I1017 16:08:53.866461 22869 caffe.cpp:218] Using GPUs 0
I1017 16:08:53.891126 22869 caffe.cpp:223] GPU 0: GeForce GTX 1080
I1017 16:08:54.122009 22869 solver.cpp:44] Initializing solver from parameters: 
test_iter: 200
test_interval: 500
base_lr: 0.01
display: 100
max_iter: 100000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0005
snapshot: 100000
snapshot_prefix: "xn/PENLU/snapshot/WRN/WRN_penlu_0.25_2study_nodecay"
solver_mode: GPU
device_id: 0
net: "/home/x306/caffe/xn/PENLU/neural/WRN/WRN_penlu_msra.prototxt"
train_state {
  level: 0
  stage: ""
}
test_initialization: false
stepvalue: 50000
stepvalue: 80000
type: "Nesterov"
I1017 16:08:54.122159 22869 solver.cpp:87] Creating training net from net file: /home/x306/caffe/xn/PENLU/neural/WRN/WRN_penlu_msra.prototxt
I1017 16:08:54.123775 22869 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: /home/x306/caffe/xn/PENLU/neural/WRN/WRN_penlu_msra.prototxt
I1017 16:08:54.123785 22869 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I1017 16:08:54.123914 22869 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer cifar
I1017 16:08:54.123980 22869 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer accuracy
I1017 16:08:54.124435 22869 net.cpp:51] Initializing net from parameters: 
name: "wrn_28_10"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 28
    mean_file: "/home/x306/caffe/xn/PENLU/data/cifar100/mean.binaryproto"
  }
  data_param {
    source: "/home/x306/caffe/xn/PENLU/data/cifar100/cifar100_train_lmdb"
    batch_size: 50
    backend: LMDB
  }
}
layer {
  name: "Convolution1"
  type: "Convolution"
  bottom: "data"
  top: "Convolution1"
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "BatchNorm1"
  type: "BatchNorm"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale1"
  type: "Scale"
  bottom: "Convolution1"
  top: "Convolution1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu1"
  type: "PENLU"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution2"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution2"
  convolution_param {
    num_output: 160
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "BatchNorm2"
  type: "BatchNorm"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale2"
  type: "Scale"
  bottom: "Convolution2"
  top: "Convolution2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu2"
  type: "PENLU"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution3"
  type: "Convolution"
  bottom: "Convolution2"
  top: "Convolution3"
  convolution_param {
    num_output: 160
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "Convolution4"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution4"
  convolution_param {
    num_output: 160
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "Eltwise1"
  type: "Eltwise"
  bottom: "Convolution3"
  bottom: "Convolution4"
  top: "Eltwise1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "BatchNorm3"
  type: "BatchNorm"
  bottom: "Eltwise1"
  top: "Eltwise1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale3"
  type: "Scale"
  bottom: "Eltwise1"
  top: "Eltwise1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu3"
  type: "PENLU"
  bottom: "Eltwise1"
  top: "Eltwise1"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution5"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution5"
  convolution_param {
    num_output: 160
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "BatchNorm4"
  type: "BatchNorm"
  bottom: "Convolution5"
  top: "Convolution5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale4"
  type: "Scale"
  bottom: "Convolution5"
  top: "Convolution5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu4"
  type: "PENLU"
  bottom: "Convolution5"
  top: "Convolution5"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution6"
  type: "Convolution"
  bottom: "Convolution5"
  top: "Convolution6"
  convolution_param {
    num_output: 160
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "Eltwise2"
  type: "Eltwise"
  bottom: "Convolution6"
  bottom: "Eltwise1"
  top: "Eltwise2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "BatchNorm5"
  type: "BatchNorm"
  bottom: "Eltwise2"
  top: "Eltwise2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale5"
  type: "Scale"
  bottom: "Eltwise2"
  top: "Eltwise2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu5"
  type: "PENLU"
  bottom: "Eltwise2"
  top: "Eltwise2"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution7"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution7"
  convolution_param {
    num_output: 160
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "BatchNorm6"
  type: "BatchNorm"
  bottom: "Convolution7"
  top: "Convolution7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale6"
  type: "Scale"
  bottom: "Convolution7"
  top: "Convolution7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu6"
  type: "PENLU"
  bottom: "Convolution7"
  top: "Convolution7"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution8"
  type: "Convolution"
  bottom: "Convolution7"
  top: "Convolution8"
  convolution_param {
    num_output: 160
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "Eltwise3"
  type: "Eltwise"
  bottom: "Convolution8"
  bottom: "Eltwise2"
  top: "Eltwise3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "BatchNorm7"
  type: "BatchNorm"
  bottom: "Eltwise3"
  top: "Eltwise3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale7"
  type: "Scale"
  bottom: "Eltwise3"
  top: "Eltwise3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu7"
  type: "PENLU"
  bottom: "Eltwise3"
  top: "Eltwise3"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution9"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution9"
  convolution_param {
    num_output: 160
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "BatchNorm8"
  type: "BatchNorm"
  bottom: "Convolution9"
  top: "Convolution9"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale8"
  type: "Scale"
  bottom: "Convolution9"
  top: "Convolution9"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu8"
  type: "PENLU"
  bottom: "Convolution9"
  top: "Convolution9"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution10"
  type: "Convolution"
  bottom: "Convolution9"
  top: "Convolution10"
  convolution_param {
    num_output: 160
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "Eltwise4"
  type: "Eltwise"
  bottom: "Convolution10"
  bottom: "Eltwise3"
  top: "Eltwise4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "Convolution11"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution11"
  convolution_param {
    num_output: 320
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "BatchNorm9"
  type: "BatchNorm"
  bottom: "Convolution11"
  top: "Convolution11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale9"
  type: "Scale"
  bottom: "Convolution11"
  top: "Convolution11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu9"
  type: "PENLU"
  bottom: "Convolution11"
  top: "Convolution11"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution12"
  type: "Convolution"
  bottom: "Convolution11"
  top: "Convolution12"
  convolution_param {
    num_output: 320
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "Convolution13"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution13"
  convolution_param {
    num_output: 320
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "Eltwise5"
  type: "Eltwise"
  bottom: "Convolution12"
  bottom: "Convolution13"
  top: "Eltwise5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "BatchNorm10"
  type: "BatchNorm"
  bottom: "Eltwise5"
  top: "Eltwise5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale10"
  type: "Scale"
  bottom: "Eltwise5"
  top: "Eltwise5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu10"
  type: "PENLU"
  bottom: "Eltwise5"
  top: "Eltwise5"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution14"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution14"
  convolution_param {
    num_output: 320
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "BatchNorm11"
  type: "BatchNorm"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale11"
  type: "Scale"
  bottom: "Convolution14"
  top: "Convolution14"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu11"
  type: "PENLU"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution15"
  type: "Convolution"
  bottom: "Convolution14"
  top: "Convolution15"
  convolution_param {
    num_output: 320
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "Eltwise6"
  type: "Eltwise"
  bottom: "Convolution15"
  bottom: "Eltwise5"
  top: "Eltwise6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "BatchNorm12"
  type: "BatchNorm"
  bottom: "Eltwise6"
  top: "Eltwise6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale12"
  type: "Scale"
  bottom: "Eltwise6"
  top: "Eltwise6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu12"
  type: "PENLU"
  bottom: "Eltwise6"
  top: "Eltwise6"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution16"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution16"
  convolution_param {
    num_output: 320
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "BatchNorm13"
  type: "BatchNorm"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale13"
  type: "Scale"
  bottom: "Convolution16"
  top: "Convolution16"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu13"
  type: "PENLU"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution17"
  type: "Convolution"
  bottom: "Convolution16"
  top: "Convolution17"
  convolution_param {
    num_output: 320
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "Eltwise7"
  type: "Eltwise"
  bottom: "Convolution17"
  bottom: "Eltwise6"
  top: "Eltwise7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "BatchNorm14"
  type: "BatchNorm"
  bottom: "Eltwise7"
  top: "Eltwise7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale14"
  type: "Scale"
  bottom: "Eltwise7"
  top: "Eltwise7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu14"
  type: "PENLU"
  bottom: "Eltwise7"
  top: "Eltwise7"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution18"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution18"
  convolution_param {
    num_output: 320
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "BatchNorm15"
  type: "BatchNorm"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale15"
  type: "Scale"
  bottom: "Convolution18"
  top: "Convolution18"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu15"
  type: "PENLU"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution19"
  type: "Convolution"
  bottom: "Convolution18"
  top: "Convolution19"
  convolution_param {
    num_output: 320
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "Eltwise8"
  type: "Eltwise"
  bottom: "Convolution19"
  bottom: "Eltwise7"
  top: "Eltwise8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "Convolution20"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution20"
  convolution_param {
    num_output: 640
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "BatchNorm16"
  type: "BatchNorm"
  bottom: "Convolution20"
  top: "Convolution20"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale16"
  type: "Scale"
  bottom: "Convolution20"
  top: "Convolution20"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu16"
  type: "PENLU"
  bottom: "Convolution20"
  top: "Convolution20"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution21"
  type: "Convolution"
  bottom: "Convolution20"
  top: "Convolution21"
  convolution_param {
    num_output: 640
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "Convolution22"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution22"
  convolution_param {
    num_output: 640
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "Eltwise9"
  type: "Eltwise"
  bottom: "Convolution21"
  bottom: "Convolution22"
  top: "Eltwise9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "BatchNorm17"
  type: "BatchNorm"
  bottom: "Eltwise9"
  top: "Eltwise9"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale17"
  type: "Scale"
  bottom: "Eltwise9"
  top: "Eltwise9"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu17"
  type: "PENLU"
  bottom: "Eltwise9"
  top: "Eltwise9"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution23"
  type: "Convolution"
  bottom: "Eltwise9"
  top: "Convolution23"
  convolution_param {
    num_output: 640
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "BatchNorm18"
  type: "BatchNorm"
  bottom: "Convolution23"
  top: "Convolution23"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale18"
  type: "Scale"
  bottom: "Convolution23"
  top: "Convolution23"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu18"
  type: "PENLU"
  bottom: "Convolution23"
  top: "Convolution23"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution24"
  type: "Convolution"
  bottom: "Convolution23"
  top: "Convolution24"
  convolution_param {
    num_output: 640
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "Eltwise10"
  type: "Eltwise"
  bottom: "Convolution24"
  bottom: "Eltwise9"
  top: "Eltwise10"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "BatchNorm19"
  type: "BatchNorm"
  bottom: "Eltwise10"
  top: "Eltwise10"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale19"
  type: "Scale"
  bottom: "Eltwise10"
  top: "Eltwise10"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu19"
  type: "PENLU"
  bottom: "Eltwise10"
  top: "Eltwise10"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution25"
  type: "Convolution"
  bottom: "Eltwise10"
  top: "Convolution25"
  convolution_param {
    num_output: 640
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "BatchNorm20"
  type: "BatchNorm"
  bottom: "Convolution25"
  top: "Convolution25"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale20"
  type: "Scale"
  bottom: "Convolution25"
  top: "Convolution25"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu20"
  type: "PENLU"
  bottom: "Convolution25"
  top: "Convolution25"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution26"
  type: "Convolution"
  bottom: "Convolution25"
  top: "Convolution26"
  convolution_param {
    num_output: 640
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "Eltwise11"
  type: "Eltwise"
  bottom: "Convolution26"
  bottom: "Eltwise10"
  top: "Eltwise11"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "BatchNorm21"
  type: "BatchNorm"
  bottom: "Eltwise11"
  top: "Eltwise11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale21"
  type: "Scale"
  bottom: "Eltwise11"
  top: "Eltwise11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu21"
  type: "PENLU"
  bottom: "Eltwise11"
  top: "Eltwise11"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution27"
  type: "Convolution"
  bottom: "Eltwise11"
  top: "Convolution27"
  convolution_param {
    num_output: 640
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "BatchNorm22"
  type: "BatchNorm"
  bottom: "Convolution27"
  top: "Convolution27"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale22"
  type: "Scale"
  bottom: "Convolution27"
  top: "Convolution27"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu22"
  type: "PENLU"
  bottom: "Convolution27"
  top: "Convolution27"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution28"
  type: "Convolution"
  bottom: "Convolution27"
  top: "Convolution28"
  convolution_param {
    num_output: 640
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "Eltwise12"
  type: "Eltwise"
  bottom: "Convolution28"
  bottom: "Eltwise11"
  top: "Eltwise12"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "Pooling1"
  type: "Pooling"
  bottom: "Eltwise12"
  top: "Pooling1"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "InnerProduct1"
  type: "InnerProduct"
  bottom: "Pooling1"
  top: "InnerProduct1"
  inner_product_param {
    num_output: 100
  }
}
layer {
  name: "SoftmaxWithLoss1"
  type: "SoftmaxWithLoss"
  bottom: "InnerProduct1"
  bottom: "label"
  top: "SoftmaxWithLoss1"
}
I1017 16:08:54.124913 22869 layer_factory.hpp:77] Creating layer cifar
I1017 16:08:54.125016 22869 db_lmdb.cpp:35] Opened lmdb /home/x306/caffe/xn/PENLU/data/cifar100/cifar100_train_lmdb
I1017 16:08:54.125042 22869 net.cpp:84] Creating Layer cifar
I1017 16:08:54.125051 22869 net.cpp:380] cifar -> data
I1017 16:08:54.125072 22869 net.cpp:380] cifar -> label
I1017 16:08:54.125084 22869 data_transformer.cpp:25] Loading mean file from: /home/x306/caffe/xn/PENLU/data/cifar100/mean.binaryproto
I1017 16:08:54.126587 22869 data_layer.cpp:45] output data size: 50,3,28,28
I1017 16:08:54.127979 22869 net.cpp:122] Setting up cifar
I1017 16:08:54.127990 22869 net.cpp:129] Top shape: 50 3 28 28 (117600)
I1017 16:08:54.127995 22869 net.cpp:129] Top shape: 50 (50)
I1017 16:08:54.127996 22869 net.cpp:137] Memory required for data: 470600
I1017 16:08:54.128001 22869 layer_factory.hpp:77] Creating layer Convolution1
I1017 16:08:54.128015 22869 net.cpp:84] Creating Layer Convolution1
I1017 16:08:54.128020 22869 net.cpp:406] Convolution1 <- data
I1017 16:08:54.128026 22869 net.cpp:380] Convolution1 -> Convolution1
I1017 16:08:54.282068 22869 net.cpp:122] Setting up Convolution1
I1017 16:08:54.282093 22869 net.cpp:129] Top shape: 50 16 28 28 (627200)
I1017 16:08:54.282096 22869 net.cpp:137] Memory required for data: 2979400
I1017 16:08:54.282110 22869 layer_factory.hpp:77] Creating layer BatchNorm1
I1017 16:08:54.282132 22869 net.cpp:84] Creating Layer BatchNorm1
I1017 16:08:54.282150 22869 net.cpp:406] BatchNorm1 <- Convolution1
I1017 16:08:54.282167 22869 net.cpp:367] BatchNorm1 -> Convolution1 (in-place)
I1017 16:08:54.282305 22869 net.cpp:122] Setting up BatchNorm1
I1017 16:08:54.282311 22869 net.cpp:129] Top shape: 50 16 28 28 (627200)
I1017 16:08:54.282315 22869 net.cpp:137] Memory required for data: 5488200
I1017 16:08:54.282322 22869 layer_factory.hpp:77] Creating layer Scale1
I1017 16:08:54.282332 22869 net.cpp:84] Creating Layer Scale1
I1017 16:08:54.282347 22869 net.cpp:406] Scale1 <- Convolution1
I1017 16:08:54.282351 22869 net.cpp:367] Scale1 -> Convolution1 (in-place)
I1017 16:08:54.282393 22869 layer_factory.hpp:77] Creating layer Scale1
I1017 16:08:54.282498 22869 net.cpp:122] Setting up Scale1
I1017 16:08:54.282505 22869 net.cpp:129] Top shape: 50 16 28 28 (627200)
I1017 16:08:54.282506 22869 net.cpp:137] Memory required for data: 7997000
I1017 16:08:54.282510 22869 layer_factory.hpp:77] Creating layer penlu1
I1017 16:08:54.282517 22869 net.cpp:84] Creating Layer penlu1
I1017 16:08:54.282521 22869 net.cpp:406] penlu1 <- Convolution1
I1017 16:08:54.282536 22869 net.cpp:367] penlu1 -> Convolution1 (in-place)
I1017 16:08:54.283145 22869 net.cpp:122] Setting up penlu1
I1017 16:08:54.283164 22869 net.cpp:129] Top shape: 50 16 28 28 (627200)
I1017 16:08:54.283170 22869 net.cpp:137] Memory required for data: 10505800
I1017 16:08:54.283191 22869 layer_factory.hpp:77] Creating layer Convolution1_penlu1_0_split
I1017 16:08:54.283201 22869 net.cpp:84] Creating Layer Convolution1_penlu1_0_split
I1017 16:08:54.283206 22869 net.cpp:406] Convolution1_penlu1_0_split <- Convolution1
I1017 16:08:54.283210 22869 net.cpp:380] Convolution1_penlu1_0_split -> Convolution1_penlu1_0_split_0
I1017 16:08:54.283217 22869 net.cpp:380] Convolution1_penlu1_0_split -> Convolution1_penlu1_0_split_1
I1017 16:08:54.283268 22869 net.cpp:122] Setting up Convolution1_penlu1_0_split
I1017 16:08:54.283282 22869 net.cpp:129] Top shape: 50 16 28 28 (627200)
I1017 16:08:54.283287 22869 net.cpp:129] Top shape: 50 16 28 28 (627200)
I1017 16:08:54.283299 22869 net.cpp:137] Memory required for data: 15523400
I1017 16:08:54.283303 22869 layer_factory.hpp:77] Creating layer Convolution2
I1017 16:08:54.283323 22869 net.cpp:84] Creating Layer Convolution2
I1017 16:08:54.283325 22869 net.cpp:406] Convolution2 <- Convolution1_penlu1_0_split_0
I1017 16:08:54.283329 22869 net.cpp:380] Convolution2 -> Convolution2
I1017 16:08:54.285446 22869 net.cpp:122] Setting up Convolution2
I1017 16:08:54.285456 22869 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1017 16:08:54.285470 22869 net.cpp:137] Memory required for data: 40611400
I1017 16:08:54.285475 22869 layer_factory.hpp:77] Creating layer BatchNorm2
I1017 16:08:54.285495 22869 net.cpp:84] Creating Layer BatchNorm2
I1017 16:08:54.285500 22869 net.cpp:406] BatchNorm2 <- Convolution2
I1017 16:08:54.285516 22869 net.cpp:367] BatchNorm2 -> Convolution2 (in-place)
I1017 16:08:54.285650 22869 net.cpp:122] Setting up BatchNorm2
I1017 16:08:54.285655 22869 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1017 16:08:54.285660 22869 net.cpp:137] Memory required for data: 65699400
I1017 16:08:54.285681 22869 layer_factory.hpp:77] Creating layer Scale2
I1017 16:08:54.285688 22869 net.cpp:84] Creating Layer Scale2
I1017 16:08:54.285692 22869 net.cpp:406] Scale2 <- Convolution2
I1017 16:08:54.285697 22869 net.cpp:367] Scale2 -> Convolution2 (in-place)
I1017 16:08:54.285734 22869 layer_factory.hpp:77] Creating layer Scale2
I1017 16:08:54.285835 22869 net.cpp:122] Setting up Scale2
I1017 16:08:54.285840 22869 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1017 16:08:54.285842 22869 net.cpp:137] Memory required for data: 90787400
I1017 16:08:54.285857 22869 layer_factory.hpp:77] Creating layer penlu2
I1017 16:08:54.285864 22869 net.cpp:84] Creating Layer penlu2
I1017 16:08:54.285867 22869 net.cpp:406] penlu2 <- Convolution2
I1017 16:08:54.285871 22869 net.cpp:367] penlu2 -> Convolution2 (in-place)
I1017 16:08:54.286520 22869 net.cpp:122] Setting up penlu2
I1017 16:08:54.286530 22869 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1017 16:08:54.286533 22869 net.cpp:137] Memory required for data: 115875400
I1017 16:08:54.286541 22869 layer_factory.hpp:77] Creating layer Convolution3
I1017 16:08:54.286548 22869 net.cpp:84] Creating Layer Convolution3
I1017 16:08:54.286552 22869 net.cpp:406] Convolution3 <- Convolution2
I1017 16:08:54.286556 22869 net.cpp:380] Convolution3 -> Convolution3
I1017 16:08:54.292654 22869 net.cpp:122] Setting up Convolution3
I1017 16:08:54.292665 22869 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1017 16:08:54.292668 22869 net.cpp:137] Memory required for data: 140963400
I1017 16:08:54.292672 22869 layer_factory.hpp:77] Creating layer Convolution4
I1017 16:08:54.292680 22869 net.cpp:84] Creating Layer Convolution4
I1017 16:08:54.292683 22869 net.cpp:406] Convolution4 <- Convolution1_penlu1_0_split_1
I1017 16:08:54.292687 22869 net.cpp:380] Convolution4 -> Convolution4
I1017 16:08:54.293542 22869 net.cpp:122] Setting up Convolution4
I1017 16:08:54.293552 22869 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1017 16:08:54.293556 22869 net.cpp:137] Memory required for data: 166051400
I1017 16:08:54.293560 22869 layer_factory.hpp:77] Creating layer Eltwise1
I1017 16:08:54.293575 22869 net.cpp:84] Creating Layer Eltwise1
I1017 16:08:54.293578 22869 net.cpp:406] Eltwise1 <- Convolution3
I1017 16:08:54.293582 22869 net.cpp:406] Eltwise1 <- Convolution4
I1017 16:08:54.293586 22869 net.cpp:380] Eltwise1 -> Eltwise1
I1017 16:08:54.293608 22869 net.cpp:122] Setting up Eltwise1
I1017 16:08:54.293613 22869 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1017 16:08:54.293617 22869 net.cpp:137] Memory required for data: 191139400
I1017 16:08:54.293619 22869 layer_factory.hpp:77] Creating layer BatchNorm3
I1017 16:08:54.293624 22869 net.cpp:84] Creating Layer BatchNorm3
I1017 16:08:54.293627 22869 net.cpp:406] BatchNorm3 <- Eltwise1
I1017 16:08:54.293630 22869 net.cpp:367] BatchNorm3 -> Eltwise1 (in-place)
I1017 16:08:54.293766 22869 net.cpp:122] Setting up BatchNorm3
I1017 16:08:54.293773 22869 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1017 16:08:54.293776 22869 net.cpp:137] Memory required for data: 216227400
I1017 16:08:54.293782 22869 layer_factory.hpp:77] Creating layer Scale3
I1017 16:08:54.293788 22869 net.cpp:84] Creating Layer Scale3
I1017 16:08:54.293792 22869 net.cpp:406] Scale3 <- Eltwise1
I1017 16:08:54.293795 22869 net.cpp:367] Scale3 -> Eltwise1 (in-place)
I1017 16:08:54.293822 22869 layer_factory.hpp:77] Creating layer Scale3
I1017 16:08:54.293920 22869 net.cpp:122] Setting up Scale3
I1017 16:08:54.293933 22869 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1017 16:08:54.293938 22869 net.cpp:137] Memory required for data: 241315400
I1017 16:08:54.293946 22869 layer_factory.hpp:77] Creating layer penlu3
I1017 16:08:54.293956 22869 net.cpp:84] Creating Layer penlu3
I1017 16:08:54.293962 22869 net.cpp:406] penlu3 <- Eltwise1
I1017 16:08:54.293968 22869 net.cpp:367] penlu3 -> Eltwise1 (in-place)
I1017 16:08:54.294153 22869 net.cpp:122] Setting up penlu3
I1017 16:08:54.294160 22869 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1017 16:08:54.294163 22869 net.cpp:137] Memory required for data: 266403400
I1017 16:08:54.294180 22869 layer_factory.hpp:77] Creating layer Eltwise1_penlu3_0_split
I1017 16:08:54.294188 22869 net.cpp:84] Creating Layer Eltwise1_penlu3_0_split
I1017 16:08:54.294190 22869 net.cpp:406] Eltwise1_penlu3_0_split <- Eltwise1
I1017 16:08:54.294194 22869 net.cpp:380] Eltwise1_penlu3_0_split -> Eltwise1_penlu3_0_split_0
I1017 16:08:54.294199 22869 net.cpp:380] Eltwise1_penlu3_0_split -> Eltwise1_penlu3_0_split_1
I1017 16:08:54.294225 22869 net.cpp:122] Setting up Eltwise1_penlu3_0_split
I1017 16:08:54.294230 22869 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1017 16:08:54.294234 22869 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1017 16:08:54.294239 22869 net.cpp:137] Memory required for data: 316579400
I1017 16:08:54.294243 22869 layer_factory.hpp:77] Creating layer Convolution5
I1017 16:08:54.294251 22869 net.cpp:84] Creating Layer Convolution5
I1017 16:08:54.294256 22869 net.cpp:406] Convolution5 <- Eltwise1_penlu3_0_split_0
I1017 16:08:54.294261 22869 net.cpp:380] Convolution5 -> Convolution5
I1017 16:08:54.301036 22869 net.cpp:122] Setting up Convolution5
I1017 16:08:54.301051 22869 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1017 16:08:54.301054 22869 net.cpp:137] Memory required for data: 341667400
I1017 16:08:54.301059 22869 layer_factory.hpp:77] Creating layer BatchNorm4
I1017 16:08:54.301065 22869 net.cpp:84] Creating Layer BatchNorm4
I1017 16:08:54.301070 22869 net.cpp:406] BatchNorm4 <- Convolution5
I1017 16:08:54.301074 22869 net.cpp:367] BatchNorm4 -> Convolution5 (in-place)
I1017 16:08:54.301208 22869 net.cpp:122] Setting up BatchNorm4
I1017 16:08:54.301213 22869 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1017 16:08:54.301215 22869 net.cpp:137] Memory required for data: 366755400
I1017 16:08:54.301225 22869 layer_factory.hpp:77] Creating layer Scale4
I1017 16:08:54.301235 22869 net.cpp:84] Creating Layer Scale4
I1017 16:08:54.301239 22869 net.cpp:406] Scale4 <- Convolution5
I1017 16:08:54.301242 22869 net.cpp:367] Scale4 -> Convolution5 (in-place)
I1017 16:08:54.301270 22869 layer_factory.hpp:77] Creating layer Scale4
I1017 16:08:54.301354 22869 net.cpp:122] Setting up Scale4
I1017 16:08:54.301360 22869 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1017 16:08:54.301363 22869 net.cpp:137] Memory required for data: 391843400
I1017 16:08:54.301367 22869 layer_factory.hpp:77] Creating layer penlu4
I1017 16:08:54.301374 22869 net.cpp:84] Creating Layer penlu4
I1017 16:08:54.301378 22869 net.cpp:406] penlu4 <- Convolution5
I1017 16:08:54.301381 22869 net.cpp:367] penlu4 -> Convolution5 (in-place)
I1017 16:08:54.301553 22869 net.cpp:122] Setting up penlu4
I1017 16:08:54.301558 22869 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1017 16:08:54.301560 22869 net.cpp:137] Memory required for data: 416931400
I1017 16:08:54.301565 22869 layer_factory.hpp:77] Creating layer Convolution6
I1017 16:08:54.301573 22869 net.cpp:84] Creating Layer Convolution6
I1017 16:08:54.301576 22869 net.cpp:406] Convolution6 <- Convolution5
I1017 16:08:54.301580 22869 net.cpp:380] Convolution6 -> Convolution6
I1017 16:08:54.308284 22869 net.cpp:122] Setting up Convolution6
I1017 16:08:54.308295 22869 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1017 16:08:54.308298 22869 net.cpp:137] Memory required for data: 442019400
I1017 16:08:54.308302 22869 layer_factory.hpp:77] Creating layer Eltwise2
I1017 16:08:54.308308 22869 net.cpp:84] Creating Layer Eltwise2
I1017 16:08:54.308313 22869 net.cpp:406] Eltwise2 <- Convolution6
I1017 16:08:54.308316 22869 net.cpp:406] Eltwise2 <- Eltwise1_penlu3_0_split_1
I1017 16:08:54.308320 22869 net.cpp:380] Eltwise2 -> Eltwise2
I1017 16:08:54.308341 22869 net.cpp:122] Setting up Eltwise2
I1017 16:08:54.308346 22869 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1017 16:08:54.308348 22869 net.cpp:137] Memory required for data: 467107400
I1017 16:08:54.308351 22869 layer_factory.hpp:77] Creating layer BatchNorm5
I1017 16:08:54.308356 22869 net.cpp:84] Creating Layer BatchNorm5
I1017 16:08:54.308358 22869 net.cpp:406] BatchNorm5 <- Eltwise2
I1017 16:08:54.308362 22869 net.cpp:367] BatchNorm5 -> Eltwise2 (in-place)
I1017 16:08:54.308492 22869 net.cpp:122] Setting up BatchNorm5
I1017 16:08:54.308497 22869 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1017 16:08:54.308501 22869 net.cpp:137] Memory required for data: 492195400
I1017 16:08:54.308506 22869 layer_factory.hpp:77] Creating layer Scale5
I1017 16:08:54.308511 22869 net.cpp:84] Creating Layer Scale5
I1017 16:08:54.308516 22869 net.cpp:406] Scale5 <- Eltwise2
I1017 16:08:54.308518 22869 net.cpp:367] Scale5 -> Eltwise2 (in-place)
I1017 16:08:54.308547 22869 layer_factory.hpp:77] Creating layer Scale5
I1017 16:08:54.308626 22869 net.cpp:122] Setting up Scale5
I1017 16:08:54.308631 22869 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1017 16:08:54.308634 22869 net.cpp:137] Memory required for data: 517283400
I1017 16:08:54.308639 22869 layer_factory.hpp:77] Creating layer penlu5
I1017 16:08:54.308645 22869 net.cpp:84] Creating Layer penlu5
I1017 16:08:54.308648 22869 net.cpp:406] penlu5 <- Eltwise2
I1017 16:08:54.308652 22869 net.cpp:367] penlu5 -> Eltwise2 (in-place)
I1017 16:08:54.308820 22869 net.cpp:122] Setting up penlu5
I1017 16:08:54.308825 22869 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1017 16:08:54.308827 22869 net.cpp:137] Memory required for data: 542371400
I1017 16:08:54.308832 22869 layer_factory.hpp:77] Creating layer Eltwise2_penlu5_0_split
I1017 16:08:54.308837 22869 net.cpp:84] Creating Layer Eltwise2_penlu5_0_split
I1017 16:08:54.308840 22869 net.cpp:406] Eltwise2_penlu5_0_split <- Eltwise2
I1017 16:08:54.308843 22869 net.cpp:380] Eltwise2_penlu5_0_split -> Eltwise2_penlu5_0_split_0
I1017 16:08:54.308848 22869 net.cpp:380] Eltwise2_penlu5_0_split -> Eltwise2_penlu5_0_split_1
I1017 16:08:54.308871 22869 net.cpp:122] Setting up Eltwise2_penlu5_0_split
I1017 16:08:54.308876 22869 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1017 16:08:54.308881 22869 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1017 16:08:54.308882 22869 net.cpp:137] Memory required for data: 592547400
I1017 16:08:54.308884 22869 layer_factory.hpp:77] Creating layer Convolution7
I1017 16:08:54.308899 22869 net.cpp:84] Creating Layer Convolution7
I1017 16:08:54.308903 22869 net.cpp:406] Convolution7 <- Eltwise2_penlu5_0_split_0
I1017 16:08:54.308907 22869 net.cpp:380] Convolution7 -> Convolution7
I1017 16:08:54.315542 22869 net.cpp:122] Setting up Convolution7
I1017 16:08:54.315557 22869 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1017 16:08:54.315559 22869 net.cpp:137] Memory required for data: 617635400
I1017 16:08:54.315564 22869 layer_factory.hpp:77] Creating layer BatchNorm6
I1017 16:08:54.315582 22869 net.cpp:84] Creating Layer BatchNorm6
I1017 16:08:54.315585 22869 net.cpp:406] BatchNorm6 <- Convolution7
I1017 16:08:54.315589 22869 net.cpp:367] BatchNorm6 -> Convolution7 (in-place)
I1017 16:08:54.315744 22869 net.cpp:122] Setting up BatchNorm6
I1017 16:08:54.315750 22869 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1017 16:08:54.315753 22869 net.cpp:137] Memory required for data: 642723400
I1017 16:08:54.315769 22869 layer_factory.hpp:77] Creating layer Scale6
I1017 16:08:54.315774 22869 net.cpp:84] Creating Layer Scale6
I1017 16:08:54.315778 22869 net.cpp:406] Scale6 <- Convolution7
I1017 16:08:54.315781 22869 net.cpp:367] Scale6 -> Convolution7 (in-place)
I1017 16:08:54.315820 22869 layer_factory.hpp:77] Creating layer Scale6
I1017 16:08:54.315903 22869 net.cpp:122] Setting up Scale6
I1017 16:08:54.315909 22869 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1017 16:08:54.315912 22869 net.cpp:137] Memory required for data: 667811400
I1017 16:08:54.315915 22869 layer_factory.hpp:77] Creating layer penlu6
I1017 16:08:54.315922 22869 net.cpp:84] Creating Layer penlu6
I1017 16:08:54.315925 22869 net.cpp:406] penlu6 <- Convolution7
I1017 16:08:54.315929 22869 net.cpp:367] penlu6 -> Convolution7 (in-place)
I1017 16:08:54.316117 22869 net.cpp:122] Setting up penlu6
I1017 16:08:54.316123 22869 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1017 16:08:54.316124 22869 net.cpp:137] Memory required for data: 692899400
I1017 16:08:54.316129 22869 layer_factory.hpp:77] Creating layer Convolution8
I1017 16:08:54.316138 22869 net.cpp:84] Creating Layer Convolution8
I1017 16:08:54.316140 22869 net.cpp:406] Convolution8 <- Convolution7
I1017 16:08:54.316144 22869 net.cpp:380] Convolution8 -> Convolution8
I1017 16:08:54.322892 22869 net.cpp:122] Setting up Convolution8
I1017 16:08:54.322903 22869 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1017 16:08:54.322906 22869 net.cpp:137] Memory required for data: 717987400
I1017 16:08:54.322911 22869 layer_factory.hpp:77] Creating layer Eltwise3
I1017 16:08:54.322921 22869 net.cpp:84] Creating Layer Eltwise3
I1017 16:08:54.322924 22869 net.cpp:406] Eltwise3 <- Convolution8
I1017 16:08:54.322928 22869 net.cpp:406] Eltwise3 <- Eltwise2_penlu5_0_split_1
I1017 16:08:54.322932 22869 net.cpp:380] Eltwise3 -> Eltwise3
I1017 16:08:54.322952 22869 net.cpp:122] Setting up Eltwise3
I1017 16:08:54.322957 22869 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1017 16:08:54.322960 22869 net.cpp:137] Memory required for data: 743075400
I1017 16:08:54.322962 22869 layer_factory.hpp:77] Creating layer BatchNorm7
I1017 16:08:54.322966 22869 net.cpp:84] Creating Layer BatchNorm7
I1017 16:08:54.322970 22869 net.cpp:406] BatchNorm7 <- Eltwise3
I1017 16:08:54.322973 22869 net.cpp:367] BatchNorm7 -> Eltwise3 (in-place)
I1017 16:08:54.323107 22869 net.cpp:122] Setting up BatchNorm7
I1017 16:08:54.323113 22869 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1017 16:08:54.323117 22869 net.cpp:137] Memory required for data: 768163400
I1017 16:08:54.323122 22869 layer_factory.hpp:77] Creating layer Scale7
I1017 16:08:54.323127 22869 net.cpp:84] Creating Layer Scale7
I1017 16:08:54.323128 22869 net.cpp:406] Scale7 <- Eltwise3
I1017 16:08:54.323132 22869 net.cpp:367] Scale7 -> Eltwise3 (in-place)
I1017 16:08:54.323159 22869 layer_factory.hpp:77] Creating layer Scale7
I1017 16:08:54.323240 22869 net.cpp:122] Setting up Scale7
I1017 16:08:54.323245 22869 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1017 16:08:54.323247 22869 net.cpp:137] Memory required for data: 793251400
I1017 16:08:54.323261 22869 layer_factory.hpp:77] Creating layer penlu7
I1017 16:08:54.323268 22869 net.cpp:84] Creating Layer penlu7
I1017 16:08:54.323272 22869 net.cpp:406] penlu7 <- Eltwise3
I1017 16:08:54.323276 22869 net.cpp:367] penlu7 -> Eltwise3 (in-place)
I1017 16:08:54.323437 22869 net.cpp:122] Setting up penlu7
I1017 16:08:54.323443 22869 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1017 16:08:54.323446 22869 net.cpp:137] Memory required for data: 818339400
I1017 16:08:54.323458 22869 layer_factory.hpp:77] Creating layer Eltwise3_penlu7_0_split
I1017 16:08:54.323463 22869 net.cpp:84] Creating Layer Eltwise3_penlu7_0_split
I1017 16:08:54.323467 22869 net.cpp:406] Eltwise3_penlu7_0_split <- Eltwise3
I1017 16:08:54.323470 22869 net.cpp:380] Eltwise3_penlu7_0_split -> Eltwise3_penlu7_0_split_0
I1017 16:08:54.323475 22869 net.cpp:380] Eltwise3_penlu7_0_split -> Eltwise3_penlu7_0_split_1
I1017 16:08:54.323500 22869 net.cpp:122] Setting up Eltwise3_penlu7_0_split
I1017 16:08:54.323505 22869 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1017 16:08:54.323509 22869 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1017 16:08:54.323511 22869 net.cpp:137] Memory required for data: 868515400
I1017 16:08:54.323514 22869 layer_factory.hpp:77] Creating layer Convolution9
I1017 16:08:54.323520 22869 net.cpp:84] Creating Layer Convolution9
I1017 16:08:54.323523 22869 net.cpp:406] Convolution9 <- Eltwise3_penlu7_0_split_0
I1017 16:08:54.323527 22869 net.cpp:380] Convolution9 -> Convolution9
I1017 16:08:54.330247 22869 net.cpp:122] Setting up Convolution9
I1017 16:08:54.330258 22869 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1017 16:08:54.330261 22869 net.cpp:137] Memory required for data: 893603400
I1017 16:08:54.330266 22869 layer_factory.hpp:77] Creating layer BatchNorm8
I1017 16:08:54.330272 22869 net.cpp:84] Creating Layer BatchNorm8
I1017 16:08:54.330276 22869 net.cpp:406] BatchNorm8 <- Convolution9
I1017 16:08:54.330281 22869 net.cpp:367] BatchNorm8 -> Convolution9 (in-place)
I1017 16:08:54.330420 22869 net.cpp:122] Setting up BatchNorm8
I1017 16:08:54.330425 22869 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1017 16:08:54.330428 22869 net.cpp:137] Memory required for data: 918691400
I1017 16:08:54.330433 22869 layer_factory.hpp:77] Creating layer Scale8
I1017 16:08:54.330440 22869 net.cpp:84] Creating Layer Scale8
I1017 16:08:54.330443 22869 net.cpp:406] Scale8 <- Convolution9
I1017 16:08:54.330446 22869 net.cpp:367] Scale8 -> Convolution9 (in-place)
I1017 16:08:54.330473 22869 layer_factory.hpp:77] Creating layer Scale8
I1017 16:08:54.330554 22869 net.cpp:122] Setting up Scale8
I1017 16:08:54.330559 22869 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1017 16:08:54.330562 22869 net.cpp:137] Memory required for data: 943779400
I1017 16:08:54.330566 22869 layer_factory.hpp:77] Creating layer penlu8
I1017 16:08:54.330574 22869 net.cpp:84] Creating Layer penlu8
I1017 16:08:54.330577 22869 net.cpp:406] penlu8 <- Convolution9
I1017 16:08:54.330580 22869 net.cpp:367] penlu8 -> Convolution9 (in-place)
I1017 16:08:54.330739 22869 net.cpp:122] Setting up penlu8
I1017 16:08:54.330745 22869 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1017 16:08:54.330749 22869 net.cpp:137] Memory required for data: 968867400
I1017 16:08:54.330752 22869 layer_factory.hpp:77] Creating layer Convolution10
I1017 16:08:54.330760 22869 net.cpp:84] Creating Layer Convolution10
I1017 16:08:54.330763 22869 net.cpp:406] Convolution10 <- Convolution9
I1017 16:08:54.330767 22869 net.cpp:380] Convolution10 -> Convolution10
I1017 16:08:54.337472 22869 net.cpp:122] Setting up Convolution10
I1017 16:08:54.337484 22869 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1017 16:08:54.337487 22869 net.cpp:137] Memory required for data: 993955400
I1017 16:08:54.337491 22869 layer_factory.hpp:77] Creating layer Eltwise4
I1017 16:08:54.337499 22869 net.cpp:84] Creating Layer Eltwise4
I1017 16:08:54.337502 22869 net.cpp:406] Eltwise4 <- Convolution10
I1017 16:08:54.337507 22869 net.cpp:406] Eltwise4 <- Eltwise3_penlu7_0_split_1
I1017 16:08:54.337509 22869 net.cpp:380] Eltwise4 -> Eltwise4
I1017 16:08:54.337540 22869 net.cpp:122] Setting up Eltwise4
I1017 16:08:54.337546 22869 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1017 16:08:54.337548 22869 net.cpp:137] Memory required for data: 1019043400
I1017 16:08:54.337551 22869 layer_factory.hpp:77] Creating layer Eltwise4_Eltwise4_0_split
I1017 16:08:54.337554 22869 net.cpp:84] Creating Layer Eltwise4_Eltwise4_0_split
I1017 16:08:54.337558 22869 net.cpp:406] Eltwise4_Eltwise4_0_split <- Eltwise4
I1017 16:08:54.337561 22869 net.cpp:380] Eltwise4_Eltwise4_0_split -> Eltwise4_Eltwise4_0_split_0
I1017 16:08:54.337566 22869 net.cpp:380] Eltwise4_Eltwise4_0_split -> Eltwise4_Eltwise4_0_split_1
I1017 16:08:54.337591 22869 net.cpp:122] Setting up Eltwise4_Eltwise4_0_split
I1017 16:08:54.337596 22869 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1017 16:08:54.337600 22869 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1017 16:08:54.337602 22869 net.cpp:137] Memory required for data: 1069219400
I1017 16:08:54.337604 22869 layer_factory.hpp:77] Creating layer Convolution11
I1017 16:08:54.337610 22869 net.cpp:84] Creating Layer Convolution11
I1017 16:08:54.337613 22869 net.cpp:406] Convolution11 <- Eltwise4_Eltwise4_0_split_0
I1017 16:08:54.337618 22869 net.cpp:380] Convolution11 -> Convolution11
I1017 16:08:54.349450 22869 net.cpp:122] Setting up Convolution11
I1017 16:08:54.349475 22869 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1017 16:08:54.349478 22869 net.cpp:137] Memory required for data: 1081763400
I1017 16:08:54.349484 22869 layer_factory.hpp:77] Creating layer BatchNorm9
I1017 16:08:54.349493 22869 net.cpp:84] Creating Layer BatchNorm9
I1017 16:08:54.349496 22869 net.cpp:406] BatchNorm9 <- Convolution11
I1017 16:08:54.349501 22869 net.cpp:367] BatchNorm9 -> Convolution11 (in-place)
I1017 16:08:54.349668 22869 net.cpp:122] Setting up BatchNorm9
I1017 16:08:54.349673 22869 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1017 16:08:54.349685 22869 net.cpp:137] Memory required for data: 1094307400
I1017 16:08:54.349691 22869 layer_factory.hpp:77] Creating layer Scale9
I1017 16:08:54.349697 22869 net.cpp:84] Creating Layer Scale9
I1017 16:08:54.349699 22869 net.cpp:406] Scale9 <- Convolution11
I1017 16:08:54.349704 22869 net.cpp:367] Scale9 -> Convolution11 (in-place)
I1017 16:08:54.349735 22869 layer_factory.hpp:77] Creating layer Scale9
I1017 16:08:54.349818 22869 net.cpp:122] Setting up Scale9
I1017 16:08:54.349823 22869 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1017 16:08:54.349825 22869 net.cpp:137] Memory required for data: 1106851400
I1017 16:08:54.349829 22869 layer_factory.hpp:77] Creating layer penlu9
I1017 16:08:54.349838 22869 net.cpp:84] Creating Layer penlu9
I1017 16:08:54.349841 22869 net.cpp:406] penlu9 <- Convolution11
I1017 16:08:54.349844 22869 net.cpp:367] penlu9 -> Convolution11 (in-place)
I1017 16:08:54.350023 22869 net.cpp:122] Setting up penlu9
I1017 16:08:54.350028 22869 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1017 16:08:54.350031 22869 net.cpp:137] Memory required for data: 1119395400
I1017 16:08:54.350036 22869 layer_factory.hpp:77] Creating layer Convolution12
I1017 16:08:54.350044 22869 net.cpp:84] Creating Layer Convolution12
I1017 16:08:54.350047 22869 net.cpp:406] Convolution12 <- Convolution11
I1017 16:08:54.350051 22869 net.cpp:380] Convolution12 -> Convolution12
I1017 16:08:54.372599 22869 net.cpp:122] Setting up Convolution12
I1017 16:08:54.372617 22869 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1017 16:08:54.372622 22869 net.cpp:137] Memory required for data: 1131939400
I1017 16:08:54.372628 22869 layer_factory.hpp:77] Creating layer Convolution13
I1017 16:08:54.372639 22869 net.cpp:84] Creating Layer Convolution13
I1017 16:08:54.372644 22869 net.cpp:406] Convolution13 <- Eltwise4_Eltwise4_0_split_1
I1017 16:08:54.372650 22869 net.cpp:380] Convolution13 -> Convolution13
I1017 16:08:54.374826 22869 net.cpp:122] Setting up Convolution13
I1017 16:08:54.374838 22869 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1017 16:08:54.374841 22869 net.cpp:137] Memory required for data: 1144483400
I1017 16:08:54.374866 22869 layer_factory.hpp:77] Creating layer Eltwise5
I1017 16:08:54.374871 22869 net.cpp:84] Creating Layer Eltwise5
I1017 16:08:54.374876 22869 net.cpp:406] Eltwise5 <- Convolution12
I1017 16:08:54.374878 22869 net.cpp:406] Eltwise5 <- Convolution13
I1017 16:08:54.374882 22869 net.cpp:380] Eltwise5 -> Eltwise5
I1017 16:08:54.374905 22869 net.cpp:122] Setting up Eltwise5
I1017 16:08:54.374910 22869 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1017 16:08:54.374913 22869 net.cpp:137] Memory required for data: 1157027400
I1017 16:08:54.374925 22869 layer_factory.hpp:77] Creating layer BatchNorm10
I1017 16:08:54.374930 22869 net.cpp:84] Creating Layer BatchNorm10
I1017 16:08:54.374943 22869 net.cpp:406] BatchNorm10 <- Eltwise5
I1017 16:08:54.374948 22869 net.cpp:367] BatchNorm10 -> Eltwise5 (in-place)
I1017 16:08:54.375108 22869 net.cpp:122] Setting up BatchNorm10
I1017 16:08:54.375113 22869 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1017 16:08:54.375116 22869 net.cpp:137] Memory required for data: 1169571400
I1017 16:08:54.375133 22869 layer_factory.hpp:77] Creating layer Scale10
I1017 16:08:54.375138 22869 net.cpp:84] Creating Layer Scale10
I1017 16:08:54.375141 22869 net.cpp:406] Scale10 <- Eltwise5
I1017 16:08:54.375144 22869 net.cpp:367] Scale10 -> Eltwise5 (in-place)
I1017 16:08:54.375190 22869 layer_factory.hpp:77] Creating layer Scale10
I1017 16:08:54.375291 22869 net.cpp:122] Setting up Scale10
I1017 16:08:54.375298 22869 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1017 16:08:54.375300 22869 net.cpp:137] Memory required for data: 1182115400
I1017 16:08:54.375314 22869 layer_factory.hpp:77] Creating layer penlu10
I1017 16:08:54.375321 22869 net.cpp:84] Creating Layer penlu10
I1017 16:08:54.375324 22869 net.cpp:406] penlu10 <- Eltwise5
I1017 16:08:54.375329 22869 net.cpp:367] penlu10 -> Eltwise5 (in-place)
I1017 16:08:54.375489 22869 net.cpp:122] Setting up penlu10
I1017 16:08:54.375495 22869 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1017 16:08:54.375497 22869 net.cpp:137] Memory required for data: 1194659400
I1017 16:08:54.375512 22869 layer_factory.hpp:77] Creating layer Eltwise5_penlu10_0_split
I1017 16:08:54.375517 22869 net.cpp:84] Creating Layer Eltwise5_penlu10_0_split
I1017 16:08:54.375520 22869 net.cpp:406] Eltwise5_penlu10_0_split <- Eltwise5
I1017 16:08:54.375524 22869 net.cpp:380] Eltwise5_penlu10_0_split -> Eltwise5_penlu10_0_split_0
I1017 16:08:54.375532 22869 net.cpp:380] Eltwise5_penlu10_0_split -> Eltwise5_penlu10_0_split_1
I1017 16:08:54.375573 22869 net.cpp:122] Setting up Eltwise5_penlu10_0_split
I1017 16:08:54.375578 22869 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1017 16:08:54.375584 22869 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1017 16:08:54.375599 22869 net.cpp:137] Memory required for data: 1219747400
I1017 16:08:54.375604 22869 layer_factory.hpp:77] Creating layer Convolution14
I1017 16:08:54.375612 22869 net.cpp:84] Creating Layer Convolution14
I1017 16:08:54.375617 22869 net.cpp:406] Convolution14 <- Eltwise5_penlu10_0_split_0
I1017 16:08:54.375622 22869 net.cpp:380] Convolution14 -> Convolution14
I1017 16:08:54.397931 22869 net.cpp:122] Setting up Convolution14
I1017 16:08:54.397948 22869 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1017 16:08:54.397950 22869 net.cpp:137] Memory required for data: 1232291400
I1017 16:08:54.397964 22869 layer_factory.hpp:77] Creating layer BatchNorm11
I1017 16:08:54.397982 22869 net.cpp:84] Creating Layer BatchNorm11
I1017 16:08:54.397986 22869 net.cpp:406] BatchNorm11 <- Convolution14
I1017 16:08:54.397991 22869 net.cpp:367] BatchNorm11 -> Convolution14 (in-place)
I1017 16:08:54.398155 22869 net.cpp:122] Setting up BatchNorm11
I1017 16:08:54.398160 22869 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1017 16:08:54.398164 22869 net.cpp:137] Memory required for data: 1244835400
I1017 16:08:54.398169 22869 layer_factory.hpp:77] Creating layer Scale11
I1017 16:08:54.398175 22869 net.cpp:84] Creating Layer Scale11
I1017 16:08:54.398177 22869 net.cpp:406] Scale11 <- Convolution14
I1017 16:08:54.398190 22869 net.cpp:367] Scale11 -> Convolution14 (in-place)
I1017 16:08:54.398224 22869 layer_factory.hpp:77] Creating layer Scale11
I1017 16:08:54.398308 22869 net.cpp:122] Setting up Scale11
I1017 16:08:54.398313 22869 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1017 16:08:54.398316 22869 net.cpp:137] Memory required for data: 1257379400
I1017 16:08:54.398320 22869 layer_factory.hpp:77] Creating layer penlu11
I1017 16:08:54.398327 22869 net.cpp:84] Creating Layer penlu11
I1017 16:08:54.398330 22869 net.cpp:406] penlu11 <- Convolution14
I1017 16:08:54.398334 22869 net.cpp:367] penlu11 -> Convolution14 (in-place)
I1017 16:08:54.398486 22869 net.cpp:122] Setting up penlu11
I1017 16:08:54.398492 22869 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1017 16:08:54.398494 22869 net.cpp:137] Memory required for data: 1269923400
I1017 16:08:54.398499 22869 layer_factory.hpp:77] Creating layer Convolution15
I1017 16:08:54.398506 22869 net.cpp:84] Creating Layer Convolution15
I1017 16:08:54.398510 22869 net.cpp:406] Convolution15 <- Convolution14
I1017 16:08:54.398514 22869 net.cpp:380] Convolution15 -> Convolution15
I1017 16:08:54.420783 22869 net.cpp:122] Setting up Convolution15
I1017 16:08:54.420801 22869 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1017 16:08:54.420804 22869 net.cpp:137] Memory required for data: 1282467400
I1017 16:08:54.420810 22869 layer_factory.hpp:77] Creating layer Eltwise6
I1017 16:08:54.420819 22869 net.cpp:84] Creating Layer Eltwise6
I1017 16:08:54.420833 22869 net.cpp:406] Eltwise6 <- Convolution15
I1017 16:08:54.420838 22869 net.cpp:406] Eltwise6 <- Eltwise5_penlu10_0_split_1
I1017 16:08:54.420843 22869 net.cpp:380] Eltwise6 -> Eltwise6
I1017 16:08:54.420868 22869 net.cpp:122] Setting up Eltwise6
I1017 16:08:54.420873 22869 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1017 16:08:54.420876 22869 net.cpp:137] Memory required for data: 1295011400
I1017 16:08:54.420887 22869 layer_factory.hpp:77] Creating layer BatchNorm12
I1017 16:08:54.420892 22869 net.cpp:84] Creating Layer BatchNorm12
I1017 16:08:54.420907 22869 net.cpp:406] BatchNorm12 <- Eltwise6
I1017 16:08:54.420909 22869 net.cpp:367] BatchNorm12 -> Eltwise6 (in-place)
I1017 16:08:54.421072 22869 net.cpp:122] Setting up BatchNorm12
I1017 16:08:54.421077 22869 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1017 16:08:54.421080 22869 net.cpp:137] Memory required for data: 1307555400
I1017 16:08:54.421095 22869 layer_factory.hpp:77] Creating layer Scale12
I1017 16:08:54.421102 22869 net.cpp:84] Creating Layer Scale12
I1017 16:08:54.421104 22869 net.cpp:406] Scale12 <- Eltwise6
I1017 16:08:54.421108 22869 net.cpp:367] Scale12 -> Eltwise6 (in-place)
I1017 16:08:54.421157 22869 layer_factory.hpp:77] Creating layer Scale12
I1017 16:08:54.421264 22869 net.cpp:122] Setting up Scale12
I1017 16:08:54.421272 22869 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1017 16:08:54.421275 22869 net.cpp:137] Memory required for data: 1320099400
I1017 16:08:54.421293 22869 layer_factory.hpp:77] Creating layer penlu12
I1017 16:08:54.421303 22869 net.cpp:84] Creating Layer penlu12
I1017 16:08:54.421308 22869 net.cpp:406] penlu12 <- Eltwise6
I1017 16:08:54.421315 22869 net.cpp:367] penlu12 -> Eltwise6 (in-place)
I1017 16:08:54.421473 22869 net.cpp:122] Setting up penlu12
I1017 16:08:54.421479 22869 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1017 16:08:54.421484 22869 net.cpp:137] Memory required for data: 1332643400
I1017 16:08:54.421494 22869 layer_factory.hpp:77] Creating layer Eltwise6_penlu12_0_split
I1017 16:08:54.421506 22869 net.cpp:84] Creating Layer Eltwise6_penlu12_0_split
I1017 16:08:54.421510 22869 net.cpp:406] Eltwise6_penlu12_0_split <- Eltwise6
I1017 16:08:54.421515 22869 net.cpp:380] Eltwise6_penlu12_0_split -> Eltwise6_penlu12_0_split_0
I1017 16:08:54.421521 22869 net.cpp:380] Eltwise6_penlu12_0_split -> Eltwise6_penlu12_0_split_1
I1017 16:08:54.421548 22869 net.cpp:122] Setting up Eltwise6_penlu12_0_split
I1017 16:08:54.421555 22869 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1017 16:08:54.421558 22869 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1017 16:08:54.421569 22869 net.cpp:137] Memory required for data: 1357731400
I1017 16:08:54.421572 22869 layer_factory.hpp:77] Creating layer Convolution16
I1017 16:08:54.421579 22869 net.cpp:84] Creating Layer Convolution16
I1017 16:08:54.421583 22869 net.cpp:406] Convolution16 <- Eltwise6_penlu12_0_split_0
I1017 16:08:54.421587 22869 net.cpp:380] Convolution16 -> Convolution16
I1017 16:08:54.443929 22869 net.cpp:122] Setting up Convolution16
I1017 16:08:54.443948 22869 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1017 16:08:54.443950 22869 net.cpp:137] Memory required for data: 1370275400
I1017 16:08:54.443956 22869 layer_factory.hpp:77] Creating layer BatchNorm13
I1017 16:08:54.443965 22869 net.cpp:84] Creating Layer BatchNorm13
I1017 16:08:54.443969 22869 net.cpp:406] BatchNorm13 <- Convolution16
I1017 16:08:54.443984 22869 net.cpp:367] BatchNorm13 -> Convolution16 (in-place)
I1017 16:08:54.444151 22869 net.cpp:122] Setting up BatchNorm13
I1017 16:08:54.444157 22869 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1017 16:08:54.444159 22869 net.cpp:137] Memory required for data: 1382819400
I1017 16:08:54.444165 22869 layer_factory.hpp:77] Creating layer Scale13
I1017 16:08:54.444170 22869 net.cpp:84] Creating Layer Scale13
I1017 16:08:54.444173 22869 net.cpp:406] Scale13 <- Convolution16
I1017 16:08:54.444176 22869 net.cpp:367] Scale13 -> Convolution16 (in-place)
I1017 16:08:54.444221 22869 layer_factory.hpp:77] Creating layer Scale13
I1017 16:08:54.444334 22869 net.cpp:122] Setting up Scale13
I1017 16:08:54.444339 22869 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1017 16:08:54.444340 22869 net.cpp:137] Memory required for data: 1395363400
I1017 16:08:54.444344 22869 layer_factory.hpp:77] Creating layer penlu13
I1017 16:08:54.444362 22869 net.cpp:84] Creating Layer penlu13
I1017 16:08:54.444365 22869 net.cpp:406] penlu13 <- Convolution16
I1017 16:08:54.444370 22869 net.cpp:367] penlu13 -> Convolution16 (in-place)
I1017 16:08:54.444531 22869 net.cpp:122] Setting up penlu13
I1017 16:08:54.444537 22869 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1017 16:08:54.444540 22869 net.cpp:137] Memory required for data: 1407907400
I1017 16:08:54.444553 22869 layer_factory.hpp:77] Creating layer Convolution17
I1017 16:08:54.444562 22869 net.cpp:84] Creating Layer Convolution17
I1017 16:08:54.444566 22869 net.cpp:406] Convolution17 <- Convolution16
I1017 16:08:54.444569 22869 net.cpp:380] Convolution17 -> Convolution17
I1017 16:08:54.466464 22869 net.cpp:122] Setting up Convolution17
I1017 16:08:54.466480 22869 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1017 16:08:54.466482 22869 net.cpp:137] Memory required for data: 1420451400
I1017 16:08:54.466488 22869 layer_factory.hpp:77] Creating layer Eltwise7
I1017 16:08:54.466497 22869 net.cpp:84] Creating Layer Eltwise7
I1017 16:08:54.466511 22869 net.cpp:406] Eltwise7 <- Convolution17
I1017 16:08:54.466516 22869 net.cpp:406] Eltwise7 <- Eltwise6_penlu12_0_split_1
I1017 16:08:54.466521 22869 net.cpp:380] Eltwise7 -> Eltwise7
I1017 16:08:54.466578 22869 net.cpp:122] Setting up Eltwise7
I1017 16:08:54.466583 22869 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1017 16:08:54.466596 22869 net.cpp:137] Memory required for data: 1432995400
I1017 16:08:54.466598 22869 layer_factory.hpp:77] Creating layer BatchNorm14
I1017 16:08:54.466603 22869 net.cpp:84] Creating Layer BatchNorm14
I1017 16:08:54.466614 22869 net.cpp:406] BatchNorm14 <- Eltwise7
I1017 16:08:54.466619 22869 net.cpp:367] BatchNorm14 -> Eltwise7 (in-place)
I1017 16:08:54.466792 22869 net.cpp:122] Setting up BatchNorm14
I1017 16:08:54.466797 22869 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1017 16:08:54.466799 22869 net.cpp:137] Memory required for data: 1445539400
I1017 16:08:54.466804 22869 layer_factory.hpp:77] Creating layer Scale14
I1017 16:08:54.466809 22869 net.cpp:84] Creating Layer Scale14
I1017 16:08:54.466812 22869 net.cpp:406] Scale14 <- Eltwise7
I1017 16:08:54.466826 22869 net.cpp:367] Scale14 -> Eltwise7 (in-place)
I1017 16:08:54.466859 22869 layer_factory.hpp:77] Creating layer Scale14
I1017 16:08:54.466984 22869 net.cpp:122] Setting up Scale14
I1017 16:08:54.466990 22869 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1017 16:08:54.466992 22869 net.cpp:137] Memory required for data: 1458083400
I1017 16:08:54.467006 22869 layer_factory.hpp:77] Creating layer penlu14
I1017 16:08:54.467015 22869 net.cpp:84] Creating Layer penlu14
I1017 16:08:54.467017 22869 net.cpp:406] penlu14 <- Eltwise7
I1017 16:08:54.467021 22869 net.cpp:367] penlu14 -> Eltwise7 (in-place)
I1017 16:08:54.467187 22869 net.cpp:122] Setting up penlu14
I1017 16:08:54.467193 22869 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1017 16:08:54.467196 22869 net.cpp:137] Memory required for data: 1470627400
I1017 16:08:54.467221 22869 layer_factory.hpp:77] Creating layer Eltwise7_penlu14_0_split
I1017 16:08:54.467227 22869 net.cpp:84] Creating Layer Eltwise7_penlu14_0_split
I1017 16:08:54.467231 22869 net.cpp:406] Eltwise7_penlu14_0_split <- Eltwise7
I1017 16:08:54.467234 22869 net.cpp:380] Eltwise7_penlu14_0_split -> Eltwise7_penlu14_0_split_0
I1017 16:08:54.467239 22869 net.cpp:380] Eltwise7_penlu14_0_split -> Eltwise7_penlu14_0_split_1
I1017 16:08:54.467291 22869 net.cpp:122] Setting up Eltwise7_penlu14_0_split
I1017 16:08:54.467305 22869 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1017 16:08:54.467309 22869 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1017 16:08:54.467322 22869 net.cpp:137] Memory required for data: 1495715400
I1017 16:08:54.467324 22869 layer_factory.hpp:77] Creating layer Convolution18
I1017 16:08:54.467340 22869 net.cpp:84] Creating Layer Convolution18
I1017 16:08:54.467344 22869 net.cpp:406] Convolution18 <- Eltwise7_penlu14_0_split_0
I1017 16:08:54.467348 22869 net.cpp:380] Convolution18 -> Convolution18
I1017 16:08:54.489150 22869 net.cpp:122] Setting up Convolution18
I1017 16:08:54.489163 22869 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1017 16:08:54.489166 22869 net.cpp:137] Memory required for data: 1508259400
I1017 16:08:54.489181 22869 layer_factory.hpp:77] Creating layer BatchNorm15
I1017 16:08:54.489200 22869 net.cpp:84] Creating Layer BatchNorm15
I1017 16:08:54.489205 22869 net.cpp:406] BatchNorm15 <- Convolution18
I1017 16:08:54.489210 22869 net.cpp:367] BatchNorm15 -> Convolution18 (in-place)
I1017 16:08:54.489384 22869 net.cpp:122] Setting up BatchNorm15
I1017 16:08:54.489390 22869 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1017 16:08:54.489403 22869 net.cpp:137] Memory required for data: 1520803400
I1017 16:08:54.489408 22869 layer_factory.hpp:77] Creating layer Scale15
I1017 16:08:54.489413 22869 net.cpp:84] Creating Layer Scale15
I1017 16:08:54.489416 22869 net.cpp:406] Scale15 <- Convolution18
I1017 16:08:54.489429 22869 net.cpp:367] Scale15 -> Convolution18 (in-place)
I1017 16:08:54.489483 22869 layer_factory.hpp:77] Creating layer Scale15
I1017 16:08:54.489589 22869 net.cpp:122] Setting up Scale15
I1017 16:08:54.489595 22869 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1017 16:08:54.489608 22869 net.cpp:137] Memory required for data: 1533347400
I1017 16:08:54.489611 22869 layer_factory.hpp:77] Creating layer penlu15
I1017 16:08:54.489617 22869 net.cpp:84] Creating Layer penlu15
I1017 16:08:54.489620 22869 net.cpp:406] penlu15 <- Convolution18
I1017 16:08:54.489624 22869 net.cpp:367] penlu15 -> Convolution18 (in-place)
I1017 16:08:54.489789 22869 net.cpp:122] Setting up penlu15
I1017 16:08:54.489795 22869 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1017 16:08:54.489807 22869 net.cpp:137] Memory required for data: 1545891400
I1017 16:08:54.489812 22869 layer_factory.hpp:77] Creating layer Convolution19
I1017 16:08:54.489820 22869 net.cpp:84] Creating Layer Convolution19
I1017 16:08:54.489822 22869 net.cpp:406] Convolution19 <- Convolution18
I1017 16:08:54.489827 22869 net.cpp:380] Convolution19 -> Convolution19
I1017 16:08:54.512054 22869 net.cpp:122] Setting up Convolution19
I1017 16:08:54.512073 22869 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1017 16:08:54.512076 22869 net.cpp:137] Memory required for data: 1558435400
I1017 16:08:54.512081 22869 layer_factory.hpp:77] Creating layer Eltwise8
I1017 16:08:54.512115 22869 net.cpp:84] Creating Layer Eltwise8
I1017 16:08:54.512131 22869 net.cpp:406] Eltwise8 <- Convolution19
I1017 16:08:54.512145 22869 net.cpp:406] Eltwise8 <- Eltwise7_penlu14_0_split_1
I1017 16:08:54.512150 22869 net.cpp:380] Eltwise8 -> Eltwise8
I1017 16:08:54.512194 22869 net.cpp:122] Setting up Eltwise8
I1017 16:08:54.512208 22869 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1017 16:08:54.512210 22869 net.cpp:137] Memory required for data: 1570979400
I1017 16:08:54.512212 22869 layer_factory.hpp:77] Creating layer Eltwise8_Eltwise8_0_split
I1017 16:08:54.512228 22869 net.cpp:84] Creating Layer Eltwise8_Eltwise8_0_split
I1017 16:08:54.512229 22869 net.cpp:406] Eltwise8_Eltwise8_0_split <- Eltwise8
I1017 16:08:54.512233 22869 net.cpp:380] Eltwise8_Eltwise8_0_split -> Eltwise8_Eltwise8_0_split_0
I1017 16:08:54.512246 22869 net.cpp:380] Eltwise8_Eltwise8_0_split -> Eltwise8_Eltwise8_0_split_1
I1017 16:08:54.512305 22869 net.cpp:122] Setting up Eltwise8_Eltwise8_0_split
I1017 16:08:54.512310 22869 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1017 16:08:54.512313 22869 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1017 16:08:54.512326 22869 net.cpp:137] Memory required for data: 1596067400
I1017 16:08:54.512327 22869 layer_factory.hpp:77] Creating layer Convolution20
I1017 16:08:54.512334 22869 net.cpp:84] Creating Layer Convolution20
I1017 16:08:54.512349 22869 net.cpp:406] Convolution20 <- Eltwise8_Eltwise8_0_split_0
I1017 16:08:54.512354 22869 net.cpp:380] Convolution20 -> Convolution20
I1017 16:08:54.554544 22869 net.cpp:122] Setting up Convolution20
I1017 16:08:54.554566 22869 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1017 16:08:54.554569 22869 net.cpp:137] Memory required for data: 1602339400
I1017 16:08:54.554575 22869 layer_factory.hpp:77] Creating layer BatchNorm16
I1017 16:08:54.554586 22869 net.cpp:84] Creating Layer BatchNorm16
I1017 16:08:54.554601 22869 net.cpp:406] BatchNorm16 <- Convolution20
I1017 16:08:54.554606 22869 net.cpp:367] BatchNorm16 -> Convolution20 (in-place)
I1017 16:08:54.554798 22869 net.cpp:122] Setting up BatchNorm16
I1017 16:08:54.554805 22869 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1017 16:08:54.554806 22869 net.cpp:137] Memory required for data: 1608611400
I1017 16:08:54.554811 22869 layer_factory.hpp:77] Creating layer Scale16
I1017 16:08:54.554816 22869 net.cpp:84] Creating Layer Scale16
I1017 16:08:54.554819 22869 net.cpp:406] Scale16 <- Convolution20
I1017 16:08:54.554822 22869 net.cpp:367] Scale16 -> Convolution20 (in-place)
I1017 16:08:54.554884 22869 layer_factory.hpp:77] Creating layer Scale16
I1017 16:08:54.555014 22869 net.cpp:122] Setting up Scale16
I1017 16:08:54.555019 22869 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1017 16:08:54.555022 22869 net.cpp:137] Memory required for data: 1614883400
I1017 16:08:54.555025 22869 layer_factory.hpp:77] Creating layer penlu16
I1017 16:08:54.555032 22869 net.cpp:84] Creating Layer penlu16
I1017 16:08:54.555035 22869 net.cpp:406] penlu16 <- Convolution20
I1017 16:08:54.555049 22869 net.cpp:367] penlu16 -> Convolution20 (in-place)
I1017 16:08:54.555717 22869 net.cpp:122] Setting up penlu16
I1017 16:08:54.555727 22869 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1017 16:08:54.555729 22869 net.cpp:137] Memory required for data: 1621155400
I1017 16:08:54.555734 22869 layer_factory.hpp:77] Creating layer Convolution21
I1017 16:08:54.555743 22869 net.cpp:84] Creating Layer Convolution21
I1017 16:08:54.555755 22869 net.cpp:406] Convolution21 <- Convolution20
I1017 16:08:54.555760 22869 net.cpp:380] Convolution21 -> Convolution21
I1017 16:08:54.639389 22869 net.cpp:122] Setting up Convolution21
I1017 16:08:54.639412 22869 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1017 16:08:54.639415 22869 net.cpp:137] Memory required for data: 1627427400
I1017 16:08:54.639421 22869 layer_factory.hpp:77] Creating layer Convolution22
I1017 16:08:54.639442 22869 net.cpp:84] Creating Layer Convolution22
I1017 16:08:54.639447 22869 net.cpp:406] Convolution22 <- Eltwise8_Eltwise8_0_split_1
I1017 16:08:54.639477 22869 net.cpp:380] Convolution22 -> Convolution22
I1017 16:08:54.644781 22869 net.cpp:122] Setting up Convolution22
I1017 16:08:54.644793 22869 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1017 16:08:54.644795 22869 net.cpp:137] Memory required for data: 1633699400
I1017 16:08:54.644798 22869 layer_factory.hpp:77] Creating layer Eltwise9
I1017 16:08:54.644804 22869 net.cpp:84] Creating Layer Eltwise9
I1017 16:08:54.644806 22869 net.cpp:406] Eltwise9 <- Convolution21
I1017 16:08:54.644810 22869 net.cpp:406] Eltwise9 <- Convolution22
I1017 16:08:54.644824 22869 net.cpp:380] Eltwise9 -> Eltwise9
I1017 16:08:54.644866 22869 net.cpp:122] Setting up Eltwise9
I1017 16:08:54.644871 22869 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1017 16:08:54.644873 22869 net.cpp:137] Memory required for data: 1639971400
I1017 16:08:54.644886 22869 layer_factory.hpp:77] Creating layer BatchNorm17
I1017 16:08:54.644891 22869 net.cpp:84] Creating Layer BatchNorm17
I1017 16:08:54.644893 22869 net.cpp:406] BatchNorm17 <- Eltwise9
I1017 16:08:54.644907 22869 net.cpp:367] BatchNorm17 -> Eltwise9 (in-place)
I1017 16:08:54.645086 22869 net.cpp:122] Setting up BatchNorm17
I1017 16:08:54.645092 22869 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1017 16:08:54.645093 22869 net.cpp:137] Memory required for data: 1646243400
I1017 16:08:54.645098 22869 layer_factory.hpp:77] Creating layer Scale17
I1017 16:08:54.645103 22869 net.cpp:84] Creating Layer Scale17
I1017 16:08:54.645107 22869 net.cpp:406] Scale17 <- Eltwise9
I1017 16:08:54.645109 22869 net.cpp:367] Scale17 -> Eltwise9 (in-place)
I1017 16:08:54.645174 22869 layer_factory.hpp:77] Creating layer Scale17
I1017 16:08:54.645323 22869 net.cpp:122] Setting up Scale17
I1017 16:08:54.645328 22869 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1017 16:08:54.645330 22869 net.cpp:137] Memory required for data: 1652515400
I1017 16:08:54.645334 22869 layer_factory.hpp:77] Creating layer penlu17
I1017 16:08:54.645341 22869 net.cpp:84] Creating Layer penlu17
I1017 16:08:54.645344 22869 net.cpp:406] penlu17 <- Eltwise9
I1017 16:08:54.645347 22869 net.cpp:367] penlu17 -> Eltwise9 (in-place)
I1017 16:08:54.645508 22869 net.cpp:122] Setting up penlu17
I1017 16:08:54.645514 22869 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1017 16:08:54.645515 22869 net.cpp:137] Memory required for data: 1658787400
I1017 16:08:54.645520 22869 layer_factory.hpp:77] Creating layer Eltwise9_penlu17_0_split
I1017 16:08:54.645524 22869 net.cpp:84] Creating Layer Eltwise9_penlu17_0_split
I1017 16:08:54.645526 22869 net.cpp:406] Eltwise9_penlu17_0_split <- Eltwise9
I1017 16:08:54.645529 22869 net.cpp:380] Eltwise9_penlu17_0_split -> Eltwise9_penlu17_0_split_0
I1017 16:08:54.645545 22869 net.cpp:380] Eltwise9_penlu17_0_split -> Eltwise9_penlu17_0_split_1
I1017 16:08:54.645601 22869 net.cpp:122] Setting up Eltwise9_penlu17_0_split
I1017 16:08:54.645606 22869 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1017 16:08:54.645609 22869 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1017 16:08:54.645611 22869 net.cpp:137] Memory required for data: 1671331400
I1017 16:08:54.645613 22869 layer_factory.hpp:77] Creating layer Convolution23
I1017 16:08:54.645618 22869 net.cpp:84] Creating Layer Convolution23
I1017 16:08:54.645622 22869 net.cpp:406] Convolution23 <- Eltwise9_penlu17_0_split_0
I1017 16:08:54.645625 22869 net.cpp:380] Convolution23 -> Convolution23
I1017 16:08:54.729122 22869 net.cpp:122] Setting up Convolution23
I1017 16:08:54.729154 22869 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1017 16:08:54.729157 22869 net.cpp:137] Memory required for data: 1677603400
I1017 16:08:54.729164 22869 layer_factory.hpp:77] Creating layer BatchNorm18
I1017 16:08:54.729176 22869 net.cpp:84] Creating Layer BatchNorm18
I1017 16:08:54.729189 22869 net.cpp:406] BatchNorm18 <- Convolution23
I1017 16:08:54.729197 22869 net.cpp:367] BatchNorm18 -> Convolution23 (in-place)
I1017 16:08:54.729374 22869 net.cpp:122] Setting up BatchNorm18
I1017 16:08:54.729379 22869 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1017 16:08:54.729391 22869 net.cpp:137] Memory required for data: 1683875400
I1017 16:08:54.729418 22869 layer_factory.hpp:77] Creating layer Scale18
I1017 16:08:54.729424 22869 net.cpp:84] Creating Layer Scale18
I1017 16:08:54.729429 22869 net.cpp:406] Scale18 <- Convolution23
I1017 16:08:54.729431 22869 net.cpp:367] Scale18 -> Convolution23 (in-place)
I1017 16:08:54.729486 22869 layer_factory.hpp:77] Creating layer Scale18
I1017 16:08:54.729615 22869 net.cpp:122] Setting up Scale18
I1017 16:08:54.729620 22869 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1017 16:08:54.729634 22869 net.cpp:137] Memory required for data: 1690147400
I1017 16:08:54.729637 22869 layer_factory.hpp:77] Creating layer penlu18
I1017 16:08:54.729645 22869 net.cpp:84] Creating Layer penlu18
I1017 16:08:54.729657 22869 net.cpp:406] penlu18 <- Convolution23
I1017 16:08:54.729660 22869 net.cpp:367] penlu18 -> Convolution23 (in-place)
I1017 16:08:54.729812 22869 net.cpp:122] Setting up penlu18
I1017 16:08:54.729817 22869 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1017 16:08:54.729830 22869 net.cpp:137] Memory required for data: 1696419400
I1017 16:08:54.729835 22869 layer_factory.hpp:77] Creating layer Convolution24
I1017 16:08:54.729841 22869 net.cpp:84] Creating Layer Convolution24
I1017 16:08:54.729854 22869 net.cpp:406] Convolution24 <- Convolution23
I1017 16:08:54.729859 22869 net.cpp:380] Convolution24 -> Convolution24
I1017 16:08:54.813330 22869 net.cpp:122] Setting up Convolution24
I1017 16:08:54.813366 22869 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1017 16:08:54.813369 22869 net.cpp:137] Memory required for data: 1702691400
I1017 16:08:54.813377 22869 layer_factory.hpp:77] Creating layer Eltwise10
I1017 16:08:54.813386 22869 net.cpp:84] Creating Layer Eltwise10
I1017 16:08:54.813401 22869 net.cpp:406] Eltwise10 <- Convolution24
I1017 16:08:54.813408 22869 net.cpp:406] Eltwise10 <- Eltwise9_penlu17_0_split_1
I1017 16:08:54.813415 22869 net.cpp:380] Eltwise10 -> Eltwise10
I1017 16:08:54.813463 22869 net.cpp:122] Setting up Eltwise10
I1017 16:08:54.813469 22869 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1017 16:08:54.813472 22869 net.cpp:137] Memory required for data: 1708963400
I1017 16:08:54.813473 22869 layer_factory.hpp:77] Creating layer BatchNorm19
I1017 16:08:54.813480 22869 net.cpp:84] Creating Layer BatchNorm19
I1017 16:08:54.813482 22869 net.cpp:406] BatchNorm19 <- Eltwise10
I1017 16:08:54.813486 22869 net.cpp:367] BatchNorm19 -> Eltwise10 (in-place)
I1017 16:08:54.813685 22869 net.cpp:122] Setting up BatchNorm19
I1017 16:08:54.813691 22869 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1017 16:08:54.813694 22869 net.cpp:137] Memory required for data: 1715235400
I1017 16:08:54.813699 22869 layer_factory.hpp:77] Creating layer Scale19
I1017 16:08:54.813705 22869 net.cpp:84] Creating Layer Scale19
I1017 16:08:54.813709 22869 net.cpp:406] Scale19 <- Eltwise10
I1017 16:08:54.813711 22869 net.cpp:367] Scale19 -> Eltwise10 (in-place)
I1017 16:08:54.813778 22869 layer_factory.hpp:77] Creating layer Scale19
I1017 16:08:54.813937 22869 net.cpp:122] Setting up Scale19
I1017 16:08:54.813943 22869 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1017 16:08:54.813956 22869 net.cpp:137] Memory required for data: 1721507400
I1017 16:08:54.813959 22869 layer_factory.hpp:77] Creating layer penlu19
I1017 16:08:54.813977 22869 net.cpp:84] Creating Layer penlu19
I1017 16:08:54.813979 22869 net.cpp:406] penlu19 <- Eltwise10
I1017 16:08:54.813994 22869 net.cpp:367] penlu19 -> Eltwise10 (in-place)
I1017 16:08:54.814185 22869 net.cpp:122] Setting up penlu19
I1017 16:08:54.814191 22869 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1017 16:08:54.814193 22869 net.cpp:137] Memory required for data: 1727779400
I1017 16:08:54.814198 22869 layer_factory.hpp:77] Creating layer Eltwise10_penlu19_0_split
I1017 16:08:54.814203 22869 net.cpp:84] Creating Layer Eltwise10_penlu19_0_split
I1017 16:08:54.814204 22869 net.cpp:406] Eltwise10_penlu19_0_split <- Eltwise10
I1017 16:08:54.814208 22869 net.cpp:380] Eltwise10_penlu19_0_split -> Eltwise10_penlu19_0_split_0
I1017 16:08:54.814222 22869 net.cpp:380] Eltwise10_penlu19_0_split -> Eltwise10_penlu19_0_split_1
I1017 16:08:54.814307 22869 net.cpp:122] Setting up Eltwise10_penlu19_0_split
I1017 16:08:54.814323 22869 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1017 16:08:54.814327 22869 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1017 16:08:54.814330 22869 net.cpp:137] Memory required for data: 1740323400
I1017 16:08:54.814342 22869 layer_factory.hpp:77] Creating layer Convolution25
I1017 16:08:54.814348 22869 net.cpp:84] Creating Layer Convolution25
I1017 16:08:54.814363 22869 net.cpp:406] Convolution25 <- Eltwise10_penlu19_0_split_0
I1017 16:08:54.814368 22869 net.cpp:380] Convolution25 -> Convolution25
I1017 16:08:54.898298 22869 net.cpp:122] Setting up Convolution25
I1017 16:08:54.898320 22869 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1017 16:08:54.898324 22869 net.cpp:137] Memory required for data: 1746595400
I1017 16:08:54.898331 22869 layer_factory.hpp:77] Creating layer BatchNorm20
I1017 16:08:54.898351 22869 net.cpp:84] Creating Layer BatchNorm20
I1017 16:08:54.898356 22869 net.cpp:406] BatchNorm20 <- Convolution25
I1017 16:08:54.898362 22869 net.cpp:367] BatchNorm20 -> Convolution25 (in-place)
I1017 16:08:54.898557 22869 net.cpp:122] Setting up BatchNorm20
I1017 16:08:54.898564 22869 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1017 16:08:54.898566 22869 net.cpp:137] Memory required for data: 1752867400
I1017 16:08:54.898571 22869 layer_factory.hpp:77] Creating layer Scale20
I1017 16:08:54.898579 22869 net.cpp:84] Creating Layer Scale20
I1017 16:08:54.898582 22869 net.cpp:406] Scale20 <- Convolution25
I1017 16:08:54.898596 22869 net.cpp:367] Scale20 -> Convolution25 (in-place)
I1017 16:08:54.898653 22869 layer_factory.hpp:77] Creating layer Scale20
I1017 16:08:54.898804 22869 net.cpp:122] Setting up Scale20
I1017 16:08:54.898810 22869 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1017 16:08:54.898813 22869 net.cpp:137] Memory required for data: 1759139400
I1017 16:08:54.898816 22869 layer_factory.hpp:77] Creating layer penlu20
I1017 16:08:54.898823 22869 net.cpp:84] Creating Layer penlu20
I1017 16:08:54.898826 22869 net.cpp:406] penlu20 <- Convolution25
I1017 16:08:54.898830 22869 net.cpp:367] penlu20 -> Convolution25 (in-place)
I1017 16:08:54.898998 22869 net.cpp:122] Setting up penlu20
I1017 16:08:54.899003 22869 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1017 16:08:54.899004 22869 net.cpp:137] Memory required for data: 1765411400
I1017 16:08:54.899009 22869 layer_factory.hpp:77] Creating layer Convolution26
I1017 16:08:54.899019 22869 net.cpp:84] Creating Layer Convolution26
I1017 16:08:54.899020 22869 net.cpp:406] Convolution26 <- Convolution25
I1017 16:08:54.899034 22869 net.cpp:380] Convolution26 -> Convolution26
I1017 16:08:54.982524 22869 net.cpp:122] Setting up Convolution26
I1017 16:08:54.982548 22869 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1017 16:08:54.982551 22869 net.cpp:137] Memory required for data: 1771683400
I1017 16:08:54.982559 22869 layer_factory.hpp:77] Creating layer Eltwise11
I1017 16:08:54.982578 22869 net.cpp:84] Creating Layer Eltwise11
I1017 16:08:54.982584 22869 net.cpp:406] Eltwise11 <- Convolution26
I1017 16:08:54.982589 22869 net.cpp:406] Eltwise11 <- Eltwise10_penlu19_0_split_1
I1017 16:08:54.982605 22869 net.cpp:380] Eltwise11 -> Eltwise11
I1017 16:08:54.982656 22869 net.cpp:122] Setting up Eltwise11
I1017 16:08:54.982661 22869 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1017 16:08:54.982673 22869 net.cpp:137] Memory required for data: 1777955400
I1017 16:08:54.982676 22869 layer_factory.hpp:77] Creating layer BatchNorm21
I1017 16:08:54.982682 22869 net.cpp:84] Creating Layer BatchNorm21
I1017 16:08:54.982693 22869 net.cpp:406] BatchNorm21 <- Eltwise11
I1017 16:08:54.982697 22869 net.cpp:367] BatchNorm21 -> Eltwise11 (in-place)
I1017 16:08:54.982897 22869 net.cpp:122] Setting up BatchNorm21
I1017 16:08:54.982903 22869 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1017 16:08:54.982904 22869 net.cpp:137] Memory required for data: 1784227400
I1017 16:08:54.982909 22869 layer_factory.hpp:77] Creating layer Scale21
I1017 16:08:54.982936 22869 net.cpp:84] Creating Layer Scale21
I1017 16:08:54.982940 22869 net.cpp:406] Scale21 <- Eltwise11
I1017 16:08:54.982956 22869 net.cpp:367] Scale21 -> Eltwise11 (in-place)
I1017 16:08:54.983011 22869 layer_factory.hpp:77] Creating layer Scale21
I1017 16:08:54.983135 22869 net.cpp:122] Setting up Scale21
I1017 16:08:54.983141 22869 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1017 16:08:54.983144 22869 net.cpp:137] Memory required for data: 1790499400
I1017 16:08:54.983147 22869 layer_factory.hpp:77] Creating layer penlu21
I1017 16:08:54.983153 22869 net.cpp:84] Creating Layer penlu21
I1017 16:08:54.983156 22869 net.cpp:406] penlu21 <- Eltwise11
I1017 16:08:54.983160 22869 net.cpp:367] penlu21 -> Eltwise11 (in-place)
I1017 16:08:54.983330 22869 net.cpp:122] Setting up penlu21
I1017 16:08:54.983336 22869 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1017 16:08:54.983338 22869 net.cpp:137] Memory required for data: 1796771400
I1017 16:08:54.983342 22869 layer_factory.hpp:77] Creating layer Eltwise11_penlu21_0_split
I1017 16:08:54.983347 22869 net.cpp:84] Creating Layer Eltwise11_penlu21_0_split
I1017 16:08:54.983350 22869 net.cpp:406] Eltwise11_penlu21_0_split <- Eltwise11
I1017 16:08:54.983353 22869 net.cpp:380] Eltwise11_penlu21_0_split -> Eltwise11_penlu21_0_split_0
I1017 16:08:54.983368 22869 net.cpp:380] Eltwise11_penlu21_0_split -> Eltwise11_penlu21_0_split_1
I1017 16:08:54.983417 22869 net.cpp:122] Setting up Eltwise11_penlu21_0_split
I1017 16:08:54.983422 22869 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1017 16:08:54.983438 22869 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1017 16:08:54.983439 22869 net.cpp:137] Memory required for data: 1809315400
I1017 16:08:54.983443 22869 layer_factory.hpp:77] Creating layer Convolution27
I1017 16:08:54.983460 22869 net.cpp:84] Creating Layer Convolution27
I1017 16:08:54.983474 22869 net.cpp:406] Convolution27 <- Eltwise11_penlu21_0_split_0
I1017 16:08:54.983479 22869 net.cpp:380] Convolution27 -> Convolution27
I1017 16:08:55.066604 22869 net.cpp:122] Setting up Convolution27
I1017 16:08:55.066639 22869 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1017 16:08:55.066644 22869 net.cpp:137] Memory required for data: 1815587400
I1017 16:08:55.066651 22869 layer_factory.hpp:77] Creating layer BatchNorm22
I1017 16:08:55.066670 22869 net.cpp:84] Creating Layer BatchNorm22
I1017 16:08:55.066675 22869 net.cpp:406] BatchNorm22 <- Convolution27
I1017 16:08:55.066682 22869 net.cpp:367] BatchNorm22 -> Convolution27 (in-place)
I1017 16:08:55.066884 22869 net.cpp:122] Setting up BatchNorm22
I1017 16:08:55.066891 22869 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1017 16:08:55.066903 22869 net.cpp:137] Memory required for data: 1821859400
I1017 16:08:55.066910 22869 layer_factory.hpp:77] Creating layer Scale22
I1017 16:08:55.066915 22869 net.cpp:84] Creating Layer Scale22
I1017 16:08:55.066928 22869 net.cpp:406] Scale22 <- Convolution27
I1017 16:08:55.066931 22869 net.cpp:367] Scale22 -> Convolution27 (in-place)
I1017 16:08:55.066985 22869 layer_factory.hpp:77] Creating layer Scale22
I1017 16:08:55.067117 22869 net.cpp:122] Setting up Scale22
I1017 16:08:55.067122 22869 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1017 16:08:55.067134 22869 net.cpp:137] Memory required for data: 1828131400
I1017 16:08:55.067139 22869 layer_factory.hpp:77] Creating layer penlu22
I1017 16:08:55.067145 22869 net.cpp:84] Creating Layer penlu22
I1017 16:08:55.067148 22869 net.cpp:406] penlu22 <- Convolution27
I1017 16:08:55.067162 22869 net.cpp:367] penlu22 -> Convolution27 (in-place)
I1017 16:08:55.067317 22869 net.cpp:122] Setting up penlu22
I1017 16:08:55.067323 22869 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1017 16:08:55.067335 22869 net.cpp:137] Memory required for data: 1834403400
I1017 16:08:55.067340 22869 layer_factory.hpp:77] Creating layer Convolution28
I1017 16:08:55.067348 22869 net.cpp:84] Creating Layer Convolution28
I1017 16:08:55.067359 22869 net.cpp:406] Convolution28 <- Convolution27
I1017 16:08:55.067366 22869 net.cpp:380] Convolution28 -> Convolution28
I1017 16:08:55.151000 22869 net.cpp:122] Setting up Convolution28
I1017 16:08:55.151022 22869 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1017 16:08:55.151026 22869 net.cpp:137] Memory required for data: 1840675400
I1017 16:08:55.151032 22869 layer_factory.hpp:77] Creating layer Eltwise12
I1017 16:08:55.151041 22869 net.cpp:84] Creating Layer Eltwise12
I1017 16:08:55.151057 22869 net.cpp:406] Eltwise12 <- Convolution28
I1017 16:08:55.151062 22869 net.cpp:406] Eltwise12 <- Eltwise11_penlu21_0_split_1
I1017 16:08:55.151077 22869 net.cpp:380] Eltwise12 -> Eltwise12
I1017 16:08:55.151129 22869 net.cpp:122] Setting up Eltwise12
I1017 16:08:55.151134 22869 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1017 16:08:55.151149 22869 net.cpp:137] Memory required for data: 1846947400
I1017 16:08:55.151152 22869 layer_factory.hpp:77] Creating layer Pooling1
I1017 16:08:55.151157 22869 net.cpp:84] Creating Layer Pooling1
I1017 16:08:55.151168 22869 net.cpp:406] Pooling1 <- Eltwise12
I1017 16:08:55.151173 22869 net.cpp:380] Pooling1 -> Pooling1
I1017 16:08:55.151760 22869 net.cpp:122] Setting up Pooling1
I1017 16:08:55.151770 22869 net.cpp:129] Top shape: 50 640 1 1 (32000)
I1017 16:08:55.151772 22869 net.cpp:137] Memory required for data: 1847075400
I1017 16:08:55.151775 22869 layer_factory.hpp:77] Creating layer InnerProduct1
I1017 16:08:55.151787 22869 net.cpp:84] Creating Layer InnerProduct1
I1017 16:08:55.151800 22869 net.cpp:406] InnerProduct1 <- Pooling1
I1017 16:08:55.151808 22869 net.cpp:380] InnerProduct1 -> InnerProduct1
I1017 16:08:55.151994 22869 net.cpp:122] Setting up InnerProduct1
I1017 16:08:55.151999 22869 net.cpp:129] Top shape: 50 100 (5000)
I1017 16:08:55.152003 22869 net.cpp:137] Memory required for data: 1847095400
I1017 16:08:55.152006 22869 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I1017 16:08:55.152012 22869 net.cpp:84] Creating Layer SoftmaxWithLoss1
I1017 16:08:55.152015 22869 net.cpp:406] SoftmaxWithLoss1 <- InnerProduct1
I1017 16:08:55.152019 22869 net.cpp:406] SoftmaxWithLoss1 <- label
I1017 16:08:55.152031 22869 net.cpp:380] SoftmaxWithLoss1 -> SoftmaxWithLoss1
I1017 16:08:55.152048 22869 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I1017 16:08:55.152298 22869 net.cpp:122] Setting up SoftmaxWithLoss1
I1017 16:08:55.152305 22869 net.cpp:129] Top shape: (1)
I1017 16:08:55.152318 22869 net.cpp:132]     with loss weight 1
I1017 16:08:55.152343 22869 net.cpp:137] Memory required for data: 1847095404
I1017 16:08:55.152346 22869 net.cpp:198] SoftmaxWithLoss1 needs backward computation.
I1017 16:08:55.152349 22869 net.cpp:198] InnerProduct1 needs backward computation.
I1017 16:08:55.152351 22869 net.cpp:198] Pooling1 needs backward computation.
I1017 16:08:55.152354 22869 net.cpp:198] Eltwise12 needs backward computation.
I1017 16:08:55.152356 22869 net.cpp:198] Convolution28 needs backward computation.
I1017 16:08:55.152359 22869 net.cpp:198] penlu22 needs backward computation.
I1017 16:08:55.152362 22869 net.cpp:198] Scale22 needs backward computation.
I1017 16:08:55.152364 22869 net.cpp:198] BatchNorm22 needs backward computation.
I1017 16:08:55.152366 22869 net.cpp:198] Convolution27 needs backward computation.
I1017 16:08:55.152370 22869 net.cpp:198] Eltwise11_penlu21_0_split needs backward computation.
I1017 16:08:55.152372 22869 net.cpp:198] penlu21 needs backward computation.
I1017 16:08:55.152375 22869 net.cpp:198] Scale21 needs backward computation.
I1017 16:08:55.152377 22869 net.cpp:198] BatchNorm21 needs backward computation.
I1017 16:08:55.152380 22869 net.cpp:198] Eltwise11 needs backward computation.
I1017 16:08:55.152384 22869 net.cpp:198] Convolution26 needs backward computation.
I1017 16:08:55.152387 22869 net.cpp:198] penlu20 needs backward computation.
I1017 16:08:55.152390 22869 net.cpp:198] Scale20 needs backward computation.
I1017 16:08:55.152391 22869 net.cpp:198] BatchNorm20 needs backward computation.
I1017 16:08:55.152393 22869 net.cpp:198] Convolution25 needs backward computation.
I1017 16:08:55.152397 22869 net.cpp:198] Eltwise10_penlu19_0_split needs backward computation.
I1017 16:08:55.152410 22869 net.cpp:198] penlu19 needs backward computation.
I1017 16:08:55.152413 22869 net.cpp:198] Scale19 needs backward computation.
I1017 16:08:55.152416 22869 net.cpp:198] BatchNorm19 needs backward computation.
I1017 16:08:55.152418 22869 net.cpp:198] Eltwise10 needs backward computation.
I1017 16:08:55.152420 22869 net.cpp:198] Convolution24 needs backward computation.
I1017 16:08:55.152423 22869 net.cpp:198] penlu18 needs backward computation.
I1017 16:08:55.152426 22869 net.cpp:198] Scale18 needs backward computation.
I1017 16:08:55.152428 22869 net.cpp:198] BatchNorm18 needs backward computation.
I1017 16:08:55.152431 22869 net.cpp:198] Convolution23 needs backward computation.
I1017 16:08:55.152434 22869 net.cpp:198] Eltwise9_penlu17_0_split needs backward computation.
I1017 16:08:55.152438 22869 net.cpp:198] penlu17 needs backward computation.
I1017 16:08:55.152441 22869 net.cpp:198] Scale17 needs backward computation.
I1017 16:08:55.152443 22869 net.cpp:198] BatchNorm17 needs backward computation.
I1017 16:08:55.152446 22869 net.cpp:198] Eltwise9 needs backward computation.
I1017 16:08:55.152448 22869 net.cpp:198] Convolution22 needs backward computation.
I1017 16:08:55.152452 22869 net.cpp:198] Convolution21 needs backward computation.
I1017 16:08:55.152454 22869 net.cpp:198] penlu16 needs backward computation.
I1017 16:08:55.152457 22869 net.cpp:198] Scale16 needs backward computation.
I1017 16:08:55.152460 22869 net.cpp:198] BatchNorm16 needs backward computation.
I1017 16:08:55.152462 22869 net.cpp:198] Convolution20 needs backward computation.
I1017 16:08:55.152465 22869 net.cpp:198] Eltwise8_Eltwise8_0_split needs backward computation.
I1017 16:08:55.152468 22869 net.cpp:198] Eltwise8 needs backward computation.
I1017 16:08:55.152472 22869 net.cpp:198] Convolution19 needs backward computation.
I1017 16:08:55.152474 22869 net.cpp:198] penlu15 needs backward computation.
I1017 16:08:55.152477 22869 net.cpp:198] Scale15 needs backward computation.
I1017 16:08:55.152479 22869 net.cpp:198] BatchNorm15 needs backward computation.
I1017 16:08:55.152482 22869 net.cpp:198] Convolution18 needs backward computation.
I1017 16:08:55.152485 22869 net.cpp:198] Eltwise7_penlu14_0_split needs backward computation.
I1017 16:08:55.152488 22869 net.cpp:198] penlu14 needs backward computation.
I1017 16:08:55.152492 22869 net.cpp:198] Scale14 needs backward computation.
I1017 16:08:55.152493 22869 net.cpp:198] BatchNorm14 needs backward computation.
I1017 16:08:55.152496 22869 net.cpp:198] Eltwise7 needs backward computation.
I1017 16:08:55.152499 22869 net.cpp:198] Convolution17 needs backward computation.
I1017 16:08:55.152503 22869 net.cpp:198] penlu13 needs backward computation.
I1017 16:08:55.152505 22869 net.cpp:198] Scale13 needs backward computation.
I1017 16:08:55.152508 22869 net.cpp:198] BatchNorm13 needs backward computation.
I1017 16:08:55.152509 22869 net.cpp:198] Convolution16 needs backward computation.
I1017 16:08:55.152513 22869 net.cpp:198] Eltwise6_penlu12_0_split needs backward computation.
I1017 16:08:55.152515 22869 net.cpp:198] penlu12 needs backward computation.
I1017 16:08:55.152518 22869 net.cpp:198] Scale12 needs backward computation.
I1017 16:08:55.152521 22869 net.cpp:198] BatchNorm12 needs backward computation.
I1017 16:08:55.152523 22869 net.cpp:198] Eltwise6 needs backward computation.
I1017 16:08:55.152526 22869 net.cpp:198] Convolution15 needs backward computation.
I1017 16:08:55.152529 22869 net.cpp:198] penlu11 needs backward computation.
I1017 16:08:55.152532 22869 net.cpp:198] Scale11 needs backward computation.
I1017 16:08:55.152534 22869 net.cpp:198] BatchNorm11 needs backward computation.
I1017 16:08:55.152536 22869 net.cpp:198] Convolution14 needs backward computation.
I1017 16:08:55.152539 22869 net.cpp:198] Eltwise5_penlu10_0_split needs backward computation.
I1017 16:08:55.152542 22869 net.cpp:198] penlu10 needs backward computation.
I1017 16:08:55.152545 22869 net.cpp:198] Scale10 needs backward computation.
I1017 16:08:55.152547 22869 net.cpp:198] BatchNorm10 needs backward computation.
I1017 16:08:55.152555 22869 net.cpp:198] Eltwise5 needs backward computation.
I1017 16:08:55.152559 22869 net.cpp:198] Convolution13 needs backward computation.
I1017 16:08:55.152561 22869 net.cpp:198] Convolution12 needs backward computation.
I1017 16:08:55.152565 22869 net.cpp:198] penlu9 needs backward computation.
I1017 16:08:55.152566 22869 net.cpp:198] Scale9 needs backward computation.
I1017 16:08:55.152568 22869 net.cpp:198] BatchNorm9 needs backward computation.
I1017 16:08:55.152572 22869 net.cpp:198] Convolution11 needs backward computation.
I1017 16:08:55.152575 22869 net.cpp:198] Eltwise4_Eltwise4_0_split needs backward computation.
I1017 16:08:55.152577 22869 net.cpp:198] Eltwise4 needs backward computation.
I1017 16:08:55.152581 22869 net.cpp:198] Convolution10 needs backward computation.
I1017 16:08:55.152585 22869 net.cpp:198] penlu8 needs backward computation.
I1017 16:08:55.152587 22869 net.cpp:198] Scale8 needs backward computation.
I1017 16:08:55.152590 22869 net.cpp:198] BatchNorm8 needs backward computation.
I1017 16:08:55.152592 22869 net.cpp:198] Convolution9 needs backward computation.
I1017 16:08:55.152595 22869 net.cpp:198] Eltwise3_penlu7_0_split needs backward computation.
I1017 16:08:55.152600 22869 net.cpp:198] penlu7 needs backward computation.
I1017 16:08:55.152601 22869 net.cpp:198] Scale7 needs backward computation.
I1017 16:08:55.152603 22869 net.cpp:198] BatchNorm7 needs backward computation.
I1017 16:08:55.152606 22869 net.cpp:198] Eltwise3 needs backward computation.
I1017 16:08:55.152609 22869 net.cpp:198] Convolution8 needs backward computation.
I1017 16:08:55.152613 22869 net.cpp:198] penlu6 needs backward computation.
I1017 16:08:55.152616 22869 net.cpp:198] Scale6 needs backward computation.
I1017 16:08:55.152618 22869 net.cpp:198] BatchNorm6 needs backward computation.
I1017 16:08:55.152621 22869 net.cpp:198] Convolution7 needs backward computation.
I1017 16:08:55.152624 22869 net.cpp:198] Eltwise2_penlu5_0_split needs backward computation.
I1017 16:08:55.152627 22869 net.cpp:198] penlu5 needs backward computation.
I1017 16:08:55.152631 22869 net.cpp:198] Scale5 needs backward computation.
I1017 16:08:55.152632 22869 net.cpp:198] BatchNorm5 needs backward computation.
I1017 16:08:55.152634 22869 net.cpp:198] Eltwise2 needs backward computation.
I1017 16:08:55.152637 22869 net.cpp:198] Convolution6 needs backward computation.
I1017 16:08:55.152642 22869 net.cpp:198] penlu4 needs backward computation.
I1017 16:08:55.152643 22869 net.cpp:198] Scale4 needs backward computation.
I1017 16:08:55.152647 22869 net.cpp:198] BatchNorm4 needs backward computation.
I1017 16:08:55.152649 22869 net.cpp:198] Convolution5 needs backward computation.
I1017 16:08:55.152652 22869 net.cpp:198] Eltwise1_penlu3_0_split needs backward computation.
I1017 16:08:55.152654 22869 net.cpp:198] penlu3 needs backward computation.
I1017 16:08:55.152657 22869 net.cpp:198] Scale3 needs backward computation.
I1017 16:08:55.152659 22869 net.cpp:198] BatchNorm3 needs backward computation.
I1017 16:08:55.152662 22869 net.cpp:198] Eltwise1 needs backward computation.
I1017 16:08:55.152665 22869 net.cpp:198] Convolution4 needs backward computation.
I1017 16:08:55.152668 22869 net.cpp:198] Convolution3 needs backward computation.
I1017 16:08:55.152671 22869 net.cpp:198] penlu2 needs backward computation.
I1017 16:08:55.152674 22869 net.cpp:198] Scale2 needs backward computation.
I1017 16:08:55.152676 22869 net.cpp:198] BatchNorm2 needs backward computation.
I1017 16:08:55.152678 22869 net.cpp:198] Convolution2 needs backward computation.
I1017 16:08:55.152681 22869 net.cpp:198] Convolution1_penlu1_0_split needs backward computation.
I1017 16:08:55.152684 22869 net.cpp:198] penlu1 needs backward computation.
I1017 16:08:55.152688 22869 net.cpp:198] Scale1 needs backward computation.
I1017 16:08:55.152689 22869 net.cpp:198] BatchNorm1 needs backward computation.
I1017 16:08:55.152693 22869 net.cpp:198] Convolution1 needs backward computation.
I1017 16:08:55.152695 22869 net.cpp:200] cifar does not need backward computation.
I1017 16:08:55.152701 22869 net.cpp:242] This network produces output SoftmaxWithLoss1
I1017 16:08:55.152752 22869 net.cpp:255] Network initialization done.
I1017 16:08:55.154680 22869 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: /home/x306/caffe/xn/PENLU/neural/WRN/WRN_penlu_msra.prototxt
I1017 16:08:55.154690 22869 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I1017 16:08:55.154695 22869 solver.cpp:172] Creating test net (#0) specified by net file: /home/x306/caffe/xn/PENLU/neural/WRN/WRN_penlu_msra.prototxt
I1017 16:08:55.154783 22869 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer cifar
I1017 16:08:55.155282 22869 net.cpp:51] Initializing net from parameters: 
name: "wrn_28_10"
state {
  phase: TEST
}
layer {
  name: "cifar"
  type: "Data"
  top: "data"
  top: "label"
  include {
    phase: TEST
  }
  transform_param {
    mirror: false
    crop_size: 28
    mean_file: "/home/x306/caffe/xn/PENLU/data/cifar100/mean.binaryproto"
  }
  data_param {
    source: "/home/x306/caffe/xn/PENLU/data/cifar100/cifar100_test_lmdb"
    batch_size: 50
    backend: LMDB
  }
}
layer {
  name: "Convolution1"
  type: "Convolution"
  bottom: "data"
  top: "Convolution1"
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "BatchNorm1"
  type: "BatchNorm"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale1"
  type: "Scale"
  bottom: "Convolution1"
  top: "Convolution1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu1"
  type: "PENLU"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution2"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution2"
  convolution_param {
    num_output: 160
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "BatchNorm2"
  type: "BatchNorm"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale2"
  type: "Scale"
  bottom: "Convolution2"
  top: "Convolution2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu2"
  type: "PENLU"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution3"
  type: "Convolution"
  bottom: "Convolution2"
  top: "Convolution3"
  convolution_param {
    num_output: 160
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "Convolution4"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution4"
  convolution_param {
    num_output: 160
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "Eltwise1"
  type: "Eltwise"
  bottom: "Convolution3"
  bottom: "Convolution4"
  top: "Eltwise1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "BatchNorm3"
  type: "BatchNorm"
  bottom: "Eltwise1"
  top: "Eltwise1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale3"
  type: "Scale"
  bottom: "Eltwise1"
  top: "Eltwise1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu3"
  type: "PENLU"
  bottom: "Eltwise1"
  top: "Eltwise1"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution5"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution5"
  convolution_param {
    num_output: 160
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "BatchNorm4"
  type: "BatchNorm"
  bottom: "Convolution5"
  top: "Convolution5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale4"
  type: "Scale"
  bottom: "Convolution5"
  top: "Convolution5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu4"
  type: "PENLU"
  bottom: "Convolution5"
  top: "Convolution5"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution6"
  type: "Convolution"
  bottom: "Convolution5"
  top: "Convolution6"
  convolution_param {
    num_output: 160
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "Eltwise2"
  type: "Eltwise"
  bottom: "Convolution6"
  bottom: "Eltwise1"
  top: "Eltwise2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "BatchNorm5"
  type: "BatchNorm"
  bottom: "Eltwise2"
  top: "Eltwise2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale5"
  type: "Scale"
  bottom: "Eltwise2"
  top: "Eltwise2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu5"
  type: "PENLU"
  bottom: "Eltwise2"
  top: "Eltwise2"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution7"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution7"
  convolution_param {
    num_output: 160
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "BatchNorm6"
  type: "BatchNorm"
  bottom: "Convolution7"
  top: "Convolution7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale6"
  type: "Scale"
  bottom: "Convolution7"
  top: "Convolution7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu6"
  type: "PENLU"
  bottom: "Convolution7"
  top: "Convolution7"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution8"
  type: "Convolution"
  bottom: "Convolution7"
  top: "Convolution8"
  convolution_param {
    num_output: 160
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "Eltwise3"
  type: "Eltwise"
  bottom: "Convolution8"
  bottom: "Eltwise2"
  top: "Eltwise3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "BatchNorm7"
  type: "BatchNorm"
  bottom: "Eltwise3"
  top: "Eltwise3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale7"
  type: "Scale"
  bottom: "Eltwise3"
  top: "Eltwise3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu7"
  type: "PENLU"
  bottom: "Eltwise3"
  top: "Eltwise3"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution9"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution9"
  convolution_param {
    num_output: 160
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "BatchNorm8"
  type: "BatchNorm"
  bottom: "Convolution9"
  top: "Convolution9"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale8"
  type: "Scale"
  bottom: "Convolution9"
  top: "Convolution9"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu8"
  type: "PENLU"
  bottom: "Convolution9"
  top: "Convolution9"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution10"
  type: "Convolution"
  bottom: "Convolution9"
  top: "Convolution10"
  convolution_param {
    num_output: 160
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "Eltwise4"
  type: "Eltwise"
  bottom: "Convolution10"
  bottom: "Eltwise3"
  top: "Eltwise4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "Convolution11"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution11"
  convolution_param {
    num_output: 320
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "BatchNorm9"
  type: "BatchNorm"
  bottom: "Convolution11"
  top: "Convolution11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale9"
  type: "Scale"
  bottom: "Convolution11"
  top: "Convolution11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu9"
  type: "PENLU"
  bottom: "Convolution11"
  top: "Convolution11"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution12"
  type: "Convolution"
  bottom: "Convolution11"
  top: "Convolution12"
  convolution_param {
    num_output: 320
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "Convolution13"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution13"
  convolution_param {
    num_output: 320
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "Eltwise5"
  type: "Eltwise"
  bottom: "Convolution12"
  bottom: "Convolution13"
  top: "Eltwise5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "BatchNorm10"
  type: "BatchNorm"
  bottom: "Eltwise5"
  top: "Eltwise5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale10"
  type: "Scale"
  bottom: "Eltwise5"
  top: "Eltwise5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu10"
  type: "PENLU"
  bottom: "Eltwise5"
  top: "Eltwise5"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution14"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution14"
  convolution_param {
    num_output: 320
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "BatchNorm11"
  type: "BatchNorm"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale11"
  type: "Scale"
  bottom: "Convolution14"
  top: "Convolution14"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu11"
  type: "PENLU"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution15"
  type: "Convolution"
  bottom: "Convolution14"
  top: "Convolution15"
  convolution_param {
    num_output: 320
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "Eltwise6"
  type: "Eltwise"
  bottom: "Convolution15"
  bottom: "Eltwise5"
  top: "Eltwise6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "BatchNorm12"
  type: "BatchNorm"
  bottom: "Eltwise6"
  top: "Eltwise6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale12"
  type: "Scale"
  bottom: "Eltwise6"
  top: "Eltwise6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu12"
  type: "PENLU"
  bottom: "Eltwise6"
  top: "Eltwise6"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution16"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution16"
  convolution_param {
    num_output: 320
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "BatchNorm13"
  type: "BatchNorm"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale13"
  type: "Scale"
  bottom: "Convolution16"
  top: "Convolution16"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu13"
  type: "PENLU"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution17"
  type: "Convolution"
  bottom: "Convolution16"
  top: "Convolution17"
  convolution_param {
    num_output: 320
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "Eltwise7"
  type: "Eltwise"
  bottom: "Convolution17"
  bottom: "Eltwise6"
  top: "Eltwise7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "BatchNorm14"
  type: "BatchNorm"
  bottom: "Eltwise7"
  top: "Eltwise7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale14"
  type: "Scale"
  bottom: "Eltwise7"
  top: "Eltwise7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu14"
  type: "PENLU"
  bottom: "Eltwise7"
  top: "Eltwise7"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution18"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution18"
  convolution_param {
    num_output: 320
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "BatchNorm15"
  type: "BatchNorm"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale15"
  type: "Scale"
  bottom: "Convolution18"
  top: "Convolution18"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu15"
  type: "PENLU"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution19"
  type: "Convolution"
  bottom: "Convolution18"
  top: "Convolution19"
  convolution_param {
    num_output: 320
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "Eltwise8"
  type: "Eltwise"
  bottom: "Convolution19"
  bottom: "Eltwise7"
  top: "Eltwise8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "Convolution20"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution20"
  convolution_param {
    num_output: 640
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "BatchNorm16"
  type: "BatchNorm"
  bottom: "Convolution20"
  top: "Convolution20"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale16"
  type: "Scale"
  bottom: "Convolution20"
  top: "Convolution20"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu16"
  type: "PENLU"
  bottom: "Convolution20"
  top: "Convolution20"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution21"
  type: "Convolution"
  bottom: "Convolution20"
  top: "Convolution21"
  convolution_param {
    num_output: 640
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "Convolution22"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution22"
  convolution_param {
    num_output: 640
    bias_term: false
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "Eltwise9"
  type: "Eltwise"
  bottom: "Convolution21"
  bottom: "Convolution22"
  top: "Eltwise9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "BatchNorm17"
  type: "BatchNorm"
  bottom: "Eltwise9"
  top: "Eltwise9"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale17"
  type: "Scale"
  bottom: "Eltwise9"
  top: "Eltwise9"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu17"
  type: "PENLU"
  bottom: "Eltwise9"
  top: "Eltwise9"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution23"
  type: "Convolution"
  bottom: "Eltwise9"
  top: "Convolution23"
  convolution_param {
    num_output: 640
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "BatchNorm18"
  type: "BatchNorm"
  bottom: "Convolution23"
  top: "Convolution23"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale18"
  type: "Scale"
  bottom: "Convolution23"
  top: "Convolution23"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu18"
  type: "PENLU"
  bottom: "Convolution23"
  top: "Convolution23"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution24"
  type: "Convolution"
  bottom: "Convolution23"
  top: "Convolution24"
  convolution_param {
    num_output: 640
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "Eltwise10"
  type: "Eltwise"
  bottom: "Convolution24"
  bottom: "Eltwise9"
  top: "Eltwise10"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "BatchNorm19"
  type: "BatchNorm"
  bottom: "Eltwise10"
  top: "Eltwise10"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale19"
  type: "Scale"
  bottom: "Eltwise10"
  top: "Eltwise10"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu19"
  type: "PENLU"
  bottom: "Eltwise10"
  top: "Eltwise10"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution25"
  type: "Convolution"
  bottom: "Eltwise10"
  top: "Convolution25"
  convolution_param {
    num_output: 640
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "BatchNorm20"
  type: "BatchNorm"
  bottom: "Convolution25"
  top: "Convolution25"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale20"
  type: "Scale"
  bottom: "Convolution25"
  top: "Convolution25"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu20"
  type: "PENLU"
  bottom: "Convolution25"
  top: "Convolution25"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution26"
  type: "Convolution"
  bottom: "Convolution25"
  top: "Convolution26"
  convolution_param {
    num_output: 640
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "Eltwise11"
  type: "Eltwise"
  bottom: "Convolution26"
  bottom: "Eltwise10"
  top: "Eltwise11"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "BatchNorm21"
  type: "BatchNorm"
  bottom: "Eltwise11"
  top: "Eltwise11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale21"
  type: "Scale"
  bottom: "Eltwise11"
  top: "Eltwise11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu21"
  type: "PENLU"
  bottom: "Eltwise11"
  top: "Eltwise11"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution27"
  type: "Convolution"
  bottom: "Eltwise11"
  top: "Convolution27"
  convolution_param {
    num_output: 640
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "BatchNorm22"
  type: "BatchNorm"
  bottom: "Convolution27"
  top: "Convolution27"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  batch_norm_param {
    use_global_stats: false
  }
}
layer {
  name: "Scale22"
  type: "Scale"
  bottom: "Convolution27"
  top: "Convolution27"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu22"
  type: "PENLU"
  bottom: "Convolution27"
  top: "Convolution27"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution28"
  type: "Convolution"
  bottom: "Convolution27"
  top: "Convolution28"
  convolution_param {
    num_output: 640
    bias_term: false
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "msra"
    }
  }
}
layer {
  name: "Eltwise12"
  type: "Eltwise"
  bottom: "Convolution28"
  bottom: "Eltwise11"
  top: "Eltwise12"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "Pooling1"
  type: "Pooling"
  bottom: "Eltwise12"
  top: "Pooling1"
  pooling_param {
    pool: AVE
    global_pooling: true
  }
}
layer {
  name: "InnerProduct1"
  type: "InnerProduct"
  bottom: "Pooling1"
  top: "InnerProduct1"
  inner_product_param {
    num_output: 100
  }
}
layer {
  name: "SoftmaxWithLoss1"
  type: "SoftmaxWithLoss"
  bottom: "InnerProduct1"
  bottom: "label"
  top: "SoftmaxWithLoss1"
}
layer {
  name: "accuracy"
  type: "Accuracy"
  bottom: "InnerProduct1"
  bottom: "label"
  top: "accuracy"
  include {
    phase: TEST
  }
}
I1017 16:08:55.155591 22869 layer_factory.hpp:77] Creating layer cifar
I1017 16:08:55.155633 22869 db_lmdb.cpp:35] Opened lmdb /home/x306/caffe/xn/PENLU/data/cifar100/cifar100_test_lmdb
I1017 16:08:55.155644 22869 net.cpp:84] Creating Layer cifar
I1017 16:08:55.155648 22869 net.cpp:380] cifar -> data
I1017 16:08:55.155663 22869 net.cpp:380] cifar -> label
I1017 16:08:55.155668 22869 data_transformer.cpp:25] Loading mean file from: /home/x306/caffe/xn/PENLU/data/cifar100/mean.binaryproto
I1017 16:08:55.155795 22869 data_layer.cpp:45] output data size: 50,3,28,28
I1017 16:08:55.156394 22869 net.cpp:122] Setting up cifar
I1017 16:08:55.156412 22869 net.cpp:129] Top shape: 50 3 28 28 (117600)
I1017 16:08:55.156416 22869 net.cpp:129] Top shape: 50 (50)
I1017 16:08:55.156419 22869 net.cpp:137] Memory required for data: 470600
I1017 16:08:55.156420 22869 layer_factory.hpp:77] Creating layer label_cifar_1_split
I1017 16:08:55.156425 22869 net.cpp:84] Creating Layer label_cifar_1_split
I1017 16:08:55.156428 22869 net.cpp:406] label_cifar_1_split <- label
I1017 16:08:55.156431 22869 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_0
I1017 16:08:55.156436 22869 net.cpp:380] label_cifar_1_split -> label_cifar_1_split_1
I1017 16:08:55.156512 22869 net.cpp:122] Setting up label_cifar_1_split
I1017 16:08:55.156517 22869 net.cpp:129] Top shape: 50 (50)
I1017 16:08:55.156520 22869 net.cpp:129] Top shape: 50 (50)
I1017 16:08:55.156522 22869 net.cpp:137] Memory required for data: 471000
I1017 16:08:55.156524 22869 layer_factory.hpp:77] Creating layer Convolution1
I1017 16:08:55.156532 22869 net.cpp:84] Creating Layer Convolution1
I1017 16:08:55.156533 22869 net.cpp:406] Convolution1 <- data
I1017 16:08:55.156538 22869 net.cpp:380] Convolution1 -> Convolution1
I1017 16:08:55.157691 22869 net.cpp:122] Setting up Convolution1
I1017 16:08:55.157699 22869 net.cpp:129] Top shape: 50 16 28 28 (627200)
I1017 16:08:55.157702 22869 net.cpp:137] Memory required for data: 2979800
I1017 16:08:55.157709 22869 layer_factory.hpp:77] Creating layer BatchNorm1
I1017 16:08:55.157716 22869 net.cpp:84] Creating Layer BatchNorm1
I1017 16:08:55.157718 22869 net.cpp:406] BatchNorm1 <- Convolution1
I1017 16:08:55.157724 22869 net.cpp:367] BatchNorm1 -> Convolution1 (in-place)
I1017 16:08:55.157886 22869 net.cpp:122] Setting up BatchNorm1
I1017 16:08:55.157894 22869 net.cpp:129] Top shape: 50 16 28 28 (627200)
I1017 16:08:55.157897 22869 net.cpp:137] Memory required for data: 5488600
I1017 16:08:55.157905 22869 layer_factory.hpp:77] Creating layer Scale1
I1017 16:08:55.157912 22869 net.cpp:84] Creating Layer Scale1
I1017 16:08:55.157914 22869 net.cpp:406] Scale1 <- Convolution1
I1017 16:08:55.157938 22869 net.cpp:367] Scale1 -> Convolution1 (in-place)
I1017 16:08:55.157984 22869 layer_factory.hpp:77] Creating layer Scale1
I1017 16:08:55.158092 22869 net.cpp:122] Setting up Scale1
I1017 16:08:55.158097 22869 net.cpp:129] Top shape: 50 16 28 28 (627200)
I1017 16:08:55.158098 22869 net.cpp:137] Memory required for data: 7997400
I1017 16:08:55.158112 22869 layer_factory.hpp:77] Creating layer penlu1
I1017 16:08:55.158118 22869 net.cpp:84] Creating Layer penlu1
I1017 16:08:55.158120 22869 net.cpp:406] penlu1 <- Convolution1
I1017 16:08:55.158124 22869 net.cpp:367] penlu1 -> Convolution1 (in-place)
I1017 16:08:55.158277 22869 net.cpp:122] Setting up penlu1
I1017 16:08:55.158283 22869 net.cpp:129] Top shape: 50 16 28 28 (627200)
I1017 16:08:55.158285 22869 net.cpp:137] Memory required for data: 10506200
I1017 16:08:55.158291 22869 layer_factory.hpp:77] Creating layer Convolution1_penlu1_0_split
I1017 16:08:55.158298 22869 net.cpp:84] Creating Layer Convolution1_penlu1_0_split
I1017 16:08:55.158300 22869 net.cpp:406] Convolution1_penlu1_0_split <- Convolution1
I1017 16:08:55.158303 22869 net.cpp:380] Convolution1_penlu1_0_split -> Convolution1_penlu1_0_split_0
I1017 16:08:55.158308 22869 net.cpp:380] Convolution1_penlu1_0_split -> Convolution1_penlu1_0_split_1
I1017 16:08:55.158336 22869 net.cpp:122] Setting up Convolution1_penlu1_0_split
I1017 16:08:55.158340 22869 net.cpp:129] Top shape: 50 16 28 28 (627200)
I1017 16:08:55.158344 22869 net.cpp:129] Top shape: 50 16 28 28 (627200)
I1017 16:08:55.158346 22869 net.cpp:137] Memory required for data: 15523800
I1017 16:08:55.158349 22869 layer_factory.hpp:77] Creating layer Convolution2
I1017 16:08:55.158354 22869 net.cpp:84] Creating Layer Convolution2
I1017 16:08:55.158356 22869 net.cpp:406] Convolution2 <- Convolution1_penlu1_0_split_0
I1017 16:08:55.158360 22869 net.cpp:380] Convolution2 -> Convolution2
I1017 16:08:55.159981 22869 net.cpp:122] Setting up Convolution2
I1017 16:08:55.159989 22869 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1017 16:08:55.159992 22869 net.cpp:137] Memory required for data: 40611800
I1017 16:08:55.159996 22869 layer_factory.hpp:77] Creating layer BatchNorm2
I1017 16:08:55.160002 22869 net.cpp:84] Creating Layer BatchNorm2
I1017 16:08:55.160006 22869 net.cpp:406] BatchNorm2 <- Convolution2
I1017 16:08:55.160008 22869 net.cpp:367] BatchNorm2 -> Convolution2 (in-place)
I1017 16:08:55.160167 22869 net.cpp:122] Setting up BatchNorm2
I1017 16:08:55.160172 22869 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1017 16:08:55.160174 22869 net.cpp:137] Memory required for data: 65699800
I1017 16:08:55.160179 22869 layer_factory.hpp:77] Creating layer Scale2
I1017 16:08:55.160183 22869 net.cpp:84] Creating Layer Scale2
I1017 16:08:55.160187 22869 net.cpp:406] Scale2 <- Convolution2
I1017 16:08:55.160189 22869 net.cpp:367] Scale2 -> Convolution2 (in-place)
I1017 16:08:55.160220 22869 layer_factory.hpp:77] Creating layer Scale2
I1017 16:08:55.160310 22869 net.cpp:122] Setting up Scale2
I1017 16:08:55.160315 22869 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1017 16:08:55.160317 22869 net.cpp:137] Memory required for data: 90787800
I1017 16:08:55.160322 22869 layer_factory.hpp:77] Creating layer penlu2
I1017 16:08:55.160326 22869 net.cpp:84] Creating Layer penlu2
I1017 16:08:55.160329 22869 net.cpp:406] penlu2 <- Convolution2
I1017 16:08:55.160333 22869 net.cpp:367] penlu2 -> Convolution2 (in-place)
I1017 16:08:55.160538 22869 net.cpp:122] Setting up penlu2
I1017 16:08:55.160542 22869 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1017 16:08:55.160544 22869 net.cpp:137] Memory required for data: 115875800
I1017 16:08:55.160552 22869 layer_factory.hpp:77] Creating layer Convolution3
I1017 16:08:55.160558 22869 net.cpp:84] Creating Layer Convolution3
I1017 16:08:55.160560 22869 net.cpp:406] Convolution3 <- Convolution2
I1017 16:08:55.160564 22869 net.cpp:380] Convolution3 -> Convolution3
I1017 16:08:55.168524 22869 net.cpp:122] Setting up Convolution3
I1017 16:08:55.168536 22869 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1017 16:08:55.168539 22869 net.cpp:137] Memory required for data: 140963800
I1017 16:08:55.168543 22869 layer_factory.hpp:77] Creating layer Convolution4
I1017 16:08:55.168552 22869 net.cpp:84] Creating Layer Convolution4
I1017 16:08:55.168555 22869 net.cpp:406] Convolution4 <- Convolution1_penlu1_0_split_1
I1017 16:08:55.168560 22869 net.cpp:380] Convolution4 -> Convolution4
I1017 16:08:55.169533 22869 net.cpp:122] Setting up Convolution4
I1017 16:08:55.169543 22869 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1017 16:08:55.169545 22869 net.cpp:137] Memory required for data: 166051800
I1017 16:08:55.169549 22869 layer_factory.hpp:77] Creating layer Eltwise1
I1017 16:08:55.169554 22869 net.cpp:84] Creating Layer Eltwise1
I1017 16:08:55.169558 22869 net.cpp:406] Eltwise1 <- Convolution3
I1017 16:08:55.169560 22869 net.cpp:406] Eltwise1 <- Convolution4
I1017 16:08:55.169564 22869 net.cpp:380] Eltwise1 -> Eltwise1
I1017 16:08:55.169584 22869 net.cpp:122] Setting up Eltwise1
I1017 16:08:55.169589 22869 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1017 16:08:55.169590 22869 net.cpp:137] Memory required for data: 191139800
I1017 16:08:55.169594 22869 layer_factory.hpp:77] Creating layer BatchNorm3
I1017 16:08:55.169597 22869 net.cpp:84] Creating Layer BatchNorm3
I1017 16:08:55.169600 22869 net.cpp:406] BatchNorm3 <- Eltwise1
I1017 16:08:55.169603 22869 net.cpp:367] BatchNorm3 -> Eltwise1 (in-place)
I1017 16:08:55.169759 22869 net.cpp:122] Setting up BatchNorm3
I1017 16:08:55.169762 22869 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1017 16:08:55.169764 22869 net.cpp:137] Memory required for data: 216227800
I1017 16:08:55.169770 22869 layer_factory.hpp:77] Creating layer Scale3
I1017 16:08:55.169773 22869 net.cpp:84] Creating Layer Scale3
I1017 16:08:55.169776 22869 net.cpp:406] Scale3 <- Eltwise1
I1017 16:08:55.169780 22869 net.cpp:367] Scale3 -> Eltwise1 (in-place)
I1017 16:08:55.169811 22869 layer_factory.hpp:77] Creating layer Scale3
I1017 16:08:55.169903 22869 net.cpp:122] Setting up Scale3
I1017 16:08:55.169908 22869 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1017 16:08:55.169909 22869 net.cpp:137] Memory required for data: 241315800
I1017 16:08:55.169914 22869 layer_factory.hpp:77] Creating layer penlu3
I1017 16:08:55.169936 22869 net.cpp:84] Creating Layer penlu3
I1017 16:08:55.169939 22869 net.cpp:406] penlu3 <- Eltwise1
I1017 16:08:55.169944 22869 net.cpp:367] penlu3 -> Eltwise1 (in-place)
I1017 16:08:55.170161 22869 net.cpp:122] Setting up penlu3
I1017 16:08:55.170166 22869 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1017 16:08:55.170168 22869 net.cpp:137] Memory required for data: 266403800
I1017 16:08:55.170172 22869 layer_factory.hpp:77] Creating layer Eltwise1_penlu3_0_split
I1017 16:08:55.170178 22869 net.cpp:84] Creating Layer Eltwise1_penlu3_0_split
I1017 16:08:55.170181 22869 net.cpp:406] Eltwise1_penlu3_0_split <- Eltwise1
I1017 16:08:55.170183 22869 net.cpp:380] Eltwise1_penlu3_0_split -> Eltwise1_penlu3_0_split_0
I1017 16:08:55.170188 22869 net.cpp:380] Eltwise1_penlu3_0_split -> Eltwise1_penlu3_0_split_1
I1017 16:08:55.170214 22869 net.cpp:122] Setting up Eltwise1_penlu3_0_split
I1017 16:08:55.170218 22869 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1017 16:08:55.170222 22869 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1017 16:08:55.170223 22869 net.cpp:137] Memory required for data: 316579800
I1017 16:08:55.170225 22869 layer_factory.hpp:77] Creating layer Convolution5
I1017 16:08:55.170230 22869 net.cpp:84] Creating Layer Convolution5
I1017 16:08:55.170233 22869 net.cpp:406] Convolution5 <- Eltwise1_penlu3_0_split_0
I1017 16:08:55.170236 22869 net.cpp:380] Convolution5 -> Convolution5
I1017 16:08:55.177567 22869 net.cpp:122] Setting up Convolution5
I1017 16:08:55.177575 22869 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1017 16:08:55.177577 22869 net.cpp:137] Memory required for data: 341667800
I1017 16:08:55.177582 22869 layer_factory.hpp:77] Creating layer BatchNorm4
I1017 16:08:55.177587 22869 net.cpp:84] Creating Layer BatchNorm4
I1017 16:08:55.177590 22869 net.cpp:406] BatchNorm4 <- Convolution5
I1017 16:08:55.177594 22869 net.cpp:367] BatchNorm4 -> Convolution5 (in-place)
I1017 16:08:55.177762 22869 net.cpp:122] Setting up BatchNorm4
I1017 16:08:55.177767 22869 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1017 16:08:55.177769 22869 net.cpp:137] Memory required for data: 366755800
I1017 16:08:55.177778 22869 layer_factory.hpp:77] Creating layer Scale4
I1017 16:08:55.177791 22869 net.cpp:84] Creating Layer Scale4
I1017 16:08:55.177794 22869 net.cpp:406] Scale4 <- Convolution5
I1017 16:08:55.177798 22869 net.cpp:367] Scale4 -> Convolution5 (in-place)
I1017 16:08:55.177834 22869 layer_factory.hpp:77] Creating layer Scale4
I1017 16:08:55.177935 22869 net.cpp:122] Setting up Scale4
I1017 16:08:55.177942 22869 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1017 16:08:55.177943 22869 net.cpp:137] Memory required for data: 391843800
I1017 16:08:55.177947 22869 layer_factory.hpp:77] Creating layer penlu4
I1017 16:08:55.177953 22869 net.cpp:84] Creating Layer penlu4
I1017 16:08:55.177956 22869 net.cpp:406] penlu4 <- Convolution5
I1017 16:08:55.177961 22869 net.cpp:367] penlu4 -> Convolution5 (in-place)
I1017 16:08:55.178191 22869 net.cpp:122] Setting up penlu4
I1017 16:08:55.178196 22869 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1017 16:08:55.178198 22869 net.cpp:137] Memory required for data: 416931800
I1017 16:08:55.178203 22869 layer_factory.hpp:77] Creating layer Convolution6
I1017 16:08:55.178210 22869 net.cpp:84] Creating Layer Convolution6
I1017 16:08:55.178213 22869 net.cpp:406] Convolution6 <- Convolution5
I1017 16:08:55.178216 22869 net.cpp:380] Convolution6 -> Convolution6
I1017 16:08:55.186162 22869 net.cpp:122] Setting up Convolution6
I1017 16:08:55.186173 22869 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1017 16:08:55.186177 22869 net.cpp:137] Memory required for data: 442019800
I1017 16:08:55.186182 22869 layer_factory.hpp:77] Creating layer Eltwise2
I1017 16:08:55.186187 22869 net.cpp:84] Creating Layer Eltwise2
I1017 16:08:55.186190 22869 net.cpp:406] Eltwise2 <- Convolution6
I1017 16:08:55.186193 22869 net.cpp:406] Eltwise2 <- Eltwise1_penlu3_0_split_1
I1017 16:08:55.186198 22869 net.cpp:380] Eltwise2 -> Eltwise2
I1017 16:08:55.186223 22869 net.cpp:122] Setting up Eltwise2
I1017 16:08:55.186228 22869 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1017 16:08:55.186229 22869 net.cpp:137] Memory required for data: 467107800
I1017 16:08:55.186231 22869 layer_factory.hpp:77] Creating layer BatchNorm5
I1017 16:08:55.186238 22869 net.cpp:84] Creating Layer BatchNorm5
I1017 16:08:55.186239 22869 net.cpp:406] BatchNorm5 <- Eltwise2
I1017 16:08:55.186244 22869 net.cpp:367] BatchNorm5 -> Eltwise2 (in-place)
I1017 16:08:55.186411 22869 net.cpp:122] Setting up BatchNorm5
I1017 16:08:55.186416 22869 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1017 16:08:55.186419 22869 net.cpp:137] Memory required for data: 492195800
I1017 16:08:55.186424 22869 layer_factory.hpp:77] Creating layer Scale5
I1017 16:08:55.186429 22869 net.cpp:84] Creating Layer Scale5
I1017 16:08:55.186432 22869 net.cpp:406] Scale5 <- Eltwise2
I1017 16:08:55.186435 22869 net.cpp:367] Scale5 -> Eltwise2 (in-place)
I1017 16:08:55.186470 22869 layer_factory.hpp:77] Creating layer Scale5
I1017 16:08:55.186571 22869 net.cpp:122] Setting up Scale5
I1017 16:08:55.186576 22869 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1017 16:08:55.186578 22869 net.cpp:137] Memory required for data: 517283800
I1017 16:08:55.186583 22869 layer_factory.hpp:77] Creating layer penlu5
I1017 16:08:55.186589 22869 net.cpp:84] Creating Layer penlu5
I1017 16:08:55.186592 22869 net.cpp:406] penlu5 <- Eltwise2
I1017 16:08:55.186596 22869 net.cpp:367] penlu5 -> Eltwise2 (in-place)
I1017 16:08:55.186805 22869 net.cpp:122] Setting up penlu5
I1017 16:08:55.186810 22869 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1017 16:08:55.186812 22869 net.cpp:137] Memory required for data: 542371800
I1017 16:08:55.186817 22869 layer_factory.hpp:77] Creating layer Eltwise2_penlu5_0_split
I1017 16:08:55.186821 22869 net.cpp:84] Creating Layer Eltwise2_penlu5_0_split
I1017 16:08:55.186823 22869 net.cpp:406] Eltwise2_penlu5_0_split <- Eltwise2
I1017 16:08:55.186828 22869 net.cpp:380] Eltwise2_penlu5_0_split -> Eltwise2_penlu5_0_split_0
I1017 16:08:55.186835 22869 net.cpp:380] Eltwise2_penlu5_0_split -> Eltwise2_penlu5_0_split_1
I1017 16:08:55.186861 22869 net.cpp:122] Setting up Eltwise2_penlu5_0_split
I1017 16:08:55.186875 22869 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1017 16:08:55.186879 22869 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1017 16:08:55.186882 22869 net.cpp:137] Memory required for data: 592547800
I1017 16:08:55.186883 22869 layer_factory.hpp:77] Creating layer Convolution7
I1017 16:08:55.186890 22869 net.cpp:84] Creating Layer Convolution7
I1017 16:08:55.186892 22869 net.cpp:406] Convolution7 <- Eltwise2_penlu5_0_split_0
I1017 16:08:55.186897 22869 net.cpp:380] Convolution7 -> Convolution7
I1017 16:08:55.194581 22869 net.cpp:122] Setting up Convolution7
I1017 16:08:55.194589 22869 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1017 16:08:55.194592 22869 net.cpp:137] Memory required for data: 617635800
I1017 16:08:55.194597 22869 layer_factory.hpp:77] Creating layer BatchNorm6
I1017 16:08:55.194602 22869 net.cpp:84] Creating Layer BatchNorm6
I1017 16:08:55.194604 22869 net.cpp:406] BatchNorm6 <- Convolution7
I1017 16:08:55.194608 22869 net.cpp:367] BatchNorm6 -> Convolution7 (in-place)
I1017 16:08:55.194772 22869 net.cpp:122] Setting up BatchNorm6
I1017 16:08:55.194777 22869 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1017 16:08:55.194779 22869 net.cpp:137] Memory required for data: 642723800
I1017 16:08:55.194784 22869 layer_factory.hpp:77] Creating layer Scale6
I1017 16:08:55.194788 22869 net.cpp:84] Creating Layer Scale6
I1017 16:08:55.194792 22869 net.cpp:406] Scale6 <- Convolution7
I1017 16:08:55.194794 22869 net.cpp:367] Scale6 -> Convolution7 (in-place)
I1017 16:08:55.194828 22869 layer_factory.hpp:77] Creating layer Scale6
I1017 16:08:55.194921 22869 net.cpp:122] Setting up Scale6
I1017 16:08:55.194926 22869 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1017 16:08:55.194928 22869 net.cpp:137] Memory required for data: 667811800
I1017 16:08:55.194932 22869 layer_factory.hpp:77] Creating layer penlu6
I1017 16:08:55.194937 22869 net.cpp:84] Creating Layer penlu6
I1017 16:08:55.194941 22869 net.cpp:406] penlu6 <- Convolution7
I1017 16:08:55.194944 22869 net.cpp:367] penlu6 -> Convolution7 (in-place)
I1017 16:08:55.195142 22869 net.cpp:122] Setting up penlu6
I1017 16:08:55.195147 22869 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1017 16:08:55.195148 22869 net.cpp:137] Memory required for data: 692899800
I1017 16:08:55.195153 22869 layer_factory.hpp:77] Creating layer Convolution8
I1017 16:08:55.195163 22869 net.cpp:84] Creating Layer Convolution8
I1017 16:08:55.195165 22869 net.cpp:406] Convolution8 <- Convolution7
I1017 16:08:55.195169 22869 net.cpp:380] Convolution8 -> Convolution8
I1017 16:08:55.202826 22869 net.cpp:122] Setting up Convolution8
I1017 16:08:55.202834 22869 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1017 16:08:55.202837 22869 net.cpp:137] Memory required for data: 717987800
I1017 16:08:55.202841 22869 layer_factory.hpp:77] Creating layer Eltwise3
I1017 16:08:55.202847 22869 net.cpp:84] Creating Layer Eltwise3
I1017 16:08:55.202849 22869 net.cpp:406] Eltwise3 <- Convolution8
I1017 16:08:55.202852 22869 net.cpp:406] Eltwise3 <- Eltwise2_penlu5_0_split_1
I1017 16:08:55.202857 22869 net.cpp:380] Eltwise3 -> Eltwise3
I1017 16:08:55.202879 22869 net.cpp:122] Setting up Eltwise3
I1017 16:08:55.202884 22869 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1017 16:08:55.202886 22869 net.cpp:137] Memory required for data: 743075800
I1017 16:08:55.202888 22869 layer_factory.hpp:77] Creating layer BatchNorm7
I1017 16:08:55.202893 22869 net.cpp:84] Creating Layer BatchNorm7
I1017 16:08:55.202895 22869 net.cpp:406] BatchNorm7 <- Eltwise3
I1017 16:08:55.202898 22869 net.cpp:367] BatchNorm7 -> Eltwise3 (in-place)
I1017 16:08:55.203054 22869 net.cpp:122] Setting up BatchNorm7
I1017 16:08:55.203058 22869 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1017 16:08:55.203061 22869 net.cpp:137] Memory required for data: 768163800
I1017 16:08:55.203066 22869 layer_factory.hpp:77] Creating layer Scale7
I1017 16:08:55.203070 22869 net.cpp:84] Creating Layer Scale7
I1017 16:08:55.203073 22869 net.cpp:406] Scale7 <- Eltwise3
I1017 16:08:55.203076 22869 net.cpp:367] Scale7 -> Eltwise3 (in-place)
I1017 16:08:55.203117 22869 layer_factory.hpp:77] Creating layer Scale7
I1017 16:08:55.203212 22869 net.cpp:122] Setting up Scale7
I1017 16:08:55.203217 22869 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1017 16:08:55.203218 22869 net.cpp:137] Memory required for data: 793251800
I1017 16:08:55.203222 22869 layer_factory.hpp:77] Creating layer penlu7
I1017 16:08:55.203228 22869 net.cpp:84] Creating Layer penlu7
I1017 16:08:55.203230 22869 net.cpp:406] penlu7 <- Eltwise3
I1017 16:08:55.203234 22869 net.cpp:367] penlu7 -> Eltwise3 (in-place)
I1017 16:08:55.203429 22869 net.cpp:122] Setting up penlu7
I1017 16:08:55.203434 22869 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1017 16:08:55.203436 22869 net.cpp:137] Memory required for data: 818339800
I1017 16:08:55.203449 22869 layer_factory.hpp:77] Creating layer Eltwise3_penlu7_0_split
I1017 16:08:55.203454 22869 net.cpp:84] Creating Layer Eltwise3_penlu7_0_split
I1017 16:08:55.203457 22869 net.cpp:406] Eltwise3_penlu7_0_split <- Eltwise3
I1017 16:08:55.203460 22869 net.cpp:380] Eltwise3_penlu7_0_split -> Eltwise3_penlu7_0_split_0
I1017 16:08:55.203465 22869 net.cpp:380] Eltwise3_penlu7_0_split -> Eltwise3_penlu7_0_split_1
I1017 16:08:55.203493 22869 net.cpp:122] Setting up Eltwise3_penlu7_0_split
I1017 16:08:55.203497 22869 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1017 16:08:55.203500 22869 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1017 16:08:55.203502 22869 net.cpp:137] Memory required for data: 868515800
I1017 16:08:55.203505 22869 layer_factory.hpp:77] Creating layer Convolution9
I1017 16:08:55.203510 22869 net.cpp:84] Creating Layer Convolution9
I1017 16:08:55.203512 22869 net.cpp:406] Convolution9 <- Eltwise3_penlu7_0_split_0
I1017 16:08:55.203517 22869 net.cpp:380] Convolution9 -> Convolution9
I1017 16:08:55.211613 22869 net.cpp:122] Setting up Convolution9
I1017 16:08:55.211624 22869 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1017 16:08:55.211637 22869 net.cpp:137] Memory required for data: 893603800
I1017 16:08:55.211642 22869 layer_factory.hpp:77] Creating layer BatchNorm8
I1017 16:08:55.211659 22869 net.cpp:84] Creating Layer BatchNorm8
I1017 16:08:55.211663 22869 net.cpp:406] BatchNorm8 <- Convolution9
I1017 16:08:55.211668 22869 net.cpp:367] BatchNorm8 -> Convolution9 (in-place)
I1017 16:08:55.211850 22869 net.cpp:122] Setting up BatchNorm8
I1017 16:08:55.211855 22869 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1017 16:08:55.211868 22869 net.cpp:137] Memory required for data: 918691800
I1017 16:08:55.211874 22869 layer_factory.hpp:77] Creating layer Scale8
I1017 16:08:55.211879 22869 net.cpp:84] Creating Layer Scale8
I1017 16:08:55.211881 22869 net.cpp:406] Scale8 <- Convolution9
I1017 16:08:55.211885 22869 net.cpp:367] Scale8 -> Convolution9 (in-place)
I1017 16:08:55.211921 22869 layer_factory.hpp:77] Creating layer Scale8
I1017 16:08:55.212021 22869 net.cpp:122] Setting up Scale8
I1017 16:08:55.212028 22869 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1017 16:08:55.212030 22869 net.cpp:137] Memory required for data: 943779800
I1017 16:08:55.212034 22869 layer_factory.hpp:77] Creating layer penlu8
I1017 16:08:55.212041 22869 net.cpp:84] Creating Layer penlu8
I1017 16:08:55.212044 22869 net.cpp:406] penlu8 <- Convolution9
I1017 16:08:55.212049 22869 net.cpp:367] penlu8 -> Convolution9 (in-place)
I1017 16:08:55.212268 22869 net.cpp:122] Setting up penlu8
I1017 16:08:55.212275 22869 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1017 16:08:55.212277 22869 net.cpp:137] Memory required for data: 968867800
I1017 16:08:55.212282 22869 layer_factory.hpp:77] Creating layer Convolution10
I1017 16:08:55.212290 22869 net.cpp:84] Creating Layer Convolution10
I1017 16:08:55.212293 22869 net.cpp:406] Convolution10 <- Convolution9
I1017 16:08:55.212297 22869 net.cpp:380] Convolution10 -> Convolution10
I1017 16:08:55.220161 22869 net.cpp:122] Setting up Convolution10
I1017 16:08:55.220182 22869 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1017 16:08:55.220185 22869 net.cpp:137] Memory required for data: 993955800
I1017 16:08:55.220197 22869 layer_factory.hpp:77] Creating layer Eltwise4
I1017 16:08:55.220211 22869 net.cpp:84] Creating Layer Eltwise4
I1017 16:08:55.220214 22869 net.cpp:406] Eltwise4 <- Convolution10
I1017 16:08:55.220217 22869 net.cpp:406] Eltwise4 <- Eltwise3_penlu7_0_split_1
I1017 16:08:55.220221 22869 net.cpp:380] Eltwise4 -> Eltwise4
I1017 16:08:55.220247 22869 net.cpp:122] Setting up Eltwise4
I1017 16:08:55.220250 22869 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1017 16:08:55.220252 22869 net.cpp:137] Memory required for data: 1019043800
I1017 16:08:55.220254 22869 layer_factory.hpp:77] Creating layer Eltwise4_Eltwise4_0_split
I1017 16:08:55.220259 22869 net.cpp:84] Creating Layer Eltwise4_Eltwise4_0_split
I1017 16:08:55.220262 22869 net.cpp:406] Eltwise4_Eltwise4_0_split <- Eltwise4
I1017 16:08:55.220264 22869 net.cpp:380] Eltwise4_Eltwise4_0_split -> Eltwise4_Eltwise4_0_split_0
I1017 16:08:55.220268 22869 net.cpp:380] Eltwise4_Eltwise4_0_split -> Eltwise4_Eltwise4_0_split_1
I1017 16:08:55.220297 22869 net.cpp:122] Setting up Eltwise4_Eltwise4_0_split
I1017 16:08:55.220301 22869 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1017 16:08:55.220304 22869 net.cpp:129] Top shape: 50 160 28 28 (6272000)
I1017 16:08:55.220306 22869 net.cpp:137] Memory required for data: 1069219800
I1017 16:08:55.220309 22869 layer_factory.hpp:77] Creating layer Convolution11
I1017 16:08:55.220314 22869 net.cpp:84] Creating Layer Convolution11
I1017 16:08:55.220316 22869 net.cpp:406] Convolution11 <- Eltwise4_Eltwise4_0_split_0
I1017 16:08:55.220320 22869 net.cpp:380] Convolution11 -> Convolution11
I1017 16:08:55.233481 22869 net.cpp:122] Setting up Convolution11
I1017 16:08:55.233490 22869 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1017 16:08:55.233494 22869 net.cpp:137] Memory required for data: 1081763800
I1017 16:08:55.233496 22869 layer_factory.hpp:77] Creating layer BatchNorm9
I1017 16:08:55.233502 22869 net.cpp:84] Creating Layer BatchNorm9
I1017 16:08:55.233505 22869 net.cpp:406] BatchNorm9 <- Convolution11
I1017 16:08:55.233510 22869 net.cpp:367] BatchNorm9 -> Convolution11 (in-place)
I1017 16:08:55.233686 22869 net.cpp:122] Setting up BatchNorm9
I1017 16:08:55.233690 22869 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1017 16:08:55.233692 22869 net.cpp:137] Memory required for data: 1094307800
I1017 16:08:55.233697 22869 layer_factory.hpp:77] Creating layer Scale9
I1017 16:08:55.233702 22869 net.cpp:84] Creating Layer Scale9
I1017 16:08:55.233705 22869 net.cpp:406] Scale9 <- Convolution11
I1017 16:08:55.233708 22869 net.cpp:367] Scale9 -> Convolution11 (in-place)
I1017 16:08:55.233745 22869 layer_factory.hpp:77] Creating layer Scale9
I1017 16:08:55.233840 22869 net.cpp:122] Setting up Scale9
I1017 16:08:55.233845 22869 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1017 16:08:55.233847 22869 net.cpp:137] Memory required for data: 1106851800
I1017 16:08:55.233851 22869 layer_factory.hpp:77] Creating layer penlu9
I1017 16:08:55.233857 22869 net.cpp:84] Creating Layer penlu9
I1017 16:08:55.233860 22869 net.cpp:406] penlu9 <- Convolution11
I1017 16:08:55.233865 22869 net.cpp:367] penlu9 -> Convolution11 (in-place)
I1017 16:08:55.234041 22869 net.cpp:122] Setting up penlu9
I1017 16:08:55.234046 22869 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1017 16:08:55.234048 22869 net.cpp:137] Memory required for data: 1119395800
I1017 16:08:55.234053 22869 layer_factory.hpp:77] Creating layer Convolution12
I1017 16:08:55.234058 22869 net.cpp:84] Creating Layer Convolution12
I1017 16:08:55.234061 22869 net.cpp:406] Convolution12 <- Convolution11
I1017 16:08:55.234066 22869 net.cpp:380] Convolution12 -> Convolution12
I1017 16:08:55.260318 22869 net.cpp:122] Setting up Convolution12
I1017 16:08:55.260337 22869 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1017 16:08:55.260340 22869 net.cpp:137] Memory required for data: 1131939800
I1017 16:08:55.260346 22869 layer_factory.hpp:77] Creating layer Convolution13
I1017 16:08:55.260370 22869 net.cpp:84] Creating Layer Convolution13
I1017 16:08:55.260375 22869 net.cpp:406] Convolution13 <- Eltwise4_Eltwise4_0_split_1
I1017 16:08:55.260398 22869 net.cpp:380] Convolution13 -> Convolution13
I1017 16:08:55.263047 22869 net.cpp:122] Setting up Convolution13
I1017 16:08:55.263057 22869 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1017 16:08:55.263061 22869 net.cpp:137] Memory required for data: 1144483800
I1017 16:08:55.263064 22869 layer_factory.hpp:77] Creating layer Eltwise5
I1017 16:08:55.263070 22869 net.cpp:84] Creating Layer Eltwise5
I1017 16:08:55.263073 22869 net.cpp:406] Eltwise5 <- Convolution12
I1017 16:08:55.263077 22869 net.cpp:406] Eltwise5 <- Convolution13
I1017 16:08:55.263082 22869 net.cpp:380] Eltwise5 -> Eltwise5
I1017 16:08:55.263105 22869 net.cpp:122] Setting up Eltwise5
I1017 16:08:55.263110 22869 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1017 16:08:55.263113 22869 net.cpp:137] Memory required for data: 1157027800
I1017 16:08:55.263114 22869 layer_factory.hpp:77] Creating layer BatchNorm10
I1017 16:08:55.263119 22869 net.cpp:84] Creating Layer BatchNorm10
I1017 16:08:55.263121 22869 net.cpp:406] BatchNorm10 <- Eltwise5
I1017 16:08:55.263125 22869 net.cpp:367] BatchNorm10 -> Eltwise5 (in-place)
I1017 16:08:55.263305 22869 net.cpp:122] Setting up BatchNorm10
I1017 16:08:55.263310 22869 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1017 16:08:55.263314 22869 net.cpp:137] Memory required for data: 1169571800
I1017 16:08:55.263319 22869 layer_factory.hpp:77] Creating layer Scale10
I1017 16:08:55.263324 22869 net.cpp:84] Creating Layer Scale10
I1017 16:08:55.263327 22869 net.cpp:406] Scale10 <- Eltwise5
I1017 16:08:55.263331 22869 net.cpp:367] Scale10 -> Eltwise5 (in-place)
I1017 16:08:55.263370 22869 layer_factory.hpp:77] Creating layer Scale10
I1017 16:08:55.263466 22869 net.cpp:122] Setting up Scale10
I1017 16:08:55.263471 22869 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1017 16:08:55.263474 22869 net.cpp:137] Memory required for data: 1182115800
I1017 16:08:55.263478 22869 layer_factory.hpp:77] Creating layer penlu10
I1017 16:08:55.263485 22869 net.cpp:84] Creating Layer penlu10
I1017 16:08:55.263489 22869 net.cpp:406] penlu10 <- Eltwise5
I1017 16:08:55.263494 22869 net.cpp:367] penlu10 -> Eltwise5 (in-place)
I1017 16:08:55.263664 22869 net.cpp:122] Setting up penlu10
I1017 16:08:55.263670 22869 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1017 16:08:55.263674 22869 net.cpp:137] Memory required for data: 1194659800
I1017 16:08:55.263679 22869 layer_factory.hpp:77] Creating layer Eltwise5_penlu10_0_split
I1017 16:08:55.263684 22869 net.cpp:84] Creating Layer Eltwise5_penlu10_0_split
I1017 16:08:55.263686 22869 net.cpp:406] Eltwise5_penlu10_0_split <- Eltwise5
I1017 16:08:55.263689 22869 net.cpp:380] Eltwise5_penlu10_0_split -> Eltwise5_penlu10_0_split_0
I1017 16:08:55.263698 22869 net.cpp:380] Eltwise5_penlu10_0_split -> Eltwise5_penlu10_0_split_1
I1017 16:08:55.263727 22869 net.cpp:122] Setting up Eltwise5_penlu10_0_split
I1017 16:08:55.263732 22869 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1017 16:08:55.263736 22869 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1017 16:08:55.263737 22869 net.cpp:137] Memory required for data: 1219747800
I1017 16:08:55.263739 22869 layer_factory.hpp:77] Creating layer Convolution14
I1017 16:08:55.263746 22869 net.cpp:84] Creating Layer Convolution14
I1017 16:08:55.263749 22869 net.cpp:406] Convolution14 <- Eltwise5_penlu10_0_split_0
I1017 16:08:55.263753 22869 net.cpp:380] Convolution14 -> Convolution14
I1017 16:08:55.289580 22869 net.cpp:122] Setting up Convolution14
I1017 16:08:55.289599 22869 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1017 16:08:55.289603 22869 net.cpp:137] Memory required for data: 1232291800
I1017 16:08:55.289608 22869 layer_factory.hpp:77] Creating layer BatchNorm11
I1017 16:08:55.289616 22869 net.cpp:84] Creating Layer BatchNorm11
I1017 16:08:55.289630 22869 net.cpp:406] BatchNorm11 <- Convolution14
I1017 16:08:55.289636 22869 net.cpp:367] BatchNorm11 -> Convolution14 (in-place)
I1017 16:08:55.289880 22869 net.cpp:122] Setting up BatchNorm11
I1017 16:08:55.289885 22869 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1017 16:08:55.289897 22869 net.cpp:137] Memory required for data: 1244835800
I1017 16:08:55.289903 22869 layer_factory.hpp:77] Creating layer Scale11
I1017 16:08:55.289934 22869 net.cpp:84] Creating Layer Scale11
I1017 16:08:55.289938 22869 net.cpp:406] Scale11 <- Convolution14
I1017 16:08:55.289942 22869 net.cpp:367] Scale11 -> Convolution14 (in-place)
I1017 16:08:55.290004 22869 layer_factory.hpp:77] Creating layer Scale11
I1017 16:08:55.290123 22869 net.cpp:122] Setting up Scale11
I1017 16:08:55.290128 22869 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1017 16:08:55.290130 22869 net.cpp:137] Memory required for data: 1257379800
I1017 16:08:55.290134 22869 layer_factory.hpp:77] Creating layer penlu11
I1017 16:08:55.290140 22869 net.cpp:84] Creating Layer penlu11
I1017 16:08:55.290143 22869 net.cpp:406] penlu11 <- Convolution14
I1017 16:08:55.290148 22869 net.cpp:367] penlu11 -> Convolution14 (in-place)
I1017 16:08:55.290871 22869 net.cpp:122] Setting up penlu11
I1017 16:08:55.290880 22869 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1017 16:08:55.290882 22869 net.cpp:137] Memory required for data: 1269923800
I1017 16:08:55.290887 22869 layer_factory.hpp:77] Creating layer Convolution15
I1017 16:08:55.290895 22869 net.cpp:84] Creating Layer Convolution15
I1017 16:08:55.290908 22869 net.cpp:406] Convolution15 <- Convolution14
I1017 16:08:55.290913 22869 net.cpp:380] Convolution15 -> Convolution15
I1017 16:08:55.316401 22869 net.cpp:122] Setting up Convolution15
I1017 16:08:55.316416 22869 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1017 16:08:55.316421 22869 net.cpp:137] Memory required for data: 1282467800
I1017 16:08:55.316426 22869 layer_factory.hpp:77] Creating layer Eltwise6
I1017 16:08:55.316433 22869 net.cpp:84] Creating Layer Eltwise6
I1017 16:08:55.316447 22869 net.cpp:406] Eltwise6 <- Convolution15
I1017 16:08:55.316452 22869 net.cpp:406] Eltwise6 <- Eltwise5_penlu10_0_split_1
I1017 16:08:55.316469 22869 net.cpp:380] Eltwise6 -> Eltwise6
I1017 16:08:55.316527 22869 net.cpp:122] Setting up Eltwise6
I1017 16:08:55.316532 22869 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1017 16:08:55.316535 22869 net.cpp:137] Memory required for data: 1295011800
I1017 16:08:55.316537 22869 layer_factory.hpp:77] Creating layer BatchNorm12
I1017 16:08:55.316542 22869 net.cpp:84] Creating Layer BatchNorm12
I1017 16:08:55.316545 22869 net.cpp:406] BatchNorm12 <- Eltwise6
I1017 16:08:55.316548 22869 net.cpp:367] BatchNorm12 -> Eltwise6 (in-place)
I1017 16:08:55.316752 22869 net.cpp:122] Setting up BatchNorm12
I1017 16:08:55.316757 22869 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1017 16:08:55.316759 22869 net.cpp:137] Memory required for data: 1307555800
I1017 16:08:55.316766 22869 layer_factory.hpp:77] Creating layer Scale12
I1017 16:08:55.316771 22869 net.cpp:84] Creating Layer Scale12
I1017 16:08:55.316772 22869 net.cpp:406] Scale12 <- Eltwise6
I1017 16:08:55.316787 22869 net.cpp:367] Scale12 -> Eltwise6 (in-place)
I1017 16:08:55.316835 22869 layer_factory.hpp:77] Creating layer Scale12
I1017 16:08:55.316954 22869 net.cpp:122] Setting up Scale12
I1017 16:08:55.316959 22869 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1017 16:08:55.316962 22869 net.cpp:137] Memory required for data: 1320099800
I1017 16:08:55.316965 22869 layer_factory.hpp:77] Creating layer penlu12
I1017 16:08:55.316988 22869 net.cpp:84] Creating Layer penlu12
I1017 16:08:55.316992 22869 net.cpp:406] penlu12 <- Eltwise6
I1017 16:08:55.316994 22869 net.cpp:367] penlu12 -> Eltwise6 (in-place)
I1017 16:08:55.317178 22869 net.cpp:122] Setting up penlu12
I1017 16:08:55.317183 22869 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1017 16:08:55.317185 22869 net.cpp:137] Memory required for data: 1332643800
I1017 16:08:55.317190 22869 layer_factory.hpp:77] Creating layer Eltwise6_penlu12_0_split
I1017 16:08:55.317194 22869 net.cpp:84] Creating Layer Eltwise6_penlu12_0_split
I1017 16:08:55.317198 22869 net.cpp:406] Eltwise6_penlu12_0_split <- Eltwise6
I1017 16:08:55.317212 22869 net.cpp:380] Eltwise6_penlu12_0_split -> Eltwise6_penlu12_0_split_0
I1017 16:08:55.317226 22869 net.cpp:380] Eltwise6_penlu12_0_split -> Eltwise6_penlu12_0_split_1
I1017 16:08:55.317286 22869 net.cpp:122] Setting up Eltwise6_penlu12_0_split
I1017 16:08:55.317291 22869 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1017 16:08:55.317293 22869 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1017 16:08:55.317296 22869 net.cpp:137] Memory required for data: 1357731800
I1017 16:08:55.317297 22869 layer_factory.hpp:77] Creating layer Convolution16
I1017 16:08:55.317315 22869 net.cpp:84] Creating Layer Convolution16
I1017 16:08:55.317318 22869 net.cpp:406] Convolution16 <- Eltwise6_penlu12_0_split_0
I1017 16:08:55.317322 22869 net.cpp:380] Convolution16 -> Convolution16
I1017 16:08:55.343598 22869 net.cpp:122] Setting up Convolution16
I1017 16:08:55.343616 22869 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1017 16:08:55.343619 22869 net.cpp:137] Memory required for data: 1370275800
I1017 16:08:55.343624 22869 layer_factory.hpp:77] Creating layer BatchNorm13
I1017 16:08:55.343633 22869 net.cpp:84] Creating Layer BatchNorm13
I1017 16:08:55.343647 22869 net.cpp:406] BatchNorm13 <- Convolution16
I1017 16:08:55.343653 22869 net.cpp:367] BatchNorm13 -> Convolution16 (in-place)
I1017 16:08:55.343888 22869 net.cpp:122] Setting up BatchNorm13
I1017 16:08:55.343894 22869 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1017 16:08:55.343896 22869 net.cpp:137] Memory required for data: 1382819800
I1017 16:08:55.343902 22869 layer_factory.hpp:77] Creating layer Scale13
I1017 16:08:55.343907 22869 net.cpp:84] Creating Layer Scale13
I1017 16:08:55.343910 22869 net.cpp:406] Scale13 <- Convolution16
I1017 16:08:55.343914 22869 net.cpp:367] Scale13 -> Convolution16 (in-place)
I1017 16:08:55.343976 22869 layer_factory.hpp:77] Creating layer Scale13
I1017 16:08:55.344097 22869 net.cpp:122] Setting up Scale13
I1017 16:08:55.344103 22869 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1017 16:08:55.344105 22869 net.cpp:137] Memory required for data: 1395363800
I1017 16:08:55.344120 22869 layer_factory.hpp:77] Creating layer penlu13
I1017 16:08:55.344127 22869 net.cpp:84] Creating Layer penlu13
I1017 16:08:55.344144 22869 net.cpp:406] penlu13 <- Convolution16
I1017 16:08:55.344149 22869 net.cpp:367] penlu13 -> Convolution16 (in-place)
I1017 16:08:55.344365 22869 net.cpp:122] Setting up penlu13
I1017 16:08:55.344372 22869 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1017 16:08:55.344374 22869 net.cpp:137] Memory required for data: 1407907800
I1017 16:08:55.344378 22869 layer_factory.hpp:77] Creating layer Convolution17
I1017 16:08:55.344385 22869 net.cpp:84] Creating Layer Convolution17
I1017 16:08:55.344388 22869 net.cpp:406] Convolution17 <- Convolution16
I1017 16:08:55.344403 22869 net.cpp:380] Convolution17 -> Convolution17
I1017 16:08:55.370638 22869 net.cpp:122] Setting up Convolution17
I1017 16:08:55.370657 22869 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1017 16:08:55.370661 22869 net.cpp:137] Memory required for data: 1420451800
I1017 16:08:55.370666 22869 layer_factory.hpp:77] Creating layer Eltwise7
I1017 16:08:55.370676 22869 net.cpp:84] Creating Layer Eltwise7
I1017 16:08:55.370690 22869 net.cpp:406] Eltwise7 <- Convolution17
I1017 16:08:55.370695 22869 net.cpp:406] Eltwise7 <- Eltwise6_penlu12_0_split_1
I1017 16:08:55.370712 22869 net.cpp:380] Eltwise7 -> Eltwise7
I1017 16:08:55.370764 22869 net.cpp:122] Setting up Eltwise7
I1017 16:08:55.370769 22869 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1017 16:08:55.370770 22869 net.cpp:137] Memory required for data: 1432995800
I1017 16:08:55.370772 22869 layer_factory.hpp:77] Creating layer BatchNorm14
I1017 16:08:55.370777 22869 net.cpp:84] Creating Layer BatchNorm14
I1017 16:08:55.370780 22869 net.cpp:406] BatchNorm14 <- Eltwise7
I1017 16:08:55.370784 22869 net.cpp:367] BatchNorm14 -> Eltwise7 (in-place)
I1017 16:08:55.370988 22869 net.cpp:122] Setting up BatchNorm14
I1017 16:08:55.370993 22869 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1017 16:08:55.370995 22869 net.cpp:137] Memory required for data: 1445539800
I1017 16:08:55.371001 22869 layer_factory.hpp:77] Creating layer Scale14
I1017 16:08:55.371026 22869 net.cpp:84] Creating Layer Scale14
I1017 16:08:55.371029 22869 net.cpp:406] Scale14 <- Eltwise7
I1017 16:08:55.371044 22869 net.cpp:367] Scale14 -> Eltwise7 (in-place)
I1017 16:08:55.371119 22869 layer_factory.hpp:77] Creating layer Scale14
I1017 16:08:55.371240 22869 net.cpp:122] Setting up Scale14
I1017 16:08:55.371245 22869 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1017 16:08:55.371248 22869 net.cpp:137] Memory required for data: 1458083800
I1017 16:08:55.371251 22869 layer_factory.hpp:77] Creating layer penlu14
I1017 16:08:55.371258 22869 net.cpp:84] Creating Layer penlu14
I1017 16:08:55.371260 22869 net.cpp:406] penlu14 <- Eltwise7
I1017 16:08:55.371274 22869 net.cpp:367] penlu14 -> Eltwise7 (in-place)
I1017 16:08:55.371485 22869 net.cpp:122] Setting up penlu14
I1017 16:08:55.371491 22869 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1017 16:08:55.371493 22869 net.cpp:137] Memory required for data: 1470627800
I1017 16:08:55.371508 22869 layer_factory.hpp:77] Creating layer Eltwise7_penlu14_0_split
I1017 16:08:55.371526 22869 net.cpp:84] Creating Layer Eltwise7_penlu14_0_split
I1017 16:08:55.371528 22869 net.cpp:406] Eltwise7_penlu14_0_split <- Eltwise7
I1017 16:08:55.371532 22869 net.cpp:380] Eltwise7_penlu14_0_split -> Eltwise7_penlu14_0_split_0
I1017 16:08:55.371537 22869 net.cpp:380] Eltwise7_penlu14_0_split -> Eltwise7_penlu14_0_split_1
I1017 16:08:55.371615 22869 net.cpp:122] Setting up Eltwise7_penlu14_0_split
I1017 16:08:55.371620 22869 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1017 16:08:55.371623 22869 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1017 16:08:55.371625 22869 net.cpp:137] Memory required for data: 1495715800
I1017 16:08:55.371628 22869 layer_factory.hpp:77] Creating layer Convolution18
I1017 16:08:55.371634 22869 net.cpp:84] Creating Layer Convolution18
I1017 16:08:55.371637 22869 net.cpp:406] Convolution18 <- Eltwise7_penlu14_0_split_0
I1017 16:08:55.371650 22869 net.cpp:380] Convolution18 -> Convolution18
I1017 16:08:55.397328 22869 net.cpp:122] Setting up Convolution18
I1017 16:08:55.397356 22869 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1017 16:08:55.397359 22869 net.cpp:137] Memory required for data: 1508259800
I1017 16:08:55.397366 22869 layer_factory.hpp:77] Creating layer BatchNorm15
I1017 16:08:55.397373 22869 net.cpp:84] Creating Layer BatchNorm15
I1017 16:08:55.397377 22869 net.cpp:406] BatchNorm15 <- Convolution18
I1017 16:08:55.397382 22869 net.cpp:367] BatchNorm15 -> Convolution18 (in-place)
I1017 16:08:55.397604 22869 net.cpp:122] Setting up BatchNorm15
I1017 16:08:55.397610 22869 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1017 16:08:55.397613 22869 net.cpp:137] Memory required for data: 1520803800
I1017 16:08:55.397617 22869 layer_factory.hpp:77] Creating layer Scale15
I1017 16:08:55.397624 22869 net.cpp:84] Creating Layer Scale15
I1017 16:08:55.397626 22869 net.cpp:406] Scale15 <- Convolution18
I1017 16:08:55.397639 22869 net.cpp:367] Scale15 -> Convolution18 (in-place)
I1017 16:08:55.397688 22869 layer_factory.hpp:77] Creating layer Scale15
I1017 16:08:55.397810 22869 net.cpp:122] Setting up Scale15
I1017 16:08:55.397815 22869 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1017 16:08:55.397817 22869 net.cpp:137] Memory required for data: 1533347800
I1017 16:08:55.397821 22869 layer_factory.hpp:77] Creating layer penlu15
I1017 16:08:55.397827 22869 net.cpp:84] Creating Layer penlu15
I1017 16:08:55.397830 22869 net.cpp:406] penlu15 <- Convolution18
I1017 16:08:55.397845 22869 net.cpp:367] penlu15 -> Convolution18 (in-place)
I1017 16:08:55.398032 22869 net.cpp:122] Setting up penlu15
I1017 16:08:55.398038 22869 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1017 16:08:55.398041 22869 net.cpp:137] Memory required for data: 1545891800
I1017 16:08:55.398046 22869 layer_factory.hpp:77] Creating layer Convolution19
I1017 16:08:55.398052 22869 net.cpp:84] Creating Layer Convolution19
I1017 16:08:55.398056 22869 net.cpp:406] Convolution19 <- Convolution18
I1017 16:08:55.398068 22869 net.cpp:380] Convolution19 -> Convolution19
I1017 16:08:55.423611 22869 net.cpp:122] Setting up Convolution19
I1017 16:08:55.423627 22869 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1017 16:08:55.423630 22869 net.cpp:137] Memory required for data: 1558435800
I1017 16:08:55.423646 22869 layer_factory.hpp:77] Creating layer Eltwise8
I1017 16:08:55.423665 22869 net.cpp:84] Creating Layer Eltwise8
I1017 16:08:55.423669 22869 net.cpp:406] Eltwise8 <- Convolution19
I1017 16:08:55.423673 22869 net.cpp:406] Eltwise8 <- Eltwise7_penlu14_0_split_1
I1017 16:08:55.423687 22869 net.cpp:380] Eltwise8 -> Eltwise8
I1017 16:08:55.423733 22869 net.cpp:122] Setting up Eltwise8
I1017 16:08:55.423738 22869 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1017 16:08:55.423749 22869 net.cpp:137] Memory required for data: 1570979800
I1017 16:08:55.423751 22869 layer_factory.hpp:77] Creating layer Eltwise8_Eltwise8_0_split
I1017 16:08:55.423756 22869 net.cpp:84] Creating Layer Eltwise8_Eltwise8_0_split
I1017 16:08:55.423769 22869 net.cpp:406] Eltwise8_Eltwise8_0_split <- Eltwise8
I1017 16:08:55.423773 22869 net.cpp:380] Eltwise8_Eltwise8_0_split -> Eltwise8_Eltwise8_0_split_0
I1017 16:08:55.423777 22869 net.cpp:380] Eltwise8_Eltwise8_0_split -> Eltwise8_Eltwise8_0_split_1
I1017 16:08:55.423827 22869 net.cpp:122] Setting up Eltwise8_Eltwise8_0_split
I1017 16:08:55.423833 22869 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1017 16:08:55.423846 22869 net.cpp:129] Top shape: 50 320 14 14 (3136000)
I1017 16:08:55.423848 22869 net.cpp:137] Memory required for data: 1596067800
I1017 16:08:55.423851 22869 layer_factory.hpp:77] Creating layer Convolution20
I1017 16:08:55.423858 22869 net.cpp:84] Creating Layer Convolution20
I1017 16:08:55.423861 22869 net.cpp:406] Convolution20 <- Eltwise8_Eltwise8_0_split_0
I1017 16:08:55.423866 22869 net.cpp:380] Convolution20 -> Convolution20
I1017 16:08:55.473788 22869 net.cpp:122] Setting up Convolution20
I1017 16:08:55.473809 22869 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1017 16:08:55.473812 22869 net.cpp:137] Memory required for data: 1602339800
I1017 16:08:55.473819 22869 layer_factory.hpp:77] Creating layer BatchNorm16
I1017 16:08:55.473829 22869 net.cpp:84] Creating Layer BatchNorm16
I1017 16:08:55.473832 22869 net.cpp:406] BatchNorm16 <- Convolution20
I1017 16:08:55.473847 22869 net.cpp:367] BatchNorm16 -> Convolution20 (in-place)
I1017 16:08:55.474052 22869 net.cpp:122] Setting up BatchNorm16
I1017 16:08:55.474059 22869 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1017 16:08:55.474061 22869 net.cpp:137] Memory required for data: 1608611800
I1017 16:08:55.474066 22869 layer_factory.hpp:77] Creating layer Scale16
I1017 16:08:55.474071 22869 net.cpp:84] Creating Layer Scale16
I1017 16:08:55.474074 22869 net.cpp:406] Scale16 <- Convolution20
I1017 16:08:55.474077 22869 net.cpp:367] Scale16 -> Convolution20 (in-place)
I1017 16:08:55.474134 22869 layer_factory.hpp:77] Creating layer Scale16
I1017 16:08:55.474254 22869 net.cpp:122] Setting up Scale16
I1017 16:08:55.474259 22869 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1017 16:08:55.474262 22869 net.cpp:137] Memory required for data: 1614883800
I1017 16:08:55.474267 22869 layer_factory.hpp:77] Creating layer penlu16
I1017 16:08:55.474272 22869 net.cpp:84] Creating Layer penlu16
I1017 16:08:55.474275 22869 net.cpp:406] penlu16 <- Convolution20
I1017 16:08:55.474278 22869 net.cpp:367] penlu16 -> Convolution20 (in-place)
I1017 16:08:55.474443 22869 net.cpp:122] Setting up penlu16
I1017 16:08:55.474448 22869 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1017 16:08:55.474450 22869 net.cpp:137] Memory required for data: 1621155800
I1017 16:08:55.474455 22869 layer_factory.hpp:77] Creating layer Convolution21
I1017 16:08:55.474463 22869 net.cpp:84] Creating Layer Convolution21
I1017 16:08:55.474465 22869 net.cpp:406] Convolution21 <- Convolution20
I1017 16:08:55.474469 22869 net.cpp:380] Convolution21 -> Convolution21
I1017 16:08:55.571895 22869 net.cpp:122] Setting up Convolution21
I1017 16:08:55.571919 22869 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1017 16:08:55.571938 22869 net.cpp:137] Memory required for data: 1627427800
I1017 16:08:55.571945 22869 layer_factory.hpp:77] Creating layer Convolution22
I1017 16:08:55.571967 22869 net.cpp:84] Creating Layer Convolution22
I1017 16:08:55.571974 22869 net.cpp:406] Convolution22 <- Eltwise8_Eltwise8_0_split_1
I1017 16:08:55.571980 22869 net.cpp:380] Convolution22 -> Convolution22
I1017 16:08:55.578112 22869 net.cpp:122] Setting up Convolution22
I1017 16:08:55.578122 22869 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1017 16:08:55.578125 22869 net.cpp:137] Memory required for data: 1633699800
I1017 16:08:55.578130 22869 layer_factory.hpp:77] Creating layer Eltwise9
I1017 16:08:55.578135 22869 net.cpp:84] Creating Layer Eltwise9
I1017 16:08:55.578137 22869 net.cpp:406] Eltwise9 <- Convolution21
I1017 16:08:55.578140 22869 net.cpp:406] Eltwise9 <- Convolution22
I1017 16:08:55.578145 22869 net.cpp:380] Eltwise9 -> Eltwise9
I1017 16:08:55.578187 22869 net.cpp:122] Setting up Eltwise9
I1017 16:08:55.578193 22869 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1017 16:08:55.578207 22869 net.cpp:137] Memory required for data: 1639971800
I1017 16:08:55.578208 22869 layer_factory.hpp:77] Creating layer BatchNorm17
I1017 16:08:55.578213 22869 net.cpp:84] Creating Layer BatchNorm17
I1017 16:08:55.578225 22869 net.cpp:406] BatchNorm17 <- Eltwise9
I1017 16:08:55.578230 22869 net.cpp:367] BatchNorm17 -> Eltwise9 (in-place)
I1017 16:08:55.578425 22869 net.cpp:122] Setting up BatchNorm17
I1017 16:08:55.578430 22869 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1017 16:08:55.578433 22869 net.cpp:137] Memory required for data: 1646243800
I1017 16:08:55.578447 22869 layer_factory.hpp:77] Creating layer Scale17
I1017 16:08:55.578454 22869 net.cpp:84] Creating Layer Scale17
I1017 16:08:55.578457 22869 net.cpp:406] Scale17 <- Eltwise9
I1017 16:08:55.578460 22869 net.cpp:367] Scale17 -> Eltwise9 (in-place)
I1017 16:08:55.578507 22869 layer_factory.hpp:77] Creating layer Scale17
I1017 16:08:55.578624 22869 net.cpp:122] Setting up Scale17
I1017 16:08:55.578629 22869 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1017 16:08:55.578632 22869 net.cpp:137] Memory required for data: 1652515800
I1017 16:08:55.578646 22869 layer_factory.hpp:77] Creating layer penlu17
I1017 16:08:55.578654 22869 net.cpp:84] Creating Layer penlu17
I1017 16:08:55.578656 22869 net.cpp:406] penlu17 <- Eltwise9
I1017 16:08:55.578661 22869 net.cpp:367] penlu17 -> Eltwise9 (in-place)
I1017 16:08:55.578814 22869 net.cpp:122] Setting up penlu17
I1017 16:08:55.578820 22869 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1017 16:08:55.578822 22869 net.cpp:137] Memory required for data: 1658787800
I1017 16:08:55.578827 22869 layer_factory.hpp:77] Creating layer Eltwise9_penlu17_0_split
I1017 16:08:55.578832 22869 net.cpp:84] Creating Layer Eltwise9_penlu17_0_split
I1017 16:08:55.578836 22869 net.cpp:406] Eltwise9_penlu17_0_split <- Eltwise9
I1017 16:08:55.578840 22869 net.cpp:380] Eltwise9_penlu17_0_split -> Eltwise9_penlu17_0_split_0
I1017 16:08:55.578845 22869 net.cpp:380] Eltwise9_penlu17_0_split -> Eltwise9_penlu17_0_split_1
I1017 16:08:55.578876 22869 net.cpp:122] Setting up Eltwise9_penlu17_0_split
I1017 16:08:55.578881 22869 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1017 16:08:55.578886 22869 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1017 16:08:55.578887 22869 net.cpp:137] Memory required for data: 1671331800
I1017 16:08:55.578891 22869 layer_factory.hpp:77] Creating layer Convolution23
I1017 16:08:55.578896 22869 net.cpp:84] Creating Layer Convolution23
I1017 16:08:55.578899 22869 net.cpp:406] Convolution23 <- Eltwise9_penlu17_0_split_0
I1017 16:08:55.578903 22869 net.cpp:380] Convolution23 -> Convolution23
I1017 16:08:55.676574 22869 net.cpp:122] Setting up Convolution23
I1017 16:08:55.676597 22869 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1017 16:08:55.676601 22869 net.cpp:137] Memory required for data: 1677603800
I1017 16:08:55.676609 22869 layer_factory.hpp:77] Creating layer BatchNorm18
I1017 16:08:55.676628 22869 net.cpp:84] Creating Layer BatchNorm18
I1017 16:08:55.676647 22869 net.cpp:406] BatchNorm18 <- Convolution23
I1017 16:08:55.676654 22869 net.cpp:367] BatchNorm18 -> Convolution23 (in-place)
I1017 16:08:55.676869 22869 net.cpp:122] Setting up BatchNorm18
I1017 16:08:55.676877 22869 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1017 16:08:55.676879 22869 net.cpp:137] Memory required for data: 1683875800
I1017 16:08:55.676884 22869 layer_factory.hpp:77] Creating layer Scale18
I1017 16:08:55.676890 22869 net.cpp:84] Creating Layer Scale18
I1017 16:08:55.676893 22869 net.cpp:406] Scale18 <- Convolution23
I1017 16:08:55.676898 22869 net.cpp:367] Scale18 -> Convolution23 (in-place)
I1017 16:08:55.676956 22869 layer_factory.hpp:77] Creating layer Scale18
I1017 16:08:55.677078 22869 net.cpp:122] Setting up Scale18
I1017 16:08:55.677084 22869 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1017 16:08:55.677086 22869 net.cpp:137] Memory required for data: 1690147800
I1017 16:08:55.677090 22869 layer_factory.hpp:77] Creating layer penlu18
I1017 16:08:55.677098 22869 net.cpp:84] Creating Layer penlu18
I1017 16:08:55.677100 22869 net.cpp:406] penlu18 <- Convolution23
I1017 16:08:55.677104 22869 net.cpp:367] penlu18 -> Convolution23 (in-place)
I1017 16:08:55.677273 22869 net.cpp:122] Setting up penlu18
I1017 16:08:55.677279 22869 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1017 16:08:55.677283 22869 net.cpp:137] Memory required for data: 1696419800
I1017 16:08:55.677287 22869 layer_factory.hpp:77] Creating layer Convolution24
I1017 16:08:55.677294 22869 net.cpp:84] Creating Layer Convolution24
I1017 16:08:55.677297 22869 net.cpp:406] Convolution24 <- Convolution23
I1017 16:08:55.677301 22869 net.cpp:380] Convolution24 -> Convolution24
I1017 16:08:55.774423 22869 net.cpp:122] Setting up Convolution24
I1017 16:08:55.774446 22869 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1017 16:08:55.774449 22869 net.cpp:137] Memory required for data: 1702691800
I1017 16:08:55.774456 22869 layer_factory.hpp:77] Creating layer Eltwise10
I1017 16:08:55.774467 22869 net.cpp:84] Creating Layer Eltwise10
I1017 16:08:55.774472 22869 net.cpp:406] Eltwise10 <- Convolution24
I1017 16:08:55.774488 22869 net.cpp:406] Eltwise10 <- Eltwise9_penlu17_0_split_1
I1017 16:08:55.774493 22869 net.cpp:380] Eltwise10 -> Eltwise10
I1017 16:08:55.774529 22869 net.cpp:122] Setting up Eltwise10
I1017 16:08:55.774535 22869 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1017 16:08:55.774547 22869 net.cpp:137] Memory required for data: 1708963800
I1017 16:08:55.774549 22869 layer_factory.hpp:77] Creating layer BatchNorm19
I1017 16:08:55.774565 22869 net.cpp:84] Creating Layer BatchNorm19
I1017 16:08:55.774569 22869 net.cpp:406] BatchNorm19 <- Eltwise10
I1017 16:08:55.774574 22869 net.cpp:367] BatchNorm19 -> Eltwise10 (in-place)
I1017 16:08:55.774773 22869 net.cpp:122] Setting up BatchNorm19
I1017 16:08:55.774780 22869 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1017 16:08:55.774781 22869 net.cpp:137] Memory required for data: 1715235800
I1017 16:08:55.774797 22869 layer_factory.hpp:77] Creating layer Scale19
I1017 16:08:55.774804 22869 net.cpp:84] Creating Layer Scale19
I1017 16:08:55.774808 22869 net.cpp:406] Scale19 <- Eltwise10
I1017 16:08:55.774811 22869 net.cpp:367] Scale19 -> Eltwise10 (in-place)
I1017 16:08:55.774859 22869 layer_factory.hpp:77] Creating layer Scale19
I1017 16:08:55.774982 22869 net.cpp:122] Setting up Scale19
I1017 16:08:55.774988 22869 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1017 16:08:55.774991 22869 net.cpp:137] Memory required for data: 1721507800
I1017 16:08:55.775004 22869 layer_factory.hpp:77] Creating layer penlu19
I1017 16:08:55.775014 22869 net.cpp:84] Creating Layer penlu19
I1017 16:08:55.775017 22869 net.cpp:406] penlu19 <- Eltwise10
I1017 16:08:55.775022 22869 net.cpp:367] penlu19 -> Eltwise10 (in-place)
I1017 16:08:55.775184 22869 net.cpp:122] Setting up penlu19
I1017 16:08:55.775190 22869 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1017 16:08:55.775193 22869 net.cpp:137] Memory required for data: 1727779800
I1017 16:08:55.775208 22869 layer_factory.hpp:77] Creating layer Eltwise10_penlu19_0_split
I1017 16:08:55.775225 22869 net.cpp:84] Creating Layer Eltwise10_penlu19_0_split
I1017 16:08:55.775229 22869 net.cpp:406] Eltwise10_penlu19_0_split <- Eltwise10
I1017 16:08:55.775233 22869 net.cpp:380] Eltwise10_penlu19_0_split -> Eltwise10_penlu19_0_split_0
I1017 16:08:55.775238 22869 net.cpp:380] Eltwise10_penlu19_0_split -> Eltwise10_penlu19_0_split_1
I1017 16:08:55.775281 22869 net.cpp:122] Setting up Eltwise10_penlu19_0_split
I1017 16:08:55.775286 22869 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1017 16:08:55.775290 22869 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1017 16:08:55.775302 22869 net.cpp:137] Memory required for data: 1740323800
I1017 16:08:55.775305 22869 layer_factory.hpp:77] Creating layer Convolution25
I1017 16:08:55.775311 22869 net.cpp:84] Creating Layer Convolution25
I1017 16:08:55.775315 22869 net.cpp:406] Convolution25 <- Eltwise10_penlu19_0_split_0
I1017 16:08:55.775318 22869 net.cpp:380] Convolution25 -> Convolution25
I1017 16:08:55.872472 22869 net.cpp:122] Setting up Convolution25
I1017 16:08:55.872498 22869 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1017 16:08:55.872500 22869 net.cpp:137] Memory required for data: 1746595800
I1017 16:08:55.872508 22869 layer_factory.hpp:77] Creating layer BatchNorm20
I1017 16:08:55.872517 22869 net.cpp:84] Creating Layer BatchNorm20
I1017 16:08:55.872522 22869 net.cpp:406] BatchNorm20 <- Convolution25
I1017 16:08:55.872539 22869 net.cpp:367] BatchNorm20 -> Convolution25 (in-place)
I1017 16:08:55.872750 22869 net.cpp:122] Setting up BatchNorm20
I1017 16:08:55.872757 22869 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1017 16:08:55.872759 22869 net.cpp:137] Memory required for data: 1752867800
I1017 16:08:55.872766 22869 layer_factory.hpp:77] Creating layer Scale20
I1017 16:08:55.872771 22869 net.cpp:84] Creating Layer Scale20
I1017 16:08:55.872774 22869 net.cpp:406] Scale20 <- Convolution25
I1017 16:08:55.872777 22869 net.cpp:367] Scale20 -> Convolution25 (in-place)
I1017 16:08:55.872839 22869 layer_factory.hpp:77] Creating layer Scale20
I1017 16:08:55.872967 22869 net.cpp:122] Setting up Scale20
I1017 16:08:55.872972 22869 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1017 16:08:55.872973 22869 net.cpp:137] Memory required for data: 1759139800
I1017 16:08:55.872978 22869 layer_factory.hpp:77] Creating layer penlu20
I1017 16:08:55.872984 22869 net.cpp:84] Creating Layer penlu20
I1017 16:08:55.872987 22869 net.cpp:406] penlu20 <- Convolution25
I1017 16:08:55.872990 22869 net.cpp:367] penlu20 -> Convolution25 (in-place)
I1017 16:08:55.873167 22869 net.cpp:122] Setting up penlu20
I1017 16:08:55.873172 22869 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1017 16:08:55.873174 22869 net.cpp:137] Memory required for data: 1765411800
I1017 16:08:55.873179 22869 layer_factory.hpp:77] Creating layer Convolution26
I1017 16:08:55.873186 22869 net.cpp:84] Creating Layer Convolution26
I1017 16:08:55.873189 22869 net.cpp:406] Convolution26 <- Convolution25
I1017 16:08:55.873204 22869 net.cpp:380] Convolution26 -> Convolution26
I1017 16:08:55.970804 22869 net.cpp:122] Setting up Convolution26
I1017 16:08:55.970827 22869 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1017 16:08:55.970831 22869 net.cpp:137] Memory required for data: 1771683800
I1017 16:08:55.970839 22869 layer_factory.hpp:77] Creating layer Eltwise11
I1017 16:08:55.970849 22869 net.cpp:84] Creating Layer Eltwise11
I1017 16:08:55.970865 22869 net.cpp:406] Eltwise11 <- Convolution26
I1017 16:08:55.970870 22869 net.cpp:406] Eltwise11 <- Eltwise10_penlu19_0_split_1
I1017 16:08:55.970875 22869 net.cpp:380] Eltwise11 -> Eltwise11
I1017 16:08:55.970922 22869 net.cpp:122] Setting up Eltwise11
I1017 16:08:55.970928 22869 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1017 16:08:55.970930 22869 net.cpp:137] Memory required for data: 1777955800
I1017 16:08:55.970932 22869 layer_factory.hpp:77] Creating layer BatchNorm21
I1017 16:08:55.970938 22869 net.cpp:84] Creating Layer BatchNorm21
I1017 16:08:55.970942 22869 net.cpp:406] BatchNorm21 <- Eltwise11
I1017 16:08:55.970944 22869 net.cpp:367] BatchNorm21 -> Eltwise11 (in-place)
I1017 16:08:55.971173 22869 net.cpp:122] Setting up BatchNorm21
I1017 16:08:55.971179 22869 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1017 16:08:55.971181 22869 net.cpp:137] Memory required for data: 1784227800
I1017 16:08:55.971196 22869 layer_factory.hpp:77] Creating layer Scale21
I1017 16:08:55.971204 22869 net.cpp:84] Creating Layer Scale21
I1017 16:08:55.971207 22869 net.cpp:406] Scale21 <- Eltwise11
I1017 16:08:55.971211 22869 net.cpp:367] Scale21 -> Eltwise11 (in-place)
I1017 16:08:55.971261 22869 layer_factory.hpp:77] Creating layer Scale21
I1017 16:08:55.971386 22869 net.cpp:122] Setting up Scale21
I1017 16:08:55.971392 22869 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1017 16:08:55.971395 22869 net.cpp:137] Memory required for data: 1790499800
I1017 16:08:55.971408 22869 layer_factory.hpp:77] Creating layer penlu21
I1017 16:08:55.971416 22869 net.cpp:84] Creating Layer penlu21
I1017 16:08:55.971420 22869 net.cpp:406] penlu21 <- Eltwise11
I1017 16:08:55.971423 22869 net.cpp:367] penlu21 -> Eltwise11 (in-place)
I1017 16:08:55.971596 22869 net.cpp:122] Setting up penlu21
I1017 16:08:55.971601 22869 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1017 16:08:55.971603 22869 net.cpp:137] Memory required for data: 1796771800
I1017 16:08:55.971618 22869 layer_factory.hpp:77] Creating layer Eltwise11_penlu21_0_split
I1017 16:08:55.971623 22869 net.cpp:84] Creating Layer Eltwise11_penlu21_0_split
I1017 16:08:55.971627 22869 net.cpp:406] Eltwise11_penlu21_0_split <- Eltwise11
I1017 16:08:55.971631 22869 net.cpp:380] Eltwise11_penlu21_0_split -> Eltwise11_penlu21_0_split_0
I1017 16:08:55.971645 22869 net.cpp:380] Eltwise11_penlu21_0_split -> Eltwise11_penlu21_0_split_1
I1017 16:08:55.971705 22869 net.cpp:122] Setting up Eltwise11_penlu21_0_split
I1017 16:08:55.971710 22869 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1017 16:08:55.971724 22869 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1017 16:08:55.971727 22869 net.cpp:137] Memory required for data: 1809315800
I1017 16:08:55.971729 22869 layer_factory.hpp:77] Creating layer Convolution27
I1017 16:08:55.971747 22869 net.cpp:84] Creating Layer Convolution27
I1017 16:08:55.971751 22869 net.cpp:406] Convolution27 <- Eltwise11_penlu21_0_split_0
I1017 16:08:55.971755 22869 net.cpp:380] Convolution27 -> Convolution27
I1017 16:08:56.069460 22869 net.cpp:122] Setting up Convolution27
I1017 16:08:56.069483 22869 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1017 16:08:56.069486 22869 net.cpp:137] Memory required for data: 1815587800
I1017 16:08:56.069494 22869 layer_factory.hpp:77] Creating layer BatchNorm22
I1017 16:08:56.069515 22869 net.cpp:84] Creating Layer BatchNorm22
I1017 16:08:56.069521 22869 net.cpp:406] BatchNorm22 <- Convolution27
I1017 16:08:56.069537 22869 net.cpp:367] BatchNorm22 -> Convolution27 (in-place)
I1017 16:08:56.069767 22869 net.cpp:122] Setting up BatchNorm22
I1017 16:08:56.069773 22869 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1017 16:08:56.069777 22869 net.cpp:137] Memory required for data: 1821859800
I1017 16:08:56.069782 22869 layer_factory.hpp:77] Creating layer Scale22
I1017 16:08:56.069787 22869 net.cpp:84] Creating Layer Scale22
I1017 16:08:56.069790 22869 net.cpp:406] Scale22 <- Convolution27
I1017 16:08:56.069794 22869 net.cpp:367] Scale22 -> Convolution27 (in-place)
I1017 16:08:56.069854 22869 layer_factory.hpp:77] Creating layer Scale22
I1017 16:08:56.070008 22869 net.cpp:122] Setting up Scale22
I1017 16:08:56.070013 22869 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1017 16:08:56.070015 22869 net.cpp:137] Memory required for data: 1828131800
I1017 16:08:56.070020 22869 layer_factory.hpp:77] Creating layer penlu22
I1017 16:08:56.070027 22869 net.cpp:84] Creating Layer penlu22
I1017 16:08:56.070030 22869 net.cpp:406] penlu22 <- Convolution27
I1017 16:08:56.070034 22869 net.cpp:367] penlu22 -> Convolution27 (in-place)
I1017 16:08:56.070214 22869 net.cpp:122] Setting up penlu22
I1017 16:08:56.070219 22869 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1017 16:08:56.070221 22869 net.cpp:137] Memory required for data: 1834403800
I1017 16:08:56.070237 22869 layer_factory.hpp:77] Creating layer Convolution28
I1017 16:08:56.070258 22869 net.cpp:84] Creating Layer Convolution28
I1017 16:08:56.070262 22869 net.cpp:406] Convolution28 <- Convolution27
I1017 16:08:56.070267 22869 net.cpp:380] Convolution28 -> Convolution28
I1017 16:08:56.168159 22869 net.cpp:122] Setting up Convolution28
I1017 16:08:56.168182 22869 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1017 16:08:56.168186 22869 net.cpp:137] Memory required for data: 1840675800
I1017 16:08:56.168193 22869 layer_factory.hpp:77] Creating layer Eltwise12
I1017 16:08:56.168215 22869 net.cpp:84] Creating Layer Eltwise12
I1017 16:08:56.168220 22869 net.cpp:406] Eltwise12 <- Convolution28
I1017 16:08:56.168227 22869 net.cpp:406] Eltwise12 <- Eltwise11_penlu21_0_split_1
I1017 16:08:56.168232 22869 net.cpp:380] Eltwise12 -> Eltwise12
I1017 16:08:56.168282 22869 net.cpp:122] Setting up Eltwise12
I1017 16:08:56.168288 22869 net.cpp:129] Top shape: 50 640 7 7 (1568000)
I1017 16:08:56.168292 22869 net.cpp:137] Memory required for data: 1846947800
I1017 16:08:56.168293 22869 layer_factory.hpp:77] Creating layer Pooling1
I1017 16:08:56.168298 22869 net.cpp:84] Creating Layer Pooling1
I1017 16:08:56.168301 22869 net.cpp:406] Pooling1 <- Eltwise12
I1017 16:08:56.168305 22869 net.cpp:380] Pooling1 -> Pooling1
I1017 16:08:56.168484 22869 net.cpp:122] Setting up Pooling1
I1017 16:08:56.168493 22869 net.cpp:129] Top shape: 50 640 1 1 (32000)
I1017 16:08:56.168495 22869 net.cpp:137] Memory required for data: 1847075800
I1017 16:08:56.168509 22869 layer_factory.hpp:77] Creating layer InnerProduct1
I1017 16:08:56.168514 22869 net.cpp:84] Creating Layer InnerProduct1
I1017 16:08:56.168517 22869 net.cpp:406] InnerProduct1 <- Pooling1
I1017 16:08:56.168521 22869 net.cpp:380] InnerProduct1 -> InnerProduct1
I1017 16:08:56.169332 22869 net.cpp:122] Setting up InnerProduct1
I1017 16:08:56.169342 22869 net.cpp:129] Top shape: 50 100 (5000)
I1017 16:08:56.169354 22869 net.cpp:137] Memory required for data: 1847095800
I1017 16:08:56.169360 22869 layer_factory.hpp:77] Creating layer InnerProduct1_InnerProduct1_0_split
I1017 16:08:56.169381 22869 net.cpp:84] Creating Layer InnerProduct1_InnerProduct1_0_split
I1017 16:08:56.169385 22869 net.cpp:406] InnerProduct1_InnerProduct1_0_split <- InnerProduct1
I1017 16:08:56.169397 22869 net.cpp:380] InnerProduct1_InnerProduct1_0_split -> InnerProduct1_InnerProduct1_0_split_0
I1017 16:08:56.169404 22869 net.cpp:380] InnerProduct1_InnerProduct1_0_split -> InnerProduct1_InnerProduct1_0_split_1
I1017 16:08:56.169488 22869 net.cpp:122] Setting up InnerProduct1_InnerProduct1_0_split
I1017 16:08:56.169493 22869 net.cpp:129] Top shape: 50 100 (5000)
I1017 16:08:56.169497 22869 net.cpp:129] Top shape: 50 100 (5000)
I1017 16:08:56.169510 22869 net.cpp:137] Memory required for data: 1847135800
I1017 16:08:56.169513 22869 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I1017 16:08:56.169528 22869 net.cpp:84] Creating Layer SoftmaxWithLoss1
I1017 16:08:56.169530 22869 net.cpp:406] SoftmaxWithLoss1 <- InnerProduct1_InnerProduct1_0_split_0
I1017 16:08:56.169533 22869 net.cpp:406] SoftmaxWithLoss1 <- label_cifar_1_split_0
I1017 16:08:56.169548 22869 net.cpp:380] SoftmaxWithLoss1 -> SoftmaxWithLoss1
I1017 16:08:56.169554 22869 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I1017 16:08:56.170253 22869 net.cpp:122] Setting up SoftmaxWithLoss1
I1017 16:08:56.170262 22869 net.cpp:129] Top shape: (1)
I1017 16:08:56.170265 22869 net.cpp:132]     with loss weight 1
I1017 16:08:56.170284 22869 net.cpp:137] Memory required for data: 1847135804
I1017 16:08:56.170302 22869 layer_factory.hpp:77] Creating layer accuracy
I1017 16:08:56.170313 22869 net.cpp:84] Creating Layer accuracy
I1017 16:08:56.170317 22869 net.cpp:406] accuracy <- InnerProduct1_InnerProduct1_0_split_1
I1017 16:08:56.170320 22869 net.cpp:406] accuracy <- label_cifar_1_split_1
I1017 16:08:56.170325 22869 net.cpp:380] accuracy -> accuracy
I1017 16:08:56.170333 22869 net.cpp:122] Setting up accuracy
I1017 16:08:56.170358 22869 net.cpp:129] Top shape: (1)
I1017 16:08:56.170361 22869 net.cpp:137] Memory required for data: 1847135808
I1017 16:08:56.170363 22869 net.cpp:200] accuracy does not need backward computation.
I1017 16:08:56.170375 22869 net.cpp:198] SoftmaxWithLoss1 needs backward computation.
I1017 16:08:56.170377 22869 net.cpp:198] InnerProduct1_InnerProduct1_0_split needs backward computation.
I1017 16:08:56.170380 22869 net.cpp:198] InnerProduct1 needs backward computation.
I1017 16:08:56.170393 22869 net.cpp:198] Pooling1 needs backward computation.
I1017 16:08:56.170395 22869 net.cpp:198] Eltwise12 needs backward computation.
I1017 16:08:56.170398 22869 net.cpp:198] Convolution28 needs backward computation.
I1017 16:08:56.170402 22869 net.cpp:198] penlu22 needs backward computation.
I1017 16:08:56.170403 22869 net.cpp:198] Scale22 needs backward computation.
I1017 16:08:56.170405 22869 net.cpp:198] BatchNorm22 needs backward computation.
I1017 16:08:56.170408 22869 net.cpp:198] Convolution27 needs backward computation.
I1017 16:08:56.170410 22869 net.cpp:198] Eltwise11_penlu21_0_split needs backward computation.
I1017 16:08:56.170413 22869 net.cpp:198] penlu21 needs backward computation.
I1017 16:08:56.170415 22869 net.cpp:198] Scale21 needs backward computation.
I1017 16:08:56.170418 22869 net.cpp:198] BatchNorm21 needs backward computation.
I1017 16:08:56.170419 22869 net.cpp:198] Eltwise11 needs backward computation.
I1017 16:08:56.170423 22869 net.cpp:198] Convolution26 needs backward computation.
I1017 16:08:56.170424 22869 net.cpp:198] penlu20 needs backward computation.
I1017 16:08:56.170428 22869 net.cpp:198] Scale20 needs backward computation.
I1017 16:08:56.170429 22869 net.cpp:198] BatchNorm20 needs backward computation.
I1017 16:08:56.170440 22869 net.cpp:198] Convolution25 needs backward computation.
I1017 16:08:56.170442 22869 net.cpp:198] Eltwise10_penlu19_0_split needs backward computation.
I1017 16:08:56.170445 22869 net.cpp:198] penlu19 needs backward computation.
I1017 16:08:56.170447 22869 net.cpp:198] Scale19 needs backward computation.
I1017 16:08:56.170449 22869 net.cpp:198] BatchNorm19 needs backward computation.
I1017 16:08:56.170451 22869 net.cpp:198] Eltwise10 needs backward computation.
I1017 16:08:56.170454 22869 net.cpp:198] Convolution24 needs backward computation.
I1017 16:08:56.170456 22869 net.cpp:198] penlu18 needs backward computation.
I1017 16:08:56.170459 22869 net.cpp:198] Scale18 needs backward computation.
I1017 16:08:56.170461 22869 net.cpp:198] BatchNorm18 needs backward computation.
I1017 16:08:56.170464 22869 net.cpp:198] Convolution23 needs backward computation.
I1017 16:08:56.170465 22869 net.cpp:198] Eltwise9_penlu17_0_split needs backward computation.
I1017 16:08:56.170469 22869 net.cpp:198] penlu17 needs backward computation.
I1017 16:08:56.170470 22869 net.cpp:198] Scale17 needs backward computation.
I1017 16:08:56.170472 22869 net.cpp:198] BatchNorm17 needs backward computation.
I1017 16:08:56.170475 22869 net.cpp:198] Eltwise9 needs backward computation.
I1017 16:08:56.170477 22869 net.cpp:198] Convolution22 needs backward computation.
I1017 16:08:56.170480 22869 net.cpp:198] Convolution21 needs backward computation.
I1017 16:08:56.170482 22869 net.cpp:198] penlu16 needs backward computation.
I1017 16:08:56.170485 22869 net.cpp:198] Scale16 needs backward computation.
I1017 16:08:56.170487 22869 net.cpp:198] BatchNorm16 needs backward computation.
I1017 16:08:56.170490 22869 net.cpp:198] Convolution20 needs backward computation.
I1017 16:08:56.170491 22869 net.cpp:198] Eltwise8_Eltwise8_0_split needs backward computation.
I1017 16:08:56.170495 22869 net.cpp:198] Eltwise8 needs backward computation.
I1017 16:08:56.170497 22869 net.cpp:198] Convolution19 needs backward computation.
I1017 16:08:56.170500 22869 net.cpp:198] penlu15 needs backward computation.
I1017 16:08:56.170501 22869 net.cpp:198] Scale15 needs backward computation.
I1017 16:08:56.170505 22869 net.cpp:198] BatchNorm15 needs backward computation.
I1017 16:08:56.170506 22869 net.cpp:198] Convolution18 needs backward computation.
I1017 16:08:56.170512 22869 net.cpp:198] Eltwise7_penlu14_0_split needs backward computation.
I1017 16:08:56.170516 22869 net.cpp:198] penlu14 needs backward computation.
I1017 16:08:56.170517 22869 net.cpp:198] Scale14 needs backward computation.
I1017 16:08:56.170519 22869 net.cpp:198] BatchNorm14 needs backward computation.
I1017 16:08:56.170522 22869 net.cpp:198] Eltwise7 needs backward computation.
I1017 16:08:56.170524 22869 net.cpp:198] Convolution17 needs backward computation.
I1017 16:08:56.170528 22869 net.cpp:198] penlu13 needs backward computation.
I1017 16:08:56.170531 22869 net.cpp:198] Scale13 needs backward computation.
I1017 16:08:56.170534 22869 net.cpp:198] BatchNorm13 needs backward computation.
I1017 16:08:56.170536 22869 net.cpp:198] Convolution16 needs backward computation.
I1017 16:08:56.170538 22869 net.cpp:198] Eltwise6_penlu12_0_split needs backward computation.
I1017 16:08:56.170542 22869 net.cpp:198] penlu12 needs backward computation.
I1017 16:08:56.170543 22869 net.cpp:198] Scale12 needs backward computation.
I1017 16:08:56.170547 22869 net.cpp:198] BatchNorm12 needs backward computation.
I1017 16:08:56.170548 22869 net.cpp:198] Eltwise6 needs backward computation.
I1017 16:08:56.170550 22869 net.cpp:198] Convolution15 needs backward computation.
I1017 16:08:56.170553 22869 net.cpp:198] penlu11 needs backward computation.
I1017 16:08:56.170555 22869 net.cpp:198] Scale11 needs backward computation.
I1017 16:08:56.170558 22869 net.cpp:198] BatchNorm11 needs backward computation.
I1017 16:08:56.170560 22869 net.cpp:198] Convolution14 needs backward computation.
I1017 16:08:56.170562 22869 net.cpp:198] Eltwise5_penlu10_0_split needs backward computation.
I1017 16:08:56.170565 22869 net.cpp:198] penlu10 needs backward computation.
I1017 16:08:56.170567 22869 net.cpp:198] Scale10 needs backward computation.
I1017 16:08:56.170570 22869 net.cpp:198] BatchNorm10 needs backward computation.
I1017 16:08:56.170572 22869 net.cpp:198] Eltwise5 needs backward computation.
I1017 16:08:56.170575 22869 net.cpp:198] Convolution13 needs backward computation.
I1017 16:08:56.170578 22869 net.cpp:198] Convolution12 needs backward computation.
I1017 16:08:56.170580 22869 net.cpp:198] penlu9 needs backward computation.
I1017 16:08:56.170583 22869 net.cpp:198] Scale9 needs backward computation.
I1017 16:08:56.170584 22869 net.cpp:198] BatchNorm9 needs backward computation.
I1017 16:08:56.170586 22869 net.cpp:198] Convolution11 needs backward computation.
I1017 16:08:56.170589 22869 net.cpp:198] Eltwise4_Eltwise4_0_split needs backward computation.
I1017 16:08:56.170591 22869 net.cpp:198] Eltwise4 needs backward computation.
I1017 16:08:56.170594 22869 net.cpp:198] Convolution10 needs backward computation.
I1017 16:08:56.170598 22869 net.cpp:198] penlu8 needs backward computation.
I1017 16:08:56.170599 22869 net.cpp:198] Scale8 needs backward computation.
I1017 16:08:56.170603 22869 net.cpp:198] BatchNorm8 needs backward computation.
I1017 16:08:56.170604 22869 net.cpp:198] Convolution9 needs backward computation.
I1017 16:08:56.170606 22869 net.cpp:198] Eltwise3_penlu7_0_split needs backward computation.
I1017 16:08:56.170609 22869 net.cpp:198] penlu7 needs backward computation.
I1017 16:08:56.170611 22869 net.cpp:198] Scale7 needs backward computation.
I1017 16:08:56.170614 22869 net.cpp:198] BatchNorm7 needs backward computation.
I1017 16:08:56.170615 22869 net.cpp:198] Eltwise3 needs backward computation.
I1017 16:08:56.170619 22869 net.cpp:198] Convolution8 needs backward computation.
I1017 16:08:56.170621 22869 net.cpp:198] penlu6 needs backward computation.
I1017 16:08:56.170624 22869 net.cpp:198] Scale6 needs backward computation.
I1017 16:08:56.170625 22869 net.cpp:198] BatchNorm6 needs backward computation.
I1017 16:08:56.170627 22869 net.cpp:198] Convolution7 needs backward computation.
I1017 16:08:56.170630 22869 net.cpp:198] Eltwise2_penlu5_0_split needs backward computation.
I1017 16:08:56.170632 22869 net.cpp:198] penlu5 needs backward computation.
I1017 16:08:56.170634 22869 net.cpp:198] Scale5 needs backward computation.
I1017 16:08:56.170640 22869 net.cpp:198] BatchNorm5 needs backward computation.
I1017 16:08:56.170642 22869 net.cpp:198] Eltwise2 needs backward computation.
I1017 16:08:56.170645 22869 net.cpp:198] Convolution6 needs backward computation.
I1017 16:08:56.170647 22869 net.cpp:198] penlu4 needs backward computation.
I1017 16:08:56.170650 22869 net.cpp:198] Scale4 needs backward computation.
I1017 16:08:56.170652 22869 net.cpp:198] BatchNorm4 needs backward computation.
I1017 16:08:56.170655 22869 net.cpp:198] Convolution5 needs backward computation.
I1017 16:08:56.170656 22869 net.cpp:198] Eltwise1_penlu3_0_split needs backward computation.
I1017 16:08:56.170660 22869 net.cpp:198] penlu3 needs backward computation.
I1017 16:08:56.170661 22869 net.cpp:198] Scale3 needs backward computation.
I1017 16:08:56.170663 22869 net.cpp:198] BatchNorm3 needs backward computation.
I1017 16:08:56.170666 22869 net.cpp:198] Eltwise1 needs backward computation.
I1017 16:08:56.170670 22869 net.cpp:198] Convolution4 needs backward computation.
I1017 16:08:56.170671 22869 net.cpp:198] Convolution3 needs backward computation.
I1017 16:08:56.170673 22869 net.cpp:198] penlu2 needs backward computation.
I1017 16:08:56.170676 22869 net.cpp:198] Scale2 needs backward computation.
I1017 16:08:56.170678 22869 net.cpp:198] BatchNorm2 needs backward computation.
I1017 16:08:56.170680 22869 net.cpp:198] Convolution2 needs backward computation.
I1017 16:08:56.170683 22869 net.cpp:198] Convolution1_penlu1_0_split needs backward computation.
I1017 16:08:56.170686 22869 net.cpp:198] penlu1 needs backward computation.
I1017 16:08:56.170687 22869 net.cpp:198] Scale1 needs backward computation.
I1017 16:08:56.170691 22869 net.cpp:198] BatchNorm1 needs backward computation.
I1017 16:08:56.170692 22869 net.cpp:198] Convolution1 needs backward computation.
I1017 16:08:56.170696 22869 net.cpp:200] label_cifar_1_split does not need backward computation.
I1017 16:08:56.170698 22869 net.cpp:200] cifar does not need backward computation.
I1017 16:08:56.170701 22869 net.cpp:242] This network produces output SoftmaxWithLoss1
I1017 16:08:56.170703 22869 net.cpp:242] This network produces output accuracy
I1017 16:08:56.170750 22869 net.cpp:255] Network initialization done.
I1017 16:08:56.171114 22869 solver.cpp:56] Solver scaffolding done.
I1017 16:08:56.177451 22869 caffe.cpp:248] Starting Optimization
I1017 16:08:56.177459 22869 solver.cpp:272] Solving wrn_28_10
I1017 16:08:56.177460 22869 solver.cpp:273] Learning Rate Policy: multistep
I1017 16:08:56.534075 22869 solver.cpp:218] Iteration 0 (-3.11362e-39 iter/s, 0.35659s/100 iters), loss = 4.60517
I1017 16:08:56.534107 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 4.60517 (* 1 = 4.60517 loss)
I1017 16:08:56.534117 22869 sgd_solver.cpp:105] Iteration 0, lr = 0.01
I1017 16:09:25.140251 22869 solver.cpp:218] Iteration 100 (3.49578 iter/s, 28.6059s/100 iters), loss = 3.9203
I1017 16:09:25.140324 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 3.9203 (* 1 = 3.9203 loss)
I1017 16:09:25.140341 22869 sgd_solver.cpp:105] Iteration 100, lr = 0.01
I1017 16:09:53.927618 22869 solver.cpp:218] Iteration 200 (3.47378 iter/s, 28.787s/100 iters), loss = 3.74907
I1017 16:09:53.927649 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 3.74907 (* 1 = 3.74907 loss)
I1017 16:09:53.927655 22869 sgd_solver.cpp:105] Iteration 200, lr = 0.01
I1017 16:10:22.695233 22869 solver.cpp:218] Iteration 300 (3.47616 iter/s, 28.7674s/100 iters), loss = 3.79617
I1017 16:10:22.695370 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 3.79617 (* 1 = 3.79617 loss)
I1017 16:10:22.695379 22869 sgd_solver.cpp:105] Iteration 300, lr = 0.01
I1017 16:10:51.552575 22869 solver.cpp:218] Iteration 400 (3.46536 iter/s, 28.857s/100 iters), loss = 3.50952
I1017 16:10:51.552606 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 3.50952 (* 1 = 3.50952 loss)
I1017 16:10:51.552613 22869 sgd_solver.cpp:105] Iteration 400, lr = 0.01
I1017 16:11:20.095741 22869 solver.cpp:330] Iteration 500, Testing net (#0)
I1017 16:11:35.904065 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 16:11:36.226670 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 3.30348 (* 1 = 3.30348 loss)
I1017 16:11:36.226686 22869 solver.cpp:397]     Test net output #1: accuracy = 0.1891
I1017 16:11:36.509383 22869 solver.cpp:218] Iteration 500 (2.22437 iter/s, 44.9566s/100 iters), loss = 3.28884
I1017 16:11:36.509418 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 3.28884 (* 1 = 3.28884 loss)
I1017 16:11:36.509425 22869 sgd_solver.cpp:105] Iteration 500, lr = 0.01
I1017 16:12:05.319252 22869 solver.cpp:218] Iteration 600 (3.47105 iter/s, 28.8097s/100 iters), loss = 3.24105
I1017 16:12:05.319368 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 3.24105 (* 1 = 3.24105 loss)
I1017 16:12:05.319386 22869 sgd_solver.cpp:105] Iteration 600, lr = 0.01
I1017 16:12:34.166437 22869 solver.cpp:218] Iteration 700 (3.46657 iter/s, 28.847s/100 iters), loss = 2.98202
I1017 16:12:34.166466 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 2.98202 (* 1 = 2.98202 loss)
I1017 16:12:34.166471 22869 sgd_solver.cpp:105] Iteration 700, lr = 0.01
I1017 16:13:03.215356 22869 solver.cpp:218] Iteration 800 (3.44249 iter/s, 29.0488s/100 iters), loss = 2.55034
I1017 16:13:03.215467 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 2.55034 (* 1 = 2.55034 loss)
I1017 16:13:03.215484 22869 sgd_solver.cpp:105] Iteration 800, lr = 0.01
I1017 16:13:32.402889 22869 solver.cpp:218] Iteration 900 (3.42614 iter/s, 29.1873s/100 iters), loss = 2.68154
I1017 16:13:32.402920 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 2.68154 (* 1 = 2.68154 loss)
I1017 16:13:32.402926 22869 sgd_solver.cpp:105] Iteration 900, lr = 0.01
I1017 16:14:00.207000 22877 data_layer.cpp:73] Restarting data prefetching from start.
I1017 16:14:01.376435 22869 solver.cpp:330] Iteration 1000, Testing net (#0)
I1017 16:14:17.325788 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 16:14:17.652695 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 2.7538 (* 1 = 2.7538 loss)
I1017 16:14:17.652710 22869 solver.cpp:397]     Test net output #1: accuracy = 0.2892
I1017 16:14:17.943472 22869 solver.cpp:218] Iteration 1000 (2.19585 iter/s, 45.5404s/100 iters), loss = 2.60865
I1017 16:14:17.943502 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 2.60865 (* 1 = 2.60865 loss)
I1017 16:14:17.943508 22869 sgd_solver.cpp:105] Iteration 1000, lr = 0.01
I1017 16:14:47.324041 22869 solver.cpp:218] Iteration 1100 (3.40362 iter/s, 29.3805s/100 iters), loss = 2.69125
I1017 16:14:47.324174 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 2.69125 (* 1 = 2.69125 loss)
I1017 16:14:47.324182 22869 sgd_solver.cpp:105] Iteration 1100, lr = 0.01
I1017 16:15:16.807212 22869 solver.cpp:218] Iteration 1200 (3.39179 iter/s, 29.483s/100 iters), loss = 2.6928
I1017 16:15:16.807255 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 2.6928 (* 1 = 2.6928 loss)
I1017 16:15:16.807260 22869 sgd_solver.cpp:105] Iteration 1200, lr = 0.01
I1017 16:15:46.322433 22869 solver.cpp:218] Iteration 1300 (3.38809 iter/s, 29.5151s/100 iters), loss = 2.66868
I1017 16:15:46.322530 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 2.66868 (* 1 = 2.66868 loss)
I1017 16:15:46.322536 22869 sgd_solver.cpp:105] Iteration 1300, lr = 0.01
I1017 16:16:15.865838 22869 solver.cpp:218] Iteration 1400 (3.38487 iter/s, 29.5432s/100 iters), loss = 2.33711
I1017 16:16:15.865870 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 2.33711 (* 1 = 2.33711 loss)
I1017 16:16:15.865876 22869 sgd_solver.cpp:105] Iteration 1400, lr = 0.01
I1017 16:16:45.199795 22869 solver.cpp:330] Iteration 1500, Testing net (#0)
I1017 16:17:01.326083 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 16:17:01.659080 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 2.48853 (* 1 = 2.48853 loss)
I1017 16:17:01.659096 22869 solver.cpp:397]     Test net output #1: accuracy = 0.3439
I1017 16:17:01.953289 22869 solver.cpp:218] Iteration 1500 (2.16979 iter/s, 46.0873s/100 iters), loss = 2.24431
I1017 16:17:01.953325 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 2.24431 (* 1 = 2.24431 loss)
I1017 16:17:01.953331 22869 sgd_solver.cpp:105] Iteration 1500, lr = 0.01
I1017 16:17:31.636945 22869 solver.cpp:218] Iteration 1600 (3.36887 iter/s, 29.6836s/100 iters), loss = 2.43977
I1017 16:17:31.637094 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 2.43977 (* 1 = 2.43977 loss)
I1017 16:17:31.637101 22869 sgd_solver.cpp:105] Iteration 1600, lr = 0.01
I1017 16:18:01.402526 22869 solver.cpp:218] Iteration 1700 (3.35961 iter/s, 29.7654s/100 iters), loss = 2.50201
I1017 16:18:01.402557 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 2.50201 (* 1 = 2.50201 loss)
I1017 16:18:01.402564 22869 sgd_solver.cpp:105] Iteration 1700, lr = 0.01
I1017 16:18:31.184082 22869 solver.cpp:218] Iteration 1800 (3.35779 iter/s, 29.7815s/100 iters), loss = 1.91012
I1017 16:18:31.184195 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.91012 (* 1 = 1.91012 loss)
I1017 16:18:31.184212 22869 sgd_solver.cpp:105] Iteration 1800, lr = 0.01
I1017 16:19:01.057106 22869 solver.cpp:218] Iteration 1900 (3.34752 iter/s, 29.8729s/100 iters), loss = 2.22611
I1017 16:19:01.057135 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 2.22611 (* 1 = 2.22611 loss)
I1017 16:19:01.057142 22869 sgd_solver.cpp:105] Iteration 1900, lr = 0.01
I1017 16:19:29.425554 22877 data_layer.cpp:73] Restarting data prefetching from start.
I1017 16:19:30.621567 22869 solver.cpp:330] Iteration 2000, Testing net (#0)
I1017 16:19:46.879220 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 16:19:47.210633 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 2.21979 (* 1 = 2.21979 loss)
I1017 16:19:47.210649 22869 solver.cpp:397]     Test net output #1: accuracy = 0.4056
I1017 16:19:47.504519 22869 solver.cpp:218] Iteration 2000 (2.15298 iter/s, 46.4473s/100 iters), loss = 1.84272
I1017 16:19:47.504550 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.84272 (* 1 = 1.84272 loss)
I1017 16:19:47.504557 22869 sgd_solver.cpp:105] Iteration 2000, lr = 0.01
I1017 16:20:17.410060 22869 solver.cpp:218] Iteration 2100 (3.34387 iter/s, 29.9055s/100 iters), loss = 2.2497
I1017 16:20:17.410151 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 2.2497 (* 1 = 2.2497 loss)
I1017 16:20:17.410168 22869 sgd_solver.cpp:105] Iteration 2100, lr = 0.01
I1017 16:20:47.391633 22869 solver.cpp:218] Iteration 2200 (3.3354 iter/s, 29.9815s/100 iters), loss = 2.06998
I1017 16:20:47.391664 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 2.06998 (* 1 = 2.06998 loss)
I1017 16:20:47.391669 22869 sgd_solver.cpp:105] Iteration 2200, lr = 0.01
I1017 16:21:17.321668 22869 solver.cpp:218] Iteration 2300 (3.34113 iter/s, 29.93s/100 iters), loss = 2.22226
I1017 16:21:17.321791 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 2.22226 (* 1 = 2.22226 loss)
I1017 16:21:17.321799 22869 sgd_solver.cpp:105] Iteration 2300, lr = 0.01
I1017 16:21:47.325312 22869 solver.cpp:218] Iteration 2400 (3.33294 iter/s, 30.0035s/100 iters), loss = 2.01502
I1017 16:21:47.325451 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 2.01502 (* 1 = 2.01502 loss)
I1017 16:21:47.325460 22869 sgd_solver.cpp:105] Iteration 2400, lr = 0.01
I1017 16:22:17.027439 22869 solver.cpp:330] Iteration 2500, Testing net (#0)
I1017 16:22:33.355522 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 16:22:33.690135 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 2.08581 (* 1 = 2.08581 loss)
I1017 16:22:33.690150 22869 solver.cpp:397]     Test net output #1: accuracy = 0.4345
I1017 16:22:33.985616 22869 solver.cpp:218] Iteration 2500 (2.14316 iter/s, 46.6601s/100 iters), loss = 1.84287
I1017 16:22:33.985647 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.84287 (* 1 = 1.84287 loss)
I1017 16:22:33.985653 22869 sgd_solver.cpp:105] Iteration 2500, lr = 0.01
I1017 16:23:04.030503 22869 solver.cpp:218] Iteration 2600 (3.32836 iter/s, 30.0448s/100 iters), loss = 2.05907
I1017 16:23:04.031298 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 2.05907 (* 1 = 2.05907 loss)
I1017 16:23:04.031306 22869 sgd_solver.cpp:105] Iteration 2600, lr = 0.01
I1017 16:23:34.026700 22869 solver.cpp:218] Iteration 2700 (3.33385 iter/s, 29.9954s/100 iters), loss = 2.0652
I1017 16:23:34.026731 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 2.0652 (* 1 = 2.0652 loss)
I1017 16:23:34.026737 22869 sgd_solver.cpp:105] Iteration 2700, lr = 0.01
I1017 16:24:04.063248 22869 solver.cpp:218] Iteration 2800 (3.32928 iter/s, 30.0365s/100 iters), loss = 1.67958
I1017 16:24:04.063350 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.67958 (* 1 = 1.67958 loss)
I1017 16:24:04.063357 22869 sgd_solver.cpp:105] Iteration 2800, lr = 0.01
I1017 16:24:34.144521 22869 solver.cpp:218] Iteration 2900 (3.32434 iter/s, 30.0812s/100 iters), loss = 2.21714
I1017 16:24:34.144662 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 2.21714 (* 1 = 2.21714 loss)
I1017 16:24:34.144671 22869 sgd_solver.cpp:105] Iteration 2900, lr = 0.01
I1017 16:25:02.738018 22877 data_layer.cpp:73] Restarting data prefetching from start.
I1017 16:25:03.943794 22869 solver.cpp:330] Iteration 3000, Testing net (#0)
I1017 16:25:20.293053 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 16:25:20.627952 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.92712 (* 1 = 1.92712 loss)
I1017 16:25:20.627969 22869 solver.cpp:397]     Test net output #1: accuracy = 0.4699
I1017 16:25:20.924747 22869 solver.cpp:218] Iteration 3000 (2.13766 iter/s, 46.7801s/100 iters), loss = 1.45751
I1017 16:25:20.924780 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.45751 (* 1 = 1.45751 loss)
I1017 16:25:20.924787 22869 sgd_solver.cpp:105] Iteration 3000, lr = 0.01
I1017 16:25:51.004761 22869 solver.cpp:218] Iteration 3100 (3.32448 iter/s, 30.0799s/100 iters), loss = 1.97734
I1017 16:25:51.004905 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.97734 (* 1 = 1.97734 loss)
I1017 16:25:51.004915 22869 sgd_solver.cpp:105] Iteration 3100, lr = 0.01
I1017 16:26:21.112888 22869 solver.cpp:218] Iteration 3200 (3.32138 iter/s, 30.108s/100 iters), loss = 1.77805
I1017 16:26:21.112999 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.77805 (* 1 = 1.77805 loss)
I1017 16:26:21.113008 22869 sgd_solver.cpp:105] Iteration 3200, lr = 0.01
I1017 16:26:51.226179 22869 solver.cpp:218] Iteration 3300 (3.32081 iter/s, 30.1132s/100 iters), loss = 1.81387
I1017 16:26:51.226279 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.81387 (* 1 = 1.81387 loss)
I1017 16:26:51.226286 22869 sgd_solver.cpp:105] Iteration 3300, lr = 0.01
I1017 16:27:21.322580 22869 solver.cpp:218] Iteration 3400 (3.32267 iter/s, 30.0963s/100 iters), loss = 1.84058
I1017 16:27:21.325796 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.84058 (* 1 = 1.84058 loss)
I1017 16:27:21.325804 22869 sgd_solver.cpp:105] Iteration 3400, lr = 0.01
I1017 16:27:51.147971 22869 solver.cpp:330] Iteration 3500, Testing net (#0)
I1017 16:28:07.553954 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 16:28:07.889173 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.85862 (* 1 = 1.85862 loss)
I1017 16:28:07.889190 22869 solver.cpp:397]     Test net output #1: accuracy = 0.4921
I1017 16:28:08.187065 22869 solver.cpp:218] Iteration 3500 (2.13396 iter/s, 46.8613s/100 iters), loss = 1.57307
I1017 16:28:08.187094 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.57307 (* 1 = 1.57307 loss)
I1017 16:28:08.187100 22869 sgd_solver.cpp:105] Iteration 3500, lr = 0.01
I1017 16:28:38.374928 22869 solver.cpp:218] Iteration 3600 (3.31259 iter/s, 30.1878s/100 iters), loss = 1.84599
I1017 16:28:38.375083 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.84599 (* 1 = 1.84599 loss)
I1017 16:28:38.375104 22869 sgd_solver.cpp:105] Iteration 3600, lr = 0.01
I1017 16:29:08.538996 22869 solver.cpp:218] Iteration 3700 (3.31522 iter/s, 30.1639s/100 iters), loss = 1.80035
I1017 16:29:08.539126 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.80035 (* 1 = 1.80035 loss)
I1017 16:29:08.539134 22869 sgd_solver.cpp:105] Iteration 3700, lr = 0.01
I1017 16:29:38.667320 22869 solver.cpp:218] Iteration 3800 (3.31915 iter/s, 30.1282s/100 iters), loss = 1.3965
I1017 16:29:38.667460 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.3965 (* 1 = 1.3965 loss)
I1017 16:29:38.667469 22869 sgd_solver.cpp:105] Iteration 3800, lr = 0.01
I1017 16:30:08.823626 22869 solver.cpp:218] Iteration 3900 (3.31607 iter/s, 30.1562s/100 iters), loss = 1.74137
I1017 16:30:08.823740 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.74137 (* 1 = 1.74137 loss)
I1017 16:30:08.823746 22869 sgd_solver.cpp:105] Iteration 3900, lr = 0.01
I1017 16:30:37.515753 22877 data_layer.cpp:73] Restarting data prefetching from start.
I1017 16:30:38.713960 22869 solver.cpp:330] Iteration 4000, Testing net (#0)
I1017 16:30:55.127084 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 16:30:55.460641 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.7908 (* 1 = 1.7908 loss)
I1017 16:30:55.460657 22869 solver.cpp:397]     Test net output #1: accuracy = 0.5106
I1017 16:30:55.754742 22869 solver.cpp:218] Iteration 4000 (2.13079 iter/s, 46.931s/100 iters), loss = 1.17938
I1017 16:30:55.754775 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.17938 (* 1 = 1.17938 loss)
I1017 16:30:55.754781 22869 sgd_solver.cpp:105] Iteration 4000, lr = 0.01
I1017 16:31:25.963544 22869 solver.cpp:218] Iteration 4100 (3.3103 iter/s, 30.2088s/100 iters), loss = 1.75383
I1017 16:31:25.963680 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.75383 (* 1 = 1.75383 loss)
I1017 16:31:25.963690 22869 sgd_solver.cpp:105] Iteration 4100, lr = 0.01
I1017 16:31:56.116778 22869 solver.cpp:218] Iteration 4200 (3.31641 iter/s, 30.1531s/100 iters), loss = 1.46102
I1017 16:31:56.116880 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.46102 (* 1 = 1.46102 loss)
I1017 16:31:56.116888 22869 sgd_solver.cpp:105] Iteration 4200, lr = 0.01
I1017 16:32:26.298620 22869 solver.cpp:218] Iteration 4300 (3.31326 iter/s, 30.1817s/100 iters), loss = 1.6121
I1017 16:32:26.298758 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.6121 (* 1 = 1.6121 loss)
I1017 16:32:26.298766 22869 sgd_solver.cpp:105] Iteration 4300, lr = 0.01
I1017 16:32:56.453510 22869 solver.cpp:218] Iteration 4400 (3.31623 iter/s, 30.1547s/100 iters), loss = 1.55034
I1017 16:32:56.454047 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.55034 (* 1 = 1.55034 loss)
I1017 16:32:56.454056 22869 sgd_solver.cpp:105] Iteration 4400, lr = 0.01
I1017 16:33:26.344251 22869 solver.cpp:330] Iteration 4500, Testing net (#0)
I1017 16:33:42.760565 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 16:33:43.096158 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.72558 (* 1 = 1.72558 loss)
I1017 16:33:43.096174 22869 solver.cpp:397]     Test net output #1: accuracy = 0.5233
I1017 16:33:43.392696 22869 solver.cpp:218] Iteration 4500 (2.13044 iter/s, 46.9386s/100 iters), loss = 1.34303
I1017 16:33:43.392729 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.34303 (* 1 = 1.34303 loss)
I1017 16:33:43.392735 22869 sgd_solver.cpp:105] Iteration 4500, lr = 0.01
I1017 16:34:13.540623 22869 solver.cpp:218] Iteration 4600 (3.31698 iter/s, 30.1479s/100 iters), loss = 1.72948
I1017 16:34:13.540724 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.72948 (* 1 = 1.72948 loss)
I1017 16:34:13.540731 22869 sgd_solver.cpp:105] Iteration 4600, lr = 0.01
I1017 16:34:43.686563 22869 solver.cpp:218] Iteration 4700 (3.31721 iter/s, 30.1458s/100 iters), loss = 1.331
I1017 16:34:43.686681 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.331 (* 1 = 1.331 loss)
I1017 16:34:43.686688 22869 sgd_solver.cpp:105] Iteration 4700, lr = 0.01
I1017 16:35:13.939628 22869 solver.cpp:218] Iteration 4800 (3.30546 iter/s, 30.2529s/100 iters), loss = 1.11047
I1017 16:35:13.939775 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.11047 (* 1 = 1.11047 loss)
I1017 16:35:13.939785 22869 sgd_solver.cpp:105] Iteration 4800, lr = 0.01
I1017 16:35:44.091734 22869 solver.cpp:218] Iteration 4900 (3.31653 iter/s, 30.152s/100 iters), loss = 1.6257
I1017 16:35:44.091847 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.6257 (* 1 = 1.6257 loss)
I1017 16:35:44.091855 22869 sgd_solver.cpp:105] Iteration 4900, lr = 0.01
I1017 16:36:12.748251 22877 data_layer.cpp:73] Restarting data prefetching from start.
I1017 16:36:13.959504 22869 solver.cpp:330] Iteration 5000, Testing net (#0)
I1017 16:36:30.424978 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 16:36:30.761675 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.6598 (* 1 = 1.6598 loss)
I1017 16:36:30.761692 22869 solver.cpp:397]     Test net output #1: accuracy = 0.5421
I1017 16:36:31.057428 22869 solver.cpp:218] Iteration 5000 (2.12922 iter/s, 46.9656s/100 iters), loss = 1.01468
I1017 16:36:31.057464 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.01468 (* 1 = 1.01468 loss)
I1017 16:36:31.057482 22869 sgd_solver.cpp:105] Iteration 5000, lr = 0.01
I1017 16:37:01.270412 22869 solver.cpp:218] Iteration 5100 (3.30984 iter/s, 30.2129s/100 iters), loss = 1.80615
I1017 16:37:01.270525 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.80615 (* 1 = 1.80615 loss)
I1017 16:37:01.270550 22869 sgd_solver.cpp:105] Iteration 5100, lr = 0.01
I1017 16:37:31.524641 22869 solver.cpp:218] Iteration 5200 (3.30534 iter/s, 30.2541s/100 iters), loss = 1.36747
I1017 16:37:31.524780 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.36747 (* 1 = 1.36747 loss)
I1017 16:37:31.524788 22869 sgd_solver.cpp:105] Iteration 5200, lr = 0.01
I1017 16:38:01.735007 22869 solver.cpp:218] Iteration 5300 (3.31014 iter/s, 30.2102s/100 iters), loss = 1.51984
I1017 16:38:01.735097 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.51984 (* 1 = 1.51984 loss)
I1017 16:38:01.735116 22869 sgd_solver.cpp:105] Iteration 5300, lr = 0.01
I1017 16:38:31.989758 22869 solver.cpp:218] Iteration 5400 (3.30528 iter/s, 30.2547s/100 iters), loss = 1.50595
I1017 16:38:31.989854 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.50595 (* 1 = 1.50595 loss)
I1017 16:38:31.989871 22869 sgd_solver.cpp:105] Iteration 5400, lr = 0.01
I1017 16:39:01.930074 22869 solver.cpp:330] Iteration 5500, Testing net (#0)
I1017 16:39:18.392154 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 16:39:18.726765 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.6584 (* 1 = 1.6584 loss)
I1017 16:39:18.726780 22869 solver.cpp:397]     Test net output #1: accuracy = 0.5421
I1017 16:39:19.026157 22869 solver.cpp:218] Iteration 5500 (2.12602 iter/s, 47.0363s/100 iters), loss = 1.2053
I1017 16:39:19.026190 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.2053 (* 1 = 1.2053 loss)
I1017 16:39:19.026196 22869 sgd_solver.cpp:105] Iteration 5500, lr = 0.01
I1017 16:39:49.269345 22869 solver.cpp:218] Iteration 5600 (3.30653 iter/s, 30.2431s/100 iters), loss = 1.41978
I1017 16:39:49.269445 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.41978 (* 1 = 1.41978 loss)
I1017 16:39:49.269453 22869 sgd_solver.cpp:105] Iteration 5600, lr = 0.01
I1017 16:40:19.496552 22869 solver.cpp:218] Iteration 5700 (3.30829 iter/s, 30.2271s/100 iters), loss = 1.23349
I1017 16:40:19.496646 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.23349 (* 1 = 1.23349 loss)
I1017 16:40:19.496654 22869 sgd_solver.cpp:105] Iteration 5700, lr = 0.01
I1017 16:40:49.726755 22869 solver.cpp:218] Iteration 5800 (3.30796 iter/s, 30.2301s/100 iters), loss = 1.02654
I1017 16:40:49.726891 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.02654 (* 1 = 1.02654 loss)
I1017 16:40:49.726909 22869 sgd_solver.cpp:105] Iteration 5800, lr = 0.01
I1017 16:41:19.994285 22869 solver.cpp:218] Iteration 5900 (3.30388 iter/s, 30.2674s/100 iters), loss = 1.47538
I1017 16:41:19.994362 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.47538 (* 1 = 1.47538 loss)
I1017 16:41:19.994380 22869 sgd_solver.cpp:105] Iteration 5900, lr = 0.01
I1017 16:41:48.736469 22877 data_layer.cpp:73] Restarting data prefetching from start.
I1017 16:41:49.939767 22869 solver.cpp:330] Iteration 6000, Testing net (#0)
I1017 16:42:06.427026 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 16:42:06.763923 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.58717 (* 1 = 1.58717 loss)
I1017 16:42:06.763938 22869 solver.cpp:397]     Test net output #1: accuracy = 0.5621
I1017 16:42:07.060736 22869 solver.cpp:218] Iteration 6000 (2.12466 iter/s, 47.0664s/100 iters), loss = 1.06969
I1017 16:42:07.060766 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.06969 (* 1 = 1.06969 loss)
I1017 16:42:07.060773 22869 sgd_solver.cpp:105] Iteration 6000, lr = 0.01
I1017 16:42:37.332898 22869 solver.cpp:218] Iteration 6100 (3.30337 iter/s, 30.2721s/100 iters), loss = 1.36497
I1017 16:42:37.333047 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.36497 (* 1 = 1.36497 loss)
I1017 16:42:37.333055 22869 sgd_solver.cpp:105] Iteration 6100, lr = 0.01
I1017 16:43:07.666067 22869 solver.cpp:218] Iteration 6200 (3.29674 iter/s, 30.333s/100 iters), loss = 1.33937
I1017 16:43:07.666206 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.33937 (* 1 = 1.33937 loss)
I1017 16:43:07.666214 22869 sgd_solver.cpp:105] Iteration 6200, lr = 0.01
I1017 16:43:37.948338 22869 solver.cpp:218] Iteration 6300 (3.30228 iter/s, 30.2821s/100 iters), loss = 1.33034
I1017 16:43:37.948454 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.33034 (* 1 = 1.33034 loss)
I1017 16:43:37.948462 22869 sgd_solver.cpp:105] Iteration 6300, lr = 0.01
I1017 16:44:08.219004 22869 solver.cpp:218] Iteration 6400 (3.30354 iter/s, 30.2705s/100 iters), loss = 1.37759
I1017 16:44:08.219137 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.37759 (* 1 = 1.37759 loss)
I1017 16:44:08.219146 22869 sgd_solver.cpp:105] Iteration 6400, lr = 0.01
I1017 16:44:38.216536 22869 solver.cpp:330] Iteration 6500, Testing net (#0)
I1017 16:44:54.739820 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 16:44:55.078101 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.57864 (* 1 = 1.57864 loss)
I1017 16:44:55.078117 22869 solver.cpp:397]     Test net output #1: accuracy = 0.5613
I1017 16:44:55.375680 22869 solver.cpp:218] Iteration 6500 (2.1206 iter/s, 47.1565s/100 iters), loss = 1.10395
I1017 16:44:55.375725 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.10395 (* 1 = 1.10395 loss)
I1017 16:44:55.375730 22869 sgd_solver.cpp:105] Iteration 6500, lr = 0.01
I1017 16:45:25.669224 22869 solver.cpp:218] Iteration 6600 (3.30104 iter/s, 30.2935s/100 iters), loss = 1.21895
I1017 16:45:25.669375 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.21895 (* 1 = 1.21895 loss)
I1017 16:45:25.669384 22869 sgd_solver.cpp:105] Iteration 6600, lr = 0.01
I1017 16:45:55.948779 22869 solver.cpp:218] Iteration 6700 (3.30258 iter/s, 30.2794s/100 iters), loss = 1.25039
I1017 16:45:55.948892 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.25039 (* 1 = 1.25039 loss)
I1017 16:45:55.948912 22869 sgd_solver.cpp:105] Iteration 6700, lr = 0.01
I1017 16:46:26.223191 22869 solver.cpp:218] Iteration 6800 (3.30313 iter/s, 30.2743s/100 iters), loss = 0.990574
I1017 16:46:26.223309 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.990574 (* 1 = 0.990574 loss)
I1017 16:46:26.223315 22869 sgd_solver.cpp:105] Iteration 6800, lr = 0.01
I1017 16:46:56.524914 22869 solver.cpp:218] Iteration 6900 (3.30015 iter/s, 30.3016s/100 iters), loss = 1.40131
I1017 16:46:56.525027 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.40131 (* 1 = 1.40131 loss)
I1017 16:46:56.525037 22869 sgd_solver.cpp:105] Iteration 6900, lr = 0.01
I1017 16:47:25.317390 22877 data_layer.cpp:73] Restarting data prefetching from start.
I1017 16:47:26.536512 22869 solver.cpp:330] Iteration 7000, Testing net (#0)
I1017 16:47:43.017380 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 16:47:43.353217 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.55286 (* 1 = 1.55286 loss)
I1017 16:47:43.353232 22869 solver.cpp:397]     Test net output #1: accuracy = 0.5736
I1017 16:47:43.649744 22869 solver.cpp:218] Iteration 7000 (2.12203 iter/s, 47.1247s/100 iters), loss = 0.99631
I1017 16:47:43.649775 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.99631 (* 1 = 0.99631 loss)
I1017 16:47:43.649780 22869 sgd_solver.cpp:105] Iteration 7000, lr = 0.01
I1017 16:48:13.965364 22869 solver.cpp:218] Iteration 7100 (3.29863 iter/s, 30.3156s/100 iters), loss = 1.27885
I1017 16:48:13.965477 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.27885 (* 1 = 1.27885 loss)
I1017 16:48:13.965484 22869 sgd_solver.cpp:105] Iteration 7100, lr = 0.01
I1017 16:48:44.270005 22869 solver.cpp:218] Iteration 7200 (3.29984 iter/s, 30.3045s/100 iters), loss = 1.12231
I1017 16:48:44.270135 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.12231 (* 1 = 1.12231 loss)
I1017 16:48:44.270144 22869 sgd_solver.cpp:105] Iteration 7200, lr = 0.01
I1017 16:49:14.644829 22869 solver.cpp:218] Iteration 7300 (3.29221 iter/s, 30.3747s/100 iters), loss = 1.1998
I1017 16:49:14.644924 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.1998 (* 1 = 1.1998 loss)
I1017 16:49:14.644932 22869 sgd_solver.cpp:105] Iteration 7300, lr = 0.01
I1017 16:49:44.979398 22869 solver.cpp:218] Iteration 7400 (3.29658 iter/s, 30.3345s/100 iters), loss = 1.25857
I1017 16:49:44.979540 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.25857 (* 1 = 1.25857 loss)
I1017 16:49:44.979549 22869 sgd_solver.cpp:105] Iteration 7400, lr = 0.01
I1017 16:50:15.003443 22869 solver.cpp:330] Iteration 7500, Testing net (#0)
I1017 16:50:31.503507 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 16:50:31.842152 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.54461 (* 1 = 1.54461 loss)
I1017 16:50:31.842170 22869 solver.cpp:397]     Test net output #1: accuracy = 0.5771
I1017 16:50:32.141331 22869 solver.cpp:218] Iteration 7500 (2.12036 iter/s, 47.1618s/100 iters), loss = 1.10416
I1017 16:50:32.141366 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.10416 (* 1 = 1.10416 loss)
I1017 16:50:32.141371 22869 sgd_solver.cpp:105] Iteration 7500, lr = 0.01
I1017 16:51:02.460790 22869 solver.cpp:218] Iteration 7600 (3.29822 iter/s, 30.3194s/100 iters), loss = 1.31921
I1017 16:51:02.460919 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.31921 (* 1 = 1.31921 loss)
I1017 16:51:02.460927 22869 sgd_solver.cpp:105] Iteration 7600, lr = 0.01
I1017 16:51:32.776589 22869 solver.cpp:218] Iteration 7700 (3.29862 iter/s, 30.3157s/100 iters), loss = 1.12341
I1017 16:51:32.776731 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.12341 (* 1 = 1.12341 loss)
I1017 16:51:32.776738 22869 sgd_solver.cpp:105] Iteration 7700, lr = 0.01
I1017 16:52:03.130592 22869 solver.cpp:218] Iteration 7800 (3.29447 iter/s, 30.3539s/100 iters), loss = 0.948441
I1017 16:52:03.130698 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.948441 (* 1 = 0.948441 loss)
I1017 16:52:03.130707 22869 sgd_solver.cpp:105] Iteration 7800, lr = 0.01
I1017 16:52:33.446840 22869 solver.cpp:218] Iteration 7900 (3.29857 iter/s, 30.3161s/100 iters), loss = 1.18231
I1017 16:52:33.446959 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.18231 (* 1 = 1.18231 loss)
I1017 16:52:33.446966 22869 sgd_solver.cpp:105] Iteration 7900, lr = 0.01
I1017 16:53:02.319407 22877 data_layer.cpp:73] Restarting data prefetching from start.
I1017 16:53:03.530958 22869 solver.cpp:330] Iteration 8000, Testing net (#0)
I1017 16:53:20.039991 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 16:53:20.375726 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.5422 (* 1 = 1.5422 loss)
I1017 16:53:20.375742 22869 solver.cpp:397]     Test net output #1: accuracy = 0.5758
I1017 16:53:20.674955 22869 solver.cpp:218] Iteration 8000 (2.11739 iter/s, 47.228s/100 iters), loss = 0.940419
I1017 16:53:20.674991 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.940419 (* 1 = 0.940419 loss)
I1017 16:53:20.674998 22869 sgd_solver.cpp:105] Iteration 8000, lr = 0.01
I1017 16:53:50.979951 22869 solver.cpp:218] Iteration 8100 (3.29979 iter/s, 30.305s/100 iters), loss = 1.44245
I1017 16:53:50.980098 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.44245 (* 1 = 1.44245 loss)
I1017 16:53:50.980119 22869 sgd_solver.cpp:105] Iteration 8100, lr = 0.01
I1017 16:54:21.310117 22869 solver.cpp:218] Iteration 8200 (3.29706 iter/s, 30.33s/100 iters), loss = 1.09326
I1017 16:54:21.310259 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.09326 (* 1 = 1.09326 loss)
I1017 16:54:21.310268 22869 sgd_solver.cpp:105] Iteration 8200, lr = 0.01
I1017 16:54:51.674906 22869 solver.cpp:218] Iteration 8300 (3.2933 iter/s, 30.3646s/100 iters), loss = 1.06791
I1017 16:54:51.675022 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.06791 (* 1 = 1.06791 loss)
I1017 16:54:51.675030 22869 sgd_solver.cpp:105] Iteration 8300, lr = 0.01
I1017 16:55:22.000145 22869 solver.cpp:218] Iteration 8400 (3.2976 iter/s, 30.3251s/100 iters), loss = 1.05606
I1017 16:55:22.000254 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.05606 (* 1 = 1.05606 loss)
I1017 16:55:22.000262 22869 sgd_solver.cpp:105] Iteration 8400, lr = 0.01
I1017 16:55:52.074981 22869 solver.cpp:330] Iteration 8500, Testing net (#0)
I1017 16:56:08.523177 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 16:56:08.864156 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.53383 (* 1 = 1.53383 loss)
I1017 16:56:08.864171 22869 solver.cpp:397]     Test net output #1: accuracy = 0.5797
I1017 16:56:09.166926 22869 solver.cpp:218] Iteration 8500 (2.12014 iter/s, 47.1667s/100 iters), loss = 1.01664
I1017 16:56:09.166961 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.01664 (* 1 = 1.01664 loss)
I1017 16:56:09.166968 22869 sgd_solver.cpp:105] Iteration 8500, lr = 0.01
I1017 16:56:39.536461 22869 solver.cpp:218] Iteration 8600 (3.29278 iter/s, 30.3695s/100 iters), loss = 1.16931
I1017 16:56:39.536571 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.16931 (* 1 = 1.16931 loss)
I1017 16:56:39.536577 22869 sgd_solver.cpp:105] Iteration 8600, lr = 0.01
I1017 16:57:09.906390 22869 solver.cpp:218] Iteration 8700 (3.29274 iter/s, 30.3698s/100 iters), loss = 1.02732
I1017 16:57:09.906533 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.02732 (* 1 = 1.02732 loss)
I1017 16:57:09.906543 22869 sgd_solver.cpp:105] Iteration 8700, lr = 0.01
I1017 16:57:40.250249 22869 solver.cpp:218] Iteration 8800 (3.29558 iter/s, 30.3437s/100 iters), loss = 0.882537
I1017 16:57:40.250391 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.882537 (* 1 = 0.882537 loss)
I1017 16:57:40.250399 22869 sgd_solver.cpp:105] Iteration 8800, lr = 0.01
I1017 16:58:10.617836 22869 solver.cpp:218] Iteration 8900 (3.293 iter/s, 30.3674s/100 iters), loss = 0.871593
I1017 16:58:10.617962 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.871593 (* 1 = 0.871593 loss)
I1017 16:58:10.617969 22869 sgd_solver.cpp:105] Iteration 8900, lr = 0.01
I1017 16:58:39.468260 22877 data_layer.cpp:73] Restarting data prefetching from start.
I1017 16:58:40.678643 22869 solver.cpp:330] Iteration 9000, Testing net (#0)
I1017 16:58:57.123970 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 16:58:57.462843 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.45875 (* 1 = 1.45875 loss)
I1017 16:58:57.462859 22869 solver.cpp:397]     Test net output #1: accuracy = 0.5986
I1017 16:58:57.764662 22869 solver.cpp:218] Iteration 9000 (2.12104 iter/s, 47.1467s/100 iters), loss = 0.917045
I1017 16:58:57.764698 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.917045 (* 1 = 0.917045 loss)
I1017 16:58:57.764704 22869 sgd_solver.cpp:105] Iteration 9000, lr = 0.01
I1017 16:59:28.119448 22869 solver.cpp:218] Iteration 9100 (3.29438 iter/s, 30.3547s/100 iters), loss = 1.22353
I1017 16:59:28.119596 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.22353 (* 1 = 1.22353 loss)
I1017 16:59:28.119604 22869 sgd_solver.cpp:105] Iteration 9100, lr = 0.01
I1017 16:59:58.441460 22869 solver.cpp:218] Iteration 9200 (3.29795 iter/s, 30.3219s/100 iters), loss = 1.06415
I1017 16:59:58.441608 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.06415 (* 1 = 1.06415 loss)
I1017 16:59:58.441615 22869 sgd_solver.cpp:105] Iteration 9200, lr = 0.01
I1017 17:00:28.791307 22869 solver.cpp:218] Iteration 9300 (3.29492 iter/s, 30.3497s/100 iters), loss = 1.03886
I1017 17:00:28.791434 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.03886 (* 1 = 1.03886 loss)
I1017 17:00:28.791440 22869 sgd_solver.cpp:105] Iteration 9300, lr = 0.01
I1017 17:00:59.105773 22869 solver.cpp:218] Iteration 9400 (3.29877 iter/s, 30.3143s/100 iters), loss = 0.874906
I1017 17:00:59.105845 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.874906 (* 1 = 0.874906 loss)
I1017 17:00:59.105864 22869 sgd_solver.cpp:105] Iteration 9400, lr = 0.01
I1017 17:01:29.158408 22869 solver.cpp:330] Iteration 9500, Testing net (#0)
I1017 17:01:45.655663 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 17:01:45.991856 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.46899 (* 1 = 1.46899 loss)
I1017 17:01:45.991873 22869 solver.cpp:397]     Test net output #1: accuracy = 0.5981
I1017 17:01:46.289160 22869 solver.cpp:218] Iteration 9500 (2.11939 iter/s, 47.1833s/100 iters), loss = 1.00784
I1017 17:01:46.289196 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.00784 (* 1 = 1.00784 loss)
I1017 17:01:46.289203 22869 sgd_solver.cpp:105] Iteration 9500, lr = 0.01
I1017 17:02:16.541153 22869 solver.cpp:218] Iteration 9600 (3.30557 iter/s, 30.2519s/100 iters), loss = 1.12289
I1017 17:02:16.541294 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.12289 (* 1 = 1.12289 loss)
I1017 17:02:16.541303 22869 sgd_solver.cpp:105] Iteration 9600, lr = 0.01
I1017 17:02:46.855855 22869 solver.cpp:218] Iteration 9700 (3.29875 iter/s, 30.3146s/100 iters), loss = 0.804396
I1017 17:02:46.855962 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.804396 (* 1 = 0.804396 loss)
I1017 17:02:46.855969 22869 sgd_solver.cpp:105] Iteration 9700, lr = 0.01
I1017 17:03:17.126531 22869 solver.cpp:218] Iteration 9800 (3.30354 iter/s, 30.2706s/100 iters), loss = 0.683101
I1017 17:03:17.126668 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.683101 (* 1 = 0.683101 loss)
I1017 17:03:17.126677 22869 sgd_solver.cpp:105] Iteration 9800, lr = 0.01
I1017 17:03:47.413692 22869 solver.cpp:218] Iteration 9900 (3.30174 iter/s, 30.287s/100 iters), loss = 1.12023
I1017 17:03:47.413780 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.12023 (* 1 = 1.12023 loss)
I1017 17:03:47.413787 22869 sgd_solver.cpp:105] Iteration 9900, lr = 0.01
I1017 17:04:16.190165 22877 data_layer.cpp:73] Restarting data prefetching from start.
I1017 17:04:17.412973 22869 solver.cpp:330] Iteration 10000, Testing net (#0)
I1017 17:04:33.908843 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 17:04:34.249603 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.48863 (* 1 = 1.48863 loss)
I1017 17:04:34.249619 22869 solver.cpp:397]     Test net output #1: accuracy = 0.5936
I1017 17:04:34.552568 22869 solver.cpp:218] Iteration 10000 (2.1214 iter/s, 47.1388s/100 iters), loss = 0.614065
I1017 17:04:34.552600 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.614065 (* 1 = 0.614065 loss)
I1017 17:04:34.552608 22869 sgd_solver.cpp:105] Iteration 10000, lr = 0.01
I1017 17:05:04.873946 22869 solver.cpp:218] Iteration 10100 (3.29801 iter/s, 30.3213s/100 iters), loss = 1.13377
I1017 17:05:04.874017 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.13377 (* 1 = 1.13377 loss)
I1017 17:05:04.874034 22869 sgd_solver.cpp:105] Iteration 10100, lr = 0.01
I1017 17:05:35.175045 22869 solver.cpp:218] Iteration 10200 (3.30022 iter/s, 30.301s/100 iters), loss = 1.05848
I1017 17:05:35.175117 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.05848 (* 1 = 1.05848 loss)
I1017 17:05:35.175124 22869 sgd_solver.cpp:105] Iteration 10200, lr = 0.01
I1017 17:06:05.497067 22869 solver.cpp:218] Iteration 10300 (3.29794 iter/s, 30.3219s/100 iters), loss = 1.01564
I1017 17:06:05.497176 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.01564 (* 1 = 1.01564 loss)
I1017 17:06:05.497193 22869 sgd_solver.cpp:105] Iteration 10300, lr = 0.01
I1017 17:06:35.819236 22869 solver.cpp:218] Iteration 10400 (3.29793 iter/s, 30.3221s/100 iters), loss = 0.821272
I1017 17:06:35.819386 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.821272 (* 1 = 0.821272 loss)
I1017 17:06:35.819406 22869 sgd_solver.cpp:105] Iteration 10400, lr = 0.01
I1017 17:07:05.834055 22869 solver.cpp:330] Iteration 10500, Testing net (#0)
I1017 17:07:22.306717 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 17:07:22.647972 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.4718 (* 1 = 1.4718 loss)
I1017 17:07:22.647987 22869 solver.cpp:397]     Test net output #1: accuracy = 0.601
I1017 17:07:22.947562 22869 solver.cpp:218] Iteration 10500 (2.12187 iter/s, 47.1282s/100 iters), loss = 0.988899
I1017 17:07:22.947597 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.988899 (* 1 = 0.988899 loss)
I1017 17:07:22.947604 22869 sgd_solver.cpp:105] Iteration 10500, lr = 0.01
I1017 17:07:53.259573 22869 solver.cpp:218] Iteration 10600 (3.29903 iter/s, 30.312s/100 iters), loss = 0.986441
I1017 17:07:53.259726 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.986441 (* 1 = 0.986441 loss)
I1017 17:07:53.259744 22869 sgd_solver.cpp:105] Iteration 10600, lr = 0.01
I1017 17:08:23.572744 22869 solver.cpp:218] Iteration 10700 (3.29891 iter/s, 30.313s/100 iters), loss = 0.725112
I1017 17:08:23.572888 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.725112 (* 1 = 0.725112 loss)
I1017 17:08:23.572897 22869 sgd_solver.cpp:105] Iteration 10700, lr = 0.01
I1017 17:08:53.887729 22869 solver.cpp:218] Iteration 10800 (3.29871 iter/s, 30.3148s/100 iters), loss = 0.739448
I1017 17:08:53.887872 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.739448 (* 1 = 0.739448 loss)
I1017 17:08:53.887881 22869 sgd_solver.cpp:105] Iteration 10800, lr = 0.01
I1017 17:09:24.226151 22869 solver.cpp:218] Iteration 10900 (3.29617 iter/s, 30.3383s/100 iters), loss = 1.09007
I1017 17:09:24.226258 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.09007 (* 1 = 1.09007 loss)
I1017 17:09:24.226266 22869 sgd_solver.cpp:105] Iteration 10900, lr = 0.01
I1017 17:09:53.035264 22877 data_layer.cpp:73] Restarting data prefetching from start.
I1017 17:09:54.253141 22869 solver.cpp:330] Iteration 11000, Testing net (#0)
I1017 17:10:10.738948 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 17:10:11.076385 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.42969 (* 1 = 1.42969 loss)
I1017 17:10:11.076400 22869 solver.cpp:397]     Test net output #1: accuracy = 0.6143
I1017 17:10:11.376111 22869 solver.cpp:218] Iteration 11000 (2.1209 iter/s, 47.1498s/100 iters), loss = 0.608365
I1017 17:10:11.376147 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.608365 (* 1 = 0.608365 loss)
I1017 17:10:11.376154 22869 sgd_solver.cpp:105] Iteration 11000, lr = 0.01
I1017 17:10:41.712994 22869 solver.cpp:218] Iteration 11100 (3.29632 iter/s, 30.3368s/100 iters), loss = 0.914205
I1017 17:10:41.713130 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.914205 (* 1 = 0.914205 loss)
I1017 17:10:41.713138 22869 sgd_solver.cpp:105] Iteration 11100, lr = 0.01
I1017 17:11:12.024967 22869 solver.cpp:218] Iteration 11200 (3.29904 iter/s, 30.3118s/100 iters), loss = 0.916784
I1017 17:11:12.025051 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.916784 (* 1 = 0.916784 loss)
I1017 17:11:12.025068 22869 sgd_solver.cpp:105] Iteration 11200, lr = 0.01
I1017 17:11:42.322899 22869 solver.cpp:218] Iteration 11300 (3.30057 iter/s, 30.2978s/100 iters), loss = 0.843593
I1017 17:11:42.323045 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.843592 (* 1 = 0.843592 loss)
I1017 17:11:42.323053 22869 sgd_solver.cpp:105] Iteration 11300, lr = 0.01
I1017 17:12:12.640214 22869 solver.cpp:218] Iteration 11400 (3.29846 iter/s, 30.3172s/100 iters), loss = 0.642347
I1017 17:12:12.640358 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.642347 (* 1 = 0.642347 loss)
I1017 17:12:12.640367 22869 sgd_solver.cpp:105] Iteration 11400, lr = 0.01
I1017 17:12:42.626905 22869 solver.cpp:330] Iteration 11500, Testing net (#0)
I1017 17:12:59.050501 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 17:12:59.386273 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.44876 (* 1 = 1.44876 loss)
I1017 17:12:59.386289 22869 solver.cpp:397]     Test net output #1: accuracy = 0.6103
I1017 17:12:59.684734 22869 solver.cpp:218] Iteration 11500 (2.12565 iter/s, 47.0444s/100 iters), loss = 0.898142
I1017 17:12:59.684777 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.898142 (* 1 = 0.898142 loss)
I1017 17:12:59.684783 22869 sgd_solver.cpp:105] Iteration 11500, lr = 0.01
I1017 17:13:30.002559 22869 solver.cpp:218] Iteration 11600 (3.29839 iter/s, 30.3178s/100 iters), loss = 1.05802
I1017 17:13:30.002651 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.05802 (* 1 = 1.05802 loss)
I1017 17:13:30.002658 22869 sgd_solver.cpp:105] Iteration 11600, lr = 0.01
I1017 17:14:00.262845 22869 solver.cpp:218] Iteration 11700 (3.30467 iter/s, 30.2602s/100 iters), loss = 0.647984
I1017 17:14:00.262951 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.647984 (* 1 = 0.647984 loss)
I1017 17:14:00.262959 22869 sgd_solver.cpp:105] Iteration 11700, lr = 0.01
I1017 17:14:30.571949 22869 solver.cpp:218] Iteration 11800 (3.29935 iter/s, 30.309s/100 iters), loss = 0.601876
I1017 17:14:30.572084 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.601875 (* 1 = 0.601875 loss)
I1017 17:14:30.572093 22869 sgd_solver.cpp:105] Iteration 11800, lr = 0.01
I1017 17:15:00.913499 22869 solver.cpp:218] Iteration 11900 (3.29583 iter/s, 30.3414s/100 iters), loss = 0.842196
I1017 17:15:00.913611 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.842196 (* 1 = 0.842196 loss)
I1017 17:15:00.913622 22869 sgd_solver.cpp:105] Iteration 11900, lr = 0.01
I1017 17:15:29.763505 22877 data_layer.cpp:73] Restarting data prefetching from start.
I1017 17:15:30.989225 22869 solver.cpp:330] Iteration 12000, Testing net (#0)
I1017 17:15:47.457465 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 17:15:47.797309 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.42536 (* 1 = 1.42536 loss)
I1017 17:15:47.797324 22869 solver.cpp:397]     Test net output #1: accuracy = 0.6195
I1017 17:15:48.098798 22869 solver.cpp:218] Iteration 12000 (2.11931 iter/s, 47.1852s/100 iters), loss = 0.541636
I1017 17:15:48.098829 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.541635 (* 1 = 0.541635 loss)
I1017 17:15:48.098836 22869 sgd_solver.cpp:105] Iteration 12000, lr = 0.01
I1017 17:16:18.386461 22869 solver.cpp:218] Iteration 12100 (3.30168 iter/s, 30.2876s/100 iters), loss = 1.06245
I1017 17:16:18.386638 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.06245 (* 1 = 1.06245 loss)
I1017 17:16:18.386647 22869 sgd_solver.cpp:105] Iteration 12100, lr = 0.01
I1017 17:16:48.647140 22869 solver.cpp:218] Iteration 12200 (3.30464 iter/s, 30.2605s/100 iters), loss = 0.966219
I1017 17:16:48.647289 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.966219 (* 1 = 0.966219 loss)
I1017 17:16:48.647296 22869 sgd_solver.cpp:105] Iteration 12200, lr = 0.01
I1017 17:17:18.954593 22869 solver.cpp:218] Iteration 12300 (3.29953 iter/s, 30.3073s/100 iters), loss = 0.648143
I1017 17:17:18.954876 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.648143 (* 1 = 0.648143 loss)
I1017 17:17:18.954895 22869 sgd_solver.cpp:105] Iteration 12300, lr = 0.01
I1017 17:17:49.256187 22869 solver.cpp:218] Iteration 12400 (3.30019 iter/s, 30.3013s/100 iters), loss = 0.753093
I1017 17:17:49.256286 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.753093 (* 1 = 0.753093 loss)
I1017 17:17:49.256304 22869 sgd_solver.cpp:105] Iteration 12400, lr = 0.01
I1017 17:18:19.224397 22869 solver.cpp:330] Iteration 12500, Testing net (#0)
I1017 17:18:35.619958 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 17:18:35.961966 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.45086 (* 1 = 1.45086 loss)
I1017 17:18:35.961982 22869 solver.cpp:397]     Test net output #1: accuracy = 0.6141
I1017 17:18:36.260071 22869 solver.cpp:218] Iteration 12500 (2.12749 iter/s, 47.0038s/100 iters), loss = 0.737705
I1017 17:18:36.260108 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.737705 (* 1 = 0.737705 loss)
I1017 17:18:36.260115 22869 sgd_solver.cpp:105] Iteration 12500, lr = 0.01
I1017 17:19:06.552037 22869 solver.cpp:218] Iteration 12600 (3.30121 iter/s, 30.2919s/100 iters), loss = 0.95915
I1017 17:19:06.552104 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.95915 (* 1 = 0.95915 loss)
I1017 17:19:06.552112 22869 sgd_solver.cpp:105] Iteration 12600, lr = 0.01
I1017 17:19:36.856467 22869 solver.cpp:218] Iteration 12700 (3.29986 iter/s, 30.3044s/100 iters), loss = 0.607328
I1017 17:19:36.856611 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.607328 (* 1 = 0.607328 loss)
I1017 17:19:36.856619 22869 sgd_solver.cpp:105] Iteration 12700, lr = 0.01
I1017 17:20:07.144881 22869 solver.cpp:218] Iteration 12800 (3.30161 iter/s, 30.2883s/100 iters), loss = 0.531092
I1017 17:20:07.145011 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.531092 (* 1 = 0.531092 loss)
I1017 17:20:07.145021 22869 sgd_solver.cpp:105] Iteration 12800, lr = 0.01
I1017 17:20:37.398754 22869 solver.cpp:218] Iteration 12900 (3.30538 iter/s, 30.2537s/100 iters), loss = 0.993781
I1017 17:20:37.398888 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.993781 (* 1 = 0.993781 loss)
I1017 17:20:37.398895 22869 sgd_solver.cpp:105] Iteration 12900, lr = 0.01
I1017 17:21:06.177273 22877 data_layer.cpp:73] Restarting data prefetching from start.
I1017 17:21:07.385879 22869 solver.cpp:330] Iteration 13000, Testing net (#0)
I1017 17:21:23.852129 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 17:21:24.192559 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.42897 (* 1 = 1.42897 loss)
I1017 17:21:24.192575 22869 solver.cpp:397]     Test net output #1: accuracy = 0.6208
I1017 17:21:24.498858 22869 solver.cpp:218] Iteration 13000 (2.12314 iter/s, 47.1s/100 iters), loss = 0.41117
I1017 17:21:24.498900 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.41117 (* 1 = 0.41117 loss)
I1017 17:21:24.498908 22869 sgd_solver.cpp:105] Iteration 13000, lr = 0.01
I1017 17:21:54.732547 22869 solver.cpp:218] Iteration 13100 (3.30757 iter/s, 30.2336s/100 iters), loss = 0.794959
I1017 17:21:54.732697 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.794959 (* 1 = 0.794959 loss)
I1017 17:21:54.732718 22869 sgd_solver.cpp:105] Iteration 13100, lr = 0.01
I1017 17:22:24.991473 22869 solver.cpp:218] Iteration 13200 (3.30483 iter/s, 30.2588s/100 iters), loss = 0.888697
I1017 17:22:24.991623 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.888697 (* 1 = 0.888697 loss)
I1017 17:22:24.991631 22869 sgd_solver.cpp:105] Iteration 13200, lr = 0.01
I1017 17:22:55.267196 22869 solver.cpp:218] Iteration 13300 (3.30299 iter/s, 30.2756s/100 iters), loss = 0.677994
I1017 17:22:55.267349 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.677994 (* 1 = 0.677994 loss)
I1017 17:22:55.267359 22869 sgd_solver.cpp:105] Iteration 13300, lr = 0.01
I1017 17:23:25.568768 22869 solver.cpp:218] Iteration 13400 (3.30018 iter/s, 30.3014s/100 iters), loss = 0.690564
I1017 17:23:25.568903 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.690564 (* 1 = 0.690564 loss)
I1017 17:23:25.568910 22869 sgd_solver.cpp:105] Iteration 13400, lr = 0.01
I1017 17:23:55.495116 22869 solver.cpp:330] Iteration 13500, Testing net (#0)
I1017 17:24:11.926259 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 17:24:12.265130 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.44934 (* 1 = 1.44934 loss)
I1017 17:24:12.265144 22869 solver.cpp:397]     Test net output #1: accuracy = 0.6227
I1017 17:24:12.567102 22869 solver.cpp:218] Iteration 13500 (2.12774 iter/s, 46.9982s/100 iters), loss = 0.854598
I1017 17:24:12.567132 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.854598 (* 1 = 0.854598 loss)
I1017 17:24:12.567138 22869 sgd_solver.cpp:105] Iteration 13500, lr = 0.01
I1017 17:24:42.822263 22869 solver.cpp:218] Iteration 13600 (3.30523 iter/s, 30.2551s/100 iters), loss = 0.694288
I1017 17:24:42.822407 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.694288 (* 1 = 0.694288 loss)
I1017 17:24:42.822415 22869 sgd_solver.cpp:105] Iteration 13600, lr = 0.01
I1017 17:25:13.097859 22869 solver.cpp:218] Iteration 13700 (3.30301 iter/s, 30.2754s/100 iters), loss = 0.468125
I1017 17:25:13.098011 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.468125 (* 1 = 0.468125 loss)
I1017 17:25:13.098021 22869 sgd_solver.cpp:105] Iteration 13700, lr = 0.01
I1017 17:25:43.349860 22869 solver.cpp:218] Iteration 13800 (3.30558 iter/s, 30.2518s/100 iters), loss = 0.477542
I1017 17:25:43.349969 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.477542 (* 1 = 0.477542 loss)
I1017 17:25:43.349977 22869 sgd_solver.cpp:105] Iteration 13800, lr = 0.01
I1017 17:26:13.620240 22869 solver.cpp:218] Iteration 13900 (3.30357 iter/s, 30.2703s/100 iters), loss = 0.75748
I1017 17:26:13.620337 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.75748 (* 1 = 0.75748 loss)
I1017 17:26:13.620344 22869 sgd_solver.cpp:105] Iteration 13900, lr = 0.01
I1017 17:26:42.394017 22877 data_layer.cpp:73] Restarting data prefetching from start.
I1017 17:26:43.612543 22869 solver.cpp:330] Iteration 14000, Testing net (#0)
I1017 17:27:00.033246 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 17:27:00.370060 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.44755 (* 1 = 1.44755 loss)
I1017 17:27:00.370079 22869 solver.cpp:397]     Test net output #1: accuracy = 0.6226
I1017 17:27:00.668011 22869 solver.cpp:218] Iteration 14000 (2.1255 iter/s, 47.0477s/100 iters), loss = 0.612307
I1017 17:27:00.668042 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.612307 (* 1 = 0.612307 loss)
I1017 17:27:00.668048 22869 sgd_solver.cpp:105] Iteration 14000, lr = 0.01
I1017 17:27:30.977453 22869 solver.cpp:218] Iteration 14100 (3.29931 iter/s, 30.3094s/100 iters), loss = 0.578752
I1017 17:27:30.977552 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.578752 (* 1 = 0.578752 loss)
I1017 17:27:30.977560 22869 sgd_solver.cpp:105] Iteration 14100, lr = 0.01
I1017 17:28:01.285549 22869 solver.cpp:218] Iteration 14200 (3.29946 iter/s, 30.308s/100 iters), loss = 0.764064
I1017 17:28:01.285650 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.764064 (* 1 = 0.764064 loss)
I1017 17:28:01.285660 22869 sgd_solver.cpp:105] Iteration 14200, lr = 0.01
I1017 17:28:31.542204 22869 solver.cpp:218] Iteration 14300 (3.30507 iter/s, 30.2565s/100 iters), loss = 0.594967
I1017 17:28:31.542338 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.594967 (* 1 = 0.594967 loss)
I1017 17:28:31.542348 22869 sgd_solver.cpp:105] Iteration 14300, lr = 0.01
I1017 17:29:01.827581 22869 solver.cpp:218] Iteration 14400 (3.30194 iter/s, 30.2852s/100 iters), loss = 0.643018
I1017 17:29:01.827728 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.643018 (* 1 = 0.643018 loss)
I1017 17:29:01.827738 22869 sgd_solver.cpp:105] Iteration 14400, lr = 0.01
I1017 17:29:31.804958 22869 solver.cpp:330] Iteration 14500, Testing net (#0)
I1017 17:29:48.272655 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 17:29:48.609268 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.46779 (* 1 = 1.46779 loss)
I1017 17:29:48.609284 22869 solver.cpp:397]     Test net output #1: accuracy = 0.6195
I1017 17:29:48.906906 22869 solver.cpp:218] Iteration 14500 (2.12408 iter/s, 47.0792s/100 iters), loss = 0.708398
I1017 17:29:48.906939 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.708398 (* 1 = 0.708398 loss)
I1017 17:29:48.906944 22869 sgd_solver.cpp:105] Iteration 14500, lr = 0.01
I1017 17:30:19.214936 22869 solver.cpp:218] Iteration 14600 (3.29946 iter/s, 30.308s/100 iters), loss = 0.862599
I1017 17:30:19.215081 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.862599 (* 1 = 0.862599 loss)
I1017 17:30:19.215090 22869 sgd_solver.cpp:105] Iteration 14600, lr = 0.01
I1017 17:30:49.479065 22869 solver.cpp:218] Iteration 14700 (3.30426 iter/s, 30.264s/100 iters), loss = 0.715314
I1017 17:30:49.479141 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.715314 (* 1 = 0.715314 loss)
I1017 17:30:49.479149 22869 sgd_solver.cpp:105] Iteration 14700, lr = 0.01
I1017 17:31:19.783745 22869 solver.cpp:218] Iteration 14800 (3.29983 iter/s, 30.3046s/100 iters), loss = 0.445238
I1017 17:31:19.783872 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.445238 (* 1 = 0.445238 loss)
I1017 17:31:19.783892 22869 sgd_solver.cpp:105] Iteration 14800, lr = 0.01
I1017 17:31:50.009551 22869 solver.cpp:218] Iteration 14900 (3.30844 iter/s, 30.2257s/100 iters), loss = 0.539955
I1017 17:31:50.009655 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.539955 (* 1 = 0.539955 loss)
I1017 17:31:50.009662 22869 sgd_solver.cpp:105] Iteration 14900, lr = 0.01
I1017 17:32:18.770737 22877 data_layer.cpp:73] Restarting data prefetching from start.
I1017 17:32:19.975317 22869 solver.cpp:330] Iteration 15000, Testing net (#0)
I1017 17:32:36.384290 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 17:32:36.720094 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.45454 (* 1 = 1.45454 loss)
I1017 17:32:36.720109 22869 solver.cpp:397]     Test net output #1: accuracy = 0.6262
I1017 17:32:37.017089 22869 solver.cpp:218] Iteration 15000 (2.12732 iter/s, 47.0074s/100 iters), loss = 0.413163
I1017 17:32:37.017122 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.413163 (* 1 = 0.413163 loss)
I1017 17:32:37.017127 22869 sgd_solver.cpp:105] Iteration 15000, lr = 0.01
I1017 17:33:07.316691 22869 solver.cpp:218] Iteration 15100 (3.30038 iter/s, 30.2996s/100 iters), loss = 0.602739
I1017 17:33:07.316787 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.602739 (* 1 = 0.602739 loss)
I1017 17:33:07.316794 22869 sgd_solver.cpp:105] Iteration 15100, lr = 0.01
I1017 17:33:37.552778 22869 solver.cpp:218] Iteration 15200 (3.30732 iter/s, 30.236s/100 iters), loss = 0.628313
I1017 17:33:37.552918 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.628313 (* 1 = 0.628313 loss)
I1017 17:33:37.552927 22869 sgd_solver.cpp:105] Iteration 15200, lr = 0.01
I1017 17:34:07.799479 22869 solver.cpp:218] Iteration 15300 (3.30616 iter/s, 30.2466s/100 iters), loss = 0.80685
I1017 17:34:07.799592 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.80685 (* 1 = 0.80685 loss)
I1017 17:34:07.799609 22869 sgd_solver.cpp:105] Iteration 15300, lr = 0.01
I1017 17:34:38.086485 22869 solver.cpp:218] Iteration 15400 (3.30176 iter/s, 30.2869s/100 iters), loss = 0.576897
I1017 17:34:38.086632 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.576897 (* 1 = 0.576897 loss)
I1017 17:34:38.086639 22869 sgd_solver.cpp:105] Iteration 15400, lr = 0.01
I1017 17:35:08.102795 22869 solver.cpp:330] Iteration 15500, Testing net (#0)
I1017 17:35:24.559727 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 17:35:24.898380 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.49018 (* 1 = 1.49018 loss)
I1017 17:35:24.898394 22869 solver.cpp:397]     Test net output #1: accuracy = 0.62
I1017 17:35:25.194773 22869 solver.cpp:218] Iteration 15500 (2.12278 iter/s, 47.1081s/100 iters), loss = 0.569968
I1017 17:35:25.194808 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.569968 (* 1 = 0.569968 loss)
I1017 17:35:25.194815 22869 sgd_solver.cpp:105] Iteration 15500, lr = 0.01
I1017 17:35:55.520267 22869 solver.cpp:218] Iteration 15600 (3.29756 iter/s, 30.3255s/100 iters), loss = 0.706793
I1017 17:35:55.520370 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.706793 (* 1 = 0.706793 loss)
I1017 17:35:55.520376 22869 sgd_solver.cpp:105] Iteration 15600, lr = 0.01
I1017 17:36:25.811893 22869 solver.cpp:218] Iteration 15700 (3.30125 iter/s, 30.2915s/100 iters), loss = 0.467138
I1017 17:36:25.811997 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.467138 (* 1 = 0.467138 loss)
I1017 17:36:25.812006 22869 sgd_solver.cpp:105] Iteration 15700, lr = 0.01
I1017 17:36:56.097560 22869 solver.cpp:218] Iteration 15800 (3.3019 iter/s, 30.2856s/100 iters), loss = 0.487152
I1017 17:36:56.097693 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.487152 (* 1 = 0.487152 loss)
I1017 17:36:56.097702 22869 sgd_solver.cpp:105] Iteration 15800, lr = 0.01
I1017 17:37:26.398072 22869 solver.cpp:218] Iteration 15900 (3.30029 iter/s, 30.3004s/100 iters), loss = 0.571619
I1017 17:37:26.398226 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.571619 (* 1 = 0.571619 loss)
I1017 17:37:26.398233 22869 sgd_solver.cpp:105] Iteration 15900, lr = 0.01
I1017 17:37:55.170990 22877 data_layer.cpp:73] Restarting data prefetching from start.
I1017 17:37:56.376297 22869 solver.cpp:330] Iteration 16000, Testing net (#0)
I1017 17:38:12.823879 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 17:38:13.161924 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.44961 (* 1 = 1.44961 loss)
I1017 17:38:13.161939 22869 solver.cpp:397]     Test net output #1: accuracy = 0.6268
I1017 17:38:13.461025 22869 solver.cpp:218] Iteration 16000 (2.12482 iter/s, 47.0628s/100 iters), loss = 0.433629
I1017 17:38:13.461055 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.433629 (* 1 = 0.433629 loss)
I1017 17:38:13.461061 22869 sgd_solver.cpp:105] Iteration 16000, lr = 0.01
I1017 17:38:43.773808 22869 solver.cpp:218] Iteration 16100 (3.29894 iter/s, 30.3127s/100 iters), loss = 0.785486
I1017 17:38:43.773952 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.785486 (* 1 = 0.785486 loss)
I1017 17:38:43.773960 22869 sgd_solver.cpp:105] Iteration 16100, lr = 0.01
I1017 17:39:14.016443 22869 solver.cpp:218] Iteration 16200 (3.30661 iter/s, 30.2425s/100 iters), loss = 0.880679
I1017 17:39:14.016588 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.880679 (* 1 = 0.880679 loss)
I1017 17:39:14.016597 22869 sgd_solver.cpp:105] Iteration 16200, lr = 0.01
I1017 17:39:44.293054 22869 solver.cpp:218] Iteration 16300 (3.3029 iter/s, 30.2765s/100 iters), loss = 0.61084
I1017 17:39:44.293210 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.61084 (* 1 = 0.61084 loss)
I1017 17:39:44.293221 22869 sgd_solver.cpp:105] Iteration 16300, lr = 0.01
I1017 17:40:14.565837 22869 solver.cpp:218] Iteration 16400 (3.30331 iter/s, 30.2726s/100 iters), loss = 0.560969
I1017 17:40:14.565961 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.560969 (* 1 = 0.560969 loss)
I1017 17:40:14.565979 22869 sgd_solver.cpp:105] Iteration 16400, lr = 0.01
I1017 17:40:44.542168 22869 solver.cpp:330] Iteration 16500, Testing net (#0)
I1017 17:41:00.954850 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 17:41:01.288951 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.50159 (* 1 = 1.50159 loss)
I1017 17:41:01.288969 22869 solver.cpp:397]     Test net output #1: accuracy = 0.623
I1017 17:41:01.585242 22869 solver.cpp:218] Iteration 16500 (2.12679 iter/s, 47.0193s/100 iters), loss = 0.444927
I1017 17:41:01.585273 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.444928 (* 1 = 0.444928 loss)
I1017 17:41:01.585280 22869 sgd_solver.cpp:105] Iteration 16500, lr = 0.01
I1017 17:41:31.869751 22869 solver.cpp:218] Iteration 16600 (3.30202 iter/s, 30.2845s/100 iters), loss = 0.475918
I1017 17:41:31.869865 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.475919 (* 1 = 0.475919 loss)
I1017 17:41:31.869886 22869 sgd_solver.cpp:105] Iteration 16600, lr = 0.01
I1017 17:42:02.164863 22869 solver.cpp:218] Iteration 16700 (3.30087 iter/s, 30.295s/100 iters), loss = 0.443304
I1017 17:42:02.164961 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.443304 (* 1 = 0.443304 loss)
I1017 17:42:02.164968 22869 sgd_solver.cpp:105] Iteration 16700, lr = 0.01
I1017 17:42:32.415433 22869 solver.cpp:218] Iteration 16800 (3.30573 iter/s, 30.2505s/100 iters), loss = 0.431066
I1017 17:42:32.415556 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.431066 (* 1 = 0.431066 loss)
I1017 17:42:32.415565 22869 sgd_solver.cpp:105] Iteration 16800, lr = 0.01
I1017 17:43:02.717408 22869 solver.cpp:218] Iteration 16900 (3.30013 iter/s, 30.3018s/100 iters), loss = 0.551368
I1017 17:43:02.717541 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.551368 (* 1 = 0.551368 loss)
I1017 17:43:02.717548 22869 sgd_solver.cpp:105] Iteration 16900, lr = 0.01
I1017 17:43:31.520548 22877 data_layer.cpp:73] Restarting data prefetching from start.
I1017 17:43:32.726622 22869 solver.cpp:330] Iteration 17000, Testing net (#0)
I1017 17:43:49.233023 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 17:43:49.569070 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.44728 (* 1 = 1.44728 loss)
I1017 17:43:49.569087 22869 solver.cpp:397]     Test net output #1: accuracy = 0.6364
I1017 17:43:49.867252 22869 solver.cpp:218] Iteration 17000 (2.1209 iter/s, 47.1497s/100 iters), loss = 0.371499
I1017 17:43:49.867286 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.371499 (* 1 = 0.371499 loss)
I1017 17:43:49.867293 22869 sgd_solver.cpp:105] Iteration 17000, lr = 0.01
I1017 17:44:20.117077 22869 solver.cpp:218] Iteration 17100 (3.30581 iter/s, 30.2498s/100 iters), loss = 0.630865
I1017 17:44:20.117223 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.630865 (* 1 = 0.630865 loss)
I1017 17:44:20.117233 22869 sgd_solver.cpp:105] Iteration 17100, lr = 0.01
I1017 17:44:50.432759 22869 solver.cpp:218] Iteration 17200 (3.29864 iter/s, 30.3155s/100 iters), loss = 0.915408
I1017 17:44:50.432868 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.915408 (* 1 = 0.915408 loss)
I1017 17:44:50.432875 22869 sgd_solver.cpp:105] Iteration 17200, lr = 0.01
I1017 17:45:20.706490 22869 solver.cpp:218] Iteration 17300 (3.30321 iter/s, 30.2736s/100 iters), loss = 0.566235
I1017 17:45:20.706629 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.566235 (* 1 = 0.566235 loss)
I1017 17:45:20.706638 22869 sgd_solver.cpp:105] Iteration 17300, lr = 0.01
I1017 17:45:50.970633 22869 solver.cpp:218] Iteration 17400 (3.30426 iter/s, 30.264s/100 iters), loss = 0.374224
I1017 17:45:50.970772 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.374224 (* 1 = 0.374224 loss)
I1017 17:45:50.970790 22869 sgd_solver.cpp:105] Iteration 17400, lr = 0.01
I1017 17:46:20.974457 22869 solver.cpp:330] Iteration 17500, Testing net (#0)
I1017 17:46:37.302750 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 17:46:37.636790 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.488 (* 1 = 1.488 loss)
I1017 17:46:37.636806 22869 solver.cpp:397]     Test net output #1: accuracy = 0.6322
I1017 17:46:37.932368 22869 solver.cpp:218] Iteration 17500 (2.1294 iter/s, 46.9616s/100 iters), loss = 0.654849
I1017 17:46:37.932405 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.654849 (* 1 = 0.654849 loss)
I1017 17:46:37.932412 22869 sgd_solver.cpp:105] Iteration 17500, lr = 0.01
I1017 17:47:08.032970 22869 solver.cpp:218] Iteration 17600 (3.3222 iter/s, 30.1006s/100 iters), loss = 0.751004
I1017 17:47:08.033113 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.751003 (* 1 = 0.751003 loss)
I1017 17:47:08.033121 22869 sgd_solver.cpp:105] Iteration 17600, lr = 0.01
I1017 17:47:38.135119 22869 solver.cpp:218] Iteration 17700 (3.32204 iter/s, 30.102s/100 iters), loss = 0.451791
I1017 17:47:38.135231 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.45179 (* 1 = 0.45179 loss)
I1017 17:47:38.135237 22869 sgd_solver.cpp:105] Iteration 17700, lr = 0.01
I1017 17:48:08.239673 22869 solver.cpp:218] Iteration 17800 (3.32177 iter/s, 30.1045s/100 iters), loss = 0.470273
I1017 17:48:08.239806 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.470273 (* 1 = 0.470273 loss)
I1017 17:48:08.239815 22869 sgd_solver.cpp:105] Iteration 17800, lr = 0.01
I1017 17:48:38.344245 22869 solver.cpp:218] Iteration 17900 (3.32177 iter/s, 30.1044s/100 iters), loss = 0.541508
I1017 17:48:38.344389 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.541508 (* 1 = 0.541508 loss)
I1017 17:48:38.344398 22869 sgd_solver.cpp:105] Iteration 17900, lr = 0.01
I1017 17:49:06.962621 22877 data_layer.cpp:73] Restarting data prefetching from start.
I1017 17:49:08.164459 22869 solver.cpp:330] Iteration 18000, Testing net (#0)
I1017 17:49:24.517202 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 17:49:24.850713 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.4615 (* 1 = 1.4615 loss)
I1017 17:49:24.850729 22869 solver.cpp:397]     Test net output #1: accuracy = 0.6355
I1017 17:49:25.145458 22869 solver.cpp:218] Iteration 18000 (2.1367 iter/s, 46.8011s/100 iters), loss = 0.355753
I1017 17:49:25.145488 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.355753 (* 1 = 0.355753 loss)
I1017 17:49:25.145494 22869 sgd_solver.cpp:105] Iteration 18000, lr = 0.01
I1017 17:49:55.286957 22869 solver.cpp:218] Iteration 18100 (3.31769 iter/s, 30.1415s/100 iters), loss = 0.541847
I1017 17:49:55.287081 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.541847 (* 1 = 0.541847 loss)
I1017 17:49:55.287088 22869 sgd_solver.cpp:105] Iteration 18100, lr = 0.01
I1017 17:50:25.408107 22869 solver.cpp:218] Iteration 18200 (3.31994 iter/s, 30.121s/100 iters), loss = 0.551467
I1017 17:50:25.408246 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.551466 (* 1 = 0.551466 loss)
I1017 17:50:25.408254 22869 sgd_solver.cpp:105] Iteration 18200, lr = 0.01
I1017 17:50:55.544061 22869 solver.cpp:218] Iteration 18300 (3.31831 iter/s, 30.1358s/100 iters), loss = 0.491291
I1017 17:50:55.544165 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.49129 (* 1 = 0.49129 loss)
I1017 17:50:55.544173 22869 sgd_solver.cpp:105] Iteration 18300, lr = 0.01
I1017 17:51:25.674266 22869 solver.cpp:218] Iteration 18400 (3.31894 iter/s, 30.1301s/100 iters), loss = 0.414981
I1017 17:51:25.674407 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.414981 (* 1 = 0.414981 loss)
I1017 17:51:25.674415 22869 sgd_solver.cpp:105] Iteration 18400, lr = 0.01
I1017 17:51:55.499100 22869 solver.cpp:330] Iteration 18500, Testing net (#0)
I1017 17:52:11.870368 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 17:52:12.206317 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.48732 (* 1 = 1.48732 loss)
I1017 17:52:12.206334 22869 solver.cpp:397]     Test net output #1: accuracy = 0.634
I1017 17:52:12.504556 22869 solver.cpp:218] Iteration 18500 (2.13538 iter/s, 46.8302s/100 iters), loss = 0.546926
I1017 17:52:12.504588 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.546926 (* 1 = 0.546926 loss)
I1017 17:52:12.504595 22869 sgd_solver.cpp:105] Iteration 18500, lr = 0.01
I1017 17:52:42.599375 22869 solver.cpp:218] Iteration 18600 (3.32283 iter/s, 30.0948s/100 iters), loss = 0.430284
I1017 17:52:42.599516 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.430284 (* 1 = 0.430284 loss)
I1017 17:52:42.599524 22869 sgd_solver.cpp:105] Iteration 18600, lr = 0.01
I1017 17:53:12.720485 22869 solver.cpp:218] Iteration 18700 (3.31995 iter/s, 30.121s/100 iters), loss = 0.481055
I1017 17:53:12.720608 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.481055 (* 1 = 0.481055 loss)
I1017 17:53:12.720616 22869 sgd_solver.cpp:105] Iteration 18700, lr = 0.01
I1017 17:53:42.824167 22869 solver.cpp:218] Iteration 18800 (3.32187 iter/s, 30.1036s/100 iters), loss = 0.405792
I1017 17:53:42.824313 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.405792 (* 1 = 0.405792 loss)
I1017 17:53:42.824321 22869 sgd_solver.cpp:105] Iteration 18800, lr = 0.01
I1017 17:54:12.938985 22869 solver.cpp:218] Iteration 18900 (3.32064 iter/s, 30.1147s/100 iters), loss = 0.391919
I1017 17:54:12.939129 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.391919 (* 1 = 0.391919 loss)
I1017 17:54:12.939137 22869 sgd_solver.cpp:105] Iteration 18900, lr = 0.01
I1017 17:54:41.545361 22877 data_layer.cpp:73] Restarting data prefetching from start.
I1017 17:54:42.753190 22869 solver.cpp:330] Iteration 19000, Testing net (#0)
I1017 17:54:59.110193 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 17:54:59.445405 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.4628 (* 1 = 1.4628 loss)
I1017 17:54:59.445420 22869 solver.cpp:397]     Test net output #1: accuracy = 0.6409
I1017 17:54:59.741654 22869 solver.cpp:218] Iteration 19000 (2.13664 iter/s, 46.8025s/100 iters), loss = 0.230668
I1017 17:54:59.741688 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.230668 (* 1 = 0.230668 loss)
I1017 17:54:59.741695 22869 sgd_solver.cpp:105] Iteration 19000, lr = 0.01
I1017 17:55:29.842648 22869 solver.cpp:218] Iteration 19100 (3.32215 iter/s, 30.101s/100 iters), loss = 0.582193
I1017 17:55:29.842794 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.582193 (* 1 = 0.582193 loss)
I1017 17:55:29.842803 22869 sgd_solver.cpp:105] Iteration 19100, lr = 0.01
I1017 17:55:59.946055 22869 solver.cpp:218] Iteration 19200 (3.3219 iter/s, 30.1033s/100 iters), loss = 0.276598
I1017 17:55:59.946204 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.276597 (* 1 = 0.276597 loss)
I1017 17:55:59.946214 22869 sgd_solver.cpp:105] Iteration 19200, lr = 0.01
I1017 17:56:30.051556 22869 solver.cpp:218] Iteration 19300 (3.32167 iter/s, 30.1054s/100 iters), loss = 0.47984
I1017 17:56:30.051694 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.479839 (* 1 = 0.479839 loss)
I1017 17:56:30.051702 22869 sgd_solver.cpp:105] Iteration 19300, lr = 0.01
I1017 17:57:00.169347 22869 solver.cpp:218] Iteration 19400 (3.32031 iter/s, 30.1177s/100 iters), loss = 0.620348
I1017 17:57:00.169489 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.620348 (* 1 = 0.620348 loss)
I1017 17:57:00.169499 22869 sgd_solver.cpp:105] Iteration 19400, lr = 0.01
I1017 17:57:29.987383 22869 solver.cpp:330] Iteration 19500, Testing net (#0)
I1017 17:57:46.338469 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 17:57:46.673224 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.54114 (* 1 = 1.54114 loss)
I1017 17:57:46.673239 22869 solver.cpp:397]     Test net output #1: accuracy = 0.6361
I1017 17:57:46.970096 22869 solver.cpp:218] Iteration 19500 (2.13672 iter/s, 46.8006s/100 iters), loss = 0.449852
I1017 17:57:46.970144 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.449852 (* 1 = 0.449852 loss)
I1017 17:57:46.970150 22869 sgd_solver.cpp:105] Iteration 19500, lr = 0.01
I1017 17:58:17.071938 22869 solver.cpp:218] Iteration 19600 (3.32206 iter/s, 30.1018s/100 iters), loss = 0.365885
I1017 17:58:17.072059 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.365885 (* 1 = 0.365885 loss)
I1017 17:58:17.072077 22869 sgd_solver.cpp:105] Iteration 19600, lr = 0.01
I1017 17:58:47.194825 22869 solver.cpp:218] Iteration 19700 (3.31975 iter/s, 30.1228s/100 iters), loss = 0.261183
I1017 17:58:47.194947 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.261183 (* 1 = 0.261183 loss)
I1017 17:58:47.194955 22869 sgd_solver.cpp:105] Iteration 19700, lr = 0.01
I1017 17:59:17.302057 22869 solver.cpp:218] Iteration 19800 (3.32148 iter/s, 30.1071s/100 iters), loss = 0.304073
I1017 17:59:17.302175 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.304072 (* 1 = 0.304072 loss)
I1017 17:59:17.302183 22869 sgd_solver.cpp:105] Iteration 19800, lr = 0.01
I1017 17:59:47.410902 22869 solver.cpp:218] Iteration 19900 (3.3213 iter/s, 30.1087s/100 iters), loss = 0.394155
I1017 17:59:47.411043 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.394154 (* 1 = 0.394154 loss)
I1017 17:59:47.411051 22869 sgd_solver.cpp:105] Iteration 19900, lr = 0.01
I1017 18:00:16.025593 22877 data_layer.cpp:73] Restarting data prefetching from start.
I1017 18:00:17.231166 22869 solver.cpp:330] Iteration 20000, Testing net (#0)
I1017 18:00:33.573137 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 18:00:33.907799 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.50983 (* 1 = 1.50983 loss)
I1017 18:00:33.907814 22869 solver.cpp:397]     Test net output #1: accuracy = 0.6369
I1017 18:00:34.203994 22869 solver.cpp:218] Iteration 20000 (2.13707 iter/s, 46.793s/100 iters), loss = 0.372959
I1017 18:00:34.204030 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.372958 (* 1 = 0.372958 loss)
I1017 18:00:34.204036 22869 sgd_solver.cpp:105] Iteration 20000, lr = 0.01
I1017 18:01:04.319756 22869 solver.cpp:218] Iteration 20100 (3.32052 iter/s, 30.1157s/100 iters), loss = 0.489757
I1017 18:01:04.319869 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.489757 (* 1 = 0.489757 loss)
I1017 18:01:04.319886 22869 sgd_solver.cpp:105] Iteration 20100, lr = 0.01
I1017 18:01:34.430090 22869 solver.cpp:218] Iteration 20200 (3.32113 iter/s, 30.1102s/100 iters), loss = 0.396108
I1017 18:01:34.430238 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.396108 (* 1 = 0.396108 loss)
I1017 18:01:34.430246 22869 sgd_solver.cpp:105] Iteration 20200, lr = 0.01
I1017 18:02:04.544814 22869 solver.cpp:218] Iteration 20300 (3.32065 iter/s, 30.1146s/100 iters), loss = 0.391491
I1017 18:02:04.544912 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.391491 (* 1 = 0.391491 loss)
I1017 18:02:04.544929 22869 sgd_solver.cpp:105] Iteration 20300, lr = 0.01
I1017 18:02:34.650450 22869 solver.cpp:218] Iteration 20400 (3.32165 iter/s, 30.1055s/100 iters), loss = 0.603105
I1017 18:02:34.650586 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.603105 (* 1 = 0.603105 loss)
I1017 18:02:34.650593 22869 sgd_solver.cpp:105] Iteration 20400, lr = 0.01
I1017 18:03:04.471532 22869 solver.cpp:330] Iteration 20500, Testing net (#0)
I1017 18:03:20.809574 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 18:03:21.143553 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.55973 (* 1 = 1.55973 loss)
I1017 18:03:21.143569 22869 solver.cpp:397]     Test net output #1: accuracy = 0.6252
I1017 18:03:21.439968 22869 solver.cpp:218] Iteration 20500 (2.13724 iter/s, 46.7894s/100 iters), loss = 0.443398
I1017 18:03:21.440001 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.443398 (* 1 = 0.443398 loss)
I1017 18:03:21.440007 22869 sgd_solver.cpp:105] Iteration 20500, lr = 0.01
I1017 18:03:51.554599 22869 solver.cpp:218] Iteration 20600 (3.32065 iter/s, 30.1146s/100 iters), loss = 0.444792
I1017 18:03:51.554765 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.444792 (* 1 = 0.444792 loss)
I1017 18:03:51.554774 22869 sgd_solver.cpp:105] Iteration 20600, lr = 0.01
I1017 18:04:21.660506 22869 solver.cpp:218] Iteration 20700 (3.32163 iter/s, 30.1057s/100 iters), loss = 0.267097
I1017 18:04:21.660607 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.267097 (* 1 = 0.267097 loss)
I1017 18:04:21.660614 22869 sgd_solver.cpp:105] Iteration 20700, lr = 0.01
I1017 18:04:51.769131 22869 solver.cpp:218] Iteration 20800 (3.32132 iter/s, 30.1085s/100 iters), loss = 0.374077
I1017 18:04:51.769279 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.374077 (* 1 = 0.374077 loss)
I1017 18:04:51.769289 22869 sgd_solver.cpp:105] Iteration 20800, lr = 0.01
I1017 18:05:21.860329 22869 solver.cpp:218] Iteration 20900 (3.32325 iter/s, 30.0911s/100 iters), loss = 0.299314
I1017 18:05:21.860426 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.299313 (* 1 = 0.299313 loss)
I1017 18:05:21.860433 22869 sgd_solver.cpp:105] Iteration 20900, lr = 0.01
I1017 18:05:50.465515 22877 data_layer.cpp:73] Restarting data prefetching from start.
I1017 18:05:51.675108 22869 solver.cpp:330] Iteration 21000, Testing net (#0)
I1017 18:06:08.031021 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 18:06:08.365434 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.51371 (* 1 = 1.51371 loss)
I1017 18:06:08.365450 22869 solver.cpp:397]     Test net output #1: accuracy = 0.6413
I1017 18:06:08.659358 22869 solver.cpp:218] Iteration 21000 (2.1368 iter/s, 46.7989s/100 iters), loss = 0.334594
I1017 18:06:08.659389 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.334594 (* 1 = 0.334594 loss)
I1017 18:06:08.659395 22869 sgd_solver.cpp:105] Iteration 21000, lr = 0.01
I1017 18:06:38.768463 22869 solver.cpp:218] Iteration 21100 (3.32126 iter/s, 30.1091s/100 iters), loss = 0.523372
I1017 18:06:38.768548 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.523371 (* 1 = 0.523371 loss)
I1017 18:06:38.768564 22869 sgd_solver.cpp:105] Iteration 21100, lr = 0.01
I1017 18:07:08.854043 22869 solver.cpp:218] Iteration 21200 (3.32386 iter/s, 30.0855s/100 iters), loss = 0.600882
I1017 18:07:08.854188 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.600882 (* 1 = 0.600882 loss)
I1017 18:07:08.854197 22869 sgd_solver.cpp:105] Iteration 21200, lr = 0.01
I1017 18:07:38.956468 22869 solver.cpp:218] Iteration 21300 (3.32201 iter/s, 30.1023s/100 iters), loss = 0.404151
I1017 18:07:38.956593 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.404151 (* 1 = 0.404151 loss)
I1017 18:07:38.956600 22869 sgd_solver.cpp:105] Iteration 21300, lr = 0.01
I1017 18:08:09.058032 22869 solver.cpp:218] Iteration 21400 (3.3221 iter/s, 30.1014s/100 iters), loss = 0.41772
I1017 18:08:09.058145 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.417719 (* 1 = 0.417719 loss)
I1017 18:08:09.058153 22869 sgd_solver.cpp:105] Iteration 21400, lr = 0.01
I1017 18:08:38.864468 22869 solver.cpp:330] Iteration 21500, Testing net (#0)
I1017 18:08:55.221817 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 18:08:55.556617 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.56664 (* 1 = 1.56664 loss)
I1017 18:08:55.556632 22869 solver.cpp:397]     Test net output #1: accuracy = 0.6312
I1017 18:08:55.852529 22869 solver.cpp:218] Iteration 21500 (2.13701 iter/s, 46.7944s/100 iters), loss = 0.406161
I1017 18:08:55.852562 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.40616 (* 1 = 0.40616 loss)
I1017 18:08:55.852571 22869 sgd_solver.cpp:105] Iteration 21500, lr = 0.01
I1017 18:09:25.961727 22869 solver.cpp:218] Iteration 21600 (3.32125 iter/s, 30.1092s/100 iters), loss = 0.476411
I1017 18:09:25.961877 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.47641 (* 1 = 0.47641 loss)
I1017 18:09:25.961905 22869 sgd_solver.cpp:105] Iteration 21600, lr = 0.01
I1017 18:09:56.079550 22869 solver.cpp:218] Iteration 21700 (3.32031 iter/s, 30.1177s/100 iters), loss = 0.3826
I1017 18:09:56.079707 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.3826 (* 1 = 0.3826 loss)
I1017 18:09:56.079717 22869 sgd_solver.cpp:105] Iteration 21700, lr = 0.01
I1017 18:10:26.171937 22869 solver.cpp:218] Iteration 21800 (3.32312 iter/s, 30.0922s/100 iters), loss = 0.387635
I1017 18:10:26.172050 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.387634 (* 1 = 0.387634 loss)
I1017 18:10:26.172058 22869 sgd_solver.cpp:105] Iteration 21800, lr = 0.01
I1017 18:10:56.274821 22869 solver.cpp:218] Iteration 21900 (3.32195 iter/s, 30.1028s/100 iters), loss = 0.565627
I1017 18:10:56.274969 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.565627 (* 1 = 0.565627 loss)
I1017 18:10:56.274988 22869 sgd_solver.cpp:105] Iteration 21900, lr = 0.01
I1017 18:11:24.866926 22877 data_layer.cpp:73] Restarting data prefetching from start.
I1017 18:11:26.069581 22869 solver.cpp:330] Iteration 22000, Testing net (#0)
I1017 18:11:42.405215 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 18:11:42.740262 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.5146 (* 1 = 1.5146 loss)
I1017 18:11:42.740278 22869 solver.cpp:397]     Test net output #1: accuracy = 0.6418
I1017 18:11:43.036523 22869 solver.cpp:218] Iteration 22000 (2.13851 iter/s, 46.7616s/100 iters), loss = 0.172159
I1017 18:11:43.036552 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.172159 (* 1 = 0.172159 loss)
I1017 18:11:43.036559 22869 sgd_solver.cpp:105] Iteration 22000, lr = 0.01
I1017 18:12:13.144711 22869 solver.cpp:218] Iteration 22100 (3.32136 iter/s, 30.1082s/100 iters), loss = 0.395408
I1017 18:12:13.144865 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.395407 (* 1 = 0.395407 loss)
I1017 18:12:13.144873 22869 sgd_solver.cpp:105] Iteration 22100, lr = 0.01
I1017 18:12:43.255550 22869 solver.cpp:218] Iteration 22200 (3.32108 iter/s, 30.1107s/100 iters), loss = 0.49804
I1017 18:12:43.255650 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.498039 (* 1 = 0.498039 loss)
I1017 18:12:43.255657 22869 sgd_solver.cpp:105] Iteration 22200, lr = 0.01
I1017 18:13:13.370524 22869 solver.cpp:218] Iteration 22300 (3.32062 iter/s, 30.1149s/100 iters), loss = 0.545307
I1017 18:13:13.370662 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.545306 (* 1 = 0.545306 loss)
I1017 18:13:13.370669 22869 sgd_solver.cpp:105] Iteration 22300, lr = 0.01
I1017 18:13:43.475349 22869 solver.cpp:218] Iteration 22400 (3.32174 iter/s, 30.1047s/100 iters), loss = 0.441966
I1017 18:13:43.475487 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.441965 (* 1 = 0.441965 loss)
I1017 18:13:43.475494 22869 sgd_solver.cpp:105] Iteration 22400, lr = 0.01
I1017 18:14:13.286420 22869 solver.cpp:330] Iteration 22500, Testing net (#0)
I1017 18:14:29.642431 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 18:14:29.976387 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.58482 (* 1 = 1.58482 loss)
I1017 18:14:29.976402 22869 solver.cpp:397]     Test net output #1: accuracy = 0.6356
I1017 18:14:30.271760 22869 solver.cpp:218] Iteration 22500 (2.13692 iter/s, 46.7963s/100 iters), loss = 0.481539
I1017 18:14:30.271796 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.481538 (* 1 = 0.481538 loss)
I1017 18:14:30.271803 22869 sgd_solver.cpp:105] Iteration 22500, lr = 0.01
I1017 18:15:00.373216 22869 solver.cpp:218] Iteration 22600 (3.3221 iter/s, 30.1014s/100 iters), loss = 0.494278
I1017 18:15:00.373354 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.494277 (* 1 = 0.494277 loss)
I1017 18:15:00.373373 22869 sgd_solver.cpp:105] Iteration 22600, lr = 0.01
I1017 18:15:30.482205 22869 solver.cpp:218] Iteration 22700 (3.32128 iter/s, 30.1089s/100 iters), loss = 0.243757
I1017 18:15:30.482347 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.243756 (* 1 = 0.243756 loss)
I1017 18:15:30.482365 22869 sgd_solver.cpp:105] Iteration 22700, lr = 0.01
I1017 18:16:00.597735 22869 solver.cpp:218] Iteration 22800 (3.32056 iter/s, 30.1154s/100 iters), loss = 0.408236
I1017 18:16:00.597859 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.408235 (* 1 = 0.408235 loss)
I1017 18:16:00.597867 22869 sgd_solver.cpp:105] Iteration 22800, lr = 0.01
I1017 18:16:30.707728 22869 solver.cpp:218] Iteration 22900 (3.32117 iter/s, 30.1099s/100 iters), loss = 0.381456
I1017 18:16:30.707864 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.381455 (* 1 = 0.381455 loss)
I1017 18:16:30.707871 22869 sgd_solver.cpp:105] Iteration 22900, lr = 0.01
I1017 18:16:59.313024 22877 data_layer.cpp:73] Restarting data prefetching from start.
I1017 18:17:00.519974 22869 solver.cpp:330] Iteration 23000, Testing net (#0)
I1017 18:17:16.863324 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 18:17:17.196300 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.52335 (* 1 = 1.52335 loss)
I1017 18:17:17.196316 22869 solver.cpp:397]     Test net output #1: accuracy = 0.6456
I1017 18:17:17.490706 22869 solver.cpp:218] Iteration 23000 (2.13754 iter/s, 46.7828s/100 iters), loss = 0.141293
I1017 18:17:17.490736 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.141292 (* 1 = 0.141292 loss)
I1017 18:17:17.490742 22869 sgd_solver.cpp:105] Iteration 23000, lr = 0.01
I1017 18:17:47.587170 22869 solver.cpp:218] Iteration 23100 (3.32266 iter/s, 30.0964s/100 iters), loss = 0.378802
I1017 18:17:47.587307 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.378801 (* 1 = 0.378801 loss)
I1017 18:17:47.587314 22869 sgd_solver.cpp:105] Iteration 23100, lr = 0.01
I1017 18:18:17.699223 22869 solver.cpp:218] Iteration 23200 (3.32094 iter/s, 30.1119s/100 iters), loss = 0.275773
I1017 18:18:17.699358 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.275772 (* 1 = 0.275772 loss)
I1017 18:18:17.699367 22869 sgd_solver.cpp:105] Iteration 23200, lr = 0.01
I1017 18:18:47.831369 22869 solver.cpp:218] Iteration 23300 (3.31873 iter/s, 30.132s/100 iters), loss = 0.220117
I1017 18:18:47.831513 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.220117 (* 1 = 0.220117 loss)
I1017 18:18:47.831533 22869 sgd_solver.cpp:105] Iteration 23300, lr = 0.01
I1017 18:19:17.924515 22869 solver.cpp:218] Iteration 23400 (3.32303 iter/s, 30.093s/100 iters), loss = 0.266509
I1017 18:19:17.924661 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.266508 (* 1 = 0.266508 loss)
I1017 18:19:17.924681 22869 sgd_solver.cpp:105] Iteration 23400, lr = 0.01
I1017 18:19:47.742148 22869 solver.cpp:330] Iteration 23500, Testing net (#0)
I1017 18:20:04.080224 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 18:20:04.415333 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.63059 (* 1 = 1.63059 loss)
I1017 18:20:04.415349 22869 solver.cpp:397]     Test net output #1: accuracy = 0.6282
I1017 18:20:04.712081 22869 solver.cpp:218] Iteration 23500 (2.13733 iter/s, 46.7874s/100 iters), loss = 0.507878
I1017 18:20:04.712117 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.507877 (* 1 = 0.507877 loss)
I1017 18:20:04.712124 22869 sgd_solver.cpp:105] Iteration 23500, lr = 0.01
I1017 18:20:34.831059 22869 solver.cpp:218] Iteration 23600 (3.32017 iter/s, 30.1189s/100 iters), loss = 0.292796
I1017 18:20:34.831192 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.292795 (* 1 = 0.292795 loss)
I1017 18:20:34.831200 22869 sgd_solver.cpp:105] Iteration 23600, lr = 0.01
I1017 18:21:04.975734 22869 solver.cpp:218] Iteration 23700 (3.31735 iter/s, 30.1445s/100 iters), loss = 0.25005
I1017 18:21:04.976052 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.250049 (* 1 = 0.250049 loss)
I1017 18:21:04.976061 22869 sgd_solver.cpp:105] Iteration 23700, lr = 0.01
I1017 18:21:35.108685 22869 solver.cpp:218] Iteration 23800 (3.31866 iter/s, 30.1326s/100 iters), loss = 0.242095
I1017 18:21:35.108794 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.242094 (* 1 = 0.242094 loss)
I1017 18:21:35.108813 22869 sgd_solver.cpp:105] Iteration 23800, lr = 0.01
I1017 18:22:05.235208 22869 solver.cpp:218] Iteration 23900 (3.31935 iter/s, 30.1264s/100 iters), loss = 0.282878
I1017 18:22:05.235313 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.282878 (* 1 = 0.282878 loss)
I1017 18:22:05.235321 22869 sgd_solver.cpp:105] Iteration 23900, lr = 0.01
I1017 18:22:33.840487 22877 data_layer.cpp:73] Restarting data prefetching from start.
I1017 18:22:35.044517 22869 solver.cpp:330] Iteration 24000, Testing net (#0)
I1017 18:22:51.385488 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 18:22:51.719491 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.50201 (* 1 = 1.50201 loss)
I1017 18:22:51.719506 22869 solver.cpp:397]     Test net output #1: accuracy = 0.6501
I1017 18:22:52.017405 22869 solver.cpp:218] Iteration 24000 (2.13757 iter/s, 46.7821s/100 iters), loss = 0.143767
I1017 18:22:52.017439 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.143766 (* 1 = 0.143766 loss)
I1017 18:22:52.017446 22869 sgd_solver.cpp:105] Iteration 24000, lr = 0.01
I1017 18:23:22.125252 22869 solver.cpp:218] Iteration 24100 (3.3214 iter/s, 30.1078s/100 iters), loss = 0.303253
I1017 18:23:22.125350 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.303252 (* 1 = 0.303252 loss)
I1017 18:23:22.125357 22869 sgd_solver.cpp:105] Iteration 24100, lr = 0.01
I1017 18:23:52.235590 22869 solver.cpp:218] Iteration 24200 (3.32113 iter/s, 30.1102s/100 iters), loss = 0.404571
I1017 18:23:52.235702 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.40457 (* 1 = 0.40457 loss)
I1017 18:23:52.235709 22869 sgd_solver.cpp:105] Iteration 24200, lr = 0.01
I1017 18:24:22.358626 22869 solver.cpp:218] Iteration 24300 (3.31973 iter/s, 30.1229s/100 iters), loss = 0.402673
I1017 18:24:22.358724 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.402672 (* 1 = 0.402672 loss)
I1017 18:24:22.358731 22869 sgd_solver.cpp:105] Iteration 24300, lr = 0.01
I1017 18:24:52.465927 22869 solver.cpp:218] Iteration 24400 (3.32146 iter/s, 30.1072s/100 iters), loss = 0.267136
I1017 18:24:52.466024 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.267135 (* 1 = 0.267135 loss)
I1017 18:24:52.466032 22869 sgd_solver.cpp:105] Iteration 24400, lr = 0.01
I1017 18:25:22.280577 22869 solver.cpp:330] Iteration 24500, Testing net (#0)
I1017 18:25:38.633460 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 18:25:38.966871 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.57109 (* 1 = 1.57109 loss)
I1017 18:25:38.966887 22869 solver.cpp:397]     Test net output #1: accuracy = 0.6376
I1017 18:25:39.262492 22869 solver.cpp:218] Iteration 24500 (2.13691 iter/s, 46.7965s/100 iters), loss = 0.461499
I1017 18:25:39.262526 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.461498 (* 1 = 0.461498 loss)
I1017 18:25:39.262533 22869 sgd_solver.cpp:105] Iteration 24500, lr = 0.01
I1017 18:26:09.365948 22869 solver.cpp:218] Iteration 24600 (3.32188 iter/s, 30.1034s/100 iters), loss = 0.36089
I1017 18:26:09.366092 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.360889 (* 1 = 0.360889 loss)
I1017 18:26:09.366101 22869 sgd_solver.cpp:105] Iteration 24600, lr = 0.01
I1017 18:26:39.479473 22869 solver.cpp:218] Iteration 24700 (3.32078 iter/s, 30.1134s/100 iters), loss = 0.263113
I1017 18:26:39.479606 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.263112 (* 1 = 0.263112 loss)
I1017 18:26:39.479614 22869 sgd_solver.cpp:105] Iteration 24700, lr = 0.01
I1017 18:27:09.581730 22869 solver.cpp:218] Iteration 24800 (3.32202 iter/s, 30.1021s/100 iters), loss = 0.168505
I1017 18:27:09.581876 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.168504 (* 1 = 0.168504 loss)
I1017 18:27:09.581885 22869 sgd_solver.cpp:105] Iteration 24800, lr = 0.01
I1017 18:27:39.683490 22869 solver.cpp:218] Iteration 24900 (3.32208 iter/s, 30.1016s/100 iters), loss = 0.204304
I1017 18:27:39.683600 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.204302 (* 1 = 0.204302 loss)
I1017 18:27:39.683607 22869 sgd_solver.cpp:105] Iteration 24900, lr = 0.01
I1017 18:28:08.299983 22877 data_layer.cpp:73] Restarting data prefetching from start.
I1017 18:28:09.501315 22869 solver.cpp:330] Iteration 25000, Testing net (#0)
I1017 18:28:25.843384 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 18:28:26.177335 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.56029 (* 1 = 1.56029 loss)
I1017 18:28:26.177350 22869 solver.cpp:397]     Test net output #1: accuracy = 0.6408
I1017 18:28:26.471254 22869 solver.cpp:218] Iteration 25000 (2.13732 iter/s, 46.7877s/100 iters), loss = 0.555966
I1017 18:28:26.471287 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.555965 (* 1 = 0.555965 loss)
I1017 18:28:26.471304 22869 sgd_solver.cpp:105] Iteration 25000, lr = 0.01
I1017 18:28:56.565826 22869 solver.cpp:218] Iteration 25100 (3.32286 iter/s, 30.0945s/100 iters), loss = 0.268967
I1017 18:28:56.565940 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.268966 (* 1 = 0.268966 loss)
I1017 18:28:56.565958 22869 sgd_solver.cpp:105] Iteration 25100, lr = 0.01
I1017 18:29:26.673758 22869 solver.cpp:218] Iteration 25200 (3.3214 iter/s, 30.1078s/100 iters), loss = 0.476173
I1017 18:29:26.673897 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.476172 (* 1 = 0.476172 loss)
I1017 18:29:26.673905 22869 sgd_solver.cpp:105] Iteration 25200, lr = 0.01
I1017 18:29:56.800539 22869 solver.cpp:218] Iteration 25300 (3.31932 iter/s, 30.1266s/100 iters), loss = 0.31491
I1017 18:29:56.800904 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.314909 (* 1 = 0.314909 loss)
I1017 18:29:56.800911 22869 sgd_solver.cpp:105] Iteration 25300, lr = 0.01
I1017 18:30:26.916157 22869 solver.cpp:218] Iteration 25400 (3.32058 iter/s, 30.1153s/100 iters), loss = 0.266293
I1017 18:30:26.916255 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.266292 (* 1 = 0.266292 loss)
I1017 18:30:26.916273 22869 sgd_solver.cpp:105] Iteration 25400, lr = 0.01
I1017 18:30:56.716269 22869 solver.cpp:330] Iteration 25500, Testing net (#0)
I1017 18:31:13.071910 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 18:31:13.406860 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.59105 (* 1 = 1.59105 loss)
I1017 18:31:13.406877 22869 solver.cpp:397]     Test net output #1: accuracy = 0.6439
I1017 18:31:13.703160 22869 solver.cpp:218] Iteration 25500 (2.13735 iter/s, 46.7869s/100 iters), loss = 0.265598
I1017 18:31:13.703199 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.265597 (* 1 = 0.265597 loss)
I1017 18:31:13.703207 22869 sgd_solver.cpp:105] Iteration 25500, lr = 0.01
I1017 18:31:43.806588 22869 solver.cpp:218] Iteration 25600 (3.32189 iter/s, 30.1034s/100 iters), loss = 0.259425
I1017 18:31:43.806700 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.259424 (* 1 = 0.259424 loss)
I1017 18:31:43.806708 22869 sgd_solver.cpp:105] Iteration 25600, lr = 0.01
I1017 18:32:13.919734 22869 solver.cpp:218] Iteration 25700 (3.32082 iter/s, 30.113s/100 iters), loss = 0.205721
I1017 18:32:13.919832 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.20572 (* 1 = 0.20572 loss)
I1017 18:32:13.919840 22869 sgd_solver.cpp:105] Iteration 25700, lr = 0.01
I1017 18:32:44.049783 22869 solver.cpp:218] Iteration 25800 (3.31896 iter/s, 30.13s/100 iters), loss = 0.283195
I1017 18:32:44.049971 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.283194 (* 1 = 0.283194 loss)
I1017 18:32:44.049981 22869 sgd_solver.cpp:105] Iteration 25800, lr = 0.01
I1017 18:33:14.191308 22869 solver.cpp:218] Iteration 25900 (3.3177 iter/s, 30.1414s/100 iters), loss = 0.352962
I1017 18:33:14.191401 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.352961 (* 1 = 0.352961 loss)
I1017 18:33:14.191409 22869 sgd_solver.cpp:105] Iteration 25900, lr = 0.01
I1017 18:33:42.801743 22877 data_layer.cpp:73] Restarting data prefetching from start.
I1017 18:33:44.005626 22869 solver.cpp:330] Iteration 26000, Testing net (#0)
I1017 18:34:00.352578 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 18:34:00.686254 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.54317 (* 1 = 1.54317 loss)
I1017 18:34:00.686270 22869 solver.cpp:397]     Test net output #1: accuracy = 0.6503
I1017 18:34:00.983749 22869 solver.cpp:218] Iteration 26000 (2.1371 iter/s, 46.7924s/100 iters), loss = 0.234873
I1017 18:34:00.983783 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.234872 (* 1 = 0.234872 loss)
I1017 18:34:00.983789 22869 sgd_solver.cpp:105] Iteration 26000, lr = 0.01
I1017 18:34:31.094395 22869 solver.cpp:218] Iteration 26100 (3.32109 iter/s, 30.1106s/100 iters), loss = 0.369912
I1017 18:34:31.094561 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.369911 (* 1 = 0.369911 loss)
I1017 18:34:31.094581 22869 sgd_solver.cpp:105] Iteration 26100, lr = 0.01
I1017 18:35:01.193480 22869 solver.cpp:218] Iteration 26200 (3.32238 iter/s, 30.0989s/100 iters), loss = 0.569304
I1017 18:35:01.193575 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.569303 (* 1 = 0.569303 loss)
I1017 18:35:01.193594 22869 sgd_solver.cpp:105] Iteration 26200, lr = 0.01
I1017 18:35:31.281034 22869 solver.cpp:218] Iteration 26300 (3.32364 iter/s, 30.0875s/100 iters), loss = 0.417802
I1017 18:35:31.281154 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.417802 (* 1 = 0.417802 loss)
I1017 18:35:31.281163 22869 sgd_solver.cpp:105] Iteration 26300, lr = 0.01
I1017 18:36:01.393580 22869 solver.cpp:218] Iteration 26400 (3.32089 iter/s, 30.1124s/100 iters), loss = 0.284025
I1017 18:36:01.393678 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.284024 (* 1 = 0.284024 loss)
I1017 18:36:01.393687 22869 sgd_solver.cpp:105] Iteration 26400, lr = 0.01
I1017 18:36:31.207783 22869 solver.cpp:330] Iteration 26500, Testing net (#0)
I1017 18:36:47.562005 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 18:36:47.896457 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.59103 (* 1 = 1.59103 loss)
I1017 18:36:47.896473 22869 solver.cpp:397]     Test net output #1: accuracy = 0.6447
I1017 18:36:48.192754 22869 solver.cpp:218] Iteration 26500 (2.13679 iter/s, 46.7991s/100 iters), loss = 0.29799
I1017 18:36:48.192790 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.297989 (* 1 = 0.297989 loss)
I1017 18:36:48.192796 22869 sgd_solver.cpp:105] Iteration 26500, lr = 0.01
I1017 18:37:18.306872 22869 solver.cpp:218] Iteration 26600 (3.32071 iter/s, 30.1141s/100 iters), loss = 0.308215
I1017 18:37:18.307024 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.308215 (* 1 = 0.308215 loss)
I1017 18:37:18.307032 22869 sgd_solver.cpp:105] Iteration 26600, lr = 0.01
I1017 18:37:48.420794 22869 solver.cpp:218] Iteration 26700 (3.32074 iter/s, 30.1138s/100 iters), loss = 0.274906
I1017 18:37:48.420908 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.274905 (* 1 = 0.274905 loss)
I1017 18:37:48.420917 22869 sgd_solver.cpp:105] Iteration 26700, lr = 0.01
I1017 18:38:18.518034 22869 solver.cpp:218] Iteration 26800 (3.32258 iter/s, 30.0971s/100 iters), loss = 0.383708
I1017 18:38:18.518185 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.383707 (* 1 = 0.383707 loss)
I1017 18:38:18.518205 22869 sgd_solver.cpp:105] Iteration 26800, lr = 0.01
I1017 18:38:48.616168 22869 solver.cpp:218] Iteration 26900 (3.32248 iter/s, 30.098s/100 iters), loss = 0.30169
I1017 18:38:48.616324 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.30169 (* 1 = 0.30169 loss)
I1017 18:38:48.616334 22869 sgd_solver.cpp:105] Iteration 26900, lr = 0.01
I1017 18:39:17.217579 22877 data_layer.cpp:73] Restarting data prefetching from start.
I1017 18:39:18.419741 22869 solver.cpp:330] Iteration 27000, Testing net (#0)
I1017 18:39:34.773098 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 18:39:35.106160 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.53677 (* 1 = 1.53677 loss)
I1017 18:39:35.106175 22869 solver.cpp:397]     Test net output #1: accuracy = 0.6502
I1017 18:39:35.401353 22869 solver.cpp:218] Iteration 27000 (2.13744 iter/s, 46.785s/100 iters), loss = 0.119263
I1017 18:39:35.401387 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.119263 (* 1 = 0.119263 loss)
I1017 18:39:35.401394 22869 sgd_solver.cpp:105] Iteration 27000, lr = 0.01
I1017 18:40:05.526895 22869 solver.cpp:218] Iteration 27100 (3.31945 iter/s, 30.1255s/100 iters), loss = 0.300719
I1017 18:40:05.526993 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.300718 (* 1 = 0.300718 loss)
I1017 18:40:05.527000 22869 sgd_solver.cpp:105] Iteration 27100, lr = 0.01
I1017 18:40:35.646944 22869 solver.cpp:218] Iteration 27200 (3.32006 iter/s, 30.12s/100 iters), loss = 0.1695
I1017 18:40:35.647053 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.169499 (* 1 = 0.169499 loss)
I1017 18:40:35.647068 22869 sgd_solver.cpp:105] Iteration 27200, lr = 0.01
I1017 18:41:05.770905 22869 solver.cpp:218] Iteration 27300 (3.31963 iter/s, 30.1239s/100 iters), loss = 0.457652
I1017 18:41:05.771049 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.457652 (* 1 = 0.457652 loss)
I1017 18:41:05.771059 22869 sgd_solver.cpp:105] Iteration 27300, lr = 0.01
I1017 18:41:35.905030 22869 solver.cpp:218] Iteration 27400 (3.31851 iter/s, 30.134s/100 iters), loss = 0.371078
I1017 18:41:35.905172 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.371077 (* 1 = 0.371077 loss)
I1017 18:41:35.905181 22869 sgd_solver.cpp:105] Iteration 27400, lr = 0.01
I1017 18:42:05.721591 22869 solver.cpp:330] Iteration 27500, Testing net (#0)
I1017 18:42:22.055863 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 18:42:22.391185 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.63567 (* 1 = 1.63567 loss)
I1017 18:42:22.391201 22869 solver.cpp:397]     Test net output #1: accuracy = 0.635
I1017 18:42:22.687295 22869 solver.cpp:218] Iteration 27500 (2.13757 iter/s, 46.7821s/100 iters), loss = 0.305948
I1017 18:42:22.687330 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.305947 (* 1 = 0.305947 loss)
I1017 18:42:22.687337 22869 sgd_solver.cpp:105] Iteration 27500, lr = 0.01
I1017 18:42:52.786098 22869 solver.cpp:218] Iteration 27600 (3.3224 iter/s, 30.0988s/100 iters), loss = 0.300922
I1017 18:42:52.786211 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.300922 (* 1 = 0.300922 loss)
I1017 18:42:52.786217 22869 sgd_solver.cpp:105] Iteration 27600, lr = 0.01
I1017 18:43:22.896332 22869 solver.cpp:218] Iteration 27700 (3.32114 iter/s, 30.1101s/100 iters), loss = 0.213033
I1017 18:43:22.896442 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.213032 (* 1 = 0.213032 loss)
I1017 18:43:22.896461 22869 sgd_solver.cpp:105] Iteration 27700, lr = 0.01
I1017 18:43:53.023174 22869 solver.cpp:218] Iteration 27800 (3.31931 iter/s, 30.1267s/100 iters), loss = 0.169916
I1017 18:43:53.023283 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.169915 (* 1 = 0.169915 loss)
I1017 18:43:53.023289 22869 sgd_solver.cpp:105] Iteration 27800, lr = 0.01
I1017 18:44:23.142531 22869 solver.cpp:218] Iteration 27900 (3.32014 iter/s, 30.1193s/100 iters), loss = 0.278417
I1017 18:44:23.142700 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.278417 (* 1 = 0.278417 loss)
I1017 18:44:23.142719 22869 sgd_solver.cpp:105] Iteration 27900, lr = 0.01
I1017 18:44:51.767874 22877 data_layer.cpp:73] Restarting data prefetching from start.
I1017 18:44:52.977175 22869 solver.cpp:330] Iteration 28000, Testing net (#0)
I1017 18:45:09.308802 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 18:45:09.643528 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.53395 (* 1 = 1.53395 loss)
I1017 18:45:09.643544 22869 solver.cpp:397]     Test net output #1: accuracy = 0.654
I1017 18:45:09.940995 22869 solver.cpp:218] Iteration 28000 (2.13683 iter/s, 46.7983s/100 iters), loss = 0.192427
I1017 18:45:09.941036 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.192427 (* 1 = 0.192427 loss)
I1017 18:45:09.941043 22869 sgd_solver.cpp:105] Iteration 28000, lr = 0.01
I1017 18:45:40.071116 22869 solver.cpp:218] Iteration 28100 (3.31894 iter/s, 30.1301s/100 iters), loss = 0.236514
I1017 18:45:40.071261 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.236513 (* 1 = 0.236513 loss)
I1017 18:45:40.071270 22869 sgd_solver.cpp:105] Iteration 28100, lr = 0.01
I1017 18:46:10.187824 22869 solver.cpp:218] Iteration 28200 (3.32043 iter/s, 30.1166s/100 iters), loss = 0.338712
I1017 18:46:10.187937 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.338711 (* 1 = 0.338711 loss)
I1017 18:46:10.187957 22869 sgd_solver.cpp:105] Iteration 28200, lr = 0.01
I1017 18:46:40.504166 22869 solver.cpp:218] Iteration 28300 (3.29856 iter/s, 30.3162s/100 iters), loss = 0.395719
I1017 18:46:40.504312 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.395718 (* 1 = 0.395718 loss)
I1017 18:46:40.504321 22869 sgd_solver.cpp:105] Iteration 28300, lr = 0.01
I1017 18:47:11.044870 22869 solver.cpp:218] Iteration 28400 (3.27433 iter/s, 30.5406s/100 iters), loss = 0.170755
I1017 18:47:11.045018 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.170754 (* 1 = 0.170754 loss)
I1017 18:47:11.045037 22869 sgd_solver.cpp:105] Iteration 28400, lr = 0.01
I1017 18:47:41.035786 22869 solver.cpp:330] Iteration 28500, Testing net (#0)
I1017 18:47:57.381392 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 18:47:57.716393 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.62704 (* 1 = 1.62704 loss)
I1017 18:47:57.716408 22869 solver.cpp:397]     Test net output #1: accuracy = 0.6424
I1017 18:47:58.010802 22869 solver.cpp:218] Iteration 28500 (2.12921 iter/s, 46.9658s/100 iters), loss = 0.188228
I1017 18:47:58.010846 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.188227 (* 1 = 0.188227 loss)
I1017 18:47:58.010854 22869 sgd_solver.cpp:105] Iteration 28500, lr = 0.01
I1017 18:48:28.128916 22869 solver.cpp:218] Iteration 28600 (3.32027 iter/s, 30.1181s/100 iters), loss = 0.220336
I1017 18:48:28.129058 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.220335 (* 1 = 0.220335 loss)
I1017 18:48:28.129067 22869 sgd_solver.cpp:105] Iteration 28600, lr = 0.01
I1017 18:48:58.227975 22869 solver.cpp:218] Iteration 28700 (3.32238 iter/s, 30.0989s/100 iters), loss = 0.341534
I1017 18:48:58.228121 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.341533 (* 1 = 0.341533 loss)
I1017 18:48:58.228129 22869 sgd_solver.cpp:105] Iteration 28700, lr = 0.01
I1017 18:49:28.329902 22869 solver.cpp:218] Iteration 28800 (3.32206 iter/s, 30.1018s/100 iters), loss = 0.159862
I1017 18:49:28.330025 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.159861 (* 1 = 0.159861 loss)
I1017 18:49:28.330034 22869 sgd_solver.cpp:105] Iteration 28800, lr = 0.01
I1017 18:49:58.448179 22869 solver.cpp:218] Iteration 28900 (3.32026 iter/s, 30.1182s/100 iters), loss = 0.31381
I1017 18:49:58.448288 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.313809 (* 1 = 0.313809 loss)
I1017 18:49:58.448297 22869 sgd_solver.cpp:105] Iteration 28900, lr = 0.01
I1017 18:50:27.071363 22877 data_layer.cpp:73] Restarting data prefetching from start.
I1017 18:50:28.280362 22869 solver.cpp:330] Iteration 29000, Testing net (#0)
I1017 18:50:44.605069 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 18:50:44.938807 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.58208 (* 1 = 1.58208 loss)
I1017 18:50:44.938823 22869 solver.cpp:397]     Test net output #1: accuracy = 0.6518
I1017 18:50:45.234549 22869 solver.cpp:218] Iteration 29000 (2.13738 iter/s, 46.7863s/100 iters), loss = 0.361816
I1017 18:50:45.234585 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.361815 (* 1 = 0.361815 loss)
I1017 18:50:45.234591 22869 sgd_solver.cpp:105] Iteration 29000, lr = 0.01
I1017 18:51:15.362323 22869 solver.cpp:218] Iteration 29100 (3.3192 iter/s, 30.1277s/100 iters), loss = 0.270583
I1017 18:51:15.362427 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.270582 (* 1 = 0.270582 loss)
I1017 18:51:15.362434 22869 sgd_solver.cpp:105] Iteration 29100, lr = 0.01
I1017 18:51:45.481694 22869 solver.cpp:218] Iteration 29200 (3.32013 iter/s, 30.1193s/100 iters), loss = 0.286153
I1017 18:51:45.481791 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.286153 (* 1 = 0.286153 loss)
I1017 18:51:45.481807 22869 sgd_solver.cpp:105] Iteration 29200, lr = 0.01
I1017 18:52:15.593648 22869 solver.cpp:218] Iteration 29300 (3.32095 iter/s, 30.1119s/100 iters), loss = 0.346205
I1017 18:52:15.593787 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.346204 (* 1 = 0.346204 loss)
I1017 18:52:15.593796 22869 sgd_solver.cpp:105] Iteration 29300, lr = 0.01
I1017 18:52:45.698184 22869 solver.cpp:218] Iteration 29400 (3.32177 iter/s, 30.1044s/100 iters), loss = 0.24211
I1017 18:52:45.698314 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.242109 (* 1 = 0.242109 loss)
I1017 18:52:45.698323 22869 sgd_solver.cpp:105] Iteration 29400, lr = 0.01
I1017 18:53:15.520607 22869 solver.cpp:330] Iteration 29500, Testing net (#0)
I1017 18:53:31.860662 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 18:53:32.194645 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.56659 (* 1 = 1.56659 loss)
I1017 18:53:32.194663 22869 solver.cpp:397]     Test net output #1: accuracy = 0.6512
I1017 18:53:32.490064 22869 solver.cpp:218] Iteration 29500 (2.13713 iter/s, 46.7918s/100 iters), loss = 0.334701
I1017 18:53:32.490094 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.3347 (* 1 = 0.3347 loss)
I1017 18:53:32.490100 22869 sgd_solver.cpp:105] Iteration 29500, lr = 0.01
I1017 18:54:02.597875 22869 solver.cpp:218] Iteration 29600 (3.3214 iter/s, 30.1078s/100 iters), loss = 0.313005
I1017 18:54:02.597975 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.313005 (* 1 = 0.313005 loss)
I1017 18:54:02.597983 22869 sgd_solver.cpp:105] Iteration 29600, lr = 0.01
I1017 18:54:32.684392 22869 solver.cpp:218] Iteration 29700 (3.32379 iter/s, 30.0862s/100 iters), loss = 0.162399
I1017 18:54:32.684548 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.162398 (* 1 = 0.162398 loss)
I1017 18:54:32.684568 22869 sgd_solver.cpp:105] Iteration 29700, lr = 0.01
I1017 18:55:02.993106 22869 solver.cpp:218] Iteration 29800 (3.2994 iter/s, 30.3086s/100 iters), loss = 0.26973
I1017 18:55:02.993191 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.269729 (* 1 = 0.269729 loss)
I1017 18:55:02.993211 22869 sgd_solver.cpp:105] Iteration 29800, lr = 0.01
I1017 18:55:33.215499 22869 solver.cpp:218] Iteration 29900 (3.30881 iter/s, 30.2223s/100 iters), loss = 0.267096
I1017 18:55:33.215616 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.267095 (* 1 = 0.267095 loss)
I1017 18:55:33.215636 22869 sgd_solver.cpp:105] Iteration 29900, lr = 0.01
I1017 18:56:02.179204 22877 data_layer.cpp:73] Restarting data prefetching from start.
I1017 18:56:03.396322 22869 solver.cpp:330] Iteration 30000, Testing net (#0)
I1017 18:56:19.818666 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 18:56:20.152721 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.61661 (* 1 = 1.61661 loss)
I1017 18:56:20.152737 22869 solver.cpp:397]     Test net output #1: accuracy = 0.6445
I1017 18:56:20.448612 22869 solver.cpp:218] Iteration 30000 (2.11716 iter/s, 47.233s/100 iters), loss = 0.148484
I1017 18:56:20.448647 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.148483 (* 1 = 0.148483 loss)
I1017 18:56:20.448654 22869 sgd_solver.cpp:105] Iteration 30000, lr = 0.01
I1017 18:56:50.597132 22869 solver.cpp:218] Iteration 30100 (3.31692 iter/s, 30.1485s/100 iters), loss = 0.196383
I1017 18:56:50.597268 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.196382 (* 1 = 0.196382 loss)
I1017 18:56:50.597275 22869 sgd_solver.cpp:105] Iteration 30100, lr = 0.01
I1017 18:57:20.719866 22869 solver.cpp:218] Iteration 30200 (3.31977 iter/s, 30.1226s/100 iters), loss = 0.218784
I1017 18:57:20.719990 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.218783 (* 1 = 0.218783 loss)
I1017 18:57:20.719997 22869 sgd_solver.cpp:105] Iteration 30200, lr = 0.01
I1017 18:57:50.819340 22869 solver.cpp:218] Iteration 30300 (3.32233 iter/s, 30.0994s/100 iters), loss = 0.514695
I1017 18:57:50.819452 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.514694 (* 1 = 0.514694 loss)
I1017 18:57:50.819459 22869 sgd_solver.cpp:105] Iteration 30300, lr = 0.01
I1017 18:58:20.917171 22869 solver.cpp:218] Iteration 30400 (3.32251 iter/s, 30.0977s/100 iters), loss = 0.179445
I1017 18:58:20.917309 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.179444 (* 1 = 0.179444 loss)
I1017 18:58:20.917316 22869 sgd_solver.cpp:105] Iteration 30400, lr = 0.01
I1017 18:58:50.732422 22869 solver.cpp:330] Iteration 30500, Testing net (#0)
I1017 18:59:07.067174 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 18:59:07.401679 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.58541 (* 1 = 1.58541 loss)
I1017 18:59:07.401695 22869 solver.cpp:397]     Test net output #1: accuracy = 0.6508
I1017 18:59:07.697626 22869 solver.cpp:218] Iteration 30500 (2.13765 iter/s, 46.7803s/100 iters), loss = 0.151377
I1017 18:59:07.697660 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.151376 (* 1 = 0.151376 loss)
I1017 18:59:07.697669 22869 sgd_solver.cpp:105] Iteration 30500, lr = 0.01
I1017 18:59:37.791993 22869 solver.cpp:218] Iteration 30600 (3.32288 iter/s, 30.0943s/100 iters), loss = 0.368823
I1017 18:59:37.792094 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.368822 (* 1 = 0.368822 loss)
I1017 18:59:37.792112 22869 sgd_solver.cpp:105] Iteration 30600, lr = 0.01
I1017 19:00:08.299513 22869 solver.cpp:218] Iteration 30700 (3.27789 iter/s, 30.5074s/100 iters), loss = 0.170647
I1017 19:00:08.299626 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.170646 (* 1 = 0.170646 loss)
I1017 19:00:08.299645 22869 sgd_solver.cpp:105] Iteration 30700, lr = 0.01
I1017 19:00:38.602046 22869 solver.cpp:218] Iteration 30800 (3.30007 iter/s, 30.3024s/100 iters), loss = 0.197095
I1017 19:00:38.602180 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.197094 (* 1 = 0.197094 loss)
I1017 19:00:38.602187 22869 sgd_solver.cpp:105] Iteration 30800, lr = 0.01
I1017 19:01:08.891367 22869 solver.cpp:218] Iteration 30900 (3.30151 iter/s, 30.2892s/100 iters), loss = 0.262305
I1017 19:01:08.891477 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.262304 (* 1 = 0.262304 loss)
I1017 19:01:08.891484 22869 sgd_solver.cpp:105] Iteration 30900, lr = 0.01
I1017 19:01:37.688699 22877 data_layer.cpp:73] Restarting data prefetching from start.
I1017 19:01:38.903193 22869 solver.cpp:330] Iteration 31000, Testing net (#0)
I1017 19:01:55.318215 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 19:01:55.654777 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.59386 (* 1 = 1.59386 loss)
I1017 19:01:55.654793 22869 solver.cpp:397]     Test net output #1: accuracy = 0.6507
I1017 19:01:55.953018 22869 solver.cpp:218] Iteration 31000 (2.12488 iter/s, 47.0616s/100 iters), loss = 0.37596
I1017 19:01:55.953049 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.375959 (* 1 = 0.375959 loss)
I1017 19:01:55.953055 22869 sgd_solver.cpp:105] Iteration 31000, lr = 0.01
I1017 19:02:26.243845 22869 solver.cpp:218] Iteration 31100 (3.30133 iter/s, 30.2908s/100 iters), loss = 0.324097
I1017 19:02:26.243980 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.324095 (* 1 = 0.324095 loss)
I1017 19:02:26.243999 22869 sgd_solver.cpp:105] Iteration 31100, lr = 0.01
I1017 19:02:56.558748 22869 solver.cpp:218] Iteration 31200 (3.29872 iter/s, 30.3148s/100 iters), loss = 0.20281
I1017 19:02:56.558889 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.202809 (* 1 = 0.202809 loss)
I1017 19:02:56.558898 22869 sgd_solver.cpp:105] Iteration 31200, lr = 0.01
I1017 19:03:26.856518 22869 solver.cpp:218] Iteration 31300 (3.30059 iter/s, 30.2976s/100 iters), loss = 0.161634
I1017 19:03:26.856626 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.161633 (* 1 = 0.161633 loss)
I1017 19:03:26.856633 22869 sgd_solver.cpp:105] Iteration 31300, lr = 0.01
I1017 19:03:57.178606 22869 solver.cpp:218] Iteration 31400 (3.29794 iter/s, 30.322s/100 iters), loss = 0.365425
I1017 19:03:57.178743 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.365424 (* 1 = 0.365424 loss)
I1017 19:03:57.178761 22869 sgd_solver.cpp:105] Iteration 31400, lr = 0.01
I1017 19:04:27.227507 22869 solver.cpp:330] Iteration 31500, Testing net (#0)
I1017 19:04:43.673188 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 19:04:44.009769 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.60054 (* 1 = 1.60054 loss)
I1017 19:04:44.009784 22869 solver.cpp:397]     Test net output #1: accuracy = 0.6513
I1017 19:04:44.310160 22869 solver.cpp:218] Iteration 31500 (2.12173 iter/s, 47.1314s/100 iters), loss = 0.314134
I1017 19:04:44.310196 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.314133 (* 1 = 0.314133 loss)
I1017 19:04:44.310204 22869 sgd_solver.cpp:105] Iteration 31500, lr = 0.01
I1017 19:05:14.645470 22869 solver.cpp:218] Iteration 31600 (3.29649 iter/s, 30.3353s/100 iters), loss = 0.21603
I1017 19:05:14.645601 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.216029 (* 1 = 0.216029 loss)
I1017 19:05:14.645611 22869 sgd_solver.cpp:105] Iteration 31600, lr = 0.01
I1017 19:05:44.904697 22869 solver.cpp:218] Iteration 31700 (3.30479 iter/s, 30.2591s/100 iters), loss = 0.279218
I1017 19:05:44.904819 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.279217 (* 1 = 0.279217 loss)
I1017 19:05:44.904826 22869 sgd_solver.cpp:105] Iteration 31700, lr = 0.01
I1017 19:06:15.208235 22869 solver.cpp:218] Iteration 31800 (3.29996 iter/s, 30.3034s/100 iters), loss = 0.274367
I1017 19:06:15.208370 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.274366 (* 1 = 0.274366 loss)
I1017 19:06:15.208379 22869 sgd_solver.cpp:105] Iteration 31800, lr = 0.01
I1017 19:06:45.479276 22869 solver.cpp:218] Iteration 31900 (3.3035 iter/s, 30.2709s/100 iters), loss = 0.255877
I1017 19:06:45.479416 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.255876 (* 1 = 0.255876 loss)
I1017 19:06:45.479424 22869 sgd_solver.cpp:105] Iteration 31900, lr = 0.01
I1017 19:07:14.294538 22877 data_layer.cpp:73] Restarting data prefetching from start.
I1017 19:07:15.493427 22869 solver.cpp:330] Iteration 32000, Testing net (#0)
I1017 19:07:31.949038 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 19:07:32.288224 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.55798 (* 1 = 1.55798 loss)
I1017 19:07:32.288241 22869 solver.cpp:397]     Test net output #1: accuracy = 0.6549
I1017 19:07:32.587725 22869 solver.cpp:218] Iteration 32000 (2.12277 iter/s, 47.1083s/100 iters), loss = 0.127699
I1017 19:07:32.587755 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.127698 (* 1 = 0.127698 loss)
I1017 19:07:32.587762 22869 sgd_solver.cpp:105] Iteration 32000, lr = 0.01
I1017 19:08:02.899616 22869 solver.cpp:218] Iteration 32100 (3.29904 iter/s, 30.3119s/100 iters), loss = 0.277395
I1017 19:08:02.899765 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.277394 (* 1 = 0.277394 loss)
I1017 19:08:02.899772 22869 sgd_solver.cpp:105] Iteration 32100, lr = 0.01
I1017 19:08:33.252158 22869 solver.cpp:218] Iteration 32200 (3.29463 iter/s, 30.3524s/100 iters), loss = 0.228756
I1017 19:08:33.252261 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.228755 (* 1 = 0.228755 loss)
I1017 19:08:33.252279 22869 sgd_solver.cpp:105] Iteration 32200, lr = 0.01
I1017 19:09:03.594624 22869 solver.cpp:218] Iteration 32300 (3.29572 iter/s, 30.3424s/100 iters), loss = 0.192723
I1017 19:09:03.594759 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.192722 (* 1 = 0.192722 loss)
I1017 19:09:03.594768 22869 sgd_solver.cpp:105] Iteration 32300, lr = 0.01
I1017 19:09:33.914788 22869 solver.cpp:218] Iteration 32400 (3.29815 iter/s, 30.32s/100 iters), loss = 0.249769
I1017 19:09:33.914907 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.249768 (* 1 = 0.249768 loss)
I1017 19:09:33.914925 22869 sgd_solver.cpp:105] Iteration 32400, lr = 0.01
I1017 19:10:03.917023 22869 solver.cpp:330] Iteration 32500, Testing net (#0)
I1017 19:10:20.401325 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 19:10:20.740064 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.56778 (* 1 = 1.56778 loss)
I1017 19:10:20.740079 22869 solver.cpp:397]     Test net output #1: accuracy = 0.6588
I1017 19:10:21.038905 22869 solver.cpp:218] Iteration 32500 (2.12207 iter/s, 47.1239s/100 iters), loss = 0.291255
I1017 19:10:21.038935 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.291254 (* 1 = 0.291254 loss)
I1017 19:10:21.038942 22869 sgd_solver.cpp:105] Iteration 32500, lr = 0.01
I1017 19:10:51.346294 22869 solver.cpp:218] Iteration 32600 (3.29953 iter/s, 30.3074s/100 iters), loss = 0.21682
I1017 19:10:51.346397 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.216819 (* 1 = 0.216819 loss)
I1017 19:10:51.346405 22869 sgd_solver.cpp:105] Iteration 32600, lr = 0.01
I1017 19:11:21.676306 22869 solver.cpp:218] Iteration 32700 (3.29708 iter/s, 30.3299s/100 iters), loss = 0.211509
I1017 19:11:21.676460 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.211508 (* 1 = 0.211508 loss)
I1017 19:11:21.676470 22869 sgd_solver.cpp:105] Iteration 32700, lr = 0.01
I1017 19:11:51.993345 22869 solver.cpp:218] Iteration 32800 (3.29849 iter/s, 30.3169s/100 iters), loss = 0.19882
I1017 19:11:51.993491 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.198819 (* 1 = 0.198819 loss)
I1017 19:11:51.993499 22869 sgd_solver.cpp:105] Iteration 32800, lr = 0.01
I1017 19:12:22.301389 22869 solver.cpp:218] Iteration 32900 (3.29947 iter/s, 30.3079s/100 iters), loss = 0.342734
I1017 19:12:22.301491 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.342733 (* 1 = 0.342733 loss)
I1017 19:12:22.301509 22869 sgd_solver.cpp:105] Iteration 32900, lr = 0.01
I1017 19:12:51.092216 22877 data_layer.cpp:73] Restarting data prefetching from start.
I1017 19:12:52.300982 22869 solver.cpp:330] Iteration 33000, Testing net (#0)
I1017 19:13:08.805518 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 19:13:09.142768 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.57804 (* 1 = 1.57804 loss)
I1017 19:13:09.142784 22869 solver.cpp:397]     Test net output #1: accuracy = 0.6598
I1017 19:13:09.443239 22869 solver.cpp:218] Iteration 33000 (2.12126 iter/s, 47.1417s/100 iters), loss = 0.132031
I1017 19:13:09.443275 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.13203 (* 1 = 0.13203 loss)
I1017 19:13:09.443282 22869 sgd_solver.cpp:105] Iteration 33000, lr = 0.01
I1017 19:13:39.678532 22869 solver.cpp:218] Iteration 33100 (3.3074 iter/s, 30.2352s/100 iters), loss = 0.263675
I1017 19:13:39.678697 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.263674 (* 1 = 0.263674 loss)
I1017 19:13:39.678707 22869 sgd_solver.cpp:105] Iteration 33100, lr = 0.01
I1017 19:14:10.008283 22869 solver.cpp:218] Iteration 33200 (3.29711 iter/s, 30.3296s/100 iters), loss = 0.397907
I1017 19:14:10.008406 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.397906 (* 1 = 0.397906 loss)
I1017 19:14:10.008414 22869 sgd_solver.cpp:105] Iteration 33200, lr = 0.01
I1017 19:14:40.335841 22869 solver.cpp:218] Iteration 33300 (3.29734 iter/s, 30.3274s/100 iters), loss = 0.301752
I1017 19:14:40.335976 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.301751 (* 1 = 0.301751 loss)
I1017 19:14:40.335984 22869 sgd_solver.cpp:105] Iteration 33300, lr = 0.01
I1017 19:15:10.635339 22869 solver.cpp:218] Iteration 33400 (3.3004 iter/s, 30.2994s/100 iters), loss = 0.262814
I1017 19:15:10.635437 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.262813 (* 1 = 0.262813 loss)
I1017 19:15:10.635445 22869 sgd_solver.cpp:105] Iteration 33400, lr = 0.01
I1017 19:15:40.647460 22869 solver.cpp:330] Iteration 33500, Testing net (#0)
I1017 19:15:57.110069 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 19:15:57.447623 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.61904 (* 1 = 1.61904 loss)
I1017 19:15:57.447638 22869 solver.cpp:397]     Test net output #1: accuracy = 0.6535
I1017 19:15:57.746937 22869 solver.cpp:218] Iteration 33500 (2.12262 iter/s, 47.1115s/100 iters), loss = 0.162319
I1017 19:15:57.746969 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.162317 (* 1 = 0.162317 loss)
I1017 19:15:57.746976 22869 sgd_solver.cpp:105] Iteration 33500, lr = 0.01
I1017 19:16:28.044591 22869 solver.cpp:218] Iteration 33600 (3.30059 iter/s, 30.2976s/100 iters), loss = 0.301925
I1017 19:16:28.044739 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.301924 (* 1 = 0.301924 loss)
I1017 19:16:28.044747 22869 sgd_solver.cpp:105] Iteration 33600, lr = 0.01
I1017 19:16:58.364336 22869 solver.cpp:218] Iteration 33700 (3.2982 iter/s, 30.3196s/100 iters), loss = 0.340736
I1017 19:16:58.364480 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.340735 (* 1 = 0.340735 loss)
I1017 19:16:58.364487 22869 sgd_solver.cpp:105] Iteration 33700, lr = 0.01
I1017 19:17:28.683110 22869 solver.cpp:218] Iteration 33800 (3.2983 iter/s, 30.3186s/100 iters), loss = 0.25295
I1017 19:17:28.683219 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.252949 (* 1 = 0.252949 loss)
I1017 19:17:28.683236 22869 sgd_solver.cpp:105] Iteration 33800, lr = 0.01
I1017 19:17:58.996433 22869 solver.cpp:218] Iteration 33900 (3.29889 iter/s, 30.3132s/100 iters), loss = 0.232456
I1017 19:17:58.996543 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.232454 (* 1 = 0.232454 loss)
I1017 19:17:58.996551 22869 sgd_solver.cpp:105] Iteration 33900, lr = 0.01
I1017 19:18:27.792404 22877 data_layer.cpp:73] Restarting data prefetching from start.
I1017 19:18:29.013772 22869 solver.cpp:330] Iteration 34000, Testing net (#0)
I1017 19:18:45.498616 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 19:18:45.834233 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.60982 (* 1 = 1.60982 loss)
I1017 19:18:45.834249 22869 solver.cpp:397]     Test net output #1: accuracy = 0.6509
I1017 19:18:46.132663 22869 solver.cpp:218] Iteration 34000 (2.12152 iter/s, 47.1361s/100 iters), loss = 0.283524
I1017 19:18:46.132692 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.283523 (* 1 = 0.283523 loss)
I1017 19:18:46.132699 22869 sgd_solver.cpp:105] Iteration 34000, lr = 0.01
I1017 19:19:16.431017 22869 solver.cpp:218] Iteration 34100 (3.30051 iter/s, 30.2983s/100 iters), loss = 0.210537
I1017 19:19:16.431118 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.210536 (* 1 = 0.210536 loss)
I1017 19:19:16.431125 22869 sgd_solver.cpp:105] Iteration 34100, lr = 0.01
I1017 19:19:46.738271 22869 solver.cpp:218] Iteration 34200 (3.29955 iter/s, 30.3071s/100 iters), loss = 0.160751
I1017 19:19:46.738404 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.16075 (* 1 = 0.16075 loss)
I1017 19:19:46.738411 22869 sgd_solver.cpp:105] Iteration 34200, lr = 0.01
I1017 19:20:16.997583 22869 solver.cpp:218] Iteration 34300 (3.30478 iter/s, 30.2592s/100 iters), loss = 0.328916
I1017 19:20:16.997721 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.328915 (* 1 = 0.328915 loss)
I1017 19:20:16.997730 22869 sgd_solver.cpp:105] Iteration 34300, lr = 0.01
I1017 19:20:47.304327 22869 solver.cpp:218] Iteration 34400 (3.29961 iter/s, 30.3066s/100 iters), loss = 0.362474
I1017 19:20:47.304464 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.362473 (* 1 = 0.362473 loss)
I1017 19:20:47.304472 22869 sgd_solver.cpp:105] Iteration 34400, lr = 0.01
I1017 19:21:17.342092 22869 solver.cpp:330] Iteration 34500, Testing net (#0)
I1017 19:21:33.825752 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 19:21:34.163167 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.61691 (* 1 = 1.61691 loss)
I1017 19:21:34.163184 22869 solver.cpp:397]     Test net output #1: accuracy = 0.6511
I1017 19:21:34.462052 22869 solver.cpp:218] Iteration 34500 (2.12055 iter/s, 47.1576s/100 iters), loss = 0.237085
I1017 19:21:34.462085 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.237084 (* 1 = 0.237084 loss)
I1017 19:21:34.462091 22869 sgd_solver.cpp:105] Iteration 34500, lr = 0.01
I1017 19:22:04.731396 22869 solver.cpp:218] Iteration 34600 (3.30368 iter/s, 30.2693s/100 iters), loss = 0.37233
I1017 19:22:04.731470 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.372329 (* 1 = 0.372329 loss)
I1017 19:22:04.731480 22869 sgd_solver.cpp:105] Iteration 34600, lr = 0.01
I1017 19:22:35.053689 22869 solver.cpp:218] Iteration 34700 (3.29791 iter/s, 30.3222s/100 iters), loss = 0.0964722
I1017 19:22:35.053794 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0964712 (* 1 = 0.0964712 loss)
I1017 19:22:35.053812 22869 sgd_solver.cpp:105] Iteration 34700, lr = 0.01
I1017 19:23:05.327692 22869 solver.cpp:218] Iteration 34800 (3.30318 iter/s, 30.2739s/100 iters), loss = 0.183989
I1017 19:23:05.327786 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.183988 (* 1 = 0.183988 loss)
I1017 19:23:05.327805 22869 sgd_solver.cpp:105] Iteration 34800, lr = 0.01
I1017 19:23:35.607944 22869 solver.cpp:218] Iteration 34900 (3.30249 iter/s, 30.2802s/100 iters), loss = 0.118599
I1017 19:23:35.608052 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.118598 (* 1 = 0.118598 loss)
I1017 19:23:35.608058 22869 sgd_solver.cpp:105] Iteration 34900, lr = 0.01
I1017 19:24:04.398666 22877 data_layer.cpp:73] Restarting data prefetching from start.
I1017 19:24:05.604135 22869 solver.cpp:330] Iteration 35000, Testing net (#0)
I1017 19:24:22.072983 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 19:24:22.409478 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.58967 (* 1 = 1.58967 loss)
I1017 19:24:22.409493 22869 solver.cpp:397]     Test net output #1: accuracy = 0.6476
I1017 19:24:22.708214 22869 solver.cpp:218] Iteration 35000 (2.12313 iter/s, 47.1002s/100 iters), loss = 0.278057
I1017 19:24:22.708259 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.278056 (* 1 = 0.278056 loss)
I1017 19:24:22.708266 22869 sgd_solver.cpp:105] Iteration 35000, lr = 0.01
I1017 19:24:53.022846 22869 solver.cpp:218] Iteration 35100 (3.29874 iter/s, 30.3146s/100 iters), loss = 0.48139
I1017 19:24:53.022956 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.481389 (* 1 = 0.481389 loss)
I1017 19:24:53.022964 22869 sgd_solver.cpp:105] Iteration 35100, lr = 0.01
I1017 19:25:23.289189 22869 solver.cpp:218] Iteration 35200 (3.30401 iter/s, 30.2662s/100 iters), loss = 0.231968
I1017 19:25:23.289360 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.231967 (* 1 = 0.231967 loss)
I1017 19:25:23.289368 22869 sgd_solver.cpp:105] Iteration 35200, lr = 0.01
I1017 19:25:53.581764 22869 solver.cpp:218] Iteration 35300 (3.30116 iter/s, 30.2924s/100 iters), loss = 0.180288
I1017 19:25:53.581866 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.180287 (* 1 = 0.180287 loss)
I1017 19:25:53.581882 22869 sgd_solver.cpp:105] Iteration 35300, lr = 0.01
I1017 19:26:23.840338 22869 solver.cpp:218] Iteration 35400 (3.30486 iter/s, 30.2585s/100 iters), loss = 0.133357
I1017 19:26:23.840448 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.133356 (* 1 = 0.133356 loss)
I1017 19:26:23.840456 22869 sgd_solver.cpp:105] Iteration 35400, lr = 0.01
I1017 19:26:53.851850 22869 solver.cpp:330] Iteration 35500, Testing net (#0)
I1017 19:27:10.340392 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 19:27:10.679042 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.59277 (* 1 = 1.59277 loss)
I1017 19:27:10.679059 22869 solver.cpp:397]     Test net output #1: accuracy = 0.6534
I1017 19:27:10.976439 22869 solver.cpp:218] Iteration 35500 (2.12152 iter/s, 47.136s/100 iters), loss = 0.281191
I1017 19:27:10.976470 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.28119 (* 1 = 0.28119 loss)
I1017 19:27:10.976476 22869 sgd_solver.cpp:105] Iteration 35500, lr = 0.01
I1017 19:27:41.245421 22869 solver.cpp:218] Iteration 35600 (3.30372 iter/s, 30.2689s/100 iters), loss = 0.445564
I1017 19:27:41.245542 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.445563 (* 1 = 0.445563 loss)
I1017 19:27:41.245559 22869 sgd_solver.cpp:105] Iteration 35600, lr = 0.01
I1017 19:28:11.513159 22869 solver.cpp:218] Iteration 35700 (3.30386 iter/s, 30.2676s/100 iters), loss = 0.279359
I1017 19:28:11.513262 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.279358 (* 1 = 0.279358 loss)
I1017 19:28:11.513269 22869 sgd_solver.cpp:105] Iteration 35700, lr = 0.01
I1017 19:28:41.801411 22869 solver.cpp:218] Iteration 35800 (3.30162 iter/s, 30.2881s/100 iters), loss = 0.120894
I1017 19:28:41.801525 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.120893 (* 1 = 0.120893 loss)
I1017 19:28:41.801532 22869 sgd_solver.cpp:105] Iteration 35800, lr = 0.01
I1017 19:29:12.069015 22869 solver.cpp:218] Iteration 35900 (3.30387 iter/s, 30.2675s/100 iters), loss = 0.257154
I1017 19:29:12.069157 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.257153 (* 1 = 0.257153 loss)
I1017 19:29:12.069166 22869 sgd_solver.cpp:105] Iteration 35900, lr = 0.01
I1017 19:29:40.849988 22877 data_layer.cpp:73] Restarting data prefetching from start.
I1017 19:29:42.058542 22869 solver.cpp:330] Iteration 36000, Testing net (#0)
I1017 19:29:58.527884 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 19:29:58.861843 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.60495 (* 1 = 1.60495 loss)
I1017 19:29:58.861860 22869 solver.cpp:397]     Test net output #1: accuracy = 0.6512
I1017 19:29:59.157943 22869 solver.cpp:218] Iteration 36000 (2.12365 iter/s, 47.0888s/100 iters), loss = 0.203727
I1017 19:29:59.157976 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.203726 (* 1 = 0.203726 loss)
I1017 19:29:59.157984 22869 sgd_solver.cpp:105] Iteration 36000, lr = 0.01
I1017 19:30:29.504673 22869 solver.cpp:218] Iteration 36100 (3.29526 iter/s, 30.3467s/100 iters), loss = 0.224919
I1017 19:30:29.504783 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.224918 (* 1 = 0.224918 loss)
I1017 19:30:29.504799 22869 sgd_solver.cpp:105] Iteration 36100, lr = 0.01
I1017 19:30:59.788496 22869 solver.cpp:218] Iteration 36200 (3.30211 iter/s, 30.2837s/100 iters), loss = 0.318812
I1017 19:30:59.788636 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.318812 (* 1 = 0.318812 loss)
I1017 19:30:59.788645 22869 sgd_solver.cpp:105] Iteration 36200, lr = 0.01
I1017 19:31:30.123669 22869 solver.cpp:218] Iteration 36300 (3.29652 iter/s, 30.335s/100 iters), loss = 0.415026
I1017 19:31:30.123790 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.415025 (* 1 = 0.415025 loss)
I1017 19:31:30.123800 22869 sgd_solver.cpp:105] Iteration 36300, lr = 0.01
I1017 19:32:00.433064 22869 solver.cpp:218] Iteration 36400 (3.29932 iter/s, 30.3093s/100 iters), loss = 0.280454
I1017 19:32:00.433207 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.280453 (* 1 = 0.280453 loss)
I1017 19:32:00.433217 22869 sgd_solver.cpp:105] Iteration 36400, lr = 0.01
I1017 19:32:30.457803 22869 solver.cpp:330] Iteration 36500, Testing net (#0)
I1017 19:32:46.967423 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 19:32:47.302471 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.61956 (* 1 = 1.61956 loss)
I1017 19:32:47.302486 22869 solver.cpp:397]     Test net output #1: accuracy = 0.6449
I1017 19:32:47.600414 22869 solver.cpp:218] Iteration 36500 (2.12012 iter/s, 47.1672s/100 iters), loss = 0.0908364
I1017 19:32:47.600452 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0908354 (* 1 = 0.0908354 loss)
I1017 19:32:47.600459 22869 sgd_solver.cpp:105] Iteration 36500, lr = 0.01
I1017 19:33:17.885833 22869 solver.cpp:218] Iteration 36600 (3.30192 iter/s, 30.2854s/100 iters), loss = 0.295608
I1017 19:33:17.885965 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.295607 (* 1 = 0.295607 loss)
I1017 19:33:17.885984 22869 sgd_solver.cpp:105] Iteration 36600, lr = 0.01
I1017 19:33:48.217634 22869 solver.cpp:218] Iteration 36700 (3.29688 iter/s, 30.3317s/100 iters), loss = 0.1865
I1017 19:33:48.217772 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.186499 (* 1 = 0.186499 loss)
I1017 19:33:48.217782 22869 sgd_solver.cpp:105] Iteration 36700, lr = 0.01
I1017 19:34:18.528038 22869 solver.cpp:218] Iteration 36800 (3.29921 iter/s, 30.3103s/100 iters), loss = 0.154921
I1017 19:34:18.528146 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.15492 (* 1 = 0.15492 loss)
I1017 19:34:18.528162 22869 sgd_solver.cpp:105] Iteration 36800, lr = 0.01
I1017 19:34:48.825922 22869 solver.cpp:218] Iteration 36900 (3.30057 iter/s, 30.2978s/100 iters), loss = 0.150943
I1017 19:34:48.826066 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.150942 (* 1 = 0.150942 loss)
I1017 19:34:48.826076 22869 sgd_solver.cpp:105] Iteration 36900, lr = 0.01
I1017 19:35:17.654023 22877 data_layer.cpp:73] Restarting data prefetching from start.
I1017 19:35:18.871356 22869 solver.cpp:330] Iteration 37000, Testing net (#0)
I1017 19:35:35.308583 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 19:35:35.647935 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.57975 (* 1 = 1.57975 loss)
I1017 19:35:35.647953 22869 solver.cpp:397]     Test net output #1: accuracy = 0.6579
I1017 19:35:35.949440 22869 solver.cpp:218] Iteration 37000 (2.12209 iter/s, 47.1234s/100 iters), loss = 0.0622375
I1017 19:35:35.949473 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0622367 (* 1 = 0.0622367 loss)
I1017 19:35:35.949481 22869 sgd_solver.cpp:105] Iteration 37000, lr = 0.01
I1017 19:36:06.253670 22869 solver.cpp:218] Iteration 37100 (3.29987 iter/s, 30.3042s/100 iters), loss = 0.226759
I1017 19:36:06.253783 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.226759 (* 1 = 0.226759 loss)
I1017 19:36:06.253790 22869 sgd_solver.cpp:105] Iteration 37100, lr = 0.01
I1017 19:36:36.563376 22869 solver.cpp:218] Iteration 37200 (3.29929 iter/s, 30.3096s/100 iters), loss = 0.134682
I1017 19:36:36.563486 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.134682 (* 1 = 0.134682 loss)
I1017 19:36:36.563504 22869 sgd_solver.cpp:105] Iteration 37200, lr = 0.01
I1017 19:37:06.818538 22869 solver.cpp:218] Iteration 37300 (3.30523 iter/s, 30.2551s/100 iters), loss = 0.235675
I1017 19:37:06.818686 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.235674 (* 1 = 0.235674 loss)
I1017 19:37:06.818694 22869 sgd_solver.cpp:105] Iteration 37300, lr = 0.01
I1017 19:37:37.163503 22869 solver.cpp:218] Iteration 37400 (3.29546 iter/s, 30.3448s/100 iters), loss = 0.258697
I1017 19:37:37.163664 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.258696 (* 1 = 0.258696 loss)
I1017 19:37:37.163686 22869 sgd_solver.cpp:105] Iteration 37400, lr = 0.01
I1017 19:38:07.211681 22869 solver.cpp:330] Iteration 37500, Testing net (#0)
I1017 19:38:23.696395 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 19:38:24.032300 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.59548 (* 1 = 1.59548 loss)
I1017 19:38:24.032317 22869 solver.cpp:397]     Test net output #1: accuracy = 0.653
I1017 19:38:24.332726 22869 solver.cpp:218] Iteration 37500 (2.12003 iter/s, 47.1691s/100 iters), loss = 0.0577573
I1017 19:38:24.332770 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0577564 (* 1 = 0.0577564 loss)
I1017 19:38:24.332777 22869 sgd_solver.cpp:105] Iteration 37500, lr = 0.01
I1017 19:38:54.613260 22869 solver.cpp:218] Iteration 37600 (3.30246 iter/s, 30.2805s/100 iters), loss = 0.155735
I1017 19:38:54.613401 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.155734 (* 1 = 0.155734 loss)
I1017 19:38:54.613409 22869 sgd_solver.cpp:105] Iteration 37600, lr = 0.01
I1017 19:39:24.894188 22869 solver.cpp:218] Iteration 37700 (3.30242 iter/s, 30.2808s/100 iters), loss = 0.295648
I1017 19:39:24.894323 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.295647 (* 1 = 0.295647 loss)
I1017 19:39:24.894330 22869 sgd_solver.cpp:105] Iteration 37700, lr = 0.01
I1017 19:39:55.219751 22869 solver.cpp:218] Iteration 37800 (3.29756 iter/s, 30.3254s/100 iters), loss = 0.185212
I1017 19:39:55.219863 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.185211 (* 1 = 0.185211 loss)
I1017 19:39:55.219871 22869 sgd_solver.cpp:105] Iteration 37800, lr = 0.01
I1017 19:40:25.543378 22869 solver.cpp:218] Iteration 37900 (3.29777 iter/s, 30.3235s/100 iters), loss = 0.17829
I1017 19:40:25.544960 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.178289 (* 1 = 0.178289 loss)
I1017 19:40:25.544968 22869 sgd_solver.cpp:105] Iteration 37900, lr = 0.01
I1017 19:40:54.367977 22877 data_layer.cpp:73] Restarting data prefetching from start.
I1017 19:40:55.589604 22869 solver.cpp:330] Iteration 38000, Testing net (#0)
I1017 19:41:12.023533 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 19:41:12.360347 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.62227 (* 1 = 1.62227 loss)
I1017 19:41:12.360363 22869 solver.cpp:397]     Test net output #1: accuracy = 0.6553
I1017 19:41:12.659840 22869 solver.cpp:218] Iteration 38000 (2.12247 iter/s, 47.1149s/100 iters), loss = 0.12798
I1017 19:41:12.659876 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.127979 (* 1 = 0.127979 loss)
I1017 19:41:12.659893 22869 sgd_solver.cpp:105] Iteration 38000, lr = 0.01
I1017 19:41:43.050258 22869 solver.cpp:218] Iteration 38100 (3.29052 iter/s, 30.3904s/100 iters), loss = 0.170451
I1017 19:41:43.050397 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.17045 (* 1 = 0.17045 loss)
I1017 19:41:43.050405 22869 sgd_solver.cpp:105] Iteration 38100, lr = 0.01
I1017 19:42:13.341028 22869 solver.cpp:218] Iteration 38200 (3.30135 iter/s, 30.2906s/100 iters), loss = 0.208793
I1017 19:42:13.341164 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.208792 (* 1 = 0.208792 loss)
I1017 19:42:13.341171 22869 sgd_solver.cpp:105] Iteration 38200, lr = 0.01
I1017 19:42:43.642194 22869 solver.cpp:218] Iteration 38300 (3.30022 iter/s, 30.301s/100 iters), loss = 0.326292
I1017 19:42:43.642338 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.326291 (* 1 = 0.326291 loss)
I1017 19:42:43.642346 22869 sgd_solver.cpp:105] Iteration 38300, lr = 0.01
I1017 19:43:13.939045 22869 solver.cpp:218] Iteration 38400 (3.30069 iter/s, 30.2967s/100 iters), loss = 0.19754
I1017 19:43:13.939167 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.197539 (* 1 = 0.197539 loss)
I1017 19:43:13.939175 22869 sgd_solver.cpp:105] Iteration 38400, lr = 0.01
I1017 19:43:43.918848 22869 solver.cpp:330] Iteration 38500, Testing net (#0)
I1017 19:44:00.345650 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 19:44:00.681113 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.62601 (* 1 = 1.62601 loss)
I1017 19:44:00.681129 22869 solver.cpp:397]     Test net output #1: accuracy = 0.6487
I1017 19:44:00.979153 22869 solver.cpp:218] Iteration 38500 (2.12585 iter/s, 47.04s/100 iters), loss = 0.40034
I1017 19:44:00.979187 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.400339 (* 1 = 0.400339 loss)
I1017 19:44:00.979192 22869 sgd_solver.cpp:105] Iteration 38500, lr = 0.01
I1017 19:44:31.306874 22869 solver.cpp:218] Iteration 38600 (3.29732 iter/s, 30.3277s/100 iters), loss = 0.220531
I1017 19:44:31.306980 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.22053 (* 1 = 0.22053 loss)
I1017 19:44:31.306988 22869 sgd_solver.cpp:105] Iteration 38600, lr = 0.01
I1017 19:45:01.569406 22869 solver.cpp:218] Iteration 38700 (3.30443 iter/s, 30.2624s/100 iters), loss = 0.120016
I1017 19:45:01.569507 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.120015 (* 1 = 0.120015 loss)
I1017 19:45:01.569515 22869 sgd_solver.cpp:105] Iteration 38700, lr = 0.01
I1017 19:45:31.823590 22869 solver.cpp:218] Iteration 38800 (3.30534 iter/s, 30.2541s/100 iters), loss = 0.284922
I1017 19:45:31.823745 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.284922 (* 1 = 0.284922 loss)
I1017 19:45:31.823753 22869 sgd_solver.cpp:105] Iteration 38800, lr = 0.01
I1017 19:46:02.168566 22869 solver.cpp:218] Iteration 38900 (3.29546 iter/s, 30.3448s/100 iters), loss = 0.146137
I1017 19:46:02.168654 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.146136 (* 1 = 0.146136 loss)
I1017 19:46:02.168663 22869 sgd_solver.cpp:105] Iteration 38900, lr = 0.01
I1017 19:46:30.950227 22877 data_layer.cpp:73] Restarting data prefetching from start.
I1017 19:46:32.171211 22869 solver.cpp:330] Iteration 39000, Testing net (#0)
I1017 19:46:48.633810 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 19:46:48.972148 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.61867 (* 1 = 1.61867 loss)
I1017 19:46:48.972167 22869 solver.cpp:397]     Test net output #1: accuracy = 0.6541
I1017 19:46:49.273106 22869 solver.cpp:218] Iteration 39000 (2.12294 iter/s, 47.1045s/100 iters), loss = 0.151478
I1017 19:46:49.273140 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.151477 (* 1 = 0.151477 loss)
I1017 19:46:49.273147 22869 sgd_solver.cpp:105] Iteration 39000, lr = 0.01
I1017 19:47:19.581601 22869 solver.cpp:218] Iteration 39100 (3.29941 iter/s, 30.3085s/100 iters), loss = 0.185678
I1017 19:47:19.581738 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.185677 (* 1 = 0.185677 loss)
I1017 19:47:19.581748 22869 sgd_solver.cpp:105] Iteration 39100, lr = 0.01
I1017 19:47:49.864107 22869 solver.cpp:218] Iteration 39200 (3.30225 iter/s, 30.2824s/100 iters), loss = 0.369763
I1017 19:47:49.864205 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.369762 (* 1 = 0.369762 loss)
I1017 19:47:49.864220 22869 sgd_solver.cpp:105] Iteration 39200, lr = 0.01
I1017 19:48:20.188758 22869 solver.cpp:218] Iteration 39300 (3.29766 iter/s, 30.3245s/100 iters), loss = 0.142022
I1017 19:48:20.188868 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.142021 (* 1 = 0.142021 loss)
I1017 19:48:20.188875 22869 sgd_solver.cpp:105] Iteration 39300, lr = 0.01
I1017 19:48:50.499150 22869 solver.cpp:218] Iteration 39400 (3.29921 iter/s, 30.3103s/100 iters), loss = 0.110226
I1017 19:48:50.499261 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.110225 (* 1 = 0.110225 loss)
I1017 19:48:50.499279 22869 sgd_solver.cpp:105] Iteration 39400, lr = 0.01
I1017 19:49:20.521725 22869 solver.cpp:330] Iteration 39500, Testing net (#0)
I1017 19:49:36.993989 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 19:49:37.330569 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.58416 (* 1 = 1.58416 loss)
I1017 19:49:37.330586 22869 solver.cpp:397]     Test net output #1: accuracy = 0.6582
I1017 19:49:37.629209 22869 solver.cpp:218] Iteration 39500 (2.12179 iter/s, 47.1299s/100 iters), loss = 0.365114
I1017 19:49:37.629247 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.365113 (* 1 = 0.365113 loss)
I1017 19:49:37.629254 22869 sgd_solver.cpp:105] Iteration 39500, lr = 0.01
I1017 19:50:07.940465 22869 solver.cpp:218] Iteration 39600 (3.29911 iter/s, 30.3112s/100 iters), loss = 0.264028
I1017 19:50:07.941568 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.264027 (* 1 = 0.264027 loss)
I1017 19:50:07.941576 22869 sgd_solver.cpp:105] Iteration 39600, lr = 0.01
I1017 19:50:38.254184 22869 solver.cpp:218] Iteration 39700 (3.29896 iter/s, 30.3126s/100 iters), loss = 0.230413
I1017 19:50:38.254281 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.230412 (* 1 = 0.230412 loss)
I1017 19:50:38.254297 22869 sgd_solver.cpp:105] Iteration 39700, lr = 0.01
I1017 19:51:08.635278 22869 solver.cpp:218] Iteration 39800 (3.29153 iter/s, 30.381s/100 iters), loss = 0.147474
I1017 19:51:08.635408 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.147473 (* 1 = 0.147473 loss)
I1017 19:51:08.635417 22869 sgd_solver.cpp:105] Iteration 39800, lr = 0.01
I1017 19:51:38.977476 22869 solver.cpp:218] Iteration 39900 (3.29575 iter/s, 30.3421s/100 iters), loss = 0.163406
I1017 19:51:38.977571 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.163405 (* 1 = 0.163405 loss)
I1017 19:51:38.977577 22869 sgd_solver.cpp:105] Iteration 39900, lr = 0.01
I1017 19:52:07.806474 22877 data_layer.cpp:73] Restarting data prefetching from start.
I1017 19:52:09.023557 22869 solver.cpp:330] Iteration 40000, Testing net (#0)
I1017 19:52:25.465112 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 19:52:25.806040 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.62432 (* 1 = 1.62432 loss)
I1017 19:52:25.806056 22869 solver.cpp:397]     Test net output #1: accuracy = 0.6567
I1017 19:52:26.108826 22869 solver.cpp:218] Iteration 40000 (2.12173 iter/s, 47.1312s/100 iters), loss = 0.161231
I1017 19:52:26.108855 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.16123 (* 1 = 0.16123 loss)
I1017 19:52:26.108861 22869 sgd_solver.cpp:105] Iteration 40000, lr = 0.01
I1017 19:52:56.431726 22869 solver.cpp:218] Iteration 40100 (3.29784 iter/s, 30.3229s/100 iters), loss = 0.263265
I1017 19:52:56.431807 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.263264 (* 1 = 0.263264 loss)
I1017 19:52:56.431823 22869 sgd_solver.cpp:105] Iteration 40100, lr = 0.01
I1017 19:53:26.741389 22869 solver.cpp:218] Iteration 40200 (3.29929 iter/s, 30.3096s/100 iters), loss = 0.135949
I1017 19:53:26.741492 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.135948 (* 1 = 0.135948 loss)
I1017 19:53:26.741513 22869 sgd_solver.cpp:105] Iteration 40200, lr = 0.01
I1017 19:53:57.066001 22869 solver.cpp:218] Iteration 40300 (3.29766 iter/s, 30.3245s/100 iters), loss = 0.344137
I1017 19:53:57.066133 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.344136 (* 1 = 0.344136 loss)
I1017 19:53:57.066141 22869 sgd_solver.cpp:105] Iteration 40300, lr = 0.01
I1017 19:54:27.374583 22869 solver.cpp:218] Iteration 40400 (3.29941 iter/s, 30.3084s/100 iters), loss = 0.318205
I1017 19:54:27.374717 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.318204 (* 1 = 0.318204 loss)
I1017 19:54:27.374725 22869 sgd_solver.cpp:105] Iteration 40400, lr = 0.01
I1017 19:54:57.389008 22869 solver.cpp:330] Iteration 40500, Testing net (#0)
I1017 19:55:13.873250 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 19:55:14.209041 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.59478 (* 1 = 1.59478 loss)
I1017 19:55:14.209058 22869 solver.cpp:397]     Test net output #1: accuracy = 0.6551
I1017 19:55:14.506808 22869 solver.cpp:218] Iteration 40500 (2.1217 iter/s, 47.1321s/100 iters), loss = 0.18319
I1017 19:55:14.506840 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.183189 (* 1 = 0.183189 loss)
I1017 19:55:14.506846 22869 sgd_solver.cpp:105] Iteration 40500, lr = 0.01
I1017 19:55:44.799954 22869 solver.cpp:218] Iteration 40600 (3.30108 iter/s, 30.2931s/100 iters), loss = 0.21756
I1017 19:55:44.800112 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.217559 (* 1 = 0.217559 loss)
I1017 19:55:44.800124 22869 sgd_solver.cpp:105] Iteration 40600, lr = 0.01
I1017 19:56:15.114615 22869 solver.cpp:218] Iteration 40700 (3.29875 iter/s, 30.3145s/100 iters), loss = 0.225467
I1017 19:56:15.114717 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.225466 (* 1 = 0.225466 loss)
I1017 19:56:15.114723 22869 sgd_solver.cpp:105] Iteration 40700, lr = 0.01
I1017 19:56:45.406808 22869 solver.cpp:218] Iteration 40800 (3.30119 iter/s, 30.2921s/100 iters), loss = 0.162004
I1017 19:56:45.406903 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.162003 (* 1 = 0.162003 loss)
I1017 19:56:45.406919 22869 sgd_solver.cpp:105] Iteration 40800, lr = 0.01
I1017 19:57:15.724601 22869 solver.cpp:218] Iteration 40900 (3.2984 iter/s, 30.3177s/100 iters), loss = 0.196648
I1017 19:57:15.724742 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.196647 (* 1 = 0.196647 loss)
I1017 19:57:15.724750 22869 sgd_solver.cpp:105] Iteration 40900, lr = 0.01
I1017 19:57:44.519335 22877 data_layer.cpp:73] Restarting data prefetching from start.
I1017 19:57:45.745795 22869 solver.cpp:330] Iteration 41000, Testing net (#0)
I1017 19:58:02.164778 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 19:58:02.500986 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.61329 (* 1 = 1.61329 loss)
I1017 19:58:02.501003 22869 solver.cpp:397]     Test net output #1: accuracy = 0.6534
I1017 19:58:02.797256 22869 solver.cpp:218] Iteration 41000 (2.12438 iter/s, 47.0725s/100 iters), loss = 0.0882036
I1017 19:58:02.797293 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0882025 (* 1 = 0.0882025 loss)
I1017 19:58:02.797300 22869 sgd_solver.cpp:105] Iteration 41000, lr = 0.01
I1017 19:58:33.125372 22869 solver.cpp:218] Iteration 41100 (3.29728 iter/s, 30.3281s/100 iters), loss = 0.182931
I1017 19:58:33.125486 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.18293 (* 1 = 0.18293 loss)
I1017 19:58:33.125504 22869 sgd_solver.cpp:105] Iteration 41100, lr = 0.01
I1017 19:59:03.413524 22869 solver.cpp:218] Iteration 41200 (3.30163 iter/s, 30.288s/100 iters), loss = 0.170428
I1017 19:59:03.413638 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.170427 (* 1 = 0.170427 loss)
I1017 19:59:03.413656 22869 sgd_solver.cpp:105] Iteration 41200, lr = 0.01
I1017 19:59:33.680853 22869 solver.cpp:218] Iteration 41300 (3.3039 iter/s, 30.2672s/100 iters), loss = 0.156571
I1017 19:59:33.681403 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.15657 (* 1 = 0.15657 loss)
I1017 19:59:33.681411 22869 sgd_solver.cpp:105] Iteration 41300, lr = 0.01
I1017 20:00:04.002976 22869 solver.cpp:218] Iteration 41400 (3.29798 iter/s, 30.3216s/100 iters), loss = 0.17487
I1017 20:00:04.003118 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.174869 (* 1 = 0.174869 loss)
I1017 20:00:04.003126 22869 sgd_solver.cpp:105] Iteration 41400, lr = 0.01
I1017 20:00:33.984001 22869 solver.cpp:330] Iteration 41500, Testing net (#0)
I1017 20:00:50.473968 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 20:00:50.811146 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.58795 (* 1 = 1.58795 loss)
I1017 20:00:50.811163 22869 solver.cpp:397]     Test net output #1: accuracy = 0.6599
I1017 20:00:51.108404 22869 solver.cpp:218] Iteration 41500 (2.1229 iter/s, 47.1053s/100 iters), loss = 0.280749
I1017 20:00:51.108443 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.280748 (* 1 = 0.280748 loss)
I1017 20:00:51.108450 22869 sgd_solver.cpp:105] Iteration 41500, lr = 0.01
I1017 20:01:21.359071 22869 solver.cpp:218] Iteration 41600 (3.30572 iter/s, 30.2506s/100 iters), loss = 0.301248
I1017 20:01:21.359202 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.301246 (* 1 = 0.301246 loss)
I1017 20:01:21.359210 22869 sgd_solver.cpp:105] Iteration 41600, lr = 0.01
I1017 20:01:51.650884 22869 solver.cpp:218] Iteration 41700 (3.30124 iter/s, 30.2917s/100 iters), loss = 0.3148
I1017 20:01:51.650990 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.314799 (* 1 = 0.314799 loss)
I1017 20:01:51.651006 22869 sgd_solver.cpp:105] Iteration 41700, lr = 0.01
I1017 20:02:21.919981 22869 solver.cpp:218] Iteration 41800 (3.30371 iter/s, 30.269s/100 iters), loss = 0.270777
I1017 20:02:21.920080 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.270776 (* 1 = 0.270776 loss)
I1017 20:02:21.920097 22869 sgd_solver.cpp:105] Iteration 41800, lr = 0.01
I1017 20:02:52.199038 22869 solver.cpp:218] Iteration 41900 (3.30262 iter/s, 30.2789s/100 iters), loss = 0.191415
I1017 20:02:52.199138 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.191413 (* 1 = 0.191413 loss)
I1017 20:02:52.199146 22869 sgd_solver.cpp:105] Iteration 41900, lr = 0.01
I1017 20:03:20.972863 22877 data_layer.cpp:73] Restarting data prefetching from start.
I1017 20:03:22.174382 22869 solver.cpp:330] Iteration 42000, Testing net (#0)
I1017 20:03:38.667397 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 20:03:39.005120 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.61776 (* 1 = 1.61776 loss)
I1017 20:03:39.005136 22869 solver.cpp:397]     Test net output #1: accuracy = 0.6562
I1017 20:03:39.304371 22869 solver.cpp:218] Iteration 42000 (2.12291 iter/s, 47.1052s/100 iters), loss = 0.129512
I1017 20:03:39.304404 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.129511 (* 1 = 0.129511 loss)
I1017 20:03:39.304411 22869 sgd_solver.cpp:105] Iteration 42000, lr = 0.01
I1017 20:04:09.594274 22869 solver.cpp:218] Iteration 42100 (3.30143 iter/s, 30.2899s/100 iters), loss = 0.11423
I1017 20:04:09.594364 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.114229 (* 1 = 0.114229 loss)
I1017 20:04:09.594380 22869 sgd_solver.cpp:105] Iteration 42100, lr = 0.01
I1017 20:04:39.872519 22869 solver.cpp:218] Iteration 42200 (3.30271 iter/s, 30.2781s/100 iters), loss = 0.192706
I1017 20:04:39.872649 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.192705 (* 1 = 0.192705 loss)
I1017 20:04:39.872658 22869 sgd_solver.cpp:105] Iteration 42200, lr = 0.01
I1017 20:05:10.160193 22869 solver.cpp:218] Iteration 42300 (3.30169 iter/s, 30.2875s/100 iters), loss = 0.207535
I1017 20:05:10.160305 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.207534 (* 1 = 0.207534 loss)
I1017 20:05:10.160322 22869 sgd_solver.cpp:105] Iteration 42300, lr = 0.01
I1017 20:05:40.409551 22869 solver.cpp:218] Iteration 42400 (3.30587 iter/s, 30.2493s/100 iters), loss = 0.0809793
I1017 20:05:40.409931 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0809781 (* 1 = 0.0809781 loss)
I1017 20:05:40.409951 22869 sgd_solver.cpp:105] Iteration 42400, lr = 0.01
I1017 20:06:10.383937 22869 solver.cpp:330] Iteration 42500, Testing net (#0)
I1017 20:06:26.851387 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 20:06:27.191782 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.60296 (* 1 = 1.60296 loss)
I1017 20:06:27.191798 22869 solver.cpp:397]     Test net output #1: accuracy = 0.6563
I1017 20:06:27.492507 22869 solver.cpp:218] Iteration 42500 (2.12393 iter/s, 47.0826s/100 iters), loss = 0.296131
I1017 20:06:27.492538 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.29613 (* 1 = 0.29613 loss)
I1017 20:06:27.492544 22869 sgd_solver.cpp:105] Iteration 42500, lr = 0.01
I1017 20:06:57.783411 22869 solver.cpp:218] Iteration 42600 (3.30133 iter/s, 30.2909s/100 iters), loss = 0.340939
I1017 20:06:57.783506 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.340938 (* 1 = 0.340938 loss)
I1017 20:06:57.783524 22869 sgd_solver.cpp:105] Iteration 42600, lr = 0.01
I1017 20:07:28.052033 22869 solver.cpp:218] Iteration 42700 (3.30376 iter/s, 30.2685s/100 iters), loss = 0.158366
I1017 20:07:28.052175 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.158365 (* 1 = 0.158365 loss)
I1017 20:07:28.052184 22869 sgd_solver.cpp:105] Iteration 42700, lr = 0.01
I1017 20:07:58.307538 22869 solver.cpp:218] Iteration 42800 (3.3052 iter/s, 30.2554s/100 iters), loss = 0.157228
I1017 20:07:58.307678 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.157227 (* 1 = 0.157227 loss)
I1017 20:07:58.307687 22869 sgd_solver.cpp:105] Iteration 42800, lr = 0.01
I1017 20:08:28.554515 22869 solver.cpp:218] Iteration 42900 (3.30613 iter/s, 30.2468s/100 iters), loss = 0.175302
I1017 20:08:28.554656 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.1753 (* 1 = 0.1753 loss)
I1017 20:08:28.554663 22869 sgd_solver.cpp:105] Iteration 42900, lr = 0.01
I1017 20:08:57.328546 22877 data_layer.cpp:73] Restarting data prefetching from start.
I1017 20:08:58.533239 22869 solver.cpp:330] Iteration 43000, Testing net (#0)
I1017 20:09:14.979800 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 20:09:15.314174 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.60272 (* 1 = 1.60272 loss)
I1017 20:09:15.314193 22869 solver.cpp:397]     Test net output #1: accuracy = 0.6637
I1017 20:09:15.608906 22869 solver.cpp:218] Iteration 43000 (2.12521 iter/s, 47.0542s/100 iters), loss = 0.0969111
I1017 20:09:15.608944 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0969099 (* 1 = 0.0969099 loss)
I1017 20:09:15.608952 22869 sgd_solver.cpp:105] Iteration 43000, lr = 0.01
I1017 20:09:45.900377 22869 solver.cpp:218] Iteration 43100 (3.30126 iter/s, 30.2914s/100 iters), loss = 0.190361
I1017 20:09:45.900533 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.19036 (* 1 = 0.19036 loss)
I1017 20:09:45.900542 22869 sgd_solver.cpp:105] Iteration 43100, lr = 0.01
I1017 20:10:16.193990 22869 solver.cpp:218] Iteration 43200 (3.30104 iter/s, 30.2935s/100 iters), loss = 0.17184
I1017 20:10:16.194133 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.171838 (* 1 = 0.171838 loss)
I1017 20:10:16.194141 22869 sgd_solver.cpp:105] Iteration 43200, lr = 0.01
I1017 20:10:46.486986 22869 solver.cpp:218] Iteration 43300 (3.30111 iter/s, 30.2929s/100 iters), loss = 0.369978
I1017 20:10:46.488911 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.369977 (* 1 = 0.369977 loss)
I1017 20:10:46.488932 22869 sgd_solver.cpp:105] Iteration 43300, lr = 0.01
I1017 20:11:16.791421 22869 solver.cpp:218] Iteration 43400 (3.30006 iter/s, 30.3025s/100 iters), loss = 0.235588
I1017 20:11:16.791529 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.235587 (* 1 = 0.235587 loss)
I1017 20:11:16.791538 22869 sgd_solver.cpp:105] Iteration 43400, lr = 0.01
I1017 20:11:46.813120 22869 solver.cpp:330] Iteration 43500, Testing net (#0)
I1017 20:12:03.303997 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 20:12:03.638638 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.65676 (* 1 = 1.65676 loss)
I1017 20:12:03.638653 22869 solver.cpp:397]     Test net output #1: accuracy = 0.6498
I1017 20:12:03.933466 22869 solver.cpp:218] Iteration 43500 (2.12125 iter/s, 47.1419s/100 iters), loss = 0.273879
I1017 20:12:03.933496 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.273878 (* 1 = 0.273878 loss)
I1017 20:12:03.933503 22869 sgd_solver.cpp:105] Iteration 43500, lr = 0.01
I1017 20:12:34.205488 22869 solver.cpp:218] Iteration 43600 (3.30338 iter/s, 30.272s/100 iters), loss = 0.118638
I1017 20:12:34.205643 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.118637 (* 1 = 0.118637 loss)
I1017 20:12:34.205653 22869 sgd_solver.cpp:105] Iteration 43600, lr = 0.01
I1017 20:13:04.507832 22869 solver.cpp:218] Iteration 43700 (3.30009 iter/s, 30.3022s/100 iters), loss = 0.180633
I1017 20:13:04.507928 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.180632 (* 1 = 0.180632 loss)
I1017 20:13:04.507936 22869 sgd_solver.cpp:105] Iteration 43700, lr = 0.01
I1017 20:13:34.775090 22869 solver.cpp:218] Iteration 43800 (3.30391 iter/s, 30.2672s/100 iters), loss = 0.139637
I1017 20:13:34.775202 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.139636 (* 1 = 0.139636 loss)
I1017 20:13:34.775223 22869 sgd_solver.cpp:105] Iteration 43800, lr = 0.01
I1017 20:14:05.072165 22869 solver.cpp:218] Iteration 43900 (3.30066 iter/s, 30.297s/100 iters), loss = 0.307058
I1017 20:14:05.072306 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.307057 (* 1 = 0.307057 loss)
I1017 20:14:05.072315 22869 sgd_solver.cpp:105] Iteration 43900, lr = 0.01
I1017 20:14:33.884227 22877 data_layer.cpp:73] Restarting data prefetching from start.
I1017 20:14:35.101578 22869 solver.cpp:330] Iteration 44000, Testing net (#0)
I1017 20:14:51.556538 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 20:14:51.894984 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.60062 (* 1 = 1.60062 loss)
I1017 20:14:51.894999 22869 solver.cpp:397]     Test net output #1: accuracy = 0.6573
I1017 20:14:52.194764 22869 solver.cpp:218] Iteration 44000 (2.12213 iter/s, 47.1225s/100 iters), loss = 0.165802
I1017 20:14:52.194800 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.165801 (* 1 = 0.165801 loss)
I1017 20:14:52.194808 22869 sgd_solver.cpp:105] Iteration 44000, lr = 0.01
I1017 20:15:22.505530 22869 solver.cpp:218] Iteration 44100 (3.29916 iter/s, 30.3107s/100 iters), loss = 0.179971
I1017 20:15:22.505642 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.179969 (* 1 = 0.179969 loss)
I1017 20:15:22.505650 22869 sgd_solver.cpp:105] Iteration 44100, lr = 0.01
I1017 20:15:52.793287 22869 solver.cpp:218] Iteration 44200 (3.30168 iter/s, 30.2876s/100 iters), loss = 0.226447
I1017 20:15:52.793385 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.226445 (* 1 = 0.226445 loss)
I1017 20:15:52.793391 22869 sgd_solver.cpp:105] Iteration 44200, lr = 0.01
I1017 20:16:23.099205 22869 solver.cpp:218] Iteration 44300 (3.2997 iter/s, 30.3058s/100 iters), loss = 0.330118
I1017 20:16:23.099349 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.330116 (* 1 = 0.330116 loss)
I1017 20:16:23.099359 22869 sgd_solver.cpp:105] Iteration 44300, lr = 0.01
I1017 20:16:53.394119 22869 solver.cpp:218] Iteration 44400 (3.3009 iter/s, 30.2948s/100 iters), loss = 0.220981
I1017 20:16:53.394259 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.22098 (* 1 = 0.22098 loss)
I1017 20:16:53.394266 22869 sgd_solver.cpp:105] Iteration 44400, lr = 0.01
I1017 20:17:23.417563 22869 solver.cpp:330] Iteration 44500, Testing net (#0)
I1017 20:17:39.890425 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 20:17:40.226053 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.61826 (* 1 = 1.61826 loss)
I1017 20:17:40.226070 22869 solver.cpp:397]     Test net output #1: accuracy = 0.6564
I1017 20:17:40.522750 22869 solver.cpp:218] Iteration 44500 (2.12186 iter/s, 47.1285s/100 iters), loss = 0.15639
I1017 20:17:40.522780 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.156389 (* 1 = 0.156389 loss)
I1017 20:17:40.522786 22869 sgd_solver.cpp:105] Iteration 44500, lr = 0.01
I1017 20:18:10.886011 22869 solver.cpp:218] Iteration 44600 (3.29346 iter/s, 30.3632s/100 iters), loss = 0.174408
I1017 20:18:10.886152 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.174407 (* 1 = 0.174407 loss)
I1017 20:18:10.886160 22869 sgd_solver.cpp:105] Iteration 44600, lr = 0.01
I1017 20:18:41.199129 22869 solver.cpp:218] Iteration 44700 (3.29892 iter/s, 30.313s/100 iters), loss = 0.265292
I1017 20:18:41.199250 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.265291 (* 1 = 0.265291 loss)
I1017 20:18:41.199259 22869 sgd_solver.cpp:105] Iteration 44700, lr = 0.01
I1017 20:19:11.503479 22869 solver.cpp:218] Iteration 44800 (3.29987 iter/s, 30.3042s/100 iters), loss = 0.139082
I1017 20:19:11.503597 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.13908 (* 1 = 0.13908 loss)
I1017 20:19:11.503604 22869 sgd_solver.cpp:105] Iteration 44800, lr = 0.01
I1017 20:19:41.822316 22869 solver.cpp:218] Iteration 44900 (3.29829 iter/s, 30.3187s/100 iters), loss = 0.163194
I1017 20:19:41.822420 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.163192 (* 1 = 0.163192 loss)
I1017 20:19:41.822427 22869 sgd_solver.cpp:105] Iteration 44900, lr = 0.01
I1017 20:20:10.623602 22877 data_layer.cpp:73] Restarting data prefetching from start.
I1017 20:20:11.835304 22869 solver.cpp:330] Iteration 45000, Testing net (#0)
I1017 20:20:28.307687 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 20:20:28.646077 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.54032 (* 1 = 1.54032 loss)
I1017 20:20:28.646095 22869 solver.cpp:397]     Test net output #1: accuracy = 0.6704
I1017 20:20:28.945622 22869 solver.cpp:218] Iteration 45000 (2.1221 iter/s, 47.1232s/100 iters), loss = 0.193511
I1017 20:20:28.945653 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.19351 (* 1 = 0.19351 loss)
I1017 20:20:28.945660 22869 sgd_solver.cpp:105] Iteration 45000, lr = 0.01
I1017 20:20:59.249687 22869 solver.cpp:218] Iteration 45100 (3.29989 iter/s, 30.304s/100 iters), loss = 0.220557
I1017 20:20:59.249832 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.220556 (* 1 = 0.220556 loss)
I1017 20:20:59.249841 22869 sgd_solver.cpp:105] Iteration 45100, lr = 0.01
I1017 20:21:29.540331 22869 solver.cpp:218] Iteration 45200 (3.30137 iter/s, 30.2905s/100 iters), loss = 0.0889124
I1017 20:21:29.540472 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0889111 (* 1 = 0.0889111 loss)
I1017 20:21:29.540480 22869 sgd_solver.cpp:105] Iteration 45200, lr = 0.01
I1017 20:21:59.872303 22869 solver.cpp:218] Iteration 45300 (3.29687 iter/s, 30.3318s/100 iters), loss = 0.294755
I1017 20:21:59.872413 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.294754 (* 1 = 0.294754 loss)
I1017 20:21:59.872421 22869 sgd_solver.cpp:105] Iteration 45300, lr = 0.01
I1017 20:22:30.176751 22869 solver.cpp:218] Iteration 45400 (3.29986 iter/s, 30.3043s/100 iters), loss = 0.16673
I1017 20:22:30.176873 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.166729 (* 1 = 0.166729 loss)
I1017 20:22:30.176889 22869 sgd_solver.cpp:105] Iteration 45400, lr = 0.01
I1017 20:23:00.195410 22869 solver.cpp:330] Iteration 45500, Testing net (#0)
I1017 20:23:16.636245 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 20:23:16.970422 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.63847 (* 1 = 1.63847 loss)
I1017 20:23:16.970437 22869 solver.cpp:397]     Test net output #1: accuracy = 0.6519
I1017 20:23:17.271095 22869 solver.cpp:218] Iteration 45500 (2.1234 iter/s, 47.0942s/100 iters), loss = 0.148414
I1017 20:23:17.271124 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.148413 (* 1 = 0.148413 loss)
I1017 20:23:17.271131 22869 sgd_solver.cpp:105] Iteration 45500, lr = 0.01
I1017 20:23:47.604305 22869 solver.cpp:218] Iteration 45600 (3.29672 iter/s, 30.3332s/100 iters), loss = 0.154874
I1017 20:23:47.604447 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.154873 (* 1 = 0.154873 loss)
I1017 20:23:47.604456 22869 sgd_solver.cpp:105] Iteration 45600, lr = 0.01
I1017 20:24:17.902415 22869 solver.cpp:218] Iteration 45700 (3.30055 iter/s, 30.298s/100 iters), loss = 0.0576928
I1017 20:24:17.902523 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0576914 (* 1 = 0.0576914 loss)
I1017 20:24:17.902530 22869 sgd_solver.cpp:105] Iteration 45700, lr = 0.01
I1017 20:24:48.194371 22869 solver.cpp:218] Iteration 45800 (3.30122 iter/s, 30.2918s/100 iters), loss = 0.256314
I1017 20:24:48.194552 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.256313 (* 1 = 0.256313 loss)
I1017 20:24:48.194562 22869 sgd_solver.cpp:105] Iteration 45800, lr = 0.01
I1017 20:25:18.507815 22869 solver.cpp:218] Iteration 45900 (3.29889 iter/s, 30.3133s/100 iters), loss = 0.230223
I1017 20:25:18.507938 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.230221 (* 1 = 0.230221 loss)
I1017 20:25:18.507946 22869 sgd_solver.cpp:105] Iteration 45900, lr = 0.01
I1017 20:25:47.303932 22877 data_layer.cpp:73] Restarting data prefetching from start.
I1017 20:25:48.510915 22869 solver.cpp:330] Iteration 46000, Testing net (#0)
I1017 20:26:04.925128 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 20:26:05.260413 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.5956 (* 1 = 1.5956 loss)
I1017 20:26:05.260429 22869 solver.cpp:397]     Test net output #1: accuracy = 0.6609
I1017 20:26:05.561547 22869 solver.cpp:218] Iteration 46000 (2.12524 iter/s, 47.0536s/100 iters), loss = 0.283619
I1017 20:26:05.561581 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.283617 (* 1 = 0.283617 loss)
I1017 20:26:05.561589 22869 sgd_solver.cpp:105] Iteration 46000, lr = 0.01
I1017 20:26:35.818065 22869 solver.cpp:218] Iteration 46100 (3.30508 iter/s, 30.2565s/100 iters), loss = 0.124195
I1017 20:26:35.818740 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.124194 (* 1 = 0.124194 loss)
I1017 20:26:35.818758 22869 sgd_solver.cpp:105] Iteration 46100, lr = 0.01
I1017 20:27:06.093300 22869 solver.cpp:218] Iteration 46200 (3.3031 iter/s, 30.2746s/100 iters), loss = 0.122834
I1017 20:27:06.093410 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.122833 (* 1 = 0.122833 loss)
I1017 20:27:06.093427 22869 sgd_solver.cpp:105] Iteration 46200, lr = 0.01
I1017 20:27:36.358248 22869 solver.cpp:218] Iteration 46300 (3.30416 iter/s, 30.2648s/100 iters), loss = 0.283986
I1017 20:27:36.358383 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.283985 (* 1 = 0.283985 loss)
I1017 20:27:36.358392 22869 sgd_solver.cpp:105] Iteration 46300, lr = 0.01
I1017 20:28:06.623412 22869 solver.cpp:218] Iteration 46400 (3.30414 iter/s, 30.265s/100 iters), loss = 0.29611
I1017 20:28:06.623564 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.296109 (* 1 = 0.296109 loss)
I1017 20:28:06.623584 22869 sgd_solver.cpp:105] Iteration 46400, lr = 0.01
I1017 20:28:36.600971 22869 solver.cpp:330] Iteration 46500, Testing net (#0)
I1017 20:28:53.095180 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 20:28:53.433928 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.57852 (* 1 = 1.57852 loss)
I1017 20:28:53.433943 22869 solver.cpp:397]     Test net output #1: accuracy = 0.6597
I1017 20:28:53.731570 22869 solver.cpp:218] Iteration 46500 (2.12278 iter/s, 47.108s/100 iters), loss = 0.273131
I1017 20:28:53.731604 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.273129 (* 1 = 0.273129 loss)
I1017 20:28:53.731611 22869 sgd_solver.cpp:105] Iteration 46500, lr = 0.01
I1017 20:29:23.996539 22869 solver.cpp:218] Iteration 46600 (3.30415 iter/s, 30.2649s/100 iters), loss = 0.159719
I1017 20:29:23.996641 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.159717 (* 1 = 0.159717 loss)
I1017 20:29:23.996659 22869 sgd_solver.cpp:105] Iteration 46600, lr = 0.01
I1017 20:29:54.232517 22869 solver.cpp:218] Iteration 46700 (3.30733 iter/s, 30.2359s/100 iters), loss = 0.220754
I1017 20:29:54.232627 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.220753 (* 1 = 0.220753 loss)
I1017 20:29:54.232635 22869 sgd_solver.cpp:105] Iteration 46700, lr = 0.01
I1017 20:30:24.492422 22869 solver.cpp:218] Iteration 46800 (3.30471 iter/s, 30.2598s/100 iters), loss = 0.224202
I1017 20:30:24.492552 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.2242 (* 1 = 0.2242 loss)
I1017 20:30:24.492570 22869 sgd_solver.cpp:105] Iteration 46800, lr = 0.01
I1017 20:30:54.731874 22869 solver.cpp:218] Iteration 46900 (3.30695 iter/s, 30.2393s/100 iters), loss = 0.231238
I1017 20:30:54.732020 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.231236 (* 1 = 0.231236 loss)
I1017 20:30:54.732029 22869 sgd_solver.cpp:105] Iteration 46900, lr = 0.01
I1017 20:31:23.522809 22877 data_layer.cpp:73] Restarting data prefetching from start.
I1017 20:31:24.733316 22869 solver.cpp:330] Iteration 47000, Testing net (#0)
I1017 20:31:41.165330 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 20:31:41.501864 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.55507 (* 1 = 1.55507 loss)
I1017 20:31:41.501879 22869 solver.cpp:397]     Test net output #1: accuracy = 0.6638
I1017 20:31:41.798972 22869 solver.cpp:218] Iteration 47000 (2.12463 iter/s, 47.0669s/100 iters), loss = 0.242609
I1017 20:31:41.799017 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.242607 (* 1 = 0.242607 loss)
I1017 20:31:41.799024 22869 sgd_solver.cpp:105] Iteration 47000, lr = 0.01
I1017 20:32:12.022629 22869 solver.cpp:218] Iteration 47100 (3.30867 iter/s, 30.2236s/100 iters), loss = 0.236735
I1017 20:32:12.022771 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.236733 (* 1 = 0.236733 loss)
I1017 20:32:12.022780 22869 sgd_solver.cpp:105] Iteration 47100, lr = 0.01
I1017 20:32:42.314393 22869 solver.cpp:218] Iteration 47200 (3.30124 iter/s, 30.2916s/100 iters), loss = 0.140429
I1017 20:32:42.314499 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.140428 (* 1 = 0.140428 loss)
I1017 20:32:42.314515 22869 sgd_solver.cpp:105] Iteration 47200, lr = 0.01
I1017 20:33:12.581497 22869 solver.cpp:218] Iteration 47300 (3.30393 iter/s, 30.267s/100 iters), loss = 0.185752
I1017 20:33:12.581624 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.185751 (* 1 = 0.185751 loss)
I1017 20:33:12.581630 22869 sgd_solver.cpp:105] Iteration 47300, lr = 0.01
I1017 20:33:42.878219 22869 solver.cpp:218] Iteration 47400 (3.3007 iter/s, 30.2966s/100 iters), loss = 0.106382
I1017 20:33:42.878362 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.106381 (* 1 = 0.106381 loss)
I1017 20:33:42.878371 22869 sgd_solver.cpp:105] Iteration 47400, lr = 0.01
I1017 20:34:12.833632 22869 solver.cpp:330] Iteration 47500, Testing net (#0)
I1017 20:34:29.317286 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 20:34:29.654341 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.6117 (* 1 = 1.6117 loss)
I1017 20:34:29.654357 22869 solver.cpp:397]     Test net output #1: accuracy = 0.6563
I1017 20:34:29.953061 22869 solver.cpp:218] Iteration 47500 (2.12428 iter/s, 47.0747s/100 iters), loss = 0.306218
I1017 20:34:29.953095 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.306217 (* 1 = 0.306217 loss)
I1017 20:34:29.953102 22869 sgd_solver.cpp:105] Iteration 47500, lr = 0.01
I1017 20:35:00.191941 22869 solver.cpp:218] Iteration 47600 (3.30701 iter/s, 30.2388s/100 iters), loss = 0.16119
I1017 20:35:00.192037 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.161189 (* 1 = 0.161189 loss)
I1017 20:35:00.192046 22869 sgd_solver.cpp:105] Iteration 47600, lr = 0.01
I1017 20:35:30.457424 22869 solver.cpp:218] Iteration 47700 (3.30412 iter/s, 30.2652s/100 iters), loss = 0.0900116
I1017 20:35:30.457526 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0900103 (* 1 = 0.0900103 loss)
I1017 20:35:30.457543 22869 sgd_solver.cpp:105] Iteration 47700, lr = 0.01
I1017 20:36:00.705127 22869 solver.cpp:218] Iteration 47800 (3.30605 iter/s, 30.2476s/100 iters), loss = 0.19438
I1017 20:36:00.705253 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.194379 (* 1 = 0.194379 loss)
I1017 20:36:00.705260 22869 sgd_solver.cpp:105] Iteration 47800, lr = 0.01
I1017 20:36:30.952802 22869 solver.cpp:218] Iteration 47900 (3.30605 iter/s, 30.2475s/100 iters), loss = 0.315838
I1017 20:36:30.952980 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.315837 (* 1 = 0.315837 loss)
I1017 20:36:30.952991 22869 sgd_solver.cpp:105] Iteration 47900, lr = 0.01
I1017 20:36:59.670019 22877 data_layer.cpp:73] Restarting data prefetching from start.
I1017 20:37:00.879083 22869 solver.cpp:330] Iteration 48000, Testing net (#0)
I1017 20:37:17.354393 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 20:37:17.690171 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.60148 (* 1 = 1.60148 loss)
I1017 20:37:17.690186 22869 solver.cpp:397]     Test net output #1: accuracy = 0.6619
I1017 20:37:17.987671 22869 solver.cpp:218] Iteration 48000 (2.12609 iter/s, 47.0347s/100 iters), loss = 0.0865817
I1017 20:37:17.987705 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0865803 (* 1 = 0.0865803 loss)
I1017 20:37:17.987712 22869 sgd_solver.cpp:105] Iteration 48000, lr = 0.01
I1017 20:37:48.269826 22869 solver.cpp:218] Iteration 48100 (3.30228 iter/s, 30.2821s/100 iters), loss = 0.213282
I1017 20:37:48.269906 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.21328 (* 1 = 0.21328 loss)
I1017 20:37:48.269928 22869 sgd_solver.cpp:105] Iteration 48100, lr = 0.01
I1017 20:38:18.600926 22869 solver.cpp:218] Iteration 48200 (3.29696 iter/s, 30.331s/100 iters), loss = 0.24117
I1017 20:38:18.601066 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.241169 (* 1 = 0.241169 loss)
I1017 20:38:18.601074 22869 sgd_solver.cpp:105] Iteration 48200, lr = 0.01
I1017 20:38:48.820850 22869 solver.cpp:218] Iteration 48300 (3.30909 iter/s, 30.2198s/100 iters), loss = 0.0729841
I1017 20:38:48.820950 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0729826 (* 1 = 0.0729826 loss)
I1017 20:38:48.820956 22869 sgd_solver.cpp:105] Iteration 48300, lr = 0.01
I1017 20:39:19.114763 22869 solver.cpp:218] Iteration 48400 (3.301 iter/s, 30.2938s/100 iters), loss = 0.221642
I1017 20:39:19.114863 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.221641 (* 1 = 0.221641 loss)
I1017 20:39:19.114871 22869 sgd_solver.cpp:105] Iteration 48400, lr = 0.01
I1017 20:39:49.142359 22869 solver.cpp:330] Iteration 48500, Testing net (#0)
I1017 20:40:05.621966 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 20:40:05.961014 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.61239 (* 1 = 1.61239 loss)
I1017 20:40:05.961032 22869 solver.cpp:397]     Test net output #1: accuracy = 0.6583
I1017 20:40:06.259493 22869 solver.cpp:218] Iteration 48500 (2.12113 iter/s, 47.1446s/100 iters), loss = 0.13338
I1017 20:40:06.259526 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.133378 (* 1 = 0.133378 loss)
I1017 20:40:06.259532 22869 sgd_solver.cpp:105] Iteration 48500, lr = 0.01
I1017 20:40:36.511257 22869 solver.cpp:218] Iteration 48600 (3.3056 iter/s, 30.2517s/100 iters), loss = 0.202533
I1017 20:40:36.511394 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.202532 (* 1 = 0.202532 loss)
I1017 20:40:36.511401 22869 sgd_solver.cpp:105] Iteration 48600, lr = 0.01
I1017 20:41:06.780357 22869 solver.cpp:218] Iteration 48700 (3.30371 iter/s, 30.269s/100 iters), loss = 0.17363
I1017 20:41:06.780470 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.173629 (* 1 = 0.173629 loss)
I1017 20:41:06.780478 22869 sgd_solver.cpp:105] Iteration 48700, lr = 0.01
I1017 20:41:37.053354 22869 solver.cpp:218] Iteration 48800 (3.30329 iter/s, 30.2729s/100 iters), loss = 0.213017
I1017 20:41:37.053447 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.213016 (* 1 = 0.213016 loss)
I1017 20:41:37.053454 22869 sgd_solver.cpp:105] Iteration 48800, lr = 0.01
I1017 20:42:07.348733 22869 solver.cpp:218] Iteration 48900 (3.30084 iter/s, 30.2953s/100 iters), loss = 0.242485
I1017 20:42:07.348820 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.242483 (* 1 = 0.242483 loss)
I1017 20:42:07.348839 22869 sgd_solver.cpp:105] Iteration 48900, lr = 0.01
I1017 20:42:36.097080 22877 data_layer.cpp:73] Restarting data prefetching from start.
I1017 20:42:37.307541 22869 solver.cpp:330] Iteration 49000, Testing net (#0)
I1017 20:42:53.788666 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 20:42:54.126552 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.57016 (* 1 = 1.57016 loss)
I1017 20:42:54.126569 22869 solver.cpp:397]     Test net output #1: accuracy = 0.6637
I1017 20:42:54.427686 22869 solver.cpp:218] Iteration 49000 (2.1241 iter/s, 47.0789s/100 iters), loss = 0.236921
I1017 20:42:54.427718 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.23692 (* 1 = 0.23692 loss)
I1017 20:42:54.427726 22869 sgd_solver.cpp:105] Iteration 49000, lr = 0.01
I1017 20:43:24.644862 22869 solver.cpp:218] Iteration 49100 (3.30938 iter/s, 30.2171s/100 iters), loss = 0.221649
I1017 20:43:24.645006 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.221647 (* 1 = 0.221647 loss)
I1017 20:43:24.645015 22869 sgd_solver.cpp:105] Iteration 49100, lr = 0.01
I1017 20:43:54.916193 22869 solver.cpp:218] Iteration 49200 (3.30347 iter/s, 30.2712s/100 iters), loss = 0.296162
I1017 20:43:54.916337 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.29616 (* 1 = 0.29616 loss)
I1017 20:43:54.916345 22869 sgd_solver.cpp:105] Iteration 49200, lr = 0.01
I1017 20:44:25.189496 22869 solver.cpp:218] Iteration 49300 (3.30326 iter/s, 30.2732s/100 iters), loss = 0.246215
I1017 20:44:25.189638 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.246213 (* 1 = 0.246213 loss)
I1017 20:44:25.189656 22869 sgd_solver.cpp:105] Iteration 49300, lr = 0.01
I1017 20:44:55.437975 22869 solver.cpp:218] Iteration 49400 (3.30597 iter/s, 30.2483s/100 iters), loss = 0.0964286
I1017 20:44:55.438117 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0964273 (* 1 = 0.0964273 loss)
I1017 20:44:55.438125 22869 sgd_solver.cpp:105] Iteration 49400, lr = 0.01
I1017 20:45:25.467450 22869 solver.cpp:330] Iteration 49500, Testing net (#0)
I1017 20:45:41.863147 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 20:45:42.199642 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.5902 (* 1 = 1.5902 loss)
I1017 20:45:42.199658 22869 solver.cpp:397]     Test net output #1: accuracy = 0.6572
I1017 20:45:42.496456 22869 solver.cpp:218] Iteration 49500 (2.12502 iter/s, 47.0583s/100 iters), loss = 0.141912
I1017 20:45:42.496490 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.14191 (* 1 = 0.14191 loss)
I1017 20:45:42.496496 22869 sgd_solver.cpp:105] Iteration 49500, lr = 0.01
I1017 20:46:12.804273 22869 solver.cpp:218] Iteration 49600 (3.29948 iter/s, 30.3078s/100 iters), loss = 0.263883
I1017 20:46:12.804414 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.263881 (* 1 = 0.263881 loss)
I1017 20:46:12.804422 22869 sgd_solver.cpp:105] Iteration 49600, lr = 0.01
I1017 20:46:43.051239 22869 solver.cpp:218] Iteration 49700 (3.30613 iter/s, 30.2468s/100 iters), loss = 0.0986926
I1017 20:46:43.051327 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0986913 (* 1 = 0.0986913 loss)
I1017 20:46:43.051345 22869 sgd_solver.cpp:105] Iteration 49700, lr = 0.01
I1017 20:47:13.256271 22869 solver.cpp:218] Iteration 49800 (3.31072 iter/s, 30.2049s/100 iters), loss = 0.129204
I1017 20:47:13.256371 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.129203 (* 1 = 0.129203 loss)
I1017 20:47:13.256377 22869 sgd_solver.cpp:105] Iteration 49800, lr = 0.01
I1017 20:47:43.540350 22869 solver.cpp:218] Iteration 49900 (3.30208 iter/s, 30.284s/100 iters), loss = 0.203425
I1017 20:47:43.540447 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.203424 (* 1 = 0.203424 loss)
I1017 20:47:43.540465 22869 sgd_solver.cpp:105] Iteration 49900, lr = 0.01
I1017 20:48:12.282491 22877 data_layer.cpp:73] Restarting data prefetching from start.
I1017 20:48:13.490685 22869 solver.cpp:330] Iteration 50000, Testing net (#0)
I1017 20:48:29.902961 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 20:48:30.244055 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.64072 (* 1 = 1.64072 loss)
I1017 20:48:30.244071 22869 solver.cpp:397]     Test net output #1: accuracy = 0.6562
I1017 20:48:30.545759 22869 solver.cpp:218] Iteration 50000 (2.12742 iter/s, 47.0053s/100 iters), loss = 0.350582
I1017 20:48:30.545790 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.350581 (* 1 = 0.350581 loss)
I1017 20:48:30.545795 22869 sgd_solver.cpp:46] MultiStep Status: Iteration 50000, step = 1
I1017 20:48:30.545799 22869 sgd_solver.cpp:105] Iteration 50000, lr = 0.001
I1017 20:49:00.812458 22869 solver.cpp:218] Iteration 50100 (3.30397 iter/s, 30.2667s/100 iters), loss = 0.0630171
I1017 20:49:00.812536 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0630158 (* 1 = 0.0630158 loss)
I1017 20:49:00.812544 22869 sgd_solver.cpp:105] Iteration 50100, lr = 0.001
I1017 20:49:31.070729 22869 solver.cpp:218] Iteration 50200 (3.30489 iter/s, 30.2582s/100 iters), loss = 0.0913882
I1017 20:49:31.070873 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0913869 (* 1 = 0.0913869 loss)
I1017 20:49:31.070883 22869 sgd_solver.cpp:105] Iteration 50200, lr = 0.001
I1017 20:50:01.357651 22869 solver.cpp:218] Iteration 50300 (3.30177 iter/s, 30.2868s/100 iters), loss = 0.11248
I1017 20:50:01.357817 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.112478 (* 1 = 0.112478 loss)
I1017 20:50:01.357825 22869 sgd_solver.cpp:105] Iteration 50300, lr = 0.001
I1017 20:50:31.627300 22869 solver.cpp:218] Iteration 50400 (3.30366 iter/s, 30.2695s/100 iters), loss = 0.0823216
I1017 20:50:31.627423 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0823203 (* 1 = 0.0823203 loss)
I1017 20:50:31.627446 22869 sgd_solver.cpp:105] Iteration 50400, lr = 0.001
I1017 20:51:01.621943 22869 solver.cpp:330] Iteration 50500, Testing net (#0)
I1017 20:51:18.026403 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 20:51:18.364275 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.31736 (* 1 = 1.31736 loss)
I1017 20:51:18.364290 22869 solver.cpp:397]     Test net output #1: accuracy = 0.7128
I1017 20:51:18.661257 22869 solver.cpp:218] Iteration 50500 (2.12613 iter/s, 47.0338s/100 iters), loss = 0.103416
I1017 20:51:18.661288 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.103415 (* 1 = 0.103415 loss)
I1017 20:51:18.661295 22869 sgd_solver.cpp:105] Iteration 50500, lr = 0.001
I1017 20:51:48.970713 22869 solver.cpp:218] Iteration 50600 (3.2993 iter/s, 30.3094s/100 iters), loss = 0.0310803
I1017 20:51:48.970796 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0310789 (* 1 = 0.0310789 loss)
I1017 20:51:48.970813 22869 sgd_solver.cpp:105] Iteration 50600, lr = 0.001
I1017 20:52:19.238489 22869 solver.cpp:218] Iteration 50700 (3.30385 iter/s, 30.2677s/100 iters), loss = 0.0459863
I1017 20:52:19.238572 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0459849 (* 1 = 0.0459849 loss)
I1017 20:52:19.238587 22869 sgd_solver.cpp:105] Iteration 50700, lr = 0.001
I1017 20:52:49.494920 22869 solver.cpp:218] Iteration 50800 (3.30509 iter/s, 30.2563s/100 iters), loss = 0.0482676
I1017 20:52:49.494983 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0482662 (* 1 = 0.0482662 loss)
I1017 20:52:49.494990 22869 sgd_solver.cpp:105] Iteration 50800, lr = 0.001
I1017 20:53:19.762491 22869 solver.cpp:218] Iteration 50900 (3.30387 iter/s, 30.2675s/100 iters), loss = 0.0147178
I1017 20:53:19.762624 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0147164 (* 1 = 0.0147164 loss)
I1017 20:53:19.762632 22869 sgd_solver.cpp:105] Iteration 50900, lr = 0.001
I1017 20:53:48.550765 22877 data_layer.cpp:73] Restarting data prefetching from start.
I1017 20:53:49.769148 22869 solver.cpp:330] Iteration 51000, Testing net (#0)
I1017 20:54:06.266957 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 20:54:06.603727 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.28499 (* 1 = 1.28499 loss)
I1017 20:54:06.603742 22869 solver.cpp:397]     Test net output #1: accuracy = 0.7178
I1017 20:54:06.901958 22869 solver.cpp:218] Iteration 51000 (2.12137 iter/s, 47.1393s/100 iters), loss = 0.0120727
I1017 20:54:06.901995 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0120713 (* 1 = 0.0120713 loss)
I1017 20:54:06.902003 22869 sgd_solver.cpp:105] Iteration 51000, lr = 0.001
I1017 20:54:37.162997 22869 solver.cpp:218] Iteration 51100 (3.30458 iter/s, 30.261s/100 iters), loss = 0.0567102
I1017 20:54:37.163148 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0567088 (* 1 = 0.0567088 loss)
I1017 20:54:37.163157 22869 sgd_solver.cpp:105] Iteration 51100, lr = 0.001
I1017 20:55:07.411110 22869 solver.cpp:218] Iteration 51200 (3.30601 iter/s, 30.248s/100 iters), loss = 0.00845964
I1017 20:55:07.411245 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00845824 (* 1 = 0.00845824 loss)
I1017 20:55:07.411253 22869 sgd_solver.cpp:105] Iteration 51200, lr = 0.001
I1017 20:55:37.708168 22869 solver.cpp:218] Iteration 51300 (3.30066 iter/s, 30.2969s/100 iters), loss = 0.0342693
I1017 20:55:37.708313 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0342679 (* 1 = 0.0342679 loss)
I1017 20:55:37.708323 22869 sgd_solver.cpp:105] Iteration 51300, lr = 0.001
I1017 20:56:07.991525 22869 solver.cpp:218] Iteration 51400 (3.30216 iter/s, 30.2832s/100 iters), loss = 0.0247695
I1017 20:56:07.991627 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0247681 (* 1 = 0.0247681 loss)
I1017 20:56:07.991636 22869 sgd_solver.cpp:105] Iteration 51400, lr = 0.001
I1017 20:56:37.981101 22869 solver.cpp:330] Iteration 51500, Testing net (#0)
I1017 20:56:54.442873 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 20:56:54.781615 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.2674 (* 1 = 1.2674 loss)
I1017 20:56:54.781630 22869 solver.cpp:397]     Test net output #1: accuracy = 0.7214
I1017 20:56:55.082547 22869 solver.cpp:218] Iteration 51500 (2.12355 iter/s, 47.0909s/100 iters), loss = 0.0313957
I1017 20:56:55.082586 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0313943 (* 1 = 0.0313943 loss)
I1017 20:56:55.082605 22869 sgd_solver.cpp:105] Iteration 51500, lr = 0.001
I1017 20:57:25.368254 22869 solver.cpp:218] Iteration 51600 (3.30189 iter/s, 30.2857s/100 iters), loss = 0.0409359
I1017 20:57:25.368392 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0409346 (* 1 = 0.0409346 loss)
I1017 20:57:25.368399 22869 sgd_solver.cpp:105] Iteration 51600, lr = 0.001
I1017 20:57:55.623352 22869 solver.cpp:218] Iteration 51700 (3.30524 iter/s, 30.255s/100 iters), loss = 0.0385737
I1017 20:57:55.623450 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0385723 (* 1 = 0.0385723 loss)
I1017 20:57:55.623457 22869 sgd_solver.cpp:105] Iteration 51700, lr = 0.001
I1017 20:58:25.829126 22869 solver.cpp:218] Iteration 51800 (3.31064 iter/s, 30.2057s/100 iters), loss = 0.0170705
I1017 20:58:25.829257 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0170691 (* 1 = 0.0170691 loss)
I1017 20:58:25.829267 22869 sgd_solver.cpp:105] Iteration 51800, lr = 0.001
I1017 20:58:56.099236 22869 solver.cpp:218] Iteration 51900 (3.3036 iter/s, 30.27s/100 iters), loss = 0.00738808
I1017 20:58:56.099378 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00738668 (* 1 = 0.00738668 loss)
I1017 20:58:56.099387 22869 sgd_solver.cpp:105] Iteration 51900, lr = 0.001
I1017 20:59:24.861730 22877 data_layer.cpp:73] Restarting data prefetching from start.
I1017 20:59:26.075814 22869 solver.cpp:330] Iteration 52000, Testing net (#0)
I1017 20:59:42.496083 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 20:59:42.833633 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.25818 (* 1 = 1.25818 loss)
I1017 20:59:42.833649 22869 solver.cpp:397]     Test net output #1: accuracy = 0.7237
I1017 20:59:43.132637 22869 solver.cpp:218] Iteration 52000 (2.12616 iter/s, 47.0333s/100 iters), loss = 0.0618377
I1017 20:59:43.132669 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0618364 (* 1 = 0.0618364 loss)
I1017 20:59:43.132675 22869 sgd_solver.cpp:105] Iteration 52000, lr = 0.001
I1017 21:00:13.379065 22869 solver.cpp:218] Iteration 52100 (3.30618 iter/s, 30.2464s/100 iters), loss = 0.0461427
I1017 21:00:13.379216 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0461413 (* 1 = 0.0461413 loss)
I1017 21:00:13.379235 22869 sgd_solver.cpp:105] Iteration 52100, lr = 0.001
I1017 21:00:43.658969 22869 solver.cpp:218] Iteration 52200 (3.30254 iter/s, 30.2797s/100 iters), loss = 0.0719772
I1017 21:00:43.659085 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0719758 (* 1 = 0.0719758 loss)
I1017 21:00:43.659101 22869 sgd_solver.cpp:105] Iteration 52200, lr = 0.001
I1017 21:01:13.879096 22869 solver.cpp:218] Iteration 52300 (3.30907 iter/s, 30.22s/100 iters), loss = 0.0333131
I1017 21:01:13.879240 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0333117 (* 1 = 0.0333117 loss)
I1017 21:01:13.879250 22869 sgd_solver.cpp:105] Iteration 52300, lr = 0.001
I1017 21:01:44.131017 22869 solver.cpp:218] Iteration 52400 (3.30559 iter/s, 30.2518s/100 iters), loss = 0.0256378
I1017 21:01:44.131093 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0256364 (* 1 = 0.0256364 loss)
I1017 21:01:44.131101 22869 sgd_solver.cpp:105] Iteration 52400, lr = 0.001
I1017 21:02:14.090143 22869 solver.cpp:330] Iteration 52500, Testing net (#0)
I1017 21:02:30.567231 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 21:02:30.903175 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.25313 (* 1 = 1.25313 loss)
I1017 21:02:30.903193 22869 solver.cpp:397]     Test net output #1: accuracy = 0.7242
I1017 21:02:31.198604 22869 solver.cpp:218] Iteration 52500 (2.12461 iter/s, 47.0675s/100 iters), loss = 0.065499
I1017 21:02:31.198642 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0654976 (* 1 = 0.0654976 loss)
I1017 21:02:31.198648 22869 sgd_solver.cpp:105] Iteration 52500, lr = 0.001
I1017 21:03:01.442045 22869 solver.cpp:218] Iteration 52600 (3.30651 iter/s, 30.2434s/100 iters), loss = 0.00438415
I1017 21:03:01.442184 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00438275 (* 1 = 0.00438275 loss)
I1017 21:03:01.442193 22869 sgd_solver.cpp:105] Iteration 52600, lr = 0.001
I1017 21:03:31.690903 22869 solver.cpp:218] Iteration 52700 (3.30593 iter/s, 30.2487s/100 iters), loss = 0.0144563
I1017 21:03:31.691072 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0144549 (* 1 = 0.0144549 loss)
I1017 21:03:31.691099 22869 sgd_solver.cpp:105] Iteration 52700, lr = 0.001
I1017 21:04:01.924337 22869 solver.cpp:218] Iteration 52800 (3.30761 iter/s, 30.2333s/100 iters), loss = 0.0215891
I1017 21:04:01.924487 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0215877 (* 1 = 0.0215877 loss)
I1017 21:04:01.924515 22869 sgd_solver.cpp:105] Iteration 52800, lr = 0.001
I1017 21:04:32.191154 22869 solver.cpp:218] Iteration 52900 (3.30396 iter/s, 30.2667s/100 iters), loss = 0.0208215
I1017 21:04:32.191267 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0208201 (* 1 = 0.0208201 loss)
I1017 21:04:32.191277 22869 sgd_solver.cpp:105] Iteration 52900, lr = 0.001
I1017 21:05:00.935278 22877 data_layer.cpp:73] Restarting data prefetching from start.
I1017 21:05:02.145313 22869 solver.cpp:330] Iteration 53000, Testing net (#0)
I1017 21:05:18.592664 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 21:05:18.929702 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.24374 (* 1 = 1.24374 loss)
I1017 21:05:18.929720 22869 solver.cpp:397]     Test net output #1: accuracy = 0.7279
I1017 21:05:19.227735 22869 solver.cpp:218] Iteration 53000 (2.12601 iter/s, 47.0365s/100 iters), loss = 0.00455402
I1017 21:05:19.227771 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00455262 (* 1 = 0.00455262 loss)
I1017 21:05:19.227778 22869 sgd_solver.cpp:105] Iteration 53000, lr = 0.001
I1017 21:05:49.507508 22869 solver.cpp:218] Iteration 53100 (3.30254 iter/s, 30.2797s/100 iters), loss = 0.017752
I1017 21:05:49.507629 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0177506 (* 1 = 0.0177506 loss)
I1017 21:05:49.507647 22869 sgd_solver.cpp:105] Iteration 53100, lr = 0.001
I1017 21:06:19.762019 22869 solver.cpp:218] Iteration 53200 (3.30531 iter/s, 30.2544s/100 iters), loss = 0.00866061
I1017 21:06:19.762164 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00865922 (* 1 = 0.00865922 loss)
I1017 21:06:19.762173 22869 sgd_solver.cpp:105] Iteration 53200, lr = 0.001
I1017 21:06:50.092813 22869 solver.cpp:218] Iteration 53300 (3.297 iter/s, 30.3306s/100 iters), loss = 0.0111848
I1017 21:06:50.092958 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0111834 (* 1 = 0.0111834 loss)
I1017 21:06:50.092968 22869 sgd_solver.cpp:105] Iteration 53300, lr = 0.001
I1017 21:07:20.388092 22869 solver.cpp:218] Iteration 53400 (3.30086 iter/s, 30.2951s/100 iters), loss = 0.0207019
I1017 21:07:20.388202 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0207005 (* 1 = 0.0207005 loss)
I1017 21:07:20.388219 22869 sgd_solver.cpp:105] Iteration 53400, lr = 0.001
I1017 21:07:50.369681 22869 solver.cpp:330] Iteration 53500, Testing net (#0)
I1017 21:08:06.811252 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 21:08:07.148840 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.24013 (* 1 = 1.24013 loss)
I1017 21:08:07.148855 22869 solver.cpp:397]     Test net output #1: accuracy = 0.7261
I1017 21:08:07.449993 22869 solver.cpp:218] Iteration 53500 (2.12487 iter/s, 47.0618s/100 iters), loss = 0.0446819
I1017 21:08:07.450022 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0446805 (* 1 = 0.0446805 loss)
I1017 21:08:07.450029 22869 sgd_solver.cpp:105] Iteration 53500, lr = 0.001
I1017 21:08:37.685998 22869 solver.cpp:218] Iteration 53600 (3.30732 iter/s, 30.236s/100 iters), loss = 0.0128072
I1017 21:08:37.686128 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0128058 (* 1 = 0.0128058 loss)
I1017 21:08:37.686137 22869 sgd_solver.cpp:105] Iteration 53600, lr = 0.001
I1017 21:09:07.948913 22869 solver.cpp:218] Iteration 53700 (3.30439 iter/s, 30.2628s/100 iters), loss = 0.0141122
I1017 21:09:07.949985 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0141108 (* 1 = 0.0141108 loss)
I1017 21:09:07.949995 22869 sgd_solver.cpp:105] Iteration 53700, lr = 0.001
I1017 21:09:38.223250 22869 solver.cpp:218] Iteration 53800 (3.30324 iter/s, 30.2733s/100 iters), loss = 0.0347976
I1017 21:09:38.223352 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0347962 (* 1 = 0.0347962 loss)
I1017 21:09:38.223361 22869 sgd_solver.cpp:105] Iteration 53800, lr = 0.001
I1017 21:10:08.503154 22869 solver.cpp:218] Iteration 53900 (3.30253 iter/s, 30.2798s/100 iters), loss = 0.00469163
I1017 21:10:08.503293 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00469023 (* 1 = 0.00469023 loss)
I1017 21:10:08.503301 22869 sgd_solver.cpp:105] Iteration 53900, lr = 0.001
I1017 21:10:37.244063 22877 data_layer.cpp:73] Restarting data prefetching from start.
I1017 21:10:38.448513 22869 solver.cpp:330] Iteration 54000, Testing net (#0)
I1017 21:10:54.914175 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 21:10:55.250967 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.23542 (* 1 = 1.23542 loss)
I1017 21:10:55.250982 22869 solver.cpp:397]     Test net output #1: accuracy = 0.7285
I1017 21:10:55.550690 22869 solver.cpp:218] Iteration 54000 (2.12552 iter/s, 47.0474s/100 iters), loss = 0.00898615
I1017 21:10:55.550721 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00898475 (* 1 = 0.00898475 loss)
I1017 21:10:55.550729 22869 sgd_solver.cpp:105] Iteration 54000, lr = 0.001
I1017 21:11:25.843731 22869 solver.cpp:218] Iteration 54100 (3.30109 iter/s, 30.293s/100 iters), loss = 0.0234507
I1017 21:11:25.843833 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0234493 (* 1 = 0.0234493 loss)
I1017 21:11:25.843850 22869 sgd_solver.cpp:105] Iteration 54100, lr = 0.001
I1017 21:11:56.130242 22869 solver.cpp:218] Iteration 54200 (3.30181 iter/s, 30.2864s/100 iters), loss = 0.00751371
I1017 21:11:56.130357 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00751232 (* 1 = 0.00751232 loss)
I1017 21:11:56.130363 22869 sgd_solver.cpp:105] Iteration 54200, lr = 0.001
I1017 21:12:26.411893 22869 solver.cpp:218] Iteration 54300 (3.30234 iter/s, 30.2815s/100 iters), loss = 0.0203105
I1017 21:12:26.412029 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0203091 (* 1 = 0.0203091 loss)
I1017 21:12:26.412035 22869 sgd_solver.cpp:105] Iteration 54300, lr = 0.001
I1017 21:12:56.656383 22869 solver.cpp:218] Iteration 54400 (3.3064 iter/s, 30.2444s/100 iters), loss = 0.00716189
I1017 21:12:56.656466 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00716048 (* 1 = 0.00716048 loss)
I1017 21:12:56.656483 22869 sgd_solver.cpp:105] Iteration 54400, lr = 0.001
I1017 21:13:26.639199 22869 solver.cpp:330] Iteration 54500, Testing net (#0)
I1017 21:13:43.091022 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 21:13:43.430589 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.23364 (* 1 = 1.23364 loss)
I1017 21:13:43.430605 22869 solver.cpp:397]     Test net output #1: accuracy = 0.7282
I1017 21:13:43.729440 22869 solver.cpp:218] Iteration 54500 (2.12436 iter/s, 47.073s/100 iters), loss = 0.0381118
I1017 21:13:43.729476 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0381104 (* 1 = 0.0381104 loss)
I1017 21:13:43.729483 22869 sgd_solver.cpp:105] Iteration 54500, lr = 0.001
I1017 21:14:13.965404 22869 solver.cpp:218] Iteration 54600 (3.30732 iter/s, 30.2359s/100 iters), loss = 0.0072849
I1017 21:14:13.965548 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00728351 (* 1 = 0.00728351 loss)
I1017 21:14:13.965556 22869 sgd_solver.cpp:105] Iteration 54600, lr = 0.001
I1017 21:14:44.275491 22869 solver.cpp:218] Iteration 54700 (3.29925 iter/s, 30.3099s/100 iters), loss = 0.0128121
I1017 21:14:44.275638 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0128107 (* 1 = 0.0128107 loss)
I1017 21:14:44.275646 22869 sgd_solver.cpp:105] Iteration 54700, lr = 0.001
I1017 21:15:14.515938 22869 solver.cpp:218] Iteration 54800 (3.30685 iter/s, 30.2403s/100 iters), loss = 0.0270083
I1017 21:15:14.516048 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0270069 (* 1 = 0.0270069 loss)
I1017 21:15:14.516057 22869 sgd_solver.cpp:105] Iteration 54800, lr = 0.001
I1017 21:15:44.808900 22869 solver.cpp:218] Iteration 54900 (3.30111 iter/s, 30.2929s/100 iters), loss = 0.00431153
I1017 21:15:44.809012 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00431014 (* 1 = 0.00431014 loss)
I1017 21:15:44.809032 22869 sgd_solver.cpp:105] Iteration 54900, lr = 0.001
I1017 21:16:13.574925 22877 data_layer.cpp:73] Restarting data prefetching from start.
I1017 21:16:14.791236 22869 solver.cpp:330] Iteration 55000, Testing net (#0)
I1017 21:16:31.234920 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 21:16:31.570225 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.22888 (* 1 = 1.22888 loss)
I1017 21:16:31.570241 22869 solver.cpp:397]     Test net output #1: accuracy = 0.7295
I1017 21:16:31.869117 22869 solver.cpp:218] Iteration 55000 (2.12494 iter/s, 47.0601s/100 iters), loss = 0.0589558
I1017 21:16:31.869153 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0589544 (* 1 = 0.0589544 loss)
I1017 21:16:31.869159 22869 sgd_solver.cpp:105] Iteration 55000, lr = 0.001
I1017 21:17:02.191555 22869 solver.cpp:218] Iteration 55100 (3.29789 iter/s, 30.3224s/100 iters), loss = 0.02537
I1017 21:17:02.193676 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0253686 (* 1 = 0.0253686 loss)
I1017 21:17:02.193686 22869 sgd_solver.cpp:105] Iteration 55100, lr = 0.001
I1017 21:17:32.486958 22869 solver.cpp:218] Iteration 55200 (3.30106 iter/s, 30.2933s/100 iters), loss = 0.011813
I1017 21:17:32.487071 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0118116 (* 1 = 0.0118116 loss)
I1017 21:17:32.487078 22869 sgd_solver.cpp:105] Iteration 55200, lr = 0.001
I1017 21:18:02.734262 22869 solver.cpp:218] Iteration 55300 (3.30609 iter/s, 30.2472s/100 iters), loss = 0.0228746
I1017 21:18:02.734397 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0228732 (* 1 = 0.0228732 loss)
I1017 21:18:02.734407 22869 sgd_solver.cpp:105] Iteration 55300, lr = 0.001
I1017 21:18:33.012802 22869 solver.cpp:218] Iteration 55400 (3.30268 iter/s, 30.2784s/100 iters), loss = 0.00615834
I1017 21:18:33.012910 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00615696 (* 1 = 0.00615696 loss)
I1017 21:18:33.012918 22869 sgd_solver.cpp:105] Iteration 55400, lr = 0.001
I1017 21:19:03.055938 22869 solver.cpp:330] Iteration 55500, Testing net (#0)
I1017 21:19:19.510915 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 21:19:19.845654 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.22593 (* 1 = 1.22593 loss)
I1017 21:19:19.845669 22869 solver.cpp:397]     Test net output #1: accuracy = 0.7299
I1017 21:19:20.143009 22869 solver.cpp:218] Iteration 55500 (2.12179 iter/s, 47.1301s/100 iters), loss = 0.00755087
I1017 21:19:20.143043 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00754949 (* 1 = 0.00754949 loss)
I1017 21:19:20.143049 22869 sgd_solver.cpp:105] Iteration 55500, lr = 0.001
I1017 21:19:50.403239 22869 solver.cpp:218] Iteration 55600 (3.30467 iter/s, 30.2602s/100 iters), loss = 0.00842144
I1017 21:19:50.403381 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00842006 (* 1 = 0.00842006 loss)
I1017 21:19:50.403389 22869 sgd_solver.cpp:105] Iteration 55600, lr = 0.001
I1017 21:20:20.791193 22869 solver.cpp:218] Iteration 55700 (3.29079 iter/s, 30.3878s/100 iters), loss = 0.0112244
I1017 21:20:20.791307 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.011223 (* 1 = 0.011223 loss)
I1017 21:20:20.791323 22869 sgd_solver.cpp:105] Iteration 55700, lr = 0.001
I1017 21:20:51.578091 22869 solver.cpp:218] Iteration 55800 (3.24815 iter/s, 30.7868s/100 iters), loss = 0.0175284
I1017 21:20:51.578199 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0175271 (* 1 = 0.0175271 loss)
I1017 21:20:51.578207 22869 sgd_solver.cpp:105] Iteration 55800, lr = 0.001
I1017 21:21:21.972559 22869 solver.cpp:218] Iteration 55900 (3.29009 iter/s, 30.3944s/100 iters), loss = 0.0051319
I1017 21:21:21.972667 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00513053 (* 1 = 0.00513053 loss)
I1017 21:21:21.972676 22869 sgd_solver.cpp:105] Iteration 55900, lr = 0.001
I1017 21:21:50.781872 22877 data_layer.cpp:73] Restarting data prefetching from start.
I1017 21:21:51.990839 22869 solver.cpp:330] Iteration 56000, Testing net (#0)
I1017 21:22:08.376236 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 21:22:08.712127 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.22446 (* 1 = 1.22446 loss)
I1017 21:22:08.712141 22869 solver.cpp:397]     Test net output #1: accuracy = 0.7286
I1017 21:22:09.008738 22869 solver.cpp:218] Iteration 56000 (2.12603 iter/s, 47.0361s/100 iters), loss = 0.00545082
I1017 21:22:09.008772 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00544945 (* 1 = 0.00544945 loss)
I1017 21:22:09.008780 22869 sgd_solver.cpp:105] Iteration 56000, lr = 0.001
I1017 21:22:39.312162 22869 solver.cpp:218] Iteration 56100 (3.29996 iter/s, 30.3034s/100 iters), loss = 0.00847619
I1017 21:22:39.312299 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00847482 (* 1 = 0.00847482 loss)
I1017 21:22:39.312307 22869 sgd_solver.cpp:105] Iteration 56100, lr = 0.001
I1017 21:23:09.609017 22869 solver.cpp:218] Iteration 56200 (3.30069 iter/s, 30.2967s/100 iters), loss = 0.0265379
I1017 21:23:09.609156 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0265366 (* 1 = 0.0265366 loss)
I1017 21:23:09.609163 22869 sgd_solver.cpp:105] Iteration 56200, lr = 0.001
I1017 21:23:39.882938 22869 solver.cpp:218] Iteration 56300 (3.30319 iter/s, 30.2738s/100 iters), loss = 0.0280172
I1017 21:23:39.883076 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0280158 (* 1 = 0.0280158 loss)
I1017 21:23:39.883083 22869 sgd_solver.cpp:105] Iteration 56300, lr = 0.001
I1017 21:24:10.149859 22869 solver.cpp:218] Iteration 56400 (3.30395 iter/s, 30.2668s/100 iters), loss = 0.0687979
I1017 21:24:10.149952 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0687965 (* 1 = 0.0687965 loss)
I1017 21:24:10.149960 22869 sgd_solver.cpp:105] Iteration 56400, lr = 0.001
I1017 21:24:40.175515 22869 solver.cpp:330] Iteration 56500, Testing net (#0)
I1017 21:24:56.612715 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 21:24:56.948840 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.22302 (* 1 = 1.22302 loss)
I1017 21:24:56.948856 22869 solver.cpp:397]     Test net output #1: accuracy = 0.7313
I1017 21:24:57.246235 22869 solver.cpp:218] Iteration 56500 (2.12331 iter/s, 47.0963s/100 iters), loss = 0.00705465
I1017 21:24:57.246266 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00705329 (* 1 = 0.00705329 loss)
I1017 21:24:57.246273 22869 sgd_solver.cpp:105] Iteration 56500, lr = 0.001
I1017 21:25:27.558964 22869 solver.cpp:218] Iteration 56600 (3.29895 iter/s, 30.3127s/100 iters), loss = 0.00908863
I1017 21:25:27.559056 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00908726 (* 1 = 0.00908726 loss)
I1017 21:25:27.559063 22869 sgd_solver.cpp:105] Iteration 56600, lr = 0.001
I1017 21:25:57.872380 22869 solver.cpp:218] Iteration 56700 (3.29888 iter/s, 30.3133s/100 iters), loss = 0.0199292
I1017 21:25:57.872457 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0199278 (* 1 = 0.0199278 loss)
I1017 21:25:57.872473 22869 sgd_solver.cpp:105] Iteration 56700, lr = 0.001
I1017 21:26:28.117511 22869 solver.cpp:218] Iteration 56800 (3.30633 iter/s, 30.245s/100 iters), loss = 0.013039
I1017 21:26:28.117616 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0130376 (* 1 = 0.0130376 loss)
I1017 21:26:28.117633 22869 sgd_solver.cpp:105] Iteration 56800, lr = 0.001
I1017 21:26:58.416793 22869 solver.cpp:218] Iteration 56900 (3.30042 iter/s, 30.2992s/100 iters), loss = 0.00568545
I1017 21:26:58.416932 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00568407 (* 1 = 0.00568407 loss)
I1017 21:26:58.416939 22869 sgd_solver.cpp:105] Iteration 56900, lr = 0.001
I1017 21:27:27.186581 22877 data_layer.cpp:73] Restarting data prefetching from start.
I1017 21:27:28.398555 22869 solver.cpp:330] Iteration 57000, Testing net (#0)
I1017 21:27:44.871105 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 21:27:45.210161 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.22239 (* 1 = 1.22239 loss)
I1017 21:27:45.210176 22869 solver.cpp:397]     Test net output #1: accuracy = 0.731
I1017 21:27:45.508886 22869 solver.cpp:218] Iteration 57000 (2.1235 iter/s, 47.092s/100 iters), loss = 0.00499742
I1017 21:27:45.508931 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00499605 (* 1 = 0.00499605 loss)
I1017 21:27:45.508939 22869 sgd_solver.cpp:105] Iteration 57000, lr = 0.001
I1017 21:28:15.747678 22869 solver.cpp:218] Iteration 57100 (3.30702 iter/s, 30.2387s/100 iters), loss = 0.00920262
I1017 21:28:15.747787 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00920124 (* 1 = 0.00920124 loss)
I1017 21:28:15.747805 22869 sgd_solver.cpp:105] Iteration 57100, lr = 0.001
I1017 21:28:45.979478 22869 solver.cpp:218] Iteration 57200 (3.30779 iter/s, 30.2317s/100 iters), loss = 0.0395768
I1017 21:28:45.979732 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0395754 (* 1 = 0.0395754 loss)
I1017 21:28:45.979750 22869 sgd_solver.cpp:105] Iteration 57200, lr = 0.001
I1017 21:29:16.251186 22869 solver.cpp:218] Iteration 57300 (3.30344 iter/s, 30.2715s/100 iters), loss = 0.00679528
I1017 21:29:16.251296 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0067939 (* 1 = 0.0067939 loss)
I1017 21:29:16.251303 22869 sgd_solver.cpp:105] Iteration 57300, lr = 0.001
I1017 21:29:46.459254 22869 solver.cpp:218] Iteration 57400 (3.31039 iter/s, 30.208s/100 iters), loss = 0.0105457
I1017 21:29:46.459401 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0105443 (* 1 = 0.0105443 loss)
I1017 21:29:46.459409 22869 sgd_solver.cpp:105] Iteration 57400, lr = 0.001
I1017 21:30:16.417240 22869 solver.cpp:330] Iteration 57500, Testing net (#0)
I1017 21:30:32.888669 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 21:30:33.226882 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.22046 (* 1 = 1.22046 loss)
I1017 21:30:33.226898 22869 solver.cpp:397]     Test net output #1: accuracy = 0.7329
I1017 21:30:33.528082 22869 solver.cpp:218] Iteration 57500 (2.12456 iter/s, 47.0687s/100 iters), loss = 0.0173075
I1017 21:30:33.528112 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0173061 (* 1 = 0.0173061 loss)
I1017 21:30:33.528120 22869 sgd_solver.cpp:105] Iteration 57500, lr = 0.001
I1017 21:31:03.802965 22869 solver.cpp:218] Iteration 57600 (3.30307 iter/s, 30.2748s/100 iters), loss = 0.00366839
I1017 21:31:03.803680 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00366701 (* 1 = 0.00366701 loss)
I1017 21:31:03.803689 22869 sgd_solver.cpp:105] Iteration 57600, lr = 0.001
I1017 21:31:34.068074 22869 solver.cpp:218] Iteration 57700 (3.30421 iter/s, 30.2644s/100 iters), loss = 0.00564092
I1017 21:31:34.068190 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00563956 (* 1 = 0.00563956 loss)
I1017 21:31:34.068198 22869 sgd_solver.cpp:105] Iteration 57700, lr = 0.001
I1017 21:32:04.354142 22869 solver.cpp:218] Iteration 57800 (3.30186 iter/s, 30.2859s/100 iters), loss = 0.0135799
I1017 21:32:04.354288 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0135786 (* 1 = 0.0135786 loss)
I1017 21:32:04.354298 22869 sgd_solver.cpp:105] Iteration 57800, lr = 0.001
I1017 21:32:34.623720 22869 solver.cpp:218] Iteration 57900 (3.30366 iter/s, 30.2694s/100 iters), loss = 0.00521551
I1017 21:32:34.623793 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00521415 (* 1 = 0.00521415 loss)
I1017 21:32:34.623808 22869 sgd_solver.cpp:105] Iteration 57900, lr = 0.001
I1017 21:33:03.381928 22877 data_layer.cpp:73] Restarting data prefetching from start.
I1017 21:33:04.586720 22869 solver.cpp:330] Iteration 58000, Testing net (#0)
I1017 21:33:21.067901 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 21:33:21.405767 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.21618 (* 1 = 1.21618 loss)
I1017 21:33:21.405782 22869 solver.cpp:397]     Test net output #1: accuracy = 0.7318
I1017 21:33:21.706928 22869 solver.cpp:218] Iteration 58000 (2.1239 iter/s, 47.0831s/100 iters), loss = 0.00399901
I1017 21:33:21.706961 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00399764 (* 1 = 0.00399764 loss)
I1017 21:33:21.706969 22869 sgd_solver.cpp:105] Iteration 58000, lr = 0.001
I1017 21:33:51.984235 22869 solver.cpp:218] Iteration 58100 (3.30281 iter/s, 30.2772s/100 iters), loss = 0.0170983
I1017 21:33:51.984382 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.017097 (* 1 = 0.017097 loss)
I1017 21:33:51.984392 22869 sgd_solver.cpp:105] Iteration 58100, lr = 0.001
I1017 21:34:22.304260 22869 solver.cpp:218] Iteration 58200 (3.29817 iter/s, 30.3199s/100 iters), loss = 0.00636835
I1017 21:34:22.304430 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00636699 (* 1 = 0.00636699 loss)
I1017 21:34:22.304448 22869 sgd_solver.cpp:105] Iteration 58200, lr = 0.001
I1017 21:34:52.592304 22869 solver.cpp:218] Iteration 58300 (3.30165 iter/s, 30.2879s/100 iters), loss = 0.0208873
I1017 21:34:52.592414 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0208859 (* 1 = 0.0208859 loss)
I1017 21:34:52.592422 22869 sgd_solver.cpp:105] Iteration 58300, lr = 0.001
I1017 21:35:22.887044 22869 solver.cpp:218] Iteration 58400 (3.30091 iter/s, 30.2946s/100 iters), loss = 0.00365736
I1017 21:35:22.887169 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.003656 (* 1 = 0.003656 loss)
I1017 21:35:22.887177 22869 sgd_solver.cpp:105] Iteration 58400, lr = 0.001
I1017 21:35:52.830344 22869 solver.cpp:330] Iteration 58500, Testing net (#0)
I1017 21:36:09.267367 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 21:36:09.604807 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.21574 (* 1 = 1.21574 loss)
I1017 21:36:09.604821 22869 solver.cpp:397]     Test net output #1: accuracy = 0.7327
I1017 21:36:09.903334 22869 solver.cpp:218] Iteration 58500 (2.12693 iter/s, 47.0162s/100 iters), loss = 0.00663268
I1017 21:36:09.903365 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00663132 (* 1 = 0.00663132 loss)
I1017 21:36:09.903373 22869 sgd_solver.cpp:105] Iteration 58500, lr = 0.001
I1017 21:36:40.141111 22869 solver.cpp:218] Iteration 58600 (3.30713 iter/s, 30.2377s/100 iters), loss = 0.00278901
I1017 21:36:40.141254 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00278765 (* 1 = 0.00278765 loss)
I1017 21:36:40.141263 22869 sgd_solver.cpp:105] Iteration 58600, lr = 0.001
I1017 21:37:10.414209 22869 solver.cpp:218] Iteration 58700 (3.30328 iter/s, 30.273s/100 iters), loss = 0.0106004
I1017 21:37:10.414347 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.010599 (* 1 = 0.010599 loss)
I1017 21:37:10.414356 22869 sgd_solver.cpp:105] Iteration 58700, lr = 0.001
I1017 21:37:40.684485 22869 solver.cpp:218] Iteration 58800 (3.30359 iter/s, 30.2701s/100 iters), loss = 0.00926283
I1017 21:37:40.684634 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00926147 (* 1 = 0.00926147 loss)
I1017 21:37:40.684644 22869 sgd_solver.cpp:105] Iteration 58800, lr = 0.001
I1017 21:38:10.955113 22869 solver.cpp:218] Iteration 58900 (3.30355 iter/s, 30.2705s/100 iters), loss = 0.00403638
I1017 21:38:10.955246 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00403502 (* 1 = 0.00403502 loss)
I1017 21:38:10.955255 22869 sgd_solver.cpp:105] Iteration 58900, lr = 0.001
I1017 21:38:39.726428 22877 data_layer.cpp:73] Restarting data prefetching from start.
I1017 21:38:40.937510 22869 solver.cpp:330] Iteration 59000, Testing net (#0)
I1017 21:38:57.417815 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 21:38:57.755944 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.21555 (* 1 = 1.21555 loss)
I1017 21:38:57.755959 22869 solver.cpp:397]     Test net output #1: accuracy = 0.7322
I1017 21:38:58.053751 22869 solver.cpp:218] Iteration 59000 (2.12321 iter/s, 47.0985s/100 iters), loss = 0.0037398
I1017 21:38:58.053786 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00373844 (* 1 = 0.00373844 loss)
I1017 21:38:58.053793 22869 sgd_solver.cpp:105] Iteration 59000, lr = 0.001
I1017 21:39:28.265133 22869 solver.cpp:218] Iteration 59100 (3.31002 iter/s, 30.2113s/100 iters), loss = 0.0185695
I1017 21:39:28.265275 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0185682 (* 1 = 0.0185682 loss)
I1017 21:39:28.265285 22869 sgd_solver.cpp:105] Iteration 59100, lr = 0.001
I1017 21:39:58.532323 22869 solver.cpp:218] Iteration 59200 (3.30392 iter/s, 30.267s/100 iters), loss = 0.00860215
I1017 21:39:58.532459 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0086008 (* 1 = 0.0086008 loss)
I1017 21:39:58.532466 22869 sgd_solver.cpp:105] Iteration 59200, lr = 0.001
I1017 21:40:28.769069 22869 solver.cpp:218] Iteration 59300 (3.30725 iter/s, 30.2366s/100 iters), loss = 0.00739125
I1017 21:40:28.769162 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0073899 (* 1 = 0.0073899 loss)
I1017 21:40:28.769170 22869 sgd_solver.cpp:105] Iteration 59300, lr = 0.001
I1017 21:40:59.004758 22869 solver.cpp:218] Iteration 59400 (3.30736 iter/s, 30.2356s/100 iters), loss = 0.0112839
I1017 21:40:59.004881 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0112826 (* 1 = 0.0112826 loss)
I1017 21:40:59.004889 22869 sgd_solver.cpp:105] Iteration 59400, lr = 0.001
I1017 21:41:28.916743 22869 solver.cpp:330] Iteration 59500, Testing net (#0)
I1017 21:41:45.370980 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 21:41:45.708117 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.21068 (* 1 = 1.21068 loss)
I1017 21:41:45.708132 22869 solver.cpp:397]     Test net output #1: accuracy = 0.7324
I1017 21:41:46.004461 22869 solver.cpp:218] Iteration 59500 (2.12768 iter/s, 46.9996s/100 iters), loss = 0.0105337
I1017 21:41:46.004496 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0105323 (* 1 = 0.0105323 loss)
I1017 21:41:46.004503 22869 sgd_solver.cpp:105] Iteration 59500, lr = 0.001
I1017 21:42:16.225317 22869 solver.cpp:218] Iteration 59600 (3.30898 iter/s, 30.2208s/100 iters), loss = 0.00454666
I1017 21:42:16.225437 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00454532 (* 1 = 0.00454532 loss)
I1017 21:42:16.225445 22869 sgd_solver.cpp:105] Iteration 59600, lr = 0.001
I1017 21:42:46.458330 22869 solver.cpp:218] Iteration 59700 (3.30766 iter/s, 30.2329s/100 iters), loss = 0.00456374
I1017 21:42:46.458467 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0045624 (* 1 = 0.0045624 loss)
I1017 21:42:46.458474 22869 sgd_solver.cpp:105] Iteration 59700, lr = 0.001
I1017 21:43:16.673269 22869 solver.cpp:218] Iteration 59800 (3.30964 iter/s, 30.2148s/100 iters), loss = 0.00899981
I1017 21:43:16.673387 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00899848 (* 1 = 0.00899848 loss)
I1017 21:43:16.673394 22869 sgd_solver.cpp:105] Iteration 59800, lr = 0.001
I1017 21:43:46.934542 22869 solver.cpp:218] Iteration 59900 (3.30457 iter/s, 30.2611s/100 iters), loss = 0.00167898
I1017 21:43:46.934635 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00167765 (* 1 = 0.00167765 loss)
I1017 21:43:46.934643 22869 sgd_solver.cpp:105] Iteration 59900, lr = 0.001
I1017 21:44:15.648349 22877 data_layer.cpp:73] Restarting data prefetching from start.
I1017 21:44:16.866890 22869 solver.cpp:330] Iteration 60000, Testing net (#0)
I1017 21:44:33.340991 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 21:44:33.678009 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.20862 (* 1 = 1.20862 loss)
I1017 21:44:33.678023 22869 solver.cpp:397]     Test net output #1: accuracy = 0.7337
I1017 21:44:33.974512 22869 solver.cpp:218] Iteration 60000 (2.12586 iter/s, 47.0399s/100 iters), loss = 0.00424281
I1017 21:44:33.974548 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00424148 (* 1 = 0.00424148 loss)
I1017 21:44:33.974555 22869 sgd_solver.cpp:105] Iteration 60000, lr = 0.001
I1017 21:45:04.233218 22869 solver.cpp:218] Iteration 60100 (3.30484 iter/s, 30.2587s/100 iters), loss = 0.0109779
I1017 21:45:04.233350 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0109766 (* 1 = 0.0109766 loss)
I1017 21:45:04.233358 22869 sgd_solver.cpp:105] Iteration 60100, lr = 0.001
I1017 21:45:34.475788 22869 solver.cpp:218] Iteration 60200 (3.30661 iter/s, 30.2424s/100 iters), loss = 0.00984925
I1017 21:45:34.475924 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00984793 (* 1 = 0.00984793 loss)
I1017 21:45:34.475934 22869 sgd_solver.cpp:105] Iteration 60200, lr = 0.001
I1017 21:46:04.776188 22869 solver.cpp:218] Iteration 60300 (3.3003 iter/s, 30.3003s/100 iters), loss = 0.0126627
I1017 21:46:04.776355 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0126614 (* 1 = 0.0126614 loss)
I1017 21:46:04.776373 22869 sgd_solver.cpp:105] Iteration 60300, lr = 0.001
I1017 21:46:35.051754 22869 solver.cpp:218] Iteration 60400 (3.30301 iter/s, 30.2754s/100 iters), loss = 0.0079428
I1017 21:46:35.051873 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00794149 (* 1 = 0.00794149 loss)
I1017 21:46:35.051892 22869 sgd_solver.cpp:105] Iteration 60400, lr = 0.001
I1017 21:47:05.029610 22869 solver.cpp:330] Iteration 60500, Testing net (#0)
I1017 21:47:21.482841 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 21:47:21.818884 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.20636 (* 1 = 1.20636 loss)
I1017 21:47:21.818898 22869 solver.cpp:397]     Test net output #1: accuracy = 0.7346
I1017 21:47:22.116782 22869 solver.cpp:218] Iteration 60500 (2.12473 iter/s, 47.0649s/100 iters), loss = 0.0161677
I1017 21:47:22.116817 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0161663 (* 1 = 0.0161663 loss)
I1017 21:47:22.116825 22869 sgd_solver.cpp:105] Iteration 60500, lr = 0.001
I1017 21:47:52.347558 22869 solver.cpp:218] Iteration 60600 (3.30789 iter/s, 30.2307s/100 iters), loss = 0.00298707
I1017 21:47:52.347683 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00298575 (* 1 = 0.00298575 loss)
I1017 21:47:52.347690 22869 sgd_solver.cpp:105] Iteration 60600, lr = 0.001
I1017 21:48:22.651475 22869 solver.cpp:218] Iteration 60700 (3.29992 iter/s, 30.3038s/100 iters), loss = 0.0057605
I1017 21:48:22.651618 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00575918 (* 1 = 0.00575918 loss)
I1017 21:48:22.651624 22869 sgd_solver.cpp:105] Iteration 60700, lr = 0.001
I1017 21:48:52.916115 22869 solver.cpp:218] Iteration 60800 (3.3042 iter/s, 30.2645s/100 iters), loss = 0.00812796
I1017 21:48:52.916242 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00812664 (* 1 = 0.00812664 loss)
I1017 21:48:52.916260 22869 sgd_solver.cpp:105] Iteration 60800, lr = 0.001
I1017 21:49:23.208652 22869 solver.cpp:218] Iteration 60900 (3.30116 iter/s, 30.2924s/100 iters), loss = 0.0016094
I1017 21:49:23.208783 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00160808 (* 1 = 0.00160808 loss)
I1017 21:49:23.208792 22869 sgd_solver.cpp:105] Iteration 60900, lr = 0.001
I1017 21:49:51.993947 22877 data_layer.cpp:73] Restarting data prefetching from start.
I1017 21:49:53.208145 22869 solver.cpp:330] Iteration 61000, Testing net (#0)
I1017 21:50:09.633895 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 21:50:09.970296 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.20216 (* 1 = 1.20216 loss)
I1017 21:50:09.970312 22869 solver.cpp:397]     Test net output #1: accuracy = 0.735
I1017 21:50:10.268507 22869 solver.cpp:218] Iteration 61000 (2.12496 iter/s, 47.0597s/100 iters), loss = 0.00314739
I1017 21:50:10.268539 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00314608 (* 1 = 0.00314608 loss)
I1017 21:50:10.268546 22869 sgd_solver.cpp:105] Iteration 61000, lr = 0.001
I1017 21:50:40.542014 22869 solver.cpp:218] Iteration 61100 (3.30322 iter/s, 30.2735s/100 iters), loss = 0.00465558
I1017 21:50:40.542135 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00465427 (* 1 = 0.00465427 loss)
I1017 21:50:40.542141 22869 sgd_solver.cpp:105] Iteration 61100, lr = 0.001
I1017 21:51:10.774325 22869 solver.cpp:218] Iteration 61200 (3.30773 iter/s, 30.2322s/100 iters), loss = 0.00189725
I1017 21:51:10.774478 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00189593 (* 1 = 0.00189593 loss)
I1017 21:51:10.774487 22869 sgd_solver.cpp:105] Iteration 61200, lr = 0.001
I1017 21:51:41.028980 22869 solver.cpp:218] Iteration 61300 (3.30529 iter/s, 30.2545s/100 iters), loss = 0.0308413
I1017 21:51:41.029114 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.03084 (* 1 = 0.03084 loss)
I1017 21:51:41.029122 22869 sgd_solver.cpp:105] Iteration 61300, lr = 0.001
I1017 21:52:11.289999 22869 solver.cpp:218] Iteration 61400 (3.3046 iter/s, 30.2609s/100 iters), loss = 0.00398531
I1017 21:52:11.290165 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00398399 (* 1 = 0.00398399 loss)
I1017 21:52:11.290174 22869 sgd_solver.cpp:105] Iteration 61400, lr = 0.001
I1017 21:52:41.274456 22869 solver.cpp:330] Iteration 61500, Testing net (#0)
I1017 21:52:57.770912 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 21:52:58.106355 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.19863 (* 1 = 1.19863 loss)
I1017 21:52:58.106371 22869 solver.cpp:397]     Test net output #1: accuracy = 0.7348
I1017 21:52:58.403651 22869 solver.cpp:218] Iteration 61500 (2.12253 iter/s, 47.1135s/100 iters), loss = 0.00452306
I1017 21:52:58.403683 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00452174 (* 1 = 0.00452174 loss)
I1017 21:52:58.403690 22869 sgd_solver.cpp:105] Iteration 61500, lr = 0.001
I1017 21:53:28.656957 22869 solver.cpp:218] Iteration 61600 (3.30543 iter/s, 30.2533s/100 iters), loss = 0.00351568
I1017 21:53:28.657099 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00351436 (* 1 = 0.00351436 loss)
I1017 21:53:28.657107 22869 sgd_solver.cpp:105] Iteration 61600, lr = 0.001
I1017 21:53:58.923787 22869 solver.cpp:218] Iteration 61700 (3.30396 iter/s, 30.2667s/100 iters), loss = 0.00347406
I1017 21:53:58.923929 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00347274 (* 1 = 0.00347274 loss)
I1017 21:53:58.923938 22869 sgd_solver.cpp:105] Iteration 61700, lr = 0.001
I1017 21:54:29.197649 22869 solver.cpp:218] Iteration 61800 (3.3032 iter/s, 30.2737s/100 iters), loss = 0.00351794
I1017 21:54:29.197782 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00351662 (* 1 = 0.00351662 loss)
I1017 21:54:29.197789 22869 sgd_solver.cpp:105] Iteration 61800, lr = 0.001
I1017 21:54:59.423306 22869 solver.cpp:218] Iteration 61900 (3.30846 iter/s, 30.2255s/100 iters), loss = 0.00516835
I1017 21:54:59.423419 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00516703 (* 1 = 0.00516703 loss)
I1017 21:54:59.423436 22869 sgd_solver.cpp:105] Iteration 61900, lr = 0.001
I1017 21:55:28.197484 22877 data_layer.cpp:73] Restarting data prefetching from start.
I1017 21:55:29.427536 22869 solver.cpp:330] Iteration 62000, Testing net (#0)
I1017 21:55:45.852901 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 21:55:46.187319 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.19776 (* 1 = 1.19776 loss)
I1017 21:55:46.187335 22869 solver.cpp:397]     Test net output #1: accuracy = 0.7338
I1017 21:55:46.485031 22869 solver.cpp:218] Iteration 62000 (2.12487 iter/s, 47.0616s/100 iters), loss = 0.0134132
I1017 21:55:46.485062 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0134119 (* 1 = 0.0134119 loss)
I1017 21:55:46.485069 22869 sgd_solver.cpp:105] Iteration 62000, lr = 0.001
I1017 21:56:16.701396 22869 solver.cpp:218] Iteration 62100 (3.30947 iter/s, 30.2163s/100 iters), loss = 0.0100721
I1017 21:56:16.701515 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0100708 (* 1 = 0.0100708 loss)
I1017 21:56:16.701524 22869 sgd_solver.cpp:105] Iteration 62100, lr = 0.001
I1017 21:56:46.922619 22869 solver.cpp:218] Iteration 62200 (3.30895 iter/s, 30.2211s/100 iters), loss = 0.00527529
I1017 21:56:46.922760 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00527397 (* 1 = 0.00527397 loss)
I1017 21:56:46.922768 22869 sgd_solver.cpp:105] Iteration 62200, lr = 0.001
I1017 21:57:17.134250 22869 solver.cpp:218] Iteration 62300 (3.31 iter/s, 30.2115s/100 iters), loss = 0.00647786
I1017 21:57:17.134398 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00647655 (* 1 = 0.00647655 loss)
I1017 21:57:17.134407 22869 sgd_solver.cpp:105] Iteration 62300, lr = 0.001
I1017 21:57:47.322736 22869 solver.cpp:218] Iteration 62400 (3.31254 iter/s, 30.1883s/100 iters), loss = 0.00543105
I1017 21:57:47.322857 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00542974 (* 1 = 0.00542974 loss)
I1017 21:57:47.322865 22869 sgd_solver.cpp:105] Iteration 62400, lr = 0.001
I1017 21:58:17.247794 22869 solver.cpp:330] Iteration 62500, Testing net (#0)
I1017 21:58:33.722723 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 21:58:34.059068 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.19691 (* 1 = 1.19691 loss)
I1017 21:58:34.059083 22869 solver.cpp:397]     Test net output #1: accuracy = 0.7344
I1017 21:58:34.356232 22869 solver.cpp:218] Iteration 62500 (2.12615 iter/s, 47.0334s/100 iters), loss = 0.00981469
I1017 21:58:34.356273 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00981338 (* 1 = 0.00981338 loss)
I1017 21:58:34.356281 22869 sgd_solver.cpp:105] Iteration 62500, lr = 0.001
I1017 21:59:04.572890 22869 solver.cpp:218] Iteration 62600 (3.30944 iter/s, 30.2166s/100 iters), loss = 0.00529807
I1017 21:59:04.573019 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00529676 (* 1 = 0.00529676 loss)
I1017 21:59:04.573027 22869 sgd_solver.cpp:105] Iteration 62600, lr = 0.001
I1017 21:59:34.778530 22869 solver.cpp:218] Iteration 62700 (3.31065 iter/s, 30.2055s/100 iters), loss = 0.00324013
I1017 21:59:34.778628 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00323881 (* 1 = 0.00323881 loss)
I1017 21:59:34.778635 22869 sgd_solver.cpp:105] Iteration 62700, lr = 0.001
I1017 22:00:04.971807 22869 solver.cpp:218] Iteration 62800 (3.31201 iter/s, 30.1932s/100 iters), loss = 0.00354678
I1017 22:00:04.971902 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00354547 (* 1 = 0.00354547 loss)
I1017 22:00:04.971920 22869 sgd_solver.cpp:105] Iteration 62800, lr = 0.001
I1017 22:00:35.183302 22869 solver.cpp:218] Iteration 62900 (3.31001 iter/s, 30.2114s/100 iters), loss = 0.00268862
I1017 22:00:35.183403 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00268731 (* 1 = 0.00268731 loss)
I1017 22:00:35.183420 22869 sgd_solver.cpp:105] Iteration 62900, lr = 0.001
I1017 22:01:03.849581 22877 data_layer.cpp:73] Restarting data prefetching from start.
I1017 22:01:05.054852 22869 solver.cpp:330] Iteration 63000, Testing net (#0)
I1017 22:01:21.516034 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 22:01:21.850769 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.19512 (* 1 = 1.19512 loss)
I1017 22:01:21.850785 22869 solver.cpp:397]     Test net output #1: accuracy = 0.736
I1017 22:01:22.147146 22869 solver.cpp:218] Iteration 63000 (2.1293 iter/s, 46.9637s/100 iters), loss = 0.00323191
I1017 22:01:22.147186 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0032306 (* 1 = 0.0032306 loss)
I1017 22:01:22.147193 22869 sgd_solver.cpp:105] Iteration 63000, lr = 0.001
I1017 22:01:52.363915 22869 solver.cpp:218] Iteration 63100 (3.30943 iter/s, 30.2167s/100 iters), loss = 0.00935432
I1017 22:01:52.364037 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.009353 (* 1 = 0.009353 loss)
I1017 22:01:52.364045 22869 sgd_solver.cpp:105] Iteration 63100, lr = 0.001
I1017 22:02:22.551622 22869 solver.cpp:218] Iteration 63200 (3.31262 iter/s, 30.1876s/100 iters), loss = 0.00437926
I1017 22:02:22.551767 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00437794 (* 1 = 0.00437794 loss)
I1017 22:02:22.551776 22869 sgd_solver.cpp:105] Iteration 63200, lr = 0.001
I1017 22:02:52.780834 22869 solver.cpp:218] Iteration 63300 (3.30807 iter/s, 30.2291s/100 iters), loss = 0.00498573
I1017 22:02:52.780975 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00498441 (* 1 = 0.00498441 loss)
I1017 22:02:52.780984 22869 sgd_solver.cpp:105] Iteration 63300, lr = 0.001
I1017 22:03:22.962311 22869 solver.cpp:218] Iteration 63400 (3.31331 iter/s, 30.1813s/100 iters), loss = 0.00483082
I1017 22:03:22.962416 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00482949 (* 1 = 0.00482949 loss)
I1017 22:03:22.962432 22869 sgd_solver.cpp:105] Iteration 63400, lr = 0.001
I1017 22:03:52.872237 22869 solver.cpp:330] Iteration 63500, Testing net (#0)
I1017 22:04:09.325539 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 22:04:09.662349 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.19409 (* 1 = 1.19409 loss)
I1017 22:04:09.662370 22869 solver.cpp:397]     Test net output #1: accuracy = 0.7366
I1017 22:04:09.959547 22869 solver.cpp:218] Iteration 63500 (2.12779 iter/s, 46.9971s/100 iters), loss = 0.00858353
I1017 22:04:09.959581 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00858221 (* 1 = 0.00858221 loss)
I1017 22:04:09.959589 22869 sgd_solver.cpp:105] Iteration 63500, lr = 0.001
I1017 22:04:40.115087 22869 solver.cpp:218] Iteration 63600 (3.31614 iter/s, 30.1555s/100 iters), loss = 0.0040405
I1017 22:04:40.115227 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00403918 (* 1 = 0.00403918 loss)
I1017 22:04:40.115236 22869 sgd_solver.cpp:105] Iteration 63600, lr = 0.001
I1017 22:05:10.312525 22869 solver.cpp:218] Iteration 63700 (3.31156 iter/s, 30.1973s/100 iters), loss = 0.00443
I1017 22:05:10.312620 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00442868 (* 1 = 0.00442868 loss)
I1017 22:05:10.312628 22869 sgd_solver.cpp:105] Iteration 63700, lr = 0.001
I1017 22:05:40.501785 22869 solver.cpp:218] Iteration 63800 (3.31245 iter/s, 30.1892s/100 iters), loss = 0.00660019
I1017 22:05:40.501863 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00659886 (* 1 = 0.00659886 loss)
I1017 22:05:40.501879 22869 sgd_solver.cpp:105] Iteration 63800, lr = 0.001
I1017 22:06:10.682767 22869 solver.cpp:218] Iteration 63900 (3.31335 iter/s, 30.1809s/100 iters), loss = 0.00485466
I1017 22:06:10.682875 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00485333 (* 1 = 0.00485333 loss)
I1017 22:06:10.682883 22869 sgd_solver.cpp:105] Iteration 63900, lr = 0.001
I1017 22:06:39.386356 22877 data_layer.cpp:73] Restarting data prefetching from start.
I1017 22:06:40.590523 22869 solver.cpp:330] Iteration 64000, Testing net (#0)
I1017 22:06:56.996379 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 22:06:57.330343 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.19149 (* 1 = 1.19149 loss)
I1017 22:06:57.330363 22869 solver.cpp:397]     Test net output #1: accuracy = 0.7361
I1017 22:06:57.625960 22869 solver.cpp:218] Iteration 64000 (2.13024 iter/s, 46.9431s/100 iters), loss = 0.0238558
I1017 22:06:57.625991 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0238545 (* 1 = 0.0238545 loss)
I1017 22:06:57.625998 22869 sgd_solver.cpp:105] Iteration 64000, lr = 0.001
I1017 22:07:27.837692 22869 solver.cpp:218] Iteration 64100 (3.30998 iter/s, 30.2117s/100 iters), loss = 0.0114709
I1017 22:07:27.837832 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0114696 (* 1 = 0.0114696 loss)
I1017 22:07:27.837841 22869 sgd_solver.cpp:105] Iteration 64100, lr = 0.001
I1017 22:07:58.016582 22869 solver.cpp:218] Iteration 64200 (3.31359 iter/s, 30.1787s/100 iters), loss = 0.0031653
I1017 22:07:58.016682 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00316398 (* 1 = 0.00316398 loss)
I1017 22:07:58.016690 22869 sgd_solver.cpp:105] Iteration 64200, lr = 0.001
I1017 22:08:28.252089 22869 solver.cpp:218] Iteration 64300 (3.30738 iter/s, 30.2354s/100 iters), loss = 0.00981433
I1017 22:08:28.252233 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00981301 (* 1 = 0.00981301 loss)
I1017 22:08:28.252243 22869 sgd_solver.cpp:105] Iteration 64300, lr = 0.001
I1017 22:08:58.449101 22869 solver.cpp:218] Iteration 64400 (3.3116 iter/s, 30.1969s/100 iters), loss = 0.00591315
I1017 22:08:58.449245 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00591183 (* 1 = 0.00591183 loss)
I1017 22:08:58.449254 22869 sgd_solver.cpp:105] Iteration 64400, lr = 0.001
I1017 22:09:28.360476 22869 solver.cpp:330] Iteration 64500, Testing net (#0)
I1017 22:09:44.795076 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 22:09:45.130512 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.18801 (* 1 = 1.18801 loss)
I1017 22:09:45.130528 22869 solver.cpp:397]     Test net output #1: accuracy = 0.736
I1017 22:09:45.427541 22869 solver.cpp:218] Iteration 64500 (2.12864 iter/s, 46.9783s/100 iters), loss = 0.00402176
I1017 22:09:45.427570 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00402044 (* 1 = 0.00402044 loss)
I1017 22:09:45.427577 22869 sgd_solver.cpp:105] Iteration 64500, lr = 0.001
I1017 22:10:15.590134 22869 solver.cpp:218] Iteration 64600 (3.31537 iter/s, 30.1626s/100 iters), loss = 0.00241227
I1017 22:10:15.590276 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00241095 (* 1 = 0.00241095 loss)
I1017 22:10:15.590283 22869 sgd_solver.cpp:105] Iteration 64600, lr = 0.001
I1017 22:10:45.768463 22869 solver.cpp:218] Iteration 64700 (3.31365 iter/s, 30.1782s/100 iters), loss = 0.00950288
I1017 22:10:45.768571 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00950157 (* 1 = 0.00950157 loss)
I1017 22:10:45.768591 22869 sgd_solver.cpp:105] Iteration 64700, lr = 0.001
I1017 22:11:15.926759 22869 solver.cpp:218] Iteration 64800 (3.31585 iter/s, 30.1582s/100 iters), loss = 0.0024911
I1017 22:11:15.926905 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00248978 (* 1 = 0.00248978 loss)
I1017 22:11:15.926915 22869 sgd_solver.cpp:105] Iteration 64800, lr = 0.001
I1017 22:11:46.088529 22869 solver.cpp:218] Iteration 64900 (3.31547 iter/s, 30.1616s/100 iters), loss = 0.00226629
I1017 22:11:46.088675 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00226498 (* 1 = 0.00226498 loss)
I1017 22:11:46.088683 22869 sgd_solver.cpp:105] Iteration 64900, lr = 0.001
I1017 22:12:14.771333 22877 data_layer.cpp:73] Restarting data prefetching from start.
I1017 22:12:15.987767 22869 solver.cpp:330] Iteration 65000, Testing net (#0)
I1017 22:12:32.398345 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 22:12:32.738153 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.1856 (* 1 = 1.1856 loss)
I1017 22:12:32.738168 22869 solver.cpp:397]     Test net output #1: accuracy = 0.7366
I1017 22:12:33.038774 22869 solver.cpp:218] Iteration 65000 (2.12992 iter/s, 46.9501s/100 iters), loss = 0.00657595
I1017 22:12:33.038807 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00657464 (* 1 = 0.00657464 loss)
I1017 22:12:33.038815 22869 sgd_solver.cpp:105] Iteration 65000, lr = 0.001
I1017 22:13:03.252265 22869 solver.cpp:218] Iteration 65100 (3.30978 iter/s, 30.2134s/100 iters), loss = 0.010717
I1017 22:13:03.252413 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0107157 (* 1 = 0.0107157 loss)
I1017 22:13:03.252423 22869 sgd_solver.cpp:105] Iteration 65100, lr = 0.001
I1017 22:13:33.442848 22869 solver.cpp:218] Iteration 65200 (3.31231 iter/s, 30.1904s/100 iters), loss = 0.0073748
I1017 22:13:33.442944 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00737348 (* 1 = 0.00737348 loss)
I1017 22:13:33.442965 22869 sgd_solver.cpp:105] Iteration 65200, lr = 0.001
I1017 22:14:03.629910 22869 solver.cpp:218] Iteration 65300 (3.31269 iter/s, 30.187s/100 iters), loss = 0.0232817
I1017 22:14:03.630054 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0232804 (* 1 = 0.0232804 loss)
I1017 22:14:03.630064 22869 sgd_solver.cpp:105] Iteration 65300, lr = 0.001
I1017 22:14:33.793576 22869 solver.cpp:218] Iteration 65400 (3.31526 iter/s, 30.1635s/100 iters), loss = 0.00847127
I1017 22:14:33.793723 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00846996 (* 1 = 0.00846996 loss)
I1017 22:14:33.793732 22869 sgd_solver.cpp:105] Iteration 65400, lr = 0.001
I1017 22:15:03.689399 22869 solver.cpp:330] Iteration 65500, Testing net (#0)
I1017 22:15:20.117686 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 22:15:20.453567 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.18238 (* 1 = 1.18238 loss)
I1017 22:15:20.453583 22869 solver.cpp:397]     Test net output #1: accuracy = 0.7366
I1017 22:15:20.750481 22869 solver.cpp:218] Iteration 65500 (2.12962 iter/s, 46.9567s/100 iters), loss = 0.00494282
I1017 22:15:20.750517 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00494151 (* 1 = 0.00494151 loss)
I1017 22:15:20.750524 22869 sgd_solver.cpp:105] Iteration 65500, lr = 0.001
I1017 22:15:50.903556 22869 solver.cpp:218] Iteration 65600 (3.31642 iter/s, 30.153s/100 iters), loss = 0.00650361
I1017 22:15:50.903707 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0065023 (* 1 = 0.0065023 loss)
I1017 22:15:50.903729 22869 sgd_solver.cpp:105] Iteration 65600, lr = 0.001
I1017 22:16:21.057328 22869 solver.cpp:218] Iteration 65700 (3.31635 iter/s, 30.1536s/100 iters), loss = 0.00404591
I1017 22:16:21.057428 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0040446 (* 1 = 0.0040446 loss)
I1017 22:16:21.057436 22869 sgd_solver.cpp:105] Iteration 65700, lr = 0.001
I1017 22:16:51.206771 22869 solver.cpp:218] Iteration 65800 (3.31682 iter/s, 30.1493s/100 iters), loss = 0.0034543
I1017 22:16:51.206866 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00345299 (* 1 = 0.00345299 loss)
I1017 22:16:51.206884 22869 sgd_solver.cpp:105] Iteration 65800, lr = 0.001
I1017 22:17:21.392597 22869 solver.cpp:218] Iteration 65900 (3.31282 iter/s, 30.1857s/100 iters), loss = 0.00365492
I1017 22:17:21.392675 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00365361 (* 1 = 0.00365361 loss)
I1017 22:17:21.392691 22869 sgd_solver.cpp:105] Iteration 65900, lr = 0.001
I1017 22:17:50.127178 22877 data_layer.cpp:73] Restarting data prefetching from start.
I1017 22:17:51.331367 22869 solver.cpp:330] Iteration 66000, Testing net (#0)
I1017 22:18:07.689632 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 22:18:08.024266 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.18151 (* 1 = 1.18151 loss)
I1017 22:18:08.024281 22869 solver.cpp:397]     Test net output #1: accuracy = 0.738
I1017 22:18:08.319581 22869 solver.cpp:218] Iteration 66000 (2.13097 iter/s, 46.9269s/100 iters), loss = 0.0058325
I1017 22:18:08.319612 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00583118 (* 1 = 0.00583118 loss)
I1017 22:18:08.319618 22869 sgd_solver.cpp:105] Iteration 66000, lr = 0.001
I1017 22:18:38.547860 22869 solver.cpp:218] Iteration 66100 (3.30816 iter/s, 30.2282s/100 iters), loss = 0.00495943
I1017 22:18:38.547971 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00495811 (* 1 = 0.00495811 loss)
I1017 22:18:38.547979 22869 sgd_solver.cpp:105] Iteration 66100, lr = 0.001
I1017 22:19:08.796983 22869 solver.cpp:218] Iteration 66200 (3.30589 iter/s, 30.249s/100 iters), loss = 0.00342116
I1017 22:19:08.797163 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00341984 (* 1 = 0.00341984 loss)
I1017 22:19:08.797173 22869 sgd_solver.cpp:105] Iteration 66200, lr = 0.001
I1017 22:19:39.012821 22869 solver.cpp:218] Iteration 66300 (3.30954 iter/s, 30.2157s/100 iters), loss = 0.00550979
I1017 22:19:39.012974 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00550847 (* 1 = 0.00550847 loss)
I1017 22:19:39.012981 22869 sgd_solver.cpp:105] Iteration 66300, lr = 0.001
I1017 22:20:09.172411 22869 solver.cpp:218] Iteration 66400 (3.31571 iter/s, 30.1594s/100 iters), loss = 0.0156779
I1017 22:20:09.172530 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0156766 (* 1 = 0.0156766 loss)
I1017 22:20:09.172538 22869 sgd_solver.cpp:105] Iteration 66400, lr = 0.001
I1017 22:20:39.086139 22869 solver.cpp:330] Iteration 66500, Testing net (#0)
I1017 22:20:55.486546 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 22:20:55.821276 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.17922 (* 1 = 1.17922 loss)
I1017 22:20:55.821291 22869 solver.cpp:397]     Test net output #1: accuracy = 0.7362
I1017 22:20:56.119462 22869 solver.cpp:218] Iteration 66500 (2.13007 iter/s, 46.9469s/100 iters), loss = 0.00615677
I1017 22:20:56.119495 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00615546 (* 1 = 0.00615546 loss)
I1017 22:20:56.119503 22869 sgd_solver.cpp:105] Iteration 66500, lr = 0.001
I1017 22:21:26.328914 22869 solver.cpp:218] Iteration 66600 (3.31023 iter/s, 30.2094s/100 iters), loss = 0.00487668
I1017 22:21:26.329066 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00487537 (* 1 = 0.00487537 loss)
I1017 22:21:26.329083 22869 sgd_solver.cpp:105] Iteration 66600, lr = 0.001
I1017 22:21:56.549221 22869 solver.cpp:218] Iteration 66700 (3.30905 iter/s, 30.2202s/100 iters), loss = 0.00910851
I1017 22:21:56.549365 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0091072 (* 1 = 0.0091072 loss)
I1017 22:21:56.549373 22869 sgd_solver.cpp:105] Iteration 66700, lr = 0.001
I1017 22:22:26.749197 22869 solver.cpp:218] Iteration 66800 (3.31128 iter/s, 30.1998s/100 iters), loss = 0.00571183
I1017 22:22:26.749296 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00571051 (* 1 = 0.00571051 loss)
I1017 22:22:26.749313 22869 sgd_solver.cpp:105] Iteration 66800, lr = 0.001
I1017 22:22:56.926822 22869 solver.cpp:218] Iteration 66900 (3.31373 iter/s, 30.1775s/100 iters), loss = 0.00196235
I1017 22:22:56.926947 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00196104 (* 1 = 0.00196104 loss)
I1017 22:22:56.926955 22869 sgd_solver.cpp:105] Iteration 66900, lr = 0.001
I1017 22:23:25.668496 22877 data_layer.cpp:73] Restarting data prefetching from start.
I1017 22:23:26.868376 22869 solver.cpp:330] Iteration 67000, Testing net (#0)
I1017 22:23:43.267033 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 22:23:43.602625 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.17707 (* 1 = 1.17707 loss)
I1017 22:23:43.602640 22869 solver.cpp:397]     Test net output #1: accuracy = 0.737
I1017 22:23:43.899238 22869 solver.cpp:218] Iteration 67000 (2.12892 iter/s, 46.9723s/100 iters), loss = 0.0040756
I1017 22:23:43.899276 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00407429 (* 1 = 0.00407429 loss)
I1017 22:23:43.899282 22869 sgd_solver.cpp:105] Iteration 67000, lr = 0.001
I1017 22:24:14.074291 22869 solver.cpp:218] Iteration 67100 (3.314 iter/s, 30.175s/100 iters), loss = 0.00741159
I1017 22:24:14.074430 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00741027 (* 1 = 0.00741027 loss)
I1017 22:24:14.074439 22869 sgd_solver.cpp:105] Iteration 67100, lr = 0.001
I1017 22:24:44.267769 22869 solver.cpp:218] Iteration 67200 (3.31199 iter/s, 30.1933s/100 iters), loss = 0.00490333
I1017 22:24:44.267879 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.004902 (* 1 = 0.004902 loss)
I1017 22:24:44.267887 22869 sgd_solver.cpp:105] Iteration 67200, lr = 0.001
I1017 22:25:14.420538 22869 solver.cpp:218] Iteration 67300 (3.31646 iter/s, 30.1527s/100 iters), loss = 0.00680797
I1017 22:25:14.420670 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00680664 (* 1 = 0.00680664 loss)
I1017 22:25:14.420680 22869 sgd_solver.cpp:105] Iteration 67300, lr = 0.001
I1017 22:25:44.621119 22869 solver.cpp:218] Iteration 67400 (3.31121 iter/s, 30.2004s/100 iters), loss = 0.0103901
I1017 22:25:44.621227 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0103888 (* 1 = 0.0103888 loss)
I1017 22:25:44.621243 22869 sgd_solver.cpp:105] Iteration 67400, lr = 0.001
I1017 22:26:14.512066 22869 solver.cpp:330] Iteration 67500, Testing net (#0)
I1017 22:26:30.901178 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 22:26:31.236933 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.17558 (* 1 = 1.17558 loss)
I1017 22:26:31.236949 22869 solver.cpp:397]     Test net output #1: accuracy = 0.7367
I1017 22:26:31.533946 22869 solver.cpp:218] Iteration 67500 (2.13162 iter/s, 46.9127s/100 iters), loss = 0.00533788
I1017 22:26:31.533990 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00533656 (* 1 = 0.00533656 loss)
I1017 22:26:31.533998 22869 sgd_solver.cpp:105] Iteration 67500, lr = 0.001
I1017 22:27:01.716006 22869 solver.cpp:218] Iteration 67600 (3.31323 iter/s, 30.182s/100 iters), loss = 0.00490831
I1017 22:27:01.716173 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.004907 (* 1 = 0.004907 loss)
I1017 22:27:01.716197 22869 sgd_solver.cpp:105] Iteration 67600, lr = 0.001
I1017 22:27:31.869671 22869 solver.cpp:218] Iteration 67700 (3.31636 iter/s, 30.1535s/100 iters), loss = 0.00742762
I1017 22:27:31.869820 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0074263 (* 1 = 0.0074263 loss)
I1017 22:27:31.869843 22869 sgd_solver.cpp:105] Iteration 67700, lr = 0.001
I1017 22:28:02.037855 22869 solver.cpp:218] Iteration 67800 (3.31477 iter/s, 30.168s/100 iters), loss = 0.00315371
I1017 22:28:02.037953 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00315239 (* 1 = 0.00315239 loss)
I1017 22:28:02.037963 22869 sgd_solver.cpp:105] Iteration 67800, lr = 0.001
I1017 22:28:32.223652 22869 solver.cpp:218] Iteration 67900 (3.31283 iter/s, 30.1857s/100 iters), loss = 0.00536295
I1017 22:28:32.223803 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00536163 (* 1 = 0.00536163 loss)
I1017 22:28:32.223826 22869 sgd_solver.cpp:105] Iteration 67900, lr = 0.001
I1017 22:29:00.944036 22877 data_layer.cpp:73] Restarting data prefetching from start.
I1017 22:29:02.144804 22869 solver.cpp:330] Iteration 68000, Testing net (#0)
I1017 22:29:18.572273 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 22:29:18.908233 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.17357 (* 1 = 1.17357 loss)
I1017 22:29:18.908252 22869 solver.cpp:397]     Test net output #1: accuracy = 0.7371
I1017 22:29:19.205497 22869 solver.cpp:218] Iteration 68000 (2.12849 iter/s, 46.9817s/100 iters), loss = 0.00640703
I1017 22:29:19.205530 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00640571 (* 1 = 0.00640571 loss)
I1017 22:29:19.205540 22869 sgd_solver.cpp:105] Iteration 68000, lr = 0.001
I1017 22:29:49.362905 22869 solver.cpp:218] Iteration 68100 (3.31594 iter/s, 30.1574s/100 iters), loss = 0.00776606
I1017 22:29:49.363047 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00776475 (* 1 = 0.00776475 loss)
I1017 22:29:49.363059 22869 sgd_solver.cpp:105] Iteration 68100, lr = 0.001
I1017 22:30:19.538271 22869 solver.cpp:218] Iteration 68200 (3.31398 iter/s, 30.1752s/100 iters), loss = 0.00950029
I1017 22:30:19.538419 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00949897 (* 1 = 0.00949897 loss)
I1017 22:30:19.538445 22869 sgd_solver.cpp:105] Iteration 68200, lr = 0.001
I1017 22:30:49.741562 22869 solver.cpp:218] Iteration 68300 (3.31091 iter/s, 30.2031s/100 iters), loss = 0.00748958
I1017 22:30:49.741708 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00748827 (* 1 = 0.00748827 loss)
I1017 22:30:49.741719 22869 sgd_solver.cpp:105] Iteration 68300, lr = 0.001
I1017 22:31:19.942549 22869 solver.cpp:218] Iteration 68400 (3.31117 iter/s, 30.2008s/100 iters), loss = 0.00750503
I1017 22:31:19.942706 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00750371 (* 1 = 0.00750371 loss)
I1017 22:31:19.942733 22869 sgd_solver.cpp:105] Iteration 68400, lr = 0.001
I1017 22:31:49.873909 22869 solver.cpp:330] Iteration 68500, Testing net (#0)
I1017 22:32:06.302536 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 22:32:06.637151 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.17016 (* 1 = 1.17016 loss)
I1017 22:32:06.637167 22869 solver.cpp:397]     Test net output #1: accuracy = 0.7379
I1017 22:32:06.936884 22869 solver.cpp:218] Iteration 68500 (2.12792 iter/s, 46.9942s/100 iters), loss = 0.00404436
I1017 22:32:06.936923 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00404304 (* 1 = 0.00404304 loss)
I1017 22:32:06.936933 22869 sgd_solver.cpp:105] Iteration 68500, lr = 0.001
I1017 22:32:37.169706 22869 solver.cpp:218] Iteration 68600 (3.30767 iter/s, 30.2328s/100 iters), loss = 0.00355141
I1017 22:32:37.169850 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0035501 (* 1 = 0.0035501 loss)
I1017 22:32:37.169862 22869 sgd_solver.cpp:105] Iteration 68600, lr = 0.001
I1017 22:33:07.374037 22869 solver.cpp:218] Iteration 68700 (3.3108 iter/s, 30.2042s/100 iters), loss = 0.00342862
I1017 22:33:07.374189 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0034273 (* 1 = 0.0034273 loss)
I1017 22:33:07.374212 22869 sgd_solver.cpp:105] Iteration 68700, lr = 0.001
I1017 22:33:37.545553 22869 solver.cpp:218] Iteration 68800 (3.3144 iter/s, 30.1714s/100 iters), loss = 0.00508541
I1017 22:33:37.545696 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0050841 (* 1 = 0.0050841 loss)
I1017 22:33:37.545709 22869 sgd_solver.cpp:105] Iteration 68800, lr = 0.001
I1017 22:34:07.732967 22869 solver.cpp:218] Iteration 68900 (3.31266 iter/s, 30.1873s/100 iters), loss = 0.00343584
I1017 22:34:07.733116 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00343453 (* 1 = 0.00343453 loss)
I1017 22:34:07.733144 22869 sgd_solver.cpp:105] Iteration 68900, lr = 0.001
I1017 22:34:36.416107 22877 data_layer.cpp:73] Restarting data prefetching from start.
I1017 22:34:37.625030 22869 solver.cpp:330] Iteration 69000, Testing net (#0)
I1017 22:34:54.017558 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 22:34:54.352668 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.16768 (* 1 = 1.16768 loss)
I1017 22:34:54.352684 22869 solver.cpp:397]     Test net output #1: accuracy = 0.739
I1017 22:34:54.650090 22869 solver.cpp:218] Iteration 69000 (2.13142 iter/s, 46.917s/100 iters), loss = 0.00438779
I1017 22:34:54.650122 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00438647 (* 1 = 0.00438647 loss)
I1017 22:34:54.650131 22869 sgd_solver.cpp:105] Iteration 69000, lr = 0.001
I1017 22:35:24.867171 22869 solver.cpp:218] Iteration 69100 (3.30939 iter/s, 30.217s/100 iters), loss = 0.00858775
I1017 22:35:24.867314 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00858643 (* 1 = 0.00858643 loss)
I1017 22:35:24.867337 22869 sgd_solver.cpp:105] Iteration 69100, lr = 0.001
I1017 22:35:55.063802 22869 solver.cpp:218] Iteration 69200 (3.31164 iter/s, 30.1965s/100 iters), loss = 0.00498546
I1017 22:35:55.063948 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00498415 (* 1 = 0.00498415 loss)
I1017 22:35:55.063971 22869 sgd_solver.cpp:105] Iteration 69200, lr = 0.001
I1017 22:36:25.256036 22869 solver.cpp:218] Iteration 69300 (3.31213 iter/s, 30.1921s/100 iters), loss = 0.00498372
I1017 22:36:25.256165 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00498241 (* 1 = 0.00498241 loss)
I1017 22:36:25.256176 22869 sgd_solver.cpp:105] Iteration 69300, lr = 0.001
I1017 22:36:55.425009 22869 solver.cpp:218] Iteration 69400 (3.31468 iter/s, 30.1688s/100 iters), loss = 0.00635722
I1017 22:36:55.425154 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0063559 (* 1 = 0.0063559 loss)
I1017 22:36:55.425168 22869 sgd_solver.cpp:105] Iteration 69400, lr = 0.001
I1017 22:37:25.300194 22869 solver.cpp:330] Iteration 69500, Testing net (#0)
I1017 22:37:41.713649 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 22:37:42.049880 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.1663 (* 1 = 1.1663 loss)
I1017 22:37:42.049896 22869 solver.cpp:397]     Test net output #1: accuracy = 0.7384
I1017 22:37:42.348016 22869 solver.cpp:218] Iteration 69500 (2.13116 iter/s, 46.9229s/100 iters), loss = 0.00540283
I1017 22:37:42.348058 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00540151 (* 1 = 0.00540151 loss)
I1017 22:37:42.348069 22869 sgd_solver.cpp:105] Iteration 69500, lr = 0.001
I1017 22:38:12.553468 22869 solver.cpp:218] Iteration 69600 (3.31067 iter/s, 30.2054s/100 iters), loss = 0.00472954
I1017 22:38:12.553632 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00472822 (* 1 = 0.00472822 loss)
I1017 22:38:12.553645 22869 sgd_solver.cpp:105] Iteration 69600, lr = 0.001
I1017 22:38:42.728523 22869 solver.cpp:218] Iteration 69700 (3.31401 iter/s, 30.1749s/100 iters), loss = 0.00346123
I1017 22:38:42.728670 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00345992 (* 1 = 0.00345992 loss)
I1017 22:38:42.728696 22869 sgd_solver.cpp:105] Iteration 69700, lr = 0.001
I1017 22:39:12.890218 22869 solver.cpp:218] Iteration 69800 (3.31548 iter/s, 30.1615s/100 iters), loss = 0.012685
I1017 22:39:12.890328 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0126837 (* 1 = 0.0126837 loss)
I1017 22:39:12.890337 22869 sgd_solver.cpp:105] Iteration 69800, lr = 0.001
I1017 22:39:42.967295 22869 solver.cpp:218] Iteration 69900 (3.3248 iter/s, 30.077s/100 iters), loss = 0.0029092
I1017 22:39:42.967437 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00290789 (* 1 = 0.00290789 loss)
I1017 22:39:42.967449 22869 sgd_solver.cpp:105] Iteration 69900, lr = 0.001
I1017 22:40:11.341403 22877 data_layer.cpp:73] Restarting data prefetching from start.
I1017 22:40:12.544833 22869 solver.cpp:330] Iteration 70000, Testing net (#0)
I1017 22:40:28.738365 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 22:40:29.070127 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.16422 (* 1 = 1.16422 loss)
I1017 22:40:29.070143 22869 solver.cpp:397]     Test net output #1: accuracy = 0.7382
I1017 22:40:29.363070 22869 solver.cpp:218] Iteration 70000 (2.15538 iter/s, 46.3956s/100 iters), loss = 0.00335118
I1017 22:40:29.363101 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00334987 (* 1 = 0.00334987 loss)
I1017 22:40:29.363111 22869 sgd_solver.cpp:105] Iteration 70000, lr = 0.001
I1017 22:40:59.233501 22869 solver.cpp:218] Iteration 70100 (3.3478 iter/s, 29.8704s/100 iters), loss = 0.00597089
I1017 22:40:59.233649 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00596958 (* 1 = 0.00596958 loss)
I1017 22:40:59.233676 22869 sgd_solver.cpp:105] Iteration 70100, lr = 0.001
I1017 22:41:29.123263 22869 solver.cpp:218] Iteration 70200 (3.34564 iter/s, 29.8896s/100 iters), loss = 0.00694875
I1017 22:41:29.123298 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00694744 (* 1 = 0.00694744 loss)
I1017 22:41:29.123307 22869 sgd_solver.cpp:105] Iteration 70200, lr = 0.001
I1017 22:41:59.018918 22869 solver.cpp:218] Iteration 70300 (3.34497 iter/s, 29.8956s/100 iters), loss = 0.00394023
I1017 22:41:59.019065 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00393892 (* 1 = 0.00393892 loss)
I1017 22:41:59.019093 22869 sgd_solver.cpp:105] Iteration 70300, lr = 0.001
I1017 22:42:28.913754 22869 solver.cpp:218] Iteration 70400 (3.34508 iter/s, 29.8947s/100 iters), loss = 0.00337378
I1017 22:42:28.913787 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00337248 (* 1 = 0.00337248 loss)
I1017 22:42:28.913795 22869 sgd_solver.cpp:105] Iteration 70400, lr = 0.001
I1017 22:42:58.500694 22869 solver.cpp:330] Iteration 70500, Testing net (#0)
I1017 22:43:14.691349 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 22:43:15.023196 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.16211 (* 1 = 1.16211 loss)
I1017 22:43:15.023213 22869 solver.cpp:397]     Test net output #1: accuracy = 0.7382
I1017 22:43:15.315371 22869 solver.cpp:218] Iteration 70500 (2.1551 iter/s, 46.4016s/100 iters), loss = 0.00405998
I1017 22:43:15.315404 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00405867 (* 1 = 0.00405867 loss)
I1017 22:43:15.315414 22869 sgd_solver.cpp:105] Iteration 70500, lr = 0.001
I1017 22:43:45.200474 22869 solver.cpp:218] Iteration 70600 (3.34615 iter/s, 29.8851s/100 iters), loss = 0.00561366
I1017 22:43:45.200637 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00561235 (* 1 = 0.00561235 loss)
I1017 22:43:45.200649 22869 sgd_solver.cpp:105] Iteration 70600, lr = 0.001
I1017 22:44:15.089637 22869 solver.cpp:218] Iteration 70700 (3.34571 iter/s, 29.889s/100 iters), loss = 0.00482904
I1017 22:44:15.089673 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00482774 (* 1 = 0.00482774 loss)
I1017 22:44:15.089681 22869 sgd_solver.cpp:105] Iteration 70700, lr = 0.001
I1017 22:44:44.964246 22869 solver.cpp:218] Iteration 70800 (3.34733 iter/s, 29.8746s/100 iters), loss = 0.00424424
I1017 22:44:44.964395 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00424294 (* 1 = 0.00424294 loss)
I1017 22:44:44.964421 22869 sgd_solver.cpp:105] Iteration 70800, lr = 0.001
I1017 22:45:14.877560 22869 solver.cpp:218] Iteration 70900 (3.34301 iter/s, 29.9132s/100 iters), loss = 0.00337306
I1017 22:45:14.877598 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00337176 (* 1 = 0.00337176 loss)
I1017 22:45:14.877606 22869 sgd_solver.cpp:105] Iteration 70900, lr = 0.001
I1017 22:45:43.315912 22877 data_layer.cpp:73] Restarting data prefetching from start.
I1017 22:45:44.509706 22869 solver.cpp:330] Iteration 71000, Testing net (#0)
I1017 22:46:00.712186 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 22:46:01.044082 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.16025 (* 1 = 1.16025 loss)
I1017 22:46:01.044100 22869 solver.cpp:397]     Test net output #1: accuracy = 0.7393
I1017 22:46:01.336038 22869 solver.cpp:218] Iteration 71000 (2.15246 iter/s, 46.4584s/100 iters), loss = 0.00853291
I1017 22:46:01.336071 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0085316 (* 1 = 0.0085316 loss)
I1017 22:46:01.336081 22869 sgd_solver.cpp:105] Iteration 71000, lr = 0.001
I1017 22:46:31.229125 22869 solver.cpp:218] Iteration 71100 (3.34526 iter/s, 29.8931s/100 iters), loss = 0.00477406
I1017 22:46:31.229272 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00477275 (* 1 = 0.00477275 loss)
I1017 22:46:31.229310 22869 sgd_solver.cpp:105] Iteration 71100, lr = 0.001
I1017 22:47:01.115263 22869 solver.cpp:218] Iteration 71200 (3.34605 iter/s, 29.886s/100 iters), loss = 0.00595596
I1017 22:47:01.115301 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00595465 (* 1 = 0.00595465 loss)
I1017 22:47:01.115310 22869 sgd_solver.cpp:105] Iteration 71200, lr = 0.001
I1017 22:47:31.016619 22869 solver.cpp:218] Iteration 71300 (3.34433 iter/s, 29.9013s/100 iters), loss = 0.00816183
I1017 22:47:31.016770 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00816053 (* 1 = 0.00816053 loss)
I1017 22:47:31.016810 22869 sgd_solver.cpp:105] Iteration 71300, lr = 0.001
I1017 22:48:00.908838 22869 solver.cpp:218] Iteration 71400 (3.34537 iter/s, 29.8921s/100 iters), loss = 0.0058946
I1017 22:48:00.908875 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00589329 (* 1 = 0.00589329 loss)
I1017 22:48:00.908885 22869 sgd_solver.cpp:105] Iteration 71400, lr = 0.001
I1017 22:48:30.501495 22869 solver.cpp:330] Iteration 71500, Testing net (#0)
I1017 22:48:46.697594 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 22:48:47.027521 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.15859 (* 1 = 1.15859 loss)
I1017 22:48:47.027537 22869 solver.cpp:397]     Test net output #1: accuracy = 0.7386
I1017 22:48:47.318496 22869 solver.cpp:218] Iteration 71500 (2.15473 iter/s, 46.4096s/100 iters), loss = 0.00699675
I1017 22:48:47.318537 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00699544 (* 1 = 0.00699544 loss)
I1017 22:48:47.318547 22869 sgd_solver.cpp:105] Iteration 71500, lr = 0.001
I1017 22:49:17.210371 22869 solver.cpp:218] Iteration 71600 (3.3454 iter/s, 29.8918s/100 iters), loss = 0.00427739
I1017 22:49:17.210479 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00427608 (* 1 = 0.00427608 loss)
I1017 22:49:17.210489 22869 sgd_solver.cpp:105] Iteration 71600, lr = 0.001
I1017 22:49:47.102373 22869 solver.cpp:218] Iteration 71700 (3.34539 iter/s, 29.8919s/100 iters), loss = 0.00467108
I1017 22:49:47.102408 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00466977 (* 1 = 0.00466977 loss)
I1017 22:49:47.102418 22869 sgd_solver.cpp:105] Iteration 71700, lr = 0.001
I1017 22:50:16.987491 22869 solver.cpp:218] Iteration 71800 (3.34615 iter/s, 29.8851s/100 iters), loss = 0.00570767
I1017 22:50:16.987673 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00570637 (* 1 = 0.00570637 loss)
I1017 22:50:16.987685 22869 sgd_solver.cpp:105] Iteration 71800, lr = 0.001
I1017 22:50:46.876793 22869 solver.cpp:218] Iteration 71900 (3.3457 iter/s, 29.8891s/100 iters), loss = 0.0030682
I1017 22:50:46.876824 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0030669 (* 1 = 0.0030669 loss)
I1017 22:50:46.876830 22869 sgd_solver.cpp:105] Iteration 71900, lr = 0.001
I1017 22:51:15.267850 22877 data_layer.cpp:73] Restarting data prefetching from start.
I1017 22:51:16.464033 22869 solver.cpp:330] Iteration 72000, Testing net (#0)
I1017 22:51:32.665967 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 22:51:32.999143 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.15724 (* 1 = 1.15724 loss)
I1017 22:51:32.999159 22869 solver.cpp:397]     Test net output #1: accuracy = 0.7395
I1017 22:51:33.293171 22869 solver.cpp:218] Iteration 72000 (2.15441 iter/s, 46.4163s/100 iters), loss = 0.0056533
I1017 22:51:33.293207 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00565199 (* 1 = 0.00565199 loss)
I1017 22:51:33.293215 22869 sgd_solver.cpp:105] Iteration 72000, lr = 0.001
I1017 22:52:03.161322 22869 solver.cpp:218] Iteration 72100 (3.34805 iter/s, 29.8681s/100 iters), loss = 0.00487979
I1017 22:52:03.161465 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00487849 (* 1 = 0.00487849 loss)
I1017 22:52:03.161474 22869 sgd_solver.cpp:105] Iteration 72100, lr = 0.001
I1017 22:52:33.042330 22869 solver.cpp:218] Iteration 72200 (3.34662 iter/s, 29.8809s/100 iters), loss = 0.00431873
I1017 22:52:33.042366 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00431742 (* 1 = 0.00431742 loss)
I1017 22:52:33.042372 22869 sgd_solver.cpp:105] Iteration 72200, lr = 0.001
I1017 22:53:02.935828 22869 solver.cpp:218] Iteration 72300 (3.34521 iter/s, 29.8935s/100 iters), loss = 0.0095602
I1017 22:53:02.935938 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0095589 (* 1 = 0.0095589 loss)
I1017 22:53:02.935956 22869 sgd_solver.cpp:105] Iteration 72300, lr = 0.001
I1017 22:53:32.835430 22869 solver.cpp:218] Iteration 72400 (3.34454 iter/s, 29.8995s/100 iters), loss = 0.0102624
I1017 22:53:32.835463 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0102611 (* 1 = 0.0102611 loss)
I1017 22:53:32.835469 22869 sgd_solver.cpp:105] Iteration 72400, lr = 0.001
I1017 22:54:02.448267 22869 solver.cpp:330] Iteration 72500, Testing net (#0)
I1017 22:54:18.653810 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 22:54:18.984369 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.15518 (* 1 = 1.15518 loss)
I1017 22:54:18.984385 22869 solver.cpp:397]     Test net output #1: accuracy = 0.7382
I1017 22:54:19.278661 22869 solver.cpp:218] Iteration 72500 (2.15317 iter/s, 46.4432s/100 iters), loss = 0.00815502
I1017 22:54:19.278692 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00815371 (* 1 = 0.00815371 loss)
I1017 22:54:19.278699 22869 sgd_solver.cpp:105] Iteration 72500, lr = 0.001
I1017 22:54:49.155354 22869 solver.cpp:218] Iteration 72600 (3.34709 iter/s, 29.8767s/100 iters), loss = 0.00407667
I1017 22:54:49.155458 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00407536 (* 1 = 0.00407536 loss)
I1017 22:54:49.155477 22869 sgd_solver.cpp:105] Iteration 72600, lr = 0.001
I1017 22:55:19.026010 22869 solver.cpp:218] Iteration 72700 (3.34778 iter/s, 29.8706s/100 iters), loss = 0.00618697
I1017 22:55:19.026041 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00618567 (* 1 = 0.00618567 loss)
I1017 22:55:19.026047 22869 sgd_solver.cpp:105] Iteration 72700, lr = 0.001
I1017 22:55:48.888514 22869 solver.cpp:218] Iteration 72800 (3.34869 iter/s, 29.8625s/100 iters), loss = 0.00473016
I1017 22:55:48.888639 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00472885 (* 1 = 0.00472885 loss)
I1017 22:55:48.888648 22869 sgd_solver.cpp:105] Iteration 72800, lr = 0.001
I1017 22:56:18.779032 22869 solver.cpp:218] Iteration 72900 (3.34556 iter/s, 29.8904s/100 iters), loss = 0.00234712
I1017 22:56:18.779064 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00234581 (* 1 = 0.00234581 loss)
I1017 22:56:18.779070 22869 sgd_solver.cpp:105] Iteration 72900, lr = 0.001
I1017 22:56:47.160378 22877 data_layer.cpp:73] Restarting data prefetching from start.
I1017 22:56:48.355527 22869 solver.cpp:330] Iteration 73000, Testing net (#0)
I1017 22:57:04.546247 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 22:57:04.879560 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.15281 (* 1 = 1.15281 loss)
I1017 22:57:04.879577 22869 solver.cpp:397]     Test net output #1: accuracy = 0.7398
I1017 22:57:05.174309 22869 solver.cpp:218] Iteration 73000 (2.15539 iter/s, 46.3952s/100 iters), loss = 0.00235383
I1017 22:57:05.174340 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00235252 (* 1 = 0.00235252 loss)
I1017 22:57:05.174347 22869 sgd_solver.cpp:105] Iteration 73000, lr = 0.001
I1017 22:57:35.015403 22869 solver.cpp:218] Iteration 73100 (3.35109 iter/s, 29.841s/100 iters), loss = 0.00440452
I1017 22:57:35.015545 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00440321 (* 1 = 0.00440321 loss)
I1017 22:57:35.015554 22869 sgd_solver.cpp:105] Iteration 73100, lr = 0.001
I1017 22:58:04.866483 22869 solver.cpp:218] Iteration 73200 (3.34998 iter/s, 29.8509s/100 iters), loss = 0.00742218
I1017 22:58:04.866514 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00742087 (* 1 = 0.00742087 loss)
I1017 22:58:04.866520 22869 sgd_solver.cpp:105] Iteration 73200, lr = 0.001
I1017 22:58:34.702138 22869 solver.cpp:218] Iteration 73300 (3.3517 iter/s, 29.8356s/100 iters), loss = 0.00510999
I1017 22:58:34.702206 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00510868 (* 1 = 0.00510868 loss)
I1017 22:58:34.702224 22869 sgd_solver.cpp:105] Iteration 73300, lr = 0.001
I1017 22:59:04.536538 22869 solver.cpp:218] Iteration 73400 (3.35184 iter/s, 29.8343s/100 iters), loss = 0.00888636
I1017 22:59:04.536569 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00888505 (* 1 = 0.00888505 loss)
I1017 22:59:04.536576 22869 sgd_solver.cpp:105] Iteration 73400, lr = 0.001
I1017 22:59:34.114807 22869 solver.cpp:330] Iteration 73500, Testing net (#0)
I1017 22:59:50.311866 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 22:59:50.643551 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.15071 (* 1 = 1.15071 loss)
I1017 22:59:50.643565 22869 solver.cpp:397]     Test net output #1: accuracy = 0.7395
I1017 22:59:50.935701 22869 solver.cpp:218] Iteration 73500 (2.15521 iter/s, 46.3991s/100 iters), loss = 0.00826677
I1017 22:59:50.935736 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00826546 (* 1 = 0.00826546 loss)
I1017 22:59:50.935745 22869 sgd_solver.cpp:105] Iteration 73500, lr = 0.001
I1017 23:00:20.788120 22869 solver.cpp:218] Iteration 73600 (3.34982 iter/s, 29.8524s/100 iters), loss = 0.00288957
I1017 23:00:20.788261 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00288826 (* 1 = 0.00288826 loss)
I1017 23:00:20.788270 22869 sgd_solver.cpp:105] Iteration 73600, lr = 0.001
I1017 23:00:50.656862 22869 solver.cpp:218] Iteration 73700 (3.348 iter/s, 29.8686s/100 iters), loss = 0.00354477
I1017 23:00:50.656893 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00354346 (* 1 = 0.00354346 loss)
I1017 23:00:50.656900 22869 sgd_solver.cpp:105] Iteration 73700, lr = 0.001
I1017 23:01:20.549918 22869 solver.cpp:218] Iteration 73800 (3.34526 iter/s, 29.893s/100 iters), loss = 0.00783751
I1017 23:01:20.550082 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0078362 (* 1 = 0.0078362 loss)
I1017 23:01:20.550108 22869 sgd_solver.cpp:105] Iteration 73800, lr = 0.001
I1017 23:01:50.432148 22869 solver.cpp:218] Iteration 73900 (3.34649 iter/s, 29.8821s/100 iters), loss = 0.0039728
I1017 23:01:50.432190 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00397149 (* 1 = 0.00397149 loss)
I1017 23:01:50.432198 22869 sgd_solver.cpp:105] Iteration 73900, lr = 0.001
I1017 23:02:18.835031 22877 data_layer.cpp:73] Restarting data prefetching from start.
I1017 23:02:20.028220 22869 solver.cpp:330] Iteration 74000, Testing net (#0)
I1017 23:02:36.229081 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 23:02:36.559849 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.14961 (* 1 = 1.14961 loss)
I1017 23:02:36.559865 22869 solver.cpp:397]     Test net output #1: accuracy = 0.7401
I1017 23:02:36.851471 22869 solver.cpp:218] Iteration 74000 (2.15428 iter/s, 46.4193s/100 iters), loss = 0.00446952
I1017 23:02:36.851500 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00446821 (* 1 = 0.00446821 loss)
I1017 23:02:36.851506 22869 sgd_solver.cpp:105] Iteration 74000, lr = 0.001
I1017 23:03:06.757565 22869 solver.cpp:218] Iteration 74100 (3.3438 iter/s, 29.9061s/100 iters), loss = 0.00671882
I1017 23:03:06.757670 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00671751 (* 1 = 0.00671751 loss)
I1017 23:03:06.757678 22869 sgd_solver.cpp:105] Iteration 74100, lr = 0.001
I1017 23:03:36.674067 22869 solver.cpp:218] Iteration 74200 (3.34265 iter/s, 29.9164s/100 iters), loss = 0.00435052
I1017 23:03:36.674098 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00434921 (* 1 = 0.00434921 loss)
I1017 23:03:36.674105 22869 sgd_solver.cpp:105] Iteration 74200, lr = 0.001
I1017 23:04:06.586421 22869 solver.cpp:218] Iteration 74300 (3.3431 iter/s, 29.9123s/100 iters), loss = 0.00352743
I1017 23:04:06.586529 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00352612 (* 1 = 0.00352612 loss)
I1017 23:04:06.586539 22869 sgd_solver.cpp:105] Iteration 74300, lr = 0.001
I1017 23:04:36.499191 22869 solver.cpp:218] Iteration 74400 (3.34307 iter/s, 29.9127s/100 iters), loss = 0.00654761
I1017 23:04:36.499222 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0065463 (* 1 = 0.0065463 loss)
I1017 23:04:36.499228 22869 sgd_solver.cpp:105] Iteration 74400, lr = 0.001
I1017 23:05:06.144946 22869 solver.cpp:330] Iteration 74500, Testing net (#0)
I1017 23:05:22.339417 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 23:05:22.671569 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.14725 (* 1 = 1.14725 loss)
I1017 23:05:22.671586 22869 solver.cpp:397]     Test net output #1: accuracy = 0.738
I1017 23:05:22.965869 22869 solver.cpp:218] Iteration 74500 (2.15208 iter/s, 46.4666s/100 iters), loss = 0.00680899
I1017 23:05:22.965904 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00680768 (* 1 = 0.00680768 loss)
I1017 23:05:22.965911 22869 sgd_solver.cpp:105] Iteration 74500, lr = 0.001
I1017 23:05:52.849015 22869 solver.cpp:218] Iteration 74600 (3.34637 iter/s, 29.8831s/100 iters), loss = 0.00344399
I1017 23:05:52.849154 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00344269 (* 1 = 0.00344269 loss)
I1017 23:05:52.849164 22869 sgd_solver.cpp:105] Iteration 74600, lr = 0.001
I1017 23:06:22.745380 22869 solver.cpp:218] Iteration 74700 (3.3449 iter/s, 29.8962s/100 iters), loss = 0.00638944
I1017 23:06:22.745411 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00638813 (* 1 = 0.00638813 loss)
I1017 23:06:22.745419 22869 sgd_solver.cpp:105] Iteration 74700, lr = 0.001
I1017 23:06:52.637666 22869 solver.cpp:218] Iteration 74800 (3.34535 iter/s, 29.8923s/100 iters), loss = 0.00218821
I1017 23:06:52.637827 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0021869 (* 1 = 0.0021869 loss)
I1017 23:06:52.637838 22869 sgd_solver.cpp:105] Iteration 74800, lr = 0.001
I1017 23:07:22.546365 22869 solver.cpp:218] Iteration 74900 (3.34353 iter/s, 29.9085s/100 iters), loss = 0.00286658
I1017 23:07:22.546401 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00286527 (* 1 = 0.00286527 loss)
I1017 23:07:22.546409 22869 sgd_solver.cpp:105] Iteration 74900, lr = 0.001
I1017 23:07:50.970938 22877 data_layer.cpp:73] Restarting data prefetching from start.
I1017 23:07:52.166188 22869 solver.cpp:330] Iteration 75000, Testing net (#0)
I1017 23:08:08.364394 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 23:08:08.696250 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.14485 (* 1 = 1.14485 loss)
I1017 23:08:08.696266 22869 solver.cpp:397]     Test net output #1: accuracy = 0.7403
I1017 23:08:08.991490 22869 solver.cpp:218] Iteration 75000 (2.15308 iter/s, 46.4451s/100 iters), loss = 0.00310839
I1017 23:08:08.991524 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00310708 (* 1 = 0.00310708 loss)
I1017 23:08:08.991531 22869 sgd_solver.cpp:105] Iteration 75000, lr = 0.001
I1017 23:08:38.892421 22869 solver.cpp:218] Iteration 75100 (3.34438 iter/s, 29.9009s/100 iters), loss = 0.00942367
I1017 23:08:38.892565 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00942236 (* 1 = 0.00942236 loss)
I1017 23:08:38.892575 22869 sgd_solver.cpp:105] Iteration 75100, lr = 0.001
I1017 23:09:08.786938 22869 solver.cpp:218] Iteration 75200 (3.34511 iter/s, 29.8944s/100 iters), loss = 0.00492509
I1017 23:09:08.786970 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00492378 (* 1 = 0.00492378 loss)
I1017 23:09:08.786978 22869 sgd_solver.cpp:105] Iteration 75200, lr = 0.001
I1017 23:09:38.699430 22869 solver.cpp:218] Iteration 75300 (3.34309 iter/s, 29.9125s/100 iters), loss = 0.00625239
I1017 23:09:38.699579 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00625108 (* 1 = 0.00625108 loss)
I1017 23:09:38.699589 22869 sgd_solver.cpp:105] Iteration 75300, lr = 0.001
I1017 23:10:08.618250 22869 solver.cpp:218] Iteration 75400 (3.34239 iter/s, 29.9187s/100 iters), loss = 0.00386489
I1017 23:10:08.618283 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00386359 (* 1 = 0.00386359 loss)
I1017 23:10:08.618289 22869 sgd_solver.cpp:105] Iteration 75400, lr = 0.001
I1017 23:10:38.233880 22869 solver.cpp:330] Iteration 75500, Testing net (#0)
I1017 23:10:54.428763 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 23:10:54.760710 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.14334 (* 1 = 1.14334 loss)
I1017 23:10:54.760725 22869 solver.cpp:397]     Test net output #1: accuracy = 0.7399
I1017 23:10:55.053709 22869 solver.cpp:218] Iteration 75500 (2.15353 iter/s, 46.4354s/100 iters), loss = 0.00768616
I1017 23:10:55.053741 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00768486 (* 1 = 0.00768486 loss)
I1017 23:10:55.053748 22869 sgd_solver.cpp:105] Iteration 75500, lr = 0.001
I1017 23:11:24.932389 22869 solver.cpp:218] Iteration 75600 (3.34687 iter/s, 29.8786s/100 iters), loss = 0.00384452
I1017 23:11:24.932487 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00384322 (* 1 = 0.00384322 loss)
I1017 23:11:24.932505 22869 sgd_solver.cpp:105] Iteration 75600, lr = 0.001
I1017 23:11:54.830198 22869 solver.cpp:218] Iteration 75700 (3.34474 iter/s, 29.8977s/100 iters), loss = 0.00595065
I1017 23:11:54.830230 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00594935 (* 1 = 0.00594935 loss)
I1017 23:11:54.830237 22869 sgd_solver.cpp:105] Iteration 75700, lr = 0.001
I1017 23:12:24.714967 22869 solver.cpp:218] Iteration 75800 (3.34619 iter/s, 29.8847s/100 iters), loss = 0.00476645
I1017 23:12:24.715117 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00476515 (* 1 = 0.00476515 loss)
I1017 23:12:24.715128 22869 sgd_solver.cpp:105] Iteration 75800, lr = 0.001
I1017 23:12:54.610821 22869 solver.cpp:218] Iteration 75900 (3.34496 iter/s, 29.8957s/100 iters), loss = 0.0033284
I1017 23:12:54.610855 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0033271 (* 1 = 0.0033271 loss)
I1017 23:12:54.610862 22869 sgd_solver.cpp:105] Iteration 75900, lr = 0.001
I1017 23:13:22.980229 22877 data_layer.cpp:73] Restarting data prefetching from start.
I1017 23:13:24.177784 22869 solver.cpp:330] Iteration 76000, Testing net (#0)
I1017 23:13:40.378319 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 23:13:40.711812 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.14129 (* 1 = 1.14129 loss)
I1017 23:13:40.711827 22869 solver.cpp:397]     Test net output #1: accuracy = 0.7407
I1017 23:13:41.004871 22869 solver.cpp:218] Iteration 76000 (2.15545 iter/s, 46.394s/100 iters), loss = 0.00257675
I1017 23:13:41.004899 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00257545 (* 1 = 0.00257545 loss)
I1017 23:13:41.004905 22869 sgd_solver.cpp:105] Iteration 76000, lr = 0.001
I1017 23:14:10.887094 22869 solver.cpp:218] Iteration 76100 (3.34648 iter/s, 29.8822s/100 iters), loss = 0.00423368
I1017 23:14:10.887197 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00423238 (* 1 = 0.00423238 loss)
I1017 23:14:10.887204 22869 sgd_solver.cpp:105] Iteration 76100, lr = 0.001
I1017 23:14:40.752046 22869 solver.cpp:218] Iteration 76200 (3.34842 iter/s, 29.8648s/100 iters), loss = 0.00280288
I1017 23:14:40.752076 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00280158 (* 1 = 0.00280158 loss)
I1017 23:14:40.752084 22869 sgd_solver.cpp:105] Iteration 76200, lr = 0.001
I1017 23:15:10.611212 22869 solver.cpp:218] Iteration 76300 (3.34906 iter/s, 29.8591s/100 iters), loss = 0.00477666
I1017 23:15:10.611318 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00477536 (* 1 = 0.00477536 loss)
I1017 23:15:10.611337 22869 sgd_solver.cpp:105] Iteration 76300, lr = 0.001
I1017 23:15:40.486799 22869 solver.cpp:218] Iteration 76400 (3.34723 iter/s, 29.8755s/100 iters), loss = 0.00564946
I1017 23:15:40.486829 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00564816 (* 1 = 0.00564816 loss)
I1017 23:15:40.486835 22869 sgd_solver.cpp:105] Iteration 76400, lr = 0.001
I1017 23:16:10.077810 22869 solver.cpp:330] Iteration 76500, Testing net (#0)
I1017 23:16:26.267951 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 23:16:26.598212 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.13968 (* 1 = 1.13968 loss)
I1017 23:16:26.598228 22869 solver.cpp:397]     Test net output #1: accuracy = 0.741
I1017 23:16:26.892849 22869 solver.cpp:218] Iteration 76500 (2.15489 iter/s, 46.406s/100 iters), loss = 0.00344698
I1017 23:16:26.892887 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00344568 (* 1 = 0.00344568 loss)
I1017 23:16:26.892894 22869 sgd_solver.cpp:105] Iteration 76500, lr = 0.001
I1017 23:16:56.767742 22869 solver.cpp:218] Iteration 76600 (3.3473 iter/s, 29.8749s/100 iters), loss = 0.0027233
I1017 23:16:56.767858 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.002722 (* 1 = 0.002722 loss)
I1017 23:16:56.767865 22869 sgd_solver.cpp:105] Iteration 76600, lr = 0.001
I1017 23:17:26.635460 22869 solver.cpp:218] Iteration 76700 (3.34811 iter/s, 29.8676s/100 iters), loss = 0.00559628
I1017 23:17:26.635490 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00559498 (* 1 = 0.00559498 loss)
I1017 23:17:26.635496 22869 sgd_solver.cpp:105] Iteration 76700, lr = 0.001
I1017 23:17:56.486228 22869 solver.cpp:218] Iteration 76800 (3.35 iter/s, 29.8507s/100 iters), loss = 0.00689748
I1017 23:17:56.486333 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00689619 (* 1 = 0.00689619 loss)
I1017 23:17:56.486341 22869 sgd_solver.cpp:105] Iteration 76800, lr = 0.001
I1017 23:18:26.348016 22869 solver.cpp:218] Iteration 76900 (3.34877 iter/s, 29.8617s/100 iters), loss = 0.00408643
I1017 23:18:26.348047 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00408513 (* 1 = 0.00408513 loss)
I1017 23:18:26.348053 22869 sgd_solver.cpp:105] Iteration 76900, lr = 0.001
I1017 23:18:54.734802 22877 data_layer.cpp:73] Restarting data prefetching from start.
I1017 23:18:55.930752 22869 solver.cpp:330] Iteration 77000, Testing net (#0)
I1017 23:19:12.127475 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 23:19:12.459422 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.1374 (* 1 = 1.1374 loss)
I1017 23:19:12.459441 22869 solver.cpp:397]     Test net output #1: accuracy = 0.7419
I1017 23:19:12.753458 22869 solver.cpp:218] Iteration 77000 (2.15492 iter/s, 46.4054s/100 iters), loss = 0.00420149
I1017 23:19:12.753487 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00420019 (* 1 = 0.00420019 loss)
I1017 23:19:12.753494 22869 sgd_solver.cpp:105] Iteration 77000, lr = 0.001
I1017 23:19:42.614565 22869 solver.cpp:218] Iteration 77100 (3.34884 iter/s, 29.8611s/100 iters), loss = 0.0047304
I1017 23:19:42.614706 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0047291 (* 1 = 0.0047291 loss)
I1017 23:19:42.614715 22869 sgd_solver.cpp:105] Iteration 77100, lr = 0.001
I1017 23:20:12.490705 22869 solver.cpp:218] Iteration 77200 (3.34717 iter/s, 29.876s/100 iters), loss = 0.00539791
I1017 23:20:12.490741 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00539661 (* 1 = 0.00539661 loss)
I1017 23:20:12.490747 22869 sgd_solver.cpp:105] Iteration 77200, lr = 0.001
I1017 23:20:42.352030 22869 solver.cpp:218] Iteration 77300 (3.34882 iter/s, 29.8613s/100 iters), loss = 0.00491592
I1017 23:20:42.352138 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00491463 (* 1 = 0.00491463 loss)
I1017 23:20:42.352159 22869 sgd_solver.cpp:105] Iteration 77300, lr = 0.001
I1017 23:21:12.213392 22869 solver.cpp:218] Iteration 77400 (3.34882 iter/s, 29.8613s/100 iters), loss = 0.00312091
I1017 23:21:12.213424 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00311961 (* 1 = 0.00311961 loss)
I1017 23:21:12.213431 22869 sgd_solver.cpp:105] Iteration 77400, lr = 0.001
I1017 23:21:41.795336 22869 solver.cpp:330] Iteration 77500, Testing net (#0)
I1017 23:21:57.994426 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 23:21:58.323654 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.13578 (* 1 = 1.13578 loss)
I1017 23:21:58.323669 22869 solver.cpp:397]     Test net output #1: accuracy = 0.7411
I1017 23:21:58.617457 22869 solver.cpp:218] Iteration 77500 (2.15499 iter/s, 46.404s/100 iters), loss = 0.00860743
I1017 23:21:58.617493 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00860613 (* 1 = 0.00860613 loss)
I1017 23:21:58.617499 22869 sgd_solver.cpp:105] Iteration 77500, lr = 0.001
I1017 23:22:28.496037 22869 solver.cpp:218] Iteration 77600 (3.34688 iter/s, 29.8785s/100 iters), loss = 0.00274672
I1017 23:22:28.496177 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00274542 (* 1 = 0.00274542 loss)
I1017 23:22:28.496186 22869 sgd_solver.cpp:105] Iteration 77600, lr = 0.001
I1017 23:22:58.396898 22869 solver.cpp:218] Iteration 77700 (3.3444 iter/s, 29.9007s/100 iters), loss = 0.00366778
I1017 23:22:58.396929 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00366649 (* 1 = 0.00366649 loss)
I1017 23:22:58.396934 22869 sgd_solver.cpp:105] Iteration 77700, lr = 0.001
I1017 23:23:28.314100 22869 solver.cpp:218] Iteration 77800 (3.34256 iter/s, 29.9172s/100 iters), loss = 0.00341624
I1017 23:23:28.314224 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00341495 (* 1 = 0.00341495 loss)
I1017 23:23:28.314241 22869 sgd_solver.cpp:105] Iteration 77800, lr = 0.001
I1017 23:23:58.220875 22869 solver.cpp:218] Iteration 77900 (3.34374 iter/s, 29.9067s/100 iters), loss = 0.00264392
I1017 23:23:58.220906 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00264262 (* 1 = 0.00264262 loss)
I1017 23:23:58.220911 22869 sgd_solver.cpp:105] Iteration 77900, lr = 0.001
I1017 23:24:26.648296 22877 data_layer.cpp:73] Restarting data prefetching from start.
I1017 23:24:27.842697 22869 solver.cpp:330] Iteration 78000, Testing net (#0)
I1017 23:24:44.040154 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 23:24:44.371006 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.13425 (* 1 = 1.13425 loss)
I1017 23:24:44.371022 22869 solver.cpp:397]     Test net output #1: accuracy = 0.7418
I1017 23:24:44.663524 22869 solver.cpp:218] Iteration 78000 (2.15319 iter/s, 46.4426s/100 iters), loss = 0.00403421
I1017 23:24:44.663568 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00403292 (* 1 = 0.00403292 loss)
I1017 23:24:44.663574 22869 sgd_solver.cpp:105] Iteration 78000, lr = 0.001
I1017 23:25:14.532505 22869 solver.cpp:218] Iteration 78100 (3.34796 iter/s, 29.8689s/100 iters), loss = 0.00854162
I1017 23:25:14.532657 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00854032 (* 1 = 0.00854032 loss)
I1017 23:25:14.532666 22869 sgd_solver.cpp:105] Iteration 78100, lr = 0.001
I1017 23:25:44.402417 22869 solver.cpp:218] Iteration 78200 (3.34787 iter/s, 29.8698s/100 iters), loss = 0.00324343
I1017 23:25:44.402449 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00324213 (* 1 = 0.00324213 loss)
I1017 23:25:44.402456 22869 sgd_solver.cpp:105] Iteration 78200, lr = 0.001
I1017 23:26:14.288836 22869 solver.cpp:218] Iteration 78300 (3.346 iter/s, 29.8864s/100 iters), loss = 0.00432715
I1017 23:26:14.288978 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00432586 (* 1 = 0.00432586 loss)
I1017 23:26:14.288987 22869 sgd_solver.cpp:105] Iteration 78300, lr = 0.001
I1017 23:26:44.167044 22869 solver.cpp:218] Iteration 78400 (3.34694 iter/s, 29.8781s/100 iters), loss = 0.00516462
I1017 23:26:44.167075 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00516332 (* 1 = 0.00516332 loss)
I1017 23:26:44.167081 22869 sgd_solver.cpp:105] Iteration 78400, lr = 0.001
I1017 23:27:13.739941 22869 solver.cpp:330] Iteration 78500, Testing net (#0)
I1017 23:27:29.934979 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 23:27:30.266475 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.13209 (* 1 = 1.13209 loss)
I1017 23:27:30.266490 22869 solver.cpp:397]     Test net output #1: accuracy = 0.7412
I1017 23:27:30.559929 22869 solver.cpp:218] Iteration 78500 (2.1555 iter/s, 46.3929s/100 iters), loss = 0.00533225
I1017 23:27:30.559963 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00533096 (* 1 = 0.00533096 loss)
I1017 23:27:30.559969 22869 sgd_solver.cpp:105] Iteration 78500, lr = 0.001
I1017 23:28:00.461614 22869 solver.cpp:218] Iteration 78600 (3.3443 iter/s, 29.9016s/100 iters), loss = 0.00534859
I1017 23:28:00.461729 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0053473 (* 1 = 0.0053473 loss)
I1017 23:28:00.461748 22869 sgd_solver.cpp:105] Iteration 78600, lr = 0.001
I1017 23:28:30.352890 22869 solver.cpp:218] Iteration 78700 (3.34547 iter/s, 29.8912s/100 iters), loss = 0.00428382
I1017 23:28:30.352921 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00428253 (* 1 = 0.00428253 loss)
I1017 23:28:30.352926 22869 sgd_solver.cpp:105] Iteration 78700, lr = 0.001
I1017 23:29:00.240514 22869 solver.cpp:218] Iteration 78800 (3.34587 iter/s, 29.8876s/100 iters), loss = 0.00406635
I1017 23:29:00.240662 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00406505 (* 1 = 0.00406505 loss)
I1017 23:29:00.240672 22869 sgd_solver.cpp:105] Iteration 78800, lr = 0.001
I1017 23:29:30.129842 22869 solver.cpp:218] Iteration 78900 (3.34569 iter/s, 29.8892s/100 iters), loss = 0.00496484
I1017 23:29:30.129871 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00496355 (* 1 = 0.00496355 loss)
I1017 23:29:30.129878 22869 sgd_solver.cpp:105] Iteration 78900, lr = 0.001
I1017 23:29:58.549531 22877 data_layer.cpp:73] Restarting data prefetching from start.
I1017 23:29:59.744197 22869 solver.cpp:330] Iteration 79000, Testing net (#0)
I1017 23:30:15.936275 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 23:30:16.268678 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.13085 (* 1 = 1.13085 loss)
I1017 23:30:16.268695 22869 solver.cpp:397]     Test net output #1: accuracy = 0.7426
I1017 23:30:16.562361 22869 solver.cpp:218] Iteration 79000 (2.15366 iter/s, 46.4325s/100 iters), loss = 0.00375145
I1017 23:30:16.562392 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00375016 (* 1 = 0.00375016 loss)
I1017 23:30:16.562399 22869 sgd_solver.cpp:105] Iteration 79000, lr = 0.001
I1017 23:30:46.437094 22869 solver.cpp:218] Iteration 79100 (3.34731 iter/s, 29.8747s/100 iters), loss = 0.00569873
I1017 23:30:46.437223 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00569744 (* 1 = 0.00569744 loss)
I1017 23:30:46.437232 22869 sgd_solver.cpp:105] Iteration 79100, lr = 0.001
I1017 23:31:16.326514 22869 solver.cpp:218] Iteration 79200 (3.34568 iter/s, 29.8893s/100 iters), loss = 0.00466718
I1017 23:31:16.326545 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00466588 (* 1 = 0.00466588 loss)
I1017 23:31:16.326552 22869 sgd_solver.cpp:105] Iteration 79200, lr = 0.001
I1017 23:31:46.219549 22869 solver.cpp:218] Iteration 79300 (3.34526 iter/s, 29.893s/100 iters), loss = 0.007629
I1017 23:31:46.219658 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0076277 (* 1 = 0.0076277 loss)
I1017 23:31:46.219666 22869 sgd_solver.cpp:105] Iteration 79300, lr = 0.001
I1017 23:32:16.118413 22869 solver.cpp:218] Iteration 79400 (3.34462 iter/s, 29.8988s/100 iters), loss = 0.00940944
I1017 23:32:16.118450 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00940814 (* 1 = 0.00940814 loss)
I1017 23:32:16.118458 22869 sgd_solver.cpp:105] Iteration 79400, lr = 0.001
I1017 23:32:45.717469 22869 solver.cpp:330] Iteration 79500, Testing net (#0)
I1017 23:33:01.913842 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 23:33:02.244735 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.12942 (* 1 = 1.12942 loss)
I1017 23:33:02.244751 22869 solver.cpp:397]     Test net output #1: accuracy = 0.7411
I1017 23:33:02.537353 22869 solver.cpp:218] Iteration 79500 (2.15429 iter/s, 46.4189s/100 iters), loss = 0.00528088
I1017 23:33:02.537392 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00527958 (* 1 = 0.00527958 loss)
I1017 23:33:02.537400 22869 sgd_solver.cpp:105] Iteration 79500, lr = 0.001
I1017 23:33:32.421620 22869 solver.cpp:218] Iteration 79600 (3.34625 iter/s, 29.8842s/100 iters), loss = 0.00329769
I1017 23:33:32.421767 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00329639 (* 1 = 0.00329639 loss)
I1017 23:33:32.421777 22869 sgd_solver.cpp:105] Iteration 79600, lr = 0.001
I1017 23:34:02.309891 22869 solver.cpp:218] Iteration 79700 (3.34581 iter/s, 29.8881s/100 iters), loss = 0.00601884
I1017 23:34:02.309943 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00601754 (* 1 = 0.00601754 loss)
I1017 23:34:02.309950 22869 sgd_solver.cpp:105] Iteration 79700, lr = 0.001
I1017 23:34:32.198297 22869 solver.cpp:218] Iteration 79800 (3.34578 iter/s, 29.8884s/100 iters), loss = 0.00547707
I1017 23:34:32.198397 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00547577 (* 1 = 0.00547577 loss)
I1017 23:34:32.198405 22869 sgd_solver.cpp:105] Iteration 79800, lr = 0.001
I1017 23:35:02.071660 22869 solver.cpp:218] Iteration 79900 (3.34748 iter/s, 29.8733s/100 iters), loss = 0.00211771
I1017 23:35:02.071691 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00211641 (* 1 = 0.00211641 loss)
I1017 23:35:02.071696 22869 sgd_solver.cpp:105] Iteration 79900, lr = 0.001
I1017 23:35:30.490747 22877 data_layer.cpp:73] Restarting data prefetching from start.
I1017 23:35:31.690410 22869 solver.cpp:330] Iteration 80000, Testing net (#0)
I1017 23:35:47.876404 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 23:35:48.206279 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.12751 (* 1 = 1.12751 loss)
I1017 23:35:48.206295 22869 solver.cpp:397]     Test net output #1: accuracy = 0.7422
I1017 23:35:48.498607 22869 solver.cpp:218] Iteration 80000 (2.15392 iter/s, 46.4269s/100 iters), loss = 0.00543774
I1017 23:35:48.498638 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00543644 (* 1 = 0.00543644 loss)
I1017 23:35:48.498644 22869 sgd_solver.cpp:46] MultiStep Status: Iteration 80000, step = 2
I1017 23:35:48.498647 22869 sgd_solver.cpp:105] Iteration 80000, lr = 0.0001
I1017 23:36:18.363004 22869 solver.cpp:218] Iteration 80100 (3.34847 iter/s, 29.8644s/100 iters), loss = 0.0101507
I1017 23:36:18.363119 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0101494 (* 1 = 0.0101494 loss)
I1017 23:36:18.363126 22869 sgd_solver.cpp:105] Iteration 80100, lr = 0.0001
I1017 23:36:48.258332 22869 solver.cpp:218] Iteration 80200 (3.34502 iter/s, 29.8952s/100 iters), loss = 0.0045329
I1017 23:36:48.258364 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00453161 (* 1 = 0.00453161 loss)
I1017 23:36:48.258370 22869 sgd_solver.cpp:105] Iteration 80200, lr = 0.0001
I1017 23:37:18.155957 22869 solver.cpp:218] Iteration 80300 (3.34475 iter/s, 29.8976s/100 iters), loss = 0.0069084
I1017 23:37:18.156410 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0069071 (* 1 = 0.0069071 loss)
I1017 23:37:18.156430 22869 sgd_solver.cpp:105] Iteration 80300, lr = 0.0001
I1017 23:37:48.051978 22869 solver.cpp:218] Iteration 80400 (3.34498 iter/s, 29.8956s/100 iters), loss = 0.00769196
I1017 23:37:48.052011 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00769066 (* 1 = 0.00769066 loss)
I1017 23:37:48.052017 22869 sgd_solver.cpp:105] Iteration 80400, lr = 0.0001
I1017 23:38:17.653475 22869 solver.cpp:330] Iteration 80500, Testing net (#0)
I1017 23:38:33.850445 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 23:38:34.183022 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.12741 (* 1 = 1.12741 loss)
I1017 23:38:34.183037 22869 solver.cpp:397]     Test net output #1: accuracy = 0.742
I1017 23:38:34.476640 22869 solver.cpp:218] Iteration 80500 (2.15403 iter/s, 46.4246s/100 iters), loss = 0.00479775
I1017 23:38:34.476676 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00479645 (* 1 = 0.00479645 loss)
I1017 23:38:34.476683 22869 sgd_solver.cpp:105] Iteration 80500, lr = 0.0001
I1017 23:39:04.349505 22869 solver.cpp:218] Iteration 80600 (3.34752 iter/s, 29.8728s/100 iters), loss = 0.00381412
I1017 23:39:04.349614 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00381282 (* 1 = 0.00381282 loss)
I1017 23:39:04.349622 22869 sgd_solver.cpp:105] Iteration 80600, lr = 0.0001
I1017 23:39:34.199038 22869 solver.cpp:218] Iteration 80700 (3.35015 iter/s, 29.8494s/100 iters), loss = 0.00707945
I1017 23:39:34.199070 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00707815 (* 1 = 0.00707815 loss)
I1017 23:39:34.199077 22869 sgd_solver.cpp:105] Iteration 80700, lr = 0.0001
I1017 23:40:04.068197 22869 solver.cpp:218] Iteration 80800 (3.34794 iter/s, 29.8691s/100 iters), loss = 0.00644139
I1017 23:40:04.068342 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00644009 (* 1 = 0.00644009 loss)
I1017 23:40:04.068351 22869 sgd_solver.cpp:105] Iteration 80800, lr = 0.0001
I1017 23:40:33.941610 22869 solver.cpp:218] Iteration 80900 (3.34747 iter/s, 29.8733s/100 iters), loss = 0.00306702
I1017 23:40:33.941642 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00306573 (* 1 = 0.00306573 loss)
I1017 23:40:33.941649 22869 sgd_solver.cpp:105] Iteration 80900, lr = 0.0001
I1017 23:41:02.309762 22877 data_layer.cpp:73] Restarting data prefetching from start.
I1017 23:41:03.506961 22869 solver.cpp:330] Iteration 81000, Testing net (#0)
I1017 23:41:19.702791 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 23:41:20.035429 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.12717 (* 1 = 1.12717 loss)
I1017 23:41:20.035446 22869 solver.cpp:397]     Test net output #1: accuracy = 0.7418
I1017 23:41:20.327837 22869 solver.cpp:218] Iteration 81000 (2.15581 iter/s, 46.3862s/100 iters), loss = 0.00433719
I1017 23:41:20.327869 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00433589 (* 1 = 0.00433589 loss)
I1017 23:41:20.327877 22869 sgd_solver.cpp:105] Iteration 81000, lr = 0.0001
I1017 23:41:50.187012 22869 solver.cpp:218] Iteration 81100 (3.34906 iter/s, 29.8591s/100 iters), loss = 0.00791072
I1017 23:41:50.187155 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00790942 (* 1 = 0.00790942 loss)
I1017 23:41:50.187163 22869 sgd_solver.cpp:105] Iteration 81100, lr = 0.0001
I1017 23:42:20.060519 22869 solver.cpp:218] Iteration 81200 (3.34746 iter/s, 29.8734s/100 iters), loss = 0.00756918
I1017 23:42:20.060550 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00756789 (* 1 = 0.00756789 loss)
I1017 23:42:20.060557 22869 sgd_solver.cpp:105] Iteration 81200, lr = 0.0001
I1017 23:42:49.922217 22869 solver.cpp:218] Iteration 81300 (3.34878 iter/s, 29.8617s/100 iters), loss = 0.00521505
I1017 23:42:49.922363 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00521375 (* 1 = 0.00521375 loss)
I1017 23:42:49.922372 22869 sgd_solver.cpp:105] Iteration 81300, lr = 0.0001
I1017 23:43:19.764525 22869 solver.cpp:218] Iteration 81400 (3.35096 iter/s, 29.8422s/100 iters), loss = 0.00414421
I1017 23:43:19.764559 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00414291 (* 1 = 0.00414291 loss)
I1017 23:43:19.764564 22869 sgd_solver.cpp:105] Iteration 81400, lr = 0.0001
I1017 23:43:49.312870 22869 solver.cpp:330] Iteration 81500, Testing net (#0)
I1017 23:44:05.510316 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 23:44:05.841037 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.12691 (* 1 = 1.12691 loss)
I1017 23:44:05.841055 22869 solver.cpp:397]     Test net output #1: accuracy = 0.7416
I1017 23:44:06.133468 22869 solver.cpp:218] Iteration 81500 (2.15662 iter/s, 46.3689s/100 iters), loss = 0.00719594
I1017 23:44:06.133502 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00719464 (* 1 = 0.00719464 loss)
I1017 23:44:06.133509 22869 sgd_solver.cpp:105] Iteration 81500, lr = 0.0001
I1017 23:44:35.974208 22869 solver.cpp:218] Iteration 81600 (3.35113 iter/s, 29.8407s/100 iters), loss = 0.00348645
I1017 23:44:35.974352 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00348515 (* 1 = 0.00348515 loss)
I1017 23:44:35.974361 22869 sgd_solver.cpp:105] Iteration 81600, lr = 0.0001
I1017 23:45:05.825893 22869 solver.cpp:218] Iteration 81700 (3.34991 iter/s, 29.8515s/100 iters), loss = 0.00390075
I1017 23:45:05.825927 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00389945 (* 1 = 0.00389945 loss)
I1017 23:45:05.825934 22869 sgd_solver.cpp:105] Iteration 81700, lr = 0.0001
I1017 23:45:35.681349 22869 solver.cpp:218] Iteration 81800 (3.34948 iter/s, 29.8554s/100 iters), loss = 0.00623599
I1017 23:45:35.681452 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00623469 (* 1 = 0.00623469 loss)
I1017 23:45:35.681473 22869 sgd_solver.cpp:105] Iteration 81800, lr = 0.0001
I1017 23:46:05.523378 22869 solver.cpp:218] Iteration 81900 (3.35099 iter/s, 29.8419s/100 iters), loss = 0.0052468
I1017 23:46:05.523411 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00524551 (* 1 = 0.00524551 loss)
I1017 23:46:05.523418 22869 sgd_solver.cpp:105] Iteration 81900, lr = 0.0001
I1017 23:46:33.882581 22877 data_layer.cpp:73] Restarting data prefetching from start.
I1017 23:46:35.074461 22869 solver.cpp:330] Iteration 82000, Testing net (#0)
I1017 23:46:51.259472 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 23:46:51.591893 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.12667 (* 1 = 1.12667 loss)
I1017 23:46:51.591910 22869 solver.cpp:397]     Test net output #1: accuracy = 0.7417
I1017 23:46:51.885566 22869 solver.cpp:218] Iteration 82000 (2.15693 iter/s, 46.3622s/100 iters), loss = 0.00321296
I1017 23:46:51.885603 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00321167 (* 1 = 0.00321167 loss)
I1017 23:46:51.885610 22869 sgd_solver.cpp:105] Iteration 82000, lr = 0.0001
I1017 23:47:21.708703 22869 solver.cpp:218] Iteration 82100 (3.35311 iter/s, 29.8231s/100 iters), loss = 0.00823334
I1017 23:47:21.708874 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00823205 (* 1 = 0.00823205 loss)
I1017 23:47:21.708894 22869 sgd_solver.cpp:105] Iteration 82100, lr = 0.0001
I1017 23:47:51.560083 22869 solver.cpp:218] Iteration 82200 (3.34995 iter/s, 29.8512s/100 iters), loss = 0.00373468
I1017 23:47:51.560117 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00373338 (* 1 = 0.00373338 loss)
I1017 23:47:51.560122 22869 sgd_solver.cpp:105] Iteration 82200, lr = 0.0001
I1017 23:48:21.403563 22869 solver.cpp:218] Iteration 82300 (3.35082 iter/s, 29.8434s/100 iters), loss = 0.0060175
I1017 23:48:21.403676 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00601621 (* 1 = 0.00601621 loss)
I1017 23:48:21.403683 22869 sgd_solver.cpp:105] Iteration 82300, lr = 0.0001
I1017 23:48:51.253487 22869 solver.cpp:218] Iteration 82400 (3.3501 iter/s, 29.8498s/100 iters), loss = 0.00580922
I1017 23:48:51.253517 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00580792 (* 1 = 0.00580792 loss)
I1017 23:48:51.253523 22869 sgd_solver.cpp:105] Iteration 82400, lr = 0.0001
I1017 23:49:20.802897 22869 solver.cpp:330] Iteration 82500, Testing net (#0)
I1017 23:49:37.002480 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 23:49:37.333215 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.12647 (* 1 = 1.12647 loss)
I1017 23:49:37.333230 22869 solver.cpp:397]     Test net output #1: accuracy = 0.7414
I1017 23:49:37.627758 22869 solver.cpp:218] Iteration 82500 (2.15637 iter/s, 46.3742s/100 iters), loss = 0.0063507
I1017 23:49:37.627797 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00634941 (* 1 = 0.00634941 loss)
I1017 23:49:37.627805 22869 sgd_solver.cpp:105] Iteration 82500, lr = 0.0001
I1017 23:50:07.471946 22869 solver.cpp:218] Iteration 82600 (3.35074 iter/s, 29.8441s/100 iters), loss = 0.00261493
I1017 23:50:07.472046 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00261364 (* 1 = 0.00261364 loss)
I1017 23:50:07.472069 22869 sgd_solver.cpp:105] Iteration 82600, lr = 0.0001
I1017 23:50:37.316015 22869 solver.cpp:218] Iteration 82700 (3.35076 iter/s, 29.844s/100 iters), loss = 0.00779612
I1017 23:50:37.316045 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00779483 (* 1 = 0.00779483 loss)
I1017 23:50:37.316049 22869 sgd_solver.cpp:105] Iteration 82700, lr = 0.0001
I1017 23:51:07.148030 22869 solver.cpp:218] Iteration 82800 (3.35211 iter/s, 29.832s/100 iters), loss = 0.00365344
I1017 23:51:07.148172 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00365215 (* 1 = 0.00365215 loss)
I1017 23:51:07.148181 22869 sgd_solver.cpp:105] Iteration 82800, lr = 0.0001
I1017 23:51:36.999661 22869 solver.cpp:218] Iteration 82900 (3.34992 iter/s, 29.8515s/100 iters), loss = 0.00388393
I1017 23:51:36.999692 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00388263 (* 1 = 0.00388263 loss)
I1017 23:51:36.999698 22869 sgd_solver.cpp:105] Iteration 82900, lr = 0.0001
I1017 23:52:05.379458 22877 data_layer.cpp:73] Restarting data prefetching from start.
I1017 23:52:06.574483 22869 solver.cpp:330] Iteration 83000, Testing net (#0)
I1017 23:52:22.775270 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 23:52:23.108438 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.12629 (* 1 = 1.12629 loss)
I1017 23:52:23.108454 22869 solver.cpp:397]     Test net output #1: accuracy = 0.7423
I1017 23:52:23.401593 22869 solver.cpp:218] Iteration 83000 (2.15508 iter/s, 46.4019s/100 iters), loss = 0.00370306
I1017 23:52:23.401639 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00370177 (* 1 = 0.00370177 loss)
I1017 23:52:23.401646 22869 sgd_solver.cpp:105] Iteration 83000, lr = 0.0001
I1017 23:52:53.287441 22869 solver.cpp:218] Iteration 83100 (3.34607 iter/s, 29.8858s/100 iters), loss = 0.00549413
I1017 23:52:53.287603 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00549283 (* 1 = 0.00549283 loss)
I1017 23:52:53.287611 22869 sgd_solver.cpp:105] Iteration 83100, lr = 0.0001
I1017 23:53:23.637964 22869 solver.cpp:218] Iteration 83200 (3.29485 iter/s, 30.3504s/100 iters), loss = 0.00495435
I1017 23:53:23.638063 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00495305 (* 1 = 0.00495305 loss)
I1017 23:53:23.638080 22869 sgd_solver.cpp:105] Iteration 83200, lr = 0.0001
I1017 23:53:53.992658 22869 solver.cpp:218] Iteration 83300 (3.29439 iter/s, 30.3546s/100 iters), loss = 0.00397016
I1017 23:53:53.992804 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00396887 (* 1 = 0.00396887 loss)
I1017 23:53:53.992812 22869 sgd_solver.cpp:105] Iteration 83300, lr = 0.0001
I1017 23:54:24.351358 22869 solver.cpp:218] Iteration 83400 (3.29396 iter/s, 30.3586s/100 iters), loss = 0.0057663
I1017 23:54:24.351460 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00576501 (* 1 = 0.00576501 loss)
I1017 23:54:24.351469 22869 sgd_solver.cpp:105] Iteration 83400, lr = 0.0001
I1017 23:54:54.430099 22869 solver.cpp:330] Iteration 83500, Testing net (#0)
I1017 23:55:10.850997 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 23:55:11.186614 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.12609 (* 1 = 1.12609 loss)
I1017 23:55:11.186630 22869 solver.cpp:397]     Test net output #1: accuracy = 0.7422
I1017 23:55:11.485718 22869 solver.cpp:218] Iteration 83500 (2.1216 iter/s, 47.1343s/100 iters), loss = 0.00928694
I1017 23:55:11.485750 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00928564 (* 1 = 0.00928564 loss)
I1017 23:55:11.485757 22869 sgd_solver.cpp:105] Iteration 83500, lr = 0.0001
I1017 23:55:41.822170 22869 solver.cpp:218] Iteration 83600 (3.29637 iter/s, 30.3364s/100 iters), loss = 0.0037531
I1017 23:55:41.822315 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0037518 (* 1 = 0.0037518 loss)
I1017 23:55:41.822324 22869 sgd_solver.cpp:105] Iteration 83600, lr = 0.0001
I1017 23:56:12.161963 22869 solver.cpp:218] Iteration 83700 (3.29602 iter/s, 30.3396s/100 iters), loss = 0.00625272
I1017 23:56:12.162045 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00625143 (* 1 = 0.00625143 loss)
I1017 23:56:12.162061 22869 sgd_solver.cpp:105] Iteration 83700, lr = 0.0001
I1017 23:56:42.520226 22869 solver.cpp:218] Iteration 83800 (3.29401 iter/s, 30.3582s/100 iters), loss = 0.00219971
I1017 23:56:42.520364 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00219842 (* 1 = 0.00219842 loss)
I1017 23:56:42.520370 22869 sgd_solver.cpp:105] Iteration 83800, lr = 0.0001
I1017 23:57:12.884779 22869 solver.cpp:218] Iteration 83900 (3.29333 iter/s, 30.3644s/100 iters), loss = 0.00614637
I1017 23:57:12.884925 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00614508 (* 1 = 0.00614508 loss)
I1017 23:57:12.884934 22869 sgd_solver.cpp:105] Iteration 83900, lr = 0.0001
I1017 23:57:41.729928 22877 data_layer.cpp:73] Restarting data prefetching from start.
I1017 23:57:42.949475 22869 solver.cpp:330] Iteration 84000, Testing net (#0)
I1017 23:57:59.376540 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1017 23:57:59.713238 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.12572 (* 1 = 1.12572 loss)
I1017 23:57:59.713253 22869 solver.cpp:397]     Test net output #1: accuracy = 0.7418
I1017 23:58:00.011541 22869 solver.cpp:218] Iteration 84000 (2.12194 iter/s, 47.1266s/100 iters), loss = 0.00271233
I1017 23:58:00.011575 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00271103 (* 1 = 0.00271103 loss)
I1017 23:58:00.011582 22869 sgd_solver.cpp:105] Iteration 84000, lr = 0.0001
I1017 23:58:30.335716 22869 solver.cpp:218] Iteration 84100 (3.2977 iter/s, 30.3241s/100 iters), loss = 0.00799891
I1017 23:58:30.335877 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00799761 (* 1 = 0.00799761 loss)
I1017 23:58:30.335886 22869 sgd_solver.cpp:105] Iteration 84100, lr = 0.0001
I1017 23:59:00.672272 22869 solver.cpp:218] Iteration 84200 (3.29637 iter/s, 30.3364s/100 iters), loss = 0.00579554
I1017 23:59:00.672374 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00579424 (* 1 = 0.00579424 loss)
I1017 23:59:00.672382 22869 sgd_solver.cpp:105] Iteration 84200, lr = 0.0001
I1017 23:59:31.022609 22869 solver.cpp:218] Iteration 84300 (3.29487 iter/s, 30.3502s/100 iters), loss = 0.0056361
I1017 23:59:31.022722 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0056348 (* 1 = 0.0056348 loss)
I1017 23:59:31.022729 22869 sgd_solver.cpp:105] Iteration 84300, lr = 0.0001
I1018 00:00:01.367056 22869 solver.cpp:218] Iteration 84400 (3.29551 iter/s, 30.3443s/100 iters), loss = 0.00896383
I1018 00:00:01.367190 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00896254 (* 1 = 0.00896254 loss)
I1018 00:00:01.367198 22869 sgd_solver.cpp:105] Iteration 84400, lr = 0.0001
I1018 00:00:31.430908 22869 solver.cpp:330] Iteration 84500, Testing net (#0)
I1018 00:00:47.875511 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1018 00:00:48.211159 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.1254 (* 1 = 1.1254 loss)
I1018 00:00:48.211175 22869 solver.cpp:397]     Test net output #1: accuracy = 0.7419
I1018 00:00:48.510860 22869 solver.cpp:218] Iteration 84500 (2.12118 iter/s, 47.1437s/100 iters), loss = 0.00922186
I1018 00:00:48.510891 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00922057 (* 1 = 0.00922057 loss)
I1018 00:00:48.510898 22869 sgd_solver.cpp:105] Iteration 84500, lr = 0.0001
I1018 00:01:18.837092 22869 solver.cpp:218] Iteration 84600 (3.29748 iter/s, 30.3262s/100 iters), loss = 0.00303205
I1018 00:01:18.837210 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00303075 (* 1 = 0.00303075 loss)
I1018 00:01:18.837229 22869 sgd_solver.cpp:105] Iteration 84600, lr = 0.0001
I1018 00:01:49.176151 22869 solver.cpp:218] Iteration 84700 (3.29609 iter/s, 30.3389s/100 iters), loss = 0.00449501
I1018 00:01:49.176229 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00449372 (* 1 = 0.00449372 loss)
I1018 00:01:49.176249 22869 sgd_solver.cpp:105] Iteration 84700, lr = 0.0001
I1018 00:02:19.496974 22869 solver.cpp:218] Iteration 84800 (3.29807 iter/s, 30.3207s/100 iters), loss = 0.00771142
I1018 00:02:19.497078 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00771013 (* 1 = 0.00771013 loss)
I1018 00:02:19.497097 22869 sgd_solver.cpp:105] Iteration 84800, lr = 0.0001
I1018 00:02:49.819247 22869 solver.cpp:218] Iteration 84900 (3.29792 iter/s, 30.3222s/100 iters), loss = 0.00213851
I1018 00:02:49.819393 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00213721 (* 1 = 0.00213721 loss)
I1018 00:02:49.819402 22869 sgd_solver.cpp:105] Iteration 84900, lr = 0.0001
I1018 00:03:18.632709 22877 data_layer.cpp:73] Restarting data prefetching from start.
I1018 00:03:19.845337 22869 solver.cpp:330] Iteration 85000, Testing net (#0)
I1018 00:03:36.302501 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1018 00:03:36.639865 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.12519 (* 1 = 1.12519 loss)
I1018 00:03:36.639881 22869 solver.cpp:397]     Test net output #1: accuracy = 0.742
I1018 00:03:36.938031 22869 solver.cpp:218] Iteration 85000 (2.1223 iter/s, 47.1186s/100 iters), loss = 0.00335572
I1018 00:03:36.938066 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00335442 (* 1 = 0.00335442 loss)
I1018 00:03:36.938073 22869 sgd_solver.cpp:105] Iteration 85000, lr = 0.0001
I1018 00:04:07.238883 22869 solver.cpp:218] Iteration 85100 (3.30024 iter/s, 30.3008s/100 iters), loss = 0.00525587
I1018 00:04:07.239070 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00525457 (* 1 = 0.00525457 loss)
I1018 00:04:07.239084 22869 sgd_solver.cpp:105] Iteration 85100, lr = 0.0001
I1018 00:04:37.557616 22869 solver.cpp:218] Iteration 85200 (3.29831 iter/s, 30.3186s/100 iters), loss = 0.00272971
I1018 00:04:37.557767 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00272841 (* 1 = 0.00272841 loss)
I1018 00:04:37.557796 22869 sgd_solver.cpp:105] Iteration 85200, lr = 0.0001
I1018 00:05:07.894177 22869 solver.cpp:218] Iteration 85300 (3.29637 iter/s, 30.3364s/100 iters), loss = 0.00435554
I1018 00:05:07.894328 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00435424 (* 1 = 0.00435424 loss)
I1018 00:05:07.894356 22869 sgd_solver.cpp:105] Iteration 85300, lr = 0.0001
I1018 00:05:38.219749 22869 solver.cpp:218] Iteration 85400 (3.29756 iter/s, 30.3254s/100 iters), loss = 0.00620888
I1018 00:05:38.219851 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00620758 (* 1 = 0.00620758 loss)
I1018 00:05:38.219863 22869 sgd_solver.cpp:105] Iteration 85400, lr = 0.0001
I1018 00:06:08.263226 22869 solver.cpp:330] Iteration 85500, Testing net (#0)
I1018 00:06:24.719175 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1018 00:06:25.055631 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.12506 (* 1 = 1.12506 loss)
I1018 00:06:25.055649 22869 solver.cpp:397]     Test net output #1: accuracy = 0.7423
I1018 00:06:25.354456 22869 solver.cpp:218] Iteration 85500 (2.12158 iter/s, 47.1346s/100 iters), loss = 0.0106665
I1018 00:06:25.354495 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0106652 (* 1 = 0.0106652 loss)
I1018 00:06:25.354503 22869 sgd_solver.cpp:105] Iteration 85500, lr = 0.0001
I1018 00:06:55.663763 22869 solver.cpp:218] Iteration 85600 (3.29932 iter/s, 30.3093s/100 iters), loss = 0.00721507
I1018 00:06:55.663862 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00721378 (* 1 = 0.00721378 loss)
I1018 00:06:55.663872 22869 sgd_solver.cpp:105] Iteration 85600, lr = 0.0001
I1018 00:07:25.965129 22869 solver.cpp:218] Iteration 85700 (3.30019 iter/s, 30.3013s/100 iters), loss = 0.00416643
I1018 00:07:25.965229 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00416514 (* 1 = 0.00416514 loss)
I1018 00:07:25.965241 22869 sgd_solver.cpp:105] Iteration 85700, lr = 0.0001
I1018 00:07:56.281663 22869 solver.cpp:218] Iteration 85800 (3.29854 iter/s, 30.3164s/100 iters), loss = 0.00332263
I1018 00:07:56.281779 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00332134 (* 1 = 0.00332134 loss)
I1018 00:07:56.281800 22869 sgd_solver.cpp:105] Iteration 85800, lr = 0.0001
I1018 00:08:26.572875 22869 solver.cpp:218] Iteration 85900 (3.3013 iter/s, 30.2911s/100 iters), loss = 0.00260238
I1018 00:08:26.573019 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00260108 (* 1 = 0.00260108 loss)
I1018 00:08:26.573029 22869 sgd_solver.cpp:105] Iteration 85900, lr = 0.0001
I1018 00:08:55.375250 22877 data_layer.cpp:73] Restarting data prefetching from start.
I1018 00:08:56.586148 22869 solver.cpp:330] Iteration 86000, Testing net (#0)
I1018 00:09:13.002707 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1018 00:09:13.338641 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.12487 (* 1 = 1.12487 loss)
I1018 00:09:13.338673 22869 solver.cpp:397]     Test net output #1: accuracy = 0.7422
I1018 00:09:13.637648 22869 solver.cpp:218] Iteration 86000 (2.12474 iter/s, 47.0646s/100 iters), loss = 0.00225064
I1018 00:09:13.637689 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00224934 (* 1 = 0.00224934 loss)
I1018 00:09:13.637696 22869 sgd_solver.cpp:105] Iteration 86000, lr = 0.0001
I1018 00:09:43.952090 22869 solver.cpp:218] Iteration 86100 (3.29876 iter/s, 30.3144s/100 iters), loss = 0.0086627
I1018 00:09:43.952247 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0086614 (* 1 = 0.0086614 loss)
I1018 00:09:43.952256 22869 sgd_solver.cpp:105] Iteration 86100, lr = 0.0001
I1018 00:10:14.266419 22869 solver.cpp:218] Iteration 86200 (3.29879 iter/s, 30.3142s/100 iters), loss = 0.00808655
I1018 00:10:14.266563 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00808526 (* 1 = 0.00808526 loss)
I1018 00:10:14.266573 22869 sgd_solver.cpp:105] Iteration 86200, lr = 0.0001
I1018 00:10:44.585427 22869 solver.cpp:218] Iteration 86300 (3.29828 iter/s, 30.3188s/100 iters), loss = 0.00694171
I1018 00:10:44.585566 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00694042 (* 1 = 0.00694042 loss)
I1018 00:10:44.585573 22869 sgd_solver.cpp:105] Iteration 86300, lr = 0.0001
I1018 00:11:14.902320 22869 solver.cpp:218] Iteration 86400 (3.29851 iter/s, 30.3167s/100 iters), loss = 0.00828419
I1018 00:11:14.902411 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0082829 (* 1 = 0.0082829 loss)
I1018 00:11:14.902429 22869 sgd_solver.cpp:105] Iteration 86400, lr = 0.0001
I1018 00:11:44.905663 22869 solver.cpp:330] Iteration 86500, Testing net (#0)
I1018 00:12:01.351212 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1018 00:12:01.686122 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.12474 (* 1 = 1.12474 loss)
I1018 00:12:01.686138 22869 solver.cpp:397]     Test net output #1: accuracy = 0.742
I1018 00:12:01.983206 22869 solver.cpp:218] Iteration 86500 (2.12401 iter/s, 47.0808s/100 iters), loss = 0.00943536
I1018 00:12:01.983239 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00943407 (* 1 = 0.00943407 loss)
I1018 00:12:01.983247 22869 sgd_solver.cpp:105] Iteration 86500, lr = 0.0001
I1018 00:12:32.299937 22869 solver.cpp:218] Iteration 86600 (3.29851 iter/s, 30.3167s/100 iters), loss = 0.00252719
I1018 00:12:32.300048 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0025259 (* 1 = 0.0025259 loss)
I1018 00:12:32.300065 22869 sgd_solver.cpp:105] Iteration 86600, lr = 0.0001
I1018 00:13:02.623111 22869 solver.cpp:218] Iteration 86700 (3.29782 iter/s, 30.3231s/100 iters), loss = 0.00465793
I1018 00:13:02.623250 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00465663 (* 1 = 0.00465663 loss)
I1018 00:13:02.623258 22869 sgd_solver.cpp:105] Iteration 86700, lr = 0.0001
I1018 00:13:32.948976 22869 solver.cpp:218] Iteration 86800 (3.29753 iter/s, 30.3257s/100 iters), loss = 0.00957293
I1018 00:13:32.949084 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00957163 (* 1 = 0.00957163 loss)
I1018 00:13:32.949101 22869 sgd_solver.cpp:105] Iteration 86800, lr = 0.0001
I1018 00:14:03.290479 22869 solver.cpp:218] Iteration 86900 (3.29583 iter/s, 30.3414s/100 iters), loss = 0.00311007
I1018 00:14:03.290635 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00310877 (* 1 = 0.00310877 loss)
I1018 00:14:03.290644 22869 sgd_solver.cpp:105] Iteration 86900, lr = 0.0001
I1018 00:14:32.118232 22877 data_layer.cpp:73] Restarting data prefetching from start.
I1018 00:14:33.330936 22869 solver.cpp:330] Iteration 87000, Testing net (#0)
I1018 00:14:49.775367 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1018 00:14:50.113034 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.12449 (* 1 = 1.12449 loss)
I1018 00:14:50.113049 22869 solver.cpp:397]     Test net output #1: accuracy = 0.7421
I1018 00:14:50.410217 22869 solver.cpp:218] Iteration 87000 (2.12226 iter/s, 47.1196s/100 iters), loss = 0.00282951
I1018 00:14:50.410255 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00282821 (* 1 = 0.00282821 loss)
I1018 00:14:50.410264 22869 sgd_solver.cpp:105] Iteration 87000, lr = 0.0001
I1018 00:15:20.766387 22869 solver.cpp:218] Iteration 87100 (3.29423 iter/s, 30.3561s/100 iters), loss = 0.00668461
I1018 00:15:20.766554 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00668331 (* 1 = 0.00668331 loss)
I1018 00:15:20.766564 22869 sgd_solver.cpp:105] Iteration 87100, lr = 0.0001
I1018 00:15:51.100009 22869 solver.cpp:218] Iteration 87200 (3.29669 iter/s, 30.3335s/100 iters), loss = 0.00369309
I1018 00:15:51.100127 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00369179 (* 1 = 0.00369179 loss)
I1018 00:15:51.100136 22869 sgd_solver.cpp:105] Iteration 87200, lr = 0.0001
I1018 00:16:21.469398 22869 solver.cpp:218] Iteration 87300 (3.2928 iter/s, 30.3693s/100 iters), loss = 0.0032311
I1018 00:16:21.469493 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0032298 (* 1 = 0.0032298 loss)
I1018 00:16:21.469509 22869 sgd_solver.cpp:105] Iteration 87300, lr = 0.0001
I1018 00:16:51.803421 22869 solver.cpp:218] Iteration 87400 (3.29664 iter/s, 30.3339s/100 iters), loss = 0.00400273
I1018 00:16:51.803563 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00400143 (* 1 = 0.00400143 loss)
I1018 00:16:51.803582 22869 sgd_solver.cpp:105] Iteration 87400, lr = 0.0001
I1018 00:17:21.855878 22869 solver.cpp:330] Iteration 87500, Testing net (#0)
I1018 00:17:38.294617 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1018 00:17:38.629762 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.12428 (* 1 = 1.12428 loss)
I1018 00:17:38.629781 22869 solver.cpp:397]     Test net output #1: accuracy = 0.7422
I1018 00:17:38.929003 22869 solver.cpp:218] Iteration 87500 (2.122 iter/s, 47.1254s/100 iters), loss = 0.00765654
I1018 00:17:38.929039 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00765524 (* 1 = 0.00765524 loss)
I1018 00:17:38.929047 22869 sgd_solver.cpp:105] Iteration 87500, lr = 0.0001
I1018 00:18:09.266907 22869 solver.cpp:218] Iteration 87600 (3.29621 iter/s, 30.3379s/100 iters), loss = 0.00392785
I1018 00:18:09.267030 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00392655 (* 1 = 0.00392655 loss)
I1018 00:18:09.267037 22869 sgd_solver.cpp:105] Iteration 87600, lr = 0.0001
I1018 00:18:39.587087 22869 solver.cpp:218] Iteration 87700 (3.29815 iter/s, 30.32s/100 iters), loss = 0.00572034
I1018 00:18:39.587155 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00571904 (* 1 = 0.00571904 loss)
I1018 00:18:39.587162 22869 sgd_solver.cpp:105] Iteration 87700, lr = 0.0001
I1018 00:19:09.928369 22869 solver.cpp:218] Iteration 87800 (3.29585 iter/s, 30.3412s/100 iters), loss = 0.00413075
I1018 00:19:09.928472 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00412945 (* 1 = 0.00412945 loss)
I1018 00:19:09.928489 22869 sgd_solver.cpp:105] Iteration 87800, lr = 0.0001
I1018 00:19:40.279772 22869 solver.cpp:218] Iteration 87900 (3.29475 iter/s, 30.3513s/100 iters), loss = 0.00258693
I1018 00:19:40.279917 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00258563 (* 1 = 0.00258563 loss)
I1018 00:19:40.279925 22869 sgd_solver.cpp:105] Iteration 87900, lr = 0.0001
I1018 00:20:09.109016 22877 data_layer.cpp:73] Restarting data prefetching from start.
I1018 00:20:10.319833 22869 solver.cpp:330] Iteration 88000, Testing net (#0)
I1018 00:20:26.734015 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1018 00:20:27.070112 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.12404 (* 1 = 1.12404 loss)
I1018 00:20:27.070127 22869 solver.cpp:397]     Test net output #1: accuracy = 0.7423
I1018 00:20:27.368794 22869 solver.cpp:218] Iteration 88000 (2.12364 iter/s, 47.0889s/100 iters), loss = 0.00488577
I1018 00:20:27.368824 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00488447 (* 1 = 0.00488447 loss)
I1018 00:20:27.368832 22869 sgd_solver.cpp:105] Iteration 88000, lr = 0.0001
I1018 00:20:57.679759 22869 solver.cpp:218] Iteration 88100 (3.29914 iter/s, 30.3109s/100 iters), loss = 0.00463181
I1018 00:20:57.679857 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00463051 (* 1 = 0.00463051 loss)
I1018 00:20:57.679862 22869 sgd_solver.cpp:105] Iteration 88100, lr = 0.0001
I1018 00:21:27.984130 22869 solver.cpp:218] Iteration 88200 (3.29987 iter/s, 30.3043s/100 iters), loss = 0.00568591
I1018 00:21:27.984272 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00568461 (* 1 = 0.00568461 loss)
I1018 00:21:27.984289 22869 sgd_solver.cpp:105] Iteration 88200, lr = 0.0001
I1018 00:21:58.285477 22869 solver.cpp:218] Iteration 88300 (3.3002 iter/s, 30.3012s/100 iters), loss = 0.00422721
I1018 00:21:58.285622 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00422592 (* 1 = 0.00422592 loss)
I1018 00:21:58.285631 22869 sgd_solver.cpp:105] Iteration 88300, lr = 0.0001
I1018 00:22:28.576512 22869 solver.cpp:218] Iteration 88400 (3.30132 iter/s, 30.2909s/100 iters), loss = 0.00870121
I1018 00:22:28.576612 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00869992 (* 1 = 0.00869992 loss)
I1018 00:22:28.576622 22869 sgd_solver.cpp:105] Iteration 88400, lr = 0.0001
I1018 00:22:58.567406 22869 solver.cpp:330] Iteration 88500, Testing net (#0)
I1018 00:23:15.001385 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1018 00:23:15.337282 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.12386 (* 1 = 1.12386 loss)
I1018 00:23:15.337301 22869 solver.cpp:397]     Test net output #1: accuracy = 0.7423
I1018 00:23:15.636404 22869 solver.cpp:218] Iteration 88500 (2.12496 iter/s, 47.0598s/100 iters), loss = 0.00776999
I1018 00:23:15.636437 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00776869 (* 1 = 0.00776869 loss)
I1018 00:23:15.636445 22869 sgd_solver.cpp:105] Iteration 88500, lr = 0.0001
I1018 00:23:45.944310 22869 solver.cpp:218] Iteration 88600 (3.29947 iter/s, 30.3079s/100 iters), loss = 0.00236596
I1018 00:23:45.944414 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00236467 (* 1 = 0.00236467 loss)
I1018 00:23:45.944423 22869 sgd_solver.cpp:105] Iteration 88600, lr = 0.0001
I1018 00:24:16.248855 22869 solver.cpp:218] Iteration 88700 (3.29985 iter/s, 30.3044s/100 iters), loss = 0.00393883
I1018 00:24:16.251236 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00393753 (* 1 = 0.00393753 loss)
I1018 00:24:16.251245 22869 sgd_solver.cpp:105] Iteration 88700, lr = 0.0001
I1018 00:24:46.562397 22869 solver.cpp:218] Iteration 88800 (3.29912 iter/s, 30.3111s/100 iters), loss = 0.00910001
I1018 00:24:46.563103 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00909871 (* 1 = 0.00909871 loss)
I1018 00:24:46.563112 22869 sgd_solver.cpp:105] Iteration 88800, lr = 0.0001
I1018 00:25:16.883498 22869 solver.cpp:218] Iteration 88900 (3.29811 iter/s, 30.3204s/100 iters), loss = 0.00396872
I1018 00:25:16.883626 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00396743 (* 1 = 0.00396743 loss)
I1018 00:25:16.883635 22869 sgd_solver.cpp:105] Iteration 88900, lr = 0.0001
I1018 00:25:45.670961 22877 data_layer.cpp:73] Restarting data prefetching from start.
I1018 00:25:46.882840 22869 solver.cpp:330] Iteration 89000, Testing net (#0)
I1018 00:26:03.337709 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1018 00:26:03.673537 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.12374 (* 1 = 1.12374 loss)
I1018 00:26:03.673552 22869 solver.cpp:397]     Test net output #1: accuracy = 0.7421
I1018 00:26:03.970377 22869 solver.cpp:218] Iteration 89000 (2.12374 iter/s, 47.0867s/100 iters), loss = 0.00778502
I1018 00:26:03.970413 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00778372 (* 1 = 0.00778372 loss)
I1018 00:26:03.970420 22869 sgd_solver.cpp:105] Iteration 89000, lr = 0.0001
I1018 00:26:34.278093 22869 solver.cpp:218] Iteration 89100 (3.2995 iter/s, 30.3077s/100 iters), loss = 0.0058792
I1018 00:26:34.278225 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0058779 (* 1 = 0.0058779 loss)
I1018 00:26:34.278234 22869 sgd_solver.cpp:105] Iteration 89100, lr = 0.0001
I1018 00:27:04.597645 22869 solver.cpp:218] Iteration 89200 (3.29822 iter/s, 30.3194s/100 iters), loss = 0.00626154
I1018 00:27:04.597769 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00626025 (* 1 = 0.00626025 loss)
I1018 00:27:04.597775 22869 sgd_solver.cpp:105] Iteration 89200, lr = 0.0001
I1018 00:27:34.941483 22869 solver.cpp:218] Iteration 89300 (3.29558 iter/s, 30.3437s/100 iters), loss = 0.00812853
I1018 00:27:34.941596 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00812724 (* 1 = 0.00812724 loss)
I1018 00:27:34.941612 22869 sgd_solver.cpp:105] Iteration 89300, lr = 0.0001
I1018 00:28:05.273301 22869 solver.cpp:218] Iteration 89400 (3.29688 iter/s, 30.3317s/100 iters), loss = 0.00481554
I1018 00:28:05.273440 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00481424 (* 1 = 0.00481424 loss)
I1018 00:28:05.273447 22869 sgd_solver.cpp:105] Iteration 89400, lr = 0.0001
I1018 00:28:35.307999 22869 solver.cpp:330] Iteration 89500, Testing net (#0)
I1018 00:28:51.761603 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1018 00:28:52.096632 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.12359 (* 1 = 1.12359 loss)
I1018 00:28:52.096647 22869 solver.cpp:397]     Test net output #1: accuracy = 0.742
I1018 00:28:52.394927 22869 solver.cpp:218] Iteration 89500 (2.12218 iter/s, 47.1215s/100 iters), loss = 0.00647797
I1018 00:28:52.394963 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00647667 (* 1 = 0.00647667 loss)
I1018 00:28:52.394970 22869 sgd_solver.cpp:105] Iteration 89500, lr = 0.0001
I1018 00:29:22.746461 22869 solver.cpp:218] Iteration 89600 (3.29473 iter/s, 30.3515s/100 iters), loss = 0.0040152
I1018 00:29:22.746599 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0040139 (* 1 = 0.0040139 loss)
I1018 00:29:22.746608 22869 sgd_solver.cpp:105] Iteration 89600, lr = 0.0001
I1018 00:29:53.095379 22869 solver.cpp:218] Iteration 89700 (3.29503 iter/s, 30.3488s/100 iters), loss = 0.00399309
I1018 00:29:53.095487 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00399179 (* 1 = 0.00399179 loss)
I1018 00:29:53.095495 22869 sgd_solver.cpp:105] Iteration 89700, lr = 0.0001
I1018 00:30:23.460146 22869 solver.cpp:218] Iteration 89800 (3.2933 iter/s, 30.3647s/100 iters), loss = 0.00447503
I1018 00:30:23.460289 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00447373 (* 1 = 0.00447373 loss)
I1018 00:30:23.460295 22869 sgd_solver.cpp:105] Iteration 89800, lr = 0.0001
I1018 00:30:53.797148 22869 solver.cpp:218] Iteration 89900 (3.29632 iter/s, 30.3368s/100 iters), loss = 0.00279804
I1018 00:30:53.797293 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00279674 (* 1 = 0.00279674 loss)
I1018 00:30:53.797302 22869 sgd_solver.cpp:105] Iteration 89900, lr = 0.0001
I1018 00:31:22.623903 22877 data_layer.cpp:73] Restarting data prefetching from start.
I1018 00:31:23.836541 22869 solver.cpp:330] Iteration 90000, Testing net (#0)
I1018 00:31:40.270915 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1018 00:31:40.606326 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.12334 (* 1 = 1.12334 loss)
I1018 00:31:40.606343 22869 solver.cpp:397]     Test net output #1: accuracy = 0.7421
I1018 00:31:40.903864 22869 solver.cpp:218] Iteration 90000 (2.12285 iter/s, 47.1066s/100 iters), loss = 0.00241583
I1018 00:31:40.903897 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00241453 (* 1 = 0.00241453 loss)
I1018 00:31:40.903903 22869 sgd_solver.cpp:105] Iteration 90000, lr = 0.0001
I1018 00:32:11.207104 22869 solver.cpp:218] Iteration 90100 (3.29998 iter/s, 30.3032s/100 iters), loss = 0.0072987
I1018 00:32:11.207237 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0072974 (* 1 = 0.0072974 loss)
I1018 00:32:11.207247 22869 sgd_solver.cpp:105] Iteration 90100, lr = 0.0001
I1018 00:32:41.523160 22869 solver.cpp:218] Iteration 90200 (3.2986 iter/s, 30.3159s/100 iters), loss = 0.0082411
I1018 00:32:41.523586 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0082398 (* 1 = 0.0082398 loss)
I1018 00:32:41.523594 22869 sgd_solver.cpp:105] Iteration 90200, lr = 0.0001
I1018 00:33:11.817859 22869 solver.cpp:218] Iteration 90300 (3.30095 iter/s, 30.2943s/100 iters), loss = 0.00321355
I1018 00:33:11.817958 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00321225 (* 1 = 0.00321225 loss)
I1018 00:33:11.817975 22869 sgd_solver.cpp:105] Iteration 90300, lr = 0.0001
I1018 00:33:42.121070 22869 solver.cpp:218] Iteration 90400 (3.29999 iter/s, 30.3031s/100 iters), loss = 0.00607564
I1018 00:33:42.121220 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00607434 (* 1 = 0.00607434 loss)
I1018 00:33:42.121238 22869 sgd_solver.cpp:105] Iteration 90400, lr = 0.0001
I1018 00:34:12.132783 22869 solver.cpp:330] Iteration 90500, Testing net (#0)
I1018 00:34:28.540593 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1018 00:34:28.876806 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.1231 (* 1 = 1.1231 loss)
I1018 00:34:28.876823 22869 solver.cpp:397]     Test net output #1: accuracy = 0.7417
I1018 00:34:29.175478 22869 solver.cpp:218] Iteration 90500 (2.12521 iter/s, 47.0542s/100 iters), loss = 0.010357
I1018 00:34:29.175520 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0103557 (* 1 = 0.0103557 loss)
I1018 00:34:29.175528 22869 sgd_solver.cpp:105] Iteration 90500, lr = 0.0001
I1018 00:34:59.477037 22869 solver.cpp:218] Iteration 90600 (3.30017 iter/s, 30.3015s/100 iters), loss = 0.00207703
I1018 00:34:59.477144 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00207574 (* 1 = 0.00207574 loss)
I1018 00:34:59.477151 22869 sgd_solver.cpp:105] Iteration 90600, lr = 0.0001
I1018 00:35:29.771989 22869 solver.cpp:218] Iteration 90700 (3.30089 iter/s, 30.2948s/100 iters), loss = 0.00481749
I1018 00:35:29.772130 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00481619 (* 1 = 0.00481619 loss)
I1018 00:35:29.772137 22869 sgd_solver.cpp:105] Iteration 90700, lr = 0.0001
I1018 00:36:00.064199 22869 solver.cpp:218] Iteration 90800 (3.3012 iter/s, 30.2921s/100 iters), loss = 0.00354223
I1018 00:36:00.064342 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00354094 (* 1 = 0.00354094 loss)
I1018 00:36:00.064350 22869 sgd_solver.cpp:105] Iteration 90800, lr = 0.0001
I1018 00:36:30.382433 22869 solver.cpp:218] Iteration 90900 (3.29836 iter/s, 30.3181s/100 iters), loss = 0.00323629
I1018 00:36:30.382572 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00323499 (* 1 = 0.00323499 loss)
I1018 00:36:30.382580 22869 sgd_solver.cpp:105] Iteration 90900, lr = 0.0001
I1018 00:36:59.178127 22877 data_layer.cpp:73] Restarting data prefetching from start.
I1018 00:37:00.389451 22869 solver.cpp:330] Iteration 91000, Testing net (#0)
I1018 00:37:16.808991 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1018 00:37:17.147748 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.12282 (* 1 = 1.12282 loss)
I1018 00:37:17.147764 22869 solver.cpp:397]     Test net output #1: accuracy = 0.7416
I1018 00:37:17.445920 22869 solver.cpp:218] Iteration 91000 (2.1248 iter/s, 47.0633s/100 iters), loss = 0.00254397
I1018 00:37:17.445951 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00254267 (* 1 = 0.00254267 loss)
I1018 00:37:17.445957 22869 sgd_solver.cpp:105] Iteration 91000, lr = 0.0001
I1018 00:37:47.721470 22869 solver.cpp:218] Iteration 91100 (3.303 iter/s, 30.2755s/100 iters), loss = 0.0055451
I1018 00:37:47.721549 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0055438 (* 1 = 0.0055438 loss)
I1018 00:37:47.721565 22869 sgd_solver.cpp:105] Iteration 91100, lr = 0.0001
I1018 00:38:18.041616 22869 solver.cpp:218] Iteration 91200 (3.29815 iter/s, 30.3201s/100 iters), loss = 0.0097332
I1018 00:38:18.041716 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0097319 (* 1 = 0.0097319 loss)
I1018 00:38:18.041724 22869 sgd_solver.cpp:105] Iteration 91200, lr = 0.0001
I1018 00:38:48.342429 22869 solver.cpp:218] Iteration 91300 (3.30025 iter/s, 30.3007s/100 iters), loss = 0.00380457
I1018 00:38:48.342548 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00380328 (* 1 = 0.00380328 loss)
I1018 00:38:48.342556 22869 sgd_solver.cpp:105] Iteration 91300, lr = 0.0001
I1018 00:39:18.676937 22869 solver.cpp:218] Iteration 91400 (3.29659 iter/s, 30.3344s/100 iters), loss = 0.00472231
I1018 00:39:18.677050 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00472101 (* 1 = 0.00472101 loss)
I1018 00:39:18.677057 22869 sgd_solver.cpp:105] Iteration 91400, lr = 0.0001
I1018 00:39:48.709970 22869 solver.cpp:330] Iteration 91500, Testing net (#0)
I1018 00:40:05.144595 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1018 00:40:05.481587 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.12275 (* 1 = 1.12275 loss)
I1018 00:40:05.481603 22869 solver.cpp:397]     Test net output #1: accuracy = 0.7419
I1018 00:40:05.779245 22869 solver.cpp:218] Iteration 91500 (2.12304 iter/s, 47.1022s/100 iters), loss = 0.00910336
I1018 00:40:05.779284 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00910206 (* 1 = 0.00910206 loss)
I1018 00:40:05.779292 22869 sgd_solver.cpp:105] Iteration 91500, lr = 0.0001
I1018 00:40:36.131047 22869 solver.cpp:218] Iteration 91600 (3.2947 iter/s, 30.3517s/100 iters), loss = 0.0037475
I1018 00:40:36.131191 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0037462 (* 1 = 0.0037462 loss)
I1018 00:40:36.131201 22869 sgd_solver.cpp:105] Iteration 91600, lr = 0.0001
I1018 00:41:06.492684 22869 solver.cpp:218] Iteration 91700 (3.29365 iter/s, 30.3615s/100 iters), loss = 0.00437299
I1018 00:41:06.492792 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0043717 (* 1 = 0.0043717 loss)
I1018 00:41:06.492799 22869 sgd_solver.cpp:105] Iteration 91700, lr = 0.0001
I1018 00:41:36.852123 22869 solver.cpp:218] Iteration 91800 (3.29388 iter/s, 30.3593s/100 iters), loss = 0.0025667
I1018 00:41:36.852267 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0025654 (* 1 = 0.0025654 loss)
I1018 00:41:36.852274 22869 sgd_solver.cpp:105] Iteration 91800, lr = 0.0001
I1018 00:42:07.208451 22869 solver.cpp:218] Iteration 91900 (3.29422 iter/s, 30.3562s/100 iters), loss = 0.00305875
I1018 00:42:07.208592 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00305746 (* 1 = 0.00305746 loss)
I1018 00:42:07.208601 22869 sgd_solver.cpp:105] Iteration 91900, lr = 0.0001
I1018 00:42:36.056936 22877 data_layer.cpp:73] Restarting data prefetching from start.
I1018 00:42:37.272163 22869 solver.cpp:330] Iteration 92000, Testing net (#0)
I1018 00:42:53.689967 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1018 00:42:54.024895 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.12253 (* 1 = 1.12253 loss)
I1018 00:42:54.024912 22869 solver.cpp:397]     Test net output #1: accuracy = 0.7417
I1018 00:42:54.324003 22869 solver.cpp:218] Iteration 92000 (2.12245 iter/s, 47.1154s/100 iters), loss = 0.00317936
I1018 00:42:54.324033 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00317806 (* 1 = 0.00317806 loss)
I1018 00:42:54.324039 22869 sgd_solver.cpp:105] Iteration 92000, lr = 0.0001
I1018 00:43:24.654047 22869 solver.cpp:218] Iteration 92100 (3.29707 iter/s, 30.33s/100 iters), loss = 0.00910215
I1018 00:43:24.654173 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00910086 (* 1 = 0.00910086 loss)
I1018 00:43:24.654181 22869 sgd_solver.cpp:105] Iteration 92100, lr = 0.0001
I1018 00:43:54.984167 22869 solver.cpp:218] Iteration 92200 (3.29707 iter/s, 30.33s/100 iters), loss = 0.00598314
I1018 00:43:54.984275 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00598185 (* 1 = 0.00598185 loss)
I1018 00:43:54.984283 22869 sgd_solver.cpp:105] Iteration 92200, lr = 0.0001
I1018 00:44:25.315582 22869 solver.cpp:218] Iteration 92300 (3.29693 iter/s, 30.3313s/100 iters), loss = 0.00457304
I1018 00:44:25.315757 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00457175 (* 1 = 0.00457175 loss)
I1018 00:44:25.315768 22869 sgd_solver.cpp:105] Iteration 92300, lr = 0.0001
I1018 00:44:55.652106 22869 solver.cpp:218] Iteration 92400 (3.29638 iter/s, 30.3363s/100 iters), loss = 0.00328277
I1018 00:44:55.652220 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00328147 (* 1 = 0.00328147 loss)
I1018 00:44:55.652237 22869 sgd_solver.cpp:105] Iteration 92400, lr = 0.0001
I1018 00:45:25.713731 22869 solver.cpp:330] Iteration 92500, Testing net (#0)
I1018 00:45:42.126284 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1018 00:45:42.462461 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.12245 (* 1 = 1.12245 loss)
I1018 00:45:42.462478 22869 solver.cpp:397]     Test net output #1: accuracy = 0.7422
I1018 00:45:42.763322 22869 solver.cpp:218] Iteration 92500 (2.12264 iter/s, 47.1111s/100 iters), loss = 0.00727137
I1018 00:45:42.763355 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00727008 (* 1 = 0.00727008 loss)
I1018 00:45:42.763361 22869 sgd_solver.cpp:105] Iteration 92500, lr = 0.0001
I1018 00:46:13.054055 22869 solver.cpp:218] Iteration 92600 (3.30135 iter/s, 30.2907s/100 iters), loss = 0.00524751
I1018 00:46:13.054157 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00524622 (* 1 = 0.00524622 loss)
I1018 00:46:13.054175 22869 sgd_solver.cpp:105] Iteration 92600, lr = 0.0001
I1018 00:46:43.364511 22869 solver.cpp:218] Iteration 92700 (3.2992 iter/s, 30.3103s/100 iters), loss = 0.00363091
I1018 00:46:43.364608 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00362961 (* 1 = 0.00362961 loss)
I1018 00:46:43.364615 22869 sgd_solver.cpp:105] Iteration 92700, lr = 0.0001
I1018 00:47:13.676136 22869 solver.cpp:218] Iteration 92800 (3.29908 iter/s, 30.3115s/100 iters), loss = 0.00814803
I1018 00:47:13.676235 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00814674 (* 1 = 0.00814674 loss)
I1018 00:47:13.676242 22869 sgd_solver.cpp:105] Iteration 92800, lr = 0.0001
I1018 00:47:43.996075 22869 solver.cpp:218] Iteration 92900 (3.29817 iter/s, 30.3198s/100 iters), loss = 0.00199757
I1018 00:47:43.996196 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00199627 (* 1 = 0.00199627 loss)
I1018 00:47:43.996206 22869 sgd_solver.cpp:105] Iteration 92900, lr = 0.0001
I1018 00:48:12.799844 22877 data_layer.cpp:73] Restarting data prefetching from start.
I1018 00:48:14.014330 22869 solver.cpp:330] Iteration 93000, Testing net (#0)
I1018 00:48:30.447016 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1018 00:48:30.783413 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.12236 (* 1 = 1.12236 loss)
I1018 00:48:30.783432 22869 solver.cpp:397]     Test net output #1: accuracy = 0.742
I1018 00:48:31.081691 22869 solver.cpp:218] Iteration 93000 (2.1238 iter/s, 47.0855s/100 iters), loss = 0.00507483
I1018 00:48:31.081724 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00507353 (* 1 = 0.00507353 loss)
I1018 00:48:31.081732 22869 sgd_solver.cpp:105] Iteration 93000, lr = 0.0001
I1018 00:49:01.406091 22869 solver.cpp:218] Iteration 93100 (3.29768 iter/s, 30.3244s/100 iters), loss = 0.00580566
I1018 00:49:01.406230 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00580437 (* 1 = 0.00580437 loss)
I1018 00:49:01.406239 22869 sgd_solver.cpp:105] Iteration 93100, lr = 0.0001
I1018 00:49:31.698246 22869 solver.cpp:218] Iteration 93200 (3.3012 iter/s, 30.292s/100 iters), loss = 0.00406474
I1018 00:49:31.698390 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00406345 (* 1 = 0.00406345 loss)
I1018 00:49:31.698400 22869 sgd_solver.cpp:105] Iteration 93200, lr = 0.0001
I1018 00:50:01.999305 22869 solver.cpp:218] Iteration 93300 (3.30023 iter/s, 30.3009s/100 iters), loss = 0.00389482
I1018 00:50:01.999469 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00389353 (* 1 = 0.00389353 loss)
I1018 00:50:01.999492 22869 sgd_solver.cpp:105] Iteration 93300, lr = 0.0001
I1018 00:50:32.330315 22869 solver.cpp:218] Iteration 93400 (3.29697 iter/s, 30.3309s/100 iters), loss = 0.00660954
I1018 00:50:32.330493 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00660825 (* 1 = 0.00660825 loss)
I1018 00:50:32.330503 22869 sgd_solver.cpp:105] Iteration 93400, lr = 0.0001
I1018 00:51:02.361886 22869 solver.cpp:330] Iteration 93500, Testing net (#0)
I1018 00:51:18.794081 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1018 00:51:19.130313 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.122 (* 1 = 1.122 loss)
I1018 00:51:19.130331 22869 solver.cpp:397]     Test net output #1: accuracy = 0.7421
I1018 00:51:19.428426 22869 solver.cpp:218] Iteration 93500 (2.12324 iter/s, 47.0979s/100 iters), loss = 0.00624435
I1018 00:51:19.428460 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00624306 (* 1 = 0.00624306 loss)
I1018 00:51:19.428467 22869 sgd_solver.cpp:105] Iteration 93500, lr = 0.0001
I1018 00:51:49.760114 22869 solver.cpp:218] Iteration 93600 (3.29689 iter/s, 30.3316s/100 iters), loss = 0.00284856
I1018 00:51:49.760221 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00284726 (* 1 = 0.00284726 loss)
I1018 00:51:49.760241 22869 sgd_solver.cpp:105] Iteration 93600, lr = 0.0001
I1018 00:52:20.078840 22869 solver.cpp:218] Iteration 93700 (3.29831 iter/s, 30.3186s/100 iters), loss = 0.00543489
I1018 00:52:20.078984 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0054336 (* 1 = 0.0054336 loss)
I1018 00:52:20.078994 22869 sgd_solver.cpp:105] Iteration 93700, lr = 0.0001
I1018 00:52:50.393750 22869 solver.cpp:218] Iteration 93800 (3.29872 iter/s, 30.3148s/100 iters), loss = 0.00307961
I1018 00:52:50.393862 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00307831 (* 1 = 0.00307831 loss)
I1018 00:52:50.393880 22869 sgd_solver.cpp:105] Iteration 93800, lr = 0.0001
I1018 00:53:20.725508 22869 solver.cpp:218] Iteration 93900 (3.29689 iter/s, 30.3316s/100 iters), loss = 0.00227645
I1018 00:53:20.725654 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00227516 (* 1 = 0.00227516 loss)
I1018 00:53:20.725663 22869 sgd_solver.cpp:105] Iteration 93900, lr = 0.0001
I1018 00:53:49.538605 22877 data_layer.cpp:73] Restarting data prefetching from start.
I1018 00:53:50.755259 22869 solver.cpp:330] Iteration 94000, Testing net (#0)
I1018 00:54:07.204661 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1018 00:54:07.541517 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.12176 (* 1 = 1.12176 loss)
I1018 00:54:07.541532 22869 solver.cpp:397]     Test net output #1: accuracy = 0.7424
I1018 00:54:07.839684 22869 solver.cpp:218] Iteration 94000 (2.12251 iter/s, 47.114s/100 iters), loss = 0.00421946
I1018 00:54:07.839715 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00421817 (* 1 = 0.00421817 loss)
I1018 00:54:07.839720 22869 sgd_solver.cpp:105] Iteration 94000, lr = 0.0001
I1018 00:54:38.163002 22869 solver.cpp:218] Iteration 94100 (3.2978 iter/s, 30.3233s/100 iters), loss = 0.00734164
I1018 00:54:38.163151 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00734034 (* 1 = 0.00734034 loss)
I1018 00:54:38.163161 22869 sgd_solver.cpp:105] Iteration 94100, lr = 0.0001
I1018 00:55:08.500054 22869 solver.cpp:218] Iteration 94200 (3.29632 iter/s, 30.3369s/100 iters), loss = 0.00522878
I1018 00:55:08.500200 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00522749 (* 1 = 0.00522749 loss)
I1018 00:55:08.500219 22869 sgd_solver.cpp:105] Iteration 94200, lr = 0.0001
I1018 00:55:38.815872 22869 solver.cpp:218] Iteration 94300 (3.29863 iter/s, 30.3157s/100 iters), loss = 0.00365552
I1018 00:55:38.816022 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00365423 (* 1 = 0.00365423 loss)
I1018 00:55:38.816031 22869 sgd_solver.cpp:105] Iteration 94300, lr = 0.0001
I1018 00:56:09.123430 22869 solver.cpp:218] Iteration 94400 (3.29952 iter/s, 30.3074s/100 iters), loss = 0.00731879
I1018 00:56:09.123594 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0073175 (* 1 = 0.0073175 loss)
I1018 00:56:09.123602 22869 sgd_solver.cpp:105] Iteration 94400, lr = 0.0001
I1018 00:56:39.126457 22869 solver.cpp:330] Iteration 94500, Testing net (#0)
I1018 00:56:55.561321 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1018 00:56:55.897285 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.12163 (* 1 = 1.12163 loss)
I1018 00:56:55.897300 22869 solver.cpp:397]     Test net output #1: accuracy = 0.7427
I1018 00:56:56.194562 22869 solver.cpp:218] Iteration 94500 (2.12445 iter/s, 47.0709s/100 iters), loss = 0.0052686
I1018 00:56:56.194597 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0052673 (* 1 = 0.0052673 loss)
I1018 00:56:56.194603 22869 sgd_solver.cpp:105] Iteration 94500, lr = 0.0001
I1018 00:57:26.516345 22869 solver.cpp:218] Iteration 94600 (3.29796 iter/s, 30.3217s/100 iters), loss = 0.00286521
I1018 00:57:26.516415 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00286392 (* 1 = 0.00286392 loss)
I1018 00:57:26.516433 22869 sgd_solver.cpp:105] Iteration 94600, lr = 0.0001
I1018 00:57:56.841217 22869 solver.cpp:218] Iteration 94700 (3.29763 iter/s, 30.3248s/100 iters), loss = 0.0047509
I1018 00:57:56.841317 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00474961 (* 1 = 0.00474961 loss)
I1018 00:57:56.841336 22869 sgd_solver.cpp:105] Iteration 94700, lr = 0.0001
I1018 00:58:27.173970 22869 solver.cpp:218] Iteration 94800 (3.29678 iter/s, 30.3326s/100 iters), loss = 0.0027148
I1018 00:58:27.174083 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0027135 (* 1 = 0.0027135 loss)
I1018 00:58:27.174091 22869 sgd_solver.cpp:105] Iteration 94800, lr = 0.0001
I1018 00:58:57.508556 22869 solver.cpp:218] Iteration 94900 (3.29658 iter/s, 30.3345s/100 iters), loss = 0.00282739
I1018 00:58:57.508692 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0028261 (* 1 = 0.0028261 loss)
I1018 00:58:57.508700 22869 sgd_solver.cpp:105] Iteration 94900, lr = 0.0001
I1018 00:59:26.345512 22877 data_layer.cpp:73] Restarting data prefetching from start.
I1018 00:59:27.556915 22869 solver.cpp:330] Iteration 95000, Testing net (#0)
I1018 00:59:43.982131 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1018 00:59:44.317348 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.12154 (* 1 = 1.12154 loss)
I1018 00:59:44.317361 22869 solver.cpp:397]     Test net output #1: accuracy = 0.7426
I1018 00:59:44.616145 22869 solver.cpp:218] Iteration 95000 (2.12281 iter/s, 47.1074s/100 iters), loss = 0.00688596
I1018 00:59:44.616175 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00688467 (* 1 = 0.00688467 loss)
I1018 00:59:44.616181 22869 sgd_solver.cpp:105] Iteration 95000, lr = 0.0001
I1018 01:00:14.930366 22869 solver.cpp:218] Iteration 95100 (3.29879 iter/s, 30.3142s/100 iters), loss = 0.00563388
I1018 01:00:14.930521 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00563258 (* 1 = 0.00563258 loss)
I1018 01:00:14.930542 22869 sgd_solver.cpp:105] Iteration 95100, lr = 0.0001
I1018 01:00:45.278496 22869 solver.cpp:218] Iteration 95200 (3.29511 iter/s, 30.348s/100 iters), loss = 0.00750133
I1018 01:00:45.278636 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00750003 (* 1 = 0.00750003 loss)
I1018 01:00:45.278646 22869 sgd_solver.cpp:105] Iteration 95200, lr = 0.0001
I1018 01:01:15.623659 22869 solver.cpp:218] Iteration 95300 (3.29543 iter/s, 30.345s/100 iters), loss = 0.00587198
I1018 01:01:15.623796 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00587068 (* 1 = 0.00587068 loss)
I1018 01:01:15.623803 22869 sgd_solver.cpp:105] Iteration 95300, lr = 0.0001
I1018 01:01:45.955456 22869 solver.cpp:218] Iteration 95400 (3.29689 iter/s, 30.3316s/100 iters), loss = 0.00549434
I1018 01:01:45.956182 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00549305 (* 1 = 0.00549305 loss)
I1018 01:01:45.956192 22869 sgd_solver.cpp:105] Iteration 95400, lr = 0.0001
I1018 01:02:15.998303 22869 solver.cpp:330] Iteration 95500, Testing net (#0)
I1018 01:02:32.413885 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1018 01:02:32.749730 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.12138 (* 1 = 1.12138 loss)
I1018 01:02:32.749747 22869 solver.cpp:397]     Test net output #1: accuracy = 0.7422
I1018 01:02:33.046746 22869 solver.cpp:218] Iteration 95500 (2.12357 iter/s, 47.0905s/100 iters), loss = 0.00627856
I1018 01:02:33.046785 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00627727 (* 1 = 0.00627727 loss)
I1018 01:02:33.046792 22869 sgd_solver.cpp:105] Iteration 95500, lr = 0.0001
I1018 01:03:03.367907 22869 solver.cpp:218] Iteration 95600 (3.29803 iter/s, 30.3211s/100 iters), loss = 0.00698759
I1018 01:03:03.368044 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0069863 (* 1 = 0.0069863 loss)
I1018 01:03:03.368053 22869 sgd_solver.cpp:105] Iteration 95600, lr = 0.0001
I1018 01:03:33.701333 22869 solver.cpp:218] Iteration 95700 (3.29671 iter/s, 30.3333s/100 iters), loss = 0.00436134
I1018 01:03:33.701473 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00436005 (* 1 = 0.00436005 loss)
I1018 01:03:33.701481 22869 sgd_solver.cpp:105] Iteration 95700, lr = 0.0001
I1018 01:04:04.009094 22869 solver.cpp:218] Iteration 95800 (3.2995 iter/s, 30.3076s/100 iters), loss = 0.00356489
I1018 01:04:04.009232 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0035636 (* 1 = 0.0035636 loss)
I1018 01:04:04.009240 22869 sgd_solver.cpp:105] Iteration 95800, lr = 0.0001
I1018 01:04:34.334133 22869 solver.cpp:218] Iteration 95900 (3.29762 iter/s, 30.3249s/100 iters), loss = 0.00372549
I1018 01:04:34.334277 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0037242 (* 1 = 0.0037242 loss)
I1018 01:04:34.334286 22869 sgd_solver.cpp:105] Iteration 95900, lr = 0.0001
I1018 01:05:03.150845 22877 data_layer.cpp:73] Restarting data prefetching from start.
I1018 01:05:04.364228 22869 solver.cpp:330] Iteration 96000, Testing net (#0)
I1018 01:05:20.774353 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1018 01:05:21.110903 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.12127 (* 1 = 1.12127 loss)
I1018 01:05:21.110918 22869 solver.cpp:397]     Test net output #1: accuracy = 0.7425
I1018 01:05:21.409382 22869 solver.cpp:218] Iteration 96000 (2.12427 iter/s, 47.0751s/100 iters), loss = 0.00874165
I1018 01:05:21.409412 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00874035 (* 1 = 0.00874035 loss)
I1018 01:05:21.409420 22869 sgd_solver.cpp:105] Iteration 96000, lr = 0.0001
I1018 01:05:51.735285 22869 solver.cpp:218] Iteration 96100 (3.29752 iter/s, 30.3259s/100 iters), loss = 0.00823668
I1018 01:05:51.735429 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00823539 (* 1 = 0.00823539 loss)
I1018 01:05:51.735436 22869 sgd_solver.cpp:105] Iteration 96100, lr = 0.0001
I1018 01:06:21.931054 22869 solver.cpp:218] Iteration 96200 (3.31174 iter/s, 30.1956s/100 iters), loss = 0.00883736
I1018 01:06:21.931156 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00883607 (* 1 = 0.00883607 loss)
I1018 01:06:21.931164 22869 sgd_solver.cpp:105] Iteration 96200, lr = 0.0001
I1018 01:06:52.015316 22869 solver.cpp:218] Iteration 96300 (3.32401 iter/s, 30.0841s/100 iters), loss = 0.00515952
I1018 01:06:52.015456 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00515822 (* 1 = 0.00515822 loss)
I1018 01:06:52.015465 22869 sgd_solver.cpp:105] Iteration 96300, lr = 0.0001
I1018 01:07:22.153790 22869 solver.cpp:218] Iteration 96400 (3.31803 iter/s, 30.1383s/100 iters), loss = 0.00511197
I1018 01:07:22.153939 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00511068 (* 1 = 0.00511068 loss)
I1018 01:07:22.153959 22869 sgd_solver.cpp:105] Iteration 96400, lr = 0.0001
I1018 01:07:51.999594 22869 solver.cpp:330] Iteration 96500, Testing net (#0)
I1018 01:08:08.341675 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1018 01:08:08.683990 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.12111 (* 1 = 1.12111 loss)
I1018 01:08:08.684006 22869 solver.cpp:397]     Test net output #1: accuracy = 0.7423
I1018 01:08:08.988924 22869 solver.cpp:218] Iteration 96500 (2.13516 iter/s, 46.835s/100 iters), loss = 0.0036051
I1018 01:08:08.988961 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00360381 (* 1 = 0.00360381 loss)
I1018 01:08:08.988968 22869 sgd_solver.cpp:105] Iteration 96500, lr = 0.0001
I1018 01:08:39.089416 22869 solver.cpp:218] Iteration 96600 (3.32221 iter/s, 30.1004s/100 iters), loss = 0.00492588
I1018 01:08:39.089566 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00492459 (* 1 = 0.00492459 loss)
I1018 01:08:39.089576 22869 sgd_solver.cpp:105] Iteration 96600, lr = 0.0001
I1018 01:09:09.216176 22869 solver.cpp:218] Iteration 96700 (3.31933 iter/s, 30.1266s/100 iters), loss = 0.00346477
I1018 01:09:09.216279 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00346348 (* 1 = 0.00346348 loss)
I1018 01:09:09.216295 22869 sgd_solver.cpp:105] Iteration 96700, lr = 0.0001
I1018 01:09:39.333340 22869 solver.cpp:218] Iteration 96800 (3.32038 iter/s, 30.1171s/100 iters), loss = 0.00666676
I1018 01:09:39.333462 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00666547 (* 1 = 0.00666547 loss)
I1018 01:09:39.333470 22869 sgd_solver.cpp:105] Iteration 96800, lr = 0.0001
I1018 01:10:09.469643 22869 solver.cpp:218] Iteration 96900 (3.31827 iter/s, 30.1362s/100 iters), loss = 0.00253168
I1018 01:10:09.469736 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00253039 (* 1 = 0.00253039 loss)
I1018 01:10:09.469743 22869 sgd_solver.cpp:105] Iteration 96900, lr = 0.0001
I1018 01:10:38.093698 22877 data_layer.cpp:73] Restarting data prefetching from start.
I1018 01:10:39.294512 22869 solver.cpp:330] Iteration 97000, Testing net (#0)
I1018 01:10:55.657961 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1018 01:10:55.992033 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.12083 (* 1 = 1.12083 loss)
I1018 01:10:55.992046 22869 solver.cpp:397]     Test net output #1: accuracy = 0.7427
I1018 01:10:56.286623 22869 solver.cpp:218] Iteration 97000 (2.13598 iter/s, 46.8169s/100 iters), loss = 0.00447891
I1018 01:10:56.286654 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00447762 (* 1 = 0.00447762 loss)
I1018 01:10:56.286660 22869 sgd_solver.cpp:105] Iteration 97000, lr = 0.0001
I1018 01:11:26.434440 22869 solver.cpp:218] Iteration 97100 (3.31699 iter/s, 30.1478s/100 iters), loss = 0.00843935
I1018 01:11:26.434551 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00843805 (* 1 = 0.00843805 loss)
I1018 01:11:26.434559 22869 sgd_solver.cpp:105] Iteration 97100, lr = 0.0001
I1018 01:11:56.544909 22869 solver.cpp:218] Iteration 97200 (3.32112 iter/s, 30.1104s/100 iters), loss = 0.0053348
I1018 01:11:56.545050 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00533351 (* 1 = 0.00533351 loss)
I1018 01:11:56.545058 22869 sgd_solver.cpp:105] Iteration 97200, lr = 0.0001
I1018 01:12:26.685554 22869 solver.cpp:218] Iteration 97300 (3.3178 iter/s, 30.1405s/100 iters), loss = 0.00458822
I1018 01:12:26.685698 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00458692 (* 1 = 0.00458692 loss)
I1018 01:12:26.685706 22869 sgd_solver.cpp:105] Iteration 97300, lr = 0.0001
I1018 01:12:56.828692 22869 solver.cpp:218] Iteration 97400 (3.31752 iter/s, 30.143s/100 iters), loss = 0.00556561
I1018 01:12:56.828800 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00556432 (* 1 = 0.00556432 loss)
I1018 01:12:56.828809 22869 sgd_solver.cpp:105] Iteration 97400, lr = 0.0001
I1018 01:13:26.651617 22869 solver.cpp:330] Iteration 97500, Testing net (#0)
I1018 01:13:43.019645 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1018 01:13:43.352762 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.12071 (* 1 = 1.12071 loss)
I1018 01:13:43.352778 22869 solver.cpp:397]     Test net output #1: accuracy = 0.7424
I1018 01:13:43.649543 22869 solver.cpp:218] Iteration 97500 (2.13581 iter/s, 46.8207s/100 iters), loss = 0.00625537
I1018 01:13:43.649574 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00625408 (* 1 = 0.00625408 loss)
I1018 01:13:43.649580 22869 sgd_solver.cpp:105] Iteration 97500, lr = 0.0001
I1018 01:14:13.838291 22869 solver.cpp:218] Iteration 97600 (3.3125 iter/s, 30.1887s/100 iters), loss = 0.00328153
I1018 01:14:13.838397 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00328023 (* 1 = 0.00328023 loss)
I1018 01:14:13.838403 22869 sgd_solver.cpp:105] Iteration 97600, lr = 0.0001
I1018 01:14:43.985169 22869 solver.cpp:218] Iteration 97700 (3.31711 iter/s, 30.1468s/100 iters), loss = 0.00393818
I1018 01:14:43.985308 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00393689 (* 1 = 0.00393689 loss)
I1018 01:14:43.985317 22869 sgd_solver.cpp:105] Iteration 97700, lr = 0.0001
I1018 01:15:14.124074 22869 solver.cpp:218] Iteration 97800 (3.31799 iter/s, 30.1388s/100 iters), loss = 0.00524279
I1018 01:15:14.124207 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0052415 (* 1 = 0.0052415 loss)
I1018 01:15:14.124217 22869 sgd_solver.cpp:105] Iteration 97800, lr = 0.0001
I1018 01:15:44.270422 22869 solver.cpp:218] Iteration 97900 (3.31717 iter/s, 30.1462s/100 iters), loss = 0.00397386
I1018 01:15:44.270532 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00397257 (* 1 = 0.00397257 loss)
I1018 01:15:44.270539 22869 sgd_solver.cpp:105] Iteration 97900, lr = 0.0001
I1018 01:16:12.918258 22877 data_layer.cpp:73] Restarting data prefetching from start.
I1018 01:16:14.123034 22869 solver.cpp:330] Iteration 98000, Testing net (#0)
I1018 01:16:30.477954 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1018 01:16:30.813511 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.12056 (* 1 = 1.12056 loss)
I1018 01:16:30.813527 22869 solver.cpp:397]     Test net output #1: accuracy = 0.7428
I1018 01:16:31.114078 22869 solver.cpp:218] Iteration 98000 (2.13477 iter/s, 46.8435s/100 iters), loss = 0.00431157
I1018 01:16:31.114109 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00431027 (* 1 = 0.00431027 loss)
I1018 01:16:31.114115 22869 sgd_solver.cpp:105] Iteration 98000, lr = 0.0001
I1018 01:17:01.246124 22869 solver.cpp:218] Iteration 98100 (3.31873 iter/s, 30.132s/100 iters), loss = 0.00583657
I1018 01:17:01.246233 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00583527 (* 1 = 0.00583527 loss)
I1018 01:17:01.246240 22869 sgd_solver.cpp:105] Iteration 98100, lr = 0.0001
I1018 01:17:31.387099 22869 solver.cpp:218] Iteration 98200 (3.31775 iter/s, 30.1409s/100 iters), loss = 0.0028282
I1018 01:17:31.387228 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0028269 (* 1 = 0.0028269 loss)
I1018 01:17:31.387236 22869 sgd_solver.cpp:105] Iteration 98200, lr = 0.0001
I1018 01:18:01.517653 22869 solver.cpp:218] Iteration 98300 (3.31891 iter/s, 30.1304s/100 iters), loss = 0.0046628
I1018 01:18:01.517765 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0046615 (* 1 = 0.0046615 loss)
I1018 01:18:01.517782 22869 sgd_solver.cpp:105] Iteration 98300, lr = 0.0001
I1018 01:18:31.664508 22869 solver.cpp:218] Iteration 98400 (3.31711 iter/s, 30.1467s/100 iters), loss = 0.008036
I1018 01:18:31.664618 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0080347 (* 1 = 0.0080347 loss)
I1018 01:18:31.664635 22869 sgd_solver.cpp:105] Iteration 98400, lr = 0.0001
I1018 01:19:01.536589 22869 solver.cpp:330] Iteration 98500, Testing net (#0)
I1018 01:19:17.951692 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1018 01:19:18.289778 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.12037 (* 1 = 1.12037 loss)
I1018 01:19:18.289796 22869 solver.cpp:397]     Test net output #1: accuracy = 0.7422
I1018 01:19:18.586784 22869 solver.cpp:218] Iteration 98500 (2.13119 iter/s, 46.9222s/100 iters), loss = 0.00954883
I1018 01:19:18.586827 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00954753 (* 1 = 0.00954753 loss)
I1018 01:19:18.586834 22869 sgd_solver.cpp:105] Iteration 98500, lr = 0.0001
I1018 01:19:48.685120 22869 solver.cpp:218] Iteration 98600 (3.32245 iter/s, 30.0983s/100 iters), loss = 0.00551112
I1018 01:19:48.685190 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00550982 (* 1 = 0.00550982 loss)
I1018 01:19:48.685197 22869 sgd_solver.cpp:105] Iteration 98600, lr = 0.0001
I1018 01:20:18.808219 22869 solver.cpp:218] Iteration 98700 (3.31972 iter/s, 30.123s/100 iters), loss = 0.00438861
I1018 01:20:18.808367 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00438732 (* 1 = 0.00438732 loss)
I1018 01:20:18.808377 22869 sgd_solver.cpp:105] Iteration 98700, lr = 0.0001
I1018 01:20:48.968348 22869 solver.cpp:218] Iteration 98800 (3.31565 iter/s, 30.16s/100 iters), loss = 0.00229424
I1018 01:20:48.968461 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00229294 (* 1 = 0.00229294 loss)
I1018 01:20:48.968467 22869 sgd_solver.cpp:105] Iteration 98800, lr = 0.0001
I1018 01:21:19.092974 22869 solver.cpp:218] Iteration 98900 (3.31956 iter/s, 30.1245s/100 iters), loss = 0.00278596
I1018 01:21:19.093087 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00278467 (* 1 = 0.00278467 loss)
I1018 01:21:19.093096 22869 sgd_solver.cpp:105] Iteration 98900, lr = 0.0001
I1018 01:21:47.727427 22877 data_layer.cpp:73] Restarting data prefetching from start.
I1018 01:21:48.931876 22869 solver.cpp:330] Iteration 99000, Testing net (#0)
I1018 01:22:05.321358 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1018 01:22:05.655351 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.12015 (* 1 = 1.12015 loss)
I1018 01:22:05.655369 22869 solver.cpp:397]     Test net output #1: accuracy = 0.7423
I1018 01:22:05.951711 22869 solver.cpp:218] Iteration 99000 (2.13408 iter/s, 46.8586s/100 iters), loss = 0.00730381
I1018 01:22:05.951747 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00730252 (* 1 = 0.00730252 loss)
I1018 01:22:05.951755 22869 sgd_solver.cpp:105] Iteration 99000, lr = 0.0001
I1018 01:22:36.114292 22869 solver.cpp:218] Iteration 99100 (3.31537 iter/s, 30.1625s/100 iters), loss = 0.00568348
I1018 01:22:36.114377 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00568218 (* 1 = 0.00568218 loss)
I1018 01:22:36.114393 22869 sgd_solver.cpp:105] Iteration 99100, lr = 0.0001
I1018 01:23:06.244380 22869 solver.cpp:218] Iteration 99200 (3.31895 iter/s, 30.13s/100 iters), loss = 0.0148269
I1018 01:23:06.244525 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0148256 (* 1 = 0.0148256 loss)
I1018 01:23:06.244534 22869 sgd_solver.cpp:105] Iteration 99200, lr = 0.0001
I1018 01:23:36.404953 22869 solver.cpp:218] Iteration 99300 (3.3156 iter/s, 30.1604s/100 iters), loss = 0.0069294
I1018 01:23:36.405040 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0069281 (* 1 = 0.0069281 loss)
I1018 01:23:36.405064 22869 sgd_solver.cpp:105] Iteration 99300, lr = 0.0001
I1018 01:24:06.534257 22869 solver.cpp:218] Iteration 99400 (3.31904 iter/s, 30.1292s/100 iters), loss = 0.00574342
I1018 01:24:06.535531 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00574212 (* 1 = 0.00574212 loss)
I1018 01:24:06.535539 22869 sgd_solver.cpp:105] Iteration 99400, lr = 0.0001
I1018 01:24:36.401150 22869 solver.cpp:330] Iteration 99500, Testing net (#0)
I1018 01:24:52.831012 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1018 01:24:53.166970 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.12006 (* 1 = 1.12006 loss)
I1018 01:24:53.166987 22869 solver.cpp:397]     Test net output #1: accuracy = 0.7424
I1018 01:24:53.462901 22869 solver.cpp:218] Iteration 99500 (2.13095 iter/s, 46.9274s/100 iters), loss = 0.00729085
I1018 01:24:53.462940 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00728955 (* 1 = 0.00728955 loss)
I1018 01:24:53.462950 22869 sgd_solver.cpp:105] Iteration 99500, lr = 0.0001
I1018 01:25:23.591918 22869 solver.cpp:218] Iteration 99600 (3.31906 iter/s, 30.129s/100 iters), loss = 0.00212006
I1018 01:25:23.592089 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00211875 (* 1 = 0.00211875 loss)
I1018 01:25:23.592099 22869 sgd_solver.cpp:105] Iteration 99600, lr = 0.0001
I1018 01:25:53.747797 22869 solver.cpp:218] Iteration 99700 (3.31612 iter/s, 30.1557s/100 iters), loss = 0.00239828
I1018 01:25:53.747941 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00239698 (* 1 = 0.00239698 loss)
I1018 01:25:53.747949 22869 sgd_solver.cpp:105] Iteration 99700, lr = 0.0001
I1018 01:26:23.920439 22869 solver.cpp:218] Iteration 99800 (3.31428 iter/s, 30.1725s/100 iters), loss = 0.00654638
I1018 01:26:23.920565 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00654508 (* 1 = 0.00654508 loss)
I1018 01:26:23.920572 22869 sgd_solver.cpp:105] Iteration 99800, lr = 0.0001
I1018 01:26:54.008088 22869 solver.cpp:218] Iteration 99900 (3.32364 iter/s, 30.0875s/100 iters), loss = 0.00277086
I1018 01:26:54.008239 22869 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00276956 (* 1 = 0.00276956 loss)
I1018 01:26:54.008247 22869 sgd_solver.cpp:105] Iteration 99900, lr = 0.0001
I1018 01:27:22.703675 22877 data_layer.cpp:73] Restarting data prefetching from start.
I1018 01:27:23.912031 22869 solver.cpp:447] Snapshotting to binary proto file xn/PENLU/snapshot/WRN/WRN_penlu_0.25_2study_nodecay_iter_100000.caffemodel
I1018 01:27:30.868057 22869 sgd_solver.cpp:273] Snapshotting solver state to binary proto file xn/PENLU/snapshot/WRN/WRN_penlu_0.25_2study_nodecay_iter_100000.solverstate
I1018 01:27:31.593057 22869 solver.cpp:310] Iteration 100000, loss = 0.00209729
I1018 01:27:31.593081 22869 solver.cpp:330] Iteration 100000, Testing net (#0)
I1018 01:27:47.596205 22878 data_layer.cpp:73] Restarting data prefetching from start.
I1018 01:27:47.926779 22869 solver.cpp:397]     Test net output #0: SoftmaxWithLoss1 = 1.11971 (* 1 = 1.11971 loss)
I1018 01:27:47.926796 22869 solver.cpp:397]     Test net output #1: accuracy = 0.7419
I1018 01:27:47.926800 22869 solver.cpp:315] Optimization Done.
I1018 01:27:47.926802 22869 caffe.cpp:259] Optimization Done.
