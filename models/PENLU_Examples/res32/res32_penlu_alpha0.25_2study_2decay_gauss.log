I1006 17:36:08.508744  3702 caffe.cpp:218] Using GPUs 0
I1006 17:36:08.559950  3702 caffe.cpp:223] GPU 0: GeForce GTX 1080
I1006 17:36:08.811522  3702 solver.cpp:44] Initializing solver from parameters: 
test_iter: 100
test_interval: 500
base_lr: 0.1
display: 100
max_iter: 100000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0001
snapshot: 100000
snapshot_prefix: "xn/PENLU/snapshot/resnet/res32/res32_penlu_alpha0.25_beta1_etanostudy_2study_2decay_gauss"
solver_mode: GPU
device_id: 0
net: "/home/x306/caffe/xn/PENLU/neural/resnet/res32/res32_penlu_decay_gauss.prototxt"
train_state {
  level: 0
  stage: ""
}
stepvalue: 40000
stepvalue: 80000
I1006 17:36:08.811659  3702 solver.cpp:87] Creating training net from net file: /home/x306/caffe/xn/PENLU/neural/resnet/res32/res32_penlu_decay_gauss.prototxt
I1006 17:36:08.814093  3702 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: /home/x306/caffe/xn/PENLU/neural/resnet/res32/res32_penlu_decay_gauss.prototxt
I1006 17:36:08.814105  3702 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I1006 17:36:08.814267  3702 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer Data1
I1006 17:36:08.814357  3702 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer Accuracy1
I1006 17:36:08.815057  3702 net.cpp:51] Initializing net from parameters: 
name: "resnet_cifar10"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "Data1"
  type: "Data"
  top: "Data1"
  top: "Data2"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 28
    mean_file: "/home/x306/caffe/xn/PENLU/data/cifar10/mean.binaryproto"
  }
  data_param {
    source: "/home/x306/caffe/xn/PENLU/data/cifar10/cifar10_train_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "Convolution1"
  type: "Convolution"
  bottom: "Data1"
  top: "Convolution1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm1"
  type: "BatchNorm"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1"
  type: "Scale"
  bottom: "Convolution1"
  top: "Convolution1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu1"
  type: "PENLU"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution2"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm2"
  type: "BatchNorm"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale2"
  type: "Scale"
  bottom: "Convolution2"
  top: "Convolution2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu2"
  type: "PENLU"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution3"
  type: "Convolution"
  bottom: "Convolution2"
  top: "Convolution3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm3"
  type: "BatchNorm"
  bottom: "Convolution3"
  top: "Convolution3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale3"
  type: "Scale"
  bottom: "Convolution3"
  top: "Convolution3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise1"
  type: "Eltwise"
  bottom: "Convolution1"
  bottom: "Convolution3"
  top: "Eltwise1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu3"
  type: "PENLU"
  bottom: "Eltwise1"
  top: "Eltwise1"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution4"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm4"
  type: "BatchNorm"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale4"
  type: "Scale"
  bottom: "Convolution4"
  top: "Convolution4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu4"
  type: "PENLU"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution5"
  type: "Convolution"
  bottom: "Convolution4"
  top: "Convolution5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm5"
  type: "BatchNorm"
  bottom: "Convolution5"
  top: "Convolution5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale5"
  type: "Scale"
  bottom: "Convolution5"
  top: "Convolution5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise2"
  type: "Eltwise"
  bottom: "Eltwise1"
  bottom: "Convolution5"
  top: "Eltwise2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu5"
  type: "PENLU"
  bottom: "Eltwise2"
  top: "Eltwise2"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution6"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm6"
  type: "BatchNorm"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale6"
  type: "Scale"
  bottom: "Convolution6"
  top: "Convolution6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu6"
  type: "PENLU"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution7"
  type: "Convolution"
  bottom: "Convolution6"
  top: "Convolution7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm7"
  type: "BatchNorm"
  bottom: "Convolution7"
  top: "Convolution7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale7"
  type: "Scale"
  bottom: "Convolution7"
  top: "Convolution7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise3"
  type: "Eltwise"
  bottom: "Eltwise2"
  bottom: "Convolution7"
  top: "Eltwise3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu7"
  type: "PENLU"
  bottom: "Eltwise3"
  top: "Eltwise3"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution8"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm8"
  type: "BatchNorm"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale8"
  type: "Scale"
  bottom: "Convolution8"
  top: "Convolution8"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu8"
  type: "PENLU"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution9"
  type: "Convolution"
  bottom: "Convolution8"
  top: "Convolution9"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm9"
  type: "BatchNorm"
  bottom: "Convolution9"
  top: "Convolution9"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale9"
  type: "Scale"
  bottom: "Convolution9"
  top: "Convolution9"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise4"
  type: "Eltwise"
  bottom: "Eltwise3"
  bottom: "Convolution9"
  top: "Eltwise4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu9"
  type: "PENLU"
  bottom: "Eltwise4"
  top: "Eltwise4"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution10"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution10"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm10"
  type: "BatchNorm"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale10"
  type: "Scale"
  bottom: "Convolution10"
  top: "Convolution10"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu10"
  type: "PENLU"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution11"
  type: "Convolution"
  bottom: "Convolution10"
  top: "Convolution11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm11"
  type: "BatchNorm"
  bottom: "Convolution11"
  top: "Convolution11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale11"
  type: "Scale"
  bottom: "Convolution11"
  top: "Convolution11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise5"
  type: "Eltwise"
  bottom: "Eltwise4"
  bottom: "Convolution11"
  top: "Eltwise5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu11"
  type: "PENLU"
  bottom: "Eltwise5"
  top: "Eltwise5"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution12"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.25
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm12"
  type: "BatchNorm"
  bottom: "Convolution12"
  top: "Convolution12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale12"
  type: "Scale"
  bottom: "Convolution12"
  top: "Convolution12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution13"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution13"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm13"
  type: "BatchNorm"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale13"
  type: "Scale"
  bottom: "Convolution13"
  top: "Convolution13"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu12"
  type: "PENLU"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution14"
  type: "Convolution"
  bottom: "Convolution13"
  top: "Convolution14"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm14"
  type: "BatchNorm"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale14"
  type: "Scale"
  bottom: "Convolution14"
  top: "Convolution14"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise6"
  type: "Eltwise"
  bottom: "Convolution12"
  bottom: "Convolution14"
  top: "Eltwise6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu13"
  type: "PENLU"
  bottom: "Eltwise6"
  top: "Eltwise6"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution15"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution15"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm15"
  type: "BatchNorm"
  bottom: "Convolution15"
  top: "Convolution15"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale15"
  type: "Scale"
  bottom: "Convolution15"
  top: "Convolution15"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu14"
  type: "PENLU"
  bottom: "Convolution15"
  top: "Convolution15"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution16"
  type: "Convolution"
  bottom: "Convolution15"
  top: "Convolution16"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm16"
  type: "BatchNorm"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale16"
  type: "Scale"
  bottom: "Convolution16"
  top: "Convolution16"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise7"
  type: "Eltwise"
  bottom: "Eltwise6"
  bottom: "Convolution16"
  top: "Eltwise7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu15"
  type: "PENLU"
  bottom: "Eltwise7"
  top: "Eltwise7"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution17"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution17"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm17"
  type: "BatchNorm"
  bottom: "Convolution17"
  top: "Convolution17"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale17"
  type: "Scale"
  bottom: "Convolution17"
  top: "Convolution17"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu16"
  type: "PENLU"
  bottom: "Convolution17"
  top: "Convolution17"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution18"
  type: "Convolution"
  bottom: "Convolution17"
  top: "Convolution18"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm18"
  type: "BatchNorm"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale18"
  type: "Scale"
  bottom: "Convolution18"
  top: "Convolution18"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise8"
  type: "Eltwise"
  bottom: "Eltwise7"
  bottom: "Convolution18"
  top: "Eltwise8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu17"
  type: "PENLU"
  bottom: "Eltwise8"
  top: "Eltwise8"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution19"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution19"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm19"
  type: "BatchNorm"
  bottom: "Convolution19"
  top: "Convolution19"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale19"
  type: "Scale"
  bottom: "Convolution19"
  top: "Convolution19"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu18"
  type: "PENLU"
  bottom: "Convolution19"
  top: "Convolution19"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution20"
  type: "Convolution"
  bottom: "Convolution19"
  top: "Convolution20"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm20"
  type: "BatchNorm"
  bottom: "Convolution20"
  top: "Convolution20"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale20"
  type: "Scale"
  bottom: "Convolution20"
  top: "Convolution20"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise9"
  type: "Eltwise"
  bottom: "Eltwise8"
  bottom: "Convolution20"
  top: "Eltwise9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu19"
  type: "PENLU"
  bottom: "Eltwise9"
  top: "Eltwise9"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution21"
  type: "Convolution"
  bottom: "Eltwise9"
  top: "Convolution21"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm21"
  type: "BatchNorm"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale21"
  type: "Scale"
  bottom: "Convolution21"
  top: "Convolution21"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu20"
  type: "PENLU"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution22"
  type: "Convolution"
  bottom: "Convolution21"
  top: "Convolution22"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm22"
  type: "BatchNorm"
  bottom: "Convolution22"
  top: "Convolution22"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale22"
  type: "Scale"
  bottom: "Convolution22"
  top: "Convolution22"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise10"
  type: "Eltwise"
  bottom: "Eltwise9"
  bottom: "Convolution22"
  top: "Eltwise10"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu21"
  type: "PENLU"
  bottom: "Eltwise10"
  top: "Eltwise10"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution23"
  type: "Convolution"
  bottom: "Eltwise10"
  top: "Convolution23"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.17677669
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm23"
  type: "BatchNorm"
  bottom: "Convolution23"
  top: "Convolution23"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale23"
  type: "Scale"
  bottom: "Convolution23"
  top: "Convolution23"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution24"
  type: "Convolution"
  bottom: "Eltwise10"
  top: "Convolution24"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm24"
  type: "BatchNorm"
  bottom: "Convolution24"
  top: "Convolution24"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale24"
  type: "Scale"
  bottom: 
I1006 17:36:08.815500  3702 layer_factory.hpp:77] Creating layer Data1
I1006 17:36:08.815575  3702 db_lmdb.cpp:35] Opened lmdb /home/x306/caffe/xn/PENLU/data/cifar10/cifar10_train_lmdb
I1006 17:36:08.815594  3702 net.cpp:84] Creating Layer Data1
I1006 17:36:08.815599  3702 net.cpp:380] Data1 -> Data1
I1006 17:36:08.815618  3702 net.cpp:380] Data1 -> Data2
I1006 17:36:08.815625  3702 data_transformer.cpp:25] Loading mean file from: /home/x306/caffe/xn/PENLU/data/cifar10/mean.binaryproto
I1006 17:36:08.817018  3702 data_layer.cpp:45] output data size: 100,3,28,28
I1006 17:36:08.819252  3702 net.cpp:122] Setting up Data1
I1006 17:36:08.819264  3702 net.cpp:129] Top shape: 100 3 28 28 (235200)
I1006 17:36:08.819268  3702 net.cpp:129] Top shape: 100 (100)
I1006 17:36:08.819270  3702 net.cpp:137] Memory required for data: 941200
I1006 17:36:08.819277  3702 layer_factory.hpp:77] Creating layer Convolution1
I1006 17:36:08.819294  3702 net.cpp:84] Creating Layer Convolution1
I1006 17:36:08.819298  3702 net.cpp:406] Convolution1 <- Data1
I1006 17:36:08.819308  3702 net.cpp:380] Convolution1 -> Convolution1
I1006 17:36:08.965800  3702 net.cpp:122] Setting up Convolution1
I1006 17:36:08.965836  3702 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 17:36:08.965839  3702 net.cpp:137] Memory required for data: 5958800
I1006 17:36:08.965863  3702 layer_factory.hpp:77] Creating layer BatchNorm1
I1006 17:36:08.965878  3702 net.cpp:84] Creating Layer BatchNorm1
I1006 17:36:08.965903  3702 net.cpp:406] BatchNorm1 <- Convolution1
I1006 17:36:08.965916  3702 net.cpp:367] BatchNorm1 -> Convolution1 (in-place)
I1006 17:36:08.966080  3702 net.cpp:122] Setting up BatchNorm1
I1006 17:36:08.966086  3702 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 17:36:08.966099  3702 net.cpp:137] Memory required for data: 10976400
I1006 17:36:08.966106  3702 layer_factory.hpp:77] Creating layer Scale1
I1006 17:36:08.966125  3702 net.cpp:84] Creating Layer Scale1
I1006 17:36:08.966128  3702 net.cpp:406] Scale1 <- Convolution1
I1006 17:36:08.966131  3702 net.cpp:367] Scale1 -> Convolution1 (in-place)
I1006 17:36:08.966179  3702 layer_factory.hpp:77] Creating layer Scale1
I1006 17:36:08.966300  3702 net.cpp:122] Setting up Scale1
I1006 17:36:08.966305  3702 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 17:36:08.966308  3702 net.cpp:137] Memory required for data: 15994000
I1006 17:36:08.966312  3702 layer_factory.hpp:77] Creating layer penlu1
I1006 17:36:08.966321  3702 net.cpp:84] Creating Layer penlu1
I1006 17:36:08.966323  3702 net.cpp:406] penlu1 <- Convolution1
I1006 17:36:08.966336  3702 net.cpp:367] penlu1 -> Convolution1 (in-place)
I1006 17:36:08.966964  3702 net.cpp:122] Setting up penlu1
I1006 17:36:08.966974  3702 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 17:36:08.966976  3702 net.cpp:137] Memory required for data: 21011600
I1006 17:36:08.966982  3702 layer_factory.hpp:77] Creating layer Convolution1_penlu1_0_split
I1006 17:36:08.966989  3702 net.cpp:84] Creating Layer Convolution1_penlu1_0_split
I1006 17:36:08.966990  3702 net.cpp:406] Convolution1_penlu1_0_split <- Convolution1
I1006 17:36:08.967003  3702 net.cpp:380] Convolution1_penlu1_0_split -> Convolution1_penlu1_0_split_0
I1006 17:36:08.967010  3702 net.cpp:380] Convolution1_penlu1_0_split -> Convolution1_penlu1_0_split_1
I1006 17:36:08.967046  3702 net.cpp:122] Setting up Convolution1_penlu1_0_split
I1006 17:36:08.967061  3702 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 17:36:08.967063  3702 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 17:36:08.967075  3702 net.cpp:137] Memory required for data: 31046800
I1006 17:36:08.967078  3702 layer_factory.hpp:77] Creating layer Convolution2
I1006 17:36:08.967095  3702 net.cpp:84] Creating Layer Convolution2
I1006 17:36:08.967098  3702 net.cpp:406] Convolution2 <- Convolution1_penlu1_0_split_0
I1006 17:36:08.967114  3702 net.cpp:380] Convolution2 -> Convolution2
I1006 17:36:08.968003  3702 net.cpp:122] Setting up Convolution2
I1006 17:36:08.968013  3702 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 17:36:08.968015  3702 net.cpp:137] Memory required for data: 36064400
I1006 17:36:08.968019  3702 layer_factory.hpp:77] Creating layer BatchNorm2
I1006 17:36:08.968024  3702 net.cpp:84] Creating Layer BatchNorm2
I1006 17:36:08.968027  3702 net.cpp:406] BatchNorm2 <- Convolution2
I1006 17:36:08.968031  3702 net.cpp:367] BatchNorm2 -> Convolution2 (in-place)
I1006 17:36:08.968186  3702 net.cpp:122] Setting up BatchNorm2
I1006 17:36:08.968191  3702 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 17:36:08.968194  3702 net.cpp:137] Memory required for data: 41082000
I1006 17:36:08.968199  3702 layer_factory.hpp:77] Creating layer Scale2
I1006 17:36:08.968204  3702 net.cpp:84] Creating Layer Scale2
I1006 17:36:08.968205  3702 net.cpp:406] Scale2 <- Convolution2
I1006 17:36:08.968209  3702 net.cpp:367] Scale2 -> Convolution2 (in-place)
I1006 17:36:08.968268  3702 layer_factory.hpp:77] Creating layer Scale2
I1006 17:36:08.968387  3702 net.cpp:122] Setting up Scale2
I1006 17:36:08.968392  3702 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 17:36:08.968394  3702 net.cpp:137] Memory required for data: 46099600
I1006 17:36:08.968400  3702 layer_factory.hpp:77] Creating layer penlu2
I1006 17:36:08.968405  3702 net.cpp:84] Creating Layer penlu2
I1006 17:36:08.968408  3702 net.cpp:406] penlu2 <- Convolution2
I1006 17:36:08.968421  3702 net.cpp:367] penlu2 -> Convolution2 (in-place)
I1006 17:36:08.968549  3702 net.cpp:122] Setting up penlu2
I1006 17:36:08.968561  3702 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 17:36:08.968564  3702 net.cpp:137] Memory required for data: 51117200
I1006 17:36:08.968569  3702 layer_factory.hpp:77] Creating layer Convolution3
I1006 17:36:08.968576  3702 net.cpp:84] Creating Layer Convolution3
I1006 17:36:08.968578  3702 net.cpp:406] Convolution3 <- Convolution2
I1006 17:36:08.968592  3702 net.cpp:380] Convolution3 -> Convolution3
I1006 17:36:08.969450  3702 net.cpp:122] Setting up Convolution3
I1006 17:36:08.969460  3702 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 17:36:08.969463  3702 net.cpp:137] Memory required for data: 56134800
I1006 17:36:08.969467  3702 layer_factory.hpp:77] Creating layer BatchNorm3
I1006 17:36:08.969473  3702 net.cpp:84] Creating Layer BatchNorm3
I1006 17:36:08.969475  3702 net.cpp:406] BatchNorm3 <- Convolution3
I1006 17:36:08.969489  3702 net.cpp:367] BatchNorm3 -> Convolution3 (in-place)
I1006 17:36:08.969620  3702 net.cpp:122] Setting up BatchNorm3
I1006 17:36:08.969625  3702 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 17:36:08.969627  3702 net.cpp:137] Memory required for data: 61152400
I1006 17:36:08.969633  3702 layer_factory.hpp:77] Creating layer Scale3
I1006 17:36:08.969637  3702 net.cpp:84] Creating Layer Scale3
I1006 17:36:08.969640  3702 net.cpp:406] Scale3 <- Convolution3
I1006 17:36:08.969642  3702 net.cpp:367] Scale3 -> Convolution3 (in-place)
I1006 17:36:08.969686  3702 layer_factory.hpp:77] Creating layer Scale3
I1006 17:36:08.969779  3702 net.cpp:122] Setting up Scale3
I1006 17:36:08.969784  3702 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 17:36:08.969785  3702 net.cpp:137] Memory required for data: 66170000
I1006 17:36:08.969789  3702 layer_factory.hpp:77] Creating layer Eltwise1
I1006 17:36:08.969794  3702 net.cpp:84] Creating Layer Eltwise1
I1006 17:36:08.969796  3702 net.cpp:406] Eltwise1 <- Convolution1_penlu1_0_split_1
I1006 17:36:08.969799  3702 net.cpp:406] Eltwise1 <- Convolution3
I1006 17:36:08.969812  3702 net.cpp:380] Eltwise1 -> Eltwise1
I1006 17:36:08.969830  3702 net.cpp:122] Setting up Eltwise1
I1006 17:36:08.969842  3702 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 17:36:08.969844  3702 net.cpp:137] Memory required for data: 71187600
I1006 17:36:08.969846  3702 layer_factory.hpp:77] Creating layer penlu3
I1006 17:36:08.969852  3702 net.cpp:84] Creating Layer penlu3
I1006 17:36:08.969854  3702 net.cpp:406] penlu3 <- Eltwise1
I1006 17:36:08.969857  3702 net.cpp:367] penlu3 -> Eltwise1 (in-place)
I1006 17:36:08.969974  3702 net.cpp:122] Setting up penlu3
I1006 17:36:08.969979  3702 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 17:36:08.969980  3702 net.cpp:137] Memory required for data: 76205200
I1006 17:36:08.969985  3702 layer_factory.hpp:77] Creating layer Eltwise1_penlu3_0_split
I1006 17:36:08.969988  3702 net.cpp:84] Creating Layer Eltwise1_penlu3_0_split
I1006 17:36:08.969990  3702 net.cpp:406] Eltwise1_penlu3_0_split <- Eltwise1
I1006 17:36:08.969995  3702 net.cpp:380] Eltwise1_penlu3_0_split -> Eltwise1_penlu3_0_split_0
I1006 17:36:08.970008  3702 net.cpp:380] Eltwise1_penlu3_0_split -> Eltwise1_penlu3_0_split_1
I1006 17:36:08.970038  3702 net.cpp:122] Setting up Eltwise1_penlu3_0_split
I1006 17:36:08.970043  3702 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 17:36:08.970046  3702 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 17:36:08.970047  3702 net.cpp:137] Memory required for data: 86240400
I1006 17:36:08.970049  3702 layer_factory.hpp:77] Creating layer Convolution4
I1006 17:36:08.970057  3702 net.cpp:84] Creating Layer Convolution4
I1006 17:36:08.970059  3702 net.cpp:406] Convolution4 <- Eltwise1_penlu3_0_split_0
I1006 17:36:08.970073  3702 net.cpp:380] Convolution4 -> Convolution4
I1006 17:36:08.970927  3702 net.cpp:122] Setting up Convolution4
I1006 17:36:08.970937  3702 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 17:36:08.970939  3702 net.cpp:137] Memory required for data: 91258000
I1006 17:36:08.970943  3702 layer_factory.hpp:77] Creating layer BatchNorm4
I1006 17:36:08.970960  3702 net.cpp:84] Creating Layer BatchNorm4
I1006 17:36:08.970970  3702 net.cpp:406] BatchNorm4 <- Convolution4
I1006 17:36:08.970984  3702 net.cpp:367] BatchNorm4 -> Convolution4 (in-place)
I1006 17:36:08.971124  3702 net.cpp:122] Setting up BatchNorm4
I1006 17:36:08.971129  3702 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 17:36:08.971132  3702 net.cpp:137] Memory required for data: 96275600
I1006 17:36:08.971140  3702 layer_factory.hpp:77] Creating layer Scale4
I1006 17:36:08.971144  3702 net.cpp:84] Creating Layer Scale4
I1006 17:36:08.971146  3702 net.cpp:406] Scale4 <- Convolution4
I1006 17:36:08.971160  3702 net.cpp:367] Scale4 -> Convolution4 (in-place)
I1006 17:36:08.971200  3702 layer_factory.hpp:77] Creating layer Scale4
I1006 17:36:08.971295  3702 net.cpp:122] Setting up Scale4
I1006 17:36:08.971300  3702 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 17:36:08.971302  3702 net.cpp:137] Memory required for data: 101293200
I1006 17:36:08.971307  3702 layer_factory.hpp:77] Creating layer penlu4
I1006 17:36:08.971312  3702 net.cpp:84] Creating Layer penlu4
I1006 17:36:08.971325  3702 net.cpp:406] penlu4 <- Convolution4
I1006 17:36:08.971329  3702 net.cpp:367] penlu4 -> Convolution4 (in-place)
I1006 17:36:08.971456  3702 net.cpp:122] Setting up penlu4
I1006 17:36:08.971460  3702 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 17:36:08.971462  3702 net.cpp:137] Memory required for data: 106310800
I1006 17:36:08.971467  3702 layer_factory.hpp:77] Creating layer Convolution5
I1006 17:36:08.971472  3702 net.cpp:84] Creating Layer Convolution5
I1006 17:36:08.971489  3702 net.cpp:406] Convolution5 <- Convolution4
I1006 17:36:08.971493  3702 net.cpp:380] Convolution5 -> Convolution5
I1006 17:36:08.972373  3702 net.cpp:122] Setting up Convolution5
I1006 17:36:08.972383  3702 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 17:36:08.972385  3702 net.cpp:137] Memory required for data: 111328400
I1006 17:36:08.972390  3702 layer_factory.hpp:77] Creating layer BatchNorm5
I1006 17:36:08.972394  3702 net.cpp:84] Creating Layer BatchNorm5
I1006 17:36:08.972407  3702 net.cpp:406] BatchNorm5 <- Convolution5
I1006 17:36:08.972412  3702 net.cpp:367] BatchNorm5 -> Convolution5 (in-place)
I1006 17:36:08.972549  3702 net.cpp:122] Setting up BatchNorm5
I1006 17:36:08.972554  3702 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 17:36:08.972556  3702 net.cpp:137] Memory required for data: 116346000
I1006 17:36:08.972561  3702 layer_factory.hpp:77] Creating layer Scale5
I1006 17:36:08.972565  3702 net.cpp:84] Creating Layer Scale5
I1006 17:36:08.972568  3702 net.cpp:406] Scale5 <- Convolution5
I1006 17:36:08.972581  3702 net.cpp:367] Scale5 -> Convolution5 (in-place)
I1006 17:36:08.972625  3702 layer_factory.hpp:77] Creating layer Scale5
I1006 17:36:08.972728  3702 net.cpp:122] Setting up Scale5
I1006 17:36:08.972733  3702 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 17:36:08.972735  3702 net.cpp:137] Memory required for data: 121363600
I1006 17:36:08.972749  3702 layer_factory.hpp:77] Creating layer Eltwise2
I1006 17:36:08.972754  3702 net.cpp:84] Creating Layer Eltwise2
I1006 17:36:08.972757  3702 net.cpp:406] Eltwise2 <- Eltwise1_penlu3_0_split_1
I1006 17:36:08.972759  3702 net.cpp:406] Eltwise2 <- Convolution5
I1006 17:36:08.972764  3702 net.cpp:380] Eltwise2 -> Eltwise2
I1006 17:36:08.972779  3702 net.cpp:122] Setting up Eltwise2
I1006 17:36:08.972784  3702 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 17:36:08.972786  3702 net.cpp:137] Memory required for data: 126381200
I1006 17:36:08.972790  3702 layer_factory.hpp:77] Creating layer penlu5
I1006 17:36:08.972795  3702 net.cpp:84] Creating Layer penlu5
I1006 17:36:08.972797  3702 net.cpp:406] penlu5 <- Eltwise2
I1006 17:36:08.972801  3702 net.cpp:367] penlu5 -> Eltwise2 (in-place)
I1006 17:36:08.972905  3702 net.cpp:122] Setting up penlu5
I1006 17:36:08.972910  3702 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 17:36:08.972913  3702 net.cpp:137] Memory required for data: 131398800
I1006 17:36:08.972918  3702 layer_factory.hpp:77] Creating layer Eltwise2_penlu5_0_split
I1006 17:36:08.972929  3702 net.cpp:84] Creating Layer Eltwise2_penlu5_0_split
I1006 17:36:08.972932  3702 net.cpp:406] Eltwise2_penlu5_0_split <- Eltwise2
I1006 17:36:08.972935  3702 net.cpp:380] Eltwise2_penlu5_0_split -> Eltwise2_penlu5_0_split_0
I1006 17:36:08.972940  3702 net.cpp:380] Eltwise2_penlu5_0_split -> Eltwise2_penlu5_0_split_1
I1006 17:36:08.972965  3702 net.cpp:122] Setting up Eltwise2_penlu5_0_split
I1006 17:36:08.972968  3702 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 17:36:08.972972  3702 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 17:36:08.972975  3702 net.cpp:137] Memory required for data: 141434000
I1006 17:36:08.972977  3702 layer_factory.hpp:77] Creating layer Convolution6
I1006 17:36:08.972983  3702 net.cpp:84] Creating Layer Convolution6
I1006 17:36:08.972986  3702 net.cpp:406] Convolution6 <- Eltwise2_penlu5_0_split_0
I1006 17:36:08.972991  3702 net.cpp:380] Convolution6 -> Convolution6
I1006 17:36:08.973866  3702 net.cpp:122] Setting up Convolution6
I1006 17:36:08.973876  3702 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 17:36:08.973881  3702 net.cpp:137] Memory required for data: 146451600
I1006 17:36:08.973884  3702 layer_factory.hpp:77] Creating layer BatchNorm6
I1006 17:36:08.973891  3702 net.cpp:84] Creating Layer BatchNorm6
I1006 17:36:08.973894  3702 net.cpp:406] BatchNorm6 <- Convolution6
I1006 17:36:08.973897  3702 net.cpp:367] BatchNorm6 -> Convolution6 (in-place)
I1006 17:36:08.974028  3702 net.cpp:122] Setting up BatchNorm6
I1006 17:36:08.974033  3702 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 17:36:08.974036  3702 net.cpp:137] Memory required for data: 151469200
I1006 17:36:08.974041  3702 layer_factory.hpp:77] Creating layer Scale6
I1006 17:36:08.974046  3702 net.cpp:84] Creating Layer Scale6
I1006 17:36:08.974050  3702 net.cpp:406] Scale6 <- Convolution6
I1006 17:36:08.974052  3702 net.cpp:367] Scale6 -> Convolution6 (in-place)
I1006 17:36:08.974081  3702 layer_factory.hpp:77] Creating layer Scale6
I1006 17:36:08.974158  3702 net.cpp:122] Setting up Scale6
I1006 17:36:08.974164  3702 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 17:36:08.974165  3702 net.cpp:137] Memory required for data: 156486800
I1006 17:36:08.974169  3702 layer_factory.hpp:77] Creating layer penlu6
I1006 17:36:08.974175  3702 net.cpp:84] Creating Layer penlu6
I1006 17:36:08.974179  3702 net.cpp:406] penlu6 <- Convolution6
I1006 17:36:08.974182  3702 net.cpp:367] penlu6 -> Convolution6 (in-place)
I1006 17:36:08.974287  3702 net.cpp:122] Setting up penlu6
I1006 17:36:08.974292  3702 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 17:36:08.974295  3702 net.cpp:137] Memory required for data: 161504400
I1006 17:36:08.974300  3702 layer_factory.hpp:77] Creating layer Convolution7
I1006 17:36:08.974308  3702 net.cpp:84] Creating Layer Convolution7
I1006 17:36:08.974310  3702 net.cpp:406] Convolution7 <- Convolution6
I1006 17:36:08.974314  3702 net.cpp:380] Convolution7 -> Convolution7
I1006 17:36:08.974865  3702 net.cpp:122] Setting up Convolution7
I1006 17:36:08.974875  3702 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 17:36:08.974879  3702 net.cpp:137] Memory required for data: 166522000
I1006 17:36:08.974882  3702 layer_factory.hpp:77] Creating layer BatchNorm7
I1006 17:36:08.974889  3702 net.cpp:84] Creating Layer BatchNorm7
I1006 17:36:08.974891  3702 net.cpp:406] BatchNorm7 <- Convolution7
I1006 17:36:08.974895  3702 net.cpp:367] BatchNorm7 -> Convolution7 (in-place)
I1006 17:36:08.975023  3702 net.cpp:122] Setting up BatchNorm7
I1006 17:36:08.975028  3702 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 17:36:08.975031  3702 net.cpp:137] Memory required for data: 171539600
I1006 17:36:08.975041  3702 layer_factory.hpp:77] Creating layer Scale7
I1006 17:36:08.975047  3702 net.cpp:84] Creating Layer Scale7
I1006 17:36:08.975050  3702 net.cpp:406] Scale7 <- Convolution7
I1006 17:36:08.975054  3702 net.cpp:367] Scale7 -> Convolution7 (in-place)
I1006 17:36:08.975081  3702 layer_factory.hpp:77] Creating layer Scale7
I1006 17:36:08.975168  3702 net.cpp:122] Setting up Scale7
I1006 17:36:08.975175  3702 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 17:36:08.975178  3702 net.cpp:137] Memory required for data: 176557200
I1006 17:36:08.975183  3702 layer_factory.hpp:77] Creating layer Eltwise3
I1006 17:36:08.975188  3702 net.cpp:84] Creating Layer Eltwise3
I1006 17:36:08.975191  3702 net.cpp:406] Eltwise3 <- Eltwise2_penlu5_0_split_1
I1006 17:36:08.975194  3702 net.cpp:406] Eltwise3 <- Convolution7
I1006 17:36:08.975198  3702 net.cpp:380] Eltwise3 -> Eltwise3
I1006 17:36:08.975214  3702 net.cpp:122] Setting up Eltwise3
I1006 17:36:08.975217  3702 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 17:36:08.975220  3702 net.cpp:137] Memory required for data: 181574800
I1006 17:36:08.975222  3702 layer_factory.hpp:77] Creating layer penlu7
I1006 17:36:08.975229  3702 net.cpp:84] Creating Layer penlu7
I1006 17:36:08.975231  3702 net.cpp:406] penlu7 <- Eltwise3
I1006 17:36:08.975235  3702 net.cpp:367] penlu7 -> Eltwise3 (in-place)
I1006 17:36:08.975340  3702 net.cpp:122] Setting up penlu7
I1006 17:36:08.975345  3702 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 17:36:08.975348  3702 net.cpp:137] Memory required for data: 186592400
I1006 17:36:08.975353  3702 layer_factory.hpp:77] Creating layer Eltwise3_penlu7_0_split
I1006 17:36:08.975358  3702 net.cpp:84] Creating Layer Eltwise3_penlu7_0_split
I1006 17:36:08.975360  3702 net.cpp:406] Eltwise3_penlu7_0_split <- Eltwise3
I1006 17:36:08.975363  3702 net.cpp:380] Eltwise3_penlu7_0_split -> Eltwise3_penlu7_0_split_0
I1006 17:36:08.975368  3702 net.cpp:380] Eltwise3_penlu7_0_split -> Eltwise3_penlu7_0_split_1
I1006 17:36:08.975390  3702 net.cpp:122] Setting up Eltwise3_penlu7_0_split
I1006 17:36:08.975395  3702 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 17:36:08.975399  3702 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 17:36:08.975401  3702 net.cpp:137] Memory required for data: 196627600
I1006 17:36:08.975404  3702 layer_factory.hpp:77] Creating layer Convolution8
I1006 17:36:08.975410  3702 net.cpp:84] Creating Layer Convolution8
I1006 17:36:08.975414  3702 net.cpp:406] Convolution8 <- Eltwise3_penlu7_0_split_0
I1006 17:36:08.975417  3702 net.cpp:380] Convolution8 -> Convolution8
I1006 17:36:08.976289  3702 net.cpp:122] Setting up Convolution8
I1006 17:36:08.976299  3702 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 17:36:08.976301  3702 net.cpp:137] Memory required for data: 201645200
I1006 17:36:08.976306  3702 layer_factory.hpp:77] Creating layer BatchNorm8
I1006 17:36:08.976311  3702 net.cpp:84] Creating Layer BatchNorm8
I1006 17:36:08.976315  3702 net.cpp:406] BatchNorm8 <- Convolution8
I1006 17:36:08.976320  3702 net.cpp:367] BatchNorm8 -> Convolution8 (in-place)
I1006 17:36:08.976447  3702 net.cpp:122] Setting up BatchNorm8
I1006 17:36:08.976454  3702 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 17:36:08.976456  3702 net.cpp:137] Memory required for data: 206662800
I1006 17:36:08.976461  3702 layer_factory.hpp:77] Creating layer Scale8
I1006 17:36:08.976466  3702 net.cpp:84] Creating Layer Scale8
I1006 17:36:08.976469  3702 net.cpp:406] Scale8 <- Convolution8
I1006 17:36:08.976474  3702 net.cpp:367] Scale8 -> Convolution8 (in-place)
I1006 17:36:08.976498  3702 layer_factory.hpp:77] Creating layer Scale8
I1006 17:36:08.976586  3702 net.cpp:122] Setting up Scale8
I1006 17:36:08.976591  3702 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 17:36:08.976594  3702 net.cpp:137] Memory required for data: 211680400
I1006 17:36:08.976598  3702 layer_factory.hpp:77] Creating layer penlu8
I1006 17:36:08.976604  3702 net.cpp:84] Creating Layer penlu8
I1006 17:36:08.976608  3702 net.cpp:406] penlu8 <- Convolution8
I1006 17:36:08.976613  3702 net.cpp:367] penlu8 -> Convolution8 (in-place)
I1006 17:36:08.976718  3702 net.cpp:122] Setting up penlu8
I1006 17:36:08.976723  3702 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 17:36:08.976727  3702 net.cpp:137] Memory required for data: 216698000
I1006 17:36:08.976732  3702 layer_factory.hpp:77] Creating layer Convolution9
I1006 17:36:08.976745  3702 net.cpp:84] Creating Layer Convolution9
I1006 17:36:08.976749  3702 net.cpp:406] Convolution9 <- Convolution8
I1006 17:36:08.976753  3702 net.cpp:380] Convolution9 -> Convolution9
I1006 17:36:08.977716  3702 net.cpp:122] Setting up Convolution9
I1006 17:36:08.977730  3702 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 17:36:08.977735  3702 net.cpp:137] Memory required for data: 221715600
I1006 17:36:08.977742  3702 layer_factory.hpp:77] Creating layer BatchNorm9
I1006 17:36:08.977751  3702 net.cpp:84] Creating Layer BatchNorm9
I1006 17:36:08.977757  3702 net.cpp:406] BatchNorm9 <- Convolution9
I1006 17:36:08.977763  3702 net.cpp:367] BatchNorm9 -> Convolution9 (in-place)
I1006 17:36:08.977903  3702 net.cpp:122] Setting up BatchNorm9
I1006 17:36:08.977911  3702 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 17:36:08.977916  3702 net.cpp:137] Memory required for data: 226733200
I1006 17:36:08.977923  3702 layer_factory.hpp:77] Creating layer Scale9
I1006 17:36:08.977931  3702 net.cpp:84] Creating Layer Scale9
I1006 17:36:08.977936  3702 net.cpp:406] Scale9 <- Convolution9
I1006 17:36:08.977946  3702 net.cpp:367] Scale9 -> Convolution9 (in-place)
I1006 17:36:08.977978  3702 layer_factory.hpp:77] Creating layer Scale9
I1006 17:36:08.978070  3702 net.cpp:122] Setting up Scale9
I1006 17:36:08.978076  3702 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 17:36:08.978080  3702 net.cpp:137] Memory required for data: 231750800
I1006 17:36:08.978088  3702 layer_factory.hpp:77] Creating layer Eltwise4
I1006 17:36:08.978096  3702 net.cpp:84] Creating Layer Eltwise4
I1006 17:36:08.978101  3702 net.cpp:406] Eltwise4 <- Eltwise3_penlu7_0_split_1
I1006 17:36:08.978107  3702 net.cpp:406] Eltwise4 <- Convolution9
I1006 17:36:08.978116  3702 net.cpp:380] Eltwise4 -> Eltwise4
I1006 17:36:08.978138  3702 net.cpp:122] Setting up Eltwise4
I1006 17:36:08.978145  3702 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 17:36:08.978149  3702 net.cpp:137] Memory required for data: 236768400
I1006 17:36:08.978154  3702 layer_factory.hpp:77] Creating layer penlu9
I1006 17:36:08.978163  3702 net.cpp:84] Creating Layer penlu9
I1006 17:36:08.978168  3702 net.cpp:406] penlu9 <- Eltwise4
I1006 17:36:08.978175  3702 net.cpp:367] penlu9 -> Eltwise4 (in-place)
I1006 17:36:08.978291  3702 net.cpp:122] Setting up penlu9
I1006 17:36:08.978297  3702 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 17:36:08.978302  3702 net.cpp:137] Memory required for data: 241786000
I1006 17:36:08.978312  3702 layer_factory.hpp:77] Creating layer Eltwise4_penlu9_0_split
I1006 17:36:08.978317  3702 net.cpp:84] Creating Layer Eltwise4_penlu9_0_split
I1006 17:36:08.978322  3702 net.cpp:406] Eltwise4_penlu9_0_split <- Eltwise4
I1006 17:36:08.978328  3702 net.cpp:380] Eltwise4_penlu9_0_split -> Eltwise4_penlu9_0_split_0
I1006 17:36:08.978337  3702 net.cpp:380] Eltwise4_penlu9_0_split -> Eltwise4_penlu9_0_split_1
I1006 17:36:08.978365  3702 net.cpp:122] Setting up Eltwise4_penlu9_0_split
I1006 17:36:08.978373  3702 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 17:36:08.978379  3702 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 17:36:08.978384  3702 net.cpp:137] Memory required for data: 251821200
I1006 17:36:08.978389  3702 layer_factory.hpp:77] Creating layer Convolution10
I1006 17:36:08.978399  3702 net.cpp:84] Creating Layer Convolution10
I1006 17:36:08.978404  3702 net.cpp:406] Convolution10 <- Eltwise4_penlu9_0_split_0
I1006 17:36:08.978411  3702 net.cpp:380] Convolution10 -> Convolution10
I1006 17:36:08.979393  3702 net.cpp:122] Setting up Convolution10
I1006 17:36:08.979404  3702 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 17:36:08.979409  3702 net.cpp:137] Memory required for data: 256838800
I1006 17:36:08.979426  3702 layer_factory.hpp:77] Creating layer BatchNorm10
I1006 17:36:08.979436  3702 net.cpp:84] Creating Layer BatchNorm10
I1006 17:36:08.979442  3702 net.cpp:406] BatchNorm10 <- Convolution10
I1006 17:36:08.979450  3702 net.cpp:367] BatchNorm10 -> Convolution10 (in-place)
I1006 17:36:08.979598  3702 net.cpp:122] Setting up BatchNorm10
I1006 17:36:08.979607  3702 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 17:36:08.979611  3702 net.cpp:137] Memory required for data: 261856400
I1006 17:36:08.979621  3702 layer_factory.hpp:77] Creating layer Scale10
I1006 17:36:08.979629  3702 net.cpp:84] Creating Layer Scale10
I1006 17:36:08.979635  3702 net.cpp:406] Scale10 <- Convolution10
I1006 17:36:08.979643  3702 net.cpp:367] Scale10 -> Convolution10 (in-place)
I1006 17:36:08.979674  3702 layer_factory.hpp:77] Creating layer Scale10
I1006 17:36:08.979760  3702 net.cpp:122] Setting up Scale10
I1006 17:36:08.979768  3702 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 17:36:08.979771  3702 net.cpp:137] Memory required for data: 266874000
I1006 17:36:08.979780  3702 layer_factory.hpp:77] Creating layer penlu10
I1006 17:36:08.979789  3702 net.cpp:84] Creating Layer penlu10
I1006 17:36:08.979794  3702 net.cpp:406] penlu10 <- Convolution10
I1006 17:36:08.979802  3702 net.cpp:367] penlu10 -> Convolution10 (in-place)
I1006 17:36:08.979918  3702 net.cpp:122] Setting up penlu10
I1006 17:36:08.979924  3702 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 17:36:08.979929  3702 net.cpp:137] Memory required for data: 271891600
I1006 17:36:08.979938  3702 layer_factory.hpp:77] Creating layer Convolution11
I1006 17:36:08.979950  3702 net.cpp:84] Creating Layer Convolution11
I1006 17:36:08.979955  3702 net.cpp:406] Convolution11 <- Convolution10
I1006 17:36:08.979962  3702 net.cpp:380] Convolution11 -> Convolution11
I1006 17:36:08.980885  3702 net.cpp:122] Setting up Convolution11
I1006 17:36:08.980896  3702 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 17:36:08.980901  3702 net.cpp:137] Memory required for data: 276909200
I1006 17:36:08.980908  3702 layer_factory.hpp:77] Creating layer BatchNorm11
I1006 17:36:08.980917  3702 net.cpp:84] Creating Layer BatchNorm11
I1006 17:36:08.980922  3702 net.cpp:406] BatchNorm11 <- Convolution11
I1006 17:36:08.980932  3702 net.cpp:367] BatchNorm11 -> Convolution11 (in-place)
I1006 17:36:08.981073  3702 net.cpp:122] Setting up BatchNorm11
I1006 17:36:08.981081  3702 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 17:36:08.981086  3702 net.cpp:137] Memory required for data: 281926800
I1006 17:36:08.981096  3702 layer_factory.hpp:77] Creating layer Scale11
I1006 17:36:08.981102  3702 net.cpp:84] Creating Layer Scale11
I1006 17:36:08.981107  3702 net.cpp:406] Scale11 <- Convolution11
I1006 17:36:08.981117  3702 net.cpp:367] Scale11 -> Convolution11 (in-place)
I1006 17:36:08.981148  3702 layer_factory.hpp:77] Creating layer Scale11
I1006 17:36:08.981235  3702 net.cpp:122] Setting up Scale11
I1006 17:36:08.981243  3702 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 17:36:08.981247  3702 net.cpp:137] Memory required for data: 286944400
I1006 17:36:08.981256  3702 layer_factory.hpp:77] Creating layer Eltwise5
I1006 17:36:08.981262  3702 net.cpp:84] Creating Layer Eltwise5
I1006 17:36:08.981268  3702 net.cpp:406] Eltwise5 <- Eltwise4_penlu9_0_split_1
I1006 17:36:08.981274  3702 net.cpp:406] Eltwise5 <- Convolution11
I1006 17:36:08.981283  3702 net.cpp:380] Eltwise5 -> Eltwise5
I1006 17:36:08.981303  3702 net.cpp:122] Setting up Eltwise5
I1006 17:36:08.981312  3702 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 17:36:08.981317  3702 net.cpp:137] Memory required for data: 291962000
I1006 17:36:08.981323  3702 layer_factory.hpp:77] Creating layer penlu11
I1006 17:36:08.981331  3702 net.cpp:84] Creating Layer penlu11
I1006 17:36:08.981336  3702 net.cpp:406] penlu11 <- Eltwise5
I1006 17:36:08.981343  3702 net.cpp:367] penlu11 -> Eltwise5 (in-place)
I1006 17:36:08.981462  3702 net.cpp:122] Setting up penlu11
I1006 17:36:08.981468  3702 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 17:36:08.981472  3702 net.cpp:137] Memory required for data: 296979600
I1006 17:36:08.981482  3702 layer_factory.hpp:77] Creating layer Eltwise5_penlu11_0_split
I1006 17:36:08.981488  3702 net.cpp:84] Creating Layer Eltwise5_penlu11_0_split
I1006 17:36:08.981493  3702 net.cpp:406] Eltwise5_penlu11_0_split <- Eltwise5
I1006 17:36:08.981508  3702 net.cpp:380] Eltwise5_penlu11_0_split -> Eltwise5_penlu11_0_split_0
I1006 17:36:08.981516  3702 net.cpp:380] Eltwise5_penlu11_0_split -> Eltwise5_penlu11_0_split_1
I1006 17:36:08.981547  3702 net.cpp:122] Setting up Eltwise5_penlu11_0_split
I1006 17:36:08.981554  3702 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 17:36:08.981560  3702 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 17:36:08.981564  3702 net.cpp:137] Memory required for data: 307014800
I1006 17:36:08.981570  3702 layer_factory.hpp:77] Creating layer Convolution12
I1006 17:36:08.981580  3702 net.cpp:84] Creating Layer Convolution12
I1006 17:36:08.981585  3702 net.cpp:406] Convolution12 <- Eltwise5_penlu11_0_split_0
I1006 17:36:08.981592  3702 net.cpp:380] Convolution12 -> Convolution12
I1006 17:36:08.982779  3702 net.cpp:122] Setting up Convolution12
I1006 17:36:08.982789  3702 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 17:36:08.982794  3702 net.cpp:137] Memory required for data: 309523600
I1006 17:36:08.982801  3702 layer_factory.hpp:77] Creating layer BatchNorm12
I1006 17:36:08.982811  3702 net.cpp:84] Creating Layer BatchNorm12
I1006 17:36:08.982816  3702 net.cpp:406] BatchNorm12 <- Convolution12
I1006 17:36:08.982825  3702 net.cpp:367] BatchNorm12 -> Convolution12 (in-place)
I1006 17:36:08.982970  3702 net.cpp:122] Setting up BatchNorm12
I1006 17:36:08.982978  3702 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 17:36:08.982982  3702 net.cpp:137] Memory required for data: 312032400
I1006 17:36:08.982991  3702 layer_factory.hpp:77] Creating layer Scale12
I1006 17:36:08.982998  3702 net.cpp:84] Creating Layer Scale12
I1006 17:36:08.983005  3702 net.cpp:406] Scale12 <- Convolution12
I1006 17:36:08.983011  3702 net.cpp:367] Scale12 -> Convolution12 (in-place)
I1006 17:36:08.983044  3702 layer_factory.hpp:77] Creating layer Scale12
I1006 17:36:08.983125  3702 net.cpp:122] Setting up Scale12
I1006 17:36:08.983132  3702 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 17:36:08.983137  3702 net.cpp:137] Memory required for data: 314541200
I1006 17:36:08.983145  3702 layer_factory.hpp:77] Creating layer Convolution13
I1006 17:36:08.983156  3702 net.cpp:84] Creating Layer Convolution13
I1006 17:36:08.983160  3702 net.cpp:406] Convolution13 <- Eltwise5_penlu11_0_split_1
I1006 17:36:08.983184  3702 net.cpp:380] Convolution13 -> Convolution13
I1006 17:36:08.984447  3702 net.cpp:122] Setting up Convolution13
I1006 17:36:08.984458  3702 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 17:36:08.984463  3702 net.cpp:137] Memory required for data: 317050000
I1006 17:36:08.984472  3702 layer_factory.hpp:77] Creating layer BatchNorm13
I1006 17:36:08.984482  3702 net.cpp:84] Creating Layer BatchNorm13
I1006 17:36:08.984486  3702 net.cpp:406] BatchNorm13 <- Convolution13
I1006 17:36:08.984494  3702 net.cpp:367] BatchNorm13 -> Convolution13 (in-place)
I1006 17:36:08.984632  3702 net.cpp:122] Setting up BatchNorm13
I1006 17:36:08.984640  3702 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 17:36:08.984644  3702 net.cpp:137] Memory required for data: 319558800
I1006 17:36:08.984654  3702 layer_factory.hpp:77] Creating layer Scale13
I1006 17:36:08.984663  3702 net.cpp:84] Creating Layer Scale13
I1006 17:36:08.984668  3702 net.cpp:406] Scale13 <- Convolution13
I1006 17:36:08.984674  3702 net.cpp:367] Scale13 -> Convolution13 (in-place)
I1006 17:36:08.984707  3702 layer_factory.hpp:77] Creating layer Scale13
I1006 17:36:08.984791  3702 net.cpp:122] Setting up Scale13
I1006 17:36:08.984798  3702 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 17:36:08.984802  3702 net.cpp:137] Memory required for data: 322067600
I1006 17:36:08.984810  3702 layer_factory.hpp:77] Creating layer penlu12
I1006 17:36:08.984822  3702 net.cpp:84] Creating Layer penlu12
I1006 17:36:08.984825  3702 net.cpp:406] penlu12 <- Convolution13
I1006 17:36:08.984832  3702 net.cpp:367] penlu12 -> Convolution13 (in-place)
I1006 17:36:08.984942  3702 net.cpp:122] Setting up penlu12
I1006 17:36:08.984949  3702 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 17:36:08.984961  3702 net.cpp:137] Memory required for data: 324576400
I1006 17:36:08.984972  3702 layer_factory.hpp:77] Creating layer Convolution14
I1006 17:36:08.984982  3702 net.cpp:84] Creating Layer Convolution14
I1006 17:36:08.984987  3702 net.cpp:406] Convolution14 <- Convolution13
I1006 17:36:08.984994  3702 net.cpp:380] Convolution14 -> Convolution14
I1006 17:36:08.986049  3702 net.cpp:122] Setting up Convolution14
I1006 17:36:08.986060  3702 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 17:36:08.986065  3702 net.cpp:137] Memory required for data: 327085200
I1006 17:36:08.986086  3702 layer_factory.hpp:77] Creating layer BatchNorm14
I1006 17:36:08.986099  3702 net.cpp:84] Creating Layer BatchNorm14
I1006 17:36:08.986104  3702 net.cpp:406] BatchNorm14 <- Convolution14
I1006 17:36:08.986112  3702 net.cpp:367] BatchNorm14 -> Convolution14 (in-place)
I1006 17:36:08.986249  3702 net.cpp:122] Setting up BatchNorm14
I1006 17:36:08.986258  3702 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 17:36:08.986261  3702 net.cpp:137] Memory required for data: 329594000
I1006 17:36:08.986274  3702 layer_factory.hpp:77] Creating layer Scale14
I1006 17:36:08.986280  3702 net.cpp:84] Creating Layer Scale14
I1006 17:36:08.986285  3702 net.cpp:406] Scale14 <- Convolution14
I1006 17:36:08.986292  3702 net.cpp:367] Scale14 -> Convolution14 (in-place)
I1006 17:36:08.986325  3702 layer_factory.hpp:77] Creating layer Scale14
I1006 17:36:08.986407  3702 net.cpp:122] Setting up Scale14
I1006 17:36:08.986414  3702 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 17:36:08.986418  3702 net.cpp:137] Memory required for data: 332102800
I1006 17:36:08.986426  3702 layer_factory.hpp:77] Creating layer Eltwise6
I1006 17:36:08.986433  3702 net.cpp:84] Creating Layer Eltwise6
I1006 17:36:08.986438  3702 net.cpp:406] Eltwise6 <- Convolution12
I1006 17:36:08.986444  3702 net.cpp:406] Eltwise6 <- Convolution14
I1006 17:36:08.986450  3702 net.cpp:380] Eltwise6 -> Eltwise6
I1006 17:36:08.986467  3702 net.cpp:122] Setting up Eltwise6
I1006 17:36:08.986471  3702 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 17:36:08.986474  3702 net.cpp:137] Memory required for data: 334611600
I1006 17:36:08.986475  3702 layer_factory.hpp:77] Creating layer penlu13
I1006 17:36:08.986481  3702 net.cpp:84] Creating Layer penlu13
I1006 17:36:08.986484  3702 net.cpp:406] penlu13 <- Eltwise6
I1006 17:36:08.986487  3702 net.cpp:367] penlu13 -> Eltwise6 (in-place)
I1006 17:36:08.986591  3702 net.cpp:122] Setting up penlu13
I1006 17:36:08.986596  3702 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 17:36:08.986598  3702 net.cpp:137] Memory required for data: 337120400
I1006 17:36:08.986603  3702 layer_factory.hpp:77] Creating layer Eltwise6_penlu13_0_split
I1006 17:36:08.986606  3702 net.cpp:84] Creating Layer Eltwise6_penlu13_0_split
I1006 17:36:08.986608  3702 net.cpp:406] Eltwise6_penlu13_0_split <- Eltwise6
I1006 17:36:08.986613  3702 net.cpp:380] Eltwise6_penlu13_0_split -> Eltwise6_penlu13_0_split_0
I1006 17:36:08.986616  3702 net.cpp:380] Eltwise6_penlu13_0_split -> Eltwise6_penlu13_0_split_1
I1006 17:36:08.986637  3702 net.cpp:122] Setting up Eltwise6_penlu13_0_split
I1006 17:36:08.986640  3702 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 17:36:08.986644  3702 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 17:36:08.986645  3702 net.cpp:137] Memory required for data: 342138000
I1006 17:36:08.986647  3702 layer_factory.hpp:77] Creating layer Convolution15
I1006 17:36:08.986654  3702 net.cpp:84] Creating Layer Convolution15
I1006 17:36:08.986656  3702 net.cpp:406] Convolution15 <- Eltwise6_penlu13_0_split_0
I1006 17:36:08.986660  3702 net.cpp:380] Convolution15 -> Convolution15
I1006 17:36:08.987721  3702 net.cpp:122] Setting up Convolution15
I1006 17:36:08.987730  3702 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 17:36:08.987732  3702 net.cpp:137] Memory required for data: 344646800
I1006 17:36:08.987737  3702 layer_factory.hpp:77] Creating layer BatchNorm15
I1006 17:36:08.987743  3702 net.cpp:84] Creating Layer BatchNorm15
I1006 17:36:08.987753  3702 net.cpp:406] BatchNorm15 <- Convolution15
I1006 17:36:08.987757  3702 net.cpp:367] BatchNorm15 -> Convolution15 (in-place)
I1006 17:36:08.987886  3702 net.cpp:122] Setting up BatchNorm15
I1006 17:36:08.987891  3702 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 17:36:08.987893  3702 net.cpp:137] Memory required for data: 347155600
I1006 17:36:08.987900  3702 layer_factory.hpp:77] Creating layer Scale15
I1006 17:36:08.987903  3702 net.cpp:84] Creating Layer Scale15
I1006 17:36:08.987905  3702 net.cpp:406] Scale15 <- Convolution15
I1006 17:36:08.987908  3702 net.cpp:367] Scale15 -> Convolution15 (in-place)
I1006 17:36:08.987933  3702 layer_factory.hpp:77] Creating layer Scale15
I1006 17:36:08.988008  3702 net.cpp:122] Setting up Scale15
I1006 17:36:08.988013  3702 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 17:36:08.988015  3702 net.cpp:137] Memory required for data: 349664400
I1006 17:36:08.988018  3702 layer_factory.hpp:77] Creating layer penlu14
I1006 17:36:08.988025  3702 net.cpp:84] Creating Layer penlu14
I1006 17:36:08.988028  3702 net.cpp:406] penlu14 <- Convolution15
I1006 17:36:08.988030  3702 net.cpp:367] penlu14 -> Convolution15 (in-place)
I1006 17:36:08.988134  3702 net.cpp:122] Setting up penlu14
I1006 17:36:08.988138  3702 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 17:36:08.988140  3702 net.cpp:137] Memory required for data: 352173200
I1006 17:36:08.988144  3702 layer_factory.hpp:77] Creating layer Convolution16
I1006 17:36:08.988152  3702 net.cpp:84] Creating Layer Convolution16
I1006 17:36:08.988154  3702 net.cpp:406] Convolution16 <- Convolution15
I1006 17:36:08.988158  3702 net.cpp:380] Convolution16 -> Convolution16
I1006 17:36:08.989202  3702 net.cpp:122] Setting up Convolution16
I1006 17:36:08.989210  3702 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 17:36:08.989212  3702 net.cpp:137] Memory required for data: 354682000
I1006 17:36:08.989217  3702 layer_factory.hpp:77] Creating layer BatchNorm16
I1006 17:36:08.989223  3702 net.cpp:84] Creating Layer BatchNorm16
I1006 17:36:08.989225  3702 net.cpp:406] BatchNorm16 <- Convolution16
I1006 17:36:08.989229  3702 net.cpp:367] BatchNorm16 -> Convolution16 (in-place)
I1006 17:36:08.989361  3702 net.cpp:122] Setting up BatchNorm16
I1006 17:36:08.989364  3702 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 17:36:08.989367  3702 net.cpp:137] Memory required for data: 357190800
I1006 17:36:08.989372  3702 layer_factory.hpp:77] Creating layer Scale16
I1006 17:36:08.989377  3702 net.cpp:84] Creating Layer Scale16
I1006 17:36:08.989378  3702 net.cpp:406] Scale16 <- Convolution16
I1006 17:36:08.989382  3702 net.cpp:367] Scale16 -> Convolution16 (in-place)
I1006 17:36:08.989408  3702 layer_factory.hpp:77] Creating layer Scale16
I1006 17:36:08.989482  3702 net.cpp:122] Setting up Scale16
I1006 17:36:08.989486  3702 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 17:36:08.989488  3702 net.cpp:137] Memory required for data: 359699600
I1006 17:36:08.989492  3702 layer_factory.hpp:77] Creating layer Eltwise7
I1006 17:36:08.989496  3702 net.cpp:84] Creating Layer Eltwise7
I1006 17:36:08.989498  3702 net.cpp:406] Eltwise7 <- Eltwise6_penlu13_0_split_1
I1006 17:36:08.989501  3702 net.cpp:406] Eltwise7 <- Convolution16
I1006 17:36:08.989506  3702 net.cpp:380] Eltwise7 -> Eltwise7
I1006 17:36:08.989521  3702 net.cpp:122] Setting up Eltwise7
I1006 17:36:08.989523  3702 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 17:36:08.989526  3702 net.cpp:137] Memory required for data: 362208400
I1006 17:36:08.989528  3702 layer_factory.hpp:77] Creating layer penlu15
I1006 17:36:08.989533  3702 net.cpp:84] Creating Layer penlu15
I1006 17:36:08.989537  3702 net.cpp:406] penlu15 <- Eltwise7
I1006 17:36:08.989539  3702 net.cpp:367] penlu15 -> Eltwise7 (in-place)
I1006 17:36:08.989644  3702 net.cpp:122] Setting up penlu15
I1006 17:36:08.989647  3702 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 17:36:08.989650  3702 net.cpp:137] Memory required for data: 364717200
I1006 17:36:08.989660  3702 layer_factory.hpp:77] Creating layer Eltwise7_penlu15_0_split
I1006 17:36:08.989665  3702 net.cpp:84] Creating Layer Eltwise7_penlu15_0_split
I1006 17:36:08.989666  3702 net.cpp:406] Eltwise7_penlu15_0_split <- Eltwise7
I1006 17:36:08.989670  3702 net.cpp:380] Eltwise7_penlu15_0_split -> Eltwise7_penlu15_0_split_0
I1006 17:36:08.989675  3702 net.cpp:380] Eltwise7_penlu15_0_split -> Eltwise7_penlu15_0_split_1
I1006 17:36:08.989696  3702 net.cpp:122] Setting up Eltwise7_penlu15_0_split
I1006 17:36:08.989701  3702 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 17:36:08.989703  3702 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 17:36:08.989706  3702 net.cpp:137] Memory required for data: 369734800
I1006 17:36:08.989707  3702 layer_factory.hpp:77] Creating layer Convolution17
I1006 17:36:08.989713  3702 net.cpp:84] Creating Layer Convolution17
I1006 17:36:08.989717  3702 net.cpp:406] Convolution17 <- Eltwise7_penlu15_0_split_0
I1006 17:36:08.989720  3702 net.cpp:380] Convolution17 -> Convolution17
I1006 17:36:08.990435  3702 net.cpp:122] Setting up Convolution17
I1006 17:36:08.990442  3702 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 17:36:08.990444  3702 net.cpp:137] Memory required for data: 372243600
I1006 17:36:08.990448  3702 layer_factory.hpp:77] Creating layer BatchNorm17
I1006 17:36:08.990453  3702 net.cpp:84] Creating Layer BatchNorm17
I1006 17:36:08.990456  3702 net.cpp:406] BatchNorm17 <- Convolution17
I1006 17:36:08.990460  3702 net.cpp:367] BatchNorm17 -> Convolution17 (in-place)
I1006 17:36:08.990589  3702 net.cpp:122] Setting up BatchNorm17
I1006 17:36:08.990593  3702 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 17:36:08.990595  3702 net.cpp:137] Memory required for data: 374752400
I1006 17:36:08.990600  3702 layer_factory.hpp:77] Creating layer Scale17
I1006 17:36:08.990604  3702 net.cpp:84] Creating Layer Scale17
I1006 17:36:08.990607  3702 net.cpp:406] Scale17 <- Convolution17
I1006 17:36:08.990610  3702 net.cpp:367] Scale17 -> Convolution17 (in-place)
I1006 17:36:08.990636  3702 layer_factory.hpp:77] Creating layer Scale17
I1006 17:36:08.990710  3702 net.cpp:122] Setting up Scale17
I1006 17:36:08.990715  3702 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 17:36:08.990716  3702 net.cpp:137] Memory required for data: 377261200
I1006 17:36:08.990720  3702 layer_factory.hpp:77] Creating layer penlu16
I1006 17:36:08.990725  3702 net.cpp:84] Creating Layer penlu16
I1006 17:36:08.990727  3702 net.cpp:406] penlu16 <- Convolution17
I1006 17:36:08.990731  3702 net.cpp:367] penlu16 -> Convolution17 (in-place)
I1006 17:36:08.990835  3702 net.cpp:122] Setting up penlu16
I1006 17:36:08.990839  3702 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 17:36:08.990841  3702 net.cpp:137] Memory required for data: 379770000
I1006 17:36:08.990845  3702 layer_factory.hpp:77] Creating layer Convolution18
I1006 17:36:08.990851  3702 net.cpp:84] Creating Layer Convolution18
I1006 17:36:08.990854  3702 net.cpp:406] Convolution18 <- Convolution17
I1006 17:36:08.990859  3702 net.cpp:380] Convolution18 -> Convolution18
I1006 17:36:08.991952  3702 net.cpp:122] Setting up Convolution18
I1006 17:36:08.991961  3702 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 17:36:08.991964  3702 net.cpp:137] Memory required for data: 382278800
I1006 17:36:08.991968  3702 layer_factory.hpp:77] Creating layer BatchNorm18
I1006 17:36:08.991973  3702 net.cpp:84] Creating Layer BatchNorm18
I1006 17:36:08.991976  3702 net.cpp:406] BatchNorm18 <- Convolution18
I1006 17:36:08.991981  3702 net.cpp:367] BatchNorm18 -> Convolution18 (in-place)
I1006 17:36:08.992111  3702 net.cpp:122] Setting up BatchNorm18
I1006 17:36:08.992115  3702 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 17:36:08.992117  3702 net.cpp:137] Memory required for data: 384787600
I1006 17:36:08.992122  3702 layer_factory.hpp:77] Creating layer Scale18
I1006 17:36:08.992126  3702 net.cpp:84] Creating Layer Scale18
I1006 17:36:08.992128  3702 net.cpp:406] Scale18 <- Convolution18
I1006 17:36:08.992131  3702 net.cpp:367] Scale18 -> Convolution18 (in-place)
I1006 17:36:08.992166  3702 layer_factory.hpp:77] Creating layer Scale18
I1006 17:36:08.992242  3702 net.cpp:122] Setting up Scale18
I1006 17:36:08.992247  3702 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 17:36:08.992249  3702 net.cpp:137] Memory required for data: 387296400
I1006 17:36:08.992252  3702 layer_factory.hpp:77] Creating layer Eltwise8
I1006 17:36:08.992257  3702 net.cpp:84] Creating Layer Eltwise8
I1006 17:36:08.992259  3702 net.cpp:406] Eltwise8 <- Eltwise7_penlu15_0_split_1
I1006 17:36:08.992262  3702 net.cpp:406] Eltwise8 <- Convolution18
I1006 17:36:08.992265  3702 net.cpp:380] Eltwise8 -> Eltwise8
I1006 17:36:08.992281  3702 net.cpp:122] Setting up Eltwise8
I1006 17:36:08.992285  3702 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 17:36:08.992287  3702 net.cpp:137] Memory required for data: 389805200
I1006 17:36:08.992290  3702 layer_factory.hpp:77] Creating layer penlu17
I1006 17:36:08.992295  3702 net.cpp:84] Creating Layer penlu17
I1006 17:36:08.992296  3702 net.cpp:406] penlu17 <- Eltwise8
I1006 17:36:08.992300  3702 net.cpp:367] penlu17 -> Eltwise8 (in-place)
I1006 17:36:08.992406  3702 net.cpp:122] Setting up penlu17
I1006 17:36:08.992410  3702 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 17:36:08.992413  3702 net.cpp:137] Memory required for data: 392314000
I1006 17:36:08.992418  3702 layer_factory.hpp:77] Creating layer Eltwise8_penlu17_0_split
I1006 17:36:08.992421  3702 net.cpp:84] Creating Layer Eltwise8_penlu17_0_split
I1006 17:36:08.992424  3702 net.cpp:406] Eltwise8_penlu17_0_split <- Eltwise8
I1006 17:36:08.992426  3702 net.cpp:380] Eltwise8_penlu17_0_split -> Eltwise8_penlu17_0_split_0
I1006 17:36:08.992430  3702 net.cpp:380] Eltwise8_penlu17_0_split -> Eltwise8_penlu17_0_split_1
I1006 17:36:08.992453  3702 net.cpp:122] Setting up Eltwise8_penlu17_0_split
I1006 17:36:08.992457  3702 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 17:36:08.992460  3702 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 17:36:08.992461  3702 net.cpp:137] Memory required for data: 397331600
I1006 17:36:08.992463  3702 layer_factory.hpp:77] Creating layer Convolution19
I1006 17:36:08.992470  3702 net.cpp:84] Creating Layer Convolution19
I1006 17:36:08.992471  3702 net.cpp:406] Convolution19 <- Eltwise8_penlu17_0_split_0
I1006 17:36:08.992476  3702 net.cpp:380] Convolution19 -> Convolution19
I1006 17:36:08.994216  3702 net.cpp:122] Setting up Convolution19
I1006 17:36:08.994228  3702 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 17:36:08.994233  3702 net.cpp:137] Memory required for data: 399840400
I1006 17:36:08.994241  3702 layer_factory.hpp:77] Creating layer BatchNorm19
I1006 17:36:08.994251  3702 net.cpp:84] Creating Layer BatchNorm19
I1006 17:36:08.994258  3702 net.cpp:406] BatchNorm19 <- Convolution19
I1006 17:36:08.994266  3702 net.cpp:367] BatchNorm19 -> Convolution19 (in-place)
I1006 17:36:08.994410  3702 net.cpp:122] Setting up BatchNorm19
I1006 17:36:08.994416  3702 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 17:36:08.994421  3702 net.cpp:137] Memory required for data: 402349200
I1006 17:36:08.994429  3702 layer_factory.hpp:77] Creating layer Scale19
I1006 17:36:08.994438  3702 net.cpp:84] Creating Layer Scale19
I1006 17:36:08.994444  3702 net.cpp:406] Scale19 <- Convolution19
I1006 17:36:08.994449  3702 net.cpp:367] Scale19 -> Convolution19 (in-place)
I1006 17:36:08.994484  3702 layer_factory.hpp:77] Creating layer Scale19
I1006 17:36:08.994568  3702 net.cpp:122] Setting up Scale19
I1006 17:36:08.994575  3702 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 17:36:08.994580  3702 net.cpp:137] Memory required for data: 404858000
I1006 17:36:08.994587  3702 layer_factory.hpp:77] Creating layer penlu18
I1006 17:36:08.994597  3702 net.cpp:84] Creating Layer penlu18
I1006 17:36:08.994601  3702 net.cpp:406] penlu18 <- Convolution19
I1006 17:36:08.994609  3702 net.cpp:367] penlu18 -> Convolution19 (in-place)
I1006 17:36:08.994720  3702 net.cpp:122] Setting up penlu18
I1006 17:36:08.994729  3702 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 17:36:08.994740  3702 net.cpp:137] Memory required for data: 407366800
I1006 17:36:08.994748  3702 layer_factory.hpp:77] Creating layer Convolution20
I1006 17:36:08.994761  3702 net.cpp:84] Creating Layer Convolution20
I1006 17:36:08.994766  3702 net.cpp:406] Convolution20 <- Convolution19
I1006 17:36:08.994773  3702 net.cpp:380] Convolution20 -> Convolution20
I1006 17:36:08.995857  3702 net.cpp:122] Setting up Convolution20
I1006 17:36:08.995869  3702 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 17:36:08.995873  3702 net.cpp:137] Memory required for data: 409875600
I1006 17:36:08.995882  3702 layer_factory.hpp:77] Creating layer BatchNorm20
I1006 17:36:08.995890  3702 net.cpp:84] Creating Layer BatchNorm20
I1006 17:36:08.995895  3702 net.cpp:406] BatchNorm20 <- Convolution20
I1006 17:36:08.995903  3702 net.cpp:367] BatchNorm20 -> Convolution20 (in-place)
I1006 17:36:08.996044  3702 net.cpp:122] Setting up BatchNorm20
I1006 17:36:08.996052  3702 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 17:36:08.996055  3702 net.cpp:137] Memory required for data: 412384400
I1006 17:36:08.996065  3702 layer_factory.hpp:77] Creating layer Scale20
I1006 17:36:08.996073  3702 net.cpp:84] Creating Layer Scale20
I1006 17:36:08.996078  3702 net.cpp:406] Scale20 <- Convolution20
I1006 17:36:08.996085  3702 net.cpp:367] Scale20 -> Convolution20 (in-place)
I1006 17:36:08.996115  3702 layer_factory.hpp:77] Creating layer Scale20
I1006 17:36:08.996192  3702 net.cpp:122] Setting up Scale20
I1006 17:36:08.996197  3702 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 17:36:08.996199  3702 net.cpp:137] Memory required for data: 414893200
I1006 17:36:08.996203  3702 layer_factory.hpp:77] Creating layer Eltwise9
I1006 17:36:08.996207  3702 net.cpp:84] Creating Layer Eltwise9
I1006 17:36:08.996209  3702 net.cpp:406] Eltwise9 <- Eltwise8_penlu17_0_split_1
I1006 17:36:08.996212  3702 net.cpp:406] Eltwise9 <- Convolution20
I1006 17:36:08.996217  3702 net.cpp:380] Eltwise9 -> Eltwise9
I1006 17:36:08.996232  3702 net.cpp:122] Setting up Eltwise9
I1006 17:36:08.996235  3702 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 17:36:08.996237  3702 net.cpp:137] Memory required for data: 417402000
I1006 17:36:08.996240  3702 layer_factory.hpp:77] Creating layer penlu19
I1006 17:36:08.996244  3702 net.cpp:84] Creating Layer penlu19
I1006 17:36:08.996246  3702 net.cpp:406] penlu19 <- Eltwise9
I1006 17:36:08.996250  3702 net.cpp:367] penlu19 -> Eltwise9 (in-place)
I1006 17:36:08.996357  3702 net.cpp:122] Setting up penlu19
I1006 17:36:08.996361  3702 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 17:36:08.996363  3702 net.cpp:137] Memory required for data: 419910800
I1006 17:36:08.996368  3702 layer_factory.hpp:77] Creating layer Eltwise9_penlu19_0_split
I1006 17:36:08.996371  3702 net.cpp:84] Creating Layer Eltwise9_penlu19_0_split
I1006 17:36:08.996373  3702 net.cpp:406] Eltwise9_penlu19_0_split <- Eltwise9
I1006 17:36:08.996376  3702 net.cpp:380] Eltwise9_penlu19_0_split -> Eltwise9_penlu19_0_split_0
I1006 17:36:08.996381  3702 net.cpp:380] Eltwise9_penlu19_0_split -> Eltwise9_penlu19_0_split_1
I1006 17:36:08.996402  3702 net.cpp:122] Setting up Eltwise9_penlu19_0_split
I1006 17:36:08.996407  3702 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 17:36:08.996409  3702 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 17:36:08.996412  3702 net.cpp:137] Memory required for data: 424928400
I1006 17:36:08.996413  3702 layer_factory.hpp:77] Creating layer Convolution21
I1006 17:36:08.996419  3702 net.cpp:84] Creating Layer Convolution21
I1006 17:36:08.996423  3702 net.cpp:406] Convolution21 <- Eltwise9_penlu19_0_split_0
I1006 17:36:08.996425  3702 net.cpp:380] Convolution21 -> Convolution21
I1006 17:36:08.997778  3702 net.cpp:122] Setting up Convolution21
I1006 17:36:08.997787  3702 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 17:36:08.997789  3702 net.cpp:137] Memory required for data: 427437200
I1006 17:36:08.997794  3702 layer_factory.hpp:77] Creating layer BatchNorm21
I1006 17:36:08.997800  3702 net.cpp:84] Creating Layer BatchNorm21
I1006 17:36:08.997809  3702 net.cpp:406] BatchNorm21 <- Convolution21
I1006 17:36:08.997813  3702 net.cpp:367] BatchNorm21 -> Convolution21 (in-place)
I1006 17:36:08.997949  3702 net.cpp:122] Setting up BatchNorm21
I1006 17:36:08.997954  3702 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 17:36:08.997956  3702 net.cpp:137] Memory required for data: 429946000
I1006 17:36:08.997962  3702 layer_factory.hpp:77] Creating layer Scale21
I1006 17:36:08.997967  3702 net.cpp:84] Creating Layer Scale21
I1006 17:36:08.997968  3702 net.cpp:406] Scale21 <- Convolution21
I1006 17:36:08.997972  3702 net.cpp:367] Scale21 -> Convolution21 (in-place)
I1006 17:36:08.997999  3702 layer_factory.hpp:77] Creating layer Scale21
I1006 17:36:08.998076  3702 net.cpp:122] Setting up Scale21
I1006 17:36:08.998080  3702 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 17:36:08.998083  3702 net.cpp:137] Memory required for data: 432454800
I1006 17:36:08.998086  3702 layer_factory.hpp:77] Creating layer penlu20
I1006 17:36:08.998092  3702 net.cpp:84] Creating Layer penlu20
I1006 17:36:08.998095  3702 net.cpp:406] penlu20 <- Convolution21
I1006 17:36:08.998098  3702 net.cpp:367] penlu20 -> Convolution21 (in-place)
I1006 17:36:08.998204  3702 net.cpp:122] Setting up penlu20
I1006 17:36:08.998209  3702 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 17:36:08.998211  3702 net.cpp:137] Memory required for data: 434963600
I1006 17:36:08.998215  3702 layer_factory.hpp:77] Creating layer Convolution22
I1006 17:36:08.998224  3702 net.cpp:84] Creating Layer Convolution22
I1006 17:36:08.998225  3702 net.cpp:406] Convolution22 <- Convolution21
I1006 17:36:08.998229  3702 net.cpp:380] Convolution22 -> Convolution22
I1006 17:36:08.999310  3702 net.cpp:122] Setting up Convolution22
I1006 17:36:08.999318  3702 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 17:36:08.999321  3702 net.cpp:137] Memory required for data: 437472400
I1006 17:36:08.999325  3702 layer_factory.hpp:77] Creating layer BatchNorm22
I1006 17:36:08.999331  3702 net.cpp:84] Creating Layer BatchNorm22
I1006 17:36:08.999333  3702 net.cpp:406] BatchNorm22 <- Convolution22
I1006 17:36:08.999338  3702 net.cpp:367] BatchNorm22 -> Convolution22 (in-place)
I1006 17:36:08.999472  3702 net.cpp:122] Setting up BatchNorm22
I1006 17:36:08.999477  3702 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 17:36:08.999480  3702 net.cpp:137] Memory required for data: 439981200
I1006 17:36:08.999483  3702 layer_factory.hpp:77] Creating layer Scale22
I1006 17:36:08.999488  3702 net.cpp:84] Creating Layer Scale22
I1006 17:36:08.999491  3702 net.cpp:406] Scale22 <- Convolution22
I1006 17:36:08.999495  3702 net.cpp:367] Scale22 -> Convolution22 (in-place)
I1006 17:36:08.999521  3702 layer_factory.hpp:77] Creating layer Scale22
I1006 17:36:08.999598  3702 net.cpp:122] Setting up Scale22
I1006 17:36:08.999601  3702 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 17:36:08.999603  3702 net.cpp:137] Memory required for data: 442490000
I1006 17:36:08.999608  3702 layer_factory.hpp:77] Creating layer Eltwise10
I1006 17:36:08.999611  3702 net.cpp:84] Creating Layer Eltwise10
I1006 17:36:08.999614  3702 net.cpp:406] Eltwise10 <- Eltwise9_penlu19_0_split_1
I1006 17:36:08.999617  3702 net.cpp:406] Eltwise10 <- Convolution22
I1006 17:36:08.999620  3702 net.cpp:380] Eltwise10 -> Eltwise10
I1006 17:36:08.999636  3702 net.cpp:122] Setting up Eltwise10
I1006 17:36:08.999640  3702 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 17:36:08.999642  3702 net.cpp:137] Memory required for data: 444998800
I1006 17:36:08.999644  3702 layer_factory.hpp:77] Creating layer penlu21
I1006 17:36:08.999650  3702 net.cpp:84] Creating Layer penlu21
I1006 17:36:08.999652  3702 net.cpp:406] penlu21 <- Eltwise10
I1006 17:36:08.999655  3702 net.cpp:367] penlu21 -> Eltwise10 (in-place)
I1006 17:36:08.999763  3702 net.cpp:122] Setting up penlu21
I1006 17:36:08.999766  3702 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 17:36:08.999769  3702 net.cpp:137] Memory required for data: 447507600
I1006 17:36:08.999773  3702 layer_factory.hpp:77] Creating layer Eltwise10_penlu21_0_split
I1006 17:36:08.999784  3702 net.cpp:84] Creating Layer Eltwise10_penlu21_0_split
I1006 17:36:08.999788  3702 net.cpp:406] Eltwise10_penlu21_0_split <- Eltwise10
I1006 17:36:08.999790  3702 net.cpp:380] Eltwise10_penlu21_0_split -> Eltwise10_penlu21_0_split_0
I1006 17:36:08.999794  3702 net.cpp:380] Eltwise10_penlu21_0_split -> Eltwise10_penlu21_0_split_1
I1006 17:36:08.999819  3702 net.cpp:122] Setting up Eltwise10_penlu21_0_split
I1006 17:36:08.999822  3702 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 17:36:08.999825  3702 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 17:36:08.999827  3702 net.cpp:137] Memory required for data: 452525200
I1006 17:36:08.999830  3702 layer_factory.hpp:77] Creating layer Convolution23
I1006 17:36:08.999836  3702 net.cpp:84] Creating Layer Convolution23
I1006 17:36:08.999838  3702 net.cpp:406] Convolution23 <- Eltwise10_penlu21_0_split_0
I1006 17:36:08.999842  3702 net.cpp:380] Convolution23 -> Convolution23
I1006 17:36:09.000736  3702 net.cpp:122] Setting up Convolution23
I1006 17:36:09.000744  3702 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 17:36:09.000747  3702 net.cpp:137] Memory required for data: 453779600
I1006 17:36:09.000751  3702 layer_factory.hpp:77] Creating layer BatchNorm23
I1006 17:36:09.000757  3702 net.cpp:84] Creating Layer BatchNorm23
I1006 17:36:09.000759  3702 net.cpp:406] BatchNorm23 <- Convolution23
I1006 17:36:09.000763  3702 net.cpp:367] BatchNorm23 -> Convolution23 (in-place)
I1006 17:36:09.000896  3702 net.cpp:122] Setting up BatchNorm23
I1006 17:36:09.000901  3702 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 17:36:09.000903  3702 net.cpp:137] Memory required for data: 455034000
I1006 17:36:09.000907  3702 layer_factory.hpp:77] Creating layer Scale23
I1006 17:36:09.000912  3702 net.cpp:84] Creating Layer Scale23
I1006 17:36:09.000915  3702 net.cpp:406] Scale23 <- Convolution23
I1006 17:36:09.000917  3702 net.cpp:367] Scale23 -> Convolution23 (in-place)
I1006 17:36:09.000943  3702 layer_factory.hpp:77] Creating layer Scale23
I1006 17:36:09.001020  3702 net.cpp:122] Setting up Scale23
I1006 17:36:09.001025  3702 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 17:36:09.001027  3702 net.cpp:137] Memory required for data: 456288400
I1006 17:36:09.001031  3702 layer_factory.hpp:77] Creating layer Convolution24
I1006 17:36:09.001039  3702 net.cpp:84] Creating Layer Convolution24
I1006 17:36:09.001041  3702 net.cpp:406] Convolution24 <- Eltwise10_penlu21_0_split_1
I1006 17:36:09.001045  3702 net.cpp:380] Convolution24 -> Convolution24
I1006 17:36:09.002811  3702 net.cpp:122] Setting up Convolution24
I1006 17:36:09.002820  3702 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 17:36:09.002822  3702 net.cpp:137] Memory required for data: 457542800
I1006 17:36:09.002827  3702 layer_factory.hpp:77] Creating layer BatchNorm24
I1006 17:36:09.002832  3702 net.cpp:84] Creating Layer BatchNorm24
I1006 17:36:09.002835  3702 net.cpp:406] BatchNorm24 <- Convolution24
I1006 17:36:09.002840  3702 net.cpp:367] BatchNorm24 -> Convolution24 (in-place)
I1006 17:36:09.002974  3702 net.cpp:122] Setting up BatchNorm24
I1006 17:36:09.002979  3702 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 17:36:09.002981  3702 net.cpp:137] Memory required for data: 458797200
I1006 17:36:09.002985  3702 layer_factory.hpp:77] Creating layer Scale24
I1006 17:36:09.002990  3702 net.cpp:84] Creating Layer Scale24
I1006 17:36:09.002993  3702 net.cpp:406] Scale24 <- Convolution24
I1006 17:36:09.002996  3702 net.cpp:367] Scale24 -> Convolution24 (in-place)
I1006 17:36:09.003022  3702 layer_factory.hpp:77] Creating layer Scale24
I1006 17:36:09.003101  3702 net.cpp:122] Setting up Scale24
I1006 17:36:09.003106  3702 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 17:36:09.003108  3702 net.cpp:137] Memory required for data: 460051600
I1006 17:36:09.003113  3702 layer_factory.hpp:77] Creating layer penlu22
I1006 17:36:09.003118  3702 net.cpp:84] Creating Layer penlu22
I1006 17:36:09.003119  3702 net.cpp:406] penlu22 <- Convolution24
I1006 17:36:09.003130  3702 net.cpp:367] penlu22 -> Convolution24 (in-place)
I1006 17:36:09.003265  3702 net.cpp:122] Setting up penlu22
I1006 17:36:09.003271  3702 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 17:36:09.003273  3702 net.cpp:137] Memory required for data: 461306000
I1006 17:36:09.003278  3702 layer_factory.hpp:77] Creating layer Convolution25
I1006 17:36:09.003284  3702 net.cpp:84] Creating Layer Convolution25
I1006 17:36:09.003288  3702 net.cpp:406] Convolution25 <- Convolution24
I1006 17:36:09.003291  3702 net.cpp:380] Convolution25 -> Convolution25
I1006 17:36:09.005252  3702 net.cpp:122] Setting up Convolution25
I1006 17:36:09.005260  3702 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 17:36:09.005264  3702 net.cpp:137] Memory required for data: 462560400
I1006 17:36:09.005267  3702 layer_factory.hpp:77] Creating layer BatchNorm25
I1006 17:36:09.005273  3702 net.cpp:84] Creating Layer BatchNorm25
I1006 17:36:09.005275  3702 net.cpp:406] BatchNorm25 <- Convolution25
I1006 17:36:09.005280  3702 net.cpp:367] BatchNorm25 -> Convolution25 (in-place)
I1006 17:36:09.005419  3702 net.cpp:122] Setting up BatchNorm25
I1006 17:36:09.005424  3702 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 17:36:09.005425  3702 net.cpp:137] Memory required for data: 463814800
I1006 17:36:09.005430  3702 layer_factory.hpp:77] Creating layer Scale25
I1006 17:36:09.005434  3702 net.cpp:84] Creating Layer Scale25
I1006 17:36:09.005436  3702 net.cpp:406] Scale25 <- Convolution25
I1006 17:36:09.005440  3702 net.cpp:367] Scale25 -> Convolution25 (in-place)
I1006 17:36:09.005468  3702 layer_factory.hpp:77] Creating layer Scale25
I1006 17:36:09.005545  3702 net.cpp:122] Setting up Scale25
I1006 17:36:09.005549  3702 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 17:36:09.005551  3702 net.cpp:137] Memory required for data: 465069200
I1006 17:36:09.005554  3702 layer_factory.hpp:77] Creating layer Eltwise11
I1006 17:36:09.005559  3702 net.cpp:84] Creating Layer Eltwise11
I1006 17:36:09.005561  3702 net.cpp:406] Eltwise11 <- Convolution23
I1006 17:36:09.005564  3702 net.cpp:406] Eltwise11 <- Convolution25
I1006 17:36:09.005568  3702 net.cpp:380] Eltwise11 -> Eltwise11
I1006 17:36:09.005584  3702 net.cpp:122] Setting up Eltwise11
I1006 17:36:09.005587  3702 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 17:36:09.005589  3702 net.cpp:137] Memory required for data: 466323600
I1006 17:36:09.005591  3702 layer_factory.hpp:77] Creating layer penlu23
I1006 17:36:09.005597  3702 net.cpp:84] Creating Layer penlu23
I1006 17:36:09.005599  3702 net.cpp:406] penlu23 <- Eltwise11
I1006 17:36:09.005602  3702 net.cpp:367] penlu23 -> Eltwise11 (in-place)
I1006 17:36:09.005712  3702 net.cpp:122] Setting up penlu23
I1006 17:36:09.005717  3702 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 17:36:09.005718  3702 net.cpp:137] Memory required for data: 467578000
I1006 17:36:09.005722  3702 layer_factory.hpp:77] Creating layer Eltwise11_penlu23_0_split
I1006 17:36:09.005726  3702 net.cpp:84] Creating Layer Eltwise11_penlu23_0_split
I1006 17:36:09.005728  3702 net.cpp:406] Eltwise11_penlu23_0_split <- Eltwise11
I1006 17:36:09.005733  3702 net.cpp:380] Eltwise11_penlu23_0_split -> Eltwise11_penlu23_0_split_0
I1006 17:36:09.005736  3702 net.cpp:380] Eltwise11_penlu23_0_split -> Eltwise11_penlu23_0_split_1
I1006 17:36:09.005759  3702 net.cpp:122] Setting up Eltwise11_penlu23_0_split
I1006 17:36:09.005762  3702 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 17:36:09.005765  3702 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 17:36:09.005767  3702 net.cpp:137] Memory required for data: 470086800
I1006 17:36:09.005769  3702 layer_factory.hpp:77] Creating layer Convolution26
I1006 17:36:09.005775  3702 net.cpp:84] Creating Layer Convolution26
I1006 17:36:09.005777  3702 net.cpp:406] Convolution26 <- Eltwise11_penlu23_0_split_0
I1006 17:36:09.005782  3702 net.cpp:380] Convolution26 -> Convolution26
I1006 17:36:09.007462  3702 net.cpp:122] Setting up Convolution26
I1006 17:36:09.007472  3702 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 17:36:09.007480  3702 net.cpp:137] Memory required for data: 471341200
I1006 17:36:09.007485  3702 layer_factory.hpp:77] Creating layer BatchNorm26
I1006 17:36:09.007491  3702 net.cpp:84] Creating Layer BatchNorm26
I1006 17:36:09.007494  3702 net.cpp:406] BatchNorm26 <- Convolution26
I1006 17:36:09.007498  3702 net.cpp:367] BatchNorm26 -> Convolution26 (in-place)
I1006 17:36:09.007634  3702 net.cpp:122] Setting up BatchNorm26
I1006 17:36:09.007638  3702 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 17:36:09.007640  3702 net.cpp:137] Memory required for data: 472595600
I1006 17:36:09.007645  3702 layer_factory.hpp:77] Creating layer Scale26
I1006 17:36:09.007649  3702 net.cpp:84] Creating Layer Scale26
I1006 17:36:09.007652  3702 net.cpp:406] Scale26 <- Convolution26
I1006 17:36:09.007655  3702 net.cpp:367] Scale26 -> Convolution26 (in-place)
I1006 17:36:09.007683  3702 layer_factory.hpp:77] Creating layer Scale26
I1006 17:36:09.007761  3702 net.cpp:122] Setting up Scale26
I1006 17:36:09.007766  3702 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 17:36:09.007768  3702 net.cpp:137] Memory required for data: 473850000
I1006 17:36:09.007772  3702 layer_factory.hpp:77] Creating layer penlu24
I1006 17:36:09.007776  3702 net.cpp:84] Creating Layer penlu24
I1006 17:36:09.007779  3702 net.cpp:406] penlu24 <- Convolution26
I1006 17:36:09.007783  3702 net.cpp:367] penlu24 -> Convolution26 (in-place)
I1006 17:36:09.007894  3702 net.cpp:122] Setting up penlu24
I1006 17:36:09.007899  3702 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 17:36:09.007901  3702 net.cpp:137] Memory required for data: 475104400
I1006 17:36:09.007905  3702 layer_factory.hpp:77] Creating layer Convolution27
I1006 17:36:09.007912  3702 net.cpp:84] Creating Layer Convolution27
I1006 17:36:09.007915  3702 net.cpp:406] Convolution27 <- Convolution26
I1006 17:36:09.007920  3702 net.cpp:380] Convolution27 -> Convolution27
I1006 17:36:09.009563  3702 net.cpp:122] Setting up Convolution27
I1006 17:36:09.009572  3702 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 17:36:09.009575  3702 net.cpp:137] Memory required for data: 476358800
I1006 17:36:09.009579  3702 layer_factory.hpp:77] Creating layer BatchNorm27
I1006 17:36:09.009583  3702 net.cpp:84] Creating Layer BatchNorm27
I1006 17:36:09.009587  3702 net.cpp:406] BatchNorm27 <- Convolution27
I1006 17:36:09.009590  3702 net.cpp:367] BatchNorm27 -> Convolution27 (in-place)
I1006 17:36:09.009732  3702 net.cpp:122] Setting up BatchNorm27
I1006 17:36:09.009735  3702 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 17:36:09.009737  3702 net.cpp:137] Memory required for data: 477613200
I1006 17:36:09.009760  3702 layer_factory.hpp:77] Creating layer Scale27
I1006 17:36:09.009773  3702 net.cpp:84] Creating Layer Scale27
I1006 17:36:09.009776  3702 net.cpp:406] Scale27 <- Convolution27
I1006 17:36:09.009779  3702 net.cpp:367] Scale27 -> Convolution27 (in-place)
I1006 17:36:09.009809  3702 layer_factory.hpp:77] Creating layer Scale27
I1006 17:36:09.009887  3702 net.cpp:122] Setting up Scale27
I1006 17:36:09.009891  3702 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 17:36:09.009894  3702 net.cpp:137] Memory required for data: 478867600
I1006 17:36:09.009898  3702 layer_factory.hpp:77] Creating layer Eltwise12
I1006 17:36:09.009902  3702 net.cpp:84] Creating Layer Eltwise12
I1006 17:36:09.009905  3702 net.cpp:406] Eltwise12 <- Eltwise11_penlu23_0_split_1
I1006 17:36:09.009908  3702 net.cpp:406] Eltwise12 <- Convolution27
I1006 17:36:09.009912  3702 net.cpp:380] Eltwise12 -> Eltwise12
I1006 17:36:09.009932  3702 net.cpp:122] Setting up Eltwise12
I1006 17:36:09.009937  3702 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 17:36:09.009938  3702 net.cpp:137] Memory required for data: 480122000
I1006 17:36:09.009940  3702 layer_factory.hpp:77] Creating layer penlu25
I1006 17:36:09.009945  3702 net.cpp:84] Creating Layer penlu25
I1006 17:36:09.009948  3702 net.cpp:406] penlu25 <- Eltwise12
I1006 17:36:09.009950  3702 net.cpp:367] penlu25 -> Eltwise12 (in-place)
I1006 17:36:09.010063  3702 net.cpp:122] Setting up penlu25
I1006 17:36:09.010073  3702 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 17:36:09.010076  3702 net.cpp:137] Memory required for data: 481376400
I1006 17:36:09.010080  3702 layer_factory.hpp:77] Creating layer Eltwise12_penlu25_0_split
I1006 17:36:09.010085  3702 net.cpp:84] Creating Layer Eltwise12_penlu25_0_split
I1006 17:36:09.010088  3702 net.cpp:406] Eltwise12_penlu25_0_split <- Eltwise12
I1006 17:36:09.010092  3702 net.cpp:380] Eltwise12_penlu25_0_split -> Eltwise12_penlu25_0_split_0
I1006 17:36:09.010095  3702 net.cpp:380] Eltwise12_penlu25_0_split -> Eltwise12_penlu25_0_split_1
I1006 17:36:09.010121  3702 net.cpp:122] Setting up Eltwise12_penlu25_0_split
I1006 17:36:09.010125  3702 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 17:36:09.010128  3702 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 17:36:09.010130  3702 net.cpp:137] Memory required for data: 483885200
I1006 17:36:09.010133  3702 layer_factory.hpp:77] Creating layer Convolution28
I1006 17:36:09.010138  3702 net.cpp:84] Creating Layer Convolution28
I1006 17:36:09.010140  3702 net.cpp:406] Convolution28 <- Eltwise12_penlu25_0_split_0
I1006 17:36:09.010145  3702 net.cpp:380] Convolution28 -> Convolution28
I1006 17:36:09.011821  3702 net.cpp:122] Setting up Convolution28
I1006 17:36:09.011831  3702 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 17:36:09.011833  3702 net.cpp:137] Memory required for data: 485139600
I1006 17:36:09.011837  3702 layer_factory.hpp:77] Creating layer BatchNorm28
I1006 17:36:09.011843  3702 net.cpp:84] Creating Layer BatchNorm28
I1006 17:36:09.011845  3702 net.cpp:406] BatchNorm28 <- Convolution28
I1006 17:36:09.011849  3702 net.cpp:367] BatchNorm28 -> Convolution28 (in-place)
I1006 17:36:09.011987  3702 net.cpp:122] Setting up BatchNorm28
I1006 17:36:09.011991  3702 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 17:36:09.011993  3702 net.cpp:137] Memory required for data: 486394000
I1006 17:36:09.011998  3702 layer_factory.hpp:77] Creating layer Scale28
I1006 17:36:09.012002  3702 net.cpp:84] Creating Layer Scale28
I1006 17:36:09.012004  3702 net.cpp:406] Scale28 <- Convolution28
I1006 17:36:09.012007  3702 net.cpp:367] Scale28 -> Convolution28 (in-place)
I1006 17:36:09.012035  3702 layer_factory.hpp:77] Creating layer Scale28
I1006 17:36:09.012115  3702 net.cpp:122] Setting up Scale28
I1006 17:36:09.012118  3702 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 17:36:09.012120  3702 net.cpp:137] Memory required for data: 487648400
I1006 17:36:09.012125  3702 layer_factory.hpp:77] Creating layer penlu26
I1006 17:36:09.012130  3702 net.cpp:84] Creating Layer penlu26
I1006 17:36:09.012131  3702 net.cpp:406] penlu26 <- Convolution28
I1006 17:36:09.012135  3702 net.cpp:367] penlu26 -> Convolution28 (in-place)
I1006 17:36:09.012248  3702 net.cpp:122] Setting up penlu26
I1006 17:36:09.012253  3702 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 17:36:09.012254  3702 net.cpp:137] Memory required for data: 488902800
I1006 17:36:09.012259  3702 layer_factory.hpp:77] Creating layer Convolution29
I1006 17:36:09.012265  3702 net.cpp:84] Creating Layer Convolution29
I1006 17:36:09.012269  3702 net.cpp:406] Convolution29 <- Convolution28
I1006 17:36:09.012272  3702 net.cpp:380] Convolution29 -> Convolution29
I1006 17:36:09.014236  3702 net.cpp:122] Setting up Convolution29
I1006 17:36:09.014245  3702 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 17:36:09.014247  3702 net.cpp:137] Memory required for data: 490157200
I1006 17:36:09.014251  3702 layer_factory.hpp:77] Creating layer BatchNorm29
I1006 17:36:09.014257  3702 net.cpp:84] Creating Layer BatchNorm29
I1006 17:36:09.014261  3702 net.cpp:406] BatchNorm29 <- Convolution29
I1006 17:36:09.014264  3702 net.cpp:367] BatchNorm29 -> Convolution29 (in-place)
I1006 17:36:09.014407  3702 net.cpp:122] Setting up BatchNorm29
I1006 17:36:09.014412  3702 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 17:36:09.014415  3702 net.cpp:137] Memory required for data: 491411600
I1006 17:36:09.014420  3702 layer_factory.hpp:77] Creating layer Scale29
I1006 17:36:09.014423  3702 net.cpp:84] Creating Layer Scale29
I1006 17:36:09.014433  3702 net.cpp:406] Scale29 <- Convolution29
I1006 17:36:09.014436  3702 net.cpp:367] Scale29 -> Convolution29 (in-place)
I1006 17:36:09.014466  3702 layer_factory.hpp:77] Creating layer Scale29
I1006 17:36:09.014547  3702 net.cpp:122] Setting up Scale29
I1006 17:36:09.014551  3702 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 17:36:09.014554  3702 net.cpp:137] Memory required for data: 492666000
I1006 17:36:09.014557  3702 layer_factory.hpp:77] Creating layer Eltwise13
I1006 17:36:09.014562  3702 net.cpp:84] Creating Layer Eltwise13
I1006 17:36:09.014565  3702 net.cpp:406] Eltwise13 <- Eltwise12_penlu25_0_split_1
I1006 17:36:09.014567  3702 net.cpp:406] Eltwise13 <- Convolution29
I1006 17:36:09.014571  3702 net.cpp:380] Eltwise13 -> Eltwise13
I1006 17:36:09.014587  3702 net.cpp:122] Setting up Eltwise13
I1006 17:36:09.014591  3702 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 17:36:09.014593  3702 net.cpp:137] Memory required for data: 493920400
I1006 17:36:09.014595  3702 layer_factory.hpp:77] Creating layer penlu27
I1006 17:36:09.014601  3702 net.cpp:84] Creating Layer penlu27
I1006 17:36:09.014605  3702 net.cpp:406] penlu27 <- Eltwise13
I1006 17:36:09.014607  3702 net.cpp:367] penlu27 -> Eltwise13 (in-place)
I1006 17:36:09.014719  3702 net.cpp:122] Setting up penlu27
I1006 17:36:09.014722  3702 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 17:36:09.014724  3702 net.cpp:137] Memory required for data: 495174800
I1006 17:36:09.014729  3702 layer_factory.hpp:77] Creating layer Eltwise13_penlu27_0_split
I1006 17:36:09.014732  3702 net.cpp:84] Creating Layer Eltwise13_penlu27_0_split
I1006 17:36:09.014735  3702 net.cpp:406] Eltwise13_penlu27_0_split <- Eltwise13
I1006 17:36:09.014739  3702 net.cpp:380] Eltwise13_penlu27_0_split -> Eltwise13_penlu27_0_split_0
I1006 17:36:09.014742  3702 net.cpp:380] Eltwise13_penlu27_0_split -> Eltwise13_penlu27_0_split_1
I1006 17:36:09.014765  3702 net.cpp:122] Setting up Eltwise13_penlu27_0_split
I1006 17:36:09.014770  3702 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 17:36:09.014772  3702 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 17:36:09.014775  3702 net.cpp:137] Memory required for data: 497683600
I1006 17:36:09.014776  3702 layer_factory.hpp:77] Creating layer Convolution30
I1006 17:36:09.014782  3702 net.cpp:84] Creating Layer Convolution30
I1006 17:36:09.014786  3702 net.cpp:406] Convolution30 <- Eltwise13_penlu27_0_split_0
I1006 17:36:09.014789  3702 net.cpp:380] Convolution30 -> Convolution30
I1006 17:36:09.016479  3702 net.cpp:122] Setting up Convolution30
I1006 17:36:09.016487  3702 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 17:36:09.016489  3702 net.cpp:137] Memory required for data: 498938000
I1006 17:36:09.016494  3702 layer_factory.hpp:77] Creating layer BatchNorm30
I1006 17:36:09.016499  3702 net.cpp:84] Creating Layer BatchNorm30
I1006 17:36:09.016502  3702 net.cpp:406] BatchNorm30 <- Convolution30
I1006 17:36:09.016506  3702 net.cpp:367] BatchNorm30 -> Convolution30 (in-place)
I1006 17:36:09.016645  3702 net.cpp:122] Setting up BatchNorm30
I1006 17:36:09.016649  3702 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 17:36:09.016651  3702 net.cpp:137] Memory required for data: 500192400
I1006 17:36:09.016656  3702 layer_factory.hpp:77] Creating layer Scale30
I1006 17:36:09.016661  3702 net.cpp:84] Creating Layer Scale30
I1006 17:36:09.016664  3702 net.cpp:406] Scale30 <- Convolution30
I1006 17:36:09.016667  3702 net.cpp:367] Scale30 -> Convolution30 (in-place)
I1006 17:36:09.016695  3702 layer_factory.hpp:77] Creating layer Scale30
I1006 17:36:09.016774  3702 net.cpp:122] Setting up Scale30
I1006 17:36:09.016779  3702 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 17:36:09.016782  3702 net.cpp:137] Memory required for data: 501446800
I1006 17:36:09.016785  3702 layer_factory.hpp:77] Creating layer penlu28
I1006 17:36:09.016790  3702 net.cpp:84] Creating Layer penlu28
I1006 17:36:09.016793  3702 net.cpp:406] penlu28 <- Convolution30
I1006 17:36:09.016796  3702 net.cpp:367] penlu28 -> Convolution30 (in-place)
I1006 17:36:09.016916  3702 net.cpp:122] Setting up penlu28
I1006 17:36:09.016921  3702 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 17:36:09.016922  3702 net.cpp:137] Memory required for data: 502701200
I1006 17:36:09.016927  3702 layer_factory.hpp:77] Creating layer Convolution31
I1006 17:36:09.016933  3702 net.cpp:84] Creating Layer Convolution31
I1006 17:36:09.016935  3702 net.cpp:406] Convolution31 <- Convolution30
I1006 17:36:09.016939  3702 net.cpp:380] Convolution31 -> Convolution31
I1006 17:36:09.018913  3702 net.cpp:122] Setting up Convolution31
I1006 17:36:09.018923  3702 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 17:36:09.018924  3702 net.cpp:137] Memory required for data: 503955600
I1006 17:36:09.018929  3702 layer_factory.hpp:77] Creating layer BatchNorm31
I1006 17:36:09.018934  3702 net.cpp:84] Creating Layer BatchNorm31
I1006 17:36:09.018936  3702 net.cpp:406] BatchNorm31 <- Convolution31
I1006 17:36:09.018940  3702 net.cpp:367] BatchNorm31 -> Convolution31 (in-place)
I1006 17:36:09.019083  3702 net.cpp:122] Setting up BatchNorm31
I1006 17:36:09.019088  3702 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 17:36:09.019090  3702 net.cpp:137] Memory required for data: 505210000
I1006 17:36:09.019094  3702 layer_factory.hpp:77] Creating layer Scale31
I1006 17:36:09.019098  3702 net.cpp:84] Creating Layer Scale31
I1006 17:36:09.019101  3702 net.cpp:406] Scale31 <- Convolution31
I1006 17:36:09.019105  3702 net.cpp:367] Scale31 -> Convolution31 (in-place)
I1006 17:36:09.019132  3702 layer_factory.hpp:77] Creating layer Scale31
I1006 17:36:09.019239  3702 net.cpp:122] Setting up Scale31
I1006 17:36:09.019245  3702 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 17:36:09.019248  3702 net.cpp:137] Memory required for data: 506464400
I1006 17:36:09.019251  3702 layer_factory.hpp:77] Creating layer Eltwise14
I1006 17:36:09.019255  3702 net.cpp:84] Creating Layer Eltwise14
I1006 17:36:09.019258  3702 net.cpp:406] Eltwise14 <- Eltwise13_penlu27_0_split_1
I1006 17:36:09.019260  3702 net.cpp:406] Eltwise14 <- Convolution31
I1006 17:36:09.019264  3702 net.cpp:380] Eltwise14 -> Eltwise14
I1006 17:36:09.019280  3702 net.cpp:122] Setting up Eltwise14
I1006 17:36:09.019285  3702 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 17:36:09.019287  3702 net.cpp:137] Memory required for data: 507718800
I1006 17:36:09.019289  3702 layer_factory.hpp:77] Creating layer penlu29
I1006 17:36:09.019294  3702 net.cpp:84] Creating Layer penlu29
I1006 17:36:09.019296  3702 net.cpp:406] penlu29 <- Eltwise14
I1006 17:36:09.019300  3702 net.cpp:367] penlu29 -> Eltwise14 (in-place)
I1006 17:36:09.019413  3702 net.cpp:122] Setting up penlu29
I1006 17:36:09.019418  3702 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 17:36:09.019419  3702 net.cpp:137] Memory required for data: 508973200
I1006 17:36:09.019423  3702 layer_factory.hpp:77] Creating layer Eltwise14_penlu29_0_split
I1006 17:36:09.019428  3702 net.cpp:84] Creating Layer Eltwise14_penlu29_0_split
I1006 17:36:09.019429  3702 net.cpp:406] Eltwise14_penlu29_0_split <- Eltwise14
I1006 17:36:09.019433  3702 net.cpp:380] Eltwise14_penlu29_0_split -> Eltwise14_penlu29_0_split_0
I1006 17:36:09.019436  3702 net.cpp:380] Eltwise14_penlu29_0_split -> Eltwise14_penlu29_0_split_1
I1006 17:36:09.019460  3702 net.cpp:122] Setting up Eltwise14_penlu29_0_split
I1006 17:36:09.019464  3702 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 17:36:09.019466  3702 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 17:36:09.019469  3702 net.cpp:137] Memory required for data: 511482000
I1006 17:36:09.019471  3702 layer_factory.hpp:77] Creating layer Convolution32
I1006 17:36:09.019477  3702 net.cpp:84] Creating Layer Convolution32
I1006 17:36:09.019480  3702 net.cpp:406] Convolution32 <- Eltwise14_penlu29_0_split_0
I1006 17:36:09.019484  3702 net.cpp:380] Convolution32 -> Convolution32
I1006 17:36:09.021152  3702 net.cpp:122] Setting up Convolution32
I1006 17:36:09.021162  3702 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 17:36:09.021163  3702 net.cpp:137] Memory required for data: 512736400
I1006 17:36:09.021174  3702 layer_factory.hpp:77] Creating layer BatchNorm32
I1006 17:36:09.021181  3702 net.cpp:84] Creating Layer BatchNorm32
I1006 17:36:09.021183  3702 net.cpp:406] BatchNorm32 <- Convolution32
I1006 17:36:09.021188  3702 net.cpp:367] BatchNorm32 -> Convolution32 (in-place)
I1006 17:36:09.021330  3702 net.cpp:122] Setting up BatchNorm32
I1006 17:36:09.021334  3702 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 17:36:09.021337  3702 net.cpp:137] Memory required for data: 513990800
I1006 17:36:09.021342  3702 layer_factory.hpp:77] Creating layer Scale32
I1006 17:36:09.021345  3702 net.cpp:84] Creating Layer Scale32
I1006 17:36:09.021347  3702 net.cpp:406] Scale32 <- Convolution32
I1006 17:36:09.021351  3702 net.cpp:367] Scale32 -> Convolution32 (in-place)
I1006 17:36:09.021378  3702 layer_factory.hpp:77] Creating layer Scale32
I1006 17:36:09.021459  3702 net.cpp:122] Setting up Scale32
I1006 17:36:09.021464  3702 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 17:36:09.021466  3702 net.cpp:137] Memory required for data: 515245200
I1006 17:36:09.021471  3702 layer_factory.hpp:77] Creating layer penlu30
I1006 17:36:09.021476  3702 net.cpp:84] Creating Layer penlu30
I1006 17:36:09.021478  3702 net.cpp:406] penlu30 <- Convolution32
I1006 17:36:09.021482  3702 net.cpp:367] penlu30 -> Convolution32 (in-place)
I1006 17:36:09.021594  3702 net.cpp:122] Setting up penlu30
I1006 17:36:09.021598  3702 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 17:36:09.021600  3702 net.cpp:137] Memory required for data: 516499600
I1006 17:36:09.021605  3702 layer_factory.hpp:77] Creating layer Convolution33
I1006 17:36:09.021611  3702 net.cpp:84] Creating Layer Convolution33
I1006 17:36:09.021613  3702 net.cpp:406] Convolution33 <- Convolution32
I1006 17:36:09.021617  3702 net.cpp:380] Convolution33 -> Convolution33
I1006 17:36:09.023620  3702 net.cpp:122] Setting up Convolution33
I1006 17:36:09.023629  3702 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 17:36:09.023633  3702 net.cpp:137] Memory required for data: 517754000
I1006 17:36:09.023636  3702 layer_factory.hpp:77] Creating layer BatchNorm33
I1006 17:36:09.023643  3702 net.cpp:84] Creating Layer BatchNorm33
I1006 17:36:09.023645  3702 net.cpp:406] BatchNorm33 <- Convolution33
I1006 17:36:09.023648  3702 net.cpp:367] BatchNorm33 -> Convolution33 (in-place)
I1006 17:36:09.023792  3702 net.cpp:122] Setting up BatchNorm33
I1006 17:36:09.023797  3702 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 17:36:09.023798  3702 net.cpp:137] Memory required for data: 519008400
I1006 17:36:09.023802  3702 layer_factory.hpp:77] Creating layer Scale33
I1006 17:36:09.023807  3702 net.cpp:84] Creating Layer Scale33
I1006 17:36:09.023809  3702 net.cpp:406] Scale33 <- Convolution33
I1006 17:36:09.023813  3702 net.cpp:367] Scale33 -> Convolution33 (in-place)
I1006 17:36:09.023851  3702 layer_factory.hpp:77] Creating layer Scale33
I1006 17:36:09.023982  3702 net.cpp:122] Setting up Scale33
I1006 17:36:09.023989  3702 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 17:36:09.023993  3702 net.cpp:137] Memory required for data: 520262800
I1006 17:36:09.023999  3702 layer_factory.hpp:77] Creating layer Eltwise15
I1006 17:36:09.024006  3702 net.cpp:84] Creating Layer Eltwise15
I1006 17:36:09.024010  3702 net.cpp:406] Eltwise15 <- Eltwise14_penlu29_0_split_1
I1006 17:36:09.024015  3702 net.cpp:406] Eltwise15 <- Convolution33
I1006 17:36:09.024020  3702 net.cpp:380] Eltwise15 -> Eltwise15
I1006 17:36:09.024039  3702 net.cpp:122] Setting up Eltwise15
I1006 17:36:09.024044  3702 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 17:36:09.024046  3702 net.cpp:137] Memory required for data: 521517200
I1006 17:36:09.024049  3702 layer_factory.hpp:77] Creating layer penlu31
I1006 17:36:09.024055  3702 net.cpp:84] Creating Layer penlu31
I1006 17:36:09.024056  3702 net.cpp:406] penlu31 <- Eltwise15
I1006 17:36:09.024060  3702 net.cpp:367] penlu31 -> Eltwise15 (in-place)
I1006 17:36:09.024176  3702 net.cpp:122] Setting up penlu31
I1006 17:36:09.024180  3702 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 17:36:09.024189  3702 net.cpp:137] Memory required for data: 522771600
I1006 17:36:09.024194  3702 layer_factory.hpp:77] Creating layer Pooling1
I1006 17:36:09.024199  3702 net.cpp:84] Creating Layer Pooling1
I1006 17:36:09.024202  3702 net.cpp:406] Pooling1 <- Eltwise15
I1006 17:36:09.024205  3702 net.cpp:380] Pooling1 -> Pooling1
I1006 17:36:09.024364  3702 net.cpp:122] Setting up Pooling1
I1006 17:36:09.024371  3702 net.cpp:129] Top shape: 100 64 1 1 (6400)
I1006 17:36:09.024374  3702 net.cpp:137] Memory required for data: 522797200
I1006 17:36:09.024376  3702 layer_factory.hpp:77] Creating layer InnerProduct1
I1006 17:36:09.024385  3702 net.cpp:84] Creating Layer InnerProduct1
I1006 17:36:09.024387  3702 net.cpp:406] InnerProduct1 <- Pooling1
I1006 17:36:09.024392  3702 net.cpp:380] InnerProduct1 -> InnerProduct1
I1006 17:36:09.024492  3702 net.cpp:122] Setting up InnerProduct1
I1006 17:36:09.024497  3702 net.cpp:129] Top shape: 100 10 (1000)
I1006 17:36:09.024499  3702 net.cpp:137] Memory required for data: 522801200
I1006 17:36:09.024503  3702 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I1006 17:36:09.024508  3702 net.cpp:84] Creating Layer SoftmaxWithLoss1
I1006 17:36:09.024510  3702 net.cpp:406] SoftmaxWithLoss1 <- InnerProduct1
I1006 17:36:09.024513  3702 net.cpp:406] SoftmaxWithLoss1 <- Data2
I1006 17:36:09.024518  3702 net.cpp:380] SoftmaxWithLoss1 -> SoftmaxWithLoss1
I1006 17:36:09.024523  3702 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I1006 17:36:09.024710  3702 net.cpp:122] Setting up SoftmaxWithLoss1
I1006 17:36:09.024718  3702 net.cpp:129] Top shape: (1)
I1006 17:36:09.024719  3702 net.cpp:132]     with loss weight 1
I1006 17:36:09.024731  3702 net.cpp:137] Memory required for data: 522801204
I1006 17:36:09.024734  3702 net.cpp:198] SoftmaxWithLoss1 needs backward computation.
I1006 17:36:09.024736  3702 net.cpp:198] InnerProduct1 needs backward computation.
I1006 17:36:09.024739  3702 net.cpp:198] Pooling1 needs backward computation.
I1006 17:36:09.024741  3702 net.cpp:198] penlu31 needs backward computation.
I1006 17:36:09.024744  3702 net.cpp:198] Eltwise15 needs backward computation.
I1006 17:36:09.024745  3702 net.cpp:198] Scale33 needs backward computation.
I1006 17:36:09.024747  3702 net.cpp:198] BatchNorm33 needs backward computation.
I1006 17:36:09.024749  3702 net.cpp:198] Convolution33 needs backward computation.
I1006 17:36:09.024751  3702 net.cpp:198] penlu30 needs backward computation.
I1006 17:36:09.024755  3702 net.cpp:198] Scale32 needs backward computation.
I1006 17:36:09.024756  3702 net.cpp:198] BatchNorm32 needs backward computation.
I1006 17:36:09.024757  3702 net.cpp:198] Convolution32 needs backward computation.
I1006 17:36:09.024760  3702 net.cpp:198] Eltwise14_penlu29_0_split needs backward computation.
I1006 17:36:09.024762  3702 net.cpp:198] penlu29 needs backward computation.
I1006 17:36:09.024765  3702 net.cpp:198] Eltwise14 needs backward computation.
I1006 17:36:09.024767  3702 net.cpp:198] Scale31 needs backward computation.
I1006 17:36:09.024770  3702 net.cpp:198] BatchNorm31 needs backward computation.
I1006 17:36:09.024771  3702 net.cpp:198] Convolution31 needs backward computation.
I1006 17:36:09.024773  3702 net.cpp:198] penlu28 needs backward computation.
I1006 17:36:09.024775  3702 net.cpp:198] Scale30 needs backward computation.
I1006 17:36:09.024777  3702 net.cpp:198] BatchNorm30 needs backward computation.
I1006 17:36:09.024780  3702 net.cpp:198] Convolution30 needs backward computation.
I1006 17:36:09.024781  3702 net.cpp:198] Eltwise13_penlu27_0_split needs backward computation.
I1006 17:36:09.024783  3702 net.cpp:198] penlu27 needs backward computation.
I1006 17:36:09.024785  3702 net.cpp:198] Eltwise13 needs backward computation.
I1006 17:36:09.024788  3702 net.cpp:198] Scale29 needs backward computation.
I1006 17:36:09.024791  3702 net.cpp:198] BatchNorm29 needs backward computation.
I1006 17:36:09.024792  3702 net.cpp:198] Convolution29 needs backward computation.
I1006 17:36:09.024794  3702 net.cpp:198] penlu26 needs backward computation.
I1006 17:36:09.024802  3702 net.cpp:198] Scale28 needs backward computation.
I1006 17:36:09.024804  3702 net.cpp:198] BatchNorm28 needs backward computation.
I1006 17:36:09.024806  3702 net.cpp:198] Convolution28 needs backward computation.
I1006 17:36:09.024808  3702 net.cpp:198] Eltwise12_penlu25_0_split needs backward computation.
I1006 17:36:09.024811  3702 net.cpp:198] penlu25 needs backward computation.
I1006 17:36:09.024813  3702 net.cpp:198] Eltwise12 needs backward computation.
I1006 17:36:09.024816  3702 net.cpp:198] Scale27 needs backward computation.
I1006 17:36:09.024817  3702 net.cpp:198] BatchNorm27 needs backward computation.
I1006 17:36:09.024819  3702 net.cpp:198] Convolution27 needs backward computation.
I1006 17:36:09.024821  3702 net.cpp:198] penlu24 needs backward computation.
I1006 17:36:09.024824  3702 net.cpp:198] Scale26 needs backward computation.
I1006 17:36:09.024827  3702 net.cpp:198] BatchNorm26 needs backward computation.
I1006 17:36:09.024828  3702 net.cpp:198] Convolution26 needs backward computation.
I1006 17:36:09.024830  3702 net.cpp:198] Eltwise11_penlu23_0_split needs backward computation.
I1006 17:36:09.024832  3702 net.cpp:198] penlu23 needs backward computation.
I1006 17:36:09.024834  3702 net.cpp:198] Eltwise11 needs backward computation.
I1006 17:36:09.024838  3702 net.cpp:198] Scale25 needs backward computation.
I1006 17:36:09.024840  3702 net.cpp:198] BatchNorm25 needs backward computation.
I1006 17:36:09.024842  3702 net.cpp:198] Convolution25 needs backward computation.
I1006 17:36:09.024844  3702 net.cpp:198] penlu22 needs backward computation.
I1006 17:36:09.024847  3702 net.cpp:198] Scale24 needs backward computation.
I1006 17:36:09.024848  3702 net.cpp:198] BatchNorm24 needs backward computation.
I1006 17:36:09.024850  3702 net.cpp:198] Convolution24 needs backward computation.
I1006 17:36:09.024852  3702 net.cpp:198] Scale23 needs backward computation.
I1006 17:36:09.024855  3702 net.cpp:198] BatchNorm23 needs backward computation.
I1006 17:36:09.024857  3702 net.cpp:198] Convolution23 needs backward computation.
I1006 17:36:09.024859  3702 net.cpp:198] Eltwise10_penlu21_0_split needs backward computation.
I1006 17:36:09.024861  3702 net.cpp:198] penlu21 needs backward computation.
I1006 17:36:09.024863  3702 net.cpp:198] Eltwise10 needs backward computation.
I1006 17:36:09.024866  3702 net.cpp:198] Scale22 needs backward computation.
I1006 17:36:09.024868  3702 net.cpp:198] BatchNorm22 needs backward computation.
I1006 17:36:09.024870  3702 net.cpp:198] Convolution22 needs backward computation.
I1006 17:36:09.024873  3702 net.cpp:198] penlu20 needs backward computation.
I1006 17:36:09.024875  3702 net.cpp:198] Scale21 needs backward computation.
I1006 17:36:09.024878  3702 net.cpp:198] BatchNorm21 needs backward computation.
I1006 17:36:09.024879  3702 net.cpp:198] Convolution21 needs backward computation.
I1006 17:36:09.024881  3702 net.cpp:198] Eltwise9_penlu19_0_split needs backward computation.
I1006 17:36:09.024884  3702 net.cpp:198] penlu19 needs backward computation.
I1006 17:36:09.024886  3702 net.cpp:198] Eltwise9 needs backward computation.
I1006 17:36:09.024888  3702 net.cpp:198] Scale20 needs backward computation.
I1006 17:36:09.024891  3702 net.cpp:198] BatchNorm20 needs backward computation.
I1006 17:36:09.024893  3702 net.cpp:198] Convolution20 needs backward computation.
I1006 17:36:09.024895  3702 net.cpp:198] penlu18 needs backward computation.
I1006 17:36:09.024897  3702 net.cpp:198] Scale19 needs backward computation.
I1006 17:36:09.024899  3702 net.cpp:198] BatchNorm19 needs backward computation.
I1006 17:36:09.024902  3702 net.cpp:198] Convolution19 needs backward computation.
I1006 17:36:09.024904  3702 net.cpp:198] Eltwise8_penlu17_0_split needs backward computation.
I1006 17:36:09.024907  3702 net.cpp:198] penlu17 needs backward computation.
I1006 17:36:09.024909  3702 net.cpp:198] Eltwise8 needs backward computation.
I1006 17:36:09.024911  3702 net.cpp:198] Scale18 needs backward computation.
I1006 17:36:09.024914  3702 net.cpp:198] BatchNorm18 needs backward computation.
I1006 17:36:09.024920  3702 net.cpp:198] Convolution18 needs backward computation.
I1006 17:36:09.024922  3702 net.cpp:198] penlu16 needs backward computation.
I1006 17:36:09.024924  3702 net.cpp:198] Scale17 needs backward computation.
I1006 17:36:09.024927  3702 net.cpp:198] BatchNorm17 needs backward computation.
I1006 17:36:09.024930  3702 net.cpp:198] Convolution17 needs backward computation.
I1006 17:36:09.024931  3702 net.cpp:198] Eltwise7_penlu15_0_split needs backward computation.
I1006 17:36:09.024933  3702 net.cpp:198] penlu15 needs backward computation.
I1006 17:36:09.024936  3702 net.cpp:198] Eltwise7 needs backward computation.
I1006 17:36:09.024938  3702 net.cpp:198] Scale16 needs backward computation.
I1006 17:36:09.024940  3702 net.cpp:198] BatchNorm16 needs backward computation.
I1006 17:36:09.024943  3702 net.cpp:198] Convolution16 needs backward computation.
I1006 17:36:09.024945  3702 net.cpp:198] penlu14 needs backward computation.
I1006 17:36:09.024948  3702 net.cpp:198] Scale15 needs backward computation.
I1006 17:36:09.024950  3702 net.cpp:198] BatchNorm15 needs backward computation.
I1006 17:36:09.024952  3702 net.cpp:198] Convolution15 needs backward computation.
I1006 17:36:09.024955  3702 net.cpp:198] Eltwise6_penlu13_0_split needs backward computation.
I1006 17:36:09.024957  3702 net.cpp:198] penlu13 needs backward computation.
I1006 17:36:09.024960  3702 net.cpp:198] Eltwise6 needs backward computation.
I1006 17:36:09.024962  3702 net.cpp:198] Scale14 needs backward computation.
I1006 17:36:09.024965  3702 net.cpp:198] BatchNorm14 needs backward computation.
I1006 17:36:09.024966  3702 net.cpp:198] Convolution14 needs backward computation.
I1006 17:36:09.024969  3702 net.cpp:198] penlu12 needs backward computation.
I1006 17:36:09.024971  3702 net.cpp:198] Scale13 needs backward computation.
I1006 17:36:09.024974  3702 net.cpp:198] BatchNorm13 needs backward computation.
I1006 17:36:09.024976  3702 net.cpp:198] Convolution13 needs backward computation.
I1006 17:36:09.024978  3702 net.cpp:198] Scale12 needs backward computation.
I1006 17:36:09.024981  3702 net.cpp:198] BatchNorm12 needs backward computation.
I1006 17:36:09.024983  3702 net.cpp:198] Convolution12 needs backward computation.
I1006 17:36:09.024986  3702 net.cpp:198] Eltwise5_penlu11_0_split needs backward computation.
I1006 17:36:09.024987  3702 net.cpp:198] penlu11 needs backward computation.
I1006 17:36:09.024991  3702 net.cpp:198] Eltwise5 needs backward computation.
I1006 17:36:09.024992  3702 net.cpp:198] Scale11 needs backward computation.
I1006 17:36:09.024994  3702 net.cpp:198] BatchNorm11 needs backward computation.
I1006 17:36:09.024999  3702 net.cpp:198] Convolution11 needs backward computation.
I1006 17:36:09.025002  3702 net.cpp:198] penlu10 needs backward computation.
I1006 17:36:09.025003  3702 net.cpp:198] Scale10 needs backward computation.
I1006 17:36:09.025005  3702 net.cpp:198] BatchNorm10 needs backward computation.
I1006 17:36:09.025008  3702 net.cpp:198] Convolution10 needs backward computation.
I1006 17:36:09.025010  3702 net.cpp:198] Eltwise4_penlu9_0_split needs backward computation.
I1006 17:36:09.025012  3702 net.cpp:198] penlu9 needs backward computation.
I1006 17:36:09.025015  3702 net.cpp:198] Eltwise4 needs backward computation.
I1006 17:36:09.025018  3702 net.cpp:198] Scale9 needs backward computation.
I1006 17:36:09.025020  3702 net.cpp:198] BatchNorm9 needs backward computation.
I1006 17:36:09.025022  3702 net.cpp:198] Convolution9 needs backward computation.
I1006 17:36:09.025025  3702 net.cpp:198] penlu8 needs backward computation.
I1006 17:36:09.025027  3702 net.cpp:198] Scale8 needs backward computation.
I1006 17:36:09.025029  3702 net.cpp:198] BatchNorm8 needs backward computation.
I1006 17:36:09.025032  3702 net.cpp:198] Convolution8 needs backward computation.
I1006 17:36:09.025034  3702 net.cpp:198] Eltwise3_penlu7_0_split needs backward computation.
I1006 17:36:09.025037  3702 net.cpp:198] penlu7 needs backward computation.
I1006 17:36:09.025043  3702 net.cpp:198] Eltwise3 needs backward computation.
I1006 17:36:09.025045  3702 net.cpp:198] Scale7 needs backward computation.
I1006 17:36:09.025048  3702 net.cpp:198] BatchNorm7 needs backward computation.
I1006 17:36:09.025049  3702 net.cpp:198] Convolution7 needs backward computation.
I1006 17:36:09.025053  3702 net.cpp:198] penlu6 needs backward computation.
I1006 17:36:09.025054  3702 net.cpp:198] Scale6 needs backward computation.
I1006 17:36:09.025056  3702 net.cpp:198] BatchNorm6 needs backward computation.
I1006 17:36:09.025058  3702 net.cpp:198] Convolution6 needs backward computation.
I1006 17:36:09.025061  3702 net.cpp:198] Eltwise2_penlu5_0_split needs backward computation.
I1006 17:36:09.025063  3702 net.cpp:198] penlu5 needs backward computation.
I1006 17:36:09.025075  3702 net.cpp:198] Eltwise2 needs backward computation.
I1006 17:36:09.025079  3702 net.cpp:198] Scale5 needs backward computation.
I1006 17:36:09.025080  3702 net.cpp:198] BatchNorm5 needs backward computation.
I1006 17:36:09.025082  3702 net.cpp:198] Convolution5 needs backward computation.
I1006 17:36:09.025084  3702 net.cpp:198] penlu4 needs backward computation.
I1006 17:36:09.025086  3702 net.cpp:198] Scale4 needs backward computation.
I1006 17:36:09.025089  3702 net.cpp:198] BatchNorm4 needs backward computation.
I1006 17:36:09.025091  3702 net.cpp:198] Convolution4 needs backward computation.
I1006 17:36:09.025094  3702 net.cpp:198] Eltwise1_penlu3_0_split needs backward computation.
I1006 17:36:09.025095  3702 net.cpp:198] penlu3 needs backward computation.
I1006 17:36:09.025099  3702 net.cpp:198] Eltwise1 needs backward computation.
I1006 17:36:09.025100  3702 net.cpp:198] Scale3 needs backward computation.
I1006 17:36:09.025104  3702 net.cpp:198] BatchNorm3 needs backward computation.
I1006 17:36:09.025105  3702 net.cpp:198] Convolution3 needs backward computation.
I1006 17:36:09.025108  3702 net.cpp:198] penlu2 needs backward computation.
I1006 17:36:09.025120  3702 net.cpp:198] Scale2 needs backward computation.
I1006 17:36:09.025122  3702 net.cpp:198] BatchNorm2 needs backward computation.
I1006 17:36:09.025125  3702 net.cpp:198] Convolution2 needs backward computation.
I1006 17:36:09.025127  3702 net.cpp:198] Convolution1_penlu1_0_split needs backward computation.
I1006 17:36:09.025130  3702 net.cpp:198] penlu1 needs backward computation.
I1006 17:36:09.025132  3702 net.cpp:198] Scale1 needs backward computation.
I1006 17:36:09.025135  3702 net.cpp:198] BatchNorm1 needs backward computation.
I1006 17:36:09.025136  3702 net.cpp:198] Convolution1 needs backward computation.
I1006 17:36:09.025140  3702 net.cpp:200] Data1 does not need backward computation.
I1006 17:36:09.025141  3702 net.cpp:242] This network produces output SoftmaxWithLoss1
I1006 17:36:09.025194  3702 net.cpp:255] Network initialization done.
I1006 17:36:09.028053  3702 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: /home/x306/caffe/xn/PENLU/neural/resnet/res32/res32_penlu_decay_gauss.prototxt
I1006 17:36:09.028064  3702 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I1006 17:36:09.028067  3702 solver.cpp:172] Creating test net (#0) specified by net file: /home/x306/caffe/xn/PENLU/neural/resnet/res32/res32_penlu_decay_gauss.prototxt
I1006 17:36:09.028183  3702 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer Data1
I1006 17:36:09.028928  3702 net.cpp:51] Initializing net from parameters: 
name: "resnet_cifar10"
state {
  phase: TEST
}
layer {
  name: "Data1"
  type: "Data"
  top: "Data1"
  top: "Data2"
  include {
    phase: TEST
  }
  transform_param {
    mean_file: "/home/x306/caffe/xn/PENLU/data/cifar10/mean.binaryproto"
  }
  data_param {
    source: "/home/x306/caffe/xn/PENLU/data/cifar10/cifar10_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "Convolution1"
  type: "Convolution"
  bottom: "Data1"
  top: "Convolution1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm1"
  type: "BatchNorm"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1"
  type: "Scale"
  bottom: "Convolution1"
  top: "Convolution1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu1"
  type: "PENLU"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution2"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm2"
  type: "BatchNorm"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale2"
  type: "Scale"
  bottom: "Convolution2"
  top: "Convolution2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu2"
  type: "PENLU"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution3"
  type: "Convolution"
  bottom: "Convolution2"
  top: "Convolution3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm3"
  type: "BatchNorm"
  bottom: "Convolution3"
  top: "Convolution3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale3"
  type: "Scale"
  bottom: "Convolution3"
  top: "Convolution3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise1"
  type: "Eltwise"
  bottom: "Convolution1"
  bottom: "Convolution3"
  top: "Eltwise1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu3"
  type: "PENLU"
  bottom: "Eltwise1"
  top: "Eltwise1"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution4"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm4"
  type: "BatchNorm"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale4"
  type: "Scale"
  bottom: "Convolution4"
  top: "Convolution4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu4"
  type: "PENLU"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution5"
  type: "Convolution"
  bottom: "Convolution4"
  top: "Convolution5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm5"
  type: "BatchNorm"
  bottom: "Convolution5"
  top: "Convolution5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale5"
  type: "Scale"
  bottom: "Convolution5"
  top: "Convolution5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise2"
  type: "Eltwise"
  bottom: "Eltwise1"
  bottom: "Convolution5"
  top: "Eltwise2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu5"
  type: "PENLU"
  bottom: "Eltwise2"
  top: "Eltwise2"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution6"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm6"
  type: "BatchNorm"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale6"
  type: "Scale"
  bottom: "Convolution6"
  top: "Convolution6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu6"
  type: "PENLU"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution7"
  type: "Convolution"
  bottom: "Convolution6"
  top: "Convolution7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm7"
  type: "BatchNorm"
  bottom: "Convolution7"
  top: "Convolution7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale7"
  type: "Scale"
  bottom: "Convolution7"
  top: "Convolution7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise3"
  type: "Eltwise"
  bottom: "Eltwise2"
  bottom: "Convolution7"
  top: "Eltwise3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu7"
  type: "PENLU"
  bottom: "Eltwise3"
  top: "Eltwise3"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution8"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm8"
  type: "BatchNorm"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale8"
  type: "Scale"
  bottom: "Convolution8"
  top: "Convolution8"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu8"
  type: "PENLU"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution9"
  type: "Convolution"
  bottom: "Convolution8"
  top: "Convolution9"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm9"
  type: "BatchNorm"
  bottom: "Convolution9"
  top: "Convolution9"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale9"
  type: "Scale"
  bottom: "Convolution9"
  top: "Convolution9"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise4"
  type: "Eltwise"
  bottom: "Eltwise3"
  bottom: "Convolution9"
  top: "Eltwise4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu9"
  type: "PENLU"
  bottom: "Eltwise4"
  top: "Eltwise4"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution10"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution10"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm10"
  type: "BatchNorm"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale10"
  type: "Scale"
  bottom: "Convolution10"
  top: "Convolution10"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu10"
  type: "PENLU"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution11"
  type: "Convolution"
  bottom: "Convolution10"
  top: "Convolution11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm11"
  type: "BatchNorm"
  bottom: "Convolution11"
  top: "Convolution11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale11"
  type: "Scale"
  bottom: "Convolution11"
  top: "Convolution11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise5"
  type: "Eltwise"
  bottom: "Eltwise4"
  bottom: "Convolution11"
  top: "Eltwise5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu11"
  type: "PENLU"
  bottom: "Eltwise5"
  top: "Eltwise5"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution12"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.25
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm12"
  type: "BatchNorm"
  bottom: "Convolution12"
  top: "Convolution12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale12"
  type: "Scale"
  bottom: "Convolution12"
  top: "Convolution12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution13"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution13"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm13"
  type: "BatchNorm"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale13"
  type: "Scale"
  bottom: "Convolution13"
  top: "Convolution13"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu12"
  type: "PENLU"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution14"
  type: "Convolution"
  bottom: "Convolution13"
  top: "Convolution14"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm14"
  type: "BatchNorm"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale14"
  type: "Scale"
  bottom: "Convolution14"
  top: "Convolution14"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise6"
  type: "Eltwise"
  bottom: "Convolution12"
  bottom: "Convolution14"
  top: "Eltwise6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu13"
  type: "PENLU"
  bottom: "Eltwise6"
  top: "Eltwise6"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution15"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution15"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm15"
  type: "BatchNorm"
  bottom: "Convolution15"
  top: "Convolution15"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale15"
  type: "Scale"
  bottom: "Convolution15"
  top: "Convolution15"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu14"
  type: "PENLU"
  bottom: "Convolution15"
  top: "Convolution15"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution16"
  type: "Convolution"
  bottom: "Convolution15"
  top: "Convolution16"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm16"
  type: "BatchNorm"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale16"
  type: "Scale"
  bottom: "Convolution16"
  top: "Convolution16"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise7"
  type: "Eltwise"
  bottom: "Eltwise6"
  bottom: "Convolution16"
  top: "Eltwise7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu15"
  type: "PENLU"
  bottom: "Eltwise7"
  top: "Eltwise7"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution17"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution17"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm17"
  type: "BatchNorm"
  bottom: "Convolution17"
  top: "Convolution17"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale17"
  type: "Scale"
  bottom: "Convolution17"
  top: "Convolution17"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu16"
  type: "PENLU"
  bottom: "Convolution17"
  top: "Convolution17"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution18"
  type: "Convolution"
  bottom: "Convolution17"
  top: "Convolution18"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm18"
  type: "BatchNorm"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale18"
  type: "Scale"
  bottom: "Convolution18"
  top: "Convolution18"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise8"
  type: "Eltwise"
  bottom: "Eltwise7"
  bottom: "Convolution18"
  top: "Eltwise8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu17"
  type: "PENLU"
  bottom: "Eltwise8"
  top: "Eltwise8"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution19"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution19"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm19"
  type: "BatchNorm"
  bottom: "Convolution19"
  top: "Convolution19"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale19"
  type: "Scale"
  bottom: "Convolution19"
  top: "Convolution19"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu18"
  type: "PENLU"
  bottom: "Convolution19"
  top: "Convolution19"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution20"
  type: "Convolution"
  bottom: "Convolution19"
  top: "Convolution20"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm20"
  type: "BatchNorm"
  bottom: "Convolution20"
  top: "Convolution20"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale20"
  type: "Scale"
  bottom: "Convolution20"
  top: "Convolution20"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise9"
  type: "Eltwise"
  bottom: "Eltwise8"
  bottom: "Convolution20"
  top: "Eltwise9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu19"
  type: "PENLU"
  bottom: "Eltwise9"
  top: "Eltwise9"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution21"
  type: "Convolution"
  bottom: "Eltwise9"
  top: "Convolution21"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm21"
  type: "BatchNorm"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale21"
  type: "Scale"
  bottom: "Convolution21"
  top: "Convolution21"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu20"
  type: "PENLU"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution22"
  type: "Convolution"
  bottom: "Convolution21"
  top: "Convolution22"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm22"
  type: "BatchNorm"
  bottom: "Convolution22"
  top: "Convolution22"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale22"
  type: "Scale"
  bottom: "Convolution22"
  top: "Convolution22"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise10"
  type: "Eltwise"
  bottom: "Eltwise9"
  bottom: "Convolution22"
  top: "Eltwise10"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu21"
  type: "PENLU"
  bottom: "Eltwise10"
  top: "Eltwise10"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution23"
  type: "Convolution"
  bottom: "Eltwise10"
  top: "Convolution23"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.17677669
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm23"
  type: "BatchNorm"
  bottom: "Convolution23"
  top: "Convolution23"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale23"
  type: "Scale"
  bottom: "Convolution23"
  top: "Convolution23"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution24"
  type: "Convolution"
  bottom: "Eltwise10"
  top: "Convolution24"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm24"
  type: "BatchNorm"
  bottom: "Convolution24"
  top: "Convolution24"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale24"
  type: "Scale"
  bottom: "Convolution24"
  top: "Convolution24"
  scale_param {
    bi
I1006 17:36:09.029338  3702 layer_factory.hpp:77] Creating layer Data1
I1006 17:36:09.054451  3702 db_lmdb.cpp:35] Opened lmdb /home/x306/caffe/xn/PENLU/data/cifar10/cifar10_test_lmdb
I1006 17:36:09.054469  3702 net.cpp:84] Creating Layer Data1
I1006 17:36:09.054477  3702 net.cpp:380] Data1 -> Data1
I1006 17:36:09.054487  3702 net.cpp:380] Data1 -> Data2
I1006 17:36:09.054496  3702 data_transformer.cpp:25] Loading mean file from: /home/x306/caffe/xn/PENLU/data/cifar10/mean.binaryproto
I1006 17:36:09.054648  3702 data_layer.cpp:45] output data size: 100,3,32,32
I1006 17:36:09.058933  3702 net.cpp:122] Setting up Data1
I1006 17:36:09.058954  3702 net.cpp:129] Top shape: 100 3 32 32 (307200)
I1006 17:36:09.058959  3702 net.cpp:129] Top shape: 100 (100)
I1006 17:36:09.058960  3702 net.cpp:137] Memory required for data: 1229200
I1006 17:36:09.058964  3702 layer_factory.hpp:77] Creating layer Data2_Data1_1_split
I1006 17:36:09.058974  3702 net.cpp:84] Creating Layer Data2_Data1_1_split
I1006 17:36:09.058976  3702 net.cpp:406] Data2_Data1_1_split <- Data2
I1006 17:36:09.058981  3702 net.cpp:380] Data2_Data1_1_split -> Data2_Data1_1_split_0
I1006 17:36:09.058989  3702 net.cpp:380] Data2_Data1_1_split -> Data2_Data1_1_split_1
I1006 17:36:09.059037  3702 net.cpp:122] Setting up Data2_Data1_1_split
I1006 17:36:09.059043  3702 net.cpp:129] Top shape: 100 (100)
I1006 17:36:09.059046  3702 net.cpp:129] Top shape: 100 (100)
I1006 17:36:09.059048  3702 net.cpp:137] Memory required for data: 1230000
I1006 17:36:09.059051  3702 layer_factory.hpp:77] Creating layer Convolution1
I1006 17:36:09.059062  3702 net.cpp:84] Creating Layer Convolution1
I1006 17:36:09.059064  3702 net.cpp:406] Convolution1 <- Data1
I1006 17:36:09.059068  3702 net.cpp:380] Convolution1 -> Convolution1
I1006 17:36:09.060307  3702 net.cpp:122] Setting up Convolution1
I1006 17:36:09.060318  3702 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 17:36:09.060322  3702 net.cpp:137] Memory required for data: 7783600
I1006 17:36:09.060329  3702 layer_factory.hpp:77] Creating layer BatchNorm1
I1006 17:36:09.060336  3702 net.cpp:84] Creating Layer BatchNorm1
I1006 17:36:09.060343  3702 net.cpp:406] BatchNorm1 <- Convolution1
I1006 17:36:09.060345  3702 net.cpp:367] BatchNorm1 -> Convolution1 (in-place)
I1006 17:36:09.060489  3702 net.cpp:122] Setting up BatchNorm1
I1006 17:36:09.060494  3702 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 17:36:09.060497  3702 net.cpp:137] Memory required for data: 14337200
I1006 17:36:09.060503  3702 layer_factory.hpp:77] Creating layer Scale1
I1006 17:36:09.060510  3702 net.cpp:84] Creating Layer Scale1
I1006 17:36:09.060513  3702 net.cpp:406] Scale1 <- Convolution1
I1006 17:36:09.060518  3702 net.cpp:367] Scale1 -> Convolution1 (in-place)
I1006 17:36:09.060547  3702 layer_factory.hpp:77] Creating layer Scale1
I1006 17:36:09.060628  3702 net.cpp:122] Setting up Scale1
I1006 17:36:09.060633  3702 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 17:36:09.060636  3702 net.cpp:137] Memory required for data: 20890800
I1006 17:36:09.060641  3702 layer_factory.hpp:77] Creating layer penlu1
I1006 17:36:09.060645  3702 net.cpp:84] Creating Layer penlu1
I1006 17:36:09.060648  3702 net.cpp:406] penlu1 <- Convolution1
I1006 17:36:09.060652  3702 net.cpp:367] penlu1 -> Convolution1 (in-place)
I1006 17:36:09.060786  3702 net.cpp:122] Setting up penlu1
I1006 17:36:09.060802  3702 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 17:36:09.060806  3702 net.cpp:137] Memory required for data: 27444400
I1006 17:36:09.060812  3702 layer_factory.hpp:77] Creating layer Convolution1_penlu1_0_split
I1006 17:36:09.060817  3702 net.cpp:84] Creating Layer Convolution1_penlu1_0_split
I1006 17:36:09.060818  3702 net.cpp:406] Convolution1_penlu1_0_split <- Convolution1
I1006 17:36:09.060822  3702 net.cpp:380] Convolution1_penlu1_0_split -> Convolution1_penlu1_0_split_0
I1006 17:36:09.060827  3702 net.cpp:380] Convolution1_penlu1_0_split -> Convolution1_penlu1_0_split_1
I1006 17:36:09.060853  3702 net.cpp:122] Setting up Convolution1_penlu1_0_split
I1006 17:36:09.060858  3702 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 17:36:09.060861  3702 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 17:36:09.060863  3702 net.cpp:137] Memory required for data: 40551600
I1006 17:36:09.060865  3702 layer_factory.hpp:77] Creating layer Convolution2
I1006 17:36:09.060873  3702 net.cpp:84] Creating Layer Convolution2
I1006 17:36:09.060875  3702 net.cpp:406] Convolution2 <- Convolution1_penlu1_0_split_0
I1006 17:36:09.060879  3702 net.cpp:380] Convolution2 -> Convolution2
I1006 17:36:09.061967  3702 net.cpp:122] Setting up Convolution2
I1006 17:36:09.061977  3702 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 17:36:09.061980  3702 net.cpp:137] Memory required for data: 47105200
I1006 17:36:09.061985  3702 layer_factory.hpp:77] Creating layer BatchNorm2
I1006 17:36:09.061996  3702 net.cpp:84] Creating Layer BatchNorm2
I1006 17:36:09.061998  3702 net.cpp:406] BatchNorm2 <- Convolution2
I1006 17:36:09.062005  3702 net.cpp:367] BatchNorm2 -> Convolution2 (in-place)
I1006 17:36:09.062149  3702 net.cpp:122] Setting up BatchNorm2
I1006 17:36:09.062152  3702 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 17:36:09.062156  3702 net.cpp:137] Memory required for data: 53658800
I1006 17:36:09.062162  3702 layer_factory.hpp:77] Creating layer Scale2
I1006 17:36:09.062166  3702 net.cpp:84] Creating Layer Scale2
I1006 17:36:09.062168  3702 net.cpp:406] Scale2 <- Convolution2
I1006 17:36:09.062172  3702 net.cpp:367] Scale2 -> Convolution2 (in-place)
I1006 17:36:09.062201  3702 layer_factory.hpp:77] Creating layer Scale2
I1006 17:36:09.062281  3702 net.cpp:122] Setting up Scale2
I1006 17:36:09.062288  3702 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 17:36:09.062289  3702 net.cpp:137] Memory required for data: 60212400
I1006 17:36:09.062296  3702 layer_factory.hpp:77] Creating layer penlu2
I1006 17:36:09.062302  3702 net.cpp:84] Creating Layer penlu2
I1006 17:36:09.062304  3702 net.cpp:406] penlu2 <- Convolution2
I1006 17:36:09.062309  3702 net.cpp:367] penlu2 -> Convolution2 (in-place)
I1006 17:36:09.062436  3702 net.cpp:122] Setting up penlu2
I1006 17:36:09.062441  3702 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 17:36:09.062443  3702 net.cpp:137] Memory required for data: 66766000
I1006 17:36:09.062448  3702 layer_factory.hpp:77] Creating layer Convolution3
I1006 17:36:09.062454  3702 net.cpp:84] Creating Layer Convolution3
I1006 17:36:09.062458  3702 net.cpp:406] Convolution3 <- Convolution2
I1006 17:36:09.062461  3702 net.cpp:380] Convolution3 -> Convolution3
I1006 17:36:09.063570  3702 net.cpp:122] Setting up Convolution3
I1006 17:36:09.063580  3702 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 17:36:09.063583  3702 net.cpp:137] Memory required for data: 73319600
I1006 17:36:09.063587  3702 layer_factory.hpp:77] Creating layer BatchNorm3
I1006 17:36:09.063594  3702 net.cpp:84] Creating Layer BatchNorm3
I1006 17:36:09.063597  3702 net.cpp:406] BatchNorm3 <- Convolution3
I1006 17:36:09.063601  3702 net.cpp:367] BatchNorm3 -> Convolution3 (in-place)
I1006 17:36:09.063747  3702 net.cpp:122] Setting up BatchNorm3
I1006 17:36:09.063752  3702 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 17:36:09.063755  3702 net.cpp:137] Memory required for data: 79873200
I1006 17:36:09.063760  3702 layer_factory.hpp:77] Creating layer Scale3
I1006 17:36:09.063766  3702 net.cpp:84] Creating Layer Scale3
I1006 17:36:09.063776  3702 net.cpp:406] Scale3 <- Convolution3
I1006 17:36:09.063781  3702 net.cpp:367] Scale3 -> Convolution3 (in-place)
I1006 17:36:09.063815  3702 layer_factory.hpp:77] Creating layer Scale3
I1006 17:36:09.063894  3702 net.cpp:122] Setting up Scale3
I1006 17:36:09.063899  3702 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 17:36:09.063901  3702 net.cpp:137] Memory required for data: 86426800
I1006 17:36:09.063905  3702 layer_factory.hpp:77] Creating layer Eltwise1
I1006 17:36:09.063910  3702 net.cpp:84] Creating Layer Eltwise1
I1006 17:36:09.063913  3702 net.cpp:406] Eltwise1 <- Convolution1_penlu1_0_split_1
I1006 17:36:09.063916  3702 net.cpp:406] Eltwise1 <- Convolution3
I1006 17:36:09.063920  3702 net.cpp:380] Eltwise1 -> Eltwise1
I1006 17:36:09.063937  3702 net.cpp:122] Setting up Eltwise1
I1006 17:36:09.063941  3702 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 17:36:09.063942  3702 net.cpp:137] Memory required for data: 92980400
I1006 17:36:09.063947  3702 layer_factory.hpp:77] Creating layer penlu3
I1006 17:36:09.063953  3702 net.cpp:84] Creating Layer penlu3
I1006 17:36:09.063956  3702 net.cpp:406] penlu3 <- Eltwise1
I1006 17:36:09.063961  3702 net.cpp:367] penlu3 -> Eltwise1 (in-place)
I1006 17:36:09.064080  3702 net.cpp:122] Setting up penlu3
I1006 17:36:09.064085  3702 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 17:36:09.064087  3702 net.cpp:137] Memory required for data: 99534000
I1006 17:36:09.064095  3702 layer_factory.hpp:77] Creating layer Eltwise1_penlu3_0_split
I1006 17:36:09.064100  3702 net.cpp:84] Creating Layer Eltwise1_penlu3_0_split
I1006 17:36:09.064103  3702 net.cpp:406] Eltwise1_penlu3_0_split <- Eltwise1
I1006 17:36:09.064107  3702 net.cpp:380] Eltwise1_penlu3_0_split -> Eltwise1_penlu3_0_split_0
I1006 17:36:09.064111  3702 net.cpp:380] Eltwise1_penlu3_0_split -> Eltwise1_penlu3_0_split_1
I1006 17:36:09.064136  3702 net.cpp:122] Setting up Eltwise1_penlu3_0_split
I1006 17:36:09.064141  3702 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 17:36:09.064143  3702 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 17:36:09.064146  3702 net.cpp:137] Memory required for data: 112641200
I1006 17:36:09.064147  3702 layer_factory.hpp:77] Creating layer Convolution4
I1006 17:36:09.064154  3702 net.cpp:84] Creating Layer Convolution4
I1006 17:36:09.064157  3702 net.cpp:406] Convolution4 <- Eltwise1_penlu3_0_split_0
I1006 17:36:09.064160  3702 net.cpp:380] Convolution4 -> Convolution4
I1006 17:36:09.065239  3702 net.cpp:122] Setting up Convolution4
I1006 17:36:09.065248  3702 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 17:36:09.065255  3702 net.cpp:137] Memory required for data: 119194800
I1006 17:36:09.065260  3702 layer_factory.hpp:77] Creating layer BatchNorm4
I1006 17:36:09.065265  3702 net.cpp:84] Creating Layer BatchNorm4
I1006 17:36:09.065270  3702 net.cpp:406] BatchNorm4 <- Convolution4
I1006 17:36:09.065274  3702 net.cpp:367] BatchNorm4 -> Convolution4 (in-place)
I1006 17:36:09.065439  3702 net.cpp:122] Setting up BatchNorm4
I1006 17:36:09.065443  3702 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 17:36:09.065446  3702 net.cpp:137] Memory required for data: 125748400
I1006 17:36:09.065454  3702 layer_factory.hpp:77] Creating layer Scale4
I1006 17:36:09.065459  3702 net.cpp:84] Creating Layer Scale4
I1006 17:36:09.065460  3702 net.cpp:406] Scale4 <- Convolution4
I1006 17:36:09.065464  3702 net.cpp:367] Scale4 -> Convolution4 (in-place)
I1006 17:36:09.065492  3702 layer_factory.hpp:77] Creating layer Scale4
I1006 17:36:09.065572  3702 net.cpp:122] Setting up Scale4
I1006 17:36:09.065577  3702 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 17:36:09.065578  3702 net.cpp:137] Memory required for data: 132302000
I1006 17:36:09.065582  3702 layer_factory.hpp:77] Creating layer penlu4
I1006 17:36:09.065588  3702 net.cpp:84] Creating Layer penlu4
I1006 17:36:09.065590  3702 net.cpp:406] penlu4 <- Convolution4
I1006 17:36:09.065594  3702 net.cpp:367] penlu4 -> Convolution4 (in-place)
I1006 17:36:09.065716  3702 net.cpp:122] Setting up penlu4
I1006 17:36:09.065728  3702 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 17:36:09.065731  3702 net.cpp:137] Memory required for data: 138855600
I1006 17:36:09.065737  3702 layer_factory.hpp:77] Creating layer Convolution5
I1006 17:36:09.065744  3702 net.cpp:84] Creating Layer Convolution5
I1006 17:36:09.065747  3702 net.cpp:406] Convolution5 <- Convolution4
I1006 17:36:09.065750  3702 net.cpp:380] Convolution5 -> Convolution5
I1006 17:36:09.066720  3702 net.cpp:122] Setting up Convolution5
I1006 17:36:09.066730  3702 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 17:36:09.066731  3702 net.cpp:137] Memory required for data: 145409200
I1006 17:36:09.066736  3702 layer_factory.hpp:77] Creating layer BatchNorm5
I1006 17:36:09.066742  3702 net.cpp:84] Creating Layer BatchNorm5
I1006 17:36:09.066745  3702 net.cpp:406] BatchNorm5 <- Convolution5
I1006 17:36:09.066748  3702 net.cpp:367] BatchNorm5 -> Convolution5 (in-place)
I1006 17:36:09.066892  3702 net.cpp:122] Setting up BatchNorm5
I1006 17:36:09.066897  3702 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 17:36:09.066900  3702 net.cpp:137] Memory required for data: 151962800
I1006 17:36:09.066905  3702 layer_factory.hpp:77] Creating layer Scale5
I1006 17:36:09.066908  3702 net.cpp:84] Creating Layer Scale5
I1006 17:36:09.066911  3702 net.cpp:406] Scale5 <- Convolution5
I1006 17:36:09.066915  3702 net.cpp:367] Scale5 -> Convolution5 (in-place)
I1006 17:36:09.066944  3702 layer_factory.hpp:77] Creating layer Scale5
I1006 17:36:09.067023  3702 net.cpp:122] Setting up Scale5
I1006 17:36:09.067026  3702 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 17:36:09.067028  3702 net.cpp:137] Memory required for data: 158516400
I1006 17:36:09.067032  3702 layer_factory.hpp:77] Creating layer Eltwise2
I1006 17:36:09.067037  3702 net.cpp:84] Creating Layer Eltwise2
I1006 17:36:09.067039  3702 net.cpp:406] Eltwise2 <- Eltwise1_penlu3_0_split_1
I1006 17:36:09.067042  3702 net.cpp:406] Eltwise2 <- Convolution5
I1006 17:36:09.067046  3702 net.cpp:380] Eltwise2 -> Eltwise2
I1006 17:36:09.067062  3702 net.cpp:122] Setting up Eltwise2
I1006 17:36:09.067066  3702 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 17:36:09.067068  3702 net.cpp:137] Memory required for data: 165070000
I1006 17:36:09.067070  3702 layer_factory.hpp:77] Creating layer penlu5
I1006 17:36:09.067076  3702 net.cpp:84] Creating Layer penlu5
I1006 17:36:09.067078  3702 net.cpp:406] penlu5 <- Eltwise2
I1006 17:36:09.067081  3702 net.cpp:367] penlu5 -> Eltwise2 (in-place)
I1006 17:36:09.067232  3702 net.cpp:122] Setting up penlu5
I1006 17:36:09.067237  3702 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 17:36:09.067239  3702 net.cpp:137] Memory required for data: 171623600
I1006 17:36:09.067243  3702 layer_factory.hpp:77] Creating layer Eltwise2_penlu5_0_split
I1006 17:36:09.067247  3702 net.cpp:84] Creating Layer Eltwise2_penlu5_0_split
I1006 17:36:09.067250  3702 net.cpp:406] Eltwise2_penlu5_0_split <- Eltwise2
I1006 17:36:09.067253  3702 net.cpp:380] Eltwise2_penlu5_0_split -> Eltwise2_penlu5_0_split_0
I1006 17:36:09.067256  3702 net.cpp:380] Eltwise2_penlu5_0_split -> Eltwise2_penlu5_0_split_1
I1006 17:36:09.067282  3702 net.cpp:122] Setting up Eltwise2_penlu5_0_split
I1006 17:36:09.067286  3702 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 17:36:09.067289  3702 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 17:36:09.067291  3702 net.cpp:137] Memory required for data: 184730800
I1006 17:36:09.067294  3702 layer_factory.hpp:77] Creating layer Convolution6
I1006 17:36:09.067301  3702 net.cpp:84] Creating Layer Convolution6
I1006 17:36:09.067303  3702 net.cpp:406] Convolution6 <- Eltwise2_penlu5_0_split_0
I1006 17:36:09.067307  3702 net.cpp:380] Convolution6 -> Convolution6
I1006 17:36:09.068239  3702 net.cpp:122] Setting up Convolution6
I1006 17:36:09.068248  3702 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 17:36:09.068250  3702 net.cpp:137] Memory required for data: 191284400
I1006 17:36:09.068254  3702 layer_factory.hpp:77] Creating layer BatchNorm6
I1006 17:36:09.068267  3702 net.cpp:84] Creating Layer BatchNorm6
I1006 17:36:09.068270  3702 net.cpp:406] BatchNorm6 <- Convolution6
I1006 17:36:09.068274  3702 net.cpp:367] BatchNorm6 -> Convolution6 (in-place)
I1006 17:36:09.068418  3702 net.cpp:122] Setting up BatchNorm6
I1006 17:36:09.068423  3702 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 17:36:09.068425  3702 net.cpp:137] Memory required for data: 197838000
I1006 17:36:09.068430  3702 layer_factory.hpp:77] Creating layer Scale6
I1006 17:36:09.068435  3702 net.cpp:84] Creating Layer Scale6
I1006 17:36:09.068437  3702 net.cpp:406] Scale6 <- Convolution6
I1006 17:36:09.084913  3702 net.cpp:367] Scale6 -> Convolution6 (in-place)
I1006 17:36:09.084975  3702 layer_factory.hpp:77] Creating layer Scale6
I1006 17:36:09.085078  3702 net.cpp:122] Setting up Scale6
I1006 17:36:09.085084  3702 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 17:36:09.085086  3702 net.cpp:137] Memory required for data: 204391600
I1006 17:36:09.085091  3702 layer_factory.hpp:77] Creating layer penlu6
I1006 17:36:09.085096  3702 net.cpp:84] Creating Layer penlu6
I1006 17:36:09.085099  3702 net.cpp:406] penlu6 <- Convolution6
I1006 17:36:09.085104  3702 net.cpp:367] penlu6 -> Convolution6 (in-place)
I1006 17:36:09.085239  3702 net.cpp:122] Setting up penlu6
I1006 17:36:09.085244  3702 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 17:36:09.085247  3702 net.cpp:137] Memory required for data: 210945200
I1006 17:36:09.085252  3702 layer_factory.hpp:77] Creating layer Convolution7
I1006 17:36:09.085259  3702 net.cpp:84] Creating Layer Convolution7
I1006 17:36:09.085263  3702 net.cpp:406] Convolution7 <- Convolution6
I1006 17:36:09.085266  3702 net.cpp:380] Convolution7 -> Convolution7
I1006 17:36:09.086284  3702 net.cpp:122] Setting up Convolution7
I1006 17:36:09.086293  3702 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 17:36:09.086297  3702 net.cpp:137] Memory required for data: 217498800
I1006 17:36:09.086300  3702 layer_factory.hpp:77] Creating layer BatchNorm7
I1006 17:36:09.086308  3702 net.cpp:84] Creating Layer BatchNorm7
I1006 17:36:09.086311  3702 net.cpp:406] BatchNorm7 <- Convolution7
I1006 17:36:09.086316  3702 net.cpp:367] BatchNorm7 -> Convolution7 (in-place)
I1006 17:36:09.086467  3702 net.cpp:122] Setting up BatchNorm7
I1006 17:36:09.086470  3702 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 17:36:09.086472  3702 net.cpp:137] Memory required for data: 224052400
I1006 17:36:09.086483  3702 layer_factory.hpp:77] Creating layer Scale7
I1006 17:36:09.086488  3702 net.cpp:84] Creating Layer Scale7
I1006 17:36:09.086489  3702 net.cpp:406] Scale7 <- Convolution7
I1006 17:36:09.086493  3702 net.cpp:367] Scale7 -> Convolution7 (in-place)
I1006 17:36:09.086524  3702 layer_factory.hpp:77] Creating layer Scale7
I1006 17:36:09.086606  3702 net.cpp:122] Setting up Scale7
I1006 17:36:09.086609  3702 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 17:36:09.086612  3702 net.cpp:137] Memory required for data: 230606000
I1006 17:36:09.086616  3702 layer_factory.hpp:77] Creating layer Eltwise3
I1006 17:36:09.086621  3702 net.cpp:84] Creating Layer Eltwise3
I1006 17:36:09.086624  3702 net.cpp:406] Eltwise3 <- Eltwise2_penlu5_0_split_1
I1006 17:36:09.086627  3702 net.cpp:406] Eltwise3 <- Convolution7
I1006 17:36:09.086630  3702 net.cpp:380] Eltwise3 -> Eltwise3
I1006 17:36:09.086647  3702 net.cpp:122] Setting up Eltwise3
I1006 17:36:09.086661  3702 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 17:36:09.086663  3702 net.cpp:137] Memory required for data: 237159600
I1006 17:36:09.086665  3702 layer_factory.hpp:77] Creating layer penlu7
I1006 17:36:09.086671  3702 net.cpp:84] Creating Layer penlu7
I1006 17:36:09.086673  3702 net.cpp:406] penlu7 <- Eltwise3
I1006 17:36:09.086676  3702 net.cpp:367] penlu7 -> Eltwise3 (in-place)
I1006 17:36:09.086819  3702 net.cpp:122] Setting up penlu7
I1006 17:36:09.086824  3702 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 17:36:09.086827  3702 net.cpp:137] Memory required for data: 243713200
I1006 17:36:09.086838  3702 layer_factory.hpp:77] Creating layer Eltwise3_penlu7_0_split
I1006 17:36:09.086841  3702 net.cpp:84] Creating Layer Eltwise3_penlu7_0_split
I1006 17:36:09.086843  3702 net.cpp:406] Eltwise3_penlu7_0_split <- Eltwise3
I1006 17:36:09.086846  3702 net.cpp:380] Eltwise3_penlu7_0_split -> Eltwise3_penlu7_0_split_0
I1006 17:36:09.086850  3702 net.cpp:380] Eltwise3_penlu7_0_split -> Eltwise3_penlu7_0_split_1
I1006 17:36:09.086876  3702 net.cpp:122] Setting up Eltwise3_penlu7_0_split
I1006 17:36:09.086880  3702 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 17:36:09.086884  3702 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 17:36:09.086885  3702 net.cpp:137] Memory required for data: 256820400
I1006 17:36:09.086889  3702 layer_factory.hpp:77] Creating layer Convolution8
I1006 17:36:09.086894  3702 net.cpp:84] Creating Layer Convolution8
I1006 17:36:09.086896  3702 net.cpp:406] Convolution8 <- Eltwise3_penlu7_0_split_0
I1006 17:36:09.086900  3702 net.cpp:380] Convolution8 -> Convolution8
I1006 17:36:09.087971  3702 net.cpp:122] Setting up Convolution8
I1006 17:36:09.087981  3702 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 17:36:09.087985  3702 net.cpp:137] Memory required for data: 263374000
I1006 17:36:09.087988  3702 layer_factory.hpp:77] Creating layer BatchNorm8
I1006 17:36:09.087993  3702 net.cpp:84] Creating Layer BatchNorm8
I1006 17:36:09.087996  3702 net.cpp:406] BatchNorm8 <- Convolution8
I1006 17:36:09.088001  3702 net.cpp:367] BatchNorm8 -> Convolution8 (in-place)
I1006 17:36:09.088145  3702 net.cpp:122] Setting up BatchNorm8
I1006 17:36:09.088150  3702 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 17:36:09.088151  3702 net.cpp:137] Memory required for data: 269927600
I1006 17:36:09.088156  3702 layer_factory.hpp:77] Creating layer Scale8
I1006 17:36:09.088160  3702 net.cpp:84] Creating Layer Scale8
I1006 17:36:09.088163  3702 net.cpp:406] Scale8 <- Convolution8
I1006 17:36:09.088166  3702 net.cpp:367] Scale8 -> Convolution8 (in-place)
I1006 17:36:09.088196  3702 layer_factory.hpp:77] Creating layer Scale8
I1006 17:36:09.088277  3702 net.cpp:122] Setting up Scale8
I1006 17:36:09.088281  3702 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 17:36:09.088284  3702 net.cpp:137] Memory required for data: 276481200
I1006 17:36:09.088289  3702 layer_factory.hpp:77] Creating layer penlu8
I1006 17:36:09.088294  3702 net.cpp:84] Creating Layer penlu8
I1006 17:36:09.088295  3702 net.cpp:406] penlu8 <- Convolution8
I1006 17:36:09.088299  3702 net.cpp:367] penlu8 -> Convolution8 (in-place)
I1006 17:36:09.088431  3702 net.cpp:122] Setting up penlu8
I1006 17:36:09.088449  3702 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 17:36:09.088452  3702 net.cpp:137] Memory required for data: 283034800
I1006 17:36:09.088457  3702 layer_factory.hpp:77] Creating layer Convolution9
I1006 17:36:09.088464  3702 net.cpp:84] Creating Layer Convolution9
I1006 17:36:09.088467  3702 net.cpp:406] Convolution9 <- Convolution8
I1006 17:36:09.088471  3702 net.cpp:380] Convolution9 -> Convolution9
I1006 17:36:09.089872  3702 net.cpp:122] Setting up Convolution9
I1006 17:36:09.089882  3702 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 17:36:09.089885  3702 net.cpp:137] Memory required for data: 289588400
I1006 17:36:09.089890  3702 layer_factory.hpp:77] Creating layer BatchNorm9
I1006 17:36:09.089896  3702 net.cpp:84] Creating Layer BatchNorm9
I1006 17:36:09.089900  3702 net.cpp:406] BatchNorm9 <- Convolution9
I1006 17:36:09.089903  3702 net.cpp:367] BatchNorm9 -> Convolution9 (in-place)
I1006 17:36:09.090054  3702 net.cpp:122] Setting up BatchNorm9
I1006 17:36:09.090059  3702 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 17:36:09.090061  3702 net.cpp:137] Memory required for data: 296142000
I1006 17:36:09.090066  3702 layer_factory.hpp:77] Creating layer Scale9
I1006 17:36:09.090070  3702 net.cpp:84] Creating Layer Scale9
I1006 17:36:09.090073  3702 net.cpp:406] Scale9 <- Convolution9
I1006 17:36:09.090076  3702 net.cpp:367] Scale9 -> Convolution9 (in-place)
I1006 17:36:09.090107  3702 layer_factory.hpp:77] Creating layer Scale9
I1006 17:36:09.090200  3702 net.cpp:122] Setting up Scale9
I1006 17:36:09.090205  3702 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 17:36:09.090207  3702 net.cpp:137] Memory required for data: 302695600
I1006 17:36:09.090211  3702 layer_factory.hpp:77] Creating layer Eltwise4
I1006 17:36:09.090217  3702 net.cpp:84] Creating Layer Eltwise4
I1006 17:36:09.090219  3702 net.cpp:406] Eltwise4 <- Eltwise3_penlu7_0_split_1
I1006 17:36:09.090222  3702 net.cpp:406] Eltwise4 <- Convolution9
I1006 17:36:09.090226  3702 net.cpp:380] Eltwise4 -> Eltwise4
I1006 17:36:09.090243  3702 net.cpp:122] Setting up Eltwise4
I1006 17:36:09.090247  3702 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 17:36:09.090250  3702 net.cpp:137] Memory required for data: 309249200
I1006 17:36:09.090251  3702 layer_factory.hpp:77] Creating layer penlu9
I1006 17:36:09.090257  3702 net.cpp:84] Creating Layer penlu9
I1006 17:36:09.090260  3702 net.cpp:406] penlu9 <- Eltwise4
I1006 17:36:09.090265  3702 net.cpp:367] penlu9 -> Eltwise4 (in-place)
I1006 17:36:09.090389  3702 net.cpp:122] Setting up penlu9
I1006 17:36:09.090394  3702 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 17:36:09.090396  3702 net.cpp:137] Memory required for data: 315802800
I1006 17:36:09.090401  3702 layer_factory.hpp:77] Creating layer Eltwise4_penlu9_0_split
I1006 17:36:09.090405  3702 net.cpp:84] Creating Layer Eltwise4_penlu9_0_split
I1006 17:36:09.090407  3702 net.cpp:406] Eltwise4_penlu9_0_split <- Eltwise4
I1006 17:36:09.090410  3702 net.cpp:380] Eltwise4_penlu9_0_split -> Eltwise4_penlu9_0_split_0
I1006 17:36:09.090416  3702 net.cpp:380] Eltwise4_penlu9_0_split -> Eltwise4_penlu9_0_split_1
I1006 17:36:09.090442  3702 net.cpp:122] Setting up Eltwise4_penlu9_0_split
I1006 17:36:09.090446  3702 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 17:36:09.090448  3702 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 17:36:09.090451  3702 net.cpp:137] Memory required for data: 328910000
I1006 17:36:09.090453  3702 layer_factory.hpp:77] Creating layer Convolution10
I1006 17:36:09.090461  3702 net.cpp:84] Creating Layer Convolution10
I1006 17:36:09.090462  3702 net.cpp:406] Convolution10 <- Eltwise4_penlu9_0_split_0
I1006 17:36:09.090466  3702 net.cpp:380] Convolution10 -> Convolution10
I1006 17:36:09.091073  3702 net.cpp:122] Setting up Convolution10
I1006 17:36:09.091079  3702 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 17:36:09.091083  3702 net.cpp:137] Memory required for data: 335463600
I1006 17:36:09.091086  3702 layer_factory.hpp:77] Creating layer BatchNorm10
I1006 17:36:09.091091  3702 net.cpp:84] Creating Layer BatchNorm10
I1006 17:36:09.091094  3702 net.cpp:406] BatchNorm10 <- Convolution10
I1006 17:36:09.091099  3702 net.cpp:367] BatchNorm10 -> Convolution10 (in-place)
I1006 17:36:09.091256  3702 net.cpp:122] Setting up BatchNorm10
I1006 17:36:09.091261  3702 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 17:36:09.091264  3702 net.cpp:137] Memory required for data: 342017200
I1006 17:36:09.091269  3702 layer_factory.hpp:77] Creating layer Scale10
I1006 17:36:09.091274  3702 net.cpp:84] Creating Layer Scale10
I1006 17:36:09.091276  3702 net.cpp:406] Scale10 <- Convolution10
I1006 17:36:09.091279  3702 net.cpp:367] Scale10 -> Convolution10 (in-place)
I1006 17:36:09.091310  3702 layer_factory.hpp:77] Creating layer Scale10
I1006 17:36:09.091392  3702 net.cpp:122] Setting up Scale10
I1006 17:36:09.091395  3702 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 17:36:09.091398  3702 net.cpp:137] Memory required for data: 348570800
I1006 17:36:09.091401  3702 layer_factory.hpp:77] Creating layer penlu10
I1006 17:36:09.091408  3702 net.cpp:84] Creating Layer penlu10
I1006 17:36:09.091409  3702 net.cpp:406] penlu10 <- Convolution10
I1006 17:36:09.091413  3702 net.cpp:367] penlu10 -> Convolution10 (in-place)
I1006 17:36:09.091567  3702 net.cpp:122] Setting up penlu10
I1006 17:36:09.091574  3702 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 17:36:09.091576  3702 net.cpp:137] Memory required for data: 355124400
I1006 17:36:09.091588  3702 layer_factory.hpp:77] Creating layer Convolution11
I1006 17:36:09.091595  3702 net.cpp:84] Creating Layer Convolution11
I1006 17:36:09.091598  3702 net.cpp:406] Convolution11 <- Convolution10
I1006 17:36:09.091603  3702 net.cpp:380] Convolution11 -> Convolution11
I1006 17:36:09.092542  3702 net.cpp:122] Setting up Convolution11
I1006 17:36:09.092552  3702 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 17:36:09.092555  3702 net.cpp:137] Memory required for data: 361678000
I1006 17:36:09.092559  3702 layer_factory.hpp:77] Creating layer BatchNorm11
I1006 17:36:09.092564  3702 net.cpp:84] Creating Layer BatchNorm11
I1006 17:36:09.092567  3702 net.cpp:406] BatchNorm11 <- Convolution11
I1006 17:36:09.092571  3702 net.cpp:367] BatchNorm11 -> Convolution11 (in-place)
I1006 17:36:09.092720  3702 net.cpp:122] Setting up BatchNorm11
I1006 17:36:09.092725  3702 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 17:36:09.092726  3702 net.cpp:137] Memory required for data: 368231600
I1006 17:36:09.092731  3702 layer_factory.hpp:77] Creating layer Scale11
I1006 17:36:09.092736  3702 net.cpp:84] Creating Layer Scale11
I1006 17:36:09.092737  3702 net.cpp:406] Scale11 <- Convolution11
I1006 17:36:09.092741  3702 net.cpp:367] Scale11 -> Convolution11 (in-place)
I1006 17:36:09.092770  3702 layer_factory.hpp:77] Creating layer Scale11
I1006 17:36:09.092854  3702 net.cpp:122] Setting up Scale11
I1006 17:36:09.092859  3702 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 17:36:09.092860  3702 net.cpp:137] Memory required for data: 374785200
I1006 17:36:09.092864  3702 layer_factory.hpp:77] Creating layer Eltwise5
I1006 17:36:09.092869  3702 net.cpp:84] Creating Layer Eltwise5
I1006 17:36:09.092870  3702 net.cpp:406] Eltwise5 <- Eltwise4_penlu9_0_split_1
I1006 17:36:09.092874  3702 net.cpp:406] Eltwise5 <- Convolution11
I1006 17:36:09.092877  3702 net.cpp:380] Eltwise5 -> Eltwise5
I1006 17:36:09.092895  3702 net.cpp:122] Setting up Eltwise5
I1006 17:36:09.092898  3702 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 17:36:09.092900  3702 net.cpp:137] Memory required for data: 381338800
I1006 17:36:09.092902  3702 layer_factory.hpp:77] Creating layer penlu11
I1006 17:36:09.092909  3702 net.cpp:84] Creating Layer penlu11
I1006 17:36:09.092912  3702 net.cpp:406] penlu11 <- Eltwise5
I1006 17:36:09.092916  3702 net.cpp:367] penlu11 -> Eltwise5 (in-place)
I1006 17:36:09.093042  3702 net.cpp:122] Setting up penlu11
I1006 17:36:09.093046  3702 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 17:36:09.093049  3702 net.cpp:137] Memory required for data: 387892400
I1006 17:36:09.093053  3702 layer_factory.hpp:77] Creating layer Eltwise5_penlu11_0_split
I1006 17:36:09.093056  3702 net.cpp:84] Creating Layer Eltwise5_penlu11_0_split
I1006 17:36:09.093060  3702 net.cpp:406] Eltwise5_penlu11_0_split <- Eltwise5
I1006 17:36:09.093063  3702 net.cpp:380] Eltwise5_penlu11_0_split -> Eltwise5_penlu11_0_split_0
I1006 17:36:09.093067  3702 net.cpp:380] Eltwise5_penlu11_0_split -> Eltwise5_penlu11_0_split_1
I1006 17:36:09.093091  3702 net.cpp:122] Setting up Eltwise5_penlu11_0_split
I1006 17:36:09.093096  3702 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 17:36:09.093098  3702 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 17:36:09.093101  3702 net.cpp:137] Memory required for data: 400999600
I1006 17:36:09.093102  3702 layer_factory.hpp:77] Creating layer Convolution12
I1006 17:36:09.093109  3702 net.cpp:84] Creating Layer Convolution12
I1006 17:36:09.093111  3702 net.cpp:406] Convolution12 <- Eltwise5_penlu11_0_split_0
I1006 17:36:09.093116  3702 net.cpp:380] Convolution12 -> Convolution12
I1006 17:36:09.094038  3702 net.cpp:122] Setting up Convolution12
I1006 17:36:09.094048  3702 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 17:36:09.094051  3702 net.cpp:137] Memory required for data: 404276400
I1006 17:36:09.094055  3702 layer_factory.hpp:77] Creating layer BatchNorm12
I1006 17:36:09.094059  3702 net.cpp:84] Creating Layer BatchNorm12
I1006 17:36:09.094063  3702 net.cpp:406] BatchNorm12 <- Convolution12
I1006 17:36:09.094074  3702 net.cpp:367] BatchNorm12 -> Convolution12 (in-place)
I1006 17:36:09.094218  3702 net.cpp:122] Setting up BatchNorm12
I1006 17:36:09.094223  3702 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 17:36:09.094225  3702 net.cpp:137] Memory required for data: 407553200
I1006 17:36:09.094230  3702 layer_factory.hpp:77] Creating layer Scale12
I1006 17:36:09.094234  3702 net.cpp:84] Creating Layer Scale12
I1006 17:36:09.094236  3702 net.cpp:406] Scale12 <- Convolution12
I1006 17:36:09.094239  3702 net.cpp:367] Scale12 -> Convolution12 (in-place)
I1006 17:36:09.115499  3702 layer_factory.hpp:77] Creating layer Scale12
I1006 17:36:09.115633  3702 net.cpp:122] Setting up Scale12
I1006 17:36:09.115641  3702 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 17:36:09.115645  3702 net.cpp:137] Memory required for data: 410830000
I1006 17:36:09.115653  3702 layer_factory.hpp:77] Creating layer Convolution13
I1006 17:36:09.115664  3702 net.cpp:84] Creating Layer Convolution13
I1006 17:36:09.115669  3702 net.cpp:406] Convolution13 <- Eltwise5_penlu11_0_split_1
I1006 17:36:09.115676  3702 net.cpp:380] Convolution13 -> Convolution13
I1006 17:36:09.116771  3702 net.cpp:122] Setting up Convolution13
I1006 17:36:09.116780  3702 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 17:36:09.116783  3702 net.cpp:137] Memory required for data: 414106800
I1006 17:36:09.116787  3702 layer_factory.hpp:77] Creating layer BatchNorm13
I1006 17:36:09.116794  3702 net.cpp:84] Creating Layer BatchNorm13
I1006 17:36:09.116797  3702 net.cpp:406] BatchNorm13 <- Convolution13
I1006 17:36:09.116802  3702 net.cpp:367] BatchNorm13 -> Convolution13 (in-place)
I1006 17:36:09.116950  3702 net.cpp:122] Setting up BatchNorm13
I1006 17:36:09.116955  3702 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 17:36:09.116956  3702 net.cpp:137] Memory required for data: 417383600
I1006 17:36:09.116961  3702 layer_factory.hpp:77] Creating layer Scale13
I1006 17:36:09.116966  3702 net.cpp:84] Creating Layer Scale13
I1006 17:36:09.116968  3702 net.cpp:406] Scale13 <- Convolution13
I1006 17:36:09.116972  3702 net.cpp:367] Scale13 -> Convolution13 (in-place)
I1006 17:36:09.117002  3702 layer_factory.hpp:77] Creating layer Scale13
I1006 17:36:09.117086  3702 net.cpp:122] Setting up Scale13
I1006 17:36:09.117091  3702 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 17:36:09.117094  3702 net.cpp:137] Memory required for data: 420660400
I1006 17:36:09.117097  3702 layer_factory.hpp:77] Creating layer penlu12
I1006 17:36:09.117103  3702 net.cpp:84] Creating Layer penlu12
I1006 17:36:09.117115  3702 net.cpp:406] penlu12 <- Convolution13
I1006 17:36:09.117118  3702 net.cpp:367] penlu12 -> Convolution13 (in-place)
I1006 17:36:09.117254  3702 net.cpp:122] Setting up penlu12
I1006 17:36:09.117257  3702 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 17:36:09.117259  3702 net.cpp:137] Memory required for data: 423937200
I1006 17:36:09.117264  3702 layer_factory.hpp:77] Creating layer Convolution14
I1006 17:36:09.117275  3702 net.cpp:84] Creating Layer Convolution14
I1006 17:36:09.117278  3702 net.cpp:406] Convolution14 <- Convolution13
I1006 17:36:09.117282  3702 net.cpp:380] Convolution14 -> Convolution14
I1006 17:36:09.118589  3702 net.cpp:122] Setting up Convolution14
I1006 17:36:09.118598  3702 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 17:36:09.118600  3702 net.cpp:137] Memory required for data: 427214000
I1006 17:36:09.118616  3702 layer_factory.hpp:77] Creating layer BatchNorm14
I1006 17:36:09.118623  3702 net.cpp:84] Creating Layer BatchNorm14
I1006 17:36:09.118625  3702 net.cpp:406] BatchNorm14 <- Convolution14
I1006 17:36:09.118629  3702 net.cpp:367] BatchNorm14 -> Convolution14 (in-place)
I1006 17:36:09.118774  3702 net.cpp:122] Setting up BatchNorm14
I1006 17:36:09.118778  3702 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 17:36:09.118780  3702 net.cpp:137] Memory required for data: 430490800
I1006 17:36:09.118785  3702 layer_factory.hpp:77] Creating layer Scale14
I1006 17:36:09.118789  3702 net.cpp:84] Creating Layer Scale14
I1006 17:36:09.118799  3702 net.cpp:406] Scale14 <- Convolution14
I1006 17:36:09.118803  3702 net.cpp:367] Scale14 -> Convolution14 (in-place)
I1006 17:36:09.118834  3702 layer_factory.hpp:77] Creating layer Scale14
I1006 17:36:09.118916  3702 net.cpp:122] Setting up Scale14
I1006 17:36:09.118919  3702 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 17:36:09.118921  3702 net.cpp:137] Memory required for data: 433767600
I1006 17:36:09.118926  3702 layer_factory.hpp:77] Creating layer Eltwise6
I1006 17:36:09.118929  3702 net.cpp:84] Creating Layer Eltwise6
I1006 17:36:09.118932  3702 net.cpp:406] Eltwise6 <- Convolution12
I1006 17:36:09.118934  3702 net.cpp:406] Eltwise6 <- Convolution14
I1006 17:36:09.118938  3702 net.cpp:380] Eltwise6 -> Eltwise6
I1006 17:36:09.118952  3702 net.cpp:122] Setting up Eltwise6
I1006 17:36:09.118955  3702 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 17:36:09.118957  3702 net.cpp:137] Memory required for data: 437044400
I1006 17:36:09.118960  3702 layer_factory.hpp:77] Creating layer penlu13
I1006 17:36:09.118965  3702 net.cpp:84] Creating Layer penlu13
I1006 17:36:09.118968  3702 net.cpp:406] penlu13 <- Eltwise6
I1006 17:36:09.118973  3702 net.cpp:367] penlu13 -> Eltwise6 (in-place)
I1006 17:36:09.119094  3702 net.cpp:122] Setting up penlu13
I1006 17:36:09.119098  3702 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 17:36:09.119102  3702 net.cpp:137] Memory required for data: 440321200
I1006 17:36:09.119105  3702 layer_factory.hpp:77] Creating layer Eltwise6_penlu13_0_split
I1006 17:36:09.119109  3702 net.cpp:84] Creating Layer Eltwise6_penlu13_0_split
I1006 17:36:09.119112  3702 net.cpp:406] Eltwise6_penlu13_0_split <- Eltwise6
I1006 17:36:09.119114  3702 net.cpp:380] Eltwise6_penlu13_0_split -> Eltwise6_penlu13_0_split_0
I1006 17:36:09.119118  3702 net.cpp:380] Eltwise6_penlu13_0_split -> Eltwise6_penlu13_0_split_1
I1006 17:36:09.119144  3702 net.cpp:122] Setting up Eltwise6_penlu13_0_split
I1006 17:36:09.119148  3702 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 17:36:09.119150  3702 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 17:36:09.119153  3702 net.cpp:137] Memory required for data: 446874800
I1006 17:36:09.119154  3702 layer_factory.hpp:77] Creating layer Convolution15
I1006 17:36:09.119161  3702 net.cpp:84] Creating Layer Convolution15
I1006 17:36:09.119175  3702 net.cpp:406] Convolution15 <- Eltwise6_penlu13_0_split_0
I1006 17:36:09.119190  3702 net.cpp:380] Convolution15 -> Convolution15
I1006 17:36:09.120616  3702 net.cpp:122] Setting up Convolution15
I1006 17:36:09.120625  3702 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 17:36:09.120628  3702 net.cpp:137] Memory required for data: 450151600
I1006 17:36:09.120632  3702 layer_factory.hpp:77] Creating layer BatchNorm15
I1006 17:36:09.120637  3702 net.cpp:84] Creating Layer BatchNorm15
I1006 17:36:09.120640  3702 net.cpp:406] BatchNorm15 <- Convolution15
I1006 17:36:09.120645  3702 net.cpp:367] BatchNorm15 -> Convolution15 (in-place)
I1006 17:36:09.120792  3702 net.cpp:122] Setting up BatchNorm15
I1006 17:36:09.120797  3702 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 17:36:09.120800  3702 net.cpp:137] Memory required for data: 453428400
I1006 17:36:09.120805  3702 layer_factory.hpp:77] Creating layer Scale15
I1006 17:36:09.120808  3702 net.cpp:84] Creating Layer Scale15
I1006 17:36:09.120810  3702 net.cpp:406] Scale15 <- Convolution15
I1006 17:36:09.120815  3702 net.cpp:367] Scale15 -> Convolution15 (in-place)
I1006 17:36:09.120843  3702 layer_factory.hpp:77] Creating layer Scale15
I1006 17:36:09.120925  3702 net.cpp:122] Setting up Scale15
I1006 17:36:09.120929  3702 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 17:36:09.120932  3702 net.cpp:137] Memory required for data: 456705200
I1006 17:36:09.120935  3702 layer_factory.hpp:77] Creating layer penlu14
I1006 17:36:09.120941  3702 net.cpp:84] Creating Layer penlu14
I1006 17:36:09.120944  3702 net.cpp:406] penlu14 <- Convolution15
I1006 17:36:09.120947  3702 net.cpp:367] penlu14 -> Convolution15 (in-place)
I1006 17:36:09.121073  3702 net.cpp:122] Setting up penlu14
I1006 17:36:09.121078  3702 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 17:36:09.121079  3702 net.cpp:137] Memory required for data: 459982000
I1006 17:36:09.121083  3702 layer_factory.hpp:77] Creating layer Convolution16
I1006 17:36:09.121090  3702 net.cpp:84] Creating Layer Convolution16
I1006 17:36:09.121093  3702 net.cpp:406] Convolution16 <- Convolution15
I1006 17:36:09.121098  3702 net.cpp:380] Convolution16 -> Convolution16
I1006 17:36:09.122709  3702 net.cpp:122] Setting up Convolution16
I1006 17:36:09.122719  3702 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 17:36:09.122721  3702 net.cpp:137] Memory required for data: 463258800
I1006 17:36:09.122725  3702 layer_factory.hpp:77] Creating layer BatchNorm16
I1006 17:36:09.122731  3702 net.cpp:84] Creating Layer BatchNorm16
I1006 17:36:09.122735  3702 net.cpp:406] BatchNorm16 <- Convolution16
I1006 17:36:09.122737  3702 net.cpp:367] BatchNorm16 -> Convolution16 (in-place)
I1006 17:36:09.122881  3702 net.cpp:122] Setting up BatchNorm16
I1006 17:36:09.122886  3702 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 17:36:09.122889  3702 net.cpp:137] Memory required for data: 466535600
I1006 17:36:09.122895  3702 layer_factory.hpp:77] Creating layer Scale16
I1006 17:36:09.122898  3702 net.cpp:84] Creating Layer Scale16
I1006 17:36:09.122900  3702 net.cpp:406] Scale16 <- Convolution16
I1006 17:36:09.122903  3702 net.cpp:367] Scale16 -> Convolution16 (in-place)
I1006 17:36:09.122932  3702 layer_factory.hpp:77] Creating layer Scale16
I1006 17:36:09.123016  3702 net.cpp:122] Setting up Scale16
I1006 17:36:09.123020  3702 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 17:36:09.123023  3702 net.cpp:137] Memory required for data: 469812400
I1006 17:36:09.123026  3702 layer_factory.hpp:77] Creating layer Eltwise7
I1006 17:36:09.123031  3702 net.cpp:84] Creating Layer Eltwise7
I1006 17:36:09.123034  3702 net.cpp:406] Eltwise7 <- Eltwise6_penlu13_0_split_1
I1006 17:36:09.123036  3702 net.cpp:406] Eltwise7 <- Convolution16
I1006 17:36:09.123040  3702 net.cpp:380] Eltwise7 -> Eltwise7
I1006 17:36:09.123054  3702 net.cpp:122] Setting up Eltwise7
I1006 17:36:09.123059  3702 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 17:36:09.123060  3702 net.cpp:137] Memory required for data: 473089200
I1006 17:36:09.123062  3702 layer_factory.hpp:77] Creating layer penlu15
I1006 17:36:09.123069  3702 net.cpp:84] Creating Layer penlu15
I1006 17:36:09.123070  3702 net.cpp:406] penlu15 <- Eltwise7
I1006 17:36:09.123073  3702 net.cpp:367] penlu15 -> Eltwise7 (in-place)
I1006 17:36:09.123195  3702 net.cpp:122] Setting up penlu15
I1006 17:36:09.123200  3702 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 17:36:09.123203  3702 net.cpp:137] Memory required for data: 476366000
I1006 17:36:09.123208  3702 layer_factory.hpp:77] Creating layer Eltwise7_penlu15_0_split
I1006 17:36:09.123211  3702 net.cpp:84] Creating Layer Eltwise7_penlu15_0_split
I1006 17:36:09.123214  3702 net.cpp:406] Eltwise7_penlu15_0_split <- Eltwise7
I1006 17:36:09.123216  3702 net.cpp:380] Eltwise7_penlu15_0_split -> Eltwise7_penlu15_0_split_0
I1006 17:36:09.123220  3702 net.cpp:380] Eltwise7_penlu15_0_split -> Eltwise7_penlu15_0_split_1
I1006 17:36:09.123245  3702 net.cpp:122] Setting up Eltwise7_penlu15_0_split
I1006 17:36:09.123250  3702 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 17:36:09.123252  3702 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 17:36:09.123255  3702 net.cpp:137] Memory required for data: 482919600
I1006 17:36:09.123256  3702 layer_factory.hpp:77] Creating layer Convolution17
I1006 17:36:09.123262  3702 net.cpp:84] Creating Layer Convolution17
I1006 17:36:09.123265  3702 net.cpp:406] Convolution17 <- Eltwise7_penlu15_0_split_0
I1006 17:36:09.123270  3702 net.cpp:380] Convolution17 -> Convolution17
I1006 17:36:09.124347  3702 net.cpp:122] Setting up Convolution17
I1006 17:36:09.124356  3702 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 17:36:09.124358  3702 net.cpp:137] Memory required for data: 486196400
I1006 17:36:09.124369  3702 layer_factory.hpp:77] Creating layer BatchNorm17
I1006 17:36:09.124375  3702 net.cpp:84] Creating Layer BatchNorm17
I1006 17:36:09.124378  3702 net.cpp:406] BatchNorm17 <- Convolution17
I1006 17:36:09.124382  3702 net.cpp:367] BatchNorm17 -> Convolution17 (in-place)
I1006 17:36:09.124523  3702 net.cpp:122] Setting up BatchNorm17
I1006 17:36:09.124527  3702 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 17:36:09.124531  3702 net.cpp:137] Memory required for data: 489473200
I1006 17:36:09.124534  3702 layer_factory.hpp:77] Creating layer Scale17
I1006 17:36:09.124538  3702 net.cpp:84] Creating Layer Scale17
I1006 17:36:09.124541  3702 net.cpp:406] Scale17 <- Convolution17
I1006 17:36:09.124544  3702 net.cpp:367] Scale17 -> Convolution17 (in-place)
I1006 17:36:09.124581  3702 layer_factory.hpp:77] Creating layer Scale17
I1006 17:36:09.124663  3702 net.cpp:122] Setting up Scale17
I1006 17:36:09.124667  3702 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 17:36:09.124670  3702 net.cpp:137] Memory required for data: 492750000
I1006 17:36:09.124673  3702 layer_factory.hpp:77] Creating layer penlu16
I1006 17:36:09.124677  3702 net.cpp:84] Creating Layer penlu16
I1006 17:36:09.124680  3702 net.cpp:406] penlu16 <- Convolution17
I1006 17:36:09.124685  3702 net.cpp:367] penlu16 -> Convolution17 (in-place)
I1006 17:36:09.124799  3702 net.cpp:122] Setting up penlu16
I1006 17:36:09.124804  3702 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 17:36:09.124805  3702 net.cpp:137] Memory required for data: 496026800
I1006 17:36:09.124809  3702 layer_factory.hpp:77] Creating layer Convolution18
I1006 17:36:09.124816  3702 net.cpp:84] Creating Layer Convolution18
I1006 17:36:09.124819  3702 net.cpp:406] Convolution18 <- Convolution17
I1006 17:36:09.124822  3702 net.cpp:380] Convolution18 -> Convolution18
I1006 17:36:09.125912  3702 net.cpp:122] Setting up Convolution18
I1006 17:36:09.125921  3702 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 17:36:09.125923  3702 net.cpp:137] Memory required for data: 499303600
I1006 17:36:09.125927  3702 layer_factory.hpp:77] Creating layer BatchNorm18
I1006 17:36:09.125932  3702 net.cpp:84] Creating Layer BatchNorm18
I1006 17:36:09.125936  3702 net.cpp:406] BatchNorm18 <- Convolution18
I1006 17:36:09.125939  3702 net.cpp:367] BatchNorm18 -> Convolution18 (in-place)
I1006 17:36:09.126081  3702 net.cpp:122] Setting up BatchNorm18
I1006 17:36:09.126085  3702 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 17:36:09.126087  3702 net.cpp:137] Memory required for data: 502580400
I1006 17:36:09.126092  3702 layer_factory.hpp:77] Creating layer Scale18
I1006 17:36:09.126096  3702 net.cpp:84] Creating Layer Scale18
I1006 17:36:09.126098  3702 net.cpp:406] Scale18 <- Convolution18
I1006 17:36:09.126102  3702 net.cpp:367] Scale18 -> Convolution18 (in-place)
I1006 17:36:09.126130  3702 layer_factory.hpp:77] Creating layer Scale18
I1006 17:36:09.126214  3702 net.cpp:122] Setting up Scale18
I1006 17:36:09.126217  3702 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 17:36:09.126219  3702 net.cpp:137] Memory required for data: 505857200
I1006 17:36:09.126224  3702 layer_factory.hpp:77] Creating layer Eltwise8
I1006 17:36:09.126226  3702 net.cpp:84] Creating Layer Eltwise8
I1006 17:36:09.126230  3702 net.cpp:406] Eltwise8 <- Eltwise7_penlu15_0_split_1
I1006 17:36:09.126231  3702 net.cpp:406] Eltwise8 <- Convolution18
I1006 17:36:09.126235  3702 net.cpp:380] Eltwise8 -> Eltwise8
I1006 17:36:09.126248  3702 net.cpp:122] Setting up Eltwise8
I1006 17:36:09.126252  3702 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 17:36:09.126255  3702 net.cpp:137] Memory required for data: 509134000
I1006 17:36:09.126256  3702 layer_factory.hpp:77] Creating layer penlu17
I1006 17:36:09.126261  3702 net.cpp:84] Creating Layer penlu17
I1006 17:36:09.126263  3702 net.cpp:406] penlu17 <- Eltwise8
I1006 17:36:09.126268  3702 net.cpp:367] penlu17 -> Eltwise8 (in-place)
I1006 17:36:09.126384  3702 net.cpp:122] Setting up penlu17
I1006 17:36:09.126389  3702 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 17:36:09.126396  3702 net.cpp:137] Memory required for data: 512410800
I1006 17:36:09.126401  3702 layer_factory.hpp:77] Creating layer Eltwise8_penlu17_0_split
I1006 17:36:09.126405  3702 net.cpp:84] Creating Layer Eltwise8_penlu17_0_split
I1006 17:36:09.126407  3702 net.cpp:406] Eltwise8_penlu17_0_split <- Eltwise8
I1006 17:36:09.126410  3702 net.cpp:380] Eltwise8_penlu17_0_split -> Eltwise8_penlu17_0_split_0
I1006 17:36:09.145987  3702 net.cpp:380] Eltwise8_penlu17_0_split -> Eltwise8_penlu17_0_split_1
I1006 17:36:09.146042  3702 net.cpp:122] Setting up Eltwise8_penlu17_0_split
I1006 17:36:09.146050  3702 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 17:36:09.146056  3702 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 17:36:09.146060  3702 net.cpp:137] Memory required for data: 518964400
I1006 17:36:09.146064  3702 layer_factory.hpp:77] Creating layer Convolution19
I1006 17:36:09.146073  3702 net.cpp:84] Creating Layer Convolution19
I1006 17:36:09.146078  3702 net.cpp:406] Convolution19 <- Eltwise8_penlu17_0_split_0
I1006 17:36:09.146086  3702 net.cpp:380] Convolution19 -> Convolution19
I1006 17:36:09.147354  3702 net.cpp:122] Setting up Convolution19
I1006 17:36:09.147364  3702 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 17:36:09.147367  3702 net.cpp:137] Memory required for data: 522241200
I1006 17:36:09.147372  3702 layer_factory.hpp:77] Creating layer BatchNorm19
I1006 17:36:09.147377  3702 net.cpp:84] Creating Layer BatchNorm19
I1006 17:36:09.147379  3702 net.cpp:406] BatchNorm19 <- Convolution19
I1006 17:36:09.147384  3702 net.cpp:367] BatchNorm19 -> Convolution19 (in-place)
I1006 17:36:09.147536  3702 net.cpp:122] Setting up BatchNorm19
I1006 17:36:09.147541  3702 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 17:36:09.147543  3702 net.cpp:137] Memory required for data: 525518000
I1006 17:36:09.147548  3702 layer_factory.hpp:77] Creating layer Scale19
I1006 17:36:09.147552  3702 net.cpp:84] Creating Layer Scale19
I1006 17:36:09.147555  3702 net.cpp:406] Scale19 <- Convolution19
I1006 17:36:09.147558  3702 net.cpp:367] Scale19 -> Convolution19 (in-place)
I1006 17:36:09.147588  3702 layer_factory.hpp:77] Creating layer Scale19
I1006 17:36:09.147677  3702 net.cpp:122] Setting up Scale19
I1006 17:36:09.147682  3702 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 17:36:09.147685  3702 net.cpp:137] Memory required for data: 528794800
I1006 17:36:09.147688  3702 layer_factory.hpp:77] Creating layer penlu18
I1006 17:36:09.147694  3702 net.cpp:84] Creating Layer penlu18
I1006 17:36:09.147696  3702 net.cpp:406] penlu18 <- Convolution19
I1006 17:36:09.147701  3702 net.cpp:367] penlu18 -> Convolution19 (in-place)
I1006 17:36:09.147872  3702 net.cpp:122] Setting up penlu18
I1006 17:36:09.147881  3702 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 17:36:09.147884  3702 net.cpp:137] Memory required for data: 532071600
I1006 17:36:09.147892  3702 layer_factory.hpp:77] Creating layer Convolution20
I1006 17:36:09.147903  3702 net.cpp:84] Creating Layer Convolution20
I1006 17:36:09.147907  3702 net.cpp:406] Convolution20 <- Convolution19
I1006 17:36:09.147914  3702 net.cpp:380] Convolution20 -> Convolution20
I1006 17:36:09.148749  3702 net.cpp:122] Setting up Convolution20
I1006 17:36:09.148757  3702 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 17:36:09.148761  3702 net.cpp:137] Memory required for data: 535348400
I1006 17:36:09.148764  3702 layer_factory.hpp:77] Creating layer BatchNorm20
I1006 17:36:09.148771  3702 net.cpp:84] Creating Layer BatchNorm20
I1006 17:36:09.148772  3702 net.cpp:406] BatchNorm20 <- Convolution20
I1006 17:36:09.148777  3702 net.cpp:367] BatchNorm20 -> Convolution20 (in-place)
I1006 17:36:09.148953  3702 net.cpp:122] Setting up BatchNorm20
I1006 17:36:09.148958  3702 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 17:36:09.148960  3702 net.cpp:137] Memory required for data: 538625200
I1006 17:36:09.148965  3702 layer_factory.hpp:77] Creating layer Scale20
I1006 17:36:09.148970  3702 net.cpp:84] Creating Layer Scale20
I1006 17:36:09.148972  3702 net.cpp:406] Scale20 <- Convolution20
I1006 17:36:09.148983  3702 net.cpp:367] Scale20 -> Convolution20 (in-place)
I1006 17:36:09.149024  3702 layer_factory.hpp:77] Creating layer Scale20
I1006 17:36:09.149121  3702 net.cpp:122] Setting up Scale20
I1006 17:36:09.149125  3702 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 17:36:09.149127  3702 net.cpp:137] Memory required for data: 541902000
I1006 17:36:09.149132  3702 layer_factory.hpp:77] Creating layer Eltwise9
I1006 17:36:09.149135  3702 net.cpp:84] Creating Layer Eltwise9
I1006 17:36:09.149138  3702 net.cpp:406] Eltwise9 <- Eltwise8_penlu17_0_split_1
I1006 17:36:09.149140  3702 net.cpp:406] Eltwise9 <- Convolution20
I1006 17:36:09.149144  3702 net.cpp:380] Eltwise9 -> Eltwise9
I1006 17:36:09.149158  3702 net.cpp:122] Setting up Eltwise9
I1006 17:36:09.149163  3702 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 17:36:09.149164  3702 net.cpp:137] Memory required for data: 545178800
I1006 17:36:09.149166  3702 layer_factory.hpp:77] Creating layer penlu19
I1006 17:36:09.149173  3702 net.cpp:84] Creating Layer penlu19
I1006 17:36:09.149174  3702 net.cpp:406] penlu19 <- Eltwise9
I1006 17:36:09.149178  3702 net.cpp:367] penlu19 -> Eltwise9 (in-place)
I1006 17:36:09.149312  3702 net.cpp:122] Setting up penlu19
I1006 17:36:09.149327  3702 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 17:36:09.149328  3702 net.cpp:137] Memory required for data: 548455600
I1006 17:36:09.149333  3702 layer_factory.hpp:77] Creating layer Eltwise9_penlu19_0_split
I1006 17:36:09.149336  3702 net.cpp:84] Creating Layer Eltwise9_penlu19_0_split
I1006 17:36:09.149338  3702 net.cpp:406] Eltwise9_penlu19_0_split <- Eltwise9
I1006 17:36:09.149341  3702 net.cpp:380] Eltwise9_penlu19_0_split -> Eltwise9_penlu19_0_split_0
I1006 17:36:09.149345  3702 net.cpp:380] Eltwise9_penlu19_0_split -> Eltwise9_penlu19_0_split_1
I1006 17:36:09.149371  3702 net.cpp:122] Setting up Eltwise9_penlu19_0_split
I1006 17:36:09.149375  3702 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 17:36:09.149379  3702 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 17:36:09.149380  3702 net.cpp:137] Memory required for data: 555009200
I1006 17:36:09.149382  3702 layer_factory.hpp:77] Creating layer Convolution21
I1006 17:36:09.149389  3702 net.cpp:84] Creating Layer Convolution21
I1006 17:36:09.149391  3702 net.cpp:406] Convolution21 <- Eltwise9_penlu19_0_split_0
I1006 17:36:09.149395  3702 net.cpp:380] Convolution21 -> Convolution21
I1006 17:36:09.150503  3702 net.cpp:122] Setting up Convolution21
I1006 17:36:09.150511  3702 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 17:36:09.150514  3702 net.cpp:137] Memory required for data: 558286000
I1006 17:36:09.150518  3702 layer_factory.hpp:77] Creating layer BatchNorm21
I1006 17:36:09.150523  3702 net.cpp:84] Creating Layer BatchNorm21
I1006 17:36:09.150526  3702 net.cpp:406] BatchNorm21 <- Convolution21
I1006 17:36:09.150530  3702 net.cpp:367] BatchNorm21 -> Convolution21 (in-place)
I1006 17:36:09.150676  3702 net.cpp:122] Setting up BatchNorm21
I1006 17:36:09.150681  3702 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 17:36:09.150683  3702 net.cpp:137] Memory required for data: 561562800
I1006 17:36:09.150688  3702 layer_factory.hpp:77] Creating layer Scale21
I1006 17:36:09.150692  3702 net.cpp:84] Creating Layer Scale21
I1006 17:36:09.150694  3702 net.cpp:406] Scale21 <- Convolution21
I1006 17:36:09.150697  3702 net.cpp:367] Scale21 -> Convolution21 (in-place)
I1006 17:36:09.150727  3702 layer_factory.hpp:77] Creating layer Scale21
I1006 17:36:09.150810  3702 net.cpp:122] Setting up Scale21
I1006 17:36:09.150815  3702 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 17:36:09.150817  3702 net.cpp:137] Memory required for data: 564839600
I1006 17:36:09.150821  3702 layer_factory.hpp:77] Creating layer penlu20
I1006 17:36:09.150826  3702 net.cpp:84] Creating Layer penlu20
I1006 17:36:09.150828  3702 net.cpp:406] penlu20 <- Convolution21
I1006 17:36:09.150832  3702 net.cpp:367] penlu20 -> Convolution21 (in-place)
I1006 17:36:09.150951  3702 net.cpp:122] Setting up penlu20
I1006 17:36:09.150962  3702 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 17:36:09.150964  3702 net.cpp:137] Memory required for data: 568116400
I1006 17:36:09.150969  3702 layer_factory.hpp:77] Creating layer Convolution22
I1006 17:36:09.150976  3702 net.cpp:84] Creating Layer Convolution22
I1006 17:36:09.150979  3702 net.cpp:406] Convolution22 <- Convolution21
I1006 17:36:09.150984  3702 net.cpp:380] Convolution22 -> Convolution22
I1006 17:36:09.152132  3702 net.cpp:122] Setting up Convolution22
I1006 17:36:09.152140  3702 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 17:36:09.152143  3702 net.cpp:137] Memory required for data: 571393200
I1006 17:36:09.152148  3702 layer_factory.hpp:77] Creating layer BatchNorm22
I1006 17:36:09.152153  3702 net.cpp:84] Creating Layer BatchNorm22
I1006 17:36:09.152155  3702 net.cpp:406] BatchNorm22 <- Convolution22
I1006 17:36:09.152160  3702 net.cpp:367] BatchNorm22 -> Convolution22 (in-place)
I1006 17:36:09.152310  3702 net.cpp:122] Setting up BatchNorm22
I1006 17:36:09.152315  3702 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 17:36:09.152318  3702 net.cpp:137] Memory required for data: 574670000
I1006 17:36:09.152323  3702 layer_factory.hpp:77] Creating layer Scale22
I1006 17:36:09.152326  3702 net.cpp:84] Creating Layer Scale22
I1006 17:36:09.152328  3702 net.cpp:406] Scale22 <- Convolution22
I1006 17:36:09.152333  3702 net.cpp:367] Scale22 -> Convolution22 (in-place)
I1006 17:36:09.152362  3702 layer_factory.hpp:77] Creating layer Scale22
I1006 17:36:09.152451  3702 net.cpp:122] Setting up Scale22
I1006 17:36:09.152454  3702 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 17:36:09.152456  3702 net.cpp:137] Memory required for data: 577946800
I1006 17:36:09.152460  3702 layer_factory.hpp:77] Creating layer Eltwise10
I1006 17:36:09.152464  3702 net.cpp:84] Creating Layer Eltwise10
I1006 17:36:09.152467  3702 net.cpp:406] Eltwise10 <- Eltwise9_penlu19_0_split_1
I1006 17:36:09.152470  3702 net.cpp:406] Eltwise10 <- Convolution22
I1006 17:36:09.152474  3702 net.cpp:380] Eltwise10 -> Eltwise10
I1006 17:36:09.152488  3702 net.cpp:122] Setting up Eltwise10
I1006 17:36:09.152493  3702 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 17:36:09.152494  3702 net.cpp:137] Memory required for data: 581223600
I1006 17:36:09.152496  3702 layer_factory.hpp:77] Creating layer penlu21
I1006 17:36:09.152503  3702 net.cpp:84] Creating Layer penlu21
I1006 17:36:09.152504  3702 net.cpp:406] penlu21 <- Eltwise10
I1006 17:36:09.152508  3702 net.cpp:367] penlu21 -> Eltwise10 (in-place)
I1006 17:36:09.152644  3702 net.cpp:122] Setting up penlu21
I1006 17:36:09.152649  3702 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 17:36:09.152652  3702 net.cpp:137] Memory required for data: 584500400
I1006 17:36:09.152655  3702 layer_factory.hpp:77] Creating layer Eltwise10_penlu21_0_split
I1006 17:36:09.152660  3702 net.cpp:84] Creating Layer Eltwise10_penlu21_0_split
I1006 17:36:09.152663  3702 net.cpp:406] Eltwise10_penlu21_0_split <- Eltwise10
I1006 17:36:09.152667  3702 net.cpp:380] Eltwise10_penlu21_0_split -> Eltwise10_penlu21_0_split_0
I1006 17:36:09.152670  3702 net.cpp:380] Eltwise10_penlu21_0_split -> Eltwise10_penlu21_0_split_1
I1006 17:36:09.152698  3702 net.cpp:122] Setting up Eltwise10_penlu21_0_split
I1006 17:36:09.152701  3702 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 17:36:09.152704  3702 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 17:36:09.152707  3702 net.cpp:137] Memory required for data: 591054000
I1006 17:36:09.152709  3702 layer_factory.hpp:77] Creating layer Convolution23
I1006 17:36:09.152715  3702 net.cpp:84] Creating Layer Convolution23
I1006 17:36:09.152717  3702 net.cpp:406] Convolution23 <- Eltwise10_penlu21_0_split_0
I1006 17:36:09.152722  3702 net.cpp:380] Convolution23 -> Convolution23
I1006 17:36:09.153759  3702 net.cpp:122] Setting up Convolution23
I1006 17:36:09.153769  3702 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 17:36:09.153771  3702 net.cpp:137] Memory required for data: 592692400
I1006 17:36:09.153776  3702 layer_factory.hpp:77] Creating layer BatchNorm23
I1006 17:36:09.153787  3702 net.cpp:84] Creating Layer BatchNorm23
I1006 17:36:09.153791  3702 net.cpp:406] BatchNorm23 <- Convolution23
I1006 17:36:09.153795  3702 net.cpp:367] BatchNorm23 -> Convolution23 (in-place)
I1006 17:36:09.153946  3702 net.cpp:122] Setting up BatchNorm23
I1006 17:36:09.153951  3702 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 17:36:09.153954  3702 net.cpp:137] Memory required for data: 594330800
I1006 17:36:09.153959  3702 layer_factory.hpp:77] Creating layer Scale23
I1006 17:36:09.153962  3702 net.cpp:84] Creating Layer Scale23
I1006 17:36:09.153964  3702 net.cpp:406] Scale23 <- Convolution23
I1006 17:36:09.153967  3702 net.cpp:367] Scale23 -> Convolution23 (in-place)
I1006 17:36:09.153997  3702 layer_factory.hpp:77] Creating layer Scale23
I1006 17:36:09.154084  3702 net.cpp:122] Setting up Scale23
I1006 17:36:09.154088  3702 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 17:36:09.154090  3702 net.cpp:137] Memory required for data: 595969200
I1006 17:36:09.154094  3702 layer_factory.hpp:77] Creating layer Convolution24
I1006 17:36:09.154100  3702 net.cpp:84] Creating Layer Convolution24
I1006 17:36:09.154103  3702 net.cpp:406] Convolution24 <- Eltwise10_penlu21_0_split_1
I1006 17:36:09.154109  3702 net.cpp:380] Convolution24 -> Convolution24
I1006 17:36:09.155475  3702 net.cpp:122] Setting up Convolution24
I1006 17:36:09.155485  3702 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 17:36:09.155488  3702 net.cpp:137] Memory required for data: 597607600
I1006 17:36:09.155493  3702 layer_factory.hpp:77] Creating layer BatchNorm24
I1006 17:36:09.155498  3702 net.cpp:84] Creating Layer BatchNorm24
I1006 17:36:09.155500  3702 net.cpp:406] BatchNorm24 <- Convolution24
I1006 17:36:09.155504  3702 net.cpp:367] BatchNorm24 -> Convolution24 (in-place)
I1006 17:36:09.155670  3702 net.cpp:122] Setting up BatchNorm24
I1006 17:36:09.155675  3702 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 17:36:09.155678  3702 net.cpp:137] Memory required for data: 599246000
I1006 17:36:09.155683  3702 layer_factory.hpp:77] Creating layer Scale24
I1006 17:36:09.155686  3702 net.cpp:84] Creating Layer Scale24
I1006 17:36:09.155689  3702 net.cpp:406] Scale24 <- Convolution24
I1006 17:36:09.155692  3702 net.cpp:367] Scale24 -> Convolution24 (in-place)
I1006 17:36:09.155722  3702 layer_factory.hpp:77] Creating layer Scale24
I1006 17:36:09.155808  3702 net.cpp:122] Setting up Scale24
I1006 17:36:09.155812  3702 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 17:36:09.155814  3702 net.cpp:137] Memory required for data: 600884400
I1006 17:36:09.155818  3702 layer_factory.hpp:77] Creating layer penlu22
I1006 17:36:09.155823  3702 net.cpp:84] Creating Layer penlu22
I1006 17:36:09.155825  3702 net.cpp:406] penlu22 <- Convolution24
I1006 17:36:09.155829  3702 net.cpp:367] penlu22 -> Convolution24 (in-place)
I1006 17:36:09.155949  3702 net.cpp:122] Setting up penlu22
I1006 17:36:09.155954  3702 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 17:36:09.155956  3702 net.cpp:137] Memory required for data: 602522800
I1006 17:36:09.155961  3702 layer_factory.hpp:77] Creating layer Convolution25
I1006 17:36:09.155967  3702 net.cpp:84] Creating Layer Convolution25
I1006 17:36:09.155969  3702 net.cpp:406] Convolution25 <- Convolution24
I1006 17:36:09.155973  3702 net.cpp:380] Convolution25 -> Convolution25
I1006 17:36:09.157784  3702 net.cpp:122] Setting up Convolution25
I1006 17:36:09.157793  3702 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 17:36:09.157796  3702 net.cpp:137] Memory required for data: 604161200
I1006 17:36:09.157800  3702 layer_factory.hpp:77] Creating layer BatchNorm25
I1006 17:36:09.157805  3702 net.cpp:84] Creating Layer BatchNorm25
I1006 17:36:09.157807  3702 net.cpp:406] BatchNorm25 <- Convolution25
I1006 17:36:09.157812  3702 net.cpp:367] BatchNorm25 -> Convolution25 (in-place)
I1006 17:36:09.157961  3702 net.cpp:122] Setting up BatchNorm25
I1006 17:36:09.157965  3702 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 17:36:09.157968  3702 net.cpp:137] Memory required for data: 605799600
I1006 17:36:09.157979  3702 layer_factory.hpp:77] Creating layer Scale25
I1006 17:36:09.157984  3702 net.cpp:84] Creating Layer Scale25
I1006 17:36:09.157986  3702 net.cpp:406] Scale25 <- Convolution25
I1006 17:36:09.157990  3702 net.cpp:367] Scale25 -> Convolution25 (in-place)
I1006 17:36:09.176920  3702 layer_factory.hpp:77] Creating layer Scale25
I1006 17:36:09.177031  3702 net.cpp:122] Setting up Scale25
I1006 17:36:09.177037  3702 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 17:36:09.177039  3702 net.cpp:137] Memory required for data: 607438000
I1006 17:36:09.177044  3702 layer_factory.hpp:77] Creating layer Eltwise11
I1006 17:36:09.177049  3702 net.cpp:84] Creating Layer Eltwise11
I1006 17:36:09.177052  3702 net.cpp:406] Eltwise11 <- Convolution23
I1006 17:36:09.177055  3702 net.cpp:406] Eltwise11 <- Convolution25
I1006 17:36:09.177059  3702 net.cpp:380] Eltwise11 -> Eltwise11
I1006 17:36:09.177079  3702 net.cpp:122] Setting up Eltwise11
I1006 17:36:09.177084  3702 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 17:36:09.177086  3702 net.cpp:137] Memory required for data: 609076400
I1006 17:36:09.177088  3702 layer_factory.hpp:77] Creating layer penlu23
I1006 17:36:09.177093  3702 net.cpp:84] Creating Layer penlu23
I1006 17:36:09.177096  3702 net.cpp:406] penlu23 <- Eltwise11
I1006 17:36:09.177100  3702 net.cpp:367] penlu23 -> Eltwise11 (in-place)
I1006 17:36:09.177237  3702 net.cpp:122] Setting up penlu23
I1006 17:36:09.177242  3702 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 17:36:09.177243  3702 net.cpp:137] Memory required for data: 610714800
I1006 17:36:09.177248  3702 layer_factory.hpp:77] Creating layer Eltwise11_penlu23_0_split
I1006 17:36:09.177253  3702 net.cpp:84] Creating Layer Eltwise11_penlu23_0_split
I1006 17:36:09.177254  3702 net.cpp:406] Eltwise11_penlu23_0_split <- Eltwise11
I1006 17:36:09.177258  3702 net.cpp:380] Eltwise11_penlu23_0_split -> Eltwise11_penlu23_0_split_0
I1006 17:36:09.177263  3702 net.cpp:380] Eltwise11_penlu23_0_split -> Eltwise11_penlu23_0_split_1
I1006 17:36:09.177294  3702 net.cpp:122] Setting up Eltwise11_penlu23_0_split
I1006 17:36:09.177297  3702 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 17:36:09.177300  3702 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 17:36:09.177302  3702 net.cpp:137] Memory required for data: 613991600
I1006 17:36:09.177304  3702 layer_factory.hpp:77] Creating layer Convolution26
I1006 17:36:09.177311  3702 net.cpp:84] Creating Layer Convolution26
I1006 17:36:09.177314  3702 net.cpp:406] Convolution26 <- Eltwise11_penlu23_0_split_0
I1006 17:36:09.177319  3702 net.cpp:380] Convolution26 -> Convolution26
I1006 17:36:09.179208  3702 net.cpp:122] Setting up Convolution26
I1006 17:36:09.179219  3702 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 17:36:09.179221  3702 net.cpp:137] Memory required for data: 615630000
I1006 17:36:09.179226  3702 layer_factory.hpp:77] Creating layer BatchNorm26
I1006 17:36:09.179231  3702 net.cpp:84] Creating Layer BatchNorm26
I1006 17:36:09.179234  3702 net.cpp:406] BatchNorm26 <- Convolution26
I1006 17:36:09.179239  3702 net.cpp:367] BatchNorm26 -> Convolution26 (in-place)
I1006 17:36:09.179394  3702 net.cpp:122] Setting up BatchNorm26
I1006 17:36:09.179399  3702 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 17:36:09.179401  3702 net.cpp:137] Memory required for data: 617268400
I1006 17:36:09.179406  3702 layer_factory.hpp:77] Creating layer Scale26
I1006 17:36:09.179411  3702 net.cpp:84] Creating Layer Scale26
I1006 17:36:09.179414  3702 net.cpp:406] Scale26 <- Convolution26
I1006 17:36:09.179417  3702 net.cpp:367] Scale26 -> Convolution26 (in-place)
I1006 17:36:09.179448  3702 layer_factory.hpp:77] Creating layer Scale26
I1006 17:36:09.179538  3702 net.cpp:122] Setting up Scale26
I1006 17:36:09.179541  3702 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 17:36:09.179543  3702 net.cpp:137] Memory required for data: 618906800
I1006 17:36:09.179548  3702 layer_factory.hpp:77] Creating layer penlu24
I1006 17:36:09.179553  3702 net.cpp:84] Creating Layer penlu24
I1006 17:36:09.179563  3702 net.cpp:406] penlu24 <- Convolution26
I1006 17:36:09.179567  3702 net.cpp:367] penlu24 -> Convolution26 (in-place)
I1006 17:36:09.179692  3702 net.cpp:122] Setting up penlu24
I1006 17:36:09.179697  3702 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 17:36:09.179699  3702 net.cpp:137] Memory required for data: 620545200
I1006 17:36:09.179704  3702 layer_factory.hpp:77] Creating layer Convolution27
I1006 17:36:09.179711  3702 net.cpp:84] Creating Layer Convolution27
I1006 17:36:09.179714  3702 net.cpp:406] Convolution27 <- Convolution26
I1006 17:36:09.179718  3702 net.cpp:380] Convolution27 -> Convolution27
I1006 17:36:09.181489  3702 net.cpp:122] Setting up Convolution27
I1006 17:36:09.181499  3702 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 17:36:09.181501  3702 net.cpp:137] Memory required for data: 622183600
I1006 17:36:09.181506  3702 layer_factory.hpp:77] Creating layer BatchNorm27
I1006 17:36:09.181522  3702 net.cpp:84] Creating Layer BatchNorm27
I1006 17:36:09.181525  3702 net.cpp:406] BatchNorm27 <- Convolution27
I1006 17:36:09.181530  3702 net.cpp:367] BatchNorm27 -> Convolution27 (in-place)
I1006 17:36:09.181689  3702 net.cpp:122] Setting up BatchNorm27
I1006 17:36:09.181694  3702 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 17:36:09.181695  3702 net.cpp:137] Memory required for data: 623822000
I1006 17:36:09.181721  3702 layer_factory.hpp:77] Creating layer Scale27
I1006 17:36:09.181726  3702 net.cpp:84] Creating Layer Scale27
I1006 17:36:09.181730  3702 net.cpp:406] Scale27 <- Convolution27
I1006 17:36:09.181732  3702 net.cpp:367] Scale27 -> Convolution27 (in-place)
I1006 17:36:09.181766  3702 layer_factory.hpp:77] Creating layer Scale27
I1006 17:36:09.181857  3702 net.cpp:122] Setting up Scale27
I1006 17:36:09.181861  3702 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 17:36:09.181864  3702 net.cpp:137] Memory required for data: 625460400
I1006 17:36:09.181867  3702 layer_factory.hpp:77] Creating layer Eltwise12
I1006 17:36:09.181871  3702 net.cpp:84] Creating Layer Eltwise12
I1006 17:36:09.181874  3702 net.cpp:406] Eltwise12 <- Eltwise11_penlu23_0_split_1
I1006 17:36:09.181877  3702 net.cpp:406] Eltwise12 <- Convolution27
I1006 17:36:09.181881  3702 net.cpp:380] Eltwise12 -> Eltwise12
I1006 17:36:09.181900  3702 net.cpp:122] Setting up Eltwise12
I1006 17:36:09.181903  3702 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 17:36:09.181905  3702 net.cpp:137] Memory required for data: 627098800
I1006 17:36:09.181907  3702 layer_factory.hpp:77] Creating layer penlu25
I1006 17:36:09.181913  3702 net.cpp:84] Creating Layer penlu25
I1006 17:36:09.181915  3702 net.cpp:406] penlu25 <- Eltwise12
I1006 17:36:09.181919  3702 net.cpp:367] penlu25 -> Eltwise12 (in-place)
I1006 17:36:09.182044  3702 net.cpp:122] Setting up penlu25
I1006 17:36:09.182049  3702 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 17:36:09.182050  3702 net.cpp:137] Memory required for data: 628737200
I1006 17:36:09.182054  3702 layer_factory.hpp:77] Creating layer Eltwise12_penlu25_0_split
I1006 17:36:09.182059  3702 net.cpp:84] Creating Layer Eltwise12_penlu25_0_split
I1006 17:36:09.182060  3702 net.cpp:406] Eltwise12_penlu25_0_split <- Eltwise12
I1006 17:36:09.182065  3702 net.cpp:380] Eltwise12_penlu25_0_split -> Eltwise12_penlu25_0_split_0
I1006 17:36:09.182070  3702 net.cpp:380] Eltwise12_penlu25_0_split -> Eltwise12_penlu25_0_split_1
I1006 17:36:09.182096  3702 net.cpp:122] Setting up Eltwise12_penlu25_0_split
I1006 17:36:09.182098  3702 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 17:36:09.182101  3702 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 17:36:09.182103  3702 net.cpp:137] Memory required for data: 632014000
I1006 17:36:09.182106  3702 layer_factory.hpp:77] Creating layer Convolution28
I1006 17:36:09.182112  3702 net.cpp:84] Creating Layer Convolution28
I1006 17:36:09.182116  3702 net.cpp:406] Convolution28 <- Eltwise12_penlu25_0_split_0
I1006 17:36:09.182119  3702 net.cpp:380] Convolution28 -> Convolution28
I1006 17:36:09.184226  3702 net.cpp:122] Setting up Convolution28
I1006 17:36:09.184242  3702 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 17:36:09.184245  3702 net.cpp:137] Memory required for data: 633652400
I1006 17:36:09.184250  3702 layer_factory.hpp:77] Creating layer BatchNorm28
I1006 17:36:09.184255  3702 net.cpp:84] Creating Layer BatchNorm28
I1006 17:36:09.184257  3702 net.cpp:406] BatchNorm28 <- Convolution28
I1006 17:36:09.184262  3702 net.cpp:367] BatchNorm28 -> Convolution28 (in-place)
I1006 17:36:09.184424  3702 net.cpp:122] Setting up BatchNorm28
I1006 17:36:09.184429  3702 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 17:36:09.184432  3702 net.cpp:137] Memory required for data: 635290800
I1006 17:36:09.184437  3702 layer_factory.hpp:77] Creating layer Scale28
I1006 17:36:09.184440  3702 net.cpp:84] Creating Layer Scale28
I1006 17:36:09.184442  3702 net.cpp:406] Scale28 <- Convolution28
I1006 17:36:09.184447  3702 net.cpp:367] Scale28 -> Convolution28 (in-place)
I1006 17:36:09.184478  3702 layer_factory.hpp:77] Creating layer Scale28
I1006 17:36:09.184568  3702 net.cpp:122] Setting up Scale28
I1006 17:36:09.184572  3702 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 17:36:09.184574  3702 net.cpp:137] Memory required for data: 636929200
I1006 17:36:09.184578  3702 layer_factory.hpp:77] Creating layer penlu26
I1006 17:36:09.184584  3702 net.cpp:84] Creating Layer penlu26
I1006 17:36:09.184587  3702 net.cpp:406] penlu26 <- Convolution28
I1006 17:36:09.184590  3702 net.cpp:367] penlu26 -> Convolution28 (in-place)
I1006 17:36:09.184727  3702 net.cpp:122] Setting up penlu26
I1006 17:36:09.184732  3702 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 17:36:09.184734  3702 net.cpp:137] Memory required for data: 638567600
I1006 17:36:09.184739  3702 layer_factory.hpp:77] Creating layer Convolution29
I1006 17:36:09.184746  3702 net.cpp:84] Creating Layer Convolution29
I1006 17:36:09.184749  3702 net.cpp:406] Convolution29 <- Convolution28
I1006 17:36:09.184753  3702 net.cpp:380] Convolution29 -> Convolution29
I1006 17:36:09.187084  3702 net.cpp:122] Setting up Convolution29
I1006 17:36:09.187093  3702 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 17:36:09.187095  3702 net.cpp:137] Memory required for data: 640206000
I1006 17:36:09.187100  3702 layer_factory.hpp:77] Creating layer BatchNorm29
I1006 17:36:09.187105  3702 net.cpp:84] Creating Layer BatchNorm29
I1006 17:36:09.187108  3702 net.cpp:406] BatchNorm29 <- Convolution29
I1006 17:36:09.187113  3702 net.cpp:367] BatchNorm29 -> Convolution29 (in-place)
I1006 17:36:09.187276  3702 net.cpp:122] Setting up BatchNorm29
I1006 17:36:09.187283  3702 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 17:36:09.187284  3702 net.cpp:137] Memory required for data: 641844400
I1006 17:36:09.187289  3702 layer_factory.hpp:77] Creating layer Scale29
I1006 17:36:09.187294  3702 net.cpp:84] Creating Layer Scale29
I1006 17:36:09.187296  3702 net.cpp:406] Scale29 <- Convolution29
I1006 17:36:09.187300  3702 net.cpp:367] Scale29 -> Convolution29 (in-place)
I1006 17:36:09.187331  3702 layer_factory.hpp:77] Creating layer Scale29
I1006 17:36:09.187422  3702 net.cpp:122] Setting up Scale29
I1006 17:36:09.187427  3702 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 17:36:09.187429  3702 net.cpp:137] Memory required for data: 643482800
I1006 17:36:09.187433  3702 layer_factory.hpp:77] Creating layer Eltwise13
I1006 17:36:09.187438  3702 net.cpp:84] Creating Layer Eltwise13
I1006 17:36:09.187439  3702 net.cpp:406] Eltwise13 <- Eltwise12_penlu25_0_split_1
I1006 17:36:09.187443  3702 net.cpp:406] Eltwise13 <- Convolution29
I1006 17:36:09.187446  3702 net.cpp:380] Eltwise13 -> Eltwise13
I1006 17:36:09.187464  3702 net.cpp:122] Setting up Eltwise13
I1006 17:36:09.187469  3702 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 17:36:09.187470  3702 net.cpp:137] Memory required for data: 645121200
I1006 17:36:09.187472  3702 layer_factory.hpp:77] Creating layer penlu27
I1006 17:36:09.187479  3702 net.cpp:84] Creating Layer penlu27
I1006 17:36:09.187481  3702 net.cpp:406] penlu27 <- Eltwise13
I1006 17:36:09.187484  3702 net.cpp:367] penlu27 -> Eltwise13 (in-place)
I1006 17:36:09.187618  3702 net.cpp:122] Setting up penlu27
I1006 17:36:09.187623  3702 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 17:36:09.187625  3702 net.cpp:137] Memory required for data: 646759600
I1006 17:36:09.187630  3702 layer_factory.hpp:77] Creating layer Eltwise13_penlu27_0_split
I1006 17:36:09.187633  3702 net.cpp:84] Creating Layer Eltwise13_penlu27_0_split
I1006 17:36:09.187636  3702 net.cpp:406] Eltwise13_penlu27_0_split <- Eltwise13
I1006 17:36:09.187639  3702 net.cpp:380] Eltwise13_penlu27_0_split -> Eltwise13_penlu27_0_split_0
I1006 17:36:09.187644  3702 net.cpp:380] Eltwise13_penlu27_0_split -> Eltwise13_penlu27_0_split_1
I1006 17:36:09.187671  3702 net.cpp:122] Setting up Eltwise13_penlu27_0_split
I1006 17:36:09.187675  3702 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 17:36:09.187678  3702 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 17:36:09.187680  3702 net.cpp:137] Memory required for data: 650036400
I1006 17:36:09.187690  3702 layer_factory.hpp:77] Creating layer Convolution30
I1006 17:36:09.187698  3702 net.cpp:84] Creating Layer Convolution30
I1006 17:36:09.187700  3702 net.cpp:406] Convolution30 <- Eltwise13_penlu27_0_split_0
I1006 17:36:09.187705  3702 net.cpp:380] Convolution30 -> Convolution30
I1006 17:36:09.189795  3702 net.cpp:122] Setting up Convolution30
I1006 17:36:09.189802  3702 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 17:36:09.189805  3702 net.cpp:137] Memory required for data: 651674800
I1006 17:36:09.189810  3702 layer_factory.hpp:77] Creating layer BatchNorm30
I1006 17:36:09.189815  3702 net.cpp:84] Creating Layer BatchNorm30
I1006 17:36:09.189817  3702 net.cpp:406] BatchNorm30 <- Convolution30
I1006 17:36:09.189821  3702 net.cpp:367] BatchNorm30 -> Convolution30 (in-place)
I1006 17:36:09.189980  3702 net.cpp:122] Setting up BatchNorm30
I1006 17:36:09.189985  3702 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 17:36:09.189986  3702 net.cpp:137] Memory required for data: 653313200
I1006 17:36:09.189991  3702 layer_factory.hpp:77] Creating layer Scale30
I1006 17:36:09.189996  3702 net.cpp:84] Creating Layer Scale30
I1006 17:36:09.189997  3702 net.cpp:406] Scale30 <- Convolution30
I1006 17:36:09.190003  3702 net.cpp:367] Scale30 -> Convolution30 (in-place)
I1006 17:36:09.190033  3702 layer_factory.hpp:77] Creating layer Scale30
I1006 17:36:09.190124  3702 net.cpp:122] Setting up Scale30
I1006 17:36:09.190127  3702 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 17:36:09.190129  3702 net.cpp:137] Memory required for data: 654951600
I1006 17:36:09.190134  3702 layer_factory.hpp:77] Creating layer penlu28
I1006 17:36:09.190140  3702 net.cpp:84] Creating Layer penlu28
I1006 17:36:09.190141  3702 net.cpp:406] penlu28 <- Convolution30
I1006 17:36:09.190145  3702 net.cpp:367] penlu28 -> Convolution30 (in-place)
I1006 17:36:09.190268  3702 net.cpp:122] Setting up penlu28
I1006 17:36:09.190273  3702 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 17:36:09.190274  3702 net.cpp:137] Memory required for data: 656590000
I1006 17:36:09.190279  3702 layer_factory.hpp:77] Creating layer Convolution31
I1006 17:36:09.190284  3702 net.cpp:84] Creating Layer Convolution31
I1006 17:36:09.190287  3702 net.cpp:406] Convolution31 <- Convolution30
I1006 17:36:09.190291  3702 net.cpp:380] Convolution31 -> Convolution31
I1006 17:36:09.192008  3702 net.cpp:122] Setting up Convolution31
I1006 17:36:09.192018  3702 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 17:36:09.192019  3702 net.cpp:137] Memory required for data: 658228400
I1006 17:36:09.192024  3702 layer_factory.hpp:77] Creating layer BatchNorm31
I1006 17:36:09.192028  3702 net.cpp:84] Creating Layer BatchNorm31
I1006 17:36:09.192031  3702 net.cpp:406] BatchNorm31 <- Convolution31
I1006 17:36:09.192035  3702 net.cpp:367] BatchNorm31 -> Convolution31 (in-place)
I1006 17:36:09.192191  3702 net.cpp:122] Setting up BatchNorm31
I1006 17:36:09.192195  3702 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 17:36:09.192198  3702 net.cpp:137] Memory required for data: 659866800
I1006 17:36:09.192209  3702 layer_factory.hpp:77] Creating layer Scale31
I1006 17:36:09.192214  3702 net.cpp:84] Creating Layer Scale31
I1006 17:36:09.207726  3702 net.cpp:406] Scale31 <- Convolution31
I1006 17:36:09.207738  3702 net.cpp:367] Scale31 -> Convolution31 (in-place)
I1006 17:36:09.207798  3702 layer_factory.hpp:77] Creating layer Scale31
I1006 17:36:09.207903  3702 net.cpp:122] Setting up Scale31
I1006 17:36:09.207911  3702 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 17:36:09.207916  3702 net.cpp:137] Memory required for data: 661505200
I1006 17:36:09.207922  3702 layer_factory.hpp:77] Creating layer Eltwise14
I1006 17:36:09.207929  3702 net.cpp:84] Creating Layer Eltwise14
I1006 17:36:09.207933  3702 net.cpp:406] Eltwise14 <- Eltwise13_penlu27_0_split_1
I1006 17:36:09.207937  3702 net.cpp:406] Eltwise14 <- Convolution31
I1006 17:36:09.207942  3702 net.cpp:380] Eltwise14 -> Eltwise14
I1006 17:36:09.207965  3702 net.cpp:122] Setting up Eltwise14
I1006 17:36:09.207970  3702 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 17:36:09.207981  3702 net.cpp:137] Memory required for data: 663143600
I1006 17:36:09.207983  3702 layer_factory.hpp:77] Creating layer penlu29
I1006 17:36:09.207988  3702 net.cpp:84] Creating Layer penlu29
I1006 17:36:09.207991  3702 net.cpp:406] penlu29 <- Eltwise14
I1006 17:36:09.207995  3702 net.cpp:367] penlu29 -> Eltwise14 (in-place)
I1006 17:36:09.208124  3702 net.cpp:122] Setting up penlu29
I1006 17:36:09.208128  3702 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 17:36:09.208130  3702 net.cpp:137] Memory required for data: 664782000
I1006 17:36:09.208135  3702 layer_factory.hpp:77] Creating layer Eltwise14_penlu29_0_split
I1006 17:36:09.208139  3702 net.cpp:84] Creating Layer Eltwise14_penlu29_0_split
I1006 17:36:09.208142  3702 net.cpp:406] Eltwise14_penlu29_0_split <- Eltwise14
I1006 17:36:09.208144  3702 net.cpp:380] Eltwise14_penlu29_0_split -> Eltwise14_penlu29_0_split_0
I1006 17:36:09.208149  3702 net.cpp:380] Eltwise14_penlu29_0_split -> Eltwise14_penlu29_0_split_1
I1006 17:36:09.208176  3702 net.cpp:122] Setting up Eltwise14_penlu29_0_split
I1006 17:36:09.208180  3702 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 17:36:09.208184  3702 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 17:36:09.208185  3702 net.cpp:137] Memory required for data: 668058800
I1006 17:36:09.208187  3702 layer_factory.hpp:77] Creating layer Convolution32
I1006 17:36:09.208194  3702 net.cpp:84] Creating Layer Convolution32
I1006 17:36:09.208195  3702 net.cpp:406] Convolution32 <- Eltwise14_penlu29_0_split_0
I1006 17:36:09.208200  3702 net.cpp:380] Convolution32 -> Convolution32
I1006 17:36:09.210711  3702 net.cpp:122] Setting up Convolution32
I1006 17:36:09.210721  3702 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 17:36:09.210724  3702 net.cpp:137] Memory required for data: 669697200
I1006 17:36:09.210728  3702 layer_factory.hpp:77] Creating layer BatchNorm32
I1006 17:36:09.210734  3702 net.cpp:84] Creating Layer BatchNorm32
I1006 17:36:09.210737  3702 net.cpp:406] BatchNorm32 <- Convolution32
I1006 17:36:09.210741  3702 net.cpp:367] BatchNorm32 -> Convolution32 (in-place)
I1006 17:36:09.210901  3702 net.cpp:122] Setting up BatchNorm32
I1006 17:36:09.210906  3702 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 17:36:09.210908  3702 net.cpp:137] Memory required for data: 671335600
I1006 17:36:09.210913  3702 layer_factory.hpp:77] Creating layer Scale32
I1006 17:36:09.210919  3702 net.cpp:84] Creating Layer Scale32
I1006 17:36:09.210922  3702 net.cpp:406] Scale32 <- Convolution32
I1006 17:36:09.210924  3702 net.cpp:367] Scale32 -> Convolution32 (in-place)
I1006 17:36:09.210957  3702 layer_factory.hpp:77] Creating layer Scale32
I1006 17:36:09.211046  3702 net.cpp:122] Setting up Scale32
I1006 17:36:09.211051  3702 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 17:36:09.211053  3702 net.cpp:137] Memory required for data: 672974000
I1006 17:36:09.211056  3702 layer_factory.hpp:77] Creating layer penlu30
I1006 17:36:09.211062  3702 net.cpp:84] Creating Layer penlu30
I1006 17:36:09.211066  3702 net.cpp:406] penlu30 <- Convolution32
I1006 17:36:09.211076  3702 net.cpp:367] penlu30 -> Convolution32 (in-place)
I1006 17:36:09.211254  3702 net.cpp:122] Setting up penlu30
I1006 17:36:09.211261  3702 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 17:36:09.211272  3702 net.cpp:137] Memory required for data: 674612400
I1006 17:36:09.211277  3702 layer_factory.hpp:77] Creating layer Convolution33
I1006 17:36:09.211283  3702 net.cpp:84] Creating Layer Convolution33
I1006 17:36:09.211287  3702 net.cpp:406] Convolution33 <- Convolution32
I1006 17:36:09.211290  3702 net.cpp:380] Convolution33 -> Convolution33
I1006 17:36:09.213140  3702 net.cpp:122] Setting up Convolution33
I1006 17:36:09.213148  3702 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 17:36:09.213150  3702 net.cpp:137] Memory required for data: 676250800
I1006 17:36:09.213155  3702 layer_factory.hpp:77] Creating layer BatchNorm33
I1006 17:36:09.213160  3702 net.cpp:84] Creating Layer BatchNorm33
I1006 17:36:09.213163  3702 net.cpp:406] BatchNorm33 <- Convolution33
I1006 17:36:09.213167  3702 net.cpp:367] BatchNorm33 -> Convolution33 (in-place)
I1006 17:36:09.213321  3702 net.cpp:122] Setting up BatchNorm33
I1006 17:36:09.213326  3702 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 17:36:09.213328  3702 net.cpp:137] Memory required for data: 677889200
I1006 17:36:09.213332  3702 layer_factory.hpp:77] Creating layer Scale33
I1006 17:36:09.213337  3702 net.cpp:84] Creating Layer Scale33
I1006 17:36:09.213340  3702 net.cpp:406] Scale33 <- Convolution33
I1006 17:36:09.213343  3702 net.cpp:367] Scale33 -> Convolution33 (in-place)
I1006 17:36:09.213374  3702 layer_factory.hpp:77] Creating layer Scale33
I1006 17:36:09.213464  3702 net.cpp:122] Setting up Scale33
I1006 17:36:09.213469  3702 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 17:36:09.213471  3702 net.cpp:137] Memory required for data: 679527600
I1006 17:36:09.213474  3702 layer_factory.hpp:77] Creating layer Eltwise15
I1006 17:36:09.213480  3702 net.cpp:84] Creating Layer Eltwise15
I1006 17:36:09.213484  3702 net.cpp:406] Eltwise15 <- Eltwise14_penlu29_0_split_1
I1006 17:36:09.213486  3702 net.cpp:406] Eltwise15 <- Convolution33
I1006 17:36:09.213490  3702 net.cpp:380] Eltwise15 -> Eltwise15
I1006 17:36:09.213508  3702 net.cpp:122] Setting up Eltwise15
I1006 17:36:09.213512  3702 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 17:36:09.213515  3702 net.cpp:137] Memory required for data: 681166000
I1006 17:36:09.213516  3702 layer_factory.hpp:77] Creating layer penlu31
I1006 17:36:09.213521  3702 net.cpp:84] Creating Layer penlu31
I1006 17:36:09.213524  3702 net.cpp:406] penlu31 <- Eltwise15
I1006 17:36:09.213527  3702 net.cpp:367] penlu31 -> Eltwise15 (in-place)
I1006 17:36:09.213649  3702 net.cpp:122] Setting up penlu31
I1006 17:36:09.213654  3702 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 17:36:09.213655  3702 net.cpp:137] Memory required for data: 682804400
I1006 17:36:09.213660  3702 layer_factory.hpp:77] Creating layer Pooling1
I1006 17:36:09.213663  3702 net.cpp:84] Creating Layer Pooling1
I1006 17:36:09.213666  3702 net.cpp:406] Pooling1 <- Eltwise15
I1006 17:36:09.213670  3702 net.cpp:380] Pooling1 -> Pooling1
I1006 17:36:09.213814  3702 net.cpp:122] Setting up Pooling1
I1006 17:36:09.213820  3702 net.cpp:129] Top shape: 100 64 1 1 (6400)
I1006 17:36:09.213824  3702 net.cpp:137] Memory required for data: 682830000
I1006 17:36:09.213825  3702 layer_factory.hpp:77] Creating layer InnerProduct1
I1006 17:36:09.213830  3702 net.cpp:84] Creating Layer InnerProduct1
I1006 17:36:09.213834  3702 net.cpp:406] InnerProduct1 <- Pooling1
I1006 17:36:09.213837  3702 net.cpp:380] InnerProduct1 -> InnerProduct1
I1006 17:36:09.213946  3702 net.cpp:122] Setting up InnerProduct1
I1006 17:36:09.213950  3702 net.cpp:129] Top shape: 100 10 (1000)
I1006 17:36:09.213953  3702 net.cpp:137] Memory required for data: 682834000
I1006 17:36:09.213956  3702 layer_factory.hpp:77] Creating layer InnerProduct1_InnerProduct1_0_split
I1006 17:36:09.213960  3702 net.cpp:84] Creating Layer InnerProduct1_InnerProduct1_0_split
I1006 17:36:09.213969  3702 net.cpp:406] InnerProduct1_InnerProduct1_0_split <- InnerProduct1
I1006 17:36:09.213973  3702 net.cpp:380] InnerProduct1_InnerProduct1_0_split -> InnerProduct1_InnerProduct1_0_split_0
I1006 17:36:09.213977  3702 net.cpp:380] InnerProduct1_InnerProduct1_0_split -> InnerProduct1_InnerProduct1_0_split_1
I1006 17:36:09.214007  3702 net.cpp:122] Setting up InnerProduct1_InnerProduct1_0_split
I1006 17:36:09.214011  3702 net.cpp:129] Top shape: 100 10 (1000)
I1006 17:36:09.214015  3702 net.cpp:129] Top shape: 100 10 (1000)
I1006 17:36:09.214016  3702 net.cpp:137] Memory required for data: 682842000
I1006 17:36:09.214018  3702 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I1006 17:36:09.214022  3702 net.cpp:84] Creating Layer SoftmaxWithLoss1
I1006 17:36:09.214025  3702 net.cpp:406] SoftmaxWithLoss1 <- InnerProduct1_InnerProduct1_0_split_0
I1006 17:36:09.214027  3702 net.cpp:406] SoftmaxWithLoss1 <- Data2_Data1_1_split_0
I1006 17:36:09.214031  3702 net.cpp:380] SoftmaxWithLoss1 -> SoftmaxWithLoss1
I1006 17:36:09.214036  3702 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I1006 17:36:09.214567  3702 net.cpp:122] Setting up SoftmaxWithLoss1
I1006 17:36:09.214576  3702 net.cpp:129] Top shape: (1)
I1006 17:36:09.214578  3702 net.cpp:132]     with loss weight 1
I1006 17:36:09.214586  3702 net.cpp:137] Memory required for data: 682842004
I1006 17:36:09.214587  3702 layer_factory.hpp:77] Creating layer Accuracy1
I1006 17:36:09.214592  3702 net.cpp:84] Creating Layer Accuracy1
I1006 17:36:09.214596  3702 net.cpp:406] Accuracy1 <- InnerProduct1_InnerProduct1_0_split_1
I1006 17:36:09.214598  3702 net.cpp:406] Accuracy1 <- Data2_Data1_1_split_1
I1006 17:36:09.214603  3702 net.cpp:380] Accuracy1 -> Accuracy1
I1006 17:36:09.214609  3702 net.cpp:122] Setting up Accuracy1
I1006 17:36:09.214612  3702 net.cpp:129] Top shape: (1)
I1006 17:36:09.214614  3702 net.cpp:137] Memory required for data: 682842008
I1006 17:36:09.214617  3702 net.cpp:200] Accuracy1 does not need backward computation.
I1006 17:36:09.214619  3702 net.cpp:198] SoftmaxWithLoss1 needs backward computation.
I1006 17:36:09.214622  3702 net.cpp:198] InnerProduct1_InnerProduct1_0_split needs backward computation.
I1006 17:36:09.214624  3702 net.cpp:198] InnerProduct1 needs backward computation.
I1006 17:36:09.214627  3702 net.cpp:198] Pooling1 needs backward computation.
I1006 17:36:09.214628  3702 net.cpp:198] penlu31 needs backward computation.
I1006 17:36:09.214630  3702 net.cpp:198] Eltwise15 needs backward computation.
I1006 17:36:09.214633  3702 net.cpp:198] Scale33 needs backward computation.
I1006 17:36:09.214635  3702 net.cpp:198] BatchNorm33 needs backward computation.
I1006 17:36:09.214637  3702 net.cpp:198] Convolution33 needs backward computation.
I1006 17:36:09.214639  3702 net.cpp:198] penlu30 needs backward computation.
I1006 17:36:09.214642  3702 net.cpp:198] Scale32 needs backward computation.
I1006 17:36:09.214643  3702 net.cpp:198] BatchNorm32 needs backward computation.
I1006 17:36:09.214645  3702 net.cpp:198] Convolution32 needs backward computation.
I1006 17:36:09.214648  3702 net.cpp:198] Eltwise14_penlu29_0_split needs backward computation.
I1006 17:36:09.214649  3702 net.cpp:198] penlu29 needs backward computation.
I1006 17:36:09.214651  3702 net.cpp:198] Eltwise14 needs backward computation.
I1006 17:36:09.214654  3702 net.cpp:198] Scale31 needs backward computation.
I1006 17:36:09.214656  3702 net.cpp:198] BatchNorm31 needs backward computation.
I1006 17:36:09.214658  3702 net.cpp:198] Convolution31 needs backward computation.
I1006 17:36:09.214661  3702 net.cpp:198] penlu28 needs backward computation.
I1006 17:36:09.214663  3702 net.cpp:198] Scale30 needs backward computation.
I1006 17:36:09.214665  3702 net.cpp:198] BatchNorm30 needs backward computation.
I1006 17:36:09.214668  3702 net.cpp:198] Convolution30 needs backward computation.
I1006 17:36:09.214669  3702 net.cpp:198] Eltwise13_penlu27_0_split needs backward computation.
I1006 17:36:09.214673  3702 net.cpp:198] penlu27 needs backward computation.
I1006 17:36:09.214680  3702 net.cpp:198] Eltwise13 needs backward computation.
I1006 17:36:09.214684  3702 net.cpp:198] Scale29 needs backward computation.
I1006 17:36:09.214686  3702 net.cpp:198] BatchNorm29 needs backward computation.
I1006 17:36:09.214689  3702 net.cpp:198] Convolution29 needs backward computation.
I1006 17:36:09.214690  3702 net.cpp:198] penlu26 needs backward computation.
I1006 17:36:09.214692  3702 net.cpp:198] Scale28 needs backward computation.
I1006 17:36:09.214694  3702 net.cpp:198] BatchNorm28 needs backward computation.
I1006 17:36:09.214696  3702 net.cpp:198] Convolution28 needs backward computation.
I1006 17:36:09.214699  3702 net.cpp:198] Eltwise12_penlu25_0_split needs backward computation.
I1006 17:36:09.214701  3702 net.cpp:198] penlu25 needs backward computation.
I1006 17:36:09.214704  3702 net.cpp:198] Eltwise12 needs backward computation.
I1006 17:36:09.214706  3702 net.cpp:198] Scale27 needs backward computation.
I1006 17:36:09.214709  3702 net.cpp:198] BatchNorm27 needs backward computation.
I1006 17:36:09.214711  3702 net.cpp:198] Convolution27 needs backward computation.
I1006 17:36:09.214714  3702 net.cpp:198] penlu24 needs backward computation.
I1006 17:36:09.214715  3702 net.cpp:198] Scale26 needs backward computation.
I1006 17:36:09.214717  3702 net.cpp:198] BatchNorm26 needs backward computation.
I1006 17:36:09.214720  3702 net.cpp:198] Convolution26 needs backward computation.
I1006 17:36:09.214722  3702 net.cpp:198] Eltwise11_penlu23_0_split needs backward computation.
I1006 17:36:09.214725  3702 net.cpp:198] penlu23 needs backward computation.
I1006 17:36:09.214727  3702 net.cpp:198] Eltwise11 needs backward computation.
I1006 17:36:09.214730  3702 net.cpp:198] Scale25 needs backward computation.
I1006 17:36:09.214732  3702 net.cpp:198] BatchNorm25 needs backward computation.
I1006 17:36:09.214735  3702 net.cpp:198] Convolution25 needs backward computation.
I1006 17:36:09.214736  3702 net.cpp:198] penlu22 needs backward computation.
I1006 17:36:09.214738  3702 net.cpp:198] Scale24 needs backward computation.
I1006 17:36:09.214741  3702 net.cpp:198] BatchNorm24 needs backward computation.
I1006 17:36:09.214743  3702 net.cpp:198] Convolution24 needs backward computation.
I1006 17:36:09.214746  3702 net.cpp:198] Scale23 needs backward computation.
I1006 17:36:09.214748  3702 net.cpp:198] BatchNorm23 needs backward computation.
I1006 17:36:09.214751  3702 net.cpp:198] Convolution23 needs backward computation.
I1006 17:36:09.214753  3702 net.cpp:198] Eltwise10_penlu21_0_split needs backward computation.
I1006 17:36:09.214756  3702 net.cpp:198] penlu21 needs backward computation.
I1006 17:36:09.214757  3702 net.cpp:198] Eltwise10 needs backward computation.
I1006 17:36:09.214761  3702 net.cpp:198] Scale22 needs backward computation.
I1006 17:36:09.214762  3702 net.cpp:198] BatchNorm22 needs backward computation.
I1006 17:36:09.214764  3702 net.cpp:198] Convolution22 needs backward computation.
I1006 17:36:09.214766  3702 net.cpp:198] penlu20 needs backward computation.
I1006 17:36:09.214768  3702 net.cpp:198] Scale21 needs backward computation.
I1006 17:36:09.214771  3702 net.cpp:198] BatchNorm21 needs backward computation.
I1006 17:36:09.214772  3702 net.cpp:198] Convolution21 needs backward computation.
I1006 17:36:09.214776  3702 net.cpp:198] Eltwise9_penlu19_0_split needs backward computation.
I1006 17:36:09.214778  3702 net.cpp:198] penlu19 needs backward computation.
I1006 17:36:09.214781  3702 net.cpp:198] Eltwise9 needs backward computation.
I1006 17:36:09.214782  3702 net.cpp:198] Scale20 needs backward computation.
I1006 17:36:09.214784  3702 net.cpp:198] BatchNorm20 needs backward computation.
I1006 17:36:09.214787  3702 net.cpp:198] Convolution20 needs backward computation.
I1006 17:36:09.214789  3702 net.cpp:198] penlu18 needs backward computation.
I1006 17:36:09.214792  3702 net.cpp:198] Scale19 needs backward computation.
I1006 17:36:09.214794  3702 net.cpp:198] BatchNorm19 needs backward computation.
I1006 17:36:09.214797  3702 net.cpp:198] Convolution19 needs backward computation.
I1006 17:36:09.238245  3702 net.cpp:198] Eltwise8_penlu17_0_split needs backward computation.
I1006 17:36:09.238255  3702 net.cpp:198] penlu17 needs backward computation.
I1006 17:36:09.238260  3702 net.cpp:198] Eltwise8 needs backward computation.
I1006 17:36:09.238267  3702 net.cpp:198] Scale18 needs backward computation.
I1006 17:36:09.238271  3702 net.cpp:198] BatchNorm18 needs backward computation.
I1006 17:36:09.238276  3702 net.cpp:198] Convolution18 needs backward computation.
I1006 17:36:09.238281  3702 net.cpp:198] penlu16 needs backward computation.
I1006 17:36:09.238284  3702 net.cpp:198] Scale17 needs backward computation.
I1006 17:36:09.238287  3702 net.cpp:198] BatchNorm17 needs backward computation.
I1006 17:36:09.238291  3702 net.cpp:198] Convolution17 needs backward computation.
I1006 17:36:09.238296  3702 net.cpp:198] Eltwise7_penlu15_0_split needs backward computation.
I1006 17:36:09.238301  3702 net.cpp:198] penlu15 needs backward computation.
I1006 17:36:09.238304  3702 net.cpp:198] Eltwise7 needs backward computation.
I1006 17:36:09.238309  3702 net.cpp:198] Scale16 needs backward computation.
I1006 17:36:09.238313  3702 net.cpp:198] BatchNorm16 needs backward computation.
I1006 17:36:09.238317  3702 net.cpp:198] Convolution16 needs backward computation.
I1006 17:36:09.238322  3702 net.cpp:198] penlu14 needs backward computation.
I1006 17:36:09.238325  3702 net.cpp:198] Scale15 needs backward computation.
I1006 17:36:09.238329  3702 net.cpp:198] BatchNorm15 needs backward computation.
I1006 17:36:09.238333  3702 net.cpp:198] Convolution15 needs backward computation.
I1006 17:36:09.238338  3702 net.cpp:198] Eltwise6_penlu13_0_split needs backward computation.
I1006 17:36:09.238343  3702 net.cpp:198] penlu13 needs backward computation.
I1006 17:36:09.238346  3702 net.cpp:198] Eltwise6 needs backward computation.
I1006 17:36:09.238351  3702 net.cpp:198] Scale14 needs backward computation.
I1006 17:36:09.238355  3702 net.cpp:198] BatchNorm14 needs backward computation.
I1006 17:36:09.238359  3702 net.cpp:198] Convolution14 needs backward computation.
I1006 17:36:09.238364  3702 net.cpp:198] penlu12 needs backward computation.
I1006 17:36:09.238368  3702 net.cpp:198] Scale13 needs backward computation.
I1006 17:36:09.238373  3702 net.cpp:198] BatchNorm13 needs backward computation.
I1006 17:36:09.238376  3702 net.cpp:198] Convolution13 needs backward computation.
I1006 17:36:09.238380  3702 net.cpp:198] Scale12 needs backward computation.
I1006 17:36:09.238384  3702 net.cpp:198] BatchNorm12 needs backward computation.
I1006 17:36:09.238389  3702 net.cpp:198] Convolution12 needs backward computation.
I1006 17:36:09.238394  3702 net.cpp:198] Eltwise5_penlu11_0_split needs backward computation.
I1006 17:36:09.238397  3702 net.cpp:198] penlu11 needs backward computation.
I1006 17:36:09.238401  3702 net.cpp:198] Eltwise5 needs backward computation.
I1006 17:36:09.238407  3702 net.cpp:198] Scale11 needs backward computation.
I1006 17:36:09.238411  3702 net.cpp:198] BatchNorm11 needs backward computation.
I1006 17:36:09.238415  3702 net.cpp:198] Convolution11 needs backward computation.
I1006 17:36:09.238420  3702 net.cpp:198] penlu10 needs backward computation.
I1006 17:36:09.238425  3702 net.cpp:198] Scale10 needs backward computation.
I1006 17:36:09.238428  3702 net.cpp:198] BatchNorm10 needs backward computation.
I1006 17:36:09.238432  3702 net.cpp:198] Convolution10 needs backward computation.
I1006 17:36:09.238437  3702 net.cpp:198] Eltwise4_penlu9_0_split needs backward computation.
I1006 17:36:09.238442  3702 net.cpp:198] penlu9 needs backward computation.
I1006 17:36:09.238446  3702 net.cpp:198] Eltwise4 needs backward computation.
I1006 17:36:09.238451  3702 net.cpp:198] Scale9 needs backward computation.
I1006 17:36:09.238456  3702 net.cpp:198] BatchNorm9 needs backward computation.
I1006 17:36:09.238461  3702 net.cpp:198] Convolution9 needs backward computation.
I1006 17:36:09.238466  3702 net.cpp:198] penlu8 needs backward computation.
I1006 17:36:09.238469  3702 net.cpp:198] Scale8 needs backward computation.
I1006 17:36:09.238483  3702 net.cpp:198] BatchNorm8 needs backward computation.
I1006 17:36:09.238488  3702 net.cpp:198] Convolution8 needs backward computation.
I1006 17:36:09.238492  3702 net.cpp:198] Eltwise3_penlu7_0_split needs backward computation.
I1006 17:36:09.238497  3702 net.cpp:198] penlu7 needs backward computation.
I1006 17:36:09.238502  3702 net.cpp:198] Eltwise3 needs backward computation.
I1006 17:36:09.238507  3702 net.cpp:198] Scale7 needs backward computation.
I1006 17:36:09.238512  3702 net.cpp:198] BatchNorm7 needs backward computation.
I1006 17:36:09.238515  3702 net.cpp:198] Convolution7 needs backward computation.
I1006 17:36:09.238519  3702 net.cpp:198] penlu6 needs backward computation.
I1006 17:36:09.238523  3702 net.cpp:198] Scale6 needs backward computation.
I1006 17:36:09.238528  3702 net.cpp:198] BatchNorm6 needs backward computation.
I1006 17:36:09.238533  3702 net.cpp:198] Convolution6 needs backward computation.
I1006 17:36:09.238536  3702 net.cpp:198] Eltwise2_penlu5_0_split needs backward computation.
I1006 17:36:09.238541  3702 net.cpp:198] penlu5 needs backward computation.
I1006 17:36:09.238545  3702 net.cpp:198] Eltwise2 needs backward computation.
I1006 17:36:09.238550  3702 net.cpp:198] Scale5 needs backward computation.
I1006 17:36:09.238555  3702 net.cpp:198] BatchNorm5 needs backward computation.
I1006 17:36:09.238559  3702 net.cpp:198] Convolution5 needs backward computation.
I1006 17:36:09.238564  3702 net.cpp:198] penlu4 needs backward computation.
I1006 17:36:09.238567  3702 net.cpp:198] Scale4 needs backward computation.
I1006 17:36:09.238572  3702 net.cpp:198] BatchNorm4 needs backward computation.
I1006 17:36:09.238576  3702 net.cpp:198] Convolution4 needs backward computation.
I1006 17:36:09.238581  3702 net.cpp:198] Eltwise1_penlu3_0_split needs backward computation.
I1006 17:36:09.238585  3702 net.cpp:198] penlu3 needs backward computation.
I1006 17:36:09.238591  3702 net.cpp:198] Eltwise1 needs backward computation.
I1006 17:36:09.238596  3702 net.cpp:198] Scale3 needs backward computation.
I1006 17:36:09.238601  3702 net.cpp:198] BatchNorm3 needs backward computation.
I1006 17:36:09.238605  3702 net.cpp:198] Convolution3 needs backward computation.
I1006 17:36:09.238610  3702 net.cpp:198] penlu2 needs backward computation.
I1006 17:36:09.238615  3702 net.cpp:198] Scale2 needs backward computation.
I1006 17:36:09.238618  3702 net.cpp:198] BatchNorm2 needs backward computation.
I1006 17:36:09.238622  3702 net.cpp:198] Convolution2 needs backward computation.
I1006 17:36:09.238627  3702 net.cpp:198] Convolution1_penlu1_0_split needs backward computation.
I1006 17:36:09.238632  3702 net.cpp:198] penlu1 needs backward computation.
I1006 17:36:09.238636  3702 net.cpp:198] Scale1 needs backward computation.
I1006 17:36:09.238641  3702 net.cpp:198] BatchNorm1 needs backward computation.
I1006 17:36:09.238646  3702 net.cpp:198] Convolution1 needs backward computation.
I1006 17:36:09.238651  3702 net.cpp:200] Data2_Data1_1_split does not need backward computation.
I1006 17:36:09.238656  3702 net.cpp:200] Data1 does not need backward computation.
I1006 17:36:09.238659  3702 net.cpp:242] This network produces output Accuracy1
I1006 17:36:09.238663  3702 net.cpp:242] This network produces output SoftmaxWithLoss1
I1006 17:36:09.238755  3702 net.cpp:255] Network initialization done.
I1006 17:36:09.239390  3702 solver.cpp:56] Solver scaffolding done.
I1006 17:36:09.248927  3702 caffe.cpp:248] Starting Optimization
I1006 17:36:09.248941  3702 solver.cpp:272] Solving resnet_cifar10
I1006 17:36:09.248944  3702 solver.cpp:273] Learning Rate Policy: multistep
I1006 17:36:09.252550  3702 solver.cpp:330] Iteration 0, Testing net (#0)
I1006 17:36:11.218888  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:36:11.298445  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.1
I1006 17:36:11.298480  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 87.3365 (* 1 = 87.3365 loss)
I1006 17:36:11.415313  3702 solver.cpp:218] Iteration 0 (0 iter/s, 2.1663s/100 iters), loss = 2.32816
I1006 17:36:11.415350  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 2.32816 (* 1 = 2.32816 loss)
I1006 17:36:11.415364  3702 sgd_solver.cpp:105] Iteration 0, lr = 0.1
I1006 17:36:19.741860  3702 solver.cpp:218] Iteration 100 (12.0099 iter/s, 8.32648s/100 iters), loss = 1.73274
I1006 17:36:19.741899  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.73274 (* 1 = 1.73274 loss)
I1006 17:36:19.741905  3702 sgd_solver.cpp:105] Iteration 100, lr = 0.1
I1006 17:36:28.055958  3702 solver.cpp:218] Iteration 200 (12.0279 iter/s, 8.31404s/100 iters), loss = 1.83487
I1006 17:36:28.055999  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.83487 (* 1 = 1.83487 loss)
I1006 17:36:28.056005  3702 sgd_solver.cpp:105] Iteration 200, lr = 0.1
I1006 17:36:36.365245  3702 solver.cpp:218] Iteration 300 (12.0348 iter/s, 8.30922s/100 iters), loss = 1.42728
I1006 17:36:36.365275  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.42728 (* 1 = 1.42728 loss)
I1006 17:36:36.365281  3702 sgd_solver.cpp:105] Iteration 300, lr = 0.1
I1006 17:36:44.684315  3702 solver.cpp:218] Iteration 400 (12.0207 iter/s, 8.31901s/100 iters), loss = 1.25839
I1006 17:36:44.684398  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.25839 (* 1 = 1.25839 loss)
I1006 17:36:44.684404  3702 sgd_solver.cpp:105] Iteration 400, lr = 0.1
I1006 17:36:52.589753  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:36:52.923230  3702 solver.cpp:330] Iteration 500, Testing net (#0)
I1006 17:36:54.850894  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:36:54.931231  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.2344
I1006 17:36:54.931257  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 3.45185 (* 1 = 3.45185 loss)
I1006 17:36:55.014883  3702 solver.cpp:218] Iteration 500 (9.68012 iter/s, 10.3305s/100 iters), loss = 1.30249
I1006 17:36:55.014909  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.30249 (* 1 = 1.30249 loss)
I1006 17:36:55.014914  3702 sgd_solver.cpp:105] Iteration 500, lr = 0.1
I1006 17:37:03.349712  3702 solver.cpp:218] Iteration 600 (11.9979 iter/s, 8.33477s/100 iters), loss = 1.19948
I1006 17:37:03.349752  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.19948 (* 1 = 1.19948 loss)
I1006 17:37:03.349758  3702 sgd_solver.cpp:105] Iteration 600, lr = 0.1
I1006 17:37:11.676931  3702 solver.cpp:218] Iteration 700 (12.0089 iter/s, 8.32715s/100 iters), loss = 1.09051
I1006 17:37:11.676960  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.09051 (* 1 = 1.09051 loss)
I1006 17:37:11.676966  3702 sgd_solver.cpp:105] Iteration 700, lr = 0.1
I1006 17:37:20.011126  3702 solver.cpp:218] Iteration 800 (11.9988 iter/s, 8.33414s/100 iters), loss = 1.16346
I1006 17:37:20.011237  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.16346 (* 1 = 1.16346 loss)
I1006 17:37:20.011257  3702 sgd_solver.cpp:105] Iteration 800, lr = 0.1
I1006 17:37:28.342396  3702 solver.cpp:218] Iteration 900 (12.0032 iter/s, 8.33113s/100 iters), loss = 0.889357
I1006 17:37:28.342435  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.889357 (* 1 = 0.889357 loss)
I1006 17:37:28.342442  3702 sgd_solver.cpp:105] Iteration 900, lr = 0.1
I1006 17:37:36.260275  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:37:36.593641  3702 solver.cpp:330] Iteration 1000, Testing net (#0)
I1006 17:37:38.521786  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:37:38.602684  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.3361
I1006 17:37:38.602720  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 2.55962 (* 1 = 2.55962 loss)
I1006 17:37:38.685132  3702 solver.cpp:218] Iteration 1000 (9.66869 iter/s, 10.3427s/100 iters), loss = 0.946218
I1006 17:37:38.685155  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.946218 (* 1 = 0.946218 loss)
I1006 17:37:38.685163  3702 sgd_solver.cpp:105] Iteration 1000, lr = 0.1
I1006 17:37:47.016247  3702 solver.cpp:218] Iteration 1100 (12.0033 iter/s, 8.33106s/100 iters), loss = 0.773344
I1006 17:37:47.016286  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.773344 (* 1 = 0.773344 loss)
I1006 17:37:47.016293  3702 sgd_solver.cpp:105] Iteration 1100, lr = 0.1
I1006 17:37:55.357350  3702 solver.cpp:218] Iteration 1200 (11.9889 iter/s, 8.34103s/100 iters), loss = 0.77525
I1006 17:37:55.357496  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.77525 (* 1 = 0.77525 loss)
I1006 17:37:55.357514  3702 sgd_solver.cpp:105] Iteration 1200, lr = 0.1
I1006 17:38:03.694468  3702 solver.cpp:218] Iteration 1300 (11.9948 iter/s, 8.33695s/100 iters), loss = 0.882587
I1006 17:38:03.694507  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.882587 (* 1 = 0.882587 loss)
I1006 17:38:03.694514  3702 sgd_solver.cpp:105] Iteration 1300, lr = 0.1
I1006 17:38:12.032363  3702 solver.cpp:218] Iteration 1400 (11.9935 iter/s, 8.33783s/100 iters), loss = 0.767688
I1006 17:38:12.032402  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.767688 (* 1 = 0.767688 loss)
I1006 17:38:12.032408  3702 sgd_solver.cpp:105] Iteration 1400, lr = 0.1
I1006 17:38:19.951781  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:38:20.286484  3702 solver.cpp:330] Iteration 1500, Testing net (#0)
I1006 17:38:22.214428  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:38:22.295064  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.4003
I1006 17:38:22.295100  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 2.00294 (* 1 = 2.00294 loss)
I1006 17:38:22.379235  3702 solver.cpp:218] Iteration 1500 (9.66483 iter/s, 10.3468s/100 iters), loss = 0.80264
I1006 17:38:22.379261  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.80264 (* 1 = 0.80264 loss)
I1006 17:38:22.379267  3702 sgd_solver.cpp:105] Iteration 1500, lr = 0.1
I1006 17:38:30.714805  3702 solver.cpp:218] Iteration 1600 (11.9969 iter/s, 8.33552s/100 iters), loss = 0.621652
I1006 17:38:30.714912  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.621652 (* 1 = 0.621652 loss)
I1006 17:38:30.714920  3702 sgd_solver.cpp:105] Iteration 1600, lr = 0.1
I1006 17:38:39.048892  3702 solver.cpp:218] Iteration 1700 (11.9991 iter/s, 8.33395s/100 iters), loss = 0.653668
I1006 17:38:39.048929  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.653668 (* 1 = 0.653668 loss)
I1006 17:38:39.048935  3702 sgd_solver.cpp:105] Iteration 1700, lr = 0.1
I1006 17:38:47.382128  3702 solver.cpp:218] Iteration 1800 (12.0002 iter/s, 8.33317s/100 iters), loss = 0.832786
I1006 17:38:47.382158  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.832786 (* 1 = 0.832786 loss)
I1006 17:38:47.382163  3702 sgd_solver.cpp:105] Iteration 1800, lr = 0.1
I1006 17:38:55.715704  3702 solver.cpp:218] Iteration 1900 (11.9997 iter/s, 8.33352s/100 iters), loss = 0.589897
I1006 17:38:55.715744  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.589897 (* 1 = 0.589897 loss)
I1006 17:38:55.715749  3702 sgd_solver.cpp:105] Iteration 1900, lr = 0.1
I1006 17:39:03.640509  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:39:03.973609  3702 solver.cpp:330] Iteration 2000, Testing net (#0)
I1006 17:39:05.900015  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:39:05.981405  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.4188
I1006 17:39:05.981454  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.77147 (* 1 = 1.77147 loss)
I1006 17:39:06.064302  3702 solver.cpp:218] Iteration 2000 (9.66321 iter/s, 10.3485s/100 iters), loss = 0.740505
I1006 17:39:06.064327  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.740505 (* 1 = 0.740505 loss)
I1006 17:39:06.064334  3702 sgd_solver.cpp:105] Iteration 2000, lr = 0.1
I1006 17:39:14.400939  3702 solver.cpp:218] Iteration 2100 (11.9953 iter/s, 8.33659s/100 iters), loss = 0.510746
I1006 17:39:14.400979  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.510746 (* 1 = 0.510746 loss)
I1006 17:39:14.400985  3702 sgd_solver.cpp:105] Iteration 2100, lr = 0.1
I1006 17:39:22.741780  3702 solver.cpp:218] Iteration 2200 (11.9893 iter/s, 8.34077s/100 iters), loss = 0.59917
I1006 17:39:22.741808  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.59917 (* 1 = 0.59917 loss)
I1006 17:39:22.741816  3702 sgd_solver.cpp:105] Iteration 2200, lr = 0.1
I1006 17:39:31.075105  3702 solver.cpp:218] Iteration 2300 (12.0001 iter/s, 8.33327s/100 iters), loss = 0.667276
I1006 17:39:31.075145  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.667276 (* 1 = 0.667276 loss)
I1006 17:39:31.075151  3702 sgd_solver.cpp:105] Iteration 2300, lr = 0.1
I1006 17:39:39.415649  3702 solver.cpp:218] Iteration 2400 (11.9897 iter/s, 8.34048s/100 iters), loss = 0.554311
I1006 17:39:39.415758  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.554311 (* 1 = 0.554311 loss)
I1006 17:39:39.415774  3702 sgd_solver.cpp:105] Iteration 2400, lr = 0.1
I1006 17:39:47.342761  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:39:47.676224  3702 solver.cpp:330] Iteration 2500, Testing net (#0)
I1006 17:39:49.602090  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:39:49.682770  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.535
I1006 17:39:49.682796  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.2643 (* 1 = 1.2643 loss)
I1006 17:39:49.766185  3702 solver.cpp:218] Iteration 2500 (9.66147 iter/s, 10.3504s/100 iters), loss = 0.634576
I1006 17:39:49.766213  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.634576 (* 1 = 0.634576 loss)
I1006 17:39:49.766219  3702 sgd_solver.cpp:105] Iteration 2500, lr = 0.1
I1006 17:39:58.106695  3702 solver.cpp:218] Iteration 2600 (11.9898 iter/s, 8.34046s/100 iters), loss = 0.52508
I1006 17:39:58.106725  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.52508 (* 1 = 0.52508 loss)
I1006 17:39:58.106730  3702 sgd_solver.cpp:105] Iteration 2600, lr = 0.1
I1006 17:40:06.443876  3702 solver.cpp:218] Iteration 2700 (11.9945 iter/s, 8.33712s/100 iters), loss = 0.471204
I1006 17:40:06.443915  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.471204 (* 1 = 0.471204 loss)
I1006 17:40:06.443922  3702 sgd_solver.cpp:105] Iteration 2700, lr = 0.1
I1006 17:40:14.786819  3702 solver.cpp:218] Iteration 2800 (11.9863 iter/s, 8.34288s/100 iters), loss = 0.558854
I1006 17:40:14.786954  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.558854 (* 1 = 0.558854 loss)
I1006 17:40:14.786962  3702 sgd_solver.cpp:105] Iteration 2800, lr = 0.1
I1006 17:40:23.124214  3702 solver.cpp:218] Iteration 2900 (11.9944 iter/s, 8.33725s/100 iters), loss = 0.496636
I1006 17:40:23.124255  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.496636 (* 1 = 0.496636 loss)
I1006 17:40:23.124261  3702 sgd_solver.cpp:105] Iteration 2900, lr = 0.1
I1006 17:40:31.055709  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:40:31.389070  3702 solver.cpp:330] Iteration 3000, Testing net (#0)
I1006 17:40:33.316165  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:40:33.396878  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.5306
I1006 17:40:33.396912  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.33908 (* 1 = 1.33908 loss)
I1006 17:40:33.479574  3702 solver.cpp:218] Iteration 3000 (9.6569 iter/s, 10.3553s/100 iters), loss = 0.627567
I1006 17:40:33.479599  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.627567 (* 1 = 0.627567 loss)
I1006 17:40:33.479605  3702 sgd_solver.cpp:105] Iteration 3000, lr = 0.1
I1006 17:40:41.798265  3702 solver.cpp:218] Iteration 3100 (12.0212 iter/s, 8.31864s/100 iters), loss = 0.418676
I1006 17:40:41.798306  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.418676 (* 1 = 0.418676 loss)
I1006 17:40:41.798311  3702 sgd_solver.cpp:105] Iteration 3100, lr = 0.1
I1006 17:40:50.121139  3702 solver.cpp:218] Iteration 3200 (12.0152 iter/s, 8.32281s/100 iters), loss = 0.465415
I1006 17:40:50.121256  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.465415 (* 1 = 0.465415 loss)
I1006 17:40:50.121264  3702 sgd_solver.cpp:105] Iteration 3200, lr = 0.1
I1006 17:40:58.441587  3702 solver.cpp:218] Iteration 3300 (12.0188 iter/s, 8.32032s/100 iters), loss = 0.61853
I1006 17:40:58.441615  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.61853 (* 1 = 0.61853 loss)
I1006 17:40:58.441622  3702 sgd_solver.cpp:105] Iteration 3300, lr = 0.1
I1006 17:41:06.767024  3702 solver.cpp:218] Iteration 3400 (12.0115 iter/s, 8.32538s/100 iters), loss = 0.457292
I1006 17:41:06.767053  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.457292 (* 1 = 0.457292 loss)
I1006 17:41:06.767069  3702 sgd_solver.cpp:105] Iteration 3400, lr = 0.1
I1006 17:41:14.674666  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:41:15.007838  3702 solver.cpp:330] Iteration 3500, Testing net (#0)
I1006 17:41:16.933950  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:41:17.014749  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6433
I1006 17:41:17.014773  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.05731 (* 1 = 1.05731 loss)
I1006 17:41:17.098055  3702 solver.cpp:218] Iteration 3500 (9.67963 iter/s, 10.331s/100 iters), loss = 0.501651
I1006 17:41:17.098088  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.501651 (* 1 = 0.501651 loss)
I1006 17:41:17.098095  3702 sgd_solver.cpp:105] Iteration 3500, lr = 0.1
I1006 17:41:25.425065  3702 solver.cpp:218] Iteration 3600 (12.0092 iter/s, 8.32695s/100 iters), loss = 0.388637
I1006 17:41:25.425209  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.388637 (* 1 = 0.388637 loss)
I1006 17:41:25.425217  3702 sgd_solver.cpp:105] Iteration 3600, lr = 0.1
I1006 17:41:33.739998  3702 solver.cpp:218] Iteration 3700 (12.0268 iter/s, 8.31477s/100 iters), loss = 0.452976
I1006 17:41:33.740026  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.452976 (* 1 = 0.452976 loss)
I1006 17:41:33.740032  3702 sgd_solver.cpp:105] Iteration 3700, lr = 0.1
I1006 17:41:42.064308  3702 solver.cpp:218] Iteration 3800 (12.0131 iter/s, 8.32426s/100 iters), loss = 0.503158
I1006 17:41:42.064347  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.503158 (* 1 = 0.503158 loss)
I1006 17:41:42.064353  3702 sgd_solver.cpp:105] Iteration 3800, lr = 0.1
I1006 17:41:50.387212  3702 solver.cpp:218] Iteration 3900 (12.0151 iter/s, 8.32284s/100 iters), loss = 0.383938
I1006 17:41:50.387241  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.383938 (* 1 = 0.383938 loss)
I1006 17:41:50.387248  3702 sgd_solver.cpp:105] Iteration 3900, lr = 0.1
I1006 17:41:58.297837  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:41:58.630795  3702 solver.cpp:330] Iteration 4000, Testing net (#0)
I1006 17:42:00.559538  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:42:00.640383  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.658
I1006 17:42:00.640408  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.931745 (* 1 = 0.931745 loss)
I1006 17:42:00.723381  3702 solver.cpp:218] Iteration 4000 (9.67482 iter/s, 10.3361s/100 iters), loss = 0.458029
I1006 17:42:00.723407  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.458029 (* 1 = 0.458029 loss)
I1006 17:42:00.723413  3702 sgd_solver.cpp:105] Iteration 4000, lr = 0.1
I1006 17:42:09.053373  3702 solver.cpp:218] Iteration 4100 (12.0049 iter/s, 8.32994s/100 iters), loss = 0.392996
I1006 17:42:09.053412  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.392996 (* 1 = 0.392996 loss)
I1006 17:42:09.053418  3702 sgd_solver.cpp:105] Iteration 4100, lr = 0.1
I1006 17:42:17.384706  3702 solver.cpp:218] Iteration 4200 (12.003 iter/s, 8.33127s/100 iters), loss = 0.437791
I1006 17:42:17.384735  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.437791 (* 1 = 0.437791 loss)
I1006 17:42:17.384742  3702 sgd_solver.cpp:105] Iteration 4200, lr = 0.1
I1006 17:42:25.709813  3702 solver.cpp:218] Iteration 4300 (12.0119 iter/s, 8.32505s/100 iters), loss = 0.447867
I1006 17:42:25.709853  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.447867 (* 1 = 0.447867 loss)
I1006 17:42:25.709861  3702 sgd_solver.cpp:105] Iteration 4300, lr = 0.1
I1006 17:42:34.044010  3702 solver.cpp:218] Iteration 4400 (11.9988 iter/s, 8.33414s/100 iters), loss = 0.417366
I1006 17:42:34.044139  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.417366 (* 1 = 0.417366 loss)
I1006 17:42:34.044155  3702 sgd_solver.cpp:105] Iteration 4400, lr = 0.1
I1006 17:42:41.962600  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:42:42.296272  3702 solver.cpp:330] Iteration 4500, Testing net (#0)
I1006 17:42:44.223224  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:42:44.303465  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.66
I1006 17:42:44.303490  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.01402 (* 1 = 1.01402 loss)
I1006 17:42:44.387361  3702 solver.cpp:218] Iteration 4500 (9.66819 iter/s, 10.3432s/100 iters), loss = 0.403155
I1006 17:42:44.387398  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.403155 (* 1 = 0.403155 loss)
I1006 17:42:44.387408  3702 sgd_solver.cpp:105] Iteration 4500, lr = 0.1
I1006 17:42:52.724294  3702 solver.cpp:218] Iteration 4600 (11.9949 iter/s, 8.33687s/100 iters), loss = 0.385072
I1006 17:42:52.724334  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.385072 (* 1 = 0.385072 loss)
I1006 17:42:52.724339  3702 sgd_solver.cpp:105] Iteration 4600, lr = 0.1
I1006 17:43:01.060350  3702 solver.cpp:218] Iteration 4700 (11.9962 iter/s, 8.33599s/100 iters), loss = 0.364681
I1006 17:43:01.060379  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.364681 (* 1 = 0.364681 loss)
I1006 17:43:01.060384  3702 sgd_solver.cpp:105] Iteration 4700, lr = 0.1
I1006 17:43:09.399768  3702 solver.cpp:218] Iteration 4800 (11.9913 iter/s, 8.33936s/100 iters), loss = 0.48457
I1006 17:43:09.399879  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.48457 (* 1 = 0.48457 loss)
I1006 17:43:09.399886  3702 sgd_solver.cpp:105] Iteration 4800, lr = 0.1
I1006 17:43:17.726934  3702 solver.cpp:218] Iteration 4900 (12.0091 iter/s, 8.32704s/100 iters), loss = 0.380468
I1006 17:43:17.726974  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.380468 (* 1 = 0.380468 loss)
I1006 17:43:17.726979  3702 sgd_solver.cpp:105] Iteration 4900, lr = 0.1
I1006 17:43:25.651229  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:43:25.984892  3702 solver.cpp:330] Iteration 5000, Testing net (#0)
I1006 17:43:27.911530  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:43:27.992743  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.71
I1006 17:43:27.992769  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.802341 (* 1 = 0.802341 loss)
I1006 17:43:28.075701  3702 solver.cpp:218] Iteration 5000 (9.66305 iter/s, 10.3487s/100 iters), loss = 0.434124
I1006 17:43:28.075731  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.434124 (* 1 = 0.434124 loss)
I1006 17:43:28.075737  3702 sgd_solver.cpp:105] Iteration 5000, lr = 0.1
I1006 17:43:36.410883  3702 solver.cpp:218] Iteration 5100 (11.9974 iter/s, 8.33513s/100 iters), loss = 0.409483
I1006 17:43:36.410912  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.409483 (* 1 = 0.409483 loss)
I1006 17:43:36.410917  3702 sgd_solver.cpp:105] Iteration 5100, lr = 0.1
I1006 17:43:44.750509  3702 solver.cpp:218] Iteration 5200 (11.991 iter/s, 8.33957s/100 iters), loss = 0.364987
I1006 17:43:44.750641  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.364987 (* 1 = 0.364987 loss)
I1006 17:43:44.750648  3702 sgd_solver.cpp:105] Iteration 5200, lr = 0.1
I1006 17:43:53.081542  3702 solver.cpp:218] Iteration 5300 (12.0035 iter/s, 8.33088s/100 iters), loss = 0.503953
I1006 17:43:53.081570  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.503953 (* 1 = 0.503953 loss)
I1006 17:43:53.081576  3702 sgd_solver.cpp:105] Iteration 5300, lr = 0.1
I1006 17:44:01.419705  3702 solver.cpp:218] Iteration 5400 (11.9931 iter/s, 8.33811s/100 iters), loss = 0.421601
I1006 17:44:01.419735  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.421601 (* 1 = 0.421601 loss)
I1006 17:44:01.419741  3702 sgd_solver.cpp:105] Iteration 5400, lr = 0.1
I1006 17:44:09.339766  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:44:09.673076  3702 solver.cpp:330] Iteration 5500, Testing net (#0)
I1006 17:44:11.600371  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:44:11.680737  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6533
I1006 17:44:11.680771  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.01081 (* 1 = 1.01081 loss)
I1006 17:44:11.764041  3702 solver.cpp:218] Iteration 5500 (9.66718 iter/s, 10.3443s/100 iters), loss = 0.408476
I1006 17:44:11.764066  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.408476 (* 1 = 0.408476 loss)
I1006 17:44:11.764073  3702 sgd_solver.cpp:105] Iteration 5500, lr = 0.1
I1006 17:44:20.099426  3702 solver.cpp:218] Iteration 5600 (11.9971 iter/s, 8.33533s/100 iters), loss = 0.398867
I1006 17:44:20.099563  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.398867 (* 1 = 0.398867 loss)
I1006 17:44:20.099571  3702 sgd_solver.cpp:105] Iteration 5600, lr = 0.1
I1006 17:44:28.426354  3702 solver.cpp:218] Iteration 5700 (12.0095 iter/s, 8.32677s/100 iters), loss = 0.356643
I1006 17:44:28.426383  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.356643 (* 1 = 0.356643 loss)
I1006 17:44:28.426389  3702 sgd_solver.cpp:105] Iteration 5700, lr = 0.1
I1006 17:44:36.757447  3702 solver.cpp:218] Iteration 5800 (12.0033 iter/s, 8.33104s/100 iters), loss = 0.416779
I1006 17:44:36.757475  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.416779 (* 1 = 0.416779 loss)
I1006 17:44:36.757481  3702 sgd_solver.cpp:105] Iteration 5800, lr = 0.1
I1006 17:44:45.085252  3702 solver.cpp:218] Iteration 5900 (12.008 iter/s, 8.32775s/100 iters), loss = 0.408416
I1006 17:44:45.085279  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.408416 (* 1 = 0.408416 loss)
I1006 17:44:45.085295  3702 sgd_solver.cpp:105] Iteration 5900, lr = 0.1
I1006 17:44:53.005630  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:44:53.341164  3702 solver.cpp:330] Iteration 6000, Testing net (#0)
I1006 17:44:55.268208  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:44:55.349282  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7252
I1006 17:44:55.349305  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.856475 (* 1 = 0.856475 loss)
I1006 17:44:55.431951  3702 solver.cpp:218] Iteration 6000 (9.66497 iter/s, 10.3466s/100 iters), loss = 0.353813
I1006 17:44:55.431977  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.353813 (* 1 = 0.353813 loss)
I1006 17:44:55.431984  3702 sgd_solver.cpp:105] Iteration 6000, lr = 0.1
I1006 17:45:03.766738  3702 solver.cpp:218] Iteration 6100 (11.998 iter/s, 8.33473s/100 iters), loss = 0.326384
I1006 17:45:03.766777  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.326384 (* 1 = 0.326384 loss)
I1006 17:45:03.766783  3702 sgd_solver.cpp:105] Iteration 6100, lr = 0.1
I1006 17:45:12.099231  3702 solver.cpp:218] Iteration 6200 (12.0013 iter/s, 8.33243s/100 iters), loss = 0.33935
I1006 17:45:12.099261  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.33935 (* 1 = 0.33935 loss)
I1006 17:45:12.099267  3702 sgd_solver.cpp:105] Iteration 6200, lr = 0.1
I1006 17:45:20.425127  3702 solver.cpp:218] Iteration 6300 (12.0108 iter/s, 8.32584s/100 iters), loss = 0.430132
I1006 17:45:20.425180  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.430132 (* 1 = 0.430132 loss)
I1006 17:45:20.425189  3702 sgd_solver.cpp:105] Iteration 6300, lr = 0.1
I1006 17:45:28.755141  3702 solver.cpp:218] Iteration 6400 (12.0049 iter/s, 8.32994s/100 iters), loss = 0.376713
I1006 17:45:28.755292  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.376713 (* 1 = 0.376713 loss)
I1006 17:45:28.755300  3702 sgd_solver.cpp:105] Iteration 6400, lr = 0.1
I1006 17:45:36.665124  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:45:36.998304  3702 solver.cpp:330] Iteration 6500, Testing net (#0)
I1006 17:45:38.922580  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:45:39.002305  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7092
I1006 17:45:39.002327  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.872915 (* 1 = 0.872915 loss)
I1006 17:45:39.085448  3702 solver.cpp:218] Iteration 6500 (9.68042 iter/s, 10.3301s/100 iters), loss = 0.35418
I1006 17:45:39.085484  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.35418 (* 1 = 0.35418 loss)
I1006 17:45:39.085490  3702 sgd_solver.cpp:105] Iteration 6500, lr = 0.1
I1006 17:45:47.407347  3702 solver.cpp:218] Iteration 6600 (12.0166 iter/s, 8.32184s/100 iters), loss = 0.403615
I1006 17:45:47.407377  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.403615 (* 1 = 0.403615 loss)
I1006 17:45:47.407383  3702 sgd_solver.cpp:105] Iteration 6600, lr = 0.1
I1006 17:45:55.730478  3702 solver.cpp:218] Iteration 6700 (12.0148 iter/s, 8.32308s/100 iters), loss = 0.264794
I1006 17:45:55.730517  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.264794 (* 1 = 0.264794 loss)
I1006 17:45:55.730523  3702 sgd_solver.cpp:105] Iteration 6700, lr = 0.1
I1006 17:46:04.054818  3702 solver.cpp:218] Iteration 6800 (12.0131 iter/s, 8.32427s/100 iters), loss = 0.35209
I1006 17:46:04.054918  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.35209 (* 1 = 0.35209 loss)
I1006 17:46:04.054924  3702 sgd_solver.cpp:105] Iteration 6800, lr = 0.1
I1006 17:46:12.377940  3702 solver.cpp:218] Iteration 6900 (12.0149 iter/s, 8.323s/100 iters), loss = 0.319101
I1006 17:46:12.377969  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.319101 (* 1 = 0.319101 loss)
I1006 17:46:12.377974  3702 sgd_solver.cpp:105] Iteration 6900, lr = 0.1
I1006 17:46:20.286232  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:46:20.619941  3702 solver.cpp:330] Iteration 7000, Testing net (#0)
I1006 17:46:22.546463  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:46:22.627087  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8015
I1006 17:46:22.627122  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.5941 (* 1 = 0.5941 loss)
I1006 17:46:22.709930  3702 solver.cpp:218] Iteration 7000 (9.67873 iter/s, 10.3319s/100 iters), loss = 0.295868
I1006 17:46:22.709955  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.295868 (* 1 = 0.295868 loss)
I1006 17:46:22.709962  3702 sgd_solver.cpp:105] Iteration 7000, lr = 0.1
I1006 17:46:31.030115  3702 solver.cpp:218] Iteration 7100 (12.019 iter/s, 8.32013s/100 iters), loss = 0.401178
I1006 17:46:31.030155  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.401178 (* 1 = 0.401178 loss)
I1006 17:46:31.030163  3702 sgd_solver.cpp:105] Iteration 7100, lr = 0.1
I1006 17:46:39.356528  3702 solver.cpp:218] Iteration 7200 (12.0101 iter/s, 8.32634s/100 iters), loss = 0.378339
I1006 17:46:39.356645  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.378339 (* 1 = 0.378339 loss)
I1006 17:46:39.356663  3702 sgd_solver.cpp:105] Iteration 7200, lr = 0.1
I1006 17:46:47.675745  3702 solver.cpp:218] Iteration 7300 (12.0206 iter/s, 8.31907s/100 iters), loss = 0.436084
I1006 17:46:47.675784  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.436084 (* 1 = 0.436084 loss)
I1006 17:46:47.675791  3702 sgd_solver.cpp:105] Iteration 7300, lr = 0.1
I1006 17:46:56.000859  3702 solver.cpp:218] Iteration 7400 (12.0119 iter/s, 8.32505s/100 iters), loss = 0.331713
I1006 17:46:56.000897  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.331713 (* 1 = 0.331713 loss)
I1006 17:46:56.000902  3702 sgd_solver.cpp:105] Iteration 7400, lr = 0.1
I1006 17:47:03.911619  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:47:04.245502  3702 solver.cpp:330] Iteration 7500, Testing net (#0)
I1006 17:47:06.172654  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:47:06.253222  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7254
I1006 17:47:06.253257  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.839345 (* 1 = 0.839345 loss)
I1006 17:47:06.337069  3702 solver.cpp:218] Iteration 7500 (9.67479 iter/s, 10.3361s/100 iters), loss = 0.317846
I1006 17:47:06.337100  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.317846 (* 1 = 0.317846 loss)
I1006 17:47:06.337108  3702 sgd_solver.cpp:105] Iteration 7500, lr = 0.1
I1006 17:47:14.670917  3702 solver.cpp:218] Iteration 7600 (11.9993 iter/s, 8.33379s/100 iters), loss = 0.329541
I1006 17:47:14.671066  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.329541 (* 1 = 0.329541 loss)
I1006 17:47:14.671084  3702 sgd_solver.cpp:105] Iteration 7600, lr = 0.1
I1006 17:47:22.988762  3702 solver.cpp:218] Iteration 7700 (12.0226 iter/s, 8.31768s/100 iters), loss = 0.290629
I1006 17:47:22.988800  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.290629 (* 1 = 0.290629 loss)
I1006 17:47:22.988806  3702 sgd_solver.cpp:105] Iteration 7700, lr = 0.1
I1006 17:47:31.324251  3702 solver.cpp:218] Iteration 7800 (11.997 iter/s, 8.33543s/100 iters), loss = 0.36935
I1006 17:47:31.324285  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.36935 (* 1 = 0.36935 loss)
I1006 17:47:31.324290  3702 sgd_solver.cpp:105] Iteration 7800, lr = 0.1
I1006 17:47:39.653579  3702 solver.cpp:218] Iteration 7900 (12.0059 iter/s, 8.32927s/100 iters), loss = 0.318783
I1006 17:47:39.653609  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.318783 (* 1 = 0.318783 loss)
I1006 17:47:39.653614  3702 sgd_solver.cpp:105] Iteration 7900, lr = 0.1
I1006 17:47:47.574304  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:47:47.907987  3702 solver.cpp:330] Iteration 8000, Testing net (#0)
I1006 17:47:49.835566  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:47:49.916885  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6765
I1006 17:47:49.916919  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.944961 (* 1 = 0.944961 loss)
I1006 17:47:49.999445  3702 solver.cpp:218] Iteration 8000 (9.66575 iter/s, 10.3458s/100 iters), loss = 0.327417
I1006 17:47:49.999471  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.327417 (* 1 = 0.327417 loss)
I1006 17:47:49.999478  3702 sgd_solver.cpp:105] Iteration 8000, lr = 0.1
I1006 17:47:58.321904  3702 solver.cpp:218] Iteration 8100 (12.0158 iter/s, 8.3224s/100 iters), loss = 0.226276
I1006 17:47:58.321935  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.226277 (* 1 = 0.226277 loss)
I1006 17:47:58.321941  3702 sgd_solver.cpp:105] Iteration 8100, lr = 0.1
I1006 17:48:06.656517  3702 solver.cpp:218] Iteration 8200 (11.9982 iter/s, 8.33455s/100 iters), loss = 0.321788
I1006 17:48:06.656558  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.321788 (* 1 = 0.321788 loss)
I1006 17:48:06.656563  3702 sgd_solver.cpp:105] Iteration 8200, lr = 0.1
I1006 17:48:14.983561  3702 solver.cpp:218] Iteration 8300 (12.0092 iter/s, 8.32698s/100 iters), loss = 0.419174
I1006 17:48:14.983602  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.419174 (* 1 = 0.419174 loss)
I1006 17:48:14.983608  3702 sgd_solver.cpp:105] Iteration 8300, lr = 0.1
I1006 17:48:23.317972  3702 solver.cpp:218] Iteration 8400 (11.9985 iter/s, 8.33434s/100 iters), loss = 0.381088
I1006 17:48:23.318089  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.381088 (* 1 = 0.381088 loss)
I1006 17:48:23.318096  3702 sgd_solver.cpp:105] Iteration 8400, lr = 0.1
I1006 17:48:31.232762  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:48:31.565867  3702 solver.cpp:330] Iteration 8500, Testing net (#0)
I1006 17:48:33.493172  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:48:33.573658  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7868
I1006 17:48:33.573694  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.638745 (* 1 = 0.638745 loss)
I1006 17:48:33.657281  3702 solver.cpp:218] Iteration 8500 (9.67196 iter/s, 10.3392s/100 iters), loss = 0.323106
I1006 17:48:33.657307  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.323106 (* 1 = 0.323106 loss)
I1006 17:48:33.657313  3702 sgd_solver.cpp:105] Iteration 8500, lr = 0.1
I1006 17:48:41.991588  3702 solver.cpp:218] Iteration 8600 (11.9987 iter/s, 8.33425s/100 iters), loss = 0.336557
I1006 17:48:41.991618  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.336557 (* 1 = 0.336557 loss)
I1006 17:48:41.991623  3702 sgd_solver.cpp:105] Iteration 8600, lr = 0.1
I1006 17:48:50.324096  3702 solver.cpp:218] Iteration 8700 (12.0013 iter/s, 8.33245s/100 iters), loss = 0.362913
I1006 17:48:50.324126  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.362913 (* 1 = 0.362913 loss)
I1006 17:48:50.324131  3702 sgd_solver.cpp:105] Iteration 8700, lr = 0.1
I1006 17:48:58.656860  3702 solver.cpp:218] Iteration 8800 (12.0009 iter/s, 8.33271s/100 iters), loss = 0.312926
I1006 17:48:58.657007  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.312926 (* 1 = 0.312926 loss)
I1006 17:48:58.657013  3702 sgd_solver.cpp:105] Iteration 8800, lr = 0.1
I1006 17:49:06.994204  3702 solver.cpp:218] Iteration 8900 (11.9945 iter/s, 8.33718s/100 iters), loss = 0.244997
I1006 17:49:06.994233  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.244997 (* 1 = 0.244997 loss)
I1006 17:49:06.994238  3702 sgd_solver.cpp:105] Iteration 8900, lr = 0.1
I1006 17:49:14.909761  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:49:15.243711  3702 solver.cpp:330] Iteration 9000, Testing net (#0)
I1006 17:49:17.171304  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:49:17.252370  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7707
I1006 17:49:17.252405  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.688143 (* 1 = 0.688143 loss)
I1006 17:49:17.334730  3702 solver.cpp:218] Iteration 9000 (9.67074 iter/s, 10.3405s/100 iters), loss = 0.315019
I1006 17:49:17.334755  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.315019 (* 1 = 0.315019 loss)
I1006 17:49:17.334763  3702 sgd_solver.cpp:105] Iteration 9000, lr = 0.1
I1006 17:49:25.648490  3702 solver.cpp:218] Iteration 9100 (12.0283 iter/s, 8.31371s/100 iters), loss = 0.375858
I1006 17:49:25.648519  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.375858 (* 1 = 0.375858 loss)
I1006 17:49:25.648535  3702 sgd_solver.cpp:105] Iteration 9100, lr = 0.1
I1006 17:49:33.975091  3702 solver.cpp:218] Iteration 9200 (12.0098 iter/s, 8.32654s/100 iters), loss = 0.255696
I1006 17:49:33.975225  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.255696 (* 1 = 0.255696 loss)
I1006 17:49:33.975242  3702 sgd_solver.cpp:105] Iteration 9200, lr = 0.1
I1006 17:49:42.292765  3702 solver.cpp:218] Iteration 9300 (12.0228 iter/s, 8.31751s/100 iters), loss = 0.334321
I1006 17:49:42.292794  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.334321 (* 1 = 0.334321 loss)
I1006 17:49:42.292809  3702 sgd_solver.cpp:105] Iteration 9300, lr = 0.1
I1006 17:49:50.614007  3702 solver.cpp:218] Iteration 9400 (12.0175 iter/s, 8.32119s/100 iters), loss = 0.231503
I1006 17:49:50.614037  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.231503 (* 1 = 0.231503 loss)
I1006 17:49:50.614042  3702 sgd_solver.cpp:105] Iteration 9400, lr = 0.1
I1006 17:49:58.521986  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:49:58.854368  3702 solver.cpp:330] Iteration 9500, Testing net (#0)
I1006 17:50:00.782794  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:50:00.863152  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7306
I1006 17:50:00.863179  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.817372 (* 1 = 0.817372 loss)
I1006 17:50:00.946677  3702 solver.cpp:218] Iteration 9500 (9.6781 iter/s, 10.3326s/100 iters), loss = 0.276959
I1006 17:50:00.946703  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.276959 (* 1 = 0.276959 loss)
I1006 17:50:00.946710  3702 sgd_solver.cpp:105] Iteration 9500, lr = 0.1
I1006 17:50:09.279701  3702 solver.cpp:218] Iteration 9600 (12.0005 iter/s, 8.33297s/100 iters), loss = 0.248535
I1006 17:50:09.279882  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.248535 (* 1 = 0.248535 loss)
I1006 17:50:09.279901  3702 sgd_solver.cpp:105] Iteration 9600, lr = 0.1
I1006 17:50:17.601063  3702 solver.cpp:218] Iteration 9700 (12.0175 iter/s, 8.32118s/100 iters), loss = 0.334471
I1006 17:50:17.601092  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.334471 (* 1 = 0.334471 loss)
I1006 17:50:17.601107  3702 sgd_solver.cpp:105] Iteration 9700, lr = 0.1
I1006 17:50:25.934772  3702 solver.cpp:218] Iteration 9800 (11.9995 iter/s, 8.33365s/100 iters), loss = 0.299425
I1006 17:50:25.934801  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.299425 (* 1 = 0.299425 loss)
I1006 17:50:25.934818  3702 sgd_solver.cpp:105] Iteration 9800, lr = 0.1
I1006 17:50:34.264364  3702 solver.cpp:218] Iteration 9900 (12.0055 iter/s, 8.32954s/100 iters), loss = 0.300421
I1006 17:50:34.264394  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.300421 (* 1 = 0.300421 loss)
I1006 17:50:34.264398  3702 sgd_solver.cpp:105] Iteration 9900, lr = 0.1
I1006 17:50:42.175624  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:50:42.509284  3702 solver.cpp:330] Iteration 10000, Testing net (#0)
I1006 17:50:44.434578  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:50:44.515528  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7519
I1006 17:50:44.515563  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.777626 (* 1 = 0.777626 loss)
I1006 17:50:44.597981  3702 solver.cpp:218] Iteration 10000 (9.67721 iter/s, 10.3336s/100 iters), loss = 0.23386
I1006 17:50:44.598007  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.23386 (* 1 = 0.23386 loss)
I1006 17:50:44.598013  3702 sgd_solver.cpp:105] Iteration 10000, lr = 0.1
I1006 17:50:52.906962  3702 solver.cpp:218] Iteration 10100 (12.0352 iter/s, 8.30893s/100 iters), loss = 0.380131
I1006 17:50:52.907002  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.380132 (* 1 = 0.380132 loss)
I1006 17:50:52.907007  3702 sgd_solver.cpp:105] Iteration 10100, lr = 0.1
I1006 17:51:01.232112  3702 solver.cpp:218] Iteration 10200 (12.0119 iter/s, 8.32508s/100 iters), loss = 0.416216
I1006 17:51:01.232149  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.416216 (* 1 = 0.416216 loss)
I1006 17:51:01.232157  3702 sgd_solver.cpp:105] Iteration 10200, lr = 0.1
I1006 17:51:09.552243  3702 solver.cpp:218] Iteration 10300 (12.0191 iter/s, 8.32007s/100 iters), loss = 0.385383
I1006 17:51:09.552289  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.385383 (* 1 = 0.385383 loss)
I1006 17:51:09.552295  3702 sgd_solver.cpp:105] Iteration 10300, lr = 0.1
I1006 17:51:17.877470  3702 solver.cpp:218] Iteration 10400 (12.0118 iter/s, 8.32515s/100 iters), loss = 0.386541
I1006 17:51:17.877596  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.386541 (* 1 = 0.386541 loss)
I1006 17:51:17.877604  3702 sgd_solver.cpp:105] Iteration 10400, lr = 0.1
I1006 17:51:25.784314  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:51:26.116806  3702 solver.cpp:330] Iteration 10500, Testing net (#0)
I1006 17:51:28.042384  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:51:28.122865  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7818
I1006 17:51:28.122890  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.658082 (* 1 = 0.658082 loss)
I1006 17:51:28.206997  3702 solver.cpp:218] Iteration 10500 (9.68113 iter/s, 10.3294s/100 iters), loss = 0.266276
I1006 17:51:28.207032  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.266276 (* 1 = 0.266276 loss)
I1006 17:51:28.207039  3702 sgd_solver.cpp:105] Iteration 10500, lr = 0.1
I1006 17:51:36.542773  3702 solver.cpp:218] Iteration 10600 (11.9966 iter/s, 8.33572s/100 iters), loss = 0.334685
I1006 17:51:36.542814  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.334685 (* 1 = 0.334685 loss)
I1006 17:51:36.542819  3702 sgd_solver.cpp:105] Iteration 10600, lr = 0.1
I1006 17:51:44.869323  3702 solver.cpp:218] Iteration 10700 (12.0099 iter/s, 8.32648s/100 iters), loss = 0.34879
I1006 17:51:44.869362  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.34879 (* 1 = 0.34879 loss)
I1006 17:51:44.869369  3702 sgd_solver.cpp:105] Iteration 10700, lr = 0.1
I1006 17:51:53.200511  3702 solver.cpp:218] Iteration 10800 (12.0032 iter/s, 8.33112s/100 iters), loss = 0.259533
I1006 17:51:53.200631  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.259533 (* 1 = 0.259533 loss)
I1006 17:51:53.200639  3702 sgd_solver.cpp:105] Iteration 10800, lr = 0.1
I1006 17:52:01.528422  3702 solver.cpp:218] Iteration 10900 (12.008 iter/s, 8.32778s/100 iters), loss = 0.25642
I1006 17:52:01.528460  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.25642 (* 1 = 0.25642 loss)
I1006 17:52:01.528466  3702 sgd_solver.cpp:105] Iteration 10900, lr = 0.1
I1006 17:52:09.450853  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:52:09.784067  3702 solver.cpp:330] Iteration 11000, Testing net (#0)
I1006 17:52:11.711410  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:52:11.792680  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7517
I1006 17:52:11.792716  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.741922 (* 1 = 0.741922 loss)
I1006 17:52:11.875571  3702 solver.cpp:218] Iteration 11000 (9.66456 iter/s, 10.3471s/100 iters), loss = 0.245627
I1006 17:52:11.875599  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.245627 (* 1 = 0.245627 loss)
I1006 17:52:11.875607  3702 sgd_solver.cpp:105] Iteration 11000, lr = 0.1
I1006 17:52:20.199235  3702 solver.cpp:218] Iteration 11100 (12.014 iter/s, 8.32361s/100 iters), loss = 0.256478
I1006 17:52:20.199265  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.256478 (* 1 = 0.256478 loss)
I1006 17:52:20.199270  3702 sgd_solver.cpp:105] Iteration 11100, lr = 0.1
I1006 17:52:28.528268  3702 solver.cpp:218] Iteration 11200 (12.0063 iter/s, 8.32898s/100 iters), loss = 0.291761
I1006 17:52:28.528408  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.291761 (* 1 = 0.291761 loss)
I1006 17:52:28.528415  3702 sgd_solver.cpp:105] Iteration 11200, lr = 0.1
I1006 17:52:36.855818  3702 solver.cpp:218] Iteration 11300 (12.0086 iter/s, 8.32738s/100 iters), loss = 0.357977
I1006 17:52:36.855846  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.357977 (* 1 = 0.357977 loss)
I1006 17:52:36.855852  3702 sgd_solver.cpp:105] Iteration 11300, lr = 0.1
I1006 17:52:45.186384  3702 solver.cpp:218] Iteration 11400 (12.0041 iter/s, 8.33051s/100 iters), loss = 0.296304
I1006 17:52:45.186414  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.296304 (* 1 = 0.296304 loss)
I1006 17:52:45.186419  3702 sgd_solver.cpp:105] Iteration 11400, lr = 0.1
I1006 17:52:53.099475  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:52:53.432449  3702 solver.cpp:330] Iteration 11500, Testing net (#0)
I1006 17:52:55.359333  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:52:55.439402  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.777
I1006 17:52:55.439436  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.670408 (* 1 = 0.670408 loss)
I1006 17:52:55.522974  3702 solver.cpp:218] Iteration 11500 (9.67443 iter/s, 10.3365s/100 iters), loss = 0.292327
I1006 17:52:55.523001  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.292327 (* 1 = 0.292327 loss)
I1006 17:52:55.523007  3702 sgd_solver.cpp:105] Iteration 11500, lr = 0.1
I1006 17:53:03.855710  3702 solver.cpp:218] Iteration 11600 (12.0009 iter/s, 8.33268s/100 iters), loss = 0.266214
I1006 17:53:03.855825  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.266214 (* 1 = 0.266214 loss)
I1006 17:53:03.855832  3702 sgd_solver.cpp:105] Iteration 11600, lr = 0.1
I1006 17:53:12.180387  3702 solver.cpp:218] Iteration 11700 (12.0127 iter/s, 8.32454s/100 iters), loss = 0.283514
I1006 17:53:12.180415  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.283514 (* 1 = 0.283514 loss)
I1006 17:53:12.180420  3702 sgd_solver.cpp:105] Iteration 11700, lr = 0.1
I1006 17:53:20.509001  3702 solver.cpp:218] Iteration 11800 (12.0069 iter/s, 8.32856s/100 iters), loss = 0.299062
I1006 17:53:20.509039  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.299062 (* 1 = 0.299062 loss)
I1006 17:53:20.509045  3702 sgd_solver.cpp:105] Iteration 11800, lr = 0.1
I1006 17:53:28.835430  3702 solver.cpp:218] Iteration 11900 (12.01 iter/s, 8.32637s/100 iters), loss = 0.323023
I1006 17:53:28.835460  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.323023 (* 1 = 0.323023 loss)
I1006 17:53:28.835466  3702 sgd_solver.cpp:105] Iteration 11900, lr = 0.1
I1006 17:53:36.755630  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:53:37.088695  3702 solver.cpp:330] Iteration 12000, Testing net (#0)
I1006 17:53:39.015908  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:53:39.096971  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6937
I1006 17:53:39.096997  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.04977 (* 1 = 1.04977 loss)
I1006 17:53:39.179451  3702 solver.cpp:218] Iteration 12000 (9.66748 iter/s, 10.344s/100 iters), loss = 0.256806
I1006 17:53:39.179477  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.256806 (* 1 = 0.256806 loss)
I1006 17:53:39.179483  3702 sgd_solver.cpp:105] Iteration 12000, lr = 0.1
I1006 17:53:47.494419  3702 solver.cpp:218] Iteration 12100 (12.0266 iter/s, 8.31492s/100 iters), loss = 0.214903
I1006 17:53:47.494448  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.214903 (* 1 = 0.214903 loss)
I1006 17:53:47.494453  3702 sgd_solver.cpp:105] Iteration 12100, lr = 0.1
I1006 17:53:55.818024  3702 solver.cpp:218] Iteration 12200 (12.0141 iter/s, 8.32355s/100 iters), loss = 0.293401
I1006 17:53:55.818053  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.293401 (* 1 = 0.293401 loss)
I1006 17:53:55.818059  3702 sgd_solver.cpp:105] Iteration 12200, lr = 0.1
I1006 17:54:04.137671  3702 solver.cpp:218] Iteration 12300 (12.0198 iter/s, 8.31959s/100 iters), loss = 0.297728
I1006 17:54:04.137701  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.297728 (* 1 = 0.297728 loss)
I1006 17:54:04.137707  3702 sgd_solver.cpp:105] Iteration 12300, lr = 0.1
I1006 17:54:12.461058  3702 solver.cpp:218] Iteration 12400 (12.0144 iter/s, 8.32333s/100 iters), loss = 0.314806
I1006 17:54:12.461199  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.314806 (* 1 = 0.314806 loss)
I1006 17:54:12.461206  3702 sgd_solver.cpp:105] Iteration 12400, lr = 0.1
I1006 17:54:20.369835  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:54:20.703232  3702 solver.cpp:330] Iteration 12500, Testing net (#0)
I1006 17:54:22.630218  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:54:22.710606  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7877
I1006 17:54:22.710641  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.669562 (* 1 = 0.669562 loss)
I1006 17:54:22.794258  3702 solver.cpp:218] Iteration 12500 (9.67769 iter/s, 10.333s/100 iters), loss = 0.23047
I1006 17:54:22.794284  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.23047 (* 1 = 0.23047 loss)
I1006 17:54:22.794291  3702 sgd_solver.cpp:105] Iteration 12500, lr = 0.1
I1006 17:54:31.132266  3702 solver.cpp:218] Iteration 12600 (11.9933 iter/s, 8.33796s/100 iters), loss = 0.32746
I1006 17:54:31.132295  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.32746 (* 1 = 0.32746 loss)
I1006 17:54:31.132302  3702 sgd_solver.cpp:105] Iteration 12600, lr = 0.1
I1006 17:54:39.457024  3702 solver.cpp:218] Iteration 12700 (12.0124 iter/s, 8.3247s/100 iters), loss = 0.323341
I1006 17:54:39.457063  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.323341 (* 1 = 0.323341 loss)
I1006 17:54:39.457069  3702 sgd_solver.cpp:105] Iteration 12700, lr = 0.1
I1006 17:54:47.782510  3702 solver.cpp:218] Iteration 12800 (12.0114 iter/s, 8.32542s/100 iters), loss = 0.26557
I1006 17:54:47.782631  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.26557 (* 1 = 0.26557 loss)
I1006 17:54:47.782639  3702 sgd_solver.cpp:105] Iteration 12800, lr = 0.1
I1006 17:54:56.106843  3702 solver.cpp:218] Iteration 12900 (12.0132 iter/s, 8.32419s/100 iters), loss = 0.267592
I1006 17:54:56.106884  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.267592 (* 1 = 0.267592 loss)
I1006 17:54:56.106889  3702 sgd_solver.cpp:105] Iteration 12900, lr = 0.1
I1006 17:55:04.022187  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:55:04.355149  3702 solver.cpp:330] Iteration 13000, Testing net (#0)
I1006 17:55:06.281945  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:55:06.363116  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6535
I1006 17:55:06.363152  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.29382 (* 1 = 1.29382 loss)
I1006 17:55:06.445952  3702 solver.cpp:218] Iteration 13000 (9.67208 iter/s, 10.339s/100 iters), loss = 0.346321
I1006 17:55:06.445983  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.346321 (* 1 = 0.346321 loss)
I1006 17:55:06.445991  3702 sgd_solver.cpp:105] Iteration 13000, lr = 0.1
I1006 17:55:14.764413  3702 solver.cpp:218] Iteration 13100 (12.0215 iter/s, 8.31841s/100 iters), loss = 0.32151
I1006 17:55:14.764453  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.32151 (* 1 = 0.32151 loss)
I1006 17:55:14.764459  3702 sgd_solver.cpp:105] Iteration 13100, lr = 0.1
I1006 17:55:23.089107  3702 solver.cpp:218] Iteration 13200 (12.0126 iter/s, 8.32463s/100 iters), loss = 0.334979
I1006 17:55:23.089258  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.334979 (* 1 = 0.334979 loss)
I1006 17:55:23.089265  3702 sgd_solver.cpp:105] Iteration 13200, lr = 0.1
I1006 17:55:31.408956  3702 solver.cpp:218] Iteration 13300 (12.0197 iter/s, 8.31967s/100 iters), loss = 0.273303
I1006 17:55:31.408994  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.273303 (* 1 = 0.273303 loss)
I1006 17:55:31.408999  3702 sgd_solver.cpp:105] Iteration 13300, lr = 0.1
I1006 17:55:39.734792  3702 solver.cpp:218] Iteration 13400 (12.0109 iter/s, 8.32577s/100 iters), loss = 0.280517
I1006 17:55:39.734832  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.280517 (* 1 = 0.280517 loss)
I1006 17:55:39.734838  3702 sgd_solver.cpp:105] Iteration 13400, lr = 0.1
I1006 17:55:47.645961  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:55:47.979965  3702 solver.cpp:330] Iteration 13500, Testing net (#0)
I1006 17:55:49.907619  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:55:49.987948  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7506
I1006 17:55:49.987983  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.774581 (* 1 = 0.774581 loss)
I1006 17:55:50.072281  3702 solver.cpp:218] Iteration 13500 (9.6736 iter/s, 10.3374s/100 iters), loss = 0.248191
I1006 17:55:50.072309  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.248191 (* 1 = 0.248191 loss)
I1006 17:55:50.072315  3702 sgd_solver.cpp:105] Iteration 13500, lr = 0.1
I1006 17:55:58.405944  3702 solver.cpp:218] Iteration 13600 (11.9996 iter/s, 8.33361s/100 iters), loss = 0.250551
I1006 17:55:58.406075  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.250551 (* 1 = 0.250551 loss)
I1006 17:55:58.406083  3702 sgd_solver.cpp:105] Iteration 13600, lr = 0.1
I1006 17:56:06.727854  3702 solver.cpp:218] Iteration 13700 (12.0167 iter/s, 8.32175s/100 iters), loss = 0.225476
I1006 17:56:06.727893  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.225476 (* 1 = 0.225476 loss)
I1006 17:56:06.727900  3702 sgd_solver.cpp:105] Iteration 13700, lr = 0.1
I1006 17:56:15.060613  3702 solver.cpp:218] Iteration 13800 (12.0009 iter/s, 8.33269s/100 iters), loss = 0.249405
I1006 17:56:15.060652  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.249405 (* 1 = 0.249405 loss)
I1006 17:56:15.060658  3702 sgd_solver.cpp:105] Iteration 13800, lr = 0.1
I1006 17:56:23.388342  3702 solver.cpp:218] Iteration 13900 (12.0082 iter/s, 8.32767s/100 iters), loss = 0.227467
I1006 17:56:23.388382  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.227467 (* 1 = 0.227467 loss)
I1006 17:56:23.388388  3702 sgd_solver.cpp:105] Iteration 13900, lr = 0.1
I1006 17:56:31.306596  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:56:31.641037  3702 solver.cpp:330] Iteration 14000, Testing net (#0)
I1006 17:56:33.567087  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:56:33.647747  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7629
I1006 17:56:33.647781  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.711512 (* 1 = 0.711512 loss)
I1006 17:56:33.730492  3702 solver.cpp:218] Iteration 14000 (9.66924 iter/s, 10.3421s/100 iters), loss = 0.240954
I1006 17:56:33.730517  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.240954 (* 1 = 0.240954 loss)
I1006 17:56:33.730525  3702 sgd_solver.cpp:105] Iteration 14000, lr = 0.1
I1006 17:56:42.051023  3702 solver.cpp:218] Iteration 14100 (12.0185 iter/s, 8.32048s/100 iters), loss = 0.253244
I1006 17:56:42.051051  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.253244 (* 1 = 0.253244 loss)
I1006 17:56:42.051057  3702 sgd_solver.cpp:105] Iteration 14100, lr = 0.1
I1006 17:56:50.382876  3702 solver.cpp:218] Iteration 14200 (12.0022 iter/s, 8.3318s/100 iters), loss = 0.264798
I1006 17:56:50.382906  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.264798 (* 1 = 0.264798 loss)
I1006 17:56:50.382911  3702 sgd_solver.cpp:105] Iteration 14200, lr = 0.1
I1006 17:56:58.706188  3702 solver.cpp:218] Iteration 14300 (12.0145 iter/s, 8.32326s/100 iters), loss = 0.219772
I1006 17:56:58.706228  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.219772 (* 1 = 0.219772 loss)
I1006 17:56:58.706233  3702 sgd_solver.cpp:105] Iteration 14300, lr = 0.1
I1006 17:57:07.035189  3702 solver.cpp:218] Iteration 14400 (12.0063 iter/s, 8.32894s/100 iters), loss = 0.237014
I1006 17:57:07.035300  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.237014 (* 1 = 0.237014 loss)
I1006 17:57:07.035305  3702 sgd_solver.cpp:105] Iteration 14400, lr = 0.1
I1006 17:57:14.945894  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:57:15.279889  3702 solver.cpp:330] Iteration 14500, Testing net (#0)
I1006 17:57:17.207223  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:57:17.287065  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6969
I1006 17:57:17.287106  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.04344 (* 1 = 1.04344 loss)
I1006 17:57:17.370256  3702 solver.cpp:218] Iteration 14500 (9.67592 iter/s, 10.3349s/100 iters), loss = 0.27622
I1006 17:57:17.370281  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.27622 (* 1 = 0.27622 loss)
I1006 17:57:17.370287  3702 sgd_solver.cpp:105] Iteration 14500, lr = 0.1
I1006 17:57:25.698511  3702 solver.cpp:218] Iteration 14600 (12.0074 iter/s, 8.3282s/100 iters), loss = 0.279684
I1006 17:57:25.698539  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.279684 (* 1 = 0.279684 loss)
I1006 17:57:25.698545  3702 sgd_solver.cpp:105] Iteration 14600, lr = 0.1
I1006 17:57:34.013828  3702 solver.cpp:218] Iteration 14700 (12.0261 iter/s, 8.31526s/100 iters), loss = 0.261203
I1006 17:57:34.013866  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.261203 (* 1 = 0.261203 loss)
I1006 17:57:34.013871  3702 sgd_solver.cpp:105] Iteration 14700, lr = 0.1
I1006 17:57:42.343592  3702 solver.cpp:218] Iteration 14800 (12.0052 iter/s, 8.3297s/100 iters), loss = 0.337158
I1006 17:57:42.343731  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.337157 (* 1 = 0.337157 loss)
I1006 17:57:42.343750  3702 sgd_solver.cpp:105] Iteration 14800, lr = 0.1
I1006 17:57:50.669286  3702 solver.cpp:218] Iteration 14900 (12.0112 iter/s, 8.32553s/100 iters), loss = 0.256425
I1006 17:57:50.669325  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.256425 (* 1 = 0.256425 loss)
I1006 17:57:50.669332  3702 sgd_solver.cpp:105] Iteration 14900, lr = 0.1
I1006 17:57:58.588600  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:57:58.922040  3702 solver.cpp:330] Iteration 15000, Testing net (#0)
I1006 17:58:00.851117  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:58:00.932071  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6848
I1006 17:58:00.932106  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.11371 (* 1 = 1.11371 loss)
I1006 17:58:01.015251  3702 solver.cpp:218] Iteration 15000 (9.66567 iter/s, 10.3459s/100 iters), loss = 0.261389
I1006 17:58:01.015287  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.261389 (* 1 = 0.261389 loss)
I1006 17:58:01.015295  3702 sgd_solver.cpp:105] Iteration 15000, lr = 0.1
I1006 17:58:09.349149  3702 solver.cpp:218] Iteration 15100 (11.9993 iter/s, 8.33383s/100 iters), loss = 0.295144
I1006 17:58:09.349179  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.295144 (* 1 = 0.295144 loss)
I1006 17:58:09.349184  3702 sgd_solver.cpp:105] Iteration 15100, lr = 0.1
I1006 17:58:17.688504  3702 solver.cpp:218] Iteration 15200 (11.9914 iter/s, 8.3393s/100 iters), loss = 0.255151
I1006 17:58:17.688611  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.255151 (* 1 = 0.255151 loss)
I1006 17:58:17.688618  3702 sgd_solver.cpp:105] Iteration 15200, lr = 0.1
I1006 17:58:26.026556  3702 solver.cpp:218] Iteration 15300 (11.9934 iter/s, 8.33792s/100 iters), loss = 0.384036
I1006 17:58:26.026594  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.384036 (* 1 = 0.384036 loss)
I1006 17:58:26.026600  3702 sgd_solver.cpp:105] Iteration 15300, lr = 0.1
I1006 17:58:34.370074  3702 solver.cpp:218] Iteration 15400 (11.9854 iter/s, 8.34345s/100 iters), loss = 0.230777
I1006 17:58:34.370102  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.230777 (* 1 = 0.230777 loss)
I1006 17:58:34.370108  3702 sgd_solver.cpp:105] Iteration 15400, lr = 0.1
I1006 17:58:42.286695  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:58:42.620726  3702 solver.cpp:330] Iteration 15500, Testing net (#0)
I1006 17:58:44.547088  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:58:44.627686  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7773
I1006 17:58:44.627722  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.688201 (* 1 = 0.688201 loss)
I1006 17:58:44.711427  3702 solver.cpp:218] Iteration 15500 (9.66997 iter/s, 10.3413s/100 iters), loss = 0.202397
I1006 17:58:44.711455  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.202397 (* 1 = 0.202397 loss)
I1006 17:58:44.711462  3702 sgd_solver.cpp:105] Iteration 15500, lr = 0.1
I1006 17:58:53.041808  3702 solver.cpp:218] Iteration 15600 (12.0043 iter/s, 8.33033s/100 iters), loss = 0.179345
I1006 17:58:53.041966  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.179344 (* 1 = 0.179344 loss)
I1006 17:58:53.041975  3702 sgd_solver.cpp:105] Iteration 15600, lr = 0.1
I1006 17:59:01.365484  3702 solver.cpp:218] Iteration 15700 (12.0142 iter/s, 8.3235s/100 iters), loss = 0.226885
I1006 17:59:01.365523  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.226885 (* 1 = 0.226885 loss)
I1006 17:59:01.365530  3702 sgd_solver.cpp:105] Iteration 15700, lr = 0.1
I1006 17:59:09.697654  3702 solver.cpp:218] Iteration 15800 (12.0018 iter/s, 8.33211s/100 iters), loss = 0.269315
I1006 17:59:09.697695  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.269315 (* 1 = 0.269315 loss)
I1006 17:59:09.697700  3702 sgd_solver.cpp:105] Iteration 15800, lr = 0.1
I1006 17:59:18.019253  3702 solver.cpp:218] Iteration 15900 (12.017 iter/s, 8.32153s/100 iters), loss = 0.221313
I1006 17:59:18.019290  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.221313 (* 1 = 0.221313 loss)
I1006 17:59:18.019296  3702 sgd_solver.cpp:105] Iteration 15900, lr = 0.1
I1006 17:59:25.937973  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:59:26.270336  3702 solver.cpp:330] Iteration 16000, Testing net (#0)
I1006 17:59:28.198225  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:59:28.279510  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7818
I1006 17:59:28.279546  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.700417 (* 1 = 0.700417 loss)
I1006 17:59:28.361902  3702 solver.cpp:218] Iteration 16000 (9.66877 iter/s, 10.3426s/100 iters), loss = 0.273922
I1006 17:59:28.361933  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.273922 (* 1 = 0.273922 loss)
I1006 17:59:28.361940  3702 sgd_solver.cpp:105] Iteration 16000, lr = 0.1
I1006 17:59:36.687757  3702 solver.cpp:218] Iteration 16100 (12.0109 iter/s, 8.3258s/100 iters), loss = 0.235856
I1006 17:59:36.687795  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.235856 (* 1 = 0.235856 loss)
I1006 17:59:36.687801  3702 sgd_solver.cpp:105] Iteration 16100, lr = 0.1
I1006 17:59:45.023548  3702 solver.cpp:218] Iteration 16200 (11.9966 iter/s, 8.33573s/100 iters), loss = 0.323772
I1006 17:59:45.023586  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.323771 (* 1 = 0.323771 loss)
I1006 17:59:45.023592  3702 sgd_solver.cpp:105] Iteration 16200, lr = 0.1
I1006 17:59:53.353150  3702 solver.cpp:218] Iteration 16300 (12.0055 iter/s, 8.32954s/100 iters), loss = 0.315347
I1006 17:59:53.353179  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.315347 (* 1 = 0.315347 loss)
I1006 17:59:53.353185  3702 sgd_solver.cpp:105] Iteration 16300, lr = 0.1
I1006 18:00:01.685995  3702 solver.cpp:218] Iteration 16400 (12.0008 iter/s, 8.33279s/100 iters), loss = 0.205432
I1006 18:00:01.686082  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.205431 (* 1 = 0.205431 loss)
I1006 18:00:01.686098  3702 sgd_solver.cpp:105] Iteration 16400, lr = 0.1
I1006 18:00:09.601222  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:00:09.935410  3702 solver.cpp:330] Iteration 16500, Testing net (#0)
I1006 18:00:11.862346  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:00:11.943174  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7646
I1006 18:00:11.943207  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.726303 (* 1 = 0.726303 loss)
I1006 18:00:12.026873  3702 solver.cpp:218] Iteration 16500 (9.67047 iter/s, 10.3408s/100 iters), loss = 0.244101
I1006 18:00:12.026899  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.244101 (* 1 = 0.244101 loss)
I1006 18:00:12.026906  3702 sgd_solver.cpp:105] Iteration 16500, lr = 0.1
I1006 18:00:20.350451  3702 solver.cpp:218] Iteration 16600 (12.0141 iter/s, 8.32353s/100 iters), loss = 0.333009
I1006 18:00:20.350491  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.333009 (* 1 = 0.333009 loss)
I1006 18:00:20.350497  3702 sgd_solver.cpp:105] Iteration 16600, lr = 0.1
I1006 18:00:28.667002  3702 solver.cpp:218] Iteration 16700 (12.0243 iter/s, 8.31649s/100 iters), loss = 0.244182
I1006 18:00:28.667032  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.244181 (* 1 = 0.244181 loss)
I1006 18:00:28.667038  3702 sgd_solver.cpp:105] Iteration 16700, lr = 0.1
I1006 18:00:36.991123  3702 solver.cpp:218] Iteration 16800 (12.0134 iter/s, 8.32407s/100 iters), loss = 0.28225
I1006 18:00:36.991250  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.28225 (* 1 = 0.28225 loss)
I1006 18:00:36.991257  3702 sgd_solver.cpp:105] Iteration 16800, lr = 0.1
I1006 18:00:45.308677  3702 solver.cpp:218] Iteration 16900 (12.023 iter/s, 8.3174s/100 iters), loss = 0.171725
I1006 18:00:45.308717  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.171725 (* 1 = 0.171725 loss)
I1006 18:00:45.308722  3702 sgd_solver.cpp:105] Iteration 16900, lr = 0.1
I1006 18:00:53.224382  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:00:53.557406  3702 solver.cpp:330] Iteration 17000, Testing net (#0)
I1006 18:00:55.484436  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:00:55.565240  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8139
I1006 18:00:55.565265  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.557852 (* 1 = 0.557852 loss)
I1006 18:00:55.648023  3702 solver.cpp:218] Iteration 17000 (9.67186 iter/s, 10.3393s/100 iters), loss = 0.177465
I1006 18:00:55.648051  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.177465 (* 1 = 0.177465 loss)
I1006 18:00:55.648056  3702 sgd_solver.cpp:105] Iteration 17000, lr = 0.1
I1006 18:01:03.974081  3702 solver.cpp:218] Iteration 17100 (12.0106 iter/s, 8.326s/100 iters), loss = 0.230193
I1006 18:01:03.974120  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.230193 (* 1 = 0.230193 loss)
I1006 18:01:03.974126  3702 sgd_solver.cpp:105] Iteration 17100, lr = 0.1
I1006 18:01:12.310765  3702 solver.cpp:218] Iteration 17200 (11.9953 iter/s, 8.33662s/100 iters), loss = 0.288742
I1006 18:01:12.310904  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.288742 (* 1 = 0.288742 loss)
I1006 18:01:12.310912  3702 sgd_solver.cpp:105] Iteration 17200, lr = 0.1
I1006 18:01:20.637557  3702 solver.cpp:218] Iteration 17300 (12.0097 iter/s, 8.32663s/100 iters), loss = 0.277156
I1006 18:01:20.637596  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.277156 (* 1 = 0.277156 loss)
I1006 18:01:20.637603  3702 sgd_solver.cpp:105] Iteration 17300, lr = 0.1
I1006 18:01:28.968225  3702 solver.cpp:218] Iteration 17400 (12.0039 iter/s, 8.3306s/100 iters), loss = 0.203264
I1006 18:01:28.968255  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.203264 (* 1 = 0.203264 loss)
I1006 18:01:28.968261  3702 sgd_solver.cpp:105] Iteration 17400, lr = 0.1
I1006 18:01:36.883277  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:01:37.217947  3702 solver.cpp:330] Iteration 17500, Testing net (#0)
I1006 18:01:39.144629  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:01:39.224884  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7151
I1006 18:01:39.224918  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.950512 (* 1 = 0.950512 loss)
I1006 18:01:39.308236  3702 solver.cpp:218] Iteration 17500 (9.67123 iter/s, 10.34s/100 iters), loss = 0.281484
I1006 18:01:39.308261  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.281483 (* 1 = 0.281483 loss)
I1006 18:01:39.308269  3702 sgd_solver.cpp:105] Iteration 17500, lr = 0.1
I1006 18:01:47.631678  3702 solver.cpp:218] Iteration 17600 (12.0143 iter/s, 8.32339s/100 iters), loss = 0.29947
I1006 18:01:47.631834  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.29947 (* 1 = 0.29947 loss)
I1006 18:01:47.631841  3702 sgd_solver.cpp:105] Iteration 17600, lr = 0.1
I1006 18:01:55.952859  3702 solver.cpp:218] Iteration 17700 (12.0178 iter/s, 8.32101s/100 iters), loss = 0.45073
I1006 18:01:55.952888  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.450729 (* 1 = 0.450729 loss)
I1006 18:01:55.952893  3702 sgd_solver.cpp:105] Iteration 17700, lr = 0.1
I1006 18:02:04.280879  3702 solver.cpp:218] Iteration 17800 (12.0077 iter/s, 8.32797s/100 iters), loss = 0.196663
I1006 18:02:04.280910  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.196663 (* 1 = 0.196663 loss)
I1006 18:02:04.280915  3702 sgd_solver.cpp:105] Iteration 17800, lr = 0.1
I1006 18:02:12.601332  3702 solver.cpp:218] Iteration 17900 (12.0187 iter/s, 8.3204s/100 iters), loss = 0.301228
I1006 18:02:12.601372  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.301228 (* 1 = 0.301228 loss)
I1006 18:02:12.601377  3702 sgd_solver.cpp:105] Iteration 17900, lr = 0.1
I1006 18:02:20.517278  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:02:20.850545  3702 solver.cpp:330] Iteration 18000, Testing net (#0)
I1006 18:02:22.776885  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:02:22.857360  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7584
I1006 18:02:22.857395  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.763702 (* 1 = 0.763702 loss)
I1006 18:02:22.940217  3702 solver.cpp:218] Iteration 18000 (9.67229 iter/s, 10.3388s/100 iters), loss = 0.215373
I1006 18:02:22.940243  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.215373 (* 1 = 0.215373 loss)
I1006 18:02:22.940248  3702 sgd_solver.cpp:105] Iteration 18000, lr = 0.1
I1006 18:02:31.272138  3702 solver.cpp:218] Iteration 18100 (12.0021 iter/s, 8.33187s/100 iters), loss = 0.235323
I1006 18:02:31.272177  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.235323 (* 1 = 0.235323 loss)
I1006 18:02:31.272183  3702 sgd_solver.cpp:105] Iteration 18100, lr = 0.1
I1006 18:02:39.607590  3702 solver.cpp:218] Iteration 18200 (11.997 iter/s, 8.33539s/100 iters), loss = 0.238889
I1006 18:02:39.607630  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.238889 (* 1 = 0.238889 loss)
I1006 18:02:39.607635  3702 sgd_solver.cpp:105] Iteration 18200, lr = 0.1
I1006 18:02:47.937605  3702 solver.cpp:218] Iteration 18300 (12.0049 iter/s, 8.32995s/100 iters), loss = 0.18796
I1006 18:02:47.937644  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.18796 (* 1 = 0.18796 loss)
I1006 18:02:47.937650  3702 sgd_solver.cpp:105] Iteration 18300, lr = 0.1
I1006 18:02:56.276176  3702 solver.cpp:218] Iteration 18400 (11.9926 iter/s, 8.33851s/100 iters), loss = 0.314167
I1006 18:02:56.276288  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.314167 (* 1 = 0.314167 loss)
I1006 18:02:56.276294  3702 sgd_solver.cpp:105] Iteration 18400, lr = 0.1
I1006 18:03:04.195078  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:03:04.528239  3702 solver.cpp:330] Iteration 18500, Testing net (#0)
I1006 18:03:06.456578  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:03:06.537035  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8022
I1006 18:03:06.537070  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.629175 (* 1 = 0.629175 loss)
I1006 18:03:06.620764  3702 solver.cpp:218] Iteration 18500 (9.66701 iter/s, 10.3445s/100 iters), loss = 0.241112
I1006 18:03:06.620795  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.241112 (* 1 = 0.241112 loss)
I1006 18:03:06.620802  3702 sgd_solver.cpp:105] Iteration 18500, lr = 0.1
I1006 18:03:14.959040  3702 solver.cpp:218] Iteration 18600 (11.993 iter/s, 8.33822s/100 iters), loss = 0.238804
I1006 18:03:14.959069  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.238804 (* 1 = 0.238804 loss)
I1006 18:03:14.959074  3702 sgd_solver.cpp:105] Iteration 18600, lr = 0.1
I1006 18:03:23.291414  3702 solver.cpp:218] Iteration 18700 (12.0015 iter/s, 8.33232s/100 iters), loss = 0.287744
I1006 18:03:23.291445  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.287744 (* 1 = 0.287744 loss)
I1006 18:03:23.291450  3702 sgd_solver.cpp:105] Iteration 18700, lr = 0.1
I1006 18:03:31.631446  3702 solver.cpp:218] Iteration 18800 (11.9904 iter/s, 8.33997s/100 iters), loss = 0.36889
I1006 18:03:31.631608  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.368889 (* 1 = 0.368889 loss)
I1006 18:03:31.631624  3702 sgd_solver.cpp:105] Iteration 18800, lr = 0.1
I1006 18:03:39.963418  3702 solver.cpp:218] Iteration 18900 (12.0022 iter/s, 8.33179s/100 iters), loss = 0.211509
I1006 18:03:39.963448  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.211509 (* 1 = 0.211509 loss)
I1006 18:03:39.963454  3702 sgd_solver.cpp:105] Iteration 18900, lr = 0.1
I1006 18:03:47.885963  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:03:48.218698  3702 solver.cpp:330] Iteration 19000, Testing net (#0)
I1006 18:03:50.146960  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:03:50.228055  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8129
I1006 18:03:50.228078  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.552954 (* 1 = 0.552954 loss)
I1006 18:03:50.310995  3702 solver.cpp:218] Iteration 19000 (9.66416 iter/s, 10.3475s/100 iters), loss = 0.153976
I1006 18:03:50.311028  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.153976 (* 1 = 0.153976 loss)
I1006 18:03:50.311035  3702 sgd_solver.cpp:105] Iteration 19000, lr = 0.1
I1006 18:03:58.638257  3702 solver.cpp:218] Iteration 19100 (12.0088 iter/s, 8.3272s/100 iters), loss = 0.222549
I1006 18:03:58.638298  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.222548 (* 1 = 0.222548 loss)
I1006 18:03:58.638303  3702 sgd_solver.cpp:105] Iteration 19100, lr = 0.1
I1006 18:04:06.977356  3702 solver.cpp:218] Iteration 19200 (11.9918 iter/s, 8.33903s/100 iters), loss = 0.173078
I1006 18:04:06.977433  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.173078 (* 1 = 0.173078 loss)
I1006 18:04:06.977440  3702 sgd_solver.cpp:105] Iteration 19200, lr = 0.1
I1006 18:04:15.310102  3702 solver.cpp:218] Iteration 19300 (12.001 iter/s, 8.33264s/100 iters), loss = 0.262928
I1006 18:04:15.310142  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.262927 (* 1 = 0.262927 loss)
I1006 18:04:15.310148  3702 sgd_solver.cpp:105] Iteration 19300, lr = 0.1
I1006 18:04:23.649276  3702 solver.cpp:218] Iteration 19400 (11.9917 iter/s, 8.33911s/100 iters), loss = 0.292492
I1006 18:04:23.649305  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.292491 (* 1 = 0.292491 loss)
I1006 18:04:23.649312  3702 sgd_solver.cpp:105] Iteration 19400, lr = 0.1
I1006 18:04:31.568521  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:04:31.902822  3702 solver.cpp:330] Iteration 19500, Testing net (#0)
I1006 18:04:33.828811  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:04:33.909121  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6558
I1006 18:04:33.909157  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.20332 (* 1 = 1.20332 loss)
I1006 18:04:33.992705  3702 solver.cpp:218] Iteration 19500 (9.66803 iter/s, 10.3434s/100 iters), loss = 0.222158
I1006 18:04:33.992730  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.222158 (* 1 = 0.222158 loss)
I1006 18:04:33.992738  3702 sgd_solver.cpp:105] Iteration 19500, lr = 0.1
I1006 18:04:42.325666  3702 solver.cpp:218] Iteration 19600 (12.0006 iter/s, 8.33291s/100 iters), loss = 0.318188
I1006 18:04:42.325767  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.318188 (* 1 = 0.318188 loss)
I1006 18:04:42.325783  3702 sgd_solver.cpp:105] Iteration 19600, lr = 0.1
I1006 18:04:50.655797  3702 solver.cpp:218] Iteration 19700 (12.0048 iter/s, 8.33s/100 iters), loss = 0.323003
I1006 18:04:50.655836  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.323003 (* 1 = 0.323003 loss)
I1006 18:04:50.655843  3702 sgd_solver.cpp:105] Iteration 19700, lr = 0.1
I1006 18:04:58.987159  3702 solver.cpp:218] Iteration 19800 (12.0029 iter/s, 8.3313s/100 iters), loss = 0.273915
I1006 18:04:58.987202  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.273915 (* 1 = 0.273915 loss)
I1006 18:04:58.987208  3702 sgd_solver.cpp:105] Iteration 19800, lr = 0.1
I1006 18:05:07.314069  3702 solver.cpp:218] Iteration 19900 (12.0093 iter/s, 8.32685s/100 iters), loss = 0.171544
I1006 18:05:07.314097  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.171544 (* 1 = 0.171544 loss)
I1006 18:05:07.314105  3702 sgd_solver.cpp:105] Iteration 19900, lr = 0.1
I1006 18:05:15.229770  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:05:15.562393  3702 solver.cpp:330] Iteration 20000, Testing net (#0)
I1006 18:05:17.488762  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:05:17.569995  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7986
I1006 18:05:17.570020  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.623779 (* 1 = 0.623779 loss)
I1006 18:05:17.652266  3702 solver.cpp:218] Iteration 20000 (9.67292 iter/s, 10.3381s/100 iters), loss = 0.222992
I1006 18:05:17.652293  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.222992 (* 1 = 0.222992 loss)
I1006 18:05:17.652300  3702 sgd_solver.cpp:105] Iteration 20000, lr = 0.1
I1006 18:05:25.983738  3702 solver.cpp:218] Iteration 20100 (12.0028 iter/s, 8.33142s/100 iters), loss = 0.168156
I1006 18:05:25.983778  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.168155 (* 1 = 0.168155 loss)
I1006 18:05:25.983783  3702 sgd_solver.cpp:105] Iteration 20100, lr = 0.1
I1006 18:05:34.319825  3702 solver.cpp:218] Iteration 20200 (11.9961 iter/s, 8.33602s/100 iters), loss = 0.228671
I1006 18:05:34.319854  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.228671 (* 1 = 0.228671 loss)
I1006 18:05:34.319859  3702 sgd_solver.cpp:105] Iteration 20200, lr = 0.1
I1006 18:05:42.654157  3702 solver.cpp:218] Iteration 20300 (11.9986 iter/s, 8.33427s/100 iters), loss = 0.203246
I1006 18:05:42.654197  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.203246 (* 1 = 0.203246 loss)
I1006 18:05:42.654203  3702 sgd_solver.cpp:105] Iteration 20300, lr = 0.1
I1006 18:05:50.992628  3702 solver.cpp:218] Iteration 20400 (11.9927 iter/s, 8.33841s/100 iters), loss = 0.16858
I1006 18:05:50.992736  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.16858 (* 1 = 0.16858 loss)
I1006 18:05:50.992744  3702 sgd_solver.cpp:105] Iteration 20400, lr = 0.1
I1006 18:05:58.911273  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:05:59.244280  3702 solver.cpp:330] Iteration 20500, Testing net (#0)
I1006 18:06:01.172852  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:06:01.253185  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7362
I1006 18:06:01.253221  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.934142 (* 1 = 0.934142 loss)
I1006 18:06:01.337007  3702 solver.cpp:218] Iteration 20500 (9.66721 iter/s, 10.3442s/100 iters), loss = 0.239844
I1006 18:06:01.337035  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.239843 (* 1 = 0.239843 loss)
I1006 18:06:01.337041  3702 sgd_solver.cpp:105] Iteration 20500, lr = 0.1
I1006 18:06:09.663044  3702 solver.cpp:218] Iteration 20600 (12.0106 iter/s, 8.32598s/100 iters), loss = 0.290167
I1006 18:06:09.663074  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.290166 (* 1 = 0.290166 loss)
I1006 18:06:09.663089  3702 sgd_solver.cpp:105] Iteration 20600, lr = 0.1
I1006 18:06:17.989233  3702 solver.cpp:218] Iteration 20700 (12.0104 iter/s, 8.32613s/100 iters), loss = 0.170759
I1006 18:06:17.989271  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.170759 (* 1 = 0.170759 loss)
I1006 18:06:17.989276  3702 sgd_solver.cpp:105] Iteration 20700, lr = 0.1
I1006 18:06:26.319411  3702 solver.cpp:218] Iteration 20800 (12.0046 iter/s, 8.33012s/100 iters), loss = 0.196999
I1006 18:06:26.319583  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.196999 (* 1 = 0.196999 loss)
I1006 18:06:26.319602  3702 sgd_solver.cpp:105] Iteration 20800, lr = 0.1
I1006 18:06:34.641261  3702 solver.cpp:218] Iteration 20900 (12.0168 iter/s, 8.32167s/100 iters), loss = 0.174534
I1006 18:06:34.641301  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.174534 (* 1 = 0.174534 loss)
I1006 18:06:34.641307  3702 sgd_solver.cpp:105] Iteration 20900, lr = 0.1
I1006 18:06:42.557461  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:06:42.891293  3702 solver.cpp:330] Iteration 21000, Testing net (#0)
I1006 18:06:44.819205  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:06:44.899914  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.801
I1006 18:06:44.899940  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.627486 (* 1 = 0.627486 loss)
I1006 18:06:44.982944  3702 solver.cpp:218] Iteration 21000 (9.66967 iter/s, 10.3416s/100 iters), loss = 0.195858
I1006 18:06:44.982969  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.195858 (* 1 = 0.195858 loss)
I1006 18:06:44.982975  3702 sgd_solver.cpp:105] Iteration 21000, lr = 0.1
I1006 18:06:53.313585  3702 solver.cpp:218] Iteration 21100 (12.004 iter/s, 8.33059s/100 iters), loss = 0.246781
I1006 18:06:53.313623  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.246781 (* 1 = 0.246781 loss)
I1006 18:06:53.313639  3702 sgd_solver.cpp:105] Iteration 21100, lr = 0.1
I1006 18:07:01.654229  3702 solver.cpp:218] Iteration 21200 (11.9896 iter/s, 8.34058s/100 iters), loss = 0.163337
I1006 18:07:01.654362  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.163337 (* 1 = 0.163337 loss)
I1006 18:07:01.654369  3702 sgd_solver.cpp:105] Iteration 21200, lr = 0.1
I1006 18:07:09.986258  3702 solver.cpp:218] Iteration 21300 (12.0021 iter/s, 8.33187s/100 iters), loss = 0.244506
I1006 18:07:09.986297  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.244506 (* 1 = 0.244506 loss)
I1006 18:07:09.986304  3702 sgd_solver.cpp:105] Iteration 21300, lr = 0.1
I1006 18:07:18.327483  3702 solver.cpp:218] Iteration 21400 (11.9887 iter/s, 8.34116s/100 iters), loss = 0.303007
I1006 18:07:18.327522  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.303007 (* 1 = 0.303007 loss)
I1006 18:07:18.327529  3702 sgd_solver.cpp:105] Iteration 21400, lr = 0.1
I1006 18:07:26.249868  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:07:26.583585  3702 solver.cpp:330] Iteration 21500, Testing net (#0)
I1006 18:07:28.510442  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:07:28.590931  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8204
I1006 18:07:28.590965  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.539857 (* 1 = 0.539857 loss)
I1006 18:07:28.674456  3702 solver.cpp:218] Iteration 21500 (9.66473 iter/s, 10.3469s/100 iters), loss = 0.208965
I1006 18:07:28.674484  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.208965 (* 1 = 0.208965 loss)
I1006 18:07:28.674491  3702 sgd_solver.cpp:105] Iteration 21500, lr = 0.1
I1006 18:07:37.009299  3702 solver.cpp:218] Iteration 21600 (11.9979 iter/s, 8.33479s/100 iters), loss = 0.1284
I1006 18:07:37.009399  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.1284 (* 1 = 0.1284 loss)
I1006 18:07:37.009407  3702 sgd_solver.cpp:105] Iteration 21600, lr = 0.1
I1006 18:07:45.340688  3702 solver.cpp:218] Iteration 21700 (12.003 iter/s, 8.33126s/100 iters), loss = 0.269897
I1006 18:07:45.340716  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.269897 (* 1 = 0.269897 loss)
I1006 18:07:45.340721  3702 sgd_solver.cpp:105] Iteration 21700, lr = 0.1
I1006 18:07:53.677197  3702 solver.cpp:218] Iteration 21800 (11.9955 iter/s, 8.33646s/100 iters), loss = 0.261135
I1006 18:07:53.677237  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.261135 (* 1 = 0.261135 loss)
I1006 18:07:53.677242  3702 sgd_solver.cpp:105] Iteration 21800, lr = 0.1
I1006 18:08:02.008594  3702 solver.cpp:218] Iteration 21900 (12.0029 iter/s, 8.33133s/100 iters), loss = 0.308765
I1006 18:08:02.008622  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.308765 (* 1 = 0.308765 loss)
I1006 18:08:02.008628  3702 sgd_solver.cpp:105] Iteration 21900, lr = 0.1
I1006 18:08:09.934053  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:08:10.267961  3702 solver.cpp:330] Iteration 22000, Testing net (#0)
I1006 18:08:12.195431  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:08:12.276381  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7724
I1006 18:08:12.276417  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.797565 (* 1 = 0.797565 loss)
I1006 18:08:12.359159  3702 solver.cpp:218] Iteration 22000 (9.66136 iter/s, 10.3505s/100 iters), loss = 0.22255
I1006 18:08:12.359189  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.22255 (* 1 = 0.22255 loss)
I1006 18:08:12.359194  3702 sgd_solver.cpp:105] Iteration 22000, lr = 0.1
I1006 18:08:20.684388  3702 solver.cpp:218] Iteration 22100 (12.0118 iter/s, 8.32517s/100 iters), loss = 0.247212
I1006 18:08:20.684417  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.247212 (* 1 = 0.247212 loss)
I1006 18:08:20.684423  3702 sgd_solver.cpp:105] Iteration 22100, lr = 0.1
I1006 18:08:29.016438  3702 solver.cpp:218] Iteration 22200 (12.0019 iter/s, 8.33199s/100 iters), loss = 0.214357
I1006 18:08:29.016476  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.214357 (* 1 = 0.214357 loss)
I1006 18:08:29.016482  3702 sgd_solver.cpp:105] Iteration 22200, lr = 0.1
I1006 18:08:37.342350  3702 solver.cpp:218] Iteration 22300 (12.0108 iter/s, 8.32584s/100 iters), loss = 0.265651
I1006 18:08:37.342381  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.265651 (* 1 = 0.265651 loss)
I1006 18:08:37.342386  3702 sgd_solver.cpp:105] Iteration 22300, lr = 0.1
I1006 18:08:45.672752  3702 solver.cpp:218] Iteration 22400 (12.0043 iter/s, 8.33035s/100 iters), loss = 0.164229
I1006 18:08:45.672863  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.164229 (* 1 = 0.164229 loss)
I1006 18:08:45.672870  3702 sgd_solver.cpp:105] Iteration 22400, lr = 0.1
I1006 18:08:53.592310  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:08:53.924769  3702 solver.cpp:330] Iteration 22500, Testing net (#0)
I1006 18:08:55.851824  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:08:55.932307  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7954
I1006 18:08:55.932340  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.686699 (* 1 = 0.686699 loss)
I1006 18:08:56.015913  3702 solver.cpp:218] Iteration 22500 (9.66835 iter/s, 10.343s/100 iters), loss = 0.188008
I1006 18:08:56.015938  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.188008 (* 1 = 0.188008 loss)
I1006 18:08:56.015945  3702 sgd_solver.cpp:105] Iteration 22500, lr = 0.1
I1006 18:09:04.337538  3702 solver.cpp:218] Iteration 22600 (12.017 iter/s, 8.32157s/100 iters), loss = 0.187497
I1006 18:09:04.337577  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.187497 (* 1 = 0.187497 loss)
I1006 18:09:04.337584  3702 sgd_solver.cpp:105] Iteration 22600, lr = 0.1
I1006 18:09:12.656157  3702 solver.cpp:218] Iteration 22700 (12.0213 iter/s, 8.31855s/100 iters), loss = 0.224524
I1006 18:09:12.656195  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.224524 (* 1 = 0.224524 loss)
I1006 18:09:12.656201  3702 sgd_solver.cpp:105] Iteration 22700, lr = 0.1
I1006 18:09:20.979650  3702 solver.cpp:218] Iteration 22800 (12.0143 iter/s, 8.32343s/100 iters), loss = 0.211037
I1006 18:09:20.979779  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.211037 (* 1 = 0.211037 loss)
I1006 18:09:20.979799  3702 sgd_solver.cpp:105] Iteration 22800, lr = 0.1
I1006 18:09:29.304391  3702 solver.cpp:218] Iteration 22900 (12.0126 iter/s, 8.32459s/100 iters), loss = 0.12504
I1006 18:09:29.304430  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.12504 (* 1 = 0.12504 loss)
I1006 18:09:29.304436  3702 sgd_solver.cpp:105] Iteration 22900, lr = 0.1
I1006 18:09:37.218616  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:09:37.551702  3702 solver.cpp:330] Iteration 23000, Testing net (#0)
I1006 18:09:39.477885  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:09:39.558521  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8277
I1006 18:09:39.558555  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.53774 (* 1 = 0.53774 loss)
I1006 18:09:39.641116  3702 solver.cpp:218] Iteration 23000 (9.67431 iter/s, 10.3367s/100 iters), loss = 0.189066
I1006 18:09:39.641144  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.189066 (* 1 = 0.189066 loss)
I1006 18:09:39.641150  3702 sgd_solver.cpp:105] Iteration 23000, lr = 0.1
I1006 18:09:47.966944  3702 solver.cpp:218] Iteration 23100 (12.0109 iter/s, 8.32578s/100 iters), loss = 0.273375
I1006 18:09:47.966974  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.273375 (* 1 = 0.273375 loss)
I1006 18:09:47.966980  3702 sgd_solver.cpp:105] Iteration 23100, lr = 0.1
I1006 18:09:56.300933  3702 solver.cpp:218] Iteration 23200 (11.9991 iter/s, 8.33393s/100 iters), loss = 0.219185
I1006 18:09:56.301028  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.219185 (* 1 = 0.219185 loss)
I1006 18:09:56.301043  3702 sgd_solver.cpp:105] Iteration 23200, lr = 0.1
I1006 18:10:04.631418  3702 solver.cpp:218] Iteration 23300 (12.0043 iter/s, 8.33037s/100 iters), loss = 0.233267
I1006 18:10:04.631448  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.233267 (* 1 = 0.233267 loss)
I1006 18:10:04.631454  3702 sgd_solver.cpp:105] Iteration 23300, lr = 0.1
I1006 18:10:12.961973  3702 solver.cpp:218] Iteration 23400 (12.0041 iter/s, 8.3305s/100 iters), loss = 0.21974
I1006 18:10:12.962013  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.21974 (* 1 = 0.21974 loss)
I1006 18:10:12.962019  3702 sgd_solver.cpp:105] Iteration 23400, lr = 0.1
I1006 18:10:20.879772  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:10:21.213769  3702 solver.cpp:330] Iteration 23500, Testing net (#0)
I1006 18:10:23.141122  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:10:23.221680  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7285
I1006 18:10:23.221715  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.967806 (* 1 = 0.967806 loss)
I1006 18:10:23.305297  3702 solver.cpp:218] Iteration 23500 (9.66813 iter/s, 10.3433s/100 iters), loss = 0.158094
I1006 18:10:23.305328  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.158093 (* 1 = 0.158093 loss)
I1006 18:10:23.305335  3702 sgd_solver.cpp:105] Iteration 23500, lr = 0.1
I1006 18:10:31.637614  3702 solver.cpp:218] Iteration 23600 (12.0015 iter/s, 8.33226s/100 iters), loss = 0.182493
I1006 18:10:31.637749  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.182492 (* 1 = 0.182492 loss)
I1006 18:10:31.637756  3702 sgd_solver.cpp:105] Iteration 23600, lr = 0.1
I1006 18:10:39.959604  3702 solver.cpp:218] Iteration 23700 (12.0166 iter/s, 8.32184s/100 iters), loss = 0.25753
I1006 18:10:39.959645  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.257529 (* 1 = 0.257529 loss)
I1006 18:10:39.959650  3702 sgd_solver.cpp:105] Iteration 23700, lr = 0.1
I1006 18:10:48.283277  3702 solver.cpp:218] Iteration 23800 (12.014 iter/s, 8.32361s/100 iters), loss = 0.218356
I1006 18:10:48.283305  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.218356 (* 1 = 0.218356 loss)
I1006 18:10:48.283310  3702 sgd_solver.cpp:105] Iteration 23800, lr = 0.1
I1006 18:10:56.606276  3702 solver.cpp:218] Iteration 23900 (12.015 iter/s, 8.32295s/100 iters), loss = 0.196877
I1006 18:10:56.606307  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.196877 (* 1 = 0.196877 loss)
I1006 18:10:56.606322  3702 sgd_solver.cpp:105] Iteration 23900, lr = 0.1
I1006 18:11:04.522701  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:11:04.855940  3702 solver.cpp:330] Iteration 24000, Testing net (#0)
I1006 18:11:06.783751  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:11:06.864783  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7884
I1006 18:11:06.864816  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.64606 (* 1 = 0.64606 loss)
I1006 18:11:06.947381  3702 solver.cpp:218] Iteration 24000 (9.6702 iter/s, 10.341s/100 iters), loss = 0.220499
I1006 18:11:06.947408  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.220498 (* 1 = 0.220498 loss)
I1006 18:11:06.947414  3702 sgd_solver.cpp:105] Iteration 24000, lr = 0.1
I1006 18:11:15.277211  3702 solver.cpp:218] Iteration 24100 (12.0051 iter/s, 8.32978s/100 iters), loss = 0.182691
I1006 18:11:15.277251  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.182691 (* 1 = 0.182691 loss)
I1006 18:11:15.277257  3702 sgd_solver.cpp:105] Iteration 24100, lr = 0.1
I1006 18:11:23.622192  3702 solver.cpp:218] Iteration 24200 (11.9833 iter/s, 8.34492s/100 iters), loss = 0.231378
I1006 18:11:23.622232  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.231378 (* 1 = 0.231378 loss)
I1006 18:11:23.622238  3702 sgd_solver.cpp:105] Iteration 24200, lr = 0.1
I1006 18:11:31.954119  3702 solver.cpp:218] Iteration 24300 (12.0021 iter/s, 8.33186s/100 iters), loss = 0.227863
I1006 18:11:31.954149  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.227863 (* 1 = 0.227863 loss)
I1006 18:11:31.954154  3702 sgd_solver.cpp:105] Iteration 24300, lr = 0.1
I1006 18:11:40.291260  3702 solver.cpp:218] Iteration 24400 (11.9946 iter/s, 8.33708s/100 iters), loss = 0.176304
I1006 18:11:40.291404  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.176304 (* 1 = 0.176304 loss)
I1006 18:11:40.291411  3702 sgd_solver.cpp:105] Iteration 24400, lr = 0.1
I1006 18:11:48.216336  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:11:48.550081  3702 solver.cpp:330] Iteration 24500, Testing net (#0)
I1006 18:11:50.476001  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:11:50.556406  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7388
I1006 18:11:50.556442  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.865631 (* 1 = 0.865631 loss)
I1006 18:11:50.639843  3702 solver.cpp:218] Iteration 24500 (9.66332 iter/s, 10.3484s/100 iters), loss = 0.19319
I1006 18:11:50.639870  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.19319 (* 1 = 0.19319 loss)
I1006 18:11:50.639878  3702 sgd_solver.cpp:105] Iteration 24500, lr = 0.1
I1006 18:11:58.973737  3702 solver.cpp:218] Iteration 24600 (11.9993 iter/s, 8.3338s/100 iters), loss = 0.16535
I1006 18:11:58.973767  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.16535 (* 1 = 0.16535 loss)
I1006 18:11:58.973772  3702 sgd_solver.cpp:105] Iteration 24600, lr = 0.1
I1006 18:12:07.302964  3702 solver.cpp:218] Iteration 24700 (12.006 iter/s, 8.32917s/100 iters), loss = 0.234393
I1006 18:12:07.302995  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.234393 (* 1 = 0.234393 loss)
I1006 18:12:07.303001  3702 sgd_solver.cpp:105] Iteration 24700, lr = 0.1
I1006 18:12:15.637235  3702 solver.cpp:218] Iteration 24800 (11.9987 iter/s, 8.33421s/100 iters), loss = 0.272891
I1006 18:12:15.637365  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.272891 (* 1 = 0.272891 loss)
I1006 18:12:15.637372  3702 sgd_solver.cpp:105] Iteration 24800, lr = 0.1
I1006 18:12:23.966765  3702 solver.cpp:218] Iteration 24900 (12.0057 iter/s, 8.32938s/100 iters), loss = 0.184175
I1006 18:12:23.966794  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.184174 (* 1 = 0.184174 loss)
I1006 18:12:23.966799  3702 sgd_solver.cpp:105] Iteration 24900, lr = 0.1
I1006 18:12:31.892205  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:12:32.225615  3702 solver.cpp:330] Iteration 25000, Testing net (#0)
I1006 18:12:34.152904  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:12:34.233459  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8206
I1006 18:12:34.233494  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.547819 (* 1 = 0.547819 loss)
I1006 18:12:34.316223  3702 solver.cpp:218] Iteration 25000 (9.6624 iter/s, 10.3494s/100 iters), loss = 0.230427
I1006 18:12:34.316249  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.230427 (* 1 = 0.230427 loss)
I1006 18:12:34.316256  3702 sgd_solver.cpp:105] Iteration 25000, lr = 0.1
I1006 18:12:42.642848  3702 solver.cpp:218] Iteration 25100 (12.0097 iter/s, 8.32657s/100 iters), loss = 0.244423
I1006 18:12:42.642877  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.244423 (* 1 = 0.244423 loss)
I1006 18:12:42.642884  3702 sgd_solver.cpp:105] Iteration 25100, lr = 0.1
I1006 18:12:50.976375  3702 solver.cpp:218] Iteration 25200 (11.9998 iter/s, 8.33347s/100 iters), loss = 0.258124
I1006 18:12:50.976511  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.258124 (* 1 = 0.258124 loss)
I1006 18:12:50.976518  3702 sgd_solver.cpp:105] Iteration 25200, lr = 0.1
I1006 18:12:59.305480  3702 solver.cpp:218] Iteration 25300 (12.0063 iter/s, 8.32896s/100 iters), loss = 0.223522
I1006 18:12:59.305510  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.223522 (* 1 = 0.223522 loss)
I1006 18:12:59.305516  3702 sgd_solver.cpp:105] Iteration 25300, lr = 0.1
I1006 18:13:07.637168  3702 solver.cpp:218] Iteration 25400 (12.0024 iter/s, 8.33163s/100 iters), loss = 0.170782
I1006 18:13:07.637197  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.170782 (* 1 = 0.170782 loss)
I1006 18:13:07.637213  3702 sgd_solver.cpp:105] Iteration 25400, lr = 0.1
I1006 18:13:15.551131  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:13:15.885818  3702 solver.cpp:330] Iteration 25500, Testing net (#0)
I1006 18:13:17.812229  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:13:17.892551  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7269
I1006 18:13:17.892585  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.00093 (* 1 = 1.00093 loss)
I1006 18:13:17.976361  3702 solver.cpp:218] Iteration 25500 (9.67199 iter/s, 10.3391s/100 iters), loss = 0.168104
I1006 18:13:17.976388  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.168104 (* 1 = 0.168104 loss)
I1006 18:13:17.976394  3702 sgd_solver.cpp:105] Iteration 25500, lr = 0.1
I1006 18:13:26.300045  3702 solver.cpp:218] Iteration 25600 (12.014 iter/s, 8.32363s/100 iters), loss = 0.254626
I1006 18:13:26.300187  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.254626 (* 1 = 0.254626 loss)
I1006 18:13:26.300196  3702 sgd_solver.cpp:105] Iteration 25600, lr = 0.1
I1006 18:13:34.616986  3702 solver.cpp:218] Iteration 25700 (12.0239 iter/s, 8.31678s/100 iters), loss = 0.242588
I1006 18:13:34.617025  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.242588 (* 1 = 0.242588 loss)
I1006 18:13:34.617031  3702 sgd_solver.cpp:105] Iteration 25700, lr = 0.1
I1006 18:13:42.951176  3702 solver.cpp:218] Iteration 25800 (11.9989 iter/s, 8.33412s/100 iters), loss = 0.263042
I1006 18:13:42.951207  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.263042 (* 1 = 0.263042 loss)
I1006 18:13:42.951213  3702 sgd_solver.cpp:105] Iteration 25800, lr = 0.1
I1006 18:13:51.368428  3702 solver.cpp:218] Iteration 25900 (11.8804 iter/s, 8.41719s/100 iters), loss = 0.15901
I1006 18:13:51.368459  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.15901 (* 1 = 0.15901 loss)
I1006 18:13:51.368466  3702 sgd_solver.cpp:105] Iteration 25900, lr = 0.1
I1006 18:13:59.312784  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:13:59.644944  3702 solver.cpp:330] Iteration 26000, Testing net (#0)
I1006 18:14:01.590658  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:14:01.672904  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7469
I1006 18:14:01.672930  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.805457 (* 1 = 0.805457 loss)
I1006 18:14:01.756602  3702 solver.cpp:218] Iteration 26000 (9.62639 iter/s, 10.3881s/100 iters), loss = 0.147194
I1006 18:14:01.756630  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.147194 (* 1 = 0.147194 loss)
I1006 18:14:01.756638  3702 sgd_solver.cpp:105] Iteration 26000, lr = 0.1
I1006 18:14:10.125555  3702 solver.cpp:218] Iteration 26100 (11.949 iter/s, 8.3689s/100 iters), loss = 0.14823
I1006 18:14:10.125594  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.14823 (* 1 = 0.14823 loss)
I1006 18:14:10.125600  3702 sgd_solver.cpp:105] Iteration 26100, lr = 0.1
I1006 18:14:18.463933  3702 solver.cpp:218] Iteration 26200 (11.9928 iter/s, 8.33831s/100 iters), loss = 0.234493
I1006 18:14:18.463961  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.234493 (* 1 = 0.234493 loss)
I1006 18:14:18.463968  3702 sgd_solver.cpp:105] Iteration 26200, lr = 0.1
I1006 18:14:26.800325  3702 solver.cpp:218] Iteration 26300 (11.9957 iter/s, 8.33634s/100 iters), loss = 0.245135
I1006 18:14:26.800355  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.245135 (* 1 = 0.245135 loss)
I1006 18:14:26.800362  3702 sgd_solver.cpp:105] Iteration 26300, lr = 0.1
I1006 18:14:35.134814  3702 solver.cpp:218] Iteration 26400 (11.9984 iter/s, 8.33443s/100 iters), loss = 0.111231
I1006 18:14:35.134949  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.111231 (* 1 = 0.111231 loss)
I1006 18:14:35.134958  3702 sgd_solver.cpp:105] Iteration 26400, lr = 0.1
I1006 18:14:43.057215  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:14:43.390854  3702 solver.cpp:330] Iteration 26500, Testing net (#0)
I1006 18:14:45.316927  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:14:45.396873  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8103
I1006 18:14:45.396909  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.584069 (* 1 = 0.584069 loss)
I1006 18:14:45.480366  3702 solver.cpp:218] Iteration 26500 (9.66613 iter/s, 10.3454s/100 iters), loss = 0.203595
I1006 18:14:45.480393  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.203595 (* 1 = 0.203595 loss)
I1006 18:14:45.480401  3702 sgd_solver.cpp:105] Iteration 26500, lr = 0.1
I1006 18:14:53.811036  3702 solver.cpp:218] Iteration 26600 (12.0039 iter/s, 8.33062s/100 iters), loss = 0.247124
I1006 18:14:53.811065  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.247124 (* 1 = 0.247124 loss)
I1006 18:14:53.811071  3702 sgd_solver.cpp:105] Iteration 26600, lr = 0.1
I1006 18:15:02.128860  3702 solver.cpp:218] Iteration 26700 (12.0225 iter/s, 8.31777s/100 iters), loss = 0.248901
I1006 18:15:02.128888  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.248901 (* 1 = 0.248901 loss)
I1006 18:15:02.128895  3702 sgd_solver.cpp:105] Iteration 26700, lr = 0.1
I1006 18:15:10.460415  3702 solver.cpp:218] Iteration 26800 (12.0026 iter/s, 8.3315s/100 iters), loss = 0.232408
I1006 18:15:10.460563  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.232408 (* 1 = 0.232408 loss)
I1006 18:15:10.460571  3702 sgd_solver.cpp:105] Iteration 26800, lr = 0.1
I1006 18:15:18.784939  3702 solver.cpp:218] Iteration 26900 (12.0129 iter/s, 8.32435s/100 iters), loss = 0.256615
I1006 18:15:18.784967  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.256615 (* 1 = 0.256615 loss)
I1006 18:15:18.784972  3702 sgd_solver.cpp:105] Iteration 26900, lr = 0.1
I1006 18:15:26.701578  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:15:27.035250  3702 solver.cpp:330] Iteration 27000, Testing net (#0)
I1006 18:15:28.962539  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:15:29.042721  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8371
I1006 18:15:29.042757  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.519025 (* 1 = 0.519025 loss)
I1006 18:15:29.125202  3702 solver.cpp:218] Iteration 27000 (9.67099 iter/s, 10.3402s/100 iters), loss = 0.145827
I1006 18:15:29.125228  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.145826 (* 1 = 0.145826 loss)
I1006 18:15:29.125234  3702 sgd_solver.cpp:105] Iteration 27000, lr = 0.1
I1006 18:15:37.460798  3702 solver.cpp:218] Iteration 27100 (11.9968 iter/s, 8.33554s/100 iters), loss = 0.164088
I1006 18:15:37.460826  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.164088 (* 1 = 0.164088 loss)
I1006 18:15:37.460831  3702 sgd_solver.cpp:105] Iteration 27100, lr = 0.1
I1006 18:15:45.800508  3702 solver.cpp:218] Iteration 27200 (11.9909 iter/s, 8.33966s/100 iters), loss = 0.199054
I1006 18:15:45.800612  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.199054 (* 1 = 0.199054 loss)
I1006 18:15:45.800628  3702 sgd_solver.cpp:105] Iteration 27200, lr = 0.1
I1006 18:15:54.136476  3702 solver.cpp:218] Iteration 27300 (11.9964 iter/s, 8.33584s/100 iters), loss = 0.188794
I1006 18:15:54.136515  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.188794 (* 1 = 0.188794 loss)
I1006 18:15:54.136521  3702 sgd_solver.cpp:105] Iteration 27300, lr = 0.1
I1006 18:16:02.470814  3702 solver.cpp:218] Iteration 27400 (11.9986 iter/s, 8.33427s/100 iters), loss = 0.153035
I1006 18:16:02.470842  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.153035 (* 1 = 0.153035 loss)
I1006 18:16:02.470849  3702 sgd_solver.cpp:105] Iteration 27400, lr = 0.1
I1006 18:16:10.390861  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:16:10.723904  3702 solver.cpp:330] Iteration 27500, Testing net (#0)
I1006 18:16:12.650791  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:16:12.731015  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.683
I1006 18:16:12.731040  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.17769 (* 1 = 1.17769 loss)
I1006 18:16:12.814414  3702 solver.cpp:218] Iteration 27500 (9.66787 iter/s, 10.3435s/100 iters), loss = 0.228657
I1006 18:16:12.814443  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.228657 (* 1 = 0.228657 loss)
I1006 18:16:12.814450  3702 sgd_solver.cpp:105] Iteration 27500, lr = 0.1
I1006 18:16:21.145534  3702 solver.cpp:218] Iteration 27600 (12.0033 iter/s, 8.33106s/100 iters), loss = 0.174841
I1006 18:16:21.145690  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.17484 (* 1 = 0.17484 loss)
I1006 18:16:21.145699  3702 sgd_solver.cpp:105] Iteration 27600, lr = 0.1
I1006 18:16:29.468617  3702 solver.cpp:218] Iteration 27700 (12.015 iter/s, 8.32291s/100 iters), loss = 0.166354
I1006 18:16:29.468647  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.166354 (* 1 = 0.166354 loss)
I1006 18:16:29.468653  3702 sgd_solver.cpp:105] Iteration 27700, lr = 0.1
I1006 18:16:37.797289  3702 solver.cpp:218] Iteration 27800 (12.0068 iter/s, 8.32862s/100 iters), loss = 0.185217
I1006 18:16:37.797329  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.185217 (* 1 = 0.185217 loss)
I1006 18:16:37.797335  3702 sgd_solver.cpp:105] Iteration 27800, lr = 0.1
I1006 18:16:46.123440  3702 solver.cpp:218] Iteration 27900 (12.0104 iter/s, 8.32609s/100 iters), loss = 0.157768
I1006 18:16:46.123471  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.157768 (* 1 = 0.157768 loss)
I1006 18:16:46.123477  3702 sgd_solver.cpp:105] Iteration 27900, lr = 0.1
I1006 18:16:54.036952  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:16:54.370285  3702 solver.cpp:330] Iteration 28000, Testing net (#0)
I1006 18:16:56.296705  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:16:56.377709  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7754
I1006 18:16:56.377745  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.686648 (* 1 = 0.686648 loss)
I1006 18:16:56.460212  3702 solver.cpp:218] Iteration 28000 (9.67426 iter/s, 10.3367s/100 iters), loss = 0.228014
I1006 18:16:56.460239  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.228014 (* 1 = 0.228014 loss)
I1006 18:16:56.460247  3702 sgd_solver.cpp:105] Iteration 28000, lr = 0.1
I1006 18:17:04.779696  3702 solver.cpp:218] Iteration 28100 (12.0201 iter/s, 8.31943s/100 iters), loss = 0.181743
I1006 18:17:04.779726  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.181743 (* 1 = 0.181743 loss)
I1006 18:17:04.779731  3702 sgd_solver.cpp:105] Iteration 28100, lr = 0.1
I1006 18:17:13.110179  3702 solver.cpp:218] Iteration 28200 (12.0042 iter/s, 8.33043s/100 iters), loss = 0.285216
I1006 18:17:13.110209  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.285216 (* 1 = 0.285216 loss)
I1006 18:17:13.110215  3702 sgd_solver.cpp:105] Iteration 28200, lr = 0.1
I1006 18:17:21.435676  3702 solver.cpp:218] Iteration 28300 (12.0114 iter/s, 8.32544s/100 iters), loss = 0.146992
I1006 18:17:21.435716  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.146992 (* 1 = 0.146992 loss)
I1006 18:17:21.435722  3702 sgd_solver.cpp:105] Iteration 28300, lr = 0.1
I1006 18:17:29.761304  3702 solver.cpp:218] Iteration 28400 (12.0112 iter/s, 8.32556s/100 iters), loss = 0.160234
I1006 18:17:29.761416  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.160233 (* 1 = 0.160233 loss)
I1006 18:17:29.761423  3702 sgd_solver.cpp:105] Iteration 28400, lr = 0.1
I1006 18:17:37.669217  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:17:38.002033  3702 solver.cpp:330] Iteration 28500, Testing net (#0)
I1006 18:17:39.925130  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:17:40.004951  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8446
I1006 18:17:40.004974  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.488956 (* 1 = 0.488956 loss)
I1006 18:17:40.088394  3702 solver.cpp:218] Iteration 28500 (9.6834 iter/s, 10.327s/100 iters), loss = 0.251454
I1006 18:17:40.088420  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.251454 (* 1 = 0.251454 loss)
I1006 18:17:40.088426  3702 sgd_solver.cpp:105] Iteration 28500, lr = 0.1
I1006 18:17:48.412173  3702 solver.cpp:218] Iteration 28600 (12.0139 iter/s, 8.32373s/100 iters), loss = 0.157443
I1006 18:17:48.412212  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.157443 (* 1 = 0.157443 loss)
I1006 18:17:48.412219  3702 sgd_solver.cpp:105] Iteration 28600, lr = 0.1
I1006 18:17:56.735225  3702 solver.cpp:218] Iteration 28700 (12.0149 iter/s, 8.32299s/100 iters), loss = 0.264663
I1006 18:17:56.735255  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.264663 (* 1 = 0.264663 loss)
I1006 18:17:56.735260  3702 sgd_solver.cpp:105] Iteration 28700, lr = 0.1
I1006 18:18:05.061758  3702 solver.cpp:218] Iteration 28800 (12.0099 iter/s, 8.32648s/100 iters), loss = 0.199644
I1006 18:18:05.061873  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.199644 (* 1 = 0.199644 loss)
I1006 18:18:05.061880  3702 sgd_solver.cpp:105] Iteration 28800, lr = 0.1
I1006 18:18:13.380939  3702 solver.cpp:218] Iteration 28900 (12.0206 iter/s, 8.31904s/100 iters), loss = 0.201697
I1006 18:18:13.380986  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.201697 (* 1 = 0.201697 loss)
I1006 18:18:13.380993  3702 sgd_solver.cpp:105] Iteration 28900, lr = 0.1
I1006 18:18:21.291613  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:18:21.624444  3702 solver.cpp:330] Iteration 29000, Testing net (#0)
I1006 18:18:23.550156  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:18:23.630627  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7798
I1006 18:18:23.630661  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.73654 (* 1 = 0.73654 loss)
I1006 18:18:23.713425  3702 solver.cpp:218] Iteration 29000 (9.67829 iter/s, 10.3324s/100 iters), loss = 0.191571
I1006 18:18:23.713455  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.191571 (* 1 = 0.191571 loss)
I1006 18:18:23.713462  3702 sgd_solver.cpp:105] Iteration 29000, lr = 0.1
I1006 18:18:32.035717  3702 solver.cpp:218] Iteration 29100 (12.016 iter/s, 8.32224s/100 iters), loss = 0.228554
I1006 18:18:32.035746  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.228554 (* 1 = 0.228554 loss)
I1006 18:18:32.035753  3702 sgd_solver.cpp:105] Iteration 29100, lr = 0.1
I1006 18:18:40.366174  3702 solver.cpp:218] Iteration 29200 (12.0042 iter/s, 8.3304s/100 iters), loss = 0.27321
I1006 18:18:40.366308  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.27321 (* 1 = 0.27321 loss)
I1006 18:18:40.366315  3702 sgd_solver.cpp:105] Iteration 29200, lr = 0.1
I1006 18:18:48.693200  3702 solver.cpp:218] Iteration 29300 (12.0093 iter/s, 8.32687s/100 iters), loss = 0.253781
I1006 18:18:48.693240  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.253781 (* 1 = 0.253781 loss)
I1006 18:18:48.693245  3702 sgd_solver.cpp:105] Iteration 29300, lr = 0.1
I1006 18:18:57.022052  3702 solver.cpp:218] Iteration 29400 (12.0066 iter/s, 8.32879s/100 iters), loss = 0.165903
I1006 18:18:57.022081  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.165903 (* 1 = 0.165903 loss)
I1006 18:18:57.022086  3702 sgd_solver.cpp:105] Iteration 29400, lr = 0.1
I1006 18:19:04.933953  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:19:05.267452  3702 solver.cpp:330] Iteration 29500, Testing net (#0)
I1006 18:19:07.195627  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:19:07.275929  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7632
I1006 18:19:07.275964  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.77961 (* 1 = 0.77961 loss)
I1006 18:19:07.359751  3702 solver.cpp:218] Iteration 29500 (9.67339 iter/s, 10.3376s/100 iters), loss = 0.296826
I1006 18:19:07.359777  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.296826 (* 1 = 0.296826 loss)
I1006 18:19:07.359784  3702 sgd_solver.cpp:105] Iteration 29500, lr = 0.1
I1006 18:19:15.693963  3702 solver.cpp:218] Iteration 29600 (11.9988 iter/s, 8.33416s/100 iters), loss = 0.1983
I1006 18:19:15.694051  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.1983 (* 1 = 0.1983 loss)
I1006 18:19:15.694057  3702 sgd_solver.cpp:105] Iteration 29600, lr = 0.1
I1006 18:19:24.016451  3702 solver.cpp:218] Iteration 29700 (12.0158 iter/s, 8.32238s/100 iters), loss = 0.338975
I1006 18:19:24.016481  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.338975 (* 1 = 0.338975 loss)
I1006 18:19:24.016497  3702 sgd_solver.cpp:105] Iteration 29700, lr = 0.1
I1006 18:19:32.349601  3702 solver.cpp:218] Iteration 29800 (12.0003 iter/s, 8.33309s/100 iters), loss = 0.257071
I1006 18:19:32.349629  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.257071 (* 1 = 0.257071 loss)
I1006 18:19:32.349634  3702 sgd_solver.cpp:105] Iteration 29800, lr = 0.1
I1006 18:19:40.676926  3702 solver.cpp:218] Iteration 29900 (12.0087 iter/s, 8.32727s/100 iters), loss = 0.206524
I1006 18:19:40.676965  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.206523 (* 1 = 0.206523 loss)
I1006 18:19:40.676971  3702 sgd_solver.cpp:105] Iteration 29900, lr = 0.1
I1006 18:19:48.596654  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:19:48.931262  3702 solver.cpp:330] Iteration 30000, Testing net (#0)
I1006 18:19:50.858700  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:19:50.939573  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7818
I1006 18:19:50.939607  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.717004 (* 1 = 0.717004 loss)
I1006 18:19:51.022615  3702 solver.cpp:218] Iteration 30000 (9.66593 iter/s, 10.3456s/100 iters), loss = 0.125565
I1006 18:19:51.022639  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.125565 (* 1 = 0.125565 loss)
I1006 18:19:51.022645  3702 sgd_solver.cpp:105] Iteration 30000, lr = 0.1
I1006 18:19:59.351733  3702 solver.cpp:218] Iteration 30100 (12.0061 iter/s, 8.32907s/100 iters), loss = 0.228059
I1006 18:19:59.351763  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.228059 (* 1 = 0.228059 loss)
I1006 18:19:59.351769  3702 sgd_solver.cpp:105] Iteration 30100, lr = 0.1
I1006 18:20:07.684130  3702 solver.cpp:218] Iteration 30200 (12.0014 iter/s, 8.33234s/100 iters), loss = 0.208255
I1006 18:20:07.684160  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.208255 (* 1 = 0.208255 loss)
I1006 18:20:07.684175  3702 sgd_solver.cpp:105] Iteration 30200, lr = 0.1
I1006 18:20:16.014148  3702 solver.cpp:218] Iteration 30300 (12.0049 iter/s, 8.32996s/100 iters), loss = 0.208752
I1006 18:20:16.014178  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.208752 (* 1 = 0.208752 loss)
I1006 18:20:16.014183  3702 sgd_solver.cpp:105] Iteration 30300, lr = 0.1
I1006 18:20:24.349779  3702 solver.cpp:218] Iteration 30400 (11.9968 iter/s, 8.33558s/100 iters), loss = 0.200858
I1006 18:20:24.349896  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.200858 (* 1 = 0.200858 loss)
I1006 18:20:24.349913  3702 sgd_solver.cpp:105] Iteration 30400, lr = 0.1
I1006 18:20:32.272234  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:20:32.606411  3702 solver.cpp:330] Iteration 30500, Testing net (#0)
I1006 18:20:34.534128  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:20:34.613963  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7916
I1006 18:20:34.613998  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.64163 (* 1 = 0.64163 loss)
I1006 18:20:34.697532  3702 solver.cpp:218] Iteration 30500 (9.66407 iter/s, 10.3476s/100 iters), loss = 0.190332
I1006 18:20:34.697559  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.190332 (* 1 = 0.190332 loss)
I1006 18:20:34.697566  3702 sgd_solver.cpp:105] Iteration 30500, lr = 0.1
I1006 18:20:43.039664  3702 solver.cpp:218] Iteration 30600 (11.9874 iter/s, 8.34208s/100 iters), loss = 0.164937
I1006 18:20:43.039692  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.164937 (* 1 = 0.164937 loss)
I1006 18:20:43.039698  3702 sgd_solver.cpp:105] Iteration 30600, lr = 0.1
I1006 18:20:51.370385  3702 solver.cpp:218] Iteration 30700 (12.0038 iter/s, 8.33067s/100 iters), loss = 0.284132
I1006 18:20:51.370414  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.284132 (* 1 = 0.284132 loss)
I1006 18:20:51.370421  3702 sgd_solver.cpp:105] Iteration 30700, lr = 0.1
I1006 18:20:59.709825  3702 solver.cpp:218] Iteration 30800 (11.9913 iter/s, 8.33939s/100 iters), loss = 0.165578
I1006 18:20:59.709925  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.165578 (* 1 = 0.165578 loss)
I1006 18:20:59.709933  3702 sgd_solver.cpp:105] Iteration 30800, lr = 0.1
I1006 18:21:08.042510  3702 solver.cpp:218] Iteration 30900 (12.0011 iter/s, 8.33256s/100 iters), loss = 0.0938476
I1006 18:21:08.042551  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0938475 (* 1 = 0.0938475 loss)
I1006 18:21:08.042557  3702 sgd_solver.cpp:105] Iteration 30900, lr = 0.1
I1006 18:21:15.970151  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:21:16.304023  3702 solver.cpp:330] Iteration 31000, Testing net (#0)
I1006 18:21:18.230880  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:21:18.311548  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8133
I1006 18:21:18.311573  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.583338 (* 1 = 0.583338 loss)
I1006 18:21:18.394310  3702 solver.cpp:218] Iteration 31000 (9.66022 iter/s, 10.3517s/100 iters), loss = 0.205639
I1006 18:21:18.394335  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.205638 (* 1 = 0.205638 loss)
I1006 18:21:18.394341  3702 sgd_solver.cpp:105] Iteration 31000, lr = 0.1
I1006 18:21:26.724951  3702 solver.cpp:218] Iteration 31100 (12.004 iter/s, 8.33059s/100 iters), loss = 0.220115
I1006 18:21:26.724989  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.220115 (* 1 = 0.220115 loss)
I1006 18:21:26.724995  3702 sgd_solver.cpp:105] Iteration 31100, lr = 0.1
I1006 18:21:35.062433  3702 solver.cpp:218] Iteration 31200 (11.9941 iter/s, 8.33742s/100 iters), loss = 0.162951
I1006 18:21:35.062546  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.162951 (* 1 = 0.162951 loss)
I1006 18:21:35.062562  3702 sgd_solver.cpp:105] Iteration 31200, lr = 0.1
I1006 18:21:43.393067  3702 solver.cpp:218] Iteration 31300 (12.0041 iter/s, 8.3305s/100 iters), loss = 0.189243
I1006 18:21:43.393095  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.189243 (* 1 = 0.189243 loss)
I1006 18:21:43.393101  3702 sgd_solver.cpp:105] Iteration 31300, lr = 0.1
I1006 18:21:51.729977  3702 solver.cpp:218] Iteration 31400 (11.9949 iter/s, 8.33686s/100 iters), loss = 0.257444
I1006 18:21:51.730007  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.257444 (* 1 = 0.257444 loss)
I1006 18:21:51.730013  3702 sgd_solver.cpp:105] Iteration 31400, lr = 0.1
I1006 18:21:59.649992  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:21:59.983664  3702 solver.cpp:330] Iteration 31500, Testing net (#0)
I1006 18:22:01.912813  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:22:01.993134  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7667
I1006 18:22:01.993171  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.823888 (* 1 = 0.823888 loss)
I1006 18:22:02.076685  3702 solver.cpp:218] Iteration 31500 (9.66497 iter/s, 10.3466s/100 iters), loss = 0.18841
I1006 18:22:02.076714  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.18841 (* 1 = 0.18841 loss)
I1006 18:22:02.076720  3702 sgd_solver.cpp:105] Iteration 31500, lr = 0.1
I1006 18:22:10.412178  3702 solver.cpp:218] Iteration 31600 (11.997 iter/s, 8.33544s/100 iters), loss = 0.210937
I1006 18:22:10.412291  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.210937 (* 1 = 0.210937 loss)
I1006 18:22:10.412297  3702 sgd_solver.cpp:105] Iteration 31600, lr = 0.1
I1006 18:22:18.743693  3702 solver.cpp:218] Iteration 31700 (12.0028 iter/s, 8.33138s/100 iters), loss = 0.187235
I1006 18:22:18.743722  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.187235 (* 1 = 0.187235 loss)
I1006 18:22:18.743728  3702 sgd_solver.cpp:105] Iteration 31700, lr = 0.1
I1006 18:22:27.081979  3702 solver.cpp:218] Iteration 31800 (11.993 iter/s, 8.33823s/100 iters), loss = 0.220976
I1006 18:22:27.082007  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.220975 (* 1 = 0.220975 loss)
I1006 18:22:27.082023  3702 sgd_solver.cpp:105] Iteration 31800, lr = 0.1
I1006 18:22:35.413673  3702 solver.cpp:218] Iteration 31900 (12.0024 iter/s, 8.33164s/100 iters), loss = 0.157543
I1006 18:22:35.413702  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.157543 (* 1 = 0.157543 loss)
I1006 18:22:35.413707  3702 sgd_solver.cpp:105] Iteration 31900, lr = 0.1
I1006 18:22:43.337296  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:22:43.671182  3702 solver.cpp:330] Iteration 32000, Testing net (#0)
I1006 18:22:45.597685  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:22:45.678382  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8067
I1006 18:22:45.678417  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.678331 (* 1 = 0.678331 loss)
I1006 18:22:45.761369  3702 solver.cpp:218] Iteration 32000 (9.66404 iter/s, 10.3476s/100 iters), loss = 0.13973
I1006 18:22:45.761394  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.13973 (* 1 = 0.13973 loss)
I1006 18:22:45.761399  3702 sgd_solver.cpp:105] Iteration 32000, lr = 0.1
I1006 18:22:54.095999  3702 solver.cpp:218] Iteration 32100 (11.9982 iter/s, 8.33458s/100 iters), loss = 0.258668
I1006 18:22:54.096038  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.258668 (* 1 = 0.258668 loss)
I1006 18:22:54.096045  3702 sgd_solver.cpp:105] Iteration 32100, lr = 0.1
I1006 18:23:02.429977  3702 solver.cpp:218] Iteration 32200 (11.9992 iter/s, 8.33391s/100 iters), loss = 0.217028
I1006 18:23:02.430006  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.217028 (* 1 = 0.217028 loss)
I1006 18:23:02.430012  3702 sgd_solver.cpp:105] Iteration 32200, lr = 0.1
I1006 18:23:10.760200  3702 solver.cpp:218] Iteration 32300 (12.0046 iter/s, 8.33017s/100 iters), loss = 0.193516
I1006 18:23:10.760228  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.193516 (* 1 = 0.193516 loss)
I1006 18:23:10.760234  3702 sgd_solver.cpp:105] Iteration 32300, lr = 0.1
I1006 18:23:19.103761  3702 solver.cpp:218] Iteration 32400 (11.9854 iter/s, 8.34351s/100 iters), loss = 0.161777
I1006 18:23:19.103898  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.161777 (* 1 = 0.161777 loss)
I1006 18:23:19.103916  3702 sgd_solver.cpp:105] Iteration 32400, lr = 0.1
I1006 18:23:27.015547  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:23:27.349231  3702 solver.cpp:330] Iteration 32500, Testing net (#0)
I1006 18:23:29.276026  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:23:29.356665  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7878
I1006 18:23:29.356700  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.675575 (* 1 = 0.675575 loss)
I1006 18:23:29.440588  3702 solver.cpp:218] Iteration 32500 (9.67429 iter/s, 10.3367s/100 iters), loss = 0.156602
I1006 18:23:29.440615  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.156602 (* 1 = 0.156602 loss)
I1006 18:23:29.440623  3702 sgd_solver.cpp:105] Iteration 32500, lr = 0.1
I1006 18:23:37.780706  3702 solver.cpp:218] Iteration 32600 (11.9904 iter/s, 8.34003s/100 iters), loss = 0.265838
I1006 18:23:37.780746  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.265838 (* 1 = 0.265838 loss)
I1006 18:23:37.780751  3702 sgd_solver.cpp:105] Iteration 32600, lr = 0.1
I1006 18:23:46.115406  3702 solver.cpp:218] Iteration 32700 (11.9981 iter/s, 8.33463s/100 iters), loss = 0.140221
I1006 18:23:46.115445  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.140221 (* 1 = 0.140221 loss)
I1006 18:23:46.115451  3702 sgd_solver.cpp:105] Iteration 32700, lr = 0.1
I1006 18:23:54.458684  3702 solver.cpp:218] Iteration 32800 (11.9858 iter/s, 8.34321s/100 iters), loss = 0.175064
I1006 18:23:54.458825  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.175064 (* 1 = 0.175064 loss)
I1006 18:23:54.458833  3702 sgd_solver.cpp:105] Iteration 32800, lr = 0.1
I1006 18:24:02.793736  3702 solver.cpp:218] Iteration 32900 (11.9978 iter/s, 8.33489s/100 iters), loss = 0.184446
I1006 18:24:02.793776  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.184446 (* 1 = 0.184446 loss)
I1006 18:24:02.793781  3702 sgd_solver.cpp:105] Iteration 32900, lr = 0.1
I1006 18:24:10.717113  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:24:11.051244  3702 solver.cpp:330] Iteration 33000, Testing net (#0)
I1006 18:24:12.977105  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:24:13.058251  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8098
I1006 18:24:13.058286  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.584037 (* 1 = 0.584037 loss)
I1006 18:24:13.140688  3702 solver.cpp:218] Iteration 33000 (9.66475 iter/s, 10.3469s/100 iters), loss = 0.22672
I1006 18:24:13.140712  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.22672 (* 1 = 0.22672 loss)
I1006 18:24:13.140718  3702 sgd_solver.cpp:105] Iteration 33000, lr = 0.1
I1006 18:24:21.463850  3702 solver.cpp:218] Iteration 33100 (12.0147 iter/s, 8.32311s/100 iters), loss = 0.215255
I1006 18:24:21.463879  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.215255 (* 1 = 0.215255 loss)
I1006 18:24:21.463886  3702 sgd_solver.cpp:105] Iteration 33100, lr = 0.1
I1006 18:24:29.793018  3702 solver.cpp:218] Iteration 33200 (12.0061 iter/s, 8.32911s/100 iters), loss = 0.221808
I1006 18:24:29.793146  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.221808 (* 1 = 0.221808 loss)
I1006 18:24:29.793164  3702 sgd_solver.cpp:105] Iteration 33200, lr = 0.1
I1006 18:24:38.119925  3702 solver.cpp:218] Iteration 33300 (12.0095 iter/s, 8.32676s/100 iters), loss = 0.173938
I1006 18:24:38.119954  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.173938 (* 1 = 0.173938 loss)
I1006 18:24:38.119971  3702 sgd_solver.cpp:105] Iteration 33300, lr = 0.1
I1006 18:24:46.454602  3702 solver.cpp:218] Iteration 33400 (11.9981 iter/s, 8.33462s/100 iters), loss = 0.266348
I1006 18:24:46.454632  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.266348 (* 1 = 0.266348 loss)
I1006 18:24:46.454638  3702 sgd_solver.cpp:105] Iteration 33400, lr = 0.1
I1006 18:24:54.366127  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:24:54.699606  3702 solver.cpp:330] Iteration 33500, Testing net (#0)
I1006 18:24:56.626632  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:24:56.709468  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7664
I1006 18:24:56.709493  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.785944 (* 1 = 0.785944 loss)
I1006 18:24:56.792670  3702 solver.cpp:218] Iteration 33500 (9.67304 iter/s, 10.338s/100 iters), loss = 0.198343
I1006 18:24:56.792697  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.198343 (* 1 = 0.198343 loss)
I1006 18:24:56.792703  3702 sgd_solver.cpp:105] Iteration 33500, lr = 0.1
I1006 18:25:05.133646  3702 solver.cpp:218] Iteration 33600 (11.9891 iter/s, 8.34092s/100 iters), loss = 0.156765
I1006 18:25:05.133729  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.156765 (* 1 = 0.156765 loss)
I1006 18:25:05.133746  3702 sgd_solver.cpp:105] Iteration 33600, lr = 0.1
I1006 18:25:13.466454  3702 solver.cpp:218] Iteration 33700 (12.0009 iter/s, 8.3327s/100 iters), loss = 0.273916
I1006 18:25:13.466481  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.273916 (* 1 = 0.273916 loss)
I1006 18:25:13.466487  3702 sgd_solver.cpp:105] Iteration 33700, lr = 0.1
I1006 18:25:21.797562  3702 solver.cpp:218] Iteration 33800 (12.0033 iter/s, 8.33105s/100 iters), loss = 0.123391
I1006 18:25:21.797592  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.123391 (* 1 = 0.123391 loss)
I1006 18:25:21.797598  3702 sgd_solver.cpp:105] Iteration 33800, lr = 0.1
I1006 18:25:30.125844  3702 solver.cpp:218] Iteration 33900 (12.0074 iter/s, 8.32823s/100 iters), loss = 0.215111
I1006 18:25:30.125872  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.215111 (* 1 = 0.215111 loss)
I1006 18:25:30.125887  3702 sgd_solver.cpp:105] Iteration 33900, lr = 0.1
I1006 18:25:38.048785  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:25:38.382447  3702 solver.cpp:330] Iteration 34000, Testing net (#0)
I1006 18:25:40.308614  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:25:40.389603  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8329
I1006 18:25:40.389639  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.526112 (* 1 = 0.526112 loss)
I1006 18:25:40.472775  3702 solver.cpp:218] Iteration 34000 (9.66476 iter/s, 10.3469s/100 iters), loss = 0.155673
I1006 18:25:40.472803  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.155673 (* 1 = 0.155673 loss)
I1006 18:25:40.472810  3702 sgd_solver.cpp:105] Iteration 34000, lr = 0.1
I1006 18:25:48.811525  3702 solver.cpp:218] Iteration 34100 (11.9923 iter/s, 8.3387s/100 iters), loss = 0.160534
I1006 18:25:48.811555  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.160534 (* 1 = 0.160534 loss)
I1006 18:25:48.811561  3702 sgd_solver.cpp:105] Iteration 34100, lr = 0.1
I1006 18:25:57.148480  3702 solver.cpp:218] Iteration 34200 (11.9949 iter/s, 8.3369s/100 iters), loss = 0.361331
I1006 18:25:57.148521  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.36133 (* 1 = 0.36133 loss)
I1006 18:25:57.148526  3702 sgd_solver.cpp:105] Iteration 34200, lr = 0.1
I1006 18:26:05.489013  3702 solver.cpp:218] Iteration 34300 (11.9897 iter/s, 8.34047s/100 iters), loss = 0.144276
I1006 18:26:05.489042  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.144276 (* 1 = 0.144276 loss)
I1006 18:26:05.489048  3702 sgd_solver.cpp:105] Iteration 34300, lr = 0.1
I1006 18:26:13.827365  3702 solver.cpp:218] Iteration 34400 (11.9929 iter/s, 8.33829s/100 iters), loss = 0.202113
I1006 18:26:13.827479  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.202113 (* 1 = 0.202113 loss)
I1006 18:26:13.827486  3702 sgd_solver.cpp:105] Iteration 34400, lr = 0.1
I1006 18:26:21.746685  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:26:22.081588  3702 solver.cpp:330] Iteration 34500, Testing net (#0)
I1006 18:26:24.007834  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:26:24.088443  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7764
I1006 18:26:24.088479  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.684004 (* 1 = 0.684004 loss)
I1006 18:26:24.171958  3702 solver.cpp:218] Iteration 34500 (9.66702 iter/s, 10.3444s/100 iters), loss = 0.195498
I1006 18:26:24.171983  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.195498 (* 1 = 0.195498 loss)
I1006 18:26:24.171989  3702 sgd_solver.cpp:105] Iteration 34500, lr = 0.1
I1006 18:26:32.509613  3702 solver.cpp:218] Iteration 34600 (11.9939 iter/s, 8.3376s/100 iters), loss = 0.213249
I1006 18:26:32.509642  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.213249 (* 1 = 0.213249 loss)
I1006 18:26:32.509649  3702 sgd_solver.cpp:105] Iteration 34600, lr = 0.1
I1006 18:26:40.837963  3702 solver.cpp:218] Iteration 34700 (12.0073 iter/s, 8.32829s/100 iters), loss = 0.146047
I1006 18:26:40.838002  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.146046 (* 1 = 0.146046 loss)
I1006 18:26:40.838008  3702 sgd_solver.cpp:105] Iteration 34700, lr = 0.1
I1006 18:26:49.174443  3702 solver.cpp:218] Iteration 34800 (11.9956 iter/s, 8.33642s/100 iters), loss = 0.172601
I1006 18:26:49.174577  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.172601 (* 1 = 0.172601 loss)
I1006 18:26:49.174584  3702 sgd_solver.cpp:105] Iteration 34800, lr = 0.1
I1006 18:26:57.507230  3702 solver.cpp:218] Iteration 34900 (12.001 iter/s, 8.33262s/100 iters), loss = 0.242786
I1006 18:26:57.507258  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.242786 (* 1 = 0.242786 loss)
I1006 18:26:57.507264  3702 sgd_solver.cpp:105] Iteration 34900, lr = 0.1
I1006 18:27:05.434763  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:27:05.768362  3702 solver.cpp:330] Iteration 35000, Testing net (#0)
I1006 18:27:07.696146  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:27:07.777035  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8183
I1006 18:27:07.777060  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.558843 (* 1 = 0.558843 loss)
I1006 18:27:07.859223  3702 solver.cpp:218] Iteration 35000 (9.66003 iter/s, 10.3519s/100 iters), loss = 0.141996
I1006 18:27:07.859248  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.141995 (* 1 = 0.141995 loss)
I1006 18:27:07.859256  3702 sgd_solver.cpp:105] Iteration 35000, lr = 0.1
I1006 18:27:16.185115  3702 solver.cpp:218] Iteration 35100 (12.0108 iter/s, 8.32584s/100 iters), loss = 0.133678
I1006 18:27:16.185154  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.133678 (* 1 = 0.133678 loss)
I1006 18:27:16.185160  3702 sgd_solver.cpp:105] Iteration 35100, lr = 0.1
I1006 18:27:24.519209  3702 solver.cpp:218] Iteration 35200 (11.999 iter/s, 8.33403s/100 iters), loss = 0.193933
I1006 18:27:24.519364  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.193933 (* 1 = 0.193933 loss)
I1006 18:27:24.519387  3702 sgd_solver.cpp:105] Iteration 35200, lr = 0.1
I1006 18:27:32.844888  3702 solver.cpp:218] Iteration 35300 (12.0113 iter/s, 8.3255s/100 iters), loss = 0.149822
I1006 18:27:32.844918  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.149822 (* 1 = 0.149822 loss)
I1006 18:27:32.844933  3702 sgd_solver.cpp:105] Iteration 35300, lr = 0.1
I1006 18:27:41.175043  3702 solver.cpp:218] Iteration 35400 (12.0047 iter/s, 8.3301s/100 iters), loss = 0.182704
I1006 18:27:41.175073  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.182704 (* 1 = 0.182704 loss)
I1006 18:27:41.175079  3702 sgd_solver.cpp:105] Iteration 35400, lr = 0.1
I1006 18:27:49.087683  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:27:49.420951  3702 solver.cpp:330] Iteration 35500, Testing net (#0)
I1006 18:27:51.346890  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:27:51.426869  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7842
I1006 18:27:51.426905  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.694697 (* 1 = 0.694697 loss)
I1006 18:27:51.511284  3702 solver.cpp:218] Iteration 35500 (9.67475 iter/s, 10.3362s/100 iters), loss = 0.085997
I1006 18:27:51.511317  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.085997 (* 1 = 0.085997 loss)
I1006 18:27:51.511324  3702 sgd_solver.cpp:105] Iteration 35500, lr = 0.1
I1006 18:27:59.853063  3702 solver.cpp:218] Iteration 35600 (11.9879 iter/s, 8.34172s/100 iters), loss = 0.175178
I1006 18:27:59.853188  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.175178 (* 1 = 0.175178 loss)
I1006 18:27:59.853194  3702 sgd_solver.cpp:105] Iteration 35600, lr = 0.1
I1006 18:28:08.183418  3702 solver.cpp:218] Iteration 35700 (12.0045 iter/s, 8.3302s/100 iters), loss = 0.380056
I1006 18:28:08.183457  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.380056 (* 1 = 0.380056 loss)
I1006 18:28:08.183462  3702 sgd_solver.cpp:105] Iteration 35700, lr = 0.1
I1006 18:28:16.523442  3702 solver.cpp:218] Iteration 35800 (11.9905 iter/s, 8.33996s/100 iters), loss = 0.234444
I1006 18:28:16.523473  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.234443 (* 1 = 0.234443 loss)
I1006 18:28:16.523478  3702 sgd_solver.cpp:105] Iteration 35800, lr = 0.1
I1006 18:28:24.859994  3702 solver.cpp:218] Iteration 35900 (11.9954 iter/s, 8.3365s/100 iters), loss = 0.165842
I1006 18:28:24.860024  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.165842 (* 1 = 0.165842 loss)
I1006 18:28:24.860030  3702 sgd_solver.cpp:105] Iteration 35900, lr = 0.1
I1006 18:28:32.787045  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:28:33.119504  3702 solver.cpp:330] Iteration 36000, Testing net (#0)
I1006 18:28:35.044539  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:28:35.125166  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8183
I1006 18:28:35.125201  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.554848 (* 1 = 0.554848 loss)
I1006 18:28:35.207520  3702 solver.cpp:218] Iteration 36000 (9.6642 iter/s, 10.3475s/100 iters), loss = 0.151764
I1006 18:28:35.207545  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.151764 (* 1 = 0.151764 loss)
I1006 18:28:35.207551  3702 sgd_solver.cpp:105] Iteration 36000, lr = 0.1
I1006 18:28:43.534211  3702 solver.cpp:218] Iteration 36100 (12.0096 iter/s, 8.32664s/100 iters), loss = 0.284951
I1006 18:28:43.534240  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.284951 (* 1 = 0.284951 loss)
I1006 18:28:43.534245  3702 sgd_solver.cpp:105] Iteration 36100, lr = 0.1
I1006 18:28:51.862311  3702 solver.cpp:218] Iteration 36200 (12.0076 iter/s, 8.32805s/100 iters), loss = 0.225266
I1006 18:28:51.862339  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.225266 (* 1 = 0.225266 loss)
I1006 18:28:51.862344  3702 sgd_solver.cpp:105] Iteration 36200, lr = 0.1
I1006 18:29:00.187584  3702 solver.cpp:218] Iteration 36300 (12.0117 iter/s, 8.32522s/100 iters), loss = 0.238882
I1006 18:29:00.187615  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.238882 (* 1 = 0.238882 loss)
I1006 18:29:00.187621  3702 sgd_solver.cpp:105] Iteration 36300, lr = 0.1
I1006 18:29:08.522918  3702 solver.cpp:218] Iteration 36400 (11.9972 iter/s, 8.33528s/100 iters), loss = 0.0980723
I1006 18:29:08.523075  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0980722 (* 1 = 0.0980722 loss)
I1006 18:29:08.523082  3702 sgd_solver.cpp:105] Iteration 36400, lr = 0.1
I1006 18:29:16.434919  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:29:16.768992  3702 solver.cpp:330] Iteration 36500, Testing net (#0)
I1006 18:29:18.694793  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:29:18.775517  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7953
I1006 18:29:18.775552  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.684763 (* 1 = 0.684763 loss)
I1006 18:29:18.859586  3702 solver.cpp:218] Iteration 36500 (9.67447 iter/s, 10.3365s/100 iters), loss = 0.213032
I1006 18:29:18.859619  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.213032 (* 1 = 0.213032 loss)
I1006 18:29:18.859627  3702 sgd_solver.cpp:105] Iteration 36500, lr = 0.1
I1006 18:29:27.199192  3702 solver.cpp:218] Iteration 36600 (11.9911 iter/s, 8.33955s/100 iters), loss = 0.153321
I1006 18:29:27.199230  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.153321 (* 1 = 0.153321 loss)
I1006 18:29:27.199236  3702 sgd_solver.cpp:105] Iteration 36600, lr = 0.1
I1006 18:29:35.531993  3702 solver.cpp:218] Iteration 36700 (12.0009 iter/s, 8.33274s/100 iters), loss = 0.134532
I1006 18:29:35.532021  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.134532 (* 1 = 0.134532 loss)
I1006 18:29:35.532027  3702 sgd_solver.cpp:105] Iteration 36700, lr = 0.1
I1006 18:29:43.865370  3702 solver.cpp:218] Iteration 36800 (12 iter/s, 8.33332s/100 iters), loss = 0.197628
I1006 18:29:43.865483  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.197628 (* 1 = 0.197628 loss)
I1006 18:29:43.865490  3702 sgd_solver.cpp:105] Iteration 36800, lr = 0.1
I1006 18:29:52.198048  3702 solver.cpp:218] Iteration 36900 (12.0011 iter/s, 8.33255s/100 iters), loss = 0.177322
I1006 18:29:52.198078  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.177322 (* 1 = 0.177322 loss)
I1006 18:29:52.198084  3702 sgd_solver.cpp:105] Iteration 36900, lr = 0.1
I1006 18:30:00.122093  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:30:00.457396  3702 solver.cpp:330] Iteration 37000, Testing net (#0)
I1006 18:30:02.384929  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:30:02.465548  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7762
I1006 18:30:02.465581  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.733121 (* 1 = 0.733121 loss)
I1006 18:30:02.547951  3702 solver.cpp:218] Iteration 37000 (9.66198 iter/s, 10.3498s/100 iters), loss = 0.201239
I1006 18:30:02.547976  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.201239 (* 1 = 0.201239 loss)
I1006 18:30:02.547982  3702 sgd_solver.cpp:105] Iteration 37000, lr = 0.1
I1006 18:30:10.881122  3702 solver.cpp:218] Iteration 37100 (12.0003 iter/s, 8.33312s/100 iters), loss = 0.127336
I1006 18:30:10.881151  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.127336 (* 1 = 0.127336 loss)
I1006 18:30:10.881156  3702 sgd_solver.cpp:105] Iteration 37100, lr = 0.1
I1006 18:30:19.225805  3702 solver.cpp:218] Iteration 37200 (11.9838 iter/s, 8.34463s/100 iters), loss = 0.210792
I1006 18:30:19.225971  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.210792 (* 1 = 0.210792 loss)
I1006 18:30:19.225978  3702 sgd_solver.cpp:105] Iteration 37200, lr = 0.1
I1006 18:30:27.565668  3702 solver.cpp:218] Iteration 37300 (11.9909 iter/s, 8.33967s/100 iters), loss = 0.187373
I1006 18:30:27.565707  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.187373 (* 1 = 0.187373 loss)
I1006 18:30:27.565713  3702 sgd_solver.cpp:105] Iteration 37300, lr = 0.1
I1006 18:30:35.910959  3702 solver.cpp:218] Iteration 37400 (11.9829 iter/s, 8.34523s/100 iters), loss = 0.198971
I1006 18:30:35.910997  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.198971 (* 1 = 0.198971 loss)
I1006 18:30:35.911002  3702 sgd_solver.cpp:105] Iteration 37400, lr = 0.1
I1006 18:30:43.844110  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:30:44.177960  3702 solver.cpp:330] Iteration 37500, Testing net (#0)
I1006 18:30:46.104527  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:30:46.184886  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7791
I1006 18:30:46.184921  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.679389 (* 1 = 0.679389 loss)
I1006 18:30:46.268429  3702 solver.cpp:218] Iteration 37500 (9.65493 iter/s, 10.3574s/100 iters), loss = 0.243315
I1006 18:30:46.268462  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.243315 (* 1 = 0.243315 loss)
I1006 18:30:46.268470  3702 sgd_solver.cpp:105] Iteration 37500, lr = 0.1
I1006 18:30:54.608747  3702 solver.cpp:218] Iteration 37600 (11.99 iter/s, 8.34026s/100 iters), loss = 0.23998
I1006 18:30:54.608850  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.23998 (* 1 = 0.23998 loss)
I1006 18:30:54.608857  3702 sgd_solver.cpp:105] Iteration 37600, lr = 0.1
I1006 18:31:02.945138  3702 solver.cpp:218] Iteration 37700 (11.9958 iter/s, 8.33626s/100 iters), loss = 0.240346
I1006 18:31:02.945178  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.240346 (* 1 = 0.240346 loss)
I1006 18:31:02.945184  3702 sgd_solver.cpp:105] Iteration 37700, lr = 0.1
I1006 18:31:11.286455  3702 solver.cpp:218] Iteration 37800 (11.9886 iter/s, 8.34125s/100 iters), loss = 0.211905
I1006 18:31:11.286496  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.211905 (* 1 = 0.211905 loss)
I1006 18:31:11.286502  3702 sgd_solver.cpp:105] Iteration 37800, lr = 0.1
I1006 18:31:19.622455  3702 solver.cpp:218] Iteration 37900 (11.9963 iter/s, 8.33593s/100 iters), loss = 0.136942
I1006 18:31:19.622494  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.136942 (* 1 = 0.136942 loss)
I1006 18:31:19.622500  3702 sgd_solver.cpp:105] Iteration 37900, lr = 0.1
I1006 18:31:27.551812  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:31:27.886276  3702 solver.cpp:330] Iteration 38000, Testing net (#0)
I1006 18:31:29.812187  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:31:29.893090  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7948
I1006 18:31:29.893123  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.672742 (* 1 = 0.672742 loss)
I1006 18:31:29.975952  3702 solver.cpp:218] Iteration 38000 (9.65864 iter/s, 10.3534s/100 iters), loss = 0.178139
I1006 18:31:29.975976  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.178139 (* 1 = 0.178139 loss)
I1006 18:31:29.975983  3702 sgd_solver.cpp:105] Iteration 38000, lr = 0.1
I1006 18:31:38.308557  3702 solver.cpp:218] Iteration 38100 (12.0011 iter/s, 8.33255s/100 iters), loss = 0.287187
I1006 18:31:38.308585  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.287187 (* 1 = 0.287187 loss)
I1006 18:31:38.308591  3702 sgd_solver.cpp:105] Iteration 38100, lr = 0.1
I1006 18:31:46.643661  3702 solver.cpp:218] Iteration 38200 (11.9975 iter/s, 8.33505s/100 iters), loss = 0.317786
I1006 18:31:46.643690  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.317786 (* 1 = 0.317786 loss)
I1006 18:31:46.643707  3702 sgd_solver.cpp:105] Iteration 38200, lr = 0.1
I1006 18:31:54.981163  3702 solver.cpp:218] Iteration 38300 (11.9941 iter/s, 8.33745s/100 iters), loss = 0.137314
I1006 18:31:54.981194  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.137314 (* 1 = 0.137314 loss)
I1006 18:31:54.981209  3702 sgd_solver.cpp:105] Iteration 38300, lr = 0.1
I1006 18:32:03.320543  3702 solver.cpp:218] Iteration 38400 (11.9914 iter/s, 8.33932s/100 iters), loss = 0.166275
I1006 18:32:03.320721  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.166275 (* 1 = 0.166275 loss)
I1006 18:32:03.320739  3702 sgd_solver.cpp:105] Iteration 38400, lr = 0.1
I1006 18:32:11.241130  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:32:11.574476  3702 solver.cpp:330] Iteration 38500, Testing net (#0)
I1006 18:32:13.500542  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:32:13.580741  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8157
I1006 18:32:13.580775  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.586673 (* 1 = 0.586673 loss)
I1006 18:32:13.664664  3702 solver.cpp:218] Iteration 38500 (9.66752 iter/s, 10.3439s/100 iters), loss = 0.214612
I1006 18:32:13.664692  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.214612 (* 1 = 0.214612 loss)
I1006 18:32:13.664700  3702 sgd_solver.cpp:105] Iteration 38500, lr = 0.1
I1006 18:32:22.008683  3702 solver.cpp:218] Iteration 38600 (11.9847 iter/s, 8.34396s/100 iters), loss = 0.236253
I1006 18:32:22.008719  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.236253 (* 1 = 0.236253 loss)
I1006 18:32:22.008726  3702 sgd_solver.cpp:105] Iteration 38600, lr = 0.1
I1006 18:32:30.340181  3702 solver.cpp:218] Iteration 38700 (12.0027 iter/s, 8.33144s/100 iters), loss = 0.25502
I1006 18:32:30.340210  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.25502 (* 1 = 0.25502 loss)
I1006 18:32:30.340216  3702 sgd_solver.cpp:105] Iteration 38700, lr = 0.1
I1006 18:32:38.681358  3702 solver.cpp:218] Iteration 38800 (11.9888 iter/s, 8.34112s/100 iters), loss = 0.178646
I1006 18:32:38.681479  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.178646 (* 1 = 0.178646 loss)
I1006 18:32:38.681488  3702 sgd_solver.cpp:105] Iteration 38800, lr = 0.1
I1006 18:32:47.017769  3702 solver.cpp:218] Iteration 38900 (11.9958 iter/s, 8.33628s/100 iters), loss = 0.112353
I1006 18:32:47.017801  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.112353 (* 1 = 0.112353 loss)
I1006 18:32:47.017807  3702 sgd_solver.cpp:105] Iteration 38900, lr = 0.1
I1006 18:32:54.947149  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:32:55.280436  3702 solver.cpp:330] Iteration 39000, Testing net (#0)
I1006 18:32:57.206673  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:32:57.287544  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7455
I1006 18:32:57.287569  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.856295 (* 1 = 0.856295 loss)
I1006 18:32:57.370530  3702 solver.cpp:218] Iteration 39000 (9.65932 iter/s, 10.3527s/100 iters), loss = 0.211094
I1006 18:32:57.370556  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.211094 (* 1 = 0.211094 loss)
I1006 18:32:57.370563  3702 sgd_solver.cpp:105] Iteration 39000, lr = 0.1
I1006 18:33:05.698268  3702 solver.cpp:218] Iteration 39100 (12.0081 iter/s, 8.32769s/100 iters), loss = 0.21237
I1006 18:33:05.698307  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.21237 (* 1 = 0.21237 loss)
I1006 18:33:05.698313  3702 sgd_solver.cpp:105] Iteration 39100, lr = 0.1
I1006 18:33:14.029350  3702 solver.cpp:218] Iteration 39200 (12.0033 iter/s, 8.33102s/100 iters), loss = 0.277556
I1006 18:33:14.029482  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.277556 (* 1 = 0.277556 loss)
I1006 18:33:14.029500  3702 sgd_solver.cpp:105] Iteration 39200, lr = 0.1
I1006 18:33:22.358259  3702 solver.cpp:218] Iteration 39300 (12.0066 iter/s, 8.32876s/100 iters), loss = 0.205938
I1006 18:33:22.358289  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.205938 (* 1 = 0.205938 loss)
I1006 18:33:22.358294  3702 sgd_solver.cpp:105] Iteration 39300, lr = 0.1
I1006 18:33:30.689842  3702 solver.cpp:218] Iteration 39400 (12.0026 iter/s, 8.33153s/100 iters), loss = 0.156107
I1006 18:33:30.689882  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.156107 (* 1 = 0.156107 loss)
I1006 18:33:30.689888  3702 sgd_solver.cpp:105] Iteration 39400, lr = 0.1
I1006 18:33:38.601905  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:33:38.935060  3702 solver.cpp:330] Iteration 39500, Testing net (#0)
I1006 18:33:40.861598  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:33:40.942003  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6896
I1006 18:33:40.942036  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.31233 (* 1 = 1.31233 loss)
I1006 18:33:41.025913  3702 solver.cpp:218] Iteration 39500 (9.67492 iter/s, 10.336s/100 iters), loss = 0.242182
I1006 18:33:41.025939  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.242182 (* 1 = 0.242182 loss)
I1006 18:33:41.025946  3702 sgd_solver.cpp:105] Iteration 39500, lr = 0.1
I1006 18:33:49.370450  3702 solver.cpp:218] Iteration 39600 (11.984 iter/s, 8.34448s/100 iters), loss = 0.18383
I1006 18:33:49.370592  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.18383 (* 1 = 0.18383 loss)
I1006 18:33:49.370601  3702 sgd_solver.cpp:105] Iteration 39600, lr = 0.1
I1006 18:33:57.704208  3702 solver.cpp:218] Iteration 39700 (11.9996 iter/s, 8.33359s/100 iters), loss = 0.151193
I1006 18:33:57.704236  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.151193 (* 1 = 0.151193 loss)
I1006 18:33:57.704242  3702 sgd_solver.cpp:105] Iteration 39700, lr = 0.1
I1006 18:34:06.043006  3702 solver.cpp:218] Iteration 39800 (11.9922 iter/s, 8.33874s/100 iters), loss = 0.113757
I1006 18:34:06.043037  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.113757 (* 1 = 0.113757 loss)
I1006 18:34:06.043043  3702 sgd_solver.cpp:105] Iteration 39800, lr = 0.1
I1006 18:34:14.380177  3702 solver.cpp:218] Iteration 39900 (11.9946 iter/s, 8.33711s/100 iters), loss = 0.166372
I1006 18:34:14.380204  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.166372 (* 1 = 0.166372 loss)
I1006 18:34:14.380210  3702 sgd_solver.cpp:105] Iteration 39900, lr = 0.1
I1006 18:34:22.303867  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:34:22.639153  3702 solver.cpp:330] Iteration 40000, Testing net (#0)
I1006 18:34:24.565189  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:34:24.645975  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7776
I1006 18:34:24.646010  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.762316 (* 1 = 0.762316 loss)
I1006 18:34:24.728451  3702 solver.cpp:218] Iteration 40000 (9.6635 iter/s, 10.3482s/100 iters), loss = 0.211168
I1006 18:34:24.728477  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.211168 (* 1 = 0.211168 loss)
I1006 18:34:24.728482  3702 sgd_solver.cpp:46] MultiStep Status: Iteration 40000, step = 1
I1006 18:34:24.728485  3702 sgd_solver.cpp:105] Iteration 40000, lr = 0.01
I1006 18:34:33.066308  3702 solver.cpp:218] Iteration 40100 (11.9936 iter/s, 8.33781s/100 iters), loss = 0.168147
I1006 18:34:33.066339  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.168147 (* 1 = 0.168147 loss)
I1006 18:34:33.066354  3702 sgd_solver.cpp:105] Iteration 40100, lr = 0.01
I1006 18:34:41.406500  3702 solver.cpp:218] Iteration 40200 (11.9902 iter/s, 8.34014s/100 iters), loss = 0.150823
I1006 18:34:41.406530  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.150823 (* 1 = 0.150823 loss)
I1006 18:34:41.406545  3702 sgd_solver.cpp:105] Iteration 40200, lr = 0.01
I1006 18:34:49.745575  3702 solver.cpp:218] Iteration 40300 (11.9918 iter/s, 8.33902s/100 iters), loss = 0.200083
I1006 18:34:49.745604  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.200083 (* 1 = 0.200083 loss)
I1006 18:34:49.745620  3702 sgd_solver.cpp:105] Iteration 40300, lr = 0.01
I1006 18:34:58.088937  3702 solver.cpp:218] Iteration 40400 (11.9857 iter/s, 8.34331s/100 iters), loss = 0.0768623
I1006 18:34:58.089073  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0768623 (* 1 = 0.0768623 loss)
I1006 18:34:58.089092  3702 sgd_solver.cpp:105] Iteration 40400, lr = 0.01
I1006 18:35:06.009037  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:35:06.342501  3702 solver.cpp:330] Iteration 40500, Testing net (#0)
I1006 18:35:08.269142  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:35:08.349611  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9082
I1006 18:35:08.349645  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.272602 (* 1 = 0.272602 loss)
I1006 18:35:08.433197  3702 solver.cpp:218] Iteration 40500 (9.66735 iter/s, 10.3441s/100 iters), loss = 0.0636071
I1006 18:35:08.433223  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0636071 (* 1 = 0.0636071 loss)
I1006 18:35:08.433229  3702 sgd_solver.cpp:105] Iteration 40500, lr = 0.01
I1006 18:35:16.780766  3702 solver.cpp:218] Iteration 40600 (11.9796 iter/s, 8.34752s/100 iters), loss = 0.137108
I1006 18:35:16.780795  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.137108 (* 1 = 0.137108 loss)
I1006 18:35:16.780802  3702 sgd_solver.cpp:105] Iteration 40600, lr = 0.01
I1006 18:35:25.120595  3702 solver.cpp:218] Iteration 40700 (11.9907 iter/s, 8.33977s/100 iters), loss = 0.0955864
I1006 18:35:25.120625  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0955864 (* 1 = 0.0955864 loss)
I1006 18:35:25.120630  3702 sgd_solver.cpp:105] Iteration 40700, lr = 0.01
I1006 18:35:33.469997  3702 solver.cpp:218] Iteration 40800 (11.977 iter/s, 8.34935s/100 iters), loss = 0.098781
I1006 18:35:33.470137  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.098781 (* 1 = 0.098781 loss)
I1006 18:35:33.470145  3702 sgd_solver.cpp:105] Iteration 40800, lr = 0.01
I1006 18:35:41.809454  3702 solver.cpp:218] Iteration 40900 (11.9914 iter/s, 8.3393s/100 iters), loss = 0.0589463
I1006 18:35:41.809484  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0589462 (* 1 = 0.0589462 loss)
I1006 18:35:41.809500  3702 sgd_solver.cpp:105] Iteration 40900, lr = 0.01
I1006 18:35:49.743928  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:35:50.077829  3702 solver.cpp:330] Iteration 41000, Testing net (#0)
I1006 18:35:52.003751  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:35:52.084702  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9134
I1006 18:35:52.084728  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.25458 (* 1 = 0.25458 loss)
I1006 18:35:52.167299  3702 solver.cpp:218] Iteration 41000 (9.65457 iter/s, 10.3578s/100 iters), loss = 0.119819
I1006 18:35:52.167335  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.119819 (* 1 = 0.119819 loss)
I1006 18:35:52.167342  3702 sgd_solver.cpp:105] Iteration 41000, lr = 0.01
I1006 18:36:00.500771  3702 solver.cpp:218] Iteration 41100 (11.9999 iter/s, 8.33341s/100 iters), loss = 0.174968
I1006 18:36:00.500800  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.174968 (* 1 = 0.174968 loss)
I1006 18:36:00.500816  3702 sgd_solver.cpp:105] Iteration 41100, lr = 0.01
I1006 18:36:08.837241  3702 solver.cpp:218] Iteration 41200 (11.9956 iter/s, 8.33642s/100 iters), loss = 0.0774086
I1006 18:36:08.837347  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0774086 (* 1 = 0.0774086 loss)
I1006 18:36:08.837364  3702 sgd_solver.cpp:105] Iteration 41200, lr = 0.01
I1006 18:36:17.171264  3702 solver.cpp:218] Iteration 41300 (11.9992 iter/s, 8.33389s/100 iters), loss = 0.117835
I1006 18:36:17.171293  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.117835 (* 1 = 0.117835 loss)
I1006 18:36:17.171309  3702 sgd_solver.cpp:105] Iteration 41300, lr = 0.01
I1006 18:36:25.511939  3702 solver.cpp:218] Iteration 41400 (11.9895 iter/s, 8.34062s/100 iters), loss = 0.0374039
I1006 18:36:25.511967  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0374039 (* 1 = 0.0374039 loss)
I1006 18:36:25.511983  3702 sgd_solver.cpp:105] Iteration 41400, lr = 0.01
I1006 18:36:33.435695  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:36:33.770022  3702 solver.cpp:330] Iteration 41500, Testing net (#0)
I1006 18:36:35.695926  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:36:35.776257  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9128
I1006 18:36:35.776291  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.263231 (* 1 = 0.263231 loss)
I1006 18:36:35.859892  3702 solver.cpp:218] Iteration 41500 (9.6638 iter/s, 10.3479s/100 iters), loss = 0.0802054
I1006 18:36:35.859920  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0802054 (* 1 = 0.0802054 loss)
I1006 18:36:35.859926  3702 sgd_solver.cpp:105] Iteration 41500, lr = 0.01
I1006 18:36:44.206157  3702 solver.cpp:218] Iteration 41600 (11.9815 iter/s, 8.34622s/100 iters), loss = 0.123603
I1006 18:36:44.206293  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.123603 (* 1 = 0.123603 loss)
I1006 18:36:44.206310  3702 sgd_solver.cpp:105] Iteration 41600, lr = 0.01
I1006 18:36:52.546720  3702 solver.cpp:218] Iteration 41700 (11.9898 iter/s, 8.3404s/100 iters), loss = 0.0650395
I1006 18:36:52.546751  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0650396 (* 1 = 0.0650396 loss)
I1006 18:36:52.546766  3702 sgd_solver.cpp:105] Iteration 41700, lr = 0.01
I1006 18:37:00.898725  3702 solver.cpp:218] Iteration 41800 (11.9733 iter/s, 8.35195s/100 iters), loss = 0.0807246
I1006 18:37:00.898754  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0807247 (* 1 = 0.0807247 loss)
I1006 18:37:00.898771  3702 sgd_solver.cpp:105] Iteration 41800, lr = 0.01
I1006 18:37:09.239799  3702 solver.cpp:218] Iteration 41900 (11.9889 iter/s, 8.34102s/100 iters), loss = 0.0686634
I1006 18:37:09.239830  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0686635 (* 1 = 0.0686635 loss)
I1006 18:37:09.239845  3702 sgd_solver.cpp:105] Iteration 41900, lr = 0.01
I1006 18:37:17.177037  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:37:17.510635  3702 solver.cpp:330] Iteration 42000, Testing net (#0)
I1006 18:37:19.437568  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:37:19.518570  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.914
I1006 18:37:19.518605  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.260069 (* 1 = 0.260069 loss)
I1006 18:37:19.600445  3702 solver.cpp:218] Iteration 42000 (9.65196 iter/s, 10.3606s/100 iters), loss = 0.10428
I1006 18:37:19.600468  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.10428 (* 1 = 0.10428 loss)
I1006 18:37:19.600476  3702 sgd_solver.cpp:105] Iteration 42000, lr = 0.01
I1006 18:37:27.934283  3702 solver.cpp:218] Iteration 42100 (11.9994 iter/s, 8.33378s/100 iters), loss = 0.0387915
I1006 18:37:27.934324  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0387916 (* 1 = 0.0387916 loss)
I1006 18:37:27.934330  3702 sgd_solver.cpp:105] Iteration 42100, lr = 0.01
I1006 18:37:36.270174  3702 solver.cpp:218] Iteration 42200 (11.9964 iter/s, 8.33583s/100 iters), loss = 0.0822719
I1006 18:37:36.270211  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.082272 (* 1 = 0.082272 loss)
I1006 18:37:36.270217  3702 sgd_solver.cpp:105] Iteration 42200, lr = 0.01
I1006 18:37:44.606408  3702 solver.cpp:218] Iteration 42300 (11.9959 iter/s, 8.33617s/100 iters), loss = 0.0387271
I1006 18:37:44.606447  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0387272 (* 1 = 0.0387272 loss)
I1006 18:37:44.606453  3702 sgd_solver.cpp:105] Iteration 42300, lr = 0.01
I1006 18:37:52.943806  3702 solver.cpp:218] Iteration 42400 (11.9942 iter/s, 8.33733s/100 iters), loss = 0.0351497
I1006 18:37:52.943920  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0351498 (* 1 = 0.0351498 loss)
I1006 18:37:52.943928  3702 sgd_solver.cpp:105] Iteration 42400, lr = 0.01
I1006 18:38:00.863791  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:38:01.197702  3702 solver.cpp:330] Iteration 42500, Testing net (#0)
I1006 18:38:03.124686  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:38:03.205276  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9184
I1006 18:38:03.205312  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.253108 (* 1 = 0.253108 loss)
I1006 18:38:03.289018  3702 solver.cpp:218] Iteration 42500 (9.66644 iter/s, 10.3451s/100 iters), loss = 0.117688
I1006 18:38:03.289050  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.117688 (* 1 = 0.117688 loss)
I1006 18:38:03.289057  3702 sgd_solver.cpp:105] Iteration 42500, lr = 0.01
I1006 18:38:11.636127  3702 solver.cpp:218] Iteration 42600 (11.9803 iter/s, 8.34705s/100 iters), loss = 0.0489187
I1006 18:38:11.636168  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0489188 (* 1 = 0.0489188 loss)
I1006 18:38:11.636173  3702 sgd_solver.cpp:105] Iteration 42600, lr = 0.01
I1006 18:38:19.974864  3702 solver.cpp:218] Iteration 42700 (11.9923 iter/s, 8.33867s/100 iters), loss = 0.0825918
I1006 18:38:19.974905  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0825919 (* 1 = 0.0825919 loss)
I1006 18:38:19.974910  3702 sgd_solver.cpp:105] Iteration 42700, lr = 0.01
I1006 18:38:28.317037  3702 solver.cpp:218] Iteration 42800 (11.9874 iter/s, 8.34211s/100 iters), loss = 0.0663624
I1006 18:38:28.317158  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0663625 (* 1 = 0.0663625 loss)
I1006 18:38:28.317175  3702 sgd_solver.cpp:105] Iteration 42800, lr = 0.01
I1006 18:38:36.657649  3702 solver.cpp:218] Iteration 42900 (11.9897 iter/s, 8.34047s/100 iters), loss = 0.0577273
I1006 18:38:36.657688  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0577274 (* 1 = 0.0577274 loss)
I1006 18:38:36.657694  3702 sgd_solver.cpp:105] Iteration 42900, lr = 0.01
I1006 18:38:44.588177  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:38:44.923280  3702 solver.cpp:330] Iteration 43000, Testing net (#0)
I1006 18:38:46.850131  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:38:46.931047  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9154
I1006 18:38:46.931082  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.253589 (* 1 = 0.253589 loss)
I1006 18:38:47.014283  3702 solver.cpp:218] Iteration 43000 (9.65571 iter/s, 10.3566s/100 iters), loss = 0.0670699
I1006 18:38:47.014320  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.06707 (* 1 = 0.06707 loss)
I1006 18:38:47.014327  3702 sgd_solver.cpp:105] Iteration 43000, lr = 0.01
I1006 18:38:55.346611  3702 solver.cpp:218] Iteration 43100 (12.0015 iter/s, 8.33227s/100 iters), loss = 0.0544332
I1006 18:38:55.346652  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0544332 (* 1 = 0.0544332 loss)
I1006 18:38:55.346657  3702 sgd_solver.cpp:105] Iteration 43100, lr = 0.01
I1006 18:39:03.692355  3702 solver.cpp:218] Iteration 43200 (11.9822 iter/s, 8.34568s/100 iters), loss = 0.0370464
I1006 18:39:03.692492  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0370464 (* 1 = 0.0370464 loss)
I1006 18:39:03.692498  3702 sgd_solver.cpp:105] Iteration 43200, lr = 0.01
I1006 18:39:12.027951  3702 solver.cpp:218] Iteration 43300 (11.997 iter/s, 8.33545s/100 iters), loss = 0.0831444
I1006 18:39:12.027992  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0831445 (* 1 = 0.0831445 loss)
I1006 18:39:12.027997  3702 sgd_solver.cpp:105] Iteration 43300, lr = 0.01
I1006 18:39:20.366381  3702 solver.cpp:218] Iteration 43400 (11.9928 iter/s, 8.33837s/100 iters), loss = 0.0262118
I1006 18:39:20.366420  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0262119 (* 1 = 0.0262119 loss)
I1006 18:39:20.366426  3702 sgd_solver.cpp:105] Iteration 43400, lr = 0.01
I1006 18:39:28.283776  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:39:28.616870  3702 solver.cpp:330] Iteration 43500, Testing net (#0)
I1006 18:39:30.543982  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:39:30.624671  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.916
I1006 18:39:30.624706  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.258764 (* 1 = 0.258764 loss)
I1006 18:39:30.708284  3702 solver.cpp:218] Iteration 43500 (9.66947 iter/s, 10.3418s/100 iters), loss = 0.0528764
I1006 18:39:30.708312  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0528765 (* 1 = 0.0528765 loss)
I1006 18:39:30.708317  3702 sgd_solver.cpp:105] Iteration 43500, lr = 0.01
I1006 18:39:39.055745  3702 solver.cpp:218] Iteration 43600 (11.9798 iter/s, 8.34741s/100 iters), loss = 0.0848375
I1006 18:39:39.055902  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0848375 (* 1 = 0.0848375 loss)
I1006 18:39:39.055908  3702 sgd_solver.cpp:105] Iteration 43600, lr = 0.01
I1006 18:39:47.390651  3702 solver.cpp:218] Iteration 43700 (11.998 iter/s, 8.33473s/100 iters), loss = 0.0465237
I1006 18:39:47.390691  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0465238 (* 1 = 0.0465238 loss)
I1006 18:39:47.390697  3702 sgd_solver.cpp:105] Iteration 43700, lr = 0.01
I1006 18:39:55.736770  3702 solver.cpp:218] Iteration 43800 (11.9817 iter/s, 8.34606s/100 iters), loss = 0.0385619
I1006 18:39:55.736809  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0385619 (* 1 = 0.0385619 loss)
I1006 18:39:55.736815  3702 sgd_solver.cpp:105] Iteration 43800, lr = 0.01
I1006 18:40:04.075337  3702 solver.cpp:218] Iteration 43900 (11.9926 iter/s, 8.3385s/100 iters), loss = 0.0166714
I1006 18:40:04.075378  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0166715 (* 1 = 0.0166715 loss)
I1006 18:40:04.075386  3702 sgd_solver.cpp:105] Iteration 43900, lr = 0.01
I1006 18:40:12.005621  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:40:12.340409  3702 solver.cpp:330] Iteration 44000, Testing net (#0)
I1006 18:40:14.269299  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:40:14.350075  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9164
I1006 18:40:14.350108  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.267723 (* 1 = 0.267723 loss)
I1006 18:40:14.432654  3702 solver.cpp:218] Iteration 44000 (9.65508 iter/s, 10.3572s/100 iters), loss = 0.0279123
I1006 18:40:14.432680  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0279124 (* 1 = 0.0279124 loss)
I1006 18:40:14.432687  3702 sgd_solver.cpp:105] Iteration 44000, lr = 0.01
I1006 18:40:22.774590  3702 solver.cpp:218] Iteration 44100 (11.9877 iter/s, 8.34189s/100 iters), loss = 0.086005
I1006 18:40:22.774631  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0860051 (* 1 = 0.0860051 loss)
I1006 18:40:22.774636  3702 sgd_solver.cpp:105] Iteration 44100, lr = 0.01
I1006 18:40:31.120658  3702 solver.cpp:218] Iteration 44200 (11.9818 iter/s, 8.346s/100 iters), loss = 0.0438308
I1006 18:40:31.120698  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0438308 (* 1 = 0.0438308 loss)
I1006 18:40:31.120703  3702 sgd_solver.cpp:105] Iteration 44200, lr = 0.01
I1006 18:40:39.464624  3702 solver.cpp:218] Iteration 44300 (11.9848 iter/s, 8.3439s/100 iters), loss = 0.0251183
I1006 18:40:39.464664  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0251183 (* 1 = 0.0251183 loss)
I1006 18:40:39.464669  3702 sgd_solver.cpp:105] Iteration 44300, lr = 0.01
I1006 18:40:47.805879  3702 solver.cpp:218] Iteration 44400 (11.9887 iter/s, 8.34119s/100 iters), loss = 0.0149987
I1006 18:40:47.805986  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0149987 (* 1 = 0.0149987 loss)
I1006 18:40:47.805994  3702 sgd_solver.cpp:105] Iteration 44400, lr = 0.01
I1006 18:40:55.734000  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:40:56.067935  3702 solver.cpp:330] Iteration 44500, Testing net (#0)
I1006 18:40:57.994101  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:40:58.074599  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9146
I1006 18:40:58.074635  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.27267 (* 1 = 0.27267 loss)
I1006 18:40:58.157771  3702 solver.cpp:218] Iteration 44500 (9.6602 iter/s, 10.3518s/100 iters), loss = 0.0265685
I1006 18:40:58.157797  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0265686 (* 1 = 0.0265686 loss)
I1006 18:40:58.157804  3702 sgd_solver.cpp:105] Iteration 44500, lr = 0.01
I1006 18:41:06.497845  3702 solver.cpp:218] Iteration 44600 (11.9904 iter/s, 8.34002s/100 iters), loss = 0.0413662
I1006 18:41:06.497885  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0413662 (* 1 = 0.0413662 loss)
I1006 18:41:06.497891  3702 sgd_solver.cpp:105] Iteration 44600, lr = 0.01
I1006 18:41:14.834873  3702 solver.cpp:218] Iteration 44700 (11.9948 iter/s, 8.33696s/100 iters), loss = 0.0428282
I1006 18:41:14.834914  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0428282 (* 1 = 0.0428282 loss)
I1006 18:41:14.834919  3702 sgd_solver.cpp:105] Iteration 44700, lr = 0.01
I1006 18:41:23.176234  3702 solver.cpp:218] Iteration 44800 (11.9885 iter/s, 8.3413s/100 iters), loss = 0.0298822
I1006 18:41:23.176383  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0298822 (* 1 = 0.0298822 loss)
I1006 18:41:23.176389  3702 sgd_solver.cpp:105] Iteration 44800, lr = 0.01
I1006 18:41:31.515282  3702 solver.cpp:218] Iteration 44900 (11.992 iter/s, 8.33888s/100 iters), loss = 0.0517721
I1006 18:41:31.515322  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0517721 (* 1 = 0.0517721 loss)
I1006 18:41:31.515327  3702 sgd_solver.cpp:105] Iteration 44900, lr = 0.01
I1006 18:41:39.443543  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:41:39.777395  3702 solver.cpp:330] Iteration 45000, Testing net (#0)
I1006 18:41:41.703893  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:41:41.784777  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9168
I1006 18:41:41.784802  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.266309 (* 1 = 0.266309 loss)
I1006 18:41:41.867245  3702 solver.cpp:218] Iteration 45000 (9.66007 iter/s, 10.3519s/100 iters), loss = 0.073516
I1006 18:41:41.867274  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.073516 (* 1 = 0.073516 loss)
I1006 18:41:41.867280  3702 sgd_solver.cpp:105] Iteration 45000, lr = 0.01
I1006 18:41:50.194193  3702 solver.cpp:218] Iteration 45100 (12.0093 iter/s, 8.3269s/100 iters), loss = 0.047905
I1006 18:41:50.194233  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0479051 (* 1 = 0.0479051 loss)
I1006 18:41:50.194239  3702 sgd_solver.cpp:105] Iteration 45100, lr = 0.01
I1006 18:41:58.536273  3702 solver.cpp:218] Iteration 45200 (11.9875 iter/s, 8.34202s/100 iters), loss = 0.0142006
I1006 18:41:58.536420  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0142006 (* 1 = 0.0142006 loss)
I1006 18:41:58.536428  3702 sgd_solver.cpp:105] Iteration 45200, lr = 0.01
I1006 18:42:06.872738  3702 solver.cpp:218] Iteration 45300 (11.9957 iter/s, 8.33631s/100 iters), loss = 0.0169275
I1006 18:42:06.872779  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0169275 (* 1 = 0.0169275 loss)
I1006 18:42:06.872786  3702 sgd_solver.cpp:105] Iteration 45300, lr = 0.01
I1006 18:42:15.210356  3702 solver.cpp:218] Iteration 45400 (11.9939 iter/s, 8.33755s/100 iters), loss = 0.0383295
I1006 18:42:15.210386  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0383296 (* 1 = 0.0383296 loss)
I1006 18:42:15.210391  3702 sgd_solver.cpp:105] Iteration 45400, lr = 0.01
I1006 18:42:23.131961  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:42:23.466085  3702 solver.cpp:330] Iteration 45500, Testing net (#0)
I1006 18:42:25.394253  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:42:25.474802  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9146
I1006 18:42:25.474835  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.285149 (* 1 = 0.285149 loss)
I1006 18:42:25.558760  3702 solver.cpp:218] Iteration 45500 (9.66338 iter/s, 10.3483s/100 iters), loss = 0.0416135
I1006 18:42:25.558786  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0416135 (* 1 = 0.0416135 loss)
I1006 18:42:25.558792  3702 sgd_solver.cpp:105] Iteration 45500, lr = 0.01
I1006 18:42:33.899595  3702 solver.cpp:218] Iteration 45600 (11.9893 iter/s, 8.34078s/100 iters), loss = 0.0254945
I1006 18:42:33.899710  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0254945 (* 1 = 0.0254945 loss)
I1006 18:42:33.899725  3702 sgd_solver.cpp:105] Iteration 45600, lr = 0.01
I1006 18:42:42.232776  3702 solver.cpp:218] Iteration 45700 (12.0004 iter/s, 8.33305s/100 iters), loss = 0.0304321
I1006 18:42:42.232806  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0304322 (* 1 = 0.0304322 loss)
I1006 18:42:42.232812  3702 sgd_solver.cpp:105] Iteration 45700, lr = 0.01
I1006 18:42:50.577720  3702 solver.cpp:218] Iteration 45800 (11.9834 iter/s, 8.34489s/100 iters), loss = 0.0514547
I1006 18:42:50.577759  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0514547 (* 1 = 0.0514547 loss)
I1006 18:42:50.577765  3702 sgd_solver.cpp:105] Iteration 45800, lr = 0.01
I1006 18:42:58.922528  3702 solver.cpp:218] Iteration 45900 (11.9836 iter/s, 8.34474s/100 iters), loss = 0.0126505
I1006 18:42:58.922556  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0126505 (* 1 = 0.0126505 loss)
I1006 18:42:58.922562  3702 sgd_solver.cpp:105] Iteration 45900, lr = 0.01
I1006 18:43:06.853495  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:43:07.188599  3702 solver.cpp:330] Iteration 46000, Testing net (#0)
I1006 18:43:09.115696  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:43:09.197126  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9173
I1006 18:43:09.197161  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.268561 (* 1 = 0.268561 loss)
I1006 18:43:09.279669  3702 solver.cpp:218] Iteration 46000 (9.65523 iter/s, 10.3571s/100 iters), loss = 0.082321
I1006 18:43:09.279700  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.082321 (* 1 = 0.082321 loss)
I1006 18:43:09.279706  3702 sgd_solver.cpp:105] Iteration 46000, lr = 0.01
I1006 18:43:17.612010  3702 solver.cpp:218] Iteration 46100 (12.0015 iter/s, 8.33229s/100 iters), loss = 0.0142893
I1006 18:43:17.612040  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0142893 (* 1 = 0.0142893 loss)
I1006 18:43:17.612046  3702 sgd_solver.cpp:105] Iteration 46100, lr = 0.01
I1006 18:43:25.956804  3702 solver.cpp:218] Iteration 46200 (11.9836 iter/s, 8.34474s/100 iters), loss = 0.0257995
I1006 18:43:25.956832  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0257995 (* 1 = 0.0257995 loss)
I1006 18:43:25.956838  3702 sgd_solver.cpp:105] Iteration 46200, lr = 0.01
I1006 18:43:34.295024  3702 solver.cpp:218] Iteration 46300 (11.993 iter/s, 8.33817s/100 iters), loss = 0.0503679
I1006 18:43:34.295064  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0503679 (* 1 = 0.0503679 loss)
I1006 18:43:34.295069  3702 sgd_solver.cpp:105] Iteration 46300, lr = 0.01
I1006 18:43:42.637593  3702 solver.cpp:218] Iteration 46400 (11.9868 iter/s, 8.3425s/100 iters), loss = 0.0198362
I1006 18:43:42.637748  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0198363 (* 1 = 0.0198363 loss)
I1006 18:43:42.637766  3702 sgd_solver.cpp:105] Iteration 46400, lr = 0.01
I1006 18:43:50.561468  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:43:50.895334  3702 solver.cpp:330] Iteration 46500, Testing net (#0)
I1006 18:43:52.821367  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:43:52.901715  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9165
I1006 18:43:52.901749  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.288811 (* 1 = 0.288811 loss)
I1006 18:43:52.984938  3702 solver.cpp:218] Iteration 46500 (9.66448 iter/s, 10.3472s/100 iters), loss = 0.0113589
I1006 18:43:52.984966  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0113589 (* 1 = 0.0113589 loss)
I1006 18:43:52.984972  3702 sgd_solver.cpp:105] Iteration 46500, lr = 0.01
I1006 18:44:01.331130  3702 solver.cpp:218] Iteration 46600 (11.9816 iter/s, 8.34614s/100 iters), loss = 0.0236199
I1006 18:44:01.331158  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0236199 (* 1 = 0.0236199 loss)
I1006 18:44:01.331166  3702 sgd_solver.cpp:105] Iteration 46600, lr = 0.01
I1006 18:44:09.668632  3702 solver.cpp:218] Iteration 46700 (11.9941 iter/s, 8.33745s/100 iters), loss = 0.0213258
I1006 18:44:09.668671  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0213258 (* 1 = 0.0213258 loss)
I1006 18:44:09.668676  3702 sgd_solver.cpp:105] Iteration 46700, lr = 0.01
I1006 18:44:18.009150  3702 solver.cpp:218] Iteration 46800 (11.9898 iter/s, 8.34045s/100 iters), loss = 0.0703763
I1006 18:44:18.009259  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0703763 (* 1 = 0.0703763 loss)
I1006 18:44:18.009266  3702 sgd_solver.cpp:105] Iteration 46800, lr = 0.01
I1006 18:44:26.353103  3702 solver.cpp:218] Iteration 46900 (11.9849 iter/s, 8.34383s/100 iters), loss = 0.0231134
I1006 18:44:26.353142  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0231134 (* 1 = 0.0231134 loss)
I1006 18:44:26.353148  3702 sgd_solver.cpp:105] Iteration 46900, lr = 0.01
I1006 18:44:34.288950  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:44:34.623767  3702 solver.cpp:330] Iteration 47000, Testing net (#0)
I1006 18:44:36.552031  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:44:36.632859  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9163
I1006 18:44:36.632892  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.286332 (* 1 = 0.286332 loss)
I1006 18:44:36.715517  3702 solver.cpp:218] Iteration 47000 (9.65032 iter/s, 10.3623s/100 iters), loss = 0.0196971
I1006 18:44:36.715544  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0196971 (* 1 = 0.0196971 loss)
I1006 18:44:36.715550  3702 sgd_solver.cpp:105] Iteration 47000, lr = 0.01
I1006 18:44:45.054682  3702 solver.cpp:218] Iteration 47100 (11.9917 iter/s, 8.33911s/100 iters), loss = 0.031955
I1006 18:44:45.054721  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.031955 (* 1 = 0.031955 loss)
I1006 18:44:45.054728  3702 sgd_solver.cpp:105] Iteration 47100, lr = 0.01
I1006 18:44:53.395661  3702 solver.cpp:218] Iteration 47200 (11.9891 iter/s, 8.34092s/100 iters), loss = 0.0217687
I1006 18:44:53.395771  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0217687 (* 1 = 0.0217687 loss)
I1006 18:44:53.395788  3702 sgd_solver.cpp:105] Iteration 47200, lr = 0.01
I1006 18:45:01.727922  3702 solver.cpp:218] Iteration 47300 (12.0017 iter/s, 8.33214s/100 iters), loss = 0.0555872
I1006 18:45:01.727962  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0555872 (* 1 = 0.0555872 loss)
I1006 18:45:01.727967  3702 sgd_solver.cpp:105] Iteration 47300, lr = 0.01
I1006 18:45:10.061000  3702 solver.cpp:218] Iteration 47400 (12.0005 iter/s, 8.33301s/100 iters), loss = 0.00943819
I1006 18:45:10.061030  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00943818 (* 1 = 0.00943818 loss)
I1006 18:45:10.061035  3702 sgd_solver.cpp:105] Iteration 47400, lr = 0.01
I1006 18:45:17.977475  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:45:18.310886  3702 solver.cpp:330] Iteration 47500, Testing net (#0)
I1006 18:45:20.237095  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:45:20.317582  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9172
I1006 18:45:20.317617  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.284121 (* 1 = 0.284121 loss)
I1006 18:45:20.401310  3702 solver.cpp:218] Iteration 47500 (9.67095 iter/s, 10.3403s/100 iters), loss = 0.0233048
I1006 18:45:20.401335  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0233048 (* 1 = 0.0233048 loss)
I1006 18:45:20.401341  3702 sgd_solver.cpp:105] Iteration 47500, lr = 0.01
I1006 18:45:28.743506  3702 solver.cpp:218] Iteration 47600 (11.9873 iter/s, 8.34214s/100 iters), loss = 0.0340164
I1006 18:45:28.743643  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0340164 (* 1 = 0.0340164 loss)
I1006 18:45:28.743661  3702 sgd_solver.cpp:105] Iteration 47600, lr = 0.01
I1006 18:45:37.078282  3702 solver.cpp:218] Iteration 47700 (11.9981 iter/s, 8.33463s/100 iters), loss = 0.00844016
I1006 18:45:37.078323  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00844016 (* 1 = 0.00844016 loss)
I1006 18:45:37.078330  3702 sgd_solver.cpp:105] Iteration 47700, lr = 0.01
I1006 18:45:45.425487  3702 solver.cpp:218] Iteration 47800 (11.9802 iter/s, 8.34714s/100 iters), loss = 0.0232055
I1006 18:45:45.425526  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0232056 (* 1 = 0.0232056 loss)
I1006 18:45:45.425532  3702 sgd_solver.cpp:105] Iteration 47800, lr = 0.01
I1006 18:45:53.765424  3702 solver.cpp:218] Iteration 47900 (11.9906 iter/s, 8.33987s/100 iters), loss = 0.0182276
I1006 18:45:53.765453  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0182276 (* 1 = 0.0182276 loss)
I1006 18:45:53.765470  3702 sgd_solver.cpp:105] Iteration 47900, lr = 0.01
I1006 18:46:01.696655  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:46:02.030489  3702 solver.cpp:330] Iteration 48000, Testing net (#0)
I1006 18:46:03.955786  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:46:04.036568  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9167
I1006 18:46:04.036593  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.288592 (* 1 = 0.288592 loss)
I1006 18:46:04.118751  3702 solver.cpp:218] Iteration 48000 (9.65879 iter/s, 10.3533s/100 iters), loss = 0.0580892
I1006 18:46:04.118791  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0580892 (* 1 = 0.0580892 loss)
I1006 18:46:04.118798  3702 sgd_solver.cpp:105] Iteration 48000, lr = 0.01
I1006 18:46:12.456017  3702 solver.cpp:218] Iteration 48100 (11.9944 iter/s, 8.3372s/100 iters), loss = 0.0358172
I1006 18:46:12.456045  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0358172 (* 1 = 0.0358172 loss)
I1006 18:46:12.456051  3702 sgd_solver.cpp:105] Iteration 48100, lr = 0.01
I1006 18:46:20.799257  3702 solver.cpp:218] Iteration 48200 (11.9858 iter/s, 8.34319s/100 iters), loss = 0.0131551
I1006 18:46:20.799295  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0131551 (* 1 = 0.0131551 loss)
I1006 18:46:20.799301  3702 sgd_solver.cpp:105] Iteration 48200, lr = 0.01
I1006 18:46:29.141888  3702 solver.cpp:218] Iteration 48300 (11.9867 iter/s, 8.34257s/100 iters), loss = 0.00950157
I1006 18:46:29.141919  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00950158 (* 1 = 0.00950158 loss)
I1006 18:46:29.141924  3702 sgd_solver.cpp:105] Iteration 48300, lr = 0.01
I1006 18:46:37.490212  3702 solver.cpp:218] Iteration 48400 (11.9785 iter/s, 8.34827s/100 iters), loss = 0.0110342
I1006 18:46:37.490309  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0110343 (* 1 = 0.0110343 loss)
I1006 18:46:37.490317  3702 sgd_solver.cpp:105] Iteration 48400, lr = 0.01
I1006 18:46:45.416023  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:46:45.750241  3702 solver.cpp:330] Iteration 48500, Testing net (#0)
I1006 18:46:47.676019  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:46:47.756548  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9164
I1006 18:46:47.756583  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.287492 (* 1 = 0.287492 loss)
I1006 18:46:47.839949  3702 solver.cpp:218] Iteration 48500 (9.6622 iter/s, 10.3496s/100 iters), loss = 0.027099
I1006 18:46:47.839977  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.027099 (* 1 = 0.027099 loss)
I1006 18:46:47.839984  3702 sgd_solver.cpp:105] Iteration 48500, lr = 0.01
I1006 18:46:56.176188  3702 solver.cpp:218] Iteration 48600 (11.9959 iter/s, 8.33619s/100 iters), loss = 0.0114991
I1006 18:46:56.176218  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0114991 (* 1 = 0.0114991 loss)
I1006 18:46:56.176224  3702 sgd_solver.cpp:105] Iteration 48600, lr = 0.01
I1006 18:47:04.504889  3702 solver.cpp:218] Iteration 48700 (12.0068 iter/s, 8.32864s/100 iters), loss = 0.0420984
I1006 18:47:04.504918  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0420984 (* 1 = 0.0420984 loss)
I1006 18:47:04.504935  3702 sgd_solver.cpp:105] Iteration 48700, lr = 0.01
I1006 18:47:12.835023  3702 solver.cpp:218] Iteration 48800 (12.0047 iter/s, 8.33008s/100 iters), loss = 0.0440234
I1006 18:47:12.835093  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0440234 (* 1 = 0.0440234 loss)
I1006 18:47:12.835099  3702 sgd_solver.cpp:105] Iteration 48800, lr = 0.01
I1006 18:47:21.164115  3702 solver.cpp:218] Iteration 48900 (12.0062 iter/s, 8.329s/100 iters), loss = 0.012122
I1006 18:47:21.164144  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.012122 (* 1 = 0.012122 loss)
I1006 18:47:21.164150  3702 sgd_solver.cpp:105] Iteration 48900, lr = 0.01
I1006 18:47:29.084884  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:47:29.418045  3702 solver.cpp:330] Iteration 49000, Testing net (#0)
I1006 18:47:31.344374  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:47:31.425580  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9166
I1006 18:47:31.425616  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.284974 (* 1 = 0.284974 loss)
I1006 18:47:31.508500  3702 solver.cpp:218] Iteration 49000 (9.66714 iter/s, 10.3443s/100 iters), loss = 0.0139999
I1006 18:47:31.508527  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0139999 (* 1 = 0.0139999 loss)
I1006 18:47:31.508533  3702 sgd_solver.cpp:105] Iteration 49000, lr = 0.01
I1006 18:47:39.835053  3702 solver.cpp:218] Iteration 49100 (12.0098 iter/s, 8.3265s/100 iters), loss = 0.0145636
I1006 18:47:39.835081  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0145636 (* 1 = 0.0145636 loss)
I1006 18:47:39.835088  3702 sgd_solver.cpp:105] Iteration 49100, lr = 0.01
I1006 18:47:48.165863  3702 solver.cpp:218] Iteration 49200 (12.0037 iter/s, 8.33075s/100 iters), loss = 0.0355755
I1006 18:47:48.165999  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0355755 (* 1 = 0.0355755 loss)
I1006 18:47:48.166007  3702 sgd_solver.cpp:105] Iteration 49200, lr = 0.01
I1006 18:47:56.497625  3702 solver.cpp:218] Iteration 49300 (12.0025 iter/s, 8.33161s/100 iters), loss = 0.0148022
I1006 18:47:56.497654  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0148022 (* 1 = 0.0148022 loss)
I1006 18:47:56.497670  3702 sgd_solver.cpp:105] Iteration 49300, lr = 0.01
I1006 18:48:04.839121  3702 solver.cpp:218] Iteration 49400 (11.9883 iter/s, 8.34144s/100 iters), loss = 0.043533
I1006 18:48:04.839148  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.043533 (* 1 = 0.043533 loss)
I1006 18:48:04.839154  3702 sgd_solver.cpp:105] Iteration 49400, lr = 0.01
I1006 18:48:12.761042  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:48:13.094236  3702 solver.cpp:330] Iteration 49500, Testing net (#0)
I1006 18:48:15.021674  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:48:15.102092  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9174
I1006 18:48:15.102126  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.287913 (* 1 = 0.287913 loss)
I1006 18:48:15.186024  3702 solver.cpp:218] Iteration 49500 (9.66478 iter/s, 10.3468s/100 iters), loss = 0.047824
I1006 18:48:15.186049  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.047824 (* 1 = 0.047824 loss)
I1006 18:48:15.186056  3702 sgd_solver.cpp:105] Iteration 49500, lr = 0.01
I1006 18:48:23.535840  3702 solver.cpp:218] Iteration 49600 (11.9764 iter/s, 8.34977s/100 iters), loss = 0.0263948
I1006 18:48:23.535967  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0263948 (* 1 = 0.0263948 loss)
I1006 18:48:23.535974  3702 sgd_solver.cpp:105] Iteration 49600, lr = 0.01
I1006 18:48:31.882428  3702 solver.cpp:218] Iteration 49700 (11.9812 iter/s, 8.34644s/100 iters), loss = 0.0278256
I1006 18:48:31.882469  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0278255 (* 1 = 0.0278255 loss)
I1006 18:48:31.882475  3702 sgd_solver.cpp:105] Iteration 49700, lr = 0.01
I1006 18:48:40.232396  3702 solver.cpp:218] Iteration 49800 (11.9762 iter/s, 8.3499s/100 iters), loss = 0.0488418
I1006 18:48:40.232426  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0488418 (* 1 = 0.0488418 loss)
I1006 18:48:40.232432  3702 sgd_solver.cpp:105] Iteration 49800, lr = 0.01
I1006 18:48:48.575567  3702 solver.cpp:218] Iteration 49900 (11.9859 iter/s, 8.34311s/100 iters), loss = 0.0114917
I1006 18:48:48.575595  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0114917 (* 1 = 0.0114917 loss)
I1006 18:48:48.575601  3702 sgd_solver.cpp:105] Iteration 49900, lr = 0.01
I1006 18:48:56.513635  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:48:56.848426  3702 solver.cpp:330] Iteration 50000, Testing net (#0)
I1006 18:48:58.775511  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:48:58.856019  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9207
I1006 18:48:58.856055  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.278461 (* 1 = 0.278461 loss)
I1006 18:48:58.939632  3702 solver.cpp:218] Iteration 50000 (9.64878 iter/s, 10.364s/100 iters), loss = 0.0303991
I1006 18:48:58.939661  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0303991 (* 1 = 0.0303991 loss)
I1006 18:48:58.939666  3702 sgd_solver.cpp:105] Iteration 50000, lr = 0.01
I1006 18:49:07.278561  3702 solver.cpp:218] Iteration 50100 (11.992 iter/s, 8.33887s/100 iters), loss = 0.0299786
I1006 18:49:07.278590  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0299786 (* 1 = 0.0299786 loss)
I1006 18:49:07.278596  3702 sgd_solver.cpp:105] Iteration 50100, lr = 0.01
I1006 18:49:15.617923  3702 solver.cpp:218] Iteration 50200 (11.9914 iter/s, 8.3393s/100 iters), loss = 0.0236055
I1006 18:49:15.617960  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0236055 (* 1 = 0.0236055 loss)
I1006 18:49:15.617965  3702 sgd_solver.cpp:105] Iteration 50200, lr = 0.01
I1006 18:49:23.951645  3702 solver.cpp:218] Iteration 50300 (11.9995 iter/s, 8.33366s/100 iters), loss = 0.0268481
I1006 18:49:23.951673  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0268481 (* 1 = 0.0268481 loss)
I1006 18:49:23.951679  3702 sgd_solver.cpp:105] Iteration 50300, lr = 0.01
I1006 18:49:32.290657  3702 solver.cpp:218] Iteration 50400 (11.9919 iter/s, 8.33895s/100 iters), loss = 0.00612205
I1006 18:49:32.290750  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.006122 (* 1 = 0.006122 loss)
I1006 18:49:32.290756  3702 sgd_solver.cpp:105] Iteration 50400, lr = 0.01
I1006 18:49:40.210846  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:49:40.544637  3702 solver.cpp:330] Iteration 50500, Testing net (#0)
I1006 18:49:42.472060  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:49:42.552510  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9138
I1006 18:49:42.552536  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.302295 (* 1 = 0.302295 loss)
I1006 18:49:42.635699  3702 solver.cpp:218] Iteration 50500 (9.66658 iter/s, 10.3449s/100 iters), loss = 0.0262602
I1006 18:49:42.635725  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0262601 (* 1 = 0.0262601 loss)
I1006 18:49:42.635732  3702 sgd_solver.cpp:105] Iteration 50500, lr = 0.01
I1006 18:49:50.983719  3702 solver.cpp:218] Iteration 50600 (11.979 iter/s, 8.34797s/100 iters), loss = 0.0436994
I1006 18:49:50.983747  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0436994 (* 1 = 0.0436994 loss)
I1006 18:49:50.983753  3702 sgd_solver.cpp:105] Iteration 50600, lr = 0.01
I1006 18:49:59.319921  3702 solver.cpp:218] Iteration 50700 (11.996 iter/s, 8.33614s/100 iters), loss = 0.00619979
I1006 18:49:59.319949  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00619973 (* 1 = 0.00619973 loss)
I1006 18:49:59.319955  3702 sgd_solver.cpp:105] Iteration 50700, lr = 0.01
I1006 18:50:07.663743  3702 solver.cpp:218] Iteration 50800 (11.985 iter/s, 8.34377s/100 iters), loss = 0.0709664
I1006 18:50:07.663887  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0709663 (* 1 = 0.0709663 loss)
I1006 18:50:07.663895  3702 sgd_solver.cpp:105] Iteration 50800, lr = 0.01
I1006 18:50:16.001586  3702 solver.cpp:218] Iteration 50900 (11.9937 iter/s, 8.33768s/100 iters), loss = 0.0121219
I1006 18:50:16.001615  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0121218 (* 1 = 0.0121218 loss)
I1006 18:50:16.001621  3702 sgd_solver.cpp:105] Iteration 50900, lr = 0.01
I1006 18:50:23.934468  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:50:24.269536  3702 solver.cpp:330] Iteration 51000, Testing net (#0)
I1006 18:50:26.195907  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:50:26.277133  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9125
I1006 18:50:26.277169  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.314332 (* 1 = 0.314332 loss)
I1006 18:50:26.359771  3702 solver.cpp:218] Iteration 51000 (9.65426 iter/s, 10.3581s/100 iters), loss = 0.0204858
I1006 18:50:26.359798  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0204857 (* 1 = 0.0204857 loss)
I1006 18:50:26.359805  3702 sgd_solver.cpp:105] Iteration 51000, lr = 0.01
I1006 18:50:34.691295  3702 solver.cpp:218] Iteration 51100 (12.0027 iter/s, 8.33147s/100 iters), loss = 0.0144732
I1006 18:50:34.691334  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0144731 (* 1 = 0.0144731 loss)
I1006 18:50:34.691340  3702 sgd_solver.cpp:105] Iteration 51100, lr = 0.01
I1006 18:50:43.038185  3702 solver.cpp:218] Iteration 51200 (11.9806 iter/s, 8.34682s/100 iters), loss = 0.0396975
I1006 18:50:43.038256  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0396974 (* 1 = 0.0396974 loss)
I1006 18:50:43.038264  3702 sgd_solver.cpp:105] Iteration 51200, lr = 0.01
I1006 18:50:51.374577  3702 solver.cpp:218] Iteration 51300 (11.9957 iter/s, 8.3363s/100 iters), loss = 0.0454412
I1006 18:50:51.374606  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0454411 (* 1 = 0.0454411 loss)
I1006 18:50:51.374622  3702 sgd_solver.cpp:105] Iteration 51300, lr = 0.01
I1006 18:50:59.717986  3702 solver.cpp:218] Iteration 51400 (11.9856 iter/s, 8.34336s/100 iters), loss = 0.00406662
I1006 18:50:59.718015  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00406654 (* 1 = 0.00406654 loss)
I1006 18:50:59.718020  3702 sgd_solver.cpp:105] Iteration 51400, lr = 0.01
I1006 18:51:07.638444  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:51:07.973212  3702 solver.cpp:330] Iteration 51500, Testing net (#0)
I1006 18:51:09.899883  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:51:09.979856  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9172
I1006 18:51:09.979882  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.303076 (* 1 = 0.303076 loss)
I1006 18:51:10.063393  3702 solver.cpp:218] Iteration 51500 (9.66618 iter/s, 10.3453s/100 iters), loss = 0.0341166
I1006 18:51:10.063426  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0341165 (* 1 = 0.0341165 loss)
I1006 18:51:10.063431  3702 sgd_solver.cpp:105] Iteration 51500, lr = 0.01
I1006 18:51:18.404178  3702 solver.cpp:218] Iteration 51600 (11.9894 iter/s, 8.34073s/100 iters), loss = 0.0156966
I1006 18:51:18.404302  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0156965 (* 1 = 0.0156965 loss)
I1006 18:51:18.404309  3702 sgd_solver.cpp:105] Iteration 51600, lr = 0.01
I1006 18:51:26.736634  3702 solver.cpp:218] Iteration 51700 (12.0015 iter/s, 8.3323s/100 iters), loss = 0.00837781
I1006 18:51:26.736665  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00837773 (* 1 = 0.00837773 loss)
I1006 18:51:26.736670  3702 sgd_solver.cpp:105] Iteration 51700, lr = 0.01
I1006 18:51:35.079643  3702 solver.cpp:218] Iteration 51800 (11.9862 iter/s, 8.34295s/100 iters), loss = 0.00459532
I1006 18:51:35.079684  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00459525 (* 1 = 0.00459525 loss)
I1006 18:51:35.079689  3702 sgd_solver.cpp:105] Iteration 51800, lr = 0.01
I1006 18:51:43.415195  3702 solver.cpp:218] Iteration 51900 (11.9969 iter/s, 8.33549s/100 iters), loss = 0.0209019
I1006 18:51:43.415235  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0209019 (* 1 = 0.0209019 loss)
I1006 18:51:43.415241  3702 sgd_solver.cpp:105] Iteration 51900, lr = 0.01
I1006 18:51:51.343289  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:51:51.677476  3702 solver.cpp:330] Iteration 52000, Testing net (#0)
I1006 18:51:53.603703  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:51:53.685176  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9199
I1006 18:51:53.685202  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.293583 (* 1 = 0.293583 loss)
I1006 18:51:53.767412  3702 solver.cpp:218] Iteration 52000 (9.65983 iter/s, 10.3521s/100 iters), loss = 0.0147991
I1006 18:51:53.767436  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0147991 (* 1 = 0.0147991 loss)
I1006 18:51:53.767443  3702 sgd_solver.cpp:105] Iteration 52000, lr = 0.01
I1006 18:52:02.102039  3702 solver.cpp:218] Iteration 52100 (11.9982 iter/s, 8.33458s/100 iters), loss = 0.0577994
I1006 18:52:02.102068  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0577994 (* 1 = 0.0577994 loss)
I1006 18:52:02.102074  3702 sgd_solver.cpp:105] Iteration 52100, lr = 0.01
I1006 18:52:10.444731  3702 solver.cpp:218] Iteration 52200 (11.9866 iter/s, 8.34263s/100 iters), loss = 0.0160721
I1006 18:52:10.444761  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0160721 (* 1 = 0.0160721 loss)
I1006 18:52:10.444766  3702 sgd_solver.cpp:105] Iteration 52200, lr = 0.01
I1006 18:52:18.784031  3702 solver.cpp:218] Iteration 52300 (11.9915 iter/s, 8.33925s/100 iters), loss = 0.0261739
I1006 18:52:18.784070  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0261739 (* 1 = 0.0261739 loss)
I1006 18:52:18.784076  3702 sgd_solver.cpp:105] Iteration 52300, lr = 0.01
I1006 18:52:27.132802  3702 solver.cpp:218] Iteration 52400 (11.9779 iter/s, 8.34871s/100 iters), loss = 0.0313602
I1006 18:52:27.132900  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0313601 (* 1 = 0.0313601 loss)
I1006 18:52:27.132917  3702 sgd_solver.cpp:105] Iteration 52400, lr = 0.01
I1006 18:52:35.060803  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:52:35.394347  3702 solver.cpp:330] Iteration 52500, Testing net (#0)
I1006 18:52:37.321830  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:52:37.402472  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.916
I1006 18:52:37.402505  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.307445 (* 1 = 0.307445 loss)
I1006 18:52:37.485906  3702 solver.cpp:218] Iteration 52500 (9.65906 iter/s, 10.353s/100 iters), loss = 0.0253243
I1006 18:52:37.485934  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0253243 (* 1 = 0.0253243 loss)
I1006 18:52:37.485941  3702 sgd_solver.cpp:105] Iteration 52500, lr = 0.01
I1006 18:52:45.830461  3702 solver.cpp:218] Iteration 52600 (11.9839 iter/s, 8.3445s/100 iters), loss = 0.0345228
I1006 18:52:45.830488  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0345228 (* 1 = 0.0345228 loss)
I1006 18:52:45.830494  3702 sgd_solver.cpp:105] Iteration 52600, lr = 0.01
I1006 18:52:54.167488  3702 solver.cpp:218] Iteration 52700 (11.9948 iter/s, 8.33697s/100 iters), loss = 0.0165316
I1006 18:52:54.167517  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0165315 (* 1 = 0.0165315 loss)
I1006 18:52:54.167522  3702 sgd_solver.cpp:105] Iteration 52700, lr = 0.01
I1006 18:53:02.514900  3702 solver.cpp:218] Iteration 52800 (11.9798 iter/s, 8.34736s/100 iters), loss = 0.00344581
I1006 18:53:02.515058  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00344576 (* 1 = 0.00344576 loss)
I1006 18:53:02.515065  3702 sgd_solver.cpp:105] Iteration 52800, lr = 0.01
I1006 18:53:10.853206  3702 solver.cpp:218] Iteration 52900 (11.9931 iter/s, 8.33813s/100 iters), loss = 0.0138339
I1006 18:53:10.853246  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0138339 (* 1 = 0.0138339 loss)
I1006 18:53:10.853251  3702 sgd_solver.cpp:105] Iteration 52900, lr = 0.01
I1006 18:53:18.785226  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:53:19.118111  3702 solver.cpp:330] Iteration 53000, Testing net (#0)
I1006 18:53:21.046386  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:53:21.127511  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9168
I1006 18:53:21.127535  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.305276 (* 1 = 0.305276 loss)
I1006 18:53:21.209549  3702 solver.cpp:218] Iteration 53000 (9.65599 iter/s, 10.3563s/100 iters), loss = 0.0151865
I1006 18:53:21.209583  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0151864 (* 1 = 0.0151864 loss)
I1006 18:53:21.209589  3702 sgd_solver.cpp:105] Iteration 53000, lr = 0.01
I1006 18:53:29.536785  3702 solver.cpp:218] Iteration 53100 (12.0089 iter/s, 8.32718s/100 iters), loss = 0.0454691
I1006 18:53:29.536813  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.045469 (* 1 = 0.045469 loss)
I1006 18:53:29.536819  3702 sgd_solver.cpp:105] Iteration 53100, lr = 0.01
I1006 18:53:37.881055  3702 solver.cpp:218] Iteration 53200 (11.9843 iter/s, 8.34422s/100 iters), loss = 0.0107151
I1006 18:53:37.881181  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0107151 (* 1 = 0.0107151 loss)
I1006 18:53:37.881197  3702 sgd_solver.cpp:105] Iteration 53200, lr = 0.01
I1006 18:53:46.219252  3702 solver.cpp:218] Iteration 53300 (11.9932 iter/s, 8.33805s/100 iters), loss = 0.0280211
I1006 18:53:46.219281  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.028021 (* 1 = 0.028021 loss)
I1006 18:53:46.219297  3702 sgd_solver.cpp:105] Iteration 53300, lr = 0.01
I1006 18:53:54.563057  3702 solver.cpp:218] Iteration 53400 (11.985 iter/s, 8.34375s/100 iters), loss = 0.0111905
I1006 18:53:54.563086  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0111905 (* 1 = 0.0111905 loss)
I1006 18:53:54.563102  3702 sgd_solver.cpp:105] Iteration 53400, lr = 0.01
I1006 18:54:02.487671  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:54:02.821717  3702 solver.cpp:330] Iteration 53500, Testing net (#0)
I1006 18:54:04.747480  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:54:04.827855  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9134
I1006 18:54:04.827889  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.326411 (* 1 = 0.326411 loss)
I1006 18:54:04.911792  3702 solver.cpp:218] Iteration 53500 (9.66307 iter/s, 10.3487s/100 iters), loss = 0.0213433
I1006 18:54:04.911819  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0213432 (* 1 = 0.0213432 loss)
I1006 18:54:04.911825  3702 sgd_solver.cpp:105] Iteration 53500, lr = 0.01
I1006 18:54:13.259531  3702 solver.cpp:218] Iteration 53600 (11.9794 iter/s, 8.34769s/100 iters), loss = 0.0102433
I1006 18:54:13.259685  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0102432 (* 1 = 0.0102432 loss)
I1006 18:54:13.259702  3702 sgd_solver.cpp:105] Iteration 53600, lr = 0.01
I1006 18:54:21.597110  3702 solver.cpp:218] Iteration 53700 (11.9941 iter/s, 8.33741s/100 iters), loss = 0.0201803
I1006 18:54:21.597139  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0201803 (* 1 = 0.0201803 loss)
I1006 18:54:21.597146  3702 sgd_solver.cpp:105] Iteration 53700, lr = 0.01
I1006 18:54:29.938637  3702 solver.cpp:218] Iteration 53800 (11.9883 iter/s, 8.34147s/100 iters), loss = 0.00535619
I1006 18:54:29.938678  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00535617 (* 1 = 0.00535617 loss)
I1006 18:54:29.938683  3702 sgd_solver.cpp:105] Iteration 53800, lr = 0.01
I1006 18:54:38.280565  3702 solver.cpp:218] Iteration 53900 (11.9877 iter/s, 8.34186s/100 iters), loss = 0.0166428
I1006 18:54:38.280596  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0166428 (* 1 = 0.0166428 loss)
I1006 18:54:38.280601  3702 sgd_solver.cpp:105] Iteration 53900, lr = 0.01
I1006 18:54:46.213482  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:54:46.546665  3702 solver.cpp:330] Iteration 54000, Testing net (#0)
I1006 18:54:48.473417  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:54:48.554497  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9157
I1006 18:54:48.554531  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.327391 (* 1 = 0.327391 loss)
I1006 18:54:48.636966  3702 solver.cpp:218] Iteration 54000 (9.65592 iter/s, 10.3563s/100 iters), loss = 0.0371267
I1006 18:54:48.636992  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0371267 (* 1 = 0.0371267 loss)
I1006 18:54:48.636999  3702 sgd_solver.cpp:105] Iteration 54000, lr = 0.01
I1006 18:54:56.980286  3702 solver.cpp:218] Iteration 54100 (11.9857 iter/s, 8.34327s/100 iters), loss = 0.0107431
I1006 18:54:56.980315  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0107431 (* 1 = 0.0107431 loss)
I1006 18:54:56.980321  3702 sgd_solver.cpp:105] Iteration 54100, lr = 0.01
I1006 18:55:05.331810  3702 solver.cpp:218] Iteration 54200 (11.9739 iter/s, 8.35147s/100 iters), loss = 0.0271486
I1006 18:55:05.331848  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0271486 (* 1 = 0.0271486 loss)
I1006 18:55:05.331854  3702 sgd_solver.cpp:105] Iteration 54200, lr = 0.01
I1006 18:55:13.667490  3702 solver.cpp:218] Iteration 54300 (11.9967 iter/s, 8.33562s/100 iters), loss = 0.0268369
I1006 18:55:13.667529  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0268369 (* 1 = 0.0268369 loss)
I1006 18:55:13.667534  3702 sgd_solver.cpp:105] Iteration 54300, lr = 0.01
I1006 18:55:22.015341  3702 solver.cpp:218] Iteration 54400 (11.9792 iter/s, 8.34779s/100 iters), loss = 0.017732
I1006 18:55:22.015439  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.017732 (* 1 = 0.017732 loss)
I1006 18:55:22.015446  3702 sgd_solver.cpp:105] Iteration 54400, lr = 0.01
I1006 18:55:29.944887  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:55:30.278615  3702 solver.cpp:330] Iteration 54500, Testing net (#0)
I1006 18:55:32.203470  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:55:32.284104  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9135
I1006 18:55:32.284131  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.32403 (* 1 = 0.32403 loss)
I1006 18:55:32.367241  3702 solver.cpp:218] Iteration 54500 (9.66018 iter/s, 10.3518s/100 iters), loss = 0.00462596
I1006 18:55:32.367270  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00462596 (* 1 = 0.00462596 loss)
I1006 18:55:32.367277  3702 sgd_solver.cpp:105] Iteration 54500, lr = 0.01
I1006 18:55:40.709806  3702 solver.cpp:218] Iteration 54600 (11.9868 iter/s, 8.34251s/100 iters), loss = 0.00792283
I1006 18:55:40.709846  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00792282 (* 1 = 0.00792282 loss)
I1006 18:55:40.709852  3702 sgd_solver.cpp:105] Iteration 54600, lr = 0.01
I1006 18:55:49.046123  3702 solver.cpp:218] Iteration 54700 (11.9958 iter/s, 8.33625s/100 iters), loss = 0.0180328
I1006 18:55:49.046162  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0180328 (* 1 = 0.0180328 loss)
I1006 18:55:49.046169  3702 sgd_solver.cpp:105] Iteration 54700, lr = 0.01
I1006 18:55:57.387377  3702 solver.cpp:218] Iteration 54800 (11.9887 iter/s, 8.34119s/100 iters), loss = 0.00517704
I1006 18:55:57.387523  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00517705 (* 1 = 0.00517705 loss)
I1006 18:55:57.387532  3702 sgd_solver.cpp:105] Iteration 54800, lr = 0.01
I1006 18:56:05.729516  3702 solver.cpp:218] Iteration 54900 (11.9876 iter/s, 8.34197s/100 iters), loss = 0.00445249
I1006 18:56:05.729545  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00445249 (* 1 = 0.00445249 loss)
I1006 18:56:05.729562  3702 sgd_solver.cpp:105] Iteration 54900, lr = 0.01
I1006 18:56:13.660231  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:56:13.993252  3702 solver.cpp:330] Iteration 55000, Testing net (#0)
I1006 18:56:15.920090  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:56:16.000789  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9145
I1006 18:56:16.000825  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.311402 (* 1 = 0.311402 loss)
I1006 18:56:16.083503  3702 solver.cpp:218] Iteration 55000 (9.65817 iter/s, 10.3539s/100 iters), loss = 0.0486591
I1006 18:56:16.083528  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0486591 (* 1 = 0.0486591 loss)
I1006 18:56:16.083535  3702 sgd_solver.cpp:105] Iteration 55000, lr = 0.01
I1006 18:56:24.417295  3702 solver.cpp:218] Iteration 55100 (11.9994 iter/s, 8.33374s/100 iters), loss = 0.0271758
I1006 18:56:24.417325  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0271758 (* 1 = 0.0271758 loss)
I1006 18:56:24.417330  3702 sgd_solver.cpp:105] Iteration 55100, lr = 0.01
I1006 18:56:32.759802  3702 solver.cpp:218] Iteration 55200 (11.9869 iter/s, 8.34245s/100 iters), loss = 0.0408637
I1006 18:56:32.759878  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0408637 (* 1 = 0.0408637 loss)
I1006 18:56:32.759886  3702 sgd_solver.cpp:105] Iteration 55200, lr = 0.01
I1006 18:56:41.088665  3702 solver.cpp:218] Iteration 55300 (12.0066 iter/s, 8.32876s/100 iters), loss = 0.0440045
I1006 18:56:41.088711  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0440045 (* 1 = 0.0440045 loss)
I1006 18:56:41.088718  3702 sgd_solver.cpp:105] Iteration 55300, lr = 0.01
I1006 18:56:49.421217  3702 solver.cpp:218] Iteration 55400 (12.0012 iter/s, 8.33248s/100 iters), loss = 0.00724478
I1006 18:56:49.421257  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00724478 (* 1 = 0.00724478 loss)
I1006 18:56:49.421262  3702 sgd_solver.cpp:105] Iteration 55400, lr = 0.01
I1006 18:56:57.347245  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:56:57.680279  3702 solver.cpp:330] Iteration 55500, Testing net (#0)
I1006 18:56:59.607367  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:56:59.688405  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.918
I1006 18:56:59.688428  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.320463 (* 1 = 0.320463 loss)
I1006 18:56:59.771849  3702 solver.cpp:218] Iteration 55500 (9.66131 iter/s, 10.3506s/100 iters), loss = 0.00883368
I1006 18:56:59.771875  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00883367 (* 1 = 0.00883367 loss)
I1006 18:56:59.771881  3702 sgd_solver.cpp:105] Iteration 55500, lr = 0.01
I1006 18:57:08.125140  3702 solver.cpp:218] Iteration 55600 (11.9714 iter/s, 8.35324s/100 iters), loss = 0.0271792
I1006 18:57:08.125226  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0271792 (* 1 = 0.0271792 loss)
I1006 18:57:08.125232  3702 sgd_solver.cpp:105] Iteration 55600, lr = 0.01
I1006 18:57:16.474845  3702 solver.cpp:218] Iteration 55700 (11.9766 iter/s, 8.3496s/100 iters), loss = 0.00745293
I1006 18:57:16.474884  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00745291 (* 1 = 0.00745291 loss)
I1006 18:57:16.474890  3702 sgd_solver.cpp:105] Iteration 55700, lr = 0.01
I1006 18:57:24.830562  3702 solver.cpp:218] Iteration 55800 (11.9679 iter/s, 8.35565s/100 iters), loss = 0.0173158
I1006 18:57:24.830591  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0173158 (* 1 = 0.0173158 loss)
I1006 18:57:24.830597  3702 sgd_solver.cpp:105] Iteration 55800, lr = 0.01
I1006 18:57:33.183387  3702 solver.cpp:218] Iteration 55900 (11.9721 iter/s, 8.35277s/100 iters), loss = 0.0363195
I1006 18:57:33.183415  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0363194 (* 1 = 0.0363194 loss)
I1006 18:57:33.183420  3702 sgd_solver.cpp:105] Iteration 55900, lr = 0.01
I1006 18:57:41.123070  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:57:41.457200  3702 solver.cpp:330] Iteration 56000, Testing net (#0)
I1006 18:57:43.384526  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:57:43.465009  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9149
I1006 18:57:43.465046  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.321564 (* 1 = 0.321564 loss)
I1006 18:57:43.548456  3702 solver.cpp:218] Iteration 56000 (9.64784 iter/s, 10.365s/100 iters), loss = 0.00387713
I1006 18:57:43.548481  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00387709 (* 1 = 0.00387709 loss)
I1006 18:57:43.548488  3702 sgd_solver.cpp:105] Iteration 56000, lr = 0.01
I1006 18:57:51.890720  3702 solver.cpp:218] Iteration 56100 (11.9872 iter/s, 8.34221s/100 iters), loss = 0.0203242
I1006 18:57:51.890761  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0203241 (* 1 = 0.0203241 loss)
I1006 18:57:51.890769  3702 sgd_solver.cpp:105] Iteration 56100, lr = 0.01
I1006 18:58:00.237602  3702 solver.cpp:218] Iteration 56200 (11.9806 iter/s, 8.34681s/100 iters), loss = 0.0132532
I1006 18:58:00.237635  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0132532 (* 1 = 0.0132532 loss)
I1006 18:58:00.237643  3702 sgd_solver.cpp:105] Iteration 56200, lr = 0.01
I1006 18:58:08.577632  3702 solver.cpp:218] Iteration 56300 (11.9904 iter/s, 8.33997s/100 iters), loss = 0.0634133
I1006 18:58:08.577672  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0634133 (* 1 = 0.0634133 loss)
I1006 18:58:08.577677  3702 sgd_solver.cpp:105] Iteration 56300, lr = 0.01
I1006 18:58:16.918809  3702 solver.cpp:218] Iteration 56400 (11.9888 iter/s, 8.34111s/100 iters), loss = 0.0108281
I1006 18:58:16.918931  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.010828 (* 1 = 0.010828 loss)
I1006 18:58:16.918938  3702 sgd_solver.cpp:105] Iteration 56400, lr = 0.01
I1006 18:58:24.844591  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:58:25.179299  3702 solver.cpp:330] Iteration 56500, Testing net (#0)
I1006 18:58:27.107159  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:58:27.187697  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9161
I1006 18:58:27.187733  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.308586 (* 1 = 0.308586 loss)
I1006 18:58:27.271157  3702 solver.cpp:218] Iteration 56500 (9.65978 iter/s, 10.3522s/100 iters), loss = 0.0134554
I1006 18:58:27.271190  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0134554 (* 1 = 0.0134554 loss)
I1006 18:58:27.271198  3702 sgd_solver.cpp:105] Iteration 56500, lr = 0.01
I1006 18:58:35.620808  3702 solver.cpp:218] Iteration 56600 (11.9766 iter/s, 8.34959s/100 iters), loss = 0.00827486
I1006 18:58:35.620838  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00827482 (* 1 = 0.00827482 loss)
I1006 18:58:35.620844  3702 sgd_solver.cpp:105] Iteration 56600, lr = 0.01
I1006 18:58:43.965695  3702 solver.cpp:218] Iteration 56700 (11.9835 iter/s, 8.34483s/100 iters), loss = 0.00915797
I1006 18:58:43.965734  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00915792 (* 1 = 0.00915792 loss)
I1006 18:58:43.965740  3702 sgd_solver.cpp:105] Iteration 56700, lr = 0.01
I1006 18:58:52.316012  3702 solver.cpp:218] Iteration 56800 (11.9757 iter/s, 8.35025s/100 iters), loss = 0.0160811
I1006 18:58:52.316118  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0160811 (* 1 = 0.0160811 loss)
I1006 18:58:52.316134  3702 sgd_solver.cpp:105] Iteration 56800, lr = 0.01
I1006 18:59:00.661154  3702 solver.cpp:218] Iteration 56900 (11.9832 iter/s, 8.34501s/100 iters), loss = 0.0174551
I1006 18:59:00.661182  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0174551 (* 1 = 0.0174551 loss)
I1006 18:59:00.661187  3702 sgd_solver.cpp:105] Iteration 56900, lr = 0.01
I1006 18:59:08.593215  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:59:08.926573  3702 solver.cpp:330] Iteration 57000, Testing net (#0)
I1006 18:59:10.853209  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:59:10.934487  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9193
I1006 18:59:10.934522  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.317521 (* 1 = 0.317521 loss)
I1006 18:59:11.017076  3702 solver.cpp:218] Iteration 57000 (9.65637 iter/s, 10.3559s/100 iters), loss = 0.0121734
I1006 18:59:11.017099  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0121734 (* 1 = 0.0121734 loss)
I1006 18:59:11.017107  3702 sgd_solver.cpp:105] Iteration 57000, lr = 0.01
I1006 18:59:19.353714  3702 solver.cpp:218] Iteration 57100 (11.9953 iter/s, 8.33659s/100 iters), loss = 0.00753361
I1006 18:59:19.353744  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00753358 (* 1 = 0.00753358 loss)
I1006 18:59:19.353750  3702 sgd_solver.cpp:105] Iteration 57100, lr = 0.01
I1006 18:59:27.696499  3702 solver.cpp:218] Iteration 57200 (11.9865 iter/s, 8.34273s/100 iters), loss = 0.0249935
I1006 18:59:27.696597  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0249934 (* 1 = 0.0249934 loss)
I1006 18:59:27.696604  3702 sgd_solver.cpp:105] Iteration 57200, lr = 0.01
I1006 18:59:36.034322  3702 solver.cpp:218] Iteration 57300 (11.9937 iter/s, 8.3377s/100 iters), loss = 0.0128308
I1006 18:59:36.034350  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0128308 (* 1 = 0.0128308 loss)
I1006 18:59:36.034356  3702 sgd_solver.cpp:105] Iteration 57300, lr = 0.01
I1006 18:59:44.373733  3702 solver.cpp:218] Iteration 57400 (11.9913 iter/s, 8.33936s/100 iters), loss = 0.0237686
I1006 18:59:44.373764  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0237685 (* 1 = 0.0237685 loss)
I1006 18:59:44.373769  3702 sgd_solver.cpp:105] Iteration 57400, lr = 0.01
I1006 18:59:52.301934  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:59:52.635756  3702 solver.cpp:330] Iteration 57500, Testing net (#0)
I1006 18:59:54.563446  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 18:59:54.643774  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9092
I1006 18:59:54.643808  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.357715 (* 1 = 0.357715 loss)
I1006 18:59:54.727003  3702 solver.cpp:218] Iteration 57500 (9.65884 iter/s, 10.3532s/100 iters), loss = 0.0516472
I1006 18:59:54.727030  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0516472 (* 1 = 0.0516472 loss)
I1006 18:59:54.727035  3702 sgd_solver.cpp:105] Iteration 57500, lr = 0.01
I1006 19:00:03.070150  3702 solver.cpp:218] Iteration 57600 (11.986 iter/s, 8.3431s/100 iters), loss = 0.00381306
I1006 19:00:03.070309  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00381304 (* 1 = 0.00381304 loss)
I1006 19:00:03.070327  3702 sgd_solver.cpp:105] Iteration 57600, lr = 0.01
I1006 19:00:11.410148  3702 solver.cpp:218] Iteration 57700 (11.9907 iter/s, 8.33982s/100 iters), loss = 0.00705648
I1006 19:00:11.410179  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00705645 (* 1 = 0.00705645 loss)
I1006 19:00:11.410184  3702 sgd_solver.cpp:105] Iteration 57700, lr = 0.01
I1006 19:00:19.748517  3702 solver.cpp:218] Iteration 57800 (11.9928 iter/s, 8.33831s/100 iters), loss = 0.0210608
I1006 19:00:19.748558  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0210607 (* 1 = 0.0210607 loss)
I1006 19:00:19.748562  3702 sgd_solver.cpp:105] Iteration 57800, lr = 0.01
I1006 19:00:28.085314  3702 solver.cpp:218] Iteration 57900 (11.9951 iter/s, 8.33673s/100 iters), loss = 0.0337193
I1006 19:00:28.085343  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0337192 (* 1 = 0.0337192 loss)
I1006 19:00:28.085350  3702 sgd_solver.cpp:105] Iteration 57900, lr = 0.01
I1006 19:00:36.009654  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:00:36.344300  3702 solver.cpp:330] Iteration 58000, Testing net (#0)
I1006 19:00:38.271266  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:00:38.352413  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9175
I1006 19:00:38.352448  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.326225 (* 1 = 0.326225 loss)
I1006 19:00:38.435114  3702 solver.cpp:218] Iteration 58000 (9.66208 iter/s, 10.3497s/100 iters), loss = 0.00474143
I1006 19:00:38.435138  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0047414 (* 1 = 0.0047414 loss)
I1006 19:00:38.435145  3702 sgd_solver.cpp:105] Iteration 58000, lr = 0.01
I1006 19:00:46.770776  3702 solver.cpp:218] Iteration 58100 (11.9967 iter/s, 8.33561s/100 iters), loss = 0.0256048
I1006 19:00:46.770805  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0256048 (* 1 = 0.0256048 loss)
I1006 19:00:46.770812  3702 sgd_solver.cpp:105] Iteration 58100, lr = 0.01
I1006 19:00:55.115967  3702 solver.cpp:218] Iteration 58200 (11.983 iter/s, 8.34514s/100 iters), loss = 0.0150994
I1006 19:00:55.116008  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0150993 (* 1 = 0.0150993 loss)
I1006 19:00:55.116014  3702 sgd_solver.cpp:105] Iteration 58200, lr = 0.01
I1006 19:01:03.459074  3702 solver.cpp:218] Iteration 58300 (11.986 iter/s, 8.34305s/100 iters), loss = 0.00632138
I1006 19:01:03.459102  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00632133 (* 1 = 0.00632133 loss)
I1006 19:01:03.459108  3702 sgd_solver.cpp:105] Iteration 58300, lr = 0.01
I1006 19:01:11.804107  3702 solver.cpp:218] Iteration 58400 (11.9833 iter/s, 8.34498s/100 iters), loss = 0.00124357
I1006 19:01:11.804249  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00124351 (* 1 = 0.00124351 loss)
I1006 19:01:11.804255  3702 sgd_solver.cpp:105] Iteration 58400, lr = 0.01
I1006 19:01:19.730476  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:01:20.065264  3702 solver.cpp:330] Iteration 58500, Testing net (#0)
I1006 19:01:21.992228  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:01:22.072816  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9132
I1006 19:01:22.072841  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.340378 (* 1 = 0.340378 loss)
I1006 19:01:22.156357  3702 solver.cpp:218] Iteration 58500 (9.65989 iter/s, 10.3521s/100 iters), loss = 0.00680025
I1006 19:01:22.156385  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00680018 (* 1 = 0.00680018 loss)
I1006 19:01:22.156392  3702 sgd_solver.cpp:105] Iteration 58500, lr = 0.01
I1006 19:01:30.498834  3702 solver.cpp:218] Iteration 58600 (11.9869 iter/s, 8.34242s/100 iters), loss = 0.0117584
I1006 19:01:30.498863  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0117583 (* 1 = 0.0117583 loss)
I1006 19:01:30.498869  3702 sgd_solver.cpp:105] Iteration 58600, lr = 0.01
I1006 19:01:38.834903  3702 solver.cpp:218] Iteration 58700 (11.9961 iter/s, 8.33601s/100 iters), loss = 0.0350533
I1006 19:01:38.834930  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0350532 (* 1 = 0.0350532 loss)
I1006 19:01:38.834936  3702 sgd_solver.cpp:105] Iteration 58700, lr = 0.01
I1006 19:01:47.180367  3702 solver.cpp:218] Iteration 58800 (11.9826 iter/s, 8.34541s/100 iters), loss = 0.00226145
I1006 19:01:47.180493  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00226138 (* 1 = 0.00226138 loss)
I1006 19:01:47.180500  3702 sgd_solver.cpp:105] Iteration 58800, lr = 0.01
I1006 19:01:55.522233  3702 solver.cpp:218] Iteration 58900 (11.9879 iter/s, 8.34172s/100 iters), loss = 0.0473111
I1006 19:01:55.522274  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.047311 (* 1 = 0.047311 loss)
I1006 19:01:55.522280  3702 sgd_solver.cpp:105] Iteration 58900, lr = 0.01
I1006 19:02:03.455724  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:02:03.789433  3702 solver.cpp:330] Iteration 59000, Testing net (#0)
I1006 19:02:05.716985  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:02:05.797935  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9182
I1006 19:02:05.797971  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.324335 (* 1 = 0.324335 loss)
I1006 19:02:05.880097  3702 solver.cpp:218] Iteration 59000 (9.65456 iter/s, 10.3578s/100 iters), loss = 0.0201824
I1006 19:02:05.880122  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0201823 (* 1 = 0.0201823 loss)
I1006 19:02:05.880129  3702 sgd_solver.cpp:105] Iteration 59000, lr = 0.01
I1006 19:02:14.214635  3702 solver.cpp:218] Iteration 59100 (11.9983 iter/s, 8.33449s/100 iters), loss = 0.0748022
I1006 19:02:14.214674  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0748022 (* 1 = 0.0748022 loss)
I1006 19:02:14.214680  3702 sgd_solver.cpp:105] Iteration 59100, lr = 0.01
I1006 19:02:22.565840  3702 solver.cpp:218] Iteration 59200 (11.9744 iter/s, 8.35114s/100 iters), loss = 0.00535769
I1006 19:02:22.565928  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00535762 (* 1 = 0.00535762 loss)
I1006 19:02:22.565945  3702 sgd_solver.cpp:105] Iteration 59200, lr = 0.01
I1006 19:02:30.906059  3702 solver.cpp:218] Iteration 59300 (11.9903 iter/s, 8.34011s/100 iters), loss = 0.00630646
I1006 19:02:30.906098  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00630639 (* 1 = 0.00630639 loss)
I1006 19:02:30.906105  3702 sgd_solver.cpp:105] Iteration 59300, lr = 0.01
I1006 19:02:39.252483  3702 solver.cpp:218] Iteration 59400 (11.9813 iter/s, 8.34636s/100 iters), loss = 0.00258246
I1006 19:02:39.252523  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00258238 (* 1 = 0.00258238 loss)
I1006 19:02:39.252530  3702 sgd_solver.cpp:105] Iteration 59400, lr = 0.01
I1006 19:02:47.174816  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:02:47.508954  3702 solver.cpp:330] Iteration 59500, Testing net (#0)
I1006 19:02:49.434753  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:02:49.515363  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9188
I1006 19:02:49.515398  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.314167 (* 1 = 0.314167 loss)
I1006 19:02:49.598665  3702 solver.cpp:218] Iteration 59500 (9.66547 iter/s, 10.3461s/100 iters), loss = 0.0141844
I1006 19:02:49.598695  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0141844 (* 1 = 0.0141844 loss)
I1006 19:02:49.598701  3702 sgd_solver.cpp:105] Iteration 59500, lr = 0.01
I1006 19:02:57.952528  3702 solver.cpp:218] Iteration 59600 (11.9706 iter/s, 8.35381s/100 iters), loss = 0.0171202
I1006 19:02:57.952606  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0171201 (* 1 = 0.0171201 loss)
I1006 19:02:57.952613  3702 sgd_solver.cpp:105] Iteration 59600, lr = 0.01
I1006 19:03:06.303716  3702 solver.cpp:218] Iteration 59700 (11.9745 iter/s, 8.35108s/100 iters), loss = 0.00183108
I1006 19:03:06.303757  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00183101 (* 1 = 0.00183101 loss)
I1006 19:03:06.303763  3702 sgd_solver.cpp:105] Iteration 59700, lr = 0.01
I1006 19:03:14.653858  3702 solver.cpp:218] Iteration 59800 (11.9759 iter/s, 8.35008s/100 iters), loss = 0.00391307
I1006 19:03:14.653887  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00391299 (* 1 = 0.00391299 loss)
I1006 19:03:14.653892  3702 sgd_solver.cpp:105] Iteration 59800, lr = 0.01
I1006 19:03:23.003294  3702 solver.cpp:218] Iteration 59900 (11.9769 iter/s, 8.34938s/100 iters), loss = 0.00683547
I1006 19:03:23.003334  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00683539 (* 1 = 0.00683539 loss)
I1006 19:03:23.003340  3702 sgd_solver.cpp:105] Iteration 59900, lr = 0.01
I1006 19:03:30.942100  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:03:31.276890  3702 solver.cpp:330] Iteration 60000, Testing net (#0)
I1006 19:03:33.203908  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:03:33.284559  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9128
I1006 19:03:33.284603  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.319307 (* 1 = 0.319307 loss)
I1006 19:03:33.367581  3702 solver.cpp:218] Iteration 60000 (9.64858 iter/s, 10.3642s/100 iters), loss = 0.0219244
I1006 19:03:33.367609  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0219244 (* 1 = 0.0219244 loss)
I1006 19:03:33.367615  3702 sgd_solver.cpp:105] Iteration 60000, lr = 0.01
I1006 19:03:41.706081  3702 solver.cpp:218] Iteration 60100 (11.9926 iter/s, 8.33845s/100 iters), loss = 0.0212827
I1006 19:03:41.706110  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0212826 (* 1 = 0.0212826 loss)
I1006 19:03:41.706115  3702 sgd_solver.cpp:105] Iteration 60100, lr = 0.01
I1006 19:03:50.047729  3702 solver.cpp:218] Iteration 60200 (11.9881 iter/s, 8.34159s/100 iters), loss = 0.00465964
I1006 19:03:50.047757  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00465957 (* 1 = 0.00465957 loss)
I1006 19:03:50.047762  3702 sgd_solver.cpp:105] Iteration 60200, lr = 0.01
I1006 19:03:58.389050  3702 solver.cpp:218] Iteration 60300 (11.9886 iter/s, 8.34127s/100 iters), loss = 0.00437058
I1006 19:03:58.389081  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00437051 (* 1 = 0.00437051 loss)
I1006 19:03:58.389086  3702 sgd_solver.cpp:105] Iteration 60300, lr = 0.01
I1006 19:04:06.736394  3702 solver.cpp:218] Iteration 60400 (11.9799 iter/s, 8.34729s/100 iters), loss = 0.0216963
I1006 19:04:06.736515  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0216962 (* 1 = 0.0216962 loss)
I1006 19:04:06.736523  3702 sgd_solver.cpp:105] Iteration 60400, lr = 0.01
I1006 19:04:14.658123  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:04:14.992498  3702 solver.cpp:330] Iteration 60500, Testing net (#0)
I1006 19:04:16.920219  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:04:17.000581  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9198
I1006 19:04:17.000617  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.324628 (* 1 = 0.324628 loss)
I1006 19:04:17.084273  3702 solver.cpp:218] Iteration 60500 (9.66395 iter/s, 10.3477s/100 iters), loss = 0.00806506
I1006 19:04:17.084300  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00806499 (* 1 = 0.00806499 loss)
I1006 19:04:17.084306  3702 sgd_solver.cpp:105] Iteration 60500, lr = 0.01
I1006 19:04:25.429450  3702 solver.cpp:218] Iteration 60600 (11.983 iter/s, 8.34512s/100 iters), loss = 0.0344974
I1006 19:04:25.429479  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0344973 (* 1 = 0.0344973 loss)
I1006 19:04:25.429486  3702 sgd_solver.cpp:105] Iteration 60600, lr = 0.01
I1006 19:04:33.764163  3702 solver.cpp:218] Iteration 60700 (11.9981 iter/s, 8.33466s/100 iters), loss = 0.0235374
I1006 19:04:33.764190  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0235373 (* 1 = 0.0235373 loss)
I1006 19:04:33.764195  3702 sgd_solver.cpp:105] Iteration 60700, lr = 0.01
I1006 19:04:42.106950  3702 solver.cpp:218] Iteration 60800 (11.9865 iter/s, 8.34274s/100 iters), loss = 0.0121214
I1006 19:04:42.107125  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0121214 (* 1 = 0.0121214 loss)
I1006 19:04:42.107132  3702 sgd_solver.cpp:105] Iteration 60800, lr = 0.01
I1006 19:04:50.447814  3702 solver.cpp:218] Iteration 60900 (11.9894 iter/s, 8.34067s/100 iters), loss = 0.0202204
I1006 19:04:50.447844  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0202203 (* 1 = 0.0202203 loss)
I1006 19:04:50.447851  3702 sgd_solver.cpp:105] Iteration 60900, lr = 0.01
I1006 19:04:58.375442  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:04:58.708708  3702 solver.cpp:330] Iteration 61000, Testing net (#0)
I1006 19:05:00.636366  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:05:00.717171  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9148
I1006 19:05:00.717206  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.33744 (* 1 = 0.33744 loss)
I1006 19:05:00.799932  3702 solver.cpp:218] Iteration 61000 (9.65991 iter/s, 10.3521s/100 iters), loss = 0.0161764
I1006 19:05:00.799955  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0161763 (* 1 = 0.0161763 loss)
I1006 19:05:00.799962  3702 sgd_solver.cpp:105] Iteration 61000, lr = 0.01
I1006 19:05:09.140367  3702 solver.cpp:218] Iteration 61100 (11.9899 iter/s, 8.34039s/100 iters), loss = 0.0217244
I1006 19:05:09.140406  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0217243 (* 1 = 0.0217243 loss)
I1006 19:05:09.140413  3702 sgd_solver.cpp:105] Iteration 61100, lr = 0.01
I1006 19:05:17.485774  3702 solver.cpp:218] Iteration 61200 (11.9827 iter/s, 8.34534s/100 iters), loss = 0.0123374
I1006 19:05:17.485931  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0123374 (* 1 = 0.0123374 loss)
I1006 19:05:17.485939  3702 sgd_solver.cpp:105] Iteration 61200, lr = 0.01
I1006 19:05:25.821353  3702 solver.cpp:218] Iteration 61300 (11.997 iter/s, 8.3354s/100 iters), loss = 0.00667318
I1006 19:05:25.821382  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00667311 (* 1 = 0.00667311 loss)
I1006 19:05:25.821386  3702 sgd_solver.cpp:105] Iteration 61300, lr = 0.01
I1006 19:05:34.159477  3702 solver.cpp:218] Iteration 61400 (11.9932 iter/s, 8.33807s/100 iters), loss = 0.0040915
I1006 19:05:34.159507  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00409142 (* 1 = 0.00409142 loss)
I1006 19:05:34.159512  3702 sgd_solver.cpp:105] Iteration 61400, lr = 0.01
I1006 19:05:42.084080  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:05:42.417491  3702 solver.cpp:330] Iteration 61500, Testing net (#0)
I1006 19:05:44.343492  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:05:44.424007  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9198
I1006 19:05:44.424042  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.317706 (* 1 = 0.317706 loss)
I1006 19:05:44.508059  3702 solver.cpp:218] Iteration 61500 (9.66322 iter/s, 10.3485s/100 iters), loss = 0.00396561
I1006 19:05:44.508092  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00396552 (* 1 = 0.00396552 loss)
I1006 19:05:44.508100  3702 sgd_solver.cpp:105] Iteration 61500, lr = 0.01
I1006 19:05:52.853627  3702 solver.cpp:218] Iteration 61600 (11.9825 iter/s, 8.34551s/100 iters), loss = 0.0126453
I1006 19:05:52.853704  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0126452 (* 1 = 0.0126452 loss)
I1006 19:05:52.853721  3702 sgd_solver.cpp:105] Iteration 61600, lr = 0.01
I1006 19:06:01.191609  3702 solver.cpp:218] Iteration 61700 (11.9935 iter/s, 8.33788s/100 iters), loss = 0.0468669
I1006 19:06:01.191638  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0468668 (* 1 = 0.0468668 loss)
I1006 19:06:01.191644  3702 sgd_solver.cpp:105] Iteration 61700, lr = 0.01
I1006 19:06:09.530316  3702 solver.cpp:218] Iteration 61800 (11.9923 iter/s, 8.33865s/100 iters), loss = 0.00315758
I1006 19:06:09.530346  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0031575 (* 1 = 0.0031575 loss)
I1006 19:06:09.530352  3702 sgd_solver.cpp:105] Iteration 61800, lr = 0.01
I1006 19:06:17.867974  3702 solver.cpp:218] Iteration 61900 (11.9939 iter/s, 8.3376s/100 iters), loss = 0.0028065
I1006 19:06:17.868001  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00280642 (* 1 = 0.00280642 loss)
I1006 19:06:17.868007  3702 sgd_solver.cpp:105] Iteration 61900, lr = 0.01
I1006 19:06:25.794101  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:06:26.128051  3702 solver.cpp:330] Iteration 62000, Testing net (#0)
I1006 19:06:28.054505  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:06:28.135624  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9179
I1006 19:06:28.135648  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.332816 (* 1 = 0.332816 loss)
I1006 19:06:28.217952  3702 solver.cpp:218] Iteration 62000 (9.66191 iter/s, 10.3499s/100 iters), loss = 0.016077
I1006 19:06:28.217981  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0160769 (* 1 = 0.0160769 loss)
I1006 19:06:28.217988  3702 sgd_solver.cpp:105] Iteration 62000, lr = 0.01
I1006 19:06:36.554246  3702 solver.cpp:218] Iteration 62100 (11.9958 iter/s, 8.33624s/100 iters), loss = 0.0156892
I1006 19:06:36.554275  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0156892 (* 1 = 0.0156892 loss)
I1006 19:06:36.554281  3702 sgd_solver.cpp:105] Iteration 62100, lr = 0.01
I1006 19:06:44.889699  3702 solver.cpp:218] Iteration 62200 (11.997 iter/s, 8.3354s/100 iters), loss = 0.0130042
I1006 19:06:44.889729  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0130041 (* 1 = 0.0130041 loss)
I1006 19:06:44.889735  3702 sgd_solver.cpp:105] Iteration 62200, lr = 0.01
I1006 19:06:53.231820  3702 solver.cpp:218] Iteration 62300 (11.9874 iter/s, 8.34206s/100 iters), loss = 0.00917051
I1006 19:06:53.231861  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00917045 (* 1 = 0.00917045 loss)
I1006 19:06:53.231866  3702 sgd_solver.cpp:105] Iteration 62300, lr = 0.01
I1006 19:07:01.574501  3702 solver.cpp:218] Iteration 62400 (11.9866 iter/s, 8.34262s/100 iters), loss = 0.0067479
I1006 19:07:01.574643  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00674784 (* 1 = 0.00674784 loss)
I1006 19:07:01.574651  3702 sgd_solver.cpp:105] Iteration 62400, lr = 0.01
I1006 19:07:09.494491  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:07:09.828187  3702 solver.cpp:330] Iteration 62500, Testing net (#0)
I1006 19:07:11.755446  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:07:11.835767  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9103
I1006 19:07:11.835803  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.361127 (* 1 = 0.361127 loss)
I1006 19:07:11.919553  3702 solver.cpp:218] Iteration 62500 (9.66661 iter/s, 10.3449s/100 iters), loss = 0.00684314
I1006 19:07:11.919579  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00684307 (* 1 = 0.00684307 loss)
I1006 19:07:11.919585  3702 sgd_solver.cpp:105] Iteration 62500, lr = 0.01
I1006 19:07:20.268052  3702 solver.cpp:218] Iteration 62600 (11.9783 iter/s, 8.34845s/100 iters), loss = 0.00463415
I1006 19:07:20.268081  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00463408 (* 1 = 0.00463408 loss)
I1006 19:07:20.268087  3702 sgd_solver.cpp:105] Iteration 62600, lr = 0.01
I1006 19:07:28.602473  3702 solver.cpp:218] Iteration 62700 (11.9985 iter/s, 8.33437s/100 iters), loss = 0.0152877
I1006 19:07:28.602501  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0152876 (* 1 = 0.0152876 loss)
I1006 19:07:28.602507  3702 sgd_solver.cpp:105] Iteration 62700, lr = 0.01
I1006 19:07:36.947708  3702 solver.cpp:218] Iteration 62800 (11.983 iter/s, 8.34518s/100 iters), loss = 0.00578895
I1006 19:07:36.947793  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0057889 (* 1 = 0.0057889 loss)
I1006 19:07:36.947808  3702 sgd_solver.cpp:105] Iteration 62800, lr = 0.01
I1006 19:07:45.286998  3702 solver.cpp:218] Iteration 62900 (11.9916 iter/s, 8.33918s/100 iters), loss = 0.00708369
I1006 19:07:45.287027  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00708364 (* 1 = 0.00708364 loss)
I1006 19:07:45.287034  3702 sgd_solver.cpp:105] Iteration 62900, lr = 0.01
I1006 19:07:53.215958  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:07:53.550477  3702 solver.cpp:330] Iteration 63000, Testing net (#0)
I1006 19:07:55.476629  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:07:55.557555  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9168
I1006 19:07:55.557591  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.335484 (* 1 = 0.335484 loss)
I1006 19:07:55.640616  3702 solver.cpp:218] Iteration 63000 (9.65851 iter/s, 10.3536s/100 iters), loss = 0.0118572
I1006 19:07:55.640643  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0118572 (* 1 = 0.0118572 loss)
I1006 19:07:55.640650  3702 sgd_solver.cpp:105] Iteration 63000, lr = 0.01
I1006 19:08:03.973839  3702 solver.cpp:218] Iteration 63100 (12.0002 iter/s, 8.33317s/100 iters), loss = 0.00738753
I1006 19:08:03.973867  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00738747 (* 1 = 0.00738747 loss)
I1006 19:08:03.973873  3702 sgd_solver.cpp:105] Iteration 63100, lr = 0.01
I1006 19:08:12.316661  3702 solver.cpp:218] Iteration 63200 (11.9864 iter/s, 8.34277s/100 iters), loss = 0.00463512
I1006 19:08:12.316768  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00463506 (* 1 = 0.00463506 loss)
I1006 19:08:12.316783  3702 sgd_solver.cpp:105] Iteration 63200, lr = 0.01
I1006 19:08:20.652436  3702 solver.cpp:218] Iteration 63300 (11.9967 iter/s, 8.33566s/100 iters), loss = 0.0115313
I1006 19:08:20.652464  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0115312 (* 1 = 0.0115312 loss)
I1006 19:08:20.652470  3702 sgd_solver.cpp:105] Iteration 63300, lr = 0.01
I1006 19:08:28.985760  3702 solver.cpp:218] Iteration 63400 (12.0001 iter/s, 8.33327s/100 iters), loss = 0.00319206
I1006 19:08:28.985800  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.003192 (* 1 = 0.003192 loss)
I1006 19:08:28.985806  3702 sgd_solver.cpp:105] Iteration 63400, lr = 0.01
I1006 19:08:36.908725  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:08:37.242713  3702 solver.cpp:330] Iteration 63500, Testing net (#0)
I1006 19:08:39.168262  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:08:39.248860  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9155
I1006 19:08:39.248895  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.352062 (* 1 = 0.352062 loss)
I1006 19:08:39.332633  3702 solver.cpp:218] Iteration 63500 (9.66482 iter/s, 10.3468s/100 iters), loss = 0.0105773
I1006 19:08:39.332660  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0105773 (* 1 = 0.0105773 loss)
I1006 19:08:39.332667  3702 sgd_solver.cpp:105] Iteration 63500, lr = 0.01
I1006 19:08:47.669737  3702 solver.cpp:218] Iteration 63600 (11.9946 iter/s, 8.33705s/100 iters), loss = 0.00449507
I1006 19:08:47.669880  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00449502 (* 1 = 0.00449502 loss)
I1006 19:08:47.669888  3702 sgd_solver.cpp:105] Iteration 63600, lr = 0.01
I1006 19:08:56.000517  3702 solver.cpp:218] Iteration 63700 (12.0039 iter/s, 8.33062s/100 iters), loss = 0.0026329
I1006 19:08:56.000557  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00263285 (* 1 = 0.00263285 loss)
I1006 19:08:56.000562  3702 sgd_solver.cpp:105] Iteration 63700, lr = 0.01
I1006 19:09:04.337705  3702 solver.cpp:218] Iteration 63800 (11.9945 iter/s, 8.33712s/100 iters), loss = 0.0467912
I1006 19:09:04.337733  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0467912 (* 1 = 0.0467912 loss)
I1006 19:09:04.337739  3702 sgd_solver.cpp:105] Iteration 63800, lr = 0.01
I1006 19:09:12.673166  3702 solver.cpp:218] Iteration 63900 (11.997 iter/s, 8.33541s/100 iters), loss = 0.0444084
I1006 19:09:12.673205  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0444083 (* 1 = 0.0444083 loss)
I1006 19:09:12.673211  3702 sgd_solver.cpp:105] Iteration 63900, lr = 0.01
I1006 19:09:20.595381  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:09:20.929512  3702 solver.cpp:330] Iteration 64000, Testing net (#0)
I1006 19:09:22.855617  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:09:22.936617  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9162
I1006 19:09:22.936651  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.339494 (* 1 = 0.339494 loss)
I1006 19:09:23.018990  3702 solver.cpp:218] Iteration 64000 (9.6658 iter/s, 10.3458s/100 iters), loss = 0.00545833
I1006 19:09:23.019014  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00545828 (* 1 = 0.00545828 loss)
I1006 19:09:23.019021  3702 sgd_solver.cpp:105] Iteration 64000, lr = 0.01
I1006 19:09:31.353993  3702 solver.cpp:218] Iteration 64100 (11.9977 iter/s, 8.33495s/100 iters), loss = 0.0129579
I1006 19:09:31.354032  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0129578 (* 1 = 0.0129578 loss)
I1006 19:09:31.354038  3702 sgd_solver.cpp:105] Iteration 64100, lr = 0.01
I1006 19:09:39.696135  3702 solver.cpp:218] Iteration 64200 (11.9874 iter/s, 8.34208s/100 iters), loss = 0.00293564
I1006 19:09:39.696174  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0029356 (* 1 = 0.0029356 loss)
I1006 19:09:39.696180  3702 sgd_solver.cpp:105] Iteration 64200, lr = 0.01
I1006 19:09:48.035228  3702 solver.cpp:218] Iteration 64300 (11.9918 iter/s, 8.33903s/100 iters), loss = 0.0570613
I1006 19:09:48.035257  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0570612 (* 1 = 0.0570612 loss)
I1006 19:09:48.035264  3702 sgd_solver.cpp:105] Iteration 64300, lr = 0.01
I1006 19:09:56.373965  3702 solver.cpp:218] Iteration 64400 (11.9923 iter/s, 8.33868s/100 iters), loss = 0.00231611
I1006 19:09:56.374102  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00231605 (* 1 = 0.00231605 loss)
I1006 19:09:56.374110  3702 sgd_solver.cpp:105] Iteration 64400, lr = 0.01
I1006 19:10:04.298198  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:10:04.631906  3702 solver.cpp:330] Iteration 64500, Testing net (#0)
I1006 19:10:06.557516  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:10:06.638150  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.919
I1006 19:10:06.638185  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.33387 (* 1 = 0.33387 loss)
I1006 19:10:06.721391  3702 solver.cpp:218] Iteration 64500 (9.66439 iter/s, 10.3473s/100 iters), loss = 0.00623607
I1006 19:10:06.721416  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00623602 (* 1 = 0.00623602 loss)
I1006 19:10:06.721422  3702 sgd_solver.cpp:105] Iteration 64500, lr = 0.01
I1006 19:10:15.066664  3702 solver.cpp:218] Iteration 64600 (11.9829 iter/s, 8.34522s/100 iters), loss = 0.046574
I1006 19:10:15.066694  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.046574 (* 1 = 0.046574 loss)
I1006 19:10:15.066699  3702 sgd_solver.cpp:105] Iteration 64600, lr = 0.01
I1006 19:10:23.405520  3702 solver.cpp:218] Iteration 64700 (11.9921 iter/s, 8.3388s/100 iters), loss = 0.00283773
I1006 19:10:23.405560  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00283767 (* 1 = 0.00283767 loss)
I1006 19:10:23.405565  3702 sgd_solver.cpp:105] Iteration 64700, lr = 0.01
I1006 19:10:31.746160  3702 solver.cpp:218] Iteration 64800 (11.9896 iter/s, 8.34058s/100 iters), loss = 0.00809485
I1006 19:10:31.746294  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00809478 (* 1 = 0.00809478 loss)
I1006 19:10:31.746310  3702 sgd_solver.cpp:105] Iteration 64800, lr = 0.01
I1006 19:10:40.083808  3702 solver.cpp:218] Iteration 64900 (11.994 iter/s, 8.3375s/100 iters), loss = 0.00197896
I1006 19:10:40.083847  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00197889 (* 1 = 0.00197889 loss)
I1006 19:10:40.083853  3702 sgd_solver.cpp:105] Iteration 64900, lr = 0.01
I1006 19:10:48.007735  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:10:48.340968  3702 solver.cpp:330] Iteration 65000, Testing net (#0)
I1006 19:10:50.266645  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:10:50.348114  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9121
I1006 19:10:50.348148  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.362787 (* 1 = 0.362787 loss)
I1006 19:10:50.430999  3702 solver.cpp:218] Iteration 65000 (9.66452 iter/s, 10.3471s/100 iters), loss = 0.00187096
I1006 19:10:50.431025  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00187089 (* 1 = 0.00187089 loss)
I1006 19:10:50.431031  3702 sgd_solver.cpp:105] Iteration 65000, lr = 0.01
I1006 19:10:58.767822  3702 solver.cpp:218] Iteration 65100 (11.995 iter/s, 8.33677s/100 iters), loss = 0.00170254
I1006 19:10:58.767861  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00170247 (* 1 = 0.00170247 loss)
I1006 19:10:58.767868  3702 sgd_solver.cpp:105] Iteration 65100, lr = 0.01
I1006 19:11:07.107513  3702 solver.cpp:218] Iteration 65200 (11.9909 iter/s, 8.33963s/100 iters), loss = 0.00772141
I1006 19:11:07.107650  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00772135 (* 1 = 0.00772135 loss)
I1006 19:11:07.107657  3702 sgd_solver.cpp:105] Iteration 65200, lr = 0.01
I1006 19:11:15.443955  3702 solver.cpp:218] Iteration 65300 (11.9957 iter/s, 8.33629s/100 iters), loss = 0.00666998
I1006 19:11:15.443994  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00666992 (* 1 = 0.00666992 loss)
I1006 19:11:15.444000  3702 sgd_solver.cpp:105] Iteration 65300, lr = 0.01
I1006 19:11:23.789121  3702 solver.cpp:218] Iteration 65400 (11.9831 iter/s, 8.3451s/100 iters), loss = 0.00141101
I1006 19:11:23.789161  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00141096 (* 1 = 0.00141096 loss)
I1006 19:11:23.789167  3702 sgd_solver.cpp:105] Iteration 65400, lr = 0.01
I1006 19:11:31.713743  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:11:32.047425  3702 solver.cpp:330] Iteration 65500, Testing net (#0)
I1006 19:11:33.973191  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:11:34.053619  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9143
I1006 19:11:34.053655  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.358738 (* 1 = 0.358738 loss)
I1006 19:11:34.137125  3702 solver.cpp:218] Iteration 65500 (9.66376 iter/s, 10.3479s/100 iters), loss = 0.0450023
I1006 19:11:34.137151  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0450022 (* 1 = 0.0450022 loss)
I1006 19:11:34.137157  3702 sgd_solver.cpp:105] Iteration 65500, lr = 0.01
I1006 19:11:42.490558  3702 solver.cpp:218] Iteration 65600 (11.9712 iter/s, 8.35338s/100 iters), loss = 0.0164705
I1006 19:11:42.490658  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0164705 (* 1 = 0.0164705 loss)
I1006 19:11:42.490664  3702 sgd_solver.cpp:105] Iteration 65600, lr = 0.01
I1006 19:11:50.833690  3702 solver.cpp:218] Iteration 65700 (11.9861 iter/s, 8.34301s/100 iters), loss = 0.00467249
I1006 19:11:50.833730  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00467244 (* 1 = 0.00467244 loss)
I1006 19:11:50.833736  3702 sgd_solver.cpp:105] Iteration 65700, lr = 0.01
I1006 19:11:59.177093  3702 solver.cpp:218] Iteration 65800 (11.9856 iter/s, 8.34334s/100 iters), loss = 0.00798781
I1006 19:11:59.177134  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00798777 (* 1 = 0.00798777 loss)
I1006 19:11:59.177139  3702 sgd_solver.cpp:105] Iteration 65800, lr = 0.01
I1006 19:12:07.521148  3702 solver.cpp:218] Iteration 65900 (11.9847 iter/s, 8.34399s/100 iters), loss = 0.00354237
I1006 19:12:07.521188  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00354234 (* 1 = 0.00354234 loss)
I1006 19:12:07.521194  3702 sgd_solver.cpp:105] Iteration 65900, lr = 0.01
I1006 19:12:15.455777  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:12:15.788949  3702 solver.cpp:330] Iteration 66000, Testing net (#0)
I1006 19:12:17.715677  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:12:17.796671  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9121
I1006 19:12:17.796706  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.378684 (* 1 = 0.378684 loss)
I1006 19:12:17.878635  3702 solver.cpp:218] Iteration 66000 (9.65491 iter/s, 10.3574s/100 iters), loss = 0.027256
I1006 19:12:17.878667  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.027256 (* 1 = 0.027256 loss)
I1006 19:12:17.878674  3702 sgd_solver.cpp:105] Iteration 66000, lr = 0.01
I1006 19:12:26.215528  3702 solver.cpp:218] Iteration 66100 (11.995 iter/s, 8.33684s/100 iters), loss = 0.00466481
I1006 19:12:26.215565  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00466477 (* 1 = 0.00466477 loss)
I1006 19:12:26.215571  3702 sgd_solver.cpp:105] Iteration 66100, lr = 0.01
I1006 19:12:34.558418  3702 solver.cpp:218] Iteration 66200 (11.9863 iter/s, 8.34283s/100 iters), loss = 0.00208664
I1006 19:12:34.558447  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00208661 (* 1 = 0.00208661 loss)
I1006 19:12:34.558454  3702 sgd_solver.cpp:105] Iteration 66200, lr = 0.01
I1006 19:12:42.897891  3702 solver.cpp:218] Iteration 66300 (11.9912 iter/s, 8.33942s/100 iters), loss = 0.031298
I1006 19:12:42.897938  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.031298 (* 1 = 0.031298 loss)
I1006 19:12:42.897944  3702 sgd_solver.cpp:105] Iteration 66300, lr = 0.01
I1006 19:12:51.235839  3702 solver.cpp:218] Iteration 66400 (11.9934 iter/s, 8.33789s/100 iters), loss = 0.00738173
I1006 19:12:51.235941  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0073817 (* 1 = 0.0073817 loss)
I1006 19:12:51.235950  3702 sgd_solver.cpp:105] Iteration 66400, lr = 0.01
I1006 19:12:59.164181  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:12:59.497835  3702 solver.cpp:330] Iteration 66500, Testing net (#0)
I1006 19:13:01.426327  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:13:01.506979  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9131
I1006 19:13:01.507014  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.35952 (* 1 = 0.35952 loss)
I1006 19:13:01.590107  3702 solver.cpp:218] Iteration 66500 (9.65796 iter/s, 10.3541s/100 iters), loss = 0.0203618
I1006 19:13:01.590135  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0203617 (* 1 = 0.0203617 loss)
I1006 19:13:01.590142  3702 sgd_solver.cpp:105] Iteration 66500, lr = 0.01
I1006 19:13:09.925595  3702 solver.cpp:218] Iteration 66600 (11.997 iter/s, 8.33544s/100 iters), loss = 0.04391
I1006 19:13:09.925626  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0439099 (* 1 = 0.0439099 loss)
I1006 19:13:09.925631  3702 sgd_solver.cpp:105] Iteration 66600, lr = 0.01
I1006 19:13:18.261678  3702 solver.cpp:218] Iteration 66700 (11.9961 iter/s, 8.33603s/100 iters), loss = 0.00385527
I1006 19:13:18.261708  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00385524 (* 1 = 0.00385524 loss)
I1006 19:13:18.261713  3702 sgd_solver.cpp:105] Iteration 66700, lr = 0.01
I1006 19:13:26.601434  3702 solver.cpp:218] Iteration 66800 (11.9908 iter/s, 8.3397s/100 iters), loss = 0.00700459
I1006 19:13:26.601577  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00700456 (* 1 = 0.00700456 loss)
I1006 19:13:26.601596  3702 sgd_solver.cpp:105] Iteration 66800, lr = 0.01
I1006 19:13:34.930371  3702 solver.cpp:218] Iteration 66900 (12.0066 iter/s, 8.32877s/100 iters), loss = 0.0129152
I1006 19:13:34.930399  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0129152 (* 1 = 0.0129152 loss)
I1006 19:13:34.930405  3702 sgd_solver.cpp:105] Iteration 66900, lr = 0.01
I1006 19:13:42.855129  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:13:43.189548  3702 solver.cpp:330] Iteration 67000, Testing net (#0)
I1006 19:13:45.116219  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:13:45.196167  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.912
I1006 19:13:45.196193  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.36562 (* 1 = 0.36562 loss)
I1006 19:13:45.279265  3702 solver.cpp:218] Iteration 67000 (9.66292 iter/s, 10.3488s/100 iters), loss = 0.00369964
I1006 19:13:45.279297  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00369962 (* 1 = 0.00369962 loss)
I1006 19:13:45.279304  3702 sgd_solver.cpp:105] Iteration 67000, lr = 0.01
I1006 19:13:53.608191  3702 solver.cpp:218] Iteration 67100 (12.0064 iter/s, 8.32887s/100 iters), loss = 0.00277494
I1006 19:13:53.608232  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00277491 (* 1 = 0.00277491 loss)
I1006 19:13:53.608237  3702 sgd_solver.cpp:105] Iteration 67100, lr = 0.01
I1006 19:14:01.947685  3702 solver.cpp:218] Iteration 67200 (11.9912 iter/s, 8.33943s/100 iters), loss = 0.0146365
I1006 19:14:01.947758  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0146365 (* 1 = 0.0146365 loss)
I1006 19:14:01.947775  3702 sgd_solver.cpp:105] Iteration 67200, lr = 0.01
I1006 19:14:10.277830  3702 solver.cpp:218] Iteration 67300 (12.0047 iter/s, 8.33005s/100 iters), loss = 0.0114253
I1006 19:14:10.277859  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0114253 (* 1 = 0.0114253 loss)
I1006 19:14:10.277865  3702 sgd_solver.cpp:105] Iteration 67300, lr = 0.01
I1006 19:14:18.605824  3702 solver.cpp:218] Iteration 67400 (12.0078 iter/s, 8.32794s/100 iters), loss = 0.00271754
I1006 19:14:18.605864  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00271751 (* 1 = 0.00271751 loss)
I1006 19:14:18.605870  3702 sgd_solver.cpp:105] Iteration 67400, lr = 0.01
I1006 19:14:26.520265  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:14:26.853530  3702 solver.cpp:330] Iteration 67500, Testing net (#0)
I1006 19:14:28.779677  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:14:28.859995  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9134
I1006 19:14:28.860029  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.367561 (* 1 = 0.367561 loss)
I1006 19:14:28.943755  3702 solver.cpp:218] Iteration 67500 (9.67318 iter/s, 10.3379s/100 iters), loss = 0.0174135
I1006 19:14:28.943783  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0174135 (* 1 = 0.0174135 loss)
I1006 19:14:28.943789  3702 sgd_solver.cpp:105] Iteration 67500, lr = 0.01
I1006 19:14:37.286274  3702 solver.cpp:218] Iteration 67600 (11.9869 iter/s, 8.34247s/100 iters), loss = 0.00386021
I1006 19:14:37.286423  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00386019 (* 1 = 0.00386019 loss)
I1006 19:14:37.286432  3702 sgd_solver.cpp:105] Iteration 67600, lr = 0.01
I1006 19:14:45.625169  3702 solver.cpp:218] Iteration 67700 (11.9922 iter/s, 8.33873s/100 iters), loss = 0.0352662
I1006 19:14:45.625198  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0352661 (* 1 = 0.0352661 loss)
I1006 19:14:45.625205  3702 sgd_solver.cpp:105] Iteration 67700, lr = 0.01
I1006 19:14:53.970203  3702 solver.cpp:218] Iteration 67800 (11.9832 iter/s, 8.34498s/100 iters), loss = 0.00808951
I1006 19:14:53.970242  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00808948 (* 1 = 0.00808948 loss)
I1006 19:14:53.970247  3702 sgd_solver.cpp:105] Iteration 67800, lr = 0.01
I1006 19:15:02.308650  3702 solver.cpp:218] Iteration 67900 (11.9927 iter/s, 8.33838s/100 iters), loss = 0.00856236
I1006 19:15:02.308681  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00856234 (* 1 = 0.00856234 loss)
I1006 19:15:02.308688  3702 sgd_solver.cpp:105] Iteration 67900, lr = 0.01
I1006 19:15:10.236609  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:15:10.569123  3702 solver.cpp:330] Iteration 68000, Testing net (#0)
I1006 19:15:12.496593  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:15:12.577226  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9127
I1006 19:15:12.577251  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.347507 (* 1 = 0.347507 loss)
I1006 19:15:12.659955  3702 solver.cpp:218] Iteration 68000 (9.66067 iter/s, 10.3512s/100 iters), loss = 0.00674724
I1006 19:15:12.659981  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00674722 (* 1 = 0.00674722 loss)
I1006 19:15:12.659986  3702 sgd_solver.cpp:105] Iteration 68000, lr = 0.01
I1006 19:15:20.992682  3702 solver.cpp:218] Iteration 68100 (12.0009 iter/s, 8.33268s/100 iters), loss = 0.0212897
I1006 19:15:20.992712  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0212897 (* 1 = 0.0212897 loss)
I1006 19:15:20.992717  3702 sgd_solver.cpp:105] Iteration 68100, lr = 0.01
I1006 19:15:29.333865  3702 solver.cpp:218] Iteration 68200 (11.9888 iter/s, 8.34113s/100 iters), loss = 0.00669155
I1006 19:15:29.333894  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00669154 (* 1 = 0.00669154 loss)
I1006 19:15:29.333900  3702 sgd_solver.cpp:105] Iteration 68200, lr = 0.01
I1006 19:15:37.667573  3702 solver.cpp:218] Iteration 68300 (11.9995 iter/s, 8.33366s/100 iters), loss = 0.0026746
I1006 19:15:37.667603  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00267457 (* 1 = 0.00267457 loss)
I1006 19:15:37.667609  3702 sgd_solver.cpp:105] Iteration 68300, lr = 0.01
I1006 19:15:46.003226  3702 solver.cpp:218] Iteration 68400 (11.9967 iter/s, 8.3356s/100 iters), loss = 0.00294804
I1006 19:15:46.003329  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00294802 (* 1 = 0.00294802 loss)
I1006 19:15:46.003338  3702 sgd_solver.cpp:105] Iteration 68400, lr = 0.01
I1006 19:15:53.923663  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:15:54.257647  3702 solver.cpp:330] Iteration 68500, Testing net (#0)
I1006 19:15:56.184247  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:15:56.264559  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9176
I1006 19:15:56.264583  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.337841 (* 1 = 0.337841 loss)
I1006 19:15:56.348583  3702 solver.cpp:218] Iteration 68500 (9.66629 iter/s, 10.3452s/100 iters), loss = 0.0155755
I1006 19:15:56.348610  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0155754 (* 1 = 0.0155754 loss)
I1006 19:15:56.348618  3702 sgd_solver.cpp:105] Iteration 68500, lr = 0.01
I1006 19:16:04.695263  3702 solver.cpp:218] Iteration 68600 (11.9809 iter/s, 8.34663s/100 iters), loss = 0.00495625
I1006 19:16:04.695293  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00495622 (* 1 = 0.00495622 loss)
I1006 19:16:04.695299  3702 sgd_solver.cpp:105] Iteration 68600, lr = 0.01
I1006 19:16:13.038277  3702 solver.cpp:218] Iteration 68700 (11.9862 iter/s, 8.34296s/100 iters), loss = 0.0161096
I1006 19:16:13.038306  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0161096 (* 1 = 0.0161096 loss)
I1006 19:16:13.038312  3702 sgd_solver.cpp:105] Iteration 68700, lr = 0.01
I1006 19:16:21.385329  3702 solver.cpp:218] Iteration 68800 (11.9804 iter/s, 8.347s/100 iters), loss = 0.0021572
I1006 19:16:21.385444  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00215718 (* 1 = 0.00215718 loss)
I1006 19:16:21.385462  3702 sgd_solver.cpp:105] Iteration 68800, lr = 0.01
I1006 19:16:29.726202  3702 solver.cpp:218] Iteration 68900 (11.9894 iter/s, 8.34074s/100 iters), loss = 0.000885937
I1006 19:16:29.726243  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000885914 (* 1 = 0.000885914 loss)
I1006 19:16:29.726248  3702 sgd_solver.cpp:105] Iteration 68900, lr = 0.01
I1006 19:16:37.659816  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:16:37.994155  3702 solver.cpp:330] Iteration 69000, Testing net (#0)
I1006 19:16:39.920918  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:16:40.001715  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9148
I1006 19:16:40.001751  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.346125 (* 1 = 0.346125 loss)
I1006 19:16:40.084355  3702 solver.cpp:218] Iteration 69000 (9.65429 iter/s, 10.3581s/100 iters), loss = 0.00345776
I1006 19:16:40.084393  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00345774 (* 1 = 0.00345774 loss)
I1006 19:16:40.084400  3702 sgd_solver.cpp:105] Iteration 69000, lr = 0.01
I1006 19:16:48.426564  3702 solver.cpp:218] Iteration 69100 (11.9873 iter/s, 8.34215s/100 iters), loss = 0.00373438
I1006 19:16:48.426594  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00373436 (* 1 = 0.00373436 loss)
I1006 19:16:48.426599  3702 sgd_solver.cpp:105] Iteration 69100, lr = 0.01
I1006 19:16:56.767186  3702 solver.cpp:218] Iteration 69200 (11.9896 iter/s, 8.34055s/100 iters), loss = 0.00637233
I1006 19:16:56.767333  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00637231 (* 1 = 0.00637231 loss)
I1006 19:16:56.767339  3702 sgd_solver.cpp:105] Iteration 69200, lr = 0.01
I1006 19:17:05.107167  3702 solver.cpp:218] Iteration 69300 (11.9907 iter/s, 8.33982s/100 iters), loss = 0.00204008
I1006 19:17:05.107194  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00204007 (* 1 = 0.00204007 loss)
I1006 19:17:05.107200  3702 sgd_solver.cpp:105] Iteration 69300, lr = 0.01
I1006 19:17:13.454352  3702 solver.cpp:218] Iteration 69400 (11.9802 iter/s, 8.34713s/100 iters), loss = 0.00429973
I1006 19:17:13.454391  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00429972 (* 1 = 0.00429972 loss)
I1006 19:17:13.454397  3702 sgd_solver.cpp:105] Iteration 69400, lr = 0.01
I1006 19:17:21.385327  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:17:21.720129  3702 solver.cpp:330] Iteration 69500, Testing net (#0)
I1006 19:17:23.646260  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:17:23.726874  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.913
I1006 19:17:23.726908  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.367271 (* 1 = 0.367271 loss)
I1006 19:17:23.810295  3702 solver.cpp:218] Iteration 69500 (9.65635 iter/s, 10.3559s/100 iters), loss = 0.00306395
I1006 19:17:23.810322  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00306394 (* 1 = 0.00306394 loss)
I1006 19:17:23.810329  3702 sgd_solver.cpp:105] Iteration 69500, lr = 0.01
I1006 19:17:32.155763  3702 solver.cpp:218] Iteration 69600 (11.9826 iter/s, 8.34542s/100 iters), loss = 0.0232923
I1006 19:17:32.155860  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0232923 (* 1 = 0.0232923 loss)
I1006 19:17:32.155876  3702 sgd_solver.cpp:105] Iteration 69600, lr = 0.01
I1006 19:17:40.496047  3702 solver.cpp:218] Iteration 69700 (11.9902 iter/s, 8.34017s/100 iters), loss = 0.00579245
I1006 19:17:40.496086  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00579244 (* 1 = 0.00579244 loss)
I1006 19:17:40.496093  3702 sgd_solver.cpp:105] Iteration 69700, lr = 0.01
I1006 19:17:48.841415  3702 solver.cpp:218] Iteration 69800 (11.9828 iter/s, 8.34531s/100 iters), loss = 0.0121939
I1006 19:17:48.841444  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0121939 (* 1 = 0.0121939 loss)
I1006 19:17:48.841449  3702 sgd_solver.cpp:105] Iteration 69800, lr = 0.01
I1006 19:17:57.178993  3702 solver.cpp:218] Iteration 69900 (11.994 iter/s, 8.33753s/100 iters), loss = 0.0106
I1006 19:17:57.179033  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0106 (* 1 = 0.0106 loss)
I1006 19:17:57.179039  3702 sgd_solver.cpp:105] Iteration 69900, lr = 0.01
I1006 19:18:05.113113  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:18:05.447139  3702 solver.cpp:330] Iteration 70000, Testing net (#0)
I1006 19:18:07.374176  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:18:07.455127  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9148
I1006 19:18:07.455162  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.347444 (* 1 = 0.347444 loss)
I1006 19:18:07.537770  3702 solver.cpp:218] Iteration 70000 (9.65371 iter/s, 10.3587s/100 iters), loss = 0.00563422
I1006 19:18:07.537794  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00563422 (* 1 = 0.00563422 loss)
I1006 19:18:07.537801  3702 sgd_solver.cpp:105] Iteration 70000, lr = 0.01
I1006 19:18:15.867873  3702 solver.cpp:218] Iteration 70100 (12.0047 iter/s, 8.33005s/100 iters), loss = 0.0164591
I1006 19:18:15.867913  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0164591 (* 1 = 0.0164591 loss)
I1006 19:18:15.867918  3702 sgd_solver.cpp:105] Iteration 70100, lr = 0.01
I1006 19:18:24.205531  3702 solver.cpp:218] Iteration 70200 (11.9939 iter/s, 8.3376s/100 iters), loss = 0.0065064
I1006 19:18:24.205571  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00650641 (* 1 = 0.00650641 loss)
I1006 19:18:24.205577  3702 sgd_solver.cpp:105] Iteration 70200, lr = 0.01
I1006 19:18:32.539726  3702 solver.cpp:218] Iteration 70300 (11.9988 iter/s, 8.33413s/100 iters), loss = 0.00379496
I1006 19:18:32.539765  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00379496 (* 1 = 0.00379496 loss)
I1006 19:18:32.539772  3702 sgd_solver.cpp:105] Iteration 70300, lr = 0.01
I1006 19:18:40.879230  3702 solver.cpp:218] Iteration 70400 (11.9912 iter/s, 8.33944s/100 iters), loss = 0.0144535
I1006 19:18:40.879333  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0144535 (* 1 = 0.0144535 loss)
I1006 19:18:40.879348  3702 sgd_solver.cpp:105] Iteration 70400, lr = 0.01
I1006 19:18:48.806689  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:18:49.140529  3702 solver.cpp:330] Iteration 70500, Testing net (#0)
I1006 19:18:51.067207  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:18:51.147512  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9175
I1006 19:18:51.147536  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.338617 (* 1 = 0.338617 loss)
I1006 19:18:51.230605  3702 solver.cpp:218] Iteration 70500 (9.66067 iter/s, 10.3512s/100 iters), loss = 0.00668418
I1006 19:18:51.230633  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0066842 (* 1 = 0.0066842 loss)
I1006 19:18:51.230639  3702 sgd_solver.cpp:105] Iteration 70500, lr = 0.01
I1006 19:18:59.570909  3702 solver.cpp:218] Iteration 70600 (11.9901 iter/s, 8.34021s/100 iters), loss = 0.0358313
I1006 19:18:59.570936  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0358313 (* 1 = 0.0358313 loss)
I1006 19:18:59.570942  3702 sgd_solver.cpp:105] Iteration 70600, lr = 0.01
I1006 19:19:07.907153  3702 solver.cpp:218] Iteration 70700 (11.9959 iter/s, 8.33619s/100 iters), loss = 0.00703969
I1006 19:19:07.907186  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00703969 (* 1 = 0.00703969 loss)
I1006 19:19:07.907202  3702 sgd_solver.cpp:105] Iteration 70700, lr = 0.01
I1006 19:19:16.242446  3702 solver.cpp:218] Iteration 70800 (11.9973 iter/s, 8.33524s/100 iters), loss = 0.00522505
I1006 19:19:16.242570  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00522505 (* 1 = 0.00522505 loss)
I1006 19:19:16.242578  3702 sgd_solver.cpp:105] Iteration 70800, lr = 0.01
I1006 19:19:24.579121  3702 solver.cpp:218] Iteration 70900 (11.9954 iter/s, 8.33653s/100 iters), loss = 0.00741801
I1006 19:19:24.579160  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.007418 (* 1 = 0.007418 loss)
I1006 19:19:24.579167  3702 sgd_solver.cpp:105] Iteration 70900, lr = 0.01
I1006 19:19:32.505642  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:19:32.839818  3702 solver.cpp:330] Iteration 71000, Testing net (#0)
I1006 19:19:34.766099  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:19:34.847012  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9131
I1006 19:19:34.847046  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.346959 (* 1 = 0.346959 loss)
I1006 19:19:34.929678  3702 solver.cpp:218] Iteration 71000 (9.66138 iter/s, 10.3505s/100 iters), loss = 0.0231263
I1006 19:19:34.929703  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0231263 (* 1 = 0.0231263 loss)
I1006 19:19:34.929710  3702 sgd_solver.cpp:105] Iteration 71000, lr = 0.01
I1006 19:19:43.262476  3702 solver.cpp:218] Iteration 71100 (12.0008 iter/s, 8.33275s/100 iters), loss = 0.00174169
I1006 19:19:43.262506  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00174168 (* 1 = 0.00174168 loss)
I1006 19:19:43.262511  3702 sgd_solver.cpp:105] Iteration 71100, lr = 0.01
I1006 19:19:51.597276  3702 solver.cpp:218] Iteration 71200 (11.998 iter/s, 8.33475s/100 iters), loss = 0.0142062
I1006 19:19:51.597388  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0142061 (* 1 = 0.0142061 loss)
I1006 19:19:51.597394  3702 sgd_solver.cpp:105] Iteration 71200, lr = 0.01
I1006 19:19:59.938788  3702 solver.cpp:218] Iteration 71300 (11.9884 iter/s, 8.34139s/100 iters), loss = 0.0102097
I1006 19:19:59.938817  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0102097 (* 1 = 0.0102097 loss)
I1006 19:19:59.938822  3702 sgd_solver.cpp:105] Iteration 71300, lr = 0.01
I1006 19:20:08.281054  3702 solver.cpp:218] Iteration 71400 (11.9872 iter/s, 8.34221s/100 iters), loss = 0.00600708
I1006 19:20:08.281083  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00600707 (* 1 = 0.00600707 loss)
I1006 19:20:08.281088  3702 sgd_solver.cpp:105] Iteration 71400, lr = 0.01
I1006 19:20:16.205199  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:20:16.539306  3702 solver.cpp:330] Iteration 71500, Testing net (#0)
I1006 19:20:18.466193  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:20:18.547096  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.918
I1006 19:20:18.547130  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.345321 (* 1 = 0.345321 loss)
I1006 19:20:18.630868  3702 solver.cpp:218] Iteration 71500 (9.66206 iter/s, 10.3498s/100 iters), loss = 0.0300949
I1006 19:20:18.630895  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0300949 (* 1 = 0.0300949 loss)
I1006 19:20:18.630901  3702 sgd_solver.cpp:105] Iteration 71500, lr = 0.01
I1006 19:20:26.976608  3702 solver.cpp:218] Iteration 71600 (11.9823 iter/s, 8.34565s/100 iters), loss = 0.0260123
I1006 19:20:26.976734  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0260123 (* 1 = 0.0260123 loss)
I1006 19:20:26.976752  3702 sgd_solver.cpp:105] Iteration 71600, lr = 0.01
I1006 19:20:35.309064  3702 solver.cpp:218] Iteration 71700 (12.0015 iter/s, 8.33232s/100 iters), loss = 0.0149123
I1006 19:20:35.309092  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0149123 (* 1 = 0.0149123 loss)
I1006 19:20:35.309098  3702 sgd_solver.cpp:105] Iteration 71700, lr = 0.01
I1006 19:20:43.647972  3702 solver.cpp:218] Iteration 71800 (11.9921 iter/s, 8.33886s/100 iters), loss = 0.00479713
I1006 19:20:43.648001  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00479714 (* 1 = 0.00479714 loss)
I1006 19:20:43.648007  3702 sgd_solver.cpp:105] Iteration 71800, lr = 0.01
I1006 19:20:51.983806  3702 solver.cpp:218] Iteration 71900 (11.9965 iter/s, 8.33578s/100 iters), loss = 0.0351384
I1006 19:20:51.983845  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0351384 (* 1 = 0.0351384 loss)
I1006 19:20:51.983851  3702 sgd_solver.cpp:105] Iteration 71900, lr = 0.01
I1006 19:20:59.910640  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:21:00.244818  3702 solver.cpp:330] Iteration 72000, Testing net (#0)
I1006 19:21:02.171578  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:21:02.252533  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9158
I1006 19:21:02.252568  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.346656 (* 1 = 0.346656 loss)
I1006 19:21:02.335147  3702 solver.cpp:218] Iteration 72000 (9.66065 iter/s, 10.3513s/100 iters), loss = 0.0138675
I1006 19:21:02.335194  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0138675 (* 1 = 0.0138675 loss)
I1006 19:21:02.335201  3702 sgd_solver.cpp:105] Iteration 72000, lr = 0.01
I1006 19:21:10.673635  3702 solver.cpp:218] Iteration 72100 (11.9927 iter/s, 8.33843s/100 iters), loss = 0.00731519
I1006 19:21:10.673665  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00731519 (* 1 = 0.00731519 loss)
I1006 19:21:10.673671  3702 sgd_solver.cpp:105] Iteration 72100, lr = 0.01
I1006 19:21:19.018493  3702 solver.cpp:218] Iteration 72200 (11.9835 iter/s, 8.34481s/100 iters), loss = 0.00427195
I1006 19:21:19.018520  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00427197 (* 1 = 0.00427197 loss)
I1006 19:21:19.018527  3702 sgd_solver.cpp:105] Iteration 72200, lr = 0.01
I1006 19:21:27.354039  3702 solver.cpp:218] Iteration 72300 (11.9969 iter/s, 8.33549s/100 iters), loss = 0.0124651
I1006 19:21:27.354068  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0124651 (* 1 = 0.0124651 loss)
I1006 19:21:27.354074  3702 sgd_solver.cpp:105] Iteration 72300, lr = 0.01
I1006 19:21:35.694509  3702 solver.cpp:218] Iteration 72400 (11.9898 iter/s, 8.34042s/100 iters), loss = 0.0136047
I1006 19:21:35.694630  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0136047 (* 1 = 0.0136047 loss)
I1006 19:21:35.694648  3702 sgd_solver.cpp:105] Iteration 72400, lr = 0.01
I1006 19:21:43.620040  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:21:43.953416  3702 solver.cpp:330] Iteration 72500, Testing net (#0)
I1006 19:21:45.880439  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:21:45.960868  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9115
I1006 19:21:45.960904  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.361982 (* 1 = 0.361982 loss)
I1006 19:21:46.044440  3702 solver.cpp:218] Iteration 72500 (9.66204 iter/s, 10.3498s/100 iters), loss = 0.0141729
I1006 19:21:46.044474  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0141729 (* 1 = 0.0141729 loss)
I1006 19:21:46.044481  3702 sgd_solver.cpp:105] Iteration 72500, lr = 0.01
I1006 19:21:54.380091  3702 solver.cpp:218] Iteration 72600 (11.9967 iter/s, 8.33559s/100 iters), loss = 0.00455252
I1006 19:21:54.380120  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00455253 (* 1 = 0.00455253 loss)
I1006 19:21:54.380125  3702 sgd_solver.cpp:105] Iteration 72600, lr = 0.01
I1006 19:22:02.702540  3702 solver.cpp:218] Iteration 72700 (12.0158 iter/s, 8.3224s/100 iters), loss = 0.00964641
I1006 19:22:02.702569  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00964643 (* 1 = 0.00964643 loss)
I1006 19:22:02.702574  3702 sgd_solver.cpp:105] Iteration 72700, lr = 0.01
I1006 19:22:11.030158  3702 solver.cpp:218] Iteration 72800 (12.0083 iter/s, 8.32757s/100 iters), loss = 0.0152917
I1006 19:22:11.030282  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0152917 (* 1 = 0.0152917 loss)
I1006 19:22:11.030287  3702 sgd_solver.cpp:105] Iteration 72800, lr = 0.01
I1006 19:22:19.359839  3702 solver.cpp:218] Iteration 72900 (12.0055 iter/s, 8.32953s/100 iters), loss = 0.00916917
I1006 19:22:19.359869  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0091692 (* 1 = 0.0091692 loss)
I1006 19:22:19.359874  3702 sgd_solver.cpp:105] Iteration 72900, lr = 0.01
I1006 19:22:27.284401  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:22:27.617404  3702 solver.cpp:330] Iteration 73000, Testing net (#0)
I1006 19:22:29.544828  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:22:29.625926  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9135
I1006 19:22:29.625959  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.358841 (* 1 = 0.358841 loss)
I1006 19:22:29.709009  3702 solver.cpp:218] Iteration 73000 (9.66266 iter/s, 10.3491s/100 iters), loss = 0.0380835
I1006 19:22:29.709043  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0380835 (* 1 = 0.0380835 loss)
I1006 19:22:29.709050  3702 sgd_solver.cpp:105] Iteration 73000, lr = 0.01
I1006 19:22:38.047545  3702 solver.cpp:218] Iteration 73100 (11.9926 iter/s, 8.33848s/100 iters), loss = 0.0595221
I1006 19:22:38.047586  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0595221 (* 1 = 0.0595221 loss)
I1006 19:22:38.047592  3702 sgd_solver.cpp:105] Iteration 73100, lr = 0.01
I1006 19:22:46.393096  3702 solver.cpp:218] Iteration 73200 (11.9825 iter/s, 8.34548s/100 iters), loss = 0.000662821
I1006 19:22:46.393182  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000662842 (* 1 = 0.000662842 loss)
I1006 19:22:46.393198  3702 sgd_solver.cpp:105] Iteration 73200, lr = 0.01
I1006 19:22:54.737124  3702 solver.cpp:218] Iteration 73300 (11.9848 iter/s, 8.34392s/100 iters), loss = 0.00250366
I1006 19:22:54.737154  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00250367 (* 1 = 0.00250367 loss)
I1006 19:22:54.737159  3702 sgd_solver.cpp:105] Iteration 73300, lr = 0.01
I1006 19:23:03.083729  3702 solver.cpp:218] Iteration 73400 (11.981 iter/s, 8.34655s/100 iters), loss = 0.00616831
I1006 19:23:03.083767  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00616831 (* 1 = 0.00616831 loss)
I1006 19:23:03.083773  3702 sgd_solver.cpp:105] Iteration 73400, lr = 0.01
I1006 19:23:11.012708  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:23:11.346726  3702 solver.cpp:330] Iteration 73500, Testing net (#0)
I1006 19:23:13.273564  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:23:13.354332  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9124
I1006 19:23:13.354367  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.387249 (* 1 = 0.387249 loss)
I1006 19:23:13.438158  3702 solver.cpp:218] Iteration 73500 (9.65777 iter/s, 10.3544s/100 iters), loss = 0.00508317
I1006 19:23:13.438206  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00508317 (* 1 = 0.00508317 loss)
I1006 19:23:13.438215  3702 sgd_solver.cpp:105] Iteration 73500, lr = 0.01
I1006 19:23:21.783716  3702 solver.cpp:218] Iteration 73600 (11.9825 iter/s, 8.34549s/100 iters), loss = 0.00317579
I1006 19:23:21.783829  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00317578 (* 1 = 0.00317578 loss)
I1006 19:23:21.783846  3702 sgd_solver.cpp:105] Iteration 73600, lr = 0.01
I1006 19:23:30.120607  3702 solver.cpp:218] Iteration 73700 (11.9951 iter/s, 8.33676s/100 iters), loss = 0.0029892
I1006 19:23:30.120637  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00298919 (* 1 = 0.00298919 loss)
I1006 19:23:30.120643  3702 sgd_solver.cpp:105] Iteration 73700, lr = 0.01
I1006 19:23:38.461283  3702 solver.cpp:218] Iteration 73800 (11.9895 iter/s, 8.34062s/100 iters), loss = 0.00176356
I1006 19:23:38.461311  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00176356 (* 1 = 0.00176356 loss)
I1006 19:23:38.461318  3702 sgd_solver.cpp:105] Iteration 73800, lr = 0.01
I1006 19:23:46.794975  3702 solver.cpp:218] Iteration 73900 (11.9996 iter/s, 8.33364s/100 iters), loss = 0.00951673
I1006 19:23:46.795014  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00951674 (* 1 = 0.00951674 loss)
I1006 19:23:46.795020  3702 sgd_solver.cpp:105] Iteration 73900, lr = 0.01
I1006 19:23:54.722425  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:23:55.056493  3702 solver.cpp:330] Iteration 74000, Testing net (#0)
I1006 19:23:56.982336  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:23:57.063019  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9096
I1006 19:23:57.063053  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.390486 (* 1 = 0.390486 loss)
I1006 19:23:57.145387  3702 solver.cpp:218] Iteration 74000 (9.66151 iter/s, 10.3503s/100 iters), loss = 0.00845526
I1006 19:23:57.145414  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00845527 (* 1 = 0.00845527 loss)
I1006 19:23:57.145421  3702 sgd_solver.cpp:105] Iteration 74000, lr = 0.01
I1006 19:24:05.480983  3702 solver.cpp:218] Iteration 74100 (11.9968 iter/s, 8.33554s/100 iters), loss = 0.0274602
I1006 19:24:05.481010  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0274602 (* 1 = 0.0274602 loss)
I1006 19:24:05.481016  3702 sgd_solver.cpp:105] Iteration 74100, lr = 0.01
I1006 19:24:13.826123  3702 solver.cpp:218] Iteration 74200 (11.9831 iter/s, 8.34509s/100 iters), loss = 0.0105802
I1006 19:24:13.826164  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0105802 (* 1 = 0.0105802 loss)
I1006 19:24:13.826169  3702 sgd_solver.cpp:105] Iteration 74200, lr = 0.01
I1006 19:24:22.160748  3702 solver.cpp:218] Iteration 74300 (11.9982 iter/s, 8.33456s/100 iters), loss = 0.0225412
I1006 19:24:22.160776  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0225413 (* 1 = 0.0225413 loss)
I1006 19:24:22.160782  3702 sgd_solver.cpp:105] Iteration 74300, lr = 0.01
I1006 19:24:30.501926  3702 solver.cpp:218] Iteration 74400 (11.9888 iter/s, 8.34112s/100 iters), loss = 0.00593589
I1006 19:24:30.502068  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0059359 (* 1 = 0.0059359 loss)
I1006 19:24:30.502076  3702 sgd_solver.cpp:105] Iteration 74400, lr = 0.01
I1006 19:24:38.427950  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:24:38.762497  3702 solver.cpp:330] Iteration 74500, Testing net (#0)
I1006 19:24:40.688127  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:24:40.768858  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9153
I1006 19:24:40.768894  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.354663 (* 1 = 0.354663 loss)
I1006 19:24:40.852538  3702 solver.cpp:218] Iteration 74500 (9.66142 iter/s, 10.3504s/100 iters), loss = 0.00413391
I1006 19:24:40.852567  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00413393 (* 1 = 0.00413393 loss)
I1006 19:24:40.852573  3702 sgd_solver.cpp:105] Iteration 74500, lr = 0.01
I1006 19:24:49.196494  3702 solver.cpp:218] Iteration 74600 (11.9848 iter/s, 8.3439s/100 iters), loss = 0.00660075
I1006 19:24:49.196523  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00660075 (* 1 = 0.00660075 loss)
I1006 19:24:49.196529  3702 sgd_solver.cpp:105] Iteration 74600, lr = 0.01
I1006 19:24:57.532881  3702 solver.cpp:218] Iteration 74700 (11.9957 iter/s, 8.33633s/100 iters), loss = 0.0039522
I1006 19:24:57.532912  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00395221 (* 1 = 0.00395221 loss)
I1006 19:24:57.532917  3702 sgd_solver.cpp:105] Iteration 74700, lr = 0.01
I1006 19:25:05.875668  3702 solver.cpp:218] Iteration 74800 (11.9865 iter/s, 8.34273s/100 iters), loss = 0.0396333
I1006 19:25:05.875798  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0396333 (* 1 = 0.0396333 loss)
I1006 19:25:05.875805  3702 sgd_solver.cpp:105] Iteration 74800, lr = 0.01
I1006 19:25:14.214076  3702 solver.cpp:218] Iteration 74900 (11.9929 iter/s, 8.33826s/100 iters), loss = 0.0142812
I1006 19:25:14.214117  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0142812 (* 1 = 0.0142812 loss)
I1006 19:25:14.214121  3702 sgd_solver.cpp:105] Iteration 74900, lr = 0.01
I1006 19:25:22.144071  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:25:22.478685  3702 solver.cpp:330] Iteration 75000, Testing net (#0)
I1006 19:25:24.405571  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:25:24.486914  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9171
I1006 19:25:24.486949  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.356871 (* 1 = 0.356871 loss)
I1006 19:25:24.569885  3702 solver.cpp:218] Iteration 75000 (9.65648 iter/s, 10.3557s/100 iters), loss = 0.0445701
I1006 19:25:24.569911  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0445701 (* 1 = 0.0445701 loss)
I1006 19:25:24.569917  3702 sgd_solver.cpp:105] Iteration 75000, lr = 0.01
I1006 19:25:32.905787  3702 solver.cpp:218] Iteration 75100 (11.9964 iter/s, 8.33585s/100 iters), loss = 0.0270114
I1006 19:25:32.905827  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0270114 (* 1 = 0.0270114 loss)
I1006 19:25:32.905833  3702 sgd_solver.cpp:105] Iteration 75100, lr = 0.01
I1006 19:25:41.246698  3702 solver.cpp:218] Iteration 75200 (11.9892 iter/s, 8.34085s/100 iters), loss = 0.0121334
I1006 19:25:41.246773  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0121334 (* 1 = 0.0121334 loss)
I1006 19:25:41.246780  3702 sgd_solver.cpp:105] Iteration 75200, lr = 0.01
I1006 19:25:49.587345  3702 solver.cpp:218] Iteration 75300 (11.9896 iter/s, 8.34055s/100 iters), loss = 0.0290675
I1006 19:25:49.587384  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0290675 (* 1 = 0.0290675 loss)
I1006 19:25:49.587390  3702 sgd_solver.cpp:105] Iteration 75300, lr = 0.01
I1006 19:25:57.932715  3702 solver.cpp:218] Iteration 75400 (11.9828 iter/s, 8.34531s/100 iters), loss = 0.011176
I1006 19:25:57.932754  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.011176 (* 1 = 0.011176 loss)
I1006 19:25:57.932760  3702 sgd_solver.cpp:105] Iteration 75400, lr = 0.01
I1006 19:26:05.858095  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:26:06.192876  3702 solver.cpp:330] Iteration 75500, Testing net (#0)
I1006 19:26:08.120070  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:26:08.200325  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9135
I1006 19:26:08.200361  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.365494 (* 1 = 0.365494 loss)
I1006 19:26:08.284353  3702 solver.cpp:218] Iteration 75500 (9.66037 iter/s, 10.3516s/100 iters), loss = 0.00551266
I1006 19:26:08.284386  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00551264 (* 1 = 0.00551264 loss)
I1006 19:26:08.284394  3702 sgd_solver.cpp:105] Iteration 75500, lr = 0.01
I1006 19:26:16.619488  3702 solver.cpp:218] Iteration 75600 (11.9975 iter/s, 8.33508s/100 iters), loss = 0.00167676
I1006 19:26:16.619599  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00167673 (* 1 = 0.00167673 loss)
I1006 19:26:16.619616  3702 sgd_solver.cpp:105] Iteration 75600, lr = 0.01
I1006 19:26:24.946122  3702 solver.cpp:218] Iteration 75700 (12.0098 iter/s, 8.32651s/100 iters), loss = 0.00324392
I1006 19:26:24.946162  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00324388 (* 1 = 0.00324388 loss)
I1006 19:26:24.946167  3702 sgd_solver.cpp:105] Iteration 75700, lr = 0.01
I1006 19:26:33.279458  3702 solver.cpp:218] Iteration 75800 (12.0001 iter/s, 8.33327s/100 iters), loss = 0.0276543
I1006 19:26:33.279494  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0276543 (* 1 = 0.0276543 loss)
I1006 19:26:33.279500  3702 sgd_solver.cpp:105] Iteration 75800, lr = 0.01
I1006 19:26:41.613473  3702 solver.cpp:218] Iteration 75900 (11.9991 iter/s, 8.33395s/100 iters), loss = 0.00613044
I1006 19:26:41.613512  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00613042 (* 1 = 0.00613042 loss)
I1006 19:26:41.613519  3702 sgd_solver.cpp:105] Iteration 75900, lr = 0.01
I1006 19:26:49.537108  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:26:49.871423  3702 solver.cpp:330] Iteration 76000, Testing net (#0)
I1006 19:26:51.797327  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:26:51.878337  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9091
I1006 19:26:51.878372  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.399017 (* 1 = 0.399017 loss)
I1006 19:26:51.960530  3702 solver.cpp:218] Iteration 76000 (9.66465 iter/s, 10.347s/100 iters), loss = 0.00444263
I1006 19:26:51.960554  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00444261 (* 1 = 0.00444261 loss)
I1006 19:26:51.960561  3702 sgd_solver.cpp:105] Iteration 76000, lr = 0.01
I1006 19:27:00.304117  3702 solver.cpp:218] Iteration 76100 (11.9853 iter/s, 8.34354s/100 iters), loss = 0.0031218
I1006 19:27:00.304147  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00312178 (* 1 = 0.00312178 loss)
I1006 19:27:00.304153  3702 sgd_solver.cpp:105] Iteration 76100, lr = 0.01
I1006 19:27:08.653882  3702 solver.cpp:218] Iteration 76200 (11.9765 iter/s, 8.34971s/100 iters), loss = 0.00191842
I1006 19:27:08.653921  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0019184 (* 1 = 0.0019184 loss)
I1006 19:27:08.653926  3702 sgd_solver.cpp:105] Iteration 76200, lr = 0.01
I1006 19:27:16.997262  3702 solver.cpp:218] Iteration 76300 (11.9856 iter/s, 8.34332s/100 iters), loss = 0.0036915
I1006 19:27:16.997301  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00369147 (* 1 = 0.00369147 loss)
I1006 19:27:16.997308  3702 sgd_solver.cpp:105] Iteration 76300, lr = 0.01
I1006 19:27:25.343500  3702 solver.cpp:218] Iteration 76400 (11.9815 iter/s, 8.34618s/100 iters), loss = 0.0013674
I1006 19:27:25.343648  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00136738 (* 1 = 0.00136738 loss)
I1006 19:27:25.343657  3702 sgd_solver.cpp:105] Iteration 76400, lr = 0.01
I1006 19:27:33.271143  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:27:33.605295  3702 solver.cpp:330] Iteration 76500, Testing net (#0)
I1006 19:27:35.532349  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:27:35.613198  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9135
I1006 19:27:35.613234  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.366866 (* 1 = 0.366866 loss)
I1006 19:27:35.696502  3702 solver.cpp:218] Iteration 76500 (9.6592 iter/s, 10.3528s/100 iters), loss = 0.0332431
I1006 19:27:35.696527  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0332431 (* 1 = 0.0332431 loss)
I1006 19:27:35.696534  3702 sgd_solver.cpp:105] Iteration 76500, lr = 0.01
I1006 19:27:44.041563  3702 solver.cpp:218] Iteration 76600 (11.9832 iter/s, 8.34501s/100 iters), loss = 0.0104428
I1006 19:27:44.041602  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0104428 (* 1 = 0.0104428 loss)
I1006 19:27:44.041610  3702 sgd_solver.cpp:105] Iteration 76600, lr = 0.01
I1006 19:27:52.373986  3702 solver.cpp:218] Iteration 76700 (12.0014 iter/s, 8.33236s/100 iters), loss = 0.0378516
I1006 19:27:52.374025  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0378516 (* 1 = 0.0378516 loss)
I1006 19:27:52.374030  3702 sgd_solver.cpp:105] Iteration 76700, lr = 0.01
I1006 19:28:00.714370  3702 solver.cpp:218] Iteration 76800 (11.9899 iter/s, 8.34032s/100 iters), loss = 0.0151587
I1006 19:28:00.714460  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0151587 (* 1 = 0.0151587 loss)
I1006 19:28:00.714469  3702 sgd_solver.cpp:105] Iteration 76800, lr = 0.01
I1006 19:28:09.052191  3702 solver.cpp:218] Iteration 76900 (11.9937 iter/s, 8.33772s/100 iters), loss = 0.00673681
I1006 19:28:09.052219  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00673678 (* 1 = 0.00673678 loss)
I1006 19:28:09.052225  3702 sgd_solver.cpp:105] Iteration 76900, lr = 0.01
I1006 19:28:16.983103  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:28:17.317353  3702 solver.cpp:330] Iteration 77000, Testing net (#0)
I1006 19:28:19.243000  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:28:19.323897  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9059
I1006 19:28:19.323932  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.391599 (* 1 = 0.391599 loss)
I1006 19:28:19.406504  3702 solver.cpp:218] Iteration 77000 (9.65787 iter/s, 10.3543s/100 iters), loss = 0.0395168
I1006 19:28:19.406529  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0395167 (* 1 = 0.0395167 loss)
I1006 19:28:19.406536  3702 sgd_solver.cpp:105] Iteration 77000, lr = 0.01
I1006 19:28:27.746785  3702 solver.cpp:218] Iteration 77100 (11.9901 iter/s, 8.34023s/100 iters), loss = 0.00607138
I1006 19:28:27.746815  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00607134 (* 1 = 0.00607134 loss)
I1006 19:28:27.746821  3702 sgd_solver.cpp:105] Iteration 77100, lr = 0.01
I1006 19:28:36.089180  3702 solver.cpp:218] Iteration 77200 (11.987 iter/s, 8.34234s/100 iters), loss = 0.0191372
I1006 19:28:36.089339  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0191371 (* 1 = 0.0191371 loss)
I1006 19:28:36.089361  3702 sgd_solver.cpp:105] Iteration 77200, lr = 0.01
I1006 19:28:44.426676  3702 solver.cpp:218] Iteration 77300 (11.9943 iter/s, 8.33732s/100 iters), loss = 0.0104596
I1006 19:28:44.426704  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0104596 (* 1 = 0.0104596 loss)
I1006 19:28:44.426710  3702 sgd_solver.cpp:105] Iteration 77300, lr = 0.01
I1006 19:28:52.776043  3702 solver.cpp:218] Iteration 77400 (11.977 iter/s, 8.34931s/100 iters), loss = 0.00702962
I1006 19:28:52.776082  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00702958 (* 1 = 0.00702958 loss)
I1006 19:28:52.776088  3702 sgd_solver.cpp:105] Iteration 77400, lr = 0.01
I1006 19:29:00.702952  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:29:01.036562  3702 solver.cpp:330] Iteration 77500, Testing net (#0)
I1006 19:29:02.963558  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:29:03.044332  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9142
I1006 19:29:03.044366  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.354976 (* 1 = 0.354976 loss)
I1006 19:29:03.127506  3702 solver.cpp:218] Iteration 77500 (9.66053 iter/s, 10.3514s/100 iters), loss = 0.0138149
I1006 19:29:03.127532  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0138148 (* 1 = 0.0138148 loss)
I1006 19:29:03.127538  3702 sgd_solver.cpp:105] Iteration 77500, lr = 0.01
I1006 19:29:11.466365  3702 solver.cpp:218] Iteration 77600 (11.9921 iter/s, 8.33881s/100 iters), loss = 0.00384343
I1006 19:29:11.466465  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00384339 (* 1 = 0.00384339 loss)
I1006 19:29:11.466472  3702 sgd_solver.cpp:105] Iteration 77600, lr = 0.01
I1006 19:29:19.802130  3702 solver.cpp:218] Iteration 77700 (11.9967 iter/s, 8.33564s/100 iters), loss = 0.0168214
I1006 19:29:19.802158  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0168214 (* 1 = 0.0168214 loss)
I1006 19:29:19.802165  3702 sgd_solver.cpp:105] Iteration 77700, lr = 0.01
I1006 19:29:28.144896  3702 solver.cpp:218] Iteration 77800 (11.9865 iter/s, 8.34271s/100 iters), loss = 0.00526934
I1006 19:29:28.144935  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00526931 (* 1 = 0.00526931 loss)
I1006 19:29:28.144942  3702 sgd_solver.cpp:105] Iteration 77800, lr = 0.01
I1006 19:29:36.483206  3702 solver.cpp:218] Iteration 77900 (11.9929 iter/s, 8.33825s/100 iters), loss = 0.0118474
I1006 19:29:36.483245  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0118474 (* 1 = 0.0118474 loss)
I1006 19:29:36.483250  3702 sgd_solver.cpp:105] Iteration 77900, lr = 0.01
I1006 19:29:44.414453  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:29:44.749162  3702 solver.cpp:330] Iteration 78000, Testing net (#0)
I1006 19:29:46.675706  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:29:46.756856  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.913
I1006 19:29:46.756891  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.357279 (* 1 = 0.357279 loss)
I1006 19:29:46.839601  3702 solver.cpp:218] Iteration 78000 (9.65593 iter/s, 10.3563s/100 iters), loss = 0.00708084
I1006 19:29:46.839627  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00708081 (* 1 = 0.00708081 loss)
I1006 19:29:46.839633  3702 sgd_solver.cpp:105] Iteration 78000, lr = 0.01
I1006 19:29:55.182411  3702 solver.cpp:218] Iteration 78100 (11.9864 iter/s, 8.34276s/100 iters), loss = 0.0113922
I1006 19:29:55.182440  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0113922 (* 1 = 0.0113922 loss)
I1006 19:29:55.182456  3702 sgd_solver.cpp:105] Iteration 78100, lr = 0.01
I1006 19:30:03.529475  3702 solver.cpp:218] Iteration 78200 (11.9803 iter/s, 8.34701s/100 iters), loss = 0.00237136
I1006 19:30:03.529517  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00237132 (* 1 = 0.00237132 loss)
I1006 19:30:03.529523  3702 sgd_solver.cpp:105] Iteration 78200, lr = 0.01
I1006 19:30:11.871562  3702 solver.cpp:218] Iteration 78300 (11.9875 iter/s, 8.34202s/100 iters), loss = 0.00337523
I1006 19:30:11.871592  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0033752 (* 1 = 0.0033752 loss)
I1006 19:30:11.871608  3702 sgd_solver.cpp:105] Iteration 78300, lr = 0.01
I1006 19:30:20.217758  3702 solver.cpp:218] Iteration 78400 (11.9816 iter/s, 8.34614s/100 iters), loss = 0.00728787
I1006 19:30:20.217891  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00728784 (* 1 = 0.00728784 loss)
I1006 19:30:20.217900  3702 sgd_solver.cpp:105] Iteration 78400, lr = 0.01
I1006 19:30:28.142822  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:30:28.477733  3702 solver.cpp:330] Iteration 78500, Testing net (#0)
I1006 19:30:30.403641  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:30:30.484146  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9155
I1006 19:30:30.484181  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.355512 (* 1 = 0.355512 loss)
I1006 19:30:30.567302  3702 solver.cpp:218] Iteration 78500 (9.66241 iter/s, 10.3494s/100 iters), loss = 0.0097561
I1006 19:30:30.567328  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00975607 (* 1 = 0.00975607 loss)
I1006 19:30:30.567335  3702 sgd_solver.cpp:105] Iteration 78500, lr = 0.01
I1006 19:30:38.904072  3702 solver.cpp:218] Iteration 78600 (11.9951 iter/s, 8.33672s/100 iters), loss = 0.00907996
I1006 19:30:38.904112  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00907993 (* 1 = 0.00907993 loss)
I1006 19:30:38.904119  3702 sgd_solver.cpp:105] Iteration 78600, lr = 0.01
I1006 19:30:47.232722  3702 solver.cpp:218] Iteration 78700 (12.0068 iter/s, 8.32858s/100 iters), loss = 0.00857593
I1006 19:30:47.232760  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0085759 (* 1 = 0.0085759 loss)
I1006 19:30:47.232766  3702 sgd_solver.cpp:105] Iteration 78700, lr = 0.01
I1006 19:30:55.568081  3702 solver.cpp:218] Iteration 78800 (11.9972 iter/s, 8.3353s/100 iters), loss = 0.00201802
I1006 19:30:55.568178  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.002018 (* 1 = 0.002018 loss)
I1006 19:30:55.568195  3702 sgd_solver.cpp:105] Iteration 78800, lr = 0.01
I1006 19:31:03.899065  3702 solver.cpp:218] Iteration 78900 (12.0036 iter/s, 8.33086s/100 iters), loss = 0.00539123
I1006 19:31:03.899094  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0053912 (* 1 = 0.0053912 loss)
I1006 19:31:03.899101  3702 sgd_solver.cpp:105] Iteration 78900, lr = 0.01
I1006 19:31:11.822398  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:31:12.156520  3702 solver.cpp:330] Iteration 79000, Testing net (#0)
I1006 19:31:14.083545  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:31:14.164553  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9146
I1006 19:31:14.164588  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.349563 (* 1 = 0.349563 loss)
I1006 19:31:14.247052  3702 solver.cpp:218] Iteration 79000 (9.66377 iter/s, 10.3479s/100 iters), loss = 0.0165572
I1006 19:31:14.247084  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0165572 (* 1 = 0.0165572 loss)
I1006 19:31:14.247092  3702 sgd_solver.cpp:105] Iteration 79000, lr = 0.01
I1006 19:31:22.584957  3702 solver.cpp:218] Iteration 79100 (11.9935 iter/s, 8.33785s/100 iters), loss = 0.0081661
I1006 19:31:22.584986  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00816606 (* 1 = 0.00816606 loss)
I1006 19:31:22.584991  3702 sgd_solver.cpp:105] Iteration 79100, lr = 0.01
I1006 19:31:30.923425  3702 solver.cpp:218] Iteration 79200 (11.9927 iter/s, 8.33841s/100 iters), loss = 0.0161228
I1006 19:31:30.923516  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0161228 (* 1 = 0.0161228 loss)
I1006 19:31:30.923523  3702 sgd_solver.cpp:105] Iteration 79200, lr = 0.01
I1006 19:31:39.266047  3702 solver.cpp:218] Iteration 79300 (11.9868 iter/s, 8.34251s/100 iters), loss = 0.00372748
I1006 19:31:39.266075  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00372744 (* 1 = 0.00372744 loss)
I1006 19:31:39.266082  3702 sgd_solver.cpp:105] Iteration 79300, lr = 0.01
I1006 19:31:47.607816  3702 solver.cpp:218] Iteration 79400 (11.9879 iter/s, 8.34172s/100 iters), loss = 0.000956044
I1006 19:31:47.607844  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000956008 (* 1 = 0.000956008 loss)
I1006 19:31:47.607851  3702 sgd_solver.cpp:105] Iteration 79400, lr = 0.01
I1006 19:31:55.537286  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:31:55.871357  3702 solver.cpp:330] Iteration 79500, Testing net (#0)
I1006 19:31:57.797832  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:31:57.878326  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9134
I1006 19:31:57.878361  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.348453 (* 1 = 0.348453 loss)
I1006 19:31:57.962143  3702 solver.cpp:218] Iteration 79500 (9.65786 iter/s, 10.3543s/100 iters), loss = 0.000895893
I1006 19:31:57.962174  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00089586 (* 1 = 0.00089586 loss)
I1006 19:31:57.962182  3702 sgd_solver.cpp:105] Iteration 79500, lr = 0.01
I1006 19:32:06.302085  3702 solver.cpp:218] Iteration 79600 (11.9906 iter/s, 8.33988s/100 iters), loss = 0.00765869
I1006 19:32:06.302228  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00765866 (* 1 = 0.00765866 loss)
I1006 19:32:06.302237  3702 sgd_solver.cpp:105] Iteration 79600, lr = 0.01
I1006 19:32:14.635273  3702 solver.cpp:218] Iteration 79700 (12.0004 iter/s, 8.33302s/100 iters), loss = 0.00543977
I1006 19:32:14.635303  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00543974 (* 1 = 0.00543974 loss)
I1006 19:32:14.635308  3702 sgd_solver.cpp:105] Iteration 79700, lr = 0.01
I1006 19:32:22.974228  3702 solver.cpp:218] Iteration 79800 (11.992 iter/s, 8.3389s/100 iters), loss = 0.00120528
I1006 19:32:22.974258  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00120524 (* 1 = 0.00120524 loss)
I1006 19:32:22.974265  3702 sgd_solver.cpp:105] Iteration 79800, lr = 0.01
I1006 19:32:31.302451  3702 solver.cpp:218] Iteration 79900 (12.0074 iter/s, 8.32817s/100 iters), loss = 0.0402113
I1006 19:32:31.302480  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0402112 (* 1 = 0.0402112 loss)
I1006 19:32:31.302486  3702 sgd_solver.cpp:105] Iteration 79900, lr = 0.01
I1006 19:32:39.226001  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:32:39.559285  3702 solver.cpp:330] Iteration 80000, Testing net (#0)
I1006 19:32:41.486868  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:32:41.568011  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9138
I1006 19:32:41.568047  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.350809 (* 1 = 0.350809 loss)
I1006 19:32:41.650218  3702 solver.cpp:218] Iteration 80000 (9.66398 iter/s, 10.3477s/100 iters), loss = 0.00341459
I1006 19:32:41.650244  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00341456 (* 1 = 0.00341456 loss)
I1006 19:32:41.650250  3702 sgd_solver.cpp:46] MultiStep Status: Iteration 80000, step = 2
I1006 19:32:41.650254  3702 sgd_solver.cpp:105] Iteration 80000, lr = 0.001
I1006 19:32:49.987226  3702 solver.cpp:218] Iteration 80100 (11.9948 iter/s, 8.33696s/100 iters), loss = 0.018684
I1006 19:32:49.987262  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0186839 (* 1 = 0.0186839 loss)
I1006 19:32:49.987269  3702 sgd_solver.cpp:105] Iteration 80100, lr = 0.001
I1006 19:32:58.334570  3702 solver.cpp:218] Iteration 80200 (11.9799 iter/s, 8.34728s/100 iters), loss = 0.00372746
I1006 19:32:58.334599  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00372742 (* 1 = 0.00372742 loss)
I1006 19:32:58.334604  3702 sgd_solver.cpp:105] Iteration 80200, lr = 0.001
I1006 19:33:06.679412  3702 solver.cpp:218] Iteration 80300 (11.9835 iter/s, 8.34479s/100 iters), loss = 0.0026843
I1006 19:33:06.679441  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00268426 (* 1 = 0.00268426 loss)
I1006 19:33:06.679446  3702 sgd_solver.cpp:105] Iteration 80300, lr = 0.001
I1006 19:33:15.021754  3702 solver.cpp:218] Iteration 80400 (11.9871 iter/s, 8.34229s/100 iters), loss = 0.00176538
I1006 19:33:15.021842  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00176535 (* 1 = 0.00176535 loss)
I1006 19:33:15.021859  3702 sgd_solver.cpp:105] Iteration 80400, lr = 0.001
I1006 19:33:22.955229  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:33:23.289086  3702 solver.cpp:330] Iteration 80500, Testing net (#0)
I1006 19:33:25.215232  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:33:25.296080  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9211
I1006 19:33:25.296106  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.317567 (* 1 = 0.317567 loss)
I1006 19:33:25.379678  3702 solver.cpp:218] Iteration 80500 (9.65455 iter/s, 10.3578s/100 iters), loss = 0.00853472
I1006 19:33:25.379704  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00853469 (* 1 = 0.00853469 loss)
I1006 19:33:25.379711  3702 sgd_solver.cpp:105] Iteration 80500, lr = 0.001
I1006 19:33:33.723001  3702 solver.cpp:218] Iteration 80600 (11.9857 iter/s, 8.34327s/100 iters), loss = 0.0168948
I1006 19:33:33.723040  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0168948 (* 1 = 0.0168948 loss)
I1006 19:33:33.723045  3702 sgd_solver.cpp:105] Iteration 80600, lr = 0.001
I1006 19:33:42.054563  3702 solver.cpp:218] Iteration 80700 (12.0026 iter/s, 8.3315s/100 iters), loss = 0.00644947
I1006 19:33:42.054592  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00644945 (* 1 = 0.00644945 loss)
I1006 19:33:42.054599  3702 sgd_solver.cpp:105] Iteration 80700, lr = 0.001
I1006 19:33:50.393867  3702 solver.cpp:218] Iteration 80800 (11.9915 iter/s, 8.33925s/100 iters), loss = 0.0171756
I1006 19:33:50.394008  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0171756 (* 1 = 0.0171756 loss)
I1006 19:33:50.394016  3702 sgd_solver.cpp:105] Iteration 80800, lr = 0.001
I1006 19:33:58.728611  3702 solver.cpp:218] Iteration 80900 (11.9982 iter/s, 8.33458s/100 iters), loss = 0.00728168
I1006 19:33:58.728652  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00728167 (* 1 = 0.00728167 loss)
I1006 19:33:58.728657  3702 sgd_solver.cpp:105] Iteration 80900, lr = 0.001
I1006 19:34:06.656994  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:34:06.991258  3702 solver.cpp:330] Iteration 81000, Testing net (#0)
I1006 19:34:08.917556  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:34:08.998342  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9233
I1006 19:34:08.998379  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.306875 (* 1 = 0.306875 loss)
I1006 19:34:09.081158  3702 solver.cpp:218] Iteration 81000 (9.65952 iter/s, 10.3525s/100 iters), loss = 0.00676299
I1006 19:34:09.081183  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00676297 (* 1 = 0.00676297 loss)
I1006 19:34:09.081190  3702 sgd_solver.cpp:105] Iteration 81000, lr = 0.001
I1006 19:34:17.421875  3702 solver.cpp:218] Iteration 81100 (11.9895 iter/s, 8.34067s/100 iters), loss = 0.00153777
I1006 19:34:17.421903  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00153776 (* 1 = 0.00153776 loss)
I1006 19:34:17.421910  3702 sgd_solver.cpp:105] Iteration 81100, lr = 0.001
I1006 19:34:25.774760  3702 solver.cpp:218] Iteration 81200 (11.972 iter/s, 8.35283s/100 iters), loss = 0.00725519
I1006 19:34:25.774852  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00725517 (* 1 = 0.00725517 loss)
I1006 19:34:25.774859  3702 sgd_solver.cpp:105] Iteration 81200, lr = 0.001
I1006 19:34:34.121114  3702 solver.cpp:218] Iteration 81300 (11.9814 iter/s, 8.34624s/100 iters), loss = 0.00546976
I1006 19:34:34.121152  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00546974 (* 1 = 0.00546974 loss)
I1006 19:34:34.121158  3702 sgd_solver.cpp:105] Iteration 81300, lr = 0.001
I1006 19:34:42.471621  3702 solver.cpp:218] Iteration 81400 (11.9754 iter/s, 8.35044s/100 iters), loss = 0.000671092
I1006 19:34:42.471662  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000671074 (* 1 = 0.000671074 loss)
I1006 19:34:42.471668  3702 sgd_solver.cpp:105] Iteration 81400, lr = 0.001
I1006 19:34:50.402194  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:34:50.735492  3702 solver.cpp:330] Iteration 81500, Testing net (#0)
I1006 19:34:52.662235  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:34:52.742784  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9237
I1006 19:34:52.742817  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.306306 (* 1 = 0.306306 loss)
I1006 19:34:52.825886  3702 solver.cpp:218] Iteration 81500 (9.65792 iter/s, 10.3542s/100 iters), loss = 0.00515017
I1006 19:34:52.825914  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00515014 (* 1 = 0.00515014 loss)
I1006 19:34:52.825922  3702 sgd_solver.cpp:105] Iteration 81500, lr = 0.001
I1006 19:35:01.164608  3702 solver.cpp:218] Iteration 81600 (11.9923 iter/s, 8.33867s/100 iters), loss = 0.0110084
I1006 19:35:01.164716  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0110083 (* 1 = 0.0110083 loss)
I1006 19:35:01.164721  3702 sgd_solver.cpp:105] Iteration 81600, lr = 0.001
I1006 19:35:09.493798  3702 solver.cpp:218] Iteration 81700 (12.0061 iter/s, 8.32907s/100 iters), loss = 0.00804972
I1006 19:35:09.493829  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0080497 (* 1 = 0.0080497 loss)
I1006 19:35:09.493844  3702 sgd_solver.cpp:105] Iteration 81700, lr = 0.001
I1006 19:35:17.830870  3702 solver.cpp:218] Iteration 81800 (11.9947 iter/s, 8.33702s/100 iters), loss = 0.00182068
I1006 19:35:17.830901  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00182067 (* 1 = 0.00182067 loss)
I1006 19:35:17.830906  3702 sgd_solver.cpp:105] Iteration 81800, lr = 0.001
I1006 19:35:26.164042  3702 solver.cpp:218] Iteration 81900 (12.0003 iter/s, 8.33312s/100 iters), loss = 0.0116731
I1006 19:35:26.164082  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0116731 (* 1 = 0.0116731 loss)
I1006 19:35:26.164088  3702 sgd_solver.cpp:105] Iteration 81900, lr = 0.001
I1006 19:35:34.089188  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:35:34.423540  3702 solver.cpp:330] Iteration 82000, Testing net (#0)
I1006 19:35:36.350208  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:35:36.431504  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9226
I1006 19:35:36.431537  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.306595 (* 1 = 0.306595 loss)
I1006 19:35:36.514047  3702 solver.cpp:218] Iteration 82000 (9.6619 iter/s, 10.3499s/100 iters), loss = 0.00707712
I1006 19:35:36.514073  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0070771 (* 1 = 0.0070771 loss)
I1006 19:35:36.514080  3702 sgd_solver.cpp:105] Iteration 82000, lr = 0.001
I1006 19:35:44.848824  3702 solver.cpp:218] Iteration 82100 (11.998 iter/s, 8.33473s/100 iters), loss = 0.0272838
I1006 19:35:44.848852  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0272838 (* 1 = 0.0272838 loss)
I1006 19:35:44.848858  3702 sgd_solver.cpp:105] Iteration 82100, lr = 0.001
I1006 19:35:53.195194  3702 solver.cpp:218] Iteration 82200 (11.9813 iter/s, 8.34632s/100 iters), loss = 0.00675847
I1006 19:35:53.195233  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00675845 (* 1 = 0.00675845 loss)
I1006 19:35:53.195240  3702 sgd_solver.cpp:105] Iteration 82200, lr = 0.001
I1006 19:36:01.537650  3702 solver.cpp:218] Iteration 82300 (11.987 iter/s, 8.34239s/100 iters), loss = 0.00695235
I1006 19:36:01.537690  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00695233 (* 1 = 0.00695233 loss)
I1006 19:36:01.537695  3702 sgd_solver.cpp:105] Iteration 82300, lr = 0.001
I1006 19:36:09.880749  3702 solver.cpp:218] Iteration 82400 (11.986 iter/s, 8.34303s/100 iters), loss = 0.000850843
I1006 19:36:09.880861  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000850825 (* 1 = 0.000850825 loss)
I1006 19:36:09.880867  3702 sgd_solver.cpp:105] Iteration 82400, lr = 0.001
I1006 19:36:17.806488  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:36:18.139998  3702 solver.cpp:330] Iteration 82500, Testing net (#0)
I1006 19:36:20.068217  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:36:20.148919  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9218
I1006 19:36:20.148953  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.304126 (* 1 = 0.304126 loss)
I1006 19:36:20.232544  3702 solver.cpp:218] Iteration 82500 (9.66029 iter/s, 10.3517s/100 iters), loss = 0.00312311
I1006 19:36:20.232587  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00312309 (* 1 = 0.00312309 loss)
I1006 19:36:20.232594  3702 sgd_solver.cpp:105] Iteration 82500, lr = 0.001
I1006 19:36:28.571188  3702 solver.cpp:218] Iteration 82600 (11.9925 iter/s, 8.33853s/100 iters), loss = 0.000764361
I1006 19:36:28.571216  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000764344 (* 1 = 0.000764344 loss)
I1006 19:36:28.571223  3702 sgd_solver.cpp:105] Iteration 82600, lr = 0.001
I1006 19:36:36.907804  3702 solver.cpp:218] Iteration 82700 (11.9954 iter/s, 8.33656s/100 iters), loss = 0.0108064
I1006 19:36:36.907831  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0108064 (* 1 = 0.0108064 loss)
I1006 19:36:36.907837  3702 sgd_solver.cpp:105] Iteration 82700, lr = 0.001
I1006 19:36:45.251153  3702 solver.cpp:218] Iteration 82800 (11.9857 iter/s, 8.3433s/100 iters), loss = 0.00325166
I1006 19:36:45.251233  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00325164 (* 1 = 0.00325164 loss)
I1006 19:36:45.251250  3702 sgd_solver.cpp:105] Iteration 82800, lr = 0.001
I1006 19:36:53.593935  3702 solver.cpp:218] Iteration 82900 (11.9866 iter/s, 8.34268s/100 iters), loss = 0.00619283
I1006 19:36:53.593963  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00619282 (* 1 = 0.00619282 loss)
I1006 19:36:53.593968  3702 sgd_solver.cpp:105] Iteration 82900, lr = 0.001
I1006 19:37:01.525071  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:37:01.858955  3702 solver.cpp:330] Iteration 83000, Testing net (#0)
I1006 19:37:03.785213  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:37:03.866202  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9243
I1006 19:37:03.866236  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.303936 (* 1 = 0.303936 loss)
I1006 19:37:03.948897  3702 solver.cpp:218] Iteration 83000 (9.65726 iter/s, 10.3549s/100 iters), loss = 0.0109472
I1006 19:37:03.948922  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0109472 (* 1 = 0.0109472 loss)
I1006 19:37:03.948930  3702 sgd_solver.cpp:105] Iteration 83000, lr = 0.001
I1006 19:37:12.287488  3702 solver.cpp:218] Iteration 83100 (11.9925 iter/s, 8.33854s/100 iters), loss = 0.0047278
I1006 19:37:12.287518  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00472778 (* 1 = 0.00472778 loss)
I1006 19:37:12.287524  3702 sgd_solver.cpp:105] Iteration 83100, lr = 0.001
I1006 19:37:20.631716  3702 solver.cpp:218] Iteration 83200 (11.9844 iter/s, 8.34417s/100 iters), loss = 0.0221839
I1006 19:37:20.631882  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0221838 (* 1 = 0.0221838 loss)
I1006 19:37:20.631889  3702 sgd_solver.cpp:105] Iteration 83200, lr = 0.001
I1006 19:37:28.972021  3702 solver.cpp:218] Iteration 83300 (11.9902 iter/s, 8.34012s/100 iters), loss = 0.00315115
I1006 19:37:28.972060  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00315113 (* 1 = 0.00315113 loss)
I1006 19:37:28.972066  3702 sgd_solver.cpp:105] Iteration 83300, lr = 0.001
I1006 19:37:37.318560  3702 solver.cpp:218] Iteration 83400 (11.9811 iter/s, 8.34647s/100 iters), loss = 0.00352397
I1006 19:37:37.318589  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00352395 (* 1 = 0.00352395 loss)
I1006 19:37:37.318595  3702 sgd_solver.cpp:105] Iteration 83400, lr = 0.001
I1006 19:37:45.244860  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:37:45.579358  3702 solver.cpp:330] Iteration 83500, Testing net (#0)
I1006 19:37:47.506166  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:37:47.586805  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9239
I1006 19:37:47.586841  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.304408 (* 1 = 0.304408 loss)
I1006 19:37:47.670343  3702 solver.cpp:218] Iteration 83500 (9.66023 iter/s, 10.3517s/100 iters), loss = 0.00524445
I1006 19:37:47.670372  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00524443 (* 1 = 0.00524443 loss)
I1006 19:37:47.670378  3702 sgd_solver.cpp:105] Iteration 83500, lr = 0.001
I1006 19:37:56.014883  3702 solver.cpp:218] Iteration 83600 (11.984 iter/s, 8.34448s/100 iters), loss = 0.00222086
I1006 19:37:56.014981  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00222083 (* 1 = 0.00222083 loss)
I1006 19:37:56.014987  3702 sgd_solver.cpp:105] Iteration 83600, lr = 0.001
I1006 19:38:04.355840  3702 solver.cpp:218] Iteration 83700 (11.9892 iter/s, 8.34084s/100 iters), loss = 0.00254848
I1006 19:38:04.355870  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00254845 (* 1 = 0.00254845 loss)
I1006 19:38:04.355875  3702 sgd_solver.cpp:105] Iteration 83700, lr = 0.001
I1006 19:38:12.705088  3702 solver.cpp:218] Iteration 83800 (11.9772 iter/s, 8.34919s/100 iters), loss = 0.00147863
I1006 19:38:12.705128  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0014786 (* 1 = 0.0014786 loss)
I1006 19:38:12.705134  3702 sgd_solver.cpp:105] Iteration 83800, lr = 0.001
I1006 19:38:21.048147  3702 solver.cpp:218] Iteration 83900 (11.9861 iter/s, 8.34299s/100 iters), loss = 0.00186918
I1006 19:38:21.048179  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00186915 (* 1 = 0.00186915 loss)
I1006 19:38:21.048185  3702 sgd_solver.cpp:105] Iteration 83900, lr = 0.001
I1006 19:38:28.980187  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:38:29.314940  3702 solver.cpp:330] Iteration 84000, Testing net (#0)
I1006 19:38:31.242463  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:38:31.323319  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9246
I1006 19:38:31.323344  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.305122 (* 1 = 0.305122 loss)
I1006 19:38:31.406100  3702 solver.cpp:218] Iteration 84000 (9.65447 iter/s, 10.3579s/100 iters), loss = 0.00562301
I1006 19:38:31.406124  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00562298 (* 1 = 0.00562298 loss)
I1006 19:38:31.406131  3702 sgd_solver.cpp:105] Iteration 84000, lr = 0.001
I1006 19:38:39.742946  3702 solver.cpp:218] Iteration 84100 (11.995 iter/s, 8.33679s/100 iters), loss = 0.00509932
I1006 19:38:39.742993  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00509929 (* 1 = 0.00509929 loss)
I1006 19:38:39.743000  3702 sgd_solver.cpp:105] Iteration 84100, lr = 0.001
I1006 19:38:48.090698  3702 solver.cpp:218] Iteration 84200 (11.9794 iter/s, 8.34768s/100 iters), loss = 0.000847205
I1006 19:38:48.090728  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00084718 (* 1 = 0.00084718 loss)
I1006 19:38:48.090734  3702 sgd_solver.cpp:105] Iteration 84200, lr = 0.001
I1006 19:38:56.435746  3702 solver.cpp:218] Iteration 84300 (11.9832 iter/s, 8.345s/100 iters), loss = 0.00181344
I1006 19:38:56.435775  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00181341 (* 1 = 0.00181341 loss)
I1006 19:38:56.435781  3702 sgd_solver.cpp:105] Iteration 84300, lr = 0.001
I1006 19:39:04.784422  3702 solver.cpp:218] Iteration 84400 (11.978 iter/s, 8.34862s/100 iters), loss = 0.00195064
I1006 19:39:04.784533  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00195061 (* 1 = 0.00195061 loss)
I1006 19:39:04.784550  3702 sgd_solver.cpp:105] Iteration 84400, lr = 0.001
I1006 19:39:12.711941  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:39:13.046283  3702 solver.cpp:330] Iteration 84500, Testing net (#0)
I1006 19:39:14.973863  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:39:15.054641  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.924
I1006 19:39:15.054677  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.307033 (* 1 = 0.307033 loss)
I1006 19:39:15.137965  3702 solver.cpp:218] Iteration 84500 (9.65866 iter/s, 10.3534s/100 iters), loss = 0.00108444
I1006 19:39:15.137991  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00108441 (* 1 = 0.00108441 loss)
I1006 19:39:15.137998  3702 sgd_solver.cpp:105] Iteration 84500, lr = 0.001
I1006 19:39:23.470069  3702 solver.cpp:218] Iteration 84600 (12.0018 iter/s, 8.33205s/100 iters), loss = 0.00168725
I1006 19:39:23.470098  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00168723 (* 1 = 0.00168723 loss)
I1006 19:39:23.470104  3702 sgd_solver.cpp:105] Iteration 84600, lr = 0.001
I1006 19:39:31.804404  3702 solver.cpp:218] Iteration 84700 (11.9986 iter/s, 8.33428s/100 iters), loss = 0.00293771
I1006 19:39:31.804442  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00293768 (* 1 = 0.00293768 loss)
I1006 19:39:31.804448  3702 sgd_solver.cpp:105] Iteration 84700, lr = 0.001
I1006 19:39:40.139349  3702 solver.cpp:218] Iteration 84800 (11.9978 iter/s, 8.33488s/100 iters), loss = 0.00149686
I1006 19:39:40.139487  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00149684 (* 1 = 0.00149684 loss)
I1006 19:39:40.139493  3702 sgd_solver.cpp:105] Iteration 84800, lr = 0.001
I1006 19:39:48.474918  3702 solver.cpp:218] Iteration 84900 (11.997 iter/s, 8.33542s/100 iters), loss = 0.00200215
I1006 19:39:48.474947  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00200214 (* 1 = 0.00200214 loss)
I1006 19:39:48.474963  3702 sgd_solver.cpp:105] Iteration 84900, lr = 0.001
I1006 19:39:56.398921  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:39:56.732513  3702 solver.cpp:330] Iteration 85000, Testing net (#0)
I1006 19:39:58.658462  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:39:58.739289  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9252
I1006 19:39:58.739315  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.30519 (* 1 = 0.30519 loss)
I1006 19:39:58.821786  3702 solver.cpp:218] Iteration 85000 (9.66481 iter/s, 10.3468s/100 iters), loss = 0.00505924
I1006 19:39:58.821812  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00505922 (* 1 = 0.00505922 loss)
I1006 19:39:58.821820  3702 sgd_solver.cpp:105] Iteration 85000, lr = 0.001
I1006 19:40:07.160007  3702 solver.cpp:218] Iteration 85100 (11.993 iter/s, 8.33817s/100 iters), loss = 0.00182576
I1006 19:40:07.160048  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00182575 (* 1 = 0.00182575 loss)
I1006 19:40:07.160053  3702 sgd_solver.cpp:105] Iteration 85100, lr = 0.001
I1006 19:40:15.502535  3702 solver.cpp:218] Iteration 85200 (11.9869 iter/s, 8.34246s/100 iters), loss = 0.00270214
I1006 19:40:15.502656  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00270212 (* 1 = 0.00270212 loss)
I1006 19:40:15.502663  3702 sgd_solver.cpp:105] Iteration 85200, lr = 0.001
I1006 19:40:23.846128  3702 solver.cpp:218] Iteration 85300 (11.9854 iter/s, 8.34345s/100 iters), loss = 0.00340818
I1006 19:40:23.846156  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00340817 (* 1 = 0.00340817 loss)
I1006 19:40:23.846163  3702 sgd_solver.cpp:105] Iteration 85300, lr = 0.001
I1006 19:40:32.191293  3702 solver.cpp:218] Iteration 85400 (11.9831 iter/s, 8.34511s/100 iters), loss = 0.00044314
I1006 19:40:32.191320  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000443128 (* 1 = 0.000443128 loss)
I1006 19:40:32.191326  3702 sgd_solver.cpp:105] Iteration 85400, lr = 0.001
I1006 19:40:40.118325  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:40:40.451997  3702 solver.cpp:330] Iteration 85500, Testing net (#0)
I1006 19:40:42.378733  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:40:42.458678  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9246
I1006 19:40:42.458712  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.305453 (* 1 = 0.305453 loss)
I1006 19:40:42.542026  3702 solver.cpp:218] Iteration 85500 (9.66121 iter/s, 10.3507s/100 iters), loss = 0.00394856
I1006 19:40:42.542052  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00394855 (* 1 = 0.00394855 loss)
I1006 19:40:42.542058  3702 sgd_solver.cpp:105] Iteration 85500, lr = 0.001
I1006 19:40:50.888813  3702 solver.cpp:218] Iteration 85600 (11.9807 iter/s, 8.34674s/100 iters), loss = 0.00225645
I1006 19:40:50.888898  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00225644 (* 1 = 0.00225644 loss)
I1006 19:40:50.888914  3702 sgd_solver.cpp:105] Iteration 85600, lr = 0.001
I1006 19:40:59.221109  3702 solver.cpp:218] Iteration 85700 (12.0016 iter/s, 8.33219s/100 iters), loss = 0.00171819
I1006 19:40:59.221138  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00171818 (* 1 = 0.00171818 loss)
I1006 19:40:59.221144  3702 sgd_solver.cpp:105] Iteration 85700, lr = 0.001
I1006 19:41:07.562012  3702 solver.cpp:218] Iteration 85800 (11.9892 iter/s, 8.34085s/100 iters), loss = 0.00156794
I1006 19:41:07.562052  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00156793 (* 1 = 0.00156793 loss)
I1006 19:41:07.562057  3702 sgd_solver.cpp:105] Iteration 85800, lr = 0.001
I1006 19:41:15.901963  3702 solver.cpp:218] Iteration 85900 (11.9906 iter/s, 8.33989s/100 iters), loss = 0.00249593
I1006 19:41:15.902004  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00249592 (* 1 = 0.00249592 loss)
I1006 19:41:15.902009  3702 sgd_solver.cpp:105] Iteration 85900, lr = 0.001
I1006 19:41:23.830272  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:41:24.163348  3702 solver.cpp:330] Iteration 86000, Testing net (#0)
I1006 19:41:26.090592  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:41:26.171799  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9241
I1006 19:41:26.171834  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.306981 (* 1 = 0.306981 loss)
I1006 19:41:26.254606  3702 solver.cpp:218] Iteration 86000 (9.65944 iter/s, 10.3526s/100 iters), loss = 0.00530388
I1006 19:41:26.254638  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00530387 (* 1 = 0.00530387 loss)
I1006 19:41:26.254645  3702 sgd_solver.cpp:105] Iteration 86000, lr = 0.001
I1006 19:41:34.595337  3702 solver.cpp:218] Iteration 86100 (11.9894 iter/s, 8.34068s/100 iters), loss = 0.00447338
I1006 19:41:34.595366  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00447337 (* 1 = 0.00447337 loss)
I1006 19:41:34.595371  3702 sgd_solver.cpp:105] Iteration 86100, lr = 0.001
I1006 19:41:42.937548  3702 solver.cpp:218] Iteration 86200 (11.9873 iter/s, 8.34216s/100 iters), loss = 0.00216652
I1006 19:41:42.937578  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00216651 (* 1 = 0.00216651 loss)
I1006 19:41:42.937583  3702 sgd_solver.cpp:105] Iteration 86200, lr = 0.001
I1006 19:41:51.271692  3702 solver.cpp:218] Iteration 86300 (11.9989 iter/s, 8.33409s/100 iters), loss = 0.00151793
I1006 19:41:51.271733  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00151791 (* 1 = 0.00151791 loss)
I1006 19:41:51.271737  3702 sgd_solver.cpp:105] Iteration 86300, lr = 0.001
I1006 19:41:59.614648  3702 solver.cpp:218] Iteration 86400 (11.9862 iter/s, 8.34289s/100 iters), loss = 0.0209784
I1006 19:41:59.614765  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0209784 (* 1 = 0.0209784 loss)
I1006 19:41:59.614773  3702 sgd_solver.cpp:105] Iteration 86400, lr = 0.001
I1006 19:42:07.538681  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:42:07.872369  3702 solver.cpp:330] Iteration 86500, Testing net (#0)
I1006 19:42:09.798684  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:42:09.879086  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9247
I1006 19:42:09.879120  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.307366 (* 1 = 0.307366 loss)
I1006 19:42:09.962577  3702 solver.cpp:218] Iteration 86500 (9.6639 iter/s, 10.3478s/100 iters), loss = 0.00220597
I1006 19:42:09.962604  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00220595 (* 1 = 0.00220595 loss)
I1006 19:42:09.962610  3702 sgd_solver.cpp:105] Iteration 86500, lr = 0.001
I1006 19:42:18.308081  3702 solver.cpp:218] Iteration 86600 (11.9826 iter/s, 8.34545s/100 iters), loss = 0.00440053
I1006 19:42:18.308109  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00440051 (* 1 = 0.00440051 loss)
I1006 19:42:18.308115  3702 sgd_solver.cpp:105] Iteration 86600, lr = 0.001
I1006 19:42:26.646244  3702 solver.cpp:218] Iteration 86700 (11.9931 iter/s, 8.33811s/100 iters), loss = 0.00692528
I1006 19:42:26.646283  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00692526 (* 1 = 0.00692526 loss)
I1006 19:42:26.646289  3702 sgd_solver.cpp:105] Iteration 86700, lr = 0.001
I1006 19:42:34.990337  3702 solver.cpp:218] Iteration 86800 (11.9846 iter/s, 8.34403s/100 iters), loss = 0.00271449
I1006 19:42:34.990437  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00271447 (* 1 = 0.00271447 loss)
I1006 19:42:34.990453  3702 sgd_solver.cpp:105] Iteration 86800, lr = 0.001
I1006 19:42:43.327484  3702 solver.cpp:218] Iteration 86900 (11.9947 iter/s, 8.33702s/100 iters), loss = 0.0019619
I1006 19:42:43.327513  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00196188 (* 1 = 0.00196188 loss)
I1006 19:42:43.327519  3702 sgd_solver.cpp:105] Iteration 86900, lr = 0.001
I1006 19:42:51.259909  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:42:51.593657  3702 solver.cpp:330] Iteration 87000, Testing net (#0)
I1006 19:42:53.521039  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:42:53.601680  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9248
I1006 19:42:53.601714  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.308902 (* 1 = 0.308902 loss)
I1006 19:42:53.684171  3702 solver.cpp:218] Iteration 87000 (9.65565 iter/s, 10.3566s/100 iters), loss = 0.00766411
I1006 19:42:53.684197  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00766409 (* 1 = 0.00766409 loss)
I1006 19:42:53.684204  3702 sgd_solver.cpp:105] Iteration 87000, lr = 0.001
I1006 19:43:02.028923  3702 solver.cpp:218] Iteration 87100 (11.9837 iter/s, 8.3447s/100 iters), loss = 0.00504095
I1006 19:43:02.028962  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00504093 (* 1 = 0.00504093 loss)
I1006 19:43:02.028969  3702 sgd_solver.cpp:105] Iteration 87100, lr = 0.001
I1006 19:43:10.378897  3702 solver.cpp:218] Iteration 87200 (11.9762 iter/s, 8.34991s/100 iters), loss = 0.0049031
I1006 19:43:10.379004  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00490308 (* 1 = 0.00490308 loss)
I1006 19:43:10.379010  3702 sgd_solver.cpp:105] Iteration 87200, lr = 0.001
I1006 19:43:18.719408  3702 solver.cpp:218] Iteration 87300 (11.9899 iter/s, 8.34038s/100 iters), loss = 0.00317324
I1006 19:43:18.719447  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00317322 (* 1 = 0.00317322 loss)
I1006 19:43:18.719454  3702 sgd_solver.cpp:105] Iteration 87300, lr = 0.001
I1006 19:43:27.066478  3702 solver.cpp:218] Iteration 87400 (11.9803 iter/s, 8.347s/100 iters), loss = 0.00264029
I1006 19:43:27.066506  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00264027 (* 1 = 0.00264027 loss)
I1006 19:43:27.066512  3702 sgd_solver.cpp:105] Iteration 87400, lr = 0.001
I1006 19:43:34.991145  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:43:35.325013  3702 solver.cpp:330] Iteration 87500, Testing net (#0)
I1006 19:43:37.251996  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:43:37.332543  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9243
I1006 19:43:37.332578  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.308659 (* 1 = 0.308659 loss)
I1006 19:43:37.416026  3702 solver.cpp:218] Iteration 87500 (9.66231 iter/s, 10.3495s/100 iters), loss = 0.00369087
I1006 19:43:37.416054  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00369085 (* 1 = 0.00369085 loss)
I1006 19:43:37.416060  3702 sgd_solver.cpp:105] Iteration 87500, lr = 0.001
I1006 19:43:45.756048  3702 solver.cpp:218] Iteration 87600 (11.9905 iter/s, 8.33997s/100 iters), loss = 0.0030919
I1006 19:43:45.756168  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00309188 (* 1 = 0.00309188 loss)
I1006 19:43:45.756186  3702 sgd_solver.cpp:105] Iteration 87600, lr = 0.001
I1006 19:43:54.087260  3702 solver.cpp:218] Iteration 87700 (12.0033 iter/s, 8.33108s/100 iters), loss = 0.00211977
I1006 19:43:54.087296  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00211975 (* 1 = 0.00211975 loss)
I1006 19:43:54.087306  3702 sgd_solver.cpp:105] Iteration 87700, lr = 0.001
I1006 19:44:02.424146  3702 solver.cpp:218] Iteration 87800 (11.995 iter/s, 8.33683s/100 iters), loss = 0.00383384
I1006 19:44:02.424175  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00383382 (* 1 = 0.00383382 loss)
I1006 19:44:02.424180  3702 sgd_solver.cpp:105] Iteration 87800, lr = 0.001
I1006 19:44:10.760771  3702 solver.cpp:218] Iteration 87900 (11.9953 iter/s, 8.33657s/100 iters), loss = 0.000775192
I1006 19:44:10.760799  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000775179 (* 1 = 0.000775179 loss)
I1006 19:44:10.760805  3702 sgd_solver.cpp:105] Iteration 87900, lr = 0.001
I1006 19:44:18.684255  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:44:19.017830  3702 solver.cpp:330] Iteration 88000, Testing net (#0)
I1006 19:44:20.945641  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:44:21.027189  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9238
I1006 19:44:21.027225  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.306943 (* 1 = 0.306943 loss)
I1006 19:44:21.109853  3702 solver.cpp:218] Iteration 88000 (9.66275 iter/s, 10.349s/100 iters), loss = 0.00642293
I1006 19:44:21.109879  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00642292 (* 1 = 0.00642292 loss)
I1006 19:44:21.109886  3702 sgd_solver.cpp:105] Iteration 88000, lr = 0.001
I1006 19:44:29.451565  3702 solver.cpp:218] Iteration 88100 (11.988 iter/s, 8.34166s/100 iters), loss = 0.00361363
I1006 19:44:29.451603  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00361362 (* 1 = 0.00361362 loss)
I1006 19:44:29.451609  3702 sgd_solver.cpp:105] Iteration 88100, lr = 0.001
I1006 19:44:37.796771  3702 solver.cpp:218] Iteration 88200 (11.983 iter/s, 8.34514s/100 iters), loss = 0.00289795
I1006 19:44:37.796810  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00289794 (* 1 = 0.00289794 loss)
I1006 19:44:37.796816  3702 sgd_solver.cpp:105] Iteration 88200, lr = 0.001
I1006 19:44:46.131430  3702 solver.cpp:218] Iteration 88300 (11.9982 iter/s, 8.3346s/100 iters), loss = 0.0017012
I1006 19:44:46.131459  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0017012 (* 1 = 0.0017012 loss)
I1006 19:44:46.131465  3702 sgd_solver.cpp:105] Iteration 88300, lr = 0.001
I1006 19:44:54.475750  3702 solver.cpp:218] Iteration 88400 (11.9843 iter/s, 8.34427s/100 iters), loss = 0.000841236
I1006 19:44:54.475852  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000841227 (* 1 = 0.000841227 loss)
I1006 19:44:54.475859  3702 sgd_solver.cpp:105] Iteration 88400, lr = 0.001
I1006 19:45:02.406193  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:45:02.739368  3702 solver.cpp:330] Iteration 88500, Testing net (#0)
I1006 19:45:04.666041  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:45:04.746971  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9241
I1006 19:45:04.747005  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.306592 (* 1 = 0.306592 loss)
I1006 19:45:04.830909  3702 solver.cpp:218] Iteration 88500 (9.65713 iter/s, 10.355s/100 iters), loss = 0.00609857
I1006 19:45:04.830936  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00609857 (* 1 = 0.00609857 loss)
I1006 19:45:04.830942  3702 sgd_solver.cpp:105] Iteration 88500, lr = 0.001
I1006 19:45:13.173262  3702 solver.cpp:218] Iteration 88600 (11.9871 iter/s, 8.3423s/100 iters), loss = 0.00706283
I1006 19:45:13.173291  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00706282 (* 1 = 0.00706282 loss)
I1006 19:45:13.173297  3702 sgd_solver.cpp:105] Iteration 88600, lr = 0.001
I1006 19:45:21.500293  3702 solver.cpp:218] Iteration 88700 (12.0092 iter/s, 8.32698s/100 iters), loss = 0.00312558
I1006 19:45:21.500322  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00312558 (* 1 = 0.00312558 loss)
I1006 19:45:21.500327  3702 sgd_solver.cpp:105] Iteration 88700, lr = 0.001
I1006 19:45:29.843111  3702 solver.cpp:218] Iteration 88800 (11.9864 iter/s, 8.34276s/100 iters), loss = 0.00636353
I1006 19:45:29.843204  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00636353 (* 1 = 0.00636353 loss)
I1006 19:45:29.843220  3702 sgd_solver.cpp:105] Iteration 88800, lr = 0.001
I1006 19:45:38.180676  3702 solver.cpp:218] Iteration 88900 (11.9941 iter/s, 8.33745s/100 iters), loss = 0.000768143
I1006 19:45:38.180706  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000768135 (* 1 = 0.000768135 loss)
I1006 19:45:38.180711  3702 sgd_solver.cpp:105] Iteration 88900, lr = 0.001
I1006 19:45:46.109778  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:45:46.444277  3702 solver.cpp:330] Iteration 89000, Testing net (#0)
I1006 19:45:48.371096  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:45:48.452262  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9248
I1006 19:45:48.452297  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.307386 (* 1 = 0.307386 loss)
I1006 19:45:48.534873  3702 solver.cpp:218] Iteration 89000 (9.65797 iter/s, 10.3541s/100 iters), loss = 0.00280254
I1006 19:45:48.534898  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00280253 (* 1 = 0.00280253 loss)
I1006 19:45:48.534905  3702 sgd_solver.cpp:105] Iteration 89000, lr = 0.001
I1006 19:45:56.869753  3702 solver.cpp:218] Iteration 89100 (11.9978 iter/s, 8.33483s/100 iters), loss = 0.0010607
I1006 19:45:56.869789  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0010607 (* 1 = 0.0010607 loss)
I1006 19:45:56.869796  3702 sgd_solver.cpp:105] Iteration 89100, lr = 0.001
I1006 19:46:05.211218  3702 solver.cpp:218] Iteration 89200 (11.9884 iter/s, 8.3414s/100 iters), loss = 0.000423451
I1006 19:46:05.211333  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000423444 (* 1 = 0.000423444 loss)
I1006 19:46:05.211340  3702 sgd_solver.cpp:105] Iteration 89200, lr = 0.001
I1006 19:46:13.551257  3702 solver.cpp:218] Iteration 89300 (11.9905 iter/s, 8.33991s/100 iters), loss = 0.00172085
I1006 19:46:13.551296  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00172084 (* 1 = 0.00172084 loss)
I1006 19:46:13.551302  3702 sgd_solver.cpp:105] Iteration 89300, lr = 0.001
I1006 19:46:21.894362  3702 solver.cpp:218] Iteration 89400 (11.986 iter/s, 8.34304s/100 iters), loss = 0.00167036
I1006 19:46:21.894392  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00167035 (* 1 = 0.00167035 loss)
I1006 19:46:21.894397  3702 sgd_solver.cpp:105] Iteration 89400, lr = 0.001
I1006 19:46:29.815825  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:46:30.148423  3702 solver.cpp:330] Iteration 89500, Testing net (#0)
I1006 19:46:32.075037  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:46:32.155649  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9244
I1006 19:46:32.155684  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.307979 (* 1 = 0.307979 loss)
I1006 19:46:32.239565  3702 solver.cpp:218] Iteration 89500 (9.66637 iter/s, 10.3451s/100 iters), loss = 0.00344697
I1006 19:46:32.239598  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00344696 (* 1 = 0.00344696 loss)
I1006 19:46:32.239605  3702 sgd_solver.cpp:105] Iteration 89500, lr = 0.001
I1006 19:46:40.580160  3702 solver.cpp:218] Iteration 89600 (11.9896 iter/s, 8.34054s/100 iters), loss = 0.00111704
I1006 19:46:40.580276  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00111703 (* 1 = 0.00111703 loss)
I1006 19:46:40.580287  3702 sgd_solver.cpp:105] Iteration 89600, lr = 0.001
I1006 19:46:48.912078  3702 solver.cpp:218] Iteration 89700 (12.0022 iter/s, 8.33179s/100 iters), loss = 0.00217109
I1006 19:46:48.912108  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00217108 (* 1 = 0.00217108 loss)
I1006 19:46:48.912114  3702 sgd_solver.cpp:105] Iteration 89700, lr = 0.001
I1006 19:46:57.252068  3702 solver.cpp:218] Iteration 89800 (11.9905 iter/s, 8.33993s/100 iters), loss = 0.0020938
I1006 19:46:57.252099  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00209379 (* 1 = 0.00209379 loss)
I1006 19:46:57.252104  3702 sgd_solver.cpp:105] Iteration 89800, lr = 0.001
I1006 19:47:05.590945  3702 solver.cpp:218] Iteration 89900 (11.9921 iter/s, 8.33882s/100 iters), loss = 0.000778726
I1006 19:47:05.590975  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000778713 (* 1 = 0.000778713 loss)
I1006 19:47:05.590981  3702 sgd_solver.cpp:105] Iteration 89900, lr = 0.001
I1006 19:47:13.515816  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:47:13.850551  3702 solver.cpp:330] Iteration 90000, Testing net (#0)
I1006 19:47:15.777462  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:47:15.858566  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9245
I1006 19:47:15.858602  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.308135 (* 1 = 0.308135 loss)
I1006 19:47:15.941597  3702 solver.cpp:218] Iteration 90000 (9.66128 iter/s, 10.3506s/100 iters), loss = 0.00598239
I1006 19:47:15.941623  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00598237 (* 1 = 0.00598237 loss)
I1006 19:47:15.941630  3702 sgd_solver.cpp:105] Iteration 90000, lr = 0.001
I1006 19:47:24.277267  3702 solver.cpp:218] Iteration 90100 (11.9967 iter/s, 8.33562s/100 iters), loss = 0.0057523
I1006 19:47:24.277308  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00575229 (* 1 = 0.00575229 loss)
I1006 19:47:24.277314  3702 sgd_solver.cpp:105] Iteration 90100, lr = 0.001
I1006 19:47:32.623519  3702 solver.cpp:218] Iteration 90200 (11.9815 iter/s, 8.34619s/100 iters), loss = 0.00428931
I1006 19:47:32.623559  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0042893 (* 1 = 0.0042893 loss)
I1006 19:47:32.623564  3702 sgd_solver.cpp:105] Iteration 90200, lr = 0.001
I1006 19:47:40.963047  3702 solver.cpp:218] Iteration 90300 (11.9912 iter/s, 8.33946s/100 iters), loss = 0.000864739
I1006 19:47:40.963086  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000864728 (* 1 = 0.000864728 loss)
I1006 19:47:40.963093  3702 sgd_solver.cpp:105] Iteration 90300, lr = 0.001
I1006 19:47:49.306363  3702 solver.cpp:218] Iteration 90400 (11.9857 iter/s, 8.34326s/100 iters), loss = 0.000461617
I1006 19:47:49.306458  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000461607 (* 1 = 0.000461607 loss)
I1006 19:47:49.306476  3702 sgd_solver.cpp:105] Iteration 90400, lr = 0.001
I1006 19:47:57.236569  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:47:57.570204  3702 solver.cpp:330] Iteration 90500, Testing net (#0)
I1006 19:47:59.496428  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:47:59.576498  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9246
I1006 19:47:59.576522  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.309069 (* 1 = 0.309069 loss)
I1006 19:47:59.660135  3702 solver.cpp:218] Iteration 90500 (9.65843 iter/s, 10.3537s/100 iters), loss = 0.00114682
I1006 19:47:59.660164  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00114681 (* 1 = 0.00114681 loss)
I1006 19:47:59.660171  3702 sgd_solver.cpp:105] Iteration 90500, lr = 0.001
I1006 19:48:08.006953  3702 solver.cpp:218] Iteration 90600 (11.9807 iter/s, 8.34676s/100 iters), loss = 0.00545446
I1006 19:48:08.006992  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00545445 (* 1 = 0.00545445 loss)
I1006 19:48:08.006999  3702 sgd_solver.cpp:105] Iteration 90600, lr = 0.001
I1006 19:48:16.342839  3702 solver.cpp:218] Iteration 90700 (11.9964 iter/s, 8.33582s/100 iters), loss = 0.00493131
I1006 19:48:16.342866  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00493131 (* 1 = 0.00493131 loss)
I1006 19:48:16.342872  3702 sgd_solver.cpp:105] Iteration 90700, lr = 0.001
I1006 19:48:24.688889  3702 solver.cpp:218] Iteration 90800 (11.9818 iter/s, 8.34599s/100 iters), loss = 0.00297506
I1006 19:48:24.689028  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00297505 (* 1 = 0.00297505 loss)
I1006 19:48:24.689033  3702 sgd_solver.cpp:105] Iteration 90800, lr = 0.001
I1006 19:48:33.025317  3702 solver.cpp:218] Iteration 90900 (11.9958 iter/s, 8.33628s/100 iters), loss = 0.00409676
I1006 19:48:33.025362  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00409675 (* 1 = 0.00409675 loss)
I1006 19:48:33.025368  3702 sgd_solver.cpp:105] Iteration 90900, lr = 0.001
I1006 19:48:40.954197  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:48:41.287433  3702 solver.cpp:330] Iteration 91000, Testing net (#0)
I1006 19:48:43.214262  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:48:43.294859  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9248
I1006 19:48:43.294895  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.311176 (* 1 = 0.311176 loss)
I1006 19:48:43.377638  3702 solver.cpp:218] Iteration 91000 (9.65974 iter/s, 10.3522s/100 iters), loss = 0.00324731
I1006 19:48:43.377665  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0032473 (* 1 = 0.0032473 loss)
I1006 19:48:43.377671  3702 sgd_solver.cpp:105] Iteration 91000, lr = 0.001
I1006 19:48:51.716233  3702 solver.cpp:218] Iteration 91100 (11.9925 iter/s, 8.33854s/100 iters), loss = 0.00332466
I1006 19:48:51.716272  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00332465 (* 1 = 0.00332465 loss)
I1006 19:48:51.716279  3702 sgd_solver.cpp:105] Iteration 91100, lr = 0.001
I1006 19:49:00.062724  3702 solver.cpp:218] Iteration 91200 (11.9812 iter/s, 8.34643s/100 iters), loss = 0.00300357
I1006 19:49:00.062892  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00300357 (* 1 = 0.00300357 loss)
I1006 19:49:00.062901  3702 sgd_solver.cpp:105] Iteration 91200, lr = 0.001
I1006 19:49:08.410809  3702 solver.cpp:218] Iteration 91300 (11.979 iter/s, 8.34791s/100 iters), loss = 0.00322985
I1006 19:49:08.410836  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00322984 (* 1 = 0.00322984 loss)
I1006 19:49:08.410842  3702 sgd_solver.cpp:105] Iteration 91300, lr = 0.001
I1006 19:49:16.758136  3702 solver.cpp:218] Iteration 91400 (11.98 iter/s, 8.34728s/100 iters), loss = 0.00155269
I1006 19:49:16.758164  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00155268 (* 1 = 0.00155268 loss)
I1006 19:49:16.758170  3702 sgd_solver.cpp:105] Iteration 91400, lr = 0.001
I1006 19:49:24.690807  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:49:25.024950  3702 solver.cpp:330] Iteration 91500, Testing net (#0)
I1006 19:49:26.950757  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:49:27.031491  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9244
I1006 19:49:27.031527  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.310131 (* 1 = 0.310131 loss)
I1006 19:49:27.114732  3702 solver.cpp:218] Iteration 91500 (9.65574 iter/s, 10.3565s/100 iters), loss = 0.00572808
I1006 19:49:27.114759  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00572807 (* 1 = 0.00572807 loss)
I1006 19:49:27.114765  3702 sgd_solver.cpp:105] Iteration 91500, lr = 0.001
I1006 19:49:35.460921  3702 solver.cpp:218] Iteration 91600 (11.9816 iter/s, 8.34614s/100 iters), loss = 0.00190521
I1006 19:49:35.461019  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0019052 (* 1 = 0.0019052 loss)
I1006 19:49:35.461027  3702 sgd_solver.cpp:105] Iteration 91600, lr = 0.001
I1006 19:49:43.800736  3702 solver.cpp:218] Iteration 91700 (11.9908 iter/s, 8.33969s/100 iters), loss = 0.0032648
I1006 19:49:43.800776  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0032648 (* 1 = 0.0032648 loss)
I1006 19:49:43.800781  3702 sgd_solver.cpp:105] Iteration 91700, lr = 0.001
I1006 19:49:52.147871  3702 solver.cpp:218] Iteration 91800 (11.9803 iter/s, 8.34707s/100 iters), loss = 0.00107148
I1006 19:49:52.147899  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00107148 (* 1 = 0.00107148 loss)
I1006 19:49:52.147905  3702 sgd_solver.cpp:105] Iteration 91800, lr = 0.001
I1006 19:50:00.488893  3702 solver.cpp:218] Iteration 91900 (11.989 iter/s, 8.34097s/100 iters), loss = 0.00473947
I1006 19:50:00.488921  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00473947 (* 1 = 0.00473947 loss)
I1006 19:50:00.488926  3702 sgd_solver.cpp:105] Iteration 91900, lr = 0.001
I1006 19:50:08.418987  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:50:08.752748  3702 solver.cpp:330] Iteration 92000, Testing net (#0)
I1006 19:50:10.680342  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:50:10.761334  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9245
I1006 19:50:10.761369  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.30912 (* 1 = 0.30912 loss)
I1006 19:50:10.843318  3702 solver.cpp:218] Iteration 92000 (9.65776 iter/s, 10.3544s/100 iters), loss = 0.00161202
I1006 19:50:10.843344  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00161201 (* 1 = 0.00161201 loss)
I1006 19:50:10.843350  3702 sgd_solver.cpp:105] Iteration 92000, lr = 0.001
I1006 19:50:19.179838  3702 solver.cpp:218] Iteration 92100 (11.9955 iter/s, 8.33647s/100 iters), loss = 0.00458868
I1006 19:50:19.179868  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00458867 (* 1 = 0.00458867 loss)
I1006 19:50:19.179873  3702 sgd_solver.cpp:105] Iteration 92100, lr = 0.001
I1006 19:50:27.521582  3702 solver.cpp:218] Iteration 92200 (11.988 iter/s, 8.34169s/100 iters), loss = 0.00135403
I1006 19:50:27.521621  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00135403 (* 1 = 0.00135403 loss)
I1006 19:50:27.521627  3702 sgd_solver.cpp:105] Iteration 92200, lr = 0.001
I1006 19:50:35.854228  3702 solver.cpp:218] Iteration 92300 (12.0011 iter/s, 8.33258s/100 iters), loss = 0.00105779
I1006 19:50:35.854257  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00105778 (* 1 = 0.00105778 loss)
I1006 19:50:35.854264  3702 sgd_solver.cpp:105] Iteration 92300, lr = 0.001
I1006 19:50:44.193348  3702 solver.cpp:218] Iteration 92400 (11.9917 iter/s, 8.33907s/100 iters), loss = 0.000437049
I1006 19:50:44.193477  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000437043 (* 1 = 0.000437043 loss)
I1006 19:50:44.193485  3702 sgd_solver.cpp:105] Iteration 92400, lr = 0.001
I1006 19:50:52.115263  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:50:52.448743  3702 solver.cpp:330] Iteration 92500, Testing net (#0)
I1006 19:50:54.375656  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:50:54.456436  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9253
I1006 19:50:54.456471  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.308016 (* 1 = 0.308016 loss)
I1006 19:50:54.540084  3702 solver.cpp:218] Iteration 92500 (9.66502 iter/s, 10.3466s/100 iters), loss = 0.00169597
I1006 19:50:54.540112  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00169597 (* 1 = 0.00169597 loss)
I1006 19:50:54.540118  3702 sgd_solver.cpp:105] Iteration 92500, lr = 0.001
I1006 19:51:02.879047  3702 solver.cpp:218] Iteration 92600 (11.992 iter/s, 8.33891s/100 iters), loss = 0.00213927
I1006 19:51:02.879087  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00213927 (* 1 = 0.00213927 loss)
I1006 19:51:02.879093  3702 sgd_solver.cpp:105] Iteration 92600, lr = 0.001
I1006 19:51:11.210536  3702 solver.cpp:218] Iteration 92700 (12.0028 iter/s, 8.33142s/100 iters), loss = 0.00262844
I1006 19:51:11.210566  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00262844 (* 1 = 0.00262844 loss)
I1006 19:51:11.210572  3702 sgd_solver.cpp:105] Iteration 92700, lr = 0.001
I1006 19:51:19.550500  3702 solver.cpp:218] Iteration 92800 (11.9905 iter/s, 8.33991s/100 iters), loss = 0.00175881
I1006 19:51:19.550606  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00175881 (* 1 = 0.00175881 loss)
I1006 19:51:19.550612  3702 sgd_solver.cpp:105] Iteration 92800, lr = 0.001
I1006 19:51:27.885892  3702 solver.cpp:218] Iteration 92900 (11.9972 iter/s, 8.33527s/100 iters), loss = 0.00102995
I1006 19:51:27.885922  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00102994 (* 1 = 0.00102994 loss)
I1006 19:51:27.885938  3702 sgd_solver.cpp:105] Iteration 92900, lr = 0.001
I1006 19:51:35.811550  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:51:36.144708  3702 solver.cpp:330] Iteration 93000, Testing net (#0)
I1006 19:51:38.071239  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:51:38.152272  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9252
I1006 19:51:38.152307  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.308705 (* 1 = 0.308705 loss)
I1006 19:51:38.235074  3702 solver.cpp:218] Iteration 93000 (9.66266 iter/s, 10.3491s/100 iters), loss = 0.00167436
I1006 19:51:38.235107  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00167436 (* 1 = 0.00167436 loss)
I1006 19:51:38.235114  3702 sgd_solver.cpp:105] Iteration 93000, lr = 0.001
I1006 19:51:46.573228  3702 solver.cpp:218] Iteration 93100 (11.9931 iter/s, 8.3381s/100 iters), loss = 0.00598465
I1006 19:51:46.573268  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00598464 (* 1 = 0.00598464 loss)
I1006 19:51:46.573274  3702 sgd_solver.cpp:105] Iteration 93100, lr = 0.001
I1006 19:51:54.918339  3702 solver.cpp:218] Iteration 93200 (11.9832 iter/s, 8.34505s/100 iters), loss = 0.004069
I1006 19:51:54.918442  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00406899 (* 1 = 0.00406899 loss)
I1006 19:51:54.918459  3702 sgd_solver.cpp:105] Iteration 93200, lr = 0.001
I1006 19:52:03.257954  3702 solver.cpp:218] Iteration 93300 (11.9911 iter/s, 8.33949s/100 iters), loss = 0.00150894
I1006 19:52:03.257983  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00150894 (* 1 = 0.00150894 loss)
I1006 19:52:03.257989  3702 sgd_solver.cpp:105] Iteration 93300, lr = 0.001
I1006 19:52:11.602470  3702 solver.cpp:218] Iteration 93400 (11.984 iter/s, 8.34446s/100 iters), loss = 0.000910709
I1006 19:52:11.602509  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000910707 (* 1 = 0.000910707 loss)
I1006 19:52:11.602515  3702 sgd_solver.cpp:105] Iteration 93400, lr = 0.001
I1006 19:52:19.532997  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:52:19.866705  3702 solver.cpp:330] Iteration 93500, Testing net (#0)
I1006 19:52:21.793182  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:52:21.873771  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9252
I1006 19:52:21.873809  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.307511 (* 1 = 0.307511 loss)
I1006 19:52:21.957257  3702 solver.cpp:218] Iteration 93500 (9.65743 iter/s, 10.3547s/100 iters), loss = 0.00152603
I1006 19:52:21.957283  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00152603 (* 1 = 0.00152603 loss)
I1006 19:52:21.957290  3702 sgd_solver.cpp:105] Iteration 93500, lr = 0.001
I1006 19:52:30.298714  3702 solver.cpp:218] Iteration 93600 (11.9884 iter/s, 8.3414s/100 iters), loss = 0.00149595
I1006 19:52:30.298785  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00149595 (* 1 = 0.00149595 loss)
I1006 19:52:30.298804  3702 sgd_solver.cpp:105] Iteration 93600, lr = 0.001
I1006 19:52:38.628839  3702 solver.cpp:218] Iteration 93700 (12.0048 iter/s, 8.33003s/100 iters), loss = 0.000610227
I1006 19:52:38.628880  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000610221 (* 1 = 0.000610221 loss)
I1006 19:52:38.628885  3702 sgd_solver.cpp:105] Iteration 93700, lr = 0.001
I1006 19:52:46.972007  3702 solver.cpp:218] Iteration 93800 (11.986 iter/s, 8.3431s/100 iters), loss = 0.000686913
I1006 19:52:46.972046  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000686908 (* 1 = 0.000686908 loss)
I1006 19:52:46.972053  3702 sgd_solver.cpp:105] Iteration 93800, lr = 0.001
I1006 19:52:55.306988  3702 solver.cpp:218] Iteration 93900 (11.9977 iter/s, 8.33492s/100 iters), loss = 0.000951586
I1006 19:52:55.307018  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000951581 (* 1 = 0.000951581 loss)
I1006 19:52:55.307024  3702 sgd_solver.cpp:105] Iteration 93900, lr = 0.001
I1006 19:53:03.233562  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:53:03.566828  3702 solver.cpp:330] Iteration 94000, Testing net (#0)
I1006 19:53:05.494137  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:53:05.575170  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9251
I1006 19:53:05.575206  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.3093 (* 1 = 0.3093 loss)
I1006 19:53:05.658226  3702 solver.cpp:218] Iteration 94000 (9.66073 iter/s, 10.3512s/100 iters), loss = 0.00134098
I1006 19:53:05.658252  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00134098 (* 1 = 0.00134098 loss)
I1006 19:53:05.658258  3702 sgd_solver.cpp:105] Iteration 94000, lr = 0.001
I1006 19:53:13.997845  3702 solver.cpp:218] Iteration 94100 (11.991 iter/s, 8.33957s/100 iters), loss = 0.00188914
I1006 19:53:13.997874  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00188913 (* 1 = 0.00188913 loss)
I1006 19:53:13.997880  3702 sgd_solver.cpp:105] Iteration 94100, lr = 0.001
I1006 19:53:22.340466  3702 solver.cpp:218] Iteration 94200 (11.9867 iter/s, 8.34257s/100 iters), loss = 0.0012711
I1006 19:53:22.340504  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00127109 (* 1 = 0.00127109 loss)
I1006 19:53:22.340510  3702 sgd_solver.cpp:105] Iteration 94200, lr = 0.001
I1006 19:53:30.682852  3702 solver.cpp:218] Iteration 94300 (11.9871 iter/s, 8.34232s/100 iters), loss = 0.00241767
I1006 19:53:30.682891  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00241767 (* 1 = 0.00241767 loss)
I1006 19:53:30.682898  3702 sgd_solver.cpp:105] Iteration 94300, lr = 0.001
I1006 19:53:39.027365  3702 solver.cpp:218] Iteration 94400 (11.984 iter/s, 8.34445s/100 iters), loss = 0.00312883
I1006 19:53:39.027493  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00312883 (* 1 = 0.00312883 loss)
I1006 19:53:39.027508  3702 sgd_solver.cpp:105] Iteration 94400, lr = 0.001
I1006 19:53:46.951987  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:53:47.287340  3702 solver.cpp:330] Iteration 94500, Testing net (#0)
I1006 19:53:49.213958  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:53:49.294494  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.925
I1006 19:53:49.294530  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.308603 (* 1 = 0.308603 loss)
I1006 19:53:49.378029  3702 solver.cpp:218] Iteration 94500 (9.66135 iter/s, 10.3505s/100 iters), loss = 0.00210826
I1006 19:53:49.378056  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00210826 (* 1 = 0.00210826 loss)
I1006 19:53:49.378062  3702 sgd_solver.cpp:105] Iteration 94500, lr = 0.001
I1006 19:53:57.721055  3702 solver.cpp:218] Iteration 94600 (11.9861 iter/s, 8.34298s/100 iters), loss = 0.00265002
I1006 19:53:57.721084  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00265001 (* 1 = 0.00265001 loss)
I1006 19:53:57.721101  3702 sgd_solver.cpp:105] Iteration 94600, lr = 0.001
I1006 19:54:06.060421  3702 solver.cpp:218] Iteration 94700 (11.9914 iter/s, 8.33931s/100 iters), loss = 0.0109939
I1006 19:54:06.060461  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0109939 (* 1 = 0.0109939 loss)
I1006 19:54:06.060467  3702 sgd_solver.cpp:105] Iteration 94700, lr = 0.001
I1006 19:54:14.405717  3702 solver.cpp:218] Iteration 94800 (11.9829 iter/s, 8.34523s/100 iters), loss = 0.00186746
I1006 19:54:14.405843  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00186746 (* 1 = 0.00186746 loss)
I1006 19:54:14.405859  3702 sgd_solver.cpp:105] Iteration 94800, lr = 0.001
I1006 19:54:22.747138  3702 solver.cpp:218] Iteration 94900 (11.9886 iter/s, 8.34127s/100 iters), loss = 0.00155911
I1006 19:54:22.747180  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00155911 (* 1 = 0.00155911 loss)
I1006 19:54:22.747186  3702 sgd_solver.cpp:105] Iteration 94900, lr = 0.001
I1006 19:54:30.679603  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:54:31.013852  3702 solver.cpp:330] Iteration 95000, Testing net (#0)
I1006 19:54:32.939951  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:54:33.020998  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9259
I1006 19:54:33.021039  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.308908 (* 1 = 0.308908 loss)
I1006 19:54:33.103446  3702 solver.cpp:218] Iteration 95000 (9.65602 iter/s, 10.3562s/100 iters), loss = 0.00543699
I1006 19:54:33.103472  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00543699 (* 1 = 0.00543699 loss)
I1006 19:54:33.103478  3702 sgd_solver.cpp:105] Iteration 95000, lr = 0.001
I1006 19:54:41.443531  3702 solver.cpp:218] Iteration 95100 (11.9904 iter/s, 8.34004s/100 iters), loss = 0.00818155
I1006 19:54:41.443572  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00818154 (* 1 = 0.00818154 loss)
I1006 19:54:41.443578  3702 sgd_solver.cpp:105] Iteration 95100, lr = 0.001
I1006 19:54:49.786188  3702 solver.cpp:218] Iteration 95200 (11.9867 iter/s, 8.3426s/100 iters), loss = 0.000709463
I1006 19:54:49.786309  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000709465 (* 1 = 0.000709465 loss)
I1006 19:54:49.786316  3702 sgd_solver.cpp:105] Iteration 95200, lr = 0.001
I1006 19:54:58.122757  3702 solver.cpp:218] Iteration 95300 (11.9956 iter/s, 8.33642s/100 iters), loss = 0.00171604
I1006 19:54:58.122786  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00171604 (* 1 = 0.00171604 loss)
I1006 19:54:58.122792  3702 sgd_solver.cpp:105] Iteration 95300, lr = 0.001
I1006 19:55:06.461755  3702 solver.cpp:218] Iteration 95400 (11.9919 iter/s, 8.33895s/100 iters), loss = 0.0010682
I1006 19:55:06.461786  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0010682 (* 1 = 0.0010682 loss)
I1006 19:55:06.461791  3702 sgd_solver.cpp:105] Iteration 95400, lr = 0.001
I1006 19:55:14.381434  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:55:14.715257  3702 solver.cpp:330] Iteration 95500, Testing net (#0)
I1006 19:55:16.642757  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:55:16.723155  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9257
I1006 19:55:16.723193  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.309232 (* 1 = 0.309232 loss)
I1006 19:55:16.806318  3702 solver.cpp:218] Iteration 95500 (9.66697 iter/s, 10.3445s/100 iters), loss = 0.00344206
I1006 19:55:16.806344  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00344205 (* 1 = 0.00344205 loss)
I1006 19:55:16.806350  3702 sgd_solver.cpp:105] Iteration 95500, lr = 0.001
I1006 19:55:25.146772  3702 solver.cpp:218] Iteration 95600 (11.9898 iter/s, 8.3404s/100 iters), loss = 0.00129101
I1006 19:55:25.146903  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00129101 (* 1 = 0.00129101 loss)
I1006 19:55:25.146911  3702 sgd_solver.cpp:105] Iteration 95600, lr = 0.001
I1006 19:55:33.480234  3702 solver.cpp:218] Iteration 95700 (12 iter/s, 8.33331s/100 iters), loss = 0.00325328
I1006 19:55:33.480273  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00325328 (* 1 = 0.00325328 loss)
I1006 19:55:33.480279  3702 sgd_solver.cpp:105] Iteration 95700, lr = 0.001
I1006 19:55:41.818591  3702 solver.cpp:218] Iteration 95800 (11.9929 iter/s, 8.33829s/100 iters), loss = 0.00306572
I1006 19:55:41.818621  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00306572 (* 1 = 0.00306572 loss)
I1006 19:55:41.818626  3702 sgd_solver.cpp:105] Iteration 95800, lr = 0.001
I1006 19:55:50.152791  3702 solver.cpp:218] Iteration 95900 (11.9988 iter/s, 8.33415s/100 iters), loss = 0.000926819
I1006 19:55:50.152830  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000926819 (* 1 = 0.000926819 loss)
I1006 19:55:50.152837  3702 sgd_solver.cpp:105] Iteration 95900, lr = 0.001
I1006 19:55:58.083845  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:55:58.417596  3702 solver.cpp:330] Iteration 96000, Testing net (#0)
I1006 19:56:00.345360  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:56:00.426743  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.926
I1006 19:56:00.426769  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.310305 (* 1 = 0.310305 loss)
I1006 19:56:00.509333  3702 solver.cpp:218] Iteration 96000 (9.6558 iter/s, 10.3565s/100 iters), loss = 0.000709512
I1006 19:56:00.509358  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000709514 (* 1 = 0.000709514 loss)
I1006 19:56:00.509366  3702 sgd_solver.cpp:105] Iteration 96000, lr = 0.001
I1006 19:56:08.845230  3702 solver.cpp:218] Iteration 96100 (11.9964 iter/s, 8.33585s/100 iters), loss = 0.00299314
I1006 19:56:08.845270  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00299314 (* 1 = 0.00299314 loss)
I1006 19:56:08.845276  3702 sgd_solver.cpp:105] Iteration 96100, lr = 0.001
I1006 19:56:17.188246  3702 solver.cpp:218] Iteration 96200 (11.9862 iter/s, 8.34295s/100 iters), loss = 0.00123692
I1006 19:56:17.188275  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00123692 (* 1 = 0.00123692 loss)
I1006 19:56:17.188282  3702 sgd_solver.cpp:105] Iteration 96200, lr = 0.001
I1006 19:56:25.527192  3702 solver.cpp:218] Iteration 96300 (11.992 iter/s, 8.33889s/100 iters), loss = 0.00322785
I1006 19:56:25.527222  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00322785 (* 1 = 0.00322785 loss)
I1006 19:56:25.527238  3702 sgd_solver.cpp:105] Iteration 96300, lr = 0.001
I1006 19:56:33.869195  3702 solver.cpp:218] Iteration 96400 (11.9876 iter/s, 8.34195s/100 iters), loss = 0.00319289
I1006 19:56:33.869330  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00319289 (* 1 = 0.00319289 loss)
I1006 19:56:33.869349  3702 sgd_solver.cpp:105] Iteration 96400, lr = 0.001
I1006 19:56:41.792711  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:56:42.126744  3702 solver.cpp:330] Iteration 96500, Testing net (#0)
I1006 19:56:44.052767  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:56:44.133517  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9258
I1006 19:56:44.133553  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.308651 (* 1 = 0.308651 loss)
I1006 19:56:44.216881  3702 solver.cpp:218] Iteration 96500 (9.66414 iter/s, 10.3475s/100 iters), loss = 0.00490099
I1006 19:56:44.216914  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00490099 (* 1 = 0.00490099 loss)
I1006 19:56:44.216922  3702 sgd_solver.cpp:105] Iteration 96500, lr = 0.001
I1006 19:56:52.558814  3702 solver.cpp:218] Iteration 96600 (11.9877 iter/s, 8.34188s/100 iters), loss = 0.00434613
I1006 19:56:52.558842  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00434613 (* 1 = 0.00434613 loss)
I1006 19:56:52.558858  3702 sgd_solver.cpp:105] Iteration 96600, lr = 0.001
I1006 19:57:00.896723  3702 solver.cpp:218] Iteration 96700 (11.9935 iter/s, 8.33786s/100 iters), loss = 0.00144181
I1006 19:57:00.896752  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00144181 (* 1 = 0.00144181 loss)
I1006 19:57:00.896767  3702 sgd_solver.cpp:105] Iteration 96700, lr = 0.001
I1006 19:57:09.238925  3702 solver.cpp:218] Iteration 96800 (11.9873 iter/s, 8.34215s/100 iters), loss = 0.00379403
I1006 19:57:09.239056  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00379403 (* 1 = 0.00379403 loss)
I1006 19:57:09.239068  3702 sgd_solver.cpp:105] Iteration 96800, lr = 0.001
I1006 19:57:17.578948  3702 solver.cpp:218] Iteration 96900 (11.9906 iter/s, 8.33988s/100 iters), loss = 0.000727994
I1006 19:57:17.578986  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000727996 (* 1 = 0.000727996 loss)
I1006 19:57:17.578992  3702 sgd_solver.cpp:105] Iteration 96900, lr = 0.001
I1006 19:57:25.509968  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:57:25.843837  3702 solver.cpp:330] Iteration 97000, Testing net (#0)
I1006 19:57:27.770741  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:57:27.851372  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9258
I1006 19:57:27.851408  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.310179 (* 1 = 0.310179 loss)
I1006 19:57:27.934013  3702 solver.cpp:218] Iteration 97000 (9.65717 iter/s, 10.355s/100 iters), loss = 0.00126441
I1006 19:57:27.934038  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00126441 (* 1 = 0.00126441 loss)
I1006 19:57:27.934046  3702 sgd_solver.cpp:105] Iteration 97000, lr = 0.001
I1006 19:57:36.277566  3702 solver.cpp:218] Iteration 97100 (11.9854 iter/s, 8.3435s/100 iters), loss = 0.00257626
I1006 19:57:36.277606  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00257626 (* 1 = 0.00257626 loss)
I1006 19:57:36.277611  3702 sgd_solver.cpp:105] Iteration 97100, lr = 0.001
I1006 19:57:44.628839  3702 solver.cpp:218] Iteration 97200 (11.9743 iter/s, 8.35121s/100 iters), loss = 0.00126359
I1006 19:57:44.628935  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00126359 (* 1 = 0.00126359 loss)
I1006 19:57:44.628942  3702 sgd_solver.cpp:105] Iteration 97200, lr = 0.001
I1006 19:57:52.974185  3702 solver.cpp:218] Iteration 97300 (11.9829 iter/s, 8.34523s/100 iters), loss = 0.0113729
I1006 19:57:52.974215  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0113729 (* 1 = 0.0113729 loss)
I1006 19:57:52.974220  3702 sgd_solver.cpp:105] Iteration 97300, lr = 0.001
I1006 19:58:01.320451  3702 solver.cpp:218] Iteration 97400 (11.9815 iter/s, 8.34622s/100 iters), loss = 0.00158784
I1006 19:58:01.320482  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00158783 (* 1 = 0.00158783 loss)
I1006 19:58:01.320487  3702 sgd_solver.cpp:105] Iteration 97400, lr = 0.001
I1006 19:58:09.248764  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:58:09.583475  3702 solver.cpp:330] Iteration 97500, Testing net (#0)
I1006 19:58:11.510504  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:58:11.591495  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9243
I1006 19:58:11.591531  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.309441 (* 1 = 0.309441 loss)
I1006 19:58:11.675118  3702 solver.cpp:218] Iteration 97500 (9.65753 iter/s, 10.3546s/100 iters), loss = 0.00440215
I1006 19:58:11.675145  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00440214 (* 1 = 0.00440214 loss)
I1006 19:58:11.675153  3702 sgd_solver.cpp:105] Iteration 97500, lr = 0.001
I1006 19:58:20.021878  3702 solver.cpp:218] Iteration 97600 (11.9808 iter/s, 8.34671s/100 iters), loss = 0.0020471
I1006 19:58:20.021980  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0020471 (* 1 = 0.0020471 loss)
I1006 19:58:20.021986  3702 sgd_solver.cpp:105] Iteration 97600, lr = 0.001
I1006 19:58:28.366201  3702 solver.cpp:218] Iteration 97700 (11.9844 iter/s, 8.34421s/100 iters), loss = 0.00151723
I1006 19:58:28.366242  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00151722 (* 1 = 0.00151722 loss)
I1006 19:58:28.366248  3702 sgd_solver.cpp:105] Iteration 97700, lr = 0.001
I1006 19:58:36.711771  3702 solver.cpp:218] Iteration 97800 (11.9825 iter/s, 8.34551s/100 iters), loss = 0.00283059
I1006 19:58:36.711812  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00283058 (* 1 = 0.00283058 loss)
I1006 19:58:36.711817  3702 sgd_solver.cpp:105] Iteration 97800, lr = 0.001
I1006 19:58:45.053561  3702 solver.cpp:218] Iteration 97900 (11.9879 iter/s, 8.34173s/100 iters), loss = 0.00108082
I1006 19:58:45.053601  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00108081 (* 1 = 0.00108081 loss)
I1006 19:58:45.053607  3702 sgd_solver.cpp:105] Iteration 97900, lr = 0.001
I1006 19:58:52.986840  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:58:53.320439  3702 solver.cpp:330] Iteration 98000, Testing net (#0)
I1006 19:58:55.247118  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:58:55.328013  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9247
I1006 19:58:55.328048  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.309713 (* 1 = 0.309713 loss)
I1006 19:58:55.410886  3702 solver.cpp:218] Iteration 98000 (9.65507 iter/s, 10.3573s/100 iters), loss = 0.00521932
I1006 19:58:55.410915  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00521931 (* 1 = 0.00521931 loss)
I1006 19:58:55.410923  3702 sgd_solver.cpp:105] Iteration 98000, lr = 0.001
I1006 19:59:03.748798  3702 solver.cpp:218] Iteration 98100 (11.9935 iter/s, 8.33786s/100 iters), loss = 0.00293
I1006 19:59:03.748827  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00292999 (* 1 = 0.00292999 loss)
I1006 19:59:03.748833  3702 sgd_solver.cpp:105] Iteration 98100, lr = 0.001
I1006 19:59:12.090930  3702 solver.cpp:218] Iteration 98200 (11.9874 iter/s, 8.34208s/100 iters), loss = 0.00344718
I1006 19:59:12.090970  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00344717 (* 1 = 0.00344717 loss)
I1006 19:59:12.090976  3702 sgd_solver.cpp:105] Iteration 98200, lr = 0.001
I1006 19:59:20.432279  3702 solver.cpp:218] Iteration 98300 (11.9886 iter/s, 8.34129s/100 iters), loss = 0.00205971
I1006 19:59:20.432310  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0020597 (* 1 = 0.0020597 loss)
I1006 19:59:20.432317  3702 sgd_solver.cpp:105] Iteration 98300, lr = 0.001
I1006 19:59:28.773916  3702 solver.cpp:218] Iteration 98400 (11.9881 iter/s, 8.34158s/100 iters), loss = 0.00232537
I1006 19:59:28.774026  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00232536 (* 1 = 0.00232536 loss)
I1006 19:59:28.774034  3702 sgd_solver.cpp:105] Iteration 98400, lr = 0.001
I1006 19:59:36.702926  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:59:37.036219  3702 solver.cpp:330] Iteration 98500, Testing net (#0)
I1006 19:59:38.961768  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 19:59:39.042114  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9251
I1006 19:59:39.042138  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.309785 (* 1 = 0.309785 loss)
I1006 19:59:39.125308  3702 solver.cpp:218] Iteration 98500 (9.66066 iter/s, 10.3513s/100 iters), loss = 0.00081147
I1006 19:59:39.125336  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000811455 (* 1 = 0.000811455 loss)
I1006 19:59:39.125342  3702 sgd_solver.cpp:105] Iteration 98500, lr = 0.001
I1006 19:59:47.473150  3702 solver.cpp:218] Iteration 98600 (11.9792 iter/s, 8.34779s/100 iters), loss = 0.00120839
I1006 19:59:47.473191  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00120837 (* 1 = 0.00120837 loss)
I1006 19:59:47.473196  3702 sgd_solver.cpp:105] Iteration 98600, lr = 0.001
I1006 19:59:55.813097  3702 solver.cpp:218] Iteration 98700 (11.9906 iter/s, 8.33988s/100 iters), loss = 0.0183409
I1006 19:59:55.813135  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0183408 (* 1 = 0.0183408 loss)
I1006 19:59:55.813141  3702 sgd_solver.cpp:105] Iteration 98700, lr = 0.001
I1006 20:00:04.158371  3702 solver.cpp:218] Iteration 98800 (11.9829 iter/s, 8.34521s/100 iters), loss = 0.000757329
I1006 20:00:04.158507  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000757313 (* 1 = 0.000757313 loss)
I1006 20:00:04.158514  3702 sgd_solver.cpp:105] Iteration 98800, lr = 0.001
I1006 20:00:12.499706  3702 solver.cpp:218] Iteration 98900 (11.9887 iter/s, 8.34119s/100 iters), loss = 0.00151327
I1006 20:00:12.499745  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00151325 (* 1 = 0.00151325 loss)
I1006 20:00:12.499752  3702 sgd_solver.cpp:105] Iteration 98900, lr = 0.001
I1006 20:00:20.431498  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:00:20.765985  3702 solver.cpp:330] Iteration 99000, Testing net (#0)
I1006 20:00:22.691937  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:00:22.772755  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9251
I1006 20:00:22.772791  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.309472 (* 1 = 0.309472 loss)
I1006 20:00:22.855896  3702 solver.cpp:218] Iteration 99000 (9.65612 iter/s, 10.3561s/100 iters), loss = 0.00881253
I1006 20:00:22.855926  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00881251 (* 1 = 0.00881251 loss)
I1006 20:00:22.855931  3702 sgd_solver.cpp:105] Iteration 99000, lr = 0.001
I1006 20:00:31.196535  3702 solver.cpp:218] Iteration 99100 (11.9896 iter/s, 8.34058s/100 iters), loss = 0.00193546
I1006 20:00:31.196583  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00193545 (* 1 = 0.00193545 loss)
I1006 20:00:31.196589  3702 sgd_solver.cpp:105] Iteration 99100, lr = 0.001
I1006 20:00:39.538964  3702 solver.cpp:218] Iteration 99200 (11.987 iter/s, 8.34236s/100 iters), loss = 0.00343293
I1006 20:00:39.539053  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00343291 (* 1 = 0.00343291 loss)
I1006 20:00:39.539060  3702 sgd_solver.cpp:105] Iteration 99200, lr = 0.001
I1006 20:00:47.881304  3702 solver.cpp:218] Iteration 99300 (11.9872 iter/s, 8.34223s/100 iters), loss = 0.00650074
I1006 20:00:47.881343  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00650073 (* 1 = 0.00650073 loss)
I1006 20:00:47.881350  3702 sgd_solver.cpp:105] Iteration 99300, lr = 0.001
I1006 20:00:56.226706  3702 solver.cpp:218] Iteration 99400 (11.9827 iter/s, 8.34534s/100 iters), loss = 0.000380944
I1006 20:00:56.226745  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000380926 (* 1 = 0.000380926 loss)
I1006 20:00:56.226752  3702 sgd_solver.cpp:105] Iteration 99400, lr = 0.001
I1006 20:01:04.159160  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:01:04.493666  3702 solver.cpp:330] Iteration 99500, Testing net (#0)
I1006 20:01:06.420809  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:01:06.501250  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9249
I1006 20:01:06.501286  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.309411 (* 1 = 0.309411 loss)
I1006 20:01:06.584959  3702 solver.cpp:218] Iteration 99500 (9.6542 iter/s, 10.3582s/100 iters), loss = 0.00322326
I1006 20:01:06.584988  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00322324 (* 1 = 0.00322324 loss)
I1006 20:01:06.584995  3702 sgd_solver.cpp:105] Iteration 99500, lr = 0.001
I1006 20:01:14.930342  3702 solver.cpp:218] Iteration 99600 (11.9828 iter/s, 8.34533s/100 iters), loss = 0.00138462
I1006 20:01:14.930418  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0013846 (* 1 = 0.0013846 loss)
I1006 20:01:14.930424  3702 sgd_solver.cpp:105] Iteration 99600, lr = 0.001
I1006 20:01:23.269049  3702 solver.cpp:218] Iteration 99700 (11.9924 iter/s, 8.33861s/100 iters), loss = 0.000301311
I1006 20:01:23.269090  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000301288 (* 1 = 0.000301288 loss)
I1006 20:01:23.269096  3702 sgd_solver.cpp:105] Iteration 99700, lr = 0.001
I1006 20:01:31.610661  3702 solver.cpp:218] Iteration 99800 (11.9882 iter/s, 8.34155s/100 iters), loss = 0.0033483
I1006 20:01:31.610700  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00334828 (* 1 = 0.00334828 loss)
I1006 20:01:31.610707  3702 sgd_solver.cpp:105] Iteration 99800, lr = 0.001
I1006 20:01:39.944684  3702 solver.cpp:218] Iteration 99900 (11.9991 iter/s, 8.33396s/100 iters), loss = 0.000680223
I1006 20:01:39.944723  3702 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000680202 (* 1 = 0.000680202 loss)
I1006 20:01:39.944730  3702 sgd_solver.cpp:105] Iteration 99900, lr = 0.001
I1006 20:01:47.873899  3711 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:01:48.207813  3702 solver.cpp:447] Snapshotting to binary proto file xn/PENLU/snapshot/resnet/res32/res32_penlu_alpha0.25_beta1_etanostudy_2study_2decay_gauss_iter_100000.caffemodel
I1006 20:01:48.221926  3702 sgd_solver.cpp:273] Snapshotting solver state to binary proto file xn/PENLU/snapshot/resnet/res32/res32_penlu_alpha0.25_beta1_etanostudy_2study_2decay_gauss_iter_100000.solverstate
I1006 20:01:48.288522  3702 solver.cpp:310] Iteration 100000, loss = 0.000752704
I1006 20:01:48.288542  3702 solver.cpp:330] Iteration 100000, Testing net (#0)
I1006 20:01:50.212788  3712 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:01:50.292649  3702 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9247
I1006 20:01:50.292672  3702 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.308558 (* 1 = 0.308558 loss)
I1006 20:01:50.292676  3702 solver.cpp:315] Optimization Done.
I1006 20:01:50.292678  3702 caffe.cpp:259] Optimization Done.
