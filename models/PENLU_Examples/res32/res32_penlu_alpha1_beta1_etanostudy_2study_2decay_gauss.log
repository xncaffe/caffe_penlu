I1007 10:06:32.993576  4720 caffe.cpp:218] Using GPUs 0
I1007 10:06:33.028084  4720 caffe.cpp:223] GPU 0: GeForce GTX 1080
I1007 10:06:33.255053  4720 solver.cpp:44] Initializing solver from parameters: 
test_iter: 100
test_interval: 500
base_lr: 0.1
display: 100
max_iter: 100000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0001
snapshot: 100000
snapshot_prefix: "xn/PENLU/snapshot/resnet/res32/res32_penlu_alpha1_beta1_etanostudy_2study_2decay_gauss"
solver_mode: GPU
device_id: 0
net: "/home/x306/caffe/xn/PENLU/neural/resnet/res32/res32_penlu_decay_gauss.prototxt"
train_state {
  level: 0
  stage: ""
}
stepvalue: 40000
stepvalue: 80000
I1007 10:06:33.255198  4720 solver.cpp:87] Creating training net from net file: /home/x306/caffe/xn/PENLU/neural/resnet/res32/res32_penlu_decay_gauss.prototxt
I1007 10:06:33.257581  4720 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: /home/x306/caffe/xn/PENLU/neural/resnet/res32/res32_penlu_decay_gauss.prototxt
I1007 10:06:33.257593  4720 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I1007 10:06:33.257784  4720 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer Data1
I1007 10:06:33.257877  4720 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer Accuracy1
I1007 10:06:33.258582  4720 net.cpp:51] Initializing net from parameters: 
name: "resnet_cifar10"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "Data1"
  type: "Data"
  top: "Data1"
  top: "Data2"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 28
    mean_file: "/home/x306/caffe/xn/PENLU/data/cifar10/mean.binaryproto"
  }
  data_param {
    source: "/home/x306/caffe/xn/PENLU/data/cifar10/cifar10_train_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "Convolution1"
  type: "Convolution"
  bottom: "Data1"
  top: "Convolution1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm1"
  type: "BatchNorm"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1"
  type: "Scale"
  bottom: "Convolution1"
  top: "Convolution1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu1"
  type: "PENLU"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution2"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm2"
  type: "BatchNorm"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale2"
  type: "Scale"
  bottom: "Convolution2"
  top: "Convolution2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu2"
  type: "PENLU"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution3"
  type: "Convolution"
  bottom: "Convolution2"
  top: "Convolution3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm3"
  type: "BatchNorm"
  bottom: "Convolution3"
  top: "Convolution3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale3"
  type: "Scale"
  bottom: "Convolution3"
  top: "Convolution3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise1"
  type: "Eltwise"
  bottom: "Convolution1"
  bottom: "Convolution3"
  top: "Eltwise1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu3"
  type: "PENLU"
  bottom: "Eltwise1"
  top: "Eltwise1"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution4"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm4"
  type: "BatchNorm"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale4"
  type: "Scale"
  bottom: "Convolution4"
  top: "Convolution4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu4"
  type: "PENLU"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution5"
  type: "Convolution"
  bottom: "Convolution4"
  top: "Convolution5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm5"
  type: "BatchNorm"
  bottom: "Convolution5"
  top: "Convolution5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale5"
  type: "Scale"
  bottom: "Convolution5"
  top: "Convolution5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise2"
  type: "Eltwise"
  bottom: "Eltwise1"
  bottom: "Convolution5"
  top: "Eltwise2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu5"
  type: "PENLU"
  bottom: "Eltwise2"
  top: "Eltwise2"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution6"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm6"
  type: "BatchNorm"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale6"
  type: "Scale"
  bottom: "Convolution6"
  top: "Convolution6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu6"
  type: "PENLU"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution7"
  type: "Convolution"
  bottom: "Convolution6"
  top: "Convolution7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm7"
  type: "BatchNorm"
  bottom: "Convolution7"
  top: "Convolution7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale7"
  type: "Scale"
  bottom: "Convolution7"
  top: "Convolution7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise3"
  type: "Eltwise"
  bottom: "Eltwise2"
  bottom: "Convolution7"
  top: "Eltwise3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu7"
  type: "PENLU"
  bottom: "Eltwise3"
  top: "Eltwise3"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution8"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm8"
  type: "BatchNorm"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale8"
  type: "Scale"
  bottom: "Convolution8"
  top: "Convolution8"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu8"
  type: "PENLU"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution9"
  type: "Convolution"
  bottom: "Convolution8"
  top: "Convolution9"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm9"
  type: "BatchNorm"
  bottom: "Convolution9"
  top: "Convolution9"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale9"
  type: "Scale"
  bottom: "Convolution9"
  top: "Convolution9"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise4"
  type: "Eltwise"
  bottom: "Eltwise3"
  bottom: "Convolution9"
  top: "Eltwise4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu9"
  type: "PENLU"
  bottom: "Eltwise4"
  top: "Eltwise4"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution10"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution10"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm10"
  type: "BatchNorm"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale10"
  type: "Scale"
  bottom: "Convolution10"
  top: "Convolution10"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu10"
  type: "PENLU"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution11"
  type: "Convolution"
  bottom: "Convolution10"
  top: "Convolution11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm11"
  type: "BatchNorm"
  bottom: "Convolution11"
  top: "Convolution11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale11"
  type: "Scale"
  bottom: "Convolution11"
  top: "Convolution11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise5"
  type: "Eltwise"
  bottom: "Eltwise4"
  bottom: "Convolution11"
  top: "Eltwise5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu11"
  type: "PENLU"
  bottom: "Eltwise5"
  top: "Eltwise5"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution12"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.25
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm12"
  type: "BatchNorm"
  bottom: "Convolution12"
  top: "Convolution12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale12"
  type: "Scale"
  bottom: "Convolution12"
  top: "Convolution12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution13"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution13"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm13"
  type: "BatchNorm"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale13"
  type: "Scale"
  bottom: "Convolution13"
  top: "Convolution13"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu12"
  type: "PENLU"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution14"
  type: "Convolution"
  bottom: "Convolution13"
  top: "Convolution14"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm14"
  type: "BatchNorm"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale14"
  type: "Scale"
  bottom: "Convolution14"
  top: "Convolution14"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise6"
  type: "Eltwise"
  bottom: "Convolution12"
  bottom: "Convolution14"
  top: "Eltwise6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu13"
  type: "PENLU"
  bottom: "Eltwise6"
  top: "Eltwise6"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution15"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution15"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm15"
  type: "BatchNorm"
  bottom: "Convolution15"
  top: "Convolution15"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale15"
  type: "Scale"
  bottom: "Convolution15"
  top: "Convolution15"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu14"
  type: "PENLU"
  bottom: "Convolution15"
  top: "Convolution15"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution16"
  type: "Convolution"
  bottom: "Convolution15"
  top: "Convolution16"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm16"
  type: "BatchNorm"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale16"
  type: "Scale"
  bottom: "Convolution16"
  top: "Convolution16"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise7"
  type: "Eltwise"
  bottom: "Eltwise6"
  bottom: "Convolution16"
  top: "Eltwise7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu15"
  type: "PENLU"
  bottom: "Eltwise7"
  top: "Eltwise7"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution17"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution17"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm17"
  type: "BatchNorm"
  bottom: "Convolution17"
  top: "Convolution17"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale17"
  type: "Scale"
  bottom: "Convolution17"
  top: "Convolution17"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu16"
  type: "PENLU"
  bottom: "Convolution17"
  top: "Convolution17"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution18"
  type: "Convolution"
  bottom: "Convolution17"
  top: "Convolution18"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm18"
  type: "BatchNorm"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale18"
  type: "Scale"
  bottom: "Convolution18"
  top: "Convolution18"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise8"
  type: "Eltwise"
  bottom: "Eltwise7"
  bottom: "Convolution18"
  top: "Eltwise8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu17"
  type: "PENLU"
  bottom: "Eltwise8"
  top: "Eltwise8"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution19"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution19"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm19"
  type: "BatchNorm"
  bottom: "Convolution19"
  top: "Convolution19"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale19"
  type: "Scale"
  bottom: "Convolution19"
  top: "Convolution19"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu18"
  type: "PENLU"
  bottom: "Convolution19"
  top: "Convolution19"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution20"
  type: "Convolution"
  bottom: "Convolution19"
  top: "Convolution20"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm20"
  type: "BatchNorm"
  bottom: "Convolution20"
  top: "Convolution20"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale20"
  type: "Scale"
  bottom: "Convolution20"
  top: "Convolution20"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise9"
  type: "Eltwise"
  bottom: "Eltwise8"
  bottom: "Convolution20"
  top: "Eltwise9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu19"
  type: "PENLU"
  bottom: "Eltwise9"
  top: "Eltwise9"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution21"
  type: "Convolution"
  bottom: "Eltwise9"
  top: "Convolution21"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm21"
  type: "BatchNorm"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale21"
  type: "Scale"
  bottom: "Convolution21"
  top: "Convolution21"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu20"
  type: "PENLU"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution22"
  type: "Convolution"
  bottom: "Convolution21"
  top: "Convolution22"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm22"
  type: "BatchNorm"
  bottom: "Convolution22"
  top: "Convolution22"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale22"
  type: "Scale"
  bottom: "Convolution22"
  top: "Convolution22"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise10"
  type: "Eltwise"
  bottom: "Eltwise9"
  bottom: "Convolution22"
  top: "Eltwise10"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu21"
  type: "PENLU"
  bottom: "Eltwise10"
  top: "Eltwise10"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution23"
  type: "Convolution"
  bottom: "Eltwise10"
  top: "Convolution23"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.17677669
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm23"
  type: "BatchNorm"
  bottom: "Convolution23"
  top: "Convolution23"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale23"
  type: "Scale"
  bottom: "Convolution23"
  top: "Convolution23"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution24"
  type: "Convolution"
  bottom: "Eltwise10"
  top: "Convolution24"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm24"
  type: "BatchNorm"
  bottom: "Convolution24"
  top: "Convolution24"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale24"
  type: "Scale"
  bottom: "Convolution24"
  top: "Convolution24"
  scale_param {
    bias
I1007 10:06:33.259265  4720 layer_factory.hpp:77] Creating layer Data1
I1007 10:06:33.259363  4720 db_lmdb.cpp:35] Opened lmdb /home/x306/caffe/xn/PENLU/data/cifar10/cifar10_train_lmdb
I1007 10:06:33.259389  4720 net.cpp:84] Creating Layer Data1
I1007 10:06:33.259398  4720 net.cpp:380] Data1 -> Data1
I1007 10:06:33.259423  4720 net.cpp:380] Data1 -> Data2
I1007 10:06:33.259435  4720 data_transformer.cpp:25] Loading mean file from: /home/x306/caffe/xn/PENLU/data/cifar10/mean.binaryproto
I1007 10:06:33.260989  4720 data_layer.cpp:45] output data size: 100,3,28,28
I1007 10:06:33.263315  4720 net.cpp:122] Setting up Data1
I1007 10:06:33.263329  4720 net.cpp:129] Top shape: 100 3 28 28 (235200)
I1007 10:06:33.263334  4720 net.cpp:129] Top shape: 100 (100)
I1007 10:06:33.263335  4720 net.cpp:137] Memory required for data: 941200
I1007 10:06:33.263341  4720 layer_factory.hpp:77] Creating layer Convolution1
I1007 10:06:33.263358  4720 net.cpp:84] Creating Layer Convolution1
I1007 10:06:33.263363  4720 net.cpp:406] Convolution1 <- Data1
I1007 10:06:33.263372  4720 net.cpp:380] Convolution1 -> Convolution1
I1007 10:06:33.407353  4720 net.cpp:122] Setting up Convolution1
I1007 10:06:33.407377  4720 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 10:06:33.407380  4720 net.cpp:137] Memory required for data: 5958800
I1007 10:06:33.407395  4720 layer_factory.hpp:77] Creating layer BatchNorm1
I1007 10:06:33.407421  4720 net.cpp:84] Creating Layer BatchNorm1
I1007 10:06:33.407436  4720 net.cpp:406] BatchNorm1 <- Convolution1
I1007 10:06:33.407450  4720 net.cpp:367] BatchNorm1 -> Convolution1 (in-place)
I1007 10:06:33.407594  4720 net.cpp:122] Setting up BatchNorm1
I1007 10:06:33.407600  4720 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 10:06:33.407603  4720 net.cpp:137] Memory required for data: 10976400
I1007 10:06:33.407610  4720 layer_factory.hpp:77] Creating layer Scale1
I1007 10:06:33.407619  4720 net.cpp:84] Creating Layer Scale1
I1007 10:06:33.407634  4720 net.cpp:406] Scale1 <- Convolution1
I1007 10:06:33.407639  4720 net.cpp:367] Scale1 -> Convolution1 (in-place)
I1007 10:06:33.407685  4720 layer_factory.hpp:77] Creating layer Scale1
I1007 10:06:33.407781  4720 net.cpp:122] Setting up Scale1
I1007 10:06:33.407786  4720 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 10:06:33.407788  4720 net.cpp:137] Memory required for data: 15994000
I1007 10:06:33.407793  4720 layer_factory.hpp:77] Creating layer penlu1
I1007 10:06:33.407802  4720 net.cpp:84] Creating Layer penlu1
I1007 10:06:33.407806  4720 net.cpp:406] penlu1 <- Convolution1
I1007 10:06:33.407824  4720 net.cpp:367] penlu1 -> Convolution1 (in-place)
I1007 10:06:33.408421  4720 net.cpp:122] Setting up penlu1
I1007 10:06:33.408430  4720 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 10:06:33.408433  4720 net.cpp:137] Memory required for data: 21011600
I1007 10:06:33.408440  4720 layer_factory.hpp:77] Creating layer Convolution1_penlu1_0_split
I1007 10:06:33.408445  4720 net.cpp:84] Creating Layer Convolution1_penlu1_0_split
I1007 10:06:33.408449  4720 net.cpp:406] Convolution1_penlu1_0_split <- Convolution1
I1007 10:06:33.408464  4720 net.cpp:380] Convolution1_penlu1_0_split -> Convolution1_penlu1_0_split_0
I1007 10:06:33.408473  4720 net.cpp:380] Convolution1_penlu1_0_split -> Convolution1_penlu1_0_split_1
I1007 10:06:33.408507  4720 net.cpp:122] Setting up Convolution1_penlu1_0_split
I1007 10:06:33.408512  4720 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 10:06:33.408526  4720 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 10:06:33.408529  4720 net.cpp:137] Memory required for data: 31046800
I1007 10:06:33.408530  4720 layer_factory.hpp:77] Creating layer Convolution2
I1007 10:06:33.408548  4720 net.cpp:84] Creating Layer Convolution2
I1007 10:06:33.408551  4720 net.cpp:406] Convolution2 <- Convolution1_penlu1_0_split_0
I1007 10:06:33.408569  4720 net.cpp:380] Convolution2 -> Convolution2
I1007 10:06:33.409404  4720 net.cpp:122] Setting up Convolution2
I1007 10:06:33.409415  4720 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 10:06:33.409420  4720 net.cpp:137] Memory required for data: 36064400
I1007 10:06:33.409435  4720 layer_factory.hpp:77] Creating layer BatchNorm2
I1007 10:06:33.409440  4720 net.cpp:84] Creating Layer BatchNorm2
I1007 10:06:33.409445  4720 net.cpp:406] BatchNorm2 <- Convolution2
I1007 10:06:33.409449  4720 net.cpp:367] BatchNorm2 -> Convolution2 (in-place)
I1007 10:06:33.409606  4720 net.cpp:122] Setting up BatchNorm2
I1007 10:06:33.409612  4720 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 10:06:33.409624  4720 net.cpp:137] Memory required for data: 41082000
I1007 10:06:33.409631  4720 layer_factory.hpp:77] Creating layer Scale2
I1007 10:06:33.409636  4720 net.cpp:84] Creating Layer Scale2
I1007 10:06:33.409649  4720 net.cpp:406] Scale2 <- Convolution2
I1007 10:06:33.409653  4720 net.cpp:367] Scale2 -> Convolution2 (in-place)
I1007 10:06:33.409696  4720 layer_factory.hpp:77] Creating layer Scale2
I1007 10:06:33.409797  4720 net.cpp:122] Setting up Scale2
I1007 10:06:33.409802  4720 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 10:06:33.409814  4720 net.cpp:137] Memory required for data: 46099600
I1007 10:06:33.409821  4720 layer_factory.hpp:77] Creating layer penlu2
I1007 10:06:33.409837  4720 net.cpp:84] Creating Layer penlu2
I1007 10:06:33.409842  4720 net.cpp:406] penlu2 <- Convolution2
I1007 10:06:33.409847  4720 net.cpp:367] penlu2 -> Convolution2 (in-place)
I1007 10:06:33.409965  4720 net.cpp:122] Setting up penlu2
I1007 10:06:33.409977  4720 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 10:06:33.409989  4720 net.cpp:137] Memory required for data: 51117200
I1007 10:06:33.409994  4720 layer_factory.hpp:77] Creating layer Convolution3
I1007 10:06:33.410012  4720 net.cpp:84] Creating Layer Convolution3
I1007 10:06:33.410014  4720 net.cpp:406] Convolution3 <- Convolution2
I1007 10:06:33.410019  4720 net.cpp:380] Convolution3 -> Convolution3
I1007 10:06:33.410890  4720 net.cpp:122] Setting up Convolution3
I1007 10:06:33.410900  4720 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 10:06:33.410913  4720 net.cpp:137] Memory required for data: 56134800
I1007 10:06:33.410917  4720 layer_factory.hpp:77] Creating layer BatchNorm3
I1007 10:06:33.410923  4720 net.cpp:84] Creating Layer BatchNorm3
I1007 10:06:33.410926  4720 net.cpp:406] BatchNorm3 <- Convolution3
I1007 10:06:33.410930  4720 net.cpp:367] BatchNorm3 -> Convolution3 (in-place)
I1007 10:06:33.411062  4720 net.cpp:122] Setting up BatchNorm3
I1007 10:06:33.411067  4720 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 10:06:33.411079  4720 net.cpp:137] Memory required for data: 61152400
I1007 10:06:33.411084  4720 layer_factory.hpp:77] Creating layer Scale3
I1007 10:06:33.411089  4720 net.cpp:84] Creating Layer Scale3
I1007 10:06:33.411092  4720 net.cpp:406] Scale3 <- Convolution3
I1007 10:06:33.411095  4720 net.cpp:367] Scale3 -> Convolution3 (in-place)
I1007 10:06:33.411130  4720 layer_factory.hpp:77] Creating layer Scale3
I1007 10:06:33.411229  4720 net.cpp:122] Setting up Scale3
I1007 10:06:33.411234  4720 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 10:06:33.411247  4720 net.cpp:137] Memory required for data: 66170000
I1007 10:06:33.411252  4720 layer_factory.hpp:77] Creating layer Eltwise1
I1007 10:06:33.411255  4720 net.cpp:84] Creating Layer Eltwise1
I1007 10:06:33.411258  4720 net.cpp:406] Eltwise1 <- Convolution1_penlu1_0_split_1
I1007 10:06:33.411260  4720 net.cpp:406] Eltwise1 <- Convolution3
I1007 10:06:33.411264  4720 net.cpp:380] Eltwise1 -> Eltwise1
I1007 10:06:33.411283  4720 net.cpp:122] Setting up Eltwise1
I1007 10:06:33.411295  4720 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 10:06:33.411298  4720 net.cpp:137] Memory required for data: 71187600
I1007 10:06:33.411299  4720 layer_factory.hpp:77] Creating layer penlu3
I1007 10:06:33.411315  4720 net.cpp:84] Creating Layer penlu3
I1007 10:06:33.411317  4720 net.cpp:406] penlu3 <- Eltwise1
I1007 10:06:33.411321  4720 net.cpp:367] penlu3 -> Eltwise1 (in-place)
I1007 10:06:33.411429  4720 net.cpp:122] Setting up penlu3
I1007 10:06:33.411434  4720 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 10:06:33.411437  4720 net.cpp:137] Memory required for data: 76205200
I1007 10:06:33.411451  4720 layer_factory.hpp:77] Creating layer Eltwise1_penlu3_0_split
I1007 10:06:33.411455  4720 net.cpp:84] Creating Layer Eltwise1_penlu3_0_split
I1007 10:06:33.411458  4720 net.cpp:406] Eltwise1_penlu3_0_split <- Eltwise1
I1007 10:06:33.411460  4720 net.cpp:380] Eltwise1_penlu3_0_split -> Eltwise1_penlu3_0_split_0
I1007 10:06:33.411465  4720 net.cpp:380] Eltwise1_penlu3_0_split -> Eltwise1_penlu3_0_split_1
I1007 10:06:33.411487  4720 net.cpp:122] Setting up Eltwise1_penlu3_0_split
I1007 10:06:33.411492  4720 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 10:06:33.411504  4720 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 10:06:33.411506  4720 net.cpp:137] Memory required for data: 86240400
I1007 10:06:33.411509  4720 layer_factory.hpp:77] Creating layer Convolution4
I1007 10:06:33.411526  4720 net.cpp:84] Creating Layer Convolution4
I1007 10:06:33.411528  4720 net.cpp:406] Convolution4 <- Eltwise1_penlu3_0_split_0
I1007 10:06:33.411533  4720 net.cpp:380] Convolution4 -> Convolution4
I1007 10:06:33.412406  4720 net.cpp:122] Setting up Convolution4
I1007 10:06:33.412416  4720 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 10:06:33.412428  4720 net.cpp:137] Memory required for data: 91258000
I1007 10:06:33.412433  4720 layer_factory.hpp:77] Creating layer BatchNorm4
I1007 10:06:33.412439  4720 net.cpp:84] Creating Layer BatchNorm4
I1007 10:06:33.412451  4720 net.cpp:406] BatchNorm4 <- Convolution4
I1007 10:06:33.412456  4720 net.cpp:367] BatchNorm4 -> Convolution4 (in-place)
I1007 10:06:33.412585  4720 net.cpp:122] Setting up BatchNorm4
I1007 10:06:33.412590  4720 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 10:06:33.412603  4720 net.cpp:137] Memory required for data: 96275600
I1007 10:06:33.412611  4720 layer_factory.hpp:77] Creating layer Scale4
I1007 10:06:33.412616  4720 net.cpp:84] Creating Layer Scale4
I1007 10:06:33.412621  4720 net.cpp:406] Scale4 <- Convolution4
I1007 10:06:33.412623  4720 net.cpp:367] Scale4 -> Convolution4 (in-place)
I1007 10:06:33.412658  4720 layer_factory.hpp:77] Creating layer Scale4
I1007 10:06:33.412741  4720 net.cpp:122] Setting up Scale4
I1007 10:06:33.412747  4720 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 10:06:33.412750  4720 net.cpp:137] Memory required for data: 101293200
I1007 10:06:33.412755  4720 layer_factory.hpp:77] Creating layer penlu4
I1007 10:06:33.412760  4720 net.cpp:84] Creating Layer penlu4
I1007 10:06:33.412762  4720 net.cpp:406] penlu4 <- Convolution4
I1007 10:06:33.412766  4720 net.cpp:367] penlu4 -> Convolution4 (in-place)
I1007 10:06:33.412864  4720 net.cpp:122] Setting up penlu4
I1007 10:06:33.412870  4720 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 10:06:33.412873  4720 net.cpp:137] Memory required for data: 106310800
I1007 10:06:33.412878  4720 layer_factory.hpp:77] Creating layer Convolution5
I1007 10:06:33.412885  4720 net.cpp:84] Creating Layer Convolution5
I1007 10:06:33.412889  4720 net.cpp:406] Convolution5 <- Convolution4
I1007 10:06:33.412894  4720 net.cpp:380] Convolution5 -> Convolution5
I1007 10:06:33.413776  4720 net.cpp:122] Setting up Convolution5
I1007 10:06:33.413786  4720 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 10:06:33.413790  4720 net.cpp:137] Memory required for data: 111328400
I1007 10:06:33.413794  4720 layer_factory.hpp:77] Creating layer BatchNorm5
I1007 10:06:33.413800  4720 net.cpp:84] Creating Layer BatchNorm5
I1007 10:06:33.413805  4720 net.cpp:406] BatchNorm5 <- Convolution5
I1007 10:06:33.413807  4720 net.cpp:367] BatchNorm5 -> Convolution5 (in-place)
I1007 10:06:33.413935  4720 net.cpp:122] Setting up BatchNorm5
I1007 10:06:33.413941  4720 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 10:06:33.413944  4720 net.cpp:137] Memory required for data: 116346000
I1007 10:06:33.413949  4720 layer_factory.hpp:77] Creating layer Scale5
I1007 10:06:33.413954  4720 net.cpp:84] Creating Layer Scale5
I1007 10:06:33.413957  4720 net.cpp:406] Scale5 <- Convolution5
I1007 10:06:33.413960  4720 net.cpp:367] Scale5 -> Convolution5 (in-place)
I1007 10:06:33.413988  4720 layer_factory.hpp:77] Creating layer Scale5
I1007 10:06:33.414064  4720 net.cpp:122] Setting up Scale5
I1007 10:06:33.414070  4720 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 10:06:33.414073  4720 net.cpp:137] Memory required for data: 121363600
I1007 10:06:33.414077  4720 layer_factory.hpp:77] Creating layer Eltwise2
I1007 10:06:33.414082  4720 net.cpp:84] Creating Layer Eltwise2
I1007 10:06:33.414084  4720 net.cpp:406] Eltwise2 <- Eltwise1_penlu3_0_split_1
I1007 10:06:33.414088  4720 net.cpp:406] Eltwise2 <- Convolution5
I1007 10:06:33.414091  4720 net.cpp:380] Eltwise2 -> Eltwise2
I1007 10:06:33.414108  4720 net.cpp:122] Setting up Eltwise2
I1007 10:06:33.414113  4720 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 10:06:33.414114  4720 net.cpp:137] Memory required for data: 126381200
I1007 10:06:33.414117  4720 layer_factory.hpp:77] Creating layer penlu5
I1007 10:06:33.414122  4720 net.cpp:84] Creating Layer penlu5
I1007 10:06:33.414125  4720 net.cpp:406] penlu5 <- Eltwise2
I1007 10:06:33.414130  4720 net.cpp:367] penlu5 -> Eltwise2 (in-place)
I1007 10:06:33.414233  4720 net.cpp:122] Setting up penlu5
I1007 10:06:33.414238  4720 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 10:06:33.414242  4720 net.cpp:137] Memory required for data: 131398800
I1007 10:06:33.414247  4720 layer_factory.hpp:77] Creating layer Eltwise2_penlu5_0_split
I1007 10:06:33.414258  4720 net.cpp:84] Creating Layer Eltwise2_penlu5_0_split
I1007 10:06:33.414261  4720 net.cpp:406] Eltwise2_penlu5_0_split <- Eltwise2
I1007 10:06:33.414265  4720 net.cpp:380] Eltwise2_penlu5_0_split -> Eltwise2_penlu5_0_split_0
I1007 10:06:33.414269  4720 net.cpp:380] Eltwise2_penlu5_0_split -> Eltwise2_penlu5_0_split_1
I1007 10:06:33.414293  4720 net.cpp:122] Setting up Eltwise2_penlu5_0_split
I1007 10:06:33.414297  4720 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 10:06:33.414301  4720 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 10:06:33.414304  4720 net.cpp:137] Memory required for data: 141434000
I1007 10:06:33.414306  4720 layer_factory.hpp:77] Creating layer Convolution6
I1007 10:06:33.414312  4720 net.cpp:84] Creating Layer Convolution6
I1007 10:06:33.414315  4720 net.cpp:406] Convolution6 <- Eltwise2_penlu5_0_split_0
I1007 10:06:33.414320  4720 net.cpp:380] Convolution6 -> Convolution6
I1007 10:06:33.415208  4720 net.cpp:122] Setting up Convolution6
I1007 10:06:33.415220  4720 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 10:06:33.415222  4720 net.cpp:137] Memory required for data: 146451600
I1007 10:06:33.415227  4720 layer_factory.hpp:77] Creating layer BatchNorm6
I1007 10:06:33.415233  4720 net.cpp:84] Creating Layer BatchNorm6
I1007 10:06:33.415237  4720 net.cpp:406] BatchNorm6 <- Convolution6
I1007 10:06:33.415241  4720 net.cpp:367] BatchNorm6 -> Convolution6 (in-place)
I1007 10:06:33.415369  4720 net.cpp:122] Setting up BatchNorm6
I1007 10:06:33.415374  4720 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 10:06:33.415377  4720 net.cpp:137] Memory required for data: 151469200
I1007 10:06:33.415382  4720 layer_factory.hpp:77] Creating layer Scale6
I1007 10:06:33.415386  4720 net.cpp:84] Creating Layer Scale6
I1007 10:06:33.415390  4720 net.cpp:406] Scale6 <- Convolution6
I1007 10:06:33.415393  4720 net.cpp:367] Scale6 -> Convolution6 (in-place)
I1007 10:06:33.415421  4720 layer_factory.hpp:77] Creating layer Scale6
I1007 10:06:33.415498  4720 net.cpp:122] Setting up Scale6
I1007 10:06:33.415503  4720 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 10:06:33.415505  4720 net.cpp:137] Memory required for data: 156486800
I1007 10:06:33.415509  4720 layer_factory.hpp:77] Creating layer penlu6
I1007 10:06:33.415515  4720 net.cpp:84] Creating Layer penlu6
I1007 10:06:33.415518  4720 net.cpp:406] penlu6 <- Convolution6
I1007 10:06:33.415522  4720 net.cpp:367] penlu6 -> Convolution6 (in-place)
I1007 10:06:33.415627  4720 net.cpp:122] Setting up penlu6
I1007 10:06:33.415632  4720 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 10:06:33.415635  4720 net.cpp:137] Memory required for data: 161504400
I1007 10:06:33.415639  4720 layer_factory.hpp:77] Creating layer Convolution7
I1007 10:06:33.415647  4720 net.cpp:84] Creating Layer Convolution7
I1007 10:06:33.415652  4720 net.cpp:406] Convolution7 <- Convolution6
I1007 10:06:33.415654  4720 net.cpp:380] Convolution7 -> Convolution7
I1007 10:06:33.416211  4720 net.cpp:122] Setting up Convolution7
I1007 10:06:33.416220  4720 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 10:06:33.416224  4720 net.cpp:137] Memory required for data: 166522000
I1007 10:06:33.416227  4720 layer_factory.hpp:77] Creating layer BatchNorm7
I1007 10:06:33.416234  4720 net.cpp:84] Creating Layer BatchNorm7
I1007 10:06:33.416237  4720 net.cpp:406] BatchNorm7 <- Convolution7
I1007 10:06:33.416240  4720 net.cpp:367] BatchNorm7 -> Convolution7 (in-place)
I1007 10:06:33.416369  4720 net.cpp:122] Setting up BatchNorm7
I1007 10:06:33.416375  4720 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 10:06:33.416378  4720 net.cpp:137] Memory required for data: 171539600
I1007 10:06:33.416388  4720 layer_factory.hpp:77] Creating layer Scale7
I1007 10:06:33.416395  4720 net.cpp:84] Creating Layer Scale7
I1007 10:06:33.416399  4720 net.cpp:406] Scale7 <- Convolution7
I1007 10:06:33.416402  4720 net.cpp:367] Scale7 -> Convolution7 (in-place)
I1007 10:06:33.416429  4720 layer_factory.hpp:77] Creating layer Scale7
I1007 10:06:33.416513  4720 net.cpp:122] Setting up Scale7
I1007 10:06:33.416519  4720 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 10:06:33.416522  4720 net.cpp:137] Memory required for data: 176557200
I1007 10:06:33.416527  4720 layer_factory.hpp:77] Creating layer Eltwise3
I1007 10:06:33.416532  4720 net.cpp:84] Creating Layer Eltwise3
I1007 10:06:33.416535  4720 net.cpp:406] Eltwise3 <- Eltwise2_penlu5_0_split_1
I1007 10:06:33.416538  4720 net.cpp:406] Eltwise3 <- Convolution7
I1007 10:06:33.416543  4720 net.cpp:380] Eltwise3 -> Eltwise3
I1007 10:06:33.416558  4720 net.cpp:122] Setting up Eltwise3
I1007 10:06:33.416561  4720 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 10:06:33.416564  4720 net.cpp:137] Memory required for data: 181574800
I1007 10:06:33.416566  4720 layer_factory.hpp:77] Creating layer penlu7
I1007 10:06:33.416574  4720 net.cpp:84] Creating Layer penlu7
I1007 10:06:33.416576  4720 net.cpp:406] penlu7 <- Eltwise3
I1007 10:06:33.416579  4720 net.cpp:367] penlu7 -> Eltwise3 (in-place)
I1007 10:06:33.416682  4720 net.cpp:122] Setting up penlu7
I1007 10:06:33.416687  4720 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 10:06:33.416689  4720 net.cpp:137] Memory required for data: 186592400
I1007 10:06:33.416694  4720 layer_factory.hpp:77] Creating layer Eltwise3_penlu7_0_split
I1007 10:06:33.416698  4720 net.cpp:84] Creating Layer Eltwise3_penlu7_0_split
I1007 10:06:33.416702  4720 net.cpp:406] Eltwise3_penlu7_0_split <- Eltwise3
I1007 10:06:33.416704  4720 net.cpp:380] Eltwise3_penlu7_0_split -> Eltwise3_penlu7_0_split_0
I1007 10:06:33.416709  4720 net.cpp:380] Eltwise3_penlu7_0_split -> Eltwise3_penlu7_0_split_1
I1007 10:06:33.416731  4720 net.cpp:122] Setting up Eltwise3_penlu7_0_split
I1007 10:06:33.416735  4720 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 10:06:33.416739  4720 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 10:06:33.416743  4720 net.cpp:137] Memory required for data: 196627600
I1007 10:06:33.416744  4720 layer_factory.hpp:77] Creating layer Convolution8
I1007 10:06:33.416751  4720 net.cpp:84] Creating Layer Convolution8
I1007 10:06:33.416754  4720 net.cpp:406] Convolution8 <- Eltwise3_penlu7_0_split_0
I1007 10:06:33.416759  4720 net.cpp:380] Convolution8 -> Convolution8
I1007 10:06:33.417636  4720 net.cpp:122] Setting up Convolution8
I1007 10:06:33.417647  4720 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 10:06:33.417650  4720 net.cpp:137] Memory required for data: 201645200
I1007 10:06:33.417655  4720 layer_factory.hpp:77] Creating layer BatchNorm8
I1007 10:06:33.417661  4720 net.cpp:84] Creating Layer BatchNorm8
I1007 10:06:33.417665  4720 net.cpp:406] BatchNorm8 <- Convolution8
I1007 10:06:33.417668  4720 net.cpp:367] BatchNorm8 -> Convolution8 (in-place)
I1007 10:06:33.417796  4720 net.cpp:122] Setting up BatchNorm8
I1007 10:06:33.417801  4720 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 10:06:33.417804  4720 net.cpp:137] Memory required for data: 206662800
I1007 10:06:33.417809  4720 layer_factory.hpp:77] Creating layer Scale8
I1007 10:06:33.417816  4720 net.cpp:84] Creating Layer Scale8
I1007 10:06:33.417819  4720 net.cpp:406] Scale8 <- Convolution8
I1007 10:06:33.417824  4720 net.cpp:367] Scale8 -> Convolution8 (in-place)
I1007 10:06:33.417850  4720 layer_factory.hpp:77] Creating layer Scale8
I1007 10:06:33.417927  4720 net.cpp:122] Setting up Scale8
I1007 10:06:33.417932  4720 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 10:06:33.417934  4720 net.cpp:137] Memory required for data: 211680400
I1007 10:06:33.417937  4720 layer_factory.hpp:77] Creating layer penlu8
I1007 10:06:33.417944  4720 net.cpp:84] Creating Layer penlu8
I1007 10:06:33.417948  4720 net.cpp:406] penlu8 <- Convolution8
I1007 10:06:33.417951  4720 net.cpp:367] penlu8 -> Convolution8 (in-place)
I1007 10:06:33.418056  4720 net.cpp:122] Setting up penlu8
I1007 10:06:33.418061  4720 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 10:06:33.418063  4720 net.cpp:137] Memory required for data: 216698000
I1007 10:06:33.418067  4720 layer_factory.hpp:77] Creating layer Convolution9
I1007 10:06:33.418083  4720 net.cpp:84] Creating Layer Convolution9
I1007 10:06:33.418087  4720 net.cpp:406] Convolution9 <- Convolution8
I1007 10:06:33.418092  4720 net.cpp:380] Convolution9 -> Convolution9
I1007 10:06:33.419034  4720 net.cpp:122] Setting up Convolution9
I1007 10:06:33.419049  4720 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 10:06:33.419054  4720 net.cpp:137] Memory required for data: 221715600
I1007 10:06:33.419061  4720 layer_factory.hpp:77] Creating layer BatchNorm9
I1007 10:06:33.419066  4720 net.cpp:84] Creating Layer BatchNorm9
I1007 10:06:33.419068  4720 net.cpp:406] BatchNorm9 <- Convolution9
I1007 10:06:33.419073  4720 net.cpp:367] BatchNorm9 -> Convolution9 (in-place)
I1007 10:06:33.419261  4720 net.cpp:122] Setting up BatchNorm9
I1007 10:06:33.419271  4720 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 10:06:33.419273  4720 net.cpp:137] Memory required for data: 226733200
I1007 10:06:33.419279  4720 layer_factory.hpp:77] Creating layer Scale9
I1007 10:06:33.419284  4720 net.cpp:84] Creating Layer Scale9
I1007 10:06:33.419287  4720 net.cpp:406] Scale9 <- Convolution9
I1007 10:06:33.419292  4720 net.cpp:367] Scale9 -> Convolution9 (in-place)
I1007 10:06:33.419319  4720 layer_factory.hpp:77] Creating layer Scale9
I1007 10:06:33.419399  4720 net.cpp:122] Setting up Scale9
I1007 10:06:33.419404  4720 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 10:06:33.419407  4720 net.cpp:137] Memory required for data: 231750800
I1007 10:06:33.419412  4720 layer_factory.hpp:77] Creating layer Eltwise4
I1007 10:06:33.419416  4720 net.cpp:84] Creating Layer Eltwise4
I1007 10:06:33.419420  4720 net.cpp:406] Eltwise4 <- Eltwise3_penlu7_0_split_1
I1007 10:06:33.419422  4720 net.cpp:406] Eltwise4 <- Convolution9
I1007 10:06:33.419427  4720 net.cpp:380] Eltwise4 -> Eltwise4
I1007 10:06:33.419442  4720 net.cpp:122] Setting up Eltwise4
I1007 10:06:33.419447  4720 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 10:06:33.419450  4720 net.cpp:137] Memory required for data: 236768400
I1007 10:06:33.419452  4720 layer_factory.hpp:77] Creating layer penlu9
I1007 10:06:33.419457  4720 net.cpp:84] Creating Layer penlu9
I1007 10:06:33.419461  4720 net.cpp:406] penlu9 <- Eltwise4
I1007 10:06:33.419464  4720 net.cpp:367] penlu9 -> Eltwise4 (in-place)
I1007 10:06:33.419574  4720 net.cpp:122] Setting up penlu9
I1007 10:06:33.419579  4720 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 10:06:33.419582  4720 net.cpp:137] Memory required for data: 241786000
I1007 10:06:33.419586  4720 layer_factory.hpp:77] Creating layer Eltwise4_penlu9_0_split
I1007 10:06:33.419590  4720 net.cpp:84] Creating Layer Eltwise4_penlu9_0_split
I1007 10:06:33.419594  4720 net.cpp:406] Eltwise4_penlu9_0_split <- Eltwise4
I1007 10:06:33.419597  4720 net.cpp:380] Eltwise4_penlu9_0_split -> Eltwise4_penlu9_0_split_0
I1007 10:06:33.419601  4720 net.cpp:380] Eltwise4_penlu9_0_split -> Eltwise4_penlu9_0_split_1
I1007 10:06:33.419625  4720 net.cpp:122] Setting up Eltwise4_penlu9_0_split
I1007 10:06:33.419628  4720 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 10:06:33.419632  4720 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 10:06:33.419636  4720 net.cpp:137] Memory required for data: 251821200
I1007 10:06:33.419637  4720 layer_factory.hpp:77] Creating layer Convolution10
I1007 10:06:33.419643  4720 net.cpp:84] Creating Layer Convolution10
I1007 10:06:33.419647  4720 net.cpp:406] Convolution10 <- Eltwise4_penlu9_0_split_0
I1007 10:06:33.419651  4720 net.cpp:380] Convolution10 -> Convolution10
I1007 10:06:33.420549  4720 net.cpp:122] Setting up Convolution10
I1007 10:06:33.420559  4720 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 10:06:33.420563  4720 net.cpp:137] Memory required for data: 256838800
I1007 10:06:33.420567  4720 layer_factory.hpp:77] Creating layer BatchNorm10
I1007 10:06:33.420573  4720 net.cpp:84] Creating Layer BatchNorm10
I1007 10:06:33.420577  4720 net.cpp:406] BatchNorm10 <- Convolution10
I1007 10:06:33.420581  4720 net.cpp:367] BatchNorm10 -> Convolution10 (in-place)
I1007 10:06:33.420719  4720 net.cpp:122] Setting up BatchNorm10
I1007 10:06:33.420725  4720 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 10:06:33.420728  4720 net.cpp:137] Memory required for data: 261856400
I1007 10:06:33.420733  4720 layer_factory.hpp:77] Creating layer Scale10
I1007 10:06:33.420738  4720 net.cpp:84] Creating Layer Scale10
I1007 10:06:33.420742  4720 net.cpp:406] Scale10 <- Convolution10
I1007 10:06:33.420745  4720 net.cpp:367] Scale10 -> Convolution10 (in-place)
I1007 10:06:33.420771  4720 layer_factory.hpp:77] Creating layer Scale10
I1007 10:06:33.420848  4720 net.cpp:122] Setting up Scale10
I1007 10:06:33.420853  4720 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 10:06:33.420856  4720 net.cpp:137] Memory required for data: 266874000
I1007 10:06:33.420861  4720 layer_factory.hpp:77] Creating layer penlu10
I1007 10:06:33.420866  4720 net.cpp:84] Creating Layer penlu10
I1007 10:06:33.420869  4720 net.cpp:406] penlu10 <- Convolution10
I1007 10:06:33.420872  4720 net.cpp:367] penlu10 -> Convolution10 (in-place)
I1007 10:06:33.420989  4720 net.cpp:122] Setting up penlu10
I1007 10:06:33.420994  4720 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 10:06:33.420997  4720 net.cpp:137] Memory required for data: 271891600
I1007 10:06:33.421001  4720 layer_factory.hpp:77] Creating layer Convolution11
I1007 10:06:33.421010  4720 net.cpp:84] Creating Layer Convolution11
I1007 10:06:33.421012  4720 net.cpp:406] Convolution11 <- Convolution10
I1007 10:06:33.421017  4720 net.cpp:380] Convolution11 -> Convolution11
I1007 10:06:33.421897  4720 net.cpp:122] Setting up Convolution11
I1007 10:06:33.421907  4720 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 10:06:33.421911  4720 net.cpp:137] Memory required for data: 276909200
I1007 10:06:33.421916  4720 layer_factory.hpp:77] Creating layer BatchNorm11
I1007 10:06:33.421921  4720 net.cpp:84] Creating Layer BatchNorm11
I1007 10:06:33.421924  4720 net.cpp:406] BatchNorm11 <- Convolution11
I1007 10:06:33.421928  4720 net.cpp:367] BatchNorm11 -> Convolution11 (in-place)
I1007 10:06:33.422060  4720 net.cpp:122] Setting up BatchNorm11
I1007 10:06:33.422065  4720 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 10:06:33.422068  4720 net.cpp:137] Memory required for data: 281926800
I1007 10:06:33.422073  4720 layer_factory.hpp:77] Creating layer Scale11
I1007 10:06:33.422078  4720 net.cpp:84] Creating Layer Scale11
I1007 10:06:33.422081  4720 net.cpp:406] Scale11 <- Convolution11
I1007 10:06:33.422085  4720 net.cpp:367] Scale11 -> Convolution11 (in-place)
I1007 10:06:33.422111  4720 layer_factory.hpp:77] Creating layer Scale11
I1007 10:06:33.422186  4720 net.cpp:122] Setting up Scale11
I1007 10:06:33.422191  4720 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 10:06:33.422194  4720 net.cpp:137] Memory required for data: 286944400
I1007 10:06:33.422199  4720 layer_factory.hpp:77] Creating layer Eltwise5
I1007 10:06:33.422202  4720 net.cpp:84] Creating Layer Eltwise5
I1007 10:06:33.422205  4720 net.cpp:406] Eltwise5 <- Eltwise4_penlu9_0_split_1
I1007 10:06:33.422209  4720 net.cpp:406] Eltwise5 <- Convolution11
I1007 10:06:33.422212  4720 net.cpp:380] Eltwise5 -> Eltwise5
I1007 10:06:33.422227  4720 net.cpp:122] Setting up Eltwise5
I1007 10:06:33.422231  4720 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 10:06:33.422235  4720 net.cpp:137] Memory required for data: 291962000
I1007 10:06:33.422236  4720 layer_factory.hpp:77] Creating layer penlu11
I1007 10:06:33.422242  4720 net.cpp:84] Creating Layer penlu11
I1007 10:06:33.422245  4720 net.cpp:406] penlu11 <- Eltwise5
I1007 10:06:33.422250  4720 net.cpp:367] penlu11 -> Eltwise5 (in-place)
I1007 10:06:33.422356  4720 net.cpp:122] Setting up penlu11
I1007 10:06:33.422361  4720 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 10:06:33.422364  4720 net.cpp:137] Memory required for data: 296979600
I1007 10:06:33.422369  4720 layer_factory.hpp:77] Creating layer Eltwise5_penlu11_0_split
I1007 10:06:33.422372  4720 net.cpp:84] Creating Layer Eltwise5_penlu11_0_split
I1007 10:06:33.422375  4720 net.cpp:406] Eltwise5_penlu11_0_split <- Eltwise5
I1007 10:06:33.422385  4720 net.cpp:380] Eltwise5_penlu11_0_split -> Eltwise5_penlu11_0_split_0
I1007 10:06:33.422390  4720 net.cpp:380] Eltwise5_penlu11_0_split -> Eltwise5_penlu11_0_split_1
I1007 10:06:33.422415  4720 net.cpp:122] Setting up Eltwise5_penlu11_0_split
I1007 10:06:33.422420  4720 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 10:06:33.422422  4720 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 10:06:33.422425  4720 net.cpp:137] Memory required for data: 307014800
I1007 10:06:33.422427  4720 layer_factory.hpp:77] Creating layer Convolution12
I1007 10:06:33.422433  4720 net.cpp:84] Creating Layer Convolution12
I1007 10:06:33.422436  4720 net.cpp:406] Convolution12 <- Eltwise5_penlu11_0_split_0
I1007 10:06:33.422441  4720 net.cpp:380] Convolution12 -> Convolution12
I1007 10:06:33.423619  4720 net.cpp:122] Setting up Convolution12
I1007 10:06:33.423629  4720 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 10:06:33.423632  4720 net.cpp:137] Memory required for data: 309523600
I1007 10:06:33.423637  4720 layer_factory.hpp:77] Creating layer BatchNorm12
I1007 10:06:33.423643  4720 net.cpp:84] Creating Layer BatchNorm12
I1007 10:06:33.423647  4720 net.cpp:406] BatchNorm12 <- Convolution12
I1007 10:06:33.423651  4720 net.cpp:367] BatchNorm12 -> Convolution12 (in-place)
I1007 10:06:33.423787  4720 net.cpp:122] Setting up BatchNorm12
I1007 10:06:33.423794  4720 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 10:06:33.423796  4720 net.cpp:137] Memory required for data: 312032400
I1007 10:06:33.423801  4720 layer_factory.hpp:77] Creating layer Scale12
I1007 10:06:33.423806  4720 net.cpp:84] Creating Layer Scale12
I1007 10:06:33.423810  4720 net.cpp:406] Scale12 <- Convolution12
I1007 10:06:33.423813  4720 net.cpp:367] Scale12 -> Convolution12 (in-place)
I1007 10:06:33.423840  4720 layer_factory.hpp:77] Creating layer Scale12
I1007 10:06:33.423913  4720 net.cpp:122] Setting up Scale12
I1007 10:06:33.423918  4720 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 10:06:33.423921  4720 net.cpp:137] Memory required for data: 314541200
I1007 10:06:33.423925  4720 layer_factory.hpp:77] Creating layer Convolution13
I1007 10:06:33.423933  4720 net.cpp:84] Creating Layer Convolution13
I1007 10:06:33.423935  4720 net.cpp:406] Convolution13 <- Eltwise5_penlu11_0_split_1
I1007 10:06:33.423940  4720 net.cpp:380] Convolution13 -> Convolution13
I1007 10:06:33.425179  4720 net.cpp:122] Setting up Convolution13
I1007 10:06:33.425189  4720 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 10:06:33.425192  4720 net.cpp:137] Memory required for data: 317050000
I1007 10:06:33.425196  4720 layer_factory.hpp:77] Creating layer BatchNorm13
I1007 10:06:33.425202  4720 net.cpp:84] Creating Layer BatchNorm13
I1007 10:06:33.425206  4720 net.cpp:406] BatchNorm13 <- Convolution13
I1007 10:06:33.425210  4720 net.cpp:367] BatchNorm13 -> Convolution13 (in-place)
I1007 10:06:33.425343  4720 net.cpp:122] Setting up BatchNorm13
I1007 10:06:33.425348  4720 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 10:06:33.425350  4720 net.cpp:137] Memory required for data: 319558800
I1007 10:06:33.425355  4720 layer_factory.hpp:77] Creating layer Scale13
I1007 10:06:33.425360  4720 net.cpp:84] Creating Layer Scale13
I1007 10:06:33.425364  4720 net.cpp:406] Scale13 <- Convolution13
I1007 10:06:33.425366  4720 net.cpp:367] Scale13 -> Convolution13 (in-place)
I1007 10:06:33.425393  4720 layer_factory.hpp:77] Creating layer Scale13
I1007 10:06:33.425467  4720 net.cpp:122] Setting up Scale13
I1007 10:06:33.425472  4720 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 10:06:33.425473  4720 net.cpp:137] Memory required for data: 322067600
I1007 10:06:33.425477  4720 layer_factory.hpp:77] Creating layer penlu12
I1007 10:06:33.425483  4720 net.cpp:84] Creating Layer penlu12
I1007 10:06:33.425487  4720 net.cpp:406] penlu12 <- Convolution13
I1007 10:06:33.425492  4720 net.cpp:367] penlu12 -> Convolution13 (in-place)
I1007 10:06:33.425593  4720 net.cpp:122] Setting up penlu12
I1007 10:06:33.425598  4720 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 10:06:33.425608  4720 net.cpp:137] Memory required for data: 324576400
I1007 10:06:33.425614  4720 layer_factory.hpp:77] Creating layer Convolution14
I1007 10:06:33.425621  4720 net.cpp:84] Creating Layer Convolution14
I1007 10:06:33.425626  4720 net.cpp:406] Convolution14 <- Convolution13
I1007 10:06:33.425629  4720 net.cpp:380] Convolution14 -> Convolution14
I1007 10:06:33.426673  4720 net.cpp:122] Setting up Convolution14
I1007 10:06:33.426683  4720 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 10:06:33.426687  4720 net.cpp:137] Memory required for data: 327085200
I1007 10:06:33.426702  4720 layer_factory.hpp:77] Creating layer BatchNorm14
I1007 10:06:33.426712  4720 net.cpp:84] Creating Layer BatchNorm14
I1007 10:06:33.426715  4720 net.cpp:406] BatchNorm14 <- Convolution14
I1007 10:06:33.426718  4720 net.cpp:367] BatchNorm14 -> Convolution14 (in-place)
I1007 10:06:33.426846  4720 net.cpp:122] Setting up BatchNorm14
I1007 10:06:33.426851  4720 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 10:06:33.426854  4720 net.cpp:137] Memory required for data: 329594000
I1007 10:06:33.426859  4720 layer_factory.hpp:77] Creating layer Scale14
I1007 10:06:33.426867  4720 net.cpp:84] Creating Layer Scale14
I1007 10:06:33.426869  4720 net.cpp:406] Scale14 <- Convolution14
I1007 10:06:33.426873  4720 net.cpp:367] Scale14 -> Convolution14 (in-place)
I1007 10:06:33.426899  4720 layer_factory.hpp:77] Creating layer Scale14
I1007 10:06:33.426973  4720 net.cpp:122] Setting up Scale14
I1007 10:06:33.426978  4720 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 10:06:33.426981  4720 net.cpp:137] Memory required for data: 332102800
I1007 10:06:33.426985  4720 layer_factory.hpp:77] Creating layer Eltwise6
I1007 10:06:33.426990  4720 net.cpp:84] Creating Layer Eltwise6
I1007 10:06:33.426995  4720 net.cpp:406] Eltwise6 <- Convolution12
I1007 10:06:33.426996  4720 net.cpp:406] Eltwise6 <- Convolution14
I1007 10:06:33.427000  4720 net.cpp:380] Eltwise6 -> Eltwise6
I1007 10:06:33.427014  4720 net.cpp:122] Setting up Eltwise6
I1007 10:06:33.427018  4720 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 10:06:33.427021  4720 net.cpp:137] Memory required for data: 334611600
I1007 10:06:33.427022  4720 layer_factory.hpp:77] Creating layer penlu13
I1007 10:06:33.427028  4720 net.cpp:84] Creating Layer penlu13
I1007 10:06:33.427031  4720 net.cpp:406] penlu13 <- Eltwise6
I1007 10:06:33.427033  4720 net.cpp:367] penlu13 -> Eltwise6 (in-place)
I1007 10:06:33.427134  4720 net.cpp:122] Setting up penlu13
I1007 10:06:33.427139  4720 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 10:06:33.427140  4720 net.cpp:137] Memory required for data: 337120400
I1007 10:06:33.427145  4720 layer_factory.hpp:77] Creating layer Eltwise6_penlu13_0_split
I1007 10:06:33.427148  4720 net.cpp:84] Creating Layer Eltwise6_penlu13_0_split
I1007 10:06:33.427150  4720 net.cpp:406] Eltwise6_penlu13_0_split <- Eltwise6
I1007 10:06:33.427153  4720 net.cpp:380] Eltwise6_penlu13_0_split -> Eltwise6_penlu13_0_split_0
I1007 10:06:33.427158  4720 net.cpp:380] Eltwise6_penlu13_0_split -> Eltwise6_penlu13_0_split_1
I1007 10:06:33.427196  4720 net.cpp:122] Setting up Eltwise6_penlu13_0_split
I1007 10:06:33.427211  4720 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 10:06:33.427212  4720 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 10:06:33.427214  4720 net.cpp:137] Memory required for data: 342138000
I1007 10:06:33.427217  4720 layer_factory.hpp:77] Creating layer Convolution15
I1007 10:06:33.427224  4720 net.cpp:84] Creating Layer Convolution15
I1007 10:06:33.427227  4720 net.cpp:406] Convolution15 <- Eltwise6_penlu13_0_split_0
I1007 10:06:33.427230  4720 net.cpp:380] Convolution15 -> Convolution15
I1007 10:06:33.428256  4720 net.cpp:122] Setting up Convolution15
I1007 10:06:33.428266  4720 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 10:06:33.428267  4720 net.cpp:137] Memory required for data: 344646800
I1007 10:06:33.428272  4720 layer_factory.hpp:77] Creating layer BatchNorm15
I1007 10:06:33.428277  4720 net.cpp:84] Creating Layer BatchNorm15
I1007 10:06:33.428287  4720 net.cpp:406] BatchNorm15 <- Convolution15
I1007 10:06:33.428292  4720 net.cpp:367] BatchNorm15 -> Convolution15 (in-place)
I1007 10:06:33.428419  4720 net.cpp:122] Setting up BatchNorm15
I1007 10:06:33.428424  4720 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 10:06:33.428426  4720 net.cpp:137] Memory required for data: 347155600
I1007 10:06:33.428431  4720 layer_factory.hpp:77] Creating layer Scale15
I1007 10:06:33.428436  4720 net.cpp:84] Creating Layer Scale15
I1007 10:06:33.428438  4720 net.cpp:406] Scale15 <- Convolution15
I1007 10:06:33.428442  4720 net.cpp:367] Scale15 -> Convolution15 (in-place)
I1007 10:06:33.428467  4720 layer_factory.hpp:77] Creating layer Scale15
I1007 10:06:33.428539  4720 net.cpp:122] Setting up Scale15
I1007 10:06:33.428544  4720 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 10:06:33.428546  4720 net.cpp:137] Memory required for data: 349664400
I1007 10:06:33.428550  4720 layer_factory.hpp:77] Creating layer penlu14
I1007 10:06:33.428555  4720 net.cpp:84] Creating Layer penlu14
I1007 10:06:33.428557  4720 net.cpp:406] penlu14 <- Convolution15
I1007 10:06:33.428561  4720 net.cpp:367] penlu14 -> Convolution15 (in-place)
I1007 10:06:33.428663  4720 net.cpp:122] Setting up penlu14
I1007 10:06:33.428668  4720 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 10:06:33.428670  4720 net.cpp:137] Memory required for data: 352173200
I1007 10:06:33.428674  4720 layer_factory.hpp:77] Creating layer Convolution16
I1007 10:06:33.428681  4720 net.cpp:84] Creating Layer Convolution16
I1007 10:06:33.428684  4720 net.cpp:406] Convolution16 <- Convolution15
I1007 10:06:33.428689  4720 net.cpp:380] Convolution16 -> Convolution16
I1007 10:06:33.429713  4720 net.cpp:122] Setting up Convolution16
I1007 10:06:33.429720  4720 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 10:06:33.429723  4720 net.cpp:137] Memory required for data: 354682000
I1007 10:06:33.429728  4720 layer_factory.hpp:77] Creating layer BatchNorm16
I1007 10:06:33.429733  4720 net.cpp:84] Creating Layer BatchNorm16
I1007 10:06:33.429736  4720 net.cpp:406] BatchNorm16 <- Convolution16
I1007 10:06:33.429740  4720 net.cpp:367] BatchNorm16 -> Convolution16 (in-place)
I1007 10:06:33.429868  4720 net.cpp:122] Setting up BatchNorm16
I1007 10:06:33.429872  4720 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 10:06:33.429875  4720 net.cpp:137] Memory required for data: 357190800
I1007 10:06:33.429879  4720 layer_factory.hpp:77] Creating layer Scale16
I1007 10:06:33.429884  4720 net.cpp:84] Creating Layer Scale16
I1007 10:06:33.429888  4720 net.cpp:406] Scale16 <- Convolution16
I1007 10:06:33.429890  4720 net.cpp:367] Scale16 -> Convolution16 (in-place)
I1007 10:06:33.429915  4720 layer_factory.hpp:77] Creating layer Scale16
I1007 10:06:33.429988  4720 net.cpp:122] Setting up Scale16
I1007 10:06:33.429992  4720 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 10:06:33.429994  4720 net.cpp:137] Memory required for data: 359699600
I1007 10:06:33.429998  4720 layer_factory.hpp:77] Creating layer Eltwise7
I1007 10:06:33.430002  4720 net.cpp:84] Creating Layer Eltwise7
I1007 10:06:33.430006  4720 net.cpp:406] Eltwise7 <- Eltwise6_penlu13_0_split_1
I1007 10:06:33.430008  4720 net.cpp:406] Eltwise7 <- Convolution16
I1007 10:06:33.430011  4720 net.cpp:380] Eltwise7 -> Eltwise7
I1007 10:06:33.430027  4720 net.cpp:122] Setting up Eltwise7
I1007 10:06:33.430030  4720 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 10:06:33.430032  4720 net.cpp:137] Memory required for data: 362208400
I1007 10:06:33.430034  4720 layer_factory.hpp:77] Creating layer penlu15
I1007 10:06:33.430039  4720 net.cpp:84] Creating Layer penlu15
I1007 10:06:33.430042  4720 net.cpp:406] penlu15 <- Eltwise7
I1007 10:06:33.430045  4720 net.cpp:367] penlu15 -> Eltwise7 (in-place)
I1007 10:06:33.430147  4720 net.cpp:122] Setting up penlu15
I1007 10:06:33.430151  4720 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 10:06:33.430153  4720 net.cpp:137] Memory required for data: 364717200
I1007 10:06:33.430164  4720 layer_factory.hpp:77] Creating layer Eltwise7_penlu15_0_split
I1007 10:06:33.430168  4720 net.cpp:84] Creating Layer Eltwise7_penlu15_0_split
I1007 10:06:33.430171  4720 net.cpp:406] Eltwise7_penlu15_0_split <- Eltwise7
I1007 10:06:33.430173  4720 net.cpp:380] Eltwise7_penlu15_0_split -> Eltwise7_penlu15_0_split_0
I1007 10:06:33.430177  4720 net.cpp:380] Eltwise7_penlu15_0_split -> Eltwise7_penlu15_0_split_1
I1007 10:06:33.430200  4720 net.cpp:122] Setting up Eltwise7_penlu15_0_split
I1007 10:06:33.430204  4720 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 10:06:33.430207  4720 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 10:06:33.430209  4720 net.cpp:137] Memory required for data: 369734800
I1007 10:06:33.430212  4720 layer_factory.hpp:77] Creating layer Convolution17
I1007 10:06:33.430217  4720 net.cpp:84] Creating Layer Convolution17
I1007 10:06:33.430220  4720 net.cpp:406] Convolution17 <- Eltwise7_penlu15_0_split_0
I1007 10:06:33.430224  4720 net.cpp:380] Convolution17 -> Convolution17
I1007 10:06:33.430932  4720 net.cpp:122] Setting up Convolution17
I1007 10:06:33.430939  4720 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 10:06:33.430941  4720 net.cpp:137] Memory required for data: 372243600
I1007 10:06:33.430945  4720 layer_factory.hpp:77] Creating layer BatchNorm17
I1007 10:06:33.430950  4720 net.cpp:84] Creating Layer BatchNorm17
I1007 10:06:33.430953  4720 net.cpp:406] BatchNorm17 <- Convolution17
I1007 10:06:33.430958  4720 net.cpp:367] BatchNorm17 -> Convolution17 (in-place)
I1007 10:06:33.431085  4720 net.cpp:122] Setting up BatchNorm17
I1007 10:06:33.431089  4720 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 10:06:33.431092  4720 net.cpp:137] Memory required for data: 374752400
I1007 10:06:33.431097  4720 layer_factory.hpp:77] Creating layer Scale17
I1007 10:06:33.431100  4720 net.cpp:84] Creating Layer Scale17
I1007 10:06:33.431103  4720 net.cpp:406] Scale17 <- Convolution17
I1007 10:06:33.431107  4720 net.cpp:367] Scale17 -> Convolution17 (in-place)
I1007 10:06:33.431133  4720 layer_factory.hpp:77] Creating layer Scale17
I1007 10:06:33.431241  4720 net.cpp:122] Setting up Scale17
I1007 10:06:33.431246  4720 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 10:06:33.431247  4720 net.cpp:137] Memory required for data: 377261200
I1007 10:06:33.431252  4720 layer_factory.hpp:77] Creating layer penlu16
I1007 10:06:33.431257  4720 net.cpp:84] Creating Layer penlu16
I1007 10:06:33.431259  4720 net.cpp:406] penlu16 <- Convolution17
I1007 10:06:33.431263  4720 net.cpp:367] penlu16 -> Convolution17 (in-place)
I1007 10:06:33.431365  4720 net.cpp:122] Setting up penlu16
I1007 10:06:33.431368  4720 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 10:06:33.431370  4720 net.cpp:137] Memory required for data: 379770000
I1007 10:06:33.431375  4720 layer_factory.hpp:77] Creating layer Convolution18
I1007 10:06:33.431381  4720 net.cpp:84] Creating Layer Convolution18
I1007 10:06:33.431383  4720 net.cpp:406] Convolution18 <- Convolution17
I1007 10:06:33.431387  4720 net.cpp:380] Convolution18 -> Convolution18
I1007 10:06:33.432390  4720 net.cpp:122] Setting up Convolution18
I1007 10:06:33.432399  4720 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 10:06:33.432401  4720 net.cpp:137] Memory required for data: 382278800
I1007 10:06:33.432406  4720 layer_factory.hpp:77] Creating layer BatchNorm18
I1007 10:06:33.432411  4720 net.cpp:84] Creating Layer BatchNorm18
I1007 10:06:33.432415  4720 net.cpp:406] BatchNorm18 <- Convolution18
I1007 10:06:33.432417  4720 net.cpp:367] BatchNorm18 -> Convolution18 (in-place)
I1007 10:06:33.432543  4720 net.cpp:122] Setting up BatchNorm18
I1007 10:06:33.432546  4720 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 10:06:33.432548  4720 net.cpp:137] Memory required for data: 384787600
I1007 10:06:33.432554  4720 layer_factory.hpp:77] Creating layer Scale18
I1007 10:06:33.432557  4720 net.cpp:84] Creating Layer Scale18
I1007 10:06:33.432559  4720 net.cpp:406] Scale18 <- Convolution18
I1007 10:06:33.432562  4720 net.cpp:367] Scale18 -> Convolution18 (in-place)
I1007 10:06:33.432596  4720 layer_factory.hpp:77] Creating layer Scale18
I1007 10:06:33.432670  4720 net.cpp:122] Setting up Scale18
I1007 10:06:33.432674  4720 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 10:06:33.432677  4720 net.cpp:137] Memory required for data: 387296400
I1007 10:06:33.432680  4720 layer_factory.hpp:77] Creating layer Eltwise8
I1007 10:06:33.432684  4720 net.cpp:84] Creating Layer Eltwise8
I1007 10:06:33.432687  4720 net.cpp:406] Eltwise8 <- Eltwise7_penlu15_0_split_1
I1007 10:06:33.432690  4720 net.cpp:406] Eltwise8 <- Convolution18
I1007 10:06:33.432693  4720 net.cpp:380] Eltwise8 -> Eltwise8
I1007 10:06:33.432708  4720 net.cpp:122] Setting up Eltwise8
I1007 10:06:33.432710  4720 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 10:06:33.432713  4720 net.cpp:137] Memory required for data: 389805200
I1007 10:06:33.432714  4720 layer_factory.hpp:77] Creating layer penlu17
I1007 10:06:33.432719  4720 net.cpp:84] Creating Layer penlu17
I1007 10:06:33.432723  4720 net.cpp:406] penlu17 <- Eltwise8
I1007 10:06:33.432725  4720 net.cpp:367] penlu17 -> Eltwise8 (in-place)
I1007 10:06:33.432826  4720 net.cpp:122] Setting up penlu17
I1007 10:06:33.432831  4720 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 10:06:33.432832  4720 net.cpp:137] Memory required for data: 392314000
I1007 10:06:33.432837  4720 layer_factory.hpp:77] Creating layer Eltwise8_penlu17_0_split
I1007 10:06:33.432839  4720 net.cpp:84] Creating Layer Eltwise8_penlu17_0_split
I1007 10:06:33.432842  4720 net.cpp:406] Eltwise8_penlu17_0_split <- Eltwise8
I1007 10:06:33.432847  4720 net.cpp:380] Eltwise8_penlu17_0_split -> Eltwise8_penlu17_0_split_0
I1007 10:06:33.432852  4720 net.cpp:380] Eltwise8_penlu17_0_split -> Eltwise8_penlu17_0_split_1
I1007 10:06:33.432873  4720 net.cpp:122] Setting up Eltwise8_penlu17_0_split
I1007 10:06:33.432876  4720 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 10:06:33.432879  4720 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 10:06:33.432881  4720 net.cpp:137] Memory required for data: 397331600
I1007 10:06:33.432883  4720 layer_factory.hpp:77] Creating layer Convolution19
I1007 10:06:33.432889  4720 net.cpp:84] Creating Layer Convolution19
I1007 10:06:33.432893  4720 net.cpp:406] Convolution19 <- Eltwise8_penlu17_0_split_0
I1007 10:06:33.432896  4720 net.cpp:380] Convolution19 -> Convolution19
I1007 10:06:33.434327  4720 net.cpp:122] Setting up Convolution19
I1007 10:06:33.434335  4720 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 10:06:33.434339  4720 net.cpp:137] Memory required for data: 399840400
I1007 10:06:33.434342  4720 layer_factory.hpp:77] Creating layer BatchNorm19
I1007 10:06:33.434348  4720 net.cpp:84] Creating Layer BatchNorm19
I1007 10:06:33.434351  4720 net.cpp:406] BatchNorm19 <- Convolution19
I1007 10:06:33.434355  4720 net.cpp:367] BatchNorm19 -> Convolution19 (in-place)
I1007 10:06:33.434533  4720 net.cpp:122] Setting up BatchNorm19
I1007 10:06:33.434540  4720 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 10:06:33.434542  4720 net.cpp:137] Memory required for data: 402349200
I1007 10:06:33.434547  4720 layer_factory.hpp:77] Creating layer Scale19
I1007 10:06:33.434553  4720 net.cpp:84] Creating Layer Scale19
I1007 10:06:33.434556  4720 net.cpp:406] Scale19 <- Convolution19
I1007 10:06:33.434559  4720 net.cpp:367] Scale19 -> Convolution19 (in-place)
I1007 10:06:33.434605  4720 layer_factory.hpp:77] Creating layer Scale19
I1007 10:06:33.434710  4720 net.cpp:122] Setting up Scale19
I1007 10:06:33.434717  4720 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 10:06:33.434720  4720 net.cpp:137] Memory required for data: 404858000
I1007 10:06:33.434723  4720 layer_factory.hpp:77] Creating layer penlu18
I1007 10:06:33.434729  4720 net.cpp:84] Creating Layer penlu18
I1007 10:06:33.434732  4720 net.cpp:406] penlu18 <- Convolution19
I1007 10:06:33.434737  4720 net.cpp:367] penlu18 -> Convolution19 (in-place)
I1007 10:06:33.434873  4720 net.cpp:122] Setting up penlu18
I1007 10:06:33.434881  4720 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 10:06:33.434890  4720 net.cpp:137] Memory required for data: 407366800
I1007 10:06:33.434895  4720 layer_factory.hpp:77] Creating layer Convolution20
I1007 10:06:33.434903  4720 net.cpp:84] Creating Layer Convolution20
I1007 10:06:33.434906  4720 net.cpp:406] Convolution20 <- Convolution19
I1007 10:06:33.434911  4720 net.cpp:380] Convolution20 -> Convolution20
I1007 10:06:33.436084  4720 net.cpp:122] Setting up Convolution20
I1007 10:06:33.436105  4720 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 10:06:33.436108  4720 net.cpp:137] Memory required for data: 409875600
I1007 10:06:33.436113  4720 layer_factory.hpp:77] Creating layer BatchNorm20
I1007 10:06:33.436117  4720 net.cpp:84] Creating Layer BatchNorm20
I1007 10:06:33.436121  4720 net.cpp:406] BatchNorm20 <- Convolution20
I1007 10:06:33.436127  4720 net.cpp:367] BatchNorm20 -> Convolution20 (in-place)
I1007 10:06:33.436267  4720 net.cpp:122] Setting up BatchNorm20
I1007 10:06:33.436272  4720 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 10:06:33.436285  4720 net.cpp:137] Memory required for data: 412384400
I1007 10:06:33.436290  4720 layer_factory.hpp:77] Creating layer Scale20
I1007 10:06:33.436293  4720 net.cpp:84] Creating Layer Scale20
I1007 10:06:33.436296  4720 net.cpp:406] Scale20 <- Convolution20
I1007 10:06:33.436300  4720 net.cpp:367] Scale20 -> Convolution20 (in-place)
I1007 10:06:33.436334  4720 layer_factory.hpp:77] Creating layer Scale20
I1007 10:06:33.436419  4720 net.cpp:122] Setting up Scale20
I1007 10:06:33.436424  4720 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 10:06:33.436425  4720 net.cpp:137] Memory required for data: 414893200
I1007 10:06:33.436429  4720 layer_factory.hpp:77] Creating layer Eltwise9
I1007 10:06:33.436434  4720 net.cpp:84] Creating Layer Eltwise9
I1007 10:06:33.436435  4720 net.cpp:406] Eltwise9 <- Eltwise8_penlu17_0_split_1
I1007 10:06:33.436439  4720 net.cpp:406] Eltwise9 <- Convolution20
I1007 10:06:33.436442  4720 net.cpp:380] Eltwise9 -> Eltwise9
I1007 10:06:33.436457  4720 net.cpp:122] Setting up Eltwise9
I1007 10:06:33.436461  4720 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 10:06:33.436463  4720 net.cpp:137] Memory required for data: 417402000
I1007 10:06:33.436477  4720 layer_factory.hpp:77] Creating layer penlu19
I1007 10:06:33.436482  4720 net.cpp:84] Creating Layer penlu19
I1007 10:06:33.436494  4720 net.cpp:406] penlu19 <- Eltwise9
I1007 10:06:33.436498  4720 net.cpp:367] penlu19 -> Eltwise9 (in-place)
I1007 10:06:33.436612  4720 net.cpp:122] Setting up penlu19
I1007 10:06:33.436616  4720 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 10:06:33.436619  4720 net.cpp:137] Memory required for data: 419910800
I1007 10:06:33.436622  4720 layer_factory.hpp:77] Creating layer Eltwise9_penlu19_0_split
I1007 10:06:33.436626  4720 net.cpp:84] Creating Layer Eltwise9_penlu19_0_split
I1007 10:06:33.436628  4720 net.cpp:406] Eltwise9_penlu19_0_split <- Eltwise9
I1007 10:06:33.436631  4720 net.cpp:380] Eltwise9_penlu19_0_split -> Eltwise9_penlu19_0_split_0
I1007 10:06:33.436635  4720 net.cpp:380] Eltwise9_penlu19_0_split -> Eltwise9_penlu19_0_split_1
I1007 10:06:33.436656  4720 net.cpp:122] Setting up Eltwise9_penlu19_0_split
I1007 10:06:33.436661  4720 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 10:06:33.436663  4720 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 10:06:33.436666  4720 net.cpp:137] Memory required for data: 424928400
I1007 10:06:33.436667  4720 layer_factory.hpp:77] Creating layer Convolution21
I1007 10:06:33.436672  4720 net.cpp:84] Creating Layer Convolution21
I1007 10:06:33.436676  4720 net.cpp:406] Convolution21 <- Eltwise9_penlu19_0_split_0
I1007 10:06:33.436679  4720 net.cpp:380] Convolution21 -> Convolution21
I1007 10:06:33.438019  4720 net.cpp:122] Setting up Convolution21
I1007 10:06:33.438027  4720 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 10:06:33.438030  4720 net.cpp:137] Memory required for data: 427437200
I1007 10:06:33.438035  4720 layer_factory.hpp:77] Creating layer BatchNorm21
I1007 10:06:33.438040  4720 net.cpp:84] Creating Layer BatchNorm21
I1007 10:06:33.438050  4720 net.cpp:406] BatchNorm21 <- Convolution21
I1007 10:06:33.438055  4720 net.cpp:367] BatchNorm21 -> Convolution21 (in-place)
I1007 10:06:33.438186  4720 net.cpp:122] Setting up BatchNorm21
I1007 10:06:33.438190  4720 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 10:06:33.438192  4720 net.cpp:137] Memory required for data: 429946000
I1007 10:06:33.438197  4720 layer_factory.hpp:77] Creating layer Scale21
I1007 10:06:33.438202  4720 net.cpp:84] Creating Layer Scale21
I1007 10:06:33.438205  4720 net.cpp:406] Scale21 <- Convolution21
I1007 10:06:33.438208  4720 net.cpp:367] Scale21 -> Convolution21 (in-place)
I1007 10:06:33.438235  4720 layer_factory.hpp:77] Creating layer Scale21
I1007 10:06:33.438310  4720 net.cpp:122] Setting up Scale21
I1007 10:06:33.438314  4720 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 10:06:33.438316  4720 net.cpp:137] Memory required for data: 432454800
I1007 10:06:33.438320  4720 layer_factory.hpp:77] Creating layer penlu20
I1007 10:06:33.438326  4720 net.cpp:84] Creating Layer penlu20
I1007 10:06:33.438328  4720 net.cpp:406] penlu20 <- Convolution21
I1007 10:06:33.438331  4720 net.cpp:367] penlu20 -> Convolution21 (in-place)
I1007 10:06:33.438436  4720 net.cpp:122] Setting up penlu20
I1007 10:06:33.438441  4720 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 10:06:33.438442  4720 net.cpp:137] Memory required for data: 434963600
I1007 10:06:33.438447  4720 layer_factory.hpp:77] Creating layer Convolution22
I1007 10:06:33.438453  4720 net.cpp:84] Creating Layer Convolution22
I1007 10:06:33.438457  4720 net.cpp:406] Convolution22 <- Convolution21
I1007 10:06:33.438459  4720 net.cpp:380] Convolution22 -> Convolution22
I1007 10:06:33.439513  4720 net.cpp:122] Setting up Convolution22
I1007 10:06:33.439522  4720 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 10:06:33.439524  4720 net.cpp:137] Memory required for data: 437472400
I1007 10:06:33.439528  4720 layer_factory.hpp:77] Creating layer BatchNorm22
I1007 10:06:33.439533  4720 net.cpp:84] Creating Layer BatchNorm22
I1007 10:06:33.439537  4720 net.cpp:406] BatchNorm22 <- Convolution22
I1007 10:06:33.439540  4720 net.cpp:367] BatchNorm22 -> Convolution22 (in-place)
I1007 10:06:33.439671  4720 net.cpp:122] Setting up BatchNorm22
I1007 10:06:33.439677  4720 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 10:06:33.439678  4720 net.cpp:137] Memory required for data: 439981200
I1007 10:06:33.439682  4720 layer_factory.hpp:77] Creating layer Scale22
I1007 10:06:33.439687  4720 net.cpp:84] Creating Layer Scale22
I1007 10:06:33.439689  4720 net.cpp:406] Scale22 <- Convolution22
I1007 10:06:33.439692  4720 net.cpp:367] Scale22 -> Convolution22 (in-place)
I1007 10:06:33.439718  4720 layer_factory.hpp:77] Creating layer Scale22
I1007 10:06:33.439792  4720 net.cpp:122] Setting up Scale22
I1007 10:06:33.439796  4720 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 10:06:33.439798  4720 net.cpp:137] Memory required for data: 442490000
I1007 10:06:33.439802  4720 layer_factory.hpp:77] Creating layer Eltwise10
I1007 10:06:33.439806  4720 net.cpp:84] Creating Layer Eltwise10
I1007 10:06:33.439810  4720 net.cpp:406] Eltwise10 <- Eltwise9_penlu19_0_split_1
I1007 10:06:33.439811  4720 net.cpp:406] Eltwise10 <- Convolution22
I1007 10:06:33.439815  4720 net.cpp:380] Eltwise10 -> Eltwise10
I1007 10:06:33.439831  4720 net.cpp:122] Setting up Eltwise10
I1007 10:06:33.439834  4720 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 10:06:33.439836  4720 net.cpp:137] Memory required for data: 444998800
I1007 10:06:33.439838  4720 layer_factory.hpp:77] Creating layer penlu21
I1007 10:06:33.439843  4720 net.cpp:84] Creating Layer penlu21
I1007 10:06:33.439846  4720 net.cpp:406] penlu21 <- Eltwise10
I1007 10:06:33.439849  4720 net.cpp:367] penlu21 -> Eltwise10 (in-place)
I1007 10:06:33.439952  4720 net.cpp:122] Setting up penlu21
I1007 10:06:33.439956  4720 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 10:06:33.439959  4720 net.cpp:137] Memory required for data: 447507600
I1007 10:06:33.439962  4720 layer_factory.hpp:77] Creating layer Eltwise10_penlu21_0_split
I1007 10:06:33.439973  4720 net.cpp:84] Creating Layer Eltwise10_penlu21_0_split
I1007 10:06:33.439975  4720 net.cpp:406] Eltwise10_penlu21_0_split <- Eltwise10
I1007 10:06:33.439978  4720 net.cpp:380] Eltwise10_penlu21_0_split -> Eltwise10_penlu21_0_split_0
I1007 10:06:33.439983  4720 net.cpp:380] Eltwise10_penlu21_0_split -> Eltwise10_penlu21_0_split_1
I1007 10:06:33.440006  4720 net.cpp:122] Setting up Eltwise10_penlu21_0_split
I1007 10:06:33.440011  4720 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 10:06:33.440013  4720 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 10:06:33.440016  4720 net.cpp:137] Memory required for data: 452525200
I1007 10:06:33.440017  4720 layer_factory.hpp:77] Creating layer Convolution23
I1007 10:06:33.440023  4720 net.cpp:84] Creating Layer Convolution23
I1007 10:06:33.440026  4720 net.cpp:406] Convolution23 <- Eltwise10_penlu21_0_split_0
I1007 10:06:33.440029  4720 net.cpp:380] Convolution23 -> Convolution23
I1007 10:06:33.440899  4720 net.cpp:122] Setting up Convolution23
I1007 10:06:33.440907  4720 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 10:06:33.440910  4720 net.cpp:137] Memory required for data: 453779600
I1007 10:06:33.440914  4720 layer_factory.hpp:77] Creating layer BatchNorm23
I1007 10:06:33.440920  4720 net.cpp:84] Creating Layer BatchNorm23
I1007 10:06:33.440923  4720 net.cpp:406] BatchNorm23 <- Convolution23
I1007 10:06:33.440927  4720 net.cpp:367] BatchNorm23 -> Convolution23 (in-place)
I1007 10:06:33.441056  4720 net.cpp:122] Setting up BatchNorm23
I1007 10:06:33.441059  4720 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 10:06:33.441062  4720 net.cpp:137] Memory required for data: 455034000
I1007 10:06:33.441066  4720 layer_factory.hpp:77] Creating layer Scale23
I1007 10:06:33.441071  4720 net.cpp:84] Creating Layer Scale23
I1007 10:06:33.441072  4720 net.cpp:406] Scale23 <- Convolution23
I1007 10:06:33.441076  4720 net.cpp:367] Scale23 -> Convolution23 (in-place)
I1007 10:06:33.441102  4720 layer_factory.hpp:77] Creating layer Scale23
I1007 10:06:33.441176  4720 net.cpp:122] Setting up Scale23
I1007 10:06:33.441180  4720 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 10:06:33.441182  4720 net.cpp:137] Memory required for data: 456288400
I1007 10:06:33.441186  4720 layer_factory.hpp:77] Creating layer Convolution24
I1007 10:06:33.441192  4720 net.cpp:84] Creating Layer Convolution24
I1007 10:06:33.441196  4720 net.cpp:406] Convolution24 <- Eltwise10_penlu21_0_split_1
I1007 10:06:33.441200  4720 net.cpp:380] Convolution24 -> Convolution24
I1007 10:06:33.442919  4720 net.cpp:122] Setting up Convolution24
I1007 10:06:33.442929  4720 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 10:06:33.442931  4720 net.cpp:137] Memory required for data: 457542800
I1007 10:06:33.442935  4720 layer_factory.hpp:77] Creating layer BatchNorm24
I1007 10:06:33.442941  4720 net.cpp:84] Creating Layer BatchNorm24
I1007 10:06:33.442945  4720 net.cpp:406] BatchNorm24 <- Convolution24
I1007 10:06:33.442947  4720 net.cpp:367] BatchNorm24 -> Convolution24 (in-place)
I1007 10:06:33.443078  4720 net.cpp:122] Setting up BatchNorm24
I1007 10:06:33.443084  4720 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 10:06:33.443085  4720 net.cpp:137] Memory required for data: 458797200
I1007 10:06:33.443089  4720 layer_factory.hpp:77] Creating layer Scale24
I1007 10:06:33.443094  4720 net.cpp:84] Creating Layer Scale24
I1007 10:06:33.443097  4720 net.cpp:406] Scale24 <- Convolution24
I1007 10:06:33.443100  4720 net.cpp:367] Scale24 -> Convolution24 (in-place)
I1007 10:06:33.443126  4720 layer_factory.hpp:77] Creating layer Scale24
I1007 10:06:33.443230  4720 net.cpp:122] Setting up Scale24
I1007 10:06:33.443235  4720 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 10:06:33.443238  4720 net.cpp:137] Memory required for data: 460051600
I1007 10:06:33.443241  4720 layer_factory.hpp:77] Creating layer penlu22
I1007 10:06:33.443248  4720 net.cpp:84] Creating Layer penlu22
I1007 10:06:33.443250  4720 net.cpp:406] penlu22 <- Convolution24
I1007 10:06:33.443260  4720 net.cpp:367] penlu22 -> Convolution24 (in-place)
I1007 10:06:33.443367  4720 net.cpp:122] Setting up penlu22
I1007 10:06:33.443372  4720 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 10:06:33.443374  4720 net.cpp:137] Memory required for data: 461306000
I1007 10:06:33.443378  4720 layer_factory.hpp:77] Creating layer Convolution25
I1007 10:06:33.443385  4720 net.cpp:84] Creating Layer Convolution25
I1007 10:06:33.443387  4720 net.cpp:406] Convolution25 <- Convolution24
I1007 10:06:33.443392  4720 net.cpp:380] Convolution25 -> Convolution25
I1007 10:06:33.445302  4720 net.cpp:122] Setting up Convolution25
I1007 10:06:33.445312  4720 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 10:06:33.445313  4720 net.cpp:137] Memory required for data: 462560400
I1007 10:06:33.445319  4720 layer_factory.hpp:77] Creating layer BatchNorm25
I1007 10:06:33.445324  4720 net.cpp:84] Creating Layer BatchNorm25
I1007 10:06:33.445327  4720 net.cpp:406] BatchNorm25 <- Convolution25
I1007 10:06:33.445330  4720 net.cpp:367] BatchNorm25 -> Convolution25 (in-place)
I1007 10:06:33.445466  4720 net.cpp:122] Setting up BatchNorm25
I1007 10:06:33.445471  4720 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 10:06:33.445472  4720 net.cpp:137] Memory required for data: 463814800
I1007 10:06:33.445477  4720 layer_factory.hpp:77] Creating layer Scale25
I1007 10:06:33.445482  4720 net.cpp:84] Creating Layer Scale25
I1007 10:06:33.445484  4720 net.cpp:406] Scale25 <- Convolution25
I1007 10:06:33.445487  4720 net.cpp:367] Scale25 -> Convolution25 (in-place)
I1007 10:06:33.445513  4720 layer_factory.hpp:77] Creating layer Scale25
I1007 10:06:33.445590  4720 net.cpp:122] Setting up Scale25
I1007 10:06:33.445595  4720 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 10:06:33.445596  4720 net.cpp:137] Memory required for data: 465069200
I1007 10:06:33.445600  4720 layer_factory.hpp:77] Creating layer Eltwise11
I1007 10:06:33.445603  4720 net.cpp:84] Creating Layer Eltwise11
I1007 10:06:33.445607  4720 net.cpp:406] Eltwise11 <- Convolution23
I1007 10:06:33.445610  4720 net.cpp:406] Eltwise11 <- Convolution25
I1007 10:06:33.445613  4720 net.cpp:380] Eltwise11 -> Eltwise11
I1007 10:06:33.445627  4720 net.cpp:122] Setting up Eltwise11
I1007 10:06:33.445631  4720 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 10:06:33.445633  4720 net.cpp:137] Memory required for data: 466323600
I1007 10:06:33.445636  4720 layer_factory.hpp:77] Creating layer penlu23
I1007 10:06:33.445641  4720 net.cpp:84] Creating Layer penlu23
I1007 10:06:33.445643  4720 net.cpp:406] penlu23 <- Eltwise11
I1007 10:06:33.445647  4720 net.cpp:367] penlu23 -> Eltwise11 (in-place)
I1007 10:06:33.445753  4720 net.cpp:122] Setting up penlu23
I1007 10:06:33.445757  4720 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 10:06:33.445760  4720 net.cpp:137] Memory required for data: 467578000
I1007 10:06:33.445763  4720 layer_factory.hpp:77] Creating layer Eltwise11_penlu23_0_split
I1007 10:06:33.445768  4720 net.cpp:84] Creating Layer Eltwise11_penlu23_0_split
I1007 10:06:33.445770  4720 net.cpp:406] Eltwise11_penlu23_0_split <- Eltwise11
I1007 10:06:33.445773  4720 net.cpp:380] Eltwise11_penlu23_0_split -> Eltwise11_penlu23_0_split_0
I1007 10:06:33.445777  4720 net.cpp:380] Eltwise11_penlu23_0_split -> Eltwise11_penlu23_0_split_1
I1007 10:06:33.445799  4720 net.cpp:122] Setting up Eltwise11_penlu23_0_split
I1007 10:06:33.445803  4720 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 10:06:33.445806  4720 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 10:06:33.445808  4720 net.cpp:137] Memory required for data: 470086800
I1007 10:06:33.445811  4720 layer_factory.hpp:77] Creating layer Convolution26
I1007 10:06:33.445816  4720 net.cpp:84] Creating Layer Convolution26
I1007 10:06:33.445818  4720 net.cpp:406] Convolution26 <- Eltwise11_penlu23_0_split_0
I1007 10:06:33.445822  4720 net.cpp:380] Convolution26 -> Convolution26
I1007 10:06:33.447443  4720 net.cpp:122] Setting up Convolution26
I1007 10:06:33.447451  4720 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 10:06:33.447453  4720 net.cpp:137] Memory required for data: 471341200
I1007 10:06:33.447464  4720 layer_factory.hpp:77] Creating layer BatchNorm26
I1007 10:06:33.447470  4720 net.cpp:84] Creating Layer BatchNorm26
I1007 10:06:33.447474  4720 net.cpp:406] BatchNorm26 <- Convolution26
I1007 10:06:33.447477  4720 net.cpp:367] BatchNorm26 -> Convolution26 (in-place)
I1007 10:06:33.447612  4720 net.cpp:122] Setting up BatchNorm26
I1007 10:06:33.447615  4720 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 10:06:33.447618  4720 net.cpp:137] Memory required for data: 472595600
I1007 10:06:33.447623  4720 layer_factory.hpp:77] Creating layer Scale26
I1007 10:06:33.447626  4720 net.cpp:84] Creating Layer Scale26
I1007 10:06:33.447628  4720 net.cpp:406] Scale26 <- Convolution26
I1007 10:06:33.447631  4720 net.cpp:367] Scale26 -> Convolution26 (in-place)
I1007 10:06:33.447660  4720 layer_factory.hpp:77] Creating layer Scale26
I1007 10:06:33.447736  4720 net.cpp:122] Setting up Scale26
I1007 10:06:33.447741  4720 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 10:06:33.447742  4720 net.cpp:137] Memory required for data: 473850000
I1007 10:06:33.447746  4720 layer_factory.hpp:77] Creating layer penlu24
I1007 10:06:33.447751  4720 net.cpp:84] Creating Layer penlu24
I1007 10:06:33.447754  4720 net.cpp:406] penlu24 <- Convolution26
I1007 10:06:33.447758  4720 net.cpp:367] penlu24 -> Convolution26 (in-place)
I1007 10:06:33.447867  4720 net.cpp:122] Setting up penlu24
I1007 10:06:33.447871  4720 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 10:06:33.447873  4720 net.cpp:137] Memory required for data: 475104400
I1007 10:06:33.447877  4720 layer_factory.hpp:77] Creating layer Convolution27
I1007 10:06:33.447885  4720 net.cpp:84] Creating Layer Convolution27
I1007 10:06:33.447887  4720 net.cpp:406] Convolution27 <- Convolution26
I1007 10:06:33.447891  4720 net.cpp:380] Convolution27 -> Convolution27
I1007 10:06:33.449492  4720 net.cpp:122] Setting up Convolution27
I1007 10:06:33.449501  4720 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 10:06:33.449503  4720 net.cpp:137] Memory required for data: 476358800
I1007 10:06:33.449509  4720 layer_factory.hpp:77] Creating layer BatchNorm27
I1007 10:06:33.449513  4720 net.cpp:84] Creating Layer BatchNorm27
I1007 10:06:33.449517  4720 net.cpp:406] BatchNorm27 <- Convolution27
I1007 10:06:33.449520  4720 net.cpp:367] BatchNorm27 -> Convolution27 (in-place)
I1007 10:06:33.449656  4720 net.cpp:122] Setting up BatchNorm27
I1007 10:06:33.449661  4720 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 10:06:33.449662  4720 net.cpp:137] Memory required for data: 477613200
I1007 10:06:33.449688  4720 layer_factory.hpp:77] Creating layer Scale27
I1007 10:06:33.449702  4720 net.cpp:84] Creating Layer Scale27
I1007 10:06:33.449704  4720 net.cpp:406] Scale27 <- Convolution27
I1007 10:06:33.449708  4720 net.cpp:367] Scale27 -> Convolution27 (in-place)
I1007 10:06:33.449736  4720 layer_factory.hpp:77] Creating layer Scale27
I1007 10:06:33.449812  4720 net.cpp:122] Setting up Scale27
I1007 10:06:33.449817  4720 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 10:06:33.449820  4720 net.cpp:137] Memory required for data: 478867600
I1007 10:06:33.449823  4720 layer_factory.hpp:77] Creating layer Eltwise12
I1007 10:06:33.449827  4720 net.cpp:84] Creating Layer Eltwise12
I1007 10:06:33.449829  4720 net.cpp:406] Eltwise12 <- Eltwise11_penlu23_0_split_1
I1007 10:06:33.449833  4720 net.cpp:406] Eltwise12 <- Convolution27
I1007 10:06:33.449836  4720 net.cpp:380] Eltwise12 -> Eltwise12
I1007 10:06:33.449856  4720 net.cpp:122] Setting up Eltwise12
I1007 10:06:33.449862  4720 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 10:06:33.449863  4720 net.cpp:137] Memory required for data: 480122000
I1007 10:06:33.449865  4720 layer_factory.hpp:77] Creating layer penlu25
I1007 10:06:33.449870  4720 net.cpp:84] Creating Layer penlu25
I1007 10:06:33.449872  4720 net.cpp:406] penlu25 <- Eltwise12
I1007 10:06:33.449875  4720 net.cpp:367] penlu25 -> Eltwise12 (in-place)
I1007 10:06:33.449986  4720 net.cpp:122] Setting up penlu25
I1007 10:06:33.449996  4720 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 10:06:33.449998  4720 net.cpp:137] Memory required for data: 481376400
I1007 10:06:33.450003  4720 layer_factory.hpp:77] Creating layer Eltwise12_penlu25_0_split
I1007 10:06:33.450008  4720 net.cpp:84] Creating Layer Eltwise12_penlu25_0_split
I1007 10:06:33.450011  4720 net.cpp:406] Eltwise12_penlu25_0_split <- Eltwise12
I1007 10:06:33.450013  4720 net.cpp:380] Eltwise12_penlu25_0_split -> Eltwise12_penlu25_0_split_0
I1007 10:06:33.450018  4720 net.cpp:380] Eltwise12_penlu25_0_split -> Eltwise12_penlu25_0_split_1
I1007 10:06:33.450042  4720 net.cpp:122] Setting up Eltwise12_penlu25_0_split
I1007 10:06:33.450045  4720 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 10:06:33.450048  4720 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 10:06:33.450050  4720 net.cpp:137] Memory required for data: 483885200
I1007 10:06:33.450052  4720 layer_factory.hpp:77] Creating layer Convolution28
I1007 10:06:33.450058  4720 net.cpp:84] Creating Layer Convolution28
I1007 10:06:33.450060  4720 net.cpp:406] Convolution28 <- Eltwise12_penlu25_0_split_0
I1007 10:06:33.450065  4720 net.cpp:380] Convolution28 -> Convolution28
I1007 10:06:33.451683  4720 net.cpp:122] Setting up Convolution28
I1007 10:06:33.451691  4720 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 10:06:33.451694  4720 net.cpp:137] Memory required for data: 485139600
I1007 10:06:33.451699  4720 layer_factory.hpp:77] Creating layer BatchNorm28
I1007 10:06:33.451704  4720 net.cpp:84] Creating Layer BatchNorm28
I1007 10:06:33.451706  4720 net.cpp:406] BatchNorm28 <- Convolution28
I1007 10:06:33.451710  4720 net.cpp:367] BatchNorm28 -> Convolution28 (in-place)
I1007 10:06:33.451844  4720 net.cpp:122] Setting up BatchNorm28
I1007 10:06:33.451848  4720 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 10:06:33.451850  4720 net.cpp:137] Memory required for data: 486394000
I1007 10:06:33.451854  4720 layer_factory.hpp:77] Creating layer Scale28
I1007 10:06:33.451858  4720 net.cpp:84] Creating Layer Scale28
I1007 10:06:33.451861  4720 net.cpp:406] Scale28 <- Convolution28
I1007 10:06:33.451864  4720 net.cpp:367] Scale28 -> Convolution28 (in-place)
I1007 10:06:33.451891  4720 layer_factory.hpp:77] Creating layer Scale28
I1007 10:06:33.451967  4720 net.cpp:122] Setting up Scale28
I1007 10:06:33.451972  4720 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 10:06:33.451973  4720 net.cpp:137] Memory required for data: 487648400
I1007 10:06:33.451977  4720 layer_factory.hpp:77] Creating layer penlu26
I1007 10:06:33.451982  4720 net.cpp:84] Creating Layer penlu26
I1007 10:06:33.451985  4720 net.cpp:406] penlu26 <- Convolution28
I1007 10:06:33.451988  4720 net.cpp:367] penlu26 -> Convolution28 (in-place)
I1007 10:06:33.452097  4720 net.cpp:122] Setting up penlu26
I1007 10:06:33.452101  4720 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 10:06:33.452103  4720 net.cpp:137] Memory required for data: 488902800
I1007 10:06:33.452108  4720 layer_factory.hpp:77] Creating layer Convolution29
I1007 10:06:33.452114  4720 net.cpp:84] Creating Layer Convolution29
I1007 10:06:33.452117  4720 net.cpp:406] Convolution29 <- Convolution28
I1007 10:06:33.452121  4720 net.cpp:380] Convolution29 -> Convolution29
I1007 10:06:33.454040  4720 net.cpp:122] Setting up Convolution29
I1007 10:06:33.454047  4720 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 10:06:33.454049  4720 net.cpp:137] Memory required for data: 490157200
I1007 10:06:33.454054  4720 layer_factory.hpp:77] Creating layer BatchNorm29
I1007 10:06:33.454059  4720 net.cpp:84] Creating Layer BatchNorm29
I1007 10:06:33.454062  4720 net.cpp:406] BatchNorm29 <- Convolution29
I1007 10:06:33.454066  4720 net.cpp:367] BatchNorm29 -> Convolution29 (in-place)
I1007 10:06:33.454205  4720 net.cpp:122] Setting up BatchNorm29
I1007 10:06:33.454210  4720 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 10:06:33.454212  4720 net.cpp:137] Memory required for data: 491411600
I1007 10:06:33.454216  4720 layer_factory.hpp:77] Creating layer Scale29
I1007 10:06:33.454221  4720 net.cpp:84] Creating Layer Scale29
I1007 10:06:33.454231  4720 net.cpp:406] Scale29 <- Convolution29
I1007 10:06:33.454234  4720 net.cpp:367] Scale29 -> Convolution29 (in-place)
I1007 10:06:33.454262  4720 layer_factory.hpp:77] Creating layer Scale29
I1007 10:06:33.454342  4720 net.cpp:122] Setting up Scale29
I1007 10:06:33.454346  4720 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 10:06:33.454349  4720 net.cpp:137] Memory required for data: 492666000
I1007 10:06:33.454352  4720 layer_factory.hpp:77] Creating layer Eltwise13
I1007 10:06:33.454357  4720 net.cpp:84] Creating Layer Eltwise13
I1007 10:06:33.454360  4720 net.cpp:406] Eltwise13 <- Eltwise12_penlu25_0_split_1
I1007 10:06:33.454362  4720 net.cpp:406] Eltwise13 <- Convolution29
I1007 10:06:33.454365  4720 net.cpp:380] Eltwise13 -> Eltwise13
I1007 10:06:33.454382  4720 net.cpp:122] Setting up Eltwise13
I1007 10:06:33.454385  4720 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 10:06:33.454387  4720 net.cpp:137] Memory required for data: 493920400
I1007 10:06:33.454390  4720 layer_factory.hpp:77] Creating layer penlu27
I1007 10:06:33.454396  4720 net.cpp:84] Creating Layer penlu27
I1007 10:06:33.454397  4720 net.cpp:406] penlu27 <- Eltwise13
I1007 10:06:33.454401  4720 net.cpp:367] penlu27 -> Eltwise13 (in-place)
I1007 10:06:33.454509  4720 net.cpp:122] Setting up penlu27
I1007 10:06:33.454514  4720 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 10:06:33.454516  4720 net.cpp:137] Memory required for data: 495174800
I1007 10:06:33.454520  4720 layer_factory.hpp:77] Creating layer Eltwise13_penlu27_0_split
I1007 10:06:33.454524  4720 net.cpp:84] Creating Layer Eltwise13_penlu27_0_split
I1007 10:06:33.454525  4720 net.cpp:406] Eltwise13_penlu27_0_split <- Eltwise13
I1007 10:06:33.454530  4720 net.cpp:380] Eltwise13_penlu27_0_split -> Eltwise13_penlu27_0_split_0
I1007 10:06:33.454532  4720 net.cpp:380] Eltwise13_penlu27_0_split -> Eltwise13_penlu27_0_split_1
I1007 10:06:33.454555  4720 net.cpp:122] Setting up Eltwise13_penlu27_0_split
I1007 10:06:33.454560  4720 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 10:06:33.454561  4720 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 10:06:33.454563  4720 net.cpp:137] Memory required for data: 497683600
I1007 10:06:33.454566  4720 layer_factory.hpp:77] Creating layer Convolution30
I1007 10:06:33.454572  4720 net.cpp:84] Creating Layer Convolution30
I1007 10:06:33.454574  4720 net.cpp:406] Convolution30 <- Eltwise13_penlu27_0_split_0
I1007 10:06:33.454578  4720 net.cpp:380] Convolution30 -> Convolution30
I1007 10:06:33.456205  4720 net.cpp:122] Setting up Convolution30
I1007 10:06:33.456213  4720 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 10:06:33.456217  4720 net.cpp:137] Memory required for data: 498938000
I1007 10:06:33.456220  4720 layer_factory.hpp:77] Creating layer BatchNorm30
I1007 10:06:33.456225  4720 net.cpp:84] Creating Layer BatchNorm30
I1007 10:06:33.456228  4720 net.cpp:406] BatchNorm30 <- Convolution30
I1007 10:06:33.456233  4720 net.cpp:367] BatchNorm30 -> Convolution30 (in-place)
I1007 10:06:33.456367  4720 net.cpp:122] Setting up BatchNorm30
I1007 10:06:33.456372  4720 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 10:06:33.456374  4720 net.cpp:137] Memory required for data: 500192400
I1007 10:06:33.456378  4720 layer_factory.hpp:77] Creating layer Scale30
I1007 10:06:33.456383  4720 net.cpp:84] Creating Layer Scale30
I1007 10:06:33.456387  4720 net.cpp:406] Scale30 <- Convolution30
I1007 10:06:33.456389  4720 net.cpp:367] Scale30 -> Convolution30 (in-place)
I1007 10:06:33.456416  4720 layer_factory.hpp:77] Creating layer Scale30
I1007 10:06:33.456493  4720 net.cpp:122] Setting up Scale30
I1007 10:06:33.456497  4720 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 10:06:33.456499  4720 net.cpp:137] Memory required for data: 501446800
I1007 10:06:33.456503  4720 layer_factory.hpp:77] Creating layer penlu28
I1007 10:06:33.456508  4720 net.cpp:84] Creating Layer penlu28
I1007 10:06:33.456511  4720 net.cpp:406] penlu28 <- Convolution30
I1007 10:06:33.456516  4720 net.cpp:367] penlu28 -> Convolution30 (in-place)
I1007 10:06:33.456631  4720 net.cpp:122] Setting up penlu28
I1007 10:06:33.456636  4720 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 10:06:33.456638  4720 net.cpp:137] Memory required for data: 502701200
I1007 10:06:33.456642  4720 layer_factory.hpp:77] Creating layer Convolution31
I1007 10:06:33.456650  4720 net.cpp:84] Creating Layer Convolution31
I1007 10:06:33.456651  4720 net.cpp:406] Convolution31 <- Convolution30
I1007 10:06:33.456655  4720 net.cpp:380] Convolution31 -> Convolution31
I1007 10:06:33.458585  4720 net.cpp:122] Setting up Convolution31
I1007 10:06:33.458593  4720 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 10:06:33.458596  4720 net.cpp:137] Memory required for data: 503955600
I1007 10:06:33.458601  4720 layer_factory.hpp:77] Creating layer BatchNorm31
I1007 10:06:33.458606  4720 net.cpp:84] Creating Layer BatchNorm31
I1007 10:06:33.458608  4720 net.cpp:406] BatchNorm31 <- Convolution31
I1007 10:06:33.458612  4720 net.cpp:367] BatchNorm31 -> Convolution31 (in-place)
I1007 10:06:33.458755  4720 net.cpp:122] Setting up BatchNorm31
I1007 10:06:33.458758  4720 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 10:06:33.458761  4720 net.cpp:137] Memory required for data: 505210000
I1007 10:06:33.458766  4720 layer_factory.hpp:77] Creating layer Scale31
I1007 10:06:33.458770  4720 net.cpp:84] Creating Layer Scale31
I1007 10:06:33.458772  4720 net.cpp:406] Scale31 <- Convolution31
I1007 10:06:33.458775  4720 net.cpp:367] Scale31 -> Convolution31 (in-place)
I1007 10:06:33.458803  4720 layer_factory.hpp:77] Creating layer Scale31
I1007 10:06:33.458881  4720 net.cpp:122] Setting up Scale31
I1007 10:06:33.458885  4720 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 10:06:33.458887  4720 net.cpp:137] Memory required for data: 506464400
I1007 10:06:33.458891  4720 layer_factory.hpp:77] Creating layer Eltwise14
I1007 10:06:33.458894  4720 net.cpp:84] Creating Layer Eltwise14
I1007 10:06:33.458897  4720 net.cpp:406] Eltwise14 <- Eltwise13_penlu27_0_split_1
I1007 10:06:33.458900  4720 net.cpp:406] Eltwise14 <- Convolution31
I1007 10:06:33.458904  4720 net.cpp:380] Eltwise14 -> Eltwise14
I1007 10:06:33.458920  4720 net.cpp:122] Setting up Eltwise14
I1007 10:06:33.458922  4720 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 10:06:33.458925  4720 net.cpp:137] Memory required for data: 507718800
I1007 10:06:33.458926  4720 layer_factory.hpp:77] Creating layer penlu29
I1007 10:06:33.458931  4720 net.cpp:84] Creating Layer penlu29
I1007 10:06:33.458935  4720 net.cpp:406] penlu29 <- Eltwise14
I1007 10:06:33.458938  4720 net.cpp:367] penlu29 -> Eltwise14 (in-place)
I1007 10:06:33.459048  4720 net.cpp:122] Setting up penlu29
I1007 10:06:33.459051  4720 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 10:06:33.459053  4720 net.cpp:137] Memory required for data: 508973200
I1007 10:06:33.459058  4720 layer_factory.hpp:77] Creating layer Eltwise14_penlu29_0_split
I1007 10:06:33.459061  4720 net.cpp:84] Creating Layer Eltwise14_penlu29_0_split
I1007 10:06:33.459064  4720 net.cpp:406] Eltwise14_penlu29_0_split <- Eltwise14
I1007 10:06:33.459066  4720 net.cpp:380] Eltwise14_penlu29_0_split -> Eltwise14_penlu29_0_split_0
I1007 10:06:33.459070  4720 net.cpp:380] Eltwise14_penlu29_0_split -> Eltwise14_penlu29_0_split_1
I1007 10:06:33.459094  4720 net.cpp:122] Setting up Eltwise14_penlu29_0_split
I1007 10:06:33.459097  4720 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 10:06:33.459100  4720 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 10:06:33.459101  4720 net.cpp:137] Memory required for data: 511482000
I1007 10:06:33.459105  4720 layer_factory.hpp:77] Creating layer Convolution32
I1007 10:06:33.459110  4720 net.cpp:84] Creating Layer Convolution32
I1007 10:06:33.459112  4720 net.cpp:406] Convolution32 <- Eltwise14_penlu29_0_split_0
I1007 10:06:33.459116  4720 net.cpp:380] Convolution32 -> Convolution32
I1007 10:06:33.460748  4720 net.cpp:122] Setting up Convolution32
I1007 10:06:33.460757  4720 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 10:06:33.460759  4720 net.cpp:137] Memory required for data: 512736400
I1007 10:06:33.460770  4720 layer_factory.hpp:77] Creating layer BatchNorm32
I1007 10:06:33.460775  4720 net.cpp:84] Creating Layer BatchNorm32
I1007 10:06:33.460777  4720 net.cpp:406] BatchNorm32 <- Convolution32
I1007 10:06:33.460783  4720 net.cpp:367] BatchNorm32 -> Convolution32 (in-place)
I1007 10:06:33.460922  4720 net.cpp:122] Setting up BatchNorm32
I1007 10:06:33.460927  4720 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 10:06:33.460928  4720 net.cpp:137] Memory required for data: 513990800
I1007 10:06:33.460932  4720 layer_factory.hpp:77] Creating layer Scale32
I1007 10:06:33.460937  4720 net.cpp:84] Creating Layer Scale32
I1007 10:06:33.460939  4720 net.cpp:406] Scale32 <- Convolution32
I1007 10:06:33.460943  4720 net.cpp:367] Scale32 -> Convolution32 (in-place)
I1007 10:06:33.460970  4720 layer_factory.hpp:77] Creating layer Scale32
I1007 10:06:33.461050  4720 net.cpp:122] Setting up Scale32
I1007 10:06:33.461053  4720 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 10:06:33.461055  4720 net.cpp:137] Memory required for data: 515245200
I1007 10:06:33.461060  4720 layer_factory.hpp:77] Creating layer penlu30
I1007 10:06:33.461066  4720 net.cpp:84] Creating Layer penlu30
I1007 10:06:33.461067  4720 net.cpp:406] penlu30 <- Convolution32
I1007 10:06:33.461071  4720 net.cpp:367] penlu30 -> Convolution32 (in-place)
I1007 10:06:33.461181  4720 net.cpp:122] Setting up penlu30
I1007 10:06:33.461185  4720 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 10:06:33.461187  4720 net.cpp:137] Memory required for data: 516499600
I1007 10:06:33.461191  4720 layer_factory.hpp:77] Creating layer Convolution33
I1007 10:06:33.461199  4720 net.cpp:84] Creating Layer Convolution33
I1007 10:06:33.461201  4720 net.cpp:406] Convolution33 <- Convolution32
I1007 10:06:33.461205  4720 net.cpp:380] Convolution33 -> Convolution33
I1007 10:06:33.463130  4720 net.cpp:122] Setting up Convolution33
I1007 10:06:33.463138  4720 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 10:06:33.463141  4720 net.cpp:137] Memory required for data: 517754000
I1007 10:06:33.463145  4720 layer_factory.hpp:77] Creating layer BatchNorm33
I1007 10:06:33.463151  4720 net.cpp:84] Creating Layer BatchNorm33
I1007 10:06:33.463153  4720 net.cpp:406] BatchNorm33 <- Convolution33
I1007 10:06:33.463158  4720 net.cpp:367] BatchNorm33 -> Convolution33 (in-place)
I1007 10:06:33.463302  4720 net.cpp:122] Setting up BatchNorm33
I1007 10:06:33.463307  4720 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 10:06:33.463310  4720 net.cpp:137] Memory required for data: 519008400
I1007 10:06:33.463315  4720 layer_factory.hpp:77] Creating layer Scale33
I1007 10:06:33.463320  4720 net.cpp:84] Creating Layer Scale33
I1007 10:06:33.463321  4720 net.cpp:406] Scale33 <- Convolution33
I1007 10:06:33.463325  4720 net.cpp:367] Scale33 -> Convolution33 (in-place)
I1007 10:06:33.463352  4720 layer_factory.hpp:77] Creating layer Scale33
I1007 10:06:33.463433  4720 net.cpp:122] Setting up Scale33
I1007 10:06:33.463436  4720 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 10:06:33.463438  4720 net.cpp:137] Memory required for data: 520262800
I1007 10:06:33.463443  4720 layer_factory.hpp:77] Creating layer Eltwise15
I1007 10:06:33.463445  4720 net.cpp:84] Creating Layer Eltwise15
I1007 10:06:33.463449  4720 net.cpp:406] Eltwise15 <- Eltwise14_penlu29_0_split_1
I1007 10:06:33.463450  4720 net.cpp:406] Eltwise15 <- Convolution33
I1007 10:06:33.463454  4720 net.cpp:380] Eltwise15 -> Eltwise15
I1007 10:06:33.463470  4720 net.cpp:122] Setting up Eltwise15
I1007 10:06:33.463474  4720 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 10:06:33.463475  4720 net.cpp:137] Memory required for data: 521517200
I1007 10:06:33.463477  4720 layer_factory.hpp:77] Creating layer penlu31
I1007 10:06:33.463484  4720 net.cpp:84] Creating Layer penlu31
I1007 10:06:33.463485  4720 net.cpp:406] penlu31 <- Eltwise15
I1007 10:06:33.463490  4720 net.cpp:367] penlu31 -> Eltwise15 (in-place)
I1007 10:06:33.463596  4720 net.cpp:122] Setting up penlu31
I1007 10:06:33.463600  4720 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 10:06:33.463609  4720 net.cpp:137] Memory required for data: 522771600
I1007 10:06:33.463614  4720 layer_factory.hpp:77] Creating layer Pooling1
I1007 10:06:33.463620  4720 net.cpp:84] Creating Layer Pooling1
I1007 10:06:33.463623  4720 net.cpp:406] Pooling1 <- Eltwise15
I1007 10:06:33.463625  4720 net.cpp:380] Pooling1 -> Pooling1
I1007 10:06:33.463775  4720 net.cpp:122] Setting up Pooling1
I1007 10:06:33.463783  4720 net.cpp:129] Top shape: 100 64 1 1 (6400)
I1007 10:06:33.463785  4720 net.cpp:137] Memory required for data: 522797200
I1007 10:06:33.463788  4720 layer_factory.hpp:77] Creating layer InnerProduct1
I1007 10:06:33.463796  4720 net.cpp:84] Creating Layer InnerProduct1
I1007 10:06:33.463798  4720 net.cpp:406] InnerProduct1 <- Pooling1
I1007 10:06:33.463804  4720 net.cpp:380] InnerProduct1 -> InnerProduct1
I1007 10:06:33.463899  4720 net.cpp:122] Setting up InnerProduct1
I1007 10:06:33.463903  4720 net.cpp:129] Top shape: 100 10 (1000)
I1007 10:06:33.463906  4720 net.cpp:137] Memory required for data: 522801200
I1007 10:06:33.463909  4720 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I1007 10:06:33.463914  4720 net.cpp:84] Creating Layer SoftmaxWithLoss1
I1007 10:06:33.463917  4720 net.cpp:406] SoftmaxWithLoss1 <- InnerProduct1
I1007 10:06:33.463919  4720 net.cpp:406] SoftmaxWithLoss1 <- Data2
I1007 10:06:33.463923  4720 net.cpp:380] SoftmaxWithLoss1 -> SoftmaxWithLoss1
I1007 10:06:33.463928  4720 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I1007 10:06:33.464105  4720 net.cpp:122] Setting up SoftmaxWithLoss1
I1007 10:06:33.464112  4720 net.cpp:129] Top shape: (1)
I1007 10:06:33.464114  4720 net.cpp:132]     with loss weight 1
I1007 10:06:33.464126  4720 net.cpp:137] Memory required for data: 522801204
I1007 10:06:33.464128  4720 net.cpp:198] SoftmaxWithLoss1 needs backward computation.
I1007 10:06:33.464131  4720 net.cpp:198] InnerProduct1 needs backward computation.
I1007 10:06:33.464133  4720 net.cpp:198] Pooling1 needs backward computation.
I1007 10:06:33.464135  4720 net.cpp:198] penlu31 needs backward computation.
I1007 10:06:33.464138  4720 net.cpp:198] Eltwise15 needs backward computation.
I1007 10:06:33.464139  4720 net.cpp:198] Scale33 needs backward computation.
I1007 10:06:33.464141  4720 net.cpp:198] BatchNorm33 needs backward computation.
I1007 10:06:33.464143  4720 net.cpp:198] Convolution33 needs backward computation.
I1007 10:06:33.464145  4720 net.cpp:198] penlu30 needs backward computation.
I1007 10:06:33.464148  4720 net.cpp:198] Scale32 needs backward computation.
I1007 10:06:33.464149  4720 net.cpp:198] BatchNorm32 needs backward computation.
I1007 10:06:33.464151  4720 net.cpp:198] Convolution32 needs backward computation.
I1007 10:06:33.464154  4720 net.cpp:198] Eltwise14_penlu29_0_split needs backward computation.
I1007 10:06:33.464155  4720 net.cpp:198] penlu29 needs backward computation.
I1007 10:06:33.464157  4720 net.cpp:198] Eltwise14 needs backward computation.
I1007 10:06:33.464159  4720 net.cpp:198] Scale31 needs backward computation.
I1007 10:06:33.464161  4720 net.cpp:198] BatchNorm31 needs backward computation.
I1007 10:06:33.464164  4720 net.cpp:198] Convolution31 needs backward computation.
I1007 10:06:33.464165  4720 net.cpp:198] penlu28 needs backward computation.
I1007 10:06:33.464167  4720 net.cpp:198] Scale30 needs backward computation.
I1007 10:06:33.464169  4720 net.cpp:198] BatchNorm30 needs backward computation.
I1007 10:06:33.464171  4720 net.cpp:198] Convolution30 needs backward computation.
I1007 10:06:33.464174  4720 net.cpp:198] Eltwise13_penlu27_0_split needs backward computation.
I1007 10:06:33.464175  4720 net.cpp:198] penlu27 needs backward computation.
I1007 10:06:33.464177  4720 net.cpp:198] Eltwise13 needs backward computation.
I1007 10:06:33.464179  4720 net.cpp:198] Scale29 needs backward computation.
I1007 10:06:33.464182  4720 net.cpp:198] BatchNorm29 needs backward computation.
I1007 10:06:33.464184  4720 net.cpp:198] Convolution29 needs backward computation.
I1007 10:06:33.464185  4720 net.cpp:198] penlu26 needs backward computation.
I1007 10:06:33.464195  4720 net.cpp:198] Scale28 needs backward computation.
I1007 10:06:33.464196  4720 net.cpp:198] BatchNorm28 needs backward computation.
I1007 10:06:33.464198  4720 net.cpp:198] Convolution28 needs backward computation.
I1007 10:06:33.464200  4720 net.cpp:198] Eltwise12_penlu25_0_split needs backward computation.
I1007 10:06:33.464202  4720 net.cpp:198] penlu25 needs backward computation.
I1007 10:06:33.464205  4720 net.cpp:198] Eltwise12 needs backward computation.
I1007 10:06:33.464207  4720 net.cpp:198] Scale27 needs backward computation.
I1007 10:06:33.464210  4720 net.cpp:198] BatchNorm27 needs backward computation.
I1007 10:06:33.464211  4720 net.cpp:198] Convolution27 needs backward computation.
I1007 10:06:33.464213  4720 net.cpp:198] penlu24 needs backward computation.
I1007 10:06:33.464215  4720 net.cpp:198] Scale26 needs backward computation.
I1007 10:06:33.464217  4720 net.cpp:198] BatchNorm26 needs backward computation.
I1007 10:06:33.464220  4720 net.cpp:198] Convolution26 needs backward computation.
I1007 10:06:33.464221  4720 net.cpp:198] Eltwise11_penlu23_0_split needs backward computation.
I1007 10:06:33.464223  4720 net.cpp:198] penlu23 needs backward computation.
I1007 10:06:33.464226  4720 net.cpp:198] Eltwise11 needs backward computation.
I1007 10:06:33.464228  4720 net.cpp:198] Scale25 needs backward computation.
I1007 10:06:33.464231  4720 net.cpp:198] BatchNorm25 needs backward computation.
I1007 10:06:33.464232  4720 net.cpp:198] Convolution25 needs backward computation.
I1007 10:06:33.464234  4720 net.cpp:198] penlu22 needs backward computation.
I1007 10:06:33.464236  4720 net.cpp:198] Scale24 needs backward computation.
I1007 10:06:33.464238  4720 net.cpp:198] BatchNorm24 needs backward computation.
I1007 10:06:33.464241  4720 net.cpp:198] Convolution24 needs backward computation.
I1007 10:06:33.464242  4720 net.cpp:198] Scale23 needs backward computation.
I1007 10:06:33.464244  4720 net.cpp:198] BatchNorm23 needs backward computation.
I1007 10:06:33.464246  4720 net.cpp:198] Convolution23 needs backward computation.
I1007 10:06:33.464248  4720 net.cpp:198] Eltwise10_penlu21_0_split needs backward computation.
I1007 10:06:33.464251  4720 net.cpp:198] penlu21 needs backward computation.
I1007 10:06:33.464252  4720 net.cpp:198] Eltwise10 needs backward computation.
I1007 10:06:33.464256  4720 net.cpp:198] Scale22 needs backward computation.
I1007 10:06:33.464257  4720 net.cpp:198] BatchNorm22 needs backward computation.
I1007 10:06:33.464259  4720 net.cpp:198] Convolution22 needs backward computation.
I1007 10:06:33.464262  4720 net.cpp:198] penlu20 needs backward computation.
I1007 10:06:33.464263  4720 net.cpp:198] Scale21 needs backward computation.
I1007 10:06:33.464265  4720 net.cpp:198] BatchNorm21 needs backward computation.
I1007 10:06:33.464267  4720 net.cpp:198] Convolution21 needs backward computation.
I1007 10:06:33.464270  4720 net.cpp:198] Eltwise9_penlu19_0_split needs backward computation.
I1007 10:06:33.464273  4720 net.cpp:198] penlu19 needs backward computation.
I1007 10:06:33.464275  4720 net.cpp:198] Eltwise9 needs backward computation.
I1007 10:06:33.464277  4720 net.cpp:198] Scale20 needs backward computation.
I1007 10:06:33.464279  4720 net.cpp:198] BatchNorm20 needs backward computation.
I1007 10:06:33.464282  4720 net.cpp:198] Convolution20 needs backward computation.
I1007 10:06:33.464284  4720 net.cpp:198] penlu18 needs backward computation.
I1007 10:06:33.464287  4720 net.cpp:198] Scale19 needs backward computation.
I1007 10:06:33.464288  4720 net.cpp:198] BatchNorm19 needs backward computation.
I1007 10:06:33.464290  4720 net.cpp:198] Convolution19 needs backward computation.
I1007 10:06:33.464293  4720 net.cpp:198] Eltwise8_penlu17_0_split needs backward computation.
I1007 10:06:33.464295  4720 net.cpp:198] penlu17 needs backward computation.
I1007 10:06:33.464298  4720 net.cpp:198] Eltwise8 needs backward computation.
I1007 10:06:33.464299  4720 net.cpp:198] Scale18 needs backward computation.
I1007 10:06:33.464303  4720 net.cpp:198] BatchNorm18 needs backward computation.
I1007 10:06:33.464308  4720 net.cpp:198] Convolution18 needs backward computation.
I1007 10:06:33.464310  4720 net.cpp:198] penlu16 needs backward computation.
I1007 10:06:33.464313  4720 net.cpp:198] Scale17 needs backward computation.
I1007 10:06:33.464314  4720 net.cpp:198] BatchNorm17 needs backward computation.
I1007 10:06:33.464316  4720 net.cpp:198] Convolution17 needs backward computation.
I1007 10:06:33.464319  4720 net.cpp:198] Eltwise7_penlu15_0_split needs backward computation.
I1007 10:06:33.464321  4720 net.cpp:198] penlu15 needs backward computation.
I1007 10:06:33.464323  4720 net.cpp:198] Eltwise7 needs backward computation.
I1007 10:06:33.464326  4720 net.cpp:198] Scale16 needs backward computation.
I1007 10:06:33.464329  4720 net.cpp:198] BatchNorm16 needs backward computation.
I1007 10:06:33.464330  4720 net.cpp:198] Convolution16 needs backward computation.
I1007 10:06:33.464332  4720 net.cpp:198] penlu14 needs backward computation.
I1007 10:06:33.464334  4720 net.cpp:198] Scale15 needs backward computation.
I1007 10:06:33.464337  4720 net.cpp:198] BatchNorm15 needs backward computation.
I1007 10:06:33.464339  4720 net.cpp:198] Convolution15 needs backward computation.
I1007 10:06:33.464341  4720 net.cpp:198] Eltwise6_penlu13_0_split needs backward computation.
I1007 10:06:33.464344  4720 net.cpp:198] penlu13 needs backward computation.
I1007 10:06:33.464346  4720 net.cpp:198] Eltwise6 needs backward computation.
I1007 10:06:33.464349  4720 net.cpp:198] Scale14 needs backward computation.
I1007 10:06:33.464350  4720 net.cpp:198] BatchNorm14 needs backward computation.
I1007 10:06:33.464352  4720 net.cpp:198] Convolution14 needs backward computation.
I1007 10:06:33.464354  4720 net.cpp:198] penlu12 needs backward computation.
I1007 10:06:33.464357  4720 net.cpp:198] Scale13 needs backward computation.
I1007 10:06:33.464359  4720 net.cpp:198] BatchNorm13 needs backward computation.
I1007 10:06:33.464361  4720 net.cpp:198] Convolution13 needs backward computation.
I1007 10:06:33.464363  4720 net.cpp:198] Scale12 needs backward computation.
I1007 10:06:33.464365  4720 net.cpp:198] BatchNorm12 needs backward computation.
I1007 10:06:33.464367  4720 net.cpp:198] Convolution12 needs backward computation.
I1007 10:06:33.464370  4720 net.cpp:198] Eltwise5_penlu11_0_split needs backward computation.
I1007 10:06:33.464372  4720 net.cpp:198] penlu11 needs backward computation.
I1007 10:06:33.464375  4720 net.cpp:198] Eltwise5 needs backward computation.
I1007 10:06:33.464376  4720 net.cpp:198] Scale11 needs backward computation.
I1007 10:06:33.464380  4720 net.cpp:198] BatchNorm11 needs backward computation.
I1007 10:06:33.464381  4720 net.cpp:198] Convolution11 needs backward computation.
I1007 10:06:33.464385  4720 net.cpp:198] penlu10 needs backward computation.
I1007 10:06:33.464386  4720 net.cpp:198] Scale10 needs backward computation.
I1007 10:06:33.464388  4720 net.cpp:198] BatchNorm10 needs backward computation.
I1007 10:06:33.464390  4720 net.cpp:198] Convolution10 needs backward computation.
I1007 10:06:33.464392  4720 net.cpp:198] Eltwise4_penlu9_0_split needs backward computation.
I1007 10:06:33.464395  4720 net.cpp:198] penlu9 needs backward computation.
I1007 10:06:33.464396  4720 net.cpp:198] Eltwise4 needs backward computation.
I1007 10:06:33.464399  4720 net.cpp:198] Scale9 needs backward computation.
I1007 10:06:33.464402  4720 net.cpp:198] BatchNorm9 needs backward computation.
I1007 10:06:33.464404  4720 net.cpp:198] Convolution9 needs backward computation.
I1007 10:06:33.464406  4720 net.cpp:198] penlu8 needs backward computation.
I1007 10:06:33.464408  4720 net.cpp:198] Scale8 needs backward computation.
I1007 10:06:33.464411  4720 net.cpp:198] BatchNorm8 needs backward computation.
I1007 10:06:33.464412  4720 net.cpp:198] Convolution8 needs backward computation.
I1007 10:06:33.464416  4720 net.cpp:198] Eltwise3_penlu7_0_split needs backward computation.
I1007 10:06:33.464417  4720 net.cpp:198] penlu7 needs backward computation.
I1007 10:06:33.464422  4720 net.cpp:198] Eltwise3 needs backward computation.
I1007 10:06:33.464426  4720 net.cpp:198] Scale7 needs backward computation.
I1007 10:06:33.464428  4720 net.cpp:198] BatchNorm7 needs backward computation.
I1007 10:06:33.464431  4720 net.cpp:198] Convolution7 needs backward computation.
I1007 10:06:33.464432  4720 net.cpp:198] penlu6 needs backward computation.
I1007 10:06:33.464434  4720 net.cpp:198] Scale6 needs backward computation.
I1007 10:06:33.464437  4720 net.cpp:198] BatchNorm6 needs backward computation.
I1007 10:06:33.464439  4720 net.cpp:198] Convolution6 needs backward computation.
I1007 10:06:33.464442  4720 net.cpp:198] Eltwise2_penlu5_0_split needs backward computation.
I1007 10:06:33.464443  4720 net.cpp:198] penlu5 needs backward computation.
I1007 10:06:33.464445  4720 net.cpp:198] Eltwise2 needs backward computation.
I1007 10:06:33.464448  4720 net.cpp:198] Scale5 needs backward computation.
I1007 10:06:33.464450  4720 net.cpp:198] BatchNorm5 needs backward computation.
I1007 10:06:33.464452  4720 net.cpp:198] Convolution5 needs backward computation.
I1007 10:06:33.464455  4720 net.cpp:198] penlu4 needs backward computation.
I1007 10:06:33.464457  4720 net.cpp:198] Scale4 needs backward computation.
I1007 10:06:33.464459  4720 net.cpp:198] BatchNorm4 needs backward computation.
I1007 10:06:33.464462  4720 net.cpp:198] Convolution4 needs backward computation.
I1007 10:06:33.464463  4720 net.cpp:198] Eltwise1_penlu3_0_split needs backward computation.
I1007 10:06:33.464467  4720 net.cpp:198] penlu3 needs backward computation.
I1007 10:06:33.464468  4720 net.cpp:198] Eltwise1 needs backward computation.
I1007 10:06:33.464470  4720 net.cpp:198] Scale3 needs backward computation.
I1007 10:06:33.464473  4720 net.cpp:198] BatchNorm3 needs backward computation.
I1007 10:06:33.464475  4720 net.cpp:198] Convolution3 needs backward computation.
I1007 10:06:33.464478  4720 net.cpp:198] penlu2 needs backward computation.
I1007 10:06:33.464479  4720 net.cpp:198] Scale2 needs backward computation.
I1007 10:06:33.464481  4720 net.cpp:198] BatchNorm2 needs backward computation.
I1007 10:06:33.464483  4720 net.cpp:198] Convolution2 needs backward computation.
I1007 10:06:33.464485  4720 net.cpp:198] Convolution1_penlu1_0_split needs backward computation.
I1007 10:06:33.464488  4720 net.cpp:198] penlu1 needs backward computation.
I1007 10:06:33.464490  4720 net.cpp:198] Scale1 needs backward computation.
I1007 10:06:33.464493  4720 net.cpp:198] BatchNorm1 needs backward computation.
I1007 10:06:33.464494  4720 net.cpp:198] Convolution1 needs backward computation.
I1007 10:06:33.464498  4720 net.cpp:200] Data1 does not need backward computation.
I1007 10:06:33.464499  4720 net.cpp:242] This network produces output SoftmaxWithLoss1
I1007 10:06:33.464550  4720 net.cpp:255] Network initialization done.
I1007 10:06:33.467471  4720 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: /home/x306/caffe/xn/PENLU/neural/resnet/res32/res32_penlu_decay_gauss.prototxt
I1007 10:06:33.467483  4720 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I1007 10:06:33.467488  4720 solver.cpp:172] Creating test net (#0) specified by net file: /home/x306/caffe/xn/PENLU/neural/resnet/res32/res32_penlu_decay_gauss.prototxt
I1007 10:06:33.467603  4720 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer Data1
I1007 10:06:33.468420  4720 net.cpp:51] Initializing net from parameters: 
name: "resnet_cifar10"
state {
  phase: TEST
}
layer {
  name: "Data1"
  type: "Data"
  top: "Data1"
  top: "Data2"
  include {
    phase: TEST
  }
  transform_param {
    mean_file: "/home/x306/caffe/xn/PENLU/data/cifar10/mean.binaryproto"
  }
  data_param {
    source: "/home/x306/caffe/xn/PENLU/data/cifar10/cifar10_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "Convolution1"
  type: "Convolution"
  bottom: "Data1"
  top: "Convolution1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm1"
  type: "BatchNorm"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1"
  type: "Scale"
  bottom: "Convolution1"
  top: "Convolution1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu1"
  type: "PENLU"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution2"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm2"
  type: "BatchNorm"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale2"
  type: "Scale"
  bottom: "Convolution2"
  top: "Convolution2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu2"
  type: "PENLU"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution3"
  type: "Convolution"
  bottom: "Convolution2"
  top: "Convolution3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm3"
  type: "BatchNorm"
  bottom: "Convolution3"
  top: "Convolution3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale3"
  type: "Scale"
  bottom: "Convolution3"
  top: "Convolution3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise1"
  type: "Eltwise"
  bottom: "Convolution1"
  bottom: "Convolution3"
  top: "Eltwise1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu3"
  type: "PENLU"
  bottom: "Eltwise1"
  top: "Eltwise1"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution4"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm4"
  type: "BatchNorm"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale4"
  type: "Scale"
  bottom: "Convolution4"
  top: "Convolution4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu4"
  type: "PENLU"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution5"
  type: "Convolution"
  bottom: "Convolution4"
  top: "Convolution5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm5"
  type: "BatchNorm"
  bottom: "Convolution5"
  top: "Convolution5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale5"
  type: "Scale"
  bottom: "Convolution5"
  top: "Convolution5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise2"
  type: "Eltwise"
  bottom: "Eltwise1"
  bottom: "Convolution5"
  top: "Eltwise2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu5"
  type: "PENLU"
  bottom: "Eltwise2"
  top: "Eltwise2"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution6"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm6"
  type: "BatchNorm"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale6"
  type: "Scale"
  bottom: "Convolution6"
  top: "Convolution6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu6"
  type: "PENLU"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution7"
  type: "Convolution"
  bottom: "Convolution6"
  top: "Convolution7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm7"
  type: "BatchNorm"
  bottom: "Convolution7"
  top: "Convolution7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale7"
  type: "Scale"
  bottom: "Convolution7"
  top: "Convolution7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise3"
  type: "Eltwise"
  bottom: "Eltwise2"
  bottom: "Convolution7"
  top: "Eltwise3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu7"
  type: "PENLU"
  bottom: "Eltwise3"
  top: "Eltwise3"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution8"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm8"
  type: "BatchNorm"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale8"
  type: "Scale"
  bottom: "Convolution8"
  top: "Convolution8"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu8"
  type: "PENLU"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution9"
  type: "Convolution"
  bottom: "Convolution8"
  top: "Convolution9"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm9"
  type: "BatchNorm"
  bottom: "Convolution9"
  top: "Convolution9"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale9"
  type: "Scale"
  bottom: "Convolution9"
  top: "Convolution9"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise4"
  type: "Eltwise"
  bottom: "Eltwise3"
  bottom: "Convolution9"
  top: "Eltwise4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu9"
  type: "PENLU"
  bottom: "Eltwise4"
  top: "Eltwise4"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution10"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution10"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm10"
  type: "BatchNorm"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale10"
  type: "Scale"
  bottom: "Convolution10"
  top: "Convolution10"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu10"
  type: "PENLU"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution11"
  type: "Convolution"
  bottom: "Convolution10"
  top: "Convolution11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm11"
  type: "BatchNorm"
  bottom: "Convolution11"
  top: "Convolution11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale11"
  type: "Scale"
  bottom: "Convolution11"
  top: "Convolution11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise5"
  type: "Eltwise"
  bottom: "Eltwise4"
  bottom: "Convolution11"
  top: "Eltwise5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu11"
  type: "PENLU"
  bottom: "Eltwise5"
  top: "Eltwise5"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution12"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.25
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm12"
  type: "BatchNorm"
  bottom: "Convolution12"
  top: "Convolution12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale12"
  type: "Scale"
  bottom: "Convolution12"
  top: "Convolution12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution13"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution13"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm13"
  type: "BatchNorm"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale13"
  type: "Scale"
  bottom: "Convolution13"
  top: "Convolution13"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu12"
  type: "PENLU"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution14"
  type: "Convolution"
  bottom: "Convolution13"
  top: "Convolution14"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm14"
  type: "BatchNorm"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale14"
  type: "Scale"
  bottom: "Convolution14"
  top: "Convolution14"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise6"
  type: "Eltwise"
  bottom: "Convolution12"
  bottom: "Convolution14"
  top: "Eltwise6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu13"
  type: "PENLU"
  bottom: "Eltwise6"
  top: "Eltwise6"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution15"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution15"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm15"
  type: "BatchNorm"
  bottom: "Convolution15"
  top: "Convolution15"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale15"
  type: "Scale"
  bottom: "Convolution15"
  top: "Convolution15"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu14"
  type: "PENLU"
  bottom: "Convolution15"
  top: "Convolution15"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution16"
  type: "Convolution"
  bottom: "Convolution15"
  top: "Convolution16"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm16"
  type: "BatchNorm"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale16"
  type: "Scale"
  bottom: "Convolution16"
  top: "Convolution16"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise7"
  type: "Eltwise"
  bottom: "Eltwise6"
  bottom: "Convolution16"
  top: "Eltwise7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu15"
  type: "PENLU"
  bottom: "Eltwise7"
  top: "Eltwise7"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution17"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution17"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm17"
  type: "BatchNorm"
  bottom: "Convolution17"
  top: "Convolution17"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale17"
  type: "Scale"
  bottom: "Convolution17"
  top: "Convolution17"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu16"
  type: "PENLU"
  bottom: "Convolution17"
  top: "Convolution17"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution18"
  type: "Convolution"
  bottom: "Convolution17"
  top: "Convolution18"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm18"
  type: "BatchNorm"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale18"
  type: "Scale"
  bottom: "Convolution18"
  top: "Convolution18"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise8"
  type: "Eltwise"
  bottom: "Eltwise7"
  bottom: "Convolution18"
  top: "Eltwise8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu17"
  type: "PENLU"
  bottom: "Eltwise8"
  top: "Eltwise8"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution19"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution19"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm19"
  type: "BatchNorm"
  bottom: "Convolution19"
  top: "Convolution19"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale19"
  type: "Scale"
  bottom: "Convolution19"
  top: "Convolution19"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu18"
  type: "PENLU"
  bottom: "Convolution19"
  top: "Convolution19"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution20"
  type: "Convolution"
  bottom: "Convolution19"
  top: "Convolution20"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm20"
  type: "BatchNorm"
  bottom: "Convolution20"
  top: "Convolution20"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale20"
  type: "Scale"
  bottom: "Convolution20"
  top: "Convolution20"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise9"
  type: "Eltwise"
  bottom: "Eltwise8"
  bottom: "Convolution20"
  top: "Eltwise9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu19"
  type: "PENLU"
  bottom: "Eltwise9"
  top: "Eltwise9"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution21"
  type: "Convolution"
  bottom: "Eltwise9"
  top: "Convolution21"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm21"
  type: "BatchNorm"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale21"
  type: "Scale"
  bottom: "Convolution21"
  top: "Convolution21"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu20"
  type: "PENLU"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution22"
  type: "Convolution"
  bottom: "Convolution21"
  top: "Convolution22"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm22"
  type: "BatchNorm"
  bottom: "Convolution22"
  top: "Convolution22"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale22"
  type: "Scale"
  bottom: "Convolution22"
  top: "Convolution22"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise10"
  type: "Eltwise"
  bottom: "Eltwise9"
  bottom: "Convolution22"
  top: "Eltwise10"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu21"
  type: "PENLU"
  bottom: "Eltwise10"
  top: "Eltwise10"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution23"
  type: "Convolution"
  bottom: "Eltwise10"
  top: "Convolution23"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.17677669
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm23"
  type: "BatchNorm"
  bottom: "Convolution23"
  top: "Convolution23"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale23"
  type: "Scale"
  bottom: "Convolution23"
  top: "Convolution23"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution24"
  type: "Convolution"
  bottom: "Eltwise10"
  top: "Convolution24"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm24"
  type: "BatchNorm"
  bottom: "Convolution24"
  top: "Convolution24"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale24"
  type: "Scale"
  bottom: "Convolution24"
  top: "Convolution24"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu22"
  type: "PENLU"
 
I1007 10:06:33.468822  4720 layer_factory.hpp:77] Creating layer Data1
I1007 10:06:33.496096  4720 db_lmdb.cpp:35] Opened lmdb /home/x306/caffe/xn/PENLU/data/cifar10/cifar10_test_lmdb
I1007 10:06:33.496110  4720 net.cpp:84] Creating Layer Data1
I1007 10:06:33.496114  4720 net.cpp:380] Data1 -> Data1
I1007 10:06:33.496121  4720 net.cpp:380] Data1 -> Data2
I1007 10:06:33.496129  4720 data_transformer.cpp:25] Loading mean file from: /home/x306/caffe/xn/PENLU/data/cifar10/mean.binaryproto
I1007 10:06:33.496273  4720 data_layer.cpp:45] output data size: 100,3,32,32
I1007 10:06:33.500711  4720 net.cpp:122] Setting up Data1
I1007 10:06:33.500730  4720 net.cpp:129] Top shape: 100 3 32 32 (307200)
I1007 10:06:33.500735  4720 net.cpp:129] Top shape: 100 (100)
I1007 10:06:33.500737  4720 net.cpp:137] Memory required for data: 1229200
I1007 10:06:33.500742  4720 layer_factory.hpp:77] Creating layer Data2_Data1_1_split
I1007 10:06:33.500752  4720 net.cpp:84] Creating Layer Data2_Data1_1_split
I1007 10:06:33.500756  4720 net.cpp:406] Data2_Data1_1_split <- Data2
I1007 10:06:33.500761  4720 net.cpp:380] Data2_Data1_1_split -> Data2_Data1_1_split_0
I1007 10:06:33.500768  4720 net.cpp:380] Data2_Data1_1_split -> Data2_Data1_1_split_1
I1007 10:06:33.500838  4720 net.cpp:122] Setting up Data2_Data1_1_split
I1007 10:06:33.500844  4720 net.cpp:129] Top shape: 100 (100)
I1007 10:06:33.500847  4720 net.cpp:129] Top shape: 100 (100)
I1007 10:06:33.500849  4720 net.cpp:137] Memory required for data: 1230000
I1007 10:06:33.500851  4720 layer_factory.hpp:77] Creating layer Convolution1
I1007 10:06:33.500861  4720 net.cpp:84] Creating Layer Convolution1
I1007 10:06:33.500864  4720 net.cpp:406] Convolution1 <- Data1
I1007 10:06:33.500869  4720 net.cpp:380] Convolution1 -> Convolution1
I1007 10:06:33.502101  4720 net.cpp:122] Setting up Convolution1
I1007 10:06:33.502112  4720 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 10:06:33.502117  4720 net.cpp:137] Memory required for data: 7783600
I1007 10:06:33.502125  4720 layer_factory.hpp:77] Creating layer BatchNorm1
I1007 10:06:33.502130  4720 net.cpp:84] Creating Layer BatchNorm1
I1007 10:06:33.502133  4720 net.cpp:406] BatchNorm1 <- Convolution1
I1007 10:06:33.502138  4720 net.cpp:367] BatchNorm1 -> Convolution1 (in-place)
I1007 10:06:33.502286  4720 net.cpp:122] Setting up BatchNorm1
I1007 10:06:33.502291  4720 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 10:06:33.502293  4720 net.cpp:137] Memory required for data: 14337200
I1007 10:06:33.502300  4720 layer_factory.hpp:77] Creating layer Scale1
I1007 10:06:33.502307  4720 net.cpp:84] Creating Layer Scale1
I1007 10:06:33.502310  4720 net.cpp:406] Scale1 <- Convolution1
I1007 10:06:33.502313  4720 net.cpp:367] Scale1 -> Convolution1 (in-place)
I1007 10:06:33.502343  4720 layer_factory.hpp:77] Creating layer Scale1
I1007 10:06:33.502424  4720 net.cpp:122] Setting up Scale1
I1007 10:06:33.502431  4720 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 10:06:33.502434  4720 net.cpp:137] Memory required for data: 20890800
I1007 10:06:33.502439  4720 layer_factory.hpp:77] Creating layer penlu1
I1007 10:06:33.502444  4720 net.cpp:84] Creating Layer penlu1
I1007 10:06:33.502447  4720 net.cpp:406] penlu1 <- Convolution1
I1007 10:06:33.502454  4720 net.cpp:367] penlu1 -> Convolution1 (in-place)
I1007 10:06:33.502588  4720 net.cpp:122] Setting up penlu1
I1007 10:06:33.502604  4720 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 10:06:33.502606  4720 net.cpp:137] Memory required for data: 27444400
I1007 10:06:33.502614  4720 layer_factory.hpp:77] Creating layer Convolution1_penlu1_0_split
I1007 10:06:33.502617  4720 net.cpp:84] Creating Layer Convolution1_penlu1_0_split
I1007 10:06:33.502620  4720 net.cpp:406] Convolution1_penlu1_0_split <- Convolution1
I1007 10:06:33.502624  4720 net.cpp:380] Convolution1_penlu1_0_split -> Convolution1_penlu1_0_split_0
I1007 10:06:33.502630  4720 net.cpp:380] Convolution1_penlu1_0_split -> Convolution1_penlu1_0_split_1
I1007 10:06:33.502657  4720 net.cpp:122] Setting up Convolution1_penlu1_0_split
I1007 10:06:33.502661  4720 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 10:06:33.502665  4720 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 10:06:33.502668  4720 net.cpp:137] Memory required for data: 40551600
I1007 10:06:33.502671  4720 layer_factory.hpp:77] Creating layer Convolution2
I1007 10:06:33.502677  4720 net.cpp:84] Creating Layer Convolution2
I1007 10:06:33.502681  4720 net.cpp:406] Convolution2 <- Convolution1_penlu1_0_split_0
I1007 10:06:33.502684  4720 net.cpp:380] Convolution2 -> Convolution2
I1007 10:06:33.503933  4720 net.cpp:122] Setting up Convolution2
I1007 10:06:33.503944  4720 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 10:06:33.503947  4720 net.cpp:137] Memory required for data: 47105200
I1007 10:06:33.503952  4720 layer_factory.hpp:77] Creating layer BatchNorm2
I1007 10:06:33.503960  4720 net.cpp:84] Creating Layer BatchNorm2
I1007 10:06:33.503963  4720 net.cpp:406] BatchNorm2 <- Convolution2
I1007 10:06:33.503968  4720 net.cpp:367] BatchNorm2 -> Convolution2 (in-place)
I1007 10:06:33.504117  4720 net.cpp:122] Setting up BatchNorm2
I1007 10:06:33.504122  4720 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 10:06:33.504124  4720 net.cpp:137] Memory required for data: 53658800
I1007 10:06:33.504129  4720 layer_factory.hpp:77] Creating layer Scale2
I1007 10:06:33.504134  4720 net.cpp:84] Creating Layer Scale2
I1007 10:06:33.504137  4720 net.cpp:406] Scale2 <- Convolution2
I1007 10:06:33.504140  4720 net.cpp:367] Scale2 -> Convolution2 (in-place)
I1007 10:06:33.504170  4720 layer_factory.hpp:77] Creating layer Scale2
I1007 10:06:33.504251  4720 net.cpp:122] Setting up Scale2
I1007 10:06:33.504256  4720 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 10:06:33.504259  4720 net.cpp:137] Memory required for data: 60212400
I1007 10:06:33.504266  4720 layer_factory.hpp:77] Creating layer penlu2
I1007 10:06:33.504271  4720 net.cpp:84] Creating Layer penlu2
I1007 10:06:33.504273  4720 net.cpp:406] penlu2 <- Convolution2
I1007 10:06:33.504278  4720 net.cpp:367] penlu2 -> Convolution2 (in-place)
I1007 10:06:33.504405  4720 net.cpp:122] Setting up penlu2
I1007 10:06:33.504415  4720 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 10:06:33.504416  4720 net.cpp:137] Memory required for data: 66766000
I1007 10:06:33.504421  4720 layer_factory.hpp:77] Creating layer Convolution3
I1007 10:06:33.504428  4720 net.cpp:84] Creating Layer Convolution3
I1007 10:06:33.504432  4720 net.cpp:406] Convolution3 <- Convolution2
I1007 10:06:33.504437  4720 net.cpp:380] Convolution3 -> Convolution3
I1007 10:06:33.505539  4720 net.cpp:122] Setting up Convolution3
I1007 10:06:33.505548  4720 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 10:06:33.505551  4720 net.cpp:137] Memory required for data: 73319600
I1007 10:06:33.505556  4720 layer_factory.hpp:77] Creating layer BatchNorm3
I1007 10:06:33.505563  4720 net.cpp:84] Creating Layer BatchNorm3
I1007 10:06:33.505566  4720 net.cpp:406] BatchNorm3 <- Convolution3
I1007 10:06:33.505571  4720 net.cpp:367] BatchNorm3 -> Convolution3 (in-place)
I1007 10:06:33.505717  4720 net.cpp:122] Setting up BatchNorm3
I1007 10:06:33.505723  4720 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 10:06:33.505725  4720 net.cpp:137] Memory required for data: 79873200
I1007 10:06:33.505730  4720 layer_factory.hpp:77] Creating layer Scale3
I1007 10:06:33.505736  4720 net.cpp:84] Creating Layer Scale3
I1007 10:06:33.505746  4720 net.cpp:406] Scale3 <- Convolution3
I1007 10:06:33.505750  4720 net.cpp:367] Scale3 -> Convolution3 (in-place)
I1007 10:06:33.505781  4720 layer_factory.hpp:77] Creating layer Scale3
I1007 10:06:33.505863  4720 net.cpp:122] Setting up Scale3
I1007 10:06:33.505868  4720 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 10:06:33.505870  4720 net.cpp:137] Memory required for data: 86426800
I1007 10:06:33.505874  4720 layer_factory.hpp:77] Creating layer Eltwise1
I1007 10:06:33.505878  4720 net.cpp:84] Creating Layer Eltwise1
I1007 10:06:33.505882  4720 net.cpp:406] Eltwise1 <- Convolution1_penlu1_0_split_1
I1007 10:06:33.505884  4720 net.cpp:406] Eltwise1 <- Convolution3
I1007 10:06:33.505889  4720 net.cpp:380] Eltwise1 -> Eltwise1
I1007 10:06:33.505908  4720 net.cpp:122] Setting up Eltwise1
I1007 10:06:33.505911  4720 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 10:06:33.505918  4720 net.cpp:137] Memory required for data: 92980400
I1007 10:06:33.505920  4720 layer_factory.hpp:77] Creating layer penlu3
I1007 10:06:33.505925  4720 net.cpp:84] Creating Layer penlu3
I1007 10:06:33.505928  4720 net.cpp:406] penlu3 <- Eltwise1
I1007 10:06:33.505933  4720 net.cpp:367] penlu3 -> Eltwise1 (in-place)
I1007 10:06:33.506057  4720 net.cpp:122] Setting up penlu3
I1007 10:06:33.506062  4720 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 10:06:33.506064  4720 net.cpp:137] Memory required for data: 99534000
I1007 10:06:33.506068  4720 layer_factory.hpp:77] Creating layer Eltwise1_penlu3_0_split
I1007 10:06:33.506073  4720 net.cpp:84] Creating Layer Eltwise1_penlu3_0_split
I1007 10:06:33.506076  4720 net.cpp:406] Eltwise1_penlu3_0_split <- Eltwise1
I1007 10:06:33.506080  4720 net.cpp:380] Eltwise1_penlu3_0_split -> Eltwise1_penlu3_0_split_0
I1007 10:06:33.506084  4720 net.cpp:380] Eltwise1_penlu3_0_split -> Eltwise1_penlu3_0_split_1
I1007 10:06:33.506109  4720 net.cpp:122] Setting up Eltwise1_penlu3_0_split
I1007 10:06:33.506114  4720 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 10:06:33.506116  4720 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 10:06:33.506119  4720 net.cpp:137] Memory required for data: 112641200
I1007 10:06:33.506120  4720 layer_factory.hpp:77] Creating layer Convolution4
I1007 10:06:33.506127  4720 net.cpp:84] Creating Layer Convolution4
I1007 10:06:33.506129  4720 net.cpp:406] Convolution4 <- Eltwise1_penlu3_0_split_0
I1007 10:06:33.506134  4720 net.cpp:380] Convolution4 -> Convolution4
I1007 10:06:33.507251  4720 net.cpp:122] Setting up Convolution4
I1007 10:06:33.507259  4720 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 10:06:33.507263  4720 net.cpp:137] Memory required for data: 119194800
I1007 10:06:33.507267  4720 layer_factory.hpp:77] Creating layer BatchNorm4
I1007 10:06:33.507272  4720 net.cpp:84] Creating Layer BatchNorm4
I1007 10:06:33.507274  4720 net.cpp:406] BatchNorm4 <- Convolution4
I1007 10:06:33.507279  4720 net.cpp:367] BatchNorm4 -> Convolution4 (in-place)
I1007 10:06:33.507426  4720 net.cpp:122] Setting up BatchNorm4
I1007 10:06:33.507431  4720 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 10:06:33.507432  4720 net.cpp:137] Memory required for data: 125748400
I1007 10:06:33.507441  4720 layer_factory.hpp:77] Creating layer Scale4
I1007 10:06:33.507446  4720 net.cpp:84] Creating Layer Scale4
I1007 10:06:33.507448  4720 net.cpp:406] Scale4 <- Convolution4
I1007 10:06:33.507452  4720 net.cpp:367] Scale4 -> Convolution4 (in-place)
I1007 10:06:33.507486  4720 layer_factory.hpp:77] Creating layer Scale4
I1007 10:06:33.507571  4720 net.cpp:122] Setting up Scale4
I1007 10:06:33.507577  4720 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 10:06:33.507580  4720 net.cpp:137] Memory required for data: 132302000
I1007 10:06:33.507583  4720 layer_factory.hpp:77] Creating layer penlu4
I1007 10:06:33.507589  4720 net.cpp:84] Creating Layer penlu4
I1007 10:06:33.507592  4720 net.cpp:406] penlu4 <- Convolution4
I1007 10:06:33.507596  4720 net.cpp:367] penlu4 -> Convolution4 (in-place)
I1007 10:06:33.507720  4720 net.cpp:122] Setting up penlu4
I1007 10:06:33.507735  4720 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 10:06:33.507738  4720 net.cpp:137] Memory required for data: 138855600
I1007 10:06:33.507743  4720 layer_factory.hpp:77] Creating layer Convolution5
I1007 10:06:33.507750  4720 net.cpp:84] Creating Layer Convolution5
I1007 10:06:33.507752  4720 net.cpp:406] Convolution5 <- Convolution4
I1007 10:06:33.507757  4720 net.cpp:380] Convolution5 -> Convolution5
I1007 10:06:33.508759  4720 net.cpp:122] Setting up Convolution5
I1007 10:06:33.508769  4720 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 10:06:33.508771  4720 net.cpp:137] Memory required for data: 145409200
I1007 10:06:33.508776  4720 layer_factory.hpp:77] Creating layer BatchNorm5
I1007 10:06:33.508782  4720 net.cpp:84] Creating Layer BatchNorm5
I1007 10:06:33.508785  4720 net.cpp:406] BatchNorm5 <- Convolution5
I1007 10:06:33.508788  4720 net.cpp:367] BatchNorm5 -> Convolution5 (in-place)
I1007 10:06:33.508934  4720 net.cpp:122] Setting up BatchNorm5
I1007 10:06:33.508937  4720 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 10:06:33.508939  4720 net.cpp:137] Memory required for data: 151962800
I1007 10:06:33.508944  4720 layer_factory.hpp:77] Creating layer Scale5
I1007 10:06:33.508950  4720 net.cpp:84] Creating Layer Scale5
I1007 10:06:33.508954  4720 net.cpp:406] Scale5 <- Convolution5
I1007 10:06:33.508956  4720 net.cpp:367] Scale5 -> Convolution5 (in-place)
I1007 10:06:33.508986  4720 layer_factory.hpp:77] Creating layer Scale5
I1007 10:06:33.509068  4720 net.cpp:122] Setting up Scale5
I1007 10:06:33.509071  4720 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 10:06:33.509073  4720 net.cpp:137] Memory required for data: 158516400
I1007 10:06:33.509078  4720 layer_factory.hpp:77] Creating layer Eltwise2
I1007 10:06:33.509083  4720 net.cpp:84] Creating Layer Eltwise2
I1007 10:06:33.509085  4720 net.cpp:406] Eltwise2 <- Eltwise1_penlu3_0_split_1
I1007 10:06:33.509088  4720 net.cpp:406] Eltwise2 <- Convolution5
I1007 10:06:33.509091  4720 net.cpp:380] Eltwise2 -> Eltwise2
I1007 10:06:33.509109  4720 net.cpp:122] Setting up Eltwise2
I1007 10:06:33.509112  4720 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 10:06:33.509114  4720 net.cpp:137] Memory required for data: 165070000
I1007 10:06:33.509116  4720 layer_factory.hpp:77] Creating layer penlu5
I1007 10:06:33.509122  4720 net.cpp:84] Creating Layer penlu5
I1007 10:06:33.509124  4720 net.cpp:406] penlu5 <- Eltwise2
I1007 10:06:33.509127  4720 net.cpp:367] penlu5 -> Eltwise2 (in-place)
I1007 10:06:33.509253  4720 net.cpp:122] Setting up penlu5
I1007 10:06:33.509258  4720 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 10:06:33.509260  4720 net.cpp:137] Memory required for data: 171623600
I1007 10:06:33.509264  4720 layer_factory.hpp:77] Creating layer Eltwise2_penlu5_0_split
I1007 10:06:33.509268  4720 net.cpp:84] Creating Layer Eltwise2_penlu5_0_split
I1007 10:06:33.509270  4720 net.cpp:406] Eltwise2_penlu5_0_split <- Eltwise2
I1007 10:06:33.509274  4720 net.cpp:380] Eltwise2_penlu5_0_split -> Eltwise2_penlu5_0_split_0
I1007 10:06:33.509277  4720 net.cpp:380] Eltwise2_penlu5_0_split -> Eltwise2_penlu5_0_split_1
I1007 10:06:33.509305  4720 net.cpp:122] Setting up Eltwise2_penlu5_0_split
I1007 10:06:33.509308  4720 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 10:06:33.509311  4720 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 10:06:33.509313  4720 net.cpp:137] Memory required for data: 184730800
I1007 10:06:33.509315  4720 layer_factory.hpp:77] Creating layer Convolution6
I1007 10:06:33.509322  4720 net.cpp:84] Creating Layer Convolution6
I1007 10:06:33.509325  4720 net.cpp:406] Convolution6 <- Eltwise2_penlu5_0_split_0
I1007 10:06:33.509330  4720 net.cpp:380] Convolution6 -> Convolution6
I1007 10:06:33.510288  4720 net.cpp:122] Setting up Convolution6
I1007 10:06:33.510296  4720 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 10:06:33.510299  4720 net.cpp:137] Memory required for data: 191284400
I1007 10:06:33.510303  4720 layer_factory.hpp:77] Creating layer BatchNorm6
I1007 10:06:33.510315  4720 net.cpp:84] Creating Layer BatchNorm6
I1007 10:06:33.510318  4720 net.cpp:406] BatchNorm6 <- Convolution6
I1007 10:06:33.510323  4720 net.cpp:367] BatchNorm6 -> Convolution6 (in-place)
I1007 10:06:33.510470  4720 net.cpp:122] Setting up BatchNorm6
I1007 10:06:33.510475  4720 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 10:06:33.510478  4720 net.cpp:137] Memory required for data: 197838000
I1007 10:06:33.510483  4720 layer_factory.hpp:77] Creating layer Scale6
I1007 10:06:33.510486  4720 net.cpp:84] Creating Layer Scale6
I1007 10:06:33.510488  4720 net.cpp:406] Scale6 <- Convolution6
I1007 10:06:33.526404  4720 net.cpp:367] Scale6 -> Convolution6 (in-place)
I1007 10:06:33.526451  4720 layer_factory.hpp:77] Creating layer Scale6
I1007 10:06:33.526546  4720 net.cpp:122] Setting up Scale6
I1007 10:06:33.526551  4720 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 10:06:33.526554  4720 net.cpp:137] Memory required for data: 204391600
I1007 10:06:33.526559  4720 layer_factory.hpp:77] Creating layer penlu6
I1007 10:06:33.526564  4720 net.cpp:84] Creating Layer penlu6
I1007 10:06:33.526567  4720 net.cpp:406] penlu6 <- Convolution6
I1007 10:06:33.526571  4720 net.cpp:367] penlu6 -> Convolution6 (in-place)
I1007 10:06:33.526705  4720 net.cpp:122] Setting up penlu6
I1007 10:06:33.526710  4720 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 10:06:33.526712  4720 net.cpp:137] Memory required for data: 210945200
I1007 10:06:33.526717  4720 layer_factory.hpp:77] Creating layer Convolution7
I1007 10:06:33.526724  4720 net.cpp:84] Creating Layer Convolution7
I1007 10:06:33.526727  4720 net.cpp:406] Convolution7 <- Convolution6
I1007 10:06:33.526732  4720 net.cpp:380] Convolution7 -> Convolution7
I1007 10:06:33.527768  4720 net.cpp:122] Setting up Convolution7
I1007 10:06:33.527778  4720 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 10:06:33.527781  4720 net.cpp:137] Memory required for data: 217498800
I1007 10:06:33.527786  4720 layer_factory.hpp:77] Creating layer BatchNorm7
I1007 10:06:33.527794  4720 net.cpp:84] Creating Layer BatchNorm7
I1007 10:06:33.527797  4720 net.cpp:406] BatchNorm7 <- Convolution7
I1007 10:06:33.527801  4720 net.cpp:367] BatchNorm7 -> Convolution7 (in-place)
I1007 10:06:33.527990  4720 net.cpp:122] Setting up BatchNorm7
I1007 10:06:33.527998  4720 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 10:06:33.528002  4720 net.cpp:137] Memory required for data: 224052400
I1007 10:06:33.528013  4720 layer_factory.hpp:77] Creating layer Scale7
I1007 10:06:33.528019  4720 net.cpp:84] Creating Layer Scale7
I1007 10:06:33.528023  4720 net.cpp:406] Scale7 <- Convolution7
I1007 10:06:33.528028  4720 net.cpp:367] Scale7 -> Convolution7 (in-place)
I1007 10:06:33.528081  4720 layer_factory.hpp:77] Creating layer Scale7
I1007 10:06:33.528189  4720 net.cpp:122] Setting up Scale7
I1007 10:06:33.528197  4720 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 10:06:33.528198  4720 net.cpp:137] Memory required for data: 230606000
I1007 10:06:33.528203  4720 layer_factory.hpp:77] Creating layer Eltwise3
I1007 10:06:33.528208  4720 net.cpp:84] Creating Layer Eltwise3
I1007 10:06:33.528210  4720 net.cpp:406] Eltwise3 <- Eltwise2_penlu5_0_split_1
I1007 10:06:33.528214  4720 net.cpp:406] Eltwise3 <- Convolution7
I1007 10:06:33.528218  4720 net.cpp:380] Eltwise3 -> Eltwise3
I1007 10:06:33.528235  4720 net.cpp:122] Setting up Eltwise3
I1007 10:06:33.528239  4720 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 10:06:33.528241  4720 net.cpp:137] Memory required for data: 237159600
I1007 10:06:33.528244  4720 layer_factory.hpp:77] Creating layer penlu7
I1007 10:06:33.528249  4720 net.cpp:84] Creating Layer penlu7
I1007 10:06:33.528251  4720 net.cpp:406] penlu7 <- Eltwise3
I1007 10:06:33.528255  4720 net.cpp:367] penlu7 -> Eltwise3 (in-place)
I1007 10:06:33.528380  4720 net.cpp:122] Setting up penlu7
I1007 10:06:33.528385  4720 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 10:06:33.528388  4720 net.cpp:137] Memory required for data: 243713200
I1007 10:06:33.528399  4720 layer_factory.hpp:77] Creating layer Eltwise3_penlu7_0_split
I1007 10:06:33.528403  4720 net.cpp:84] Creating Layer Eltwise3_penlu7_0_split
I1007 10:06:33.528405  4720 net.cpp:406] Eltwise3_penlu7_0_split <- Eltwise3
I1007 10:06:33.528409  4720 net.cpp:380] Eltwise3_penlu7_0_split -> Eltwise3_penlu7_0_split_0
I1007 10:06:33.528414  4720 net.cpp:380] Eltwise3_penlu7_0_split -> Eltwise3_penlu7_0_split_1
I1007 10:06:33.528440  4720 net.cpp:122] Setting up Eltwise3_penlu7_0_split
I1007 10:06:33.528445  4720 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 10:06:33.528447  4720 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 10:06:33.528450  4720 net.cpp:137] Memory required for data: 256820400
I1007 10:06:33.528452  4720 layer_factory.hpp:77] Creating layer Convolution8
I1007 10:06:33.528458  4720 net.cpp:84] Creating Layer Convolution8
I1007 10:06:33.528461  4720 net.cpp:406] Convolution8 <- Eltwise3_penlu7_0_split_0
I1007 10:06:33.528465  4720 net.cpp:380] Convolution8 -> Convolution8
I1007 10:06:33.529428  4720 net.cpp:122] Setting up Convolution8
I1007 10:06:33.529436  4720 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 10:06:33.529439  4720 net.cpp:137] Memory required for data: 263374000
I1007 10:06:33.529444  4720 layer_factory.hpp:77] Creating layer BatchNorm8
I1007 10:06:33.529449  4720 net.cpp:84] Creating Layer BatchNorm8
I1007 10:06:33.529453  4720 net.cpp:406] BatchNorm8 <- Convolution8
I1007 10:06:33.529455  4720 net.cpp:367] BatchNorm8 -> Convolution8 (in-place)
I1007 10:06:33.529605  4720 net.cpp:122] Setting up BatchNorm8
I1007 10:06:33.529610  4720 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 10:06:33.529613  4720 net.cpp:137] Memory required for data: 269927600
I1007 10:06:33.529618  4720 layer_factory.hpp:77] Creating layer Scale8
I1007 10:06:33.529621  4720 net.cpp:84] Creating Layer Scale8
I1007 10:06:33.529623  4720 net.cpp:406] Scale8 <- Convolution8
I1007 10:06:33.529628  4720 net.cpp:367] Scale8 -> Convolution8 (in-place)
I1007 10:06:33.529657  4720 layer_factory.hpp:77] Creating layer Scale8
I1007 10:06:33.529741  4720 net.cpp:122] Setting up Scale8
I1007 10:06:33.529745  4720 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 10:06:33.529747  4720 net.cpp:137] Memory required for data: 276481200
I1007 10:06:33.529752  4720 layer_factory.hpp:77] Creating layer penlu8
I1007 10:06:33.529757  4720 net.cpp:84] Creating Layer penlu8
I1007 10:06:33.529760  4720 net.cpp:406] penlu8 <- Convolution8
I1007 10:06:33.529764  4720 net.cpp:367] penlu8 -> Convolution8 (in-place)
I1007 10:06:33.529891  4720 net.cpp:122] Setting up penlu8
I1007 10:06:33.529894  4720 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 10:06:33.529897  4720 net.cpp:137] Memory required for data: 283034800
I1007 10:06:33.529901  4720 layer_factory.hpp:77] Creating layer Convolution9
I1007 10:06:33.529908  4720 net.cpp:84] Creating Layer Convolution9
I1007 10:06:33.529911  4720 net.cpp:406] Convolution9 <- Convolution8
I1007 10:06:33.529914  4720 net.cpp:380] Convolution9 -> Convolution9
I1007 10:06:33.531339  4720 net.cpp:122] Setting up Convolution9
I1007 10:06:33.531348  4720 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 10:06:33.531352  4720 net.cpp:137] Memory required for data: 289588400
I1007 10:06:33.531357  4720 layer_factory.hpp:77] Creating layer BatchNorm9
I1007 10:06:33.531361  4720 net.cpp:84] Creating Layer BatchNorm9
I1007 10:06:33.531364  4720 net.cpp:406] BatchNorm9 <- Convolution9
I1007 10:06:33.531368  4720 net.cpp:367] BatchNorm9 -> Convolution9 (in-place)
I1007 10:06:33.531518  4720 net.cpp:122] Setting up BatchNorm9
I1007 10:06:33.531523  4720 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 10:06:33.531525  4720 net.cpp:137] Memory required for data: 296142000
I1007 10:06:33.531530  4720 layer_factory.hpp:77] Creating layer Scale9
I1007 10:06:33.531534  4720 net.cpp:84] Creating Layer Scale9
I1007 10:06:33.531536  4720 net.cpp:406] Scale9 <- Convolution9
I1007 10:06:33.531540  4720 net.cpp:367] Scale9 -> Convolution9 (in-place)
I1007 10:06:33.531570  4720 layer_factory.hpp:77] Creating layer Scale9
I1007 10:06:33.531663  4720 net.cpp:122] Setting up Scale9
I1007 10:06:33.531668  4720 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 10:06:33.531671  4720 net.cpp:137] Memory required for data: 302695600
I1007 10:06:33.531675  4720 layer_factory.hpp:77] Creating layer Eltwise4
I1007 10:06:33.531680  4720 net.cpp:84] Creating Layer Eltwise4
I1007 10:06:33.531682  4720 net.cpp:406] Eltwise4 <- Eltwise3_penlu7_0_split_1
I1007 10:06:33.531685  4720 net.cpp:406] Eltwise4 <- Convolution9
I1007 10:06:33.531688  4720 net.cpp:380] Eltwise4 -> Eltwise4
I1007 10:06:33.531707  4720 net.cpp:122] Setting up Eltwise4
I1007 10:06:33.531710  4720 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 10:06:33.531713  4720 net.cpp:137] Memory required for data: 309249200
I1007 10:06:33.531714  4720 layer_factory.hpp:77] Creating layer penlu9
I1007 10:06:33.531719  4720 net.cpp:84] Creating Layer penlu9
I1007 10:06:33.531723  4720 net.cpp:406] penlu9 <- Eltwise4
I1007 10:06:33.531725  4720 net.cpp:367] penlu9 -> Eltwise4 (in-place)
I1007 10:06:33.531852  4720 net.cpp:122] Setting up penlu9
I1007 10:06:33.531857  4720 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 10:06:33.531859  4720 net.cpp:137] Memory required for data: 315802800
I1007 10:06:33.531863  4720 layer_factory.hpp:77] Creating layer Eltwise4_penlu9_0_split
I1007 10:06:33.531867  4720 net.cpp:84] Creating Layer Eltwise4_penlu9_0_split
I1007 10:06:33.531869  4720 net.cpp:406] Eltwise4_penlu9_0_split <- Eltwise4
I1007 10:06:33.531872  4720 net.cpp:380] Eltwise4_penlu9_0_split -> Eltwise4_penlu9_0_split_0
I1007 10:06:33.531877  4720 net.cpp:380] Eltwise4_penlu9_0_split -> Eltwise4_penlu9_0_split_1
I1007 10:06:33.531901  4720 net.cpp:122] Setting up Eltwise4_penlu9_0_split
I1007 10:06:33.531905  4720 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 10:06:33.531908  4720 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 10:06:33.531910  4720 net.cpp:137] Memory required for data: 328910000
I1007 10:06:33.531913  4720 layer_factory.hpp:77] Creating layer Convolution10
I1007 10:06:33.531919  4720 net.cpp:84] Creating Layer Convolution10
I1007 10:06:33.531921  4720 net.cpp:406] Convolution10 <- Eltwise4_penlu9_0_split_0
I1007 10:06:33.531925  4720 net.cpp:380] Convolution10 -> Convolution10
I1007 10:06:33.532536  4720 net.cpp:122] Setting up Convolution10
I1007 10:06:33.532543  4720 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 10:06:33.532546  4720 net.cpp:137] Memory required for data: 335463600
I1007 10:06:33.532551  4720 layer_factory.hpp:77] Creating layer BatchNorm10
I1007 10:06:33.532555  4720 net.cpp:84] Creating Layer BatchNorm10
I1007 10:06:33.532559  4720 net.cpp:406] BatchNorm10 <- Convolution10
I1007 10:06:33.532562  4720 net.cpp:367] BatchNorm10 -> Convolution10 (in-place)
I1007 10:06:33.532711  4720 net.cpp:122] Setting up BatchNorm10
I1007 10:06:33.532714  4720 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 10:06:33.532716  4720 net.cpp:137] Memory required for data: 342017200
I1007 10:06:33.532721  4720 layer_factory.hpp:77] Creating layer Scale10
I1007 10:06:33.532727  4720 net.cpp:84] Creating Layer Scale10
I1007 10:06:33.532729  4720 net.cpp:406] Scale10 <- Convolution10
I1007 10:06:33.532732  4720 net.cpp:367] Scale10 -> Convolution10 (in-place)
I1007 10:06:33.532762  4720 layer_factory.hpp:77] Creating layer Scale10
I1007 10:06:33.532845  4720 net.cpp:122] Setting up Scale10
I1007 10:06:33.532850  4720 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 10:06:33.532851  4720 net.cpp:137] Memory required for data: 348570800
I1007 10:06:33.532855  4720 layer_factory.hpp:77] Creating layer penlu10
I1007 10:06:33.532860  4720 net.cpp:84] Creating Layer penlu10
I1007 10:06:33.532863  4720 net.cpp:406] penlu10 <- Convolution10
I1007 10:06:33.532867  4720 net.cpp:367] penlu10 -> Convolution10 (in-place)
I1007 10:06:33.532991  4720 net.cpp:122] Setting up penlu10
I1007 10:06:33.532997  4720 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 10:06:33.532999  4720 net.cpp:137] Memory required for data: 355124400
I1007 10:06:33.533010  4720 layer_factory.hpp:77] Creating layer Convolution11
I1007 10:06:33.533017  4720 net.cpp:84] Creating Layer Convolution11
I1007 10:06:33.533020  4720 net.cpp:406] Convolution11 <- Convolution10
I1007 10:06:33.533023  4720 net.cpp:380] Convolution11 -> Convolution11
I1007 10:06:33.533975  4720 net.cpp:122] Setting up Convolution11
I1007 10:06:33.533984  4720 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 10:06:33.533987  4720 net.cpp:137] Memory required for data: 361678000
I1007 10:06:33.533991  4720 layer_factory.hpp:77] Creating layer BatchNorm11
I1007 10:06:33.533998  4720 net.cpp:84] Creating Layer BatchNorm11
I1007 10:06:33.534000  4720 net.cpp:406] BatchNorm11 <- Convolution11
I1007 10:06:33.534003  4720 net.cpp:367] BatchNorm11 -> Convolution11 (in-place)
I1007 10:06:33.534153  4720 net.cpp:122] Setting up BatchNorm11
I1007 10:06:33.534158  4720 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 10:06:33.534160  4720 net.cpp:137] Memory required for data: 368231600
I1007 10:06:33.534165  4720 layer_factory.hpp:77] Creating layer Scale11
I1007 10:06:33.534169  4720 net.cpp:84] Creating Layer Scale11
I1007 10:06:33.534173  4720 net.cpp:406] Scale11 <- Convolution11
I1007 10:06:33.534175  4720 net.cpp:367] Scale11 -> Convolution11 (in-place)
I1007 10:06:33.534204  4720 layer_factory.hpp:77] Creating layer Scale11
I1007 10:06:33.534287  4720 net.cpp:122] Setting up Scale11
I1007 10:06:33.534291  4720 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 10:06:33.534293  4720 net.cpp:137] Memory required for data: 374785200
I1007 10:06:33.534297  4720 layer_factory.hpp:77] Creating layer Eltwise5
I1007 10:06:33.534302  4720 net.cpp:84] Creating Layer Eltwise5
I1007 10:06:33.534306  4720 net.cpp:406] Eltwise5 <- Eltwise4_penlu9_0_split_1
I1007 10:06:33.534308  4720 net.cpp:406] Eltwise5 <- Convolution11
I1007 10:06:33.534312  4720 net.cpp:380] Eltwise5 -> Eltwise5
I1007 10:06:33.534328  4720 net.cpp:122] Setting up Eltwise5
I1007 10:06:33.534332  4720 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 10:06:33.534334  4720 net.cpp:137] Memory required for data: 381338800
I1007 10:06:33.534337  4720 layer_factory.hpp:77] Creating layer penlu11
I1007 10:06:33.534343  4720 net.cpp:84] Creating Layer penlu11
I1007 10:06:33.534344  4720 net.cpp:406] penlu11 <- Eltwise5
I1007 10:06:33.534349  4720 net.cpp:367] penlu11 -> Eltwise5 (in-place)
I1007 10:06:33.534476  4720 net.cpp:122] Setting up penlu11
I1007 10:06:33.534481  4720 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 10:06:33.534482  4720 net.cpp:137] Memory required for data: 387892400
I1007 10:06:33.534487  4720 layer_factory.hpp:77] Creating layer Eltwise5_penlu11_0_split
I1007 10:06:33.534490  4720 net.cpp:84] Creating Layer Eltwise5_penlu11_0_split
I1007 10:06:33.534492  4720 net.cpp:406] Eltwise5_penlu11_0_split <- Eltwise5
I1007 10:06:33.534497  4720 net.cpp:380] Eltwise5_penlu11_0_split -> Eltwise5_penlu11_0_split_0
I1007 10:06:33.534500  4720 net.cpp:380] Eltwise5_penlu11_0_split -> Eltwise5_penlu11_0_split_1
I1007 10:06:33.534525  4720 net.cpp:122] Setting up Eltwise5_penlu11_0_split
I1007 10:06:33.534529  4720 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 10:06:33.534533  4720 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 10:06:33.534534  4720 net.cpp:137] Memory required for data: 400999600
I1007 10:06:33.534536  4720 layer_factory.hpp:77] Creating layer Convolution12
I1007 10:06:33.534543  4720 net.cpp:84] Creating Layer Convolution12
I1007 10:06:33.534545  4720 net.cpp:406] Convolution12 <- Eltwise5_penlu11_0_split_0
I1007 10:06:33.534549  4720 net.cpp:380] Convolution12 -> Convolution12
I1007 10:06:33.535483  4720 net.cpp:122] Setting up Convolution12
I1007 10:06:33.535492  4720 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 10:06:33.535495  4720 net.cpp:137] Memory required for data: 404276400
I1007 10:06:33.535500  4720 layer_factory.hpp:77] Creating layer BatchNorm12
I1007 10:06:33.535506  4720 net.cpp:84] Creating Layer BatchNorm12
I1007 10:06:33.535508  4720 net.cpp:406] BatchNorm12 <- Convolution12
I1007 10:06:33.535518  4720 net.cpp:367] BatchNorm12 -> Convolution12 (in-place)
I1007 10:06:33.535668  4720 net.cpp:122] Setting up BatchNorm12
I1007 10:06:33.535673  4720 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 10:06:33.535676  4720 net.cpp:137] Memory required for data: 407553200
I1007 10:06:33.535681  4720 layer_factory.hpp:77] Creating layer Scale12
I1007 10:06:33.535686  4720 net.cpp:84] Creating Layer Scale12
I1007 10:06:33.535688  4720 net.cpp:406] Scale12 <- Convolution12
I1007 10:06:33.535691  4720 net.cpp:367] Scale12 -> Convolution12 (in-place)
I1007 10:06:33.556860  4720 layer_factory.hpp:77] Creating layer Scale12
I1007 10:06:33.556960  4720 net.cpp:122] Setting up Scale12
I1007 10:06:33.556965  4720 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 10:06:33.556968  4720 net.cpp:137] Memory required for data: 410830000
I1007 10:06:33.556973  4720 layer_factory.hpp:77] Creating layer Convolution13
I1007 10:06:33.556982  4720 net.cpp:84] Creating Layer Convolution13
I1007 10:06:33.556984  4720 net.cpp:406] Convolution13 <- Eltwise5_penlu11_0_split_1
I1007 10:06:33.556988  4720 net.cpp:380] Convolution13 -> Convolution13
I1007 10:06:33.558073  4720 net.cpp:122] Setting up Convolution13
I1007 10:06:33.558082  4720 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 10:06:33.558085  4720 net.cpp:137] Memory required for data: 414106800
I1007 10:06:33.558090  4720 layer_factory.hpp:77] Creating layer BatchNorm13
I1007 10:06:33.558096  4720 net.cpp:84] Creating Layer BatchNorm13
I1007 10:06:33.558099  4720 net.cpp:406] BatchNorm13 <- Convolution13
I1007 10:06:33.558104  4720 net.cpp:367] BatchNorm13 -> Convolution13 (in-place)
I1007 10:06:33.558281  4720 net.cpp:122] Setting up BatchNorm13
I1007 10:06:33.558290  4720 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 10:06:33.558292  4720 net.cpp:137] Memory required for data: 417383600
I1007 10:06:33.558297  4720 layer_factory.hpp:77] Creating layer Scale13
I1007 10:06:33.558302  4720 net.cpp:84] Creating Layer Scale13
I1007 10:06:33.558305  4720 net.cpp:406] Scale13 <- Convolution13
I1007 10:06:33.558310  4720 net.cpp:367] Scale13 -> Convolution13 (in-place)
I1007 10:06:33.558341  4720 layer_factory.hpp:77] Creating layer Scale13
I1007 10:06:33.558460  4720 net.cpp:122] Setting up Scale13
I1007 10:06:33.558468  4720 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 10:06:33.558470  4720 net.cpp:137] Memory required for data: 420660400
I1007 10:06:33.558475  4720 layer_factory.hpp:77] Creating layer penlu12
I1007 10:06:33.558481  4720 net.cpp:84] Creating Layer penlu12
I1007 10:06:33.558483  4720 net.cpp:406] penlu12 <- Convolution13
I1007 10:06:33.558490  4720 net.cpp:367] penlu12 -> Convolution13 (in-place)
I1007 10:06:33.558624  4720 net.cpp:122] Setting up penlu12
I1007 10:06:33.558629  4720 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 10:06:33.558631  4720 net.cpp:137] Memory required for data: 423937200
I1007 10:06:33.558636  4720 layer_factory.hpp:77] Creating layer Convolution14
I1007 10:06:33.558647  4720 net.cpp:84] Creating Layer Convolution14
I1007 10:06:33.558650  4720 net.cpp:406] Convolution14 <- Convolution13
I1007 10:06:33.558655  4720 net.cpp:380] Convolution14 -> Convolution14
I1007 10:06:33.559797  4720 net.cpp:122] Setting up Convolution14
I1007 10:06:33.559805  4720 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 10:06:33.559808  4720 net.cpp:137] Memory required for data: 427214000
I1007 10:06:33.559824  4720 layer_factory.hpp:77] Creating layer BatchNorm14
I1007 10:06:33.559829  4720 net.cpp:84] Creating Layer BatchNorm14
I1007 10:06:33.559833  4720 net.cpp:406] BatchNorm14 <- Convolution14
I1007 10:06:33.559836  4720 net.cpp:367] BatchNorm14 -> Convolution14 (in-place)
I1007 10:06:33.559985  4720 net.cpp:122] Setting up BatchNorm14
I1007 10:06:33.559989  4720 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 10:06:33.559993  4720 net.cpp:137] Memory required for data: 430490800
I1007 10:06:33.559998  4720 layer_factory.hpp:77] Creating layer Scale14
I1007 10:06:33.560003  4720 net.cpp:84] Creating Layer Scale14
I1007 10:06:33.560012  4720 net.cpp:406] Scale14 <- Convolution14
I1007 10:06:33.560016  4720 net.cpp:367] Scale14 -> Convolution14 (in-place)
I1007 10:06:33.560048  4720 layer_factory.hpp:77] Creating layer Scale14
I1007 10:06:33.560132  4720 net.cpp:122] Setting up Scale14
I1007 10:06:33.560137  4720 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 10:06:33.560138  4720 net.cpp:137] Memory required for data: 433767600
I1007 10:06:33.560142  4720 layer_factory.hpp:77] Creating layer Eltwise6
I1007 10:06:33.560148  4720 net.cpp:84] Creating Layer Eltwise6
I1007 10:06:33.560150  4720 net.cpp:406] Eltwise6 <- Convolution12
I1007 10:06:33.560153  4720 net.cpp:406] Eltwise6 <- Convolution14
I1007 10:06:33.560158  4720 net.cpp:380] Eltwise6 -> Eltwise6
I1007 10:06:33.560171  4720 net.cpp:122] Setting up Eltwise6
I1007 10:06:33.560174  4720 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 10:06:33.560176  4720 net.cpp:137] Memory required for data: 437044400
I1007 10:06:33.560178  4720 layer_factory.hpp:77] Creating layer penlu13
I1007 10:06:33.560184  4720 net.cpp:84] Creating Layer penlu13
I1007 10:06:33.560187  4720 net.cpp:406] penlu13 <- Eltwise6
I1007 10:06:33.560190  4720 net.cpp:367] penlu13 -> Eltwise6 (in-place)
I1007 10:06:33.560314  4720 net.cpp:122] Setting up penlu13
I1007 10:06:33.560319  4720 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 10:06:33.560322  4720 net.cpp:137] Memory required for data: 440321200
I1007 10:06:33.560325  4720 layer_factory.hpp:77] Creating layer Eltwise6_penlu13_0_split
I1007 10:06:33.560329  4720 net.cpp:84] Creating Layer Eltwise6_penlu13_0_split
I1007 10:06:33.560331  4720 net.cpp:406] Eltwise6_penlu13_0_split <- Eltwise6
I1007 10:06:33.560335  4720 net.cpp:380] Eltwise6_penlu13_0_split -> Eltwise6_penlu13_0_split_0
I1007 10:06:33.560338  4720 net.cpp:380] Eltwise6_penlu13_0_split -> Eltwise6_penlu13_0_split_1
I1007 10:06:33.560364  4720 net.cpp:122] Setting up Eltwise6_penlu13_0_split
I1007 10:06:33.560369  4720 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 10:06:33.560371  4720 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 10:06:33.560374  4720 net.cpp:137] Memory required for data: 446874800
I1007 10:06:33.560375  4720 layer_factory.hpp:77] Creating layer Convolution15
I1007 10:06:33.560382  4720 net.cpp:84] Creating Layer Convolution15
I1007 10:06:33.560384  4720 net.cpp:406] Convolution15 <- Eltwise6_penlu13_0_split_0
I1007 10:06:33.560389  4720 net.cpp:380] Convolution15 -> Convolution15
I1007 10:06:33.561842  4720 net.cpp:122] Setting up Convolution15
I1007 10:06:33.561851  4720 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 10:06:33.561853  4720 net.cpp:137] Memory required for data: 450151600
I1007 10:06:33.561859  4720 layer_factory.hpp:77] Creating layer BatchNorm15
I1007 10:06:33.561864  4720 net.cpp:84] Creating Layer BatchNorm15
I1007 10:06:33.561867  4720 net.cpp:406] BatchNorm15 <- Convolution15
I1007 10:06:33.561872  4720 net.cpp:367] BatchNorm15 -> Convolution15 (in-place)
I1007 10:06:33.562026  4720 net.cpp:122] Setting up BatchNorm15
I1007 10:06:33.562031  4720 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 10:06:33.562032  4720 net.cpp:137] Memory required for data: 453428400
I1007 10:06:33.562037  4720 layer_factory.hpp:77] Creating layer Scale15
I1007 10:06:33.562041  4720 net.cpp:84] Creating Layer Scale15
I1007 10:06:33.562043  4720 net.cpp:406] Scale15 <- Convolution15
I1007 10:06:33.562047  4720 net.cpp:367] Scale15 -> Convolution15 (in-place)
I1007 10:06:33.562078  4720 layer_factory.hpp:77] Creating layer Scale15
I1007 10:06:33.562163  4720 net.cpp:122] Setting up Scale15
I1007 10:06:33.562167  4720 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 10:06:33.562170  4720 net.cpp:137] Memory required for data: 456705200
I1007 10:06:33.562173  4720 layer_factory.hpp:77] Creating layer penlu14
I1007 10:06:33.562178  4720 net.cpp:84] Creating Layer penlu14
I1007 10:06:33.562181  4720 net.cpp:406] penlu14 <- Convolution15
I1007 10:06:33.562186  4720 net.cpp:367] penlu14 -> Convolution15 (in-place)
I1007 10:06:33.562314  4720 net.cpp:122] Setting up penlu14
I1007 10:06:33.562319  4720 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 10:06:33.562321  4720 net.cpp:137] Memory required for data: 459982000
I1007 10:06:33.562326  4720 layer_factory.hpp:77] Creating layer Convolution16
I1007 10:06:33.562333  4720 net.cpp:84] Creating Layer Convolution16
I1007 10:06:33.562336  4720 net.cpp:406] Convolution16 <- Convolution15
I1007 10:06:33.562340  4720 net.cpp:380] Convolution16 -> Convolution16
I1007 10:06:33.564018  4720 net.cpp:122] Setting up Convolution16
I1007 10:06:33.564028  4720 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 10:06:33.564031  4720 net.cpp:137] Memory required for data: 463258800
I1007 10:06:33.564036  4720 layer_factory.hpp:77] Creating layer BatchNorm16
I1007 10:06:33.564043  4720 net.cpp:84] Creating Layer BatchNorm16
I1007 10:06:33.564046  4720 net.cpp:406] BatchNorm16 <- Convolution16
I1007 10:06:33.564049  4720 net.cpp:367] BatchNorm16 -> Convolution16 (in-place)
I1007 10:06:33.564199  4720 net.cpp:122] Setting up BatchNorm16
I1007 10:06:33.564203  4720 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 10:06:33.564205  4720 net.cpp:137] Memory required for data: 466535600
I1007 10:06:33.564210  4720 layer_factory.hpp:77] Creating layer Scale16
I1007 10:06:33.564215  4720 net.cpp:84] Creating Layer Scale16
I1007 10:06:33.564218  4720 net.cpp:406] Scale16 <- Convolution16
I1007 10:06:33.564221  4720 net.cpp:367] Scale16 -> Convolution16 (in-place)
I1007 10:06:33.564252  4720 layer_factory.hpp:77] Creating layer Scale16
I1007 10:06:33.564337  4720 net.cpp:122] Setting up Scale16
I1007 10:06:33.564342  4720 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 10:06:33.564343  4720 net.cpp:137] Memory required for data: 469812400
I1007 10:06:33.564347  4720 layer_factory.hpp:77] Creating layer Eltwise7
I1007 10:06:33.564352  4720 net.cpp:84] Creating Layer Eltwise7
I1007 10:06:33.564355  4720 net.cpp:406] Eltwise7 <- Eltwise6_penlu13_0_split_1
I1007 10:06:33.564358  4720 net.cpp:406] Eltwise7 <- Convolution16
I1007 10:06:33.564362  4720 net.cpp:380] Eltwise7 -> Eltwise7
I1007 10:06:33.564376  4720 net.cpp:122] Setting up Eltwise7
I1007 10:06:33.564379  4720 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 10:06:33.564381  4720 net.cpp:137] Memory required for data: 473089200
I1007 10:06:33.564383  4720 layer_factory.hpp:77] Creating layer penlu15
I1007 10:06:33.564388  4720 net.cpp:84] Creating Layer penlu15
I1007 10:06:33.564390  4720 net.cpp:406] penlu15 <- Eltwise7
I1007 10:06:33.564394  4720 net.cpp:367] penlu15 -> Eltwise7 (in-place)
I1007 10:06:33.564517  4720 net.cpp:122] Setting up penlu15
I1007 10:06:33.564520  4720 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 10:06:33.564522  4720 net.cpp:137] Memory required for data: 476366000
I1007 10:06:33.564527  4720 layer_factory.hpp:77] Creating layer Eltwise7_penlu15_0_split
I1007 10:06:33.564532  4720 net.cpp:84] Creating Layer Eltwise7_penlu15_0_split
I1007 10:06:33.564533  4720 net.cpp:406] Eltwise7_penlu15_0_split <- Eltwise7
I1007 10:06:33.564537  4720 net.cpp:380] Eltwise7_penlu15_0_split -> Eltwise7_penlu15_0_split_0
I1007 10:06:33.564540  4720 net.cpp:380] Eltwise7_penlu15_0_split -> Eltwise7_penlu15_0_split_1
I1007 10:06:33.564566  4720 net.cpp:122] Setting up Eltwise7_penlu15_0_split
I1007 10:06:33.564570  4720 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 10:06:33.564574  4720 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 10:06:33.564575  4720 net.cpp:137] Memory required for data: 482919600
I1007 10:06:33.564577  4720 layer_factory.hpp:77] Creating layer Convolution17
I1007 10:06:33.564584  4720 net.cpp:84] Creating Layer Convolution17
I1007 10:06:33.564587  4720 net.cpp:406] Convolution17 <- Eltwise7_penlu15_0_split_0
I1007 10:06:33.564591  4720 net.cpp:380] Convolution17 -> Convolution17
I1007 10:06:33.565714  4720 net.cpp:122] Setting up Convolution17
I1007 10:06:33.565723  4720 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 10:06:33.565726  4720 net.cpp:137] Memory required for data: 486196400
I1007 10:06:33.565737  4720 layer_factory.hpp:77] Creating layer BatchNorm17
I1007 10:06:33.565744  4720 net.cpp:84] Creating Layer BatchNorm17
I1007 10:06:33.565747  4720 net.cpp:406] BatchNorm17 <- Convolution17
I1007 10:06:33.565750  4720 net.cpp:367] BatchNorm17 -> Convolution17 (in-place)
I1007 10:06:33.565901  4720 net.cpp:122] Setting up BatchNorm17
I1007 10:06:33.565906  4720 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 10:06:33.565908  4720 net.cpp:137] Memory required for data: 489473200
I1007 10:06:33.565912  4720 layer_factory.hpp:77] Creating layer Scale17
I1007 10:06:33.565917  4720 net.cpp:84] Creating Layer Scale17
I1007 10:06:33.565919  4720 net.cpp:406] Scale17 <- Convolution17
I1007 10:06:33.565922  4720 net.cpp:367] Scale17 -> Convolution17 (in-place)
I1007 10:06:33.565953  4720 layer_factory.hpp:77] Creating layer Scale17
I1007 10:06:33.566037  4720 net.cpp:122] Setting up Scale17
I1007 10:06:33.566041  4720 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 10:06:33.566043  4720 net.cpp:137] Memory required for data: 492750000
I1007 10:06:33.566047  4720 layer_factory.hpp:77] Creating layer penlu16
I1007 10:06:33.566053  4720 net.cpp:84] Creating Layer penlu16
I1007 10:06:33.566056  4720 net.cpp:406] penlu16 <- Convolution17
I1007 10:06:33.566061  4720 net.cpp:367] penlu16 -> Convolution17 (in-place)
I1007 10:06:33.566179  4720 net.cpp:122] Setting up penlu16
I1007 10:06:33.566184  4720 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 10:06:33.566185  4720 net.cpp:137] Memory required for data: 496026800
I1007 10:06:33.566190  4720 layer_factory.hpp:77] Creating layer Convolution18
I1007 10:06:33.566197  4720 net.cpp:84] Creating Layer Convolution18
I1007 10:06:33.566200  4720 net.cpp:406] Convolution18 <- Convolution17
I1007 10:06:33.566203  4720 net.cpp:380] Convolution18 -> Convolution18
I1007 10:06:33.567342  4720 net.cpp:122] Setting up Convolution18
I1007 10:06:33.567351  4720 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 10:06:33.567353  4720 net.cpp:137] Memory required for data: 499303600
I1007 10:06:33.567358  4720 layer_factory.hpp:77] Creating layer BatchNorm18
I1007 10:06:33.567363  4720 net.cpp:84] Creating Layer BatchNorm18
I1007 10:06:33.567366  4720 net.cpp:406] BatchNorm18 <- Convolution18
I1007 10:06:33.567370  4720 net.cpp:367] BatchNorm18 -> Convolution18 (in-place)
I1007 10:06:33.567522  4720 net.cpp:122] Setting up BatchNorm18
I1007 10:06:33.567526  4720 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 10:06:33.567528  4720 net.cpp:137] Memory required for data: 502580400
I1007 10:06:33.567533  4720 layer_factory.hpp:77] Creating layer Scale18
I1007 10:06:33.567538  4720 net.cpp:84] Creating Layer Scale18
I1007 10:06:33.567540  4720 net.cpp:406] Scale18 <- Convolution18
I1007 10:06:33.567544  4720 net.cpp:367] Scale18 -> Convolution18 (in-place)
I1007 10:06:33.567574  4720 layer_factory.hpp:77] Creating layer Scale18
I1007 10:06:33.567662  4720 net.cpp:122] Setting up Scale18
I1007 10:06:33.567667  4720 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 10:06:33.567668  4720 net.cpp:137] Memory required for data: 505857200
I1007 10:06:33.567672  4720 layer_factory.hpp:77] Creating layer Eltwise8
I1007 10:06:33.567677  4720 net.cpp:84] Creating Layer Eltwise8
I1007 10:06:33.567679  4720 net.cpp:406] Eltwise8 <- Eltwise7_penlu15_0_split_1
I1007 10:06:33.567682  4720 net.cpp:406] Eltwise8 <- Convolution18
I1007 10:06:33.567685  4720 net.cpp:380] Eltwise8 -> Eltwise8
I1007 10:06:33.567700  4720 net.cpp:122] Setting up Eltwise8
I1007 10:06:33.567704  4720 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 10:06:33.567706  4720 net.cpp:137] Memory required for data: 509134000
I1007 10:06:33.567708  4720 layer_factory.hpp:77] Creating layer penlu17
I1007 10:06:33.567714  4720 net.cpp:84] Creating Layer penlu17
I1007 10:06:33.567718  4720 net.cpp:406] penlu17 <- Eltwise8
I1007 10:06:33.567721  4720 net.cpp:367] penlu17 -> Eltwise8 (in-place)
I1007 10:06:33.567845  4720 net.cpp:122] Setting up penlu17
I1007 10:06:33.567850  4720 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 10:06:33.567859  4720 net.cpp:137] Memory required for data: 512410800
I1007 10:06:33.567864  4720 layer_factory.hpp:77] Creating layer Eltwise8_penlu17_0_split
I1007 10:06:33.567869  4720 net.cpp:84] Creating Layer Eltwise8_penlu17_0_split
I1007 10:06:33.567872  4720 net.cpp:406] Eltwise8_penlu17_0_split <- Eltwise8
I1007 10:06:33.567875  4720 net.cpp:380] Eltwise8_penlu17_0_split -> Eltwise8_penlu17_0_split_0
I1007 10:06:33.587086  4720 net.cpp:380] Eltwise8_penlu17_0_split -> Eltwise8_penlu17_0_split_1
I1007 10:06:33.587131  4720 net.cpp:122] Setting up Eltwise8_penlu17_0_split
I1007 10:06:33.587136  4720 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 10:06:33.587141  4720 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 10:06:33.587142  4720 net.cpp:137] Memory required for data: 518964400
I1007 10:06:33.587146  4720 layer_factory.hpp:77] Creating layer Convolution19
I1007 10:06:33.587152  4720 net.cpp:84] Creating Layer Convolution19
I1007 10:06:33.587154  4720 net.cpp:406] Convolution19 <- Eltwise8_penlu17_0_split_0
I1007 10:06:33.587160  4720 net.cpp:380] Convolution19 -> Convolution19
I1007 10:06:33.588380  4720 net.cpp:122] Setting up Convolution19
I1007 10:06:33.588390  4720 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 10:06:33.588393  4720 net.cpp:137] Memory required for data: 522241200
I1007 10:06:33.588397  4720 layer_factory.hpp:77] Creating layer BatchNorm19
I1007 10:06:33.588403  4720 net.cpp:84] Creating Layer BatchNorm19
I1007 10:06:33.588407  4720 net.cpp:406] BatchNorm19 <- Convolution19
I1007 10:06:33.588410  4720 net.cpp:367] BatchNorm19 -> Convolution19 (in-place)
I1007 10:06:33.588606  4720 net.cpp:122] Setting up BatchNorm19
I1007 10:06:33.588618  4720 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 10:06:33.588623  4720 net.cpp:137] Memory required for data: 525518000
I1007 10:06:33.588631  4720 layer_factory.hpp:77] Creating layer Scale19
I1007 10:06:33.588639  4720 net.cpp:84] Creating Layer Scale19
I1007 10:06:33.588642  4720 net.cpp:406] Scale19 <- Convolution19
I1007 10:06:33.588646  4720 net.cpp:367] Scale19 -> Convolution19 (in-place)
I1007 10:06:33.588681  4720 layer_factory.hpp:77] Creating layer Scale19
I1007 10:06:33.588769  4720 net.cpp:122] Setting up Scale19
I1007 10:06:33.588773  4720 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 10:06:33.588775  4720 net.cpp:137] Memory required for data: 528794800
I1007 10:06:33.588779  4720 layer_factory.hpp:77] Creating layer penlu18
I1007 10:06:33.588785  4720 net.cpp:84] Creating Layer penlu18
I1007 10:06:33.588788  4720 net.cpp:406] penlu18 <- Convolution19
I1007 10:06:33.588793  4720 net.cpp:367] penlu18 -> Convolution19 (in-place)
I1007 10:06:33.588915  4720 net.cpp:122] Setting up penlu18
I1007 10:06:33.588919  4720 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 10:06:33.588922  4720 net.cpp:137] Memory required for data: 532071600
I1007 10:06:33.588927  4720 layer_factory.hpp:77] Creating layer Convolution20
I1007 10:06:33.588933  4720 net.cpp:84] Creating Layer Convolution20
I1007 10:06:33.588937  4720 net.cpp:406] Convolution20 <- Convolution19
I1007 10:06:33.588940  4720 net.cpp:380] Convolution20 -> Convolution20
I1007 10:06:33.589728  4720 net.cpp:122] Setting up Convolution20
I1007 10:06:33.589736  4720 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 10:06:33.589738  4720 net.cpp:137] Memory required for data: 535348400
I1007 10:06:33.589743  4720 layer_factory.hpp:77] Creating layer BatchNorm20
I1007 10:06:33.589748  4720 net.cpp:84] Creating Layer BatchNorm20
I1007 10:06:33.589751  4720 net.cpp:406] BatchNorm20 <- Convolution20
I1007 10:06:33.589754  4720 net.cpp:367] BatchNorm20 -> Convolution20 (in-place)
I1007 10:06:33.589905  4720 net.cpp:122] Setting up BatchNorm20
I1007 10:06:33.589910  4720 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 10:06:33.589912  4720 net.cpp:137] Memory required for data: 538625200
I1007 10:06:33.589916  4720 layer_factory.hpp:77] Creating layer Scale20
I1007 10:06:33.589921  4720 net.cpp:84] Creating Layer Scale20
I1007 10:06:33.589925  4720 net.cpp:406] Scale20 <- Convolution20
I1007 10:06:33.589936  4720 net.cpp:367] Scale20 -> Convolution20 (in-place)
I1007 10:06:33.589968  4720 layer_factory.hpp:77] Creating layer Scale20
I1007 10:06:33.590055  4720 net.cpp:122] Setting up Scale20
I1007 10:06:33.590059  4720 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 10:06:33.590061  4720 net.cpp:137] Memory required for data: 541902000
I1007 10:06:33.590065  4720 layer_factory.hpp:77] Creating layer Eltwise9
I1007 10:06:33.590070  4720 net.cpp:84] Creating Layer Eltwise9
I1007 10:06:33.590073  4720 net.cpp:406] Eltwise9 <- Eltwise8_penlu17_0_split_1
I1007 10:06:33.590076  4720 net.cpp:406] Eltwise9 <- Convolution20
I1007 10:06:33.590080  4720 net.cpp:380] Eltwise9 -> Eltwise9
I1007 10:06:33.590095  4720 net.cpp:122] Setting up Eltwise9
I1007 10:06:33.590098  4720 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 10:06:33.590101  4720 net.cpp:137] Memory required for data: 545178800
I1007 10:06:33.590103  4720 layer_factory.hpp:77] Creating layer penlu19
I1007 10:06:33.590107  4720 net.cpp:84] Creating Layer penlu19
I1007 10:06:33.590109  4720 net.cpp:406] penlu19 <- Eltwise9
I1007 10:06:33.590114  4720 net.cpp:367] penlu19 -> Eltwise9 (in-place)
I1007 10:06:33.590240  4720 net.cpp:122] Setting up penlu19
I1007 10:06:33.590245  4720 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 10:06:33.590246  4720 net.cpp:137] Memory required for data: 548455600
I1007 10:06:33.590251  4720 layer_factory.hpp:77] Creating layer Eltwise9_penlu19_0_split
I1007 10:06:33.590255  4720 net.cpp:84] Creating Layer Eltwise9_penlu19_0_split
I1007 10:06:33.590257  4720 net.cpp:406] Eltwise9_penlu19_0_split <- Eltwise9
I1007 10:06:33.590260  4720 net.cpp:380] Eltwise9_penlu19_0_split -> Eltwise9_penlu19_0_split_0
I1007 10:06:33.590265  4720 net.cpp:380] Eltwise9_penlu19_0_split -> Eltwise9_penlu19_0_split_1
I1007 10:06:33.590291  4720 net.cpp:122] Setting up Eltwise9_penlu19_0_split
I1007 10:06:33.590296  4720 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 10:06:33.590298  4720 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 10:06:33.590301  4720 net.cpp:137] Memory required for data: 555009200
I1007 10:06:33.590302  4720 layer_factory.hpp:77] Creating layer Convolution21
I1007 10:06:33.590308  4720 net.cpp:84] Creating Layer Convolution21
I1007 10:06:33.590312  4720 net.cpp:406] Convolution21 <- Eltwise9_penlu19_0_split_0
I1007 10:06:33.590315  4720 net.cpp:380] Convolution21 -> Convolution21
I1007 10:06:33.591470  4720 net.cpp:122] Setting up Convolution21
I1007 10:06:33.591480  4720 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 10:06:33.591482  4720 net.cpp:137] Memory required for data: 558286000
I1007 10:06:33.591486  4720 layer_factory.hpp:77] Creating layer BatchNorm21
I1007 10:06:33.591490  4720 net.cpp:84] Creating Layer BatchNorm21
I1007 10:06:33.591493  4720 net.cpp:406] BatchNorm21 <- Convolution21
I1007 10:06:33.591498  4720 net.cpp:367] BatchNorm21 -> Convolution21 (in-place)
I1007 10:06:33.591648  4720 net.cpp:122] Setting up BatchNorm21
I1007 10:06:33.591653  4720 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 10:06:33.591655  4720 net.cpp:137] Memory required for data: 561562800
I1007 10:06:33.591660  4720 layer_factory.hpp:77] Creating layer Scale21
I1007 10:06:33.591665  4720 net.cpp:84] Creating Layer Scale21
I1007 10:06:33.591666  4720 net.cpp:406] Scale21 <- Convolution21
I1007 10:06:33.591670  4720 net.cpp:367] Scale21 -> Convolution21 (in-place)
I1007 10:06:33.591699  4720 layer_factory.hpp:77] Creating layer Scale21
I1007 10:06:33.591787  4720 net.cpp:122] Setting up Scale21
I1007 10:06:33.591792  4720 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 10:06:33.591794  4720 net.cpp:137] Memory required for data: 564839600
I1007 10:06:33.591799  4720 layer_factory.hpp:77] Creating layer penlu20
I1007 10:06:33.591804  4720 net.cpp:84] Creating Layer penlu20
I1007 10:06:33.591806  4720 net.cpp:406] penlu20 <- Convolution21
I1007 10:06:33.591810  4720 net.cpp:367] penlu20 -> Convolution21 (in-place)
I1007 10:06:33.591931  4720 net.cpp:122] Setting up penlu20
I1007 10:06:33.591943  4720 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 10:06:33.591945  4720 net.cpp:137] Memory required for data: 568116400
I1007 10:06:33.591950  4720 layer_factory.hpp:77] Creating layer Convolution22
I1007 10:06:33.591958  4720 net.cpp:84] Creating Layer Convolution22
I1007 10:06:33.591960  4720 net.cpp:406] Convolution22 <- Convolution21
I1007 10:06:33.591965  4720 net.cpp:380] Convolution22 -> Convolution22
I1007 10:06:33.593099  4720 net.cpp:122] Setting up Convolution22
I1007 10:06:33.593108  4720 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 10:06:33.593111  4720 net.cpp:137] Memory required for data: 571393200
I1007 10:06:33.593116  4720 layer_factory.hpp:77] Creating layer BatchNorm22
I1007 10:06:33.593122  4720 net.cpp:84] Creating Layer BatchNorm22
I1007 10:06:33.593124  4720 net.cpp:406] BatchNorm22 <- Convolution22
I1007 10:06:33.593127  4720 net.cpp:367] BatchNorm22 -> Convolution22 (in-place)
I1007 10:06:33.593278  4720 net.cpp:122] Setting up BatchNorm22
I1007 10:06:33.593283  4720 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 10:06:33.593286  4720 net.cpp:137] Memory required for data: 574670000
I1007 10:06:33.593291  4720 layer_factory.hpp:77] Creating layer Scale22
I1007 10:06:33.593294  4720 net.cpp:84] Creating Layer Scale22
I1007 10:06:33.593297  4720 net.cpp:406] Scale22 <- Convolution22
I1007 10:06:33.593302  4720 net.cpp:367] Scale22 -> Convolution22 (in-place)
I1007 10:06:33.593330  4720 layer_factory.hpp:77] Creating layer Scale22
I1007 10:06:33.593416  4720 net.cpp:122] Setting up Scale22
I1007 10:06:33.593421  4720 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 10:06:33.593423  4720 net.cpp:137] Memory required for data: 577946800
I1007 10:06:33.593427  4720 layer_factory.hpp:77] Creating layer Eltwise10
I1007 10:06:33.593431  4720 net.cpp:84] Creating Layer Eltwise10
I1007 10:06:33.593433  4720 net.cpp:406] Eltwise10 <- Eltwise9_penlu19_0_split_1
I1007 10:06:33.593436  4720 net.cpp:406] Eltwise10 <- Convolution22
I1007 10:06:33.593441  4720 net.cpp:380] Eltwise10 -> Eltwise10
I1007 10:06:33.593454  4720 net.cpp:122] Setting up Eltwise10
I1007 10:06:33.593458  4720 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 10:06:33.593461  4720 net.cpp:137] Memory required for data: 581223600
I1007 10:06:33.593463  4720 layer_factory.hpp:77] Creating layer penlu21
I1007 10:06:33.593468  4720 net.cpp:84] Creating Layer penlu21
I1007 10:06:33.593472  4720 net.cpp:406] penlu21 <- Eltwise10
I1007 10:06:33.593474  4720 net.cpp:367] penlu21 -> Eltwise10 (in-place)
I1007 10:06:33.593600  4720 net.cpp:122] Setting up penlu21
I1007 10:06:33.593605  4720 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 10:06:33.593607  4720 net.cpp:137] Memory required for data: 584500400
I1007 10:06:33.593611  4720 layer_factory.hpp:77] Creating layer Eltwise10_penlu21_0_split
I1007 10:06:33.593616  4720 net.cpp:84] Creating Layer Eltwise10_penlu21_0_split
I1007 10:06:33.593618  4720 net.cpp:406] Eltwise10_penlu21_0_split <- Eltwise10
I1007 10:06:33.593621  4720 net.cpp:380] Eltwise10_penlu21_0_split -> Eltwise10_penlu21_0_split_0
I1007 10:06:33.593626  4720 net.cpp:380] Eltwise10_penlu21_0_split -> Eltwise10_penlu21_0_split_1
I1007 10:06:33.593652  4720 net.cpp:122] Setting up Eltwise10_penlu21_0_split
I1007 10:06:33.593657  4720 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 10:06:33.593659  4720 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 10:06:33.593662  4720 net.cpp:137] Memory required for data: 591054000
I1007 10:06:33.593663  4720 layer_factory.hpp:77] Creating layer Convolution23
I1007 10:06:33.593668  4720 net.cpp:84] Creating Layer Convolution23
I1007 10:06:33.593672  4720 net.cpp:406] Convolution23 <- Eltwise10_penlu21_0_split_0
I1007 10:06:33.593675  4720 net.cpp:380] Convolution23 -> Convolution23
I1007 10:06:33.594667  4720 net.cpp:122] Setting up Convolution23
I1007 10:06:33.594676  4720 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 10:06:33.594678  4720 net.cpp:137] Memory required for data: 592692400
I1007 10:06:33.594683  4720 layer_factory.hpp:77] Creating layer BatchNorm23
I1007 10:06:33.594696  4720 net.cpp:84] Creating Layer BatchNorm23
I1007 10:06:33.594699  4720 net.cpp:406] BatchNorm23 <- Convolution23
I1007 10:06:33.594702  4720 net.cpp:367] BatchNorm23 -> Convolution23 (in-place)
I1007 10:06:33.594862  4720 net.cpp:122] Setting up BatchNorm23
I1007 10:06:33.594867  4720 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 10:06:33.594871  4720 net.cpp:137] Memory required for data: 594330800
I1007 10:06:33.594876  4720 layer_factory.hpp:77] Creating layer Scale23
I1007 10:06:33.594878  4720 net.cpp:84] Creating Layer Scale23
I1007 10:06:33.594882  4720 net.cpp:406] Scale23 <- Convolution23
I1007 10:06:33.594884  4720 net.cpp:367] Scale23 -> Convolution23 (in-place)
I1007 10:06:33.594918  4720 layer_factory.hpp:77] Creating layer Scale23
I1007 10:06:33.595006  4720 net.cpp:122] Setting up Scale23
I1007 10:06:33.595012  4720 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 10:06:33.595015  4720 net.cpp:137] Memory required for data: 595969200
I1007 10:06:33.595018  4720 layer_factory.hpp:77] Creating layer Convolution24
I1007 10:06:33.595024  4720 net.cpp:84] Creating Layer Convolution24
I1007 10:06:33.595027  4720 net.cpp:406] Convolution24 <- Eltwise10_penlu21_0_split_1
I1007 10:06:33.595031  4720 net.cpp:380] Convolution24 -> Convolution24
I1007 10:06:33.596400  4720 net.cpp:122] Setting up Convolution24
I1007 10:06:33.596410  4720 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 10:06:33.596413  4720 net.cpp:137] Memory required for data: 597607600
I1007 10:06:33.596418  4720 layer_factory.hpp:77] Creating layer BatchNorm24
I1007 10:06:33.596422  4720 net.cpp:84] Creating Layer BatchNorm24
I1007 10:06:33.596426  4720 net.cpp:406] BatchNorm24 <- Convolution24
I1007 10:06:33.596431  4720 net.cpp:367] BatchNorm24 -> Convolution24 (in-place)
I1007 10:06:33.596588  4720 net.cpp:122] Setting up BatchNorm24
I1007 10:06:33.596592  4720 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 10:06:33.596596  4720 net.cpp:137] Memory required for data: 599246000
I1007 10:06:33.596599  4720 layer_factory.hpp:77] Creating layer Scale24
I1007 10:06:33.596603  4720 net.cpp:84] Creating Layer Scale24
I1007 10:06:33.596606  4720 net.cpp:406] Scale24 <- Convolution24
I1007 10:06:33.596611  4720 net.cpp:367] Scale24 -> Convolution24 (in-place)
I1007 10:06:33.596640  4720 layer_factory.hpp:77] Creating layer Scale24
I1007 10:06:33.596729  4720 net.cpp:122] Setting up Scale24
I1007 10:06:33.596732  4720 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 10:06:33.596735  4720 net.cpp:137] Memory required for data: 600884400
I1007 10:06:33.596738  4720 layer_factory.hpp:77] Creating layer penlu22
I1007 10:06:33.596745  4720 net.cpp:84] Creating Layer penlu22
I1007 10:06:33.596746  4720 net.cpp:406] penlu22 <- Convolution24
I1007 10:06:33.596750  4720 net.cpp:367] penlu22 -> Convolution24 (in-place)
I1007 10:06:33.596874  4720 net.cpp:122] Setting up penlu22
I1007 10:06:33.596879  4720 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 10:06:33.596880  4720 net.cpp:137] Memory required for data: 602522800
I1007 10:06:33.596885  4720 layer_factory.hpp:77] Creating layer Convolution25
I1007 10:06:33.596894  4720 net.cpp:84] Creating Layer Convolution25
I1007 10:06:33.596896  4720 net.cpp:406] Convolution25 <- Convolution24
I1007 10:06:33.596901  4720 net.cpp:380] Convolution25 -> Convolution25
I1007 10:06:33.598680  4720 net.cpp:122] Setting up Convolution25
I1007 10:06:33.598690  4720 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 10:06:33.598692  4720 net.cpp:137] Memory required for data: 604161200
I1007 10:06:33.598697  4720 layer_factory.hpp:77] Creating layer BatchNorm25
I1007 10:06:33.598702  4720 net.cpp:84] Creating Layer BatchNorm25
I1007 10:06:33.598706  4720 net.cpp:406] BatchNorm25 <- Convolution25
I1007 10:06:33.598709  4720 net.cpp:367] BatchNorm25 -> Convolution25 (in-place)
I1007 10:06:33.598865  4720 net.cpp:122] Setting up BatchNorm25
I1007 10:06:33.598870  4720 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 10:06:33.598871  4720 net.cpp:137] Memory required for data: 605799600
I1007 10:06:33.598883  4720 layer_factory.hpp:77] Creating layer Scale25
I1007 10:06:33.598888  4720 net.cpp:84] Creating Layer Scale25
I1007 10:06:33.598891  4720 net.cpp:406] Scale25 <- Convolution25
I1007 10:06:33.598894  4720 net.cpp:367] Scale25 -> Convolution25 (in-place)
I1007 10:06:33.617972  4720 layer_factory.hpp:77] Creating layer Scale25
I1007 10:06:33.618077  4720 net.cpp:122] Setting up Scale25
I1007 10:06:33.618083  4720 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 10:06:33.618084  4720 net.cpp:137] Memory required for data: 607438000
I1007 10:06:33.618089  4720 layer_factory.hpp:77] Creating layer Eltwise11
I1007 10:06:33.618093  4720 net.cpp:84] Creating Layer Eltwise11
I1007 10:06:33.618096  4720 net.cpp:406] Eltwise11 <- Convolution23
I1007 10:06:33.618100  4720 net.cpp:406] Eltwise11 <- Convolution25
I1007 10:06:33.618103  4720 net.cpp:380] Eltwise11 -> Eltwise11
I1007 10:06:33.618124  4720 net.cpp:122] Setting up Eltwise11
I1007 10:06:33.618129  4720 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 10:06:33.618130  4720 net.cpp:137] Memory required for data: 609076400
I1007 10:06:33.618132  4720 layer_factory.hpp:77] Creating layer penlu23
I1007 10:06:33.618139  4720 net.cpp:84] Creating Layer penlu23
I1007 10:06:33.618141  4720 net.cpp:406] penlu23 <- Eltwise11
I1007 10:06:33.618145  4720 net.cpp:367] penlu23 -> Eltwise11 (in-place)
I1007 10:06:33.618278  4720 net.cpp:122] Setting up penlu23
I1007 10:06:33.618283  4720 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 10:06:33.618285  4720 net.cpp:137] Memory required for data: 610714800
I1007 10:06:33.618290  4720 layer_factory.hpp:77] Creating layer Eltwise11_penlu23_0_split
I1007 10:06:33.618294  4720 net.cpp:84] Creating Layer Eltwise11_penlu23_0_split
I1007 10:06:33.618296  4720 net.cpp:406] Eltwise11_penlu23_0_split <- Eltwise11
I1007 10:06:33.618300  4720 net.cpp:380] Eltwise11_penlu23_0_split -> Eltwise11_penlu23_0_split_0
I1007 10:06:33.618304  4720 net.cpp:380] Eltwise11_penlu23_0_split -> Eltwise11_penlu23_0_split_1
I1007 10:06:33.618332  4720 net.cpp:122] Setting up Eltwise11_penlu23_0_split
I1007 10:06:33.618336  4720 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 10:06:33.618340  4720 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 10:06:33.618342  4720 net.cpp:137] Memory required for data: 613991600
I1007 10:06:33.618345  4720 layer_factory.hpp:77] Creating layer Convolution26
I1007 10:06:33.618350  4720 net.cpp:84] Creating Layer Convolution26
I1007 10:06:33.618353  4720 net.cpp:406] Convolution26 <- Eltwise11_penlu23_0_split_0
I1007 10:06:33.618358  4720 net.cpp:380] Convolution26 -> Convolution26
I1007 10:06:33.620303  4720 net.cpp:122] Setting up Convolution26
I1007 10:06:33.620314  4720 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 10:06:33.620317  4720 net.cpp:137] Memory required for data: 615630000
I1007 10:06:33.620321  4720 layer_factory.hpp:77] Creating layer BatchNorm26
I1007 10:06:33.620327  4720 net.cpp:84] Creating Layer BatchNorm26
I1007 10:06:33.620331  4720 net.cpp:406] BatchNorm26 <- Convolution26
I1007 10:06:33.620334  4720 net.cpp:367] BatchNorm26 -> Convolution26 (in-place)
I1007 10:06:33.620492  4720 net.cpp:122] Setting up BatchNorm26
I1007 10:06:33.620497  4720 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 10:06:33.620499  4720 net.cpp:137] Memory required for data: 617268400
I1007 10:06:33.620504  4720 layer_factory.hpp:77] Creating layer Scale26
I1007 10:06:33.620508  4720 net.cpp:84] Creating Layer Scale26
I1007 10:06:33.620510  4720 net.cpp:406] Scale26 <- Convolution26
I1007 10:06:33.620517  4720 net.cpp:367] Scale26 -> Convolution26 (in-place)
I1007 10:06:33.620549  4720 layer_factory.hpp:77] Creating layer Scale26
I1007 10:06:33.620640  4720 net.cpp:122] Setting up Scale26
I1007 10:06:33.620643  4720 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 10:06:33.620646  4720 net.cpp:137] Memory required for data: 618906800
I1007 10:06:33.620651  4720 layer_factory.hpp:77] Creating layer penlu24
I1007 10:06:33.620656  4720 net.cpp:84] Creating Layer penlu24
I1007 10:06:33.620666  4720 net.cpp:406] penlu24 <- Convolution26
I1007 10:06:33.620671  4720 net.cpp:367] penlu24 -> Convolution26 (in-place)
I1007 10:06:33.620797  4720 net.cpp:122] Setting up penlu24
I1007 10:06:33.620801  4720 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 10:06:33.620805  4720 net.cpp:137] Memory required for data: 620545200
I1007 10:06:33.620808  4720 layer_factory.hpp:77] Creating layer Convolution27
I1007 10:06:33.620816  4720 net.cpp:84] Creating Layer Convolution27
I1007 10:06:33.620818  4720 net.cpp:406] Convolution27 <- Convolution26
I1007 10:06:33.620822  4720 net.cpp:380] Convolution27 -> Convolution27
I1007 10:06:33.622612  4720 net.cpp:122] Setting up Convolution27
I1007 10:06:33.622622  4720 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 10:06:33.622624  4720 net.cpp:137] Memory required for data: 622183600
I1007 10:06:33.622628  4720 layer_factory.hpp:77] Creating layer BatchNorm27
I1007 10:06:33.622643  4720 net.cpp:84] Creating Layer BatchNorm27
I1007 10:06:33.622647  4720 net.cpp:406] BatchNorm27 <- Convolution27
I1007 10:06:33.622650  4720 net.cpp:367] BatchNorm27 -> Convolution27 (in-place)
I1007 10:06:33.622809  4720 net.cpp:122] Setting up BatchNorm27
I1007 10:06:33.622814  4720 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 10:06:33.622817  4720 net.cpp:137] Memory required for data: 623822000
I1007 10:06:33.622841  4720 layer_factory.hpp:77] Creating layer Scale27
I1007 10:06:33.622846  4720 net.cpp:84] Creating Layer Scale27
I1007 10:06:33.622849  4720 net.cpp:406] Scale27 <- Convolution27
I1007 10:06:33.622853  4720 net.cpp:367] Scale27 -> Convolution27 (in-place)
I1007 10:06:33.622885  4720 layer_factory.hpp:77] Creating layer Scale27
I1007 10:06:33.622974  4720 net.cpp:122] Setting up Scale27
I1007 10:06:33.622979  4720 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 10:06:33.622982  4720 net.cpp:137] Memory required for data: 625460400
I1007 10:06:33.622985  4720 layer_factory.hpp:77] Creating layer Eltwise12
I1007 10:06:33.622990  4720 net.cpp:84] Creating Layer Eltwise12
I1007 10:06:33.622993  4720 net.cpp:406] Eltwise12 <- Eltwise11_penlu23_0_split_1
I1007 10:06:33.622997  4720 net.cpp:406] Eltwise12 <- Convolution27
I1007 10:06:33.623000  4720 net.cpp:380] Eltwise12 -> Eltwise12
I1007 10:06:33.623018  4720 net.cpp:122] Setting up Eltwise12
I1007 10:06:33.623023  4720 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 10:06:33.623024  4720 net.cpp:137] Memory required for data: 627098800
I1007 10:06:33.623026  4720 layer_factory.hpp:77] Creating layer penlu25
I1007 10:06:33.623031  4720 net.cpp:84] Creating Layer penlu25
I1007 10:06:33.623034  4720 net.cpp:406] penlu25 <- Eltwise12
I1007 10:06:33.623039  4720 net.cpp:367] penlu25 -> Eltwise12 (in-place)
I1007 10:06:33.623169  4720 net.cpp:122] Setting up penlu25
I1007 10:06:33.623174  4720 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 10:06:33.623178  4720 net.cpp:137] Memory required for data: 628737200
I1007 10:06:33.623181  4720 layer_factory.hpp:77] Creating layer Eltwise12_penlu25_0_split
I1007 10:06:33.623185  4720 net.cpp:84] Creating Layer Eltwise12_penlu25_0_split
I1007 10:06:33.623188  4720 net.cpp:406] Eltwise12_penlu25_0_split <- Eltwise12
I1007 10:06:33.623191  4720 net.cpp:380] Eltwise12_penlu25_0_split -> Eltwise12_penlu25_0_split_0
I1007 10:06:33.623195  4720 net.cpp:380] Eltwise12_penlu25_0_split -> Eltwise12_penlu25_0_split_1
I1007 10:06:33.623224  4720 net.cpp:122] Setting up Eltwise12_penlu25_0_split
I1007 10:06:33.623227  4720 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 10:06:33.623230  4720 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 10:06:33.623232  4720 net.cpp:137] Memory required for data: 632014000
I1007 10:06:33.623234  4720 layer_factory.hpp:77] Creating layer Convolution28
I1007 10:06:33.623241  4720 net.cpp:84] Creating Layer Convolution28
I1007 10:06:33.623245  4720 net.cpp:406] Convolution28 <- Eltwise12_penlu25_0_split_0
I1007 10:06:33.623248  4720 net.cpp:380] Convolution28 -> Convolution28
I1007 10:06:33.625356  4720 net.cpp:122] Setting up Convolution28
I1007 10:06:33.625373  4720 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 10:06:33.625376  4720 net.cpp:137] Memory required for data: 633652400
I1007 10:06:33.625381  4720 layer_factory.hpp:77] Creating layer BatchNorm28
I1007 10:06:33.625386  4720 net.cpp:84] Creating Layer BatchNorm28
I1007 10:06:33.625389  4720 net.cpp:406] BatchNorm28 <- Convolution28
I1007 10:06:33.625394  4720 net.cpp:367] BatchNorm28 -> Convolution28 (in-place)
I1007 10:06:33.625558  4720 net.cpp:122] Setting up BatchNorm28
I1007 10:06:33.625563  4720 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 10:06:33.625566  4720 net.cpp:137] Memory required for data: 635290800
I1007 10:06:33.625571  4720 layer_factory.hpp:77] Creating layer Scale28
I1007 10:06:33.625574  4720 net.cpp:84] Creating Layer Scale28
I1007 10:06:33.625576  4720 net.cpp:406] Scale28 <- Convolution28
I1007 10:06:33.625579  4720 net.cpp:367] Scale28 -> Convolution28 (in-place)
I1007 10:06:33.625612  4720 layer_factory.hpp:77] Creating layer Scale28
I1007 10:06:33.625701  4720 net.cpp:122] Setting up Scale28
I1007 10:06:33.625706  4720 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 10:06:33.625708  4720 net.cpp:137] Memory required for data: 636929200
I1007 10:06:33.625712  4720 layer_factory.hpp:77] Creating layer penlu26
I1007 10:06:33.625717  4720 net.cpp:84] Creating Layer penlu26
I1007 10:06:33.625720  4720 net.cpp:406] penlu26 <- Convolution28
I1007 10:06:33.625723  4720 net.cpp:367] penlu26 -> Convolution28 (in-place)
I1007 10:06:33.625851  4720 net.cpp:122] Setting up penlu26
I1007 10:06:33.625855  4720 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 10:06:33.625857  4720 net.cpp:137] Memory required for data: 638567600
I1007 10:06:33.625862  4720 layer_factory.hpp:77] Creating layer Convolution29
I1007 10:06:33.625869  4720 net.cpp:84] Creating Layer Convolution29
I1007 10:06:33.625872  4720 net.cpp:406] Convolution29 <- Convolution28
I1007 10:06:33.625876  4720 net.cpp:380] Convolution29 -> Convolution29
I1007 10:06:33.628197  4720 net.cpp:122] Setting up Convolution29
I1007 10:06:33.628207  4720 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 10:06:33.628211  4720 net.cpp:137] Memory required for data: 640206000
I1007 10:06:33.628216  4720 layer_factory.hpp:77] Creating layer BatchNorm29
I1007 10:06:33.628221  4720 net.cpp:84] Creating Layer BatchNorm29
I1007 10:06:33.628224  4720 net.cpp:406] BatchNorm29 <- Convolution29
I1007 10:06:33.628228  4720 net.cpp:367] BatchNorm29 -> Convolution29 (in-place)
I1007 10:06:33.628389  4720 net.cpp:122] Setting up BatchNorm29
I1007 10:06:33.628393  4720 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 10:06:33.628396  4720 net.cpp:137] Memory required for data: 641844400
I1007 10:06:33.628401  4720 layer_factory.hpp:77] Creating layer Scale29
I1007 10:06:33.628406  4720 net.cpp:84] Creating Layer Scale29
I1007 10:06:33.628408  4720 net.cpp:406] Scale29 <- Convolution29
I1007 10:06:33.628412  4720 net.cpp:367] Scale29 -> Convolution29 (in-place)
I1007 10:06:33.628443  4720 layer_factory.hpp:77] Creating layer Scale29
I1007 10:06:33.628536  4720 net.cpp:122] Setting up Scale29
I1007 10:06:33.628541  4720 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 10:06:33.628543  4720 net.cpp:137] Memory required for data: 643482800
I1007 10:06:33.628547  4720 layer_factory.hpp:77] Creating layer Eltwise13
I1007 10:06:33.628552  4720 net.cpp:84] Creating Layer Eltwise13
I1007 10:06:33.628556  4720 net.cpp:406] Eltwise13 <- Eltwise12_penlu25_0_split_1
I1007 10:06:33.628558  4720 net.cpp:406] Eltwise13 <- Convolution29
I1007 10:06:33.628561  4720 net.cpp:380] Eltwise13 -> Eltwise13
I1007 10:06:33.628581  4720 net.cpp:122] Setting up Eltwise13
I1007 10:06:33.628584  4720 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 10:06:33.628587  4720 net.cpp:137] Memory required for data: 645121200
I1007 10:06:33.628589  4720 layer_factory.hpp:77] Creating layer penlu27
I1007 10:06:33.628594  4720 net.cpp:84] Creating Layer penlu27
I1007 10:06:33.628597  4720 net.cpp:406] penlu27 <- Eltwise13
I1007 10:06:33.628600  4720 net.cpp:367] penlu27 -> Eltwise13 (in-place)
I1007 10:06:33.628737  4720 net.cpp:122] Setting up penlu27
I1007 10:06:33.628742  4720 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 10:06:33.628746  4720 net.cpp:137] Memory required for data: 646759600
I1007 10:06:33.628749  4720 layer_factory.hpp:77] Creating layer Eltwise13_penlu27_0_split
I1007 10:06:33.628753  4720 net.cpp:84] Creating Layer Eltwise13_penlu27_0_split
I1007 10:06:33.628756  4720 net.cpp:406] Eltwise13_penlu27_0_split <- Eltwise13
I1007 10:06:33.628759  4720 net.cpp:380] Eltwise13_penlu27_0_split -> Eltwise13_penlu27_0_split_0
I1007 10:06:33.628763  4720 net.cpp:380] Eltwise13_penlu27_0_split -> Eltwise13_penlu27_0_split_1
I1007 10:06:33.628790  4720 net.cpp:122] Setting up Eltwise13_penlu27_0_split
I1007 10:06:33.628794  4720 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 10:06:33.628798  4720 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 10:06:33.628799  4720 net.cpp:137] Memory required for data: 650036400
I1007 10:06:33.628801  4720 layer_factory.hpp:77] Creating layer Convolution30
I1007 10:06:33.628808  4720 net.cpp:84] Creating Layer Convolution30
I1007 10:06:33.628811  4720 net.cpp:406] Convolution30 <- Eltwise13_penlu27_0_split_0
I1007 10:06:33.628815  4720 net.cpp:380] Convolution30 -> Convolution30
I1007 10:06:33.630923  4720 net.cpp:122] Setting up Convolution30
I1007 10:06:33.630931  4720 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 10:06:33.630934  4720 net.cpp:137] Memory required for data: 651674800
I1007 10:06:33.630939  4720 layer_factory.hpp:77] Creating layer BatchNorm30
I1007 10:06:33.630944  4720 net.cpp:84] Creating Layer BatchNorm30
I1007 10:06:33.630947  4720 net.cpp:406] BatchNorm30 <- Convolution30
I1007 10:06:33.630951  4720 net.cpp:367] BatchNorm30 -> Convolution30 (in-place)
I1007 10:06:33.631117  4720 net.cpp:122] Setting up BatchNorm30
I1007 10:06:33.631121  4720 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 10:06:33.631124  4720 net.cpp:137] Memory required for data: 653313200
I1007 10:06:33.631129  4720 layer_factory.hpp:77] Creating layer Scale30
I1007 10:06:33.631132  4720 net.cpp:84] Creating Layer Scale30
I1007 10:06:33.631135  4720 net.cpp:406] Scale30 <- Convolution30
I1007 10:06:33.631139  4720 net.cpp:367] Scale30 -> Convolution30 (in-place)
I1007 10:06:33.631175  4720 layer_factory.hpp:77] Creating layer Scale30
I1007 10:06:33.631269  4720 net.cpp:122] Setting up Scale30
I1007 10:06:33.631273  4720 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 10:06:33.631275  4720 net.cpp:137] Memory required for data: 654951600
I1007 10:06:33.631279  4720 layer_factory.hpp:77] Creating layer penlu28
I1007 10:06:33.631284  4720 net.cpp:84] Creating Layer penlu28
I1007 10:06:33.631287  4720 net.cpp:406] penlu28 <- Convolution30
I1007 10:06:33.631291  4720 net.cpp:367] penlu28 -> Convolution30 (in-place)
I1007 10:06:33.631420  4720 net.cpp:122] Setting up penlu28
I1007 10:06:33.631424  4720 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 10:06:33.631427  4720 net.cpp:137] Memory required for data: 656590000
I1007 10:06:33.631431  4720 layer_factory.hpp:77] Creating layer Convolution31
I1007 10:06:33.631438  4720 net.cpp:84] Creating Layer Convolution31
I1007 10:06:33.631440  4720 net.cpp:406] Convolution31 <- Convolution30
I1007 10:06:33.631445  4720 net.cpp:380] Convolution31 -> Convolution31
I1007 10:06:33.633221  4720 net.cpp:122] Setting up Convolution31
I1007 10:06:33.633230  4720 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 10:06:33.633234  4720 net.cpp:137] Memory required for data: 658228400
I1007 10:06:33.633237  4720 layer_factory.hpp:77] Creating layer BatchNorm31
I1007 10:06:33.633244  4720 net.cpp:84] Creating Layer BatchNorm31
I1007 10:06:33.633246  4720 net.cpp:406] BatchNorm31 <- Convolution31
I1007 10:06:33.633250  4720 net.cpp:367] BatchNorm31 -> Convolution31 (in-place)
I1007 10:06:33.633411  4720 net.cpp:122] Setting up BatchNorm31
I1007 10:06:33.633416  4720 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 10:06:33.633419  4720 net.cpp:137] Memory required for data: 659866800
I1007 10:06:33.633424  4720 layer_factory.hpp:77] Creating layer Scale31
I1007 10:06:33.633435  4720 net.cpp:84] Creating Layer Scale31
I1007 10:06:33.648875  4720 net.cpp:406] Scale31 <- Convolution31
I1007 10:06:33.648885  4720 net.cpp:367] Scale31 -> Convolution31 (in-place)
I1007 10:06:33.648936  4720 layer_factory.hpp:77] Creating layer Scale31
I1007 10:06:33.649037  4720 net.cpp:122] Setting up Scale31
I1007 10:06:33.649044  4720 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 10:06:33.649046  4720 net.cpp:137] Memory required for data: 661505200
I1007 10:06:33.649051  4720 layer_factory.hpp:77] Creating layer Eltwise14
I1007 10:06:33.649055  4720 net.cpp:84] Creating Layer Eltwise14
I1007 10:06:33.649058  4720 net.cpp:406] Eltwise14 <- Eltwise13_penlu27_0_split_1
I1007 10:06:33.649061  4720 net.cpp:406] Eltwise14 <- Convolution31
I1007 10:06:33.649065  4720 net.cpp:380] Eltwise14 -> Eltwise14
I1007 10:06:33.649086  4720 net.cpp:122] Setting up Eltwise14
I1007 10:06:33.649091  4720 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 10:06:33.649092  4720 net.cpp:137] Memory required for data: 663143600
I1007 10:06:33.649094  4720 layer_factory.hpp:77] Creating layer penlu29
I1007 10:06:33.649101  4720 net.cpp:84] Creating Layer penlu29
I1007 10:06:33.649103  4720 net.cpp:406] penlu29 <- Eltwise14
I1007 10:06:33.649107  4720 net.cpp:367] penlu29 -> Eltwise14 (in-place)
I1007 10:06:33.649242  4720 net.cpp:122] Setting up penlu29
I1007 10:06:33.649247  4720 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 10:06:33.649250  4720 net.cpp:137] Memory required for data: 664782000
I1007 10:06:33.649255  4720 layer_factory.hpp:77] Creating layer Eltwise14_penlu29_0_split
I1007 10:06:33.649260  4720 net.cpp:84] Creating Layer Eltwise14_penlu29_0_split
I1007 10:06:33.649262  4720 net.cpp:406] Eltwise14_penlu29_0_split <- Eltwise14
I1007 10:06:33.649266  4720 net.cpp:380] Eltwise14_penlu29_0_split -> Eltwise14_penlu29_0_split_0
I1007 10:06:33.649271  4720 net.cpp:380] Eltwise14_penlu29_0_split -> Eltwise14_penlu29_0_split_1
I1007 10:06:33.649299  4720 net.cpp:122] Setting up Eltwise14_penlu29_0_split
I1007 10:06:33.649303  4720 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 10:06:33.649307  4720 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 10:06:33.649308  4720 net.cpp:137] Memory required for data: 668058800
I1007 10:06:33.649310  4720 layer_factory.hpp:77] Creating layer Convolution32
I1007 10:06:33.649317  4720 net.cpp:84] Creating Layer Convolution32
I1007 10:06:33.649320  4720 net.cpp:406] Convolution32 <- Eltwise14_penlu29_0_split_0
I1007 10:06:33.649325  4720 net.cpp:380] Convolution32 -> Convolution32
I1007 10:06:33.651849  4720 net.cpp:122] Setting up Convolution32
I1007 10:06:33.651859  4720 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 10:06:33.651861  4720 net.cpp:137] Memory required for data: 669697200
I1007 10:06:33.651865  4720 layer_factory.hpp:77] Creating layer BatchNorm32
I1007 10:06:33.651871  4720 net.cpp:84] Creating Layer BatchNorm32
I1007 10:06:33.651875  4720 net.cpp:406] BatchNorm32 <- Convolution32
I1007 10:06:33.651878  4720 net.cpp:367] BatchNorm32 -> Convolution32 (in-place)
I1007 10:06:33.652040  4720 net.cpp:122] Setting up BatchNorm32
I1007 10:06:33.652045  4720 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 10:06:33.652047  4720 net.cpp:137] Memory required for data: 671335600
I1007 10:06:33.652052  4720 layer_factory.hpp:77] Creating layer Scale32
I1007 10:06:33.652058  4720 net.cpp:84] Creating Layer Scale32
I1007 10:06:33.652061  4720 net.cpp:406] Scale32 <- Convolution32
I1007 10:06:33.652065  4720 net.cpp:367] Scale32 -> Convolution32 (in-place)
I1007 10:06:33.652097  4720 layer_factory.hpp:77] Creating layer Scale32
I1007 10:06:33.652187  4720 net.cpp:122] Setting up Scale32
I1007 10:06:33.652191  4720 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 10:06:33.652194  4720 net.cpp:137] Memory required for data: 672974000
I1007 10:06:33.652197  4720 layer_factory.hpp:77] Creating layer penlu30
I1007 10:06:33.652204  4720 net.cpp:84] Creating Layer penlu30
I1007 10:06:33.652206  4720 net.cpp:406] penlu30 <- Convolution32
I1007 10:06:33.652217  4720 net.cpp:367] penlu30 -> Convolution32 (in-place)
I1007 10:06:33.652345  4720 net.cpp:122] Setting up penlu30
I1007 10:06:33.652350  4720 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 10:06:33.652353  4720 net.cpp:137] Memory required for data: 674612400
I1007 10:06:33.652356  4720 layer_factory.hpp:77] Creating layer Convolution33
I1007 10:06:33.652364  4720 net.cpp:84] Creating Layer Convolution33
I1007 10:06:33.652366  4720 net.cpp:406] Convolution33 <- Convolution32
I1007 10:06:33.652370  4720 net.cpp:380] Convolution33 -> Convolution33
I1007 10:06:33.654114  4720 net.cpp:122] Setting up Convolution33
I1007 10:06:33.654124  4720 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 10:06:33.654126  4720 net.cpp:137] Memory required for data: 676250800
I1007 10:06:33.654131  4720 layer_factory.hpp:77] Creating layer BatchNorm33
I1007 10:06:33.654136  4720 net.cpp:84] Creating Layer BatchNorm33
I1007 10:06:33.654139  4720 net.cpp:406] BatchNorm33 <- Convolution33
I1007 10:06:33.654144  4720 net.cpp:367] BatchNorm33 -> Convolution33 (in-place)
I1007 10:06:33.654300  4720 net.cpp:122] Setting up BatchNorm33
I1007 10:06:33.654304  4720 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 10:06:33.654306  4720 net.cpp:137] Memory required for data: 677889200
I1007 10:06:33.654311  4720 layer_factory.hpp:77] Creating layer Scale33
I1007 10:06:33.654315  4720 net.cpp:84] Creating Layer Scale33
I1007 10:06:33.654319  4720 net.cpp:406] Scale33 <- Convolution33
I1007 10:06:33.654322  4720 net.cpp:367] Scale33 -> Convolution33 (in-place)
I1007 10:06:33.654352  4720 layer_factory.hpp:77] Creating layer Scale33
I1007 10:06:33.654443  4720 net.cpp:122] Setting up Scale33
I1007 10:06:33.654446  4720 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 10:06:33.654448  4720 net.cpp:137] Memory required for data: 679527600
I1007 10:06:33.654453  4720 layer_factory.hpp:77] Creating layer Eltwise15
I1007 10:06:33.654456  4720 net.cpp:84] Creating Layer Eltwise15
I1007 10:06:33.654459  4720 net.cpp:406] Eltwise15 <- Eltwise14_penlu29_0_split_1
I1007 10:06:33.654464  4720 net.cpp:406] Eltwise15 <- Convolution33
I1007 10:06:33.654466  4720 net.cpp:380] Eltwise15 -> Eltwise15
I1007 10:06:33.654486  4720 net.cpp:122] Setting up Eltwise15
I1007 10:06:33.654489  4720 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 10:06:33.654491  4720 net.cpp:137] Memory required for data: 681166000
I1007 10:06:33.654495  4720 layer_factory.hpp:77] Creating layer penlu31
I1007 10:06:33.654500  4720 net.cpp:84] Creating Layer penlu31
I1007 10:06:33.654502  4720 net.cpp:406] penlu31 <- Eltwise15
I1007 10:06:33.654505  4720 net.cpp:367] penlu31 -> Eltwise15 (in-place)
I1007 10:06:33.654631  4720 net.cpp:122] Setting up penlu31
I1007 10:06:33.654636  4720 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 10:06:33.654639  4720 net.cpp:137] Memory required for data: 682804400
I1007 10:06:33.654644  4720 layer_factory.hpp:77] Creating layer Pooling1
I1007 10:06:33.654647  4720 net.cpp:84] Creating Layer Pooling1
I1007 10:06:33.654650  4720 net.cpp:406] Pooling1 <- Eltwise15
I1007 10:06:33.654654  4720 net.cpp:380] Pooling1 -> Pooling1
I1007 10:06:33.654798  4720 net.cpp:122] Setting up Pooling1
I1007 10:06:33.654804  4720 net.cpp:129] Top shape: 100 64 1 1 (6400)
I1007 10:06:33.654808  4720 net.cpp:137] Memory required for data: 682830000
I1007 10:06:33.654809  4720 layer_factory.hpp:77] Creating layer InnerProduct1
I1007 10:06:33.654815  4720 net.cpp:84] Creating Layer InnerProduct1
I1007 10:06:33.654819  4720 net.cpp:406] InnerProduct1 <- Pooling1
I1007 10:06:33.654824  4720 net.cpp:380] InnerProduct1 -> InnerProduct1
I1007 10:06:33.654932  4720 net.cpp:122] Setting up InnerProduct1
I1007 10:06:33.654937  4720 net.cpp:129] Top shape: 100 10 (1000)
I1007 10:06:33.654939  4720 net.cpp:137] Memory required for data: 682834000
I1007 10:06:33.654943  4720 layer_factory.hpp:77] Creating layer InnerProduct1_InnerProduct1_0_split
I1007 10:06:33.654947  4720 net.cpp:84] Creating Layer InnerProduct1_InnerProduct1_0_split
I1007 10:06:33.654955  4720 net.cpp:406] InnerProduct1_InnerProduct1_0_split <- InnerProduct1
I1007 10:06:33.654960  4720 net.cpp:380] InnerProduct1_InnerProduct1_0_split -> InnerProduct1_InnerProduct1_0_split_0
I1007 10:06:33.654964  4720 net.cpp:380] InnerProduct1_InnerProduct1_0_split -> InnerProduct1_InnerProduct1_0_split_1
I1007 10:06:33.654995  4720 net.cpp:122] Setting up InnerProduct1_InnerProduct1_0_split
I1007 10:06:33.654999  4720 net.cpp:129] Top shape: 100 10 (1000)
I1007 10:06:33.655001  4720 net.cpp:129] Top shape: 100 10 (1000)
I1007 10:06:33.655004  4720 net.cpp:137] Memory required for data: 682842000
I1007 10:06:33.655006  4720 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I1007 10:06:33.655009  4720 net.cpp:84] Creating Layer SoftmaxWithLoss1
I1007 10:06:33.655012  4720 net.cpp:406] SoftmaxWithLoss1 <- InnerProduct1_InnerProduct1_0_split_0
I1007 10:06:33.655015  4720 net.cpp:406] SoftmaxWithLoss1 <- Data2_Data1_1_split_0
I1007 10:06:33.655019  4720 net.cpp:380] SoftmaxWithLoss1 -> SoftmaxWithLoss1
I1007 10:06:33.655025  4720 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I1007 10:06:33.655560  4720 net.cpp:122] Setting up SoftmaxWithLoss1
I1007 10:06:33.655567  4720 net.cpp:129] Top shape: (1)
I1007 10:06:33.655570  4720 net.cpp:132]     with loss weight 1
I1007 10:06:33.655577  4720 net.cpp:137] Memory required for data: 682842004
I1007 10:06:33.655580  4720 layer_factory.hpp:77] Creating layer Accuracy1
I1007 10:06:33.655586  4720 net.cpp:84] Creating Layer Accuracy1
I1007 10:06:33.655588  4720 net.cpp:406] Accuracy1 <- InnerProduct1_InnerProduct1_0_split_1
I1007 10:06:33.655591  4720 net.cpp:406] Accuracy1 <- Data2_Data1_1_split_1
I1007 10:06:33.655596  4720 net.cpp:380] Accuracy1 -> Accuracy1
I1007 10:06:33.655601  4720 net.cpp:122] Setting up Accuracy1
I1007 10:06:33.655606  4720 net.cpp:129] Top shape: (1)
I1007 10:06:33.655607  4720 net.cpp:137] Memory required for data: 682842008
I1007 10:06:33.655609  4720 net.cpp:200] Accuracy1 does not need backward computation.
I1007 10:06:33.655611  4720 net.cpp:198] SoftmaxWithLoss1 needs backward computation.
I1007 10:06:33.655614  4720 net.cpp:198] InnerProduct1_InnerProduct1_0_split needs backward computation.
I1007 10:06:33.655616  4720 net.cpp:198] InnerProduct1 needs backward computation.
I1007 10:06:33.655619  4720 net.cpp:198] Pooling1 needs backward computation.
I1007 10:06:33.655622  4720 net.cpp:198] penlu31 needs backward computation.
I1007 10:06:33.655623  4720 net.cpp:198] Eltwise15 needs backward computation.
I1007 10:06:33.655625  4720 net.cpp:198] Scale33 needs backward computation.
I1007 10:06:33.655627  4720 net.cpp:198] BatchNorm33 needs backward computation.
I1007 10:06:33.655629  4720 net.cpp:198] Convolution33 needs backward computation.
I1007 10:06:33.655632  4720 net.cpp:198] penlu30 needs backward computation.
I1007 10:06:33.655634  4720 net.cpp:198] Scale32 needs backward computation.
I1007 10:06:33.655637  4720 net.cpp:198] BatchNorm32 needs backward computation.
I1007 10:06:33.655638  4720 net.cpp:198] Convolution32 needs backward computation.
I1007 10:06:33.655640  4720 net.cpp:198] Eltwise14_penlu29_0_split needs backward computation.
I1007 10:06:33.655642  4720 net.cpp:198] penlu29 needs backward computation.
I1007 10:06:33.655644  4720 net.cpp:198] Eltwise14 needs backward computation.
I1007 10:06:33.655647  4720 net.cpp:198] Scale31 needs backward computation.
I1007 10:06:33.655649  4720 net.cpp:198] BatchNorm31 needs backward computation.
I1007 10:06:33.655652  4720 net.cpp:198] Convolution31 needs backward computation.
I1007 10:06:33.655653  4720 net.cpp:198] penlu28 needs backward computation.
I1007 10:06:33.655655  4720 net.cpp:198] Scale30 needs backward computation.
I1007 10:06:33.655658  4720 net.cpp:198] BatchNorm30 needs backward computation.
I1007 10:06:33.655659  4720 net.cpp:198] Convolution30 needs backward computation.
I1007 10:06:33.655663  4720 net.cpp:198] Eltwise13_penlu27_0_split needs backward computation.
I1007 10:06:33.655664  4720 net.cpp:198] penlu27 needs backward computation.
I1007 10:06:33.655673  4720 net.cpp:198] Eltwise13 needs backward computation.
I1007 10:06:33.655678  4720 net.cpp:198] Scale29 needs backward computation.
I1007 10:06:33.655679  4720 net.cpp:198] BatchNorm29 needs backward computation.
I1007 10:06:33.655683  4720 net.cpp:198] Convolution29 needs backward computation.
I1007 10:06:33.655684  4720 net.cpp:198] penlu26 needs backward computation.
I1007 10:06:33.655686  4720 net.cpp:198] Scale28 needs backward computation.
I1007 10:06:33.655689  4720 net.cpp:198] BatchNorm28 needs backward computation.
I1007 10:06:33.655691  4720 net.cpp:198] Convolution28 needs backward computation.
I1007 10:06:33.655694  4720 net.cpp:198] Eltwise12_penlu25_0_split needs backward computation.
I1007 10:06:33.655695  4720 net.cpp:198] penlu25 needs backward computation.
I1007 10:06:33.655699  4720 net.cpp:198] Eltwise12 needs backward computation.
I1007 10:06:33.655700  4720 net.cpp:198] Scale27 needs backward computation.
I1007 10:06:33.655704  4720 net.cpp:198] BatchNorm27 needs backward computation.
I1007 10:06:33.655705  4720 net.cpp:198] Convolution27 needs backward computation.
I1007 10:06:33.655707  4720 net.cpp:198] penlu24 needs backward computation.
I1007 10:06:33.655710  4720 net.cpp:198] Scale26 needs backward computation.
I1007 10:06:33.655712  4720 net.cpp:198] BatchNorm26 needs backward computation.
I1007 10:06:33.655714  4720 net.cpp:198] Convolution26 needs backward computation.
I1007 10:06:33.655716  4720 net.cpp:198] Eltwise11_penlu23_0_split needs backward computation.
I1007 10:06:33.655719  4720 net.cpp:198] penlu23 needs backward computation.
I1007 10:06:33.655721  4720 net.cpp:198] Eltwise11 needs backward computation.
I1007 10:06:33.655724  4720 net.cpp:198] Scale25 needs backward computation.
I1007 10:06:33.655726  4720 net.cpp:198] BatchNorm25 needs backward computation.
I1007 10:06:33.655728  4720 net.cpp:198] Convolution25 needs backward computation.
I1007 10:06:33.655730  4720 net.cpp:198] penlu22 needs backward computation.
I1007 10:06:33.655733  4720 net.cpp:198] Scale24 needs backward computation.
I1007 10:06:33.655735  4720 net.cpp:198] BatchNorm24 needs backward computation.
I1007 10:06:33.655737  4720 net.cpp:198] Convolution24 needs backward computation.
I1007 10:06:33.655740  4720 net.cpp:198] Scale23 needs backward computation.
I1007 10:06:33.655742  4720 net.cpp:198] BatchNorm23 needs backward computation.
I1007 10:06:33.655745  4720 net.cpp:198] Convolution23 needs backward computation.
I1007 10:06:33.655746  4720 net.cpp:198] Eltwise10_penlu21_0_split needs backward computation.
I1007 10:06:33.655750  4720 net.cpp:198] penlu21 needs backward computation.
I1007 10:06:33.655751  4720 net.cpp:198] Eltwise10 needs backward computation.
I1007 10:06:33.655755  4720 net.cpp:198] Scale22 needs backward computation.
I1007 10:06:33.655756  4720 net.cpp:198] BatchNorm22 needs backward computation.
I1007 10:06:33.655758  4720 net.cpp:198] Convolution22 needs backward computation.
I1007 10:06:33.655761  4720 net.cpp:198] penlu20 needs backward computation.
I1007 10:06:33.655763  4720 net.cpp:198] Scale21 needs backward computation.
I1007 10:06:33.655766  4720 net.cpp:198] BatchNorm21 needs backward computation.
I1007 10:06:33.655767  4720 net.cpp:198] Convolution21 needs backward computation.
I1007 10:06:33.655769  4720 net.cpp:198] Eltwise9_penlu19_0_split needs backward computation.
I1007 10:06:33.655772  4720 net.cpp:198] penlu19 needs backward computation.
I1007 10:06:33.655774  4720 net.cpp:198] Eltwise9 needs backward computation.
I1007 10:06:33.655777  4720 net.cpp:198] Scale20 needs backward computation.
I1007 10:06:33.655779  4720 net.cpp:198] BatchNorm20 needs backward computation.
I1007 10:06:33.655781  4720 net.cpp:198] Convolution20 needs backward computation.
I1007 10:06:33.655784  4720 net.cpp:198] penlu18 needs backward computation.
I1007 10:06:33.655786  4720 net.cpp:198] Scale19 needs backward computation.
I1007 10:06:33.655788  4720 net.cpp:198] BatchNorm19 needs backward computation.
I1007 10:06:33.655791  4720 net.cpp:198] Convolution19 needs backward computation.
I1007 10:06:33.679502  4720 net.cpp:198] Eltwise8_penlu17_0_split needs backward computation.
I1007 10:06:33.679509  4720 net.cpp:198] penlu17 needs backward computation.
I1007 10:06:33.679512  4720 net.cpp:198] Eltwise8 needs backward computation.
I1007 10:06:33.679515  4720 net.cpp:198] Scale18 needs backward computation.
I1007 10:06:33.679518  4720 net.cpp:198] BatchNorm18 needs backward computation.
I1007 10:06:33.679520  4720 net.cpp:198] Convolution18 needs backward computation.
I1007 10:06:33.679523  4720 net.cpp:198] penlu16 needs backward computation.
I1007 10:06:33.679527  4720 net.cpp:198] Scale17 needs backward computation.
I1007 10:06:33.679528  4720 net.cpp:198] BatchNorm17 needs backward computation.
I1007 10:06:33.679531  4720 net.cpp:198] Convolution17 needs backward computation.
I1007 10:06:33.679533  4720 net.cpp:198] Eltwise7_penlu15_0_split needs backward computation.
I1007 10:06:33.679536  4720 net.cpp:198] penlu15 needs backward computation.
I1007 10:06:33.679539  4720 net.cpp:198] Eltwise7 needs backward computation.
I1007 10:06:33.679543  4720 net.cpp:198] Scale16 needs backward computation.
I1007 10:06:33.679544  4720 net.cpp:198] BatchNorm16 needs backward computation.
I1007 10:06:33.679548  4720 net.cpp:198] Convolution16 needs backward computation.
I1007 10:06:33.679549  4720 net.cpp:198] penlu14 needs backward computation.
I1007 10:06:33.679553  4720 net.cpp:198] Scale15 needs backward computation.
I1007 10:06:33.679554  4720 net.cpp:198] BatchNorm15 needs backward computation.
I1007 10:06:33.679556  4720 net.cpp:198] Convolution15 needs backward computation.
I1007 10:06:33.679559  4720 net.cpp:198] Eltwise6_penlu13_0_split needs backward computation.
I1007 10:06:33.679563  4720 net.cpp:198] penlu13 needs backward computation.
I1007 10:06:33.679564  4720 net.cpp:198] Eltwise6 needs backward computation.
I1007 10:06:33.679567  4720 net.cpp:198] Scale14 needs backward computation.
I1007 10:06:33.679570  4720 net.cpp:198] BatchNorm14 needs backward computation.
I1007 10:06:33.679572  4720 net.cpp:198] Convolution14 needs backward computation.
I1007 10:06:33.679575  4720 net.cpp:198] penlu12 needs backward computation.
I1007 10:06:33.679577  4720 net.cpp:198] Scale13 needs backward computation.
I1007 10:06:33.679580  4720 net.cpp:198] BatchNorm13 needs backward computation.
I1007 10:06:33.679582  4720 net.cpp:198] Convolution13 needs backward computation.
I1007 10:06:33.679587  4720 net.cpp:198] Scale12 needs backward computation.
I1007 10:06:33.679590  4720 net.cpp:198] BatchNorm12 needs backward computation.
I1007 10:06:33.679592  4720 net.cpp:198] Convolution12 needs backward computation.
I1007 10:06:33.679595  4720 net.cpp:198] Eltwise5_penlu11_0_split needs backward computation.
I1007 10:06:33.679597  4720 net.cpp:198] penlu11 needs backward computation.
I1007 10:06:33.679600  4720 net.cpp:198] Eltwise5 needs backward computation.
I1007 10:06:33.679603  4720 net.cpp:198] Scale11 needs backward computation.
I1007 10:06:33.679605  4720 net.cpp:198] BatchNorm11 needs backward computation.
I1007 10:06:33.679608  4720 net.cpp:198] Convolution11 needs backward computation.
I1007 10:06:33.679610  4720 net.cpp:198] penlu10 needs backward computation.
I1007 10:06:33.679613  4720 net.cpp:198] Scale10 needs backward computation.
I1007 10:06:33.679615  4720 net.cpp:198] BatchNorm10 needs backward computation.
I1007 10:06:33.679617  4720 net.cpp:198] Convolution10 needs backward computation.
I1007 10:06:33.679620  4720 net.cpp:198] Eltwise4_penlu9_0_split needs backward computation.
I1007 10:06:33.679623  4720 net.cpp:198] penlu9 needs backward computation.
I1007 10:06:33.679625  4720 net.cpp:198] Eltwise4 needs backward computation.
I1007 10:06:33.679630  4720 net.cpp:198] Scale9 needs backward computation.
I1007 10:06:33.679631  4720 net.cpp:198] BatchNorm9 needs backward computation.
I1007 10:06:33.679633  4720 net.cpp:198] Convolution9 needs backward computation.
I1007 10:06:33.679636  4720 net.cpp:198] penlu8 needs backward computation.
I1007 10:06:33.679639  4720 net.cpp:198] Scale8 needs backward computation.
I1007 10:06:33.679649  4720 net.cpp:198] BatchNorm8 needs backward computation.
I1007 10:06:33.679651  4720 net.cpp:198] Convolution8 needs backward computation.
I1007 10:06:33.679654  4720 net.cpp:198] Eltwise3_penlu7_0_split needs backward computation.
I1007 10:06:33.679657  4720 net.cpp:198] penlu7 needs backward computation.
I1007 10:06:33.679659  4720 net.cpp:198] Eltwise3 needs backward computation.
I1007 10:06:33.679662  4720 net.cpp:198] Scale7 needs backward computation.
I1007 10:06:33.679666  4720 net.cpp:198] BatchNorm7 needs backward computation.
I1007 10:06:33.679667  4720 net.cpp:198] Convolution7 needs backward computation.
I1007 10:06:33.679671  4720 net.cpp:198] penlu6 needs backward computation.
I1007 10:06:33.679672  4720 net.cpp:198] Scale6 needs backward computation.
I1007 10:06:33.679674  4720 net.cpp:198] BatchNorm6 needs backward computation.
I1007 10:06:33.679677  4720 net.cpp:198] Convolution6 needs backward computation.
I1007 10:06:33.679679  4720 net.cpp:198] Eltwise2_penlu5_0_split needs backward computation.
I1007 10:06:33.679682  4720 net.cpp:198] penlu5 needs backward computation.
I1007 10:06:33.679684  4720 net.cpp:198] Eltwise2 needs backward computation.
I1007 10:06:33.679687  4720 net.cpp:198] Scale5 needs backward computation.
I1007 10:06:33.679690  4720 net.cpp:198] BatchNorm5 needs backward computation.
I1007 10:06:33.679692  4720 net.cpp:198] Convolution5 needs backward computation.
I1007 10:06:33.679695  4720 net.cpp:198] penlu4 needs backward computation.
I1007 10:06:33.679697  4720 net.cpp:198] Scale4 needs backward computation.
I1007 10:06:33.679699  4720 net.cpp:198] BatchNorm4 needs backward computation.
I1007 10:06:33.679702  4720 net.cpp:198] Convolution4 needs backward computation.
I1007 10:06:33.679705  4720 net.cpp:198] Eltwise1_penlu3_0_split needs backward computation.
I1007 10:06:33.679708  4720 net.cpp:198] penlu3 needs backward computation.
I1007 10:06:33.679710  4720 net.cpp:198] Eltwise1 needs backward computation.
I1007 10:06:33.679713  4720 net.cpp:198] Scale3 needs backward computation.
I1007 10:06:33.679716  4720 net.cpp:198] BatchNorm3 needs backward computation.
I1007 10:06:33.679718  4720 net.cpp:198] Convolution3 needs backward computation.
I1007 10:06:33.679721  4720 net.cpp:198] penlu2 needs backward computation.
I1007 10:06:33.679723  4720 net.cpp:198] Scale2 needs backward computation.
I1007 10:06:33.679726  4720 net.cpp:198] BatchNorm2 needs backward computation.
I1007 10:06:33.679728  4720 net.cpp:198] Convolution2 needs backward computation.
I1007 10:06:33.679731  4720 net.cpp:198] Convolution1_penlu1_0_split needs backward computation.
I1007 10:06:33.679734  4720 net.cpp:198] penlu1 needs backward computation.
I1007 10:06:33.679736  4720 net.cpp:198] Scale1 needs backward computation.
I1007 10:06:33.679739  4720 net.cpp:198] BatchNorm1 needs backward computation.
I1007 10:06:33.679741  4720 net.cpp:198] Convolution1 needs backward computation.
I1007 10:06:33.679744  4720 net.cpp:200] Data2_Data1_1_split does not need backward computation.
I1007 10:06:33.679749  4720 net.cpp:200] Data1 does not need backward computation.
I1007 10:06:33.679750  4720 net.cpp:242] This network produces output Accuracy1
I1007 10:06:33.679754  4720 net.cpp:242] This network produces output SoftmaxWithLoss1
I1007 10:06:33.679812  4720 net.cpp:255] Network initialization done.
I1007 10:06:33.680279  4720 solver.cpp:56] Solver scaffolding done.
I1007 10:06:33.689275  4720 caffe.cpp:248] Starting Optimization
I1007 10:06:33.689288  4720 solver.cpp:272] Solving resnet_cifar10
I1007 10:06:33.689291  4720 solver.cpp:273] Learning Rate Policy: multistep
I1007 10:06:33.692909  4720 solver.cpp:330] Iteration 0, Testing net (#0)
I1007 10:06:35.652164  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:06:35.731838  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.1
I1007 10:06:35.731865  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 87.3365 (* 1 = 87.3365 loss)
I1007 10:06:35.846181  4720 solver.cpp:218] Iteration 0 (-8.27814e-33 iter/s, 2.1568s/100 iters), loss = 2.30459
I1007 10:06:35.846225  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 2.30459 (* 1 = 2.30459 loss)
I1007 10:06:35.846240  4720 sgd_solver.cpp:105] Iteration 0, lr = 0.1
I1007 10:06:44.154018  4720 solver.cpp:218] Iteration 100 (12.037 iter/s, 8.30771s/100 iters), loss = 1.67239
I1007 10:06:44.154049  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.67239 (* 1 = 1.67239 loss)
I1007 10:06:44.154067  4720 sgd_solver.cpp:105] Iteration 100, lr = 0.1
I1007 10:06:52.455477  4720 solver.cpp:218] Iteration 200 (12.0462 iter/s, 8.30135s/100 iters), loss = 1.64695
I1007 10:06:52.455509  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.64695 (* 1 = 1.64695 loss)
I1007 10:06:52.455528  4720 sgd_solver.cpp:105] Iteration 200, lr = 0.1
I1007 10:07:00.767463  4720 solver.cpp:218] Iteration 300 (12.031 iter/s, 8.31187s/100 iters), loss = 1.17266
I1007 10:07:00.767496  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.17266 (* 1 = 1.17266 loss)
I1007 10:07:00.767514  4720 sgd_solver.cpp:105] Iteration 300, lr = 0.1
I1007 10:07:09.080562  4720 solver.cpp:218] Iteration 400 (12.0294 iter/s, 8.31299s/100 iters), loss = 1.01561
I1007 10:07:09.080703  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.01561 (* 1 = 1.01561 loss)
I1007 10:07:09.080714  4720 sgd_solver.cpp:105] Iteration 400, lr = 0.1
I1007 10:07:16.974002  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:07:17.307389  4720 solver.cpp:330] Iteration 500, Testing net (#0)
I1007 10:07:19.231287  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:07:19.311444  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.4191
I1007 10:07:19.311472  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 2.20572 (* 1 = 2.20572 loss)
I1007 10:07:19.394692  4720 solver.cpp:218] Iteration 500 (9.69566 iter/s, 10.3139s/100 iters), loss = 1.25048
I1007 10:07:19.394722  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.25048 (* 1 = 1.25048 loss)
I1007 10:07:19.394731  4720 sgd_solver.cpp:105] Iteration 500, lr = 0.1
I1007 10:07:27.720379  4720 solver.cpp:218] Iteration 600 (12.0112 iter/s, 8.32557s/100 iters), loss = 1.00089
I1007 10:07:27.720412  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.00089 (* 1 = 1.00089 loss)
I1007 10:07:27.720429  4720 sgd_solver.cpp:105] Iteration 600, lr = 0.1
I1007 10:07:36.031596  4720 solver.cpp:218] Iteration 700 (12.0321 iter/s, 8.3111s/100 iters), loss = 1.05995
I1007 10:07:36.031628  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.05995 (* 1 = 1.05995 loss)
I1007 10:07:36.031646  4720 sgd_solver.cpp:105] Iteration 700, lr = 0.1
I1007 10:07:44.348249  4720 solver.cpp:218] Iteration 800 (12.0242 iter/s, 8.31654s/100 iters), loss = 0.967103
I1007 10:07:44.348361  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.967103 (* 1 = 0.967103 loss)
I1007 10:07:44.348371  4720 sgd_solver.cpp:105] Iteration 800, lr = 0.1
I1007 10:07:52.661581  4720 solver.cpp:218] Iteration 900 (12.0291 iter/s, 8.31315s/100 iters), loss = 0.811024
I1007 10:07:52.661613  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.811024 (* 1 = 0.811024 loss)
I1007 10:07:52.661631  4720 sgd_solver.cpp:105] Iteration 900, lr = 0.1
I1007 10:08:00.638895  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:08:00.972461  4720 solver.cpp:330] Iteration 1000, Testing net (#0)
I1007 10:08:02.909145  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:08:02.989176  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.3296
I1007 10:08:02.989212  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 2.66506 (* 1 = 2.66506 loss)
I1007 10:08:03.072052  4720 solver.cpp:218] Iteration 1000 (9.60583 iter/s, 10.4103s/100 iters), loss = 0.975665
I1007 10:08:03.072077  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.975665 (* 1 = 0.975665 loss)
I1007 10:08:03.072084  4720 sgd_solver.cpp:105] Iteration 1000, lr = 0.1
I1007 10:08:11.486132  4720 solver.cpp:218] Iteration 1100 (11.885 iter/s, 8.41397s/100 iters), loss = 0.701597
I1007 10:08:11.486161  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.701597 (* 1 = 0.701597 loss)
I1007 10:08:11.486167  4720 sgd_solver.cpp:105] Iteration 1100, lr = 0.1
I1007 10:08:19.801720  4720 solver.cpp:218] Iteration 1200 (12.0258 iter/s, 8.31548s/100 iters), loss = 0.7235
I1007 10:08:19.801854  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.7235 (* 1 = 0.7235 loss)
I1007 10:08:19.801862  4720 sgd_solver.cpp:105] Iteration 1200, lr = 0.1
I1007 10:08:28.273247  4720 solver.cpp:218] Iteration 1300 (11.8045 iter/s, 8.47131s/100 iters), loss = 0.770438
I1007 10:08:28.273278  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.770438 (* 1 = 0.770438 loss)
I1007 10:08:28.273285  4720 sgd_solver.cpp:105] Iteration 1300, lr = 0.1
I1007 10:08:36.635100  4720 solver.cpp:218] Iteration 1400 (11.9592 iter/s, 8.36174s/100 iters), loss = 0.694442
I1007 10:08:36.635130  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.694442 (* 1 = 0.694442 loss)
I1007 10:08:36.635135  4720 sgd_solver.cpp:105] Iteration 1400, lr = 0.1
I1007 10:08:44.548336  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:08:44.882200  4720 solver.cpp:330] Iteration 1500, Testing net (#0)
I1007 10:08:46.811278  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:08:46.891636  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.5514
I1007 10:08:46.891674  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.33058 (* 1 = 1.33058 loss)
I1007 10:08:46.974880  4720 solver.cpp:218] Iteration 1500 (9.6715 iter/s, 10.3397s/100 iters), loss = 0.708499
I1007 10:08:46.974906  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.708499 (* 1 = 0.708499 loss)
I1007 10:08:46.974913  4720 sgd_solver.cpp:105] Iteration 1500, lr = 0.1
I1007 10:08:55.317375  4720 solver.cpp:218] Iteration 1600 (11.987 iter/s, 8.34239s/100 iters), loss = 0.566505
I1007 10:08:55.317487  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.566505 (* 1 = 0.566505 loss)
I1007 10:08:55.317494  4720 sgd_solver.cpp:105] Iteration 1600, lr = 0.1
I1007 10:09:03.645223  4720 solver.cpp:218] Iteration 1700 (12.0082 iter/s, 8.32767s/100 iters), loss = 0.687303
I1007 10:09:03.645252  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.687303 (* 1 = 0.687303 loss)
I1007 10:09:03.645258  4720 sgd_solver.cpp:105] Iteration 1700, lr = 0.1
I1007 10:09:11.985921  4720 solver.cpp:218] Iteration 1800 (11.9896 iter/s, 8.3406s/100 iters), loss = 0.681956
I1007 10:09:11.985950  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.681956 (* 1 = 0.681956 loss)
I1007 10:09:11.985956  4720 sgd_solver.cpp:105] Iteration 1800, lr = 0.1
I1007 10:09:20.465952  4720 solver.cpp:218] Iteration 1900 (11.7926 iter/s, 8.47993s/100 iters), loss = 0.600509
I1007 10:09:20.465981  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.600509 (* 1 = 0.600509 loss)
I1007 10:09:20.465987  4720 sgd_solver.cpp:105] Iteration 1900, lr = 0.1
I1007 10:09:28.381265  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:09:28.714205  4720 solver.cpp:330] Iteration 2000, Testing net (#0)
I1007 10:09:30.650374  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:09:30.732416  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.5968
I1007 10:09:30.732450  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.15542 (* 1 = 1.15542 loss)
I1007 10:09:30.815708  4720 solver.cpp:218] Iteration 2000 (9.66217 iter/s, 10.3496s/100 iters), loss = 0.625381
I1007 10:09:30.815748  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.625381 (* 1 = 0.625381 loss)
I1007 10:09:30.815757  4720 sgd_solver.cpp:105] Iteration 2000, lr = 0.1
I1007 10:09:39.292146  4720 solver.cpp:218] Iteration 2100 (11.7976 iter/s, 8.47633s/100 iters), loss = 0.465605
I1007 10:09:39.292186  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.465605 (* 1 = 0.465605 loss)
I1007 10:09:39.292192  4720 sgd_solver.cpp:105] Iteration 2100, lr = 0.1
I1007 10:09:47.768617  4720 solver.cpp:218] Iteration 2200 (11.7975 iter/s, 8.47636s/100 iters), loss = 0.683852
I1007 10:09:47.768648  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.683852 (* 1 = 0.683852 loss)
I1007 10:09:47.768654  4720 sgd_solver.cpp:105] Iteration 2200, lr = 0.1
I1007 10:09:56.274821  4720 solver.cpp:218] Iteration 2300 (11.7563 iter/s, 8.50611s/100 iters), loss = 0.714856
I1007 10:09:56.274855  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.714856 (* 1 = 0.714856 loss)
I1007 10:09:56.274863  4720 sgd_solver.cpp:105] Iteration 2300, lr = 0.1
I1007 10:10:04.666762  4720 solver.cpp:218] Iteration 2400 (11.9163 iter/s, 8.39184s/100 iters), loss = 0.599479
I1007 10:10:04.666887  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.599479 (* 1 = 0.599479 loss)
I1007 10:10:04.666905  4720 sgd_solver.cpp:105] Iteration 2400, lr = 0.1
I1007 10:10:12.579812  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:10:12.913872  4720 solver.cpp:330] Iteration 2500, Testing net (#0)
I1007 10:10:14.843233  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:10:14.923734  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6426
I1007 10:10:14.923770  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.07232 (* 1 = 1.07232 loss)
I1007 10:10:15.007043  4720 solver.cpp:218] Iteration 2500 (9.6711 iter/s, 10.3401s/100 iters), loss = 0.538168
I1007 10:10:15.007074  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.538168 (* 1 = 0.538168 loss)
I1007 10:10:15.007091  4720 sgd_solver.cpp:105] Iteration 2500, lr = 0.1
I1007 10:10:23.338565  4720 solver.cpp:218] Iteration 2600 (12.0027 iter/s, 8.33143s/100 iters), loss = 0.449246
I1007 10:10:23.338594  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.449246 (* 1 = 0.449246 loss)
I1007 10:10:23.338609  4720 sgd_solver.cpp:105] Iteration 2600, lr = 0.1
I1007 10:10:31.735277  4720 solver.cpp:218] Iteration 2700 (11.9095 iter/s, 8.39663s/100 iters), loss = 0.576444
I1007 10:10:31.735309  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.576444 (* 1 = 0.576444 loss)
I1007 10:10:31.735325  4720 sgd_solver.cpp:105] Iteration 2700, lr = 0.1
I1007 10:10:40.162500  4720 solver.cpp:218] Iteration 2800 (11.8664 iter/s, 8.42714s/100 iters), loss = 0.633931
I1007 10:10:40.162626  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.63393 (* 1 = 0.63393 loss)
I1007 10:10:40.162644  4720 sgd_solver.cpp:105] Iteration 2800, lr = 0.1
I1007 10:10:48.537328  4720 solver.cpp:218] Iteration 2900 (11.9408 iter/s, 8.37465s/100 iters), loss = 0.534313
I1007 10:10:48.537367  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.534313 (* 1 = 0.534313 loss)
I1007 10:10:48.537374  4720 sgd_solver.cpp:105] Iteration 2900, lr = 0.1
I1007 10:10:56.478600  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:10:56.817979  4720 solver.cpp:330] Iteration 3000, Testing net (#0)
I1007 10:10:58.767844  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:10:58.848426  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6305
I1007 10:10:58.848461  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.1357 (* 1 = 1.1357 loss)
I1007 10:10:58.931670  4720 solver.cpp:218] Iteration 3000 (9.62071 iter/s, 10.3942s/100 iters), loss = 0.541137
I1007 10:10:58.931697  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.541137 (* 1 = 0.541137 loss)
I1007 10:10:58.931704  4720 sgd_solver.cpp:105] Iteration 3000, lr = 0.1
I1007 10:11:07.320732  4720 solver.cpp:218] Iteration 3100 (11.9204 iter/s, 8.38898s/100 iters), loss = 0.391947
I1007 10:11:07.320780  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.391947 (* 1 = 0.391947 loss)
I1007 10:11:07.320787  4720 sgd_solver.cpp:105] Iteration 3100, lr = 0.1
I1007 10:11:15.768316  4720 solver.cpp:218] Iteration 3200 (11.8378 iter/s, 8.44749s/100 iters), loss = 0.501378
I1007 10:11:15.768443  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.501378 (* 1 = 0.501378 loss)
I1007 10:11:15.768451  4720 sgd_solver.cpp:105] Iteration 3200, lr = 0.1
I1007 10:11:24.279065  4720 solver.cpp:218] Iteration 3300 (11.7501 iter/s, 8.51058s/100 iters), loss = 0.535421
I1007 10:11:24.279099  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.535421 (* 1 = 0.535421 loss)
I1007 10:11:24.279106  4720 sgd_solver.cpp:105] Iteration 3300, lr = 0.1
I1007 10:11:32.810035  4720 solver.cpp:218] Iteration 3400 (11.7221 iter/s, 8.53089s/100 iters), loss = 0.48386
I1007 10:11:32.810068  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.48386 (* 1 = 0.48386 loss)
I1007 10:11:32.810075  4720 sgd_solver.cpp:105] Iteration 3400, lr = 0.1
I1007 10:11:40.764731  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:11:41.116416  4720 solver.cpp:330] Iteration 3500, Testing net (#0)
I1007 10:11:43.104035  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:11:43.185437  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6193
I1007 10:11:43.185462  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.1112 (* 1 = 1.1112 loss)
I1007 10:11:43.268889  4720 solver.cpp:218] Iteration 3500 (9.56136 iter/s, 10.4588s/100 iters), loss = 0.435
I1007 10:11:43.268924  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.435 (* 1 = 0.435 loss)
I1007 10:11:43.268930  4720 sgd_solver.cpp:105] Iteration 3500, lr = 0.1
I1007 10:11:51.698787  4720 solver.cpp:218] Iteration 3600 (11.8627 iter/s, 8.42982s/100 iters), loss = 0.39439
I1007 10:11:51.698926  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.39439 (* 1 = 0.39439 loss)
I1007 10:11:51.698935  4720 sgd_solver.cpp:105] Iteration 3600, lr = 0.1
I1007 10:12:00.250496  4720 solver.cpp:218] Iteration 3700 (11.6938 iter/s, 8.55153s/100 iters), loss = 0.451308
I1007 10:12:00.250530  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.451308 (* 1 = 0.451308 loss)
I1007 10:12:00.250536  4720 sgd_solver.cpp:105] Iteration 3700, lr = 0.1
I1007 10:12:08.792099  4720 solver.cpp:218] Iteration 3800 (11.7075 iter/s, 8.54153s/100 iters), loss = 0.558608
I1007 10:12:08.792129  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.558607 (* 1 = 0.558607 loss)
I1007 10:12:08.792136  4720 sgd_solver.cpp:105] Iteration 3800, lr = 0.1
I1007 10:12:17.356520  4720 solver.cpp:218] Iteration 3900 (11.6763 iter/s, 8.56434s/100 iters), loss = 0.438572
I1007 10:12:17.356555  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.438572 (* 1 = 0.438572 loss)
I1007 10:12:17.356562  4720 sgd_solver.cpp:105] Iteration 3900, lr = 0.1
I1007 10:12:25.431506  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:12:25.780867  4720 solver.cpp:330] Iteration 4000, Testing net (#0)
I1007 10:12:27.744002  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:12:27.824735  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.681
I1007 10:12:27.824770  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.935984 (* 1 = 0.935984 loss)
I1007 10:12:27.908012  4720 solver.cpp:218] Iteration 4000 (9.47837 iter/s, 10.5503s/100 iters), loss = 0.36888
I1007 10:12:27.908049  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.36888 (* 1 = 0.36888 loss)
I1007 10:12:27.908056  4720 sgd_solver.cpp:105] Iteration 4000, lr = 0.1
I1007 10:12:36.343621  4720 solver.cpp:218] Iteration 4100 (11.8546 iter/s, 8.43553s/100 iters), loss = 0.328635
I1007 10:12:36.343653  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.328635 (* 1 = 0.328635 loss)
I1007 10:12:36.343659  4720 sgd_solver.cpp:105] Iteration 4100, lr = 0.1
I1007 10:12:44.897717  4720 solver.cpp:218] Iteration 4200 (11.6904 iter/s, 8.55402s/100 iters), loss = 0.472035
I1007 10:12:44.897749  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.472035 (* 1 = 0.472035 loss)
I1007 10:12:44.897756  4720 sgd_solver.cpp:105] Iteration 4200, lr = 0.1
I1007 10:12:53.314338  4720 solver.cpp:218] Iteration 4300 (11.8814 iter/s, 8.41654s/100 iters), loss = 0.459957
I1007 10:12:53.314368  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.459956 (* 1 = 0.459956 loss)
I1007 10:12:53.314375  4720 sgd_solver.cpp:105] Iteration 4300, lr = 0.1
I1007 10:13:01.653458  4720 solver.cpp:218] Iteration 4400 (11.9918 iter/s, 8.33905s/100 iters), loss = 0.400683
I1007 10:13:01.653614  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.400683 (* 1 = 0.400683 loss)
I1007 10:13:01.653625  4720 sgd_solver.cpp:105] Iteration 4400, lr = 0.1
I1007 10:13:09.786053  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:13:10.118717  4720 solver.cpp:330] Iteration 4500, Testing net (#0)
I1007 10:13:12.047418  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:13:12.127866  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7107
I1007 10:13:12.127900  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.867563 (* 1 = 0.867563 loss)
I1007 10:13:12.210801  4720 solver.cpp:218] Iteration 4500 (9.47226 iter/s, 10.5571s/100 iters), loss = 0.335637
I1007 10:13:12.210834  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.335637 (* 1 = 0.335637 loss)
I1007 10:13:12.210841  4720 sgd_solver.cpp:105] Iteration 4500, lr = 0.1
I1007 10:13:20.550045  4720 solver.cpp:218] Iteration 4600 (11.9916 iter/s, 8.33917s/100 iters), loss = 0.365852
I1007 10:13:20.550073  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.365852 (* 1 = 0.365852 loss)
I1007 10:13:20.550079  4720 sgd_solver.cpp:105] Iteration 4600, lr = 0.1
I1007 10:13:28.879621  4720 solver.cpp:218] Iteration 4700 (12.0055 iter/s, 8.32951s/100 iters), loss = 0.424503
I1007 10:13:28.879662  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.424503 (* 1 = 0.424503 loss)
I1007 10:13:28.879667  4720 sgd_solver.cpp:105] Iteration 4700, lr = 0.1
I1007 10:13:37.217602  4720 solver.cpp:218] Iteration 4800 (11.9934 iter/s, 8.3379s/100 iters), loss = 0.490385
I1007 10:13:37.217748  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.490384 (* 1 = 0.490384 loss)
I1007 10:13:37.217757  4720 sgd_solver.cpp:105] Iteration 4800, lr = 0.1
I1007 10:13:45.555976  4720 solver.cpp:218] Iteration 4900 (11.993 iter/s, 8.33819s/100 iters), loss = 0.444397
I1007 10:13:45.556015  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.444397 (* 1 = 0.444397 loss)
I1007 10:13:45.556021  4720 sgd_solver.cpp:105] Iteration 4900, lr = 0.1
I1007 10:13:53.468060  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:13:53.801869  4720 solver.cpp:330] Iteration 5000, Testing net (#0)
I1007 10:13:55.730209  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:13:55.811051  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7262
I1007 10:13:55.811087  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.82736 (* 1 = 0.82736 loss)
I1007 10:13:55.893702  4720 solver.cpp:218] Iteration 5000 (9.67339 iter/s, 10.3376s/100 iters), loss = 0.392834
I1007 10:13:55.893734  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.392834 (* 1 = 0.392834 loss)
I1007 10:13:55.893741  4720 sgd_solver.cpp:105] Iteration 5000, lr = 0.1
I1007 10:14:04.226063  4720 solver.cpp:218] Iteration 5100 (12.0015 iter/s, 8.33229s/100 iters), loss = 0.262641
I1007 10:14:04.226104  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.262641 (* 1 = 0.262641 loss)
I1007 10:14:04.226109  4720 sgd_solver.cpp:105] Iteration 5100, lr = 0.1
I1007 10:14:12.555569  4720 solver.cpp:218] Iteration 5200 (12.0056 iter/s, 8.32943s/100 iters), loss = 0.478344
I1007 10:14:12.555727  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.478344 (* 1 = 0.478344 loss)
I1007 10:14:12.555737  4720 sgd_solver.cpp:105] Iteration 5200, lr = 0.1
I1007 10:14:20.896903  4720 solver.cpp:218] Iteration 5300 (11.9888 iter/s, 8.34114s/100 iters), loss = 0.448124
I1007 10:14:20.896941  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.448124 (* 1 = 0.448124 loss)
I1007 10:14:20.896960  4720 sgd_solver.cpp:105] Iteration 5300, lr = 0.1
I1007 10:14:29.220623  4720 solver.cpp:218] Iteration 5400 (12.014 iter/s, 8.32364s/100 iters), loss = 0.485608
I1007 10:14:29.220654  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.485608 (* 1 = 0.485608 loss)
I1007 10:14:29.220659  4720 sgd_solver.cpp:105] Iteration 5400, lr = 0.1
I1007 10:14:37.134318  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:14:37.467121  4720 solver.cpp:330] Iteration 5500, Testing net (#0)
I1007 10:14:39.394006  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:14:39.474283  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6835
I1007 10:14:39.474318  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.912393 (* 1 = 0.912393 loss)
I1007 10:14:39.557402  4720 solver.cpp:218] Iteration 5500 (9.67426 iter/s, 10.3367s/100 iters), loss = 0.349769
I1007 10:14:39.557428  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.349769 (* 1 = 0.349769 loss)
I1007 10:14:39.557435  4720 sgd_solver.cpp:105] Iteration 5500, lr = 0.1
I1007 10:14:47.885421  4720 solver.cpp:218] Iteration 5600 (12.0078 iter/s, 8.32795s/100 iters), loss = 0.343759
I1007 10:14:47.885530  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.343759 (* 1 = 0.343759 loss)
I1007 10:14:47.885547  4720 sgd_solver.cpp:105] Iteration 5600, lr = 0.1
I1007 10:14:56.254001  4720 solver.cpp:218] Iteration 5700 (11.9497 iter/s, 8.36843s/100 iters), loss = 0.305204
I1007 10:14:56.254034  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.305204 (* 1 = 0.305204 loss)
I1007 10:14:56.254040  4720 sgd_solver.cpp:105] Iteration 5700, lr = 0.1
I1007 10:15:04.605556  4720 solver.cpp:218] Iteration 5800 (11.9739 iter/s, 8.35148s/100 iters), loss = 0.396189
I1007 10:15:04.605584  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.396188 (* 1 = 0.396188 loss)
I1007 10:15:04.605590  4720 sgd_solver.cpp:105] Iteration 5800, lr = 0.1
I1007 10:15:12.943239  4720 solver.cpp:218] Iteration 5900 (11.9938 iter/s, 8.33762s/100 iters), loss = 0.38155
I1007 10:15:12.943269  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.38155 (* 1 = 0.38155 loss)
I1007 10:15:12.943285  4720 sgd_solver.cpp:105] Iteration 5900, lr = 0.1
I1007 10:15:20.868852  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:15:21.202255  4720 solver.cpp:330] Iteration 6000, Testing net (#0)
I1007 10:15:23.129967  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:15:23.210630  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7317
I1007 10:15:23.210666  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.766196 (* 1 = 0.766196 loss)
I1007 10:15:23.293248  4720 solver.cpp:218] Iteration 6000 (9.6619 iter/s, 10.3499s/100 iters), loss = 0.34357
I1007 10:15:23.293282  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.34357 (* 1 = 0.34357 loss)
I1007 10:15:23.293287  4720 sgd_solver.cpp:105] Iteration 6000, lr = 0.1
I1007 10:15:31.624300  4720 solver.cpp:218] Iteration 6100 (12.0034 iter/s, 8.33098s/100 iters), loss = 0.343554
I1007 10:15:31.624341  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.343554 (* 1 = 0.343554 loss)
I1007 10:15:31.624346  4720 sgd_solver.cpp:105] Iteration 6100, lr = 0.1
I1007 10:15:39.959736  4720 solver.cpp:218] Iteration 6200 (11.9971 iter/s, 8.33536s/100 iters), loss = 0.313667
I1007 10:15:39.959776  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.313667 (* 1 = 0.313667 loss)
I1007 10:15:39.959781  4720 sgd_solver.cpp:105] Iteration 6200, lr = 0.1
I1007 10:15:48.297060  4720 solver.cpp:218] Iteration 6300 (11.9944 iter/s, 8.33724s/100 iters), loss = 0.452808
I1007 10:15:48.297101  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.452808 (* 1 = 0.452808 loss)
I1007 10:15:48.297106  4720 sgd_solver.cpp:105] Iteration 6300, lr = 0.1
I1007 10:15:56.637984  4720 solver.cpp:218] Iteration 6400 (11.9892 iter/s, 8.34085s/100 iters), loss = 0.460447
I1007 10:15:56.638082  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.460447 (* 1 = 0.460447 loss)
I1007 10:15:56.638099  4720 sgd_solver.cpp:105] Iteration 6400, lr = 0.1
I1007 10:16:04.554239  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:16:04.888568  4720 solver.cpp:330] Iteration 6500, Testing net (#0)
I1007 10:16:06.817503  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:16:06.898030  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7341
I1007 10:16:06.898063  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.771731 (* 1 = 0.771731 loss)
I1007 10:16:06.981786  4720 solver.cpp:218] Iteration 6500 (9.66776 iter/s, 10.3437s/100 iters), loss = 0.275021
I1007 10:16:06.981814  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.275021 (* 1 = 0.275021 loss)
I1007 10:16:06.981822  4720 sgd_solver.cpp:105] Iteration 6500, lr = 0.1
I1007 10:16:15.320551  4720 solver.cpp:218] Iteration 6600 (11.9923 iter/s, 8.3387s/100 iters), loss = 0.271517
I1007 10:16:15.320580  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.271517 (* 1 = 0.271517 loss)
I1007 10:16:15.320586  4720 sgd_solver.cpp:105] Iteration 6600, lr = 0.1
I1007 10:16:23.650492  4720 solver.cpp:218] Iteration 6700 (12.005 iter/s, 8.32987s/100 iters), loss = 0.369417
I1007 10:16:23.650521  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.369417 (* 1 = 0.369417 loss)
I1007 10:16:23.650527  4720 sgd_solver.cpp:105] Iteration 6700, lr = 0.1
I1007 10:16:31.989305  4720 solver.cpp:218] Iteration 6800 (11.9922 iter/s, 8.33875s/100 iters), loss = 0.403789
I1007 10:16:31.989411  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.403789 (* 1 = 0.403789 loss)
I1007 10:16:31.989418  4720 sgd_solver.cpp:105] Iteration 6800, lr = 0.1
I1007 10:16:40.324942  4720 solver.cpp:218] Iteration 6900 (11.9969 iter/s, 8.3355s/100 iters), loss = 0.378604
I1007 10:16:40.324982  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.378604 (* 1 = 0.378604 loss)
I1007 10:16:40.324988  4720 sgd_solver.cpp:105] Iteration 6900, lr = 0.1
I1007 10:16:48.248379  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:16:48.581450  4720 solver.cpp:330] Iteration 7000, Testing net (#0)
I1007 10:16:50.512537  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:16:50.593575  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.779
I1007 10:16:50.593611  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.641711 (* 1 = 0.641711 loss)
I1007 10:16:50.676427  4720 solver.cpp:218] Iteration 7000 (9.66053 iter/s, 10.3514s/100 iters), loss = 0.371745
I1007 10:16:50.676455  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.371745 (* 1 = 0.371745 loss)
I1007 10:16:50.676462  4720 sgd_solver.cpp:105] Iteration 7000, lr = 0.1
I1007 10:16:59.019040  4720 solver.cpp:218] Iteration 7100 (11.9867 iter/s, 8.34255s/100 iters), loss = 0.338055
I1007 10:16:59.019080  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.338055 (* 1 = 0.338055 loss)
I1007 10:16:59.019086  4720 sgd_solver.cpp:105] Iteration 7100, lr = 0.1
I1007 10:17:07.363459  4720 solver.cpp:218] Iteration 7200 (11.9842 iter/s, 8.34434s/100 iters), loss = 0.461094
I1007 10:17:07.363582  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.461094 (* 1 = 0.461094 loss)
I1007 10:17:07.363600  4720 sgd_solver.cpp:105] Iteration 7200, lr = 0.1
I1007 10:17:15.700438  4720 solver.cpp:218] Iteration 7300 (11.995 iter/s, 8.33682s/100 iters), loss = 0.345302
I1007 10:17:15.700479  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.345302 (* 1 = 0.345302 loss)
I1007 10:17:15.700484  4720 sgd_solver.cpp:105] Iteration 7300, lr = 0.1
I1007 10:17:24.046308  4720 solver.cpp:218] Iteration 7400 (11.9821 iter/s, 8.34579s/100 iters), loss = 0.323247
I1007 10:17:24.046347  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.323247 (* 1 = 0.323247 loss)
I1007 10:17:24.046353  4720 sgd_solver.cpp:105] Iteration 7400, lr = 0.1
I1007 10:17:31.972882  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:17:32.308475  4720 solver.cpp:330] Iteration 7500, Testing net (#0)
I1007 10:17:34.241328  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:17:34.321710  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8063
I1007 10:17:34.321745  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.56825 (* 1 = 0.56825 loss)
I1007 10:17:34.405880  4720 solver.cpp:218] Iteration 7500 (9.65299 iter/s, 10.3595s/100 iters), loss = 0.310842
I1007 10:17:34.405908  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.310842 (* 1 = 0.310842 loss)
I1007 10:17:34.405915  4720 sgd_solver.cpp:105] Iteration 7500, lr = 0.1
I1007 10:17:42.757659  4720 solver.cpp:218] Iteration 7600 (11.9736 iter/s, 8.35172s/100 iters), loss = 0.272252
I1007 10:17:42.757817  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.272252 (* 1 = 0.272252 loss)
I1007 10:17:42.757841  4720 sgd_solver.cpp:105] Iteration 7600, lr = 0.1
I1007 10:17:51.104624  4720 solver.cpp:218] Iteration 7700 (11.9807 iter/s, 8.34677s/100 iters), loss = 0.3783
I1007 10:17:51.104665  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.3783 (* 1 = 0.3783 loss)
I1007 10:17:51.104671  4720 sgd_solver.cpp:105] Iteration 7700, lr = 0.1
I1007 10:17:59.457530  4720 solver.cpp:218] Iteration 7800 (11.972 iter/s, 8.35283s/100 iters), loss = 0.370929
I1007 10:17:59.457559  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.370929 (* 1 = 0.370929 loss)
I1007 10:17:59.457566  4720 sgd_solver.cpp:105] Iteration 7800, lr = 0.1
I1007 10:18:07.805827  4720 solver.cpp:218] Iteration 7900 (11.9786 iter/s, 8.34823s/100 iters), loss = 0.359742
I1007 10:18:07.805867  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.359742 (* 1 = 0.359742 loss)
I1007 10:18:07.805872  4720 sgd_solver.cpp:105] Iteration 7900, lr = 0.1
I1007 10:18:15.736012  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:18:16.070799  4720 solver.cpp:330] Iteration 8000, Testing net (#0)
I1007 10:18:18.005717  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:18:18.086796  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.783
I1007 10:18:18.086830  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.645342 (* 1 = 0.645342 loss)
I1007 10:18:18.170246  4720 solver.cpp:218] Iteration 8000 (9.64847 iter/s, 10.3643s/100 iters), loss = 0.263434
I1007 10:18:18.170274  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.263434 (* 1 = 0.263434 loss)
I1007 10:18:18.170279  4720 sgd_solver.cpp:105] Iteration 8000, lr = 0.1
I1007 10:18:26.507791  4720 solver.cpp:218] Iteration 8100 (11.994 iter/s, 8.33748s/100 iters), loss = 0.255068
I1007 10:18:26.507822  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.255068 (* 1 = 0.255068 loss)
I1007 10:18:26.507827  4720 sgd_solver.cpp:105] Iteration 8100, lr = 0.1
I1007 10:18:34.852098  4720 solver.cpp:218] Iteration 8200 (11.9843 iter/s, 8.34424s/100 iters), loss = 0.38434
I1007 10:18:34.852138  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.38434 (* 1 = 0.38434 loss)
I1007 10:18:34.852144  4720 sgd_solver.cpp:105] Iteration 8200, lr = 0.1
I1007 10:18:43.195550  4720 solver.cpp:218] Iteration 8300 (11.9856 iter/s, 8.34337s/100 iters), loss = 0.441496
I1007 10:18:43.195600  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.441496 (* 1 = 0.441496 loss)
I1007 10:18:43.195607  4720 sgd_solver.cpp:105] Iteration 8300, lr = 0.1
I1007 10:18:51.537420  4720 solver.cpp:218] Iteration 8400 (11.9878 iter/s, 8.34179s/100 iters), loss = 0.353036
I1007 10:18:51.537596  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.353036 (* 1 = 0.353036 loss)
I1007 10:18:51.537605  4720 sgd_solver.cpp:105] Iteration 8400, lr = 0.1
I1007 10:18:59.464597  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:18:59.798442  4720 solver.cpp:330] Iteration 8500, Testing net (#0)
I1007 10:19:01.733445  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:19:01.814105  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7718
I1007 10:19:01.814141  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.680892 (* 1 = 0.680892 loss)
I1007 10:19:01.898492  4720 solver.cpp:218] Iteration 8500 (9.6517 iter/s, 10.3609s/100 iters), loss = 0.36914
I1007 10:19:01.898520  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.36914 (* 1 = 0.36914 loss)
I1007 10:19:01.898526  4720 sgd_solver.cpp:105] Iteration 8500, lr = 0.1
I1007 10:19:10.251418  4720 solver.cpp:218] Iteration 8600 (11.9719 iter/s, 8.35286s/100 iters), loss = 0.248365
I1007 10:19:10.251448  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.248365 (* 1 = 0.248365 loss)
I1007 10:19:10.251453  4720 sgd_solver.cpp:105] Iteration 8600, lr = 0.1
I1007 10:19:18.595127  4720 solver.cpp:218] Iteration 8700 (11.9852 iter/s, 8.34365s/100 iters), loss = 0.285691
I1007 10:19:18.595168  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.285691 (* 1 = 0.285691 loss)
I1007 10:19:18.595175  4720 sgd_solver.cpp:105] Iteration 8700, lr = 0.1
I1007 10:19:26.944634  4720 solver.cpp:218] Iteration 8800 (11.9769 iter/s, 8.34943s/100 iters), loss = 0.408131
I1007 10:19:26.944747  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.408131 (* 1 = 0.408131 loss)
I1007 10:19:26.944754  4720 sgd_solver.cpp:105] Iteration 8800, lr = 0.1
I1007 10:19:35.289429  4720 solver.cpp:218] Iteration 8900 (11.9837 iter/s, 8.34465s/100 iters), loss = 0.303759
I1007 10:19:35.289466  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.30376 (* 1 = 0.30376 loss)
I1007 10:19:35.289474  4720 sgd_solver.cpp:105] Iteration 8900, lr = 0.1
I1007 10:19:43.228022  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:19:43.562422  4720 solver.cpp:330] Iteration 9000, Testing net (#0)
I1007 10:19:45.496704  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:19:45.577244  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7279
I1007 10:19:45.577280  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.850539 (* 1 = 0.850539 loss)
I1007 10:19:45.659986  4720 solver.cpp:218] Iteration 9000 (9.64275 iter/s, 10.3705s/100 iters), loss = 0.225836
I1007 10:19:45.660013  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.225836 (* 1 = 0.225836 loss)
I1007 10:19:45.660020  4720 sgd_solver.cpp:105] Iteration 9000, lr = 0.1
I1007 10:19:54.001792  4720 solver.cpp:218] Iteration 9100 (11.9879 iter/s, 8.34175s/100 iters), loss = 0.333734
I1007 10:19:54.001821  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.333734 (* 1 = 0.333734 loss)
I1007 10:19:54.001827  4720 sgd_solver.cpp:105] Iteration 9100, lr = 0.1
I1007 10:20:02.350137  4720 solver.cpp:218] Iteration 9200 (11.9785 iter/s, 8.34828s/100 iters), loss = 0.369239
I1007 10:20:02.350248  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.369239 (* 1 = 0.369239 loss)
I1007 10:20:02.350255  4720 sgd_solver.cpp:105] Iteration 9200, lr = 0.1
I1007 10:20:10.693910  4720 solver.cpp:218] Iteration 9300 (11.9852 iter/s, 8.34364s/100 iters), loss = 0.322984
I1007 10:20:10.693939  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.322984 (* 1 = 0.322984 loss)
I1007 10:20:10.693945  4720 sgd_solver.cpp:105] Iteration 9300, lr = 0.1
I1007 10:20:19.038993  4720 solver.cpp:218] Iteration 9400 (11.9832 iter/s, 8.34502s/100 iters), loss = 0.427068
I1007 10:20:19.039024  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.427068 (* 1 = 0.427068 loss)
I1007 10:20:19.039039  4720 sgd_solver.cpp:105] Iteration 9400, lr = 0.1
I1007 10:20:26.967628  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:20:27.302397  4720 solver.cpp:330] Iteration 9500, Testing net (#0)
I1007 10:20:29.237586  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:20:29.317967  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7728
I1007 10:20:29.318004  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.677075 (* 1 = 0.677075 loss)
I1007 10:20:29.401949  4720 solver.cpp:218] Iteration 9500 (9.64982 iter/s, 10.3629s/100 iters), loss = 0.275216
I1007 10:20:29.401978  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.275216 (* 1 = 0.275216 loss)
I1007 10:20:29.401984  4720 sgd_solver.cpp:105] Iteration 9500, lr = 0.1
I1007 10:20:37.759449  4720 solver.cpp:218] Iteration 9600 (11.9654 iter/s, 8.35743s/100 iters), loss = 0.223448
I1007 10:20:37.759608  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.223448 (* 1 = 0.223448 loss)
I1007 10:20:37.759615  4720 sgd_solver.cpp:105] Iteration 9600, lr = 0.1
I1007 10:20:46.103507  4720 solver.cpp:218] Iteration 9700 (11.9848 iter/s, 8.34387s/100 iters), loss = 0.372396
I1007 10:20:46.103546  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.372396 (* 1 = 0.372396 loss)
I1007 10:20:46.103551  4720 sgd_solver.cpp:105] Iteration 9700, lr = 0.1
I1007 10:20:54.454962  4720 solver.cpp:218] Iteration 9800 (11.9741 iter/s, 8.35138s/100 iters), loss = 0.364051
I1007 10:20:54.455003  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.364051 (* 1 = 0.364051 loss)
I1007 10:20:54.455008  4720 sgd_solver.cpp:105] Iteration 9800, lr = 0.1
I1007 10:21:02.809417  4720 solver.cpp:218] Iteration 9900 (11.9698 iter/s, 8.35438s/100 iters), loss = 0.308151
I1007 10:21:02.809448  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.308151 (* 1 = 0.308151 loss)
I1007 10:21:02.809453  4720 sgd_solver.cpp:105] Iteration 9900, lr = 0.1
I1007 10:21:10.746690  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:21:11.081480  4720 solver.cpp:330] Iteration 10000, Testing net (#0)
I1007 10:21:13.017402  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:21:13.098387  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7887
I1007 10:21:13.098422  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.642117 (* 1 = 0.642117 loss)
I1007 10:21:13.181803  4720 solver.cpp:218] Iteration 10000 (9.64105 iter/s, 10.3723s/100 iters), loss = 0.26122
I1007 10:21:13.181836  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.26122 (* 1 = 0.26122 loss)
I1007 10:21:13.181843  4720 sgd_solver.cpp:105] Iteration 10000, lr = 0.1
I1007 10:21:21.523109  4720 solver.cpp:218] Iteration 10100 (11.9886 iter/s, 8.34124s/100 iters), loss = 0.308007
I1007 10:21:21.523138  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.308007 (* 1 = 0.308007 loss)
I1007 10:21:21.523144  4720 sgd_solver.cpp:105] Iteration 10100, lr = 0.1
I1007 10:21:29.869859  4720 solver.cpp:218] Iteration 10200 (11.9808 iter/s, 8.34669s/100 iters), loss = 0.343219
I1007 10:21:29.869889  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.343219 (* 1 = 0.343219 loss)
I1007 10:21:29.869894  4720 sgd_solver.cpp:105] Iteration 10200, lr = 0.1
I1007 10:21:38.208320  4720 solver.cpp:218] Iteration 10300 (11.9927 iter/s, 8.3384s/100 iters), loss = 0.358525
I1007 10:21:38.208349  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.358525 (* 1 = 0.358525 loss)
I1007 10:21:38.208355  4720 sgd_solver.cpp:105] Iteration 10300, lr = 0.1
I1007 10:21:46.557101  4720 solver.cpp:218] Iteration 10400 (11.9779 iter/s, 8.34872s/100 iters), loss = 0.330082
I1007 10:21:46.557265  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.330083 (* 1 = 0.330083 loss)
I1007 10:21:46.557273  4720 sgd_solver.cpp:105] Iteration 10400, lr = 0.1
I1007 10:21:54.490972  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:21:54.825173  4720 solver.cpp:330] Iteration 10500, Testing net (#0)
I1007 10:21:56.758554  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:21:56.839260  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.772
I1007 10:21:56.839295  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.695563 (* 1 = 0.695563 loss)
I1007 10:21:56.922925  4720 solver.cpp:218] Iteration 10500 (9.64727 iter/s, 10.3656s/100 iters), loss = 0.275313
I1007 10:21:56.922955  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.275313 (* 1 = 0.275313 loss)
I1007 10:21:56.922960  4720 sgd_solver.cpp:105] Iteration 10500, lr = 0.1
I1007 10:22:05.273613  4720 solver.cpp:218] Iteration 10600 (11.9751 iter/s, 8.35063s/100 iters), loss = 0.274587
I1007 10:22:05.273644  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.274587 (* 1 = 0.274587 loss)
I1007 10:22:05.273650  4720 sgd_solver.cpp:105] Iteration 10600, lr = 0.1
I1007 10:22:13.612785  4720 solver.cpp:218] Iteration 10700 (11.9917 iter/s, 8.33911s/100 iters), loss = 0.289351
I1007 10:22:13.612825  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.289351 (* 1 = 0.289351 loss)
I1007 10:22:13.612831  4720 sgd_solver.cpp:105] Iteration 10700, lr = 0.1
I1007 10:22:21.956095  4720 solver.cpp:218] Iteration 10800 (11.9858 iter/s, 8.34324s/100 iters), loss = 0.375223
I1007 10:22:21.956248  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.375223 (* 1 = 0.375223 loss)
I1007 10:22:21.956255  4720 sgd_solver.cpp:105] Iteration 10800, lr = 0.1
I1007 10:22:30.293730  4720 solver.cpp:218] Iteration 10900 (11.9941 iter/s, 8.33745s/100 iters), loss = 0.26555
I1007 10:22:30.293761  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.265551 (* 1 = 0.265551 loss)
I1007 10:22:30.293767  4720 sgd_solver.cpp:105] Iteration 10900, lr = 0.1
I1007 10:22:38.222687  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:22:38.556548  4720 solver.cpp:330] Iteration 11000, Testing net (#0)
I1007 10:22:40.489913  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:22:40.571465  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7477
I1007 10:22:40.571501  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.848727 (* 1 = 0.848727 loss)
I1007 10:22:40.653913  4720 solver.cpp:218] Iteration 11000 (9.6524 iter/s, 10.3601s/100 iters), loss = 0.266359
I1007 10:22:40.653939  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.266359 (* 1 = 0.266359 loss)
I1007 10:22:40.653944  4720 sgd_solver.cpp:105] Iteration 11000, lr = 0.1
I1007 10:22:48.997205  4720 solver.cpp:218] Iteration 11100 (11.9858 iter/s, 8.34323s/100 iters), loss = 0.230184
I1007 10:22:48.997233  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.230184 (* 1 = 0.230184 loss)
I1007 10:22:48.997239  4720 sgd_solver.cpp:105] Iteration 11100, lr = 0.1
I1007 10:22:57.343780  4720 solver.cpp:218] Iteration 11200 (11.9811 iter/s, 8.34651s/100 iters), loss = 0.272476
I1007 10:22:57.343875  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.272476 (* 1 = 0.272476 loss)
I1007 10:22:57.343891  4720 sgd_solver.cpp:105] Iteration 11200, lr = 0.1
I1007 10:23:05.690757  4720 solver.cpp:218] Iteration 11300 (11.9806 iter/s, 8.34685s/100 iters), loss = 0.333248
I1007 10:23:05.690785  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.333248 (* 1 = 0.333248 loss)
I1007 10:23:05.690791  4720 sgd_solver.cpp:105] Iteration 11300, lr = 0.1
I1007 10:23:14.041658  4720 solver.cpp:218] Iteration 11400 (11.9748 iter/s, 8.35084s/100 iters), loss = 0.33787
I1007 10:23:14.041687  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.33787 (* 1 = 0.33787 loss)
I1007 10:23:14.041692  4720 sgd_solver.cpp:105] Iteration 11400, lr = 0.1
I1007 10:23:21.973150  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:23:22.307369  4720 solver.cpp:330] Iteration 11500, Testing net (#0)
I1007 10:23:24.242516  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:23:24.322410  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8035
I1007 10:23:24.322446  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.601615 (* 1 = 0.601615 loss)
I1007 10:23:24.406343  4720 solver.cpp:218] Iteration 11500 (9.64821 iter/s, 10.3646s/100 iters), loss = 0.282576
I1007 10:23:24.406376  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.282576 (* 1 = 0.282576 loss)
I1007 10:23:24.406383  4720 sgd_solver.cpp:105] Iteration 11500, lr = 0.1
I1007 10:23:32.758484  4720 solver.cpp:218] Iteration 11600 (11.9731 iter/s, 8.35207s/100 iters), loss = 0.227614
I1007 10:23:32.758630  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.227614 (* 1 = 0.227614 loss)
I1007 10:23:32.758649  4720 sgd_solver.cpp:105] Iteration 11600, lr = 0.1
I1007 10:23:41.105062  4720 solver.cpp:218] Iteration 11700 (11.9812 iter/s, 8.3464s/100 iters), loss = 0.368202
I1007 10:23:41.105093  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.368202 (* 1 = 0.368202 loss)
I1007 10:23:41.105098  4720 sgd_solver.cpp:105] Iteration 11700, lr = 0.1
I1007 10:23:49.450525  4720 solver.cpp:218] Iteration 11800 (11.9826 iter/s, 8.3454s/100 iters), loss = 0.386324
I1007 10:23:49.450553  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.386325 (* 1 = 0.386325 loss)
I1007 10:23:49.450559  4720 sgd_solver.cpp:105] Iteration 11800, lr = 0.1
I1007 10:23:57.790987  4720 solver.cpp:218] Iteration 11900 (11.9898 iter/s, 8.3404s/100 iters), loss = 0.340327
I1007 10:23:57.791014  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.340327 (* 1 = 0.340327 loss)
I1007 10:23:57.791020  4720 sgd_solver.cpp:105] Iteration 11900, lr = 0.1
I1007 10:24:05.728534  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:24:06.062584  4720 solver.cpp:330] Iteration 12000, Testing net (#0)
I1007 10:24:07.997963  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:24:08.078281  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7267
I1007 10:24:08.078316  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.950877 (* 1 = 0.950877 loss)
I1007 10:24:08.161455  4720 solver.cpp:218] Iteration 12000 (9.64283 iter/s, 10.3704s/100 iters), loss = 0.228658
I1007 10:24:08.161484  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.228659 (* 1 = 0.228659 loss)
I1007 10:24:08.161490  4720 sgd_solver.cpp:105] Iteration 12000, lr = 0.1
I1007 10:24:16.507750  4720 solver.cpp:218] Iteration 12100 (11.9815 iter/s, 8.34623s/100 iters), loss = 0.215805
I1007 10:24:16.507789  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.215805 (* 1 = 0.215805 loss)
I1007 10:24:16.507794  4720 sgd_solver.cpp:105] Iteration 12100, lr = 0.1
I1007 10:24:24.853894  4720 solver.cpp:218] Iteration 12200 (11.9817 iter/s, 8.34607s/100 iters), loss = 0.293538
I1007 10:24:24.853924  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.293539 (* 1 = 0.293539 loss)
I1007 10:24:24.853929  4720 sgd_solver.cpp:105] Iteration 12200, lr = 0.1
I1007 10:24:33.196893  4720 solver.cpp:218] Iteration 12300 (11.9862 iter/s, 8.34294s/100 iters), loss = 0.260668
I1007 10:24:33.196934  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.260668 (* 1 = 0.260668 loss)
I1007 10:24:33.196940  4720 sgd_solver.cpp:105] Iteration 12300, lr = 0.1
I1007 10:24:41.545917  4720 solver.cpp:218] Iteration 12400 (11.9776 iter/s, 8.34895s/100 iters), loss = 0.273036
I1007 10:24:41.546018  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.273036 (* 1 = 0.273036 loss)
I1007 10:24:41.546025  4720 sgd_solver.cpp:105] Iteration 12400, lr = 0.1
I1007 10:24:49.476718  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:24:49.810803  4720 solver.cpp:330] Iteration 12500, Testing net (#0)
I1007 10:24:51.743979  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:24:51.824976  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7275
I1007 10:24:51.825011  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.972528 (* 1 = 0.972528 loss)
I1007 10:24:51.908812  4720 solver.cpp:218] Iteration 12500 (9.64994 iter/s, 10.3628s/100 iters), loss = 0.253065
I1007 10:24:51.908843  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.253065 (* 1 = 0.253065 loss)
I1007 10:24:51.908849  4720 sgd_solver.cpp:105] Iteration 12500, lr = 0.1
I1007 10:25:00.262331  4720 solver.cpp:218] Iteration 12600 (11.9711 iter/s, 8.35345s/100 iters), loss = 0.272912
I1007 10:25:00.262364  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.272912 (* 1 = 0.272912 loss)
I1007 10:25:00.262372  4720 sgd_solver.cpp:105] Iteration 12600, lr = 0.1
I1007 10:25:08.608165  4720 solver.cpp:218] Iteration 12700 (11.9821 iter/s, 8.34577s/100 iters), loss = 0.511934
I1007 10:25:08.608206  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.511934 (* 1 = 0.511934 loss)
I1007 10:25:08.608211  4720 sgd_solver.cpp:105] Iteration 12700, lr = 0.1
I1007 10:25:16.954499  4720 solver.cpp:218] Iteration 12800 (11.9814 iter/s, 8.34626s/100 iters), loss = 0.346612
I1007 10:25:16.954644  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.346612 (* 1 = 0.346612 loss)
I1007 10:25:16.954664  4720 sgd_solver.cpp:105] Iteration 12800, lr = 0.1
I1007 10:25:25.299504  4720 solver.cpp:218] Iteration 12900 (11.9835 iter/s, 8.34483s/100 iters), loss = 0.268039
I1007 10:25:25.299536  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.268039 (* 1 = 0.268039 loss)
I1007 10:25:25.299545  4720 sgd_solver.cpp:105] Iteration 12900, lr = 0.1
I1007 10:25:33.233147  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:25:33.566468  4720 solver.cpp:330] Iteration 13000, Testing net (#0)
I1007 10:25:35.499902  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:25:35.580708  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.5112
I1007 10:25:35.580735  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 2.28402 (* 1 = 2.28402 loss)
I1007 10:25:35.663942  4720 solver.cpp:218] Iteration 13000 (9.64844 iter/s, 10.3644s/100 iters), loss = 0.275298
I1007 10:25:35.663972  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.275298 (* 1 = 0.275298 loss)
I1007 10:25:35.663981  4720 sgd_solver.cpp:105] Iteration 13000, lr = 0.1
I1007 10:25:44.013558  4720 solver.cpp:218] Iteration 13100 (11.9767 iter/s, 8.34956s/100 iters), loss = 0.208608
I1007 10:25:44.013592  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.208608 (* 1 = 0.208608 loss)
I1007 10:25:44.013599  4720 sgd_solver.cpp:105] Iteration 13100, lr = 0.1
I1007 10:25:52.361996  4720 solver.cpp:218] Iteration 13200 (11.9784 iter/s, 8.34838s/100 iters), loss = 0.353554
I1007 10:25:52.362141  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.353554 (* 1 = 0.353554 loss)
I1007 10:25:52.362164  4720 sgd_solver.cpp:105] Iteration 13200, lr = 0.1
I1007 10:26:00.708279  4720 solver.cpp:218] Iteration 13300 (11.9816 iter/s, 8.34611s/100 iters), loss = 0.405084
I1007 10:26:00.708312  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.405084 (* 1 = 0.405084 loss)
I1007 10:26:00.708318  4720 sgd_solver.cpp:105] Iteration 13300, lr = 0.1
I1007 10:26:09.057183  4720 solver.cpp:218] Iteration 13400 (11.9777 iter/s, 8.34884s/100 iters), loss = 0.265463
I1007 10:26:09.057214  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.265463 (* 1 = 0.265463 loss)
I1007 10:26:09.057222  4720 sgd_solver.cpp:105] Iteration 13400, lr = 0.1
I1007 10:26:16.990298  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:26:17.324110  4720 solver.cpp:330] Iteration 13500, Testing net (#0)
I1007 10:26:19.259389  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:26:19.340006  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7741
I1007 10:26:19.340034  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.677653 (* 1 = 0.677653 loss)
I1007 10:26:19.424149  4720 solver.cpp:218] Iteration 13500 (9.64609 iter/s, 10.3669s/100 iters), loss = 0.197464
I1007 10:26:19.424185  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.197464 (* 1 = 0.197464 loss)
I1007 10:26:19.424193  4720 sgd_solver.cpp:105] Iteration 13500, lr = 0.1
I1007 10:26:27.772336  4720 solver.cpp:218] Iteration 13600 (11.9787 iter/s, 8.34812s/100 iters), loss = 0.196887
I1007 10:26:27.772477  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.196887 (* 1 = 0.196887 loss)
I1007 10:26:27.772497  4720 sgd_solver.cpp:105] Iteration 13600, lr = 0.1
I1007 10:26:36.115658  4720 solver.cpp:218] Iteration 13700 (11.9859 iter/s, 8.34316s/100 iters), loss = 0.221543
I1007 10:26:36.115691  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.221543 (* 1 = 0.221543 loss)
I1007 10:26:36.115700  4720 sgd_solver.cpp:105] Iteration 13700, lr = 0.1
I1007 10:26:44.466634  4720 solver.cpp:218] Iteration 13800 (11.9747 iter/s, 8.35091s/100 iters), loss = 0.277126
I1007 10:26:44.466666  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.277126 (* 1 = 0.277126 loss)
I1007 10:26:44.466675  4720 sgd_solver.cpp:105] Iteration 13800, lr = 0.1
I1007 10:26:52.811493  4720 solver.cpp:218] Iteration 13900 (11.9835 iter/s, 8.3448s/100 iters), loss = 0.241254
I1007 10:26:52.811525  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.241254 (* 1 = 0.241254 loss)
I1007 10:26:52.811532  4720 sgd_solver.cpp:105] Iteration 13900, lr = 0.1
I1007 10:27:00.744601  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:27:01.079156  4720 solver.cpp:330] Iteration 14000, Testing net (#0)
I1007 10:27:03.011572  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:27:03.093250  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6866
I1007 10:27:03.093276  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.20855 (* 1 = 1.20855 loss)
I1007 10:27:03.176203  4720 solver.cpp:218] Iteration 14000 (9.64818 iter/s, 10.3646s/100 iters), loss = 0.201924
I1007 10:27:03.176232  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.201924 (* 1 = 0.201924 loss)
I1007 10:27:03.176251  4720 sgd_solver.cpp:105] Iteration 14000, lr = 0.1
I1007 10:27:11.519932  4720 solver.cpp:218] Iteration 14100 (11.9851 iter/s, 8.34367s/100 iters), loss = 0.161172
I1007 10:27:11.519963  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.161172 (* 1 = 0.161172 loss)
I1007 10:27:11.519981  4720 sgd_solver.cpp:105] Iteration 14100, lr = 0.1
I1007 10:27:19.875079  4720 solver.cpp:218] Iteration 14200 (11.9688 iter/s, 8.35509s/100 iters), loss = 0.264561
I1007 10:27:19.875111  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.264561 (* 1 = 0.264561 loss)
I1007 10:27:19.875118  4720 sgd_solver.cpp:105] Iteration 14200, lr = 0.1
I1007 10:27:28.223634  4720 solver.cpp:218] Iteration 14300 (11.9782 iter/s, 8.34849s/100 iters), loss = 0.37105
I1007 10:27:28.223666  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.37105 (* 1 = 0.37105 loss)
I1007 10:27:28.223675  4720 sgd_solver.cpp:105] Iteration 14300, lr = 0.1
I1007 10:27:36.574828  4720 solver.cpp:218] Iteration 14400 (11.9744 iter/s, 8.35113s/100 iters), loss = 0.34406
I1007 10:27:36.574954  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.34406 (* 1 = 0.34406 loss)
I1007 10:27:36.574964  4720 sgd_solver.cpp:105] Iteration 14400, lr = 0.1
I1007 10:27:44.511785  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:27:44.845152  4720 solver.cpp:330] Iteration 14500, Testing net (#0)
I1007 10:27:46.778611  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:27:46.859119  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7844
I1007 10:27:46.859145  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.667291 (* 1 = 0.667291 loss)
I1007 10:27:46.942672  4720 solver.cpp:218] Iteration 14500 (9.64536 iter/s, 10.3677s/100 iters), loss = 0.212637
I1007 10:27:46.942705  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.212637 (* 1 = 0.212637 loss)
I1007 10:27:46.942714  4720 sgd_solver.cpp:105] Iteration 14500, lr = 0.1
I1007 10:27:55.301968  4720 solver.cpp:218] Iteration 14600 (11.9628 iter/s, 8.35924s/100 iters), loss = 0.269791
I1007 10:27:55.302001  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.269791 (* 1 = 0.269791 loss)
I1007 10:27:55.302021  4720 sgd_solver.cpp:105] Iteration 14600, lr = 0.1
I1007 10:28:03.650516  4720 solver.cpp:218] Iteration 14700 (11.9782 iter/s, 8.34849s/100 iters), loss = 0.28262
I1007 10:28:03.650548  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.28262 (* 1 = 0.28262 loss)
I1007 10:28:03.650557  4720 sgd_solver.cpp:105] Iteration 14700, lr = 0.1
I1007 10:28:12.004570  4720 solver.cpp:218] Iteration 14800 (11.9703 iter/s, 8.35399s/100 iters), loss = 0.314715
I1007 10:28:12.004700  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.314715 (* 1 = 0.314715 loss)
I1007 10:28:12.004710  4720 sgd_solver.cpp:105] Iteration 14800, lr = 0.1
I1007 10:28:20.358615  4720 solver.cpp:218] Iteration 14900 (11.9705 iter/s, 8.35389s/100 iters), loss = 0.293443
I1007 10:28:20.358647  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.293443 (* 1 = 0.293443 loss)
I1007 10:28:20.358655  4720 sgd_solver.cpp:105] Iteration 14900, lr = 0.1
I1007 10:28:28.305701  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:28:28.640146  4720 solver.cpp:330] Iteration 15000, Testing net (#0)
I1007 10:28:30.574026  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:28:30.654606  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7617
I1007 10:28:30.654633  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.740125 (* 1 = 0.740125 loss)
I1007 10:28:30.738044  4720 solver.cpp:218] Iteration 15000 (9.6345 iter/s, 10.3794s/100 iters), loss = 0.256308
I1007 10:28:30.738073  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.256308 (* 1 = 0.256308 loss)
I1007 10:28:30.738082  4720 sgd_solver.cpp:105] Iteration 15000, lr = 0.1
I1007 10:28:39.083361  4720 solver.cpp:218] Iteration 15100 (11.9829 iter/s, 8.34526s/100 iters), loss = 0.247061
I1007 10:28:39.083394  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.247061 (* 1 = 0.247061 loss)
I1007 10:28:39.083401  4720 sgd_solver.cpp:105] Iteration 15100, lr = 0.1
I1007 10:28:47.435727  4720 solver.cpp:218] Iteration 15200 (11.9727 iter/s, 8.35231s/100 iters), loss = 0.285528
I1007 10:28:47.435838  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.285528 (* 1 = 0.285528 loss)
I1007 10:28:47.435847  4720 sgd_solver.cpp:105] Iteration 15200, lr = 0.1
I1007 10:28:55.783565  4720 solver.cpp:218] Iteration 15300 (11.9793 iter/s, 8.3477s/100 iters), loss = 0.35787
I1007 10:28:55.783597  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.35787 (* 1 = 0.35787 loss)
I1007 10:28:55.783614  4720 sgd_solver.cpp:105] Iteration 15300, lr = 0.1
I1007 10:29:04.138634  4720 solver.cpp:218] Iteration 15400 (11.9689 iter/s, 8.35501s/100 iters), loss = 0.184362
I1007 10:29:04.138666  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.184361 (* 1 = 0.184361 loss)
I1007 10:29:04.138684  4720 sgd_solver.cpp:105] Iteration 15400, lr = 0.1
I1007 10:29:12.075851  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:29:12.410538  4720 solver.cpp:330] Iteration 15500, Testing net (#0)
I1007 10:29:14.345976  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:29:14.426592  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8117
I1007 10:29:14.426618  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.594922 (* 1 = 0.594922 loss)
I1007 10:29:14.510282  4720 solver.cpp:218] Iteration 15500 (9.64173 iter/s, 10.3716s/100 iters), loss = 0.168208
I1007 10:29:14.510316  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.168208 (* 1 = 0.168208 loss)
I1007 10:29:14.510325  4720 sgd_solver.cpp:105] Iteration 15500, lr = 0.1
I1007 10:29:22.863876  4720 solver.cpp:218] Iteration 15600 (11.971 iter/s, 8.35353s/100 iters), loss = 0.162007
I1007 10:29:22.864013  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.162007 (* 1 = 0.162007 loss)
I1007 10:29:22.864033  4720 sgd_solver.cpp:105] Iteration 15600, lr = 0.1
I1007 10:29:31.210283  4720 solver.cpp:218] Iteration 15700 (11.9814 iter/s, 8.34625s/100 iters), loss = 0.309182
I1007 10:29:31.210315  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.309182 (* 1 = 0.309182 loss)
I1007 10:29:31.210333  4720 sgd_solver.cpp:105] Iteration 15700, lr = 0.1
I1007 10:29:39.566354  4720 solver.cpp:218] Iteration 15800 (11.9674 iter/s, 8.35601s/100 iters), loss = 0.289658
I1007 10:29:39.566387  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.289658 (* 1 = 0.289658 loss)
I1007 10:29:39.566406  4720 sgd_solver.cpp:105] Iteration 15800, lr = 0.1
I1007 10:29:47.913226  4720 solver.cpp:218] Iteration 15900 (11.9806 iter/s, 8.34681s/100 iters), loss = 0.198947
I1007 10:29:47.913259  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.198947 (* 1 = 0.198947 loss)
I1007 10:29:47.913277  4720 sgd_solver.cpp:105] Iteration 15900, lr = 0.1
I1007 10:29:55.850044  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:29:56.183310  4720 solver.cpp:330] Iteration 16000, Testing net (#0)
I1007 10:29:58.117461  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:29:58.197937  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7828
I1007 10:29:58.197964  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.694377 (* 1 = 0.694377 loss)
I1007 10:29:58.281231  4720 solver.cpp:218] Iteration 16000 (9.64512 iter/s, 10.3679s/100 iters), loss = 0.223439
I1007 10:29:58.281263  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.223439 (* 1 = 0.223439 loss)
I1007 10:29:58.281273  4720 sgd_solver.cpp:105] Iteration 16000, lr = 0.1
I1007 10:30:06.628021  4720 solver.cpp:218] Iteration 16100 (11.9807 iter/s, 8.34673s/100 iters), loss = 0.23177
I1007 10:30:06.628051  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.23177 (* 1 = 0.23177 loss)
I1007 10:30:06.628059  4720 sgd_solver.cpp:105] Iteration 16100, lr = 0.1
I1007 10:30:14.977017  4720 solver.cpp:218] Iteration 16200 (11.9776 iter/s, 8.34894s/100 iters), loss = 0.312342
I1007 10:30:14.977051  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.312342 (* 1 = 0.312342 loss)
I1007 10:30:14.977058  4720 sgd_solver.cpp:105] Iteration 16200, lr = 0.1
I1007 10:30:23.320611  4720 solver.cpp:218] Iteration 16300 (11.9853 iter/s, 8.34353s/100 iters), loss = 0.240449
I1007 10:30:23.320641  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.240448 (* 1 = 0.240448 loss)
I1007 10:30:23.320647  4720 sgd_solver.cpp:105] Iteration 16300, lr = 0.1
I1007 10:30:31.670243  4720 solver.cpp:218] Iteration 16400 (11.9767 iter/s, 8.34957s/100 iters), loss = 0.20513
I1007 10:30:31.670383  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.20513 (* 1 = 0.20513 loss)
I1007 10:30:31.670390  4720 sgd_solver.cpp:105] Iteration 16400, lr = 0.1
I1007 10:30:39.607750  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:30:39.942795  4720 solver.cpp:330] Iteration 16500, Testing net (#0)
I1007 10:30:41.875607  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:30:41.956185  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7884
I1007 10:30:41.956220  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.663441 (* 1 = 0.663441 loss)
I1007 10:30:42.040254  4720 solver.cpp:218] Iteration 16500 (9.64334 iter/s, 10.3698s/100 iters), loss = 0.300372
I1007 10:30:42.040283  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.300372 (* 1 = 0.300372 loss)
I1007 10:30:42.040290  4720 sgd_solver.cpp:105] Iteration 16500, lr = 0.1
I1007 10:30:50.389163  4720 solver.cpp:218] Iteration 16600 (11.9777 iter/s, 8.34885s/100 iters), loss = 0.247547
I1007 10:30:50.389192  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.247547 (* 1 = 0.247547 loss)
I1007 10:30:50.389199  4720 sgd_solver.cpp:105] Iteration 16600, lr = 0.1
I1007 10:30:58.733299  4720 solver.cpp:218] Iteration 16700 (11.9845 iter/s, 8.34408s/100 iters), loss = 0.341434
I1007 10:30:58.733340  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.341434 (* 1 = 0.341434 loss)
I1007 10:30:58.733346  4720 sgd_solver.cpp:105] Iteration 16700, lr = 0.1
I1007 10:31:07.082867  4720 solver.cpp:218] Iteration 16800 (11.9768 iter/s, 8.3495s/100 iters), loss = 0.332589
I1007 10:31:07.082999  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.332589 (* 1 = 0.332589 loss)
I1007 10:31:07.083006  4720 sgd_solver.cpp:105] Iteration 16800, lr = 0.1
I1007 10:31:15.428483  4720 solver.cpp:218] Iteration 16900 (11.9826 iter/s, 8.34546s/100 iters), loss = 0.26223
I1007 10:31:15.428514  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.26223 (* 1 = 0.26223 loss)
I1007 10:31:15.428519  4720 sgd_solver.cpp:105] Iteration 16900, lr = 0.1
I1007 10:31:23.360527  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:31:23.695668  4720 solver.cpp:330] Iteration 17000, Testing net (#0)
I1007 10:31:25.628279  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:31:25.708906  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8247
I1007 10:31:25.708942  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.534791 (* 1 = 0.534791 loss)
I1007 10:31:25.792191  4720 solver.cpp:218] Iteration 17000 (9.64912 iter/s, 10.3636s/100 iters), loss = 0.229589
I1007 10:31:25.792219  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.229589 (* 1 = 0.229589 loss)
I1007 10:31:25.792225  4720 sgd_solver.cpp:105] Iteration 17000, lr = 0.1
I1007 10:31:34.141144  4720 solver.cpp:218] Iteration 17100 (11.9776 iter/s, 8.3489s/100 iters), loss = 0.22127
I1007 10:31:34.141173  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.221269 (* 1 = 0.221269 loss)
I1007 10:31:34.141180  4720 sgd_solver.cpp:105] Iteration 17100, lr = 0.1
I1007 10:31:42.497824  4720 solver.cpp:218] Iteration 17200 (11.9666 iter/s, 8.35662s/100 iters), loss = 0.261308
I1007 10:31:42.497943  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.261307 (* 1 = 0.261307 loss)
I1007 10:31:42.497961  4720 sgd_solver.cpp:105] Iteration 17200, lr = 0.1
I1007 10:31:50.847309  4720 solver.cpp:218] Iteration 17300 (11.977 iter/s, 8.34934s/100 iters), loss = 0.344271
I1007 10:31:50.847338  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.344271 (* 1 = 0.344271 loss)
I1007 10:31:50.847343  4720 sgd_solver.cpp:105] Iteration 17300, lr = 0.1
I1007 10:31:59.200867  4720 solver.cpp:218] Iteration 17400 (11.971 iter/s, 8.3535s/100 iters), loss = 0.218914
I1007 10:31:59.200908  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.218914 (* 1 = 0.218914 loss)
I1007 10:31:59.200914  4720 sgd_solver.cpp:105] Iteration 17400, lr = 0.1
I1007 10:32:07.138202  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:32:07.471997  4720 solver.cpp:330] Iteration 17500, Testing net (#0)
I1007 10:32:09.404657  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:32:09.485298  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7479
I1007 10:32:09.485352  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.806299 (* 1 = 0.806299 loss)
I1007 10:32:09.568907  4720 solver.cpp:218] Iteration 17500 (9.6451 iter/s, 10.368s/100 iters), loss = 0.191786
I1007 10:32:09.568938  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.191786 (* 1 = 0.191786 loss)
I1007 10:32:09.568944  4720 sgd_solver.cpp:105] Iteration 17500, lr = 0.1
I1007 10:32:17.924015  4720 solver.cpp:218] Iteration 17600 (11.9688 iter/s, 8.35505s/100 iters), loss = 0.191485
I1007 10:32:17.924145  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.191485 (* 1 = 0.191485 loss)
I1007 10:32:17.924152  4720 sgd_solver.cpp:105] Iteration 17600, lr = 0.1
I1007 10:32:26.272248  4720 solver.cpp:218] Iteration 17700 (11.9788 iter/s, 8.34809s/100 iters), loss = 0.283483
I1007 10:32:26.272279  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.283483 (* 1 = 0.283483 loss)
I1007 10:32:26.272284  4720 sgd_solver.cpp:105] Iteration 17700, lr = 0.1
I1007 10:32:34.634189  4720 solver.cpp:218] Iteration 17800 (11.959 iter/s, 8.36188s/100 iters), loss = 0.340236
I1007 10:32:34.634228  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.340236 (* 1 = 0.340236 loss)
I1007 10:32:34.634234  4720 sgd_solver.cpp:105] Iteration 17800, lr = 0.1
I1007 10:32:42.984637  4720 solver.cpp:218] Iteration 17900 (11.9755 iter/s, 8.35038s/100 iters), loss = 0.263347
I1007 10:32:42.984675  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.263347 (* 1 = 0.263347 loss)
I1007 10:32:42.984680  4720 sgd_solver.cpp:105] Iteration 17900, lr = 0.1
I1007 10:32:50.930107  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:32:51.264520  4720 solver.cpp:330] Iteration 18000, Testing net (#0)
I1007 10:32:53.196774  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:32:53.276935  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7633
I1007 10:32:53.276970  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.818837 (* 1 = 0.818837 loss)
I1007 10:32:53.359987  4720 solver.cpp:218] Iteration 18000 (9.6383 iter/s, 10.3753s/100 iters), loss = 0.177598
I1007 10:32:53.360015  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.177598 (* 1 = 0.177598 loss)
I1007 10:32:53.360021  4720 sgd_solver.cpp:105] Iteration 18000, lr = 0.1
I1007 10:33:01.710542  4720 solver.cpp:218] Iteration 18100 (11.9753 iter/s, 8.3505s/100 iters), loss = 0.276143
I1007 10:33:01.710582  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.276143 (* 1 = 0.276143 loss)
I1007 10:33:01.710587  4720 sgd_solver.cpp:105] Iteration 18100, lr = 0.1
I1007 10:33:10.067445  4720 solver.cpp:218] Iteration 18200 (11.9663 iter/s, 8.35683s/100 iters), loss = 0.270008
I1007 10:33:10.067473  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.270008 (* 1 = 0.270008 loss)
I1007 10:33:10.067479  4720 sgd_solver.cpp:105] Iteration 18200, lr = 0.1
I1007 10:33:18.415629  4720 solver.cpp:218] Iteration 18300 (11.9787 iter/s, 8.34813s/100 iters), loss = 0.216751
I1007 10:33:18.415659  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.216751 (* 1 = 0.216751 loss)
I1007 10:33:18.415665  4720 sgd_solver.cpp:105] Iteration 18300, lr = 0.1
I1007 10:33:26.771683  4720 solver.cpp:218] Iteration 18400 (11.9675 iter/s, 8.356s/100 iters), loss = 0.286907
I1007 10:33:26.771831  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.286907 (* 1 = 0.286907 loss)
I1007 10:33:26.771838  4720 sgd_solver.cpp:105] Iteration 18400, lr = 0.1
I1007 10:33:34.701625  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:33:35.035464  4720 solver.cpp:330] Iteration 18500, Testing net (#0)
I1007 10:33:36.968991  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:33:37.049628  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8088
I1007 10:33:37.049664  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.56624 (* 1 = 0.56624 loss)
I1007 10:33:37.133399  4720 solver.cpp:218] Iteration 18500 (9.65108 iter/s, 10.3615s/100 iters), loss = 0.211055
I1007 10:33:37.133427  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.211055 (* 1 = 0.211055 loss)
I1007 10:33:37.133433  4720 sgd_solver.cpp:105] Iteration 18500, lr = 0.1
I1007 10:33:45.484892  4720 solver.cpp:218] Iteration 18600 (11.974 iter/s, 8.35144s/100 iters), loss = 0.216509
I1007 10:33:45.484920  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.216509 (* 1 = 0.216509 loss)
I1007 10:33:45.484926  4720 sgd_solver.cpp:105] Iteration 18600, lr = 0.1
I1007 10:33:53.830096  4720 solver.cpp:218] Iteration 18700 (11.983 iter/s, 8.34514s/100 iters), loss = 0.238946
I1007 10:33:53.830127  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.238946 (* 1 = 0.238946 loss)
I1007 10:33:53.830134  4720 sgd_solver.cpp:105] Iteration 18700, lr = 0.1
I1007 10:34:02.179078  4720 solver.cpp:218] Iteration 18800 (11.9776 iter/s, 8.34892s/100 iters), loss = 0.248069
I1007 10:34:02.179181  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.248069 (* 1 = 0.248069 loss)
I1007 10:34:02.179199  4720 sgd_solver.cpp:105] Iteration 18800, lr = 0.1
I1007 10:34:10.529860  4720 solver.cpp:218] Iteration 18900 (11.9751 iter/s, 8.35065s/100 iters), loss = 0.391837
I1007 10:34:10.529889  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.391837 (* 1 = 0.391837 loss)
I1007 10:34:10.529894  4720 sgd_solver.cpp:105] Iteration 18900, lr = 0.1
I1007 10:34:18.472009  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:34:18.808266  4720 solver.cpp:330] Iteration 19000, Testing net (#0)
I1007 10:34:20.740348  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:34:20.820452  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8033
I1007 10:34:20.820488  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.60987 (* 1 = 0.60987 loss)
I1007 10:34:20.904028  4720 solver.cpp:218] Iteration 19000 (9.63939 iter/s, 10.3741s/100 iters), loss = 0.155469
I1007 10:34:20.904062  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.155469 (* 1 = 0.155469 loss)
I1007 10:34:20.904068  4720 sgd_solver.cpp:105] Iteration 19000, lr = 0.1
I1007 10:34:29.254220  4720 solver.cpp:218] Iteration 19100 (11.9759 iter/s, 8.35013s/100 iters), loss = 0.220254
I1007 10:34:29.254251  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.220254 (* 1 = 0.220254 loss)
I1007 10:34:29.254256  4720 sgd_solver.cpp:105] Iteration 19100, lr = 0.1
I1007 10:34:37.603401  4720 solver.cpp:218] Iteration 19200 (11.9773 iter/s, 8.34912s/100 iters), loss = 0.271274
I1007 10:34:37.603508  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.271274 (* 1 = 0.271274 loss)
I1007 10:34:37.603515  4720 sgd_solver.cpp:105] Iteration 19200, lr = 0.1
I1007 10:34:45.953168  4720 solver.cpp:218] Iteration 19300 (11.9766 iter/s, 8.34963s/100 iters), loss = 0.224603
I1007 10:34:45.953207  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.224603 (* 1 = 0.224603 loss)
I1007 10:34:45.953213  4720 sgd_solver.cpp:105] Iteration 19300, lr = 0.1
I1007 10:34:54.303486  4720 solver.cpp:218] Iteration 19400 (11.9757 iter/s, 8.35025s/100 iters), loss = 0.294228
I1007 10:34:54.303517  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.294228 (* 1 = 0.294228 loss)
I1007 10:34:54.303524  4720 sgd_solver.cpp:105] Iteration 19400, lr = 0.1
I1007 10:35:02.237033  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:35:02.572026  4720 solver.cpp:330] Iteration 19500, Testing net (#0)
I1007 10:35:04.506469  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:35:04.587239  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8156
I1007 10:35:04.587273  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.574832 (* 1 = 0.574832 loss)
I1007 10:35:04.671176  4720 solver.cpp:218] Iteration 19500 (9.64541 iter/s, 10.3676s/100 iters), loss = 0.300752
I1007 10:35:04.671205  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.300753 (* 1 = 0.300753 loss)
I1007 10:35:04.671213  4720 sgd_solver.cpp:105] Iteration 19500, lr = 0.1
I1007 10:35:13.021522  4720 solver.cpp:218] Iteration 19600 (11.9756 iter/s, 8.35029s/100 iters), loss = 0.214087
I1007 10:35:13.021641  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.214087 (* 1 = 0.214087 loss)
I1007 10:35:13.021657  4720 sgd_solver.cpp:105] Iteration 19600, lr = 0.1
I1007 10:35:21.362546  4720 solver.cpp:218] Iteration 19700 (11.9891 iter/s, 8.34088s/100 iters), loss = 0.224431
I1007 10:35:21.362586  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.224431 (* 1 = 0.224431 loss)
I1007 10:35:21.362602  4720 sgd_solver.cpp:105] Iteration 19700, lr = 0.1
I1007 10:35:29.709018  4720 solver.cpp:218] Iteration 19800 (11.9812 iter/s, 8.3464s/100 iters), loss = 0.339061
I1007 10:35:29.709048  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.339061 (* 1 = 0.339061 loss)
I1007 10:35:29.709064  4720 sgd_solver.cpp:105] Iteration 19800, lr = 0.1
I1007 10:35:38.054554  4720 solver.cpp:218] Iteration 19900 (11.9825 iter/s, 8.34548s/100 iters), loss = 0.259517
I1007 10:35:38.054584  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.259517 (* 1 = 0.259517 loss)
I1007 10:35:38.054600  4720 sgd_solver.cpp:105] Iteration 19900, lr = 0.1
I1007 10:35:45.993216  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:35:46.327433  4720 solver.cpp:330] Iteration 20000, Testing net (#0)
I1007 10:35:48.260565  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:35:48.340875  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7962
I1007 10:35:48.340900  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.625028 (* 1 = 0.625028 loss)
I1007 10:35:48.424077  4720 solver.cpp:218] Iteration 20000 (9.64371 iter/s, 10.3695s/100 iters), loss = 0.207889
I1007 10:35:48.424104  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.207889 (* 1 = 0.207889 loss)
I1007 10:35:48.424110  4720 sgd_solver.cpp:105] Iteration 20000, lr = 0.1
I1007 10:35:56.763779  4720 solver.cpp:218] Iteration 20100 (11.9909 iter/s, 8.33965s/100 iters), loss = 0.271665
I1007 10:35:56.763820  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.271665 (* 1 = 0.271665 loss)
I1007 10:35:56.763825  4720 sgd_solver.cpp:105] Iteration 20100, lr = 0.1
I1007 10:36:05.108418  4720 solver.cpp:218] Iteration 20200 (11.9838 iter/s, 8.34457s/100 iters), loss = 0.260453
I1007 10:36:05.108448  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.260454 (* 1 = 0.260454 loss)
I1007 10:36:05.108453  4720 sgd_solver.cpp:105] Iteration 20200, lr = 0.1
I1007 10:36:13.446929  4720 solver.cpp:218] Iteration 20300 (11.9926 iter/s, 8.33845s/100 iters), loss = 0.25175
I1007 10:36:13.446957  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.25175 (* 1 = 0.25175 loss)
I1007 10:36:13.446964  4720 sgd_solver.cpp:105] Iteration 20300, lr = 0.1
I1007 10:36:21.787498  4720 solver.cpp:218] Iteration 20400 (11.9897 iter/s, 8.34051s/100 iters), loss = 0.181807
I1007 10:36:21.787597  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.181807 (* 1 = 0.181807 loss)
I1007 10:36:21.787605  4720 sgd_solver.cpp:105] Iteration 20400, lr = 0.1
I1007 10:36:29.718340  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:36:30.051327  4720 solver.cpp:330] Iteration 20500, Testing net (#0)
I1007 10:36:31.984246  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:36:32.064596  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.814
I1007 10:36:32.064632  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.570041 (* 1 = 0.570041 loss)
I1007 10:36:32.148607  4720 solver.cpp:218] Iteration 20500 (9.6516 iter/s, 10.361s/100 iters), loss = 0.176643
I1007 10:36:32.148638  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.176643 (* 1 = 0.176643 loss)
I1007 10:36:32.148644  4720 sgd_solver.cpp:105] Iteration 20500, lr = 0.1
I1007 10:36:40.503257  4720 solver.cpp:218] Iteration 20600 (11.9695 iter/s, 8.35459s/100 iters), loss = 0.229993
I1007 10:36:40.503298  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.229993 (* 1 = 0.229993 loss)
I1007 10:36:40.503304  4720 sgd_solver.cpp:105] Iteration 20600, lr = 0.1
I1007 10:36:48.851058  4720 solver.cpp:218] Iteration 20700 (11.9793 iter/s, 8.34773s/100 iters), loss = 0.35515
I1007 10:36:48.851088  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.35515 (* 1 = 0.35515 loss)
I1007 10:36:48.851092  4720 sgd_solver.cpp:105] Iteration 20700, lr = 0.1
I1007 10:36:57.202606  4720 solver.cpp:218] Iteration 20800 (11.9739 iter/s, 8.35149s/100 iters), loss = 0.220122
I1007 10:36:57.202744  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.220122 (* 1 = 0.220122 loss)
I1007 10:36:57.202751  4720 sgd_solver.cpp:105] Iteration 20800, lr = 0.1
I1007 10:37:05.549832  4720 solver.cpp:218] Iteration 20900 (11.9803 iter/s, 8.34706s/100 iters), loss = 0.191093
I1007 10:37:05.549861  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.191093 (* 1 = 0.191093 loss)
I1007 10:37:05.549867  4720 sgd_solver.cpp:105] Iteration 20900, lr = 0.1
I1007 10:37:13.482465  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:37:13.816124  4720 solver.cpp:330] Iteration 21000, Testing net (#0)
I1007 10:37:15.749785  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:37:15.830468  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7233
I1007 10:37:15.830503  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.954488 (* 1 = 0.954488 loss)
I1007 10:37:15.913955  4720 solver.cpp:218] Iteration 21000 (9.64873 iter/s, 10.3641s/100 iters), loss = 0.189646
I1007 10:37:15.913985  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.189646 (* 1 = 0.189646 loss)
I1007 10:37:15.913990  4720 sgd_solver.cpp:105] Iteration 21000, lr = 0.1
I1007 10:37:24.260044  4720 solver.cpp:218] Iteration 21100 (11.9817 iter/s, 8.34603s/100 iters), loss = 0.217811
I1007 10:37:24.260074  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.217811 (* 1 = 0.217811 loss)
I1007 10:37:24.260080  4720 sgd_solver.cpp:105] Iteration 21100, lr = 0.1
I1007 10:37:32.607384  4720 solver.cpp:218] Iteration 21200 (11.9799 iter/s, 8.34728s/100 iters), loss = 0.236507
I1007 10:37:32.607494  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.236507 (* 1 = 0.236507 loss)
I1007 10:37:32.607502  4720 sgd_solver.cpp:105] Iteration 21200, lr = 0.1
I1007 10:37:40.954963  4720 solver.cpp:218] Iteration 21300 (11.9797 iter/s, 8.34744s/100 iters), loss = 0.304641
I1007 10:37:40.954993  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.304641 (* 1 = 0.304641 loss)
I1007 10:37:40.954998  4720 sgd_solver.cpp:105] Iteration 21300, lr = 0.1
I1007 10:37:49.302067  4720 solver.cpp:218] Iteration 21400 (11.9803 iter/s, 8.34704s/100 iters), loss = 0.293219
I1007 10:37:49.302095  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.293219 (* 1 = 0.293219 loss)
I1007 10:37:49.302101  4720 sgd_solver.cpp:105] Iteration 21400, lr = 0.1
I1007 10:37:57.235391  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:37:57.568872  4720 solver.cpp:330] Iteration 21500, Testing net (#0)
I1007 10:37:59.502154  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:37:59.583135  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8041
I1007 10:37:59.583174  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.613853 (* 1 = 0.613853 loss)
I1007 10:37:59.667417  4720 solver.cpp:218] Iteration 21500 (9.64759 iter/s, 10.3653s/100 iters), loss = 0.157785
I1007 10:37:59.667448  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.157786 (* 1 = 0.157786 loss)
I1007 10:37:59.667454  4720 sgd_solver.cpp:105] Iteration 21500, lr = 0.1
I1007 10:38:08.013873  4720 solver.cpp:218] Iteration 21600 (11.9812 iter/s, 8.3464s/100 iters), loss = 0.24379
I1007 10:38:08.014008  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.24379 (* 1 = 0.24379 loss)
I1007 10:38:08.014015  4720 sgd_solver.cpp:105] Iteration 21600, lr = 0.1
I1007 10:38:16.355612  4720 solver.cpp:218] Iteration 21700 (11.9881 iter/s, 8.34159s/100 iters), loss = 0.328328
I1007 10:38:16.355641  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.328328 (* 1 = 0.328328 loss)
I1007 10:38:16.355648  4720 sgd_solver.cpp:105] Iteration 21700, lr = 0.1
I1007 10:38:24.706707  4720 solver.cpp:218] Iteration 21800 (11.9746 iter/s, 8.35104s/100 iters), loss = 0.203396
I1007 10:38:24.706737  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.203396 (* 1 = 0.203396 loss)
I1007 10:38:24.706742  4720 sgd_solver.cpp:105] Iteration 21800, lr = 0.1
I1007 10:38:33.052513  4720 solver.cpp:218] Iteration 21900 (11.9821 iter/s, 8.34575s/100 iters), loss = 0.230772
I1007 10:38:33.052543  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.230772 (* 1 = 0.230772 loss)
I1007 10:38:33.052548  4720 sgd_solver.cpp:105] Iteration 21900, lr = 0.1
I1007 10:38:40.989332  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:38:41.325031  4720 solver.cpp:330] Iteration 22000, Testing net (#0)
I1007 10:38:43.257390  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:38:43.337898  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7425
I1007 10:38:43.337934  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.782265 (* 1 = 0.782265 loss)
I1007 10:38:43.421270  4720 solver.cpp:218] Iteration 22000 (9.64442 iter/s, 10.3687s/100 iters), loss = 0.216729
I1007 10:38:43.421298  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.216729 (* 1 = 0.216729 loss)
I1007 10:38:43.421303  4720 sgd_solver.cpp:105] Iteration 22000, lr = 0.1
I1007 10:38:51.754626  4720 solver.cpp:218] Iteration 22100 (12 iter/s, 8.3333s/100 iters), loss = 0.167701
I1007 10:38:51.754667  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.167701 (* 1 = 0.167701 loss)
I1007 10:38:51.754672  4720 sgd_solver.cpp:105] Iteration 22100, lr = 0.1
I1007 10:39:00.089599  4720 solver.cpp:218] Iteration 22200 (11.9977 iter/s, 8.33491s/100 iters), loss = 0.216567
I1007 10:39:00.089639  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.216567 (* 1 = 0.216567 loss)
I1007 10:39:00.089644  4720 sgd_solver.cpp:105] Iteration 22200, lr = 0.1
I1007 10:39:08.426056  4720 solver.cpp:218] Iteration 22300 (11.9956 iter/s, 8.33639s/100 iters), loss = 0.20787
I1007 10:39:08.426103  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.20787 (* 1 = 0.20787 loss)
I1007 10:39:08.426110  4720 sgd_solver.cpp:105] Iteration 22300, lr = 0.1
I1007 10:39:16.771214  4720 solver.cpp:218] Iteration 22400 (11.9831 iter/s, 8.34508s/100 iters), loss = 0.180671
I1007 10:39:16.771291  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.180671 (* 1 = 0.180671 loss)
I1007 10:39:16.771297  4720 sgd_solver.cpp:105] Iteration 22400, lr = 0.1
I1007 10:39:24.700685  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:39:25.035931  4720 solver.cpp:330] Iteration 22500, Testing net (#0)
I1007 10:39:26.967756  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:39:27.048321  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7397
I1007 10:39:27.048355  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.920942 (* 1 = 0.920942 loss)
I1007 10:39:27.132515  4720 solver.cpp:218] Iteration 22500 (9.6514 iter/s, 10.3612s/100 iters), loss = 0.173039
I1007 10:39:27.132544  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.173039 (* 1 = 0.173039 loss)
I1007 10:39:27.132551  4720 sgd_solver.cpp:105] Iteration 22500, lr = 0.1
I1007 10:39:35.482712  4720 solver.cpp:218] Iteration 22600 (11.9758 iter/s, 8.35014s/100 iters), loss = 0.202765
I1007 10:39:35.482740  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.202765 (* 1 = 0.202765 loss)
I1007 10:39:35.482746  4720 sgd_solver.cpp:105] Iteration 22600, lr = 0.1
I1007 10:39:43.817642  4720 solver.cpp:218] Iteration 22700 (11.9978 iter/s, 8.33487s/100 iters), loss = 0.214941
I1007 10:39:43.817682  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.214941 (* 1 = 0.214941 loss)
I1007 10:39:43.817687  4720 sgd_solver.cpp:105] Iteration 22700, lr = 0.1
I1007 10:39:52.161200  4720 solver.cpp:218] Iteration 22800 (11.9854 iter/s, 8.34349s/100 iters), loss = 0.190591
I1007 10:39:52.161295  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.190591 (* 1 = 0.190591 loss)
I1007 10:39:52.161303  4720 sgd_solver.cpp:105] Iteration 22800, lr = 0.1
I1007 10:40:00.503672  4720 solver.cpp:218] Iteration 22900 (11.987 iter/s, 8.34235s/100 iters), loss = 0.232637
I1007 10:40:00.503718  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.232637 (* 1 = 0.232637 loss)
I1007 10:40:00.503726  4720 sgd_solver.cpp:105] Iteration 22900, lr = 0.1
I1007 10:40:08.434957  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:40:08.768327  4720 solver.cpp:330] Iteration 23000, Testing net (#0)
I1007 10:40:10.702183  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:40:10.783352  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8115
I1007 10:40:10.783387  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.578842 (* 1 = 0.578842 loss)
I1007 10:40:10.866286  4720 solver.cpp:218] Iteration 23000 (9.65015 iter/s, 10.3625s/100 iters), loss = 0.131121
I1007 10:40:10.866312  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.131121 (* 1 = 0.131121 loss)
I1007 10:40:10.866318  4720 sgd_solver.cpp:105] Iteration 23000, lr = 0.1
I1007 10:40:19.218652  4720 solver.cpp:218] Iteration 23100 (11.9727 iter/s, 8.35231s/100 iters), loss = 0.178581
I1007 10:40:19.218693  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.178581 (* 1 = 0.178581 loss)
I1007 10:40:19.218698  4720 sgd_solver.cpp:105] Iteration 23100, lr = 0.1
I1007 10:40:27.571427  4720 solver.cpp:218] Iteration 23200 (11.9722 iter/s, 8.35271s/100 iters), loss = 0.201932
I1007 10:40:27.571550  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.201932 (* 1 = 0.201932 loss)
I1007 10:40:27.571568  4720 sgd_solver.cpp:105] Iteration 23200, lr = 0.1
I1007 10:40:35.923410  4720 solver.cpp:218] Iteration 23300 (11.9734 iter/s, 8.35184s/100 iters), loss = 0.276614
I1007 10:40:35.923451  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.276614 (* 1 = 0.276614 loss)
I1007 10:40:35.923457  4720 sgd_solver.cpp:105] Iteration 23300, lr = 0.1
I1007 10:40:44.272457  4720 solver.cpp:218] Iteration 23400 (11.9775 iter/s, 8.34898s/100 iters), loss = 0.174173
I1007 10:40:44.272497  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.174174 (* 1 = 0.174174 loss)
I1007 10:40:44.272503  4720 sgd_solver.cpp:105] Iteration 23400, lr = 0.1
I1007 10:40:52.204140  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:40:52.539978  4720 solver.cpp:330] Iteration 23500, Testing net (#0)
I1007 10:40:54.473726  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:40:54.554081  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8056
I1007 10:40:54.554117  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.619535 (* 1 = 0.619535 loss)
I1007 10:40:54.638187  4720 solver.cpp:218] Iteration 23500 (9.64724 iter/s, 10.3657s/100 iters), loss = 0.175772
I1007 10:40:54.638216  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.175772 (* 1 = 0.175772 loss)
I1007 10:40:54.638222  4720 sgd_solver.cpp:105] Iteration 23500, lr = 0.1
I1007 10:41:02.980971  4720 solver.cpp:218] Iteration 23600 (11.9865 iter/s, 8.34272s/100 iters), loss = 0.22044
I1007 10:41:02.981055  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.22044 (* 1 = 0.22044 loss)
I1007 10:41:02.981072  4720 sgd_solver.cpp:105] Iteration 23600, lr = 0.1
I1007 10:41:11.319380  4720 solver.cpp:218] Iteration 23700 (11.9929 iter/s, 8.3383s/100 iters), loss = 0.268097
I1007 10:41:11.319412  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.268097 (* 1 = 0.268097 loss)
I1007 10:41:11.319418  4720 sgd_solver.cpp:105] Iteration 23700, lr = 0.1
I1007 10:41:19.669355  4720 solver.cpp:218] Iteration 23800 (11.9762 iter/s, 8.34992s/100 iters), loss = 0.286582
I1007 10:41:19.669386  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.286582 (* 1 = 0.286582 loss)
I1007 10:41:19.669391  4720 sgd_solver.cpp:105] Iteration 23800, lr = 0.1
I1007 10:41:28.007402  4720 solver.cpp:218] Iteration 23900 (11.9933 iter/s, 8.33799s/100 iters), loss = 0.306986
I1007 10:41:28.007442  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.306986 (* 1 = 0.306986 loss)
I1007 10:41:28.007448  4720 sgd_solver.cpp:105] Iteration 23900, lr = 0.1
I1007 10:41:35.946449  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:41:36.280839  4720 solver.cpp:330] Iteration 24000, Testing net (#0)
I1007 10:41:38.214588  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:41:38.295125  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.801
I1007 10:41:38.295151  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.593584 (* 1 = 0.593584 loss)
I1007 10:41:38.378372  4720 solver.cpp:218] Iteration 24000 (9.64237 iter/s, 10.3709s/100 iters), loss = 0.179674
I1007 10:41:38.378401  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.179674 (* 1 = 0.179674 loss)
I1007 10:41:38.378408  4720 sgd_solver.cpp:105] Iteration 24000, lr = 0.1
I1007 10:41:46.721325  4720 solver.cpp:218] Iteration 24100 (11.9862 iter/s, 8.34289s/100 iters), loss = 0.124988
I1007 10:41:46.721366  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.124988 (* 1 = 0.124988 loss)
I1007 10:41:46.721372  4720 sgd_solver.cpp:105] Iteration 24100, lr = 0.1
I1007 10:41:55.075492  4720 solver.cpp:218] Iteration 24200 (11.9702 iter/s, 8.3541s/100 iters), loss = 0.275551
I1007 10:41:55.075533  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.275551 (* 1 = 0.275551 loss)
I1007 10:41:55.075539  4720 sgd_solver.cpp:105] Iteration 24200, lr = 0.1
I1007 10:42:03.421627  4720 solver.cpp:218] Iteration 24300 (11.9817 iter/s, 8.34607s/100 iters), loss = 0.28901
I1007 10:42:03.421656  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.28901 (* 1 = 0.28901 loss)
I1007 10:42:03.421661  4720 sgd_solver.cpp:105] Iteration 24300, lr = 0.1
I1007 10:42:11.772435  4720 solver.cpp:218] Iteration 24400 (11.975 iter/s, 8.35075s/100 iters), loss = 0.208913
I1007 10:42:11.772557  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.208913 (* 1 = 0.208913 loss)
I1007 10:42:11.772573  4720 sgd_solver.cpp:105] Iteration 24400, lr = 0.1
I1007 10:42:19.701218  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:42:20.035234  4720 solver.cpp:330] Iteration 24500, Testing net (#0)
I1007 10:42:21.968575  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:42:22.049392  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7419
I1007 10:42:22.049427  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.858325 (* 1 = 0.858325 loss)
I1007 10:42:22.133396  4720 solver.cpp:218] Iteration 24500 (9.65175 iter/s, 10.3608s/100 iters), loss = 0.249765
I1007 10:42:22.133425  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.249765 (* 1 = 0.249765 loss)
I1007 10:42:22.133432  4720 sgd_solver.cpp:105] Iteration 24500, lr = 0.1
I1007 10:42:30.487740  4720 solver.cpp:218] Iteration 24600 (11.9699 iter/s, 8.35429s/100 iters), loss = 0.196737
I1007 10:42:30.487782  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.196737 (* 1 = 0.196737 loss)
I1007 10:42:30.487787  4720 sgd_solver.cpp:105] Iteration 24600, lr = 0.1
I1007 10:42:38.826289  4720 solver.cpp:218] Iteration 24700 (11.9926 iter/s, 8.33848s/100 iters), loss = 0.237428
I1007 10:42:38.826331  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.237428 (* 1 = 0.237428 loss)
I1007 10:42:38.826337  4720 sgd_solver.cpp:105] Iteration 24700, lr = 0.1
I1007 10:42:47.179461  4720 solver.cpp:218] Iteration 24800 (11.9716 iter/s, 8.3531s/100 iters), loss = 0.244418
I1007 10:42:47.179563  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.244418 (* 1 = 0.244418 loss)
I1007 10:42:47.179580  4720 sgd_solver.cpp:105] Iteration 24800, lr = 0.1
I1007 10:42:55.530892  4720 solver.cpp:218] Iteration 24900 (11.9742 iter/s, 8.35131s/100 iters), loss = 0.289559
I1007 10:42:55.530932  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.289559 (* 1 = 0.289559 loss)
I1007 10:42:55.530937  4720 sgd_solver.cpp:105] Iteration 24900, lr = 0.1
I1007 10:43:03.467178  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:43:03.801615  4720 solver.cpp:330] Iteration 25000, Testing net (#0)
I1007 10:43:05.735069  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:43:05.815845  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7928
I1007 10:43:05.815879  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.695645 (* 1 = 0.695645 loss)
I1007 10:43:05.899375  4720 solver.cpp:218] Iteration 25000 (9.64468 iter/s, 10.3684s/100 iters), loss = 0.181812
I1007 10:43:05.899405  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.181813 (* 1 = 0.181813 loss)
I1007 10:43:05.899412  4720 sgd_solver.cpp:105] Iteration 25000, lr = 0.1
I1007 10:43:14.242861  4720 solver.cpp:218] Iteration 25100 (11.9855 iter/s, 8.34343s/100 iters), loss = 0.149268
I1007 10:43:14.242902  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.149268 (* 1 = 0.149268 loss)
I1007 10:43:14.242908  4720 sgd_solver.cpp:105] Iteration 25100, lr = 0.1
I1007 10:43:22.594686  4720 solver.cpp:218] Iteration 25200 (11.9735 iter/s, 8.35176s/100 iters), loss = 0.290361
I1007 10:43:22.594826  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.290361 (* 1 = 0.290361 loss)
I1007 10:43:22.594833  4720 sgd_solver.cpp:105] Iteration 25200, lr = 0.1
I1007 10:43:30.945797  4720 solver.cpp:218] Iteration 25300 (11.9747 iter/s, 8.35095s/100 iters), loss = 0.226242
I1007 10:43:30.945838  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.226242 (* 1 = 0.226242 loss)
I1007 10:43:30.945843  4720 sgd_solver.cpp:105] Iteration 25300, lr = 0.1
I1007 10:43:39.297003  4720 solver.cpp:218] Iteration 25400 (11.9744 iter/s, 8.35114s/100 iters), loss = 0.271528
I1007 10:43:39.297044  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.271528 (* 1 = 0.271528 loss)
I1007 10:43:39.297050  4720 sgd_solver.cpp:105] Iteration 25400, lr = 0.1
I1007 10:43:47.236611  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:43:47.571416  4720 solver.cpp:330] Iteration 25500, Testing net (#0)
I1007 10:43:49.504214  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:43:49.584939  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.822
I1007 10:43:49.584975  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.531353 (* 1 = 0.531353 loss)
I1007 10:43:49.671226  4720 solver.cpp:218] Iteration 25500 (9.63935 iter/s, 10.3741s/100 iters), loss = 0.145644
I1007 10:43:49.671255  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.145644 (* 1 = 0.145644 loss)
I1007 10:43:49.671263  4720 sgd_solver.cpp:105] Iteration 25500, lr = 0.1
I1007 10:43:58.027844  4720 solver.cpp:218] Iteration 25600 (11.9666 iter/s, 8.35656s/100 iters), loss = 0.314755
I1007 10:43:58.027948  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.314755 (* 1 = 0.314755 loss)
I1007 10:43:58.027956  4720 sgd_solver.cpp:105] Iteration 25600, lr = 0.1
I1007 10:44:06.380456  4720 solver.cpp:218] Iteration 25700 (11.9725 iter/s, 8.35248s/100 iters), loss = 0.458396
I1007 10:44:06.380487  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.458396 (* 1 = 0.458396 loss)
I1007 10:44:06.380493  4720 sgd_solver.cpp:105] Iteration 25700, lr = 0.1
I1007 10:44:14.737335  4720 solver.cpp:218] Iteration 25800 (11.9663 iter/s, 8.35682s/100 iters), loss = 0.215164
I1007 10:44:14.737370  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.215164 (* 1 = 0.215164 loss)
I1007 10:44:14.737376  4720 sgd_solver.cpp:105] Iteration 25800, lr = 0.1
I1007 10:44:23.089969  4720 solver.cpp:218] Iteration 25900 (11.9724 iter/s, 8.35257s/100 iters), loss = 0.224778
I1007 10:44:23.090010  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.224778 (* 1 = 0.224778 loss)
I1007 10:44:23.090015  4720 sgd_solver.cpp:105] Iteration 25900, lr = 0.1
I1007 10:44:31.035991  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:44:31.370853  4720 solver.cpp:330] Iteration 26000, Testing net (#0)
I1007 10:44:33.304023  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:44:33.384804  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6791
I1007 10:44:33.384840  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.15708 (* 1 = 1.15708 loss)
I1007 10:44:33.468046  4720 solver.cpp:218] Iteration 26000 (9.63577 iter/s, 10.378s/100 iters), loss = 0.214705
I1007 10:44:33.468075  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.214705 (* 1 = 0.214705 loss)
I1007 10:44:33.468082  4720 sgd_solver.cpp:105] Iteration 26000, lr = 0.1
I1007 10:44:41.823103  4720 solver.cpp:218] Iteration 26100 (11.9689 iter/s, 8.355s/100 iters), loss = 0.188427
I1007 10:44:41.823143  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.188427 (* 1 = 0.188427 loss)
I1007 10:44:41.823148  4720 sgd_solver.cpp:105] Iteration 26100, lr = 0.1
I1007 10:44:50.176764  4720 solver.cpp:218] Iteration 26200 (11.9709 iter/s, 8.35359s/100 iters), loss = 0.254593
I1007 10:44:50.176803  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.254593 (* 1 = 0.254593 loss)
I1007 10:44:50.176810  4720 sgd_solver.cpp:105] Iteration 26200, lr = 0.1
I1007 10:44:58.516839  4720 solver.cpp:218] Iteration 26300 (11.9904 iter/s, 8.34001s/100 iters), loss = 0.275948
I1007 10:44:58.516885  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.275948 (* 1 = 0.275948 loss)
I1007 10:44:58.516892  4720 sgd_solver.cpp:105] Iteration 26300, lr = 0.1
I1007 10:45:06.865224  4720 solver.cpp:218] Iteration 26400 (11.9785 iter/s, 8.34831s/100 iters), loss = 0.135592
I1007 10:45:06.865363  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.135592 (* 1 = 0.135592 loss)
I1007 10:45:06.865370  4720 sgd_solver.cpp:105] Iteration 26400, lr = 0.1
I1007 10:45:14.789618  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:45:15.123338  4720 solver.cpp:330] Iteration 26500, Testing net (#0)
I1007 10:45:17.056824  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:45:17.138054  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7644
I1007 10:45:17.138088  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.797362 (* 1 = 0.797362 loss)
I1007 10:45:17.221580  4720 solver.cpp:218] Iteration 26500 (9.65606 iter/s, 10.3562s/100 iters), loss = 0.181339
I1007 10:45:17.221611  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.181339 (* 1 = 0.181339 loss)
I1007 10:45:17.221616  4720 sgd_solver.cpp:105] Iteration 26500, lr = 0.1
I1007 10:45:25.579695  4720 solver.cpp:218] Iteration 26600 (11.9645 iter/s, 8.35806s/100 iters), loss = 0.187042
I1007 10:45:25.579736  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.187042 (* 1 = 0.187042 loss)
I1007 10:45:25.579741  4720 sgd_solver.cpp:105] Iteration 26600, lr = 0.1
I1007 10:45:33.927909  4720 solver.cpp:218] Iteration 26700 (11.9787 iter/s, 8.34815s/100 iters), loss = 0.275686
I1007 10:45:33.927950  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.275686 (* 1 = 0.275686 loss)
I1007 10:45:33.927955  4720 sgd_solver.cpp:105] Iteration 26700, lr = 0.1
I1007 10:45:42.287633  4720 solver.cpp:218] Iteration 26800 (11.9622 iter/s, 8.35966s/100 iters), loss = 0.291902
I1007 10:45:42.287778  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.291902 (* 1 = 0.291902 loss)
I1007 10:45:42.287787  4720 sgd_solver.cpp:105] Iteration 26800, lr = 0.1
I1007 10:45:50.636179  4720 solver.cpp:218] Iteration 26900 (11.9784 iter/s, 8.34838s/100 iters), loss = 0.270992
I1007 10:45:50.636220  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.270992 (* 1 = 0.270992 loss)
I1007 10:45:50.636225  4720 sgd_solver.cpp:105] Iteration 26900, lr = 0.1
I1007 10:45:58.576059  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:45:58.910490  4720 solver.cpp:330] Iteration 27000, Testing net (#0)
I1007 10:46:00.845866  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:46:00.926431  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7219
I1007 10:46:00.926466  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.13589 (* 1 = 1.13589 loss)
I1007 10:46:01.009158  4720 solver.cpp:218] Iteration 27000 (9.6405 iter/s, 10.3729s/100 iters), loss = 0.161209
I1007 10:46:01.009186  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.161209 (* 1 = 0.161209 loss)
I1007 10:46:01.009192  4720 sgd_solver.cpp:105] Iteration 27000, lr = 0.1
I1007 10:46:09.357215  4720 solver.cpp:218] Iteration 27100 (11.9789 iter/s, 8.348s/100 iters), loss = 0.201534
I1007 10:46:09.357255  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.201534 (* 1 = 0.201534 loss)
I1007 10:46:09.357261  4720 sgd_solver.cpp:105] Iteration 27100, lr = 0.1
I1007 10:46:17.712193  4720 solver.cpp:218] Iteration 27200 (11.969 iter/s, 8.35491s/100 iters), loss = 0.280154
I1007 10:46:17.712323  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.280154 (* 1 = 0.280154 loss)
I1007 10:46:17.712330  4720 sgd_solver.cpp:105] Iteration 27200, lr = 0.1
I1007 10:46:26.064832  4720 solver.cpp:218] Iteration 27300 (11.9725 iter/s, 8.35248s/100 iters), loss = 0.250795
I1007 10:46:26.064872  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.250796 (* 1 = 0.250796 loss)
I1007 10:46:26.064878  4720 sgd_solver.cpp:105] Iteration 27300, lr = 0.1
I1007 10:46:34.418540  4720 solver.cpp:218] Iteration 27400 (11.9708 iter/s, 8.35364s/100 iters), loss = 0.170607
I1007 10:46:34.418586  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.170607 (* 1 = 0.170607 loss)
I1007 10:46:34.418593  4720 sgd_solver.cpp:105] Iteration 27400, lr = 0.1
I1007 10:46:42.351727  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:46:42.685696  4720 solver.cpp:330] Iteration 27500, Testing net (#0)
I1007 10:46:44.618716  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:46:44.699091  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8131
I1007 10:46:44.699127  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.586156 (* 1 = 0.586156 loss)
I1007 10:46:44.783017  4720 solver.cpp:218] Iteration 27500 (9.64841 iter/s, 10.3644s/100 iters), loss = 0.245572
I1007 10:46:44.783052  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.245572 (* 1 = 0.245572 loss)
I1007 10:46:44.783061  4720 sgd_solver.cpp:105] Iteration 27500, lr = 0.1
I1007 10:46:53.139950  4720 solver.cpp:218] Iteration 27600 (11.9662 iter/s, 8.35687s/100 iters), loss = 0.200613
I1007 10:46:53.140072  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.200613 (* 1 = 0.200613 loss)
I1007 10:46:53.140090  4720 sgd_solver.cpp:105] Iteration 27600, lr = 0.1
I1007 10:47:01.488607  4720 solver.cpp:218] Iteration 27700 (11.9782 iter/s, 8.34851s/100 iters), loss = 0.268397
I1007 10:47:01.488647  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.268397 (* 1 = 0.268397 loss)
I1007 10:47:01.488653  4720 sgd_solver.cpp:105] Iteration 27700, lr = 0.1
I1007 10:47:09.840585  4720 solver.cpp:218] Iteration 27800 (11.9733 iter/s, 8.35191s/100 iters), loss = 0.276026
I1007 10:47:09.840616  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.276027 (* 1 = 0.276027 loss)
I1007 10:47:09.840622  4720 sgd_solver.cpp:105] Iteration 27800, lr = 0.1
I1007 10:47:18.189558  4720 solver.cpp:218] Iteration 27900 (11.9776 iter/s, 8.34891s/100 iters), loss = 0.135519
I1007 10:47:18.189596  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.135519 (* 1 = 0.135519 loss)
I1007 10:47:18.189602  4720 sgd_solver.cpp:105] Iteration 27900, lr = 0.1
I1007 10:47:26.131513  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:47:26.466202  4720 solver.cpp:330] Iteration 28000, Testing net (#0)
I1007 10:47:28.399996  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:47:28.480859  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7911
I1007 10:47:28.480885  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.698314 (* 1 = 0.698314 loss)
I1007 10:47:28.563740  4720 solver.cpp:218] Iteration 28000 (9.63938 iter/s, 10.3741s/100 iters), loss = 0.191694
I1007 10:47:28.563768  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.191694 (* 1 = 0.191694 loss)
I1007 10:47:28.563774  4720 sgd_solver.cpp:105] Iteration 28000, lr = 0.1
I1007 10:47:36.904963  4720 solver.cpp:218] Iteration 28100 (11.9887 iter/s, 8.34117s/100 iters), loss = 0.19198
I1007 10:47:36.905004  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.19198 (* 1 = 0.19198 loss)
I1007 10:47:36.905010  4720 sgd_solver.cpp:105] Iteration 28100, lr = 0.1
I1007 10:47:45.253589  4720 solver.cpp:218] Iteration 28200 (11.9781 iter/s, 8.34856s/100 iters), loss = 0.277587
I1007 10:47:45.253631  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.277587 (* 1 = 0.277587 loss)
I1007 10:47:45.253638  4720 sgd_solver.cpp:105] Iteration 28200, lr = 0.1
I1007 10:47:53.605125  4720 solver.cpp:218] Iteration 28300 (11.9739 iter/s, 8.35147s/100 iters), loss = 0.356946
I1007 10:47:53.605165  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.356946 (* 1 = 0.356946 loss)
I1007 10:47:53.605170  4720 sgd_solver.cpp:105] Iteration 28300, lr = 0.1
I1007 10:48:01.965925  4720 solver.cpp:218] Iteration 28400 (11.9607 iter/s, 8.36073s/100 iters), loss = 0.212201
I1007 10:48:01.966017  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.212201 (* 1 = 0.212201 loss)
I1007 10:48:01.966033  4720 sgd_solver.cpp:105] Iteration 28400, lr = 0.1
I1007 10:48:09.903220  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:48:10.238979  4720 solver.cpp:330] Iteration 28500, Testing net (#0)
I1007 10:48:12.170954  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:48:12.251796  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8153
I1007 10:48:12.251830  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.588149 (* 1 = 0.588149 loss)
I1007 10:48:12.335599  4720 solver.cpp:218] Iteration 28500 (9.64362 iter/s, 10.3695s/100 iters), loss = 0.173468
I1007 10:48:12.335630  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.173468 (* 1 = 0.173468 loss)
I1007 10:48:12.335638  4720 sgd_solver.cpp:105] Iteration 28500, lr = 0.1
I1007 10:48:20.696519  4720 solver.cpp:218] Iteration 28600 (11.9605 iter/s, 8.36086s/100 iters), loss = 0.157114
I1007 10:48:20.696560  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.157114 (* 1 = 0.157114 loss)
I1007 10:48:20.696566  4720 sgd_solver.cpp:105] Iteration 28600, lr = 0.1
I1007 10:48:29.048056  4720 solver.cpp:218] Iteration 28700 (11.9739 iter/s, 8.35147s/100 iters), loss = 0.295908
I1007 10:48:29.048096  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.295908 (* 1 = 0.295908 loss)
I1007 10:48:29.048102  4720 sgd_solver.cpp:105] Iteration 28700, lr = 0.1
I1007 10:48:37.408109  4720 solver.cpp:218] Iteration 28800 (11.9617 iter/s, 8.35999s/100 iters), loss = 0.183987
I1007 10:48:37.408216  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.183987 (* 1 = 0.183987 loss)
I1007 10:48:37.408232  4720 sgd_solver.cpp:105] Iteration 28800, lr = 0.1
I1007 10:48:45.764109  4720 solver.cpp:218] Iteration 28900 (11.9676 iter/s, 8.35588s/100 iters), loss = 0.191883
I1007 10:48:45.764138  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.191883 (* 1 = 0.191883 loss)
I1007 10:48:45.764144  4720 sgd_solver.cpp:105] Iteration 28900, lr = 0.1
I1007 10:48:53.708652  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:48:54.042362  4720 solver.cpp:330] Iteration 29000, Testing net (#0)
I1007 10:48:55.976044  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:48:56.056519  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7245
I1007 10:48:56.056552  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.975935 (* 1 = 0.975935 loss)
I1007 10:48:56.139358  4720 solver.cpp:218] Iteration 29000 (9.63838 iter/s, 10.3752s/100 iters), loss = 0.249496
I1007 10:48:56.139385  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.249496 (* 1 = 0.249496 loss)
I1007 10:48:56.139391  4720 sgd_solver.cpp:105] Iteration 29000, lr = 0.1
I1007 10:49:04.490504  4720 solver.cpp:218] Iteration 29100 (11.9745 iter/s, 8.35109s/100 iters), loss = 0.215197
I1007 10:49:04.490543  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.215197 (* 1 = 0.215197 loss)
I1007 10:49:04.490550  4720 sgd_solver.cpp:105] Iteration 29100, lr = 0.1
I1007 10:49:12.846276  4720 solver.cpp:218] Iteration 29200 (11.9679 iter/s, 8.35571s/100 iters), loss = 0.187544
I1007 10:49:12.846372  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.187544 (* 1 = 0.187544 loss)
I1007 10:49:12.846379  4720 sgd_solver.cpp:105] Iteration 29200, lr = 0.1
I1007 10:49:21.200704  4720 solver.cpp:218] Iteration 29300 (11.9699 iter/s, 8.35431s/100 iters), loss = 0.263033
I1007 10:49:21.200734  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.263033 (* 1 = 0.263033 loss)
I1007 10:49:21.200740  4720 sgd_solver.cpp:105] Iteration 29300, lr = 0.1
I1007 10:49:29.550693  4720 solver.cpp:218] Iteration 29400 (11.9761 iter/s, 8.34993s/100 iters), loss = 0.259627
I1007 10:49:29.550731  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.259627 (* 1 = 0.259627 loss)
I1007 10:49:29.550737  4720 sgd_solver.cpp:105] Iteration 29400, lr = 0.1
I1007 10:49:37.486299  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:49:37.820926  4720 solver.cpp:330] Iteration 29500, Testing net (#0)
I1007 10:49:39.752676  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:49:39.833683  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8153
I1007 10:49:39.833708  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.56696 (* 1 = 0.56696 loss)
I1007 10:49:39.917381  4720 solver.cpp:218] Iteration 29500 (9.64635 iter/s, 10.3666s/100 iters), loss = 0.181756
I1007 10:49:39.917407  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.181756 (* 1 = 0.181756 loss)
I1007 10:49:39.917414  4720 sgd_solver.cpp:105] Iteration 29500, lr = 0.1
I1007 10:49:48.271634  4720 solver.cpp:218] Iteration 29600 (11.97 iter/s, 8.3542s/100 iters), loss = 0.200748
I1007 10:49:48.271730  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.200748 (* 1 = 0.200748 loss)
I1007 10:49:48.271747  4720 sgd_solver.cpp:105] Iteration 29600, lr = 0.1
I1007 10:49:56.620973  4720 solver.cpp:218] Iteration 29700 (11.9772 iter/s, 8.34922s/100 iters), loss = 0.15056
I1007 10:49:56.621002  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.15056 (* 1 = 0.15056 loss)
I1007 10:49:56.621008  4720 sgd_solver.cpp:105] Iteration 29700, lr = 0.1
I1007 10:50:04.967939  4720 solver.cpp:218] Iteration 29800 (11.9805 iter/s, 8.34691s/100 iters), loss = 0.156556
I1007 10:50:04.967968  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.156556 (* 1 = 0.156556 loss)
I1007 10:50:04.967974  4720 sgd_solver.cpp:105] Iteration 29800, lr = 0.1
I1007 10:50:13.311332  4720 solver.cpp:218] Iteration 29900 (11.9856 iter/s, 8.34334s/100 iters), loss = 0.196002
I1007 10:50:13.311362  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.196002 (* 1 = 0.196002 loss)
I1007 10:50:13.311368  4720 sgd_solver.cpp:105] Iteration 29900, lr = 0.1
I1007 10:50:21.247581  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:50:21.581341  4720 solver.cpp:330] Iteration 30000, Testing net (#0)
I1007 10:50:23.513478  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:50:23.594070  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7776
I1007 10:50:23.594108  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.6836 (* 1 = 0.6836 loss)
I1007 10:50:23.677433  4720 solver.cpp:218] Iteration 30000 (9.64688 iter/s, 10.366s/100 iters), loss = 0.122783
I1007 10:50:23.677461  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.122783 (* 1 = 0.122783 loss)
I1007 10:50:23.677469  4720 sgd_solver.cpp:105] Iteration 30000, lr = 0.1
I1007 10:50:32.025117  4720 solver.cpp:218] Iteration 30100 (11.9794 iter/s, 8.34763s/100 iters), loss = 0.133546
I1007 10:50:32.025146  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.133546 (* 1 = 0.133546 loss)
I1007 10:50:32.025151  4720 sgd_solver.cpp:105] Iteration 30100, lr = 0.1
I1007 10:50:40.384560  4720 solver.cpp:218] Iteration 30200 (11.9626 iter/s, 8.35939s/100 iters), loss = 0.225477
I1007 10:50:40.384590  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.225477 (* 1 = 0.225477 loss)
I1007 10:50:40.384598  4720 sgd_solver.cpp:105] Iteration 30200, lr = 0.1
I1007 10:50:48.733538  4720 solver.cpp:218] Iteration 30300 (11.9776 iter/s, 8.34892s/100 iters), loss = 0.27575
I1007 10:50:48.733567  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.27575 (* 1 = 0.27575 loss)
I1007 10:50:48.733573  4720 sgd_solver.cpp:105] Iteration 30300, lr = 0.1
I1007 10:50:57.090710  4720 solver.cpp:218] Iteration 30400 (11.9658 iter/s, 8.35712s/100 iters), loss = 0.207118
I1007 10:50:57.090870  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.207118 (* 1 = 0.207118 loss)
I1007 10:50:57.090878  4720 sgd_solver.cpp:105] Iteration 30400, lr = 0.1
I1007 10:51:05.015538  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:51:05.349697  4720 solver.cpp:330] Iteration 30500, Testing net (#0)
I1007 10:51:07.282063  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:51:07.362846  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7896
I1007 10:51:07.362884  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.684911 (* 1 = 0.684911 loss)
I1007 10:51:07.446693  4720 solver.cpp:218] Iteration 30500 (9.65643 iter/s, 10.3558s/100 iters), loss = 0.13535
I1007 10:51:07.446725  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.13535 (* 1 = 0.13535 loss)
I1007 10:51:07.446732  4720 sgd_solver.cpp:105] Iteration 30500, lr = 0.1
I1007 10:51:15.798054  4720 solver.cpp:218] Iteration 30600 (11.9742 iter/s, 8.3513s/100 iters), loss = 0.173721
I1007 10:51:15.798082  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.173721 (* 1 = 0.173721 loss)
I1007 10:51:15.798089  4720 sgd_solver.cpp:105] Iteration 30600, lr = 0.1
I1007 10:51:24.141680  4720 solver.cpp:218] Iteration 30700 (11.9853 iter/s, 8.34357s/100 iters), loss = 0.240269
I1007 10:51:24.141708  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.240269 (* 1 = 0.240269 loss)
I1007 10:51:24.141715  4720 sgd_solver.cpp:105] Iteration 30700, lr = 0.1
I1007 10:51:32.501581  4720 solver.cpp:218] Iteration 30800 (11.9619 iter/s, 8.35985s/100 iters), loss = 0.277364
I1007 10:51:32.501721  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.277365 (* 1 = 0.277365 loss)
I1007 10:51:32.501729  4720 sgd_solver.cpp:105] Iteration 30800, lr = 0.1
I1007 10:51:40.853554  4720 solver.cpp:218] Iteration 30900 (11.9735 iter/s, 8.35181s/100 iters), loss = 0.21078
I1007 10:51:40.853583  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.210781 (* 1 = 0.210781 loss)
I1007 10:51:40.853590  4720 sgd_solver.cpp:105] Iteration 30900, lr = 0.1
I1007 10:51:48.794020  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:51:49.126986  4720 solver.cpp:330] Iteration 31000, Testing net (#0)
I1007 10:51:51.060618  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:51:51.141342  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7536
I1007 10:51:51.141377  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.793258 (* 1 = 0.793258 loss)
I1007 10:51:51.224215  4720 solver.cpp:218] Iteration 31000 (9.64264 iter/s, 10.3706s/100 iters), loss = 0.100407
I1007 10:51:51.224241  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.100407 (* 1 = 0.100407 loss)
I1007 10:51:51.224248  4720 sgd_solver.cpp:105] Iteration 31000, lr = 0.1
I1007 10:51:59.577407  4720 solver.cpp:218] Iteration 31100 (11.9715 iter/s, 8.35314s/100 iters), loss = 0.213587
I1007 10:51:59.577455  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.213587 (* 1 = 0.213587 loss)
I1007 10:51:59.577461  4720 sgd_solver.cpp:105] Iteration 31100, lr = 0.1
I1007 10:52:07.930268  4720 solver.cpp:218] Iteration 31200 (11.9721 iter/s, 8.35279s/100 iters), loss = 0.205927
I1007 10:52:07.930392  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.205927 (* 1 = 0.205927 loss)
I1007 10:52:07.930408  4720 sgd_solver.cpp:105] Iteration 31200, lr = 0.1
I1007 10:52:16.278906  4720 solver.cpp:218] Iteration 31300 (11.9782 iter/s, 8.34849s/100 iters), loss = 0.2204
I1007 10:52:16.278954  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.2204 (* 1 = 0.2204 loss)
I1007 10:52:16.278961  4720 sgd_solver.cpp:105] Iteration 31300, lr = 0.1
I1007 10:52:24.626258  4720 solver.cpp:218] Iteration 31400 (11.98 iter/s, 8.34728s/100 iters), loss = 0.20083
I1007 10:52:24.626304  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.20083 (* 1 = 0.20083 loss)
I1007 10:52:24.626312  4720 sgd_solver.cpp:105] Iteration 31400, lr = 0.1
I1007 10:52:32.565512  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:52:32.899080  4720 solver.cpp:330] Iteration 31500, Testing net (#0)
I1007 10:52:34.831863  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:52:34.912250  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.762
I1007 10:52:34.912287  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.835605 (* 1 = 0.835605 loss)
I1007 10:52:34.996388  4720 solver.cpp:218] Iteration 31500 (9.64315 iter/s, 10.3701s/100 iters), loss = 0.260095
I1007 10:52:34.996415  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.260095 (* 1 = 0.260095 loss)
I1007 10:52:34.996423  4720 sgd_solver.cpp:105] Iteration 31500, lr = 0.1
I1007 10:52:43.350500  4720 solver.cpp:218] Iteration 31600 (11.9702 iter/s, 8.35406s/100 iters), loss = 0.169342
I1007 10:52:43.350611  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.169342 (* 1 = 0.169342 loss)
I1007 10:52:43.350617  4720 sgd_solver.cpp:105] Iteration 31600, lr = 0.1
I1007 10:52:51.696144  4720 solver.cpp:218] Iteration 31700 (11.9825 iter/s, 8.34552s/100 iters), loss = 0.182629
I1007 10:52:51.696175  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.182629 (* 1 = 0.182629 loss)
I1007 10:52:51.696192  4720 sgd_solver.cpp:105] Iteration 31700, lr = 0.1
I1007 10:53:00.053575  4720 solver.cpp:218] Iteration 31800 (11.9655 iter/s, 8.35737s/100 iters), loss = 0.249986
I1007 10:53:00.053604  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.249986 (* 1 = 0.249986 loss)
I1007 10:53:00.053609  4720 sgd_solver.cpp:105] Iteration 31800, lr = 0.1
I1007 10:53:08.408233  4720 solver.cpp:218] Iteration 31900 (11.9694 iter/s, 8.3546s/100 iters), loss = 0.159081
I1007 10:53:08.408274  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.159081 (* 1 = 0.159081 loss)
I1007 10:53:08.408279  4720 sgd_solver.cpp:105] Iteration 31900, lr = 0.1
I1007 10:53:16.350924  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:53:16.684432  4720 solver.cpp:330] Iteration 32000, Testing net (#0)
I1007 10:53:18.616981  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:53:18.697808  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7655
I1007 10:53:18.697844  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.75712 (* 1 = 0.75712 loss)
I1007 10:53:18.780771  4720 solver.cpp:218] Iteration 32000 (9.64091 iter/s, 10.3725s/100 iters), loss = 0.169152
I1007 10:53:18.780798  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.169152 (* 1 = 0.169152 loss)
I1007 10:53:18.780805  4720 sgd_solver.cpp:105] Iteration 32000, lr = 0.1
I1007 10:53:27.136127  4720 solver.cpp:218] Iteration 32100 (11.9685 iter/s, 8.35529s/100 iters), loss = 0.218642
I1007 10:53:27.136175  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.218642 (* 1 = 0.218642 loss)
I1007 10:53:27.136181  4720 sgd_solver.cpp:105] Iteration 32100, lr = 0.1
I1007 10:53:35.494292  4720 solver.cpp:218] Iteration 32200 (11.9644 iter/s, 8.3581s/100 iters), loss = 0.237608
I1007 10:53:35.494321  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.237608 (* 1 = 0.237608 loss)
I1007 10:53:35.494326  4720 sgd_solver.cpp:105] Iteration 32200, lr = 0.1
I1007 10:53:43.848620  4720 solver.cpp:218] Iteration 32300 (11.9699 iter/s, 8.35427s/100 iters), loss = 0.235448
I1007 10:53:43.848659  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.235448 (* 1 = 0.235448 loss)
I1007 10:53:43.848664  4720 sgd_solver.cpp:105] Iteration 32300, lr = 0.1
I1007 10:53:52.209867  4720 solver.cpp:218] Iteration 32400 (11.96 iter/s, 8.36118s/100 iters), loss = 0.159383
I1007 10:53:52.209988  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.159383 (* 1 = 0.159383 loss)
I1007 10:53:52.210006  4720 sgd_solver.cpp:105] Iteration 32400, lr = 0.1
I1007 10:54:00.152331  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:54:00.486030  4720 solver.cpp:330] Iteration 32500, Testing net (#0)
I1007 10:54:02.421257  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:54:02.502020  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7917
I1007 10:54:02.502045  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.661715 (* 1 = 0.661715 loss)
I1007 10:54:02.585608  4720 solver.cpp:218] Iteration 32500 (9.638 iter/s, 10.3756s/100 iters), loss = 0.191141
I1007 10:54:02.585635  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.191141 (* 1 = 0.191141 loss)
I1007 10:54:02.585642  4720 sgd_solver.cpp:105] Iteration 32500, lr = 0.1
I1007 10:54:10.946143  4720 solver.cpp:218] Iteration 32600 (11.961 iter/s, 8.36048s/100 iters), loss = 0.176313
I1007 10:54:10.946182  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.176313 (* 1 = 0.176313 loss)
I1007 10:54:10.946188  4720 sgd_solver.cpp:105] Iteration 32600, lr = 0.1
I1007 10:54:19.295428  4720 solver.cpp:218] Iteration 32700 (11.9772 iter/s, 8.34922s/100 iters), loss = 0.329867
I1007 10:54:19.295469  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.329867 (* 1 = 0.329867 loss)
I1007 10:54:19.295475  4720 sgd_solver.cpp:105] Iteration 32700, lr = 0.1
I1007 10:54:27.654057  4720 solver.cpp:218] Iteration 32800 (11.9638 iter/s, 8.35856s/100 iters), loss = 0.202946
I1007 10:54:27.654180  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.202946 (* 1 = 0.202946 loss)
I1007 10:54:27.654186  4720 sgd_solver.cpp:105] Iteration 32800, lr = 0.1
I1007 10:54:36.008432  4720 solver.cpp:218] Iteration 32900 (11.97 iter/s, 8.35423s/100 iters), loss = 0.246999
I1007 10:54:36.008471  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.246999 (* 1 = 0.246999 loss)
I1007 10:54:36.008476  4720 sgd_solver.cpp:105] Iteration 32900, lr = 0.1
I1007 10:54:43.947926  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:54:44.282471  4720 solver.cpp:330] Iteration 33000, Testing net (#0)
I1007 10:54:46.217084  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:54:46.297977  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7739
I1007 10:54:46.298004  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.795986 (* 1 = 0.795986 loss)
I1007 10:54:46.381597  4720 solver.cpp:218] Iteration 33000 (9.64032 iter/s, 10.3731s/100 iters), loss = 0.168457
I1007 10:54:46.381625  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.168457 (* 1 = 0.168457 loss)
I1007 10:54:46.381633  4720 sgd_solver.cpp:105] Iteration 33000, lr = 0.1
I1007 10:54:54.734218  4720 solver.cpp:218] Iteration 33100 (11.9724 iter/s, 8.35257s/100 iters), loss = 0.140606
I1007 10:54:54.734249  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.140607 (* 1 = 0.140607 loss)
I1007 10:54:54.734264  4720 sgd_solver.cpp:105] Iteration 33100, lr = 0.1
I1007 10:55:03.094827  4720 solver.cpp:218] Iteration 33200 (11.9609 iter/s, 8.36055s/100 iters), loss = 0.326394
I1007 10:55:03.094959  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.326394 (* 1 = 0.326394 loss)
I1007 10:55:03.094976  4720 sgd_solver.cpp:105] Iteration 33200, lr = 0.1
I1007 10:55:11.447265  4720 solver.cpp:218] Iteration 33300 (11.9728 iter/s, 8.35228s/100 iters), loss = 0.253695
I1007 10:55:11.447304  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.253695 (* 1 = 0.253695 loss)
I1007 10:55:11.447310  4720 sgd_solver.cpp:105] Iteration 33300, lr = 0.1
I1007 10:55:19.806682  4720 solver.cpp:218] Iteration 33400 (11.9626 iter/s, 8.35935s/100 iters), loss = 0.141746
I1007 10:55:19.806722  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.141746 (* 1 = 0.141746 loss)
I1007 10:55:19.806728  4720 sgd_solver.cpp:105] Iteration 33400, lr = 0.1
I1007 10:55:27.750447  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:55:28.084350  4720 solver.cpp:330] Iteration 33500, Testing net (#0)
I1007 10:55:30.018566  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:55:30.099535  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8485
I1007 10:55:30.099561  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.468025 (* 1 = 0.468025 loss)
I1007 10:55:30.183292  4720 solver.cpp:218] Iteration 33500 (9.63712 iter/s, 10.3765s/100 iters), loss = 0.201375
I1007 10:55:30.183321  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.201375 (* 1 = 0.201375 loss)
I1007 10:55:30.183328  4720 sgd_solver.cpp:105] Iteration 33500, lr = 0.1
I1007 10:55:38.539696  4720 solver.cpp:218] Iteration 33600 (11.9669 iter/s, 8.35635s/100 iters), loss = 0.195812
I1007 10:55:38.539803  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.195812 (* 1 = 0.195812 loss)
I1007 10:55:38.539810  4720 sgd_solver.cpp:105] Iteration 33600, lr = 0.1
I1007 10:55:46.890087  4720 solver.cpp:218] Iteration 33700 (11.9757 iter/s, 8.35026s/100 iters), loss = 0.286591
I1007 10:55:46.890126  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.286591 (* 1 = 0.286591 loss)
I1007 10:55:46.890132  4720 sgd_solver.cpp:105] Iteration 33700, lr = 0.1
I1007 10:55:55.245213  4720 solver.cpp:218] Iteration 33800 (11.9688 iter/s, 8.35506s/100 iters), loss = 0.204124
I1007 10:55:55.245254  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.204124 (* 1 = 0.204124 loss)
I1007 10:55:55.245260  4720 sgd_solver.cpp:105] Iteration 33800, lr = 0.1
I1007 10:56:03.598265  4720 solver.cpp:218] Iteration 33900 (11.9718 iter/s, 8.35298s/100 iters), loss = 0.156837
I1007 10:56:03.598294  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.156837 (* 1 = 0.156837 loss)
I1007 10:56:03.598300  4720 sgd_solver.cpp:105] Iteration 33900, lr = 0.1
I1007 10:56:11.537667  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:56:11.873107  4720 solver.cpp:330] Iteration 34000, Testing net (#0)
I1007 10:56:13.806028  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:56:13.886477  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8286
I1007 10:56:13.886512  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.546832 (* 1 = 0.546832 loss)
I1007 10:56:13.970433  4720 solver.cpp:218] Iteration 34000 (9.64124 iter/s, 10.3721s/100 iters), loss = 0.219431
I1007 10:56:13.970461  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.219431 (* 1 = 0.219431 loss)
I1007 10:56:13.970468  4720 sgd_solver.cpp:105] Iteration 34000, lr = 0.1
I1007 10:56:22.334028  4720 solver.cpp:218] Iteration 34100 (11.9567 iter/s, 8.36354s/100 iters), loss = 0.156951
I1007 10:56:22.334070  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.156951 (* 1 = 0.156951 loss)
I1007 10:56:22.334076  4720 sgd_solver.cpp:105] Iteration 34100, lr = 0.1
I1007 10:56:30.700812  4720 solver.cpp:218] Iteration 34200 (11.9521 iter/s, 8.36672s/100 iters), loss = 0.236398
I1007 10:56:30.700852  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.236398 (* 1 = 0.236398 loss)
I1007 10:56:30.700857  4720 sgd_solver.cpp:105] Iteration 34200, lr = 0.1
I1007 10:56:39.069290  4720 solver.cpp:218] Iteration 34300 (11.9497 iter/s, 8.36841s/100 iters), loss = 0.215789
I1007 10:56:39.069329  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.215789 (* 1 = 0.215789 loss)
I1007 10:56:39.069335  4720 sgd_solver.cpp:105] Iteration 34300, lr = 0.1
I1007 10:56:47.433080  4720 solver.cpp:218] Iteration 34400 (11.9564 iter/s, 8.36372s/100 iters), loss = 0.135247
I1007 10:56:47.433243  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.135247 (* 1 = 0.135247 loss)
I1007 10:56:47.433261  4720 sgd_solver.cpp:105] Iteration 34400, lr = 0.1
I1007 10:56:55.377962  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:56:55.712419  4720 solver.cpp:330] Iteration 34500, Testing net (#0)
I1007 10:56:57.646338  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:56:57.727275  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7462
I1007 10:56:57.727310  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.865434 (* 1 = 0.865434 loss)
I1007 10:56:57.811228  4720 solver.cpp:218] Iteration 34500 (9.63581 iter/s, 10.378s/100 iters), loss = 0.204911
I1007 10:56:57.811257  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.204911 (* 1 = 0.204911 loss)
I1007 10:56:57.811264  4720 sgd_solver.cpp:105] Iteration 34500, lr = 0.1
I1007 10:57:06.172099  4720 solver.cpp:218] Iteration 34600 (11.9606 iter/s, 8.36082s/100 iters), loss = 0.17267
I1007 10:57:06.172128  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.17267 (* 1 = 0.17267 loss)
I1007 10:57:06.172134  4720 sgd_solver.cpp:105] Iteration 34600, lr = 0.1
I1007 10:57:14.525426  4720 solver.cpp:218] Iteration 34700 (11.9714 iter/s, 8.35327s/100 iters), loss = 0.207275
I1007 10:57:14.525456  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.207275 (* 1 = 0.207275 loss)
I1007 10:57:14.525461  4720 sgd_solver.cpp:105] Iteration 34700, lr = 0.1
I1007 10:57:22.886673  4720 solver.cpp:218] Iteration 34800 (11.96 iter/s, 8.36119s/100 iters), loss = 0.145424
I1007 10:57:22.886800  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.145424 (* 1 = 0.145424 loss)
I1007 10:57:22.886806  4720 sgd_solver.cpp:105] Iteration 34800, lr = 0.1
I1007 10:57:31.246798  4720 solver.cpp:218] Iteration 34900 (11.9618 iter/s, 8.35997s/100 iters), loss = 0.145455
I1007 10:57:31.246829  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.145455 (* 1 = 0.145455 loss)
I1007 10:57:31.246834  4720 sgd_solver.cpp:105] Iteration 34900, lr = 0.1
I1007 10:57:39.193167  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:57:39.527952  4720 solver.cpp:330] Iteration 35000, Testing net (#0)
I1007 10:57:41.462430  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:57:41.542598  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7817
I1007 10:57:41.542632  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.698091 (* 1 = 0.698091 loss)
I1007 10:57:41.626519  4720 solver.cpp:218] Iteration 35000 (9.63422 iter/s, 10.3797s/100 iters), loss = 0.178808
I1007 10:57:41.626554  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.178808 (* 1 = 0.178808 loss)
I1007 10:57:41.626561  4720 sgd_solver.cpp:105] Iteration 35000, lr = 0.1
I1007 10:57:49.977583  4720 solver.cpp:218] Iteration 35100 (11.9746 iter/s, 8.351s/100 iters), loss = 0.183987
I1007 10:57:49.977613  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.183987 (* 1 = 0.183987 loss)
I1007 10:57:49.977619  4720 sgd_solver.cpp:105] Iteration 35100, lr = 0.1
I1007 10:57:58.338752  4720 solver.cpp:218] Iteration 35200 (11.9601 iter/s, 8.36111s/100 iters), loss = 0.222161
I1007 10:57:58.338886  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.222161 (* 1 = 0.222161 loss)
I1007 10:57:58.338892  4720 sgd_solver.cpp:105] Iteration 35200, lr = 0.1
I1007 10:58:06.694203  4720 solver.cpp:218] Iteration 35300 (11.9685 iter/s, 8.35529s/100 iters), loss = 0.187354
I1007 10:58:06.694232  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.187354 (* 1 = 0.187354 loss)
I1007 10:58:06.694238  4720 sgd_solver.cpp:105] Iteration 35300, lr = 0.1
I1007 10:58:15.051759  4720 solver.cpp:218] Iteration 35400 (11.9653 iter/s, 8.3575s/100 iters), loss = 0.186793
I1007 10:58:15.051800  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.186793 (* 1 = 0.186793 loss)
I1007 10:58:15.051805  4720 sgd_solver.cpp:105] Iteration 35400, lr = 0.1
I1007 10:58:22.992060  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:58:23.326592  4720 solver.cpp:330] Iteration 35500, Testing net (#0)
I1007 10:58:25.259820  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:58:25.340411  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7987
I1007 10:58:25.340448  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.638911 (* 1 = 0.638911 loss)
I1007 10:58:25.424002  4720 solver.cpp:218] Iteration 35500 (9.64118 iter/s, 10.3722s/100 iters), loss = 0.183317
I1007 10:58:25.424032  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.183317 (* 1 = 0.183317 loss)
I1007 10:58:25.424038  4720 sgd_solver.cpp:105] Iteration 35500, lr = 0.1
I1007 10:58:33.789548  4720 solver.cpp:218] Iteration 35600 (11.9539 iter/s, 8.36549s/100 iters), loss = 0.200287
I1007 10:58:33.789664  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.200287 (* 1 = 0.200287 loss)
I1007 10:58:33.789680  4720 sgd_solver.cpp:105] Iteration 35600, lr = 0.1
I1007 10:58:42.145047  4720 solver.cpp:218] Iteration 35700 (11.9684 iter/s, 8.35537s/100 iters), loss = 0.206823
I1007 10:58:42.145087  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.206823 (* 1 = 0.206823 loss)
I1007 10:58:42.145092  4720 sgd_solver.cpp:105] Iteration 35700, lr = 0.1
I1007 10:58:50.501472  4720 solver.cpp:218] Iteration 35800 (11.9669 iter/s, 8.35636s/100 iters), loss = 0.233089
I1007 10:58:50.501513  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.233089 (* 1 = 0.233089 loss)
I1007 10:58:50.501518  4720 sgd_solver.cpp:105] Iteration 35800, lr = 0.1
I1007 10:58:58.859042  4720 solver.cpp:218] Iteration 35900 (11.9653 iter/s, 8.3575s/100 iters), loss = 0.176713
I1007 10:58:58.859083  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.176713 (* 1 = 0.176713 loss)
I1007 10:58:58.859088  4720 sgd_solver.cpp:105] Iteration 35900, lr = 0.1
I1007 10:59:06.810714  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:59:07.145486  4720 solver.cpp:330] Iteration 36000, Testing net (#0)
I1007 10:59:09.077764  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:59:09.157833  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7873
I1007 10:59:09.157868  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.691493 (* 1 = 0.691493 loss)
I1007 10:59:09.241288  4720 solver.cpp:218] Iteration 36000 (9.63189 iter/s, 10.3822s/100 iters), loss = 0.235846
I1007 10:59:09.241322  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.235846 (* 1 = 0.235846 loss)
I1007 10:59:09.241329  4720 sgd_solver.cpp:105] Iteration 36000, lr = 0.1
I1007 10:59:17.592595  4720 solver.cpp:218] Iteration 36100 (11.9743 iter/s, 8.35125s/100 iters), loss = 0.12843
I1007 10:59:17.592635  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.12843 (* 1 = 0.12843 loss)
I1007 10:59:17.592641  4720 sgd_solver.cpp:105] Iteration 36100, lr = 0.1
I1007 10:59:25.951894  4720 solver.cpp:218] Iteration 36200 (11.9628 iter/s, 8.35923s/100 iters), loss = 0.158996
I1007 10:59:25.951934  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.158996 (* 1 = 0.158996 loss)
I1007 10:59:25.951941  4720 sgd_solver.cpp:105] Iteration 36200, lr = 0.1
I1007 10:59:34.308459  4720 solver.cpp:218] Iteration 36300 (11.9667 iter/s, 8.3565s/100 iters), loss = 0.195565
I1007 10:59:34.308499  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.195565 (* 1 = 0.195565 loss)
I1007 10:59:34.308506  4720 sgd_solver.cpp:105] Iteration 36300, lr = 0.1
I1007 10:59:42.665791  4720 solver.cpp:218] Iteration 36400 (11.9656 iter/s, 8.35727s/100 iters), loss = 0.154465
I1007 10:59:42.665928  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.154465 (* 1 = 0.154465 loss)
I1007 10:59:42.665935  4720 sgd_solver.cpp:105] Iteration 36400, lr = 0.1
I1007 10:59:50.599109  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:59:50.933435  4720 solver.cpp:330] Iteration 36500, Testing net (#0)
I1007 10:59:52.867583  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 10:59:52.948599  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7627
I1007 10:59:52.948635  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.775434 (* 1 = 0.775434 loss)
I1007 10:59:53.032253  4720 solver.cpp:218] Iteration 36500 (9.64665 iter/s, 10.3663s/100 iters), loss = 0.203183
I1007 10:59:53.032281  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.203183 (* 1 = 0.203183 loss)
I1007 10:59:53.032289  4720 sgd_solver.cpp:105] Iteration 36500, lr = 0.1
I1007 11:00:01.398113  4720 solver.cpp:218] Iteration 36600 (11.9534 iter/s, 8.36581s/100 iters), loss = 0.23924
I1007 11:00:01.398141  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.23924 (* 1 = 0.23924 loss)
I1007 11:00:01.398147  4720 sgd_solver.cpp:105] Iteration 36600, lr = 0.1
I1007 11:00:09.752115  4720 solver.cpp:218] Iteration 36700 (11.9704 iter/s, 8.35395s/100 iters), loss = 0.297603
I1007 11:00:09.752156  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.297603 (* 1 = 0.297603 loss)
I1007 11:00:09.752161  4720 sgd_solver.cpp:105] Iteration 36700, lr = 0.1
I1007 11:00:18.114812  4720 solver.cpp:218] Iteration 36800 (11.958 iter/s, 8.36263s/100 iters), loss = 0.251479
I1007 11:00:18.114904  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.251479 (* 1 = 0.251479 loss)
I1007 11:00:18.114923  4720 sgd_solver.cpp:105] Iteration 36800, lr = 0.1
I1007 11:00:26.474277  4720 solver.cpp:218] Iteration 36900 (11.9627 iter/s, 8.35935s/100 iters), loss = 0.1853
I1007 11:00:26.474306  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.1853 (* 1 = 0.1853 loss)
I1007 11:00:26.474311  4720 sgd_solver.cpp:105] Iteration 36900, lr = 0.1
I1007 11:00:34.428010  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:00:34.762615  4720 solver.cpp:330] Iteration 37000, Testing net (#0)
I1007 11:00:36.698076  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:00:36.778350  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7988
I1007 11:00:36.778386  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.648418 (* 1 = 0.648418 loss)
I1007 11:00:36.862350  4720 solver.cpp:218] Iteration 37000 (9.62648 iter/s, 10.388s/100 iters), loss = 0.177556
I1007 11:00:36.862382  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.177556 (* 1 = 0.177556 loss)
I1007 11:00:36.862390  4720 sgd_solver.cpp:105] Iteration 37000, lr = 0.1
I1007 11:00:45.215965  4720 solver.cpp:218] Iteration 37100 (11.971 iter/s, 8.35355s/100 iters), loss = 0.201865
I1007 11:00:45.215994  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.201865 (* 1 = 0.201865 loss)
I1007 11:00:45.216001  4720 sgd_solver.cpp:105] Iteration 37100, lr = 0.1
I1007 11:00:53.575080  4720 solver.cpp:218] Iteration 37200 (11.9631 iter/s, 8.35906s/100 iters), loss = 0.273512
I1007 11:00:53.575225  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.273512 (* 1 = 0.273512 loss)
I1007 11:00:53.575242  4720 sgd_solver.cpp:105] Iteration 37200, lr = 0.1
I1007 11:01:01.932762  4720 solver.cpp:218] Iteration 37300 (11.9653 iter/s, 8.35751s/100 iters), loss = 0.257268
I1007 11:01:01.932792  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.257268 (* 1 = 0.257268 loss)
I1007 11:01:01.932798  4720 sgd_solver.cpp:105] Iteration 37300, lr = 0.1
I1007 11:01:10.291580  4720 solver.cpp:218] Iteration 37400 (11.9635 iter/s, 8.35876s/100 iters), loss = 0.182416
I1007 11:01:10.291610  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.182416 (* 1 = 0.182416 loss)
I1007 11:01:10.291616  4720 sgd_solver.cpp:105] Iteration 37400, lr = 0.1
I1007 11:01:18.233017  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:01:18.566854  4720 solver.cpp:330] Iteration 37500, Testing net (#0)
I1007 11:01:20.499338  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:01:20.580008  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7523
I1007 11:01:20.580034  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.921513 (* 1 = 0.921513 loss)
I1007 11:01:20.664217  4720 solver.cpp:218] Iteration 37500 (9.64081 iter/s, 10.3726s/100 iters), loss = 0.169379
I1007 11:01:20.664247  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.169379 (* 1 = 0.169379 loss)
I1007 11:01:20.664253  4720 sgd_solver.cpp:105] Iteration 37500, lr = 0.1
I1007 11:01:29.022109  4720 solver.cpp:218] Iteration 37600 (11.9648 iter/s, 8.35784s/100 iters), loss = 0.233788
I1007 11:01:29.022195  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.233788 (* 1 = 0.233788 loss)
I1007 11:01:29.022212  4720 sgd_solver.cpp:105] Iteration 37600, lr = 0.1
I1007 11:01:37.375006  4720 solver.cpp:218] Iteration 37700 (11.9721 iter/s, 8.35279s/100 iters), loss = 0.182739
I1007 11:01:37.375036  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.182739 (* 1 = 0.182739 loss)
I1007 11:01:37.375041  4720 sgd_solver.cpp:105] Iteration 37700, lr = 0.1
I1007 11:01:45.730926  4720 solver.cpp:218] Iteration 37800 (11.9676 iter/s, 8.35586s/100 iters), loss = 0.136418
I1007 11:01:45.730957  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.136418 (* 1 = 0.136418 loss)
I1007 11:01:45.730962  4720 sgd_solver.cpp:105] Iteration 37800, lr = 0.1
I1007 11:01:54.087033  4720 solver.cpp:218] Iteration 37900 (11.9674 iter/s, 8.35605s/100 iters), loss = 0.185573
I1007 11:01:54.087064  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.185573 (* 1 = 0.185573 loss)
I1007 11:01:54.087069  4720 sgd_solver.cpp:105] Iteration 37900, lr = 0.1
I1007 11:02:02.032557  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:02:02.367091  4720 solver.cpp:330] Iteration 38000, Testing net (#0)
I1007 11:02:04.300850  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:02:04.381429  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7252
I1007 11:02:04.381455  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.99485 (* 1 = 0.99485 loss)
I1007 11:02:04.464946  4720 solver.cpp:218] Iteration 38000 (9.63591 iter/s, 10.3779s/100 iters), loss = 0.173598
I1007 11:02:04.464973  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.173598 (* 1 = 0.173598 loss)
I1007 11:02:04.464980  4720 sgd_solver.cpp:105] Iteration 38000, lr = 0.1
I1007 11:02:12.825217  4720 solver.cpp:218] Iteration 38100 (11.9614 iter/s, 8.36022s/100 iters), loss = 0.148675
I1007 11:02:12.825258  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.148675 (* 1 = 0.148675 loss)
I1007 11:02:12.825263  4720 sgd_solver.cpp:105] Iteration 38100, lr = 0.1
I1007 11:02:21.191355  4720 solver.cpp:218] Iteration 38200 (11.953 iter/s, 8.36607s/100 iters), loss = 0.276628
I1007 11:02:21.191385  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.276628 (* 1 = 0.276628 loss)
I1007 11:02:21.191390  4720 sgd_solver.cpp:105] Iteration 38200, lr = 0.1
I1007 11:02:29.555089  4720 solver.cpp:218] Iteration 38300 (11.9565 iter/s, 8.36368s/100 iters), loss = 0.162137
I1007 11:02:29.555119  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.162137 (* 1 = 0.162137 loss)
I1007 11:02:29.555135  4720 sgd_solver.cpp:105] Iteration 38300, lr = 0.1
I1007 11:02:37.923777  4720 solver.cpp:218] Iteration 38400 (11.9494 iter/s, 8.36863s/100 iters), loss = 0.11584
I1007 11:02:37.923933  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.11584 (* 1 = 0.11584 loss)
I1007 11:02:37.923941  4720 sgd_solver.cpp:105] Iteration 38400, lr = 0.1
I1007 11:02:45.870527  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:02:46.205112  4720 solver.cpp:330] Iteration 38500, Testing net (#0)
I1007 11:02:48.140159  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:02:48.220574  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8105
I1007 11:02:48.220600  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.601167 (* 1 = 0.601167 loss)
I1007 11:02:48.304404  4720 solver.cpp:218] Iteration 38500 (9.6335 iter/s, 10.3804s/100 iters), loss = 0.153587
I1007 11:02:48.304437  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.153587 (* 1 = 0.153587 loss)
I1007 11:02:48.304443  4720 sgd_solver.cpp:105] Iteration 38500, lr = 0.1
I1007 11:02:56.665253  4720 solver.cpp:218] Iteration 38600 (11.9606 iter/s, 8.36079s/100 iters), loss = 0.207466
I1007 11:02:56.665293  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.207466 (* 1 = 0.207466 loss)
I1007 11:02:56.665299  4720 sgd_solver.cpp:105] Iteration 38600, lr = 0.1
I1007 11:03:05.020328  4720 solver.cpp:218] Iteration 38700 (11.9689 iter/s, 8.35501s/100 iters), loss = 0.201822
I1007 11:03:05.020368  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.201822 (* 1 = 0.201822 loss)
I1007 11:03:05.020373  4720 sgd_solver.cpp:105] Iteration 38700, lr = 0.1
I1007 11:03:13.383987  4720 solver.cpp:218] Iteration 38800 (11.9566 iter/s, 8.36359s/100 iters), loss = 0.192413
I1007 11:03:13.384078  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.192413 (* 1 = 0.192413 loss)
I1007 11:03:13.384094  4720 sgd_solver.cpp:105] Iteration 38800, lr = 0.1
I1007 11:03:21.743716  4720 solver.cpp:218] Iteration 38900 (11.9623 iter/s, 8.35961s/100 iters), loss = 0.178397
I1007 11:03:21.743747  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.178398 (* 1 = 0.178398 loss)
I1007 11:03:21.743752  4720 sgd_solver.cpp:105] Iteration 38900, lr = 0.1
I1007 11:03:29.687299  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:03:30.021282  4720 solver.cpp:330] Iteration 39000, Testing net (#0)
I1007 11:03:31.955894  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:03:32.036937  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8015
I1007 11:03:32.036973  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.637174 (* 1 = 0.637174 loss)
I1007 11:03:32.120523  4720 solver.cpp:218] Iteration 39000 (9.63693 iter/s, 10.3767s/100 iters), loss = 0.193192
I1007 11:03:32.120553  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.193192 (* 1 = 0.193192 loss)
I1007 11:03:32.120558  4720 sgd_solver.cpp:105] Iteration 39000, lr = 0.1
I1007 11:03:40.474336  4720 solver.cpp:218] Iteration 39100 (11.9707 iter/s, 8.35376s/100 iters), loss = 0.159883
I1007 11:03:40.474365  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.159883 (* 1 = 0.159883 loss)
I1007 11:03:40.474370  4720 sgd_solver.cpp:105] Iteration 39100, lr = 0.1
I1007 11:03:48.835294  4720 solver.cpp:218] Iteration 39200 (11.9604 iter/s, 8.3609s/100 iters), loss = 0.245044
I1007 11:03:48.835451  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.245044 (* 1 = 0.245044 loss)
I1007 11:03:48.835469  4720 sgd_solver.cpp:105] Iteration 39200, lr = 0.1
I1007 11:03:57.194044  4720 solver.cpp:218] Iteration 39300 (11.9638 iter/s, 8.35857s/100 iters), loss = 0.166945
I1007 11:03:57.194075  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.166945 (* 1 = 0.166945 loss)
I1007 11:03:57.194080  4720 sgd_solver.cpp:105] Iteration 39300, lr = 0.1
I1007 11:04:05.553839  4720 solver.cpp:218] Iteration 39400 (11.9621 iter/s, 8.35974s/100 iters), loss = 0.163559
I1007 11:04:05.553869  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.163559 (* 1 = 0.163559 loss)
I1007 11:04:05.553874  4720 sgd_solver.cpp:105] Iteration 39400, lr = 0.1
I1007 11:04:13.497054  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:04:13.830842  4720 solver.cpp:330] Iteration 39500, Testing net (#0)
I1007 11:04:15.763813  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:04:15.844772  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7862
I1007 11:04:15.844807  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.724988 (* 1 = 0.724988 loss)
I1007 11:04:15.928349  4720 solver.cpp:218] Iteration 39500 (9.63907 iter/s, 10.3744s/100 iters), loss = 0.196851
I1007 11:04:15.928377  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.196851 (* 1 = 0.196851 loss)
I1007 11:04:15.928385  4720 sgd_solver.cpp:105] Iteration 39500, lr = 0.1
I1007 11:04:24.290146  4720 solver.cpp:218] Iteration 39600 (11.9592 iter/s, 8.36174s/100 iters), loss = 0.313625
I1007 11:04:24.290272  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.313625 (* 1 = 0.313625 loss)
I1007 11:04:24.290290  4720 sgd_solver.cpp:105] Iteration 39600, lr = 0.1
I1007 11:04:32.650632  4720 solver.cpp:218] Iteration 39700 (11.9612 iter/s, 8.36034s/100 iters), loss = 0.245671
I1007 11:04:32.650672  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.245672 (* 1 = 0.245672 loss)
I1007 11:04:32.650677  4720 sgd_solver.cpp:105] Iteration 39700, lr = 0.1
I1007 11:04:41.019641  4720 solver.cpp:218] Iteration 39800 (11.9489 iter/s, 8.36894s/100 iters), loss = 0.268552
I1007 11:04:41.019682  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.268552 (* 1 = 0.268552 loss)
I1007 11:04:41.019687  4720 sgd_solver.cpp:105] Iteration 39800, lr = 0.1
I1007 11:04:49.387555  4720 solver.cpp:218] Iteration 39900 (11.9505 iter/s, 8.36785s/100 iters), loss = 0.144841
I1007 11:04:49.387595  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.144841 (* 1 = 0.144841 loss)
I1007 11:04:49.387601  4720 sgd_solver.cpp:105] Iteration 39900, lr = 0.1
I1007 11:04:57.341238  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:04:57.675804  4720 solver.cpp:330] Iteration 40000, Testing net (#0)
I1007 11:04:59.608788  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:04:59.688964  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7628
I1007 11:04:59.689000  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.852541 (* 1 = 0.852541 loss)
I1007 11:04:59.772019  4720 solver.cpp:218] Iteration 40000 (9.62983 iter/s, 10.3844s/100 iters), loss = 0.149686
I1007 11:04:59.772048  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.149687 (* 1 = 0.149687 loss)
I1007 11:04:59.772054  4720 sgd_solver.cpp:46] MultiStep Status: Iteration 40000, step = 1
I1007 11:04:59.772058  4720 sgd_solver.cpp:105] Iteration 40000, lr = 0.01
I1007 11:05:08.141831  4720 solver.cpp:218] Iteration 40100 (11.9478 iter/s, 8.36976s/100 iters), loss = 0.192318
I1007 11:05:08.141871  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.192318 (* 1 = 0.192318 loss)
I1007 11:05:08.141877  4720 sgd_solver.cpp:105] Iteration 40100, lr = 0.01
I1007 11:05:16.511973  4720 solver.cpp:218] Iteration 40200 (11.9473 iter/s, 8.37008s/100 iters), loss = 0.136897
I1007 11:05:16.512001  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.136897 (* 1 = 0.136897 loss)
I1007 11:05:16.512006  4720 sgd_solver.cpp:105] Iteration 40200, lr = 0.01
I1007 11:05:24.878454  4720 solver.cpp:218] Iteration 40300 (11.9525 iter/s, 8.36643s/100 iters), loss = 0.107466
I1007 11:05:24.878484  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.107467 (* 1 = 0.107467 loss)
I1007 11:05:24.878489  4720 sgd_solver.cpp:105] Iteration 40300, lr = 0.01
I1007 11:05:33.249814  4720 solver.cpp:218] Iteration 40400 (11.9456 iter/s, 8.3713s/100 iters), loss = 0.0837847
I1007 11:05:33.249960  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0837848 (* 1 = 0.0837848 loss)
I1007 11:05:33.249969  4720 sgd_solver.cpp:105] Iteration 40400, lr = 0.01
I1007 11:05:41.200512  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:05:41.534818  4720 solver.cpp:330] Iteration 40500, Testing net (#0)
I1007 11:05:43.468359  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:05:43.549556  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9013
I1007 11:05:43.549592  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.296927 (* 1 = 0.296927 loss)
I1007 11:05:43.632918  4720 solver.cpp:218] Iteration 40500 (9.63119 iter/s, 10.3829s/100 iters), loss = 0.0880782
I1007 11:05:43.632947  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0880783 (* 1 = 0.0880783 loss)
I1007 11:05:43.632953  4720 sgd_solver.cpp:105] Iteration 40500, lr = 0.01
I1007 11:05:51.989462  4720 solver.cpp:218] Iteration 40600 (11.9667 iter/s, 8.35649s/100 iters), loss = 0.13645
I1007 11:05:51.989502  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.13645 (* 1 = 0.13645 loss)
I1007 11:05:51.989508  4720 sgd_solver.cpp:105] Iteration 40600, lr = 0.01
I1007 11:06:00.337755  4720 solver.cpp:218] Iteration 40700 (11.9786 iter/s, 8.34823s/100 iters), loss = 0.172073
I1007 11:06:00.337795  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.172073 (* 1 = 0.172073 loss)
I1007 11:06:00.337800  4720 sgd_solver.cpp:105] Iteration 40700, lr = 0.01
I1007 11:06:08.696401  4720 solver.cpp:218] Iteration 40800 (11.9638 iter/s, 8.35858s/100 iters), loss = 0.10816
I1007 11:06:08.696518  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.10816 (* 1 = 0.10816 loss)
I1007 11:06:08.696526  4720 sgd_solver.cpp:105] Iteration 40800, lr = 0.01
I1007 11:06:17.052551  4720 solver.cpp:218] Iteration 40900 (11.9674 iter/s, 8.35601s/100 iters), loss = 0.100148
I1007 11:06:17.052592  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.100148 (* 1 = 0.100148 loss)
I1007 11:06:17.052597  4720 sgd_solver.cpp:105] Iteration 40900, lr = 0.01
I1007 11:06:24.996729  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:06:25.331305  4720 solver.cpp:330] Iteration 41000, Testing net (#0)
I1007 11:06:27.264521  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:06:27.345229  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9108
I1007 11:06:27.345268  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.276843 (* 1 = 0.276843 loss)
I1007 11:06:27.428580  4720 solver.cpp:218] Iteration 41000 (9.63766 iter/s, 10.376s/100 iters), loss = 0.0709993
I1007 11:06:27.428608  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0709994 (* 1 = 0.0709994 loss)
I1007 11:06:27.428614  4720 sgd_solver.cpp:105] Iteration 41000, lr = 0.01
I1007 11:06:35.782138  4720 solver.cpp:218] Iteration 41100 (11.971 iter/s, 8.3535s/100 iters), loss = 0.0916883
I1007 11:06:35.782179  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0916885 (* 1 = 0.0916885 loss)
I1007 11:06:35.782184  4720 sgd_solver.cpp:105] Iteration 41100, lr = 0.01
I1007 11:06:44.146312  4720 solver.cpp:218] Iteration 41200 (11.9558 iter/s, 8.36411s/100 iters), loss = 0.078335
I1007 11:06:44.146453  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0783352 (* 1 = 0.0783352 loss)
I1007 11:06:44.146461  4720 sgd_solver.cpp:105] Iteration 41200, lr = 0.01
I1007 11:06:52.504995  4720 solver.cpp:218] Iteration 41300 (11.9638 iter/s, 8.35852s/100 iters), loss = 0.0993362
I1007 11:06:52.505035  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0993364 (* 1 = 0.0993364 loss)
I1007 11:06:52.505041  4720 sgd_solver.cpp:105] Iteration 41300, lr = 0.01
I1007 11:07:00.874440  4720 solver.cpp:218] Iteration 41400 (11.9483 iter/s, 8.36938s/100 iters), loss = 0.0436668
I1007 11:07:00.874480  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.043667 (* 1 = 0.043667 loss)
I1007 11:07:00.874486  4720 sgd_solver.cpp:105] Iteration 41400, lr = 0.01
I1007 11:07:08.821591  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:07:09.156448  4720 solver.cpp:330] Iteration 41500, Testing net (#0)
I1007 11:07:11.090693  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:07:11.170997  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9136
I1007 11:07:11.171034  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.262391 (* 1 = 0.262391 loss)
I1007 11:07:11.255090  4720 solver.cpp:218] Iteration 41500 (9.63338 iter/s, 10.3806s/100 iters), loss = 0.0620897
I1007 11:07:11.255125  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0620899 (* 1 = 0.0620899 loss)
I1007 11:07:11.255132  4720 sgd_solver.cpp:105] Iteration 41500, lr = 0.01
I1007 11:07:19.614401  4720 solver.cpp:218] Iteration 41600 (11.9628 iter/s, 8.35925s/100 iters), loss = 0.111953
I1007 11:07:19.614506  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.111953 (* 1 = 0.111953 loss)
I1007 11:07:19.614523  4720 sgd_solver.cpp:105] Iteration 41600, lr = 0.01
I1007 11:07:27.970340  4720 solver.cpp:218] Iteration 41700 (11.9677 iter/s, 8.35581s/100 iters), loss = 0.0684058
I1007 11:07:27.970379  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.068406 (* 1 = 0.068406 loss)
I1007 11:07:27.970386  4720 sgd_solver.cpp:105] Iteration 41700, lr = 0.01
I1007 11:07:36.323530  4720 solver.cpp:218] Iteration 41800 (11.9716 iter/s, 8.35312s/100 iters), loss = 0.0482402
I1007 11:07:36.323570  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0482404 (* 1 = 0.0482404 loss)
I1007 11:07:36.323576  4720 sgd_solver.cpp:105] Iteration 41800, lr = 0.01
I1007 11:07:44.671535  4720 solver.cpp:218] Iteration 41900 (11.979 iter/s, 8.34794s/100 iters), loss = 0.0464077
I1007 11:07:44.671573  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0464079 (* 1 = 0.0464079 loss)
I1007 11:07:44.671578  4720 sgd_solver.cpp:105] Iteration 41900, lr = 0.01
I1007 11:07:52.614936  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:07:52.949381  4720 solver.cpp:330] Iteration 42000, Testing net (#0)
I1007 11:07:54.882323  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:07:54.963053  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9167
I1007 11:07:54.963091  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.255356 (* 1 = 0.255356 loss)
I1007 11:07:55.046319  4720 solver.cpp:218] Iteration 42000 (9.63882 iter/s, 10.3747s/100 iters), loss = 0.0597422
I1007 11:07:55.046346  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0597424 (* 1 = 0.0597424 loss)
I1007 11:07:55.046353  4720 sgd_solver.cpp:105] Iteration 42000, lr = 0.01
I1007 11:08:03.398931  4720 solver.cpp:218] Iteration 42100 (11.9724 iter/s, 8.35256s/100 iters), loss = 0.0712671
I1007 11:08:03.398972  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0712673 (* 1 = 0.0712673 loss)
I1007 11:08:03.398977  4720 sgd_solver.cpp:105] Iteration 42100, lr = 0.01
I1007 11:08:11.755152  4720 solver.cpp:218] Iteration 42200 (11.9672 iter/s, 8.35615s/100 iters), loss = 0.0854263
I1007 11:08:11.755194  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0854265 (* 1 = 0.0854265 loss)
I1007 11:08:11.755201  4720 sgd_solver.cpp:105] Iteration 42200, lr = 0.01
I1007 11:08:20.111107  4720 solver.cpp:218] Iteration 42300 (11.9676 iter/s, 8.35589s/100 iters), loss = 0.0880956
I1007 11:08:20.111148  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0880958 (* 1 = 0.0880958 loss)
I1007 11:08:20.111155  4720 sgd_solver.cpp:105] Iteration 42300, lr = 0.01
I1007 11:08:28.474160  4720 solver.cpp:218] Iteration 42400 (11.9574 iter/s, 8.36299s/100 iters), loss = 0.045732
I1007 11:08:28.474301  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0457322 (* 1 = 0.0457322 loss)
I1007 11:08:28.474318  4720 sgd_solver.cpp:105] Iteration 42400, lr = 0.01
I1007 11:08:36.414659  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:08:36.749379  4720 solver.cpp:330] Iteration 42500, Testing net (#0)
I1007 11:08:38.684100  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:08:38.764727  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9147
I1007 11:08:38.764763  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.265833 (* 1 = 0.265833 loss)
I1007 11:08:38.848616  4720 solver.cpp:218] Iteration 42500 (9.63922 iter/s, 10.3743s/100 iters), loss = 0.0822521
I1007 11:08:38.848649  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0822523 (* 1 = 0.0822523 loss)
I1007 11:08:38.848656  4720 sgd_solver.cpp:105] Iteration 42500, lr = 0.01
I1007 11:08:47.211854  4720 solver.cpp:218] Iteration 42600 (11.9572 iter/s, 8.36318s/100 iters), loss = 0.105313
I1007 11:08:47.211884  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.105313 (* 1 = 0.105313 loss)
I1007 11:08:47.211890  4720 sgd_solver.cpp:105] Iteration 42600, lr = 0.01
I1007 11:08:55.567281  4720 solver.cpp:218] Iteration 42700 (11.9683 iter/s, 8.35537s/100 iters), loss = 0.0514069
I1007 11:08:55.567322  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0514071 (* 1 = 0.0514071 loss)
I1007 11:08:55.567327  4720 sgd_solver.cpp:105] Iteration 42700, lr = 0.01
I1007 11:09:03.936225  4720 solver.cpp:218] Iteration 42800 (11.949 iter/s, 8.36888s/100 iters), loss = 0.0341668
I1007 11:09:03.936311  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.034167 (* 1 = 0.034167 loss)
I1007 11:09:03.936326  4720 sgd_solver.cpp:105] Iteration 42800, lr = 0.01
I1007 11:09:12.301231  4720 solver.cpp:218] Iteration 42900 (11.9547 iter/s, 8.3649s/100 iters), loss = 0.034083
I1007 11:09:12.301272  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0340832 (* 1 = 0.0340832 loss)
I1007 11:09:12.301278  4720 sgd_solver.cpp:105] Iteration 42900, lr = 0.01
I1007 11:09:20.246861  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:09:20.581293  4720 solver.cpp:330] Iteration 43000, Testing net (#0)
I1007 11:09:22.516155  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:09:22.596473  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9156
I1007 11:09:22.596508  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.25794 (* 1 = 0.25794 loss)
I1007 11:09:22.679478  4720 solver.cpp:218] Iteration 43000 (9.6356 iter/s, 10.3782s/100 iters), loss = 0.0583707
I1007 11:09:22.679507  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0583709 (* 1 = 0.0583709 loss)
I1007 11:09:22.679513  4720 sgd_solver.cpp:105] Iteration 43000, lr = 0.01
I1007 11:09:31.031164  4720 solver.cpp:218] Iteration 43100 (11.9737 iter/s, 8.35163s/100 iters), loss = 0.0574539
I1007 11:09:31.031204  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0574541 (* 1 = 0.0574541 loss)
I1007 11:09:31.031210  4720 sgd_solver.cpp:105] Iteration 43100, lr = 0.01
I1007 11:09:39.391747  4720 solver.cpp:218] Iteration 43200 (11.961 iter/s, 8.36052s/100 iters), loss = 0.0295765
I1007 11:09:39.391891  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0295767 (* 1 = 0.0295767 loss)
I1007 11:09:39.391899  4720 sgd_solver.cpp:105] Iteration 43200, lr = 0.01
I1007 11:09:47.754827  4720 solver.cpp:218] Iteration 43300 (11.9576 iter/s, 8.36291s/100 iters), loss = 0.0447156
I1007 11:09:47.754868  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0447159 (* 1 = 0.0447159 loss)
I1007 11:09:47.754873  4720 sgd_solver.cpp:105] Iteration 43300, lr = 0.01
I1007 11:09:56.120100  4720 solver.cpp:218] Iteration 43400 (11.9543 iter/s, 8.36521s/100 iters), loss = 0.0257989
I1007 11:09:56.120138  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0257991 (* 1 = 0.0257991 loss)
I1007 11:09:56.120144  4720 sgd_solver.cpp:105] Iteration 43400, lr = 0.01
I1007 11:10:04.062664  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:10:04.397625  4720 solver.cpp:330] Iteration 43500, Testing net (#0)
I1007 11:10:06.330909  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:10:06.411720  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9162
I1007 11:10:06.411756  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.257281 (* 1 = 0.257281 loss)
I1007 11:10:06.495376  4720 solver.cpp:218] Iteration 43500 (9.63836 iter/s, 10.3752s/100 iters), loss = 0.0302725
I1007 11:10:06.495406  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0302727 (* 1 = 0.0302727 loss)
I1007 11:10:06.495412  4720 sgd_solver.cpp:105] Iteration 43500, lr = 0.01
I1007 11:10:14.864930  4720 solver.cpp:218] Iteration 43600 (11.9481 iter/s, 8.3695s/100 iters), loss = 0.0933425
I1007 11:10:14.865073  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0933427 (* 1 = 0.0933427 loss)
I1007 11:10:14.865082  4720 sgd_solver.cpp:105] Iteration 43600, lr = 0.01
I1007 11:10:23.225666  4720 solver.cpp:218] Iteration 43700 (11.9609 iter/s, 8.36057s/100 iters), loss = 0.0510245
I1007 11:10:23.225697  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0510247 (* 1 = 0.0510247 loss)
I1007 11:10:23.225713  4720 sgd_solver.cpp:105] Iteration 43700, lr = 0.01
I1007 11:10:31.591210  4720 solver.cpp:218] Iteration 43800 (11.9539 iter/s, 8.36549s/100 iters), loss = 0.0321855
I1007 11:10:31.591250  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0321858 (* 1 = 0.0321858 loss)
I1007 11:10:31.591256  4720 sgd_solver.cpp:105] Iteration 43800, lr = 0.01
I1007 11:10:39.952772  4720 solver.cpp:218] Iteration 43900 (11.9596 iter/s, 8.3615s/100 iters), loss = 0.0320521
I1007 11:10:39.952812  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0320524 (* 1 = 0.0320524 loss)
I1007 11:10:39.952817  4720 sgd_solver.cpp:105] Iteration 43900, lr = 0.01
I1007 11:10:47.902501  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:10:48.237736  4720 solver.cpp:330] Iteration 44000, Testing net (#0)
I1007 11:10:50.170892  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:10:50.251405  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9156
I1007 11:10:50.251441  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.268378 (* 1 = 0.268378 loss)
I1007 11:10:50.334483  4720 solver.cpp:218] Iteration 44000 (9.63239 iter/s, 10.3816s/100 iters), loss = 0.0404424
I1007 11:10:50.334512  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0404427 (* 1 = 0.0404427 loss)
I1007 11:10:50.334519  4720 sgd_solver.cpp:105] Iteration 44000, lr = 0.01
I1007 11:10:58.689350  4720 solver.cpp:218] Iteration 44100 (11.9691 iter/s, 8.35481s/100 iters), loss = 0.073407
I1007 11:10:58.689391  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0734072 (* 1 = 0.0734072 loss)
I1007 11:10:58.689396  4720 sgd_solver.cpp:105] Iteration 44100, lr = 0.01
I1007 11:11:07.051465  4720 solver.cpp:218] Iteration 44200 (11.9588 iter/s, 8.36205s/100 iters), loss = 0.0441092
I1007 11:11:07.051506  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0441094 (* 1 = 0.0441094 loss)
I1007 11:11:07.051512  4720 sgd_solver.cpp:105] Iteration 44200, lr = 0.01
I1007 11:11:15.413627  4720 solver.cpp:218] Iteration 44300 (11.9587 iter/s, 8.3621s/100 iters), loss = 0.0720585
I1007 11:11:15.413657  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0720587 (* 1 = 0.0720587 loss)
I1007 11:11:15.413663  4720 sgd_solver.cpp:105] Iteration 44300, lr = 0.01
I1007 11:11:23.780225  4720 solver.cpp:218] Iteration 44400 (11.9524 iter/s, 8.36654s/100 iters), loss = 0.0445002
I1007 11:11:23.780355  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0445004 (* 1 = 0.0445004 loss)
I1007 11:11:23.780372  4720 sgd_solver.cpp:105] Iteration 44400, lr = 0.01
I1007 11:11:31.724964  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:11:32.058954  4720 solver.cpp:330] Iteration 44500, Testing net (#0)
I1007 11:11:33.993208  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:11:34.073645  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9164
I1007 11:11:34.073681  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.263242 (* 1 = 0.263242 loss)
I1007 11:11:34.157462  4720 solver.cpp:218] Iteration 44500 (9.63662 iter/s, 10.3771s/100 iters), loss = 0.0479939
I1007 11:11:34.157490  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0479941 (* 1 = 0.0479941 loss)
I1007 11:11:34.157495  4720 sgd_solver.cpp:105] Iteration 44500, lr = 0.01
I1007 11:11:42.509999  4720 solver.cpp:218] Iteration 44600 (11.9725 iter/s, 8.35248s/100 iters), loss = 0.0888899
I1007 11:11:42.510040  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0888902 (* 1 = 0.0888902 loss)
I1007 11:11:42.510046  4720 sgd_solver.cpp:105] Iteration 44600, lr = 0.01
I1007 11:11:50.861783  4720 solver.cpp:218] Iteration 44700 (11.9736 iter/s, 8.35172s/100 iters), loss = 0.0265925
I1007 11:11:50.861824  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0265928 (* 1 = 0.0265928 loss)
I1007 11:11:50.861830  4720 sgd_solver.cpp:105] Iteration 44700, lr = 0.01
I1007 11:11:59.221566  4720 solver.cpp:218] Iteration 44800 (11.9621 iter/s, 8.35972s/100 iters), loss = 0.0426361
I1007 11:11:59.221660  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0426363 (* 1 = 0.0426363 loss)
I1007 11:11:59.221668  4720 sgd_solver.cpp:105] Iteration 44800, lr = 0.01
I1007 11:12:07.578186  4720 solver.cpp:218] Iteration 44900 (11.9667 iter/s, 8.3565s/100 iters), loss = 0.018293
I1007 11:12:07.578227  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0182932 (* 1 = 0.0182932 loss)
I1007 11:12:07.578233  4720 sgd_solver.cpp:105] Iteration 44900, lr = 0.01
I1007 11:12:15.520864  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:12:15.854679  4720 solver.cpp:330] Iteration 45000, Testing net (#0)
I1007 11:12:17.789113  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:12:17.870117  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.916
I1007 11:12:17.870151  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.271675 (* 1 = 0.271675 loss)
I1007 11:12:17.952848  4720 solver.cpp:218] Iteration 45000 (9.63893 iter/s, 10.3746s/100 iters), loss = 0.0246631
I1007 11:12:17.952877  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0246633 (* 1 = 0.0246633 loss)
I1007 11:12:17.952883  4720 sgd_solver.cpp:105] Iteration 45000, lr = 0.01
I1007 11:12:26.310792  4720 solver.cpp:218] Iteration 45100 (11.9647 iter/s, 8.35789s/100 iters), loss = 0.0536062
I1007 11:12:26.310833  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0536064 (* 1 = 0.0536064 loss)
I1007 11:12:26.310839  4720 sgd_solver.cpp:105] Iteration 45100, lr = 0.01
I1007 11:12:34.677196  4720 solver.cpp:218] Iteration 45200 (11.9527 iter/s, 8.36634s/100 iters), loss = 0.0526884
I1007 11:12:34.677304  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0526886 (* 1 = 0.0526886 loss)
I1007 11:12:34.677312  4720 sgd_solver.cpp:105] Iteration 45200, lr = 0.01
I1007 11:12:43.034448  4720 solver.cpp:218] Iteration 45300 (11.9658 iter/s, 8.35712s/100 iters), loss = 0.0377108
I1007 11:12:43.034488  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.037711 (* 1 = 0.037711 loss)
I1007 11:12:43.034494  4720 sgd_solver.cpp:105] Iteration 45300, lr = 0.01
I1007 11:12:51.401619  4720 solver.cpp:218] Iteration 45400 (11.9516 iter/s, 8.36711s/100 iters), loss = 0.0212944
I1007 11:12:51.401648  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0212945 (* 1 = 0.0212945 loss)
I1007 11:12:51.401654  4720 sgd_solver.cpp:105] Iteration 45400, lr = 0.01
I1007 11:12:59.347756  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:12:59.681900  4720 solver.cpp:330] Iteration 45500, Testing net (#0)
I1007 11:13:01.616117  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:13:01.696883  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9161
I1007 11:13:01.696919  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.274474 (* 1 = 0.274474 loss)
I1007 11:13:01.780787  4720 solver.cpp:218] Iteration 45500 (9.63474 iter/s, 10.3791s/100 iters), loss = 0.0576467
I1007 11:13:01.780815  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0576468 (* 1 = 0.0576468 loss)
I1007 11:13:01.780822  4720 sgd_solver.cpp:105] Iteration 45500, lr = 0.01
I1007 11:13:10.145141  4720 solver.cpp:218] Iteration 45600 (11.9556 iter/s, 8.3643s/100 iters), loss = 0.0736502
I1007 11:13:10.145282  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0736504 (* 1 = 0.0736504 loss)
I1007 11:13:10.145298  4720 sgd_solver.cpp:105] Iteration 45600, lr = 0.01
I1007 11:13:18.496871  4720 solver.cpp:218] Iteration 45700 (11.9738 iter/s, 8.35157s/100 iters), loss = 0.0332846
I1007 11:13:18.496912  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0332848 (* 1 = 0.0332848 loss)
I1007 11:13:18.496917  4720 sgd_solver.cpp:105] Iteration 45700, lr = 0.01
I1007 11:13:26.857168  4720 solver.cpp:218] Iteration 45800 (11.9614 iter/s, 8.36023s/100 iters), loss = 0.0705329
I1007 11:13:26.857200  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0705331 (* 1 = 0.0705331 loss)
I1007 11:13:26.857206  4720 sgd_solver.cpp:105] Iteration 45800, lr = 0.01
I1007 11:13:35.212018  4720 solver.cpp:218] Iteration 45900 (11.9692 iter/s, 8.35479s/100 iters), loss = 0.0169678
I1007 11:13:35.212047  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.016968 (* 1 = 0.016968 loss)
I1007 11:13:35.212052  4720 sgd_solver.cpp:105] Iteration 45900, lr = 0.01
I1007 11:13:43.161346  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:13:43.495328  4720 solver.cpp:330] Iteration 46000, Testing net (#0)
I1007 11:13:45.428406  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:13:45.508637  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9122
I1007 11:13:45.508672  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.292767 (* 1 = 0.292767 loss)
I1007 11:13:45.591817  4720 solver.cpp:218] Iteration 46000 (9.63415 iter/s, 10.3797s/100 iters), loss = 0.0128258
I1007 11:13:45.591845  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.012826 (* 1 = 0.012826 loss)
I1007 11:13:45.591852  4720 sgd_solver.cpp:105] Iteration 46000, lr = 0.01
I1007 11:13:53.953048  4720 solver.cpp:218] Iteration 46100 (11.96 iter/s, 8.36117s/100 iters), loss = 0.0756413
I1007 11:13:53.953088  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0756415 (* 1 = 0.0756415 loss)
I1007 11:13:53.953094  4720 sgd_solver.cpp:105] Iteration 46100, lr = 0.01
I1007 11:14:02.318174  4720 solver.cpp:218] Iteration 46200 (11.9545 iter/s, 8.36506s/100 iters), loss = 0.014812
I1007 11:14:02.318214  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0148122 (* 1 = 0.0148122 loss)
I1007 11:14:02.318219  4720 sgd_solver.cpp:105] Iteration 46200, lr = 0.01
I1007 11:14:10.674840  4720 solver.cpp:218] Iteration 46300 (11.9666 iter/s, 8.3566s/100 iters), loss = 0.03971
I1007 11:14:10.674881  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0397101 (* 1 = 0.0397101 loss)
I1007 11:14:10.674886  4720 sgd_solver.cpp:105] Iteration 46300, lr = 0.01
I1007 11:14:19.041939  4720 solver.cpp:218] Iteration 46400 (11.9517 iter/s, 8.36703s/100 iters), loss = 0.0349175
I1007 11:14:19.042099  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0349177 (* 1 = 0.0349177 loss)
I1007 11:14:19.042116  4720 sgd_solver.cpp:105] Iteration 46400, lr = 0.01
I1007 11:14:26.987197  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:14:27.322599  4720 solver.cpp:330] Iteration 46500, Testing net (#0)
I1007 11:14:29.256929  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:14:29.338222  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9178
I1007 11:14:29.338258  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.273452 (* 1 = 0.273452 loss)
I1007 11:14:29.421902  4720 solver.cpp:218] Iteration 46500 (9.63411 iter/s, 10.3798s/100 iters), loss = 0.0162307
I1007 11:14:29.421931  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0162309 (* 1 = 0.0162309 loss)
I1007 11:14:29.421936  4720 sgd_solver.cpp:105] Iteration 46500, lr = 0.01
I1007 11:14:37.792392  4720 solver.cpp:218] Iteration 46600 (11.9468 iter/s, 8.37044s/100 iters), loss = 0.0449933
I1007 11:14:37.792431  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0449934 (* 1 = 0.0449934 loss)
I1007 11:14:37.792438  4720 sgd_solver.cpp:105] Iteration 46600, lr = 0.01
I1007 11:14:46.152321  4720 solver.cpp:218] Iteration 46700 (11.9619 iter/s, 8.35987s/100 iters), loss = 0.0329293
I1007 11:14:46.152360  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0329295 (* 1 = 0.0329295 loss)
I1007 11:14:46.152366  4720 sgd_solver.cpp:105] Iteration 46700, lr = 0.01
I1007 11:14:54.521152  4720 solver.cpp:218] Iteration 46800 (11.9492 iter/s, 8.36877s/100 iters), loss = 0.026335
I1007 11:14:54.521296  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0263352 (* 1 = 0.0263352 loss)
I1007 11:14:54.521304  4720 sgd_solver.cpp:105] Iteration 46800, lr = 0.01
I1007 11:15:02.886823  4720 solver.cpp:218] Iteration 46900 (11.9538 iter/s, 8.36551s/100 iters), loss = 0.0243692
I1007 11:15:02.886863  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0243693 (* 1 = 0.0243693 loss)
I1007 11:15:02.886869  4720 sgd_solver.cpp:105] Iteration 46900, lr = 0.01
I1007 11:15:10.836236  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:15:11.171196  4720 solver.cpp:330] Iteration 47000, Testing net (#0)
I1007 11:15:13.105103  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:15:13.185086  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9142
I1007 11:15:13.185122  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.290763 (* 1 = 0.290763 loss)
I1007 11:15:13.267971  4720 solver.cpp:218] Iteration 47000 (9.63291 iter/s, 10.3811s/100 iters), loss = 0.031482
I1007 11:15:13.268004  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0314822 (* 1 = 0.0314822 loss)
I1007 11:15:13.268010  4720 sgd_solver.cpp:105] Iteration 47000, lr = 0.01
I1007 11:15:21.627187  4720 solver.cpp:218] Iteration 47100 (11.9629 iter/s, 8.35916s/100 iters), loss = 0.0339974
I1007 11:15:21.627215  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0339976 (* 1 = 0.0339976 loss)
I1007 11:15:21.627231  4720 sgd_solver.cpp:105] Iteration 47100, lr = 0.01
I1007 11:15:29.992957  4720 solver.cpp:218] Iteration 47200 (11.9536 iter/s, 8.36572s/100 iters), loss = 0.0417391
I1007 11:15:29.993098  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0417392 (* 1 = 0.0417392 loss)
I1007 11:15:29.993104  4720 sgd_solver.cpp:105] Iteration 47200, lr = 0.01
I1007 11:15:38.353087  4720 solver.cpp:218] Iteration 47300 (11.9618 iter/s, 8.35998s/100 iters), loss = 0.0420083
I1007 11:15:38.353127  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0420085 (* 1 = 0.0420085 loss)
I1007 11:15:38.353133  4720 sgd_solver.cpp:105] Iteration 47300, lr = 0.01
I1007 11:15:46.715592  4720 solver.cpp:218] Iteration 47400 (11.9582 iter/s, 8.36244s/100 iters), loss = 0.0244346
I1007 11:15:46.715631  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0244348 (* 1 = 0.0244348 loss)
I1007 11:15:46.715637  4720 sgd_solver.cpp:105] Iteration 47400, lr = 0.01
I1007 11:15:54.657941  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:15:54.993495  4720 solver.cpp:330] Iteration 47500, Testing net (#0)
I1007 11:15:56.926661  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:15:57.007524  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9177
I1007 11:15:57.007558  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.280949 (* 1 = 0.280949 loss)
I1007 11:15:57.091420  4720 solver.cpp:218] Iteration 47500 (9.63785 iter/s, 10.3758s/100 iters), loss = 0.0328537
I1007 11:15:57.091447  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0328539 (* 1 = 0.0328539 loss)
I1007 11:15:57.091454  4720 sgd_solver.cpp:105] Iteration 47500, lr = 0.01
I1007 11:16:05.457731  4720 solver.cpp:218] Iteration 47600 (11.9528 iter/s, 8.36626s/100 iters), loss = 0.0218911
I1007 11:16:05.457851  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0218913 (* 1 = 0.0218913 loss)
I1007 11:16:05.457859  4720 sgd_solver.cpp:105] Iteration 47600, lr = 0.01
I1007 11:16:13.819720  4720 solver.cpp:218] Iteration 47700 (11.9591 iter/s, 8.36186s/100 iters), loss = 0.0241063
I1007 11:16:13.819761  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0241065 (* 1 = 0.0241065 loss)
I1007 11:16:13.819766  4720 sgd_solver.cpp:105] Iteration 47700, lr = 0.01
I1007 11:16:22.184276  4720 solver.cpp:218] Iteration 47800 (11.9553 iter/s, 8.36449s/100 iters), loss = 0.0254965
I1007 11:16:22.184316  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0254967 (* 1 = 0.0254967 loss)
I1007 11:16:22.184322  4720 sgd_solver.cpp:105] Iteration 47800, lr = 0.01
I1007 11:16:30.546543  4720 solver.cpp:218] Iteration 47900 (11.9586 iter/s, 8.3622s/100 iters), loss = 0.0173535
I1007 11:16:30.546583  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0173537 (* 1 = 0.0173537 loss)
I1007 11:16:30.546589  4720 sgd_solver.cpp:105] Iteration 47900, lr = 0.01
I1007 11:16:38.501967  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:16:38.836729  4720 solver.cpp:330] Iteration 48000, Testing net (#0)
I1007 11:16:40.769780  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:16:40.850250  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9171
I1007 11:16:40.850286  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.283054 (* 1 = 0.283054 loss)
I1007 11:16:40.933624  4720 solver.cpp:218] Iteration 48000 (9.62741 iter/s, 10.387s/100 iters), loss = 0.025765
I1007 11:16:40.933657  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0257652 (* 1 = 0.0257652 loss)
I1007 11:16:40.933665  4720 sgd_solver.cpp:105] Iteration 48000, lr = 0.01
I1007 11:16:49.286814  4720 solver.cpp:218] Iteration 48100 (11.9716 iter/s, 8.35313s/100 iters), loss = 0.0265932
I1007 11:16:49.286844  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0265934 (* 1 = 0.0265934 loss)
I1007 11:16:49.286860  4720 sgd_solver.cpp:105] Iteration 48100, lr = 0.01
I1007 11:16:57.645328  4720 solver.cpp:218] Iteration 48200 (11.9639 iter/s, 8.35845s/100 iters), loss = 0.0296908
I1007 11:16:57.645359  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.029691 (* 1 = 0.029691 loss)
I1007 11:16:57.645366  4720 sgd_solver.cpp:105] Iteration 48200, lr = 0.01
I1007 11:17:05.996616  4720 solver.cpp:218] Iteration 48300 (11.9743 iter/s, 8.35123s/100 iters), loss = 0.0294609
I1007 11:17:05.996646  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0294611 (* 1 = 0.0294611 loss)
I1007 11:17:05.996652  4720 sgd_solver.cpp:105] Iteration 48300, lr = 0.01
I1007 11:17:14.348608  4720 solver.cpp:218] Iteration 48400 (11.9733 iter/s, 8.35193s/100 iters), loss = 0.0164152
I1007 11:17:14.348781  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0164154 (* 1 = 0.0164154 loss)
I1007 11:17:14.348790  4720 sgd_solver.cpp:105] Iteration 48400, lr = 0.01
I1007 11:17:22.286088  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:17:22.619058  4720 solver.cpp:330] Iteration 48500, Testing net (#0)
I1007 11:17:24.551682  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:17:24.632369  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9138
I1007 11:17:24.632392  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.291827 (* 1 = 0.291827 loss)
I1007 11:17:24.716080  4720 solver.cpp:218] Iteration 48500 (9.64574 iter/s, 10.3673s/100 iters), loss = 0.0192036
I1007 11:17:24.716109  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0192038 (* 1 = 0.0192038 loss)
I1007 11:17:24.716114  4720 sgd_solver.cpp:105] Iteration 48500, lr = 0.01
I1007 11:17:33.080978  4720 solver.cpp:218] Iteration 48600 (11.9548 iter/s, 8.36484s/100 iters), loss = 0.0545623
I1007 11:17:33.081008  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0545625 (* 1 = 0.0545625 loss)
I1007 11:17:33.081024  4720 sgd_solver.cpp:105] Iteration 48600, lr = 0.01
I1007 11:17:41.434780  4720 solver.cpp:218] Iteration 48700 (11.9707 iter/s, 8.35375s/100 iters), loss = 0.0231721
I1007 11:17:41.434810  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0231722 (* 1 = 0.0231722 loss)
I1007 11:17:41.434825  4720 sgd_solver.cpp:105] Iteration 48700, lr = 0.01
I1007 11:17:49.800058  4720 solver.cpp:218] Iteration 48800 (11.9543 iter/s, 8.36522s/100 iters), loss = 0.0252153
I1007 11:17:49.800148  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0252155 (* 1 = 0.0252155 loss)
I1007 11:17:49.800163  4720 sgd_solver.cpp:105] Iteration 48800, lr = 0.01
I1007 11:17:58.159344  4720 solver.cpp:218] Iteration 48900 (11.9629 iter/s, 8.35917s/100 iters), loss = 0.0237658
I1007 11:17:58.159373  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0237659 (* 1 = 0.0237659 loss)
I1007 11:17:58.159389  4720 sgd_solver.cpp:105] Iteration 48900, lr = 0.01
I1007 11:18:06.097173  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:18:06.431535  4720 solver.cpp:330] Iteration 49000, Testing net (#0)
I1007 11:18:08.365419  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:18:08.446120  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9143
I1007 11:18:08.446156  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.294127 (* 1 = 0.294127 loss)
I1007 11:18:08.529696  4720 solver.cpp:218] Iteration 49000 (9.64293 iter/s, 10.3703s/100 iters), loss = 0.0149622
I1007 11:18:08.529722  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0149624 (* 1 = 0.0149624 loss)
I1007 11:18:08.529729  4720 sgd_solver.cpp:105] Iteration 49000, lr = 0.01
I1007 11:18:16.888264  4720 solver.cpp:218] Iteration 49100 (11.9638 iter/s, 8.35851s/100 iters), loss = 0.0461599
I1007 11:18:16.888294  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.04616 (* 1 = 0.04616 loss)
I1007 11:18:16.888310  4720 sgd_solver.cpp:105] Iteration 49100, lr = 0.01
I1007 11:18:25.249475  4720 solver.cpp:218] Iteration 49200 (11.9601 iter/s, 8.36116s/100 iters), loss = 0.0256522
I1007 11:18:25.249596  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0256524 (* 1 = 0.0256524 loss)
I1007 11:18:25.249614  4720 sgd_solver.cpp:105] Iteration 49200, lr = 0.01
I1007 11:18:33.608546  4720 solver.cpp:218] Iteration 49300 (11.9633 iter/s, 8.35893s/100 iters), loss = 0.0172703
I1007 11:18:33.608574  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0172705 (* 1 = 0.0172705 loss)
I1007 11:18:33.608579  4720 sgd_solver.cpp:105] Iteration 49300, lr = 0.01
I1007 11:18:41.969702  4720 solver.cpp:218] Iteration 49400 (11.9601 iter/s, 8.3611s/100 iters), loss = 0.0254376
I1007 11:18:41.969730  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0254378 (* 1 = 0.0254378 loss)
I1007 11:18:41.969738  4720 sgd_solver.cpp:105] Iteration 49400, lr = 0.01
I1007 11:18:49.913976  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:18:50.248375  4720 solver.cpp:330] Iteration 49500, Testing net (#0)
I1007 11:18:52.180795  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:18:52.261443  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9142
I1007 11:18:52.261479  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.293289 (* 1 = 0.293289 loss)
I1007 11:18:52.344849  4720 solver.cpp:218] Iteration 49500 (9.63847 iter/s, 10.3751s/100 iters), loss = 0.0309413
I1007 11:18:52.344877  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0309415 (* 1 = 0.0309415 loss)
I1007 11:18:52.344884  4720 sgd_solver.cpp:105] Iteration 49500, lr = 0.01
I1007 11:19:00.703568  4720 solver.cpp:218] Iteration 49600 (11.9636 iter/s, 8.35867s/100 iters), loss = 0.0256604
I1007 11:19:00.703704  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0256606 (* 1 = 0.0256606 loss)
I1007 11:19:00.703722  4720 sgd_solver.cpp:105] Iteration 49600, lr = 0.01
I1007 11:19:09.058805  4720 solver.cpp:218] Iteration 49700 (11.9688 iter/s, 8.35509s/100 iters), loss = 0.0147651
I1007 11:19:09.058847  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0147652 (* 1 = 0.0147652 loss)
I1007 11:19:09.058853  4720 sgd_solver.cpp:105] Iteration 49700, lr = 0.01
I1007 11:19:17.419494  4720 solver.cpp:218] Iteration 49800 (11.9608 iter/s, 8.36062s/100 iters), loss = 0.0198337
I1007 11:19:17.419533  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0198339 (* 1 = 0.0198339 loss)
I1007 11:19:17.419539  4720 sgd_solver.cpp:105] Iteration 49800, lr = 0.01
I1007 11:19:25.776804  4720 solver.cpp:218] Iteration 49900 (11.9657 iter/s, 8.35725s/100 iters), loss = 0.00672581
I1007 11:19:25.776844  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.006726 (* 1 = 0.006726 loss)
I1007 11:19:25.776849  4720 sgd_solver.cpp:105] Iteration 49900, lr = 0.01
I1007 11:19:33.723423  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:19:34.058331  4720 solver.cpp:330] Iteration 50000, Testing net (#0)
I1007 11:19:35.991652  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:19:36.071840  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9121
I1007 11:19:36.071876  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.311784 (* 1 = 0.311784 loss)
I1007 11:19:36.154815  4720 solver.cpp:218] Iteration 50000 (9.63582 iter/s, 10.3779s/100 iters), loss = 0.0183603
I1007 11:19:36.154844  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0183605 (* 1 = 0.0183605 loss)
I1007 11:19:36.154850  4720 sgd_solver.cpp:105] Iteration 50000, lr = 0.01
I1007 11:19:44.511822  4720 solver.cpp:218] Iteration 50100 (11.9661 iter/s, 8.35695s/100 iters), loss = 0.0337495
I1007 11:19:44.511852  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0337497 (* 1 = 0.0337497 loss)
I1007 11:19:44.511857  4720 sgd_solver.cpp:105] Iteration 50100, lr = 0.01
I1007 11:19:52.868950  4720 solver.cpp:218] Iteration 50200 (11.9659 iter/s, 8.35707s/100 iters), loss = 0.0197424
I1007 11:19:52.868980  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0197426 (* 1 = 0.0197426 loss)
I1007 11:19:52.868985  4720 sgd_solver.cpp:105] Iteration 50200, lr = 0.01
I1007 11:20:01.224124  4720 solver.cpp:218] Iteration 50300 (11.9687 iter/s, 8.35512s/100 iters), loss = 0.0346363
I1007 11:20:01.224155  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0346365 (* 1 = 0.0346365 loss)
I1007 11:20:01.224160  4720 sgd_solver.cpp:105] Iteration 50300, lr = 0.01
I1007 11:20:09.586225  4720 solver.cpp:218] Iteration 50400 (11.9588 iter/s, 8.36205s/100 iters), loss = 0.00579213
I1007 11:20:09.586336  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00579234 (* 1 = 0.00579234 loss)
I1007 11:20:09.586344  4720 sgd_solver.cpp:105] Iteration 50400, lr = 0.01
I1007 11:20:17.518657  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:20:17.852568  4720 solver.cpp:330] Iteration 50500, Testing net (#0)
I1007 11:20:19.787618  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:20:19.868197  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9169
I1007 11:20:19.868221  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.29123 (* 1 = 0.29123 loss)
I1007 11:20:19.952055  4720 solver.cpp:218] Iteration 50500 (9.6472 iter/s, 10.3657s/100 iters), loss = 0.0134416
I1007 11:20:19.952083  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0134418 (* 1 = 0.0134418 loss)
I1007 11:20:19.952090  4720 sgd_solver.cpp:105] Iteration 50500, lr = 0.01
I1007 11:20:28.316673  4720 solver.cpp:218] Iteration 50600 (11.9552 iter/s, 8.36456s/100 iters), loss = 0.015728
I1007 11:20:28.316701  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0157282 (* 1 = 0.0157282 loss)
I1007 11:20:28.316707  4720 sgd_solver.cpp:105] Iteration 50600, lr = 0.01
I1007 11:20:36.678932  4720 solver.cpp:218] Iteration 50700 (11.9586 iter/s, 8.36221s/100 iters), loss = 0.0145916
I1007 11:20:36.678961  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0145918 (* 1 = 0.0145918 loss)
I1007 11:20:36.678967  4720 sgd_solver.cpp:105] Iteration 50700, lr = 0.01
I1007 11:20:45.039772  4720 solver.cpp:218] Iteration 50800 (11.9606 iter/s, 8.36078s/100 iters), loss = 0.0154972
I1007 11:20:45.039906  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0154974 (* 1 = 0.0154974 loss)
I1007 11:20:45.039927  4720 sgd_solver.cpp:105] Iteration 50800, lr = 0.01
I1007 11:20:53.404561  4720 solver.cpp:218] Iteration 50900 (11.9551 iter/s, 8.36464s/100 iters), loss = 0.0147955
I1007 11:20:53.404590  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0147957 (* 1 = 0.0147957 loss)
I1007 11:20:53.404606  4720 sgd_solver.cpp:105] Iteration 50900, lr = 0.01
I1007 11:21:01.360445  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:21:01.694558  4720 solver.cpp:330] Iteration 51000, Testing net (#0)
I1007 11:21:03.626415  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:21:03.706773  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9198
I1007 11:21:03.706809  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.288935 (* 1 = 0.288935 loss)
I1007 11:21:03.790004  4720 solver.cpp:218] Iteration 51000 (9.62892 iter/s, 10.3854s/100 iters), loss = 0.0274922
I1007 11:21:03.790031  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0274924 (* 1 = 0.0274924 loss)
I1007 11:21:03.790038  4720 sgd_solver.cpp:105] Iteration 51000, lr = 0.01
I1007 11:21:12.142186  4720 solver.cpp:218] Iteration 51100 (11.973 iter/s, 8.35213s/100 iters), loss = 0.0489056
I1007 11:21:12.142216  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0489058 (* 1 = 0.0489058 loss)
I1007 11:21:12.142221  4720 sgd_solver.cpp:105] Iteration 51100, lr = 0.01
I1007 11:21:20.504467  4720 solver.cpp:218] Iteration 51200 (11.9585 iter/s, 8.36223s/100 iters), loss = 0.0254796
I1007 11:21:20.504566  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0254798 (* 1 = 0.0254798 loss)
I1007 11:21:20.504583  4720 sgd_solver.cpp:105] Iteration 51200, lr = 0.01
I1007 11:21:28.860771  4720 solver.cpp:218] Iteration 51300 (11.9672 iter/s, 8.35618s/100 iters), loss = 0.0549271
I1007 11:21:28.860811  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0549273 (* 1 = 0.0549273 loss)
I1007 11:21:28.860817  4720 sgd_solver.cpp:105] Iteration 51300, lr = 0.01
I1007 11:21:37.211781  4720 solver.cpp:218] Iteration 51400 (11.9747 iter/s, 8.35094s/100 iters), loss = 0.039013
I1007 11:21:37.211822  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0390132 (* 1 = 0.0390132 loss)
I1007 11:21:37.211827  4720 sgd_solver.cpp:105] Iteration 51400, lr = 0.01
I1007 11:21:45.152298  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:21:45.486726  4720 solver.cpp:330] Iteration 51500, Testing net (#0)
I1007 11:21:47.418822  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:21:47.499666  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9165
I1007 11:21:47.499692  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.303484 (* 1 = 0.303484 loss)
I1007 11:21:47.583601  4720 solver.cpp:218] Iteration 51500 (9.64158 iter/s, 10.3717s/100 iters), loss = 0.005541
I1007 11:21:47.583631  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0055412 (* 1 = 0.0055412 loss)
I1007 11:21:47.583636  4720 sgd_solver.cpp:105] Iteration 51500, lr = 0.01
I1007 11:21:55.951139  4720 solver.cpp:218] Iteration 51600 (11.951 iter/s, 8.36749s/100 iters), loss = 0.0421388
I1007 11:21:55.951292  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.042139 (* 1 = 0.042139 loss)
I1007 11:21:55.951308  4720 sgd_solver.cpp:105] Iteration 51600, lr = 0.01
I1007 11:22:04.312484  4720 solver.cpp:218] Iteration 51700 (11.96 iter/s, 8.36118s/100 iters), loss = 0.02474
I1007 11:22:04.312525  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0247402 (* 1 = 0.0247402 loss)
I1007 11:22:04.312530  4720 sgd_solver.cpp:105] Iteration 51700, lr = 0.01
I1007 11:22:12.676836  4720 solver.cpp:218] Iteration 51800 (11.9556 iter/s, 8.36429s/100 iters), loss = 0.0126198
I1007 11:22:12.676875  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.01262 (* 1 = 0.01262 loss)
I1007 11:22:12.676882  4720 sgd_solver.cpp:105] Iteration 51800, lr = 0.01
I1007 11:22:21.037314  4720 solver.cpp:218] Iteration 51900 (11.9611 iter/s, 8.36041s/100 iters), loss = 0.00430162
I1007 11:22:21.037355  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00430183 (* 1 = 0.00430183 loss)
I1007 11:22:21.037361  4720 sgd_solver.cpp:105] Iteration 51900, lr = 0.01
I1007 11:22:28.986281  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:22:29.320606  4720 solver.cpp:330] Iteration 52000, Testing net (#0)
I1007 11:22:31.253844  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:22:31.333920  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9169
I1007 11:22:31.333945  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.296124 (* 1 = 0.296124 loss)
I1007 11:22:31.417022  4720 solver.cpp:218] Iteration 52000 (9.63425 iter/s, 10.3796s/100 iters), loss = 0.0263179
I1007 11:22:31.417050  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0263181 (* 1 = 0.0263181 loss)
I1007 11:22:31.417057  4720 sgd_solver.cpp:105] Iteration 52000, lr = 0.01
I1007 11:22:39.774168  4720 solver.cpp:218] Iteration 52100 (11.9659 iter/s, 8.35709s/100 iters), loss = 0.018011
I1007 11:22:39.774209  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0180113 (* 1 = 0.0180113 loss)
I1007 11:22:39.774215  4720 sgd_solver.cpp:105] Iteration 52100, lr = 0.01
I1007 11:22:48.129853  4720 solver.cpp:218] Iteration 52200 (11.968 iter/s, 8.35562s/100 iters), loss = 0.0148194
I1007 11:22:48.129881  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0148196 (* 1 = 0.0148196 loss)
I1007 11:22:48.129887  4720 sgd_solver.cpp:105] Iteration 52200, lr = 0.01
I1007 11:22:56.481014  4720 solver.cpp:218] Iteration 52300 (11.9745 iter/s, 8.35111s/100 iters), loss = 0.0172028
I1007 11:22:56.481042  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0172031 (* 1 = 0.0172031 loss)
I1007 11:22:56.481048  4720 sgd_solver.cpp:105] Iteration 52300, lr = 0.01
I1007 11:23:04.836926  4720 solver.cpp:218] Iteration 52400 (11.9677 iter/s, 8.35586s/100 iters), loss = 0.0197341
I1007 11:23:04.837013  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0197343 (* 1 = 0.0197343 loss)
I1007 11:23:04.837028  4720 sgd_solver.cpp:105] Iteration 52400, lr = 0.01
I1007 11:23:12.771630  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:23:13.105051  4720 solver.cpp:330] Iteration 52500, Testing net (#0)
I1007 11:23:15.039222  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:23:15.120270  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9193
I1007 11:23:15.120306  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.288257 (* 1 = 0.288257 loss)
I1007 11:23:15.203997  4720 solver.cpp:218] Iteration 52500 (9.64604 iter/s, 10.367s/100 iters), loss = 0.0259807
I1007 11:23:15.204026  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0259809 (* 1 = 0.0259809 loss)
I1007 11:23:15.204032  4720 sgd_solver.cpp:105] Iteration 52500, lr = 0.01
I1007 11:23:23.569345  4720 solver.cpp:218] Iteration 52600 (11.9542 iter/s, 8.36529s/100 iters), loss = 0.0192163
I1007 11:23:23.569386  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0192166 (* 1 = 0.0192166 loss)
I1007 11:23:23.569392  4720 sgd_solver.cpp:105] Iteration 52600, lr = 0.01
I1007 11:23:31.923473  4720 solver.cpp:218] Iteration 52700 (11.9702 iter/s, 8.35406s/100 iters), loss = 0.0137504
I1007 11:23:31.923513  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0137506 (* 1 = 0.0137506 loss)
I1007 11:23:31.923519  4720 sgd_solver.cpp:105] Iteration 52700, lr = 0.01
I1007 11:23:40.285765  4720 solver.cpp:218] Iteration 52800 (11.9585 iter/s, 8.36223s/100 iters), loss = 0.029727
I1007 11:23:40.285859  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0297272 (* 1 = 0.0297272 loss)
I1007 11:23:40.285867  4720 sgd_solver.cpp:105] Iteration 52800, lr = 0.01
I1007 11:23:48.644834  4720 solver.cpp:218] Iteration 52900 (11.9632 iter/s, 8.35895s/100 iters), loss = 0.00748767
I1007 11:23:48.644873  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00748791 (* 1 = 0.00748791 loss)
I1007 11:23:48.644879  4720 sgd_solver.cpp:105] Iteration 52900, lr = 0.01
I1007 11:23:56.594079  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:23:56.928563  4720 solver.cpp:330] Iteration 53000, Testing net (#0)
I1007 11:23:58.862428  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:23:58.942888  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9163
I1007 11:23:58.942924  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.301461 (* 1 = 0.301461 loss)
I1007 11:23:59.025766  4720 solver.cpp:218] Iteration 53000 (9.63311 iter/s, 10.3809s/100 iters), loss = 0.0252496
I1007 11:23:59.025794  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0252499 (* 1 = 0.0252499 loss)
I1007 11:23:59.025800  4720 sgd_solver.cpp:105] Iteration 53000, lr = 0.01
I1007 11:24:07.377575  4720 solver.cpp:218] Iteration 53100 (11.9735 iter/s, 8.35176s/100 iters), loss = 0.0252231
I1007 11:24:07.377615  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0252234 (* 1 = 0.0252234 loss)
I1007 11:24:07.377621  4720 sgd_solver.cpp:105] Iteration 53100, lr = 0.01
I1007 11:24:15.733170  4720 solver.cpp:218] Iteration 53200 (11.9681 iter/s, 8.35553s/100 iters), loss = 0.0270799
I1007 11:24:15.733273  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0270801 (* 1 = 0.0270801 loss)
I1007 11:24:15.733279  4720 sgd_solver.cpp:105] Iteration 53200, lr = 0.01
I1007 11:24:24.086796  4720 solver.cpp:218] Iteration 53300 (11.971 iter/s, 8.35351s/100 iters), loss = 0.0193484
I1007 11:24:24.086836  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0193487 (* 1 = 0.0193487 loss)
I1007 11:24:24.086843  4720 sgd_solver.cpp:105] Iteration 53300, lr = 0.01
I1007 11:24:32.440980  4720 solver.cpp:218] Iteration 53400 (11.9701 iter/s, 8.35412s/100 iters), loss = 0.00772222
I1007 11:24:32.441021  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00772249 (* 1 = 0.00772249 loss)
I1007 11:24:32.441027  4720 sgd_solver.cpp:105] Iteration 53400, lr = 0.01
I1007 11:24:40.380933  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:24:40.716096  4720 solver.cpp:330] Iteration 53500, Testing net (#0)
I1007 11:24:42.649152  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:24:42.730394  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9151
I1007 11:24:42.730429  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.313933 (* 1 = 0.313933 loss)
I1007 11:24:42.814396  4720 solver.cpp:218] Iteration 53500 (9.64009 iter/s, 10.3733s/100 iters), loss = 0.00810337
I1007 11:24:42.814426  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00810363 (* 1 = 0.00810363 loss)
I1007 11:24:42.814433  4720 sgd_solver.cpp:105] Iteration 53500, lr = 0.01
I1007 11:24:51.176981  4720 solver.cpp:218] Iteration 53600 (11.9581 iter/s, 8.36253s/100 iters), loss = 0.0172714
I1007 11:24:51.177124  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0172717 (* 1 = 0.0172717 loss)
I1007 11:24:51.177130  4720 sgd_solver.cpp:105] Iteration 53600, lr = 0.01
I1007 11:24:59.534201  4720 solver.cpp:218] Iteration 53700 (11.9659 iter/s, 8.35705s/100 iters), loss = 0.0268172
I1007 11:24:59.534242  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0268174 (* 1 = 0.0268174 loss)
I1007 11:24:59.534247  4720 sgd_solver.cpp:105] Iteration 53700, lr = 0.01
I1007 11:25:07.892204  4720 solver.cpp:218] Iteration 53800 (11.9647 iter/s, 8.35794s/100 iters), loss = 0.0108297
I1007 11:25:07.892244  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0108299 (* 1 = 0.0108299 loss)
I1007 11:25:07.892251  4720 sgd_solver.cpp:105] Iteration 53800, lr = 0.01
I1007 11:25:16.247534  4720 solver.cpp:218] Iteration 53900 (11.9685 iter/s, 8.35527s/100 iters), loss = 0.00335191
I1007 11:25:16.247576  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00335215 (* 1 = 0.00335215 loss)
I1007 11:25:16.247582  4720 sgd_solver.cpp:105] Iteration 53900, lr = 0.01
I1007 11:25:24.196310  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:25:24.530689  4720 solver.cpp:330] Iteration 54000, Testing net (#0)
I1007 11:25:26.462760  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:25:26.543296  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9141
I1007 11:25:26.543332  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.325939 (* 1 = 0.325939 loss)
I1007 11:25:26.626724  4720 solver.cpp:218] Iteration 54000 (9.63473 iter/s, 10.3791s/100 iters), loss = 0.00925386
I1007 11:25:26.626752  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00925412 (* 1 = 0.00925412 loss)
I1007 11:25:26.626760  4720 sgd_solver.cpp:105] Iteration 54000, lr = 0.01
I1007 11:25:34.987617  4720 solver.cpp:218] Iteration 54100 (11.9605 iter/s, 8.36084s/100 iters), loss = 0.0148397
I1007 11:25:34.987656  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.01484 (* 1 = 0.01484 loss)
I1007 11:25:34.987663  4720 sgd_solver.cpp:105] Iteration 54100, lr = 0.01
I1007 11:25:43.352682  4720 solver.cpp:218] Iteration 54200 (11.9546 iter/s, 8.365s/100 iters), loss = 0.0109881
I1007 11:25:43.352722  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0109883 (* 1 = 0.0109883 loss)
I1007 11:25:43.352728  4720 sgd_solver.cpp:105] Iteration 54200, lr = 0.01
I1007 11:25:51.709919  4720 solver.cpp:218] Iteration 54300 (11.9658 iter/s, 8.35717s/100 iters), loss = 0.0187321
I1007 11:25:51.709960  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0187323 (* 1 = 0.0187323 loss)
I1007 11:25:51.709965  4720 sgd_solver.cpp:105] Iteration 54300, lr = 0.01
I1007 11:26:00.067207  4720 solver.cpp:218] Iteration 54400 (11.9657 iter/s, 8.35722s/100 iters), loss = 0.018424
I1007 11:26:00.067312  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0184242 (* 1 = 0.0184242 loss)
I1007 11:26:00.067318  4720 sgd_solver.cpp:105] Iteration 54400, lr = 0.01
I1007 11:26:08.012050  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:26:08.346818  4720 solver.cpp:330] Iteration 54500, Testing net (#0)
I1007 11:26:10.280336  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:26:10.361477  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9175
I1007 11:26:10.361513  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.293518 (* 1 = 0.293518 loss)
I1007 11:26:10.444679  4720 solver.cpp:218] Iteration 54500 (9.63638 iter/s, 10.3773s/100 iters), loss = 0.016076
I1007 11:26:10.444708  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0160763 (* 1 = 0.0160763 loss)
I1007 11:26:10.444715  4720 sgd_solver.cpp:105] Iteration 54500, lr = 0.01
I1007 11:26:18.808535  4720 solver.cpp:218] Iteration 54600 (11.9563 iter/s, 8.3638s/100 iters), loss = 0.0122511
I1007 11:26:18.808575  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0122513 (* 1 = 0.0122513 loss)
I1007 11:26:18.808580  4720 sgd_solver.cpp:105] Iteration 54600, lr = 0.01
I1007 11:26:27.158073  4720 solver.cpp:218] Iteration 54700 (11.9768 iter/s, 8.34947s/100 iters), loss = 0.0257866
I1007 11:26:27.158103  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0257868 (* 1 = 0.0257868 loss)
I1007 11:26:27.158109  4720 sgd_solver.cpp:105] Iteration 54700, lr = 0.01
I1007 11:26:35.516921  4720 solver.cpp:218] Iteration 54800 (11.9635 iter/s, 8.35879s/100 iters), loss = 0.0435846
I1007 11:26:35.517081  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0435849 (* 1 = 0.0435849 loss)
I1007 11:26:35.517088  4720 sgd_solver.cpp:105] Iteration 54800, lr = 0.01
I1007 11:26:43.871804  4720 solver.cpp:218] Iteration 54900 (11.9693 iter/s, 8.35471s/100 iters), loss = 0.00691613
I1007 11:26:43.871845  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00691639 (* 1 = 0.00691639 loss)
I1007 11:26:43.871850  4720 sgd_solver.cpp:105] Iteration 54900, lr = 0.01
I1007 11:26:51.813134  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:26:52.148180  4720 solver.cpp:330] Iteration 55000, Testing net (#0)
I1007 11:26:54.083344  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:26:54.163699  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9185
I1007 11:26:54.163724  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.305554 (* 1 = 0.305554 loss)
I1007 11:26:54.247169  4720 solver.cpp:218] Iteration 55000 (9.63828 iter/s, 10.3753s/100 iters), loss = 0.0400428
I1007 11:26:54.247201  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0400431 (* 1 = 0.0400431 loss)
I1007 11:26:54.247208  4720 sgd_solver.cpp:105] Iteration 55000, lr = 0.01
I1007 11:27:02.603662  4720 solver.cpp:218] Iteration 55100 (11.9668 iter/s, 8.35644s/100 iters), loss = 0.0111552
I1007 11:27:02.603703  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0111554 (* 1 = 0.0111554 loss)
I1007 11:27:02.603708  4720 sgd_solver.cpp:105] Iteration 55100, lr = 0.01
I1007 11:27:10.966888  4720 solver.cpp:218] Iteration 55200 (11.9572 iter/s, 8.36316s/100 iters), loss = 0.0315044
I1007 11:27:10.966998  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0315046 (* 1 = 0.0315046 loss)
I1007 11:27:10.967005  4720 sgd_solver.cpp:105] Iteration 55200, lr = 0.01
I1007 11:27:19.323772  4720 solver.cpp:218] Iteration 55300 (11.9664 iter/s, 8.35676s/100 iters), loss = 0.0132073
I1007 11:27:19.323802  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0132076 (* 1 = 0.0132076 loss)
I1007 11:27:19.323808  4720 sgd_solver.cpp:105] Iteration 55300, lr = 0.01
I1007 11:27:27.684216  4720 solver.cpp:218] Iteration 55400 (11.9612 iter/s, 8.36039s/100 iters), loss = 0.0335082
I1007 11:27:27.684247  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0335084 (* 1 = 0.0335084 loss)
I1007 11:27:27.684253  4720 sgd_solver.cpp:105] Iteration 55400, lr = 0.01
I1007 11:27:35.628154  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:27:35.962476  4720 solver.cpp:330] Iteration 55500, Testing net (#0)
I1007 11:27:37.894791  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:27:37.975805  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9171
I1007 11:27:37.975841  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.309345 (* 1 = 0.309345 loss)
I1007 11:27:38.059993  4720 solver.cpp:218] Iteration 55500 (9.63789 iter/s, 10.3757s/100 iters), loss = 0.0116754
I1007 11:27:38.060022  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0116757 (* 1 = 0.0116757 loss)
I1007 11:27:38.060029  4720 sgd_solver.cpp:105] Iteration 55500, lr = 0.01
I1007 11:27:46.429371  4720 solver.cpp:218] Iteration 55600 (11.9484 iter/s, 8.36932s/100 iters), loss = 0.0363188
I1007 11:27:46.429533  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0363191 (* 1 = 0.0363191 loss)
I1007 11:27:46.429541  4720 sgd_solver.cpp:105] Iteration 55600, lr = 0.01
I1007 11:27:54.792302  4720 solver.cpp:218] Iteration 55700 (11.9578 iter/s, 8.36275s/100 iters), loss = 0.0161657
I1007 11:27:54.792342  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.016166 (* 1 = 0.016166 loss)
I1007 11:27:54.792348  4720 sgd_solver.cpp:105] Iteration 55700, lr = 0.01
I1007 11:28:03.165091  4720 solver.cpp:218] Iteration 55800 (11.9435 iter/s, 8.37272s/100 iters), loss = 0.017965
I1007 11:28:03.165120  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0179652 (* 1 = 0.0179652 loss)
I1007 11:28:03.165136  4720 sgd_solver.cpp:105] Iteration 55800, lr = 0.01
I1007 11:28:11.523083  4720 solver.cpp:218] Iteration 55900 (11.9647 iter/s, 8.35794s/100 iters), loss = 0.00244397
I1007 11:28:11.523113  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00244425 (* 1 = 0.00244425 loss)
I1007 11:28:11.523118  4720 sgd_solver.cpp:105] Iteration 55900, lr = 0.01
I1007 11:28:19.475862  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:28:19.811152  4720 solver.cpp:330] Iteration 56000, Testing net (#0)
I1007 11:28:21.741778  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:28:21.821967  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9116
I1007 11:28:21.822002  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.327922 (* 1 = 0.327922 loss)
I1007 11:28:21.904624  4720 solver.cpp:218] Iteration 56000 (9.63254 iter/s, 10.3815s/100 iters), loss = 0.00712678
I1007 11:28:21.904652  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00712705 (* 1 = 0.00712705 loss)
I1007 11:28:21.904670  4720 sgd_solver.cpp:105] Iteration 56000, lr = 0.01
I1007 11:28:30.256119  4720 solver.cpp:218] Iteration 56100 (11.974 iter/s, 8.35144s/100 iters), loss = 0.0198925
I1007 11:28:30.256167  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0198928 (* 1 = 0.0198928 loss)
I1007 11:28:30.256175  4720 sgd_solver.cpp:105] Iteration 56100, lr = 0.01
I1007 11:28:38.618348  4720 solver.cpp:218] Iteration 56200 (11.9586 iter/s, 8.36216s/100 iters), loss = 0.00816367
I1007 11:28:38.618396  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00816396 (* 1 = 0.00816396 loss)
I1007 11:28:38.618403  4720 sgd_solver.cpp:105] Iteration 56200, lr = 0.01
I1007 11:28:46.967558  4720 solver.cpp:218] Iteration 56300 (11.9773 iter/s, 8.34914s/100 iters), loss = 0.0242984
I1007 11:28:46.967594  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0242987 (* 1 = 0.0242987 loss)
I1007 11:28:46.967602  4720 sgd_solver.cpp:105] Iteration 56300, lr = 0.01
I1007 11:28:55.321596  4720 solver.cpp:218] Iteration 56400 (11.9703 iter/s, 8.35398s/100 iters), loss = 0.0558037
I1007 11:28:55.321705  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.055804 (* 1 = 0.055804 loss)
I1007 11:28:55.321722  4720 sgd_solver.cpp:105] Iteration 56400, lr = 0.01
I1007 11:29:03.257176  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:29:03.591447  4720 solver.cpp:330] Iteration 56500, Testing net (#0)
I1007 11:29:05.524701  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:29:05.605036  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9194
I1007 11:29:05.605062  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.307687 (* 1 = 0.307687 loss)
I1007 11:29:05.688227  4720 solver.cpp:218] Iteration 56500 (9.64647 iter/s, 10.3665s/100 iters), loss = 0.0238494
I1007 11:29:05.688256  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0238497 (* 1 = 0.0238497 loss)
I1007 11:29:05.688262  4720 sgd_solver.cpp:105] Iteration 56500, lr = 0.01
I1007 11:29:14.044982  4720 solver.cpp:218] Iteration 56600 (11.9664 iter/s, 8.3567s/100 iters), loss = 0.00583154
I1007 11:29:14.045022  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00583184 (* 1 = 0.00583184 loss)
I1007 11:29:14.045027  4720 sgd_solver.cpp:105] Iteration 56600, lr = 0.01
I1007 11:29:22.393982  4720 solver.cpp:218] Iteration 56700 (11.9776 iter/s, 8.34893s/100 iters), loss = 0.00900705
I1007 11:29:22.394029  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00900735 (* 1 = 0.00900735 loss)
I1007 11:29:22.394037  4720 sgd_solver.cpp:105] Iteration 56700, lr = 0.01
I1007 11:29:30.753630  4720 solver.cpp:218] Iteration 56800 (11.9623 iter/s, 8.35958s/100 iters), loss = 0.020411
I1007 11:29:30.753752  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0204113 (* 1 = 0.0204113 loss)
I1007 11:29:30.753760  4720 sgd_solver.cpp:105] Iteration 56800, lr = 0.01
I1007 11:29:39.108605  4720 solver.cpp:218] Iteration 56900 (11.9691 iter/s, 8.35483s/100 iters), loss = 0.00588987
I1007 11:29:39.108635  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00589017 (* 1 = 0.00589017 loss)
I1007 11:29:39.108641  4720 sgd_solver.cpp:105] Iteration 56900, lr = 0.01
I1007 11:29:47.058082  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:29:47.392848  4720 solver.cpp:330] Iteration 57000, Testing net (#0)
I1007 11:29:49.331245  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:29:49.411298  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9186
I1007 11:29:49.411324  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.304664 (* 1 = 0.304664 loss)
I1007 11:29:49.494334  4720 solver.cpp:218] Iteration 57000 (9.62865 iter/s, 10.3857s/100 iters), loss = 0.00379002
I1007 11:29:49.494362  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00379031 (* 1 = 0.00379031 loss)
I1007 11:29:49.494369  4720 sgd_solver.cpp:105] Iteration 57000, lr = 0.01
I1007 11:29:57.852430  4720 solver.cpp:218] Iteration 57100 (11.9645 iter/s, 8.35804s/100 iters), loss = 0.0156591
I1007 11:29:57.852470  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0156594 (* 1 = 0.0156594 loss)
I1007 11:29:57.852476  4720 sgd_solver.cpp:105] Iteration 57100, lr = 0.01
I1007 11:30:06.217425  4720 solver.cpp:218] Iteration 57200 (11.9547 iter/s, 8.36493s/100 iters), loss = 0.0140107
I1007 11:30:06.217548  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.014011 (* 1 = 0.014011 loss)
I1007 11:30:06.217566  4720 sgd_solver.cpp:105] Iteration 57200, lr = 0.01
I1007 11:30:14.576462  4720 solver.cpp:218] Iteration 57300 (11.9633 iter/s, 8.35889s/100 iters), loss = 0.00645274
I1007 11:30:14.576493  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00645303 (* 1 = 0.00645303 loss)
I1007 11:30:14.576509  4720 sgd_solver.cpp:105] Iteration 57300, lr = 0.01
I1007 11:30:22.939368  4720 solver.cpp:218] Iteration 57400 (11.9576 iter/s, 8.36285s/100 iters), loss = 0.00409342
I1007 11:30:22.939407  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00409372 (* 1 = 0.00409372 loss)
I1007 11:30:22.939412  4720 sgd_solver.cpp:105] Iteration 57400, lr = 0.01
I1007 11:30:30.887241  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:30:31.221981  4720 solver.cpp:330] Iteration 57500, Testing net (#0)
I1007 11:30:33.155200  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:30:33.235935  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9167
I1007 11:30:33.235971  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.325051 (* 1 = 0.325051 loss)
I1007 11:30:33.319520  4720 solver.cpp:218] Iteration 57500 (9.63383 iter/s, 10.3801s/100 iters), loss = 0.004957
I1007 11:30:33.319550  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0049573 (* 1 = 0.0049573 loss)
I1007 11:30:33.319556  4720 sgd_solver.cpp:105] Iteration 57500, lr = 0.01
I1007 11:30:41.682654  4720 solver.cpp:218] Iteration 57600 (11.9573 iter/s, 8.36308s/100 iters), loss = 0.00928546
I1007 11:30:41.682826  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00928577 (* 1 = 0.00928577 loss)
I1007 11:30:41.682834  4720 sgd_solver.cpp:105] Iteration 57600, lr = 0.01
I1007 11:30:50.036684  4720 solver.cpp:218] Iteration 57700 (11.9705 iter/s, 8.35385s/100 iters), loss = 0.0191532
I1007 11:30:50.036712  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0191536 (* 1 = 0.0191536 loss)
I1007 11:30:50.036717  4720 sgd_solver.cpp:105] Iteration 57700, lr = 0.01
I1007 11:30:58.393604  4720 solver.cpp:218] Iteration 57800 (11.9662 iter/s, 8.35686s/100 iters), loss = 0.0113771
I1007 11:30:58.393643  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0113774 (* 1 = 0.0113774 loss)
I1007 11:30:58.393649  4720 sgd_solver.cpp:105] Iteration 57800, lr = 0.01
I1007 11:31:06.749693  4720 solver.cpp:218] Iteration 57900 (11.9674 iter/s, 8.35603s/100 iters), loss = 0.00809225
I1007 11:31:06.749733  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00809256 (* 1 = 0.00809256 loss)
I1007 11:31:06.749738  4720 sgd_solver.cpp:105] Iteration 57900, lr = 0.01
I1007 11:31:14.696449  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:31:15.032194  4720 solver.cpp:330] Iteration 58000, Testing net (#0)
I1007 11:31:16.964001  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:31:17.044525  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9153
I1007 11:31:17.044560  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.334376 (* 1 = 0.334376 loss)
I1007 11:31:17.127682  4720 solver.cpp:218] Iteration 58000 (9.63584 iter/s, 10.3779s/100 iters), loss = 0.00321004
I1007 11:31:17.127710  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00321035 (* 1 = 0.00321035 loss)
I1007 11:31:17.127717  4720 sgd_solver.cpp:105] Iteration 58000, lr = 0.01
I1007 11:31:25.482831  4720 solver.cpp:218] Iteration 58100 (11.9687 iter/s, 8.3551s/100 iters), loss = 0.0339291
I1007 11:31:25.482872  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0339294 (* 1 = 0.0339294 loss)
I1007 11:31:25.482877  4720 sgd_solver.cpp:105] Iteration 58100, lr = 0.01
I1007 11:31:33.840555  4720 solver.cpp:218] Iteration 58200 (11.9651 iter/s, 8.35766s/100 iters), loss = 0.00552513
I1007 11:31:33.840595  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00552545 (* 1 = 0.00552545 loss)
I1007 11:31:33.840601  4720 sgd_solver.cpp:105] Iteration 58200, lr = 0.01
I1007 11:31:42.192545  4720 solver.cpp:218] Iteration 58300 (11.9733 iter/s, 8.35193s/100 iters), loss = 0.0298268
I1007 11:31:42.192575  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0298271 (* 1 = 0.0298271 loss)
I1007 11:31:42.192581  4720 sgd_solver.cpp:105] Iteration 58300, lr = 0.01
I1007 11:31:50.553252  4720 solver.cpp:218] Iteration 58400 (11.9608 iter/s, 8.36065s/100 iters), loss = 0.025254
I1007 11:31:50.553362  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0252543 (* 1 = 0.0252543 loss)
I1007 11:31:50.553370  4720 sgd_solver.cpp:105] Iteration 58400, lr = 0.01
I1007 11:31:58.491856  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:31:58.827564  4720 solver.cpp:330] Iteration 58500, Testing net (#0)
I1007 11:32:00.762020  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:32:00.843024  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9172
I1007 11:32:00.843060  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.346002 (* 1 = 0.346002 loss)
I1007 11:32:00.926704  4720 solver.cpp:218] Iteration 58500 (9.64012 iter/s, 10.3733s/100 iters), loss = 0.0657774
I1007 11:32:00.926733  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0657777 (* 1 = 0.0657777 loss)
I1007 11:32:00.926738  4720 sgd_solver.cpp:105] Iteration 58500, lr = 0.01
I1007 11:32:09.285347  4720 solver.cpp:218] Iteration 58600 (11.9637 iter/s, 8.35859s/100 iters), loss = 0.00838618
I1007 11:32:09.285388  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00838649 (* 1 = 0.00838649 loss)
I1007 11:32:09.285395  4720 sgd_solver.cpp:105] Iteration 58600, lr = 0.01
I1007 11:32:17.639158  4720 solver.cpp:218] Iteration 58700 (11.9707 iter/s, 8.35374s/100 iters), loss = 0.014077
I1007 11:32:17.639199  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0140773 (* 1 = 0.0140773 loss)
I1007 11:32:17.639204  4720 sgd_solver.cpp:105] Iteration 58700, lr = 0.01
I1007 11:32:26.001652  4720 solver.cpp:218] Iteration 58800 (11.9582 iter/s, 8.36243s/100 iters), loss = 0.0145529
I1007 11:32:26.001792  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0145532 (* 1 = 0.0145532 loss)
I1007 11:32:26.001799  4720 sgd_solver.cpp:105] Iteration 58800, lr = 0.01
I1007 11:32:34.359277  4720 solver.cpp:218] Iteration 58900 (11.9654 iter/s, 8.35746s/100 iters), loss = 0.00260366
I1007 11:32:34.359316  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00260396 (* 1 = 0.00260396 loss)
I1007 11:32:34.359323  4720 sgd_solver.cpp:105] Iteration 58900, lr = 0.01
I1007 11:32:42.300410  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:32:42.635557  4720 solver.cpp:330] Iteration 59000, Testing net (#0)
I1007 11:32:44.568758  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:32:44.648999  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9184
I1007 11:32:44.649034  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.322841 (* 1 = 0.322841 loss)
I1007 11:32:44.731999  4720 solver.cpp:218] Iteration 59000 (9.64073 iter/s, 10.3727s/100 iters), loss = 0.0712627
I1007 11:32:44.732028  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0712629 (* 1 = 0.0712629 loss)
I1007 11:32:44.732034  4720 sgd_solver.cpp:105] Iteration 59000, lr = 0.01
I1007 11:32:53.091373  4720 solver.cpp:218] Iteration 59100 (11.9627 iter/s, 8.35932s/100 iters), loss = 0.0597818
I1007 11:32:53.091413  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0597821 (* 1 = 0.0597821 loss)
I1007 11:32:53.091419  4720 sgd_solver.cpp:105] Iteration 59100, lr = 0.01
I1007 11:33:01.461161  4720 solver.cpp:218] Iteration 59200 (11.9478 iter/s, 8.36972s/100 iters), loss = 0.0122315
I1007 11:33:01.461236  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0122318 (* 1 = 0.0122318 loss)
I1007 11:33:01.461242  4720 sgd_solver.cpp:105] Iteration 59200, lr = 0.01
I1007 11:33:09.821755  4720 solver.cpp:218] Iteration 59300 (11.961 iter/s, 8.3605s/100 iters), loss = 0.020523
I1007 11:33:09.821795  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0205232 (* 1 = 0.0205232 loss)
I1007 11:33:09.821801  4720 sgd_solver.cpp:105] Iteration 59300, lr = 0.01
I1007 11:33:18.184981  4720 solver.cpp:218] Iteration 59400 (11.9572 iter/s, 8.36316s/100 iters), loss = 0.0155837
I1007 11:33:18.185020  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.015584 (* 1 = 0.015584 loss)
I1007 11:33:18.185025  4720 sgd_solver.cpp:105] Iteration 59400, lr = 0.01
I1007 11:33:26.130007  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:33:26.465313  4720 solver.cpp:330] Iteration 59500, Testing net (#0)
I1007 11:33:28.398308  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:33:28.478941  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9156
I1007 11:33:28.478976  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.324553 (* 1 = 0.324553 loss)
I1007 11:33:28.562911  4720 solver.cpp:218] Iteration 59500 (9.6359 iter/s, 10.3779s/100 iters), loss = 0.0188142
I1007 11:33:28.562938  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0188145 (* 1 = 0.0188145 loss)
I1007 11:33:28.562945  4720 sgd_solver.cpp:105] Iteration 59500, lr = 0.01
I1007 11:33:36.928238  4720 solver.cpp:218] Iteration 59600 (11.9542 iter/s, 8.36528s/100 iters), loss = 0.0377922
I1007 11:33:36.928364  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0377925 (* 1 = 0.0377925 loss)
I1007 11:33:36.928371  4720 sgd_solver.cpp:105] Iteration 59600, lr = 0.01
I1007 11:33:45.288936  4720 solver.cpp:218] Iteration 59700 (11.9609 iter/s, 8.36055s/100 iters), loss = 0.012649
I1007 11:33:45.288976  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0126492 (* 1 = 0.0126492 loss)
I1007 11:33:45.288982  4720 sgd_solver.cpp:105] Iteration 59700, lr = 0.01
I1007 11:33:53.657222  4720 solver.cpp:218] Iteration 59800 (11.95 iter/s, 8.36822s/100 iters), loss = 0.00484801
I1007 11:33:53.657261  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00484826 (* 1 = 0.00484826 loss)
I1007 11:33:53.657268  4720 sgd_solver.cpp:105] Iteration 59800, lr = 0.01
I1007 11:34:02.016469  4720 solver.cpp:218] Iteration 59900 (11.9629 iter/s, 8.35918s/100 iters), loss = 0.00616709
I1007 11:34:02.016507  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00616734 (* 1 = 0.00616734 loss)
I1007 11:34:02.016513  4720 sgd_solver.cpp:105] Iteration 59900, lr = 0.01
I1007 11:34:09.965556  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:34:10.300232  4720 solver.cpp:330] Iteration 60000, Testing net (#0)
I1007 11:34:12.233117  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:34:12.312844  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9159
I1007 11:34:12.312880  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.345967 (* 1 = 0.345967 loss)
I1007 11:34:12.396075  4720 solver.cpp:218] Iteration 60000 (9.63434 iter/s, 10.3795s/100 iters), loss = 0.0269019
I1007 11:34:12.396102  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0269021 (* 1 = 0.0269021 loss)
I1007 11:34:12.396109  4720 sgd_solver.cpp:105] Iteration 60000, lr = 0.01
I1007 11:34:20.754822  4720 solver.cpp:218] Iteration 60100 (11.9636 iter/s, 8.35869s/100 iters), loss = 0.0123853
I1007 11:34:20.754861  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0123856 (* 1 = 0.0123856 loss)
I1007 11:34:20.754868  4720 sgd_solver.cpp:105] Iteration 60100, lr = 0.01
I1007 11:34:29.110543  4720 solver.cpp:218] Iteration 60200 (11.9679 iter/s, 8.35566s/100 iters), loss = 0.00993854
I1007 11:34:29.110572  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00993879 (* 1 = 0.00993879 loss)
I1007 11:34:29.110579  4720 sgd_solver.cpp:105] Iteration 60200, lr = 0.01
I1007 11:34:37.466477  4720 solver.cpp:218] Iteration 60300 (11.9676 iter/s, 8.35588s/100 iters), loss = 0.0227016
I1007 11:34:37.466507  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0227019 (* 1 = 0.0227019 loss)
I1007 11:34:37.466513  4720 sgd_solver.cpp:105] Iteration 60300, lr = 0.01
I1007 11:34:45.825769  4720 solver.cpp:218] Iteration 60400 (11.9628 iter/s, 8.35923s/100 iters), loss = 0.00302607
I1007 11:34:45.825841  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00302632 (* 1 = 0.00302632 loss)
I1007 11:34:45.825850  4720 sgd_solver.cpp:105] Iteration 60400, lr = 0.01
I1007 11:34:53.761505  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:34:54.096072  4720 solver.cpp:330] Iteration 60500, Testing net (#0)
I1007 11:34:56.030601  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:34:56.111104  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9159
I1007 11:34:56.111138  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.340813 (* 1 = 0.340813 loss)
I1007 11:34:56.194857  4720 solver.cpp:218] Iteration 60500 (9.64414 iter/s, 10.369s/100 iters), loss = 0.00670471
I1007 11:34:56.194885  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00670497 (* 1 = 0.00670497 loss)
I1007 11:34:56.194891  4720 sgd_solver.cpp:105] Iteration 60500, lr = 0.01
I1007 11:35:04.562093  4720 solver.cpp:218] Iteration 60600 (11.9515 iter/s, 8.36718s/100 iters), loss = 0.0082684
I1007 11:35:04.562134  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00826866 (* 1 = 0.00826866 loss)
I1007 11:35:04.562139  4720 sgd_solver.cpp:105] Iteration 60600, lr = 0.01
I1007 11:35:12.919189  4720 solver.cpp:218] Iteration 60700 (11.966 iter/s, 8.35703s/100 iters), loss = 0.0165616
I1007 11:35:12.919229  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0165619 (* 1 = 0.0165619 loss)
I1007 11:35:12.919235  4720 sgd_solver.cpp:105] Iteration 60700, lr = 0.01
I1007 11:35:21.288097  4720 solver.cpp:218] Iteration 60800 (11.9491 iter/s, 8.36884s/100 iters), loss = 0.0161272
I1007 11:35:21.288259  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0161275 (* 1 = 0.0161275 loss)
I1007 11:35:21.288267  4720 sgd_solver.cpp:105] Iteration 60800, lr = 0.01
I1007 11:35:29.647922  4720 solver.cpp:218] Iteration 60900 (11.9622 iter/s, 8.35965s/100 iters), loss = 0.0191547
I1007 11:35:29.647953  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.019155 (* 1 = 0.019155 loss)
I1007 11:35:29.647969  4720 sgd_solver.cpp:105] Iteration 60900, lr = 0.01
I1007 11:35:37.601510  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:35:37.936028  4720 solver.cpp:330] Iteration 61000, Testing net (#0)
I1007 11:35:39.870529  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:35:39.950826  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9148
I1007 11:35:39.950860  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.33677 (* 1 = 0.33677 loss)
I1007 11:35:40.033995  4720 solver.cpp:218] Iteration 61000 (9.62833 iter/s, 10.386s/100 iters), loss = 0.0128741
I1007 11:35:40.034023  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0128744 (* 1 = 0.0128744 loss)
I1007 11:35:40.034029  4720 sgd_solver.cpp:105] Iteration 61000, lr = 0.01
I1007 11:35:48.395551  4720 solver.cpp:218] Iteration 61100 (11.9596 iter/s, 8.3615s/100 iters), loss = 0.0677553
I1007 11:35:48.395591  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0677556 (* 1 = 0.0677556 loss)
I1007 11:35:48.395596  4720 sgd_solver.cpp:105] Iteration 61100, lr = 0.01
I1007 11:35:56.762300  4720 solver.cpp:218] Iteration 61200 (11.9522 iter/s, 8.36669s/100 iters), loss = 0.00782351
I1007 11:35:56.762372  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00782379 (* 1 = 0.00782379 loss)
I1007 11:35:56.762388  4720 sgd_solver.cpp:105] Iteration 61200, lr = 0.01
I1007 11:36:05.129230  4720 solver.cpp:218] Iteration 61300 (11.9519 iter/s, 8.36684s/100 iters), loss = 0.00944965
I1007 11:36:05.129271  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00944993 (* 1 = 0.00944993 loss)
I1007 11:36:05.129276  4720 sgd_solver.cpp:105] Iteration 61300, lr = 0.01
I1007 11:36:13.493023  4720 solver.cpp:218] Iteration 61400 (11.9564 iter/s, 8.36373s/100 iters), loss = 0.019473
I1007 11:36:13.493063  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0194733 (* 1 = 0.0194733 loss)
I1007 11:36:13.493069  4720 sgd_solver.cpp:105] Iteration 61400, lr = 0.01
I1007 11:36:21.436882  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:36:21.770859  4720 solver.cpp:330] Iteration 61500, Testing net (#0)
I1007 11:36:23.704965  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:36:23.786080  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.914
I1007 11:36:23.786114  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.345416 (* 1 = 0.345416 loss)
I1007 11:36:23.870316  4720 solver.cpp:218] Iteration 61500 (9.63649 iter/s, 10.3772s/100 iters), loss = 0.0146772
I1007 11:36:23.870352  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0146775 (* 1 = 0.0146775 loss)
I1007 11:36:23.870357  4720 sgd_solver.cpp:105] Iteration 61500, lr = 0.01
I1007 11:36:32.232475  4720 solver.cpp:218] Iteration 61600 (11.9587 iter/s, 8.3621s/100 iters), loss = 0.0114874
I1007 11:36:32.232581  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0114877 (* 1 = 0.0114877 loss)
I1007 11:36:32.232589  4720 sgd_solver.cpp:105] Iteration 61600, lr = 0.01
I1007 11:36:40.587430  4720 solver.cpp:218] Iteration 61700 (11.9691 iter/s, 8.35484s/100 iters), loss = 0.0138496
I1007 11:36:40.587460  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0138499 (* 1 = 0.0138499 loss)
I1007 11:36:40.587466  4720 sgd_solver.cpp:105] Iteration 61700, lr = 0.01
I1007 11:36:48.944103  4720 solver.cpp:218] Iteration 61800 (11.9666 iter/s, 8.35662s/100 iters), loss = 0.00658256
I1007 11:36:48.944133  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00658285 (* 1 = 0.00658285 loss)
I1007 11:36:48.944149  4720 sgd_solver.cpp:105] Iteration 61800, lr = 0.01
I1007 11:36:57.299149  4720 solver.cpp:218] Iteration 61900 (11.9689 iter/s, 8.35499s/100 iters), loss = 0.0141407
I1007 11:36:57.299183  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.014141 (* 1 = 0.014141 loss)
I1007 11:36:57.299190  4720 sgd_solver.cpp:105] Iteration 61900, lr = 0.01
I1007 11:37:05.246685  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:37:05.579975  4720 solver.cpp:330] Iteration 62000, Testing net (#0)
I1007 11:37:07.512969  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:37:07.593958  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9159
I1007 11:37:07.593996  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.34139 (* 1 = 0.34139 loss)
I1007 11:37:07.677011  4720 solver.cpp:218] Iteration 62000 (9.63595 iter/s, 10.3778s/100 iters), loss = 0.00907561
I1007 11:37:07.677039  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0090759 (* 1 = 0.0090759 loss)
I1007 11:37:07.677045  4720 sgd_solver.cpp:105] Iteration 62000, lr = 0.01
I1007 11:37:16.028554  4720 solver.cpp:218] Iteration 62100 (11.9739 iter/s, 8.35149s/100 iters), loss = 0.01132
I1007 11:37:16.028584  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0113203 (* 1 = 0.0113203 loss)
I1007 11:37:16.028590  4720 sgd_solver.cpp:105] Iteration 62100, lr = 0.01
I1007 11:37:24.387259  4720 solver.cpp:218] Iteration 62200 (11.9637 iter/s, 8.35865s/100 iters), loss = 0.0055293
I1007 11:37:24.387295  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00552959 (* 1 = 0.00552959 loss)
I1007 11:37:24.387302  4720 sgd_solver.cpp:105] Iteration 62200, lr = 0.01
I1007 11:37:32.740072  4720 solver.cpp:218] Iteration 62300 (11.9721 iter/s, 8.35275s/100 iters), loss = 0.00851919
I1007 11:37:32.740111  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00851948 (* 1 = 0.00851948 loss)
I1007 11:37:32.740118  4720 sgd_solver.cpp:105] Iteration 62300, lr = 0.01
I1007 11:37:41.093798  4720 solver.cpp:218] Iteration 62400 (11.9708 iter/s, 8.35366s/100 iters), loss = 0.0162282
I1007 11:37:41.093883  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0162285 (* 1 = 0.0162285 loss)
I1007 11:37:41.093888  4720 sgd_solver.cpp:105] Iteration 62400, lr = 0.01
I1007 11:37:49.031054  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:37:49.366575  4720 solver.cpp:330] Iteration 62500, Testing net (#0)
I1007 11:37:51.300782  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:37:51.381486  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9112
I1007 11:37:51.381522  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.35071 (* 1 = 0.35071 loss)
I1007 11:37:51.465620  4720 solver.cpp:218] Iteration 62500 (9.6416 iter/s, 10.3717s/100 iters), loss = 0.0323781
I1007 11:37:51.465651  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0323784 (* 1 = 0.0323784 loss)
I1007 11:37:51.465656  4720 sgd_solver.cpp:105] Iteration 62500, lr = 0.01
I1007 11:37:59.826637  4720 solver.cpp:218] Iteration 62600 (11.9603 iter/s, 8.36096s/100 iters), loss = 0.00371623
I1007 11:37:59.826666  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00371651 (* 1 = 0.00371651 loss)
I1007 11:37:59.826673  4720 sgd_solver.cpp:105] Iteration 62600, lr = 0.01
I1007 11:38:08.172401  4720 solver.cpp:218] Iteration 62700 (11.9822 iter/s, 8.34571s/100 iters), loss = 0.00839469
I1007 11:38:08.172441  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00839497 (* 1 = 0.00839497 loss)
I1007 11:38:08.172447  4720 sgd_solver.cpp:105] Iteration 62700, lr = 0.01
I1007 11:38:16.532188  4720 solver.cpp:218] Iteration 62800 (11.9621 iter/s, 8.35972s/100 iters), loss = 0.0157175
I1007 11:38:16.532317  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0157178 (* 1 = 0.0157178 loss)
I1007 11:38:16.532326  4720 sgd_solver.cpp:105] Iteration 62800, lr = 0.01
I1007 11:38:24.887133  4720 solver.cpp:218] Iteration 62900 (11.9692 iter/s, 8.35479s/100 iters), loss = 0.00299024
I1007 11:38:24.887174  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00299051 (* 1 = 0.00299051 loss)
I1007 11:38:24.887181  4720 sgd_solver.cpp:105] Iteration 62900, lr = 0.01
I1007 11:38:32.836354  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:38:33.170780  4720 solver.cpp:330] Iteration 63000, Testing net (#0)
I1007 11:38:35.105388  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:38:35.185670  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9177
I1007 11:38:35.185705  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.329285 (* 1 = 0.329285 loss)
I1007 11:38:35.269032  4720 solver.cpp:218] Iteration 63000 (9.63221 iter/s, 10.3818s/100 iters), loss = 0.00501209
I1007 11:38:35.269065  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00501236 (* 1 = 0.00501236 loss)
I1007 11:38:35.269073  4720 sgd_solver.cpp:105] Iteration 63000, lr = 0.01
I1007 11:38:43.626953  4720 solver.cpp:218] Iteration 63100 (11.9648 iter/s, 8.35786s/100 iters), loss = 0.00636467
I1007 11:38:43.627001  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00636494 (* 1 = 0.00636494 loss)
I1007 11:38:43.627008  4720 sgd_solver.cpp:105] Iteration 63100, lr = 0.01
I1007 11:38:51.992944  4720 solver.cpp:218] Iteration 63200 (11.9533 iter/s, 8.36592s/100 iters), loss = 0.0102214
I1007 11:38:51.993050  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0102216 (* 1 = 0.0102216 loss)
I1007 11:38:51.993070  4720 sgd_solver.cpp:105] Iteration 63200, lr = 0.01
I1007 11:39:00.409538  4720 solver.cpp:218] Iteration 63300 (11.8815 iter/s, 8.41646s/100 iters), loss = 0.0489294
I1007 11:39:00.409569  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0489297 (* 1 = 0.0489297 loss)
I1007 11:39:00.409574  4720 sgd_solver.cpp:105] Iteration 63300, lr = 0.01
I1007 11:39:08.832720  4720 solver.cpp:218] Iteration 63400 (11.8721 iter/s, 8.42313s/100 iters), loss = 0.0268786
I1007 11:39:08.832752  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0268789 (* 1 = 0.0268789 loss)
I1007 11:39:08.832768  4720 sgd_solver.cpp:105] Iteration 63400, lr = 0.01
I1007 11:39:16.777551  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:39:17.112620  4720 solver.cpp:330] Iteration 63500, Testing net (#0)
I1007 11:39:19.046208  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:39:19.126937  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9182
I1007 11:39:19.126972  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.326187 (* 1 = 0.326187 loss)
I1007 11:39:19.210649  4720 solver.cpp:218] Iteration 63500 (9.63589 iter/s, 10.3779s/100 iters), loss = 0.00211712
I1007 11:39:19.210678  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0021174 (* 1 = 0.0021174 loss)
I1007 11:39:19.210685  4720 sgd_solver.cpp:105] Iteration 63500, lr = 0.01
I1007 11:39:27.566325  4720 solver.cpp:218] Iteration 63600 (11.968 iter/s, 8.35562s/100 iters), loss = 0.0438156
I1007 11:39:27.566459  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0438159 (* 1 = 0.0438159 loss)
I1007 11:39:27.566467  4720 sgd_solver.cpp:105] Iteration 63600, lr = 0.01
I1007 11:39:35.915187  4720 solver.cpp:218] Iteration 63700 (11.9779 iter/s, 8.34871s/100 iters), loss = 0.00814505
I1007 11:39:35.915217  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00814534 (* 1 = 0.00814534 loss)
I1007 11:39:35.915223  4720 sgd_solver.cpp:105] Iteration 63700, lr = 0.01
I1007 11:39:44.274056  4720 solver.cpp:218] Iteration 63800 (11.9634 iter/s, 8.35881s/100 iters), loss = 0.0572741
I1007 11:39:44.274086  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0572744 (* 1 = 0.0572744 loss)
I1007 11:39:44.274091  4720 sgd_solver.cpp:105] Iteration 63800, lr = 0.01
I1007 11:39:52.626606  4720 solver.cpp:218] Iteration 63900 (11.9725 iter/s, 8.3525s/100 iters), loss = 0.00384285
I1007 11:39:52.626636  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00384313 (* 1 = 0.00384313 loss)
I1007 11:39:52.626642  4720 sgd_solver.cpp:105] Iteration 63900, lr = 0.01
I1007 11:40:00.570235  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:40:00.905433  4720 solver.cpp:330] Iteration 64000, Testing net (#0)
I1007 11:40:02.836706  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:40:02.917201  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9122
I1007 11:40:02.917237  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.355142 (* 1 = 0.355142 loss)
I1007 11:40:03.000071  4720 solver.cpp:218] Iteration 64000 (9.64004 iter/s, 10.3734s/100 iters), loss = 0.0143547
I1007 11:40:03.000097  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.014355 (* 1 = 0.014355 loss)
I1007 11:40:03.000102  4720 sgd_solver.cpp:105] Iteration 64000, lr = 0.01
I1007 11:40:11.358651  4720 solver.cpp:218] Iteration 64100 (11.9638 iter/s, 8.35853s/100 iters), loss = 0.00829946
I1007 11:40:11.358691  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00829973 (* 1 = 0.00829973 loss)
I1007 11:40:11.358697  4720 sgd_solver.cpp:105] Iteration 64100, lr = 0.01
I1007 11:40:19.722590  4720 solver.cpp:218] Iteration 64200 (11.9562 iter/s, 8.36387s/100 iters), loss = 0.00463239
I1007 11:40:19.722621  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00463266 (* 1 = 0.00463266 loss)
I1007 11:40:19.722627  4720 sgd_solver.cpp:105] Iteration 64200, lr = 0.01
I1007 11:40:28.085278  4720 solver.cpp:218] Iteration 64300 (11.958 iter/s, 8.36263s/100 iters), loss = 0.00326121
I1007 11:40:28.085307  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00326148 (* 1 = 0.00326148 loss)
I1007 11:40:28.085314  4720 sgd_solver.cpp:105] Iteration 64300, lr = 0.01
I1007 11:40:36.450724  4720 solver.cpp:218] Iteration 64400 (11.954 iter/s, 8.36539s/100 iters), loss = 0.0168153
I1007 11:40:36.450834  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0168156 (* 1 = 0.0168156 loss)
I1007 11:40:36.450841  4720 sgd_solver.cpp:105] Iteration 64400, lr = 0.01
I1007 11:40:44.394121  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:40:44.730626  4720 solver.cpp:330] Iteration 64500, Testing net (#0)
I1007 11:40:46.663194  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:40:46.743572  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9107
I1007 11:40:46.743615  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.37234 (* 1 = 0.37234 loss)
I1007 11:40:46.827337  4720 solver.cpp:218] Iteration 64500 (9.63718 iter/s, 10.3765s/100 iters), loss = 0.0110318
I1007 11:40:46.827365  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.011032 (* 1 = 0.011032 loss)
I1007 11:40:46.827371  4720 sgd_solver.cpp:105] Iteration 64500, lr = 0.01
I1007 11:40:55.188269  4720 solver.cpp:218] Iteration 64600 (11.9605 iter/s, 8.36088s/100 iters), loss = 0.0117446
I1007 11:40:55.188310  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0117449 (* 1 = 0.0117449 loss)
I1007 11:40:55.188316  4720 sgd_solver.cpp:105] Iteration 64600, lr = 0.01
I1007 11:41:03.544067  4720 solver.cpp:218] Iteration 64700 (11.9678 iter/s, 8.35573s/100 iters), loss = 0.00667845
I1007 11:41:03.544098  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00667871 (* 1 = 0.00667871 loss)
I1007 11:41:03.544114  4720 sgd_solver.cpp:105] Iteration 64700, lr = 0.01
I1007 11:41:11.911392  4720 solver.cpp:218] Iteration 64800 (11.9513 iter/s, 8.36727s/100 iters), loss = 0.00579709
I1007 11:41:11.911516  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00579734 (* 1 = 0.00579734 loss)
I1007 11:41:11.911523  4720 sgd_solver.cpp:105] Iteration 64800, lr = 0.01
I1007 11:41:20.275921  4720 solver.cpp:218] Iteration 64900 (11.9555 iter/s, 8.36438s/100 iters), loss = 0.00571271
I1007 11:41:20.275961  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00571296 (* 1 = 0.00571296 loss)
I1007 11:41:20.275967  4720 sgd_solver.cpp:105] Iteration 64900, lr = 0.01
I1007 11:41:28.227783  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:41:28.562412  4720 solver.cpp:330] Iteration 65000, Testing net (#0)
I1007 11:41:30.497419  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:41:30.577826  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9142
I1007 11:41:30.577860  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.345819 (* 1 = 0.345819 loss)
I1007 11:41:30.660815  4720 solver.cpp:218] Iteration 65000 (9.62944 iter/s, 10.3848s/100 iters), loss = 0.0330818
I1007 11:41:30.660843  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.033082 (* 1 = 0.033082 loss)
I1007 11:41:30.660850  4720 sgd_solver.cpp:105] Iteration 65000, lr = 0.01
I1007 11:41:39.018117  4720 solver.cpp:218] Iteration 65100 (11.9657 iter/s, 8.35725s/100 iters), loss = 0.0034602
I1007 11:41:39.018157  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00346046 (* 1 = 0.00346046 loss)
I1007 11:41:39.018163  4720 sgd_solver.cpp:105] Iteration 65100, lr = 0.01
I1007 11:41:47.379736  4720 solver.cpp:218] Iteration 65200 (11.9595 iter/s, 8.36156s/100 iters), loss = 0.00127068
I1007 11:41:47.379883  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00127095 (* 1 = 0.00127095 loss)
I1007 11:41:47.379891  4720 sgd_solver.cpp:105] Iteration 65200, lr = 0.01
I1007 11:41:55.738906  4720 solver.cpp:218] Iteration 65300 (11.9631 iter/s, 8.359s/100 iters), loss = 0.00384175
I1007 11:41:55.738946  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00384203 (* 1 = 0.00384203 loss)
I1007 11:41:55.738952  4720 sgd_solver.cpp:105] Iteration 65300, lr = 0.01
I1007 11:42:04.099670  4720 solver.cpp:218] Iteration 65400 (11.9607 iter/s, 8.3607s/100 iters), loss = 0.00320911
I1007 11:42:04.099700  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00320939 (* 1 = 0.00320939 loss)
I1007 11:42:04.099706  4720 sgd_solver.cpp:105] Iteration 65400, lr = 0.01
I1007 11:42:12.048120  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:42:12.383291  4720 solver.cpp:330] Iteration 65500, Testing net (#0)
I1007 11:42:14.316138  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:42:14.396991  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9171
I1007 11:42:14.397028  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.338584 (* 1 = 0.338584 loss)
I1007 11:42:14.480531  4720 solver.cpp:218] Iteration 65500 (9.63317 iter/s, 10.3808s/100 iters), loss = 0.00202377
I1007 11:42:14.480561  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00202405 (* 1 = 0.00202405 loss)
I1007 11:42:14.480566  4720 sgd_solver.cpp:105] Iteration 65500, lr = 0.01
I1007 11:42:22.842638  4720 solver.cpp:218] Iteration 65600 (11.9588 iter/s, 8.36206s/100 iters), loss = 0.00565552
I1007 11:42:22.842747  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0056558 (* 1 = 0.0056558 loss)
I1007 11:42:22.842754  4720 sgd_solver.cpp:105] Iteration 65600, lr = 0.01
I1007 11:42:31.194761  4720 solver.cpp:218] Iteration 65700 (11.9732 iter/s, 8.35199s/100 iters), loss = 0.0111299
I1007 11:42:31.194790  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0111302 (* 1 = 0.0111302 loss)
I1007 11:42:31.194795  4720 sgd_solver.cpp:105] Iteration 65700, lr = 0.01
I1007 11:42:39.552572  4720 solver.cpp:218] Iteration 65800 (11.9649 iter/s, 8.35776s/100 iters), loss = 0.0150741
I1007 11:42:39.552603  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0150744 (* 1 = 0.0150744 loss)
I1007 11:42:39.552608  4720 sgd_solver.cpp:105] Iteration 65800, lr = 0.01
I1007 11:42:47.911150  4720 solver.cpp:218] Iteration 65900 (11.9638 iter/s, 8.35852s/100 iters), loss = 0.011303
I1007 11:42:47.911191  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0113032 (* 1 = 0.0113032 loss)
I1007 11:42:47.911197  4720 sgd_solver.cpp:105] Iteration 65900, lr = 0.01
I1007 11:42:55.853991  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:42:56.189206  4720 solver.cpp:330] Iteration 66000, Testing net (#0)
I1007 11:42:58.119942  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:42:58.200630  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9133
I1007 11:42:58.200656  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.349434 (* 1 = 0.349434 loss)
I1007 11:42:58.283748  4720 solver.cpp:218] Iteration 66000 (9.64085 iter/s, 10.3725s/100 iters), loss = 0.00146847
I1007 11:42:58.283780  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00146874 (* 1 = 0.00146874 loss)
I1007 11:42:58.283787  4720 sgd_solver.cpp:105] Iteration 66000, lr = 0.01
I1007 11:43:06.640498  4720 solver.cpp:218] Iteration 66100 (11.9665 iter/s, 8.35669s/100 iters), loss = 0.0039551
I1007 11:43:06.640538  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00395537 (* 1 = 0.00395537 loss)
I1007 11:43:06.640543  4720 sgd_solver.cpp:105] Iteration 66100, lr = 0.01
I1007 11:43:14.995965  4720 solver.cpp:218] Iteration 66200 (11.9683 iter/s, 8.3554s/100 iters), loss = 0.0126718
I1007 11:43:14.995995  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0126721 (* 1 = 0.0126721 loss)
I1007 11:43:14.996001  4720 sgd_solver.cpp:105] Iteration 66200, lr = 0.01
I1007 11:43:23.346794  4720 solver.cpp:218] Iteration 66300 (11.9749 iter/s, 8.35077s/100 iters), loss = 0.0121938
I1007 11:43:23.346823  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.012194 (* 1 = 0.012194 loss)
I1007 11:43:23.346828  4720 sgd_solver.cpp:105] Iteration 66300, lr = 0.01
I1007 11:43:31.700911  4720 solver.cpp:218] Iteration 66400 (11.9702 iter/s, 8.35406s/100 iters), loss = 0.0413597
I1007 11:43:31.701031  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0413599 (* 1 = 0.0413599 loss)
I1007 11:43:31.701038  4720 sgd_solver.cpp:105] Iteration 66400, lr = 0.01
I1007 11:43:39.640218  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:43:39.976245  4720 solver.cpp:330] Iteration 66500, Testing net (#0)
I1007 11:43:41.908315  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:43:41.989202  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9083
I1007 11:43:41.989236  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.365094 (* 1 = 0.365094 loss)
I1007 11:43:42.072250  4720 solver.cpp:218] Iteration 66500 (9.64209 iter/s, 10.3712s/100 iters), loss = 0.00508002
I1007 11:43:42.072279  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00508028 (* 1 = 0.00508028 loss)
I1007 11:43:42.072286  4720 sgd_solver.cpp:105] Iteration 66500, lr = 0.01
I1007 11:43:50.433267  4720 solver.cpp:218] Iteration 66600 (11.9603 iter/s, 8.36096s/100 iters), loss = 0.00737278
I1007 11:43:50.433302  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00737305 (* 1 = 0.00737305 loss)
I1007 11:43:50.433310  4720 sgd_solver.cpp:105] Iteration 66600, lr = 0.01
I1007 11:43:58.782189  4720 solver.cpp:218] Iteration 66700 (11.9777 iter/s, 8.34886s/100 iters), loss = 0.00108112
I1007 11:43:58.782236  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0010814 (* 1 = 0.0010814 loss)
I1007 11:43:58.782244  4720 sgd_solver.cpp:105] Iteration 66700, lr = 0.01
I1007 11:44:07.143084  4720 solver.cpp:218] Iteration 66800 (11.9605 iter/s, 8.36082s/100 iters), loss = 0.0508607
I1007 11:44:07.143200  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0508609 (* 1 = 0.0508609 loss)
I1007 11:44:07.143216  4720 sgd_solver.cpp:105] Iteration 66800, lr = 0.01
I1007 11:44:15.496106  4720 solver.cpp:218] Iteration 66900 (11.9719 iter/s, 8.35289s/100 iters), loss = 0.00491918
I1007 11:44:15.496136  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00491943 (* 1 = 0.00491943 loss)
I1007 11:44:15.496142  4720 sgd_solver.cpp:105] Iteration 66900, lr = 0.01
I1007 11:44:23.444555  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:44:23.778728  4720 solver.cpp:330] Iteration 67000, Testing net (#0)
I1007 11:44:25.711990  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:44:25.791990  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9164
I1007 11:44:25.792026  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.340695 (* 1 = 0.340695 loss)
I1007 11:44:25.875387  4720 solver.cpp:218] Iteration 67000 (9.63463 iter/s, 10.3792s/100 iters), loss = 0.00443287
I1007 11:44:25.875416  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00443313 (* 1 = 0.00443313 loss)
I1007 11:44:25.875422  4720 sgd_solver.cpp:105] Iteration 67000, lr = 0.01
I1007 11:44:34.233412  4720 solver.cpp:218] Iteration 67100 (11.9646 iter/s, 8.35797s/100 iters), loss = 0.00448427
I1007 11:44:34.233451  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00448452 (* 1 = 0.00448452 loss)
I1007 11:44:34.233458  4720 sgd_solver.cpp:105] Iteration 67100, lr = 0.01
I1007 11:44:42.599931  4720 solver.cpp:218] Iteration 67200 (11.9525 iter/s, 8.36646s/100 iters), loss = 0.00769581
I1007 11:44:42.600021  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00769606 (* 1 = 0.00769606 loss)
I1007 11:44:42.600037  4720 sgd_solver.cpp:105] Iteration 67200, lr = 0.01
I1007 11:44:50.959590  4720 solver.cpp:218] Iteration 67300 (11.9624 iter/s, 8.35955s/100 iters), loss = 0.0101609
I1007 11:44:50.959617  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0101612 (* 1 = 0.0101612 loss)
I1007 11:44:50.959623  4720 sgd_solver.cpp:105] Iteration 67300, lr = 0.01
I1007 11:44:59.325700  4720 solver.cpp:218] Iteration 67400 (11.9531 iter/s, 8.36606s/100 iters), loss = 0.0171907
I1007 11:44:59.325728  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.017191 (* 1 = 0.017191 loss)
I1007 11:44:59.325734  4720 sgd_solver.cpp:105] Iteration 67400, lr = 0.01
I1007 11:45:07.274253  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:45:07.608600  4720 solver.cpp:330] Iteration 67500, Testing net (#0)
I1007 11:45:09.540406  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:45:09.621008  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.912
I1007 11:45:09.621044  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.374685 (* 1 = 0.374685 loss)
I1007 11:45:09.704283  4720 solver.cpp:218] Iteration 67500 (9.63528 iter/s, 10.3785s/100 iters), loss = 0.00876945
I1007 11:45:09.704311  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0087697 (* 1 = 0.0087697 loss)
I1007 11:45:09.704319  4720 sgd_solver.cpp:105] Iteration 67500, lr = 0.01
I1007 11:45:18.069160  4720 solver.cpp:218] Iteration 67600 (11.9548 iter/s, 8.36482s/100 iters), loss = 0.0306288
I1007 11:45:18.069295  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.030629 (* 1 = 0.030629 loss)
I1007 11:45:18.069304  4720 sgd_solver.cpp:105] Iteration 67600, lr = 0.01
I1007 11:45:26.427158  4720 solver.cpp:218] Iteration 67700 (11.9648 iter/s, 8.35785s/100 iters), loss = 0.00847331
I1007 11:45:26.427188  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00847357 (* 1 = 0.00847357 loss)
I1007 11:45:26.427194  4720 sgd_solver.cpp:105] Iteration 67700, lr = 0.01
I1007 11:45:34.779124  4720 solver.cpp:218] Iteration 67800 (11.9733 iter/s, 8.35191s/100 iters), loss = 0.0171384
I1007 11:45:34.779176  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0171387 (* 1 = 0.0171387 loss)
I1007 11:45:34.779194  4720 sgd_solver.cpp:105] Iteration 67800, lr = 0.01
I1007 11:45:43.133731  4720 solver.cpp:218] Iteration 67900 (11.9695 iter/s, 8.35454s/100 iters), loss = 0.00675679
I1007 11:45:43.133761  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00675705 (* 1 = 0.00675705 loss)
I1007 11:45:43.133767  4720 sgd_solver.cpp:105] Iteration 67900, lr = 0.01
I1007 11:45:51.073125  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:45:51.408404  4720 solver.cpp:330] Iteration 68000, Testing net (#0)
I1007 11:45:53.339340  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:45:53.420284  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9156
I1007 11:45:53.420320  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.359049 (* 1 = 0.359049 loss)
I1007 11:45:53.503504  4720 solver.cpp:218] Iteration 68000 (9.64347 iter/s, 10.3697s/100 iters), loss = 0.00667639
I1007 11:45:53.503532  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00667664 (* 1 = 0.00667664 loss)
I1007 11:45:53.503540  4720 sgd_solver.cpp:105] Iteration 68000, lr = 0.01
I1007 11:46:01.850790  4720 solver.cpp:218] Iteration 68100 (11.98 iter/s, 8.34723s/100 iters), loss = 0.0427787
I1007 11:46:01.850818  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0427789 (* 1 = 0.0427789 loss)
I1007 11:46:01.850824  4720 sgd_solver.cpp:105] Iteration 68100, lr = 0.01
I1007 11:46:10.212437  4720 solver.cpp:218] Iteration 68200 (11.9594 iter/s, 8.36159s/100 iters), loss = 0.0128393
I1007 11:46:10.212469  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0128396 (* 1 = 0.0128396 loss)
I1007 11:46:10.212476  4720 sgd_solver.cpp:105] Iteration 68200, lr = 0.01
I1007 11:46:18.561416  4720 solver.cpp:218] Iteration 68300 (11.9776 iter/s, 8.34892s/100 iters), loss = 0.0334461
I1007 11:46:18.561456  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0334463 (* 1 = 0.0334463 loss)
I1007 11:46:18.561461  4720 sgd_solver.cpp:105] Iteration 68300, lr = 0.01
I1007 11:46:26.924773  4720 solver.cpp:218] Iteration 68400 (11.957 iter/s, 8.36329s/100 iters), loss = 0.00651372
I1007 11:46:26.924885  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00651398 (* 1 = 0.00651398 loss)
I1007 11:46:26.924893  4720 sgd_solver.cpp:105] Iteration 68400, lr = 0.01
I1007 11:46:34.865655  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:46:35.200376  4720 solver.cpp:330] Iteration 68500, Testing net (#0)
I1007 11:46:37.134341  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:46:37.215241  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9118
I1007 11:46:37.215277  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.348503 (* 1 = 0.348503 loss)
I1007 11:46:37.299404  4720 solver.cpp:218] Iteration 68500 (9.63902 iter/s, 10.3745s/100 iters), loss = 0.00197506
I1007 11:46:37.299437  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00197531 (* 1 = 0.00197531 loss)
I1007 11:46:37.299444  4720 sgd_solver.cpp:105] Iteration 68500, lr = 0.01
I1007 11:46:45.666913  4720 solver.cpp:218] Iteration 68600 (11.9511 iter/s, 8.36745s/100 iters), loss = 0.00872335
I1007 11:46:45.666944  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0087236 (* 1 = 0.0087236 loss)
I1007 11:46:45.666959  4720 sgd_solver.cpp:105] Iteration 68600, lr = 0.01
I1007 11:46:54.026860  4720 solver.cpp:218] Iteration 68700 (11.9619 iter/s, 8.35989s/100 iters), loss = 0.0137752
I1007 11:46:54.026888  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0137754 (* 1 = 0.0137754 loss)
I1007 11:46:54.026895  4720 sgd_solver.cpp:105] Iteration 68700, lr = 0.01
I1007 11:47:02.391767  4720 solver.cpp:218] Iteration 68800 (11.9548 iter/s, 8.36485s/100 iters), loss = 0.0168035
I1007 11:47:02.391885  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0168037 (* 1 = 0.0168037 loss)
I1007 11:47:02.391902  4720 sgd_solver.cpp:105] Iteration 68800, lr = 0.01
I1007 11:47:10.757860  4720 solver.cpp:218] Iteration 68900 (11.9532 iter/s, 8.36595s/100 iters), loss = 0.020751
I1007 11:47:10.757890  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0207513 (* 1 = 0.0207513 loss)
I1007 11:47:10.757906  4720 sgd_solver.cpp:105] Iteration 68900, lr = 0.01
I1007 11:47:18.705636  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:47:19.039958  4720 solver.cpp:330] Iteration 69000, Testing net (#0)
I1007 11:47:20.973870  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:47:21.054044  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9117
I1007 11:47:21.054069  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.357643 (* 1 = 0.357643 loss)
I1007 11:47:21.136406  4720 solver.cpp:218] Iteration 69000 (9.63531 iter/s, 10.3785s/100 iters), loss = 0.006161
I1007 11:47:21.136435  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00616124 (* 1 = 0.00616124 loss)
I1007 11:47:21.136441  4720 sgd_solver.cpp:105] Iteration 69000, lr = 0.01
I1007 11:47:29.483690  4720 solver.cpp:218] Iteration 69100 (11.98 iter/s, 8.34723s/100 iters), loss = 0.0118934
I1007 11:47:29.483719  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0118936 (* 1 = 0.0118936 loss)
I1007 11:47:29.483726  4720 sgd_solver.cpp:105] Iteration 69100, lr = 0.01
I1007 11:47:37.836287  4720 solver.cpp:218] Iteration 69200 (11.9724 iter/s, 8.35254s/100 iters), loss = 0.0236756
I1007 11:47:37.836412  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0236758 (* 1 = 0.0236758 loss)
I1007 11:47:37.836419  4720 sgd_solver.cpp:105] Iteration 69200, lr = 0.01
I1007 11:47:46.188885  4720 solver.cpp:218] Iteration 69300 (11.9725 iter/s, 8.35245s/100 iters), loss = 0.00513425
I1007 11:47:46.188925  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00513449 (* 1 = 0.00513449 loss)
I1007 11:47:46.188931  4720 sgd_solver.cpp:105] Iteration 69300, lr = 0.01
I1007 11:47:54.543416  4720 solver.cpp:218] Iteration 69400 (11.9696 iter/s, 8.35447s/100 iters), loss = 0.0296192
I1007 11:47:54.543455  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0296194 (* 1 = 0.0296194 loss)
I1007 11:47:54.543462  4720 sgd_solver.cpp:105] Iteration 69400, lr = 0.01
I1007 11:48:02.482053  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:48:02.816771  4720 solver.cpp:330] Iteration 69500, Testing net (#0)
I1007 11:48:04.748227  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:48:04.829102  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9143
I1007 11:48:04.829138  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.333794 (* 1 = 0.333794 loss)
I1007 11:48:04.912807  4720 solver.cpp:218] Iteration 69500 (9.64383 iter/s, 10.3693s/100 iters), loss = 0.00720984
I1007 11:48:04.912837  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00721009 (* 1 = 0.00721009 loss)
I1007 11:48:04.912842  4720 sgd_solver.cpp:105] Iteration 69500, lr = 0.01
I1007 11:48:13.270604  4720 solver.cpp:218] Iteration 69600 (11.965 iter/s, 8.35774s/100 iters), loss = 0.00624941
I1007 11:48:13.270746  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00624965 (* 1 = 0.00624965 loss)
I1007 11:48:13.270754  4720 sgd_solver.cpp:105] Iteration 69600, lr = 0.01
I1007 11:48:21.622473  4720 solver.cpp:218] Iteration 69700 (11.9736 iter/s, 8.35171s/100 iters), loss = 0.0576472
I1007 11:48:21.622514  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0576475 (* 1 = 0.0576475 loss)
I1007 11:48:21.622520  4720 sgd_solver.cpp:105] Iteration 69700, lr = 0.01
I1007 11:48:29.977732  4720 solver.cpp:218] Iteration 69800 (11.9686 iter/s, 8.35519s/100 iters), loss = 0.0134609
I1007 11:48:29.977772  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0134611 (* 1 = 0.0134611 loss)
I1007 11:48:29.977778  4720 sgd_solver.cpp:105] Iteration 69800, lr = 0.01
I1007 11:48:38.331131  4720 solver.cpp:218] Iteration 69900 (11.9713 iter/s, 8.35333s/100 iters), loss = 0.0229626
I1007 11:48:38.331173  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0229629 (* 1 = 0.0229629 loss)
I1007 11:48:38.331179  4720 sgd_solver.cpp:105] Iteration 69900, lr = 0.01
I1007 11:48:46.274076  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:48:46.608970  4720 solver.cpp:330] Iteration 70000, Testing net (#0)
I1007 11:48:48.541823  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:48:48.622890  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9167
I1007 11:48:48.622926  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.339268 (* 1 = 0.339268 loss)
I1007 11:48:48.706563  4720 solver.cpp:218] Iteration 70000 (9.63822 iter/s, 10.3754s/100 iters), loss = 0.00211451
I1007 11:48:48.706598  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00211474 (* 1 = 0.00211474 loss)
I1007 11:48:48.706606  4720 sgd_solver.cpp:105] Iteration 70000, lr = 0.01
I1007 11:48:57.066097  4720 solver.cpp:218] Iteration 70100 (11.9625 iter/s, 8.35948s/100 iters), loss = 0.00997678
I1007 11:48:57.066136  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00997701 (* 1 = 0.00997701 loss)
I1007 11:48:57.066141  4720 sgd_solver.cpp:105] Iteration 70100, lr = 0.01
I1007 11:49:05.432301  4720 solver.cpp:218] Iteration 70200 (11.9529 iter/s, 8.36614s/100 iters), loss = 0.00622827
I1007 11:49:05.432332  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00622849 (* 1 = 0.00622849 loss)
I1007 11:49:05.432338  4720 sgd_solver.cpp:105] Iteration 70200, lr = 0.01
I1007 11:49:13.792279  4720 solver.cpp:218] Iteration 70300 (11.9618 iter/s, 8.35992s/100 iters), loss = 0.00902675
I1007 11:49:13.792318  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00902698 (* 1 = 0.00902698 loss)
I1007 11:49:13.792323  4720 sgd_solver.cpp:105] Iteration 70300, lr = 0.01
I1007 11:49:22.151612  4720 solver.cpp:218] Iteration 70400 (11.9628 iter/s, 8.35927s/100 iters), loss = 0.000677224
I1007 11:49:22.151696  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00067745 (* 1 = 0.00067745 loss)
I1007 11:49:22.151713  4720 sgd_solver.cpp:105] Iteration 70400, lr = 0.01
I1007 11:49:30.093778  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:49:30.428390  4720 solver.cpp:330] Iteration 70500, Testing net (#0)
I1007 11:49:32.359225  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:49:32.440172  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9162
I1007 11:49:32.440209  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.346241 (* 1 = 0.346241 loss)
I1007 11:49:32.523672  4720 solver.cpp:218] Iteration 70500 (9.64139 iter/s, 10.3719s/100 iters), loss = 0.00694377
I1007 11:49:32.523701  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.006944 (* 1 = 0.006944 loss)
I1007 11:49:32.523707  4720 sgd_solver.cpp:105] Iteration 70500, lr = 0.01
I1007 11:49:40.883102  4720 solver.cpp:218] Iteration 70600 (11.9626 iter/s, 8.35938s/100 iters), loss = 0.0164162
I1007 11:49:40.883141  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0164164 (* 1 = 0.0164164 loss)
I1007 11:49:40.883147  4720 sgd_solver.cpp:105] Iteration 70600, lr = 0.01
I1007 11:49:49.232810  4720 solver.cpp:218] Iteration 70700 (11.9766 iter/s, 8.34964s/100 iters), loss = 0.0135797
I1007 11:49:49.232839  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.01358 (* 1 = 0.01358 loss)
I1007 11:49:49.232846  4720 sgd_solver.cpp:105] Iteration 70700, lr = 0.01
I1007 11:49:57.591315  4720 solver.cpp:218] Iteration 70800 (11.9639 iter/s, 8.35845s/100 iters), loss = 0.00766395
I1007 11:49:57.591434  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00766418 (* 1 = 0.00766418 loss)
I1007 11:49:57.591442  4720 sgd_solver.cpp:105] Iteration 70800, lr = 0.01
I1007 11:50:05.946754  4720 solver.cpp:218] Iteration 70900 (11.9684 iter/s, 8.35531s/100 iters), loss = 0.00238648
I1007 11:50:05.946795  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00238671 (* 1 = 0.00238671 loss)
I1007 11:50:05.946801  4720 sgd_solver.cpp:105] Iteration 70900, lr = 0.01
I1007 11:50:13.895349  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:50:14.229583  4720 solver.cpp:330] Iteration 71000, Testing net (#0)
I1007 11:50:16.163259  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:50:16.243628  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.911
I1007 11:50:16.243664  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.363318 (* 1 = 0.363318 loss)
I1007 11:50:16.327201  4720 solver.cpp:218] Iteration 71000 (9.63356 iter/s, 10.3804s/100 iters), loss = 0.00796715
I1007 11:50:16.327229  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00796739 (* 1 = 0.00796739 loss)
I1007 11:50:16.327236  4720 sgd_solver.cpp:105] Iteration 71000, lr = 0.01
I1007 11:50:24.678231  4720 solver.cpp:218] Iteration 71100 (11.9746 iter/s, 8.35098s/100 iters), loss = 0.0150835
I1007 11:50:24.678270  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0150837 (* 1 = 0.0150837 loss)
I1007 11:50:24.678275  4720 sgd_solver.cpp:105] Iteration 71100, lr = 0.01
I1007 11:50:33.042007  4720 solver.cpp:218] Iteration 71200 (11.9564 iter/s, 8.36371s/100 iters), loss = 0.0224198
I1007 11:50:33.042089  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.02242 (* 1 = 0.02242 loss)
I1007 11:50:33.042105  4720 sgd_solver.cpp:105] Iteration 71200, lr = 0.01
I1007 11:50:41.394129  4720 solver.cpp:218] Iteration 71300 (11.9732 iter/s, 8.35201s/100 iters), loss = 0.0125389
I1007 11:50:41.394176  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0125392 (* 1 = 0.0125392 loss)
I1007 11:50:41.394182  4720 sgd_solver.cpp:105] Iteration 71300, lr = 0.01
I1007 11:50:49.748265  4720 solver.cpp:218] Iteration 71400 (11.9702 iter/s, 8.35406s/100 iters), loss = 0.00229227
I1007 11:50:49.748311  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00229251 (* 1 = 0.00229251 loss)
I1007 11:50:49.748318  4720 sgd_solver.cpp:105] Iteration 71400, lr = 0.01
I1007 11:50:57.687374  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:50:58.021939  4720 solver.cpp:330] Iteration 71500, Testing net (#0)
I1007 11:50:59.953956  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:51:00.034559  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.903
I1007 11:51:00.034593  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.391345 (* 1 = 0.391345 loss)
I1007 11:51:00.118603  4720 solver.cpp:218] Iteration 71500 (9.64296 iter/s, 10.3703s/100 iters), loss = 0.0162676
I1007 11:51:00.118634  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0162678 (* 1 = 0.0162678 loss)
I1007 11:51:00.118641  4720 sgd_solver.cpp:105] Iteration 71500, lr = 0.01
I1007 11:51:08.487432  4720 solver.cpp:218] Iteration 71600 (11.9492 iter/s, 8.36877s/100 iters), loss = 0.0144922
I1007 11:51:08.487581  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0144924 (* 1 = 0.0144924 loss)
I1007 11:51:08.487591  4720 sgd_solver.cpp:105] Iteration 71600, lr = 0.01
I1007 11:51:16.841946  4720 solver.cpp:218] Iteration 71700 (11.9698 iter/s, 8.35434s/100 iters), loss = 0.00492529
I1007 11:51:16.841986  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00492551 (* 1 = 0.00492551 loss)
I1007 11:51:16.841991  4720 sgd_solver.cpp:105] Iteration 71700, lr = 0.01
I1007 11:51:25.194104  4720 solver.cpp:218] Iteration 71800 (11.973 iter/s, 8.35209s/100 iters), loss = 0.0031778
I1007 11:51:25.194141  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00317803 (* 1 = 0.00317803 loss)
I1007 11:51:25.194149  4720 sgd_solver.cpp:105] Iteration 71800, lr = 0.01
I1007 11:51:33.551345  4720 solver.cpp:218] Iteration 71900 (11.9658 iter/s, 8.35718s/100 iters), loss = 0.0120199
I1007 11:51:33.551381  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0120201 (* 1 = 0.0120201 loss)
I1007 11:51:33.551388  4720 sgd_solver.cpp:105] Iteration 71900, lr = 0.01
I1007 11:51:41.495955  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:51:41.829522  4720 solver.cpp:330] Iteration 72000, Testing net (#0)
I1007 11:51:43.760917  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:51:43.842097  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9087
I1007 11:51:43.842120  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.368908 (* 1 = 0.368908 loss)
I1007 11:51:43.925330  4720 solver.cpp:218] Iteration 72000 (9.63956 iter/s, 10.3739s/100 iters), loss = 0.0163124
I1007 11:51:43.925357  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0163126 (* 1 = 0.0163126 loss)
I1007 11:51:43.925364  4720 sgd_solver.cpp:105] Iteration 72000, lr = 0.01
I1007 11:51:52.277026  4720 solver.cpp:218] Iteration 72100 (11.9737 iter/s, 8.35164s/100 iters), loss = 0.0105016
I1007 11:51:52.277066  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0105018 (* 1 = 0.0105018 loss)
I1007 11:51:52.277072  4720 sgd_solver.cpp:105] Iteration 72100, lr = 0.01
I1007 11:52:00.631260  4720 solver.cpp:218] Iteration 72200 (11.9701 iter/s, 8.35417s/100 iters), loss = 0.0164484
I1007 11:52:00.631299  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0164486 (* 1 = 0.0164486 loss)
I1007 11:52:00.631305  4720 sgd_solver.cpp:105] Iteration 72200, lr = 0.01
I1007 11:52:08.982419  4720 solver.cpp:218] Iteration 72300 (11.9745 iter/s, 8.3511s/100 iters), loss = 0.00823092
I1007 11:52:08.982460  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00823114 (* 1 = 0.00823114 loss)
I1007 11:52:08.982465  4720 sgd_solver.cpp:105] Iteration 72300, lr = 0.01
I1007 11:52:17.342144  4720 solver.cpp:218] Iteration 72400 (11.9622 iter/s, 8.35966s/100 iters), loss = 0.00293004
I1007 11:52:17.342245  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00293026 (* 1 = 0.00293026 loss)
I1007 11:52:17.342253  4720 sgd_solver.cpp:105] Iteration 72400, lr = 0.01
I1007 11:52:25.283079  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:52:25.616978  4720 solver.cpp:330] Iteration 72500, Testing net (#0)
I1007 11:52:27.550725  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:52:27.631564  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9148
I1007 11:52:27.631599  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.34735 (* 1 = 0.34735 loss)
I1007 11:52:27.715229  4720 solver.cpp:218] Iteration 72500 (9.64045 iter/s, 10.373s/100 iters), loss = 0.00645108
I1007 11:52:27.715257  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00645129 (* 1 = 0.00645129 loss)
I1007 11:52:27.715263  4720 sgd_solver.cpp:105] Iteration 72500, lr = 0.01
I1007 11:52:36.074138  4720 solver.cpp:218] Iteration 72600 (11.9634 iter/s, 8.35886s/100 iters), loss = 0.00276085
I1007 11:52:36.074178  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00276107 (* 1 = 0.00276107 loss)
I1007 11:52:36.074184  4720 sgd_solver.cpp:105] Iteration 72600, lr = 0.01
I1007 11:52:44.427225  4720 solver.cpp:218] Iteration 72700 (11.9717 iter/s, 8.35302s/100 iters), loss = 0.0549269
I1007 11:52:44.427264  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0549271 (* 1 = 0.0549271 loss)
I1007 11:52:44.427269  4720 sgd_solver.cpp:105] Iteration 72700, lr = 0.01
I1007 11:52:52.783323  4720 solver.cpp:218] Iteration 72800 (11.9674 iter/s, 8.35603s/100 iters), loss = 0.00557387
I1007 11:52:52.783469  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00557409 (* 1 = 0.00557409 loss)
I1007 11:52:52.783476  4720 sgd_solver.cpp:105] Iteration 72800, lr = 0.01
I1007 11:53:01.137744  4720 solver.cpp:218] Iteration 72900 (11.9699 iter/s, 8.35426s/100 iters), loss = 0.00359742
I1007 11:53:01.137784  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00359763 (* 1 = 0.00359763 loss)
I1007 11:53:01.137790  4720 sgd_solver.cpp:105] Iteration 72900, lr = 0.01
I1007 11:53:09.082849  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:53:09.416797  4720 solver.cpp:330] Iteration 73000, Testing net (#0)
I1007 11:53:11.350759  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:53:11.431257  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9171
I1007 11:53:11.431293  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.348744 (* 1 = 0.348744 loss)
I1007 11:53:11.514539  4720 solver.cpp:218] Iteration 73000 (9.63695 iter/s, 10.3767s/100 iters), loss = 0.000948986
I1007 11:53:11.514567  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000949195 (* 1 = 0.000949195 loss)
I1007 11:53:11.514575  4720 sgd_solver.cpp:105] Iteration 73000, lr = 0.01
I1007 11:53:19.871444  4720 solver.cpp:218] Iteration 73100 (11.9662 iter/s, 8.35685s/100 iters), loss = 0.0121082
I1007 11:53:19.871484  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0121084 (* 1 = 0.0121084 loss)
I1007 11:53:19.871490  4720 sgd_solver.cpp:105] Iteration 73100, lr = 0.01
I1007 11:53:28.229259  4720 solver.cpp:218] Iteration 73200 (11.9649 iter/s, 8.35775s/100 iters), loss = 0.0246563
I1007 11:53:28.229403  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0246565 (* 1 = 0.0246565 loss)
I1007 11:53:28.229411  4720 sgd_solver.cpp:105] Iteration 73200, lr = 0.01
I1007 11:53:36.584089  4720 solver.cpp:218] Iteration 73300 (11.9694 iter/s, 8.35467s/100 iters), loss = 0.00265181
I1007 11:53:36.584130  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00265202 (* 1 = 0.00265202 loss)
I1007 11:53:36.584136  4720 sgd_solver.cpp:105] Iteration 73300, lr = 0.01
I1007 11:53:44.944849  4720 solver.cpp:218] Iteration 73400 (11.9607 iter/s, 8.36069s/100 iters), loss = 0.0114532
I1007 11:53:44.944890  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0114534 (* 1 = 0.0114534 loss)
I1007 11:53:44.944895  4720 sgd_solver.cpp:105] Iteration 73400, lr = 0.01
I1007 11:53:52.883077  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:53:53.218425  4720 solver.cpp:330] Iteration 73500, Testing net (#0)
I1007 11:53:55.150480  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:53:55.231319  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9107
I1007 11:53:55.231344  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.37169 (* 1 = 0.37169 loss)
I1007 11:53:55.314890  4720 solver.cpp:218] Iteration 73500 (9.64323 iter/s, 10.37s/100 iters), loss = 0.00781967
I1007 11:53:55.314920  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00781988 (* 1 = 0.00781988 loss)
I1007 11:53:55.314926  4720 sgd_solver.cpp:105] Iteration 73500, lr = 0.01
I1007 11:54:03.680271  4720 solver.cpp:218] Iteration 73600 (11.9541 iter/s, 8.36533s/100 iters), loss = 0.0123229
I1007 11:54:03.680409  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0123231 (* 1 = 0.0123231 loss)
I1007 11:54:03.680416  4720 sgd_solver.cpp:105] Iteration 73600, lr = 0.01
I1007 11:54:12.037080  4720 solver.cpp:218] Iteration 73700 (11.9665 iter/s, 8.35666s/100 iters), loss = 0.00231794
I1007 11:54:12.037119  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00231816 (* 1 = 0.00231816 loss)
I1007 11:54:12.037125  4720 sgd_solver.cpp:105] Iteration 73700, lr = 0.01
I1007 11:54:20.401757  4720 solver.cpp:218] Iteration 73800 (11.9551 iter/s, 8.36461s/100 iters), loss = 0.0140242
I1007 11:54:20.401796  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0140244 (* 1 = 0.0140244 loss)
I1007 11:54:20.401801  4720 sgd_solver.cpp:105] Iteration 73800, lr = 0.01
I1007 11:54:28.763397  4720 solver.cpp:218] Iteration 73900 (11.9595 iter/s, 8.36158s/100 iters), loss = 0.00165171
I1007 11:54:28.763437  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00165191 (* 1 = 0.00165191 loss)
I1007 11:54:28.763443  4720 sgd_solver.cpp:105] Iteration 73900, lr = 0.01
I1007 11:54:36.712888  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:54:37.047296  4720 solver.cpp:330] Iteration 74000, Testing net (#0)
I1007 11:54:38.980854  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:54:39.061190  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9127
I1007 11:54:39.061225  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.365519 (* 1 = 0.365519 loss)
I1007 11:54:39.144635  4720 solver.cpp:218] Iteration 74000 (9.63283 iter/s, 10.3812s/100 iters), loss = 0.0138069
I1007 11:54:39.144667  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0138071 (* 1 = 0.0138071 loss)
I1007 11:54:39.144675  4720 sgd_solver.cpp:105] Iteration 74000, lr = 0.01
I1007 11:54:47.503523  4720 solver.cpp:218] Iteration 74100 (11.9634 iter/s, 8.35883s/100 iters), loss = 0.0126223
I1007 11:54:47.503551  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0126225 (* 1 = 0.0126225 loss)
I1007 11:54:47.503557  4720 sgd_solver.cpp:105] Iteration 74100, lr = 0.01
I1007 11:54:55.861241  4720 solver.cpp:218] Iteration 74200 (11.9651 iter/s, 8.35767s/100 iters), loss = 0.00501756
I1007 11:54:55.861271  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00501776 (* 1 = 0.00501776 loss)
I1007 11:54:55.861277  4720 sgd_solver.cpp:105] Iteration 74200, lr = 0.01
I1007 11:55:04.217234  4720 solver.cpp:218] Iteration 74300 (11.9675 iter/s, 8.35594s/100 iters), loss = 0.00612995
I1007 11:55:04.217273  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00613015 (* 1 = 0.00613015 loss)
I1007 11:55:04.217279  4720 sgd_solver.cpp:105] Iteration 74300, lr = 0.01
I1007 11:55:12.581141  4720 solver.cpp:218] Iteration 74400 (11.9562 iter/s, 8.36384s/100 iters), loss = 0.0304581
I1007 11:55:12.581280  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0304583 (* 1 = 0.0304583 loss)
I1007 11:55:12.581287  4720 sgd_solver.cpp:105] Iteration 74400, lr = 0.01
I1007 11:55:20.523054  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:55:20.858175  4720 solver.cpp:330] Iteration 74500, Testing net (#0)
I1007 11:55:22.792532  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:55:22.873327  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9133
I1007 11:55:22.873361  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.35152 (* 1 = 0.35152 loss)
I1007 11:55:22.956918  4720 solver.cpp:218] Iteration 74500 (9.63798 iter/s, 10.3756s/100 iters), loss = 0.0126939
I1007 11:55:22.956945  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0126941 (* 1 = 0.0126941 loss)
I1007 11:55:22.956953  4720 sgd_solver.cpp:105] Iteration 74500, lr = 0.01
I1007 11:55:31.321661  4720 solver.cpp:218] Iteration 74600 (11.955 iter/s, 8.36469s/100 iters), loss = 0.00664852
I1007 11:55:31.321702  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0066487 (* 1 = 0.0066487 loss)
I1007 11:55:31.321708  4720 sgd_solver.cpp:105] Iteration 74600, lr = 0.01
I1007 11:55:39.673594  4720 solver.cpp:218] Iteration 74700 (11.9734 iter/s, 8.35187s/100 iters), loss = 0.00279021
I1007 11:55:39.673633  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00279039 (* 1 = 0.00279039 loss)
I1007 11:55:39.673640  4720 sgd_solver.cpp:105] Iteration 74700, lr = 0.01
I1007 11:55:48.031062  4720 solver.cpp:218] Iteration 74800 (11.9654 iter/s, 8.3574s/100 iters), loss = 0.03777
I1007 11:55:48.031200  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0377701 (* 1 = 0.0377701 loss)
I1007 11:55:48.031219  4720 sgd_solver.cpp:105] Iteration 74800, lr = 0.01
I1007 11:55:56.380029  4720 solver.cpp:218] Iteration 74900 (11.9778 iter/s, 8.34881s/100 iters), loss = 0.0071981
I1007 11:55:56.380069  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00719829 (* 1 = 0.00719829 loss)
I1007 11:55:56.380075  4720 sgd_solver.cpp:105] Iteration 74900, lr = 0.01
I1007 11:56:04.325840  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:56:04.660084  4720 solver.cpp:330] Iteration 75000, Testing net (#0)
I1007 11:56:06.593935  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:56:06.674928  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.907
I1007 11:56:06.674964  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.38499 (* 1 = 0.38499 loss)
I1007 11:56:06.757871  4720 solver.cpp:218] Iteration 75000 (9.63598 iter/s, 10.3778s/100 iters), loss = 0.0355737
I1007 11:56:06.757899  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0355739 (* 1 = 0.0355739 loss)
I1007 11:56:06.757905  4720 sgd_solver.cpp:105] Iteration 75000, lr = 0.01
I1007 11:56:15.110153  4720 solver.cpp:218] Iteration 75100 (11.9729 iter/s, 8.35223s/100 iters), loss = 0.00616802
I1007 11:56:15.110183  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00616821 (* 1 = 0.00616821 loss)
I1007 11:56:15.110189  4720 sgd_solver.cpp:105] Iteration 75100, lr = 0.01
I1007 11:56:23.474483  4720 solver.cpp:218] Iteration 75200 (11.9556 iter/s, 8.36427s/100 iters), loss = 0.0206822
I1007 11:56:23.474620  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0206824 (* 1 = 0.0206824 loss)
I1007 11:56:23.474628  4720 sgd_solver.cpp:105] Iteration 75200, lr = 0.01
I1007 11:56:31.834545  4720 solver.cpp:218] Iteration 75300 (11.9619 iter/s, 8.35991s/100 iters), loss = 0.00868633
I1007 11:56:31.834584  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00868653 (* 1 = 0.00868653 loss)
I1007 11:56:31.834590  4720 sgd_solver.cpp:105] Iteration 75300, lr = 0.01
I1007 11:56:40.197401  4720 solver.cpp:218] Iteration 75400 (11.9577 iter/s, 8.36279s/100 iters), loss = 0.0318543
I1007 11:56:40.197428  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0318545 (* 1 = 0.0318545 loss)
I1007 11:56:40.197434  4720 sgd_solver.cpp:105] Iteration 75400, lr = 0.01
I1007 11:56:48.142530  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:56:48.476699  4720 solver.cpp:330] Iteration 75500, Testing net (#0)
I1007 11:56:50.409050  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:56:50.490080  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9101
I1007 11:56:50.490114  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.371012 (* 1 = 0.371012 loss)
I1007 11:56:50.573592  4720 solver.cpp:218] Iteration 75500 (9.6375 iter/s, 10.3761s/100 iters), loss = 0.00606505
I1007 11:56:50.573619  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00606528 (* 1 = 0.00606528 loss)
I1007 11:56:50.573626  4720 sgd_solver.cpp:105] Iteration 75500, lr = 0.01
I1007 11:56:58.929352  4720 solver.cpp:218] Iteration 75600 (11.9679 iter/s, 8.35571s/100 iters), loss = 0.0183572
I1007 11:56:58.929457  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0183574 (* 1 = 0.0183574 loss)
I1007 11:56:58.929464  4720 sgd_solver.cpp:105] Iteration 75600, lr = 0.01
I1007 11:57:07.282106  4720 solver.cpp:218] Iteration 75700 (11.9723 iter/s, 8.35262s/100 iters), loss = 0.00297035
I1007 11:57:07.282136  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00297057 (* 1 = 0.00297057 loss)
I1007 11:57:07.282142  4720 sgd_solver.cpp:105] Iteration 75700, lr = 0.01
I1007 11:57:15.642841  4720 solver.cpp:218] Iteration 75800 (11.9607 iter/s, 8.36068s/100 iters), loss = 0.0151247
I1007 11:57:15.642880  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0151249 (* 1 = 0.0151249 loss)
I1007 11:57:15.642885  4720 sgd_solver.cpp:105] Iteration 75800, lr = 0.01
I1007 11:57:23.995118  4720 solver.cpp:218] Iteration 75900 (11.9729 iter/s, 8.35221s/100 iters), loss = 0.0418265
I1007 11:57:23.995146  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0418267 (* 1 = 0.0418267 loss)
I1007 11:57:23.995152  4720 sgd_solver.cpp:105] Iteration 75900, lr = 0.01
I1007 11:57:31.939757  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:57:32.274310  4720 solver.cpp:330] Iteration 76000, Testing net (#0)
I1007 11:57:34.205426  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:57:34.286273  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9059
I1007 11:57:34.286299  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.404361 (* 1 = 0.404361 loss)
I1007 11:57:34.369909  4720 solver.cpp:218] Iteration 76000 (9.6388 iter/s, 10.3747s/100 iters), loss = 0.0186439
I1007 11:57:34.369936  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0186441 (* 1 = 0.0186441 loss)
I1007 11:57:34.369942  4720 sgd_solver.cpp:105] Iteration 76000, lr = 0.01
I1007 11:57:42.728935  4720 solver.cpp:218] Iteration 76100 (11.9632 iter/s, 8.35897s/100 iters), loss = 0.00728016
I1007 11:57:42.728965  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00728037 (* 1 = 0.00728037 loss)
I1007 11:57:42.728971  4720 sgd_solver.cpp:105] Iteration 76100, lr = 0.01
I1007 11:57:51.091092  4720 solver.cpp:218] Iteration 76200 (11.9587 iter/s, 8.3621s/100 iters), loss = 0.00192958
I1007 11:57:51.091122  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00192979 (* 1 = 0.00192979 loss)
I1007 11:57:51.091128  4720 sgd_solver.cpp:105] Iteration 76200, lr = 0.01
I1007 11:57:59.450228  4720 solver.cpp:218] Iteration 76300 (11.963 iter/s, 8.35908s/100 iters), loss = 0.0160447
I1007 11:57:59.450268  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0160449 (* 1 = 0.0160449 loss)
I1007 11:57:59.450284  4720 sgd_solver.cpp:105] Iteration 76300, lr = 0.01
I1007 11:58:07.813191  4720 solver.cpp:218] Iteration 76400 (11.9576 iter/s, 8.3629s/100 iters), loss = 0.00356757
I1007 11:58:07.813297  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00356778 (* 1 = 0.00356778 loss)
I1007 11:58:07.813304  4720 sgd_solver.cpp:105] Iteration 76400, lr = 0.01
I1007 11:58:15.750890  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:58:16.085564  4720 solver.cpp:330] Iteration 76500, Testing net (#0)
I1007 11:58:18.018158  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:58:18.099017  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8977
I1007 11:58:18.099043  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.442859 (* 1 = 0.442859 loss)
I1007 11:58:18.182929  4720 solver.cpp:218] Iteration 76500 (9.64357 iter/s, 10.3696s/100 iters), loss = 0.0094346
I1007 11:58:18.182955  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0094348 (* 1 = 0.0094348 loss)
I1007 11:58:18.182962  4720 sgd_solver.cpp:105] Iteration 76500, lr = 0.01
I1007 11:58:26.540500  4720 solver.cpp:218] Iteration 76600 (11.9653 iter/s, 8.35752s/100 iters), loss = 0.0138973
I1007 11:58:26.540529  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0138975 (* 1 = 0.0138975 loss)
I1007 11:58:26.540535  4720 sgd_solver.cpp:105] Iteration 76600, lr = 0.01
I1007 11:58:34.899634  4720 solver.cpp:218] Iteration 76700 (11.963 iter/s, 8.35908s/100 iters), loss = 0.00235607
I1007 11:58:34.899665  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00235626 (* 1 = 0.00235626 loss)
I1007 11:58:34.899682  4720 sgd_solver.cpp:105] Iteration 76700, lr = 0.01
I1007 11:58:43.262320  4720 solver.cpp:218] Iteration 76800 (11.958 iter/s, 8.36263s/100 iters), loss = 0.00393259
I1007 11:58:43.262415  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00393278 (* 1 = 0.00393278 loss)
I1007 11:58:43.262432  4720 sgd_solver.cpp:105] Iteration 76800, lr = 0.01
I1007 11:58:51.620615  4720 solver.cpp:218] Iteration 76900 (11.9643 iter/s, 8.35818s/100 iters), loss = 0.00843038
I1007 11:58:51.620643  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00843056 (* 1 = 0.00843056 loss)
I1007 11:58:51.620649  4720 sgd_solver.cpp:105] Iteration 76900, lr = 0.01
I1007 11:58:59.569118  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:58:59.904665  4720 solver.cpp:330] Iteration 77000, Testing net (#0)
I1007 11:59:01.838521  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:59:01.918625  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9156
I1007 11:59:01.918658  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.346911 (* 1 = 0.346911 loss)
I1007 11:59:02.001745  4720 solver.cpp:218] Iteration 77000 (9.63291 iter/s, 10.3811s/100 iters), loss = 0.00188047
I1007 11:59:02.001772  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00188065 (* 1 = 0.00188065 loss)
I1007 11:59:02.001780  4720 sgd_solver.cpp:105] Iteration 77000, lr = 0.01
I1007 11:59:10.357475  4720 solver.cpp:218] Iteration 77100 (11.9679 iter/s, 8.35567s/100 iters), loss = 0.00952408
I1007 11:59:10.357522  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00952426 (* 1 = 0.00952426 loss)
I1007 11:59:10.357530  4720 sgd_solver.cpp:105] Iteration 77100, lr = 0.01
I1007 11:59:18.716650  4720 solver.cpp:218] Iteration 77200 (11.963 iter/s, 8.3591s/100 iters), loss = 0.0100327
I1007 11:59:18.716801  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0100329 (* 1 = 0.0100329 loss)
I1007 11:59:18.716809  4720 sgd_solver.cpp:105] Iteration 77200, lr = 0.01
I1007 11:59:27.070855  4720 solver.cpp:218] Iteration 77300 (11.9703 iter/s, 8.35404s/100 iters), loss = 0.0079302
I1007 11:59:27.070883  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00793038 (* 1 = 0.00793038 loss)
I1007 11:59:27.070889  4720 sgd_solver.cpp:105] Iteration 77300, lr = 0.01
I1007 11:59:35.429021  4720 solver.cpp:218] Iteration 77400 (11.9644 iter/s, 8.35811s/100 iters), loss = 0.0071808
I1007 11:59:35.429049  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00718098 (* 1 = 0.00718098 loss)
I1007 11:59:35.429055  4720 sgd_solver.cpp:105] Iteration 77400, lr = 0.01
I1007 11:59:43.372289  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:59:43.707427  4720 solver.cpp:330] Iteration 77500, Testing net (#0)
I1007 11:59:45.639355  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 11:59:45.720150  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9107
I1007 11:59:45.720185  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.365268 (* 1 = 0.365268 loss)
I1007 11:59:45.804133  4720 solver.cpp:218] Iteration 77500 (9.6385 iter/s, 10.3751s/100 iters), loss = 0.0139813
I1007 11:59:45.804162  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0139815 (* 1 = 0.0139815 loss)
I1007 11:59:45.804168  4720 sgd_solver.cpp:105] Iteration 77500, lr = 0.01
I1007 11:59:54.164821  4720 solver.cpp:218] Iteration 77600 (11.9608 iter/s, 8.36063s/100 iters), loss = 0.0141852
I1007 11:59:54.164924  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0141854 (* 1 = 0.0141854 loss)
I1007 11:59:54.164932  4720 sgd_solver.cpp:105] Iteration 77600, lr = 0.01
I1007 12:00:02.515529  4720 solver.cpp:218] Iteration 77700 (11.9752 iter/s, 8.35058s/100 iters), loss = 0.0280326
I1007 12:00:02.515559  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0280328 (* 1 = 0.0280328 loss)
I1007 12:00:02.515565  4720 sgd_solver.cpp:105] Iteration 77700, lr = 0.01
I1007 12:00:10.879420  4720 solver.cpp:218] Iteration 77800 (11.9562 iter/s, 8.36384s/100 iters), loss = 0.00623857
I1007 12:00:10.879449  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00623877 (* 1 = 0.00623877 loss)
I1007 12:00:10.879454  4720 sgd_solver.cpp:105] Iteration 77800, lr = 0.01
I1007 12:00:19.235903  4720 solver.cpp:218] Iteration 77900 (11.9668 iter/s, 8.35643s/100 iters), loss = 0.00542787
I1007 12:00:19.235935  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00542805 (* 1 = 0.00542805 loss)
I1007 12:00:19.235941  4720 sgd_solver.cpp:105] Iteration 77900, lr = 0.01
I1007 12:00:27.184736  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:00:27.519560  4720 solver.cpp:330] Iteration 78000, Testing net (#0)
I1007 12:00:29.452692  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:00:29.533068  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9128
I1007 12:00:29.533103  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.363654 (* 1 = 0.363654 loss)
I1007 12:00:29.616557  4720 solver.cpp:218] Iteration 78000 (9.63336 iter/s, 10.3806s/100 iters), loss = 0.00184888
I1007 12:00:29.616586  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00184906 (* 1 = 0.00184906 loss)
I1007 12:00:29.616592  4720 sgd_solver.cpp:105] Iteration 78000, lr = 0.01
I1007 12:00:37.975736  4720 solver.cpp:218] Iteration 78100 (11.963 iter/s, 8.35913s/100 iters), loss = 0.00429097
I1007 12:00:37.975777  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00429115 (* 1 = 0.00429115 loss)
I1007 12:00:37.975783  4720 sgd_solver.cpp:105] Iteration 78100, lr = 0.01
I1007 12:00:46.334388  4720 solver.cpp:218] Iteration 78200 (11.9637 iter/s, 8.35858s/100 iters), loss = 0.00157696
I1007 12:00:46.334434  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00157715 (* 1 = 0.00157715 loss)
I1007 12:00:46.334442  4720 sgd_solver.cpp:105] Iteration 78200, lr = 0.01
I1007 12:00:54.684216  4720 solver.cpp:218] Iteration 78300 (11.9764 iter/s, 8.34976s/100 iters), loss = 0.00145987
I1007 12:00:54.684255  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00146005 (* 1 = 0.00146005 loss)
I1007 12:00:54.684262  4720 sgd_solver.cpp:105] Iteration 78300, lr = 0.01
I1007 12:01:03.043452  4720 solver.cpp:218] Iteration 78400 (11.9629 iter/s, 8.35917s/100 iters), loss = 0.0271815
I1007 12:01:03.043562  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0271816 (* 1 = 0.0271816 loss)
I1007 12:01:03.043570  4720 sgd_solver.cpp:105] Iteration 78400, lr = 0.01
I1007 12:01:10.977326  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:01:11.311009  4720 solver.cpp:330] Iteration 78500, Testing net (#0)
I1007 12:01:13.244952  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:01:13.325816  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9074
I1007 12:01:13.325852  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.385081 (* 1 = 0.385081 loss)
I1007 12:01:13.409580  4720 solver.cpp:218] Iteration 78500 (9.64693 iter/s, 10.366s/100 iters), loss = 0.00288605
I1007 12:01:13.409608  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00288622 (* 1 = 0.00288622 loss)
I1007 12:01:13.409615  4720 sgd_solver.cpp:105] Iteration 78500, lr = 0.01
I1007 12:01:21.762621  4720 solver.cpp:218] Iteration 78600 (11.9718 iter/s, 8.35299s/100 iters), loss = 0.00748951
I1007 12:01:21.762668  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00748967 (* 1 = 0.00748967 loss)
I1007 12:01:21.762676  4720 sgd_solver.cpp:105] Iteration 78600, lr = 0.01
I1007 12:01:30.109625  4720 solver.cpp:218] Iteration 78700 (11.9804 iter/s, 8.34693s/100 iters), loss = 0.00303465
I1007 12:01:30.109673  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00303483 (* 1 = 0.00303483 loss)
I1007 12:01:30.109680  4720 sgd_solver.cpp:105] Iteration 78700, lr = 0.01
I1007 12:01:38.464478  4720 solver.cpp:218] Iteration 78800 (11.9692 iter/s, 8.35478s/100 iters), loss = 0.014537
I1007 12:01:38.464584  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0145372 (* 1 = 0.0145372 loss)
I1007 12:01:38.464591  4720 sgd_solver.cpp:105] Iteration 78800, lr = 0.01
I1007 12:01:46.819641  4720 solver.cpp:218] Iteration 78900 (11.9688 iter/s, 8.35503s/100 iters), loss = 0.00577518
I1007 12:01:46.819680  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00577535 (* 1 = 0.00577535 loss)
I1007 12:01:46.819686  4720 sgd_solver.cpp:105] Iteration 78900, lr = 0.01
I1007 12:01:54.753664  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:01:55.088632  4720 solver.cpp:330] Iteration 79000, Testing net (#0)
I1007 12:01:57.022442  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:01:57.103291  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9127
I1007 12:01:57.103327  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.356285 (* 1 = 0.356285 loss)
I1007 12:01:57.187254  4720 solver.cpp:218] Iteration 79000 (9.64549 iter/s, 10.3675s/100 iters), loss = 0.0202994
I1007 12:01:57.187289  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0202995 (* 1 = 0.0202995 loss)
I1007 12:01:57.187297  4720 sgd_solver.cpp:105] Iteration 79000, lr = 0.01
I1007 12:02:05.540441  4720 solver.cpp:218] Iteration 79100 (11.9716 iter/s, 8.35313s/100 iters), loss = 0.00399638
I1007 12:02:05.540472  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00399654 (* 1 = 0.00399654 loss)
I1007 12:02:05.540477  4720 sgd_solver.cpp:105] Iteration 79100, lr = 0.01
I1007 12:02:13.896530  4720 solver.cpp:218] Iteration 79200 (11.9674 iter/s, 8.35603s/100 iters), loss = 0.00823164
I1007 12:02:13.896677  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00823179 (* 1 = 0.00823179 loss)
I1007 12:02:13.896684  4720 sgd_solver.cpp:105] Iteration 79200, lr = 0.01
I1007 12:02:22.244386  4720 solver.cpp:218] Iteration 79300 (11.9794 iter/s, 8.3477s/100 iters), loss = 0.00317594
I1007 12:02:22.244416  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00317609 (* 1 = 0.00317609 loss)
I1007 12:02:22.244422  4720 sgd_solver.cpp:105] Iteration 79300, lr = 0.01
I1007 12:02:30.594111  4720 solver.cpp:218] Iteration 79400 (11.9765 iter/s, 8.34967s/100 iters), loss = 0.00555999
I1007 12:02:30.594152  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00556014 (* 1 = 0.00556014 loss)
I1007 12:02:30.594158  4720 sgd_solver.cpp:105] Iteration 79400, lr = 0.01
I1007 12:02:38.532382  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:02:38.867378  4720 solver.cpp:330] Iteration 79500, Testing net (#0)
I1007 12:02:40.799911  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:02:40.880767  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9145
I1007 12:02:40.880794  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.348429 (* 1 = 0.348429 loss)
I1007 12:02:40.965102  4720 solver.cpp:218] Iteration 79500 (9.64234 iter/s, 10.3709s/100 iters), loss = 0.00158596
I1007 12:02:40.965131  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00158611 (* 1 = 0.00158611 loss)
I1007 12:02:40.965138  4720 sgd_solver.cpp:105] Iteration 79500, lr = 0.01
I1007 12:02:49.327808  4720 solver.cpp:218] Iteration 79600 (11.9579 iter/s, 8.36265s/100 iters), loss = 0.0118128
I1007 12:02:49.327950  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0118129 (* 1 = 0.0118129 loss)
I1007 12:02:49.327960  4720 sgd_solver.cpp:105] Iteration 79600, lr = 0.01
I1007 12:02:57.682775  4720 solver.cpp:218] Iteration 79700 (11.9692 iter/s, 8.3548s/100 iters), loss = 0.00491091
I1007 12:02:57.682806  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00491105 (* 1 = 0.00491105 loss)
I1007 12:02:57.682811  4720 sgd_solver.cpp:105] Iteration 79700, lr = 0.01
I1007 12:03:06.043864  4720 solver.cpp:218] Iteration 79800 (11.9602 iter/s, 8.36104s/100 iters), loss = 0.0131054
I1007 12:03:06.043895  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0131055 (* 1 = 0.0131055 loss)
I1007 12:03:06.043900  4720 sgd_solver.cpp:105] Iteration 79800, lr = 0.01
I1007 12:03:14.400197  4720 solver.cpp:218] Iteration 79900 (11.967 iter/s, 8.35628s/100 iters), loss = 0.00843909
I1007 12:03:14.400238  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00843923 (* 1 = 0.00843923 loss)
I1007 12:03:14.400243  4720 sgd_solver.cpp:105] Iteration 79900, lr = 0.01
I1007 12:03:22.345999  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:03:22.680961  4720 solver.cpp:330] Iteration 80000, Testing net (#0)
I1007 12:03:24.614147  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:03:24.694838  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9067
I1007 12:03:24.694874  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.392044 (* 1 = 0.392044 loss)
I1007 12:03:24.778472  4720 solver.cpp:218] Iteration 80000 (9.63558 iter/s, 10.3782s/100 iters), loss = 0.00437259
I1007 12:03:24.778499  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00437272 (* 1 = 0.00437272 loss)
I1007 12:03:24.778504  4720 sgd_solver.cpp:46] MultiStep Status: Iteration 80000, step = 2
I1007 12:03:24.778508  4720 sgd_solver.cpp:105] Iteration 80000, lr = 0.001
I1007 12:03:33.140914  4720 solver.cpp:218] Iteration 80100 (11.9583 iter/s, 8.36239s/100 iters), loss = 0.00695364
I1007 12:03:33.140945  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00695377 (* 1 = 0.00695377 loss)
I1007 12:03:33.140951  4720 sgd_solver.cpp:105] Iteration 80100, lr = 0.001
I1007 12:03:41.506454  4720 solver.cpp:218] Iteration 80200 (11.9539 iter/s, 8.36548s/100 iters), loss = 0.0129733
I1007 12:03:41.506494  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0129734 (* 1 = 0.0129734 loss)
I1007 12:03:41.506500  4720 sgd_solver.cpp:105] Iteration 80200, lr = 0.001
I1007 12:03:49.868079  4720 solver.cpp:218] Iteration 80300 (11.9595 iter/s, 8.36156s/100 iters), loss = 0.00483376
I1007 12:03:49.868108  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00483389 (* 1 = 0.00483389 loss)
I1007 12:03:49.868114  4720 sgd_solver.cpp:105] Iteration 80300, lr = 0.001
I1007 12:03:58.231281  4720 solver.cpp:218] Iteration 80400 (11.9572 iter/s, 8.36315s/100 iters), loss = 0.00282011
I1007 12:03:58.231371  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00282024 (* 1 = 0.00282024 loss)
I1007 12:03:58.231389  4720 sgd_solver.cpp:105] Iteration 80400, lr = 0.001
I1007 12:04:06.174795  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:04:06.509923  4720 solver.cpp:330] Iteration 80500, Testing net (#0)
I1007 12:04:08.444671  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:04:08.525548  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9189
I1007 12:04:08.525573  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.336794 (* 1 = 0.336794 loss)
I1007 12:04:08.609091  4720 solver.cpp:218] Iteration 80500 (9.63605 iter/s, 10.3777s/100 iters), loss = 0.00142028
I1007 12:04:08.609119  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0014204 (* 1 = 0.0014204 loss)
I1007 12:04:08.609127  4720 sgd_solver.cpp:105] Iteration 80500, lr = 0.001
I1007 12:04:16.969712  4720 solver.cpp:218] Iteration 80600 (11.9609 iter/s, 8.36057s/100 iters), loss = 0.0176834
I1007 12:04:16.969741  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0176835 (* 1 = 0.0176835 loss)
I1007 12:04:16.969748  4720 sgd_solver.cpp:105] Iteration 80600, lr = 0.001
I1007 12:04:25.327543  4720 solver.cpp:218] Iteration 80700 (11.9649 iter/s, 8.35777s/100 iters), loss = 0.00468514
I1007 12:04:25.327571  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00468525 (* 1 = 0.00468525 loss)
I1007 12:04:25.327577  4720 sgd_solver.cpp:105] Iteration 80700, lr = 0.001
I1007 12:04:33.693130  4720 solver.cpp:218] Iteration 80800 (11.9538 iter/s, 8.36553s/100 iters), loss = 0.00626599
I1007 12:04:33.693256  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0062661 (* 1 = 0.0062661 loss)
I1007 12:04:33.693264  4720 sgd_solver.cpp:105] Iteration 80800, lr = 0.001
I1007 12:04:42.054054  4720 solver.cpp:218] Iteration 80900 (11.9606 iter/s, 8.36079s/100 iters), loss = 0.00104987
I1007 12:04:42.054095  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00104998 (* 1 = 0.00104998 loss)
I1007 12:04:42.054100  4720 sgd_solver.cpp:105] Iteration 80900, lr = 0.001
I1007 12:04:50.003947  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:04:50.338066  4720 solver.cpp:330] Iteration 81000, Testing net (#0)
I1007 12:04:52.271942  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:04:52.352437  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9205
I1007 12:04:52.352463  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.326804 (* 1 = 0.326804 loss)
I1007 12:04:52.435930  4720 solver.cpp:218] Iteration 81000 (9.63223 iter/s, 10.3818s/100 iters), loss = 0.00425476
I1007 12:04:52.435958  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00425488 (* 1 = 0.00425488 loss)
I1007 12:04:52.435964  4720 sgd_solver.cpp:105] Iteration 81000, lr = 0.001
I1007 12:05:00.798740  4720 solver.cpp:218] Iteration 81100 (11.9578 iter/s, 8.36276s/100 iters), loss = 0.00212329
I1007 12:05:00.798780  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00212341 (* 1 = 0.00212341 loss)
I1007 12:05:00.798786  4720 sgd_solver.cpp:105] Iteration 81100, lr = 0.001
I1007 12:05:09.158963  4720 solver.cpp:218] Iteration 81200 (11.9615 iter/s, 8.36015s/100 iters), loss = 0.0028629
I1007 12:05:09.159142  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00286302 (* 1 = 0.00286302 loss)
I1007 12:05:09.159149  4720 sgd_solver.cpp:105] Iteration 81200, lr = 0.001
I1007 12:05:17.509191  4720 solver.cpp:218] Iteration 81300 (11.976 iter/s, 8.35005s/100 iters), loss = 0.00205712
I1007 12:05:17.509222  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00205724 (* 1 = 0.00205724 loss)
I1007 12:05:17.509227  4720 sgd_solver.cpp:105] Iteration 81300, lr = 0.001
I1007 12:05:25.871289  4720 solver.cpp:218] Iteration 81400 (11.9588 iter/s, 8.36205s/100 iters), loss = 0.00182872
I1007 12:05:25.871320  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00182883 (* 1 = 0.00182883 loss)
I1007 12:05:25.871325  4720 sgd_solver.cpp:105] Iteration 81400, lr = 0.001
I1007 12:05:33.811759  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:05:34.145978  4720 solver.cpp:330] Iteration 81500, Testing net (#0)
I1007 12:05:36.077975  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:05:36.158964  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9206
I1007 12:05:36.158990  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.321638 (* 1 = 0.321638 loss)
I1007 12:05:36.242316  4720 solver.cpp:218] Iteration 81500 (9.6423 iter/s, 10.371s/100 iters), loss = 0.00107519
I1007 12:05:36.242350  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00107531 (* 1 = 0.00107531 loss)
I1007 12:05:36.242357  4720 sgd_solver.cpp:105] Iteration 81500, lr = 0.001
I1007 12:05:44.603919  4720 solver.cpp:218] Iteration 81600 (11.9595 iter/s, 8.36155s/100 iters), loss = 0.00203874
I1007 12:05:44.604055  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00203886 (* 1 = 0.00203886 loss)
I1007 12:05:44.604063  4720 sgd_solver.cpp:105] Iteration 81600, lr = 0.001
I1007 12:05:52.962795  4720 solver.cpp:218] Iteration 81700 (11.9636 iter/s, 8.35872s/100 iters), loss = 0.00271428
I1007 12:05:52.962836  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0027144 (* 1 = 0.0027144 loss)
I1007 12:05:52.962841  4720 sgd_solver.cpp:105] Iteration 81700, lr = 0.001
I1007 12:06:01.321890  4720 solver.cpp:218] Iteration 81800 (11.9631 iter/s, 8.35903s/100 iters), loss = 0.00869929
I1007 12:06:01.321920  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00869941 (* 1 = 0.00869941 loss)
I1007 12:06:01.321926  4720 sgd_solver.cpp:105] Iteration 81800, lr = 0.001
I1007 12:06:09.678025  4720 solver.cpp:218] Iteration 81900 (11.9673 iter/s, 8.35608s/100 iters), loss = 0.00321736
I1007 12:06:09.678056  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00321748 (* 1 = 0.00321748 loss)
I1007 12:06:09.678061  4720 sgd_solver.cpp:105] Iteration 81900, lr = 0.001
I1007 12:06:17.629772  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:06:17.963838  4720 solver.cpp:330] Iteration 82000, Testing net (#0)
I1007 12:06:19.897186  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:06:19.977653  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9215
I1007 12:06:19.977687  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.32113 (* 1 = 0.32113 loss)
I1007 12:06:20.061050  4720 solver.cpp:218] Iteration 82000 (9.63116 iter/s, 10.383s/100 iters), loss = 0.00188249
I1007 12:06:20.061077  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00188261 (* 1 = 0.00188261 loss)
I1007 12:06:20.061084  4720 sgd_solver.cpp:105] Iteration 82000, lr = 0.001
I1007 12:06:28.412247  4720 solver.cpp:218] Iteration 82100 (11.9744 iter/s, 8.35114s/100 iters), loss = 0.00577069
I1007 12:06:28.412277  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00577082 (* 1 = 0.00577082 loss)
I1007 12:06:28.412283  4720 sgd_solver.cpp:105] Iteration 82100, lr = 0.001
I1007 12:06:36.767179  4720 solver.cpp:218] Iteration 82200 (11.9691 iter/s, 8.35488s/100 iters), loss = 0.00232192
I1007 12:06:36.767218  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00232204 (* 1 = 0.00232204 loss)
I1007 12:06:36.767225  4720 sgd_solver.cpp:105] Iteration 82200, lr = 0.001
I1007 12:06:45.120573  4720 solver.cpp:218] Iteration 82300 (11.9713 iter/s, 8.35333s/100 iters), loss = 0.0131441
I1007 12:06:45.120602  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0131442 (* 1 = 0.0131442 loss)
I1007 12:06:45.120607  4720 sgd_solver.cpp:105] Iteration 82300, lr = 0.001
I1007 12:06:53.482272  4720 solver.cpp:218] Iteration 82400 (11.9594 iter/s, 8.36165s/100 iters), loss = 0.00275799
I1007 12:06:53.482419  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00275811 (* 1 = 0.00275811 loss)
I1007 12:06:53.482427  4720 sgd_solver.cpp:105] Iteration 82400, lr = 0.001
I1007 12:07:01.425479  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:07:01.759773  4720 solver.cpp:330] Iteration 82500, Testing net (#0)
I1007 12:07:03.693292  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:07:03.774190  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9237
I1007 12:07:03.774226  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.322844 (* 1 = 0.322844 loss)
I1007 12:07:03.857609  4720 solver.cpp:218] Iteration 82500 (9.6384 iter/s, 10.3752s/100 iters), loss = 0.0113559
I1007 12:07:03.857640  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.011356 (* 1 = 0.011356 loss)
I1007 12:07:03.857645  4720 sgd_solver.cpp:105] Iteration 82500, lr = 0.001
I1007 12:07:12.221006  4720 solver.cpp:218] Iteration 82600 (11.9569 iter/s, 8.36334s/100 iters), loss = 0.00532125
I1007 12:07:12.221045  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00532137 (* 1 = 0.00532137 loss)
I1007 12:07:12.221051  4720 sgd_solver.cpp:105] Iteration 82600, lr = 0.001
I1007 12:07:20.579932  4720 solver.cpp:218] Iteration 82700 (11.9634 iter/s, 8.35886s/100 iters), loss = 0.0318914
I1007 12:07:20.579978  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0318915 (* 1 = 0.0318915 loss)
I1007 12:07:20.579985  4720 sgd_solver.cpp:105] Iteration 82700, lr = 0.001
I1007 12:07:28.945433  4720 solver.cpp:218] Iteration 82800 (11.954 iter/s, 8.36543s/100 iters), loss = 0.0145307
I1007 12:07:28.945544  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0145308 (* 1 = 0.0145308 loss)
I1007 12:07:28.945551  4720 sgd_solver.cpp:105] Iteration 82800, lr = 0.001
I1007 12:07:37.299612  4720 solver.cpp:218] Iteration 82900 (11.9702 iter/s, 8.35405s/100 iters), loss = 0.0051226
I1007 12:07:37.299643  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00512272 (* 1 = 0.00512272 loss)
I1007 12:07:37.299648  4720 sgd_solver.cpp:105] Iteration 82900, lr = 0.001
I1007 12:07:45.241977  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:07:45.575963  4720 solver.cpp:330] Iteration 83000, Testing net (#0)
I1007 12:07:47.509987  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:07:47.590935  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9228
I1007 12:07:47.590971  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.320411 (* 1 = 0.320411 loss)
I1007 12:07:47.673717  4720 solver.cpp:218] Iteration 83000 (9.63944 iter/s, 10.374s/100 iters), loss = 0.00076005
I1007 12:07:47.673743  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000760162 (* 1 = 0.000760162 loss)
I1007 12:07:47.673749  4720 sgd_solver.cpp:105] Iteration 83000, lr = 0.001
I1007 12:07:56.030427  4720 solver.cpp:218] Iteration 83100 (11.9665 iter/s, 8.35666s/100 iters), loss = 0.0312203
I1007 12:07:56.030467  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0312205 (* 1 = 0.0312205 loss)
I1007 12:07:56.030472  4720 sgd_solver.cpp:105] Iteration 83100, lr = 0.001
I1007 12:08:04.395051  4720 solver.cpp:218] Iteration 83200 (11.9552 iter/s, 8.36455s/100 iters), loss = 0.00208375
I1007 12:08:04.395221  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00208386 (* 1 = 0.00208386 loss)
I1007 12:08:04.395231  4720 sgd_solver.cpp:105] Iteration 83200, lr = 0.001
I1007 12:08:12.756038  4720 solver.cpp:218] Iteration 83300 (11.9606 iter/s, 8.36081s/100 iters), loss = 0.00134297
I1007 12:08:12.756078  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00134308 (* 1 = 0.00134308 loss)
I1007 12:08:12.756084  4720 sgd_solver.cpp:105] Iteration 83300, lr = 0.001
I1007 12:08:21.119746  4720 solver.cpp:218] Iteration 83400 (11.9565 iter/s, 8.36364s/100 iters), loss = 0.00128787
I1007 12:08:21.119776  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00128798 (* 1 = 0.00128798 loss)
I1007 12:08:21.119782  4720 sgd_solver.cpp:105] Iteration 83400, lr = 0.001
I1007 12:08:29.066043  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:08:29.401034  4720 solver.cpp:330] Iteration 83500, Testing net (#0)
I1007 12:08:31.334678  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:08:31.415669  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9226
I1007 12:08:31.415705  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.322009 (* 1 = 0.322009 loss)
I1007 12:08:31.499033  4720 solver.cpp:218] Iteration 83500 (9.63463 iter/s, 10.3792s/100 iters), loss = 0.0135409
I1007 12:08:31.499063  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.013541 (* 1 = 0.013541 loss)
I1007 12:08:31.499069  4720 sgd_solver.cpp:105] Iteration 83500, lr = 0.001
I1007 12:08:39.866528  4720 solver.cpp:218] Iteration 83600 (11.9511 iter/s, 8.36744s/100 iters), loss = 0.00659902
I1007 12:08:39.866647  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00659914 (* 1 = 0.00659914 loss)
I1007 12:08:39.866663  4720 sgd_solver.cpp:105] Iteration 83600, lr = 0.001
I1007 12:08:48.221034  4720 solver.cpp:218] Iteration 83700 (11.9698 iter/s, 8.35437s/100 iters), loss = 0.0103071
I1007 12:08:48.221065  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0103072 (* 1 = 0.0103072 loss)
I1007 12:08:48.221071  4720 sgd_solver.cpp:105] Iteration 83700, lr = 0.001
I1007 12:08:56.577635  4720 solver.cpp:218] Iteration 83800 (11.9667 iter/s, 8.35655s/100 iters), loss = 0.00302982
I1007 12:08:56.577674  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00302994 (* 1 = 0.00302994 loss)
I1007 12:08:56.577680  4720 sgd_solver.cpp:105] Iteration 83800, lr = 0.001
I1007 12:09:04.937885  4720 solver.cpp:218] Iteration 83900 (11.9615 iter/s, 8.36019s/100 iters), loss = 0.00426665
I1007 12:09:04.937924  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00426677 (* 1 = 0.00426677 loss)
I1007 12:09:04.937930  4720 sgd_solver.cpp:105] Iteration 83900, lr = 0.001
I1007 12:09:12.885454  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:09:13.220206  4720 solver.cpp:330] Iteration 84000, Testing net (#0)
I1007 12:09:15.153817  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:09:15.234210  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.923
I1007 12:09:15.234244  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.321143 (* 1 = 0.321143 loss)
I1007 12:09:15.317379  4720 solver.cpp:218] Iteration 84000 (9.63444 iter/s, 10.3794s/100 iters), loss = 0.0016724
I1007 12:09:15.317407  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00167252 (* 1 = 0.00167252 loss)
I1007 12:09:15.317414  4720 sgd_solver.cpp:105] Iteration 84000, lr = 0.001
I1007 12:09:23.673665  4720 solver.cpp:218] Iteration 84100 (11.9671 iter/s, 8.35623s/100 iters), loss = 0.00239063
I1007 12:09:23.673704  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00239075 (* 1 = 0.00239075 loss)
I1007 12:09:23.673710  4720 sgd_solver.cpp:105] Iteration 84100, lr = 0.001
I1007 12:09:32.036774  4720 solver.cpp:218] Iteration 84200 (11.9574 iter/s, 8.36304s/100 iters), loss = 0.0178941
I1007 12:09:32.036820  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0178942 (* 1 = 0.0178942 loss)
I1007 12:09:32.036828  4720 sgd_solver.cpp:105] Iteration 84200, lr = 0.001
I1007 12:09:40.389801  4720 solver.cpp:218] Iteration 84300 (11.9718 iter/s, 8.35296s/100 iters), loss = 0.00284608
I1007 12:09:40.389840  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0028462 (* 1 = 0.0028462 loss)
I1007 12:09:40.389847  4720 sgd_solver.cpp:105] Iteration 84300, lr = 0.001
I1007 12:09:48.749624  4720 solver.cpp:218] Iteration 84400 (11.9621 iter/s, 8.35976s/100 iters), loss = 0.000795359
I1007 12:09:48.749744  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00079548 (* 1 = 0.00079548 loss)
I1007 12:09:48.749752  4720 sgd_solver.cpp:105] Iteration 84400, lr = 0.001
I1007 12:09:56.684979  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:09:57.020042  4720 solver.cpp:330] Iteration 84500, Testing net (#0)
I1007 12:09:58.954676  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:09:59.035604  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9229
I1007 12:09:59.035639  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.320165 (* 1 = 0.320165 loss)
I1007 12:09:59.119817  4720 solver.cpp:218] Iteration 84500 (9.64316 iter/s, 10.37s/100 iters), loss = 0.000750551
I1007 12:09:59.119843  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000750672 (* 1 = 0.000750672 loss)
I1007 12:09:59.119850  4720 sgd_solver.cpp:105] Iteration 84500, lr = 0.001
I1007 12:10:07.499667  4720 solver.cpp:218] Iteration 84600 (11.9335 iter/s, 8.3798s/100 iters), loss = 0.0016252
I1007 12:10:07.499701  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00162532 (* 1 = 0.00162532 loss)
I1007 12:10:07.499707  4720 sgd_solver.cpp:105] Iteration 84600, lr = 0.001
I1007 12:10:15.907330  4720 solver.cpp:218] Iteration 84700 (11.894 iter/s, 8.4076s/100 iters), loss = 0.00294805
I1007 12:10:15.907363  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00294817 (* 1 = 0.00294817 loss)
I1007 12:10:15.907369  4720 sgd_solver.cpp:105] Iteration 84700, lr = 0.001
I1007 12:10:24.316872  4720 solver.cpp:218] Iteration 84800 (11.8913 iter/s, 8.40949s/100 iters), loss = 0.00139484
I1007 12:10:24.316954  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00139496 (* 1 = 0.00139496 loss)
I1007 12:10:24.316972  4720 sgd_solver.cpp:105] Iteration 84800, lr = 0.001
I1007 12:10:32.722777  4720 solver.cpp:218] Iteration 84900 (11.8965 iter/s, 8.4058s/100 iters), loss = 0.00214384
I1007 12:10:32.722818  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00214397 (* 1 = 0.00214397 loss)
I1007 12:10:32.722825  4720 sgd_solver.cpp:105] Iteration 84900, lr = 0.001
I1007 12:10:40.734431  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:10:41.069471  4720 solver.cpp:330] Iteration 85000, Testing net (#0)
I1007 12:10:43.003912  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:10:43.084776  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9221
I1007 12:10:43.084817  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.324624 (* 1 = 0.324624 loss)
I1007 12:10:43.168716  4720 solver.cpp:218] Iteration 85000 (9.57316 iter/s, 10.4459s/100 iters), loss = 0.00232697
I1007 12:10:43.168746  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00232709 (* 1 = 0.00232709 loss)
I1007 12:10:43.168752  4720 sgd_solver.cpp:105] Iteration 85000, lr = 0.001
I1007 12:10:51.518127  4720 solver.cpp:218] Iteration 85100 (11.977 iter/s, 8.34936s/100 iters), loss = 0.00928813
I1007 12:10:51.518167  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00928826 (* 1 = 0.00928826 loss)
I1007 12:10:51.518173  4720 sgd_solver.cpp:105] Iteration 85100, lr = 0.001
I1007 12:10:59.868302  4720 solver.cpp:218] Iteration 85200 (11.9759 iter/s, 8.35011s/100 iters), loss = 0.00223666
I1007 12:10:59.868456  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00223677 (* 1 = 0.00223677 loss)
I1007 12:10:59.868463  4720 sgd_solver.cpp:105] Iteration 85200, lr = 0.001
I1007 12:11:08.219758  4720 solver.cpp:218] Iteration 85300 (11.9742 iter/s, 8.35129s/100 iters), loss = 0.00760948
I1007 12:11:08.219797  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0076096 (* 1 = 0.0076096 loss)
I1007 12:11:08.219804  4720 sgd_solver.cpp:105] Iteration 85300, lr = 0.001
I1007 12:11:16.569376  4720 solver.cpp:218] Iteration 85400 (11.9767 iter/s, 8.34956s/100 iters), loss = 0.0100435
I1007 12:11:16.569416  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0100437 (* 1 = 0.0100437 loss)
I1007 12:11:16.569422  4720 sgd_solver.cpp:105] Iteration 85400, lr = 0.001
I1007 12:11:24.598877  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:11:24.933900  4720 solver.cpp:330] Iteration 85500, Testing net (#0)
I1007 12:11:26.879072  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:11:26.959846  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9218
I1007 12:11:26.959882  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.32123 (* 1 = 0.32123 loss)
I1007 12:11:27.043999  4720 solver.cpp:218] Iteration 85500 (9.54695 iter/s, 10.4746s/100 iters), loss = 0.00129212
I1007 12:11:27.044030  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00129224 (* 1 = 0.00129224 loss)
I1007 12:11:27.044037  4720 sgd_solver.cpp:105] Iteration 85500, lr = 0.001
I1007 12:11:35.463342  4720 solver.cpp:218] Iteration 85600 (11.8775 iter/s, 8.41929s/100 iters), loss = 0.00257417
I1007 12:11:35.463464  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00257429 (* 1 = 0.00257429 loss)
I1007 12:11:35.463482  4720 sgd_solver.cpp:105] Iteration 85600, lr = 0.001
I1007 12:11:43.904837  4720 solver.cpp:218] Iteration 85700 (11.8465 iter/s, 8.44134s/100 iters), loss = 0.00196105
I1007 12:11:43.904893  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00196116 (* 1 = 0.00196116 loss)
I1007 12:11:43.904901  4720 sgd_solver.cpp:105] Iteration 85700, lr = 0.001
I1007 12:11:52.304546  4720 solver.cpp:218] Iteration 85800 (11.9053 iter/s, 8.39964s/100 iters), loss = 0.000836922
I1007 12:11:52.304576  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000837038 (* 1 = 0.000837038 loss)
I1007 12:11:52.304584  4720 sgd_solver.cpp:105] Iteration 85800, lr = 0.001
I1007 12:12:00.681771  4720 solver.cpp:218] Iteration 85900 (11.9372 iter/s, 8.37717s/100 iters), loss = 0.00297491
I1007 12:12:00.681800  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00297503 (* 1 = 0.00297503 loss)
I1007 12:12:00.681807  4720 sgd_solver.cpp:105] Iteration 85900, lr = 0.001
I1007 12:12:08.645552  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:12:08.979660  4720 solver.cpp:330] Iteration 86000, Testing net (#0)
I1007 12:12:10.930140  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:12:11.010408  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9223
I1007 12:12:11.010442  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.321121 (* 1 = 0.321121 loss)
I1007 12:12:11.094519  4720 solver.cpp:218] Iteration 86000 (9.60367 iter/s, 10.4127s/100 iters), loss = 0.0010221
I1007 12:12:11.094554  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00102222 (* 1 = 0.00102222 loss)
I1007 12:12:11.094561  4720 sgd_solver.cpp:105] Iteration 86000, lr = 0.001
I1007 12:12:19.487784  4720 solver.cpp:218] Iteration 86100 (11.9144 iter/s, 8.39321s/100 iters), loss = 0.0302612
I1007 12:12:19.487813  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0302614 (* 1 = 0.0302614 loss)
I1007 12:12:19.487819  4720 sgd_solver.cpp:105] Iteration 86100, lr = 0.001
I1007 12:12:27.880784  4720 solver.cpp:218] Iteration 86200 (11.9148 iter/s, 8.39294s/100 iters), loss = 0.00829982
I1007 12:12:27.880825  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00829994 (* 1 = 0.00829994 loss)
I1007 12:12:27.880831  4720 sgd_solver.cpp:105] Iteration 86200, lr = 0.001
I1007 12:12:36.295127  4720 solver.cpp:218] Iteration 86300 (11.8846 iter/s, 8.41427s/100 iters), loss = 0.00115236
I1007 12:12:36.295159  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00115248 (* 1 = 0.00115248 loss)
I1007 12:12:36.295168  4720 sgd_solver.cpp:105] Iteration 86300, lr = 0.001
I1007 12:12:44.696996  4720 solver.cpp:218] Iteration 86400 (11.9022 iter/s, 8.40181s/100 iters), loss = 0.00361206
I1007 12:12:44.697058  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00361218 (* 1 = 0.00361218 loss)
I1007 12:12:44.697067  4720 sgd_solver.cpp:105] Iteration 86400, lr = 0.001
I1007 12:12:52.706578  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:12:53.050132  4720 solver.cpp:330] Iteration 86500, Testing net (#0)
I1007 12:12:55.010743  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:12:55.091610  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9233
I1007 12:12:55.091647  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.319755 (* 1 = 0.319755 loss)
I1007 12:12:55.175113  4720 solver.cpp:218] Iteration 86500 (9.54378 iter/s, 10.478s/100 iters), loss = 0.00322823
I1007 12:12:55.175139  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00322835 (* 1 = 0.00322835 loss)
I1007 12:12:55.175145  4720 sgd_solver.cpp:105] Iteration 86500, lr = 0.001
I1007 12:13:03.607192  4720 solver.cpp:218] Iteration 86600 (11.8595 iter/s, 8.43203s/100 iters), loss = 0.00218315
I1007 12:13:03.607224  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00218328 (* 1 = 0.00218328 loss)
I1007 12:13:03.607230  4720 sgd_solver.cpp:105] Iteration 86600, lr = 0.001
I1007 12:13:12.018779  4720 solver.cpp:218] Iteration 86700 (11.8884 iter/s, 8.41153s/100 iters), loss = 0.00121823
I1007 12:13:12.018808  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00121836 (* 1 = 0.00121836 loss)
I1007 12:13:12.018815  4720 sgd_solver.cpp:105] Iteration 86700, lr = 0.001
I1007 12:13:20.449353  4720 solver.cpp:218] Iteration 86800 (11.8617 iter/s, 8.43052s/100 iters), loss = 0.00316059
I1007 12:13:20.449451  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00316071 (* 1 = 0.00316071 loss)
I1007 12:13:20.449460  4720 sgd_solver.cpp:105] Iteration 86800, lr = 0.001
I1007 12:13:28.856782  4720 solver.cpp:218] Iteration 86900 (11.8944 iter/s, 8.40731s/100 iters), loss = 0.00272728
I1007 12:13:28.856822  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0027274 (* 1 = 0.0027274 loss)
I1007 12:13:28.856827  4720 sgd_solver.cpp:105] Iteration 86900, lr = 0.001
I1007 12:13:36.843449  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:13:37.180207  4720 solver.cpp:330] Iteration 87000, Testing net (#0)
I1007 12:13:39.145895  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:13:39.227263  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9237
I1007 12:13:39.227303  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.318618 (* 1 = 0.318618 loss)
I1007 12:13:39.310575  4720 solver.cpp:218] Iteration 87000 (9.56597 iter/s, 10.4537s/100 iters), loss = 0.00116974
I1007 12:13:39.310608  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00116986 (* 1 = 0.00116986 loss)
I1007 12:13:39.310616  4720 sgd_solver.cpp:105] Iteration 87000, lr = 0.001
I1007 12:13:47.736912  4720 solver.cpp:218] Iteration 87100 (11.8676 iter/s, 8.42628s/100 iters), loss = 0.00885787
I1007 12:13:47.736944  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00885799 (* 1 = 0.00885799 loss)
I1007 12:13:47.736950  4720 sgd_solver.cpp:105] Iteration 87100, lr = 0.001
I1007 12:13:56.169309  4720 solver.cpp:218] Iteration 87200 (11.8591 iter/s, 8.43234s/100 iters), loss = 0.00105013
I1007 12:13:56.169473  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00105025 (* 1 = 0.00105025 loss)
I1007 12:13:56.169481  4720 sgd_solver.cpp:105] Iteration 87200, lr = 0.001
I1007 12:14:04.592533  4720 solver.cpp:218] Iteration 87300 (11.8722 iter/s, 8.42304s/100 iters), loss = 0.00898654
I1007 12:14:04.592563  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00898666 (* 1 = 0.00898666 loss)
I1007 12:14:04.592569  4720 sgd_solver.cpp:105] Iteration 87300, lr = 0.001
I1007 12:14:13.031188  4720 solver.cpp:218] Iteration 87400 (11.8503 iter/s, 8.43859s/100 iters), loss = 0.00125764
I1007 12:14:13.031219  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00125776 (* 1 = 0.00125776 loss)
I1007 12:14:13.031225  4720 sgd_solver.cpp:105] Iteration 87400, lr = 0.001
I1007 12:14:21.036876  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:14:21.383725  4720 solver.cpp:330] Iteration 87500, Testing net (#0)
I1007 12:14:23.322263  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:14:23.402644  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9233
I1007 12:14:23.402670  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.320994 (* 1 = 0.320994 loss)
I1007 12:14:23.485649  4720 solver.cpp:218] Iteration 87500 (9.56535 iter/s, 10.4544s/100 iters), loss = 0.00054747
I1007 12:14:23.485678  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000547596 (* 1 = 0.000547596 loss)
I1007 12:14:23.485684  4720 sgd_solver.cpp:105] Iteration 87500, lr = 0.001
I1007 12:14:31.917515  4720 solver.cpp:218] Iteration 87600 (11.8598 iter/s, 8.43181s/100 iters), loss = 0.00207212
I1007 12:14:31.917654  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00207224 (* 1 = 0.00207224 loss)
I1007 12:14:31.917660  4720 sgd_solver.cpp:105] Iteration 87600, lr = 0.001
I1007 12:14:40.357014  4720 solver.cpp:218] Iteration 87700 (11.8493 iter/s, 8.43934s/100 iters), loss = 0.00248787
I1007 12:14:40.357045  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00248799 (* 1 = 0.00248799 loss)
I1007 12:14:40.357061  4720 sgd_solver.cpp:105] Iteration 87700, lr = 0.001
I1007 12:14:48.795902  4720 solver.cpp:218] Iteration 87800 (11.85 iter/s, 8.43883s/100 iters), loss = 0.00504596
I1007 12:14:48.795931  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00504609 (* 1 = 0.00504609 loss)
I1007 12:14:48.795948  4720 sgd_solver.cpp:105] Iteration 87800, lr = 0.001
I1007 12:14:57.236657  4720 solver.cpp:218] Iteration 87900 (11.8474 iter/s, 8.44068s/100 iters), loss = 0.00726141
I1007 12:14:57.236732  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00726154 (* 1 = 0.00726154 loss)
I1007 12:14:57.236742  4720 sgd_solver.cpp:105] Iteration 87900, lr = 0.001
I1007 12:15:05.240489  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:15:05.584414  4720 solver.cpp:330] Iteration 88000, Testing net (#0)
I1007 12:15:07.536643  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:15:07.617758  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9232
I1007 12:15:07.617785  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.320633 (* 1 = 0.320633 loss)
I1007 12:15:07.706091  4720 solver.cpp:218] Iteration 88000 (9.5517 iter/s, 10.4693s/100 iters), loss = 0.00231425
I1007 12:15:07.706137  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00231439 (* 1 = 0.00231439 loss)
I1007 12:15:07.706164  4720 sgd_solver.cpp:105] Iteration 88000, lr = 0.001
I1007 12:15:16.129492  4720 solver.cpp:218] Iteration 88100 (11.8718 iter/s, 8.42334s/100 iters), loss = 0.00184807
I1007 12:15:16.129528  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00184821 (* 1 = 0.00184821 loss)
I1007 12:15:16.129537  4720 sgd_solver.cpp:105] Iteration 88100, lr = 0.001
I1007 12:15:24.551580  4720 solver.cpp:218] Iteration 88200 (11.8736 iter/s, 8.42203s/100 iters), loss = 0.0162811
I1007 12:15:24.551614  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0162813 (* 1 = 0.0162813 loss)
I1007 12:15:24.551621  4720 sgd_solver.cpp:105] Iteration 88200, lr = 0.001
I1007 12:15:32.968180  4720 solver.cpp:218] Iteration 88300 (11.8814 iter/s, 8.41654s/100 iters), loss = 0.00154962
I1007 12:15:32.968214  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00154976 (* 1 = 0.00154976 loss)
I1007 12:15:32.968232  4720 sgd_solver.cpp:105] Iteration 88300, lr = 0.001
I1007 12:15:41.370560  4720 solver.cpp:218] Iteration 88400 (11.9015 iter/s, 8.40232s/100 iters), loss = 0.00721807
I1007 12:15:41.370674  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00721821 (* 1 = 0.00721821 loss)
I1007 12:15:41.370685  4720 sgd_solver.cpp:105] Iteration 88400, lr = 0.001
I1007 12:15:49.345428  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:15:49.683531  4720 solver.cpp:330] Iteration 88500, Testing net (#0)
I1007 12:15:51.620775  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:15:51.701843  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.924
I1007 12:15:51.701869  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.320388 (* 1 = 0.320388 loss)
I1007 12:15:51.784808  4720 solver.cpp:218] Iteration 88500 (9.60235 iter/s, 10.4141s/100 iters), loss = 0.000446253
I1007 12:15:51.784838  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000446388 (* 1 = 0.000446388 loss)
I1007 12:15:51.784848  4720 sgd_solver.cpp:105] Iteration 88500, lr = 0.001
I1007 12:16:00.206588  4720 solver.cpp:218] Iteration 88600 (11.8741 iter/s, 8.42172s/100 iters), loss = 0.00128397
I1007 12:16:00.206626  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0012841 (* 1 = 0.0012841 loss)
I1007 12:16:00.206635  4720 sgd_solver.cpp:105] Iteration 88600, lr = 0.001
I1007 12:16:08.627511  4720 solver.cpp:218] Iteration 88700 (11.8753 iter/s, 8.42086s/100 iters), loss = 0.000786434
I1007 12:16:08.627542  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000786559 (* 1 = 0.000786559 loss)
I1007 12:16:08.627547  4720 sgd_solver.cpp:105] Iteration 88700, lr = 0.001
I1007 12:16:17.066318  4720 solver.cpp:218] Iteration 88800 (11.8501 iter/s, 8.43875s/100 iters), loss = 0.00352805
I1007 12:16:17.066457  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00352817 (* 1 = 0.00352817 loss)
I1007 12:16:17.066465  4720 sgd_solver.cpp:105] Iteration 88800, lr = 0.001
I1007 12:16:25.498411  4720 solver.cpp:218] Iteration 88900 (11.8597 iter/s, 8.43193s/100 iters), loss = 0.00767877
I1007 12:16:25.498451  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0076789 (* 1 = 0.0076789 loss)
I1007 12:16:25.498457  4720 sgd_solver.cpp:105] Iteration 88900, lr = 0.001
I1007 12:16:33.521167  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:16:33.862220  4720 solver.cpp:330] Iteration 89000, Testing net (#0)
I1007 12:16:35.811095  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:16:35.891917  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9229
I1007 12:16:35.891942  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.32055 (* 1 = 0.32055 loss)
I1007 12:16:35.975073  4720 solver.cpp:218] Iteration 89000 (9.54509 iter/s, 10.4766s/100 iters), loss = 0.00193226
I1007 12:16:35.975098  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00193239 (* 1 = 0.00193239 loss)
I1007 12:16:35.975105  4720 sgd_solver.cpp:105] Iteration 89000, lr = 0.001
I1007 12:16:44.401319  4720 solver.cpp:218] Iteration 89100 (11.8678 iter/s, 8.42619s/100 iters), loss = 0.00392042
I1007 12:16:44.401348  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00392055 (* 1 = 0.00392055 loss)
I1007 12:16:44.401353  4720 sgd_solver.cpp:105] Iteration 89100, lr = 0.001
I1007 12:16:52.845403  4720 solver.cpp:218] Iteration 89200 (11.8427 iter/s, 8.44403s/100 iters), loss = 0.06059
I1007 12:16:52.845511  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0605901 (* 1 = 0.0605901 loss)
I1007 12:16:52.845518  4720 sgd_solver.cpp:105] Iteration 89200, lr = 0.001
I1007 12:17:01.274859  4720 solver.cpp:218] Iteration 89300 (11.8634 iter/s, 8.42932s/100 iters), loss = 0.00230756
I1007 12:17:01.274897  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00230769 (* 1 = 0.00230769 loss)
I1007 12:17:01.274906  4720 sgd_solver.cpp:105] Iteration 89300, lr = 0.001
I1007 12:17:09.696054  4720 solver.cpp:218] Iteration 89400 (11.8749 iter/s, 8.42113s/100 iters), loss = 0.00282617
I1007 12:17:09.696087  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0028263 (* 1 = 0.0028263 loss)
I1007 12:17:09.696094  4720 sgd_solver.cpp:105] Iteration 89400, lr = 0.001
I1007 12:17:17.709708  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:17:18.051667  4720 solver.cpp:330] Iteration 89500, Testing net (#0)
I1007 12:17:19.993687  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:17:20.074673  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9246
I1007 12:17:20.074698  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.32058 (* 1 = 0.32058 loss)
I1007 12:17:20.157714  4720 solver.cpp:218] Iteration 89500 (9.55877 iter/s, 10.4616s/100 iters), loss = 0.00420116
I1007 12:17:20.157743  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00420128 (* 1 = 0.00420128 loss)
I1007 12:17:20.157749  4720 sgd_solver.cpp:105] Iteration 89500, lr = 0.001
I1007 12:17:28.599334  4720 solver.cpp:218] Iteration 89600 (11.8461 iter/s, 8.44156s/100 iters), loss = 0.00150293
I1007 12:17:28.599494  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00150305 (* 1 = 0.00150305 loss)
I1007 12:17:28.599503  4720 sgd_solver.cpp:105] Iteration 89600, lr = 0.001
I1007 12:17:37.045725  4720 solver.cpp:218] Iteration 89700 (11.8396 iter/s, 8.44621s/100 iters), loss = 0.00268934
I1007 12:17:37.045769  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00268947 (* 1 = 0.00268947 loss)
I1007 12:17:37.045776  4720 sgd_solver.cpp:105] Iteration 89700, lr = 0.001
I1007 12:17:45.511440  4720 solver.cpp:218] Iteration 89800 (11.8124 iter/s, 8.46564s/100 iters), loss = 0.00196265
I1007 12:17:45.511471  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00196278 (* 1 = 0.00196278 loss)
I1007 12:17:45.511485  4720 sgd_solver.cpp:105] Iteration 89800, lr = 0.001
I1007 12:17:53.894325  4720 solver.cpp:218] Iteration 89900 (11.9291 iter/s, 8.38283s/100 iters), loss = 0.00202893
I1007 12:17:53.894358  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00202905 (* 1 = 0.00202905 loss)
I1007 12:17:53.894364  4720 sgd_solver.cpp:105] Iteration 89900, lr = 0.001
I1007 12:18:01.876534  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:18:02.212384  4720 solver.cpp:330] Iteration 90000, Testing net (#0)
I1007 12:18:04.149437  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:18:04.230067  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9236
I1007 12:18:04.230103  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.322221 (* 1 = 0.322221 loss)
I1007 12:18:04.313241  4720 solver.cpp:218] Iteration 90000 (9.59799 iter/s, 10.4189s/100 iters), loss = 0.000445728
I1007 12:18:04.313272  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000445848 (* 1 = 0.000445848 loss)
I1007 12:18:04.313279  4720 sgd_solver.cpp:105] Iteration 90000, lr = 0.001
I1007 12:18:12.692446  4720 solver.cpp:218] Iteration 90100 (11.9344 iter/s, 8.37914s/100 iters), loss = 0.0110673
I1007 12:18:12.692487  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0110674 (* 1 = 0.0110674 loss)
I1007 12:18:12.692495  4720 sgd_solver.cpp:105] Iteration 90100, lr = 0.001
I1007 12:18:21.070155  4720 solver.cpp:218] Iteration 90200 (11.9365 iter/s, 8.37764s/100 iters), loss = 0.00241802
I1007 12:18:21.070196  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00241814 (* 1 = 0.00241814 loss)
I1007 12:18:21.070202  4720 sgd_solver.cpp:105] Iteration 90200, lr = 0.001
I1007 12:18:29.522040  4720 solver.cpp:218] Iteration 90300 (11.8318 iter/s, 8.45182s/100 iters), loss = 0.000857938
I1007 12:18:29.522071  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000858058 (* 1 = 0.000858058 loss)
I1007 12:18:29.522089  4720 sgd_solver.cpp:105] Iteration 90300, lr = 0.001
I1007 12:18:37.966112  4720 solver.cpp:218] Iteration 90400 (11.8427 iter/s, 8.44401s/100 iters), loss = 0.0011809
I1007 12:18:37.966220  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00118102 (* 1 = 0.00118102 loss)
I1007 12:18:37.966243  4720 sgd_solver.cpp:105] Iteration 90400, lr = 0.001
I1007 12:18:45.941807  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:18:46.275609  4720 solver.cpp:330] Iteration 90500, Testing net (#0)
I1007 12:18:48.249729  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:18:48.333300  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9238
I1007 12:18:48.333325  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.321883 (* 1 = 0.321883 loss)
I1007 12:18:48.417129  4720 solver.cpp:218] Iteration 90500 (9.56857 iter/s, 10.4509s/100 iters), loss = 0.00184101
I1007 12:18:48.417158  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00184114 (* 1 = 0.00184114 loss)
I1007 12:18:48.417165  4720 sgd_solver.cpp:105] Iteration 90500, lr = 0.001
I1007 12:18:56.881019  4720 solver.cpp:218] Iteration 90600 (11.815 iter/s, 8.46383s/100 iters), loss = 0.00230386
I1007 12:18:56.881053  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00230398 (* 1 = 0.00230398 loss)
I1007 12:18:56.881059  4720 sgd_solver.cpp:105] Iteration 90600, lr = 0.001
I1007 12:19:05.347017  4720 solver.cpp:218] Iteration 90700 (11.812 iter/s, 8.46593s/100 iters), loss = 0.00199782
I1007 12:19:05.347046  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00199794 (* 1 = 0.00199794 loss)
I1007 12:19:05.347053  4720 sgd_solver.cpp:105] Iteration 90700, lr = 0.001
I1007 12:19:13.797163  4720 solver.cpp:218] Iteration 90800 (11.8342 iter/s, 8.45008s/100 iters), loss = 0.00130539
I1007 12:19:13.797327  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00130551 (* 1 = 0.00130551 loss)
I1007 12:19:13.797345  4720 sgd_solver.cpp:105] Iteration 90800, lr = 0.001
I1007 12:19:22.277545  4720 solver.cpp:218] Iteration 90900 (11.7922 iter/s, 8.48019s/100 iters), loss = 0.00146649
I1007 12:19:22.277577  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00146661 (* 1 = 0.00146661 loss)
I1007 12:19:22.277583  4720 sgd_solver.cpp:105] Iteration 90900, lr = 0.001
I1007 12:19:30.312090  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:19:30.652467  4720 solver.cpp:330] Iteration 91000, Testing net (#0)
I1007 12:19:32.588626  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:19:32.669699  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9249
I1007 12:19:32.669735  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.321839 (* 1 = 0.321839 loss)
I1007 12:19:32.753094  4720 solver.cpp:218] Iteration 91000 (9.54609 iter/s, 10.4755s/100 iters), loss = 0.00283481
I1007 12:19:32.753120  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00283492 (* 1 = 0.00283492 loss)
I1007 12:19:32.753126  4720 sgd_solver.cpp:105] Iteration 91000, lr = 0.001
I1007 12:19:41.177307  4720 solver.cpp:218] Iteration 91100 (11.8706 iter/s, 8.42416s/100 iters), loss = 0.00155254
I1007 12:19:41.177337  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00155265 (* 1 = 0.00155265 loss)
I1007 12:19:41.177342  4720 sgd_solver.cpp:105] Iteration 91100, lr = 0.001
I1007 12:19:49.653225  4720 solver.cpp:218] Iteration 91200 (11.7982 iter/s, 8.47586s/100 iters), loss = 0.00125876
I1007 12:19:49.653362  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00125887 (* 1 = 0.00125887 loss)
I1007 12:19:49.653368  4720 sgd_solver.cpp:105] Iteration 91200, lr = 0.001
I1007 12:19:58.143121  4720 solver.cpp:218] Iteration 91300 (11.7789 iter/s, 8.48973s/100 iters), loss = 0.0038609
I1007 12:19:58.143157  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00386102 (* 1 = 0.00386102 loss)
I1007 12:19:58.143165  4720 sgd_solver.cpp:105] Iteration 91300, lr = 0.001
I1007 12:20:06.587752  4720 solver.cpp:218] Iteration 91400 (11.8419 iter/s, 8.44457s/100 iters), loss = 0.00139424
I1007 12:20:06.587787  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00139435 (* 1 = 0.00139435 loss)
I1007 12:20:06.587805  4720 sgd_solver.cpp:105] Iteration 91400, lr = 0.001
I1007 12:20:14.652693  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:20:14.989815  4720 solver.cpp:330] Iteration 91500, Testing net (#0)
I1007 12:20:16.953752  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:20:17.034607  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9243
I1007 12:20:17.034641  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.320797 (* 1 = 0.320797 loss)
I1007 12:20:17.118486  4720 solver.cpp:218] Iteration 91500 (9.49608 iter/s, 10.5307s/100 iters), loss = 0.0017697
I1007 12:20:17.118520  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00176982 (* 1 = 0.00176982 loss)
I1007 12:20:17.118526  4720 sgd_solver.cpp:105] Iteration 91500, lr = 0.001
I1007 12:20:25.589200  4720 solver.cpp:218] Iteration 91600 (11.8055 iter/s, 8.47065s/100 iters), loss = 0.00163486
I1007 12:20:25.589316  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00163498 (* 1 = 0.00163498 loss)
I1007 12:20:25.589335  4720 sgd_solver.cpp:105] Iteration 91600, lr = 0.001
I1007 12:20:34.060302  4720 solver.cpp:218] Iteration 91700 (11.805 iter/s, 8.47096s/100 iters), loss = 0.0278469
I1007 12:20:34.060348  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.027847 (* 1 = 0.027847 loss)
I1007 12:20:34.060355  4720 sgd_solver.cpp:105] Iteration 91700, lr = 0.001
I1007 12:20:42.534968  4720 solver.cpp:218] Iteration 91800 (11.8 iter/s, 8.47459s/100 iters), loss = 0.00177421
I1007 12:20:42.534999  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00177433 (* 1 = 0.00177433 loss)
I1007 12:20:42.535006  4720 sgd_solver.cpp:105] Iteration 91800, lr = 0.001
I1007 12:20:50.991264  4720 solver.cpp:218] Iteration 91900 (11.8256 iter/s, 8.45623s/100 iters), loss = 0.00181301
I1007 12:20:50.991302  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00181312 (* 1 = 0.00181312 loss)
I1007 12:20:50.991309  4720 sgd_solver.cpp:105] Iteration 91900, lr = 0.001
I1007 12:20:59.055410  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:20:59.393381  4720 solver.cpp:330] Iteration 92000, Testing net (#0)
I1007 12:21:01.335475  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:21:01.416406  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9241
I1007 12:21:01.416441  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.321107 (* 1 = 0.321107 loss)
I1007 12:21:01.500043  4720 solver.cpp:218] Iteration 92000 (9.51598 iter/s, 10.5086s/100 iters), loss = 0.000548052
I1007 12:21:01.500073  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000548174 (* 1 = 0.000548174 loss)
I1007 12:21:01.500079  4720 sgd_solver.cpp:105] Iteration 92000, lr = 0.001
I1007 12:21:10.004178  4720 solver.cpp:218] Iteration 92100 (11.7591 iter/s, 8.50408s/100 iters), loss = 0.00178276
I1007 12:21:10.004209  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00178288 (* 1 = 0.00178288 loss)
I1007 12:21:10.004216  4720 sgd_solver.cpp:105] Iteration 92100, lr = 0.001
I1007 12:21:18.460474  4720 solver.cpp:218] Iteration 92200 (11.8256 iter/s, 8.45623s/100 iters), loss = 0.00940219
I1007 12:21:18.460512  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00940231 (* 1 = 0.00940231 loss)
I1007 12:21:18.460532  4720 sgd_solver.cpp:105] Iteration 92200, lr = 0.001
I1007 12:21:26.919560  4720 solver.cpp:218] Iteration 92300 (11.8217 iter/s, 8.45902s/100 iters), loss = 0.00569603
I1007 12:21:26.919595  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00569615 (* 1 = 0.00569615 loss)
I1007 12:21:26.919602  4720 sgd_solver.cpp:105] Iteration 92300, lr = 0.001
I1007 12:21:35.385967  4720 solver.cpp:218] Iteration 92400 (11.8115 iter/s, 8.46635s/100 iters), loss = 0.0073263
I1007 12:21:35.386132  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00732642 (* 1 = 0.00732642 loss)
I1007 12:21:35.386143  4720 sgd_solver.cpp:105] Iteration 92400, lr = 0.001
I1007 12:21:43.437819  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:21:43.772678  4720 solver.cpp:330] Iteration 92500, Testing net (#0)
I1007 12:21:45.728806  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:21:45.811087  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9235
I1007 12:21:45.811115  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.321882 (* 1 = 0.321882 loss)
I1007 12:21:45.894371  4720 solver.cpp:218] Iteration 92500 (9.51637 iter/s, 10.5082s/100 iters), loss = 0.00061828
I1007 12:21:45.894399  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000618403 (* 1 = 0.000618403 loss)
I1007 12:21:45.894408  4720 sgd_solver.cpp:105] Iteration 92500, lr = 0.001
I1007 12:21:54.357338  4720 solver.cpp:218] Iteration 92600 (11.8163 iter/s, 8.46291s/100 iters), loss = 0.00116884
I1007 12:21:54.357379  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00116896 (* 1 = 0.00116896 loss)
I1007 12:21:54.357386  4720 sgd_solver.cpp:105] Iteration 92600, lr = 0.001
I1007 12:22:02.852484  4720 solver.cpp:218] Iteration 92700 (11.7715 iter/s, 8.49508s/100 iters), loss = 0.00238965
I1007 12:22:02.852514  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00238977 (* 1 = 0.00238977 loss)
I1007 12:22:02.852520  4720 sgd_solver.cpp:105] Iteration 92700, lr = 0.001
I1007 12:22:11.315310  4720 solver.cpp:218] Iteration 92800 (11.8165 iter/s, 8.46275s/100 iters), loss = 0.00221626
I1007 12:22:11.315419  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00221639 (* 1 = 0.00221639 loss)
I1007 12:22:11.315438  4720 sgd_solver.cpp:105] Iteration 92800, lr = 0.001
I1007 12:22:19.751998  4720 solver.cpp:218] Iteration 92900 (11.8532 iter/s, 8.43655s/100 iters), loss = 0.00367059
I1007 12:22:19.752028  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00367071 (* 1 = 0.00367071 loss)
I1007 12:22:19.752033  4720 sgd_solver.cpp:105] Iteration 92900, lr = 0.001
I1007 12:22:27.700398  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:22:28.036381  4720 solver.cpp:330] Iteration 93000, Testing net (#0)
I1007 12:22:29.987289  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:22:30.067910  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9234
I1007 12:22:30.067945  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.322657 (* 1 = 0.322657 loss)
I1007 12:22:30.151505  4720 solver.cpp:218] Iteration 93000 (9.6159 iter/s, 10.3994s/100 iters), loss = 0.00144998
I1007 12:22:30.151530  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00145011 (* 1 = 0.00145011 loss)
I1007 12:22:30.151536  4720 sgd_solver.cpp:105] Iteration 93000, lr = 0.001
I1007 12:22:38.576515  4720 solver.cpp:218] Iteration 93100 (11.8695 iter/s, 8.42496s/100 iters), loss = 0.00391452
I1007 12:22:38.576555  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00391465 (* 1 = 0.00391465 loss)
I1007 12:22:38.576561  4720 sgd_solver.cpp:105] Iteration 93100, lr = 0.001
I1007 12:22:46.950769  4720 solver.cpp:218] Iteration 93200 (11.9415 iter/s, 8.37419s/100 iters), loss = 0.00206172
I1007 12:22:46.950863  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00206184 (* 1 = 0.00206184 loss)
I1007 12:22:46.950870  4720 sgd_solver.cpp:105] Iteration 93200, lr = 0.001
I1007 12:22:55.337146  4720 solver.cpp:218] Iteration 93300 (11.9243 iter/s, 8.38625s/100 iters), loss = 0.00070993
I1007 12:22:55.337178  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000710056 (* 1 = 0.000710056 loss)
I1007 12:22:55.337185  4720 sgd_solver.cpp:105] Iteration 93300, lr = 0.001
I1007 12:23:03.716292  4720 solver.cpp:218] Iteration 93400 (11.9345 iter/s, 8.37909s/100 iters), loss = 0.00273049
I1007 12:23:03.716332  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00273062 (* 1 = 0.00273062 loss)
I1007 12:23:03.716338  4720 sgd_solver.cpp:105] Iteration 93400, lr = 0.001
I1007 12:23:11.665592  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:23:12.001664  4720 solver.cpp:330] Iteration 93500, Testing net (#0)
I1007 12:23:13.936157  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:23:14.017099  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.924
I1007 12:23:14.017137  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.322881 (* 1 = 0.322881 loss)
I1007 12:23:14.100389  4720 solver.cpp:218] Iteration 93500 (9.63018 iter/s, 10.384s/100 iters), loss = 0.000500553
I1007 12:23:14.100415  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000500679 (* 1 = 0.000500679 loss)
I1007 12:23:14.100421  4720 sgd_solver.cpp:105] Iteration 93500, lr = 0.001
I1007 12:23:22.468312  4720 solver.cpp:218] Iteration 93600 (11.9505 iter/s, 8.36787s/100 iters), loss = 0.00145873
I1007 12:23:22.468446  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00145886 (* 1 = 0.00145886 loss)
I1007 12:23:22.468453  4720 sgd_solver.cpp:105] Iteration 93600, lr = 0.001
I1007 12:23:30.864328  4720 solver.cpp:218] Iteration 93700 (11.9106 iter/s, 8.39586s/100 iters), loss = 0.00243255
I1007 12:23:30.864368  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00243267 (* 1 = 0.00243267 loss)
I1007 12:23:30.864374  4720 sgd_solver.cpp:105] Iteration 93700, lr = 0.001
I1007 12:23:39.269917  4720 solver.cpp:218] Iteration 93800 (11.8969 iter/s, 8.40552s/100 iters), loss = 0.00226434
I1007 12:23:39.269953  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00226446 (* 1 = 0.00226446 loss)
I1007 12:23:39.269960  4720 sgd_solver.cpp:105] Iteration 93800, lr = 0.001
I1007 12:23:47.663503  4720 solver.cpp:218] Iteration 93900 (11.9139 iter/s, 8.39352s/100 iters), loss = 0.00278554
I1007 12:23:47.663542  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00278567 (* 1 = 0.00278567 loss)
I1007 12:23:47.663548  4720 sgd_solver.cpp:105] Iteration 93900, lr = 0.001
I1007 12:23:55.609427  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:23:55.944160  4720 solver.cpp:330] Iteration 94000, Testing net (#0)
I1007 12:23:57.875507  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:23:57.956452  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.924
I1007 12:23:57.956488  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.323149 (* 1 = 0.323149 loss)
I1007 12:23:58.039379  4720 solver.cpp:218] Iteration 94000 (9.63781 iter/s, 10.3758s/100 iters), loss = 0.000928114
I1007 12:23:58.039412  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000928243 (* 1 = 0.000928243 loss)
I1007 12:23:58.039418  4720 sgd_solver.cpp:105] Iteration 94000, lr = 0.001
I1007 12:24:06.398286  4720 solver.cpp:218] Iteration 94100 (11.9634 iter/s, 8.35885s/100 iters), loss = 0.00221676
I1007 12:24:06.398326  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00221689 (* 1 = 0.00221689 loss)
I1007 12:24:06.398331  4720 sgd_solver.cpp:105] Iteration 94100, lr = 0.001
I1007 12:24:14.765323  4720 solver.cpp:218] Iteration 94200 (11.9518 iter/s, 8.36697s/100 iters), loss = 0.00371636
I1007 12:24:14.765363  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00371649 (* 1 = 0.00371649 loss)
I1007 12:24:14.765369  4720 sgd_solver.cpp:105] Iteration 94200, lr = 0.001
I1007 12:24:23.126421  4720 solver.cpp:218] Iteration 94300 (11.9602 iter/s, 8.36103s/100 iters), loss = 0.00293677
I1007 12:24:23.126462  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00293691 (* 1 = 0.00293691 loss)
I1007 12:24:23.126468  4720 sgd_solver.cpp:105] Iteration 94300, lr = 0.001
I1007 12:24:31.491113  4720 solver.cpp:218] Iteration 94400 (11.9551 iter/s, 8.36462s/100 iters), loss = 0.00282684
I1007 12:24:31.491276  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00282698 (* 1 = 0.00282698 loss)
I1007 12:24:31.491284  4720 sgd_solver.cpp:105] Iteration 94400, lr = 0.001
I1007 12:24:39.437440  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:24:39.772456  4720 solver.cpp:330] Iteration 94500, Testing net (#0)
I1007 12:24:41.704944  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:24:41.785837  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9239
I1007 12:24:41.785872  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.324685 (* 1 = 0.324685 loss)
I1007 12:24:41.869416  4720 solver.cpp:218] Iteration 94500 (9.63567 iter/s, 10.3781s/100 iters), loss = 0.001628
I1007 12:24:41.869446  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00162813 (* 1 = 0.00162813 loss)
I1007 12:24:41.869451  4720 sgd_solver.cpp:105] Iteration 94500, lr = 0.001
I1007 12:24:50.229706  4720 solver.cpp:218] Iteration 94600 (11.9614 iter/s, 8.36023s/100 iters), loss = 0.00206133
I1007 12:24:50.229734  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00206146 (* 1 = 0.00206146 loss)
I1007 12:24:50.229740  4720 sgd_solver.cpp:105] Iteration 94600, lr = 0.001
I1007 12:24:58.578003  4720 solver.cpp:218] Iteration 94700 (11.9786 iter/s, 8.34824s/100 iters), loss = 0.00319619
I1007 12:24:58.578033  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00319632 (* 1 = 0.00319632 loss)
I1007 12:24:58.578039  4720 sgd_solver.cpp:105] Iteration 94700, lr = 0.001
I1007 12:25:06.934756  4720 solver.cpp:218] Iteration 94800 (11.9665 iter/s, 8.3567s/100 iters), loss = 0.00322945
I1007 12:25:06.934865  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00322958 (* 1 = 0.00322958 loss)
I1007 12:25:06.934872  4720 sgd_solver.cpp:105] Iteration 94800, lr = 0.001
I1007 12:25:15.288691  4720 solver.cpp:218] Iteration 94900 (11.9706 iter/s, 8.35381s/100 iters), loss = 0.00102193
I1007 12:25:15.288722  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00102206 (* 1 = 0.00102206 loss)
I1007 12:25:15.288727  4720 sgd_solver.cpp:105] Iteration 94900, lr = 0.001
I1007 12:25:23.231386  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:25:23.566047  4720 solver.cpp:330] Iteration 95000, Testing net (#0)
I1007 12:25:25.499656  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:25:25.580478  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9245
I1007 12:25:25.580503  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.32555 (* 1 = 0.32555 loss)
I1007 12:25:25.663429  4720 solver.cpp:218] Iteration 95000 (9.63885 iter/s, 10.3747s/100 iters), loss = 0.000948773
I1007 12:25:25.663456  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000948901 (* 1 = 0.000948901 loss)
I1007 12:25:25.663463  4720 sgd_solver.cpp:105] Iteration 95000, lr = 0.001
I1007 12:25:34.021633  4720 solver.cpp:218] Iteration 95100 (11.9644 iter/s, 8.35815s/100 iters), loss = 0.00455768
I1007 12:25:34.021673  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00455781 (* 1 = 0.00455781 loss)
I1007 12:25:34.021678  4720 sgd_solver.cpp:105] Iteration 95100, lr = 0.001
I1007 12:25:42.385514  4720 solver.cpp:218] Iteration 95200 (11.9563 iter/s, 8.36381s/100 iters), loss = 0.00236643
I1007 12:25:42.385653  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00236656 (* 1 = 0.00236656 loss)
I1007 12:25:42.385670  4720 sgd_solver.cpp:105] Iteration 95200, lr = 0.001
I1007 12:25:50.738082  4720 solver.cpp:218] Iteration 95300 (11.9726 iter/s, 8.3524s/100 iters), loss = 0.00133044
I1007 12:25:50.738112  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00133057 (* 1 = 0.00133057 loss)
I1007 12:25:50.738117  4720 sgd_solver.cpp:105] Iteration 95300, lr = 0.001
I1007 12:25:59.093323  4720 solver.cpp:218] Iteration 95400 (11.9686 iter/s, 8.35518s/100 iters), loss = 0.00246116
I1007 12:25:59.093353  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00246129 (* 1 = 0.00246129 loss)
I1007 12:25:59.093358  4720 sgd_solver.cpp:105] Iteration 95400, lr = 0.001
I1007 12:26:07.030781  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:26:07.365618  4720 solver.cpp:330] Iteration 95500, Testing net (#0)
I1007 12:26:09.299510  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:26:09.380393  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9236
I1007 12:26:09.380429  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.325162 (* 1 = 0.325162 loss)
I1007 12:26:09.464442  4720 solver.cpp:218] Iteration 95500 (9.64222 iter/s, 10.3711s/100 iters), loss = 0.00399715
I1007 12:26:09.464471  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00399728 (* 1 = 0.00399728 loss)
I1007 12:26:09.464478  4720 sgd_solver.cpp:105] Iteration 95500, lr = 0.001
I1007 12:26:17.822397  4720 solver.cpp:218] Iteration 95600 (11.9647 iter/s, 8.3579s/100 iters), loss = 0.00177586
I1007 12:26:17.822533  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00177598 (* 1 = 0.00177598 loss)
I1007 12:26:17.822540  4720 sgd_solver.cpp:105] Iteration 95600, lr = 0.001
I1007 12:26:26.184779  4720 solver.cpp:218] Iteration 95700 (11.9585 iter/s, 8.36223s/100 iters), loss = 0.00127111
I1007 12:26:26.184819  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00127123 (* 1 = 0.00127123 loss)
I1007 12:26:26.184825  4720 sgd_solver.cpp:105] Iteration 95700, lr = 0.001
I1007 12:26:34.547644  4720 solver.cpp:218] Iteration 95800 (11.9577 iter/s, 8.3628s/100 iters), loss = 0.00161192
I1007 12:26:34.547685  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00161204 (* 1 = 0.00161204 loss)
I1007 12:26:34.547691  4720 sgd_solver.cpp:105] Iteration 95800, lr = 0.001
I1007 12:26:42.903316  4720 solver.cpp:218] Iteration 95900 (11.968 iter/s, 8.3556s/100 iters), loss = 0.00169377
I1007 12:26:42.903347  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0016939 (* 1 = 0.0016939 loss)
I1007 12:26:42.903352  4720 sgd_solver.cpp:105] Iteration 95900, lr = 0.001
I1007 12:26:50.849498  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:26:51.184129  4720 solver.cpp:330] Iteration 96000, Testing net (#0)
I1007 12:26:53.116914  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:26:53.197731  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9236
I1007 12:26:53.197767  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.323899 (* 1 = 0.323899 loss)
I1007 12:26:53.281064  4720 solver.cpp:218] Iteration 96000 (9.63606 iter/s, 10.3777s/100 iters), loss = 0.00182687
I1007 12:26:53.281096  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.001827 (* 1 = 0.001827 loss)
I1007 12:26:53.281103  4720 sgd_solver.cpp:105] Iteration 96000, lr = 0.001
I1007 12:27:01.636502  4720 solver.cpp:218] Iteration 96100 (11.9683 iter/s, 8.35538s/100 iters), loss = 0.000633697
I1007 12:27:01.636530  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000633823 (* 1 = 0.000633823 loss)
I1007 12:27:01.636535  4720 sgd_solver.cpp:105] Iteration 96100, lr = 0.001
I1007 12:27:09.996495  4720 solver.cpp:218] Iteration 96200 (11.9618 iter/s, 8.35994s/100 iters), loss = 0.0013026
I1007 12:27:09.996536  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00130273 (* 1 = 0.00130273 loss)
I1007 12:27:09.996541  4720 sgd_solver.cpp:105] Iteration 96200, lr = 0.001
I1007 12:27:18.350713  4720 solver.cpp:218] Iteration 96300 (11.9701 iter/s, 8.35415s/100 iters), loss = 0.00149821
I1007 12:27:18.350741  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00149834 (* 1 = 0.00149834 loss)
I1007 12:27:18.350747  4720 sgd_solver.cpp:105] Iteration 96300, lr = 0.001
I1007 12:27:26.706143  4720 solver.cpp:218] Iteration 96400 (11.9683 iter/s, 8.35537s/100 iters), loss = 0.0035989
I1007 12:27:26.706291  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00359903 (* 1 = 0.00359903 loss)
I1007 12:27:26.706298  4720 sgd_solver.cpp:105] Iteration 96400, lr = 0.001
I1007 12:27:34.648934  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:27:34.984014  4720 solver.cpp:330] Iteration 96500, Testing net (#0)
I1007 12:27:36.916615  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:27:36.997620  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9236
I1007 12:27:36.997654  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.322595 (* 1 = 0.322595 loss)
I1007 12:27:37.080965  4720 solver.cpp:218] Iteration 96500 (9.63889 iter/s, 10.3746s/100 iters), loss = 0.00397161
I1007 12:27:37.080992  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00397174 (* 1 = 0.00397174 loss)
I1007 12:27:37.080999  4720 sgd_solver.cpp:105] Iteration 96500, lr = 0.001
I1007 12:27:45.444422  4720 solver.cpp:218] Iteration 96600 (11.9569 iter/s, 8.3634s/100 iters), loss = 0.00255405
I1007 12:27:45.444460  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00255417 (* 1 = 0.00255417 loss)
I1007 12:27:45.444465  4720 sgd_solver.cpp:105] Iteration 96600, lr = 0.001
I1007 12:27:53.795748  4720 solver.cpp:218] Iteration 96700 (11.9742 iter/s, 8.35126s/100 iters), loss = 0.000561976
I1007 12:27:53.795778  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000562101 (* 1 = 0.000562101 loss)
I1007 12:27:53.795784  4720 sgd_solver.cpp:105] Iteration 96700, lr = 0.001
I1007 12:28:02.159622  4720 solver.cpp:218] Iteration 96800 (11.9563 iter/s, 8.36382s/100 iters), loss = 0.00243694
I1007 12:28:02.159752  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00243707 (* 1 = 0.00243707 loss)
I1007 12:28:02.159760  4720 sgd_solver.cpp:105] Iteration 96800, lr = 0.001
I1007 12:28:10.516070  4720 solver.cpp:218] Iteration 96900 (11.967 iter/s, 8.35629s/100 iters), loss = 0.00151192
I1007 12:28:10.516110  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00151205 (* 1 = 0.00151205 loss)
I1007 12:28:10.516115  4720 sgd_solver.cpp:105] Iteration 96900, lr = 0.001
I1007 12:28:18.463089  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:28:18.797745  4720 solver.cpp:330] Iteration 97000, Testing net (#0)
I1007 12:28:20.731761  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:28:20.811918  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9243
I1007 12:28:20.811954  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.323924 (* 1 = 0.323924 loss)
I1007 12:28:20.895141  4720 solver.cpp:218] Iteration 97000 (9.63484 iter/s, 10.379s/100 iters), loss = 0.0011815
I1007 12:28:20.895172  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00118163 (* 1 = 0.00118163 loss)
I1007 12:28:20.895179  4720 sgd_solver.cpp:105] Iteration 97000, lr = 0.001
I1007 12:28:29.243531  4720 solver.cpp:218] Iteration 97100 (11.9784 iter/s, 8.34833s/100 iters), loss = 0.00369039
I1007 12:28:29.243564  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00369052 (* 1 = 0.00369052 loss)
I1007 12:28:29.243571  4720 sgd_solver.cpp:105] Iteration 97100, lr = 0.001
I1007 12:28:37.603359  4720 solver.cpp:218] Iteration 97200 (11.9621 iter/s, 8.35977s/100 iters), loss = 0.00119933
I1007 12:28:37.603513  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00119946 (* 1 = 0.00119946 loss)
I1007 12:28:37.603520  4720 sgd_solver.cpp:105] Iteration 97200, lr = 0.001
I1007 12:28:45.956532  4720 solver.cpp:218] Iteration 97300 (11.9717 iter/s, 8.35301s/100 iters), loss = 0.00313121
I1007 12:28:45.956571  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00313134 (* 1 = 0.00313134 loss)
I1007 12:28:45.956578  4720 sgd_solver.cpp:105] Iteration 97300, lr = 0.001
I1007 12:28:54.314374  4720 solver.cpp:218] Iteration 97400 (11.9649 iter/s, 8.35777s/100 iters), loss = 0.00159634
I1007 12:28:54.314405  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00159646 (* 1 = 0.00159646 loss)
I1007 12:28:54.314411  4720 sgd_solver.cpp:105] Iteration 97400, lr = 0.001
I1007 12:29:02.251822  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:29:02.586745  4720 solver.cpp:330] Iteration 97500, Testing net (#0)
I1007 12:29:04.520628  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:29:04.601562  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9238
I1007 12:29:04.601598  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.32446 (* 1 = 0.32446 loss)
I1007 12:29:04.685353  4720 solver.cpp:218] Iteration 97500 (9.64235 iter/s, 10.3709s/100 iters), loss = 0.00289387
I1007 12:29:04.685384  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.002894 (* 1 = 0.002894 loss)
I1007 12:29:04.685391  4720 sgd_solver.cpp:105] Iteration 97500, lr = 0.001
I1007 12:29:13.051103  4720 solver.cpp:218] Iteration 97600 (11.9536 iter/s, 8.36569s/100 iters), loss = 0.000558254
I1007 12:29:13.051185  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000558383 (* 1 = 0.000558383 loss)
I1007 12:29:13.051194  4720 sgd_solver.cpp:105] Iteration 97600, lr = 0.001
I1007 12:29:21.410303  4720 solver.cpp:218] Iteration 97700 (11.963 iter/s, 8.35909s/100 iters), loss = 0.00377331
I1007 12:29:21.410332  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00377344 (* 1 = 0.00377344 loss)
I1007 12:29:21.410337  4720 sgd_solver.cpp:105] Iteration 97700, lr = 0.001
I1007 12:29:29.773520  4720 solver.cpp:218] Iteration 97800 (11.9572 iter/s, 8.36316s/100 iters), loss = 0.00349556
I1007 12:29:29.773561  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00349568 (* 1 = 0.00349568 loss)
I1007 12:29:29.773566  4720 sgd_solver.cpp:105] Iteration 97800, lr = 0.001
I1007 12:29:38.139623  4720 solver.cpp:218] Iteration 97900 (11.9531 iter/s, 8.36603s/100 iters), loss = 0.000881855
I1007 12:29:38.139657  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00088198 (* 1 = 0.00088198 loss)
I1007 12:29:38.139662  4720 sgd_solver.cpp:105] Iteration 97900, lr = 0.001
I1007 12:29:46.196355  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:29:46.531412  4720 solver.cpp:330] Iteration 98000, Testing net (#0)
I1007 12:29:48.466111  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:29:48.546038  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9232
I1007 12:29:48.546074  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.323359 (* 1 = 0.323359 loss)
I1007 12:29:48.629436  4720 solver.cpp:218] Iteration 98000 (9.53312 iter/s, 10.4897s/100 iters), loss = 0.00268457
I1007 12:29:48.629463  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0026847 (* 1 = 0.0026847 loss)
I1007 12:29:48.629470  4720 sgd_solver.cpp:105] Iteration 98000, lr = 0.001
I1007 12:29:56.998028  4720 solver.cpp:218] Iteration 98100 (11.9495 iter/s, 8.36854s/100 iters), loss = 0.0010365
I1007 12:29:56.998057  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00103662 (* 1 = 0.00103662 loss)
I1007 12:29:56.998062  4720 sgd_solver.cpp:105] Iteration 98100, lr = 0.001
I1007 12:30:05.371716  4720 solver.cpp:218] Iteration 98200 (11.9423 iter/s, 8.37363s/100 iters), loss = 0.0033209
I1007 12:30:05.371747  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00332103 (* 1 = 0.00332103 loss)
I1007 12:30:05.371752  4720 sgd_solver.cpp:105] Iteration 98200, lr = 0.001
I1007 12:30:13.740705  4720 solver.cpp:218] Iteration 98300 (11.949 iter/s, 8.36893s/100 iters), loss = 0.00255576
I1007 12:30:13.740737  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00255588 (* 1 = 0.00255588 loss)
I1007 12:30:13.740743  4720 sgd_solver.cpp:105] Iteration 98300, lr = 0.001
I1007 12:30:22.102905  4720 solver.cpp:218] Iteration 98400 (11.9587 iter/s, 8.36214s/100 iters), loss = 0.00161871
I1007 12:30:22.103091  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00161883 (* 1 = 0.00161883 loss)
I1007 12:30:22.103099  4720 sgd_solver.cpp:105] Iteration 98400, lr = 0.001
I1007 12:30:30.063622  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:30:30.400138  4720 solver.cpp:330] Iteration 98500, Testing net (#0)
I1007 12:30:32.335101  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:30:32.416134  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9242
I1007 12:30:32.416159  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.325123 (* 1 = 0.325123 loss)
I1007 12:30:32.499641  4720 solver.cpp:218] Iteration 98500 (9.61859 iter/s, 10.3965s/100 iters), loss = 0.00100427
I1007 12:30:32.499670  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0010044 (* 1 = 0.0010044 loss)
I1007 12:30:32.499676  4720 sgd_solver.cpp:105] Iteration 98500, lr = 0.001
I1007 12:30:40.858891  4720 solver.cpp:218] Iteration 98600 (11.9629 iter/s, 8.35919s/100 iters), loss = 0.00166991
I1007 12:30:40.858930  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00167003 (* 1 = 0.00167003 loss)
I1007 12:30:40.858937  4720 sgd_solver.cpp:105] Iteration 98600, lr = 0.001
I1007 12:30:49.220778  4720 solver.cpp:218] Iteration 98700 (11.9591 iter/s, 8.36182s/100 iters), loss = 0.00158736
I1007 12:30:49.220808  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00158748 (* 1 = 0.00158748 loss)
I1007 12:30:49.220815  4720 sgd_solver.cpp:105] Iteration 98700, lr = 0.001
I1007 12:30:57.578722  4720 solver.cpp:218] Iteration 98800 (11.9647 iter/s, 8.35789s/100 iters), loss = 0.0011221
I1007 12:30:57.578812  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00112223 (* 1 = 0.00112223 loss)
I1007 12:30:57.578830  4720 sgd_solver.cpp:105] Iteration 98800, lr = 0.001
I1007 12:31:05.941004  4720 solver.cpp:218] Iteration 98900 (11.9586 iter/s, 8.36217s/100 iters), loss = 0.00519
I1007 12:31:05.941035  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00519013 (* 1 = 0.00519013 loss)
I1007 12:31:05.941051  4720 sgd_solver.cpp:105] Iteration 98900, lr = 0.001
I1007 12:31:13.882573  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:31:14.218789  4720 solver.cpp:330] Iteration 99000, Testing net (#0)
I1007 12:31:16.151201  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:31:16.231976  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9233
I1007 12:31:16.232002  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.325326 (* 1 = 0.325326 loss)
I1007 12:31:16.315663  4720 solver.cpp:218] Iteration 99000 (9.63893 iter/s, 10.3746s/100 iters), loss = 0.000764703
I1007 12:31:16.315696  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00076483 (* 1 = 0.00076483 loss)
I1007 12:31:16.315703  4720 sgd_solver.cpp:105] Iteration 99000, lr = 0.001
I1007 12:31:24.672157  4720 solver.cpp:218] Iteration 99100 (11.9668 iter/s, 8.35643s/100 iters), loss = 0.00367968
I1007 12:31:24.672185  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00367981 (* 1 = 0.00367981 loss)
I1007 12:31:24.672191  4720 sgd_solver.cpp:105] Iteration 99100, lr = 0.001
I1007 12:31:33.026809  4720 solver.cpp:218] Iteration 99200 (11.9695 iter/s, 8.3546s/100 iters), loss = 0.000675362
I1007 12:31:33.026927  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000675487 (* 1 = 0.000675487 loss)
I1007 12:31:33.026943  4720 sgd_solver.cpp:105] Iteration 99200, lr = 0.001
I1007 12:31:41.387866  4720 solver.cpp:218] Iteration 99300 (11.9604 iter/s, 8.36092s/100 iters), loss = 0.000650975
I1007 12:31:41.387895  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0006511 (* 1 = 0.0006511 loss)
I1007 12:31:41.387912  4720 sgd_solver.cpp:105] Iteration 99300, lr = 0.001
I1007 12:31:49.750679  4720 solver.cpp:218] Iteration 99400 (11.9578 iter/s, 8.36276s/100 iters), loss = 0.000963518
I1007 12:31:49.750707  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000963642 (* 1 = 0.000963642 loss)
I1007 12:31:49.750712  4720 sgd_solver.cpp:105] Iteration 99400, lr = 0.001
I1007 12:31:57.701856  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:31:58.036581  4720 solver.cpp:330] Iteration 99500, Testing net (#0)
I1007 12:31:59.970764  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:32:00.050845  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9245
I1007 12:32:00.050880  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.325163 (* 1 = 0.325163 loss)
I1007 12:32:00.133913  4720 solver.cpp:218] Iteration 99500 (9.63097 iter/s, 10.3832s/100 iters), loss = 0.00145996
I1007 12:32:00.133944  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00146009 (* 1 = 0.00146009 loss)
I1007 12:32:00.133949  4720 sgd_solver.cpp:105] Iteration 99500, lr = 0.001
I1007 12:32:08.488816  4720 solver.cpp:218] Iteration 99600 (11.9691 iter/s, 8.35485s/100 iters), loss = 0.00889449
I1007 12:32:08.488931  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00889461 (* 1 = 0.00889461 loss)
I1007 12:32:08.488940  4720 sgd_solver.cpp:105] Iteration 99600, lr = 0.001
I1007 12:32:16.853771  4720 solver.cpp:218] Iteration 99700 (11.9548 iter/s, 8.36481s/100 iters), loss = 0.00193137
I1007 12:32:16.853802  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0019315 (* 1 = 0.0019315 loss)
I1007 12:32:16.853808  4720 sgd_solver.cpp:105] Iteration 99700, lr = 0.001
I1007 12:32:25.211997  4720 solver.cpp:218] Iteration 99800 (11.9644 iter/s, 8.35816s/100 iters), loss = 0.000701702
I1007 12:32:25.212033  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000701828 (* 1 = 0.000701828 loss)
I1007 12:32:25.212039  4720 sgd_solver.cpp:105] Iteration 99800, lr = 0.001
I1007 12:32:33.570370  4720 solver.cpp:218] Iteration 99900 (11.9641 iter/s, 8.35831s/100 iters), loss = 0.00241424
I1007 12:32:33.570411  4720 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00241437 (* 1 = 0.00241437 loss)
I1007 12:32:33.570417  4720 sgd_solver.cpp:105] Iteration 99900, lr = 0.001
I1007 12:32:41.511968  4729 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:32:41.846149  4720 solver.cpp:447] Snapshotting to binary proto file xn/PENLU/snapshot/resnet/res32/res32_penlu_alpha1_beta1_etanostudy_2study_2decay_gauss_iter_100000.caffemodel
I1007 12:32:41.859499  4720 sgd_solver.cpp:273] Snapshotting solver state to binary proto file xn/PENLU/snapshot/resnet/res32/res32_penlu_alpha1_beta1_etanostudy_2study_2decay_gauss_iter_100000.solverstate
I1007 12:32:41.882691  4720 solver.cpp:310] Iteration 100000, loss = 0.00174341
I1007 12:32:41.882714  4720 solver.cpp:330] Iteration 100000, Testing net (#0)
I1007 12:32:43.814054  4730 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:32:43.895156  4720 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9229
I1007 12:32:43.895195  4720 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.325607 (* 1 = 0.325607 loss)
I1007 12:32:43.895200  4720 solver.cpp:315] Optimization Done.
I1007 12:32:43.895203  4720 caffe.cpp:259] Optimization Done.
