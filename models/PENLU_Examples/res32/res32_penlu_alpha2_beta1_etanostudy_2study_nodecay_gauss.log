I1007 15:08:43.073958  4982 caffe.cpp:218] Using GPUs 0
I1007 15:08:43.098748  4982 caffe.cpp:223] GPU 0: GeForce GTX 1080
I1007 15:08:43.324476  4982 solver.cpp:44] Initializing solver from parameters: 
test_iter: 100
test_interval: 500
base_lr: 0.1
display: 100
max_iter: 100000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0001
snapshot: 100000
snapshot_prefix: "xn/PENLU/snapshot/resnet/res32/res32_penlu_alpha2_beta1_etanostudy_2study_nodecay_gauss"
solver_mode: GPU
device_id: 0
net: "/home/x306/caffe/xn/PENLU/neural/resnet/res32/res32_penlu_gauss.prototxt"
train_state {
  level: 0
  stage: ""
}
stepvalue: 40000
stepvalue: 80000
I1007 15:08:43.324631  4982 solver.cpp:87] Creating training net from net file: /home/x306/caffe/xn/PENLU/neural/resnet/res32/res32_penlu_gauss.prototxt
I1007 15:08:43.326944  4982 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: /home/x306/caffe/xn/PENLU/neural/resnet/res32/res32_penlu_gauss.prototxt
I1007 15:08:43.326957  4982 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I1007 15:08:43.327148  4982 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer Data1
I1007 15:08:43.327265  4982 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer Accuracy1
I1007 15:08:43.327975  4982 net.cpp:51] Initializing net from parameters: 
name: "resnet_cifar10"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "Data1"
  type: "Data"
  top: "Data1"
  top: "Data2"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 28
    mean_file: "/home/x306/caffe/xn/PENLU/data/cifar10/mean.binaryproto"
  }
  data_param {
    source: "/home/x306/caffe/xn/PENLU/data/cifar10/cifar10_train_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "Convolution1"
  type: "Convolution"
  bottom: "Data1"
  top: "Convolution1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm1"
  type: "BatchNorm"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1"
  type: "Scale"
  bottom: "Convolution1"
  top: "Convolution1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu1"
  type: "PENLU"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution2"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm2"
  type: "BatchNorm"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale2"
  type: "Scale"
  bottom: "Convolution2"
  top: "Convolution2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu2"
  type: "PENLU"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution3"
  type: "Convolution"
  bottom: "Convolution2"
  top: "Convolution3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm3"
  type: "BatchNorm"
  bottom: "Convolution3"
  top: "Convolution3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale3"
  type: "Scale"
  bottom: "Convolution3"
  top: "Convolution3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise1"
  type: "Eltwise"
  bottom: "Convolution1"
  bottom: "Convolution3"
  top: "Eltwise1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu3"
  type: "PENLU"
  bottom: "Eltwise1"
  top: "Eltwise1"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution4"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm4"
  type: "BatchNorm"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale4"
  type: "Scale"
  bottom: "Convolution4"
  top: "Convolution4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu4"
  type: "PENLU"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution5"
  type: "Convolution"
  bottom: "Convolution4"
  top: "Convolution5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm5"
  type: "BatchNorm"
  bottom: "Convolution5"
  top: "Convolution5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale5"
  type: "Scale"
  bottom: "Convolution5"
  top: "Convolution5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise2"
  type: "Eltwise"
  bottom: "Eltwise1"
  bottom: "Convolution5"
  top: "Eltwise2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu5"
  type: "PENLU"
  bottom: "Eltwise2"
  top: "Eltwise2"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution6"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm6"
  type: "BatchNorm"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale6"
  type: "Scale"
  bottom: "Convolution6"
  top: "Convolution6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu6"
  type: "PENLU"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution7"
  type: "Convolution"
  bottom: "Convolution6"
  top: "Convolution7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm7"
  type: "BatchNorm"
  bottom: "Convolution7"
  top: "Convolution7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale7"
  type: "Scale"
  bottom: "Convolution7"
  top: "Convolution7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise3"
  type: "Eltwise"
  bottom: "Eltwise2"
  bottom: "Convolution7"
  top: "Eltwise3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu7"
  type: "PENLU"
  bottom: "Eltwise3"
  top: "Eltwise3"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution8"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm8"
  type: "BatchNorm"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale8"
  type: "Scale"
  bottom: "Convolution8"
  top: "Convolution8"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu8"
  type: "PENLU"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution9"
  type: "Convolution"
  bottom: "Convolution8"
  top: "Convolution9"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm9"
  type: "BatchNorm"
  bottom: "Convolution9"
  top: "Convolution9"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale9"
  type: "Scale"
  bottom: "Convolution9"
  top: "Convolution9"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise4"
  type: "Eltwise"
  bottom: "Eltwise3"
  bottom: "Convolution9"
  top: "Eltwise4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu9"
  type: "PENLU"
  bottom: "Eltwise4"
  top: "Eltwise4"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution10"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution10"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm10"
  type: "BatchNorm"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale10"
  type: "Scale"
  bottom: "Convolution10"
  top: "Convolution10"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu10"
  type: "PENLU"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution11"
  type: "Convolution"
  bottom: "Convolution10"
  top: "Convolution11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm11"
  type: "BatchNorm"
  bottom: "Convolution11"
  top: "Convolution11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale11"
  type: "Scale"
  bottom: "Convolution11"
  top: "Convolution11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise5"
  type: "Eltwise"
  bottom: "Eltwise4"
  bottom: "Convolution11"
  top: "Eltwise5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu11"
  type: "PENLU"
  bottom: "Eltwise5"
  top: "Eltwise5"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution12"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.25
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm12"
  type: "BatchNorm"
  bottom: "Convolution12"
  top: "Convolution12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale12"
  type: "Scale"
  bottom: "Convolution12"
  top: "Convolution12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution13"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution13"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm13"
  type: "BatchNorm"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale13"
  type: "Scale"
  bottom: "Convolution13"
  top: "Convolution13"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu12"
  type: "PENLU"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution14"
  type: "Convolution"
  bottom: "Convolution13"
  top: "Convolution14"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm14"
  type: "BatchNorm"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale14"
  type: "Scale"
  bottom: "Convolution14"
  top: "Convolution14"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise6"
  type: "Eltwise"
  bottom: "Convolution12"
  bottom: "Convolution14"
  top: "Eltwise6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu13"
  type: "PENLU"
  bottom: "Eltwise6"
  top: "Eltwise6"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution15"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution15"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm15"
  type: "BatchNorm"
  bottom: "Convolution15"
  top: "Convolution15"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale15"
  type: "Scale"
  bottom: "Convolution15"
  top: "Convolution15"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu14"
  type: "PENLU"
  bottom: "Convolution15"
  top: "Convolution15"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution16"
  type: "Convolution"
  bottom: "Convolution15"
  top: "Convolution16"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm16"
  type: "BatchNorm"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale16"
  type: "Scale"
  bottom: "Convolution16"
  top: "Convolution16"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise7"
  type: "Eltwise"
  bottom: "Eltwise6"
  bottom: "Convolution16"
  top: "Eltwise7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu15"
  type: "PENLU"
  bottom: "Eltwise7"
  top: "Eltwise7"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution17"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution17"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm17"
  type: "BatchNorm"
  bottom: "Convolution17"
  top: "Convolution17"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale17"
  type: "Scale"
  bottom: "Convolution17"
  top: "Convolution17"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu16"
  type: "PENLU"
  bottom: "Convolution17"
  top: "Convolution17"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution18"
  type: "Convolution"
  bottom: "Convolution17"
  top: "Convolution18"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm18"
  type: "BatchNorm"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale18"
  type: "Scale"
  bottom: "Convolution18"
  top: "Convolution18"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise8"
  type: "Eltwise"
  bottom: "Eltwise7"
  bottom: "Convolution18"
  top: "Eltwise8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu17"
  type: "PENLU"
  bottom: "Eltwise8"
  top: "Eltwise8"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution19"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution19"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm19"
  type: "BatchNorm"
  bottom: "Convolution19"
  top: "Convolution19"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale19"
  type: "Scale"
  bottom: "Convolution19"
  top: "Convolution19"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu18"
  type: "PENLU"
  bottom: "Convolution19"
  top: "Convolution19"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution20"
  type: "Convolution"
  bottom: "Convolution19"
  top: "Convolution20"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm20"
  type: "BatchNorm"
  bottom: "Convolution20"
  top: "Convolution20"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale20"
  type: "Scale"
  bottom: "Convolution20"
  top: "Convolution20"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise9"
  type: "Eltwise"
  bottom: "Eltwise8"
  bottom: "Convolution20"
  top: "Eltwise9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu19"
  type: "PENLU"
  bottom: "Eltwise9"
  top: "Eltwise9"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution21"
  type: "Convolution"
  bottom: "Eltwise9"
  top: "Convolution21"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm21"
  type: "BatchNorm"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale21"
  type: "Scale"
  bottom: "Convolution21"
  top: "Convolution21"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu20"
  type: "PENLU"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution22"
  type: "Convolution"
  bottom: "Convolution21"
  top: "Convolution22"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm22"
  type: "BatchNorm"
  bottom: "Convolution22"
  top: "Convolution22"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale22"
  type: "Scale"
  bottom: "Convolution22"
  top: "Convolution22"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise10"
  type: "Eltwise"
  bottom: "Eltwise9"
  bottom: "Convolution22"
  top: "Eltwise10"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu21"
  type: "PENLU"
  bottom: "Eltwise10"
  top: "Eltwise10"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution23"
  type: "Convolution"
  bottom: "Eltwise10"
  top: "Convolution23"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.17677669
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm23"
  type: "BatchNorm"
  bottom: "Convolution23"
  top: "Convolution23"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale23"
  type: "Scale"
  bottom: "Convolution23"
  top: "Convolution23"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution24"
  type: "Convolution"
  bottom: "Eltwise10"
  top: "Convolution24"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm24"
  type: "BatchNorm"
  bottom: "Convolution24"
  top: "Convolution24"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale24"
  type: "Scale"
  bottom: "Convolution24"
  top: "Convolution24"
  scale_param {
    bias
I1007 15:08:43.328654  4982 layer_factory.hpp:77] Creating layer Data1
I1007 15:08:43.328748  4982 db_lmdb.cpp:35] Opened lmdb /home/x306/caffe/xn/PENLU/data/cifar10/cifar10_train_lmdb
I1007 15:08:43.328773  4982 net.cpp:84] Creating Layer Data1
I1007 15:08:43.328780  4982 net.cpp:380] Data1 -> Data1
I1007 15:08:43.328804  4982 net.cpp:380] Data1 -> Data2
I1007 15:08:43.328817  4982 data_transformer.cpp:25] Loading mean file from: /home/x306/caffe/xn/PENLU/data/cifar10/mean.binaryproto
I1007 15:08:43.330354  4982 data_layer.cpp:45] output data size: 100,3,28,28
I1007 15:08:43.332696  4982 net.cpp:122] Setting up Data1
I1007 15:08:43.332710  4982 net.cpp:129] Top shape: 100 3 28 28 (235200)
I1007 15:08:43.332713  4982 net.cpp:129] Top shape: 100 (100)
I1007 15:08:43.332716  4982 net.cpp:137] Memory required for data: 941200
I1007 15:08:43.332721  4982 layer_factory.hpp:77] Creating layer Convolution1
I1007 15:08:43.332741  4982 net.cpp:84] Creating Layer Convolution1
I1007 15:08:43.332746  4982 net.cpp:406] Convolution1 <- Data1
I1007 15:08:43.332754  4982 net.cpp:380] Convolution1 -> Convolution1
I1007 15:08:43.478391  4982 net.cpp:122] Setting up Convolution1
I1007 15:08:43.478416  4982 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 15:08:43.478421  4982 net.cpp:137] Memory required for data: 5958800
I1007 15:08:43.478440  4982 layer_factory.hpp:77] Creating layer BatchNorm1
I1007 15:08:43.478471  4982 net.cpp:84] Creating Layer BatchNorm1
I1007 15:08:43.478495  4982 net.cpp:406] BatchNorm1 <- Convolution1
I1007 15:08:43.478513  4982 net.cpp:367] BatchNorm1 -> Convolution1 (in-place)
I1007 15:08:43.478662  4982 net.cpp:122] Setting up BatchNorm1
I1007 15:08:43.478668  4982 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 15:08:43.478673  4982 net.cpp:137] Memory required for data: 10976400
I1007 15:08:43.478685  4982 layer_factory.hpp:77] Creating layer Scale1
I1007 15:08:43.478706  4982 net.cpp:84] Creating Layer Scale1
I1007 15:08:43.478711  4982 net.cpp:406] Scale1 <- Convolution1
I1007 15:08:43.478718  4982 net.cpp:367] Scale1 -> Convolution1 (in-place)
I1007 15:08:43.478765  4982 layer_factory.hpp:77] Creating layer Scale1
I1007 15:08:43.478869  4982 net.cpp:122] Setting up Scale1
I1007 15:08:43.478876  4982 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 15:08:43.478881  4982 net.cpp:137] Memory required for data: 15994000
I1007 15:08:43.478889  4982 layer_factory.hpp:77] Creating layer penlu1
I1007 15:08:43.478912  4982 net.cpp:84] Creating Layer penlu1
I1007 15:08:43.478916  4982 net.cpp:406] penlu1 <- Convolution1
I1007 15:08:43.478932  4982 net.cpp:367] penlu1 -> Convolution1 (in-place)
I1007 15:08:43.479563  4982 net.cpp:122] Setting up penlu1
I1007 15:08:43.479574  4982 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 15:08:43.479578  4982 net.cpp:137] Memory required for data: 21011600
I1007 15:08:43.479600  4982 layer_factory.hpp:77] Creating layer Convolution1_penlu1_0_split
I1007 15:08:43.479609  4982 net.cpp:84] Creating Layer Convolution1_penlu1_0_split
I1007 15:08:43.479614  4982 net.cpp:406] Convolution1_penlu1_0_split <- Convolution1
I1007 15:08:43.479620  4982 net.cpp:380] Convolution1_penlu1_0_split -> Convolution1_penlu1_0_split_0
I1007 15:08:43.479640  4982 net.cpp:380] Convolution1_penlu1_0_split -> Convolution1_penlu1_0_split_1
I1007 15:08:43.479677  4982 net.cpp:122] Setting up Convolution1_penlu1_0_split
I1007 15:08:43.479686  4982 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 15:08:43.479702  4982 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 15:08:43.479707  4982 net.cpp:137] Memory required for data: 31046800
I1007 15:08:43.479720  4982 layer_factory.hpp:77] Creating layer Convolution2
I1007 15:08:43.479740  4982 net.cpp:84] Creating Layer Convolution2
I1007 15:08:43.479745  4982 net.cpp:406] Convolution2 <- Convolution1_penlu1_0_split_0
I1007 15:08:43.479761  4982 net.cpp:380] Convolution2 -> Convolution2
I1007 15:08:43.480643  4982 net.cpp:122] Setting up Convolution2
I1007 15:08:43.480654  4982 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 15:08:43.480659  4982 net.cpp:137] Memory required for data: 36064400
I1007 15:08:43.480677  4982 layer_factory.hpp:77] Creating layer BatchNorm2
I1007 15:08:43.480700  4982 net.cpp:84] Creating Layer BatchNorm2
I1007 15:08:43.480715  4982 net.cpp:406] BatchNorm2 <- Convolution2
I1007 15:08:43.480732  4982 net.cpp:367] BatchNorm2 -> Convolution2 (in-place)
I1007 15:08:43.480866  4982 net.cpp:122] Setting up BatchNorm2
I1007 15:08:43.480873  4982 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 15:08:43.480877  4982 net.cpp:137] Memory required for data: 41082000
I1007 15:08:43.480896  4982 layer_factory.hpp:77] Creating layer Scale2
I1007 15:08:43.480904  4982 net.cpp:84] Creating Layer Scale2
I1007 15:08:43.480909  4982 net.cpp:406] Scale2 <- Convolution2
I1007 15:08:43.480916  4982 net.cpp:367] Scale2 -> Convolution2 (in-place)
I1007 15:08:43.480948  4982 layer_factory.hpp:77] Creating layer Scale2
I1007 15:08:43.481055  4982 net.cpp:122] Setting up Scale2
I1007 15:08:43.481061  4982 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 15:08:43.481065  4982 net.cpp:137] Memory required for data: 46099600
I1007 15:08:43.481086  4982 layer_factory.hpp:77] Creating layer penlu2
I1007 15:08:43.481093  4982 net.cpp:84] Creating Layer penlu2
I1007 15:08:43.481099  4982 net.cpp:406] penlu2 <- Convolution2
I1007 15:08:43.481106  4982 net.cpp:367] penlu2 -> Convolution2 (in-place)
I1007 15:08:43.481215  4982 net.cpp:122] Setting up penlu2
I1007 15:08:43.481222  4982 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 15:08:43.481235  4982 net.cpp:137] Memory required for data: 51117200
I1007 15:08:43.481245  4982 layer_factory.hpp:77] Creating layer Convolution3
I1007 15:08:43.481256  4982 net.cpp:84] Creating Layer Convolution3
I1007 15:08:43.481261  4982 net.cpp:406] Convolution3 <- Convolution2
I1007 15:08:43.481268  4982 net.cpp:380] Convolution3 -> Convolution3
I1007 15:08:43.482120  4982 net.cpp:122] Setting up Convolution3
I1007 15:08:43.482131  4982 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 15:08:43.482136  4982 net.cpp:137] Memory required for data: 56134800
I1007 15:08:43.482144  4982 layer_factory.hpp:77] Creating layer BatchNorm3
I1007 15:08:43.482153  4982 net.cpp:84] Creating Layer BatchNorm3
I1007 15:08:43.482158  4982 net.cpp:406] BatchNorm3 <- Convolution3
I1007 15:08:43.482165  4982 net.cpp:367] BatchNorm3 -> Convolution3 (in-place)
I1007 15:08:43.482288  4982 net.cpp:122] Setting up BatchNorm3
I1007 15:08:43.482295  4982 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 15:08:43.482300  4982 net.cpp:137] Memory required for data: 61152400
I1007 15:08:43.482311  4982 layer_factory.hpp:77] Creating layer Scale3
I1007 15:08:43.482317  4982 net.cpp:84] Creating Layer Scale3
I1007 15:08:43.482322  4982 net.cpp:406] Scale3 <- Convolution3
I1007 15:08:43.482328  4982 net.cpp:367] Scale3 -> Convolution3 (in-place)
I1007 15:08:43.482359  4982 layer_factory.hpp:77] Creating layer Scale3
I1007 15:08:43.482434  4982 net.cpp:122] Setting up Scale3
I1007 15:08:43.482441  4982 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 15:08:43.482445  4982 net.cpp:137] Memory required for data: 66170000
I1007 15:08:43.482455  4982 layer_factory.hpp:77] Creating layer Eltwise1
I1007 15:08:43.482462  4982 net.cpp:84] Creating Layer Eltwise1
I1007 15:08:43.482467  4982 net.cpp:406] Eltwise1 <- Convolution1_penlu1_0_split_1
I1007 15:08:43.482472  4982 net.cpp:406] Eltwise1 <- Convolution3
I1007 15:08:43.482480  4982 net.cpp:380] Eltwise1 -> Eltwise1
I1007 15:08:43.482501  4982 net.cpp:122] Setting up Eltwise1
I1007 15:08:43.482508  4982 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 15:08:43.482512  4982 net.cpp:137] Memory required for data: 71187600
I1007 15:08:43.482518  4982 layer_factory.hpp:77] Creating layer penlu3
I1007 15:08:43.482527  4982 net.cpp:84] Creating Layer penlu3
I1007 15:08:43.482532  4982 net.cpp:406] penlu3 <- Eltwise1
I1007 15:08:43.482538  4982 net.cpp:367] penlu3 -> Eltwise1 (in-place)
I1007 15:08:43.482640  4982 net.cpp:122] Setting up penlu3
I1007 15:08:43.482647  4982 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 15:08:43.482651  4982 net.cpp:137] Memory required for data: 76205200
I1007 15:08:43.482659  4982 layer_factory.hpp:77] Creating layer Eltwise1_penlu3_0_split
I1007 15:08:43.482666  4982 net.cpp:84] Creating Layer Eltwise1_penlu3_0_split
I1007 15:08:43.482671  4982 net.cpp:406] Eltwise1_penlu3_0_split <- Eltwise1
I1007 15:08:43.482677  4982 net.cpp:380] Eltwise1_penlu3_0_split -> Eltwise1_penlu3_0_split_0
I1007 15:08:43.482686  4982 net.cpp:380] Eltwise1_penlu3_0_split -> Eltwise1_penlu3_0_split_1
I1007 15:08:43.482712  4982 net.cpp:122] Setting up Eltwise1_penlu3_0_split
I1007 15:08:43.482719  4982 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 15:08:43.482727  4982 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 15:08:43.482731  4982 net.cpp:137] Memory required for data: 86240400
I1007 15:08:43.482736  4982 layer_factory.hpp:77] Creating layer Convolution4
I1007 15:08:43.482748  4982 net.cpp:84] Creating Layer Convolution4
I1007 15:08:43.482751  4982 net.cpp:406] Convolution4 <- Eltwise1_penlu3_0_split_0
I1007 15:08:43.482758  4982 net.cpp:380] Convolution4 -> Convolution4
I1007 15:08:43.483603  4982 net.cpp:122] Setting up Convolution4
I1007 15:08:43.483614  4982 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 15:08:43.483619  4982 net.cpp:137] Memory required for data: 91258000
I1007 15:08:43.483628  4982 layer_factory.hpp:77] Creating layer BatchNorm4
I1007 15:08:43.483636  4982 net.cpp:84] Creating Layer BatchNorm4
I1007 15:08:43.483649  4982 net.cpp:406] BatchNorm4 <- Convolution4
I1007 15:08:43.483659  4982 net.cpp:367] BatchNorm4 -> Convolution4 (in-place)
I1007 15:08:43.483780  4982 net.cpp:122] Setting up BatchNorm4
I1007 15:08:43.483788  4982 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 15:08:43.483793  4982 net.cpp:137] Memory required for data: 96275600
I1007 15:08:43.483804  4982 layer_factory.hpp:77] Creating layer Scale4
I1007 15:08:43.483810  4982 net.cpp:84] Creating Layer Scale4
I1007 15:08:43.483815  4982 net.cpp:406] Scale4 <- Convolution4
I1007 15:08:43.483822  4982 net.cpp:367] Scale4 -> Convolution4 (in-place)
I1007 15:08:43.483852  4982 layer_factory.hpp:77] Creating layer Scale4
I1007 15:08:43.483928  4982 net.cpp:122] Setting up Scale4
I1007 15:08:43.483935  4982 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 15:08:43.483939  4982 net.cpp:137] Memory required for data: 101293200
I1007 15:08:43.483947  4982 layer_factory.hpp:77] Creating layer penlu4
I1007 15:08:43.483955  4982 net.cpp:84] Creating Layer penlu4
I1007 15:08:43.483960  4982 net.cpp:406] penlu4 <- Convolution4
I1007 15:08:43.483966  4982 net.cpp:367] penlu4 -> Convolution4 (in-place)
I1007 15:08:43.484067  4982 net.cpp:122] Setting up penlu4
I1007 15:08:43.484074  4982 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 15:08:43.484078  4982 net.cpp:137] Memory required for data: 106310800
I1007 15:08:43.484087  4982 layer_factory.hpp:77] Creating layer Convolution5
I1007 15:08:43.484097  4982 net.cpp:84] Creating Layer Convolution5
I1007 15:08:43.484102  4982 net.cpp:406] Convolution5 <- Convolution4
I1007 15:08:43.484108  4982 net.cpp:380] Convolution5 -> Convolution5
I1007 15:08:43.484953  4982 net.cpp:122] Setting up Convolution5
I1007 15:08:43.484964  4982 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 15:08:43.484969  4982 net.cpp:137] Memory required for data: 111328400
I1007 15:08:43.484977  4982 layer_factory.hpp:77] Creating layer BatchNorm5
I1007 15:08:43.484987  4982 net.cpp:84] Creating Layer BatchNorm5
I1007 15:08:43.484992  4982 net.cpp:406] BatchNorm5 <- Convolution5
I1007 15:08:43.484998  4982 net.cpp:367] BatchNorm5 -> Convolution5 (in-place)
I1007 15:08:43.485123  4982 net.cpp:122] Setting up BatchNorm5
I1007 15:08:43.485131  4982 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 15:08:43.485136  4982 net.cpp:137] Memory required for data: 116346000
I1007 15:08:43.485146  4982 layer_factory.hpp:77] Creating layer Scale5
I1007 15:08:43.485152  4982 net.cpp:84] Creating Layer Scale5
I1007 15:08:43.485157  4982 net.cpp:406] Scale5 <- Convolution5
I1007 15:08:43.485163  4982 net.cpp:367] Scale5 -> Convolution5 (in-place)
I1007 15:08:43.485194  4982 layer_factory.hpp:77] Creating layer Scale5
I1007 15:08:43.485271  4982 net.cpp:122] Setting up Scale5
I1007 15:08:43.485280  4982 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 15:08:43.485283  4982 net.cpp:137] Memory required for data: 121363600
I1007 15:08:43.485291  4982 layer_factory.hpp:77] Creating layer Eltwise2
I1007 15:08:43.485298  4982 net.cpp:84] Creating Layer Eltwise2
I1007 15:08:43.485304  4982 net.cpp:406] Eltwise2 <- Eltwise1_penlu3_0_split_1
I1007 15:08:43.485309  4982 net.cpp:406] Eltwise2 <- Convolution5
I1007 15:08:43.485316  4982 net.cpp:380] Eltwise2 -> Eltwise2
I1007 15:08:43.485337  4982 net.cpp:122] Setting up Eltwise2
I1007 15:08:43.485343  4982 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 15:08:43.485347  4982 net.cpp:137] Memory required for data: 126381200
I1007 15:08:43.485352  4982 layer_factory.hpp:77] Creating layer penlu5
I1007 15:08:43.485361  4982 net.cpp:84] Creating Layer penlu5
I1007 15:08:43.485366  4982 net.cpp:406] penlu5 <- Eltwise2
I1007 15:08:43.485373  4982 net.cpp:367] penlu5 -> Eltwise2 (in-place)
I1007 15:08:43.485478  4982 net.cpp:122] Setting up penlu5
I1007 15:08:43.485486  4982 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 15:08:43.485489  4982 net.cpp:137] Memory required for data: 131398800
I1007 15:08:43.485498  4982 layer_factory.hpp:77] Creating layer Eltwise2_penlu5_0_split
I1007 15:08:43.485512  4982 net.cpp:84] Creating Layer Eltwise2_penlu5_0_split
I1007 15:08:43.485517  4982 net.cpp:406] Eltwise2_penlu5_0_split <- Eltwise2
I1007 15:08:43.485524  4982 net.cpp:380] Eltwise2_penlu5_0_split -> Eltwise2_penlu5_0_split_0
I1007 15:08:43.485532  4982 net.cpp:380] Eltwise2_penlu5_0_split -> Eltwise2_penlu5_0_split_1
I1007 15:08:43.485560  4982 net.cpp:122] Setting up Eltwise2_penlu5_0_split
I1007 15:08:43.485566  4982 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 15:08:43.485572  4982 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 15:08:43.485577  4982 net.cpp:137] Memory required for data: 141434000
I1007 15:08:43.485581  4982 layer_factory.hpp:77] Creating layer Convolution6
I1007 15:08:43.485592  4982 net.cpp:84] Creating Layer Convolution6
I1007 15:08:43.485596  4982 net.cpp:406] Convolution6 <- Eltwise2_penlu5_0_split_0
I1007 15:08:43.485604  4982 net.cpp:380] Convolution6 -> Convolution6
I1007 15:08:43.486455  4982 net.cpp:122] Setting up Convolution6
I1007 15:08:43.486466  4982 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 15:08:43.486471  4982 net.cpp:137] Memory required for data: 146451600
I1007 15:08:43.486479  4982 layer_factory.hpp:77] Creating layer BatchNorm6
I1007 15:08:43.486488  4982 net.cpp:84] Creating Layer BatchNorm6
I1007 15:08:43.486495  4982 net.cpp:406] BatchNorm6 <- Convolution6
I1007 15:08:43.486501  4982 net.cpp:367] BatchNorm6 -> Convolution6 (in-place)
I1007 15:08:43.486629  4982 net.cpp:122] Setting up BatchNorm6
I1007 15:08:43.486636  4982 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 15:08:43.486640  4982 net.cpp:137] Memory required for data: 151469200
I1007 15:08:43.486651  4982 layer_factory.hpp:77] Creating layer Scale6
I1007 15:08:43.486659  4982 net.cpp:84] Creating Layer Scale6
I1007 15:08:43.486663  4982 net.cpp:406] Scale6 <- Convolution6
I1007 15:08:43.486670  4982 net.cpp:367] Scale6 -> Convolution6 (in-place)
I1007 15:08:43.486701  4982 layer_factory.hpp:77] Creating layer Scale6
I1007 15:08:43.486778  4982 net.cpp:122] Setting up Scale6
I1007 15:08:43.486785  4982 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 15:08:43.486789  4982 net.cpp:137] Memory required for data: 156486800
I1007 15:08:43.486796  4982 layer_factory.hpp:77] Creating layer penlu6
I1007 15:08:43.486804  4982 net.cpp:84] Creating Layer penlu6
I1007 15:08:43.486809  4982 net.cpp:406] penlu6 <- Convolution6
I1007 15:08:43.486816  4982 net.cpp:367] penlu6 -> Convolution6 (in-place)
I1007 15:08:43.486922  4982 net.cpp:122] Setting up penlu6
I1007 15:08:43.486928  4982 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 15:08:43.486933  4982 net.cpp:137] Memory required for data: 161504400
I1007 15:08:43.486941  4982 layer_factory.hpp:77] Creating layer Convolution7
I1007 15:08:43.486951  4982 net.cpp:84] Creating Layer Convolution7
I1007 15:08:43.486955  4982 net.cpp:406] Convolution7 <- Convolution6
I1007 15:08:43.486963  4982 net.cpp:380] Convolution7 -> Convolution7
I1007 15:08:43.487498  4982 net.cpp:122] Setting up Convolution7
I1007 15:08:43.487509  4982 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 15:08:43.487512  4982 net.cpp:137] Memory required for data: 166522000
I1007 15:08:43.487520  4982 layer_factory.hpp:77] Creating layer BatchNorm7
I1007 15:08:43.487529  4982 net.cpp:84] Creating Layer BatchNorm7
I1007 15:08:43.487534  4982 net.cpp:406] BatchNorm7 <- Convolution7
I1007 15:08:43.487540  4982 net.cpp:367] BatchNorm7 -> Convolution7 (in-place)
I1007 15:08:43.487668  4982 net.cpp:122] Setting up BatchNorm7
I1007 15:08:43.487675  4982 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 15:08:43.487679  4982 net.cpp:137] Memory required for data: 171539600
I1007 15:08:43.487692  4982 layer_factory.hpp:77] Creating layer Scale7
I1007 15:08:43.487701  4982 net.cpp:84] Creating Layer Scale7
I1007 15:08:43.487706  4982 net.cpp:406] Scale7 <- Convolution7
I1007 15:08:43.487712  4982 net.cpp:367] Scale7 -> Convolution7 (in-place)
I1007 15:08:43.487743  4982 layer_factory.hpp:77] Creating layer Scale7
I1007 15:08:43.487823  4982 net.cpp:122] Setting up Scale7
I1007 15:08:43.487838  4982 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 15:08:43.487843  4982 net.cpp:137] Memory required for data: 176557200
I1007 15:08:43.487851  4982 layer_factory.hpp:77] Creating layer Eltwise3
I1007 15:08:43.487859  4982 net.cpp:84] Creating Layer Eltwise3
I1007 15:08:43.487864  4982 net.cpp:406] Eltwise3 <- Eltwise2_penlu5_0_split_1
I1007 15:08:43.487869  4982 net.cpp:406] Eltwise3 <- Convolution7
I1007 15:08:43.487875  4982 net.cpp:380] Eltwise3 -> Eltwise3
I1007 15:08:43.487897  4982 net.cpp:122] Setting up Eltwise3
I1007 15:08:43.487903  4982 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 15:08:43.487908  4982 net.cpp:137] Memory required for data: 181574800
I1007 15:08:43.487912  4982 layer_factory.hpp:77] Creating layer penlu7
I1007 15:08:43.487920  4982 net.cpp:84] Creating Layer penlu7
I1007 15:08:43.487926  4982 net.cpp:406] penlu7 <- Eltwise3
I1007 15:08:43.487932  4982 net.cpp:367] penlu7 -> Eltwise3 (in-place)
I1007 15:08:43.488037  4982 net.cpp:122] Setting up penlu7
I1007 15:08:43.488044  4982 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 15:08:43.488049  4982 net.cpp:137] Memory required for data: 186592400
I1007 15:08:43.488056  4982 layer_factory.hpp:77] Creating layer Eltwise3_penlu7_0_split
I1007 15:08:43.488064  4982 net.cpp:84] Creating Layer Eltwise3_penlu7_0_split
I1007 15:08:43.488068  4982 net.cpp:406] Eltwise3_penlu7_0_split <- Eltwise3
I1007 15:08:43.488075  4982 net.cpp:380] Eltwise3_penlu7_0_split -> Eltwise3_penlu7_0_split_0
I1007 15:08:43.488082  4982 net.cpp:380] Eltwise3_penlu7_0_split -> Eltwise3_penlu7_0_split_1
I1007 15:08:43.488109  4982 net.cpp:122] Setting up Eltwise3_penlu7_0_split
I1007 15:08:43.488116  4982 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 15:08:43.488121  4982 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 15:08:43.488126  4982 net.cpp:137] Memory required for data: 196627600
I1007 15:08:43.488129  4982 layer_factory.hpp:77] Creating layer Convolution8
I1007 15:08:43.488140  4982 net.cpp:84] Creating Layer Convolution8
I1007 15:08:43.488144  4982 net.cpp:406] Convolution8 <- Eltwise3_penlu7_0_split_0
I1007 15:08:43.488152  4982 net.cpp:380] Convolution8 -> Convolution8
I1007 15:08:43.488993  4982 net.cpp:122] Setting up Convolution8
I1007 15:08:43.489004  4982 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 15:08:43.489009  4982 net.cpp:137] Memory required for data: 201645200
I1007 15:08:43.489017  4982 layer_factory.hpp:77] Creating layer BatchNorm8
I1007 15:08:43.489027  4982 net.cpp:84] Creating Layer BatchNorm8
I1007 15:08:43.489032  4982 net.cpp:406] BatchNorm8 <- Convolution8
I1007 15:08:43.489038  4982 net.cpp:367] BatchNorm8 -> Convolution8 (in-place)
I1007 15:08:43.489176  4982 net.cpp:122] Setting up BatchNorm8
I1007 15:08:43.489184  4982 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 15:08:43.489188  4982 net.cpp:137] Memory required for data: 206662800
I1007 15:08:43.489197  4982 layer_factory.hpp:77] Creating layer Scale8
I1007 15:08:43.489204  4982 net.cpp:84] Creating Layer Scale8
I1007 15:08:43.489210  4982 net.cpp:406] Scale8 <- Convolution8
I1007 15:08:43.489217  4982 net.cpp:367] Scale8 -> Convolution8 (in-place)
I1007 15:08:43.489248  4982 layer_factory.hpp:77] Creating layer Scale8
I1007 15:08:43.489328  4982 net.cpp:122] Setting up Scale8
I1007 15:08:43.489336  4982 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 15:08:43.489341  4982 net.cpp:137] Memory required for data: 211680400
I1007 15:08:43.489348  4982 layer_factory.hpp:77] Creating layer penlu8
I1007 15:08:43.489356  4982 net.cpp:84] Creating Layer penlu8
I1007 15:08:43.489362  4982 net.cpp:406] penlu8 <- Convolution8
I1007 15:08:43.489368  4982 net.cpp:367] penlu8 -> Convolution8 (in-place)
I1007 15:08:43.489476  4982 net.cpp:122] Setting up penlu8
I1007 15:08:43.489483  4982 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 15:08:43.489488  4982 net.cpp:137] Memory required for data: 216698000
I1007 15:08:43.489496  4982 layer_factory.hpp:77] Creating layer Convolution9
I1007 15:08:43.489512  4982 net.cpp:84] Creating Layer Convolution9
I1007 15:08:43.489519  4982 net.cpp:406] Convolution9 <- Convolution8
I1007 15:08:43.489527  4982 net.cpp:380] Convolution9 -> Convolution9
I1007 15:08:43.490491  4982 net.cpp:122] Setting up Convolution9
I1007 15:08:43.490504  4982 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 15:08:43.490509  4982 net.cpp:137] Memory required for data: 221715600
I1007 15:08:43.490526  4982 layer_factory.hpp:77] Creating layer BatchNorm9
I1007 15:08:43.490535  4982 net.cpp:84] Creating Layer BatchNorm9
I1007 15:08:43.490550  4982 net.cpp:406] BatchNorm9 <- Convolution9
I1007 15:08:43.490567  4982 net.cpp:367] BatchNorm9 -> Convolution9 (in-place)
I1007 15:08:43.490701  4982 net.cpp:122] Setting up BatchNorm9
I1007 15:08:43.490710  4982 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 15:08:43.490713  4982 net.cpp:137] Memory required for data: 226733200
I1007 15:08:43.490722  4982 layer_factory.hpp:77] Creating layer Scale9
I1007 15:08:43.490731  4982 net.cpp:84] Creating Layer Scale9
I1007 15:08:43.490736  4982 net.cpp:406] Scale9 <- Convolution9
I1007 15:08:43.490743  4982 net.cpp:367] Scale9 -> Convolution9 (in-place)
I1007 15:08:43.490777  4982 layer_factory.hpp:77] Creating layer Scale9
I1007 15:08:43.490861  4982 net.cpp:122] Setting up Scale9
I1007 15:08:43.490869  4982 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 15:08:43.490873  4982 net.cpp:137] Memory required for data: 231750800
I1007 15:08:43.490880  4982 layer_factory.hpp:77] Creating layer Eltwise4
I1007 15:08:43.490887  4982 net.cpp:84] Creating Layer Eltwise4
I1007 15:08:43.490892  4982 net.cpp:406] Eltwise4 <- Eltwise3_penlu7_0_split_1
I1007 15:08:43.490898  4982 net.cpp:406] Eltwise4 <- Convolution9
I1007 15:08:43.490906  4982 net.cpp:380] Eltwise4 -> Eltwise4
I1007 15:08:43.490926  4982 net.cpp:122] Setting up Eltwise4
I1007 15:08:43.490933  4982 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 15:08:43.490937  4982 net.cpp:137] Memory required for data: 236768400
I1007 15:08:43.490943  4982 layer_factory.hpp:77] Creating layer penlu9
I1007 15:08:43.490952  4982 net.cpp:84] Creating Layer penlu9
I1007 15:08:43.490957  4982 net.cpp:406] penlu9 <- Eltwise4
I1007 15:08:43.490964  4982 net.cpp:367] penlu9 -> Eltwise4 (in-place)
I1007 15:08:43.491075  4982 net.cpp:122] Setting up penlu9
I1007 15:08:43.491081  4982 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 15:08:43.491086  4982 net.cpp:137] Memory required for data: 241786000
I1007 15:08:43.491093  4982 layer_factory.hpp:77] Creating layer Eltwise4_penlu9_0_split
I1007 15:08:43.491101  4982 net.cpp:84] Creating Layer Eltwise4_penlu9_0_split
I1007 15:08:43.491106  4982 net.cpp:406] Eltwise4_penlu9_0_split <- Eltwise4
I1007 15:08:43.491112  4982 net.cpp:380] Eltwise4_penlu9_0_split -> Eltwise4_penlu9_0_split_0
I1007 15:08:43.491120  4982 net.cpp:380] Eltwise4_penlu9_0_split -> Eltwise4_penlu9_0_split_1
I1007 15:08:43.491148  4982 net.cpp:122] Setting up Eltwise4_penlu9_0_split
I1007 15:08:43.491155  4982 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 15:08:43.491161  4982 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 15:08:43.491171  4982 net.cpp:137] Memory required for data: 251821200
I1007 15:08:43.491176  4982 layer_factory.hpp:77] Creating layer Convolution10
I1007 15:08:43.491186  4982 net.cpp:84] Creating Layer Convolution10
I1007 15:08:43.491190  4982 net.cpp:406] Convolution10 <- Eltwise4_penlu9_0_split_0
I1007 15:08:43.491197  4982 net.cpp:380] Convolution10 -> Convolution10
I1007 15:08:43.492267  4982 net.cpp:122] Setting up Convolution10
I1007 15:08:43.492282  4982 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 15:08:43.492287  4982 net.cpp:137] Memory required for data: 256838800
I1007 15:08:43.492295  4982 layer_factory.hpp:77] Creating layer BatchNorm10
I1007 15:08:43.492305  4982 net.cpp:84] Creating Layer BatchNorm10
I1007 15:08:43.492310  4982 net.cpp:406] BatchNorm10 <- Convolution10
I1007 15:08:43.492316  4982 net.cpp:367] BatchNorm10 -> Convolution10 (in-place)
I1007 15:08:43.492492  4982 net.cpp:122] Setting up BatchNorm10
I1007 15:08:43.492509  4982 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 15:08:43.492513  4982 net.cpp:137] Memory required for data: 261856400
I1007 15:08:43.492519  4982 layer_factory.hpp:77] Creating layer Scale10
I1007 15:08:43.492524  4982 net.cpp:84] Creating Layer Scale10
I1007 15:08:43.492527  4982 net.cpp:406] Scale10 <- Convolution10
I1007 15:08:43.492532  4982 net.cpp:367] Scale10 -> Convolution10 (in-place)
I1007 15:08:43.492559  4982 layer_factory.hpp:77] Creating layer Scale10
I1007 15:08:43.492635  4982 net.cpp:122] Setting up Scale10
I1007 15:08:43.492640  4982 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 15:08:43.492642  4982 net.cpp:137] Memory required for data: 266874000
I1007 15:08:43.492646  4982 layer_factory.hpp:77] Creating layer penlu10
I1007 15:08:43.492652  4982 net.cpp:84] Creating Layer penlu10
I1007 15:08:43.492655  4982 net.cpp:406] penlu10 <- Convolution10
I1007 15:08:43.492660  4982 net.cpp:367] penlu10 -> Convolution10 (in-place)
I1007 15:08:43.492763  4982 net.cpp:122] Setting up penlu10
I1007 15:08:43.492769  4982 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 15:08:43.492771  4982 net.cpp:137] Memory required for data: 271891600
I1007 15:08:43.492775  4982 layer_factory.hpp:77] Creating layer Convolution11
I1007 15:08:43.492782  4982 net.cpp:84] Creating Layer Convolution11
I1007 15:08:43.492786  4982 net.cpp:406] Convolution11 <- Convolution10
I1007 15:08:43.492790  4982 net.cpp:380] Convolution11 -> Convolution11
I1007 15:08:43.493661  4982 net.cpp:122] Setting up Convolution11
I1007 15:08:43.493672  4982 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 15:08:43.493675  4982 net.cpp:137] Memory required for data: 276909200
I1007 15:08:43.493680  4982 layer_factory.hpp:77] Creating layer BatchNorm11
I1007 15:08:43.493685  4982 net.cpp:84] Creating Layer BatchNorm11
I1007 15:08:43.493690  4982 net.cpp:406] BatchNorm11 <- Convolution11
I1007 15:08:43.493693  4982 net.cpp:367] BatchNorm11 -> Convolution11 (in-place)
I1007 15:08:43.493819  4982 net.cpp:122] Setting up BatchNorm11
I1007 15:08:43.493824  4982 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 15:08:43.493827  4982 net.cpp:137] Memory required for data: 281926800
I1007 15:08:43.493832  4982 layer_factory.hpp:77] Creating layer Scale11
I1007 15:08:43.493837  4982 net.cpp:84] Creating Layer Scale11
I1007 15:08:43.493840  4982 net.cpp:406] Scale11 <- Convolution11
I1007 15:08:43.493844  4982 net.cpp:367] Scale11 -> Convolution11 (in-place)
I1007 15:08:43.493868  4982 layer_factory.hpp:77] Creating layer Scale11
I1007 15:08:43.493942  4982 net.cpp:122] Setting up Scale11
I1007 15:08:43.493947  4982 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 15:08:43.493950  4982 net.cpp:137] Memory required for data: 286944400
I1007 15:08:43.493954  4982 layer_factory.hpp:77] Creating layer Eltwise5
I1007 15:08:43.493959  4982 net.cpp:84] Creating Layer Eltwise5
I1007 15:08:43.493963  4982 net.cpp:406] Eltwise5 <- Eltwise4_penlu9_0_split_1
I1007 15:08:43.493965  4982 net.cpp:406] Eltwise5 <- Convolution11
I1007 15:08:43.493969  4982 net.cpp:380] Eltwise5 -> Eltwise5
I1007 15:08:43.493985  4982 net.cpp:122] Setting up Eltwise5
I1007 15:08:43.493989  4982 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 15:08:43.493993  4982 net.cpp:137] Memory required for data: 291962000
I1007 15:08:43.493994  4982 layer_factory.hpp:77] Creating layer penlu11
I1007 15:08:43.493999  4982 net.cpp:84] Creating Layer penlu11
I1007 15:08:43.494002  4982 net.cpp:406] penlu11 <- Eltwise5
I1007 15:08:43.494006  4982 net.cpp:367] penlu11 -> Eltwise5 (in-place)
I1007 15:08:43.494112  4982 net.cpp:122] Setting up penlu11
I1007 15:08:43.494117  4982 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 15:08:43.494119  4982 net.cpp:137] Memory required for data: 296979600
I1007 15:08:43.494123  4982 layer_factory.hpp:77] Creating layer Eltwise5_penlu11_0_split
I1007 15:08:43.494127  4982 net.cpp:84] Creating Layer Eltwise5_penlu11_0_split
I1007 15:08:43.494130  4982 net.cpp:406] Eltwise5_penlu11_0_split <- Eltwise5
I1007 15:08:43.494141  4982 net.cpp:380] Eltwise5_penlu11_0_split -> Eltwise5_penlu11_0_split_0
I1007 15:08:43.494146  4982 net.cpp:380] Eltwise5_penlu11_0_split -> Eltwise5_penlu11_0_split_1
I1007 15:08:43.494170  4982 net.cpp:122] Setting up Eltwise5_penlu11_0_split
I1007 15:08:43.494175  4982 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 15:08:43.494179  4982 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 15:08:43.494180  4982 net.cpp:137] Memory required for data: 307014800
I1007 15:08:43.494184  4982 layer_factory.hpp:77] Creating layer Convolution12
I1007 15:08:43.494189  4982 net.cpp:84] Creating Layer Convolution12
I1007 15:08:43.494192  4982 net.cpp:406] Convolution12 <- Eltwise5_penlu11_0_split_0
I1007 15:08:43.494196  4982 net.cpp:380] Convolution12 -> Convolution12
I1007 15:08:43.495360  4982 net.cpp:122] Setting up Convolution12
I1007 15:08:43.495370  4982 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 15:08:43.495374  4982 net.cpp:137] Memory required for data: 309523600
I1007 15:08:43.495379  4982 layer_factory.hpp:77] Creating layer BatchNorm12
I1007 15:08:43.495384  4982 net.cpp:84] Creating Layer BatchNorm12
I1007 15:08:43.495388  4982 net.cpp:406] BatchNorm12 <- Convolution12
I1007 15:08:43.495393  4982 net.cpp:367] BatchNorm12 -> Convolution12 (in-place)
I1007 15:08:43.495523  4982 net.cpp:122] Setting up BatchNorm12
I1007 15:08:43.495528  4982 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 15:08:43.495532  4982 net.cpp:137] Memory required for data: 312032400
I1007 15:08:43.495537  4982 layer_factory.hpp:77] Creating layer Scale12
I1007 15:08:43.495542  4982 net.cpp:84] Creating Layer Scale12
I1007 15:08:43.495544  4982 net.cpp:406] Scale12 <- Convolution12
I1007 15:08:43.495548  4982 net.cpp:367] Scale12 -> Convolution12 (in-place)
I1007 15:08:43.495574  4982 layer_factory.hpp:77] Creating layer Scale12
I1007 15:08:43.495645  4982 net.cpp:122] Setting up Scale12
I1007 15:08:43.495649  4982 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 15:08:43.495652  4982 net.cpp:137] Memory required for data: 314541200
I1007 15:08:43.495656  4982 layer_factory.hpp:77] Creating layer Convolution13
I1007 15:08:43.495663  4982 net.cpp:84] Creating Layer Convolution13
I1007 15:08:43.495667  4982 net.cpp:406] Convolution13 <- Eltwise5_penlu11_0_split_1
I1007 15:08:43.495671  4982 net.cpp:380] Convolution13 -> Convolution13
I1007 15:08:43.496902  4982 net.cpp:122] Setting up Convolution13
I1007 15:08:43.496912  4982 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 15:08:43.496917  4982 net.cpp:137] Memory required for data: 317050000
I1007 15:08:43.496922  4982 layer_factory.hpp:77] Creating layer BatchNorm13
I1007 15:08:43.496927  4982 net.cpp:84] Creating Layer BatchNorm13
I1007 15:08:43.496930  4982 net.cpp:406] BatchNorm13 <- Convolution13
I1007 15:08:43.496934  4982 net.cpp:367] BatchNorm13 -> Convolution13 (in-place)
I1007 15:08:43.497061  4982 net.cpp:122] Setting up BatchNorm13
I1007 15:08:43.497067  4982 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 15:08:43.497071  4982 net.cpp:137] Memory required for data: 319558800
I1007 15:08:43.497076  4982 layer_factory.hpp:77] Creating layer Scale13
I1007 15:08:43.497079  4982 net.cpp:84] Creating Layer Scale13
I1007 15:08:43.497083  4982 net.cpp:406] Scale13 <- Convolution13
I1007 15:08:43.497087  4982 net.cpp:367] Scale13 -> Convolution13 (in-place)
I1007 15:08:43.497112  4982 layer_factory.hpp:77] Creating layer Scale13
I1007 15:08:43.497184  4982 net.cpp:122] Setting up Scale13
I1007 15:08:43.497189  4982 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 15:08:43.497191  4982 net.cpp:137] Memory required for data: 322067600
I1007 15:08:43.497195  4982 layer_factory.hpp:77] Creating layer penlu12
I1007 15:08:43.497201  4982 net.cpp:84] Creating Layer penlu12
I1007 15:08:43.497205  4982 net.cpp:406] penlu12 <- Convolution13
I1007 15:08:43.497208  4982 net.cpp:367] penlu12 -> Convolution13 (in-place)
I1007 15:08:43.497309  4982 net.cpp:122] Setting up penlu12
I1007 15:08:43.497314  4982 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 15:08:43.497323  4982 net.cpp:137] Memory required for data: 324576400
I1007 15:08:43.497328  4982 layer_factory.hpp:77] Creating layer Convolution14
I1007 15:08:43.497335  4982 net.cpp:84] Creating Layer Convolution14
I1007 15:08:43.497339  4982 net.cpp:406] Convolution14 <- Convolution13
I1007 15:08:43.497344  4982 net.cpp:380] Convolution14 -> Convolution14
I1007 15:08:43.498368  4982 net.cpp:122] Setting up Convolution14
I1007 15:08:43.498379  4982 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 15:08:43.498383  4982 net.cpp:137] Memory required for data: 327085200
I1007 15:08:43.498395  4982 layer_factory.hpp:77] Creating layer BatchNorm14
I1007 15:08:43.498404  4982 net.cpp:84] Creating Layer BatchNorm14
I1007 15:08:43.498407  4982 net.cpp:406] BatchNorm14 <- Convolution14
I1007 15:08:43.498411  4982 net.cpp:367] BatchNorm14 -> Convolution14 (in-place)
I1007 15:08:43.498536  4982 net.cpp:122] Setting up BatchNorm14
I1007 15:08:43.498541  4982 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 15:08:43.498544  4982 net.cpp:137] Memory required for data: 329594000
I1007 15:08:43.498549  4982 layer_factory.hpp:77] Creating layer Scale14
I1007 15:08:43.498554  4982 net.cpp:84] Creating Layer Scale14
I1007 15:08:43.498558  4982 net.cpp:406] Scale14 <- Convolution14
I1007 15:08:43.498561  4982 net.cpp:367] Scale14 -> Convolution14 (in-place)
I1007 15:08:43.498586  4982 layer_factory.hpp:77] Creating layer Scale14
I1007 15:08:43.498657  4982 net.cpp:122] Setting up Scale14
I1007 15:08:43.498662  4982 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 15:08:43.498666  4982 net.cpp:137] Memory required for data: 332102800
I1007 15:08:43.498669  4982 layer_factory.hpp:77] Creating layer Eltwise6
I1007 15:08:43.498674  4982 net.cpp:84] Creating Layer Eltwise6
I1007 15:08:43.498677  4982 net.cpp:406] Eltwise6 <- Convolution12
I1007 15:08:43.498680  4982 net.cpp:406] Eltwise6 <- Convolution14
I1007 15:08:43.498683  4982 net.cpp:380] Eltwise6 -> Eltwise6
I1007 15:08:43.498698  4982 net.cpp:122] Setting up Eltwise6
I1007 15:08:43.498703  4982 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 15:08:43.498704  4982 net.cpp:137] Memory required for data: 334611600
I1007 15:08:43.498706  4982 layer_factory.hpp:77] Creating layer penlu13
I1007 15:08:43.498711  4982 net.cpp:84] Creating Layer penlu13
I1007 15:08:43.498713  4982 net.cpp:406] penlu13 <- Eltwise6
I1007 15:08:43.498718  4982 net.cpp:367] penlu13 -> Eltwise6 (in-place)
I1007 15:08:43.498817  4982 net.cpp:122] Setting up penlu13
I1007 15:08:43.498821  4982 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 15:08:43.498823  4982 net.cpp:137] Memory required for data: 337120400
I1007 15:08:43.498828  4982 layer_factory.hpp:77] Creating layer Eltwise6_penlu13_0_split
I1007 15:08:43.498831  4982 net.cpp:84] Creating Layer Eltwise6_penlu13_0_split
I1007 15:08:43.498833  4982 net.cpp:406] Eltwise6_penlu13_0_split <- Eltwise6
I1007 15:08:43.498837  4982 net.cpp:380] Eltwise6_penlu13_0_split -> Eltwise6_penlu13_0_split_0
I1007 15:08:43.498842  4982 net.cpp:380] Eltwise6_penlu13_0_split -> Eltwise6_penlu13_0_split_1
I1007 15:08:43.498862  4982 net.cpp:122] Setting up Eltwise6_penlu13_0_split
I1007 15:08:43.498867  4982 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 15:08:43.498869  4982 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 15:08:43.498872  4982 net.cpp:137] Memory required for data: 342138000
I1007 15:08:43.498873  4982 layer_factory.hpp:77] Creating layer Convolution15
I1007 15:08:43.498879  4982 net.cpp:84] Creating Layer Convolution15
I1007 15:08:43.498883  4982 net.cpp:406] Convolution15 <- Eltwise6_penlu13_0_split_0
I1007 15:08:43.498885  4982 net.cpp:380] Convolution15 -> Convolution15
I1007 15:08:43.499904  4982 net.cpp:122] Setting up Convolution15
I1007 15:08:43.499913  4982 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 15:08:43.499915  4982 net.cpp:137] Memory required for data: 344646800
I1007 15:08:43.499920  4982 layer_factory.hpp:77] Creating layer BatchNorm15
I1007 15:08:43.499925  4982 net.cpp:84] Creating Layer BatchNorm15
I1007 15:08:43.499934  4982 net.cpp:406] BatchNorm15 <- Convolution15
I1007 15:08:43.499939  4982 net.cpp:367] BatchNorm15 -> Convolution15 (in-place)
I1007 15:08:43.500062  4982 net.cpp:122] Setting up BatchNorm15
I1007 15:08:43.500066  4982 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 15:08:43.500069  4982 net.cpp:137] Memory required for data: 347155600
I1007 15:08:43.500074  4982 layer_factory.hpp:77] Creating layer Scale15
I1007 15:08:43.500078  4982 net.cpp:84] Creating Layer Scale15
I1007 15:08:43.500080  4982 net.cpp:406] Scale15 <- Convolution15
I1007 15:08:43.500083  4982 net.cpp:367] Scale15 -> Convolution15 (in-place)
I1007 15:08:43.500108  4982 layer_factory.hpp:77] Creating layer Scale15
I1007 15:08:43.500178  4982 net.cpp:122] Setting up Scale15
I1007 15:08:43.500182  4982 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 15:08:43.500185  4982 net.cpp:137] Memory required for data: 349664400
I1007 15:08:43.500188  4982 layer_factory.hpp:77] Creating layer penlu14
I1007 15:08:43.500195  4982 net.cpp:84] Creating Layer penlu14
I1007 15:08:43.500196  4982 net.cpp:406] penlu14 <- Convolution15
I1007 15:08:43.500200  4982 net.cpp:367] penlu14 -> Convolution15 (in-place)
I1007 15:08:43.500298  4982 net.cpp:122] Setting up penlu14
I1007 15:08:43.500303  4982 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 15:08:43.500304  4982 net.cpp:137] Memory required for data: 352173200
I1007 15:08:43.500309  4982 layer_factory.hpp:77] Creating layer Convolution16
I1007 15:08:43.500315  4982 net.cpp:84] Creating Layer Convolution16
I1007 15:08:43.500318  4982 net.cpp:406] Convolution16 <- Convolution15
I1007 15:08:43.500321  4982 net.cpp:380] Convolution16 -> Convolution16
I1007 15:08:43.501327  4982 net.cpp:122] Setting up Convolution16
I1007 15:08:43.501335  4982 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 15:08:43.501338  4982 net.cpp:137] Memory required for data: 354682000
I1007 15:08:43.501343  4982 layer_factory.hpp:77] Creating layer BatchNorm16
I1007 15:08:43.501348  4982 net.cpp:84] Creating Layer BatchNorm16
I1007 15:08:43.501351  4982 net.cpp:406] BatchNorm16 <- Convolution16
I1007 15:08:43.501354  4982 net.cpp:367] BatchNorm16 -> Convolution16 (in-place)
I1007 15:08:43.501478  4982 net.cpp:122] Setting up BatchNorm16
I1007 15:08:43.501483  4982 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 15:08:43.501485  4982 net.cpp:137] Memory required for data: 357190800
I1007 15:08:43.501490  4982 layer_factory.hpp:77] Creating layer Scale16
I1007 15:08:43.501494  4982 net.cpp:84] Creating Layer Scale16
I1007 15:08:43.501497  4982 net.cpp:406] Scale16 <- Convolution16
I1007 15:08:43.501499  4982 net.cpp:367] Scale16 -> Convolution16 (in-place)
I1007 15:08:43.501524  4982 layer_factory.hpp:77] Creating layer Scale16
I1007 15:08:43.501595  4982 net.cpp:122] Setting up Scale16
I1007 15:08:43.501598  4982 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 15:08:43.501601  4982 net.cpp:137] Memory required for data: 359699600
I1007 15:08:43.501605  4982 layer_factory.hpp:77] Creating layer Eltwise7
I1007 15:08:43.501610  4982 net.cpp:84] Creating Layer Eltwise7
I1007 15:08:43.501611  4982 net.cpp:406] Eltwise7 <- Eltwise6_penlu13_0_split_1
I1007 15:08:43.501615  4982 net.cpp:406] Eltwise7 <- Convolution16
I1007 15:08:43.501617  4982 net.cpp:380] Eltwise7 -> Eltwise7
I1007 15:08:43.501632  4982 net.cpp:122] Setting up Eltwise7
I1007 15:08:43.501636  4982 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 15:08:43.501638  4982 net.cpp:137] Memory required for data: 362208400
I1007 15:08:43.501641  4982 layer_factory.hpp:77] Creating layer penlu15
I1007 15:08:43.501646  4982 net.cpp:84] Creating Layer penlu15
I1007 15:08:43.501647  4982 net.cpp:406] penlu15 <- Eltwise7
I1007 15:08:43.501652  4982 net.cpp:367] penlu15 -> Eltwise7 (in-place)
I1007 15:08:43.501751  4982 net.cpp:122] Setting up penlu15
I1007 15:08:43.501755  4982 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 15:08:43.501757  4982 net.cpp:137] Memory required for data: 364717200
I1007 15:08:43.501761  4982 layer_factory.hpp:77] Creating layer Eltwise7_penlu15_0_split
I1007 15:08:43.501772  4982 net.cpp:84] Creating Layer Eltwise7_penlu15_0_split
I1007 15:08:43.501775  4982 net.cpp:406] Eltwise7_penlu15_0_split <- Eltwise7
I1007 15:08:43.501778  4982 net.cpp:380] Eltwise7_penlu15_0_split -> Eltwise7_penlu15_0_split_0
I1007 15:08:43.501782  4982 net.cpp:380] Eltwise7_penlu15_0_split -> Eltwise7_penlu15_0_split_1
I1007 15:08:43.501806  4982 net.cpp:122] Setting up Eltwise7_penlu15_0_split
I1007 15:08:43.501809  4982 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 15:08:43.501812  4982 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 15:08:43.501814  4982 net.cpp:137] Memory required for data: 369734800
I1007 15:08:43.501816  4982 layer_factory.hpp:77] Creating layer Convolution17
I1007 15:08:43.501822  4982 net.cpp:84] Creating Layer Convolution17
I1007 15:08:43.501824  4982 net.cpp:406] Convolution17 <- Eltwise7_penlu15_0_split_0
I1007 15:08:43.501828  4982 net.cpp:380] Convolution17 -> Convolution17
I1007 15:08:43.502508  4982 net.cpp:122] Setting up Convolution17
I1007 15:08:43.502516  4982 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 15:08:43.502517  4982 net.cpp:137] Memory required for data: 372243600
I1007 15:08:43.502522  4982 layer_factory.hpp:77] Creating layer BatchNorm17
I1007 15:08:43.502526  4982 net.cpp:84] Creating Layer BatchNorm17
I1007 15:08:43.502528  4982 net.cpp:406] BatchNorm17 <- Convolution17
I1007 15:08:43.502532  4982 net.cpp:367] BatchNorm17 -> Convolution17 (in-place)
I1007 15:08:43.502650  4982 net.cpp:122] Setting up BatchNorm17
I1007 15:08:43.502655  4982 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 15:08:43.502657  4982 net.cpp:137] Memory required for data: 374752400
I1007 15:08:43.502661  4982 layer_factory.hpp:77] Creating layer Scale17
I1007 15:08:43.502665  4982 net.cpp:84] Creating Layer Scale17
I1007 15:08:43.502668  4982 net.cpp:406] Scale17 <- Convolution17
I1007 15:08:43.502671  4982 net.cpp:367] Scale17 -> Convolution17 (in-place)
I1007 15:08:43.502696  4982 layer_factory.hpp:77] Creating layer Scale17
I1007 15:08:43.502764  4982 net.cpp:122] Setting up Scale17
I1007 15:08:43.502768  4982 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 15:08:43.502770  4982 net.cpp:137] Memory required for data: 377261200
I1007 15:08:43.502774  4982 layer_factory.hpp:77] Creating layer penlu16
I1007 15:08:43.502779  4982 net.cpp:84] Creating Layer penlu16
I1007 15:08:43.502781  4982 net.cpp:406] penlu16 <- Convolution17
I1007 15:08:43.502785  4982 net.cpp:367] penlu16 -> Convolution17 (in-place)
I1007 15:08:43.502881  4982 net.cpp:122] Setting up penlu16
I1007 15:08:43.502885  4982 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 15:08:43.502887  4982 net.cpp:137] Memory required for data: 379770000
I1007 15:08:43.502892  4982 layer_factory.hpp:77] Creating layer Convolution18
I1007 15:08:43.502897  4982 net.cpp:84] Creating Layer Convolution18
I1007 15:08:43.502900  4982 net.cpp:406] Convolution18 <- Convolution17
I1007 15:08:43.502903  4982 net.cpp:380] Convolution18 -> Convolution18
I1007 15:08:43.503912  4982 net.cpp:122] Setting up Convolution18
I1007 15:08:43.503921  4982 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 15:08:43.503924  4982 net.cpp:137] Memory required for data: 382278800
I1007 15:08:43.503929  4982 layer_factory.hpp:77] Creating layer BatchNorm18
I1007 15:08:43.503933  4982 net.cpp:84] Creating Layer BatchNorm18
I1007 15:08:43.503937  4982 net.cpp:406] BatchNorm18 <- Convolution18
I1007 15:08:43.503939  4982 net.cpp:367] BatchNorm18 -> Convolution18 (in-place)
I1007 15:08:43.504060  4982 net.cpp:122] Setting up BatchNorm18
I1007 15:08:43.504065  4982 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 15:08:43.504067  4982 net.cpp:137] Memory required for data: 384787600
I1007 15:08:43.504071  4982 layer_factory.hpp:77] Creating layer Scale18
I1007 15:08:43.504076  4982 net.cpp:84] Creating Layer Scale18
I1007 15:08:43.504078  4982 net.cpp:406] Scale18 <- Convolution18
I1007 15:08:43.504081  4982 net.cpp:367] Scale18 -> Convolution18 (in-place)
I1007 15:08:43.504113  4982 layer_factory.hpp:77] Creating layer Scale18
I1007 15:08:43.504184  4982 net.cpp:122] Setting up Scale18
I1007 15:08:43.504189  4982 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 15:08:43.504190  4982 net.cpp:137] Memory required for data: 387296400
I1007 15:08:43.504194  4982 layer_factory.hpp:77] Creating layer Eltwise8
I1007 15:08:43.504197  4982 net.cpp:84] Creating Layer Eltwise8
I1007 15:08:43.504200  4982 net.cpp:406] Eltwise8 <- Eltwise7_penlu15_0_split_1
I1007 15:08:43.504204  4982 net.cpp:406] Eltwise8 <- Convolution18
I1007 15:08:43.504206  4982 net.cpp:380] Eltwise8 -> Eltwise8
I1007 15:08:43.504221  4982 net.cpp:122] Setting up Eltwise8
I1007 15:08:43.504225  4982 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 15:08:43.504226  4982 net.cpp:137] Memory required for data: 389805200
I1007 15:08:43.504228  4982 layer_factory.hpp:77] Creating layer penlu17
I1007 15:08:43.504233  4982 net.cpp:84] Creating Layer penlu17
I1007 15:08:43.504236  4982 net.cpp:406] penlu17 <- Eltwise8
I1007 15:08:43.504240  4982 net.cpp:367] penlu17 -> Eltwise8 (in-place)
I1007 15:08:43.504338  4982 net.cpp:122] Setting up penlu17
I1007 15:08:43.504341  4982 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 15:08:43.504343  4982 net.cpp:137] Memory required for data: 392314000
I1007 15:08:43.504348  4982 layer_factory.hpp:77] Creating layer Eltwise8_penlu17_0_split
I1007 15:08:43.504351  4982 net.cpp:84] Creating Layer Eltwise8_penlu17_0_split
I1007 15:08:43.504354  4982 net.cpp:406] Eltwise8_penlu17_0_split <- Eltwise8
I1007 15:08:43.504356  4982 net.cpp:380] Eltwise8_penlu17_0_split -> Eltwise8_penlu17_0_split_0
I1007 15:08:43.504360  4982 net.cpp:380] Eltwise8_penlu17_0_split -> Eltwise8_penlu17_0_split_1
I1007 15:08:43.504382  4982 net.cpp:122] Setting up Eltwise8_penlu17_0_split
I1007 15:08:43.504386  4982 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 15:08:43.504389  4982 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 15:08:43.504390  4982 net.cpp:137] Memory required for data: 397331600
I1007 15:08:43.504393  4982 layer_factory.hpp:77] Creating layer Convolution19
I1007 15:08:43.504398  4982 net.cpp:84] Creating Layer Convolution19
I1007 15:08:43.504401  4982 net.cpp:406] Convolution19 <- Eltwise8_penlu17_0_split_0
I1007 15:08:43.504415  4982 net.cpp:380] Convolution19 -> Convolution19
I1007 15:08:43.505784  4982 net.cpp:122] Setting up Convolution19
I1007 15:08:43.505792  4982 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 15:08:43.505795  4982 net.cpp:137] Memory required for data: 399840400
I1007 15:08:43.505800  4982 layer_factory.hpp:77] Creating layer BatchNorm19
I1007 15:08:43.505805  4982 net.cpp:84] Creating Layer BatchNorm19
I1007 15:08:43.505807  4982 net.cpp:406] BatchNorm19 <- Convolution19
I1007 15:08:43.505813  4982 net.cpp:367] BatchNorm19 -> Convolution19 (in-place)
I1007 15:08:43.505976  4982 net.cpp:122] Setting up BatchNorm19
I1007 15:08:43.505985  4982 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 15:08:43.505986  4982 net.cpp:137] Memory required for data: 402349200
I1007 15:08:43.505992  4982 layer_factory.hpp:77] Creating layer Scale19
I1007 15:08:43.505996  4982 net.cpp:84] Creating Layer Scale19
I1007 15:08:43.506000  4982 net.cpp:406] Scale19 <- Convolution19
I1007 15:08:43.506002  4982 net.cpp:367] Scale19 -> Convolution19 (in-place)
I1007 15:08:43.506029  4982 layer_factory.hpp:77] Creating layer Scale19
I1007 15:08:43.506110  4982 net.cpp:122] Setting up Scale19
I1007 15:08:43.506115  4982 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 15:08:43.506117  4982 net.cpp:137] Memory required for data: 404858000
I1007 15:08:43.506121  4982 layer_factory.hpp:77] Creating layer penlu18
I1007 15:08:43.506126  4982 net.cpp:84] Creating Layer penlu18
I1007 15:08:43.506129  4982 net.cpp:406] penlu18 <- Convolution19
I1007 15:08:43.506132  4982 net.cpp:367] penlu18 -> Convolution19 (in-place)
I1007 15:08:43.506237  4982 net.cpp:122] Setting up penlu18
I1007 15:08:43.506242  4982 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 15:08:43.506243  4982 net.cpp:137] Memory required for data: 407366800
I1007 15:08:43.506253  4982 layer_factory.hpp:77] Creating layer Convolution20
I1007 15:08:43.506260  4982 net.cpp:84] Creating Layer Convolution20
I1007 15:08:43.506263  4982 net.cpp:406] Convolution20 <- Convolution19
I1007 15:08:43.506266  4982 net.cpp:380] Convolution20 -> Convolution20
I1007 15:08:43.507375  4982 net.cpp:122] Setting up Convolution20
I1007 15:08:43.507385  4982 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 15:08:43.507400  4982 net.cpp:137] Memory required for data: 409875600
I1007 15:08:43.507403  4982 layer_factory.hpp:77] Creating layer BatchNorm20
I1007 15:08:43.507410  4982 net.cpp:84] Creating Layer BatchNorm20
I1007 15:08:43.507412  4982 net.cpp:406] BatchNorm20 <- Convolution20
I1007 15:08:43.507416  4982 net.cpp:367] BatchNorm20 -> Convolution20 (in-place)
I1007 15:08:43.507551  4982 net.cpp:122] Setting up BatchNorm20
I1007 15:08:43.507556  4982 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 15:08:43.507558  4982 net.cpp:137] Memory required for data: 412384400
I1007 15:08:43.507573  4982 layer_factory.hpp:77] Creating layer Scale20
I1007 15:08:43.507578  4982 net.cpp:84] Creating Layer Scale20
I1007 15:08:43.507580  4982 net.cpp:406] Scale20 <- Convolution20
I1007 15:08:43.507583  4982 net.cpp:367] Scale20 -> Convolution20 (in-place)
I1007 15:08:43.507618  4982 layer_factory.hpp:77] Creating layer Scale20
I1007 15:08:43.507691  4982 net.cpp:122] Setting up Scale20
I1007 15:08:43.507695  4982 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 15:08:43.507697  4982 net.cpp:137] Memory required for data: 414893200
I1007 15:08:43.507701  4982 layer_factory.hpp:77] Creating layer Eltwise9
I1007 15:08:43.507704  4982 net.cpp:84] Creating Layer Eltwise9
I1007 15:08:43.507707  4982 net.cpp:406] Eltwise9 <- Eltwise8_penlu17_0_split_1
I1007 15:08:43.507709  4982 net.cpp:406] Eltwise9 <- Convolution20
I1007 15:08:43.507714  4982 net.cpp:380] Eltwise9 -> Eltwise9
I1007 15:08:43.507728  4982 net.cpp:122] Setting up Eltwise9
I1007 15:08:43.507731  4982 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 15:08:43.507733  4982 net.cpp:137] Memory required for data: 417402000
I1007 15:08:43.507735  4982 layer_factory.hpp:77] Creating layer penlu19
I1007 15:08:43.507740  4982 net.cpp:84] Creating Layer penlu19
I1007 15:08:43.507743  4982 net.cpp:406] penlu19 <- Eltwise9
I1007 15:08:43.507746  4982 net.cpp:367] penlu19 -> Eltwise9 (in-place)
I1007 15:08:43.507845  4982 net.cpp:122] Setting up penlu19
I1007 15:08:43.507849  4982 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 15:08:43.507851  4982 net.cpp:137] Memory required for data: 419910800
I1007 15:08:43.507855  4982 layer_factory.hpp:77] Creating layer Eltwise9_penlu19_0_split
I1007 15:08:43.507859  4982 net.cpp:84] Creating Layer Eltwise9_penlu19_0_split
I1007 15:08:43.507861  4982 net.cpp:406] Eltwise9_penlu19_0_split <- Eltwise9
I1007 15:08:43.507864  4982 net.cpp:380] Eltwise9_penlu19_0_split -> Eltwise9_penlu19_0_split_0
I1007 15:08:43.507869  4982 net.cpp:380] Eltwise9_penlu19_0_split -> Eltwise9_penlu19_0_split_1
I1007 15:08:43.507889  4982 net.cpp:122] Setting up Eltwise9_penlu19_0_split
I1007 15:08:43.507892  4982 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 15:08:43.507895  4982 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 15:08:43.507897  4982 net.cpp:137] Memory required for data: 424928400
I1007 15:08:43.507899  4982 layer_factory.hpp:77] Creating layer Convolution21
I1007 15:08:43.507906  4982 net.cpp:84] Creating Layer Convolution21
I1007 15:08:43.507908  4982 net.cpp:406] Convolution21 <- Eltwise9_penlu19_0_split_0
I1007 15:08:43.507912  4982 net.cpp:380] Convolution21 -> Convolution21
I1007 15:08:43.509474  4982 net.cpp:122] Setting up Convolution21
I1007 15:08:43.509483  4982 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 15:08:43.509486  4982 net.cpp:137] Memory required for data: 427437200
I1007 15:08:43.509491  4982 layer_factory.hpp:77] Creating layer BatchNorm21
I1007 15:08:43.509496  4982 net.cpp:84] Creating Layer BatchNorm21
I1007 15:08:43.509516  4982 net.cpp:406] BatchNorm21 <- Convolution21
I1007 15:08:43.509521  4982 net.cpp:367] BatchNorm21 -> Convolution21 (in-place)
I1007 15:08:43.509651  4982 net.cpp:122] Setting up BatchNorm21
I1007 15:08:43.509656  4982 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 15:08:43.509658  4982 net.cpp:137] Memory required for data: 429946000
I1007 15:08:43.509663  4982 layer_factory.hpp:77] Creating layer Scale21
I1007 15:08:43.509667  4982 net.cpp:84] Creating Layer Scale21
I1007 15:08:43.509670  4982 net.cpp:406] Scale21 <- Convolution21
I1007 15:08:43.509672  4982 net.cpp:367] Scale21 -> Convolution21 (in-place)
I1007 15:08:43.509698  4982 layer_factory.hpp:77] Creating layer Scale21
I1007 15:08:43.509771  4982 net.cpp:122] Setting up Scale21
I1007 15:08:43.509775  4982 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 15:08:43.509778  4982 net.cpp:137] Memory required for data: 432454800
I1007 15:08:43.509781  4982 layer_factory.hpp:77] Creating layer penlu20
I1007 15:08:43.509786  4982 net.cpp:84] Creating Layer penlu20
I1007 15:08:43.509788  4982 net.cpp:406] penlu20 <- Convolution21
I1007 15:08:43.509793  4982 net.cpp:367] penlu20 -> Convolution21 (in-place)
I1007 15:08:43.509896  4982 net.cpp:122] Setting up penlu20
I1007 15:08:43.509901  4982 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 15:08:43.509902  4982 net.cpp:137] Memory required for data: 434963600
I1007 15:08:43.509907  4982 layer_factory.hpp:77] Creating layer Convolution22
I1007 15:08:43.509913  4982 net.cpp:84] Creating Layer Convolution22
I1007 15:08:43.509915  4982 net.cpp:406] Convolution22 <- Convolution21
I1007 15:08:43.509920  4982 net.cpp:380] Convolution22 -> Convolution22
I1007 15:08:43.510946  4982 net.cpp:122] Setting up Convolution22
I1007 15:08:43.510954  4982 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 15:08:43.510957  4982 net.cpp:137] Memory required for data: 437472400
I1007 15:08:43.510962  4982 layer_factory.hpp:77] Creating layer BatchNorm22
I1007 15:08:43.510968  4982 net.cpp:84] Creating Layer BatchNorm22
I1007 15:08:43.510970  4982 net.cpp:406] BatchNorm22 <- Convolution22
I1007 15:08:43.510974  4982 net.cpp:367] BatchNorm22 -> Convolution22 (in-place)
I1007 15:08:43.511102  4982 net.cpp:122] Setting up BatchNorm22
I1007 15:08:43.511106  4982 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 15:08:43.511108  4982 net.cpp:137] Memory required for data: 439981200
I1007 15:08:43.511113  4982 layer_factory.hpp:77] Creating layer Scale22
I1007 15:08:43.511117  4982 net.cpp:84] Creating Layer Scale22
I1007 15:08:43.511119  4982 net.cpp:406] Scale22 <- Convolution22
I1007 15:08:43.511122  4982 net.cpp:367] Scale22 -> Convolution22 (in-place)
I1007 15:08:43.511148  4982 layer_factory.hpp:77] Creating layer Scale22
I1007 15:08:43.511248  4982 net.cpp:122] Setting up Scale22
I1007 15:08:43.511253  4982 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 15:08:43.511255  4982 net.cpp:137] Memory required for data: 442490000
I1007 15:08:43.511260  4982 layer_factory.hpp:77] Creating layer Eltwise10
I1007 15:08:43.511263  4982 net.cpp:84] Creating Layer Eltwise10
I1007 15:08:43.511266  4982 net.cpp:406] Eltwise10 <- Eltwise9_penlu19_0_split_1
I1007 15:08:43.511270  4982 net.cpp:406] Eltwise10 <- Convolution22
I1007 15:08:43.511272  4982 net.cpp:380] Eltwise10 -> Eltwise10
I1007 15:08:43.511288  4982 net.cpp:122] Setting up Eltwise10
I1007 15:08:43.511291  4982 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 15:08:43.511293  4982 net.cpp:137] Memory required for data: 444998800
I1007 15:08:43.511296  4982 layer_factory.hpp:77] Creating layer penlu21
I1007 15:08:43.511301  4982 net.cpp:84] Creating Layer penlu21
I1007 15:08:43.511303  4982 net.cpp:406] penlu21 <- Eltwise10
I1007 15:08:43.511307  4982 net.cpp:367] penlu21 -> Eltwise10 (in-place)
I1007 15:08:43.511409  4982 net.cpp:122] Setting up penlu21
I1007 15:08:43.511415  4982 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 15:08:43.511415  4982 net.cpp:137] Memory required for data: 447507600
I1007 15:08:43.511420  4982 layer_factory.hpp:77] Creating layer Eltwise10_penlu21_0_split
I1007 15:08:43.511430  4982 net.cpp:84] Creating Layer Eltwise10_penlu21_0_split
I1007 15:08:43.511433  4982 net.cpp:406] Eltwise10_penlu21_0_split <- Eltwise10
I1007 15:08:43.511437  4982 net.cpp:380] Eltwise10_penlu21_0_split -> Eltwise10_penlu21_0_split_0
I1007 15:08:43.511441  4982 net.cpp:380] Eltwise10_penlu21_0_split -> Eltwise10_penlu21_0_split_1
I1007 15:08:43.511463  4982 net.cpp:122] Setting up Eltwise10_penlu21_0_split
I1007 15:08:43.511468  4982 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 15:08:43.511471  4982 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 15:08:43.511473  4982 net.cpp:137] Memory required for data: 452525200
I1007 15:08:43.511476  4982 layer_factory.hpp:77] Creating layer Convolution23
I1007 15:08:43.511481  4982 net.cpp:84] Creating Layer Convolution23
I1007 15:08:43.511483  4982 net.cpp:406] Convolution23 <- Eltwise10_penlu21_0_split_0
I1007 15:08:43.511487  4982 net.cpp:380] Convolution23 -> Convolution23
I1007 15:08:43.512351  4982 net.cpp:122] Setting up Convolution23
I1007 15:08:43.512359  4982 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 15:08:43.512362  4982 net.cpp:137] Memory required for data: 453779600
I1007 15:08:43.512365  4982 layer_factory.hpp:77] Creating layer BatchNorm23
I1007 15:08:43.512372  4982 net.cpp:84] Creating Layer BatchNorm23
I1007 15:08:43.512374  4982 net.cpp:406] BatchNorm23 <- Convolution23
I1007 15:08:43.512377  4982 net.cpp:367] BatchNorm23 -> Convolution23 (in-place)
I1007 15:08:43.512506  4982 net.cpp:122] Setting up BatchNorm23
I1007 15:08:43.512509  4982 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 15:08:43.512511  4982 net.cpp:137] Memory required for data: 455034000
I1007 15:08:43.512516  4982 layer_factory.hpp:77] Creating layer Scale23
I1007 15:08:43.512519  4982 net.cpp:84] Creating Layer Scale23
I1007 15:08:43.512522  4982 net.cpp:406] Scale23 <- Convolution23
I1007 15:08:43.512526  4982 net.cpp:367] Scale23 -> Convolution23 (in-place)
I1007 15:08:43.512552  4982 layer_factory.hpp:77] Creating layer Scale23
I1007 15:08:43.512624  4982 net.cpp:122] Setting up Scale23
I1007 15:08:43.512627  4982 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 15:08:43.512629  4982 net.cpp:137] Memory required for data: 456288400
I1007 15:08:43.512634  4982 layer_factory.hpp:77] Creating layer Convolution24
I1007 15:08:43.512639  4982 net.cpp:84] Creating Layer Convolution24
I1007 15:08:43.512642  4982 net.cpp:406] Convolution24 <- Eltwise10_penlu21_0_split_1
I1007 15:08:43.512646  4982 net.cpp:380] Convolution24 -> Convolution24
I1007 15:08:43.514361  4982 net.cpp:122] Setting up Convolution24
I1007 15:08:43.514369  4982 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 15:08:43.514372  4982 net.cpp:137] Memory required for data: 457542800
I1007 15:08:43.514376  4982 layer_factory.hpp:77] Creating layer BatchNorm24
I1007 15:08:43.514381  4982 net.cpp:84] Creating Layer BatchNorm24
I1007 15:08:43.514384  4982 net.cpp:406] BatchNorm24 <- Convolution24
I1007 15:08:43.514389  4982 net.cpp:367] BatchNorm24 -> Convolution24 (in-place)
I1007 15:08:43.514519  4982 net.cpp:122] Setting up BatchNorm24
I1007 15:08:43.514524  4982 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 15:08:43.514526  4982 net.cpp:137] Memory required for data: 458797200
I1007 15:08:43.514530  4982 layer_factory.hpp:77] Creating layer Scale24
I1007 15:08:43.514534  4982 net.cpp:84] Creating Layer Scale24
I1007 15:08:43.514538  4982 net.cpp:406] Scale24 <- Convolution24
I1007 15:08:43.514540  4982 net.cpp:367] Scale24 -> Convolution24 (in-place)
I1007 15:08:43.514577  4982 layer_factory.hpp:77] Creating layer Scale24
I1007 15:08:43.514662  4982 net.cpp:122] Setting up Scale24
I1007 15:08:43.514667  4982 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 15:08:43.514668  4982 net.cpp:137] Memory required for data: 460051600
I1007 15:08:43.514672  4982 layer_factory.hpp:77] Creating layer penlu22
I1007 15:08:43.514678  4982 net.cpp:84] Creating Layer penlu22
I1007 15:08:43.514679  4982 net.cpp:406] penlu22 <- Convolution24
I1007 15:08:43.514683  4982 net.cpp:367] penlu22 -> Convolution24 (in-place)
I1007 15:08:43.514796  4982 net.cpp:122] Setting up penlu22
I1007 15:08:43.514801  4982 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 15:08:43.514802  4982 net.cpp:137] Memory required for data: 461306000
I1007 15:08:43.514806  4982 layer_factory.hpp:77] Creating layer Convolution25
I1007 15:08:43.514813  4982 net.cpp:84] Creating Layer Convolution25
I1007 15:08:43.514816  4982 net.cpp:406] Convolution25 <- Convolution24
I1007 15:08:43.514819  4982 net.cpp:380] Convolution25 -> Convolution25
I1007 15:08:43.516752  4982 net.cpp:122] Setting up Convolution25
I1007 15:08:43.516759  4982 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 15:08:43.516762  4982 net.cpp:137] Memory required for data: 462560400
I1007 15:08:43.516767  4982 layer_factory.hpp:77] Creating layer BatchNorm25
I1007 15:08:43.516772  4982 net.cpp:84] Creating Layer BatchNorm25
I1007 15:08:43.516773  4982 net.cpp:406] BatchNorm25 <- Convolution25
I1007 15:08:43.516778  4982 net.cpp:367] BatchNorm25 -> Convolution25 (in-place)
I1007 15:08:43.516912  4982 net.cpp:122] Setting up BatchNorm25
I1007 15:08:43.516917  4982 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 15:08:43.516919  4982 net.cpp:137] Memory required for data: 463814800
I1007 15:08:43.516924  4982 layer_factory.hpp:77] Creating layer Scale25
I1007 15:08:43.516928  4982 net.cpp:84] Creating Layer Scale25
I1007 15:08:43.516930  4982 net.cpp:406] Scale25 <- Convolution25
I1007 15:08:43.516934  4982 net.cpp:367] Scale25 -> Convolution25 (in-place)
I1007 15:08:43.516959  4982 layer_factory.hpp:77] Creating layer Scale25
I1007 15:08:43.517035  4982 net.cpp:122] Setting up Scale25
I1007 15:08:43.517040  4982 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 15:08:43.517041  4982 net.cpp:137] Memory required for data: 465069200
I1007 15:08:43.517045  4982 layer_factory.hpp:77] Creating layer Eltwise11
I1007 15:08:43.517048  4982 net.cpp:84] Creating Layer Eltwise11
I1007 15:08:43.517051  4982 net.cpp:406] Eltwise11 <- Convolution23
I1007 15:08:43.517053  4982 net.cpp:406] Eltwise11 <- Convolution25
I1007 15:08:43.517057  4982 net.cpp:380] Eltwise11 -> Eltwise11
I1007 15:08:43.517073  4982 net.cpp:122] Setting up Eltwise11
I1007 15:08:43.517076  4982 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 15:08:43.517078  4982 net.cpp:137] Memory required for data: 466323600
I1007 15:08:43.517081  4982 layer_factory.hpp:77] Creating layer penlu23
I1007 15:08:43.517086  4982 net.cpp:84] Creating Layer penlu23
I1007 15:08:43.517087  4982 net.cpp:406] penlu23 <- Eltwise11
I1007 15:08:43.517091  4982 net.cpp:367] penlu23 -> Eltwise11 (in-place)
I1007 15:08:43.517197  4982 net.cpp:122] Setting up penlu23
I1007 15:08:43.517202  4982 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 15:08:43.517204  4982 net.cpp:137] Memory required for data: 467578000
I1007 15:08:43.517208  4982 layer_factory.hpp:77] Creating layer Eltwise11_penlu23_0_split
I1007 15:08:43.517211  4982 net.cpp:84] Creating Layer Eltwise11_penlu23_0_split
I1007 15:08:43.517213  4982 net.cpp:406] Eltwise11_penlu23_0_split <- Eltwise11
I1007 15:08:43.517217  4982 net.cpp:380] Eltwise11_penlu23_0_split -> Eltwise11_penlu23_0_split_0
I1007 15:08:43.517221  4982 net.cpp:380] Eltwise11_penlu23_0_split -> Eltwise11_penlu23_0_split_1
I1007 15:08:43.517243  4982 net.cpp:122] Setting up Eltwise11_penlu23_0_split
I1007 15:08:43.517247  4982 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 15:08:43.517249  4982 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 15:08:43.517251  4982 net.cpp:137] Memory required for data: 470086800
I1007 15:08:43.517253  4982 layer_factory.hpp:77] Creating layer Convolution26
I1007 15:08:43.517261  4982 net.cpp:84] Creating Layer Convolution26
I1007 15:08:43.517262  4982 net.cpp:406] Convolution26 <- Eltwise11_penlu23_0_split_0
I1007 15:08:43.517266  4982 net.cpp:380] Convolution26 -> Convolution26
I1007 15:08:43.518875  4982 net.cpp:122] Setting up Convolution26
I1007 15:08:43.518884  4982 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 15:08:43.518887  4982 net.cpp:137] Memory required for data: 471341200
I1007 15:08:43.518898  4982 layer_factory.hpp:77] Creating layer BatchNorm26
I1007 15:08:43.518903  4982 net.cpp:84] Creating Layer BatchNorm26
I1007 15:08:43.518905  4982 net.cpp:406] BatchNorm26 <- Convolution26
I1007 15:08:43.518909  4982 net.cpp:367] BatchNorm26 -> Convolution26 (in-place)
I1007 15:08:43.519040  4982 net.cpp:122] Setting up BatchNorm26
I1007 15:08:43.519045  4982 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 15:08:43.519047  4982 net.cpp:137] Memory required for data: 472595600
I1007 15:08:43.519052  4982 layer_factory.hpp:77] Creating layer Scale26
I1007 15:08:43.519057  4982 net.cpp:84] Creating Layer Scale26
I1007 15:08:43.519059  4982 net.cpp:406] Scale26 <- Convolution26
I1007 15:08:43.519062  4982 net.cpp:367] Scale26 -> Convolution26 (in-place)
I1007 15:08:43.519089  4982 layer_factory.hpp:77] Creating layer Scale26
I1007 15:08:43.519168  4982 net.cpp:122] Setting up Scale26
I1007 15:08:43.519184  4982 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 15:08:43.519186  4982 net.cpp:137] Memory required for data: 473850000
I1007 15:08:43.519189  4982 layer_factory.hpp:77] Creating layer penlu24
I1007 15:08:43.519196  4982 net.cpp:84] Creating Layer penlu24
I1007 15:08:43.519198  4982 net.cpp:406] penlu24 <- Convolution26
I1007 15:08:43.519202  4982 net.cpp:367] penlu24 -> Convolution26 (in-place)
I1007 15:08:43.519317  4982 net.cpp:122] Setting up penlu24
I1007 15:08:43.519321  4982 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 15:08:43.519323  4982 net.cpp:137] Memory required for data: 475104400
I1007 15:08:43.519327  4982 layer_factory.hpp:77] Creating layer Convolution27
I1007 15:08:43.519335  4982 net.cpp:84] Creating Layer Convolution27
I1007 15:08:43.519336  4982 net.cpp:406] Convolution27 <- Convolution26
I1007 15:08:43.519340  4982 net.cpp:380] Convolution27 -> Convolution27
I1007 15:08:43.520939  4982 net.cpp:122] Setting up Convolution27
I1007 15:08:43.520947  4982 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 15:08:43.520951  4982 net.cpp:137] Memory required for data: 476358800
I1007 15:08:43.520956  4982 layer_factory.hpp:77] Creating layer BatchNorm27
I1007 15:08:43.520961  4982 net.cpp:84] Creating Layer BatchNorm27
I1007 15:08:43.520962  4982 net.cpp:406] BatchNorm27 <- Convolution27
I1007 15:08:43.520967  4982 net.cpp:367] BatchNorm27 -> Convolution27 (in-place)
I1007 15:08:43.521100  4982 net.cpp:122] Setting up BatchNorm27
I1007 15:08:43.521104  4982 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 15:08:43.521106  4982 net.cpp:137] Memory required for data: 477613200
I1007 15:08:43.521131  4982 layer_factory.hpp:77] Creating layer Scale27
I1007 15:08:43.521143  4982 net.cpp:84] Creating Layer Scale27
I1007 15:08:43.521145  4982 net.cpp:406] Scale27 <- Convolution27
I1007 15:08:43.521148  4982 net.cpp:367] Scale27 -> Convolution27 (in-place)
I1007 15:08:43.521178  4982 layer_factory.hpp:77] Creating layer Scale27
I1007 15:08:43.521253  4982 net.cpp:122] Setting up Scale27
I1007 15:08:43.521257  4982 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 15:08:43.521260  4982 net.cpp:137] Memory required for data: 478867600
I1007 15:08:43.521263  4982 layer_factory.hpp:77] Creating layer Eltwise12
I1007 15:08:43.521267  4982 net.cpp:84] Creating Layer Eltwise12
I1007 15:08:43.521270  4982 net.cpp:406] Eltwise12 <- Eltwise11_penlu23_0_split_1
I1007 15:08:43.521272  4982 net.cpp:406] Eltwise12 <- Convolution27
I1007 15:08:43.521276  4982 net.cpp:380] Eltwise12 -> Eltwise12
I1007 15:08:43.521294  4982 net.cpp:122] Setting up Eltwise12
I1007 15:08:43.521299  4982 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 15:08:43.521301  4982 net.cpp:137] Memory required for data: 480122000
I1007 15:08:43.521303  4982 layer_factory.hpp:77] Creating layer penlu25
I1007 15:08:43.521307  4982 net.cpp:84] Creating Layer penlu25
I1007 15:08:43.521311  4982 net.cpp:406] penlu25 <- Eltwise12
I1007 15:08:43.521314  4982 net.cpp:367] penlu25 -> Eltwise12 (in-place)
I1007 15:08:43.521420  4982 net.cpp:122] Setting up penlu25
I1007 15:08:43.521425  4982 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 15:08:43.521433  4982 net.cpp:137] Memory required for data: 481376400
I1007 15:08:43.521438  4982 layer_factory.hpp:77] Creating layer Eltwise12_penlu25_0_split
I1007 15:08:43.521442  4982 net.cpp:84] Creating Layer Eltwise12_penlu25_0_split
I1007 15:08:43.521445  4982 net.cpp:406] Eltwise12_penlu25_0_split <- Eltwise12
I1007 15:08:43.521447  4982 net.cpp:380] Eltwise12_penlu25_0_split -> Eltwise12_penlu25_0_split_0
I1007 15:08:43.521451  4982 net.cpp:380] Eltwise12_penlu25_0_split -> Eltwise12_penlu25_0_split_1
I1007 15:08:43.521476  4982 net.cpp:122] Setting up Eltwise12_penlu25_0_split
I1007 15:08:43.521478  4982 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 15:08:43.521481  4982 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 15:08:43.521483  4982 net.cpp:137] Memory required for data: 483885200
I1007 15:08:43.521486  4982 layer_factory.hpp:77] Creating layer Convolution28
I1007 15:08:43.521492  4982 net.cpp:84] Creating Layer Convolution28
I1007 15:08:43.521494  4982 net.cpp:406] Convolution28 <- Eltwise12_penlu25_0_split_0
I1007 15:08:43.521497  4982 net.cpp:380] Convolution28 -> Convolution28
I1007 15:08:43.523103  4982 net.cpp:122] Setting up Convolution28
I1007 15:08:43.523113  4982 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 15:08:43.523115  4982 net.cpp:137] Memory required for data: 485139600
I1007 15:08:43.523119  4982 layer_factory.hpp:77] Creating layer BatchNorm28
I1007 15:08:43.523123  4982 net.cpp:84] Creating Layer BatchNorm28
I1007 15:08:43.523126  4982 net.cpp:406] BatchNorm28 <- Convolution28
I1007 15:08:43.523130  4982 net.cpp:367] BatchNorm28 -> Convolution28 (in-place)
I1007 15:08:43.523288  4982 net.cpp:122] Setting up BatchNorm28
I1007 15:08:43.523294  4982 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 15:08:43.523296  4982 net.cpp:137] Memory required for data: 486394000
I1007 15:08:43.523300  4982 layer_factory.hpp:77] Creating layer Scale28
I1007 15:08:43.523304  4982 net.cpp:84] Creating Layer Scale28
I1007 15:08:43.523308  4982 net.cpp:406] Scale28 <- Convolution28
I1007 15:08:43.523311  4982 net.cpp:367] Scale28 -> Convolution28 (in-place)
I1007 15:08:43.523336  4982 layer_factory.hpp:77] Creating layer Scale28
I1007 15:08:43.523412  4982 net.cpp:122] Setting up Scale28
I1007 15:08:43.523416  4982 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 15:08:43.523418  4982 net.cpp:137] Memory required for data: 487648400
I1007 15:08:43.523422  4982 layer_factory.hpp:77] Creating layer penlu26
I1007 15:08:43.523428  4982 net.cpp:84] Creating Layer penlu26
I1007 15:08:43.523430  4982 net.cpp:406] penlu26 <- Convolution28
I1007 15:08:43.523434  4982 net.cpp:367] penlu26 -> Convolution28 (in-place)
I1007 15:08:43.523543  4982 net.cpp:122] Setting up penlu26
I1007 15:08:43.523548  4982 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 15:08:43.523550  4982 net.cpp:137] Memory required for data: 488902800
I1007 15:08:43.523555  4982 layer_factory.hpp:77] Creating layer Convolution29
I1007 15:08:43.523561  4982 net.cpp:84] Creating Layer Convolution29
I1007 15:08:43.523563  4982 net.cpp:406] Convolution29 <- Convolution28
I1007 15:08:43.523567  4982 net.cpp:380] Convolution29 -> Convolution29
I1007 15:08:43.525481  4982 net.cpp:122] Setting up Convolution29
I1007 15:08:43.525490  4982 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 15:08:43.525492  4982 net.cpp:137] Memory required for data: 490157200
I1007 15:08:43.525496  4982 layer_factory.hpp:77] Creating layer BatchNorm29
I1007 15:08:43.525501  4982 net.cpp:84] Creating Layer BatchNorm29
I1007 15:08:43.525504  4982 net.cpp:406] BatchNorm29 <- Convolution29
I1007 15:08:43.525507  4982 net.cpp:367] BatchNorm29 -> Convolution29 (in-place)
I1007 15:08:43.525646  4982 net.cpp:122] Setting up BatchNorm29
I1007 15:08:43.525650  4982 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 15:08:43.525652  4982 net.cpp:137] Memory required for data: 491411600
I1007 15:08:43.525657  4982 layer_factory.hpp:77] Creating layer Scale29
I1007 15:08:43.525661  4982 net.cpp:84] Creating Layer Scale29
I1007 15:08:43.525671  4982 net.cpp:406] Scale29 <- Convolution29
I1007 15:08:43.525674  4982 net.cpp:367] Scale29 -> Convolution29 (in-place)
I1007 15:08:43.525702  4982 layer_factory.hpp:77] Creating layer Scale29
I1007 15:08:43.525780  4982 net.cpp:122] Setting up Scale29
I1007 15:08:43.525784  4982 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 15:08:43.525786  4982 net.cpp:137] Memory required for data: 492666000
I1007 15:08:43.525790  4982 layer_factory.hpp:77] Creating layer Eltwise13
I1007 15:08:43.525794  4982 net.cpp:84] Creating Layer Eltwise13
I1007 15:08:43.525797  4982 net.cpp:406] Eltwise13 <- Eltwise12_penlu25_0_split_1
I1007 15:08:43.525799  4982 net.cpp:406] Eltwise13 <- Convolution29
I1007 15:08:43.525802  4982 net.cpp:380] Eltwise13 -> Eltwise13
I1007 15:08:43.525818  4982 net.cpp:122] Setting up Eltwise13
I1007 15:08:43.525822  4982 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 15:08:43.525825  4982 net.cpp:137] Memory required for data: 493920400
I1007 15:08:43.525826  4982 layer_factory.hpp:77] Creating layer penlu27
I1007 15:08:43.525831  4982 net.cpp:84] Creating Layer penlu27
I1007 15:08:43.525835  4982 net.cpp:406] penlu27 <- Eltwise13
I1007 15:08:43.525837  4982 net.cpp:367] penlu27 -> Eltwise13 (in-place)
I1007 15:08:43.525946  4982 net.cpp:122] Setting up penlu27
I1007 15:08:43.525950  4982 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 15:08:43.525952  4982 net.cpp:137] Memory required for data: 495174800
I1007 15:08:43.525957  4982 layer_factory.hpp:77] Creating layer Eltwise13_penlu27_0_split
I1007 15:08:43.525960  4982 net.cpp:84] Creating Layer Eltwise13_penlu27_0_split
I1007 15:08:43.525962  4982 net.cpp:406] Eltwise13_penlu27_0_split <- Eltwise13
I1007 15:08:43.525965  4982 net.cpp:380] Eltwise13_penlu27_0_split -> Eltwise13_penlu27_0_split_0
I1007 15:08:43.525969  4982 net.cpp:380] Eltwise13_penlu27_0_split -> Eltwise13_penlu27_0_split_1
I1007 15:08:43.525992  4982 net.cpp:122] Setting up Eltwise13_penlu27_0_split
I1007 15:08:43.525996  4982 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 15:08:43.525998  4982 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 15:08:43.526000  4982 net.cpp:137] Memory required for data: 497683600
I1007 15:08:43.526002  4982 layer_factory.hpp:77] Creating layer Convolution30
I1007 15:08:43.526008  4982 net.cpp:84] Creating Layer Convolution30
I1007 15:08:43.526010  4982 net.cpp:406] Convolution30 <- Eltwise13_penlu27_0_split_0
I1007 15:08:43.526015  4982 net.cpp:380] Convolution30 -> Convolution30
I1007 15:08:43.527657  4982 net.cpp:122] Setting up Convolution30
I1007 15:08:43.527664  4982 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 15:08:43.527667  4982 net.cpp:137] Memory required for data: 498938000
I1007 15:08:43.527671  4982 layer_factory.hpp:77] Creating layer BatchNorm30
I1007 15:08:43.527678  4982 net.cpp:84] Creating Layer BatchNorm30
I1007 15:08:43.527680  4982 net.cpp:406] BatchNorm30 <- Convolution30
I1007 15:08:43.527683  4982 net.cpp:367] BatchNorm30 -> Convolution30 (in-place)
I1007 15:08:43.527818  4982 net.cpp:122] Setting up BatchNorm30
I1007 15:08:43.527823  4982 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 15:08:43.527825  4982 net.cpp:137] Memory required for data: 500192400
I1007 15:08:43.527829  4982 layer_factory.hpp:77] Creating layer Scale30
I1007 15:08:43.527833  4982 net.cpp:84] Creating Layer Scale30
I1007 15:08:43.527837  4982 net.cpp:406] Scale30 <- Convolution30
I1007 15:08:43.527839  4982 net.cpp:367] Scale30 -> Convolution30 (in-place)
I1007 15:08:43.527868  4982 layer_factory.hpp:77] Creating layer Scale30
I1007 15:08:43.527945  4982 net.cpp:122] Setting up Scale30
I1007 15:08:43.527950  4982 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 15:08:43.527951  4982 net.cpp:137] Memory required for data: 501446800
I1007 15:08:43.527956  4982 layer_factory.hpp:77] Creating layer penlu28
I1007 15:08:43.527961  4982 net.cpp:84] Creating Layer penlu28
I1007 15:08:43.527963  4982 net.cpp:406] penlu28 <- Convolution30
I1007 15:08:43.527967  4982 net.cpp:367] penlu28 -> Convolution30 (in-place)
I1007 15:08:43.528084  4982 net.cpp:122] Setting up penlu28
I1007 15:08:43.528089  4982 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 15:08:43.528090  4982 net.cpp:137] Memory required for data: 502701200
I1007 15:08:43.528095  4982 layer_factory.hpp:77] Creating layer Convolution31
I1007 15:08:43.528101  4982 net.cpp:84] Creating Layer Convolution31
I1007 15:08:43.528105  4982 net.cpp:406] Convolution31 <- Convolution30
I1007 15:08:43.528108  4982 net.cpp:380] Convolution31 -> Convolution31
I1007 15:08:43.530037  4982 net.cpp:122] Setting up Convolution31
I1007 15:08:43.530045  4982 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 15:08:43.530048  4982 net.cpp:137] Memory required for data: 503955600
I1007 15:08:43.530052  4982 layer_factory.hpp:77] Creating layer BatchNorm31
I1007 15:08:43.530057  4982 net.cpp:84] Creating Layer BatchNorm31
I1007 15:08:43.530061  4982 net.cpp:406] BatchNorm31 <- Convolution31
I1007 15:08:43.530064  4982 net.cpp:367] BatchNorm31 -> Convolution31 (in-place)
I1007 15:08:43.530202  4982 net.cpp:122] Setting up BatchNorm31
I1007 15:08:43.530206  4982 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 15:08:43.530210  4982 net.cpp:137] Memory required for data: 505210000
I1007 15:08:43.530213  4982 layer_factory.hpp:77] Creating layer Scale31
I1007 15:08:43.530218  4982 net.cpp:84] Creating Layer Scale31
I1007 15:08:43.530221  4982 net.cpp:406] Scale31 <- Convolution31
I1007 15:08:43.530225  4982 net.cpp:367] Scale31 -> Convolution31 (in-place)
I1007 15:08:43.530251  4982 layer_factory.hpp:77] Creating layer Scale31
I1007 15:08:43.530328  4982 net.cpp:122] Setting up Scale31
I1007 15:08:43.530333  4982 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 15:08:43.530334  4982 net.cpp:137] Memory required for data: 506464400
I1007 15:08:43.530339  4982 layer_factory.hpp:77] Creating layer Eltwise14
I1007 15:08:43.530342  4982 net.cpp:84] Creating Layer Eltwise14
I1007 15:08:43.530345  4982 net.cpp:406] Eltwise14 <- Eltwise13_penlu27_0_split_1
I1007 15:08:43.530347  4982 net.cpp:406] Eltwise14 <- Convolution31
I1007 15:08:43.530351  4982 net.cpp:380] Eltwise14 -> Eltwise14
I1007 15:08:43.530367  4982 net.cpp:122] Setting up Eltwise14
I1007 15:08:43.530370  4982 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 15:08:43.530372  4982 net.cpp:137] Memory required for data: 507718800
I1007 15:08:43.530375  4982 layer_factory.hpp:77] Creating layer penlu29
I1007 15:08:43.530380  4982 net.cpp:84] Creating Layer penlu29
I1007 15:08:43.530382  4982 net.cpp:406] penlu29 <- Eltwise14
I1007 15:08:43.530385  4982 net.cpp:367] penlu29 -> Eltwise14 (in-place)
I1007 15:08:43.530493  4982 net.cpp:122] Setting up penlu29
I1007 15:08:43.530498  4982 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 15:08:43.530500  4982 net.cpp:137] Memory required for data: 508973200
I1007 15:08:43.530504  4982 layer_factory.hpp:77] Creating layer Eltwise14_penlu29_0_split
I1007 15:08:43.530508  4982 net.cpp:84] Creating Layer Eltwise14_penlu29_0_split
I1007 15:08:43.530510  4982 net.cpp:406] Eltwise14_penlu29_0_split <- Eltwise14
I1007 15:08:43.530514  4982 net.cpp:380] Eltwise14_penlu29_0_split -> Eltwise14_penlu29_0_split_0
I1007 15:08:43.530519  4982 net.cpp:380] Eltwise14_penlu29_0_split -> Eltwise14_penlu29_0_split_1
I1007 15:08:43.530540  4982 net.cpp:122] Setting up Eltwise14_penlu29_0_split
I1007 15:08:43.530544  4982 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 15:08:43.530546  4982 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 15:08:43.530549  4982 net.cpp:137] Memory required for data: 511482000
I1007 15:08:43.530551  4982 layer_factory.hpp:77] Creating layer Convolution32
I1007 15:08:43.530557  4982 net.cpp:84] Creating Layer Convolution32
I1007 15:08:43.530560  4982 net.cpp:406] Convolution32 <- Eltwise14_penlu29_0_split_0
I1007 15:08:43.530563  4982 net.cpp:380] Convolution32 -> Convolution32
I1007 15:08:43.532212  4982 net.cpp:122] Setting up Convolution32
I1007 15:08:43.532219  4982 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 15:08:43.532222  4982 net.cpp:137] Memory required for data: 512736400
I1007 15:08:43.532233  4982 layer_factory.hpp:77] Creating layer BatchNorm32
I1007 15:08:43.532238  4982 net.cpp:84] Creating Layer BatchNorm32
I1007 15:08:43.532243  4982 net.cpp:406] BatchNorm32 <- Convolution32
I1007 15:08:43.532245  4982 net.cpp:367] BatchNorm32 -> Convolution32 (in-place)
I1007 15:08:43.532384  4982 net.cpp:122] Setting up BatchNorm32
I1007 15:08:43.532388  4982 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 15:08:43.532390  4982 net.cpp:137] Memory required for data: 513990800
I1007 15:08:43.532395  4982 layer_factory.hpp:77] Creating layer Scale32
I1007 15:08:43.532400  4982 net.cpp:84] Creating Layer Scale32
I1007 15:08:43.532402  4982 net.cpp:406] Scale32 <- Convolution32
I1007 15:08:43.532405  4982 net.cpp:367] Scale32 -> Convolution32 (in-place)
I1007 15:08:43.532433  4982 layer_factory.hpp:77] Creating layer Scale32
I1007 15:08:43.532510  4982 net.cpp:122] Setting up Scale32
I1007 15:08:43.532515  4982 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 15:08:43.532516  4982 net.cpp:137] Memory required for data: 515245200
I1007 15:08:43.532521  4982 layer_factory.hpp:77] Creating layer penlu30
I1007 15:08:43.532526  4982 net.cpp:84] Creating Layer penlu30
I1007 15:08:43.532528  4982 net.cpp:406] penlu30 <- Convolution32
I1007 15:08:43.532531  4982 net.cpp:367] penlu30 -> Convolution32 (in-place)
I1007 15:08:43.532639  4982 net.cpp:122] Setting up penlu30
I1007 15:08:43.532642  4982 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 15:08:43.532644  4982 net.cpp:137] Memory required for data: 516499600
I1007 15:08:43.532649  4982 layer_factory.hpp:77] Creating layer Convolution33
I1007 15:08:43.532655  4982 net.cpp:84] Creating Layer Convolution33
I1007 15:08:43.532657  4982 net.cpp:406] Convolution33 <- Convolution32
I1007 15:08:43.532661  4982 net.cpp:380] Convolution33 -> Convolution33
I1007 15:08:43.534591  4982 net.cpp:122] Setting up Convolution33
I1007 15:08:43.534600  4982 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 15:08:43.534602  4982 net.cpp:137] Memory required for data: 517754000
I1007 15:08:43.534607  4982 layer_factory.hpp:77] Creating layer BatchNorm33
I1007 15:08:43.534611  4982 net.cpp:84] Creating Layer BatchNorm33
I1007 15:08:43.534615  4982 net.cpp:406] BatchNorm33 <- Convolution33
I1007 15:08:43.534618  4982 net.cpp:367] BatchNorm33 -> Convolution33 (in-place)
I1007 15:08:43.534756  4982 net.cpp:122] Setting up BatchNorm33
I1007 15:08:43.534761  4982 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 15:08:43.534763  4982 net.cpp:137] Memory required for data: 519008400
I1007 15:08:43.534767  4982 layer_factory.hpp:77] Creating layer Scale33
I1007 15:08:43.534771  4982 net.cpp:84] Creating Layer Scale33
I1007 15:08:43.534775  4982 net.cpp:406] Scale33 <- Convolution33
I1007 15:08:43.534777  4982 net.cpp:367] Scale33 -> Convolution33 (in-place)
I1007 15:08:43.534804  4982 layer_factory.hpp:77] Creating layer Scale33
I1007 15:08:43.534883  4982 net.cpp:122] Setting up Scale33
I1007 15:08:43.534888  4982 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 15:08:43.534889  4982 net.cpp:137] Memory required for data: 520262800
I1007 15:08:43.534893  4982 layer_factory.hpp:77] Creating layer Eltwise15
I1007 15:08:43.534896  4982 net.cpp:84] Creating Layer Eltwise15
I1007 15:08:43.534899  4982 net.cpp:406] Eltwise15 <- Eltwise14_penlu29_0_split_1
I1007 15:08:43.534903  4982 net.cpp:406] Eltwise15 <- Convolution33
I1007 15:08:43.534906  4982 net.cpp:380] Eltwise15 -> Eltwise15
I1007 15:08:43.534921  4982 net.cpp:122] Setting up Eltwise15
I1007 15:08:43.534926  4982 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 15:08:43.534929  4982 net.cpp:137] Memory required for data: 521517200
I1007 15:08:43.534930  4982 layer_factory.hpp:77] Creating layer penlu31
I1007 15:08:43.534934  4982 net.cpp:84] Creating Layer penlu31
I1007 15:08:43.534936  4982 net.cpp:406] penlu31 <- Eltwise15
I1007 15:08:43.534941  4982 net.cpp:367] penlu31 -> Eltwise15 (in-place)
I1007 15:08:43.535048  4982 net.cpp:122] Setting up penlu31
I1007 15:08:43.535053  4982 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 15:08:43.535060  4982 net.cpp:137] Memory required for data: 522771600
I1007 15:08:43.535065  4982 layer_factory.hpp:77] Creating layer Pooling1
I1007 15:08:43.535069  4982 net.cpp:84] Creating Layer Pooling1
I1007 15:08:43.535073  4982 net.cpp:406] Pooling1 <- Eltwise15
I1007 15:08:43.535075  4982 net.cpp:380] Pooling1 -> Pooling1
I1007 15:08:43.535248  4982 net.cpp:122] Setting up Pooling1
I1007 15:08:43.535254  4982 net.cpp:129] Top shape: 100 64 1 1 (6400)
I1007 15:08:43.535257  4982 net.cpp:137] Memory required for data: 522797200
I1007 15:08:43.535259  4982 layer_factory.hpp:77] Creating layer InnerProduct1
I1007 15:08:43.535269  4982 net.cpp:84] Creating Layer InnerProduct1
I1007 15:08:43.535271  4982 net.cpp:406] InnerProduct1 <- Pooling1
I1007 15:08:43.535275  4982 net.cpp:380] InnerProduct1 -> InnerProduct1
I1007 15:08:43.535368  4982 net.cpp:122] Setting up InnerProduct1
I1007 15:08:43.535372  4982 net.cpp:129] Top shape: 100 10 (1000)
I1007 15:08:43.535374  4982 net.cpp:137] Memory required for data: 522801200
I1007 15:08:43.535378  4982 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I1007 15:08:43.535383  4982 net.cpp:84] Creating Layer SoftmaxWithLoss1
I1007 15:08:43.535385  4982 net.cpp:406] SoftmaxWithLoss1 <- InnerProduct1
I1007 15:08:43.535388  4982 net.cpp:406] SoftmaxWithLoss1 <- Data2
I1007 15:08:43.535392  4982 net.cpp:380] SoftmaxWithLoss1 -> SoftmaxWithLoss1
I1007 15:08:43.535398  4982 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I1007 15:08:43.535588  4982 net.cpp:122] Setting up SoftmaxWithLoss1
I1007 15:08:43.535593  4982 net.cpp:129] Top shape: (1)
I1007 15:08:43.535595  4982 net.cpp:132]     with loss weight 1
I1007 15:08:43.535607  4982 net.cpp:137] Memory required for data: 522801204
I1007 15:08:43.535609  4982 net.cpp:198] SoftmaxWithLoss1 needs backward computation.
I1007 15:08:43.535612  4982 net.cpp:198] InnerProduct1 needs backward computation.
I1007 15:08:43.535614  4982 net.cpp:198] Pooling1 needs backward computation.
I1007 15:08:43.535616  4982 net.cpp:198] penlu31 needs backward computation.
I1007 15:08:43.535619  4982 net.cpp:198] Eltwise15 needs backward computation.
I1007 15:08:43.535621  4982 net.cpp:198] Scale33 needs backward computation.
I1007 15:08:43.535624  4982 net.cpp:198] BatchNorm33 needs backward computation.
I1007 15:08:43.535624  4982 net.cpp:198] Convolution33 needs backward computation.
I1007 15:08:43.535627  4982 net.cpp:198] penlu30 needs backward computation.
I1007 15:08:43.535629  4982 net.cpp:198] Scale32 needs backward computation.
I1007 15:08:43.535630  4982 net.cpp:198] BatchNorm32 needs backward computation.
I1007 15:08:43.535632  4982 net.cpp:198] Convolution32 needs backward computation.
I1007 15:08:43.535635  4982 net.cpp:198] Eltwise14_penlu29_0_split needs backward computation.
I1007 15:08:43.535637  4982 net.cpp:198] penlu29 needs backward computation.
I1007 15:08:43.535640  4982 net.cpp:198] Eltwise14 needs backward computation.
I1007 15:08:43.535641  4982 net.cpp:198] Scale31 needs backward computation.
I1007 15:08:43.535643  4982 net.cpp:198] BatchNorm31 needs backward computation.
I1007 15:08:43.535645  4982 net.cpp:198] Convolution31 needs backward computation.
I1007 15:08:43.535647  4982 net.cpp:198] penlu28 needs backward computation.
I1007 15:08:43.535650  4982 net.cpp:198] Scale30 needs backward computation.
I1007 15:08:43.535651  4982 net.cpp:198] BatchNorm30 needs backward computation.
I1007 15:08:43.535653  4982 net.cpp:198] Convolution30 needs backward computation.
I1007 15:08:43.535655  4982 net.cpp:198] Eltwise13_penlu27_0_split needs backward computation.
I1007 15:08:43.535657  4982 net.cpp:198] penlu27 needs backward computation.
I1007 15:08:43.535660  4982 net.cpp:198] Eltwise13 needs backward computation.
I1007 15:08:43.535661  4982 net.cpp:198] Scale29 needs backward computation.
I1007 15:08:43.535663  4982 net.cpp:198] BatchNorm29 needs backward computation.
I1007 15:08:43.535665  4982 net.cpp:198] Convolution29 needs backward computation.
I1007 15:08:43.535667  4982 net.cpp:198] penlu26 needs backward computation.
I1007 15:08:43.535676  4982 net.cpp:198] Scale28 needs backward computation.
I1007 15:08:43.535678  4982 net.cpp:198] BatchNorm28 needs backward computation.
I1007 15:08:43.535681  4982 net.cpp:198] Convolution28 needs backward computation.
I1007 15:08:43.535682  4982 net.cpp:198] Eltwise12_penlu25_0_split needs backward computation.
I1007 15:08:43.535684  4982 net.cpp:198] penlu25 needs backward computation.
I1007 15:08:43.535686  4982 net.cpp:198] Eltwise12 needs backward computation.
I1007 15:08:43.535688  4982 net.cpp:198] Scale27 needs backward computation.
I1007 15:08:43.535691  4982 net.cpp:198] BatchNorm27 needs backward computation.
I1007 15:08:43.535692  4982 net.cpp:198] Convolution27 needs backward computation.
I1007 15:08:43.535694  4982 net.cpp:198] penlu24 needs backward computation.
I1007 15:08:43.535696  4982 net.cpp:198] Scale26 needs backward computation.
I1007 15:08:43.535698  4982 net.cpp:198] BatchNorm26 needs backward computation.
I1007 15:08:43.535701  4982 net.cpp:198] Convolution26 needs backward computation.
I1007 15:08:43.535702  4982 net.cpp:198] Eltwise11_penlu23_0_split needs backward computation.
I1007 15:08:43.535704  4982 net.cpp:198] penlu23 needs backward computation.
I1007 15:08:43.535706  4982 net.cpp:198] Eltwise11 needs backward computation.
I1007 15:08:43.535709  4982 net.cpp:198] Scale25 needs backward computation.
I1007 15:08:43.535712  4982 net.cpp:198] BatchNorm25 needs backward computation.
I1007 15:08:43.535714  4982 net.cpp:198] Convolution25 needs backward computation.
I1007 15:08:43.535717  4982 net.cpp:198] penlu22 needs backward computation.
I1007 15:08:43.535718  4982 net.cpp:198] Scale24 needs backward computation.
I1007 15:08:43.535720  4982 net.cpp:198] BatchNorm24 needs backward computation.
I1007 15:08:43.535722  4982 net.cpp:198] Convolution24 needs backward computation.
I1007 15:08:43.535724  4982 net.cpp:198] Scale23 needs backward computation.
I1007 15:08:43.535727  4982 net.cpp:198] BatchNorm23 needs backward computation.
I1007 15:08:43.535728  4982 net.cpp:198] Convolution23 needs backward computation.
I1007 15:08:43.535730  4982 net.cpp:198] Eltwise10_penlu21_0_split needs backward computation.
I1007 15:08:43.535732  4982 net.cpp:198] penlu21 needs backward computation.
I1007 15:08:43.535734  4982 net.cpp:198] Eltwise10 needs backward computation.
I1007 15:08:43.535737  4982 net.cpp:198] Scale22 needs backward computation.
I1007 15:08:43.535739  4982 net.cpp:198] BatchNorm22 needs backward computation.
I1007 15:08:43.535742  4982 net.cpp:198] Convolution22 needs backward computation.
I1007 15:08:43.535743  4982 net.cpp:198] penlu20 needs backward computation.
I1007 15:08:43.535745  4982 net.cpp:198] Scale21 needs backward computation.
I1007 15:08:43.535748  4982 net.cpp:198] BatchNorm21 needs backward computation.
I1007 15:08:43.535749  4982 net.cpp:198] Convolution21 needs backward computation.
I1007 15:08:43.535751  4982 net.cpp:198] Eltwise9_penlu19_0_split needs backward computation.
I1007 15:08:43.535754  4982 net.cpp:198] penlu19 needs backward computation.
I1007 15:08:43.535756  4982 net.cpp:198] Eltwise9 needs backward computation.
I1007 15:08:43.535758  4982 net.cpp:198] Scale20 needs backward computation.
I1007 15:08:43.535760  4982 net.cpp:198] BatchNorm20 needs backward computation.
I1007 15:08:43.535763  4982 net.cpp:198] Convolution20 needs backward computation.
I1007 15:08:43.535764  4982 net.cpp:198] penlu18 needs backward computation.
I1007 15:08:43.535768  4982 net.cpp:198] Scale19 needs backward computation.
I1007 15:08:43.535769  4982 net.cpp:198] BatchNorm19 needs backward computation.
I1007 15:08:43.535771  4982 net.cpp:198] Convolution19 needs backward computation.
I1007 15:08:43.535773  4982 net.cpp:198] Eltwise8_penlu17_0_split needs backward computation.
I1007 15:08:43.535775  4982 net.cpp:198] penlu17 needs backward computation.
I1007 15:08:43.535778  4982 net.cpp:198] Eltwise8 needs backward computation.
I1007 15:08:43.535780  4982 net.cpp:198] Scale18 needs backward computation.
I1007 15:08:43.535782  4982 net.cpp:198] BatchNorm18 needs backward computation.
I1007 15:08:43.535787  4982 net.cpp:198] Convolution18 needs backward computation.
I1007 15:08:43.535790  4982 net.cpp:198] penlu16 needs backward computation.
I1007 15:08:43.535792  4982 net.cpp:198] Scale17 needs backward computation.
I1007 15:08:43.535794  4982 net.cpp:198] BatchNorm17 needs backward computation.
I1007 15:08:43.535796  4982 net.cpp:198] Convolution17 needs backward computation.
I1007 15:08:43.535799  4982 net.cpp:198] Eltwise7_penlu15_0_split needs backward computation.
I1007 15:08:43.535801  4982 net.cpp:198] penlu15 needs backward computation.
I1007 15:08:43.535804  4982 net.cpp:198] Eltwise7 needs backward computation.
I1007 15:08:43.535805  4982 net.cpp:198] Scale16 needs backward computation.
I1007 15:08:43.535809  4982 net.cpp:198] BatchNorm16 needs backward computation.
I1007 15:08:43.535809  4982 net.cpp:198] Convolution16 needs backward computation.
I1007 15:08:43.535812  4982 net.cpp:198] penlu14 needs backward computation.
I1007 15:08:43.535815  4982 net.cpp:198] Scale15 needs backward computation.
I1007 15:08:43.535816  4982 net.cpp:198] BatchNorm15 needs backward computation.
I1007 15:08:43.535818  4982 net.cpp:198] Convolution15 needs backward computation.
I1007 15:08:43.535821  4982 net.cpp:198] Eltwise6_penlu13_0_split needs backward computation.
I1007 15:08:43.535823  4982 net.cpp:198] penlu13 needs backward computation.
I1007 15:08:43.535825  4982 net.cpp:198] Eltwise6 needs backward computation.
I1007 15:08:43.535828  4982 net.cpp:198] Scale14 needs backward computation.
I1007 15:08:43.535830  4982 net.cpp:198] BatchNorm14 needs backward computation.
I1007 15:08:43.535832  4982 net.cpp:198] Convolution14 needs backward computation.
I1007 15:08:43.535835  4982 net.cpp:198] penlu12 needs backward computation.
I1007 15:08:43.535836  4982 net.cpp:198] Scale13 needs backward computation.
I1007 15:08:43.535838  4982 net.cpp:198] BatchNorm13 needs backward computation.
I1007 15:08:43.535840  4982 net.cpp:198] Convolution13 needs backward computation.
I1007 15:08:43.535843  4982 net.cpp:198] Scale12 needs backward computation.
I1007 15:08:43.535845  4982 net.cpp:198] BatchNorm12 needs backward computation.
I1007 15:08:43.535847  4982 net.cpp:198] Convolution12 needs backward computation.
I1007 15:08:43.535850  4982 net.cpp:198] Eltwise5_penlu11_0_split needs backward computation.
I1007 15:08:43.535851  4982 net.cpp:198] penlu11 needs backward computation.
I1007 15:08:43.535854  4982 net.cpp:198] Eltwise5 needs backward computation.
I1007 15:08:43.535856  4982 net.cpp:198] Scale11 needs backward computation.
I1007 15:08:43.535858  4982 net.cpp:198] BatchNorm11 needs backward computation.
I1007 15:08:43.535861  4982 net.cpp:198] Convolution11 needs backward computation.
I1007 15:08:43.535863  4982 net.cpp:198] penlu10 needs backward computation.
I1007 15:08:43.535866  4982 net.cpp:198] Scale10 needs backward computation.
I1007 15:08:43.535867  4982 net.cpp:198] BatchNorm10 needs backward computation.
I1007 15:08:43.535869  4982 net.cpp:198] Convolution10 needs backward computation.
I1007 15:08:43.535871  4982 net.cpp:198] Eltwise4_penlu9_0_split needs backward computation.
I1007 15:08:43.535874  4982 net.cpp:198] penlu9 needs backward computation.
I1007 15:08:43.535876  4982 net.cpp:198] Eltwise4 needs backward computation.
I1007 15:08:43.535879  4982 net.cpp:198] Scale9 needs backward computation.
I1007 15:08:43.535881  4982 net.cpp:198] BatchNorm9 needs backward computation.
I1007 15:08:43.535883  4982 net.cpp:198] Convolution9 needs backward computation.
I1007 15:08:43.535887  4982 net.cpp:198] penlu8 needs backward computation.
I1007 15:08:43.535888  4982 net.cpp:198] Scale8 needs backward computation.
I1007 15:08:43.535890  4982 net.cpp:198] BatchNorm8 needs backward computation.
I1007 15:08:43.535892  4982 net.cpp:198] Convolution8 needs backward computation.
I1007 15:08:43.535894  4982 net.cpp:198] Eltwise3_penlu7_0_split needs backward computation.
I1007 15:08:43.535897  4982 net.cpp:198] penlu7 needs backward computation.
I1007 15:08:43.535899  4982 net.cpp:198] Eltwise3 needs backward computation.
I1007 15:08:43.535904  4982 net.cpp:198] Scale7 needs backward computation.
I1007 15:08:43.535907  4982 net.cpp:198] BatchNorm7 needs backward computation.
I1007 15:08:43.535909  4982 net.cpp:198] Convolution7 needs backward computation.
I1007 15:08:43.535912  4982 net.cpp:198] penlu6 needs backward computation.
I1007 15:08:43.535913  4982 net.cpp:198] Scale6 needs backward computation.
I1007 15:08:43.535915  4982 net.cpp:198] BatchNorm6 needs backward computation.
I1007 15:08:43.535917  4982 net.cpp:198] Convolution6 needs backward computation.
I1007 15:08:43.535920  4982 net.cpp:198] Eltwise2_penlu5_0_split needs backward computation.
I1007 15:08:43.535923  4982 net.cpp:198] penlu5 needs backward computation.
I1007 15:08:43.535925  4982 net.cpp:198] Eltwise2 needs backward computation.
I1007 15:08:43.535928  4982 net.cpp:198] Scale5 needs backward computation.
I1007 15:08:43.535929  4982 net.cpp:198] BatchNorm5 needs backward computation.
I1007 15:08:43.535933  4982 net.cpp:198] Convolution5 needs backward computation.
I1007 15:08:43.535935  4982 net.cpp:198] penlu4 needs backward computation.
I1007 15:08:43.535938  4982 net.cpp:198] Scale4 needs backward computation.
I1007 15:08:43.535939  4982 net.cpp:198] BatchNorm4 needs backward computation.
I1007 15:08:43.535941  4982 net.cpp:198] Convolution4 needs backward computation.
I1007 15:08:43.535944  4982 net.cpp:198] Eltwise1_penlu3_0_split needs backward computation.
I1007 15:08:43.535948  4982 net.cpp:198] penlu3 needs backward computation.
I1007 15:08:43.535950  4982 net.cpp:198] Eltwise1 needs backward computation.
I1007 15:08:43.535954  4982 net.cpp:198] Scale3 needs backward computation.
I1007 15:08:43.535956  4982 net.cpp:198] BatchNorm3 needs backward computation.
I1007 15:08:43.535959  4982 net.cpp:198] Convolution3 needs backward computation.
I1007 15:08:43.535961  4982 net.cpp:198] penlu2 needs backward computation.
I1007 15:08:43.535964  4982 net.cpp:198] Scale2 needs backward computation.
I1007 15:08:43.535965  4982 net.cpp:198] BatchNorm2 needs backward computation.
I1007 15:08:43.535967  4982 net.cpp:198] Convolution2 needs backward computation.
I1007 15:08:43.535970  4982 net.cpp:198] Convolution1_penlu1_0_split needs backward computation.
I1007 15:08:43.535972  4982 net.cpp:198] penlu1 needs backward computation.
I1007 15:08:43.535974  4982 net.cpp:198] Scale1 needs backward computation.
I1007 15:08:43.535977  4982 net.cpp:198] BatchNorm1 needs backward computation.
I1007 15:08:43.535979  4982 net.cpp:198] Convolution1 needs backward computation.
I1007 15:08:43.535982  4982 net.cpp:200] Data1 does not need backward computation.
I1007 15:08:43.535984  4982 net.cpp:242] This network produces output SoftmaxWithLoss1
I1007 15:08:43.536036  4982 net.cpp:255] Network initialization done.
I1007 15:08:43.538849  4982 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: /home/x306/caffe/xn/PENLU/neural/resnet/res32/res32_penlu_gauss.prototxt
I1007 15:08:43.538864  4982 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I1007 15:08:43.538872  4982 solver.cpp:172] Creating test net (#0) specified by net file: /home/x306/caffe/xn/PENLU/neural/resnet/res32/res32_penlu_gauss.prototxt
I1007 15:08:43.539041  4982 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer Data1
I1007 15:08:43.539814  4982 net.cpp:51] Initializing net from parameters: 
name: "resnet_cifar10"
state {
  phase: TEST
}
layer {
  name: "Data1"
  type: "Data"
  top: "Data1"
  top: "Data2"
  include {
    phase: TEST
  }
  transform_param {
    mean_file: "/home/x306/caffe/xn/PENLU/data/cifar10/mean.binaryproto"
  }
  data_param {
    source: "/home/x306/caffe/xn/PENLU/data/cifar10/cifar10_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "Convolution1"
  type: "Convolution"
  bottom: "Data1"
  top: "Convolution1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm1"
  type: "BatchNorm"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1"
  type: "Scale"
  bottom: "Convolution1"
  top: "Convolution1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu1"
  type: "PENLU"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution2"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm2"
  type: "BatchNorm"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale2"
  type: "Scale"
  bottom: "Convolution2"
  top: "Convolution2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu2"
  type: "PENLU"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution3"
  type: "Convolution"
  bottom: "Convolution2"
  top: "Convolution3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm3"
  type: "BatchNorm"
  bottom: "Convolution3"
  top: "Convolution3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale3"
  type: "Scale"
  bottom: "Convolution3"
  top: "Convolution3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise1"
  type: "Eltwise"
  bottom: "Convolution1"
  bottom: "Convolution3"
  top: "Eltwise1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu3"
  type: "PENLU"
  bottom: "Eltwise1"
  top: "Eltwise1"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution4"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm4"
  type: "BatchNorm"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale4"
  type: "Scale"
  bottom: "Convolution4"
  top: "Convolution4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu4"
  type: "PENLU"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution5"
  type: "Convolution"
  bottom: "Convolution4"
  top: "Convolution5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm5"
  type: "BatchNorm"
  bottom: "Convolution5"
  top: "Convolution5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale5"
  type: "Scale"
  bottom: "Convolution5"
  top: "Convolution5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise2"
  type: "Eltwise"
  bottom: "Eltwise1"
  bottom: "Convolution5"
  top: "Eltwise2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu5"
  type: "PENLU"
  bottom: "Eltwise2"
  top: "Eltwise2"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution6"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm6"
  type: "BatchNorm"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale6"
  type: "Scale"
  bottom: "Convolution6"
  top: "Convolution6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu6"
  type: "PENLU"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution7"
  type: "Convolution"
  bottom: "Convolution6"
  top: "Convolution7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm7"
  type: "BatchNorm"
  bottom: "Convolution7"
  top: "Convolution7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale7"
  type: "Scale"
  bottom: "Convolution7"
  top: "Convolution7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise3"
  type: "Eltwise"
  bottom: "Eltwise2"
  bottom: "Convolution7"
  top: "Eltwise3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu7"
  type: "PENLU"
  bottom: "Eltwise3"
  top: "Eltwise3"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution8"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm8"
  type: "BatchNorm"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale8"
  type: "Scale"
  bottom: "Convolution8"
  top: "Convolution8"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu8"
  type: "PENLU"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution9"
  type: "Convolution"
  bottom: "Convolution8"
  top: "Convolution9"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm9"
  type: "BatchNorm"
  bottom: "Convolution9"
  top: "Convolution9"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale9"
  type: "Scale"
  bottom: "Convolution9"
  top: "Convolution9"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise4"
  type: "Eltwise"
  bottom: "Eltwise3"
  bottom: "Convolution9"
  top: "Eltwise4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu9"
  type: "PENLU"
  bottom: "Eltwise4"
  top: "Eltwise4"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution10"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution10"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm10"
  type: "BatchNorm"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale10"
  type: "Scale"
  bottom: "Convolution10"
  top: "Convolution10"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu10"
  type: "PENLU"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution11"
  type: "Convolution"
  bottom: "Convolution10"
  top: "Convolution11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm11"
  type: "BatchNorm"
  bottom: "Convolution11"
  top: "Convolution11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale11"
  type: "Scale"
  bottom: "Convolution11"
  top: "Convolution11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise5"
  type: "Eltwise"
  bottom: "Eltwise4"
  bottom: "Convolution11"
  top: "Eltwise5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu11"
  type: "PENLU"
  bottom: "Eltwise5"
  top: "Eltwise5"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution12"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.25
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm12"
  type: "BatchNorm"
  bottom: "Convolution12"
  top: "Convolution12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale12"
  type: "Scale"
  bottom: "Convolution12"
  top: "Convolution12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution13"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution13"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm13"
  type: "BatchNorm"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale13"
  type: "Scale"
  bottom: "Convolution13"
  top: "Convolution13"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu12"
  type: "PENLU"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution14"
  type: "Convolution"
  bottom: "Convolution13"
  top: "Convolution14"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm14"
  type: "BatchNorm"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale14"
  type: "Scale"
  bottom: "Convolution14"
  top: "Convolution14"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise6"
  type: "Eltwise"
  bottom: "Convolution12"
  bottom: "Convolution14"
  top: "Eltwise6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu13"
  type: "PENLU"
  bottom: "Eltwise6"
  top: "Eltwise6"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution15"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution15"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm15"
  type: "BatchNorm"
  bottom: "Convolution15"
  top: "Convolution15"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale15"
  type: "Scale"
  bottom: "Convolution15"
  top: "Convolution15"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu14"
  type: "PENLU"
  bottom: "Convolution15"
  top: "Convolution15"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution16"
  type: "Convolution"
  bottom: "Convolution15"
  top: "Convolution16"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm16"
  type: "BatchNorm"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale16"
  type: "Scale"
  bottom: "Convolution16"
  top: "Convolution16"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise7"
  type: "Eltwise"
  bottom: "Eltwise6"
  bottom: "Convolution16"
  top: "Eltwise7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu15"
  type: "PENLU"
  bottom: "Eltwise7"
  top: "Eltwise7"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution17"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution17"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm17"
  type: "BatchNorm"
  bottom: "Convolution17"
  top: "Convolution17"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale17"
  type: "Scale"
  bottom: "Convolution17"
  top: "Convolution17"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu16"
  type: "PENLU"
  bottom: "Convolution17"
  top: "Convolution17"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution18"
  type: "Convolution"
  bottom: "Convolution17"
  top: "Convolution18"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm18"
  type: "BatchNorm"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale18"
  type: "Scale"
  bottom: "Convolution18"
  top: "Convolution18"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise8"
  type: "Eltwise"
  bottom: "Eltwise7"
  bottom: "Convolution18"
  top: "Eltwise8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu17"
  type: "PENLU"
  bottom: "Eltwise8"
  top: "Eltwise8"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution19"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution19"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm19"
  type: "BatchNorm"
  bottom: "Convolution19"
  top: "Convolution19"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale19"
  type: "Scale"
  bottom: "Convolution19"
  top: "Convolution19"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu18"
  type: "PENLU"
  bottom: "Convolution19"
  top: "Convolution19"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution20"
  type: "Convolution"
  bottom: "Convolution19"
  top: "Convolution20"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm20"
  type: "BatchNorm"
  bottom: "Convolution20"
  top: "Convolution20"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale20"
  type: "Scale"
  bottom: "Convolution20"
  top: "Convolution20"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise9"
  type: "Eltwise"
  bottom: "Eltwise8"
  bottom: "Convolution20"
  top: "Eltwise9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu19"
  type: "PENLU"
  bottom: "Eltwise9"
  top: "Eltwise9"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution21"
  type: "Convolution"
  bottom: "Eltwise9"
  top: "Convolution21"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm21"
  type: "BatchNorm"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale21"
  type: "Scale"
  bottom: "Convolution21"
  top: "Convolution21"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu20"
  type: "PENLU"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution22"
  type: "Convolution"
  bottom: "Convolution21"
  top: "Convolution22"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm22"
  type: "BatchNorm"
  bottom: "Convolution22"
  top: "Convolution22"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale22"
  type: "Scale"
  bottom: "Convolution22"
  top: "Convolution22"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise10"
  type: "Eltwise"
  bottom: "Eltwise9"
  bottom: "Convolution22"
  top: "Eltwise10"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu21"
  type: "PENLU"
  bottom: "Eltwise10"
  top: "Eltwise10"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution23"
  type: "Convolution"
  bottom: "Eltwise10"
  top: "Convolution23"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.17677669
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm23"
  type: "BatchNorm"
  bottom: "Convolution23"
  top: "Convolution23"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale23"
  type: "Scale"
  bottom: "Convolution23"
  top: "Convolution23"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution24"
  type: "Convolution"
  bottom: "Eltwise10"
  top: "Convolution24"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm24"
  type: "BatchNorm"
  bottom: "Convolution24"
  top: "Convolution24"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale24"
  type: "Scale"
  bottom: "Convolution24"
  top: "Convolution24"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu22"
  type: "PENLU"
 
I1007 15:08:43.540355  4982 layer_factory.hpp:77] Creating layer Data1
I1007 15:08:43.567306  4982 db_lmdb.cpp:35] Opened lmdb /home/x306/caffe/xn/PENLU/data/cifar10/cifar10_test_lmdb
I1007 15:08:43.567320  4982 net.cpp:84] Creating Layer Data1
I1007 15:08:43.567325  4982 net.cpp:380] Data1 -> Data1
I1007 15:08:43.567332  4982 net.cpp:380] Data1 -> Data2
I1007 15:08:43.567338  4982 data_transformer.cpp:25] Loading mean file from: /home/x306/caffe/xn/PENLU/data/cifar10/mean.binaryproto
I1007 15:08:43.567483  4982 data_layer.cpp:45] output data size: 100,3,32,32
I1007 15:08:43.572548  4982 net.cpp:122] Setting up Data1
I1007 15:08:43.572567  4982 net.cpp:129] Top shape: 100 3 32 32 (307200)
I1007 15:08:43.572572  4982 net.cpp:129] Top shape: 100 (100)
I1007 15:08:43.572574  4982 net.cpp:137] Memory required for data: 1229200
I1007 15:08:43.572579  4982 layer_factory.hpp:77] Creating layer Data2_Data1_1_split
I1007 15:08:43.572588  4982 net.cpp:84] Creating Layer Data2_Data1_1_split
I1007 15:08:43.572592  4982 net.cpp:406] Data2_Data1_1_split <- Data2
I1007 15:08:43.572595  4982 net.cpp:380] Data2_Data1_1_split -> Data2_Data1_1_split_0
I1007 15:08:43.572602  4982 net.cpp:380] Data2_Data1_1_split -> Data2_Data1_1_split_1
I1007 15:08:43.572662  4982 net.cpp:122] Setting up Data2_Data1_1_split
I1007 15:08:43.572676  4982 net.cpp:129] Top shape: 100 (100)
I1007 15:08:43.572679  4982 net.cpp:129] Top shape: 100 (100)
I1007 15:08:43.572681  4982 net.cpp:137] Memory required for data: 1230000
I1007 15:08:43.572692  4982 layer_factory.hpp:77] Creating layer Convolution1
I1007 15:08:43.572703  4982 net.cpp:84] Creating Layer Convolution1
I1007 15:08:43.572705  4982 net.cpp:406] Convolution1 <- Data1
I1007 15:08:43.572710  4982 net.cpp:380] Convolution1 -> Convolution1
I1007 15:08:43.573916  4982 net.cpp:122] Setting up Convolution1
I1007 15:08:43.573925  4982 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 15:08:43.573928  4982 net.cpp:137] Memory required for data: 7783600
I1007 15:08:43.573936  4982 layer_factory.hpp:77] Creating layer BatchNorm1
I1007 15:08:43.573942  4982 net.cpp:84] Creating Layer BatchNorm1
I1007 15:08:43.573946  4982 net.cpp:406] BatchNorm1 <- Convolution1
I1007 15:08:43.573951  4982 net.cpp:367] BatchNorm1 -> Convolution1 (in-place)
I1007 15:08:43.574092  4982 net.cpp:122] Setting up BatchNorm1
I1007 15:08:43.574096  4982 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 15:08:43.574100  4982 net.cpp:137] Memory required for data: 14337200
I1007 15:08:43.574106  4982 layer_factory.hpp:77] Creating layer Scale1
I1007 15:08:43.574112  4982 net.cpp:84] Creating Layer Scale1
I1007 15:08:43.574115  4982 net.cpp:406] Scale1 <- Convolution1
I1007 15:08:43.574118  4982 net.cpp:367] Scale1 -> Convolution1 (in-place)
I1007 15:08:43.574147  4982 layer_factory.hpp:77] Creating layer Scale1
I1007 15:08:43.574229  4982 net.cpp:122] Setting up Scale1
I1007 15:08:43.574234  4982 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 15:08:43.574236  4982 net.cpp:137] Memory required for data: 20890800
I1007 15:08:43.574240  4982 layer_factory.hpp:77] Creating layer penlu1
I1007 15:08:43.574247  4982 net.cpp:84] Creating Layer penlu1
I1007 15:08:43.574250  4982 net.cpp:406] penlu1 <- Convolution1
I1007 15:08:43.574254  4982 net.cpp:367] penlu1 -> Convolution1 (in-place)
I1007 15:08:43.574376  4982 net.cpp:122] Setting up penlu1
I1007 15:08:43.574380  4982 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 15:08:43.574393  4982 net.cpp:137] Memory required for data: 27444400
I1007 15:08:43.574399  4982 layer_factory.hpp:77] Creating layer Convolution1_penlu1_0_split
I1007 15:08:43.574405  4982 net.cpp:84] Creating Layer Convolution1_penlu1_0_split
I1007 15:08:43.574407  4982 net.cpp:406] Convolution1_penlu1_0_split <- Convolution1
I1007 15:08:43.574411  4982 net.cpp:380] Convolution1_penlu1_0_split -> Convolution1_penlu1_0_split_0
I1007 15:08:43.574416  4982 net.cpp:380] Convolution1_penlu1_0_split -> Convolution1_penlu1_0_split_1
I1007 15:08:43.574442  4982 net.cpp:122] Setting up Convolution1_penlu1_0_split
I1007 15:08:43.574445  4982 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 15:08:43.574448  4982 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 15:08:43.574450  4982 net.cpp:137] Memory required for data: 40551600
I1007 15:08:43.574457  4982 layer_factory.hpp:77] Creating layer Convolution2
I1007 15:08:43.574465  4982 net.cpp:84] Creating Layer Convolution2
I1007 15:08:43.574467  4982 net.cpp:406] Convolution2 <- Convolution1_penlu1_0_split_0
I1007 15:08:43.574471  4982 net.cpp:380] Convolution2 -> Convolution2
I1007 15:08:43.575580  4982 net.cpp:122] Setting up Convolution2
I1007 15:08:43.575589  4982 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 15:08:43.575593  4982 net.cpp:137] Memory required for data: 47105200
I1007 15:08:43.575598  4982 layer_factory.hpp:77] Creating layer BatchNorm2
I1007 15:08:43.575604  4982 net.cpp:84] Creating Layer BatchNorm2
I1007 15:08:43.575606  4982 net.cpp:406] BatchNorm2 <- Convolution2
I1007 15:08:43.575611  4982 net.cpp:367] BatchNorm2 -> Convolution2 (in-place)
I1007 15:08:43.575753  4982 net.cpp:122] Setting up BatchNorm2
I1007 15:08:43.575757  4982 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 15:08:43.575759  4982 net.cpp:137] Memory required for data: 53658800
I1007 15:08:43.575764  4982 layer_factory.hpp:77] Creating layer Scale2
I1007 15:08:43.575768  4982 net.cpp:84] Creating Layer Scale2
I1007 15:08:43.575772  4982 net.cpp:406] Scale2 <- Convolution2
I1007 15:08:43.575774  4982 net.cpp:367] Scale2 -> Convolution2 (in-place)
I1007 15:08:43.575804  4982 layer_factory.hpp:77] Creating layer Scale2
I1007 15:08:43.575884  4982 net.cpp:122] Setting up Scale2
I1007 15:08:43.575888  4982 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 15:08:43.575891  4982 net.cpp:137] Memory required for data: 60212400
I1007 15:08:43.575898  4982 layer_factory.hpp:77] Creating layer penlu2
I1007 15:08:43.575904  4982 net.cpp:84] Creating Layer penlu2
I1007 15:08:43.575907  4982 net.cpp:406] penlu2 <- Convolution2
I1007 15:08:43.575911  4982 net.cpp:367] penlu2 -> Convolution2 (in-place)
I1007 15:08:43.576032  4982 net.cpp:122] Setting up penlu2
I1007 15:08:43.576037  4982 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 15:08:43.576040  4982 net.cpp:137] Memory required for data: 66766000
I1007 15:08:43.576043  4982 layer_factory.hpp:77] Creating layer Convolution3
I1007 15:08:43.576050  4982 net.cpp:84] Creating Layer Convolution3
I1007 15:08:43.576053  4982 net.cpp:406] Convolution3 <- Convolution2
I1007 15:08:43.576057  4982 net.cpp:380] Convolution3 -> Convolution3
I1007 15:08:43.577129  4982 net.cpp:122] Setting up Convolution3
I1007 15:08:43.577142  4982 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 15:08:43.577143  4982 net.cpp:137] Memory required for data: 73319600
I1007 15:08:43.577153  4982 layer_factory.hpp:77] Creating layer BatchNorm3
I1007 15:08:43.577158  4982 net.cpp:84] Creating Layer BatchNorm3
I1007 15:08:43.577162  4982 net.cpp:406] BatchNorm3 <- Convolution3
I1007 15:08:43.577167  4982 net.cpp:367] BatchNorm3 -> Convolution3 (in-place)
I1007 15:08:43.577308  4982 net.cpp:122] Setting up BatchNorm3
I1007 15:08:43.577313  4982 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 15:08:43.577316  4982 net.cpp:137] Memory required for data: 79873200
I1007 15:08:43.577323  4982 layer_factory.hpp:77] Creating layer Scale3
I1007 15:08:43.577327  4982 net.cpp:84] Creating Layer Scale3
I1007 15:08:43.577337  4982 net.cpp:406] Scale3 <- Convolution3
I1007 15:08:43.577342  4982 net.cpp:367] Scale3 -> Convolution3 (in-place)
I1007 15:08:43.577371  4982 layer_factory.hpp:77] Creating layer Scale3
I1007 15:08:43.577453  4982 net.cpp:122] Setting up Scale3
I1007 15:08:43.577457  4982 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 15:08:43.577460  4982 net.cpp:137] Memory required for data: 86426800
I1007 15:08:43.577463  4982 layer_factory.hpp:77] Creating layer Eltwise1
I1007 15:08:43.577468  4982 net.cpp:84] Creating Layer Eltwise1
I1007 15:08:43.577471  4982 net.cpp:406] Eltwise1 <- Convolution1_penlu1_0_split_1
I1007 15:08:43.577473  4982 net.cpp:406] Eltwise1 <- Convolution3
I1007 15:08:43.577479  4982 net.cpp:380] Eltwise1 -> Eltwise1
I1007 15:08:43.577497  4982 net.cpp:122] Setting up Eltwise1
I1007 15:08:43.577502  4982 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 15:08:43.577503  4982 net.cpp:137] Memory required for data: 92980400
I1007 15:08:43.577505  4982 layer_factory.hpp:77] Creating layer penlu3
I1007 15:08:43.577512  4982 net.cpp:84] Creating Layer penlu3
I1007 15:08:43.577513  4982 net.cpp:406] penlu3 <- Eltwise1
I1007 15:08:43.577518  4982 net.cpp:367] penlu3 -> Eltwise1 (in-place)
I1007 15:08:43.577638  4982 net.cpp:122] Setting up penlu3
I1007 15:08:43.577642  4982 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 15:08:43.577644  4982 net.cpp:137] Memory required for data: 99534000
I1007 15:08:43.577649  4982 layer_factory.hpp:77] Creating layer Eltwise1_penlu3_0_split
I1007 15:08:43.577653  4982 net.cpp:84] Creating Layer Eltwise1_penlu3_0_split
I1007 15:08:43.577656  4982 net.cpp:406] Eltwise1_penlu3_0_split <- Eltwise1
I1007 15:08:43.577661  4982 net.cpp:380] Eltwise1_penlu3_0_split -> Eltwise1_penlu3_0_split_0
I1007 15:08:43.577664  4982 net.cpp:380] Eltwise1_penlu3_0_split -> Eltwise1_penlu3_0_split_1
I1007 15:08:43.577687  4982 net.cpp:122] Setting up Eltwise1_penlu3_0_split
I1007 15:08:43.577692  4982 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 15:08:43.577694  4982 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 15:08:43.577697  4982 net.cpp:137] Memory required for data: 112641200
I1007 15:08:43.577698  4982 layer_factory.hpp:77] Creating layer Convolution4
I1007 15:08:43.577706  4982 net.cpp:84] Creating Layer Convolution4
I1007 15:08:43.577709  4982 net.cpp:406] Convolution4 <- Eltwise1_penlu3_0_split_0
I1007 15:08:43.577713  4982 net.cpp:380] Convolution4 -> Convolution4
I1007 15:08:43.578825  4982 net.cpp:122] Setting up Convolution4
I1007 15:08:43.578835  4982 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 15:08:43.578837  4982 net.cpp:137] Memory required for data: 119194800
I1007 15:08:43.578842  4982 layer_factory.hpp:77] Creating layer BatchNorm4
I1007 15:08:43.578847  4982 net.cpp:84] Creating Layer BatchNorm4
I1007 15:08:43.578850  4982 net.cpp:406] BatchNorm4 <- Convolution4
I1007 15:08:43.578855  4982 net.cpp:367] BatchNorm4 -> Convolution4 (in-place)
I1007 15:08:43.578995  4982 net.cpp:122] Setting up BatchNorm4
I1007 15:08:43.579000  4982 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 15:08:43.579002  4982 net.cpp:137] Memory required for data: 125748400
I1007 15:08:43.579011  4982 layer_factory.hpp:77] Creating layer Scale4
I1007 15:08:43.579015  4982 net.cpp:84] Creating Layer Scale4
I1007 15:08:43.579017  4982 net.cpp:406] Scale4 <- Convolution4
I1007 15:08:43.579025  4982 net.cpp:367] Scale4 -> Convolution4 (in-place)
I1007 15:08:43.579056  4982 layer_factory.hpp:77] Creating layer Scale4
I1007 15:08:43.579135  4982 net.cpp:122] Setting up Scale4
I1007 15:08:43.579140  4982 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 15:08:43.579143  4982 net.cpp:137] Memory required for data: 132302000
I1007 15:08:43.579146  4982 layer_factory.hpp:77] Creating layer penlu4
I1007 15:08:43.579152  4982 net.cpp:84] Creating Layer penlu4
I1007 15:08:43.579154  4982 net.cpp:406] penlu4 <- Convolution4
I1007 15:08:43.579159  4982 net.cpp:367] penlu4 -> Convolution4 (in-place)
I1007 15:08:43.579293  4982 net.cpp:122] Setting up penlu4
I1007 15:08:43.579308  4982 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 15:08:43.579314  4982 net.cpp:137] Memory required for data: 138855600
I1007 15:08:43.579319  4982 layer_factory.hpp:77] Creating layer Convolution5
I1007 15:08:43.579326  4982 net.cpp:84] Creating Layer Convolution5
I1007 15:08:43.579329  4982 net.cpp:406] Convolution5 <- Convolution4
I1007 15:08:43.579334  4982 net.cpp:380] Convolution5 -> Convolution5
I1007 15:08:43.580309  4982 net.cpp:122] Setting up Convolution5
I1007 15:08:43.580318  4982 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 15:08:43.580320  4982 net.cpp:137] Memory required for data: 145409200
I1007 15:08:43.580325  4982 layer_factory.hpp:77] Creating layer BatchNorm5
I1007 15:08:43.580330  4982 net.cpp:84] Creating Layer BatchNorm5
I1007 15:08:43.580332  4982 net.cpp:406] BatchNorm5 <- Convolution5
I1007 15:08:43.580338  4982 net.cpp:367] BatchNorm5 -> Convolution5 (in-place)
I1007 15:08:43.580479  4982 net.cpp:122] Setting up BatchNorm5
I1007 15:08:43.580484  4982 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 15:08:43.580487  4982 net.cpp:137] Memory required for data: 151962800
I1007 15:08:43.580492  4982 layer_factory.hpp:77] Creating layer Scale5
I1007 15:08:43.580495  4982 net.cpp:84] Creating Layer Scale5
I1007 15:08:43.580498  4982 net.cpp:406] Scale5 <- Convolution5
I1007 15:08:43.580502  4982 net.cpp:367] Scale5 -> Convolution5 (in-place)
I1007 15:08:43.580530  4982 layer_factory.hpp:77] Creating layer Scale5
I1007 15:08:43.580610  4982 net.cpp:122] Setting up Scale5
I1007 15:08:43.580615  4982 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 15:08:43.580616  4982 net.cpp:137] Memory required for data: 158516400
I1007 15:08:43.580621  4982 layer_factory.hpp:77] Creating layer Eltwise2
I1007 15:08:43.580624  4982 net.cpp:84] Creating Layer Eltwise2
I1007 15:08:43.580627  4982 net.cpp:406] Eltwise2 <- Eltwise1_penlu3_0_split_1
I1007 15:08:43.580631  4982 net.cpp:406] Eltwise2 <- Convolution5
I1007 15:08:43.580633  4982 net.cpp:380] Eltwise2 -> Eltwise2
I1007 15:08:43.580651  4982 net.cpp:122] Setting up Eltwise2
I1007 15:08:43.580654  4982 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 15:08:43.580657  4982 net.cpp:137] Memory required for data: 165070000
I1007 15:08:43.580658  4982 layer_factory.hpp:77] Creating layer penlu5
I1007 15:08:43.580663  4982 net.cpp:84] Creating Layer penlu5
I1007 15:08:43.580665  4982 net.cpp:406] penlu5 <- Eltwise2
I1007 15:08:43.580669  4982 net.cpp:367] penlu5 -> Eltwise2 (in-place)
I1007 15:08:43.580791  4982 net.cpp:122] Setting up penlu5
I1007 15:08:43.580796  4982 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 15:08:43.580798  4982 net.cpp:137] Memory required for data: 171623600
I1007 15:08:43.580802  4982 layer_factory.hpp:77] Creating layer Eltwise2_penlu5_0_split
I1007 15:08:43.580806  4982 net.cpp:84] Creating Layer Eltwise2_penlu5_0_split
I1007 15:08:43.580808  4982 net.cpp:406] Eltwise2_penlu5_0_split <- Eltwise2
I1007 15:08:43.580812  4982 net.cpp:380] Eltwise2_penlu5_0_split -> Eltwise2_penlu5_0_split_0
I1007 15:08:43.580816  4982 net.cpp:380] Eltwise2_penlu5_0_split -> Eltwise2_penlu5_0_split_1
I1007 15:08:43.580842  4982 net.cpp:122] Setting up Eltwise2_penlu5_0_split
I1007 15:08:43.580847  4982 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 15:08:43.580850  4982 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 15:08:43.580852  4982 net.cpp:137] Memory required for data: 184730800
I1007 15:08:43.580854  4982 layer_factory.hpp:77] Creating layer Convolution6
I1007 15:08:43.580859  4982 net.cpp:84] Creating Layer Convolution6
I1007 15:08:43.580862  4982 net.cpp:406] Convolution6 <- Eltwise2_penlu5_0_split_0
I1007 15:08:43.580866  4982 net.cpp:380] Convolution6 -> Convolution6
I1007 15:08:43.581802  4982 net.cpp:122] Setting up Convolution6
I1007 15:08:43.581810  4982 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 15:08:43.581814  4982 net.cpp:137] Memory required for data: 191284400
I1007 15:08:43.581817  4982 layer_factory.hpp:77] Creating layer BatchNorm6
I1007 15:08:43.581830  4982 net.cpp:84] Creating Layer BatchNorm6
I1007 15:08:43.581832  4982 net.cpp:406] BatchNorm6 <- Convolution6
I1007 15:08:43.581836  4982 net.cpp:367] BatchNorm6 -> Convolution6 (in-place)
I1007 15:08:43.581980  4982 net.cpp:122] Setting up BatchNorm6
I1007 15:08:43.581984  4982 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 15:08:43.581986  4982 net.cpp:137] Memory required for data: 197838000
I1007 15:08:43.581991  4982 layer_factory.hpp:77] Creating layer Scale6
I1007 15:08:43.581996  4982 net.cpp:84] Creating Layer Scale6
I1007 15:08:43.581998  4982 net.cpp:406] Scale6 <- Convolution6
I1007 15:08:43.598942  4982 net.cpp:367] Scale6 -> Convolution6 (in-place)
I1007 15:08:43.598992  4982 layer_factory.hpp:77] Creating layer Scale6
I1007 15:08:43.599086  4982 net.cpp:122] Setting up Scale6
I1007 15:08:43.599092  4982 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 15:08:43.599094  4982 net.cpp:137] Memory required for data: 204391600
I1007 15:08:43.599099  4982 layer_factory.hpp:77] Creating layer penlu6
I1007 15:08:43.599105  4982 net.cpp:84] Creating Layer penlu6
I1007 15:08:43.599108  4982 net.cpp:406] penlu6 <- Convolution6
I1007 15:08:43.599112  4982 net.cpp:367] penlu6 -> Convolution6 (in-place)
I1007 15:08:43.599264  4982 net.cpp:122] Setting up penlu6
I1007 15:08:43.599270  4982 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 15:08:43.599272  4982 net.cpp:137] Memory required for data: 210945200
I1007 15:08:43.599277  4982 layer_factory.hpp:77] Creating layer Convolution7
I1007 15:08:43.599284  4982 net.cpp:84] Creating Layer Convolution7
I1007 15:08:43.599287  4982 net.cpp:406] Convolution7 <- Convolution6
I1007 15:08:43.599290  4982 net.cpp:380] Convolution7 -> Convolution7
I1007 15:08:43.600265  4982 net.cpp:122] Setting up Convolution7
I1007 15:08:43.600275  4982 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 15:08:43.600277  4982 net.cpp:137] Memory required for data: 217498800
I1007 15:08:43.600281  4982 layer_factory.hpp:77] Creating layer BatchNorm7
I1007 15:08:43.600289  4982 net.cpp:84] Creating Layer BatchNorm7
I1007 15:08:43.600292  4982 net.cpp:406] BatchNorm7 <- Convolution7
I1007 15:08:43.600296  4982 net.cpp:367] BatchNorm7 -> Convolution7 (in-place)
I1007 15:08:43.600445  4982 net.cpp:122] Setting up BatchNorm7
I1007 15:08:43.600450  4982 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 15:08:43.600452  4982 net.cpp:137] Memory required for data: 224052400
I1007 15:08:43.600462  4982 layer_factory.hpp:77] Creating layer Scale7
I1007 15:08:43.600466  4982 net.cpp:84] Creating Layer Scale7
I1007 15:08:43.600469  4982 net.cpp:406] Scale7 <- Convolution7
I1007 15:08:43.600473  4982 net.cpp:367] Scale7 -> Convolution7 (in-place)
I1007 15:08:43.600504  4982 layer_factory.hpp:77] Creating layer Scale7
I1007 15:08:43.600594  4982 net.cpp:122] Setting up Scale7
I1007 15:08:43.600599  4982 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 15:08:43.600600  4982 net.cpp:137] Memory required for data: 230606000
I1007 15:08:43.600605  4982 layer_factory.hpp:77] Creating layer Eltwise3
I1007 15:08:43.600610  4982 net.cpp:84] Creating Layer Eltwise3
I1007 15:08:43.600612  4982 net.cpp:406] Eltwise3 <- Eltwise2_penlu5_0_split_1
I1007 15:08:43.600615  4982 net.cpp:406] Eltwise3 <- Convolution7
I1007 15:08:43.600618  4982 net.cpp:380] Eltwise3 -> Eltwise3
I1007 15:08:43.600636  4982 net.cpp:122] Setting up Eltwise3
I1007 15:08:43.600639  4982 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 15:08:43.600641  4982 net.cpp:137] Memory required for data: 237159600
I1007 15:08:43.600643  4982 layer_factory.hpp:77] Creating layer penlu7
I1007 15:08:43.600648  4982 net.cpp:84] Creating Layer penlu7
I1007 15:08:43.600651  4982 net.cpp:406] penlu7 <- Eltwise3
I1007 15:08:43.600654  4982 net.cpp:367] penlu7 -> Eltwise3 (in-place)
I1007 15:08:43.600776  4982 net.cpp:122] Setting up penlu7
I1007 15:08:43.600780  4982 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 15:08:43.600782  4982 net.cpp:137] Memory required for data: 243713200
I1007 15:08:43.600786  4982 layer_factory.hpp:77] Creating layer Eltwise3_penlu7_0_split
I1007 15:08:43.600798  4982 net.cpp:84] Creating Layer Eltwise3_penlu7_0_split
I1007 15:08:43.600800  4982 net.cpp:406] Eltwise3_penlu7_0_split <- Eltwise3
I1007 15:08:43.600805  4982 net.cpp:380] Eltwise3_penlu7_0_split -> Eltwise3_penlu7_0_split_0
I1007 15:08:43.600810  4982 net.cpp:380] Eltwise3_penlu7_0_split -> Eltwise3_penlu7_0_split_1
I1007 15:08:43.600834  4982 net.cpp:122] Setting up Eltwise3_penlu7_0_split
I1007 15:08:43.600837  4982 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 15:08:43.600841  4982 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 15:08:43.600842  4982 net.cpp:137] Memory required for data: 256820400
I1007 15:08:43.600845  4982 layer_factory.hpp:77] Creating layer Convolution8
I1007 15:08:43.600852  4982 net.cpp:84] Creating Layer Convolution8
I1007 15:08:43.600854  4982 net.cpp:406] Convolution8 <- Eltwise3_penlu7_0_split_0
I1007 15:08:43.600858  4982 net.cpp:380] Convolution8 -> Convolution8
I1007 15:08:43.602005  4982 net.cpp:122] Setting up Convolution8
I1007 15:08:43.602025  4982 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 15:08:43.602030  4982 net.cpp:137] Memory required for data: 263374000
I1007 15:08:43.602037  4982 layer_factory.hpp:77] Creating layer BatchNorm8
I1007 15:08:43.602046  4982 net.cpp:84] Creating Layer BatchNorm8
I1007 15:08:43.602051  4982 net.cpp:406] BatchNorm8 <- Convolution8
I1007 15:08:43.602056  4982 net.cpp:367] BatchNorm8 -> Convolution8 (in-place)
I1007 15:08:43.602284  4982 net.cpp:122] Setting up BatchNorm8
I1007 15:08:43.602295  4982 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 15:08:43.602300  4982 net.cpp:137] Memory required for data: 269927600
I1007 15:08:43.602308  4982 layer_factory.hpp:77] Creating layer Scale8
I1007 15:08:43.602314  4982 net.cpp:84] Creating Layer Scale8
I1007 15:08:43.602319  4982 net.cpp:406] Scale8 <- Convolution8
I1007 15:08:43.602326  4982 net.cpp:367] Scale8 -> Convolution8 (in-place)
I1007 15:08:43.602372  4982 layer_factory.hpp:77] Creating layer Scale8
I1007 15:08:43.602504  4982 net.cpp:122] Setting up Scale8
I1007 15:08:43.602516  4982 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 15:08:43.602520  4982 net.cpp:137] Memory required for data: 276481200
I1007 15:08:43.602527  4982 layer_factory.hpp:77] Creating layer penlu8
I1007 15:08:43.602535  4982 net.cpp:84] Creating Layer penlu8
I1007 15:08:43.602540  4982 net.cpp:406] penlu8 <- Convolution8
I1007 15:08:43.602546  4982 net.cpp:367] penlu8 -> Convolution8 (in-place)
I1007 15:08:43.602715  4982 net.cpp:122] Setting up penlu8
I1007 15:08:43.602725  4982 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 15:08:43.602727  4982 net.cpp:137] Memory required for data: 283034800
I1007 15:08:43.602732  4982 layer_factory.hpp:77] Creating layer Convolution9
I1007 15:08:43.602741  4982 net.cpp:84] Creating Layer Convolution9
I1007 15:08:43.602744  4982 net.cpp:406] Convolution9 <- Convolution8
I1007 15:08:43.602751  4982 net.cpp:380] Convolution9 -> Convolution9
I1007 15:08:43.604082  4982 net.cpp:122] Setting up Convolution9
I1007 15:08:43.604094  4982 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 15:08:43.604096  4982 net.cpp:137] Memory required for data: 289588400
I1007 15:08:43.604100  4982 layer_factory.hpp:77] Creating layer BatchNorm9
I1007 15:08:43.604106  4982 net.cpp:84] Creating Layer BatchNorm9
I1007 15:08:43.604110  4982 net.cpp:406] BatchNorm9 <- Convolution9
I1007 15:08:43.604113  4982 net.cpp:367] BatchNorm9 -> Convolution9 (in-place)
I1007 15:08:43.604264  4982 net.cpp:122] Setting up BatchNorm9
I1007 15:08:43.604269  4982 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 15:08:43.604271  4982 net.cpp:137] Memory required for data: 296142000
I1007 15:08:43.604275  4982 layer_factory.hpp:77] Creating layer Scale9
I1007 15:08:43.604280  4982 net.cpp:84] Creating Layer Scale9
I1007 15:08:43.604284  4982 net.cpp:406] Scale9 <- Convolution9
I1007 15:08:43.604287  4982 net.cpp:367] Scale9 -> Convolution9 (in-place)
I1007 15:08:43.604316  4982 layer_factory.hpp:77] Creating layer Scale9
I1007 15:08:43.604409  4982 net.cpp:122] Setting up Scale9
I1007 15:08:43.604415  4982 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 15:08:43.604418  4982 net.cpp:137] Memory required for data: 302695600
I1007 15:08:43.604421  4982 layer_factory.hpp:77] Creating layer Eltwise4
I1007 15:08:43.604426  4982 net.cpp:84] Creating Layer Eltwise4
I1007 15:08:43.604430  4982 net.cpp:406] Eltwise4 <- Eltwise3_penlu7_0_split_1
I1007 15:08:43.604434  4982 net.cpp:406] Eltwise4 <- Convolution9
I1007 15:08:43.604436  4982 net.cpp:380] Eltwise4 -> Eltwise4
I1007 15:08:43.604455  4982 net.cpp:122] Setting up Eltwise4
I1007 15:08:43.604460  4982 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 15:08:43.604461  4982 net.cpp:137] Memory required for data: 309249200
I1007 15:08:43.604465  4982 layer_factory.hpp:77] Creating layer penlu9
I1007 15:08:43.604470  4982 net.cpp:84] Creating Layer penlu9
I1007 15:08:43.604472  4982 net.cpp:406] penlu9 <- Eltwise4
I1007 15:08:43.604476  4982 net.cpp:367] penlu9 -> Eltwise4 (in-place)
I1007 15:08:43.604604  4982 net.cpp:122] Setting up penlu9
I1007 15:08:43.604609  4982 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 15:08:43.604611  4982 net.cpp:137] Memory required for data: 315802800
I1007 15:08:43.604615  4982 layer_factory.hpp:77] Creating layer Eltwise4_penlu9_0_split
I1007 15:08:43.604622  4982 net.cpp:84] Creating Layer Eltwise4_penlu9_0_split
I1007 15:08:43.604625  4982 net.cpp:406] Eltwise4_penlu9_0_split <- Eltwise4
I1007 15:08:43.604629  4982 net.cpp:380] Eltwise4_penlu9_0_split -> Eltwise4_penlu9_0_split_0
I1007 15:08:43.604634  4982 net.cpp:380] Eltwise4_penlu9_0_split -> Eltwise4_penlu9_0_split_1
I1007 15:08:43.604670  4982 net.cpp:122] Setting up Eltwise4_penlu9_0_split
I1007 15:08:43.604674  4982 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 15:08:43.604677  4982 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 15:08:43.604689  4982 net.cpp:137] Memory required for data: 328910000
I1007 15:08:43.604692  4982 layer_factory.hpp:77] Creating layer Convolution10
I1007 15:08:43.604697  4982 net.cpp:84] Creating Layer Convolution10
I1007 15:08:43.604701  4982 net.cpp:406] Convolution10 <- Eltwise4_penlu9_0_split_0
I1007 15:08:43.604706  4982 net.cpp:380] Convolution10 -> Convolution10
I1007 15:08:43.605319  4982 net.cpp:122] Setting up Convolution10
I1007 15:08:43.605329  4982 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 15:08:43.605332  4982 net.cpp:137] Memory required for data: 335463600
I1007 15:08:43.605336  4982 layer_factory.hpp:77] Creating layer BatchNorm10
I1007 15:08:43.605341  4982 net.cpp:84] Creating Layer BatchNorm10
I1007 15:08:43.605345  4982 net.cpp:406] BatchNorm10 <- Convolution10
I1007 15:08:43.605350  4982 net.cpp:367] BatchNorm10 -> Convolution10 (in-place)
I1007 15:08:43.605499  4982 net.cpp:122] Setting up BatchNorm10
I1007 15:08:43.605504  4982 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 15:08:43.605506  4982 net.cpp:137] Memory required for data: 342017200
I1007 15:08:43.605510  4982 layer_factory.hpp:77] Creating layer Scale10
I1007 15:08:43.605515  4982 net.cpp:84] Creating Layer Scale10
I1007 15:08:43.605518  4982 net.cpp:406] Scale10 <- Convolution10
I1007 15:08:43.605522  4982 net.cpp:367] Scale10 -> Convolution10 (in-place)
I1007 15:08:43.605551  4982 layer_factory.hpp:77] Creating layer Scale10
I1007 15:08:43.605635  4982 net.cpp:122] Setting up Scale10
I1007 15:08:43.605640  4982 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 15:08:43.605643  4982 net.cpp:137] Memory required for data: 348570800
I1007 15:08:43.605646  4982 layer_factory.hpp:77] Creating layer penlu10
I1007 15:08:43.605653  4982 net.cpp:84] Creating Layer penlu10
I1007 15:08:43.605655  4982 net.cpp:406] penlu10 <- Convolution10
I1007 15:08:43.605659  4982 net.cpp:367] penlu10 -> Convolution10 (in-place)
I1007 15:08:43.605784  4982 net.cpp:122] Setting up penlu10
I1007 15:08:43.605790  4982 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 15:08:43.605792  4982 net.cpp:137] Memory required for data: 355124400
I1007 15:08:43.605803  4982 layer_factory.hpp:77] Creating layer Convolution11
I1007 15:08:43.605811  4982 net.cpp:84] Creating Layer Convolution11
I1007 15:08:43.605815  4982 net.cpp:406] Convolution11 <- Convolution10
I1007 15:08:43.605819  4982 net.cpp:380] Convolution11 -> Convolution11
I1007 15:08:43.606775  4982 net.cpp:122] Setting up Convolution11
I1007 15:08:43.606786  4982 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 15:08:43.606789  4982 net.cpp:137] Memory required for data: 361678000
I1007 15:08:43.606793  4982 layer_factory.hpp:77] Creating layer BatchNorm11
I1007 15:08:43.606801  4982 net.cpp:84] Creating Layer BatchNorm11
I1007 15:08:43.606803  4982 net.cpp:406] BatchNorm11 <- Convolution11
I1007 15:08:43.606807  4982 net.cpp:367] BatchNorm11 -> Convolution11 (in-place)
I1007 15:08:43.606956  4982 net.cpp:122] Setting up BatchNorm11
I1007 15:08:43.606962  4982 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 15:08:43.606964  4982 net.cpp:137] Memory required for data: 368231600
I1007 15:08:43.606969  4982 layer_factory.hpp:77] Creating layer Scale11
I1007 15:08:43.606974  4982 net.cpp:84] Creating Layer Scale11
I1007 15:08:43.606977  4982 net.cpp:406] Scale11 <- Convolution11
I1007 15:08:43.606981  4982 net.cpp:367] Scale11 -> Convolution11 (in-place)
I1007 15:08:43.607010  4982 layer_factory.hpp:77] Creating layer Scale11
I1007 15:08:43.607095  4982 net.cpp:122] Setting up Scale11
I1007 15:08:43.607100  4982 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 15:08:43.607102  4982 net.cpp:137] Memory required for data: 374785200
I1007 15:08:43.607106  4982 layer_factory.hpp:77] Creating layer Eltwise5
I1007 15:08:43.607111  4982 net.cpp:84] Creating Layer Eltwise5
I1007 15:08:43.607115  4982 net.cpp:406] Eltwise5 <- Eltwise4_penlu9_0_split_1
I1007 15:08:43.607118  4982 net.cpp:406] Eltwise5 <- Convolution11
I1007 15:08:43.607121  4982 net.cpp:380] Eltwise5 -> Eltwise5
I1007 15:08:43.607139  4982 net.cpp:122] Setting up Eltwise5
I1007 15:08:43.607144  4982 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 15:08:43.607146  4982 net.cpp:137] Memory required for data: 381338800
I1007 15:08:43.607148  4982 layer_factory.hpp:77] Creating layer penlu11
I1007 15:08:43.607153  4982 net.cpp:84] Creating Layer penlu11
I1007 15:08:43.607157  4982 net.cpp:406] penlu11 <- Eltwise5
I1007 15:08:43.607161  4982 net.cpp:367] penlu11 -> Eltwise5 (in-place)
I1007 15:08:43.607302  4982 net.cpp:122] Setting up penlu11
I1007 15:08:43.607307  4982 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 15:08:43.607309  4982 net.cpp:137] Memory required for data: 387892400
I1007 15:08:43.607324  4982 layer_factory.hpp:77] Creating layer Eltwise5_penlu11_0_split
I1007 15:08:43.607329  4982 net.cpp:84] Creating Layer Eltwise5_penlu11_0_split
I1007 15:08:43.607331  4982 net.cpp:406] Eltwise5_penlu11_0_split <- Eltwise5
I1007 15:08:43.607334  4982 net.cpp:380] Eltwise5_penlu11_0_split -> Eltwise5_penlu11_0_split_0
I1007 15:08:43.607339  4982 net.cpp:380] Eltwise5_penlu11_0_split -> Eltwise5_penlu11_0_split_1
I1007 15:08:43.607374  4982 net.cpp:122] Setting up Eltwise5_penlu11_0_split
I1007 15:08:43.607378  4982 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 15:08:43.607381  4982 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 15:08:43.607383  4982 net.cpp:137] Memory required for data: 400999600
I1007 15:08:43.607386  4982 layer_factory.hpp:77] Creating layer Convolution12
I1007 15:08:43.607393  4982 net.cpp:84] Creating Layer Convolution12
I1007 15:08:43.607395  4982 net.cpp:406] Convolution12 <- Eltwise5_penlu11_0_split_0
I1007 15:08:43.607399  4982 net.cpp:380] Convolution12 -> Convolution12
I1007 15:08:43.608304  4982 net.cpp:122] Setting up Convolution12
I1007 15:08:43.608314  4982 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 15:08:43.608316  4982 net.cpp:137] Memory required for data: 404276400
I1007 15:08:43.608321  4982 layer_factory.hpp:77] Creating layer BatchNorm12
I1007 15:08:43.608327  4982 net.cpp:84] Creating Layer BatchNorm12
I1007 15:08:43.608330  4982 net.cpp:406] BatchNorm12 <- Convolution12
I1007 15:08:43.608351  4982 net.cpp:367] BatchNorm12 -> Convolution12 (in-place)
I1007 15:08:43.608505  4982 net.cpp:122] Setting up BatchNorm12
I1007 15:08:43.608510  4982 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 15:08:43.608513  4982 net.cpp:137] Memory required for data: 407553200
I1007 15:08:43.608528  4982 layer_factory.hpp:77] Creating layer Scale12
I1007 15:08:43.608533  4982 net.cpp:84] Creating Layer Scale12
I1007 15:08:43.608537  4982 net.cpp:406] Scale12 <- Convolution12
I1007 15:08:43.608541  4982 net.cpp:367] Scale12 -> Convolution12 (in-place)
I1007 15:08:43.608572  4982 layer_factory.hpp:77] Creating layer Scale12
I1007 15:08:43.608654  4982 net.cpp:122] Setting up Scale12
I1007 15:08:43.608660  4982 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 15:08:43.608664  4982 net.cpp:137] Memory required for data: 410830000
I1007 15:08:43.608667  4982 layer_factory.hpp:77] Creating layer Convolution13
I1007 15:08:43.608675  4982 net.cpp:84] Creating Layer Convolution13
I1007 15:08:43.608678  4982 net.cpp:406] Convolution13 <- Eltwise5_penlu11_0_split_1
I1007 15:08:43.608682  4982 net.cpp:380] Convolution13 -> Convolution13
I1007 15:08:43.609690  4982 net.cpp:122] Setting up Convolution13
I1007 15:08:43.609701  4982 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 15:08:43.609704  4982 net.cpp:137] Memory required for data: 414106800
I1007 15:08:43.609709  4982 layer_factory.hpp:77] Creating layer BatchNorm13
I1007 15:08:43.609715  4982 net.cpp:84] Creating Layer BatchNorm13
I1007 15:08:43.609719  4982 net.cpp:406] BatchNorm13 <- Convolution13
I1007 15:08:43.609724  4982 net.cpp:367] BatchNorm13 -> Convolution13 (in-place)
I1007 15:08:43.609879  4982 net.cpp:122] Setting up BatchNorm13
I1007 15:08:43.609884  4982 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 15:08:43.609886  4982 net.cpp:137] Memory required for data: 417383600
I1007 15:08:43.609902  4982 layer_factory.hpp:77] Creating layer Scale13
I1007 15:08:43.609907  4982 net.cpp:84] Creating Layer Scale13
I1007 15:08:43.609911  4982 net.cpp:406] Scale13 <- Convolution13
I1007 15:08:43.609915  4982 net.cpp:367] Scale13 -> Convolution13 (in-place)
I1007 15:08:43.609954  4982 layer_factory.hpp:77] Creating layer Scale13
I1007 15:08:43.610057  4982 net.cpp:122] Setting up Scale13
I1007 15:08:43.610062  4982 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 15:08:43.610065  4982 net.cpp:137] Memory required for data: 420660400
I1007 15:08:43.610080  4982 layer_factory.hpp:77] Creating layer penlu12
I1007 15:08:43.610086  4982 net.cpp:84] Creating Layer penlu12
I1007 15:08:43.610090  4982 net.cpp:406] penlu12 <- Convolution13
I1007 15:08:43.610093  4982 net.cpp:367] penlu12 -> Convolution13 (in-place)
I1007 15:08:43.610218  4982 net.cpp:122] Setting up penlu12
I1007 15:08:43.610222  4982 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 15:08:43.610224  4982 net.cpp:137] Memory required for data: 423937200
I1007 15:08:43.610239  4982 layer_factory.hpp:77] Creating layer Convolution14
I1007 15:08:43.610250  4982 net.cpp:84] Creating Layer Convolution14
I1007 15:08:43.610254  4982 net.cpp:406] Convolution14 <- Convolution13
I1007 15:08:43.610257  4982 net.cpp:380] Convolution14 -> Convolution14
I1007 15:08:43.611393  4982 net.cpp:122] Setting up Convolution14
I1007 15:08:43.611403  4982 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 15:08:43.611407  4982 net.cpp:137] Memory required for data: 427214000
I1007 15:08:43.611431  4982 layer_factory.hpp:77] Creating layer BatchNorm14
I1007 15:08:43.611438  4982 net.cpp:84] Creating Layer BatchNorm14
I1007 15:08:43.611441  4982 net.cpp:406] BatchNorm14 <- Convolution14
I1007 15:08:43.611445  4982 net.cpp:367] BatchNorm14 -> Convolution14 (in-place)
I1007 15:08:43.611618  4982 net.cpp:122] Setting up BatchNorm14
I1007 15:08:43.611624  4982 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 15:08:43.611626  4982 net.cpp:137] Memory required for data: 430490800
I1007 15:08:43.611641  4982 layer_factory.hpp:77] Creating layer Scale14
I1007 15:08:43.611645  4982 net.cpp:84] Creating Layer Scale14
I1007 15:08:43.611675  4982 net.cpp:406] Scale14 <- Convolution14
I1007 15:08:43.611681  4982 net.cpp:367] Scale14 -> Convolution14 (in-place)
I1007 15:08:43.611721  4982 layer_factory.hpp:77] Creating layer Scale14
I1007 15:08:43.611821  4982 net.cpp:122] Setting up Scale14
I1007 15:08:43.611826  4982 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 15:08:43.611829  4982 net.cpp:137] Memory required for data: 433767600
I1007 15:08:43.611842  4982 layer_factory.hpp:77] Creating layer Eltwise6
I1007 15:08:43.611846  4982 net.cpp:84] Creating Layer Eltwise6
I1007 15:08:43.611850  4982 net.cpp:406] Eltwise6 <- Convolution12
I1007 15:08:43.611852  4982 net.cpp:406] Eltwise6 <- Convolution14
I1007 15:08:43.611855  4982 net.cpp:380] Eltwise6 -> Eltwise6
I1007 15:08:43.611871  4982 net.cpp:122] Setting up Eltwise6
I1007 15:08:43.611874  4982 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 15:08:43.611876  4982 net.cpp:137] Memory required for data: 437044400
I1007 15:08:43.611888  4982 layer_factory.hpp:77] Creating layer penlu13
I1007 15:08:43.611893  4982 net.cpp:84] Creating Layer penlu13
I1007 15:08:43.611907  4982 net.cpp:406] penlu13 <- Eltwise6
I1007 15:08:43.611909  4982 net.cpp:367] penlu13 -> Eltwise6 (in-place)
I1007 15:08:43.612032  4982 net.cpp:122] Setting up penlu13
I1007 15:08:43.612037  4982 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 15:08:43.612040  4982 net.cpp:137] Memory required for data: 440321200
I1007 15:08:43.612045  4982 layer_factory.hpp:77] Creating layer Eltwise6_penlu13_0_split
I1007 15:08:43.612049  4982 net.cpp:84] Creating Layer Eltwise6_penlu13_0_split
I1007 15:08:43.612052  4982 net.cpp:406] Eltwise6_penlu13_0_split <- Eltwise6
I1007 15:08:43.612056  4982 net.cpp:380] Eltwise6_penlu13_0_split -> Eltwise6_penlu13_0_split_0
I1007 15:08:43.612059  4982 net.cpp:380] Eltwise6_penlu13_0_split -> Eltwise6_penlu13_0_split_1
I1007 15:08:43.612084  4982 net.cpp:122] Setting up Eltwise6_penlu13_0_split
I1007 15:08:43.612089  4982 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 15:08:43.612092  4982 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 15:08:43.612094  4982 net.cpp:137] Memory required for data: 446874800
I1007 15:08:43.612097  4982 layer_factory.hpp:77] Creating layer Convolution15
I1007 15:08:43.612102  4982 net.cpp:84] Creating Layer Convolution15
I1007 15:08:43.612105  4982 net.cpp:406] Convolution15 <- Eltwise6_penlu13_0_split_0
I1007 15:08:43.612109  4982 net.cpp:380] Convolution15 -> Convolution15
I1007 15:08:43.613521  4982 net.cpp:122] Setting up Convolution15
I1007 15:08:43.613531  4982 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 15:08:43.613534  4982 net.cpp:137] Memory required for data: 450151600
I1007 15:08:43.613539  4982 layer_factory.hpp:77] Creating layer BatchNorm15
I1007 15:08:43.613544  4982 net.cpp:84] Creating Layer BatchNorm15
I1007 15:08:43.613548  4982 net.cpp:406] BatchNorm15 <- Convolution15
I1007 15:08:43.613553  4982 net.cpp:367] BatchNorm15 -> Convolution15 (in-place)
I1007 15:08:43.613698  4982 net.cpp:122] Setting up BatchNorm15
I1007 15:08:43.613703  4982 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 15:08:43.613706  4982 net.cpp:137] Memory required for data: 453428400
I1007 15:08:43.613710  4982 layer_factory.hpp:77] Creating layer Scale15
I1007 15:08:43.613715  4982 net.cpp:84] Creating Layer Scale15
I1007 15:08:43.613718  4982 net.cpp:406] Scale15 <- Convolution15
I1007 15:08:43.613723  4982 net.cpp:367] Scale15 -> Convolution15 (in-place)
I1007 15:08:43.613751  4982 layer_factory.hpp:77] Creating layer Scale15
I1007 15:08:43.613836  4982 net.cpp:122] Setting up Scale15
I1007 15:08:43.613840  4982 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 15:08:43.613842  4982 net.cpp:137] Memory required for data: 456705200
I1007 15:08:43.613847  4982 layer_factory.hpp:77] Creating layer penlu14
I1007 15:08:43.613850  4982 net.cpp:84] Creating Layer penlu14
I1007 15:08:43.613854  4982 net.cpp:406] penlu14 <- Convolution15
I1007 15:08:43.613858  4982 net.cpp:367] penlu14 -> Convolution15 (in-place)
I1007 15:08:43.613976  4982 net.cpp:122] Setting up penlu14
I1007 15:08:43.613986  4982 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 15:08:43.613991  4982 net.cpp:137] Memory required for data: 459982000
I1007 15:08:43.613994  4982 layer_factory.hpp:77] Creating layer Convolution16
I1007 15:08:43.614001  4982 net.cpp:84] Creating Layer Convolution16
I1007 15:08:43.614004  4982 net.cpp:406] Convolution16 <- Convolution15
I1007 15:08:43.614009  4982 net.cpp:380] Convolution16 -> Convolution16
I1007 15:08:43.615670  4982 net.cpp:122] Setting up Convolution16
I1007 15:08:43.615681  4982 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 15:08:43.615684  4982 net.cpp:137] Memory required for data: 463258800
I1007 15:08:43.615700  4982 layer_factory.hpp:77] Creating layer BatchNorm16
I1007 15:08:43.615706  4982 net.cpp:84] Creating Layer BatchNorm16
I1007 15:08:43.615710  4982 net.cpp:406] BatchNorm16 <- Convolution16
I1007 15:08:43.615713  4982 net.cpp:367] BatchNorm16 -> Convolution16 (in-place)
I1007 15:08:43.615869  4982 net.cpp:122] Setting up BatchNorm16
I1007 15:08:43.615873  4982 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 15:08:43.615876  4982 net.cpp:137] Memory required for data: 466535600
I1007 15:08:43.615891  4982 layer_factory.hpp:77] Creating layer Scale16
I1007 15:08:43.615896  4982 net.cpp:84] Creating Layer Scale16
I1007 15:08:43.615900  4982 net.cpp:406] Scale16 <- Convolution16
I1007 15:08:43.615903  4982 net.cpp:367] Scale16 -> Convolution16 (in-place)
I1007 15:08:43.615943  4982 layer_factory.hpp:77] Creating layer Scale16
I1007 15:08:43.616027  4982 net.cpp:122] Setting up Scale16
I1007 15:08:43.616032  4982 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 15:08:43.616034  4982 net.cpp:137] Memory required for data: 469812400
I1007 15:08:43.616039  4982 layer_factory.hpp:77] Creating layer Eltwise7
I1007 15:08:43.616044  4982 net.cpp:84] Creating Layer Eltwise7
I1007 15:08:43.616046  4982 net.cpp:406] Eltwise7 <- Eltwise6_penlu13_0_split_1
I1007 15:08:43.616050  4982 net.cpp:406] Eltwise7 <- Convolution16
I1007 15:08:43.616052  4982 net.cpp:380] Eltwise7 -> Eltwise7
I1007 15:08:43.616066  4982 net.cpp:122] Setting up Eltwise7
I1007 15:08:43.616070  4982 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 15:08:43.616072  4982 net.cpp:137] Memory required for data: 473089200
I1007 15:08:43.616075  4982 layer_factory.hpp:77] Creating layer penlu15
I1007 15:08:43.616081  4982 net.cpp:84] Creating Layer penlu15
I1007 15:08:43.616084  4982 net.cpp:406] penlu15 <- Eltwise7
I1007 15:08:43.616087  4982 net.cpp:367] penlu15 -> Eltwise7 (in-place)
I1007 15:08:43.616206  4982 net.cpp:122] Setting up penlu15
I1007 15:08:43.616211  4982 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 15:08:43.616214  4982 net.cpp:137] Memory required for data: 476366000
I1007 15:08:43.616217  4982 layer_factory.hpp:77] Creating layer Eltwise7_penlu15_0_split
I1007 15:08:43.616222  4982 net.cpp:84] Creating Layer Eltwise7_penlu15_0_split
I1007 15:08:43.616225  4982 net.cpp:406] Eltwise7_penlu15_0_split <- Eltwise7
I1007 15:08:43.616228  4982 net.cpp:380] Eltwise7_penlu15_0_split -> Eltwise7_penlu15_0_split_0
I1007 15:08:43.616233  4982 net.cpp:380] Eltwise7_penlu15_0_split -> Eltwise7_penlu15_0_split_1
I1007 15:08:43.616258  4982 net.cpp:122] Setting up Eltwise7_penlu15_0_split
I1007 15:08:43.616263  4982 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 15:08:43.616266  4982 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 15:08:43.616268  4982 net.cpp:137] Memory required for data: 482919600
I1007 15:08:43.616271  4982 layer_factory.hpp:77] Creating layer Convolution17
I1007 15:08:43.616276  4982 net.cpp:84] Creating Layer Convolution17
I1007 15:08:43.616281  4982 net.cpp:406] Convolution17 <- Eltwise7_penlu15_0_split_0
I1007 15:08:43.616293  4982 net.cpp:380] Convolution17 -> Convolution17
I1007 15:08:43.617396  4982 net.cpp:122] Setting up Convolution17
I1007 15:08:43.617406  4982 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 15:08:43.617409  4982 net.cpp:137] Memory required for data: 486196400
I1007 15:08:43.617414  4982 layer_factory.hpp:77] Creating layer BatchNorm17
I1007 15:08:43.617427  4982 net.cpp:84] Creating Layer BatchNorm17
I1007 15:08:43.617431  4982 net.cpp:406] BatchNorm17 <- Convolution17
I1007 15:08:43.617435  4982 net.cpp:367] BatchNorm17 -> Convolution17 (in-place)
I1007 15:08:43.617580  4982 net.cpp:122] Setting up BatchNorm17
I1007 15:08:43.617585  4982 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 15:08:43.617588  4982 net.cpp:137] Memory required for data: 489473200
I1007 15:08:43.617593  4982 layer_factory.hpp:77] Creating layer Scale17
I1007 15:08:43.617597  4982 net.cpp:84] Creating Layer Scale17
I1007 15:08:43.617601  4982 net.cpp:406] Scale17 <- Convolution17
I1007 15:08:43.617604  4982 net.cpp:367] Scale17 -> Convolution17 (in-place)
I1007 15:08:43.617635  4982 layer_factory.hpp:77] Creating layer Scale17
I1007 15:08:43.617717  4982 net.cpp:122] Setting up Scale17
I1007 15:08:43.617722  4982 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 15:08:43.617724  4982 net.cpp:137] Memory required for data: 492750000
I1007 15:08:43.617728  4982 layer_factory.hpp:77] Creating layer penlu16
I1007 15:08:43.617734  4982 net.cpp:84] Creating Layer penlu16
I1007 15:08:43.617738  4982 net.cpp:406] penlu16 <- Convolution17
I1007 15:08:43.617741  4982 net.cpp:367] penlu16 -> Convolution17 (in-place)
I1007 15:08:43.617856  4982 net.cpp:122] Setting up penlu16
I1007 15:08:43.617861  4982 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 15:08:43.617864  4982 net.cpp:137] Memory required for data: 496026800
I1007 15:08:43.617868  4982 layer_factory.hpp:77] Creating layer Convolution18
I1007 15:08:43.617874  4982 net.cpp:84] Creating Layer Convolution18
I1007 15:08:43.617877  4982 net.cpp:406] Convolution18 <- Convolution17
I1007 15:08:43.617882  4982 net.cpp:380] Convolution18 -> Convolution18
I1007 15:08:43.619235  4982 net.cpp:122] Setting up Convolution18
I1007 15:08:43.619251  4982 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 15:08:43.619264  4982 net.cpp:137] Memory required for data: 499303600
I1007 15:08:43.619272  4982 layer_factory.hpp:77] Creating layer BatchNorm18
I1007 15:08:43.619282  4982 net.cpp:84] Creating Layer BatchNorm18
I1007 15:08:43.619287  4982 net.cpp:406] BatchNorm18 <- Convolution18
I1007 15:08:43.619293  4982 net.cpp:367] BatchNorm18 -> Convolution18 (in-place)
I1007 15:08:43.619526  4982 net.cpp:122] Setting up BatchNorm18
I1007 15:08:43.619539  4982 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 15:08:43.619544  4982 net.cpp:137] Memory required for data: 502580400
I1007 15:08:43.619552  4982 layer_factory.hpp:77] Creating layer Scale18
I1007 15:08:43.619561  4982 net.cpp:84] Creating Layer Scale18
I1007 15:08:43.619567  4982 net.cpp:406] Scale18 <- Convolution18
I1007 15:08:43.619585  4982 net.cpp:367] Scale18 -> Convolution18 (in-place)
I1007 15:08:43.619634  4982 layer_factory.hpp:77] Creating layer Scale18
I1007 15:08:43.619736  4982 net.cpp:122] Setting up Scale18
I1007 15:08:43.619743  4982 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 15:08:43.619745  4982 net.cpp:137] Memory required for data: 505857200
I1007 15:08:43.619750  4982 layer_factory.hpp:77] Creating layer Eltwise8
I1007 15:08:43.619755  4982 net.cpp:84] Creating Layer Eltwise8
I1007 15:08:43.619758  4982 net.cpp:406] Eltwise8 <- Eltwise7_penlu15_0_split_1
I1007 15:08:43.619762  4982 net.cpp:406] Eltwise8 <- Convolution18
I1007 15:08:43.619766  4982 net.cpp:380] Eltwise8 -> Eltwise8
I1007 15:08:43.619782  4982 net.cpp:122] Setting up Eltwise8
I1007 15:08:43.619787  4982 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 15:08:43.619789  4982 net.cpp:137] Memory required for data: 509134000
I1007 15:08:43.619791  4982 layer_factory.hpp:77] Creating layer penlu17
I1007 15:08:43.619797  4982 net.cpp:84] Creating Layer penlu17
I1007 15:08:43.619801  4982 net.cpp:406] penlu17 <- Eltwise8
I1007 15:08:43.619804  4982 net.cpp:367] penlu17 -> Eltwise8 (in-place)
I1007 15:08:43.619930  4982 net.cpp:122] Setting up penlu17
I1007 15:08:43.619935  4982 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 15:08:43.619936  4982 net.cpp:137] Memory required for data: 512410800
I1007 15:08:43.619949  4982 layer_factory.hpp:77] Creating layer Eltwise8_penlu17_0_split
I1007 15:08:43.619954  4982 net.cpp:84] Creating Layer Eltwise8_penlu17_0_split
I1007 15:08:43.619957  4982 net.cpp:406] Eltwise8_penlu17_0_split <- Eltwise8
I1007 15:08:43.619961  4982 net.cpp:380] Eltwise8_penlu17_0_split -> Eltwise8_penlu17_0_split_0
I1007 15:08:43.619964  4982 net.cpp:380] Eltwise8_penlu17_0_split -> Eltwise8_penlu17_0_split_1
I1007 15:08:43.620003  4982 net.cpp:122] Setting up Eltwise8_penlu17_0_split
I1007 15:08:43.620008  4982 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 15:08:43.620012  4982 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 15:08:43.620013  4982 net.cpp:137] Memory required for data: 518964400
I1007 15:08:43.620015  4982 layer_factory.hpp:77] Creating layer Convolution19
I1007 15:08:43.620023  4982 net.cpp:84] Creating Layer Convolution19
I1007 15:08:43.620025  4982 net.cpp:406] Convolution19 <- Eltwise8_penlu17_0_split_0
I1007 15:08:43.620039  4982 net.cpp:380] Convolution19 -> Convolution19
I1007 15:08:43.621168  4982 net.cpp:122] Setting up Convolution19
I1007 15:08:43.621178  4982 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 15:08:43.621182  4982 net.cpp:137] Memory required for data: 522241200
I1007 15:08:43.621187  4982 layer_factory.hpp:77] Creating layer BatchNorm19
I1007 15:08:43.621193  4982 net.cpp:84] Creating Layer BatchNorm19
I1007 15:08:43.621196  4982 net.cpp:406] BatchNorm19 <- Convolution19
I1007 15:08:43.621201  4982 net.cpp:367] BatchNorm19 -> Convolution19 (in-place)
I1007 15:08:43.621351  4982 net.cpp:122] Setting up BatchNorm19
I1007 15:08:43.621357  4982 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 15:08:43.621361  4982 net.cpp:137] Memory required for data: 525518000
I1007 15:08:43.621366  4982 layer_factory.hpp:77] Creating layer Scale19
I1007 15:08:43.621369  4982 net.cpp:84] Creating Layer Scale19
I1007 15:08:43.621373  4982 net.cpp:406] Scale19 <- Convolution19
I1007 15:08:43.621376  4982 net.cpp:367] Scale19 -> Convolution19 (in-place)
I1007 15:08:43.621408  4982 layer_factory.hpp:77] Creating layer Scale19
I1007 15:08:43.621496  4982 net.cpp:122] Setting up Scale19
I1007 15:08:43.621502  4982 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 15:08:43.621505  4982 net.cpp:137] Memory required for data: 528794800
I1007 15:08:43.621510  4982 layer_factory.hpp:77] Creating layer penlu18
I1007 15:08:43.621515  4982 net.cpp:84] Creating Layer penlu18
I1007 15:08:43.621517  4982 net.cpp:406] penlu18 <- Convolution19
I1007 15:08:43.621522  4982 net.cpp:367] penlu18 -> Convolution19 (in-place)
I1007 15:08:43.621644  4982 net.cpp:122] Setting up penlu18
I1007 15:08:43.621649  4982 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 15:08:43.621652  4982 net.cpp:137] Memory required for data: 532071600
I1007 15:08:43.621657  4982 layer_factory.hpp:77] Creating layer Convolution20
I1007 15:08:43.621666  4982 net.cpp:84] Creating Layer Convolution20
I1007 15:08:43.621670  4982 net.cpp:406] Convolution20 <- Convolution19
I1007 15:08:43.621673  4982 net.cpp:380] Convolution20 -> Convolution20
I1007 15:08:43.622449  4982 net.cpp:122] Setting up Convolution20
I1007 15:08:43.622458  4982 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 15:08:43.622462  4982 net.cpp:137] Memory required for data: 535348400
I1007 15:08:43.622465  4982 layer_factory.hpp:77] Creating layer BatchNorm20
I1007 15:08:43.622470  4982 net.cpp:84] Creating Layer BatchNorm20
I1007 15:08:43.622473  4982 net.cpp:406] BatchNorm20 <- Convolution20
I1007 15:08:43.622478  4982 net.cpp:367] BatchNorm20 -> Convolution20 (in-place)
I1007 15:08:43.622628  4982 net.cpp:122] Setting up BatchNorm20
I1007 15:08:43.622633  4982 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 15:08:43.622637  4982 net.cpp:137] Memory required for data: 538625200
I1007 15:08:43.622642  4982 layer_factory.hpp:77] Creating layer Scale20
I1007 15:08:43.622647  4982 net.cpp:84] Creating Layer Scale20
I1007 15:08:43.622649  4982 net.cpp:406] Scale20 <- Convolution20
I1007 15:08:43.622659  4982 net.cpp:367] Scale20 -> Convolution20 (in-place)
I1007 15:08:43.622692  4982 layer_factory.hpp:77] Creating layer Scale20
I1007 15:08:43.622779  4982 net.cpp:122] Setting up Scale20
I1007 15:08:43.622784  4982 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 15:08:43.622786  4982 net.cpp:137] Memory required for data: 541902000
I1007 15:08:43.622792  4982 layer_factory.hpp:77] Creating layer Eltwise9
I1007 15:08:43.622797  4982 net.cpp:84] Creating Layer Eltwise9
I1007 15:08:43.622799  4982 net.cpp:406] Eltwise9 <- Eltwise8_penlu17_0_split_1
I1007 15:08:43.622802  4982 net.cpp:406] Eltwise9 <- Convolution20
I1007 15:08:43.622807  4982 net.cpp:380] Eltwise9 -> Eltwise9
I1007 15:08:43.622822  4982 net.cpp:122] Setting up Eltwise9
I1007 15:08:43.622825  4982 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 15:08:43.622828  4982 net.cpp:137] Memory required for data: 545178800
I1007 15:08:43.622831  4982 layer_factory.hpp:77] Creating layer penlu19
I1007 15:08:43.622836  4982 net.cpp:84] Creating Layer penlu19
I1007 15:08:43.622839  4982 net.cpp:406] penlu19 <- Eltwise9
I1007 15:08:43.622844  4982 net.cpp:367] penlu19 -> Eltwise9 (in-place)
I1007 15:08:43.622969  4982 net.cpp:122] Setting up penlu19
I1007 15:08:43.622974  4982 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 15:08:43.622977  4982 net.cpp:137] Memory required for data: 548455600
I1007 15:08:43.622982  4982 layer_factory.hpp:77] Creating layer Eltwise9_penlu19_0_split
I1007 15:08:43.622985  4982 net.cpp:84] Creating Layer Eltwise9_penlu19_0_split
I1007 15:08:43.622989  4982 net.cpp:406] Eltwise9_penlu19_0_split <- Eltwise9
I1007 15:08:43.622993  4982 net.cpp:380] Eltwise9_penlu19_0_split -> Eltwise9_penlu19_0_split_0
I1007 15:08:43.622998  4982 net.cpp:380] Eltwise9_penlu19_0_split -> Eltwise9_penlu19_0_split_1
I1007 15:08:43.623024  4982 net.cpp:122] Setting up Eltwise9_penlu19_0_split
I1007 15:08:43.623029  4982 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 15:08:43.623033  4982 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 15:08:43.623034  4982 net.cpp:137] Memory required for data: 555009200
I1007 15:08:43.623036  4982 layer_factory.hpp:77] Creating layer Convolution21
I1007 15:08:43.623042  4982 net.cpp:84] Creating Layer Convolution21
I1007 15:08:43.623046  4982 net.cpp:406] Convolution21 <- Eltwise9_penlu19_0_split_0
I1007 15:08:43.623050  4982 net.cpp:380] Convolution21 -> Convolution21
I1007 15:08:43.624182  4982 net.cpp:122] Setting up Convolution21
I1007 15:08:43.624192  4982 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 15:08:43.624197  4982 net.cpp:137] Memory required for data: 558286000
I1007 15:08:43.624200  4982 layer_factory.hpp:77] Creating layer BatchNorm21
I1007 15:08:43.624207  4982 net.cpp:84] Creating Layer BatchNorm21
I1007 15:08:43.624209  4982 net.cpp:406] BatchNorm21 <- Convolution21
I1007 15:08:43.624214  4982 net.cpp:367] BatchNorm21 -> Convolution21 (in-place)
I1007 15:08:43.624363  4982 net.cpp:122] Setting up BatchNorm21
I1007 15:08:43.624368  4982 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 15:08:43.624372  4982 net.cpp:137] Memory required for data: 561562800
I1007 15:08:43.624377  4982 layer_factory.hpp:77] Creating layer Scale21
I1007 15:08:43.624380  4982 net.cpp:84] Creating Layer Scale21
I1007 15:08:43.624384  4982 net.cpp:406] Scale21 <- Convolution21
I1007 15:08:43.624388  4982 net.cpp:367] Scale21 -> Convolution21 (in-place)
I1007 15:08:43.624418  4982 layer_factory.hpp:77] Creating layer Scale21
I1007 15:08:43.624505  4982 net.cpp:122] Setting up Scale21
I1007 15:08:43.624510  4982 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 15:08:43.624512  4982 net.cpp:137] Memory required for data: 564839600
I1007 15:08:43.624516  4982 layer_factory.hpp:77] Creating layer penlu20
I1007 15:08:43.624521  4982 net.cpp:84] Creating Layer penlu20
I1007 15:08:43.624524  4982 net.cpp:406] penlu20 <- Convolution21
I1007 15:08:43.624528  4982 net.cpp:367] penlu20 -> Convolution21 (in-place)
I1007 15:08:43.624649  4982 net.cpp:122] Setting up penlu20
I1007 15:08:43.624660  4982 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 15:08:43.624663  4982 net.cpp:137] Memory required for data: 568116400
I1007 15:08:43.624668  4982 layer_factory.hpp:77] Creating layer Convolution22
I1007 15:08:43.624675  4982 net.cpp:84] Creating Layer Convolution22
I1007 15:08:43.624680  4982 net.cpp:406] Convolution22 <- Convolution21
I1007 15:08:43.624683  4982 net.cpp:380] Convolution22 -> Convolution22
I1007 15:08:43.625792  4982 net.cpp:122] Setting up Convolution22
I1007 15:08:43.625802  4982 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 15:08:43.625805  4982 net.cpp:137] Memory required for data: 571393200
I1007 15:08:43.625820  4982 layer_factory.hpp:77] Creating layer BatchNorm22
I1007 15:08:43.625825  4982 net.cpp:84] Creating Layer BatchNorm22
I1007 15:08:43.625829  4982 net.cpp:406] BatchNorm22 <- Convolution22
I1007 15:08:43.625843  4982 net.cpp:367] BatchNorm22 -> Convolution22 (in-place)
I1007 15:08:43.625989  4982 net.cpp:122] Setting up BatchNorm22
I1007 15:08:43.625994  4982 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 15:08:43.625998  4982 net.cpp:137] Memory required for data: 574670000
I1007 15:08:43.626001  4982 layer_factory.hpp:77] Creating layer Scale22
I1007 15:08:43.626006  4982 net.cpp:84] Creating Layer Scale22
I1007 15:08:43.626010  4982 net.cpp:406] Scale22 <- Convolution22
I1007 15:08:43.626013  4982 net.cpp:367] Scale22 -> Convolution22 (in-place)
I1007 15:08:43.626044  4982 layer_factory.hpp:77] Creating layer Scale22
I1007 15:08:43.626129  4982 net.cpp:122] Setting up Scale22
I1007 15:08:43.626134  4982 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 15:08:43.626137  4982 net.cpp:137] Memory required for data: 577946800
I1007 15:08:43.626142  4982 layer_factory.hpp:77] Creating layer Eltwise10
I1007 15:08:43.626145  4982 net.cpp:84] Creating Layer Eltwise10
I1007 15:08:43.626149  4982 net.cpp:406] Eltwise10 <- Eltwise9_penlu19_0_split_1
I1007 15:08:43.626152  4982 net.cpp:406] Eltwise10 <- Convolution22
I1007 15:08:43.626155  4982 net.cpp:380] Eltwise10 -> Eltwise10
I1007 15:08:43.626170  4982 net.cpp:122] Setting up Eltwise10
I1007 15:08:43.626175  4982 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 15:08:43.626178  4982 net.cpp:137] Memory required for data: 581223600
I1007 15:08:43.626179  4982 layer_factory.hpp:77] Creating layer penlu21
I1007 15:08:43.626184  4982 net.cpp:84] Creating Layer penlu21
I1007 15:08:43.626188  4982 net.cpp:406] penlu21 <- Eltwise10
I1007 15:08:43.626191  4982 net.cpp:367] penlu21 -> Eltwise10 (in-place)
I1007 15:08:43.626313  4982 net.cpp:122] Setting up penlu21
I1007 15:08:43.626318  4982 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 15:08:43.626320  4982 net.cpp:137] Memory required for data: 584500400
I1007 15:08:43.626324  4982 layer_factory.hpp:77] Creating layer Eltwise10_penlu21_0_split
I1007 15:08:43.626329  4982 net.cpp:84] Creating Layer Eltwise10_penlu21_0_split
I1007 15:08:43.626332  4982 net.cpp:406] Eltwise10_penlu21_0_split <- Eltwise10
I1007 15:08:43.626335  4982 net.cpp:380] Eltwise10_penlu21_0_split -> Eltwise10_penlu21_0_split_0
I1007 15:08:43.626339  4982 net.cpp:380] Eltwise10_penlu21_0_split -> Eltwise10_penlu21_0_split_1
I1007 15:08:43.626365  4982 net.cpp:122] Setting up Eltwise10_penlu21_0_split
I1007 15:08:43.626370  4982 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 15:08:43.626374  4982 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 15:08:43.626375  4982 net.cpp:137] Memory required for data: 591054000
I1007 15:08:43.626377  4982 layer_factory.hpp:77] Creating layer Convolution23
I1007 15:08:43.626384  4982 net.cpp:84] Creating Layer Convolution23
I1007 15:08:43.626387  4982 net.cpp:406] Convolution23 <- Eltwise10_penlu21_0_split_0
I1007 15:08:43.626391  4982 net.cpp:380] Convolution23 -> Convolution23
I1007 15:08:43.627380  4982 net.cpp:122] Setting up Convolution23
I1007 15:08:43.627390  4982 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 15:08:43.627393  4982 net.cpp:137] Memory required for data: 592692400
I1007 15:08:43.627398  4982 layer_factory.hpp:77] Creating layer BatchNorm23
I1007 15:08:43.627411  4982 net.cpp:84] Creating Layer BatchNorm23
I1007 15:08:43.627415  4982 net.cpp:406] BatchNorm23 <- Convolution23
I1007 15:08:43.627419  4982 net.cpp:367] BatchNorm23 -> Convolution23 (in-place)
I1007 15:08:43.627590  4982 net.cpp:122] Setting up BatchNorm23
I1007 15:08:43.627595  4982 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 15:08:43.627599  4982 net.cpp:137] Memory required for data: 594330800
I1007 15:08:43.627614  4982 layer_factory.hpp:77] Creating layer Scale23
I1007 15:08:43.627619  4982 net.cpp:84] Creating Layer Scale23
I1007 15:08:43.627622  4982 net.cpp:406] Scale23 <- Convolution23
I1007 15:08:43.627625  4982 net.cpp:367] Scale23 -> Convolution23 (in-place)
I1007 15:08:43.627667  4982 layer_factory.hpp:77] Creating layer Scale23
I1007 15:08:43.627755  4982 net.cpp:122] Setting up Scale23
I1007 15:08:43.627760  4982 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 15:08:43.627763  4982 net.cpp:137] Memory required for data: 595969200
I1007 15:08:43.627766  4982 layer_factory.hpp:77] Creating layer Convolution24
I1007 15:08:43.627774  4982 net.cpp:84] Creating Layer Convolution24
I1007 15:08:43.627776  4982 net.cpp:406] Convolution24 <- Eltwise10_penlu21_0_split_1
I1007 15:08:43.627780  4982 net.cpp:380] Convolution24 -> Convolution24
I1007 15:08:43.629097  4982 net.cpp:122] Setting up Convolution24
I1007 15:08:43.629107  4982 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 15:08:43.629112  4982 net.cpp:137] Memory required for data: 597607600
I1007 15:08:43.629115  4982 layer_factory.hpp:77] Creating layer BatchNorm24
I1007 15:08:43.629122  4982 net.cpp:84] Creating Layer BatchNorm24
I1007 15:08:43.629124  4982 net.cpp:406] BatchNorm24 <- Convolution24
I1007 15:08:43.629129  4982 net.cpp:367] BatchNorm24 -> Convolution24 (in-place)
I1007 15:08:43.629281  4982 net.cpp:122] Setting up BatchNorm24
I1007 15:08:43.629287  4982 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 15:08:43.629289  4982 net.cpp:137] Memory required for data: 599246000
I1007 15:08:43.629294  4982 layer_factory.hpp:77] Creating layer Scale24
I1007 15:08:43.629299  4982 net.cpp:84] Creating Layer Scale24
I1007 15:08:43.629302  4982 net.cpp:406] Scale24 <- Convolution24
I1007 15:08:43.629305  4982 net.cpp:367] Scale24 -> Convolution24 (in-place)
I1007 15:08:43.629335  4982 layer_factory.hpp:77] Creating layer Scale24
I1007 15:08:43.629422  4982 net.cpp:122] Setting up Scale24
I1007 15:08:43.629427  4982 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 15:08:43.629429  4982 net.cpp:137] Memory required for data: 600884400
I1007 15:08:43.629433  4982 layer_factory.hpp:77] Creating layer penlu22
I1007 15:08:43.629439  4982 net.cpp:84] Creating Layer penlu22
I1007 15:08:43.629442  4982 net.cpp:406] penlu22 <- Convolution24
I1007 15:08:43.629446  4982 net.cpp:367] penlu22 -> Convolution24 (in-place)
I1007 15:08:43.629565  4982 net.cpp:122] Setting up penlu22
I1007 15:08:43.629570  4982 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 15:08:43.629571  4982 net.cpp:137] Memory required for data: 602522800
I1007 15:08:43.629576  4982 layer_factory.hpp:77] Creating layer Convolution25
I1007 15:08:43.629585  4982 net.cpp:84] Creating Layer Convolution25
I1007 15:08:43.629587  4982 net.cpp:406] Convolution25 <- Convolution24
I1007 15:08:43.629591  4982 net.cpp:380] Convolution25 -> Convolution25
I1007 15:08:43.631361  4982 net.cpp:122] Setting up Convolution25
I1007 15:08:43.631371  4982 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 15:08:43.631376  4982 net.cpp:137] Memory required for data: 604161200
I1007 15:08:43.631391  4982 layer_factory.hpp:77] Creating layer BatchNorm25
I1007 15:08:43.631397  4982 net.cpp:84] Creating Layer BatchNorm25
I1007 15:08:43.631400  4982 net.cpp:406] BatchNorm25 <- Convolution25
I1007 15:08:43.631404  4982 net.cpp:367] BatchNorm25 -> Convolution25 (in-place)
I1007 15:08:43.631564  4982 net.cpp:122] Setting up BatchNorm25
I1007 15:08:43.631569  4982 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 15:08:43.631572  4982 net.cpp:137] Memory required for data: 605799600
I1007 15:08:43.631584  4982 layer_factory.hpp:77] Creating layer Scale25
I1007 15:08:43.631592  4982 net.cpp:84] Creating Layer Scale25
I1007 15:08:43.631594  4982 net.cpp:406] Scale25 <- Convolution25
I1007 15:08:43.631597  4982 net.cpp:367] Scale25 -> Convolution25 (in-place)
I1007 15:08:43.631629  4982 layer_factory.hpp:77] Creating layer Scale25
I1007 15:08:43.631716  4982 net.cpp:122] Setting up Scale25
I1007 15:08:43.631722  4982 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 15:08:43.631724  4982 net.cpp:137] Memory required for data: 607438000
I1007 15:08:43.631728  4982 layer_factory.hpp:77] Creating layer Eltwise11
I1007 15:08:43.631733  4982 net.cpp:84] Creating Layer Eltwise11
I1007 15:08:43.631737  4982 net.cpp:406] Eltwise11 <- Convolution23
I1007 15:08:43.631739  4982 net.cpp:406] Eltwise11 <- Convolution25
I1007 15:08:43.631743  4982 net.cpp:380] Eltwise11 -> Eltwise11
I1007 15:08:43.631762  4982 net.cpp:122] Setting up Eltwise11
I1007 15:08:43.631767  4982 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 15:08:43.631768  4982 net.cpp:137] Memory required for data: 609076400
I1007 15:08:43.631770  4982 layer_factory.hpp:77] Creating layer penlu23
I1007 15:08:43.631775  4982 net.cpp:84] Creating Layer penlu23
I1007 15:08:43.631778  4982 net.cpp:406] penlu23 <- Eltwise11
I1007 15:08:43.631783  4982 net.cpp:367] penlu23 -> Eltwise11 (in-place)
I1007 15:08:43.631903  4982 net.cpp:122] Setting up penlu23
I1007 15:08:43.631909  4982 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 15:08:43.631911  4982 net.cpp:137] Memory required for data: 610714800
I1007 15:08:43.631916  4982 layer_factory.hpp:77] Creating layer Eltwise11_penlu23_0_split
I1007 15:08:43.631919  4982 net.cpp:84] Creating Layer Eltwise11_penlu23_0_split
I1007 15:08:43.631922  4982 net.cpp:406] Eltwise11_penlu23_0_split <- Eltwise11
I1007 15:08:43.631925  4982 net.cpp:380] Eltwise11_penlu23_0_split -> Eltwise11_penlu23_0_split_0
I1007 15:08:43.631929  4982 net.cpp:380] Eltwise11_penlu23_0_split -> Eltwise11_penlu23_0_split_1
I1007 15:08:43.631958  4982 net.cpp:122] Setting up Eltwise11_penlu23_0_split
I1007 15:08:43.631963  4982 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 15:08:43.631965  4982 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 15:08:43.631968  4982 net.cpp:137] Memory required for data: 613991600
I1007 15:08:43.631970  4982 layer_factory.hpp:77] Creating layer Convolution26
I1007 15:08:43.631976  4982 net.cpp:84] Creating Layer Convolution26
I1007 15:08:43.631979  4982 net.cpp:406] Convolution26 <- Eltwise11_penlu23_0_split_0
I1007 15:08:43.631983  4982 net.cpp:380] Convolution26 -> Convolution26
I1007 15:08:43.633713  4982 net.cpp:122] Setting up Convolution26
I1007 15:08:43.633723  4982 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 15:08:43.633728  4982 net.cpp:137] Memory required for data: 615630000
I1007 15:08:43.633731  4982 layer_factory.hpp:77] Creating layer BatchNorm26
I1007 15:08:43.633738  4982 net.cpp:84] Creating Layer BatchNorm26
I1007 15:08:43.633743  4982 net.cpp:406] BatchNorm26 <- Convolution26
I1007 15:08:43.633745  4982 net.cpp:367] BatchNorm26 -> Convolution26 (in-place)
I1007 15:08:43.633898  4982 net.cpp:122] Setting up BatchNorm26
I1007 15:08:43.633903  4982 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 15:08:43.633905  4982 net.cpp:137] Memory required for data: 617268400
I1007 15:08:43.633910  4982 layer_factory.hpp:77] Creating layer Scale26
I1007 15:08:43.633914  4982 net.cpp:84] Creating Layer Scale26
I1007 15:08:43.633918  4982 net.cpp:406] Scale26 <- Convolution26
I1007 15:08:43.633920  4982 net.cpp:367] Scale26 -> Convolution26 (in-place)
I1007 15:08:43.633952  4982 layer_factory.hpp:77] Creating layer Scale26
I1007 15:08:43.634039  4982 net.cpp:122] Setting up Scale26
I1007 15:08:43.634044  4982 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 15:08:43.634047  4982 net.cpp:137] Memory required for data: 618906800
I1007 15:08:43.634050  4982 layer_factory.hpp:77] Creating layer penlu24
I1007 15:08:43.634055  4982 net.cpp:84] Creating Layer penlu24
I1007 15:08:43.634058  4982 net.cpp:406] penlu24 <- Convolution26
I1007 15:08:43.634070  4982 net.cpp:367] penlu24 -> Convolution26 (in-place)
I1007 15:08:43.634193  4982 net.cpp:122] Setting up penlu24
I1007 15:08:43.634198  4982 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 15:08:43.634201  4982 net.cpp:137] Memory required for data: 620545200
I1007 15:08:43.634205  4982 layer_factory.hpp:77] Creating layer Convolution27
I1007 15:08:43.634213  4982 net.cpp:84] Creating Layer Convolution27
I1007 15:08:43.634217  4982 net.cpp:406] Convolution27 <- Convolution26
I1007 15:08:43.634220  4982 net.cpp:380] Convolution27 -> Convolution27
I1007 15:08:43.636076  4982 net.cpp:122] Setting up Convolution27
I1007 15:08:43.636086  4982 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 15:08:43.636090  4982 net.cpp:137] Memory required for data: 622183600
I1007 15:08:43.636095  4982 layer_factory.hpp:77] Creating layer BatchNorm27
I1007 15:08:43.636109  4982 net.cpp:84] Creating Layer BatchNorm27
I1007 15:08:43.636113  4982 net.cpp:406] BatchNorm27 <- Convolution27
I1007 15:08:43.636117  4982 net.cpp:367] BatchNorm27 -> Convolution27 (in-place)
I1007 15:08:43.636272  4982 net.cpp:122] Setting up BatchNorm27
I1007 15:08:43.636277  4982 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 15:08:43.636281  4982 net.cpp:137] Memory required for data: 623822000
I1007 15:08:43.636304  4982 layer_factory.hpp:77] Creating layer Scale27
I1007 15:08:43.636312  4982 net.cpp:84] Creating Layer Scale27
I1007 15:08:43.636314  4982 net.cpp:406] Scale27 <- Convolution27
I1007 15:08:43.636318  4982 net.cpp:367] Scale27 -> Convolution27 (in-place)
I1007 15:08:43.636382  4982 layer_factory.hpp:77] Creating layer Scale27
I1007 15:08:43.636521  4982 net.cpp:122] Setting up Scale27
I1007 15:08:43.636529  4982 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 15:08:43.636533  4982 net.cpp:137] Memory required for data: 625460400
I1007 15:08:43.636536  4982 layer_factory.hpp:77] Creating layer Eltwise12
I1007 15:08:43.636550  4982 net.cpp:84] Creating Layer Eltwise12
I1007 15:08:43.636554  4982 net.cpp:406] Eltwise12 <- Eltwise11_penlu23_0_split_1
I1007 15:08:43.636557  4982 net.cpp:406] Eltwise12 <- Convolution27
I1007 15:08:43.636561  4982 net.cpp:380] Eltwise12 -> Eltwise12
I1007 15:08:43.636595  4982 net.cpp:122] Setting up Eltwise12
I1007 15:08:43.636608  4982 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 15:08:43.636611  4982 net.cpp:137] Memory required for data: 627098800
I1007 15:08:43.636613  4982 layer_factory.hpp:77] Creating layer penlu25
I1007 15:08:43.636629  4982 net.cpp:84] Creating Layer penlu25
I1007 15:08:43.636632  4982 net.cpp:406] penlu25 <- Eltwise12
I1007 15:08:43.636636  4982 net.cpp:367] penlu25 -> Eltwise12 (in-place)
I1007 15:08:43.636759  4982 net.cpp:122] Setting up penlu25
I1007 15:08:43.636765  4982 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 15:08:43.636767  4982 net.cpp:137] Memory required for data: 628737200
I1007 15:08:43.636771  4982 layer_factory.hpp:77] Creating layer Eltwise12_penlu25_0_split
I1007 15:08:43.636776  4982 net.cpp:84] Creating Layer Eltwise12_penlu25_0_split
I1007 15:08:43.636780  4982 net.cpp:406] Eltwise12_penlu25_0_split <- Eltwise12
I1007 15:08:43.636783  4982 net.cpp:380] Eltwise12_penlu25_0_split -> Eltwise12_penlu25_0_split_0
I1007 15:08:43.636787  4982 net.cpp:380] Eltwise12_penlu25_0_split -> Eltwise12_penlu25_0_split_1
I1007 15:08:43.636816  4982 net.cpp:122] Setting up Eltwise12_penlu25_0_split
I1007 15:08:43.636819  4982 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 15:08:43.636823  4982 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 15:08:43.636826  4982 net.cpp:137] Memory required for data: 632014000
I1007 15:08:43.636827  4982 layer_factory.hpp:77] Creating layer Convolution28
I1007 15:08:43.636833  4982 net.cpp:84] Creating Layer Convolution28
I1007 15:08:43.636837  4982 net.cpp:406] Convolution28 <- Eltwise12_penlu25_0_split_0
I1007 15:08:43.636842  4982 net.cpp:380] Convolution28 -> Convolution28
I1007 15:08:43.639108  4982 net.cpp:122] Setting up Convolution28
I1007 15:08:43.639119  4982 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 15:08:43.639139  4982 net.cpp:137] Memory required for data: 633652400
I1007 15:08:43.639145  4982 layer_factory.hpp:77] Creating layer BatchNorm28
I1007 15:08:43.639153  4982 net.cpp:84] Creating Layer BatchNorm28
I1007 15:08:43.639155  4982 net.cpp:406] BatchNorm28 <- Convolution28
I1007 15:08:43.639160  4982 net.cpp:367] BatchNorm28 -> Convolution28 (in-place)
I1007 15:08:43.639343  4982 net.cpp:122] Setting up BatchNorm28
I1007 15:08:43.639349  4982 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 15:08:43.639353  4982 net.cpp:137] Memory required for data: 635290800
I1007 15:08:43.639358  4982 layer_factory.hpp:77] Creating layer Scale28
I1007 15:08:43.639363  4982 net.cpp:84] Creating Layer Scale28
I1007 15:08:43.639365  4982 net.cpp:406] Scale28 <- Convolution28
I1007 15:08:43.639369  4982 net.cpp:367] Scale28 -> Convolution28 (in-place)
I1007 15:08:43.639410  4982 layer_factory.hpp:77] Creating layer Scale28
I1007 15:08:43.639508  4982 net.cpp:122] Setting up Scale28
I1007 15:08:43.639513  4982 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 15:08:43.639514  4982 net.cpp:137] Memory required for data: 636929200
I1007 15:08:43.639518  4982 layer_factory.hpp:77] Creating layer penlu26
I1007 15:08:43.639525  4982 net.cpp:84] Creating Layer penlu26
I1007 15:08:43.639528  4982 net.cpp:406] penlu26 <- Convolution28
I1007 15:08:43.639533  4982 net.cpp:367] penlu26 -> Convolution28 (in-place)
I1007 15:08:43.639657  4982 net.cpp:122] Setting up penlu26
I1007 15:08:43.639662  4982 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 15:08:43.639664  4982 net.cpp:137] Memory required for data: 638567600
I1007 15:08:43.639668  4982 layer_factory.hpp:77] Creating layer Convolution29
I1007 15:08:43.639677  4982 net.cpp:84] Creating Layer Convolution29
I1007 15:08:43.639678  4982 net.cpp:406] Convolution29 <- Convolution28
I1007 15:08:43.639683  4982 net.cpp:380] Convolution29 -> Convolution29
I1007 15:08:43.641932  4982 net.cpp:122] Setting up Convolution29
I1007 15:08:43.641942  4982 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 15:08:43.641945  4982 net.cpp:137] Memory required for data: 640206000
I1007 15:08:43.641950  4982 layer_factory.hpp:77] Creating layer BatchNorm29
I1007 15:08:43.641968  4982 net.cpp:84] Creating Layer BatchNorm29
I1007 15:08:43.641973  4982 net.cpp:406] BatchNorm29 <- Convolution29
I1007 15:08:43.641985  4982 net.cpp:367] BatchNorm29 -> Convolution29 (in-place)
I1007 15:08:43.642148  4982 net.cpp:122] Setting up BatchNorm29
I1007 15:08:43.642153  4982 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 15:08:43.642154  4982 net.cpp:137] Memory required for data: 641844400
I1007 15:08:43.642159  4982 layer_factory.hpp:77] Creating layer Scale29
I1007 15:08:43.642164  4982 net.cpp:84] Creating Layer Scale29
I1007 15:08:43.642168  4982 net.cpp:406] Scale29 <- Convolution29
I1007 15:08:43.642170  4982 net.cpp:367] Scale29 -> Convolution29 (in-place)
I1007 15:08:43.642202  4982 layer_factory.hpp:77] Creating layer Scale29
I1007 15:08:43.642288  4982 net.cpp:122] Setting up Scale29
I1007 15:08:43.642294  4982 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 15:08:43.642297  4982 net.cpp:137] Memory required for data: 643482800
I1007 15:08:43.642300  4982 layer_factory.hpp:77] Creating layer Eltwise13
I1007 15:08:43.642304  4982 net.cpp:84] Creating Layer Eltwise13
I1007 15:08:43.642307  4982 net.cpp:406] Eltwise13 <- Eltwise12_penlu25_0_split_1
I1007 15:08:43.642310  4982 net.cpp:406] Eltwise13 <- Convolution29
I1007 15:08:43.642314  4982 net.cpp:380] Eltwise13 -> Eltwise13
I1007 15:08:43.642333  4982 net.cpp:122] Setting up Eltwise13
I1007 15:08:43.642338  4982 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 15:08:43.642339  4982 net.cpp:137] Memory required for data: 645121200
I1007 15:08:43.642341  4982 layer_factory.hpp:77] Creating layer penlu27
I1007 15:08:43.642346  4982 net.cpp:84] Creating Layer penlu27
I1007 15:08:43.642349  4982 net.cpp:406] penlu27 <- Eltwise13
I1007 15:08:43.642354  4982 net.cpp:367] penlu27 -> Eltwise13 (in-place)
I1007 15:08:43.642483  4982 net.cpp:122] Setting up penlu27
I1007 15:08:43.642488  4982 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 15:08:43.642491  4982 net.cpp:137] Memory required for data: 646759600
I1007 15:08:43.642495  4982 layer_factory.hpp:77] Creating layer Eltwise13_penlu27_0_split
I1007 15:08:43.642500  4982 net.cpp:84] Creating Layer Eltwise13_penlu27_0_split
I1007 15:08:43.642503  4982 net.cpp:406] Eltwise13_penlu27_0_split <- Eltwise13
I1007 15:08:43.642508  4982 net.cpp:380] Eltwise13_penlu27_0_split -> Eltwise13_penlu27_0_split_0
I1007 15:08:43.642511  4982 net.cpp:380] Eltwise13_penlu27_0_split -> Eltwise13_penlu27_0_split_1
I1007 15:08:43.642558  4982 net.cpp:122] Setting up Eltwise13_penlu27_0_split
I1007 15:08:43.642562  4982 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 15:08:43.642565  4982 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 15:08:43.642567  4982 net.cpp:137] Memory required for data: 650036400
I1007 15:08:43.642570  4982 layer_factory.hpp:77] Creating layer Convolution30
I1007 15:08:43.642575  4982 net.cpp:84] Creating Layer Convolution30
I1007 15:08:43.642578  4982 net.cpp:406] Convolution30 <- Eltwise13_penlu27_0_split_0
I1007 15:08:43.642583  4982 net.cpp:380] Convolution30 -> Convolution30
I1007 15:08:43.644608  4982 net.cpp:122] Setting up Convolution30
I1007 15:08:43.644618  4982 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 15:08:43.644621  4982 net.cpp:137] Memory required for data: 651674800
I1007 15:08:43.644626  4982 layer_factory.hpp:77] Creating layer BatchNorm30
I1007 15:08:43.644632  4982 net.cpp:84] Creating Layer BatchNorm30
I1007 15:08:43.644635  4982 net.cpp:406] BatchNorm30 <- Convolution30
I1007 15:08:43.644640  4982 net.cpp:367] BatchNorm30 -> Convolution30 (in-place)
I1007 15:08:43.644794  4982 net.cpp:122] Setting up BatchNorm30
I1007 15:08:43.644799  4982 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 15:08:43.644801  4982 net.cpp:137] Memory required for data: 653313200
I1007 15:08:43.644806  4982 layer_factory.hpp:77] Creating layer Scale30
I1007 15:08:43.644812  4982 net.cpp:84] Creating Layer Scale30
I1007 15:08:43.644815  4982 net.cpp:406] Scale30 <- Convolution30
I1007 15:08:43.644819  4982 net.cpp:367] Scale30 -> Convolution30 (in-place)
I1007 15:08:43.644850  4982 layer_factory.hpp:77] Creating layer Scale30
I1007 15:08:43.644937  4982 net.cpp:122] Setting up Scale30
I1007 15:08:43.644942  4982 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 15:08:43.644944  4982 net.cpp:137] Memory required for data: 654951600
I1007 15:08:43.644948  4982 layer_factory.hpp:77] Creating layer penlu28
I1007 15:08:43.644954  4982 net.cpp:84] Creating Layer penlu28
I1007 15:08:43.644958  4982 net.cpp:406] penlu28 <- Convolution30
I1007 15:08:43.644961  4982 net.cpp:367] penlu28 -> Convolution30 (in-place)
I1007 15:08:43.645081  4982 net.cpp:122] Setting up penlu28
I1007 15:08:43.645087  4982 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 15:08:43.645088  4982 net.cpp:137] Memory required for data: 656590000
I1007 15:08:43.645092  4982 layer_factory.hpp:77] Creating layer Convolution31
I1007 15:08:43.645099  4982 net.cpp:84] Creating Layer Convolution31
I1007 15:08:43.645102  4982 net.cpp:406] Convolution31 <- Convolution30
I1007 15:08:43.645107  4982 net.cpp:380] Convolution31 -> Convolution31
I1007 15:08:43.646778  4982 net.cpp:122] Setting up Convolution31
I1007 15:08:43.646788  4982 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 15:08:43.646791  4982 net.cpp:137] Memory required for data: 658228400
I1007 15:08:43.646795  4982 layer_factory.hpp:77] Creating layer BatchNorm31
I1007 15:08:43.646801  4982 net.cpp:84] Creating Layer BatchNorm31
I1007 15:08:43.646805  4982 net.cpp:406] BatchNorm31 <- Convolution31
I1007 15:08:43.646808  4982 net.cpp:367] BatchNorm31 -> Convolution31 (in-place)
I1007 15:08:43.646960  4982 net.cpp:122] Setting up BatchNorm31
I1007 15:08:43.646965  4982 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 15:08:43.646966  4982 net.cpp:137] Memory required for data: 659866800
I1007 15:08:43.646971  4982 layer_factory.hpp:77] Creating layer Scale31
I1007 15:08:43.646983  4982 net.cpp:84] Creating Layer Scale31
I1007 15:08:43.646987  4982 net.cpp:406] Scale31 <- Convolution31
I1007 15:08:43.646991  4982 net.cpp:367] Scale31 -> Convolution31 (in-place)
I1007 15:08:43.647022  4982 layer_factory.hpp:77] Creating layer Scale31
I1007 15:08:43.647109  4982 net.cpp:122] Setting up Scale31
I1007 15:08:43.647114  4982 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 15:08:43.647116  4982 net.cpp:137] Memory required for data: 661505200
I1007 15:08:43.647119  4982 layer_factory.hpp:77] Creating layer Eltwise14
I1007 15:08:43.647125  4982 net.cpp:84] Creating Layer Eltwise14
I1007 15:08:43.647128  4982 net.cpp:406] Eltwise14 <- Eltwise13_penlu27_0_split_1
I1007 15:08:43.647131  4982 net.cpp:406] Eltwise14 <- Convolution31
I1007 15:08:43.647135  4982 net.cpp:380] Eltwise14 -> Eltwise14
I1007 15:08:43.647153  4982 net.cpp:122] Setting up Eltwise14
I1007 15:08:43.647158  4982 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 15:08:43.647161  4982 net.cpp:137] Memory required for data: 663143600
I1007 15:08:43.647162  4982 layer_factory.hpp:77] Creating layer penlu29
I1007 15:08:43.647183  4982 net.cpp:84] Creating Layer penlu29
I1007 15:08:43.647186  4982 net.cpp:406] penlu29 <- Eltwise14
I1007 15:08:43.647189  4982 net.cpp:367] penlu29 -> Eltwise14 (in-place)
I1007 15:08:43.647328  4982 net.cpp:122] Setting up penlu29
I1007 15:08:43.647333  4982 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 15:08:43.647336  4982 net.cpp:137] Memory required for data: 664782000
I1007 15:08:43.647341  4982 layer_factory.hpp:77] Creating layer Eltwise14_penlu29_0_split
I1007 15:08:43.647344  4982 net.cpp:84] Creating Layer Eltwise14_penlu29_0_split
I1007 15:08:43.647346  4982 net.cpp:406] Eltwise14_penlu29_0_split <- Eltwise14
I1007 15:08:43.647349  4982 net.cpp:380] Eltwise14_penlu29_0_split -> Eltwise14_penlu29_0_split_0
I1007 15:08:43.647353  4982 net.cpp:380] Eltwise14_penlu29_0_split -> Eltwise14_penlu29_0_split_1
I1007 15:08:43.647382  4982 net.cpp:122] Setting up Eltwise14_penlu29_0_split
I1007 15:08:43.647387  4982 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 15:08:43.647389  4982 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 15:08:43.647392  4982 net.cpp:137] Memory required for data: 668058800
I1007 15:08:43.647393  4982 layer_factory.hpp:77] Creating layer Convolution32
I1007 15:08:43.647399  4982 net.cpp:84] Creating Layer Convolution32
I1007 15:08:43.647403  4982 net.cpp:406] Convolution32 <- Eltwise14_penlu29_0_split_0
I1007 15:08:43.647408  4982 net.cpp:380] Convolution32 -> Convolution32
I1007 15:08:43.649389  4982 net.cpp:122] Setting up Convolution32
I1007 15:08:43.649399  4982 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 15:08:43.649401  4982 net.cpp:137] Memory required for data: 669697200
I1007 15:08:43.649406  4982 layer_factory.hpp:77] Creating layer BatchNorm32
I1007 15:08:43.649411  4982 net.cpp:84] Creating Layer BatchNorm32
I1007 15:08:43.649415  4982 net.cpp:406] BatchNorm32 <- Convolution32
I1007 15:08:43.649418  4982 net.cpp:367] BatchNorm32 -> Convolution32 (in-place)
I1007 15:08:43.649572  4982 net.cpp:122] Setting up BatchNorm32
I1007 15:08:43.649577  4982 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 15:08:43.649580  4982 net.cpp:137] Memory required for data: 671335600
I1007 15:08:43.649585  4982 layer_factory.hpp:77] Creating layer Scale32
I1007 15:08:43.649590  4982 net.cpp:84] Creating Layer Scale32
I1007 15:08:43.649591  4982 net.cpp:406] Scale32 <- Convolution32
I1007 15:08:43.649595  4982 net.cpp:367] Scale32 -> Convolution32 (in-place)
I1007 15:08:43.649627  4982 layer_factory.hpp:77] Creating layer Scale32
I1007 15:08:43.649716  4982 net.cpp:122] Setting up Scale32
I1007 15:08:43.649721  4982 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 15:08:43.649724  4982 net.cpp:137] Memory required for data: 672974000
I1007 15:08:43.649727  4982 layer_factory.hpp:77] Creating layer penlu30
I1007 15:08:43.649734  4982 net.cpp:84] Creating Layer penlu30
I1007 15:08:43.649737  4982 net.cpp:406] penlu30 <- Convolution32
I1007 15:08:43.649749  4982 net.cpp:367] penlu30 -> Convolution32 (in-place)
I1007 15:08:43.649873  4982 net.cpp:122] Setting up penlu30
I1007 15:08:43.649878  4982 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 15:08:43.649879  4982 net.cpp:137] Memory required for data: 674612400
I1007 15:08:43.649883  4982 layer_factory.hpp:77] Creating layer Convolution33
I1007 15:08:43.649890  4982 net.cpp:84] Creating Layer Convolution33
I1007 15:08:43.649894  4982 net.cpp:406] Convolution33 <- Convolution32
I1007 15:08:43.649899  4982 net.cpp:380] Convolution33 -> Convolution33
I1007 15:08:43.651608  4982 net.cpp:122] Setting up Convolution33
I1007 15:08:43.651618  4982 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 15:08:43.651621  4982 net.cpp:137] Memory required for data: 676250800
I1007 15:08:43.651625  4982 layer_factory.hpp:77] Creating layer BatchNorm33
I1007 15:08:43.651631  4982 net.cpp:84] Creating Layer BatchNorm33
I1007 15:08:43.651635  4982 net.cpp:406] BatchNorm33 <- Convolution33
I1007 15:08:43.651639  4982 net.cpp:367] BatchNorm33 -> Convolution33 (in-place)
I1007 15:08:43.651788  4982 net.cpp:122] Setting up BatchNorm33
I1007 15:08:43.651793  4982 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 15:08:43.651795  4982 net.cpp:137] Memory required for data: 677889200
I1007 15:08:43.651800  4982 layer_factory.hpp:77] Creating layer Scale33
I1007 15:08:43.651805  4982 net.cpp:84] Creating Layer Scale33
I1007 15:08:43.651808  4982 net.cpp:406] Scale33 <- Convolution33
I1007 15:08:43.651811  4982 net.cpp:367] Scale33 -> Convolution33 (in-place)
I1007 15:08:43.651842  4982 layer_factory.hpp:77] Creating layer Scale33
I1007 15:08:43.651932  4982 net.cpp:122] Setting up Scale33
I1007 15:08:43.651937  4982 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 15:08:43.651938  4982 net.cpp:137] Memory required for data: 679527600
I1007 15:08:43.651942  4982 layer_factory.hpp:77] Creating layer Eltwise15
I1007 15:08:43.651947  4982 net.cpp:84] Creating Layer Eltwise15
I1007 15:08:43.651950  4982 net.cpp:406] Eltwise15 <- Eltwise14_penlu29_0_split_1
I1007 15:08:43.651954  4982 net.cpp:406] Eltwise15 <- Convolution33
I1007 15:08:43.651957  4982 net.cpp:380] Eltwise15 -> Eltwise15
I1007 15:08:43.651976  4982 net.cpp:122] Setting up Eltwise15
I1007 15:08:43.651980  4982 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 15:08:43.651983  4982 net.cpp:137] Memory required for data: 681166000
I1007 15:08:43.651985  4982 layer_factory.hpp:77] Creating layer penlu31
I1007 15:08:43.651989  4982 net.cpp:84] Creating Layer penlu31
I1007 15:08:43.651991  4982 net.cpp:406] penlu31 <- Eltwise15
I1007 15:08:43.651995  4982 net.cpp:367] penlu31 -> Eltwise15 (in-place)
I1007 15:08:43.652135  4982 net.cpp:122] Setting up penlu31
I1007 15:08:43.652139  4982 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 15:08:43.652143  4982 net.cpp:137] Memory required for data: 682804400
I1007 15:08:43.652156  4982 layer_factory.hpp:77] Creating layer Pooling1
I1007 15:08:43.652163  4982 net.cpp:84] Creating Layer Pooling1
I1007 15:08:43.652165  4982 net.cpp:406] Pooling1 <- Eltwise15
I1007 15:08:43.652169  4982 net.cpp:380] Pooling1 -> Pooling1
I1007 15:08:43.652318  4982 net.cpp:122] Setting up Pooling1
I1007 15:08:43.652324  4982 net.cpp:129] Top shape: 100 64 1 1 (6400)
I1007 15:08:43.652328  4982 net.cpp:137] Memory required for data: 682830000
I1007 15:08:43.652330  4982 layer_factory.hpp:77] Creating layer InnerProduct1
I1007 15:08:43.652335  4982 net.cpp:84] Creating Layer InnerProduct1
I1007 15:08:43.652338  4982 net.cpp:406] InnerProduct1 <- Pooling1
I1007 15:08:43.652343  4982 net.cpp:380] InnerProduct1 -> InnerProduct1
I1007 15:08:43.652447  4982 net.cpp:122] Setting up InnerProduct1
I1007 15:08:43.652452  4982 net.cpp:129] Top shape: 100 10 (1000)
I1007 15:08:43.652454  4982 net.cpp:137] Memory required for data: 682834000
I1007 15:08:43.652457  4982 layer_factory.hpp:77] Creating layer InnerProduct1_InnerProduct1_0_split
I1007 15:08:43.652462  4982 net.cpp:84] Creating Layer InnerProduct1_InnerProduct1_0_split
I1007 15:08:43.652463  4982 net.cpp:406] InnerProduct1_InnerProduct1_0_split <- InnerProduct1
I1007 15:08:43.652475  4982 net.cpp:380] InnerProduct1_InnerProduct1_0_split -> InnerProduct1_InnerProduct1_0_split_0
I1007 15:08:43.652480  4982 net.cpp:380] InnerProduct1_InnerProduct1_0_split -> InnerProduct1_InnerProduct1_0_split_1
I1007 15:08:43.652509  4982 net.cpp:122] Setting up InnerProduct1_InnerProduct1_0_split
I1007 15:08:43.652513  4982 net.cpp:129] Top shape: 100 10 (1000)
I1007 15:08:43.652516  4982 net.cpp:129] Top shape: 100 10 (1000)
I1007 15:08:43.652518  4982 net.cpp:137] Memory required for data: 682842000
I1007 15:08:43.652520  4982 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I1007 15:08:43.652524  4982 net.cpp:84] Creating Layer SoftmaxWithLoss1
I1007 15:08:43.652528  4982 net.cpp:406] SoftmaxWithLoss1 <- InnerProduct1_InnerProduct1_0_split_0
I1007 15:08:43.652530  4982 net.cpp:406] SoftmaxWithLoss1 <- Data2_Data1_1_split_0
I1007 15:08:43.652534  4982 net.cpp:380] SoftmaxWithLoss1 -> SoftmaxWithLoss1
I1007 15:08:43.652539  4982 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I1007 15:08:43.653054  4982 net.cpp:122] Setting up SoftmaxWithLoss1
I1007 15:08:43.653064  4982 net.cpp:129] Top shape: (1)
I1007 15:08:43.653065  4982 net.cpp:132]     with loss weight 1
I1007 15:08:43.653072  4982 net.cpp:137] Memory required for data: 682842004
I1007 15:08:43.653075  4982 layer_factory.hpp:77] Creating layer Accuracy1
I1007 15:08:43.653079  4982 net.cpp:84] Creating Layer Accuracy1
I1007 15:08:43.653082  4982 net.cpp:406] Accuracy1 <- InnerProduct1_InnerProduct1_0_split_1
I1007 15:08:43.653085  4982 net.cpp:406] Accuracy1 <- Data2_Data1_1_split_1
I1007 15:08:43.653089  4982 net.cpp:380] Accuracy1 -> Accuracy1
I1007 15:08:43.653095  4982 net.cpp:122] Setting up Accuracy1
I1007 15:08:43.653097  4982 net.cpp:129] Top shape: (1)
I1007 15:08:43.653100  4982 net.cpp:137] Memory required for data: 682842008
I1007 15:08:43.653102  4982 net.cpp:200] Accuracy1 does not need backward computation.
I1007 15:08:43.653105  4982 net.cpp:198] SoftmaxWithLoss1 needs backward computation.
I1007 15:08:43.653106  4982 net.cpp:198] InnerProduct1_InnerProduct1_0_split needs backward computation.
I1007 15:08:43.653110  4982 net.cpp:198] InnerProduct1 needs backward computation.
I1007 15:08:43.653111  4982 net.cpp:198] Pooling1 needs backward computation.
I1007 15:08:43.653113  4982 net.cpp:198] penlu31 needs backward computation.
I1007 15:08:43.653115  4982 net.cpp:198] Eltwise15 needs backward computation.
I1007 15:08:43.653118  4982 net.cpp:198] Scale33 needs backward computation.
I1007 15:08:43.653120  4982 net.cpp:198] BatchNorm33 needs backward computation.
I1007 15:08:43.653122  4982 net.cpp:198] Convolution33 needs backward computation.
I1007 15:08:43.653125  4982 net.cpp:198] penlu30 needs backward computation.
I1007 15:08:43.653126  4982 net.cpp:198] Scale32 needs backward computation.
I1007 15:08:43.653128  4982 net.cpp:198] BatchNorm32 needs backward computation.
I1007 15:08:43.653129  4982 net.cpp:198] Convolution32 needs backward computation.
I1007 15:08:43.653132  4982 net.cpp:198] Eltwise14_penlu29_0_split needs backward computation.
I1007 15:08:43.653134  4982 net.cpp:198] penlu29 needs backward computation.
I1007 15:08:43.653136  4982 net.cpp:198] Eltwise14 needs backward computation.
I1007 15:08:43.653138  4982 net.cpp:198] Scale31 needs backward computation.
I1007 15:08:43.653141  4982 net.cpp:198] BatchNorm31 needs backward computation.
I1007 15:08:43.653142  4982 net.cpp:198] Convolution31 needs backward computation.
I1007 15:08:43.653146  4982 net.cpp:198] penlu28 needs backward computation.
I1007 15:08:43.653146  4982 net.cpp:198] Scale30 needs backward computation.
I1007 15:08:43.653148  4982 net.cpp:198] BatchNorm30 needs backward computation.
I1007 15:08:43.653151  4982 net.cpp:198] Convolution30 needs backward computation.
I1007 15:08:43.653152  4982 net.cpp:198] Eltwise13_penlu27_0_split needs backward computation.
I1007 15:08:43.653156  4982 net.cpp:198] penlu27 needs backward computation.
I1007 15:08:43.653157  4982 net.cpp:198] Eltwise13 needs backward computation.
I1007 15:08:43.653165  4982 net.cpp:198] Scale29 needs backward computation.
I1007 15:08:43.653168  4982 net.cpp:198] BatchNorm29 needs backward computation.
I1007 15:08:43.653170  4982 net.cpp:198] Convolution29 needs backward computation.
I1007 15:08:43.653172  4982 net.cpp:198] penlu26 needs backward computation.
I1007 15:08:43.653174  4982 net.cpp:198] Scale28 needs backward computation.
I1007 15:08:43.653177  4982 net.cpp:198] BatchNorm28 needs backward computation.
I1007 15:08:43.653178  4982 net.cpp:198] Convolution28 needs backward computation.
I1007 15:08:43.653180  4982 net.cpp:198] Eltwise12_penlu25_0_split needs backward computation.
I1007 15:08:43.653182  4982 net.cpp:198] penlu25 needs backward computation.
I1007 15:08:43.653184  4982 net.cpp:198] Eltwise12 needs backward computation.
I1007 15:08:43.653187  4982 net.cpp:198] Scale27 needs backward computation.
I1007 15:08:43.653189  4982 net.cpp:198] BatchNorm27 needs backward computation.
I1007 15:08:43.653192  4982 net.cpp:198] Convolution27 needs backward computation.
I1007 15:08:43.653193  4982 net.cpp:198] penlu24 needs backward computation.
I1007 15:08:43.653195  4982 net.cpp:198] Scale26 needs backward computation.
I1007 15:08:43.653198  4982 net.cpp:198] BatchNorm26 needs backward computation.
I1007 15:08:43.653199  4982 net.cpp:198] Convolution26 needs backward computation.
I1007 15:08:43.653201  4982 net.cpp:198] Eltwise11_penlu23_0_split needs backward computation.
I1007 15:08:43.653204  4982 net.cpp:198] penlu23 needs backward computation.
I1007 15:08:43.653206  4982 net.cpp:198] Eltwise11 needs backward computation.
I1007 15:08:43.653208  4982 net.cpp:198] Scale25 needs backward computation.
I1007 15:08:43.653211  4982 net.cpp:198] BatchNorm25 needs backward computation.
I1007 15:08:43.653213  4982 net.cpp:198] Convolution25 needs backward computation.
I1007 15:08:43.653215  4982 net.cpp:198] penlu22 needs backward computation.
I1007 15:08:43.653218  4982 net.cpp:198] Scale24 needs backward computation.
I1007 15:08:43.653219  4982 net.cpp:198] BatchNorm24 needs backward computation.
I1007 15:08:43.653221  4982 net.cpp:198] Convolution24 needs backward computation.
I1007 15:08:43.653224  4982 net.cpp:198] Scale23 needs backward computation.
I1007 15:08:43.653226  4982 net.cpp:198] BatchNorm23 needs backward computation.
I1007 15:08:43.653228  4982 net.cpp:198] Convolution23 needs backward computation.
I1007 15:08:43.653230  4982 net.cpp:198] Eltwise10_penlu21_0_split needs backward computation.
I1007 15:08:43.653232  4982 net.cpp:198] penlu21 needs backward computation.
I1007 15:08:43.653235  4982 net.cpp:198] Eltwise10 needs backward computation.
I1007 15:08:43.653237  4982 net.cpp:198] Scale22 needs backward computation.
I1007 15:08:43.653239  4982 net.cpp:198] BatchNorm22 needs backward computation.
I1007 15:08:43.653242  4982 net.cpp:198] Convolution22 needs backward computation.
I1007 15:08:43.653244  4982 net.cpp:198] penlu20 needs backward computation.
I1007 15:08:43.653246  4982 net.cpp:198] Scale21 needs backward computation.
I1007 15:08:43.653249  4982 net.cpp:198] BatchNorm21 needs backward computation.
I1007 15:08:43.653250  4982 net.cpp:198] Convolution21 needs backward computation.
I1007 15:08:43.653254  4982 net.cpp:198] Eltwise9_penlu19_0_split needs backward computation.
I1007 15:08:43.653255  4982 net.cpp:198] penlu19 needs backward computation.
I1007 15:08:43.653259  4982 net.cpp:198] Eltwise9 needs backward computation.
I1007 15:08:43.653260  4982 net.cpp:198] Scale20 needs backward computation.
I1007 15:08:43.653262  4982 net.cpp:198] BatchNorm20 needs backward computation.
I1007 15:08:43.653264  4982 net.cpp:198] Convolution20 needs backward computation.
I1007 15:08:43.653266  4982 net.cpp:198] penlu18 needs backward computation.
I1007 15:08:43.653270  4982 net.cpp:198] Scale19 needs backward computation.
I1007 15:08:43.653271  4982 net.cpp:198] BatchNorm19 needs backward computation.
I1007 15:08:43.653273  4982 net.cpp:198] Convolution19 needs backward computation.
I1007 15:08:43.653280  4982 net.cpp:198] Eltwise8_penlu17_0_split needs backward computation.
I1007 15:08:43.653281  4982 net.cpp:198] penlu17 needs backward computation.
I1007 15:08:43.653283  4982 net.cpp:198] Eltwise8 needs backward computation.
I1007 15:08:43.653286  4982 net.cpp:198] Scale18 needs backward computation.
I1007 15:08:43.653288  4982 net.cpp:198] BatchNorm18 needs backward computation.
I1007 15:08:43.653290  4982 net.cpp:198] Convolution18 needs backward computation.
I1007 15:08:43.653293  4982 net.cpp:198] penlu16 needs backward computation.
I1007 15:08:43.653295  4982 net.cpp:198] Scale17 needs backward computation.
I1007 15:08:43.653297  4982 net.cpp:198] BatchNorm17 needs backward computation.
I1007 15:08:43.653300  4982 net.cpp:198] Convolution17 needs backward computation.
I1007 15:08:43.653301  4982 net.cpp:198] Eltwise7_penlu15_0_split needs backward computation.
I1007 15:08:43.653304  4982 net.cpp:198] penlu15 needs backward computation.
I1007 15:08:43.653306  4982 net.cpp:198] Eltwise7 needs backward computation.
I1007 15:08:43.653308  4982 net.cpp:198] Scale16 needs backward computation.
I1007 15:08:43.653311  4982 net.cpp:198] BatchNorm16 needs backward computation.
I1007 15:08:43.653313  4982 net.cpp:198] Convolution16 needs backward computation.
I1007 15:08:43.653316  4982 net.cpp:198] penlu14 needs backward computation.
I1007 15:08:43.653317  4982 net.cpp:198] Scale15 needs backward computation.
I1007 15:08:43.653319  4982 net.cpp:198] BatchNorm15 needs backward computation.
I1007 15:08:43.653321  4982 net.cpp:198] Convolution15 needs backward computation.
I1007 15:08:43.653324  4982 net.cpp:198] Eltwise6_penlu13_0_split needs backward computation.
I1007 15:08:43.653327  4982 net.cpp:198] penlu13 needs backward computation.
I1007 15:08:43.653329  4982 net.cpp:198] Eltwise6 needs backward computation.
I1007 15:08:43.653331  4982 net.cpp:198] Scale14 needs backward computation.
I1007 15:08:43.653334  4982 net.cpp:198] BatchNorm14 needs backward computation.
I1007 15:08:43.653337  4982 net.cpp:198] Convolution14 needs backward computation.
I1007 15:08:43.653338  4982 net.cpp:198] penlu12 needs backward computation.
I1007 15:08:43.653340  4982 net.cpp:198] Scale13 needs backward computation.
I1007 15:08:43.653342  4982 net.cpp:198] BatchNorm13 needs backward computation.
I1007 15:08:43.653345  4982 net.cpp:198] Convolution13 needs backward computation.
I1007 15:08:43.653347  4982 net.cpp:198] Scale12 needs backward computation.
I1007 15:08:43.653349  4982 net.cpp:198] BatchNorm12 needs backward computation.
I1007 15:08:43.653352  4982 net.cpp:198] Convolution12 needs backward computation.
I1007 15:08:43.653354  4982 net.cpp:198] Eltwise5_penlu11_0_split needs backward computation.
I1007 15:08:43.653357  4982 net.cpp:198] penlu11 needs backward computation.
I1007 15:08:43.653358  4982 net.cpp:198] Eltwise5 needs backward computation.
I1007 15:08:43.653362  4982 net.cpp:198] Scale11 needs backward computation.
I1007 15:08:43.653363  4982 net.cpp:198] BatchNorm11 needs backward computation.
I1007 15:08:43.653365  4982 net.cpp:198] Convolution11 needs backward computation.
I1007 15:08:43.653367  4982 net.cpp:198] penlu10 needs backward computation.
I1007 15:08:43.653369  4982 net.cpp:198] Scale10 needs backward computation.
I1007 15:08:43.653372  4982 net.cpp:198] BatchNorm10 needs backward computation.
I1007 15:08:43.653373  4982 net.cpp:198] Convolution10 needs backward computation.
I1007 15:08:43.653376  4982 net.cpp:198] Eltwise4_penlu9_0_split needs backward computation.
I1007 15:08:43.653378  4982 net.cpp:198] penlu9 needs backward computation.
I1007 15:08:43.653381  4982 net.cpp:198] Eltwise4 needs backward computation.
I1007 15:08:43.653384  4982 net.cpp:198] Scale9 needs backward computation.
I1007 15:08:43.653386  4982 net.cpp:198] BatchNorm9 needs backward computation.
I1007 15:08:43.653388  4982 net.cpp:198] Convolution9 needs backward computation.
I1007 15:08:43.653391  4982 net.cpp:198] penlu8 needs backward computation.
I1007 15:08:43.653393  4982 net.cpp:198] Scale8 needs backward computation.
I1007 15:08:43.653400  4982 net.cpp:198] BatchNorm8 needs backward computation.
I1007 15:08:43.653403  4982 net.cpp:198] Convolution8 needs backward computation.
I1007 15:08:43.653405  4982 net.cpp:198] Eltwise3_penlu7_0_split needs backward computation.
I1007 15:08:43.653409  4982 net.cpp:198] penlu7 needs backward computation.
I1007 15:08:43.653410  4982 net.cpp:198] Eltwise3 needs backward computation.
I1007 15:08:43.653414  4982 net.cpp:198] Scale7 needs backward computation.
I1007 15:08:43.653415  4982 net.cpp:198] BatchNorm7 needs backward computation.
I1007 15:08:43.653417  4982 net.cpp:198] Convolution7 needs backward computation.
I1007 15:08:43.653419  4982 net.cpp:198] penlu6 needs backward computation.
I1007 15:08:43.653421  4982 net.cpp:198] Scale6 needs backward computation.
I1007 15:08:43.653424  4982 net.cpp:198] BatchNorm6 needs backward computation.
I1007 15:08:43.653425  4982 net.cpp:198] Convolution6 needs backward computation.
I1007 15:08:43.653429  4982 net.cpp:198] Eltwise2_penlu5_0_split needs backward computation.
I1007 15:08:43.653430  4982 net.cpp:198] penlu5 needs backward computation.
I1007 15:08:43.653432  4982 net.cpp:198] Eltwise2 needs backward computation.
I1007 15:08:43.653435  4982 net.cpp:198] Scale5 needs backward computation.
I1007 15:08:43.653437  4982 net.cpp:198] BatchNorm5 needs backward computation.
I1007 15:08:43.653439  4982 net.cpp:198] Convolution5 needs backward computation.
I1007 15:08:43.653442  4982 net.cpp:198] penlu4 needs backward computation.
I1007 15:08:43.653445  4982 net.cpp:198] Scale4 needs backward computation.
I1007 15:08:43.653446  4982 net.cpp:198] BatchNorm4 needs backward computation.
I1007 15:08:43.653448  4982 net.cpp:198] Convolution4 needs backward computation.
I1007 15:08:43.653450  4982 net.cpp:198] Eltwise1_penlu3_0_split needs backward computation.
I1007 15:08:43.653453  4982 net.cpp:198] penlu3 needs backward computation.
I1007 15:08:43.653455  4982 net.cpp:198] Eltwise1 needs backward computation.
I1007 15:08:43.653458  4982 net.cpp:198] Scale3 needs backward computation.
I1007 15:08:43.653460  4982 net.cpp:198] BatchNorm3 needs backward computation.
I1007 15:08:43.653462  4982 net.cpp:198] Convolution3 needs backward computation.
I1007 15:08:43.653465  4982 net.cpp:198] penlu2 needs backward computation.
I1007 15:08:43.653467  4982 net.cpp:198] Scale2 needs backward computation.
I1007 15:08:43.653470  4982 net.cpp:198] BatchNorm2 needs backward computation.
I1007 15:08:43.653471  4982 net.cpp:198] Convolution2 needs backward computation.
I1007 15:08:43.653475  4982 net.cpp:198] Convolution1_penlu1_0_split needs backward computation.
I1007 15:08:43.653476  4982 net.cpp:198] penlu1 needs backward computation.
I1007 15:08:43.653478  4982 net.cpp:198] Scale1 needs backward computation.
I1007 15:08:43.653481  4982 net.cpp:198] BatchNorm1 needs backward computation.
I1007 15:08:43.653482  4982 net.cpp:198] Convolution1 needs backward computation.
I1007 15:08:43.653486  4982 net.cpp:200] Data2_Data1_1_split does not need backward computation.
I1007 15:08:43.653488  4982 net.cpp:200] Data1 does not need backward computation.
I1007 15:08:43.653491  4982 net.cpp:242] This network produces output Accuracy1
I1007 15:08:43.653492  4982 net.cpp:242] This network produces output SoftmaxWithLoss1
I1007 15:08:43.653544  4982 net.cpp:255] Network initialization done.
I1007 15:08:43.653947  4982 solver.cpp:56] Solver scaffolding done.
I1007 15:08:43.662737  4982 caffe.cpp:248] Starting Optimization
I1007 15:08:43.662748  4982 solver.cpp:272] Solving resnet_cifar10
I1007 15:08:43.662751  4982 solver.cpp:273] Learning Rate Policy: multistep
I1007 15:08:43.666720  4982 solver.cpp:330] Iteration 0, Testing net (#0)
I1007 15:08:45.625567  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:08:45.704910  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.1
I1007 15:08:45.704946  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 87.3365 (* 1 = 87.3365 loss)
I1007 15:08:45.819026  4982 solver.cpp:218] Iteration 0 (0 iter/s, 2.1562s/100 iters), loss = 2.30892
I1007 15:08:45.819066  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 2.30892 (* 1 = 2.30892 loss)
I1007 15:08:45.819082  4982 sgd_solver.cpp:105] Iteration 0, lr = 0.1
I1007 15:08:54.113298  4982 solver.cpp:218] Iteration 100 (12.0567 iter/s, 8.29416s/100 iters), loss = 1.59237
I1007 15:08:54.113329  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.59237 (* 1 = 1.59237 loss)
I1007 15:08:54.113335  4982 sgd_solver.cpp:105] Iteration 100, lr = 0.1
I1007 15:09:02.401600  4982 solver.cpp:218] Iteration 200 (12.0653 iter/s, 8.2882s/100 iters), loss = 1.55713
I1007 15:09:02.401631  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.55713 (* 1 = 1.55713 loss)
I1007 15:09:02.401648  4982 sgd_solver.cpp:105] Iteration 200, lr = 0.1
I1007 15:09:10.688261  4982 solver.cpp:218] Iteration 300 (12.0677 iter/s, 8.28655s/100 iters), loss = 1.22878
I1007 15:09:10.688292  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.22878 (* 1 = 1.22878 loss)
I1007 15:09:10.688307  4982 sgd_solver.cpp:105] Iteration 300, lr = 0.1
I1007 15:09:18.977681  4982 solver.cpp:218] Iteration 400 (12.0637 iter/s, 8.28932s/100 iters), loss = 0.953651
I1007 15:09:18.977756  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.953651 (* 1 = 0.953651 loss)
I1007 15:09:18.977773  4982 sgd_solver.cpp:105] Iteration 400, lr = 0.1
I1007 15:09:26.858495  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:09:27.190258  4982 solver.cpp:330] Iteration 500, Testing net (#0)
I1007 15:09:29.115700  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:09:29.195883  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.352
I1007 15:09:29.195919  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 3.10225 (* 1 = 3.10225 loss)
I1007 15:09:29.279124  4982 solver.cpp:218] Iteration 500 (9.70754 iter/s, 10.3013s/100 iters), loss = 1.11044
I1007 15:09:29.279155  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.11044 (* 1 = 1.11044 loss)
I1007 15:09:29.279165  4982 sgd_solver.cpp:105] Iteration 500, lr = 0.1
I1007 15:09:37.579917  4982 solver.cpp:218] Iteration 600 (12.0472 iter/s, 8.30065s/100 iters), loss = 1.08677
I1007 15:09:37.579947  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.08677 (* 1 = 1.08677 loss)
I1007 15:09:37.579964  4982 sgd_solver.cpp:105] Iteration 600, lr = 0.1
I1007 15:09:45.879250  4982 solver.cpp:218] Iteration 700 (12.0493 iter/s, 8.29923s/100 iters), loss = 1.12819
I1007 15:09:45.879281  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.12819 (* 1 = 1.12819 loss)
I1007 15:09:45.879297  4982 sgd_solver.cpp:105] Iteration 700, lr = 0.1
I1007 15:09:54.182488  4982 solver.cpp:218] Iteration 800 (12.0436 iter/s, 8.30314s/100 iters), loss = 1.03759
I1007 15:09:54.182598  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.03759 (* 1 = 1.03759 loss)
I1007 15:09:54.182605  4982 sgd_solver.cpp:105] Iteration 800, lr = 0.1
I1007 15:10:02.481420  4982 solver.cpp:218] Iteration 900 (12.05 iter/s, 8.29876s/100 iters), loss = 0.824957
I1007 15:10:02.481451  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.824957 (* 1 = 0.824957 loss)
I1007 15:10:02.481467  4982 sgd_solver.cpp:105] Iteration 900, lr = 0.1
I1007 15:10:10.377990  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:10:10.710328  4982 solver.cpp:330] Iteration 1000, Testing net (#0)
I1007 15:10:12.635676  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:10:12.716563  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.4549
I1007 15:10:12.716589  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 2.15255 (* 1 = 2.15255 loss)
I1007 15:10:12.799549  4982 solver.cpp:218] Iteration 1000 (9.69179 iter/s, 10.318s/100 iters), loss = 0.887655
I1007 15:10:12.799576  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.887655 (* 1 = 0.887655 loss)
I1007 15:10:12.799582  4982 sgd_solver.cpp:105] Iteration 1000, lr = 0.1
I1007 15:10:21.114356  4982 solver.cpp:218] Iteration 1100 (12.0269 iter/s, 8.31471s/100 iters), loss = 0.793573
I1007 15:10:21.114387  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.793573 (* 1 = 0.793573 loss)
I1007 15:10:21.114393  4982 sgd_solver.cpp:105] Iteration 1100, lr = 0.1
I1007 15:10:29.431377  4982 solver.cpp:218] Iteration 1200 (12.0237 iter/s, 8.31692s/100 iters), loss = 0.938147
I1007 15:10:29.431533  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.938147 (* 1 = 0.938147 loss)
I1007 15:10:29.431558  4982 sgd_solver.cpp:105] Iteration 1200, lr = 0.1
I1007 15:10:37.745086  4982 solver.cpp:218] Iteration 1300 (12.0286 iter/s, 8.3135s/100 iters), loss = 0.932781
I1007 15:10:37.745123  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.932781 (* 1 = 0.932781 loss)
I1007 15:10:37.745141  4982 sgd_solver.cpp:105] Iteration 1300, lr = 0.1
I1007 15:10:46.064453  4982 solver.cpp:218] Iteration 1400 (12.0203 iter/s, 8.31926s/100 iters), loss = 0.697288
I1007 15:10:46.064483  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.697288 (* 1 = 0.697288 loss)
I1007 15:10:46.064499  4982 sgd_solver.cpp:105] Iteration 1400, lr = 0.1
I1007 15:10:53.969012  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:10:54.302315  4982 solver.cpp:330] Iteration 1500, Testing net (#0)
I1007 15:10:56.228648  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:10:56.308971  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6354
I1007 15:10:56.309007  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.15671 (* 1 = 1.15671 loss)
I1007 15:10:56.392539  4982 solver.cpp:218] Iteration 1500 (9.68244 iter/s, 10.328s/100 iters), loss = 0.869125
I1007 15:10:56.392567  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.869125 (* 1 = 0.869125 loss)
I1007 15:10:56.392575  4982 sgd_solver.cpp:105] Iteration 1500, lr = 0.1
I1007 15:11:04.706393  4982 solver.cpp:218] Iteration 1600 (12.0283 iter/s, 8.31376s/100 iters), loss = 0.749132
I1007 15:11:04.706508  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.749132 (* 1 = 0.749132 loss)
I1007 15:11:04.706517  4982 sgd_solver.cpp:105] Iteration 1600, lr = 0.1
I1007 15:11:13.013849  4982 solver.cpp:218] Iteration 1700 (12.0376 iter/s, 8.30728s/100 iters), loss = 0.816207
I1007 15:11:13.013880  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.816207 (* 1 = 0.816207 loss)
I1007 15:11:13.013885  4982 sgd_solver.cpp:105] Iteration 1700, lr = 0.1
I1007 15:11:21.332290  4982 solver.cpp:218] Iteration 1800 (12.0216 iter/s, 8.31835s/100 iters), loss = 0.769503
I1007 15:11:21.332320  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.769503 (* 1 = 0.769503 loss)
I1007 15:11:21.332326  4982 sgd_solver.cpp:105] Iteration 1800, lr = 0.1
I1007 15:11:29.644625  4982 solver.cpp:218] Iteration 1900 (12.0304 iter/s, 8.31225s/100 iters), loss = 0.685864
I1007 15:11:29.644666  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.685864 (* 1 = 0.685864 loss)
I1007 15:11:29.644672  4982 sgd_solver.cpp:105] Iteration 1900, lr = 0.1
I1007 15:11:37.546794  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:11:37.879398  4982 solver.cpp:330] Iteration 2000, Testing net (#0)
I1007 15:11:39.807451  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:11:39.888648  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6494
I1007 15:11:39.888684  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.15259 (* 1 = 1.15259 loss)
I1007 15:11:39.971540  4982 solver.cpp:218] Iteration 2000 (9.68354 iter/s, 10.3268s/100 iters), loss = 0.840531
I1007 15:11:39.971567  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.840531 (* 1 = 0.840531 loss)
I1007 15:11:39.971575  4982 sgd_solver.cpp:105] Iteration 2000, lr = 0.1
I1007 15:11:48.287519  4982 solver.cpp:218] Iteration 2100 (12.0252 iter/s, 8.31589s/100 iters), loss = 0.587409
I1007 15:11:48.287550  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.587409 (* 1 = 0.587409 loss)
I1007 15:11:48.287556  4982 sgd_solver.cpp:105] Iteration 2100, lr = 0.1
I1007 15:11:56.609995  4982 solver.cpp:218] Iteration 2200 (12.0158 iter/s, 8.32239s/100 iters), loss = 0.818125
I1007 15:11:56.610036  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.818125 (* 1 = 0.818125 loss)
I1007 15:11:56.610043  4982 sgd_solver.cpp:105] Iteration 2200, lr = 0.1
I1007 15:12:04.929703  4982 solver.cpp:218] Iteration 2300 (12.0198 iter/s, 8.31962s/100 iters), loss = 0.694448
I1007 15:12:04.929764  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.694448 (* 1 = 0.694448 loss)
I1007 15:12:04.929769  4982 sgd_solver.cpp:105] Iteration 2300, lr = 0.1
I1007 15:12:13.248965  4982 solver.cpp:218] Iteration 2400 (12.0204 iter/s, 8.31916s/100 iters), loss = 0.652444
I1007 15:12:13.249097  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.652444 (* 1 = 0.652444 loss)
I1007 15:12:13.249104  4982 sgd_solver.cpp:105] Iteration 2400, lr = 0.1
I1007 15:12:21.156759  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:12:21.488999  4982 solver.cpp:330] Iteration 2500, Testing net (#0)
I1007 15:12:23.413842  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:12:23.494181  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6207
I1007 15:12:23.494216  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.21625 (* 1 = 1.21625 loss)
I1007 15:12:23.577788  4982 solver.cpp:218] Iteration 2500 (9.68181 iter/s, 10.3286s/100 iters), loss = 0.788838
I1007 15:12:23.577816  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.788838 (* 1 = 0.788838 loss)
I1007 15:12:23.577822  4982 sgd_solver.cpp:105] Iteration 2500, lr = 0.1
I1007 15:12:31.905696  4982 solver.cpp:218] Iteration 2600 (12.0079 iter/s, 8.32784s/100 iters), loss = 0.508324
I1007 15:12:31.905740  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.508324 (* 1 = 0.508324 loss)
I1007 15:12:31.905745  4982 sgd_solver.cpp:105] Iteration 2600, lr = 0.1
I1007 15:12:40.224931  4982 solver.cpp:218] Iteration 2700 (12.0205 iter/s, 8.31915s/100 iters), loss = 0.664265
I1007 15:12:40.224972  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.664265 (* 1 = 0.664265 loss)
I1007 15:12:40.224977  4982 sgd_solver.cpp:105] Iteration 2700, lr = 0.1
I1007 15:12:48.545068  4982 solver.cpp:218] Iteration 2800 (12.0192 iter/s, 8.32006s/100 iters), loss = 0.651371
I1007 15:12:48.545205  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.651371 (* 1 = 0.651371 loss)
I1007 15:12:48.545213  4982 sgd_solver.cpp:105] Iteration 2800, lr = 0.1
I1007 15:12:56.862151  4982 solver.cpp:218] Iteration 2900 (12.0237 iter/s, 8.31692s/100 iters), loss = 0.65946
I1007 15:12:56.862182  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.65946 (* 1 = 0.65946 loss)
I1007 15:12:56.862188  4982 sgd_solver.cpp:105] Iteration 2900, lr = 0.1
I1007 15:13:04.773998  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:13:05.107296  4982 solver.cpp:330] Iteration 3000, Testing net (#0)
I1007 15:13:07.034462  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:13:07.114997  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6303
I1007 15:13:07.115023  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.24869 (* 1 = 1.24869 loss)
I1007 15:13:07.197657  4982 solver.cpp:218] Iteration 3000 (9.67546 iter/s, 10.3354s/100 iters), loss = 0.699608
I1007 15:13:07.197685  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.699608 (* 1 = 0.699608 loss)
I1007 15:13:07.197692  4982 sgd_solver.cpp:105] Iteration 3000, lr = 0.1
I1007 15:13:15.511616  4982 solver.cpp:218] Iteration 3100 (12.0281 iter/s, 8.31389s/100 iters), loss = 0.505523
I1007 15:13:15.511646  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.505523 (* 1 = 0.505523 loss)
I1007 15:13:15.511651  4982 sgd_solver.cpp:105] Iteration 3100, lr = 0.1
I1007 15:13:23.830761  4982 solver.cpp:218] Iteration 3200 (12.0206 iter/s, 8.31908s/100 iters), loss = 0.60896
I1007 15:13:23.830898  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.60896 (* 1 = 0.60896 loss)
I1007 15:13:23.830920  4982 sgd_solver.cpp:105] Iteration 3200, lr = 0.1
I1007 15:13:32.149154  4982 solver.cpp:218] Iteration 3300 (12.0218 iter/s, 8.31823s/100 iters), loss = 0.683556
I1007 15:13:32.149184  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.683556 (* 1 = 0.683556 loss)
I1007 15:13:32.149190  4982 sgd_solver.cpp:105] Iteration 3300, lr = 0.1
I1007 15:13:40.472074  4982 solver.cpp:218] Iteration 3400 (12.0151 iter/s, 8.32285s/100 iters), loss = 0.566607
I1007 15:13:40.472113  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.566607 (* 1 = 0.566607 loss)
I1007 15:13:40.472120  4982 sgd_solver.cpp:105] Iteration 3400, lr = 0.1
I1007 15:13:48.375470  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:13:48.709156  4982 solver.cpp:330] Iteration 3500, Testing net (#0)
I1007 15:13:50.638164  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:13:50.719220  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6929
I1007 15:13:50.719257  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.928421 (* 1 = 0.928421 loss)
I1007 15:13:50.802986  4982 solver.cpp:218] Iteration 3500 (9.67977 iter/s, 10.3308s/100 iters), loss = 0.572185
I1007 15:13:50.803014  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.572185 (* 1 = 0.572185 loss)
I1007 15:13:50.803020  4982 sgd_solver.cpp:105] Iteration 3500, lr = 0.1
I1007 15:13:59.120138  4982 solver.cpp:218] Iteration 3600 (12.0234 iter/s, 8.31709s/100 iters), loss = 0.498918
I1007 15:13:59.120282  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.498918 (* 1 = 0.498918 loss)
I1007 15:13:59.120290  4982 sgd_solver.cpp:105] Iteration 3600, lr = 0.1
I1007 15:14:07.431416  4982 solver.cpp:218] Iteration 3700 (12.0321 iter/s, 8.3111s/100 iters), loss = 0.533909
I1007 15:14:07.431444  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.533909 (* 1 = 0.533909 loss)
I1007 15:14:07.431450  4982 sgd_solver.cpp:105] Iteration 3700, lr = 0.1
I1007 15:14:15.747282  4982 solver.cpp:218] Iteration 3800 (12.0253 iter/s, 8.3158s/100 iters), loss = 0.590811
I1007 15:14:15.747311  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.590811 (* 1 = 0.590811 loss)
I1007 15:14:15.747319  4982 sgd_solver.cpp:105] Iteration 3800, lr = 0.1
I1007 15:14:24.058516  4982 solver.cpp:218] Iteration 3900 (12.032 iter/s, 8.31117s/100 iters), loss = 0.533606
I1007 15:14:24.058547  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.533606 (* 1 = 0.533606 loss)
I1007 15:14:24.058552  4982 sgd_solver.cpp:105] Iteration 3900, lr = 0.1
I1007 15:14:31.964249  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:14:32.297050  4982 solver.cpp:330] Iteration 4000, Testing net (#0)
I1007 15:14:34.226115  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:14:34.307195  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7106
I1007 15:14:34.307232  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.829768 (* 1 = 0.829768 loss)
I1007 15:14:34.389878  4982 solver.cpp:218] Iteration 4000 (9.67933 iter/s, 10.3313s/100 iters), loss = 0.553318
I1007 15:14:34.389905  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.553318 (* 1 = 0.553318 loss)
I1007 15:14:34.389912  4982 sgd_solver.cpp:105] Iteration 4000, lr = 0.1
I1007 15:14:42.712580  4982 solver.cpp:218] Iteration 4100 (12.0154 iter/s, 8.32264s/100 iters), loss = 0.489185
I1007 15:14:42.712621  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.489185 (* 1 = 0.489185 loss)
I1007 15:14:42.712627  4982 sgd_solver.cpp:105] Iteration 4100, lr = 0.1
I1007 15:14:51.044093  4982 solver.cpp:218] Iteration 4200 (12.0027 iter/s, 8.33143s/100 iters), loss = 0.546204
I1007 15:14:51.044124  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.546204 (* 1 = 0.546204 loss)
I1007 15:14:51.044131  4982 sgd_solver.cpp:105] Iteration 4200, lr = 0.1
I1007 15:14:59.368196  4982 solver.cpp:218] Iteration 4300 (12.0134 iter/s, 8.32403s/100 iters), loss = 0.633472
I1007 15:14:59.368227  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.633472 (* 1 = 0.633472 loss)
I1007 15:14:59.368232  4982 sgd_solver.cpp:105] Iteration 4300, lr = 0.1
I1007 15:15:07.694989  4982 solver.cpp:218] Iteration 4400 (12.0095 iter/s, 8.32673s/100 iters), loss = 0.527077
I1007 15:15:07.695116  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.527077 (* 1 = 0.527077 loss)
I1007 15:15:07.695123  4982 sgd_solver.cpp:105] Iteration 4400, lr = 0.1
I1007 15:15:15.607826  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:15:15.940629  4982 solver.cpp:330] Iteration 4500, Testing net (#0)
I1007 15:15:17.868728  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:15:17.948669  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6969
I1007 15:15:17.948705  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.863002 (* 1 = 0.863002 loss)
I1007 15:15:18.032232  4982 solver.cpp:218] Iteration 4500 (9.67392 iter/s, 10.3371s/100 iters), loss = 0.541872
I1007 15:15:18.032259  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.541872 (* 1 = 0.541872 loss)
I1007 15:15:18.032266  4982 sgd_solver.cpp:105] Iteration 4500, lr = 0.1
I1007 15:15:26.360345  4982 solver.cpp:218] Iteration 4600 (12.0076 iter/s, 8.32805s/100 iters), loss = 0.456789
I1007 15:15:26.360388  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.456789 (* 1 = 0.456789 loss)
I1007 15:15:26.360394  4982 sgd_solver.cpp:105] Iteration 4600, lr = 0.1
I1007 15:15:34.677963  4982 solver.cpp:218] Iteration 4700 (12.0228 iter/s, 8.31754s/100 iters), loss = 0.529273
I1007 15:15:34.678004  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.529273 (* 1 = 0.529273 loss)
I1007 15:15:34.678011  4982 sgd_solver.cpp:105] Iteration 4700, lr = 0.1
I1007 15:15:43.001435  4982 solver.cpp:218] Iteration 4800 (12.0143 iter/s, 8.3234s/100 iters), loss = 0.601073
I1007 15:15:43.001543  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.601073 (* 1 = 0.601073 loss)
I1007 15:15:43.001550  4982 sgd_solver.cpp:105] Iteration 4800, lr = 0.1
I1007 15:15:51.322660  4982 solver.cpp:218] Iteration 4900 (12.0177 iter/s, 8.32108s/100 iters), loss = 0.505854
I1007 15:15:51.322701  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.505854 (* 1 = 0.505854 loss)
I1007 15:15:51.322707  4982 sgd_solver.cpp:105] Iteration 4900, lr = 0.1
I1007 15:15:59.234494  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:15:59.567628  4982 solver.cpp:330] Iteration 5000, Testing net (#0)
I1007 15:16:01.497114  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:16:01.578166  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.724
I1007 15:16:01.578192  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.815802 (* 1 = 0.815802 loss)
I1007 15:16:01.661145  4982 solver.cpp:218] Iteration 5000 (9.67268 iter/s, 10.3384s/100 iters), loss = 0.532011
I1007 15:16:01.661170  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.532011 (* 1 = 0.532011 loss)
I1007 15:16:01.661176  4982 sgd_solver.cpp:105] Iteration 5000, lr = 0.1
I1007 15:16:09.976456  4982 solver.cpp:218] Iteration 5100 (12.0261 iter/s, 8.31525s/100 iters), loss = 0.34892
I1007 15:16:09.976487  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.34892 (* 1 = 0.34892 loss)
I1007 15:16:09.976495  4982 sgd_solver.cpp:105] Iteration 5100, lr = 0.1
I1007 15:16:18.295280  4982 solver.cpp:218] Iteration 5200 (12.021 iter/s, 8.31875s/100 iters), loss = 0.464367
I1007 15:16:18.295444  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.464367 (* 1 = 0.464367 loss)
I1007 15:16:18.295464  4982 sgd_solver.cpp:105] Iteration 5200, lr = 0.1
I1007 15:16:26.611860  4982 solver.cpp:218] Iteration 5300 (12.0245 iter/s, 8.31639s/100 iters), loss = 0.552368
I1007 15:16:26.611902  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.552368 (* 1 = 0.552368 loss)
I1007 15:16:26.611908  4982 sgd_solver.cpp:105] Iteration 5300, lr = 0.1
I1007 15:16:34.929358  4982 solver.cpp:218] Iteration 5400 (12.023 iter/s, 8.31742s/100 iters), loss = 0.496459
I1007 15:16:34.929399  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.496459 (* 1 = 0.496459 loss)
I1007 15:16:34.929405  4982 sgd_solver.cpp:105] Iteration 5400, lr = 0.1
I1007 15:16:42.827775  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:16:43.161665  4982 solver.cpp:330] Iteration 5500, Testing net (#0)
I1007 15:16:45.090517  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:16:45.171042  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.736
I1007 15:16:45.171078  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.756128 (* 1 = 0.756128 loss)
I1007 15:16:45.254319  4982 solver.cpp:218] Iteration 5500 (9.68535 iter/s, 10.3249s/100 iters), loss = 0.488018
I1007 15:16:45.254354  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.488018 (* 1 = 0.488018 loss)
I1007 15:16:45.254360  4982 sgd_solver.cpp:105] Iteration 5500, lr = 0.1
I1007 15:16:53.581859  4982 solver.cpp:218] Iteration 5600 (12.0084 iter/s, 8.32747s/100 iters), loss = 0.423933
I1007 15:16:53.581972  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.423933 (* 1 = 0.423933 loss)
I1007 15:16:53.581979  4982 sgd_solver.cpp:105] Iteration 5600, lr = 0.1
I1007 15:17:01.903457  4982 solver.cpp:218] Iteration 5700 (12.0171 iter/s, 8.32146s/100 iters), loss = 0.481339
I1007 15:17:01.903488  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.481339 (* 1 = 0.481339 loss)
I1007 15:17:01.903494  4982 sgd_solver.cpp:105] Iteration 5700, lr = 0.1
I1007 15:17:10.227481  4982 solver.cpp:218] Iteration 5800 (12.0135 iter/s, 8.32396s/100 iters), loss = 0.681592
I1007 15:17:10.227522  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.681592 (* 1 = 0.681592 loss)
I1007 15:17:10.227529  4982 sgd_solver.cpp:105] Iteration 5800, lr = 0.1
I1007 15:17:18.543274  4982 solver.cpp:218] Iteration 5900 (12.0254 iter/s, 8.31572s/100 iters), loss = 0.499617
I1007 15:17:18.543315  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.499617 (* 1 = 0.499617 loss)
I1007 15:17:18.543321  4982 sgd_solver.cpp:105] Iteration 5900, lr = 0.1
I1007 15:17:26.453282  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:17:26.786249  4982 solver.cpp:330] Iteration 6000, Testing net (#0)
I1007 15:17:28.712045  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:17:28.793124  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.708
I1007 15:17:28.793159  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.816681 (* 1 = 0.816681 loss)
I1007 15:17:28.876405  4982 solver.cpp:218] Iteration 6000 (9.67769 iter/s, 10.333s/100 iters), loss = 0.434639
I1007 15:17:28.876432  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.434639 (* 1 = 0.434639 loss)
I1007 15:17:28.876440  4982 sgd_solver.cpp:105] Iteration 6000, lr = 0.1
I1007 15:17:37.187953  4982 solver.cpp:218] Iteration 6100 (12.0315 iter/s, 8.31148s/100 iters), loss = 0.385544
I1007 15:17:37.187983  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.385544 (* 1 = 0.385544 loss)
I1007 15:17:37.187988  4982 sgd_solver.cpp:105] Iteration 6100, lr = 0.1
I1007 15:17:45.503243  4982 solver.cpp:218] Iteration 6200 (12.0261 iter/s, 8.31523s/100 iters), loss = 0.435298
I1007 15:17:45.503273  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.435298 (* 1 = 0.435298 loss)
I1007 15:17:45.503279  4982 sgd_solver.cpp:105] Iteration 6200, lr = 0.1
I1007 15:17:53.813705  4982 solver.cpp:218] Iteration 6300 (12.0331 iter/s, 8.3104s/100 iters), loss = 0.500896
I1007 15:17:53.813735  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.500896 (* 1 = 0.500896 loss)
I1007 15:17:53.813742  4982 sgd_solver.cpp:105] Iteration 6300, lr = 0.1
I1007 15:18:02.128787  4982 solver.cpp:218] Iteration 6400 (12.0264 iter/s, 8.31502s/100 iters), loss = 0.436697
I1007 15:18:02.128907  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.436697 (* 1 = 0.436697 loss)
I1007 15:18:02.128916  4982 sgd_solver.cpp:105] Iteration 6400, lr = 0.1
I1007 15:18:10.030390  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:18:10.362640  4982 solver.cpp:330] Iteration 6500, Testing net (#0)
I1007 15:18:12.289854  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:18:12.370527  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7424
I1007 15:18:12.370561  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.725587 (* 1 = 0.725587 loss)
I1007 15:18:12.454110  4982 solver.cpp:218] Iteration 6500 (9.68508 iter/s, 10.3252s/100 iters), loss = 0.442276
I1007 15:18:12.454136  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.442276 (* 1 = 0.442276 loss)
I1007 15:18:12.454144  4982 sgd_solver.cpp:105] Iteration 6500, lr = 0.1
I1007 15:18:20.765843  4982 solver.cpp:218] Iteration 6600 (12.0313 iter/s, 8.31167s/100 iters), loss = 0.37318
I1007 15:18:20.765884  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.37318 (* 1 = 0.37318 loss)
I1007 15:18:20.765890  4982 sgd_solver.cpp:105] Iteration 6600, lr = 0.1
I1007 15:18:29.071382  4982 solver.cpp:218] Iteration 6700 (12.0403 iter/s, 8.30546s/100 iters), loss = 0.484392
I1007 15:18:29.071413  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.484392 (* 1 = 0.484392 loss)
I1007 15:18:29.071418  4982 sgd_solver.cpp:105] Iteration 6700, lr = 0.1
I1007 15:18:37.386396  4982 solver.cpp:218] Iteration 6800 (12.0265 iter/s, 8.31495s/100 iters), loss = 0.469869
I1007 15:18:37.386533  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.469869 (* 1 = 0.469869 loss)
I1007 15:18:37.386554  4982 sgd_solver.cpp:105] Iteration 6800, lr = 0.1
I1007 15:18:45.697355  4982 solver.cpp:218] Iteration 6900 (12.0325 iter/s, 8.31079s/100 iters), loss = 0.417282
I1007 15:18:45.697386  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.417282 (* 1 = 0.417282 loss)
I1007 15:18:45.697393  4982 sgd_solver.cpp:105] Iteration 6900, lr = 0.1
I1007 15:18:53.598754  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:18:53.930698  4982 solver.cpp:330] Iteration 7000, Testing net (#0)
I1007 15:18:55.859097  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:18:55.940099  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6525
I1007 15:18:55.940134  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.00704 (* 1 = 1.00704 loss)
I1007 15:18:56.023234  4982 solver.cpp:218] Iteration 7000 (9.68447 iter/s, 10.3258s/100 iters), loss = 0.425554
I1007 15:18:56.023259  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.425554 (* 1 = 0.425554 loss)
I1007 15:18:56.023267  4982 sgd_solver.cpp:105] Iteration 7000, lr = 0.1
I1007 15:19:04.342380  4982 solver.cpp:218] Iteration 7100 (12.0205 iter/s, 8.31909s/100 iters), loss = 0.251816
I1007 15:19:04.342409  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.251816 (* 1 = 0.251816 loss)
I1007 15:19:04.342416  4982 sgd_solver.cpp:105] Iteration 7100, lr = 0.1
I1007 15:19:12.666184  4982 solver.cpp:218] Iteration 7200 (12.0138 iter/s, 8.32374s/100 iters), loss = 0.491826
I1007 15:19:12.666288  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.491826 (* 1 = 0.491826 loss)
I1007 15:19:12.666296  4982 sgd_solver.cpp:105] Iteration 7200, lr = 0.1
I1007 15:19:20.983110  4982 solver.cpp:218] Iteration 7300 (12.0239 iter/s, 8.31679s/100 iters), loss = 0.489229
I1007 15:19:20.983150  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.489229 (* 1 = 0.489229 loss)
I1007 15:19:20.983156  4982 sgd_solver.cpp:105] Iteration 7300, lr = 0.1
I1007 15:19:29.297545  4982 solver.cpp:218] Iteration 7400 (12.0274 iter/s, 8.31436s/100 iters), loss = 0.447089
I1007 15:19:29.297586  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.447089 (* 1 = 0.447089 loss)
I1007 15:19:29.297592  4982 sgd_solver.cpp:105] Iteration 7400, lr = 0.1
I1007 15:19:37.201925  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:19:37.534806  4982 solver.cpp:330] Iteration 7500, Testing net (#0)
I1007 15:19:39.462944  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:19:39.543450  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7591
I1007 15:19:39.543486  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.708208 (* 1 = 0.708208 loss)
I1007 15:19:39.627737  4982 solver.cpp:218] Iteration 7500 (9.68044 iter/s, 10.3301s/100 iters), loss = 0.449312
I1007 15:19:39.627764  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.449312 (* 1 = 0.449312 loss)
I1007 15:19:39.627771  4982 sgd_solver.cpp:105] Iteration 7500, lr = 0.1
I1007 15:19:47.950862  4982 solver.cpp:218] Iteration 7600 (12.0148 iter/s, 8.32307s/100 iters), loss = 0.420251
I1007 15:19:47.950986  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.420251 (* 1 = 0.420251 loss)
I1007 15:19:47.950994  4982 sgd_solver.cpp:105] Iteration 7600, lr = 0.1
I1007 15:19:56.264720  4982 solver.cpp:218] Iteration 7700 (12.0283 iter/s, 8.3137s/100 iters), loss = 0.440795
I1007 15:19:56.264750  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.440795 (* 1 = 0.440795 loss)
I1007 15:19:56.264757  4982 sgd_solver.cpp:105] Iteration 7700, lr = 0.1
I1007 15:20:04.582923  4982 solver.cpp:218] Iteration 7800 (12.0219 iter/s, 8.31814s/100 iters), loss = 0.476052
I1007 15:20:04.582953  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.476052 (* 1 = 0.476052 loss)
I1007 15:20:04.582960  4982 sgd_solver.cpp:105] Iteration 7800, lr = 0.1
I1007 15:20:12.900388  4982 solver.cpp:218] Iteration 7900 (12.023 iter/s, 8.3174s/100 iters), loss = 0.432903
I1007 15:20:12.900419  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.432903 (* 1 = 0.432903 loss)
I1007 15:20:12.900427  4982 sgd_solver.cpp:105] Iteration 7900, lr = 0.1
I1007 15:20:20.808858  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:20:21.141660  4982 solver.cpp:330] Iteration 8000, Testing net (#0)
I1007 15:20:23.069031  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:20:23.150104  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7069
I1007 15:20:23.150140  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.84204 (* 1 = 0.84204 loss)
I1007 15:20:23.232730  4982 solver.cpp:218] Iteration 8000 (9.67841 iter/s, 10.3323s/100 iters), loss = 0.454548
I1007 15:20:23.232772  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.454548 (* 1 = 0.454548 loss)
I1007 15:20:23.232779  4982 sgd_solver.cpp:105] Iteration 8000, lr = 0.1
I1007 15:20:31.550649  4982 solver.cpp:218] Iteration 8100 (12.0223 iter/s, 8.31785s/100 iters), loss = 0.319537
I1007 15:20:31.550690  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.319537 (* 1 = 0.319537 loss)
I1007 15:20:31.550696  4982 sgd_solver.cpp:105] Iteration 8100, lr = 0.1
I1007 15:20:39.870532  4982 solver.cpp:218] Iteration 8200 (12.0195 iter/s, 8.31981s/100 iters), loss = 0.391852
I1007 15:20:39.870559  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.391852 (* 1 = 0.391852 loss)
I1007 15:20:39.870565  4982 sgd_solver.cpp:105] Iteration 8200, lr = 0.1
I1007 15:20:48.181331  4982 solver.cpp:218] Iteration 8300 (12.0326 iter/s, 8.31074s/100 iters), loss = 0.527533
I1007 15:20:48.181361  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.527533 (* 1 = 0.527533 loss)
I1007 15:20:48.181366  4982 sgd_solver.cpp:105] Iteration 8300, lr = 0.1
I1007 15:20:56.498867  4982 solver.cpp:218] Iteration 8400 (12.0229 iter/s, 8.31747s/100 iters), loss = 0.456875
I1007 15:20:56.498966  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.456875 (* 1 = 0.456875 loss)
I1007 15:20:56.498975  4982 sgd_solver.cpp:105] Iteration 8400, lr = 0.1
I1007 15:21:04.406307  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:21:04.740355  4982 solver.cpp:330] Iteration 8500, Testing net (#0)
I1007 15:21:06.669884  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:21:06.750255  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7458
I1007 15:21:06.750291  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.74212 (* 1 = 0.74212 loss)
I1007 15:21:06.834127  4982 solver.cpp:218] Iteration 8500 (9.67574 iter/s, 10.3351s/100 iters), loss = 0.467493
I1007 15:21:06.834156  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.467493 (* 1 = 0.467493 loss)
I1007 15:21:06.834162  4982 sgd_solver.cpp:105] Iteration 8500, lr = 0.1
I1007 15:21:15.167593  4982 solver.cpp:218] Iteration 8600 (11.9999 iter/s, 8.33341s/100 iters), loss = 0.365573
I1007 15:21:15.167624  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.365573 (* 1 = 0.365573 loss)
I1007 15:21:15.167630  4982 sgd_solver.cpp:105] Iteration 8600, lr = 0.1
I1007 15:21:23.502737  4982 solver.cpp:218] Iteration 8700 (11.9975 iter/s, 8.33508s/100 iters), loss = 0.345772
I1007 15:21:23.502768  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.345772 (* 1 = 0.345772 loss)
I1007 15:21:23.502774  4982 sgd_solver.cpp:105] Iteration 8700, lr = 0.1
I1007 15:21:31.845302  4982 solver.cpp:218] Iteration 8800 (11.9868 iter/s, 8.3425s/100 iters), loss = 0.521405
I1007 15:21:31.845384  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.521405 (* 1 = 0.521405 loss)
I1007 15:21:31.845391  4982 sgd_solver.cpp:105] Iteration 8800, lr = 0.1
I1007 15:21:40.183843  4982 solver.cpp:218] Iteration 8900 (11.9927 iter/s, 8.33843s/100 iters), loss = 0.359961
I1007 15:21:40.183889  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.359961 (* 1 = 0.359961 loss)
I1007 15:21:40.183897  4982 sgd_solver.cpp:105] Iteration 8900, lr = 0.1
I1007 15:21:48.108986  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:21:48.442303  4982 solver.cpp:330] Iteration 9000, Testing net (#0)
I1007 15:21:50.373574  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:21:50.454601  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6704
I1007 15:21:50.454634  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.07662 (* 1 = 1.07662 loss)
I1007 15:21:50.537463  4982 solver.cpp:218] Iteration 9000 (9.65853 iter/s, 10.3535s/100 iters), loss = 0.365701
I1007 15:21:50.537488  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.365701 (* 1 = 0.365701 loss)
I1007 15:21:50.537494  4982 sgd_solver.cpp:105] Iteration 9000, lr = 0.1
I1007 15:21:58.859709  4982 solver.cpp:218] Iteration 9100 (12.0161 iter/s, 8.32219s/100 iters), loss = 0.315271
I1007 15:21:58.859740  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.315271 (* 1 = 0.315271 loss)
I1007 15:21:58.859745  4982 sgd_solver.cpp:105] Iteration 9100, lr = 0.1
I1007 15:22:07.192507  4982 solver.cpp:218] Iteration 9200 (12.0009 iter/s, 8.33274s/100 iters), loss = 0.478537
I1007 15:22:07.192598  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.478537 (* 1 = 0.478537 loss)
I1007 15:22:07.192615  4982 sgd_solver.cpp:105] Iteration 9200, lr = 0.1
I1007 15:22:15.519493  4982 solver.cpp:218] Iteration 9300 (12.0093 iter/s, 8.32687s/100 iters), loss = 0.435451
I1007 15:22:15.519533  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.435451 (* 1 = 0.435451 loss)
I1007 15:22:15.519539  4982 sgd_solver.cpp:105] Iteration 9300, lr = 0.1
I1007 15:22:23.847311  4982 solver.cpp:218] Iteration 9400 (12.0081 iter/s, 8.32775s/100 iters), loss = 0.37447
I1007 15:22:23.847342  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.37447 (* 1 = 0.37447 loss)
I1007 15:22:23.847347  4982 sgd_solver.cpp:105] Iteration 9400, lr = 0.1
I1007 15:22:31.762965  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:22:32.096666  4982 solver.cpp:330] Iteration 9500, Testing net (#0)
I1007 15:22:34.029881  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:22:34.110463  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7681
I1007 15:22:34.110497  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.689275 (* 1 = 0.689275 loss)
I1007 15:22:34.194119  4982 solver.cpp:218] Iteration 9500 (9.66488 iter/s, 10.3467s/100 iters), loss = 0.410733
I1007 15:22:34.194145  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.410733 (* 1 = 0.410733 loss)
I1007 15:22:34.194151  4982 sgd_solver.cpp:105] Iteration 9500, lr = 0.1
I1007 15:22:42.516456  4982 solver.cpp:218] Iteration 9600 (12.0159 iter/s, 8.32228s/100 iters), loss = 0.426842
I1007 15:22:42.516577  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.426842 (* 1 = 0.426842 loss)
I1007 15:22:42.516584  4982 sgd_solver.cpp:105] Iteration 9600, lr = 0.1
I1007 15:22:50.842222  4982 solver.cpp:218] Iteration 9700 (12.0111 iter/s, 8.32562s/100 iters), loss = 0.448867
I1007 15:22:50.842252  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.448867 (* 1 = 0.448867 loss)
I1007 15:22:50.842257  4982 sgd_solver.cpp:105] Iteration 9700, lr = 0.1
I1007 15:22:59.170733  4982 solver.cpp:218] Iteration 9800 (12.007 iter/s, 8.32845s/100 iters), loss = 0.431386
I1007 15:22:59.170763  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.431386 (* 1 = 0.431386 loss)
I1007 15:22:59.170768  4982 sgd_solver.cpp:105] Iteration 9800, lr = 0.1
I1007 15:23:07.494460  4982 solver.cpp:218] Iteration 9900 (12.0139 iter/s, 8.32367s/100 iters), loss = 0.374473
I1007 15:23:07.494500  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.374473 (* 1 = 0.374473 loss)
I1007 15:23:07.494506  4982 sgd_solver.cpp:105] Iteration 9900, lr = 0.1
I1007 15:23:15.410404  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:23:15.743741  4982 solver.cpp:330] Iteration 10000, Testing net (#0)
I1007 15:23:17.675055  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:23:17.755820  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7816
I1007 15:23:17.755856  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.640548 (* 1 = 0.640548 loss)
I1007 15:23:17.838697  4982 solver.cpp:218] Iteration 10000 (9.66729 iter/s, 10.3442s/100 iters), loss = 0.406795
I1007 15:23:17.838724  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.406795 (* 1 = 0.406795 loss)
I1007 15:23:17.838732  4982 sgd_solver.cpp:105] Iteration 10000, lr = 0.1
I1007 15:23:26.167668  4982 solver.cpp:218] Iteration 10100 (12.0064 iter/s, 8.32891s/100 iters), loss = 0.287259
I1007 15:23:26.167708  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.287259 (* 1 = 0.287259 loss)
I1007 15:23:26.167714  4982 sgd_solver.cpp:105] Iteration 10100, lr = 0.1
I1007 15:23:34.500849  4982 solver.cpp:218] Iteration 10200 (12.0003 iter/s, 8.33311s/100 iters), loss = 0.376428
I1007 15:23:34.500880  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.376428 (* 1 = 0.376428 loss)
I1007 15:23:34.500885  4982 sgd_solver.cpp:105] Iteration 10200, lr = 0.1
I1007 15:23:42.827539  4982 solver.cpp:218] Iteration 10300 (12.0097 iter/s, 8.32663s/100 iters), loss = 0.405799
I1007 15:23:42.827570  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.405799 (* 1 = 0.405799 loss)
I1007 15:23:42.827575  4982 sgd_solver.cpp:105] Iteration 10300, lr = 0.1
I1007 15:23:51.163345  4982 solver.cpp:218] Iteration 10400 (11.9965 iter/s, 8.33575s/100 iters), loss = 0.36303
I1007 15:23:51.163473  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.36303 (* 1 = 0.36303 loss)
I1007 15:23:51.163491  4982 sgd_solver.cpp:105] Iteration 10400, lr = 0.1
I1007 15:23:59.081487  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:23:59.415482  4982 solver.cpp:330] Iteration 10500, Testing net (#0)
I1007 15:24:01.348858  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:24:01.429708  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7634
I1007 15:24:01.429745  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.693453 (* 1 = 0.693453 loss)
I1007 15:24:01.513738  4982 solver.cpp:218] Iteration 10500 (9.66161 iter/s, 10.3502s/100 iters), loss = 0.405604
I1007 15:24:01.513767  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.405604 (* 1 = 0.405604 loss)
I1007 15:24:01.513773  4982 sgd_solver.cpp:105] Iteration 10500, lr = 0.1
I1007 15:24:09.849680  4982 solver.cpp:218] Iteration 10600 (11.9963 iter/s, 8.33589s/100 iters), loss = 0.268638
I1007 15:24:09.849712  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.268638 (* 1 = 0.268638 loss)
I1007 15:24:09.849719  4982 sgd_solver.cpp:105] Iteration 10600, lr = 0.1
I1007 15:24:18.178755  4982 solver.cpp:218] Iteration 10700 (12.0062 iter/s, 8.32901s/100 iters), loss = 0.39722
I1007 15:24:18.178795  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.39722 (* 1 = 0.39722 loss)
I1007 15:24:18.178802  4982 sgd_solver.cpp:105] Iteration 10700, lr = 0.1
I1007 15:24:26.515463  4982 solver.cpp:218] Iteration 10800 (11.9952 iter/s, 8.33664s/100 iters), loss = 0.527947
I1007 15:24:26.515575  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.527947 (* 1 = 0.527947 loss)
I1007 15:24:26.515583  4982 sgd_solver.cpp:105] Iteration 10800, lr = 0.1
I1007 15:24:34.845923  4982 solver.cpp:218] Iteration 10900 (12.0043 iter/s, 8.33033s/100 iters), loss = 0.526061
I1007 15:24:34.845953  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.526061 (* 1 = 0.526061 loss)
I1007 15:24:34.845959  4982 sgd_solver.cpp:105] Iteration 10900, lr = 0.1
I1007 15:24:42.768676  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:24:43.101181  4982 solver.cpp:330] Iteration 11000, Testing net (#0)
I1007 15:24:45.032611  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:24:45.114733  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7525
I1007 15:24:45.114759  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.734015 (* 1 = 0.734015 loss)
I1007 15:24:45.197373  4982 solver.cpp:218] Iteration 11000 (9.66054 iter/s, 10.3514s/100 iters), loss = 0.374559
I1007 15:24:45.197398  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.374559 (* 1 = 0.374559 loss)
I1007 15:24:45.197405  4982 sgd_solver.cpp:105] Iteration 11000, lr = 0.1
I1007 15:24:53.532789  4982 solver.cpp:218] Iteration 11100 (11.9971 iter/s, 8.33536s/100 iters), loss = 0.373318
I1007 15:24:53.532829  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.373318 (* 1 = 0.373318 loss)
I1007 15:24:53.532835  4982 sgd_solver.cpp:105] Iteration 11100, lr = 0.1
I1007 15:25:01.872620  4982 solver.cpp:218] Iteration 11200 (11.9908 iter/s, 8.33976s/100 iters), loss = 0.395216
I1007 15:25:01.872699  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.395216 (* 1 = 0.395216 loss)
I1007 15:25:01.872714  4982 sgd_solver.cpp:105] Iteration 11200, lr = 0.1
I1007 15:25:10.207126  4982 solver.cpp:218] Iteration 11300 (11.9985 iter/s, 8.33439s/100 iters), loss = 0.496007
I1007 15:25:10.207159  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.496007 (* 1 = 0.496007 loss)
I1007 15:25:10.207166  4982 sgd_solver.cpp:105] Iteration 11300, lr = 0.1
I1007 15:25:18.550103  4982 solver.cpp:218] Iteration 11400 (11.9862 iter/s, 8.34292s/100 iters), loss = 0.435594
I1007 15:25:18.550144  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.435594 (* 1 = 0.435594 loss)
I1007 15:25:18.550150  4982 sgd_solver.cpp:105] Iteration 11400, lr = 0.1
I1007 15:25:26.471328  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:25:26.804991  4982 solver.cpp:330] Iteration 11500, Testing net (#0)
I1007 15:25:28.736018  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:25:28.816715  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.777
I1007 15:25:28.816743  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.681076 (* 1 = 0.681076 loss)
I1007 15:25:28.900563  4982 solver.cpp:218] Iteration 11500 (9.66148 iter/s, 10.3504s/100 iters), loss = 0.382113
I1007 15:25:28.900593  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.382113 (* 1 = 0.382113 loss)
I1007 15:25:28.900604  4982 sgd_solver.cpp:105] Iteration 11500, lr = 0.1
I1007 15:25:37.248649  4982 solver.cpp:218] Iteration 11600 (11.9789 iter/s, 8.34803s/100 iters), loss = 0.288063
I1007 15:25:37.248777  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.288063 (* 1 = 0.288063 loss)
I1007 15:25:37.248801  4982 sgd_solver.cpp:105] Iteration 11600, lr = 0.1
I1007 15:25:45.582629  4982 solver.cpp:218] Iteration 11700 (11.9993 iter/s, 8.33384s/100 iters), loss = 0.413046
I1007 15:25:45.582661  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.413046 (* 1 = 0.413046 loss)
I1007 15:25:45.582680  4982 sgd_solver.cpp:105] Iteration 11700, lr = 0.1
I1007 15:25:53.920231  4982 solver.cpp:218] Iteration 11800 (11.9939 iter/s, 8.33754s/100 iters), loss = 0.532315
I1007 15:25:53.920264  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.532315 (* 1 = 0.532315 loss)
I1007 15:25:53.920284  4982 sgd_solver.cpp:105] Iteration 11800, lr = 0.1
I1007 15:26:02.259148  4982 solver.cpp:218] Iteration 11900 (11.9921 iter/s, 8.33885s/100 iters), loss = 0.381827
I1007 15:26:02.259183  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.381826 (* 1 = 0.381826 loss)
I1007 15:26:02.259192  4982 sgd_solver.cpp:105] Iteration 11900, lr = 0.1
I1007 15:26:10.182016  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:26:10.517659  4982 solver.cpp:330] Iteration 12000, Testing net (#0)
I1007 15:26:12.448987  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:26:12.529851  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7847
I1007 15:26:12.529880  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.620846 (* 1 = 0.620846 loss)
I1007 15:26:12.612679  4982 solver.cpp:218] Iteration 12000 (9.6586 iter/s, 10.3535s/100 iters), loss = 0.386379
I1007 15:26:12.612706  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.386379 (* 1 = 0.386379 loss)
I1007 15:26:12.612716  4982 sgd_solver.cpp:105] Iteration 12000, lr = 0.1
I1007 15:26:20.941885  4982 solver.cpp:218] Iteration 12100 (12.006 iter/s, 8.32915s/100 iters), loss = 0.304459
I1007 15:26:20.941917  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.304459 (* 1 = 0.304459 loss)
I1007 15:26:20.941936  4982 sgd_solver.cpp:105] Iteration 12100, lr = 0.1
I1007 15:26:29.281371  4982 solver.cpp:218] Iteration 12200 (11.9912 iter/s, 8.33943s/100 iters), loss = 0.350802
I1007 15:26:29.281405  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.350802 (* 1 = 0.350802 loss)
I1007 15:26:29.281414  4982 sgd_solver.cpp:105] Iteration 12200, lr = 0.1
I1007 15:26:37.618221  4982 solver.cpp:218] Iteration 12300 (11.995 iter/s, 8.33678s/100 iters), loss = 0.399587
I1007 15:26:37.618253  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.399587 (* 1 = 0.399587 loss)
I1007 15:26:37.618271  4982 sgd_solver.cpp:105] Iteration 12300, lr = 0.1
I1007 15:26:45.958017  4982 solver.cpp:218] Iteration 12400 (11.9908 iter/s, 8.33974s/100 iters), loss = 0.371588
I1007 15:26:45.958128  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.371588 (* 1 = 0.371588 loss)
I1007 15:26:45.958138  4982 sgd_solver.cpp:105] Iteration 12400, lr = 0.1
I1007 15:26:53.877679  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:26:54.209877  4982 solver.cpp:330] Iteration 12500, Testing net (#0)
I1007 15:26:56.143388  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:26:56.224231  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8009
I1007 15:26:56.224259  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.579428 (* 1 = 0.579428 loss)
I1007 15:26:56.307723  4982 solver.cpp:218] Iteration 12500 (9.66224 iter/s, 10.3496s/100 iters), loss = 0.325235
I1007 15:26:56.307757  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.325235 (* 1 = 0.325235 loss)
I1007 15:26:56.307767  4982 sgd_solver.cpp:105] Iteration 12500, lr = 0.1
I1007 15:27:04.634804  4982 solver.cpp:218] Iteration 12600 (12.0091 iter/s, 8.32702s/100 iters), loss = 0.296232
I1007 15:27:04.634837  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.296232 (* 1 = 0.296232 loss)
I1007 15:27:04.634855  4982 sgd_solver.cpp:105] Iteration 12600, lr = 0.1
I1007 15:27:12.953423  4982 solver.cpp:218] Iteration 12700 (12.0213 iter/s, 8.31856s/100 iters), loss = 0.506837
I1007 15:27:12.953456  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.506837 (* 1 = 0.506837 loss)
I1007 15:27:12.953474  4982 sgd_solver.cpp:105] Iteration 12700, lr = 0.1
I1007 15:27:21.280604  4982 solver.cpp:218] Iteration 12800 (12.009 iter/s, 8.32712s/100 iters), loss = 0.432395
I1007 15:27:21.280784  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.432395 (* 1 = 0.432395 loss)
I1007 15:27:21.280809  4982 sgd_solver.cpp:105] Iteration 12800, lr = 0.1
I1007 15:27:29.605522  4982 solver.cpp:218] Iteration 12900 (12.0124 iter/s, 8.32473s/100 iters), loss = 0.309763
I1007 15:27:29.605557  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.309763 (* 1 = 0.309763 loss)
I1007 15:27:29.605576  4982 sgd_solver.cpp:105] Iteration 12900, lr = 0.1
I1007 15:27:37.523121  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:27:37.856463  4982 solver.cpp:330] Iteration 13000, Testing net (#0)
I1007 15:27:39.787983  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:27:39.869179  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7556
I1007 15:27:39.869207  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.74216 (* 1 = 0.74216 loss)
I1007 15:27:39.951866  4982 solver.cpp:218] Iteration 13000 (9.66531 iter/s, 10.3463s/100 iters), loss = 0.303021
I1007 15:27:39.951895  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.303021 (* 1 = 0.303021 loss)
I1007 15:27:39.951905  4982 sgd_solver.cpp:105] Iteration 13000, lr = 0.1
I1007 15:27:48.286605  4982 solver.cpp:218] Iteration 13100 (11.9981 iter/s, 8.33468s/100 iters), loss = 0.2884
I1007 15:27:48.286638  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.2884 (* 1 = 0.2884 loss)
I1007 15:27:48.286656  4982 sgd_solver.cpp:105] Iteration 13100, lr = 0.1
I1007 15:27:56.627910  4982 solver.cpp:218] Iteration 13200 (11.9886 iter/s, 8.34125s/100 iters), loss = 0.380371
I1007 15:27:56.628057  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.380371 (* 1 = 0.380371 loss)
I1007 15:27:56.628068  4982 sgd_solver.cpp:105] Iteration 13200, lr = 0.1
I1007 15:28:04.964139  4982 solver.cpp:218] Iteration 13300 (11.9961 iter/s, 8.33605s/100 iters), loss = 0.476281
I1007 15:28:04.964172  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.476281 (* 1 = 0.476281 loss)
I1007 15:28:04.964190  4982 sgd_solver.cpp:105] Iteration 13300, lr = 0.1
I1007 15:28:13.303815  4982 solver.cpp:218] Iteration 13400 (11.991 iter/s, 8.33962s/100 iters), loss = 0.274809
I1007 15:28:13.303849  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.274809 (* 1 = 0.274809 loss)
I1007 15:28:13.303858  4982 sgd_solver.cpp:105] Iteration 13400, lr = 0.1
I1007 15:28:21.224699  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:28:21.557904  4982 solver.cpp:330] Iteration 13500, Testing net (#0)
I1007 15:28:23.489233  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:28:23.569723  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8117
I1007 15:28:23.569753  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.5561 (* 1 = 0.5561 loss)
I1007 15:28:23.653801  4982 solver.cpp:218] Iteration 13500 (9.66191 iter/s, 10.3499s/100 iters), loss = 0.32914
I1007 15:28:23.653829  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.32914 (* 1 = 0.32914 loss)
I1007 15:28:23.653839  4982 sgd_solver.cpp:105] Iteration 13500, lr = 0.1
I1007 15:28:31.986922  4982 solver.cpp:218] Iteration 13600 (12.0004 iter/s, 8.33306s/100 iters), loss = 0.32032
I1007 15:28:31.987084  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.32032 (* 1 = 0.32032 loss)
I1007 15:28:31.987105  4982 sgd_solver.cpp:105] Iteration 13600, lr = 0.1
I1007 15:28:40.309084  4982 solver.cpp:218] Iteration 13700 (12.0164 iter/s, 8.32199s/100 iters), loss = 0.363638
I1007 15:28:40.309118  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.363638 (* 1 = 0.363638 loss)
I1007 15:28:40.309137  4982 sgd_solver.cpp:105] Iteration 13700, lr = 0.1
I1007 15:28:48.632474  4982 solver.cpp:218] Iteration 13800 (12.0144 iter/s, 8.32333s/100 iters), loss = 0.444532
I1007 15:28:48.632508  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.444532 (* 1 = 0.444532 loss)
I1007 15:28:48.632526  4982 sgd_solver.cpp:105] Iteration 13800, lr = 0.1
I1007 15:28:56.957871  4982 solver.cpp:218] Iteration 13900 (12.0115 iter/s, 8.32534s/100 iters), loss = 0.379276
I1007 15:28:56.957904  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.379276 (* 1 = 0.379276 loss)
I1007 15:28:56.957923  4982 sgd_solver.cpp:105] Iteration 13900, lr = 0.1
I1007 15:29:04.878955  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:29:05.212661  4982 solver.cpp:330] Iteration 14000, Testing net (#0)
I1007 15:29:07.144770  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:29:07.225466  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8286
I1007 15:29:07.225493  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.506365 (* 1 = 0.506365 loss)
I1007 15:29:07.308347  4982 solver.cpp:218] Iteration 14000 (9.66145 iter/s, 10.3504s/100 iters), loss = 0.367857
I1007 15:29:07.308382  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.367857 (* 1 = 0.367857 loss)
I1007 15:29:07.308392  4982 sgd_solver.cpp:105] Iteration 14000, lr = 0.1
I1007 15:29:15.643213  4982 solver.cpp:218] Iteration 14100 (11.9979 iter/s, 8.3348s/100 iters), loss = 0.27982
I1007 15:29:15.643247  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.279819 (* 1 = 0.279819 loss)
I1007 15:29:15.643256  4982 sgd_solver.cpp:105] Iteration 14100, lr = 0.1
I1007 15:29:23.983039  4982 solver.cpp:218] Iteration 14200 (11.9907 iter/s, 8.33977s/100 iters), loss = 0.404179
I1007 15:29:23.983074  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.404179 (* 1 = 0.404179 loss)
I1007 15:29:23.983093  4982 sgd_solver.cpp:105] Iteration 14200, lr = 0.1
I1007 15:29:32.317051  4982 solver.cpp:218] Iteration 14300 (11.9991 iter/s, 8.33395s/100 iters), loss = 0.46139
I1007 15:29:32.317085  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.46139 (* 1 = 0.46139 loss)
I1007 15:29:32.317102  4982 sgd_solver.cpp:105] Iteration 14300, lr = 0.1
I1007 15:29:40.652480  4982 solver.cpp:218] Iteration 14400 (11.9971 iter/s, 8.33537s/100 iters), loss = 0.400089
I1007 15:29:40.652609  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.400089 (* 1 = 0.400089 loss)
I1007 15:29:40.652643  4982 sgd_solver.cpp:105] Iteration 14400, lr = 0.1
I1007 15:29:48.566517  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:29:48.899500  4982 solver.cpp:330] Iteration 14500, Testing net (#0)
I1007 15:29:50.832676  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:29:50.913471  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7884
I1007 15:29:50.913501  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.640291 (* 1 = 0.640291 loss)
I1007 15:29:50.996815  4982 solver.cpp:218] Iteration 14500 (9.66727 iter/s, 10.3442s/100 iters), loss = 0.401741
I1007 15:29:50.996841  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.401741 (* 1 = 0.401741 loss)
I1007 15:29:50.996852  4982 sgd_solver.cpp:105] Iteration 14500, lr = 0.1
I1007 15:29:59.333859  4982 solver.cpp:218] Iteration 14600 (11.9947 iter/s, 8.33699s/100 iters), loss = 0.243048
I1007 15:29:59.333892  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.243048 (* 1 = 0.243048 loss)
I1007 15:29:59.333901  4982 sgd_solver.cpp:105] Iteration 14600, lr = 0.1
I1007 15:30:07.660917  4982 solver.cpp:218] Iteration 14700 (12.0091 iter/s, 8.327s/100 iters), loss = 0.418829
I1007 15:30:07.660950  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.418829 (* 1 = 0.418829 loss)
I1007 15:30:07.660959  4982 sgd_solver.cpp:105] Iteration 14700, lr = 0.1
I1007 15:30:15.989251  4982 solver.cpp:218] Iteration 14800 (12.0073 iter/s, 8.32827s/100 iters), loss = 0.367301
I1007 15:30:15.989372  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.3673 (* 1 = 0.3673 loss)
I1007 15:30:15.989393  4982 sgd_solver.cpp:105] Iteration 14800, lr = 0.1
I1007 15:30:24.317385  4982 solver.cpp:218] Iteration 14900 (12.0077 iter/s, 8.32799s/100 iters), loss = 0.365891
I1007 15:30:24.317420  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.365891 (* 1 = 0.365891 loss)
I1007 15:30:24.317438  4982 sgd_solver.cpp:105] Iteration 14900, lr = 0.1
I1007 15:30:32.237787  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:30:32.571434  4982 solver.cpp:330] Iteration 15000, Testing net (#0)
I1007 15:30:34.502409  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:30:34.583307  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7984
I1007 15:30:34.583333  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.616603 (* 1 = 0.616603 loss)
I1007 15:30:34.666030  4982 solver.cpp:218] Iteration 15000 (9.66317 iter/s, 10.3486s/100 iters), loss = 0.430922
I1007 15:30:34.666062  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.430922 (* 1 = 0.430922 loss)
I1007 15:30:34.666072  4982 sgd_solver.cpp:105] Iteration 15000, lr = 0.1
I1007 15:30:42.999155  4982 solver.cpp:218] Iteration 15100 (12.0004 iter/s, 8.33306s/100 iters), loss = 0.35107
I1007 15:30:42.999189  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.35107 (* 1 = 0.35107 loss)
I1007 15:30:42.999198  4982 sgd_solver.cpp:105] Iteration 15100, lr = 0.1
I1007 15:30:51.340450  4982 solver.cpp:218] Iteration 15200 (11.9886 iter/s, 8.34123s/100 iters), loss = 0.356258
I1007 15:30:51.340569  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.356258 (* 1 = 0.356258 loss)
I1007 15:30:51.340592  4982 sgd_solver.cpp:105] Iteration 15200, lr = 0.1
I1007 15:30:59.677059  4982 solver.cpp:218] Iteration 15300 (11.9955 iter/s, 8.33647s/100 iters), loss = 0.385227
I1007 15:30:59.677093  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.385227 (* 1 = 0.385227 loss)
I1007 15:30:59.677110  4982 sgd_solver.cpp:105] Iteration 15300, lr = 0.1
I1007 15:31:08.016075  4982 solver.cpp:218] Iteration 15400 (11.9919 iter/s, 8.33896s/100 iters), loss = 0.333108
I1007 15:31:08.016108  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.333108 (* 1 = 0.333108 loss)
I1007 15:31:08.016116  4982 sgd_solver.cpp:105] Iteration 15400, lr = 0.1
I1007 15:31:15.936722  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:31:16.270660  4982 solver.cpp:330] Iteration 15500, Testing net (#0)
I1007 15:31:18.201742  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:31:18.282372  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7512
I1007 15:31:18.282399  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.764573 (* 1 = 0.764573 loss)
I1007 15:31:18.366114  4982 solver.cpp:218] Iteration 15500 (9.66186 iter/s, 10.35s/100 iters), loss = 0.335546
I1007 15:31:18.366144  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.335546 (* 1 = 0.335546 loss)
I1007 15:31:18.366154  4982 sgd_solver.cpp:105] Iteration 15500, lr = 0.1
I1007 15:31:26.700322  4982 solver.cpp:218] Iteration 15600 (11.9988 iter/s, 8.33415s/100 iters), loss = 0.284312
I1007 15:31:26.700471  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.284312 (* 1 = 0.284312 loss)
I1007 15:31:26.700511  4982 sgd_solver.cpp:105] Iteration 15600, lr = 0.1
I1007 15:31:35.025727  4982 solver.cpp:218] Iteration 15700 (12.0117 iter/s, 8.32523s/100 iters), loss = 0.33698
I1007 15:31:35.025760  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.33698 (* 1 = 0.33698 loss)
I1007 15:31:35.025779  4982 sgd_solver.cpp:105] Iteration 15700, lr = 0.1
I1007 15:31:43.361277  4982 solver.cpp:218] Iteration 15800 (11.9969 iter/s, 8.33549s/100 iters), loss = 0.465732
I1007 15:31:43.361310  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.465732 (* 1 = 0.465732 loss)
I1007 15:31:43.361320  4982 sgd_solver.cpp:105] Iteration 15800, lr = 0.1
I1007 15:31:51.693104  4982 solver.cpp:218] Iteration 15900 (12.0023 iter/s, 8.33177s/100 iters), loss = 0.407968
I1007 15:31:51.693136  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.407967 (* 1 = 0.407967 loss)
I1007 15:31:51.693145  4982 sgd_solver.cpp:105] Iteration 15900, lr = 0.1
I1007 15:31:59.615839  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:31:59.949697  4982 solver.cpp:330] Iteration 16000, Testing net (#0)
I1007 15:32:01.883769  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:32:01.964975  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7263
I1007 15:32:01.965003  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.88398 (* 1 = 0.88398 loss)
I1007 15:32:02.047991  4982 solver.cpp:218] Iteration 16000 (9.65734 iter/s, 10.3548s/100 iters), loss = 0.321035
I1007 15:32:02.048018  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.321035 (* 1 = 0.321035 loss)
I1007 15:32:02.048028  4982 sgd_solver.cpp:105] Iteration 16000, lr = 0.1
I1007 15:32:10.378342  4982 solver.cpp:218] Iteration 16100 (12.0044 iter/s, 8.33029s/100 iters), loss = 0.294076
I1007 15:32:10.378376  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.294076 (* 1 = 0.294076 loss)
I1007 15:32:10.378383  4982 sgd_solver.cpp:105] Iteration 16100, lr = 0.1
I1007 15:32:18.715091  4982 solver.cpp:218] Iteration 16200 (11.9952 iter/s, 8.33669s/100 iters), loss = 0.426299
I1007 15:32:18.715124  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.426299 (* 1 = 0.426299 loss)
I1007 15:32:18.715133  4982 sgd_solver.cpp:105] Iteration 16200, lr = 0.1
I1007 15:32:27.050478  4982 solver.cpp:218] Iteration 16300 (11.9971 iter/s, 8.33533s/100 iters), loss = 0.311811
I1007 15:32:27.050510  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.311811 (* 1 = 0.311811 loss)
I1007 15:32:27.050519  4982 sgd_solver.cpp:105] Iteration 16300, lr = 0.1
I1007 15:32:35.388799  4982 solver.cpp:218] Iteration 16400 (11.9929 iter/s, 8.33826s/100 iters), loss = 0.393466
I1007 15:32:35.388947  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.393465 (* 1 = 0.393465 loss)
I1007 15:32:35.388969  4982 sgd_solver.cpp:105] Iteration 16400, lr = 0.1
I1007 15:32:43.309618  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:32:43.641777  4982 solver.cpp:330] Iteration 16500, Testing net (#0)
I1007 15:32:45.572885  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:32:45.653317  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8057
I1007 15:32:45.653344  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.564496 (* 1 = 0.564496 loss)
I1007 15:32:45.737437  4982 solver.cpp:218] Iteration 16500 (9.66327 iter/s, 10.3485s/100 iters), loss = 0.276008
I1007 15:32:45.737467  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.276007 (* 1 = 0.276007 loss)
I1007 15:32:45.737476  4982 sgd_solver.cpp:105] Iteration 16500, lr = 0.1
I1007 15:32:54.080525  4982 solver.cpp:218] Iteration 16600 (11.9861 iter/s, 8.34303s/100 iters), loss = 0.299127
I1007 15:32:54.080559  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.299126 (* 1 = 0.299126 loss)
I1007 15:32:54.080577  4982 sgd_solver.cpp:105] Iteration 16600, lr = 0.1
I1007 15:33:02.414268  4982 solver.cpp:218] Iteration 16700 (11.9995 iter/s, 8.33368s/100 iters), loss = 0.328107
I1007 15:33:02.414300  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.328107 (* 1 = 0.328107 loss)
I1007 15:33:02.414319  4982 sgd_solver.cpp:105] Iteration 16700, lr = 0.1
I1007 15:33:10.752274  4982 solver.cpp:218] Iteration 16800 (11.9934 iter/s, 8.33795s/100 iters), loss = 0.461546
I1007 15:33:10.752411  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.461546 (* 1 = 0.461546 loss)
I1007 15:33:10.752423  4982 sgd_solver.cpp:105] Iteration 16800, lr = 0.1
I1007 15:33:19.080277  4982 solver.cpp:218] Iteration 16900 (12.0079 iter/s, 8.32784s/100 iters), loss = 0.350246
I1007 15:33:19.080312  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.350246 (* 1 = 0.350246 loss)
I1007 15:33:19.080319  4982 sgd_solver.cpp:105] Iteration 16900, lr = 0.1
I1007 15:33:27.008126  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:33:27.340490  4982 solver.cpp:330] Iteration 17000, Testing net (#0)
I1007 15:33:29.271103  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:33:29.352463  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7941
I1007 15:33:29.352493  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.606371 (* 1 = 0.606371 loss)
I1007 15:33:29.435464  4982 solver.cpp:218] Iteration 17000 (9.65706 iter/s, 10.3551s/100 iters), loss = 0.362761
I1007 15:33:29.435494  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.362761 (* 1 = 0.362761 loss)
I1007 15:33:29.435514  4982 sgd_solver.cpp:105] Iteration 17000, lr = 0.1
I1007 15:33:37.767822  4982 solver.cpp:218] Iteration 17100 (12.0015 iter/s, 8.3323s/100 iters), loss = 0.350105
I1007 15:33:37.767860  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.350104 (* 1 = 0.350104 loss)
I1007 15:33:37.767879  4982 sgd_solver.cpp:105] Iteration 17100, lr = 0.1
I1007 15:33:46.107712  4982 solver.cpp:218] Iteration 17200 (11.9907 iter/s, 8.33983s/100 iters), loss = 0.344532
I1007 15:33:46.107806  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.344532 (* 1 = 0.344532 loss)
I1007 15:33:46.107816  4982 sgd_solver.cpp:105] Iteration 17200, lr = 0.1
I1007 15:33:54.435482  4982 solver.cpp:218] Iteration 17300 (12.0082 iter/s, 8.32765s/100 iters), loss = 0.468559
I1007 15:33:54.435515  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.468559 (* 1 = 0.468559 loss)
I1007 15:33:54.435534  4982 sgd_solver.cpp:105] Iteration 17300, lr = 0.1
I1007 15:34:02.771564  4982 solver.cpp:218] Iteration 17400 (11.9961 iter/s, 8.33602s/100 iters), loss = 0.327857
I1007 15:34:02.771601  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.327856 (* 1 = 0.327856 loss)
I1007 15:34:02.771610  4982 sgd_solver.cpp:105] Iteration 17400, lr = 0.1
I1007 15:34:10.693174  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:34:11.028076  4982 solver.cpp:330] Iteration 17500, Testing net (#0)
I1007 15:34:12.960430  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:34:13.041185  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8307
I1007 15:34:13.041213  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.512149 (* 1 = 0.512149 loss)
I1007 15:34:13.124694  4982 solver.cpp:218] Iteration 17500 (9.65898 iter/s, 10.3531s/100 iters), loss = 0.286489
I1007 15:34:13.124723  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.286489 (* 1 = 0.286489 loss)
I1007 15:34:13.124732  4982 sgd_solver.cpp:105] Iteration 17500, lr = 0.1
I1007 15:34:21.462266  4982 solver.cpp:218] Iteration 17600 (11.994 iter/s, 8.33751s/100 iters), loss = 0.285502
I1007 15:34:21.462453  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.285502 (* 1 = 0.285502 loss)
I1007 15:34:21.462468  4982 sgd_solver.cpp:105] Iteration 17600, lr = 0.1
I1007 15:34:29.795542  4982 solver.cpp:218] Iteration 17700 (12.0004 iter/s, 8.33309s/100 iters), loss = 0.344228
I1007 15:34:29.795577  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.344228 (* 1 = 0.344228 loss)
I1007 15:34:29.795594  4982 sgd_solver.cpp:105] Iteration 17700, lr = 0.1
I1007 15:34:38.131350  4982 solver.cpp:218] Iteration 17800 (11.9965 iter/s, 8.33575s/100 iters), loss = 0.295389
I1007 15:34:38.131381  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.295389 (* 1 = 0.295389 loss)
I1007 15:34:38.131391  4982 sgd_solver.cpp:105] Iteration 17800, lr = 0.1
I1007 15:34:46.463156  4982 solver.cpp:218] Iteration 17900 (12.0023 iter/s, 8.33175s/100 iters), loss = 0.311977
I1007 15:34:46.463191  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.311977 (* 1 = 0.311977 loss)
I1007 15:34:46.463199  4982 sgd_solver.cpp:105] Iteration 17900, lr = 0.1
I1007 15:34:54.387239  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:34:54.721248  4982 solver.cpp:330] Iteration 18000, Testing net (#0)
I1007 15:34:56.654238  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:34:56.735527  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7787
I1007 15:34:56.735554  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.707582 (* 1 = 0.707582 loss)
I1007 15:34:56.818305  4982 solver.cpp:218] Iteration 18000 (9.65709 iter/s, 10.3551s/100 iters), loss = 0.360292
I1007 15:34:56.818333  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.360292 (* 1 = 0.360292 loss)
I1007 15:34:56.818358  4982 sgd_solver.cpp:105] Iteration 18000, lr = 0.1
I1007 15:35:05.149991  4982 solver.cpp:218] Iteration 18100 (12.0025 iter/s, 8.33163s/100 iters), loss = 0.246777
I1007 15:35:05.150023  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.246777 (* 1 = 0.246777 loss)
I1007 15:35:05.150032  4982 sgd_solver.cpp:105] Iteration 18100, lr = 0.1
I1007 15:35:13.485522  4982 solver.cpp:218] Iteration 18200 (11.9969 iter/s, 8.33547s/100 iters), loss = 0.347643
I1007 15:35:13.485553  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.347643 (* 1 = 0.347643 loss)
I1007 15:35:13.485572  4982 sgd_solver.cpp:105] Iteration 18200, lr = 0.1
I1007 15:35:21.815862  4982 solver.cpp:218] Iteration 18300 (12.0044 iter/s, 8.33028s/100 iters), loss = 0.422428
I1007 15:35:21.815894  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.422427 (* 1 = 0.422427 loss)
I1007 15:35:21.815912  4982 sgd_solver.cpp:105] Iteration 18300, lr = 0.1
I1007 15:35:30.148210  4982 solver.cpp:218] Iteration 18400 (12.0015 iter/s, 8.33229s/100 iters), loss = 0.33809
I1007 15:35:30.148356  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.33809 (* 1 = 0.33809 loss)
I1007 15:35:30.148381  4982 sgd_solver.cpp:105] Iteration 18400, lr = 0.1
I1007 15:35:38.068601  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:35:38.402135  4982 solver.cpp:330] Iteration 18500, Testing net (#0)
I1007 15:35:40.333199  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:35:40.413578  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8056
I1007 15:35:40.413606  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.581506 (* 1 = 0.581506 loss)
I1007 15:35:40.497393  4982 solver.cpp:218] Iteration 18500 (9.66276 iter/s, 10.349s/100 iters), loss = 0.374602
I1007 15:35:40.497423  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.374602 (* 1 = 0.374602 loss)
I1007 15:35:40.497434  4982 sgd_solver.cpp:105] Iteration 18500, lr = 0.1
I1007 15:35:48.834389  4982 solver.cpp:218] Iteration 18600 (11.9948 iter/s, 8.33694s/100 iters), loss = 0.277418
I1007 15:35:48.834420  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.277418 (* 1 = 0.277418 loss)
I1007 15:35:48.834439  4982 sgd_solver.cpp:105] Iteration 18600, lr = 0.1
I1007 15:35:57.166828  4982 solver.cpp:218] Iteration 18700 (12.0014 iter/s, 8.33238s/100 iters), loss = 0.288477
I1007 15:35:57.166860  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.288476 (* 1 = 0.288476 loss)
I1007 15:35:57.166879  4982 sgd_solver.cpp:105] Iteration 18700, lr = 0.1
I1007 15:36:05.505069  4982 solver.cpp:218] Iteration 18800 (11.993 iter/s, 8.33818s/100 iters), loss = 0.272364
I1007 15:36:05.505203  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.272364 (* 1 = 0.272364 loss)
I1007 15:36:05.505228  4982 sgd_solver.cpp:105] Iteration 18800, lr = 0.1
I1007 15:36:13.831534  4982 solver.cpp:218] Iteration 18900 (12.0101 iter/s, 8.32631s/100 iters), loss = 0.266186
I1007 15:36:13.831568  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.266186 (* 1 = 0.266186 loss)
I1007 15:36:13.831578  4982 sgd_solver.cpp:105] Iteration 18900, lr = 0.1
I1007 15:36:21.751780  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:36:22.085618  4982 solver.cpp:330] Iteration 19000, Testing net (#0)
I1007 15:36:24.017526  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:36:24.098461  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8186
I1007 15:36:24.098489  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.524561 (* 1 = 0.524561 loss)
I1007 15:36:24.180738  4982 solver.cpp:218] Iteration 19000 (9.66264 iter/s, 10.3491s/100 iters), loss = 0.295679
I1007 15:36:24.180768  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.295679 (* 1 = 0.295679 loss)
I1007 15:36:24.180778  4982 sgd_solver.cpp:105] Iteration 19000, lr = 0.1
I1007 15:36:32.502229  4982 solver.cpp:218] Iteration 19100 (12.0172 iter/s, 8.32143s/100 iters), loss = 0.262608
I1007 15:36:32.502267  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.262608 (* 1 = 0.262608 loss)
I1007 15:36:32.502275  4982 sgd_solver.cpp:105] Iteration 19100, lr = 0.1
I1007 15:36:40.829799  4982 solver.cpp:218] Iteration 19200 (12.0084 iter/s, 8.32751s/100 iters), loss = 0.320245
I1007 15:36:40.829946  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.320245 (* 1 = 0.320245 loss)
I1007 15:36:40.829972  4982 sgd_solver.cpp:105] Iteration 19200, lr = 0.1
I1007 15:36:49.157456  4982 solver.cpp:218] Iteration 19300 (12.0084 iter/s, 8.3275s/100 iters), loss = 0.43722
I1007 15:36:49.157488  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.43722 (* 1 = 0.43722 loss)
I1007 15:36:49.157496  4982 sgd_solver.cpp:105] Iteration 19300, lr = 0.1
I1007 15:36:57.482153  4982 solver.cpp:218] Iteration 19400 (12.0125 iter/s, 8.32464s/100 iters), loss = 0.421965
I1007 15:36:57.482187  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.421964 (* 1 = 0.421964 loss)
I1007 15:36:57.482204  4982 sgd_solver.cpp:105] Iteration 19400, lr = 0.1
I1007 15:37:05.387992  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:37:05.721735  4982 solver.cpp:330] Iteration 19500, Testing net (#0)
I1007 15:37:07.654109  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:37:07.734372  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7173
I1007 15:37:07.734400  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.855292 (* 1 = 0.855292 loss)
I1007 15:37:07.818300  4982 solver.cpp:218] Iteration 19500 (9.67485 iter/s, 10.3361s/100 iters), loss = 0.204105
I1007 15:37:07.818331  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.204105 (* 1 = 0.204105 loss)
I1007 15:37:07.818341  4982 sgd_solver.cpp:105] Iteration 19500, lr = 0.1
I1007 15:37:16.150396  4982 solver.cpp:218] Iteration 19600 (12.0019 iter/s, 8.33204s/100 iters), loss = 0.309436
I1007 15:37:16.150576  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.309436 (* 1 = 0.309436 loss)
I1007 15:37:16.150605  4982 sgd_solver.cpp:105] Iteration 19600, lr = 0.1
I1007 15:37:24.476178  4982 solver.cpp:218] Iteration 19700 (12.0112 iter/s, 8.32559s/100 iters), loss = 0.273196
I1007 15:37:24.476225  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.273196 (* 1 = 0.273196 loss)
I1007 15:37:24.476233  4982 sgd_solver.cpp:105] Iteration 19700, lr = 0.1
I1007 15:37:32.812556  4982 solver.cpp:218] Iteration 19800 (11.9957 iter/s, 8.3363s/100 iters), loss = 0.327173
I1007 15:37:32.812584  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.327173 (* 1 = 0.327173 loss)
I1007 15:37:32.812590  4982 sgd_solver.cpp:105] Iteration 19800, lr = 0.1
I1007 15:37:41.145718  4982 solver.cpp:218] Iteration 19900 (12.0003 iter/s, 8.33311s/100 iters), loss = 0.266485
I1007 15:37:41.145748  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.266485 (* 1 = 0.266485 loss)
I1007 15:37:41.145754  4982 sgd_solver.cpp:105] Iteration 19900, lr = 0.1
I1007 15:37:49.070564  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:37:49.404657  4982 solver.cpp:330] Iteration 20000, Testing net (#0)
I1007 15:37:51.337250  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:37:51.417791  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.834
I1007 15:37:51.417827  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.479931 (* 1 = 0.479931 loss)
I1007 15:37:51.500919  4982 solver.cpp:218] Iteration 20000 (9.65704 iter/s, 10.3551s/100 iters), loss = 0.244516
I1007 15:37:51.500955  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.244516 (* 1 = 0.244516 loss)
I1007 15:37:51.500962  4982 sgd_solver.cpp:105] Iteration 20000, lr = 0.1
I1007 15:37:59.831763  4982 solver.cpp:218] Iteration 20100 (12.0037 iter/s, 8.33078s/100 iters), loss = 0.328164
I1007 15:37:59.831804  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.328163 (* 1 = 0.328163 loss)
I1007 15:37:59.831809  4982 sgd_solver.cpp:105] Iteration 20100, lr = 0.1
I1007 15:38:08.170188  4982 solver.cpp:218] Iteration 20200 (11.9928 iter/s, 8.33836s/100 iters), loss = 0.351838
I1007 15:38:08.170229  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.351838 (* 1 = 0.351838 loss)
I1007 15:38:08.170234  4982 sgd_solver.cpp:105] Iteration 20200, lr = 0.1
I1007 15:38:16.500996  4982 solver.cpp:218] Iteration 20300 (12.0037 iter/s, 8.33074s/100 iters), loss = 0.32299
I1007 15:38:16.501026  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.32299 (* 1 = 0.32299 loss)
I1007 15:38:16.501032  4982 sgd_solver.cpp:105] Iteration 20300, lr = 0.1
I1007 15:38:24.835095  4982 solver.cpp:218] Iteration 20400 (11.999 iter/s, 8.33404s/100 iters), loss = 0.295995
I1007 15:38:24.835222  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.295995 (* 1 = 0.295995 loss)
I1007 15:38:24.835228  4982 sgd_solver.cpp:105] Iteration 20400, lr = 0.1
I1007 15:38:32.746546  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:38:33.080778  4982 solver.cpp:330] Iteration 20500, Testing net (#0)
I1007 15:38:35.012012  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:38:35.092703  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7654
I1007 15:38:35.092739  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.718019 (* 1 = 0.718019 loss)
I1007 15:38:35.176172  4982 solver.cpp:218] Iteration 20500 (9.67032 iter/s, 10.3409s/100 iters), loss = 0.349503
I1007 15:38:35.176199  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.349503 (* 1 = 0.349503 loss)
I1007 15:38:35.176206  4982 sgd_solver.cpp:105] Iteration 20500, lr = 0.1
I1007 15:38:43.514200  4982 solver.cpp:218] Iteration 20600 (11.9933 iter/s, 8.33797s/100 iters), loss = 0.256327
I1007 15:38:43.514230  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.256326 (* 1 = 0.256326 loss)
I1007 15:38:43.514235  4982 sgd_solver.cpp:105] Iteration 20600, lr = 0.1
I1007 15:38:51.847447  4982 solver.cpp:218] Iteration 20700 (12.0002 iter/s, 8.33319s/100 iters), loss = 0.256992
I1007 15:38:51.847477  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.256992 (* 1 = 0.256992 loss)
I1007 15:38:51.847483  4982 sgd_solver.cpp:105] Iteration 20700, lr = 0.1
I1007 15:39:00.189479  4982 solver.cpp:218] Iteration 20800 (11.9876 iter/s, 8.34197s/100 iters), loss = 0.382597
I1007 15:39:00.189656  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.382596 (* 1 = 0.382596 loss)
I1007 15:39:00.189676  4982 sgd_solver.cpp:105] Iteration 20800, lr = 0.1
I1007 15:39:08.529271  4982 solver.cpp:218] Iteration 20900 (11.991 iter/s, 8.33961s/100 iters), loss = 0.224665
I1007 15:39:08.529312  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.224664 (* 1 = 0.224664 loss)
I1007 15:39:08.529319  4982 sgd_solver.cpp:105] Iteration 20900, lr = 0.1
I1007 15:39:16.460000  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:39:16.792721  4982 solver.cpp:330] Iteration 21000, Testing net (#0)
I1007 15:39:18.724673  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:39:18.805816  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7317
I1007 15:39:18.805842  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.856501 (* 1 = 0.856501 loss)
I1007 15:39:18.888561  4982 solver.cpp:218] Iteration 21000 (9.65324 iter/s, 10.3592s/100 iters), loss = 0.222657
I1007 15:39:18.888602  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.222657 (* 1 = 0.222657 loss)
I1007 15:39:18.888608  4982 sgd_solver.cpp:105] Iteration 21000, lr = 0.1
I1007 15:39:27.214946  4982 solver.cpp:218] Iteration 21100 (12.0101 iter/s, 8.32632s/100 iters), loss = 0.299075
I1007 15:39:27.214987  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.299075 (* 1 = 0.299075 loss)
I1007 15:39:27.214993  4982 sgd_solver.cpp:105] Iteration 21100, lr = 0.1
I1007 15:39:35.549804  4982 solver.cpp:218] Iteration 21200 (11.9979 iter/s, 8.33479s/100 iters), loss = 0.333335
I1007 15:39:35.549929  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.333334 (* 1 = 0.333334 loss)
I1007 15:39:35.549947  4982 sgd_solver.cpp:105] Iteration 21200, lr = 0.1
I1007 15:39:43.881665  4982 solver.cpp:218] Iteration 21300 (12.0023 iter/s, 8.33171s/100 iters), loss = 0.376678
I1007 15:39:43.881695  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.376678 (* 1 = 0.376678 loss)
I1007 15:39:43.881701  4982 sgd_solver.cpp:105] Iteration 21300, lr = 0.1
I1007 15:39:52.215971  4982 solver.cpp:218] Iteration 21400 (11.9987 iter/s, 8.33425s/100 iters), loss = 0.288441
I1007 15:39:52.216018  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.28844 (* 1 = 0.28844 loss)
I1007 15:39:52.216025  4982 sgd_solver.cpp:105] Iteration 21400, lr = 0.1
I1007 15:40:00.137192  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:40:00.471464  4982 solver.cpp:330] Iteration 21500, Testing net (#0)
I1007 15:40:02.403491  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:40:02.483960  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8121
I1007 15:40:02.483995  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.553882 (* 1 = 0.553882 loss)
I1007 15:40:02.567538  4982 solver.cpp:218] Iteration 21500 (9.66045 iter/s, 10.3515s/100 iters), loss = 0.258062
I1007 15:40:02.567564  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.258062 (* 1 = 0.258062 loss)
I1007 15:40:02.567571  4982 sgd_solver.cpp:105] Iteration 21500, lr = 0.1
I1007 15:40:10.902122  4982 solver.cpp:218] Iteration 21600 (11.9983 iter/s, 8.33453s/100 iters), loss = 0.239912
I1007 15:40:10.902256  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.239912 (* 1 = 0.239912 loss)
I1007 15:40:10.902263  4982 sgd_solver.cpp:105] Iteration 21600, lr = 0.1
I1007 15:40:19.229037  4982 solver.cpp:218] Iteration 21700 (12.0095 iter/s, 8.32677s/100 iters), loss = 0.350333
I1007 15:40:19.229079  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.350333 (* 1 = 0.350333 loss)
I1007 15:40:19.229084  4982 sgd_solver.cpp:105] Iteration 21700, lr = 0.1
I1007 15:40:27.569212  4982 solver.cpp:218] Iteration 21800 (11.9903 iter/s, 8.34011s/100 iters), loss = 0.362566
I1007 15:40:27.569253  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.362566 (* 1 = 0.362566 loss)
I1007 15:40:27.569259  4982 sgd_solver.cpp:105] Iteration 21800, lr = 0.1
I1007 15:40:35.900962  4982 solver.cpp:218] Iteration 21900 (12.0024 iter/s, 8.33168s/100 iters), loss = 0.218107
I1007 15:40:35.901003  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.218107 (* 1 = 0.218107 loss)
I1007 15:40:35.901010  4982 sgd_solver.cpp:105] Iteration 21900, lr = 0.1
I1007 15:40:43.825022  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:40:44.158936  4982 solver.cpp:330] Iteration 22000, Testing net (#0)
I1007 15:40:46.091307  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:40:46.172093  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7707
I1007 15:40:46.172119  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.714753 (* 1 = 0.714753 loss)
I1007 15:40:46.255070  4982 solver.cpp:218] Iteration 22000 (9.65807 iter/s, 10.354s/100 iters), loss = 0.21619
I1007 15:40:46.255100  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.21619 (* 1 = 0.21619 loss)
I1007 15:40:46.255107  4982 sgd_solver.cpp:105] Iteration 22000, lr = 0.1
I1007 15:40:54.590909  4982 solver.cpp:218] Iteration 22100 (11.9965 iter/s, 8.33578s/100 iters), loss = 0.276666
I1007 15:40:54.590948  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.276666 (* 1 = 0.276666 loss)
I1007 15:40:54.590955  4982 sgd_solver.cpp:105] Iteration 22100, lr = 0.1
I1007 15:41:02.927841  4982 solver.cpp:218] Iteration 22200 (11.9949 iter/s, 8.33687s/100 iters), loss = 0.310357
I1007 15:41:02.927881  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.310357 (* 1 = 0.310357 loss)
I1007 15:41:02.927887  4982 sgd_solver.cpp:105] Iteration 22200, lr = 0.1
I1007 15:41:11.259531  4982 solver.cpp:218] Iteration 22300 (12.0025 iter/s, 8.33162s/100 iters), loss = 0.433346
I1007 15:41:11.259572  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.433346 (* 1 = 0.433346 loss)
I1007 15:41:11.259577  4982 sgd_solver.cpp:105] Iteration 22300, lr = 0.1
I1007 15:41:19.599133  4982 solver.cpp:218] Iteration 22400 (11.9911 iter/s, 8.33953s/100 iters), loss = 0.219377
I1007 15:41:19.599234  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.219377 (* 1 = 0.219377 loss)
I1007 15:41:19.599251  4982 sgd_solver.cpp:105] Iteration 22400, lr = 0.1
I1007 15:41:27.522053  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:41:27.855502  4982 solver.cpp:330] Iteration 22500, Testing net (#0)
I1007 15:41:29.786103  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:41:29.866878  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7388
I1007 15:41:29.866902  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.791124 (* 1 = 0.791124 loss)
I1007 15:41:29.950482  4982 solver.cpp:218] Iteration 22500 (9.66069 iter/s, 10.3512s/100 iters), loss = 0.235061
I1007 15:41:29.950510  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.235061 (* 1 = 0.235061 loss)
I1007 15:41:29.950515  4982 sgd_solver.cpp:105] Iteration 22500, lr = 0.1
I1007 15:41:38.283290  4982 solver.cpp:218] Iteration 22600 (12.0008 iter/s, 8.33275s/100 iters), loss = 0.224614
I1007 15:41:38.283331  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.224614 (* 1 = 0.224614 loss)
I1007 15:41:38.283337  4982 sgd_solver.cpp:105] Iteration 22600, lr = 0.1
I1007 15:41:46.613718  4982 solver.cpp:218] Iteration 22700 (12.0043 iter/s, 8.33036s/100 iters), loss = 0.345178
I1007 15:41:46.613757  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.345178 (* 1 = 0.345178 loss)
I1007 15:41:46.613764  4982 sgd_solver.cpp:105] Iteration 22700, lr = 0.1
I1007 15:41:54.946732  4982 solver.cpp:218] Iteration 22800 (12.0006 iter/s, 8.33295s/100 iters), loss = 0.248296
I1007 15:41:54.946861  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.248295 (* 1 = 0.248295 loss)
I1007 15:41:54.946878  4982 sgd_solver.cpp:105] Iteration 22800, lr = 0.1
I1007 15:42:03.278759  4982 solver.cpp:218] Iteration 22900 (12.0021 iter/s, 8.33187s/100 iters), loss = 0.277823
I1007 15:42:03.278800  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.277823 (* 1 = 0.277823 loss)
I1007 15:42:03.278807  4982 sgd_solver.cpp:105] Iteration 22900, lr = 0.1
I1007 15:42:11.199345  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:42:11.532505  4982 solver.cpp:330] Iteration 23000, Testing net (#0)
I1007 15:42:13.466471  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:42:13.547677  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7658
I1007 15:42:13.547703  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.721078 (* 1 = 0.721078 loss)
I1007 15:42:13.630447  4982 solver.cpp:218] Iteration 23000 (9.66033 iter/s, 10.3516s/100 iters), loss = 0.22595
I1007 15:42:13.630473  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.22595 (* 1 = 0.22595 loss)
I1007 15:42:13.630481  4982 sgd_solver.cpp:105] Iteration 23000, lr = 0.1
I1007 15:42:21.955456  4982 solver.cpp:218] Iteration 23100 (12.0121 iter/s, 8.32496s/100 iters), loss = 0.366384
I1007 15:42:21.955497  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.366384 (* 1 = 0.366384 loss)
I1007 15:42:21.955503  4982 sgd_solver.cpp:105] Iteration 23100, lr = 0.1
I1007 15:42:30.285387  4982 solver.cpp:218] Iteration 23200 (12.005 iter/s, 8.32986s/100 iters), loss = 0.386608
I1007 15:42:30.285501  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.386608 (* 1 = 0.386608 loss)
I1007 15:42:30.285509  4982 sgd_solver.cpp:105] Iteration 23200, lr = 0.1
I1007 15:42:38.623167  4982 solver.cpp:218] Iteration 23300 (11.9938 iter/s, 8.33765s/100 iters), loss = 0.351957
I1007 15:42:38.623208  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.351957 (* 1 = 0.351957 loss)
I1007 15:42:38.623222  4982 sgd_solver.cpp:105] Iteration 23300, lr = 0.1
I1007 15:42:46.958950  4982 solver.cpp:218] Iteration 23400 (11.9966 iter/s, 8.33572s/100 iters), loss = 0.29359
I1007 15:42:46.958992  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.293589 (* 1 = 0.293589 loss)
I1007 15:42:46.958997  4982 sgd_solver.cpp:105] Iteration 23400, lr = 0.1
I1007 15:42:54.875191  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:42:55.208041  4982 solver.cpp:330] Iteration 23500, Testing net (#0)
I1007 15:42:57.141064  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:42:57.221743  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7969
I1007 15:42:57.221779  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.63058 (* 1 = 0.63058 loss)
I1007 15:42:57.305433  4982 solver.cpp:218] Iteration 23500 (9.66519 iter/s, 10.3464s/100 iters), loss = 0.26478
I1007 15:42:57.305465  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.26478 (* 1 = 0.26478 loss)
I1007 15:42:57.305472  4982 sgd_solver.cpp:105] Iteration 23500, lr = 0.1
I1007 15:43:05.646919  4982 solver.cpp:218] Iteration 23600 (11.9884 iter/s, 8.34143s/100 iters), loss = 0.293981
I1007 15:43:05.647053  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.293981 (* 1 = 0.293981 loss)
I1007 15:43:05.647060  4982 sgd_solver.cpp:105] Iteration 23600, lr = 0.1
I1007 15:43:13.979101  4982 solver.cpp:218] Iteration 23700 (12.0019 iter/s, 8.33202s/100 iters), loss = 0.387905
I1007 15:43:13.979133  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.387904 (* 1 = 0.387904 loss)
I1007 15:43:13.979140  4982 sgd_solver.cpp:105] Iteration 23700, lr = 0.1
I1007 15:43:22.327425  4982 solver.cpp:218] Iteration 23800 (11.9785 iter/s, 8.34827s/100 iters), loss = 0.362284
I1007 15:43:22.327466  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.362283 (* 1 = 0.362283 loss)
I1007 15:43:22.327472  4982 sgd_solver.cpp:105] Iteration 23800, lr = 0.1
I1007 15:43:30.661136  4982 solver.cpp:218] Iteration 23900 (11.9996 iter/s, 8.33364s/100 iters), loss = 0.241881
I1007 15:43:30.661166  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.241881 (* 1 = 0.241881 loss)
I1007 15:43:30.661172  4982 sgd_solver.cpp:105] Iteration 23900, lr = 0.1
I1007 15:43:38.588073  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:43:38.921156  4982 solver.cpp:330] Iteration 24000, Testing net (#0)
I1007 15:43:40.853157  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:43:40.934583  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7438
I1007 15:43:40.934619  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.828789 (* 1 = 0.828789 loss)
I1007 15:43:41.017552  4982 solver.cpp:218] Iteration 24000 (9.65591 iter/s, 10.3564s/100 iters), loss = 0.254176
I1007 15:43:41.017578  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.254176 (* 1 = 0.254176 loss)
I1007 15:43:41.017585  4982 sgd_solver.cpp:105] Iteration 24000, lr = 0.1
I1007 15:43:49.350531  4982 solver.cpp:218] Iteration 24100 (12.0006 iter/s, 8.33292s/100 iters), loss = 0.22851
I1007 15:43:49.350560  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.22851 (* 1 = 0.22851 loss)
I1007 15:43:49.350566  4982 sgd_solver.cpp:105] Iteration 24100, lr = 0.1
I1007 15:43:57.687688  4982 solver.cpp:218] Iteration 24200 (11.9946 iter/s, 8.3371s/100 iters), loss = 0.3089
I1007 15:43:57.687718  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.308899 (* 1 = 0.308899 loss)
I1007 15:43:57.687723  4982 sgd_solver.cpp:105] Iteration 24200, lr = 0.1
I1007 15:44:06.017575  4982 solver.cpp:218] Iteration 24300 (12.005 iter/s, 8.32983s/100 iters), loss = 0.338743
I1007 15:44:06.017606  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.338743 (* 1 = 0.338743 loss)
I1007 15:44:06.017611  4982 sgd_solver.cpp:105] Iteration 24300, lr = 0.1
I1007 15:44:14.354321  4982 solver.cpp:218] Iteration 24400 (11.9952 iter/s, 8.33669s/100 iters), loss = 0.274549
I1007 15:44:14.354434  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.274549 (* 1 = 0.274549 loss)
I1007 15:44:14.354441  4982 sgd_solver.cpp:105] Iteration 24400, lr = 0.1
I1007 15:44:22.277503  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:44:22.611243  4982 solver.cpp:330] Iteration 24500, Testing net (#0)
I1007 15:44:24.542255  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:44:24.622489  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8099
I1007 15:44:24.622525  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.567162 (* 1 = 0.567162 loss)
I1007 15:44:24.706434  4982 solver.cpp:218] Iteration 24500 (9.66 iter/s, 10.352s/100 iters), loss = 0.239533
I1007 15:44:24.706465  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.239532 (* 1 = 0.239532 loss)
I1007 15:44:24.706473  4982 sgd_solver.cpp:105] Iteration 24500, lr = 0.1
I1007 15:44:33.041942  4982 solver.cpp:218] Iteration 24600 (11.997 iter/s, 8.33545s/100 iters), loss = 0.20584
I1007 15:44:33.041972  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.205839 (* 1 = 0.205839 loss)
I1007 15:44:33.041977  4982 sgd_solver.cpp:105] Iteration 24600, lr = 0.1
I1007 15:44:41.369882  4982 solver.cpp:218] Iteration 24700 (12.0079 iter/s, 8.32788s/100 iters), loss = 0.287884
I1007 15:44:41.369922  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.287883 (* 1 = 0.287883 loss)
I1007 15:44:41.369928  4982 sgd_solver.cpp:105] Iteration 24700, lr = 0.1
I1007 15:44:49.702211  4982 solver.cpp:218] Iteration 24800 (12.0015 iter/s, 8.33226s/100 iters), loss = 0.267724
I1007 15:44:49.702338  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.267724 (* 1 = 0.267724 loss)
I1007 15:44:49.702347  4982 sgd_solver.cpp:105] Iteration 24800, lr = 0.1
I1007 15:44:58.029767  4982 solver.cpp:218] Iteration 24900 (12.0085 iter/s, 8.3274s/100 iters), loss = 0.146657
I1007 15:44:58.029795  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.146657 (* 1 = 0.146657 loss)
I1007 15:44:58.029801  4982 sgd_solver.cpp:105] Iteration 24900, lr = 0.1
I1007 15:45:05.953181  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:45:06.286566  4982 solver.cpp:330] Iteration 25000, Testing net (#0)
I1007 15:45:08.218441  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:45:08.300027  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.797
I1007 15:45:08.300065  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.636261 (* 1 = 0.636261 loss)
I1007 15:45:08.383406  4982 solver.cpp:218] Iteration 25000 (9.65849 iter/s, 10.3536s/100 iters), loss = 0.259434
I1007 15:45:08.383430  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.259433 (* 1 = 0.259433 loss)
I1007 15:45:08.383437  4982 sgd_solver.cpp:105] Iteration 25000, lr = 0.1
I1007 15:45:16.715622  4982 solver.cpp:218] Iteration 25100 (12.0017 iter/s, 8.33216s/100 iters), loss = 0.217525
I1007 15:45:16.715663  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.217525 (* 1 = 0.217525 loss)
I1007 15:45:16.715669  4982 sgd_solver.cpp:105] Iteration 25100, lr = 0.1
I1007 15:45:25.047868  4982 solver.cpp:218] Iteration 25200 (12.0017 iter/s, 8.33218s/100 iters), loss = 0.370451
I1007 15:45:25.047947  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.370451 (* 1 = 0.370451 loss)
I1007 15:45:25.047953  4982 sgd_solver.cpp:105] Iteration 25200, lr = 0.1
I1007 15:45:33.380894  4982 solver.cpp:218] Iteration 25300 (12.0006 iter/s, 8.33292s/100 iters), loss = 0.316434
I1007 15:45:33.380921  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.316434 (* 1 = 0.316434 loss)
I1007 15:45:33.380928  4982 sgd_solver.cpp:105] Iteration 25300, lr = 0.1
I1007 15:45:41.716958  4982 solver.cpp:218] Iteration 25400 (11.9962 iter/s, 8.33601s/100 iters), loss = 0.25123
I1007 15:45:41.716989  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.25123 (* 1 = 0.25123 loss)
I1007 15:45:41.716994  4982 sgd_solver.cpp:105] Iteration 25400, lr = 0.1
I1007 15:45:49.636245  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:45:49.968840  4982 solver.cpp:330] Iteration 25500, Testing net (#0)
I1007 15:45:51.899230  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:45:51.979872  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.834
I1007 15:45:51.979908  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.487535 (* 1 = 0.487535 loss)
I1007 15:45:52.066278  4982 solver.cpp:218] Iteration 25500 (9.66253 iter/s, 10.3493s/100 iters), loss = 0.24841
I1007 15:45:52.066308  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.24841 (* 1 = 0.24841 loss)
I1007 15:45:52.066314  4982 sgd_solver.cpp:105] Iteration 25500, lr = 0.1
I1007 15:46:00.404793  4982 solver.cpp:218] Iteration 25600 (11.9926 iter/s, 8.33845s/100 iters), loss = 0.241596
I1007 15:46:00.404884  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.241596 (* 1 = 0.241596 loss)
I1007 15:46:00.404902  4982 sgd_solver.cpp:105] Iteration 25600, lr = 0.1
I1007 15:46:08.734230  4982 solver.cpp:218] Iteration 25700 (12.0058 iter/s, 8.32932s/100 iters), loss = 0.230822
I1007 15:46:08.734259  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.230822 (* 1 = 0.230822 loss)
I1007 15:46:08.734266  4982 sgd_solver.cpp:105] Iteration 25700, lr = 0.1
I1007 15:46:17.066980  4982 solver.cpp:218] Iteration 25800 (12.0009 iter/s, 8.33269s/100 iters), loss = 0.349095
I1007 15:46:17.067011  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.349095 (* 1 = 0.349095 loss)
I1007 15:46:17.067016  4982 sgd_solver.cpp:105] Iteration 25800, lr = 0.1
I1007 15:46:25.396828  4982 solver.cpp:218] Iteration 25900 (12.0051 iter/s, 8.32979s/100 iters), loss = 0.185749
I1007 15:46:25.396868  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.185749 (* 1 = 0.185749 loss)
I1007 15:46:25.396874  4982 sgd_solver.cpp:105] Iteration 25900, lr = 0.1
I1007 15:46:33.321326  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:46:33.654722  4982 solver.cpp:330] Iteration 26000, Testing net (#0)
I1007 15:46:35.585142  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:46:35.666357  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7692
I1007 15:46:35.666393  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.710533 (* 1 = 0.710533 loss)
I1007 15:46:35.748966  4982 solver.cpp:218] Iteration 26000 (9.65991 iter/s, 10.3521s/100 iters), loss = 0.249334
I1007 15:46:35.748991  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.249334 (* 1 = 0.249334 loss)
I1007 15:46:35.748997  4982 sgd_solver.cpp:105] Iteration 26000, lr = 0.1
I1007 15:46:44.077958  4982 solver.cpp:218] Iteration 26100 (12.0063 iter/s, 8.32894s/100 iters), loss = 0.252882
I1007 15:46:44.077999  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.252882 (* 1 = 0.252882 loss)
I1007 15:46:44.078004  4982 sgd_solver.cpp:105] Iteration 26100, lr = 0.1
I1007 15:46:52.419517  4982 solver.cpp:218] Iteration 26200 (11.9883 iter/s, 8.34149s/100 iters), loss = 0.323886
I1007 15:46:52.419556  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.323886 (* 1 = 0.323886 loss)
I1007 15:46:52.419562  4982 sgd_solver.cpp:105] Iteration 26200, lr = 0.1
I1007 15:47:00.751826  4982 solver.cpp:218] Iteration 26300 (12.0016 iter/s, 8.33224s/100 iters), loss = 0.374933
I1007 15:47:00.751857  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.374933 (* 1 = 0.374933 loss)
I1007 15:47:00.751862  4982 sgd_solver.cpp:105] Iteration 26300, lr = 0.1
I1007 15:47:09.086277  4982 solver.cpp:218] Iteration 26400 (11.9985 iter/s, 8.33439s/100 iters), loss = 0.241494
I1007 15:47:09.086377  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.241494 (* 1 = 0.241494 loss)
I1007 15:47:09.086395  4982 sgd_solver.cpp:105] Iteration 26400, lr = 0.1
I1007 15:47:17.005749  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:47:17.340507  4982 solver.cpp:330] Iteration 26500, Testing net (#0)
I1007 15:47:19.272279  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:47:19.352901  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8109
I1007 15:47:19.352937  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.57184 (* 1 = 0.57184 loss)
I1007 15:47:19.437098  4982 solver.cpp:218] Iteration 26500 (9.66119 iter/s, 10.3507s/100 iters), loss = 0.269599
I1007 15:47:19.437124  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.269598 (* 1 = 0.269598 loss)
I1007 15:47:19.437130  4982 sgd_solver.cpp:105] Iteration 26500, lr = 0.1
I1007 15:47:27.779572  4982 solver.cpp:218] Iteration 26600 (11.9869 iter/s, 8.34242s/100 iters), loss = 0.24571
I1007 15:47:27.779613  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.245709 (* 1 = 0.245709 loss)
I1007 15:47:27.779618  4982 sgd_solver.cpp:105] Iteration 26600, lr = 0.1
I1007 15:47:36.117501  4982 solver.cpp:218] Iteration 26700 (11.9935 iter/s, 8.33786s/100 iters), loss = 0.237363
I1007 15:47:36.117542  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.237362 (* 1 = 0.237362 loss)
I1007 15:47:36.117548  4982 sgd_solver.cpp:105] Iteration 26700, lr = 0.1
I1007 15:47:44.459961  4982 solver.cpp:218] Iteration 26800 (11.987 iter/s, 8.34239s/100 iters), loss = 0.392015
I1007 15:47:44.460036  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.392015 (* 1 = 0.392015 loss)
I1007 15:47:44.460053  4982 sgd_solver.cpp:105] Iteration 26800, lr = 0.1
I1007 15:47:52.800287  4982 solver.cpp:218] Iteration 26900 (11.9901 iter/s, 8.34023s/100 iters), loss = 0.288354
I1007 15:47:52.800326  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.288353 (* 1 = 0.288353 loss)
I1007 15:47:52.800333  4982 sgd_solver.cpp:105] Iteration 26900, lr = 0.1
I1007 15:48:00.733389  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:48:01.067519  4982 solver.cpp:330] Iteration 27000, Testing net (#0)
I1007 15:48:03.000800  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:48:03.081444  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.829
I1007 15:48:03.081480  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.495908 (* 1 = 0.495908 loss)
I1007 15:48:03.164541  4982 solver.cpp:218] Iteration 27000 (9.64861 iter/s, 10.3642s/100 iters), loss = 0.25862
I1007 15:48:03.164567  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.25862 (* 1 = 0.25862 loss)
I1007 15:48:03.164573  4982 sgd_solver.cpp:105] Iteration 27000, lr = 0.1
I1007 15:48:11.497615  4982 solver.cpp:218] Iteration 27100 (12.0004 iter/s, 8.33302s/100 iters), loss = 0.322352
I1007 15:48:11.497656  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.322352 (* 1 = 0.322352 loss)
I1007 15:48:11.497663  4982 sgd_solver.cpp:105] Iteration 27100, lr = 0.1
I1007 15:48:19.840687  4982 solver.cpp:218] Iteration 27200 (11.9861 iter/s, 8.34301s/100 iters), loss = 0.311148
I1007 15:48:19.840783  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.311148 (* 1 = 0.311148 loss)
I1007 15:48:19.840801  4982 sgd_solver.cpp:105] Iteration 27200, lr = 0.1
I1007 15:48:28.183526  4982 solver.cpp:218] Iteration 27300 (11.9865 iter/s, 8.34272s/100 iters), loss = 0.249771
I1007 15:48:28.183567  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.249771 (* 1 = 0.249771 loss)
I1007 15:48:28.183573  4982 sgd_solver.cpp:105] Iteration 27300, lr = 0.1
I1007 15:48:36.530436  4982 solver.cpp:218] Iteration 27400 (11.9806 iter/s, 8.34684s/100 iters), loss = 0.228171
I1007 15:48:36.530477  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.22817 (* 1 = 0.22817 loss)
I1007 15:48:36.530483  4982 sgd_solver.cpp:105] Iteration 27400, lr = 0.1
I1007 15:48:44.457607  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:48:44.790863  4982 solver.cpp:330] Iteration 27500, Testing net (#0)
I1007 15:48:46.721438  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:48:46.802032  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8208
I1007 15:48:46.802068  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.548461 (* 1 = 0.548461 loss)
I1007 15:48:46.886047  4982 solver.cpp:218] Iteration 27500 (9.65667 iter/s, 10.3555s/100 iters), loss = 0.149725
I1007 15:48:46.886075  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.149725 (* 1 = 0.149725 loss)
I1007 15:48:46.886082  4982 sgd_solver.cpp:105] Iteration 27500, lr = 0.1
I1007 15:48:55.223273  4982 solver.cpp:218] Iteration 27600 (11.9945 iter/s, 8.33717s/100 iters), loss = 0.273414
I1007 15:48:55.223379  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.273414 (* 1 = 0.273414 loss)
I1007 15:48:55.223387  4982 sgd_solver.cpp:105] Iteration 27600, lr = 0.1
I1007 15:49:03.550784  4982 solver.cpp:218] Iteration 27700 (12.0086 iter/s, 8.32738s/100 iters), loss = 0.261243
I1007 15:49:03.550827  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.261243 (* 1 = 0.261243 loss)
I1007 15:49:03.550832  4982 sgd_solver.cpp:105] Iteration 27700, lr = 0.1
I1007 15:49:11.884778  4982 solver.cpp:218] Iteration 27800 (11.9991 iter/s, 8.33393s/100 iters), loss = 0.399841
I1007 15:49:11.884819  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.39984 (* 1 = 0.39984 loss)
I1007 15:49:11.884824  4982 sgd_solver.cpp:105] Iteration 27800, lr = 0.1
I1007 15:49:20.219256  4982 solver.cpp:218] Iteration 27900 (11.9984 iter/s, 8.33441s/100 iters), loss = 0.234952
I1007 15:49:20.219297  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.234952 (* 1 = 0.234952 loss)
I1007 15:49:20.219305  4982 sgd_solver.cpp:105] Iteration 27900, lr = 0.1
I1007 15:49:28.143015  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:49:28.476776  4982 solver.cpp:330] Iteration 28000, Testing net (#0)
I1007 15:49:30.406649  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:49:30.487936  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8204
I1007 15:49:30.487972  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.528821 (* 1 = 0.528821 loss)
I1007 15:49:30.570750  4982 solver.cpp:218] Iteration 28000 (9.66051 iter/s, 10.3514s/100 iters), loss = 0.214378
I1007 15:49:30.570785  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.214378 (* 1 = 0.214378 loss)
I1007 15:49:30.570791  4982 sgd_solver.cpp:105] Iteration 28000, lr = 0.1
I1007 15:49:38.904950  4982 solver.cpp:218] Iteration 28100 (11.9988 iter/s, 8.33414s/100 iters), loss = 0.259216
I1007 15:49:38.904991  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.259215 (* 1 = 0.259215 loss)
I1007 15:49:38.904997  4982 sgd_solver.cpp:105] Iteration 28100, lr = 0.1
I1007 15:49:47.245182  4982 solver.cpp:218] Iteration 28200 (11.9902 iter/s, 8.34016s/100 iters), loss = 0.294604
I1007 15:49:47.245215  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.294603 (* 1 = 0.294603 loss)
I1007 15:49:47.245234  4982 sgd_solver.cpp:105] Iteration 28200, lr = 0.1
I1007 15:49:55.580248  4982 solver.cpp:218] Iteration 28300 (11.9976 iter/s, 8.33501s/100 iters), loss = 0.29598
I1007 15:49:55.580281  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.29598 (* 1 = 0.29598 loss)
I1007 15:49:55.580289  4982 sgd_solver.cpp:105] Iteration 28300, lr = 0.1
I1007 15:50:03.919208  4982 solver.cpp:218] Iteration 28400 (11.992 iter/s, 8.3389s/100 iters), loss = 0.212258
I1007 15:50:03.919312  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.212258 (* 1 = 0.212258 loss)
I1007 15:50:03.919322  4982 sgd_solver.cpp:105] Iteration 28400, lr = 0.1
I1007 15:50:11.836460  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:50:12.169425  4982 solver.cpp:330] Iteration 28500, Testing net (#0)
I1007 15:50:14.100888  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:50:14.181931  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7288
I1007 15:50:14.181959  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.906745 (* 1 = 0.906745 loss)
I1007 15:50:14.265779  4982 solver.cpp:218] Iteration 28500 (9.66516 iter/s, 10.3464s/100 iters), loss = 0.216505
I1007 15:50:14.265815  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.216505 (* 1 = 0.216505 loss)
I1007 15:50:14.265825  4982 sgd_solver.cpp:105] Iteration 28500, lr = 0.1
I1007 15:50:22.605540  4982 solver.cpp:218] Iteration 28600 (11.9908 iter/s, 8.3397s/100 iters), loss = 0.230914
I1007 15:50:22.605571  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.230914 (* 1 = 0.230914 loss)
I1007 15:50:22.605576  4982 sgd_solver.cpp:105] Iteration 28600, lr = 0.1
I1007 15:50:30.933207  4982 solver.cpp:218] Iteration 28700 (12.0082 iter/s, 8.32761s/100 iters), loss = 0.289245
I1007 15:50:30.933248  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.289245 (* 1 = 0.289245 loss)
I1007 15:50:30.933254  4982 sgd_solver.cpp:105] Iteration 28700, lr = 0.1
I1007 15:50:39.271658  4982 solver.cpp:218] Iteration 28800 (11.9927 iter/s, 8.33838s/100 iters), loss = 0.255223
I1007 15:50:39.271771  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.255222 (* 1 = 0.255222 loss)
I1007 15:50:39.271791  4982 sgd_solver.cpp:105] Iteration 28800, lr = 0.1
I1007 15:50:47.607343  4982 solver.cpp:218] Iteration 28900 (11.9968 iter/s, 8.33556s/100 iters), loss = 0.248764
I1007 15:50:47.607374  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.248763 (* 1 = 0.248763 loss)
I1007 15:50:47.607380  4982 sgd_solver.cpp:105] Iteration 28900, lr = 0.1
I1007 15:50:55.527864  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:50:55.861917  4982 solver.cpp:330] Iteration 29000, Testing net (#0)
I1007 15:50:57.794389  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:50:57.875768  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8303
I1007 15:50:57.875804  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.52778 (* 1 = 0.52778 loss)
I1007 15:50:57.958804  4982 solver.cpp:218] Iteration 29000 (9.66053 iter/s, 10.3514s/100 iters), loss = 0.181001
I1007 15:50:57.958830  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.181001 (* 1 = 0.181001 loss)
I1007 15:50:57.958837  4982 sgd_solver.cpp:105] Iteration 29000, lr = 0.1
I1007 15:51:06.287468  4982 solver.cpp:218] Iteration 29100 (12.0068 iter/s, 8.32861s/100 iters), loss = 0.24277
I1007 15:51:06.287499  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.24277 (* 1 = 0.24277 loss)
I1007 15:51:06.287505  4982 sgd_solver.cpp:105] Iteration 29100, lr = 0.1
I1007 15:51:14.626370  4982 solver.cpp:218] Iteration 29200 (11.9921 iter/s, 8.33885s/100 iters), loss = 0.229791
I1007 15:51:14.626489  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.229791 (* 1 = 0.229791 loss)
I1007 15:51:14.626497  4982 sgd_solver.cpp:105] Iteration 29200, lr = 0.1
I1007 15:51:22.956435  4982 solver.cpp:218] Iteration 29300 (12.0049 iter/s, 8.32992s/100 iters), loss = 0.343125
I1007 15:51:22.956465  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.343125 (* 1 = 0.343125 loss)
I1007 15:51:22.956481  4982 sgd_solver.cpp:105] Iteration 29300, lr = 0.1
I1007 15:51:31.292462  4982 solver.cpp:218] Iteration 29400 (11.9962 iter/s, 8.33597s/100 iters), loss = 0.282307
I1007 15:51:31.292493  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.282307 (* 1 = 0.282307 loss)
I1007 15:51:31.292510  4982 sgd_solver.cpp:105] Iteration 29400, lr = 0.1
I1007 15:51:39.213513  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:51:39.547296  4982 solver.cpp:330] Iteration 29500, Testing net (#0)
I1007 15:51:41.479229  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:51:41.560128  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8146
I1007 15:51:41.560173  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.55588 (* 1 = 0.55588 loss)
I1007 15:51:41.644017  4982 solver.cpp:218] Iteration 29500 (9.66044 iter/s, 10.3515s/100 iters), loss = 0.189249
I1007 15:51:41.644047  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.189249 (* 1 = 0.189249 loss)
I1007 15:51:41.644052  4982 sgd_solver.cpp:105] Iteration 29500, lr = 0.1
I1007 15:51:49.978122  4982 solver.cpp:218] Iteration 29600 (11.999 iter/s, 8.33405s/100 iters), loss = 0.325043
I1007 15:51:49.978237  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.325043 (* 1 = 0.325043 loss)
I1007 15:51:49.978253  4982 sgd_solver.cpp:105] Iteration 29600, lr = 0.1
I1007 15:51:58.312188  4982 solver.cpp:218] Iteration 29700 (11.9991 iter/s, 8.33393s/100 iters), loss = 0.335258
I1007 15:51:58.312229  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.335258 (* 1 = 0.335258 loss)
I1007 15:51:58.312235  4982 sgd_solver.cpp:105] Iteration 29700, lr = 0.1
I1007 15:52:06.651355  4982 solver.cpp:218] Iteration 29800 (11.9917 iter/s, 8.3391s/100 iters), loss = 0.277446
I1007 15:52:06.651396  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.277446 (* 1 = 0.277446 loss)
I1007 15:52:06.651402  4982 sgd_solver.cpp:105] Iteration 29800, lr = 0.1
I1007 15:52:14.983996  4982 solver.cpp:218] Iteration 29900 (12.0011 iter/s, 8.33257s/100 iters), loss = 0.300687
I1007 15:52:14.984036  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.300687 (* 1 = 0.300687 loss)
I1007 15:52:14.984042  4982 sgd_solver.cpp:105] Iteration 29900, lr = 0.1
I1007 15:52:22.908823  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:52:23.243368  4982 solver.cpp:330] Iteration 30000, Testing net (#0)
I1007 15:52:25.175353  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:52:25.256273  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8236
I1007 15:52:25.256297  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.528484 (* 1 = 0.528484 loss)
I1007 15:52:25.339311  4982 solver.cpp:218] Iteration 30000 (9.65694 iter/s, 10.3552s/100 iters), loss = 0.213422
I1007 15:52:25.339336  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.213422 (* 1 = 0.213422 loss)
I1007 15:52:25.339342  4982 sgd_solver.cpp:105] Iteration 30000, lr = 0.1
I1007 15:52:33.666458  4982 solver.cpp:218] Iteration 30100 (12.009 iter/s, 8.3271s/100 iters), loss = 0.292541
I1007 15:52:33.666488  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.29254 (* 1 = 0.29254 loss)
I1007 15:52:33.666494  4982 sgd_solver.cpp:105] Iteration 30100, lr = 0.1
I1007 15:52:41.999819  4982 solver.cpp:218] Iteration 30200 (12 iter/s, 8.3333s/100 iters), loss = 0.269129
I1007 15:52:41.999848  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.269129 (* 1 = 0.269129 loss)
I1007 15:52:41.999863  4982 sgd_solver.cpp:105] Iteration 30200, lr = 0.1
I1007 15:52:50.329644  4982 solver.cpp:218] Iteration 30300 (12.0051 iter/s, 8.32977s/100 iters), loss = 0.354921
I1007 15:52:50.329680  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.35492 (* 1 = 0.35492 loss)
I1007 15:52:50.329687  4982 sgd_solver.cpp:105] Iteration 30300, lr = 0.1
I1007 15:52:58.665212  4982 solver.cpp:218] Iteration 30400 (11.9969 iter/s, 8.33551s/100 iters), loss = 0.221343
I1007 15:52:58.665324  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.221343 (* 1 = 0.221343 loss)
I1007 15:52:58.665331  4982 sgd_solver.cpp:105] Iteration 30400, lr = 0.1
I1007 15:53:06.580356  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:53:06.914094  4982 solver.cpp:330] Iteration 30500, Testing net (#0)
I1007 15:53:08.847621  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:53:08.928247  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7847
I1007 15:53:08.928283  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.706909 (* 1 = 0.706909 loss)
I1007 15:53:09.011917  4982 solver.cpp:218] Iteration 30500 (9.66504 iter/s, 10.3466s/100 iters), loss = 0.26576
I1007 15:53:09.011945  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.265759 (* 1 = 0.265759 loss)
I1007 15:53:09.011951  4982 sgd_solver.cpp:105] Iteration 30500, lr = 0.1
I1007 15:53:17.351569  4982 solver.cpp:218] Iteration 30600 (11.991 iter/s, 8.33959s/100 iters), loss = 0.18113
I1007 15:53:17.351605  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.18113 (* 1 = 0.18113 loss)
I1007 15:53:17.351613  4982 sgd_solver.cpp:105] Iteration 30600, lr = 0.1
I1007 15:53:25.682479  4982 solver.cpp:218] Iteration 30700 (12.0036 iter/s, 8.33085s/100 iters), loss = 0.304034
I1007 15:53:25.682520  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.304034 (* 1 = 0.304034 loss)
I1007 15:53:25.682525  4982 sgd_solver.cpp:105] Iteration 30700, lr = 0.1
I1007 15:53:34.017961  4982 solver.cpp:218] Iteration 30800 (11.997 iter/s, 8.33542s/100 iters), loss = 0.27054
I1007 15:53:34.018061  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.27054 (* 1 = 0.27054 loss)
I1007 15:53:34.018079  4982 sgd_solver.cpp:105] Iteration 30800, lr = 0.1
I1007 15:53:42.346585  4982 solver.cpp:218] Iteration 30900 (12.007 iter/s, 8.3285s/100 iters), loss = 0.259984
I1007 15:53:42.346614  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.259983 (* 1 = 0.259983 loss)
I1007 15:53:42.346619  4982 sgd_solver.cpp:105] Iteration 30900, lr = 0.1
I1007 15:53:50.271011  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:53:50.604362  4982 solver.cpp:330] Iteration 31000, Testing net (#0)
I1007 15:53:52.536221  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:53:52.617223  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8003
I1007 15:53:52.617249  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.616945 (* 1 = 0.616945 loss)
I1007 15:53:52.699976  4982 solver.cpp:218] Iteration 31000 (9.65873 iter/s, 10.3533s/100 iters), loss = 0.254383
I1007 15:53:52.700002  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.254383 (* 1 = 0.254383 loss)
I1007 15:53:52.700008  4982 sgd_solver.cpp:105] Iteration 31000, lr = 0.1
I1007 15:54:01.039078  4982 solver.cpp:218] Iteration 31100 (11.9918 iter/s, 8.33905s/100 iters), loss = 0.231231
I1007 15:54:01.039119  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.231231 (* 1 = 0.231231 loss)
I1007 15:54:01.039124  4982 sgd_solver.cpp:105] Iteration 31100, lr = 0.1
I1007 15:54:09.386257  4982 solver.cpp:218] Iteration 31200 (11.9802 iter/s, 8.34711s/100 iters), loss = 0.320542
I1007 15:54:09.386416  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.320542 (* 1 = 0.320542 loss)
I1007 15:54:09.386425  4982 sgd_solver.cpp:105] Iteration 31200, lr = 0.1
I1007 15:54:17.726428  4982 solver.cpp:218] Iteration 31300 (11.9904 iter/s, 8.33999s/100 iters), loss = 0.227057
I1007 15:54:17.726475  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.227057 (* 1 = 0.227057 loss)
I1007 15:54:17.726481  4982 sgd_solver.cpp:105] Iteration 31300, lr = 0.1
I1007 15:54:26.071547  4982 solver.cpp:218] Iteration 31400 (11.9832 iter/s, 8.34505s/100 iters), loss = 0.192835
I1007 15:54:26.071578  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.192835 (* 1 = 0.192835 loss)
I1007 15:54:26.071583  4982 sgd_solver.cpp:105] Iteration 31400, lr = 0.1
I1007 15:54:33.995460  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:54:34.328539  4982 solver.cpp:330] Iteration 31500, Testing net (#0)
I1007 15:54:36.259822  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:54:36.340764  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.821
I1007 15:54:36.340798  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.561801 (* 1 = 0.561801 loss)
I1007 15:54:36.424700  4982 solver.cpp:218] Iteration 31500 (9.65895 iter/s, 10.3531s/100 iters), loss = 0.197323
I1007 15:54:36.424728  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.197323 (* 1 = 0.197323 loss)
I1007 15:54:36.424734  4982 sgd_solver.cpp:105] Iteration 31500, lr = 0.1
I1007 15:54:44.760426  4982 solver.cpp:218] Iteration 31600 (11.9966 iter/s, 8.33567s/100 iters), loss = 0.28442
I1007 15:54:44.760546  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.28442 (* 1 = 0.28442 loss)
I1007 15:54:44.760562  4982 sgd_solver.cpp:105] Iteration 31600, lr = 0.1
I1007 15:54:53.095748  4982 solver.cpp:218] Iteration 31700 (11.9973 iter/s, 8.33519s/100 iters), loss = 0.342885
I1007 15:54:53.095788  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.342885 (* 1 = 0.342885 loss)
I1007 15:54:53.095794  4982 sgd_solver.cpp:105] Iteration 31700, lr = 0.1
I1007 15:55:01.437126  4982 solver.cpp:218] Iteration 31800 (11.9885 iter/s, 8.34131s/100 iters), loss = 0.291364
I1007 15:55:01.437155  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.291363 (* 1 = 0.291363 loss)
I1007 15:55:01.437161  4982 sgd_solver.cpp:105] Iteration 31800, lr = 0.1
I1007 15:55:09.773350  4982 solver.cpp:218] Iteration 31900 (11.9959 iter/s, 8.33617s/100 iters), loss = 0.186439
I1007 15:55:09.773391  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.186439 (* 1 = 0.186439 loss)
I1007 15:55:09.773396  4982 sgd_solver.cpp:105] Iteration 31900, lr = 0.1
I1007 15:55:17.704627  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:55:18.040374  4982 solver.cpp:330] Iteration 32000, Testing net (#0)
I1007 15:55:19.970643  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:55:20.051645  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7616
I1007 15:55:20.051671  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.695733 (* 1 = 0.695733 loss)
I1007 15:55:20.134457  4982 solver.cpp:218] Iteration 32000 (9.65154 iter/s, 10.361s/100 iters), loss = 0.272213
I1007 15:55:20.134485  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.272212 (* 1 = 0.272212 loss)
I1007 15:55:20.134491  4982 sgd_solver.cpp:105] Iteration 32000, lr = 0.1
I1007 15:55:28.475304  4982 solver.cpp:218] Iteration 32100 (11.9893 iter/s, 8.34079s/100 iters), loss = 0.26556
I1007 15:55:28.475345  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.265559 (* 1 = 0.265559 loss)
I1007 15:55:28.475352  4982 sgd_solver.cpp:105] Iteration 32100, lr = 0.1
I1007 15:55:36.819574  4982 solver.cpp:218] Iteration 32200 (11.9844 iter/s, 8.3442s/100 iters), loss = 0.369449
I1007 15:55:36.819617  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.369449 (* 1 = 0.369449 loss)
I1007 15:55:36.819622  4982 sgd_solver.cpp:105] Iteration 32200, lr = 0.1
I1007 15:55:45.163018  4982 solver.cpp:218] Iteration 32300 (11.9856 iter/s, 8.34338s/100 iters), loss = 0.319356
I1007 15:55:45.163058  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.319356 (* 1 = 0.319356 loss)
I1007 15:55:45.163064  4982 sgd_solver.cpp:105] Iteration 32300, lr = 0.1
I1007 15:55:53.505834  4982 solver.cpp:218] Iteration 32400 (11.9865 iter/s, 8.34275s/100 iters), loss = 0.214636
I1007 15:55:53.505970  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.214635 (* 1 = 0.214635 loss)
I1007 15:55:53.505986  4982 sgd_solver.cpp:105] Iteration 32400, lr = 0.1
I1007 15:56:01.429117  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:56:01.763819  4982 solver.cpp:330] Iteration 32500, Testing net (#0)
I1007 15:56:03.698058  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:56:03.778756  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.83
I1007 15:56:03.778791  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.51457 (* 1 = 0.51457 loss)
I1007 15:56:03.861948  4982 solver.cpp:218] Iteration 32500 (9.65628 iter/s, 10.356s/100 iters), loss = 0.208042
I1007 15:56:03.861974  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.208042 (* 1 = 0.208042 loss)
I1007 15:56:03.861980  4982 sgd_solver.cpp:105] Iteration 32500, lr = 0.1
I1007 15:56:12.195770  4982 solver.cpp:218] Iteration 32600 (11.9994 iter/s, 8.33377s/100 iters), loss = 0.28752
I1007 15:56:12.195801  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.28752 (* 1 = 0.28752 loss)
I1007 15:56:12.195806  4982 sgd_solver.cpp:105] Iteration 32600, lr = 0.1
I1007 15:56:20.525465  4982 solver.cpp:218] Iteration 32700 (12.0053 iter/s, 8.32964s/100 iters), loss = 0.248225
I1007 15:56:20.525493  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.248224 (* 1 = 0.248224 loss)
I1007 15:56:20.525499  4982 sgd_solver.cpp:105] Iteration 32700, lr = 0.1
I1007 15:56:28.861549  4982 solver.cpp:218] Iteration 32800 (11.9961 iter/s, 8.33603s/100 iters), loss = 0.303741
I1007 15:56:28.861613  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.303741 (* 1 = 0.303741 loss)
I1007 15:56:28.861620  4982 sgd_solver.cpp:105] Iteration 32800, lr = 0.1
I1007 15:56:37.192816  4982 solver.cpp:218] Iteration 32900 (12.0031 iter/s, 8.33118s/100 iters), loss = 0.257349
I1007 15:56:37.192852  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.257349 (* 1 = 0.257349 loss)
I1007 15:56:37.192860  4982 sgd_solver.cpp:105] Iteration 32900, lr = 0.1
I1007 15:56:45.114910  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:56:45.447633  4982 solver.cpp:330] Iteration 33000, Testing net (#0)
I1007 15:56:47.379039  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:56:47.460324  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7779
I1007 15:56:47.460358  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.683115 (* 1 = 0.683115 loss)
I1007 15:56:47.543118  4982 solver.cpp:218] Iteration 33000 (9.66162 iter/s, 10.3502s/100 iters), loss = 0.184049
I1007 15:56:47.543143  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.184049 (* 1 = 0.184049 loss)
I1007 15:56:47.543150  4982 sgd_solver.cpp:105] Iteration 33000, lr = 0.1
I1007 15:56:55.871819  4982 solver.cpp:218] Iteration 33100 (12.0068 iter/s, 8.32865s/100 iters), loss = 0.203964
I1007 15:56:55.871850  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.203964 (* 1 = 0.203964 loss)
I1007 15:56:55.871856  4982 sgd_solver.cpp:105] Iteration 33100, lr = 0.1
I1007 15:57:04.206096  4982 solver.cpp:218] Iteration 33200 (11.9987 iter/s, 8.33422s/100 iters), loss = 0.186113
I1007 15:57:04.206269  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.186113 (* 1 = 0.186113 loss)
I1007 15:57:04.206277  4982 sgd_solver.cpp:105] Iteration 33200, lr = 0.1
I1007 15:57:12.532878  4982 solver.cpp:218] Iteration 33300 (12.0097 iter/s, 8.3266s/100 iters), loss = 0.186793
I1007 15:57:12.532920  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.186792 (* 1 = 0.186792 loss)
I1007 15:57:12.532927  4982 sgd_solver.cpp:105] Iteration 33300, lr = 0.1
I1007 15:57:20.865101  4982 solver.cpp:218] Iteration 33400 (12.0017 iter/s, 8.33216s/100 iters), loss = 0.157281
I1007 15:57:20.865142  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.15728 (* 1 = 0.15728 loss)
I1007 15:57:20.865149  4982 sgd_solver.cpp:105] Iteration 33400, lr = 0.1
I1007 15:57:28.782595  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:57:29.116457  4982 solver.cpp:330] Iteration 33500, Testing net (#0)
I1007 15:57:31.048703  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:57:31.129120  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7004
I1007 15:57:31.129154  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.00502 (* 1 = 1.00502 loss)
I1007 15:57:31.212740  4982 solver.cpp:218] Iteration 33500 (9.66411 iter/s, 10.3476s/100 iters), loss = 0.232284
I1007 15:57:31.212766  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.232284 (* 1 = 0.232284 loss)
I1007 15:57:31.212772  4982 sgd_solver.cpp:105] Iteration 33500, lr = 0.1
I1007 15:57:39.551265  4982 solver.cpp:218] Iteration 33600 (11.9926 iter/s, 8.33847s/100 iters), loss = 0.201197
I1007 15:57:39.551358  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.201197 (* 1 = 0.201197 loss)
I1007 15:57:39.551376  4982 sgd_solver.cpp:105] Iteration 33600, lr = 0.1
I1007 15:57:47.880192  4982 solver.cpp:218] Iteration 33700 (12.0065 iter/s, 8.32881s/100 iters), loss = 0.29187
I1007 15:57:47.880234  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.29187 (* 1 = 0.29187 loss)
I1007 15:57:47.880239  4982 sgd_solver.cpp:105] Iteration 33700, lr = 0.1
I1007 15:57:56.218363  4982 solver.cpp:218] Iteration 33800 (11.9931 iter/s, 8.3381s/100 iters), loss = 0.289433
I1007 15:57:56.218392  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.289432 (* 1 = 0.289432 loss)
I1007 15:57:56.218399  4982 sgd_solver.cpp:105] Iteration 33800, lr = 0.1
I1007 15:58:04.557747  4982 solver.cpp:218] Iteration 33900 (11.9914 iter/s, 8.33933s/100 iters), loss = 0.20108
I1007 15:58:04.557788  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.20108 (* 1 = 0.20108 loss)
I1007 15:58:04.557795  4982 sgd_solver.cpp:105] Iteration 33900, lr = 0.1
I1007 15:58:12.487766  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:58:12.821575  4982 solver.cpp:330] Iteration 34000, Testing net (#0)
I1007 15:58:14.755403  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:58:14.836673  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7994
I1007 15:58:14.836709  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.636709 (* 1 = 0.636709 loss)
I1007 15:58:14.920274  4982 solver.cpp:218] Iteration 34000 (9.65022 iter/s, 10.3625s/100 iters), loss = 0.239248
I1007 15:58:14.920300  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.239247 (* 1 = 0.239247 loss)
I1007 15:58:14.920306  4982 sgd_solver.cpp:105] Iteration 34000, lr = 0.1
I1007 15:58:23.246815  4982 solver.cpp:218] Iteration 34100 (12.0099 iter/s, 8.32649s/100 iters), loss = 0.222526
I1007 15:58:23.246847  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.222526 (* 1 = 0.222526 loss)
I1007 15:58:23.246855  4982 sgd_solver.cpp:105] Iteration 34100, lr = 0.1
I1007 15:58:31.581714  4982 solver.cpp:218] Iteration 34200 (11.9978 iter/s, 8.33484s/100 iters), loss = 0.305068
I1007 15:58:31.581744  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.305068 (* 1 = 0.305068 loss)
I1007 15:58:31.581750  4982 sgd_solver.cpp:105] Iteration 34200, lr = 0.1
I1007 15:58:39.911640  4982 solver.cpp:218] Iteration 34300 (12.005 iter/s, 8.32987s/100 iters), loss = 0.26972
I1007 15:58:39.911670  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.269719 (* 1 = 0.269719 loss)
I1007 15:58:39.911676  4982 sgd_solver.cpp:105] Iteration 34300, lr = 0.1
I1007 15:58:48.249240  4982 solver.cpp:218] Iteration 34400 (11.9939 iter/s, 8.33754s/100 iters), loss = 0.193032
I1007 15:58:48.249377  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.193031 (* 1 = 0.193031 loss)
I1007 15:58:48.249384  4982 sgd_solver.cpp:105] Iteration 34400, lr = 0.1
I1007 15:58:56.160326  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:58:56.493589  4982 solver.cpp:330] Iteration 34500, Testing net (#0)
I1007 15:58:58.426177  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:58:58.507131  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7328
I1007 15:58:58.507171  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.919402 (* 1 = 0.919402 loss)
I1007 15:58:58.590539  4982 solver.cpp:218] Iteration 34500 (9.67011 iter/s, 10.3411s/100 iters), loss = 0.187515
I1007 15:58:58.590567  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.187515 (* 1 = 0.187515 loss)
I1007 15:58:58.590574  4982 sgd_solver.cpp:105] Iteration 34500, lr = 0.1
I1007 15:59:06.922803  4982 solver.cpp:218] Iteration 34600 (12.0016 iter/s, 8.33221s/100 iters), loss = 0.284736
I1007 15:59:06.922844  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.284735 (* 1 = 0.284735 loss)
I1007 15:59:06.922852  4982 sgd_solver.cpp:105] Iteration 34600, lr = 0.1
I1007 15:59:15.246112  4982 solver.cpp:218] Iteration 34700 (12.0146 iter/s, 8.32324s/100 iters), loss = 0.280519
I1007 15:59:15.246145  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.280519 (* 1 = 0.280519 loss)
I1007 15:59:15.246150  4982 sgd_solver.cpp:105] Iteration 34700, lr = 0.1
I1007 15:59:23.582461  4982 solver.cpp:218] Iteration 34800 (11.9957 iter/s, 8.33629s/100 iters), loss = 0.269039
I1007 15:59:23.582574  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.269039 (* 1 = 0.269039 loss)
I1007 15:59:23.582583  4982 sgd_solver.cpp:105] Iteration 34800, lr = 0.1
I1007 15:59:31.910208  4982 solver.cpp:218] Iteration 34900 (12.0082 iter/s, 8.32761s/100 iters), loss = 0.232671
I1007 15:59:31.910250  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.232671 (* 1 = 0.232671 loss)
I1007 15:59:31.910256  4982 sgd_solver.cpp:105] Iteration 34900, lr = 0.1
I1007 15:59:39.835916  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:59:40.169318  4982 solver.cpp:330] Iteration 35000, Testing net (#0)
I1007 15:59:42.101058  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 15:59:42.182121  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.773
I1007 15:59:42.182157  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.674906 (* 1 = 0.674906 loss)
I1007 15:59:42.264739  4982 solver.cpp:218] Iteration 35000 (9.65768 iter/s, 10.3545s/100 iters), loss = 0.280636
I1007 15:59:42.264772  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.280636 (* 1 = 0.280636 loss)
I1007 15:59:42.264780  4982 sgd_solver.cpp:105] Iteration 35000, lr = 0.1
I1007 15:59:50.588397  4982 solver.cpp:218] Iteration 35100 (12.014 iter/s, 8.3236s/100 iters), loss = 0.228545
I1007 15:59:50.588444  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.228545 (* 1 = 0.228545 loss)
I1007 15:59:50.588451  4982 sgd_solver.cpp:105] Iteration 35100, lr = 0.1
I1007 15:59:58.924898  4982 solver.cpp:218] Iteration 35200 (11.9955 iter/s, 8.33643s/100 iters), loss = 0.241948
I1007 15:59:58.925031  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.241948 (* 1 = 0.241948 loss)
I1007 15:59:58.925048  4982 sgd_solver.cpp:105] Iteration 35200, lr = 0.1
I1007 16:00:07.254030  4982 solver.cpp:218] Iteration 35300 (12.0063 iter/s, 8.32898s/100 iters), loss = 0.368286
I1007 16:00:07.254061  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.368286 (* 1 = 0.368286 loss)
I1007 16:00:07.254067  4982 sgd_solver.cpp:105] Iteration 35300, lr = 0.1
I1007 16:00:15.593149  4982 solver.cpp:218] Iteration 35400 (11.9918 iter/s, 8.33906s/100 iters), loss = 0.210686
I1007 16:00:15.593189  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.210686 (* 1 = 0.210686 loss)
I1007 16:00:15.593195  4982 sgd_solver.cpp:105] Iteration 35400, lr = 0.1
I1007 16:00:23.511317  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:00:23.844254  4982 solver.cpp:330] Iteration 35500, Testing net (#0)
I1007 16:00:25.775110  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:00:25.855515  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7842
I1007 16:00:25.855551  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.620068 (* 1 = 0.620068 loss)
I1007 16:00:25.939164  4982 solver.cpp:218] Iteration 35500 (9.66563 iter/s, 10.3459s/100 iters), loss = 0.220892
I1007 16:00:25.939191  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.220891 (* 1 = 0.220891 loss)
I1007 16:00:25.939199  4982 sgd_solver.cpp:105] Iteration 35500, lr = 0.1
I1007 16:00:34.285231  4982 solver.cpp:218] Iteration 35600 (11.9818 iter/s, 8.34601s/100 iters), loss = 0.396836
I1007 16:00:34.285377  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.396835 (* 1 = 0.396835 loss)
I1007 16:00:34.285387  4982 sgd_solver.cpp:105] Iteration 35600, lr = 0.1
I1007 16:00:42.614586  4982 solver.cpp:218] Iteration 35700 (12.006 iter/s, 8.32918s/100 iters), loss = 0.370213
I1007 16:00:42.614634  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.370213 (* 1 = 0.370213 loss)
I1007 16:00:42.614641  4982 sgd_solver.cpp:105] Iteration 35700, lr = 0.1
I1007 16:00:50.951716  4982 solver.cpp:218] Iteration 35800 (11.9946 iter/s, 8.33705s/100 iters), loss = 0.286144
I1007 16:00:50.951766  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.286144 (* 1 = 0.286144 loss)
I1007 16:00:50.951773  4982 sgd_solver.cpp:105] Iteration 35800, lr = 0.1
I1007 16:00:59.284195  4982 solver.cpp:218] Iteration 35900 (12.0013 iter/s, 8.3324s/100 iters), loss = 0.258127
I1007 16:00:59.284226  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.258127 (* 1 = 0.258127 loss)
I1007 16:00:59.284232  4982 sgd_solver.cpp:105] Iteration 35900, lr = 0.1
I1007 16:01:07.218865  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:01:07.552772  4982 solver.cpp:330] Iteration 36000, Testing net (#0)
I1007 16:01:09.485478  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:01:09.566013  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7878
I1007 16:01:09.566049  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.68122 (* 1 = 0.68122 loss)
I1007 16:01:09.649308  4982 solver.cpp:218] Iteration 36000 (9.64781 iter/s, 10.365s/100 iters), loss = 0.25829
I1007 16:01:09.649334  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.25829 (* 1 = 0.25829 loss)
I1007 16:01:09.649341  4982 sgd_solver.cpp:105] Iteration 36000, lr = 0.1
I1007 16:01:17.981813  4982 solver.cpp:218] Iteration 36100 (12.0013 iter/s, 8.33245s/100 iters), loss = 0.270108
I1007 16:01:17.981859  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.270108 (* 1 = 0.270108 loss)
I1007 16:01:17.981868  4982 sgd_solver.cpp:105] Iteration 36100, lr = 0.1
I1007 16:01:26.316522  4982 solver.cpp:218] Iteration 36200 (11.9981 iter/s, 8.33464s/100 iters), loss = 0.367248
I1007 16:01:26.316551  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.367247 (* 1 = 0.367247 loss)
I1007 16:01:26.316557  4982 sgd_solver.cpp:105] Iteration 36200, lr = 0.1
I1007 16:01:34.649369  4982 solver.cpp:218] Iteration 36300 (12.0008 iter/s, 8.33279s/100 iters), loss = 0.267575
I1007 16:01:34.649410  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.267575 (* 1 = 0.267575 loss)
I1007 16:01:34.649415  4982 sgd_solver.cpp:105] Iteration 36300, lr = 0.1
I1007 16:01:42.986816  4982 solver.cpp:218] Iteration 36400 (11.9942 iter/s, 8.33738s/100 iters), loss = 0.210717
I1007 16:01:42.986945  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.210717 (* 1 = 0.210717 loss)
I1007 16:01:42.986963  4982 sgd_solver.cpp:105] Iteration 36400, lr = 0.1
I1007 16:01:50.908419  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:01:51.242501  4982 solver.cpp:330] Iteration 36500, Testing net (#0)
I1007 16:01:53.173916  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:01:53.254461  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8078
I1007 16:01:53.254496  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.581921 (* 1 = 0.581921 loss)
I1007 16:01:53.338644  4982 solver.cpp:218] Iteration 36500 (9.66028 iter/s, 10.3517s/100 iters), loss = 0.192468
I1007 16:01:53.338672  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.192467 (* 1 = 0.192467 loss)
I1007 16:01:53.338680  4982 sgd_solver.cpp:105] Iteration 36500, lr = 0.1
I1007 16:02:01.678290  4982 solver.cpp:218] Iteration 36600 (11.991 iter/s, 8.33959s/100 iters), loss = 0.174072
I1007 16:02:01.678338  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.174072 (* 1 = 0.174072 loss)
I1007 16:02:01.678345  4982 sgd_solver.cpp:105] Iteration 36600, lr = 0.1
I1007 16:02:10.001616  4982 solver.cpp:218] Iteration 36700 (12.0145 iter/s, 8.32325s/100 iters), loss = 0.26841
I1007 16:02:10.001664  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.26841 (* 1 = 0.26841 loss)
I1007 16:02:10.001672  4982 sgd_solver.cpp:105] Iteration 36700, lr = 0.1
I1007 16:02:18.339351  4982 solver.cpp:218] Iteration 36800 (11.9938 iter/s, 8.33766s/100 iters), loss = 0.187332
I1007 16:02:18.339460  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.187332 (* 1 = 0.187332 loss)
I1007 16:02:18.339468  4982 sgd_solver.cpp:105] Iteration 36800, lr = 0.1
I1007 16:02:26.671200  4982 solver.cpp:218] Iteration 36900 (12.0023 iter/s, 8.33172s/100 iters), loss = 0.260607
I1007 16:02:26.671241  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.260607 (* 1 = 0.260607 loss)
I1007 16:02:26.671247  4982 sgd_solver.cpp:105] Iteration 36900, lr = 0.1
I1007 16:02:34.600621  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:02:34.933969  4982 solver.cpp:330] Iteration 37000, Testing net (#0)
I1007 16:02:36.864698  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:02:36.946200  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7993
I1007 16:02:36.946225  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.586307 (* 1 = 0.586307 loss)
I1007 16:02:37.028810  4982 solver.cpp:218] Iteration 37000 (9.65481 iter/s, 10.3575s/100 iters), loss = 0.186777
I1007 16:02:37.028836  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.186777 (* 1 = 0.186777 loss)
I1007 16:02:37.028842  4982 sgd_solver.cpp:105] Iteration 37000, lr = 0.1
I1007 16:02:45.355902  4982 solver.cpp:218] Iteration 37100 (12.0091 iter/s, 8.32704s/100 iters), loss = 0.416118
I1007 16:02:45.355931  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.416118 (* 1 = 0.416118 loss)
I1007 16:02:45.355937  4982 sgd_solver.cpp:105] Iteration 37100, lr = 0.1
I1007 16:02:53.693429  4982 solver.cpp:218] Iteration 37200 (11.994 iter/s, 8.33747s/100 iters), loss = 0.293757
I1007 16:02:53.693555  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.293757 (* 1 = 0.293757 loss)
I1007 16:02:53.693563  4982 sgd_solver.cpp:105] Iteration 37200, lr = 0.1
I1007 16:03:02.024271  4982 solver.cpp:218] Iteration 37300 (12.0038 iter/s, 8.33069s/100 iters), loss = 0.314566
I1007 16:03:02.024300  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.314566 (* 1 = 0.314566 loss)
I1007 16:03:02.024307  4982 sgd_solver.cpp:105] Iteration 37300, lr = 0.1
I1007 16:03:10.354975  4982 solver.cpp:218] Iteration 37400 (12.0039 iter/s, 8.33065s/100 iters), loss = 0.190262
I1007 16:03:10.355005  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.190262 (* 1 = 0.190262 loss)
I1007 16:03:10.355011  4982 sgd_solver.cpp:105] Iteration 37400, lr = 0.1
I1007 16:03:18.269675  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:03:18.605938  4982 solver.cpp:330] Iteration 37500, Testing net (#0)
I1007 16:03:20.538383  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:03:20.619354  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8211
I1007 16:03:20.619390  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.516605 (* 1 = 0.516605 loss)
I1007 16:03:20.703229  4982 solver.cpp:218] Iteration 37500 (9.66353 iter/s, 10.3482s/100 iters), loss = 0.186662
I1007 16:03:20.703264  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.186662 (* 1 = 0.186662 loss)
I1007 16:03:20.703281  4982 sgd_solver.cpp:105] Iteration 37500, lr = 0.1
I1007 16:03:29.047477  4982 solver.cpp:218] Iteration 37600 (11.9844 iter/s, 8.34419s/100 iters), loss = 0.243254
I1007 16:03:29.047606  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.243254 (* 1 = 0.243254 loss)
I1007 16:03:29.047624  4982 sgd_solver.cpp:105] Iteration 37600, lr = 0.1
I1007 16:03:37.380597  4982 solver.cpp:218] Iteration 37700 (12.0005 iter/s, 8.33297s/100 iters), loss = 0.231777
I1007 16:03:37.380626  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.231777 (* 1 = 0.231777 loss)
I1007 16:03:37.380632  4982 sgd_solver.cpp:105] Iteration 37700, lr = 0.1
I1007 16:03:45.717106  4982 solver.cpp:218] Iteration 37800 (11.9955 iter/s, 8.33645s/100 iters), loss = 0.203127
I1007 16:03:45.717149  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.203127 (* 1 = 0.203127 loss)
I1007 16:03:45.717154  4982 sgd_solver.cpp:105] Iteration 37800, lr = 0.1
I1007 16:03:54.046674  4982 solver.cpp:218] Iteration 37900 (12.0055 iter/s, 8.3295s/100 iters), loss = 0.186047
I1007 16:03:54.046711  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.186047 (* 1 = 0.186047 loss)
I1007 16:03:54.046730  4982 sgd_solver.cpp:105] Iteration 37900, lr = 0.1
I1007 16:04:01.974393  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:04:02.307859  4982 solver.cpp:330] Iteration 38000, Testing net (#0)
I1007 16:04:04.240988  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:04:04.322036  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6544
I1007 16:04:04.322062  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.37519 (* 1 = 1.37519 loss)
I1007 16:04:04.404852  4982 solver.cpp:218] Iteration 38000 (9.65427 iter/s, 10.3581s/100 iters), loss = 0.236195
I1007 16:04:04.404878  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.236195 (* 1 = 0.236195 loss)
I1007 16:04:04.404886  4982 sgd_solver.cpp:105] Iteration 38000, lr = 0.1
I1007 16:04:12.744782  4982 solver.cpp:218] Iteration 38100 (11.9906 iter/s, 8.33988s/100 iters), loss = 0.184095
I1007 16:04:12.744823  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.184095 (* 1 = 0.184095 loss)
I1007 16:04:12.744829  4982 sgd_solver.cpp:105] Iteration 38100, lr = 0.1
I1007 16:04:21.088985  4982 solver.cpp:218] Iteration 38200 (11.9845 iter/s, 8.34414s/100 iters), loss = 0.24915
I1007 16:04:21.089015  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.24915 (* 1 = 0.24915 loss)
I1007 16:04:21.089020  4982 sgd_solver.cpp:105] Iteration 38200, lr = 0.1
I1007 16:04:29.423852  4982 solver.cpp:218] Iteration 38300 (11.9979 iter/s, 8.33481s/100 iters), loss = 0.32477
I1007 16:04:29.423882  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.32477 (* 1 = 0.32477 loss)
I1007 16:04:29.423888  4982 sgd_solver.cpp:105] Iteration 38300, lr = 0.1
I1007 16:04:37.763484  4982 solver.cpp:218] Iteration 38400 (11.991 iter/s, 8.33957s/100 iters), loss = 0.135364
I1007 16:04:37.763626  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.135364 (* 1 = 0.135364 loss)
I1007 16:04:37.763644  4982 sgd_solver.cpp:105] Iteration 38400, lr = 0.1
I1007 16:04:45.691207  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:04:46.024318  4982 solver.cpp:330] Iteration 38500, Testing net (#0)
I1007 16:04:47.954578  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:04:48.035378  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8176
I1007 16:04:48.035405  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.538792 (* 1 = 0.538792 loss)
I1007 16:04:48.119283  4982 solver.cpp:218] Iteration 38500 (9.65659 iter/s, 10.3556s/100 iters), loss = 0.250001
I1007 16:04:48.119309  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.250001 (* 1 = 0.250001 loss)
I1007 16:04:48.119316  4982 sgd_solver.cpp:105] Iteration 38500, lr = 0.1
I1007 16:04:56.460582  4982 solver.cpp:218] Iteration 38600 (11.9886 iter/s, 8.34125s/100 iters), loss = 0.292916
I1007 16:04:56.460623  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.292916 (* 1 = 0.292916 loss)
I1007 16:04:56.460628  4982 sgd_solver.cpp:105] Iteration 38600, lr = 0.1
I1007 16:05:04.796658  4982 solver.cpp:218] Iteration 38700 (11.9961 iter/s, 8.33601s/100 iters), loss = 0.251016
I1007 16:05:04.796700  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.251016 (* 1 = 0.251016 loss)
I1007 16:05:04.796705  4982 sgd_solver.cpp:105] Iteration 38700, lr = 0.1
I1007 16:05:13.134124  4982 solver.cpp:218] Iteration 38800 (11.9942 iter/s, 8.3374s/100 iters), loss = 0.263228
I1007 16:05:13.134208  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.263228 (* 1 = 0.263228 loss)
I1007 16:05:13.134223  4982 sgd_solver.cpp:105] Iteration 38800, lr = 0.1
I1007 16:05:21.471446  4982 solver.cpp:218] Iteration 38900 (11.9944 iter/s, 8.33721s/100 iters), loss = 0.282384
I1007 16:05:21.471487  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.282384 (* 1 = 0.282384 loss)
I1007 16:05:21.471491  4982 sgd_solver.cpp:105] Iteration 38900, lr = 0.1
I1007 16:05:29.402638  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:05:29.736286  4982 solver.cpp:330] Iteration 39000, Testing net (#0)
I1007 16:05:31.666473  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:05:31.747854  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8304
I1007 16:05:31.747879  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.513064 (* 1 = 0.513064 loss)
I1007 16:05:31.830303  4982 solver.cpp:218] Iteration 39000 (9.65364 iter/s, 10.3588s/100 iters), loss = 0.221191
I1007 16:05:31.830334  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.221191 (* 1 = 0.221191 loss)
I1007 16:05:31.830341  4982 sgd_solver.cpp:105] Iteration 39000, lr = 0.1
I1007 16:05:40.162948  4982 solver.cpp:218] Iteration 39100 (12.0011 iter/s, 8.33259s/100 iters), loss = 0.193412
I1007 16:05:40.162989  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.193412 (* 1 = 0.193412 loss)
I1007 16:05:40.162994  4982 sgd_solver.cpp:105] Iteration 39100, lr = 0.1
I1007 16:05:48.497155  4982 solver.cpp:218] Iteration 39200 (11.9988 iter/s, 8.33414s/100 iters), loss = 0.324277
I1007 16:05:48.497288  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.324277 (* 1 = 0.324277 loss)
I1007 16:05:48.497295  4982 sgd_solver.cpp:105] Iteration 39200, lr = 0.1
I1007 16:05:56.829910  4982 solver.cpp:218] Iteration 39300 (12.001 iter/s, 8.3326s/100 iters), loss = 0.266093
I1007 16:05:56.829952  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.266093 (* 1 = 0.266093 loss)
I1007 16:05:56.829957  4982 sgd_solver.cpp:105] Iteration 39300, lr = 0.1
I1007 16:06:05.167130  4982 solver.cpp:218] Iteration 39400 (11.9945 iter/s, 8.33715s/100 iters), loss = 0.190265
I1007 16:06:05.167173  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.190265 (* 1 = 0.190265 loss)
I1007 16:06:05.167179  4982 sgd_solver.cpp:105] Iteration 39400, lr = 0.1
I1007 16:06:13.088773  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:06:13.422184  4982 solver.cpp:330] Iteration 39500, Testing net (#0)
I1007 16:06:15.353947  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:06:15.434660  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7565
I1007 16:06:15.434686  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.725945 (* 1 = 0.725945 loss)
I1007 16:06:15.518095  4982 solver.cpp:218] Iteration 39500 (9.66101 iter/s, 10.3509s/100 iters), loss = 0.170669
I1007 16:06:15.518121  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.170668 (* 1 = 0.170668 loss)
I1007 16:06:15.518128  4982 sgd_solver.cpp:105] Iteration 39500, lr = 0.1
I1007 16:06:23.860409  4982 solver.cpp:218] Iteration 39600 (11.9872 iter/s, 8.34226s/100 iters), loss = 0.233528
I1007 16:06:23.860548  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.233527 (* 1 = 0.233527 loss)
I1007 16:06:23.860554  4982 sgd_solver.cpp:105] Iteration 39600, lr = 0.1
I1007 16:06:32.184828  4982 solver.cpp:218] Iteration 39700 (12.0131 iter/s, 8.32425s/100 iters), loss = 0.277544
I1007 16:06:32.184859  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.277544 (* 1 = 0.277544 loss)
I1007 16:06:32.184864  4982 sgd_solver.cpp:105] Iteration 39700, lr = 0.1
I1007 16:06:40.522202  4982 solver.cpp:218] Iteration 39800 (11.9943 iter/s, 8.33732s/100 iters), loss = 0.265511
I1007 16:06:40.522243  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.265511 (* 1 = 0.265511 loss)
I1007 16:06:40.522248  4982 sgd_solver.cpp:105] Iteration 39800, lr = 0.1
I1007 16:06:48.855520  4982 solver.cpp:218] Iteration 39900 (12.0001 iter/s, 8.33325s/100 iters), loss = 0.180294
I1007 16:06:48.855561  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.180293 (* 1 = 0.180293 loss)
I1007 16:06:48.855566  4982 sgd_solver.cpp:105] Iteration 39900, lr = 0.1
I1007 16:06:56.781568  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:06:57.115197  4982 solver.cpp:330] Iteration 40000, Testing net (#0)
I1007 16:06:59.047446  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:06:59.128312  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7611
I1007 16:06:59.128337  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.826642 (* 1 = 0.826642 loss)
I1007 16:06:59.211086  4982 solver.cpp:218] Iteration 40000 (9.65671 iter/s, 10.3555s/100 iters), loss = 0.204241
I1007 16:06:59.211112  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.204241 (* 1 = 0.204241 loss)
I1007 16:06:59.211118  4982 sgd_solver.cpp:46] MultiStep Status: Iteration 40000, step = 1
I1007 16:06:59.211122  4982 sgd_solver.cpp:105] Iteration 40000, lr = 0.01
I1007 16:07:07.553773  4982 solver.cpp:218] Iteration 40100 (11.9866 iter/s, 8.34263s/100 iters), loss = 0.239765
I1007 16:07:07.553814  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.239765 (* 1 = 0.239765 loss)
I1007 16:07:07.553820  4982 sgd_solver.cpp:105] Iteration 40100, lr = 0.01
I1007 16:07:15.900283  4982 solver.cpp:218] Iteration 40200 (11.9812 iter/s, 8.34644s/100 iters), loss = 0.211306
I1007 16:07:15.900323  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.211306 (* 1 = 0.211306 loss)
I1007 16:07:15.900329  4982 sgd_solver.cpp:105] Iteration 40200, lr = 0.01
I1007 16:07:24.240311  4982 solver.cpp:218] Iteration 40300 (11.9905 iter/s, 8.33996s/100 iters), loss = 0.192699
I1007 16:07:24.240342  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.192699 (* 1 = 0.192699 loss)
I1007 16:07:24.240348  4982 sgd_solver.cpp:105] Iteration 40300, lr = 0.01
I1007 16:07:32.582101  4982 solver.cpp:218] Iteration 40400 (11.9879 iter/s, 8.34173s/100 iters), loss = 0.111843
I1007 16:07:32.582221  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.111843 (* 1 = 0.111843 loss)
I1007 16:07:32.582227  4982 sgd_solver.cpp:105] Iteration 40400, lr = 0.01
I1007 16:07:40.508062  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:07:40.841660  4982 solver.cpp:330] Iteration 40500, Testing net (#0)
I1007 16:07:42.774336  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:07:42.855109  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8877
I1007 16:07:42.855135  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.340101 (* 1 = 0.340101 loss)
I1007 16:07:42.938791  4982 solver.cpp:218] Iteration 40500 (9.65574 iter/s, 10.3565s/100 iters), loss = 0.0965988
I1007 16:07:42.938818  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0965987 (* 1 = 0.0965987 loss)
I1007 16:07:42.938824  4982 sgd_solver.cpp:105] Iteration 40500, lr = 0.01
I1007 16:07:51.278409  4982 solver.cpp:218] Iteration 40600 (11.991 iter/s, 8.33956s/100 iters), loss = 0.198704
I1007 16:07:51.278439  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.198704 (* 1 = 0.198704 loss)
I1007 16:07:51.278445  4982 sgd_solver.cpp:105] Iteration 40600, lr = 0.01
I1007 16:07:59.610468  4982 solver.cpp:218] Iteration 40700 (12.0019 iter/s, 8.332s/100 iters), loss = 0.174644
I1007 16:07:59.610508  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.174644 (* 1 = 0.174644 loss)
I1007 16:07:59.610514  4982 sgd_solver.cpp:105] Iteration 40700, lr = 0.01
I1007 16:08:07.947082  4982 solver.cpp:218] Iteration 40800 (11.9954 iter/s, 8.33655s/100 iters), loss = 0.164619
I1007 16:08:07.947216  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.164619 (* 1 = 0.164619 loss)
I1007 16:08:07.947221  4982 sgd_solver.cpp:105] Iteration 40800, lr = 0.01
I1007 16:08:16.282121  4982 solver.cpp:218] Iteration 40900 (11.9978 iter/s, 8.33488s/100 iters), loss = 0.082296
I1007 16:08:16.282162  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0822959 (* 1 = 0.0822959 loss)
I1007 16:08:16.282169  4982 sgd_solver.cpp:105] Iteration 40900, lr = 0.01
I1007 16:08:24.206666  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:08:24.539438  4982 solver.cpp:330] Iteration 41000, Testing net (#0)
I1007 16:08:26.470700  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:08:26.552177  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8946
I1007 16:08:26.552202  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.311659 (* 1 = 0.311659 loss)
I1007 16:08:26.634827  4982 solver.cpp:218] Iteration 41000 (9.65938 iter/s, 10.3526s/100 iters), loss = 0.144129
I1007 16:08:26.634853  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.144129 (* 1 = 0.144129 loss)
I1007 16:08:26.634860  4982 sgd_solver.cpp:105] Iteration 41000, lr = 0.01
I1007 16:08:34.963935  4982 solver.cpp:218] Iteration 41100 (12.0062 iter/s, 8.32906s/100 iters), loss = 0.113976
I1007 16:08:34.963965  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.113976 (* 1 = 0.113976 loss)
I1007 16:08:34.963970  4982 sgd_solver.cpp:105] Iteration 41100, lr = 0.01
I1007 16:08:43.303175  4982 solver.cpp:218] Iteration 41200 (11.9916 iter/s, 8.33918s/100 iters), loss = 0.141964
I1007 16:08:43.303287  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.141964 (* 1 = 0.141964 loss)
I1007 16:08:43.303294  4982 sgd_solver.cpp:105] Iteration 41200, lr = 0.01
I1007 16:08:51.636212  4982 solver.cpp:218] Iteration 41300 (12.0006 iter/s, 8.33291s/100 iters), loss = 0.141586
I1007 16:08:51.636253  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.141586 (* 1 = 0.141586 loss)
I1007 16:08:51.636260  4982 sgd_solver.cpp:105] Iteration 41300, lr = 0.01
I1007 16:08:59.974056  4982 solver.cpp:218] Iteration 41400 (11.9936 iter/s, 8.33778s/100 iters), loss = 0.0628652
I1007 16:08:59.974095  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0628651 (* 1 = 0.0628651 loss)
I1007 16:08:59.974102  4982 sgd_solver.cpp:105] Iteration 41400, lr = 0.01
I1007 16:09:07.898913  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:09:08.232164  4982 solver.cpp:330] Iteration 41500, Testing net (#0)
I1007 16:09:10.163985  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:09:10.244889  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8956
I1007 16:09:10.244915  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.311903 (* 1 = 0.311903 loss)
I1007 16:09:10.328635  4982 solver.cpp:218] Iteration 41500 (9.65763 iter/s, 10.3545s/100 iters), loss = 0.123741
I1007 16:09:10.328661  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.123741 (* 1 = 0.123741 loss)
I1007 16:09:10.328668  4982 sgd_solver.cpp:105] Iteration 41500, lr = 0.01
I1007 16:09:18.664132  4982 solver.cpp:218] Iteration 41600 (11.997 iter/s, 8.33544s/100 iters), loss = 0.128385
I1007 16:09:18.664255  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.128385 (* 1 = 0.128385 loss)
I1007 16:09:18.664273  4982 sgd_solver.cpp:105] Iteration 41600, lr = 0.01
I1007 16:09:26.994572  4982 solver.cpp:218] Iteration 41700 (12.0044 iter/s, 8.33029s/100 iters), loss = 0.144251
I1007 16:09:26.994613  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.14425 (* 1 = 0.14425 loss)
I1007 16:09:26.994618  4982 sgd_solver.cpp:105] Iteration 41700, lr = 0.01
I1007 16:09:35.332614  4982 solver.cpp:218] Iteration 41800 (11.9933 iter/s, 8.33797s/100 iters), loss = 0.133075
I1007 16:09:35.332650  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.133075 (* 1 = 0.133075 loss)
I1007 16:09:35.332657  4982 sgd_solver.cpp:105] Iteration 41800, lr = 0.01
I1007 16:09:43.659988  4982 solver.cpp:218] Iteration 41900 (12.0087 iter/s, 8.32731s/100 iters), loss = 0.0995694
I1007 16:09:43.660028  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0995693 (* 1 = 0.0995693 loss)
I1007 16:09:43.660034  4982 sgd_solver.cpp:105] Iteration 41900, lr = 0.01
I1007 16:09:51.583894  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:09:51.917440  4982 solver.cpp:330] Iteration 42000, Testing net (#0)
I1007 16:09:53.847703  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:09:53.929054  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8933
I1007 16:09:53.929080  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.314618 (* 1 = 0.314618 loss)
I1007 16:09:54.012924  4982 solver.cpp:218] Iteration 42000 (9.65916 iter/s, 10.3529s/100 iters), loss = 0.0704713
I1007 16:09:54.012953  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0704712 (* 1 = 0.0704712 loss)
I1007 16:09:54.012960  4982 sgd_solver.cpp:105] Iteration 42000, lr = 0.01
I1007 16:10:02.353353  4982 solver.cpp:218] Iteration 42100 (11.9899 iter/s, 8.34037s/100 iters), loss = 0.0935287
I1007 16:10:02.353384  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0935286 (* 1 = 0.0935286 loss)
I1007 16:10:02.353389  4982 sgd_solver.cpp:105] Iteration 42100, lr = 0.01
I1007 16:10:10.698771  4982 solver.cpp:218] Iteration 42200 (11.9827 iter/s, 8.34536s/100 iters), loss = 0.151042
I1007 16:10:10.698801  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.151041 (* 1 = 0.151041 loss)
I1007 16:10:10.698807  4982 sgd_solver.cpp:105] Iteration 42200, lr = 0.01
I1007 16:10:19.036769  4982 solver.cpp:218] Iteration 42300 (11.9934 iter/s, 8.33794s/100 iters), loss = 0.0987044
I1007 16:10:19.036799  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0987044 (* 1 = 0.0987044 loss)
I1007 16:10:19.036805  4982 sgd_solver.cpp:105] Iteration 42300, lr = 0.01
I1007 16:10:27.381474  4982 solver.cpp:218] Iteration 42400 (11.9837 iter/s, 8.34465s/100 iters), loss = 0.0914299
I1007 16:10:27.381592  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0914298 (* 1 = 0.0914298 loss)
I1007 16:10:27.381598  4982 sgd_solver.cpp:105] Iteration 42400, lr = 0.01
I1007 16:10:35.302978  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:10:35.635828  4982 solver.cpp:330] Iteration 42500, Testing net (#0)
I1007 16:10:37.568979  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:10:37.649428  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8961
I1007 16:10:37.649454  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.31333 (* 1 = 0.31333 loss)
I1007 16:10:37.733567  4982 solver.cpp:218] Iteration 42500 (9.66002 iter/s, 10.3519s/100 iters), loss = 0.0983253
I1007 16:10:37.733597  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0983253 (* 1 = 0.0983253 loss)
I1007 16:10:37.733603  4982 sgd_solver.cpp:105] Iteration 42500, lr = 0.01
I1007 16:10:46.071710  4982 solver.cpp:218] Iteration 42600 (11.9932 iter/s, 8.33809s/100 iters), loss = 0.12537
I1007 16:10:46.071751  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.12537 (* 1 = 0.12537 loss)
I1007 16:10:46.071756  4982 sgd_solver.cpp:105] Iteration 42600, lr = 0.01
I1007 16:10:54.403867  4982 solver.cpp:218] Iteration 42700 (12.0018 iter/s, 8.33209s/100 iters), loss = 0.127077
I1007 16:10:54.403897  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.127077 (* 1 = 0.127077 loss)
I1007 16:10:54.403903  4982 sgd_solver.cpp:105] Iteration 42700, lr = 0.01
I1007 16:11:02.739888  4982 solver.cpp:218] Iteration 42800 (11.9962 iter/s, 8.33597s/100 iters), loss = 0.0941327
I1007 16:11:02.740030  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0941326 (* 1 = 0.0941326 loss)
I1007 16:11:02.740036  4982 sgd_solver.cpp:105] Iteration 42800, lr = 0.01
I1007 16:11:11.071125  4982 solver.cpp:218] Iteration 42900 (12.0033 iter/s, 8.33107s/100 iters), loss = 0.0443211
I1007 16:11:11.071154  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0443212 (* 1 = 0.0443212 loss)
I1007 16:11:11.071172  4982 sgd_solver.cpp:105] Iteration 42900, lr = 0.01
I1007 16:11:18.990602  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:11:19.326872  4982 solver.cpp:330] Iteration 43000, Testing net (#0)
I1007 16:11:21.258761  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:11:21.339846  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9009
I1007 16:11:21.339874  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.303955 (* 1 = 0.303955 loss)
I1007 16:11:21.422868  4982 solver.cpp:218] Iteration 43000 (9.66027 iter/s, 10.3517s/100 iters), loss = 0.0517085
I1007 16:11:21.422894  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0517086 (* 1 = 0.0517086 loss)
I1007 16:11:21.422899  4982 sgd_solver.cpp:105] Iteration 43000, lr = 0.01
I1007 16:11:29.754169  4982 solver.cpp:218] Iteration 43100 (12.003 iter/s, 8.33125s/100 iters), loss = 0.127332
I1007 16:11:29.754209  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.127332 (* 1 = 0.127332 loss)
I1007 16:11:29.754215  4982 sgd_solver.cpp:105] Iteration 43100, lr = 0.01
I1007 16:11:38.093298  4982 solver.cpp:218] Iteration 43200 (11.9918 iter/s, 8.33906s/100 iters), loss = 0.118488
I1007 16:11:38.093411  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.118488 (* 1 = 0.118488 loss)
I1007 16:11:38.093418  4982 sgd_solver.cpp:105] Iteration 43200, lr = 0.01
I1007 16:11:46.430291  4982 solver.cpp:218] Iteration 43300 (11.9949 iter/s, 8.33686s/100 iters), loss = 0.079951
I1007 16:11:46.430332  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.079951 (* 1 = 0.079951 loss)
I1007 16:11:46.430338  4982 sgd_solver.cpp:105] Iteration 43300, lr = 0.01
I1007 16:11:54.769363  4982 solver.cpp:218] Iteration 43400 (11.9918 iter/s, 8.339s/100 iters), loss = 0.0914904
I1007 16:11:54.769394  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0914904 (* 1 = 0.0914904 loss)
I1007 16:11:54.769399  4982 sgd_solver.cpp:105] Iteration 43400, lr = 0.01
I1007 16:12:02.688860  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:12:03.022650  4982 solver.cpp:330] Iteration 43500, Testing net (#0)
I1007 16:12:04.956596  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:12:05.037230  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8977
I1007 16:12:05.037266  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.316645 (* 1 = 0.316645 loss)
I1007 16:12:05.120877  4982 solver.cpp:218] Iteration 43500 (9.66048 iter/s, 10.3515s/100 iters), loss = 0.0322217
I1007 16:12:05.120903  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0322217 (* 1 = 0.0322217 loss)
I1007 16:12:05.120909  4982 sgd_solver.cpp:105] Iteration 43500, lr = 0.01
I1007 16:12:13.455498  4982 solver.cpp:218] Iteration 43600 (11.9982 iter/s, 8.33457s/100 iters), loss = 0.114771
I1007 16:12:13.455631  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.114771 (* 1 = 0.114771 loss)
I1007 16:12:13.455637  4982 sgd_solver.cpp:105] Iteration 43600, lr = 0.01
I1007 16:12:21.783202  4982 solver.cpp:218] Iteration 43700 (12.0083 iter/s, 8.32756s/100 iters), loss = 0.0958035
I1007 16:12:21.783232  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0958035 (* 1 = 0.0958035 loss)
I1007 16:12:21.783237  4982 sgd_solver.cpp:105] Iteration 43700, lr = 0.01
I1007 16:12:30.118990  4982 solver.cpp:218] Iteration 43800 (11.9965 iter/s, 8.33573s/100 iters), loss = 0.0872214
I1007 16:12:30.119021  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0872213 (* 1 = 0.0872213 loss)
I1007 16:12:30.119026  4982 sgd_solver.cpp:105] Iteration 43800, lr = 0.01
I1007 16:12:38.450476  4982 solver.cpp:218] Iteration 43900 (12.0027 iter/s, 8.33143s/100 iters), loss = 0.050391
I1007 16:12:38.450516  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0503909 (* 1 = 0.0503909 loss)
I1007 16:12:38.450522  4982 sgd_solver.cpp:105] Iteration 43900, lr = 0.01
I1007 16:12:46.374938  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:12:46.709684  4982 solver.cpp:330] Iteration 44000, Testing net (#0)
I1007 16:12:48.641114  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:12:48.722265  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.899
I1007 16:12:48.722299  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.312319 (* 1 = 0.312319 loss)
I1007 16:12:48.805310  4982 solver.cpp:218] Iteration 44000 (9.65739 iter/s, 10.3548s/100 iters), loss = 0.0569103
I1007 16:12:48.805335  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0569103 (* 1 = 0.0569103 loss)
I1007 16:12:48.805341  4982 sgd_solver.cpp:105] Iteration 44000, lr = 0.01
I1007 16:12:57.145100  4982 solver.cpp:218] Iteration 44100 (11.9908 iter/s, 8.33974s/100 iters), loss = 0.0744018
I1007 16:12:57.145140  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0744017 (* 1 = 0.0744017 loss)
I1007 16:12:57.145146  4982 sgd_solver.cpp:105] Iteration 44100, lr = 0.01
I1007 16:13:05.489845  4982 solver.cpp:218] Iteration 44200 (11.9837 iter/s, 8.34468s/100 iters), loss = 0.157831
I1007 16:13:05.489876  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.157831 (* 1 = 0.157831 loss)
I1007 16:13:05.489881  4982 sgd_solver.cpp:105] Iteration 44200, lr = 0.01
I1007 16:13:13.822625  4982 solver.cpp:218] Iteration 44300 (12.0009 iter/s, 8.33272s/100 iters), loss = 0.0804761
I1007 16:13:13.822666  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.080476 (* 1 = 0.080476 loss)
I1007 16:13:13.822672  4982 sgd_solver.cpp:105] Iteration 44300, lr = 0.01
I1007 16:13:22.161092  4982 solver.cpp:218] Iteration 44400 (11.9927 iter/s, 8.3384s/100 iters), loss = 0.0934805
I1007 16:13:22.161254  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0934804 (* 1 = 0.0934804 loss)
I1007 16:13:22.161273  4982 sgd_solver.cpp:105] Iteration 44400, lr = 0.01
I1007 16:13:30.083988  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:13:30.417084  4982 solver.cpp:330] Iteration 44500, Testing net (#0)
I1007 16:13:32.349814  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:13:32.430452  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8996
I1007 16:13:32.430479  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.311847 (* 1 = 0.311847 loss)
I1007 16:13:32.514200  4982 solver.cpp:218] Iteration 44500 (9.65911 iter/s, 10.3529s/100 iters), loss = 0.0930048
I1007 16:13:32.514227  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0930048 (* 1 = 0.0930048 loss)
I1007 16:13:32.514233  4982 sgd_solver.cpp:105] Iteration 44500, lr = 0.01
I1007 16:13:40.853292  4982 solver.cpp:218] Iteration 44600 (11.9918 iter/s, 8.33904s/100 iters), loss = 0.0657568
I1007 16:13:40.853323  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0657568 (* 1 = 0.0657568 loss)
I1007 16:13:40.853339  4982 sgd_solver.cpp:105] Iteration 44600, lr = 0.01
I1007 16:13:49.182960  4982 solver.cpp:218] Iteration 44700 (12.0054 iter/s, 8.32961s/100 iters), loss = 0.0785882
I1007 16:13:49.182989  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0785882 (* 1 = 0.0785882 loss)
I1007 16:13:49.182996  4982 sgd_solver.cpp:105] Iteration 44700, lr = 0.01
I1007 16:13:57.519527  4982 solver.cpp:218] Iteration 44800 (11.9954 iter/s, 8.33651s/100 iters), loss = 0.135673
I1007 16:13:57.519656  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.135673 (* 1 = 0.135673 loss)
I1007 16:13:57.519665  4982 sgd_solver.cpp:105] Iteration 44800, lr = 0.01
I1007 16:14:05.854125  4982 solver.cpp:218] Iteration 44900 (11.9984 iter/s, 8.33444s/100 iters), loss = 0.0696947
I1007 16:14:05.854156  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0696947 (* 1 = 0.0696947 loss)
I1007 16:14:05.854161  4982 sgd_solver.cpp:105] Iteration 44900, lr = 0.01
I1007 16:14:13.772563  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:14:14.106578  4982 solver.cpp:330] Iteration 45000, Testing net (#0)
I1007 16:14:16.041220  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:14:16.122309  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8975
I1007 16:14:16.122345  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.322089 (* 1 = 0.322089 loss)
I1007 16:14:16.205158  4982 solver.cpp:218] Iteration 45000 (9.66093 iter/s, 10.351s/100 iters), loss = 0.0610305
I1007 16:14:16.205183  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0610305 (* 1 = 0.0610305 loss)
I1007 16:14:16.205188  4982 sgd_solver.cpp:105] Iteration 45000, lr = 0.01
I1007 16:14:24.540622  4982 solver.cpp:218] Iteration 45100 (11.997 iter/s, 8.33541s/100 iters), loss = 0.065567
I1007 16:14:24.540652  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0655671 (* 1 = 0.0655671 loss)
I1007 16:14:24.540658  4982 sgd_solver.cpp:105] Iteration 45100, lr = 0.01
I1007 16:14:32.875383  4982 solver.cpp:218] Iteration 45200 (11.998 iter/s, 8.3347s/100 iters), loss = 0.0816317
I1007 16:14:32.875483  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0816317 (* 1 = 0.0816317 loss)
I1007 16:14:32.875489  4982 sgd_solver.cpp:105] Iteration 45200, lr = 0.01
I1007 16:14:41.209121  4982 solver.cpp:218] Iteration 45300 (11.9996 iter/s, 8.33361s/100 iters), loss = 0.128926
I1007 16:14:41.209151  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.128926 (* 1 = 0.128926 loss)
I1007 16:14:41.209159  4982 sgd_solver.cpp:105] Iteration 45300, lr = 0.01
I1007 16:14:49.550292  4982 solver.cpp:218] Iteration 45400 (11.9888 iter/s, 8.34111s/100 iters), loss = 0.0558991
I1007 16:14:49.550323  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0558991 (* 1 = 0.0558991 loss)
I1007 16:14:49.550338  4982 sgd_solver.cpp:105] Iteration 45400, lr = 0.01
I1007 16:14:57.472002  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:14:57.805557  4982 solver.cpp:330] Iteration 45500, Testing net (#0)
I1007 16:14:59.736778  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:14:59.817385  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8989
I1007 16:14:59.817409  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.312822 (* 1 = 0.312822 loss)
I1007 16:14:59.901046  4982 solver.cpp:218] Iteration 45500 (9.66119 iter/s, 10.3507s/100 iters), loss = 0.055755
I1007 16:14:59.901072  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0557551 (* 1 = 0.0557551 loss)
I1007 16:14:59.901079  4982 sgd_solver.cpp:105] Iteration 45500, lr = 0.01
I1007 16:15:08.243587  4982 solver.cpp:218] Iteration 45600 (11.9868 iter/s, 8.34249s/100 iters), loss = 0.0690888
I1007 16:15:08.243724  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0690889 (* 1 = 0.0690889 loss)
I1007 16:15:08.243732  4982 sgd_solver.cpp:105] Iteration 45600, lr = 0.01
I1007 16:15:16.576110  4982 solver.cpp:218] Iteration 45700 (12.0014 iter/s, 8.33237s/100 iters), loss = 0.0827254
I1007 16:15:16.576150  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0827255 (* 1 = 0.0827255 loss)
I1007 16:15:16.576158  4982 sgd_solver.cpp:105] Iteration 45700, lr = 0.01
I1007 16:15:24.918901  4982 solver.cpp:218] Iteration 45800 (11.9865 iter/s, 8.34272s/100 iters), loss = 0.0911516
I1007 16:15:24.918942  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0911516 (* 1 = 0.0911516 loss)
I1007 16:15:24.918949  4982 sgd_solver.cpp:105] Iteration 45800, lr = 0.01
I1007 16:15:33.253360  4982 solver.cpp:218] Iteration 45900 (11.9985 iter/s, 8.33439s/100 iters), loss = 0.0736845
I1007 16:15:33.253393  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0736845 (* 1 = 0.0736845 loss)
I1007 16:15:33.253399  4982 sgd_solver.cpp:105] Iteration 45900, lr = 0.01
I1007 16:15:41.176131  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:15:41.508965  4982 solver.cpp:330] Iteration 46000, Testing net (#0)
I1007 16:15:43.441143  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:15:43.522300  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8994
I1007 16:15:43.522336  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.317858 (* 1 = 0.317858 loss)
I1007 16:15:43.604827  4982 solver.cpp:218] Iteration 46000 (9.66053 iter/s, 10.3514s/100 iters), loss = 0.0346147
I1007 16:15:43.604851  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0346147 (* 1 = 0.0346147 loss)
I1007 16:15:43.604857  4982 sgd_solver.cpp:105] Iteration 46000, lr = 0.01
I1007 16:15:51.940843  4982 solver.cpp:218] Iteration 46100 (11.9962 iter/s, 8.33596s/100 iters), loss = 0.0791886
I1007 16:15:51.940884  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0791886 (* 1 = 0.0791886 loss)
I1007 16:15:51.940889  4982 sgd_solver.cpp:105] Iteration 46100, lr = 0.01
I1007 16:16:00.282238  4982 solver.cpp:218] Iteration 46200 (11.9885 iter/s, 8.34132s/100 iters), loss = 0.0868508
I1007 16:16:00.282279  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0868509 (* 1 = 0.0868509 loss)
I1007 16:16:00.282285  4982 sgd_solver.cpp:105] Iteration 46200, lr = 0.01
I1007 16:16:08.617648  4982 solver.cpp:218] Iteration 46300 (11.9971 iter/s, 8.33534s/100 iters), loss = 0.0767329
I1007 16:16:08.617688  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0767329 (* 1 = 0.0767329 loss)
I1007 16:16:08.617696  4982 sgd_solver.cpp:105] Iteration 46300, lr = 0.01
I1007 16:16:16.958421  4982 solver.cpp:218] Iteration 46400 (11.9894 iter/s, 8.3407s/100 iters), loss = 0.0731853
I1007 16:16:16.958547  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0731853 (* 1 = 0.0731853 loss)
I1007 16:16:16.958565  4982 sgd_solver.cpp:105] Iteration 46400, lr = 0.01
I1007 16:16:24.884181  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:16:25.217635  4982 solver.cpp:330] Iteration 46500, Testing net (#0)
I1007 16:16:27.150801  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:16:27.231482  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9023
I1007 16:16:27.231519  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.315605 (* 1 = 0.315605 loss)
I1007 16:16:27.314513  4982 solver.cpp:218] Iteration 46500 (9.65629 iter/s, 10.3559s/100 iters), loss = 0.0818024
I1007 16:16:27.314543  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0818024 (* 1 = 0.0818024 loss)
I1007 16:16:27.314551  4982 sgd_solver.cpp:105] Iteration 46500, lr = 0.01
I1007 16:16:35.662473  4982 solver.cpp:218] Iteration 46600 (11.9791 iter/s, 8.3479s/100 iters), loss = 0.0750153
I1007 16:16:35.662514  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0750153 (* 1 = 0.0750153 loss)
I1007 16:16:35.662520  4982 sgd_solver.cpp:105] Iteration 46600, lr = 0.01
I1007 16:16:44.001711  4982 solver.cpp:218] Iteration 46700 (11.9916 iter/s, 8.33917s/100 iters), loss = 0.173921
I1007 16:16:44.001752  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.173921 (* 1 = 0.173921 loss)
I1007 16:16:44.001758  4982 sgd_solver.cpp:105] Iteration 46700, lr = 0.01
I1007 16:16:52.347079  4982 solver.cpp:218] Iteration 46800 (11.9828 iter/s, 8.3453s/100 iters), loss = 0.064077
I1007 16:16:52.347201  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.064077 (* 1 = 0.064077 loss)
I1007 16:16:52.347219  4982 sgd_solver.cpp:105] Iteration 46800, lr = 0.01
I1007 16:17:00.690210  4982 solver.cpp:218] Iteration 46900 (11.9861 iter/s, 8.34298s/100 iters), loss = 0.078825
I1007 16:17:00.690241  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0788251 (* 1 = 0.0788251 loss)
I1007 16:17:00.690248  4982 sgd_solver.cpp:105] Iteration 46900, lr = 0.01
I1007 16:17:08.621404  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:17:08.955457  4982 solver.cpp:330] Iteration 47000, Testing net (#0)
I1007 16:17:10.889868  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:17:10.970327  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9019
I1007 16:17:10.970362  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.312732 (* 1 = 0.312732 loss)
I1007 16:17:11.052979  4982 solver.cpp:218] Iteration 47000 (9.64999 iter/s, 10.3627s/100 iters), loss = 0.0426412
I1007 16:17:11.053004  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0426413 (* 1 = 0.0426413 loss)
I1007 16:17:11.053011  4982 sgd_solver.cpp:105] Iteration 47000, lr = 0.01
I1007 16:17:19.384594  4982 solver.cpp:218] Iteration 47100 (12.0026 iter/s, 8.33156s/100 iters), loss = 0.123576
I1007 16:17:19.384624  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.123576 (* 1 = 0.123576 loss)
I1007 16:17:19.384630  4982 sgd_solver.cpp:105] Iteration 47100, lr = 0.01
I1007 16:17:27.722954  4982 solver.cpp:218] Iteration 47200 (11.9929 iter/s, 8.3383s/100 iters), loss = 0.11484
I1007 16:17:27.723042  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.114841 (* 1 = 0.114841 loss)
I1007 16:17:27.723058  4982 sgd_solver.cpp:105] Iteration 47200, lr = 0.01
I1007 16:17:36.059459  4982 solver.cpp:218] Iteration 47300 (11.9956 iter/s, 8.33639s/100 iters), loss = 0.0272917
I1007 16:17:36.059490  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0272918 (* 1 = 0.0272918 loss)
I1007 16:17:36.059496  4982 sgd_solver.cpp:105] Iteration 47300, lr = 0.01
I1007 16:17:44.395748  4982 solver.cpp:218] Iteration 47400 (11.9958 iter/s, 8.33623s/100 iters), loss = 0.0685414
I1007 16:17:44.395778  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0685415 (* 1 = 0.0685415 loss)
I1007 16:17:44.395784  4982 sgd_solver.cpp:105] Iteration 47400, lr = 0.01
I1007 16:17:52.317102  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:17:52.650589  4982 solver.cpp:330] Iteration 47500, Testing net (#0)
I1007 16:17:54.583377  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:17:54.663517  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8962
I1007 16:17:54.663552  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.333357 (* 1 = 0.333357 loss)
I1007 16:17:54.747045  4982 solver.cpp:218] Iteration 47500 (9.66069 iter/s, 10.3512s/100 iters), loss = 0.154774
I1007 16:17:54.747071  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.154774 (* 1 = 0.154774 loss)
I1007 16:17:54.747077  4982 sgd_solver.cpp:105] Iteration 47500, lr = 0.01
I1007 16:18:03.084625  4982 solver.cpp:218] Iteration 47600 (11.994 iter/s, 8.33753s/100 iters), loss = 0.126597
I1007 16:18:03.084774  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.126597 (* 1 = 0.126597 loss)
I1007 16:18:03.084792  4982 sgd_solver.cpp:105] Iteration 47600, lr = 0.01
I1007 16:18:11.415139  4982 solver.cpp:218] Iteration 47700 (12.0043 iter/s, 8.33034s/100 iters), loss = 0.0860302
I1007 16:18:11.415170  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0860303 (* 1 = 0.0860303 loss)
I1007 16:18:11.415177  4982 sgd_solver.cpp:105] Iteration 47700, lr = 0.01
I1007 16:18:19.749716  4982 solver.cpp:218] Iteration 47800 (11.9983 iter/s, 8.33452s/100 iters), loss = 0.0402492
I1007 16:18:19.749756  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0402494 (* 1 = 0.0402494 loss)
I1007 16:18:19.749763  4982 sgd_solver.cpp:105] Iteration 47800, lr = 0.01
I1007 16:18:28.077787  4982 solver.cpp:218] Iteration 47900 (12.0077 iter/s, 8.328s/100 iters), loss = 0.0286004
I1007 16:18:28.077828  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0286006 (* 1 = 0.0286006 loss)
I1007 16:18:28.077834  4982 sgd_solver.cpp:105] Iteration 47900, lr = 0.01
I1007 16:18:35.996357  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:18:36.330031  4982 solver.cpp:330] Iteration 48000, Testing net (#0)
I1007 16:18:38.261785  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:18:38.342931  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9028
I1007 16:18:38.342963  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.324765 (* 1 = 0.324765 loss)
I1007 16:18:38.424849  4982 solver.cpp:218] Iteration 48000 (9.66465 iter/s, 10.347s/100 iters), loss = 0.0511582
I1007 16:18:38.424880  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0511584 (* 1 = 0.0511584 loss)
I1007 16:18:38.424888  4982 sgd_solver.cpp:105] Iteration 48000, lr = 0.01
I1007 16:18:46.760417  4982 solver.cpp:218] Iteration 48100 (11.9969 iter/s, 8.33551s/100 iters), loss = 0.0683629
I1007 16:18:46.760465  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0683631 (* 1 = 0.0683631 loss)
I1007 16:18:46.760473  4982 sgd_solver.cpp:105] Iteration 48100, lr = 0.01
I1007 16:18:55.100329  4982 solver.cpp:218] Iteration 48200 (11.9906 iter/s, 8.33984s/100 iters), loss = 0.118539
I1007 16:18:55.100361  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.118539 (* 1 = 0.118539 loss)
I1007 16:18:55.100368  4982 sgd_solver.cpp:105] Iteration 48200, lr = 0.01
I1007 16:19:03.434757  4982 solver.cpp:218] Iteration 48300 (11.9985 iter/s, 8.33437s/100 iters), loss = 0.138811
I1007 16:19:03.434785  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.138811 (* 1 = 0.138811 loss)
I1007 16:19:03.434792  4982 sgd_solver.cpp:105] Iteration 48300, lr = 0.01
I1007 16:19:11.767649  4982 solver.cpp:218] Iteration 48400 (12.0007 iter/s, 8.33284s/100 iters), loss = 0.0690226
I1007 16:19:11.767763  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0690227 (* 1 = 0.0690227 loss)
I1007 16:19:11.767771  4982 sgd_solver.cpp:105] Iteration 48400, lr = 0.01
I1007 16:19:19.686110  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:19:20.019470  4982 solver.cpp:330] Iteration 48500, Testing net (#0)
I1007 16:19:21.952111  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:19:22.033067  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8964
I1007 16:19:22.033092  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.344409 (* 1 = 0.344409 loss)
I1007 16:19:22.116238  4982 solver.cpp:218] Iteration 48500 (9.66329 iter/s, 10.3484s/100 iters), loss = 0.0822658
I1007 16:19:22.116266  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0822659 (* 1 = 0.0822659 loss)
I1007 16:19:22.116271  4982 sgd_solver.cpp:105] Iteration 48500, lr = 0.01
I1007 16:19:30.457991  4982 solver.cpp:218] Iteration 48600 (11.988 iter/s, 8.3417s/100 iters), loss = 0.0470252
I1007 16:19:30.458021  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0470253 (* 1 = 0.0470253 loss)
I1007 16:19:30.458026  4982 sgd_solver.cpp:105] Iteration 48600, lr = 0.01
I1007 16:19:38.788414  4982 solver.cpp:218] Iteration 48700 (12.0043 iter/s, 8.33037s/100 iters), loss = 0.0349806
I1007 16:19:38.788453  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0349807 (* 1 = 0.0349807 loss)
I1007 16:19:38.788460  4982 sgd_solver.cpp:105] Iteration 48700, lr = 0.01
I1007 16:19:47.134259  4982 solver.cpp:218] Iteration 48800 (11.9821 iter/s, 8.34578s/100 iters), loss = 0.102583
I1007 16:19:47.134377  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.102583 (* 1 = 0.102583 loss)
I1007 16:19:47.134385  4982 sgd_solver.cpp:105] Iteration 48800, lr = 0.01
I1007 16:19:55.475430  4982 solver.cpp:218] Iteration 48900 (11.9889 iter/s, 8.34104s/100 iters), loss = 0.0607502
I1007 16:19:55.475468  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0607503 (* 1 = 0.0607503 loss)
I1007 16:19:55.475474  4982 sgd_solver.cpp:105] Iteration 48900, lr = 0.01
I1007 16:20:03.402856  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:20:03.736702  4982 solver.cpp:330] Iteration 49000, Testing net (#0)
I1007 16:20:05.669785  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:20:05.751257  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9017
I1007 16:20:05.751293  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.335709 (* 1 = 0.335709 loss)
I1007 16:20:05.833742  4982 solver.cpp:218] Iteration 49000 (9.65415 iter/s, 10.3582s/100 iters), loss = 0.0315962
I1007 16:20:05.833770  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0315963 (* 1 = 0.0315963 loss)
I1007 16:20:05.833775  4982 sgd_solver.cpp:105] Iteration 49000, lr = 0.01
I1007 16:20:14.159353  4982 solver.cpp:218] Iteration 49100 (12.0112 iter/s, 8.32556s/100 iters), loss = 0.0450907
I1007 16:20:14.159394  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0450908 (* 1 = 0.0450908 loss)
I1007 16:20:14.159399  4982 sgd_solver.cpp:105] Iteration 49100, lr = 0.01
I1007 16:20:22.496666  4982 solver.cpp:218] Iteration 49200 (11.9944 iter/s, 8.33724s/100 iters), loss = 0.0611199
I1007 16:20:22.496793  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.06112 (* 1 = 0.06112 loss)
I1007 16:20:22.496812  4982 sgd_solver.cpp:105] Iteration 49200, lr = 0.01
I1007 16:20:30.829177  4982 solver.cpp:218] Iteration 49300 (12.0014 iter/s, 8.33236s/100 iters), loss = 0.104589
I1007 16:20:30.829223  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.104589 (* 1 = 0.104589 loss)
I1007 16:20:30.829231  4982 sgd_solver.cpp:105] Iteration 49300, lr = 0.01
I1007 16:20:39.160440  4982 solver.cpp:218] Iteration 49400 (12.0031 iter/s, 8.33119s/100 iters), loss = 0.0804029
I1007 16:20:39.160481  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.080403 (* 1 = 0.080403 loss)
I1007 16:20:39.160487  4982 sgd_solver.cpp:105] Iteration 49400, lr = 0.01
I1007 16:20:47.080092  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:20:47.413602  4982 solver.cpp:330] Iteration 49500, Testing net (#0)
I1007 16:20:49.344566  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:20:49.424888  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.897
I1007 16:20:49.424914  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.358502 (* 1 = 0.358502 loss)
I1007 16:20:49.508994  4982 solver.cpp:218] Iteration 49500 (9.66325 iter/s, 10.3485s/100 iters), loss = 0.0469884
I1007 16:20:49.509027  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0469885 (* 1 = 0.0469885 loss)
I1007 16:20:49.509034  4982 sgd_solver.cpp:105] Iteration 49500, lr = 0.01
I1007 16:20:57.850123  4982 solver.cpp:218] Iteration 49600 (11.9889 iter/s, 8.34107s/100 iters), loss = 0.0444972
I1007 16:20:57.850281  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0444973 (* 1 = 0.0444973 loss)
I1007 16:20:57.850289  4982 sgd_solver.cpp:105] Iteration 49600, lr = 0.01
I1007 16:21:06.188732  4982 solver.cpp:218] Iteration 49700 (11.9927 iter/s, 8.33843s/100 iters), loss = 0.0300265
I1007 16:21:06.188761  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0300266 (* 1 = 0.0300266 loss)
I1007 16:21:06.188767  4982 sgd_solver.cpp:105] Iteration 49700, lr = 0.01
I1007 16:21:14.521795  4982 solver.cpp:218] Iteration 49800 (12.0005 iter/s, 8.33301s/100 iters), loss = 0.0279372
I1007 16:21:14.521826  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0279373 (* 1 = 0.0279373 loss)
I1007 16:21:14.521832  4982 sgd_solver.cpp:105] Iteration 49800, lr = 0.01
I1007 16:21:22.858376  4982 solver.cpp:218] Iteration 49900 (11.9954 iter/s, 8.33652s/100 iters), loss = 0.0519278
I1007 16:21:22.858417  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.051928 (* 1 = 0.051928 loss)
I1007 16:21:22.858423  4982 sgd_solver.cpp:105] Iteration 49900, lr = 0.01
I1007 16:21:30.786586  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:21:31.120172  4982 solver.cpp:330] Iteration 50000, Testing net (#0)
I1007 16:21:33.052547  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:21:33.133965  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9024
I1007 16:21:33.133999  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.3392 (* 1 = 0.3392 loss)
I1007 16:21:33.216935  4982 solver.cpp:218] Iteration 50000 (9.65392 iter/s, 10.3585s/100 iters), loss = 0.0368767
I1007 16:21:33.216964  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0368768 (* 1 = 0.0368768 loss)
I1007 16:21:33.216970  4982 sgd_solver.cpp:105] Iteration 50000, lr = 0.01
I1007 16:21:41.549901  4982 solver.cpp:218] Iteration 50100 (12.0006 iter/s, 8.33291s/100 iters), loss = 0.0374916
I1007 16:21:41.549942  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0374918 (* 1 = 0.0374918 loss)
I1007 16:21:41.549947  4982 sgd_solver.cpp:105] Iteration 50100, lr = 0.01
I1007 16:21:49.889437  4982 solver.cpp:218] Iteration 50200 (11.9912 iter/s, 8.33947s/100 iters), loss = 0.091659
I1007 16:21:49.889468  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0916591 (* 1 = 0.0916591 loss)
I1007 16:21:49.889474  4982 sgd_solver.cpp:105] Iteration 50200, lr = 0.01
I1007 16:21:58.223254  4982 solver.cpp:218] Iteration 50300 (11.9994 iter/s, 8.33376s/100 iters), loss = 0.0501906
I1007 16:21:58.223294  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0501907 (* 1 = 0.0501907 loss)
I1007 16:21:58.223299  4982 sgd_solver.cpp:105] Iteration 50300, lr = 0.01
I1007 16:22:06.566270  4982 solver.cpp:218] Iteration 50400 (11.9862 iter/s, 8.34295s/100 iters), loss = 0.0403103
I1007 16:22:06.566395  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0403103 (* 1 = 0.0403103 loss)
I1007 16:22:06.566412  4982 sgd_solver.cpp:105] Iteration 50400, lr = 0.01
I1007 16:22:14.484118  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:22:14.817898  4982 solver.cpp:330] Iteration 50500, Testing net (#0)
I1007 16:22:16.750233  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:22:16.831121  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9023
I1007 16:22:16.831156  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.339758 (* 1 = 0.339758 loss)
I1007 16:22:16.914686  4982 solver.cpp:218] Iteration 50500 (9.66346 iter/s, 10.3483s/100 iters), loss = 0.0374334
I1007 16:22:16.914712  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0374335 (* 1 = 0.0374335 loss)
I1007 16:22:16.914718  4982 sgd_solver.cpp:105] Iteration 50500, lr = 0.01
I1007 16:22:25.250380  4982 solver.cpp:218] Iteration 50600 (11.9967 iter/s, 8.33564s/100 iters), loss = 0.0489978
I1007 16:22:25.250419  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0489979 (* 1 = 0.0489979 loss)
I1007 16:22:25.250425  4982 sgd_solver.cpp:105] Iteration 50600, lr = 0.01
I1007 16:22:33.578964  4982 solver.cpp:218] Iteration 50700 (12.0069 iter/s, 8.32852s/100 iters), loss = 0.0348154
I1007 16:22:33.579005  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0348155 (* 1 = 0.0348155 loss)
I1007 16:22:33.579011  4982 sgd_solver.cpp:105] Iteration 50700, lr = 0.01
I1007 16:22:41.914669  4982 solver.cpp:218] Iteration 50800 (11.9967 iter/s, 8.33564s/100 iters), loss = 0.0470566
I1007 16:22:41.914811  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0470567 (* 1 = 0.0470567 loss)
I1007 16:22:41.914829  4982 sgd_solver.cpp:105] Iteration 50800, lr = 0.01
I1007 16:22:50.246523  4982 solver.cpp:218] Iteration 50900 (12.0024 iter/s, 8.3317s/100 iters), loss = 0.0926035
I1007 16:22:50.246565  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0926036 (* 1 = 0.0926036 loss)
I1007 16:22:50.246572  4982 sgd_solver.cpp:105] Iteration 50900, lr = 0.01
I1007 16:22:58.170523  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:22:58.505837  4982 solver.cpp:330] Iteration 51000, Testing net (#0)
I1007 16:23:00.440353  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:23:00.521872  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9023
I1007 16:23:00.521908  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.334237 (* 1 = 0.334237 loss)
I1007 16:23:00.604881  4982 solver.cpp:218] Iteration 51000 (9.65411 iter/s, 10.3583s/100 iters), loss = 0.0753778
I1007 16:23:00.604907  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0753779 (* 1 = 0.0753779 loss)
I1007 16:23:00.604912  4982 sgd_solver.cpp:105] Iteration 51000, lr = 0.01
I1007 16:23:08.933290  4982 solver.cpp:218] Iteration 51100 (12.0072 iter/s, 8.32836s/100 iters), loss = 0.0689935
I1007 16:23:08.933331  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0689937 (* 1 = 0.0689937 loss)
I1007 16:23:08.933336  4982 sgd_solver.cpp:105] Iteration 51100, lr = 0.01
I1007 16:23:17.268654  4982 solver.cpp:218] Iteration 51200 (11.9972 iter/s, 8.33529s/100 iters), loss = 0.0571695
I1007 16:23:17.268774  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0571696 (* 1 = 0.0571696 loss)
I1007 16:23:17.268792  4982 sgd_solver.cpp:105] Iteration 51200, lr = 0.01
I1007 16:23:25.592823  4982 solver.cpp:218] Iteration 51300 (12.0134 iter/s, 8.32402s/100 iters), loss = 0.0510531
I1007 16:23:25.592871  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0510533 (* 1 = 0.0510533 loss)
I1007 16:23:25.592880  4982 sgd_solver.cpp:105] Iteration 51300, lr = 0.01
I1007 16:23:33.925026  4982 solver.cpp:218] Iteration 51400 (12.0017 iter/s, 8.33213s/100 iters), loss = 0.0748645
I1007 16:23:33.925057  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0748647 (* 1 = 0.0748647 loss)
I1007 16:23:33.925073  4982 sgd_solver.cpp:105] Iteration 51400, lr = 0.01
I1007 16:23:41.838536  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:23:42.171711  4982 solver.cpp:330] Iteration 51500, Testing net (#0)
I1007 16:23:44.103401  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:23:44.184041  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8961
I1007 16:23:44.184077  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.356873 (* 1 = 0.356873 loss)
I1007 16:23:44.267809  4982 solver.cpp:218] Iteration 51500 (9.66864 iter/s, 10.3427s/100 iters), loss = 0.0332518
I1007 16:23:44.267843  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.033252 (* 1 = 0.033252 loss)
I1007 16:23:44.267849  4982 sgd_solver.cpp:105] Iteration 51500, lr = 0.01
I1007 16:23:52.603763  4982 solver.cpp:218] Iteration 51600 (11.9963 iter/s, 8.33589s/100 iters), loss = 0.0495315
I1007 16:23:52.603885  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0495316 (* 1 = 0.0495316 loss)
I1007 16:23:52.603893  4982 sgd_solver.cpp:105] Iteration 51600, lr = 0.01
I1007 16:24:00.935819  4982 solver.cpp:218] Iteration 51700 (12.002 iter/s, 8.33192s/100 iters), loss = 0.0534699
I1007 16:24:00.935859  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0534701 (* 1 = 0.0534701 loss)
I1007 16:24:00.935865  4982 sgd_solver.cpp:105] Iteration 51700, lr = 0.01
I1007 16:24:09.268841  4982 solver.cpp:218] Iteration 51800 (12.0006 iter/s, 8.33295s/100 iters), loss = 0.0550512
I1007 16:24:09.268877  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0550513 (* 1 = 0.0550513 loss)
I1007 16:24:09.268884  4982 sgd_solver.cpp:105] Iteration 51800, lr = 0.01
I1007 16:24:17.600811  4982 solver.cpp:218] Iteration 51900 (12.0021 iter/s, 8.33191s/100 iters), loss = 0.0616508
I1007 16:24:17.600859  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.061651 (* 1 = 0.061651 loss)
I1007 16:24:17.600867  4982 sgd_solver.cpp:105] Iteration 51900, lr = 0.01
I1007 16:24:25.522517  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:24:25.855232  4982 solver.cpp:330] Iteration 52000, Testing net (#0)
I1007 16:24:27.787266  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:24:27.868490  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8992
I1007 16:24:27.868526  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.357447 (* 1 = 0.357447 loss)
I1007 16:24:27.951084  4982 solver.cpp:218] Iteration 52000 (9.66165 iter/s, 10.3502s/100 iters), loss = 0.0729656
I1007 16:24:27.951110  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0729658 (* 1 = 0.0729658 loss)
I1007 16:24:27.951117  4982 sgd_solver.cpp:105] Iteration 52000, lr = 0.01
I1007 16:24:36.279022  4982 solver.cpp:218] Iteration 52100 (12.0079 iter/s, 8.32788s/100 iters), loss = 0.064496
I1007 16:24:36.279053  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0644962 (* 1 = 0.0644962 loss)
I1007 16:24:36.279059  4982 sgd_solver.cpp:105] Iteration 52100, lr = 0.01
I1007 16:24:44.609124  4982 solver.cpp:218] Iteration 52200 (12.0047 iter/s, 8.33004s/100 iters), loss = 0.0191397
I1007 16:24:44.609165  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0191399 (* 1 = 0.0191399 loss)
I1007 16:24:44.609172  4982 sgd_solver.cpp:105] Iteration 52200, lr = 0.01
I1007 16:24:52.938307  4982 solver.cpp:218] Iteration 52300 (12.0061 iter/s, 8.32911s/100 iters), loss = 0.0498484
I1007 16:24:52.938336  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0498486 (* 1 = 0.0498486 loss)
I1007 16:24:52.938343  4982 sgd_solver.cpp:105] Iteration 52300, lr = 0.01
I1007 16:25:01.275499  4982 solver.cpp:218] Iteration 52400 (11.9945 iter/s, 8.33713s/100 iters), loss = 0.056474
I1007 16:25:01.275619  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0564741 (* 1 = 0.0564741 loss)
I1007 16:25:01.275638  4982 sgd_solver.cpp:105] Iteration 52400, lr = 0.01
I1007 16:25:09.188959  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:25:09.522886  4982 solver.cpp:330] Iteration 52500, Testing net (#0)
I1007 16:25:11.456341  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:25:11.536985  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.897
I1007 16:25:11.537020  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.364977 (* 1 = 0.364977 loss)
I1007 16:25:11.620276  4982 solver.cpp:218] Iteration 52500 (9.66684 iter/s, 10.3446s/100 iters), loss = 0.0585281
I1007 16:25:11.620303  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0585282 (* 1 = 0.0585282 loss)
I1007 16:25:11.620311  4982 sgd_solver.cpp:105] Iteration 52500, lr = 0.01
I1007 16:25:19.961248  4982 solver.cpp:218] Iteration 52600 (11.9891 iter/s, 8.34092s/100 iters), loss = 0.0441539
I1007 16:25:19.961278  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0441541 (* 1 = 0.0441541 loss)
I1007 16:25:19.961284  4982 sgd_solver.cpp:105] Iteration 52600, lr = 0.01
I1007 16:25:28.291741  4982 solver.cpp:218] Iteration 52700 (12.0042 iter/s, 8.33044s/100 iters), loss = 0.0948752
I1007 16:25:28.291771  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0948754 (* 1 = 0.0948754 loss)
I1007 16:25:28.291777  4982 sgd_solver.cpp:105] Iteration 52700, lr = 0.01
I1007 16:25:36.631320  4982 solver.cpp:218] Iteration 52800 (11.9911 iter/s, 8.33952s/100 iters), loss = 0.0336914
I1007 16:25:36.631461  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0336916 (* 1 = 0.0336916 loss)
I1007 16:25:36.631479  4982 sgd_solver.cpp:105] Iteration 52800, lr = 0.01
I1007 16:25:44.970561  4982 solver.cpp:218] Iteration 52900 (11.9917 iter/s, 8.33908s/100 iters), loss = 0.0231476
I1007 16:25:44.970592  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0231478 (* 1 = 0.0231478 loss)
I1007 16:25:44.970598  4982 sgd_solver.cpp:105] Iteration 52900, lr = 0.01
I1007 16:25:52.897166  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:25:53.230636  4982 solver.cpp:330] Iteration 53000, Testing net (#0)
I1007 16:25:55.162695  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:25:55.244407  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8975
I1007 16:25:55.244432  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.350421 (* 1 = 0.350421 loss)
I1007 16:25:55.326910  4982 solver.cpp:218] Iteration 53000 (9.65597 iter/s, 10.3563s/100 iters), loss = 0.018566
I1007 16:25:55.326937  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0185662 (* 1 = 0.0185662 loss)
I1007 16:25:55.326944  4982 sgd_solver.cpp:105] Iteration 53000, lr = 0.01
I1007 16:26:03.657184  4982 solver.cpp:218] Iteration 53100 (12.0045 iter/s, 8.33022s/100 iters), loss = 0.0434306
I1007 16:26:03.657215  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0434308 (* 1 = 0.0434308 loss)
I1007 16:26:03.657223  4982 sgd_solver.cpp:105] Iteration 53100, lr = 0.01
I1007 16:26:11.991394  4982 solver.cpp:218] Iteration 53200 (11.9988 iter/s, 8.33415s/100 iters), loss = 0.0754121
I1007 16:26:11.991513  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0754123 (* 1 = 0.0754123 loss)
I1007 16:26:11.991533  4982 sgd_solver.cpp:105] Iteration 53200, lr = 0.01
I1007 16:26:20.324256  4982 solver.cpp:218] Iteration 53300 (12.0009 iter/s, 8.33272s/100 iters), loss = 0.0461926
I1007 16:26:20.324288  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0461928 (* 1 = 0.0461928 loss)
I1007 16:26:20.324295  4982 sgd_solver.cpp:105] Iteration 53300, lr = 0.01
I1007 16:26:28.659204  4982 solver.cpp:218] Iteration 53400 (11.9978 iter/s, 8.33489s/100 iters), loss = 0.0224297
I1007 16:26:28.659235  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0224299 (* 1 = 0.0224299 loss)
I1007 16:26:28.659242  4982 sgd_solver.cpp:105] Iteration 53400, lr = 0.01
I1007 16:26:36.577025  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:26:36.910980  4982 solver.cpp:330] Iteration 53500, Testing net (#0)
I1007 16:26:38.842706  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:26:38.923444  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8968
I1007 16:26:38.923481  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.370676 (* 1 = 0.370676 loss)
I1007 16:26:39.006889  4982 solver.cpp:218] Iteration 53500 (9.66405 iter/s, 10.3476s/100 iters), loss = 0.0698261
I1007 16:26:39.006916  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0698263 (* 1 = 0.0698263 loss)
I1007 16:26:39.006922  4982 sgd_solver.cpp:105] Iteration 53500, lr = 0.01
I1007 16:26:47.343150  4982 solver.cpp:218] Iteration 53600 (11.9959 iter/s, 8.33621s/100 iters), loss = 0.0182981
I1007 16:26:47.343271  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0182983 (* 1 = 0.0182983 loss)
I1007 16:26:47.343281  4982 sgd_solver.cpp:105] Iteration 53600, lr = 0.01
I1007 16:26:55.670964  4982 solver.cpp:218] Iteration 53700 (12.0082 iter/s, 8.32767s/100 iters), loss = 0.0721829
I1007 16:26:55.670994  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0721831 (* 1 = 0.0721831 loss)
I1007 16:26:55.671010  4982 sgd_solver.cpp:105] Iteration 53700, lr = 0.01
I1007 16:27:04.003211  4982 solver.cpp:218] Iteration 53800 (12.0016 iter/s, 8.33219s/100 iters), loss = 0.0751484
I1007 16:27:04.003242  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0751486 (* 1 = 0.0751486 loss)
I1007 16:27:04.003250  4982 sgd_solver.cpp:105] Iteration 53800, lr = 0.01
I1007 16:27:12.330989  4982 solver.cpp:218] Iteration 53900 (12.0081 iter/s, 8.32772s/100 iters), loss = 0.038236
I1007 16:27:12.331019  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0382362 (* 1 = 0.0382362 loss)
I1007 16:27:12.331025  4982 sgd_solver.cpp:105] Iteration 53900, lr = 0.01
I1007 16:27:20.242784  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:27:20.578524  4982 solver.cpp:330] Iteration 54000, Testing net (#0)
I1007 16:27:22.509738  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:27:22.591418  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9033
I1007 16:27:22.591454  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.347922 (* 1 = 0.347922 loss)
I1007 16:27:22.674159  4982 solver.cpp:218] Iteration 54000 (9.66827 iter/s, 10.3431s/100 iters), loss = 0.0495002
I1007 16:27:22.674183  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0495004 (* 1 = 0.0495004 loss)
I1007 16:27:22.674190  4982 sgd_solver.cpp:105] Iteration 54000, lr = 0.01
I1007 16:27:31.002624  4982 solver.cpp:218] Iteration 54100 (12.0071 iter/s, 8.32841s/100 iters), loss = 0.0211841
I1007 16:27:31.002665  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0211843 (* 1 = 0.0211843 loss)
I1007 16:27:31.002671  4982 sgd_solver.cpp:105] Iteration 54100, lr = 0.01
I1007 16:27:39.339956  4982 solver.cpp:218] Iteration 54200 (11.9943 iter/s, 8.33727s/100 iters), loss = 0.0779633
I1007 16:27:39.339984  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0779635 (* 1 = 0.0779635 loss)
I1007 16:27:39.339990  4982 sgd_solver.cpp:105] Iteration 54200, lr = 0.01
I1007 16:27:47.672349  4982 solver.cpp:218] Iteration 54300 (12.0014 iter/s, 8.33234s/100 iters), loss = 0.0374633
I1007 16:27:47.672391  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0374635 (* 1 = 0.0374635 loss)
I1007 16:27:47.672397  4982 sgd_solver.cpp:105] Iteration 54300, lr = 0.01
I1007 16:27:56.005812  4982 solver.cpp:218] Iteration 54400 (11.9999 iter/s, 8.3334s/100 iters), loss = 0.0513411
I1007 16:27:56.005928  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0513413 (* 1 = 0.0513413 loss)
I1007 16:27:56.005945  4982 sgd_solver.cpp:105] Iteration 54400, lr = 0.01
I1007 16:28:03.928421  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:28:04.262470  4982 solver.cpp:330] Iteration 54500, Testing net (#0)
I1007 16:28:06.194941  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:28:06.275709  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8976
I1007 16:28:06.275746  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.361825 (* 1 = 0.361825 loss)
I1007 16:28:06.359350  4982 solver.cpp:218] Iteration 54500 (9.65866 iter/s, 10.3534s/100 iters), loss = 0.0262015
I1007 16:28:06.359380  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0262018 (* 1 = 0.0262018 loss)
I1007 16:28:06.359387  4982 sgd_solver.cpp:105] Iteration 54500, lr = 0.01
I1007 16:28:14.694464  4982 solver.cpp:218] Iteration 54600 (11.9975 iter/s, 8.33506s/100 iters), loss = 0.0398325
I1007 16:28:14.694511  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0398327 (* 1 = 0.0398327 loss)
I1007 16:28:14.694519  4982 sgd_solver.cpp:105] Iteration 54600, lr = 0.01
I1007 16:28:23.019807  4982 solver.cpp:218] Iteration 54700 (12.0116 iter/s, 8.32527s/100 iters), loss = 0.0346852
I1007 16:28:23.019848  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0346854 (* 1 = 0.0346854 loss)
I1007 16:28:23.019855  4982 sgd_solver.cpp:105] Iteration 54700, lr = 0.01
I1007 16:28:31.352960  4982 solver.cpp:218] Iteration 54800 (12.0004 iter/s, 8.33308s/100 iters), loss = 0.0889615
I1007 16:28:31.353072  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0889618 (* 1 = 0.0889618 loss)
I1007 16:28:31.353080  4982 sgd_solver.cpp:105] Iteration 54800, lr = 0.01
I1007 16:28:39.686789  4982 solver.cpp:218] Iteration 54900 (11.9995 iter/s, 8.33369s/100 iters), loss = 0.0741226
I1007 16:28:39.686830  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0741228 (* 1 = 0.0741228 loss)
I1007 16:28:39.686836  4982 sgd_solver.cpp:105] Iteration 54900, lr = 0.01
I1007 16:28:47.616328  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:28:47.950270  4982 solver.cpp:330] Iteration 55000, Testing net (#0)
I1007 16:28:49.881131  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:28:49.962529  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9005
I1007 16:28:49.962565  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.356272 (* 1 = 0.356272 loss)
I1007 16:28:50.045516  4982 solver.cpp:218] Iteration 55000 (9.65376 iter/s, 10.3587s/100 iters), loss = 0.0301014
I1007 16:28:50.045541  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0301016 (* 1 = 0.0301016 loss)
I1007 16:28:50.045547  4982 sgd_solver.cpp:105] Iteration 55000, lr = 0.01
I1007 16:28:58.386551  4982 solver.cpp:218] Iteration 55100 (11.989 iter/s, 8.34098s/100 iters), loss = 0.0619967
I1007 16:28:58.386581  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0619969 (* 1 = 0.0619969 loss)
I1007 16:28:58.386587  4982 sgd_solver.cpp:105] Iteration 55100, lr = 0.01
I1007 16:29:06.733781  4982 solver.cpp:218] Iteration 55200 (11.9801 iter/s, 8.34717s/100 iters), loss = 0.0136691
I1007 16:29:06.733917  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0136693 (* 1 = 0.0136693 loss)
I1007 16:29:06.733925  4982 sgd_solver.cpp:105] Iteration 55200, lr = 0.01
I1007 16:29:15.075680  4982 solver.cpp:218] Iteration 55300 (11.9879 iter/s, 8.34175s/100 iters), loss = 0.0238843
I1007 16:29:15.075711  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0238845 (* 1 = 0.0238845 loss)
I1007 16:29:15.075716  4982 sgd_solver.cpp:105] Iteration 55300, lr = 0.01
I1007 16:29:23.421732  4982 solver.cpp:218] Iteration 55400 (11.9818 iter/s, 8.34599s/100 iters), loss = 0.0692849
I1007 16:29:23.421773  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0692851 (* 1 = 0.0692851 loss)
I1007 16:29:23.421778  4982 sgd_solver.cpp:105] Iteration 55400, lr = 0.01
I1007 16:29:31.348357  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:29:31.682164  4982 solver.cpp:330] Iteration 55500, Testing net (#0)
I1007 16:29:33.613878  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:29:33.694303  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8954
I1007 16:29:33.694341  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.383814 (* 1 = 0.383814 loss)
I1007 16:29:33.777741  4982 solver.cpp:218] Iteration 55500 (9.6563 iter/s, 10.3559s/100 iters), loss = 0.0223849
I1007 16:29:33.777776  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.022385 (* 1 = 0.022385 loss)
I1007 16:29:33.777782  4982 sgd_solver.cpp:105] Iteration 55500, lr = 0.01
I1007 16:29:42.115221  4982 solver.cpp:218] Iteration 55600 (11.9941 iter/s, 8.33742s/100 iters), loss = 0.128797
I1007 16:29:42.115373  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.128797 (* 1 = 0.128797 loss)
I1007 16:29:42.115381  4982 sgd_solver.cpp:105] Iteration 55600, lr = 0.01
I1007 16:29:50.446400  4982 solver.cpp:218] Iteration 55700 (12.0033 iter/s, 8.33101s/100 iters), loss = 0.0852018
I1007 16:29:50.446431  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.085202 (* 1 = 0.085202 loss)
I1007 16:29:50.446437  4982 sgd_solver.cpp:105] Iteration 55700, lr = 0.01
I1007 16:29:58.787407  4982 solver.cpp:218] Iteration 55800 (11.989 iter/s, 8.34095s/100 iters), loss = 0.0313317
I1007 16:29:58.787448  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0313319 (* 1 = 0.0313319 loss)
I1007 16:29:58.787454  4982 sgd_solver.cpp:105] Iteration 55800, lr = 0.01
I1007 16:30:07.118952  4982 solver.cpp:218] Iteration 55900 (12.0027 iter/s, 8.33148s/100 iters), loss = 0.021522
I1007 16:30:07.118991  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0215222 (* 1 = 0.0215222 loss)
I1007 16:30:07.118998  4982 sgd_solver.cpp:105] Iteration 55900, lr = 0.01
I1007 16:30:15.039330  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:30:15.372633  4982 solver.cpp:330] Iteration 56000, Testing net (#0)
I1007 16:30:17.306506  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:30:17.387300  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8946
I1007 16:30:17.387336  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.392424 (* 1 = 0.392424 loss)
I1007 16:30:17.470084  4982 solver.cpp:218] Iteration 56000 (9.66084 iter/s, 10.3511s/100 iters), loss = 0.0186713
I1007 16:30:17.470111  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0186715 (* 1 = 0.0186715 loss)
I1007 16:30:17.470118  4982 sgd_solver.cpp:105] Iteration 56000, lr = 0.01
I1007 16:30:25.796703  4982 solver.cpp:218] Iteration 56100 (12.0098 iter/s, 8.32656s/100 iters), loss = 0.048256
I1007 16:30:25.796746  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0482562 (* 1 = 0.0482562 loss)
I1007 16:30:25.796751  4982 sgd_solver.cpp:105] Iteration 56100, lr = 0.01
I1007 16:30:34.136133  4982 solver.cpp:218] Iteration 56200 (11.9913 iter/s, 8.33936s/100 iters), loss = 0.0563472
I1007 16:30:34.136162  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0563474 (* 1 = 0.0563474 loss)
I1007 16:30:34.136168  4982 sgd_solver.cpp:105] Iteration 56200, lr = 0.01
I1007 16:30:42.466164  4982 solver.cpp:218] Iteration 56300 (12.0048 iter/s, 8.32998s/100 iters), loss = 0.0768129
I1007 16:30:42.466193  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0768131 (* 1 = 0.0768131 loss)
I1007 16:30:42.466199  4982 sgd_solver.cpp:105] Iteration 56300, lr = 0.01
I1007 16:30:50.802953  4982 solver.cpp:218] Iteration 56400 (11.9951 iter/s, 8.33673s/100 iters), loss = 0.0483999
I1007 16:30:50.803092  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0484001 (* 1 = 0.0484001 loss)
I1007 16:30:50.803100  4982 sgd_solver.cpp:105] Iteration 56400, lr = 0.01
I1007 16:30:58.718020  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:30:59.051556  4982 solver.cpp:330] Iteration 56500, Testing net (#0)
I1007 16:31:00.986253  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:31:01.066968  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9009
I1007 16:31:01.067004  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.367592 (* 1 = 0.367592 loss)
I1007 16:31:01.150897  4982 solver.cpp:218] Iteration 56500 (9.66391 iter/s, 10.3478s/100 iters), loss = 0.0163419
I1007 16:31:01.150926  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0163421 (* 1 = 0.0163421 loss)
I1007 16:31:01.150933  4982 sgd_solver.cpp:105] Iteration 56500, lr = 0.01
I1007 16:31:09.489027  4982 solver.cpp:218] Iteration 56600 (11.9932 iter/s, 8.33807s/100 iters), loss = 0.054145
I1007 16:31:09.489056  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0541452 (* 1 = 0.0541452 loss)
I1007 16:31:09.489061  4982 sgd_solver.cpp:105] Iteration 56600, lr = 0.01
I1007 16:31:17.827639  4982 solver.cpp:218] Iteration 56700 (11.9925 iter/s, 8.33856s/100 iters), loss = 0.0268746
I1007 16:31:17.827668  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0268748 (* 1 = 0.0268748 loss)
I1007 16:31:17.827684  4982 sgd_solver.cpp:105] Iteration 56700, lr = 0.01
I1007 16:31:26.239581  4982 solver.cpp:218] Iteration 56800 (11.8879 iter/s, 8.41188s/100 iters), loss = 0.027426
I1007 16:31:26.239720  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0274262 (* 1 = 0.0274262 loss)
I1007 16:31:26.239744  4982 sgd_solver.cpp:105] Iteration 56800, lr = 0.01
I1007 16:31:34.650171  4982 solver.cpp:218] Iteration 56900 (11.89 iter/s, 8.41044s/100 iters), loss = 0.0356882
I1007 16:31:34.650202  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0356883 (* 1 = 0.0356883 loss)
I1007 16:31:34.650210  4982 sgd_solver.cpp:105] Iteration 56900, lr = 0.01
I1007 16:31:42.605703  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:31:42.938889  4982 solver.cpp:330] Iteration 57000, Testing net (#0)
I1007 16:31:44.871660  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:31:44.951474  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8969
I1007 16:31:44.951500  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.365217 (* 1 = 0.365217 loss)
I1007 16:31:45.034073  4982 solver.cpp:218] Iteration 57000 (9.63035 iter/s, 10.3838s/100 iters), loss = 0.0370482
I1007 16:31:45.034103  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0370484 (* 1 = 0.0370484 loss)
I1007 16:31:45.034112  4982 sgd_solver.cpp:105] Iteration 57000, lr = 0.01
I1007 16:31:53.412586  4982 solver.cpp:218] Iteration 57100 (11.9354 iter/s, 8.37845s/100 iters), loss = 0.0134141
I1007 16:31:53.412642  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0134143 (* 1 = 0.0134143 loss)
I1007 16:31:53.412653  4982 sgd_solver.cpp:105] Iteration 57100, lr = 0.01
I1007 16:32:01.812903  4982 solver.cpp:218] Iteration 57200 (11.9059 iter/s, 8.39919s/100 iters), loss = 0.122464
I1007 16:32:01.812975  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.122464 (* 1 = 0.122464 loss)
I1007 16:32:01.812983  4982 sgd_solver.cpp:105] Iteration 57200, lr = 0.01
I1007 16:32:10.138777  4982 solver.cpp:218] Iteration 57300 (12.0109 iter/s, 8.32578s/100 iters), loss = 0.0612356
I1007 16:32:10.138806  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0612358 (* 1 = 0.0612358 loss)
I1007 16:32:10.138811  4982 sgd_solver.cpp:105] Iteration 57300, lr = 0.01
I1007 16:32:18.474277  4982 solver.cpp:218] Iteration 57400 (11.997 iter/s, 8.33545s/100 iters), loss = 0.0559897
I1007 16:32:18.474308  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0559899 (* 1 = 0.0559899 loss)
I1007 16:32:18.474313  4982 sgd_solver.cpp:105] Iteration 57400, lr = 0.01
I1007 16:32:26.394611  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:32:26.727985  4982 solver.cpp:330] Iteration 57500, Testing net (#0)
I1007 16:32:28.659044  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:32:28.740101  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.899
I1007 16:32:28.740125  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.368969 (* 1 = 0.368969 loss)
I1007 16:32:28.823763  4982 solver.cpp:218] Iteration 57500 (9.66237 iter/s, 10.3494s/100 iters), loss = 0.0671899
I1007 16:32:28.823796  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0671901 (* 1 = 0.0671901 loss)
I1007 16:32:28.823802  4982 sgd_solver.cpp:105] Iteration 57500, lr = 0.01
I1007 16:32:37.163264  4982 solver.cpp:218] Iteration 57600 (11.9912 iter/s, 8.33944s/100 iters), loss = 0.014596
I1007 16:32:37.163386  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0145962 (* 1 = 0.0145962 loss)
I1007 16:32:37.163394  4982 sgd_solver.cpp:105] Iteration 57600, lr = 0.01
I1007 16:32:45.490802  4982 solver.cpp:218] Iteration 57700 (12.0086 iter/s, 8.32739s/100 iters), loss = 0.0653307
I1007 16:32:45.490830  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0653309 (* 1 = 0.0653309 loss)
I1007 16:32:45.490835  4982 sgd_solver.cpp:105] Iteration 57700, lr = 0.01
I1007 16:32:53.822530  4982 solver.cpp:218] Iteration 57800 (12.0024 iter/s, 8.33167s/100 iters), loss = 0.0341077
I1007 16:32:53.822559  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0341079 (* 1 = 0.0341079 loss)
I1007 16:32:53.822566  4982 sgd_solver.cpp:105] Iteration 57800, lr = 0.01
I1007 16:33:02.151617  4982 solver.cpp:218] Iteration 57900 (12.0062 iter/s, 8.32903s/100 iters), loss = 0.0325703
I1007 16:33:02.151656  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0325706 (* 1 = 0.0325706 loss)
I1007 16:33:02.151661  4982 sgd_solver.cpp:105] Iteration 57900, lr = 0.01
I1007 16:33:10.071816  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:33:10.404861  4982 solver.cpp:330] Iteration 58000, Testing net (#0)
I1007 16:33:12.338280  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:33:12.419678  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8994
I1007 16:33:12.419713  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.371662 (* 1 = 0.371662 loss)
I1007 16:33:12.502125  4982 solver.cpp:218] Iteration 58000 (9.66143 iter/s, 10.3504s/100 iters), loss = 0.0423655
I1007 16:33:12.502151  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0423657 (* 1 = 0.0423657 loss)
I1007 16:33:12.502157  4982 sgd_solver.cpp:105] Iteration 58000, lr = 0.01
I1007 16:33:20.835366  4982 solver.cpp:218] Iteration 58100 (12.0002 iter/s, 8.33319s/100 iters), loss = 0.0172697
I1007 16:33:20.835394  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0172699 (* 1 = 0.0172699 loss)
I1007 16:33:20.835400  4982 sgd_solver.cpp:105] Iteration 58100, lr = 0.01
I1007 16:33:29.172462  4982 solver.cpp:218] Iteration 58200 (11.9947 iter/s, 8.33704s/100 iters), loss = 0.0416353
I1007 16:33:29.172492  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0416356 (* 1 = 0.0416356 loss)
I1007 16:33:29.172497  4982 sgd_solver.cpp:105] Iteration 58200, lr = 0.01
I1007 16:33:37.507699  4982 solver.cpp:218] Iteration 58300 (11.9973 iter/s, 8.33518s/100 iters), loss = 0.0538595
I1007 16:33:37.507728  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0538597 (* 1 = 0.0538597 loss)
I1007 16:33:37.507735  4982 sgd_solver.cpp:105] Iteration 58300, lr = 0.01
I1007 16:33:45.844837  4982 solver.cpp:218] Iteration 58400 (11.9946 iter/s, 8.33708s/100 iters), loss = 0.0178213
I1007 16:33:45.844976  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0178215 (* 1 = 0.0178215 loss)
I1007 16:33:45.844985  4982 sgd_solver.cpp:105] Iteration 58400, lr = 0.01
I1007 16:33:53.761339  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:33:54.094651  4982 solver.cpp:330] Iteration 58500, Testing net (#0)
I1007 16:33:56.027212  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:33:56.107916  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9004
I1007 16:33:56.107954  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.367568 (* 1 = 0.367568 loss)
I1007 16:33:56.191431  4982 solver.cpp:218] Iteration 58500 (9.66517 iter/s, 10.3464s/100 iters), loss = 0.0276494
I1007 16:33:56.191458  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0276496 (* 1 = 0.0276496 loss)
I1007 16:33:56.191464  4982 sgd_solver.cpp:105] Iteration 58500, lr = 0.01
I1007 16:34:04.523180  4982 solver.cpp:218] Iteration 58600 (12.0024 iter/s, 8.33164s/100 iters), loss = 0.0704807
I1007 16:34:04.523221  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.070481 (* 1 = 0.070481 loss)
I1007 16:34:04.523227  4982 sgd_solver.cpp:105] Iteration 58600, lr = 0.01
I1007 16:34:12.851506  4982 solver.cpp:218] Iteration 58700 (12.0073 iter/s, 8.32826s/100 iters), loss = 0.0945778
I1007 16:34:12.851536  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0945781 (* 1 = 0.0945781 loss)
I1007 16:34:12.851543  4982 sgd_solver.cpp:105] Iteration 58700, lr = 0.01
I1007 16:34:21.189165  4982 solver.cpp:218] Iteration 58800 (11.9939 iter/s, 8.3376s/100 iters), loss = 0.047324
I1007 16:34:21.189292  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0473243 (* 1 = 0.0473243 loss)
I1007 16:34:21.189309  4982 sgd_solver.cpp:105] Iteration 58800, lr = 0.01
I1007 16:34:29.517897  4982 solver.cpp:218] Iteration 58900 (12.0068 iter/s, 8.32858s/100 iters), loss = 0.0994928
I1007 16:34:29.517928  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0994931 (* 1 = 0.0994931 loss)
I1007 16:34:29.517933  4982 sgd_solver.cpp:105] Iteration 58900, lr = 0.01
I1007 16:34:37.446620  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:34:37.779642  4982 solver.cpp:330] Iteration 59000, Testing net (#0)
I1007 16:34:39.710327  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:34:39.791587  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.894
I1007 16:34:39.791623  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.420618 (* 1 = 0.420618 loss)
I1007 16:34:39.874058  4982 solver.cpp:218] Iteration 59000 (9.65615 iter/s, 10.3561s/100 iters), loss = 0.0260382
I1007 16:34:39.874086  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0260384 (* 1 = 0.0260384 loss)
I1007 16:34:39.874094  4982 sgd_solver.cpp:105] Iteration 59000, lr = 0.01
I1007 16:34:48.209328  4982 solver.cpp:218] Iteration 59100 (11.9973 iter/s, 8.33522s/100 iters), loss = 0.0433701
I1007 16:34:48.209368  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0433703 (* 1 = 0.0433703 loss)
I1007 16:34:48.209374  4982 sgd_solver.cpp:105] Iteration 59100, lr = 0.01
I1007 16:34:56.553076  4982 solver.cpp:218] Iteration 59200 (11.9851 iter/s, 8.34368s/100 iters), loss = 0.0361342
I1007 16:34:56.553189  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0361344 (* 1 = 0.0361344 loss)
I1007 16:34:56.553195  4982 sgd_solver.cpp:105] Iteration 59200, lr = 0.01
I1007 16:35:04.889914  4982 solver.cpp:218] Iteration 59300 (11.9951 iter/s, 8.33671s/100 iters), loss = 0.0903958
I1007 16:35:04.889943  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0903961 (* 1 = 0.0903961 loss)
I1007 16:35:04.889950  4982 sgd_solver.cpp:105] Iteration 59300, lr = 0.01
I1007 16:35:13.231092  4982 solver.cpp:218] Iteration 59400 (11.9888 iter/s, 8.34112s/100 iters), loss = 0.0270106
I1007 16:35:13.231122  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0270108 (* 1 = 0.0270108 loss)
I1007 16:35:13.231128  4982 sgd_solver.cpp:105] Iteration 59400, lr = 0.01
I1007 16:35:21.153980  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:35:21.487758  4982 solver.cpp:330] Iteration 59500, Testing net (#0)
I1007 16:35:23.419378  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:35:23.500177  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8977
I1007 16:35:23.500213  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.385353 (* 1 = 0.385353 loss)
I1007 16:35:23.583640  4982 solver.cpp:218] Iteration 59500 (9.65952 iter/s, 10.3525s/100 iters), loss = 0.0223359
I1007 16:35:23.583665  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0223361 (* 1 = 0.0223361 loss)
I1007 16:35:23.583673  4982 sgd_solver.cpp:105] Iteration 59500, lr = 0.01
I1007 16:35:31.924450  4982 solver.cpp:218] Iteration 59600 (11.9893 iter/s, 8.34076s/100 iters), loss = 0.0321312
I1007 16:35:31.924598  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0321315 (* 1 = 0.0321315 loss)
I1007 16:35:31.924608  4982 sgd_solver.cpp:105] Iteration 59600, lr = 0.01
I1007 16:35:40.253535  4982 solver.cpp:218] Iteration 59700 (12.0064 iter/s, 8.32891s/100 iters), loss = 0.00902181
I1007 16:35:40.253566  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00902208 (* 1 = 0.00902208 loss)
I1007 16:35:40.253571  4982 sgd_solver.cpp:105] Iteration 59700, lr = 0.01
I1007 16:35:48.592420  4982 solver.cpp:218] Iteration 59800 (11.9921 iter/s, 8.33883s/100 iters), loss = 0.0141801
I1007 16:35:48.592450  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0141803 (* 1 = 0.0141803 loss)
I1007 16:35:48.592455  4982 sgd_solver.cpp:105] Iteration 59800, lr = 0.01
I1007 16:35:56.928078  4982 solver.cpp:218] Iteration 59900 (11.9967 iter/s, 8.3356s/100 iters), loss = 0.0665975
I1007 16:35:56.928107  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0665977 (* 1 = 0.0665977 loss)
I1007 16:35:56.928113  4982 sgd_solver.cpp:105] Iteration 59900, lr = 0.01
I1007 16:36:04.850217  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:36:05.184464  4982 solver.cpp:330] Iteration 60000, Testing net (#0)
I1007 16:36:07.118512  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:36:07.199666  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9002
I1007 16:36:07.199702  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.376707 (* 1 = 0.376707 loss)
I1007 16:36:07.282398  4982 solver.cpp:218] Iteration 60000 (9.65786 iter/s, 10.3543s/100 iters), loss = 0.0282834
I1007 16:36:07.282444  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0282837 (* 1 = 0.0282837 loss)
I1007 16:36:07.282462  4982 sgd_solver.cpp:105] Iteration 60000, lr = 0.01
I1007 16:36:15.612761  4982 solver.cpp:218] Iteration 60100 (12.0044 iter/s, 8.33029s/100 iters), loss = 0.043046
I1007 16:36:15.612802  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0430463 (* 1 = 0.0430463 loss)
I1007 16:36:15.612808  4982 sgd_solver.cpp:105] Iteration 60100, lr = 0.01
I1007 16:36:23.953099  4982 solver.cpp:218] Iteration 60200 (11.99 iter/s, 8.34027s/100 iters), loss = 0.0618373
I1007 16:36:23.953140  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0618376 (* 1 = 0.0618376 loss)
I1007 16:36:23.953146  4982 sgd_solver.cpp:105] Iteration 60200, lr = 0.01
I1007 16:36:32.287551  4982 solver.cpp:218] Iteration 60300 (11.9985 iter/s, 8.33438s/100 iters), loss = 0.0411915
I1007 16:36:32.287583  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0411918 (* 1 = 0.0411918 loss)
I1007 16:36:32.287590  4982 sgd_solver.cpp:105] Iteration 60300, lr = 0.01
I1007 16:36:40.626217  4982 solver.cpp:218] Iteration 60400 (11.9924 iter/s, 8.33861s/100 iters), loss = 0.0420778
I1007 16:36:40.626322  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0420781 (* 1 = 0.0420781 loss)
I1007 16:36:40.626329  4982 sgd_solver.cpp:105] Iteration 60400, lr = 0.01
I1007 16:36:48.546200  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:36:48.878773  4982 solver.cpp:330] Iteration 60500, Testing net (#0)
I1007 16:36:50.811573  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:36:50.892078  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8987
I1007 16:36:50.892104  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.396716 (* 1 = 0.396716 loss)
I1007 16:36:50.975440  4982 solver.cpp:218] Iteration 60500 (9.66269 iter/s, 10.3491s/100 iters), loss = 0.0369329
I1007 16:36:50.975466  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0369332 (* 1 = 0.0369332 loss)
I1007 16:36:50.975472  4982 sgd_solver.cpp:105] Iteration 60500, lr = 0.01
I1007 16:36:59.311522  4982 solver.cpp:218] Iteration 60600 (11.9962 iter/s, 8.33598s/100 iters), loss = 0.0317095
I1007 16:36:59.311554  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0317098 (* 1 = 0.0317098 loss)
I1007 16:36:59.311560  4982 sgd_solver.cpp:105] Iteration 60600, lr = 0.01
I1007 16:37:07.641062  4982 solver.cpp:218] Iteration 60700 (12.0056 iter/s, 8.32948s/100 iters), loss = 0.0200148
I1007 16:37:07.641104  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.020015 (* 1 = 0.020015 loss)
I1007 16:37:07.641110  4982 sgd_solver.cpp:105] Iteration 60700, lr = 0.01
I1007 16:37:15.972523  4982 solver.cpp:218] Iteration 60800 (12.0028 iter/s, 8.33139s/100 iters), loss = 0.0208828
I1007 16:37:15.972640  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.020883 (* 1 = 0.020883 loss)
I1007 16:37:15.972648  4982 sgd_solver.cpp:105] Iteration 60800, lr = 0.01
I1007 16:37:24.305421  4982 solver.cpp:218] Iteration 60900 (12.0008 iter/s, 8.33276s/100 iters), loss = 0.0649321
I1007 16:37:24.305452  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0649324 (* 1 = 0.0649324 loss)
I1007 16:37:24.305459  4982 sgd_solver.cpp:105] Iteration 60900, lr = 0.01
I1007 16:37:32.226464  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:37:32.560374  4982 solver.cpp:330] Iteration 61000, Testing net (#0)
I1007 16:37:34.492370  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:37:34.573892  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8963
I1007 16:37:34.573930  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.41542 (* 1 = 0.41542 loss)
I1007 16:37:34.656738  4982 solver.cpp:218] Iteration 61000 (9.66067 iter/s, 10.3513s/100 iters), loss = 0.052435
I1007 16:37:34.656762  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0524353 (* 1 = 0.0524353 loss)
I1007 16:37:34.656769  4982 sgd_solver.cpp:105] Iteration 61000, lr = 0.01
I1007 16:37:42.988530  4982 solver.cpp:218] Iteration 61100 (12.0023 iter/s, 8.33174s/100 iters), loss = 0.0306896
I1007 16:37:42.988571  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0306898 (* 1 = 0.0306898 loss)
I1007 16:37:42.988577  4982 sgd_solver.cpp:105] Iteration 61100, lr = 0.01
I1007 16:37:51.325780  4982 solver.cpp:218] Iteration 61200 (11.9945 iter/s, 8.33718s/100 iters), loss = 0.0747787
I1007 16:37:51.325892  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.074779 (* 1 = 0.074779 loss)
I1007 16:37:51.325899  4982 sgd_solver.cpp:105] Iteration 61200, lr = 0.01
I1007 16:37:59.662153  4982 solver.cpp:218] Iteration 61300 (11.9958 iter/s, 8.33624s/100 iters), loss = 0.0179678
I1007 16:37:59.662195  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0179681 (* 1 = 0.0179681 loss)
I1007 16:37:59.662201  4982 sgd_solver.cpp:105] Iteration 61300, lr = 0.01
I1007 16:38:07.995651  4982 solver.cpp:218] Iteration 61400 (11.9999 iter/s, 8.33343s/100 iters), loss = 0.0149497
I1007 16:38:07.995692  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.01495 (* 1 = 0.01495 loss)
I1007 16:38:07.995697  4982 sgd_solver.cpp:105] Iteration 61400, lr = 0.01
I1007 16:38:15.920910  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:38:16.256155  4982 solver.cpp:330] Iteration 61500, Testing net (#0)
I1007 16:38:18.187409  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:38:18.268095  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8979
I1007 16:38:18.268131  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.398514 (* 1 = 0.398514 loss)
I1007 16:38:18.351676  4982 solver.cpp:218] Iteration 61500 (9.65628 iter/s, 10.356s/100 iters), loss = 0.0387214
I1007 16:38:18.351704  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0387217 (* 1 = 0.0387217 loss)
I1007 16:38:18.351711  4982 sgd_solver.cpp:105] Iteration 61500, lr = 0.01
I1007 16:38:26.698221  4982 solver.cpp:218] Iteration 61600 (11.9811 iter/s, 8.34649s/100 iters), loss = 0.0152918
I1007 16:38:26.698355  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0152921 (* 1 = 0.0152921 loss)
I1007 16:38:26.698374  4982 sgd_solver.cpp:105] Iteration 61600, lr = 0.01
I1007 16:38:35.030428  4982 solver.cpp:218] Iteration 61700 (12.0018 iter/s, 8.33206s/100 iters), loss = 0.0337912
I1007 16:38:35.030457  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0337915 (* 1 = 0.0337915 loss)
I1007 16:38:35.030463  4982 sgd_solver.cpp:105] Iteration 61700, lr = 0.01
I1007 16:38:43.375985  4982 solver.cpp:218] Iteration 61800 (11.9825 iter/s, 8.3455s/100 iters), loss = 0.0222865
I1007 16:38:43.376025  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0222868 (* 1 = 0.0222868 loss)
I1007 16:38:43.376031  4982 sgd_solver.cpp:105] Iteration 61800, lr = 0.01
I1007 16:38:51.717008  4982 solver.cpp:218] Iteration 61900 (11.989 iter/s, 8.34095s/100 iters), loss = 0.0219089
I1007 16:38:51.717049  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0219092 (* 1 = 0.0219092 loss)
I1007 16:38:51.717056  4982 sgd_solver.cpp:105] Iteration 61900, lr = 0.01
I1007 16:38:59.650614  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:38:59.985469  4982 solver.cpp:330] Iteration 62000, Testing net (#0)
I1007 16:39:01.919081  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:39:02.000046  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9037
I1007 16:39:02.000092  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.376356 (* 1 = 0.376356 loss)
I1007 16:39:02.083434  4982 solver.cpp:218] Iteration 62000 (9.64659 iter/s, 10.3664s/100 iters), loss = 0.0170479
I1007 16:39:02.083462  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0170482 (* 1 = 0.0170482 loss)
I1007 16:39:02.083469  4982 sgd_solver.cpp:105] Iteration 62000, lr = 0.01
I1007 16:39:10.422710  4982 solver.cpp:218] Iteration 62100 (11.9915 iter/s, 8.33922s/100 iters), loss = 0.0716639
I1007 16:39:10.422741  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0716642 (* 1 = 0.0716642 loss)
I1007 16:39:10.422747  4982 sgd_solver.cpp:105] Iteration 62100, lr = 0.01
I1007 16:39:18.768577  4982 solver.cpp:218] Iteration 62200 (11.9821 iter/s, 8.34581s/100 iters), loss = 0.0255607
I1007 16:39:18.768618  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.025561 (* 1 = 0.025561 loss)
I1007 16:39:18.768625  4982 sgd_solver.cpp:105] Iteration 62200, lr = 0.01
I1007 16:39:27.112038  4982 solver.cpp:218] Iteration 62300 (11.9855 iter/s, 8.34339s/100 iters), loss = 0.0275767
I1007 16:39:27.112068  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.027577 (* 1 = 0.027577 loss)
I1007 16:39:27.112073  4982 sgd_solver.cpp:105] Iteration 62300, lr = 0.01
I1007 16:39:35.445451  4982 solver.cpp:218] Iteration 62400 (12 iter/s, 8.33335s/100 iters), loss = 0.0325745
I1007 16:39:35.445592  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0325749 (* 1 = 0.0325749 loss)
I1007 16:39:35.445600  4982 sgd_solver.cpp:105] Iteration 62400, lr = 0.01
I1007 16:39:43.369144  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:39:43.701756  4982 solver.cpp:330] Iteration 62500, Testing net (#0)
I1007 16:39:45.634433  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:39:45.715196  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8833
I1007 16:39:45.715232  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.451408 (* 1 = 0.451408 loss)
I1007 16:39:45.798852  4982 solver.cpp:218] Iteration 62500 (9.65882 iter/s, 10.3532s/100 iters), loss = 0.0186512
I1007 16:39:45.798879  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0186515 (* 1 = 0.0186515 loss)
I1007 16:39:45.798887  4982 sgd_solver.cpp:105] Iteration 62500, lr = 0.01
I1007 16:39:54.132416  4982 solver.cpp:218] Iteration 62600 (11.9997 iter/s, 8.33351s/100 iters), loss = 0.040991
I1007 16:39:54.132446  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0409913 (* 1 = 0.0409913 loss)
I1007 16:39:54.132452  4982 sgd_solver.cpp:105] Iteration 62600, lr = 0.01
I1007 16:40:02.463268  4982 solver.cpp:218] Iteration 62700 (12.0037 iter/s, 8.3308s/100 iters), loss = 0.0280258
I1007 16:40:02.463299  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0280261 (* 1 = 0.0280261 loss)
I1007 16:40:02.463304  4982 sgd_solver.cpp:105] Iteration 62700, lr = 0.01
I1007 16:40:10.796842  4982 solver.cpp:218] Iteration 62800 (11.9997 iter/s, 8.33352s/100 iters), loss = 0.0828208
I1007 16:40:10.796965  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0828212 (* 1 = 0.0828212 loss)
I1007 16:40:10.796982  4982 sgd_solver.cpp:105] Iteration 62800, lr = 0.01
I1007 16:40:19.122369  4982 solver.cpp:218] Iteration 62900 (12.0115 iter/s, 8.32538s/100 iters), loss = 0.0283727
I1007 16:40:19.122400  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0283731 (* 1 = 0.0283731 loss)
I1007 16:40:19.122416  4982 sgd_solver.cpp:105] Iteration 62900, lr = 0.01
I1007 16:40:27.044282  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:40:27.378454  4982 solver.cpp:330] Iteration 63000, Testing net (#0)
I1007 16:40:29.310261  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:40:29.391641  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8969
I1007 16:40:29.391679  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.385809 (* 1 = 0.385809 loss)
I1007 16:40:29.474385  4982 solver.cpp:218] Iteration 63000 (9.66001 iter/s, 10.352s/100 iters), loss = 0.0337037
I1007 16:40:29.474411  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0337041 (* 1 = 0.0337041 loss)
I1007 16:40:29.474418  4982 sgd_solver.cpp:105] Iteration 63000, lr = 0.01
I1007 16:40:37.811210  4982 solver.cpp:218] Iteration 63100 (11.995 iter/s, 8.33677s/100 iters), loss = 0.0345763
I1007 16:40:37.811250  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0345768 (* 1 = 0.0345768 loss)
I1007 16:40:37.811256  4982 sgd_solver.cpp:105] Iteration 63100, lr = 0.01
I1007 16:40:46.159373  4982 solver.cpp:218] Iteration 63200 (11.9788 iter/s, 8.3481s/100 iters), loss = 0.0231407
I1007 16:40:46.159515  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0231411 (* 1 = 0.0231411 loss)
I1007 16:40:46.159523  4982 sgd_solver.cpp:105] Iteration 63200, lr = 0.01
I1007 16:40:54.499338  4982 solver.cpp:218] Iteration 63300 (11.9907 iter/s, 8.3398s/100 iters), loss = 0.0138028
I1007 16:40:54.499368  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0138032 (* 1 = 0.0138032 loss)
I1007 16:40:54.499373  4982 sgd_solver.cpp:105] Iteration 63300, lr = 0.01
I1007 16:41:02.842428  4982 solver.cpp:218] Iteration 63400 (11.986 iter/s, 8.34303s/100 iters), loss = 0.0350574
I1007 16:41:02.842458  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0350578 (* 1 = 0.0350578 loss)
I1007 16:41:02.842463  4982 sgd_solver.cpp:105] Iteration 63400, lr = 0.01
I1007 16:41:10.769332  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:41:11.102421  4982 solver.cpp:330] Iteration 63500, Testing net (#0)
I1007 16:41:13.036047  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:41:13.116533  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.897
I1007 16:41:13.116556  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.382913 (* 1 = 0.382913 loss)
I1007 16:41:13.200538  4982 solver.cpp:218] Iteration 63500 (9.65433 iter/s, 10.358s/100 iters), loss = 0.0427004
I1007 16:41:13.200565  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0427008 (* 1 = 0.0427008 loss)
I1007 16:41:13.200572  4982 sgd_solver.cpp:105] Iteration 63500, lr = 0.01
I1007 16:41:21.541105  4982 solver.cpp:218] Iteration 63600 (11.9897 iter/s, 8.34051s/100 iters), loss = 0.0219737
I1007 16:41:21.541177  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0219741 (* 1 = 0.0219741 loss)
I1007 16:41:21.541182  4982 sgd_solver.cpp:105] Iteration 63600, lr = 0.01
I1007 16:41:29.876164  4982 solver.cpp:218] Iteration 63700 (11.9977 iter/s, 8.33496s/100 iters), loss = 0.0617449
I1007 16:41:29.876205  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0617453 (* 1 = 0.0617453 loss)
I1007 16:41:29.876210  4982 sgd_solver.cpp:105] Iteration 63700, lr = 0.01
I1007 16:41:38.219471  4982 solver.cpp:218] Iteration 63800 (11.9858 iter/s, 8.34324s/100 iters), loss = 0.0142531
I1007 16:41:38.219511  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0142535 (* 1 = 0.0142535 loss)
I1007 16:41:38.219518  4982 sgd_solver.cpp:105] Iteration 63800, lr = 0.01
I1007 16:41:46.552799  4982 solver.cpp:218] Iteration 63900 (12.0001 iter/s, 8.33326s/100 iters), loss = 0.0129448
I1007 16:41:46.552839  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0129452 (* 1 = 0.0129452 loss)
I1007 16:41:46.552845  4982 sgd_solver.cpp:105] Iteration 63900, lr = 0.01
I1007 16:41:54.478715  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:41:54.812099  4982 solver.cpp:330] Iteration 64000, Testing net (#0)
I1007 16:41:56.746246  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:41:56.827118  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8956
I1007 16:41:56.827154  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.378474 (* 1 = 0.378474 loss)
I1007 16:41:56.909579  4982 solver.cpp:218] Iteration 64000 (9.65558 iter/s, 10.3567s/100 iters), loss = 0.0117639
I1007 16:41:56.909607  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0117643 (* 1 = 0.0117643 loss)
I1007 16:41:56.909613  4982 sgd_solver.cpp:105] Iteration 64000, lr = 0.01
I1007 16:42:05.242301  4982 solver.cpp:218] Iteration 64100 (12.001 iter/s, 8.33267s/100 iters), loss = 0.0476892
I1007 16:42:05.242332  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0476896 (* 1 = 0.0476896 loss)
I1007 16:42:05.242337  4982 sgd_solver.cpp:105] Iteration 64100, lr = 0.01
I1007 16:42:13.585358  4982 solver.cpp:218] Iteration 64200 (11.9861 iter/s, 8.343s/100 iters), loss = 0.0725661
I1007 16:42:13.585399  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0725665 (* 1 = 0.0725665 loss)
I1007 16:42:13.585405  4982 sgd_solver.cpp:105] Iteration 64200, lr = 0.01
I1007 16:42:21.923449  4982 solver.cpp:218] Iteration 64300 (11.9933 iter/s, 8.33802s/100 iters), loss = 0.0210381
I1007 16:42:21.923480  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0210385 (* 1 = 0.0210385 loss)
I1007 16:42:21.923485  4982 sgd_solver.cpp:105] Iteration 64300, lr = 0.01
I1007 16:42:30.268935  4982 solver.cpp:218] Iteration 64400 (11.9826 iter/s, 8.34543s/100 iters), loss = 0.0310372
I1007 16:42:30.269039  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0310376 (* 1 = 0.0310376 loss)
I1007 16:42:30.269057  4982 sgd_solver.cpp:105] Iteration 64400, lr = 0.01
I1007 16:42:38.196933  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:42:38.531355  4982 solver.cpp:330] Iteration 64500, Testing net (#0)
I1007 16:42:40.464087  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:42:40.544534  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8884
I1007 16:42:40.544571  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.420755 (* 1 = 0.420755 loss)
I1007 16:42:40.627853  4982 solver.cpp:218] Iteration 64500 (9.65364 iter/s, 10.3588s/100 iters), loss = 0.0304223
I1007 16:42:40.627881  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0304226 (* 1 = 0.0304226 loss)
I1007 16:42:40.627887  4982 sgd_solver.cpp:105] Iteration 64500, lr = 0.01
I1007 16:42:48.966645  4982 solver.cpp:218] Iteration 64600 (11.9922 iter/s, 8.33874s/100 iters), loss = 0.0157441
I1007 16:42:48.966686  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0157445 (* 1 = 0.0157445 loss)
I1007 16:42:48.966691  4982 sgd_solver.cpp:105] Iteration 64600, lr = 0.01
I1007 16:42:57.296954  4982 solver.cpp:218] Iteration 64700 (12.0045 iter/s, 8.33024s/100 iters), loss = 0.0532885
I1007 16:42:57.296986  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0532888 (* 1 = 0.0532888 loss)
I1007 16:42:57.296993  4982 sgd_solver.cpp:105] Iteration 64700, lr = 0.01
I1007 16:43:05.635973  4982 solver.cpp:218] Iteration 64800 (11.9919 iter/s, 8.33896s/100 iters), loss = 0.0231208
I1007 16:43:05.636121  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0231211 (* 1 = 0.0231211 loss)
I1007 16:43:05.636128  4982 sgd_solver.cpp:105] Iteration 64800, lr = 0.01
I1007 16:43:13.969843  4982 solver.cpp:218] Iteration 64900 (11.9995 iter/s, 8.3337s/100 iters), loss = 0.0813373
I1007 16:43:13.969873  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0813376 (* 1 = 0.0813376 loss)
I1007 16:43:13.969879  4982 sgd_solver.cpp:105] Iteration 64900, lr = 0.01
I1007 16:43:21.893741  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:43:22.227193  4982 solver.cpp:330] Iteration 65000, Testing net (#0)
I1007 16:43:24.159032  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:43:24.240484  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8968
I1007 16:43:24.240520  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.405461 (* 1 = 0.405461 loss)
I1007 16:43:24.323454  4982 solver.cpp:218] Iteration 65000 (9.65852 iter/s, 10.3535s/100 iters), loss = 0.0141728
I1007 16:43:24.323480  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0141731 (* 1 = 0.0141731 loss)
I1007 16:43:24.323487  4982 sgd_solver.cpp:105] Iteration 65000, lr = 0.01
I1007 16:43:32.656275  4982 solver.cpp:218] Iteration 65100 (12.0008 iter/s, 8.33277s/100 iters), loss = 0.0155901
I1007 16:43:32.656313  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0155904 (* 1 = 0.0155904 loss)
I1007 16:43:32.656319  4982 sgd_solver.cpp:105] Iteration 65100, lr = 0.01
I1007 16:43:40.991858  4982 solver.cpp:218] Iteration 65200 (11.9969 iter/s, 8.33552s/100 iters), loss = 0.0758647
I1007 16:43:40.991961  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.075865 (* 1 = 0.075865 loss)
I1007 16:43:40.991977  4982 sgd_solver.cpp:105] Iteration 65200, lr = 0.01
I1007 16:43:49.327301  4982 solver.cpp:218] Iteration 65300 (11.9971 iter/s, 8.33531s/100 iters), loss = 0.0431547
I1007 16:43:49.327342  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0431551 (* 1 = 0.0431551 loss)
I1007 16:43:49.327347  4982 sgd_solver.cpp:105] Iteration 65300, lr = 0.01
I1007 16:43:57.667212  4982 solver.cpp:218] Iteration 65400 (11.9906 iter/s, 8.33984s/100 iters), loss = 0.0345018
I1007 16:43:57.667243  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0345022 (* 1 = 0.0345022 loss)
I1007 16:43:57.667248  4982 sgd_solver.cpp:105] Iteration 65400, lr = 0.01
I1007 16:44:05.587870  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:44:05.921488  4982 solver.cpp:330] Iteration 65500, Testing net (#0)
I1007 16:44:07.854480  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:44:07.935580  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8893
I1007 16:44:07.935616  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.457211 (* 1 = 0.457211 loss)
I1007 16:44:08.019237  4982 solver.cpp:218] Iteration 65500 (9.66 iter/s, 10.352s/100 iters), loss = 0.0587068
I1007 16:44:08.019265  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0587072 (* 1 = 0.0587072 loss)
I1007 16:44:08.019271  4982 sgd_solver.cpp:105] Iteration 65500, lr = 0.01
I1007 16:44:16.356091  4982 solver.cpp:218] Iteration 65600 (11.995 iter/s, 8.3368s/100 iters), loss = 0.0559488
I1007 16:44:16.356220  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0559491 (* 1 = 0.0559491 loss)
I1007 16:44:16.356227  4982 sgd_solver.cpp:105] Iteration 65600, lr = 0.01
I1007 16:44:24.686132  4982 solver.cpp:218] Iteration 65700 (12.005 iter/s, 8.32989s/100 iters), loss = 0.0368934
I1007 16:44:24.686172  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0368938 (* 1 = 0.0368938 loss)
I1007 16:44:24.686178  4982 sgd_solver.cpp:105] Iteration 65700, lr = 0.01
I1007 16:44:33.023455  4982 solver.cpp:218] Iteration 65800 (11.9944 iter/s, 8.33726s/100 iters), loss = 0.0289034
I1007 16:44:33.023484  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0289037 (* 1 = 0.0289037 loss)
I1007 16:44:33.023489  4982 sgd_solver.cpp:105] Iteration 65800, lr = 0.01
I1007 16:44:41.351397  4982 solver.cpp:218] Iteration 65900 (12.0078 iter/s, 8.32789s/100 iters), loss = 0.0319995
I1007 16:44:41.351428  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0319998 (* 1 = 0.0319998 loss)
I1007 16:44:41.351433  4982 sgd_solver.cpp:105] Iteration 65900, lr = 0.01
I1007 16:44:49.275149  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:44:49.607874  4982 solver.cpp:330] Iteration 66000, Testing net (#0)
I1007 16:44:51.540267  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:44:51.623231  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8951
I1007 16:44:51.623267  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.417318 (* 1 = 0.417318 loss)
I1007 16:44:51.707379  4982 solver.cpp:218] Iteration 66000 (9.65631 iter/s, 10.3559s/100 iters), loss = 0.0207585
I1007 16:44:51.707413  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0207588 (* 1 = 0.0207588 loss)
I1007 16:44:51.707420  4982 sgd_solver.cpp:105] Iteration 66000, lr = 0.01
I1007 16:45:00.044311  4982 solver.cpp:218] Iteration 66100 (11.9949 iter/s, 8.33687s/100 iters), loss = 0.0133351
I1007 16:45:00.044351  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0133354 (* 1 = 0.0133354 loss)
I1007 16:45:00.044358  4982 sgd_solver.cpp:105] Iteration 66100, lr = 0.01
I1007 16:45:08.390650  4982 solver.cpp:218] Iteration 66200 (11.9814 iter/s, 8.34627s/100 iters), loss = 0.00839445
I1007 16:45:08.390692  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00839477 (* 1 = 0.00839477 loss)
I1007 16:45:08.390698  4982 sgd_solver.cpp:105] Iteration 66200, lr = 0.01
I1007 16:45:16.733034  4982 solver.cpp:218] Iteration 66300 (11.9871 iter/s, 8.34232s/100 iters), loss = 0.013839
I1007 16:45:16.733067  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0138393 (* 1 = 0.0138393 loss)
I1007 16:45:16.733073  4982 sgd_solver.cpp:105] Iteration 66300, lr = 0.01
I1007 16:45:25.073788  4982 solver.cpp:218] Iteration 66400 (11.9894 iter/s, 8.3407s/100 iters), loss = 0.0612455
I1007 16:45:25.073861  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0612458 (* 1 = 0.0612458 loss)
I1007 16:45:25.073879  4982 sgd_solver.cpp:105] Iteration 66400, lr = 0.01
I1007 16:45:33.000550  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:45:33.334285  4982 solver.cpp:330] Iteration 66500, Testing net (#0)
I1007 16:45:35.267406  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:45:35.348595  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8989
I1007 16:45:35.348633  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.404289 (* 1 = 0.404289 loss)
I1007 16:45:35.432808  4982 solver.cpp:218] Iteration 66500 (9.65352 iter/s, 10.3589s/100 iters), loss = 0.0381511
I1007 16:45:35.432834  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0381515 (* 1 = 0.0381515 loss)
I1007 16:45:35.432840  4982 sgd_solver.cpp:105] Iteration 66500, lr = 0.01
I1007 16:45:43.776084  4982 solver.cpp:218] Iteration 66600 (11.9858 iter/s, 8.34322s/100 iters), loss = 0.0309023
I1007 16:45:43.776124  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0309026 (* 1 = 0.0309026 loss)
I1007 16:45:43.776130  4982 sgd_solver.cpp:105] Iteration 66600, lr = 0.01
I1007 16:45:52.106158  4982 solver.cpp:218] Iteration 66700 (12.0048 iter/s, 8.33001s/100 iters), loss = 0.034615
I1007 16:45:52.106189  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0346154 (* 1 = 0.0346154 loss)
I1007 16:45:52.106194  4982 sgd_solver.cpp:105] Iteration 66700, lr = 0.01
I1007 16:46:00.447109  4982 solver.cpp:218] Iteration 66800 (11.9891 iter/s, 8.34089s/100 iters), loss = 0.0327497
I1007 16:46:00.447288  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.03275 (* 1 = 0.03275 loss)
I1007 16:46:00.447296  4982 sgd_solver.cpp:105] Iteration 66800, lr = 0.01
I1007 16:46:08.779750  4982 solver.cpp:218] Iteration 66900 (12.0013 iter/s, 8.33245s/100 iters), loss = 0.00887212
I1007 16:46:08.779780  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00887241 (* 1 = 0.00887241 loss)
I1007 16:46:08.779785  4982 sgd_solver.cpp:105] Iteration 66900, lr = 0.01
I1007 16:46:16.704766  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:46:17.038779  4982 solver.cpp:330] Iteration 67000, Testing net (#0)
I1007 16:46:18.971324  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:46:19.052752  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8955
I1007 16:46:19.052788  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.410859 (* 1 = 0.410859 loss)
I1007 16:46:19.135238  4982 solver.cpp:218] Iteration 67000 (9.65677 iter/s, 10.3554s/100 iters), loss = 0.00639338
I1007 16:46:19.135265  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00639369 (* 1 = 0.00639369 loss)
I1007 16:46:19.135272  4982 sgd_solver.cpp:105] Iteration 67000, lr = 0.01
I1007 16:46:27.468693  4982 solver.cpp:218] Iteration 67100 (11.9999 iter/s, 8.3334s/100 iters), loss = 0.018203
I1007 16:46:27.468724  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0182034 (* 1 = 0.0182034 loss)
I1007 16:46:27.468729  4982 sgd_solver.cpp:105] Iteration 67100, lr = 0.01
I1007 16:46:35.811709  4982 solver.cpp:218] Iteration 67200 (11.9862 iter/s, 8.34296s/100 iters), loss = 0.0354599
I1007 16:46:35.811847  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0354602 (* 1 = 0.0354602 loss)
I1007 16:46:35.811854  4982 sgd_solver.cpp:105] Iteration 67200, lr = 0.01
I1007 16:46:44.147820  4982 solver.cpp:218] Iteration 67300 (11.9962 iter/s, 8.33595s/100 iters), loss = 0.0182688
I1007 16:46:44.147861  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0182691 (* 1 = 0.0182691 loss)
I1007 16:46:44.147866  4982 sgd_solver.cpp:105] Iteration 67300, lr = 0.01
I1007 16:46:52.491960  4982 solver.cpp:218] Iteration 67400 (11.9846 iter/s, 8.34407s/100 iters), loss = 0.0139356
I1007 16:46:52.491991  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0139359 (* 1 = 0.0139359 loss)
I1007 16:46:52.491997  4982 sgd_solver.cpp:105] Iteration 67400, lr = 0.01
I1007 16:47:00.418596  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:47:00.752868  4982 solver.cpp:330] Iteration 67500, Testing net (#0)
I1007 16:47:02.687484  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:47:02.768015  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8877
I1007 16:47:02.768051  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.455158 (* 1 = 0.455158 loss)
I1007 16:47:02.851485  4982 solver.cpp:218] Iteration 67500 (9.65301 iter/s, 10.3595s/100 iters), loss = 0.0269036
I1007 16:47:02.851514  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0269039 (* 1 = 0.0269039 loss)
I1007 16:47:02.851522  4982 sgd_solver.cpp:105] Iteration 67500, lr = 0.01
I1007 16:47:11.196604  4982 solver.cpp:218] Iteration 67600 (11.9831 iter/s, 8.34506s/100 iters), loss = 0.0167316
I1007 16:47:11.196684  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0167319 (* 1 = 0.0167319 loss)
I1007 16:47:11.196701  4982 sgd_solver.cpp:105] Iteration 67600, lr = 0.01
I1007 16:47:19.535995  4982 solver.cpp:218] Iteration 67700 (11.9914 iter/s, 8.33928s/100 iters), loss = 0.0204117
I1007 16:47:19.536025  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.020412 (* 1 = 0.020412 loss)
I1007 16:47:19.536031  4982 sgd_solver.cpp:105] Iteration 67700, lr = 0.01
I1007 16:47:27.878520  4982 solver.cpp:218] Iteration 67800 (11.9869 iter/s, 8.34247s/100 iters), loss = 0.0434346
I1007 16:47:27.878551  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0434349 (* 1 = 0.0434349 loss)
I1007 16:47:27.878556  4982 sgd_solver.cpp:105] Iteration 67800, lr = 0.01
I1007 16:47:36.211658  4982 solver.cpp:218] Iteration 67900 (12.0004 iter/s, 8.33308s/100 iters), loss = 0.0362675
I1007 16:47:36.211699  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0362678 (* 1 = 0.0362678 loss)
I1007 16:47:36.211704  4982 sgd_solver.cpp:105] Iteration 67900, lr = 0.01
I1007 16:47:44.131412  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:47:44.465433  4982 solver.cpp:330] Iteration 68000, Testing net (#0)
I1007 16:47:46.397920  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:47:46.478557  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9018
I1007 16:47:46.478592  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.400077 (* 1 = 0.400077 loss)
I1007 16:47:46.561513  4982 solver.cpp:218] Iteration 68000 (9.66204 iter/s, 10.3498s/100 iters), loss = 0.0546942
I1007 16:47:46.561539  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0546945 (* 1 = 0.0546945 loss)
I1007 16:47:46.561545  4982 sgd_solver.cpp:105] Iteration 68000, lr = 0.01
I1007 16:47:54.897444  4982 solver.cpp:218] Iteration 68100 (11.9963 iter/s, 8.33587s/100 iters), loss = 0.0650967
I1007 16:47:54.897475  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.065097 (* 1 = 0.065097 loss)
I1007 16:47:54.897491  4982 sgd_solver.cpp:105] Iteration 68100, lr = 0.01
I1007 16:48:03.239470  4982 solver.cpp:218] Iteration 68200 (11.9876 iter/s, 8.34197s/100 iters), loss = 0.032601
I1007 16:48:03.239500  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0326013 (* 1 = 0.0326013 loss)
I1007 16:48:03.239506  4982 sgd_solver.cpp:105] Iteration 68200, lr = 0.01
I1007 16:48:11.571892  4982 solver.cpp:218] Iteration 68300 (12.0014 iter/s, 8.33237s/100 iters), loss = 0.0589205
I1007 16:48:11.571933  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0589208 (* 1 = 0.0589208 loss)
I1007 16:48:11.571938  4982 sgd_solver.cpp:105] Iteration 68300, lr = 0.01
I1007 16:48:19.913583  4982 solver.cpp:218] Iteration 68400 (11.9881 iter/s, 8.34162s/100 iters), loss = 0.0348228
I1007 16:48:19.913697  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0348231 (* 1 = 0.0348231 loss)
I1007 16:48:19.913712  4982 sgd_solver.cpp:105] Iteration 68400, lr = 0.01
I1007 16:48:27.840235  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:48:28.175129  4982 solver.cpp:330] Iteration 68500, Testing net (#0)
I1007 16:48:30.106055  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:48:30.186892  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9015
I1007 16:48:30.186928  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.382818 (* 1 = 0.382818 loss)
I1007 16:48:30.270752  4982 solver.cpp:218] Iteration 68500 (9.65527 iter/s, 10.357s/100 iters), loss = 0.0213156
I1007 16:48:30.270787  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0213158 (* 1 = 0.0213158 loss)
I1007 16:48:30.270794  4982 sgd_solver.cpp:105] Iteration 68500, lr = 0.01
I1007 16:48:38.610915  4982 solver.cpp:218] Iteration 68600 (11.9903 iter/s, 8.3401s/100 iters), loss = 0.0184556
I1007 16:48:38.610956  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0184559 (* 1 = 0.0184559 loss)
I1007 16:48:38.610962  4982 sgd_solver.cpp:105] Iteration 68600, lr = 0.01
I1007 16:48:46.941035  4982 solver.cpp:218] Iteration 68700 (12.0047 iter/s, 8.33005s/100 iters), loss = 0.0318258
I1007 16:48:46.941064  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0318261 (* 1 = 0.0318261 loss)
I1007 16:48:46.941071  4982 sgd_solver.cpp:105] Iteration 68700, lr = 0.01
I1007 16:48:55.275980  4982 solver.cpp:218] Iteration 68800 (11.9978 iter/s, 8.33489s/100 iters), loss = 0.0130158
I1007 16:48:55.276134  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.013016 (* 1 = 0.013016 loss)
I1007 16:48:55.276154  4982 sgd_solver.cpp:105] Iteration 68800, lr = 0.01
I1007 16:49:03.609068  4982 solver.cpp:218] Iteration 68900 (12.0006 iter/s, 8.33291s/100 iters), loss = 0.0152097
I1007 16:49:03.609109  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.01521 (* 1 = 0.01521 loss)
I1007 16:49:03.609114  4982 sgd_solver.cpp:105] Iteration 68900, lr = 0.01
I1007 16:49:11.532501  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:49:11.866152  4982 solver.cpp:330] Iteration 69000, Testing net (#0)
I1007 16:49:13.798985  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:49:13.879957  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8892
I1007 16:49:13.879992  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.431407 (* 1 = 0.431407 loss)
I1007 16:49:13.962520  4982 solver.cpp:218] Iteration 69000 (9.65868 iter/s, 10.3534s/100 iters), loss = 0.0219312
I1007 16:49:13.962545  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0219314 (* 1 = 0.0219314 loss)
I1007 16:49:13.962551  4982 sgd_solver.cpp:105] Iteration 69000, lr = 0.01
I1007 16:49:22.298730  4982 solver.cpp:218] Iteration 69100 (11.9959 iter/s, 8.33616s/100 iters), loss = 0.0293792
I1007 16:49:22.298761  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0293794 (* 1 = 0.0293794 loss)
I1007 16:49:22.298768  4982 sgd_solver.cpp:105] Iteration 69100, lr = 0.01
I1007 16:49:30.643651  4982 solver.cpp:218] Iteration 69200 (11.9834 iter/s, 8.34486s/100 iters), loss = 0.0384565
I1007 16:49:30.643762  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0384567 (* 1 = 0.0384567 loss)
I1007 16:49:30.643769  4982 sgd_solver.cpp:105] Iteration 69200, lr = 0.01
I1007 16:49:38.983551  4982 solver.cpp:218] Iteration 69300 (11.9907 iter/s, 8.33976s/100 iters), loss = 0.0376551
I1007 16:49:38.983592  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0376553 (* 1 = 0.0376553 loss)
I1007 16:49:38.983598  4982 sgd_solver.cpp:105] Iteration 69300, lr = 0.01
I1007 16:49:47.325966  4982 solver.cpp:218] Iteration 69400 (11.987 iter/s, 8.34235s/100 iters), loss = 0.00697006
I1007 16:49:47.325999  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0069703 (* 1 = 0.0069703 loss)
I1007 16:49:47.326004  4982 sgd_solver.cpp:105] Iteration 69400, lr = 0.01
I1007 16:49:55.246232  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:49:55.579882  4982 solver.cpp:330] Iteration 69500, Testing net (#0)
I1007 16:49:57.513886  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:49:57.594301  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8914
I1007 16:49:57.594338  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.461762 (* 1 = 0.461762 loss)
I1007 16:49:57.678113  4982 solver.cpp:218] Iteration 69500 (9.65989 iter/s, 10.3521s/100 iters), loss = 0.0230911
I1007 16:49:57.678141  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0230914 (* 1 = 0.0230914 loss)
I1007 16:49:57.678148  4982 sgd_solver.cpp:105] Iteration 69500, lr = 0.01
I1007 16:50:06.015120  4982 solver.cpp:218] Iteration 69600 (11.9948 iter/s, 8.33695s/100 iters), loss = 0.0303494
I1007 16:50:06.015224  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0303496 (* 1 = 0.0303496 loss)
I1007 16:50:06.015244  4982 sgd_solver.cpp:105] Iteration 69600, lr = 0.01
I1007 16:50:14.345563  4982 solver.cpp:218] Iteration 69700 (12.0043 iter/s, 8.33032s/100 iters), loss = 0.0640467
I1007 16:50:14.345605  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0640469 (* 1 = 0.0640469 loss)
I1007 16:50:14.345612  4982 sgd_solver.cpp:105] Iteration 69700, lr = 0.01
I1007 16:50:22.684226  4982 solver.cpp:218] Iteration 69800 (11.9924 iter/s, 8.33859s/100 iters), loss = 0.0236055
I1007 16:50:22.684268  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0236058 (* 1 = 0.0236058 loss)
I1007 16:50:22.684274  4982 sgd_solver.cpp:105] Iteration 69800, lr = 0.01
I1007 16:50:31.022509  4982 solver.cpp:218] Iteration 69900 (11.993 iter/s, 8.33821s/100 iters), loss = 0.0581733
I1007 16:50:31.022550  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0581735 (* 1 = 0.0581735 loss)
I1007 16:50:31.022557  4982 sgd_solver.cpp:105] Iteration 69900, lr = 0.01
I1007 16:50:38.951011  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:50:39.285604  4982 solver.cpp:330] Iteration 70000, Testing net (#0)
I1007 16:50:41.216958  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:50:41.297889  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8931
I1007 16:50:41.297916  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.441457 (* 1 = 0.441457 loss)
I1007 16:50:41.380591  4982 solver.cpp:218] Iteration 70000 (9.65437 iter/s, 10.358s/100 iters), loss = 0.0245287
I1007 16:50:41.380619  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.024529 (* 1 = 0.024529 loss)
I1007 16:50:41.380626  4982 sgd_solver.cpp:105] Iteration 70000, lr = 0.01
I1007 16:50:49.712683  4982 solver.cpp:218] Iteration 70100 (12.0019 iter/s, 8.33204s/100 iters), loss = 0.00554977
I1007 16:50:49.712724  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00555002 (* 1 = 0.00555002 loss)
I1007 16:50:49.712731  4982 sgd_solver.cpp:105] Iteration 70100, lr = 0.01
I1007 16:50:58.049841  4982 solver.cpp:218] Iteration 70200 (11.9946 iter/s, 8.33709s/100 iters), loss = 0.013656
I1007 16:50:58.049882  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0136562 (* 1 = 0.0136562 loss)
I1007 16:50:58.049890  4982 sgd_solver.cpp:105] Iteration 70200, lr = 0.01
I1007 16:51:06.382676  4982 solver.cpp:218] Iteration 70300 (12.0008 iter/s, 8.33277s/100 iters), loss = 0.0400097
I1007 16:51:06.382719  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.04001 (* 1 = 0.04001 loss)
I1007 16:51:06.382725  4982 sgd_solver.cpp:105] Iteration 70300, lr = 0.01
I1007 16:51:14.719954  4982 solver.cpp:218] Iteration 70400 (11.9944 iter/s, 8.33721s/100 iters), loss = 0.0240123
I1007 16:51:14.720062  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0240126 (* 1 = 0.0240126 loss)
I1007 16:51:14.720068  4982 sgd_solver.cpp:105] Iteration 70400, lr = 0.01
I1007 16:51:22.638181  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:51:22.972285  4982 solver.cpp:330] Iteration 70500, Testing net (#0)
I1007 16:51:24.904667  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:51:24.985666  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8889
I1007 16:51:24.985703  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.444629 (* 1 = 0.444629 loss)
I1007 16:51:25.069627  4982 solver.cpp:218] Iteration 70500 (9.66227 iter/s, 10.3495s/100 iters), loss = 0.0136237
I1007 16:51:25.069651  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.013624 (* 1 = 0.013624 loss)
I1007 16:51:25.069658  4982 sgd_solver.cpp:105] Iteration 70500, lr = 0.01
I1007 16:51:33.411850  4982 solver.cpp:218] Iteration 70600 (11.9873 iter/s, 8.34217s/100 iters), loss = 0.0384771
I1007 16:51:33.411896  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0384774 (* 1 = 0.0384774 loss)
I1007 16:51:33.411905  4982 sgd_solver.cpp:105] Iteration 70600, lr = 0.01
I1007 16:51:41.738828  4982 solver.cpp:218] Iteration 70700 (12.0093 iter/s, 8.32691s/100 iters), loss = 0.0309353
I1007 16:51:41.738869  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0309356 (* 1 = 0.0309356 loss)
I1007 16:51:41.738875  4982 sgd_solver.cpp:105] Iteration 70700, lr = 0.01
I1007 16:51:50.071081  4982 solver.cpp:218] Iteration 70800 (12.0017 iter/s, 8.33218s/100 iters), loss = 0.0132104
I1007 16:51:50.071218  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0132107 (* 1 = 0.0132107 loss)
I1007 16:51:50.071228  4982 sgd_solver.cpp:105] Iteration 70800, lr = 0.01
I1007 16:51:58.401237  4982 solver.cpp:218] Iteration 70900 (12.0048 iter/s, 8.33s/100 iters), loss = 0.0862701
I1007 16:51:58.401285  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0862703 (* 1 = 0.0862703 loss)
I1007 16:51:58.401294  4982 sgd_solver.cpp:105] Iteration 70900, lr = 0.01
I1007 16:52:06.319905  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:52:06.653578  4982 solver.cpp:330] Iteration 71000, Testing net (#0)
I1007 16:52:08.586573  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:52:08.667843  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8861
I1007 16:52:08.667881  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.474617 (* 1 = 0.474617 loss)
I1007 16:52:08.750119  4982 solver.cpp:218] Iteration 71000 (9.66295 iter/s, 10.3488s/100 iters), loss = 0.0436354
I1007 16:52:08.750144  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0436356 (* 1 = 0.0436356 loss)
I1007 16:52:08.750149  4982 sgd_solver.cpp:105] Iteration 71000, lr = 0.01
I1007 16:52:17.086603  4982 solver.cpp:218] Iteration 71100 (11.9955 iter/s, 8.33643s/100 iters), loss = 0.0369293
I1007 16:52:17.086645  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0369296 (* 1 = 0.0369296 loss)
I1007 16:52:17.086652  4982 sgd_solver.cpp:105] Iteration 71100, lr = 0.01
I1007 16:52:25.433300  4982 solver.cpp:218] Iteration 71200 (11.9809 iter/s, 8.34663s/100 iters), loss = 0.079309
I1007 16:52:25.433454  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0793093 (* 1 = 0.0793093 loss)
I1007 16:52:25.433461  4982 sgd_solver.cpp:105] Iteration 71200, lr = 0.01
I1007 16:52:33.778633  4982 solver.cpp:218] Iteration 71300 (11.983 iter/s, 8.34517s/100 iters), loss = 0.022982
I1007 16:52:33.778674  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0229822 (* 1 = 0.0229822 loss)
I1007 16:52:33.778681  4982 sgd_solver.cpp:105] Iteration 71300, lr = 0.01
I1007 16:52:42.122987  4982 solver.cpp:218] Iteration 71400 (11.9843 iter/s, 8.34428s/100 iters), loss = 0.0127462
I1007 16:52:42.123026  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0127464 (* 1 = 0.0127464 loss)
I1007 16:52:42.123033  4982 sgd_solver.cpp:105] Iteration 71400, lr = 0.01
I1007 16:52:50.049003  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:52:50.383253  4982 solver.cpp:330] Iteration 71500, Testing net (#0)
I1007 16:52:52.315407  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:52:52.395761  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8854
I1007 16:52:52.395797  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.464248 (* 1 = 0.464248 loss)
I1007 16:52:52.479254  4982 solver.cpp:218] Iteration 71500 (9.65606 iter/s, 10.3562s/100 iters), loss = 0.0647564
I1007 16:52:52.479279  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0647566 (* 1 = 0.0647566 loss)
I1007 16:52:52.479286  4982 sgd_solver.cpp:105] Iteration 71500, lr = 0.01
I1007 16:53:00.825798  4982 solver.cpp:218] Iteration 71600 (11.9811 iter/s, 8.34649s/100 iters), loss = 0.0453834
I1007 16:53:00.825911  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0453836 (* 1 = 0.0453836 loss)
I1007 16:53:00.825918  4982 sgd_solver.cpp:105] Iteration 71600, lr = 0.01
I1007 16:53:09.159003  4982 solver.cpp:218] Iteration 71700 (12.0004 iter/s, 8.33308s/100 iters), loss = 0.0568909
I1007 16:53:09.159045  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0568911 (* 1 = 0.0568911 loss)
I1007 16:53:09.159052  4982 sgd_solver.cpp:105] Iteration 71700, lr = 0.01
I1007 16:53:17.499502  4982 solver.cpp:218] Iteration 71800 (11.9898 iter/s, 8.34043s/100 iters), loss = 0.00905012
I1007 16:53:17.499543  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00905033 (* 1 = 0.00905033 loss)
I1007 16:53:17.499549  4982 sgd_solver.cpp:105] Iteration 71800, lr = 0.01
I1007 16:53:25.837430  4982 solver.cpp:218] Iteration 71900 (11.9935 iter/s, 8.33786s/100 iters), loss = 0.00958039
I1007 16:53:25.837471  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00958062 (* 1 = 0.00958062 loss)
I1007 16:53:25.837476  4982 sgd_solver.cpp:105] Iteration 71900, lr = 0.01
I1007 16:53:33.761912  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:53:34.095369  4982 solver.cpp:330] Iteration 72000, Testing net (#0)
I1007 16:53:36.027544  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:53:36.108927  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8901
I1007 16:53:36.108963  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.445528 (* 1 = 0.445528 loss)
I1007 16:53:36.191637  4982 solver.cpp:218] Iteration 72000 (9.65798 iter/s, 10.3541s/100 iters), loss = 0.0194457
I1007 16:53:36.191673  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.019446 (* 1 = 0.019446 loss)
I1007 16:53:36.191679  4982 sgd_solver.cpp:105] Iteration 72000, lr = 0.01
I1007 16:53:44.523242  4982 solver.cpp:218] Iteration 72100 (12.0026 iter/s, 8.33154s/100 iters), loss = 0.023728
I1007 16:53:44.523285  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0237283 (* 1 = 0.0237283 loss)
I1007 16:53:44.523291  4982 sgd_solver.cpp:105] Iteration 72100, lr = 0.01
I1007 16:53:52.865553  4982 solver.cpp:218] Iteration 72200 (11.9872 iter/s, 8.34224s/100 iters), loss = 0.0576312
I1007 16:53:52.865595  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0576314 (* 1 = 0.0576314 loss)
I1007 16:53:52.865602  4982 sgd_solver.cpp:105] Iteration 72200, lr = 0.01
I1007 16:54:01.203493  4982 solver.cpp:218] Iteration 72300 (11.9935 iter/s, 8.33787s/100 iters), loss = 0.0392033
I1007 16:54:01.203536  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0392036 (* 1 = 0.0392036 loss)
I1007 16:54:01.203541  4982 sgd_solver.cpp:105] Iteration 72300, lr = 0.01
I1007 16:54:09.547719  4982 solver.cpp:218] Iteration 72400 (11.9844 iter/s, 8.34416s/100 iters), loss = 0.0539104
I1007 16:54:09.547825  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0539106 (* 1 = 0.0539106 loss)
I1007 16:54:09.547842  4982 sgd_solver.cpp:105] Iteration 72400, lr = 0.01
I1007 16:54:17.466470  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:54:17.800652  4982 solver.cpp:330] Iteration 72500, Testing net (#0)
I1007 16:54:19.733239  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:54:19.813885  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8899
I1007 16:54:19.813921  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.426489 (* 1 = 0.426489 loss)
I1007 16:54:19.897712  4982 solver.cpp:218] Iteration 72500 (9.66197 iter/s, 10.3499s/100 iters), loss = 0.0163404
I1007 16:54:19.897739  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0163406 (* 1 = 0.0163406 loss)
I1007 16:54:19.897747  4982 sgd_solver.cpp:105] Iteration 72500, lr = 0.01
I1007 16:54:28.246073  4982 solver.cpp:218] Iteration 72600 (11.9785 iter/s, 8.34831s/100 iters), loss = 0.0885509
I1007 16:54:28.246114  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0885511 (* 1 = 0.0885511 loss)
I1007 16:54:28.246121  4982 sgd_solver.cpp:105] Iteration 72600, lr = 0.01
I1007 16:54:36.580657  4982 solver.cpp:218] Iteration 72700 (11.9983 iter/s, 8.33451s/100 iters), loss = 0.0262563
I1007 16:54:36.580698  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0262564 (* 1 = 0.0262564 loss)
I1007 16:54:36.580703  4982 sgd_solver.cpp:105] Iteration 72700, lr = 0.01
I1007 16:54:44.923465  4982 solver.cpp:218] Iteration 72800 (11.9865 iter/s, 8.34274s/100 iters), loss = 0.116494
I1007 16:54:44.923552  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.116494 (* 1 = 0.116494 loss)
I1007 16:54:44.923568  4982 sgd_solver.cpp:105] Iteration 72800, lr = 0.01
I1007 16:54:53.261979  4982 solver.cpp:218] Iteration 72900 (11.9927 iter/s, 8.3384s/100 iters), loss = 0.010517
I1007 16:54:53.262022  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0105172 (* 1 = 0.0105172 loss)
I1007 16:54:53.262027  4982 sgd_solver.cpp:105] Iteration 72900, lr = 0.01
I1007 16:55:01.187430  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:55:01.522079  4982 solver.cpp:330] Iteration 73000, Testing net (#0)
I1007 16:55:03.455307  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:55:03.536901  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8996
I1007 16:55:03.536928  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.41669 (* 1 = 0.41669 loss)
I1007 16:55:03.619778  4982 solver.cpp:218] Iteration 73000 (9.65463 iter/s, 10.3577s/100 iters), loss = 0.0248688
I1007 16:55:03.619802  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.024869 (* 1 = 0.024869 loss)
I1007 16:55:03.619808  4982 sgd_solver.cpp:105] Iteration 73000, lr = 0.01
I1007 16:55:11.948117  4982 solver.cpp:218] Iteration 73100 (12.0073 iter/s, 8.32829s/100 iters), loss = 0.00951003
I1007 16:55:11.948148  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00951022 (* 1 = 0.00951022 loss)
I1007 16:55:11.948154  4982 sgd_solver.cpp:105] Iteration 73100, lr = 0.01
I1007 16:55:20.284600  4982 solver.cpp:218] Iteration 73200 (11.9956 iter/s, 8.33642s/100 iters), loss = 0.0404908
I1007 16:55:20.284720  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.040491 (* 1 = 0.040491 loss)
I1007 16:55:20.284729  4982 sgd_solver.cpp:105] Iteration 73200, lr = 0.01
I1007 16:55:28.613255  4982 solver.cpp:218] Iteration 73300 (12.0069 iter/s, 8.32852s/100 iters), loss = 0.0321042
I1007 16:55:28.613296  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0321044 (* 1 = 0.0321044 loss)
I1007 16:55:28.613302  4982 sgd_solver.cpp:105] Iteration 73300, lr = 0.01
I1007 16:55:36.949167  4982 solver.cpp:218] Iteration 73400 (11.9964 iter/s, 8.33584s/100 iters), loss = 0.0157397
I1007 16:55:36.949198  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0157399 (* 1 = 0.0157399 loss)
I1007 16:55:36.949203  4982 sgd_solver.cpp:105] Iteration 73400, lr = 0.01
I1007 16:55:44.867893  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:55:45.201642  4982 solver.cpp:330] Iteration 73500, Testing net (#0)
I1007 16:55:47.134426  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:55:47.215246  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8898
I1007 16:55:47.215283  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.444663 (* 1 = 0.444663 loss)
I1007 16:55:47.299206  4982 solver.cpp:218] Iteration 73500 (9.66186 iter/s, 10.35s/100 iters), loss = 0.0140289
I1007 16:55:47.299234  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0140291 (* 1 = 0.0140291 loss)
I1007 16:55:47.299242  4982 sgd_solver.cpp:105] Iteration 73500, lr = 0.01
I1007 16:55:55.648843  4982 solver.cpp:218] Iteration 73600 (11.9767 iter/s, 8.34958s/100 iters), loss = 0.068798
I1007 16:55:55.648952  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0687983 (* 1 = 0.0687983 loss)
I1007 16:55:55.648970  4982 sgd_solver.cpp:105] Iteration 73600, lr = 0.01
I1007 16:56:03.990655  4982 solver.cpp:218] Iteration 73700 (11.988 iter/s, 8.34168s/100 iters), loss = 0.0234858
I1007 16:56:03.990696  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0234861 (* 1 = 0.0234861 loss)
I1007 16:56:03.990702  4982 sgd_solver.cpp:105] Iteration 73700, lr = 0.01
I1007 16:56:12.334101  4982 solver.cpp:218] Iteration 73800 (11.9856 iter/s, 8.34338s/100 iters), loss = 0.0241744
I1007 16:56:12.334132  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0241746 (* 1 = 0.0241746 loss)
I1007 16:56:12.334138  4982 sgd_solver.cpp:105] Iteration 73800, lr = 0.01
I1007 16:56:20.673427  4982 solver.cpp:218] Iteration 73900 (11.9915 iter/s, 8.33927s/100 iters), loss = 0.039421
I1007 16:56:20.673468  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0394212 (* 1 = 0.0394212 loss)
I1007 16:56:20.673475  4982 sgd_solver.cpp:105] Iteration 73900, lr = 0.01
I1007 16:56:28.592552  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:56:28.926136  4982 solver.cpp:330] Iteration 74000, Testing net (#0)
I1007 16:56:30.858078  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:56:30.939177  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8946
I1007 16:56:30.939213  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.41607 (* 1 = 0.41607 loss)
I1007 16:56:31.021522  4982 solver.cpp:218] Iteration 74000 (9.66368 iter/s, 10.348s/100 iters), loss = 0.0264347
I1007 16:56:31.021549  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.026435 (* 1 = 0.026435 loss)
I1007 16:56:31.021556  4982 sgd_solver.cpp:105] Iteration 74000, lr = 0.01
I1007 16:56:39.363122  4982 solver.cpp:218] Iteration 74100 (11.9882 iter/s, 8.34154s/100 iters), loss = 0.0688461
I1007 16:56:39.363152  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0688463 (* 1 = 0.0688463 loss)
I1007 16:56:39.363157  4982 sgd_solver.cpp:105] Iteration 74100, lr = 0.01
I1007 16:56:47.708364  4982 solver.cpp:218] Iteration 74200 (11.983 iter/s, 8.34518s/100 iters), loss = 0.0596262
I1007 16:56:47.708395  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0596264 (* 1 = 0.0596264 loss)
I1007 16:56:47.708401  4982 sgd_solver.cpp:105] Iteration 74200, lr = 0.01
I1007 16:56:56.045655  4982 solver.cpp:218] Iteration 74300 (11.9944 iter/s, 8.33723s/100 iters), loss = 0.0309111
I1007 16:56:56.045696  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0309113 (* 1 = 0.0309113 loss)
I1007 16:56:56.045702  4982 sgd_solver.cpp:105] Iteration 74300, lr = 0.01
I1007 16:57:04.381577  4982 solver.cpp:218] Iteration 74400 (11.9964 iter/s, 8.33585s/100 iters), loss = 0.050359
I1007 16:57:04.381682  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0503592 (* 1 = 0.0503592 loss)
I1007 16:57:04.381700  4982 sgd_solver.cpp:105] Iteration 74400, lr = 0.01
I1007 16:57:12.305593  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:57:12.639608  4982 solver.cpp:330] Iteration 74500, Testing net (#0)
I1007 16:57:14.570608  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:57:14.651705  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8838
I1007 16:57:14.651742  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.495745 (* 1 = 0.495745 loss)
I1007 16:57:14.735193  4982 solver.cpp:218] Iteration 74500 (9.65859 iter/s, 10.3535s/100 iters), loss = 0.0325726
I1007 16:57:14.735222  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0325729 (* 1 = 0.0325729 loss)
I1007 16:57:14.735229  4982 sgd_solver.cpp:105] Iteration 74500, lr = 0.01
I1007 16:57:23.073726  4982 solver.cpp:218] Iteration 74600 (11.9926 iter/s, 8.33848s/100 iters), loss = 0.0477307
I1007 16:57:23.073767  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0477309 (* 1 = 0.0477309 loss)
I1007 16:57:23.073773  4982 sgd_solver.cpp:105] Iteration 74600, lr = 0.01
I1007 16:57:31.407304  4982 solver.cpp:218] Iteration 74700 (11.9998 iter/s, 8.33351s/100 iters), loss = 0.00894594
I1007 16:57:31.407333  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00894618 (* 1 = 0.00894618 loss)
I1007 16:57:31.407340  4982 sgd_solver.cpp:105] Iteration 74700, lr = 0.01
I1007 16:57:39.750030  4982 solver.cpp:218] Iteration 74800 (11.9866 iter/s, 8.34267s/100 iters), loss = 0.0296252
I1007 16:57:39.750139  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0296255 (* 1 = 0.0296255 loss)
I1007 16:57:39.750145  4982 sgd_solver.cpp:105] Iteration 74800, lr = 0.01
I1007 16:57:48.085559  4982 solver.cpp:218] Iteration 74900 (11.997 iter/s, 8.3354s/100 iters), loss = 0.0205274
I1007 16:57:48.085590  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0205276 (* 1 = 0.0205276 loss)
I1007 16:57:48.085597  4982 sgd_solver.cpp:105] Iteration 74900, lr = 0.01
I1007 16:57:56.009500  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:57:56.343436  4982 solver.cpp:330] Iteration 75000, Testing net (#0)
I1007 16:57:58.275038  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:57:58.356725  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8805
I1007 16:57:58.356763  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.495386 (* 1 = 0.495386 loss)
I1007 16:57:58.439404  4982 solver.cpp:218] Iteration 75000 (9.65831 iter/s, 10.3538s/100 iters), loss = 0.0148567
I1007 16:57:58.439429  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.014857 (* 1 = 0.014857 loss)
I1007 16:57:58.439436  4982 sgd_solver.cpp:105] Iteration 75000, lr = 0.01
I1007 16:58:06.767294  4982 solver.cpp:218] Iteration 75100 (12.0079 iter/s, 8.32784s/100 iters), loss = 0.0105632
I1007 16:58:06.767323  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0105635 (* 1 = 0.0105635 loss)
I1007 16:58:06.767329  4982 sgd_solver.cpp:105] Iteration 75100, lr = 0.01
I1007 16:58:15.102586  4982 solver.cpp:218] Iteration 75200 (11.9973 iter/s, 8.33524s/100 iters), loss = 0.00895478
I1007 16:58:15.102712  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00895504 (* 1 = 0.00895504 loss)
I1007 16:58:15.102732  4982 sgd_solver.cpp:105] Iteration 75200, lr = 0.01
I1007 16:58:23.432087  4982 solver.cpp:218] Iteration 75300 (12.0057 iter/s, 8.32935s/100 iters), loss = 0.0716548
I1007 16:58:23.432128  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0716551 (* 1 = 0.0716551 loss)
I1007 16:58:23.432134  4982 sgd_solver.cpp:105] Iteration 75300, lr = 0.01
I1007 16:58:31.762897  4982 solver.cpp:218] Iteration 75400 (12.0037 iter/s, 8.33074s/100 iters), loss = 0.0134205
I1007 16:58:31.762936  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0134208 (* 1 = 0.0134208 loss)
I1007 16:58:31.762943  4982 sgd_solver.cpp:105] Iteration 75400, lr = 0.01
I1007 16:58:39.684283  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:58:40.018016  4982 solver.cpp:330] Iteration 75500, Testing net (#0)
I1007 16:58:41.950227  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:58:42.030508  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8797
I1007 16:58:42.030544  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.507901 (* 1 = 0.507901 loss)
I1007 16:58:42.114138  4982 solver.cpp:218] Iteration 75500 (9.66074 iter/s, 10.3512s/100 iters), loss = 0.0285902
I1007 16:58:42.114166  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0285905 (* 1 = 0.0285905 loss)
I1007 16:58:42.114172  4982 sgd_solver.cpp:105] Iteration 75500, lr = 0.01
I1007 16:58:50.456025  4982 solver.cpp:218] Iteration 75600 (11.9878 iter/s, 8.34183s/100 iters), loss = 0.0226471
I1007 16:58:50.456143  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0226475 (* 1 = 0.0226475 loss)
I1007 16:58:50.456161  4982 sgd_solver.cpp:105] Iteration 75600, lr = 0.01
I1007 16:58:58.789484  4982 solver.cpp:218] Iteration 75700 (12 iter/s, 8.33333s/100 iters), loss = 0.0225298
I1007 16:58:58.789525  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0225301 (* 1 = 0.0225301 loss)
I1007 16:58:58.789531  4982 sgd_solver.cpp:105] Iteration 75700, lr = 0.01
I1007 16:59:07.129612  4982 solver.cpp:218] Iteration 75800 (11.9903 iter/s, 8.34006s/100 iters), loss = 0.0169622
I1007 16:59:07.129642  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0169625 (* 1 = 0.0169625 loss)
I1007 16:59:07.129647  4982 sgd_solver.cpp:105] Iteration 75800, lr = 0.01
I1007 16:59:15.465378  4982 solver.cpp:218] Iteration 75900 (11.9966 iter/s, 8.33571s/100 iters), loss = 0.0213303
I1007 16:59:15.465409  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0213306 (* 1 = 0.0213306 loss)
I1007 16:59:15.465415  4982 sgd_solver.cpp:105] Iteration 75900, lr = 0.01
I1007 16:59:23.388463  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:59:23.721494  4982 solver.cpp:330] Iteration 76000, Testing net (#0)
I1007 16:59:25.653432  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 16:59:25.734726  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.891
I1007 16:59:25.734750  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.440316 (* 1 = 0.440316 loss)
I1007 16:59:25.817473  4982 solver.cpp:218] Iteration 76000 (9.65994 iter/s, 10.352s/100 iters), loss = 0.0120779
I1007 16:59:25.817499  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0120783 (* 1 = 0.0120783 loss)
I1007 16:59:25.817505  4982 sgd_solver.cpp:105] Iteration 76000, lr = 0.01
I1007 16:59:34.152199  4982 solver.cpp:218] Iteration 76100 (11.9981 iter/s, 8.33467s/100 iters), loss = 0.0252914
I1007 16:59:34.152240  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0252917 (* 1 = 0.0252917 loss)
I1007 16:59:34.152245  4982 sgd_solver.cpp:105] Iteration 76100, lr = 0.01
I1007 16:59:42.490964  4982 solver.cpp:218] Iteration 76200 (11.9923 iter/s, 8.3387s/100 iters), loss = 0.0225567
I1007 16:59:42.490994  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0225571 (* 1 = 0.0225571 loss)
I1007 16:59:42.490999  4982 sgd_solver.cpp:105] Iteration 76200, lr = 0.01
I1007 16:59:50.824393  4982 solver.cpp:218] Iteration 76300 (11.9999 iter/s, 8.33337s/100 iters), loss = 0.0623108
I1007 16:59:50.824434  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0623111 (* 1 = 0.0623111 loss)
I1007 16:59:50.824440  4982 sgd_solver.cpp:105] Iteration 76300, lr = 0.01
I1007 16:59:59.163386  4982 solver.cpp:218] Iteration 76400 (11.992 iter/s, 8.33893s/100 iters), loss = 0.0158111
I1007 16:59:59.163485  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0158114 (* 1 = 0.0158114 loss)
I1007 16:59:59.163491  4982 sgd_solver.cpp:105] Iteration 76400, lr = 0.01
I1007 17:00:07.078987  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:00:07.413348  4982 solver.cpp:330] Iteration 76500, Testing net (#0)
I1007 17:00:09.345311  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:00:09.425789  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8852
I1007 17:00:09.425814  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.478669 (* 1 = 0.478669 loss)
I1007 17:00:09.509665  4982 solver.cpp:218] Iteration 76500 (9.66543 iter/s, 10.3461s/100 iters), loss = 0.00685431
I1007 17:00:09.509693  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00685463 (* 1 = 0.00685463 loss)
I1007 17:00:09.509699  4982 sgd_solver.cpp:105] Iteration 76500, lr = 0.01
I1007 17:00:17.851089  4982 solver.cpp:218] Iteration 76600 (11.9884 iter/s, 8.34137s/100 iters), loss = 0.0455449
I1007 17:00:17.851119  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0455452 (* 1 = 0.0455452 loss)
I1007 17:00:17.851126  4982 sgd_solver.cpp:105] Iteration 76600, lr = 0.01
I1007 17:00:26.183527  4982 solver.cpp:218] Iteration 76700 (12.0014 iter/s, 8.33238s/100 iters), loss = 0.0332111
I1007 17:00:26.183557  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0332114 (* 1 = 0.0332114 loss)
I1007 17:00:26.183563  4982 sgd_solver.cpp:105] Iteration 76700, lr = 0.01
I1007 17:00:34.522450  4982 solver.cpp:218] Iteration 76800 (11.992 iter/s, 8.33887s/100 iters), loss = 0.010877
I1007 17:00:34.522586  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0108774 (* 1 = 0.0108774 loss)
I1007 17:00:34.522593  4982 sgd_solver.cpp:105] Iteration 76800, lr = 0.01
I1007 17:00:42.851289  4982 solver.cpp:218] Iteration 76900 (12.0067 iter/s, 8.32868s/100 iters), loss = 0.019769
I1007 17:00:42.851320  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0197693 (* 1 = 0.0197693 loss)
I1007 17:00:42.851327  4982 sgd_solver.cpp:105] Iteration 76900, lr = 0.01
I1007 17:00:50.772302  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:00:51.106076  4982 solver.cpp:330] Iteration 77000, Testing net (#0)
I1007 17:00:53.039690  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:00:53.120460  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8841
I1007 17:00:53.120486  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.461852 (* 1 = 0.461852 loss)
I1007 17:00:53.202751  4982 solver.cpp:218] Iteration 77000 (9.66053 iter/s, 10.3514s/100 iters), loss = 0.0225353
I1007 17:00:53.202777  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0225356 (* 1 = 0.0225356 loss)
I1007 17:00:53.202785  4982 sgd_solver.cpp:105] Iteration 77000, lr = 0.01
I1007 17:01:01.537307  4982 solver.cpp:218] Iteration 77100 (11.9983 iter/s, 8.3345s/100 iters), loss = 0.0171915
I1007 17:01:01.537348  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0171918 (* 1 = 0.0171918 loss)
I1007 17:01:01.537353  4982 sgd_solver.cpp:105] Iteration 77100, lr = 0.01
I1007 17:01:09.877485  4982 solver.cpp:218] Iteration 77200 (11.9903 iter/s, 8.34011s/100 iters), loss = 0.102774
I1007 17:01:09.877579  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.102775 (* 1 = 0.102775 loss)
I1007 17:01:09.877586  4982 sgd_solver.cpp:105] Iteration 77200, lr = 0.01
I1007 17:01:18.211431  4982 solver.cpp:218] Iteration 77300 (11.9993 iter/s, 8.33383s/100 iters), loss = 0.0233518
I1007 17:01:18.211472  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0233522 (* 1 = 0.0233522 loss)
I1007 17:01:18.211477  4982 sgd_solver.cpp:105] Iteration 77300, lr = 0.01
I1007 17:01:26.547317  4982 solver.cpp:218] Iteration 77400 (11.9964 iter/s, 8.33582s/100 iters), loss = 0.0122869
I1007 17:01:26.547356  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0122872 (* 1 = 0.0122872 loss)
I1007 17:01:26.547363  4982 sgd_solver.cpp:105] Iteration 77400, lr = 0.01
I1007 17:01:34.466550  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:01:34.799932  4982 solver.cpp:330] Iteration 77500, Testing net (#0)
I1007 17:01:36.731068  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:01:36.811784  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8953
I1007 17:01:36.811825  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.433654 (* 1 = 0.433654 loss)
I1007 17:01:36.895675  4982 solver.cpp:218] Iteration 77500 (9.66344 iter/s, 10.3483s/100 iters), loss = 0.0333918
I1007 17:01:36.895704  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0333921 (* 1 = 0.0333921 loss)
I1007 17:01:36.895710  4982 sgd_solver.cpp:105] Iteration 77500, lr = 0.01
I1007 17:01:45.231132  4982 solver.cpp:218] Iteration 77600 (11.997 iter/s, 8.3354s/100 iters), loss = 0.0405438
I1007 17:01:45.231215  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0405441 (* 1 = 0.0405441 loss)
I1007 17:01:45.231231  4982 sgd_solver.cpp:105] Iteration 77600, lr = 0.01
I1007 17:01:53.562983  4982 solver.cpp:218] Iteration 77700 (12.0023 iter/s, 8.33174s/100 iters), loss = 0.0121816
I1007 17:01:53.563024  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0121819 (* 1 = 0.0121819 loss)
I1007 17:01:53.563030  4982 sgd_solver.cpp:105] Iteration 77700, lr = 0.01
I1007 17:02:01.898650  4982 solver.cpp:218] Iteration 77800 (11.9967 iter/s, 8.3356s/100 iters), loss = 0.0215176
I1007 17:02:01.898691  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0215179 (* 1 = 0.0215179 loss)
I1007 17:02:01.898697  4982 sgd_solver.cpp:105] Iteration 77800, lr = 0.01
I1007 17:02:10.227146  4982 solver.cpp:218] Iteration 77900 (12.0071 iter/s, 8.32843s/100 iters), loss = 0.0215581
I1007 17:02:10.227188  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0215583 (* 1 = 0.0215583 loss)
I1007 17:02:10.227195  4982 sgd_solver.cpp:105] Iteration 77900, lr = 0.01
I1007 17:02:18.147541  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:02:18.481189  4982 solver.cpp:330] Iteration 78000, Testing net (#0)
I1007 17:02:20.412154  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:02:20.493495  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8926
I1007 17:02:20.493520  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.424565 (* 1 = 0.424565 loss)
I1007 17:02:20.576319  4982 solver.cpp:218] Iteration 78000 (9.66268 iter/s, 10.3491s/100 iters), loss = 0.0342989
I1007 17:02:20.576344  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0342992 (* 1 = 0.0342992 loss)
I1007 17:02:20.576351  4982 sgd_solver.cpp:105] Iteration 78000, lr = 0.01
I1007 17:02:28.904994  4982 solver.cpp:218] Iteration 78100 (12.0068 iter/s, 8.32862s/100 iters), loss = 0.0192301
I1007 17:02:28.905040  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0192304 (* 1 = 0.0192304 loss)
I1007 17:02:28.905047  4982 sgd_solver.cpp:105] Iteration 78100, lr = 0.01
I1007 17:02:37.240227  4982 solver.cpp:218] Iteration 78200 (11.9974 iter/s, 8.33516s/100 iters), loss = 0.038709
I1007 17:02:37.240259  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0387093 (* 1 = 0.0387093 loss)
I1007 17:02:37.240264  4982 sgd_solver.cpp:105] Iteration 78200, lr = 0.01
I1007 17:02:45.567476  4982 solver.cpp:218] Iteration 78300 (12.0089 iter/s, 8.32719s/100 iters), loss = 0.0345955
I1007 17:02:45.567505  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0345958 (* 1 = 0.0345958 loss)
I1007 17:02:45.567522  4982 sgd_solver.cpp:105] Iteration 78300, lr = 0.01
I1007 17:02:53.899744  4982 solver.cpp:218] Iteration 78400 (12.0016 iter/s, 8.33221s/100 iters), loss = 0.017709
I1007 17:02:53.899837  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0177093 (* 1 = 0.0177093 loss)
I1007 17:02:53.899845  4982 sgd_solver.cpp:105] Iteration 78400, lr = 0.01
I1007 17:03:01.812168  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:03:02.146356  4982 solver.cpp:330] Iteration 78500, Testing net (#0)
I1007 17:03:04.078974  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:03:04.159541  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8947
I1007 17:03:04.159577  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.417484 (* 1 = 0.417484 loss)
I1007 17:03:04.243299  4982 solver.cpp:218] Iteration 78500 (9.66797 iter/s, 10.3434s/100 iters), loss = 0.0975583
I1007 17:03:04.243331  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0975586 (* 1 = 0.0975586 loss)
I1007 17:03:04.243338  4982 sgd_solver.cpp:105] Iteration 78500, lr = 0.01
I1007 17:03:12.576928  4982 solver.cpp:218] Iteration 78600 (11.9997 iter/s, 8.33357s/100 iters), loss = 0.0666744
I1007 17:03:12.576969  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0666748 (* 1 = 0.0666748 loss)
I1007 17:03:12.576974  4982 sgd_solver.cpp:105] Iteration 78600, lr = 0.01
I1007 17:03:20.908756  4982 solver.cpp:218] Iteration 78700 (12.0023 iter/s, 8.33176s/100 iters), loss = 0.0361858
I1007 17:03:20.908797  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0361861 (* 1 = 0.0361861 loss)
I1007 17:03:20.908802  4982 sgd_solver.cpp:105] Iteration 78700, lr = 0.01
I1007 17:03:29.241384  4982 solver.cpp:218] Iteration 78800 (12.0011 iter/s, 8.33256s/100 iters), loss = 0.0366229
I1007 17:03:29.241510  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0366232 (* 1 = 0.0366232 loss)
I1007 17:03:29.241528  4982 sgd_solver.cpp:105] Iteration 78800, lr = 0.01
I1007 17:03:37.570451  4982 solver.cpp:218] Iteration 78900 (12.0064 iter/s, 8.32892s/100 iters), loss = 0.0295839
I1007 17:03:37.570492  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0295842 (* 1 = 0.0295842 loss)
I1007 17:03:37.570497  4982 sgd_solver.cpp:105] Iteration 78900, lr = 0.01
I1007 17:03:45.490125  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:03:45.823714  4982 solver.cpp:330] Iteration 79000, Testing net (#0)
I1007 17:03:47.754206  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:03:47.835536  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8983
I1007 17:03:47.835562  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.414036 (* 1 = 0.414036 loss)
I1007 17:03:47.918201  4982 solver.cpp:218] Iteration 79000 (9.664 iter/s, 10.3477s/100 iters), loss = 0.0366642
I1007 17:03:47.918227  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0366645 (* 1 = 0.0366645 loss)
I1007 17:03:47.918234  4982 sgd_solver.cpp:105] Iteration 79000, lr = 0.01
I1007 17:03:56.244109  4982 solver.cpp:218] Iteration 79100 (12.0108 iter/s, 8.32585s/100 iters), loss = 0.0102983
I1007 17:03:56.244141  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0102986 (* 1 = 0.0102986 loss)
I1007 17:03:56.244148  4982 sgd_solver.cpp:105] Iteration 79100, lr = 0.01
I1007 17:04:04.582711  4982 solver.cpp:218] Iteration 79200 (11.9925 iter/s, 8.33854s/100 iters), loss = 0.0249353
I1007 17:04:04.582847  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0249356 (* 1 = 0.0249356 loss)
I1007 17:04:04.582864  4982 sgd_solver.cpp:105] Iteration 79200, lr = 0.01
I1007 17:04:12.912395  4982 solver.cpp:218] Iteration 79300 (12.0055 iter/s, 8.32953s/100 iters), loss = 0.0508649
I1007 17:04:12.912425  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0508652 (* 1 = 0.0508652 loss)
I1007 17:04:12.912441  4982 sgd_solver.cpp:105] Iteration 79300, lr = 0.01
I1007 17:04:21.249357  4982 solver.cpp:218] Iteration 79400 (11.9949 iter/s, 8.33691s/100 iters), loss = 0.00555279
I1007 17:04:21.249388  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0055531 (* 1 = 0.0055531 loss)
I1007 17:04:21.249393  4982 sgd_solver.cpp:105] Iteration 79400, lr = 0.01
I1007 17:04:29.171041  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:04:29.502854  4982 solver.cpp:330] Iteration 79500, Testing net (#0)
I1007 17:04:31.434231  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:04:31.514688  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8971
I1007 17:04:31.514724  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.427602 (* 1 = 0.427602 loss)
I1007 17:04:31.598136  4982 solver.cpp:218] Iteration 79500 (9.66303 iter/s, 10.3487s/100 iters), loss = 0.0221503
I1007 17:04:31.598161  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0221506 (* 1 = 0.0221506 loss)
I1007 17:04:31.598167  4982 sgd_solver.cpp:105] Iteration 79500, lr = 0.01
I1007 17:04:39.931941  4982 solver.cpp:218] Iteration 79600 (11.9994 iter/s, 8.33375s/100 iters), loss = 0.0203562
I1007 17:04:39.932047  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0203565 (* 1 = 0.0203565 loss)
I1007 17:04:39.932063  4982 sgd_solver.cpp:105] Iteration 79600, lr = 0.01
I1007 17:04:48.259313  4982 solver.cpp:218] Iteration 79700 (12.0088 iter/s, 8.32724s/100 iters), loss = 0.00933433
I1007 17:04:48.259344  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00933462 (* 1 = 0.00933462 loss)
I1007 17:04:48.259351  4982 sgd_solver.cpp:105] Iteration 79700, lr = 0.01
I1007 17:04:56.588472  4982 solver.cpp:218] Iteration 79800 (12.0061 iter/s, 8.3291s/100 iters), loss = 0.0326272
I1007 17:04:56.588511  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0326274 (* 1 = 0.0326274 loss)
I1007 17:04:56.588517  4982 sgd_solver.cpp:105] Iteration 79800, lr = 0.01
I1007 17:05:04.918747  4982 solver.cpp:218] Iteration 79900 (12.0045 iter/s, 8.33021s/100 iters), loss = 0.00612662
I1007 17:05:04.918788  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00612691 (* 1 = 0.00612691 loss)
I1007 17:05:04.918794  4982 sgd_solver.cpp:105] Iteration 79900, lr = 0.01
I1007 17:05:12.836338  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:05:13.170434  4982 solver.cpp:330] Iteration 80000, Testing net (#0)
I1007 17:05:15.103155  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:05:15.184705  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.89
I1007 17:05:15.184742  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.451253 (* 1 = 0.451253 loss)
I1007 17:05:15.267056  4982 solver.cpp:218] Iteration 80000 (9.66348 iter/s, 10.3482s/100 iters), loss = 0.0212673
I1007 17:05:15.267086  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0212676 (* 1 = 0.0212676 loss)
I1007 17:05:15.267092  4982 sgd_solver.cpp:46] MultiStep Status: Iteration 80000, step = 2
I1007 17:05:15.267096  4982 sgd_solver.cpp:105] Iteration 80000, lr = 0.001
I1007 17:05:23.597388  4982 solver.cpp:218] Iteration 80100 (12.0044 iter/s, 8.33028s/100 iters), loss = 0.0450049
I1007 17:05:23.597429  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0450051 (* 1 = 0.0450051 loss)
I1007 17:05:23.597434  4982 sgd_solver.cpp:105] Iteration 80100, lr = 0.001
I1007 17:05:31.933148  4982 solver.cpp:218] Iteration 80200 (11.9966 iter/s, 8.33569s/100 iters), loss = 0.0497259
I1007 17:05:31.933189  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0497261 (* 1 = 0.0497261 loss)
I1007 17:05:31.933195  4982 sgd_solver.cpp:105] Iteration 80200, lr = 0.001
I1007 17:05:40.266428  4982 solver.cpp:218] Iteration 80300 (12.0002 iter/s, 8.33321s/100 iters), loss = 0.0097209
I1007 17:05:40.266458  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00972116 (* 1 = 0.00972116 loss)
I1007 17:05:40.266464  4982 sgd_solver.cpp:105] Iteration 80300, lr = 0.001
I1007 17:05:48.604243  4982 solver.cpp:218] Iteration 80400 (11.9936 iter/s, 8.33776s/100 iters), loss = 0.0320346
I1007 17:05:48.604365  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0320349 (* 1 = 0.0320349 loss)
I1007 17:05:48.604372  4982 sgd_solver.cpp:105] Iteration 80400, lr = 0.001
I1007 17:05:56.524420  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:05:56.857868  4982 solver.cpp:330] Iteration 80500, Testing net (#0)
I1007 17:05:58.791079  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:05:58.871955  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9035
I1007 17:05:58.871981  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.383562 (* 1 = 0.383562 loss)
I1007 17:05:58.955198  4982 solver.cpp:218] Iteration 80500 (9.66109 iter/s, 10.3508s/100 iters), loss = 0.0149434
I1007 17:05:58.955224  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0149437 (* 1 = 0.0149437 loss)
I1007 17:05:58.955230  4982 sgd_solver.cpp:105] Iteration 80500, lr = 0.001
I1007 17:06:07.298007  4982 solver.cpp:218] Iteration 80600 (11.9864 iter/s, 8.34276s/100 iters), loss = 0.00566707
I1007 17:06:07.298036  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00566732 (* 1 = 0.00566732 loss)
I1007 17:06:07.298043  4982 sgd_solver.cpp:105] Iteration 80600, lr = 0.001
I1007 17:06:15.628963  4982 solver.cpp:218] Iteration 80700 (12.0035 iter/s, 8.3309s/100 iters), loss = 0.026459
I1007 17:06:15.628993  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0264592 (* 1 = 0.0264592 loss)
I1007 17:06:15.628998  4982 sgd_solver.cpp:105] Iteration 80700, lr = 0.001
I1007 17:06:23.970584  4982 solver.cpp:218] Iteration 80800 (11.9882 iter/s, 8.34157s/100 iters), loss = 0.010456
I1007 17:06:23.970687  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0104563 (* 1 = 0.0104563 loss)
I1007 17:06:23.970705  4982 sgd_solver.cpp:105] Iteration 80800, lr = 0.001
I1007 17:06:32.305462  4982 solver.cpp:218] Iteration 80900 (11.998 iter/s, 8.33475s/100 iters), loss = 0.000859776
I1007 17:06:32.305492  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000860022 (* 1 = 0.000860022 loss)
I1007 17:06:32.305498  4982 sgd_solver.cpp:105] Iteration 80900, lr = 0.001
I1007 17:06:40.232586  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:06:40.566987  4982 solver.cpp:330] Iteration 81000, Testing net (#0)
I1007 17:06:42.498795  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:06:42.580096  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9068
I1007 17:06:42.580122  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.376093 (* 1 = 0.376093 loss)
I1007 17:06:42.662370  4982 solver.cpp:218] Iteration 81000 (9.65545 iter/s, 10.3568s/100 iters), loss = 0.0480637
I1007 17:06:42.662397  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.048064 (* 1 = 0.048064 loss)
I1007 17:06:42.662405  4982 sgd_solver.cpp:105] Iteration 81000, lr = 0.001
I1007 17:06:50.990456  4982 solver.cpp:218] Iteration 81100 (12.0076 iter/s, 8.32803s/100 iters), loss = 0.00488286
I1007 17:06:50.990487  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00488312 (* 1 = 0.00488312 loss)
I1007 17:06:50.990494  4982 sgd_solver.cpp:105] Iteration 81100, lr = 0.001
I1007 17:06:59.326186  4982 solver.cpp:218] Iteration 81200 (11.9966 iter/s, 8.33567s/100 iters), loss = 0.0551623
I1007 17:06:59.326299  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0551626 (* 1 = 0.0551626 loss)
I1007 17:06:59.326308  4982 sgd_solver.cpp:105] Iteration 81200, lr = 0.001
I1007 17:07:07.653625  4982 solver.cpp:218] Iteration 81300 (12.0087 iter/s, 8.3273s/100 iters), loss = 0.0290363
I1007 17:07:07.653653  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0290366 (* 1 = 0.0290366 loss)
I1007 17:07:07.653659  4982 sgd_solver.cpp:105] Iteration 81300, lr = 0.001
I1007 17:07:15.991214  4982 solver.cpp:218] Iteration 81400 (11.994 iter/s, 8.33753s/100 iters), loss = 0.0068333
I1007 17:07:15.991255  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00683355 (* 1 = 0.00683355 loss)
I1007 17:07:15.991261  4982 sgd_solver.cpp:105] Iteration 81400, lr = 0.001
I1007 17:07:23.911497  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:07:24.244208  4982 solver.cpp:330] Iteration 81500, Testing net (#0)
I1007 17:07:26.175559  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:07:26.256486  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9083
I1007 17:07:26.256512  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.369244 (* 1 = 0.369244 loss)
I1007 17:07:26.340303  4982 solver.cpp:218] Iteration 81500 (9.66275 iter/s, 10.349s/100 iters), loss = 0.0177844
I1007 17:07:26.340330  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0177847 (* 1 = 0.0177847 loss)
I1007 17:07:26.340337  4982 sgd_solver.cpp:105] Iteration 81500, lr = 0.001
I1007 17:07:34.677011  4982 solver.cpp:218] Iteration 81600 (11.9952 iter/s, 8.33665s/100 iters), loss = 0.00518922
I1007 17:07:34.677109  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00518947 (* 1 = 0.00518947 loss)
I1007 17:07:34.677115  4982 sgd_solver.cpp:105] Iteration 81600, lr = 0.001
I1007 17:07:43.004765  4982 solver.cpp:218] Iteration 81700 (12.0082 iter/s, 8.32763s/100 iters), loss = 0.0130693
I1007 17:07:43.004794  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0130696 (* 1 = 0.0130696 loss)
I1007 17:07:43.004801  4982 sgd_solver.cpp:105] Iteration 81700, lr = 0.001
I1007 17:07:51.346423  4982 solver.cpp:218] Iteration 81800 (11.9881 iter/s, 8.3416s/100 iters), loss = 0.0261954
I1007 17:07:51.346460  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0261957 (* 1 = 0.0261957 loss)
I1007 17:07:51.346467  4982 sgd_solver.cpp:105] Iteration 81800, lr = 0.001
I1007 17:07:59.683058  4982 solver.cpp:218] Iteration 81900 (11.9953 iter/s, 8.33657s/100 iters), loss = 0.00573713
I1007 17:07:59.683099  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00573737 (* 1 = 0.00573737 loss)
I1007 17:07:59.683104  4982 sgd_solver.cpp:105] Iteration 81900, lr = 0.001
I1007 17:08:07.607189  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:08:07.941120  4982 solver.cpp:330] Iteration 82000, Testing net (#0)
I1007 17:08:09.874289  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:08:09.955561  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9087
I1007 17:08:09.955586  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.369463 (* 1 = 0.369463 loss)
I1007 17:08:10.038377  4982 solver.cpp:218] Iteration 82000 (9.65694 iter/s, 10.3552s/100 iters), loss = 0.0291063
I1007 17:08:10.038403  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0291066 (* 1 = 0.0291066 loss)
I1007 17:08:10.038410  4982 sgd_solver.cpp:105] Iteration 82000, lr = 0.001
I1007 17:08:18.365335  4982 solver.cpp:218] Iteration 82100 (12.0093 iter/s, 8.3269s/100 iters), loss = 0.0153083
I1007 17:08:18.365365  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0153086 (* 1 = 0.0153086 loss)
I1007 17:08:18.365370  4982 sgd_solver.cpp:105] Iteration 82100, lr = 0.001
I1007 17:08:26.701019  4982 solver.cpp:218] Iteration 82200 (11.9967 iter/s, 8.33563s/100 iters), loss = 0.00520655
I1007 17:08:26.701050  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00520679 (* 1 = 0.00520679 loss)
I1007 17:08:26.701056  4982 sgd_solver.cpp:105] Iteration 82200, lr = 0.001
I1007 17:08:35.031548  4982 solver.cpp:218] Iteration 82300 (12.0041 iter/s, 8.33047s/100 iters), loss = 0.00615358
I1007 17:08:35.031579  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00615382 (* 1 = 0.00615382 loss)
I1007 17:08:35.031584  4982 sgd_solver.cpp:105] Iteration 82300, lr = 0.001
I1007 17:08:43.367928  4982 solver.cpp:218] Iteration 82400 (11.9957 iter/s, 8.33632s/100 iters), loss = 0.0117291
I1007 17:08:43.368093  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0117293 (* 1 = 0.0117293 loss)
I1007 17:08:43.368103  4982 sgd_solver.cpp:105] Iteration 82400, lr = 0.001
I1007 17:08:51.284852  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:08:51.618803  4982 solver.cpp:330] Iteration 82500, Testing net (#0)
I1007 17:08:53.553006  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:08:53.633668  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.908
I1007 17:08:53.633694  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.367191 (* 1 = 0.367191 loss)
I1007 17:08:53.717161  4982 solver.cpp:218] Iteration 82500 (9.66273 iter/s, 10.349s/100 iters), loss = 0.00563479
I1007 17:08:53.717188  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00563503 (* 1 = 0.00563503 loss)
I1007 17:08:53.717195  4982 sgd_solver.cpp:105] Iteration 82500, lr = 0.001
I1007 17:09:02.056095  4982 solver.cpp:218] Iteration 82600 (11.992 iter/s, 8.33888s/100 iters), loss = 0.00370514
I1007 17:09:02.056125  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00370538 (* 1 = 0.00370538 loss)
I1007 17:09:02.056131  4982 sgd_solver.cpp:105] Iteration 82600, lr = 0.001
I1007 17:09:10.391180  4982 solver.cpp:218] Iteration 82700 (11.9976 iter/s, 8.33503s/100 iters), loss = 0.0116362
I1007 17:09:10.391207  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0116364 (* 1 = 0.0116364 loss)
I1007 17:09:10.391213  4982 sgd_solver.cpp:105] Iteration 82700, lr = 0.001
I1007 17:09:18.729910  4982 solver.cpp:218] Iteration 82800 (11.9923 iter/s, 8.33867s/100 iters), loss = 0.0088481
I1007 17:09:18.730036  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00884834 (* 1 = 0.00884834 loss)
I1007 17:09:18.730052  4982 sgd_solver.cpp:105] Iteration 82800, lr = 0.001
I1007 17:09:27.065192  4982 solver.cpp:218] Iteration 82900 (11.9974 iter/s, 8.33513s/100 iters), loss = 0.00336355
I1007 17:09:27.065233  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00336378 (* 1 = 0.00336378 loss)
I1007 17:09:27.065239  4982 sgd_solver.cpp:105] Iteration 82900, lr = 0.001
I1007 17:09:34.989598  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:09:35.323338  4982 solver.cpp:330] Iteration 83000, Testing net (#0)
I1007 17:09:37.256006  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:09:37.337116  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9082
I1007 17:09:37.337152  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.365565 (* 1 = 0.365565 loss)
I1007 17:09:37.419909  4982 solver.cpp:218] Iteration 83000 (9.6575 iter/s, 10.3546s/100 iters), loss = 0.0077152
I1007 17:09:37.419934  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00771544 (* 1 = 0.00771544 loss)
I1007 17:09:37.419940  4982 sgd_solver.cpp:105] Iteration 83000, lr = 0.001
I1007 17:09:45.752704  4982 solver.cpp:218] Iteration 83100 (12.0008 iter/s, 8.33274s/100 iters), loss = 0.00833287
I1007 17:09:45.752735  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00833312 (* 1 = 0.00833312 loss)
I1007 17:09:45.752740  4982 sgd_solver.cpp:105] Iteration 83100, lr = 0.001
I1007 17:09:54.092527  4982 solver.cpp:218] Iteration 83200 (11.9907 iter/s, 8.33977s/100 iters), loss = 0.0486915
I1007 17:09:54.092633  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0486917 (* 1 = 0.0486917 loss)
I1007 17:09:54.092649  4982 sgd_solver.cpp:105] Iteration 83200, lr = 0.001
I1007 17:10:02.427650  4982 solver.cpp:218] Iteration 83300 (11.9976 iter/s, 8.33499s/100 iters), loss = 0.0172606
I1007 17:10:02.427690  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0172609 (* 1 = 0.0172609 loss)
I1007 17:10:02.427695  4982 sgd_solver.cpp:105] Iteration 83300, lr = 0.001
I1007 17:10:10.767750  4982 solver.cpp:218] Iteration 83400 (11.9904 iter/s, 8.34003s/100 iters), loss = 0.0341162
I1007 17:10:10.767789  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0341164 (* 1 = 0.0341164 loss)
I1007 17:10:10.767796  4982 sgd_solver.cpp:105] Iteration 83400, lr = 0.001
I1007 17:10:18.689803  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:10:19.024303  4982 solver.cpp:330] Iteration 83500, Testing net (#0)
I1007 17:10:20.957058  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:10:21.038213  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9078
I1007 17:10:21.038238  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.370221 (* 1 = 0.370221 loss)
I1007 17:10:21.121706  4982 solver.cpp:218] Iteration 83500 (9.65821 iter/s, 10.3539s/100 iters), loss = 0.0239044
I1007 17:10:21.121732  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0239047 (* 1 = 0.0239047 loss)
I1007 17:10:21.121739  4982 sgd_solver.cpp:105] Iteration 83500, lr = 0.001
I1007 17:10:29.465811  4982 solver.cpp:218] Iteration 83600 (11.9846 iter/s, 8.34405s/100 iters), loss = 0.00395991
I1007 17:10:29.465960  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00396016 (* 1 = 0.00396016 loss)
I1007 17:10:29.465978  4982 sgd_solver.cpp:105] Iteration 83600, lr = 0.001
I1007 17:10:37.794142  4982 solver.cpp:218] Iteration 83700 (12.0075 iter/s, 8.32816s/100 iters), loss = 0.0152526
I1007 17:10:37.794178  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0152529 (* 1 = 0.0152529 loss)
I1007 17:10:37.794186  4982 sgd_solver.cpp:105] Iteration 83700, lr = 0.001
I1007 17:10:46.138815  4982 solver.cpp:218] Iteration 83800 (11.9838 iter/s, 8.34461s/100 iters), loss = 0.0229771
I1007 17:10:46.138845  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0229774 (* 1 = 0.0229774 loss)
I1007 17:10:46.138851  4982 sgd_solver.cpp:105] Iteration 83800, lr = 0.001
I1007 17:10:54.479725  4982 solver.cpp:218] Iteration 83900 (11.9892 iter/s, 8.34085s/100 iters), loss = 0.00841492
I1007 17:10:54.479758  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00841518 (* 1 = 0.00841518 loss)
I1007 17:10:54.479763  4982 sgd_solver.cpp:105] Iteration 83900, lr = 0.001
I1007 17:11:02.403511  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:11:02.737186  4982 solver.cpp:330] Iteration 84000, Testing net (#0)
I1007 17:11:04.667356  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:11:04.748919  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9089
I1007 17:11:04.748958  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.367061 (* 1 = 0.367061 loss)
I1007 17:11:04.830791  4982 solver.cpp:218] Iteration 84000 (9.6609 iter/s, 10.351s/100 iters), loss = 0.00563133
I1007 17:11:04.830821  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00563157 (* 1 = 0.00563157 loss)
I1007 17:11:04.830831  4982 sgd_solver.cpp:105] Iteration 84000, lr = 0.001
I1007 17:11:13.162084  4982 solver.cpp:218] Iteration 84100 (12.003 iter/s, 8.33124s/100 iters), loss = 0.00117358
I1007 17:11:13.162127  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00117383 (* 1 = 0.00117383 loss)
I1007 17:11:13.162132  4982 sgd_solver.cpp:105] Iteration 84100, lr = 0.001
I1007 17:11:21.500643  4982 solver.cpp:218] Iteration 84200 (11.9926 iter/s, 8.33849s/100 iters), loss = 0.0143039
I1007 17:11:21.500672  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0143041 (* 1 = 0.0143041 loss)
I1007 17:11:21.500679  4982 sgd_solver.cpp:105] Iteration 84200, lr = 0.001
I1007 17:11:29.832150  4982 solver.cpp:218] Iteration 84300 (12.0027 iter/s, 8.33145s/100 iters), loss = 0.00663976
I1007 17:11:29.832180  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00664001 (* 1 = 0.00664001 loss)
I1007 17:11:29.832186  4982 sgd_solver.cpp:105] Iteration 84300, lr = 0.001
I1007 17:11:38.166487  4982 solver.cpp:218] Iteration 84400 (11.9986 iter/s, 8.33428s/100 iters), loss = 0.00719743
I1007 17:11:38.166584  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00719768 (* 1 = 0.00719768 loss)
I1007 17:11:38.166601  4982 sgd_solver.cpp:105] Iteration 84400, lr = 0.001
I1007 17:11:46.086192  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:11:46.420104  4982 solver.cpp:330] Iteration 84500, Testing net (#0)
I1007 17:11:48.351438  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:11:48.431964  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9091
I1007 17:11:48.432006  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.370966 (* 1 = 0.370966 loss)
I1007 17:11:48.514971  4982 solver.cpp:218] Iteration 84500 (9.66337 iter/s, 10.3484s/100 iters), loss = 0.00662614
I1007 17:11:48.515003  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0066264 (* 1 = 0.0066264 loss)
I1007 17:11:48.515012  4982 sgd_solver.cpp:105] Iteration 84500, lr = 0.001
I1007 17:11:56.840142  4982 solver.cpp:218] Iteration 84600 (12.0118 iter/s, 8.32511s/100 iters), loss = 0.00330536
I1007 17:11:56.840173  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00330562 (* 1 = 0.00330562 loss)
I1007 17:11:56.840178  4982 sgd_solver.cpp:105] Iteration 84600, lr = 0.001
I1007 17:12:05.168233  4982 solver.cpp:218] Iteration 84700 (12.0076 iter/s, 8.32804s/100 iters), loss = 0.0115816
I1007 17:12:05.168274  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0115819 (* 1 = 0.0115819 loss)
I1007 17:12:05.168280  4982 sgd_solver.cpp:105] Iteration 84700, lr = 0.001
I1007 17:12:13.499815  4982 solver.cpp:218] Iteration 84800 (12.0026 iter/s, 8.33151s/100 iters), loss = 0.00641091
I1007 17:12:13.499961  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00641116 (* 1 = 0.00641116 loss)
I1007 17:12:13.499969  4982 sgd_solver.cpp:105] Iteration 84800, lr = 0.001
I1007 17:12:21.824898  4982 solver.cpp:218] Iteration 84900 (12.0121 iter/s, 8.32491s/100 iters), loss = 0.00530321
I1007 17:12:21.824928  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00530346 (* 1 = 0.00530346 loss)
I1007 17:12:21.824934  4982 sgd_solver.cpp:105] Iteration 84900, lr = 0.001
I1007 17:12:29.743919  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:12:30.078294  4982 solver.cpp:330] Iteration 85000, Testing net (#0)
I1007 17:12:32.010591  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:12:32.091821  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9078
I1007 17:12:32.091857  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.376109 (* 1 = 0.376109 loss)
I1007 17:12:32.174525  4982 solver.cpp:218] Iteration 85000 (9.66224 iter/s, 10.3496s/100 iters), loss = 0.00283209
I1007 17:12:32.174552  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00283234 (* 1 = 0.00283234 loss)
I1007 17:12:32.174559  4982 sgd_solver.cpp:105] Iteration 85000, lr = 0.001
I1007 17:12:40.509588  4982 solver.cpp:218] Iteration 85100 (11.9976 iter/s, 8.33501s/100 iters), loss = 0.00795757
I1007 17:12:40.509618  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00795781 (* 1 = 0.00795781 loss)
I1007 17:12:40.509623  4982 sgd_solver.cpp:105] Iteration 85100, lr = 0.001
I1007 17:12:48.849449  4982 solver.cpp:218] Iteration 85200 (11.9907 iter/s, 8.3398s/100 iters), loss = 0.011573
I1007 17:12:48.849612  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0115732 (* 1 = 0.0115732 loss)
I1007 17:12:48.849620  4982 sgd_solver.cpp:105] Iteration 85200, lr = 0.001
I1007 17:12:57.174572  4982 solver.cpp:218] Iteration 85300 (12.0121 iter/s, 8.32494s/100 iters), loss = 0.0064817
I1007 17:12:57.174603  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00648195 (* 1 = 0.00648195 loss)
I1007 17:12:57.174609  4982 sgd_solver.cpp:105] Iteration 85300, lr = 0.001
I1007 17:13:05.509506  4982 solver.cpp:218] Iteration 85400 (11.9978 iter/s, 8.33488s/100 iters), loss = 0.0116788
I1007 17:13:05.509536  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0116791 (* 1 = 0.0116791 loss)
I1007 17:13:05.509542  4982 sgd_solver.cpp:105] Iteration 85400, lr = 0.001
I1007 17:13:13.427700  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:13:13.761713  4982 solver.cpp:330] Iteration 85500, Testing net (#0)
I1007 17:13:15.693848  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:13:15.774305  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9079
I1007 17:13:15.774341  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.373344 (* 1 = 0.373344 loss)
I1007 17:13:15.857916  4982 solver.cpp:218] Iteration 85500 (9.66338 iter/s, 10.3483s/100 iters), loss = 0.00615736
I1007 17:13:15.857945  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00615761 (* 1 = 0.00615761 loss)
I1007 17:13:15.857952  4982 sgd_solver.cpp:105] Iteration 85500, lr = 0.001
I1007 17:13:24.195183  4982 solver.cpp:218] Iteration 85600 (11.9944 iter/s, 8.33721s/100 iters), loss = 0.00279427
I1007 17:13:24.195283  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00279452 (* 1 = 0.00279452 loss)
I1007 17:13:24.195291  4982 sgd_solver.cpp:105] Iteration 85600, lr = 0.001
I1007 17:13:32.523561  4982 solver.cpp:218] Iteration 85700 (12.0073 iter/s, 8.32825s/100 iters), loss = 0.0128233
I1007 17:13:32.523591  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0128236 (* 1 = 0.0128236 loss)
I1007 17:13:32.523597  4982 sgd_solver.cpp:105] Iteration 85700, lr = 0.001
I1007 17:13:40.854099  4982 solver.cpp:218] Iteration 85800 (12.0041 iter/s, 8.33048s/100 iters), loss = 0.00448004
I1007 17:13:40.854140  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00448029 (* 1 = 0.00448029 loss)
I1007 17:13:40.854146  4982 sgd_solver.cpp:105] Iteration 85800, lr = 0.001
I1007 17:13:49.180227  4982 solver.cpp:218] Iteration 85900 (12.0105 iter/s, 8.32606s/100 iters), loss = 0.00753145
I1007 17:13:49.180256  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0075317 (* 1 = 0.0075317 loss)
I1007 17:13:49.180263  4982 sgd_solver.cpp:105] Iteration 85900, lr = 0.001
I1007 17:13:57.101831  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:13:57.434306  4982 solver.cpp:330] Iteration 86000, Testing net (#0)
I1007 17:13:59.367923  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:13:59.449400  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9088
I1007 17:13:59.449435  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.365769 (* 1 = 0.365769 loss)
I1007 17:13:59.532071  4982 solver.cpp:218] Iteration 86000 (9.66017 iter/s, 10.3518s/100 iters), loss = 0.00360556
I1007 17:13:59.532102  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00360582 (* 1 = 0.00360582 loss)
I1007 17:13:59.532109  4982 sgd_solver.cpp:105] Iteration 86000, lr = 0.001
I1007 17:14:07.864969  4982 solver.cpp:218] Iteration 86100 (12.0007 iter/s, 8.33284s/100 iters), loss = 0.00337677
I1007 17:14:07.865010  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00337704 (* 1 = 0.00337704 loss)
I1007 17:14:07.865016  4982 sgd_solver.cpp:105] Iteration 86100, lr = 0.001
I1007 17:14:16.197906  4982 solver.cpp:218] Iteration 86200 (12.0007 iter/s, 8.33287s/100 iters), loss = 0.0153439
I1007 17:14:16.197947  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0153442 (* 1 = 0.0153442 loss)
I1007 17:14:16.197952  4982 sgd_solver.cpp:105] Iteration 86200, lr = 0.001
I1007 17:14:24.526041  4982 solver.cpp:218] Iteration 86300 (12.0076 iter/s, 8.32807s/100 iters), loss = 0.036638
I1007 17:14:24.526072  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0366383 (* 1 = 0.0366383 loss)
I1007 17:14:24.526078  4982 sgd_solver.cpp:105] Iteration 86300, lr = 0.001
I1007 17:14:32.855916  4982 solver.cpp:218] Iteration 86400 (12.0051 iter/s, 8.32982s/100 iters), loss = 0.00722967
I1007 17:14:32.856045  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00722994 (* 1 = 0.00722994 loss)
I1007 17:14:32.856052  4982 sgd_solver.cpp:105] Iteration 86400, lr = 0.001
I1007 17:14:40.776754  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:14:41.109683  4982 solver.cpp:330] Iteration 86500, Testing net (#0)
I1007 17:14:43.041450  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:14:43.121999  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9089
I1007 17:14:43.122033  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.368441 (* 1 = 0.368441 loss)
I1007 17:14:43.205523  4982 solver.cpp:218] Iteration 86500 (9.66235 iter/s, 10.3494s/100 iters), loss = 0.0115938
I1007 17:14:43.205549  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0115941 (* 1 = 0.0115941 loss)
I1007 17:14:43.205556  4982 sgd_solver.cpp:105] Iteration 86500, lr = 0.001
I1007 17:14:51.551030  4982 solver.cpp:218] Iteration 86600 (11.9826 iter/s, 8.34545s/100 iters), loss = 0.00347913
I1007 17:14:51.551059  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00347939 (* 1 = 0.00347939 loss)
I1007 17:14:51.551075  4982 sgd_solver.cpp:105] Iteration 86600, lr = 0.001
I1007 17:14:59.886961  4982 solver.cpp:218] Iteration 86700 (11.9963 iter/s, 8.33587s/100 iters), loss = 0.0597128
I1007 17:14:59.886991  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0597131 (* 1 = 0.0597131 loss)
I1007 17:14:59.887007  4982 sgd_solver.cpp:105] Iteration 86700, lr = 0.001
I1007 17:15:08.229174  4982 solver.cpp:218] Iteration 86800 (11.9873 iter/s, 8.34216s/100 iters), loss = 0.00268474
I1007 17:15:08.229262  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00268498 (* 1 = 0.00268498 loss)
I1007 17:15:08.229279  4982 sgd_solver.cpp:105] Iteration 86800, lr = 0.001
I1007 17:15:16.567714  4982 solver.cpp:218] Iteration 86900 (11.9927 iter/s, 8.33843s/100 iters), loss = 0.0084616
I1007 17:15:16.567744  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00846185 (* 1 = 0.00846185 loss)
I1007 17:15:16.567759  4982 sgd_solver.cpp:105] Iteration 86900, lr = 0.001
I1007 17:15:24.493343  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:15:24.826779  4982 solver.cpp:330] Iteration 87000, Testing net (#0)
I1007 17:15:26.757689  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:15:26.839191  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9087
I1007 17:15:26.839226  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.370993 (* 1 = 0.370993 loss)
I1007 17:15:26.921747  4982 solver.cpp:218] Iteration 87000 (9.65813 iter/s, 10.354s/100 iters), loss = 0.00225248
I1007 17:15:26.921773  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00225273 (* 1 = 0.00225273 loss)
I1007 17:15:26.921780  4982 sgd_solver.cpp:105] Iteration 87000, lr = 0.001
I1007 17:15:35.259740  4982 solver.cpp:218] Iteration 87100 (11.9934 iter/s, 8.33794s/100 iters), loss = 0.00369234
I1007 17:15:35.259780  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0036926 (* 1 = 0.0036926 loss)
I1007 17:15:35.259786  4982 sgd_solver.cpp:105] Iteration 87100, lr = 0.001
I1007 17:15:43.598995  4982 solver.cpp:218] Iteration 87200 (11.9916 iter/s, 8.33919s/100 iters), loss = 0.0154937
I1007 17:15:43.599156  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.015494 (* 1 = 0.015494 loss)
I1007 17:15:43.599170  4982 sgd_solver.cpp:105] Iteration 87200, lr = 0.001
I1007 17:15:51.933874  4982 solver.cpp:218] Iteration 87300 (11.998 iter/s, 8.3347s/100 iters), loss = 0.00367591
I1007 17:15:51.933915  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00367617 (* 1 = 0.00367617 loss)
I1007 17:15:51.933921  4982 sgd_solver.cpp:105] Iteration 87300, lr = 0.001
I1007 17:16:00.277256  4982 solver.cpp:218] Iteration 87400 (11.9856 iter/s, 8.34331s/100 iters), loss = 0.0249326
I1007 17:16:00.277288  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0249329 (* 1 = 0.0249329 loss)
I1007 17:16:00.277295  4982 sgd_solver.cpp:105] Iteration 87400, lr = 0.001
I1007 17:16:08.198376  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:16:08.532301  4982 solver.cpp:330] Iteration 87500, Testing net (#0)
I1007 17:16:10.466048  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:16:10.546922  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9087
I1007 17:16:10.546958  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.369306 (* 1 = 0.369306 loss)
I1007 17:16:10.630985  4982 solver.cpp:218] Iteration 87500 (9.65842 iter/s, 10.3537s/100 iters), loss = 0.00782809
I1007 17:16:10.631012  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00782835 (* 1 = 0.00782835 loss)
I1007 17:16:10.631018  4982 sgd_solver.cpp:105] Iteration 87500, lr = 0.001
I1007 17:16:18.975492  4982 solver.cpp:218] Iteration 87600 (11.9841 iter/s, 8.34442s/100 iters), loss = 0.0104443
I1007 17:16:18.975605  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0104446 (* 1 = 0.0104446 loss)
I1007 17:16:18.975612  4982 sgd_solver.cpp:105] Iteration 87600, lr = 0.001
I1007 17:16:27.311276  4982 solver.cpp:218] Iteration 87700 (11.9967 iter/s, 8.33565s/100 iters), loss = 0.0147038
I1007 17:16:27.311307  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0147041 (* 1 = 0.0147041 loss)
I1007 17:16:27.311314  4982 sgd_solver.cpp:105] Iteration 87700, lr = 0.001
I1007 17:16:35.652618  4982 solver.cpp:218] Iteration 87800 (11.9886 iter/s, 8.34128s/100 iters), loss = 0.020238
I1007 17:16:35.652658  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0202382 (* 1 = 0.0202382 loss)
I1007 17:16:35.652664  4982 sgd_solver.cpp:105] Iteration 87800, lr = 0.001
I1007 17:16:43.984344  4982 solver.cpp:218] Iteration 87900 (12.0024 iter/s, 8.33166s/100 iters), loss = 0.0250622
I1007 17:16:43.984385  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0250625 (* 1 = 0.0250625 loss)
I1007 17:16:43.984390  4982 sgd_solver.cpp:105] Iteration 87900, lr = 0.001
I1007 17:16:51.910498  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:16:52.243774  4982 solver.cpp:330] Iteration 88000, Testing net (#0)
I1007 17:16:54.177498  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:16:54.259306  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9103
I1007 17:16:54.259342  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.369238 (* 1 = 0.369238 loss)
I1007 17:16:54.342164  4982 solver.cpp:218] Iteration 88000 (9.65461 iter/s, 10.3577s/100 iters), loss = 0.00794897
I1007 17:16:54.342188  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00794923 (* 1 = 0.00794923 loss)
I1007 17:16:54.342195  4982 sgd_solver.cpp:105] Iteration 88000, lr = 0.001
I1007 17:17:02.672904  4982 solver.cpp:218] Iteration 88100 (12.0038 iter/s, 8.33069s/100 iters), loss = 0.00369185
I1007 17:17:02.672945  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00369211 (* 1 = 0.00369211 loss)
I1007 17:17:02.672951  4982 sgd_solver.cpp:105] Iteration 88100, lr = 0.001
I1007 17:17:11.010046  4982 solver.cpp:218] Iteration 88200 (11.9946 iter/s, 8.33708s/100 iters), loss = 0.0144219
I1007 17:17:11.010076  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0144221 (* 1 = 0.0144221 loss)
I1007 17:17:11.010082  4982 sgd_solver.cpp:105] Iteration 88200, lr = 0.001
I1007 17:17:19.339380  4982 solver.cpp:218] Iteration 88300 (12.0058 iter/s, 8.32928s/100 iters), loss = 0.00600123
I1007 17:17:19.339411  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00600149 (* 1 = 0.00600149 loss)
I1007 17:17:19.339416  4982 sgd_solver.cpp:105] Iteration 88300, lr = 0.001
I1007 17:17:27.675004  4982 solver.cpp:218] Iteration 88400 (11.9968 iter/s, 8.33557s/100 iters), loss = 0.0176713
I1007 17:17:27.675169  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0176716 (* 1 = 0.0176716 loss)
I1007 17:17:27.675180  4982 sgd_solver.cpp:105] Iteration 88400, lr = 0.001
I1007 17:17:35.593875  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:17:35.927460  4982 solver.cpp:330] Iteration 88500, Testing net (#0)
I1007 17:17:37.858781  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:17:37.939460  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9096
I1007 17:17:37.939493  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.370521 (* 1 = 0.370521 loss)
I1007 17:17:38.023366  4982 solver.cpp:218] Iteration 88500 (9.66353 iter/s, 10.3482s/100 iters), loss = 0.0137055
I1007 17:17:38.023401  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0137058 (* 1 = 0.0137058 loss)
I1007 17:17:38.023406  4982 sgd_solver.cpp:105] Iteration 88500, lr = 0.001
I1007 17:17:46.359326  4982 solver.cpp:218] Iteration 88600 (11.9963 iter/s, 8.3359s/100 iters), loss = 0.00752496
I1007 17:17:46.359355  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0075252 (* 1 = 0.0075252 loss)
I1007 17:17:46.359361  4982 sgd_solver.cpp:105] Iteration 88600, lr = 0.001
I1007 17:17:54.688068  4982 solver.cpp:218] Iteration 88700 (12.0067 iter/s, 8.32869s/100 iters), loss = 0.00645804
I1007 17:17:54.688109  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00645828 (* 1 = 0.00645828 loss)
I1007 17:17:54.688115  4982 sgd_solver.cpp:105] Iteration 88700, lr = 0.001
I1007 17:18:03.024255  4982 solver.cpp:218] Iteration 88800 (11.996 iter/s, 8.33612s/100 iters), loss = 0.0100541
I1007 17:18:03.024358  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0100544 (* 1 = 0.0100544 loss)
I1007 17:18:03.024365  4982 sgd_solver.cpp:105] Iteration 88800, lr = 0.001
I1007 17:18:11.355492  4982 solver.cpp:218] Iteration 88900 (12.0032 iter/s, 8.33111s/100 iters), loss = 0.0175015
I1007 17:18:11.355522  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0175018 (* 1 = 0.0175018 loss)
I1007 17:18:11.355527  4982 sgd_solver.cpp:105] Iteration 88900, lr = 0.001
I1007 17:18:19.273314  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:18:19.606274  4982 solver.cpp:330] Iteration 89000, Testing net (#0)
I1007 17:18:21.538235  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:18:21.619577  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9101
I1007 17:18:21.619603  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.368315 (* 1 = 0.368315 loss)
I1007 17:18:21.702286  4982 solver.cpp:218] Iteration 89000 (9.66489 iter/s, 10.3467s/100 iters), loss = 0.00566173
I1007 17:18:21.702309  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00566196 (* 1 = 0.00566196 loss)
I1007 17:18:21.702316  4982 sgd_solver.cpp:105] Iteration 89000, lr = 0.001
I1007 17:18:30.037853  4982 solver.cpp:218] Iteration 89100 (11.9969 iter/s, 8.33552s/100 iters), loss = 0.0024009
I1007 17:18:30.037894  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00240113 (* 1 = 0.00240113 loss)
I1007 17:18:30.037899  4982 sgd_solver.cpp:105] Iteration 89100, lr = 0.001
I1007 17:18:38.380719  4982 solver.cpp:218] Iteration 89200 (11.9864 iter/s, 8.3428s/100 iters), loss = 0.0159503
I1007 17:18:38.380878  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0159505 (* 1 = 0.0159505 loss)
I1007 17:18:38.380888  4982 sgd_solver.cpp:105] Iteration 89200, lr = 0.001
I1007 17:18:46.719290  4982 solver.cpp:218] Iteration 89300 (11.9927 iter/s, 8.33839s/100 iters), loss = 0.00858565
I1007 17:18:46.719331  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00858588 (* 1 = 0.00858588 loss)
I1007 17:18:46.719336  4982 sgd_solver.cpp:105] Iteration 89300, lr = 0.001
I1007 17:18:55.061725  4982 solver.cpp:218] Iteration 89400 (11.987 iter/s, 8.34237s/100 iters), loss = 0.00234963
I1007 17:18:55.061755  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00234986 (* 1 = 0.00234986 loss)
I1007 17:18:55.061761  4982 sgd_solver.cpp:105] Iteration 89400, lr = 0.001
I1007 17:19:02.986150  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:19:03.319983  4982 solver.cpp:330] Iteration 89500, Testing net (#0)
I1007 17:19:05.253125  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:19:05.334146  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9089
I1007 17:19:05.334183  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.369391 (* 1 = 0.369391 loss)
I1007 17:19:05.417479  4982 solver.cpp:218] Iteration 89500 (9.65653 iter/s, 10.3557s/100 iters), loss = 0.00410904
I1007 17:19:05.417506  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00410928 (* 1 = 0.00410928 loss)
I1007 17:19:05.417513  4982 sgd_solver.cpp:105] Iteration 89500, lr = 0.001
I1007 17:19:13.752768  4982 solver.cpp:218] Iteration 89600 (11.9973 iter/s, 8.33523s/100 iters), loss = 0.000977753
I1007 17:19:13.752904  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000977992 (* 1 = 0.000977992 loss)
I1007 17:19:13.752912  4982 sgd_solver.cpp:105] Iteration 89600, lr = 0.001
I1007 17:19:22.085973  4982 solver.cpp:218] Iteration 89700 (12.0004 iter/s, 8.33305s/100 iters), loss = 0.00306202
I1007 17:19:22.086004  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00306226 (* 1 = 0.00306226 loss)
I1007 17:19:22.086009  4982 sgd_solver.cpp:105] Iteration 89700, lr = 0.001
I1007 17:19:30.413758  4982 solver.cpp:218] Iteration 89800 (12.0081 iter/s, 8.32773s/100 iters), loss = 0.00550918
I1007 17:19:30.413787  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00550942 (* 1 = 0.00550942 loss)
I1007 17:19:30.413794  4982 sgd_solver.cpp:105] Iteration 89800, lr = 0.001
I1007 17:19:38.742537  4982 solver.cpp:218] Iteration 89900 (12.0066 iter/s, 8.32872s/100 iters), loss = 0.03272
I1007 17:19:38.742578  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0327203 (* 1 = 0.0327203 loss)
I1007 17:19:38.742583  4982 sgd_solver.cpp:105] Iteration 89900, lr = 0.001
I1007 17:19:46.668647  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:19:47.002071  4982 solver.cpp:330] Iteration 90000, Testing net (#0)
I1007 17:19:48.932463  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:19:49.013644  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9098
I1007 17:19:49.013679  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.372018 (* 1 = 0.372018 loss)
I1007 17:19:49.096448  4982 solver.cpp:218] Iteration 90000 (9.65825 iter/s, 10.3538s/100 iters), loss = 0.00519925
I1007 17:19:49.096475  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00519949 (* 1 = 0.00519949 loss)
I1007 17:19:49.096482  4982 sgd_solver.cpp:105] Iteration 90000, lr = 0.001
I1007 17:19:57.431547  4982 solver.cpp:218] Iteration 90100 (11.9975 iter/s, 8.33504s/100 iters), loss = 0.00126587
I1007 17:19:57.431577  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00126611 (* 1 = 0.00126611 loss)
I1007 17:19:57.431583  4982 sgd_solver.cpp:105] Iteration 90100, lr = 0.001
I1007 17:20:05.772572  4982 solver.cpp:218] Iteration 90200 (11.989 iter/s, 8.34097s/100 iters), loss = 0.0160649
I1007 17:20:05.772613  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0160651 (* 1 = 0.0160651 loss)
I1007 17:20:05.772617  4982 sgd_solver.cpp:105] Iteration 90200, lr = 0.001
I1007 17:20:14.111064  4982 solver.cpp:218] Iteration 90300 (11.9927 iter/s, 8.33843s/100 iters), loss = 0.00437095
I1007 17:20:14.111094  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0043712 (* 1 = 0.0043712 loss)
I1007 17:20:14.111100  4982 sgd_solver.cpp:105] Iteration 90300, lr = 0.001
I1007 17:20:22.451812  4982 solver.cpp:218] Iteration 90400 (11.9894 iter/s, 8.34069s/100 iters), loss = 0.0220975
I1007 17:20:22.451928  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0220977 (* 1 = 0.0220977 loss)
I1007 17:20:22.451936  4982 sgd_solver.cpp:105] Iteration 90400, lr = 0.001
I1007 17:20:30.377949  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:20:30.711695  4982 solver.cpp:330] Iteration 90500, Testing net (#0)
I1007 17:20:32.643682  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:20:32.724556  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9099
I1007 17:20:32.724592  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.376679 (* 1 = 0.376679 loss)
I1007 17:20:32.808048  4982 solver.cpp:218] Iteration 90500 (9.65615 iter/s, 10.3561s/100 iters), loss = 0.00582862
I1007 17:20:32.808076  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00582888 (* 1 = 0.00582888 loss)
I1007 17:20:32.808082  4982 sgd_solver.cpp:105] Iteration 90500, lr = 0.001
I1007 17:20:41.148536  4982 solver.cpp:218] Iteration 90600 (11.9898 iter/s, 8.34043s/100 iters), loss = 0.00748352
I1007 17:20:41.148566  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00748377 (* 1 = 0.00748377 loss)
I1007 17:20:41.148571  4982 sgd_solver.cpp:105] Iteration 90600, lr = 0.001
I1007 17:20:49.477409  4982 solver.cpp:218] Iteration 90700 (12.0065 iter/s, 8.32882s/100 iters), loss = 0.00819817
I1007 17:20:49.477450  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00819842 (* 1 = 0.00819842 loss)
I1007 17:20:49.477457  4982 sgd_solver.cpp:105] Iteration 90700, lr = 0.001
I1007 17:20:57.813593  4982 solver.cpp:218] Iteration 90800 (11.996 iter/s, 8.33611s/100 iters), loss = 0.013952
I1007 17:20:57.813732  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0139522 (* 1 = 0.0139522 loss)
I1007 17:20:57.813740  4982 sgd_solver.cpp:105] Iteration 90800, lr = 0.001
I1007 17:21:06.147238  4982 solver.cpp:218] Iteration 90900 (11.9998 iter/s, 8.33349s/100 iters), loss = 0.0142828
I1007 17:21:06.147279  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.014283 (* 1 = 0.014283 loss)
I1007 17:21:06.147284  4982 sgd_solver.cpp:105] Iteration 90900, lr = 0.001
I1007 17:21:14.064913  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:21:14.398458  4982 solver.cpp:330] Iteration 91000, Testing net (#0)
I1007 17:21:16.330358  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:21:16.412014  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9098
I1007 17:21:16.412050  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.370284 (* 1 = 0.370284 loss)
I1007 17:21:16.494379  4982 solver.cpp:218] Iteration 91000 (9.66457 iter/s, 10.3471s/100 iters), loss = 0.00197505
I1007 17:21:16.494412  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00197531 (* 1 = 0.00197531 loss)
I1007 17:21:16.494419  4982 sgd_solver.cpp:105] Iteration 91000, lr = 0.001
I1007 17:21:24.873826  4982 solver.cpp:218] Iteration 91100 (11.934 iter/s, 8.37939s/100 iters), loss = 0.00662273
I1007 17:21:24.873867  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00662299 (* 1 = 0.00662299 loss)
I1007 17:21:24.873872  4982 sgd_solver.cpp:105] Iteration 91100, lr = 0.001
I1007 17:21:33.250085  4982 solver.cpp:218] Iteration 91200 (11.9386 iter/s, 8.37619s/100 iters), loss = 0.00327141
I1007 17:21:33.250229  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00327166 (* 1 = 0.00327166 loss)
I1007 17:21:33.250237  4982 sgd_solver.cpp:105] Iteration 91200, lr = 0.001
I1007 17:21:41.585983  4982 solver.cpp:218] Iteration 91300 (11.9966 iter/s, 8.33573s/100 iters), loss = 0.00503836
I1007 17:21:41.586025  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00503861 (* 1 = 0.00503861 loss)
I1007 17:21:41.586031  4982 sgd_solver.cpp:105] Iteration 91300, lr = 0.001
I1007 17:21:49.927264  4982 solver.cpp:218] Iteration 91400 (11.9887 iter/s, 8.34121s/100 iters), loss = 0.00428659
I1007 17:21:49.927305  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00428685 (* 1 = 0.00428685 loss)
I1007 17:21:49.927311  4982 sgd_solver.cpp:105] Iteration 91400, lr = 0.001
I1007 17:21:57.848644  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:21:58.183162  4982 solver.cpp:330] Iteration 91500, Testing net (#0)
I1007 17:22:00.117769  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:22:00.198801  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9099
I1007 17:22:00.198827  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.367063 (* 1 = 0.367063 loss)
I1007 17:22:00.282246  4982 solver.cpp:218] Iteration 91500 (9.65726 iter/s, 10.3549s/100 iters), loss = 0.00569618
I1007 17:22:00.282279  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00569643 (* 1 = 0.00569643 loss)
I1007 17:22:00.282285  4982 sgd_solver.cpp:105] Iteration 91500, lr = 0.001
I1007 17:22:08.617067  4982 solver.cpp:218] Iteration 91600 (11.998 iter/s, 8.33473s/100 iters), loss = 0.0087002
I1007 17:22:08.617156  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00870045 (* 1 = 0.00870045 loss)
I1007 17:22:08.617173  4982 sgd_solver.cpp:105] Iteration 91600, lr = 0.001
I1007 17:22:16.944347  4982 solver.cpp:218] Iteration 91700 (12.0089 iter/s, 8.32717s/100 iters), loss = 0.0161474
I1007 17:22:16.944388  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0161477 (* 1 = 0.0161477 loss)
I1007 17:22:16.944394  4982 sgd_solver.cpp:105] Iteration 91700, lr = 0.001
I1007 17:22:25.274999  4982 solver.cpp:218] Iteration 91800 (12.004 iter/s, 8.33058s/100 iters), loss = 0.0230698
I1007 17:22:25.275029  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.02307 (* 1 = 0.02307 loss)
I1007 17:22:25.275035  4982 sgd_solver.cpp:105] Iteration 91800, lr = 0.001
I1007 17:22:33.605048  4982 solver.cpp:218] Iteration 91900 (12.0048 iter/s, 8.32999s/100 iters), loss = 0.00195259
I1007 17:22:33.605089  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00195284 (* 1 = 0.00195284 loss)
I1007 17:22:33.605095  4982 sgd_solver.cpp:105] Iteration 91900, lr = 0.001
I1007 17:22:41.524895  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:22:41.858839  4982 solver.cpp:330] Iteration 92000, Testing net (#0)
I1007 17:22:43.790889  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:22:43.872140  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9106
I1007 17:22:43.872176  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.367822 (* 1 = 0.367822 loss)
I1007 17:22:43.955256  4982 solver.cpp:218] Iteration 92000 (9.66171 iter/s, 10.3501s/100 iters), loss = 0.0119488
I1007 17:22:43.955282  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.011949 (* 1 = 0.011949 loss)
I1007 17:22:43.955289  4982 sgd_solver.cpp:105] Iteration 92000, lr = 0.001
I1007 17:22:52.294096  4982 solver.cpp:218] Iteration 92100 (11.9922 iter/s, 8.33879s/100 iters), loss = 0.00299776
I1007 17:22:52.294137  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00299802 (* 1 = 0.00299802 loss)
I1007 17:22:52.294143  4982 sgd_solver.cpp:105] Iteration 92100, lr = 0.001
I1007 17:23:00.635622  4982 solver.cpp:218] Iteration 92200 (11.9883 iter/s, 8.34146s/100 iters), loss = 0.0263587
I1007 17:23:00.635663  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.026359 (* 1 = 0.026359 loss)
I1007 17:23:00.635668  4982 sgd_solver.cpp:105] Iteration 92200, lr = 0.001
I1007 17:23:08.971726  4982 solver.cpp:218] Iteration 92300 (11.9961 iter/s, 8.33604s/100 iters), loss = 0.00632921
I1007 17:23:08.971755  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00632948 (* 1 = 0.00632948 loss)
I1007 17:23:08.971760  4982 sgd_solver.cpp:105] Iteration 92300, lr = 0.001
I1007 17:23:17.314812  4982 solver.cpp:218] Iteration 92400 (11.9861 iter/s, 8.34303s/100 iters), loss = 0.00839192
I1007 17:23:17.314947  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00839219 (* 1 = 0.00839219 loss)
I1007 17:23:17.314965  4982 sgd_solver.cpp:105] Iteration 92400, lr = 0.001
I1007 17:23:25.239578  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:23:25.572798  4982 solver.cpp:330] Iteration 92500, Testing net (#0)
I1007 17:23:27.505143  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:23:27.585925  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9094
I1007 17:23:27.585963  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.369604 (* 1 = 0.369604 loss)
I1007 17:23:27.669487  4982 solver.cpp:218] Iteration 92500 (9.65762 iter/s, 10.3545s/100 iters), loss = 0.00299705
I1007 17:23:27.669515  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00299731 (* 1 = 0.00299731 loss)
I1007 17:23:27.669522  4982 sgd_solver.cpp:105] Iteration 92500, lr = 0.001
I1007 17:23:36.004523  4982 solver.cpp:218] Iteration 92600 (11.9976 iter/s, 8.33498s/100 iters), loss = 0.0049493
I1007 17:23:36.004552  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00494957 (* 1 = 0.00494957 loss)
I1007 17:23:36.004559  4982 sgd_solver.cpp:105] Iteration 92600, lr = 0.001
I1007 17:23:44.335039  4982 solver.cpp:218] Iteration 92700 (12.0041 iter/s, 8.33046s/100 iters), loss = 0.0368274
I1007 17:23:44.335079  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0368276 (* 1 = 0.0368276 loss)
I1007 17:23:44.335085  4982 sgd_solver.cpp:105] Iteration 92700, lr = 0.001
I1007 17:23:52.671491  4982 solver.cpp:218] Iteration 92800 (11.9956 iter/s, 8.33638s/100 iters), loss = 0.00247622
I1007 17:23:52.671609  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00247648 (* 1 = 0.00247648 loss)
I1007 17:23:52.671625  4982 sgd_solver.cpp:105] Iteration 92800, lr = 0.001
I1007 17:24:01.004407  4982 solver.cpp:218] Iteration 92900 (12.0008 iter/s, 8.33277s/100 iters), loss = 0.00435335
I1007 17:24:01.004439  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00435361 (* 1 = 0.00435361 loss)
I1007 17:24:01.004446  4982 sgd_solver.cpp:105] Iteration 92900, lr = 0.001
I1007 17:24:08.927553  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:24:09.261440  4982 solver.cpp:330] Iteration 93000, Testing net (#0)
I1007 17:24:11.195845  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:24:11.277354  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9105
I1007 17:24:11.277391  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.369839 (* 1 = 0.369839 loss)
I1007 17:24:11.360571  4982 solver.cpp:218] Iteration 93000 (9.65614 iter/s, 10.3561s/100 iters), loss = 0.00346359
I1007 17:24:11.360597  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00346385 (* 1 = 0.00346385 loss)
I1007 17:24:11.360604  4982 sgd_solver.cpp:105] Iteration 93000, lr = 0.001
I1007 17:24:19.695397  4982 solver.cpp:218] Iteration 93100 (11.9979 iter/s, 8.33477s/100 iters), loss = 0.00342758
I1007 17:24:19.695432  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00342784 (* 1 = 0.00342784 loss)
I1007 17:24:19.695441  4982 sgd_solver.cpp:105] Iteration 93100, lr = 0.001
I1007 17:24:28.034235  4982 solver.cpp:218] Iteration 93200 (11.9922 iter/s, 8.33878s/100 iters), loss = 0.00895608
I1007 17:24:28.034358  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00895634 (* 1 = 0.00895634 loss)
I1007 17:24:28.034365  4982 sgd_solver.cpp:105] Iteration 93200, lr = 0.001
I1007 17:24:36.369254  4982 solver.cpp:218] Iteration 93300 (11.9978 iter/s, 8.33488s/100 iters), loss = 0.00545713
I1007 17:24:36.369294  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0054574 (* 1 = 0.0054574 loss)
I1007 17:24:36.369300  4982 sgd_solver.cpp:105] Iteration 93300, lr = 0.001
I1007 17:24:44.708920  4982 solver.cpp:218] Iteration 93400 (11.991 iter/s, 8.3396s/100 iters), loss = 0.00311533
I1007 17:24:44.708952  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0031156 (* 1 = 0.0031156 loss)
I1007 17:24:44.708958  4982 sgd_solver.cpp:105] Iteration 93400, lr = 0.001
I1007 17:24:52.635756  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:24:52.968968  4982 solver.cpp:330] Iteration 93500, Testing net (#0)
I1007 17:24:54.902665  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:24:54.983188  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9113
I1007 17:24:54.983224  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.370201 (* 1 = 0.370201 loss)
I1007 17:24:55.066962  4982 solver.cpp:218] Iteration 93500 (9.65439 iter/s, 10.358s/100 iters), loss = 0.003332
I1007 17:24:55.066988  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00333226 (* 1 = 0.00333226 loss)
I1007 17:24:55.066994  4982 sgd_solver.cpp:105] Iteration 93500, lr = 0.001
I1007 17:25:03.405777  4982 solver.cpp:218] Iteration 93600 (11.9922 iter/s, 8.33876s/100 iters), loss = 0.00119998
I1007 17:25:03.405879  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00120024 (* 1 = 0.00120024 loss)
I1007 17:25:03.405885  4982 sgd_solver.cpp:105] Iteration 93600, lr = 0.001
I1007 17:25:11.739194  4982 solver.cpp:218] Iteration 93700 (12 iter/s, 8.3333s/100 iters), loss = 0.023453
I1007 17:25:11.739241  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0234533 (* 1 = 0.0234533 loss)
I1007 17:25:11.739249  4982 sgd_solver.cpp:105] Iteration 93700, lr = 0.001
I1007 17:25:20.085440  4982 solver.cpp:218] Iteration 93800 (11.9815 iter/s, 8.34617s/100 iters), loss = 0.00728829
I1007 17:25:20.085481  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00728854 (* 1 = 0.00728854 loss)
I1007 17:25:20.085486  4982 sgd_solver.cpp:105] Iteration 93800, lr = 0.001
I1007 17:25:28.427386  4982 solver.cpp:218] Iteration 93900 (11.9877 iter/s, 8.34188s/100 iters), loss = 0.0109391
I1007 17:25:28.427426  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0109394 (* 1 = 0.0109394 loss)
I1007 17:25:28.427433  4982 sgd_solver.cpp:105] Iteration 93900, lr = 0.001
I1007 17:25:36.358810  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:25:36.692477  4982 solver.cpp:330] Iteration 94000, Testing net (#0)
I1007 17:25:38.623791  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:25:38.705243  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9108
I1007 17:25:38.705281  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.370635 (* 1 = 0.370635 loss)
I1007 17:25:38.788182  4982 solver.cpp:218] Iteration 94000 (9.65183 iter/s, 10.3607s/100 iters), loss = 0.00112213
I1007 17:25:38.788209  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00112239 (* 1 = 0.00112239 loss)
I1007 17:25:38.788216  4982 sgd_solver.cpp:105] Iteration 94000, lr = 0.001
I1007 17:25:47.127123  4982 solver.cpp:218] Iteration 94100 (11.992 iter/s, 8.33889s/100 iters), loss = 0.0072222
I1007 17:25:47.127166  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00722245 (* 1 = 0.00722245 loss)
I1007 17:25:47.127173  4982 sgd_solver.cpp:105] Iteration 94100, lr = 0.001
I1007 17:25:55.472743  4982 solver.cpp:218] Iteration 94200 (11.9824 iter/s, 8.34555s/100 iters), loss = 0.00223674
I1007 17:25:55.472782  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.002237 (* 1 = 0.002237 loss)
I1007 17:25:55.472790  4982 sgd_solver.cpp:105] Iteration 94200, lr = 0.001
I1007 17:26:03.816866  4982 solver.cpp:218] Iteration 94300 (11.9846 iter/s, 8.34406s/100 iters), loss = 0.0257048
I1007 17:26:03.816896  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.025705 (* 1 = 0.025705 loss)
I1007 17:26:03.816902  4982 sgd_solver.cpp:105] Iteration 94300, lr = 0.001
I1007 17:26:12.154994  4982 solver.cpp:218] Iteration 94400 (11.9932 iter/s, 8.33807s/100 iters), loss = 0.0114122
I1007 17:26:12.155148  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0114125 (* 1 = 0.0114125 loss)
I1007 17:26:12.155158  4982 sgd_solver.cpp:105] Iteration 94400, lr = 0.001
I1007 17:26:20.080745  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:26:20.415091  4982 solver.cpp:330] Iteration 94500, Testing net (#0)
I1007 17:26:22.347882  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:26:22.428289  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9106
I1007 17:26:22.428325  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.371291 (* 1 = 0.371291 loss)
I1007 17:26:22.512073  4982 solver.cpp:218] Iteration 94500 (9.6554 iter/s, 10.3569s/100 iters), loss = 0.00663702
I1007 17:26:22.512102  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00663727 (* 1 = 0.00663727 loss)
I1007 17:26:22.512109  4982 sgd_solver.cpp:105] Iteration 94500, lr = 0.001
I1007 17:26:30.849001  4982 solver.cpp:218] Iteration 94600 (11.9949 iter/s, 8.33687s/100 iters), loss = 0.0125644
I1007 17:26:30.849032  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0125647 (* 1 = 0.0125647 loss)
I1007 17:26:30.849038  4982 sgd_solver.cpp:105] Iteration 94600, lr = 0.001
I1007 17:26:39.173498  4982 solver.cpp:218] Iteration 94700 (12.0128 iter/s, 8.32444s/100 iters), loss = 0.0145305
I1007 17:26:39.173538  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0145308 (* 1 = 0.0145308 loss)
I1007 17:26:39.173544  4982 sgd_solver.cpp:105] Iteration 94700, lr = 0.001
I1007 17:26:47.510102  4982 solver.cpp:218] Iteration 94800 (11.9954 iter/s, 8.33653s/100 iters), loss = 0.00517218
I1007 17:26:47.510223  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00517243 (* 1 = 0.00517243 loss)
I1007 17:26:47.510241  4982 sgd_solver.cpp:105] Iteration 94800, lr = 0.001
I1007 17:26:55.843981  4982 solver.cpp:218] Iteration 94900 (11.9994 iter/s, 8.33373s/100 iters), loss = 0.00567904
I1007 17:26:55.844010  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00567929 (* 1 = 0.00567929 loss)
I1007 17:26:55.844017  4982 sgd_solver.cpp:105] Iteration 94900, lr = 0.001
I1007 17:27:03.764416  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:27:04.098098  4982 solver.cpp:330] Iteration 95000, Testing net (#0)
I1007 17:27:06.030807  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:27:06.112184  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.91
I1007 17:27:06.112221  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.374094 (* 1 = 0.374094 loss)
I1007 17:27:06.194170  4982 solver.cpp:218] Iteration 95000 (9.66172 iter/s, 10.3501s/100 iters), loss = 0.00536206
I1007 17:27:06.194196  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00536232 (* 1 = 0.00536232 loss)
I1007 17:27:06.194202  4982 sgd_solver.cpp:105] Iteration 95000, lr = 0.001
I1007 17:27:14.527762  4982 solver.cpp:218] Iteration 95100 (11.9997 iter/s, 8.33354s/100 iters), loss = 0.00365457
I1007 17:27:14.527793  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00365483 (* 1 = 0.00365483 loss)
I1007 17:27:14.527799  4982 sgd_solver.cpp:105] Iteration 95100, lr = 0.001
I1007 17:27:22.863608  4982 solver.cpp:218] Iteration 95200 (11.9965 iter/s, 8.33579s/100 iters), loss = 0.0320111
I1007 17:27:22.863730  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0320114 (* 1 = 0.0320114 loss)
I1007 17:27:22.863739  4982 sgd_solver.cpp:105] Iteration 95200, lr = 0.001
I1007 17:27:31.198549  4982 solver.cpp:218] Iteration 95300 (11.9979 iter/s, 8.33479s/100 iters), loss = 0.00551948
I1007 17:27:31.198578  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00551974 (* 1 = 0.00551974 loss)
I1007 17:27:31.198585  4982 sgd_solver.cpp:105] Iteration 95300, lr = 0.001
I1007 17:27:39.538655  4982 solver.cpp:218] Iteration 95400 (11.9903 iter/s, 8.34005s/100 iters), loss = 0.00302163
I1007 17:27:39.538686  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0030219 (* 1 = 0.0030219 loss)
I1007 17:27:39.538691  4982 sgd_solver.cpp:105] Iteration 95400, lr = 0.001
I1007 17:27:47.459936  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:27:47.793216  4982 solver.cpp:330] Iteration 95500, Testing net (#0)
I1007 17:27:49.723861  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:27:49.804391  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9107
I1007 17:27:49.804428  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.37123 (* 1 = 0.37123 loss)
I1007 17:27:49.888213  4982 solver.cpp:218] Iteration 95500 (9.66231 iter/s, 10.3495s/100 iters), loss = 0.00186042
I1007 17:27:49.888242  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00186069 (* 1 = 0.00186069 loss)
I1007 17:27:49.888249  4982 sgd_solver.cpp:105] Iteration 95500, lr = 0.001
I1007 17:27:58.230072  4982 solver.cpp:218] Iteration 95600 (11.9878 iter/s, 8.3418s/100 iters), loss = 0.00140464
I1007 17:27:58.230151  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0014049 (* 1 = 0.0014049 loss)
I1007 17:27:58.230170  4982 sgd_solver.cpp:105] Iteration 95600, lr = 0.001
I1007 17:28:06.566740  4982 solver.cpp:218] Iteration 95700 (11.9953 iter/s, 8.33657s/100 iters), loss = 0.0060036
I1007 17:28:06.566771  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00600386 (* 1 = 0.00600386 loss)
I1007 17:28:06.566787  4982 sgd_solver.cpp:105] Iteration 95700, lr = 0.001
I1007 17:28:14.905370  4982 solver.cpp:218] Iteration 95800 (11.9925 iter/s, 8.33857s/100 iters), loss = 0.00602918
I1007 17:28:14.905402  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00602944 (* 1 = 0.00602944 loss)
I1007 17:28:14.905418  4982 sgd_solver.cpp:105] Iteration 95800, lr = 0.001
I1007 17:28:23.242496  4982 solver.cpp:218] Iteration 95900 (11.9946 iter/s, 8.33707s/100 iters), loss = 0.00524441
I1007 17:28:23.242527  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00524468 (* 1 = 0.00524468 loss)
I1007 17:28:23.242544  4982 sgd_solver.cpp:105] Iteration 95900, lr = 0.001
I1007 17:28:31.171387  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:28:31.504688  4982 solver.cpp:330] Iteration 96000, Testing net (#0)
I1007 17:28:33.437598  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:28:33.518767  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9108
I1007 17:28:33.518803  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.372226 (* 1 = 0.372226 loss)
I1007 17:28:33.601318  4982 solver.cpp:218] Iteration 96000 (9.65367 iter/s, 10.3588s/100 iters), loss = 0.00236411
I1007 17:28:33.601343  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00236438 (* 1 = 0.00236438 loss)
I1007 17:28:33.601351  4982 sgd_solver.cpp:105] Iteration 96000, lr = 0.001
I1007 17:28:41.941918  4982 solver.cpp:218] Iteration 96100 (11.9896 iter/s, 8.34055s/100 iters), loss = 0.00160185
I1007 17:28:41.941961  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00160212 (* 1 = 0.00160212 loss)
I1007 17:28:41.941967  4982 sgd_solver.cpp:105] Iteration 96100, lr = 0.001
I1007 17:28:50.289538  4982 solver.cpp:218] Iteration 96200 (11.9796 iter/s, 8.34755s/100 iters), loss = 0.00314432
I1007 17:28:50.289571  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00314459 (* 1 = 0.00314459 loss)
I1007 17:28:50.289577  4982 sgd_solver.cpp:105] Iteration 96200, lr = 0.001
I1007 17:28:58.634505  4982 solver.cpp:218] Iteration 96300 (11.9834 iter/s, 8.34491s/100 iters), loss = 0.00164042
I1007 17:28:58.634544  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00164068 (* 1 = 0.00164068 loss)
I1007 17:28:58.634551  4982 sgd_solver.cpp:105] Iteration 96300, lr = 0.001
I1007 17:29:06.981552  4982 solver.cpp:218] Iteration 96400 (11.9804 iter/s, 8.34698s/100 iters), loss = 0.013939
I1007 17:29:06.981680  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0139392 (* 1 = 0.0139392 loss)
I1007 17:29:06.981688  4982 sgd_solver.cpp:105] Iteration 96400, lr = 0.001
I1007 17:29:14.902869  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:29:15.238037  4982 solver.cpp:330] Iteration 96500, Testing net (#0)
I1007 17:29:17.169419  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:29:17.250228  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9106
I1007 17:29:17.250264  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.371496 (* 1 = 0.371496 loss)
I1007 17:29:17.334555  4982 solver.cpp:218] Iteration 96500 (9.65918 iter/s, 10.3528s/100 iters), loss = 0.013076
I1007 17:29:17.334583  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0130762 (* 1 = 0.0130762 loss)
I1007 17:29:17.334589  4982 sgd_solver.cpp:105] Iteration 96500, lr = 0.001
I1007 17:29:25.680939  4982 solver.cpp:218] Iteration 96600 (11.9813 iter/s, 8.34633s/100 iters), loss = 0.00553363
I1007 17:29:25.680969  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00553389 (* 1 = 0.00553389 loss)
I1007 17:29:25.680975  4982 sgd_solver.cpp:105] Iteration 96600, lr = 0.001
I1007 17:29:34.013319  4982 solver.cpp:218] Iteration 96700 (12.0015 iter/s, 8.33232s/100 iters), loss = 0.0176115
I1007 17:29:34.013350  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0176118 (* 1 = 0.0176118 loss)
I1007 17:29:34.013365  4982 sgd_solver.cpp:105] Iteration 96700, lr = 0.001
I1007 17:29:42.354135  4982 solver.cpp:218] Iteration 96800 (11.9893 iter/s, 8.34076s/100 iters), loss = 0.00492421
I1007 17:29:42.354276  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00492447 (* 1 = 0.00492447 loss)
I1007 17:29:42.354285  4982 sgd_solver.cpp:105] Iteration 96800, lr = 0.001
I1007 17:29:50.691198  4982 solver.cpp:218] Iteration 96900 (11.9949 iter/s, 8.3369s/100 iters), loss = 0.00381718
I1007 17:29:50.691228  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00381744 (* 1 = 0.00381744 loss)
I1007 17:29:50.691234  4982 sgd_solver.cpp:105] Iteration 96900, lr = 0.001
I1007 17:29:58.621465  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:29:58.955494  4982 solver.cpp:330] Iteration 97000, Testing net (#0)
I1007 17:30:00.889991  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:30:00.971456  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9108
I1007 17:30:00.971493  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.372949 (* 1 = 0.372949 loss)
I1007 17:30:01.054339  4982 solver.cpp:218] Iteration 97000 (9.64964 iter/s, 10.3631s/100 iters), loss = 0.01005
I1007 17:30:01.054368  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0100503 (* 1 = 0.0100503 loss)
I1007 17:30:01.054374  4982 sgd_solver.cpp:105] Iteration 97000, lr = 0.001
I1007 17:30:09.392168  4982 solver.cpp:218] Iteration 97100 (11.9936 iter/s, 8.33777s/100 iters), loss = 0.00269925
I1007 17:30:09.392207  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00269951 (* 1 = 0.00269951 loss)
I1007 17:30:09.392213  4982 sgd_solver.cpp:105] Iteration 97100, lr = 0.001
I1007 17:30:17.732206  4982 solver.cpp:218] Iteration 97200 (11.9904 iter/s, 8.33998s/100 iters), loss = 0.0104338
I1007 17:30:17.732359  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.010434 (* 1 = 0.010434 loss)
I1007 17:30:17.732376  4982 sgd_solver.cpp:105] Iteration 97200, lr = 0.001
I1007 17:30:26.072665  4982 solver.cpp:218] Iteration 97300 (11.99 iter/s, 8.34029s/100 iters), loss = 0.00405986
I1007 17:30:26.072705  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00406012 (* 1 = 0.00406012 loss)
I1007 17:30:26.072711  4982 sgd_solver.cpp:105] Iteration 97300, lr = 0.001
I1007 17:30:34.415926  4982 solver.cpp:218] Iteration 97400 (11.9858 iter/s, 8.34319s/100 iters), loss = 0.00497763
I1007 17:30:34.415956  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00497789 (* 1 = 0.00497789 loss)
I1007 17:30:34.415962  4982 sgd_solver.cpp:105] Iteration 97400, lr = 0.001
I1007 17:30:42.336405  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:30:42.670188  4982 solver.cpp:330] Iteration 97500, Testing net (#0)
I1007 17:30:44.602434  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:30:44.683295  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9118
I1007 17:30:44.683332  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.37169 (* 1 = 0.37169 loss)
I1007 17:30:44.767135  4982 solver.cpp:218] Iteration 97500 (9.66076 iter/s, 10.3511s/100 iters), loss = 0.00173697
I1007 17:30:44.767160  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00173723 (* 1 = 0.00173723 loss)
I1007 17:30:44.767169  4982 sgd_solver.cpp:105] Iteration 97500, lr = 0.001
I1007 17:30:53.110637  4982 solver.cpp:218] Iteration 97600 (11.9854 iter/s, 8.34345s/100 iters), loss = 0.0075711
I1007 17:30:53.110747  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00757136 (* 1 = 0.00757136 loss)
I1007 17:30:53.110754  4982 sgd_solver.cpp:105] Iteration 97600, lr = 0.001
I1007 17:31:01.444524  4982 solver.cpp:218] Iteration 97700 (11.9994 iter/s, 8.33375s/100 iters), loss = 0.0031664
I1007 17:31:01.444553  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00316666 (* 1 = 0.00316666 loss)
I1007 17:31:01.444560  4982 sgd_solver.cpp:105] Iteration 97700, lr = 0.001
I1007 17:31:09.780273  4982 solver.cpp:218] Iteration 97800 (11.9966 iter/s, 8.33569s/100 iters), loss = 0.00244187
I1007 17:31:09.780303  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00244213 (* 1 = 0.00244213 loss)
I1007 17:31:09.780309  4982 sgd_solver.cpp:105] Iteration 97800, lr = 0.001
I1007 17:31:18.109797  4982 solver.cpp:218] Iteration 97900 (12.0056 iter/s, 8.32947s/100 iters), loss = 0.00815934
I1007 17:31:18.109838  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0081596 (* 1 = 0.0081596 loss)
I1007 17:31:18.109843  4982 sgd_solver.cpp:105] Iteration 97900, lr = 0.001
I1007 17:31:26.033092  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:31:26.365918  4982 solver.cpp:330] Iteration 98000, Testing net (#0)
I1007 17:31:28.297876  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:31:28.379405  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9119
I1007 17:31:28.379441  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.370842 (* 1 = 0.370842 loss)
I1007 17:31:28.461750  4982 solver.cpp:218] Iteration 98000 (9.66008 iter/s, 10.3519s/100 iters), loss = 0.00342094
I1007 17:31:28.461778  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0034212 (* 1 = 0.0034212 loss)
I1007 17:31:28.461786  4982 sgd_solver.cpp:105] Iteration 98000, lr = 0.001
I1007 17:31:36.788440  4982 solver.cpp:218] Iteration 98100 (12.0097 iter/s, 8.32664s/100 iters), loss = 0.00101557
I1007 17:31:36.788471  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00101583 (* 1 = 0.00101583 loss)
I1007 17:31:36.788477  4982 sgd_solver.cpp:105] Iteration 98100, lr = 0.001
I1007 17:31:45.115682  4982 solver.cpp:218] Iteration 98200 (12.0089 iter/s, 8.32718s/100 iters), loss = 0.00559206
I1007 17:31:45.115711  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00559232 (* 1 = 0.00559232 loss)
I1007 17:31:45.115717  4982 sgd_solver.cpp:105] Iteration 98200, lr = 0.001
I1007 17:31:53.443300  4982 solver.cpp:218] Iteration 98300 (12.0083 iter/s, 8.32756s/100 iters), loss = 0.00302283
I1007 17:31:53.443330  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00302309 (* 1 = 0.00302309 loss)
I1007 17:31:53.443336  4982 sgd_solver.cpp:105] Iteration 98300, lr = 0.001
I1007 17:32:01.780494  4982 solver.cpp:218] Iteration 98400 (11.9945 iter/s, 8.33714s/100 iters), loss = 0.00649536
I1007 17:32:01.780633  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00649563 (* 1 = 0.00649563 loss)
I1007 17:32:01.780665  4982 sgd_solver.cpp:105] Iteration 98400, lr = 0.001
I1007 17:32:09.692777  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:32:10.025527  4982 solver.cpp:330] Iteration 98500, Testing net (#0)
I1007 17:32:11.958479  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:32:12.039506  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9114
I1007 17:32:12.039541  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.369281 (* 1 = 0.369281 loss)
I1007 17:32:12.123195  4982 solver.cpp:218] Iteration 98500 (9.6688 iter/s, 10.3425s/100 iters), loss = 0.0243095
I1007 17:32:12.123224  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0243098 (* 1 = 0.0243098 loss)
I1007 17:32:12.123230  4982 sgd_solver.cpp:105] Iteration 98500, lr = 0.001
I1007 17:32:20.459780  4982 solver.cpp:218] Iteration 98600 (11.9954 iter/s, 8.33653s/100 iters), loss = 0.00669361
I1007 17:32:20.459810  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00669387 (* 1 = 0.00669387 loss)
I1007 17:32:20.459815  4982 sgd_solver.cpp:105] Iteration 98600, lr = 0.001
I1007 17:32:28.784119  4982 solver.cpp:218] Iteration 98700 (12.013 iter/s, 8.32428s/100 iters), loss = 0.00413863
I1007 17:32:28.784150  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00413889 (* 1 = 0.00413889 loss)
I1007 17:32:28.784155  4982 sgd_solver.cpp:105] Iteration 98700, lr = 0.001
I1007 17:32:37.125136  4982 solver.cpp:218] Iteration 98800 (11.989 iter/s, 8.34096s/100 iters), loss = 0.00220509
I1007 17:32:37.125278  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00220536 (* 1 = 0.00220536 loss)
I1007 17:32:37.125286  4982 sgd_solver.cpp:105] Iteration 98800, lr = 0.001
I1007 17:32:45.457906  4982 solver.cpp:218] Iteration 98900 (12.001 iter/s, 8.33261s/100 iters), loss = 0.000908511
I1007 17:32:45.457936  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000908778 (* 1 = 0.000908778 loss)
I1007 17:32:45.457942  4982 sgd_solver.cpp:105] Iteration 98900, lr = 0.001
I1007 17:32:53.376708  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:32:53.710487  4982 solver.cpp:330] Iteration 99000, Testing net (#0)
I1007 17:32:55.643611  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:32:55.724978  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9116
I1007 17:32:55.725013  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.368601 (* 1 = 0.368601 loss)
I1007 17:32:55.807683  4982 solver.cpp:218] Iteration 99000 (9.6621 iter/s, 10.3497s/100 iters), loss = 0.00265164
I1007 17:32:55.807711  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00265191 (* 1 = 0.00265191 loss)
I1007 17:32:55.807718  4982 sgd_solver.cpp:105] Iteration 99000, lr = 0.001
I1007 17:33:04.148574  4982 solver.cpp:218] Iteration 99100 (11.9892 iter/s, 8.34084s/100 iters), loss = 0.00429912
I1007 17:33:04.148614  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0042994 (* 1 = 0.0042994 loss)
I1007 17:33:04.148620  4982 sgd_solver.cpp:105] Iteration 99100, lr = 0.001
I1007 17:33:12.494788  4982 solver.cpp:218] Iteration 99200 (11.9816 iter/s, 8.34615s/100 iters), loss = 0.00473289
I1007 17:33:12.495105  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00473316 (* 1 = 0.00473316 loss)
I1007 17:33:12.495112  4982 sgd_solver.cpp:105] Iteration 99200, lr = 0.001
I1007 17:33:20.829947  4982 solver.cpp:218] Iteration 99300 (11.9978 iter/s, 8.33483s/100 iters), loss = 0.00502835
I1007 17:33:20.829978  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00502863 (* 1 = 0.00502863 loss)
I1007 17:33:20.829984  4982 sgd_solver.cpp:105] Iteration 99300, lr = 0.001
I1007 17:33:29.162947  4982 solver.cpp:218] Iteration 99400 (12.0006 iter/s, 8.33294s/100 iters), loss = 0.00407124
I1007 17:33:29.162988  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00407152 (* 1 = 0.00407152 loss)
I1007 17:33:29.162995  4982 sgd_solver.cpp:105] Iteration 99400, lr = 0.001
I1007 17:33:37.071768  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:33:37.405645  4982 solver.cpp:330] Iteration 99500, Testing net (#0)
I1007 17:33:39.337137  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:33:39.417819  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9116
I1007 17:33:39.417855  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.372643 (* 1 = 0.372643 loss)
I1007 17:33:39.501951  4982 solver.cpp:218] Iteration 99500 (9.67218 iter/s, 10.3389s/100 iters), loss = 0.0341419
I1007 17:33:39.501978  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0341421 (* 1 = 0.0341421 loss)
I1007 17:33:39.501986  4982 sgd_solver.cpp:105] Iteration 99500, lr = 0.001
I1007 17:33:47.839365  4982 solver.cpp:218] Iteration 99600 (11.9942 iter/s, 8.33736s/100 iters), loss = 0.00195845
I1007 17:33:47.839486  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00195873 (* 1 = 0.00195873 loss)
I1007 17:33:47.839504  4982 sgd_solver.cpp:105] Iteration 99600, lr = 0.001
I1007 17:33:56.171545  4982 solver.cpp:218] Iteration 99700 (12.0019 iter/s, 8.33204s/100 iters), loss = 0.00399349
I1007 17:33:56.171586  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00399376 (* 1 = 0.00399376 loss)
I1007 17:33:56.171592  4982 sgd_solver.cpp:105] Iteration 99700, lr = 0.001
I1007 17:34:04.511106  4982 solver.cpp:218] Iteration 99800 (11.9911 iter/s, 8.3395s/100 iters), loss = 0.00596406
I1007 17:34:04.511148  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00596434 (* 1 = 0.00596434 loss)
I1007 17:34:04.511153  4982 sgd_solver.cpp:105] Iteration 99800, lr = 0.001
I1007 17:34:12.838119  4982 solver.cpp:218] Iteration 99900 (12.0092 iter/s, 8.32695s/100 iters), loss = 0.00416432
I1007 17:34:12.838148  4982 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0041646 (* 1 = 0.0041646 loss)
I1007 17:34:12.838155  4982 sgd_solver.cpp:105] Iteration 99900, lr = 0.001
I1007 17:34:20.758566  4991 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:34:21.091693  4982 solver.cpp:447] Snapshotting to binary proto file xn/PENLU/snapshot/resnet/res32/res32_penlu_alpha2_beta1_etanostudy_2study_nodecay_gauss_iter_100000.caffemodel
I1007 17:34:21.105072  4982 sgd_solver.cpp:273] Snapshotting solver state to binary proto file xn/PENLU/snapshot/resnet/res32/res32_penlu_alpha2_beta1_etanostudy_2study_nodecay_gauss_iter_100000.solverstate
I1007 17:34:21.128312  4982 solver.cpp:310] Iteration 100000, loss = 0.00184118
I1007 17:34:21.128332  4982 solver.cpp:330] Iteration 100000, Testing net (#0)
I1007 17:34:23.059813  4992 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:34:23.139935  4982 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9117
I1007 17:34:23.139968  4982 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.370198 (* 1 = 0.370198 loss)
I1007 17:34:23.139973  4982 solver.cpp:315] Optimization Done.
I1007 17:34:23.139976  4982 caffe.cpp:259] Optimization Done.
