I1007 22:17:01.122356  5322 caffe.cpp:218] Using GPUs 0
I1007 22:17:01.126037  5322 caffe.cpp:223] GPU 0: GeForce GTX 1080
I1007 22:17:01.913064  5322 solver.cpp:44] Initializing solver from parameters: 
test_iter: 100
test_interval: 500
base_lr: 0.1
display: 100
max_iter: 100000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0001
snapshot: 100000
snapshot_prefix: "xn/PENLU/snapshot/resnet/res32/res32_elu_alpha0.25_gauss"
solver_mode: GPU
device_id: 0
net: "/home/x306/caffe/xn/PENLU/neural/resnet/res32/res32_elu0.25_train_test.prototxt"
train_state {
  level: 0
  stage: ""
}
stepvalue: 40000
stepvalue: 80000
I1007 22:17:01.913193  5322 solver.cpp:87] Creating training net from net file: /home/x306/caffe/xn/PENLU/neural/resnet/res32/res32_elu0.25_train_test.prototxt
I1007 22:17:01.915069  5322 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: /home/x306/caffe/xn/PENLU/neural/resnet/res32/res32_elu0.25_train_test.prototxt
I1007 22:17:01.915091  5322 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I1007 22:17:01.915256  5322 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer Data1
I1007 22:17:01.915333  5322 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer Accuracy1
I1007 22:17:01.915891  5322 net.cpp:51] Initializing net from parameters: 
name: "resnet_cifar10"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "Data1"
  type: "Data"
  top: "Data1"
  top: "Data2"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 28
    mean_file: "/home/x306/caffe/xn/PENLU/data/cifar10/mean.binaryproto"
  }
  data_param {
    source: "/home/x306/caffe/xn/PENLU/data/cifar10/cifar10_train_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "Convolution1"
  type: "Convolution"
  bottom: "Data1"
  top: "Convolution1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm1"
  type: "BatchNorm"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1"
  type: "Scale"
  bottom: "Convolution1"
  top: "Convolution1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "elu1"
  type: "ELU"
  bottom: "Convolution1"
  top: "Convolution1"
  elu_param {
    alpha: 0.25
  }
}
layer {
  name: "Convolution2"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm2"
  type: "BatchNorm"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale2"
  type: "Scale"
  bottom: "Convolution2"
  top: "Convolution2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "elu2"
  type: "ELU"
  bottom: "Convolution2"
  top: "Convolution2"
  elu_param {
    alpha: 0.25
  }
}
layer {
  name: "Convolution3"
  type: "Convolution"
  bottom: "Convolution2"
  top: "Convolution3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm3"
  type: "BatchNorm"
  bottom: "Convolution3"
  top: "Convolution3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale3"
  type: "Scale"
  bottom: "Convolution3"
  top: "Convolution3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise1"
  type: "Eltwise"
  bottom: "Convolution1"
  bottom: "Convolution3"
  top: "Eltwise1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "elu3"
  type: "ELU"
  bottom: "Eltwise1"
  top: "Eltwise1"
  elu_param {
    alpha: 0.25
  }
}
layer {
  name: "Convolution4"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm4"
  type: "BatchNorm"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale4"
  type: "Scale"
  bottom: "Convolution4"
  top: "Convolution4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "elu4"
  type: "ELU"
  bottom: "Convolution4"
  top: "Convolution4"
  elu_param {
    alpha: 0.25
  }
}
layer {
  name: "Convolution5"
  type: "Convolution"
  bottom: "Convolution4"
  top: "Convolution5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm5"
  type: "BatchNorm"
  bottom: "Convolution5"
  top: "Convolution5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale5"
  type: "Scale"
  bottom: "Convolution5"
  top: "Convolution5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise2"
  type: "Eltwise"
  bottom: "Eltwise1"
  bottom: "Convolution5"
  top: "Eltwise2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "elu5"
  type: "ELU"
  bottom: "Eltwise2"
  top: "Eltwise2"
  elu_param {
    alpha: 0.25
  }
}
layer {
  name: "Convolution6"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm6"
  type: "BatchNorm"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale6"
  type: "Scale"
  bottom: "Convolution6"
  top: "Convolution6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "elu6"
  type: "ELU"
  bottom: "Convolution6"
  top: "Convolution6"
  elu_param {
    alpha: 0.25
  }
}
layer {
  name: "Convolution7"
  type: "Convolution"
  bottom: "Convolution6"
  top: "Convolution7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm7"
  type: "BatchNorm"
  bottom: "Convolution7"
  top: "Convolution7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale7"
  type: "Scale"
  bottom: "Convolution7"
  top: "Convolution7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise3"
  type: "Eltwise"
  bottom: "Eltwise2"
  bottom: "Convolution7"
  top: "Eltwise3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "elu7"
  type: "ELU"
  bottom: "Eltwise3"
  top: "Eltwise3"
  elu_param {
    alpha: 0.25
  }
}
layer {
  name: "Convolution8"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm8"
  type: "BatchNorm"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale8"
  type: "Scale"
  bottom: "Convolution8"
  top: "Convolution8"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "elu8"
  type: "ELU"
  bottom: "Convolution8"
  top: "Convolution8"
  elu_param {
    alpha: 0.25
  }
}
layer {
  name: "Convolution9"
  type: "Convolution"
  bottom: "Convolution8"
  top: "Convolution9"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm9"
  type: "BatchNorm"
  bottom: "Convolution9"
  top: "Convolution9"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale9"
  type: "Scale"
  bottom: "Convolution9"
  top: "Convolution9"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise4"
  type: "Eltwise"
  bottom: "Eltwise3"
  bottom: "Convolution9"
  top: "Eltwise4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "elu9"
  type: "ELU"
  bottom: "Eltwise4"
  top: "Eltwise4"
  elu_param {
    alpha: 0.25
  }
}
layer {
  name: "Convolution10"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution10"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm10"
  type: "BatchNorm"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale10"
  type: "Scale"
  bottom: "Convolution10"
  top: "Convolution10"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "elu10"
  type: "ELU"
  bottom: "Convolution10"
  top: "Convolution10"
  elu_param {
    alpha: 0.25
  }
}
layer {
  name: "Convolution11"
  type: "Convolution"
  bottom: "Convolution10"
  top: "Convolution11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm11"
  type: "BatchNorm"
  bottom: "Convolution11"
  top: "Convolution11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale11"
  type: "Scale"
  bottom: "Convolution11"
  top: "Convolution11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise5"
  type: "Eltwise"
  bottom: "Eltwise4"
  bottom: "Convolution11"
  top: "Eltwise5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "elu11"
  type: "ELU"
  bottom: "Eltwise5"
  top: "Eltwise5"
  elu_param {
    alpha: 0.25
  }
}
layer {
  name: "Convolution12"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.25
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm12"
  type: "BatchNorm"
  bottom: "Convolution12"
  top: "Convolution12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale12"
  type: "Scale"
  bottom: "Convolution12"
  top: "Convolution12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution13"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution13"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm13"
  type: "BatchNorm"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale13"
  type: "Scale"
  bottom: "Convolution13"
  top: "Convolution13"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "elu12"
  type: "ELU"
  bottom: "Convolution13"
  top: "Convolution13"
  elu_param {
    alpha: 0.25
  }
}
layer {
  name: "Convolution14"
  type: "Convolution"
  bottom: "Convolution13"
  top: "Convolution14"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm14"
  type: "BatchNorm"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale14"
  type: "Scale"
  bottom: "Convolution14"
  top: "Convolution14"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise6"
  type: "Eltwise"
  bottom: "Convolution12"
  bottom: "Convolution14"
  top: "Eltwise6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "elu13"
  type: "ELU"
  bottom: "Eltwise6"
  top: "Eltwise6"
  elu_param {
    alpha: 0.25
  }
}
layer {
  name: "Convolution15"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution15"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm15"
  type: "BatchNorm"
  bottom: "Convolution15"
  top: "Convolution15"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale15"
  type: "Scale"
  bottom: "Convolution15"
  top: "Convolution15"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "elu14"
  type: "ELU"
  bottom: "Convolution15"
  top: "Convolution15"
  elu_param {
    alpha: 0.25
  }
}
layer {
  name: "Convolution16"
  type: "Convolution"
  bottom: "Convolution15"
  top: "Convolution16"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm16"
  type: "BatchNorm"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale16"
  type: "Scale"
  bottom: "Convolution16"
  top: "Convolution16"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise7"
  type: "Eltwise"
  bottom: "Eltwise6"
  bottom: "Convolution16"
  top: "Eltwise7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "elu15"
  type: "ELU"
  bottom: "Eltwise7"
  top: "Eltwise7"
  elu_param {
    alpha: 0.25
  }
}
layer {
  name: "Convolution17"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution17"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm17"
  type: "BatchNorm"
  bottom: "Convolution17"
  top: "Convolution17"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale17"
  type: "Scale"
  bottom: "Convolution17"
  top: "Convolution17"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "elu16"
  type: "ELU"
  bottom: "Convolution17"
  top: "Convolution17"
  elu_param {
    alpha: 0.25
  }
}
layer {
  name: "Convolution18"
  type: "Convolution"
  bottom: "Convolution17"
  top: "Convolution18"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm18"
  type: "BatchNorm"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale18"
  type: "Scale"
  bottom: "Convolution18"
  top: "Convolution18"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise8"
  type: "Eltwise"
  bottom: "Eltwise7"
  bottom: "Convolution18"
  top: "Eltwise8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "elu17"
  type: "ELU"
  bottom: "Eltwise8"
  top: "Eltwise8"
  elu_param {
    alpha: 0.25
  }
}
layer {
  name: "Convolution19"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution19"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm19"
  type: "BatchNorm"
  bottom: "Convolution19"
  top: "Convolution19"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale19"
  type: "Scale"
  bottom: "Convolution19"
  top: "Convolution19"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "elu18"
  type: "ELU"
  bottom: "Convolution19"
  top: "Convolution19"
  elu_param {
    alpha: 0.25
  }
}
layer {
  name: "Convolution20"
  type: "Convolution"
  bottom: "Convolution19"
  top: "Convolution20"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm20"
  type: "BatchNorm"
  bottom: "Convolution20"
  top: "Convolution20"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale20"
  type: "Scale"
  bottom: "Convolution20"
  top: "Convolution20"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise9"
  type: "Eltwise"
  bottom: "Eltwise8"
  bottom: "Convolution20"
  top: "Eltwise9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "elu19"
  type: "ELU"
  bottom: "Eltwise9"
  top: "Eltwise9"
  elu_param {
    alpha: 0.25
  }
}
layer {
  name: "Convolution21"
  type: "Convolution"
  bottom: "Eltwise9"
  top: "Convolution21"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm21"
  type: "BatchNorm"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale21"
  type: "Scale"
  bottom: "Convolution21"
  top: "Convolution21"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "elu20"
  type: "ELU"
  bottom: "Convolution21"
  top: "Convolution21"
  elu_param {
    alpha: 0.25
  }
}
layer {
  name: "Convolution22"
  type: "Convolution"
  bottom: "Convolution21"
  top: "Convolution22"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm22"
  type: "BatchNorm"
  bottom: "Convolution22"
  top: "Convolution22"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale22"
  type: "Scale"
  bottom: "Convolution22"
  top: "Convolution22"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise10"
  type: "Eltwise"
  bottom: "Eltwise9"
  bottom: "Convolution22"
  top: "Eltwise10"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "elu21"
  type: "ELU"
  bottom: "Eltwise10"
  top: "Eltwise10"
  elu_param {
    alpha: 0.25
  }
}
layer {
  name: "Convolution23"
  type: "Convolution"
  bottom: "Eltwise10"
  top: "Convolution23"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.17677669
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm23"
  type: "BatchNorm"
  bottom: "Convolution23"
  top: "Convolution23"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale23"
  type: "Scale"
  bottom: "Convolution23"
  top: "Convolution23"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution24"
  type: "Convolution"
  bottom: "Eltwise10"
  top: "Convolution24"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm24"
  type: "BatchNorm"
  bottom: "Convolution24"
  top: "Convolution24"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale24"
  type: "Scale"
  bottom: "Convolution24"
  top: "Convolution24"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "elu22"
  type: "ELU"
  bottom: "Convolution24"
  top: "Convolution24"
  elu_param {
    alpha: 0.25
  }
}
layer {
  name: "Convolution25"
  type: "Convolution"
  bottom: "Convolution24"
  top: "Convolution25"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm25"
  type: "BatchNorm"
  bottom: "Convolution25"
  top: "Convolution25"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale25"
  type: "Scale"
  bottom: "Convolution25"
  top: "Convolution25"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise11"
  type: "Eltwise"
  bottom: "Convolution23"
  bottom: "Convolution25"
  top: "Eltwise11"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "elu23"
  type: "ELU"
  bottom: "Eltwise11"
  top: "Eltwise11"
  elu_param {
    alpha: 0.25
  }
}
layer {
  name: "Convolution26"
  type: "Convolution"
  bottom: "Eltwise11"
  top: "Convolution26"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm26"
  type: "BatchNorm"
  bottom: "Convolution26"
  top: "Convolution26"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale26"
  type: "Scale"
  bottom: "Convolution26"
  top: "Convolution26"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "elu24"
  type: "ELU"
  bottom: "Convolution26"
  top: "Convolution26"
  elu_param {
    alpha: 0.25
  }
}
layer {
  name: "Convolution27"
  type: "Convolution"
  bottom: "Convolution26"
  top: "Convolution27"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm27"
  type: "BatchNorm"
  bottom: "Convolution27"
  top: "Convolution27"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale27"
  type: "Scale"
  bottom: "Convolution27"
  top: "Convolution27"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise12"
  type: "Eltwise"
  bottom: "Eltwise11"
  bottom: "Convolution27"
  top: "Eltwise12"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "elu25"
  type: "ELU"
  bottom: "Eltwise12"
  top: "Eltwise12"
  elu_param {
    alpha: 0.25
  }
}
layer {
  name: "Convolution28"
  type: "Convolution"
  bottom: "Eltwise12"
  top: "Convolution28"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm28"
  type: "BatchNorm"
  bottom: "Convolution28"
  top: "Convolution28"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale28"
  type: "Scale"
  bottom: "Convolution28"
  top: "Convolution28"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "elu26"
  type: "ELU"
  bottom: "Convolution28"
  top: "Convolution28"
  elu_param {
    alpha: 0.25
  }
}
layer {
  name: "Convolution29"
  type: "Convolution"
  bottom: "Convolution28"
  top: "Convolution29"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm29"
  type: "BatchNorm"
  bottom: "Convolution29"
  top: "Convolution29"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale29"
  type: "Scale"
  bottom: "Convolution29"
  top: "Convolution29"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise13"
  type: "Eltwise"
  bottom: "Eltwise12"
  bottom: "Convolution29"
  top: "Eltwise13"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "elu27"
  type: "ELU"
  bottom: "Eltwise13"
  top: "Eltwise13"
  elu_param {
    alpha: 0.25
  }
}
layer {
  name: "Convolution30"
  type: "Convolution"
  bottom: "Eltwise13"
  top: "Convolution30"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm30"
  type: "BatchNorm"
  bottom: "Convolution30"
  top: "Convolution30"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale30"
  type: "Scale"
  bottom: "Convolution30"
  top: "Convolution30"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "elu28"
  type: "ELU"
  bottom: "Convolution30"
  top: "Convolution30"
  elu_param {
    alpha: 0.25
  }
}
layer {
  name: "Convolution31"
  type: "Convolution"
  bottom: "Convolution30"
  top: "Convolution31"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm31"
  type: "BatchNorm"
  bottom: "Convolution31"
  top: "Convolution31"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay
I1007 22:17:01.916436  5322 layer_factory.hpp:77] Creating layer Data1
I1007 22:17:01.916523  5322 db_lmdb.cpp:35] Opened lmdb /home/x306/caffe/xn/PENLU/data/cifar10/cifar10_train_lmdb
I1007 22:17:01.916558  5322 net.cpp:84] Creating Layer Data1
I1007 22:17:01.916566  5322 net.cpp:380] Data1 -> Data1
I1007 22:17:01.916590  5322 net.cpp:380] Data1 -> Data2
I1007 22:17:01.916604  5322 data_transformer.cpp:25] Loading mean file from: /home/x306/caffe/xn/PENLU/data/cifar10/mean.binaryproto
I1007 22:17:01.918102  5322 data_layer.cpp:45] output data size: 100,3,28,28
I1007 22:17:01.927016  5322 net.cpp:122] Setting up Data1
I1007 22:17:01.927034  5322 net.cpp:129] Top shape: 100 3 28 28 (235200)
I1007 22:17:01.927038  5322 net.cpp:129] Top shape: 100 (100)
I1007 22:17:01.927042  5322 net.cpp:137] Memory required for data: 941200
I1007 22:17:01.927048  5322 layer_factory.hpp:77] Creating layer Convolution1
I1007 22:17:01.927067  5322 net.cpp:84] Creating Layer Convolution1
I1007 22:17:01.927072  5322 net.cpp:406] Convolution1 <- Data1
I1007 22:17:01.927081  5322 net.cpp:380] Convolution1 -> Convolution1
I1007 22:17:02.376924  5322 net.cpp:122] Setting up Convolution1
I1007 22:17:02.376957  5322 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:17:02.376960  5322 net.cpp:137] Memory required for data: 5958800
I1007 22:17:02.376976  5322 layer_factory.hpp:77] Creating layer BatchNorm1
I1007 22:17:02.376987  5322 net.cpp:84] Creating Layer BatchNorm1
I1007 22:17:02.377008  5322 net.cpp:406] BatchNorm1 <- Convolution1
I1007 22:17:02.377014  5322 net.cpp:367] BatchNorm1 -> Convolution1 (in-place)
I1007 22:17:02.377151  5322 net.cpp:122] Setting up BatchNorm1
I1007 22:17:02.377156  5322 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:17:02.377168  5322 net.cpp:137] Memory required for data: 10976400
I1007 22:17:02.377177  5322 layer_factory.hpp:77] Creating layer Scale1
I1007 22:17:02.377185  5322 net.cpp:84] Creating Layer Scale1
I1007 22:17:02.377188  5322 net.cpp:406] Scale1 <- Convolution1
I1007 22:17:02.377192  5322 net.cpp:367] Scale1 -> Convolution1 (in-place)
I1007 22:17:02.377223  5322 layer_factory.hpp:77] Creating layer Scale1
I1007 22:17:02.377315  5322 net.cpp:122] Setting up Scale1
I1007 22:17:02.377319  5322 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:17:02.377332  5322 net.cpp:137] Memory required for data: 15994000
I1007 22:17:02.377336  5322 layer_factory.hpp:77] Creating layer elu1
I1007 22:17:02.377342  5322 net.cpp:84] Creating Layer elu1
I1007 22:17:02.377344  5322 net.cpp:406] elu1 <- Convolution1
I1007 22:17:02.377347  5322 net.cpp:367] elu1 -> Convolution1 (in-place)
I1007 22:17:02.377353  5322 net.cpp:122] Setting up elu1
I1007 22:17:02.377357  5322 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:17:02.377358  5322 net.cpp:137] Memory required for data: 21011600
I1007 22:17:02.377360  5322 layer_factory.hpp:77] Creating layer Convolution1_elu1_0_split
I1007 22:17:02.377367  5322 net.cpp:84] Creating Layer Convolution1_elu1_0_split
I1007 22:17:02.377369  5322 net.cpp:406] Convolution1_elu1_0_split <- Convolution1
I1007 22:17:02.377372  5322 net.cpp:380] Convolution1_elu1_0_split -> Convolution1_elu1_0_split_0
I1007 22:17:02.377377  5322 net.cpp:380] Convolution1_elu1_0_split -> Convolution1_elu1_0_split_1
I1007 22:17:02.377399  5322 net.cpp:122] Setting up Convolution1_elu1_0_split
I1007 22:17:02.377404  5322 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:17:02.377410  5322 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:17:02.377413  5322 net.cpp:137] Memory required for data: 31046800
I1007 22:17:02.377418  5322 layer_factory.hpp:77] Creating layer Convolution2
I1007 22:17:02.377426  5322 net.cpp:84] Creating Layer Convolution2
I1007 22:17:02.377429  5322 net.cpp:406] Convolution2 <- Convolution1_elu1_0_split_0
I1007 22:17:02.377434  5322 net.cpp:380] Convolution2 -> Convolution2
I1007 22:17:02.389611  5322 net.cpp:122] Setting up Convolution2
I1007 22:17:02.389621  5322 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:17:02.389636  5322 net.cpp:137] Memory required for data: 36064400
I1007 22:17:02.389642  5322 layer_factory.hpp:77] Creating layer BatchNorm2
I1007 22:17:02.389647  5322 net.cpp:84] Creating Layer BatchNorm2
I1007 22:17:02.389650  5322 net.cpp:406] BatchNorm2 <- Convolution2
I1007 22:17:02.389653  5322 net.cpp:367] BatchNorm2 -> Convolution2 (in-place)
I1007 22:17:02.389777  5322 net.cpp:122] Setting up BatchNorm2
I1007 22:17:02.389782  5322 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:17:02.389796  5322 net.cpp:137] Memory required for data: 41082000
I1007 22:17:02.389801  5322 layer_factory.hpp:77] Creating layer Scale2
I1007 22:17:02.389806  5322 net.cpp:84] Creating Layer Scale2
I1007 22:17:02.389808  5322 net.cpp:406] Scale2 <- Convolution2
I1007 22:17:02.389811  5322 net.cpp:367] Scale2 -> Convolution2 (in-place)
I1007 22:17:02.389835  5322 layer_factory.hpp:77] Creating layer Scale2
I1007 22:17:02.389914  5322 net.cpp:122] Setting up Scale2
I1007 22:17:02.389919  5322 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:17:02.389930  5322 net.cpp:137] Memory required for data: 46099600
I1007 22:17:02.389935  5322 layer_factory.hpp:77] Creating layer elu2
I1007 22:17:02.389938  5322 net.cpp:84] Creating Layer elu2
I1007 22:17:02.389941  5322 net.cpp:406] elu2 <- Convolution2
I1007 22:17:02.389945  5322 net.cpp:367] elu2 -> Convolution2 (in-place)
I1007 22:17:02.389948  5322 net.cpp:122] Setting up elu2
I1007 22:17:02.389951  5322 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:17:02.389961  5322 net.cpp:137] Memory required for data: 51117200
I1007 22:17:02.389963  5322 layer_factory.hpp:77] Creating layer Convolution3
I1007 22:17:02.389971  5322 net.cpp:84] Creating Layer Convolution3
I1007 22:17:02.389973  5322 net.cpp:406] Convolution3 <- Convolution2
I1007 22:17:02.389976  5322 net.cpp:380] Convolution3 -> Convolution3
I1007 22:17:02.402945  5322 net.cpp:122] Setting up Convolution3
I1007 22:17:02.402956  5322 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:17:02.402969  5322 net.cpp:137] Memory required for data: 56134800
I1007 22:17:02.402974  5322 layer_factory.hpp:77] Creating layer BatchNorm3
I1007 22:17:02.402979  5322 net.cpp:84] Creating Layer BatchNorm3
I1007 22:17:02.402982  5322 net.cpp:406] BatchNorm3 <- Convolution3
I1007 22:17:02.402987  5322 net.cpp:367] BatchNorm3 -> Convolution3 (in-place)
I1007 22:17:02.403105  5322 net.cpp:122] Setting up BatchNorm3
I1007 22:17:02.403110  5322 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:17:02.403112  5322 net.cpp:137] Memory required for data: 61152400
I1007 22:17:02.403120  5322 layer_factory.hpp:77] Creating layer Scale3
I1007 22:17:02.403125  5322 net.cpp:84] Creating Layer Scale3
I1007 22:17:02.403127  5322 net.cpp:406] Scale3 <- Convolution3
I1007 22:17:02.403131  5322 net.cpp:367] Scale3 -> Convolution3 (in-place)
I1007 22:17:02.403154  5322 layer_factory.hpp:77] Creating layer Scale3
I1007 22:17:02.403234  5322 net.cpp:122] Setting up Scale3
I1007 22:17:02.403241  5322 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:17:02.403244  5322 net.cpp:137] Memory required for data: 66170000
I1007 22:17:02.403247  5322 layer_factory.hpp:77] Creating layer Eltwise1
I1007 22:17:02.403252  5322 net.cpp:84] Creating Layer Eltwise1
I1007 22:17:02.403255  5322 net.cpp:406] Eltwise1 <- Convolution1_elu1_0_split_1
I1007 22:17:02.403259  5322 net.cpp:406] Eltwise1 <- Convolution3
I1007 22:17:02.403261  5322 net.cpp:380] Eltwise1 -> Eltwise1
I1007 22:17:02.403278  5322 net.cpp:122] Setting up Eltwise1
I1007 22:17:02.403285  5322 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:17:02.403287  5322 net.cpp:137] Memory required for data: 71187600
I1007 22:17:02.403290  5322 layer_factory.hpp:77] Creating layer elu3
I1007 22:17:02.403293  5322 net.cpp:84] Creating Layer elu3
I1007 22:17:02.403295  5322 net.cpp:406] elu3 <- Eltwise1
I1007 22:17:02.403298  5322 net.cpp:367] elu3 -> Eltwise1 (in-place)
I1007 22:17:02.403302  5322 net.cpp:122] Setting up elu3
I1007 22:17:02.403306  5322 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:17:02.403308  5322 net.cpp:137] Memory required for data: 76205200
I1007 22:17:02.403311  5322 layer_factory.hpp:77] Creating layer Eltwise1_elu3_0_split
I1007 22:17:02.403313  5322 net.cpp:84] Creating Layer Eltwise1_elu3_0_split
I1007 22:17:02.403316  5322 net.cpp:406] Eltwise1_elu3_0_split <- Eltwise1
I1007 22:17:02.403318  5322 net.cpp:380] Eltwise1_elu3_0_split -> Eltwise1_elu3_0_split_0
I1007 22:17:02.403323  5322 net.cpp:380] Eltwise1_elu3_0_split -> Eltwise1_elu3_0_split_1
I1007 22:17:02.403343  5322 net.cpp:122] Setting up Eltwise1_elu3_0_split
I1007 22:17:02.403348  5322 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:17:02.403352  5322 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:17:02.403353  5322 net.cpp:137] Memory required for data: 86240400
I1007 22:17:02.403355  5322 layer_factory.hpp:77] Creating layer Convolution4
I1007 22:17:02.403363  5322 net.cpp:84] Creating Layer Convolution4
I1007 22:17:02.403365  5322 net.cpp:406] Convolution4 <- Eltwise1_elu3_0_split_0
I1007 22:17:02.403370  5322 net.cpp:380] Convolution4 -> Convolution4
I1007 22:17:02.411850  5322 net.cpp:122] Setting up Convolution4
I1007 22:17:02.411862  5322 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:17:02.411875  5322 net.cpp:137] Memory required for data: 91258000
I1007 22:17:02.411880  5322 layer_factory.hpp:77] Creating layer BatchNorm4
I1007 22:17:02.411885  5322 net.cpp:84] Creating Layer BatchNorm4
I1007 22:17:02.411888  5322 net.cpp:406] BatchNorm4 <- Convolution4
I1007 22:17:02.411901  5322 net.cpp:367] BatchNorm4 -> Convolution4 (in-place)
I1007 22:17:02.412029  5322 net.cpp:122] Setting up BatchNorm4
I1007 22:17:02.412034  5322 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:17:02.412046  5322 net.cpp:137] Memory required for data: 96275600
I1007 22:17:02.412051  5322 layer_factory.hpp:77] Creating layer Scale4
I1007 22:17:02.412056  5322 net.cpp:84] Creating Layer Scale4
I1007 22:17:02.412060  5322 net.cpp:406] Scale4 <- Convolution4
I1007 22:17:02.412062  5322 net.cpp:367] Scale4 -> Convolution4 (in-place)
I1007 22:17:02.412087  5322 layer_factory.hpp:77] Creating layer Scale4
I1007 22:17:02.412168  5322 net.cpp:122] Setting up Scale4
I1007 22:17:02.412173  5322 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:17:02.412174  5322 net.cpp:137] Memory required for data: 101293200
I1007 22:17:02.412189  5322 layer_factory.hpp:77] Creating layer elu4
I1007 22:17:02.412194  5322 net.cpp:84] Creating Layer elu4
I1007 22:17:02.412195  5322 net.cpp:406] elu4 <- Convolution4
I1007 22:17:02.412199  5322 net.cpp:367] elu4 -> Convolution4 (in-place)
I1007 22:17:02.412204  5322 net.cpp:122] Setting up elu4
I1007 22:17:02.412207  5322 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:17:02.412209  5322 net.cpp:137] Memory required for data: 106310800
I1007 22:17:02.412211  5322 layer_factory.hpp:77] Creating layer Convolution5
I1007 22:17:02.412219  5322 net.cpp:84] Creating Layer Convolution5
I1007 22:17:02.412221  5322 net.cpp:406] Convolution5 <- Convolution4
I1007 22:17:02.412225  5322 net.cpp:380] Convolution5 -> Convolution5
I1007 22:17:02.418541  5322 net.cpp:122] Setting up Convolution5
I1007 22:17:02.418552  5322 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:17:02.418555  5322 net.cpp:137] Memory required for data: 111328400
I1007 22:17:02.418560  5322 layer_factory.hpp:77] Creating layer BatchNorm5
I1007 22:17:02.418565  5322 net.cpp:84] Creating Layer BatchNorm5
I1007 22:17:02.418568  5322 net.cpp:406] BatchNorm5 <- Convolution5
I1007 22:17:02.418572  5322 net.cpp:367] BatchNorm5 -> Convolution5 (in-place)
I1007 22:17:02.418700  5322 net.cpp:122] Setting up BatchNorm5
I1007 22:17:02.418705  5322 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:17:02.418717  5322 net.cpp:137] Memory required for data: 116346000
I1007 22:17:02.418725  5322 layer_factory.hpp:77] Creating layer Scale5
I1007 22:17:02.418730  5322 net.cpp:84] Creating Layer Scale5
I1007 22:17:02.418733  5322 net.cpp:406] Scale5 <- Convolution5
I1007 22:17:02.418737  5322 net.cpp:367] Scale5 -> Convolution5 (in-place)
I1007 22:17:02.418762  5322 layer_factory.hpp:77] Creating layer Scale5
I1007 22:17:02.418834  5322 net.cpp:122] Setting up Scale5
I1007 22:17:02.418839  5322 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:17:02.418841  5322 net.cpp:137] Memory required for data: 121363600
I1007 22:17:02.418845  5322 layer_factory.hpp:77] Creating layer Eltwise2
I1007 22:17:02.418850  5322 net.cpp:84] Creating Layer Eltwise2
I1007 22:17:02.418853  5322 net.cpp:406] Eltwise2 <- Eltwise1_elu3_0_split_1
I1007 22:17:02.418856  5322 net.cpp:406] Eltwise2 <- Convolution5
I1007 22:17:02.418860  5322 net.cpp:380] Eltwise2 -> Eltwise2
I1007 22:17:02.418874  5322 net.cpp:122] Setting up Eltwise2
I1007 22:17:02.418879  5322 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:17:02.418882  5322 net.cpp:137] Memory required for data: 126381200
I1007 22:17:02.418884  5322 layer_factory.hpp:77] Creating layer elu5
I1007 22:17:02.418889  5322 net.cpp:84] Creating Layer elu5
I1007 22:17:02.418891  5322 net.cpp:406] elu5 <- Eltwise2
I1007 22:17:02.418895  5322 net.cpp:367] elu5 -> Eltwise2 (in-place)
I1007 22:17:02.418900  5322 net.cpp:122] Setting up elu5
I1007 22:17:02.418903  5322 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:17:02.418905  5322 net.cpp:137] Memory required for data: 131398800
I1007 22:17:02.418907  5322 layer_factory.hpp:77] Creating layer Eltwise2_elu5_0_split
I1007 22:17:02.418911  5322 net.cpp:84] Creating Layer Eltwise2_elu5_0_split
I1007 22:17:02.418921  5322 net.cpp:406] Eltwise2_elu5_0_split <- Eltwise2
I1007 22:17:02.418926  5322 net.cpp:380] Eltwise2_elu5_0_split -> Eltwise2_elu5_0_split_0
I1007 22:17:02.418929  5322 net.cpp:380] Eltwise2_elu5_0_split -> Eltwise2_elu5_0_split_1
I1007 22:17:02.418951  5322 net.cpp:122] Setting up Eltwise2_elu5_0_split
I1007 22:17:02.418956  5322 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:17:02.418959  5322 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:17:02.418962  5322 net.cpp:137] Memory required for data: 141434000
I1007 22:17:02.418964  5322 layer_factory.hpp:77] Creating layer Convolution6
I1007 22:17:02.418970  5322 net.cpp:84] Creating Layer Convolution6
I1007 22:17:02.418974  5322 net.cpp:406] Convolution6 <- Eltwise2_elu5_0_split_0
I1007 22:17:02.418978  5322 net.cpp:380] Convolution6 -> Convolution6
I1007 22:17:02.425310  5322 net.cpp:122] Setting up Convolution6
I1007 22:17:02.425320  5322 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:17:02.425324  5322 net.cpp:137] Memory required for data: 146451600
I1007 22:17:02.425329  5322 layer_factory.hpp:77] Creating layer BatchNorm6
I1007 22:17:02.425335  5322 net.cpp:84] Creating Layer BatchNorm6
I1007 22:17:02.425339  5322 net.cpp:406] BatchNorm6 <- Convolution6
I1007 22:17:02.425343  5322 net.cpp:367] BatchNorm6 -> Convolution6 (in-place)
I1007 22:17:02.425467  5322 net.cpp:122] Setting up BatchNorm6
I1007 22:17:02.425472  5322 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:17:02.425475  5322 net.cpp:137] Memory required for data: 151469200
I1007 22:17:02.425480  5322 layer_factory.hpp:77] Creating layer Scale6
I1007 22:17:02.425484  5322 net.cpp:84] Creating Layer Scale6
I1007 22:17:02.425487  5322 net.cpp:406] Scale6 <- Convolution6
I1007 22:17:02.425490  5322 net.cpp:367] Scale6 -> Convolution6 (in-place)
I1007 22:17:02.425515  5322 layer_factory.hpp:77] Creating layer Scale6
I1007 22:17:02.425587  5322 net.cpp:122] Setting up Scale6
I1007 22:17:02.425592  5322 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:17:02.425595  5322 net.cpp:137] Memory required for data: 156486800
I1007 22:17:02.425598  5322 layer_factory.hpp:77] Creating layer elu6
I1007 22:17:02.425603  5322 net.cpp:84] Creating Layer elu6
I1007 22:17:02.425606  5322 net.cpp:406] elu6 <- Convolution6
I1007 22:17:02.425611  5322 net.cpp:367] elu6 -> Convolution6 (in-place)
I1007 22:17:02.425614  5322 net.cpp:122] Setting up elu6
I1007 22:17:02.425617  5322 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:17:02.425619  5322 net.cpp:137] Memory required for data: 161504400
I1007 22:17:02.425622  5322 layer_factory.hpp:77] Creating layer Convolution7
I1007 22:17:02.425628  5322 net.cpp:84] Creating Layer Convolution7
I1007 22:17:02.425631  5322 net.cpp:406] Convolution7 <- Convolution6
I1007 22:17:02.425635  5322 net.cpp:380] Convolution7 -> Convolution7
I1007 22:17:02.432037  5322 net.cpp:122] Setting up Convolution7
I1007 22:17:02.432047  5322 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:17:02.432050  5322 net.cpp:137] Memory required for data: 166522000
I1007 22:17:02.432054  5322 layer_factory.hpp:77] Creating layer BatchNorm7
I1007 22:17:02.432060  5322 net.cpp:84] Creating Layer BatchNorm7
I1007 22:17:02.432062  5322 net.cpp:406] BatchNorm7 <- Convolution7
I1007 22:17:02.432066  5322 net.cpp:367] BatchNorm7 -> Convolution7 (in-place)
I1007 22:17:02.432190  5322 net.cpp:122] Setting up BatchNorm7
I1007 22:17:02.432195  5322 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:17:02.432198  5322 net.cpp:137] Memory required for data: 171539600
I1007 22:17:02.432202  5322 layer_factory.hpp:77] Creating layer Scale7
I1007 22:17:02.432209  5322 net.cpp:84] Creating Layer Scale7
I1007 22:17:02.432212  5322 net.cpp:406] Scale7 <- Convolution7
I1007 22:17:02.432216  5322 net.cpp:367] Scale7 -> Convolution7 (in-place)
I1007 22:17:02.432240  5322 layer_factory.hpp:77] Creating layer Scale7
I1007 22:17:02.432312  5322 net.cpp:122] Setting up Scale7
I1007 22:17:02.432317  5322 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:17:02.432327  5322 net.cpp:137] Memory required for data: 176557200
I1007 22:17:02.432332  5322 layer_factory.hpp:77] Creating layer Eltwise3
I1007 22:17:02.432337  5322 net.cpp:84] Creating Layer Eltwise3
I1007 22:17:02.432340  5322 net.cpp:406] Eltwise3 <- Eltwise2_elu5_0_split_1
I1007 22:17:02.432343  5322 net.cpp:406] Eltwise3 <- Convolution7
I1007 22:17:02.432348  5322 net.cpp:380] Eltwise3 -> Eltwise3
I1007 22:17:02.432363  5322 net.cpp:122] Setting up Eltwise3
I1007 22:17:02.432368  5322 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:17:02.432370  5322 net.cpp:137] Memory required for data: 181574800
I1007 22:17:02.432373  5322 layer_factory.hpp:77] Creating layer elu7
I1007 22:17:02.432376  5322 net.cpp:84] Creating Layer elu7
I1007 22:17:02.432379  5322 net.cpp:406] elu7 <- Eltwise3
I1007 22:17:02.432381  5322 net.cpp:367] elu7 -> Eltwise3 (in-place)
I1007 22:17:02.432386  5322 net.cpp:122] Setting up elu7
I1007 22:17:02.432390  5322 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:17:02.432392  5322 net.cpp:137] Memory required for data: 186592400
I1007 22:17:02.432394  5322 layer_factory.hpp:77] Creating layer Eltwise3_elu7_0_split
I1007 22:17:02.432399  5322 net.cpp:84] Creating Layer Eltwise3_elu7_0_split
I1007 22:17:02.432400  5322 net.cpp:406] Eltwise3_elu7_0_split <- Eltwise3
I1007 22:17:02.432404  5322 net.cpp:380] Eltwise3_elu7_0_split -> Eltwise3_elu7_0_split_0
I1007 22:17:02.432409  5322 net.cpp:380] Eltwise3_elu7_0_split -> Eltwise3_elu7_0_split_1
I1007 22:17:02.432430  5322 net.cpp:122] Setting up Eltwise3_elu7_0_split
I1007 22:17:02.432433  5322 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:17:02.432436  5322 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:17:02.432440  5322 net.cpp:137] Memory required for data: 196627600
I1007 22:17:02.432441  5322 layer_factory.hpp:77] Creating layer Convolution8
I1007 22:17:02.432447  5322 net.cpp:84] Creating Layer Convolution8
I1007 22:17:02.432451  5322 net.cpp:406] Convolution8 <- Eltwise3_elu7_0_split_0
I1007 22:17:02.432456  5322 net.cpp:380] Convolution8 -> Convolution8
I1007 22:17:02.438730  5322 net.cpp:122] Setting up Convolution8
I1007 22:17:02.438740  5322 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:17:02.438742  5322 net.cpp:137] Memory required for data: 201645200
I1007 22:17:02.438747  5322 layer_factory.hpp:77] Creating layer BatchNorm8
I1007 22:17:02.438752  5322 net.cpp:84] Creating Layer BatchNorm8
I1007 22:17:02.438755  5322 net.cpp:406] BatchNorm8 <- Convolution8
I1007 22:17:02.438760  5322 net.cpp:367] BatchNorm8 -> Convolution8 (in-place)
I1007 22:17:02.438884  5322 net.cpp:122] Setting up BatchNorm8
I1007 22:17:02.438889  5322 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:17:02.438891  5322 net.cpp:137] Memory required for data: 206662800
I1007 22:17:02.438896  5322 layer_factory.hpp:77] Creating layer Scale8
I1007 22:17:02.438901  5322 net.cpp:84] Creating Layer Scale8
I1007 22:17:02.438905  5322 net.cpp:406] Scale8 <- Convolution8
I1007 22:17:02.438907  5322 net.cpp:367] Scale8 -> Convolution8 (in-place)
I1007 22:17:02.438932  5322 layer_factory.hpp:77] Creating layer Scale8
I1007 22:17:02.439005  5322 net.cpp:122] Setting up Scale8
I1007 22:17:02.439010  5322 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:17:02.439013  5322 net.cpp:137] Memory required for data: 211680400
I1007 22:17:02.439016  5322 layer_factory.hpp:77] Creating layer elu8
I1007 22:17:02.439020  5322 net.cpp:84] Creating Layer elu8
I1007 22:17:02.439024  5322 net.cpp:406] elu8 <- Convolution8
I1007 22:17:02.439028  5322 net.cpp:367] elu8 -> Convolution8 (in-place)
I1007 22:17:02.439031  5322 net.cpp:122] Setting up elu8
I1007 22:17:02.439035  5322 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:17:02.439038  5322 net.cpp:137] Memory required for data: 216698000
I1007 22:17:02.439039  5322 layer_factory.hpp:77] Creating layer Convolution9
I1007 22:17:02.439046  5322 net.cpp:84] Creating Layer Convolution9
I1007 22:17:02.439049  5322 net.cpp:406] Convolution9 <- Convolution8
I1007 22:17:02.439054  5322 net.cpp:380] Convolution9 -> Convolution9
I1007 22:17:02.441915  5322 net.cpp:122] Setting up Convolution9
I1007 22:17:02.441926  5322 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:17:02.441929  5322 net.cpp:137] Memory required for data: 221715600
I1007 22:17:02.441934  5322 layer_factory.hpp:77] Creating layer BatchNorm9
I1007 22:17:02.441942  5322 net.cpp:84] Creating Layer BatchNorm9
I1007 22:17:02.441946  5322 net.cpp:406] BatchNorm9 <- Convolution9
I1007 22:17:02.441951  5322 net.cpp:367] BatchNorm9 -> Convolution9 (in-place)
I1007 22:17:02.442076  5322 net.cpp:122] Setting up BatchNorm9
I1007 22:17:02.442081  5322 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:17:02.442085  5322 net.cpp:137] Memory required for data: 226733200
I1007 22:17:02.442090  5322 layer_factory.hpp:77] Creating layer Scale9
I1007 22:17:02.442095  5322 net.cpp:84] Creating Layer Scale9
I1007 22:17:02.442097  5322 net.cpp:406] Scale9 <- Convolution9
I1007 22:17:02.442101  5322 net.cpp:367] Scale9 -> Convolution9 (in-place)
I1007 22:17:02.442126  5322 layer_factory.hpp:77] Creating layer Scale9
I1007 22:17:02.442200  5322 net.cpp:122] Setting up Scale9
I1007 22:17:02.442205  5322 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:17:02.442209  5322 net.cpp:137] Memory required for data: 231750800
I1007 22:17:02.442212  5322 layer_factory.hpp:77] Creating layer Eltwise4
I1007 22:17:02.442219  5322 net.cpp:84] Creating Layer Eltwise4
I1007 22:17:02.442221  5322 net.cpp:406] Eltwise4 <- Eltwise3_elu7_0_split_1
I1007 22:17:02.442224  5322 net.cpp:406] Eltwise4 <- Convolution9
I1007 22:17:02.442227  5322 net.cpp:380] Eltwise4 -> Eltwise4
I1007 22:17:02.442241  5322 net.cpp:122] Setting up Eltwise4
I1007 22:17:02.442246  5322 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:17:02.442248  5322 net.cpp:137] Memory required for data: 236768400
I1007 22:17:02.442250  5322 layer_factory.hpp:77] Creating layer elu9
I1007 22:17:02.442255  5322 net.cpp:84] Creating Layer elu9
I1007 22:17:02.442256  5322 net.cpp:406] elu9 <- Eltwise4
I1007 22:17:02.442260  5322 net.cpp:367] elu9 -> Eltwise4 (in-place)
I1007 22:17:02.442263  5322 net.cpp:122] Setting up elu9
I1007 22:17:02.442267  5322 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:17:02.442270  5322 net.cpp:137] Memory required for data: 241786000
I1007 22:17:02.442271  5322 layer_factory.hpp:77] Creating layer Eltwise4_elu9_0_split
I1007 22:17:02.442276  5322 net.cpp:84] Creating Layer Eltwise4_elu9_0_split
I1007 22:17:02.442277  5322 net.cpp:406] Eltwise4_elu9_0_split <- Eltwise4
I1007 22:17:02.442281  5322 net.cpp:380] Eltwise4_elu9_0_split -> Eltwise4_elu9_0_split_0
I1007 22:17:02.442284  5322 net.cpp:380] Eltwise4_elu9_0_split -> Eltwise4_elu9_0_split_1
I1007 22:17:02.442306  5322 net.cpp:122] Setting up Eltwise4_elu9_0_split
I1007 22:17:02.442311  5322 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:17:02.442313  5322 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:17:02.442315  5322 net.cpp:137] Memory required for data: 251821200
I1007 22:17:02.442317  5322 layer_factory.hpp:77] Creating layer Convolution10
I1007 22:17:02.442323  5322 net.cpp:84] Creating Layer Convolution10
I1007 22:17:02.442327  5322 net.cpp:406] Convolution10 <- Eltwise4_elu9_0_split_0
I1007 22:17:02.442332  5322 net.cpp:380] Convolution10 -> Convolution10
I1007 22:17:02.443188  5322 net.cpp:122] Setting up Convolution10
I1007 22:17:02.443198  5322 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:17:02.443202  5322 net.cpp:137] Memory required for data: 256838800
I1007 22:17:02.443213  5322 layer_factory.hpp:77] Creating layer BatchNorm10
I1007 22:17:02.443219  5322 net.cpp:84] Creating Layer BatchNorm10
I1007 22:17:02.443222  5322 net.cpp:406] BatchNorm10 <- Convolution10
I1007 22:17:02.443228  5322 net.cpp:367] BatchNorm10 -> Convolution10 (in-place)
I1007 22:17:02.443358  5322 net.cpp:122] Setting up BatchNorm10
I1007 22:17:02.443364  5322 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:17:02.443367  5322 net.cpp:137] Memory required for data: 261856400
I1007 22:17:02.443379  5322 layer_factory.hpp:77] Creating layer Scale10
I1007 22:17:02.443385  5322 net.cpp:84] Creating Layer Scale10
I1007 22:17:02.443388  5322 net.cpp:406] Scale10 <- Convolution10
I1007 22:17:02.443393  5322 net.cpp:367] Scale10 -> Convolution10 (in-place)
I1007 22:17:02.443420  5322 layer_factory.hpp:77] Creating layer Scale10
I1007 22:17:02.443500  5322 net.cpp:122] Setting up Scale10
I1007 22:17:02.443506  5322 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:17:02.443508  5322 net.cpp:137] Memory required for data: 266874000
I1007 22:17:02.443513  5322 layer_factory.hpp:77] Creating layer elu10
I1007 22:17:02.443517  5322 net.cpp:84] Creating Layer elu10
I1007 22:17:02.443521  5322 net.cpp:406] elu10 <- Convolution10
I1007 22:17:02.443526  5322 net.cpp:367] elu10 -> Convolution10 (in-place)
I1007 22:17:02.443529  5322 net.cpp:122] Setting up elu10
I1007 22:17:02.443532  5322 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:17:02.443534  5322 net.cpp:137] Memory required for data: 271891600
I1007 22:17:02.443537  5322 layer_factory.hpp:77] Creating layer Convolution11
I1007 22:17:02.443543  5322 net.cpp:84] Creating Layer Convolution11
I1007 22:17:02.443547  5322 net.cpp:406] Convolution11 <- Convolution10
I1007 22:17:02.443550  5322 net.cpp:380] Convolution11 -> Convolution11
I1007 22:17:02.444406  5322 net.cpp:122] Setting up Convolution11
I1007 22:17:02.444427  5322 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:17:02.444429  5322 net.cpp:137] Memory required for data: 276909200
I1007 22:17:02.444433  5322 layer_factory.hpp:77] Creating layer BatchNorm11
I1007 22:17:02.444439  5322 net.cpp:84] Creating Layer BatchNorm11
I1007 22:17:02.444443  5322 net.cpp:406] BatchNorm11 <- Convolution11
I1007 22:17:02.444447  5322 net.cpp:367] BatchNorm11 -> Convolution11 (in-place)
I1007 22:17:02.444597  5322 net.cpp:122] Setting up BatchNorm11
I1007 22:17:02.444602  5322 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:17:02.444604  5322 net.cpp:137] Memory required for data: 281926800
I1007 22:17:02.444609  5322 layer_factory.hpp:77] Creating layer Scale11
I1007 22:17:02.444614  5322 net.cpp:84] Creating Layer Scale11
I1007 22:17:02.444617  5322 net.cpp:406] Scale11 <- Convolution11
I1007 22:17:02.444620  5322 net.cpp:367] Scale11 -> Convolution11 (in-place)
I1007 22:17:02.444646  5322 layer_factory.hpp:77] Creating layer Scale11
I1007 22:17:02.444723  5322 net.cpp:122] Setting up Scale11
I1007 22:17:02.444730  5322 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:17:02.444731  5322 net.cpp:137] Memory required for data: 286944400
I1007 22:17:02.444736  5322 layer_factory.hpp:77] Creating layer Eltwise5
I1007 22:17:02.444739  5322 net.cpp:84] Creating Layer Eltwise5
I1007 22:17:02.444741  5322 net.cpp:406] Eltwise5 <- Eltwise4_elu9_0_split_1
I1007 22:17:02.444744  5322 net.cpp:406] Eltwise5 <- Convolution11
I1007 22:17:02.444748  5322 net.cpp:380] Eltwise5 -> Eltwise5
I1007 22:17:02.444764  5322 net.cpp:122] Setting up Eltwise5
I1007 22:17:02.444768  5322 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:17:02.444772  5322 net.cpp:137] Memory required for data: 291962000
I1007 22:17:02.444773  5322 layer_factory.hpp:77] Creating layer elu11
I1007 22:17:02.444778  5322 net.cpp:84] Creating Layer elu11
I1007 22:17:02.444780  5322 net.cpp:406] elu11 <- Eltwise5
I1007 22:17:02.444783  5322 net.cpp:367] elu11 -> Eltwise5 (in-place)
I1007 22:17:02.444787  5322 net.cpp:122] Setting up elu11
I1007 22:17:02.444790  5322 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:17:02.444792  5322 net.cpp:137] Memory required for data: 296979600
I1007 22:17:02.444794  5322 layer_factory.hpp:77] Creating layer Eltwise5_elu11_0_split
I1007 22:17:02.444798  5322 net.cpp:84] Creating Layer Eltwise5_elu11_0_split
I1007 22:17:02.444800  5322 net.cpp:406] Eltwise5_elu11_0_split <- Eltwise5
I1007 22:17:02.444803  5322 net.cpp:380] Eltwise5_elu11_0_split -> Eltwise5_elu11_0_split_0
I1007 22:17:02.444808  5322 net.cpp:380] Eltwise5_elu11_0_split -> Eltwise5_elu11_0_split_1
I1007 22:17:02.444838  5322 net.cpp:122] Setting up Eltwise5_elu11_0_split
I1007 22:17:02.444842  5322 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:17:02.444845  5322 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:17:02.444847  5322 net.cpp:137] Memory required for data: 307014800
I1007 22:17:02.444850  5322 layer_factory.hpp:77] Creating layer Convolution12
I1007 22:17:02.444861  5322 net.cpp:84] Creating Layer Convolution12
I1007 22:17:02.444867  5322 net.cpp:406] Convolution12 <- Eltwise5_elu11_0_split_0
I1007 22:17:02.444875  5322 net.cpp:380] Convolution12 -> Convolution12
I1007 22:17:02.449573  5322 net.cpp:122] Setting up Convolution12
I1007 22:17:02.449585  5322 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:17:02.449590  5322 net.cpp:137] Memory required for data: 309523600
I1007 22:17:02.449597  5322 layer_factory.hpp:77] Creating layer BatchNorm12
I1007 22:17:02.449607  5322 net.cpp:84] Creating Layer BatchNorm12
I1007 22:17:02.449612  5322 net.cpp:406] BatchNorm12 <- Convolution12
I1007 22:17:02.449620  5322 net.cpp:367] BatchNorm12 -> Convolution12 (in-place)
I1007 22:17:02.449816  5322 net.cpp:122] Setting up BatchNorm12
I1007 22:17:02.449825  5322 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:17:02.449829  5322 net.cpp:137] Memory required for data: 312032400
I1007 22:17:02.449837  5322 layer_factory.hpp:77] Creating layer Scale12
I1007 22:17:02.449844  5322 net.cpp:84] Creating Layer Scale12
I1007 22:17:02.449849  5322 net.cpp:406] Scale12 <- Convolution12
I1007 22:17:02.449856  5322 net.cpp:367] Scale12 -> Convolution12 (in-place)
I1007 22:17:02.449893  5322 layer_factory.hpp:77] Creating layer Scale12
I1007 22:17:02.450002  5322 net.cpp:122] Setting up Scale12
I1007 22:17:02.450011  5322 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:17:02.450016  5322 net.cpp:137] Memory required for data: 314541200
I1007 22:17:02.450022  5322 layer_factory.hpp:77] Creating layer Convolution13
I1007 22:17:02.450033  5322 net.cpp:84] Creating Layer Convolution13
I1007 22:17:02.450038  5322 net.cpp:406] Convolution13 <- Eltwise5_elu11_0_split_1
I1007 22:17:02.450047  5322 net.cpp:380] Convolution13 -> Convolution13
I1007 22:17:02.456296  5322 net.cpp:122] Setting up Convolution13
I1007 22:17:02.456310  5322 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:17:02.456315  5322 net.cpp:137] Memory required for data: 317050000
I1007 22:17:02.456322  5322 layer_factory.hpp:77] Creating layer BatchNorm13
I1007 22:17:02.456331  5322 net.cpp:84] Creating Layer BatchNorm13
I1007 22:17:02.456336  5322 net.cpp:406] BatchNorm13 <- Convolution13
I1007 22:17:02.456342  5322 net.cpp:367] BatchNorm13 -> Convolution13 (in-place)
I1007 22:17:02.456537  5322 net.cpp:122] Setting up BatchNorm13
I1007 22:17:02.456545  5322 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:17:02.456549  5322 net.cpp:137] Memory required for data: 319558800
I1007 22:17:02.456557  5322 layer_factory.hpp:77] Creating layer Scale13
I1007 22:17:02.456565  5322 net.cpp:84] Creating Layer Scale13
I1007 22:17:02.456570  5322 net.cpp:406] Scale13 <- Convolution13
I1007 22:17:02.456578  5322 net.cpp:367] Scale13 -> Convolution13 (in-place)
I1007 22:17:02.456616  5322 layer_factory.hpp:77] Creating layer Scale13
I1007 22:17:02.456729  5322 net.cpp:122] Setting up Scale13
I1007 22:17:02.456737  5322 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:17:02.456742  5322 net.cpp:137] Memory required for data: 322067600
I1007 22:17:02.456748  5322 layer_factory.hpp:77] Creating layer elu12
I1007 22:17:02.456755  5322 net.cpp:84] Creating Layer elu12
I1007 22:17:02.456760  5322 net.cpp:406] elu12 <- Convolution13
I1007 22:17:02.456766  5322 net.cpp:367] elu12 -> Convolution13 (in-place)
I1007 22:17:02.456773  5322 net.cpp:122] Setting up elu12
I1007 22:17:02.456779  5322 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:17:02.456784  5322 net.cpp:137] Memory required for data: 324576400
I1007 22:17:02.456787  5322 layer_factory.hpp:77] Creating layer Convolution14
I1007 22:17:02.456799  5322 net.cpp:84] Creating Layer Convolution14
I1007 22:17:02.456814  5322 net.cpp:406] Convolution14 <- Convolution13
I1007 22:17:02.456822  5322 net.cpp:380] Convolution14 -> Convolution14
I1007 22:17:02.462584  5322 net.cpp:122] Setting up Convolution14
I1007 22:17:02.462599  5322 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:17:02.462604  5322 net.cpp:137] Memory required for data: 327085200
I1007 22:17:02.462611  5322 layer_factory.hpp:77] Creating layer BatchNorm14
I1007 22:17:02.462626  5322 net.cpp:84] Creating Layer BatchNorm14
I1007 22:17:02.462631  5322 net.cpp:406] BatchNorm14 <- Convolution14
I1007 22:17:02.462638  5322 net.cpp:367] BatchNorm14 -> Convolution14 (in-place)
I1007 22:17:02.462831  5322 net.cpp:122] Setting up BatchNorm14
I1007 22:17:02.462839  5322 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:17:02.462844  5322 net.cpp:137] Memory required for data: 329594000
I1007 22:17:02.462852  5322 layer_factory.hpp:77] Creating layer Scale14
I1007 22:17:02.462859  5322 net.cpp:84] Creating Layer Scale14
I1007 22:17:02.462864  5322 net.cpp:406] Scale14 <- Convolution14
I1007 22:17:02.462870  5322 net.cpp:367] Scale14 -> Convolution14 (in-place)
I1007 22:17:02.462908  5322 layer_factory.hpp:77] Creating layer Scale14
I1007 22:17:02.463018  5322 net.cpp:122] Setting up Scale14
I1007 22:17:02.463027  5322 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:17:02.463030  5322 net.cpp:137] Memory required for data: 332102800
I1007 22:17:02.463037  5322 layer_factory.hpp:77] Creating layer Eltwise6
I1007 22:17:02.463044  5322 net.cpp:84] Creating Layer Eltwise6
I1007 22:17:02.463049  5322 net.cpp:406] Eltwise6 <- Convolution12
I1007 22:17:02.463054  5322 net.cpp:406] Eltwise6 <- Convolution14
I1007 22:17:02.463063  5322 net.cpp:380] Eltwise6 -> Eltwise6
I1007 22:17:02.463086  5322 net.cpp:122] Setting up Eltwise6
I1007 22:17:02.463093  5322 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:17:02.463099  5322 net.cpp:137] Memory required for data: 334611600
I1007 22:17:02.463101  5322 layer_factory.hpp:77] Creating layer elu13
I1007 22:17:02.463109  5322 net.cpp:84] Creating Layer elu13
I1007 22:17:02.463114  5322 net.cpp:406] elu13 <- Eltwise6
I1007 22:17:02.463119  5322 net.cpp:367] elu13 -> Eltwise6 (in-place)
I1007 22:17:02.463124  5322 net.cpp:122] Setting up elu13
I1007 22:17:02.463130  5322 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:17:02.463135  5322 net.cpp:137] Memory required for data: 337120400
I1007 22:17:02.463140  5322 layer_factory.hpp:77] Creating layer Eltwise6_elu13_0_split
I1007 22:17:02.463146  5322 net.cpp:84] Creating Layer Eltwise6_elu13_0_split
I1007 22:17:02.463151  5322 net.cpp:406] Eltwise6_elu13_0_split <- Eltwise6
I1007 22:17:02.463156  5322 net.cpp:380] Eltwise6_elu13_0_split -> Eltwise6_elu13_0_split_0
I1007 22:17:02.463167  5322 net.cpp:380] Eltwise6_elu13_0_split -> Eltwise6_elu13_0_split_1
I1007 22:17:02.463204  5322 net.cpp:122] Setting up Eltwise6_elu13_0_split
I1007 22:17:02.463212  5322 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:17:02.463218  5322 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:17:02.463222  5322 net.cpp:137] Memory required for data: 342138000
I1007 22:17:02.463227  5322 layer_factory.hpp:77] Creating layer Convolution15
I1007 22:17:02.463237  5322 net.cpp:84] Creating Layer Convolution15
I1007 22:17:02.463241  5322 net.cpp:406] Convolution15 <- Eltwise6_elu13_0_split_0
I1007 22:17:02.463249  5322 net.cpp:380] Convolution15 -> Convolution15
I1007 22:17:02.464918  5322 net.cpp:122] Setting up Convolution15
I1007 22:17:02.464931  5322 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:17:02.464936  5322 net.cpp:137] Memory required for data: 344646800
I1007 22:17:02.464943  5322 layer_factory.hpp:77] Creating layer BatchNorm15
I1007 22:17:02.464953  5322 net.cpp:84] Creating Layer BatchNorm15
I1007 22:17:02.464959  5322 net.cpp:406] BatchNorm15 <- Convolution15
I1007 22:17:02.464965  5322 net.cpp:367] BatchNorm15 -> Convolution15 (in-place)
I1007 22:17:02.465167  5322 net.cpp:122] Setting up BatchNorm15
I1007 22:17:02.465175  5322 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:17:02.465190  5322 net.cpp:137] Memory required for data: 347155600
I1007 22:17:02.465199  5322 layer_factory.hpp:77] Creating layer Scale15
I1007 22:17:02.465207  5322 net.cpp:84] Creating Layer Scale15
I1007 22:17:02.465214  5322 net.cpp:406] Scale15 <- Convolution15
I1007 22:17:02.465219  5322 net.cpp:367] Scale15 -> Convolution15 (in-place)
I1007 22:17:02.465262  5322 layer_factory.hpp:77] Creating layer Scale15
I1007 22:17:02.465378  5322 net.cpp:122] Setting up Scale15
I1007 22:17:02.465386  5322 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:17:02.465391  5322 net.cpp:137] Memory required for data: 349664400
I1007 22:17:02.465399  5322 layer_factory.hpp:77] Creating layer elu14
I1007 22:17:02.465407  5322 net.cpp:84] Creating Layer elu14
I1007 22:17:02.465412  5322 net.cpp:406] elu14 <- Convolution15
I1007 22:17:02.465417  5322 net.cpp:367] elu14 -> Convolution15 (in-place)
I1007 22:17:02.465425  5322 net.cpp:122] Setting up elu14
I1007 22:17:02.465431  5322 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:17:02.465436  5322 net.cpp:137] Memory required for data: 352173200
I1007 22:17:02.465441  5322 layer_factory.hpp:77] Creating layer Convolution16
I1007 22:17:02.465452  5322 net.cpp:84] Creating Layer Convolution16
I1007 22:17:02.465457  5322 net.cpp:406] Convolution16 <- Convolution15
I1007 22:17:02.465466  5322 net.cpp:380] Convolution16 -> Convolution16
I1007 22:17:02.478026  5322 net.cpp:122] Setting up Convolution16
I1007 22:17:02.478050  5322 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:17:02.478054  5322 net.cpp:137] Memory required for data: 354682000
I1007 22:17:02.478068  5322 layer_factory.hpp:77] Creating layer BatchNorm16
I1007 22:17:02.478075  5322 net.cpp:84] Creating Layer BatchNorm16
I1007 22:17:02.478080  5322 net.cpp:406] BatchNorm16 <- Convolution16
I1007 22:17:02.478083  5322 net.cpp:367] BatchNorm16 -> Convolution16 (in-place)
I1007 22:17:02.478232  5322 net.cpp:122] Setting up BatchNorm16
I1007 22:17:02.478237  5322 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:17:02.478240  5322 net.cpp:137] Memory required for data: 357190800
I1007 22:17:02.478245  5322 layer_factory.hpp:77] Creating layer Scale16
I1007 22:17:02.478267  5322 net.cpp:84] Creating Layer Scale16
I1007 22:17:02.478271  5322 net.cpp:406] Scale16 <- Convolution16
I1007 22:17:02.478274  5322 net.cpp:367] Scale16 -> Convolution16 (in-place)
I1007 22:17:02.478317  5322 layer_factory.hpp:77] Creating layer Scale16
I1007 22:17:02.478405  5322 net.cpp:122] Setting up Scale16
I1007 22:17:02.478410  5322 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:17:02.478412  5322 net.cpp:137] Memory required for data: 359699600
I1007 22:17:02.478417  5322 layer_factory.hpp:77] Creating layer Eltwise7
I1007 22:17:02.478422  5322 net.cpp:84] Creating Layer Eltwise7
I1007 22:17:02.478425  5322 net.cpp:406] Eltwise7 <- Eltwise6_elu13_0_split_1
I1007 22:17:02.478428  5322 net.cpp:406] Eltwise7 <- Convolution16
I1007 22:17:02.478432  5322 net.cpp:380] Eltwise7 -> Eltwise7
I1007 22:17:02.478448  5322 net.cpp:122] Setting up Eltwise7
I1007 22:17:02.478453  5322 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:17:02.478456  5322 net.cpp:137] Memory required for data: 362208400
I1007 22:17:02.478457  5322 layer_factory.hpp:77] Creating layer elu15
I1007 22:17:02.478461  5322 net.cpp:84] Creating Layer elu15
I1007 22:17:02.478463  5322 net.cpp:406] elu15 <- Eltwise7
I1007 22:17:02.478467  5322 net.cpp:367] elu15 -> Eltwise7 (in-place)
I1007 22:17:02.478471  5322 net.cpp:122] Setting up elu15
I1007 22:17:02.478474  5322 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:17:02.478477  5322 net.cpp:137] Memory required for data: 364717200
I1007 22:17:02.478479  5322 layer_factory.hpp:77] Creating layer Eltwise7_elu15_0_split
I1007 22:17:02.478483  5322 net.cpp:84] Creating Layer Eltwise7_elu15_0_split
I1007 22:17:02.478485  5322 net.cpp:406] Eltwise7_elu15_0_split <- Eltwise7
I1007 22:17:02.478488  5322 net.cpp:380] Eltwise7_elu15_0_split -> Eltwise7_elu15_0_split_0
I1007 22:17:02.478502  5322 net.cpp:380] Eltwise7_elu15_0_split -> Eltwise7_elu15_0_split_1
I1007 22:17:02.478526  5322 net.cpp:122] Setting up Eltwise7_elu15_0_split
I1007 22:17:02.478531  5322 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:17:02.478534  5322 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:17:02.478536  5322 net.cpp:137] Memory required for data: 369734800
I1007 22:17:02.478538  5322 layer_factory.hpp:77] Creating layer Convolution17
I1007 22:17:02.478544  5322 net.cpp:84] Creating Layer Convolution17
I1007 22:17:02.478549  5322 net.cpp:406] Convolution17 <- Eltwise7_elu15_0_split_0
I1007 22:17:02.478552  5322 net.cpp:380] Convolution17 -> Convolution17
I1007 22:17:02.491245  5322 net.cpp:122] Setting up Convolution17
I1007 22:17:02.491255  5322 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:17:02.491257  5322 net.cpp:137] Memory required for data: 372243600
I1007 22:17:02.491261  5322 layer_factory.hpp:77] Creating layer BatchNorm17
I1007 22:17:02.491267  5322 net.cpp:84] Creating Layer BatchNorm17
I1007 22:17:02.491271  5322 net.cpp:406] BatchNorm17 <- Convolution17
I1007 22:17:02.491273  5322 net.cpp:367] BatchNorm17 -> Convolution17 (in-place)
I1007 22:17:02.491406  5322 net.cpp:122] Setting up BatchNorm17
I1007 22:17:02.491411  5322 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:17:02.491413  5322 net.cpp:137] Memory required for data: 374752400
I1007 22:17:02.491418  5322 layer_factory.hpp:77] Creating layer Scale17
I1007 22:17:02.491425  5322 net.cpp:84] Creating Layer Scale17
I1007 22:17:02.491427  5322 net.cpp:406] Scale17 <- Convolution17
I1007 22:17:02.491431  5322 net.cpp:367] Scale17 -> Convolution17 (in-place)
I1007 22:17:02.491457  5322 layer_factory.hpp:77] Creating layer Scale17
I1007 22:17:02.491534  5322 net.cpp:122] Setting up Scale17
I1007 22:17:02.491539  5322 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:17:02.491542  5322 net.cpp:137] Memory required for data: 377261200
I1007 22:17:02.491546  5322 layer_factory.hpp:77] Creating layer elu16
I1007 22:17:02.491552  5322 net.cpp:84] Creating Layer elu16
I1007 22:17:02.491555  5322 net.cpp:406] elu16 <- Convolution17
I1007 22:17:02.491559  5322 net.cpp:367] elu16 -> Convolution17 (in-place)
I1007 22:17:02.491562  5322 net.cpp:122] Setting up elu16
I1007 22:17:02.491565  5322 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:17:02.491567  5322 net.cpp:137] Memory required for data: 379770000
I1007 22:17:02.491569  5322 layer_factory.hpp:77] Creating layer Convolution18
I1007 22:17:02.491576  5322 net.cpp:84] Creating Layer Convolution18
I1007 22:17:02.491580  5322 net.cpp:406] Convolution18 <- Convolution17
I1007 22:17:02.491585  5322 net.cpp:380] Convolution18 -> Convolution18
I1007 22:17:02.504340  5322 net.cpp:122] Setting up Convolution18
I1007 22:17:02.504351  5322 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:17:02.504354  5322 net.cpp:137] Memory required for data: 382278800
I1007 22:17:02.504369  5322 layer_factory.hpp:77] Creating layer BatchNorm18
I1007 22:17:02.504374  5322 net.cpp:84] Creating Layer BatchNorm18
I1007 22:17:02.504379  5322 net.cpp:406] BatchNorm18 <- Convolution18
I1007 22:17:02.504381  5322 net.cpp:367] BatchNorm18 -> Convolution18 (in-place)
I1007 22:17:02.504523  5322 net.cpp:122] Setting up BatchNorm18
I1007 22:17:02.504528  5322 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:17:02.504530  5322 net.cpp:137] Memory required for data: 384787600
I1007 22:17:02.504545  5322 layer_factory.hpp:77] Creating layer Scale18
I1007 22:17:02.504550  5322 net.cpp:84] Creating Layer Scale18
I1007 22:17:02.504554  5322 net.cpp:406] Scale18 <- Convolution18
I1007 22:17:02.504556  5322 net.cpp:367] Scale18 -> Convolution18 (in-place)
I1007 22:17:02.504595  5322 layer_factory.hpp:77] Creating layer Scale18
I1007 22:17:02.504680  5322 net.cpp:122] Setting up Scale18
I1007 22:17:02.504685  5322 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:17:02.504688  5322 net.cpp:137] Memory required for data: 387296400
I1007 22:17:02.504693  5322 layer_factory.hpp:77] Creating layer Eltwise8
I1007 22:17:02.504704  5322 net.cpp:84] Creating Layer Eltwise8
I1007 22:17:02.504709  5322 net.cpp:406] Eltwise8 <- Eltwise7_elu15_0_split_1
I1007 22:17:02.504711  5322 net.cpp:406] Eltwise8 <- Convolution18
I1007 22:17:02.504714  5322 net.cpp:380] Eltwise8 -> Eltwise8
I1007 22:17:02.504732  5322 net.cpp:122] Setting up Eltwise8
I1007 22:17:02.504736  5322 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:17:02.504739  5322 net.cpp:137] Memory required for data: 389805200
I1007 22:17:02.504741  5322 layer_factory.hpp:77] Creating layer elu17
I1007 22:17:02.504745  5322 net.cpp:84] Creating Layer elu17
I1007 22:17:02.504747  5322 net.cpp:406] elu17 <- Eltwise8
I1007 22:17:02.504750  5322 net.cpp:367] elu17 -> Eltwise8 (in-place)
I1007 22:17:02.504755  5322 net.cpp:122] Setting up elu17
I1007 22:17:02.504758  5322 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:17:02.504760  5322 net.cpp:137] Memory required for data: 392314000
I1007 22:17:02.504763  5322 layer_factory.hpp:77] Creating layer Eltwise8_elu17_0_split
I1007 22:17:02.504766  5322 net.cpp:84] Creating Layer Eltwise8_elu17_0_split
I1007 22:17:02.504768  5322 net.cpp:406] Eltwise8_elu17_0_split <- Eltwise8
I1007 22:17:02.504772  5322 net.cpp:380] Eltwise8_elu17_0_split -> Eltwise8_elu17_0_split_0
I1007 22:17:02.504776  5322 net.cpp:380] Eltwise8_elu17_0_split -> Eltwise8_elu17_0_split_1
I1007 22:17:02.504798  5322 net.cpp:122] Setting up Eltwise8_elu17_0_split
I1007 22:17:02.504803  5322 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:17:02.504806  5322 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:17:02.504808  5322 net.cpp:137] Memory required for data: 397331600
I1007 22:17:02.504811  5322 layer_factory.hpp:77] Creating layer Convolution19
I1007 22:17:02.504817  5322 net.cpp:84] Creating Layer Convolution19
I1007 22:17:02.504820  5322 net.cpp:406] Convolution19 <- Eltwise8_elu17_0_split_0
I1007 22:17:02.504824  5322 net.cpp:380] Convolution19 -> Convolution19
I1007 22:17:02.512835  5322 net.cpp:122] Setting up Convolution19
I1007 22:17:02.512847  5322 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:17:02.512850  5322 net.cpp:137] Memory required for data: 399840400
I1007 22:17:02.512866  5322 layer_factory.hpp:77] Creating layer BatchNorm19
I1007 22:17:02.512871  5322 net.cpp:84] Creating Layer BatchNorm19
I1007 22:17:02.512874  5322 net.cpp:406] BatchNorm19 <- Convolution19
I1007 22:17:02.512879  5322 net.cpp:367] BatchNorm19 -> Convolution19 (in-place)
I1007 22:17:02.513027  5322 net.cpp:122] Setting up BatchNorm19
I1007 22:17:02.513032  5322 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:17:02.513036  5322 net.cpp:137] Memory required for data: 402349200
I1007 22:17:02.513062  5322 layer_factory.hpp:77] Creating layer Scale19
I1007 22:17:02.513077  5322 net.cpp:84] Creating Layer Scale19
I1007 22:17:02.513080  5322 net.cpp:406] Scale19 <- Convolution19
I1007 22:17:02.513085  5322 net.cpp:367] Scale19 -> Convolution19 (in-place)
I1007 22:17:02.513125  5322 layer_factory.hpp:77] Creating layer Scale19
I1007 22:17:02.513206  5322 net.cpp:122] Setting up Scale19
I1007 22:17:02.513211  5322 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:17:02.513212  5322 net.cpp:137] Memory required for data: 404858000
I1007 22:17:02.513217  5322 layer_factory.hpp:77] Creating layer elu18
I1007 22:17:02.513221  5322 net.cpp:84] Creating Layer elu18
I1007 22:17:02.513223  5322 net.cpp:406] elu18 <- Convolution19
I1007 22:17:02.513226  5322 net.cpp:367] elu18 -> Convolution19 (in-place)
I1007 22:17:02.513231  5322 net.cpp:122] Setting up elu18
I1007 22:17:02.513233  5322 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:17:02.513236  5322 net.cpp:137] Memory required for data: 407366800
I1007 22:17:02.513237  5322 layer_factory.hpp:77] Creating layer Convolution20
I1007 22:17:02.513244  5322 net.cpp:84] Creating Layer Convolution20
I1007 22:17:02.513247  5322 net.cpp:406] Convolution20 <- Convolution19
I1007 22:17:02.513252  5322 net.cpp:380] Convolution20 -> Convolution20
I1007 22:17:02.521339  5322 net.cpp:122] Setting up Convolution20
I1007 22:17:02.521356  5322 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:17:02.521360  5322 net.cpp:137] Memory required for data: 409875600
I1007 22:17:02.521364  5322 layer_factory.hpp:77] Creating layer BatchNorm20
I1007 22:17:02.521369  5322 net.cpp:84] Creating Layer BatchNorm20
I1007 22:17:02.521373  5322 net.cpp:406] BatchNorm20 <- Convolution20
I1007 22:17:02.521376  5322 net.cpp:367] BatchNorm20 -> Convolution20 (in-place)
I1007 22:17:02.521513  5322 net.cpp:122] Setting up BatchNorm20
I1007 22:17:02.521519  5322 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:17:02.521522  5322 net.cpp:137] Memory required for data: 412384400
I1007 22:17:02.521526  5322 layer_factory.hpp:77] Creating layer Scale20
I1007 22:17:02.521530  5322 net.cpp:84] Creating Layer Scale20
I1007 22:17:02.521533  5322 net.cpp:406] Scale20 <- Convolution20
I1007 22:17:02.521538  5322 net.cpp:367] Scale20 -> Convolution20 (in-place)
I1007 22:17:02.521564  5322 layer_factory.hpp:77] Creating layer Scale20
I1007 22:17:02.521643  5322 net.cpp:122] Setting up Scale20
I1007 22:17:02.521648  5322 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:17:02.521651  5322 net.cpp:137] Memory required for data: 414893200
I1007 22:17:02.521654  5322 layer_factory.hpp:77] Creating layer Eltwise9
I1007 22:17:02.521658  5322 net.cpp:84] Creating Layer Eltwise9
I1007 22:17:02.521661  5322 net.cpp:406] Eltwise9 <- Eltwise8_elu17_0_split_1
I1007 22:17:02.521664  5322 net.cpp:406] Eltwise9 <- Convolution20
I1007 22:17:02.521668  5322 net.cpp:380] Eltwise9 -> Eltwise9
I1007 22:17:02.521684  5322 net.cpp:122] Setting up Eltwise9
I1007 22:17:02.521689  5322 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:17:02.521692  5322 net.cpp:137] Memory required for data: 417402000
I1007 22:17:02.521693  5322 layer_factory.hpp:77] Creating layer elu19
I1007 22:17:02.521697  5322 net.cpp:84] Creating Layer elu19
I1007 22:17:02.521699  5322 net.cpp:406] elu19 <- Eltwise9
I1007 22:17:02.521703  5322 net.cpp:367] elu19 -> Eltwise9 (in-place)
I1007 22:17:02.521706  5322 net.cpp:122] Setting up elu19
I1007 22:17:02.521709  5322 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:17:02.521711  5322 net.cpp:137] Memory required for data: 419910800
I1007 22:17:02.521713  5322 layer_factory.hpp:77] Creating layer Eltwise9_elu19_0_split
I1007 22:17:02.521718  5322 net.cpp:84] Creating Layer Eltwise9_elu19_0_split
I1007 22:17:02.521719  5322 net.cpp:406] Eltwise9_elu19_0_split <- Eltwise9
I1007 22:17:02.521724  5322 net.cpp:380] Eltwise9_elu19_0_split -> Eltwise9_elu19_0_split_0
I1007 22:17:02.521729  5322 net.cpp:380] Eltwise9_elu19_0_split -> Eltwise9_elu19_0_split_1
I1007 22:17:02.521751  5322 net.cpp:122] Setting up Eltwise9_elu19_0_split
I1007 22:17:02.521756  5322 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:17:02.521759  5322 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:17:02.521762  5322 net.cpp:137] Memory required for data: 424928400
I1007 22:17:02.521764  5322 layer_factory.hpp:77] Creating layer Convolution21
I1007 22:17:02.521770  5322 net.cpp:84] Creating Layer Convolution21
I1007 22:17:02.521773  5322 net.cpp:406] Convolution21 <- Eltwise9_elu19_0_split_0
I1007 22:17:02.521778  5322 net.cpp:380] Convolution21 -> Convolution21
I1007 22:17:02.534754  5322 net.cpp:122] Setting up Convolution21
I1007 22:17:02.534766  5322 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:17:02.534770  5322 net.cpp:137] Memory required for data: 427437200
I1007 22:17:02.534773  5322 layer_factory.hpp:77] Creating layer BatchNorm21
I1007 22:17:02.534780  5322 net.cpp:84] Creating Layer BatchNorm21
I1007 22:17:02.534788  5322 net.cpp:406] BatchNorm21 <- Convolution21
I1007 22:17:02.534792  5322 net.cpp:367] BatchNorm21 -> Convolution21 (in-place)
I1007 22:17:02.534934  5322 net.cpp:122] Setting up BatchNorm21
I1007 22:17:02.534940  5322 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:17:02.534941  5322 net.cpp:137] Memory required for data: 429946000
I1007 22:17:02.534946  5322 layer_factory.hpp:77] Creating layer Scale21
I1007 22:17:02.534960  5322 net.cpp:84] Creating Layer Scale21
I1007 22:17:02.534962  5322 net.cpp:406] Scale21 <- Convolution21
I1007 22:17:02.534976  5322 net.cpp:367] Scale21 -> Convolution21 (in-place)
I1007 22:17:02.535015  5322 layer_factory.hpp:77] Creating layer Scale21
I1007 22:17:02.535094  5322 net.cpp:122] Setting up Scale21
I1007 22:17:02.535099  5322 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:17:02.535102  5322 net.cpp:137] Memory required for data: 432454800
I1007 22:17:02.535106  5322 layer_factory.hpp:77] Creating layer elu20
I1007 22:17:02.535110  5322 net.cpp:84] Creating Layer elu20
I1007 22:17:02.535112  5322 net.cpp:406] elu20 <- Convolution21
I1007 22:17:02.535116  5322 net.cpp:367] elu20 -> Convolution21 (in-place)
I1007 22:17:02.535120  5322 net.cpp:122] Setting up elu20
I1007 22:17:02.535125  5322 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:17:02.535127  5322 net.cpp:137] Memory required for data: 434963600
I1007 22:17:02.535130  5322 layer_factory.hpp:77] Creating layer Convolution22
I1007 22:17:02.535136  5322 net.cpp:84] Creating Layer Convolution22
I1007 22:17:02.535140  5322 net.cpp:406] Convolution22 <- Convolution21
I1007 22:17:02.535143  5322 net.cpp:380] Convolution22 -> Convolution22
I1007 22:17:02.548141  5322 net.cpp:122] Setting up Convolution22
I1007 22:17:02.548151  5322 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:17:02.548153  5322 net.cpp:137] Memory required for data: 437472400
I1007 22:17:02.548168  5322 layer_factory.hpp:77] Creating layer BatchNorm22
I1007 22:17:02.548176  5322 net.cpp:84] Creating Layer BatchNorm22
I1007 22:17:02.548182  5322 net.cpp:406] BatchNorm22 <- Convolution22
I1007 22:17:02.548197  5322 net.cpp:367] BatchNorm22 -> Convolution22 (in-place)
I1007 22:17:02.548337  5322 net.cpp:122] Setting up BatchNorm22
I1007 22:17:02.548343  5322 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:17:02.548346  5322 net.cpp:137] Memory required for data: 439981200
I1007 22:17:02.548365  5322 layer_factory.hpp:77] Creating layer Scale22
I1007 22:17:02.548372  5322 net.cpp:84] Creating Layer Scale22
I1007 22:17:02.548375  5322 net.cpp:406] Scale22 <- Convolution22
I1007 22:17:02.548378  5322 net.cpp:367] Scale22 -> Convolution22 (in-place)
I1007 22:17:02.548420  5322 layer_factory.hpp:77] Creating layer Scale22
I1007 22:17:02.548502  5322 net.cpp:122] Setting up Scale22
I1007 22:17:02.548508  5322 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:17:02.548511  5322 net.cpp:137] Memory required for data: 442490000
I1007 22:17:02.548528  5322 layer_factory.hpp:77] Creating layer Eltwise10
I1007 22:17:02.548534  5322 net.cpp:84] Creating Layer Eltwise10
I1007 22:17:02.548537  5322 net.cpp:406] Eltwise10 <- Eltwise9_elu19_0_split_1
I1007 22:17:02.548540  5322 net.cpp:406] Eltwise10 <- Convolution22
I1007 22:17:02.548545  5322 net.cpp:380] Eltwise10 -> Eltwise10
I1007 22:17:02.548563  5322 net.cpp:122] Setting up Eltwise10
I1007 22:17:02.548578  5322 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:17:02.548579  5322 net.cpp:137] Memory required for data: 444998800
I1007 22:17:02.548581  5322 layer_factory.hpp:77] Creating layer elu21
I1007 22:17:02.548595  5322 net.cpp:84] Creating Layer elu21
I1007 22:17:02.548599  5322 net.cpp:406] elu21 <- Eltwise10
I1007 22:17:02.548602  5322 net.cpp:367] elu21 -> Eltwise10 (in-place)
I1007 22:17:02.548605  5322 net.cpp:122] Setting up elu21
I1007 22:17:02.548609  5322 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:17:02.548611  5322 net.cpp:137] Memory required for data: 447507600
I1007 22:17:02.548614  5322 layer_factory.hpp:77] Creating layer Eltwise10_elu21_0_split
I1007 22:17:02.548617  5322 net.cpp:84] Creating Layer Eltwise10_elu21_0_split
I1007 22:17:02.548619  5322 net.cpp:406] Eltwise10_elu21_0_split <- Eltwise10
I1007 22:17:02.548622  5322 net.cpp:380] Eltwise10_elu21_0_split -> Eltwise10_elu21_0_split_0
I1007 22:17:02.548626  5322 net.cpp:380] Eltwise10_elu21_0_split -> Eltwise10_elu21_0_split_1
I1007 22:17:02.548650  5322 net.cpp:122] Setting up Eltwise10_elu21_0_split
I1007 22:17:02.548662  5322 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:17:02.548666  5322 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:17:02.548668  5322 net.cpp:137] Memory required for data: 452525200
I1007 22:17:02.548671  5322 layer_factory.hpp:77] Creating layer Convolution23
I1007 22:17:02.548678  5322 net.cpp:84] Creating Layer Convolution23
I1007 22:17:02.548681  5322 net.cpp:406] Convolution23 <- Eltwise10_elu21_0_split_0
I1007 22:17:02.548686  5322 net.cpp:380] Convolution23 -> Convolution23
I1007 22:17:02.561270  5322 net.cpp:122] Setting up Convolution23
I1007 22:17:02.561280  5322 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:17:02.561283  5322 net.cpp:137] Memory required for data: 453779600
I1007 22:17:02.561290  5322 layer_factory.hpp:77] Creating layer BatchNorm23
I1007 22:17:02.561297  5322 net.cpp:84] Creating Layer BatchNorm23
I1007 22:17:02.561302  5322 net.cpp:406] BatchNorm23 <- Convolution23
I1007 22:17:02.561309  5322 net.cpp:367] BatchNorm23 -> Convolution23 (in-place)
I1007 22:17:02.561450  5322 net.cpp:122] Setting up BatchNorm23
I1007 22:17:02.561456  5322 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:17:02.561460  5322 net.cpp:137] Memory required for data: 455034000
I1007 22:17:02.561470  5322 layer_factory.hpp:77] Creating layer Scale23
I1007 22:17:02.561475  5322 net.cpp:84] Creating Layer Scale23
I1007 22:17:02.561478  5322 net.cpp:406] Scale23 <- Convolution23
I1007 22:17:02.561486  5322 net.cpp:367] Scale23 -> Convolution23 (in-place)
I1007 22:17:02.561517  5322 layer_factory.hpp:77] Creating layer Scale23
I1007 22:17:02.561599  5322 net.cpp:122] Setting up Scale23
I1007 22:17:02.561604  5322 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:17:02.561609  5322 net.cpp:137] Memory required for data: 456288400
I1007 22:17:02.561615  5322 layer_factory.hpp:77] Creating layer Convolution24
I1007 22:17:02.561625  5322 net.cpp:84] Creating Layer Convolution24
I1007 22:17:02.561630  5322 net.cpp:406] Convolution24 <- Eltwise10_elu21_0_split_1
I1007 22:17:02.561636  5322 net.cpp:380] Convolution24 -> Convolution24
I1007 22:17:02.574920  5322 net.cpp:122] Setting up Convolution24
I1007 22:17:02.574932  5322 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:17:02.574936  5322 net.cpp:137] Memory required for data: 457542800
I1007 22:17:02.574944  5322 layer_factory.hpp:77] Creating layer BatchNorm24
I1007 22:17:02.574964  5322 net.cpp:84] Creating Layer BatchNorm24
I1007 22:17:02.574967  5322 net.cpp:406] BatchNorm24 <- Convolution24
I1007 22:17:02.574971  5322 net.cpp:367] BatchNorm24 -> Convolution24 (in-place)
I1007 22:17:02.575117  5322 net.cpp:122] Setting up BatchNorm24
I1007 22:17:02.575124  5322 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:17:02.575125  5322 net.cpp:137] Memory required for data: 458797200
I1007 22:17:02.575145  5322 layer_factory.hpp:77] Creating layer Scale24
I1007 22:17:02.575150  5322 net.cpp:84] Creating Layer Scale24
I1007 22:17:02.575152  5322 net.cpp:406] Scale24 <- Convolution24
I1007 22:17:02.575157  5322 net.cpp:367] Scale24 -> Convolution24 (in-place)
I1007 22:17:02.575196  5322 layer_factory.hpp:77] Creating layer Scale24
I1007 22:17:02.575280  5322 net.cpp:122] Setting up Scale24
I1007 22:17:02.575286  5322 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:17:02.575289  5322 net.cpp:137] Memory required for data: 460051600
I1007 22:17:02.575295  5322 layer_factory.hpp:77] Creating layer elu22
I1007 22:17:02.575300  5322 net.cpp:84] Creating Layer elu22
I1007 22:17:02.575304  5322 net.cpp:406] elu22 <- Convolution24
I1007 22:17:02.575307  5322 net.cpp:367] elu22 -> Convolution24 (in-place)
I1007 22:17:02.575312  5322 net.cpp:122] Setting up elu22
I1007 22:17:02.575316  5322 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:17:02.575318  5322 net.cpp:137] Memory required for data: 461306000
I1007 22:17:02.575321  5322 layer_factory.hpp:77] Creating layer Convolution25
I1007 22:17:02.575330  5322 net.cpp:84] Creating Layer Convolution25
I1007 22:17:02.575333  5322 net.cpp:406] Convolution25 <- Convolution24
I1007 22:17:02.575350  5322 net.cpp:380] Convolution25 -> Convolution25
I1007 22:17:02.582332  5322 net.cpp:122] Setting up Convolution25
I1007 22:17:02.582342  5322 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:17:02.582346  5322 net.cpp:137] Memory required for data: 462560400
I1007 22:17:02.582355  5322 layer_factory.hpp:77] Creating layer BatchNorm25
I1007 22:17:02.582361  5322 net.cpp:84] Creating Layer BatchNorm25
I1007 22:17:02.582375  5322 net.cpp:406] BatchNorm25 <- Convolution25
I1007 22:17:02.582381  5322 net.cpp:367] BatchNorm25 -> Convolution25 (in-place)
I1007 22:17:02.582537  5322 net.cpp:122] Setting up BatchNorm25
I1007 22:17:02.582543  5322 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:17:02.582548  5322 net.cpp:137] Memory required for data: 463814800
I1007 22:17:02.582556  5322 layer_factory.hpp:77] Creating layer Scale25
I1007 22:17:02.582561  5322 net.cpp:84] Creating Layer Scale25
I1007 22:17:02.582566  5322 net.cpp:406] Scale25 <- Convolution25
I1007 22:17:02.582572  5322 net.cpp:367] Scale25 -> Convolution25 (in-place)
I1007 22:17:02.582603  5322 layer_factory.hpp:77] Creating layer Scale25
I1007 22:17:02.582689  5322 net.cpp:122] Setting up Scale25
I1007 22:17:02.582693  5322 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:17:02.582698  5322 net.cpp:137] Memory required for data: 465069200
I1007 22:17:02.582705  5322 layer_factory.hpp:77] Creating layer Eltwise11
I1007 22:17:02.582710  5322 net.cpp:84] Creating Layer Eltwise11
I1007 22:17:02.582715  5322 net.cpp:406] Eltwise11 <- Convolution23
I1007 22:17:02.582720  5322 net.cpp:406] Eltwise11 <- Convolution25
I1007 22:17:02.582727  5322 net.cpp:380] Eltwise11 -> Eltwise11
I1007 22:17:02.582748  5322 net.cpp:122] Setting up Eltwise11
I1007 22:17:02.582753  5322 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:17:02.582757  5322 net.cpp:137] Memory required for data: 466323600
I1007 22:17:02.582762  5322 layer_factory.hpp:77] Creating layer elu23
I1007 22:17:02.582767  5322 net.cpp:84] Creating Layer elu23
I1007 22:17:02.582772  5322 net.cpp:406] elu23 <- Eltwise11
I1007 22:17:02.582775  5322 net.cpp:367] elu23 -> Eltwise11 (in-place)
I1007 22:17:02.582782  5322 net.cpp:122] Setting up elu23
I1007 22:17:02.582787  5322 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:17:02.582790  5322 net.cpp:137] Memory required for data: 467578000
I1007 22:17:02.582795  5322 layer_factory.hpp:77] Creating layer Eltwise11_elu23_0_split
I1007 22:17:02.582801  5322 net.cpp:84] Creating Layer Eltwise11_elu23_0_split
I1007 22:17:02.582805  5322 net.cpp:406] Eltwise11_elu23_0_split <- Eltwise11
I1007 22:17:02.582809  5322 net.cpp:380] Eltwise11_elu23_0_split -> Eltwise11_elu23_0_split_0
I1007 22:17:02.582816  5322 net.cpp:380] Eltwise11_elu23_0_split -> Eltwise11_elu23_0_split_1
I1007 22:17:02.582844  5322 net.cpp:122] Setting up Eltwise11_elu23_0_split
I1007 22:17:02.582849  5322 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:17:02.582854  5322 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:17:02.582857  5322 net.cpp:137] Memory required for data: 470086800
I1007 22:17:02.582860  5322 layer_factory.hpp:77] Creating layer Convolution26
I1007 22:17:02.582870  5322 net.cpp:84] Creating Layer Convolution26
I1007 22:17:02.582872  5322 net.cpp:406] Convolution26 <- Eltwise11_elu23_0_split_0
I1007 22:17:02.582880  5322 net.cpp:380] Convolution26 -> Convolution26
I1007 22:17:02.588771  5322 net.cpp:122] Setting up Convolution26
I1007 22:17:02.588783  5322 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:17:02.588786  5322 net.cpp:137] Memory required for data: 471341200
I1007 22:17:02.588793  5322 layer_factory.hpp:77] Creating layer BatchNorm26
I1007 22:17:02.588799  5322 net.cpp:84] Creating Layer BatchNorm26
I1007 22:17:02.588804  5322 net.cpp:406] BatchNorm26 <- Convolution26
I1007 22:17:02.588807  5322 net.cpp:367] BatchNorm26 -> Convolution26 (in-place)
I1007 22:17:02.588946  5322 net.cpp:122] Setting up BatchNorm26
I1007 22:17:02.588953  5322 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:17:02.588963  5322 net.cpp:137] Memory required for data: 472595600
I1007 22:17:02.588968  5322 layer_factory.hpp:77] Creating layer Scale26
I1007 22:17:02.588973  5322 net.cpp:84] Creating Layer Scale26
I1007 22:17:02.588975  5322 net.cpp:406] Scale26 <- Convolution26
I1007 22:17:02.588979  5322 net.cpp:367] Scale26 -> Convolution26 (in-place)
I1007 22:17:02.589009  5322 layer_factory.hpp:77] Creating layer Scale26
I1007 22:17:02.589088  5322 net.cpp:122] Setting up Scale26
I1007 22:17:02.589093  5322 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:17:02.589095  5322 net.cpp:137] Memory required for data: 473850000
I1007 22:17:02.589099  5322 layer_factory.hpp:77] Creating layer elu24
I1007 22:17:02.589104  5322 net.cpp:84] Creating Layer elu24
I1007 22:17:02.589107  5322 net.cpp:406] elu24 <- Convolution26
I1007 22:17:02.589110  5322 net.cpp:367] elu24 -> Convolution26 (in-place)
I1007 22:17:02.589114  5322 net.cpp:122] Setting up elu24
I1007 22:17:02.589118  5322 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:17:02.589119  5322 net.cpp:137] Memory required for data: 475104400
I1007 22:17:02.589123  5322 layer_factory.hpp:77] Creating layer Convolution27
I1007 22:17:02.589129  5322 net.cpp:84] Creating Layer Convolution27
I1007 22:17:02.589133  5322 net.cpp:406] Convolution27 <- Convolution26
I1007 22:17:02.589138  5322 net.cpp:380] Convolution27 -> Convolution27
I1007 22:17:02.596200  5322 net.cpp:122] Setting up Convolution27
I1007 22:17:02.596212  5322 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:17:02.596215  5322 net.cpp:137] Memory required for data: 476358800
I1007 22:17:02.596230  5322 layer_factory.hpp:77] Creating layer BatchNorm27
I1007 22:17:02.596246  5322 net.cpp:84] Creating Layer BatchNorm27
I1007 22:17:02.596248  5322 net.cpp:406] BatchNorm27 <- Convolution27
I1007 22:17:02.596253  5322 net.cpp:367] BatchNorm27 -> Convolution27 (in-place)
I1007 22:17:02.596398  5322 net.cpp:122] Setting up BatchNorm27
I1007 22:17:02.596405  5322 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:17:02.596406  5322 net.cpp:137] Memory required for data: 477613200
I1007 22:17:02.596411  5322 layer_factory.hpp:77] Creating layer Scale27
I1007 22:17:02.596428  5322 net.cpp:84] Creating Layer Scale27
I1007 22:17:02.596431  5322 net.cpp:406] Scale27 <- Convolution27
I1007 22:17:02.596436  5322 net.cpp:367] Scale27 -> Convolution27 (in-place)
I1007 22:17:02.596464  5322 layer_factory.hpp:77] Creating layer Scale27
I1007 22:17:02.596546  5322 net.cpp:122] Setting up Scale27
I1007 22:17:02.596551  5322 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:17:02.596554  5322 net.cpp:137] Memory required for data: 478867600
I1007 22:17:02.596559  5322 layer_factory.hpp:77] Creating layer Eltwise12
I1007 22:17:02.596563  5322 net.cpp:84] Creating Layer Eltwise12
I1007 22:17:02.596566  5322 net.cpp:406] Eltwise12 <- Eltwise11_elu23_0_split_1
I1007 22:17:02.596570  5322 net.cpp:406] Eltwise12 <- Convolution27
I1007 22:17:02.596573  5322 net.cpp:380] Eltwise12 -> Eltwise12
I1007 22:17:02.596597  5322 net.cpp:122] Setting up Eltwise12
I1007 22:17:02.596603  5322 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:17:02.596607  5322 net.cpp:137] Memory required for data: 480122000
I1007 22:17:02.596612  5322 layer_factory.hpp:77] Creating layer elu25
I1007 22:17:02.596621  5322 net.cpp:84] Creating Layer elu25
I1007 22:17:02.596626  5322 net.cpp:406] elu25 <- Eltwise12
I1007 22:17:02.596629  5322 net.cpp:367] elu25 -> Eltwise12 (in-place)
I1007 22:17:02.596637  5322 net.cpp:122] Setting up elu25
I1007 22:17:02.596642  5322 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:17:02.596647  5322 net.cpp:137] Memory required for data: 481376400
I1007 22:17:02.596650  5322 layer_factory.hpp:77] Creating layer Eltwise12_elu25_0_split
I1007 22:17:02.596657  5322 net.cpp:84] Creating Layer Eltwise12_elu25_0_split
I1007 22:17:02.596662  5322 net.cpp:406] Eltwise12_elu25_0_split <- Eltwise12
I1007 22:17:02.596666  5322 net.cpp:380] Eltwise12_elu25_0_split -> Eltwise12_elu25_0_split_0
I1007 22:17:02.596673  5322 net.cpp:380] Eltwise12_elu25_0_split -> Eltwise12_elu25_0_split_1
I1007 22:17:02.596709  5322 net.cpp:122] Setting up Eltwise12_elu25_0_split
I1007 22:17:02.596714  5322 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:17:02.596717  5322 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:17:02.596719  5322 net.cpp:137] Memory required for data: 483885200
I1007 22:17:02.596721  5322 layer_factory.hpp:77] Creating layer Convolution28
I1007 22:17:02.596729  5322 net.cpp:84] Creating Layer Convolution28
I1007 22:17:02.596732  5322 net.cpp:406] Convolution28 <- Eltwise12_elu25_0_split_0
I1007 22:17:02.596736  5322 net.cpp:380] Convolution28 -> Convolution28
I1007 22:17:02.602867  5322 net.cpp:122] Setting up Convolution28
I1007 22:17:02.602879  5322 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:17:02.602881  5322 net.cpp:137] Memory required for data: 485139600
I1007 22:17:02.602885  5322 layer_factory.hpp:77] Creating layer BatchNorm28
I1007 22:17:02.602890  5322 net.cpp:84] Creating Layer BatchNorm28
I1007 22:17:02.602893  5322 net.cpp:406] BatchNorm28 <- Convolution28
I1007 22:17:02.602897  5322 net.cpp:367] BatchNorm28 -> Convolution28 (in-place)
I1007 22:17:02.603037  5322 net.cpp:122] Setting up BatchNorm28
I1007 22:17:02.603042  5322 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:17:02.603044  5322 net.cpp:137] Memory required for data: 486394000
I1007 22:17:02.603049  5322 layer_factory.hpp:77] Creating layer Scale28
I1007 22:17:02.603055  5322 net.cpp:84] Creating Layer Scale28
I1007 22:17:02.603057  5322 net.cpp:406] Scale28 <- Convolution28
I1007 22:17:02.603061  5322 net.cpp:367] Scale28 -> Convolution28 (in-place)
I1007 22:17:02.603090  5322 layer_factory.hpp:77] Creating layer Scale28
I1007 22:17:02.603176  5322 net.cpp:122] Setting up Scale28
I1007 22:17:02.603183  5322 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:17:02.603185  5322 net.cpp:137] Memory required for data: 487648400
I1007 22:17:02.603189  5322 layer_factory.hpp:77] Creating layer elu26
I1007 22:17:02.603193  5322 net.cpp:84] Creating Layer elu26
I1007 22:17:02.603196  5322 net.cpp:406] elu26 <- Convolution28
I1007 22:17:02.603200  5322 net.cpp:367] elu26 -> Convolution28 (in-place)
I1007 22:17:02.603204  5322 net.cpp:122] Setting up elu26
I1007 22:17:02.603209  5322 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:17:02.603210  5322 net.cpp:137] Memory required for data: 488902800
I1007 22:17:02.603212  5322 layer_factory.hpp:77] Creating layer Convolution29
I1007 22:17:02.603219  5322 net.cpp:84] Creating Layer Convolution29
I1007 22:17:02.603221  5322 net.cpp:406] Convolution29 <- Convolution28
I1007 22:17:02.603225  5322 net.cpp:380] Convolution29 -> Convolution29
I1007 22:17:02.609848  5322 net.cpp:122] Setting up Convolution29
I1007 22:17:02.609858  5322 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:17:02.609860  5322 net.cpp:137] Memory required for data: 490157200
I1007 22:17:02.609865  5322 layer_factory.hpp:77] Creating layer BatchNorm29
I1007 22:17:02.609871  5322 net.cpp:84] Creating Layer BatchNorm29
I1007 22:17:02.609874  5322 net.cpp:406] BatchNorm29 <- Convolution29
I1007 22:17:02.609879  5322 net.cpp:367] BatchNorm29 -> Convolution29 (in-place)
I1007 22:17:02.610023  5322 net.cpp:122] Setting up BatchNorm29
I1007 22:17:02.610028  5322 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:17:02.610030  5322 net.cpp:137] Memory required for data: 491411600
I1007 22:17:02.610036  5322 layer_factory.hpp:77] Creating layer Scale29
I1007 22:17:02.610040  5322 net.cpp:84] Creating Layer Scale29
I1007 22:17:02.610044  5322 net.cpp:406] Scale29 <- Convolution29
I1007 22:17:02.610047  5322 net.cpp:367] Scale29 -> Convolution29 (in-place)
I1007 22:17:02.610075  5322 layer_factory.hpp:77] Creating layer Scale29
I1007 22:17:02.610157  5322 net.cpp:122] Setting up Scale29
I1007 22:17:02.610162  5322 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:17:02.610164  5322 net.cpp:137] Memory required for data: 492666000
I1007 22:17:02.610168  5322 layer_factory.hpp:77] Creating layer Eltwise13
I1007 22:17:02.610172  5322 net.cpp:84] Creating Layer Eltwise13
I1007 22:17:02.610183  5322 net.cpp:406] Eltwise13 <- Eltwise12_elu25_0_split_1
I1007 22:17:02.610186  5322 net.cpp:406] Eltwise13 <- Convolution29
I1007 22:17:02.610191  5322 net.cpp:380] Eltwise13 -> Eltwise13
I1007 22:17:02.610209  5322 net.cpp:122] Setting up Eltwise13
I1007 22:17:02.610214  5322 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:17:02.610216  5322 net.cpp:137] Memory required for data: 493920400
I1007 22:17:02.610219  5322 layer_factory.hpp:77] Creating layer elu27
I1007 22:17:02.610224  5322 net.cpp:84] Creating Layer elu27
I1007 22:17:02.610225  5322 net.cpp:406] elu27 <- Eltwise13
I1007 22:17:02.610229  5322 net.cpp:367] elu27 -> Eltwise13 (in-place)
I1007 22:17:02.610232  5322 net.cpp:122] Setting up elu27
I1007 22:17:02.610235  5322 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:17:02.610237  5322 net.cpp:137] Memory required for data: 495174800
I1007 22:17:02.610239  5322 layer_factory.hpp:77] Creating layer Eltwise13_elu27_0_split
I1007 22:17:02.610244  5322 net.cpp:84] Creating Layer Eltwise13_elu27_0_split
I1007 22:17:02.610246  5322 net.cpp:406] Eltwise13_elu27_0_split <- Eltwise13
I1007 22:17:02.610249  5322 net.cpp:380] Eltwise13_elu27_0_split -> Eltwise13_elu27_0_split_0
I1007 22:17:02.610254  5322 net.cpp:380] Eltwise13_elu27_0_split -> Eltwise13_elu27_0_split_1
I1007 22:17:02.610277  5322 net.cpp:122] Setting up Eltwise13_elu27_0_split
I1007 22:17:02.610282  5322 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:17:02.610285  5322 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:17:02.610287  5322 net.cpp:137] Memory required for data: 497683600
I1007 22:17:02.610290  5322 layer_factory.hpp:77] Creating layer Convolution30
I1007 22:17:02.610296  5322 net.cpp:84] Creating Layer Convolution30
I1007 22:17:02.610299  5322 net.cpp:406] Convolution30 <- Eltwise13_elu27_0_split_0
I1007 22:17:02.610304  5322 net.cpp:380] Convolution30 -> Convolution30
I1007 22:17:02.612170  5322 net.cpp:122] Setting up Convolution30
I1007 22:17:02.612181  5322 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:17:02.612185  5322 net.cpp:137] Memory required for data: 498938000
I1007 22:17:02.612188  5322 layer_factory.hpp:77] Creating layer BatchNorm30
I1007 22:17:02.612195  5322 net.cpp:84] Creating Layer BatchNorm30
I1007 22:17:02.612197  5322 net.cpp:406] BatchNorm30 <- Convolution30
I1007 22:17:02.612201  5322 net.cpp:367] BatchNorm30 -> Convolution30 (in-place)
I1007 22:17:02.612340  5322 net.cpp:122] Setting up BatchNorm30
I1007 22:17:02.612346  5322 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:17:02.612349  5322 net.cpp:137] Memory required for data: 500192400
I1007 22:17:02.612354  5322 layer_factory.hpp:77] Creating layer Scale30
I1007 22:17:02.612359  5322 net.cpp:84] Creating Layer Scale30
I1007 22:17:02.612360  5322 net.cpp:406] Scale30 <- Convolution30
I1007 22:17:02.612363  5322 net.cpp:367] Scale30 -> Convolution30 (in-place)
I1007 22:17:02.612392  5322 layer_factory.hpp:77] Creating layer Scale30
I1007 22:17:02.612473  5322 net.cpp:122] Setting up Scale30
I1007 22:17:02.612478  5322 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:17:02.612480  5322 net.cpp:137] Memory required for data: 501446800
I1007 22:17:02.612484  5322 layer_factory.hpp:77] Creating layer elu28
I1007 22:17:02.612488  5322 net.cpp:84] Creating Layer elu28
I1007 22:17:02.612491  5322 net.cpp:406] elu28 <- Convolution30
I1007 22:17:02.612495  5322 net.cpp:367] elu28 -> Convolution30 (in-place)
I1007 22:17:02.612499  5322 net.cpp:122] Setting up elu28
I1007 22:17:02.612504  5322 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:17:02.612505  5322 net.cpp:137] Memory required for data: 502701200
I1007 22:17:02.612507  5322 layer_factory.hpp:77] Creating layer Convolution31
I1007 22:17:02.612515  5322 net.cpp:84] Creating Layer Convolution31
I1007 22:17:02.612519  5322 net.cpp:406] Convolution31 <- Convolution30
I1007 22:17:02.612522  5322 net.cpp:380] Convolution31 -> Convolution31
I1007 22:17:02.614460  5322 net.cpp:122] Setting up Convolution31
I1007 22:17:02.614477  5322 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:17:02.614490  5322 net.cpp:137] Memory required for data: 503955600
I1007 22:17:02.614495  5322 layer_factory.hpp:77] Creating layer BatchNorm31
I1007 22:17:02.614501  5322 net.cpp:84] Creating Layer BatchNorm31
I1007 22:17:02.614504  5322 net.cpp:406] BatchNorm31 <- Convolution31
I1007 22:17:02.614508  5322 net.cpp:367] BatchNorm31 -> Convolution31 (in-place)
I1007 22:17:02.614679  5322 net.cpp:122] Setting up BatchNorm31
I1007 22:17:02.614686  5322 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:17:02.614697  5322 net.cpp:137] Memory required for data: 505210000
I1007 22:17:02.614702  5322 layer_factory.hpp:77] Creating layer Scale31
I1007 22:17:02.614706  5322 net.cpp:84] Creating Layer Scale31
I1007 22:17:02.614709  5322 net.cpp:406] Scale31 <- Convolution31
I1007 22:17:02.614712  5322 net.cpp:367] Scale31 -> Convolution31 (in-place)
I1007 22:17:02.614742  5322 layer_factory.hpp:77] Creating layer Scale31
I1007 22:17:02.614825  5322 net.cpp:122] Setting up Scale31
I1007 22:17:02.614830  5322 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:17:02.614831  5322 net.cpp:137] Memory required for data: 506464400
I1007 22:17:02.614835  5322 layer_factory.hpp:77] Creating layer Eltwise14
I1007 22:17:02.614840  5322 net.cpp:84] Creating Layer Eltwise14
I1007 22:17:02.614843  5322 net.cpp:406] Eltwise14 <- Eltwise13_elu27_0_split_1
I1007 22:17:02.614846  5322 net.cpp:406] Eltwise14 <- Convolution31
I1007 22:17:02.614850  5322 net.cpp:380] Eltwise14 -> Eltwise14
I1007 22:17:02.614866  5322 net.cpp:122] Setting up Eltwise14
I1007 22:17:02.614871  5322 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:17:02.614873  5322 net.cpp:137] Memory required for data: 507718800
I1007 22:17:02.614876  5322 layer_factory.hpp:77] Creating layer elu29
I1007 22:17:02.614879  5322 net.cpp:84] Creating Layer elu29
I1007 22:17:02.614881  5322 net.cpp:406] elu29 <- Eltwise14
I1007 22:17:02.614886  5322 net.cpp:367] elu29 -> Eltwise14 (in-place)
I1007 22:17:02.614889  5322 net.cpp:122] Setting up elu29
I1007 22:17:02.614892  5322 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:17:02.614894  5322 net.cpp:137] Memory required for data: 508973200
I1007 22:17:02.614897  5322 layer_factory.hpp:77] Creating layer Eltwise14_elu29_0_split
I1007 22:17:02.614900  5322 net.cpp:84] Creating Layer Eltwise14_elu29_0_split
I1007 22:17:02.614902  5322 net.cpp:406] Eltwise14_elu29_0_split <- Eltwise14
I1007 22:17:02.614905  5322 net.cpp:380] Eltwise14_elu29_0_split -> Eltwise14_elu29_0_split_0
I1007 22:17:02.614909  5322 net.cpp:380] Eltwise14_elu29_0_split -> Eltwise14_elu29_0_split_1
I1007 22:17:02.614933  5322 net.cpp:122] Setting up Eltwise14_elu29_0_split
I1007 22:17:02.614938  5322 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:17:02.614940  5322 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:17:02.614943  5322 net.cpp:137] Memory required for data: 511482000
I1007 22:17:02.614944  5322 layer_factory.hpp:77] Creating layer Convolution32
I1007 22:17:02.614951  5322 net.cpp:84] Creating Layer Convolution32
I1007 22:17:02.614954  5322 net.cpp:406] Convolution32 <- Eltwise14_elu29_0_split_0
I1007 22:17:02.614958  5322 net.cpp:380] Convolution32 -> Convolution32
I1007 22:17:02.619362  5322 net.cpp:122] Setting up Convolution32
I1007 22:17:02.619376  5322 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:17:02.619381  5322 net.cpp:137] Memory required for data: 512736400
I1007 22:17:02.619388  5322 layer_factory.hpp:77] Creating layer BatchNorm32
I1007 22:17:02.619397  5322 net.cpp:84] Creating Layer BatchNorm32
I1007 22:17:02.619403  5322 net.cpp:406] BatchNorm32 <- Convolution32
I1007 22:17:02.619410  5322 net.cpp:367] BatchNorm32 -> Convolution32 (in-place)
I1007 22:17:02.619619  5322 net.cpp:122] Setting up BatchNorm32
I1007 22:17:02.619627  5322 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:17:02.619632  5322 net.cpp:137] Memory required for data: 513990800
I1007 22:17:02.619642  5322 layer_factory.hpp:77] Creating layer Scale32
I1007 22:17:02.619650  5322 net.cpp:84] Creating Layer Scale32
I1007 22:17:02.619663  5322 net.cpp:406] Scale32 <- Convolution32
I1007 22:17:02.619670  5322 net.cpp:367] Scale32 -> Convolution32 (in-place)
I1007 22:17:02.619715  5322 layer_factory.hpp:77] Creating layer Scale32
I1007 22:17:02.619838  5322 net.cpp:122] Setting up Scale32
I1007 22:17:02.619846  5322 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:17:02.619851  5322 net.cpp:137] Memory required for data: 515245200
I1007 22:17:02.619858  5322 layer_factory.hpp:77] Creating layer elu30
I1007 22:17:02.619865  5322 net.cpp:84] Creating Layer elu30
I1007 22:17:02.619870  5322 net.cpp:406] elu30 <- Convolution32
I1007 22:17:02.619875  5322 net.cpp:367] elu30 -> Convolution32 (in-place)
I1007 22:17:02.619882  5322 net.cpp:122] Setting up elu30
I1007 22:17:02.619889  5322 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:17:02.619894  5322 net.cpp:137] Memory required for data: 516499600
I1007 22:17:02.619897  5322 layer_factory.hpp:77] Creating layer Convolution33
I1007 22:17:02.619910  5322 net.cpp:84] Creating Layer Convolution33
I1007 22:17:02.619915  5322 net.cpp:406] Convolution33 <- Convolution32
I1007 22:17:02.619925  5322 net.cpp:380] Convolution33 -> Convolution33
I1007 22:17:02.626914  5322 net.cpp:122] Setting up Convolution33
I1007 22:17:02.626929  5322 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:17:02.626933  5322 net.cpp:137] Memory required for data: 517754000
I1007 22:17:02.626941  5322 layer_factory.hpp:77] Creating layer BatchNorm33
I1007 22:17:02.626951  5322 net.cpp:84] Creating Layer BatchNorm33
I1007 22:17:02.626956  5322 net.cpp:406] BatchNorm33 <- Convolution33
I1007 22:17:02.626963  5322 net.cpp:367] BatchNorm33 -> Convolution33 (in-place)
I1007 22:17:02.627182  5322 net.cpp:122] Setting up BatchNorm33
I1007 22:17:02.627192  5322 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:17:02.627195  5322 net.cpp:137] Memory required for data: 519008400
I1007 22:17:02.627204  5322 layer_factory.hpp:77] Creating layer Scale33
I1007 22:17:02.627213  5322 net.cpp:84] Creating Layer Scale33
I1007 22:17:02.627218  5322 net.cpp:406] Scale33 <- Convolution33
I1007 22:17:02.627223  5322 net.cpp:367] Scale33 -> Convolution33 (in-place)
I1007 22:17:02.627267  5322 layer_factory.hpp:77] Creating layer Scale33
I1007 22:17:02.627390  5322 net.cpp:122] Setting up Scale33
I1007 22:17:02.627398  5322 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:17:02.627403  5322 net.cpp:137] Memory required for data: 520262800
I1007 22:17:02.627409  5322 layer_factory.hpp:77] Creating layer Eltwise15
I1007 22:17:02.627418  5322 net.cpp:84] Creating Layer Eltwise15
I1007 22:17:02.627424  5322 net.cpp:406] Eltwise15 <- Eltwise14_elu29_0_split_1
I1007 22:17:02.627429  5322 net.cpp:406] Eltwise15 <- Convolution33
I1007 22:17:02.627435  5322 net.cpp:380] Eltwise15 -> Eltwise15
I1007 22:17:02.627460  5322 net.cpp:122] Setting up Eltwise15
I1007 22:17:02.627468  5322 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:17:02.627472  5322 net.cpp:137] Memory required for data: 521517200
I1007 22:17:02.627476  5322 layer_factory.hpp:77] Creating layer elu31
I1007 22:17:02.627483  5322 net.cpp:84] Creating Layer elu31
I1007 22:17:02.627488  5322 net.cpp:406] elu31 <- Eltwise15
I1007 22:17:02.627495  5322 net.cpp:367] elu31 -> Eltwise15 (in-place)
I1007 22:17:02.627501  5322 net.cpp:122] Setting up elu31
I1007 22:17:02.627507  5322 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:17:02.627511  5322 net.cpp:137] Memory required for data: 522771600
I1007 22:17:02.627516  5322 layer_factory.hpp:77] Creating layer Pooling1
I1007 22:17:02.627523  5322 net.cpp:84] Creating Layer Pooling1
I1007 22:17:02.627527  5322 net.cpp:406] Pooling1 <- Eltwise15
I1007 22:17:02.627533  5322 net.cpp:380] Pooling1 -> Pooling1
I1007 22:17:02.628830  5322 net.cpp:122] Setting up Pooling1
I1007 22:17:02.628840  5322 net.cpp:129] Top shape: 100 64 1 1 (6400)
I1007 22:17:02.628845  5322 net.cpp:137] Memory required for data: 522797200
I1007 22:17:02.628849  5322 layer_factory.hpp:77] Creating layer InnerProduct1
I1007 22:17:02.628872  5322 net.cpp:84] Creating Layer InnerProduct1
I1007 22:17:02.628877  5322 net.cpp:406] InnerProduct1 <- Pooling1
I1007 22:17:02.628885  5322 net.cpp:380] InnerProduct1 -> InnerProduct1
I1007 22:17:02.629034  5322 net.cpp:122] Setting up InnerProduct1
I1007 22:17:02.629042  5322 net.cpp:129] Top shape: 100 10 (1000)
I1007 22:17:02.629047  5322 net.cpp:137] Memory required for data: 522801200
I1007 22:17:02.629053  5322 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I1007 22:17:02.629061  5322 net.cpp:84] Creating Layer SoftmaxWithLoss1
I1007 22:17:02.629066  5322 net.cpp:406] SoftmaxWithLoss1 <- InnerProduct1
I1007 22:17:02.629071  5322 net.cpp:406] SoftmaxWithLoss1 <- Data2
I1007 22:17:02.629079  5322 net.cpp:380] SoftmaxWithLoss1 -> SoftmaxWithLoss1
I1007 22:17:02.629089  5322 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I1007 22:17:02.631170  5322 net.cpp:122] Setting up SoftmaxWithLoss1
I1007 22:17:02.631181  5322 net.cpp:129] Top shape: (1)
I1007 22:17:02.631186  5322 net.cpp:132]     with loss weight 1
I1007 22:17:02.631204  5322 net.cpp:137] Memory required for data: 522801204
I1007 22:17:02.631208  5322 net.cpp:198] SoftmaxWithLoss1 needs backward computation.
I1007 22:17:02.631214  5322 net.cpp:198] InnerProduct1 needs backward computation.
I1007 22:17:02.631218  5322 net.cpp:198] Pooling1 needs backward computation.
I1007 22:17:02.631222  5322 net.cpp:198] elu31 needs backward computation.
I1007 22:17:02.631227  5322 net.cpp:198] Eltwise15 needs backward computation.
I1007 22:17:02.631232  5322 net.cpp:198] Scale33 needs backward computation.
I1007 22:17:02.631237  5322 net.cpp:198] BatchNorm33 needs backward computation.
I1007 22:17:02.631239  5322 net.cpp:198] Convolution33 needs backward computation.
I1007 22:17:02.631244  5322 net.cpp:198] elu30 needs backward computation.
I1007 22:17:02.631248  5322 net.cpp:198] Scale32 needs backward computation.
I1007 22:17:02.631253  5322 net.cpp:198] BatchNorm32 needs backward computation.
I1007 22:17:02.631258  5322 net.cpp:198] Convolution32 needs backward computation.
I1007 22:17:02.631261  5322 net.cpp:198] Eltwise14_elu29_0_split needs backward computation.
I1007 22:17:02.631266  5322 net.cpp:198] elu29 needs backward computation.
I1007 22:17:02.631270  5322 net.cpp:198] Eltwise14 needs backward computation.
I1007 22:17:02.631275  5322 net.cpp:198] Scale31 needs backward computation.
I1007 22:17:02.631279  5322 net.cpp:198] BatchNorm31 needs backward computation.
I1007 22:17:02.631283  5322 net.cpp:198] Convolution31 needs backward computation.
I1007 22:17:02.631287  5322 net.cpp:198] elu28 needs backward computation.
I1007 22:17:02.631292  5322 net.cpp:198] Scale30 needs backward computation.
I1007 22:17:02.631295  5322 net.cpp:198] BatchNorm30 needs backward computation.
I1007 22:17:02.631300  5322 net.cpp:198] Convolution30 needs backward computation.
I1007 22:17:02.631305  5322 net.cpp:198] Eltwise13_elu27_0_split needs backward computation.
I1007 22:17:02.631310  5322 net.cpp:198] elu27 needs backward computation.
I1007 22:17:02.631315  5322 net.cpp:198] Eltwise13 needs backward computation.
I1007 22:17:02.631320  5322 net.cpp:198] Scale29 needs backward computation.
I1007 22:17:02.631325  5322 net.cpp:198] BatchNorm29 needs backward computation.
I1007 22:17:02.631330  5322 net.cpp:198] Convolution29 needs backward computation.
I1007 22:17:02.631335  5322 net.cpp:198] elu26 needs backward computation.
I1007 22:17:02.631340  5322 net.cpp:198] Scale28 needs backward computation.
I1007 22:17:02.631343  5322 net.cpp:198] BatchNorm28 needs backward computation.
I1007 22:17:02.631347  5322 net.cpp:198] Convolution28 needs backward computation.
I1007 22:17:02.631351  5322 net.cpp:198] Eltwise12_elu25_0_split needs backward computation.
I1007 22:17:02.631356  5322 net.cpp:198] elu25 needs backward computation.
I1007 22:17:02.631362  5322 net.cpp:198] Eltwise12 needs backward computation.
I1007 22:17:02.631367  5322 net.cpp:198] Scale27 needs backward computation.
I1007 22:17:02.631372  5322 net.cpp:198] BatchNorm27 needs backward computation.
I1007 22:17:02.631386  5322 net.cpp:198] Convolution27 needs backward computation.
I1007 22:17:02.631391  5322 net.cpp:198] elu24 needs backward computation.
I1007 22:17:02.631395  5322 net.cpp:198] Scale26 needs backward computation.
I1007 22:17:02.631399  5322 net.cpp:198] BatchNorm26 needs backward computation.
I1007 22:17:02.631403  5322 net.cpp:198] Convolution26 needs backward computation.
I1007 22:17:02.631408  5322 net.cpp:198] Eltwise11_elu23_0_split needs backward computation.
I1007 22:17:02.631413  5322 net.cpp:198] elu23 needs backward computation.
I1007 22:17:02.631417  5322 net.cpp:198] Eltwise11 needs backward computation.
I1007 22:17:02.631423  5322 net.cpp:198] Scale25 needs backward computation.
I1007 22:17:02.631428  5322 net.cpp:198] BatchNorm25 needs backward computation.
I1007 22:17:02.631431  5322 net.cpp:198] Convolution25 needs backward computation.
I1007 22:17:02.631436  5322 net.cpp:198] elu22 needs backward computation.
I1007 22:17:02.631440  5322 net.cpp:198] Scale24 needs backward computation.
I1007 22:17:02.631445  5322 net.cpp:198] BatchNorm24 needs backward computation.
I1007 22:17:02.631449  5322 net.cpp:198] Convolution24 needs backward computation.
I1007 22:17:02.631454  5322 net.cpp:198] Scale23 needs backward computation.
I1007 22:17:02.631458  5322 net.cpp:198] BatchNorm23 needs backward computation.
I1007 22:17:02.631463  5322 net.cpp:198] Convolution23 needs backward computation.
I1007 22:17:02.631467  5322 net.cpp:198] Eltwise10_elu21_0_split needs backward computation.
I1007 22:17:02.631472  5322 net.cpp:198] elu21 needs backward computation.
I1007 22:17:02.631476  5322 net.cpp:198] Eltwise10 needs backward computation.
I1007 22:17:02.631481  5322 net.cpp:198] Scale22 needs backward computation.
I1007 22:17:02.631486  5322 net.cpp:198] BatchNorm22 needs backward computation.
I1007 22:17:02.631490  5322 net.cpp:198] Convolution22 needs backward computation.
I1007 22:17:02.631494  5322 net.cpp:198] elu20 needs backward computation.
I1007 22:17:02.631498  5322 net.cpp:198] Scale21 needs backward computation.
I1007 22:17:02.631503  5322 net.cpp:198] BatchNorm21 needs backward computation.
I1007 22:17:02.631507  5322 net.cpp:198] Convolution21 needs backward computation.
I1007 22:17:02.631512  5322 net.cpp:198] Eltwise9_elu19_0_split needs backward computation.
I1007 22:17:02.631517  5322 net.cpp:198] elu19 needs backward computation.
I1007 22:17:02.631522  5322 net.cpp:198] Eltwise9 needs backward computation.
I1007 22:17:02.631528  5322 net.cpp:198] Scale20 needs backward computation.
I1007 22:17:02.631532  5322 net.cpp:198] BatchNorm20 needs backward computation.
I1007 22:17:02.631536  5322 net.cpp:198] Convolution20 needs backward computation.
I1007 22:17:02.631541  5322 net.cpp:198] elu18 needs backward computation.
I1007 22:17:02.631546  5322 net.cpp:198] Scale19 needs backward computation.
I1007 22:17:02.631551  5322 net.cpp:198] BatchNorm19 needs backward computation.
I1007 22:17:02.631554  5322 net.cpp:198] Convolution19 needs backward computation.
I1007 22:17:02.631559  5322 net.cpp:198] Eltwise8_elu17_0_split needs backward computation.
I1007 22:17:02.631564  5322 net.cpp:198] elu17 needs backward computation.
I1007 22:17:02.631569  5322 net.cpp:198] Eltwise8 needs backward computation.
I1007 22:17:02.631574  5322 net.cpp:198] Scale18 needs backward computation.
I1007 22:17:02.631579  5322 net.cpp:198] BatchNorm18 needs backward computation.
I1007 22:17:02.631583  5322 net.cpp:198] Convolution18 needs backward computation.
I1007 22:17:02.631587  5322 net.cpp:198] elu16 needs backward computation.
I1007 22:17:02.631592  5322 net.cpp:198] Scale17 needs backward computation.
I1007 22:17:02.631597  5322 net.cpp:198] BatchNorm17 needs backward computation.
I1007 22:17:02.631600  5322 net.cpp:198] Convolution17 needs backward computation.
I1007 22:17:02.631605  5322 net.cpp:198] Eltwise7_elu15_0_split needs backward computation.
I1007 22:17:02.631609  5322 net.cpp:198] elu15 needs backward computation.
I1007 22:17:02.631613  5322 net.cpp:198] Eltwise7 needs backward computation.
I1007 22:17:02.631623  5322 net.cpp:198] Scale16 needs backward computation.
I1007 22:17:02.631629  5322 net.cpp:198] BatchNorm16 needs backward computation.
I1007 22:17:02.631633  5322 net.cpp:198] Convolution16 needs backward computation.
I1007 22:17:02.631639  5322 net.cpp:198] elu14 needs backward computation.
I1007 22:17:02.631642  5322 net.cpp:198] Scale15 needs backward computation.
I1007 22:17:02.631647  5322 net.cpp:198] BatchNorm15 needs backward computation.
I1007 22:17:02.631651  5322 net.cpp:198] Convolution15 needs backward computation.
I1007 22:17:02.631656  5322 net.cpp:198] Eltwise6_elu13_0_split needs backward computation.
I1007 22:17:02.631661  5322 net.cpp:198] elu13 needs backward computation.
I1007 22:17:02.631666  5322 net.cpp:198] Eltwise6 needs backward computation.
I1007 22:17:02.631671  5322 net.cpp:198] Scale14 needs backward computation.
I1007 22:17:02.631676  5322 net.cpp:198] BatchNorm14 needs backward computation.
I1007 22:17:02.631680  5322 net.cpp:198] Convolution14 needs backward computation.
I1007 22:17:02.631685  5322 net.cpp:198] elu12 needs backward computation.
I1007 22:17:02.631690  5322 net.cpp:198] Scale13 needs backward computation.
I1007 22:17:02.631695  5322 net.cpp:198] BatchNorm13 needs backward computation.
I1007 22:17:02.631700  5322 net.cpp:198] Convolution13 needs backward computation.
I1007 22:17:02.631703  5322 net.cpp:198] Scale12 needs backward computation.
I1007 22:17:02.631708  5322 net.cpp:198] BatchNorm12 needs backward computation.
I1007 22:17:02.631712  5322 net.cpp:198] Convolution12 needs backward computation.
I1007 22:17:02.631717  5322 net.cpp:198] Eltwise5_elu11_0_split needs backward computation.
I1007 22:17:02.631721  5322 net.cpp:198] elu11 needs backward computation.
I1007 22:17:02.631726  5322 net.cpp:198] Eltwise5 needs backward computation.
I1007 22:17:02.631731  5322 net.cpp:198] Scale11 needs backward computation.
I1007 22:17:02.631736  5322 net.cpp:198] BatchNorm11 needs backward computation.
I1007 22:17:02.631739  5322 net.cpp:198] Convolution11 needs backward computation.
I1007 22:17:02.631744  5322 net.cpp:198] elu10 needs backward computation.
I1007 22:17:02.631748  5322 net.cpp:198] Scale10 needs backward computation.
I1007 22:17:02.631752  5322 net.cpp:198] BatchNorm10 needs backward computation.
I1007 22:17:02.631757  5322 net.cpp:198] Convolution10 needs backward computation.
I1007 22:17:02.631762  5322 net.cpp:198] Eltwise4_elu9_0_split needs backward computation.
I1007 22:17:02.631767  5322 net.cpp:198] elu9 needs backward computation.
I1007 22:17:02.631770  5322 net.cpp:198] Eltwise4 needs backward computation.
I1007 22:17:02.631777  5322 net.cpp:198] Scale9 needs backward computation.
I1007 22:17:02.631781  5322 net.cpp:198] BatchNorm9 needs backward computation.
I1007 22:17:02.631785  5322 net.cpp:198] Convolution9 needs backward computation.
I1007 22:17:02.631790  5322 net.cpp:198] elu8 needs backward computation.
I1007 22:17:02.631794  5322 net.cpp:198] Scale8 needs backward computation.
I1007 22:17:02.631799  5322 net.cpp:198] BatchNorm8 needs backward computation.
I1007 22:17:02.631803  5322 net.cpp:198] Convolution8 needs backward computation.
I1007 22:17:02.631808  5322 net.cpp:198] Eltwise3_elu7_0_split needs backward computation.
I1007 22:17:02.631814  5322 net.cpp:198] elu7 needs backward computation.
I1007 22:17:02.631817  5322 net.cpp:198] Eltwise3 needs backward computation.
I1007 22:17:02.631822  5322 net.cpp:198] Scale7 needs backward computation.
I1007 22:17:02.631827  5322 net.cpp:198] BatchNorm7 needs backward computation.
I1007 22:17:02.631832  5322 net.cpp:198] Convolution7 needs backward computation.
I1007 22:17:02.631839  5322 net.cpp:198] elu6 needs backward computation.
I1007 22:17:02.631844  5322 net.cpp:198] Scale6 needs backward computation.
I1007 22:17:02.631847  5322 net.cpp:198] BatchNorm6 needs backward computation.
I1007 22:17:02.631851  5322 net.cpp:198] Convolution6 needs backward computation.
I1007 22:17:02.631855  5322 net.cpp:198] Eltwise2_elu5_0_split needs backward computation.
I1007 22:17:02.631865  5322 net.cpp:198] elu5 needs backward computation.
I1007 22:17:02.631870  5322 net.cpp:198] Eltwise2 needs backward computation.
I1007 22:17:02.631875  5322 net.cpp:198] Scale5 needs backward computation.
I1007 22:17:02.631878  5322 net.cpp:198] BatchNorm5 needs backward computation.
I1007 22:17:02.631882  5322 net.cpp:198] Convolution5 needs backward computation.
I1007 22:17:02.631887  5322 net.cpp:198] elu4 needs backward computation.
I1007 22:17:02.631892  5322 net.cpp:198] Scale4 needs backward computation.
I1007 22:17:02.631897  5322 net.cpp:198] BatchNorm4 needs backward computation.
I1007 22:17:02.631901  5322 net.cpp:198] Convolution4 needs backward computation.
I1007 22:17:02.631906  5322 net.cpp:198] Eltwise1_elu3_0_split needs backward computation.
I1007 22:17:02.631911  5322 net.cpp:198] elu3 needs backward computation.
I1007 22:17:02.631916  5322 net.cpp:198] Eltwise1 needs backward computation.
I1007 22:17:02.631920  5322 net.cpp:198] Scale3 needs backward computation.
I1007 22:17:02.631925  5322 net.cpp:198] BatchNorm3 needs backward computation.
I1007 22:17:02.631929  5322 net.cpp:198] Convolution3 needs backward computation.
I1007 22:17:02.631934  5322 net.cpp:198] elu2 needs backward computation.
I1007 22:17:02.631939  5322 net.cpp:198] Scale2 needs backward computation.
I1007 22:17:02.631943  5322 net.cpp:198] BatchNorm2 needs backward computation.
I1007 22:17:02.631947  5322 net.cpp:198] Convolution2 needs backward computation.
I1007 22:17:02.631953  5322 net.cpp:198] Convolution1_elu1_0_split needs backward computation.
I1007 22:17:02.631958  5322 net.cpp:198] elu1 needs backward computation.
I1007 22:17:02.631963  5322 net.cpp:198] Scale1 needs backward computation.
I1007 22:17:02.631966  5322 net.cpp:198] BatchNorm1 needs backward computation.
I1007 22:17:02.631970  5322 net.cpp:198] Convolution1 needs backward computation.
I1007 22:17:02.631975  5322 net.cpp:200] Data1 does not need backward computation.
I1007 22:17:02.631980  5322 net.cpp:242] This network produces output SoftmaxWithLoss1
I1007 22:17:02.632061  5322 net.cpp:255] Network initialization done.
I1007 22:17:02.635560  5322 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: /home/x306/caffe/xn/PENLU/neural/resnet/res32/res32_elu0.25_train_test.prototxt
I1007 22:17:02.635576  5322 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I1007 22:17:02.635584  5322 solver.cpp:172] Creating test net (#0) specified by net file: /home/x306/caffe/xn/PENLU/neural/resnet/res32/res32_elu0.25_train_test.prototxt
I1007 22:17:02.635769  5322 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer Data1
I1007 22:17:02.636713  5322 net.cpp:51] Initializing net from parameters: 
name: "resnet_cifar10"
state {
  phase: TEST
}
layer {
  name: "Data1"
  type: "Data"
  top: "Data1"
  top: "Data2"
  include {
    phase: TEST
  }
  transform_param {
    mean_file: "/home/x306/caffe/xn/PENLU/data/cifar10/mean.binaryproto"
  }
  data_param {
    source: "/home/x306/caffe/xn/PENLU/data/cifar10/cifar10_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "Convolution1"
  type: "Convolution"
  bottom: "Data1"
  top: "Convolution1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm1"
  type: "BatchNorm"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1"
  type: "Scale"
  bottom: "Convolution1"
  top: "Convolution1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "elu1"
  type: "ELU"
  bottom: "Convolution1"
  top: "Convolution1"
  elu_param {
    alpha: 0.25
  }
}
layer {
  name: "Convolution2"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm2"
  type: "BatchNorm"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale2"
  type: "Scale"
  bottom: "Convolution2"
  top: "Convolution2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "elu2"
  type: "ELU"
  bottom: "Convolution2"
  top: "Convolution2"
  elu_param {
    alpha: 0.25
  }
}
layer {
  name: "Convolution3"
  type: "Convolution"
  bottom: "Convolution2"
  top: "Convolution3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm3"
  type: "BatchNorm"
  bottom: "Convolution3"
  top: "Convolution3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale3"
  type: "Scale"
  bottom: "Convolution3"
  top: "Convolution3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise1"
  type: "Eltwise"
  bottom: "Convolution1"
  bottom: "Convolution3"
  top: "Eltwise1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "elu3"
  type: "ELU"
  bottom: "Eltwise1"
  top: "Eltwise1"
  elu_param {
    alpha: 0.25
  }
}
layer {
  name: "Convolution4"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm4"
  type: "BatchNorm"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale4"
  type: "Scale"
  bottom: "Convolution4"
  top: "Convolution4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "elu4"
  type: "ELU"
  bottom: "Convolution4"
  top: "Convolution4"
  elu_param {
    alpha: 0.25
  }
}
layer {
  name: "Convolution5"
  type: "Convolution"
  bottom: "Convolution4"
  top: "Convolution5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm5"
  type: "BatchNorm"
  bottom: "Convolution5"
  top: "Convolution5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale5"
  type: "Scale"
  bottom: "Convolution5"
  top: "Convolution5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise2"
  type: "Eltwise"
  bottom: "Eltwise1"
  bottom: "Convolution5"
  top: "Eltwise2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "elu5"
  type: "ELU"
  bottom: "Eltwise2"
  top: "Eltwise2"
  elu_param {
    alpha: 0.25
  }
}
layer {
  name: "Convolution6"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm6"
  type: "BatchNorm"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale6"
  type: "Scale"
  bottom: "Convolution6"
  top: "Convolution6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "elu6"
  type: "ELU"
  bottom: "Convolution6"
  top: "Convolution6"
  elu_param {
    alpha: 0.25
  }
}
layer {
  name: "Convolution7"
  type: "Convolution"
  bottom: "Convolution6"
  top: "Convolution7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm7"
  type: "BatchNorm"
  bottom: "Convolution7"
  top: "Convolution7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale7"
  type: "Scale"
  bottom: "Convolution7"
  top: "Convolution7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise3"
  type: "Eltwise"
  bottom: "Eltwise2"
  bottom: "Convolution7"
  top: "Eltwise3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "elu7"
  type: "ELU"
  bottom: "Eltwise3"
  top: "Eltwise3"
  elu_param {
    alpha: 0.25
  }
}
layer {
  name: "Convolution8"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm8"
  type: "BatchNorm"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale8"
  type: "Scale"
  bottom: "Convolution8"
  top: "Convolution8"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "elu8"
  type: "ELU"
  bottom: "Convolution8"
  top: "Convolution8"
  elu_param {
    alpha: 0.25
  }
}
layer {
  name: "Convolution9"
  type: "Convolution"
  bottom: "Convolution8"
  top: "Convolution9"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm9"
  type: "BatchNorm"
  bottom: "Convolution9"
  top: "Convolution9"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale9"
  type: "Scale"
  bottom: "Convolution9"
  top: "Convolution9"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise4"
  type: "Eltwise"
  bottom: "Eltwise3"
  bottom: "Convolution9"
  top: "Eltwise4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "elu9"
  type: "ELU"
  bottom: "Eltwise4"
  top: "Eltwise4"
  elu_param {
    alpha: 0.25
  }
}
layer {
  name: "Convolution10"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution10"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm10"
  type: "BatchNorm"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale10"
  type: "Scale"
  bottom: "Convolution10"
  top: "Convolution10"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "elu10"
  type: "ELU"
  bottom: "Convolution10"
  top: "Convolution10"
  elu_param {
    alpha: 0.25
  }
}
layer {
  name: "Convolution11"
  type: "Convolution"
  bottom: "Convolution10"
  top: "Convolution11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm11"
  type: "BatchNorm"
  bottom: "Convolution11"
  top: "Convolution11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale11"
  type: "Scale"
  bottom: "Convolution11"
  top: "Convolution11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise5"
  type: "Eltwise"
  bottom: "Eltwise4"
  bottom: "Convolution11"
  top: "Eltwise5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "elu11"
  type: "ELU"
  bottom: "Eltwise5"
  top: "Eltwise5"
  elu_param {
    alpha: 0.25
  }
}
layer {
  name: "Convolution12"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.25
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm12"
  type: "BatchNorm"
  bottom: "Convolution12"
  top: "Convolution12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale12"
  type: "Scale"
  bottom: "Convolution12"
  top: "Convolution12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution13"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution13"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm13"
  type: "BatchNorm"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale13"
  type: "Scale"
  bottom: "Convolution13"
  top: "Convolution13"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "elu12"
  type: "ELU"
  bottom: "Convolution13"
  top: "Convolution13"
  elu_param {
    alpha: 0.25
  }
}
layer {
  name: "Convolution14"
  type: "Convolution"
  bottom: "Convolution13"
  top: "Convolution14"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm14"
  type: "BatchNorm"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale14"
  type: "Scale"
  bottom: "Convolution14"
  top: "Convolution14"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise6"
  type: "Eltwise"
  bottom: "Convolution12"
  bottom: "Convolution14"
  top: "Eltwise6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "elu13"
  type: "ELU"
  bottom: "Eltwise6"
  top: "Eltwise6"
  elu_param {
    alpha: 0.25
  }
}
layer {
  name: "Convolution15"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution15"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm15"
  type: "BatchNorm"
  bottom: "Convolution15"
  top: "Convolution15"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale15"
  type: "Scale"
  bottom: "Convolution15"
  top: "Convolution15"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "elu14"
  type: "ELU"
  bottom: "Convolution15"
  top: "Convolution15"
  elu_param {
    alpha: 0.25
  }
}
layer {
  name: "Convolution16"
  type: "Convolution"
  bottom: "Convolution15"
  top: "Convolution16"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm16"
  type: "BatchNorm"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale16"
  type: "Scale"
  bottom: "Convolution16"
  top: "Convolution16"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise7"
  type: "Eltwise"
  bottom: "Eltwise6"
  bottom: "Convolution16"
  top: "Eltwise7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "elu15"
  type: "ELU"
  bottom: "Eltwise7"
  top: "Eltwise7"
  elu_param {
    alpha: 0.25
  }
}
layer {
  name: "Convolution17"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution17"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm17"
  type: "BatchNorm"
  bottom: "Convolution17"
  top: "Convolution17"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale17"
  type: "Scale"
  bottom: "Convolution17"
  top: "Convolution17"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "elu16"
  type: "ELU"
  bottom: "Convolution17"
  top: "Convolution17"
  elu_param {
    alpha: 0.25
  }
}
layer {
  name: "Convolution18"
  type: "Convolution"
  bottom: "Convolution17"
  top: "Convolution18"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm18"
  type: "BatchNorm"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale18"
  type: "Scale"
  bottom: "Convolution18"
  top: "Convolution18"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise8"
  type: "Eltwise"
  bottom: "Eltwise7"
  bottom: "Convolution18"
  top: "Eltwise8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "elu17"
  type: "ELU"
  bottom: "Eltwise8"
  top: "Eltwise8"
  elu_param {
    alpha: 0.25
  }
}
layer {
  name: "Convolution19"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution19"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm19"
  type: "BatchNorm"
  bottom: "Convolution19"
  top: "Convolution19"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale19"
  type: "Scale"
  bottom: "Convolution19"
  top: "Convolution19"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "elu18"
  type: "ELU"
  bottom: "Convolution19"
  top: "Convolution19"
  elu_param {
    alpha: 0.25
  }
}
layer {
  name: "Convolution20"
  type: "Convolution"
  bottom: "Convolution19"
  top: "Convolution20"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm20"
  type: "BatchNorm"
  bottom: "Convolution20"
  top: "Convolution20"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale20"
  type: "Scale"
  bottom: "Convolution20"
  top: "Convolution20"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise9"
  type: "Eltwise"
  bottom: "Eltwise8"
  bottom: "Convolution20"
  top: "Eltwise9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "elu19"
  type: "ELU"
  bottom: "Eltwise9"
  top: "Eltwise9"
  elu_param {
    alpha: 0.25
  }
}
layer {
  name: "Convolution21"
  type: "Convolution"
  bottom: "Eltwise9"
  top: "Convolution21"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm21"
  type: "BatchNorm"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale21"
  type: "Scale"
  bottom: "Convolution21"
  top: "Convolution21"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "elu20"
  type: "ELU"
  bottom: "Convolution21"
  top: "Convolution21"
  elu_param {
    alpha: 0.25
  }
}
layer {
  name: "Convolution22"
  type: "Convolution"
  bottom: "Convolution21"
  top: "Convolution22"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm22"
  type: "BatchNorm"
  bottom: "Convolution22"
  top: "Convolution22"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale22"
  type: "Scale"
  bottom: "Convolution22"
  top: "Convolution22"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise10"
  type: "Eltwise"
  bottom: "Eltwise9"
  bottom: "Convolution22"
  top: "Eltwise10"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "elu21"
  type: "ELU"
  bottom: "Eltwise10"
  top: "Eltwise10"
  elu_param {
    alpha: 0.25
  }
}
layer {
  name: "Convolution23"
  type: "Convolution"
  bottom: "Eltwise10"
  top: "Convolution23"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.17677669
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm23"
  type: "BatchNorm"
  bottom: "Convolution23"
  top: "Convolution23"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale23"
  type: "Scale"
  bottom: "Convolution23"
  top: "Convolution23"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution24"
  type: "Convolution"
  bottom: "Eltwise10"
  top: "Convolution24"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm24"
  type: "BatchNorm"
  bottom: "Convolution24"
  top: "Convolution24"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale24"
  type: "Scale"
  bottom: "Convolution24"
  top: "Convolution24"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "elu22"
  type: "ELU"
  bottom: "Convolution24"
  top: "Convolution24"
  elu_param {
    alpha: 0.25
  }
}
layer {
  name: "Convolution25"
  type: "Convolution"
  bottom: "Convolution24"
  top: "Convolution25"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm25"
  type: "BatchNorm"
  bottom: "Convolution25"
  top: "Convolution25"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale25"
  type: "Scale"
  bottom: "Convolution25"
  top: "Convolution25"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise11"
  type: "Eltwise"
  bottom: "Convolution23"
  bottom: "Convolution25"
  top: "Eltwise11"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "elu23"
  type: "ELU"
  bottom: "Eltwise11"
  top: "Eltwise11"
  elu_param {
    alpha: 0.25
  }
}
layer {
  name: "Convolution26"
  type: "Convolution"
  bottom: "Eltwise11"
  top: "Convolution26"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm26"
  type: "BatchNorm"
  bottom: "Convolution26"
  top: "Convolution26"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale26"
  type: "Scale"
  bottom: "Convolution26"
  top: "Convolution26"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "elu24"
  type: "ELU"
  bottom: "Convolution26"
  top: "Convolution26"
  elu_param {
    alpha: 0.25
  }
}
layer {
  name: "Convolution27"
  type: "Convolution"
  bottom: "Convolution26"
  top: "Convolution27"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm27"
  type: "BatchNorm"
  bottom: "Convolution27"
  top: "Convolution27"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale27"
  type: "Scale"
  bottom: "Convolution27"
  top: "Convolution27"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise12"
  type: "Eltwise"
  bottom: "Eltwise11"
  bottom: "Convolution27"
  top: "Eltwise12"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "elu25"
  type: "ELU"
  bottom: "Eltwise12"
  top: "Eltwise12"
  elu_param {
    alpha: 0.25
  }
}
layer {
  name: "Convolution28"
  type: "Convolution"
  bottom: "Eltwise12"
  top: "Convolution28"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm28"
  type: "BatchNorm"
  bottom: "Convolution28"
  top: "Convolution28"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale28"
  type: "Scale"
  bottom: "Convolution28"
  top: "Convolution28"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "elu26"
  type: "ELU"
  bottom: "Convolution28"
  top: "Convolution28"
  elu_param {
    alpha: 0.25
  }
}
layer {
  name: "Convolution29"
  type: "Convolution"
  bottom: "Convolution28"
  top: "Convolution29"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm29"
  type: "BatchNorm"
  bottom: "Convolution29"
  top: "Convolution29"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale29"
  type: "Scale"
  bottom: "Convolution29"
  top: "Convolution29"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise13"
  type: "Eltwise"
  bottom: "Eltwise12"
  bottom: "Convolution29"
  top: "Eltwise13"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "elu27"
  type: "ELU"
  bottom: "Eltwise13"
  top: "Eltwise13"
  elu_param {
    alpha: 0.25
  }
}
layer {
  name: "Convolution30"
  type: "Convolution"
  bottom: "Eltwise13"
  top: "Convolution30"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm30"
  type: "BatchNorm"
  bottom: "Convolution30"
  top: "Convolution30"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale30"
  type: "Scale"
  bottom: "Convolution30"
  top: "Convolution30"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "elu28"
  type: "ELU"
  bottom: "Convolution30"
  top: "Convolution30"
  elu_param {
    alpha: 0.25
  }
}
layer {
  name: "Convolution31"
  type: "Convolution"
  bottom: "Convolution30"
  top: "Convolution31"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm31"
  type: "BatchNorm"
  bottom: "Convolution31"
  top: "Convolution31"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
I1007 22:17:02.637084  5322 layer_factory.hpp:77] Creating layer Data1
I1007 22:17:02.637121  5322 db_lmdb.cpp:35] Opened lmdb /home/x306/caffe/xn/PENLU/data/cifar10/cifar10_test_lmdb
I1007 22:17:02.637138  5322 net.cpp:84] Creating Layer Data1
I1007 22:17:02.637142  5322 net.cpp:380] Data1 -> Data1
I1007 22:17:02.637150  5322 net.cpp:380] Data1 -> Data2
I1007 22:17:02.637154  5322 data_transformer.cpp:25] Loading mean file from: /home/x306/caffe/xn/PENLU/data/cifar10/mean.binaryproto
I1007 22:17:02.637275  5322 data_layer.cpp:45] output data size: 100,3,32,32
I1007 22:17:02.657068  5322 net.cpp:122] Setting up Data1
I1007 22:17:02.657088  5322 net.cpp:129] Top shape: 100 3 32 32 (307200)
I1007 22:17:02.657091  5322 net.cpp:129] Top shape: 100 (100)
I1007 22:17:02.657094  5322 net.cpp:137] Memory required for data: 1229200
I1007 22:17:02.657099  5322 layer_factory.hpp:77] Creating layer Data2_Data1_1_split
I1007 22:17:02.657107  5322 net.cpp:84] Creating Layer Data2_Data1_1_split
I1007 22:17:02.657110  5322 net.cpp:406] Data2_Data1_1_split <- Data2
I1007 22:17:02.657115  5322 net.cpp:380] Data2_Data1_1_split -> Data2_Data1_1_split_0
I1007 22:17:02.657124  5322 net.cpp:380] Data2_Data1_1_split -> Data2_Data1_1_split_1
I1007 22:17:02.657166  5322 net.cpp:122] Setting up Data2_Data1_1_split
I1007 22:17:02.657181  5322 net.cpp:129] Top shape: 100 (100)
I1007 22:17:02.657183  5322 net.cpp:129] Top shape: 100 (100)
I1007 22:17:02.657186  5322 net.cpp:137] Memory required for data: 1230000
I1007 22:17:02.657187  5322 layer_factory.hpp:77] Creating layer Convolution1
I1007 22:17:02.657208  5322 net.cpp:84] Creating Layer Convolution1
I1007 22:17:02.657210  5322 net.cpp:406] Convolution1 <- Data1
I1007 22:17:02.657214  5322 net.cpp:380] Convolution1 -> Convolution1
I1007 22:17:02.670940  5322 net.cpp:122] Setting up Convolution1
I1007 22:17:02.670953  5322 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:17:02.670955  5322 net.cpp:137] Memory required for data: 7783600
I1007 22:17:02.670964  5322 layer_factory.hpp:77] Creating layer BatchNorm1
I1007 22:17:02.670972  5322 net.cpp:84] Creating Layer BatchNorm1
I1007 22:17:02.670975  5322 net.cpp:406] BatchNorm1 <- Convolution1
I1007 22:17:02.670979  5322 net.cpp:367] BatchNorm1 -> Convolution1 (in-place)
I1007 22:17:02.675400  5322 net.cpp:122] Setting up BatchNorm1
I1007 22:17:02.675406  5322 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:17:02.675408  5322 net.cpp:137] Memory required for data: 14337200
I1007 22:17:02.675416  5322 layer_factory.hpp:77] Creating layer Scale1
I1007 22:17:02.675424  5322 net.cpp:84] Creating Layer Scale1
I1007 22:17:02.675427  5322 net.cpp:406] Scale1 <- Convolution1
I1007 22:17:02.675431  5322 net.cpp:367] Scale1 -> Convolution1 (in-place)
I1007 22:17:02.675467  5322 layer_factory.hpp:77] Creating layer Scale1
I1007 22:17:02.675550  5322 net.cpp:122] Setting up Scale1
I1007 22:17:02.675555  5322 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:17:02.675557  5322 net.cpp:137] Memory required for data: 20890800
I1007 22:17:02.675565  5322 layer_factory.hpp:77] Creating layer elu1
I1007 22:17:02.675570  5322 net.cpp:84] Creating Layer elu1
I1007 22:17:02.675573  5322 net.cpp:406] elu1 <- Convolution1
I1007 22:17:02.675577  5322 net.cpp:367] elu1 -> Convolution1 (in-place)
I1007 22:17:02.675582  5322 net.cpp:122] Setting up elu1
I1007 22:17:02.675585  5322 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:17:02.675587  5322 net.cpp:137] Memory required for data: 27444400
I1007 22:17:02.675590  5322 layer_factory.hpp:77] Creating layer Convolution1_elu1_0_split
I1007 22:17:02.675593  5322 net.cpp:84] Creating Layer Convolution1_elu1_0_split
I1007 22:17:02.675595  5322 net.cpp:406] Convolution1_elu1_0_split <- Convolution1
I1007 22:17:02.675601  5322 net.cpp:380] Convolution1_elu1_0_split -> Convolution1_elu1_0_split_0
I1007 22:17:02.675604  5322 net.cpp:380] Convolution1_elu1_0_split -> Convolution1_elu1_0_split_1
I1007 22:17:02.675631  5322 net.cpp:122] Setting up Convolution1_elu1_0_split
I1007 22:17:02.675635  5322 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:17:02.675652  5322 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:17:02.675653  5322 net.cpp:137] Memory required for data: 40551600
I1007 22:17:02.675662  5322 layer_factory.hpp:77] Creating layer Convolution2
I1007 22:17:02.675669  5322 net.cpp:84] Creating Layer Convolution2
I1007 22:17:02.675671  5322 net.cpp:406] Convolution2 <- Convolution1_elu1_0_split_0
I1007 22:17:02.675676  5322 net.cpp:380] Convolution2 -> Convolution2
I1007 22:17:02.680826  5322 net.cpp:122] Setting up Convolution2
I1007 22:17:02.680837  5322 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:17:02.680840  5322 net.cpp:137] Memory required for data: 47105200
I1007 22:17:02.680847  5322 layer_factory.hpp:77] Creating layer BatchNorm2
I1007 22:17:02.680855  5322 net.cpp:84] Creating Layer BatchNorm2
I1007 22:17:02.680857  5322 net.cpp:406] BatchNorm2 <- Convolution2
I1007 22:17:02.680861  5322 net.cpp:367] BatchNorm2 -> Convolution2 (in-place)
I1007 22:17:02.681008  5322 net.cpp:122] Setting up BatchNorm2
I1007 22:17:02.681013  5322 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:17:02.681015  5322 net.cpp:137] Memory required for data: 53658800
I1007 22:17:02.681020  5322 layer_factory.hpp:77] Creating layer Scale2
I1007 22:17:02.681026  5322 net.cpp:84] Creating Layer Scale2
I1007 22:17:02.681028  5322 net.cpp:406] Scale2 <- Convolution2
I1007 22:17:02.681032  5322 net.cpp:367] Scale2 -> Convolution2 (in-place)
I1007 22:17:02.681061  5322 layer_factory.hpp:77] Creating layer Scale2
I1007 22:17:02.681143  5322 net.cpp:122] Setting up Scale2
I1007 22:17:02.681146  5322 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:17:02.681149  5322 net.cpp:137] Memory required for data: 60212400
I1007 22:17:02.681154  5322 layer_factory.hpp:77] Creating layer elu2
I1007 22:17:02.681159  5322 net.cpp:84] Creating Layer elu2
I1007 22:17:02.681160  5322 net.cpp:406] elu2 <- Convolution2
I1007 22:17:02.681164  5322 net.cpp:367] elu2 -> Convolution2 (in-place)
I1007 22:17:02.681167  5322 net.cpp:122] Setting up elu2
I1007 22:17:02.681170  5322 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:17:02.681172  5322 net.cpp:137] Memory required for data: 66766000
I1007 22:17:02.681180  5322 layer_factory.hpp:77] Creating layer Convolution3
I1007 22:17:02.681187  5322 net.cpp:84] Creating Layer Convolution3
I1007 22:17:02.681190  5322 net.cpp:406] Convolution3 <- Convolution2
I1007 22:17:02.681195  5322 net.cpp:380] Convolution3 -> Convolution3
I1007 22:17:02.692158  5322 net.cpp:122] Setting up Convolution3
I1007 22:17:02.692172  5322 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:17:02.692174  5322 net.cpp:137] Memory required for data: 73319600
I1007 22:17:02.692180  5322 layer_factory.hpp:77] Creating layer BatchNorm3
I1007 22:17:02.692188  5322 net.cpp:84] Creating Layer BatchNorm3
I1007 22:17:02.692193  5322 net.cpp:406] BatchNorm3 <- Convolution3
I1007 22:17:02.692196  5322 net.cpp:367] BatchNorm3 -> Convolution3 (in-place)
I1007 22:17:02.692348  5322 net.cpp:122] Setting up BatchNorm3
I1007 22:17:02.692353  5322 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:17:02.692355  5322 net.cpp:137] Memory required for data: 79873200
I1007 22:17:02.692363  5322 layer_factory.hpp:77] Creating layer Scale3
I1007 22:17:02.692369  5322 net.cpp:84] Creating Layer Scale3
I1007 22:17:02.692371  5322 net.cpp:406] Scale3 <- Convolution3
I1007 22:17:02.692375  5322 net.cpp:367] Scale3 -> Convolution3 (in-place)
I1007 22:17:02.692410  5322 layer_factory.hpp:77] Creating layer Scale3
I1007 22:17:02.692494  5322 net.cpp:122] Setting up Scale3
I1007 22:17:02.692500  5322 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:17:02.692502  5322 net.cpp:137] Memory required for data: 86426800
I1007 22:17:02.692507  5322 layer_factory.hpp:77] Creating layer Eltwise1
I1007 22:17:02.692512  5322 net.cpp:84] Creating Layer Eltwise1
I1007 22:17:02.692514  5322 net.cpp:406] Eltwise1 <- Convolution1_elu1_0_split_1
I1007 22:17:02.692517  5322 net.cpp:406] Eltwise1 <- Convolution3
I1007 22:17:02.692520  5322 net.cpp:380] Eltwise1 -> Eltwise1
I1007 22:17:02.692550  5322 net.cpp:122] Setting up Eltwise1
I1007 22:17:02.692554  5322 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:17:02.692559  5322 net.cpp:137] Memory required for data: 92980400
I1007 22:17:02.692560  5322 layer_factory.hpp:77] Creating layer elu3
I1007 22:17:02.692565  5322 net.cpp:84] Creating Layer elu3
I1007 22:17:02.692569  5322 net.cpp:406] elu3 <- Eltwise1
I1007 22:17:02.692571  5322 net.cpp:367] elu3 -> Eltwise1 (in-place)
I1007 22:17:02.692575  5322 net.cpp:122] Setting up elu3
I1007 22:17:02.692579  5322 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:17:02.692580  5322 net.cpp:137] Memory required for data: 99534000
I1007 22:17:02.692584  5322 layer_factory.hpp:77] Creating layer Eltwise1_elu3_0_split
I1007 22:17:02.692589  5322 net.cpp:84] Creating Layer Eltwise1_elu3_0_split
I1007 22:17:02.692591  5322 net.cpp:406] Eltwise1_elu3_0_split <- Eltwise1
I1007 22:17:02.692595  5322 net.cpp:380] Eltwise1_elu3_0_split -> Eltwise1_elu3_0_split_0
I1007 22:17:02.692598  5322 net.cpp:380] Eltwise1_elu3_0_split -> Eltwise1_elu3_0_split_1
I1007 22:17:02.692623  5322 net.cpp:122] Setting up Eltwise1_elu3_0_split
I1007 22:17:02.692627  5322 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:17:02.692631  5322 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:17:02.692632  5322 net.cpp:137] Memory required for data: 112641200
I1007 22:17:02.692634  5322 layer_factory.hpp:77] Creating layer Convolution4
I1007 22:17:02.692643  5322 net.cpp:84] Creating Layer Convolution4
I1007 22:17:02.692646  5322 net.cpp:406] Convolution4 <- Eltwise1_elu3_0_split_0
I1007 22:17:02.692649  5322 net.cpp:380] Convolution4 -> Convolution4
I1007 22:17:02.700738  5322 net.cpp:122] Setting up Convolution4
I1007 22:17:02.700748  5322 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:17:02.700752  5322 net.cpp:137] Memory required for data: 119194800
I1007 22:17:02.700755  5322 layer_factory.hpp:77] Creating layer BatchNorm4
I1007 22:17:02.700762  5322 net.cpp:84] Creating Layer BatchNorm4
I1007 22:17:02.700763  5322 net.cpp:406] BatchNorm4 <- Convolution4
I1007 22:17:02.700768  5322 net.cpp:367] BatchNorm4 -> Convolution4 (in-place)
I1007 22:17:02.700913  5322 net.cpp:122] Setting up BatchNorm4
I1007 22:17:02.700917  5322 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:17:02.700919  5322 net.cpp:137] Memory required for data: 125748400
I1007 22:17:02.700924  5322 layer_factory.hpp:77] Creating layer Scale4
I1007 22:17:02.700929  5322 net.cpp:84] Creating Layer Scale4
I1007 22:17:02.700932  5322 net.cpp:406] Scale4 <- Convolution4
I1007 22:17:02.700935  5322 net.cpp:367] Scale4 -> Convolution4 (in-place)
I1007 22:17:02.700964  5322 layer_factory.hpp:77] Creating layer Scale4
I1007 22:17:02.701045  5322 net.cpp:122] Setting up Scale4
I1007 22:17:02.701050  5322 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:17:02.701052  5322 net.cpp:137] Memory required for data: 132302000
I1007 22:17:02.701056  5322 layer_factory.hpp:77] Creating layer elu4
I1007 22:17:02.701061  5322 net.cpp:84] Creating Layer elu4
I1007 22:17:02.701062  5322 net.cpp:406] elu4 <- Convolution4
I1007 22:17:02.701066  5322 net.cpp:367] elu4 -> Convolution4 (in-place)
I1007 22:17:02.701071  5322 net.cpp:122] Setting up elu4
I1007 22:17:02.701073  5322 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:17:02.701076  5322 net.cpp:137] Memory required for data: 138855600
I1007 22:17:02.701077  5322 layer_factory.hpp:77] Creating layer Convolution5
I1007 22:17:02.701084  5322 net.cpp:84] Creating Layer Convolution5
I1007 22:17:02.701087  5322 net.cpp:406] Convolution5 <- Convolution4
I1007 22:17:02.701090  5322 net.cpp:380] Convolution5 -> Convolution5
I1007 22:17:02.713842  5322 net.cpp:122] Setting up Convolution5
I1007 22:17:02.713852  5322 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:17:02.713855  5322 net.cpp:137] Memory required for data: 145409200
I1007 22:17:02.713860  5322 layer_factory.hpp:77] Creating layer BatchNorm5
I1007 22:17:02.713865  5322 net.cpp:84] Creating Layer BatchNorm5
I1007 22:17:02.713874  5322 net.cpp:406] BatchNorm5 <- Convolution5
I1007 22:17:02.713879  5322 net.cpp:367] BatchNorm5 -> Convolution5 (in-place)
I1007 22:17:02.714026  5322 net.cpp:122] Setting up BatchNorm5
I1007 22:17:02.714031  5322 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:17:02.714033  5322 net.cpp:137] Memory required for data: 151962800
I1007 22:17:02.714042  5322 layer_factory.hpp:77] Creating layer Scale5
I1007 22:17:02.714046  5322 net.cpp:84] Creating Layer Scale5
I1007 22:17:02.714049  5322 net.cpp:406] Scale5 <- Convolution5
I1007 22:17:02.714052  5322 net.cpp:367] Scale5 -> Convolution5 (in-place)
I1007 22:17:02.714082  5322 layer_factory.hpp:77] Creating layer Scale5
I1007 22:17:02.714164  5322 net.cpp:122] Setting up Scale5
I1007 22:17:02.714167  5322 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:17:02.714169  5322 net.cpp:137] Memory required for data: 158516400
I1007 22:17:02.714174  5322 layer_factory.hpp:77] Creating layer Eltwise2
I1007 22:17:02.714179  5322 net.cpp:84] Creating Layer Eltwise2
I1007 22:17:02.714180  5322 net.cpp:406] Eltwise2 <- Eltwise1_elu3_0_split_1
I1007 22:17:02.714184  5322 net.cpp:406] Eltwise2 <- Convolution5
I1007 22:17:02.714186  5322 net.cpp:380] Eltwise2 -> Eltwise2
I1007 22:17:02.714205  5322 net.cpp:122] Setting up Eltwise2
I1007 22:17:02.714207  5322 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:17:02.714210  5322 net.cpp:137] Memory required for data: 165070000
I1007 22:17:02.714212  5322 layer_factory.hpp:77] Creating layer elu5
I1007 22:17:02.714215  5322 net.cpp:84] Creating Layer elu5
I1007 22:17:02.714218  5322 net.cpp:406] elu5 <- Eltwise2
I1007 22:17:02.714221  5322 net.cpp:367] elu5 -> Eltwise2 (in-place)
I1007 22:17:02.714226  5322 net.cpp:122] Setting up elu5
I1007 22:17:02.714228  5322 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:17:02.714231  5322 net.cpp:137] Memory required for data: 171623600
I1007 22:17:02.714232  5322 layer_factory.hpp:77] Creating layer Eltwise2_elu5_0_split
I1007 22:17:02.714236  5322 net.cpp:84] Creating Layer Eltwise2_elu5_0_split
I1007 22:17:02.714237  5322 net.cpp:406] Eltwise2_elu5_0_split <- Eltwise2
I1007 22:17:02.714241  5322 net.cpp:380] Eltwise2_elu5_0_split -> Eltwise2_elu5_0_split_0
I1007 22:17:02.714244  5322 net.cpp:380] Eltwise2_elu5_0_split -> Eltwise2_elu5_0_split_1
I1007 22:17:02.714270  5322 net.cpp:122] Setting up Eltwise2_elu5_0_split
I1007 22:17:02.714274  5322 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:17:02.714277  5322 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:17:02.714279  5322 net.cpp:137] Memory required for data: 184730800
I1007 22:17:02.714282  5322 layer_factory.hpp:77] Creating layer Convolution6
I1007 22:17:02.714288  5322 net.cpp:84] Creating Layer Convolution6
I1007 22:17:02.714292  5322 net.cpp:406] Convolution6 <- Eltwise2_elu5_0_split_0
I1007 22:17:02.714295  5322 net.cpp:380] Convolution6 -> Convolution6
I1007 22:17:02.727318  5322 net.cpp:122] Setting up Convolution6
I1007 22:17:02.727330  5322 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:17:02.727344  5322 net.cpp:137] Memory required for data: 191284400
I1007 22:17:02.727349  5322 layer_factory.hpp:77] Creating layer BatchNorm6
I1007 22:17:02.727357  5322 net.cpp:84] Creating Layer BatchNorm6
I1007 22:17:02.727361  5322 net.cpp:406] BatchNorm6 <- Convolution6
I1007 22:17:02.727367  5322 net.cpp:367] BatchNorm6 -> Convolution6 (in-place)
I1007 22:17:02.727524  5322 net.cpp:122] Setting up BatchNorm6
I1007 22:17:02.727530  5322 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:17:02.727542  5322 net.cpp:137] Memory required for data: 197838000
I1007 22:17:02.727548  5322 layer_factory.hpp:77] Creating layer Scale6
I1007 22:17:02.727553  5322 net.cpp:84] Creating Layer Scale6
I1007 22:17:02.727557  5322 net.cpp:406] Scale6 <- Convolution6
I1007 22:17:02.727563  5322 net.cpp:367] Scale6 -> Convolution6 (in-place)
I1007 22:17:02.727607  5322 layer_factory.hpp:77] Creating layer Scale6
I1007 22:17:02.727715  5322 net.cpp:122] Setting up Scale6
I1007 22:17:02.727728  5322 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:17:02.727741  5322 net.cpp:137] Memory required for data: 204391600
I1007 22:17:02.727746  5322 layer_factory.hpp:77] Creating layer elu6
I1007 22:17:02.727751  5322 net.cpp:84] Creating Layer elu6
I1007 22:17:02.727754  5322 net.cpp:406] elu6 <- Convolution6
I1007 22:17:02.727761  5322 net.cpp:367] elu6 -> Convolution6 (in-place)
I1007 22:17:02.727767  5322 net.cpp:122] Setting up elu6
I1007 22:17:02.727771  5322 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:17:02.727773  5322 net.cpp:137] Memory required for data: 210945200
I1007 22:17:02.727777  5322 layer_factory.hpp:77] Creating layer Convolution7
I1007 22:17:02.727785  5322 net.cpp:84] Creating Layer Convolution7
I1007 22:17:02.727788  5322 net.cpp:406] Convolution7 <- Convolution6
I1007 22:17:02.727802  5322 net.cpp:380] Convolution7 -> Convolution7
I1007 22:17:02.740387  5322 net.cpp:122] Setting up Convolution7
I1007 22:17:02.740396  5322 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:17:02.740399  5322 net.cpp:137] Memory required for data: 217498800
I1007 22:17:02.740403  5322 layer_factory.hpp:77] Creating layer BatchNorm7
I1007 22:17:02.740411  5322 net.cpp:84] Creating Layer BatchNorm7
I1007 22:17:02.740414  5322 net.cpp:406] BatchNorm7 <- Convolution7
I1007 22:17:02.740418  5322 net.cpp:367] BatchNorm7 -> Convolution7 (in-place)
I1007 22:17:02.740562  5322 net.cpp:122] Setting up BatchNorm7
I1007 22:17:02.740567  5322 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:17:02.740569  5322 net.cpp:137] Memory required for data: 224052400
I1007 22:17:02.740574  5322 layer_factory.hpp:77] Creating layer Scale7
I1007 22:17:02.740578  5322 net.cpp:84] Creating Layer Scale7
I1007 22:17:02.740581  5322 net.cpp:406] Scale7 <- Convolution7
I1007 22:17:02.740583  5322 net.cpp:367] Scale7 -> Convolution7 (in-place)
I1007 22:17:02.740613  5322 layer_factory.hpp:77] Creating layer Scale7
I1007 22:17:02.740692  5322 net.cpp:122] Setting up Scale7
I1007 22:17:02.740696  5322 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:17:02.740698  5322 net.cpp:137] Memory required for data: 230606000
I1007 22:17:02.740702  5322 layer_factory.hpp:77] Creating layer Eltwise3
I1007 22:17:02.740706  5322 net.cpp:84] Creating Layer Eltwise3
I1007 22:17:02.740710  5322 net.cpp:406] Eltwise3 <- Eltwise2_elu5_0_split_1
I1007 22:17:02.740712  5322 net.cpp:406] Eltwise3 <- Convolution7
I1007 22:17:02.740715  5322 net.cpp:380] Eltwise3 -> Eltwise3
I1007 22:17:02.740731  5322 net.cpp:122] Setting up Eltwise3
I1007 22:17:02.740736  5322 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:17:02.740737  5322 net.cpp:137] Memory required for data: 237159600
I1007 22:17:02.740739  5322 layer_factory.hpp:77] Creating layer elu7
I1007 22:17:02.740743  5322 net.cpp:84] Creating Layer elu7
I1007 22:17:02.740746  5322 net.cpp:406] elu7 <- Eltwise3
I1007 22:17:02.740749  5322 net.cpp:367] elu7 -> Eltwise3 (in-place)
I1007 22:17:02.740753  5322 net.cpp:122] Setting up elu7
I1007 22:17:02.740756  5322 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:17:02.740758  5322 net.cpp:137] Memory required for data: 243713200
I1007 22:17:02.740761  5322 layer_factory.hpp:77] Creating layer Eltwise3_elu7_0_split
I1007 22:17:02.740763  5322 net.cpp:84] Creating Layer Eltwise3_elu7_0_split
I1007 22:17:02.740766  5322 net.cpp:406] Eltwise3_elu7_0_split <- Eltwise3
I1007 22:17:02.740768  5322 net.cpp:380] Eltwise3_elu7_0_split -> Eltwise3_elu7_0_split_0
I1007 22:17:02.740772  5322 net.cpp:380] Eltwise3_elu7_0_split -> Eltwise3_elu7_0_split_1
I1007 22:17:02.740797  5322 net.cpp:122] Setting up Eltwise3_elu7_0_split
I1007 22:17:02.740800  5322 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:17:02.740803  5322 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:17:02.740805  5322 net.cpp:137] Memory required for data: 256820400
I1007 22:17:02.740808  5322 layer_factory.hpp:77] Creating layer Convolution8
I1007 22:17:02.740813  5322 net.cpp:84] Creating Layer Convolution8
I1007 22:17:02.740823  5322 net.cpp:406] Convolution8 <- Eltwise3_elu7_0_split_0
I1007 22:17:02.740828  5322 net.cpp:380] Convolution8 -> Convolution8
I1007 22:17:02.750612  5322 net.cpp:122] Setting up Convolution8
I1007 22:17:02.750633  5322 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:17:02.750638  5322 net.cpp:137] Memory required for data: 263374000
I1007 22:17:02.750643  5322 layer_factory.hpp:77] Creating layer BatchNorm8
I1007 22:17:02.750653  5322 net.cpp:84] Creating Layer BatchNorm8
I1007 22:17:02.750658  5322 net.cpp:406] BatchNorm8 <- Convolution8
I1007 22:17:02.750663  5322 net.cpp:367] BatchNorm8 -> Convolution8 (in-place)
I1007 22:17:02.750823  5322 net.cpp:122] Setting up BatchNorm8
I1007 22:17:02.750829  5322 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:17:02.750841  5322 net.cpp:137] Memory required for data: 269927600
I1007 22:17:02.750847  5322 layer_factory.hpp:77] Creating layer Scale8
I1007 22:17:02.750859  5322 net.cpp:84] Creating Layer Scale8
I1007 22:17:02.750861  5322 net.cpp:406] Scale8 <- Convolution8
I1007 22:17:02.750865  5322 net.cpp:367] Scale8 -> Convolution8 (in-place)
I1007 22:17:02.750900  5322 layer_factory.hpp:77] Creating layer Scale8
I1007 22:17:02.750984  5322 net.cpp:122] Setting up Scale8
I1007 22:17:02.750989  5322 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:17:02.750993  5322 net.cpp:137] Memory required for data: 276481200
I1007 22:17:02.750996  5322 layer_factory.hpp:77] Creating layer elu8
I1007 22:17:02.751001  5322 net.cpp:84] Creating Layer elu8
I1007 22:17:02.751004  5322 net.cpp:406] elu8 <- Convolution8
I1007 22:17:02.751008  5322 net.cpp:367] elu8 -> Convolution8 (in-place)
I1007 22:17:02.751013  5322 net.cpp:122] Setting up elu8
I1007 22:17:02.751016  5322 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:17:02.751019  5322 net.cpp:137] Memory required for data: 283034800
I1007 22:17:02.751020  5322 layer_factory.hpp:77] Creating layer Convolution9
I1007 22:17:02.751027  5322 net.cpp:84] Creating Layer Convolution9
I1007 22:17:02.751031  5322 net.cpp:406] Convolution9 <- Convolution8
I1007 22:17:02.751035  5322 net.cpp:380] Convolution9 -> Convolution9
I1007 22:17:02.757576  5322 net.cpp:122] Setting up Convolution9
I1007 22:17:02.757587  5322 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:17:02.757591  5322 net.cpp:137] Memory required for data: 289588400
I1007 22:17:02.757596  5322 layer_factory.hpp:77] Creating layer BatchNorm9
I1007 22:17:02.757602  5322 net.cpp:84] Creating Layer BatchNorm9
I1007 22:17:02.757606  5322 net.cpp:406] BatchNorm9 <- Convolution9
I1007 22:17:02.757611  5322 net.cpp:367] BatchNorm9 -> Convolution9 (in-place)
I1007 22:17:02.757762  5322 net.cpp:122] Setting up BatchNorm9
I1007 22:17:02.757767  5322 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:17:02.757771  5322 net.cpp:137] Memory required for data: 296142000
I1007 22:17:02.757776  5322 layer_factory.hpp:77] Creating layer Scale9
I1007 22:17:02.757781  5322 net.cpp:84] Creating Layer Scale9
I1007 22:17:02.757784  5322 net.cpp:406] Scale9 <- Convolution9
I1007 22:17:02.757788  5322 net.cpp:367] Scale9 -> Convolution9 (in-place)
I1007 22:17:02.757819  5322 layer_factory.hpp:77] Creating layer Scale9
I1007 22:17:02.757905  5322 net.cpp:122] Setting up Scale9
I1007 22:17:02.757910  5322 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:17:02.757913  5322 net.cpp:137] Memory required for data: 302695600
I1007 22:17:02.757917  5322 layer_factory.hpp:77] Creating layer Eltwise4
I1007 22:17:02.757921  5322 net.cpp:84] Creating Layer Eltwise4
I1007 22:17:02.757925  5322 net.cpp:406] Eltwise4 <- Eltwise3_elu7_0_split_1
I1007 22:17:02.757928  5322 net.cpp:406] Eltwise4 <- Convolution9
I1007 22:17:02.757931  5322 net.cpp:380] Eltwise4 -> Eltwise4
I1007 22:17:02.757951  5322 net.cpp:122] Setting up Eltwise4
I1007 22:17:02.757956  5322 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:17:02.757957  5322 net.cpp:137] Memory required for data: 309249200
I1007 22:17:02.757959  5322 layer_factory.hpp:77] Creating layer elu9
I1007 22:17:02.757972  5322 net.cpp:84] Creating Layer elu9
I1007 22:17:02.757975  5322 net.cpp:406] elu9 <- Eltwise4
I1007 22:17:02.757978  5322 net.cpp:367] elu9 -> Eltwise4 (in-place)
I1007 22:17:02.757983  5322 net.cpp:122] Setting up elu9
I1007 22:17:02.757987  5322 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:17:02.757989  5322 net.cpp:137] Memory required for data: 315802800
I1007 22:17:02.757992  5322 layer_factory.hpp:77] Creating layer Eltwise4_elu9_0_split
I1007 22:17:02.757995  5322 net.cpp:84] Creating Layer Eltwise4_elu9_0_split
I1007 22:17:02.757998  5322 net.cpp:406] Eltwise4_elu9_0_split <- Eltwise4
I1007 22:17:02.758002  5322 net.cpp:380] Eltwise4_elu9_0_split -> Eltwise4_elu9_0_split_0
I1007 22:17:02.758007  5322 net.cpp:380] Eltwise4_elu9_0_split -> Eltwise4_elu9_0_split_1
I1007 22:17:02.758033  5322 net.cpp:122] Setting up Eltwise4_elu9_0_split
I1007 22:17:02.758038  5322 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:17:02.758041  5322 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:17:02.758044  5322 net.cpp:137] Memory required for data: 328910000
I1007 22:17:02.758046  5322 layer_factory.hpp:77] Creating layer Convolution10
I1007 22:17:02.758054  5322 net.cpp:84] Creating Layer Convolution10
I1007 22:17:02.758056  5322 net.cpp:406] Convolution10 <- Eltwise4_elu9_0_split_0
I1007 22:17:02.758061  5322 net.cpp:380] Convolution10 -> Convolution10
I1007 22:17:02.764313  5322 net.cpp:122] Setting up Convolution10
I1007 22:17:02.764323  5322 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:17:02.764327  5322 net.cpp:137] Memory required for data: 335463600
I1007 22:17:02.764338  5322 layer_factory.hpp:77] Creating layer BatchNorm10
I1007 22:17:02.764344  5322 net.cpp:84] Creating Layer BatchNorm10
I1007 22:17:02.764348  5322 net.cpp:406] BatchNorm10 <- Convolution10
I1007 22:17:02.764353  5322 net.cpp:367] BatchNorm10 -> Convolution10 (in-place)
I1007 22:17:02.764502  5322 net.cpp:122] Setting up BatchNorm10
I1007 22:17:02.764506  5322 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:17:02.764509  5322 net.cpp:137] Memory required for data: 342017200
I1007 22:17:02.764515  5322 layer_factory.hpp:77] Creating layer Scale10
I1007 22:17:02.764520  5322 net.cpp:84] Creating Layer Scale10
I1007 22:17:02.764523  5322 net.cpp:406] Scale10 <- Convolution10
I1007 22:17:02.764528  5322 net.cpp:367] Scale10 -> Convolution10 (in-place)
I1007 22:17:02.764559  5322 layer_factory.hpp:77] Creating layer Scale10
I1007 22:17:02.764642  5322 net.cpp:122] Setting up Scale10
I1007 22:17:02.764647  5322 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:17:02.764650  5322 net.cpp:137] Memory required for data: 348570800
I1007 22:17:02.764654  5322 layer_factory.hpp:77] Creating layer elu10
I1007 22:17:02.764660  5322 net.cpp:84] Creating Layer elu10
I1007 22:17:02.764663  5322 net.cpp:406] elu10 <- Convolution10
I1007 22:17:02.764667  5322 net.cpp:367] elu10 -> Convolution10 (in-place)
I1007 22:17:02.764670  5322 net.cpp:122] Setting up elu10
I1007 22:17:02.764673  5322 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:17:02.764675  5322 net.cpp:137] Memory required for data: 355124400
I1007 22:17:02.764678  5322 layer_factory.hpp:77] Creating layer Convolution11
I1007 22:17:02.764684  5322 net.cpp:84] Creating Layer Convolution11
I1007 22:17:02.764688  5322 net.cpp:406] Convolution11 <- Convolution10
I1007 22:17:02.764693  5322 net.cpp:380] Convolution11 -> Convolution11
I1007 22:17:02.770982  5322 net.cpp:122] Setting up Convolution11
I1007 22:17:02.770993  5322 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:17:02.770997  5322 net.cpp:137] Memory required for data: 361678000
I1007 22:17:02.771001  5322 layer_factory.hpp:77] Creating layer BatchNorm11
I1007 22:17:02.771008  5322 net.cpp:84] Creating Layer BatchNorm11
I1007 22:17:02.771011  5322 net.cpp:406] BatchNorm11 <- Convolution11
I1007 22:17:02.771015  5322 net.cpp:367] BatchNorm11 -> Convolution11 (in-place)
I1007 22:17:02.771168  5322 net.cpp:122] Setting up BatchNorm11
I1007 22:17:02.771174  5322 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:17:02.771184  5322 net.cpp:137] Memory required for data: 368231600
I1007 22:17:02.771189  5322 layer_factory.hpp:77] Creating layer Scale11
I1007 22:17:02.771195  5322 net.cpp:84] Creating Layer Scale11
I1007 22:17:02.771199  5322 net.cpp:406] Scale11 <- Convolution11
I1007 22:17:02.771203  5322 net.cpp:367] Scale11 -> Convolution11 (in-place)
I1007 22:17:02.771235  5322 layer_factory.hpp:77] Creating layer Scale11
I1007 22:17:02.771322  5322 net.cpp:122] Setting up Scale11
I1007 22:17:02.771328  5322 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:17:02.771332  5322 net.cpp:137] Memory required for data: 374785200
I1007 22:17:02.771335  5322 layer_factory.hpp:77] Creating layer Eltwise5
I1007 22:17:02.771340  5322 net.cpp:84] Creating Layer Eltwise5
I1007 22:17:02.771343  5322 net.cpp:406] Eltwise5 <- Eltwise4_elu9_0_split_1
I1007 22:17:02.771347  5322 net.cpp:406] Eltwise5 <- Convolution11
I1007 22:17:02.771351  5322 net.cpp:380] Eltwise5 -> Eltwise5
I1007 22:17:02.771369  5322 net.cpp:122] Setting up Eltwise5
I1007 22:17:02.771374  5322 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:17:02.771376  5322 net.cpp:137] Memory required for data: 381338800
I1007 22:17:02.771378  5322 layer_factory.hpp:77] Creating layer elu11
I1007 22:17:02.771383  5322 net.cpp:84] Creating Layer elu11
I1007 22:17:02.771385  5322 net.cpp:406] elu11 <- Eltwise5
I1007 22:17:02.771389  5322 net.cpp:367] elu11 -> Eltwise5 (in-place)
I1007 22:17:02.771394  5322 net.cpp:122] Setting up elu11
I1007 22:17:02.771397  5322 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:17:02.771400  5322 net.cpp:137] Memory required for data: 387892400
I1007 22:17:02.771402  5322 layer_factory.hpp:77] Creating layer Eltwise5_elu11_0_split
I1007 22:17:02.771405  5322 net.cpp:84] Creating Layer Eltwise5_elu11_0_split
I1007 22:17:02.771409  5322 net.cpp:406] Eltwise5_elu11_0_split <- Eltwise5
I1007 22:17:02.771412  5322 net.cpp:380] Eltwise5_elu11_0_split -> Eltwise5_elu11_0_split_0
I1007 22:17:02.771415  5322 net.cpp:380] Eltwise5_elu11_0_split -> Eltwise5_elu11_0_split_1
I1007 22:17:02.771442  5322 net.cpp:122] Setting up Eltwise5_elu11_0_split
I1007 22:17:02.771446  5322 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:17:02.771450  5322 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:17:02.771452  5322 net.cpp:137] Memory required for data: 400999600
I1007 22:17:02.771456  5322 layer_factory.hpp:77] Creating layer Convolution12
I1007 22:17:02.771461  5322 net.cpp:84] Creating Layer Convolution12
I1007 22:17:02.771464  5322 net.cpp:406] Convolution12 <- Eltwise5_elu11_0_split_0
I1007 22:17:02.771468  5322 net.cpp:380] Convolution12 -> Convolution12
I1007 22:17:02.778156  5322 net.cpp:122] Setting up Convolution12
I1007 22:17:02.778177  5322 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:17:02.778180  5322 net.cpp:137] Memory required for data: 404276400
I1007 22:17:02.778185  5322 layer_factory.hpp:77] Creating layer BatchNorm12
I1007 22:17:02.778190  5322 net.cpp:84] Creating Layer BatchNorm12
I1007 22:17:02.778193  5322 net.cpp:406] BatchNorm12 <- Convolution12
I1007 22:17:02.778198  5322 net.cpp:367] BatchNorm12 -> Convolution12 (in-place)
I1007 22:17:02.778347  5322 net.cpp:122] Setting up BatchNorm12
I1007 22:17:02.778353  5322 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:17:02.778355  5322 net.cpp:137] Memory required for data: 407553200
I1007 22:17:02.778360  5322 layer_factory.hpp:77] Creating layer Scale12
I1007 22:17:02.778365  5322 net.cpp:84] Creating Layer Scale12
I1007 22:17:02.778368  5322 net.cpp:406] Scale12 <- Convolution12
I1007 22:17:02.778372  5322 net.cpp:367] Scale12 -> Convolution12 (in-place)
I1007 22:17:02.778403  5322 layer_factory.hpp:77] Creating layer Scale12
I1007 22:17:02.778487  5322 net.cpp:122] Setting up Scale12
I1007 22:17:02.778492  5322 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:17:02.778494  5322 net.cpp:137] Memory required for data: 410830000
I1007 22:17:02.778498  5322 layer_factory.hpp:77] Creating layer Convolution13
I1007 22:17:02.778514  5322 net.cpp:84] Creating Layer Convolution13
I1007 22:17:02.778518  5322 net.cpp:406] Convolution13 <- Eltwise5_elu11_0_split_1
I1007 22:17:02.778523  5322 net.cpp:380] Convolution13 -> Convolution13
I1007 22:17:02.782903  5322 net.cpp:122] Setting up Convolution13
I1007 22:17:02.782913  5322 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:17:02.782917  5322 net.cpp:137] Memory required for data: 414106800
I1007 22:17:02.782922  5322 layer_factory.hpp:77] Creating layer BatchNorm13
I1007 22:17:02.782927  5322 net.cpp:84] Creating Layer BatchNorm13
I1007 22:17:02.782932  5322 net.cpp:406] BatchNorm13 <- Convolution13
I1007 22:17:02.782935  5322 net.cpp:367] BatchNorm13 -> Convolution13 (in-place)
I1007 22:17:02.783084  5322 net.cpp:122] Setting up BatchNorm13
I1007 22:17:02.783090  5322 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:17:02.783093  5322 net.cpp:137] Memory required for data: 417383600
I1007 22:17:02.783098  5322 layer_factory.hpp:77] Creating layer Scale13
I1007 22:17:02.783104  5322 net.cpp:84] Creating Layer Scale13
I1007 22:17:02.783107  5322 net.cpp:406] Scale13 <- Convolution13
I1007 22:17:02.783112  5322 net.cpp:367] Scale13 -> Convolution13 (in-place)
I1007 22:17:02.783143  5322 layer_factory.hpp:77] Creating layer Scale13
I1007 22:17:02.783232  5322 net.cpp:122] Setting up Scale13
I1007 22:17:02.783238  5322 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:17:02.783241  5322 net.cpp:137] Memory required for data: 420660400
I1007 22:17:02.783246  5322 layer_factory.hpp:77] Creating layer elu12
I1007 22:17:02.783251  5322 net.cpp:84] Creating Layer elu12
I1007 22:17:02.783254  5322 net.cpp:406] elu12 <- Convolution13
I1007 22:17:02.783257  5322 net.cpp:367] elu12 -> Convolution13 (in-place)
I1007 22:17:02.783262  5322 net.cpp:122] Setting up elu12
I1007 22:17:02.783265  5322 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:17:02.783267  5322 net.cpp:137] Memory required for data: 423937200
I1007 22:17:02.783269  5322 layer_factory.hpp:77] Creating layer Convolution14
I1007 22:17:02.783280  5322 net.cpp:84] Creating Layer Convolution14
I1007 22:17:02.783284  5322 net.cpp:406] Convolution14 <- Convolution13
I1007 22:17:02.783288  5322 net.cpp:380] Convolution14 -> Convolution14
I1007 22:17:02.784370  5322 net.cpp:122] Setting up Convolution14
I1007 22:17:02.784380  5322 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:17:02.784384  5322 net.cpp:137] Memory required for data: 427214000
I1007 22:17:02.784389  5322 layer_factory.hpp:77] Creating layer BatchNorm14
I1007 22:17:02.784394  5322 net.cpp:84] Creating Layer BatchNorm14
I1007 22:17:02.784397  5322 net.cpp:406] BatchNorm14 <- Convolution14
I1007 22:17:02.784402  5322 net.cpp:367] BatchNorm14 -> Convolution14 (in-place)
I1007 22:17:02.784551  5322 net.cpp:122] Setting up BatchNorm14
I1007 22:17:02.784566  5322 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:17:02.784569  5322 net.cpp:137] Memory required for data: 430490800
I1007 22:17:02.784574  5322 layer_factory.hpp:77] Creating layer Scale14
I1007 22:17:02.784588  5322 net.cpp:84] Creating Layer Scale14
I1007 22:17:02.784590  5322 net.cpp:406] Scale14 <- Convolution14
I1007 22:17:02.784593  5322 net.cpp:367] Scale14 -> Convolution14 (in-place)
I1007 22:17:02.784633  5322 layer_factory.hpp:77] Creating layer Scale14
I1007 22:17:02.784736  5322 net.cpp:122] Setting up Scale14
I1007 22:17:02.784741  5322 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:17:02.784744  5322 net.cpp:137] Memory required for data: 433767600
I1007 22:17:02.784759  5322 layer_factory.hpp:77] Creating layer Eltwise6
I1007 22:17:02.784765  5322 net.cpp:84] Creating Layer Eltwise6
I1007 22:17:02.784766  5322 net.cpp:406] Eltwise6 <- Convolution12
I1007 22:17:02.784770  5322 net.cpp:406] Eltwise6 <- Convolution14
I1007 22:17:02.784772  5322 net.cpp:380] Eltwise6 -> Eltwise6
I1007 22:17:02.784787  5322 net.cpp:122] Setting up Eltwise6
I1007 22:17:02.784801  5322 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:17:02.784803  5322 net.cpp:137] Memory required for data: 437044400
I1007 22:17:02.784822  5322 layer_factory.hpp:77] Creating layer elu13
I1007 22:17:02.784827  5322 net.cpp:84] Creating Layer elu13
I1007 22:17:02.784829  5322 net.cpp:406] elu13 <- Eltwise6
I1007 22:17:02.784833  5322 net.cpp:367] elu13 -> Eltwise6 (in-place)
I1007 22:17:02.784837  5322 net.cpp:122] Setting up elu13
I1007 22:17:02.784840  5322 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:17:02.784843  5322 net.cpp:137] Memory required for data: 440321200
I1007 22:17:02.784845  5322 layer_factory.hpp:77] Creating layer Eltwise6_elu13_0_split
I1007 22:17:02.784849  5322 net.cpp:84] Creating Layer Eltwise6_elu13_0_split
I1007 22:17:02.784852  5322 net.cpp:406] Eltwise6_elu13_0_split <- Eltwise6
I1007 22:17:02.784857  5322 net.cpp:380] Eltwise6_elu13_0_split -> Eltwise6_elu13_0_split_0
I1007 22:17:02.784860  5322 net.cpp:380] Eltwise6_elu13_0_split -> Eltwise6_elu13_0_split_1
I1007 22:17:02.784898  5322 net.cpp:122] Setting up Eltwise6_elu13_0_split
I1007 22:17:02.784901  5322 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:17:02.784914  5322 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:17:02.784917  5322 net.cpp:137] Memory required for data: 446874800
I1007 22:17:02.784919  5322 layer_factory.hpp:77] Creating layer Convolution15
I1007 22:17:02.784926  5322 net.cpp:84] Creating Layer Convolution15
I1007 22:17:02.784929  5322 net.cpp:406] Convolution15 <- Eltwise6_elu13_0_split_0
I1007 22:17:02.784932  5322 net.cpp:380] Convolution15 -> Convolution15
I1007 22:17:02.788158  5322 net.cpp:122] Setting up Convolution15
I1007 22:17:02.788170  5322 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:17:02.788175  5322 net.cpp:137] Memory required for data: 450151600
I1007 22:17:02.788182  5322 layer_factory.hpp:77] Creating layer BatchNorm15
I1007 22:17:02.788193  5322 net.cpp:84] Creating Layer BatchNorm15
I1007 22:17:02.788199  5322 net.cpp:406] BatchNorm15 <- Convolution15
I1007 22:17:02.788206  5322 net.cpp:367] BatchNorm15 -> Convolution15 (in-place)
I1007 22:17:02.788439  5322 net.cpp:122] Setting up BatchNorm15
I1007 22:17:02.788446  5322 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:17:02.788450  5322 net.cpp:137] Memory required for data: 453428400
I1007 22:17:02.788458  5322 layer_factory.hpp:77] Creating layer Scale15
I1007 22:17:02.788466  5322 net.cpp:84] Creating Layer Scale15
I1007 22:17:02.788471  5322 net.cpp:406] Scale15 <- Convolution15
I1007 22:17:02.788477  5322 net.cpp:367] Scale15 -> Convolution15 (in-place)
I1007 22:17:02.788522  5322 layer_factory.hpp:77] Creating layer Scale15
I1007 22:17:02.788648  5322 net.cpp:122] Setting up Scale15
I1007 22:17:02.788656  5322 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:17:02.788660  5322 net.cpp:137] Memory required for data: 456705200
I1007 22:17:02.788666  5322 layer_factory.hpp:77] Creating layer elu14
I1007 22:17:02.788674  5322 net.cpp:84] Creating Layer elu14
I1007 22:17:02.788678  5322 net.cpp:406] elu14 <- Convolution15
I1007 22:17:02.788684  5322 net.cpp:367] elu14 -> Convolution15 (in-place)
I1007 22:17:02.788691  5322 net.cpp:122] Setting up elu14
I1007 22:17:02.788697  5322 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:17:02.788700  5322 net.cpp:137] Memory required for data: 459982000
I1007 22:17:02.788705  5322 layer_factory.hpp:77] Creating layer Convolution16
I1007 22:17:02.788715  5322 net.cpp:84] Creating Layer Convolution16
I1007 22:17:02.788720  5322 net.cpp:406] Convolution16 <- Convolution15
I1007 22:17:02.788727  5322 net.cpp:380] Convolution16 -> Convolution16
I1007 22:17:02.794692  5322 net.cpp:122] Setting up Convolution16
I1007 22:17:02.794704  5322 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:17:02.794708  5322 net.cpp:137] Memory required for data: 463258800
I1007 22:17:02.794715  5322 layer_factory.hpp:77] Creating layer BatchNorm16
I1007 22:17:02.794724  5322 net.cpp:84] Creating Layer BatchNorm16
I1007 22:17:02.794729  5322 net.cpp:406] BatchNorm16 <- Convolution16
I1007 22:17:02.794739  5322 net.cpp:367] BatchNorm16 -> Convolution16 (in-place)
I1007 22:17:02.794965  5322 net.cpp:122] Setting up BatchNorm16
I1007 22:17:02.794973  5322 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:17:02.794977  5322 net.cpp:137] Memory required for data: 466535600
I1007 22:17:02.794986  5322 layer_factory.hpp:77] Creating layer Scale16
I1007 22:17:02.794994  5322 net.cpp:84] Creating Layer Scale16
I1007 22:17:02.794999  5322 net.cpp:406] Scale16 <- Convolution16
I1007 22:17:02.795004  5322 net.cpp:367] Scale16 -> Convolution16 (in-place)
I1007 22:17:02.795049  5322 layer_factory.hpp:77] Creating layer Scale16
I1007 22:17:02.795182  5322 net.cpp:122] Setting up Scale16
I1007 22:17:02.795192  5322 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:17:02.795195  5322 net.cpp:137] Memory required for data: 469812400
I1007 22:17:02.795202  5322 layer_factory.hpp:77] Creating layer Eltwise7
I1007 22:17:02.795209  5322 net.cpp:84] Creating Layer Eltwise7
I1007 22:17:02.795214  5322 net.cpp:406] Eltwise7 <- Eltwise6_elu13_0_split_1
I1007 22:17:02.795219  5322 net.cpp:406] Eltwise7 <- Convolution16
I1007 22:17:02.795227  5322 net.cpp:380] Eltwise7 -> Eltwise7
I1007 22:17:02.795248  5322 net.cpp:122] Setting up Eltwise7
I1007 22:17:02.795255  5322 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:17:02.795260  5322 net.cpp:137] Memory required for data: 473089200
I1007 22:17:02.795264  5322 layer_factory.hpp:77] Creating layer elu15
I1007 22:17:02.795271  5322 net.cpp:84] Creating Layer elu15
I1007 22:17:02.795276  5322 net.cpp:406] elu15 <- Eltwise7
I1007 22:17:02.795281  5322 net.cpp:367] elu15 -> Eltwise7 (in-place)
I1007 22:17:02.795289  5322 net.cpp:122] Setting up elu15
I1007 22:17:02.795295  5322 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:17:02.795298  5322 net.cpp:137] Memory required for data: 476366000
I1007 22:17:02.795302  5322 layer_factory.hpp:77] Creating layer Eltwise7_elu15_0_split
I1007 22:17:02.795310  5322 net.cpp:84] Creating Layer Eltwise7_elu15_0_split
I1007 22:17:02.795313  5322 net.cpp:406] Eltwise7_elu15_0_split <- Eltwise7
I1007 22:17:02.795320  5322 net.cpp:380] Eltwise7_elu15_0_split -> Eltwise7_elu15_0_split_0
I1007 22:17:02.795326  5322 net.cpp:380] Eltwise7_elu15_0_split -> Eltwise7_elu15_0_split_1
I1007 22:17:02.795364  5322 net.cpp:122] Setting up Eltwise7_elu15_0_split
I1007 22:17:02.795372  5322 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:17:02.795377  5322 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:17:02.795382  5322 net.cpp:137] Memory required for data: 482919600
I1007 22:17:02.795385  5322 layer_factory.hpp:77] Creating layer Convolution17
I1007 22:17:02.795397  5322 net.cpp:84] Creating Layer Convolution17
I1007 22:17:02.795402  5322 net.cpp:406] Convolution17 <- Eltwise7_elu15_0_split_0
I1007 22:17:02.795408  5322 net.cpp:380] Convolution17 -> Convolution17
I1007 22:17:02.801316  5322 net.cpp:122] Setting up Convolution17
I1007 22:17:02.801331  5322 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:17:02.801336  5322 net.cpp:137] Memory required for data: 486196400
I1007 22:17:02.801342  5322 layer_factory.hpp:77] Creating layer BatchNorm17
I1007 22:17:02.801352  5322 net.cpp:84] Creating Layer BatchNorm17
I1007 22:17:02.801358  5322 net.cpp:406] BatchNorm17 <- Convolution17
I1007 22:17:02.801365  5322 net.cpp:367] BatchNorm17 -> Convolution17 (in-place)
I1007 22:17:02.801581  5322 net.cpp:122] Setting up BatchNorm17
I1007 22:17:02.801589  5322 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:17:02.801594  5322 net.cpp:137] Memory required for data: 489473200
I1007 22:17:02.801602  5322 layer_factory.hpp:77] Creating layer Scale17
I1007 22:17:02.801610  5322 net.cpp:84] Creating Layer Scale17
I1007 22:17:02.801615  5322 net.cpp:406] Scale17 <- Convolution17
I1007 22:17:02.801621  5322 net.cpp:367] Scale17 -> Convolution17 (in-place)
I1007 22:17:02.801666  5322 layer_factory.hpp:77] Creating layer Scale17
I1007 22:17:02.801793  5322 net.cpp:122] Setting up Scale17
I1007 22:17:02.801801  5322 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:17:02.801805  5322 net.cpp:137] Memory required for data: 492750000
I1007 22:17:02.801822  5322 layer_factory.hpp:77] Creating layer elu16
I1007 22:17:02.801829  5322 net.cpp:84] Creating Layer elu16
I1007 22:17:02.801834  5322 net.cpp:406] elu16 <- Convolution17
I1007 22:17:02.801841  5322 net.cpp:367] elu16 -> Convolution17 (in-place)
I1007 22:17:02.801848  5322 net.cpp:122] Setting up elu16
I1007 22:17:02.801854  5322 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:17:02.801859  5322 net.cpp:137] Memory required for data: 496026800
I1007 22:17:02.801863  5322 layer_factory.hpp:77] Creating layer Convolution18
I1007 22:17:02.801873  5322 net.cpp:84] Creating Layer Convolution18
I1007 22:17:02.801878  5322 net.cpp:406] Convolution18 <- Convolution17
I1007 22:17:02.801885  5322 net.cpp:380] Convolution18 -> Convolution18
I1007 22:17:02.805748  5322 net.cpp:122] Setting up Convolution18
I1007 22:17:02.805763  5322 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:17:02.805766  5322 net.cpp:137] Memory required for data: 499303600
I1007 22:17:02.805773  5322 layer_factory.hpp:77] Creating layer BatchNorm18
I1007 22:17:02.805793  5322 net.cpp:84] Creating Layer BatchNorm18
I1007 22:17:02.805797  5322 net.cpp:406] BatchNorm18 <- Convolution18
I1007 22:17:02.805805  5322 net.cpp:367] BatchNorm18 -> Convolution18 (in-place)
I1007 22:17:02.806046  5322 net.cpp:122] Setting up BatchNorm18
I1007 22:17:02.806056  5322 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:17:02.806059  5322 net.cpp:137] Memory required for data: 502580400
I1007 22:17:02.806069  5322 layer_factory.hpp:77] Creating layer Scale18
I1007 22:17:02.806077  5322 net.cpp:84] Creating Layer Scale18
I1007 22:17:02.806082  5322 net.cpp:406] Scale18 <- Convolution18
I1007 22:17:02.806088  5322 net.cpp:367] Scale18 -> Convolution18 (in-place)
I1007 22:17:02.806133  5322 layer_factory.hpp:77] Creating layer Scale18
I1007 22:17:02.806258  5322 net.cpp:122] Setting up Scale18
I1007 22:17:02.806267  5322 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:17:02.806270  5322 net.cpp:137] Memory required for data: 505857200
I1007 22:17:02.806277  5322 layer_factory.hpp:77] Creating layer Eltwise8
I1007 22:17:02.806283  5322 net.cpp:84] Creating Layer Eltwise8
I1007 22:17:02.806288  5322 net.cpp:406] Eltwise8 <- Eltwise7_elu15_0_split_1
I1007 22:17:02.806293  5322 net.cpp:406] Eltwise8 <- Convolution18
I1007 22:17:02.806299  5322 net.cpp:380] Eltwise8 -> Eltwise8
I1007 22:17:02.806321  5322 net.cpp:122] Setting up Eltwise8
I1007 22:17:02.806329  5322 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:17:02.806334  5322 net.cpp:137] Memory required for data: 509134000
I1007 22:17:02.806337  5322 layer_factory.hpp:77] Creating layer elu17
I1007 22:17:02.806342  5322 net.cpp:84] Creating Layer elu17
I1007 22:17:02.806347  5322 net.cpp:406] elu17 <- Eltwise8
I1007 22:17:02.806354  5322 net.cpp:367] elu17 -> Eltwise8 (in-place)
I1007 22:17:02.806360  5322 net.cpp:122] Setting up elu17
I1007 22:17:02.806366  5322 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:17:02.806371  5322 net.cpp:137] Memory required for data: 512410800
I1007 22:17:02.806375  5322 layer_factory.hpp:77] Creating layer Eltwise8_elu17_0_split
I1007 22:17:02.806381  5322 net.cpp:84] Creating Layer Eltwise8_elu17_0_split
I1007 22:17:02.806385  5322 net.cpp:406] Eltwise8_elu17_0_split <- Eltwise8
I1007 22:17:02.806391  5322 net.cpp:380] Eltwise8_elu17_0_split -> Eltwise8_elu17_0_split_0
I1007 22:17:02.806397  5322 net.cpp:380] Eltwise8_elu17_0_split -> Eltwise8_elu17_0_split_1
I1007 22:17:02.806437  5322 net.cpp:122] Setting up Eltwise8_elu17_0_split
I1007 22:17:02.806453  5322 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:17:02.806459  5322 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:17:02.806463  5322 net.cpp:137] Memory required for data: 518964400
I1007 22:17:02.806468  5322 layer_factory.hpp:77] Creating layer Convolution19
I1007 22:17:02.806479  5322 net.cpp:84] Creating Layer Convolution19
I1007 22:17:02.806485  5322 net.cpp:406] Convolution19 <- Eltwise8_elu17_0_split_0
I1007 22:17:02.806502  5322 net.cpp:380] Convolution19 -> Convolution19
I1007 22:17:02.812760  5322 net.cpp:122] Setting up Convolution19
I1007 22:17:02.812774  5322 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:17:02.812777  5322 net.cpp:137] Memory required for data: 522241200
I1007 22:17:02.812783  5322 layer_factory.hpp:77] Creating layer BatchNorm19
I1007 22:17:02.812800  5322 net.cpp:84] Creating Layer BatchNorm19
I1007 22:17:02.812808  5322 net.cpp:406] BatchNorm19 <- Convolution19
I1007 22:17:02.812824  5322 net.cpp:367] BatchNorm19 -> Convolution19 (in-place)
I1007 22:17:02.812978  5322 net.cpp:122] Setting up BatchNorm19
I1007 22:17:02.812984  5322 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:17:02.812988  5322 net.cpp:137] Memory required for data: 525518000
I1007 22:17:02.813007  5322 layer_factory.hpp:77] Creating layer Scale19
I1007 22:17:02.813014  5322 net.cpp:84] Creating Layer Scale19
I1007 22:17:02.813019  5322 net.cpp:406] Scale19 <- Convolution19
I1007 22:17:02.813024  5322 net.cpp:367] Scale19 -> Convolution19 (in-place)
I1007 22:17:02.813063  5322 layer_factory.hpp:77] Creating layer Scale19
I1007 22:17:02.813153  5322 net.cpp:122] Setting up Scale19
I1007 22:17:02.813158  5322 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:17:02.813161  5322 net.cpp:137] Memory required for data: 528794800
I1007 22:17:02.813169  5322 layer_factory.hpp:77] Creating layer elu18
I1007 22:17:02.813174  5322 net.cpp:84] Creating Layer elu18
I1007 22:17:02.813177  5322 net.cpp:406] elu18 <- Convolution19
I1007 22:17:02.813182  5322 net.cpp:367] elu18 -> Convolution19 (in-place)
I1007 22:17:02.813189  5322 net.cpp:122] Setting up elu18
I1007 22:17:02.813194  5322 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:17:02.813197  5322 net.cpp:137] Memory required for data: 532071600
I1007 22:17:02.813201  5322 layer_factory.hpp:77] Creating layer Convolution20
I1007 22:17:02.813210  5322 net.cpp:84] Creating Layer Convolution20
I1007 22:17:02.813215  5322 net.cpp:406] Convolution20 <- Convolution19
I1007 22:17:02.813220  5322 net.cpp:380] Convolution20 -> Convolution20
I1007 22:17:02.825891  5322 net.cpp:122] Setting up Convolution20
I1007 22:17:02.825901  5322 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:17:02.825903  5322 net.cpp:137] Memory required for data: 535348400
I1007 22:17:02.825909  5322 layer_factory.hpp:77] Creating layer BatchNorm20
I1007 22:17:02.825917  5322 net.cpp:84] Creating Layer BatchNorm20
I1007 22:17:02.825922  5322 net.cpp:406] BatchNorm20 <- Convolution20
I1007 22:17:02.825927  5322 net.cpp:367] BatchNorm20 -> Convolution20 (in-place)
I1007 22:17:02.826076  5322 net.cpp:122] Setting up BatchNorm20
I1007 22:17:02.826081  5322 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:17:02.826083  5322 net.cpp:137] Memory required for data: 538625200
I1007 22:17:02.826092  5322 layer_factory.hpp:77] Creating layer Scale20
I1007 22:17:02.826097  5322 net.cpp:84] Creating Layer Scale20
I1007 22:17:02.826102  5322 net.cpp:406] Scale20 <- Convolution20
I1007 22:17:02.826107  5322 net.cpp:367] Scale20 -> Convolution20 (in-place)
I1007 22:17:02.826140  5322 layer_factory.hpp:77] Creating layer Scale20
I1007 22:17:02.826228  5322 net.cpp:122] Setting up Scale20
I1007 22:17:02.826234  5322 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:17:02.826236  5322 net.cpp:137] Memory required for data: 541902000
I1007 22:17:02.826243  5322 layer_factory.hpp:77] Creating layer Eltwise9
I1007 22:17:02.826251  5322 net.cpp:84] Creating Layer Eltwise9
I1007 22:17:02.826256  5322 net.cpp:406] Eltwise9 <- Eltwise8_elu17_0_split_1
I1007 22:17:02.826258  5322 net.cpp:406] Eltwise9 <- Convolution20
I1007 22:17:02.826263  5322 net.cpp:380] Eltwise9 -> Eltwise9
I1007 22:17:02.826283  5322 net.cpp:122] Setting up Eltwise9
I1007 22:17:02.826288  5322 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:17:02.826292  5322 net.cpp:137] Memory required for data: 545178800
I1007 22:17:02.826295  5322 layer_factory.hpp:77] Creating layer elu19
I1007 22:17:02.826301  5322 net.cpp:84] Creating Layer elu19
I1007 22:17:02.826313  5322 net.cpp:406] elu19 <- Eltwise9
I1007 22:17:02.826319  5322 net.cpp:367] elu19 -> Eltwise9 (in-place)
I1007 22:17:02.826325  5322 net.cpp:122] Setting up elu19
I1007 22:17:02.826330  5322 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:17:02.826333  5322 net.cpp:137] Memory required for data: 548455600
I1007 22:17:02.826339  5322 layer_factory.hpp:77] Creating layer Eltwise9_elu19_0_split
I1007 22:17:02.826344  5322 net.cpp:84] Creating Layer Eltwise9_elu19_0_split
I1007 22:17:02.826347  5322 net.cpp:406] Eltwise9_elu19_0_split <- Eltwise9
I1007 22:17:02.826354  5322 net.cpp:380] Eltwise9_elu19_0_split -> Eltwise9_elu19_0_split_0
I1007 22:17:02.826359  5322 net.cpp:380] Eltwise9_elu19_0_split -> Eltwise9_elu19_0_split_1
I1007 22:17:02.826390  5322 net.cpp:122] Setting up Eltwise9_elu19_0_split
I1007 22:17:02.826395  5322 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:17:02.826400  5322 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:17:02.826403  5322 net.cpp:137] Memory required for data: 555009200
I1007 22:17:02.826406  5322 layer_factory.hpp:77] Creating layer Convolution21
I1007 22:17:02.826416  5322 net.cpp:84] Creating Layer Convolution21
I1007 22:17:02.826421  5322 net.cpp:406] Convolution21 <- Eltwise9_elu19_0_split_0
I1007 22:17:02.826426  5322 net.cpp:380] Convolution21 -> Convolution21
I1007 22:17:02.838954  5322 net.cpp:122] Setting up Convolution21
I1007 22:17:02.838965  5322 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:17:02.838968  5322 net.cpp:137] Memory required for data: 558286000
I1007 22:17:02.838976  5322 layer_factory.hpp:77] Creating layer BatchNorm21
I1007 22:17:02.838985  5322 net.cpp:84] Creating Layer BatchNorm21
I1007 22:17:02.838991  5322 net.cpp:406] BatchNorm21 <- Convolution21
I1007 22:17:02.838999  5322 net.cpp:367] BatchNorm21 -> Convolution21 (in-place)
I1007 22:17:02.839156  5322 net.cpp:122] Setting up BatchNorm21
I1007 22:17:02.839166  5322 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:17:02.839171  5322 net.cpp:137] Memory required for data: 561562800
I1007 22:17:02.839180  5322 layer_factory.hpp:77] Creating layer Scale21
I1007 22:17:02.839187  5322 net.cpp:84] Creating Layer Scale21
I1007 22:17:02.839192  5322 net.cpp:406] Scale21 <- Convolution21
I1007 22:17:02.839195  5322 net.cpp:367] Scale21 -> Convolution21 (in-place)
I1007 22:17:02.839233  5322 layer_factory.hpp:77] Creating layer Scale21
I1007 22:17:02.839334  5322 net.cpp:122] Setting up Scale21
I1007 22:17:02.839340  5322 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:17:02.839342  5322 net.cpp:137] Memory required for data: 564839600
I1007 22:17:02.839349  5322 layer_factory.hpp:77] Creating layer elu20
I1007 22:17:02.839365  5322 net.cpp:84] Creating Layer elu20
I1007 22:17:02.839367  5322 net.cpp:406] elu20 <- Convolution21
I1007 22:17:02.839375  5322 net.cpp:367] elu20 -> Convolution21 (in-place)
I1007 22:17:02.839381  5322 net.cpp:122] Setting up elu20
I1007 22:17:02.839385  5322 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:17:02.839390  5322 net.cpp:137] Memory required for data: 568116400
I1007 22:17:02.839392  5322 layer_factory.hpp:77] Creating layer Convolution22
I1007 22:17:02.839399  5322 net.cpp:84] Creating Layer Convolution22
I1007 22:17:02.839403  5322 net.cpp:406] Convolution22 <- Convolution21
I1007 22:17:02.839406  5322 net.cpp:380] Convolution22 -> Convolution22
I1007 22:17:02.851274  5322 net.cpp:122] Setting up Convolution22
I1007 22:17:02.851284  5322 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:17:02.851287  5322 net.cpp:137] Memory required for data: 571393200
I1007 22:17:02.851301  5322 layer_factory.hpp:77] Creating layer BatchNorm22
I1007 22:17:02.851308  5322 net.cpp:84] Creating Layer BatchNorm22
I1007 22:17:02.851315  5322 net.cpp:406] BatchNorm22 <- Convolution22
I1007 22:17:02.851320  5322 net.cpp:367] BatchNorm22 -> Convolution22 (in-place)
I1007 22:17:02.851480  5322 net.cpp:122] Setting up BatchNorm22
I1007 22:17:02.851486  5322 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:17:02.851507  5322 net.cpp:137] Memory required for data: 574670000
I1007 22:17:02.851513  5322 layer_factory.hpp:77] Creating layer Scale22
I1007 22:17:02.851518  5322 net.cpp:84] Creating Layer Scale22
I1007 22:17:02.851521  5322 net.cpp:406] Scale22 <- Convolution22
I1007 22:17:02.851526  5322 net.cpp:367] Scale22 -> Convolution22 (in-place)
I1007 22:17:02.851562  5322 layer_factory.hpp:77] Creating layer Scale22
I1007 22:17:02.851655  5322 net.cpp:122] Setting up Scale22
I1007 22:17:02.851661  5322 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:17:02.851663  5322 net.cpp:137] Memory required for data: 577946800
I1007 22:17:02.851670  5322 layer_factory.hpp:77] Creating layer Eltwise10
I1007 22:17:02.851676  5322 net.cpp:84] Creating Layer Eltwise10
I1007 22:17:02.851680  5322 net.cpp:406] Eltwise10 <- Eltwise9_elu19_0_split_1
I1007 22:17:02.851685  5322 net.cpp:406] Eltwise10 <- Convolution22
I1007 22:17:02.851693  5322 net.cpp:380] Eltwise10 -> Eltwise10
I1007 22:17:02.851713  5322 net.cpp:122] Setting up Eltwise10
I1007 22:17:02.851718  5322 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:17:02.851721  5322 net.cpp:137] Memory required for data: 581223600
I1007 22:17:02.851724  5322 layer_factory.hpp:77] Creating layer elu21
I1007 22:17:02.851732  5322 net.cpp:84] Creating Layer elu21
I1007 22:17:02.851735  5322 net.cpp:406] elu21 <- Eltwise10
I1007 22:17:02.851739  5322 net.cpp:367] elu21 -> Eltwise10 (in-place)
I1007 22:17:02.851745  5322 net.cpp:122] Setting up elu21
I1007 22:17:02.851750  5322 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:17:02.851753  5322 net.cpp:137] Memory required for data: 584500400
I1007 22:17:02.851758  5322 layer_factory.hpp:77] Creating layer Eltwise10_elu21_0_split
I1007 22:17:02.851763  5322 net.cpp:84] Creating Layer Eltwise10_elu21_0_split
I1007 22:17:02.851768  5322 net.cpp:406] Eltwise10_elu21_0_split <- Eltwise10
I1007 22:17:02.851773  5322 net.cpp:380] Eltwise10_elu21_0_split -> Eltwise10_elu21_0_split_0
I1007 22:17:02.851779  5322 net.cpp:380] Eltwise10_elu21_0_split -> Eltwise10_elu21_0_split_1
I1007 22:17:02.851811  5322 net.cpp:122] Setting up Eltwise10_elu21_0_split
I1007 22:17:02.851816  5322 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:17:02.851820  5322 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:17:02.851824  5322 net.cpp:137] Memory required for data: 591054000
I1007 22:17:02.851827  5322 layer_factory.hpp:77] Creating layer Convolution23
I1007 22:17:02.851838  5322 net.cpp:84] Creating Layer Convolution23
I1007 22:17:02.851841  5322 net.cpp:406] Convolution23 <- Eltwise10_elu21_0_split_0
I1007 22:17:02.851847  5322 net.cpp:380] Convolution23 -> Convolution23
I1007 22:17:02.857928  5322 net.cpp:122] Setting up Convolution23
I1007 22:17:02.857939  5322 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:17:02.857942  5322 net.cpp:137] Memory required for data: 592692400
I1007 22:17:02.857949  5322 layer_factory.hpp:77] Creating layer BatchNorm23
I1007 22:17:02.857957  5322 net.cpp:84] Creating Layer BatchNorm23
I1007 22:17:02.857962  5322 net.cpp:406] BatchNorm23 <- Convolution23
I1007 22:17:02.857967  5322 net.cpp:367] BatchNorm23 -> Convolution23 (in-place)
I1007 22:17:02.858126  5322 net.cpp:122] Setting up BatchNorm23
I1007 22:17:02.858134  5322 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:17:02.858136  5322 net.cpp:137] Memory required for data: 594330800
I1007 22:17:02.858144  5322 layer_factory.hpp:77] Creating layer Scale23
I1007 22:17:02.858150  5322 net.cpp:84] Creating Layer Scale23
I1007 22:17:02.858155  5322 net.cpp:406] Scale23 <- Convolution23
I1007 22:17:02.858160  5322 net.cpp:367] Scale23 -> Convolution23 (in-place)
I1007 22:17:02.858196  5322 layer_factory.hpp:77] Creating layer Scale23
I1007 22:17:02.858286  5322 net.cpp:122] Setting up Scale23
I1007 22:17:02.858292  5322 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:17:02.858295  5322 net.cpp:137] Memory required for data: 595969200
I1007 22:17:02.858301  5322 layer_factory.hpp:77] Creating layer Convolution24
I1007 22:17:02.858312  5322 net.cpp:84] Creating Layer Convolution24
I1007 22:17:02.858324  5322 net.cpp:406] Convolution24 <- Eltwise10_elu21_0_split_1
I1007 22:17:02.858331  5322 net.cpp:380] Convolution24 -> Convolution24
I1007 22:17:02.868854  5322 net.cpp:122] Setting up Convolution24
I1007 22:17:02.868865  5322 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:17:02.868868  5322 net.cpp:137] Memory required for data: 597607600
I1007 22:17:02.868876  5322 layer_factory.hpp:77] Creating layer BatchNorm24
I1007 22:17:02.868885  5322 net.cpp:84] Creating Layer BatchNorm24
I1007 22:17:02.868891  5322 net.cpp:406] BatchNorm24 <- Convolution24
I1007 22:17:02.868896  5322 net.cpp:367] BatchNorm24 -> Convolution24 (in-place)
I1007 22:17:02.869052  5322 net.cpp:122] Setting up BatchNorm24
I1007 22:17:02.869058  5322 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:17:02.869061  5322 net.cpp:137] Memory required for data: 599246000
I1007 22:17:02.869069  5322 layer_factory.hpp:77] Creating layer Scale24
I1007 22:17:02.869076  5322 net.cpp:84] Creating Layer Scale24
I1007 22:17:02.869079  5322 net.cpp:406] Scale24 <- Convolution24
I1007 22:17:02.869084  5322 net.cpp:367] Scale24 -> Convolution24 (in-place)
I1007 22:17:02.869122  5322 layer_factory.hpp:77] Creating layer Scale24
I1007 22:17:02.869222  5322 net.cpp:122] Setting up Scale24
I1007 22:17:02.869230  5322 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:17:02.869232  5322 net.cpp:137] Memory required for data: 600884400
I1007 22:17:02.869248  5322 layer_factory.hpp:77] Creating layer elu22
I1007 22:17:02.869252  5322 net.cpp:84] Creating Layer elu22
I1007 22:17:02.869256  5322 net.cpp:406] elu22 <- Convolution24
I1007 22:17:02.869258  5322 net.cpp:367] elu22 -> Convolution24 (in-place)
I1007 22:17:02.869262  5322 net.cpp:122] Setting up elu22
I1007 22:17:02.869266  5322 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:17:02.869268  5322 net.cpp:137] Memory required for data: 602522800
I1007 22:17:02.869271  5322 layer_factory.hpp:77] Creating layer Convolution25
I1007 22:17:02.869277  5322 net.cpp:84] Creating Layer Convolution25
I1007 22:17:02.869279  5322 net.cpp:406] Convolution25 <- Convolution24
I1007 22:17:02.869284  5322 net.cpp:380] Convolution25 -> Convolution25
I1007 22:17:02.882506  5322 net.cpp:122] Setting up Convolution25
I1007 22:17:02.882516  5322 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:17:02.882519  5322 net.cpp:137] Memory required for data: 604161200
I1007 22:17:02.882527  5322 layer_factory.hpp:77] Creating layer BatchNorm25
I1007 22:17:02.882546  5322 net.cpp:84] Creating Layer BatchNorm25
I1007 22:17:02.882550  5322 net.cpp:406] BatchNorm25 <- Convolution25
I1007 22:17:02.882555  5322 net.cpp:367] BatchNorm25 -> Convolution25 (in-place)
I1007 22:17:02.882714  5322 net.cpp:122] Setting up BatchNorm25
I1007 22:17:02.882720  5322 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:17:02.882724  5322 net.cpp:137] Memory required for data: 605799600
I1007 22:17:02.882728  5322 layer_factory.hpp:77] Creating layer Scale25
I1007 22:17:02.882736  5322 net.cpp:84] Creating Layer Scale25
I1007 22:17:02.882742  5322 net.cpp:406] Scale25 <- Convolution25
I1007 22:17:02.882746  5322 net.cpp:367] Scale25 -> Convolution25 (in-place)
I1007 22:17:02.882782  5322 layer_factory.hpp:77] Creating layer Scale25
I1007 22:17:02.882872  5322 net.cpp:122] Setting up Scale25
I1007 22:17:02.882877  5322 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:17:02.882880  5322 net.cpp:137] Memory required for data: 607438000
I1007 22:17:02.882884  5322 layer_factory.hpp:77] Creating layer Eltwise11
I1007 22:17:02.882889  5322 net.cpp:84] Creating Layer Eltwise11
I1007 22:17:02.882894  5322 net.cpp:406] Eltwise11 <- Convolution23
I1007 22:17:02.882899  5322 net.cpp:406] Eltwise11 <- Convolution25
I1007 22:17:02.882905  5322 net.cpp:380] Eltwise11 -> Eltwise11
I1007 22:17:02.882927  5322 net.cpp:122] Setting up Eltwise11
I1007 22:17:02.882932  5322 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:17:02.882935  5322 net.cpp:137] Memory required for data: 609076400
I1007 22:17:02.882949  5322 layer_factory.hpp:77] Creating layer elu23
I1007 22:17:02.882954  5322 net.cpp:84] Creating Layer elu23
I1007 22:17:02.882956  5322 net.cpp:406] elu23 <- Eltwise11
I1007 22:17:02.882961  5322 net.cpp:367] elu23 -> Eltwise11 (in-place)
I1007 22:17:02.882966  5322 net.cpp:122] Setting up elu23
I1007 22:17:02.882969  5322 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:17:02.882972  5322 net.cpp:137] Memory required for data: 610714800
I1007 22:17:02.882974  5322 layer_factory.hpp:77] Creating layer Eltwise11_elu23_0_split
I1007 22:17:02.882977  5322 net.cpp:84] Creating Layer Eltwise11_elu23_0_split
I1007 22:17:02.882980  5322 net.cpp:406] Eltwise11_elu23_0_split <- Eltwise11
I1007 22:17:02.882983  5322 net.cpp:380] Eltwise11_elu23_0_split -> Eltwise11_elu23_0_split_0
I1007 22:17:02.882987  5322 net.cpp:380] Eltwise11_elu23_0_split -> Eltwise11_elu23_0_split_1
I1007 22:17:02.883016  5322 net.cpp:122] Setting up Eltwise11_elu23_0_split
I1007 22:17:02.883021  5322 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:17:02.883024  5322 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:17:02.883026  5322 net.cpp:137] Memory required for data: 613991600
I1007 22:17:02.883028  5322 layer_factory.hpp:77] Creating layer Convolution26
I1007 22:17:02.883034  5322 net.cpp:84] Creating Layer Convolution26
I1007 22:17:02.883038  5322 net.cpp:406] Convolution26 <- Eltwise11_elu23_0_split_0
I1007 22:17:02.883043  5322 net.cpp:380] Convolution26 -> Convolution26
I1007 22:17:02.895638  5322 net.cpp:122] Setting up Convolution26
I1007 22:17:02.895650  5322 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:17:02.895653  5322 net.cpp:137] Memory required for data: 615630000
I1007 22:17:02.895658  5322 layer_factory.hpp:77] Creating layer BatchNorm26
I1007 22:17:02.895664  5322 net.cpp:84] Creating Layer BatchNorm26
I1007 22:17:02.895668  5322 net.cpp:406] BatchNorm26 <- Convolution26
I1007 22:17:02.895671  5322 net.cpp:367] BatchNorm26 -> Convolution26 (in-place)
I1007 22:17:02.895825  5322 net.cpp:122] Setting up BatchNorm26
I1007 22:17:02.895830  5322 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:17:02.895833  5322 net.cpp:137] Memory required for data: 617268400
I1007 22:17:02.895838  5322 layer_factory.hpp:77] Creating layer Scale26
I1007 22:17:02.895843  5322 net.cpp:84] Creating Layer Scale26
I1007 22:17:02.895846  5322 net.cpp:406] Scale26 <- Convolution26
I1007 22:17:02.895850  5322 net.cpp:367] Scale26 -> Convolution26 (in-place)
I1007 22:17:02.895881  5322 layer_factory.hpp:77] Creating layer Scale26
I1007 22:17:02.895970  5322 net.cpp:122] Setting up Scale26
I1007 22:17:02.895975  5322 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:17:02.895977  5322 net.cpp:137] Memory required for data: 618906800
I1007 22:17:02.895982  5322 layer_factory.hpp:77] Creating layer elu24
I1007 22:17:02.895985  5322 net.cpp:84] Creating Layer elu24
I1007 22:17:02.895988  5322 net.cpp:406] elu24 <- Convolution26
I1007 22:17:02.895992  5322 net.cpp:367] elu24 -> Convolution26 (in-place)
I1007 22:17:02.895995  5322 net.cpp:122] Setting up elu24
I1007 22:17:02.895999  5322 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:17:02.896001  5322 net.cpp:137] Memory required for data: 620545200
I1007 22:17:02.896004  5322 layer_factory.hpp:77] Creating layer Convolution27
I1007 22:17:02.896014  5322 net.cpp:84] Creating Layer Convolution27
I1007 22:17:02.896018  5322 net.cpp:406] Convolution27 <- Convolution26
I1007 22:17:02.896023  5322 net.cpp:380] Convolution27 -> Convolution27
I1007 22:17:02.909315  5322 net.cpp:122] Setting up Convolution27
I1007 22:17:02.909327  5322 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:17:02.909328  5322 net.cpp:137] Memory required for data: 622183600
I1007 22:17:02.909343  5322 layer_factory.hpp:77] Creating layer BatchNorm27
I1007 22:17:02.909376  5322 net.cpp:84] Creating Layer BatchNorm27
I1007 22:17:02.909384  5322 net.cpp:406] BatchNorm27 <- Convolution27
I1007 22:17:02.909402  5322 net.cpp:367] BatchNorm27 -> Convolution27 (in-place)
I1007 22:17:02.909576  5322 net.cpp:122] Setting up BatchNorm27
I1007 22:17:02.909590  5322 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:17:02.909593  5322 net.cpp:137] Memory required for data: 623822000
I1007 22:17:02.909611  5322 layer_factory.hpp:77] Creating layer Scale27
I1007 22:17:02.909620  5322 net.cpp:84] Creating Layer Scale27
I1007 22:17:02.909634  5322 net.cpp:406] Scale27 <- Convolution27
I1007 22:17:02.909638  5322 net.cpp:367] Scale27 -> Convolution27 (in-place)
I1007 22:17:02.909706  5322 layer_factory.hpp:77] Creating layer Scale27
I1007 22:17:02.909822  5322 net.cpp:122] Setting up Scale27
I1007 22:17:02.909829  5322 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:17:02.909832  5322 net.cpp:137] Memory required for data: 625460400
I1007 22:17:02.909840  5322 layer_factory.hpp:77] Creating layer Eltwise12
I1007 22:17:02.909848  5322 net.cpp:84] Creating Layer Eltwise12
I1007 22:17:02.909854  5322 net.cpp:406] Eltwise12 <- Eltwise11_elu23_0_split_1
I1007 22:17:02.909862  5322 net.cpp:406] Eltwise12 <- Convolution27
I1007 22:17:02.909869  5322 net.cpp:380] Eltwise12 -> Eltwise12
I1007 22:17:02.909895  5322 net.cpp:122] Setting up Eltwise12
I1007 22:17:02.909900  5322 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:17:02.909903  5322 net.cpp:137] Memory required for data: 627098800
I1007 22:17:02.909905  5322 layer_factory.hpp:77] Creating layer elu25
I1007 22:17:02.909910  5322 net.cpp:84] Creating Layer elu25
I1007 22:17:02.909912  5322 net.cpp:406] elu25 <- Eltwise12
I1007 22:17:02.909915  5322 net.cpp:367] elu25 -> Eltwise12 (in-place)
I1007 22:17:02.909919  5322 net.cpp:122] Setting up elu25
I1007 22:17:02.909924  5322 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:17:02.909925  5322 net.cpp:137] Memory required for data: 628737200
I1007 22:17:02.909927  5322 layer_factory.hpp:77] Creating layer Eltwise12_elu25_0_split
I1007 22:17:02.909931  5322 net.cpp:84] Creating Layer Eltwise12_elu25_0_split
I1007 22:17:02.909934  5322 net.cpp:406] Eltwise12_elu25_0_split <- Eltwise12
I1007 22:17:02.909936  5322 net.cpp:380] Eltwise12_elu25_0_split -> Eltwise12_elu25_0_split_0
I1007 22:17:02.909940  5322 net.cpp:380] Eltwise12_elu25_0_split -> Eltwise12_elu25_0_split_1
I1007 22:17:02.909967  5322 net.cpp:122] Setting up Eltwise12_elu25_0_split
I1007 22:17:02.909972  5322 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:17:02.909976  5322 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:17:02.909977  5322 net.cpp:137] Memory required for data: 632014000
I1007 22:17:02.909979  5322 layer_factory.hpp:77] Creating layer Convolution28
I1007 22:17:02.909986  5322 net.cpp:84] Creating Layer Convolution28
I1007 22:17:02.909991  5322 net.cpp:406] Convolution28 <- Eltwise12_elu25_0_split_0
I1007 22:17:02.909994  5322 net.cpp:380] Convolution28 -> Convolution28
I1007 22:17:02.918546  5322 net.cpp:122] Setting up Convolution28
I1007 22:17:02.918556  5322 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:17:02.918560  5322 net.cpp:137] Memory required for data: 633652400
I1007 22:17:02.918565  5322 layer_factory.hpp:77] Creating layer BatchNorm28
I1007 22:17:02.918570  5322 net.cpp:84] Creating Layer BatchNorm28
I1007 22:17:02.918575  5322 net.cpp:406] BatchNorm28 <- Convolution28
I1007 22:17:02.918578  5322 net.cpp:367] BatchNorm28 -> Convolution28 (in-place)
I1007 22:17:02.918736  5322 net.cpp:122] Setting up BatchNorm28
I1007 22:17:02.918742  5322 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:17:02.918745  5322 net.cpp:137] Memory required for data: 635290800
I1007 22:17:02.918750  5322 layer_factory.hpp:77] Creating layer Scale28
I1007 22:17:02.918754  5322 net.cpp:84] Creating Layer Scale28
I1007 22:17:02.918757  5322 net.cpp:406] Scale28 <- Convolution28
I1007 22:17:02.918761  5322 net.cpp:367] Scale28 -> Convolution28 (in-place)
I1007 22:17:02.918792  5322 layer_factory.hpp:77] Creating layer Scale28
I1007 22:17:02.918884  5322 net.cpp:122] Setting up Scale28
I1007 22:17:02.918889  5322 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:17:02.918890  5322 net.cpp:137] Memory required for data: 636929200
I1007 22:17:02.918902  5322 layer_factory.hpp:77] Creating layer elu26
I1007 22:17:02.918907  5322 net.cpp:84] Creating Layer elu26
I1007 22:17:02.918910  5322 net.cpp:406] elu26 <- Convolution28
I1007 22:17:02.918913  5322 net.cpp:367] elu26 -> Convolution28 (in-place)
I1007 22:17:02.918917  5322 net.cpp:122] Setting up elu26
I1007 22:17:02.918920  5322 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:17:02.918922  5322 net.cpp:137] Memory required for data: 638567600
I1007 22:17:02.918926  5322 layer_factory.hpp:77] Creating layer Convolution29
I1007 22:17:02.918931  5322 net.cpp:84] Creating Layer Convolution29
I1007 22:17:02.918934  5322 net.cpp:406] Convolution29 <- Convolution28
I1007 22:17:02.918939  5322 net.cpp:380] Convolution29 -> Convolution29
I1007 22:17:02.924932  5322 net.cpp:122] Setting up Convolution29
I1007 22:17:02.924942  5322 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:17:02.924945  5322 net.cpp:137] Memory required for data: 640206000
I1007 22:17:02.924950  5322 layer_factory.hpp:77] Creating layer BatchNorm29
I1007 22:17:02.924957  5322 net.cpp:84] Creating Layer BatchNorm29
I1007 22:17:02.924960  5322 net.cpp:406] BatchNorm29 <- Convolution29
I1007 22:17:02.924964  5322 net.cpp:367] BatchNorm29 -> Convolution29 (in-place)
I1007 22:17:02.925123  5322 net.cpp:122] Setting up BatchNorm29
I1007 22:17:02.925129  5322 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:17:02.925132  5322 net.cpp:137] Memory required for data: 641844400
I1007 22:17:02.925137  5322 layer_factory.hpp:77] Creating layer Scale29
I1007 22:17:02.925142  5322 net.cpp:84] Creating Layer Scale29
I1007 22:17:02.925144  5322 net.cpp:406] Scale29 <- Convolution29
I1007 22:17:02.925148  5322 net.cpp:367] Scale29 -> Convolution29 (in-place)
I1007 22:17:02.925180  5322 layer_factory.hpp:77] Creating layer Scale29
I1007 22:17:02.925271  5322 net.cpp:122] Setting up Scale29
I1007 22:17:02.925277  5322 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:17:02.925279  5322 net.cpp:137] Memory required for data: 643482800
I1007 22:17:02.925283  5322 layer_factory.hpp:77] Creating layer Eltwise13
I1007 22:17:02.925288  5322 net.cpp:84] Creating Layer Eltwise13
I1007 22:17:02.925290  5322 net.cpp:406] Eltwise13 <- Eltwise12_elu25_0_split_1
I1007 22:17:02.925294  5322 net.cpp:406] Eltwise13 <- Convolution29
I1007 22:17:02.925297  5322 net.cpp:380] Eltwise13 -> Eltwise13
I1007 22:17:02.925318  5322 net.cpp:122] Setting up Eltwise13
I1007 22:17:02.925323  5322 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:17:02.925324  5322 net.cpp:137] Memory required for data: 645121200
I1007 22:17:02.925328  5322 layer_factory.hpp:77] Creating layer elu27
I1007 22:17:02.925330  5322 net.cpp:84] Creating Layer elu27
I1007 22:17:02.925333  5322 net.cpp:406] elu27 <- Eltwise13
I1007 22:17:02.925336  5322 net.cpp:367] elu27 -> Eltwise13 (in-place)
I1007 22:17:02.925340  5322 net.cpp:122] Setting up elu27
I1007 22:17:02.925344  5322 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:17:02.925346  5322 net.cpp:137] Memory required for data: 646759600
I1007 22:17:02.925348  5322 layer_factory.hpp:77] Creating layer Eltwise13_elu27_0_split
I1007 22:17:02.925353  5322 net.cpp:84] Creating Layer Eltwise13_elu27_0_split
I1007 22:17:02.925354  5322 net.cpp:406] Eltwise13_elu27_0_split <- Eltwise13
I1007 22:17:02.925357  5322 net.cpp:380] Eltwise13_elu27_0_split -> Eltwise13_elu27_0_split_0
I1007 22:17:02.925361  5322 net.cpp:380] Eltwise13_elu27_0_split -> Eltwise13_elu27_0_split_1
I1007 22:17:02.925388  5322 net.cpp:122] Setting up Eltwise13_elu27_0_split
I1007 22:17:02.925393  5322 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:17:02.925396  5322 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:17:02.925398  5322 net.cpp:137] Memory required for data: 650036400
I1007 22:17:02.925400  5322 layer_factory.hpp:77] Creating layer Convolution30
I1007 22:17:02.925407  5322 net.cpp:84] Creating Layer Convolution30
I1007 22:17:02.925410  5322 net.cpp:406] Convolution30 <- Eltwise13_elu27_0_split_0
I1007 22:17:02.925415  5322 net.cpp:380] Convolution30 -> Convolution30
I1007 22:17:02.932562  5322 net.cpp:122] Setting up Convolution30
I1007 22:17:02.932575  5322 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:17:02.932579  5322 net.cpp:137] Memory required for data: 651674800
I1007 22:17:02.932595  5322 layer_factory.hpp:77] Creating layer BatchNorm30
I1007 22:17:02.932610  5322 net.cpp:84] Creating Layer BatchNorm30
I1007 22:17:02.932615  5322 net.cpp:406] BatchNorm30 <- Convolution30
I1007 22:17:02.932621  5322 net.cpp:367] BatchNorm30 -> Convolution30 (in-place)
I1007 22:17:02.932792  5322 net.cpp:122] Setting up BatchNorm30
I1007 22:17:02.932798  5322 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:17:02.932801  5322 net.cpp:137] Memory required for data: 653313200
I1007 22:17:02.932816  5322 layer_factory.hpp:77] Creating layer Scale30
I1007 22:17:02.932821  5322 net.cpp:84] Creating Layer Scale30
I1007 22:17:02.932823  5322 net.cpp:406] Scale30 <- Convolution30
I1007 22:17:02.932826  5322 net.cpp:367] Scale30 -> Convolution30 (in-place)
I1007 22:17:02.932864  5322 layer_factory.hpp:77] Creating layer Scale30
I1007 22:17:02.932957  5322 net.cpp:122] Setting up Scale30
I1007 22:17:02.932963  5322 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:17:02.932965  5322 net.cpp:137] Memory required for data: 654951600
I1007 22:17:02.932970  5322 layer_factory.hpp:77] Creating layer elu28
I1007 22:17:02.932973  5322 net.cpp:84] Creating Layer elu28
I1007 22:17:02.932976  5322 net.cpp:406] elu28 <- Convolution30
I1007 22:17:02.932979  5322 net.cpp:367] elu28 -> Convolution30 (in-place)
I1007 22:17:02.932983  5322 net.cpp:122] Setting up elu28
I1007 22:17:02.932986  5322 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:17:02.932988  5322 net.cpp:137] Memory required for data: 656590000
I1007 22:17:02.932991  5322 layer_factory.hpp:77] Creating layer Convolution31
I1007 22:17:02.932998  5322 net.cpp:84] Creating Layer Convolution31
I1007 22:17:02.933001  5322 net.cpp:406] Convolution31 <- Convolution30
I1007 22:17:02.933007  5322 net.cpp:380] Convolution31 -> Convolution31
I1007 22:17:02.939045  5322 net.cpp:122] Setting up Convolution31
I1007 22:17:02.939056  5322 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:17:02.939059  5322 net.cpp:137] Memory required for data: 658228400
I1007 22:17:02.939064  5322 layer_factory.hpp:77] Creating layer BatchNorm31
I1007 22:17:02.939070  5322 net.cpp:84] Creating Layer BatchNorm31
I1007 22:17:02.939074  5322 net.cpp:406] BatchNorm31 <- Convolution31
I1007 22:17:02.939079  5322 net.cpp:367] BatchNorm31 -> Convolution31 (in-place)
I1007 22:17:02.939242  5322 net.cpp:122] Setting up BatchNorm31
I1007 22:17:02.939249  5322 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:17:02.939251  5322 net.cpp:137] Memory required for data: 659866800
I1007 22:17:02.939256  5322 layer_factory.hpp:77] Creating layer Scale31
I1007 22:17:02.939261  5322 net.cpp:84] Creating Layer Scale31
I1007 22:17:02.939265  5322 net.cpp:406] Scale31 <- Convolution31
I1007 22:17:02.939267  5322 net.cpp:367] Scale31 -> Convolution31 (in-place)
I1007 22:17:02.939299  5322 layer_factory.hpp:77] Creating layer Scale31
I1007 22:17:02.939391  5322 net.cpp:122] Setting up Scale31
I1007 22:17:02.939396  5322 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:17:02.939399  5322 net.cpp:137] Memory required for data: 661505200
I1007 22:17:02.939402  5322 layer_factory.hpp:77] Creating layer Eltwise14
I1007 22:17:02.939407  5322 net.cpp:84] Creating Layer Eltwise14
I1007 22:17:02.939410  5322 net.cpp:406] Eltwise14 <- Eltwise13_elu27_0_split_1
I1007 22:17:02.939414  5322 net.cpp:406] Eltwise14 <- Convolution31
I1007 22:17:02.939417  5322 net.cpp:380] Eltwise14 -> Eltwise14
I1007 22:17:02.939436  5322 net.cpp:122] Setting up Eltwise14
I1007 22:17:02.939441  5322 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:17:02.939443  5322 net.cpp:137] Memory required for data: 663143600
I1007 22:17:02.939445  5322 layer_factory.hpp:77] Creating layer elu29
I1007 22:17:02.939450  5322 net.cpp:84] Creating Layer elu29
I1007 22:17:02.939452  5322 net.cpp:406] elu29 <- Eltwise14
I1007 22:17:02.939465  5322 net.cpp:367] elu29 -> Eltwise14 (in-place)
I1007 22:17:02.939471  5322 net.cpp:122] Setting up elu29
I1007 22:17:02.939473  5322 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:17:02.939476  5322 net.cpp:137] Memory required for data: 664782000
I1007 22:17:02.939478  5322 layer_factory.hpp:77] Creating layer Eltwise14_elu29_0_split
I1007 22:17:02.939482  5322 net.cpp:84] Creating Layer Eltwise14_elu29_0_split
I1007 22:17:02.939484  5322 net.cpp:406] Eltwise14_elu29_0_split <- Eltwise14
I1007 22:17:02.939487  5322 net.cpp:380] Eltwise14_elu29_0_split -> Eltwise14_elu29_0_split_0
I1007 22:17:02.939491  5322 net.cpp:380] Eltwise14_elu29_0_split -> Eltwise14_elu29_0_split_1
I1007 22:17:02.939519  5322 net.cpp:122] Setting up Eltwise14_elu29_0_split
I1007 22:17:02.939524  5322 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:17:02.939527  5322 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:17:02.939529  5322 net.cpp:137] Memory required for data: 668058800
I1007 22:17:02.939532  5322 layer_factory.hpp:77] Creating layer Convolution32
I1007 22:17:02.939538  5322 net.cpp:84] Creating Layer Convolution32
I1007 22:17:02.939541  5322 net.cpp:406] Convolution32 <- Eltwise14_elu29_0_split_0
I1007 22:17:02.939546  5322 net.cpp:380] Convolution32 -> Convolution32
I1007 22:17:02.946075  5322 net.cpp:122] Setting up Convolution32
I1007 22:17:02.946086  5322 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:17:02.946089  5322 net.cpp:137] Memory required for data: 669697200
I1007 22:17:02.946094  5322 layer_factory.hpp:77] Creating layer BatchNorm32
I1007 22:17:02.946099  5322 net.cpp:84] Creating Layer BatchNorm32
I1007 22:17:02.946104  5322 net.cpp:406] BatchNorm32 <- Convolution32
I1007 22:17:02.946107  5322 net.cpp:367] BatchNorm32 -> Convolution32 (in-place)
I1007 22:17:02.946272  5322 net.cpp:122] Setting up BatchNorm32
I1007 22:17:02.946279  5322 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:17:02.946280  5322 net.cpp:137] Memory required for data: 671335600
I1007 22:17:02.946285  5322 layer_factory.hpp:77] Creating layer Scale32
I1007 22:17:02.946291  5322 net.cpp:84] Creating Layer Scale32
I1007 22:17:02.946295  5322 net.cpp:406] Scale32 <- Convolution32
I1007 22:17:02.946298  5322 net.cpp:367] Scale32 -> Convolution32 (in-place)
I1007 22:17:02.946331  5322 layer_factory.hpp:77] Creating layer Scale32
I1007 22:17:02.946422  5322 net.cpp:122] Setting up Scale32
I1007 22:17:02.946427  5322 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:17:02.946429  5322 net.cpp:137] Memory required for data: 672974000
I1007 22:17:02.946434  5322 layer_factory.hpp:77] Creating layer elu30
I1007 22:17:02.946439  5322 net.cpp:84] Creating Layer elu30
I1007 22:17:02.946442  5322 net.cpp:406] elu30 <- Convolution32
I1007 22:17:02.946446  5322 net.cpp:367] elu30 -> Convolution32 (in-place)
I1007 22:17:02.946450  5322 net.cpp:122] Setting up elu30
I1007 22:17:02.946455  5322 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:17:02.946456  5322 net.cpp:137] Memory required for data: 674612400
I1007 22:17:02.946458  5322 layer_factory.hpp:77] Creating layer Convolution33
I1007 22:17:02.946465  5322 net.cpp:84] Creating Layer Convolution33
I1007 22:17:02.946467  5322 net.cpp:406] Convolution33 <- Convolution32
I1007 22:17:02.946471  5322 net.cpp:380] Convolution33 -> Convolution33
I1007 22:17:02.952126  5322 net.cpp:122] Setting up Convolution33
I1007 22:17:02.952137  5322 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:17:02.952141  5322 net.cpp:137] Memory required for data: 676250800
I1007 22:17:02.952145  5322 layer_factory.hpp:77] Creating layer BatchNorm33
I1007 22:17:02.952152  5322 net.cpp:84] Creating Layer BatchNorm33
I1007 22:17:02.952154  5322 net.cpp:406] BatchNorm33 <- Convolution33
I1007 22:17:02.952159  5322 net.cpp:367] BatchNorm33 -> Convolution33 (in-place)
I1007 22:17:02.952322  5322 net.cpp:122] Setting up BatchNorm33
I1007 22:17:02.952327  5322 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:17:02.952328  5322 net.cpp:137] Memory required for data: 677889200
I1007 22:17:02.952342  5322 layer_factory.hpp:77] Creating layer Scale33
I1007 22:17:02.952347  5322 net.cpp:84] Creating Layer Scale33
I1007 22:17:02.952348  5322 net.cpp:406] Scale33 <- Convolution33
I1007 22:17:02.952353  5322 net.cpp:367] Scale33 -> Convolution33 (in-place)
I1007 22:17:02.952386  5322 layer_factory.hpp:77] Creating layer Scale33
I1007 22:17:02.952478  5322 net.cpp:122] Setting up Scale33
I1007 22:17:02.952484  5322 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:17:02.952486  5322 net.cpp:137] Memory required for data: 679527600
I1007 22:17:02.952491  5322 layer_factory.hpp:77] Creating layer Eltwise15
I1007 22:17:02.952494  5322 net.cpp:84] Creating Layer Eltwise15
I1007 22:17:02.952497  5322 net.cpp:406] Eltwise15 <- Eltwise14_elu29_0_split_1
I1007 22:17:02.952502  5322 net.cpp:406] Eltwise15 <- Convolution33
I1007 22:17:02.952504  5322 net.cpp:380] Eltwise15 -> Eltwise15
I1007 22:17:02.952524  5322 net.cpp:122] Setting up Eltwise15
I1007 22:17:02.952529  5322 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:17:02.952531  5322 net.cpp:137] Memory required for data: 681166000
I1007 22:17:02.952533  5322 layer_factory.hpp:77] Creating layer elu31
I1007 22:17:02.952538  5322 net.cpp:84] Creating Layer elu31
I1007 22:17:02.952540  5322 net.cpp:406] elu31 <- Eltwise15
I1007 22:17:02.952543  5322 net.cpp:367] elu31 -> Eltwise15 (in-place)
I1007 22:17:02.952548  5322 net.cpp:122] Setting up elu31
I1007 22:17:02.952550  5322 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:17:02.952553  5322 net.cpp:137] Memory required for data: 682804400
I1007 22:17:02.952554  5322 layer_factory.hpp:77] Creating layer Pooling1
I1007 22:17:02.952559  5322 net.cpp:84] Creating Layer Pooling1
I1007 22:17:02.952561  5322 net.cpp:406] Pooling1 <- Eltwise15
I1007 22:17:02.952565  5322 net.cpp:380] Pooling1 -> Pooling1
I1007 22:17:02.952713  5322 net.cpp:122] Setting up Pooling1
I1007 22:17:02.952720  5322 net.cpp:129] Top shape: 100 64 1 1 (6400)
I1007 22:17:02.952723  5322 net.cpp:137] Memory required for data: 682830000
I1007 22:17:02.952725  5322 layer_factory.hpp:77] Creating layer InnerProduct1
I1007 22:17:02.952731  5322 net.cpp:84] Creating Layer InnerProduct1
I1007 22:17:02.952734  5322 net.cpp:406] InnerProduct1 <- Pooling1
I1007 22:17:02.952739  5322 net.cpp:380] InnerProduct1 -> InnerProduct1
I1007 22:17:02.952849  5322 net.cpp:122] Setting up InnerProduct1
I1007 22:17:02.952854  5322 net.cpp:129] Top shape: 100 10 (1000)
I1007 22:17:02.952857  5322 net.cpp:137] Memory required for data: 682834000
I1007 22:17:02.952860  5322 layer_factory.hpp:77] Creating layer InnerProduct1_InnerProduct1_0_split
I1007 22:17:02.952864  5322 net.cpp:84] Creating Layer InnerProduct1_InnerProduct1_0_split
I1007 22:17:02.952867  5322 net.cpp:406] InnerProduct1_InnerProduct1_0_split <- InnerProduct1
I1007 22:17:02.952872  5322 net.cpp:380] InnerProduct1_InnerProduct1_0_split -> InnerProduct1_InnerProduct1_0_split_0
I1007 22:17:02.952877  5322 net.cpp:380] InnerProduct1_InnerProduct1_0_split -> InnerProduct1_InnerProduct1_0_split_1
I1007 22:17:02.952908  5322 net.cpp:122] Setting up InnerProduct1_InnerProduct1_0_split
I1007 22:17:02.952913  5322 net.cpp:129] Top shape: 100 10 (1000)
I1007 22:17:02.952915  5322 net.cpp:129] Top shape: 100 10 (1000)
I1007 22:17:02.952917  5322 net.cpp:137] Memory required for data: 682842000
I1007 22:17:02.952919  5322 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I1007 22:17:02.952924  5322 net.cpp:84] Creating Layer SoftmaxWithLoss1
I1007 22:17:02.952927  5322 net.cpp:406] SoftmaxWithLoss1 <- InnerProduct1_InnerProduct1_0_split_0
I1007 22:17:02.952930  5322 net.cpp:406] SoftmaxWithLoss1 <- Data2_Data1_1_split_0
I1007 22:17:02.952934  5322 net.cpp:380] SoftmaxWithLoss1 -> SoftmaxWithLoss1
I1007 22:17:02.952939  5322 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I1007 22:17:02.953440  5322 net.cpp:122] Setting up SoftmaxWithLoss1
I1007 22:17:02.953449  5322 net.cpp:129] Top shape: (1)
I1007 22:17:02.953452  5322 net.cpp:132]     with loss weight 1
I1007 22:17:02.953460  5322 net.cpp:137] Memory required for data: 682842004
I1007 22:17:02.953470  5322 layer_factory.hpp:77] Creating layer Accuracy1
I1007 22:17:02.953480  5322 net.cpp:84] Creating Layer Accuracy1
I1007 22:17:02.953483  5322 net.cpp:406] Accuracy1 <- InnerProduct1_InnerProduct1_0_split_1
I1007 22:17:02.953487  5322 net.cpp:406] Accuracy1 <- Data2_Data1_1_split_1
I1007 22:17:02.953491  5322 net.cpp:380] Accuracy1 -> Accuracy1
I1007 22:17:02.953497  5322 net.cpp:122] Setting up Accuracy1
I1007 22:17:02.953501  5322 net.cpp:129] Top shape: (1)
I1007 22:17:02.953505  5322 net.cpp:137] Memory required for data: 682842008
I1007 22:17:02.953506  5322 net.cpp:200] Accuracy1 does not need backward computation.
I1007 22:17:02.953510  5322 net.cpp:198] SoftmaxWithLoss1 needs backward computation.
I1007 22:17:02.953512  5322 net.cpp:198] InnerProduct1_InnerProduct1_0_split needs backward computation.
I1007 22:17:02.953514  5322 net.cpp:198] InnerProduct1 needs backward computation.
I1007 22:17:02.953516  5322 net.cpp:198] Pooling1 needs backward computation.
I1007 22:17:02.953519  5322 net.cpp:198] elu31 needs backward computation.
I1007 22:17:02.953521  5322 net.cpp:198] Eltwise15 needs backward computation.
I1007 22:17:02.953523  5322 net.cpp:198] Scale33 needs backward computation.
I1007 22:17:02.953526  5322 net.cpp:198] BatchNorm33 needs backward computation.
I1007 22:17:02.953528  5322 net.cpp:198] Convolution33 needs backward computation.
I1007 22:17:02.953531  5322 net.cpp:198] elu30 needs backward computation.
I1007 22:17:02.953532  5322 net.cpp:198] Scale32 needs backward computation.
I1007 22:17:02.953534  5322 net.cpp:198] BatchNorm32 needs backward computation.
I1007 22:17:02.953536  5322 net.cpp:198] Convolution32 needs backward computation.
I1007 22:17:02.953538  5322 net.cpp:198] Eltwise14_elu29_0_split needs backward computation.
I1007 22:17:02.953541  5322 net.cpp:198] elu29 needs backward computation.
I1007 22:17:02.953543  5322 net.cpp:198] Eltwise14 needs backward computation.
I1007 22:17:02.953546  5322 net.cpp:198] Scale31 needs backward computation.
I1007 22:17:02.953548  5322 net.cpp:198] BatchNorm31 needs backward computation.
I1007 22:17:02.953550  5322 net.cpp:198] Convolution31 needs backward computation.
I1007 22:17:02.953552  5322 net.cpp:198] elu28 needs backward computation.
I1007 22:17:02.953554  5322 net.cpp:198] Scale30 needs backward computation.
I1007 22:17:02.953557  5322 net.cpp:198] BatchNorm30 needs backward computation.
I1007 22:17:02.953558  5322 net.cpp:198] Convolution30 needs backward computation.
I1007 22:17:02.953560  5322 net.cpp:198] Eltwise13_elu27_0_split needs backward computation.
I1007 22:17:02.953563  5322 net.cpp:198] elu27 needs backward computation.
I1007 22:17:02.953565  5322 net.cpp:198] Eltwise13 needs backward computation.
I1007 22:17:02.953568  5322 net.cpp:198] Scale29 needs backward computation.
I1007 22:17:02.953570  5322 net.cpp:198] BatchNorm29 needs backward computation.
I1007 22:17:02.953573  5322 net.cpp:198] Convolution29 needs backward computation.
I1007 22:17:02.953575  5322 net.cpp:198] elu26 needs backward computation.
I1007 22:17:02.953578  5322 net.cpp:198] Scale28 needs backward computation.
I1007 22:17:02.953580  5322 net.cpp:198] BatchNorm28 needs backward computation.
I1007 22:17:02.953583  5322 net.cpp:198] Convolution28 needs backward computation.
I1007 22:17:02.953584  5322 net.cpp:198] Eltwise12_elu25_0_split needs backward computation.
I1007 22:17:02.953588  5322 net.cpp:198] elu25 needs backward computation.
I1007 22:17:02.953589  5322 net.cpp:198] Eltwise12 needs backward computation.
I1007 22:17:02.953593  5322 net.cpp:198] Scale27 needs backward computation.
I1007 22:17:02.953594  5322 net.cpp:198] BatchNorm27 needs backward computation.
I1007 22:17:02.953598  5322 net.cpp:198] Convolution27 needs backward computation.
I1007 22:17:02.953600  5322 net.cpp:198] elu24 needs backward computation.
I1007 22:17:02.953603  5322 net.cpp:198] Scale26 needs backward computation.
I1007 22:17:02.953605  5322 net.cpp:198] BatchNorm26 needs backward computation.
I1007 22:17:02.953613  5322 net.cpp:198] Convolution26 needs backward computation.
I1007 22:17:02.953615  5322 net.cpp:198] Eltwise11_elu23_0_split needs backward computation.
I1007 22:17:02.953618  5322 net.cpp:198] elu23 needs backward computation.
I1007 22:17:02.953620  5322 net.cpp:198] Eltwise11 needs backward computation.
I1007 22:17:02.953624  5322 net.cpp:198] Scale25 needs backward computation.
I1007 22:17:02.953629  5322 net.cpp:198] BatchNorm25 needs backward computation.
I1007 22:17:02.953634  5322 net.cpp:198] Convolution25 needs backward computation.
I1007 22:17:02.953639  5322 net.cpp:198] elu22 needs backward computation.
I1007 22:17:02.953642  5322 net.cpp:198] Scale24 needs backward computation.
I1007 22:17:02.953647  5322 net.cpp:198] BatchNorm24 needs backward computation.
I1007 22:17:02.953651  5322 net.cpp:198] Convolution24 needs backward computation.
I1007 22:17:02.953656  5322 net.cpp:198] Scale23 needs backward computation.
I1007 22:17:02.953660  5322 net.cpp:198] BatchNorm23 needs backward computation.
I1007 22:17:02.953663  5322 net.cpp:198] Convolution23 needs backward computation.
I1007 22:17:02.953668  5322 net.cpp:198] Eltwise10_elu21_0_split needs backward computation.
I1007 22:17:02.953671  5322 net.cpp:198] elu21 needs backward computation.
I1007 22:17:02.953675  5322 net.cpp:198] Eltwise10 needs backward computation.
I1007 22:17:02.953681  5322 net.cpp:198] Scale22 needs backward computation.
I1007 22:17:02.953685  5322 net.cpp:198] BatchNorm22 needs backward computation.
I1007 22:17:02.953689  5322 net.cpp:198] Convolution22 needs backward computation.
I1007 22:17:02.953692  5322 net.cpp:198] elu20 needs backward computation.
I1007 22:17:02.953696  5322 net.cpp:198] Scale21 needs backward computation.
I1007 22:17:02.953701  5322 net.cpp:198] BatchNorm21 needs backward computation.
I1007 22:17:02.953703  5322 net.cpp:198] Convolution21 needs backward computation.
I1007 22:17:02.953708  5322 net.cpp:198] Eltwise9_elu19_0_split needs backward computation.
I1007 22:17:02.953713  5322 net.cpp:198] elu19 needs backward computation.
I1007 22:17:02.953716  5322 net.cpp:198] Eltwise9 needs backward computation.
I1007 22:17:02.953721  5322 net.cpp:198] Scale20 needs backward computation.
I1007 22:17:02.953725  5322 net.cpp:198] BatchNorm20 needs backward computation.
I1007 22:17:02.953728  5322 net.cpp:198] Convolution20 needs backward computation.
I1007 22:17:02.953732  5322 net.cpp:198] elu18 needs backward computation.
I1007 22:17:02.953737  5322 net.cpp:198] Scale19 needs backward computation.
I1007 22:17:02.953740  5322 net.cpp:198] BatchNorm19 needs backward computation.
I1007 22:17:02.953743  5322 net.cpp:198] Convolution19 needs backward computation.
I1007 22:17:02.953748  5322 net.cpp:198] Eltwise8_elu17_0_split needs backward computation.
I1007 22:17:02.953752  5322 net.cpp:198] elu17 needs backward computation.
I1007 22:17:02.953757  5322 net.cpp:198] Eltwise8 needs backward computation.
I1007 22:17:02.953760  5322 net.cpp:198] Scale18 needs backward computation.
I1007 22:17:02.953764  5322 net.cpp:198] BatchNorm18 needs backward computation.
I1007 22:17:02.953769  5322 net.cpp:198] Convolution18 needs backward computation.
I1007 22:17:02.953773  5322 net.cpp:198] elu16 needs backward computation.
I1007 22:17:02.953776  5322 net.cpp:198] Scale17 needs backward computation.
I1007 22:17:02.953781  5322 net.cpp:198] BatchNorm17 needs backward computation.
I1007 22:17:02.953784  5322 net.cpp:198] Convolution17 needs backward computation.
I1007 22:17:02.953788  5322 net.cpp:198] Eltwise7_elu15_0_split needs backward computation.
I1007 22:17:02.953794  5322 net.cpp:198] elu15 needs backward computation.
I1007 22:17:02.953796  5322 net.cpp:198] Eltwise7 needs backward computation.
I1007 22:17:02.953800  5322 net.cpp:198] Scale16 needs backward computation.
I1007 22:17:02.953805  5322 net.cpp:198] BatchNorm16 needs backward computation.
I1007 22:17:02.953809  5322 net.cpp:198] Convolution16 needs backward computation.
I1007 22:17:02.953812  5322 net.cpp:198] elu14 needs backward computation.
I1007 22:17:02.953821  5322 net.cpp:198] Scale15 needs backward computation.
I1007 22:17:02.953824  5322 net.cpp:198] BatchNorm15 needs backward computation.
I1007 22:17:02.953829  5322 net.cpp:198] Convolution15 needs backward computation.
I1007 22:17:02.953833  5322 net.cpp:198] Eltwise6_elu13_0_split needs backward computation.
I1007 22:17:02.953837  5322 net.cpp:198] elu13 needs backward computation.
I1007 22:17:02.953841  5322 net.cpp:198] Eltwise6 needs backward computation.
I1007 22:17:02.953845  5322 net.cpp:198] Scale14 needs backward computation.
I1007 22:17:02.953848  5322 net.cpp:198] BatchNorm14 needs backward computation.
I1007 22:17:02.953850  5322 net.cpp:198] Convolution14 needs backward computation.
I1007 22:17:02.953853  5322 net.cpp:198] elu12 needs backward computation.
I1007 22:17:02.953855  5322 net.cpp:198] Scale13 needs backward computation.
I1007 22:17:02.953857  5322 net.cpp:198] BatchNorm13 needs backward computation.
I1007 22:17:02.953860  5322 net.cpp:198] Convolution13 needs backward computation.
I1007 22:17:02.953862  5322 net.cpp:198] Scale12 needs backward computation.
I1007 22:17:02.953864  5322 net.cpp:198] BatchNorm12 needs backward computation.
I1007 22:17:02.953866  5322 net.cpp:198] Convolution12 needs backward computation.
I1007 22:17:02.953869  5322 net.cpp:198] Eltwise5_elu11_0_split needs backward computation.
I1007 22:17:02.953871  5322 net.cpp:198] elu11 needs backward computation.
I1007 22:17:02.953876  5322 net.cpp:198] Eltwise5 needs backward computation.
I1007 22:17:02.953879  5322 net.cpp:198] Scale11 needs backward computation.
I1007 22:17:02.953881  5322 net.cpp:198] BatchNorm11 needs backward computation.
I1007 22:17:02.953883  5322 net.cpp:198] Convolution11 needs backward computation.
I1007 22:17:02.953886  5322 net.cpp:198] elu10 needs backward computation.
I1007 22:17:02.953888  5322 net.cpp:198] Scale10 needs backward computation.
I1007 22:17:02.953891  5322 net.cpp:198] BatchNorm10 needs backward computation.
I1007 22:17:02.953892  5322 net.cpp:198] Convolution10 needs backward computation.
I1007 22:17:02.953896  5322 net.cpp:198] Eltwise4_elu9_0_split needs backward computation.
I1007 22:17:02.953898  5322 net.cpp:198] elu9 needs backward computation.
I1007 22:17:02.953900  5322 net.cpp:198] Eltwise4 needs backward computation.
I1007 22:17:02.953904  5322 net.cpp:198] Scale9 needs backward computation.
I1007 22:17:02.953907  5322 net.cpp:198] BatchNorm9 needs backward computation.
I1007 22:17:02.953909  5322 net.cpp:198] Convolution9 needs backward computation.
I1007 22:17:02.953912  5322 net.cpp:198] elu8 needs backward computation.
I1007 22:17:02.953913  5322 net.cpp:198] Scale8 needs backward computation.
I1007 22:17:02.953915  5322 net.cpp:198] BatchNorm8 needs backward computation.
I1007 22:17:02.953918  5322 net.cpp:198] Convolution8 needs backward computation.
I1007 22:17:02.953920  5322 net.cpp:198] Eltwise3_elu7_0_split needs backward computation.
I1007 22:17:02.953923  5322 net.cpp:198] elu7 needs backward computation.
I1007 22:17:02.953925  5322 net.cpp:198] Eltwise3 needs backward computation.
I1007 22:17:02.953928  5322 net.cpp:198] Scale7 needs backward computation.
I1007 22:17:02.953930  5322 net.cpp:198] BatchNorm7 needs backward computation.
I1007 22:17:02.953933  5322 net.cpp:198] Convolution7 needs backward computation.
I1007 22:17:02.953935  5322 net.cpp:198] elu6 needs backward computation.
I1007 22:17:02.953938  5322 net.cpp:198] Scale6 needs backward computation.
I1007 22:17:02.953939  5322 net.cpp:198] BatchNorm6 needs backward computation.
I1007 22:17:02.953943  5322 net.cpp:198] Convolution6 needs backward computation.
I1007 22:17:02.953944  5322 net.cpp:198] Eltwise2_elu5_0_split needs backward computation.
I1007 22:17:02.953948  5322 net.cpp:198] elu5 needs backward computation.
I1007 22:17:02.953949  5322 net.cpp:198] Eltwise2 needs backward computation.
I1007 22:17:02.953953  5322 net.cpp:198] Scale5 needs backward computation.
I1007 22:17:02.953954  5322 net.cpp:198] BatchNorm5 needs backward computation.
I1007 22:17:02.953956  5322 net.cpp:198] Convolution5 needs backward computation.
I1007 22:17:02.953963  5322 net.cpp:198] elu4 needs backward computation.
I1007 22:17:02.953964  5322 net.cpp:198] Scale4 needs backward computation.
I1007 22:17:02.953968  5322 net.cpp:198] BatchNorm4 needs backward computation.
I1007 22:17:02.953969  5322 net.cpp:198] Convolution4 needs backward computation.
I1007 22:17:02.953972  5322 net.cpp:198] Eltwise1_elu3_0_split needs backward computation.
I1007 22:17:02.953974  5322 net.cpp:198] elu3 needs backward computation.
I1007 22:17:02.953977  5322 net.cpp:198] Eltwise1 needs backward computation.
I1007 22:17:02.953980  5322 net.cpp:198] Scale3 needs backward computation.
I1007 22:17:02.953982  5322 net.cpp:198] BatchNorm3 needs backward computation.
I1007 22:17:02.953984  5322 net.cpp:198] Convolution3 needs backward computation.
I1007 22:17:02.953987  5322 net.cpp:198] elu2 needs backward computation.
I1007 22:17:02.953989  5322 net.cpp:198] Scale2 needs backward computation.
I1007 22:17:02.953991  5322 net.cpp:198] BatchNorm2 needs backward computation.
I1007 22:17:02.953994  5322 net.cpp:198] Convolution2 needs backward computation.
I1007 22:17:02.953996  5322 net.cpp:198] Convolution1_elu1_0_split needs backward computation.
I1007 22:17:02.953999  5322 net.cpp:198] elu1 needs backward computation.
I1007 22:17:02.954001  5322 net.cpp:198] Scale1 needs backward computation.
I1007 22:17:02.954004  5322 net.cpp:198] BatchNorm1 needs backward computation.
I1007 22:17:02.954005  5322 net.cpp:198] Convolution1 needs backward computation.
I1007 22:17:02.954010  5322 net.cpp:200] Data2_Data1_1_split does not need backward computation.
I1007 22:17:02.954012  5322 net.cpp:200] Data1 does not need backward computation.
I1007 22:17:02.954015  5322 net.cpp:242] This network produces output Accuracy1
I1007 22:17:02.954016  5322 net.cpp:242] This network produces output SoftmaxWithLoss1
I1007 22:17:02.954071  5322 net.cpp:255] Network initialization done.
I1007 22:17:02.954428  5322 solver.cpp:56] Solver scaffolding done.
I1007 22:17:02.964222  5322 caffe.cpp:248] Starting Optimization
I1007 22:17:02.964241  5322 solver.cpp:272] Solving resnet_cifar10
I1007 22:17:02.964256  5322 solver.cpp:273] Learning Rate Policy: multistep
I1007 22:17:02.968444  5322 solver.cpp:330] Iteration 0, Testing net (#0)
I1007 22:17:08.272397  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1007 22:17:08.441381  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.1
I1007 22:17:08.441419  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 87.3365 (* 1 = 87.3365 loss)
I1007 22:17:08.815485  5322 solver.cpp:218] Iteration 0 (0 iter/s, 5.85095s/100 iters), loss = 2.29864
I1007 22:17:08.815524  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 2.29864 (* 1 = 2.29864 loss)
I1007 22:17:08.815541  5322 sgd_solver.cpp:105] Iteration 0, lr = 0.1
I1007 22:17:34.055835  5322 solver.cpp:218] Iteration 100 (3.96196 iter/s, 25.2401s/100 iters), loss = 1.77415
I1007 22:17:34.055924  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.77415 (* 1 = 1.77415 loss)
I1007 22:17:34.055932  5322 sgd_solver.cpp:105] Iteration 100, lr = 0.1
I1007 22:17:59.122310  5322 solver.cpp:218] Iteration 200 (3.98977 iter/s, 25.0641s/100 iters), loss = 1.86643
I1007 22:17:59.122365  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.86643 (* 1 = 1.86643 loss)
I1007 22:17:59.122386  5322 sgd_solver.cpp:105] Iteration 200, lr = 0.1
I1007 22:18:23.758961  5322 solver.cpp:218] Iteration 300 (4.05944 iter/s, 24.634s/100 iters), loss = 1.49189
I1007 22:18:23.759079  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.49189 (* 1 = 1.49189 loss)
I1007 22:18:23.759099  5322 sgd_solver.cpp:105] Iteration 300, lr = 0.1
I1007 22:18:48.342397  5322 solver.cpp:218] Iteration 400 (4.06844 iter/s, 24.5795s/100 iters), loss = 1.22681
I1007 22:18:48.342442  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.22681 (* 1 = 1.22681 loss)
I1007 22:18:48.342449  5322 sgd_solver.cpp:105] Iteration 400, lr = 0.1
I1007 22:19:12.075987  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1007 22:19:13.057729  5322 solver.cpp:330] Iteration 500, Testing net (#0)
I1007 22:19:17.682410  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1007 22:19:17.868669  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.4095
I1007 22:19:17.868703  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.83993 (* 1 = 1.83993 loss)
I1007 22:19:18.002537  5322 solver.cpp:218] Iteration 500 (3.37204 iter/s, 29.6556s/100 iters), loss = 1.44666
I1007 22:19:18.002564  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.44666 (* 1 = 1.44666 loss)
I1007 22:19:18.002570  5322 sgd_solver.cpp:105] Iteration 500, lr = 0.1
I1007 22:19:42.644676  5322 solver.cpp:218] Iteration 600 (4.05813 iter/s, 24.6419s/100 iters), loss = 1.30688
I1007 22:19:42.644763  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.30688 (* 1 = 1.30688 loss)
I1007 22:19:42.644771  5322 sgd_solver.cpp:105] Iteration 600, lr = 0.1
I1007 22:20:07.597267  5322 solver.cpp:218] Iteration 700 (4.00797 iter/s, 24.9503s/100 iters), loss = 1.11725
I1007 22:20:07.597308  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.11725 (* 1 = 1.11725 loss)
I1007 22:20:07.597316  5322 sgd_solver.cpp:105] Iteration 700, lr = 0.1
I1007 22:20:32.199672  5322 solver.cpp:218] Iteration 800 (4.06526 iter/s, 24.5987s/100 iters), loss = 0.971097
I1007 22:20:32.199777  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.971097 (* 1 = 0.971097 loss)
I1007 22:20:32.199785  5322 sgd_solver.cpp:105] Iteration 800, lr = 0.1
I1007 22:20:56.812742  5322 solver.cpp:218] Iteration 900 (4.06353 iter/s, 24.6092s/100 iters), loss = 0.814721
I1007 22:20:56.812789  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.814721 (* 1 = 0.814721 loss)
I1007 22:20:56.812796  5322 sgd_solver.cpp:105] Iteration 900, lr = 0.1
I1007 22:21:20.565992  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1007 22:21:21.549017  5322 solver.cpp:330] Iteration 1000, Testing net (#0)
I1007 22:21:26.177435  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1007 22:21:26.368124  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.3151
I1007 22:21:26.368160  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 3.14536 (* 1 = 3.14536 loss)
I1007 22:21:26.518676  5322 solver.cpp:218] Iteration 1000 (3.36677 iter/s, 29.7021s/100 iters), loss = 1.03122
I1007 22:21:26.518717  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.03122 (* 1 = 1.03122 loss)
I1007 22:21:26.518723  5322 sgd_solver.cpp:105] Iteration 1000, lr = 0.1
I1007 22:21:51.177489  5322 solver.cpp:218] Iteration 1100 (4.05572 iter/s, 24.6565s/100 iters), loss = 0.746223
I1007 22:21:51.177573  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.746223 (* 1 = 0.746223 loss)
I1007 22:21:51.177582  5322 sgd_solver.cpp:105] Iteration 1100, lr = 0.1
I1007 22:22:16.202388  5322 solver.cpp:218] Iteration 1200 (3.99663 iter/s, 25.0211s/100 iters), loss = 0.898054
I1007 22:22:16.202433  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.898054 (* 1 = 0.898054 loss)
I1007 22:22:16.202441  5322 sgd_solver.cpp:105] Iteration 1200, lr = 0.1
I1007 22:22:40.773293  5322 solver.cpp:218] Iteration 1300 (4.0704 iter/s, 24.5676s/100 iters), loss = 0.782763
I1007 22:22:40.773391  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.782763 (* 1 = 0.782763 loss)
I1007 22:22:40.773413  5322 sgd_solver.cpp:105] Iteration 1300, lr = 0.1
I1007 22:23:05.354024  5322 solver.cpp:218] Iteration 1400 (4.06861 iter/s, 24.5784s/100 iters), loss = 0.820751
I1007 22:23:05.354064  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.820751 (* 1 = 0.820751 loss)
I1007 22:23:05.354084  5322 sgd_solver.cpp:105] Iteration 1400, lr = 0.1
I1007 22:23:29.105754  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1007 22:23:30.089311  5322 solver.cpp:330] Iteration 1500, Testing net (#0)
I1007 22:23:34.711899  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1007 22:23:34.935070  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.5145
I1007 22:23:34.935096  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.52404 (* 1 = 1.52404 loss)
I1007 22:23:35.055649  5322 solver.cpp:218] Iteration 1500 (3.36723 iter/s, 29.698s/100 iters), loss = 0.902371
I1007 22:23:35.055691  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.902371 (* 1 = 0.902371 loss)
I1007 22:23:35.055698  5322 sgd_solver.cpp:105] Iteration 1500, lr = 0.1
I1007 22:23:59.683574  5322 solver.cpp:218] Iteration 1600 (4.06081 iter/s, 24.6256s/100 iters), loss = 0.572752
I1007 22:23:59.683686  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.572752 (* 1 = 0.572752 loss)
I1007 22:23:59.683694  5322 sgd_solver.cpp:105] Iteration 1600, lr = 0.1
I1007 22:24:24.649354  5322 solver.cpp:218] Iteration 1700 (4.00585 iter/s, 24.9635s/100 iters), loss = 0.680862
I1007 22:24:24.649399  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.680862 (* 1 = 0.680862 loss)
I1007 22:24:24.649405  5322 sgd_solver.cpp:105] Iteration 1700, lr = 0.1
I1007 22:24:49.226182  5322 solver.cpp:218] Iteration 1800 (4.06925 iter/s, 24.5745s/100 iters), loss = 0.659224
I1007 22:24:49.226306  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.659224 (* 1 = 0.659224 loss)
I1007 22:24:49.226315  5322 sgd_solver.cpp:105] Iteration 1800, lr = 0.1
I1007 22:25:13.708065  5322 solver.cpp:218] Iteration 1900 (4.08533 iter/s, 24.4778s/100 iters), loss = 0.697521
I1007 22:25:13.708104  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.697521 (* 1 = 0.697521 loss)
I1007 22:25:13.708112  5322 sgd_solver.cpp:105] Iteration 1900, lr = 0.1
I1007 22:25:37.491116  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1007 22:25:38.472733  5322 solver.cpp:330] Iteration 2000, Testing net (#0)
I1007 22:25:43.125527  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1007 22:25:43.342802  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.5786
I1007 22:25:43.342839  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.36413 (* 1 = 1.36413 loss)
I1007 22:25:43.487319  5322 solver.cpp:218] Iteration 2000 (3.3583 iter/s, 29.777s/100 iters), loss = 0.612136
I1007 22:25:43.487363  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.612136 (* 1 = 0.612136 loss)
I1007 22:25:43.487371  5322 sgd_solver.cpp:105] Iteration 2000, lr = 0.1
I1007 22:26:08.110987  5322 solver.cpp:218] Iteration 2100 (4.06186 iter/s, 24.6192s/100 iters), loss = 0.526238
I1007 22:26:08.111073  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.526238 (* 1 = 0.526238 loss)
I1007 22:26:08.111081  5322 sgd_solver.cpp:105] Iteration 2100, lr = 0.1
I1007 22:26:33.063091  5322 solver.cpp:218] Iteration 2200 (4.00832 iter/s, 24.9481s/100 iters), loss = 0.603799
I1007 22:26:33.063129  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.603799 (* 1 = 0.603799 loss)
I1007 22:26:33.063140  5322 sgd_solver.cpp:105] Iteration 2200, lr = 0.1
I1007 22:26:57.683217  5322 solver.cpp:218] Iteration 2300 (4.06244 iter/s, 24.6157s/100 iters), loss = 0.578386
I1007 22:26:57.683322  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.578386 (* 1 = 0.578386 loss)
I1007 22:26:57.683346  5322 sgd_solver.cpp:105] Iteration 2300, lr = 0.1
I1007 22:27:22.289032  5322 solver.cpp:218] Iteration 2400 (4.06473 iter/s, 24.6019s/100 iters), loss = 0.595472
I1007 22:27:22.289070  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.595472 (* 1 = 0.595472 loss)
I1007 22:27:22.289089  5322 sgd_solver.cpp:105] Iteration 2400, lr = 0.1
I1007 22:27:46.085127  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1007 22:27:47.070165  5322 solver.cpp:330] Iteration 2500, Testing net (#0)
I1007 22:27:51.731885  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1007 22:27:51.918648  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6308
I1007 22:27:51.918676  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.07592 (* 1 = 1.07592 loss)
I1007 22:27:52.091933  5322 solver.cpp:218] Iteration 2500 (3.3558 iter/s, 29.7992s/100 iters), loss = 0.518083
I1007 22:27:52.091967  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.518083 (* 1 = 0.518083 loss)
I1007 22:27:52.091986  5322 sgd_solver.cpp:105] Iteration 2500, lr = 0.1
I1007 22:28:16.750351  5322 solver.cpp:218] Iteration 2600 (4.05579 iter/s, 24.6561s/100 iters), loss = 0.529569
I1007 22:28:16.750445  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.529569 (* 1 = 0.529569 loss)
I1007 22:28:16.750454  5322 sgd_solver.cpp:105] Iteration 2600, lr = 0.1
I1007 22:28:41.740100  5322 solver.cpp:218] Iteration 2700 (4.002 iter/s, 24.9875s/100 iters), loss = 0.603399
I1007 22:28:41.740135  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.603399 (* 1 = 0.603399 loss)
I1007 22:28:41.740152  5322 sgd_solver.cpp:105] Iteration 2700, lr = 0.1
I1007 22:29:06.389114  5322 solver.cpp:218] Iteration 2800 (4.05768 iter/s, 24.6446s/100 iters), loss = 0.492198
I1007 22:29:06.389211  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.492198 (* 1 = 0.492198 loss)
I1007 22:29:06.389230  5322 sgd_solver.cpp:105] Iteration 2800, lr = 0.1
I1007 22:29:31.042840  5322 solver.cpp:218] Iteration 2900 (4.05691 iter/s, 24.6493s/100 iters), loss = 0.520112
I1007 22:29:31.042876  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.520112 (* 1 = 0.520112 loss)
I1007 22:29:31.042883  5322 sgd_solver.cpp:105] Iteration 2900, lr = 0.1
I1007 22:29:54.843920  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1007 22:29:55.826875  5322 solver.cpp:330] Iteration 3000, Testing net (#0)
I1007 22:30:00.426822  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1007 22:30:00.600831  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6622
I1007 22:30:00.600859  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.984719 (* 1 = 0.984719 loss)
I1007 22:30:00.775005  5322 solver.cpp:218] Iteration 3000 (3.36379 iter/s, 29.7284s/100 iters), loss = 0.547388
I1007 22:30:00.775045  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.547388 (* 1 = 0.547388 loss)
I1007 22:30:00.775053  5322 sgd_solver.cpp:105] Iteration 3000, lr = 0.1
I1007 22:30:25.322633  5322 solver.cpp:218] Iteration 3100 (4.0741 iter/s, 24.5453s/100 iters), loss = 0.45094
I1007 22:30:25.322726  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.45094 (* 1 = 0.45094 loss)
I1007 22:30:25.322733  5322 sgd_solver.cpp:105] Iteration 3100, lr = 0.1
I1007 22:30:50.323853  5322 solver.cpp:218] Iteration 3200 (4.00038 iter/s, 24.9977s/100 iters), loss = 0.402576
I1007 22:30:50.323887  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.402576 (* 1 = 0.402576 loss)
I1007 22:30:50.323894  5322 sgd_solver.cpp:105] Iteration 3200, lr = 0.1
I1007 22:31:14.955786  5322 solver.cpp:218] Iteration 3300 (4.06039 iter/s, 24.6282s/100 iters), loss = 0.571455
I1007 22:31:14.955880  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.571455 (* 1 = 0.571455 loss)
I1007 22:31:14.955899  5322 sgd_solver.cpp:105] Iteration 3300, lr = 0.1
I1007 22:31:39.589887  5322 solver.cpp:218] Iteration 3400 (4.0601 iter/s, 24.6299s/100 iters), loss = 0.523433
I1007 22:31:39.589929  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.523433 (* 1 = 0.523433 loss)
I1007 22:31:39.589936  5322 sgd_solver.cpp:105] Iteration 3400, lr = 0.1
I1007 22:32:03.392524  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1007 22:32:04.375529  5322 solver.cpp:330] Iteration 3500, Testing net (#0)
I1007 22:32:08.948129  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1007 22:32:09.164624  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6382
I1007 22:32:09.164659  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.989739 (* 1 = 0.989739 loss)
I1007 22:32:09.295027  5322 solver.cpp:218] Iteration 3500 (3.36684 iter/s, 29.7014s/100 iters), loss = 0.453869
I1007 22:32:09.295071  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.453869 (* 1 = 0.453869 loss)
I1007 22:32:09.295078  5322 sgd_solver.cpp:105] Iteration 3500, lr = 0.1
I1007 22:32:33.964306  5322 solver.cpp:218] Iteration 3600 (4.05435 iter/s, 24.6648s/100 iters), loss = 0.47248
I1007 22:32:33.964426  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.47248 (* 1 = 0.47248 loss)
I1007 22:32:33.964443  5322 sgd_solver.cpp:105] Iteration 3600, lr = 0.1
I1007 22:32:58.965839  5322 solver.cpp:218] Iteration 3700 (4.00012 iter/s, 24.9992s/100 iters), loss = 0.46029
I1007 22:32:58.965873  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.46029 (* 1 = 0.46029 loss)
I1007 22:32:58.965879  5322 sgd_solver.cpp:105] Iteration 3700, lr = 0.1
I1007 22:33:23.611433  5322 solver.cpp:218] Iteration 3800 (4.05789 iter/s, 24.6433s/100 iters), loss = 0.513987
I1007 22:33:23.611524  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.513987 (* 1 = 0.513987 loss)
I1007 22:33:23.611531  5322 sgd_solver.cpp:105] Iteration 3800, lr = 0.1
I1007 22:33:48.251948  5322 solver.cpp:218] Iteration 3900 (4.05892 iter/s, 24.6371s/100 iters), loss = 0.422661
I1007 22:33:48.251982  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.422661 (* 1 = 0.422661 loss)
I1007 22:33:48.251989  5322 sgd_solver.cpp:105] Iteration 3900, lr = 0.1
I1007 22:34:12.055080  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1007 22:34:13.038897  5322 solver.cpp:330] Iteration 4000, Testing net (#0)
I1007 22:34:17.540179  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1007 22:34:17.750982  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6993
I1007 22:34:17.751010  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.849532 (* 1 = 0.849532 loss)
I1007 22:34:17.897622  5322 solver.cpp:218] Iteration 4000 (3.37344 iter/s, 29.6434s/100 iters), loss = 0.601172
I1007 22:34:17.897665  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.601172 (* 1 = 0.601172 loss)
I1007 22:34:17.897675  5322 sgd_solver.cpp:105] Iteration 4000, lr = 0.1
I1007 22:34:42.624713  5322 solver.cpp:218] Iteration 4100 (4.04487 iter/s, 24.7227s/100 iters), loss = 0.404256
I1007 22:34:42.624801  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.404256 (* 1 = 0.404256 loss)
I1007 22:34:42.624822  5322 sgd_solver.cpp:105] Iteration 4100, lr = 0.1
I1007 22:35:07.617200  5322 solver.cpp:218] Iteration 4200 (4.0018 iter/s, 24.9887s/100 iters), loss = 0.413016
I1007 22:35:07.617234  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.413016 (* 1 = 0.413016 loss)
I1007 22:35:07.617254  5322 sgd_solver.cpp:105] Iteration 4200, lr = 0.1
I1007 22:35:32.287420  5322 solver.cpp:218] Iteration 4300 (4.05413 iter/s, 24.6662s/100 iters), loss = 0.469423
I1007 22:35:32.287529  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.469423 (* 1 = 0.469423 loss)
I1007 22:35:32.287552  5322 sgd_solver.cpp:105] Iteration 4300, lr = 0.1
I1007 22:35:56.944337  5322 solver.cpp:218] Iteration 4400 (4.05603 iter/s, 24.6546s/100 iters), loss = 0.431995
I1007 22:35:56.944376  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.431995 (* 1 = 0.431995 loss)
I1007 22:35:56.944396  5322 sgd_solver.cpp:105] Iteration 4400, lr = 0.1
I1007 22:36:20.802443  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1007 22:36:21.787535  5322 solver.cpp:330] Iteration 4500, Testing net (#0)
I1007 22:36:26.324597  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1007 22:36:26.507025  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7294
I1007 22:36:26.507052  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.794089 (* 1 = 0.794089 loss)
I1007 22:36:26.687232  5322 solver.cpp:218] Iteration 4500 (3.36241 iter/s, 29.7406s/100 iters), loss = 0.405972
I1007 22:36:26.687274  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.405972 (* 1 = 0.405972 loss)
I1007 22:36:26.687281  5322 sgd_solver.cpp:105] Iteration 4500, lr = 0.1
I1007 22:36:51.379905  5322 solver.cpp:218] Iteration 4600 (4.05016 iter/s, 24.6904s/100 iters), loss = 0.324959
I1007 22:36:51.380030  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.324959 (* 1 = 0.324959 loss)
I1007 22:36:51.380039  5322 sgd_solver.cpp:105] Iteration 4600, lr = 0.1
I1007 22:37:16.355073  5322 solver.cpp:218] Iteration 4700 (4.00434 iter/s, 24.9729s/100 iters), loss = 0.340037
I1007 22:37:16.355108  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.340037 (* 1 = 0.340037 loss)
I1007 22:37:16.355118  5322 sgd_solver.cpp:105] Iteration 4700, lr = 0.1
I1007 22:37:40.977870  5322 solver.cpp:218] Iteration 4800 (4.062 iter/s, 24.6184s/100 iters), loss = 0.5373
I1007 22:37:40.977957  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.5373 (* 1 = 0.5373 loss)
I1007 22:37:40.977967  5322 sgd_solver.cpp:105] Iteration 4800, lr = 0.1
I1007 22:38:05.623235  5322 solver.cpp:218] Iteration 4900 (4.05828 iter/s, 24.641s/100 iters), loss = 0.44612
I1007 22:38:05.623270  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.44612 (* 1 = 0.44612 loss)
I1007 22:38:05.623276  5322 sgd_solver.cpp:105] Iteration 4900, lr = 0.1
I1007 22:38:29.425634  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1007 22:38:30.409643  5322 solver.cpp:330] Iteration 5000, Testing net (#0)
I1007 22:38:35.033761  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1007 22:38:35.218005  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6941
I1007 22:38:35.218039  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.905167 (* 1 = 0.905167 loss)
I1007 22:38:35.369478  5322 solver.cpp:218] Iteration 5000 (3.36219 iter/s, 29.7426s/100 iters), loss = 0.475197
I1007 22:38:35.369510  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.475197 (* 1 = 0.475197 loss)
I1007 22:38:35.369518  5322 sgd_solver.cpp:105] Iteration 5000, lr = 0.1
I1007 22:39:00.000892  5322 solver.cpp:218] Iteration 5100 (4.05988 iter/s, 24.6313s/100 iters), loss = 0.405256
I1007 22:39:00.000959  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.405256 (* 1 = 0.405256 loss)
I1007 22:39:00.000967  5322 sgd_solver.cpp:105] Iteration 5100, lr = 0.1
I1007 22:39:25.092916  5322 solver.cpp:218] Iteration 5200 (3.98602 iter/s, 25.0877s/100 iters), loss = 0.295853
I1007 22:39:25.092948  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.295853 (* 1 = 0.295853 loss)
I1007 22:39:25.092955  5322 sgd_solver.cpp:105] Iteration 5200, lr = 0.1
I1007 22:39:49.732476  5322 solver.cpp:218] Iteration 5300 (4.05889 iter/s, 24.6373s/100 iters), loss = 0.439332
I1007 22:39:49.732556  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.439332 (* 1 = 0.439332 loss)
I1007 22:39:49.732564  5322 sgd_solver.cpp:105] Iteration 5300, lr = 0.1
I1007 22:40:14.354010  5322 solver.cpp:218] Iteration 5400 (4.06203 iter/s, 24.6183s/100 iters), loss = 0.399128
I1007 22:40:14.354045  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.399128 (* 1 = 0.399128 loss)
I1007 22:40:14.354053  5322 sgd_solver.cpp:105] Iteration 5400, lr = 0.1
I1007 22:40:38.128098  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1007 22:40:39.111425  5322 solver.cpp:330] Iteration 5500, Testing net (#0)
I1007 22:40:43.766660  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1007 22:40:43.983918  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6951
I1007 22:40:43.983947  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.879006 (* 1 = 0.879006 loss)
I1007 22:40:44.124086  5322 solver.cpp:218] Iteration 5500 (3.35953 iter/s, 29.7661s/100 iters), loss = 0.363174
I1007 22:40:44.124119  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.363174 (* 1 = 0.363174 loss)
I1007 22:40:44.124127  5322 sgd_solver.cpp:105] Iteration 5500, lr = 0.1
I1007 22:41:08.753309  5322 solver.cpp:218] Iteration 5600 (4.06094 iter/s, 24.6248s/100 iters), loss = 0.404959
I1007 22:41:08.753437  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.404959 (* 1 = 0.404959 loss)
I1007 22:41:08.753460  5322 sgd_solver.cpp:105] Iteration 5600, lr = 0.1
I1007 22:41:33.739117  5322 solver.cpp:218] Iteration 5700 (4.00264 iter/s, 24.9835s/100 iters), loss = 0.436339
I1007 22:41:33.739161  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.436339 (* 1 = 0.436339 loss)
I1007 22:41:33.739171  5322 sgd_solver.cpp:105] Iteration 5700, lr = 0.1
I1007 22:41:58.353461  5322 solver.cpp:218] Iteration 5800 (4.06339 iter/s, 24.61s/100 iters), loss = 0.453252
I1007 22:41:58.353551  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.453252 (* 1 = 0.453252 loss)
I1007 22:41:58.353561  5322 sgd_solver.cpp:105] Iteration 5800, lr = 0.1
I1007 22:42:22.959117  5322 solver.cpp:218] Iteration 5900 (4.06484 iter/s, 24.6012s/100 iters), loss = 0.402015
I1007 22:42:22.959151  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.402015 (* 1 = 0.402015 loss)
I1007 22:42:22.959159  5322 sgd_solver.cpp:105] Iteration 5900, lr = 0.1
I1007 22:42:46.733821  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1007 22:42:47.717357  5322 solver.cpp:330] Iteration 6000, Testing net (#0)
I1007 22:42:52.318140  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1007 22:42:52.473347  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.707
I1007 22:42:52.473373  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.8369 (* 1 = 0.8369 loss)
I1007 22:42:52.667951  5322 solver.cpp:218] Iteration 6000 (3.36651 iter/s, 29.7044s/100 iters), loss = 0.338181
I1007 22:42:52.667984  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.338181 (* 1 = 0.338181 loss)
I1007 22:42:52.668000  5322 sgd_solver.cpp:105] Iteration 6000, lr = 0.1
I1007 22:43:17.181391  5322 solver.cpp:218] Iteration 6100 (4.07942 iter/s, 24.5133s/100 iters), loss = 0.233497
I1007 22:43:17.181484  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.233497 (* 1 = 0.233497 loss)
I1007 22:43:17.181493  5322 sgd_solver.cpp:105] Iteration 6100, lr = 0.1
I1007 22:43:42.254017  5322 solver.cpp:218] Iteration 6200 (3.98911 iter/s, 25.0682s/100 iters), loss = 0.393398
I1007 22:43:42.254055  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.393398 (* 1 = 0.393398 loss)
I1007 22:43:42.254061  5322 sgd_solver.cpp:105] Iteration 6200, lr = 0.1
I1007 22:44:06.891757  5322 solver.cpp:218] Iteration 6300 (4.05953 iter/s, 24.6334s/100 iters), loss = 0.451307
I1007 22:44:06.894882  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.451307 (* 1 = 0.451307 loss)
I1007 22:44:06.894901  5322 sgd_solver.cpp:105] Iteration 6300, lr = 0.1
I1007 22:44:31.548064  5322 solver.cpp:218] Iteration 6400 (4.05649 iter/s, 24.6519s/100 iters), loss = 0.472905
I1007 22:44:31.548099  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.472905 (* 1 = 0.472905 loss)
I1007 22:44:31.548108  5322 sgd_solver.cpp:105] Iteration 6400, lr = 0.1
I1007 22:44:55.418354  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1007 22:44:56.401957  5322 solver.cpp:330] Iteration 6500, Testing net (#0)
I1007 22:45:00.967079  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1007 22:45:01.139273  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7591
I1007 22:45:01.139299  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.682077 (* 1 = 0.682077 loss)
I1007 22:45:01.302723  5322 solver.cpp:218] Iteration 6500 (3.36121 iter/s, 29.7512s/100 iters), loss = 0.34205
I1007 22:45:01.302759  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.34205 (* 1 = 0.34205 loss)
I1007 22:45:01.302767  5322 sgd_solver.cpp:105] Iteration 6500, lr = 0.1
I1007 22:45:25.906843  5322 solver.cpp:218] Iteration 6600 (4.06474 iter/s, 24.6018s/100 iters), loss = 0.352961
I1007 22:45:25.906942  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.352961 (* 1 = 0.352961 loss)
I1007 22:45:25.906954  5322 sgd_solver.cpp:105] Iteration 6600, lr = 0.1
I1007 22:45:51.000008  5322 solver.cpp:218] Iteration 6700 (3.98551 iter/s, 25.0909s/100 iters), loss = 0.344717
I1007 22:45:51.000038  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.344717 (* 1 = 0.344717 loss)
I1007 22:45:51.000046  5322 sgd_solver.cpp:105] Iteration 6700, lr = 0.1
I1007 22:46:15.648000  5322 solver.cpp:218] Iteration 6800 (4.05777 iter/s, 24.6441s/100 iters), loss = 0.315858
I1007 22:46:15.648084  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.315858 (* 1 = 0.315858 loss)
I1007 22:46:15.648093  5322 sgd_solver.cpp:105] Iteration 6800, lr = 0.1
I1007 22:46:40.311050  5322 solver.cpp:218] Iteration 6900 (4.05538 iter/s, 24.6586s/100 iters), loss = 0.39084
I1007 22:46:40.311094  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.39084 (* 1 = 0.39084 loss)
I1007 22:46:40.311101  5322 sgd_solver.cpp:105] Iteration 6900, lr = 0.1
I1007 22:47:04.106667  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1007 22:47:05.089234  5322 solver.cpp:330] Iteration 7000, Testing net (#0)
I1007 22:47:09.652776  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1007 22:47:09.835610  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7925
I1007 22:47:09.835638  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.580512 (* 1 = 0.580512 loss)
I1007 22:47:09.986862  5322 solver.cpp:218] Iteration 7000 (3.37001 iter/s, 29.6735s/100 iters), loss = 0.362669
I1007 22:47:09.986896  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.362669 (* 1 = 0.362669 loss)
I1007 22:47:09.986917  5322 sgd_solver.cpp:105] Iteration 7000, lr = 0.1
I1007 22:47:34.594148  5322 solver.cpp:218] Iteration 7100 (4.06421 iter/s, 24.605s/100 iters), loss = 0.316481
I1007 22:47:34.594218  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.316481 (* 1 = 0.316481 loss)
I1007 22:47:34.594228  5322 sgd_solver.cpp:105] Iteration 7100, lr = 0.1
I1007 22:47:59.547896  5322 solver.cpp:218] Iteration 7200 (4.00802 iter/s, 24.95s/100 iters), loss = 0.394069
I1007 22:47:59.547930  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.394069 (* 1 = 0.394069 loss)
I1007 22:47:59.547937  5322 sgd_solver.cpp:105] Iteration 7200, lr = 0.1
I1007 22:48:24.175595  5322 solver.cpp:218] Iteration 7300 (4.06119 iter/s, 24.6233s/100 iters), loss = 0.336648
I1007 22:48:24.175676  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.336648 (* 1 = 0.336648 loss)
I1007 22:48:24.175685  5322 sgd_solver.cpp:105] Iteration 7300, lr = 0.1
I1007 22:48:48.806017  5322 solver.cpp:218] Iteration 7400 (4.06039 iter/s, 24.6282s/100 iters), loss = 0.319484
I1007 22:48:48.806062  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.319484 (* 1 = 0.319484 loss)
I1007 22:48:48.806069  5322 sgd_solver.cpp:105] Iteration 7400, lr = 0.1
I1007 22:49:12.608860  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1007 22:49:13.592200  5322 solver.cpp:330] Iteration 7500, Testing net (#0)
I1007 22:49:18.132578  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1007 22:49:18.310719  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7799
I1007 22:49:18.310745  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.645709 (* 1 = 0.645709 loss)
I1007 22:49:18.491739  5322 solver.cpp:218] Iteration 7500 (3.36912 iter/s, 29.6813s/100 iters), loss = 0.324327
I1007 22:49:18.491768  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.324327 (* 1 = 0.324327 loss)
I1007 22:49:18.491775  5322 sgd_solver.cpp:105] Iteration 7500, lr = 0.1
I1007 22:49:43.147404  5322 solver.cpp:218] Iteration 7600 (4.05623 iter/s, 24.6534s/100 iters), loss = 0.357314
I1007 22:49:43.147500  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.357314 (* 1 = 0.357314 loss)
I1007 22:49:43.147509  5322 sgd_solver.cpp:105] Iteration 7600, lr = 0.1
I1007 22:50:08.284827  5322 solver.cpp:218] Iteration 7700 (3.97849 iter/s, 25.1352s/100 iters), loss = 0.347857
I1007 22:50:08.284865  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.347857 (* 1 = 0.347857 loss)
I1007 22:50:08.284873  5322 sgd_solver.cpp:105] Iteration 7700, lr = 0.1
I1007 22:50:32.946070  5322 solver.cpp:218] Iteration 7800 (4.05557 iter/s, 24.6574s/100 iters), loss = 0.385561
I1007 22:50:32.946140  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.38556 (* 1 = 0.38556 loss)
I1007 22:50:32.946147  5322 sgd_solver.cpp:105] Iteration 7800, lr = 0.1
I1007 22:50:57.599925  5322 solver.cpp:218] Iteration 7900 (4.05654 iter/s, 24.6516s/100 iters), loss = 0.330836
I1007 22:50:57.599961  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.330836 (* 1 = 0.330836 loss)
I1007 22:50:57.599967  5322 sgd_solver.cpp:105] Iteration 7900, lr = 0.1
I1007 22:51:21.476549  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1007 22:51:22.459549  5322 solver.cpp:330] Iteration 8000, Testing net (#0)
I1007 22:51:27.078275  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1007 22:51:27.260978  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8204
I1007 22:51:27.261008  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.519353 (* 1 = 0.519353 loss)
I1007 22:51:27.420943  5322 solver.cpp:218] Iteration 8000 (3.3536 iter/s, 29.8187s/100 iters), loss = 0.273982
I1007 22:51:27.420976  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.273982 (* 1 = 0.273982 loss)
I1007 22:51:27.420994  5322 sgd_solver.cpp:105] Iteration 8000, lr = 0.1
I1007 22:51:52.128619  5322 solver.cpp:218] Iteration 8100 (4.0477 iter/s, 24.7054s/100 iters), loss = 0.331885
I1007 22:51:52.128684  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.331885 (* 1 = 0.331885 loss)
I1007 22:51:52.128692  5322 sgd_solver.cpp:105] Iteration 8100, lr = 0.1
I1007 22:52:17.151276  5322 solver.cpp:218] Iteration 8200 (3.99699 iter/s, 25.0188s/100 iters), loss = 0.290421
I1007 22:52:17.151314  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.290421 (* 1 = 0.290421 loss)
I1007 22:52:17.151322  5322 sgd_solver.cpp:105] Iteration 8200, lr = 0.1
I1007 22:52:41.768712  5322 solver.cpp:218] Iteration 8300 (4.06276 iter/s, 24.6138s/100 iters), loss = 0.32826
I1007 22:52:41.768807  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.32826 (* 1 = 0.32826 loss)
I1007 22:52:41.768831  5322 sgd_solver.cpp:105] Iteration 8300, lr = 0.1
I1007 22:53:06.409003  5322 solver.cpp:218] Iteration 8400 (4.05905 iter/s, 24.6363s/100 iters), loss = 0.278105
I1007 22:53:06.409039  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.278104 (* 1 = 0.278104 loss)
I1007 22:53:06.409046  5322 sgd_solver.cpp:105] Iteration 8400, lr = 0.1
I1007 22:53:30.184877  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1007 22:53:31.166785  5322 solver.cpp:330] Iteration 8500, Testing net (#0)
I1007 22:53:35.653885  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1007 22:53:35.871425  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7717
I1007 22:53:35.871451  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.676189 (* 1 = 0.676189 loss)
I1007 22:53:36.005301  5322 solver.cpp:218] Iteration 8500 (3.37924 iter/s, 29.5925s/100 iters), loss = 0.2498
I1007 22:53:36.005343  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.2498 (* 1 = 0.2498 loss)
I1007 22:53:36.005352  5322 sgd_solver.cpp:105] Iteration 8500, lr = 0.1
I1007 22:54:00.655493  5322 solver.cpp:218] Iteration 8600 (4.05749 iter/s, 24.6458s/100 iters), loss = 0.340886
I1007 22:54:00.655581  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.340886 (* 1 = 0.340886 loss)
I1007 22:54:00.655591  5322 sgd_solver.cpp:105] Iteration 8600, lr = 0.1
I1007 22:54:25.745983  5322 solver.cpp:218] Iteration 8700 (3.98625 iter/s, 25.0862s/100 iters), loss = 0.368864
I1007 22:54:25.746021  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.368864 (* 1 = 0.368864 loss)
I1007 22:54:25.746027  5322 sgd_solver.cpp:105] Iteration 8700, lr = 0.1
I1007 22:54:50.346220  5322 solver.cpp:218] Iteration 8800 (4.06503 iter/s, 24.6001s/100 iters), loss = 0.340973
I1007 22:54:50.346324  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.340973 (* 1 = 0.340973 loss)
I1007 22:54:50.346333  5322 sgd_solver.cpp:105] Iteration 8800, lr = 0.1
I1007 22:55:14.980254  5322 solver.cpp:218] Iteration 8900 (4.06016 iter/s, 24.6296s/100 iters), loss = 0.370991
I1007 22:55:14.980299  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.370991 (* 1 = 0.370991 loss)
I1007 22:55:14.980306  5322 sgd_solver.cpp:105] Iteration 8900, lr = 0.1
I1007 22:55:38.748304  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1007 22:55:39.734372  5322 solver.cpp:330] Iteration 9000, Testing net (#0)
I1007 22:55:44.371417  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1007 22:55:44.582232  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8075
I1007 22:55:44.582257  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.588038 (* 1 = 0.588038 loss)
I1007 22:55:44.714740  5322 solver.cpp:218] Iteration 9000 (3.36352 iter/s, 29.7308s/100 iters), loss = 0.267868
I1007 22:55:44.714781  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.267868 (* 1 = 0.267868 loss)
I1007 22:55:44.714790  5322 sgd_solver.cpp:105] Iteration 9000, lr = 0.1
I1007 22:56:09.394578  5322 solver.cpp:218] Iteration 9100 (4.05226 iter/s, 24.6776s/100 iters), loss = 0.312045
I1007 22:56:09.394656  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.312045 (* 1 = 0.312045 loss)
I1007 22:56:09.394665  5322 sgd_solver.cpp:105] Iteration 9100, lr = 0.1
I1007 22:56:34.454833  5322 solver.cpp:218] Iteration 9200 (3.99101 iter/s, 25.0563s/100 iters), loss = 0.398218
I1007 22:56:34.454870  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.398218 (* 1 = 0.398218 loss)
I1007 22:56:34.454880  5322 sgd_solver.cpp:105] Iteration 9200, lr = 0.1
I1007 22:56:59.084738  5322 solver.cpp:218] Iteration 9300 (4.06077 iter/s, 24.6259s/100 iters), loss = 0.315772
I1007 22:56:59.084815  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.315772 (* 1 = 0.315772 loss)
I1007 22:56:59.084825  5322 sgd_solver.cpp:105] Iteration 9300, lr = 0.1
I1007 22:57:23.723932  5322 solver.cpp:218] Iteration 9400 (4.05895 iter/s, 24.6369s/100 iters), loss = 0.258419
I1007 22:57:23.723978  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.258419 (* 1 = 0.258419 loss)
I1007 22:57:23.723987  5322 sgd_solver.cpp:105] Iteration 9400, lr = 0.1
I1007 22:57:47.503604  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1007 22:57:48.487609  5322 solver.cpp:330] Iteration 9500, Testing net (#0)
I1007 22:57:53.073689  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1007 22:57:53.233065  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.781
I1007 22:57:53.233095  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.673481 (* 1 = 0.673481 loss)
I1007 22:57:53.422853  5322 solver.cpp:218] Iteration 9500 (3.36748 iter/s, 29.6958s/100 iters), loss = 0.288548
I1007 22:57:53.422888  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.288548 (* 1 = 0.288548 loss)
I1007 22:57:53.422895  5322 sgd_solver.cpp:105] Iteration 9500, lr = 0.1
I1007 22:58:17.978950  5322 solver.cpp:218] Iteration 9600 (4.07269 iter/s, 24.5538s/100 iters), loss = 0.295636
I1007 22:58:17.979032  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.295636 (* 1 = 0.295636 loss)
I1007 22:58:17.979040  5322 sgd_solver.cpp:105] Iteration 9600, lr = 0.1
I1007 22:58:42.978986  5322 solver.cpp:218] Iteration 9700 (4.00059 iter/s, 24.9963s/100 iters), loss = 0.374524
I1007 22:58:42.979019  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.374524 (* 1 = 0.374524 loss)
I1007 22:58:42.979027  5322 sgd_solver.cpp:105] Iteration 9700, lr = 0.1
I1007 22:59:07.605685  5322 solver.cpp:218] Iteration 9800 (4.06094 iter/s, 24.6248s/100 iters), loss = 0.269504
I1007 22:59:07.605798  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.269504 (* 1 = 0.269504 loss)
I1007 22:59:07.605816  5322 sgd_solver.cpp:105] Iteration 9800, lr = 0.1
I1007 22:59:32.240057  5322 solver.cpp:218] Iteration 9900 (4.05974 iter/s, 24.6321s/100 iters), loss = 0.253315
I1007 22:59:32.240098  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.253315 (* 1 = 0.253315 loss)
I1007 22:59:32.240108  5322 sgd_solver.cpp:105] Iteration 9900, lr = 0.1
I1007 22:59:56.092847  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1007 22:59:57.077690  5322 solver.cpp:330] Iteration 10000, Testing net (#0)
I1007 23:00:01.655577  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:00:01.808190  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.821
I1007 23:00:01.808218  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.520354 (* 1 = 0.520354 loss)
I1007 23:00:01.997505  5322 solver.cpp:218] Iteration 10000 (3.36094 iter/s, 29.7536s/100 iters), loss = 0.290655
I1007 23:00:01.997539  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.290655 (* 1 = 0.290655 loss)
I1007 23:00:01.997546  5322 sgd_solver.cpp:105] Iteration 10000, lr = 0.1
I1007 23:00:26.578694  5322 solver.cpp:218] Iteration 10100 (4.06853 iter/s, 24.5789s/100 iters), loss = 0.399404
I1007 23:00:26.578766  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.399404 (* 1 = 0.399404 loss)
I1007 23:00:26.578774  5322 sgd_solver.cpp:105] Iteration 10100, lr = 0.1
I1007 23:00:51.534610  5322 solver.cpp:218] Iteration 10200 (4.00766 iter/s, 24.9522s/100 iters), loss = 0.271586
I1007 23:00:51.534646  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.271586 (* 1 = 0.271586 loss)
I1007 23:00:51.534652  5322 sgd_solver.cpp:105] Iteration 10200, lr = 0.1
I1007 23:01:16.316059  5322 solver.cpp:218] Iteration 10300 (4.036 iter/s, 24.777s/100 iters), loss = 0.438364
I1007 23:01:16.316155  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.438364 (* 1 = 0.438364 loss)
I1007 23:01:16.316179  5322 sgd_solver.cpp:105] Iteration 10300, lr = 0.1
I1007 23:01:40.966573  5322 solver.cpp:218] Iteration 10400 (4.05736 iter/s, 24.6466s/100 iters), loss = 0.293157
I1007 23:01:40.966604  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.293157 (* 1 = 0.293157 loss)
I1007 23:01:40.966611  5322 sgd_solver.cpp:105] Iteration 10400, lr = 0.1
I1007 23:02:04.832659  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:02:05.815485  5322 solver.cpp:330] Iteration 10500, Testing net (#0)
I1007 23:02:10.466526  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:02:10.674796  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8132
I1007 23:02:10.674825  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.549427 (* 1 = 0.549427 loss)
I1007 23:02:10.810786  5322 solver.cpp:218] Iteration 10500 (3.35099 iter/s, 29.8419s/100 iters), loss = 0.267618
I1007 23:02:10.810827  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.267618 (* 1 = 0.267618 loss)
I1007 23:02:10.810834  5322 sgd_solver.cpp:105] Iteration 10500, lr = 0.1
I1007 23:02:35.477250  5322 solver.cpp:218] Iteration 10600 (4.05446 iter/s, 24.6642s/100 iters), loss = 0.357463
I1007 23:02:35.477337  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.357463 (* 1 = 0.357463 loss)
I1007 23:02:35.477349  5322 sgd_solver.cpp:105] Iteration 10600, lr = 0.1
I1007 23:03:00.328486  5322 solver.cpp:218] Iteration 10700 (4.02452 iter/s, 24.8477s/100 iters), loss = 0.269543
I1007 23:03:00.328521  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.269543 (* 1 = 0.269543 loss)
I1007 23:03:00.328528  5322 sgd_solver.cpp:105] Iteration 10700, lr = 0.1
I1007 23:03:25.149163  5322 solver.cpp:218] Iteration 10800 (4.02953 iter/s, 24.8168s/100 iters), loss = 0.358581
I1007 23:03:25.149255  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.358581 (* 1 = 0.358581 loss)
I1007 23:03:25.149263  5322 sgd_solver.cpp:105] Iteration 10800, lr = 0.1
I1007 23:03:49.763906  5322 solver.cpp:218] Iteration 10900 (4.06298 iter/s, 24.6125s/100 iters), loss = 0.313669
I1007 23:03:49.763950  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.313669 (* 1 = 0.313669 loss)
I1007 23:03:49.763957  5322 sgd_solver.cpp:105] Iteration 10900, lr = 0.1
I1007 23:04:13.537894  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:04:14.521890  5322 solver.cpp:330] Iteration 11000, Testing net (#0)
I1007 23:04:19.194033  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:04:19.395332  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7591
I1007 23:04:19.395359  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.759735 (* 1 = 0.759735 loss)
I1007 23:04:19.550472  5322 solver.cpp:218] Iteration 11000 (3.35764 iter/s, 29.7828s/100 iters), loss = 0.242752
I1007 23:04:19.550503  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.242752 (* 1 = 0.242752 loss)
I1007 23:04:19.550509  5322 sgd_solver.cpp:105] Iteration 11000, lr = 0.1
I1007 23:04:44.171936  5322 solver.cpp:218] Iteration 11100 (4.06187 iter/s, 24.6192s/100 iters), loss = 0.324717
I1007 23:04:44.171994  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.324717 (* 1 = 0.324717 loss)
I1007 23:04:44.172003  5322 sgd_solver.cpp:105] Iteration 11100, lr = 0.1
I1007 23:05:08.963335  5322 solver.cpp:218] Iteration 11200 (4.03438 iter/s, 24.787s/100 iters), loss = 0.243205
I1007 23:05:08.963371  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.243205 (* 1 = 0.243205 loss)
I1007 23:05:08.963378  5322 sgd_solver.cpp:105] Iteration 11200, lr = 0.1
I1007 23:05:33.800551  5322 solver.cpp:218] Iteration 11300 (4.02682 iter/s, 24.8335s/100 iters), loss = 0.259024
I1007 23:05:33.800637  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.259024 (* 1 = 0.259024 loss)
I1007 23:05:33.800644  5322 sgd_solver.cpp:105] Iteration 11300, lr = 0.1
I1007 23:05:58.435803  5322 solver.cpp:218] Iteration 11400 (4.05986 iter/s, 24.6314s/100 iters), loss = 0.340053
I1007 23:05:58.435840  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.340053 (* 1 = 0.340053 loss)
I1007 23:05:58.435848  5322 sgd_solver.cpp:105] Iteration 11400, lr = 0.1
I1007 23:06:22.292356  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:06:23.275171  5322 solver.cpp:330] Iteration 11500, Testing net (#0)
I1007 23:06:27.898874  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:06:28.088428  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7674
I1007 23:06:28.088450  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.718504 (* 1 = 0.718504 loss)
I1007 23:06:28.236994  5322 solver.cpp:218] Iteration 11500 (3.35607 iter/s, 29.7968s/100 iters), loss = 0.320097
I1007 23:06:28.237026  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.320097 (* 1 = 0.320097 loss)
I1007 23:06:28.237033  5322 sgd_solver.cpp:105] Iteration 11500, lr = 0.1
I1007 23:06:52.945062  5322 solver.cpp:218] Iteration 11600 (4.04764 iter/s, 24.7058s/100 iters), loss = 0.348123
I1007 23:06:52.945152  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.348123 (* 1 = 0.348123 loss)
I1007 23:06:52.945159  5322 sgd_solver.cpp:105] Iteration 11600, lr = 0.1
I1007 23:07:17.639508  5322 solver.cpp:218] Iteration 11700 (4.04986 iter/s, 24.6922s/100 iters), loss = 0.340955
I1007 23:07:17.639551  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.340955 (* 1 = 0.340955 loss)
I1007 23:07:17.639559  5322 sgd_solver.cpp:105] Iteration 11700, lr = 0.1
I1007 23:07:42.582758  5322 solver.cpp:218] Iteration 11800 (4.00933 iter/s, 24.9418s/100 iters), loss = 0.253881
I1007 23:07:42.582866  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.253881 (* 1 = 0.253881 loss)
I1007 23:07:42.582875  5322 sgd_solver.cpp:105] Iteration 11800, lr = 0.1
I1007 23:08:07.236791  5322 solver.cpp:218] Iteration 11900 (4.05651 iter/s, 24.6517s/100 iters), loss = 0.254695
I1007 23:08:07.236829  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.254695 (* 1 = 0.254695 loss)
I1007 23:08:07.236835  5322 sgd_solver.cpp:105] Iteration 11900, lr = 0.1
I1007 23:08:31.104904  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:08:32.089123  5322 solver.cpp:330] Iteration 12000, Testing net (#0)
I1007 23:08:36.724550  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:08:36.930611  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.819
I1007 23:08:36.930641  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.525467 (* 1 = 0.525467 loss)
I1007 23:08:37.069023  5322 solver.cpp:218] Iteration 12000 (3.35253 iter/s, 29.8282s/100 iters), loss = 0.213
I1007 23:08:37.069056  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.213 (* 1 = 0.213 loss)
I1007 23:08:37.069063  5322 sgd_solver.cpp:105] Iteration 12000, lr = 0.1
I1007 23:09:01.765102  5322 solver.cpp:218] Iteration 12100 (4.0496 iter/s, 24.6938s/100 iters), loss = 0.30945
I1007 23:09:01.765194  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.30945 (* 1 = 0.30945 loss)
I1007 23:09:01.765202  5322 sgd_solver.cpp:105] Iteration 12100, lr = 0.1
I1007 23:09:26.377687  5322 solver.cpp:218] Iteration 12200 (4.06357 iter/s, 24.6089s/100 iters), loss = 0.346655
I1007 23:09:26.377722  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.346655 (* 1 = 0.346655 loss)
I1007 23:09:26.377728  5322 sgd_solver.cpp:105] Iteration 12200, lr = 0.1
I1007 23:09:51.457237  5322 solver.cpp:218] Iteration 12300 (3.98767 iter/s, 25.0773s/100 iters), loss = 0.333311
I1007 23:09:51.457319  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.333311 (* 1 = 0.333311 loss)
I1007 23:09:51.457327  5322 sgd_solver.cpp:105] Iteration 12300, lr = 0.1
I1007 23:10:16.108148  5322 solver.cpp:218] Iteration 12400 (4.05702 iter/s, 24.6487s/100 iters), loss = 0.299271
I1007 23:10:16.108194  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.299271 (* 1 = 0.299271 loss)
I1007 23:10:16.108202  5322 sgd_solver.cpp:105] Iteration 12400, lr = 0.1
I1007 23:10:39.892920  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:10:40.877912  5322 solver.cpp:330] Iteration 12500, Testing net (#0)
I1007 23:10:45.466405  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:10:45.660794  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8377
I1007 23:10:45.660821  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.487379 (* 1 = 0.487379 loss)
I1007 23:10:45.814414  5322 solver.cpp:218] Iteration 12500 (3.36655 iter/s, 29.704s/100 iters), loss = 0.187392
I1007 23:10:45.814447  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.187392 (* 1 = 0.187392 loss)
I1007 23:10:45.814455  5322 sgd_solver.cpp:105] Iteration 12500, lr = 0.1
I1007 23:11:10.376415  5322 solver.cpp:218] Iteration 12600 (4.0717 iter/s, 24.5597s/100 iters), loss = 0.277775
I1007 23:11:10.376505  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.277776 (* 1 = 0.277776 loss)
I1007 23:11:10.376514  5322 sgd_solver.cpp:105] Iteration 12600, lr = 0.1
I1007 23:11:34.998703  5322 solver.cpp:218] Iteration 12700 (4.06173 iter/s, 24.62s/100 iters), loss = 0.308448
I1007 23:11:34.998739  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.308448 (* 1 = 0.308448 loss)
I1007 23:11:34.998746  5322 sgd_solver.cpp:105] Iteration 12700, lr = 0.1
I1007 23:12:00.050405  5322 solver.cpp:218] Iteration 12800 (3.99231 iter/s, 25.0482s/100 iters), loss = 0.287169
I1007 23:12:00.050523  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.287169 (* 1 = 0.287169 loss)
I1007 23:12:00.050534  5322 sgd_solver.cpp:105] Iteration 12800, lr = 0.1
I1007 23:12:24.658653  5322 solver.cpp:218] Iteration 12900 (4.0643 iter/s, 24.6045s/100 iters), loss = 0.300607
I1007 23:12:24.658692  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.300607 (* 1 = 0.300607 loss)
I1007 23:12:24.658702  5322 sgd_solver.cpp:105] Iteration 12900, lr = 0.1
I1007 23:12:48.434835  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:12:49.414216  5322 solver.cpp:330] Iteration 13000, Testing net (#0)
I1007 23:12:53.949463  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:12:54.120007  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7855
I1007 23:12:54.120033  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.661183 (* 1 = 0.661183 loss)
I1007 23:12:54.316707  5322 solver.cpp:218] Iteration 13000 (3.37227 iter/s, 29.6536s/100 iters), loss = 0.220908
I1007 23:12:54.316761  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.220909 (* 1 = 0.220909 loss)
I1007 23:12:54.316772  5322 sgd_solver.cpp:105] Iteration 13000, lr = 0.1
I1007 23:13:18.978457  5322 solver.cpp:218] Iteration 13100 (4.05524 iter/s, 24.6595s/100 iters), loss = 0.271035
I1007 23:13:18.978549  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.271035 (* 1 = 0.271035 loss)
I1007 23:13:18.978557  5322 sgd_solver.cpp:105] Iteration 13100, lr = 0.1
I1007 23:13:43.623842  5322 solver.cpp:218] Iteration 13200 (4.05817 iter/s, 24.6417s/100 iters), loss = 0.42894
I1007 23:13:43.623874  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.42894 (* 1 = 0.42894 loss)
I1007 23:13:43.623881  5322 sgd_solver.cpp:105] Iteration 13200, lr = 0.1
I1007 23:14:08.636186  5322 solver.cpp:218] Iteration 13300 (3.99862 iter/s, 25.0086s/100 iters), loss = 0.269075
I1007 23:14:08.636278  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.269075 (* 1 = 0.269075 loss)
I1007 23:14:08.636291  5322 sgd_solver.cpp:105] Iteration 13300, lr = 0.1
I1007 23:14:33.270215  5322 solver.cpp:218] Iteration 13400 (4.0598 iter/s, 24.6318s/100 iters), loss = 0.295059
I1007 23:14:33.270251  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.295059 (* 1 = 0.295059 loss)
I1007 23:14:33.270259  5322 sgd_solver.cpp:105] Iteration 13400, lr = 0.1
I1007 23:14:57.131234  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:14:58.117214  5322 solver.cpp:330] Iteration 13500, Testing net (#0)
I1007 23:15:02.690207  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:15:02.878139  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8281
I1007 23:15:02.878167  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.500538 (* 1 = 0.500538 loss)
I1007 23:15:03.031123  5322 solver.cpp:218] Iteration 13500 (3.36061 iter/s, 29.7565s/100 iters), loss = 0.209575
I1007 23:15:03.031154  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.209575 (* 1 = 0.209575 loss)
I1007 23:15:03.031162  5322 sgd_solver.cpp:105] Iteration 13500, lr = 0.1
I1007 23:15:27.613668  5322 solver.cpp:218] Iteration 13600 (4.0683 iter/s, 24.5803s/100 iters), loss = 0.326737
I1007 23:15:27.613762  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.326737 (* 1 = 0.326737 loss)
I1007 23:15:27.613780  5322 sgd_solver.cpp:105] Iteration 13600, lr = 0.1
I1007 23:15:52.265465  5322 solver.cpp:218] Iteration 13700 (4.05722 iter/s, 24.6474s/100 iters), loss = 0.357131
I1007 23:15:52.265511  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.357131 (* 1 = 0.357131 loss)
I1007 23:15:52.265518  5322 sgd_solver.cpp:105] Iteration 13700, lr = 0.1
I1007 23:16:17.309439  5322 solver.cpp:218] Iteration 13800 (3.99352 iter/s, 25.0406s/100 iters), loss = 0.344467
I1007 23:16:17.309523  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.344467 (* 1 = 0.344467 loss)
I1007 23:16:17.309531  5322 sgd_solver.cpp:105] Iteration 13800, lr = 0.1
I1007 23:16:41.946399  5322 solver.cpp:218] Iteration 13900 (4.05966 iter/s, 24.6326s/100 iters), loss = 0.271824
I1007 23:16:41.946436  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.271824 (* 1 = 0.271824 loss)
I1007 23:16:41.946454  5322 sgd_solver.cpp:105] Iteration 13900, lr = 0.1
I1007 23:17:05.826055  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:17:06.809568  5322 solver.cpp:330] Iteration 14000, Testing net (#0)
I1007 23:17:11.330245  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:17:11.517238  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8303
I1007 23:17:11.517267  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.505209 (* 1 = 0.505209 loss)
I1007 23:17:11.694717  5322 solver.cpp:218] Iteration 14000 (3.36193 iter/s, 29.7448s/100 iters), loss = 0.190762
I1007 23:17:11.694748  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.190763 (* 1 = 0.190763 loss)
I1007 23:17:11.694756  5322 sgd_solver.cpp:105] Iteration 14000, lr = 0.1
I1007 23:17:36.391788  5322 solver.cpp:218] Iteration 14100 (4.04909 iter/s, 24.6969s/100 iters), loss = 0.209141
I1007 23:17:36.391872  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.209141 (* 1 = 0.209141 loss)
I1007 23:17:36.391880  5322 sgd_solver.cpp:105] Iteration 14100, lr = 0.1
I1007 23:18:01.059478  5322 solver.cpp:218] Iteration 14200 (4.05426 iter/s, 24.6654s/100 iters), loss = 0.3157
I1007 23:18:01.059521  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.3157 (* 1 = 0.3157 loss)
I1007 23:18:01.059528  5322 sgd_solver.cpp:105] Iteration 14200, lr = 0.1
I1007 23:18:26.122221  5322 solver.cpp:218] Iteration 14300 (3.99034 iter/s, 25.0605s/100 iters), loss = 0.257343
I1007 23:18:26.122300  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.257343 (* 1 = 0.257343 loss)
I1007 23:18:26.122308  5322 sgd_solver.cpp:105] Iteration 14300, lr = 0.1
I1007 23:18:50.774405  5322 solver.cpp:218] Iteration 14400 (4.05711 iter/s, 24.6481s/100 iters), loss = 0.30069
I1007 23:18:50.774441  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.30069 (* 1 = 0.30069 loss)
I1007 23:18:50.774448  5322 sgd_solver.cpp:105] Iteration 14400, lr = 0.1
I1007 23:19:14.564227  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:19:15.547152  5322 solver.cpp:330] Iteration 14500, Testing net (#0)
I1007 23:19:20.325340  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:19:20.490160  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8502
I1007 23:19:20.490188  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.448804 (* 1 = 0.448804 loss)
I1007 23:19:20.671555  5322 solver.cpp:218] Iteration 14500 (3.34527 iter/s, 29.8929s/100 iters), loss = 0.242629
I1007 23:19:20.671588  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.242629 (* 1 = 0.242629 loss)
I1007 23:19:20.671596  5322 sgd_solver.cpp:105] Iteration 14500, lr = 0.1
I1007 23:19:45.198972  5322 solver.cpp:218] Iteration 14600 (4.0771 iter/s, 24.5273s/100 iters), loss = 0.228417
I1007 23:19:45.199086  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.228418 (* 1 = 0.228418 loss)
I1007 23:19:45.199100  5322 sgd_solver.cpp:105] Iteration 14600, lr = 0.1
I1007 23:20:09.816332  5322 solver.cpp:218] Iteration 14700 (4.06289 iter/s, 24.613s/100 iters), loss = 0.326634
I1007 23:20:09.816365  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.326634 (* 1 = 0.326634 loss)
I1007 23:20:09.816371  5322 sgd_solver.cpp:105] Iteration 14700, lr = 0.1
I1007 23:20:34.822830  5322 solver.cpp:218] Iteration 14800 (3.99959 iter/s, 25.0025s/100 iters), loss = 0.285107
I1007 23:20:34.822909  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.285107 (* 1 = 0.285107 loss)
I1007 23:20:34.822917  5322 sgd_solver.cpp:105] Iteration 14800, lr = 0.1
I1007 23:20:59.441098  5322 solver.cpp:218] Iteration 14900 (4.06269 iter/s, 24.6142s/100 iters), loss = 0.247685
I1007 23:20:59.441133  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.247685 (* 1 = 0.247685 loss)
I1007 23:20:59.441141  5322 sgd_solver.cpp:105] Iteration 14900, lr = 0.1
I1007 23:21:23.208616  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:21:24.190284  5322 solver.cpp:330] Iteration 15000, Testing net (#0)
I1007 23:21:28.827558  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:21:29.015555  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8333
I1007 23:21:29.015581  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.514199 (* 1 = 0.514199 loss)
I1007 23:21:29.167865  5322 solver.cpp:218] Iteration 15000 (3.36435 iter/s, 29.7234s/100 iters), loss = 0.277233
I1007 23:21:29.167896  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.277233 (* 1 = 0.277233 loss)
I1007 23:21:29.167904  5322 sgd_solver.cpp:105] Iteration 15000, lr = 0.1
I1007 23:21:53.852520  5322 solver.cpp:218] Iteration 15100 (4.05113 iter/s, 24.6845s/100 iters), loss = 0.350147
I1007 23:21:53.852624  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.350147 (* 1 = 0.350147 loss)
I1007 23:21:53.852648  5322 sgd_solver.cpp:105] Iteration 15100, lr = 0.1
I1007 23:22:18.513592  5322 solver.cpp:218] Iteration 15200 (4.05556 iter/s, 24.6575s/100 iters), loss = 0.299135
I1007 23:22:18.513628  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.299135 (* 1 = 0.299135 loss)
I1007 23:22:18.513648  5322 sgd_solver.cpp:105] Iteration 15200, lr = 0.1
I1007 23:22:43.591470  5322 solver.cpp:218] Iteration 15300 (3.98818 iter/s, 25.0741s/100 iters), loss = 0.292479
I1007 23:22:43.591539  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.292479 (* 1 = 0.292479 loss)
I1007 23:22:43.591557  5322 sgd_solver.cpp:105] Iteration 15300, lr = 0.1
I1007 23:23:08.226243  5322 solver.cpp:218] Iteration 15400 (4.05984 iter/s, 24.6315s/100 iters), loss = 0.207363
I1007 23:23:08.226274  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.207363 (* 1 = 0.207363 loss)
I1007 23:23:08.226282  5322 sgd_solver.cpp:105] Iteration 15400, lr = 0.1
I1007 23:23:31.923856  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:23:32.904209  5322 solver.cpp:330] Iteration 15500, Testing net (#0)
I1007 23:23:37.518754  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:23:37.681946  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8177
I1007 23:23:37.681973  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.555987 (* 1 = 0.555987 loss)
I1007 23:23:37.861531  5322 solver.cpp:218] Iteration 15500 (3.37485 iter/s, 29.6309s/100 iters), loss = 0.200123
I1007 23:23:37.861562  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.200123 (* 1 = 0.200123 loss)
I1007 23:23:37.861568  5322 sgd_solver.cpp:105] Iteration 15500, lr = 0.1
I1007 23:24:02.390014  5322 solver.cpp:218] Iteration 15600 (4.07692 iter/s, 24.5283s/100 iters), loss = 0.229308
I1007 23:24:02.390105  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.229308 (* 1 = 0.229308 loss)
I1007 23:24:02.390115  5322 sgd_solver.cpp:105] Iteration 15600, lr = 0.1
I1007 23:24:27.014202  5322 solver.cpp:218] Iteration 15700 (4.06177 iter/s, 24.6198s/100 iters), loss = 0.297538
I1007 23:24:27.014237  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.297539 (* 1 = 0.297539 loss)
I1007 23:24:27.014245  5322 sgd_solver.cpp:105] Iteration 15700, lr = 0.1
I1007 23:24:52.086347  5322 solver.cpp:218] Iteration 15800 (3.98919 iter/s, 25.0677s/100 iters), loss = 0.253346
I1007 23:24:52.086428  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.253346 (* 1 = 0.253346 loss)
I1007 23:24:52.086436  5322 sgd_solver.cpp:105] Iteration 15800, lr = 0.1
I1007 23:25:16.718909  5322 solver.cpp:218] Iteration 15900 (4.06031 iter/s, 24.6287s/100 iters), loss = 0.19136
I1007 23:25:16.718942  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.19136 (* 1 = 0.19136 loss)
I1007 23:25:16.718950  5322 sgd_solver.cpp:105] Iteration 15900, lr = 0.1
I1007 23:25:40.594421  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:25:41.578881  5322 solver.cpp:330] Iteration 16000, Testing net (#0)
I1007 23:25:46.213695  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:25:46.395453  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.832
I1007 23:25:46.395481  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.49758 (* 1 = 0.49758 loss)
I1007 23:25:46.535579  5322 solver.cpp:218] Iteration 16000 (3.35408 iter/s, 29.8144s/100 iters), loss = 0.265773
I1007 23:25:46.535634  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.265774 (* 1 = 0.265774 loss)
I1007 23:25:46.535643  5322 sgd_solver.cpp:105] Iteration 16000, lr = 0.1
I1007 23:26:11.067031  5322 solver.cpp:218] Iteration 16100 (4.07677 iter/s, 24.5292s/100 iters), loss = 0.203697
I1007 23:26:11.067121  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.203697 (* 1 = 0.203697 loss)
I1007 23:26:11.067129  5322 sgd_solver.cpp:105] Iteration 16100, lr = 0.1
I1007 23:26:35.697708  5322 solver.cpp:218] Iteration 16200 (4.06064 iter/s, 24.6267s/100 iters), loss = 0.314264
I1007 23:26:35.697743  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.314264 (* 1 = 0.314264 loss)
I1007 23:26:35.697751  5322 sgd_solver.cpp:105] Iteration 16200, lr = 0.1
I1007 23:27:00.779527  5322 solver.cpp:218] Iteration 16300 (3.98765 iter/s, 25.0774s/100 iters), loss = 0.311614
I1007 23:27:00.779633  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.311614 (* 1 = 0.311614 loss)
I1007 23:27:00.779642  5322 sgd_solver.cpp:105] Iteration 16300, lr = 0.1
I1007 23:27:25.397974  5322 solver.cpp:218] Iteration 16400 (4.06257 iter/s, 24.615s/100 iters), loss = 0.227235
I1007 23:27:25.398005  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.227235 (* 1 = 0.227235 loss)
I1007 23:27:25.398010  5322 sgd_solver.cpp:105] Iteration 16400, lr = 0.1
I1007 23:27:49.275081  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:27:50.254510  5322 solver.cpp:330] Iteration 16500, Testing net (#0)
I1007 23:27:54.920919  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:27:55.115705  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8406
I1007 23:27:55.115731  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.474597 (* 1 = 0.474597 loss)
I1007 23:27:55.274335  5322 solver.cpp:218] Iteration 16500 (3.34755 iter/s, 29.8726s/100 iters), loss = 0.261626
I1007 23:27:55.274368  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.261626 (* 1 = 0.261626 loss)
I1007 23:27:55.274374  5322 sgd_solver.cpp:105] Iteration 16500, lr = 0.1
I1007 23:28:19.909070  5322 solver.cpp:218] Iteration 16600 (4.05968 iter/s, 24.6325s/100 iters), loss = 0.217672
I1007 23:28:19.909160  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.217672 (* 1 = 0.217672 loss)
I1007 23:28:19.909168  5322 sgd_solver.cpp:105] Iteration 16600, lr = 0.1
I1007 23:28:44.544610  5322 solver.cpp:218] Iteration 16700 (4.0599 iter/s, 24.6312s/100 iters), loss = 0.260894
I1007 23:28:44.544641  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.260894 (* 1 = 0.260894 loss)
I1007 23:28:44.544648  5322 sgd_solver.cpp:105] Iteration 16700, lr = 0.1
I1007 23:29:09.613080  5322 solver.cpp:218] Iteration 16800 (3.98943 iter/s, 25.0662s/100 iters), loss = 0.293372
I1007 23:29:09.613176  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.293372 (* 1 = 0.293372 loss)
I1007 23:29:09.613186  5322 sgd_solver.cpp:105] Iteration 16800, lr = 0.1
I1007 23:29:34.248442  5322 solver.cpp:218] Iteration 16900 (4.05958 iter/s, 24.6331s/100 iters), loss = 0.209973
I1007 23:29:34.248486  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.209974 (* 1 = 0.209974 loss)
I1007 23:29:34.248493  5322 sgd_solver.cpp:105] Iteration 16900, lr = 0.1
I1007 23:29:58.127251  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:29:59.108494  5322 solver.cpp:330] Iteration 17000, Testing net (#0)
I1007 23:30:03.754289  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:30:03.950001  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7662
I1007 23:30:03.950028  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.733433 (* 1 = 0.733433 loss)
I1007 23:30:04.101083  5322 solver.cpp:218] Iteration 17000 (3.35004 iter/s, 29.8504s/100 iters), loss = 0.272987
I1007 23:30:04.101114  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.272988 (* 1 = 0.272988 loss)
I1007 23:30:04.101121  5322 sgd_solver.cpp:105] Iteration 17000, lr = 0.1
I1007 23:30:28.792191  5322 solver.cpp:218] Iteration 17100 (4.05041 iter/s, 24.6889s/100 iters), loss = 0.272991
I1007 23:30:28.792259  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.272991 (* 1 = 0.272991 loss)
I1007 23:30:28.792268  5322 sgd_solver.cpp:105] Iteration 17100, lr = 0.1
I1007 23:30:53.458109  5322 solver.cpp:218] Iteration 17200 (4.05482 iter/s, 24.662s/100 iters), loss = 0.246105
I1007 23:30:53.458155  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.246105 (* 1 = 0.246105 loss)
I1007 23:30:53.458163  5322 sgd_solver.cpp:105] Iteration 17200, lr = 0.1
I1007 23:31:18.532640  5322 solver.cpp:218] Iteration 17300 (3.98881 iter/s, 25.0701s/100 iters), loss = 0.320088
I1007 23:31:18.532728  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.320089 (* 1 = 0.320089 loss)
I1007 23:31:18.532737  5322 sgd_solver.cpp:105] Iteration 17300, lr = 0.1
I1007 23:31:43.167277  5322 solver.cpp:218] Iteration 17400 (4.0599 iter/s, 24.6312s/100 iters), loss = 0.218083
I1007 23:31:43.167313  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.218083 (* 1 = 0.218083 loss)
I1007 23:31:43.167321  5322 sgd_solver.cpp:105] Iteration 17400, lr = 0.1
I1007 23:32:06.970857  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:32:07.954629  5322 solver.cpp:330] Iteration 17500, Testing net (#0)
I1007 23:32:12.575793  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:32:12.738780  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8193
I1007 23:32:12.738808  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.55397 (* 1 = 0.55397 loss)
I1007 23:32:12.914891  5322 solver.cpp:218] Iteration 17500 (3.36212 iter/s, 29.7432s/100 iters), loss = 0.228766
I1007 23:32:12.914935  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.228767 (* 1 = 0.228767 loss)
I1007 23:32:12.914942  5322 sgd_solver.cpp:105] Iteration 17500, lr = 0.1
I1007 23:32:37.460150  5322 solver.cpp:218] Iteration 17600 (4.07413 iter/s, 24.5451s/100 iters), loss = 0.298272
I1007 23:32:37.460232  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.298273 (* 1 = 0.298273 loss)
I1007 23:32:37.460242  5322 sgd_solver.cpp:105] Iteration 17600, lr = 0.1
I1007 23:33:02.110147  5322 solver.cpp:218] Iteration 17700 (4.05736 iter/s, 24.6465s/100 iters), loss = 0.34666
I1007 23:33:02.110183  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.346661 (* 1 = 0.346661 loss)
I1007 23:33:02.110190  5322 sgd_solver.cpp:105] Iteration 17700, lr = 0.1
I1007 23:33:27.204478  5322 solver.cpp:218] Iteration 17800 (3.98566 iter/s, 25.0899s/100 iters), loss = 0.286278
I1007 23:33:27.204568  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.286279 (* 1 = 0.286279 loss)
I1007 23:33:27.204578  5322 sgd_solver.cpp:105] Iteration 17800, lr = 0.1
I1007 23:33:51.871114  5322 solver.cpp:218] Iteration 17900 (4.05473 iter/s, 24.6625s/100 iters), loss = 0.276427
I1007 23:33:51.871150  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.276427 (* 1 = 0.276427 loss)
I1007 23:33:51.871170  5322 sgd_solver.cpp:105] Iteration 17900, lr = 0.1
I1007 23:34:15.670277  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:34:16.655803  5322 solver.cpp:330] Iteration 18000, Testing net (#0)
I1007 23:34:21.223748  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:34:21.402935  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8182
I1007 23:34:21.402962  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.53045 (* 1 = 0.53045 loss)
I1007 23:34:21.561116  5322 solver.cpp:218] Iteration 18000 (3.36839 iter/s, 29.6877s/100 iters), loss = 0.279178
I1007 23:34:21.561158  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.279178 (* 1 = 0.279178 loss)
I1007 23:34:21.561166  5322 sgd_solver.cpp:105] Iteration 18000, lr = 0.1
I1007 23:34:46.179625  5322 solver.cpp:218] Iteration 18100 (4.06236 iter/s, 24.6162s/100 iters), loss = 0.208056
I1007 23:34:46.179723  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.208057 (* 1 = 0.208057 loss)
I1007 23:34:46.179733  5322 sgd_solver.cpp:105] Iteration 18100, lr = 0.1
I1007 23:35:10.836395  5322 solver.cpp:218] Iteration 18200 (4.05627 iter/s, 24.6532s/100 iters), loss = 0.386037
I1007 23:35:10.836427  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.386037 (* 1 = 0.386037 loss)
I1007 23:35:10.836434  5322 sgd_solver.cpp:105] Iteration 18200, lr = 0.1
I1007 23:35:35.892325  5322 solver.cpp:218] Iteration 18300 (3.99163 iter/s, 25.0524s/100 iters), loss = 0.268649
I1007 23:35:35.892423  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.26865 (* 1 = 0.26865 loss)
I1007 23:35:35.892442  5322 sgd_solver.cpp:105] Iteration 18300, lr = 0.1
I1007 23:36:00.547431  5322 solver.cpp:218] Iteration 18400 (4.05669 iter/s, 24.6507s/100 iters), loss = 0.194568
I1007 23:36:00.547474  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.194569 (* 1 = 0.194569 loss)
I1007 23:36:00.547482  5322 sgd_solver.cpp:105] Iteration 18400, lr = 0.1
I1007 23:36:24.338860  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:36:25.322222  5322 solver.cpp:330] Iteration 18500, Testing net (#0)
I1007 23:36:29.876133  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:36:30.050369  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8295
I1007 23:36:30.050395  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.510389 (* 1 = 0.510389 loss)
I1007 23:36:30.224612  5322 solver.cpp:218] Iteration 18500 (3.37009 iter/s, 29.6728s/100 iters), loss = 0.224395
I1007 23:36:30.224644  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.224395 (* 1 = 0.224395 loss)
I1007 23:36:30.224651  5322 sgd_solver.cpp:105] Iteration 18500, lr = 0.1
I1007 23:36:54.809896  5322 solver.cpp:218] Iteration 18600 (4.06785 iter/s, 24.583s/100 iters), loss = 0.213793
I1007 23:36:54.809986  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.213793 (* 1 = 0.213793 loss)
I1007 23:36:54.809999  5322 sgd_solver.cpp:105] Iteration 18600, lr = 0.1
I1007 23:37:19.422850  5322 solver.cpp:218] Iteration 18700 (4.06327 iter/s, 24.6107s/100 iters), loss = 0.388729
I1007 23:37:19.422885  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.38873 (* 1 = 0.38873 loss)
I1007 23:37:19.422893  5322 sgd_solver.cpp:105] Iteration 18700, lr = 0.1
I1007 23:37:44.490501  5322 solver.cpp:218] Iteration 18800 (3.98991 iter/s, 25.0632s/100 iters), loss = 0.223769
I1007 23:37:44.490603  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.223769 (* 1 = 0.223769 loss)
I1007 23:37:44.490614  5322 sgd_solver.cpp:105] Iteration 18800, lr = 0.1
I1007 23:38:09.121165  5322 solver.cpp:218] Iteration 18900 (4.0607 iter/s, 24.6263s/100 iters), loss = 0.188972
I1007 23:38:09.121203  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.188972 (* 1 = 0.188972 loss)
I1007 23:38:09.121210  5322 sgd_solver.cpp:105] Iteration 18900, lr = 0.1
I1007 23:38:32.920173  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:38:33.907140  5322 solver.cpp:330] Iteration 19000, Testing net (#0)
I1007 23:38:38.399904  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:38:38.613718  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8465
I1007 23:38:38.613745  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.436488 (* 1 = 0.436488 loss)
I1007 23:38:38.753285  5322 solver.cpp:218] Iteration 19000 (3.37522 iter/s, 29.6277s/100 iters), loss = 0.172797
I1007 23:38:38.753322  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.172797 (* 1 = 0.172797 loss)
I1007 23:38:38.753331  5322 sgd_solver.cpp:105] Iteration 19000, lr = 0.1
I1007 23:39:03.379758  5322 solver.cpp:218] Iteration 19100 (4.0614 iter/s, 24.6221s/100 iters), loss = 0.283336
I1007 23:39:03.379923  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.283336 (* 1 = 0.283336 loss)
I1007 23:39:03.379935  5322 sgd_solver.cpp:105] Iteration 19100, lr = 0.1
I1007 23:39:28.030568  5322 solver.cpp:218] Iteration 19200 (4.05739 iter/s, 24.6464s/100 iters), loss = 0.307232
I1007 23:39:28.030606  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.307232 (* 1 = 0.307232 loss)
I1007 23:39:28.030613  5322 sgd_solver.cpp:105] Iteration 19200, lr = 0.1
I1007 23:39:53.101296  5322 solver.cpp:218] Iteration 19300 (3.98942 iter/s, 25.0663s/100 iters), loss = 0.217463
I1007 23:39:53.101379  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.217463 (* 1 = 0.217463 loss)
I1007 23:39:53.101387  5322 sgd_solver.cpp:105] Iteration 19300, lr = 0.1
I1007 23:40:17.769197  5322 solver.cpp:218] Iteration 19400 (4.05422 iter/s, 24.6656s/100 iters), loss = 0.184351
I1007 23:40:17.769243  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.184351 (* 1 = 0.184351 loss)
I1007 23:40:17.769249  5322 sgd_solver.cpp:105] Iteration 19400, lr = 0.1
I1007 23:40:41.499581  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:40:42.487028  5322 solver.cpp:330] Iteration 19500, Testing net (#0)
I1007 23:40:47.002229  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:40:47.190732  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8473
I1007 23:40:47.190762  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.44212 (* 1 = 0.44212 loss)
I1007 23:40:47.369997  5322 solver.cpp:218] Iteration 19500 (3.37855 iter/s, 29.5985s/100 iters), loss = 0.249511
I1007 23:40:47.370031  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.249512 (* 1 = 0.249512 loss)
I1007 23:40:47.370039  5322 sgd_solver.cpp:105] Iteration 19500, lr = 0.1
I1007 23:41:12.074005  5322 solver.cpp:218] Iteration 19600 (4.04795 iter/s, 24.7039s/100 iters), loss = 0.151133
I1007 23:41:12.074098  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.151134 (* 1 = 0.151134 loss)
I1007 23:41:12.074108  5322 sgd_solver.cpp:105] Iteration 19600, lr = 0.1
I1007 23:41:36.733191  5322 solver.cpp:218] Iteration 19700 (4.05592 iter/s, 24.6553s/100 iters), loss = 0.308513
I1007 23:41:36.733227  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.308513 (* 1 = 0.308513 loss)
I1007 23:41:36.733233  5322 sgd_solver.cpp:105] Iteration 19700, lr = 0.1
I1007 23:42:01.834017  5322 solver.cpp:218] Iteration 19800 (3.98454 iter/s, 25.097s/100 iters), loss = 0.22997
I1007 23:42:01.834100  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.229971 (* 1 = 0.229971 loss)
I1007 23:42:01.834108  5322 sgd_solver.cpp:105] Iteration 19800, lr = 0.1
I1007 23:42:26.478415  5322 solver.cpp:218] Iteration 19900 (4.05809 iter/s, 24.6421s/100 iters), loss = 0.139784
I1007 23:42:26.478448  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.139784 (* 1 = 0.139784 loss)
I1007 23:42:26.478456  5322 sgd_solver.cpp:105] Iteration 19900, lr = 0.1
I1007 23:42:50.366438  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:42:51.350108  5322 solver.cpp:330] Iteration 20000, Testing net (#0)
I1007 23:42:55.926367  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:42:56.086046  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8396
I1007 23:42:56.086072  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.469901 (* 1 = 0.469901 loss)
I1007 23:42:56.273527  5322 solver.cpp:218] Iteration 20000 (3.35675 iter/s, 29.7907s/100 iters), loss = 0.281821
I1007 23:42:56.273574  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.281821 (* 1 = 0.281821 loss)
I1007 23:42:56.273581  5322 sgd_solver.cpp:105] Iteration 20000, lr = 0.1
I1007 23:43:20.841644  5322 solver.cpp:218] Iteration 20100 (4.07069 iter/s, 24.5659s/100 iters), loss = 0.212209
I1007 23:43:20.841745  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.21221 (* 1 = 0.21221 loss)
I1007 23:43:20.841753  5322 sgd_solver.cpp:105] Iteration 20100, lr = 0.1
I1007 23:43:45.487782  5322 solver.cpp:218] Iteration 20200 (4.05816 iter/s, 24.6417s/100 iters), loss = 0.35004
I1007 23:43:45.487825  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.350041 (* 1 = 0.350041 loss)
I1007 23:43:45.487833  5322 sgd_solver.cpp:105] Iteration 20200, lr = 0.1
I1007 23:44:10.476111  5322 solver.cpp:218] Iteration 20300 (4.00253 iter/s, 24.9842s/100 iters), loss = 0.249504
I1007 23:44:10.476200  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.249504 (* 1 = 0.249504 loss)
I1007 23:44:10.476210  5322 sgd_solver.cpp:105] Iteration 20300, lr = 0.1
I1007 23:44:35.113698  5322 solver.cpp:218] Iteration 20400 (4.05945 iter/s, 24.6339s/100 iters), loss = 0.119337
I1007 23:44:35.113732  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.119337 (* 1 = 0.119337 loss)
I1007 23:44:35.113739  5322 sgd_solver.cpp:105] Iteration 20400, lr = 0.1
I1007 23:44:58.919268  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:44:59.903991  5322 solver.cpp:330] Iteration 20500, Testing net (#0)
I1007 23:45:04.525061  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:45:04.711984  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8426
I1007 23:45:04.712011  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.477112 (* 1 = 0.477112 loss)
I1007 23:45:04.862511  5322 solver.cpp:218] Iteration 20500 (3.36192 iter/s, 29.7449s/100 iters), loss = 0.188177
I1007 23:45:04.862543  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.188177 (* 1 = 0.188177 loss)
I1007 23:45:04.862551  5322 sgd_solver.cpp:105] Iteration 20500, lr = 0.1
I1007 23:45:29.500829  5322 solver.cpp:218] Iteration 20600 (4.05909 iter/s, 24.6361s/100 iters), loss = 0.219424
I1007 23:45:29.500931  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.219424 (* 1 = 0.219424 loss)
I1007 23:45:29.500944  5322 sgd_solver.cpp:105] Iteration 20600, lr = 0.1
I1007 23:45:54.145977  5322 solver.cpp:218] Iteration 20700 (4.05819 iter/s, 24.6415s/100 iters), loss = 0.28806
I1007 23:45:54.146014  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.28806 (* 1 = 0.28806 loss)
I1007 23:45:54.146021  5322 sgd_solver.cpp:105] Iteration 20700, lr = 0.1
I1007 23:46:19.165091  5322 solver.cpp:218] Iteration 20800 (3.99765 iter/s, 25.0147s/100 iters), loss = 0.307396
I1007 23:46:19.165186  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.307396 (* 1 = 0.307396 loss)
I1007 23:46:19.165206  5322 sgd_solver.cpp:105] Iteration 20800, lr = 0.1
I1007 23:46:43.840224  5322 solver.cpp:218] Iteration 20900 (4.05324 iter/s, 24.6716s/100 iters), loss = 0.236588
I1007 23:46:43.840260  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.236589 (* 1 = 0.236589 loss)
I1007 23:46:43.840267  5322 sgd_solver.cpp:105] Iteration 20900, lr = 0.1
I1007 23:47:07.700567  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:47:08.686236  5322 solver.cpp:330] Iteration 21000, Testing net (#0)
I1007 23:47:13.237432  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:47:13.445503  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7916
I1007 23:47:13.445529  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.653874 (* 1 = 0.653874 loss)
I1007 23:47:13.578567  5322 solver.cpp:218] Iteration 21000 (3.36316 iter/s, 29.734s/100 iters), loss = 0.164504
I1007 23:47:13.578601  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.164505 (* 1 = 0.164505 loss)
I1007 23:47:13.578608  5322 sgd_solver.cpp:105] Iteration 21000, lr = 0.1
I1007 23:47:38.188714  5322 solver.cpp:218] Iteration 21100 (4.06374 iter/s, 24.6079s/100 iters), loss = 0.259519
I1007 23:47:38.188835  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.25952 (* 1 = 0.25952 loss)
I1007 23:47:38.188845  5322 sgd_solver.cpp:105] Iteration 21100, lr = 0.1
I1007 23:48:02.820621  5322 solver.cpp:218] Iteration 21200 (4.0605 iter/s, 24.6275s/100 iters), loss = 0.230495
I1007 23:48:02.820657  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.230495 (* 1 = 0.230495 loss)
I1007 23:48:02.820664  5322 sgd_solver.cpp:105] Iteration 21200, lr = 0.1
I1007 23:48:27.802973  5322 solver.cpp:218] Iteration 21300 (4.00354 iter/s, 24.9779s/100 iters), loss = 0.283494
I1007 23:48:27.803071  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.283494 (* 1 = 0.283494 loss)
I1007 23:48:27.803081  5322 sgd_solver.cpp:105] Iteration 21300, lr = 0.1
I1007 23:48:52.450086  5322 solver.cpp:218] Iteration 21400 (4.058 iter/s, 24.6427s/100 iters), loss = 0.240628
I1007 23:48:52.450124  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.240628 (* 1 = 0.240628 loss)
I1007 23:48:52.450134  5322 sgd_solver.cpp:105] Iteration 21400, lr = 0.1
I1007 23:49:16.324770  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:49:17.308712  5322 solver.cpp:330] Iteration 21500, Testing net (#0)
I1007 23:49:21.838812  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:49:22.018168  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8386
I1007 23:49:22.018194  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.472767 (* 1 = 0.472767 loss)
I1007 23:49:22.197348  5322 solver.cpp:218] Iteration 21500 (3.36211 iter/s, 29.7432s/100 iters), loss = 0.238552
I1007 23:49:22.197381  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.238552 (* 1 = 0.238552 loss)
I1007 23:49:22.197388  5322 sgd_solver.cpp:105] Iteration 21500, lr = 0.1
I1007 23:49:46.898511  5322 solver.cpp:218] Iteration 21600 (4.04876 iter/s, 24.6989s/100 iters), loss = 0.21414
I1007 23:49:46.898602  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.214141 (* 1 = 0.214141 loss)
I1007 23:49:46.898610  5322 sgd_solver.cpp:105] Iteration 21600, lr = 0.1
I1007 23:50:11.532898  5322 solver.cpp:218] Iteration 21700 (4.05998 iter/s, 24.6307s/100 iters), loss = 0.230951
I1007 23:50:11.532932  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.230951 (* 1 = 0.230951 loss)
I1007 23:50:11.532939  5322 sgd_solver.cpp:105] Iteration 21700, lr = 0.1
I1007 23:50:36.546245  5322 solver.cpp:218] Iteration 21800 (3.99856 iter/s, 25.009s/100 iters), loss = 0.301836
I1007 23:50:36.546325  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.301837 (* 1 = 0.301837 loss)
I1007 23:50:36.546334  5322 sgd_solver.cpp:105] Iteration 21800, lr = 0.1
I1007 23:51:01.209015  5322 solver.cpp:218] Iteration 21900 (4.05507 iter/s, 24.6605s/100 iters), loss = 0.258694
I1007 23:51:01.209059  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.258695 (* 1 = 0.258695 loss)
I1007 23:51:01.209065  5322 sgd_solver.cpp:105] Iteration 21900, lr = 0.1
I1007 23:51:25.087803  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:51:26.071667  5322 solver.cpp:330] Iteration 22000, Testing net (#0)
I1007 23:51:30.677415  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:51:30.838913  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8184
I1007 23:51:30.838940  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.527005 (* 1 = 0.527005 loss)
I1007 23:51:31.025383  5322 solver.cpp:218] Iteration 22000 (3.35436 iter/s, 29.8119s/100 iters), loss = 0.154138
I1007 23:51:31.025418  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.154138 (* 1 = 0.154138 loss)
I1007 23:51:31.025424  5322 sgd_solver.cpp:105] Iteration 22000, lr = 0.1
I1007 23:51:55.557891  5322 solver.cpp:218] Iteration 22100 (4.07653 iter/s, 24.5307s/100 iters), loss = 0.192513
I1007 23:51:55.557996  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.192514 (* 1 = 0.192514 loss)
I1007 23:51:55.558008  5322 sgd_solver.cpp:105] Iteration 22100, lr = 0.1
I1007 23:52:20.246124  5322 solver.cpp:218] Iteration 22200 (4.05088 iter/s, 24.686s/100 iters), loss = 0.215731
I1007 23:52:20.246162  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.215731 (* 1 = 0.215731 loss)
I1007 23:52:20.246170  5322 sgd_solver.cpp:105] Iteration 22200, lr = 0.1
I1007 23:52:45.300176  5322 solver.cpp:218] Iteration 22300 (3.99207 iter/s, 25.0497s/100 iters), loss = 0.213701
I1007 23:52:45.300282  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.213701 (* 1 = 0.213701 loss)
I1007 23:52:45.300292  5322 sgd_solver.cpp:105] Iteration 22300, lr = 0.1
I1007 23:53:09.958039  5322 solver.cpp:218] Iteration 22400 (4.05622 iter/s, 24.6535s/100 iters), loss = 0.16228
I1007 23:53:09.958078  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.16228 (* 1 = 0.16228 loss)
I1007 23:53:09.958086  5322 sgd_solver.cpp:105] Iteration 22400, lr = 0.1
I1007 23:53:33.756283  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:53:34.737512  5322 solver.cpp:330] Iteration 22500, Testing net (#0)
I1007 23:53:39.393275  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:53:39.562016  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8011
I1007 23:53:39.562042  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.60575 (* 1 = 0.60575 loss)
I1007 23:53:39.737287  5322 solver.cpp:218] Iteration 22500 (3.3583 iter/s, 29.777s/100 iters), loss = 0.183525
I1007 23:53:39.737326  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.183526 (* 1 = 0.183526 loss)
I1007 23:53:39.737334  5322 sgd_solver.cpp:105] Iteration 22500, lr = 0.1
I1007 23:54:04.405807  5322 solver.cpp:218] Iteration 22600 (4.05412 iter/s, 24.6663s/100 iters), loss = 0.310161
I1007 23:54:04.405905  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.310162 (* 1 = 0.310162 loss)
I1007 23:54:04.405926  5322 sgd_solver.cpp:105] Iteration 22600, lr = 0.1
I1007 23:54:29.027036  5322 solver.cpp:218] Iteration 22700 (4.06213 iter/s, 24.6176s/100 iters), loss = 0.296299
I1007 23:54:29.027071  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.296299 (* 1 = 0.296299 loss)
I1007 23:54:29.027081  5322 sgd_solver.cpp:105] Iteration 22700, lr = 0.1
I1007 23:54:53.958233  5322 solver.cpp:218] Iteration 22800 (4.01172 iter/s, 24.9269s/100 iters), loss = 0.163593
I1007 23:54:53.958330  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.163593 (* 1 = 0.163593 loss)
I1007 23:54:53.958353  5322 sgd_solver.cpp:105] Iteration 22800, lr = 0.1
I1007 23:55:18.596006  5322 solver.cpp:218] Iteration 22900 (4.05911 iter/s, 24.636s/100 iters), loss = 0.248586
I1007 23:55:18.596040  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.248586 (* 1 = 0.248586 loss)
I1007 23:55:18.596060  5322 sgd_solver.cpp:105] Iteration 22900, lr = 0.1
I1007 23:55:42.449378  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:55:43.432312  5322 solver.cpp:330] Iteration 23000, Testing net (#0)
I1007 23:55:48.096220  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:55:48.307029  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7997
I1007 23:55:48.307054  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.628564 (* 1 = 0.628564 loss)
I1007 23:55:48.477025  5322 solver.cpp:218] Iteration 23000 (3.34702 iter/s, 29.8773s/100 iters), loss = 0.270396
I1007 23:55:48.477058  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.270396 (* 1 = 0.270396 loss)
I1007 23:55:48.477064  5322 sgd_solver.cpp:105] Iteration 23000, lr = 0.1
I1007 23:56:13.158160  5322 solver.cpp:218] Iteration 23100 (4.05239 iter/s, 24.6768s/100 iters), loss = 0.240685
I1007 23:56:13.158260  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.240685 (* 1 = 0.240685 loss)
I1007 23:56:13.158274  5322 sgd_solver.cpp:105] Iteration 23100, lr = 0.1
I1007 23:56:37.777123  5322 solver.cpp:218] Iteration 23200 (4.06263 iter/s, 24.6146s/100 iters), loss = 0.234177
I1007 23:56:37.777160  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.234178 (* 1 = 0.234178 loss)
I1007 23:56:37.777179  5322 sgd_solver.cpp:105] Iteration 23200, lr = 0.1
I1007 23:57:02.714855  5322 solver.cpp:218] Iteration 23300 (4.0106 iter/s, 24.9339s/100 iters), loss = 0.302642
I1007 23:57:02.714925  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.302643 (* 1 = 0.302643 loss)
I1007 23:57:02.714937  5322 sgd_solver.cpp:105] Iteration 23300, lr = 0.1
I1007 23:57:27.489044  5322 solver.cpp:218] Iteration 23400 (4.03649 iter/s, 24.774s/100 iters), loss = 0.230263
I1007 23:57:27.489078  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.230263 (* 1 = 0.230263 loss)
I1007 23:57:27.489089  5322 sgd_solver.cpp:105] Iteration 23400, lr = 0.1
I1007 23:57:51.332983  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:57:52.313863  5322 solver.cpp:330] Iteration 23500, Testing net (#0)
I1007 23:57:56.972826  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:57:57.166893  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8226
I1007 23:57:57.166921  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.527688 (* 1 = 0.527688 loss)
I1007 23:57:57.321334  5322 solver.cpp:218] Iteration 23500 (3.35251 iter/s, 29.8284s/100 iters), loss = 0.204066
I1007 23:57:57.321373  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.204066 (* 1 = 0.204066 loss)
I1007 23:57:57.321385  5322 sgd_solver.cpp:105] Iteration 23500, lr = 0.1
I1007 23:58:21.990234  5322 solver.cpp:218] Iteration 23600 (4.05406 iter/s, 24.6666s/100 iters), loss = 0.275228
I1007 23:58:21.990334  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.275228 (* 1 = 0.275228 loss)
I1007 23:58:21.990356  5322 sgd_solver.cpp:105] Iteration 23600, lr = 0.1
I1007 23:58:46.609694  5322 solver.cpp:218] Iteration 23700 (4.06256 iter/s, 24.615s/100 iters), loss = 0.240671
I1007 23:58:46.609727  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.240672 (* 1 = 0.240672 loss)
I1007 23:58:46.609735  5322 sgd_solver.cpp:105] Iteration 23700, lr = 0.1
I1007 23:59:11.366917  5322 solver.cpp:218] Iteration 23800 (4.03984 iter/s, 24.7534s/100 iters), loss = 0.290437
I1007 23:59:11.367009  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.290437 (* 1 = 0.290437 loss)
I1007 23:59:11.367017  5322 sgd_solver.cpp:105] Iteration 23800, lr = 0.1
I1007 23:59:36.152869  5322 solver.cpp:218] Iteration 23900 (4.03458 iter/s, 24.7857s/100 iters), loss = 0.171738
I1007 23:59:36.152912  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.171738 (* 1 = 0.171738 loss)
I1007 23:59:36.152920  5322 sgd_solver.cpp:105] Iteration 23900, lr = 0.1
I1008 00:00:00.018069  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:00:01.003640  5322 solver.cpp:330] Iteration 24000, Testing net (#0)
I1008 00:00:05.670747  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:00:05.853982  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8532
I1008 00:00:05.854007  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.439793 (* 1 = 0.439793 loss)
I1008 00:00:06.025445  5322 solver.cpp:218] Iteration 24000 (3.34781 iter/s, 29.8703s/100 iters), loss = 0.2152
I1008 00:00:06.025478  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.215201 (* 1 = 0.215201 loss)
I1008 00:00:06.025485  5322 sgd_solver.cpp:105] Iteration 24000, lr = 0.1
I1008 00:00:30.671018  5322 solver.cpp:218] Iteration 24100 (4.0579 iter/s, 24.6433s/100 iters), loss = 0.182792
I1008 00:00:30.671131  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.182793 (* 1 = 0.182793 loss)
I1008 00:00:30.671154  5322 sgd_solver.cpp:105] Iteration 24100, lr = 0.1
I1008 00:00:55.310262  5322 solver.cpp:218] Iteration 24200 (4.05922 iter/s, 24.6353s/100 iters), loss = 0.216105
I1008 00:00:55.310297  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.216105 (* 1 = 0.216105 loss)
I1008 00:00:55.310307  5322 sgd_solver.cpp:105] Iteration 24200, lr = 0.1
I1008 00:01:20.062607  5322 solver.cpp:218] Iteration 24300 (4.04039 iter/s, 24.7501s/100 iters), loss = 0.211818
I1008 00:01:20.062711  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.211818 (* 1 = 0.211818 loss)
I1008 00:01:20.062724  5322 sgd_solver.cpp:105] Iteration 24300, lr = 0.1
I1008 00:01:44.959226  5322 solver.cpp:218] Iteration 24400 (4.01697 iter/s, 24.8944s/100 iters), loss = 0.295949
I1008 00:01:44.959262  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.29595 (* 1 = 0.29595 loss)
I1008 00:01:44.959280  5322 sgd_solver.cpp:105] Iteration 24400, lr = 0.1
I1008 00:02:08.745239  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:02:09.728677  5322 solver.cpp:330] Iteration 24500, Testing net (#0)
I1008 00:02:14.341423  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:02:14.530236  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8134
I1008 00:02:14.530266  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.586772 (* 1 = 0.586772 loss)
I1008 00:02:14.690104  5322 solver.cpp:218] Iteration 24500 (3.36376 iter/s, 29.7286s/100 iters), loss = 0.225204
I1008 00:02:14.690163  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.225205 (* 1 = 0.225205 loss)
I1008 00:02:14.690173  5322 sgd_solver.cpp:105] Iteration 24500, lr = 0.1
I1008 00:02:39.319921  5322 solver.cpp:218] Iteration 24600 (4.06014 iter/s, 24.6297s/100 iters), loss = 0.201936
I1008 00:02:39.319980  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.201936 (* 1 = 0.201936 loss)
I1008 00:02:39.319988  5322 sgd_solver.cpp:105] Iteration 24600, lr = 0.1
I1008 00:03:03.957187  5322 solver.cpp:218] Iteration 24700 (4.05926 iter/s, 24.635s/100 iters), loss = 0.222306
I1008 00:03:03.957221  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.222306 (* 1 = 0.222306 loss)
I1008 00:03:03.957228  5322 sgd_solver.cpp:105] Iteration 24700, lr = 0.1
I1008 00:03:28.625430  5322 solver.cpp:218] Iteration 24800 (4.05416 iter/s, 24.666s/100 iters), loss = 0.301546
I1008 00:03:28.625509  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.301547 (* 1 = 0.301547 loss)
I1008 00:03:28.625516  5322 sgd_solver.cpp:105] Iteration 24800, lr = 0.1
I1008 00:03:53.692006  5322 solver.cpp:218] Iteration 24900 (3.98961 iter/s, 25.0651s/100 iters), loss = 0.144986
I1008 00:03:53.692042  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.144987 (* 1 = 0.144987 loss)
I1008 00:03:53.692054  5322 sgd_solver.cpp:105] Iteration 24900, lr = 0.1
I1008 00:04:17.508613  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:04:18.491902  5322 solver.cpp:330] Iteration 25000, Testing net (#0)
I1008 00:04:23.074149  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:04:23.225510  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8354
I1008 00:04:23.225538  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.517231 (* 1 = 0.517231 loss)
I1008 00:04:23.414436  5322 solver.cpp:218] Iteration 25000 (3.36496 iter/s, 29.7181s/100 iters), loss = 0.214848
I1008 00:04:23.414477  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.214848 (* 1 = 0.214848 loss)
I1008 00:04:23.414484  5322 sgd_solver.cpp:105] Iteration 25000, lr = 0.1
I1008 00:04:47.984361  5322 solver.cpp:218] Iteration 25100 (4.0704 iter/s, 24.5676s/100 iters), loss = 0.259543
I1008 00:04:47.984474  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.259543 (* 1 = 0.259543 loss)
I1008 00:04:47.984483  5322 sgd_solver.cpp:105] Iteration 25100, lr = 0.1
I1008 00:05:12.642236  5322 solver.cpp:218] Iteration 25200 (4.05587 iter/s, 24.6556s/100 iters), loss = 0.251361
I1008 00:05:12.642271  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.251361 (* 1 = 0.251361 loss)
I1008 00:05:12.642277  5322 sgd_solver.cpp:105] Iteration 25200, lr = 0.1
I1008 00:05:37.292655  5322 solver.cpp:218] Iteration 25300 (4.0571 iter/s, 24.6482s/100 iters), loss = 0.220371
I1008 00:05:37.292716  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.220371 (* 1 = 0.220371 loss)
I1008 00:05:37.292723  5322 sgd_solver.cpp:105] Iteration 25300, lr = 0.1
I1008 00:06:02.395988  5322 solver.cpp:218] Iteration 25400 (3.98423 iter/s, 25.0989s/100 iters), loss = 0.280527
I1008 00:06:02.396026  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.280527 (* 1 = 0.280527 loss)
I1008 00:06:02.396034  5322 sgd_solver.cpp:105] Iteration 25400, lr = 0.1
I1008 00:06:26.273327  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:06:27.257419  5322 solver.cpp:330] Iteration 25500, Testing net (#0)
I1008 00:06:31.845871  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:06:32.037551  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8296
I1008 00:06:32.037576  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.504095 (* 1 = 0.504095 loss)
I1008 00:06:32.189301  5322 solver.cpp:218] Iteration 25500 (3.3569 iter/s, 29.7894s/100 iters), loss = 0.191783
I1008 00:06:32.189334  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.191783 (* 1 = 0.191783 loss)
I1008 00:06:32.189342  5322 sgd_solver.cpp:105] Iteration 25500, lr = 0.1
I1008 00:06:56.765508  5322 solver.cpp:218] Iteration 25600 (4.06935 iter/s, 24.5739s/100 iters), loss = 0.24473
I1008 00:06:56.765606  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.24473 (* 1 = 0.24473 loss)
I1008 00:06:56.765617  5322 sgd_solver.cpp:105] Iteration 25600, lr = 0.1
I1008 00:07:21.442920  5322 solver.cpp:218] Iteration 25700 (4.05266 iter/s, 24.6751s/100 iters), loss = 0.237202
I1008 00:07:21.442955  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.237203 (* 1 = 0.237203 loss)
I1008 00:07:21.442962  5322 sgd_solver.cpp:105] Iteration 25700, lr = 0.1
I1008 00:07:46.089195  5322 solver.cpp:218] Iteration 25800 (4.05778 iter/s, 24.644s/100 iters), loss = 0.230318
I1008 00:07:46.089264  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.230318 (* 1 = 0.230318 loss)
I1008 00:07:46.089272  5322 sgd_solver.cpp:105] Iteration 25800, lr = 0.1
I1008 00:08:11.117069  5322 solver.cpp:218] Iteration 25900 (3.9959 iter/s, 25.0256s/100 iters), loss = 0.230353
I1008 00:08:11.117102  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.230354 (* 1 = 0.230354 loss)
I1008 00:08:11.117120  5322 sgd_solver.cpp:105] Iteration 25900, lr = 0.1
I1008 00:08:34.995548  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:08:35.980304  5322 solver.cpp:330] Iteration 26000, Testing net (#0)
I1008 00:08:40.621616  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:08:40.800781  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8358
I1008 00:08:40.800810  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.493971 (* 1 = 0.493971 loss)
I1008 00:08:40.954375  5322 solver.cpp:218] Iteration 26000 (3.35194 iter/s, 29.8335s/100 iters), loss = 0.14527
I1008 00:08:40.954407  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.145271 (* 1 = 0.145271 loss)
I1008 00:08:40.954427  5322 sgd_solver.cpp:105] Iteration 26000, lr = 0.1
I1008 00:09:05.663059  5322 solver.cpp:218] Iteration 26100 (4.04753 iter/s, 24.7064s/100 iters), loss = 0.248285
I1008 00:09:05.663151  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.248286 (* 1 = 0.248286 loss)
I1008 00:09:05.663159  5322 sgd_solver.cpp:105] Iteration 26100, lr = 0.1
I1008 00:09:30.308904  5322 solver.cpp:218] Iteration 26200 (4.05812 iter/s, 24.6419s/100 iters), loss = 0.348053
I1008 00:09:30.308943  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.348053 (* 1 = 0.348053 loss)
I1008 00:09:30.308949  5322 sgd_solver.cpp:105] Iteration 26200, lr = 0.1
I1008 00:09:54.915333  5322 solver.cpp:218] Iteration 26300 (4.06467 iter/s, 24.6022s/100 iters), loss = 0.254145
I1008 00:09:54.915441  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.254146 (* 1 = 0.254146 loss)
I1008 00:09:54.915453  5322 sgd_solver.cpp:105] Iteration 26300, lr = 0.1
I1008 00:10:20.005942  5322 solver.cpp:218] Iteration 26400 (3.9862 iter/s, 25.0865s/100 iters), loss = 0.180636
I1008 00:10:20.005977  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.180636 (* 1 = 0.180636 loss)
I1008 00:10:20.005986  5322 sgd_solver.cpp:105] Iteration 26400, lr = 0.1
I1008 00:10:43.893589  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:10:44.876015  5322 solver.cpp:330] Iteration 26500, Testing net (#0)
I1008 00:10:49.428536  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:10:49.625200  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7627
I1008 00:10:49.625231  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.794078 (* 1 = 0.794078 loss)
I1008 00:10:49.772531  5322 solver.cpp:218] Iteration 26500 (3.35973 iter/s, 29.7643s/100 iters), loss = 0.225991
I1008 00:10:49.772568  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.225992 (* 1 = 0.225992 loss)
I1008 00:10:49.772578  5322 sgd_solver.cpp:105] Iteration 26500, lr = 0.1
I1008 00:11:14.394810  5322 solver.cpp:218] Iteration 26600 (4.06139 iter/s, 24.6221s/100 iters), loss = 0.188453
I1008 00:11:14.394896  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.188453 (* 1 = 0.188453 loss)
I1008 00:11:14.394904  5322 sgd_solver.cpp:105] Iteration 26600, lr = 0.1
I1008 00:11:39.039603  5322 solver.cpp:218] Iteration 26700 (4.05826 iter/s, 24.6411s/100 iters), loss = 0.247693
I1008 00:11:39.039646  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.247693 (* 1 = 0.247693 loss)
I1008 00:11:39.039654  5322 sgd_solver.cpp:105] Iteration 26700, lr = 0.1
I1008 00:12:03.691872  5322 solver.cpp:218] Iteration 26800 (4.05706 iter/s, 24.6484s/100 iters), loss = 0.222011
I1008 00:12:03.691972  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.222011 (* 1 = 0.222011 loss)
I1008 00:12:03.691983  5322 sgd_solver.cpp:105] Iteration 26800, lr = 0.1
I1008 00:12:28.759114  5322 solver.cpp:218] Iteration 26900 (3.98981 iter/s, 25.0638s/100 iters), loss = 0.243319
I1008 00:12:28.759150  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.24332 (* 1 = 0.24332 loss)
I1008 00:12:28.759157  5322 sgd_solver.cpp:105] Iteration 26900, lr = 0.1
I1008 00:12:52.557687  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:12:53.542352  5322 solver.cpp:330] Iteration 27000, Testing net (#0)
I1008 00:12:58.186707  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:12:58.385255  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8071
I1008 00:12:58.385285  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.58416 (* 1 = 0.58416 loss)
I1008 00:12:58.535030  5322 solver.cpp:218] Iteration 27000 (3.35884 iter/s, 29.7721s/100 iters), loss = 0.160286
I1008 00:12:58.535064  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.160287 (* 1 = 0.160287 loss)
I1008 00:12:58.535073  5322 sgd_solver.cpp:105] Iteration 27000, lr = 0.1
I1008 00:13:23.190671  5322 solver.cpp:218] Iteration 27100 (4.05624 iter/s, 24.6533s/100 iters), loss = 0.246121
I1008 00:13:23.190742  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.246121 (* 1 = 0.246121 loss)
I1008 00:13:23.190749  5322 sgd_solver.cpp:105] Iteration 27100, lr = 0.1
I1008 00:13:47.816747  5322 solver.cpp:218] Iteration 27200 (4.06135 iter/s, 24.6223s/100 iters), loss = 0.281038
I1008 00:13:47.816789  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.281038 (* 1 = 0.281038 loss)
I1008 00:13:47.816807  5322 sgd_solver.cpp:105] Iteration 27200, lr = 0.1
I1008 00:14:12.425830  5322 solver.cpp:218] Iteration 27300 (4.06415 iter/s, 24.6054s/100 iters), loss = 0.27635
I1008 00:14:12.425948  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.276351 (* 1 = 0.276351 loss)
I1008 00:14:12.425956  5322 sgd_solver.cpp:105] Iteration 27300, lr = 0.1
I1008 00:14:37.402359  5322 solver.cpp:218] Iteration 27400 (4.00447 iter/s, 24.9721s/100 iters), loss = 0.175082
I1008 00:14:37.402395  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.175082 (* 1 = 0.175082 loss)
I1008 00:14:37.402402  5322 sgd_solver.cpp:105] Iteration 27400, lr = 0.1
I1008 00:15:01.283721  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:15:02.266819  5322 solver.cpp:330] Iteration 27500, Testing net (#0)
I1008 00:15:06.818018  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:15:07.022966  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8481
I1008 00:15:07.022994  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.479 (* 1 = 0.479 loss)
I1008 00:15:07.159865  5322 solver.cpp:218] Iteration 27500 (3.36092 iter/s, 29.7537s/100 iters), loss = 0.132651
I1008 00:15:07.159906  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.132652 (* 1 = 0.132652 loss)
I1008 00:15:07.159912  5322 sgd_solver.cpp:105] Iteration 27500, lr = 0.1
I1008 00:15:31.770292  5322 solver.cpp:218] Iteration 27600 (4.06334 iter/s, 24.6103s/100 iters), loss = 0.193425
I1008 00:15:31.770383  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.193426 (* 1 = 0.193426 loss)
I1008 00:15:31.770393  5322 sgd_solver.cpp:105] Iteration 27600, lr = 0.1
I1008 00:15:56.423542  5322 solver.cpp:218] Iteration 27700 (4.05686 iter/s, 24.6496s/100 iters), loss = 0.265292
I1008 00:15:56.423581  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.265292 (* 1 = 0.265292 loss)
I1008 00:15:56.423590  5322 sgd_solver.cpp:105] Iteration 27700, lr = 0.1
I1008 00:16:21.085801  5322 solver.cpp:218] Iteration 27800 (4.0555 iter/s, 24.6579s/100 iters), loss = 0.170835
I1008 00:16:21.085903  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.170836 (* 1 = 0.170836 loss)
I1008 00:16:21.085916  5322 sgd_solver.cpp:105] Iteration 27800, lr = 0.1
I1008 00:16:46.085863  5322 solver.cpp:218] Iteration 27900 (4.0006 iter/s, 24.9963s/100 iters), loss = 0.121286
I1008 00:16:46.085898  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.121286 (* 1 = 0.121286 loss)
I1008 00:16:46.085917  5322 sgd_solver.cpp:105] Iteration 27900, lr = 0.1
I1008 00:17:09.952487  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:17:10.936689  5322 solver.cpp:330] Iteration 28000, Testing net (#0)
I1008 00:17:15.451197  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:17:15.646108  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8264
I1008 00:17:15.646134  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.577473 (* 1 = 0.577473 loss)
I1008 00:17:15.806031  5322 solver.cpp:218] Iteration 28000 (3.36498 iter/s, 29.7179s/100 iters), loss = 0.142992
I1008 00:17:15.806063  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.142992 (* 1 = 0.142992 loss)
I1008 00:17:15.806071  5322 sgd_solver.cpp:105] Iteration 28000, lr = 0.1
I1008 00:17:40.438486  5322 solver.cpp:218] Iteration 28100 (4.05972 iter/s, 24.6323s/100 iters), loss = 0.231233
I1008 00:17:40.438629  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.231234 (* 1 = 0.231234 loss)
I1008 00:17:40.438639  5322 sgd_solver.cpp:105] Iteration 28100, lr = 0.1
I1008 00:18:05.083135  5322 solver.cpp:218] Iteration 28200 (4.05805 iter/s, 24.6424s/100 iters), loss = 0.25913
I1008 00:18:05.083175  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.25913 (* 1 = 0.25913 loss)
I1008 00:18:05.083184  5322 sgd_solver.cpp:105] Iteration 28200, lr = 0.1
I1008 00:18:29.724454  5322 solver.cpp:218] Iteration 28300 (4.0589 iter/s, 24.6372s/100 iters), loss = 0.265115
I1008 00:18:29.724596  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.265115 (* 1 = 0.265115 loss)
I1008 00:18:29.724607  5322 sgd_solver.cpp:105] Iteration 28300, lr = 0.1
I1008 00:18:54.711077  5322 solver.cpp:218] Iteration 28400 (4.0025 iter/s, 24.9844s/100 iters), loss = 0.177169
I1008 00:18:54.711117  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.177169 (* 1 = 0.177169 loss)
I1008 00:18:54.711127  5322 sgd_solver.cpp:105] Iteration 28400, lr = 0.1
I1008 00:19:18.583768  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:19:19.569571  5322 solver.cpp:330] Iteration 28500, Testing net (#0)
I1008 00:19:24.224675  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:19:24.425787  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8096
I1008 00:19:24.425813  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.61295 (* 1 = 0.61295 loss)
I1008 00:19:24.576011  5322 solver.cpp:218] Iteration 28500 (3.34866 iter/s, 29.8627s/100 iters), loss = 0.184632
I1008 00:19:24.576045  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.184633 (* 1 = 0.184633 loss)
I1008 00:19:24.576053  5322 sgd_solver.cpp:105] Iteration 28500, lr = 0.1
I1008 00:19:49.255822  5322 solver.cpp:218] Iteration 28600 (4.05227 iter/s, 24.6775s/100 iters), loss = 0.171063
I1008 00:19:49.255918  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.171063 (* 1 = 0.171063 loss)
I1008 00:19:49.255928  5322 sgd_solver.cpp:105] Iteration 28600, lr = 0.1
I1008 00:20:13.908329  5322 solver.cpp:218] Iteration 28700 (4.05675 iter/s, 24.6503s/100 iters), loss = 0.278978
I1008 00:20:13.908361  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.278978 (* 1 = 0.278978 loss)
I1008 00:20:13.908370  5322 sgd_solver.cpp:105] Iteration 28700, lr = 0.1
I1008 00:20:38.568619  5322 solver.cpp:218] Iteration 28800 (4.05547 iter/s, 24.658s/100 iters), loss = 0.233753
I1008 00:20:38.568696  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.233753 (* 1 = 0.233753 loss)
I1008 00:20:38.568706  5322 sgd_solver.cpp:105] Iteration 28800, lr = 0.1
I1008 00:21:03.561460  5322 solver.cpp:218] Iteration 28900 (4.00151 iter/s, 24.9906s/100 iters), loss = 0.183418
I1008 00:21:03.561493  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.183419 (* 1 = 0.183419 loss)
I1008 00:21:03.561501  5322 sgd_solver.cpp:105] Iteration 28900, lr = 0.1
I1008 00:21:27.333501  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:21:28.316563  5322 solver.cpp:330] Iteration 29000, Testing net (#0)
I1008 00:21:32.982539  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:21:33.190415  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8475
I1008 00:21:33.190440  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.464751 (* 1 = 0.464751 loss)
I1008 00:21:33.357244  5322 solver.cpp:218] Iteration 29000 (3.35644 iter/s, 29.7935s/100 iters), loss = 0.188215
I1008 00:21:33.357276  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.188216 (* 1 = 0.188216 loss)
I1008 00:21:33.357285  5322 sgd_solver.cpp:105] Iteration 29000, lr = 0.1
I1008 00:21:58.036417  5322 solver.cpp:218] Iteration 29100 (4.05237 iter/s, 24.6769s/100 iters), loss = 0.250652
I1008 00:21:58.036509  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.250652 (* 1 = 0.250652 loss)
I1008 00:21:58.036526  5322 sgd_solver.cpp:105] Iteration 29100, lr = 0.1
I1008 00:22:22.649345  5322 solver.cpp:218] Iteration 29200 (4.06353 iter/s, 24.6091s/100 iters), loss = 0.272777
I1008 00:22:22.649392  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.272778 (* 1 = 0.272778 loss)
I1008 00:22:22.649400  5322 sgd_solver.cpp:105] Iteration 29200, lr = 0.1
I1008 00:22:47.286695  5322 solver.cpp:218] Iteration 29300 (4.0596 iter/s, 24.633s/100 iters), loss = 0.298759
I1008 00:22:47.286799  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.298759 (* 1 = 0.298759 loss)
I1008 00:22:47.286810  5322 sgd_solver.cpp:105] Iteration 29300, lr = 0.1
I1008 00:23:12.358952  5322 solver.cpp:218] Iteration 29400 (3.98883 iter/s, 25.07s/100 iters), loss = 0.231435
I1008 00:23:12.358997  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.231435 (* 1 = 0.231435 loss)
I1008 00:23:12.359005  5322 sgd_solver.cpp:105] Iteration 29400, lr = 0.1
I1008 00:23:36.152935  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:23:37.136091  5322 solver.cpp:330] Iteration 29500, Testing net (#0)
I1008 00:23:41.804996  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:23:42.001642  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8347
I1008 00:23:42.001667  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.502784 (* 1 = 0.502784 loss)
I1008 00:23:42.159255  5322 solver.cpp:218] Iteration 29500 (3.35617 iter/s, 29.7959s/100 iters), loss = 0.167389
I1008 00:23:42.159286  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.16739 (* 1 = 0.16739 loss)
I1008 00:23:42.159292  5322 sgd_solver.cpp:105] Iteration 29500, lr = 0.1
I1008 00:24:06.827443  5322 solver.cpp:218] Iteration 29600 (4.05418 iter/s, 24.6659s/100 iters), loss = 0.206504
I1008 00:24:06.827515  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.206505 (* 1 = 0.206505 loss)
I1008 00:24:06.827525  5322 sgd_solver.cpp:105] Iteration 29600, lr = 0.1
I1008 00:24:31.507751  5322 solver.cpp:218] Iteration 29700 (4.05219 iter/s, 24.678s/100 iters), loss = 0.268774
I1008 00:24:31.507784  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.268774 (* 1 = 0.268774 loss)
I1008 00:24:31.507791  5322 sgd_solver.cpp:105] Iteration 29700, lr = 0.1
I1008 00:24:56.156834  5322 solver.cpp:218] Iteration 29800 (4.05756 iter/s, 24.6454s/100 iters), loss = 0.306642
I1008 00:24:56.156901  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.306642 (* 1 = 0.306642 loss)
I1008 00:24:56.156911  5322 sgd_solver.cpp:105] Iteration 29800, lr = 0.1
I1008 00:25:21.170752  5322 solver.cpp:218] Iteration 29900 (3.99838 iter/s, 25.0101s/100 iters), loss = 0.208838
I1008 00:25:21.170794  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.208838 (* 1 = 0.208838 loss)
I1008 00:25:21.170801  5322 sgd_solver.cpp:105] Iteration 29900, lr = 0.1
I1008 00:25:45.070009  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:25:46.037369  5322 solver.cpp:330] Iteration 30000, Testing net (#0)
I1008 00:25:50.705255  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:25:50.853293  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8552
I1008 00:25:50.853319  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.440607 (* 1 = 0.440607 loss)
I1008 00:25:51.061938  5322 solver.cpp:218] Iteration 30000 (3.3459 iter/s, 29.8874s/100 iters), loss = 0.207838
I1008 00:25:51.061969  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.207839 (* 1 = 0.207839 loss)
I1008 00:25:51.061986  5322 sgd_solver.cpp:105] Iteration 30000, lr = 0.1
I1008 00:26:15.705754  5322 solver.cpp:218] Iteration 30100 (4.05819 iter/s, 24.6415s/100 iters), loss = 0.235889
I1008 00:26:15.705852  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.23589 (* 1 = 0.23589 loss)
I1008 00:26:15.705862  5322 sgd_solver.cpp:105] Iteration 30100, lr = 0.1
I1008 00:26:40.368170  5322 solver.cpp:218] Iteration 30200 (4.05544 iter/s, 24.6582s/100 iters), loss = 0.226587
I1008 00:26:40.368204  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.226587 (* 1 = 0.226587 loss)
I1008 00:26:40.368212  5322 sgd_solver.cpp:105] Iteration 30200, lr = 0.1
I1008 00:27:05.018088  5322 solver.cpp:218] Iteration 30300 (4.05753 iter/s, 24.6455s/100 iters), loss = 0.225332
I1008 00:27:05.018178  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.225333 (* 1 = 0.225333 loss)
I1008 00:27:05.018187  5322 sgd_solver.cpp:105] Iteration 30300, lr = 0.1
I1008 00:27:30.037369  5322 solver.cpp:218] Iteration 30400 (3.99762 iter/s, 25.0149s/100 iters), loss = 0.322097
I1008 00:27:30.037401  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.322097 (* 1 = 0.322097 loss)
I1008 00:27:30.037408  5322 sgd_solver.cpp:105] Iteration 30400, lr = 0.1
I1008 00:27:53.839491  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:27:54.823431  5322 solver.cpp:330] Iteration 30500, Testing net (#0)
I1008 00:27:59.374279  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:27:59.553767  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8124
I1008 00:27:59.553797  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.614907 (* 1 = 0.614907 loss)
I1008 00:27:59.713019  5322 solver.cpp:218] Iteration 30500 (3.37002 iter/s, 29.6734s/100 iters), loss = 0.152784
I1008 00:27:59.713052  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.152785 (* 1 = 0.152785 loss)
I1008 00:27:59.713068  5322 sgd_solver.cpp:105] Iteration 30500, lr = 0.1
I1008 00:28:24.336298  5322 solver.cpp:218] Iteration 30600 (4.06122 iter/s, 24.6231s/100 iters), loss = 0.16028
I1008 00:28:24.336377  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.160281 (* 1 = 0.160281 loss)
I1008 00:28:24.336386  5322 sgd_solver.cpp:105] Iteration 30600, lr = 0.1
I1008 00:28:49.002185  5322 solver.cpp:218] Iteration 30700 (4.05456 iter/s, 24.6636s/100 iters), loss = 0.336469
I1008 00:28:49.002218  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.336469 (* 1 = 0.336469 loss)
I1008 00:28:49.002224  5322 sgd_solver.cpp:105] Iteration 30700, lr = 0.1
I1008 00:29:13.654083  5322 solver.cpp:218] Iteration 30800 (4.05686 iter/s, 24.6496s/100 iters), loss = 0.220721
I1008 00:29:13.654163  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.220722 (* 1 = 0.220722 loss)
I1008 00:29:13.654171  5322 sgd_solver.cpp:105] Iteration 30800, lr = 0.1
I1008 00:29:38.651351  5322 solver.cpp:218] Iteration 30900 (4.00103 iter/s, 24.9935s/100 iters), loss = 0.154654
I1008 00:29:38.651388  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.154655 (* 1 = 0.154655 loss)
I1008 00:29:38.651396  5322 sgd_solver.cpp:105] Iteration 30900, lr = 0.1
I1008 00:30:02.527711  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:30:03.510385  5322 solver.cpp:330] Iteration 31000, Testing net (#0)
I1008 00:30:08.158413  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:30:08.342104  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8456
I1008 00:30:08.342130  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.455122 (* 1 = 0.455122 loss)
I1008 00:30:08.503229  5322 solver.cpp:218] Iteration 31000 (3.35028 iter/s, 29.8482s/100 iters), loss = 0.252047
I1008 00:30:08.503262  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.252047 (* 1 = 0.252047 loss)
I1008 00:30:08.503268  5322 sgd_solver.cpp:105] Iteration 31000, lr = 0.1
I1008 00:30:33.183713  5322 solver.cpp:218] Iteration 31100 (4.05216 iter/s, 24.6782s/100 iters), loss = 0.162513
I1008 00:30:33.183811  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.162513 (* 1 = 0.162513 loss)
I1008 00:30:33.183821  5322 sgd_solver.cpp:105] Iteration 31100, lr = 0.1
I1008 00:30:57.829658  5322 solver.cpp:218] Iteration 31200 (4.05818 iter/s, 24.6416s/100 iters), loss = 0.252305
I1008 00:30:57.829689  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.252306 (* 1 = 0.252306 loss)
I1008 00:30:57.829697  5322 sgd_solver.cpp:105] Iteration 31200, lr = 0.1
I1008 00:31:22.469779  5322 solver.cpp:218] Iteration 31300 (4.05914 iter/s, 24.6357s/100 iters), loss = 0.21973
I1008 00:31:22.469872  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.21973 (* 1 = 0.21973 loss)
I1008 00:31:22.469880  5322 sgd_solver.cpp:105] Iteration 31300, lr = 0.1
I1008 00:31:47.454965  5322 solver.cpp:218] Iteration 31400 (4.00308 iter/s, 24.9808s/100 iters), loss = 0.173002
I1008 00:31:47.454998  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.173003 (* 1 = 0.173003 loss)
I1008 00:31:47.455005  5322 sgd_solver.cpp:105] Iteration 31400, lr = 0.1
I1008 00:32:11.394445  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:32:12.375675  5322 solver.cpp:330] Iteration 31500, Testing net (#0)
I1008 00:32:17.038321  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:32:17.253741  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8484
I1008 00:32:17.253770  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.455587 (* 1 = 0.455587 loss)
I1008 00:32:17.404429  5322 solver.cpp:218] Iteration 31500 (3.33945 iter/s, 29.945s/100 iters), loss = 0.183359
I1008 00:32:17.404465  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.18336 (* 1 = 0.18336 loss)
I1008 00:32:17.404484  5322 sgd_solver.cpp:105] Iteration 31500, lr = 0.1
I1008 00:32:42.100487  5322 solver.cpp:218] Iteration 31600 (4.04996 iter/s, 24.6916s/100 iters), loss = 0.315444
I1008 00:32:42.100574  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.315444 (* 1 = 0.315444 loss)
I1008 00:32:42.100587  5322 sgd_solver.cpp:105] Iteration 31600, lr = 0.1
I1008 00:33:06.759426  5322 solver.cpp:218] Iteration 31700 (4.0557 iter/s, 24.6566s/100 iters), loss = 0.276771
I1008 00:33:06.759471  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.276772 (* 1 = 0.276772 loss)
I1008 00:33:06.759479  5322 sgd_solver.cpp:105] Iteration 31700, lr = 0.1
I1008 00:33:31.407068  5322 solver.cpp:218] Iteration 31800 (4.05783 iter/s, 24.6437s/100 iters), loss = 0.219165
I1008 00:33:31.407156  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.219165 (* 1 = 0.219165 loss)
I1008 00:33:31.407169  5322 sgd_solver.cpp:105] Iteration 31800, lr = 0.1
I1008 00:33:56.498404  5322 solver.cpp:218] Iteration 31900 (3.98601 iter/s, 25.0878s/100 iters), loss = 0.169476
I1008 00:33:56.498440  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.169476 (* 1 = 0.169476 loss)
I1008 00:33:56.498450  5322 sgd_solver.cpp:105] Iteration 31900, lr = 0.1
I1008 00:34:20.363577  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:34:21.343284  5322 solver.cpp:330] Iteration 32000, Testing net (#0)
I1008 00:34:25.918208  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:34:26.085863  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8442
I1008 00:34:26.085891  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.471204 (* 1 = 0.471204 loss)
I1008 00:34:26.267375  5322 solver.cpp:218] Iteration 32000 (3.35963 iter/s, 29.7652s/100 iters), loss = 0.237336
I1008 00:34:26.267410  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.237336 (* 1 = 0.237336 loss)
I1008 00:34:26.267417  5322 sgd_solver.cpp:105] Iteration 32000, lr = 0.1
I1008 00:34:50.834044  5322 solver.cpp:218] Iteration 32100 (4.07094 iter/s, 24.5644s/100 iters), loss = 0.283747
I1008 00:34:50.834134  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.283747 (* 1 = 0.283747 loss)
I1008 00:34:50.834142  5322 sgd_solver.cpp:105] Iteration 32100, lr = 0.1
I1008 00:35:15.477119  5322 solver.cpp:218] Iteration 32200 (4.05831 iter/s, 24.6408s/100 iters), loss = 0.178827
I1008 00:35:15.477152  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.178827 (* 1 = 0.178827 loss)
I1008 00:35:15.477159  5322 sgd_solver.cpp:105] Iteration 32200, lr = 0.1
I1008 00:35:40.119525  5322 solver.cpp:218] Iteration 32300 (4.05842 iter/s, 24.6402s/100 iters), loss = 0.212567
I1008 00:35:40.119598  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.212568 (* 1 = 0.212568 loss)
I1008 00:35:40.119606  5322 sgd_solver.cpp:105] Iteration 32300, lr = 0.1
I1008 00:36:05.199245  5322 solver.cpp:218] Iteration 32400 (3.98765 iter/s, 25.0775s/100 iters), loss = 0.119415
I1008 00:36:05.199280  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.119416 (* 1 = 0.119416 loss)
I1008 00:36:05.199288  5322 sgd_solver.cpp:105] Iteration 32400, lr = 0.1
I1008 00:36:28.998026  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:36:29.980242  5322 solver.cpp:330] Iteration 32500, Testing net (#0)
I1008 00:36:34.640987  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:36:34.836952  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8276
I1008 00:36:34.836979  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.490327 (* 1 = 0.490327 loss)
I1008 00:36:34.991485  5322 solver.cpp:218] Iteration 32500 (3.35683 iter/s, 29.79s/100 iters), loss = 0.105674
I1008 00:36:34.991518  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.105675 (* 1 = 0.105675 loss)
I1008 00:36:34.991526  5322 sgd_solver.cpp:105] Iteration 32500, lr = 0.1
I1008 00:36:59.659204  5322 solver.cpp:218] Iteration 32600 (4.05425 iter/s, 24.6655s/100 iters), loss = 0.13983
I1008 00:36:59.659297  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.13983 (* 1 = 0.13983 loss)
I1008 00:36:59.659307  5322 sgd_solver.cpp:105] Iteration 32600, lr = 0.1
I1008 00:37:24.321355  5322 solver.cpp:218] Iteration 32700 (4.05535 iter/s, 24.6588s/100 iters), loss = 0.271196
I1008 00:37:24.321393  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.271196 (* 1 = 0.271196 loss)
I1008 00:37:24.321413  5322 sgd_solver.cpp:105] Iteration 32700, lr = 0.1
I1008 00:37:48.971673  5322 solver.cpp:218] Iteration 32800 (4.05741 iter/s, 24.6463s/100 iters), loss = 0.225549
I1008 00:37:48.971745  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.225549 (* 1 = 0.225549 loss)
I1008 00:37:48.971760  5322 sgd_solver.cpp:105] Iteration 32800, lr = 0.1
I1008 00:38:14.046954  5322 solver.cpp:218] Iteration 32900 (3.98862 iter/s, 25.0713s/100 iters), loss = 0.140435
I1008 00:38:14.046998  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.140436 (* 1 = 0.140436 loss)
I1008 00:38:14.047005  5322 sgd_solver.cpp:105] Iteration 32900, lr = 0.1
I1008 00:38:37.973986  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:38:38.916191  5322 solver.cpp:330] Iteration 33000, Testing net (#0)
I1008 00:38:43.478601  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:38:43.624773  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8096
I1008 00:38:43.624800  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.616035 (* 1 = 0.616035 loss)
I1008 00:38:43.813987  5322 solver.cpp:218] Iteration 33000 (3.35968 iter/s, 29.7647s/100 iters), loss = 0.176931
I1008 00:38:43.814023  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.176932 (* 1 = 0.176932 loss)
I1008 00:38:43.814033  5322 sgd_solver.cpp:105] Iteration 33000, lr = 0.1
I1008 00:39:08.301923  5322 solver.cpp:218] Iteration 33100 (4.08367 iter/s, 24.4878s/100 iters), loss = 0.181599
I1008 00:39:08.302073  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.181599 (* 1 = 0.181599 loss)
I1008 00:39:08.302084  5322 sgd_solver.cpp:105] Iteration 33100, lr = 0.1
I1008 00:39:32.951804  5322 solver.cpp:218] Iteration 33200 (4.05719 iter/s, 24.6476s/100 iters), loss = 0.237845
I1008 00:39:32.951839  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.237846 (* 1 = 0.237846 loss)
I1008 00:39:32.951848  5322 sgd_solver.cpp:105] Iteration 33200, lr = 0.1
I1008 00:39:57.584743  5322 solver.cpp:218] Iteration 33300 (4.06022 iter/s, 24.6292s/100 iters), loss = 0.195
I1008 00:39:57.584817  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.195 (* 1 = 0.195 loss)
I1008 00:39:57.584828  5322 sgd_solver.cpp:105] Iteration 33300, lr = 0.1
I1008 00:40:22.602105  5322 solver.cpp:218] Iteration 33400 (3.99759 iter/s, 25.0151s/100 iters), loss = 0.17572
I1008 00:40:22.602149  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.175721 (* 1 = 0.175721 loss)
I1008 00:40:22.602155  5322 sgd_solver.cpp:105] Iteration 33400, lr = 0.1
I1008 00:40:46.410905  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:40:47.393157  5322 solver.cpp:330] Iteration 33500, Testing net (#0)
I1008 00:40:51.927426  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:40:52.100445  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8133
I1008 00:40:52.100472  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.576363 (* 1 = 0.576363 loss)
I1008 00:40:52.287369  5322 solver.cpp:218] Iteration 33500 (3.36911 iter/s, 29.6814s/100 iters), loss = 0.244639
I1008 00:40:52.287405  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.24464 (* 1 = 0.24464 loss)
I1008 00:40:52.287415  5322 sgd_solver.cpp:105] Iteration 33500, lr = 0.1
I1008 00:41:16.889328  5322 solver.cpp:218] Iteration 33600 (4.06509 iter/s, 24.5997s/100 iters), loss = 0.187398
I1008 00:41:16.889403  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.187398 (* 1 = 0.187398 loss)
I1008 00:41:16.889422  5322 sgd_solver.cpp:105] Iteration 33600, lr = 0.1
I1008 00:41:41.549805  5322 solver.cpp:218] Iteration 33700 (4.05545 iter/s, 24.6582s/100 iters), loss = 0.289014
I1008 00:41:41.549837  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.289014 (* 1 = 0.289014 loss)
I1008 00:41:41.549845  5322 sgd_solver.cpp:105] Iteration 33700, lr = 0.1
I1008 00:42:06.216450  5322 solver.cpp:218] Iteration 33800 (4.05467 iter/s, 24.6629s/100 iters), loss = 0.248252
I1008 00:42:06.216538  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.248252 (* 1 = 0.248252 loss)
I1008 00:42:06.216560  5322 sgd_solver.cpp:105] Iteration 33800, lr = 0.1
I1008 00:42:31.323195  5322 solver.cpp:218] Iteration 33900 (3.98336 iter/s, 25.1045s/100 iters), loss = 0.14843
I1008 00:42:31.323233  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.148431 (* 1 = 0.148431 loss)
I1008 00:42:31.323253  5322 sgd_solver.cpp:105] Iteration 33900, lr = 0.1
I1008 00:42:55.040968  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:42:56.025817  5322 solver.cpp:330] Iteration 34000, Testing net (#0)
I1008 00:43:00.608575  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:43:00.796860  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8511
I1008 00:43:00.796898  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.444296 (* 1 = 0.444296 loss)
I1008 00:43:00.953923  5322 solver.cpp:218] Iteration 34000 (3.37513 iter/s, 29.6284s/100 iters), loss = 0.188658
I1008 00:43:00.953965  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.188658 (* 1 = 0.188658 loss)
I1008 00:43:00.953974  5322 sgd_solver.cpp:105] Iteration 34000, lr = 0.1
I1008 00:43:25.534945  5322 solver.cpp:218] Iteration 34100 (4.06855 iter/s, 24.5788s/100 iters), loss = 0.22547
I1008 00:43:25.535022  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.22547 (* 1 = 0.22547 loss)
I1008 00:43:25.535032  5322 sgd_solver.cpp:105] Iteration 34100, lr = 0.1
I1008 00:43:50.191057  5322 solver.cpp:218] Iteration 34200 (4.05617 iter/s, 24.6538s/100 iters), loss = 0.275537
I1008 00:43:50.191092  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.275538 (* 1 = 0.275538 loss)
I1008 00:43:50.191098  5322 sgd_solver.cpp:105] Iteration 34200, lr = 0.1
I1008 00:44:14.846735  5322 solver.cpp:218] Iteration 34300 (4.05647 iter/s, 24.652s/100 iters), loss = 0.190521
I1008 00:44:14.846812  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.190521 (* 1 = 0.190521 loss)
I1008 00:44:14.846822  5322 sgd_solver.cpp:105] Iteration 34300, lr = 0.1
I1008 00:44:39.916939  5322 solver.cpp:218] Iteration 34400 (3.98916 iter/s, 25.068s/100 iters), loss = 0.23947
I1008 00:44:39.916972  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.23947 (* 1 = 0.23947 loss)
I1008 00:44:39.916980  5322 sgd_solver.cpp:105] Iteration 34400, lr = 0.1
I1008 00:45:03.791697  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:45:04.775240  5322 solver.cpp:330] Iteration 34500, Testing net (#0)
I1008 00:45:09.324565  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:45:09.508527  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7852
I1008 00:45:09.508553  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.688241 (* 1 = 0.688241 loss)
I1008 00:45:09.669952  5322 solver.cpp:218] Iteration 34500 (3.36126 iter/s, 29.7507s/100 iters), loss = 0.209441
I1008 00:45:09.669986  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.209441 (* 1 = 0.209441 loss)
I1008 00:45:09.669992  5322 sgd_solver.cpp:105] Iteration 34500, lr = 0.1
I1008 00:45:34.289366  5322 solver.cpp:218] Iteration 34600 (4.06221 iter/s, 24.6172s/100 iters), loss = 0.233344
I1008 00:45:34.289446  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.233345 (* 1 = 0.233345 loss)
I1008 00:45:34.289456  5322 sgd_solver.cpp:105] Iteration 34600, lr = 0.1
I1008 00:45:58.933629  5322 solver.cpp:218] Iteration 34700 (4.05811 iter/s, 24.642s/100 iters), loss = 0.243474
I1008 00:45:58.933670  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.243475 (* 1 = 0.243475 loss)
I1008 00:45:58.933677  5322 sgd_solver.cpp:105] Iteration 34700, lr = 0.1
I1008 00:46:23.569300  5322 solver.cpp:218] Iteration 34800 (4.05953 iter/s, 24.6334s/100 iters), loss = 0.142689
I1008 00:46:23.569381  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.142689 (* 1 = 0.142689 loss)
I1008 00:46:23.569391  5322 sgd_solver.cpp:105] Iteration 34800, lr = 0.1
I1008 00:46:48.585583  5322 solver.cpp:218] Iteration 34900 (3.99776 iter/s, 25.014s/100 iters), loss = 0.28091
I1008 00:46:48.585615  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.280911 (* 1 = 0.280911 loss)
I1008 00:46:48.585623  5322 sgd_solver.cpp:105] Iteration 34900, lr = 0.1
I1008 00:47:12.510566  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:47:13.493484  5322 solver.cpp:330] Iteration 35000, Testing net (#0)
I1008 00:47:18.108698  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:47:18.292265  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8392
I1008 00:47:18.292295  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.490179 (* 1 = 0.490179 loss)
I1008 00:47:18.461328  5322 solver.cpp:218] Iteration 35000 (3.34741 iter/s, 29.8738s/100 iters), loss = 0.230689
I1008 00:47:18.461369  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.230689 (* 1 = 0.230689 loss)
I1008 00:47:18.461375  5322 sgd_solver.cpp:105] Iteration 35000, lr = 0.1
I1008 00:47:43.082685  5322 solver.cpp:218] Iteration 35100 (4.06189 iter/s, 24.6191s/100 iters), loss = 0.307006
I1008 00:47:43.082779  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.307006 (* 1 = 0.307006 loss)
I1008 00:47:43.082787  5322 sgd_solver.cpp:105] Iteration 35100, lr = 0.1
I1008 00:48:07.728449  5322 solver.cpp:218] Iteration 35200 (4.05787 iter/s, 24.6435s/100 iters), loss = 0.18536
I1008 00:48:07.728485  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.18536 (* 1 = 0.18536 loss)
I1008 00:48:07.728494  5322 sgd_solver.cpp:105] Iteration 35200, lr = 0.1
I1008 00:48:32.353976  5322 solver.cpp:218] Iteration 35300 (4.06156 iter/s, 24.6211s/100 iters), loss = 0.302951
I1008 00:48:32.354084  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.302951 (* 1 = 0.302951 loss)
I1008 00:48:32.354096  5322 sgd_solver.cpp:105] Iteration 35300, lr = 0.1
I1008 00:48:57.428500  5322 solver.cpp:218] Iteration 35400 (3.98877 iter/s, 25.0704s/100 iters), loss = 0.151179
I1008 00:48:57.428544  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.151179 (* 1 = 0.151179 loss)
I1008 00:48:57.428550  5322 sgd_solver.cpp:105] Iteration 35400, lr = 0.1
I1008 00:49:21.203666  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:49:22.187783  5322 solver.cpp:330] Iteration 35500, Testing net (#0)
I1008 00:49:26.682890  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:49:26.893797  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8179
I1008 00:49:26.893826  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.56871 (* 1 = 0.56871 loss)
I1008 00:49:27.041960  5322 solver.cpp:218] Iteration 35500 (3.37695 iter/s, 29.6126s/100 iters), loss = 0.148779
I1008 00:49:27.041996  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.14878 (* 1 = 0.14878 loss)
I1008 00:49:27.042002  5322 sgd_solver.cpp:105] Iteration 35500, lr = 0.1
I1008 00:49:51.751863  5322 solver.cpp:218] Iteration 35600 (4.04768 iter/s, 24.7055s/100 iters), loss = 0.300713
I1008 00:49:51.751946  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.300713 (* 1 = 0.300713 loss)
I1008 00:49:51.751955  5322 sgd_solver.cpp:105] Iteration 35600, lr = 0.1
I1008 00:50:16.390668  5322 solver.cpp:218] Iteration 35700 (4.05929 iter/s, 24.6348s/100 iters), loss = 0.191316
I1008 00:50:16.390713  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.191317 (* 1 = 0.191317 loss)
I1008 00:50:16.390722  5322 sgd_solver.cpp:105] Iteration 35700, lr = 0.1
I1008 00:50:41.037614  5322 solver.cpp:218] Iteration 35800 (4.05794 iter/s, 24.6431s/100 iters), loss = 0.231271
I1008 00:50:41.037715  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.231272 (* 1 = 0.231272 loss)
I1008 00:50:41.037727  5322 sgd_solver.cpp:105] Iteration 35800, lr = 0.1
I1008 00:51:05.996482  5322 solver.cpp:218] Iteration 35900 (4.00696 iter/s, 24.9566s/100 iters), loss = 0.144634
I1008 00:51:05.996515  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.144634 (* 1 = 0.144634 loss)
I1008 00:51:05.996522  5322 sgd_solver.cpp:105] Iteration 35900, lr = 0.1
I1008 00:51:30.007712  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:51:30.991039  5322 solver.cpp:330] Iteration 36000, Testing net (#0)
I1008 00:51:35.603763  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:51:35.774508  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8204
I1008 00:51:35.774549  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.56446 (* 1 = 0.56446 loss)
I1008 00:51:35.944839  5322 solver.cpp:218] Iteration 36000 (3.33934 iter/s, 29.9461s/100 iters), loss = 0.250624
I1008 00:51:35.944872  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.250624 (* 1 = 0.250624 loss)
I1008 00:51:35.944880  5322 sgd_solver.cpp:105] Iteration 36000, lr = 0.1
I1008 00:52:00.416651  5322 solver.cpp:218] Iteration 36100 (4.08636 iter/s, 24.4717s/100 iters), loss = 0.223969
I1008 00:52:00.416720  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.22397 (* 1 = 0.22397 loss)
I1008 00:52:00.416728  5322 sgd_solver.cpp:105] Iteration 36100, lr = 0.1
I1008 00:52:25.097074  5322 solver.cpp:218] Iteration 36200 (4.05252 iter/s, 24.676s/100 iters), loss = 0.270219
I1008 00:52:25.097113  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.270219 (* 1 = 0.270219 loss)
I1008 00:52:25.097121  5322 sgd_solver.cpp:105] Iteration 36200, lr = 0.1
I1008 00:52:49.768357  5322 solver.cpp:218] Iteration 36300 (4.05367 iter/s, 24.669s/100 iters), loss = 0.220665
I1008 00:52:49.768438  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.220665 (* 1 = 0.220665 loss)
I1008 00:52:49.768448  5322 sgd_solver.cpp:105] Iteration 36300, lr = 0.1
I1008 00:53:14.611094  5322 solver.cpp:218] Iteration 36400 (4.02569 iter/s, 24.8405s/100 iters), loss = 0.198185
I1008 00:53:14.611129  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.198186 (* 1 = 0.198186 loss)
I1008 00:53:14.611136  5322 sgd_solver.cpp:105] Iteration 36400, lr = 0.1
I1008 00:53:38.546799  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:53:39.531157  5322 solver.cpp:330] Iteration 36500, Testing net (#0)
I1008 00:53:44.107825  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:53:44.279007  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8023
I1008 00:53:44.279043  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.634147 (* 1 = 0.634147 loss)
I1008 00:53:44.458241  5322 solver.cpp:218] Iteration 36500 (3.3509 iter/s, 29.8427s/100 iters), loss = 0.194155
I1008 00:53:44.458272  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.194155 (* 1 = 0.194155 loss)
I1008 00:53:44.458281  5322 sgd_solver.cpp:105] Iteration 36500, lr = 0.1
I1008 00:54:09.020340  5322 solver.cpp:218] Iteration 36600 (4.07169 iter/s, 24.5598s/100 iters), loss = 0.152437
I1008 00:54:09.020467  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.152438 (* 1 = 0.152438 loss)
I1008 00:54:09.020475  5322 sgd_solver.cpp:105] Iteration 36600, lr = 0.1
I1008 00:54:33.666394  5322 solver.cpp:218] Iteration 36700 (4.05817 iter/s, 24.6417s/100 iters), loss = 0.151312
I1008 00:54:33.666440  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.151312 (* 1 = 0.151312 loss)
I1008 00:54:33.666448  5322 sgd_solver.cpp:105] Iteration 36700, lr = 0.1
I1008 00:54:58.300410  5322 solver.cpp:218] Iteration 36800 (4.06004 iter/s, 24.6303s/100 iters), loss = 0.169487
I1008 00:54:58.300499  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.169487 (* 1 = 0.169487 loss)
I1008 00:54:58.300511  5322 sgd_solver.cpp:105] Iteration 36800, lr = 0.1
I1008 00:55:23.019248  5322 solver.cpp:218] Iteration 36900 (4.04611 iter/s, 24.7151s/100 iters), loss = 0.137843
I1008 00:55:23.019291  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.137843 (* 1 = 0.137843 loss)
I1008 00:55:23.019299  5322 sgd_solver.cpp:105] Iteration 36900, lr = 0.1
I1008 00:55:47.073771  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:55:48.058177  5322 solver.cpp:330] Iteration 37000, Testing net (#0)
I1008 00:55:52.721933  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:55:52.914222  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7915
I1008 00:55:52.914258  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.66735 (* 1 = 0.66735 loss)
I1008 00:55:53.069053  5322 solver.cpp:218] Iteration 37000 (3.32809 iter/s, 30.0473s/100 iters), loss = 0.177783
I1008 00:55:53.069093  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.177783 (* 1 = 0.177783 loss)
I1008 00:55:53.069102  5322 sgd_solver.cpp:105] Iteration 37000, lr = 0.1
I1008 00:56:17.713271  5322 solver.cpp:218] Iteration 37100 (4.05812 iter/s, 24.6419s/100 iters), loss = 0.179427
I1008 00:56:17.713347  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.179428 (* 1 = 0.179428 loss)
I1008 00:56:17.713356  5322 sgd_solver.cpp:105] Iteration 37100, lr = 0.1
I1008 00:56:42.326638  5322 solver.cpp:218] Iteration 37200 (4.06321 iter/s, 24.6111s/100 iters), loss = 0.170003
I1008 00:56:42.326673  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.170003 (* 1 = 0.170003 loss)
I1008 00:56:42.326680  5322 sgd_solver.cpp:105] Iteration 37200, lr = 0.1
I1008 00:57:06.934353  5322 solver.cpp:218] Iteration 37300 (4.06437 iter/s, 24.6041s/100 iters), loss = 0.169973
I1008 00:57:06.934442  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.169973 (* 1 = 0.169973 loss)
I1008 00:57:06.934450  5322 sgd_solver.cpp:105] Iteration 37300, lr = 0.1
I1008 00:57:31.560979  5322 solver.cpp:218] Iteration 37400 (4.06133 iter/s, 24.6225s/100 iters), loss = 0.194376
I1008 00:57:31.561012  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.194376 (* 1 = 0.194376 loss)
I1008 00:57:31.561017  5322 sgd_solver.cpp:105] Iteration 37400, lr = 0.1
I1008 00:57:55.938938  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:57:56.920409  5322 solver.cpp:330] Iteration 37500, Testing net (#0)
I1008 00:58:01.528007  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:58:01.710922  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8303
I1008 00:58:01.710955  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.525972 (* 1 = 0.525972 loss)
I1008 00:58:01.890866  5322 solver.cpp:218] Iteration 37500 (3.29709 iter/s, 30.3297s/100 iters), loss = 0.159488
I1008 00:58:01.890898  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.159489 (* 1 = 0.159489 loss)
I1008 00:58:01.890907  5322 sgd_solver.cpp:105] Iteration 37500, lr = 0.1
I1008 00:58:26.586694  5322 solver.cpp:218] Iteration 37600 (4.04978 iter/s, 24.6927s/100 iters), loss = 0.251953
I1008 00:58:26.586818  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.251953 (* 1 = 0.251953 loss)
I1008 00:58:26.586833  5322 sgd_solver.cpp:105] Iteration 37600, lr = 0.1
I1008 00:58:51.249491  5322 solver.cpp:218] Iteration 37700 (4.05542 iter/s, 24.6584s/100 iters), loss = 0.175019
I1008 00:58:51.249533  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.175019 (* 1 = 0.175019 loss)
I1008 00:58:51.249541  5322 sgd_solver.cpp:105] Iteration 37700, lr = 0.1
I1008 00:59:15.880939  5322 solver.cpp:218] Iteration 37800 (4.0605 iter/s, 24.6275s/100 iters), loss = 0.273689
I1008 00:59:15.881026  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.273689 (* 1 = 0.273689 loss)
I1008 00:59:15.881037  5322 sgd_solver.cpp:105] Iteration 37800, lr = 0.1
I1008 00:59:40.550770  5322 solver.cpp:218] Iteration 37900 (4.05414 iter/s, 24.6662s/100 iters), loss = 0.189532
I1008 00:59:40.550813  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.189533 (* 1 = 0.189533 loss)
I1008 00:59:40.550820  5322 sgd_solver.cpp:105] Iteration 37900, lr = 0.1
I1008 01:00:04.787753  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:00:05.769193  5322 solver.cpp:330] Iteration 38000, Testing net (#0)
I1008 01:00:10.292014  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:00:10.480152  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8251
I1008 01:00:10.480180  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.551952 (* 1 = 0.551952 loss)
I1008 01:00:10.656996  5322 solver.cpp:218] Iteration 38000 (3.32183 iter/s, 30.1039s/100 iters), loss = 0.212527
I1008 01:00:10.657028  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.212527 (* 1 = 0.212527 loss)
I1008 01:00:10.657037  5322 sgd_solver.cpp:105] Iteration 38000, lr = 0.1
I1008 01:00:35.271030  5322 solver.cpp:218] Iteration 38100 (4.06309 iter/s, 24.6118s/100 iters), loss = 0.183415
I1008 01:00:35.271134  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.183415 (* 1 = 0.183415 loss)
I1008 01:00:35.271154  5322 sgd_solver.cpp:105] Iteration 38100, lr = 0.1
I1008 01:00:59.935024  5322 solver.cpp:218] Iteration 38200 (4.0551 iter/s, 24.6603s/100 iters), loss = 0.34509
I1008 01:00:59.935055  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.345091 (* 1 = 0.345091 loss)
I1008 01:00:59.935062  5322 sgd_solver.cpp:105] Iteration 38200, lr = 0.1
I1008 01:01:24.600225  5322 solver.cpp:218] Iteration 38300 (4.05496 iter/s, 24.6612s/100 iters), loss = 0.214816
I1008 01:01:24.600317  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.214816 (* 1 = 0.214816 loss)
I1008 01:01:24.600337  5322 sgd_solver.cpp:105] Iteration 38300, lr = 0.1
I1008 01:01:49.259886  5322 solver.cpp:218] Iteration 38400 (4.05586 iter/s, 24.6557s/100 iters), loss = 0.153973
I1008 01:01:49.259924  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.153973 (* 1 = 0.153973 loss)
I1008 01:01:49.259941  5322 sgd_solver.cpp:105] Iteration 38400, lr = 0.1
I1008 01:02:13.493000  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:02:14.476785  5322 solver.cpp:330] Iteration 38500, Testing net (#0)
I1008 01:02:19.059183  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:02:19.213286  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8216
I1008 01:02:19.213315  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.558675 (* 1 = 0.558675 loss)
I1008 01:02:19.406551  5322 solver.cpp:218] Iteration 38500 (3.31756 iter/s, 30.1426s/100 iters), loss = 0.18633
I1008 01:02:19.406585  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.186331 (* 1 = 0.186331 loss)
I1008 01:02:19.406594  5322 sgd_solver.cpp:105] Iteration 38500, lr = 0.1
I1008 01:02:43.985304  5322 solver.cpp:218] Iteration 38600 (4.06893 iter/s, 24.5765s/100 iters), loss = 0.247024
I1008 01:02:43.985414  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.247024 (* 1 = 0.247024 loss)
I1008 01:02:43.985424  5322 sgd_solver.cpp:105] Iteration 38600, lr = 0.1
I1008 01:03:08.577376  5322 solver.cpp:218] Iteration 38700 (4.06707 iter/s, 24.5877s/100 iters), loss = 0.213856
I1008 01:03:08.577410  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.213856 (* 1 = 0.213856 loss)
I1008 01:03:08.577417  5322 sgd_solver.cpp:105] Iteration 38700, lr = 0.1
I1008 01:03:33.064446  5322 solver.cpp:218] Iteration 38800 (4.08416 iter/s, 24.4848s/100 iters), loss = 0.158496
I1008 01:03:33.064553  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.158496 (* 1 = 0.158496 loss)
I1008 01:03:33.064569  5322 sgd_solver.cpp:105] Iteration 38800, lr = 0.1
I1008 01:03:57.719857  5322 solver.cpp:218] Iteration 38900 (4.05628 iter/s, 24.6531s/100 iters), loss = 0.201714
I1008 01:03:57.719892  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.201714 (* 1 = 0.201714 loss)
I1008 01:03:57.719899  5322 sgd_solver.cpp:105] Iteration 38900, lr = 0.1
I1008 01:04:21.957258  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:04:22.941800  5322 solver.cpp:330] Iteration 39000, Testing net (#0)
I1008 01:04:27.518328  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:04:27.672761  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8606
I1008 01:04:27.672790  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.416281 (* 1 = 0.416281 loss)
I1008 01:04:27.865973  5322 solver.cpp:218] Iteration 39000 (3.31766 iter/s, 30.1417s/100 iters), loss = 0.161743
I1008 01:04:27.866005  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.161744 (* 1 = 0.161744 loss)
I1008 01:04:27.866013  5322 sgd_solver.cpp:105] Iteration 39000, lr = 0.1
I1008 01:04:52.442144  5322 solver.cpp:218] Iteration 39100 (4.06936 iter/s, 24.5739s/100 iters), loss = 0.276672
I1008 01:04:52.442234  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.276673 (* 1 = 0.276673 loss)
I1008 01:04:52.442242  5322 sgd_solver.cpp:105] Iteration 39100, lr = 0.1
I1008 01:05:17.089203  5322 solver.cpp:218] Iteration 39200 (4.05798 iter/s, 24.6428s/100 iters), loss = 0.30351
I1008 01:05:17.089236  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.30351 (* 1 = 0.30351 loss)
I1008 01:05:17.089244  5322 sgd_solver.cpp:105] Iteration 39200, lr = 0.1
I1008 01:05:41.726465  5322 solver.cpp:218] Iteration 39300 (4.05942 iter/s, 24.634s/100 iters), loss = 0.120454
I1008 01:05:41.726569  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.120454 (* 1 = 0.120454 loss)
I1008 01:05:41.726579  5322 sgd_solver.cpp:105] Iteration 39300, lr = 0.1
I1008 01:06:06.334172  5322 solver.cpp:218] Iteration 39400 (4.0644 iter/s, 24.6038s/100 iters), loss = 0.122819
I1008 01:06:06.334216  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.122819 (* 1 = 0.122819 loss)
I1008 01:06:06.334223  5322 sgd_solver.cpp:105] Iteration 39400, lr = 0.1
I1008 01:06:30.618767  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:06:31.602133  5322 solver.cpp:330] Iteration 39500, Testing net (#0)
I1008 01:06:36.221204  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:06:36.406985  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8176
I1008 01:06:36.407011  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.565115 (* 1 = 0.565115 loss)
I1008 01:06:36.558372  5322 solver.cpp:218] Iteration 39500 (3.30886 iter/s, 30.2219s/100 iters), loss = 0.230779
I1008 01:06:36.558403  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.23078 (* 1 = 0.23078 loss)
I1008 01:06:36.558409  5322 sgd_solver.cpp:105] Iteration 39500, lr = 0.1
I1008 01:07:01.269559  5322 solver.cpp:218] Iteration 39600 (4.04713 iter/s, 24.7089s/100 iters), loss = 0.219579
I1008 01:07:01.269670  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.21958 (* 1 = 0.21958 loss)
I1008 01:07:01.269685  5322 sgd_solver.cpp:105] Iteration 39600, lr = 0.1
I1008 01:07:25.930922  5322 solver.cpp:218] Iteration 39700 (4.05566 iter/s, 24.6569s/100 iters), loss = 0.227105
I1008 01:07:25.930966  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.227105 (* 1 = 0.227105 loss)
I1008 01:07:25.930974  5322 sgd_solver.cpp:105] Iteration 39700, lr = 0.1
I1008 01:07:50.573256  5322 solver.cpp:218] Iteration 39800 (4.05878 iter/s, 24.638s/100 iters), loss = 0.181858
I1008 01:07:50.573345  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.181858 (* 1 = 0.181858 loss)
I1008 01:07:50.573354  5322 sgd_solver.cpp:105] Iteration 39800, lr = 0.1
I1008 01:08:15.223042  5322 solver.cpp:218] Iteration 39900 (4.05743 iter/s, 24.6462s/100 iters), loss = 0.191888
I1008 01:08:15.223089  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.191889 (* 1 = 0.191889 loss)
I1008 01:08:15.223098  5322 sgd_solver.cpp:105] Iteration 39900, lr = 0.1
I1008 01:08:39.562598  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:08:40.539003  5322 solver.cpp:330] Iteration 40000, Testing net (#0)
I1008 01:08:45.096319  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:08:45.296773  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8454
I1008 01:08:45.296811  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.479504 (* 1 = 0.479504 loss)
I1008 01:08:45.427737  5322 solver.cpp:218] Iteration 40000 (3.31122 iter/s, 30.2003s/100 iters), loss = 0.173326
I1008 01:08:45.427780  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.173326 (* 1 = 0.173326 loss)
I1008 01:08:45.427788  5322 sgd_solver.cpp:46] MultiStep Status: Iteration 40000, step = 1
I1008 01:08:45.427790  5322 sgd_solver.cpp:105] Iteration 40000, lr = 0.01
I1008 01:09:10.063459  5322 solver.cpp:218] Iteration 40100 (4.05952 iter/s, 24.6334s/100 iters), loss = 0.189786
I1008 01:09:10.063565  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.189786 (* 1 = 0.189786 loss)
I1008 01:09:10.063580  5322 sgd_solver.cpp:105] Iteration 40100, lr = 0.01
I1008 01:09:34.754561  5322 solver.cpp:218] Iteration 40200 (4.05076 iter/s, 24.6867s/100 iters), loss = 0.198257
I1008 01:09:34.754597  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.198257 (* 1 = 0.198257 loss)
I1008 01:09:34.754604  5322 sgd_solver.cpp:105] Iteration 40200, lr = 0.01
I1008 01:09:59.353979  5322 solver.cpp:218] Iteration 40300 (4.06574 iter/s, 24.5958s/100 iters), loss = 0.168234
I1008 01:09:59.354053  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.168234 (* 1 = 0.168234 loss)
I1008 01:09:59.354061  5322 sgd_solver.cpp:105] Iteration 40300, lr = 0.01
I1008 01:10:24.013835  5322 solver.cpp:218] Iteration 40400 (4.05578 iter/s, 24.6562s/100 iters), loss = 0.095313
I1008 01:10:24.013870  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0953134 (* 1 = 0.0953134 loss)
I1008 01:10:24.013877  5322 sgd_solver.cpp:105] Iteration 40400, lr = 0.01
I1008 01:10:48.255307  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:10:49.239374  5322 solver.cpp:330] Iteration 40500, Testing net (#0)
I1008 01:10:53.898725  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:10:54.099438  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.899
I1008 01:10:54.099463  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.291362 (* 1 = 0.291362 loss)
I1008 01:10:54.250262  5322 solver.cpp:218] Iteration 40500 (3.30752 iter/s, 30.2341s/100 iters), loss = 0.119711
I1008 01:10:54.250293  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.119712 (* 1 = 0.119712 loss)
I1008 01:10:54.250300  5322 sgd_solver.cpp:105] Iteration 40500, lr = 0.01
I1008 01:11:18.904351  5322 solver.cpp:218] Iteration 40600 (4.0565 iter/s, 24.6518s/100 iters), loss = 0.105263
I1008 01:11:18.904459  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.105264 (* 1 = 0.105264 loss)
I1008 01:11:18.904469  5322 sgd_solver.cpp:105] Iteration 40600, lr = 0.01
I1008 01:11:43.565078  5322 solver.cpp:218] Iteration 40700 (4.05576 iter/s, 24.6563s/100 iters), loss = 0.106414
I1008 01:11:43.565119  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.106414 (* 1 = 0.106414 loss)
I1008 01:11:43.565126  5322 sgd_solver.cpp:105] Iteration 40700, lr = 0.01
I1008 01:12:08.220577  5322 solver.cpp:218] Iteration 40800 (4.05653 iter/s, 24.6516s/100 iters), loss = 0.173914
I1008 01:12:08.220664  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.173914 (* 1 = 0.173914 loss)
I1008 01:12:08.220672  5322 sgd_solver.cpp:105] Iteration 40800, lr = 0.01
I1008 01:12:32.868484  5322 solver.cpp:218] Iteration 40900 (4.05775 iter/s, 24.6442s/100 iters), loss = 0.0635376
I1008 01:12:32.868518  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0635379 (* 1 = 0.0635379 loss)
I1008 01:12:32.868535  5322 sgd_solver.cpp:105] Iteration 40900, lr = 0.01
I1008 01:12:57.184536  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:12:58.165678  5322 solver.cpp:330] Iteration 41000, Testing net (#0)
I1008 01:13:02.738378  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:13:02.910353  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.909
I1008 01:13:02.910382  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.263359 (* 1 = 0.263359 loss)
I1008 01:13:03.086375  5322 solver.cpp:218] Iteration 41000 (3.30978 iter/s, 30.2135s/100 iters), loss = 0.0711726
I1008 01:13:03.086410  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0711728 (* 1 = 0.0711728 loss)
I1008 01:13:03.086417  5322 sgd_solver.cpp:105] Iteration 41000, lr = 0.01
I1008 01:13:27.670377  5322 solver.cpp:218] Iteration 41100 (4.06806 iter/s, 24.5817s/100 iters), loss = 0.122618
I1008 01:13:27.670464  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.122618 (* 1 = 0.122618 loss)
I1008 01:13:27.670473  5322 sgd_solver.cpp:105] Iteration 41100, lr = 0.01
I1008 01:13:52.286195  5322 solver.cpp:218] Iteration 41200 (4.0628 iter/s, 24.6136s/100 iters), loss = 0.105288
I1008 01:13:52.286231  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.105288 (* 1 = 0.105288 loss)
I1008 01:13:52.286239  5322 sgd_solver.cpp:105] Iteration 41200, lr = 0.01
I1008 01:14:16.963057  5322 solver.cpp:218] Iteration 41300 (4.05276 iter/s, 24.6746s/100 iters), loss = 0.0877919
I1008 01:14:16.963140  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0877921 (* 1 = 0.0877921 loss)
I1008 01:14:16.963148  5322 sgd_solver.cpp:105] Iteration 41300, lr = 0.01
I1008 01:14:41.622813  5322 solver.cpp:218] Iteration 41400 (4.05557 iter/s, 24.6575s/100 iters), loss = 0.0673662
I1008 01:14:41.622845  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0673664 (* 1 = 0.0673664 loss)
I1008 01:14:41.622853  5322 sgd_solver.cpp:105] Iteration 41400, lr = 0.01
I1008 01:15:05.930225  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:15:06.914070  5322 solver.cpp:330] Iteration 41500, Testing net (#0)
I1008 01:15:11.567155  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:15:11.765755  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9071
I1008 01:15:11.765781  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.271018 (* 1 = 0.271018 loss)
I1008 01:15:11.907770  5322 solver.cpp:218] Iteration 41500 (3.30222 iter/s, 30.2827s/100 iters), loss = 0.0666309
I1008 01:15:11.907802  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0666311 (* 1 = 0.0666311 loss)
I1008 01:15:11.907810  5322 sgd_solver.cpp:105] Iteration 41500, lr = 0.01
I1008 01:15:36.568071  5322 solver.cpp:218] Iteration 41600 (4.05547 iter/s, 24.658s/100 iters), loss = 0.0890923
I1008 01:15:36.568177  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0890925 (* 1 = 0.0890925 loss)
I1008 01:15:36.568186  5322 sgd_solver.cpp:105] Iteration 41600, lr = 0.01
I1008 01:16:01.203205  5322 solver.cpp:218] Iteration 41700 (4.05997 iter/s, 24.6307s/100 iters), loss = 0.0493278
I1008 01:16:01.203238  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.049328 (* 1 = 0.049328 loss)
I1008 01:16:01.203246  5322 sgd_solver.cpp:105] Iteration 41700, lr = 0.01
I1008 01:16:25.853595  5322 solver.cpp:218] Iteration 41800 (4.05737 iter/s, 24.6465s/100 iters), loss = 0.14568
I1008 01:16:25.853667  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.145681 (* 1 = 0.145681 loss)
I1008 01:16:25.853675  5322 sgd_solver.cpp:105] Iteration 41800, lr = 0.01
I1008 01:16:50.512450  5322 solver.cpp:218] Iteration 41900 (4.05571 iter/s, 24.6566s/100 iters), loss = 0.0464215
I1008 01:16:50.512485  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0464217 (* 1 = 0.0464217 loss)
I1008 01:16:50.512491  5322 sgd_solver.cpp:105] Iteration 41900, lr = 0.01
I1008 01:17:14.687553  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:17:15.654939  5322 solver.cpp:330] Iteration 42000, Testing net (#0)
I1008 01:17:20.218608  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:17:20.449352  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9068
I1008 01:17:20.449378  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.272072 (* 1 = 0.272072 loss)
I1008 01:17:20.578040  5322 solver.cpp:218] Iteration 42000 (3.32631 iter/s, 30.0633s/100 iters), loss = 0.0660068
I1008 01:17:20.578073  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.066007 (* 1 = 0.066007 loss)
I1008 01:17:20.578080  5322 sgd_solver.cpp:105] Iteration 42000, lr = 0.01
I1008 01:17:45.271931  5322 solver.cpp:218] Iteration 42100 (4.05031 iter/s, 24.6895s/100 iters), loss = 0.0881654
I1008 01:17:45.272016  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0881657 (* 1 = 0.0881657 loss)
I1008 01:17:45.272024  5322 sgd_solver.cpp:105] Iteration 42100, lr = 0.01
I1008 01:18:09.929841  5322 solver.cpp:218] Iteration 42200 (4.05586 iter/s, 24.6557s/100 iters), loss = 0.101726
I1008 01:18:09.929875  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.101726 (* 1 = 0.101726 loss)
I1008 01:18:09.929883  5322 sgd_solver.cpp:105] Iteration 42200, lr = 0.01
I1008 01:18:34.582681  5322 solver.cpp:218] Iteration 42300 (4.0567 iter/s, 24.6506s/100 iters), loss = 0.0836247
I1008 01:18:34.582759  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.083625 (* 1 = 0.083625 loss)
I1008 01:18:34.582769  5322 sgd_solver.cpp:105] Iteration 42300, lr = 0.01
I1008 01:18:59.220228  5322 solver.cpp:218] Iteration 42400 (4.05922 iter/s, 24.6353s/100 iters), loss = 0.0715512
I1008 01:18:59.220263  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0715514 (* 1 = 0.0715514 loss)
I1008 01:18:59.220271  5322 sgd_solver.cpp:105] Iteration 42400, lr = 0.01
I1008 01:19:23.370275  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:19:24.354651  5322 solver.cpp:330] Iteration 42500, Testing net (#0)
I1008 01:19:28.925453  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:19:29.094094  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.911
I1008 01:19:29.094122  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.264799 (* 1 = 0.264799 loss)
I1008 01:19:29.265023  5322 solver.cpp:218] Iteration 42500 (3.32886 iter/s, 30.0404s/100 iters), loss = 0.0353806
I1008 01:19:29.265069  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0353808 (* 1 = 0.0353808 loss)
I1008 01:19:29.265076  5322 sgd_solver.cpp:105] Iteration 42500, lr = 0.01
I1008 01:19:53.864661  5322 solver.cpp:218] Iteration 42600 (4.06548 iter/s, 24.5974s/100 iters), loss = 0.0869453
I1008 01:19:53.864770  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0869456 (* 1 = 0.0869456 loss)
I1008 01:19:53.864779  5322 sgd_solver.cpp:105] Iteration 42600, lr = 0.01
I1008 01:20:18.521888  5322 solver.cpp:218] Iteration 42700 (4.05626 iter/s, 24.6532s/100 iters), loss = 0.0935714
I1008 01:20:18.521930  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0935716 (* 1 = 0.0935716 loss)
I1008 01:20:18.521937  5322 sgd_solver.cpp:105] Iteration 42700, lr = 0.01
I1008 01:20:43.186208  5322 solver.cpp:218] Iteration 42800 (4.05516 iter/s, 24.6599s/100 iters), loss = 0.0670373
I1008 01:20:43.186345  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0670375 (* 1 = 0.0670375 loss)
I1008 01:20:43.186353  5322 sgd_solver.cpp:105] Iteration 42800, lr = 0.01
I1008 01:21:07.837896  5322 solver.cpp:218] Iteration 42900 (4.05689 iter/s, 24.6494s/100 iters), loss = 0.0401366
I1008 01:21:07.837929  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0401369 (* 1 = 0.0401369 loss)
I1008 01:21:07.837935  5322 sgd_solver.cpp:105] Iteration 42900, lr = 0.01
I1008 01:21:32.060868  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:21:33.045315  5322 solver.cpp:330] Iteration 43000, Testing net (#0)
I1008 01:21:37.706182  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:21:37.868604  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9114
I1008 01:21:37.868633  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.265951 (* 1 = 0.265951 loss)
I1008 01:21:38.054618  5322 solver.cpp:218] Iteration 43000 (3.30967 iter/s, 30.2145s/100 iters), loss = 0.0485084
I1008 01:21:38.054652  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0485086 (* 1 = 0.0485086 loss)
I1008 01:21:38.054659  5322 sgd_solver.cpp:105] Iteration 43000, lr = 0.01
I1008 01:22:02.725913  5322 solver.cpp:218] Iteration 43100 (4.05367 iter/s, 24.669s/100 iters), loss = 0.119666
I1008 01:22:02.725996  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.119666 (* 1 = 0.119666 loss)
I1008 01:22:02.726006  5322 sgd_solver.cpp:105] Iteration 43100, lr = 0.01
I1008 01:22:27.398430  5322 solver.cpp:218] Iteration 43200 (4.05347 iter/s, 24.6702s/100 iters), loss = 0.0658838
I1008 01:22:27.398466  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.065884 (* 1 = 0.065884 loss)
I1008 01:22:27.398474  5322 sgd_solver.cpp:105] Iteration 43200, lr = 0.01
I1008 01:22:52.053861  5322 solver.cpp:218] Iteration 43300 (4.05649 iter/s, 24.6518s/100 iters), loss = 0.125769
I1008 01:22:52.053917  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.125769 (* 1 = 0.125769 loss)
I1008 01:22:52.053925  5322 sgd_solver.cpp:105] Iteration 43300, lr = 0.01
I1008 01:23:16.642472  5322 solver.cpp:218] Iteration 43400 (4.06765 iter/s, 24.5842s/100 iters), loss = 0.0373726
I1008 01:23:16.642509  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0373729 (* 1 = 0.0373729 loss)
I1008 01:23:16.642516  5322 sgd_solver.cpp:105] Iteration 43400, lr = 0.01
I1008 01:23:40.777856  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:23:41.760486  5322 solver.cpp:330] Iteration 43500, Testing net (#0)
I1008 01:23:46.331120  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:23:46.497237  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9096
I1008 01:23:46.497263  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.269014 (* 1 = 0.269014 loss)
I1008 01:23:46.681274  5322 solver.cpp:218] Iteration 43500 (3.32942 iter/s, 30.0352s/100 iters), loss = 0.038842
I1008 01:23:46.681308  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0388422 (* 1 = 0.0388422 loss)
I1008 01:23:46.681314  5322 sgd_solver.cpp:105] Iteration 43500, lr = 0.01
I1008 01:24:11.227699  5322 solver.cpp:218] Iteration 43600 (4.07429 iter/s, 24.5441s/100 iters), loss = 0.126164
I1008 01:24:11.227808  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.126164 (* 1 = 0.126164 loss)
I1008 01:24:11.227816  5322 sgd_solver.cpp:105] Iteration 43600, lr = 0.01
I1008 01:24:35.857514  5322 solver.cpp:218] Iteration 43700 (4.06072 iter/s, 24.6262s/100 iters), loss = 0.0736759
I1008 01:24:35.857551  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0736761 (* 1 = 0.0736761 loss)
I1008 01:24:35.857558  5322 sgd_solver.cpp:105] Iteration 43700, lr = 0.01
I1008 01:25:00.468067  5322 solver.cpp:218] Iteration 43800 (4.06391 iter/s, 24.6069s/100 iters), loss = 0.0461635
I1008 01:25:00.468183  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0461637 (* 1 = 0.0461637 loss)
I1008 01:25:00.468195  5322 sgd_solver.cpp:105] Iteration 43800, lr = 0.01
I1008 01:25:25.130089  5322 solver.cpp:218] Iteration 43900 (4.05553 iter/s, 24.6577s/100 iters), loss = 0.058778
I1008 01:25:25.130122  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0587782 (* 1 = 0.0587782 loss)
I1008 01:25:25.130131  5322 sgd_solver.cpp:105] Iteration 43900, lr = 0.01
I1008 01:25:49.262157  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:25:50.245776  5322 solver.cpp:330] Iteration 44000, Testing net (#0)
I1008 01:25:54.740705  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:25:54.953212  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9162
I1008 01:25:54.953238  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.265717 (* 1 = 0.265717 loss)
I1008 01:25:55.082010  5322 solver.cpp:218] Iteration 44000 (3.3391 iter/s, 29.9482s/100 iters), loss = 0.0612048
I1008 01:25:55.082051  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.061205 (* 1 = 0.061205 loss)
I1008 01:25:55.082057  5322 sgd_solver.cpp:105] Iteration 44000, lr = 0.01
I1008 01:26:19.713572  5322 solver.cpp:218] Iteration 44100 (4.06022 iter/s, 24.6292s/100 iters), loss = 0.0497651
I1008 01:26:19.713654  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0497653 (* 1 = 0.0497653 loss)
I1008 01:26:19.713661  5322 sgd_solver.cpp:105] Iteration 44100, lr = 0.01
I1008 01:26:44.351531  5322 solver.cpp:218] Iteration 44200 (4.0594 iter/s, 24.6342s/100 iters), loss = 0.0989413
I1008 01:26:44.351567  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0989415 (* 1 = 0.0989415 loss)
I1008 01:26:44.351583  5322 sgd_solver.cpp:105] Iteration 44200, lr = 0.01
I1008 01:27:08.993408  5322 solver.cpp:218] Iteration 44300 (4.05877 iter/s, 24.638s/100 iters), loss = 0.0994979
I1008 01:27:08.993477  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0994981 (* 1 = 0.0994981 loss)
I1008 01:27:08.993485  5322 sgd_solver.cpp:105] Iteration 44300, lr = 0.01
I1008 01:27:33.637399  5322 solver.cpp:218] Iteration 44400 (4.05837 iter/s, 24.6404s/100 iters), loss = 0.0558726
I1008 01:27:33.637437  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0558728 (* 1 = 0.0558728 loss)
I1008 01:27:33.637446  5322 sgd_solver.cpp:105] Iteration 44400, lr = 0.01
I1008 01:27:57.873404  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:27:58.858636  5322 solver.cpp:330] Iteration 44500, Testing net (#0)
I1008 01:28:03.446952  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:28:03.623973  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9164
I1008 01:28:03.624003  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.259533 (* 1 = 0.259533 loss)
I1008 01:28:03.786967  5322 solver.cpp:218] Iteration 44500 (3.31705 iter/s, 30.1473s/100 iters), loss = 0.0227217
I1008 01:28:03.787003  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0227219 (* 1 = 0.0227219 loss)
I1008 01:28:03.787011  5322 sgd_solver.cpp:105] Iteration 44500, lr = 0.01
I1008 01:28:28.302294  5322 solver.cpp:218] Iteration 44600 (4.07946 iter/s, 24.513s/100 iters), loss = 0.0416283
I1008 01:28:28.302388  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0416285 (* 1 = 0.0416285 loss)
I1008 01:28:28.302398  5322 sgd_solver.cpp:105] Iteration 44600, lr = 0.01
I1008 01:28:52.907132  5322 solver.cpp:218] Iteration 44700 (4.06484 iter/s, 24.6012s/100 iters), loss = 0.0554007
I1008 01:28:52.907169  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0554009 (* 1 = 0.0554009 loss)
I1008 01:28:52.907177  5322 sgd_solver.cpp:105] Iteration 44700, lr = 0.01
I1008 01:29:17.563627  5322 solver.cpp:218] Iteration 44800 (4.05644 iter/s, 24.6521s/100 iters), loss = 0.0558345
I1008 01:29:17.563743  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0558347 (* 1 = 0.0558347 loss)
I1008 01:29:17.563762  5322 sgd_solver.cpp:105] Iteration 44800, lr = 0.01
I1008 01:29:42.196419  5322 solver.cpp:218] Iteration 44900 (4.06023 iter/s, 24.6291s/100 iters), loss = 0.0548224
I1008 01:29:42.196454  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0548226 (* 1 = 0.0548226 loss)
I1008 01:29:42.196460  5322 sgd_solver.cpp:105] Iteration 44900, lr = 0.01
I1008 01:30:06.417073  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:30:07.402037  5322 solver.cpp:330] Iteration 45000, Testing net (#0)
I1008 01:30:12.037456  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:30:12.215991  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9134
I1008 01:30:12.216017  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.268206 (* 1 = 0.268206 loss)
I1008 01:30:12.368116  5322 solver.cpp:218] Iteration 45000 (3.31461 iter/s, 30.1695s/100 iters), loss = 0.0543272
I1008 01:30:12.368146  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0543274 (* 1 = 0.0543274 loss)
I1008 01:30:12.368154  5322 sgd_solver.cpp:105] Iteration 45000, lr = 0.01
I1008 01:30:36.972277  5322 solver.cpp:218] Iteration 45100 (4.06473 iter/s, 24.6019s/100 iters), loss = 0.0980516
I1008 01:30:36.972357  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0980518 (* 1 = 0.0980518 loss)
I1008 01:30:36.972367  5322 sgd_solver.cpp:105] Iteration 45100, lr = 0.01
I1008 01:31:01.634661  5322 solver.cpp:218] Iteration 45200 (4.05513 iter/s, 24.6601s/100 iters), loss = 0.0287933
I1008 01:31:01.634693  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0287935 (* 1 = 0.0287935 loss)
I1008 01:31:01.634699  5322 sgd_solver.cpp:105] Iteration 45200, lr = 0.01
I1008 01:31:26.306279  5322 solver.cpp:218] Iteration 45300 (4.05361 iter/s, 24.6693s/100 iters), loss = 0.0529547
I1008 01:31:26.306355  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0529549 (* 1 = 0.0529549 loss)
I1008 01:31:26.306365  5322 sgd_solver.cpp:105] Iteration 45300, lr = 0.01
I1008 01:31:50.958237  5322 solver.cpp:218] Iteration 45400 (4.05684 iter/s, 24.6497s/100 iters), loss = 0.0328553
I1008 01:31:50.958281  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0328555 (* 1 = 0.0328555 loss)
I1008 01:31:50.958287  5322 sgd_solver.cpp:105] Iteration 45400, lr = 0.01
I1008 01:32:15.201046  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:32:16.185150  5322 solver.cpp:330] Iteration 45500, Testing net (#0)
I1008 01:32:20.759878  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:32:20.945221  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9135
I1008 01:32:20.945250  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.273437 (* 1 = 0.273437 loss)
I1008 01:32:21.113334  5322 solver.cpp:218] Iteration 45500 (3.31668 iter/s, 30.1506s/100 iters), loss = 0.039431
I1008 01:32:21.113369  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0394312 (* 1 = 0.0394312 loss)
I1008 01:32:21.113379  5322 sgd_solver.cpp:105] Iteration 45500, lr = 0.01
I1008 01:32:45.680706  5322 solver.cpp:218] Iteration 45600 (4.07082 iter/s, 24.5651s/100 iters), loss = 0.0614773
I1008 01:32:45.680794  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0614776 (* 1 = 0.0614776 loss)
I1008 01:32:45.680801  5322 sgd_solver.cpp:105] Iteration 45600, lr = 0.01
I1008 01:33:10.334566  5322 solver.cpp:218] Iteration 45700 (4.05679 iter/s, 24.65s/100 iters), loss = 0.0597637
I1008 01:33:10.334602  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0597639 (* 1 = 0.0597639 loss)
I1008 01:33:10.334609  5322 sgd_solver.cpp:105] Iteration 45700, lr = 0.01
I1008 01:33:34.969986  5322 solver.cpp:218] Iteration 45800 (4.05985 iter/s, 24.6314s/100 iters), loss = 0.0562852
I1008 01:33:34.970094  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0562855 (* 1 = 0.0562855 loss)
I1008 01:33:34.970113  5322 sgd_solver.cpp:105] Iteration 45800, lr = 0.01
I1008 01:33:59.616195  5322 solver.cpp:218] Iteration 45900 (4.05779 iter/s, 24.644s/100 iters), loss = 0.0472168
I1008 01:33:59.616228  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.047217 (* 1 = 0.047217 loss)
I1008 01:33:59.616235  5322 sgd_solver.cpp:105] Iteration 45900, lr = 0.01
I1008 01:34:23.887198  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:34:24.824478  5322 solver.cpp:330] Iteration 46000, Testing net (#0)
I1008 01:34:29.466439  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:34:29.681850  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9186
I1008 01:34:29.681887  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.260646 (* 1 = 0.260646 loss)
I1008 01:34:29.804721  5322 solver.cpp:218] Iteration 46000 (3.31297 iter/s, 30.1844s/100 iters), loss = 0.0441225
I1008 01:34:29.804766  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0441227 (* 1 = 0.0441227 loss)
I1008 01:34:29.804774  5322 sgd_solver.cpp:105] Iteration 46000, lr = 0.01
I1008 01:34:54.498711  5322 solver.cpp:218] Iteration 46100 (4.04994 iter/s, 24.6917s/100 iters), loss = 0.0726242
I1008 01:34:54.498797  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0726244 (* 1 = 0.0726244 loss)
I1008 01:34:54.498809  5322 sgd_solver.cpp:105] Iteration 46100, lr = 0.01
I1008 01:35:19.146780  5322 solver.cpp:218] Iteration 46200 (4.05768 iter/s, 24.6446s/100 iters), loss = 0.0335696
I1008 01:35:19.146814  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0335698 (* 1 = 0.0335698 loss)
I1008 01:35:19.146821  5322 sgd_solver.cpp:105] Iteration 46200, lr = 0.01
I1008 01:35:43.798770  5322 solver.cpp:218] Iteration 46300 (4.05713 iter/s, 24.648s/100 iters), loss = 0.0603285
I1008 01:35:43.798871  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0603287 (* 1 = 0.0603287 loss)
I1008 01:35:43.798893  5322 sgd_solver.cpp:105] Iteration 46300, lr = 0.01
I1008 01:36:08.456612  5322 solver.cpp:218] Iteration 46400 (4.05623 iter/s, 24.6534s/100 iters), loss = 0.0448901
I1008 01:36:08.456647  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0448903 (* 1 = 0.0448903 loss)
I1008 01:36:08.456655  5322 sgd_solver.cpp:105] Iteration 46400, lr = 0.01
I1008 01:36:32.588517  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:36:33.590662  5322 solver.cpp:330] Iteration 46500, Testing net (#0)
I1008 01:36:38.160058  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:36:38.329567  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9171
I1008 01:36:38.329603  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.266792 (* 1 = 0.266792 loss)
I1008 01:36:38.510049  5322 solver.cpp:218] Iteration 46500 (3.32789 iter/s, 30.0491s/100 iters), loss = 0.0337427
I1008 01:36:38.510080  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0337429 (* 1 = 0.0337429 loss)
I1008 01:36:38.510087  5322 sgd_solver.cpp:105] Iteration 46500, lr = 0.01
I1008 01:37:03.101878  5322 solver.cpp:218] Iteration 46600 (4.06676 iter/s, 24.5896s/100 iters), loss = 0.0199462
I1008 01:37:03.101943  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0199464 (* 1 = 0.0199464 loss)
I1008 01:37:03.101960  5322 sgd_solver.cpp:105] Iteration 46600, lr = 0.01
I1008 01:37:27.756752  5322 solver.cpp:218] Iteration 46700 (4.05672 iter/s, 24.6505s/100 iters), loss = 0.0384217
I1008 01:37:27.756786  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0384219 (* 1 = 0.0384219 loss)
I1008 01:37:27.756793  5322 sgd_solver.cpp:105] Iteration 46700, lr = 0.01
I1008 01:37:52.397673  5322 solver.cpp:218] Iteration 46800 (4.05888 iter/s, 24.6374s/100 iters), loss = 0.0685057
I1008 01:37:52.397796  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0685059 (* 1 = 0.0685059 loss)
I1008 01:37:52.397807  5322 sgd_solver.cpp:105] Iteration 46800, lr = 0.01
I1008 01:38:17.044229  5322 solver.cpp:218] Iteration 46900 (4.05808 iter/s, 24.6422s/100 iters), loss = 0.0522309
I1008 01:38:17.044266  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0522311 (* 1 = 0.0522311 loss)
I1008 01:38:17.044275  5322 sgd_solver.cpp:105] Iteration 46900, lr = 0.01
I1008 01:38:41.103473  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:38:42.158715  5322 solver.cpp:330] Iteration 47000, Testing net (#0)
I1008 01:38:46.788954  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:38:47.007593  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9164
I1008 01:38:47.007630  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.274854 (* 1 = 0.274854 loss)
I1008 01:38:47.110827  5322 solver.cpp:218] Iteration 47000 (3.3262 iter/s, 30.0643s/100 iters), loss = 0.0230346
I1008 01:38:47.110864  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0230348 (* 1 = 0.0230348 loss)
I1008 01:38:47.110873  5322 sgd_solver.cpp:105] Iteration 47000, lr = 0.01
I1008 01:39:11.722122  5322 solver.cpp:218] Iteration 47100 (4.06321 iter/s, 24.6111s/100 iters), loss = 0.0444431
I1008 01:39:11.722218  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0444433 (* 1 = 0.0444433 loss)
I1008 01:39:11.722230  5322 sgd_solver.cpp:105] Iteration 47100, lr = 0.01
I1008 01:39:36.347172  5322 solver.cpp:218] Iteration 47200 (4.06157 iter/s, 24.621s/100 iters), loss = 0.0490666
I1008 01:39:36.347208  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0490667 (* 1 = 0.0490667 loss)
I1008 01:39:36.347215  5322 sgd_solver.cpp:105] Iteration 47200, lr = 0.01
I1008 01:40:00.967339  5322 solver.cpp:218] Iteration 47300 (4.06243 iter/s, 24.6158s/100 iters), loss = 0.0421834
I1008 01:40:00.967422  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0421835 (* 1 = 0.0421835 loss)
I1008 01:40:00.967429  5322 sgd_solver.cpp:105] Iteration 47300, lr = 0.01
I1008 01:40:25.566329  5322 solver.cpp:218] Iteration 47400 (4.06593 iter/s, 24.5946s/100 iters), loss = 0.0380983
I1008 01:40:25.566362  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0380985 (* 1 = 0.0380985 loss)
I1008 01:40:25.566370  5322 sgd_solver.cpp:105] Iteration 47400, lr = 0.01
I1008 01:40:49.635576  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:40:50.691329  5322 solver.cpp:330] Iteration 47500, Testing net (#0)
I1008 01:40:55.413264  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:40:55.608065  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9109
I1008 01:40:55.608094  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.285324 (* 1 = 0.285324 loss)
I1008 01:40:55.755329  5322 solver.cpp:218] Iteration 47500 (3.31295 iter/s, 30.1846s/100 iters), loss = 0.021924
I1008 01:40:55.755363  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0219241 (* 1 = 0.0219241 loss)
I1008 01:40:55.755372  5322 sgd_solver.cpp:105] Iteration 47500, lr = 0.01
I1008 01:41:20.308200  5322 solver.cpp:218] Iteration 47600 (4.07287 iter/s, 24.5527s/100 iters), loss = 0.0209852
I1008 01:41:20.308315  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0209854 (* 1 = 0.0209854 loss)
I1008 01:41:20.308326  5322 sgd_solver.cpp:105] Iteration 47600, lr = 0.01
I1008 01:41:44.954622  5322 solver.cpp:218] Iteration 47700 (4.05776 iter/s, 24.6442s/100 iters), loss = 0.0543122
I1008 01:41:44.954658  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0543124 (* 1 = 0.0543124 loss)
I1008 01:41:44.954664  5322 sgd_solver.cpp:105] Iteration 47700, lr = 0.01
I1008 01:42:09.605029  5322 solver.cpp:218] Iteration 47800 (4.05732 iter/s, 24.6468s/100 iters), loss = 0.0597585
I1008 01:42:09.605131  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0597586 (* 1 = 0.0597586 loss)
I1008 01:42:09.605142  5322 sgd_solver.cpp:105] Iteration 47800, lr = 0.01
I1008 01:42:34.210834  5322 solver.cpp:218] Iteration 47900 (4.0647 iter/s, 24.6021s/100 iters), loss = 0.014355
I1008 01:42:34.210877  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0143552 (* 1 = 0.0143552 loss)
I1008 01:42:34.210885  5322 sgd_solver.cpp:105] Iteration 47900, lr = 0.01
I1008 01:42:58.192093  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:42:59.250125  5322 solver.cpp:330] Iteration 48000, Testing net (#0)
I1008 01:43:04.196089  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:43:04.381248  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9121
I1008 01:43:04.381276  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.285491 (* 1 = 0.285491 loss)
I1008 01:43:04.589601  5322 solver.cpp:218] Iteration 48000 (3.29217 iter/s, 30.3751s/100 iters), loss = 0.0153222
I1008 01:43:04.589638  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0153223 (* 1 = 0.0153223 loss)
I1008 01:43:04.589648  5322 sgd_solver.cpp:105] Iteration 48000, lr = 0.01
I1008 01:43:29.222618  5322 solver.cpp:218] Iteration 48100 (4.0602 iter/s, 24.6293s/100 iters), loss = 0.0875156
I1008 01:43:29.222673  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0875158 (* 1 = 0.0875158 loss)
I1008 01:43:29.222681  5322 sgd_solver.cpp:105] Iteration 48100, lr = 0.01
I1008 01:43:53.847076  5322 solver.cpp:218] Iteration 48200 (4.06138 iter/s, 24.6222s/100 iters), loss = 0.0196418
I1008 01:43:53.847110  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.019642 (* 1 = 0.019642 loss)
I1008 01:43:53.847117  5322 sgd_solver.cpp:105] Iteration 48200, lr = 0.01
I1008 01:44:18.451704  5322 solver.cpp:218] Iteration 48300 (4.06465 iter/s, 24.6024s/100 iters), loss = 0.0357301
I1008 01:44:18.451776  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0357302 (* 1 = 0.0357302 loss)
I1008 01:44:18.451783  5322 sgd_solver.cpp:105] Iteration 48300, lr = 0.01
I1008 01:44:43.085794  5322 solver.cpp:218] Iteration 48400 (4.05979 iter/s, 24.6318s/100 iters), loss = 0.0262092
I1008 01:44:43.085829  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0262094 (* 1 = 0.0262094 loss)
I1008 01:44:43.085836  5322 sgd_solver.cpp:105] Iteration 48400, lr = 0.01
I1008 01:45:06.885330  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:45:07.950961  5322 solver.cpp:330] Iteration 48500, Testing net (#0)
I1008 01:45:12.966053  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:45:13.140808  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9155
I1008 01:45:13.140836  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.276402 (* 1 = 0.276402 loss)
I1008 01:45:13.340600  5322 solver.cpp:218] Iteration 48500 (3.30551 iter/s, 30.2525s/100 iters), loss = 0.0110348
I1008 01:45:13.340636  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0110349 (* 1 = 0.0110349 loss)
I1008 01:45:13.340646  5322 sgd_solver.cpp:105] Iteration 48500, lr = 0.01
I1008 01:45:38.003206  5322 solver.cpp:218] Iteration 48600 (4.0551 iter/s, 24.6603s/100 iters), loss = 0.041342
I1008 01:45:38.003281  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0413422 (* 1 = 0.0413422 loss)
I1008 01:45:38.003293  5322 sgd_solver.cpp:105] Iteration 48600, lr = 0.01
I1008 01:46:02.642146  5322 solver.cpp:218] Iteration 48700 (4.05917 iter/s, 24.6356s/100 iters), loss = 0.0247008
I1008 01:46:02.642184  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.024701 (* 1 = 0.024701 loss)
I1008 01:46:02.642191  5322 sgd_solver.cpp:105] Iteration 48700, lr = 0.01
I1008 01:46:27.261850  5322 solver.cpp:218] Iteration 48800 (4.06237 iter/s, 24.6162s/100 iters), loss = 0.0446901
I1008 01:46:27.261973  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0446902 (* 1 = 0.0446902 loss)
I1008 01:46:27.261983  5322 sgd_solver.cpp:105] Iteration 48800, lr = 0.01
I1008 01:46:51.892709  5322 solver.cpp:218] Iteration 48900 (4.06054 iter/s, 24.6272s/100 iters), loss = 0.0128042
I1008 01:46:51.892753  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0128043 (* 1 = 0.0128043 loss)
I1008 01:46:51.892760  5322 sgd_solver.cpp:105] Iteration 48900, lr = 0.01
I1008 01:47:15.745954  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:47:16.806440  5322 solver.cpp:330] Iteration 49000, Testing net (#0)
I1008 01:47:21.810479  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:47:22.038830  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9152
I1008 01:47:22.038856  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.288505 (* 1 = 0.288505 loss)
I1008 01:47:22.148808  5322 solver.cpp:218] Iteration 49000 (3.30536 iter/s, 30.2538s/100 iters), loss = 0.0232397
I1008 01:47:22.148840  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0232399 (* 1 = 0.0232399 loss)
I1008 01:47:22.148849  5322 sgd_solver.cpp:105] Iteration 49000, lr = 0.01
I1008 01:47:46.815402  5322 solver.cpp:218] Iteration 49100 (4.05409 iter/s, 24.6665s/100 iters), loss = 0.0380355
I1008 01:47:46.815482  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0380356 (* 1 = 0.0380356 loss)
I1008 01:47:46.815490  5322 sgd_solver.cpp:105] Iteration 49100, lr = 0.01
I1008 01:48:11.445394  5322 solver.cpp:218] Iteration 49200 (4.0607 iter/s, 24.6263s/100 iters), loss = 0.0416786
I1008 01:48:11.445428  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0416788 (* 1 = 0.0416788 loss)
I1008 01:48:11.445436  5322 sgd_solver.cpp:105] Iteration 49200, lr = 0.01
I1008 01:48:36.059715  5322 solver.cpp:218] Iteration 49300 (4.06331 iter/s, 24.6105s/100 iters), loss = 0.0477464
I1008 01:48:36.059790  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0477466 (* 1 = 0.0477466 loss)
I1008 01:48:36.059798  5322 sgd_solver.cpp:105] Iteration 49300, lr = 0.01
I1008 01:49:00.670644  5322 solver.cpp:218] Iteration 49400 (4.06361 iter/s, 24.6087s/100 iters), loss = 0.0239326
I1008 01:49:00.670681  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0239328 (* 1 = 0.0239328 loss)
I1008 01:49:00.670691  5322 sgd_solver.cpp:105] Iteration 49400, lr = 0.01
I1008 01:49:24.460535  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:49:25.454218  5322 solver.cpp:330] Iteration 49500, Testing net (#0)
I1008 01:49:30.702349  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:49:30.878571  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9139
I1008 01:49:30.878598  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.292592 (* 1 = 0.292592 loss)
I1008 01:49:31.047348  5322 solver.cpp:218] Iteration 49500 (3.29224 iter/s, 30.3745s/100 iters), loss = 0.0536342
I1008 01:49:31.047381  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0536344 (* 1 = 0.0536344 loss)
I1008 01:49:31.047389  5322 sgd_solver.cpp:105] Iteration 49500, lr = 0.01
I1008 01:49:55.601421  5322 solver.cpp:218] Iteration 49600 (4.07302 iter/s, 24.5518s/100 iters), loss = 0.0425589
I1008 01:49:55.601490  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.042559 (* 1 = 0.042559 loss)
I1008 01:49:55.601500  5322 sgd_solver.cpp:105] Iteration 49600, lr = 0.01
I1008 01:50:20.248034  5322 solver.cpp:218] Iteration 49700 (4.05808 iter/s, 24.6422s/100 iters), loss = 0.0217013
I1008 01:50:20.248072  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0217015 (* 1 = 0.0217015 loss)
I1008 01:50:20.248080  5322 sgd_solver.cpp:105] Iteration 49700, lr = 0.01
I1008 01:50:44.900025  5322 solver.cpp:218] Iteration 49800 (4.05712 iter/s, 24.648s/100 iters), loss = 0.0250237
I1008 01:50:44.900141  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0250239 (* 1 = 0.0250239 loss)
I1008 01:50:44.900149  5322 sgd_solver.cpp:105] Iteration 49800, lr = 0.01
I1008 01:51:09.529563  5322 solver.cpp:218] Iteration 49900 (4.06081 iter/s, 24.6256s/100 iters), loss = 0.0507738
I1008 01:51:09.529599  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0507739 (* 1 = 0.0507739 loss)
I1008 01:51:09.529608  5322 sgd_solver.cpp:105] Iteration 49900, lr = 0.01
I1008 01:51:33.379498  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:51:34.366134  5322 solver.cpp:330] Iteration 50000, Testing net (#0)
I1008 01:51:39.503023  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:51:39.677295  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9118
I1008 01:51:39.677333  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.295684 (* 1 = 0.295684 loss)
I1008 01:51:39.872531  5322 solver.cpp:218] Iteration 50000 (3.29605 iter/s, 30.3394s/100 iters), loss = 0.0292005
I1008 01:51:39.872575  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0292007 (* 1 = 0.0292007 loss)
I1008 01:51:39.872583  5322 sgd_solver.cpp:105] Iteration 50000, lr = 0.01
I1008 01:52:04.546504  5322 solver.cpp:218] Iteration 50100 (4.05323 iter/s, 24.6717s/100 iters), loss = 0.0729432
I1008 01:52:04.546563  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0729433 (* 1 = 0.0729433 loss)
I1008 01:52:04.546571  5322 sgd_solver.cpp:105] Iteration 50100, lr = 0.01
I1008 01:52:29.215368  5322 solver.cpp:218] Iteration 50200 (4.05433 iter/s, 24.665s/100 iters), loss = 0.0128004
I1008 01:52:29.215404  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0128005 (* 1 = 0.0128005 loss)
I1008 01:52:29.215411  5322 sgd_solver.cpp:105] Iteration 50200, lr = 0.01
I1008 01:52:53.818697  5322 solver.cpp:218] Iteration 50300 (4.06486 iter/s, 24.6011s/100 iters), loss = 0.0483721
I1008 01:52:53.818791  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0483722 (* 1 = 0.0483722 loss)
I1008 01:52:53.818800  5322 sgd_solver.cpp:105] Iteration 50300, lr = 0.01
I1008 01:53:18.474565  5322 solver.cpp:218] Iteration 50400 (4.0562 iter/s, 24.6536s/100 iters), loss = 0.0118368
I1008 01:53:18.474598  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.011837 (* 1 = 0.011837 loss)
I1008 01:53:18.474606  5322 sgd_solver.cpp:105] Iteration 50400, lr = 0.01
I1008 01:53:42.258074  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:53:43.240952  5322 solver.cpp:330] Iteration 50500, Testing net (#0)
I1008 01:53:48.278439  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:53:48.485877  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9157
I1008 01:53:48.485901  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.293222 (* 1 = 0.293222 loss)
I1008 01:53:48.693732  5322 solver.cpp:218] Iteration 50500 (3.30941 iter/s, 30.2169s/100 iters), loss = 0.0256881
I1008 01:53:48.693765  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0256883 (* 1 = 0.0256883 loss)
I1008 01:53:48.693773  5322 sgd_solver.cpp:105] Iteration 50500, lr = 0.01
I1008 01:54:13.404554  5322 solver.cpp:218] Iteration 50600 (4.04754 iter/s, 24.7064s/100 iters), loss = 0.0227942
I1008 01:54:13.404640  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0227944 (* 1 = 0.0227944 loss)
I1008 01:54:13.404649  5322 sgd_solver.cpp:105] Iteration 50600, lr = 0.01
I1008 01:54:38.014266  5322 solver.cpp:218] Iteration 50700 (4.06381 iter/s, 24.6074s/100 iters), loss = 0.0413269
I1008 01:54:38.014302  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0413271 (* 1 = 0.0413271 loss)
I1008 01:54:38.014309  5322 sgd_solver.cpp:105] Iteration 50700, lr = 0.01
I1008 01:55:02.676596  5322 solver.cpp:218] Iteration 50800 (4.05541 iter/s, 24.6584s/100 iters), loss = 0.0364516
I1008 01:55:02.676719  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0364518 (* 1 = 0.0364518 loss)
I1008 01:55:02.676733  5322 sgd_solver.cpp:105] Iteration 50800, lr = 0.01
I1008 01:55:27.343793  5322 solver.cpp:218] Iteration 50900 (4.05457 iter/s, 24.6635s/100 iters), loss = 0.0220729
I1008 01:55:27.343830  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.022073 (* 1 = 0.022073 loss)
I1008 01:55:27.343849  5322 sgd_solver.cpp:105] Iteration 50900, lr = 0.01
I1008 01:55:51.214920  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:55:52.196645  5322 solver.cpp:330] Iteration 51000, Testing net (#0)
I1008 01:55:57.084942  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:55:57.307597  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9129
I1008 01:55:57.307626  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.308323 (* 1 = 0.308323 loss)
I1008 01:55:57.460624  5322 solver.cpp:218] Iteration 51000 (3.32065 iter/s, 30.1146s/100 iters), loss = 0.0298963
I1008 01:55:57.460667  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0298965 (* 1 = 0.0298965 loss)
I1008 01:55:57.460675  5322 sgd_solver.cpp:105] Iteration 51000, lr = 0.01
I1008 01:56:22.307826  5322 solver.cpp:218] Iteration 51100 (4.02497 iter/s, 24.8449s/100 iters), loss = 0.0658284
I1008 01:56:22.307929  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0658286 (* 1 = 0.0658286 loss)
I1008 01:56:22.307940  5322 sgd_solver.cpp:105] Iteration 51100, lr = 0.01
I1008 01:56:46.965523  5322 solver.cpp:218] Iteration 51200 (4.05617 iter/s, 24.6538s/100 iters), loss = 0.0682362
I1008 01:56:46.965555  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0682364 (* 1 = 0.0682364 loss)
I1008 01:56:46.965562  5322 sgd_solver.cpp:105] Iteration 51200, lr = 0.01
I1008 01:57:11.612012  5322 solver.cpp:218] Iteration 51300 (4.05809 iter/s, 24.6421s/100 iters), loss = 0.0358235
I1008 01:57:11.612102  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0358237 (* 1 = 0.0358237 loss)
I1008 01:57:11.612114  5322 sgd_solver.cpp:105] Iteration 51300, lr = 0.01
I1008 01:57:36.258782  5322 solver.cpp:218] Iteration 51400 (4.05794 iter/s, 24.643s/100 iters), loss = 0.0682752
I1008 01:57:36.258823  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0682755 (* 1 = 0.0682755 loss)
I1008 01:57:36.258833  5322 sgd_solver.cpp:105] Iteration 51400, lr = 0.01
I1008 01:58:00.050969  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:58:01.033910  5322 solver.cpp:330] Iteration 51500, Testing net (#0)
I1008 01:58:05.974321  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:58:06.173770  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9153
I1008 01:58:06.173797  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.297348 (* 1 = 0.297348 loss)
I1008 01:58:06.376255  5322 solver.cpp:218] Iteration 51500 (3.32074 iter/s, 30.1138s/100 iters), loss = 0.0115052
I1008 01:58:06.376288  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0115054 (* 1 = 0.0115054 loss)
I1008 01:58:06.376296  5322 sgd_solver.cpp:105] Iteration 51500, lr = 0.01
I1008 01:58:31.232189  5322 solver.cpp:218] Iteration 51600 (4.02329 iter/s, 24.8553s/100 iters), loss = 0.0141983
I1008 01:58:31.234056  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0141985 (* 1 = 0.0141985 loss)
I1008 01:58:31.234064  5322 sgd_solver.cpp:105] Iteration 51600, lr = 0.01
I1008 01:58:55.841608  5322 solver.cpp:218] Iteration 51700 (4.06411 iter/s, 24.6056s/100 iters), loss = 0.040082
I1008 01:58:55.841641  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0400822 (* 1 = 0.0400822 loss)
I1008 01:58:55.841650  5322 sgd_solver.cpp:105] Iteration 51700, lr = 0.01
I1008 01:59:20.471709  5322 solver.cpp:218] Iteration 51800 (4.0608 iter/s, 24.6257s/100 iters), loss = 0.0304573
I1008 01:59:20.471832  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0304575 (* 1 = 0.0304575 loss)
I1008 01:59:20.471844  5322 sgd_solver.cpp:105] Iteration 51800, lr = 0.01
I1008 01:59:45.084149  5322 solver.cpp:218] Iteration 51900 (4.0636 iter/s, 24.6087s/100 iters), loss = 0.0125882
I1008 01:59:45.084185  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0125884 (* 1 = 0.0125884 loss)
I1008 01:59:45.084192  5322 sgd_solver.cpp:105] Iteration 51900, lr = 0.01
I1008 02:00:08.862375  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:00:09.843899  5322 solver.cpp:330] Iteration 52000, Testing net (#0)
I1008 02:00:14.582859  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:00:14.788653  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9093
I1008 02:00:14.788681  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.313524 (* 1 = 0.313524 loss)
I1008 02:00:14.943619  5322 solver.cpp:218] Iteration 52000 (3.34945 iter/s, 29.8557s/100 iters), loss = 0.0073471
I1008 02:00:14.943661  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00734729 (* 1 = 0.00734729 loss)
I1008 02:00:14.943668  5322 sgd_solver.cpp:105] Iteration 52000, lr = 0.01
I1008 02:00:39.844111  5322 solver.cpp:218] Iteration 52100 (4.01636 iter/s, 24.8982s/100 iters), loss = 0.0760488
I1008 02:00:39.844179  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.076049 (* 1 = 0.076049 loss)
I1008 02:00:39.844187  5322 sgd_solver.cpp:105] Iteration 52100, lr = 0.01
I1008 02:01:04.448761  5322 solver.cpp:218] Iteration 52200 (4.065 iter/s, 24.6003s/100 iters), loss = 0.0270937
I1008 02:01:04.448797  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0270939 (* 1 = 0.0270939 loss)
I1008 02:01:04.448806  5322 sgd_solver.cpp:105] Iteration 52200, lr = 0.01
I1008 02:01:29.109500  5322 solver.cpp:218] Iteration 52300 (4.05575 iter/s, 24.6564s/100 iters), loss = 0.0332751
I1008 02:01:29.109578  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0332753 (* 1 = 0.0332753 loss)
I1008 02:01:29.109586  5322 sgd_solver.cpp:105] Iteration 52300, lr = 0.01
I1008 02:01:53.755856  5322 solver.cpp:218] Iteration 52400 (4.05803 iter/s, 24.6425s/100 iters), loss = 0.0119044
I1008 02:01:53.755892  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0119046 (* 1 = 0.0119046 loss)
I1008 02:01:53.755899  5322 sgd_solver.cpp:105] Iteration 52400, lr = 0.01
I1008 02:02:17.562849  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:02:18.547171  5322 solver.cpp:330] Iteration 52500, Testing net (#0)
I1008 02:02:23.251760  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:02:23.482753  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9155
I1008 02:02:23.482779  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.302494 (* 1 = 0.302494 loss)
I1008 02:02:23.651610  5322 solver.cpp:218] Iteration 52500 (3.34539 iter/s, 29.8919s/100 iters), loss = 0.0118877
I1008 02:02:23.651646  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0118879 (* 1 = 0.0118879 loss)
I1008 02:02:23.651654  5322 sgd_solver.cpp:105] Iteration 52500, lr = 0.01
I1008 02:02:48.639643  5322 solver.cpp:218] Iteration 52600 (4.00262 iter/s, 24.9837s/100 iters), loss = 0.0254343
I1008 02:02:48.639755  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0254345 (* 1 = 0.0254345 loss)
I1008 02:02:48.639778  5322 sgd_solver.cpp:105] Iteration 52600, lr = 0.01
I1008 02:03:13.255717  5322 solver.cpp:218] Iteration 52700 (4.06276 iter/s, 24.6138s/100 iters), loss = 0.0168908
I1008 02:03:13.255753  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.016891 (* 1 = 0.016891 loss)
I1008 02:03:13.255759  5322 sgd_solver.cpp:105] Iteration 52700, lr = 0.01
I1008 02:03:37.888453  5322 solver.cpp:218] Iteration 52800 (4.06027 iter/s, 24.6289s/100 iters), loss = 0.0175892
I1008 02:03:37.888556  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0175894 (* 1 = 0.0175894 loss)
I1008 02:03:37.888564  5322 sgd_solver.cpp:105] Iteration 52800, lr = 0.01
I1008 02:04:02.546438  5322 solver.cpp:218] Iteration 52900 (4.0562 iter/s, 24.6536s/100 iters), loss = 0.00908333
I1008 02:04:02.546471  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00908352 (* 1 = 0.00908352 loss)
I1008 02:04:02.546489  5322 sgd_solver.cpp:105] Iteration 52900, lr = 0.01
I1008 02:04:26.405472  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:04:27.389837  5322 solver.cpp:330] Iteration 53000, Testing net (#0)
I1008 02:04:31.933804  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:04:32.107158  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9148
I1008 02:04:32.107190  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.303037 (* 1 = 0.303037 loss)
I1008 02:04:32.290249  5322 solver.cpp:218] Iteration 53000 (3.3624 iter/s, 29.7407s/100 iters), loss = 0.0171988
I1008 02:04:32.290288  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.017199 (* 1 = 0.017199 loss)
I1008 02:04:32.290297  5322 sgd_solver.cpp:105] Iteration 53000, lr = 0.01
I1008 02:04:57.422447  5322 solver.cpp:218] Iteration 53100 (3.97932 iter/s, 25.1299s/100 iters), loss = 0.036583
I1008 02:04:57.422550  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0365832 (* 1 = 0.0365832 loss)
I1008 02:04:57.422560  5322 sgd_solver.cpp:105] Iteration 53100, lr = 0.01
I1008 02:05:22.064805  5322 solver.cpp:218] Iteration 53200 (4.05868 iter/s, 24.6386s/100 iters), loss = 0.0658556
I1008 02:05:22.064838  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0658557 (* 1 = 0.0658557 loss)
I1008 02:05:22.064846  5322 sgd_solver.cpp:105] Iteration 53200, lr = 0.01
I1008 02:05:46.712219  5322 solver.cpp:218] Iteration 53300 (4.05795 iter/s, 24.643s/100 iters), loss = 0.0173079
I1008 02:05:46.712318  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0173081 (* 1 = 0.0173081 loss)
I1008 02:05:46.712340  5322 sgd_solver.cpp:105] Iteration 53300, lr = 0.01
I1008 02:06:11.365445  5322 solver.cpp:218] Iteration 53400 (4.05698 iter/s, 24.6489s/100 iters), loss = 0.0104014
I1008 02:06:11.365480  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0104016 (* 1 = 0.0104016 loss)
I1008 02:06:11.365487  5322 sgd_solver.cpp:105] Iteration 53400, lr = 0.01
I1008 02:06:35.156448  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:06:36.140586  5322 solver.cpp:330] Iteration 53500, Testing net (#0)
I1008 02:06:40.713241  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:06:40.875044  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.913
I1008 02:06:40.875072  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.31234 (* 1 = 0.31234 loss)
I1008 02:06:41.058830  5322 solver.cpp:218] Iteration 53500 (3.36825 iter/s, 29.689s/100 iters), loss = 0.0272734
I1008 02:06:41.058863  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0272736 (* 1 = 0.0272736 loss)
I1008 02:06:41.058871  5322 sgd_solver.cpp:105] Iteration 53500, lr = 0.01
I1008 02:07:06.096842  5322 solver.cpp:218] Iteration 53600 (3.99429 iter/s, 25.0358s/100 iters), loss = 0.0322941
I1008 02:07:06.096942  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0322943 (* 1 = 0.0322943 loss)
I1008 02:07:06.096952  5322 sgd_solver.cpp:105] Iteration 53600, lr = 0.01
I1008 02:07:30.740186  5322 solver.cpp:218] Iteration 53700 (4.05844 iter/s, 24.64s/100 iters), loss = 0.0248129
I1008 02:07:30.740221  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.024813 (* 1 = 0.024813 loss)
I1008 02:07:30.740226  5322 sgd_solver.cpp:105] Iteration 53700, lr = 0.01
I1008 02:07:55.392362  5322 solver.cpp:218] Iteration 53800 (4.05707 iter/s, 24.6483s/100 iters), loss = 0.0227717
I1008 02:07:55.392464  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0227719 (* 1 = 0.0227719 loss)
I1008 02:07:55.392473  5322 sgd_solver.cpp:105] Iteration 53800, lr = 0.01
I1008 02:08:20.049679  5322 solver.cpp:218] Iteration 53900 (4.05621 iter/s, 24.6536s/100 iters), loss = 0.0307163
I1008 02:08:20.049718  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0307165 (* 1 = 0.0307165 loss)
I1008 02:08:20.049728  5322 sgd_solver.cpp:105] Iteration 53900, lr = 0.01
I1008 02:08:43.826351  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:08:44.808727  5322 solver.cpp:330] Iteration 54000, Testing net (#0)
I1008 02:08:49.338080  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:08:49.515486  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9117
I1008 02:08:49.515513  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.316967 (* 1 = 0.316967 loss)
I1008 02:08:49.697127  5322 solver.cpp:218] Iteration 54000 (3.37338 iter/s, 29.6439s/100 iters), loss = 0.00485856
I1008 02:08:49.697162  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00485874 (* 1 = 0.00485874 loss)
I1008 02:08:49.697170  5322 sgd_solver.cpp:105] Iteration 54000, lr = 0.01
I1008 02:09:14.845705  5322 solver.cpp:218] Iteration 54100 (3.97672 iter/s, 25.1463s/100 iters), loss = 0.0239919
I1008 02:09:14.845794  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0239921 (* 1 = 0.0239921 loss)
I1008 02:09:14.845803  5322 sgd_solver.cpp:105] Iteration 54100, lr = 0.01
I1008 02:09:39.501468  5322 solver.cpp:218] Iteration 54200 (4.05622 iter/s, 24.6535s/100 iters), loss = 0.0467026
I1008 02:09:39.501507  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0467028 (* 1 = 0.0467028 loss)
I1008 02:09:39.501516  5322 sgd_solver.cpp:105] Iteration 54200, lr = 0.01
I1008 02:10:04.164813  5322 solver.cpp:218] Iteration 54300 (4.05498 iter/s, 24.6611s/100 iters), loss = 0.0393418
I1008 02:10:04.164916  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0393419 (* 1 = 0.0393419 loss)
I1008 02:10:04.164927  5322 sgd_solver.cpp:105] Iteration 54300, lr = 0.01
I1008 02:10:28.833892  5322 solver.cpp:218] Iteration 54400 (4.05407 iter/s, 24.6666s/100 iters), loss = 0.0206822
I1008 02:10:28.833923  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0206824 (* 1 = 0.0206824 loss)
I1008 02:10:28.833930  5322 sgd_solver.cpp:105] Iteration 54400, lr = 0.01
I1008 02:10:52.691181  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:10:53.673995  5322 solver.cpp:330] Iteration 54500, Testing net (#0)
I1008 02:10:58.314188  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:10:58.512902  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9137
I1008 02:10:58.512946  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.313424 (* 1 = 0.313424 loss)
I1008 02:10:58.654620  5322 solver.cpp:218] Iteration 54500 (3.35363 iter/s, 29.8185s/100 iters), loss = 0.00739247
I1008 02:10:58.654655  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00739265 (* 1 = 0.00739265 loss)
I1008 02:10:58.654677  5322 sgd_solver.cpp:105] Iteration 54500, lr = 0.01
I1008 02:11:23.778097  5322 solver.cpp:218] Iteration 54600 (3.9807 iter/s, 25.1212s/100 iters), loss = 0.0398575
I1008 02:11:23.778198  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0398577 (* 1 = 0.0398577 loss)
I1008 02:11:23.778206  5322 sgd_solver.cpp:105] Iteration 54600, lr = 0.01
I1008 02:11:48.413285  5322 solver.cpp:218] Iteration 54700 (4.05987 iter/s, 24.6313s/100 iters), loss = 0.0204237
I1008 02:11:48.413328  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0204238 (* 1 = 0.0204238 loss)
I1008 02:11:48.413336  5322 sgd_solver.cpp:105] Iteration 54700, lr = 0.01
I1008 02:12:13.050876  5322 solver.cpp:218] Iteration 54800 (4.05942 iter/s, 24.6341s/100 iters), loss = 0.0323243
I1008 02:12:13.050959  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0323245 (* 1 = 0.0323245 loss)
I1008 02:12:13.050968  5322 sgd_solver.cpp:105] Iteration 54800, lr = 0.01
I1008 02:12:37.710448  5322 solver.cpp:218] Iteration 54900 (4.05594 iter/s, 24.6552s/100 iters), loss = 0.0447316
I1008 02:12:37.710484  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0447318 (* 1 = 0.0447318 loss)
I1008 02:12:37.710492  5322 sgd_solver.cpp:105] Iteration 54900, lr = 0.01
I1008 02:13:01.521456  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:13:02.503473  5322 solver.cpp:330] Iteration 55000, Testing net (#0)
I1008 02:13:07.077555  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:13:07.257215  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.916
I1008 02:13:07.257252  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.31899 (* 1 = 0.31899 loss)
I1008 02:13:07.431113  5322 solver.cpp:218] Iteration 55000 (3.36516 iter/s, 29.7163s/100 iters), loss = 0.0100038
I1008 02:13:07.431155  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.010004 (* 1 = 0.010004 loss)
I1008 02:13:07.431165  5322 sgd_solver.cpp:105] Iteration 55000, lr = 0.01
I1008 02:13:32.360438  5322 solver.cpp:218] Iteration 55100 (4.0117 iter/s, 24.9271s/100 iters), loss = 0.00750299
I1008 02:13:32.360549  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00750316 (* 1 = 0.00750316 loss)
I1008 02:13:32.360558  5322 sgd_solver.cpp:105] Iteration 55100, lr = 0.01
I1008 02:13:56.993028  5322 solver.cpp:218] Iteration 55200 (4.06033 iter/s, 24.6285s/100 iters), loss = 0.0260802
I1008 02:13:56.993062  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0260804 (* 1 = 0.0260804 loss)
I1008 02:13:56.993069  5322 sgd_solver.cpp:105] Iteration 55200, lr = 0.01
I1008 02:14:21.628275  5322 solver.cpp:218] Iteration 55300 (4.05985 iter/s, 24.6314s/100 iters), loss = 0.047798
I1008 02:14:21.628371  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0477982 (* 1 = 0.0477982 loss)
I1008 02:14:21.628381  5322 sgd_solver.cpp:105] Iteration 55300, lr = 0.01
I1008 02:14:46.296609  5322 solver.cpp:218] Iteration 55400 (4.0545 iter/s, 24.6639s/100 iters), loss = 0.00400884
I1008 02:14:46.296646  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.004009 (* 1 = 0.004009 loss)
I1008 02:14:46.296654  5322 sgd_solver.cpp:105] Iteration 55400, lr = 0.01
I1008 02:15:10.003928  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:15:10.987985  5322 solver.cpp:330] Iteration 55500, Testing net (#0)
I1008 02:15:15.648475  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:15:15.813086  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9136
I1008 02:15:15.813113  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.312589 (* 1 = 0.312589 loss)
I1008 02:15:16.006178  5322 solver.cpp:218] Iteration 55500 (3.36642 iter/s, 29.7052s/100 iters), loss = 0.0403417
I1008 02:15:16.006212  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0403419 (* 1 = 0.0403419 loss)
I1008 02:15:16.006219  5322 sgd_solver.cpp:105] Iteration 55500, lr = 0.01
I1008 02:15:41.105154  5322 solver.cpp:218] Iteration 55600 (3.98459 iter/s, 25.0967s/100 iters), loss = 0.019549
I1008 02:15:41.105232  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0195491 (* 1 = 0.0195491 loss)
I1008 02:15:41.105240  5322 sgd_solver.cpp:105] Iteration 55600, lr = 0.01
I1008 02:16:05.736279  5322 solver.cpp:218] Iteration 55700 (4.06028 iter/s, 24.6289s/100 iters), loss = 0.012746
I1008 02:16:05.736313  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0127461 (* 1 = 0.0127461 loss)
I1008 02:16:05.736320  5322 sgd_solver.cpp:105] Iteration 55700, lr = 0.01
I1008 02:16:30.379387  5322 solver.cpp:218] Iteration 55800 (4.05831 iter/s, 24.6408s/100 iters), loss = 0.0199283
I1008 02:16:30.379462  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0199284 (* 1 = 0.0199284 loss)
I1008 02:16:30.379469  5322 sgd_solver.cpp:105] Iteration 55800, lr = 0.01
I1008 02:16:55.004070  5322 solver.cpp:218] Iteration 55900 (4.06135 iter/s, 24.6224s/100 iters), loss = 0.0338473
I1008 02:16:55.004114  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0338474 (* 1 = 0.0338474 loss)
I1008 02:16:55.004127  5322 sgd_solver.cpp:105] Iteration 55900, lr = 0.01
I1008 02:17:18.858785  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:17:19.843456  5322 solver.cpp:330] Iteration 56000, Testing net (#0)
I1008 02:17:24.424268  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:17:24.593206  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9115
I1008 02:17:24.593235  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.313117 (* 1 = 0.313117 loss)
I1008 02:17:24.775903  5322 solver.cpp:218] Iteration 56000 (3.35913 iter/s, 29.7696s/100 iters), loss = 0.00362088
I1008 02:17:24.775938  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00362104 (* 1 = 0.00362104 loss)
I1008 02:17:24.775944  5322 sgd_solver.cpp:105] Iteration 56000, lr = 0.01
I1008 02:17:49.774734  5322 solver.cpp:218] Iteration 56100 (4.00055 iter/s, 24.9965s/100 iters), loss = 0.049954
I1008 02:17:49.774830  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0499541 (* 1 = 0.0499541 loss)
I1008 02:17:49.774849  5322 sgd_solver.cpp:105] Iteration 56100, lr = 0.01
I1008 02:18:14.396059  5322 solver.cpp:218] Iteration 56200 (4.06213 iter/s, 24.6176s/100 iters), loss = 0.00826995
I1008 02:18:14.396113  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00827012 (* 1 = 0.00827012 loss)
I1008 02:18:14.396121  5322 sgd_solver.cpp:105] Iteration 56200, lr = 0.01
I1008 02:18:39.002070  5322 solver.cpp:218] Iteration 56300 (4.06459 iter/s, 24.6027s/100 iters), loss = 0.00881278
I1008 02:18:39.002163  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00881294 (* 1 = 0.00881294 loss)
I1008 02:18:39.002174  5322 sgd_solver.cpp:105] Iteration 56300, lr = 0.01
I1008 02:19:03.619395  5322 solver.cpp:218] Iteration 56400 (4.06279 iter/s, 24.6136s/100 iters), loss = 0.0103233
I1008 02:19:03.619431  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0103235 (* 1 = 0.0103235 loss)
I1008 02:19:03.619441  5322 sgd_solver.cpp:105] Iteration 56400, lr = 0.01
I1008 02:19:27.403141  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:19:28.386545  5322 solver.cpp:330] Iteration 56500, Testing net (#0)
I1008 02:19:32.974406  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:19:33.134845  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.914
I1008 02:19:33.134871  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.31485 (* 1 = 0.31485 loss)
I1008 02:19:33.323710  5322 solver.cpp:218] Iteration 56500 (3.36677 iter/s, 29.702s/100 iters), loss = 0.00828004
I1008 02:19:33.323746  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00828021 (* 1 = 0.00828021 loss)
I1008 02:19:33.323753  5322 sgd_solver.cpp:105] Iteration 56500, lr = 0.01
I1008 02:19:58.315206  5322 solver.cpp:218] Iteration 56600 (4.00173 iter/s, 24.9892s/100 iters), loss = 0.035689
I1008 02:19:58.315315  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0356892 (* 1 = 0.0356892 loss)
I1008 02:19:58.315330  5322 sgd_solver.cpp:105] Iteration 56600, lr = 0.01
I1008 02:20:22.944785  5322 solver.cpp:218] Iteration 56700 (4.06088 iter/s, 24.6252s/100 iters), loss = 0.0211174
I1008 02:20:22.944824  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0211176 (* 1 = 0.0211176 loss)
I1008 02:20:22.944834  5322 sgd_solver.cpp:105] Iteration 56700, lr = 0.01
I1008 02:20:47.568864  5322 solver.cpp:218] Iteration 56800 (4.06144 iter/s, 24.6218s/100 iters), loss = 0.0375333
I1008 02:20:47.568945  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0375334 (* 1 = 0.0375334 loss)
I1008 02:20:47.568953  5322 sgd_solver.cpp:105] Iteration 56800, lr = 0.01
I1008 02:21:12.176656  5322 solver.cpp:218] Iteration 56900 (4.06448 iter/s, 24.6034s/100 iters), loss = 0.0159821
I1008 02:21:12.176698  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0159823 (* 1 = 0.0159823 loss)
I1008 02:21:12.176705  5322 sgd_solver.cpp:105] Iteration 56900, lr = 0.01
I1008 02:21:35.999408  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:21:36.983753  5322 solver.cpp:330] Iteration 57000, Testing net (#0)
I1008 02:21:41.554505  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:21:41.712121  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9114
I1008 02:21:41.712151  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.324171 (* 1 = 0.324171 loss)
I1008 02:21:41.898823  5322 solver.cpp:218] Iteration 57000 (3.36492 iter/s, 29.7184s/100 iters), loss = 0.0071334
I1008 02:21:41.898859  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00713358 (* 1 = 0.00713358 loss)
I1008 02:21:41.898866  5322 sgd_solver.cpp:105] Iteration 57000, lr = 0.01
I1008 02:22:06.926645  5322 solver.cpp:218] Iteration 57100 (3.99591 iter/s, 25.0256s/100 iters), loss = 0.0554336
I1008 02:22:06.926731  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0554338 (* 1 = 0.0554338 loss)
I1008 02:22:06.926741  5322 sgd_solver.cpp:105] Iteration 57100, lr = 0.01
I1008 02:22:31.561406  5322 solver.cpp:218] Iteration 57200 (4.05968 iter/s, 24.6325s/100 iters), loss = 0.0216556
I1008 02:22:31.561441  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0216558 (* 1 = 0.0216558 loss)
I1008 02:22:31.561449  5322 sgd_solver.cpp:105] Iteration 57200, lr = 0.01
I1008 02:22:56.210410  5322 solver.cpp:218] Iteration 57300 (4.05734 iter/s, 24.6467s/100 iters), loss = 0.0150559
I1008 02:22:56.210491  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0150561 (* 1 = 0.0150561 loss)
I1008 02:22:56.210501  5322 sgd_solver.cpp:105] Iteration 57300, lr = 0.01
I1008 02:23:20.848525  5322 solver.cpp:218] Iteration 57400 (4.05913 iter/s, 24.6358s/100 iters), loss = 0.0240464
I1008 02:23:20.848562  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0240465 (* 1 = 0.0240465 loss)
I1008 02:23:20.848568  5322 sgd_solver.cpp:105] Iteration 57400, lr = 0.01
I1008 02:23:44.715610  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:23:45.699240  5322 solver.cpp:330] Iteration 57500, Testing net (#0)
I1008 02:23:50.210009  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:23:50.414491  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9113
I1008 02:23:50.414525  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.33969 (* 1 = 0.33969 loss)
I1008 02:23:50.579823  5322 solver.cpp:218] Iteration 57500 (3.36389 iter/s, 29.7275s/100 iters), loss = 0.00927583
I1008 02:23:50.579855  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00927601 (* 1 = 0.00927601 loss)
I1008 02:23:50.579864  5322 sgd_solver.cpp:105] Iteration 57500, lr = 0.01
I1008 02:24:15.655386  5322 solver.cpp:218] Iteration 57600 (3.98865 iter/s, 25.0711s/100 iters), loss = 0.0117546
I1008 02:24:15.655458  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0117548 (* 1 = 0.0117548 loss)
I1008 02:24:15.655467  5322 sgd_solver.cpp:105] Iteration 57600, lr = 0.01
I1008 02:24:40.317196  5322 solver.cpp:218] Iteration 57700 (4.05543 iter/s, 24.6583s/100 iters), loss = 0.00895842
I1008 02:24:40.317232  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00895859 (* 1 = 0.00895859 loss)
I1008 02:24:40.317240  5322 sgd_solver.cpp:105] Iteration 57700, lr = 0.01
I1008 02:25:04.981170  5322 solver.cpp:218] Iteration 57800 (4.05506 iter/s, 24.6605s/100 iters), loss = 0.0120819
I1008 02:25:04.981256  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0120821 (* 1 = 0.0120821 loss)
I1008 02:25:04.981263  5322 sgd_solver.cpp:105] Iteration 57800, lr = 0.01
I1008 02:25:29.639389  5322 solver.cpp:218] Iteration 57900 (4.05581 iter/s, 24.656s/100 iters), loss = 0.00782463
I1008 02:25:29.639423  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0078248 (* 1 = 0.0078248 loss)
I1008 02:25:29.639432  5322 sgd_solver.cpp:105] Iteration 57900, lr = 0.01
I1008 02:25:53.531297  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:25:54.512995  5322 solver.cpp:330] Iteration 58000, Testing net (#0)
I1008 02:25:59.046324  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:25:59.232776  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9137
I1008 02:25:59.232803  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.327616 (* 1 = 0.327616 loss)
I1008 02:25:59.390615  5322 solver.cpp:218] Iteration 58000 (3.3617 iter/s, 29.7469s/100 iters), loss = 0.0033083
I1008 02:25:59.390646  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00330847 (* 1 = 0.00330847 loss)
I1008 02:25:59.390653  5322 sgd_solver.cpp:105] Iteration 58000, lr = 0.01
I1008 02:26:24.365437  5322 solver.cpp:218] Iteration 58100 (4.00406 iter/s, 24.9747s/100 iters), loss = 0.00673541
I1008 02:26:24.365509  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00673558 (* 1 = 0.00673558 loss)
I1008 02:26:24.365519  5322 sgd_solver.cpp:105] Iteration 58100, lr = 0.01
I1008 02:26:49.019526  5322 solver.cpp:218] Iteration 58200 (4.05677 iter/s, 24.6501s/100 iters), loss = 0.032908
I1008 02:26:49.019560  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0329081 (* 1 = 0.0329081 loss)
I1008 02:26:49.019567  5322 sgd_solver.cpp:105] Iteration 58200, lr = 0.01
I1008 02:27:13.667935  5322 solver.cpp:218] Iteration 58300 (4.05743 iter/s, 24.6461s/100 iters), loss = 0.0143542
I1008 02:27:13.668020  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0143544 (* 1 = 0.0143544 loss)
I1008 02:27:13.668035  5322 sgd_solver.cpp:105] Iteration 58300, lr = 0.01
I1008 02:27:38.315932  5322 solver.cpp:218] Iteration 58400 (4.0575 iter/s, 24.6457s/100 iters), loss = 0.0163311
I1008 02:27:38.315968  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0163313 (* 1 = 0.0163313 loss)
I1008 02:27:38.315986  5322 sgd_solver.cpp:105] Iteration 58400, lr = 0.01
I1008 02:28:02.199944  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:28:03.181402  5322 solver.cpp:330] Iteration 58500, Testing net (#0)
I1008 02:28:07.724728  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:28:07.889081  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.911
I1008 02:28:07.889106  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.324855 (* 1 = 0.324855 loss)
I1008 02:28:08.094375  5322 solver.cpp:218] Iteration 58500 (3.35839 iter/s, 29.7762s/100 iters), loss = 0.0267609
I1008 02:28:08.094408  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0267611 (* 1 = 0.0267611 loss)
I1008 02:28:08.094414  5322 sgd_solver.cpp:105] Iteration 58500, lr = 0.01
I1008 02:28:33.109695  5322 solver.cpp:218] Iteration 58600 (3.99791 iter/s, 25.0131s/100 iters), loss = 0.0231966
I1008 02:28:33.109773  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0231968 (* 1 = 0.0231968 loss)
I1008 02:28:33.109781  5322 sgd_solver.cpp:105] Iteration 58600, lr = 0.01
I1008 02:28:57.746201  5322 solver.cpp:218] Iteration 58700 (4.05939 iter/s, 24.6342s/100 iters), loss = 0.0168768
I1008 02:28:57.746235  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.016877 (* 1 = 0.016877 loss)
I1008 02:28:57.746243  5322 sgd_solver.cpp:105] Iteration 58700, lr = 0.01
I1008 02:29:22.397202  5322 solver.cpp:218] Iteration 58800 (4.05701 iter/s, 24.6487s/100 iters), loss = 0.0154361
I1008 02:29:22.397294  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0154362 (* 1 = 0.0154362 loss)
I1008 02:29:22.397305  5322 sgd_solver.cpp:105] Iteration 58800, lr = 0.01
I1008 02:29:47.038888  5322 solver.cpp:218] Iteration 58900 (4.05854 iter/s, 24.6394s/100 iters), loss = 0.0140162
I1008 02:29:47.038925  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0140164 (* 1 = 0.0140164 loss)
I1008 02:29:47.038933  5322 sgd_solver.cpp:105] Iteration 58900, lr = 0.01
I1008 02:30:10.906081  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:30:11.890297  5322 solver.cpp:330] Iteration 59000, Testing net (#0)
I1008 02:30:16.433223  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:30:16.609774  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9002
I1008 02:30:16.609804  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.377225 (* 1 = 0.377225 loss)
I1008 02:30:16.785706  5322 solver.cpp:218] Iteration 59000 (3.36198 iter/s, 29.7444s/100 iters), loss = 0.00901761
I1008 02:30:16.785748  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00901777 (* 1 = 0.00901777 loss)
I1008 02:30:16.785755  5322 sgd_solver.cpp:105] Iteration 59000, lr = 0.01
I1008 02:30:41.815943  5322 solver.cpp:218] Iteration 59100 (3.99553 iter/s, 25.0279s/100 iters), loss = 0.0197392
I1008 02:30:41.816038  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0197394 (* 1 = 0.0197394 loss)
I1008 02:30:41.816046  5322 sgd_solver.cpp:105] Iteration 59100, lr = 0.01
I1008 02:31:06.429392  5322 solver.cpp:218] Iteration 59200 (4.06319 iter/s, 24.6112s/100 iters), loss = 0.00852293
I1008 02:31:06.429428  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00852309 (* 1 = 0.00852309 loss)
I1008 02:31:06.429435  5322 sgd_solver.cpp:105] Iteration 59200, lr = 0.01
I1008 02:31:31.092341  5322 solver.cpp:218] Iteration 59300 (4.05504 iter/s, 24.6607s/100 iters), loss = 0.0313186
I1008 02:31:31.092422  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0313188 (* 1 = 0.0313188 loss)
I1008 02:31:31.092430  5322 sgd_solver.cpp:105] Iteration 59300, lr = 0.01
I1008 02:31:55.748214  5322 solver.cpp:218] Iteration 59400 (4.0562 iter/s, 24.6536s/100 iters), loss = 0.0473222
I1008 02:31:55.748258  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0473224 (* 1 = 0.0473224 loss)
I1008 02:31:55.748265  5322 sgd_solver.cpp:105] Iteration 59400, lr = 0.01
I1008 02:32:19.560588  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:32:20.545337  5322 solver.cpp:330] Iteration 59500, Testing net (#0)
I1008 02:32:25.151799  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:32:25.329154  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9151
I1008 02:32:25.329180  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.318717 (* 1 = 0.318717 loss)
I1008 02:32:25.500522  5322 solver.cpp:218] Iteration 59500 (3.36134 iter/s, 29.75s/100 iters), loss = 0.0183291
I1008 02:32:25.500556  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0183292 (* 1 = 0.0183292 loss)
I1008 02:32:25.500574  5322 sgd_solver.cpp:105] Iteration 59500, lr = 0.01
I1008 02:32:50.477752  5322 solver.cpp:218] Iteration 59600 (4.00367 iter/s, 24.9771s/100 iters), loss = 0.0107133
I1008 02:32:50.477855  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0107134 (* 1 = 0.0107134 loss)
I1008 02:32:50.477865  5322 sgd_solver.cpp:105] Iteration 59600, lr = 0.01
I1008 02:33:15.109235  5322 solver.cpp:218] Iteration 59700 (4.06022 iter/s, 24.6292s/100 iters), loss = 0.0635175
I1008 02:33:15.109266  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0635177 (* 1 = 0.0635177 loss)
I1008 02:33:15.109273  5322 sgd_solver.cpp:105] Iteration 59700, lr = 0.01
I1008 02:33:39.735867  5322 solver.cpp:218] Iteration 59800 (4.06102 iter/s, 24.6244s/100 iters), loss = 0.0172351
I1008 02:33:39.735992  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0172352 (* 1 = 0.0172352 loss)
I1008 02:33:39.736016  5322 sgd_solver.cpp:105] Iteration 59800, lr = 0.01
I1008 02:34:04.365474  5322 solver.cpp:218] Iteration 59900 (4.06053 iter/s, 24.6274s/100 iters), loss = 0.0051324
I1008 02:34:04.365514  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00513255 (* 1 = 0.00513255 loss)
I1008 02:34:04.365521  5322 sgd_solver.cpp:105] Iteration 59900, lr = 0.01
I1008 02:34:28.150235  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:34:29.128733  5322 solver.cpp:330] Iteration 60000, Testing net (#0)
I1008 02:34:33.764276  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:34:33.956596  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9144
I1008 02:34:33.956643  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.333493 (* 1 = 0.333493 loss)
I1008 02:34:34.105484  5322 solver.cpp:218] Iteration 60000 (3.36289 iter/s, 29.7364s/100 iters), loss = 0.0127349
I1008 02:34:34.105532  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0127351 (* 1 = 0.0127351 loss)
I1008 02:34:34.105551  5322 sgd_solver.cpp:105] Iteration 60000, lr = 0.01
I1008 02:34:59.151221  5322 solver.cpp:218] Iteration 60100 (3.99272 iter/s, 25.0456s/100 iters), loss = 0.0296817
I1008 02:34:59.151310  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0296818 (* 1 = 0.0296818 loss)
I1008 02:34:59.151329  5322 sgd_solver.cpp:105] Iteration 60100, lr = 0.01
I1008 02:35:23.744381  5322 solver.cpp:218] Iteration 60200 (4.06681 iter/s, 24.5893s/100 iters), loss = 0.015566
I1008 02:35:23.744426  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0155662 (* 1 = 0.0155662 loss)
I1008 02:35:23.744434  5322 sgd_solver.cpp:105] Iteration 60200, lr = 0.01
I1008 02:35:48.410033  5322 solver.cpp:218] Iteration 60300 (4.05484 iter/s, 24.6619s/100 iters), loss = 0.0069653
I1008 02:35:48.410120  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00696546 (* 1 = 0.00696546 loss)
I1008 02:35:48.410128  5322 sgd_solver.cpp:105] Iteration 60300, lr = 0.01
I1008 02:36:13.031996  5322 solver.cpp:218] Iteration 60400 (4.06214 iter/s, 24.6176s/100 iters), loss = 0.00747027
I1008 02:36:13.032032  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00747043 (* 1 = 0.00747043 loss)
I1008 02:36:13.032052  5322 sgd_solver.cpp:105] Iteration 60400, lr = 0.01
I1008 02:36:36.811841  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:36:37.796520  5322 solver.cpp:330] Iteration 60500, Testing net (#0)
I1008 02:36:42.456194  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:36:42.654626  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9109
I1008 02:36:42.654662  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.340887 (* 1 = 0.340887 loss)
I1008 02:36:42.802325  5322 solver.cpp:218] Iteration 60500 (3.35946 iter/s, 29.7667s/100 iters), loss = 0.0124819
I1008 02:36:42.802357  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.012482 (* 1 = 0.012482 loss)
I1008 02:36:42.802364  5322 sgd_solver.cpp:105] Iteration 60500, lr = 0.01
I1008 02:37:07.833729  5322 solver.cpp:218] Iteration 60600 (3.99534 iter/s, 25.0292s/100 iters), loss = 0.0335426
I1008 02:37:07.833833  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0335428 (* 1 = 0.0335428 loss)
I1008 02:37:07.833848  5322 sgd_solver.cpp:105] Iteration 60600, lr = 0.01
I1008 02:37:32.470821  5322 solver.cpp:218] Iteration 60700 (4.05929 iter/s, 24.6348s/100 iters), loss = 0.0174501
I1008 02:37:32.470856  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0174503 (* 1 = 0.0174503 loss)
I1008 02:37:32.470866  5322 sgd_solver.cpp:105] Iteration 60700, lr = 0.01
I1008 02:37:57.117130  5322 solver.cpp:218] Iteration 60800 (4.05777 iter/s, 24.6441s/100 iters), loss = 0.0233153
I1008 02:37:57.117233  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0233155 (* 1 = 0.0233155 loss)
I1008 02:37:57.117249  5322 sgd_solver.cpp:105] Iteration 60800, lr = 0.01
I1008 02:38:21.761162  5322 solver.cpp:218] Iteration 60900 (4.05816 iter/s, 24.6417s/100 iters), loss = 0.00792414
I1008 02:38:21.761201  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00792428 (* 1 = 0.00792428 loss)
I1008 02:38:21.761211  5322 sgd_solver.cpp:105] Iteration 60900, lr = 0.01
I1008 02:38:45.560487  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:38:46.544327  5322 solver.cpp:330] Iteration 61000, Testing net (#0)
I1008 02:38:51.102257  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:38:51.275498  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9112
I1008 02:38:51.275524  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.358159 (* 1 = 0.358159 loss)
I1008 02:38:51.437381  5322 solver.cpp:218] Iteration 61000 (3.36996 iter/s, 29.674s/100 iters), loss = 0.0240433
I1008 02:38:51.437415  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0240434 (* 1 = 0.0240434 loss)
I1008 02:38:51.437423  5322 sgd_solver.cpp:105] Iteration 61000, lr = 0.01
I1008 02:39:16.480912  5322 solver.cpp:218] Iteration 61100 (3.99341 iter/s, 25.0413s/100 iters), loss = 0.00944035
I1008 02:39:16.481001  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00944049 (* 1 = 0.00944049 loss)
I1008 02:39:16.481014  5322 sgd_solver.cpp:105] Iteration 61100, lr = 0.01
I1008 02:39:41.128497  5322 solver.cpp:218] Iteration 61200 (4.05784 iter/s, 24.6437s/100 iters), loss = 0.0307553
I1008 02:39:41.128549  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0307555 (* 1 = 0.0307555 loss)
I1008 02:39:41.128571  5322 sgd_solver.cpp:105] Iteration 61200, lr = 0.01
I1008 02:40:05.759294  5322 solver.cpp:218] Iteration 61300 (4.06033 iter/s, 24.6285s/100 iters), loss = 0.018743
I1008 02:40:05.759416  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0187431 (* 1 = 0.0187431 loss)
I1008 02:40:05.759429  5322 sgd_solver.cpp:105] Iteration 61300, lr = 0.01
I1008 02:40:30.389381  5322 solver.cpp:218] Iteration 61400 (4.06045 iter/s, 24.6278s/100 iters), loss = 0.00651178
I1008 02:40:30.389421  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00651192 (* 1 = 0.00651192 loss)
I1008 02:40:30.389430  5322 sgd_solver.cpp:105] Iteration 61400, lr = 0.01
I1008 02:40:54.166647  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:40:55.150128  5322 solver.cpp:330] Iteration 61500, Testing net (#0)
I1008 02:40:59.790009  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:41:00.004580  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9133
I1008 02:41:00.004606  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.340234 (* 1 = 0.340234 loss)
I1008 02:41:00.131017  5322 solver.cpp:218] Iteration 61500 (3.36279 iter/s, 29.7372s/100 iters), loss = 0.00759633
I1008 02:41:00.131049  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00759647 (* 1 = 0.00759647 loss)
I1008 02:41:00.131057  5322 sgd_solver.cpp:105] Iteration 61500, lr = 0.01
I1008 02:41:25.224656  5322 solver.cpp:218] Iteration 61600 (3.98543 iter/s, 25.0914s/100 iters), loss = 0.0264659
I1008 02:41:25.224730  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.026466 (* 1 = 0.026466 loss)
I1008 02:41:25.224738  5322 sgd_solver.cpp:105] Iteration 61600, lr = 0.01
I1008 02:41:49.839805  5322 solver.cpp:218] Iteration 61700 (4.06315 iter/s, 24.6115s/100 iters), loss = 0.0105031
I1008 02:41:49.839839  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0105032 (* 1 = 0.0105032 loss)
I1008 02:41:49.839855  5322 sgd_solver.cpp:105] Iteration 61700, lr = 0.01
I1008 02:42:14.500247  5322 solver.cpp:218] Iteration 61800 (4.0558 iter/s, 24.6561s/100 iters), loss = 0.0181703
I1008 02:42:14.500334  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0181705 (* 1 = 0.0181705 loss)
I1008 02:42:14.500344  5322 sgd_solver.cpp:105] Iteration 61800, lr = 0.01
I1008 02:42:39.144651  5322 solver.cpp:218] Iteration 61900 (4.05844 iter/s, 24.64s/100 iters), loss = 0.00969821
I1008 02:42:39.144687  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00969835 (* 1 = 0.00969835 loss)
I1008 02:42:39.144695  5322 sgd_solver.cpp:105] Iteration 61900, lr = 0.01
I1008 02:43:02.936714  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:43:03.921710  5322 solver.cpp:330] Iteration 62000, Testing net (#0)
I1008 02:43:08.575443  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:43:08.781927  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9134
I1008 02:43:08.781954  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.335368 (* 1 = 0.335368 loss)
I1008 02:43:08.919358  5322 solver.cpp:218] Iteration 62000 (3.35905 iter/s, 29.7703s/100 iters), loss = 0.0158988
I1008 02:43:08.919399  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0158989 (* 1 = 0.0158989 loss)
I1008 02:43:08.919406  5322 sgd_solver.cpp:105] Iteration 62000, lr = 0.01
I1008 02:43:33.996525  5322 solver.cpp:218] Iteration 62100 (3.98805 iter/s, 25.0749s/100 iters), loss = 0.00799457
I1008 02:43:33.996634  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00799472 (* 1 = 0.00799472 loss)
I1008 02:43:33.996644  5322 sgd_solver.cpp:105] Iteration 62100, lr = 0.01
I1008 02:43:58.650921  5322 solver.cpp:218] Iteration 62200 (4.05645 iter/s, 24.6521s/100 iters), loss = 0.0143499
I1008 02:43:58.650955  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0143501 (* 1 = 0.0143501 loss)
I1008 02:43:58.650962  5322 sgd_solver.cpp:105] Iteration 62200, lr = 0.01
I1008 02:44:23.293932  5322 solver.cpp:218] Iteration 62300 (4.05832 iter/s, 24.6407s/100 iters), loss = 0.0110836
I1008 02:44:23.294042  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0110837 (* 1 = 0.0110837 loss)
I1008 02:44:23.294054  5322 sgd_solver.cpp:105] Iteration 62300, lr = 0.01
I1008 02:44:47.930654  5322 solver.cpp:218] Iteration 62400 (4.05936 iter/s, 24.6344s/100 iters), loss = 0.0445611
I1008 02:44:47.930687  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0445613 (* 1 = 0.0445613 loss)
I1008 02:44:47.930696  5322 sgd_solver.cpp:105] Iteration 62400, lr = 0.01
I1008 02:45:11.738914  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:45:12.726099  5322 solver.cpp:330] Iteration 62500, Testing net (#0)
I1008 02:45:17.250586  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:45:17.439668  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9128
I1008 02:45:17.439697  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.348832 (* 1 = 0.348832 loss)
I1008 02:45:17.597901  5322 solver.cpp:218] Iteration 62500 (3.37114 iter/s, 29.6635s/100 iters), loss = 0.00896517
I1008 02:45:17.597951  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00896533 (* 1 = 0.00896533 loss)
I1008 02:45:17.597957  5322 sgd_solver.cpp:105] Iteration 62500, lr = 0.01
I1008 02:45:42.669778  5322 solver.cpp:218] Iteration 62600 (3.9889 iter/s, 25.0696s/100 iters), loss = 0.00720644
I1008 02:45:42.669875  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00720661 (* 1 = 0.00720661 loss)
I1008 02:45:42.669889  5322 sgd_solver.cpp:105] Iteration 62600, lr = 0.01
I1008 02:46:07.310031  5322 solver.cpp:218] Iteration 62700 (4.05912 iter/s, 24.6359s/100 iters), loss = 0.0140234
I1008 02:46:07.310070  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0140236 (* 1 = 0.0140236 loss)
I1008 02:46:07.310076  5322 sgd_solver.cpp:105] Iteration 62700, lr = 0.01
I1008 02:46:31.972074  5322 solver.cpp:218] Iteration 62800 (4.05554 iter/s, 24.6576s/100 iters), loss = 0.0063536
I1008 02:46:31.972172  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00635376 (* 1 = 0.00635376 loss)
I1008 02:46:31.972182  5322 sgd_solver.cpp:105] Iteration 62800, lr = 0.01
I1008 02:46:56.584576  5322 solver.cpp:218] Iteration 62900 (4.06335 iter/s, 24.6103s/100 iters), loss = 0.00653216
I1008 02:46:56.584609  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00653232 (* 1 = 0.00653232 loss)
I1008 02:46:56.584616  5322 sgd_solver.cpp:105] Iteration 62900, lr = 0.01
I1008 02:47:20.407030  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:47:21.393426  5322 solver.cpp:330] Iteration 63000, Testing net (#0)
I1008 02:47:25.893214  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:47:26.109879  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9112
I1008 02:47:26.109905  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.34601 (* 1 = 0.34601 loss)
I1008 02:47:26.243260  5322 solver.cpp:218] Iteration 63000 (3.37195 iter/s, 29.6564s/100 iters), loss = 0.0691621
I1008 02:47:26.243297  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0691622 (* 1 = 0.0691622 loss)
I1008 02:47:26.243305  5322 sgd_solver.cpp:105] Iteration 63000, lr = 0.01
I1008 02:47:51.263012  5322 solver.cpp:218] Iteration 63100 (3.99755 iter/s, 25.0153s/100 iters), loss = 0.0072782
I1008 02:47:51.263119  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00727835 (* 1 = 0.00727835 loss)
I1008 02:47:51.263128  5322 sgd_solver.cpp:105] Iteration 63100, lr = 0.01
I1008 02:48:15.882987  5322 solver.cpp:218] Iteration 63200 (4.06205 iter/s, 24.6181s/100 iters), loss = 0.0358063
I1008 02:48:15.883023  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0358065 (* 1 = 0.0358065 loss)
I1008 02:48:15.883029  5322 sgd_solver.cpp:105] Iteration 63200, lr = 0.01
I1008 02:48:40.533818  5322 solver.cpp:218] Iteration 63300 (4.05703 iter/s, 24.6486s/100 iters), loss = 0.0140722
I1008 02:48:40.533903  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0140723 (* 1 = 0.0140723 loss)
I1008 02:48:40.533921  5322 sgd_solver.cpp:105] Iteration 63300, lr = 0.01
I1008 02:49:05.163552  5322 solver.cpp:218] Iteration 63400 (4.06074 iter/s, 24.6261s/100 iters), loss = 0.0260332
I1008 02:49:05.163583  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0260334 (* 1 = 0.0260334 loss)
I1008 02:49:05.163599  5322 sgd_solver.cpp:105] Iteration 63400, lr = 0.01
I1008 02:49:29.094373  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:49:30.079114  5322 solver.cpp:330] Iteration 63500, Testing net (#0)
I1008 02:49:34.646754  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:49:34.805263  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9123
I1008 02:49:34.805291  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.345347 (* 1 = 0.345347 loss)
I1008 02:49:34.993448  5322 solver.cpp:218] Iteration 63500 (3.3528 iter/s, 29.8258s/100 iters), loss = 0.0238634
I1008 02:49:34.993479  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0238635 (* 1 = 0.0238635 loss)
I1008 02:49:34.993485  5322 sgd_solver.cpp:105] Iteration 63500, lr = 0.01
I1008 02:49:59.925719  5322 solver.cpp:218] Iteration 63600 (4.01123 iter/s, 24.93s/100 iters), loss = 0.021075
I1008 02:49:59.925801  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0210752 (* 1 = 0.0210752 loss)
I1008 02:49:59.925808  5322 sgd_solver.cpp:105] Iteration 63600, lr = 0.01
I1008 02:50:24.654884  5322 solver.cpp:218] Iteration 63700 (4.04405 iter/s, 24.7277s/100 iters), loss = 0.00952552
I1008 02:50:24.654928  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00952565 (* 1 = 0.00952565 loss)
I1008 02:50:24.654935  5322 sgd_solver.cpp:105] Iteration 63700, lr = 0.01
I1008 02:50:49.302804  5322 solver.cpp:218] Iteration 63800 (4.05751 iter/s, 24.6457s/100 iters), loss = 0.0312541
I1008 02:50:49.302884  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0312542 (* 1 = 0.0312542 loss)
I1008 02:50:49.302892  5322 sgd_solver.cpp:105] Iteration 63800, lr = 0.01
I1008 02:51:13.951723  5322 solver.cpp:218] Iteration 63900 (4.05735 iter/s, 24.6467s/100 iters), loss = 0.00393737
I1008 02:51:13.951757  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00393749 (* 1 = 0.00393749 loss)
I1008 02:51:13.951764  5322 sgd_solver.cpp:105] Iteration 63900, lr = 0.01
I1008 02:51:37.736018  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:51:38.719089  5322 solver.cpp:330] Iteration 64000, Testing net (#0)
I1008 02:51:43.370829  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:51:43.564301  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9117
I1008 02:51:43.564337  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.350316 (* 1 = 0.350316 loss)
I1008 02:51:43.716850  5322 solver.cpp:218] Iteration 64000 (3.36009 iter/s, 29.7611s/100 iters), loss = 0.00936796
I1008 02:51:43.716892  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00936807 (* 1 = 0.00936807 loss)
I1008 02:51:43.716899  5322 sgd_solver.cpp:105] Iteration 64000, lr = 0.01
I1008 02:52:08.709134  5322 solver.cpp:218] Iteration 64100 (4.0016 iter/s, 24.99s/100 iters), loss = 0.0132743
I1008 02:52:08.709247  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0132744 (* 1 = 0.0132744 loss)
I1008 02:52:08.709259  5322 sgd_solver.cpp:105] Iteration 64100, lr = 0.01
I1008 02:52:33.466423  5322 solver.cpp:218] Iteration 64200 (4.03951 iter/s, 24.7555s/100 iters), loss = 0.0375851
I1008 02:52:33.466461  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0375852 (* 1 = 0.0375852 loss)
I1008 02:52:33.466471  5322 sgd_solver.cpp:105] Iteration 64200, lr = 0.01
I1008 02:52:58.112498  5322 solver.cpp:218] Iteration 64300 (4.05803 iter/s, 24.6425s/100 iters), loss = 0.0287833
I1008 02:52:58.112610  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0287834 (* 1 = 0.0287834 loss)
I1008 02:52:58.112625  5322 sgd_solver.cpp:105] Iteration 64300, lr = 0.01
I1008 02:53:22.775290  5322 solver.cpp:218] Iteration 64400 (4.05529 iter/s, 24.6591s/100 iters), loss = 0.0130625
I1008 02:53:22.775336  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0130626 (* 1 = 0.0130626 loss)
I1008 02:53:22.775342  5322 sgd_solver.cpp:105] Iteration 64400, lr = 0.01
I1008 02:53:46.648010  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:53:47.633247  5322 solver.cpp:330] Iteration 64500, Testing net (#0)
I1008 02:53:52.244405  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:53:52.428222  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9102
I1008 02:53:52.428257  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.361786 (* 1 = 0.361786 loss)
I1008 02:53:52.597975  5322 solver.cpp:218] Iteration 64500 (3.35355 iter/s, 29.8191s/100 iters), loss = 0.0221953
I1008 02:53:52.598018  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0221954 (* 1 = 0.0221954 loss)
I1008 02:53:52.598026  5322 sgd_solver.cpp:105] Iteration 64500, lr = 0.01
I1008 02:54:17.552800  5322 solver.cpp:218] Iteration 64600 (4.00761 iter/s, 24.9525s/100 iters), loss = 0.012531
I1008 02:54:17.552899  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0125311 (* 1 = 0.0125311 loss)
I1008 02:54:17.552909  5322 sgd_solver.cpp:105] Iteration 64600, lr = 0.01
I1008 02:54:42.364876  5322 solver.cpp:218] Iteration 64700 (4.03033 iter/s, 24.8119s/100 iters), loss = 0.0216604
I1008 02:54:42.364923  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0216605 (* 1 = 0.0216605 loss)
I1008 02:54:42.364930  5322 sgd_solver.cpp:105] Iteration 64700, lr = 0.01
I1008 02:55:07.004957  5322 solver.cpp:218] Iteration 64800 (4.05916 iter/s, 24.6356s/100 iters), loss = 0.0147878
I1008 02:55:07.005043  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0147879 (* 1 = 0.0147879 loss)
I1008 02:55:07.005051  5322 sgd_solver.cpp:105] Iteration 64800, lr = 0.01
I1008 02:55:31.649145  5322 solver.cpp:218] Iteration 64900 (4.05848 iter/s, 24.6398s/100 iters), loss = 0.0352542
I1008 02:55:31.649179  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0352543 (* 1 = 0.0352543 loss)
I1008 02:55:31.649186  5322 sgd_solver.cpp:105] Iteration 64900, lr = 0.01
I1008 02:55:55.517220  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:55:56.499347  5322 solver.cpp:330] Iteration 65000, Testing net (#0)
I1008 02:56:01.020294  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:56:01.207716  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.91
I1008 02:56:01.207746  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.339139 (* 1 = 0.339139 loss)
I1008 02:56:01.385648  5322 solver.cpp:218] Iteration 65000 (3.36313 iter/s, 29.7342s/100 iters), loss = 0.0065743
I1008 02:56:01.385679  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0065744 (* 1 = 0.0065744 loss)
I1008 02:56:01.385685  5322 sgd_solver.cpp:105] Iteration 65000, lr = 0.01
I1008 02:56:26.269366  5322 solver.cpp:218] Iteration 65100 (4.01871 iter/s, 24.8836s/100 iters), loss = 0.021145
I1008 02:56:26.269465  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0211451 (* 1 = 0.0211451 loss)
I1008 02:56:26.269474  5322 sgd_solver.cpp:105] Iteration 65100, lr = 0.01
I1008 02:56:51.142102  5322 solver.cpp:218] Iteration 65200 (4.02118 iter/s, 24.8683s/100 iters), loss = 0.0118988
I1008 02:56:51.142148  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0118989 (* 1 = 0.0118989 loss)
I1008 02:56:51.142154  5322 sgd_solver.cpp:105] Iteration 65200, lr = 0.01
I1008 02:57:15.779090  5322 solver.cpp:218] Iteration 65300 (4.05966 iter/s, 24.6326s/100 iters), loss = 0.00684598
I1008 02:57:15.779167  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00684606 (* 1 = 0.00684606 loss)
I1008 02:57:15.779176  5322 sgd_solver.cpp:105] Iteration 65300, lr = 0.01
I1008 02:57:40.385226  5322 solver.cpp:218] Iteration 65400 (4.06471 iter/s, 24.602s/100 iters), loss = 0.0091837
I1008 02:57:40.385270  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00918378 (* 1 = 0.00918378 loss)
I1008 02:57:40.385277  5322 sgd_solver.cpp:105] Iteration 65400, lr = 0.01
I1008 02:58:04.186558  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:58:05.170694  5322 solver.cpp:330] Iteration 65500, Testing net (#0)
I1008 02:58:09.698809  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:58:09.880494  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9124
I1008 02:58:09.880520  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.35113 (* 1 = 0.35113 loss)
I1008 02:58:10.061652  5322 solver.cpp:218] Iteration 65500 (3.37018 iter/s, 29.672s/100 iters), loss = 0.0120252
I1008 02:58:10.061686  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0120253 (* 1 = 0.0120253 loss)
I1008 02:58:10.061692  5322 sgd_solver.cpp:105] Iteration 65500, lr = 0.01
I1008 02:58:34.834794  5322 solver.cpp:218] Iteration 65600 (4.037 iter/s, 24.7709s/100 iters), loss = 0.0132692
I1008 02:58:34.834867  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0132692 (* 1 = 0.0132692 loss)
I1008 02:58:34.834877  5322 sgd_solver.cpp:105] Iteration 65600, lr = 0.01
I1008 02:58:59.769776  5322 solver.cpp:218] Iteration 65700 (4.01114 iter/s, 24.9306s/100 iters), loss = 0.0139141
I1008 02:58:59.769820  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0139142 (* 1 = 0.0139142 loss)
I1008 02:58:59.769827  5322 sgd_solver.cpp:105] Iteration 65700, lr = 0.01
I1008 02:59:24.419003  5322 solver.cpp:218] Iteration 65800 (4.05758 iter/s, 24.6452s/100 iters), loss = 0.0056811
I1008 02:59:24.419113  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00568118 (* 1 = 0.00568118 loss)
I1008 02:59:24.419121  5322 sgd_solver.cpp:105] Iteration 65800, lr = 0.01
I1008 02:59:49.079507  5322 solver.cpp:218] Iteration 65900 (4.05579 iter/s, 24.6561s/100 iters), loss = 0.00371767
I1008 02:59:49.079551  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00371775 (* 1 = 0.00371775 loss)
I1008 02:59:49.079560  5322 sgd_solver.cpp:105] Iteration 65900, lr = 0.01
I1008 03:00:12.883460  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:00:13.867593  5322 solver.cpp:330] Iteration 66000, Testing net (#0)
I1008 03:00:18.387976  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:00:18.577280  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9096
I1008 03:00:18.577309  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.356766 (* 1 = 0.356766 loss)
I1008 03:00:18.755419  5322 solver.cpp:218] Iteration 66000 (3.37016 iter/s, 29.6722s/100 iters), loss = 0.00342972
I1008 03:00:18.755452  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0034298 (* 1 = 0.0034298 loss)
I1008 03:00:18.755460  5322 sgd_solver.cpp:105] Iteration 66000, lr = 0.01
I1008 03:00:43.473433  5322 solver.cpp:218] Iteration 66100 (4.04565 iter/s, 24.7179s/100 iters), loss = 0.00893956
I1008 03:00:43.473546  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00893964 (* 1 = 0.00893964 loss)
I1008 03:00:43.473553  5322 sgd_solver.cpp:105] Iteration 66100, lr = 0.01
I1008 03:01:08.498589  5322 solver.cpp:218] Iteration 66200 (3.9962 iter/s, 25.0238s/100 iters), loss = 0.00564543
I1008 03:01:08.498626  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00564551 (* 1 = 0.00564551 loss)
I1008 03:01:08.498636  5322 sgd_solver.cpp:105] Iteration 66200, lr = 0.01
I1008 03:01:33.130373  5322 solver.cpp:218] Iteration 66300 (4.06052 iter/s, 24.6274s/100 iters), loss = 0.0139406
I1008 03:01:33.130441  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0139407 (* 1 = 0.0139407 loss)
I1008 03:01:33.130455  5322 sgd_solver.cpp:105] Iteration 66300, lr = 0.01
I1008 03:01:57.745800  5322 solver.cpp:218] Iteration 66400 (4.06313 iter/s, 24.6116s/100 iters), loss = 0.00747719
I1008 03:01:57.745836  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00747726 (* 1 = 0.00747726 loss)
I1008 03:01:57.745857  5322 sgd_solver.cpp:105] Iteration 66400, lr = 0.01
I1008 03:02:21.670437  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:02:22.654466  5322 solver.cpp:330] Iteration 66500, Testing net (#0)
I1008 03:02:27.285475  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:02:27.469449  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9123
I1008 03:02:27.469475  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.348811 (* 1 = 0.348811 loss)
I1008 03:02:27.610157  5322 solver.cpp:218] Iteration 66500 (3.3489 iter/s, 29.8606s/100 iters), loss = 0.0140574
I1008 03:02:27.610191  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0140575 (* 1 = 0.0140575 loss)
I1008 03:02:27.610199  5322 sgd_solver.cpp:105] Iteration 66500, lr = 0.01
I1008 03:02:52.285589  5322 solver.cpp:218] Iteration 66600 (4.05299 iter/s, 24.6731s/100 iters), loss = 0.00691725
I1008 03:02:52.285725  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00691729 (* 1 = 0.00691729 loss)
I1008 03:02:52.285738  5322 sgd_solver.cpp:105] Iteration 66600, lr = 0.01
I1008 03:03:17.296288  5322 solver.cpp:218] Iteration 66700 (3.99846 iter/s, 25.0096s/100 iters), loss = 0.00331231
I1008 03:03:17.296335  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00331235 (* 1 = 0.00331235 loss)
I1008 03:03:17.296342  5322 sgd_solver.cpp:105] Iteration 66700, lr = 0.01
I1008 03:03:41.920033  5322 solver.cpp:218] Iteration 66800 (4.06178 iter/s, 24.6198s/100 iters), loss = 0.0514646
I1008 03:03:41.920106  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0514647 (* 1 = 0.0514647 loss)
I1008 03:03:41.920115  5322 sgd_solver.cpp:105] Iteration 66800, lr = 0.01
I1008 03:04:06.596135  5322 solver.cpp:218] Iteration 66900 (4.05287 iter/s, 24.6738s/100 iters), loss = 0.00262865
I1008 03:04:06.596168  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00262869 (* 1 = 0.00262869 loss)
I1008 03:04:06.596175  5322 sgd_solver.cpp:105] Iteration 66900, lr = 0.01
I1008 03:04:30.477571  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:04:31.459918  5322 solver.cpp:330] Iteration 67000, Testing net (#0)
I1008 03:04:36.112438  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:04:36.313531  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9143
I1008 03:04:36.313556  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.347346 (* 1 = 0.347346 loss)
I1008 03:04:36.451730  5322 solver.cpp:218] Iteration 67000 (3.34988 iter/s, 29.8518s/100 iters), loss = 0.0119072
I1008 03:04:36.451762  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0119073 (* 1 = 0.0119073 loss)
I1008 03:04:36.451769  5322 sgd_solver.cpp:105] Iteration 67000, lr = 0.01
I1008 03:05:01.142783  5322 solver.cpp:218] Iteration 67100 (4.05042 iter/s, 24.6888s/100 iters), loss = 0.0306661
I1008 03:05:01.142863  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0306661 (* 1 = 0.0306661 loss)
I1008 03:05:01.142876  5322 sgd_solver.cpp:105] Iteration 67100, lr = 0.01
I1008 03:05:26.116448  5322 solver.cpp:218] Iteration 67200 (4.00483 iter/s, 24.9698s/100 iters), loss = 0.00395459
I1008 03:05:26.116485  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00395464 (* 1 = 0.00395464 loss)
I1008 03:05:26.116492  5322 sgd_solver.cpp:105] Iteration 67200, lr = 0.01
I1008 03:05:50.748770  5322 solver.cpp:218] Iteration 67300 (4.06032 iter/s, 24.6286s/100 iters), loss = 0.013253
I1008 03:05:50.748880  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.013253 (* 1 = 0.013253 loss)
I1008 03:05:50.748893  5322 sgd_solver.cpp:105] Iteration 67300, lr = 0.01
I1008 03:06:15.377918  5322 solver.cpp:218] Iteration 67400 (4.06082 iter/s, 24.6256s/100 iters), loss = 0.00657145
I1008 03:06:15.377957  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00657149 (* 1 = 0.00657149 loss)
I1008 03:06:15.377966  5322 sgd_solver.cpp:105] Iteration 67400, lr = 0.01
I1008 03:06:39.226599  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:06:40.209623  5322 solver.cpp:330] Iteration 67500, Testing net (#0)
I1008 03:06:44.873034  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:06:45.088764  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9091
I1008 03:06:45.088799  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.373886 (* 1 = 0.373886 loss)
I1008 03:06:45.232246  5322 solver.cpp:218] Iteration 67500 (3.35003 iter/s, 29.8505s/100 iters), loss = 0.00507715
I1008 03:06:45.232287  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00507719 (* 1 = 0.00507719 loss)
I1008 03:06:45.232298  5322 sgd_solver.cpp:105] Iteration 67500, lr = 0.01
I1008 03:07:09.863224  5322 solver.cpp:218] Iteration 67600 (4.06065 iter/s, 24.6266s/100 iters), loss = 0.00755559
I1008 03:07:09.863324  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00755563 (* 1 = 0.00755563 loss)
I1008 03:07:09.863346  5322 sgd_solver.cpp:105] Iteration 67600, lr = 0.01
I1008 03:07:34.920338  5322 solver.cpp:218] Iteration 67700 (3.99155 iter/s, 25.0529s/100 iters), loss = 0.0189641
I1008 03:07:34.920372  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0189641 (* 1 = 0.0189641 loss)
I1008 03:07:34.920380  5322 sgd_solver.cpp:105] Iteration 67700, lr = 0.01
I1008 03:07:59.521677  5322 solver.cpp:218] Iteration 67800 (4.0652 iter/s, 24.5991s/100 iters), loss = 0.0127614
I1008 03:07:59.521745  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0127614 (* 1 = 0.0127614 loss)
I1008 03:07:59.521754  5322 sgd_solver.cpp:105] Iteration 67800, lr = 0.01
I1008 03:08:24.167104  5322 solver.cpp:218] Iteration 67900 (4.05792 iter/s, 24.6432s/100 iters), loss = 0.0059525
I1008 03:08:24.167145  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00595254 (* 1 = 0.00595254 loss)
I1008 03:08:24.167160  5322 sgd_solver.cpp:105] Iteration 67900, lr = 0.01
I1008 03:08:47.978792  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:08:48.954649  5322 solver.cpp:330] Iteration 68000, Testing net (#0)
I1008 03:08:53.503895  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:08:53.693042  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9089
I1008 03:08:53.693069  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.35691 (* 1 = 0.35691 loss)
I1008 03:08:53.826673  5322 solver.cpp:218] Iteration 68000 (3.37209 iter/s, 29.6552s/100 iters), loss = 0.00503734
I1008 03:08:53.826704  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00503739 (* 1 = 0.00503739 loss)
I1008 03:08:53.826721  5322 sgd_solver.cpp:105] Iteration 68000, lr = 0.01
I1008 03:09:18.410102  5322 solver.cpp:218] Iteration 68100 (4.06781 iter/s, 24.5832s/100 iters), loss = 0.0117577
I1008 03:09:18.410236  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0117577 (* 1 = 0.0117577 loss)
I1008 03:09:18.410248  5322 sgd_solver.cpp:105] Iteration 68100, lr = 0.01
I1008 03:09:43.518225  5322 solver.cpp:218] Iteration 68200 (3.98347 iter/s, 25.1037s/100 iters), loss = 0.00687103
I1008 03:09:43.518278  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00687108 (* 1 = 0.00687108 loss)
I1008 03:09:43.518288  5322 sgd_solver.cpp:105] Iteration 68200, lr = 0.01
I1008 03:10:08.015981  5322 solver.cpp:218] Iteration 68300 (4.08238 iter/s, 24.4955s/100 iters), loss = 0.0173334
I1008 03:10:08.016072  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0173335 (* 1 = 0.0173335 loss)
I1008 03:10:08.016082  5322 sgd_solver.cpp:105] Iteration 68300, lr = 0.01
I1008 03:10:32.574916  5322 solver.cpp:218] Iteration 68400 (4.07222 iter/s, 24.5566s/100 iters), loss = 0.0242011
I1008 03:10:32.574959  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0242012 (* 1 = 0.0242012 loss)
I1008 03:10:32.574966  5322 sgd_solver.cpp:105] Iteration 68400, lr = 0.01
I1008 03:10:56.379854  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:10:57.368474  5322 solver.cpp:330] Iteration 68500, Testing net (#0)
I1008 03:11:01.961129  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:11:02.096427  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9135
I1008 03:11:02.096453  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.330453 (* 1 = 0.330453 loss)
I1008 03:11:02.313565  5322 solver.cpp:218] Iteration 68500 (3.36313 iter/s, 29.7342s/100 iters), loss = 0.0573195
I1008 03:11:02.313608  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0573196 (* 1 = 0.0573196 loss)
I1008 03:11:02.313616  5322 sgd_solver.cpp:105] Iteration 68500, lr = 0.01
I1008 03:11:26.853993  5322 solver.cpp:218] Iteration 68600 (4.07528 iter/s, 24.5382s/100 iters), loss = 0.0148288
I1008 03:11:26.854073  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0148289 (* 1 = 0.0148289 loss)
I1008 03:11:26.854084  5322 sgd_solver.cpp:105] Iteration 68600, lr = 0.01
I1008 03:11:51.931340  5322 solver.cpp:218] Iteration 68700 (3.98802 iter/s, 25.0751s/100 iters), loss = 0.00740296
I1008 03:11:51.931377  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00740301 (* 1 = 0.00740301 loss)
I1008 03:11:51.931385  5322 sgd_solver.cpp:105] Iteration 68700, lr = 0.01
I1008 03:12:16.594753  5322 solver.cpp:218] Iteration 68800 (4.05523 iter/s, 24.6595s/100 iters), loss = 0.0140186
I1008 03:12:16.594848  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0140187 (* 1 = 0.0140187 loss)
I1008 03:12:16.594857  5322 sgd_solver.cpp:105] Iteration 68800, lr = 0.01
I1008 03:12:41.254206  5322 solver.cpp:218] Iteration 68900 (4.05584 iter/s, 24.6558s/100 iters), loss = 0.00625133
I1008 03:12:41.254256  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00625137 (* 1 = 0.00625137 loss)
I1008 03:12:41.254262  5322 sgd_solver.cpp:105] Iteration 68900, lr = 0.01
I1008 03:13:05.053031  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:13:06.037744  5322 solver.cpp:330] Iteration 69000, Testing net (#0)
I1008 03:13:10.528779  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:13:10.743559  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9178
I1008 03:13:10.743584  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.328514 (* 1 = 0.328514 loss)
I1008 03:13:10.872305  5322 solver.cpp:218] Iteration 69000 (3.37673 iter/s, 29.6145s/100 iters), loss = 0.0123942
I1008 03:13:10.872346  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0123942 (* 1 = 0.0123942 loss)
I1008 03:13:10.872354  5322 sgd_solver.cpp:105] Iteration 69000, lr = 0.01
I1008 03:13:35.547335  5322 solver.cpp:218] Iteration 69100 (4.05305 iter/s, 24.6728s/100 iters), loss = 0.0207079
I1008 03:13:35.547442  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0207079 (* 1 = 0.0207079 loss)
I1008 03:13:35.547453  5322 sgd_solver.cpp:105] Iteration 69100, lr = 0.01
I1008 03:14:00.637778  5322 solver.cpp:218] Iteration 69200 (3.98622 iter/s, 25.0864s/100 iters), loss = 0.00599081
I1008 03:14:00.637822  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00599084 (* 1 = 0.00599084 loss)
I1008 03:14:00.637830  5322 sgd_solver.cpp:105] Iteration 69200, lr = 0.01
I1008 03:14:25.288580  5322 solver.cpp:218] Iteration 69300 (4.05729 iter/s, 24.647s/100 iters), loss = 0.012807
I1008 03:14:25.288669  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.012807 (* 1 = 0.012807 loss)
I1008 03:14:25.288684  5322 sgd_solver.cpp:105] Iteration 69300, lr = 0.01
I1008 03:14:49.926087  5322 solver.cpp:218] Iteration 69400 (4.05946 iter/s, 24.6338s/100 iters), loss = 0.00167318
I1008 03:14:49.926131  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00167321 (* 1 = 0.00167321 loss)
I1008 03:14:49.926138  5322 sgd_solver.cpp:105] Iteration 69400, lr = 0.01
I1008 03:15:13.711967  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:15:14.694820  5322 solver.cpp:330] Iteration 69500, Testing net (#0)
I1008 03:15:19.342144  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:15:19.527179  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9086
I1008 03:15:19.527215  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.368422 (* 1 = 0.368422 loss)
I1008 03:15:19.686039  5322 solver.cpp:218] Iteration 69500 (3.36065 iter/s, 29.7562s/100 iters), loss = 0.00599275
I1008 03:15:19.686082  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00599278 (* 1 = 0.00599278 loss)
I1008 03:15:19.686089  5322 sgd_solver.cpp:105] Iteration 69500, lr = 0.01
I1008 03:15:44.366813  5322 solver.cpp:218] Iteration 69600 (4.05211 iter/s, 24.6785s/100 iters), loss = 0.00927735
I1008 03:15:44.366920  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00927739 (* 1 = 0.00927739 loss)
I1008 03:15:44.366930  5322 sgd_solver.cpp:105] Iteration 69600, lr = 0.01
I1008 03:16:09.455281  5322 solver.cpp:218] Iteration 69700 (3.98659 iter/s, 25.0841s/100 iters), loss = 0.00731031
I1008 03:16:09.455317  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00731035 (* 1 = 0.00731035 loss)
I1008 03:16:09.455324  5322 sgd_solver.cpp:105] Iteration 69700, lr = 0.01
I1008 03:16:34.093107  5322 solver.cpp:218] Iteration 69800 (4.05952 iter/s, 24.6334s/100 iters), loss = 0.008857
I1008 03:16:34.093207  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00885703 (* 1 = 0.00885703 loss)
I1008 03:16:34.093217  5322 sgd_solver.cpp:105] Iteration 69800, lr = 0.01
I1008 03:16:58.724886  5322 solver.cpp:218] Iteration 69900 (4.06053 iter/s, 24.6273s/100 iters), loss = 0.00356332
I1008 03:16:58.724921  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00356336 (* 1 = 0.00356336 loss)
I1008 03:16:58.724930  5322 sgd_solver.cpp:105] Iteration 69900, lr = 0.01
I1008 03:17:22.538707  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:17:23.521287  5322 solver.cpp:330] Iteration 70000, Testing net (#0)
I1008 03:17:28.103967  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:17:28.289271  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9104
I1008 03:17:28.289299  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.36038 (* 1 = 0.36038 loss)
I1008 03:17:28.451128  5322 solver.cpp:218] Iteration 70000 (3.36453 iter/s, 29.7218s/100 iters), loss = 0.00858184
I1008 03:17:28.451170  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00858187 (* 1 = 0.00858187 loss)
I1008 03:17:28.451177  5322 sgd_solver.cpp:105] Iteration 70000, lr = 0.01
I1008 03:17:53.022024  5322 solver.cpp:218] Iteration 70100 (4.07023 iter/s, 24.5686s/100 iters), loss = 0.0256384
I1008 03:17:53.022152  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0256384 (* 1 = 0.0256384 loss)
I1008 03:17:53.022162  5322 sgd_solver.cpp:105] Iteration 70100, lr = 0.01
I1008 03:18:18.111280  5322 solver.cpp:218] Iteration 70200 (3.98636 iter/s, 25.0855s/100 iters), loss = 0.00222276
I1008 03:18:18.111316  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00222277 (* 1 = 0.00222277 loss)
I1008 03:18:18.111326  5322 sgd_solver.cpp:105] Iteration 70200, lr = 0.01
I1008 03:18:42.748857  5322 solver.cpp:218] Iteration 70300 (4.05945 iter/s, 24.6339s/100 iters), loss = 0.0285594
I1008 03:18:42.748952  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0285595 (* 1 = 0.0285595 loss)
I1008 03:18:42.748961  5322 sgd_solver.cpp:105] Iteration 70300, lr = 0.01
I1008 03:19:07.394922  5322 solver.cpp:218] Iteration 70400 (4.05817 iter/s, 24.6417s/100 iters), loss = 0.0183257
I1008 03:19:07.394965  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0183257 (* 1 = 0.0183257 loss)
I1008 03:19:07.394973  5322 sgd_solver.cpp:105] Iteration 70400, lr = 0.01
I1008 03:19:31.212281  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:19:32.193622  5322 solver.cpp:330] Iteration 70500, Testing net (#0)
I1008 03:19:36.774349  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:19:36.964664  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9114
I1008 03:19:36.964691  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.35683 (* 1 = 0.35683 loss)
I1008 03:19:37.121913  5322 solver.cpp:218] Iteration 70500 (3.36445 iter/s, 29.7226s/100 iters), loss = 0.00963004
I1008 03:19:37.121953  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00963006 (* 1 = 0.00963006 loss)
I1008 03:19:37.121963  5322 sgd_solver.cpp:105] Iteration 70500, lr = 0.01
I1008 03:20:01.706477  5322 solver.cpp:218] Iteration 70600 (4.06797 iter/s, 24.5823s/100 iters), loss = 0.00430426
I1008 03:20:01.706578  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00430427 (* 1 = 0.00430427 loss)
I1008 03:20:01.706588  5322 sgd_solver.cpp:105] Iteration 70600, lr = 0.01
I1008 03:20:26.762109  5322 solver.cpp:218] Iteration 70700 (3.99179 iter/s, 25.0514s/100 iters), loss = 0.0118011
I1008 03:20:26.762143  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0118012 (* 1 = 0.0118012 loss)
I1008 03:20:26.762151  5322 sgd_solver.cpp:105] Iteration 70700, lr = 0.01
I1008 03:20:51.412462  5322 solver.cpp:218] Iteration 70800 (4.05746 iter/s, 24.646s/100 iters), loss = 0.0648249
I1008 03:20:51.412550  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0648249 (* 1 = 0.0648249 loss)
I1008 03:20:51.412559  5322 sgd_solver.cpp:105] Iteration 70800, lr = 0.01
I1008 03:21:16.047796  5322 solver.cpp:218] Iteration 70900 (4.05985 iter/s, 24.6315s/100 iters), loss = 0.0424581
I1008 03:21:16.047829  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0424581 (* 1 = 0.0424581 loss)
I1008 03:21:16.047837  5322 sgd_solver.cpp:105] Iteration 70900, lr = 0.01
I1008 03:21:39.838562  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:21:40.824220  5322 solver.cpp:330] Iteration 71000, Testing net (#0)
I1008 03:21:45.367571  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:21:45.556218  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9116
I1008 03:21:45.556244  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.348407 (* 1 = 0.348407 loss)
I1008 03:21:45.718650  5322 solver.cpp:218] Iteration 71000 (3.37081 iter/s, 29.6664s/100 iters), loss = 0.0334885
I1008 03:21:45.718683  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0334885 (* 1 = 0.0334885 loss)
I1008 03:21:45.718690  5322 sgd_solver.cpp:105] Iteration 71000, lr = 0.01
I1008 03:22:10.324810  5322 solver.cpp:218] Iteration 71100 (4.0644 iter/s, 24.6039s/100 iters), loss = 0.0240394
I1008 03:22:10.329406  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0240394 (* 1 = 0.0240394 loss)
I1008 03:22:10.329416  5322 sgd_solver.cpp:105] Iteration 71100, lr = 0.01
I1008 03:22:35.308734  5322 solver.cpp:218] Iteration 71200 (4.00365 iter/s, 24.9772s/100 iters), loss = 0.0338827
I1008 03:22:35.308769  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0338827 (* 1 = 0.0338827 loss)
I1008 03:22:35.308775  5322 sgd_solver.cpp:105] Iteration 71200, lr = 0.01
I1008 03:22:59.936188  5322 solver.cpp:218] Iteration 71300 (4.06112 iter/s, 24.6238s/100 iters), loss = 0.00716544
I1008 03:22:59.936277  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00716545 (* 1 = 0.00716545 loss)
I1008 03:22:59.936285  5322 sgd_solver.cpp:105] Iteration 71300, lr = 0.01
I1008 03:23:24.552096  5322 solver.cpp:218] Iteration 71400 (4.06314 iter/s, 24.6115s/100 iters), loss = 0.0139548
I1008 03:23:24.552129  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0139548 (* 1 = 0.0139548 loss)
I1008 03:23:24.552136  5322 sgd_solver.cpp:105] Iteration 71400, lr = 0.01
I1008 03:23:48.318625  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:23:49.301882  5322 solver.cpp:330] Iteration 71500, Testing net (#0)
I1008 03:23:53.883002  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:23:54.032958  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9094
I1008 03:23:54.032984  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.358516 (* 1 = 0.358516 loss)
I1008 03:23:54.228503  5322 solver.cpp:218] Iteration 71500 (3.37003 iter/s, 29.6733s/100 iters), loss = 0.0142076
I1008 03:23:54.228544  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0142076 (* 1 = 0.0142076 loss)
I1008 03:23:54.228551  5322 sgd_solver.cpp:105] Iteration 71500, lr = 0.01
I1008 03:24:18.800366  5322 solver.cpp:218] Iteration 71600 (4.07007 iter/s, 24.5696s/100 iters), loss = 0.0311432
I1008 03:24:18.800457  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0311432 (* 1 = 0.0311432 loss)
I1008 03:24:18.800465  5322 sgd_solver.cpp:105] Iteration 71600, lr = 0.01
I1008 03:24:43.853101  5322 solver.cpp:218] Iteration 71700 (3.99194 iter/s, 25.0505s/100 iters), loss = 0.036443
I1008 03:24:43.853138  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.036443 (* 1 = 0.036443 loss)
I1008 03:24:43.853148  5322 sgd_solver.cpp:105] Iteration 71700, lr = 0.01
I1008 03:25:08.466241  5322 solver.cpp:218] Iteration 71800 (4.0636 iter/s, 24.6087s/100 iters), loss = 0.00489234
I1008 03:25:08.466318  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00489236 (* 1 = 0.00489236 loss)
I1008 03:25:08.466332  5322 sgd_solver.cpp:105] Iteration 71800, lr = 0.01
I1008 03:25:33.079246  5322 solver.cpp:218] Iteration 71900 (4.06357 iter/s, 24.6089s/100 iters), loss = 0.0305874
I1008 03:25:33.079282  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0305874 (* 1 = 0.0305874 loss)
I1008 03:25:33.079291  5322 sgd_solver.cpp:105] Iteration 71900, lr = 0.01
I1008 03:25:56.948027  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:25:57.931105  5322 solver.cpp:330] Iteration 72000, Testing net (#0)
I1008 03:26:02.490484  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:26:02.670107  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9098
I1008 03:26:02.670137  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.363147 (* 1 = 0.363147 loss)
I1008 03:26:02.824883  5322 solver.cpp:218] Iteration 72000 (3.36233 iter/s, 29.7413s/100 iters), loss = 0.00790866
I1008 03:26:02.824918  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00790869 (* 1 = 0.00790869 loss)
I1008 03:26:02.824928  5322 sgd_solver.cpp:105] Iteration 72000, lr = 0.01
I1008 03:26:27.439693  5322 solver.cpp:218] Iteration 72100 (4.06297 iter/s, 24.6126s/100 iters), loss = 0.0146135
I1008 03:26:27.439823  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0146135 (* 1 = 0.0146135 loss)
I1008 03:26:27.439837  5322 sgd_solver.cpp:105] Iteration 72100, lr = 0.01
I1008 03:26:52.503183  5322 solver.cpp:218] Iteration 72200 (3.99023 iter/s, 25.0612s/100 iters), loss = 0.00402385
I1008 03:26:52.503218  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00402388 (* 1 = 0.00402388 loss)
I1008 03:26:52.503226  5322 sgd_solver.cpp:105] Iteration 72200, lr = 0.01
I1008 03:27:17.125952  5322 solver.cpp:218] Iteration 72300 (4.06201 iter/s, 24.6184s/100 iters), loss = 0.00206337
I1008 03:27:17.126054  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00206341 (* 1 = 0.00206341 loss)
I1008 03:27:17.126062  5322 sgd_solver.cpp:105] Iteration 72300, lr = 0.01
I1008 03:27:41.776170  5322 solver.cpp:218] Iteration 72400 (4.05735 iter/s, 24.6466s/100 iters), loss = 0.0377458
I1008 03:27:41.776216  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0377458 (* 1 = 0.0377458 loss)
I1008 03:27:41.776222  5322 sgd_solver.cpp:105] Iteration 72400, lr = 0.01
I1008 03:28:05.485713  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:28:06.472311  5322 solver.cpp:330] Iteration 72500, Testing net (#0)
I1008 03:28:10.996945  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:28:11.187896  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9072
I1008 03:28:11.187922  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.38083 (* 1 = 0.38083 loss)
I1008 03:28:11.343786  5322 solver.cpp:218] Iteration 72500 (3.38247 iter/s, 29.5642s/100 iters), loss = 0.0147976
I1008 03:28:11.343828  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0147976 (* 1 = 0.0147976 loss)
I1008 03:28:11.343835  5322 sgd_solver.cpp:105] Iteration 72500, lr = 0.01
I1008 03:28:35.914567  5322 solver.cpp:218] Iteration 72600 (4.0699 iter/s, 24.5706s/100 iters), loss = 0.0370111
I1008 03:28:35.914654  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0370112 (* 1 = 0.0370112 loss)
I1008 03:28:35.914667  5322 sgd_solver.cpp:105] Iteration 72600, lr = 0.01
I1008 03:29:00.978910  5322 solver.cpp:218] Iteration 72700 (3.99038 iter/s, 25.0603s/100 iters), loss = 0.00855909
I1008 03:29:00.978957  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00855915 (* 1 = 0.00855915 loss)
I1008 03:29:00.978965  5322 sgd_solver.cpp:105] Iteration 72700, lr = 0.01
I1008 03:29:25.640803  5322 solver.cpp:218] Iteration 72800 (4.05556 iter/s, 24.6575s/100 iters), loss = 0.0146765
I1008 03:29:25.640893  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0146766 (* 1 = 0.0146766 loss)
I1008 03:29:25.640907  5322 sgd_solver.cpp:105] Iteration 72800, lr = 0.01
I1008 03:29:50.271893  5322 solver.cpp:218] Iteration 72900 (4.06028 iter/s, 24.6288s/100 iters), loss = 0.0067256
I1008 03:29:50.271929  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00672565 (* 1 = 0.00672565 loss)
I1008 03:29:50.271936  5322 sgd_solver.cpp:105] Iteration 72900, lr = 0.01
I1008 03:30:14.060081  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:30:15.045788  5322 solver.cpp:330] Iteration 73000, Testing net (#0)
I1008 03:30:19.723064  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:30:19.926899  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9118
I1008 03:30:19.926925  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.366804 (* 1 = 0.366804 loss)
I1008 03:30:20.082989  5322 solver.cpp:218] Iteration 73000 (3.35485 iter/s, 29.8076s/100 iters), loss = 0.00386932
I1008 03:30:20.083034  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00386938 (* 1 = 0.00386938 loss)
I1008 03:30:20.083040  5322 sgd_solver.cpp:105] Iteration 73000, lr = 0.01
I1008 03:30:44.731551  5322 solver.cpp:218] Iteration 73100 (4.05776 iter/s, 24.6441s/100 iters), loss = 0.00645348
I1008 03:30:44.731655  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00645353 (* 1 = 0.00645353 loss)
I1008 03:30:44.731664  5322 sgd_solver.cpp:105] Iteration 73100, lr = 0.01
I1008 03:31:09.812525  5322 solver.cpp:218] Iteration 73200 (3.98766 iter/s, 25.0774s/100 iters), loss = 0.00864196
I1008 03:31:09.812561  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00864201 (* 1 = 0.00864201 loss)
I1008 03:31:09.812567  5322 sgd_solver.cpp:105] Iteration 73200, lr = 0.01
I1008 03:31:34.418154  5322 solver.cpp:218] Iteration 73300 (4.06483 iter/s, 24.6013s/100 iters), loss = 0.00512883
I1008 03:31:34.418248  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00512888 (* 1 = 0.00512888 loss)
I1008 03:31:34.418257  5322 sgd_solver.cpp:105] Iteration 73300, lr = 0.01
I1008 03:31:59.085680  5322 solver.cpp:218] Iteration 73400 (4.05464 iter/s, 24.6631s/100 iters), loss = 0.00561947
I1008 03:31:59.085716  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00561951 (* 1 = 0.00561951 loss)
I1008 03:31:59.085736  5322 sgd_solver.cpp:105] Iteration 73400, lr = 0.01
I1008 03:32:22.953269  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:32:23.936784  5322 solver.cpp:330] Iteration 73500, Testing net (#0)
I1008 03:32:28.511595  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:32:28.665529  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9069
I1008 03:32:28.665555  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.378362 (* 1 = 0.378362 loss)
I1008 03:32:28.856211  5322 solver.cpp:218] Iteration 73500 (3.3595 iter/s, 29.7663s/100 iters), loss = 0.00149098
I1008 03:32:28.856246  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00149102 (* 1 = 0.00149102 loss)
I1008 03:32:28.856254  5322 sgd_solver.cpp:105] Iteration 73500, lr = 0.01
I1008 03:32:53.438783  5322 solver.cpp:218] Iteration 73600 (4.0683 iter/s, 24.5803s/100 iters), loss = 0.00730137
I1008 03:32:53.438855  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00730141 (* 1 = 0.00730141 loss)
I1008 03:32:53.438864  5322 sgd_solver.cpp:105] Iteration 73600, lr = 0.01
I1008 03:33:18.430462  5322 solver.cpp:218] Iteration 73700 (4.00203 iter/s, 24.9873s/100 iters), loss = 0.0279774
I1008 03:33:18.430508  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0279774 (* 1 = 0.0279774 loss)
I1008 03:33:18.430516  5322 sgd_solver.cpp:105] Iteration 73700, lr = 0.01
I1008 03:33:43.076165  5322 solver.cpp:218] Iteration 73800 (4.05813 iter/s, 24.6419s/100 iters), loss = 0.0160681
I1008 03:33:43.076251  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0160681 (* 1 = 0.0160681 loss)
I1008 03:33:43.076261  5322 sgd_solver.cpp:105] Iteration 73800, lr = 0.01
I1008 03:34:07.696990  5322 solver.cpp:218] Iteration 73900 (4.06198 iter/s, 24.6185s/100 iters), loss = 0.00565074
I1008 03:34:07.697029  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00565077 (* 1 = 0.00565077 loss)
I1008 03:34:07.697038  5322 sgd_solver.cpp:105] Iteration 73900, lr = 0.01
I1008 03:34:31.504318  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:34:32.486577  5322 solver.cpp:330] Iteration 74000, Testing net (#0)
I1008 03:34:37.166090  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:34:37.337186  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9132
I1008 03:34:37.337213  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.348691 (* 1 = 0.348691 loss)
I1008 03:34:37.520637  5322 solver.cpp:218] Iteration 74000 (3.3533 iter/s, 29.8214s/100 iters), loss = 0.0088069
I1008 03:34:37.520670  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00880694 (* 1 = 0.00880694 loss)
I1008 03:34:37.520678  5322 sgd_solver.cpp:105] Iteration 74000, lr = 0.01
I1008 03:35:02.161839  5322 solver.cpp:218] Iteration 74100 (4.05862 iter/s, 24.6389s/100 iters), loss = 0.00752071
I1008 03:35:02.161901  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00752075 (* 1 = 0.00752075 loss)
I1008 03:35:02.161911  5322 sgd_solver.cpp:105] Iteration 74100, lr = 0.01
I1008 03:35:27.156252  5322 solver.cpp:218] Iteration 74200 (4.00155 iter/s, 24.9903s/100 iters), loss = 0.0173145
I1008 03:35:27.156287  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0173145 (* 1 = 0.0173145 loss)
I1008 03:35:27.156296  5322 sgd_solver.cpp:105] Iteration 74200, lr = 0.01
I1008 03:35:51.814148  5322 solver.cpp:218] Iteration 74300 (4.05621 iter/s, 24.6535s/100 iters), loss = 0.0310067
I1008 03:35:51.814231  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0310067 (* 1 = 0.0310067 loss)
I1008 03:35:51.814239  5322 sgd_solver.cpp:105] Iteration 74300, lr = 0.01
I1008 03:36:16.449004  5322 solver.cpp:218] Iteration 74400 (4.05992 iter/s, 24.631s/100 iters), loss = 0.00417589
I1008 03:36:16.449039  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00417594 (* 1 = 0.00417594 loss)
I1008 03:36:16.449048  5322 sgd_solver.cpp:105] Iteration 74400, lr = 0.01
I1008 03:36:40.242681  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:36:41.226902  5322 solver.cpp:330] Iteration 74500, Testing net (#0)
I1008 03:36:45.833252  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:36:45.987336  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9093
I1008 03:36:45.987365  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.369991 (* 1 = 0.369991 loss)
I1008 03:36:46.182632  5322 solver.cpp:218] Iteration 74500 (3.3637 iter/s, 29.7292s/100 iters), loss = 0.00834811
I1008 03:36:46.182667  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00834815 (* 1 = 0.00834815 loss)
I1008 03:36:46.182672  5322 sgd_solver.cpp:105] Iteration 74500, lr = 0.01
I1008 03:37:10.752879  5322 solver.cpp:218] Iteration 74600 (4.07034 iter/s, 24.568s/100 iters), loss = 0.013409
I1008 03:37:10.752957  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.013409 (* 1 = 0.013409 loss)
I1008 03:37:10.752965  5322 sgd_solver.cpp:105] Iteration 74600, lr = 0.01
I1008 03:37:35.804137  5322 solver.cpp:218] Iteration 74700 (3.99184 iter/s, 25.0511s/100 iters), loss = 0.0330213
I1008 03:37:35.804173  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0330213 (* 1 = 0.0330213 loss)
I1008 03:37:35.804181  5322 sgd_solver.cpp:105] Iteration 74700, lr = 0.01
I1008 03:38:00.425689  5322 solver.cpp:218] Iteration 74800 (4.06221 iter/s, 24.6171s/100 iters), loss = 0.0132308
I1008 03:38:00.425782  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0132309 (* 1 = 0.0132309 loss)
I1008 03:38:00.425799  5322 sgd_solver.cpp:105] Iteration 74800, lr = 0.01
I1008 03:38:25.071272  5322 solver.cpp:218] Iteration 74900 (4.05811 iter/s, 24.642s/100 iters), loss = 0.0309909
I1008 03:38:25.071310  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0309909 (* 1 = 0.0309909 loss)
I1008 03:38:25.071329  5322 sgd_solver.cpp:105] Iteration 74900, lr = 0.01
I1008 03:38:48.945883  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:38:49.932842  5322 solver.cpp:330] Iteration 75000, Testing net (#0)
I1008 03:38:54.549760  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:38:54.733115  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9103
I1008 03:38:54.733144  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.355202 (* 1 = 0.355202 loss)
I1008 03:38:54.889616  5322 solver.cpp:218] Iteration 75000 (3.35406 iter/s, 29.8146s/100 iters), loss = 0.00419349
I1008 03:38:54.889650  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00419352 (* 1 = 0.00419352 loss)
I1008 03:38:54.889657  5322 sgd_solver.cpp:105] Iteration 75000, lr = 0.01
I1008 03:39:19.600410  5322 solver.cpp:218] Iteration 75100 (4.04719 iter/s, 24.7085s/100 iters), loss = 0.0257435
I1008 03:39:19.600476  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0257435 (* 1 = 0.0257435 loss)
I1008 03:39:19.600486  5322 sgd_solver.cpp:105] Iteration 75100, lr = 0.01
I1008 03:39:44.645064  5322 solver.cpp:218] Iteration 75200 (3.99347 iter/s, 25.0409s/100 iters), loss = 0.0227586
I1008 03:39:44.645100  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0227587 (* 1 = 0.0227587 loss)
I1008 03:39:44.645108  5322 sgd_solver.cpp:105] Iteration 75200, lr = 0.01
I1008 03:40:09.304307  5322 solver.cpp:218] Iteration 75300 (4.05587 iter/s, 24.6556s/100 iters), loss = 0.00785183
I1008 03:40:09.304409  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00785188 (* 1 = 0.00785188 loss)
I1008 03:40:09.304417  5322 sgd_solver.cpp:105] Iteration 75300, lr = 0.01
I1008 03:40:33.958372  5322 solver.cpp:218] Iteration 75400 (4.05678 iter/s, 24.6501s/100 iters), loss = 0.0101316
I1008 03:40:33.958410  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0101317 (* 1 = 0.0101317 loss)
I1008 03:40:33.958416  5322 sgd_solver.cpp:105] Iteration 75400, lr = 0.01
I1008 03:40:57.829218  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:40:58.813930  5322 solver.cpp:330] Iteration 75500, Testing net (#0)
I1008 03:41:03.397619  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:41:03.580855  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9107
I1008 03:41:03.580883  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.348137 (* 1 = 0.348137 loss)
I1008 03:41:03.744061  5322 solver.cpp:218] Iteration 75500 (3.35776 iter/s, 29.7818s/100 iters), loss = 0.00842834
I1008 03:41:03.744094  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00842839 (* 1 = 0.00842839 loss)
I1008 03:41:03.744102  5322 sgd_solver.cpp:105] Iteration 75500, lr = 0.01
I1008 03:41:28.318167  5322 solver.cpp:218] Iteration 75600 (4.06971 iter/s, 24.5718s/100 iters), loss = 0.0100453
I1008 03:41:28.318253  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0100454 (* 1 = 0.0100454 loss)
I1008 03:41:28.318264  5322 sgd_solver.cpp:105] Iteration 75600, lr = 0.01
I1008 03:41:53.304450  5322 solver.cpp:218] Iteration 75700 (4.0029 iter/s, 24.9819s/100 iters), loss = 0.0121901
I1008 03:41:53.304486  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0121901 (* 1 = 0.0121901 loss)
I1008 03:41:53.304493  5322 sgd_solver.cpp:105] Iteration 75700, lr = 0.01
I1008 03:42:17.945842  5322 solver.cpp:218] Iteration 75800 (4.05894 iter/s, 24.637s/100 iters), loss = 0.0196518
I1008 03:42:17.945931  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0196518 (* 1 = 0.0196518 loss)
I1008 03:42:17.945966  5322 sgd_solver.cpp:105] Iteration 75800, lr = 0.01
I1008 03:42:42.606140  5322 solver.cpp:218] Iteration 75900 (4.05548 iter/s, 24.658s/100 iters), loss = 0.0116854
I1008 03:42:42.606180  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0116854 (* 1 = 0.0116854 loss)
I1008 03:42:42.606190  5322 sgd_solver.cpp:105] Iteration 75900, lr = 0.01
I1008 03:43:06.479709  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:43:07.463402  5322 solver.cpp:330] Iteration 76000, Testing net (#0)
I1008 03:43:12.035132  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:43:12.202061  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9104
I1008 03:43:12.202100  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.361706 (* 1 = 0.361706 loss)
I1008 03:43:12.376252  5322 solver.cpp:218] Iteration 76000 (3.35949 iter/s, 29.7664s/100 iters), loss = 0.00298991
I1008 03:43:12.376284  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00298997 (* 1 = 0.00298997 loss)
I1008 03:43:12.376291  5322 sgd_solver.cpp:105] Iteration 76000, lr = 0.01
I1008 03:43:36.980775  5322 solver.cpp:218] Iteration 76100 (4.06467 iter/s, 24.6022s/100 iters), loss = 0.014566
I1008 03:43:36.980867  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.014566 (* 1 = 0.014566 loss)
I1008 03:43:36.980875  5322 sgd_solver.cpp:105] Iteration 76100, lr = 0.01
I1008 03:44:02.018774  5322 solver.cpp:218] Iteration 76200 (3.99429 iter/s, 25.0358s/100 iters), loss = 0.0328038
I1008 03:44:02.018807  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0328039 (* 1 = 0.0328039 loss)
I1008 03:44:02.018815  5322 sgd_solver.cpp:105] Iteration 76200, lr = 0.01
I1008 03:44:26.686591  5322 solver.cpp:218] Iteration 76300 (4.05418 iter/s, 24.6659s/100 iters), loss = 0.0204043
I1008 03:44:26.686704  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0204044 (* 1 = 0.0204044 loss)
I1008 03:44:26.686713  5322 sgd_solver.cpp:105] Iteration 76300, lr = 0.01
I1008 03:44:51.331549  5322 solver.cpp:218] Iteration 76400 (4.0582 iter/s, 24.6415s/100 iters), loss = 0.010516
I1008 03:44:51.331596  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.010516 (* 1 = 0.010516 loss)
I1008 03:44:51.331604  5322 sgd_solver.cpp:105] Iteration 76400, lr = 0.01
I1008 03:45:15.224828  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:45:16.207454  5322 solver.cpp:330] Iteration 76500, Testing net (#0)
I1008 03:45:20.846009  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:45:21.035526  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.91
I1008 03:45:21.035562  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.343877 (* 1 = 0.343877 loss)
I1008 03:45:21.190600  5322 solver.cpp:218] Iteration 76500 (3.34957 iter/s, 29.8546s/100 iters), loss = 0.00273942
I1008 03:45:21.190642  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00273947 (* 1 = 0.00273947 loss)
I1008 03:45:21.190649  5322 sgd_solver.cpp:105] Iteration 76500, lr = 0.01
I1008 03:45:45.866794  5322 solver.cpp:218] Iteration 76600 (4.05286 iter/s, 24.6739s/100 iters), loss = 0.0073536
I1008 03:45:45.866888  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00735365 (* 1 = 0.00735365 loss)
I1008 03:45:45.866896  5322 sgd_solver.cpp:105] Iteration 76600, lr = 0.01
I1008 03:46:10.697443  5322 solver.cpp:218] Iteration 76700 (4.028 iter/s, 24.8262s/100 iters), loss = 0.0608232
I1008 03:46:10.697487  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0608232 (* 1 = 0.0608232 loss)
I1008 03:46:10.697495  5322 sgd_solver.cpp:105] Iteration 76700, lr = 0.01
I1008 03:46:35.464618  5322 solver.cpp:218] Iteration 76800 (4.03832 iter/s, 24.7627s/100 iters), loss = 0.00359175
I1008 03:46:35.464740  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00359178 (* 1 = 0.00359178 loss)
I1008 03:46:35.464751  5322 sgd_solver.cpp:105] Iteration 76800, lr = 0.01
I1008 03:47:00.009227  5322 solver.cpp:218] Iteration 76900 (4.07459 iter/s, 24.5424s/100 iters), loss = 0.016562
I1008 03:47:00.009260  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.016562 (* 1 = 0.016562 loss)
I1008 03:47:00.009268  5322 sgd_solver.cpp:105] Iteration 76900, lr = 0.01
I1008 03:47:23.877766  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:47:24.860478  5322 solver.cpp:330] Iteration 77000, Testing net (#0)
I1008 03:47:29.410895  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:47:29.626432  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9066
I1008 03:47:29.626461  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.371277 (* 1 = 0.371277 loss)
I1008 03:47:29.752302  5322 solver.cpp:218] Iteration 77000 (3.36256 iter/s, 29.7393s/100 iters), loss = 0.0255134
I1008 03:47:29.752337  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0255134 (* 1 = 0.0255134 loss)
I1008 03:47:29.752346  5322 sgd_solver.cpp:105] Iteration 77000, lr = 0.01
I1008 03:47:54.240936  5322 solver.cpp:218] Iteration 77100 (4.08355 iter/s, 24.4885s/100 iters), loss = 0.00769762
I1008 03:47:54.241087  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00769763 (* 1 = 0.00769763 loss)
I1008 03:47:54.241099  5322 sgd_solver.cpp:105] Iteration 77100, lr = 0.01
I1008 03:48:19.014574  5322 solver.cpp:218] Iteration 77200 (4.03692 iter/s, 24.7713s/100 iters), loss = 0.00437626
I1008 03:48:19.014606  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00437626 (* 1 = 0.00437626 loss)
I1008 03:48:19.014613  5322 sgd_solver.cpp:105] Iteration 77200, lr = 0.01
I1008 03:48:43.902678  5322 solver.cpp:218] Iteration 77300 (4.01835 iter/s, 24.8858s/100 iters), loss = 0.0162953
I1008 03:48:43.902779  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0162953 (* 1 = 0.0162953 loss)
I1008 03:48:43.902788  5322 sgd_solver.cpp:105] Iteration 77300, lr = 0.01
I1008 03:49:08.551592  5322 solver.cpp:218] Iteration 77400 (4.0576 iter/s, 24.6451s/100 iters), loss = 0.0288184
I1008 03:49:08.551626  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0288185 (* 1 = 0.0288185 loss)
I1008 03:49:08.551645  5322 sgd_solver.cpp:105] Iteration 77400, lr = 0.01
I1008 03:49:32.433892  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:49:33.420284  5322 solver.cpp:330] Iteration 77500, Testing net (#0)
I1008 03:49:37.924160  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:49:38.117396  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9087
I1008 03:49:38.117434  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.357245 (* 1 = 0.357245 loss)
I1008 03:49:38.275986  5322 solver.cpp:218] Iteration 77500 (3.3645 iter/s, 29.7221s/100 iters), loss = 0.0114036
I1008 03:49:38.276020  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0114036 (* 1 = 0.0114036 loss)
I1008 03:49:38.276036  5322 sgd_solver.cpp:105] Iteration 77500, lr = 0.01
I1008 03:50:02.917551  5322 solver.cpp:218] Iteration 77600 (4.05855 iter/s, 24.6393s/100 iters), loss = 0.0334125
I1008 03:50:02.917678  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0334125 (* 1 = 0.0334125 loss)
I1008 03:50:02.917696  5322 sgd_solver.cpp:105] Iteration 77600, lr = 0.01
I1008 03:50:27.579274  5322 solver.cpp:218] Iteration 77700 (4.05546 iter/s, 24.6581s/100 iters), loss = 0.0082437
I1008 03:50:27.579308  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0082437 (* 1 = 0.0082437 loss)
I1008 03:50:27.579314  5322 sgd_solver.cpp:105] Iteration 77700, lr = 0.01
I1008 03:50:52.517527  5322 solver.cpp:218] Iteration 77800 (4.01022 iter/s, 24.9363s/100 iters), loss = 0.0155792
I1008 03:50:52.517621  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0155792 (* 1 = 0.0155792 loss)
I1008 03:50:52.517632  5322 sgd_solver.cpp:105] Iteration 77800, lr = 0.01
I1008 03:51:17.165030  5322 solver.cpp:218] Iteration 77900 (4.05758 iter/s, 24.6453s/100 iters), loss = 0.0276431
I1008 03:51:17.165074  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0276431 (* 1 = 0.0276431 loss)
I1008 03:51:17.165081  5322 sgd_solver.cpp:105] Iteration 77900, lr = 0.01
I1008 03:51:40.969327  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:51:41.953960  5322 solver.cpp:330] Iteration 78000, Testing net (#0)
I1008 03:51:46.552192  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:51:46.733479  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9048
I1008 03:51:46.733506  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.376889 (* 1 = 0.376889 loss)
I1008 03:51:46.899348  5322 solver.cpp:218] Iteration 78000 (3.36354 iter/s, 29.7306s/100 iters), loss = 0.0405681
I1008 03:51:46.899390  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0405682 (* 1 = 0.0405682 loss)
I1008 03:51:46.899397  5322 sgd_solver.cpp:105] Iteration 78000, lr = 0.01
I1008 03:52:11.388568  5322 solver.cpp:218] Iteration 78100 (4.08381 iter/s, 24.4869s/100 iters), loss = 0.0109296
I1008 03:52:11.388654  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0109297 (* 1 = 0.0109297 loss)
I1008 03:52:11.388662  5322 sgd_solver.cpp:105] Iteration 78100, lr = 0.01
I1008 03:52:35.987283  5322 solver.cpp:218] Iteration 78200 (4.06598 iter/s, 24.5943s/100 iters), loss = 0.0266792
I1008 03:52:35.987323  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0266792 (* 1 = 0.0266792 loss)
I1008 03:52:35.987331  5322 sgd_solver.cpp:105] Iteration 78200, lr = 0.01
I1008 03:53:00.983800  5322 solver.cpp:218] Iteration 78300 (4.00117 iter/s, 24.9927s/100 iters), loss = 0.0421446
I1008 03:53:00.983913  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0421446 (* 1 = 0.0421446 loss)
I1008 03:53:00.983922  5322 sgd_solver.cpp:105] Iteration 78300, lr = 0.01
I1008 03:53:25.626956  5322 solver.cpp:218] Iteration 78400 (4.05864 iter/s, 24.6388s/100 iters), loss = 0.00749304
I1008 03:53:25.626991  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00749308 (* 1 = 0.00749308 loss)
I1008 03:53:25.626999  5322 sgd_solver.cpp:105] Iteration 78400, lr = 0.01
I1008 03:53:49.558856  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:53:50.542487  5322 solver.cpp:330] Iteration 78500, Testing net (#0)
I1008 03:53:55.129104  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:53:55.288914  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9108
I1008 03:53:55.288959  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.347874 (* 1 = 0.347874 loss)
I1008 03:53:55.477861  5322 solver.cpp:218] Iteration 78500 (3.35037 iter/s, 29.8475s/100 iters), loss = 0.00434163
I1008 03:53:55.477902  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00434167 (* 1 = 0.00434167 loss)
I1008 03:53:55.477910  5322 sgd_solver.cpp:105] Iteration 78500, lr = 0.01
I1008 03:54:20.038483  5322 solver.cpp:218] Iteration 78600 (4.07194 iter/s, 24.5583s/100 iters), loss = 0.0213941
I1008 03:54:20.038569  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0213942 (* 1 = 0.0213942 loss)
I1008 03:54:20.038578  5322 sgd_solver.cpp:105] Iteration 78600, lr = 0.01
I1008 03:54:44.683060  5322 solver.cpp:218] Iteration 78700 (4.05841 iter/s, 24.6402s/100 iters), loss = 0.0256533
I1008 03:54:44.683104  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0256534 (* 1 = 0.0256534 loss)
I1008 03:54:44.683110  5322 sgd_solver.cpp:105] Iteration 78700, lr = 0.01
I1008 03:55:09.767738  5322 solver.cpp:218] Iteration 78800 (3.9871 iter/s, 25.0809s/100 iters), loss = 0.00590098
I1008 03:55:09.767851  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00590102 (* 1 = 0.00590102 loss)
I1008 03:55:09.767864  5322 sgd_solver.cpp:105] Iteration 78800, lr = 0.01
I1008 03:55:34.424784  5322 solver.cpp:218] Iteration 78900 (4.05621 iter/s, 24.6536s/100 iters), loss = 0.00737299
I1008 03:55:34.424823  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00737303 (* 1 = 0.00737303 loss)
I1008 03:55:34.424842  5322 sgd_solver.cpp:105] Iteration 78900, lr = 0.01
I1008 03:55:58.300696  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:55:59.284896  5322 solver.cpp:330] Iteration 79000, Testing net (#0)
I1008 03:56:03.900130  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:56:04.090390  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9085
I1008 03:56:04.090420  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.383452 (* 1 = 0.383452 loss)
I1008 03:56:04.243527  5322 solver.cpp:218] Iteration 79000 (3.35401 iter/s, 29.8151s/100 iters), loss = 0.0316747
I1008 03:56:04.243582  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0316747 (* 1 = 0.0316747 loss)
I1008 03:56:04.243602  5322 sgd_solver.cpp:105] Iteration 79000, lr = 0.01
I1008 03:56:28.956930  5322 solver.cpp:218] Iteration 79100 (4.04641 iter/s, 24.7132s/100 iters), loss = 0.0106895
I1008 03:56:28.957007  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0106896 (* 1 = 0.0106896 loss)
I1008 03:56:28.957015  5322 sgd_solver.cpp:105] Iteration 79100, lr = 0.01
I1008 03:56:53.606147  5322 solver.cpp:218] Iteration 79200 (4.0573 iter/s, 24.6469s/100 iters), loss = 0.0288997
I1008 03:56:53.606181  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0288997 (* 1 = 0.0288997 loss)
I1008 03:56:53.606189  5322 sgd_solver.cpp:105] Iteration 79200, lr = 0.01
I1008 03:57:18.581425  5322 solver.cpp:218] Iteration 79300 (4.00433 iter/s, 24.973s/100 iters), loss = 0.0306307
I1008 03:57:18.581539  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0306307 (* 1 = 0.0306307 loss)
I1008 03:57:18.581549  5322 sgd_solver.cpp:105] Iteration 79300, lr = 0.01
I1008 03:57:43.192317  5322 solver.cpp:218] Iteration 79400 (4.06392 iter/s, 24.6068s/100 iters), loss = 0.00699227
I1008 03:57:43.192360  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0069923 (* 1 = 0.0069923 loss)
I1008 03:57:43.192366  5322 sgd_solver.cpp:105] Iteration 79400, lr = 0.01
I1008 03:58:06.985636  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:58:07.970537  5322 solver.cpp:330] Iteration 79500, Testing net (#0)
I1008 03:58:12.498543  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:58:12.682685  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9094
I1008 03:58:12.682713  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.369183 (* 1 = 0.369183 loss)
I1008 03:58:12.862260  5322 solver.cpp:218] Iteration 79500 (3.37087 iter/s, 29.6659s/100 iters), loss = 0.00644849
I1008 03:58:12.862301  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00644853 (* 1 = 0.00644853 loss)
I1008 03:58:12.862308  5322 sgd_solver.cpp:105] Iteration 79500, lr = 0.01
I1008 03:58:37.558940  5322 solver.cpp:218] Iteration 79600 (4.04915 iter/s, 24.6965s/100 iters), loss = 0.0128354
I1008 03:58:37.559036  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0128354 (* 1 = 0.0128354 loss)
I1008 03:58:37.559046  5322 sgd_solver.cpp:105] Iteration 79600, lr = 0.01
I1008 03:59:02.203073  5322 solver.cpp:218] Iteration 79700 (4.05849 iter/s, 24.6397s/100 iters), loss = 0.0133854
I1008 03:59:02.203106  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0133854 (* 1 = 0.0133854 loss)
I1008 03:59:02.203114  5322 sgd_solver.cpp:105] Iteration 79700, lr = 0.01
I1008 03:59:27.282256  5322 solver.cpp:218] Iteration 79800 (3.98806 iter/s, 25.0748s/100 iters), loss = 0.0119759
I1008 03:59:27.282361  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0119759 (* 1 = 0.0119759 loss)
I1008 03:59:27.282371  5322 sgd_solver.cpp:105] Iteration 79800, lr = 0.01
I1008 03:59:51.914769  5322 solver.cpp:218] Iteration 79900 (4.06027 iter/s, 24.6289s/100 iters), loss = 0.0231185
I1008 03:59:51.914803  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0231186 (* 1 = 0.0231186 loss)
I1008 03:59:51.914810  5322 sgd_solver.cpp:105] Iteration 79900, lr = 0.01
I1008 04:00:15.696897  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:00:16.681558  5322 solver.cpp:330] Iteration 80000, Testing net (#0)
I1008 04:00:21.328793  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:00:21.529037  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9115
I1008 04:00:21.529062  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.352559 (* 1 = 0.352559 loss)
I1008 04:00:21.674058  5322 solver.cpp:218] Iteration 80000 (3.36055 iter/s, 29.757s/100 iters), loss = 0.00406159
I1008 04:00:21.674100  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00406164 (* 1 = 0.00406164 loss)
I1008 04:00:21.674106  5322 sgd_solver.cpp:46] MultiStep Status: Iteration 80000, step = 2
I1008 04:00:21.674110  5322 sgd_solver.cpp:105] Iteration 80000, lr = 0.001
I1008 04:00:46.345561  5322 solver.cpp:218] Iteration 80100 (4.05364 iter/s, 24.6692s/100 iters), loss = 0.0194367
I1008 04:00:46.345631  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0194367 (* 1 = 0.0194367 loss)
I1008 04:00:46.345639  5322 sgd_solver.cpp:105] Iteration 80100, lr = 0.001
I1008 04:01:11.001294  5322 solver.cpp:218] Iteration 80200 (4.05657 iter/s, 24.6514s/100 iters), loss = 0.0276875
I1008 04:01:11.001327  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0276875 (* 1 = 0.0276875 loss)
I1008 04:01:11.001334  5322 sgd_solver.cpp:105] Iteration 80200, lr = 0.001
I1008 04:01:36.093780  5322 solver.cpp:218] Iteration 80300 (3.98595 iter/s, 25.0881s/100 iters), loss = 0.0115109
I1008 04:01:36.093891  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0115109 (* 1 = 0.0115109 loss)
I1008 04:01:36.093910  5322 sgd_solver.cpp:105] Iteration 80300, lr = 0.001
I1008 04:02:00.760321  5322 solver.cpp:218] Iteration 80400 (4.05469 iter/s, 24.6628s/100 iters), loss = 0.00562031
I1008 04:02:00.760356  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00562036 (* 1 = 0.00562036 loss)
I1008 04:02:00.760363  5322 sgd_solver.cpp:105] Iteration 80400, lr = 0.001
I1008 04:02:24.644973  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:02:25.629773  5322 solver.cpp:330] Iteration 80500, Testing net (#0)
I1008 04:02:30.187366  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:02:30.354889  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9187
I1008 04:02:30.354918  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.321446 (* 1 = 0.321446 loss)
I1008 04:02:30.544159  5322 solver.cpp:218] Iteration 80500 (3.35801 iter/s, 29.7795s/100 iters), loss = 0.00129001
I1008 04:02:30.544193  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00129005 (* 1 = 0.00129005 loss)
I1008 04:02:30.544198  5322 sgd_solver.cpp:105] Iteration 80500, lr = 0.001
I1008 04:02:55.235473  5322 solver.cpp:218] Iteration 80600 (4.05037 iter/s, 24.6891s/100 iters), loss = 0.0278935
I1008 04:02:55.235563  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0278935 (* 1 = 0.0278935 loss)
I1008 04:02:55.235570  5322 sgd_solver.cpp:105] Iteration 80600, lr = 0.001
I1008 04:03:19.882551  5322 solver.cpp:218] Iteration 80700 (4.05765 iter/s, 24.6448s/100 iters), loss = 0.00898487
I1008 04:03:19.882601  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00898491 (* 1 = 0.00898491 loss)
I1008 04:03:19.882609  5322 sgd_solver.cpp:105] Iteration 80700, lr = 0.001
I1008 04:03:44.965639  5322 solver.cpp:218] Iteration 80800 (3.9874 iter/s, 25.079s/100 iters), loss = 0.0107087
I1008 04:03:44.965734  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0107088 (* 1 = 0.0107088 loss)
I1008 04:03:44.965752  5322 sgd_solver.cpp:105] Iteration 80800, lr = 0.001
I1008 04:04:09.605340  5322 solver.cpp:218] Iteration 80900 (4.05909 iter/s, 24.636s/100 iters), loss = 0.00431535
I1008 04:04:09.605386  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0043154 (* 1 = 0.0043154 loss)
I1008 04:04:09.605393  5322 sgd_solver.cpp:105] Iteration 80900, lr = 0.001
I1008 04:04:33.399368  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:04:34.381037  5322 solver.cpp:330] Iteration 81000, Testing net (#0)
I1008 04:04:39.037153  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:04:39.248399  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9216
I1008 04:04:39.248425  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.316765 (* 1 = 0.316765 loss)
I1008 04:04:39.382863  5322 solver.cpp:218] Iteration 81000 (3.35874 iter/s, 29.7731s/100 iters), loss = 0.00573238
I1008 04:04:39.382899  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00573243 (* 1 = 0.00573243 loss)
I1008 04:04:39.382906  5322 sgd_solver.cpp:105] Iteration 81000, lr = 0.001
I1008 04:05:04.007942  5322 solver.cpp:218] Iteration 81100 (4.06127 iter/s, 24.6228s/100 iters), loss = 0.0241762
I1008 04:05:04.008008  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0241762 (* 1 = 0.0241762 loss)
I1008 04:05:04.008015  5322 sgd_solver.cpp:105] Iteration 81100, lr = 0.001
I1008 04:05:28.660277  5322 solver.cpp:218] Iteration 81200 (4.05709 iter/s, 24.6482s/100 iters), loss = 0.00997737
I1008 04:05:28.660313  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00997742 (* 1 = 0.00997742 loss)
I1008 04:05:28.660322  5322 sgd_solver.cpp:105] Iteration 81200, lr = 0.001
I1008 04:05:53.742822  5322 solver.cpp:218] Iteration 81300 (3.98743 iter/s, 25.0788s/100 iters), loss = 0.00671737
I1008 04:05:53.742941  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00671742 (* 1 = 0.00671742 loss)
I1008 04:05:53.742954  5322 sgd_solver.cpp:105] Iteration 81300, lr = 0.001
I1008 04:06:18.384366  5322 solver.cpp:218] Iteration 81400 (4.05891 iter/s, 24.6372s/100 iters), loss = 0.00805611
I1008 04:06:18.384418  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00805616 (* 1 = 0.00805616 loss)
I1008 04:06:18.384426  5322 sgd_solver.cpp:105] Iteration 81400, lr = 0.001
I1008 04:06:42.256916  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:06:43.240891  5322 solver.cpp:330] Iteration 81500, Testing net (#0)
I1008 04:06:47.852955  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:06:48.038089  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9216
I1008 04:06:48.038126  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.313134 (* 1 = 0.313134 loss)
I1008 04:06:48.200562  5322 solver.cpp:218] Iteration 81500 (3.35436 iter/s, 29.8119s/100 iters), loss = 0.00734485
I1008 04:06:48.200592  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0073449 (* 1 = 0.0073449 loss)
I1008 04:06:48.200599  5322 sgd_solver.cpp:105] Iteration 81500, lr = 0.001
I1008 04:07:12.799245  5322 solver.cpp:218] Iteration 81600 (4.06528 iter/s, 24.5985s/100 iters), loss = 0.00854446
I1008 04:07:12.799338  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00854451 (* 1 = 0.00854451 loss)
I1008 04:07:12.799356  5322 sgd_solver.cpp:105] Iteration 81600, lr = 0.001
I1008 04:07:37.480319  5322 solver.cpp:218] Iteration 81700 (4.0524 iter/s, 24.6767s/100 iters), loss = 0.00894678
I1008 04:07:37.480351  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00894683 (* 1 = 0.00894683 loss)
I1008 04:07:37.480360  5322 sgd_solver.cpp:105] Iteration 81700, lr = 0.001
I1008 04:08:02.583729  5322 solver.cpp:218] Iteration 81800 (3.98422 iter/s, 25.099s/100 iters), loss = 0.00555193
I1008 04:08:02.583815  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00555199 (* 1 = 0.00555199 loss)
I1008 04:08:02.583828  5322 sgd_solver.cpp:105] Iteration 81800, lr = 0.001
I1008 04:08:27.209205  5322 solver.cpp:218] Iteration 81900 (4.06121 iter/s, 24.6232s/100 iters), loss = 0.00631468
I1008 04:08:27.209251  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00631474 (* 1 = 0.00631474 loss)
I1008 04:08:27.209259  5322 sgd_solver.cpp:105] Iteration 81900, lr = 0.001
I1008 04:08:51.051654  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:08:52.034740  5322 solver.cpp:330] Iteration 82000, Testing net (#0)
I1008 04:08:56.594584  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:08:56.768247  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9219
I1008 04:08:56.768275  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.314512 (* 1 = 0.314512 loss)
I1008 04:08:56.934376  5322 solver.cpp:218] Iteration 82000 (3.36441 iter/s, 29.7229s/100 iters), loss = 0.00294668
I1008 04:08:56.934418  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00294674 (* 1 = 0.00294674 loss)
I1008 04:08:56.934425  5322 sgd_solver.cpp:105] Iteration 82000, lr = 0.001
I1008 04:09:21.556772  5322 solver.cpp:218] Iteration 82100 (4.06171 iter/s, 24.6201s/100 iters), loss = 0.00423408
I1008 04:09:21.556850  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00423414 (* 1 = 0.00423414 loss)
I1008 04:09:21.556859  5322 sgd_solver.cpp:105] Iteration 82100, lr = 0.001
I1008 04:09:46.210326  5322 solver.cpp:218] Iteration 82200 (4.05659 iter/s, 24.6513s/100 iters), loss = 0.00991791
I1008 04:09:46.210369  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00991797 (* 1 = 0.00991797 loss)
I1008 04:09:46.210378  5322 sgd_solver.cpp:105] Iteration 82200, lr = 0.001
I1008 04:10:11.293970  5322 solver.cpp:218] Iteration 82300 (3.98702 iter/s, 25.0814s/100 iters), loss = 0.00677835
I1008 04:10:11.294075  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00677841 (* 1 = 0.00677841 loss)
I1008 04:10:11.294086  5322 sgd_solver.cpp:105] Iteration 82300, lr = 0.001
I1008 04:10:35.883373  5322 solver.cpp:218] Iteration 82400 (4.06752 iter/s, 24.585s/100 iters), loss = 0.0130671
I1008 04:10:35.883407  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0130672 (* 1 = 0.0130672 loss)
I1008 04:10:35.883415  5322 sgd_solver.cpp:105] Iteration 82400, lr = 0.001
I1008 04:10:59.832027  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:11:00.818796  5322 solver.cpp:330] Iteration 82500, Testing net (#0)
I1008 04:11:05.410092  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:11:05.562397  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9207
I1008 04:11:05.562427  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.314081 (* 1 = 0.314081 loss)
I1008 04:11:05.765378  5322 solver.cpp:218] Iteration 82500 (3.34675 iter/s, 29.8798s/100 iters), loss = 0.00838006
I1008 04:11:05.765420  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00838013 (* 1 = 0.00838013 loss)
I1008 04:11:05.765444  5322 sgd_solver.cpp:105] Iteration 82500, lr = 0.001
I1008 04:11:30.404901  5322 solver.cpp:218] Iteration 82600 (4.0589 iter/s, 24.6372s/100 iters), loss = 0.00535381
I1008 04:11:30.405001  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00535388 (* 1 = 0.00535388 loss)
I1008 04:11:30.405014  5322 sgd_solver.cpp:105] Iteration 82600, lr = 0.001
I1008 04:11:54.986441  5322 solver.cpp:218] Iteration 82700 (4.06846 iter/s, 24.5793s/100 iters), loss = 0.0106857
I1008 04:11:54.986475  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0106858 (* 1 = 0.0106858 loss)
I1008 04:11:54.986484  5322 sgd_solver.cpp:105] Iteration 82700, lr = 0.001
I1008 04:12:20.023083  5322 solver.cpp:218] Iteration 82800 (3.99485 iter/s, 25.0323s/100 iters), loss = 0.00321635
I1008 04:12:20.023157  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00321641 (* 1 = 0.00321641 loss)
I1008 04:12:20.023171  5322 sgd_solver.cpp:105] Iteration 82800, lr = 0.001
I1008 04:12:44.675357  5322 solver.cpp:218] Iteration 82900 (4.05705 iter/s, 24.6485s/100 iters), loss = 0.00459524
I1008 04:12:44.675402  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0045953 (* 1 = 0.0045953 loss)
I1008 04:12:44.675410  5322 sgd_solver.cpp:105] Iteration 82900, lr = 0.001
I1008 04:13:08.554605  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:13:09.538915  5322 solver.cpp:330] Iteration 83000, Testing net (#0)
I1008 04:13:14.031123  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:13:14.246404  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9216
I1008 04:13:14.246443  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.312034 (* 1 = 0.312034 loss)
I1008 04:13:14.377540  5322 solver.cpp:218] Iteration 83000 (3.36717 iter/s, 29.6985s/100 iters), loss = 0.00355297
I1008 04:13:14.377583  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00355302 (* 1 = 0.00355302 loss)
I1008 04:13:14.377590  5322 sgd_solver.cpp:105] Iteration 83000, lr = 0.001
I1008 04:13:39.031641  5322 solver.cpp:218] Iteration 83100 (4.0565 iter/s, 24.6518s/100 iters), loss = 0.00424395
I1008 04:13:39.031731  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00424401 (* 1 = 0.00424401 loss)
I1008 04:13:39.031740  5322 sgd_solver.cpp:105] Iteration 83100, lr = 0.001
I1008 04:14:03.697324  5322 solver.cpp:218] Iteration 83200 (4.05483 iter/s, 24.662s/100 iters), loss = 0.00187408
I1008 04:14:03.697356  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00187413 (* 1 = 0.00187413 loss)
I1008 04:14:03.697363  5322 sgd_solver.cpp:105] Iteration 83200, lr = 0.001
I1008 04:14:28.793478  5322 solver.cpp:218] Iteration 83300 (3.98503 iter/s, 25.0939s/100 iters), loss = 0.00346985
I1008 04:14:28.793597  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00346991 (* 1 = 0.00346991 loss)
I1008 04:14:28.793606  5322 sgd_solver.cpp:105] Iteration 83300, lr = 0.001
I1008 04:14:53.450548  5322 solver.cpp:218] Iteration 83400 (4.05622 iter/s, 24.6535s/100 iters), loss = 0.00453354
I1008 04:14:53.450584  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0045336 (* 1 = 0.0045336 loss)
I1008 04:14:53.450592  5322 sgd_solver.cpp:105] Iteration 83400, lr = 0.001
I1008 04:15:17.314456  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:15:18.295343  5322 solver.cpp:330] Iteration 83500, Testing net (#0)
I1008 04:15:22.921573  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:15:23.090859  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9223
I1008 04:15:23.090884  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.314719 (* 1 = 0.314719 loss)
I1008 04:15:23.288827  5322 solver.cpp:218] Iteration 83500 (3.35165 iter/s, 29.836s/100 iters), loss = 0.0015374
I1008 04:15:23.288861  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00153746 (* 1 = 0.00153746 loss)
I1008 04:15:23.288878  5322 sgd_solver.cpp:105] Iteration 83500, lr = 0.001
I1008 04:15:47.976958  5322 solver.cpp:218] Iteration 83600 (4.05091 iter/s, 24.6858s/100 iters), loss = 0.00265877
I1008 04:15:47.977041  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00265883 (* 1 = 0.00265883 loss)
I1008 04:15:47.977049  5322 sgd_solver.cpp:105] Iteration 83600, lr = 0.001
I1008 04:16:12.641333  5322 solver.cpp:218] Iteration 83700 (4.05515 iter/s, 24.66s/100 iters), loss = 0.0050779
I1008 04:16:12.641369  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00507796 (* 1 = 0.00507796 loss)
I1008 04:16:12.641376  5322 sgd_solver.cpp:105] Iteration 83700, lr = 0.001
I1008 04:16:37.661496  5322 solver.cpp:218] Iteration 83800 (3.99747 iter/s, 25.0158s/100 iters), loss = 0.00727832
I1008 04:16:37.661576  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00727838 (* 1 = 0.00727838 loss)
I1008 04:16:37.661586  5322 sgd_solver.cpp:105] Iteration 83800, lr = 0.001
I1008 04:17:02.281960  5322 solver.cpp:218] Iteration 83900 (4.06204 iter/s, 24.6182s/100 iters), loss = 0.00381808
I1008 04:17:02.282006  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00381814 (* 1 = 0.00381814 loss)
I1008 04:17:02.282016  5322 sgd_solver.cpp:105] Iteration 83900, lr = 0.001
I1008 04:17:26.025606  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:17:27.007835  5322 solver.cpp:330] Iteration 84000, Testing net (#0)
I1008 04:17:31.533991  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:17:31.718022  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9221
I1008 04:17:31.718049  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.314119 (* 1 = 0.314119 loss)
I1008 04:17:31.897191  5322 solver.cpp:218] Iteration 84000 (3.3769 iter/s, 29.6129s/100 iters), loss = 0.00261065
I1008 04:17:31.897222  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00261071 (* 1 = 0.00261071 loss)
I1008 04:17:31.897229  5322 sgd_solver.cpp:105] Iteration 84000, lr = 0.001
I1008 04:17:56.518666  5322 solver.cpp:218] Iteration 84100 (4.06167 iter/s, 24.6204s/100 iters), loss = 0.0033363
I1008 04:17:56.518746  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00333637 (* 1 = 0.00333637 loss)
I1008 04:17:56.518755  5322 sgd_solver.cpp:105] Iteration 84100, lr = 0.001
I1008 04:18:21.178640  5322 solver.cpp:218] Iteration 84200 (4.05587 iter/s, 24.6556s/100 iters), loss = 0.00194471
I1008 04:18:21.178678  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00194478 (* 1 = 0.00194478 loss)
I1008 04:18:21.178699  5322 sgd_solver.cpp:105] Iteration 84200, lr = 0.001
I1008 04:18:46.267159  5322 solver.cpp:218] Iteration 84300 (3.98646 iter/s, 25.0849s/100 iters), loss = 0.00219433
I1008 04:18:46.267266  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00219439 (* 1 = 0.00219439 loss)
I1008 04:18:46.267277  5322 sgd_solver.cpp:105] Iteration 84300, lr = 0.001
I1008 04:19:10.929832  5322 solver.cpp:218] Iteration 84400 (4.05509 iter/s, 24.6604s/100 iters), loss = 0.00343281
I1008 04:19:10.929867  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00343288 (* 1 = 0.00343288 loss)
I1008 04:19:10.929877  5322 sgd_solver.cpp:105] Iteration 84400, lr = 0.001
I1008 04:19:34.731902  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:19:35.718425  5322 solver.cpp:330] Iteration 84500, Testing net (#0)
I1008 04:19:40.240401  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:19:40.426000  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9224
I1008 04:19:40.426031  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.315022 (* 1 = 0.315022 loss)
I1008 04:19:40.603338  5322 solver.cpp:218] Iteration 84500 (3.37027 iter/s, 29.6712s/100 iters), loss = 0.00341913
I1008 04:19:40.603369  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0034192 (* 1 = 0.0034192 loss)
I1008 04:19:40.603376  5322 sgd_solver.cpp:105] Iteration 84500, lr = 0.001
I1008 04:20:05.332154  5322 solver.cpp:218] Iteration 84600 (4.04389 iter/s, 24.7287s/100 iters), loss = 0.0138364
I1008 04:20:05.332242  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0138364 (* 1 = 0.0138364 loss)
I1008 04:20:05.332250  5322 sgd_solver.cpp:105] Iteration 84600, lr = 0.001
I1008 04:20:30.006973  5322 solver.cpp:218] Iteration 84700 (4.05309 iter/s, 24.6726s/100 iters), loss = 0.00622779
I1008 04:20:30.007004  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00622785 (* 1 = 0.00622785 loss)
I1008 04:20:30.007011  5322 sgd_solver.cpp:105] Iteration 84700, lr = 0.001
I1008 04:20:55.111011  5322 solver.cpp:218] Iteration 84800 (3.98378 iter/s, 25.1018s/100 iters), loss = 0.00380045
I1008 04:20:55.111091  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00380051 (* 1 = 0.00380051 loss)
I1008 04:20:55.111099  5322 sgd_solver.cpp:105] Iteration 84800, lr = 0.001
I1008 04:21:19.727763  5322 solver.cpp:218] Iteration 84900 (4.06301 iter/s, 24.6123s/100 iters), loss = 0.00318391
I1008 04:21:19.727799  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00318398 (* 1 = 0.00318398 loss)
I1008 04:21:19.727807  5322 sgd_solver.cpp:105] Iteration 84900, lr = 0.001
I1008 04:21:43.542405  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:21:44.524089  5322 solver.cpp:330] Iteration 85000, Testing net (#0)
I1008 04:21:49.122601  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:21:49.285409  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9216
I1008 04:21:49.285444  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.314183 (* 1 = 0.314183 loss)
I1008 04:21:49.474436  5322 solver.cpp:218] Iteration 85000 (3.36221 iter/s, 29.7423s/100 iters), loss = 0.00253518
I1008 04:21:49.474468  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00253525 (* 1 = 0.00253525 loss)
I1008 04:21:49.474474  5322 sgd_solver.cpp:105] Iteration 85000, lr = 0.001
I1008 04:22:14.004397  5322 solver.cpp:218] Iteration 85100 (4.07702 iter/s, 24.5277s/100 iters), loss = 0.00199635
I1008 04:22:14.004473  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00199641 (* 1 = 0.00199641 loss)
I1008 04:22:14.004482  5322 sgd_solver.cpp:105] Iteration 85100, lr = 0.001
I1008 04:22:38.649369  5322 solver.cpp:218] Iteration 85200 (4.05834 iter/s, 24.6406s/100 iters), loss = 0.00357029
I1008 04:22:38.649405  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00357036 (* 1 = 0.00357036 loss)
I1008 04:22:38.649411  5322 sgd_solver.cpp:105] Iteration 85200, lr = 0.001
I1008 04:23:03.719849  5322 solver.cpp:218] Iteration 85300 (3.98936 iter/s, 25.0667s/100 iters), loss = 0.00300303
I1008 04:23:03.719956  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00300309 (* 1 = 0.00300309 loss)
I1008 04:23:03.719969  5322 sgd_solver.cpp:105] Iteration 85300, lr = 0.001
I1008 04:23:28.356052  5322 solver.cpp:218] Iteration 85400 (4.05979 iter/s, 24.6318s/100 iters), loss = 0.00288968
I1008 04:23:28.356091  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00288975 (* 1 = 0.00288975 loss)
I1008 04:23:28.356098  5322 sgd_solver.cpp:105] Iteration 85400, lr = 0.001
I1008 04:23:52.130571  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:23:53.114537  5322 solver.cpp:330] Iteration 85500, Testing net (#0)
I1008 04:23:57.672853  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:23:57.844354  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9232
I1008 04:23:57.844380  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.315762 (* 1 = 0.315762 loss)
I1008 04:23:58.019841  5322 solver.cpp:218] Iteration 85500 (3.37162 iter/s, 29.6593s/100 iters), loss = 0.00899295
I1008 04:23:58.019875  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00899303 (* 1 = 0.00899303 loss)
I1008 04:23:58.019882  5322 sgd_solver.cpp:105] Iteration 85500, lr = 0.001
I1008 04:24:22.615622  5322 solver.cpp:218] Iteration 85600 (4.06612 iter/s, 24.5935s/100 iters), loss = 0.0030967
I1008 04:24:22.615700  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00309677 (* 1 = 0.00309677 loss)
I1008 04:24:22.615707  5322 sgd_solver.cpp:105] Iteration 85600, lr = 0.001
I1008 04:24:47.257318  5322 solver.cpp:218] Iteration 85700 (4.05853 iter/s, 24.6394s/100 iters), loss = 0.00874007
I1008 04:24:47.257356  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00874015 (* 1 = 0.00874015 loss)
I1008 04:24:47.257366  5322 sgd_solver.cpp:105] Iteration 85700, lr = 0.001
I1008 04:25:12.338121  5322 solver.cpp:218] Iteration 85800 (3.98781 iter/s, 25.0764s/100 iters), loss = 0.00379859
I1008 04:25:12.338228  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00379867 (* 1 = 0.00379867 loss)
I1008 04:25:12.338238  5322 sgd_solver.cpp:105] Iteration 85800, lr = 0.001
I1008 04:25:36.978370  5322 solver.cpp:218] Iteration 85900 (4.05904 iter/s, 24.6364s/100 iters), loss = 0.00238172
I1008 04:25:36.978417  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0023818 (* 1 = 0.0023818 loss)
I1008 04:25:36.978425  5322 sgd_solver.cpp:105] Iteration 85900, lr = 0.001
I1008 04:26:00.767261  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:26:01.754606  5322 solver.cpp:330] Iteration 86000, Testing net (#0)
I1008 04:26:06.315057  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:26:06.484802  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9227
I1008 04:26:06.484827  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.317484 (* 1 = 0.317484 loss)
I1008 04:26:06.666939  5322 solver.cpp:218] Iteration 86000 (3.36872 iter/s, 29.6849s/100 iters), loss = 0.00346026
I1008 04:26:06.666971  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00346034 (* 1 = 0.00346034 loss)
I1008 04:26:06.666978  5322 sgd_solver.cpp:105] Iteration 86000, lr = 0.001
I1008 04:26:31.250068  5322 solver.cpp:218] Iteration 86100 (4.0682 iter/s, 24.5809s/100 iters), loss = 0.00472013
I1008 04:26:31.250174  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00472021 (* 1 = 0.00472021 loss)
I1008 04:26:31.250183  5322 sgd_solver.cpp:105] Iteration 86100, lr = 0.001
I1008 04:26:55.879940  5322 solver.cpp:218] Iteration 86200 (4.06072 iter/s, 24.6261s/100 iters), loss = 0.00252276
I1008 04:26:55.879976  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00252285 (* 1 = 0.00252285 loss)
I1008 04:26:55.879983  5322 sgd_solver.cpp:105] Iteration 86200, lr = 0.001
I1008 04:27:20.944124  5322 solver.cpp:218] Iteration 86300 (3.99046 iter/s, 25.0598s/100 iters), loss = 0.00199579
I1008 04:27:20.944252  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00199587 (* 1 = 0.00199587 loss)
I1008 04:27:20.944265  5322 sgd_solver.cpp:105] Iteration 86300, lr = 0.001
I1008 04:27:45.567551  5322 solver.cpp:218] Iteration 86400 (4.0619 iter/s, 24.619s/100 iters), loss = 0.0015591
I1008 04:27:45.567589  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00155918 (* 1 = 0.00155918 loss)
I1008 04:27:45.567596  5322 sgd_solver.cpp:105] Iteration 86400, lr = 0.001
I1008 04:28:09.372437  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:28:10.356705  5322 solver.cpp:330] Iteration 86500, Testing net (#0)
I1008 04:28:15.018548  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:28:15.206575  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9231
I1008 04:28:15.206601  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.316425 (* 1 = 0.316425 loss)
I1008 04:28:15.378360  5322 solver.cpp:218] Iteration 86500 (3.35498 iter/s, 29.8065s/100 iters), loss = 0.00489806
I1008 04:28:15.378393  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00489814 (* 1 = 0.00489814 loss)
I1008 04:28:15.378401  5322 sgd_solver.cpp:105] Iteration 86500, lr = 0.001
I1008 04:28:40.034735  5322 solver.cpp:218] Iteration 86600 (4.05612 iter/s, 24.6541s/100 iters), loss = 0.005319
I1008 04:28:40.034844  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00531908 (* 1 = 0.00531908 loss)
I1008 04:28:40.034853  5322 sgd_solver.cpp:105] Iteration 86600, lr = 0.001
I1008 04:29:04.695951  5322 solver.cpp:218] Iteration 86700 (4.05554 iter/s, 24.6577s/100 iters), loss = 0.00815446
I1008 04:29:04.695996  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00815455 (* 1 = 0.00815455 loss)
I1008 04:29:04.696003  5322 sgd_solver.cpp:105] Iteration 86700, lr = 0.001
I1008 04:29:29.616518  5322 solver.cpp:218] Iteration 86800 (4.01335 iter/s, 24.9168s/100 iters), loss = 0.00454952
I1008 04:29:29.616614  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00454961 (* 1 = 0.00454961 loss)
I1008 04:29:29.616626  5322 sgd_solver.cpp:105] Iteration 86800, lr = 0.001
I1008 04:29:54.192458  5322 solver.cpp:218] Iteration 86900 (4.06969 iter/s, 24.5719s/100 iters), loss = 0.00333598
I1008 04:29:54.192512  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00333607 (* 1 = 0.00333607 loss)
I1008 04:29:54.192520  5322 sgd_solver.cpp:105] Iteration 86900, lr = 0.001
I1008 04:30:18.064113  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:30:19.046542  5322 solver.cpp:330] Iteration 87000, Testing net (#0)
I1008 04:30:23.594466  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:30:23.784237  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9221
I1008 04:30:23.784265  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.316078 (* 1 = 0.316078 loss)
I1008 04:30:23.933331  5322 solver.cpp:218] Iteration 87000 (3.36282 iter/s, 29.7369s/100 iters), loss = 0.00784023
I1008 04:30:23.933362  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00784032 (* 1 = 0.00784032 loss)
I1008 04:30:23.933369  5322 sgd_solver.cpp:105] Iteration 87000, lr = 0.001
I1008 04:30:48.495733  5322 solver.cpp:218] Iteration 87100 (4.07129 iter/s, 24.5623s/100 iters), loss = 0.00376443
I1008 04:30:48.495805  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00376452 (* 1 = 0.00376452 loss)
I1008 04:30:48.495817  5322 sgd_solver.cpp:105] Iteration 87100, lr = 0.001
I1008 04:31:13.197639  5322 solver.cpp:218] Iteration 87200 (4.04899 iter/s, 24.6975s/100 iters), loss = 0.00402479
I1008 04:31:13.197676  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00402488 (* 1 = 0.00402488 loss)
I1008 04:31:13.197685  5322 sgd_solver.cpp:105] Iteration 87200, lr = 0.001
I1008 04:31:38.290016  5322 solver.cpp:218] Iteration 87300 (3.98564 iter/s, 25.0901s/100 iters), loss = 0.00416424
I1008 04:31:38.290153  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00416433 (* 1 = 0.00416433 loss)
I1008 04:31:38.290168  5322 sgd_solver.cpp:105] Iteration 87300, lr = 0.001
I1008 04:32:02.935214  5322 solver.cpp:218] Iteration 87400 (4.05796 iter/s, 24.6429s/100 iters), loss = 0.00609365
I1008 04:32:02.935245  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00609374 (* 1 = 0.00609374 loss)
I1008 04:32:02.935255  5322 sgd_solver.cpp:105] Iteration 87400, lr = 0.001
I1008 04:32:26.742760  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:32:27.728472  5322 solver.cpp:330] Iteration 87500, Testing net (#0)
I1008 04:32:32.256829  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:32:32.443307  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9215
I1008 04:32:32.443333  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.317216 (* 1 = 0.317216 loss)
I1008 04:32:32.623114  5322 solver.cpp:218] Iteration 87500 (3.36882 iter/s, 29.684s/100 iters), loss = 0.00524418
I1008 04:32:32.623147  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00524427 (* 1 = 0.00524427 loss)
I1008 04:32:32.623153  5322 sgd_solver.cpp:105] Iteration 87500, lr = 0.001
I1008 04:32:57.302987  5322 solver.cpp:218] Iteration 87600 (4.05191 iter/s, 24.6797s/100 iters), loss = 0.00261855
I1008 04:32:57.303081  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00261864 (* 1 = 0.00261864 loss)
I1008 04:32:57.303094  5322 sgd_solver.cpp:105] Iteration 87600, lr = 0.001
I1008 04:33:21.912389  5322 solver.cpp:218] Iteration 87700 (4.0641 iter/s, 24.6057s/100 iters), loss = 0.00670221
I1008 04:33:21.912428  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0067023 (* 1 = 0.0067023 loss)
I1008 04:33:21.912438  5322 sgd_solver.cpp:105] Iteration 87700, lr = 0.001
I1008 04:33:46.984242  5322 solver.cpp:218] Iteration 87800 (3.98925 iter/s, 25.0673s/100 iters), loss = 0.00275573
I1008 04:33:46.984318  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00275582 (* 1 = 0.00275582 loss)
I1008 04:33:46.984328  5322 sgd_solver.cpp:105] Iteration 87800, lr = 0.001
I1008 04:34:11.623404  5322 solver.cpp:218] Iteration 87900 (4.0593 iter/s, 24.6348s/100 iters), loss = 0.00373361
I1008 04:34:11.623437  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00373371 (* 1 = 0.00373371 loss)
I1008 04:34:11.623445  5322 sgd_solver.cpp:105] Iteration 87900, lr = 0.001
I1008 04:34:35.420145  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:34:36.403626  5322 solver.cpp:330] Iteration 88000, Testing net (#0)
I1008 04:34:40.893795  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:34:41.109237  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9218
I1008 04:34:41.109263  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.314935 (* 1 = 0.314935 loss)
I1008 04:34:41.240574  5322 solver.cpp:218] Iteration 88000 (3.37692 iter/s, 29.6128s/100 iters), loss = 0.00177587
I1008 04:34:41.240610  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00177596 (* 1 = 0.00177596 loss)
I1008 04:34:41.240619  5322 sgd_solver.cpp:105] Iteration 88000, lr = 0.001
I1008 04:35:05.891978  5322 solver.cpp:218] Iteration 88100 (4.05695 iter/s, 24.6491s/100 iters), loss = 0.00367131
I1008 04:35:05.892060  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0036714 (* 1 = 0.0036714 loss)
I1008 04:35:05.892069  5322 sgd_solver.cpp:105] Iteration 88100, lr = 0.001
I1008 04:35:30.550658  5322 solver.cpp:218] Iteration 88200 (4.05608 iter/s, 24.6543s/100 iters), loss = 0.00260728
I1008 04:35:30.550694  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00260737 (* 1 = 0.00260737 loss)
I1008 04:35:30.550701  5322 sgd_solver.cpp:105] Iteration 88200, lr = 0.001
I1008 04:35:55.615962  5322 solver.cpp:218] Iteration 88300 (3.99017 iter/s, 25.0616s/100 iters), loss = 0.0014645
I1008 04:35:55.616029  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00146459 (* 1 = 0.00146459 loss)
I1008 04:35:55.616037  5322 sgd_solver.cpp:105] Iteration 88300, lr = 0.001
I1008 04:36:20.287870  5322 solver.cpp:218] Iteration 88400 (4.05391 iter/s, 24.6675s/100 iters), loss = 0.007124
I1008 04:36:20.287909  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0071241 (* 1 = 0.0071241 loss)
I1008 04:36:20.287915  5322 sgd_solver.cpp:105] Iteration 88400, lr = 0.001
I1008 04:36:44.078857  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:36:45.061614  5322 solver.cpp:330] Iteration 88500, Testing net (#0)
I1008 04:36:49.598984  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:36:49.789400  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9224
I1008 04:36:49.789427  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.314788 (* 1 = 0.314788 loss)
I1008 04:36:49.955181  5322 solver.cpp:218] Iteration 88500 (3.37115 iter/s, 29.6634s/100 iters), loss = 0.00882101
I1008 04:36:49.955214  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0088211 (* 1 = 0.0088211 loss)
I1008 04:36:49.955221  5322 sgd_solver.cpp:105] Iteration 88500, lr = 0.001
I1008 04:37:14.558135  5322 solver.cpp:218] Iteration 88600 (4.06492 iter/s, 24.6007s/100 iters), loss = 0.00204622
I1008 04:37:14.558224  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00204631 (* 1 = 0.00204631 loss)
I1008 04:37:14.558233  5322 sgd_solver.cpp:105] Iteration 88600, lr = 0.001
I1008 04:37:39.181340  5322 solver.cpp:218] Iteration 88700 (4.06176 iter/s, 24.6199s/100 iters), loss = 0.00455881
I1008 04:37:39.181370  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0045589 (* 1 = 0.0045589 loss)
I1008 04:37:39.181377  5322 sgd_solver.cpp:105] Iteration 88700, lr = 0.001
I1008 04:38:04.072882  5322 solver.cpp:218] Iteration 88800 (4.01802 iter/s, 24.8879s/100 iters), loss = 0.00275601
I1008 04:38:04.072969  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0027561 (* 1 = 0.0027561 loss)
I1008 04:38:04.072978  5322 sgd_solver.cpp:105] Iteration 88800, lr = 0.001
I1008 04:38:28.867794  5322 solver.cpp:218] Iteration 88900 (4.03381 iter/s, 24.7905s/100 iters), loss = 0.00187203
I1008 04:38:28.867830  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00187211 (* 1 = 0.00187211 loss)
I1008 04:38:28.867836  5322 sgd_solver.cpp:105] Iteration 88900, lr = 0.001
I1008 04:38:52.719203  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:38:53.702249  5322 solver.cpp:330] Iteration 89000, Testing net (#0)
I1008 04:38:58.271008  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:38:58.432188  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9216
I1008 04:38:58.432217  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.313295 (* 1 = 0.313295 loss)
I1008 04:38:58.603560  5322 solver.cpp:218] Iteration 89000 (3.36343 iter/s, 29.7315s/100 iters), loss = 0.00445048
I1008 04:38:58.603592  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00445057 (* 1 = 0.00445057 loss)
I1008 04:38:58.603600  5322 sgd_solver.cpp:105] Iteration 89000, lr = 0.001
I1008 04:39:23.193660  5322 solver.cpp:218] Iteration 89100 (4.06706 iter/s, 24.5878s/100 iters), loss = 0.00189199
I1008 04:39:23.193742  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00189208 (* 1 = 0.00189208 loss)
I1008 04:39:23.193750  5322 sgd_solver.cpp:105] Iteration 89100, lr = 0.001
I1008 04:39:47.850195  5322 solver.cpp:218] Iteration 89200 (4.05627 iter/s, 24.6532s/100 iters), loss = 0.00469526
I1008 04:39:47.850235  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00469535 (* 1 = 0.00469535 loss)
I1008 04:39:47.850255  5322 sgd_solver.cpp:105] Iteration 89200, lr = 0.001
I1008 04:40:12.681784  5322 solver.cpp:218] Iteration 89300 (4.02749 iter/s, 24.8293s/100 iters), loss = 0.00683264
I1008 04:40:12.681866  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00683272 (* 1 = 0.00683272 loss)
I1008 04:40:12.681879  5322 sgd_solver.cpp:105] Iteration 89300, lr = 0.001
I1008 04:40:37.564904  5322 solver.cpp:218] Iteration 89400 (4.01907 iter/s, 24.8814s/100 iters), loss = 0.00163751
I1008 04:40:37.564942  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0016376 (* 1 = 0.0016376 loss)
I1008 04:40:37.564952  5322 sgd_solver.cpp:105] Iteration 89400, lr = 0.001
I1008 04:41:01.421141  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:41:02.404213  5322 solver.cpp:330] Iteration 89500, Testing net (#0)
I1008 04:41:06.933873  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:41:07.123001  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9213
I1008 04:41:07.123028  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.314762 (* 1 = 0.314762 loss)
I1008 04:41:07.280915  5322 solver.cpp:218] Iteration 89500 (3.36559 iter/s, 29.7125s/100 iters), loss = 0.00173057
I1008 04:41:07.280958  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00173066 (* 1 = 0.00173066 loss)
I1008 04:41:07.280966  5322 sgd_solver.cpp:105] Iteration 89500, lr = 0.001
I1008 04:41:31.916121  5322 solver.cpp:218] Iteration 89600 (4.05925 iter/s, 24.6351s/100 iters), loss = 0.00439227
I1008 04:41:31.916210  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00439236 (* 1 = 0.00439236 loss)
I1008 04:41:31.916218  5322 sgd_solver.cpp:105] Iteration 89600, lr = 0.001
I1008 04:41:56.558823  5322 solver.cpp:218] Iteration 89700 (4.05837 iter/s, 24.6405s/100 iters), loss = 0.00220495
I1008 04:41:56.558856  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00220504 (* 1 = 0.00220504 loss)
I1008 04:41:56.558862  5322 sgd_solver.cpp:105] Iteration 89700, lr = 0.001
I1008 04:42:21.284099  5322 solver.cpp:218] Iteration 89800 (4.04481 iter/s, 24.723s/100 iters), loss = 0.00386214
I1008 04:42:21.284199  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00386223 (* 1 = 0.00386223 loss)
I1008 04:42:21.284209  5322 sgd_solver.cpp:105] Iteration 89800, lr = 0.001
I1008 04:42:46.196813  5322 solver.cpp:218] Iteration 89900 (4.01438 iter/s, 24.9105s/100 iters), loss = 0.00335687
I1008 04:42:46.196854  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00335695 (* 1 = 0.00335695 loss)
I1008 04:42:46.196861  5322 sgd_solver.cpp:105] Iteration 89900, lr = 0.001
I1008 04:43:09.999920  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:43:10.983115  5322 solver.cpp:330] Iteration 90000, Testing net (#0)
I1008 04:43:15.535325  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:43:15.717823  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9231
I1008 04:43:15.717849  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.314692 (* 1 = 0.314692 loss)
I1008 04:43:15.879233  5322 solver.cpp:218] Iteration 90000 (3.36925 iter/s, 29.6802s/100 iters), loss = 0.00137306
I1008 04:43:15.879277  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00137315 (* 1 = 0.00137315 loss)
I1008 04:43:15.879286  5322 sgd_solver.cpp:105] Iteration 90000, lr = 0.001
I1008 04:43:40.440341  5322 solver.cpp:218] Iteration 90100 (4.07185 iter/s, 24.5589s/100 iters), loss = 0.00367675
I1008 04:43:40.440405  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00367684 (* 1 = 0.00367684 loss)
I1008 04:43:40.440413  5322 sgd_solver.cpp:105] Iteration 90100, lr = 0.001
I1008 04:44:05.059617  5322 solver.cpp:218] Iteration 90200 (4.06188 iter/s, 24.6191s/100 iters), loss = 0.00650789
I1008 04:44:05.059653  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00650797 (* 1 = 0.00650797 loss)
I1008 04:44:05.059659  5322 sgd_solver.cpp:105] Iteration 90200, lr = 0.001
I1008 04:44:29.696036  5322 solver.cpp:218] Iteration 90300 (4.0594 iter/s, 24.6342s/100 iters), loss = 0.00378424
I1008 04:44:29.696156  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00378432 (* 1 = 0.00378432 loss)
I1008 04:44:29.696178  5322 sgd_solver.cpp:105] Iteration 90300, lr = 0.001
I1008 04:44:54.685941  5322 solver.cpp:218] Iteration 90400 (4.00175 iter/s, 24.9891s/100 iters), loss = 0.00362795
I1008 04:44:54.685974  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00362803 (* 1 = 0.00362803 loss)
I1008 04:44:54.685993  5322 sgd_solver.cpp:105] Iteration 90400, lr = 0.001
I1008 04:45:18.484531  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:45:19.467408  5322 solver.cpp:330] Iteration 90500, Testing net (#0)
I1008 04:45:24.131613  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:45:24.317389  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9218
I1008 04:45:24.317415  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.314026 (* 1 = 0.314026 loss)
I1008 04:45:24.493218  5322 solver.cpp:218] Iteration 90500 (3.35514 iter/s, 29.805s/100 iters), loss = 0.000912639
I1008 04:45:24.493249  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000912719 (* 1 = 0.000912719 loss)
I1008 04:45:24.493257  5322 sgd_solver.cpp:105] Iteration 90500, lr = 0.001
I1008 04:45:49.129994  5322 solver.cpp:218] Iteration 90600 (4.05934 iter/s, 24.6345s/100 iters), loss = 0.00411152
I1008 04:45:49.130077  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0041116 (* 1 = 0.0041116 loss)
I1008 04:45:49.130086  5322 sgd_solver.cpp:105] Iteration 90600, lr = 0.001
I1008 04:46:13.770100  5322 solver.cpp:218] Iteration 90700 (4.05914 iter/s, 24.6357s/100 iters), loss = 0.00607729
I1008 04:46:13.770143  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00607736 (* 1 = 0.00607736 loss)
I1008 04:46:13.770150  5322 sgd_solver.cpp:105] Iteration 90700, lr = 0.001
I1008 04:46:38.440270  5322 solver.cpp:218] Iteration 90800 (4.05385 iter/s, 24.6679s/100 iters), loss = 0.0119743
I1008 04:46:38.440363  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0119744 (* 1 = 0.0119744 loss)
I1008 04:46:38.440373  5322 sgd_solver.cpp:105] Iteration 90800, lr = 0.001
I1008 04:47:03.522037  5322 solver.cpp:218] Iteration 90900 (3.9876 iter/s, 25.0777s/100 iters), loss = 0.00439019
I1008 04:47:03.522073  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00439026 (* 1 = 0.00439026 loss)
I1008 04:47:03.522080  5322 sgd_solver.cpp:105] Iteration 90900, lr = 0.001
I1008 04:47:27.296617  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:47:28.280292  5322 solver.cpp:330] Iteration 91000, Testing net (#0)
I1008 04:47:32.862462  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:47:33.040837  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9229
I1008 04:47:33.040863  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.316728 (* 1 = 0.316728 loss)
I1008 04:47:33.213548  5322 solver.cpp:218] Iteration 91000 (3.36835 iter/s, 29.6881s/100 iters), loss = 0.00146906
I1008 04:47:33.213580  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00146914 (* 1 = 0.00146914 loss)
I1008 04:47:33.213587  5322 sgd_solver.cpp:105] Iteration 91000, lr = 0.001
I1008 04:47:57.788311  5322 solver.cpp:218] Iteration 91100 (4.06959 iter/s, 24.5725s/100 iters), loss = 0.00355424
I1008 04:47:57.788401  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00355432 (* 1 = 0.00355432 loss)
I1008 04:47:57.788409  5322 sgd_solver.cpp:105] Iteration 91100, lr = 0.001
I1008 04:48:22.425273  5322 solver.cpp:218] Iteration 91200 (4.05932 iter/s, 24.6347s/100 iters), loss = 0.00374273
I1008 04:48:22.425308  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00374281 (* 1 = 0.00374281 loss)
I1008 04:48:22.425326  5322 sgd_solver.cpp:105] Iteration 91200, lr = 0.001
I1008 04:48:47.062583  5322 solver.cpp:218] Iteration 91300 (4.05949 iter/s, 24.6336s/100 iters), loss = 0.0026648
I1008 04:48:47.062691  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00266488 (* 1 = 0.00266488 loss)
I1008 04:48:47.062700  5322 sgd_solver.cpp:105] Iteration 91300, lr = 0.001
I1008 04:49:12.133821  5322 solver.cpp:218] Iteration 91400 (3.98899 iter/s, 25.069s/100 iters), loss = 0.00194579
I1008 04:49:12.133852  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00194587 (* 1 = 0.00194587 loss)
I1008 04:49:12.133859  5322 sgd_solver.cpp:105] Iteration 91400, lr = 0.001
I1008 04:49:35.927336  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:49:36.871568  5322 solver.cpp:330] Iteration 91500, Testing net (#0)
I1008 04:49:41.440752  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:49:41.660549  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9231
I1008 04:49:41.660576  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.317016 (* 1 = 0.317016 loss)
I1008 04:49:41.777187  5322 solver.cpp:218] Iteration 91500 (3.37387 iter/s, 29.6396s/100 iters), loss = 0.004788
I1008 04:49:41.777222  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00478809 (* 1 = 0.00478809 loss)
I1008 04:49:41.777230  5322 sgd_solver.cpp:105] Iteration 91500, lr = 0.001
I1008 04:50:06.360502  5322 solver.cpp:218] Iteration 91600 (4.06818 iter/s, 24.581s/100 iters), loss = 0.00578487
I1008 04:50:06.360599  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00578495 (* 1 = 0.00578495 loss)
I1008 04:50:06.360611  5322 sgd_solver.cpp:105] Iteration 91600, lr = 0.001
I1008 04:50:30.989027  5322 solver.cpp:218] Iteration 91700 (4.06106 iter/s, 24.6241s/100 iters), loss = 0.00394007
I1008 04:50:30.989073  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00394016 (* 1 = 0.00394016 loss)
I1008 04:50:30.989079  5322 sgd_solver.cpp:105] Iteration 91700, lr = 0.001
I1008 04:50:55.633266  5322 solver.cpp:218] Iteration 91800 (4.05837 iter/s, 24.6405s/100 iters), loss = 0.00510749
I1008 04:50:55.633355  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00510758 (* 1 = 0.00510758 loss)
I1008 04:50:55.633363  5322 sgd_solver.cpp:105] Iteration 91800, lr = 0.001
I1008 04:51:20.730994  5322 solver.cpp:218] Iteration 91900 (3.98478 iter/s, 25.0955s/100 iters), loss = 0.00294984
I1008 04:51:20.731040  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00294992 (* 1 = 0.00294992 loss)
I1008 04:51:20.731047  5322 sgd_solver.cpp:105] Iteration 91900, lr = 0.001
I1008 04:51:44.608450  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:51:45.594182  5322 solver.cpp:330] Iteration 92000, Testing net (#0)
I1008 04:51:50.202003  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:51:50.383743  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.923
I1008 04:51:50.383772  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.317372 (* 1 = 0.317372 loss)
I1008 04:51:50.545789  5322 solver.cpp:218] Iteration 92000 (3.35453 iter/s, 29.8104s/100 iters), loss = 0.0228242
I1008 04:51:50.545820  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0228243 (* 1 = 0.0228243 loss)
I1008 04:51:50.545826  5322 sgd_solver.cpp:105] Iteration 92000, lr = 0.001
I1008 04:52:15.251001  5322 solver.cpp:218] Iteration 92100 (4.0478 iter/s, 24.7048s/100 iters), loss = 0.00409696
I1008 04:52:15.251086  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00409704 (* 1 = 0.00409704 loss)
I1008 04:52:15.251094  5322 sgd_solver.cpp:105] Iteration 92100, lr = 0.001
I1008 04:52:39.877095  5322 solver.cpp:218] Iteration 92200 (4.0611 iter/s, 24.6238s/100 iters), loss = 0.00876185
I1008 04:52:39.877127  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00876193 (* 1 = 0.00876193 loss)
I1008 04:52:39.877135  5322 sgd_solver.cpp:105] Iteration 92200, lr = 0.001
I1008 04:53:04.505791  5322 solver.cpp:218] Iteration 92300 (4.06096 iter/s, 24.6247s/100 iters), loss = 0.00227152
I1008 04:53:04.505913  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0022716 (* 1 = 0.0022716 loss)
I1008 04:53:04.505924  5322 sgd_solver.cpp:105] Iteration 92300, lr = 0.001
I1008 04:53:29.571517  5322 solver.cpp:218] Iteration 92400 (3.98987 iter/s, 25.0635s/100 iters), loss = 0.000762809
I1008 04:53:29.571552  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000762895 (* 1 = 0.000762895 loss)
I1008 04:53:29.571570  5322 sgd_solver.cpp:105] Iteration 92400, lr = 0.001
I1008 04:53:53.421216  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:53:54.406782  5322 solver.cpp:330] Iteration 92500, Testing net (#0)
I1008 04:53:59.011860  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:53:59.184772  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9222
I1008 04:53:59.184803  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.316971 (* 1 = 0.316971 loss)
I1008 04:53:59.360141  5322 solver.cpp:218] Iteration 92500 (3.35724 iter/s, 29.7864s/100 iters), loss = 0.00420717
I1008 04:53:59.360184  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00420725 (* 1 = 0.00420725 loss)
I1008 04:53:59.360191  5322 sgd_solver.cpp:105] Iteration 92500, lr = 0.001
I1008 04:54:23.887307  5322 solver.cpp:218] Iteration 92600 (4.07714 iter/s, 24.527s/100 iters), loss = 0.00188921
I1008 04:54:23.887408  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0018893 (* 1 = 0.0018893 loss)
I1008 04:54:23.887419  5322 sgd_solver.cpp:105] Iteration 92600, lr = 0.001
I1008 04:54:48.541808  5322 solver.cpp:218] Iteration 92700 (4.05643 iter/s, 24.6522s/100 iters), loss = 0.00788097
I1008 04:54:48.541851  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00788106 (* 1 = 0.00788106 loss)
I1008 04:54:48.541857  5322 sgd_solver.cpp:105] Iteration 92700, lr = 0.001
I1008 04:55:13.193200  5322 solver.cpp:218] Iteration 92800 (4.05694 iter/s, 24.6491s/100 iters), loss = 0.00625073
I1008 04:55:13.193303  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00625081 (* 1 = 0.00625081 loss)
I1008 04:55:13.193315  5322 sgd_solver.cpp:105] Iteration 92800, lr = 0.001
I1008 04:55:38.210921  5322 solver.cpp:218] Iteration 92900 (3.99753 iter/s, 25.0154s/100 iters), loss = 0.00622467
I1008 04:55:38.210957  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00622475 (* 1 = 0.00622475 loss)
I1008 04:55:38.210965  5322 sgd_solver.cpp:105] Iteration 92900, lr = 0.001
I1008 04:56:02.146124  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:56:03.126672  5322 solver.cpp:330] Iteration 93000, Testing net (#0)
I1008 04:56:07.706095  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:56:07.887578  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9233
I1008 04:56:07.887607  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.318054 (* 1 = 0.318054 loss)
I1008 04:56:08.046634  5322 solver.cpp:218] Iteration 93000 (3.35194 iter/s, 29.8334s/100 iters), loss = 0.00153104
I1008 04:56:08.046669  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00153112 (* 1 = 0.00153112 loss)
I1008 04:56:08.046677  5322 sgd_solver.cpp:105] Iteration 93000, lr = 0.001
I1008 04:56:32.598217  5322 solver.cpp:218] Iteration 93100 (4.07343 iter/s, 24.5493s/100 iters), loss = 0.00969703
I1008 04:56:32.598287  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00969712 (* 1 = 0.00969712 loss)
I1008 04:56:32.598295  5322 sgd_solver.cpp:105] Iteration 93100, lr = 0.001
I1008 04:56:57.266700  5322 solver.cpp:218] Iteration 93200 (4.05413 iter/s, 24.6662s/100 iters), loss = 0.00216321
I1008 04:56:57.266741  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00216329 (* 1 = 0.00216329 loss)
I1008 04:56:57.266762  5322 sgd_solver.cpp:105] Iteration 93200, lr = 0.001
I1008 04:57:21.929997  5322 solver.cpp:218] Iteration 93300 (4.05521 iter/s, 24.6597s/100 iters), loss = 0.00135637
I1008 04:57:21.930081  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00135645 (* 1 = 0.00135645 loss)
I1008 04:57:21.930094  5322 sgd_solver.cpp:105] Iteration 93300, lr = 0.001
I1008 04:57:47.016440  5322 solver.cpp:218] Iteration 93400 (3.98658 iter/s, 25.0842s/100 iters), loss = 0.00153847
I1008 04:57:47.016475  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00153855 (* 1 = 0.00153855 loss)
I1008 04:57:47.016484  5322 sgd_solver.cpp:105] Iteration 93400, lr = 0.001
I1008 04:58:10.885136  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:58:11.870764  5322 solver.cpp:330] Iteration 93500, Testing net (#0)
I1008 04:58:16.447690  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:58:16.656553  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9216
I1008 04:58:16.656581  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.318737 (* 1 = 0.318737 loss)
I1008 04:58:16.789831  5322 solver.cpp:218] Iteration 93500 (3.35896 iter/s, 29.7711s/100 iters), loss = 0.00292607
I1008 04:58:16.789862  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00292615 (* 1 = 0.00292615 loss)
I1008 04:58:16.789870  5322 sgd_solver.cpp:105] Iteration 93500, lr = 0.001
I1008 04:58:41.368846  5322 solver.cpp:218] Iteration 93600 (4.06888 iter/s, 24.5768s/100 iters), loss = 0.00128926
I1008 04:58:41.368948  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00128934 (* 1 = 0.00128934 loss)
I1008 04:58:41.368958  5322 sgd_solver.cpp:105] Iteration 93600, lr = 0.001
I1008 04:59:06.020699  5322 solver.cpp:218] Iteration 93700 (4.05722 iter/s, 24.6474s/100 iters), loss = 0.00381799
I1008 04:59:06.020735  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00381807 (* 1 = 0.00381807 loss)
I1008 04:59:06.020745  5322 sgd_solver.cpp:105] Iteration 93700, lr = 0.001
I1008 04:59:30.676025  5322 solver.cpp:218] Iteration 93800 (4.05658 iter/s, 24.6513s/100 iters), loss = 0.00184171
I1008 04:59:30.676105  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0018418 (* 1 = 0.0018418 loss)
I1008 04:59:30.676113  5322 sgd_solver.cpp:105] Iteration 93800, lr = 0.001
I1008 04:59:55.754045  5322 solver.cpp:218] Iteration 93900 (3.98817 iter/s, 25.0741s/100 iters), loss = 0.00214132
I1008 04:59:55.754091  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0021414 (* 1 = 0.0021414 loss)
I1008 04:59:55.754098  5322 sgd_solver.cpp:105] Iteration 93900, lr = 0.001
I1008 05:00:19.515646  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 05:00:20.497771  5322 solver.cpp:330] Iteration 94000, Testing net (#0)
I1008 05:00:25.136812  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 05:00:25.314965  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9242
I1008 05:00:25.314996  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.3187 (* 1 = 0.3187 loss)
I1008 05:00:25.467602  5322 solver.cpp:218] Iteration 94000 (3.36572 iter/s, 29.7113s/100 iters), loss = 0.00201747
I1008 05:00:25.467635  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00201755 (* 1 = 0.00201755 loss)
I1008 05:00:25.467645  5322 sgd_solver.cpp:105] Iteration 94000, lr = 0.001
I1008 05:00:50.066597  5322 solver.cpp:218] Iteration 94100 (4.06558 iter/s, 24.5968s/100 iters), loss = 0.00279003
I1008 05:00:50.066705  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00279011 (* 1 = 0.00279011 loss)
I1008 05:00:50.066720  5322 sgd_solver.cpp:105] Iteration 94100, lr = 0.001
I1008 05:01:14.679647  5322 solver.cpp:218] Iteration 94200 (4.0635 iter/s, 24.6093s/100 iters), loss = 0.005453
I1008 05:01:14.679693  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00545309 (* 1 = 0.00545309 loss)
I1008 05:01:14.679702  5322 sgd_solver.cpp:105] Iteration 94200, lr = 0.001
I1008 05:01:39.309870  5322 solver.cpp:218] Iteration 94300 (4.06067 iter/s, 24.6265s/100 iters), loss = 0.00511424
I1008 05:01:39.309972  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00511433 (* 1 = 0.00511433 loss)
I1008 05:01:39.309994  5322 sgd_solver.cpp:105] Iteration 94300, lr = 0.001
I1008 05:02:04.289991  5322 solver.cpp:218] Iteration 94400 (4.00378 iter/s, 24.9764s/100 iters), loss = 0.00157735
I1008 05:02:04.290042  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00157744 (* 1 = 0.00157744 loss)
I1008 05:02:04.290050  5322 sgd_solver.cpp:105] Iteration 94400, lr = 0.001
I1008 05:02:28.088827  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 05:02:29.072953  5322 solver.cpp:330] Iteration 94500, Testing net (#0)
I1008 05:02:33.569639  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 05:02:33.780563  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9238
I1008 05:02:33.780591  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.319112 (* 1 = 0.319112 loss)
I1008 05:02:33.920856  5322 solver.cpp:218] Iteration 94500 (3.37528 iter/s, 29.6272s/100 iters), loss = 0.0006045
I1008 05:02:33.920888  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000604585 (* 1 = 0.000604585 loss)
I1008 05:02:33.920897  5322 sgd_solver.cpp:105] Iteration 94500, lr = 0.001
I1008 05:02:58.548945  5322 solver.cpp:218] Iteration 94600 (4.06113 iter/s, 24.6237s/100 iters), loss = 0.00217726
I1008 05:02:58.549026  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00217734 (* 1 = 0.00217734 loss)
I1008 05:02:58.549038  5322 sgd_solver.cpp:105] Iteration 94600, lr = 0.001
I1008 05:03:23.163453  5322 solver.cpp:218] Iteration 94700 (4.06332 iter/s, 24.6104s/100 iters), loss = 0.00221592
I1008 05:03:23.163491  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.002216 (* 1 = 0.002216 loss)
I1008 05:03:23.163501  5322 sgd_solver.cpp:105] Iteration 94700, lr = 0.001
I1008 05:03:47.813411  5322 solver.cpp:218] Iteration 94800 (4.05752 iter/s, 24.6456s/100 iters), loss = 0.00153196
I1008 05:03:47.813500  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00153205 (* 1 = 0.00153205 loss)
I1008 05:03:47.813508  5322 sgd_solver.cpp:105] Iteration 94800, lr = 0.001
I1008 05:04:12.884119  5322 solver.cpp:218] Iteration 94900 (3.98942 iter/s, 25.0663s/100 iters), loss = 0.00242071
I1008 05:04:12.884158  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00242079 (* 1 = 0.00242079 loss)
I1008 05:04:12.884177  5322 sgd_solver.cpp:105] Iteration 94900, lr = 0.001
I1008 05:04:36.671257  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 05:04:37.653723  5322 solver.cpp:330] Iteration 95000, Testing net (#0)
I1008 05:04:42.286836  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 05:04:42.494931  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9237
I1008 05:04:42.494959  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.319709 (* 1 = 0.319709 loss)
I1008 05:04:42.638543  5322 solver.cpp:218] Iteration 95000 (3.3611 iter/s, 29.7522s/100 iters), loss = 0.00220341
I1008 05:04:42.638576  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00220349 (* 1 = 0.00220349 loss)
I1008 05:04:42.638583  5322 sgd_solver.cpp:105] Iteration 95000, lr = 0.001
I1008 05:05:07.325125  5322 solver.cpp:218] Iteration 95100 (4.05115 iter/s, 24.6843s/100 iters), loss = 0.00208143
I1008 05:05:07.325232  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00208151 (* 1 = 0.00208151 loss)
I1008 05:05:07.325242  5322 sgd_solver.cpp:105] Iteration 95100, lr = 0.001
I1008 05:05:31.957674  5322 solver.cpp:218] Iteration 95200 (4.06039 iter/s, 24.6282s/100 iters), loss = 0.0117694
I1008 05:05:31.957707  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0117695 (* 1 = 0.0117695 loss)
I1008 05:05:31.957715  5322 sgd_solver.cpp:105] Iteration 95200, lr = 0.001
I1008 05:05:56.608273  5322 solver.cpp:218] Iteration 95300 (4.0573 iter/s, 24.6469s/100 iters), loss = 0.00170945
I1008 05:05:56.608361  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00170954 (* 1 = 0.00170954 loss)
I1008 05:05:56.608369  5322 sgd_solver.cpp:105] Iteration 95300, lr = 0.001
I1008 05:06:21.695628  5322 solver.cpp:218] Iteration 95400 (3.98664 iter/s, 25.0838s/100 iters), loss = 0.00321286
I1008 05:06:21.695664  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00321295 (* 1 = 0.00321295 loss)
I1008 05:06:21.695674  5322 sgd_solver.cpp:105] Iteration 95400, lr = 0.001
I1008 05:06:45.485097  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 05:06:46.451360  5322 solver.cpp:330] Iteration 95500, Testing net (#0)
I1008 05:06:51.060750  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 05:06:51.243793  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9234
I1008 05:06:51.243825  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.319678 (* 1 = 0.319678 loss)
I1008 05:06:51.409461  5322 solver.cpp:218] Iteration 95500 (3.36591 iter/s, 29.7097s/100 iters), loss = 0.00357098
I1008 05:06:51.409492  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00357107 (* 1 = 0.00357107 loss)
I1008 05:06:51.409499  5322 sgd_solver.cpp:105] Iteration 95500, lr = 0.001
I1008 05:07:16.113054  5322 solver.cpp:218] Iteration 95600 (4.04872 iter/s, 24.6992s/100 iters), loss = 0.00187499
I1008 05:07:16.113135  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00187508 (* 1 = 0.00187508 loss)
I1008 05:07:16.113143  5322 sgd_solver.cpp:105] Iteration 95600, lr = 0.001
I1008 05:07:40.758512  5322 solver.cpp:218] Iteration 95700 (4.05817 iter/s, 24.6417s/100 iters), loss = 0.00389901
I1008 05:07:40.758548  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0038991 (* 1 = 0.0038991 loss)
I1008 05:07:40.758555  5322 sgd_solver.cpp:105] Iteration 95700, lr = 0.001
I1008 05:08:05.405719  5322 solver.cpp:218] Iteration 95800 (4.05786 iter/s, 24.6435s/100 iters), loss = 0.00585315
I1008 05:08:05.405804  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00585324 (* 1 = 0.00585324 loss)
I1008 05:08:05.405813  5322 sgd_solver.cpp:105] Iteration 95800, lr = 0.001
I1008 05:08:30.327322  5322 solver.cpp:218] Iteration 95900 (4.01295 iter/s, 24.9193s/100 iters), loss = 0.00342109
I1008 05:08:30.327360  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00342118 (* 1 = 0.00342118 loss)
I1008 05:08:30.327368  5322 sgd_solver.cpp:105] Iteration 95900, lr = 0.001
I1008 05:08:54.129379  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 05:08:55.111641  5322 solver.cpp:330] Iteration 96000, Testing net (#0)
I1008 05:08:59.668104  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 05:08:59.848028  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9237
I1008 05:08:59.848057  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.319165 (* 1 = 0.319165 loss)
I1008 05:09:00.022843  5322 solver.cpp:218] Iteration 96000 (3.36777 iter/s, 29.6932s/100 iters), loss = 0.000793318
I1008 05:09:00.022874  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000793414 (* 1 = 0.000793414 loss)
I1008 05:09:00.022882  5322 sgd_solver.cpp:105] Iteration 96000, lr = 0.001
I1008 05:09:24.615290  5322 solver.cpp:218] Iteration 96100 (4.06666 iter/s, 24.5902s/100 iters), loss = 0.0027794
I1008 05:09:24.615378  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0027795 (* 1 = 0.0027795 loss)
I1008 05:09:24.615386  5322 sgd_solver.cpp:105] Iteration 96100, lr = 0.001
I1008 05:09:49.259490  5322 solver.cpp:218] Iteration 96200 (4.0584 iter/s, 24.6403s/100 iters), loss = 0.00339168
I1008 05:09:49.259536  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00339178 (* 1 = 0.00339178 loss)
I1008 05:09:49.259543  5322 sgd_solver.cpp:105] Iteration 96200, lr = 0.001
I1008 05:10:13.912184  5322 solver.cpp:218] Iteration 96300 (4.05696 iter/s, 24.649s/100 iters), loss = 0.00346263
I1008 05:10:13.912273  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00346273 (* 1 = 0.00346273 loss)
I1008 05:10:13.912287  5322 sgd_solver.cpp:105] Iteration 96300, lr = 0.001
I1008 05:10:38.970036  5322 solver.cpp:218] Iteration 96400 (3.99131 iter/s, 25.0544s/100 iters), loss = 0.00192769
I1008 05:10:38.970068  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00192778 (* 1 = 0.00192778 loss)
I1008 05:10:38.970075  5322 sgd_solver.cpp:105] Iteration 96400, lr = 0.001
I1008 05:11:02.767987  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 05:11:03.751562  5322 solver.cpp:330] Iteration 96500, Testing net (#0)
I1008 05:11:08.458148  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 05:11:08.628504  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9229
I1008 05:11:08.628531  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.320558 (* 1 = 0.320558 loss)
I1008 05:11:08.826617  5322 solver.cpp:218] Iteration 96500 (3.34984 iter/s, 29.8522s/100 iters), loss = 0.00221394
I1008 05:11:08.826650  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00221403 (* 1 = 0.00221403 loss)
I1008 05:11:08.826658  5322 sgd_solver.cpp:105] Iteration 96500, lr = 0.001
I1008 05:11:33.480314  5322 solver.cpp:218] Iteration 96600 (4.05656 iter/s, 24.6515s/100 iters), loss = 0.00104192
I1008 05:11:33.480403  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00104202 (* 1 = 0.00104202 loss)
I1008 05:11:33.480412  5322 sgd_solver.cpp:105] Iteration 96600, lr = 0.001
I1008 05:11:58.115344  5322 solver.cpp:218] Iteration 96700 (4.05998 iter/s, 24.6307s/100 iters), loss = 0.00163289
I1008 05:11:58.115382  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00163298 (* 1 = 0.00163298 loss)
I1008 05:11:58.115392  5322 sgd_solver.cpp:105] Iteration 96700, lr = 0.001
I1008 05:12:22.753367  5322 solver.cpp:218] Iteration 96800 (4.05937 iter/s, 24.6344s/100 iters), loss = 0.00682155
I1008 05:12:22.753454  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00682164 (* 1 = 0.00682164 loss)
I1008 05:12:22.753466  5322 sgd_solver.cpp:105] Iteration 96800, lr = 0.001
I1008 05:12:47.847224  5322 solver.cpp:218] Iteration 96900 (3.98568 iter/s, 25.0898s/100 iters), loss = 0.0050292
I1008 05:12:47.847261  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0050293 (* 1 = 0.0050293 loss)
I1008 05:12:47.847280  5322 sgd_solver.cpp:105] Iteration 96900, lr = 0.001
I1008 05:13:11.641396  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 05:13:12.623723  5322 solver.cpp:330] Iteration 97000, Testing net (#0)
I1008 05:13:17.217746  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 05:13:17.380270  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9227
I1008 05:13:17.380296  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.31988 (* 1 = 0.31988 loss)
I1008 05:13:17.566885  5322 solver.cpp:218] Iteration 97000 (3.36503 iter/s, 29.7174s/100 iters), loss = 0.00323476
I1008 05:13:17.566917  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00323486 (* 1 = 0.00323486 loss)
I1008 05:13:17.566925  5322 sgd_solver.cpp:105] Iteration 97000, lr = 0.001
I1008 05:13:42.136801  5322 solver.cpp:218] Iteration 97100 (4.0704 iter/s, 24.5676s/100 iters), loss = 0.00675706
I1008 05:13:42.136874  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00675715 (* 1 = 0.00675715 loss)
I1008 05:13:42.136883  5322 sgd_solver.cpp:105] Iteration 97100, lr = 0.001
I1008 05:14:06.788885  5322 solver.cpp:218] Iteration 97200 (4.05683 iter/s, 24.6498s/100 iters), loss = 0.00381463
I1008 05:14:06.788925  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00381473 (* 1 = 0.00381473 loss)
I1008 05:14:06.788934  5322 sgd_solver.cpp:105] Iteration 97200, lr = 0.001
I1008 05:14:31.389909  5322 solver.cpp:218] Iteration 97300 (4.06524 iter/s, 24.5988s/100 iters), loss = 0.00112512
I1008 05:14:31.390017  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00112521 (* 1 = 0.00112521 loss)
I1008 05:14:31.390027  5322 sgd_solver.cpp:105] Iteration 97300, lr = 0.001
I1008 05:14:56.455341  5322 solver.cpp:218] Iteration 97400 (3.99025 iter/s, 25.0611s/100 iters), loss = 0.00460394
I1008 05:14:56.455376  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00460404 (* 1 = 0.00460404 loss)
I1008 05:14:56.455394  5322 sgd_solver.cpp:105] Iteration 97400, lr = 0.001
I1008 05:15:20.307333  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 05:15:21.292129  5322 solver.cpp:330] Iteration 97500, Testing net (#0)
I1008 05:15:25.928431  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 05:15:26.108868  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.923
I1008 05:15:26.108896  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.320986 (* 1 = 0.320986 loss)
I1008 05:15:26.251600  5322 solver.cpp:218] Iteration 97500 (3.35653 iter/s, 29.7927s/100 iters), loss = 0.00411331
I1008 05:15:26.251636  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0041134 (* 1 = 0.0041134 loss)
I1008 05:15:26.251647  5322 sgd_solver.cpp:105] Iteration 97500, lr = 0.001
I1008 05:15:50.973606  5322 solver.cpp:218] Iteration 97600 (4.04535 iter/s, 24.7197s/100 iters), loss = 0.00234479
I1008 05:15:50.973695  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00234489 (* 1 = 0.00234489 loss)
I1008 05:15:50.973704  5322 sgd_solver.cpp:105] Iteration 97600, lr = 0.001
I1008 05:16:15.642725  5322 solver.cpp:218] Iteration 97700 (4.05402 iter/s, 24.6669s/100 iters), loss = 0.00222289
I1008 05:16:15.642758  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00222299 (* 1 = 0.00222299 loss)
I1008 05:16:15.642766  5322 sgd_solver.cpp:105] Iteration 97700, lr = 0.001
I1008 05:16:40.290580  5322 solver.cpp:218] Iteration 97800 (4.05752 iter/s, 24.6456s/100 iters), loss = 0.00585933
I1008 05:16:40.290662  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00585943 (* 1 = 0.00585943 loss)
I1008 05:16:40.290671  5322 sgd_solver.cpp:105] Iteration 97800, lr = 0.001
I1008 05:17:05.377722  5322 solver.cpp:218] Iteration 97900 (3.98646 iter/s, 25.0849s/100 iters), loss = 0.00711152
I1008 05:17:05.377759  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00711162 (* 1 = 0.00711162 loss)
I1008 05:17:05.377768  5322 sgd_solver.cpp:105] Iteration 97900, lr = 0.001
I1008 05:17:29.163882  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 05:17:30.146744  5322 solver.cpp:330] Iteration 98000, Testing net (#0)
I1008 05:17:34.665129  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 05:17:34.861135  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9236
I1008 05:17:34.861162  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.322001 (* 1 = 0.322001 loss)
I1008 05:17:35.032621  5322 solver.cpp:218] Iteration 98000 (3.37256 iter/s, 29.651s/100 iters), loss = 0.00103603
I1008 05:17:35.032655  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00103614 (* 1 = 0.00103614 loss)
I1008 05:17:35.032661  5322 sgd_solver.cpp:105] Iteration 98000, lr = 0.001
I1008 05:17:59.713485  5322 solver.cpp:218] Iteration 98100 (4.05174 iter/s, 24.6807s/100 iters), loss = 0.00623866
I1008 05:17:59.713570  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00623877 (* 1 = 0.00623877 loss)
I1008 05:17:59.713582  5322 sgd_solver.cpp:105] Iteration 98100, lr = 0.001
I1008 05:18:24.332366  5322 solver.cpp:218] Iteration 98200 (4.06252 iter/s, 24.6152s/100 iters), loss = 0.00222361
I1008 05:18:24.332401  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00222372 (* 1 = 0.00222372 loss)
I1008 05:18:24.332408  5322 sgd_solver.cpp:105] Iteration 98200, lr = 0.001
I1008 05:18:48.959560  5322 solver.cpp:218] Iteration 98300 (4.06116 iter/s, 24.6235s/100 iters), loss = 0.0016106
I1008 05:18:48.959658  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0016107 (* 1 = 0.0016107 loss)
I1008 05:18:48.959667  5322 sgd_solver.cpp:105] Iteration 98300, lr = 0.001
I1008 05:19:14.047269  5322 solver.cpp:218] Iteration 98400 (3.98668 iter/s, 25.0835s/100 iters), loss = 0.00693006
I1008 05:19:14.047320  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00693017 (* 1 = 0.00693017 loss)
I1008 05:19:14.047329  5322 sgd_solver.cpp:105] Iteration 98400, lr = 0.001
I1008 05:19:37.904927  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 05:19:38.887878  5322 solver.cpp:330] Iteration 98500, Testing net (#0)
I1008 05:19:43.552127  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 05:19:43.742954  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.923
I1008 05:19:43.742979  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.320583 (* 1 = 0.320583 loss)
I1008 05:19:43.910567  5322 solver.cpp:218] Iteration 98500 (3.34898 iter/s, 29.8598s/100 iters), loss = 0.00238207
I1008 05:19:43.910605  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00238218 (* 1 = 0.00238218 loss)
I1008 05:19:43.910615  5322 sgd_solver.cpp:105] Iteration 98500, lr = 0.001
I1008 05:20:08.579680  5322 solver.cpp:218] Iteration 98600 (4.05402 iter/s, 24.6669s/100 iters), loss = 0.00525631
I1008 05:20:08.579780  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00525642 (* 1 = 0.00525642 loss)
I1008 05:20:08.579803  5322 sgd_solver.cpp:105] Iteration 98600, lr = 0.001
I1008 05:20:33.251078  5322 solver.cpp:218] Iteration 98700 (4.05395 iter/s, 24.6673s/100 iters), loss = 0.00383082
I1008 05:20:33.251124  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00383092 (* 1 = 0.00383092 loss)
I1008 05:20:33.251145  5322 sgd_solver.cpp:105] Iteration 98700, lr = 0.001
I1008 05:20:57.906363  5322 solver.cpp:218] Iteration 98800 (4.0563 iter/s, 24.653s/100 iters), loss = 0.00094654
I1008 05:20:57.906471  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000946644 (* 1 = 0.000946644 loss)
I1008 05:20:57.906484  5322 sgd_solver.cpp:105] Iteration 98800, lr = 0.001
I1008 05:21:22.991930  5322 solver.cpp:218] Iteration 98900 (3.98672 iter/s, 25.0833s/100 iters), loss = 0.00102306
I1008 05:21:22.991966  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00102316 (* 1 = 0.00102316 loss)
I1008 05:21:22.991976  5322 sgd_solver.cpp:105] Iteration 98900, lr = 0.001
I1008 05:21:43.310058  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 05:21:43.971025  5322 solver.cpp:330] Iteration 99000, Testing net (#0)
I1008 05:21:47.233500  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 05:21:47.333052  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9234
I1008 05:21:47.333091  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.321308 (* 1 = 0.321308 loss)
I1008 05:21:47.473810  5322 solver.cpp:218] Iteration 99000 (4.08535 iter/s, 24.4777s/100 iters), loss = 0.00126993
I1008 05:21:47.473850  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00127003 (* 1 = 0.00127003 loss)
I1008 05:21:47.473855  5322 sgd_solver.cpp:105] Iteration 99000, lr = 0.001
I1008 05:22:04.002938  5322 solver.cpp:218] Iteration 99100 (6.04996 iter/s, 16.529s/100 iters), loss = 0.0042194
I1008 05:22:04.002979  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0042195 (* 1 = 0.0042195 loss)
I1008 05:22:04.002985  5322 sgd_solver.cpp:105] Iteration 99100, lr = 0.001
I1008 05:22:20.529032  5322 solver.cpp:218] Iteration 99200 (6.05184 iter/s, 16.5239s/100 iters), loss = 0.00287577
I1008 05:22:20.529165  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00287587 (* 1 = 0.00287587 loss)
I1008 05:22:20.529184  5322 sgd_solver.cpp:105] Iteration 99200, lr = 0.001
I1008 05:22:37.077296  5322 solver.cpp:218] Iteration 99300 (6.04373 iter/s, 16.5461s/100 iters), loss = 0.00601831
I1008 05:22:37.077327  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00601842 (* 1 = 0.00601842 loss)
I1008 05:22:37.077343  5322 sgd_solver.cpp:105] Iteration 99300, lr = 0.001
I1008 05:22:53.981534  5322 solver.cpp:218] Iteration 99400 (5.91644 iter/s, 16.902s/100 iters), loss = 0.00135633
I1008 05:22:53.981655  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00135643 (* 1 = 0.00135643 loss)
I1008 05:22:53.981673  5322 sgd_solver.cpp:105] Iteration 99400, lr = 0.001
I1008 05:23:09.703290  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 05:23:10.364118  5322 solver.cpp:330] Iteration 99500, Testing net (#0)
I1008 05:23:13.624310  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 05:23:13.740208  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9221
I1008 05:23:13.740237  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.321495 (* 1 = 0.321495 loss)
I1008 05:23:13.866430  5322 solver.cpp:218] Iteration 99500 (5.0295 iter/s, 19.8827s/100 iters), loss = 0.000466819
I1008 05:23:13.866468  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000466919 (* 1 = 0.000466919 loss)
I1008 05:23:13.866475  5322 sgd_solver.cpp:105] Iteration 99500, lr = 0.001
I1008 05:23:30.392331  5322 solver.cpp:218] Iteration 99600 (6.05114 iter/s, 16.5258s/100 iters), loss = 0.00418781
I1008 05:23:30.392426  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00418791 (* 1 = 0.00418791 loss)
I1008 05:23:30.392434  5322 sgd_solver.cpp:105] Iteration 99600, lr = 0.001
I1008 05:23:46.930204  5322 solver.cpp:218] Iteration 99700 (6.04753 iter/s, 16.5357s/100 iters), loss = 0.00216275
I1008 05:23:46.930248  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00216286 (* 1 = 0.00216286 loss)
I1008 05:23:46.930254  5322 sgd_solver.cpp:105] Iteration 99700, lr = 0.001
I1008 05:24:03.464993  5322 solver.cpp:218] Iteration 99800 (6.04866 iter/s, 16.5326s/100 iters), loss = 0.00414915
I1008 05:24:03.465077  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00414925 (* 1 = 0.00414925 loss)
I1008 05:24:03.465085  5322 sgd_solver.cpp:105] Iteration 99800, lr = 0.001
I1008 05:24:19.414445  5322 solver.cpp:218] Iteration 99900 (6.27067 iter/s, 15.9473s/100 iters), loss = 0.00447306
I1008 05:24:19.414477  5322 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00447316 (* 1 = 0.00447316 loss)
I1008 05:24:19.414495  5322 sgd_solver.cpp:105] Iteration 99900, lr = 0.001
I1008 05:24:26.688064  5330 data_layer.cpp:73] Restarting data prefetching from start.
I1008 05:24:26.994408  5322 solver.cpp:447] Snapshotting to binary proto file xn/PENLU/snapshot/resnet/res32/res32_elu_alpha0.25_gauss_iter_100000.caffemodel
I1008 05:24:27.005862  5322 sgd_solver.cpp:273] Snapshotting solver state to binary proto file xn/PENLU/snapshot/resnet/res32/res32_elu_alpha0.25_gauss_iter_100000.solverstate
I1008 05:24:27.027796  5322 solver.cpp:310] Iteration 100000, loss = 0.00209824
I1008 05:24:27.027817  5322 solver.cpp:330] Iteration 100000, Testing net (#0)
I1008 05:24:28.769217  5331 data_layer.cpp:73] Restarting data prefetching from start.
I1008 05:24:28.842154  5322 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9233
I1008 05:24:28.842180  5322 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.322215 (* 1 = 0.322215 loss)
I1008 05:24:28.842183  5322 solver.cpp:315] Optimization Done.
I1008 05:24:28.842195  5322 caffe.cpp:259] Optimization Done.
