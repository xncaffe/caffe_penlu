I1007 12:33:16.796109  4874 caffe.cpp:218] Using GPUs 0
I1007 12:33:16.827055  4874 caffe.cpp:223] GPU 0: GeForce GTX 1080
I1007 12:33:17.052709  4874 solver.cpp:44] Initializing solver from parameters: 
test_iter: 100
test_interval: 500
base_lr: 0.1
display: 100
max_iter: 100000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0001
snapshot: 100000
snapshot_prefix: "xn/PENLU/snapshot/resnet/res32/res32_mpelu_alpha0.25_beta1_2study_2decay_gauss"
solver_mode: GPU
device_id: 0
net: "/home/x306/caffe/xn/PENLU/neural/resnet/res32/res32_mpelu_decay_gauss.prototxt"
train_state {
  level: 0
  stage: ""
}
stepvalue: 40000
stepvalue: 80000
I1007 12:33:17.052829  4874 solver.cpp:87] Creating training net from net file: /home/x306/caffe/xn/PENLU/neural/resnet/res32/res32_mpelu_decay_gauss.prototxt
I1007 12:33:17.054922  4874 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: /home/x306/caffe/xn/PENLU/neural/resnet/res32/res32_mpelu_decay_gauss.prototxt
I1007 12:33:17.054932  4874 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I1007 12:33:17.055074  4874 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer Data1
I1007 12:33:17.055147  4874 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer Accuracy1
I1007 12:33:17.055784  4874 net.cpp:51] Initializing net from parameters: 
name: "resnet_cifar10"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "Data1"
  type: "Data"
  top: "Data1"
  top: "Data2"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 28
    mean_file: "/home/x306/caffe/xn/PENLU/data/cifar10/mean.binaryproto"
  }
  data_param {
    source: "/home/x306/caffe/xn/PENLU/data/cifar10/cifar10_train_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "Convolution1"
  type: "Convolution"
  bottom: "Data1"
  top: "Convolution1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm1"
  type: "BatchNorm"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1"
  type: "Scale"
  bottom: "Convolution1"
  top: "Convolution1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU1"
  type: "M2PELU"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution2"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm2"
  type: "BatchNorm"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale2"
  type: "Scale"
  bottom: "Convolution2"
  top: "Convolution2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU2"
  type: "M2PELU"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution3"
  type: "Convolution"
  bottom: "Convolution2"
  top: "Convolution3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm3"
  type: "BatchNorm"
  bottom: "Convolution3"
  top: "Convolution3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale3"
  type: "Scale"
  bottom: "Convolution3"
  top: "Convolution3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise1"
  type: "Eltwise"
  bottom: "Convolution1"
  bottom: "Convolution3"
  top: "Eltwise1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU3"
  type: "M2PELU"
  bottom: "Eltwise1"
  top: "Eltwise1"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution4"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm4"
  type: "BatchNorm"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale4"
  type: "Scale"
  bottom: "Convolution4"
  top: "Convolution4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU4"
  type: "M2PELU"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution5"
  type: "Convolution"
  bottom: "Convolution4"
  top: "Convolution5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm5"
  type: "BatchNorm"
  bottom: "Convolution5"
  top: "Convolution5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale5"
  type: "Scale"
  bottom: "Convolution5"
  top: "Convolution5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise2"
  type: "Eltwise"
  bottom: "Eltwise1"
  bottom: "Convolution5"
  top: "Eltwise2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU5"
  type: "M2PELU"
  bottom: "Eltwise2"
  top: "Eltwise2"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution6"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm6"
  type: "BatchNorm"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale6"
  type: "Scale"
  bottom: "Convolution6"
  top: "Convolution6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU6"
  type: "M2PELU"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution7"
  type: "Convolution"
  bottom: "Convolution6"
  top: "Convolution7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm7"
  type: "BatchNorm"
  bottom: "Convolution7"
  top: "Convolution7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale7"
  type: "Scale"
  bottom: "Convolution7"
  top: "Convolution7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise3"
  type: "Eltwise"
  bottom: "Eltwise2"
  bottom: "Convolution7"
  top: "Eltwise3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU7"
  type: "M2PELU"
  bottom: "Eltwise3"
  top: "Eltwise3"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution8"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm8"
  type: "BatchNorm"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale8"
  type: "Scale"
  bottom: "Convolution8"
  top: "Convolution8"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU8"
  type: "M2PELU"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution9"
  type: "Convolution"
  bottom: "Convolution8"
  top: "Convolution9"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm9"
  type: "BatchNorm"
  bottom: "Convolution9"
  top: "Convolution9"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale9"
  type: "Scale"
  bottom: "Convolution9"
  top: "Convolution9"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise4"
  type: "Eltwise"
  bottom: "Eltwise3"
  bottom: "Convolution9"
  top: "Eltwise4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU9"
  type: "M2PELU"
  bottom: "Eltwise4"
  top: "Eltwise4"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution10"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution10"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm10"
  type: "BatchNorm"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale10"
  type: "Scale"
  bottom: "Convolution10"
  top: "Convolution10"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU10"
  type: "M2PELU"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution11"
  type: "Convolution"
  bottom: "Convolution10"
  top: "Convolution11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm11"
  type: "BatchNorm"
  bottom: "Convolution11"
  top: "Convolution11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale11"
  type: "Scale"
  bottom: "Convolution11"
  top: "Convolution11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise5"
  type: "Eltwise"
  bottom: "Eltwise4"
  bottom: "Convolution11"
  top: "Eltwise5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU11"
  type: "M2PELU"
  bottom: "Eltwise5"
  top: "Eltwise5"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution12"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.25
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm12"
  type: "BatchNorm"
  bottom: "Convolution12"
  top: "Convolution12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale12"
  type: "Scale"
  bottom: "Convolution12"
  top: "Convolution12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution13"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution13"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm13"
  type: "BatchNorm"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale13"
  type: "Scale"
  bottom: "Convolution13"
  top: "Convolution13"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU12"
  type: "M2PELU"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution14"
  type: "Convolution"
  bottom: "Convolution13"
  top: "Convolution14"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm14"
  type: "BatchNorm"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale14"
  type: "Scale"
  bottom: "Convolution14"
  top: "Convolution14"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise6"
  type: "Eltwise"
  bottom: "Convolution12"
  bottom: "Convolution14"
  top: "Eltwise6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU13"
  type: "M2PELU"
  bottom: "Eltwise6"
  top: "Eltwise6"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution15"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution15"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm15"
  type: "BatchNorm"
  bottom: "Convolution15"
  top: "Convolution15"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale15"
  type: "Scale"
  bottom: "Convolution15"
  top: "Convolution15"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU14"
  type: "M2PELU"
  bottom: "Convolution15"
  top: "Convolution15"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution16"
  type: "Convolution"
  bottom: "Convolution15"
  top: "Convolution16"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm16"
  type: "BatchNorm"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale16"
  type: "Scale"
  bottom: "Convolution16"
  top: "Convolution16"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise7"
  type: "Eltwise"
  bottom: "Eltwise6"
  bottom: "Convolution16"
  top: "Eltwise7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU15"
  type: "M2PELU"
  bottom: "Eltwise7"
  top: "Eltwise7"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution17"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution17"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm17"
  type: "BatchNorm"
  bottom: "Convolution17"
  top: "Convolution17"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale17"
  type: "Scale"
  bottom: "Convolution17"
  top: "Convolution17"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU16"
  type: "M2PELU"
  bottom: "Convolution17"
  top: "Convolution17"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution18"
  type: "Convolution"
  bottom: "Convolution17"
  top: "Convolution18"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm18"
  type: "BatchNorm"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale18"
  type: "Scale"
  bottom: "Convolution18"
  top: "Convolution18"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise8"
  type: "Eltwise"
  bottom: "Eltwise7"
  bottom: "Convolution18"
  top: "Eltwise8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU17"
  type: "M2PELU"
  bottom: "Eltwise8"
  top: "Eltwise8"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution19"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution19"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm19"
  type: "BatchNorm"
  bottom: "Convolution19"
  top: "Convolution19"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale19"
  type: "Scale"
  bottom: "Convolution19"
  top: "Convolution19"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU18"
  type: "M2PELU"
  bottom: "Convolution19"
  top: "Convolution19"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution20"
  type: "Convolution"
  bottom: "Convolution19"
  top: "Convolution20"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm20"
  type: "BatchNorm"
  bottom: "Convolution20"
  top: "Convolution20"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale20"
  type: "Scale"
  bottom: "Convolution20"
  top: "Convolution20"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise9"
  type: "Eltwise"
  bottom: "Eltwise8"
  bottom: "Convolution20"
  top: "Eltwise9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU19"
  type: "M2PELU"
  bottom: "Eltwise9"
  top: "Eltwise9"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution21"
  type: "Convolution"
  bottom: "Eltwise9"
  top: "Convolution21"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm21"
  type: "BatchNorm"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale21"
  type: "Scale"
  bottom: "Convolution21"
  top: "Convolution21"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU20"
  type: "M2PELU"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution22"
  type: "Convolution"
  bottom: "Convolution21"
  top: "Convolution22"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm22"
  type: "BatchNorm"
  bottom: "Convolution22"
  top: "Convolution22"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale22"
  type: "Scale"
  bottom: "Convolution22"
  top: "Convolution22"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise10"
  type: "Eltwise"
  bottom: "Eltwise9"
  bottom: "Convolution22"
  top: "Eltwise10"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU21"
  type: "M2PELU"
  bottom: "Eltwise10"
  top: "Eltwise10"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution23"
  type: "Convolution"
  bottom: "Eltwise10"
  top: "Convolution23"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.17677669
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm23"
  type: "BatchNorm"
  bottom: "Convolution23"
  top: "Convolution23"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale23"
  type: "Scale"
  bottom: "Convolution23"
  top: "Convolution23"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution24"
  type: "Convolution"
  bottom: "Eltwise10"
  top: "Convolution24"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm24"
  type: "BatchNorm"
  bottom: "Convolution24"
  top: "Convolution24"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale24"
  type: "Scale"
  bottom: "Convolution24"
  top: "Convolution24"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU22"
  type: "M2PELU"
  bottom: "Convolution24"
  top: "Convolution24"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution25"
  type: "Convolution"
  bottom: "Convolution24"
  top: "Convolution25"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm25"
  type: "BatchNorm"
  bottom: "Convolution25"
  top: "Convolution25"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale25"
  type: "Scale"
  bottom: "Convolution25"
  top: "Convolution25"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise11"
  type: "Eltwise"
  bottom: "Convolution23"
  bottom: "Convolution25"
  top: "Eltwise11"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU23"
  type: "M2PELU"
  bottom: "Eltwise11"
  top: "Eltwise11"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution26"
  type: "Convolution"
  bottom: "Eltwise11"
  top: "Convolution26"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm26"
  type: "BatchNorm"
  bottom: "Convolution26"
  top: "Convoluti
I1007 12:33:17.056236  4874 layer_factory.hpp:77] Creating layer Data1
I1007 12:33:17.056311  4874 db_lmdb.cpp:35] Opened lmdb /home/x306/caffe/xn/PENLU/data/cifar10/cifar10_train_lmdb
I1007 12:33:17.056330  4874 net.cpp:84] Creating Layer Data1
I1007 12:33:17.056336  4874 net.cpp:380] Data1 -> Data1
I1007 12:33:17.056354  4874 net.cpp:380] Data1 -> Data2
I1007 12:33:17.056362  4874 data_transformer.cpp:25] Loading mean file from: /home/x306/caffe/xn/PENLU/data/cifar10/mean.binaryproto
I1007 12:33:17.057754  4874 data_layer.cpp:45] output data size: 100,3,28,28
I1007 12:33:17.060035  4874 net.cpp:122] Setting up Data1
I1007 12:33:17.060058  4874 net.cpp:129] Top shape: 100 3 28 28 (235200)
I1007 12:33:17.060063  4874 net.cpp:129] Top shape: 100 (100)
I1007 12:33:17.060065  4874 net.cpp:137] Memory required for data: 941200
I1007 12:33:17.060071  4874 layer_factory.hpp:77] Creating layer Convolution1
I1007 12:33:17.060091  4874 net.cpp:84] Creating Layer Convolution1
I1007 12:33:17.060094  4874 net.cpp:406] Convolution1 <- Data1
I1007 12:33:17.060103  4874 net.cpp:380] Convolution1 -> Convolution1
I1007 12:33:17.205562  4874 net.cpp:122] Setting up Convolution1
I1007 12:33:17.205590  4874 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 12:33:17.205593  4874 net.cpp:137] Memory required for data: 5958800
I1007 12:33:17.205618  4874 layer_factory.hpp:77] Creating layer BatchNorm1
I1007 12:33:17.205641  4874 net.cpp:84] Creating Layer BatchNorm1
I1007 12:33:17.205664  4874 net.cpp:406] BatchNorm1 <- Convolution1
I1007 12:33:17.205682  4874 net.cpp:367] BatchNorm1 -> Convolution1 (in-place)
I1007 12:33:17.205822  4874 net.cpp:122] Setting up BatchNorm1
I1007 12:33:17.205828  4874 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 12:33:17.205831  4874 net.cpp:137] Memory required for data: 10976400
I1007 12:33:17.205850  4874 layer_factory.hpp:77] Creating layer Scale1
I1007 12:33:17.205859  4874 net.cpp:84] Creating Layer Scale1
I1007 12:33:17.205863  4874 net.cpp:406] Scale1 <- Convolution1
I1007 12:33:17.205866  4874 net.cpp:367] Scale1 -> Convolution1 (in-place)
I1007 12:33:17.205929  4874 layer_factory.hpp:77] Creating layer Scale1
I1007 12:33:17.206048  4874 net.cpp:122] Setting up Scale1
I1007 12:33:17.206054  4874 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 12:33:17.206058  4874 net.cpp:137] Memory required for data: 15994000
I1007 12:33:17.206073  4874 layer_factory.hpp:77] Creating layer M2PELU1
I1007 12:33:17.206092  4874 net.cpp:84] Creating Layer M2PELU1
I1007 12:33:17.206096  4874 net.cpp:406] M2PELU1 <- Convolution1
I1007 12:33:17.206099  4874 net.cpp:367] M2PELU1 -> Convolution1 (in-place)
I1007 12:33:17.206728  4874 net.cpp:122] Setting up M2PELU1
I1007 12:33:17.206738  4874 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 12:33:17.206751  4874 net.cpp:137] Memory required for data: 21011600
I1007 12:33:17.206759  4874 layer_factory.hpp:77] Creating layer Convolution1_M2PELU1_0_split
I1007 12:33:17.206781  4874 net.cpp:84] Creating Layer Convolution1_M2PELU1_0_split
I1007 12:33:17.206784  4874 net.cpp:406] Convolution1_M2PELU1_0_split <- Convolution1
I1007 12:33:17.206799  4874 net.cpp:380] Convolution1_M2PELU1_0_split -> Convolution1_M2PELU1_0_split_0
I1007 12:33:17.206818  4874 net.cpp:380] Convolution1_M2PELU1_0_split -> Convolution1_M2PELU1_0_split_1
I1007 12:33:17.206861  4874 net.cpp:122] Setting up Convolution1_M2PELU1_0_split
I1007 12:33:17.206867  4874 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 12:33:17.206871  4874 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 12:33:17.206874  4874 net.cpp:137] Memory required for data: 31046800
I1007 12:33:17.206876  4874 layer_factory.hpp:77] Creating layer Convolution2
I1007 12:33:17.206884  4874 net.cpp:84] Creating Layer Convolution2
I1007 12:33:17.206888  4874 net.cpp:406] Convolution2 <- Convolution1_M2PELU1_0_split_0
I1007 12:33:17.206892  4874 net.cpp:380] Convolution2 -> Convolution2
I1007 12:33:17.207753  4874 net.cpp:122] Setting up Convolution2
I1007 12:33:17.207764  4874 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 12:33:17.207768  4874 net.cpp:137] Memory required for data: 36064400
I1007 12:33:17.207772  4874 layer_factory.hpp:77] Creating layer BatchNorm2
I1007 12:33:17.207788  4874 net.cpp:84] Creating Layer BatchNorm2
I1007 12:33:17.207792  4874 net.cpp:406] BatchNorm2 <- Convolution2
I1007 12:33:17.207795  4874 net.cpp:367] BatchNorm2 -> Convolution2 (in-place)
I1007 12:33:17.207921  4874 net.cpp:122] Setting up BatchNorm2
I1007 12:33:17.207926  4874 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 12:33:17.207928  4874 net.cpp:137] Memory required for data: 41082000
I1007 12:33:17.207943  4874 layer_factory.hpp:77] Creating layer Scale2
I1007 12:33:17.207949  4874 net.cpp:84] Creating Layer Scale2
I1007 12:33:17.207952  4874 net.cpp:406] Scale2 <- Convolution2
I1007 12:33:17.207955  4874 net.cpp:367] Scale2 -> Convolution2 (in-place)
I1007 12:33:17.207981  4874 layer_factory.hpp:77] Creating layer Scale2
I1007 12:33:17.208052  4874 net.cpp:122] Setting up Scale2
I1007 12:33:17.208058  4874 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 12:33:17.208061  4874 net.cpp:137] Memory required for data: 46099600
I1007 12:33:17.208065  4874 layer_factory.hpp:77] Creating layer M2PELU2
I1007 12:33:17.208071  4874 net.cpp:84] Creating Layer M2PELU2
I1007 12:33:17.208075  4874 net.cpp:406] M2PELU2 <- Convolution2
I1007 12:33:17.208077  4874 net.cpp:367] M2PELU2 -> Convolution2 (in-place)
I1007 12:33:17.208153  4874 net.cpp:122] Setting up M2PELU2
I1007 12:33:17.208165  4874 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 12:33:17.208169  4874 net.cpp:137] Memory required for data: 51117200
I1007 12:33:17.208175  4874 layer_factory.hpp:77] Creating layer Convolution3
I1007 12:33:17.208183  4874 net.cpp:84] Creating Layer Convolution3
I1007 12:33:17.208185  4874 net.cpp:406] Convolution3 <- Convolution2
I1007 12:33:17.208189  4874 net.cpp:380] Convolution3 -> Convolution3
I1007 12:33:17.209075  4874 net.cpp:122] Setting up Convolution3
I1007 12:33:17.209085  4874 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 12:33:17.209089  4874 net.cpp:137] Memory required for data: 56134800
I1007 12:33:17.209095  4874 layer_factory.hpp:77] Creating layer BatchNorm3
I1007 12:33:17.209100  4874 net.cpp:84] Creating Layer BatchNorm3
I1007 12:33:17.209105  4874 net.cpp:406] BatchNorm3 <- Convolution3
I1007 12:33:17.209108  4874 net.cpp:367] BatchNorm3 -> Convolution3 (in-place)
I1007 12:33:17.209234  4874 net.cpp:122] Setting up BatchNorm3
I1007 12:33:17.209240  4874 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 12:33:17.209244  4874 net.cpp:137] Memory required for data: 61152400
I1007 12:33:17.209249  4874 layer_factory.hpp:77] Creating layer Scale3
I1007 12:33:17.209254  4874 net.cpp:84] Creating Layer Scale3
I1007 12:33:17.209257  4874 net.cpp:406] Scale3 <- Convolution3
I1007 12:33:17.209260  4874 net.cpp:367] Scale3 -> Convolution3 (in-place)
I1007 12:33:17.209286  4874 layer_factory.hpp:77] Creating layer Scale3
I1007 12:33:17.209363  4874 net.cpp:122] Setting up Scale3
I1007 12:33:17.209368  4874 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 12:33:17.209372  4874 net.cpp:137] Memory required for data: 66170000
I1007 12:33:17.209377  4874 layer_factory.hpp:77] Creating layer Eltwise1
I1007 12:33:17.209381  4874 net.cpp:84] Creating Layer Eltwise1
I1007 12:33:17.209385  4874 net.cpp:406] Eltwise1 <- Convolution1_M2PELU1_0_split_1
I1007 12:33:17.209388  4874 net.cpp:406] Eltwise1 <- Convolution3
I1007 12:33:17.209393  4874 net.cpp:380] Eltwise1 -> Eltwise1
I1007 12:33:17.209408  4874 net.cpp:122] Setting up Eltwise1
I1007 12:33:17.209414  4874 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 12:33:17.209416  4874 net.cpp:137] Memory required for data: 71187600
I1007 12:33:17.209419  4874 layer_factory.hpp:77] Creating layer M2PELU3
I1007 12:33:17.209424  4874 net.cpp:84] Creating Layer M2PELU3
I1007 12:33:17.209427  4874 net.cpp:406] M2PELU3 <- Eltwise1
I1007 12:33:17.209431  4874 net.cpp:367] M2PELU3 -> Eltwise1 (in-place)
I1007 12:33:17.209509  4874 net.cpp:122] Setting up M2PELU3
I1007 12:33:17.209516  4874 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 12:33:17.209518  4874 net.cpp:137] Memory required for data: 76205200
I1007 12:33:17.209522  4874 layer_factory.hpp:77] Creating layer Eltwise1_M2PELU3_0_split
I1007 12:33:17.209527  4874 net.cpp:84] Creating Layer Eltwise1_M2PELU3_0_split
I1007 12:33:17.209530  4874 net.cpp:406] Eltwise1_M2PELU3_0_split <- Eltwise1
I1007 12:33:17.209533  4874 net.cpp:380] Eltwise1_M2PELU3_0_split -> Eltwise1_M2PELU3_0_split_0
I1007 12:33:17.209538  4874 net.cpp:380] Eltwise1_M2PELU3_0_split -> Eltwise1_M2PELU3_0_split_1
I1007 12:33:17.209561  4874 net.cpp:122] Setting up Eltwise1_M2PELU3_0_split
I1007 12:33:17.209566  4874 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 12:33:17.209569  4874 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 12:33:17.209573  4874 net.cpp:137] Memory required for data: 86240400
I1007 12:33:17.209574  4874 layer_factory.hpp:77] Creating layer Convolution4
I1007 12:33:17.209583  4874 net.cpp:84] Creating Layer Convolution4
I1007 12:33:17.209585  4874 net.cpp:406] Convolution4 <- Eltwise1_M2PELU3_0_split_0
I1007 12:33:17.209589  4874 net.cpp:380] Convolution4 -> Convolution4
I1007 12:33:17.210464  4874 net.cpp:122] Setting up Convolution4
I1007 12:33:17.210474  4874 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 12:33:17.210477  4874 net.cpp:137] Memory required for data: 91258000
I1007 12:33:17.210482  4874 layer_factory.hpp:77] Creating layer BatchNorm4
I1007 12:33:17.210496  4874 net.cpp:84] Creating Layer BatchNorm4
I1007 12:33:17.210500  4874 net.cpp:406] BatchNorm4 <- Convolution4
I1007 12:33:17.210503  4874 net.cpp:367] BatchNorm4 -> Convolution4 (in-place)
I1007 12:33:17.210623  4874 net.cpp:122] Setting up BatchNorm4
I1007 12:33:17.210628  4874 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 12:33:17.210633  4874 net.cpp:137] Memory required for data: 96275600
I1007 12:33:17.210638  4874 layer_factory.hpp:77] Creating layer Scale4
I1007 12:33:17.210641  4874 net.cpp:84] Creating Layer Scale4
I1007 12:33:17.210644  4874 net.cpp:406] Scale4 <- Convolution4
I1007 12:33:17.210649  4874 net.cpp:367] Scale4 -> Convolution4 (in-place)
I1007 12:33:17.210674  4874 layer_factory.hpp:77] Creating layer Scale4
I1007 12:33:17.210744  4874 net.cpp:122] Setting up Scale4
I1007 12:33:17.210749  4874 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 12:33:17.210752  4874 net.cpp:137] Memory required for data: 101293200
I1007 12:33:17.210759  4874 layer_factory.hpp:77] Creating layer M2PELU4
I1007 12:33:17.210765  4874 net.cpp:84] Creating Layer M2PELU4
I1007 12:33:17.210768  4874 net.cpp:406] M2PELU4 <- Convolution4
I1007 12:33:17.210772  4874 net.cpp:367] M2PELU4 -> Convolution4 (in-place)
I1007 12:33:17.210849  4874 net.cpp:122] Setting up M2PELU4
I1007 12:33:17.210853  4874 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 12:33:17.210856  4874 net.cpp:137] Memory required for data: 106310800
I1007 12:33:17.210860  4874 layer_factory.hpp:77] Creating layer Convolution5
I1007 12:33:17.210867  4874 net.cpp:84] Creating Layer Convolution5
I1007 12:33:17.210870  4874 net.cpp:406] Convolution5 <- Convolution4
I1007 12:33:17.210875  4874 net.cpp:380] Convolution5 -> Convolution5
I1007 12:33:17.211740  4874 net.cpp:122] Setting up Convolution5
I1007 12:33:17.211751  4874 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 12:33:17.211755  4874 net.cpp:137] Memory required for data: 111328400
I1007 12:33:17.211760  4874 layer_factory.hpp:77] Creating layer BatchNorm5
I1007 12:33:17.211766  4874 net.cpp:84] Creating Layer BatchNorm5
I1007 12:33:17.211769  4874 net.cpp:406] BatchNorm5 <- Convolution5
I1007 12:33:17.211772  4874 net.cpp:367] BatchNorm5 -> Convolution5 (in-place)
I1007 12:33:17.211894  4874 net.cpp:122] Setting up BatchNorm5
I1007 12:33:17.211899  4874 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 12:33:17.211901  4874 net.cpp:137] Memory required for data: 116346000
I1007 12:33:17.211906  4874 layer_factory.hpp:77] Creating layer Scale5
I1007 12:33:17.211911  4874 net.cpp:84] Creating Layer Scale5
I1007 12:33:17.211915  4874 net.cpp:406] Scale5 <- Convolution5
I1007 12:33:17.211918  4874 net.cpp:367] Scale5 -> Convolution5 (in-place)
I1007 12:33:17.211943  4874 layer_factory.hpp:77] Creating layer Scale5
I1007 12:33:17.212016  4874 net.cpp:122] Setting up Scale5
I1007 12:33:17.212021  4874 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 12:33:17.212024  4874 net.cpp:137] Memory required for data: 121363600
I1007 12:33:17.212028  4874 layer_factory.hpp:77] Creating layer Eltwise2
I1007 12:33:17.212033  4874 net.cpp:84] Creating Layer Eltwise2
I1007 12:33:17.212035  4874 net.cpp:406] Eltwise2 <- Eltwise1_M2PELU3_0_split_1
I1007 12:33:17.212038  4874 net.cpp:406] Eltwise2 <- Convolution5
I1007 12:33:17.212041  4874 net.cpp:380] Eltwise2 -> Eltwise2
I1007 12:33:17.212056  4874 net.cpp:122] Setting up Eltwise2
I1007 12:33:17.212060  4874 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 12:33:17.212064  4874 net.cpp:137] Memory required for data: 126381200
I1007 12:33:17.212066  4874 layer_factory.hpp:77] Creating layer M2PELU5
I1007 12:33:17.212070  4874 net.cpp:84] Creating Layer M2PELU5
I1007 12:33:17.212074  4874 net.cpp:406] M2PELU5 <- Eltwise2
I1007 12:33:17.212077  4874 net.cpp:367] M2PELU5 -> Eltwise2 (in-place)
I1007 12:33:17.212154  4874 net.cpp:122] Setting up M2PELU5
I1007 12:33:17.212159  4874 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 12:33:17.212162  4874 net.cpp:137] Memory required for data: 131398800
I1007 12:33:17.212167  4874 layer_factory.hpp:77] Creating layer Eltwise2_M2PELU5_0_split
I1007 12:33:17.212177  4874 net.cpp:84] Creating Layer Eltwise2_M2PELU5_0_split
I1007 12:33:17.212180  4874 net.cpp:406] Eltwise2_M2PELU5_0_split <- Eltwise2
I1007 12:33:17.212184  4874 net.cpp:380] Eltwise2_M2PELU5_0_split -> Eltwise2_M2PELU5_0_split_0
I1007 12:33:17.212189  4874 net.cpp:380] Eltwise2_M2PELU5_0_split -> Eltwise2_M2PELU5_0_split_1
I1007 12:33:17.212213  4874 net.cpp:122] Setting up Eltwise2_M2PELU5_0_split
I1007 12:33:17.212218  4874 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 12:33:17.212220  4874 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 12:33:17.212224  4874 net.cpp:137] Memory required for data: 141434000
I1007 12:33:17.212226  4874 layer_factory.hpp:77] Creating layer Convolution6
I1007 12:33:17.212232  4874 net.cpp:84] Creating Layer Convolution6
I1007 12:33:17.212235  4874 net.cpp:406] Convolution6 <- Eltwise2_M2PELU5_0_split_0
I1007 12:33:17.212239  4874 net.cpp:380] Convolution6 -> Convolution6
I1007 12:33:17.213101  4874 net.cpp:122] Setting up Convolution6
I1007 12:33:17.213111  4874 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 12:33:17.213115  4874 net.cpp:137] Memory required for data: 146451600
I1007 12:33:17.213120  4874 layer_factory.hpp:77] Creating layer BatchNorm6
I1007 12:33:17.213125  4874 net.cpp:84] Creating Layer BatchNorm6
I1007 12:33:17.213129  4874 net.cpp:406] BatchNorm6 <- Convolution6
I1007 12:33:17.213132  4874 net.cpp:367] BatchNorm6 -> Convolution6 (in-place)
I1007 12:33:17.213258  4874 net.cpp:122] Setting up BatchNorm6
I1007 12:33:17.213263  4874 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 12:33:17.213265  4874 net.cpp:137] Memory required for data: 151469200
I1007 12:33:17.213270  4874 layer_factory.hpp:77] Creating layer Scale6
I1007 12:33:17.213275  4874 net.cpp:84] Creating Layer Scale6
I1007 12:33:17.213279  4874 net.cpp:406] Scale6 <- Convolution6
I1007 12:33:17.213281  4874 net.cpp:367] Scale6 -> Convolution6 (in-place)
I1007 12:33:17.213307  4874 layer_factory.hpp:77] Creating layer Scale6
I1007 12:33:17.213380  4874 net.cpp:122] Setting up Scale6
I1007 12:33:17.213385  4874 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 12:33:17.213388  4874 net.cpp:137] Memory required for data: 156486800
I1007 12:33:17.213392  4874 layer_factory.hpp:77] Creating layer M2PELU6
I1007 12:33:17.213398  4874 net.cpp:84] Creating Layer M2PELU6
I1007 12:33:17.213402  4874 net.cpp:406] M2PELU6 <- Convolution6
I1007 12:33:17.213405  4874 net.cpp:367] M2PELU6 -> Convolution6 (in-place)
I1007 12:33:17.213486  4874 net.cpp:122] Setting up M2PELU6
I1007 12:33:17.213491  4874 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 12:33:17.213495  4874 net.cpp:137] Memory required for data: 161504400
I1007 12:33:17.213498  4874 layer_factory.hpp:77] Creating layer Convolution7
I1007 12:33:17.213505  4874 net.cpp:84] Creating Layer Convolution7
I1007 12:33:17.213508  4874 net.cpp:406] Convolution7 <- Convolution6
I1007 12:33:17.213512  4874 net.cpp:380] Convolution7 -> Convolution7
I1007 12:33:17.214042  4874 net.cpp:122] Setting up Convolution7
I1007 12:33:17.214051  4874 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 12:33:17.214056  4874 net.cpp:137] Memory required for data: 166522000
I1007 12:33:17.214059  4874 layer_factory.hpp:77] Creating layer BatchNorm7
I1007 12:33:17.214064  4874 net.cpp:84] Creating Layer BatchNorm7
I1007 12:33:17.214067  4874 net.cpp:406] BatchNorm7 <- Convolution7
I1007 12:33:17.214071  4874 net.cpp:367] BatchNorm7 -> Convolution7 (in-place)
I1007 12:33:17.214195  4874 net.cpp:122] Setting up BatchNorm7
I1007 12:33:17.214200  4874 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 12:33:17.214203  4874 net.cpp:137] Memory required for data: 171539600
I1007 12:33:17.214208  4874 layer_factory.hpp:77] Creating layer Scale7
I1007 12:33:17.214215  4874 net.cpp:84] Creating Layer Scale7
I1007 12:33:17.214218  4874 net.cpp:406] Scale7 <- Convolution7
I1007 12:33:17.214221  4874 net.cpp:367] Scale7 -> Convolution7 (in-place)
I1007 12:33:17.214246  4874 layer_factory.hpp:77] Creating layer Scale7
I1007 12:33:17.214328  4874 net.cpp:122] Setting up Scale7
I1007 12:33:17.214334  4874 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 12:33:17.214336  4874 net.cpp:137] Memory required for data: 176557200
I1007 12:33:17.214340  4874 layer_factory.hpp:77] Creating layer Eltwise3
I1007 12:33:17.214345  4874 net.cpp:84] Creating Layer Eltwise3
I1007 12:33:17.214349  4874 net.cpp:406] Eltwise3 <- Eltwise2_M2PELU5_0_split_1
I1007 12:33:17.214351  4874 net.cpp:406] Eltwise3 <- Convolution7
I1007 12:33:17.214355  4874 net.cpp:380] Eltwise3 -> Eltwise3
I1007 12:33:17.214370  4874 net.cpp:122] Setting up Eltwise3
I1007 12:33:17.214375  4874 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 12:33:17.214378  4874 net.cpp:137] Memory required for data: 181574800
I1007 12:33:17.214380  4874 layer_factory.hpp:77] Creating layer M2PELU7
I1007 12:33:17.214385  4874 net.cpp:84] Creating Layer M2PELU7
I1007 12:33:17.214388  4874 net.cpp:406] M2PELU7 <- Eltwise3
I1007 12:33:17.214391  4874 net.cpp:367] M2PELU7 -> Eltwise3 (in-place)
I1007 12:33:17.214471  4874 net.cpp:122] Setting up M2PELU7
I1007 12:33:17.214476  4874 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 12:33:17.214479  4874 net.cpp:137] Memory required for data: 186592400
I1007 12:33:17.214483  4874 layer_factory.hpp:77] Creating layer Eltwise3_M2PELU7_0_split
I1007 12:33:17.214488  4874 net.cpp:84] Creating Layer Eltwise3_M2PELU7_0_split
I1007 12:33:17.214490  4874 net.cpp:406] Eltwise3_M2PELU7_0_split <- Eltwise3
I1007 12:33:17.214494  4874 net.cpp:380] Eltwise3_M2PELU7_0_split -> Eltwise3_M2PELU7_0_split_0
I1007 12:33:17.214498  4874 net.cpp:380] Eltwise3_M2PELU7_0_split -> Eltwise3_M2PELU7_0_split_1
I1007 12:33:17.214520  4874 net.cpp:122] Setting up Eltwise3_M2PELU7_0_split
I1007 12:33:17.214524  4874 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 12:33:17.214529  4874 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 12:33:17.214531  4874 net.cpp:137] Memory required for data: 196627600
I1007 12:33:17.214534  4874 layer_factory.hpp:77] Creating layer Convolution8
I1007 12:33:17.214540  4874 net.cpp:84] Creating Layer Convolution8
I1007 12:33:17.214543  4874 net.cpp:406] Convolution8 <- Eltwise3_M2PELU7_0_split_0
I1007 12:33:17.214547  4874 net.cpp:380] Convolution8 -> Convolution8
I1007 12:33:17.215409  4874 net.cpp:122] Setting up Convolution8
I1007 12:33:17.215420  4874 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 12:33:17.215423  4874 net.cpp:137] Memory required for data: 201645200
I1007 12:33:17.215433  4874 layer_factory.hpp:77] Creating layer BatchNorm8
I1007 12:33:17.215438  4874 net.cpp:84] Creating Layer BatchNorm8
I1007 12:33:17.215442  4874 net.cpp:406] BatchNorm8 <- Convolution8
I1007 12:33:17.215445  4874 net.cpp:367] BatchNorm8 -> Convolution8 (in-place)
I1007 12:33:17.215571  4874 net.cpp:122] Setting up BatchNorm8
I1007 12:33:17.215576  4874 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 12:33:17.215579  4874 net.cpp:137] Memory required for data: 206662800
I1007 12:33:17.215585  4874 layer_factory.hpp:77] Creating layer Scale8
I1007 12:33:17.215590  4874 net.cpp:84] Creating Layer Scale8
I1007 12:33:17.215593  4874 net.cpp:406] Scale8 <- Convolution8
I1007 12:33:17.215596  4874 net.cpp:367] Scale8 -> Convolution8 (in-place)
I1007 12:33:17.215622  4874 layer_factory.hpp:77] Creating layer Scale8
I1007 12:33:17.215697  4874 net.cpp:122] Setting up Scale8
I1007 12:33:17.215701  4874 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 12:33:17.215704  4874 net.cpp:137] Memory required for data: 211680400
I1007 12:33:17.215708  4874 layer_factory.hpp:77] Creating layer M2PELU8
I1007 12:33:17.215714  4874 net.cpp:84] Creating Layer M2PELU8
I1007 12:33:17.215718  4874 net.cpp:406] M2PELU8 <- Convolution8
I1007 12:33:17.215720  4874 net.cpp:367] M2PELU8 -> Convolution8 (in-place)
I1007 12:33:17.215801  4874 net.cpp:122] Setting up M2PELU8
I1007 12:33:17.215806  4874 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 12:33:17.215809  4874 net.cpp:137] Memory required for data: 216698000
I1007 12:33:17.215821  4874 layer_factory.hpp:77] Creating layer Convolution9
I1007 12:33:17.215828  4874 net.cpp:84] Creating Layer Convolution9
I1007 12:33:17.215831  4874 net.cpp:406] Convolution9 <- Convolution8
I1007 12:33:17.215836  4874 net.cpp:380] Convolution9 -> Convolution9
I1007 12:33:17.216696  4874 net.cpp:122] Setting up Convolution9
I1007 12:33:17.216707  4874 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 12:33:17.216711  4874 net.cpp:137] Memory required for data: 221715600
I1007 12:33:17.216715  4874 layer_factory.hpp:77] Creating layer BatchNorm9
I1007 12:33:17.216722  4874 net.cpp:84] Creating Layer BatchNorm9
I1007 12:33:17.216724  4874 net.cpp:406] BatchNorm9 <- Convolution9
I1007 12:33:17.216728  4874 net.cpp:367] BatchNorm9 -> Convolution9 (in-place)
I1007 12:33:17.216853  4874 net.cpp:122] Setting up BatchNorm9
I1007 12:33:17.216859  4874 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 12:33:17.216862  4874 net.cpp:137] Memory required for data: 226733200
I1007 12:33:17.216867  4874 layer_factory.hpp:77] Creating layer Scale9
I1007 12:33:17.216871  4874 net.cpp:84] Creating Layer Scale9
I1007 12:33:17.216873  4874 net.cpp:406] Scale9 <- Convolution9
I1007 12:33:17.216878  4874 net.cpp:367] Scale9 -> Convolution9 (in-place)
I1007 12:33:17.216904  4874 layer_factory.hpp:77] Creating layer Scale9
I1007 12:33:17.216979  4874 net.cpp:122] Setting up Scale9
I1007 12:33:17.216984  4874 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 12:33:17.216987  4874 net.cpp:137] Memory required for data: 231750800
I1007 12:33:17.216991  4874 layer_factory.hpp:77] Creating layer Eltwise4
I1007 12:33:17.216995  4874 net.cpp:84] Creating Layer Eltwise4
I1007 12:33:17.216998  4874 net.cpp:406] Eltwise4 <- Eltwise3_M2PELU7_0_split_1
I1007 12:33:17.217002  4874 net.cpp:406] Eltwise4 <- Convolution9
I1007 12:33:17.217006  4874 net.cpp:380] Eltwise4 -> Eltwise4
I1007 12:33:17.217020  4874 net.cpp:122] Setting up Eltwise4
I1007 12:33:17.217025  4874 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 12:33:17.217027  4874 net.cpp:137] Memory required for data: 236768400
I1007 12:33:17.217031  4874 layer_factory.hpp:77] Creating layer M2PELU9
I1007 12:33:17.217036  4874 net.cpp:84] Creating Layer M2PELU9
I1007 12:33:17.217038  4874 net.cpp:406] M2PELU9 <- Eltwise4
I1007 12:33:17.217041  4874 net.cpp:367] M2PELU9 -> Eltwise4 (in-place)
I1007 12:33:17.217125  4874 net.cpp:122] Setting up M2PELU9
I1007 12:33:17.217130  4874 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 12:33:17.217133  4874 net.cpp:137] Memory required for data: 241786000
I1007 12:33:17.217137  4874 layer_factory.hpp:77] Creating layer Eltwise4_M2PELU9_0_split
I1007 12:33:17.217140  4874 net.cpp:84] Creating Layer Eltwise4_M2PELU9_0_split
I1007 12:33:17.217144  4874 net.cpp:406] Eltwise4_M2PELU9_0_split <- Eltwise4
I1007 12:33:17.217146  4874 net.cpp:380] Eltwise4_M2PELU9_0_split -> Eltwise4_M2PELU9_0_split_0
I1007 12:33:17.217151  4874 net.cpp:380] Eltwise4_M2PELU9_0_split -> Eltwise4_M2PELU9_0_split_1
I1007 12:33:17.217173  4874 net.cpp:122] Setting up Eltwise4_M2PELU9_0_split
I1007 12:33:17.217178  4874 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 12:33:17.217181  4874 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 12:33:17.217185  4874 net.cpp:137] Memory required for data: 251821200
I1007 12:33:17.217187  4874 layer_factory.hpp:77] Creating layer Convolution10
I1007 12:33:17.217193  4874 net.cpp:84] Creating Layer Convolution10
I1007 12:33:17.217196  4874 net.cpp:406] Convolution10 <- Eltwise4_M2PELU9_0_split_0
I1007 12:33:17.217200  4874 net.cpp:380] Convolution10 -> Convolution10
I1007 12:33:17.218065  4874 net.cpp:122] Setting up Convolution10
I1007 12:33:17.218075  4874 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 12:33:17.218078  4874 net.cpp:137] Memory required for data: 256838800
I1007 12:33:17.218083  4874 layer_factory.hpp:77] Creating layer BatchNorm10
I1007 12:33:17.218089  4874 net.cpp:84] Creating Layer BatchNorm10
I1007 12:33:17.218092  4874 net.cpp:406] BatchNorm10 <- Convolution10
I1007 12:33:17.218103  4874 net.cpp:367] BatchNorm10 -> Convolution10 (in-place)
I1007 12:33:17.218232  4874 net.cpp:122] Setting up BatchNorm10
I1007 12:33:17.218237  4874 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 12:33:17.218240  4874 net.cpp:137] Memory required for data: 261856400
I1007 12:33:17.218246  4874 layer_factory.hpp:77] Creating layer Scale10
I1007 12:33:17.218251  4874 net.cpp:84] Creating Layer Scale10
I1007 12:33:17.218253  4874 net.cpp:406] Scale10 <- Convolution10
I1007 12:33:17.218257  4874 net.cpp:367] Scale10 -> Convolution10 (in-place)
I1007 12:33:17.218283  4874 layer_factory.hpp:77] Creating layer Scale10
I1007 12:33:17.218358  4874 net.cpp:122] Setting up Scale10
I1007 12:33:17.218364  4874 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 12:33:17.218367  4874 net.cpp:137] Memory required for data: 266874000
I1007 12:33:17.218371  4874 layer_factory.hpp:77] Creating layer M2PELU10
I1007 12:33:17.218377  4874 net.cpp:84] Creating Layer M2PELU10
I1007 12:33:17.218380  4874 net.cpp:406] M2PELU10 <- Convolution10
I1007 12:33:17.218384  4874 net.cpp:367] M2PELU10 -> Convolution10 (in-place)
I1007 12:33:17.218464  4874 net.cpp:122] Setting up M2PELU10
I1007 12:33:17.218471  4874 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 12:33:17.218473  4874 net.cpp:137] Memory required for data: 271891600
I1007 12:33:17.218477  4874 layer_factory.hpp:77] Creating layer Convolution11
I1007 12:33:17.218484  4874 net.cpp:84] Creating Layer Convolution11
I1007 12:33:17.218487  4874 net.cpp:406] Convolution11 <- Convolution10
I1007 12:33:17.218492  4874 net.cpp:380] Convolution11 -> Convolution11
I1007 12:33:17.219403  4874 net.cpp:122] Setting up Convolution11
I1007 12:33:17.219414  4874 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 12:33:17.219419  4874 net.cpp:137] Memory required for data: 276909200
I1007 12:33:17.219424  4874 layer_factory.hpp:77] Creating layer BatchNorm11
I1007 12:33:17.219429  4874 net.cpp:84] Creating Layer BatchNorm11
I1007 12:33:17.219432  4874 net.cpp:406] BatchNorm11 <- Convolution11
I1007 12:33:17.219436  4874 net.cpp:367] BatchNorm11 -> Convolution11 (in-place)
I1007 12:33:17.219564  4874 net.cpp:122] Setting up BatchNorm11
I1007 12:33:17.219570  4874 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 12:33:17.219573  4874 net.cpp:137] Memory required for data: 281926800
I1007 12:33:17.219578  4874 layer_factory.hpp:77] Creating layer Scale11
I1007 12:33:17.219583  4874 net.cpp:84] Creating Layer Scale11
I1007 12:33:17.219585  4874 net.cpp:406] Scale11 <- Convolution11
I1007 12:33:17.219589  4874 net.cpp:367] Scale11 -> Convolution11 (in-place)
I1007 12:33:17.219615  4874 layer_factory.hpp:77] Creating layer Scale11
I1007 12:33:17.219692  4874 net.cpp:122] Setting up Scale11
I1007 12:33:17.219697  4874 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 12:33:17.219702  4874 net.cpp:137] Memory required for data: 286944400
I1007 12:33:17.219705  4874 layer_factory.hpp:77] Creating layer Eltwise5
I1007 12:33:17.219710  4874 net.cpp:84] Creating Layer Eltwise5
I1007 12:33:17.219713  4874 net.cpp:406] Eltwise5 <- Eltwise4_M2PELU9_0_split_1
I1007 12:33:17.219717  4874 net.cpp:406] Eltwise5 <- Convolution11
I1007 12:33:17.219720  4874 net.cpp:380] Eltwise5 -> Eltwise5
I1007 12:33:17.219735  4874 net.cpp:122] Setting up Eltwise5
I1007 12:33:17.219740  4874 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 12:33:17.219744  4874 net.cpp:137] Memory required for data: 291962000
I1007 12:33:17.219746  4874 layer_factory.hpp:77] Creating layer M2PELU11
I1007 12:33:17.219751  4874 net.cpp:84] Creating Layer M2PELU11
I1007 12:33:17.219754  4874 net.cpp:406] M2PELU11 <- Eltwise5
I1007 12:33:17.219758  4874 net.cpp:367] M2PELU11 -> Eltwise5 (in-place)
I1007 12:33:17.219842  4874 net.cpp:122] Setting up M2PELU11
I1007 12:33:17.219848  4874 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 12:33:17.219851  4874 net.cpp:137] Memory required for data: 296979600
I1007 12:33:17.219856  4874 layer_factory.hpp:77] Creating layer Eltwise5_M2PELU11_0_split
I1007 12:33:17.219867  4874 net.cpp:84] Creating Layer Eltwise5_M2PELU11_0_split
I1007 12:33:17.219871  4874 net.cpp:406] Eltwise5_M2PELU11_0_split <- Eltwise5
I1007 12:33:17.219873  4874 net.cpp:380] Eltwise5_M2PELU11_0_split -> Eltwise5_M2PELU11_0_split_0
I1007 12:33:17.219878  4874 net.cpp:380] Eltwise5_M2PELU11_0_split -> Eltwise5_M2PELU11_0_split_1
I1007 12:33:17.219902  4874 net.cpp:122] Setting up Eltwise5_M2PELU11_0_split
I1007 12:33:17.219907  4874 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 12:33:17.219911  4874 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 12:33:17.219913  4874 net.cpp:137] Memory required for data: 307014800
I1007 12:33:17.219916  4874 layer_factory.hpp:77] Creating layer Convolution12
I1007 12:33:17.219923  4874 net.cpp:84] Creating Layer Convolution12
I1007 12:33:17.219925  4874 net.cpp:406] Convolution12 <- Eltwise5_M2PELU11_0_split_0
I1007 12:33:17.219930  4874 net.cpp:380] Convolution12 -> Convolution12
I1007 12:33:17.221089  4874 net.cpp:122] Setting up Convolution12
I1007 12:33:17.221101  4874 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 12:33:17.221104  4874 net.cpp:137] Memory required for data: 309523600
I1007 12:33:17.221109  4874 layer_factory.hpp:77] Creating layer BatchNorm12
I1007 12:33:17.221115  4874 net.cpp:84] Creating Layer BatchNorm12
I1007 12:33:17.221118  4874 net.cpp:406] BatchNorm12 <- Convolution12
I1007 12:33:17.221122  4874 net.cpp:367] BatchNorm12 -> Convolution12 (in-place)
I1007 12:33:17.221261  4874 net.cpp:122] Setting up BatchNorm12
I1007 12:33:17.221266  4874 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 12:33:17.221269  4874 net.cpp:137] Memory required for data: 312032400
I1007 12:33:17.221274  4874 layer_factory.hpp:77] Creating layer Scale12
I1007 12:33:17.221279  4874 net.cpp:84] Creating Layer Scale12
I1007 12:33:17.221282  4874 net.cpp:406] Scale12 <- Convolution12
I1007 12:33:17.221287  4874 net.cpp:367] Scale12 -> Convolution12 (in-place)
I1007 12:33:17.221312  4874 layer_factory.hpp:77] Creating layer Scale12
I1007 12:33:17.221386  4874 net.cpp:122] Setting up Scale12
I1007 12:33:17.221392  4874 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 12:33:17.221395  4874 net.cpp:137] Memory required for data: 314541200
I1007 12:33:17.221400  4874 layer_factory.hpp:77] Creating layer Convolution13
I1007 12:33:17.221406  4874 net.cpp:84] Creating Layer Convolution13
I1007 12:33:17.221410  4874 net.cpp:406] Convolution13 <- Eltwise5_M2PELU11_0_split_1
I1007 12:33:17.221415  4874 net.cpp:380] Convolution13 -> Convolution13
I1007 12:33:17.222661  4874 net.cpp:122] Setting up Convolution13
I1007 12:33:17.222672  4874 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 12:33:17.222676  4874 net.cpp:137] Memory required for data: 317050000
I1007 12:33:17.222681  4874 layer_factory.hpp:77] Creating layer BatchNorm13
I1007 12:33:17.222687  4874 net.cpp:84] Creating Layer BatchNorm13
I1007 12:33:17.222690  4874 net.cpp:406] BatchNorm13 <- Convolution13
I1007 12:33:17.222694  4874 net.cpp:367] BatchNorm13 -> Convolution13 (in-place)
I1007 12:33:17.222827  4874 net.cpp:122] Setting up BatchNorm13
I1007 12:33:17.222833  4874 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 12:33:17.222836  4874 net.cpp:137] Memory required for data: 319558800
I1007 12:33:17.222841  4874 layer_factory.hpp:77] Creating layer Scale13
I1007 12:33:17.222846  4874 net.cpp:84] Creating Layer Scale13
I1007 12:33:17.222849  4874 net.cpp:406] Scale13 <- Convolution13
I1007 12:33:17.222853  4874 net.cpp:367] Scale13 -> Convolution13 (in-place)
I1007 12:33:17.222879  4874 layer_factory.hpp:77] Creating layer Scale13
I1007 12:33:17.222952  4874 net.cpp:122] Setting up Scale13
I1007 12:33:17.222959  4874 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 12:33:17.222961  4874 net.cpp:137] Memory required for data: 322067600
I1007 12:33:17.222965  4874 layer_factory.hpp:77] Creating layer M2PELU12
I1007 12:33:17.222971  4874 net.cpp:84] Creating Layer M2PELU12
I1007 12:33:17.222975  4874 net.cpp:406] M2PELU12 <- Convolution13
I1007 12:33:17.222978  4874 net.cpp:367] M2PELU12 -> Convolution13 (in-place)
I1007 12:33:17.223068  4874 net.cpp:122] Setting up M2PELU12
I1007 12:33:17.223074  4874 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 12:33:17.223078  4874 net.cpp:137] Memory required for data: 324576400
I1007 12:33:17.223081  4874 layer_factory.hpp:77] Creating layer Convolution14
I1007 12:33:17.223088  4874 net.cpp:84] Creating Layer Convolution14
I1007 12:33:17.223093  4874 net.cpp:406] Convolution14 <- Convolution13
I1007 12:33:17.223096  4874 net.cpp:380] Convolution14 -> Convolution14
I1007 12:33:17.224139  4874 net.cpp:122] Setting up Convolution14
I1007 12:33:17.224150  4874 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 12:33:17.224154  4874 net.cpp:137] Memory required for data: 327085200
I1007 12:33:17.224159  4874 layer_factory.hpp:77] Creating layer BatchNorm14
I1007 12:33:17.224167  4874 net.cpp:84] Creating Layer BatchNorm14
I1007 12:33:17.224171  4874 net.cpp:406] BatchNorm14 <- Convolution14
I1007 12:33:17.224175  4874 net.cpp:367] BatchNorm14 -> Convolution14 (in-place)
I1007 12:33:17.224303  4874 net.cpp:122] Setting up BatchNorm14
I1007 12:33:17.224308  4874 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 12:33:17.224313  4874 net.cpp:137] Memory required for data: 329594000
I1007 12:33:17.224318  4874 layer_factory.hpp:77] Creating layer Scale14
I1007 12:33:17.224323  4874 net.cpp:84] Creating Layer Scale14
I1007 12:33:17.224325  4874 net.cpp:406] Scale14 <- Convolution14
I1007 12:33:17.224328  4874 net.cpp:367] Scale14 -> Convolution14 (in-place)
I1007 12:33:17.224355  4874 layer_factory.hpp:77] Creating layer Scale14
I1007 12:33:17.224427  4874 net.cpp:122] Setting up Scale14
I1007 12:33:17.224433  4874 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 12:33:17.224436  4874 net.cpp:137] Memory required for data: 332102800
I1007 12:33:17.224440  4874 layer_factory.hpp:77] Creating layer Eltwise6
I1007 12:33:17.224445  4874 net.cpp:84] Creating Layer Eltwise6
I1007 12:33:17.224448  4874 net.cpp:406] Eltwise6 <- Convolution12
I1007 12:33:17.224452  4874 net.cpp:406] Eltwise6 <- Convolution14
I1007 12:33:17.224455  4874 net.cpp:380] Eltwise6 -> Eltwise6
I1007 12:33:17.224470  4874 net.cpp:122] Setting up Eltwise6
I1007 12:33:17.224473  4874 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 12:33:17.224476  4874 net.cpp:137] Memory required for data: 334611600
I1007 12:33:17.224478  4874 layer_factory.hpp:77] Creating layer M2PELU13
I1007 12:33:17.224483  4874 net.cpp:84] Creating Layer M2PELU13
I1007 12:33:17.224485  4874 net.cpp:406] M2PELU13 <- Eltwise6
I1007 12:33:17.224488  4874 net.cpp:367] M2PELU13 -> Eltwise6 (in-place)
I1007 12:33:17.224570  4874 net.cpp:122] Setting up M2PELU13
I1007 12:33:17.224573  4874 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 12:33:17.224575  4874 net.cpp:137] Memory required for data: 337120400
I1007 12:33:17.224580  4874 layer_factory.hpp:77] Creating layer Eltwise6_M2PELU13_0_split
I1007 12:33:17.224583  4874 net.cpp:84] Creating Layer Eltwise6_M2PELU13_0_split
I1007 12:33:17.224586  4874 net.cpp:406] Eltwise6_M2PELU13_0_split <- Eltwise6
I1007 12:33:17.224588  4874 net.cpp:380] Eltwise6_M2PELU13_0_split -> Eltwise6_M2PELU13_0_split_0
I1007 12:33:17.224592  4874 net.cpp:380] Eltwise6_M2PELU13_0_split -> Eltwise6_M2PELU13_0_split_1
I1007 12:33:17.224614  4874 net.cpp:122] Setting up Eltwise6_M2PELU13_0_split
I1007 12:33:17.224618  4874 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 12:33:17.224622  4874 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 12:33:17.224623  4874 net.cpp:137] Memory required for data: 342138000
I1007 12:33:17.224627  4874 layer_factory.hpp:77] Creating layer Convolution15
I1007 12:33:17.224632  4874 net.cpp:84] Creating Layer Convolution15
I1007 12:33:17.224634  4874 net.cpp:406] Convolution15 <- Eltwise6_M2PELU13_0_split_0
I1007 12:33:17.224638  4874 net.cpp:380] Convolution15 -> Convolution15
I1007 12:33:17.225656  4874 net.cpp:122] Setting up Convolution15
I1007 12:33:17.225666  4874 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 12:33:17.225668  4874 net.cpp:137] Memory required for data: 344646800
I1007 12:33:17.225679  4874 layer_factory.hpp:77] Creating layer BatchNorm15
I1007 12:33:17.225684  4874 net.cpp:84] Creating Layer BatchNorm15
I1007 12:33:17.225687  4874 net.cpp:406] BatchNorm15 <- Convolution15
I1007 12:33:17.225692  4874 net.cpp:367] BatchNorm15 -> Convolution15 (in-place)
I1007 12:33:17.225818  4874 net.cpp:122] Setting up BatchNorm15
I1007 12:33:17.225823  4874 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 12:33:17.225826  4874 net.cpp:137] Memory required for data: 347155600
I1007 12:33:17.225838  4874 layer_factory.hpp:77] Creating layer Scale15
I1007 12:33:17.225842  4874 net.cpp:84] Creating Layer Scale15
I1007 12:33:17.225845  4874 net.cpp:406] Scale15 <- Convolution15
I1007 12:33:17.225848  4874 net.cpp:367] Scale15 -> Convolution15 (in-place)
I1007 12:33:17.225874  4874 layer_factory.hpp:77] Creating layer Scale15
I1007 12:33:17.225945  4874 net.cpp:122] Setting up Scale15
I1007 12:33:17.225950  4874 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 12:33:17.225951  4874 net.cpp:137] Memory required for data: 349664400
I1007 12:33:17.225956  4874 layer_factory.hpp:77] Creating layer M2PELU14
I1007 12:33:17.225960  4874 net.cpp:84] Creating Layer M2PELU14
I1007 12:33:17.225963  4874 net.cpp:406] M2PELU14 <- Convolution15
I1007 12:33:17.225966  4874 net.cpp:367] M2PELU14 -> Convolution15 (in-place)
I1007 12:33:17.226047  4874 net.cpp:122] Setting up M2PELU14
I1007 12:33:17.226050  4874 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 12:33:17.226052  4874 net.cpp:137] Memory required for data: 352173200
I1007 12:33:17.226056  4874 layer_factory.hpp:77] Creating layer Convolution16
I1007 12:33:17.226063  4874 net.cpp:84] Creating Layer Convolution16
I1007 12:33:17.226065  4874 net.cpp:406] Convolution16 <- Convolution15
I1007 12:33:17.226068  4874 net.cpp:380] Convolution16 -> Convolution16
I1007 12:33:17.227082  4874 net.cpp:122] Setting up Convolution16
I1007 12:33:17.227092  4874 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 12:33:17.227095  4874 net.cpp:137] Memory required for data: 354682000
I1007 12:33:17.227100  4874 layer_factory.hpp:77] Creating layer BatchNorm16
I1007 12:33:17.227104  4874 net.cpp:84] Creating Layer BatchNorm16
I1007 12:33:17.227108  4874 net.cpp:406] BatchNorm16 <- Convolution16
I1007 12:33:17.227111  4874 net.cpp:367] BatchNorm16 -> Convolution16 (in-place)
I1007 12:33:17.227241  4874 net.cpp:122] Setting up BatchNorm16
I1007 12:33:17.227247  4874 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 12:33:17.227249  4874 net.cpp:137] Memory required for data: 357190800
I1007 12:33:17.227254  4874 layer_factory.hpp:77] Creating layer Scale16
I1007 12:33:17.227258  4874 net.cpp:84] Creating Layer Scale16
I1007 12:33:17.227262  4874 net.cpp:406] Scale16 <- Convolution16
I1007 12:33:17.227264  4874 net.cpp:367] Scale16 -> Convolution16 (in-place)
I1007 12:33:17.227289  4874 layer_factory.hpp:77] Creating layer Scale16
I1007 12:33:17.227361  4874 net.cpp:122] Setting up Scale16
I1007 12:33:17.227365  4874 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 12:33:17.227367  4874 net.cpp:137] Memory required for data: 359699600
I1007 12:33:17.227371  4874 layer_factory.hpp:77] Creating layer Eltwise7
I1007 12:33:17.227375  4874 net.cpp:84] Creating Layer Eltwise7
I1007 12:33:17.227378  4874 net.cpp:406] Eltwise7 <- Eltwise6_M2PELU13_0_split_1
I1007 12:33:17.227381  4874 net.cpp:406] Eltwise7 <- Convolution16
I1007 12:33:17.227385  4874 net.cpp:380] Eltwise7 -> Eltwise7
I1007 12:33:17.227399  4874 net.cpp:122] Setting up Eltwise7
I1007 12:33:17.227403  4874 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 12:33:17.227406  4874 net.cpp:137] Memory required for data: 362208400
I1007 12:33:17.227407  4874 layer_factory.hpp:77] Creating layer M2PELU15
I1007 12:33:17.227412  4874 net.cpp:84] Creating Layer M2PELU15
I1007 12:33:17.227414  4874 net.cpp:406] M2PELU15 <- Eltwise7
I1007 12:33:17.227418  4874 net.cpp:367] M2PELU15 -> Eltwise7 (in-place)
I1007 12:33:17.227497  4874 net.cpp:122] Setting up M2PELU15
I1007 12:33:17.227501  4874 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 12:33:17.227510  4874 net.cpp:137] Memory required for data: 364717200
I1007 12:33:17.227515  4874 layer_factory.hpp:77] Creating layer Eltwise7_M2PELU15_0_split
I1007 12:33:17.227519  4874 net.cpp:84] Creating Layer Eltwise7_M2PELU15_0_split
I1007 12:33:17.227521  4874 net.cpp:406] Eltwise7_M2PELU15_0_split <- Eltwise7
I1007 12:33:17.227525  4874 net.cpp:380] Eltwise7_M2PELU15_0_split -> Eltwise7_M2PELU15_0_split_0
I1007 12:33:17.227530  4874 net.cpp:380] Eltwise7_M2PELU15_0_split -> Eltwise7_M2PELU15_0_split_1
I1007 12:33:17.227551  4874 net.cpp:122] Setting up Eltwise7_M2PELU15_0_split
I1007 12:33:17.227555  4874 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 12:33:17.227558  4874 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 12:33:17.227560  4874 net.cpp:137] Memory required for data: 369734800
I1007 12:33:17.227562  4874 layer_factory.hpp:77] Creating layer Convolution17
I1007 12:33:17.227568  4874 net.cpp:84] Creating Layer Convolution17
I1007 12:33:17.227571  4874 net.cpp:406] Convolution17 <- Eltwise7_M2PELU15_0_split_0
I1007 12:33:17.227576  4874 net.cpp:380] Convolution17 -> Convolution17
I1007 12:33:17.228255  4874 net.cpp:122] Setting up Convolution17
I1007 12:33:17.228262  4874 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 12:33:17.228266  4874 net.cpp:137] Memory required for data: 372243600
I1007 12:33:17.228269  4874 layer_factory.hpp:77] Creating layer BatchNorm17
I1007 12:33:17.228274  4874 net.cpp:84] Creating Layer BatchNorm17
I1007 12:33:17.228276  4874 net.cpp:406] BatchNorm17 <- Convolution17
I1007 12:33:17.228281  4874 net.cpp:367] BatchNorm17 -> Convolution17 (in-place)
I1007 12:33:17.228404  4874 net.cpp:122] Setting up BatchNorm17
I1007 12:33:17.228408  4874 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 12:33:17.228410  4874 net.cpp:137] Memory required for data: 374752400
I1007 12:33:17.228415  4874 layer_factory.hpp:77] Creating layer Scale17
I1007 12:33:17.228420  4874 net.cpp:84] Creating Layer Scale17
I1007 12:33:17.228422  4874 net.cpp:406] Scale17 <- Convolution17
I1007 12:33:17.228425  4874 net.cpp:367] Scale17 -> Convolution17 (in-place)
I1007 12:33:17.228449  4874 layer_factory.hpp:77] Creating layer Scale17
I1007 12:33:17.228520  4874 net.cpp:122] Setting up Scale17
I1007 12:33:17.228524  4874 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 12:33:17.228526  4874 net.cpp:137] Memory required for data: 377261200
I1007 12:33:17.228530  4874 layer_factory.hpp:77] Creating layer M2PELU16
I1007 12:33:17.228535  4874 net.cpp:84] Creating Layer M2PELU16
I1007 12:33:17.228538  4874 net.cpp:406] M2PELU16 <- Convolution17
I1007 12:33:17.228541  4874 net.cpp:367] M2PELU16 -> Convolution17 (in-place)
I1007 12:33:17.228621  4874 net.cpp:122] Setting up M2PELU16
I1007 12:33:17.228624  4874 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 12:33:17.228626  4874 net.cpp:137] Memory required for data: 379770000
I1007 12:33:17.228631  4874 layer_factory.hpp:77] Creating layer Convolution18
I1007 12:33:17.228636  4874 net.cpp:84] Creating Layer Convolution18
I1007 12:33:17.228638  4874 net.cpp:406] Convolution18 <- Convolution17
I1007 12:33:17.228642  4874 net.cpp:380] Convolution18 -> Convolution18
I1007 12:33:17.229651  4874 net.cpp:122] Setting up Convolution18
I1007 12:33:17.229660  4874 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 12:33:17.229663  4874 net.cpp:137] Memory required for data: 382278800
I1007 12:33:17.229667  4874 layer_factory.hpp:77] Creating layer BatchNorm18
I1007 12:33:17.229672  4874 net.cpp:84] Creating Layer BatchNorm18
I1007 12:33:17.229676  4874 net.cpp:406] BatchNorm18 <- Convolution18
I1007 12:33:17.229678  4874 net.cpp:367] BatchNorm18 -> Convolution18 (in-place)
I1007 12:33:17.229805  4874 net.cpp:122] Setting up BatchNorm18
I1007 12:33:17.229809  4874 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 12:33:17.229812  4874 net.cpp:137] Memory required for data: 384787600
I1007 12:33:17.229816  4874 layer_factory.hpp:77] Creating layer Scale18
I1007 12:33:17.229821  4874 net.cpp:84] Creating Layer Scale18
I1007 12:33:17.229830  4874 net.cpp:406] Scale18 <- Convolution18
I1007 12:33:17.229833  4874 net.cpp:367] Scale18 -> Convolution18 (in-place)
I1007 12:33:17.229859  4874 layer_factory.hpp:77] Creating layer Scale18
I1007 12:33:17.229930  4874 net.cpp:122] Setting up Scale18
I1007 12:33:17.229935  4874 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 12:33:17.229938  4874 net.cpp:137] Memory required for data: 387296400
I1007 12:33:17.229941  4874 layer_factory.hpp:77] Creating layer Eltwise8
I1007 12:33:17.229945  4874 net.cpp:84] Creating Layer Eltwise8
I1007 12:33:17.229948  4874 net.cpp:406] Eltwise8 <- Eltwise7_M2PELU15_0_split_1
I1007 12:33:17.229951  4874 net.cpp:406] Eltwise8 <- Convolution18
I1007 12:33:17.229954  4874 net.cpp:380] Eltwise8 -> Eltwise8
I1007 12:33:17.229969  4874 net.cpp:122] Setting up Eltwise8
I1007 12:33:17.229972  4874 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 12:33:17.229974  4874 net.cpp:137] Memory required for data: 389805200
I1007 12:33:17.229977  4874 layer_factory.hpp:77] Creating layer M2PELU17
I1007 12:33:17.229981  4874 net.cpp:84] Creating Layer M2PELU17
I1007 12:33:17.229984  4874 net.cpp:406] M2PELU17 <- Eltwise8
I1007 12:33:17.229987  4874 net.cpp:367] M2PELU17 -> Eltwise8 (in-place)
I1007 12:33:17.230065  4874 net.cpp:122] Setting up M2PELU17
I1007 12:33:17.230070  4874 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 12:33:17.230072  4874 net.cpp:137] Memory required for data: 392314000
I1007 12:33:17.230077  4874 layer_factory.hpp:77] Creating layer Eltwise8_M2PELU17_0_split
I1007 12:33:17.230079  4874 net.cpp:84] Creating Layer Eltwise8_M2PELU17_0_split
I1007 12:33:17.230082  4874 net.cpp:406] Eltwise8_M2PELU17_0_split <- Eltwise8
I1007 12:33:17.230085  4874 net.cpp:380] Eltwise8_M2PELU17_0_split -> Eltwise8_M2PELU17_0_split_0
I1007 12:33:17.230089  4874 net.cpp:380] Eltwise8_M2PELU17_0_split -> Eltwise8_M2PELU17_0_split_1
I1007 12:33:17.230111  4874 net.cpp:122] Setting up Eltwise8_M2PELU17_0_split
I1007 12:33:17.230114  4874 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 12:33:17.230118  4874 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 12:33:17.230119  4874 net.cpp:137] Memory required for data: 397331600
I1007 12:33:17.230123  4874 layer_factory.hpp:77] Creating layer Convolution19
I1007 12:33:17.230129  4874 net.cpp:84] Creating Layer Convolution19
I1007 12:33:17.230130  4874 net.cpp:406] Convolution19 <- Eltwise8_M2PELU17_0_split_0
I1007 12:33:17.230134  4874 net.cpp:380] Convolution19 -> Convolution19
I1007 12:33:17.231508  4874 net.cpp:122] Setting up Convolution19
I1007 12:33:17.231526  4874 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 12:33:17.231529  4874 net.cpp:137] Memory required for data: 399840400
I1007 12:33:17.231544  4874 layer_factory.hpp:77] Creating layer BatchNorm19
I1007 12:33:17.231549  4874 net.cpp:84] Creating Layer BatchNorm19
I1007 12:33:17.231552  4874 net.cpp:406] BatchNorm19 <- Convolution19
I1007 12:33:17.231555  4874 net.cpp:367] BatchNorm19 -> Convolution19 (in-place)
I1007 12:33:17.231685  4874 net.cpp:122] Setting up BatchNorm19
I1007 12:33:17.231689  4874 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 12:33:17.231693  4874 net.cpp:137] Memory required for data: 402349200
I1007 12:33:17.231696  4874 layer_factory.hpp:77] Creating layer Scale19
I1007 12:33:17.231701  4874 net.cpp:84] Creating Layer Scale19
I1007 12:33:17.231704  4874 net.cpp:406] Scale19 <- Convolution19
I1007 12:33:17.231708  4874 net.cpp:367] Scale19 -> Convolution19 (in-place)
I1007 12:33:17.231732  4874 layer_factory.hpp:77] Creating layer Scale19
I1007 12:33:17.231804  4874 net.cpp:122] Setting up Scale19
I1007 12:33:17.231808  4874 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 12:33:17.231811  4874 net.cpp:137] Memory required for data: 404858000
I1007 12:33:17.231814  4874 layer_factory.hpp:77] Creating layer M2PELU18
I1007 12:33:17.231819  4874 net.cpp:84] Creating Layer M2PELU18
I1007 12:33:17.231822  4874 net.cpp:406] M2PELU18 <- Convolution19
I1007 12:33:17.231825  4874 net.cpp:367] M2PELU18 -> Convolution19 (in-place)
I1007 12:33:17.231914  4874 net.cpp:122] Setting up M2PELU18
I1007 12:33:17.231919  4874 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 12:33:17.231920  4874 net.cpp:137] Memory required for data: 407366800
I1007 12:33:17.231925  4874 layer_factory.hpp:77] Creating layer Convolution20
I1007 12:33:17.231931  4874 net.cpp:84] Creating Layer Convolution20
I1007 12:33:17.231933  4874 net.cpp:406] Convolution20 <- Convolution19
I1007 12:33:17.231937  4874 net.cpp:380] Convolution20 -> Convolution20
I1007 12:33:17.232964  4874 net.cpp:122] Setting up Convolution20
I1007 12:33:17.232973  4874 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 12:33:17.232976  4874 net.cpp:137] Memory required for data: 409875600
I1007 12:33:17.232981  4874 layer_factory.hpp:77] Creating layer BatchNorm20
I1007 12:33:17.232986  4874 net.cpp:84] Creating Layer BatchNorm20
I1007 12:33:17.232988  4874 net.cpp:406] BatchNorm20 <- Convolution20
I1007 12:33:17.232992  4874 net.cpp:367] BatchNorm20 -> Convolution20 (in-place)
I1007 12:33:17.233119  4874 net.cpp:122] Setting up BatchNorm20
I1007 12:33:17.233122  4874 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 12:33:17.233124  4874 net.cpp:137] Memory required for data: 412384400
I1007 12:33:17.233129  4874 layer_factory.hpp:77] Creating layer Scale20
I1007 12:33:17.233134  4874 net.cpp:84] Creating Layer Scale20
I1007 12:33:17.233136  4874 net.cpp:406] Scale20 <- Convolution20
I1007 12:33:17.233139  4874 net.cpp:367] Scale20 -> Convolution20 (in-place)
I1007 12:33:17.233165  4874 layer_factory.hpp:77] Creating layer Scale20
I1007 12:33:17.233237  4874 net.cpp:122] Setting up Scale20
I1007 12:33:17.233242  4874 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 12:33:17.233243  4874 net.cpp:137] Memory required for data: 414893200
I1007 12:33:17.233247  4874 layer_factory.hpp:77] Creating layer Eltwise9
I1007 12:33:17.233252  4874 net.cpp:84] Creating Layer Eltwise9
I1007 12:33:17.233254  4874 net.cpp:406] Eltwise9 <- Eltwise8_M2PELU17_0_split_1
I1007 12:33:17.233258  4874 net.cpp:406] Eltwise9 <- Convolution20
I1007 12:33:17.233260  4874 net.cpp:380] Eltwise9 -> Eltwise9
I1007 12:33:17.233275  4874 net.cpp:122] Setting up Eltwise9
I1007 12:33:17.233278  4874 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 12:33:17.233281  4874 net.cpp:137] Memory required for data: 417402000
I1007 12:33:17.233283  4874 layer_factory.hpp:77] Creating layer M2PELU19
I1007 12:33:17.233289  4874 net.cpp:84] Creating Layer M2PELU19
I1007 12:33:17.233290  4874 net.cpp:406] M2PELU19 <- Eltwise9
I1007 12:33:17.233294  4874 net.cpp:367] M2PELU19 -> Eltwise9 (in-place)
I1007 12:33:17.233373  4874 net.cpp:122] Setting up M2PELU19
I1007 12:33:17.233378  4874 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 12:33:17.233389  4874 net.cpp:137] Memory required for data: 419910800
I1007 12:33:17.233393  4874 layer_factory.hpp:77] Creating layer Eltwise9_M2PELU19_0_split
I1007 12:33:17.233397  4874 net.cpp:84] Creating Layer Eltwise9_M2PELU19_0_split
I1007 12:33:17.233399  4874 net.cpp:406] Eltwise9_M2PELU19_0_split <- Eltwise9
I1007 12:33:17.233402  4874 net.cpp:380] Eltwise9_M2PELU19_0_split -> Eltwise9_M2PELU19_0_split_0
I1007 12:33:17.233407  4874 net.cpp:380] Eltwise9_M2PELU19_0_split -> Eltwise9_M2PELU19_0_split_1
I1007 12:33:17.233428  4874 net.cpp:122] Setting up Eltwise9_M2PELU19_0_split
I1007 12:33:17.233430  4874 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 12:33:17.233433  4874 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 12:33:17.233435  4874 net.cpp:137] Memory required for data: 424928400
I1007 12:33:17.233438  4874 layer_factory.hpp:77] Creating layer Convolution21
I1007 12:33:17.233443  4874 net.cpp:84] Creating Layer Convolution21
I1007 12:33:17.233446  4874 net.cpp:406] Convolution21 <- Eltwise9_M2PELU19_0_split_0
I1007 12:33:17.233449  4874 net.cpp:380] Convolution21 -> Convolution21
I1007 12:33:17.234829  4874 net.cpp:122] Setting up Convolution21
I1007 12:33:17.234840  4874 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 12:33:17.234844  4874 net.cpp:137] Memory required for data: 427437200
I1007 12:33:17.234869  4874 layer_factory.hpp:77] Creating layer BatchNorm21
I1007 12:33:17.234874  4874 net.cpp:84] Creating Layer BatchNorm21
I1007 12:33:17.234877  4874 net.cpp:406] BatchNorm21 <- Convolution21
I1007 12:33:17.234881  4874 net.cpp:367] BatchNorm21 -> Convolution21 (in-place)
I1007 12:33:17.235015  4874 net.cpp:122] Setting up BatchNorm21
I1007 12:33:17.235019  4874 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 12:33:17.235021  4874 net.cpp:137] Memory required for data: 429946000
I1007 12:33:17.235026  4874 layer_factory.hpp:77] Creating layer Scale21
I1007 12:33:17.235030  4874 net.cpp:84] Creating Layer Scale21
I1007 12:33:17.235033  4874 net.cpp:406] Scale21 <- Convolution21
I1007 12:33:17.235035  4874 net.cpp:367] Scale21 -> Convolution21 (in-place)
I1007 12:33:17.235060  4874 layer_factory.hpp:77] Creating layer Scale21
I1007 12:33:17.235148  4874 net.cpp:122] Setting up Scale21
I1007 12:33:17.235152  4874 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 12:33:17.235154  4874 net.cpp:137] Memory required for data: 432454800
I1007 12:33:17.235158  4874 layer_factory.hpp:77] Creating layer M2PELU20
I1007 12:33:17.235190  4874 net.cpp:84] Creating Layer M2PELU20
I1007 12:33:17.235193  4874 net.cpp:406] M2PELU20 <- Convolution21
I1007 12:33:17.235196  4874 net.cpp:367] M2PELU20 -> Convolution21 (in-place)
I1007 12:33:17.235297  4874 net.cpp:122] Setting up M2PELU20
I1007 12:33:17.235301  4874 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 12:33:17.235303  4874 net.cpp:137] Memory required for data: 434963600
I1007 12:33:17.235307  4874 layer_factory.hpp:77] Creating layer Convolution22
I1007 12:33:17.235313  4874 net.cpp:84] Creating Layer Convolution22
I1007 12:33:17.235316  4874 net.cpp:406] Convolution22 <- Convolution21
I1007 12:33:17.235319  4874 net.cpp:380] Convolution22 -> Convolution22
I1007 12:33:17.236367  4874 net.cpp:122] Setting up Convolution22
I1007 12:33:17.236377  4874 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 12:33:17.236379  4874 net.cpp:137] Memory required for data: 437472400
I1007 12:33:17.236383  4874 layer_factory.hpp:77] Creating layer BatchNorm22
I1007 12:33:17.236388  4874 net.cpp:84] Creating Layer BatchNorm22
I1007 12:33:17.236390  4874 net.cpp:406] BatchNorm22 <- Convolution22
I1007 12:33:17.236394  4874 net.cpp:367] BatchNorm22 -> Convolution22 (in-place)
I1007 12:33:17.236516  4874 net.cpp:122] Setting up BatchNorm22
I1007 12:33:17.236521  4874 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 12:33:17.236522  4874 net.cpp:137] Memory required for data: 439981200
I1007 12:33:17.236527  4874 layer_factory.hpp:77] Creating layer Scale22
I1007 12:33:17.236531  4874 net.cpp:84] Creating Layer Scale22
I1007 12:33:17.236533  4874 net.cpp:406] Scale22 <- Convolution22
I1007 12:33:17.236536  4874 net.cpp:367] Scale22 -> Convolution22 (in-place)
I1007 12:33:17.236560  4874 layer_factory.hpp:77] Creating layer Scale22
I1007 12:33:17.236629  4874 net.cpp:122] Setting up Scale22
I1007 12:33:17.236632  4874 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 12:33:17.236635  4874 net.cpp:137] Memory required for data: 442490000
I1007 12:33:17.236639  4874 layer_factory.hpp:77] Creating layer Eltwise10
I1007 12:33:17.236642  4874 net.cpp:84] Creating Layer Eltwise10
I1007 12:33:17.236645  4874 net.cpp:406] Eltwise10 <- Eltwise9_M2PELU19_0_split_1
I1007 12:33:17.236647  4874 net.cpp:406] Eltwise10 <- Convolution22
I1007 12:33:17.236651  4874 net.cpp:380] Eltwise10 -> Eltwise10
I1007 12:33:17.236665  4874 net.cpp:122] Setting up Eltwise10
I1007 12:33:17.236670  4874 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 12:33:17.236671  4874 net.cpp:137] Memory required for data: 444998800
I1007 12:33:17.236673  4874 layer_factory.hpp:77] Creating layer M2PELU21
I1007 12:33:17.236677  4874 net.cpp:84] Creating Layer M2PELU21
I1007 12:33:17.236680  4874 net.cpp:406] M2PELU21 <- Eltwise10
I1007 12:33:17.236683  4874 net.cpp:367] M2PELU21 -> Eltwise10 (in-place)
I1007 12:33:17.236760  4874 net.cpp:122] Setting up M2PELU21
I1007 12:33:17.236770  4874 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 12:33:17.236773  4874 net.cpp:137] Memory required for data: 447507600
I1007 12:33:17.236778  4874 layer_factory.hpp:77] Creating layer Eltwise10_M2PELU21_0_split
I1007 12:33:17.236780  4874 net.cpp:84] Creating Layer Eltwise10_M2PELU21_0_split
I1007 12:33:17.236783  4874 net.cpp:406] Eltwise10_M2PELU21_0_split <- Eltwise10
I1007 12:33:17.236786  4874 net.cpp:380] Eltwise10_M2PELU21_0_split -> Eltwise10_M2PELU21_0_split_0
I1007 12:33:17.236790  4874 net.cpp:380] Eltwise10_M2PELU21_0_split -> Eltwise10_M2PELU21_0_split_1
I1007 12:33:17.236812  4874 net.cpp:122] Setting up Eltwise10_M2PELU21_0_split
I1007 12:33:17.236816  4874 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 12:33:17.236819  4874 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 12:33:17.236820  4874 net.cpp:137] Memory required for data: 452525200
I1007 12:33:17.236822  4874 layer_factory.hpp:77] Creating layer Convolution23
I1007 12:33:17.236829  4874 net.cpp:84] Creating Layer Convolution23
I1007 12:33:17.236830  4874 net.cpp:406] Convolution23 <- Eltwise10_M2PELU21_0_split_0
I1007 12:33:17.236835  4874 net.cpp:380] Convolution23 -> Convolution23
I1007 12:33:17.237664  4874 net.cpp:122] Setting up Convolution23
I1007 12:33:17.237673  4874 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 12:33:17.237676  4874 net.cpp:137] Memory required for data: 453779600
I1007 12:33:17.237680  4874 layer_factory.hpp:77] Creating layer BatchNorm23
I1007 12:33:17.237685  4874 net.cpp:84] Creating Layer BatchNorm23
I1007 12:33:17.237687  4874 net.cpp:406] BatchNorm23 <- Convolution23
I1007 12:33:17.237691  4874 net.cpp:367] BatchNorm23 -> Convolution23 (in-place)
I1007 12:33:17.237812  4874 net.cpp:122] Setting up BatchNorm23
I1007 12:33:17.237818  4874 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 12:33:17.237819  4874 net.cpp:137] Memory required for data: 455034000
I1007 12:33:17.237823  4874 layer_factory.hpp:77] Creating layer Scale23
I1007 12:33:17.237828  4874 net.cpp:84] Creating Layer Scale23
I1007 12:33:17.237830  4874 net.cpp:406] Scale23 <- Convolution23
I1007 12:33:17.237833  4874 net.cpp:367] Scale23 -> Convolution23 (in-place)
I1007 12:33:17.237856  4874 layer_factory.hpp:77] Creating layer Scale23
I1007 12:33:17.237924  4874 net.cpp:122] Setting up Scale23
I1007 12:33:17.237928  4874 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 12:33:17.237931  4874 net.cpp:137] Memory required for data: 456288400
I1007 12:33:17.237934  4874 layer_factory.hpp:77] Creating layer Convolution24
I1007 12:33:17.237941  4874 net.cpp:84] Creating Layer Convolution24
I1007 12:33:17.237944  4874 net.cpp:406] Convolution24 <- Eltwise10_M2PELU21_0_split_1
I1007 12:33:17.237948  4874 net.cpp:380] Convolution24 -> Convolution24
I1007 12:33:17.239660  4874 net.cpp:122] Setting up Convolution24
I1007 12:33:17.239668  4874 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 12:33:17.239671  4874 net.cpp:137] Memory required for data: 457542800
I1007 12:33:17.239675  4874 layer_factory.hpp:77] Creating layer BatchNorm24
I1007 12:33:17.239681  4874 net.cpp:84] Creating Layer BatchNorm24
I1007 12:33:17.239683  4874 net.cpp:406] BatchNorm24 <- Convolution24
I1007 12:33:17.239686  4874 net.cpp:367] BatchNorm24 -> Convolution24 (in-place)
I1007 12:33:17.239809  4874 net.cpp:122] Setting up BatchNorm24
I1007 12:33:17.239812  4874 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 12:33:17.239814  4874 net.cpp:137] Memory required for data: 458797200
I1007 12:33:17.239820  4874 layer_factory.hpp:77] Creating layer Scale24
I1007 12:33:17.239823  4874 net.cpp:84] Creating Layer Scale24
I1007 12:33:17.239825  4874 net.cpp:406] Scale24 <- Convolution24
I1007 12:33:17.239828  4874 net.cpp:367] Scale24 -> Convolution24 (in-place)
I1007 12:33:17.239853  4874 layer_factory.hpp:77] Creating layer Scale24
I1007 12:33:17.239922  4874 net.cpp:122] Setting up Scale24
I1007 12:33:17.239925  4874 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 12:33:17.239928  4874 net.cpp:137] Memory required for data: 460051600
I1007 12:33:17.239938  4874 layer_factory.hpp:77] Creating layer M2PELU22
I1007 12:33:17.239943  4874 net.cpp:84] Creating Layer M2PELU22
I1007 12:33:17.239945  4874 net.cpp:406] M2PELU22 <- Convolution24
I1007 12:33:17.239949  4874 net.cpp:367] M2PELU22 -> Convolution24 (in-place)
I1007 12:33:17.240025  4874 net.cpp:122] Setting up M2PELU22
I1007 12:33:17.240030  4874 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 12:33:17.240032  4874 net.cpp:137] Memory required for data: 461306000
I1007 12:33:17.240036  4874 layer_factory.hpp:77] Creating layer Convolution25
I1007 12:33:17.240041  4874 net.cpp:84] Creating Layer Convolution25
I1007 12:33:17.240044  4874 net.cpp:406] Convolution25 <- Convolution24
I1007 12:33:17.240048  4874 net.cpp:380] Convolution25 -> Convolution25
I1007 12:33:17.241914  4874 net.cpp:122] Setting up Convolution25
I1007 12:33:17.241924  4874 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 12:33:17.241926  4874 net.cpp:137] Memory required for data: 462560400
I1007 12:33:17.241930  4874 layer_factory.hpp:77] Creating layer BatchNorm25
I1007 12:33:17.241935  4874 net.cpp:84] Creating Layer BatchNorm25
I1007 12:33:17.241938  4874 net.cpp:406] BatchNorm25 <- Convolution25
I1007 12:33:17.241941  4874 net.cpp:367] BatchNorm25 -> Convolution25 (in-place)
I1007 12:33:17.242066  4874 net.cpp:122] Setting up BatchNorm25
I1007 12:33:17.242071  4874 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 12:33:17.242074  4874 net.cpp:137] Memory required for data: 463814800
I1007 12:33:17.242077  4874 layer_factory.hpp:77] Creating layer Scale25
I1007 12:33:17.242081  4874 net.cpp:84] Creating Layer Scale25
I1007 12:33:17.242084  4874 net.cpp:406] Scale25 <- Convolution25
I1007 12:33:17.242087  4874 net.cpp:367] Scale25 -> Convolution25 (in-place)
I1007 12:33:17.242112  4874 layer_factory.hpp:77] Creating layer Scale25
I1007 12:33:17.242182  4874 net.cpp:122] Setting up Scale25
I1007 12:33:17.242185  4874 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 12:33:17.242187  4874 net.cpp:137] Memory required for data: 465069200
I1007 12:33:17.242192  4874 layer_factory.hpp:77] Creating layer Eltwise11
I1007 12:33:17.242195  4874 net.cpp:84] Creating Layer Eltwise11
I1007 12:33:17.242197  4874 net.cpp:406] Eltwise11 <- Convolution23
I1007 12:33:17.242200  4874 net.cpp:406] Eltwise11 <- Convolution25
I1007 12:33:17.242203  4874 net.cpp:380] Eltwise11 -> Eltwise11
I1007 12:33:17.242218  4874 net.cpp:122] Setting up Eltwise11
I1007 12:33:17.242223  4874 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 12:33:17.242224  4874 net.cpp:137] Memory required for data: 466323600
I1007 12:33:17.242226  4874 layer_factory.hpp:77] Creating layer M2PELU23
I1007 12:33:17.242231  4874 net.cpp:84] Creating Layer M2PELU23
I1007 12:33:17.242233  4874 net.cpp:406] M2PELU23 <- Eltwise11
I1007 12:33:17.242236  4874 net.cpp:367] M2PELU23 -> Eltwise11 (in-place)
I1007 12:33:17.242316  4874 net.cpp:122] Setting up M2PELU23
I1007 12:33:17.242319  4874 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 12:33:17.242322  4874 net.cpp:137] Memory required for data: 467578000
I1007 12:33:17.242326  4874 layer_factory.hpp:77] Creating layer Eltwise11_M2PELU23_0_split
I1007 12:33:17.242329  4874 net.cpp:84] Creating Layer Eltwise11_M2PELU23_0_split
I1007 12:33:17.242331  4874 net.cpp:406] Eltwise11_M2PELU23_0_split <- Eltwise11
I1007 12:33:17.242334  4874 net.cpp:380] Eltwise11_M2PELU23_0_split -> Eltwise11_M2PELU23_0_split_0
I1007 12:33:17.242338  4874 net.cpp:380] Eltwise11_M2PELU23_0_split -> Eltwise11_M2PELU23_0_split_1
I1007 12:33:17.242360  4874 net.cpp:122] Setting up Eltwise11_M2PELU23_0_split
I1007 12:33:17.242363  4874 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 12:33:17.242367  4874 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 12:33:17.242368  4874 net.cpp:137] Memory required for data: 470086800
I1007 12:33:17.242370  4874 layer_factory.hpp:77] Creating layer Convolution26
I1007 12:33:17.242377  4874 net.cpp:84] Creating Layer Convolution26
I1007 12:33:17.242378  4874 net.cpp:406] Convolution26 <- Eltwise11_M2PELU23_0_split_0
I1007 12:33:17.242388  4874 net.cpp:380] Convolution26 -> Convolution26
I1007 12:33:17.243988  4874 net.cpp:122] Setting up Convolution26
I1007 12:33:17.243998  4874 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 12:33:17.244000  4874 net.cpp:137] Memory required for data: 471341200
I1007 12:33:17.244004  4874 layer_factory.hpp:77] Creating layer BatchNorm26
I1007 12:33:17.244009  4874 net.cpp:84] Creating Layer BatchNorm26
I1007 12:33:17.244012  4874 net.cpp:406] BatchNorm26 <- Convolution26
I1007 12:33:17.244015  4874 net.cpp:367] BatchNorm26 -> Convolution26 (in-place)
I1007 12:33:17.244138  4874 net.cpp:122] Setting up BatchNorm26
I1007 12:33:17.244143  4874 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 12:33:17.244145  4874 net.cpp:137] Memory required for data: 472595600
I1007 12:33:17.244149  4874 layer_factory.hpp:77] Creating layer Scale26
I1007 12:33:17.244153  4874 net.cpp:84] Creating Layer Scale26
I1007 12:33:17.244155  4874 net.cpp:406] Scale26 <- Convolution26
I1007 12:33:17.244158  4874 net.cpp:367] Scale26 -> Convolution26 (in-place)
I1007 12:33:17.244184  4874 layer_factory.hpp:77] Creating layer Scale26
I1007 12:33:17.244252  4874 net.cpp:122] Setting up Scale26
I1007 12:33:17.244256  4874 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 12:33:17.244258  4874 net.cpp:137] Memory required for data: 473850000
I1007 12:33:17.244262  4874 layer_factory.hpp:77] Creating layer M2PELU24
I1007 12:33:17.244267  4874 net.cpp:84] Creating Layer M2PELU24
I1007 12:33:17.244269  4874 net.cpp:406] M2PELU24 <- Convolution26
I1007 12:33:17.244272  4874 net.cpp:367] M2PELU24 -> Convolution26 (in-place)
I1007 12:33:17.244350  4874 net.cpp:122] Setting up M2PELU24
I1007 12:33:17.244354  4874 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 12:33:17.244356  4874 net.cpp:137] Memory required for data: 475104400
I1007 12:33:17.244360  4874 layer_factory.hpp:77] Creating layer Convolution27
I1007 12:33:17.244366  4874 net.cpp:84] Creating Layer Convolution27
I1007 12:33:17.244369  4874 net.cpp:406] Convolution27 <- Convolution26
I1007 12:33:17.244372  4874 net.cpp:380] Convolution27 -> Convolution27
I1007 12:33:17.245964  4874 net.cpp:122] Setting up Convolution27
I1007 12:33:17.245972  4874 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 12:33:17.245975  4874 net.cpp:137] Memory required for data: 476358800
I1007 12:33:17.245980  4874 layer_factory.hpp:77] Creating layer BatchNorm27
I1007 12:33:17.245985  4874 net.cpp:84] Creating Layer BatchNorm27
I1007 12:33:17.245986  4874 net.cpp:406] BatchNorm27 <- Convolution27
I1007 12:33:17.245990  4874 net.cpp:367] BatchNorm27 -> Convolution27 (in-place)
I1007 12:33:17.246115  4874 net.cpp:122] Setting up BatchNorm27
I1007 12:33:17.246119  4874 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 12:33:17.246122  4874 net.cpp:137] Memory required for data: 477613200
I1007 12:33:17.246126  4874 layer_factory.hpp:77] Creating layer Scale27
I1007 12:33:17.246137  4874 net.cpp:84] Creating Layer Scale27
I1007 12:33:17.246140  4874 net.cpp:406] Scale27 <- Convolution27
I1007 12:33:17.246143  4874 net.cpp:367] Scale27 -> Convolution27 (in-place)
I1007 12:33:17.246168  4874 layer_factory.hpp:77] Creating layer Scale27
I1007 12:33:17.246239  4874 net.cpp:122] Setting up Scale27
I1007 12:33:17.246243  4874 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 12:33:17.246246  4874 net.cpp:137] Memory required for data: 478867600
I1007 12:33:17.246250  4874 layer_factory.hpp:77] Creating layer Eltwise12
I1007 12:33:17.246254  4874 net.cpp:84] Creating Layer Eltwise12
I1007 12:33:17.246256  4874 net.cpp:406] Eltwise12 <- Eltwise11_M2PELU23_0_split_1
I1007 12:33:17.246259  4874 net.cpp:406] Eltwise12 <- Convolution27
I1007 12:33:17.246263  4874 net.cpp:380] Eltwise12 -> Eltwise12
I1007 12:33:17.246281  4874 net.cpp:122] Setting up Eltwise12
I1007 12:33:17.246286  4874 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 12:33:17.246289  4874 net.cpp:137] Memory required for data: 480122000
I1007 12:33:17.246290  4874 layer_factory.hpp:77] Creating layer M2PELU25
I1007 12:33:17.246294  4874 net.cpp:84] Creating Layer M2PELU25
I1007 12:33:17.246304  4874 net.cpp:406] M2PELU25 <- Eltwise12
I1007 12:33:17.246307  4874 net.cpp:367] M2PELU25 -> Eltwise12 (in-place)
I1007 12:33:17.246390  4874 net.cpp:122] Setting up M2PELU25
I1007 12:33:17.246394  4874 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 12:33:17.246397  4874 net.cpp:137] Memory required for data: 481376400
I1007 12:33:17.246400  4874 layer_factory.hpp:77] Creating layer Eltwise12_M2PELU25_0_split
I1007 12:33:17.246403  4874 net.cpp:84] Creating Layer Eltwise12_M2PELU25_0_split
I1007 12:33:17.246405  4874 net.cpp:406] Eltwise12_M2PELU25_0_split <- Eltwise12
I1007 12:33:17.246409  4874 net.cpp:380] Eltwise12_M2PELU25_0_split -> Eltwise12_M2PELU25_0_split_0
I1007 12:33:17.246413  4874 net.cpp:380] Eltwise12_M2PELU25_0_split -> Eltwise12_M2PELU25_0_split_1
I1007 12:33:17.246434  4874 net.cpp:122] Setting up Eltwise12_M2PELU25_0_split
I1007 12:33:17.246438  4874 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 12:33:17.246441  4874 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 12:33:17.246443  4874 net.cpp:137] Memory required for data: 483885200
I1007 12:33:17.246445  4874 layer_factory.hpp:77] Creating layer Convolution28
I1007 12:33:17.246450  4874 net.cpp:84] Creating Layer Convolution28
I1007 12:33:17.246454  4874 net.cpp:406] Convolution28 <- Eltwise12_M2PELU25_0_split_0
I1007 12:33:17.246457  4874 net.cpp:380] Convolution28 -> Convolution28
I1007 12:33:17.248050  4874 net.cpp:122] Setting up Convolution28
I1007 12:33:17.248059  4874 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 12:33:17.248062  4874 net.cpp:137] Memory required for data: 485139600
I1007 12:33:17.248066  4874 layer_factory.hpp:77] Creating layer BatchNorm28
I1007 12:33:17.248072  4874 net.cpp:84] Creating Layer BatchNorm28
I1007 12:33:17.248075  4874 net.cpp:406] BatchNorm28 <- Convolution28
I1007 12:33:17.248078  4874 net.cpp:367] BatchNorm28 -> Convolution28 (in-place)
I1007 12:33:17.248203  4874 net.cpp:122] Setting up BatchNorm28
I1007 12:33:17.248208  4874 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 12:33:17.248209  4874 net.cpp:137] Memory required for data: 486394000
I1007 12:33:17.248214  4874 layer_factory.hpp:77] Creating layer Scale28
I1007 12:33:17.248219  4874 net.cpp:84] Creating Layer Scale28
I1007 12:33:17.248220  4874 net.cpp:406] Scale28 <- Convolution28
I1007 12:33:17.248224  4874 net.cpp:367] Scale28 -> Convolution28 (in-place)
I1007 12:33:17.248247  4874 layer_factory.hpp:77] Creating layer Scale28
I1007 12:33:17.248317  4874 net.cpp:122] Setting up Scale28
I1007 12:33:17.248322  4874 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 12:33:17.248323  4874 net.cpp:137] Memory required for data: 487648400
I1007 12:33:17.248327  4874 layer_factory.hpp:77] Creating layer M2PELU26
I1007 12:33:17.248332  4874 net.cpp:84] Creating Layer M2PELU26
I1007 12:33:17.248334  4874 net.cpp:406] M2PELU26 <- Convolution28
I1007 12:33:17.248338  4874 net.cpp:367] M2PELU26 -> Convolution28 (in-place)
I1007 12:33:17.248416  4874 net.cpp:122] Setting up M2PELU26
I1007 12:33:17.248420  4874 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 12:33:17.248423  4874 net.cpp:137] Memory required for data: 488902800
I1007 12:33:17.248426  4874 layer_factory.hpp:77] Creating layer Convolution29
I1007 12:33:17.248432  4874 net.cpp:84] Creating Layer Convolution29
I1007 12:33:17.248435  4874 net.cpp:406] Convolution29 <- Convolution28
I1007 12:33:17.248438  4874 net.cpp:380] Convolution29 -> Convolution29
I1007 12:33:17.250300  4874 net.cpp:122] Setting up Convolution29
I1007 12:33:17.250308  4874 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 12:33:17.250311  4874 net.cpp:137] Memory required for data: 490157200
I1007 12:33:17.250316  4874 layer_factory.hpp:77] Creating layer BatchNorm29
I1007 12:33:17.250320  4874 net.cpp:84] Creating Layer BatchNorm29
I1007 12:33:17.250324  4874 net.cpp:406] BatchNorm29 <- Convolution29
I1007 12:33:17.250326  4874 net.cpp:367] BatchNorm29 -> Convolution29 (in-place)
I1007 12:33:17.250453  4874 net.cpp:122] Setting up BatchNorm29
I1007 12:33:17.250464  4874 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 12:33:17.250466  4874 net.cpp:137] Memory required for data: 491411600
I1007 12:33:17.250471  4874 layer_factory.hpp:77] Creating layer Scale29
I1007 12:33:17.250475  4874 net.cpp:84] Creating Layer Scale29
I1007 12:33:17.250478  4874 net.cpp:406] Scale29 <- Convolution29
I1007 12:33:17.250481  4874 net.cpp:367] Scale29 -> Convolution29 (in-place)
I1007 12:33:17.250507  4874 layer_factory.hpp:77] Creating layer Scale29
I1007 12:33:17.250578  4874 net.cpp:122] Setting up Scale29
I1007 12:33:17.250582  4874 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 12:33:17.250584  4874 net.cpp:137] Memory required for data: 492666000
I1007 12:33:17.250588  4874 layer_factory.hpp:77] Creating layer Eltwise13
I1007 12:33:17.250591  4874 net.cpp:84] Creating Layer Eltwise13
I1007 12:33:17.250594  4874 net.cpp:406] Eltwise13 <- Eltwise12_M2PELU25_0_split_1
I1007 12:33:17.250597  4874 net.cpp:406] Eltwise13 <- Convolution29
I1007 12:33:17.250600  4874 net.cpp:380] Eltwise13 -> Eltwise13
I1007 12:33:17.250615  4874 net.cpp:122] Setting up Eltwise13
I1007 12:33:17.250618  4874 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 12:33:17.250620  4874 net.cpp:137] Memory required for data: 493920400
I1007 12:33:17.250623  4874 layer_factory.hpp:77] Creating layer M2PELU27
I1007 12:33:17.250627  4874 net.cpp:84] Creating Layer M2PELU27
I1007 12:33:17.250629  4874 net.cpp:406] M2PELU27 <- Eltwise13
I1007 12:33:17.250633  4874 net.cpp:367] M2PELU27 -> Eltwise13 (in-place)
I1007 12:33:17.250710  4874 net.cpp:122] Setting up M2PELU27
I1007 12:33:17.250715  4874 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 12:33:17.250717  4874 net.cpp:137] Memory required for data: 495174800
I1007 12:33:17.250736  4874 layer_factory.hpp:77] Creating layer Eltwise13_M2PELU27_0_split
I1007 12:33:17.250741  4874 net.cpp:84] Creating Layer Eltwise13_M2PELU27_0_split
I1007 12:33:17.250742  4874 net.cpp:406] Eltwise13_M2PELU27_0_split <- Eltwise13
I1007 12:33:17.250746  4874 net.cpp:380] Eltwise13_M2PELU27_0_split -> Eltwise13_M2PELU27_0_split_0
I1007 12:33:17.250749  4874 net.cpp:380] Eltwise13_M2PELU27_0_split -> Eltwise13_M2PELU27_0_split_1
I1007 12:33:17.250772  4874 net.cpp:122] Setting up Eltwise13_M2PELU27_0_split
I1007 12:33:17.250777  4874 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 12:33:17.250778  4874 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 12:33:17.250780  4874 net.cpp:137] Memory required for data: 497683600
I1007 12:33:17.250783  4874 layer_factory.hpp:77] Creating layer Convolution30
I1007 12:33:17.250788  4874 net.cpp:84] Creating Layer Convolution30
I1007 12:33:17.250792  4874 net.cpp:406] Convolution30 <- Eltwise13_M2PELU27_0_split_0
I1007 12:33:17.250795  4874 net.cpp:380] Convolution30 -> Convolution30
I1007 12:33:17.252393  4874 net.cpp:122] Setting up Convolution30
I1007 12:33:17.252403  4874 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 12:33:17.252405  4874 net.cpp:137] Memory required for data: 498938000
I1007 12:33:17.252409  4874 layer_factory.hpp:77] Creating layer BatchNorm30
I1007 12:33:17.252414  4874 net.cpp:84] Creating Layer BatchNorm30
I1007 12:33:17.252418  4874 net.cpp:406] BatchNorm30 <- Convolution30
I1007 12:33:17.252420  4874 net.cpp:367] BatchNorm30 -> Convolution30 (in-place)
I1007 12:33:17.252545  4874 net.cpp:122] Setting up BatchNorm30
I1007 12:33:17.252549  4874 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 12:33:17.252552  4874 net.cpp:137] Memory required for data: 500192400
I1007 12:33:17.252557  4874 layer_factory.hpp:77] Creating layer Scale30
I1007 12:33:17.252560  4874 net.cpp:84] Creating Layer Scale30
I1007 12:33:17.252562  4874 net.cpp:406] Scale30 <- Convolution30
I1007 12:33:17.252565  4874 net.cpp:367] Scale30 -> Convolution30 (in-place)
I1007 12:33:17.252589  4874 layer_factory.hpp:77] Creating layer Scale30
I1007 12:33:17.252660  4874 net.cpp:122] Setting up Scale30
I1007 12:33:17.252663  4874 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 12:33:17.252666  4874 net.cpp:137] Memory required for data: 501446800
I1007 12:33:17.252676  4874 layer_factory.hpp:77] Creating layer M2PELU28
I1007 12:33:17.252681  4874 net.cpp:84] Creating Layer M2PELU28
I1007 12:33:17.252684  4874 net.cpp:406] M2PELU28 <- Convolution30
I1007 12:33:17.252687  4874 net.cpp:367] M2PELU28 -> Convolution30 (in-place)
I1007 12:33:17.252771  4874 net.cpp:122] Setting up M2PELU28
I1007 12:33:17.252775  4874 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 12:33:17.252777  4874 net.cpp:137] Memory required for data: 502701200
I1007 12:33:17.252780  4874 layer_factory.hpp:77] Creating layer Convolution31
I1007 12:33:17.252786  4874 net.cpp:84] Creating Layer Convolution31
I1007 12:33:17.252789  4874 net.cpp:406] Convolution31 <- Convolution30
I1007 12:33:17.252792  4874 net.cpp:380] Convolution31 -> Convolution31
I1007 12:33:17.254662  4874 net.cpp:122] Setting up Convolution31
I1007 12:33:17.254669  4874 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 12:33:17.254673  4874 net.cpp:137] Memory required for data: 503955600
I1007 12:33:17.254678  4874 layer_factory.hpp:77] Creating layer BatchNorm31
I1007 12:33:17.254681  4874 net.cpp:84] Creating Layer BatchNorm31
I1007 12:33:17.254684  4874 net.cpp:406] BatchNorm31 <- Convolution31
I1007 12:33:17.254688  4874 net.cpp:367] BatchNorm31 -> Convolution31 (in-place)
I1007 12:33:17.254817  4874 net.cpp:122] Setting up BatchNorm31
I1007 12:33:17.254820  4874 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 12:33:17.254823  4874 net.cpp:137] Memory required for data: 505210000
I1007 12:33:17.254827  4874 layer_factory.hpp:77] Creating layer Scale31
I1007 12:33:17.254832  4874 net.cpp:84] Creating Layer Scale31
I1007 12:33:17.254834  4874 net.cpp:406] Scale31 <- Convolution31
I1007 12:33:17.254837  4874 net.cpp:367] Scale31 -> Convolution31 (in-place)
I1007 12:33:17.254863  4874 layer_factory.hpp:77] Creating layer Scale31
I1007 12:33:17.254933  4874 net.cpp:122] Setting up Scale31
I1007 12:33:17.254938  4874 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 12:33:17.254940  4874 net.cpp:137] Memory required for data: 506464400
I1007 12:33:17.254945  4874 layer_factory.hpp:77] Creating layer Eltwise14
I1007 12:33:17.254947  4874 net.cpp:84] Creating Layer Eltwise14
I1007 12:33:17.254951  4874 net.cpp:406] Eltwise14 <- Eltwise13_M2PELU27_0_split_1
I1007 12:33:17.254953  4874 net.cpp:406] Eltwise14 <- Convolution31
I1007 12:33:17.254956  4874 net.cpp:380] Eltwise14 -> Eltwise14
I1007 12:33:17.254971  4874 net.cpp:122] Setting up Eltwise14
I1007 12:33:17.254974  4874 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 12:33:17.254976  4874 net.cpp:137] Memory required for data: 507718800
I1007 12:33:17.254979  4874 layer_factory.hpp:77] Creating layer M2PELU29
I1007 12:33:17.254983  4874 net.cpp:84] Creating Layer M2PELU29
I1007 12:33:17.254986  4874 net.cpp:406] M2PELU29 <- Eltwise14
I1007 12:33:17.254988  4874 net.cpp:367] M2PELU29 -> Eltwise14 (in-place)
I1007 12:33:17.255069  4874 net.cpp:122] Setting up M2PELU29
I1007 12:33:17.255074  4874 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 12:33:17.255075  4874 net.cpp:137] Memory required for data: 508973200
I1007 12:33:17.255079  4874 layer_factory.hpp:77] Creating layer Eltwise14_M2PELU29_0_split
I1007 12:33:17.255082  4874 net.cpp:84] Creating Layer Eltwise14_M2PELU29_0_split
I1007 12:33:17.255084  4874 net.cpp:406] Eltwise14_M2PELU29_0_split <- Eltwise14
I1007 12:33:17.255087  4874 net.cpp:380] Eltwise14_M2PELU29_0_split -> Eltwise14_M2PELU29_0_split_0
I1007 12:33:17.255092  4874 net.cpp:380] Eltwise14_M2PELU29_0_split -> Eltwise14_M2PELU29_0_split_1
I1007 12:33:17.255113  4874 net.cpp:122] Setting up Eltwise14_M2PELU29_0_split
I1007 12:33:17.255116  4874 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 12:33:17.255120  4874 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 12:33:17.255121  4874 net.cpp:137] Memory required for data: 511482000
I1007 12:33:17.255125  4874 layer_factory.hpp:77] Creating layer Convolution32
I1007 12:33:17.255129  4874 net.cpp:84] Creating Layer Convolution32
I1007 12:33:17.255132  4874 net.cpp:406] Convolution32 <- Eltwise14_M2PELU29_0_split_0
I1007 12:33:17.255142  4874 net.cpp:380] Convolution32 -> Convolution32
I1007 12:33:17.256757  4874 net.cpp:122] Setting up Convolution32
I1007 12:33:17.256765  4874 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 12:33:17.256768  4874 net.cpp:137] Memory required for data: 512736400
I1007 12:33:17.256772  4874 layer_factory.hpp:77] Creating layer BatchNorm32
I1007 12:33:17.256778  4874 net.cpp:84] Creating Layer BatchNorm32
I1007 12:33:17.256779  4874 net.cpp:406] BatchNorm32 <- Convolution32
I1007 12:33:17.256783  4874 net.cpp:367] BatchNorm32 -> Convolution32 (in-place)
I1007 12:33:17.256909  4874 net.cpp:122] Setting up BatchNorm32
I1007 12:33:17.256913  4874 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 12:33:17.256916  4874 net.cpp:137] Memory required for data: 513990800
I1007 12:33:17.256920  4874 layer_factory.hpp:77] Creating layer Scale32
I1007 12:33:17.256924  4874 net.cpp:84] Creating Layer Scale32
I1007 12:33:17.256927  4874 net.cpp:406] Scale32 <- Convolution32
I1007 12:33:17.256929  4874 net.cpp:367] Scale32 -> Convolution32 (in-place)
I1007 12:33:17.256954  4874 layer_factory.hpp:77] Creating layer Scale32
I1007 12:33:17.257025  4874 net.cpp:122] Setting up Scale32
I1007 12:33:17.257030  4874 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 12:33:17.257031  4874 net.cpp:137] Memory required for data: 515245200
I1007 12:33:17.257035  4874 layer_factory.hpp:77] Creating layer M2PELU30
I1007 12:33:17.257040  4874 net.cpp:84] Creating Layer M2PELU30
I1007 12:33:17.257042  4874 net.cpp:406] M2PELU30 <- Convolution32
I1007 12:33:17.257045  4874 net.cpp:367] M2PELU30 -> Convolution32 (in-place)
I1007 12:33:17.257127  4874 net.cpp:122] Setting up M2PELU30
I1007 12:33:17.257130  4874 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 12:33:17.257133  4874 net.cpp:137] Memory required for data: 516499600
I1007 12:33:17.257135  4874 layer_factory.hpp:77] Creating layer Convolution33
I1007 12:33:17.257141  4874 net.cpp:84] Creating Layer Convolution33
I1007 12:33:17.257144  4874 net.cpp:406] Convolution33 <- Convolution32
I1007 12:33:17.257148  4874 net.cpp:380] Convolution33 -> Convolution33
I1007 12:33:17.259028  4874 net.cpp:122] Setting up Convolution33
I1007 12:33:17.259037  4874 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 12:33:17.259039  4874 net.cpp:137] Memory required for data: 517754000
I1007 12:33:17.259043  4874 layer_factory.hpp:77] Creating layer BatchNorm33
I1007 12:33:17.259048  4874 net.cpp:84] Creating Layer BatchNorm33
I1007 12:33:17.259052  4874 net.cpp:406] BatchNorm33 <- Convolution33
I1007 12:33:17.259054  4874 net.cpp:367] BatchNorm33 -> Convolution33 (in-place)
I1007 12:33:17.259212  4874 net.cpp:122] Setting up BatchNorm33
I1007 12:33:17.259217  4874 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 12:33:17.259218  4874 net.cpp:137] Memory required for data: 519008400
I1007 12:33:17.259223  4874 layer_factory.hpp:77] Creating layer Scale33
I1007 12:33:17.259227  4874 net.cpp:84] Creating Layer Scale33
I1007 12:33:17.259230  4874 net.cpp:406] Scale33 <- Convolution33
I1007 12:33:17.259233  4874 net.cpp:367] Scale33 -> Convolution33 (in-place)
I1007 12:33:17.259258  4874 layer_factory.hpp:77] Creating layer Scale33
I1007 12:33:17.259331  4874 net.cpp:122] Setting up Scale33
I1007 12:33:17.259335  4874 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 12:33:17.259337  4874 net.cpp:137] Memory required for data: 520262800
I1007 12:33:17.259341  4874 layer_factory.hpp:77] Creating layer Eltwise15
I1007 12:33:17.259346  4874 net.cpp:84] Creating Layer Eltwise15
I1007 12:33:17.259347  4874 net.cpp:406] Eltwise15 <- Eltwise14_M2PELU29_0_split_1
I1007 12:33:17.259351  4874 net.cpp:406] Eltwise15 <- Convolution33
I1007 12:33:17.259353  4874 net.cpp:380] Eltwise15 -> Eltwise15
I1007 12:33:17.259368  4874 net.cpp:122] Setting up Eltwise15
I1007 12:33:17.259372  4874 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 12:33:17.259374  4874 net.cpp:137] Memory required for data: 521517200
I1007 12:33:17.259377  4874 layer_factory.hpp:77] Creating layer M2PELU31
I1007 12:33:17.259382  4874 net.cpp:84] Creating Layer M2PELU31
I1007 12:33:17.259389  4874 net.cpp:406] M2PELU31 <- Eltwise15
I1007 12:33:17.259393  4874 net.cpp:367] M2PELU31 -> Eltwise15 (in-place)
I1007 12:33:17.259476  4874 net.cpp:122] Setting up M2PELU31
I1007 12:33:17.259480  4874 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 12:33:17.259482  4874 net.cpp:137] Memory required for data: 522771600
I1007 12:33:17.259486  4874 layer_factory.hpp:77] Creating layer Pooling1
I1007 12:33:17.259490  4874 net.cpp:84] Creating Layer Pooling1
I1007 12:33:17.259492  4874 net.cpp:406] Pooling1 <- Eltwise15
I1007 12:33:17.259495  4874 net.cpp:380] Pooling1 -> Pooling1
I1007 12:33:17.259634  4874 net.cpp:122] Setting up Pooling1
I1007 12:33:17.259640  4874 net.cpp:129] Top shape: 100 64 1 1 (6400)
I1007 12:33:17.259642  4874 net.cpp:137] Memory required for data: 522797200
I1007 12:33:17.259645  4874 layer_factory.hpp:77] Creating layer InnerProduct1
I1007 12:33:17.259654  4874 net.cpp:84] Creating Layer InnerProduct1
I1007 12:33:17.259656  4874 net.cpp:406] InnerProduct1 <- Pooling1
I1007 12:33:17.259660  4874 net.cpp:380] InnerProduct1 -> InnerProduct1
I1007 12:33:17.259752  4874 net.cpp:122] Setting up InnerProduct1
I1007 12:33:17.259757  4874 net.cpp:129] Top shape: 100 10 (1000)
I1007 12:33:17.259758  4874 net.cpp:137] Memory required for data: 522801200
I1007 12:33:17.259763  4874 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I1007 12:33:17.259766  4874 net.cpp:84] Creating Layer SoftmaxWithLoss1
I1007 12:33:17.259768  4874 net.cpp:406] SoftmaxWithLoss1 <- InnerProduct1
I1007 12:33:17.259771  4874 net.cpp:406] SoftmaxWithLoss1 <- Data2
I1007 12:33:17.259775  4874 net.cpp:380] SoftmaxWithLoss1 -> SoftmaxWithLoss1
I1007 12:33:17.259781  4874 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I1007 12:33:17.259958  4874 net.cpp:122] Setting up SoftmaxWithLoss1
I1007 12:33:17.259964  4874 net.cpp:129] Top shape: (1)
I1007 12:33:17.259966  4874 net.cpp:132]     with loss weight 1
I1007 12:33:17.259979  4874 net.cpp:137] Memory required for data: 522801204
I1007 12:33:17.259980  4874 net.cpp:198] SoftmaxWithLoss1 needs backward computation.
I1007 12:33:17.259984  4874 net.cpp:198] InnerProduct1 needs backward computation.
I1007 12:33:17.259985  4874 net.cpp:198] Pooling1 needs backward computation.
I1007 12:33:17.259987  4874 net.cpp:198] M2PELU31 needs backward computation.
I1007 12:33:17.259989  4874 net.cpp:198] Eltwise15 needs backward computation.
I1007 12:33:17.259992  4874 net.cpp:198] Scale33 needs backward computation.
I1007 12:33:17.259994  4874 net.cpp:198] BatchNorm33 needs backward computation.
I1007 12:33:17.259996  4874 net.cpp:198] Convolution33 needs backward computation.
I1007 12:33:17.259999  4874 net.cpp:198] M2PELU30 needs backward computation.
I1007 12:33:17.260000  4874 net.cpp:198] Scale32 needs backward computation.
I1007 12:33:17.260002  4874 net.cpp:198] BatchNorm32 needs backward computation.
I1007 12:33:17.260004  4874 net.cpp:198] Convolution32 needs backward computation.
I1007 12:33:17.260006  4874 net.cpp:198] Eltwise14_M2PELU29_0_split needs backward computation.
I1007 12:33:17.260010  4874 net.cpp:198] M2PELU29 needs backward computation.
I1007 12:33:17.260011  4874 net.cpp:198] Eltwise14 needs backward computation.
I1007 12:33:17.260013  4874 net.cpp:198] Scale31 needs backward computation.
I1007 12:33:17.260015  4874 net.cpp:198] BatchNorm31 needs backward computation.
I1007 12:33:17.260017  4874 net.cpp:198] Convolution31 needs backward computation.
I1007 12:33:17.260020  4874 net.cpp:198] M2PELU28 needs backward computation.
I1007 12:33:17.260021  4874 net.cpp:198] Scale30 needs backward computation.
I1007 12:33:17.260023  4874 net.cpp:198] BatchNorm30 needs backward computation.
I1007 12:33:17.260025  4874 net.cpp:198] Convolution30 needs backward computation.
I1007 12:33:17.260027  4874 net.cpp:198] Eltwise13_M2PELU27_0_split needs backward computation.
I1007 12:33:17.260030  4874 net.cpp:198] M2PELU27 needs backward computation.
I1007 12:33:17.260032  4874 net.cpp:198] Eltwise13 needs backward computation.
I1007 12:33:17.260040  4874 net.cpp:198] Scale29 needs backward computation.
I1007 12:33:17.260043  4874 net.cpp:198] BatchNorm29 needs backward computation.
I1007 12:33:17.260046  4874 net.cpp:198] Convolution29 needs backward computation.
I1007 12:33:17.260047  4874 net.cpp:198] M2PELU26 needs backward computation.
I1007 12:33:17.260049  4874 net.cpp:198] Scale28 needs backward computation.
I1007 12:33:17.260051  4874 net.cpp:198] BatchNorm28 needs backward computation.
I1007 12:33:17.260053  4874 net.cpp:198] Convolution28 needs backward computation.
I1007 12:33:17.260056  4874 net.cpp:198] Eltwise12_M2PELU25_0_split needs backward computation.
I1007 12:33:17.260057  4874 net.cpp:198] M2PELU25 needs backward computation.
I1007 12:33:17.260059  4874 net.cpp:198] Eltwise12 needs backward computation.
I1007 12:33:17.260062  4874 net.cpp:198] Scale27 needs backward computation.
I1007 12:33:17.260064  4874 net.cpp:198] BatchNorm27 needs backward computation.
I1007 12:33:17.260066  4874 net.cpp:198] Convolution27 needs backward computation.
I1007 12:33:17.260068  4874 net.cpp:198] M2PELU24 needs backward computation.
I1007 12:33:17.260071  4874 net.cpp:198] Scale26 needs backward computation.
I1007 12:33:17.260072  4874 net.cpp:198] BatchNorm26 needs backward computation.
I1007 12:33:17.260073  4874 net.cpp:198] Convolution26 needs backward computation.
I1007 12:33:17.260076  4874 net.cpp:198] Eltwise11_M2PELU23_0_split needs backward computation.
I1007 12:33:17.260078  4874 net.cpp:198] M2PELU23 needs backward computation.
I1007 12:33:17.260080  4874 net.cpp:198] Eltwise11 needs backward computation.
I1007 12:33:17.260083  4874 net.cpp:198] Scale25 needs backward computation.
I1007 12:33:17.260085  4874 net.cpp:198] BatchNorm25 needs backward computation.
I1007 12:33:17.260087  4874 net.cpp:198] Convolution25 needs backward computation.
I1007 12:33:17.260089  4874 net.cpp:198] M2PELU22 needs backward computation.
I1007 12:33:17.260092  4874 net.cpp:198] Scale24 needs backward computation.
I1007 12:33:17.260093  4874 net.cpp:198] BatchNorm24 needs backward computation.
I1007 12:33:17.260095  4874 net.cpp:198] Convolution24 needs backward computation.
I1007 12:33:17.260097  4874 net.cpp:198] Scale23 needs backward computation.
I1007 12:33:17.260099  4874 net.cpp:198] BatchNorm23 needs backward computation.
I1007 12:33:17.260102  4874 net.cpp:198] Convolution23 needs backward computation.
I1007 12:33:17.260104  4874 net.cpp:198] Eltwise10_M2PELU21_0_split needs backward computation.
I1007 12:33:17.260107  4874 net.cpp:198] M2PELU21 needs backward computation.
I1007 12:33:17.260108  4874 net.cpp:198] Eltwise10 needs backward computation.
I1007 12:33:17.260112  4874 net.cpp:198] Scale22 needs backward computation.
I1007 12:33:17.260113  4874 net.cpp:198] BatchNorm22 needs backward computation.
I1007 12:33:17.260115  4874 net.cpp:198] Convolution22 needs backward computation.
I1007 12:33:17.260118  4874 net.cpp:198] M2PELU20 needs backward computation.
I1007 12:33:17.260120  4874 net.cpp:198] Scale21 needs backward computation.
I1007 12:33:17.260123  4874 net.cpp:198] BatchNorm21 needs backward computation.
I1007 12:33:17.260124  4874 net.cpp:198] Convolution21 needs backward computation.
I1007 12:33:17.260126  4874 net.cpp:198] Eltwise9_M2PELU19_0_split needs backward computation.
I1007 12:33:17.260128  4874 net.cpp:198] M2PELU19 needs backward computation.
I1007 12:33:17.260131  4874 net.cpp:198] Eltwise9 needs backward computation.
I1007 12:33:17.260133  4874 net.cpp:198] Scale20 needs backward computation.
I1007 12:33:17.260136  4874 net.cpp:198] BatchNorm20 needs backward computation.
I1007 12:33:17.260138  4874 net.cpp:198] Convolution20 needs backward computation.
I1007 12:33:17.260140  4874 net.cpp:198] M2PELU18 needs backward computation.
I1007 12:33:17.260143  4874 net.cpp:198] Scale19 needs backward computation.
I1007 12:33:17.260144  4874 net.cpp:198] BatchNorm19 needs backward computation.
I1007 12:33:17.260146  4874 net.cpp:198] Convolution19 needs backward computation.
I1007 12:33:17.260149  4874 net.cpp:198] Eltwise8_M2PELU17_0_split needs backward computation.
I1007 12:33:17.260154  4874 net.cpp:198] M2PELU17 needs backward computation.
I1007 12:33:17.260157  4874 net.cpp:198] Eltwise8 needs backward computation.
I1007 12:33:17.260159  4874 net.cpp:198] Scale18 needs backward computation.
I1007 12:33:17.260161  4874 net.cpp:198] BatchNorm18 needs backward computation.
I1007 12:33:17.260164  4874 net.cpp:198] Convolution18 needs backward computation.
I1007 12:33:17.260166  4874 net.cpp:198] M2PELU16 needs backward computation.
I1007 12:33:17.260169  4874 net.cpp:198] Scale17 needs backward computation.
I1007 12:33:17.260170  4874 net.cpp:198] BatchNorm17 needs backward computation.
I1007 12:33:17.260172  4874 net.cpp:198] Convolution17 needs backward computation.
I1007 12:33:17.260175  4874 net.cpp:198] Eltwise7_M2PELU15_0_split needs backward computation.
I1007 12:33:17.260177  4874 net.cpp:198] M2PELU15 needs backward computation.
I1007 12:33:17.260179  4874 net.cpp:198] Eltwise7 needs backward computation.
I1007 12:33:17.260182  4874 net.cpp:198] Scale16 needs backward computation.
I1007 12:33:17.260185  4874 net.cpp:198] BatchNorm16 needs backward computation.
I1007 12:33:17.260186  4874 net.cpp:198] Convolution16 needs backward computation.
I1007 12:33:17.260188  4874 net.cpp:198] M2PELU14 needs backward computation.
I1007 12:33:17.260190  4874 net.cpp:198] Scale15 needs backward computation.
I1007 12:33:17.260193  4874 net.cpp:198] BatchNorm15 needs backward computation.
I1007 12:33:17.260195  4874 net.cpp:198] Convolution15 needs backward computation.
I1007 12:33:17.260197  4874 net.cpp:198] Eltwise6_M2PELU13_0_split needs backward computation.
I1007 12:33:17.260200  4874 net.cpp:198] M2PELU13 needs backward computation.
I1007 12:33:17.260202  4874 net.cpp:198] Eltwise6 needs backward computation.
I1007 12:33:17.260205  4874 net.cpp:198] Scale14 needs backward computation.
I1007 12:33:17.260207  4874 net.cpp:198] BatchNorm14 needs backward computation.
I1007 12:33:17.260210  4874 net.cpp:198] Convolution14 needs backward computation.
I1007 12:33:17.260211  4874 net.cpp:198] M2PELU12 needs backward computation.
I1007 12:33:17.260213  4874 net.cpp:198] Scale13 needs backward computation.
I1007 12:33:17.260215  4874 net.cpp:198] BatchNorm13 needs backward computation.
I1007 12:33:17.260218  4874 net.cpp:198] Convolution13 needs backward computation.
I1007 12:33:17.260221  4874 net.cpp:198] Scale12 needs backward computation.
I1007 12:33:17.260222  4874 net.cpp:198] BatchNorm12 needs backward computation.
I1007 12:33:17.260224  4874 net.cpp:198] Convolution12 needs backward computation.
I1007 12:33:17.260227  4874 net.cpp:198] Eltwise5_M2PELU11_0_split needs backward computation.
I1007 12:33:17.260229  4874 net.cpp:198] M2PELU11 needs backward computation.
I1007 12:33:17.260231  4874 net.cpp:198] Eltwise5 needs backward computation.
I1007 12:33:17.260234  4874 net.cpp:198] Scale11 needs backward computation.
I1007 12:33:17.260236  4874 net.cpp:198] BatchNorm11 needs backward computation.
I1007 12:33:17.260238  4874 net.cpp:198] Convolution11 needs backward computation.
I1007 12:33:17.260241  4874 net.cpp:198] M2PELU10 needs backward computation.
I1007 12:33:17.260243  4874 net.cpp:198] Scale10 needs backward computation.
I1007 12:33:17.260246  4874 net.cpp:198] BatchNorm10 needs backward computation.
I1007 12:33:17.260247  4874 net.cpp:198] Convolution10 needs backward computation.
I1007 12:33:17.260251  4874 net.cpp:198] Eltwise4_M2PELU9_0_split needs backward computation.
I1007 12:33:17.260252  4874 net.cpp:198] M2PELU9 needs backward computation.
I1007 12:33:17.260254  4874 net.cpp:198] Eltwise4 needs backward computation.
I1007 12:33:17.260257  4874 net.cpp:198] Scale9 needs backward computation.
I1007 12:33:17.260260  4874 net.cpp:198] BatchNorm9 needs backward computation.
I1007 12:33:17.260262  4874 net.cpp:198] Convolution9 needs backward computation.
I1007 12:33:17.260264  4874 net.cpp:198] M2PELU8 needs backward computation.
I1007 12:33:17.260267  4874 net.cpp:198] Scale8 needs backward computation.
I1007 12:33:17.260272  4874 net.cpp:198] BatchNorm8 needs backward computation.
I1007 12:33:17.260274  4874 net.cpp:198] Convolution8 needs backward computation.
I1007 12:33:17.260277  4874 net.cpp:198] Eltwise3_M2PELU7_0_split needs backward computation.
I1007 12:33:17.260278  4874 net.cpp:198] M2PELU7 needs backward computation.
I1007 12:33:17.260282  4874 net.cpp:198] Eltwise3 needs backward computation.
I1007 12:33:17.260283  4874 net.cpp:198] Scale7 needs backward computation.
I1007 12:33:17.260285  4874 net.cpp:198] BatchNorm7 needs backward computation.
I1007 12:33:17.260288  4874 net.cpp:198] Convolution7 needs backward computation.
I1007 12:33:17.260290  4874 net.cpp:198] M2PELU6 needs backward computation.
I1007 12:33:17.260293  4874 net.cpp:198] Scale6 needs backward computation.
I1007 12:33:17.260294  4874 net.cpp:198] BatchNorm6 needs backward computation.
I1007 12:33:17.260296  4874 net.cpp:198] Convolution6 needs backward computation.
I1007 12:33:17.260299  4874 net.cpp:198] Eltwise2_M2PELU5_0_split needs backward computation.
I1007 12:33:17.260301  4874 net.cpp:198] M2PELU5 needs backward computation.
I1007 12:33:17.260303  4874 net.cpp:198] Eltwise2 needs backward computation.
I1007 12:33:17.260306  4874 net.cpp:198] Scale5 needs backward computation.
I1007 12:33:17.260308  4874 net.cpp:198] BatchNorm5 needs backward computation.
I1007 12:33:17.260311  4874 net.cpp:198] Convolution5 needs backward computation.
I1007 12:33:17.260313  4874 net.cpp:198] M2PELU4 needs backward computation.
I1007 12:33:17.260315  4874 net.cpp:198] Scale4 needs backward computation.
I1007 12:33:17.260318  4874 net.cpp:198] BatchNorm4 needs backward computation.
I1007 12:33:17.260320  4874 net.cpp:198] Convolution4 needs backward computation.
I1007 12:33:17.260323  4874 net.cpp:198] Eltwise1_M2PELU3_0_split needs backward computation.
I1007 12:33:17.260325  4874 net.cpp:198] M2PELU3 needs backward computation.
I1007 12:33:17.260327  4874 net.cpp:198] Eltwise1 needs backward computation.
I1007 12:33:17.260330  4874 net.cpp:198] Scale3 needs backward computation.
I1007 12:33:17.260332  4874 net.cpp:198] BatchNorm3 needs backward computation.
I1007 12:33:17.260334  4874 net.cpp:198] Convolution3 needs backward computation.
I1007 12:33:17.260337  4874 net.cpp:198] M2PELU2 needs backward computation.
I1007 12:33:17.260339  4874 net.cpp:198] Scale2 needs backward computation.
I1007 12:33:17.260341  4874 net.cpp:198] BatchNorm2 needs backward computation.
I1007 12:33:17.260344  4874 net.cpp:198] Convolution2 needs backward computation.
I1007 12:33:17.260346  4874 net.cpp:198] Convolution1_M2PELU1_0_split needs backward computation.
I1007 12:33:17.260349  4874 net.cpp:198] M2PELU1 needs backward computation.
I1007 12:33:17.260351  4874 net.cpp:198] Scale1 needs backward computation.
I1007 12:33:17.260354  4874 net.cpp:198] BatchNorm1 needs backward computation.
I1007 12:33:17.260355  4874 net.cpp:198] Convolution1 needs backward computation.
I1007 12:33:17.260359  4874 net.cpp:200] Data1 does not need backward computation.
I1007 12:33:17.260360  4874 net.cpp:242] This network produces output SoftmaxWithLoss1
I1007 12:33:17.260409  4874 net.cpp:255] Network initialization done.
I1007 12:33:17.262873  4874 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: /home/x306/caffe/xn/PENLU/neural/resnet/res32/res32_mpelu_decay_gauss.prototxt
I1007 12:33:17.262882  4874 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I1007 12:33:17.262887  4874 solver.cpp:172] Creating test net (#0) specified by net file: /home/x306/caffe/xn/PENLU/neural/resnet/res32/res32_mpelu_decay_gauss.prototxt
I1007 12:33:17.262995  4874 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer Data1
I1007 12:33:17.263664  4874 net.cpp:51] Initializing net from parameters: 
name: "resnet_cifar10"
state {
  phase: TEST
}
layer {
  name: "Data1"
  type: "Data"
  top: "Data1"
  top: "Data2"
  include {
    phase: TEST
  }
  transform_param {
    mean_file: "/home/x306/caffe/xn/PENLU/data/cifar10/mean.binaryproto"
  }
  data_param {
    source: "/home/x306/caffe/xn/PENLU/data/cifar10/cifar10_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "Convolution1"
  type: "Convolution"
  bottom: "Data1"
  top: "Convolution1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm1"
  type: "BatchNorm"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1"
  type: "Scale"
  bottom: "Convolution1"
  top: "Convolution1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU1"
  type: "M2PELU"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution2"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm2"
  type: "BatchNorm"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale2"
  type: "Scale"
  bottom: "Convolution2"
  top: "Convolution2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU2"
  type: "M2PELU"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution3"
  type: "Convolution"
  bottom: "Convolution2"
  top: "Convolution3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm3"
  type: "BatchNorm"
  bottom: "Convolution3"
  top: "Convolution3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale3"
  type: "Scale"
  bottom: "Convolution3"
  top: "Convolution3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise1"
  type: "Eltwise"
  bottom: "Convolution1"
  bottom: "Convolution3"
  top: "Eltwise1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU3"
  type: "M2PELU"
  bottom: "Eltwise1"
  top: "Eltwise1"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution4"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm4"
  type: "BatchNorm"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale4"
  type: "Scale"
  bottom: "Convolution4"
  top: "Convolution4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU4"
  type: "M2PELU"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution5"
  type: "Convolution"
  bottom: "Convolution4"
  top: "Convolution5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm5"
  type: "BatchNorm"
  bottom: "Convolution5"
  top: "Convolution5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale5"
  type: "Scale"
  bottom: "Convolution5"
  top: "Convolution5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise2"
  type: "Eltwise"
  bottom: "Eltwise1"
  bottom: "Convolution5"
  top: "Eltwise2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU5"
  type: "M2PELU"
  bottom: "Eltwise2"
  top: "Eltwise2"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution6"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm6"
  type: "BatchNorm"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale6"
  type: "Scale"
  bottom: "Convolution6"
  top: "Convolution6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU6"
  type: "M2PELU"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution7"
  type: "Convolution"
  bottom: "Convolution6"
  top: "Convolution7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm7"
  type: "BatchNorm"
  bottom: "Convolution7"
  top: "Convolution7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale7"
  type: "Scale"
  bottom: "Convolution7"
  top: "Convolution7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise3"
  type: "Eltwise"
  bottom: "Eltwise2"
  bottom: "Convolution7"
  top: "Eltwise3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU7"
  type: "M2PELU"
  bottom: "Eltwise3"
  top: "Eltwise3"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution8"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm8"
  type: "BatchNorm"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale8"
  type: "Scale"
  bottom: "Convolution8"
  top: "Convolution8"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU8"
  type: "M2PELU"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution9"
  type: "Convolution"
  bottom: "Convolution8"
  top: "Convolution9"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm9"
  type: "BatchNorm"
  bottom: "Convolution9"
  top: "Convolution9"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale9"
  type: "Scale"
  bottom: "Convolution9"
  top: "Convolution9"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise4"
  type: "Eltwise"
  bottom: "Eltwise3"
  bottom: "Convolution9"
  top: "Eltwise4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU9"
  type: "M2PELU"
  bottom: "Eltwise4"
  top: "Eltwise4"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution10"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution10"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm10"
  type: "BatchNorm"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale10"
  type: "Scale"
  bottom: "Convolution10"
  top: "Convolution10"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU10"
  type: "M2PELU"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution11"
  type: "Convolution"
  bottom: "Convolution10"
  top: "Convolution11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm11"
  type: "BatchNorm"
  bottom: "Convolution11"
  top: "Convolution11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale11"
  type: "Scale"
  bottom: "Convolution11"
  top: "Convolution11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise5"
  type: "Eltwise"
  bottom: "Eltwise4"
  bottom: "Convolution11"
  top: "Eltwise5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU11"
  type: "M2PELU"
  bottom: "Eltwise5"
  top: "Eltwise5"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution12"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.25
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm12"
  type: "BatchNorm"
  bottom: "Convolution12"
  top: "Convolution12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale12"
  type: "Scale"
  bottom: "Convolution12"
  top: "Convolution12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution13"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution13"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm13"
  type: "BatchNorm"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale13"
  type: "Scale"
  bottom: "Convolution13"
  top: "Convolution13"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU12"
  type: "M2PELU"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution14"
  type: "Convolution"
  bottom: "Convolution13"
  top: "Convolution14"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm14"
  type: "BatchNorm"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale14"
  type: "Scale"
  bottom: "Convolution14"
  top: "Convolution14"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise6"
  type: "Eltwise"
  bottom: "Convolution12"
  bottom: "Convolution14"
  top: "Eltwise6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU13"
  type: "M2PELU"
  bottom: "Eltwise6"
  top: "Eltwise6"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution15"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution15"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm15"
  type: "BatchNorm"
  bottom: "Convolution15"
  top: "Convolution15"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale15"
  type: "Scale"
  bottom: "Convolution15"
  top: "Convolution15"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU14"
  type: "M2PELU"
  bottom: "Convolution15"
  top: "Convolution15"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution16"
  type: "Convolution"
  bottom: "Convolution15"
  top: "Convolution16"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm16"
  type: "BatchNorm"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale16"
  type: "Scale"
  bottom: "Convolution16"
  top: "Convolution16"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise7"
  type: "Eltwise"
  bottom: "Eltwise6"
  bottom: "Convolution16"
  top: "Eltwise7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU15"
  type: "M2PELU"
  bottom: "Eltwise7"
  top: "Eltwise7"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution17"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution17"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm17"
  type: "BatchNorm"
  bottom: "Convolution17"
  top: "Convolution17"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale17"
  type: "Scale"
  bottom: "Convolution17"
  top: "Convolution17"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU16"
  type: "M2PELU"
  bottom: "Convolution17"
  top: "Convolution17"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution18"
  type: "Convolution"
  bottom: "Convolution17"
  top: "Convolution18"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm18"
  type: "BatchNorm"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale18"
  type: "Scale"
  bottom: "Convolution18"
  top: "Convolution18"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise8"
  type: "Eltwise"
  bottom: "Eltwise7"
  bottom: "Convolution18"
  top: "Eltwise8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU17"
  type: "M2PELU"
  bottom: "Eltwise8"
  top: "Eltwise8"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution19"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution19"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm19"
  type: "BatchNorm"
  bottom: "Convolution19"
  top: "Convolution19"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale19"
  type: "Scale"
  bottom: "Convolution19"
  top: "Convolution19"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU18"
  type: "M2PELU"
  bottom: "Convolution19"
  top: "Convolution19"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution20"
  type: "Convolution"
  bottom: "Convolution19"
  top: "Convolution20"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm20"
  type: "BatchNorm"
  bottom: "Convolution20"
  top: "Convolution20"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale20"
  type: "Scale"
  bottom: "Convolution20"
  top: "Convolution20"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise9"
  type: "Eltwise"
  bottom: "Eltwise8"
  bottom: "Convolution20"
  top: "Eltwise9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU19"
  type: "M2PELU"
  bottom: "Eltwise9"
  top: "Eltwise9"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution21"
  type: "Convolution"
  bottom: "Eltwise9"
  top: "Convolution21"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm21"
  type: "BatchNorm"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale21"
  type: "Scale"
  bottom: "Convolution21"
  top: "Convolution21"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU20"
  type: "M2PELU"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution22"
  type: "Convolution"
  bottom: "Convolution21"
  top: "Convolution22"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm22"
  type: "BatchNorm"
  bottom: "Convolution22"
  top: "Convolution22"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale22"
  type: "Scale"
  bottom: "Convolution22"
  top: "Convolution22"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise10"
  type: "Eltwise"
  bottom: "Eltwise9"
  bottom: "Convolution22"
  top: "Eltwise10"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU21"
  type: "M2PELU"
  bottom: "Eltwise10"
  top: "Eltwise10"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution23"
  type: "Convolution"
  bottom: "Eltwise10"
  top: "Convolution23"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.17677669
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm23"
  type: "BatchNorm"
  bottom: "Convolution23"
  top: "Convolution23"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale23"
  type: "Scale"
  bottom: "Convolution23"
  top: "Convolution23"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution24"
  type: "Convolution"
  bottom: "Eltwise10"
  top: "Convolution24"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm24"
  type: "BatchNorm"
  bottom: "Convolution24"
  top: "Convolution24"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale24"
  type: "Scale"
  bottom: "Convolution24"
  top: "Convolution24"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU22"
  type: "M2PELU"
  bottom: "Convolution24"
  top: "Convolution24"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution25"
  type: "Convolution"
  bottom: "Convolution24"
  top: "Convolution25"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm25"
  type: "BatchNorm"
  bottom: "Convolution25"
  top: "Convolution25"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale25"
  type: "Scale"
  bottom: "Convolution25"
  top: "Convolution25"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise11"
  type: "Eltwise"
  bottom: "Convolution23"
  bottom: "Convolution25"
  top: "Eltwise11"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU23"
  type: "M2PELU"
  bottom: "Eltwise11"
  top: "Eltwise11"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution26"
  type: "Convolution"
  bottom: "Eltwise11"
  top: "Convolution26"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm26"
  type: "BatchNorm"
  bottom: "Convolution26"
  top: "Convolution26"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param 
I1007 12:33:17.266718  4874 layer_factory.hpp:77] Creating layer Data1
I1007 12:33:17.294440  4874 db_lmdb.cpp:35] Opened lmdb /home/x306/caffe/xn/PENLU/data/cifar10/cifar10_test_lmdb
I1007 12:33:17.294454  4874 net.cpp:84] Creating Layer Data1
I1007 12:33:17.294459  4874 net.cpp:380] Data1 -> Data1
I1007 12:33:17.294466  4874 net.cpp:380] Data1 -> Data2
I1007 12:33:17.294472  4874 data_transformer.cpp:25] Loading mean file from: /home/x306/caffe/xn/PENLU/data/cifar10/mean.binaryproto
I1007 12:33:17.294610  4874 data_layer.cpp:45] output data size: 100,3,32,32
I1007 12:33:17.299054  4874 net.cpp:122] Setting up Data1
I1007 12:33:17.299072  4874 net.cpp:129] Top shape: 100 3 32 32 (307200)
I1007 12:33:17.299075  4874 net.cpp:129] Top shape: 100 (100)
I1007 12:33:17.299078  4874 net.cpp:137] Memory required for data: 1229200
I1007 12:33:17.299082  4874 layer_factory.hpp:77] Creating layer Data2_Data1_1_split
I1007 12:33:17.299093  4874 net.cpp:84] Creating Layer Data2_Data1_1_split
I1007 12:33:17.299095  4874 net.cpp:406] Data2_Data1_1_split <- Data2
I1007 12:33:17.299099  4874 net.cpp:380] Data2_Data1_1_split -> Data2_Data1_1_split_0
I1007 12:33:17.299106  4874 net.cpp:380] Data2_Data1_1_split -> Data2_Data1_1_split_1
I1007 12:33:17.299162  4874 net.cpp:122] Setting up Data2_Data1_1_split
I1007 12:33:17.299190  4874 net.cpp:129] Top shape: 100 (100)
I1007 12:33:17.299193  4874 net.cpp:129] Top shape: 100 (100)
I1007 12:33:17.299196  4874 net.cpp:137] Memory required for data: 1230000
I1007 12:33:17.299197  4874 layer_factory.hpp:77] Creating layer Convolution1
I1007 12:33:17.299206  4874 net.cpp:84] Creating Layer Convolution1
I1007 12:33:17.299209  4874 net.cpp:406] Convolution1 <- Data1
I1007 12:33:17.299221  4874 net.cpp:380] Convolution1 -> Convolution1
I1007 12:33:17.300364  4874 net.cpp:122] Setting up Convolution1
I1007 12:33:17.300374  4874 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 12:33:17.300376  4874 net.cpp:137] Memory required for data: 7783600
I1007 12:33:17.300384  4874 layer_factory.hpp:77] Creating layer BatchNorm1
I1007 12:33:17.300390  4874 net.cpp:84] Creating Layer BatchNorm1
I1007 12:33:17.300393  4874 net.cpp:406] BatchNorm1 <- Convolution1
I1007 12:33:17.300397  4874 net.cpp:367] BatchNorm1 -> Convolution1 (in-place)
I1007 12:33:17.300537  4874 net.cpp:122] Setting up BatchNorm1
I1007 12:33:17.300542  4874 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 12:33:17.300544  4874 net.cpp:137] Memory required for data: 14337200
I1007 12:33:17.300551  4874 layer_factory.hpp:77] Creating layer Scale1
I1007 12:33:17.300559  4874 net.cpp:84] Creating Layer Scale1
I1007 12:33:17.300564  4874 net.cpp:406] Scale1 <- Convolution1
I1007 12:33:17.300566  4874 net.cpp:367] Scale1 -> Convolution1 (in-place)
I1007 12:33:17.300595  4874 layer_factory.hpp:77] Creating layer Scale1
I1007 12:33:17.300675  4874 net.cpp:122] Setting up Scale1
I1007 12:33:17.300680  4874 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 12:33:17.300683  4874 net.cpp:137] Memory required for data: 20890800
I1007 12:33:17.300698  4874 layer_factory.hpp:77] Creating layer M2PELU1
I1007 12:33:17.300705  4874 net.cpp:84] Creating Layer M2PELU1
I1007 12:33:17.300707  4874 net.cpp:406] M2PELU1 <- Convolution1
I1007 12:33:17.300710  4874 net.cpp:367] M2PELU1 -> Convolution1 (in-place)
I1007 12:33:17.300812  4874 net.cpp:122] Setting up M2PELU1
I1007 12:33:17.300822  4874 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 12:33:17.300823  4874 net.cpp:137] Memory required for data: 27444400
I1007 12:33:17.300832  4874 layer_factory.hpp:77] Creating layer Convolution1_M2PELU1_0_split
I1007 12:33:17.300835  4874 net.cpp:84] Creating Layer Convolution1_M2PELU1_0_split
I1007 12:33:17.300839  4874 net.cpp:406] Convolution1_M2PELU1_0_split <- Convolution1
I1007 12:33:17.300843  4874 net.cpp:380] Convolution1_M2PELU1_0_split -> Convolution1_M2PELU1_0_split_0
I1007 12:33:17.300848  4874 net.cpp:380] Convolution1_M2PELU1_0_split -> Convolution1_M2PELU1_0_split_1
I1007 12:33:17.300874  4874 net.cpp:122] Setting up Convolution1_M2PELU1_0_split
I1007 12:33:17.300879  4874 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 12:33:17.300882  4874 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 12:33:17.300884  4874 net.cpp:137] Memory required for data: 40551600
I1007 12:33:17.300889  4874 layer_factory.hpp:77] Creating layer Convolution2
I1007 12:33:17.300895  4874 net.cpp:84] Creating Layer Convolution2
I1007 12:33:17.300897  4874 net.cpp:406] Convolution2 <- Convolution1_M2PELU1_0_split_0
I1007 12:33:17.300902  4874 net.cpp:380] Convolution2 -> Convolution2
I1007 12:33:17.301975  4874 net.cpp:122] Setting up Convolution2
I1007 12:33:17.301983  4874 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 12:33:17.301987  4874 net.cpp:137] Memory required for data: 47105200
I1007 12:33:17.301991  4874 layer_factory.hpp:77] Creating layer BatchNorm2
I1007 12:33:17.301997  4874 net.cpp:84] Creating Layer BatchNorm2
I1007 12:33:17.302000  4874 net.cpp:406] BatchNorm2 <- Convolution2
I1007 12:33:17.302004  4874 net.cpp:367] BatchNorm2 -> Convolution2 (in-place)
I1007 12:33:17.302140  4874 net.cpp:122] Setting up BatchNorm2
I1007 12:33:17.302145  4874 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 12:33:17.302148  4874 net.cpp:137] Memory required for data: 53658800
I1007 12:33:17.302153  4874 layer_factory.hpp:77] Creating layer Scale2
I1007 12:33:17.302158  4874 net.cpp:84] Creating Layer Scale2
I1007 12:33:17.302160  4874 net.cpp:406] Scale2 <- Convolution2
I1007 12:33:17.302163  4874 net.cpp:367] Scale2 -> Convolution2 (in-place)
I1007 12:33:17.302191  4874 layer_factory.hpp:77] Creating layer Scale2
I1007 12:33:17.302268  4874 net.cpp:122] Setting up Scale2
I1007 12:33:17.302273  4874 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 12:33:17.302274  4874 net.cpp:137] Memory required for data: 60212400
I1007 12:33:17.302278  4874 layer_factory.hpp:77] Creating layer M2PELU2
I1007 12:33:17.302284  4874 net.cpp:84] Creating Layer M2PELU2
I1007 12:33:17.302285  4874 net.cpp:406] M2PELU2 <- Convolution2
I1007 12:33:17.302289  4874 net.cpp:367] M2PELU2 -> Convolution2 (in-place)
I1007 12:33:17.302378  4874 net.cpp:122] Setting up M2PELU2
I1007 12:33:17.302383  4874 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 12:33:17.302386  4874 net.cpp:137] Memory required for data: 66766000
I1007 12:33:17.302392  4874 layer_factory.hpp:77] Creating layer Convolution3
I1007 12:33:17.302403  4874 net.cpp:84] Creating Layer Convolution3
I1007 12:33:17.302407  4874 net.cpp:406] Convolution3 <- Convolution2
I1007 12:33:17.302412  4874 net.cpp:380] Convolution3 -> Convolution3
I1007 12:33:17.303457  4874 net.cpp:122] Setting up Convolution3
I1007 12:33:17.303469  4874 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 12:33:17.303472  4874 net.cpp:137] Memory required for data: 73319600
I1007 12:33:17.303477  4874 layer_factory.hpp:77] Creating layer BatchNorm3
I1007 12:33:17.303481  4874 net.cpp:84] Creating Layer BatchNorm3
I1007 12:33:17.303483  4874 net.cpp:406] BatchNorm3 <- Convolution3
I1007 12:33:17.303488  4874 net.cpp:367] BatchNorm3 -> Convolution3 (in-place)
I1007 12:33:17.303632  4874 net.cpp:122] Setting up BatchNorm3
I1007 12:33:17.303637  4874 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 12:33:17.303638  4874 net.cpp:137] Memory required for data: 79873200
I1007 12:33:17.303643  4874 layer_factory.hpp:77] Creating layer Scale3
I1007 12:33:17.303647  4874 net.cpp:84] Creating Layer Scale3
I1007 12:33:17.303649  4874 net.cpp:406] Scale3 <- Convolution3
I1007 12:33:17.303653  4874 net.cpp:367] Scale3 -> Convolution3 (in-place)
I1007 12:33:17.303679  4874 layer_factory.hpp:77] Creating layer Scale3
I1007 12:33:17.303755  4874 net.cpp:122] Setting up Scale3
I1007 12:33:17.303758  4874 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 12:33:17.303761  4874 net.cpp:137] Memory required for data: 86426800
I1007 12:33:17.303764  4874 layer_factory.hpp:77] Creating layer Eltwise1
I1007 12:33:17.303769  4874 net.cpp:84] Creating Layer Eltwise1
I1007 12:33:17.303771  4874 net.cpp:406] Eltwise1 <- Convolution1_M2PELU1_0_split_1
I1007 12:33:17.303774  4874 net.cpp:406] Eltwise1 <- Convolution3
I1007 12:33:17.303778  4874 net.cpp:380] Eltwise1 -> Eltwise1
I1007 12:33:17.303794  4874 net.cpp:122] Setting up Eltwise1
I1007 12:33:17.303797  4874 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 12:33:17.303799  4874 net.cpp:137] Memory required for data: 92980400
I1007 12:33:17.303802  4874 layer_factory.hpp:77] Creating layer M2PELU3
I1007 12:33:17.303808  4874 net.cpp:84] Creating Layer M2PELU3
I1007 12:33:17.303812  4874 net.cpp:406] M2PELU3 <- Eltwise1
I1007 12:33:17.303815  4874 net.cpp:367] M2PELU3 -> Eltwise1 (in-place)
I1007 12:33:17.303905  4874 net.cpp:122] Setting up M2PELU3
I1007 12:33:17.303910  4874 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 12:33:17.303912  4874 net.cpp:137] Memory required for data: 99534000
I1007 12:33:17.303915  4874 layer_factory.hpp:77] Creating layer Eltwise1_M2PELU3_0_split
I1007 12:33:17.303920  4874 net.cpp:84] Creating Layer Eltwise1_M2PELU3_0_split
I1007 12:33:17.303923  4874 net.cpp:406] Eltwise1_M2PELU3_0_split <- Eltwise1
I1007 12:33:17.303926  4874 net.cpp:380] Eltwise1_M2PELU3_0_split -> Eltwise1_M2PELU3_0_split_0
I1007 12:33:17.303930  4874 net.cpp:380] Eltwise1_M2PELU3_0_split -> Eltwise1_M2PELU3_0_split_1
I1007 12:33:17.303956  4874 net.cpp:122] Setting up Eltwise1_M2PELU3_0_split
I1007 12:33:17.303961  4874 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 12:33:17.303962  4874 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 12:33:17.303964  4874 net.cpp:137] Memory required for data: 112641200
I1007 12:33:17.303967  4874 layer_factory.hpp:77] Creating layer Convolution4
I1007 12:33:17.303973  4874 net.cpp:84] Creating Layer Convolution4
I1007 12:33:17.303977  4874 net.cpp:406] Convolution4 <- Eltwise1_M2PELU3_0_split_0
I1007 12:33:17.303982  4874 net.cpp:380] Convolution4 -> Convolution4
I1007 12:33:17.305058  4874 net.cpp:122] Setting up Convolution4
I1007 12:33:17.305068  4874 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 12:33:17.305070  4874 net.cpp:137] Memory required for data: 119194800
I1007 12:33:17.305075  4874 layer_factory.hpp:77] Creating layer BatchNorm4
I1007 12:33:17.305081  4874 net.cpp:84] Creating Layer BatchNorm4
I1007 12:33:17.305083  4874 net.cpp:406] BatchNorm4 <- Convolution4
I1007 12:33:17.305088  4874 net.cpp:367] BatchNorm4 -> Convolution4 (in-place)
I1007 12:33:17.305224  4874 net.cpp:122] Setting up BatchNorm4
I1007 12:33:17.305228  4874 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 12:33:17.305232  4874 net.cpp:137] Memory required for data: 125748400
I1007 12:33:17.305235  4874 layer_factory.hpp:77] Creating layer Scale4
I1007 12:33:17.305239  4874 net.cpp:84] Creating Layer Scale4
I1007 12:33:17.305243  4874 net.cpp:406] Scale4 <- Convolution4
I1007 12:33:17.305245  4874 net.cpp:367] Scale4 -> Convolution4 (in-place)
I1007 12:33:17.305272  4874 layer_factory.hpp:77] Creating layer Scale4
I1007 12:33:17.305347  4874 net.cpp:122] Setting up Scale4
I1007 12:33:17.305351  4874 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 12:33:17.305359  4874 net.cpp:137] Memory required for data: 132302000
I1007 12:33:17.305367  4874 layer_factory.hpp:77] Creating layer M2PELU4
I1007 12:33:17.305375  4874 net.cpp:84] Creating Layer M2PELU4
I1007 12:33:17.305377  4874 net.cpp:406] M2PELU4 <- Convolution4
I1007 12:33:17.305382  4874 net.cpp:367] M2PELU4 -> Convolution4 (in-place)
I1007 12:33:17.305477  4874 net.cpp:122] Setting up M2PELU4
I1007 12:33:17.305481  4874 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 12:33:17.305485  4874 net.cpp:137] Memory required for data: 138855600
I1007 12:33:17.305488  4874 layer_factory.hpp:77] Creating layer Convolution5
I1007 12:33:17.305495  4874 net.cpp:84] Creating Layer Convolution5
I1007 12:33:17.305500  4874 net.cpp:406] Convolution5 <- Convolution4
I1007 12:33:17.305503  4874 net.cpp:380] Convolution5 -> Convolution5
I1007 12:33:17.306435  4874 net.cpp:122] Setting up Convolution5
I1007 12:33:17.306443  4874 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 12:33:17.306447  4874 net.cpp:137] Memory required for data: 145409200
I1007 12:33:17.306450  4874 layer_factory.hpp:77] Creating layer BatchNorm5
I1007 12:33:17.306455  4874 net.cpp:84] Creating Layer BatchNorm5
I1007 12:33:17.306458  4874 net.cpp:406] BatchNorm5 <- Convolution5
I1007 12:33:17.306463  4874 net.cpp:367] BatchNorm5 -> Convolution5 (in-place)
I1007 12:33:17.306597  4874 net.cpp:122] Setting up BatchNorm5
I1007 12:33:17.306602  4874 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 12:33:17.306604  4874 net.cpp:137] Memory required for data: 151962800
I1007 12:33:17.306609  4874 layer_factory.hpp:77] Creating layer Scale5
I1007 12:33:17.306614  4874 net.cpp:84] Creating Layer Scale5
I1007 12:33:17.306617  4874 net.cpp:406] Scale5 <- Convolution5
I1007 12:33:17.306619  4874 net.cpp:367] Scale5 -> Convolution5 (in-place)
I1007 12:33:17.306648  4874 layer_factory.hpp:77] Creating layer Scale5
I1007 12:33:17.306723  4874 net.cpp:122] Setting up Scale5
I1007 12:33:17.306728  4874 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 12:33:17.306730  4874 net.cpp:137] Memory required for data: 158516400
I1007 12:33:17.306733  4874 layer_factory.hpp:77] Creating layer Eltwise2
I1007 12:33:17.306737  4874 net.cpp:84] Creating Layer Eltwise2
I1007 12:33:17.306740  4874 net.cpp:406] Eltwise2 <- Eltwise1_M2PELU3_0_split_1
I1007 12:33:17.306742  4874 net.cpp:406] Eltwise2 <- Convolution5
I1007 12:33:17.306746  4874 net.cpp:380] Eltwise2 -> Eltwise2
I1007 12:33:17.306761  4874 net.cpp:122] Setting up Eltwise2
I1007 12:33:17.306766  4874 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 12:33:17.306767  4874 net.cpp:137] Memory required for data: 165070000
I1007 12:33:17.306769  4874 layer_factory.hpp:77] Creating layer M2PELU5
I1007 12:33:17.306773  4874 net.cpp:84] Creating Layer M2PELU5
I1007 12:33:17.306777  4874 net.cpp:406] M2PELU5 <- Eltwise2
I1007 12:33:17.306779  4874 net.cpp:367] M2PELU5 -> Eltwise2 (in-place)
I1007 12:33:17.306869  4874 net.cpp:122] Setting up M2PELU5
I1007 12:33:17.306874  4874 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 12:33:17.306875  4874 net.cpp:137] Memory required for data: 171623600
I1007 12:33:17.306879  4874 layer_factory.hpp:77] Creating layer Eltwise2_M2PELU5_0_split
I1007 12:33:17.306882  4874 net.cpp:84] Creating Layer Eltwise2_M2PELU5_0_split
I1007 12:33:17.306885  4874 net.cpp:406] Eltwise2_M2PELU5_0_split <- Eltwise2
I1007 12:33:17.306888  4874 net.cpp:380] Eltwise2_M2PELU5_0_split -> Eltwise2_M2PELU5_0_split_0
I1007 12:33:17.306892  4874 net.cpp:380] Eltwise2_M2PELU5_0_split -> Eltwise2_M2PELU5_0_split_1
I1007 12:33:17.306916  4874 net.cpp:122] Setting up Eltwise2_M2PELU5_0_split
I1007 12:33:17.306921  4874 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 12:33:17.306926  4874 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 12:33:17.306927  4874 net.cpp:137] Memory required for data: 184730800
I1007 12:33:17.306929  4874 layer_factory.hpp:77] Creating layer Convolution6
I1007 12:33:17.306936  4874 net.cpp:84] Creating Layer Convolution6
I1007 12:33:17.306937  4874 net.cpp:406] Convolution6 <- Eltwise2_M2PELU5_0_split_0
I1007 12:33:17.306948  4874 net.cpp:380] Convolution6 -> Convolution6
I1007 12:33:17.307873  4874 net.cpp:122] Setting up Convolution6
I1007 12:33:17.307883  4874 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 12:33:17.307884  4874 net.cpp:137] Memory required for data: 191284400
I1007 12:33:17.307888  4874 layer_factory.hpp:77] Creating layer BatchNorm6
I1007 12:33:17.307894  4874 net.cpp:84] Creating Layer BatchNorm6
I1007 12:33:17.307898  4874 net.cpp:406] BatchNorm6 <- Convolution6
I1007 12:33:17.307900  4874 net.cpp:367] BatchNorm6 -> Convolution6 (in-place)
I1007 12:33:17.308034  4874 net.cpp:122] Setting up BatchNorm6
I1007 12:33:17.308038  4874 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 12:33:17.308040  4874 net.cpp:137] Memory required for data: 197838000
I1007 12:33:17.308044  4874 layer_factory.hpp:77] Creating layer Scale6
I1007 12:33:17.308049  4874 net.cpp:84] Creating Layer Scale6
I1007 12:33:17.324846  4874 net.cpp:406] Scale6 <- Convolution6
I1007 12:33:17.324856  4874 net.cpp:367] Scale6 -> Convolution6 (in-place)
I1007 12:33:17.324900  4874 layer_factory.hpp:77] Creating layer Scale6
I1007 12:33:17.324990  4874 net.cpp:122] Setting up Scale6
I1007 12:33:17.324996  4874 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 12:33:17.324998  4874 net.cpp:137] Memory required for data: 204391600
I1007 12:33:17.325003  4874 layer_factory.hpp:77] Creating layer M2PELU6
I1007 12:33:17.325009  4874 net.cpp:84] Creating Layer M2PELU6
I1007 12:33:17.325012  4874 net.cpp:406] M2PELU6 <- Convolution6
I1007 12:33:17.325016  4874 net.cpp:367] M2PELU6 -> Convolution6 (in-place)
I1007 12:33:17.325119  4874 net.cpp:122] Setting up M2PELU6
I1007 12:33:17.325124  4874 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 12:33:17.325125  4874 net.cpp:137] Memory required for data: 210945200
I1007 12:33:17.325130  4874 layer_factory.hpp:77] Creating layer Convolution7
I1007 12:33:17.325137  4874 net.cpp:84] Creating Layer Convolution7
I1007 12:33:17.325140  4874 net.cpp:406] Convolution7 <- Convolution6
I1007 12:33:17.325145  4874 net.cpp:380] Convolution7 -> Convolution7
I1007 12:33:17.326143  4874 net.cpp:122] Setting up Convolution7
I1007 12:33:17.326153  4874 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 12:33:17.326155  4874 net.cpp:137] Memory required for data: 217498800
I1007 12:33:17.326160  4874 layer_factory.hpp:77] Creating layer BatchNorm7
I1007 12:33:17.326169  4874 net.cpp:84] Creating Layer BatchNorm7
I1007 12:33:17.326171  4874 net.cpp:406] BatchNorm7 <- Convolution7
I1007 12:33:17.326175  4874 net.cpp:367] BatchNorm7 -> Convolution7 (in-place)
I1007 12:33:17.326328  4874 net.cpp:122] Setting up BatchNorm7
I1007 12:33:17.326333  4874 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 12:33:17.326334  4874 net.cpp:137] Memory required for data: 224052400
I1007 12:33:17.326339  4874 layer_factory.hpp:77] Creating layer Scale7
I1007 12:33:17.326344  4874 net.cpp:84] Creating Layer Scale7
I1007 12:33:17.326346  4874 net.cpp:406] Scale7 <- Convolution7
I1007 12:33:17.326350  4874 net.cpp:367] Scale7 -> Convolution7 (in-place)
I1007 12:33:17.326387  4874 layer_factory.hpp:77] Creating layer Scale7
I1007 12:33:17.326467  4874 net.cpp:122] Setting up Scale7
I1007 12:33:17.326472  4874 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 12:33:17.326474  4874 net.cpp:137] Memory required for data: 230606000
I1007 12:33:17.326478  4874 layer_factory.hpp:77] Creating layer Eltwise3
I1007 12:33:17.326483  4874 net.cpp:84] Creating Layer Eltwise3
I1007 12:33:17.326486  4874 net.cpp:406] Eltwise3 <- Eltwise2_M2PELU5_0_split_1
I1007 12:33:17.326489  4874 net.cpp:406] Eltwise3 <- Convolution7
I1007 12:33:17.326493  4874 net.cpp:380] Eltwise3 -> Eltwise3
I1007 12:33:17.326510  4874 net.cpp:122] Setting up Eltwise3
I1007 12:33:17.326514  4874 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 12:33:17.326516  4874 net.cpp:137] Memory required for data: 237159600
I1007 12:33:17.326519  4874 layer_factory.hpp:77] Creating layer M2PELU7
I1007 12:33:17.326531  4874 net.cpp:84] Creating Layer M2PELU7
I1007 12:33:17.326534  4874 net.cpp:406] M2PELU7 <- Eltwise3
I1007 12:33:17.326537  4874 net.cpp:367] M2PELU7 -> Eltwise3 (in-place)
I1007 12:33:17.326647  4874 net.cpp:122] Setting up M2PELU7
I1007 12:33:17.326650  4874 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 12:33:17.326653  4874 net.cpp:137] Memory required for data: 243713200
I1007 12:33:17.326656  4874 layer_factory.hpp:77] Creating layer Eltwise3_M2PELU7_0_split
I1007 12:33:17.326660  4874 net.cpp:84] Creating Layer Eltwise3_M2PELU7_0_split
I1007 12:33:17.326663  4874 net.cpp:406] Eltwise3_M2PELU7_0_split <- Eltwise3
I1007 12:33:17.326666  4874 net.cpp:380] Eltwise3_M2PELU7_0_split -> Eltwise3_M2PELU7_0_split_0
I1007 12:33:17.326671  4874 net.cpp:380] Eltwise3_M2PELU7_0_split -> Eltwise3_M2PELU7_0_split_1
I1007 12:33:17.326695  4874 net.cpp:122] Setting up Eltwise3_M2PELU7_0_split
I1007 12:33:17.326699  4874 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 12:33:17.326702  4874 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 12:33:17.326704  4874 net.cpp:137] Memory required for data: 256820400
I1007 12:33:17.326706  4874 layer_factory.hpp:77] Creating layer Convolution8
I1007 12:33:17.326711  4874 net.cpp:84] Creating Layer Convolution8
I1007 12:33:17.326714  4874 net.cpp:406] Convolution8 <- Eltwise3_M2PELU7_0_split_0
I1007 12:33:17.326719  4874 net.cpp:380] Convolution8 -> Convolution8
I1007 12:33:17.327726  4874 net.cpp:122] Setting up Convolution8
I1007 12:33:17.327735  4874 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 12:33:17.327738  4874 net.cpp:137] Memory required for data: 263374000
I1007 12:33:17.327749  4874 layer_factory.hpp:77] Creating layer BatchNorm8
I1007 12:33:17.327754  4874 net.cpp:84] Creating Layer BatchNorm8
I1007 12:33:17.327756  4874 net.cpp:406] BatchNorm8 <- Convolution8
I1007 12:33:17.327761  4874 net.cpp:367] BatchNorm8 -> Convolution8 (in-place)
I1007 12:33:17.327898  4874 net.cpp:122] Setting up BatchNorm8
I1007 12:33:17.327903  4874 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 12:33:17.327905  4874 net.cpp:137] Memory required for data: 269927600
I1007 12:33:17.327910  4874 layer_factory.hpp:77] Creating layer Scale8
I1007 12:33:17.327915  4874 net.cpp:84] Creating Layer Scale8
I1007 12:33:17.327917  4874 net.cpp:406] Scale8 <- Convolution8
I1007 12:33:17.327920  4874 net.cpp:367] Scale8 -> Convolution8 (in-place)
I1007 12:33:17.327950  4874 layer_factory.hpp:77] Creating layer Scale8
I1007 12:33:17.328028  4874 net.cpp:122] Setting up Scale8
I1007 12:33:17.328032  4874 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 12:33:17.328034  4874 net.cpp:137] Memory required for data: 276481200
I1007 12:33:17.328049  4874 layer_factory.hpp:77] Creating layer M2PELU8
I1007 12:33:17.328053  4874 net.cpp:84] Creating Layer M2PELU8
I1007 12:33:17.328057  4874 net.cpp:406] M2PELU8 <- Convolution8
I1007 12:33:17.328060  4874 net.cpp:367] M2PELU8 -> Convolution8 (in-place)
I1007 12:33:17.328198  4874 net.cpp:122] Setting up M2PELU8
I1007 12:33:17.328204  4874 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 12:33:17.328207  4874 net.cpp:137] Memory required for data: 283034800
I1007 12:33:17.328212  4874 layer_factory.hpp:77] Creating layer Convolution9
I1007 12:33:17.328219  4874 net.cpp:84] Creating Layer Convolution9
I1007 12:33:17.328222  4874 net.cpp:406] Convolution9 <- Convolution8
I1007 12:33:17.328227  4874 net.cpp:380] Convolution9 -> Convolution9
I1007 12:33:17.329543  4874 net.cpp:122] Setting up Convolution9
I1007 12:33:17.329552  4874 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 12:33:17.329555  4874 net.cpp:137] Memory required for data: 289588400
I1007 12:33:17.329560  4874 layer_factory.hpp:77] Creating layer BatchNorm9
I1007 12:33:17.329565  4874 net.cpp:84] Creating Layer BatchNorm9
I1007 12:33:17.329566  4874 net.cpp:406] BatchNorm9 <- Convolution9
I1007 12:33:17.329571  4874 net.cpp:367] BatchNorm9 -> Convolution9 (in-place)
I1007 12:33:17.329710  4874 net.cpp:122] Setting up BatchNorm9
I1007 12:33:17.329713  4874 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 12:33:17.329722  4874 net.cpp:137] Memory required for data: 296142000
I1007 12:33:17.329727  4874 layer_factory.hpp:77] Creating layer Scale9
I1007 12:33:17.329731  4874 net.cpp:84] Creating Layer Scale9
I1007 12:33:17.329735  4874 net.cpp:406] Scale9 <- Convolution9
I1007 12:33:17.329737  4874 net.cpp:367] Scale9 -> Convolution9 (in-place)
I1007 12:33:17.329766  4874 layer_factory.hpp:77] Creating layer Scale9
I1007 12:33:17.329844  4874 net.cpp:122] Setting up Scale9
I1007 12:33:17.329849  4874 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 12:33:17.329851  4874 net.cpp:137] Memory required for data: 302695600
I1007 12:33:17.329855  4874 layer_factory.hpp:77] Creating layer Eltwise4
I1007 12:33:17.329859  4874 net.cpp:84] Creating Layer Eltwise4
I1007 12:33:17.329861  4874 net.cpp:406] Eltwise4 <- Eltwise3_M2PELU7_0_split_1
I1007 12:33:17.329864  4874 net.cpp:406] Eltwise4 <- Convolution9
I1007 12:33:17.329867  4874 net.cpp:380] Eltwise4 -> Eltwise4
I1007 12:33:17.329883  4874 net.cpp:122] Setting up Eltwise4
I1007 12:33:17.329887  4874 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 12:33:17.329890  4874 net.cpp:137] Memory required for data: 309249200
I1007 12:33:17.329891  4874 layer_factory.hpp:77] Creating layer M2PELU9
I1007 12:33:17.329896  4874 net.cpp:84] Creating Layer M2PELU9
I1007 12:33:17.329898  4874 net.cpp:406] M2PELU9 <- Eltwise4
I1007 12:33:17.329902  4874 net.cpp:367] M2PELU9 -> Eltwise4 (in-place)
I1007 12:33:17.329995  4874 net.cpp:122] Setting up M2PELU9
I1007 12:33:17.329999  4874 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 12:33:17.330001  4874 net.cpp:137] Memory required for data: 315802800
I1007 12:33:17.330005  4874 layer_factory.hpp:77] Creating layer Eltwise4_M2PELU9_0_split
I1007 12:33:17.330009  4874 net.cpp:84] Creating Layer Eltwise4_M2PELU9_0_split
I1007 12:33:17.330011  4874 net.cpp:406] Eltwise4_M2PELU9_0_split <- Eltwise4
I1007 12:33:17.330015  4874 net.cpp:380] Eltwise4_M2PELU9_0_split -> Eltwise4_M2PELU9_0_split_0
I1007 12:33:17.330018  4874 net.cpp:380] Eltwise4_M2PELU9_0_split -> Eltwise4_M2PELU9_0_split_1
I1007 12:33:17.330044  4874 net.cpp:122] Setting up Eltwise4_M2PELU9_0_split
I1007 12:33:17.330046  4874 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 12:33:17.330049  4874 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 12:33:17.330051  4874 net.cpp:137] Memory required for data: 328910000
I1007 12:33:17.330054  4874 layer_factory.hpp:77] Creating layer Convolution10
I1007 12:33:17.330060  4874 net.cpp:84] Creating Layer Convolution10
I1007 12:33:17.330062  4874 net.cpp:406] Convolution10 <- Eltwise4_M2PELU9_0_split_0
I1007 12:33:17.330066  4874 net.cpp:380] Convolution10 -> Convolution10
I1007 12:33:17.330637  4874 net.cpp:122] Setting up Convolution10
I1007 12:33:17.330646  4874 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 12:33:17.330647  4874 net.cpp:137] Memory required for data: 335463600
I1007 12:33:17.330651  4874 layer_factory.hpp:77] Creating layer BatchNorm10
I1007 12:33:17.330657  4874 net.cpp:84] Creating Layer BatchNorm10
I1007 12:33:17.330659  4874 net.cpp:406] BatchNorm10 <- Convolution10
I1007 12:33:17.330663  4874 net.cpp:367] BatchNorm10 -> Convolution10 (in-place)
I1007 12:33:17.330818  4874 net.cpp:122] Setting up BatchNorm10
I1007 12:33:17.330823  4874 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 12:33:17.330826  4874 net.cpp:137] Memory required for data: 342017200
I1007 12:33:17.330829  4874 layer_factory.hpp:77] Creating layer Scale10
I1007 12:33:17.330833  4874 net.cpp:84] Creating Layer Scale10
I1007 12:33:17.330835  4874 net.cpp:406] Scale10 <- Convolution10
I1007 12:33:17.330839  4874 net.cpp:367] Scale10 -> Convolution10 (in-place)
I1007 12:33:17.330868  4874 layer_factory.hpp:77] Creating layer Scale10
I1007 12:33:17.330945  4874 net.cpp:122] Setting up Scale10
I1007 12:33:17.330950  4874 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 12:33:17.330951  4874 net.cpp:137] Memory required for data: 348570800
I1007 12:33:17.330955  4874 layer_factory.hpp:77] Creating layer M2PELU10
I1007 12:33:17.330965  4874 net.cpp:84] Creating Layer M2PELU10
I1007 12:33:17.330967  4874 net.cpp:406] M2PELU10 <- Convolution10
I1007 12:33:17.330971  4874 net.cpp:367] M2PELU10 -> Convolution10 (in-place)
I1007 12:33:17.331064  4874 net.cpp:122] Setting up M2PELU10
I1007 12:33:17.331068  4874 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 12:33:17.331070  4874 net.cpp:137] Memory required for data: 355124400
I1007 12:33:17.331074  4874 layer_factory.hpp:77] Creating layer Convolution11
I1007 12:33:17.331081  4874 net.cpp:84] Creating Layer Convolution11
I1007 12:33:17.331084  4874 net.cpp:406] Convolution11 <- Convolution10
I1007 12:33:17.331089  4874 net.cpp:380] Convolution11 -> Convolution11
I1007 12:33:17.332006  4874 net.cpp:122] Setting up Convolution11
I1007 12:33:17.332015  4874 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 12:33:17.332017  4874 net.cpp:137] Memory required for data: 361678000
I1007 12:33:17.332022  4874 layer_factory.hpp:77] Creating layer BatchNorm11
I1007 12:33:17.332027  4874 net.cpp:84] Creating Layer BatchNorm11
I1007 12:33:17.332029  4874 net.cpp:406] BatchNorm11 <- Convolution11
I1007 12:33:17.332033  4874 net.cpp:367] BatchNorm11 -> Convolution11 (in-place)
I1007 12:33:17.332170  4874 net.cpp:122] Setting up BatchNorm11
I1007 12:33:17.332175  4874 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 12:33:17.332177  4874 net.cpp:137] Memory required for data: 368231600
I1007 12:33:17.332181  4874 layer_factory.hpp:77] Creating layer Scale11
I1007 12:33:17.332185  4874 net.cpp:84] Creating Layer Scale11
I1007 12:33:17.332188  4874 net.cpp:406] Scale11 <- Convolution11
I1007 12:33:17.332191  4874 net.cpp:367] Scale11 -> Convolution11 (in-place)
I1007 12:33:17.332218  4874 layer_factory.hpp:77] Creating layer Scale11
I1007 12:33:17.332294  4874 net.cpp:122] Setting up Scale11
I1007 12:33:17.332299  4874 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 12:33:17.332301  4874 net.cpp:137] Memory required for data: 374785200
I1007 12:33:17.332305  4874 layer_factory.hpp:77] Creating layer Eltwise5
I1007 12:33:17.332309  4874 net.cpp:84] Creating Layer Eltwise5
I1007 12:33:17.332311  4874 net.cpp:406] Eltwise5 <- Eltwise4_M2PELU9_0_split_1
I1007 12:33:17.332314  4874 net.cpp:406] Eltwise5 <- Convolution11
I1007 12:33:17.332317  4874 net.cpp:380] Eltwise5 -> Eltwise5
I1007 12:33:17.332334  4874 net.cpp:122] Setting up Eltwise5
I1007 12:33:17.332339  4874 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 12:33:17.332340  4874 net.cpp:137] Memory required for data: 381338800
I1007 12:33:17.332342  4874 layer_factory.hpp:77] Creating layer M2PELU11
I1007 12:33:17.332347  4874 net.cpp:84] Creating Layer M2PELU11
I1007 12:33:17.332350  4874 net.cpp:406] M2PELU11 <- Eltwise5
I1007 12:33:17.332353  4874 net.cpp:367] M2PELU11 -> Eltwise5 (in-place)
I1007 12:33:17.332446  4874 net.cpp:122] Setting up M2PELU11
I1007 12:33:17.332450  4874 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 12:33:17.332453  4874 net.cpp:137] Memory required for data: 387892400
I1007 12:33:17.332456  4874 layer_factory.hpp:77] Creating layer Eltwise5_M2PELU11_0_split
I1007 12:33:17.332459  4874 net.cpp:84] Creating Layer Eltwise5_M2PELU11_0_split
I1007 12:33:17.332463  4874 net.cpp:406] Eltwise5_M2PELU11_0_split <- Eltwise5
I1007 12:33:17.332465  4874 net.cpp:380] Eltwise5_M2PELU11_0_split -> Eltwise5_M2PELU11_0_split_0
I1007 12:33:17.332470  4874 net.cpp:380] Eltwise5_M2PELU11_0_split -> Eltwise5_M2PELU11_0_split_1
I1007 12:33:17.332495  4874 net.cpp:122] Setting up Eltwise5_M2PELU11_0_split
I1007 12:33:17.332499  4874 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 12:33:17.332502  4874 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 12:33:17.332504  4874 net.cpp:137] Memory required for data: 400999600
I1007 12:33:17.332506  4874 layer_factory.hpp:77] Creating layer Convolution12
I1007 12:33:17.332512  4874 net.cpp:84] Creating Layer Convolution12
I1007 12:33:17.332515  4874 net.cpp:406] Convolution12 <- Eltwise5_M2PELU11_0_split_0
I1007 12:33:17.332518  4874 net.cpp:380] Convolution12 -> Convolution12
I1007 12:33:17.333395  4874 net.cpp:122] Setting up Convolution12
I1007 12:33:17.333405  4874 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 12:33:17.333407  4874 net.cpp:137] Memory required for data: 404276400
I1007 12:33:17.333411  4874 layer_factory.hpp:77] Creating layer BatchNorm12
I1007 12:33:17.333416  4874 net.cpp:84] Creating Layer BatchNorm12
I1007 12:33:17.333418  4874 net.cpp:406] BatchNorm12 <- Convolution12
I1007 12:33:17.333422  4874 net.cpp:367] BatchNorm12 -> Convolution12 (in-place)
I1007 12:33:17.333555  4874 net.cpp:122] Setting up BatchNorm12
I1007 12:33:17.333559  4874 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 12:33:17.333561  4874 net.cpp:137] Memory required for data: 407553200
I1007 12:33:17.333566  4874 layer_factory.hpp:77] Creating layer Scale12
I1007 12:33:17.333571  4874 net.cpp:84] Creating Layer Scale12
I1007 12:33:17.355233  4874 net.cpp:406] Scale12 <- Convolution12
I1007 12:33:17.355243  4874 net.cpp:367] Scale12 -> Convolution12 (in-place)
I1007 12:33:17.355288  4874 layer_factory.hpp:77] Creating layer Scale12
I1007 12:33:17.355378  4874 net.cpp:122] Setting up Scale12
I1007 12:33:17.355384  4874 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 12:33:17.355386  4874 net.cpp:137] Memory required for data: 410830000
I1007 12:33:17.355391  4874 layer_factory.hpp:77] Creating layer Convolution13
I1007 12:33:17.355399  4874 net.cpp:84] Creating Layer Convolution13
I1007 12:33:17.355402  4874 net.cpp:406] Convolution13 <- Eltwise5_M2PELU11_0_split_1
I1007 12:33:17.355406  4874 net.cpp:380] Convolution13 -> Convolution13
I1007 12:33:17.356470  4874 net.cpp:122] Setting up Convolution13
I1007 12:33:17.356480  4874 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 12:33:17.356483  4874 net.cpp:137] Memory required for data: 414106800
I1007 12:33:17.356488  4874 layer_factory.hpp:77] Creating layer BatchNorm13
I1007 12:33:17.356494  4874 net.cpp:84] Creating Layer BatchNorm13
I1007 12:33:17.356498  4874 net.cpp:406] BatchNorm13 <- Convolution13
I1007 12:33:17.356503  4874 net.cpp:367] BatchNorm13 -> Convolution13 (in-place)
I1007 12:33:17.356652  4874 net.cpp:122] Setting up BatchNorm13
I1007 12:33:17.356657  4874 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 12:33:17.356659  4874 net.cpp:137] Memory required for data: 417383600
I1007 12:33:17.356664  4874 layer_factory.hpp:77] Creating layer Scale13
I1007 12:33:17.356668  4874 net.cpp:84] Creating Layer Scale13
I1007 12:33:17.356672  4874 net.cpp:406] Scale13 <- Convolution13
I1007 12:33:17.356675  4874 net.cpp:367] Scale13 -> Convolution13 (in-place)
I1007 12:33:17.356705  4874 layer_factory.hpp:77] Creating layer Scale13
I1007 12:33:17.356798  4874 net.cpp:122] Setting up Scale13
I1007 12:33:17.356803  4874 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 12:33:17.356806  4874 net.cpp:137] Memory required for data: 420660400
I1007 12:33:17.356809  4874 layer_factory.hpp:77] Creating layer M2PELU12
I1007 12:33:17.356814  4874 net.cpp:84] Creating Layer M2PELU12
I1007 12:33:17.356817  4874 net.cpp:406] M2PELU12 <- Convolution13
I1007 12:33:17.356822  4874 net.cpp:367] M2PELU12 -> Convolution13 (in-place)
I1007 12:33:17.356911  4874 net.cpp:122] Setting up M2PELU12
I1007 12:33:17.356915  4874 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 12:33:17.356917  4874 net.cpp:137] Memory required for data: 423937200
I1007 12:33:17.356921  4874 layer_factory.hpp:77] Creating layer Convolution14
I1007 12:33:17.356932  4874 net.cpp:84] Creating Layer Convolution14
I1007 12:33:17.356935  4874 net.cpp:406] Convolution14 <- Convolution13
I1007 12:33:17.356940  4874 net.cpp:380] Convolution14 -> Convolution14
I1007 12:33:17.358038  4874 net.cpp:122] Setting up Convolution14
I1007 12:33:17.358047  4874 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 12:33:17.358049  4874 net.cpp:137] Memory required for data: 427214000
I1007 12:33:17.358054  4874 layer_factory.hpp:77] Creating layer BatchNorm14
I1007 12:33:17.358059  4874 net.cpp:84] Creating Layer BatchNorm14
I1007 12:33:17.358070  4874 net.cpp:406] BatchNorm14 <- Convolution14
I1007 12:33:17.358075  4874 net.cpp:367] BatchNorm14 -> Convolution14 (in-place)
I1007 12:33:17.358213  4874 net.cpp:122] Setting up BatchNorm14
I1007 12:33:17.358218  4874 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 12:33:17.358220  4874 net.cpp:137] Memory required for data: 430490800
I1007 12:33:17.358224  4874 layer_factory.hpp:77] Creating layer Scale14
I1007 12:33:17.358229  4874 net.cpp:84] Creating Layer Scale14
I1007 12:33:17.358232  4874 net.cpp:406] Scale14 <- Convolution14
I1007 12:33:17.358235  4874 net.cpp:367] Scale14 -> Convolution14 (in-place)
I1007 12:33:17.358263  4874 layer_factory.hpp:77] Creating layer Scale14
I1007 12:33:17.358374  4874 net.cpp:122] Setting up Scale14
I1007 12:33:17.358381  4874 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 12:33:17.358384  4874 net.cpp:137] Memory required for data: 433767600
I1007 12:33:17.358391  4874 layer_factory.hpp:77] Creating layer Eltwise6
I1007 12:33:17.358397  4874 net.cpp:84] Creating Layer Eltwise6
I1007 12:33:17.358402  4874 net.cpp:406] Eltwise6 <- Convolution12
I1007 12:33:17.358405  4874 net.cpp:406] Eltwise6 <- Convolution14
I1007 12:33:17.358419  4874 net.cpp:380] Eltwise6 -> Eltwise6
I1007 12:33:17.358449  4874 net.cpp:122] Setting up Eltwise6
I1007 12:33:17.358453  4874 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 12:33:17.358455  4874 net.cpp:137] Memory required for data: 437044400
I1007 12:33:17.358458  4874 layer_factory.hpp:77] Creating layer M2PELU13
I1007 12:33:17.358463  4874 net.cpp:84] Creating Layer M2PELU13
I1007 12:33:17.358464  4874 net.cpp:406] M2PELU13 <- Eltwise6
I1007 12:33:17.358469  4874 net.cpp:367] M2PELU13 -> Eltwise6 (in-place)
I1007 12:33:17.358572  4874 net.cpp:122] Setting up M2PELU13
I1007 12:33:17.358577  4874 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 12:33:17.358578  4874 net.cpp:137] Memory required for data: 440321200
I1007 12:33:17.358582  4874 layer_factory.hpp:77] Creating layer Eltwise6_M2PELU13_0_split
I1007 12:33:17.358587  4874 net.cpp:84] Creating Layer Eltwise6_M2PELU13_0_split
I1007 12:33:17.358589  4874 net.cpp:406] Eltwise6_M2PELU13_0_split <- Eltwise6
I1007 12:33:17.358592  4874 net.cpp:380] Eltwise6_M2PELU13_0_split -> Eltwise6_M2PELU13_0_split_0
I1007 12:33:17.358597  4874 net.cpp:380] Eltwise6_M2PELU13_0_split -> Eltwise6_M2PELU13_0_split_1
I1007 12:33:17.358633  4874 net.cpp:122] Setting up Eltwise6_M2PELU13_0_split
I1007 12:33:17.358638  4874 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 12:33:17.358640  4874 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 12:33:17.358642  4874 net.cpp:137] Memory required for data: 446874800
I1007 12:33:17.358644  4874 layer_factory.hpp:77] Creating layer Convolution15
I1007 12:33:17.358650  4874 net.cpp:84] Creating Layer Convolution15
I1007 12:33:17.358654  4874 net.cpp:406] Convolution15 <- Eltwise6_M2PELU13_0_split_0
I1007 12:33:17.358659  4874 net.cpp:380] Convolution15 -> Convolution15
I1007 12:33:17.360138  4874 net.cpp:122] Setting up Convolution15
I1007 12:33:17.360147  4874 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 12:33:17.360150  4874 net.cpp:137] Memory required for data: 450151600
I1007 12:33:17.360155  4874 layer_factory.hpp:77] Creating layer BatchNorm15
I1007 12:33:17.360160  4874 net.cpp:84] Creating Layer BatchNorm15
I1007 12:33:17.360163  4874 net.cpp:406] BatchNorm15 <- Convolution15
I1007 12:33:17.360168  4874 net.cpp:367] BatchNorm15 -> Convolution15 (in-place)
I1007 12:33:17.360309  4874 net.cpp:122] Setting up BatchNorm15
I1007 12:33:17.360314  4874 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 12:33:17.360316  4874 net.cpp:137] Memory required for data: 453428400
I1007 12:33:17.360332  4874 layer_factory.hpp:77] Creating layer Scale15
I1007 12:33:17.360337  4874 net.cpp:84] Creating Layer Scale15
I1007 12:33:17.360339  4874 net.cpp:406] Scale15 <- Convolution15
I1007 12:33:17.360342  4874 net.cpp:367] Scale15 -> Convolution15 (in-place)
I1007 12:33:17.360373  4874 layer_factory.hpp:77] Creating layer Scale15
I1007 12:33:17.360463  4874 net.cpp:122] Setting up Scale15
I1007 12:33:17.360468  4874 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 12:33:17.360471  4874 net.cpp:137] Memory required for data: 456705200
I1007 12:33:17.360474  4874 layer_factory.hpp:77] Creating layer M2PELU14
I1007 12:33:17.360479  4874 net.cpp:84] Creating Layer M2PELU14
I1007 12:33:17.360481  4874 net.cpp:406] M2PELU14 <- Convolution15
I1007 12:33:17.360486  4874 net.cpp:367] M2PELU14 -> Convolution15 (in-place)
I1007 12:33:17.360575  4874 net.cpp:122] Setting up M2PELU14
I1007 12:33:17.360579  4874 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 12:33:17.360582  4874 net.cpp:137] Memory required for data: 459982000
I1007 12:33:17.360585  4874 layer_factory.hpp:77] Creating layer Convolution16
I1007 12:33:17.360592  4874 net.cpp:84] Creating Layer Convolution16
I1007 12:33:17.360595  4874 net.cpp:406] Convolution16 <- Convolution15
I1007 12:33:17.360599  4874 net.cpp:380] Convolution16 -> Convolution16
I1007 12:33:17.362200  4874 net.cpp:122] Setting up Convolution16
I1007 12:33:17.362210  4874 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 12:33:17.362211  4874 net.cpp:137] Memory required for data: 463258800
I1007 12:33:17.362216  4874 layer_factory.hpp:77] Creating layer BatchNorm16
I1007 12:33:17.362222  4874 net.cpp:84] Creating Layer BatchNorm16
I1007 12:33:17.362226  4874 net.cpp:406] BatchNorm16 <- Convolution16
I1007 12:33:17.362228  4874 net.cpp:367] BatchNorm16 -> Convolution16 (in-place)
I1007 12:33:17.362366  4874 net.cpp:122] Setting up BatchNorm16
I1007 12:33:17.362371  4874 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 12:33:17.362373  4874 net.cpp:137] Memory required for data: 466535600
I1007 12:33:17.362377  4874 layer_factory.hpp:77] Creating layer Scale16
I1007 12:33:17.362382  4874 net.cpp:84] Creating Layer Scale16
I1007 12:33:17.362385  4874 net.cpp:406] Scale16 <- Convolution16
I1007 12:33:17.362387  4874 net.cpp:367] Scale16 -> Convolution16 (in-place)
I1007 12:33:17.362417  4874 layer_factory.hpp:77] Creating layer Scale16
I1007 12:33:17.362499  4874 net.cpp:122] Setting up Scale16
I1007 12:33:17.362504  4874 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 12:33:17.362506  4874 net.cpp:137] Memory required for data: 469812400
I1007 12:33:17.362510  4874 layer_factory.hpp:77] Creating layer Eltwise7
I1007 12:33:17.362514  4874 net.cpp:84] Creating Layer Eltwise7
I1007 12:33:17.362516  4874 net.cpp:406] Eltwise7 <- Eltwise6_M2PELU13_0_split_1
I1007 12:33:17.362519  4874 net.cpp:406] Eltwise7 <- Convolution16
I1007 12:33:17.362524  4874 net.cpp:380] Eltwise7 -> Eltwise7
I1007 12:33:17.362537  4874 net.cpp:122] Setting up Eltwise7
I1007 12:33:17.362541  4874 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 12:33:17.362543  4874 net.cpp:137] Memory required for data: 473089200
I1007 12:33:17.362545  4874 layer_factory.hpp:77] Creating layer M2PELU15
I1007 12:33:17.362550  4874 net.cpp:84] Creating Layer M2PELU15
I1007 12:33:17.362552  4874 net.cpp:406] M2PELU15 <- Eltwise7
I1007 12:33:17.362556  4874 net.cpp:367] M2PELU15 -> Eltwise7 (in-place)
I1007 12:33:17.362644  4874 net.cpp:122] Setting up M2PELU15
I1007 12:33:17.362648  4874 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 12:33:17.362650  4874 net.cpp:137] Memory required for data: 476366000
I1007 12:33:17.362654  4874 layer_factory.hpp:77] Creating layer Eltwise7_M2PELU15_0_split
I1007 12:33:17.362658  4874 net.cpp:84] Creating Layer Eltwise7_M2PELU15_0_split
I1007 12:33:17.362660  4874 net.cpp:406] Eltwise7_M2PELU15_0_split <- Eltwise7
I1007 12:33:17.362664  4874 net.cpp:380] Eltwise7_M2PELU15_0_split -> Eltwise7_M2PELU15_0_split_0
I1007 12:33:17.362668  4874 net.cpp:380] Eltwise7_M2PELU15_0_split -> Eltwise7_M2PELU15_0_split_1
I1007 12:33:17.362692  4874 net.cpp:122] Setting up Eltwise7_M2PELU15_0_split
I1007 12:33:17.362696  4874 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 12:33:17.362699  4874 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 12:33:17.362701  4874 net.cpp:137] Memory required for data: 482919600
I1007 12:33:17.362704  4874 layer_factory.hpp:77] Creating layer Convolution17
I1007 12:33:17.362716  4874 net.cpp:84] Creating Layer Convolution17
I1007 12:33:17.362720  4874 net.cpp:406] Convolution17 <- Eltwise7_M2PELU15_0_split_0
I1007 12:33:17.362723  4874 net.cpp:380] Convolution17 -> Convolution17
I1007 12:33:17.363831  4874 net.cpp:122] Setting up Convolution17
I1007 12:33:17.363840  4874 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 12:33:17.363843  4874 net.cpp:137] Memory required for data: 486196400
I1007 12:33:17.363848  4874 layer_factory.hpp:77] Creating layer BatchNorm17
I1007 12:33:17.363853  4874 net.cpp:84] Creating Layer BatchNorm17
I1007 12:33:17.363857  4874 net.cpp:406] BatchNorm17 <- Convolution17
I1007 12:33:17.363860  4874 net.cpp:367] BatchNorm17 -> Convolution17 (in-place)
I1007 12:33:17.363999  4874 net.cpp:122] Setting up BatchNorm17
I1007 12:33:17.364003  4874 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 12:33:17.364006  4874 net.cpp:137] Memory required for data: 489473200
I1007 12:33:17.364011  4874 layer_factory.hpp:77] Creating layer Scale17
I1007 12:33:17.364015  4874 net.cpp:84] Creating Layer Scale17
I1007 12:33:17.364017  4874 net.cpp:406] Scale17 <- Convolution17
I1007 12:33:17.364022  4874 net.cpp:367] Scale17 -> Convolution17 (in-place)
I1007 12:33:17.364049  4874 layer_factory.hpp:77] Creating layer Scale17
I1007 12:33:17.364130  4874 net.cpp:122] Setting up Scale17
I1007 12:33:17.364135  4874 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 12:33:17.364136  4874 net.cpp:137] Memory required for data: 492750000
I1007 12:33:17.364140  4874 layer_factory.hpp:77] Creating layer M2PELU16
I1007 12:33:17.364147  4874 net.cpp:84] Creating Layer M2PELU16
I1007 12:33:17.364150  4874 net.cpp:406] M2PELU16 <- Convolution17
I1007 12:33:17.364153  4874 net.cpp:367] M2PELU16 -> Convolution17 (in-place)
I1007 12:33:17.364238  4874 net.cpp:122] Setting up M2PELU16
I1007 12:33:17.364241  4874 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 12:33:17.364243  4874 net.cpp:137] Memory required for data: 496026800
I1007 12:33:17.364248  4874 layer_factory.hpp:77] Creating layer Convolution18
I1007 12:33:17.364254  4874 net.cpp:84] Creating Layer Convolution18
I1007 12:33:17.364256  4874 net.cpp:406] Convolution18 <- Convolution17
I1007 12:33:17.364260  4874 net.cpp:380] Convolution18 -> Convolution18
I1007 12:33:17.365342  4874 net.cpp:122] Setting up Convolution18
I1007 12:33:17.365351  4874 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 12:33:17.365353  4874 net.cpp:137] Memory required for data: 499303600
I1007 12:33:17.365358  4874 layer_factory.hpp:77] Creating layer BatchNorm18
I1007 12:33:17.365363  4874 net.cpp:84] Creating Layer BatchNorm18
I1007 12:33:17.365365  4874 net.cpp:406] BatchNorm18 <- Convolution18
I1007 12:33:17.365370  4874 net.cpp:367] BatchNorm18 -> Convolution18 (in-place)
I1007 12:33:17.365532  4874 net.cpp:122] Setting up BatchNorm18
I1007 12:33:17.365536  4874 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 12:33:17.365538  4874 net.cpp:137] Memory required for data: 502580400
I1007 12:33:17.365543  4874 layer_factory.hpp:77] Creating layer Scale18
I1007 12:33:17.365547  4874 net.cpp:84] Creating Layer Scale18
I1007 12:33:17.365550  4874 net.cpp:406] Scale18 <- Convolution18
I1007 12:33:17.365555  4874 net.cpp:367] Scale18 -> Convolution18 (in-place)
I1007 12:33:17.365582  4874 layer_factory.hpp:77] Creating layer Scale18
I1007 12:33:17.365664  4874 net.cpp:122] Setting up Scale18
I1007 12:33:17.365667  4874 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 12:33:17.365669  4874 net.cpp:137] Memory required for data: 505857200
I1007 12:33:17.365674  4874 layer_factory.hpp:77] Creating layer Eltwise8
I1007 12:33:17.365677  4874 net.cpp:84] Creating Layer Eltwise8
I1007 12:33:17.365679  4874 net.cpp:406] Eltwise8 <- Eltwise7_M2PELU15_0_split_1
I1007 12:33:17.365682  4874 net.cpp:406] Eltwise8 <- Convolution18
I1007 12:33:17.365686  4874 net.cpp:380] Eltwise8 -> Eltwise8
I1007 12:33:17.365700  4874 net.cpp:122] Setting up Eltwise8
I1007 12:33:17.365703  4874 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 12:33:17.365711  4874 net.cpp:137] Memory required for data: 509134000
I1007 12:33:17.365715  4874 layer_factory.hpp:77] Creating layer M2PELU17
I1007 12:33:17.365720  4874 net.cpp:84] Creating Layer M2PELU17
I1007 12:33:17.365721  4874 net.cpp:406] M2PELU17 <- Eltwise8
I1007 12:33:17.365725  4874 net.cpp:367] M2PELU17 -> Eltwise8 (in-place)
I1007 12:33:17.365815  4874 net.cpp:122] Setting up M2PELU17
I1007 12:33:17.365820  4874 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 12:33:17.365823  4874 net.cpp:137] Memory required for data: 512410800
I1007 12:33:17.365826  4874 layer_factory.hpp:77] Creating layer Eltwise8_M2PELU17_0_split
I1007 12:33:17.365829  4874 net.cpp:84] Creating Layer Eltwise8_M2PELU17_0_split
I1007 12:33:17.385640  4874 net.cpp:406] Eltwise8_M2PELU17_0_split <- Eltwise8
I1007 12:33:17.385650  4874 net.cpp:380] Eltwise8_M2PELU17_0_split -> Eltwise8_M2PELU17_0_split_0
I1007 12:33:17.385658  4874 net.cpp:380] Eltwise8_M2PELU17_0_split -> Eltwise8_M2PELU17_0_split_1
I1007 12:33:17.385696  4874 net.cpp:122] Setting up Eltwise8_M2PELU17_0_split
I1007 12:33:17.385701  4874 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 12:33:17.385705  4874 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 12:33:17.385707  4874 net.cpp:137] Memory required for data: 518964400
I1007 12:33:17.385710  4874 layer_factory.hpp:77] Creating layer Convolution19
I1007 12:33:17.385717  4874 net.cpp:84] Creating Layer Convolution19
I1007 12:33:17.385720  4874 net.cpp:406] Convolution19 <- Eltwise8_M2PELU17_0_split_0
I1007 12:33:17.385725  4874 net.cpp:380] Convolution19 -> Convolution19
I1007 12:33:17.386909  4874 net.cpp:122] Setting up Convolution19
I1007 12:33:17.386919  4874 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 12:33:17.386921  4874 net.cpp:137] Memory required for data: 522241200
I1007 12:33:17.386926  4874 layer_factory.hpp:77] Creating layer BatchNorm19
I1007 12:33:17.386932  4874 net.cpp:84] Creating Layer BatchNorm19
I1007 12:33:17.386935  4874 net.cpp:406] BatchNorm19 <- Convolution19
I1007 12:33:17.386940  4874 net.cpp:367] BatchNorm19 -> Convolution19 (in-place)
I1007 12:33:17.387092  4874 net.cpp:122] Setting up BatchNorm19
I1007 12:33:17.387097  4874 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 12:33:17.387099  4874 net.cpp:137] Memory required for data: 525518000
I1007 12:33:17.387105  4874 layer_factory.hpp:77] Creating layer Scale19
I1007 12:33:17.387110  4874 net.cpp:84] Creating Layer Scale19
I1007 12:33:17.387114  4874 net.cpp:406] Scale19 <- Convolution19
I1007 12:33:17.387116  4874 net.cpp:367] Scale19 -> Convolution19 (in-place)
I1007 12:33:17.387148  4874 layer_factory.hpp:77] Creating layer Scale19
I1007 12:33:17.387248  4874 net.cpp:122] Setting up Scale19
I1007 12:33:17.387253  4874 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 12:33:17.387255  4874 net.cpp:137] Memory required for data: 528794800
I1007 12:33:17.387259  4874 layer_factory.hpp:77] Creating layer M2PELU18
I1007 12:33:17.387265  4874 net.cpp:84] Creating Layer M2PELU18
I1007 12:33:17.387267  4874 net.cpp:406] M2PELU18 <- Convolution19
I1007 12:33:17.387271  4874 net.cpp:367] M2PELU18 -> Convolution19 (in-place)
I1007 12:33:17.387373  4874 net.cpp:122] Setting up M2PELU18
I1007 12:33:17.387377  4874 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 12:33:17.387379  4874 net.cpp:137] Memory required for data: 532071600
I1007 12:33:17.387383  4874 layer_factory.hpp:77] Creating layer Convolution20
I1007 12:33:17.387390  4874 net.cpp:84] Creating Layer Convolution20
I1007 12:33:17.387393  4874 net.cpp:406] Convolution20 <- Convolution19
I1007 12:33:17.387398  4874 net.cpp:380] Convolution20 -> Convolution20
I1007 12:33:17.388140  4874 net.cpp:122] Setting up Convolution20
I1007 12:33:17.388149  4874 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 12:33:17.388151  4874 net.cpp:137] Memory required for data: 535348400
I1007 12:33:17.388155  4874 layer_factory.hpp:77] Creating layer BatchNorm20
I1007 12:33:17.388159  4874 net.cpp:84] Creating Layer BatchNorm20
I1007 12:33:17.388169  4874 net.cpp:406] BatchNorm20 <- Convolution20
I1007 12:33:17.388173  4874 net.cpp:367] BatchNorm20 -> Convolution20 (in-place)
I1007 12:33:17.388341  4874 net.cpp:122] Setting up BatchNorm20
I1007 12:33:17.388350  4874 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 12:33:17.388353  4874 net.cpp:137] Memory required for data: 538625200
I1007 12:33:17.388360  4874 layer_factory.hpp:77] Creating layer Scale20
I1007 12:33:17.388363  4874 net.cpp:84] Creating Layer Scale20
I1007 12:33:17.388365  4874 net.cpp:406] Scale20 <- Convolution20
I1007 12:33:17.388370  4874 net.cpp:367] Scale20 -> Convolution20 (in-place)
I1007 12:33:17.388401  4874 layer_factory.hpp:77] Creating layer Scale20
I1007 12:33:17.388486  4874 net.cpp:122] Setting up Scale20
I1007 12:33:17.388490  4874 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 12:33:17.388494  4874 net.cpp:137] Memory required for data: 541902000
I1007 12:33:17.388497  4874 layer_factory.hpp:77] Creating layer Eltwise9
I1007 12:33:17.388501  4874 net.cpp:84] Creating Layer Eltwise9
I1007 12:33:17.388504  4874 net.cpp:406] Eltwise9 <- Eltwise8_M2PELU17_0_split_1
I1007 12:33:17.388506  4874 net.cpp:406] Eltwise9 <- Convolution20
I1007 12:33:17.388510  4874 net.cpp:380] Eltwise9 -> Eltwise9
I1007 12:33:17.388525  4874 net.cpp:122] Setting up Eltwise9
I1007 12:33:17.388528  4874 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 12:33:17.388530  4874 net.cpp:137] Memory required for data: 545178800
I1007 12:33:17.388532  4874 layer_factory.hpp:77] Creating layer M2PELU19
I1007 12:33:17.388537  4874 net.cpp:84] Creating Layer M2PELU19
I1007 12:33:17.388540  4874 net.cpp:406] M2PELU19 <- Eltwise9
I1007 12:33:17.388545  4874 net.cpp:367] M2PELU19 -> Eltwise9 (in-place)
I1007 12:33:17.388639  4874 net.cpp:122] Setting up M2PELU19
I1007 12:33:17.388643  4874 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 12:33:17.388646  4874 net.cpp:137] Memory required for data: 548455600
I1007 12:33:17.388649  4874 layer_factory.hpp:77] Creating layer Eltwise9_M2PELU19_0_split
I1007 12:33:17.388653  4874 net.cpp:84] Creating Layer Eltwise9_M2PELU19_0_split
I1007 12:33:17.388656  4874 net.cpp:406] Eltwise9_M2PELU19_0_split <- Eltwise9
I1007 12:33:17.388660  4874 net.cpp:380] Eltwise9_M2PELU19_0_split -> Eltwise9_M2PELU19_0_split_0
I1007 12:33:17.388664  4874 net.cpp:380] Eltwise9_M2PELU19_0_split -> Eltwise9_M2PELU19_0_split_1
I1007 12:33:17.388690  4874 net.cpp:122] Setting up Eltwise9_M2PELU19_0_split
I1007 12:33:17.388695  4874 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 12:33:17.388697  4874 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 12:33:17.388700  4874 net.cpp:137] Memory required for data: 555009200
I1007 12:33:17.388702  4874 layer_factory.hpp:77] Creating layer Convolution21
I1007 12:33:17.388708  4874 net.cpp:84] Creating Layer Convolution21
I1007 12:33:17.388711  4874 net.cpp:406] Convolution21 <- Eltwise9_M2PELU19_0_split_0
I1007 12:33:17.388715  4874 net.cpp:380] Convolution21 -> Convolution21
I1007 12:33:17.389875  4874 net.cpp:122] Setting up Convolution21
I1007 12:33:17.389885  4874 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 12:33:17.389889  4874 net.cpp:137] Memory required for data: 558286000
I1007 12:33:17.389892  4874 layer_factory.hpp:77] Creating layer BatchNorm21
I1007 12:33:17.389899  4874 net.cpp:84] Creating Layer BatchNorm21
I1007 12:33:17.389901  4874 net.cpp:406] BatchNorm21 <- Convolution21
I1007 12:33:17.389905  4874 net.cpp:367] BatchNorm21 -> Convolution21 (in-place)
I1007 12:33:17.390055  4874 net.cpp:122] Setting up BatchNorm21
I1007 12:33:17.390060  4874 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 12:33:17.390063  4874 net.cpp:137] Memory required for data: 561562800
I1007 12:33:17.390069  4874 layer_factory.hpp:77] Creating layer Scale21
I1007 12:33:17.390072  4874 net.cpp:84] Creating Layer Scale21
I1007 12:33:17.390074  4874 net.cpp:406] Scale21 <- Convolution21
I1007 12:33:17.390079  4874 net.cpp:367] Scale21 -> Convolution21 (in-place)
I1007 12:33:17.390108  4874 layer_factory.hpp:77] Creating layer Scale21
I1007 12:33:17.390214  4874 net.cpp:122] Setting up Scale21
I1007 12:33:17.390219  4874 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 12:33:17.390221  4874 net.cpp:137] Memory required for data: 564839600
I1007 12:33:17.390226  4874 layer_factory.hpp:77] Creating layer M2PELU20
I1007 12:33:17.390231  4874 net.cpp:84] Creating Layer M2PELU20
I1007 12:33:17.390233  4874 net.cpp:406] M2PELU20 <- Convolution21
I1007 12:33:17.390238  4874 net.cpp:367] M2PELU20 -> Convolution21 (in-place)
I1007 12:33:17.390328  4874 net.cpp:122] Setting up M2PELU20
I1007 12:33:17.390332  4874 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 12:33:17.390336  4874 net.cpp:137] Memory required for data: 568116400
I1007 12:33:17.390339  4874 layer_factory.hpp:77] Creating layer Convolution22
I1007 12:33:17.390346  4874 net.cpp:84] Creating Layer Convolution22
I1007 12:33:17.390348  4874 net.cpp:406] Convolution22 <- Convolution21
I1007 12:33:17.390353  4874 net.cpp:380] Convolution22 -> Convolution22
I1007 12:33:17.391475  4874 net.cpp:122] Setting up Convolution22
I1007 12:33:17.391484  4874 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 12:33:17.391487  4874 net.cpp:137] Memory required for data: 571393200
I1007 12:33:17.391491  4874 layer_factory.hpp:77] Creating layer BatchNorm22
I1007 12:33:17.391496  4874 net.cpp:84] Creating Layer BatchNorm22
I1007 12:33:17.391499  4874 net.cpp:406] BatchNorm22 <- Convolution22
I1007 12:33:17.391504  4874 net.cpp:367] BatchNorm22 -> Convolution22 (in-place)
I1007 12:33:17.391651  4874 net.cpp:122] Setting up BatchNorm22
I1007 12:33:17.391656  4874 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 12:33:17.391659  4874 net.cpp:137] Memory required for data: 574670000
I1007 12:33:17.391664  4874 layer_factory.hpp:77] Creating layer Scale22
I1007 12:33:17.391669  4874 net.cpp:84] Creating Layer Scale22
I1007 12:33:17.391670  4874 net.cpp:406] Scale22 <- Convolution22
I1007 12:33:17.391674  4874 net.cpp:367] Scale22 -> Convolution22 (in-place)
I1007 12:33:17.391703  4874 layer_factory.hpp:77] Creating layer Scale22
I1007 12:33:17.391788  4874 net.cpp:122] Setting up Scale22
I1007 12:33:17.391793  4874 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 12:33:17.391795  4874 net.cpp:137] Memory required for data: 577946800
I1007 12:33:17.391799  4874 layer_factory.hpp:77] Creating layer Eltwise10
I1007 12:33:17.391803  4874 net.cpp:84] Creating Layer Eltwise10
I1007 12:33:17.391806  4874 net.cpp:406] Eltwise10 <- Eltwise9_M2PELU19_0_split_1
I1007 12:33:17.391809  4874 net.cpp:406] Eltwise10 <- Convolution22
I1007 12:33:17.391813  4874 net.cpp:380] Eltwise10 -> Eltwise10
I1007 12:33:17.391827  4874 net.cpp:122] Setting up Eltwise10
I1007 12:33:17.391831  4874 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 12:33:17.391834  4874 net.cpp:137] Memory required for data: 581223600
I1007 12:33:17.391835  4874 layer_factory.hpp:77] Creating layer M2PELU21
I1007 12:33:17.391840  4874 net.cpp:84] Creating Layer M2PELU21
I1007 12:33:17.391844  4874 net.cpp:406] M2PELU21 <- Eltwise10
I1007 12:33:17.391846  4874 net.cpp:367] M2PELU21 -> Eltwise10 (in-place)
I1007 12:33:17.391942  4874 net.cpp:122] Setting up M2PELU21
I1007 12:33:17.391947  4874 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 12:33:17.391948  4874 net.cpp:137] Memory required for data: 584500400
I1007 12:33:17.391952  4874 layer_factory.hpp:77] Creating layer Eltwise10_M2PELU21_0_split
I1007 12:33:17.391957  4874 net.cpp:84] Creating Layer Eltwise10_M2PELU21_0_split
I1007 12:33:17.391959  4874 net.cpp:406] Eltwise10_M2PELU21_0_split <- Eltwise10
I1007 12:33:17.391963  4874 net.cpp:380] Eltwise10_M2PELU21_0_split -> Eltwise10_M2PELU21_0_split_0
I1007 12:33:17.391968  4874 net.cpp:380] Eltwise10_M2PELU21_0_split -> Eltwise10_M2PELU21_0_split_1
I1007 12:33:17.391994  4874 net.cpp:122] Setting up Eltwise10_M2PELU21_0_split
I1007 12:33:17.391999  4874 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 12:33:17.392001  4874 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 12:33:17.392004  4874 net.cpp:137] Memory required for data: 591054000
I1007 12:33:17.392012  4874 layer_factory.hpp:77] Creating layer Convolution23
I1007 12:33:17.392019  4874 net.cpp:84] Creating Layer Convolution23
I1007 12:33:17.392021  4874 net.cpp:406] Convolution23 <- Eltwise10_M2PELU21_0_split_0
I1007 12:33:17.392026  4874 net.cpp:380] Convolution23 -> Convolution23
I1007 12:33:17.393003  4874 net.cpp:122] Setting up Convolution23
I1007 12:33:17.393013  4874 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 12:33:17.393015  4874 net.cpp:137] Memory required for data: 592692400
I1007 12:33:17.393020  4874 layer_factory.hpp:77] Creating layer BatchNorm23
I1007 12:33:17.393024  4874 net.cpp:84] Creating Layer BatchNorm23
I1007 12:33:17.393028  4874 net.cpp:406] BatchNorm23 <- Convolution23
I1007 12:33:17.393033  4874 net.cpp:367] BatchNorm23 -> Convolution23 (in-place)
I1007 12:33:17.393187  4874 net.cpp:122] Setting up BatchNorm23
I1007 12:33:17.393191  4874 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 12:33:17.393193  4874 net.cpp:137] Memory required for data: 594330800
I1007 12:33:17.393198  4874 layer_factory.hpp:77] Creating layer Scale23
I1007 12:33:17.393203  4874 net.cpp:84] Creating Layer Scale23
I1007 12:33:17.393204  4874 net.cpp:406] Scale23 <- Convolution23
I1007 12:33:17.393208  4874 net.cpp:367] Scale23 -> Convolution23 (in-place)
I1007 12:33:17.393239  4874 layer_factory.hpp:77] Creating layer Scale23
I1007 12:33:17.393326  4874 net.cpp:122] Setting up Scale23
I1007 12:33:17.393331  4874 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 12:33:17.393332  4874 net.cpp:137] Memory required for data: 595969200
I1007 12:33:17.393337  4874 layer_factory.hpp:77] Creating layer Convolution24
I1007 12:33:17.393343  4874 net.cpp:84] Creating Layer Convolution24
I1007 12:33:17.393347  4874 net.cpp:406] Convolution24 <- Eltwise10_M2PELU21_0_split_1
I1007 12:33:17.393352  4874 net.cpp:380] Convolution24 -> Convolution24
I1007 12:33:17.394693  4874 net.cpp:122] Setting up Convolution24
I1007 12:33:17.394702  4874 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 12:33:17.394706  4874 net.cpp:137] Memory required for data: 597607600
I1007 12:33:17.394709  4874 layer_factory.hpp:77] Creating layer BatchNorm24
I1007 12:33:17.394714  4874 net.cpp:84] Creating Layer BatchNorm24
I1007 12:33:17.394717  4874 net.cpp:406] BatchNorm24 <- Convolution24
I1007 12:33:17.394721  4874 net.cpp:367] BatchNorm24 -> Convolution24 (in-place)
I1007 12:33:17.394875  4874 net.cpp:122] Setting up BatchNorm24
I1007 12:33:17.394879  4874 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 12:33:17.394881  4874 net.cpp:137] Memory required for data: 599246000
I1007 12:33:17.394886  4874 layer_factory.hpp:77] Creating layer Scale24
I1007 12:33:17.394891  4874 net.cpp:84] Creating Layer Scale24
I1007 12:33:17.394892  4874 net.cpp:406] Scale24 <- Convolution24
I1007 12:33:17.394896  4874 net.cpp:367] Scale24 -> Convolution24 (in-place)
I1007 12:33:17.394927  4874 layer_factory.hpp:77] Creating layer Scale24
I1007 12:33:17.395012  4874 net.cpp:122] Setting up Scale24
I1007 12:33:17.395017  4874 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 12:33:17.395020  4874 net.cpp:137] Memory required for data: 600884400
I1007 12:33:17.395023  4874 layer_factory.hpp:77] Creating layer M2PELU22
I1007 12:33:17.395028  4874 net.cpp:84] Creating Layer M2PELU22
I1007 12:33:17.395031  4874 net.cpp:406] M2PELU22 <- Convolution24
I1007 12:33:17.395035  4874 net.cpp:367] M2PELU22 -> Convolution24 (in-place)
I1007 12:33:17.395129  4874 net.cpp:122] Setting up M2PELU22
I1007 12:33:17.395133  4874 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 12:33:17.395135  4874 net.cpp:137] Memory required for data: 602522800
I1007 12:33:17.395139  4874 layer_factory.hpp:77] Creating layer Convolution25
I1007 12:33:17.395146  4874 net.cpp:84] Creating Layer Convolution25
I1007 12:33:17.395149  4874 net.cpp:406] Convolution25 <- Convolution24
I1007 12:33:17.395153  4874 net.cpp:380] Convolution25 -> Convolution25
I1007 12:33:17.396917  4874 net.cpp:122] Setting up Convolution25
I1007 12:33:17.396926  4874 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 12:33:17.396935  4874 net.cpp:137] Memory required for data: 604161200
I1007 12:33:17.396940  4874 layer_factory.hpp:77] Creating layer BatchNorm25
I1007 12:33:17.396946  4874 net.cpp:84] Creating Layer BatchNorm25
I1007 12:33:17.396950  4874 net.cpp:406] BatchNorm25 <- Convolution25
I1007 12:33:17.396952  4874 net.cpp:367] BatchNorm25 -> Convolution25 (in-place)
I1007 12:33:17.397105  4874 net.cpp:122] Setting up BatchNorm25
I1007 12:33:17.397109  4874 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 12:33:17.397112  4874 net.cpp:137] Memory required for data: 605799600
I1007 12:33:17.397117  4874 layer_factory.hpp:77] Creating layer Scale25
I1007 12:33:17.416431  4874 net.cpp:84] Creating Layer Scale25
I1007 12:33:17.416440  4874 net.cpp:406] Scale25 <- Convolution25
I1007 12:33:17.416445  4874 net.cpp:367] Scale25 -> Convolution25 (in-place)
I1007 12:33:17.416491  4874 layer_factory.hpp:77] Creating layer Scale25
I1007 12:33:17.416586  4874 net.cpp:122] Setting up Scale25
I1007 12:33:17.416592  4874 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 12:33:17.416594  4874 net.cpp:137] Memory required for data: 607438000
I1007 12:33:17.416599  4874 layer_factory.hpp:77] Creating layer Eltwise11
I1007 12:33:17.416605  4874 net.cpp:84] Creating Layer Eltwise11
I1007 12:33:17.416609  4874 net.cpp:406] Eltwise11 <- Convolution23
I1007 12:33:17.416611  4874 net.cpp:406] Eltwise11 <- Convolution25
I1007 12:33:17.416615  4874 net.cpp:380] Eltwise11 -> Eltwise11
I1007 12:33:17.416635  4874 net.cpp:122] Setting up Eltwise11
I1007 12:33:17.416640  4874 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 12:33:17.416641  4874 net.cpp:137] Memory required for data: 609076400
I1007 12:33:17.416643  4874 layer_factory.hpp:77] Creating layer M2PELU23
I1007 12:33:17.416648  4874 net.cpp:84] Creating Layer M2PELU23
I1007 12:33:17.416651  4874 net.cpp:406] M2PELU23 <- Eltwise11
I1007 12:33:17.416654  4874 net.cpp:367] M2PELU23 -> Eltwise11 (in-place)
I1007 12:33:17.416754  4874 net.cpp:122] Setting up M2PELU23
I1007 12:33:17.416759  4874 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 12:33:17.416761  4874 net.cpp:137] Memory required for data: 610714800
I1007 12:33:17.416765  4874 layer_factory.hpp:77] Creating layer Eltwise11_M2PELU23_0_split
I1007 12:33:17.416769  4874 net.cpp:84] Creating Layer Eltwise11_M2PELU23_0_split
I1007 12:33:17.416771  4874 net.cpp:406] Eltwise11_M2PELU23_0_split <- Eltwise11
I1007 12:33:17.416775  4874 net.cpp:380] Eltwise11_M2PELU23_0_split -> Eltwise11_M2PELU23_0_split_0
I1007 12:33:17.416779  4874 net.cpp:380] Eltwise11_M2PELU23_0_split -> Eltwise11_M2PELU23_0_split_1
I1007 12:33:17.416808  4874 net.cpp:122] Setting up Eltwise11_M2PELU23_0_split
I1007 12:33:17.416812  4874 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 12:33:17.416815  4874 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 12:33:17.416817  4874 net.cpp:137] Memory required for data: 613991600
I1007 12:33:17.416820  4874 layer_factory.hpp:77] Creating layer Convolution26
I1007 12:33:17.416827  4874 net.cpp:84] Creating Layer Convolution26
I1007 12:33:17.416831  4874 net.cpp:406] Convolution26 <- Eltwise11_M2PELU23_0_split_0
I1007 12:33:17.416834  4874 net.cpp:380] Convolution26 -> Convolution26
I1007 12:33:17.418704  4874 net.cpp:122] Setting up Convolution26
I1007 12:33:17.418712  4874 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 12:33:17.418715  4874 net.cpp:137] Memory required for data: 615630000
I1007 12:33:17.418721  4874 layer_factory.hpp:77] Creating layer BatchNorm26
I1007 12:33:17.418725  4874 net.cpp:84] Creating Layer BatchNorm26
I1007 12:33:17.418730  4874 net.cpp:406] BatchNorm26 <- Convolution26
I1007 12:33:17.418733  4874 net.cpp:367] BatchNorm26 -> Convolution26 (in-place)
I1007 12:33:17.418882  4874 net.cpp:122] Setting up BatchNorm26
I1007 12:33:17.418887  4874 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 12:33:17.418889  4874 net.cpp:137] Memory required for data: 617268400
I1007 12:33:17.418895  4874 layer_factory.hpp:77] Creating layer Scale26
I1007 12:33:17.418900  4874 net.cpp:84] Creating Layer Scale26
I1007 12:33:17.418910  4874 net.cpp:406] Scale26 <- Convolution26
I1007 12:33:17.418913  4874 net.cpp:367] Scale26 -> Convolution26 (in-place)
I1007 12:33:17.418946  4874 layer_factory.hpp:77] Creating layer Scale26
I1007 12:33:17.419033  4874 net.cpp:122] Setting up Scale26
I1007 12:33:17.419037  4874 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 12:33:17.419039  4874 net.cpp:137] Memory required for data: 618906800
I1007 12:33:17.419044  4874 layer_factory.hpp:77] Creating layer M2PELU24
I1007 12:33:17.419049  4874 net.cpp:84] Creating Layer M2PELU24
I1007 12:33:17.419051  4874 net.cpp:406] M2PELU24 <- Convolution26
I1007 12:33:17.419054  4874 net.cpp:367] M2PELU24 -> Convolution26 (in-place)
I1007 12:33:17.419148  4874 net.cpp:122] Setting up M2PELU24
I1007 12:33:17.419153  4874 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 12:33:17.419155  4874 net.cpp:137] Memory required for data: 620545200
I1007 12:33:17.419159  4874 layer_factory.hpp:77] Creating layer Convolution27
I1007 12:33:17.419175  4874 net.cpp:84] Creating Layer Convolution27
I1007 12:33:17.419178  4874 net.cpp:406] Convolution27 <- Convolution26
I1007 12:33:17.419183  4874 net.cpp:380] Convolution27 -> Convolution27
I1007 12:33:17.420938  4874 net.cpp:122] Setting up Convolution27
I1007 12:33:17.420948  4874 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 12:33:17.420950  4874 net.cpp:137] Memory required for data: 622183600
I1007 12:33:17.420954  4874 layer_factory.hpp:77] Creating layer BatchNorm27
I1007 12:33:17.420972  4874 net.cpp:84] Creating Layer BatchNorm27
I1007 12:33:17.420975  4874 net.cpp:406] BatchNorm27 <- Convolution27
I1007 12:33:17.420979  4874 net.cpp:367] BatchNorm27 -> Convolution27 (in-place)
I1007 12:33:17.421129  4874 net.cpp:122] Setting up BatchNorm27
I1007 12:33:17.421134  4874 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 12:33:17.421136  4874 net.cpp:137] Memory required for data: 623822000
I1007 12:33:17.421141  4874 layer_factory.hpp:77] Creating layer Scale27
I1007 12:33:17.421145  4874 net.cpp:84] Creating Layer Scale27
I1007 12:33:17.421147  4874 net.cpp:406] Scale27 <- Convolution27
I1007 12:33:17.421150  4874 net.cpp:367] Scale27 -> Convolution27 (in-place)
I1007 12:33:17.421181  4874 layer_factory.hpp:77] Creating layer Scale27
I1007 12:33:17.421267  4874 net.cpp:122] Setting up Scale27
I1007 12:33:17.421270  4874 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 12:33:17.421273  4874 net.cpp:137] Memory required for data: 625460400
I1007 12:33:17.421277  4874 layer_factory.hpp:77] Creating layer Eltwise12
I1007 12:33:17.421281  4874 net.cpp:84] Creating Layer Eltwise12
I1007 12:33:17.421283  4874 net.cpp:406] Eltwise12 <- Eltwise11_M2PELU23_0_split_1
I1007 12:33:17.421286  4874 net.cpp:406] Eltwise12 <- Convolution27
I1007 12:33:17.421289  4874 net.cpp:380] Eltwise12 -> Eltwise12
I1007 12:33:17.421310  4874 net.cpp:122] Setting up Eltwise12
I1007 12:33:17.421314  4874 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 12:33:17.421316  4874 net.cpp:137] Memory required for data: 627098800
I1007 12:33:17.421319  4874 layer_factory.hpp:77] Creating layer M2PELU25
I1007 12:33:17.421324  4874 net.cpp:84] Creating Layer M2PELU25
I1007 12:33:17.421325  4874 net.cpp:406] M2PELU25 <- Eltwise12
I1007 12:33:17.421329  4874 net.cpp:367] M2PELU25 -> Eltwise12 (in-place)
I1007 12:33:17.421422  4874 net.cpp:122] Setting up M2PELU25
I1007 12:33:17.421425  4874 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 12:33:17.421427  4874 net.cpp:137] Memory required for data: 628737200
I1007 12:33:17.421430  4874 layer_factory.hpp:77] Creating layer Eltwise12_M2PELU25_0_split
I1007 12:33:17.421434  4874 net.cpp:84] Creating Layer Eltwise12_M2PELU25_0_split
I1007 12:33:17.421437  4874 net.cpp:406] Eltwise12_M2PELU25_0_split <- Eltwise12
I1007 12:33:17.421439  4874 net.cpp:380] Eltwise12_M2PELU25_0_split -> Eltwise12_M2PELU25_0_split_0
I1007 12:33:17.421444  4874 net.cpp:380] Eltwise12_M2PELU25_0_split -> Eltwise12_M2PELU25_0_split_1
I1007 12:33:17.421470  4874 net.cpp:122] Setting up Eltwise12_M2PELU25_0_split
I1007 12:33:17.421480  4874 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 12:33:17.421483  4874 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 12:33:17.421485  4874 net.cpp:137] Memory required for data: 632014000
I1007 12:33:17.421488  4874 layer_factory.hpp:77] Creating layer Convolution28
I1007 12:33:17.421494  4874 net.cpp:84] Creating Layer Convolution28
I1007 12:33:17.421497  4874 net.cpp:406] Convolution28 <- Eltwise12_M2PELU25_0_split_0
I1007 12:33:17.421501  4874 net.cpp:380] Convolution28 -> Convolution28
I1007 12:33:17.423555  4874 net.cpp:122] Setting up Convolution28
I1007 12:33:17.423564  4874 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 12:33:17.423568  4874 net.cpp:137] Memory required for data: 633652400
I1007 12:33:17.423573  4874 layer_factory.hpp:77] Creating layer BatchNorm28
I1007 12:33:17.423578  4874 net.cpp:84] Creating Layer BatchNorm28
I1007 12:33:17.423579  4874 net.cpp:406] BatchNorm28 <- Convolution28
I1007 12:33:17.423585  4874 net.cpp:367] BatchNorm28 -> Convolution28 (in-place)
I1007 12:33:17.423743  4874 net.cpp:122] Setting up BatchNorm28
I1007 12:33:17.423746  4874 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 12:33:17.423748  4874 net.cpp:137] Memory required for data: 635290800
I1007 12:33:17.423753  4874 layer_factory.hpp:77] Creating layer Scale28
I1007 12:33:17.423758  4874 net.cpp:84] Creating Layer Scale28
I1007 12:33:17.423760  4874 net.cpp:406] Scale28 <- Convolution28
I1007 12:33:17.423764  4874 net.cpp:367] Scale28 -> Convolution28 (in-place)
I1007 12:33:17.423794  4874 layer_factory.hpp:77] Creating layer Scale28
I1007 12:33:17.423885  4874 net.cpp:122] Setting up Scale28
I1007 12:33:17.423890  4874 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 12:33:17.423892  4874 net.cpp:137] Memory required for data: 636929200
I1007 12:33:17.423897  4874 layer_factory.hpp:77] Creating layer M2PELU26
I1007 12:33:17.423902  4874 net.cpp:84] Creating Layer M2PELU26
I1007 12:33:17.423904  4874 net.cpp:406] M2PELU26 <- Convolution28
I1007 12:33:17.423907  4874 net.cpp:367] M2PELU26 -> Convolution28 (in-place)
I1007 12:33:17.424003  4874 net.cpp:122] Setting up M2PELU26
I1007 12:33:17.424008  4874 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 12:33:17.424010  4874 net.cpp:137] Memory required for data: 638567600
I1007 12:33:17.424013  4874 layer_factory.hpp:77] Creating layer Convolution29
I1007 12:33:17.424021  4874 net.cpp:84] Creating Layer Convolution29
I1007 12:33:17.424023  4874 net.cpp:406] Convolution29 <- Convolution28
I1007 12:33:17.424027  4874 net.cpp:380] Convolution29 -> Convolution29
I1007 12:33:17.426275  4874 net.cpp:122] Setting up Convolution29
I1007 12:33:17.426285  4874 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 12:33:17.426287  4874 net.cpp:137] Memory required for data: 640206000
I1007 12:33:17.426291  4874 layer_factory.hpp:77] Creating layer BatchNorm29
I1007 12:33:17.426296  4874 net.cpp:84] Creating Layer BatchNorm29
I1007 12:33:17.426300  4874 net.cpp:406] BatchNorm29 <- Convolution29
I1007 12:33:17.426303  4874 net.cpp:367] BatchNorm29 -> Convolution29 (in-place)
I1007 12:33:17.426455  4874 net.cpp:122] Setting up BatchNorm29
I1007 12:33:17.426460  4874 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 12:33:17.426462  4874 net.cpp:137] Memory required for data: 641844400
I1007 12:33:17.426467  4874 layer_factory.hpp:77] Creating layer Scale29
I1007 12:33:17.426471  4874 net.cpp:84] Creating Layer Scale29
I1007 12:33:17.426473  4874 net.cpp:406] Scale29 <- Convolution29
I1007 12:33:17.426477  4874 net.cpp:367] Scale29 -> Convolution29 (in-place)
I1007 12:33:17.426506  4874 layer_factory.hpp:77] Creating layer Scale29
I1007 12:33:17.426594  4874 net.cpp:122] Setting up Scale29
I1007 12:33:17.426597  4874 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 12:33:17.426599  4874 net.cpp:137] Memory required for data: 643482800
I1007 12:33:17.426604  4874 layer_factory.hpp:77] Creating layer Eltwise13
I1007 12:33:17.426607  4874 net.cpp:84] Creating Layer Eltwise13
I1007 12:33:17.426610  4874 net.cpp:406] Eltwise13 <- Eltwise12_M2PELU25_0_split_1
I1007 12:33:17.426620  4874 net.cpp:406] Eltwise13 <- Convolution29
I1007 12:33:17.426625  4874 net.cpp:380] Eltwise13 -> Eltwise13
I1007 12:33:17.426645  4874 net.cpp:122] Setting up Eltwise13
I1007 12:33:17.426650  4874 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 12:33:17.426651  4874 net.cpp:137] Memory required for data: 645121200
I1007 12:33:17.426653  4874 layer_factory.hpp:77] Creating layer M2PELU27
I1007 12:33:17.426657  4874 net.cpp:84] Creating Layer M2PELU27
I1007 12:33:17.426661  4874 net.cpp:406] M2PELU27 <- Eltwise13
I1007 12:33:17.426664  4874 net.cpp:367] M2PELU27 -> Eltwise13 (in-place)
I1007 12:33:17.426759  4874 net.cpp:122] Setting up M2PELU27
I1007 12:33:17.426762  4874 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 12:33:17.426764  4874 net.cpp:137] Memory required for data: 646759600
I1007 12:33:17.426787  4874 layer_factory.hpp:77] Creating layer Eltwise13_M2PELU27_0_split
I1007 12:33:17.426792  4874 net.cpp:84] Creating Layer Eltwise13_M2PELU27_0_split
I1007 12:33:17.426795  4874 net.cpp:406] Eltwise13_M2PELU27_0_split <- Eltwise13
I1007 12:33:17.426797  4874 net.cpp:380] Eltwise13_M2PELU27_0_split -> Eltwise13_M2PELU27_0_split_0
I1007 12:33:17.426802  4874 net.cpp:380] Eltwise13_M2PELU27_0_split -> Eltwise13_M2PELU27_0_split_1
I1007 12:33:17.426831  4874 net.cpp:122] Setting up Eltwise13_M2PELU27_0_split
I1007 12:33:17.426836  4874 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 12:33:17.426838  4874 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 12:33:17.426841  4874 net.cpp:137] Memory required for data: 650036400
I1007 12:33:17.426842  4874 layer_factory.hpp:77] Creating layer Convolution30
I1007 12:33:17.426849  4874 net.cpp:84] Creating Layer Convolution30
I1007 12:33:17.426852  4874 net.cpp:406] Convolution30 <- Eltwise13_M2PELU27_0_split_0
I1007 12:33:17.426857  4874 net.cpp:380] Convolution30 -> Convolution30
I1007 12:33:17.428932  4874 net.cpp:122] Setting up Convolution30
I1007 12:33:17.428941  4874 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 12:33:17.428944  4874 net.cpp:137] Memory required for data: 651674800
I1007 12:33:17.428949  4874 layer_factory.hpp:77] Creating layer BatchNorm30
I1007 12:33:17.428954  4874 net.cpp:84] Creating Layer BatchNorm30
I1007 12:33:17.428957  4874 net.cpp:406] BatchNorm30 <- Convolution30
I1007 12:33:17.428961  4874 net.cpp:367] BatchNorm30 -> Convolution30 (in-place)
I1007 12:33:17.429116  4874 net.cpp:122] Setting up BatchNorm30
I1007 12:33:17.429121  4874 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 12:33:17.429123  4874 net.cpp:137] Memory required for data: 653313200
I1007 12:33:17.429127  4874 layer_factory.hpp:77] Creating layer Scale30
I1007 12:33:17.429131  4874 net.cpp:84] Creating Layer Scale30
I1007 12:33:17.429134  4874 net.cpp:406] Scale30 <- Convolution30
I1007 12:33:17.429137  4874 net.cpp:367] Scale30 -> Convolution30 (in-place)
I1007 12:33:17.429168  4874 layer_factory.hpp:77] Creating layer Scale30
I1007 12:33:17.429255  4874 net.cpp:122] Setting up Scale30
I1007 12:33:17.429260  4874 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 12:33:17.429261  4874 net.cpp:137] Memory required for data: 654951600
I1007 12:33:17.429265  4874 layer_factory.hpp:77] Creating layer M2PELU28
I1007 12:33:17.429270  4874 net.cpp:84] Creating Layer M2PELU28
I1007 12:33:17.429272  4874 net.cpp:406] M2PELU28 <- Convolution30
I1007 12:33:17.429276  4874 net.cpp:367] M2PELU28 -> Convolution30 (in-place)
I1007 12:33:17.429370  4874 net.cpp:122] Setting up M2PELU28
I1007 12:33:17.429375  4874 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 12:33:17.429378  4874 net.cpp:137] Memory required for data: 656590000
I1007 12:33:17.429380  4874 layer_factory.hpp:77] Creating layer Convolution31
I1007 12:33:17.429388  4874 net.cpp:84] Creating Layer Convolution31
I1007 12:33:17.429390  4874 net.cpp:406] Convolution31 <- Convolution30
I1007 12:33:17.429394  4874 net.cpp:380] Convolution31 -> Convolution31
I1007 12:33:17.431095  4874 net.cpp:122] Setting up Convolution31
I1007 12:33:17.431103  4874 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 12:33:17.431113  4874 net.cpp:137] Memory required for data: 658228400
I1007 12:33:17.431118  4874 layer_factory.hpp:77] Creating layer BatchNorm31
I1007 12:33:17.431123  4874 net.cpp:84] Creating Layer BatchNorm31
I1007 12:33:17.431126  4874 net.cpp:406] BatchNorm31 <- Convolution31
I1007 12:33:17.431130  4874 net.cpp:367] BatchNorm31 -> Convolution31 (in-place)
I1007 12:33:17.431289  4874 net.cpp:122] Setting up BatchNorm31
I1007 12:33:17.431295  4874 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 12:33:17.447459  4874 net.cpp:137] Memory required for data: 659866800
I1007 12:33:17.447471  4874 layer_factory.hpp:77] Creating layer Scale31
I1007 12:33:17.447479  4874 net.cpp:84] Creating Layer Scale31
I1007 12:33:17.447482  4874 net.cpp:406] Scale31 <- Convolution31
I1007 12:33:17.447485  4874 net.cpp:367] Scale31 -> Convolution31 (in-place)
I1007 12:33:17.447531  4874 layer_factory.hpp:77] Creating layer Scale31
I1007 12:33:17.447633  4874 net.cpp:122] Setting up Scale31
I1007 12:33:17.447638  4874 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 12:33:17.447639  4874 net.cpp:137] Memory required for data: 661505200
I1007 12:33:17.447643  4874 layer_factory.hpp:77] Creating layer Eltwise14
I1007 12:33:17.447650  4874 net.cpp:84] Creating Layer Eltwise14
I1007 12:33:17.447654  4874 net.cpp:406] Eltwise14 <- Eltwise13_M2PELU27_0_split_1
I1007 12:33:17.447657  4874 net.cpp:406] Eltwise14 <- Convolution31
I1007 12:33:17.447660  4874 net.cpp:380] Eltwise14 -> Eltwise14
I1007 12:33:17.447681  4874 net.cpp:122] Setting up Eltwise14
I1007 12:33:17.447685  4874 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 12:33:17.447688  4874 net.cpp:137] Memory required for data: 663143600
I1007 12:33:17.447690  4874 layer_factory.hpp:77] Creating layer M2PELU29
I1007 12:33:17.447696  4874 net.cpp:84] Creating Layer M2PELU29
I1007 12:33:17.447698  4874 net.cpp:406] M2PELU29 <- Eltwise14
I1007 12:33:17.447702  4874 net.cpp:367] M2PELU29 -> Eltwise14 (in-place)
I1007 12:33:17.447805  4874 net.cpp:122] Setting up M2PELU29
I1007 12:33:17.447810  4874 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 12:33:17.447813  4874 net.cpp:137] Memory required for data: 664782000
I1007 12:33:17.447816  4874 layer_factory.hpp:77] Creating layer Eltwise14_M2PELU29_0_split
I1007 12:33:17.447820  4874 net.cpp:84] Creating Layer Eltwise14_M2PELU29_0_split
I1007 12:33:17.447824  4874 net.cpp:406] Eltwise14_M2PELU29_0_split <- Eltwise14
I1007 12:33:17.447826  4874 net.cpp:380] Eltwise14_M2PELU29_0_split -> Eltwise14_M2PELU29_0_split_0
I1007 12:33:17.447831  4874 net.cpp:380] Eltwise14_M2PELU29_0_split -> Eltwise14_M2PELU29_0_split_1
I1007 12:33:17.447860  4874 net.cpp:122] Setting up Eltwise14_M2PELU29_0_split
I1007 12:33:17.447865  4874 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 12:33:17.447867  4874 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 12:33:17.447870  4874 net.cpp:137] Memory required for data: 668058800
I1007 12:33:17.447871  4874 layer_factory.hpp:77] Creating layer Convolution32
I1007 12:33:17.447877  4874 net.cpp:84] Creating Layer Convolution32
I1007 12:33:17.447880  4874 net.cpp:406] Convolution32 <- Eltwise14_M2PELU29_0_split_0
I1007 12:33:17.447885  4874 net.cpp:380] Convolution32 -> Convolution32
I1007 12:33:17.450314  4874 net.cpp:122] Setting up Convolution32
I1007 12:33:17.450322  4874 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 12:33:17.450325  4874 net.cpp:137] Memory required for data: 669697200
I1007 12:33:17.450330  4874 layer_factory.hpp:77] Creating layer BatchNorm32
I1007 12:33:17.450335  4874 net.cpp:84] Creating Layer BatchNorm32
I1007 12:33:17.450338  4874 net.cpp:406] BatchNorm32 <- Convolution32
I1007 12:33:17.450343  4874 net.cpp:367] BatchNorm32 -> Convolution32 (in-place)
I1007 12:33:17.450502  4874 net.cpp:122] Setting up BatchNorm32
I1007 12:33:17.450507  4874 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 12:33:17.450510  4874 net.cpp:137] Memory required for data: 671335600
I1007 12:33:17.450515  4874 layer_factory.hpp:77] Creating layer Scale32
I1007 12:33:17.450520  4874 net.cpp:84] Creating Layer Scale32
I1007 12:33:17.450529  4874 net.cpp:406] Scale32 <- Convolution32
I1007 12:33:17.450533  4874 net.cpp:367] Scale32 -> Convolution32 (in-place)
I1007 12:33:17.450567  4874 layer_factory.hpp:77] Creating layer Scale32
I1007 12:33:17.450655  4874 net.cpp:122] Setting up Scale32
I1007 12:33:17.450660  4874 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 12:33:17.450662  4874 net.cpp:137] Memory required for data: 672974000
I1007 12:33:17.450666  4874 layer_factory.hpp:77] Creating layer M2PELU30
I1007 12:33:17.450672  4874 net.cpp:84] Creating Layer M2PELU30
I1007 12:33:17.450675  4874 net.cpp:406] M2PELU30 <- Convolution32
I1007 12:33:17.450678  4874 net.cpp:367] M2PELU30 -> Convolution32 (in-place)
I1007 12:33:17.450774  4874 net.cpp:122] Setting up M2PELU30
I1007 12:33:17.450779  4874 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 12:33:17.450781  4874 net.cpp:137] Memory required for data: 674612400
I1007 12:33:17.450785  4874 layer_factory.hpp:77] Creating layer Convolution33
I1007 12:33:17.450791  4874 net.cpp:84] Creating Layer Convolution33
I1007 12:33:17.450794  4874 net.cpp:406] Convolution33 <- Convolution32
I1007 12:33:17.450801  4874 net.cpp:380] Convolution33 -> Convolution33
I1007 12:33:17.452584  4874 net.cpp:122] Setting up Convolution33
I1007 12:33:17.452594  4874 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 12:33:17.452596  4874 net.cpp:137] Memory required for data: 676250800
I1007 12:33:17.452600  4874 layer_factory.hpp:77] Creating layer BatchNorm33
I1007 12:33:17.452606  4874 net.cpp:84] Creating Layer BatchNorm33
I1007 12:33:17.452608  4874 net.cpp:406] BatchNorm33 <- Convolution33
I1007 12:33:17.452612  4874 net.cpp:367] BatchNorm33 -> Convolution33 (in-place)
I1007 12:33:17.452766  4874 net.cpp:122] Setting up BatchNorm33
I1007 12:33:17.452771  4874 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 12:33:17.452774  4874 net.cpp:137] Memory required for data: 677889200
I1007 12:33:17.452778  4874 layer_factory.hpp:77] Creating layer Scale33
I1007 12:33:17.452781  4874 net.cpp:84] Creating Layer Scale33
I1007 12:33:17.452785  4874 net.cpp:406] Scale33 <- Convolution33
I1007 12:33:17.452787  4874 net.cpp:367] Scale33 -> Convolution33 (in-place)
I1007 12:33:17.452819  4874 layer_factory.hpp:77] Creating layer Scale33
I1007 12:33:17.452906  4874 net.cpp:122] Setting up Scale33
I1007 12:33:17.452913  4874 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 12:33:17.452914  4874 net.cpp:137] Memory required for data: 679527600
I1007 12:33:17.452919  4874 layer_factory.hpp:77] Creating layer Eltwise15
I1007 12:33:17.452922  4874 net.cpp:84] Creating Layer Eltwise15
I1007 12:33:17.452924  4874 net.cpp:406] Eltwise15 <- Eltwise14_M2PELU29_0_split_1
I1007 12:33:17.452927  4874 net.cpp:406] Eltwise15 <- Convolution33
I1007 12:33:17.452930  4874 net.cpp:380] Eltwise15 -> Eltwise15
I1007 12:33:17.452950  4874 net.cpp:122] Setting up Eltwise15
I1007 12:33:17.452953  4874 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 12:33:17.452956  4874 net.cpp:137] Memory required for data: 681166000
I1007 12:33:17.452958  4874 layer_factory.hpp:77] Creating layer M2PELU31
I1007 12:33:17.452963  4874 net.cpp:84] Creating Layer M2PELU31
I1007 12:33:17.452965  4874 net.cpp:406] M2PELU31 <- Eltwise15
I1007 12:33:17.452968  4874 net.cpp:367] M2PELU31 -> Eltwise15 (in-place)
I1007 12:33:17.453064  4874 net.cpp:122] Setting up M2PELU31
I1007 12:33:17.453068  4874 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 12:33:17.453070  4874 net.cpp:137] Memory required for data: 682804400
I1007 12:33:17.453074  4874 layer_factory.hpp:77] Creating layer Pooling1
I1007 12:33:17.453078  4874 net.cpp:84] Creating Layer Pooling1
I1007 12:33:17.453080  4874 net.cpp:406] Pooling1 <- Eltwise15
I1007 12:33:17.453085  4874 net.cpp:380] Pooling1 -> Pooling1
I1007 12:33:17.453227  4874 net.cpp:122] Setting up Pooling1
I1007 12:33:17.453233  4874 net.cpp:129] Top shape: 100 64 1 1 (6400)
I1007 12:33:17.453234  4874 net.cpp:137] Memory required for data: 682830000
I1007 12:33:17.453236  4874 layer_factory.hpp:77] Creating layer InnerProduct1
I1007 12:33:17.453249  4874 net.cpp:84] Creating Layer InnerProduct1
I1007 12:33:17.453253  4874 net.cpp:406] InnerProduct1 <- Pooling1
I1007 12:33:17.453256  4874 net.cpp:380] InnerProduct1 -> InnerProduct1
I1007 12:33:17.453367  4874 net.cpp:122] Setting up InnerProduct1
I1007 12:33:17.453372  4874 net.cpp:129] Top shape: 100 10 (1000)
I1007 12:33:17.453374  4874 net.cpp:137] Memory required for data: 682834000
I1007 12:33:17.453378  4874 layer_factory.hpp:77] Creating layer InnerProduct1_InnerProduct1_0_split
I1007 12:33:17.453382  4874 net.cpp:84] Creating Layer InnerProduct1_InnerProduct1_0_split
I1007 12:33:17.453384  4874 net.cpp:406] InnerProduct1_InnerProduct1_0_split <- InnerProduct1
I1007 12:33:17.453387  4874 net.cpp:380] InnerProduct1_InnerProduct1_0_split -> InnerProduct1_InnerProduct1_0_split_0
I1007 12:33:17.453392  4874 net.cpp:380] InnerProduct1_InnerProduct1_0_split -> InnerProduct1_InnerProduct1_0_split_1
I1007 12:33:17.453420  4874 net.cpp:122] Setting up InnerProduct1_InnerProduct1_0_split
I1007 12:33:17.453424  4874 net.cpp:129] Top shape: 100 10 (1000)
I1007 12:33:17.453428  4874 net.cpp:129] Top shape: 100 10 (1000)
I1007 12:33:17.453429  4874 net.cpp:137] Memory required for data: 682842000
I1007 12:33:17.453431  4874 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I1007 12:33:17.453436  4874 net.cpp:84] Creating Layer SoftmaxWithLoss1
I1007 12:33:17.453438  4874 net.cpp:406] SoftmaxWithLoss1 <- InnerProduct1_InnerProduct1_0_split_0
I1007 12:33:17.453441  4874 net.cpp:406] SoftmaxWithLoss1 <- Data2_Data1_1_split_0
I1007 12:33:17.453444  4874 net.cpp:380] SoftmaxWithLoss1 -> SoftmaxWithLoss1
I1007 12:33:17.453449  4874 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I1007 12:33:17.453979  4874 net.cpp:122] Setting up SoftmaxWithLoss1
I1007 12:33:17.453986  4874 net.cpp:129] Top shape: (1)
I1007 12:33:17.453989  4874 net.cpp:132]     with loss weight 1
I1007 12:33:17.453996  4874 net.cpp:137] Memory required for data: 682842004
I1007 12:33:17.453999  4874 layer_factory.hpp:77] Creating layer Accuracy1
I1007 12:33:17.454007  4874 net.cpp:84] Creating Layer Accuracy1
I1007 12:33:17.454010  4874 net.cpp:406] Accuracy1 <- InnerProduct1_InnerProduct1_0_split_1
I1007 12:33:17.454013  4874 net.cpp:406] Accuracy1 <- Data2_Data1_1_split_1
I1007 12:33:17.454017  4874 net.cpp:380] Accuracy1 -> Accuracy1
I1007 12:33:17.454023  4874 net.cpp:122] Setting up Accuracy1
I1007 12:33:17.454026  4874 net.cpp:129] Top shape: (1)
I1007 12:33:17.454028  4874 net.cpp:137] Memory required for data: 682842008
I1007 12:33:17.454030  4874 net.cpp:200] Accuracy1 does not need backward computation.
I1007 12:33:17.454033  4874 net.cpp:198] SoftmaxWithLoss1 needs backward computation.
I1007 12:33:17.454035  4874 net.cpp:198] InnerProduct1_InnerProduct1_0_split needs backward computation.
I1007 12:33:17.454038  4874 net.cpp:198] InnerProduct1 needs backward computation.
I1007 12:33:17.454041  4874 net.cpp:198] Pooling1 needs backward computation.
I1007 12:33:17.454042  4874 net.cpp:198] M2PELU31 needs backward computation.
I1007 12:33:17.454044  4874 net.cpp:198] Eltwise15 needs backward computation.
I1007 12:33:17.454047  4874 net.cpp:198] Scale33 needs backward computation.
I1007 12:33:17.454049  4874 net.cpp:198] BatchNorm33 needs backward computation.
I1007 12:33:17.454051  4874 net.cpp:198] Convolution33 needs backward computation.
I1007 12:33:17.454053  4874 net.cpp:198] M2PELU30 needs backward computation.
I1007 12:33:17.454056  4874 net.cpp:198] Scale32 needs backward computation.
I1007 12:33:17.454057  4874 net.cpp:198] BatchNorm32 needs backward computation.
I1007 12:33:17.454059  4874 net.cpp:198] Convolution32 needs backward computation.
I1007 12:33:17.454061  4874 net.cpp:198] Eltwise14_M2PELU29_0_split needs backward computation.
I1007 12:33:17.454063  4874 net.cpp:198] M2PELU29 needs backward computation.
I1007 12:33:17.454066  4874 net.cpp:198] Eltwise14 needs backward computation.
I1007 12:33:17.454068  4874 net.cpp:198] Scale31 needs backward computation.
I1007 12:33:17.454077  4874 net.cpp:198] BatchNorm31 needs backward computation.
I1007 12:33:17.454078  4874 net.cpp:198] Convolution31 needs backward computation.
I1007 12:33:17.454080  4874 net.cpp:198] M2PELU28 needs backward computation.
I1007 12:33:17.454082  4874 net.cpp:198] Scale30 needs backward computation.
I1007 12:33:17.454084  4874 net.cpp:198] BatchNorm30 needs backward computation.
I1007 12:33:17.454087  4874 net.cpp:198] Convolution30 needs backward computation.
I1007 12:33:17.454089  4874 net.cpp:198] Eltwise13_M2PELU27_0_split needs backward computation.
I1007 12:33:17.454092  4874 net.cpp:198] M2PELU27 needs backward computation.
I1007 12:33:17.454093  4874 net.cpp:198] Eltwise13 needs backward computation.
I1007 12:33:17.454097  4874 net.cpp:198] Scale29 needs backward computation.
I1007 12:33:17.454098  4874 net.cpp:198] BatchNorm29 needs backward computation.
I1007 12:33:17.454100  4874 net.cpp:198] Convolution29 needs backward computation.
I1007 12:33:17.454103  4874 net.cpp:198] M2PELU26 needs backward computation.
I1007 12:33:17.454105  4874 net.cpp:198] Scale28 needs backward computation.
I1007 12:33:17.454107  4874 net.cpp:198] BatchNorm28 needs backward computation.
I1007 12:33:17.454109  4874 net.cpp:198] Convolution28 needs backward computation.
I1007 12:33:17.454111  4874 net.cpp:198] Eltwise12_M2PELU25_0_split needs backward computation.
I1007 12:33:17.454114  4874 net.cpp:198] M2PELU25 needs backward computation.
I1007 12:33:17.454116  4874 net.cpp:198] Eltwise12 needs backward computation.
I1007 12:33:17.454118  4874 net.cpp:198] Scale27 needs backward computation.
I1007 12:33:17.454121  4874 net.cpp:198] BatchNorm27 needs backward computation.
I1007 12:33:17.454123  4874 net.cpp:198] Convolution27 needs backward computation.
I1007 12:33:17.454125  4874 net.cpp:198] M2PELU24 needs backward computation.
I1007 12:33:17.454128  4874 net.cpp:198] Scale26 needs backward computation.
I1007 12:33:17.454129  4874 net.cpp:198] BatchNorm26 needs backward computation.
I1007 12:33:17.454131  4874 net.cpp:198] Convolution26 needs backward computation.
I1007 12:33:17.454133  4874 net.cpp:198] Eltwise11_M2PELU23_0_split needs backward computation.
I1007 12:33:17.454136  4874 net.cpp:198] M2PELU23 needs backward computation.
I1007 12:33:17.454139  4874 net.cpp:198] Eltwise11 needs backward computation.
I1007 12:33:17.454141  4874 net.cpp:198] Scale25 needs backward computation.
I1007 12:33:17.454144  4874 net.cpp:198] BatchNorm25 needs backward computation.
I1007 12:33:17.454146  4874 net.cpp:198] Convolution25 needs backward computation.
I1007 12:33:17.454149  4874 net.cpp:198] M2PELU22 needs backward computation.
I1007 12:33:17.454150  4874 net.cpp:198] Scale24 needs backward computation.
I1007 12:33:17.454152  4874 net.cpp:198] BatchNorm24 needs backward computation.
I1007 12:33:17.454154  4874 net.cpp:198] Convolution24 needs backward computation.
I1007 12:33:17.454157  4874 net.cpp:198] Scale23 needs backward computation.
I1007 12:33:17.454159  4874 net.cpp:198] BatchNorm23 needs backward computation.
I1007 12:33:17.454161  4874 net.cpp:198] Convolution23 needs backward computation.
I1007 12:33:17.454164  4874 net.cpp:198] Eltwise10_M2PELU21_0_split needs backward computation.
I1007 12:33:17.454166  4874 net.cpp:198] M2PELU21 needs backward computation.
I1007 12:33:17.454169  4874 net.cpp:198] Eltwise10 needs backward computation.
I1007 12:33:17.454172  4874 net.cpp:198] Scale22 needs backward computation.
I1007 12:33:17.454174  4874 net.cpp:198] BatchNorm22 needs backward computation.
I1007 12:33:17.454176  4874 net.cpp:198] Convolution22 needs backward computation.
I1007 12:33:17.454179  4874 net.cpp:198] M2PELU20 needs backward computation.
I1007 12:33:17.454181  4874 net.cpp:198] Scale21 needs backward computation.
I1007 12:33:17.454183  4874 net.cpp:198] BatchNorm21 needs backward computation.
I1007 12:33:17.454185  4874 net.cpp:198] Convolution21 needs backward computation.
I1007 12:33:17.454187  4874 net.cpp:198] Eltwise9_M2PELU19_0_split needs backward computation.
I1007 12:33:17.454190  4874 net.cpp:198] M2PELU19 needs backward computation.
I1007 12:33:17.454196  4874 net.cpp:198] Eltwise9 needs backward computation.
I1007 12:33:17.454200  4874 net.cpp:198] Scale20 needs backward computation.
I1007 12:33:17.454201  4874 net.cpp:198] BatchNorm20 needs backward computation.
I1007 12:33:17.454203  4874 net.cpp:198] Convolution20 needs backward computation.
I1007 12:33:17.478041  4874 net.cpp:198] M2PELU18 needs backward computation.
I1007 12:33:17.478049  4874 net.cpp:198] Scale19 needs backward computation.
I1007 12:33:17.478051  4874 net.cpp:198] BatchNorm19 needs backward computation.
I1007 12:33:17.478054  4874 net.cpp:198] Convolution19 needs backward computation.
I1007 12:33:17.478057  4874 net.cpp:198] Eltwise8_M2PELU17_0_split needs backward computation.
I1007 12:33:17.478060  4874 net.cpp:198] M2PELU17 needs backward computation.
I1007 12:33:17.478062  4874 net.cpp:198] Eltwise8 needs backward computation.
I1007 12:33:17.478065  4874 net.cpp:198] Scale18 needs backward computation.
I1007 12:33:17.478068  4874 net.cpp:198] BatchNorm18 needs backward computation.
I1007 12:33:17.478070  4874 net.cpp:198] Convolution18 needs backward computation.
I1007 12:33:17.478073  4874 net.cpp:198] M2PELU16 needs backward computation.
I1007 12:33:17.478075  4874 net.cpp:198] Scale17 needs backward computation.
I1007 12:33:17.478077  4874 net.cpp:198] BatchNorm17 needs backward computation.
I1007 12:33:17.478080  4874 net.cpp:198] Convolution17 needs backward computation.
I1007 12:33:17.478083  4874 net.cpp:198] Eltwise7_M2PELU15_0_split needs backward computation.
I1007 12:33:17.478086  4874 net.cpp:198] M2PELU15 needs backward computation.
I1007 12:33:17.478088  4874 net.cpp:198] Eltwise7 needs backward computation.
I1007 12:33:17.478091  4874 net.cpp:198] Scale16 needs backward computation.
I1007 12:33:17.478093  4874 net.cpp:198] BatchNorm16 needs backward computation.
I1007 12:33:17.478096  4874 net.cpp:198] Convolution16 needs backward computation.
I1007 12:33:17.478098  4874 net.cpp:198] M2PELU14 needs backward computation.
I1007 12:33:17.478101  4874 net.cpp:198] Scale15 needs backward computation.
I1007 12:33:17.478103  4874 net.cpp:198] BatchNorm15 needs backward computation.
I1007 12:33:17.478106  4874 net.cpp:198] Convolution15 needs backward computation.
I1007 12:33:17.478108  4874 net.cpp:198] Eltwise6_M2PELU13_0_split needs backward computation.
I1007 12:33:17.478111  4874 net.cpp:198] M2PELU13 needs backward computation.
I1007 12:33:17.478113  4874 net.cpp:198] Eltwise6 needs backward computation.
I1007 12:33:17.478116  4874 net.cpp:198] Scale14 needs backward computation.
I1007 12:33:17.478118  4874 net.cpp:198] BatchNorm14 needs backward computation.
I1007 12:33:17.478121  4874 net.cpp:198] Convolution14 needs backward computation.
I1007 12:33:17.478123  4874 net.cpp:198] M2PELU12 needs backward computation.
I1007 12:33:17.478127  4874 net.cpp:198] Scale13 needs backward computation.
I1007 12:33:17.478128  4874 net.cpp:198] BatchNorm13 needs backward computation.
I1007 12:33:17.478130  4874 net.cpp:198] Convolution13 needs backward computation.
I1007 12:33:17.478133  4874 net.cpp:198] Scale12 needs backward computation.
I1007 12:33:17.478135  4874 net.cpp:198] BatchNorm12 needs backward computation.
I1007 12:33:17.478138  4874 net.cpp:198] Convolution12 needs backward computation.
I1007 12:33:17.478140  4874 net.cpp:198] Eltwise5_M2PELU11_0_split needs backward computation.
I1007 12:33:17.478143  4874 net.cpp:198] M2PELU11 needs backward computation.
I1007 12:33:17.478145  4874 net.cpp:198] Eltwise5 needs backward computation.
I1007 12:33:17.478148  4874 net.cpp:198] Scale11 needs backward computation.
I1007 12:33:17.478152  4874 net.cpp:198] BatchNorm11 needs backward computation.
I1007 12:33:17.478153  4874 net.cpp:198] Convolution11 needs backward computation.
I1007 12:33:17.478157  4874 net.cpp:198] M2PELU10 needs backward computation.
I1007 12:33:17.478158  4874 net.cpp:198] Scale10 needs backward computation.
I1007 12:33:17.478160  4874 net.cpp:198] BatchNorm10 needs backward computation.
I1007 12:33:17.478170  4874 net.cpp:198] Convolution10 needs backward computation.
I1007 12:33:17.478173  4874 net.cpp:198] Eltwise4_M2PELU9_0_split needs backward computation.
I1007 12:33:17.478176  4874 net.cpp:198] M2PELU9 needs backward computation.
I1007 12:33:17.478178  4874 net.cpp:198] Eltwise4 needs backward computation.
I1007 12:33:17.478183  4874 net.cpp:198] Scale9 needs backward computation.
I1007 12:33:17.478185  4874 net.cpp:198] BatchNorm9 needs backward computation.
I1007 12:33:17.478188  4874 net.cpp:198] Convolution9 needs backward computation.
I1007 12:33:17.478190  4874 net.cpp:198] M2PELU8 needs backward computation.
I1007 12:33:17.478193  4874 net.cpp:198] Scale8 needs backward computation.
I1007 12:33:17.478195  4874 net.cpp:198] BatchNorm8 needs backward computation.
I1007 12:33:17.478197  4874 net.cpp:198] Convolution8 needs backward computation.
I1007 12:33:17.478200  4874 net.cpp:198] Eltwise3_M2PELU7_0_split needs backward computation.
I1007 12:33:17.478204  4874 net.cpp:198] M2PELU7 needs backward computation.
I1007 12:33:17.478207  4874 net.cpp:198] Eltwise3 needs backward computation.
I1007 12:33:17.478210  4874 net.cpp:198] Scale7 needs backward computation.
I1007 12:33:17.478212  4874 net.cpp:198] BatchNorm7 needs backward computation.
I1007 12:33:17.478215  4874 net.cpp:198] Convolution7 needs backward computation.
I1007 12:33:17.478217  4874 net.cpp:198] M2PELU6 needs backward computation.
I1007 12:33:17.478219  4874 net.cpp:198] Scale6 needs backward computation.
I1007 12:33:17.478222  4874 net.cpp:198] BatchNorm6 needs backward computation.
I1007 12:33:17.478224  4874 net.cpp:198] Convolution6 needs backward computation.
I1007 12:33:17.478227  4874 net.cpp:198] Eltwise2_M2PELU5_0_split needs backward computation.
I1007 12:33:17.478229  4874 net.cpp:198] M2PELU5 needs backward computation.
I1007 12:33:17.478232  4874 net.cpp:198] Eltwise2 needs backward computation.
I1007 12:33:17.478235  4874 net.cpp:198] Scale5 needs backward computation.
I1007 12:33:17.478237  4874 net.cpp:198] BatchNorm5 needs backward computation.
I1007 12:33:17.478240  4874 net.cpp:198] Convolution5 needs backward computation.
I1007 12:33:17.478242  4874 net.cpp:198] M2PELU4 needs backward computation.
I1007 12:33:17.478245  4874 net.cpp:198] Scale4 needs backward computation.
I1007 12:33:17.478247  4874 net.cpp:198] BatchNorm4 needs backward computation.
I1007 12:33:17.478250  4874 net.cpp:198] Convolution4 needs backward computation.
I1007 12:33:17.478252  4874 net.cpp:198] Eltwise1_M2PELU3_0_split needs backward computation.
I1007 12:33:17.478255  4874 net.cpp:198] M2PELU3 needs backward computation.
I1007 12:33:17.478257  4874 net.cpp:198] Eltwise1 needs backward computation.
I1007 12:33:17.478260  4874 net.cpp:198] Scale3 needs backward computation.
I1007 12:33:17.478262  4874 net.cpp:198] BatchNorm3 needs backward computation.
I1007 12:33:17.478266  4874 net.cpp:198] Convolution3 needs backward computation.
I1007 12:33:17.478268  4874 net.cpp:198] M2PELU2 needs backward computation.
I1007 12:33:17.478271  4874 net.cpp:198] Scale2 needs backward computation.
I1007 12:33:17.478272  4874 net.cpp:198] BatchNorm2 needs backward computation.
I1007 12:33:17.478276  4874 net.cpp:198] Convolution2 needs backward computation.
I1007 12:33:17.478278  4874 net.cpp:198] Convolution1_M2PELU1_0_split needs backward computation.
I1007 12:33:17.478281  4874 net.cpp:198] M2PELU1 needs backward computation.
I1007 12:33:17.478283  4874 net.cpp:198] Scale1 needs backward computation.
I1007 12:33:17.478286  4874 net.cpp:198] BatchNorm1 needs backward computation.
I1007 12:33:17.478287  4874 net.cpp:198] Convolution1 needs backward computation.
I1007 12:33:17.478291  4874 net.cpp:200] Data2_Data1_1_split does not need backward computation.
I1007 12:33:17.478294  4874 net.cpp:200] Data1 does not need backward computation.
I1007 12:33:17.478296  4874 net.cpp:242] This network produces output Accuracy1
I1007 12:33:17.478299  4874 net.cpp:242] This network produces output SoftmaxWithLoss1
I1007 12:33:17.478358  4874 net.cpp:255] Network initialization done.
I1007 12:33:17.478811  4874 solver.cpp:56] Solver scaffolding done.
I1007 12:33:17.487293  4874 caffe.cpp:248] Starting Optimization
I1007 12:33:17.487306  4874 solver.cpp:272] Solving resnet_cifar10
I1007 12:33:17.487309  4874 solver.cpp:273] Learning Rate Policy: multistep
I1007 12:33:17.490623  4874 solver.cpp:330] Iteration 0, Testing net (#0)
I1007 12:33:19.438415  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:33:19.516690  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.1
I1007 12:33:19.516726  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 87.3365 (* 1 = 87.3365 loss)
I1007 12:33:19.629276  4874 solver.cpp:218] Iteration 0 (0.106284 iter/s, 2.14189s/100 iters), loss = 2.30751
I1007 12:33:19.629303  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 2.30751 (* 1 = 2.30751 loss)
I1007 12:33:19.629314  4874 sgd_solver.cpp:105] Iteration 0, lr = 0.1
I1007 12:33:27.738023  4874 solver.cpp:218] Iteration 100 (12.3324 iter/s, 8.10869s/100 iters), loss = 1.67566
I1007 12:33:27.738061  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.67566 (* 1 = 1.67566 loss)
I1007 12:33:27.738067  4874 sgd_solver.cpp:105] Iteration 100, lr = 0.1
I1007 12:33:35.824090  4874 solver.cpp:218] Iteration 200 (12.3671 iter/s, 8.086s/100 iters), loss = 1.64099
I1007 12:33:35.824120  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.64099 (* 1 = 1.64099 loss)
I1007 12:33:35.824126  4874 sgd_solver.cpp:105] Iteration 200, lr = 0.1
I1007 12:33:43.939213  4874 solver.cpp:218] Iteration 300 (12.3228 iter/s, 8.11507s/100 iters), loss = 1.38574
I1007 12:33:43.939252  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.38574 (* 1 = 1.38574 loss)
I1007 12:33:43.939258  4874 sgd_solver.cpp:105] Iteration 300, lr = 0.1
I1007 12:33:52.062927  4874 solver.cpp:218] Iteration 400 (12.3097 iter/s, 8.12364s/100 iters), loss = 1.1724
I1007 12:33:52.063002  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.1724 (* 1 = 1.1724 loss)
I1007 12:33:52.063009  4874 sgd_solver.cpp:105] Iteration 400, lr = 0.1
I1007 12:33:59.808601  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:34:00.133121  4874 solver.cpp:330] Iteration 500, Testing net (#0)
I1007 12:34:02.029103  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:34:02.108235  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.2614
I1007 12:34:02.108270  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 3.14002 (* 1 = 3.14002 loss)
I1007 12:34:02.189326  4874 solver.cpp:218] Iteration 500 (9.87529 iter/s, 10.1263s/100 iters), loss = 1.26225
I1007 12:34:02.189354  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.26225 (* 1 = 1.26225 loss)
I1007 12:34:02.189362  4874 sgd_solver.cpp:105] Iteration 500, lr = 0.1
I1007 12:34:10.335996  4874 solver.cpp:218] Iteration 600 (12.275 iter/s, 8.14661s/100 iters), loss = 0.95709
I1007 12:34:10.336026  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.95709 (* 1 = 0.95709 loss)
I1007 12:34:10.336033  4874 sgd_solver.cpp:105] Iteration 600, lr = 0.1
I1007 12:34:18.566560  4874 solver.cpp:218] Iteration 700 (12.1499 iter/s, 8.2305s/100 iters), loss = 1.05082
I1007 12:34:18.566591  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.05082 (* 1 = 1.05082 loss)
I1007 12:34:18.566599  4874 sgd_solver.cpp:105] Iteration 700, lr = 0.1
I1007 12:34:26.662551  4874 solver.cpp:218] Iteration 800 (12.3519 iter/s, 8.09593s/100 iters), loss = 1.08039
I1007 12:34:26.662633  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.08039 (* 1 = 1.08039 loss)
I1007 12:34:26.662652  4874 sgd_solver.cpp:105] Iteration 800, lr = 0.1
I1007 12:34:34.760562  4874 solver.cpp:218] Iteration 900 (12.3489 iter/s, 8.09791s/100 iters), loss = 0.808455
I1007 12:34:34.760594  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.808455 (* 1 = 0.808455 loss)
I1007 12:34:34.760612  4874 sgd_solver.cpp:105] Iteration 900, lr = 0.1
I1007 12:34:42.465147  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:34:42.793247  4874 solver.cpp:330] Iteration 1000, Testing net (#0)
I1007 12:34:44.686691  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:34:44.765683  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.2302
I1007 12:34:44.765709  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 3.4541 (* 1 = 3.4541 loss)
I1007 12:34:44.846863  4874 solver.cpp:218] Iteration 1000 (9.9145 iter/s, 10.0862s/100 iters), loss = 0.925555
I1007 12:34:44.846892  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.925555 (* 1 = 0.925555 loss)
I1007 12:34:44.846902  4874 sgd_solver.cpp:105] Iteration 1000, lr = 0.1
I1007 12:34:52.948120  4874 solver.cpp:218] Iteration 1100 (12.3439 iter/s, 8.1012s/100 iters), loss = 0.665437
I1007 12:34:52.948151  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.665437 (* 1 = 0.665437 loss)
I1007 12:34:52.948159  4874 sgd_solver.cpp:105] Iteration 1100, lr = 0.1
I1007 12:35:01.036294  4874 solver.cpp:218] Iteration 1200 (12.3638 iter/s, 8.08812s/100 iters), loss = 0.865336
I1007 12:35:01.036428  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.865336 (* 1 = 0.865336 loss)
I1007 12:35:01.036448  4874 sgd_solver.cpp:105] Iteration 1200, lr = 0.1
I1007 12:35:09.124477  4874 solver.cpp:218] Iteration 1300 (12.3639 iter/s, 8.08803s/100 iters), loss = 0.782191
I1007 12:35:09.124510  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.782191 (* 1 = 0.782191 loss)
I1007 12:35:09.124527  4874 sgd_solver.cpp:105] Iteration 1300, lr = 0.1
I1007 12:35:17.220665  4874 solver.cpp:218] Iteration 1400 (12.3516 iter/s, 8.09613s/100 iters), loss = 0.666119
I1007 12:35:17.220697  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.666119 (* 1 = 0.666119 loss)
I1007 12:35:17.220715  4874 sgd_solver.cpp:105] Iteration 1400, lr = 0.1
I1007 12:35:24.916556  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:35:25.239929  4874 solver.cpp:330] Iteration 1500, Testing net (#0)
I1007 12:35:27.130724  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:35:27.209795  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.4446
I1007 12:35:27.209822  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.84071 (* 1 = 1.84071 loss)
I1007 12:35:27.290717  4874 solver.cpp:218] Iteration 1500 (9.9305 iter/s, 10.07s/100 iters), loss = 0.919366
I1007 12:35:27.290751  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.919366 (* 1 = 0.919366 loss)
I1007 12:35:27.290760  4874 sgd_solver.cpp:105] Iteration 1500, lr = 0.1
I1007 12:35:35.385146  4874 solver.cpp:218] Iteration 1600 (12.3543 iter/s, 8.09437s/100 iters), loss = 0.520953
I1007 12:35:35.385294  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.520953 (* 1 = 0.520953 loss)
I1007 12:35:35.385318  4874 sgd_solver.cpp:105] Iteration 1600, lr = 0.1
I1007 12:35:43.523805  4874 solver.cpp:218] Iteration 1700 (12.2873 iter/s, 8.13849s/100 iters), loss = 0.674202
I1007 12:35:43.523838  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.674202 (* 1 = 0.674202 loss)
I1007 12:35:43.523855  4874 sgd_solver.cpp:105] Iteration 1700, lr = 0.1
I1007 12:35:51.669333  4874 solver.cpp:218] Iteration 1800 (12.2768 iter/s, 8.14547s/100 iters), loss = 0.716269
I1007 12:35:51.669365  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.716269 (* 1 = 0.716269 loss)
I1007 12:35:51.669374  4874 sgd_solver.cpp:105] Iteration 1800, lr = 0.1
I1007 12:35:59.829794  4874 solver.cpp:218] Iteration 1900 (12.2543 iter/s, 8.1604s/100 iters), loss = 0.590826
I1007 12:35:59.829828  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.590826 (* 1 = 0.590826 loss)
I1007 12:35:59.829838  4874 sgd_solver.cpp:105] Iteration 1900, lr = 0.1
I1007 12:36:07.591521  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:36:07.915416  4874 solver.cpp:330] Iteration 2000, Testing net (#0)
I1007 12:36:09.821653  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:36:09.900943  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.5408
I1007 12:36:09.900970  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.37199 (* 1 = 1.37199 loss)
I1007 12:36:09.981928  4874 solver.cpp:218] Iteration 2000 (9.85021 iter/s, 10.1521s/100 iters), loss = 0.592189
I1007 12:36:09.981959  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.592189 (* 1 = 0.592189 loss)
I1007 12:36:09.981971  4874 sgd_solver.cpp:105] Iteration 2000, lr = 0.1
I1007 12:36:18.171344  4874 solver.cpp:218] Iteration 2100 (12.211 iter/s, 8.18936s/100 iters), loss = 0.435594
I1007 12:36:18.171380  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.435594 (* 1 = 0.435594 loss)
I1007 12:36:18.171399  4874 sgd_solver.cpp:105] Iteration 2100, lr = 0.1
I1007 12:36:26.336800  4874 solver.cpp:218] Iteration 2200 (12.2468 iter/s, 8.16539s/100 iters), loss = 0.566317
I1007 12:36:26.336835  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.566317 (* 1 = 0.566317 loss)
I1007 12:36:26.336854  4874 sgd_solver.cpp:105] Iteration 2200, lr = 0.1
I1007 12:36:34.512792  4874 solver.cpp:218] Iteration 2300 (12.231 iter/s, 8.17593s/100 iters), loss = 0.658358
I1007 12:36:34.512828  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.658358 (* 1 = 0.658358 loss)
I1007 12:36:34.512837  4874 sgd_solver.cpp:105] Iteration 2300, lr = 0.1
I1007 12:36:42.698973  4874 solver.cpp:218] Iteration 2400 (12.2158 iter/s, 8.18612s/100 iters), loss = 0.581119
I1007 12:36:42.699108  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.581119 (* 1 = 0.581119 loss)
I1007 12:36:42.699120  4874 sgd_solver.cpp:105] Iteration 2400, lr = 0.1
I1007 12:36:50.460036  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:36:50.789572  4874 solver.cpp:330] Iteration 2500, Testing net (#0)
I1007 12:36:52.709033  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:36:52.788216  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.5977
I1007 12:36:52.788242  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.19013 (* 1 = 1.19013 loss)
I1007 12:36:52.869539  4874 solver.cpp:218] Iteration 2500 (9.83244 iter/s, 10.1704s/100 iters), loss = 0.503034
I1007 12:36:52.869568  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.503034 (* 1 = 0.503034 loss)
I1007 12:36:52.869577  4874 sgd_solver.cpp:105] Iteration 2500, lr = 0.1
I1007 12:37:01.041177  4874 solver.cpp:218] Iteration 2600 (12.2375 iter/s, 8.17158s/100 iters), loss = 0.415698
I1007 12:37:01.041210  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.415698 (* 1 = 0.415698 loss)
I1007 12:37:01.041220  4874 sgd_solver.cpp:105] Iteration 2600, lr = 0.1
I1007 12:37:09.223361  4874 solver.cpp:218] Iteration 2700 (12.2218 iter/s, 8.18212s/100 iters), loss = 0.582785
I1007 12:37:09.223400  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.582785 (* 1 = 0.582785 loss)
I1007 12:37:09.223419  4874 sgd_solver.cpp:105] Iteration 2700, lr = 0.1
I1007 12:37:17.400156  4874 solver.cpp:218] Iteration 2800 (12.2298 iter/s, 8.17673s/100 iters), loss = 0.526815
I1007 12:37:17.400305  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.526815 (* 1 = 0.526815 loss)
I1007 12:37:17.400331  4874 sgd_solver.cpp:105] Iteration 2800, lr = 0.1
I1007 12:37:25.562044  4874 solver.cpp:218] Iteration 2900 (12.2523 iter/s, 8.16171s/100 iters), loss = 0.537543
I1007 12:37:25.562083  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.537543 (* 1 = 0.537543 loss)
I1007 12:37:25.562100  4874 sgd_solver.cpp:105] Iteration 2900, lr = 0.1
I1007 12:37:33.335691  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:37:33.664541  4874 solver.cpp:330] Iteration 3000, Testing net (#0)
I1007 12:37:35.578595  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:37:35.657769  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6894
I1007 12:37:35.657796  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.896613 (* 1 = 0.896613 loss)
I1007 12:37:35.739495  4874 solver.cpp:218] Iteration 3000 (9.82571 iter/s, 10.1774s/100 iters), loss = 0.555698
I1007 12:37:35.739529  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.555698 (* 1 = 0.555698 loss)
I1007 12:37:35.739540  4874 sgd_solver.cpp:105] Iteration 3000, lr = 0.1
I1007 12:37:43.933800  4874 solver.cpp:218] Iteration 3100 (12.2037 iter/s, 8.19424s/100 iters), loss = 0.389716
I1007 12:37:43.933833  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.389716 (* 1 = 0.389716 loss)
I1007 12:37:43.933842  4874 sgd_solver.cpp:105] Iteration 3100, lr = 0.1
I1007 12:37:52.113987  4874 solver.cpp:218] Iteration 3200 (12.2248 iter/s, 8.18013s/100 iters), loss = 0.508519
I1007 12:37:52.114115  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.508519 (* 1 = 0.508519 loss)
I1007 12:37:52.114140  4874 sgd_solver.cpp:105] Iteration 3200, lr = 0.1
I1007 12:38:00.285194  4874 solver.cpp:218] Iteration 3300 (12.2395 iter/s, 8.1703s/100 iters), loss = 0.503345
I1007 12:38:00.285228  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.503345 (* 1 = 0.503345 loss)
I1007 12:38:00.285235  4874 sgd_solver.cpp:105] Iteration 3300, lr = 0.1
I1007 12:38:08.431613  4874 solver.cpp:218] Iteration 3400 (12.2754 iter/s, 8.14636s/100 iters), loss = 0.46923
I1007 12:38:08.431653  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.46923 (* 1 = 0.46923 loss)
I1007 12:38:08.431659  4874 sgd_solver.cpp:105] Iteration 3400, lr = 0.1
I1007 12:38:16.148696  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:38:16.477622  4874 solver.cpp:330] Iteration 3500, Testing net (#0)
I1007 12:38:18.380566  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:38:18.462633  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6197
I1007 12:38:18.462659  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.1869 (* 1 = 1.1869 loss)
I1007 12:38:18.546373  4874 solver.cpp:218] Iteration 3500 (9.88661 iter/s, 10.1147s/100 iters), loss = 0.480842
I1007 12:38:18.546407  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.480842 (* 1 = 0.480842 loss)
I1007 12:38:18.546414  4874 sgd_solver.cpp:105] Iteration 3500, lr = 0.1
I1007 12:38:26.717293  4874 solver.cpp:218] Iteration 3600 (12.2386 iter/s, 8.17085s/100 iters), loss = 0.376859
I1007 12:38:26.717411  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.376859 (* 1 = 0.376859 loss)
I1007 12:38:26.717418  4874 sgd_solver.cpp:105] Iteration 3600, lr = 0.1
I1007 12:38:34.887491  4874 solver.cpp:218] Iteration 3700 (12.2398 iter/s, 8.17005s/100 iters), loss = 0.475431
I1007 12:38:34.887532  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.475431 (* 1 = 0.475431 loss)
I1007 12:38:34.887539  4874 sgd_solver.cpp:105] Iteration 3700, lr = 0.1
I1007 12:38:43.054378  4874 solver.cpp:218] Iteration 3800 (12.2447 iter/s, 8.16682s/100 iters), loss = 0.590513
I1007 12:38:43.054416  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.590513 (* 1 = 0.590513 loss)
I1007 12:38:43.054422  4874 sgd_solver.cpp:105] Iteration 3800, lr = 0.1
I1007 12:38:51.217139  4874 solver.cpp:218] Iteration 3900 (12.2509 iter/s, 8.16269s/100 iters), loss = 0.486071
I1007 12:38:51.217171  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.486071 (* 1 = 0.486071 loss)
I1007 12:38:51.217178  4874 sgd_solver.cpp:105] Iteration 3900, lr = 0.1
I1007 12:38:58.996474  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:38:59.326069  4874 solver.cpp:330] Iteration 4000, Testing net (#0)
I1007 12:39:01.233460  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:39:01.312769  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.705
I1007 12:39:01.312805  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.881974 (* 1 = 0.881974 loss)
I1007 12:39:01.397655  4874 solver.cpp:218] Iteration 4000 (9.82275 iter/s, 10.1804s/100 iters), loss = 0.470833
I1007 12:39:01.397686  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.470833 (* 1 = 0.470833 loss)
I1007 12:39:01.397702  4874 sgd_solver.cpp:105] Iteration 4000, lr = 0.1
I1007 12:39:09.590219  4874 solver.cpp:218] Iteration 4100 (12.2063 iter/s, 8.19249s/100 iters), loss = 0.3078
I1007 12:39:09.590301  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.3078 (* 1 = 0.3078 loss)
I1007 12:39:09.590309  4874 sgd_solver.cpp:105] Iteration 4100, lr = 0.1
I1007 12:39:17.774399  4874 solver.cpp:218] Iteration 4200 (12.2189 iter/s, 8.18405s/100 iters), loss = 0.366814
I1007 12:39:17.774440  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.366814 (* 1 = 0.366814 loss)
I1007 12:39:17.774446  4874 sgd_solver.cpp:105] Iteration 4200, lr = 0.1
I1007 12:39:25.948345  4874 solver.cpp:218] Iteration 4300 (12.2341 iter/s, 8.17388s/100 iters), loss = 0.58436
I1007 12:39:25.948377  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.58436 (* 1 = 0.58436 loss)
I1007 12:39:25.948393  4874 sgd_solver.cpp:105] Iteration 4300, lr = 0.1
I1007 12:39:34.117152  4874 solver.cpp:218] Iteration 4400 (12.2418 iter/s, 8.16875s/100 iters), loss = 0.450723
I1007 12:39:34.117285  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.450723 (* 1 = 0.450723 loss)
I1007 12:39:34.117293  4874 sgd_solver.cpp:105] Iteration 4400, lr = 0.1
I1007 12:39:41.908107  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:39:42.238019  4874 solver.cpp:330] Iteration 4500, Testing net (#0)
I1007 12:39:44.134969  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:39:44.214107  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6976
I1007 12:39:44.214143  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.883109 (* 1 = 0.883109 loss)
I1007 12:39:44.297765  4874 solver.cpp:218] Iteration 4500 (9.82275 iter/s, 10.1804s/100 iters), loss = 0.51615
I1007 12:39:44.297802  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.51615 (* 1 = 0.51615 loss)
I1007 12:39:44.297811  4874 sgd_solver.cpp:105] Iteration 4500, lr = 0.1
I1007 12:39:52.492328  4874 solver.cpp:218] Iteration 4600 (12.2033 iter/s, 8.1945s/100 iters), loss = 0.355164
I1007 12:39:52.492358  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.355164 (* 1 = 0.355164 loss)
I1007 12:39:52.492363  4874 sgd_solver.cpp:105] Iteration 4600, lr = 0.1
I1007 12:40:00.665827  4874 solver.cpp:218] Iteration 4700 (12.2347 iter/s, 8.17344s/100 iters), loss = 0.432648
I1007 12:40:00.665858  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.432648 (* 1 = 0.432648 loss)
I1007 12:40:00.665864  4874 sgd_solver.cpp:105] Iteration 4700, lr = 0.1
I1007 12:40:08.855289  4874 solver.cpp:218] Iteration 4800 (12.2109 iter/s, 8.1894s/100 iters), loss = 0.596537
I1007 12:40:08.855401  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.596537 (* 1 = 0.596537 loss)
I1007 12:40:08.855407  4874 sgd_solver.cpp:105] Iteration 4800, lr = 0.1
I1007 12:40:17.037149  4874 solver.cpp:218] Iteration 4900 (12.2224 iter/s, 8.18173s/100 iters), loss = 0.464502
I1007 12:40:17.037181  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.464502 (* 1 = 0.464502 loss)
I1007 12:40:17.037187  4874 sgd_solver.cpp:105] Iteration 4900, lr = 0.1
I1007 12:40:24.868319  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:40:25.196745  4874 solver.cpp:330] Iteration 5000, Testing net (#0)
I1007 12:40:27.121389  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:40:27.201663  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7375
I1007 12:40:27.201692  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.771442 (* 1 = 0.771442 loss)
I1007 12:40:27.289144  4874 solver.cpp:218] Iteration 5000 (9.75426 iter/s, 10.2519s/100 iters), loss = 0.407082
I1007 12:40:27.289183  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.407082 (* 1 = 0.407082 loss)
I1007 12:40:27.289193  4874 sgd_solver.cpp:105] Iteration 5000, lr = 0.1
I1007 12:40:35.500627  4874 solver.cpp:218] Iteration 5100 (12.1784 iter/s, 8.21126s/100 iters), loss = 0.292268
I1007 12:40:35.500665  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.292268 (* 1 = 0.292268 loss)
I1007 12:40:35.500671  4874 sgd_solver.cpp:105] Iteration 5100, lr = 0.1
I1007 12:40:43.636958  4874 solver.cpp:218] Iteration 5200 (12.2907 iter/s, 8.13626s/100 iters), loss = 0.391487
I1007 12:40:43.637101  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.391487 (* 1 = 0.391487 loss)
I1007 12:40:43.637120  4874 sgd_solver.cpp:105] Iteration 5200, lr = 0.1
I1007 12:40:51.748340  4874 solver.cpp:218] Iteration 5300 (12.3286 iter/s, 8.11122s/100 iters), loss = 0.423024
I1007 12:40:51.748369  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.423024 (* 1 = 0.423024 loss)
I1007 12:40:51.748375  4874 sgd_solver.cpp:105] Iteration 5300, lr = 0.1
I1007 12:40:59.851404  4874 solver.cpp:218] Iteration 5400 (12.3411 iter/s, 8.10301s/100 iters), loss = 0.396491
I1007 12:40:59.851444  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.396491 (* 1 = 0.396491 loss)
I1007 12:40:59.851450  4874 sgd_solver.cpp:105] Iteration 5400, lr = 0.1
I1007 12:41:07.562691  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:41:07.887722  4874 solver.cpp:330] Iteration 5500, Testing net (#0)
I1007 12:41:09.780241  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:41:09.859117  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7546
I1007 12:41:09.859153  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.725597 (* 1 = 0.725597 loss)
I1007 12:41:09.940239  4874 solver.cpp:218] Iteration 5500 (9.91202 iter/s, 10.0888s/100 iters), loss = 0.338085
I1007 12:41:09.940269  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.338085 (* 1 = 0.338085 loss)
I1007 12:41:09.940276  4874 sgd_solver.cpp:105] Iteration 5500, lr = 0.1
I1007 12:41:18.037294  4874 solver.cpp:218] Iteration 5600 (12.3503 iter/s, 8.097s/100 iters), loss = 0.287065
I1007 12:41:18.037396  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.287065 (* 1 = 0.287065 loss)
I1007 12:41:18.037413  4874 sgd_solver.cpp:105] Iteration 5600, lr = 0.1
I1007 12:41:26.139992  4874 solver.cpp:218] Iteration 5700 (12.3418 iter/s, 8.10257s/100 iters), loss = 0.283747
I1007 12:41:26.140031  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.283747 (* 1 = 0.283747 loss)
I1007 12:41:26.140038  4874 sgd_solver.cpp:105] Iteration 5700, lr = 0.1
I1007 12:41:34.242435  4874 solver.cpp:218] Iteration 5800 (12.3421 iter/s, 8.10238s/100 iters), loss = 0.337313
I1007 12:41:34.242465  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.337313 (* 1 = 0.337313 loss)
I1007 12:41:34.242472  4874 sgd_solver.cpp:105] Iteration 5800, lr = 0.1
I1007 12:41:42.345470  4874 solver.cpp:218] Iteration 5900 (12.3411 iter/s, 8.10298s/100 iters), loss = 0.411699
I1007 12:41:42.345500  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.411699 (* 1 = 0.411699 loss)
I1007 12:41:42.345505  4874 sgd_solver.cpp:105] Iteration 5900, lr = 0.1
I1007 12:41:50.043584  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:41:50.368918  4874 solver.cpp:330] Iteration 6000, Testing net (#0)
I1007 12:41:52.262405  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:41:52.341150  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7855
I1007 12:41:52.341187  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.632602 (* 1 = 0.632602 loss)
I1007 12:41:52.422245  4874 solver.cpp:218] Iteration 6000 (9.92387 iter/s, 10.0767s/100 iters), loss = 0.370181
I1007 12:41:52.422272  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.370181 (* 1 = 0.370181 loss)
I1007 12:41:52.422279  4874 sgd_solver.cpp:105] Iteration 6000, lr = 0.1
I1007 12:42:00.523928  4874 solver.cpp:218] Iteration 6100 (12.3432 iter/s, 8.10163s/100 iters), loss = 0.324086
I1007 12:42:00.523968  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.324086 (* 1 = 0.324086 loss)
I1007 12:42:00.523974  4874 sgd_solver.cpp:105] Iteration 6100, lr = 0.1
I1007 12:42:08.616856  4874 solver.cpp:218] Iteration 6200 (12.3566 iter/s, 8.09286s/100 iters), loss = 0.4531
I1007 12:42:08.616886  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.4531 (* 1 = 0.4531 loss)
I1007 12:42:08.616902  4874 sgd_solver.cpp:105] Iteration 6200, lr = 0.1
I1007 12:42:16.717563  4874 solver.cpp:218] Iteration 6300 (12.3447 iter/s, 8.10065s/100 iters), loss = 0.432142
I1007 12:42:16.717592  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.432143 (* 1 = 0.432143 loss)
I1007 12:42:16.717598  4874 sgd_solver.cpp:105] Iteration 6300, lr = 0.1
I1007 12:42:24.811887  4874 solver.cpp:218] Iteration 6400 (12.3544 iter/s, 8.09427s/100 iters), loss = 0.369118
I1007 12:42:24.812024  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.369118 (* 1 = 0.369118 loss)
I1007 12:42:24.812033  4874 sgd_solver.cpp:105] Iteration 6400, lr = 0.1
I1007 12:42:32.510375  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:42:32.833734  4874 solver.cpp:330] Iteration 6500, Testing net (#0)
I1007 12:42:34.726562  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:42:34.805009  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.5581
I1007 12:42:34.805044  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.70846 (* 1 = 1.70846 loss)
I1007 12:42:34.885907  4874 solver.cpp:218] Iteration 6500 (9.92669 iter/s, 10.0739s/100 iters), loss = 0.282607
I1007 12:42:34.885936  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.282607 (* 1 = 0.282607 loss)
I1007 12:42:34.885942  4874 sgd_solver.cpp:105] Iteration 6500, lr = 0.1
I1007 12:42:42.989027  4874 solver.cpp:218] Iteration 6600 (12.341 iter/s, 8.10307s/100 iters), loss = 0.27342
I1007 12:42:42.989068  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.273421 (* 1 = 0.273421 loss)
I1007 12:42:42.989073  4874 sgd_solver.cpp:105] Iteration 6600, lr = 0.1
I1007 12:42:51.097728  4874 solver.cpp:218] Iteration 6700 (12.3325 iter/s, 8.10863s/100 iters), loss = 0.430156
I1007 12:42:51.097757  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.430156 (* 1 = 0.430156 loss)
I1007 12:42:51.097764  4874 sgd_solver.cpp:105] Iteration 6700, lr = 0.1
I1007 12:42:59.197038  4874 solver.cpp:218] Iteration 6800 (12.3468 iter/s, 8.09926s/100 iters), loss = 0.30183
I1007 12:42:59.197166  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.30183 (* 1 = 0.30183 loss)
I1007 12:42:59.197173  4874 sgd_solver.cpp:105] Iteration 6800, lr = 0.1
I1007 12:43:07.308689  4874 solver.cpp:218] Iteration 6900 (12.3282 iter/s, 8.11151s/100 iters), loss = 0.371414
I1007 12:43:07.308719  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.371415 (* 1 = 0.371415 loss)
I1007 12:43:07.308727  4874 sgd_solver.cpp:105] Iteration 6900, lr = 0.1
I1007 12:43:15.015298  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:43:15.338932  4874 solver.cpp:330] Iteration 7000, Testing net (#0)
I1007 12:43:17.231357  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:43:17.309708  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.689
I1007 12:43:17.309746  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.949463 (* 1 = 0.949463 loss)
I1007 12:43:17.390671  4874 solver.cpp:218] Iteration 7000 (9.91875 iter/s, 10.0819s/100 iters), loss = 0.288799
I1007 12:43:17.390697  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.288799 (* 1 = 0.288799 loss)
I1007 12:43:17.390703  4874 sgd_solver.cpp:105] Iteration 7000, lr = 0.1
I1007 12:43:25.493268  4874 solver.cpp:218] Iteration 7100 (12.3418 iter/s, 8.10255s/100 iters), loss = 0.246673
I1007 12:43:25.493296  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.246673 (* 1 = 0.246673 loss)
I1007 12:43:25.493302  4874 sgd_solver.cpp:105] Iteration 7100, lr = 0.1
I1007 12:43:33.584939  4874 solver.cpp:218] Iteration 7200 (12.3585 iter/s, 8.09162s/100 iters), loss = 0.397846
I1007 12:43:33.585032  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.397846 (* 1 = 0.397846 loss)
I1007 12:43:33.585039  4874 sgd_solver.cpp:105] Iteration 7200, lr = 0.1
I1007 12:43:41.682168  4874 solver.cpp:218] Iteration 7300 (12.3501 iter/s, 8.09711s/100 iters), loss = 0.316968
I1007 12:43:41.682195  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.316968 (* 1 = 0.316968 loss)
I1007 12:43:41.682201  4874 sgd_solver.cpp:105] Iteration 7300, lr = 0.1
I1007 12:43:49.774041  4874 solver.cpp:218] Iteration 7400 (12.3582 iter/s, 8.09182s/100 iters), loss = 0.371236
I1007 12:43:49.774083  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.371236 (* 1 = 0.371236 loss)
I1007 12:43:49.774091  4874 sgd_solver.cpp:105] Iteration 7400, lr = 0.1
I1007 12:43:57.468757  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:43:57.792613  4874 solver.cpp:330] Iteration 7500, Testing net (#0)
I1007 12:43:59.684774  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:43:59.763590  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7029
I1007 12:43:59.763626  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.923158 (* 1 = 0.923158 loss)
I1007 12:43:59.844521  4874 solver.cpp:218] Iteration 7500 (9.93009 iter/s, 10.0704s/100 iters), loss = 0.330612
I1007 12:43:59.844549  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.330613 (* 1 = 0.330613 loss)
I1007 12:43:59.844555  4874 sgd_solver.cpp:105] Iteration 7500, lr = 0.1
I1007 12:44:07.942682  4874 solver.cpp:218] Iteration 7600 (12.3486 iter/s, 8.09811s/100 iters), loss = 0.20262
I1007 12:44:07.942816  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.20262 (* 1 = 0.20262 loss)
I1007 12:44:07.942824  4874 sgd_solver.cpp:105] Iteration 7600, lr = 0.1
I1007 12:44:16.044034  4874 solver.cpp:218] Iteration 7700 (12.3438 iter/s, 8.1012s/100 iters), loss = 0.285219
I1007 12:44:16.044064  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.28522 (* 1 = 0.28522 loss)
I1007 12:44:16.044071  4874 sgd_solver.cpp:105] Iteration 7700, lr = 0.1
I1007 12:44:24.139874  4874 solver.cpp:218] Iteration 7800 (12.3521 iter/s, 8.09578s/100 iters), loss = 0.358279
I1007 12:44:24.139914  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.35828 (* 1 = 0.35828 loss)
I1007 12:44:24.139920  4874 sgd_solver.cpp:105] Iteration 7800, lr = 0.1
I1007 12:44:32.241029  4874 solver.cpp:218] Iteration 7900 (12.344 iter/s, 8.10109s/100 iters), loss = 0.3764
I1007 12:44:32.241058  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.376401 (* 1 = 0.376401 loss)
I1007 12:44:32.241065  4874 sgd_solver.cpp:105] Iteration 7900, lr = 0.1
I1007 12:44:39.933964  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:44:40.257833  4874 solver.cpp:330] Iteration 8000, Testing net (#0)
I1007 12:44:42.151379  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:44:42.230295  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.579
I1007 12:44:42.230329  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.7352 (* 1 = 1.7352 loss)
I1007 12:44:42.311208  4874 solver.cpp:218] Iteration 8000 (9.93037 iter/s, 10.0701s/100 iters), loss = 0.304373
I1007 12:44:42.311242  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.304374 (* 1 = 0.304374 loss)
I1007 12:44:42.311249  4874 sgd_solver.cpp:105] Iteration 8000, lr = 0.1
I1007 12:44:50.409596  4874 solver.cpp:218] Iteration 8100 (12.3482 iter/s, 8.09833s/100 iters), loss = 0.315994
I1007 12:44:50.409626  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.315994 (* 1 = 0.315994 loss)
I1007 12:44:50.409643  4874 sgd_solver.cpp:105] Iteration 8100, lr = 0.1
I1007 12:44:58.503778  4874 solver.cpp:218] Iteration 8200 (12.3546 iter/s, 8.09413s/100 iters), loss = 0.347488
I1007 12:44:58.503808  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.347488 (* 1 = 0.347488 loss)
I1007 12:44:58.503814  4874 sgd_solver.cpp:105] Iteration 8200, lr = 0.1
I1007 12:45:06.602727  4874 solver.cpp:218] Iteration 8300 (12.3474 iter/s, 8.09889s/100 iters), loss = 0.347157
I1007 12:45:06.602763  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.347157 (* 1 = 0.347157 loss)
I1007 12:45:06.602782  4874 sgd_solver.cpp:105] Iteration 8300, lr = 0.1
I1007 12:45:14.696360  4874 solver.cpp:218] Iteration 8400 (12.3555 iter/s, 8.09357s/100 iters), loss = 0.431673
I1007 12:45:14.696506  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.431673 (* 1 = 0.431673 loss)
I1007 12:45:14.696523  4874 sgd_solver.cpp:105] Iteration 8400, lr = 0.1
I1007 12:45:22.392005  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:45:22.716498  4874 solver.cpp:330] Iteration 8500, Testing net (#0)
I1007 12:45:24.609275  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:45:24.688398  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6315
I1007 12:45:24.688433  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.28681 (* 1 = 1.28681 loss)
I1007 12:45:24.769915  4874 solver.cpp:218] Iteration 8500 (9.92715 iter/s, 10.0734s/100 iters), loss = 0.285007
I1007 12:45:24.769946  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.285008 (* 1 = 0.285008 loss)
I1007 12:45:24.769953  4874 sgd_solver.cpp:105] Iteration 8500, lr = 0.1
I1007 12:45:32.868456  4874 solver.cpp:218] Iteration 8600 (12.348 iter/s, 8.09848s/100 iters), loss = 0.27012
I1007 12:45:32.868497  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.27012 (* 1 = 0.27012 loss)
I1007 12:45:32.868504  4874 sgd_solver.cpp:105] Iteration 8600, lr = 0.1
I1007 12:45:40.972657  4874 solver.cpp:218] Iteration 8700 (12.3394 iter/s, 8.10413s/100 iters), loss = 0.373862
I1007 12:45:40.972697  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.373863 (* 1 = 0.373863 loss)
I1007 12:45:40.972704  4874 sgd_solver.cpp:105] Iteration 8700, lr = 0.1
I1007 12:45:49.071918  4874 solver.cpp:218] Iteration 8800 (12.3469 iter/s, 8.09919s/100 iters), loss = 0.363907
I1007 12:45:49.072031  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.363908 (* 1 = 0.363908 loss)
I1007 12:45:49.072037  4874 sgd_solver.cpp:105] Iteration 8800, lr = 0.1
I1007 12:45:57.180225  4874 solver.cpp:218] Iteration 8900 (12.3332 iter/s, 8.10818s/100 iters), loss = 0.293256
I1007 12:45:57.180266  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.293256 (* 1 = 0.293256 loss)
I1007 12:45:57.180272  4874 sgd_solver.cpp:105] Iteration 8900, lr = 0.1
I1007 12:46:04.878677  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:46:05.203083  4874 solver.cpp:330] Iteration 9000, Testing net (#0)
I1007 12:46:07.097162  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:46:07.176347  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7738
I1007 12:46:07.176383  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.669942 (* 1 = 0.669942 loss)
I1007 12:46:07.257596  4874 solver.cpp:218] Iteration 9000 (9.9233 iter/s, 10.0773s/100 iters), loss = 0.295668
I1007 12:46:07.257628  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.295669 (* 1 = 0.295669 loss)
I1007 12:46:07.257635  4874 sgd_solver.cpp:105] Iteration 9000, lr = 0.1
I1007 12:46:15.355268  4874 solver.cpp:218] Iteration 9100 (12.3493 iter/s, 8.09761s/100 iters), loss = 0.30243
I1007 12:46:15.355296  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.30243 (* 1 = 0.30243 loss)
I1007 12:46:15.355303  4874 sgd_solver.cpp:105] Iteration 9100, lr = 0.1
I1007 12:46:23.456467  4874 solver.cpp:218] Iteration 9200 (12.3439 iter/s, 8.10114s/100 iters), loss = 0.355671
I1007 12:46:23.456594  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.355671 (* 1 = 0.355671 loss)
I1007 12:46:23.456601  4874 sgd_solver.cpp:105] Iteration 9200, lr = 0.1
I1007 12:46:31.556447  4874 solver.cpp:218] Iteration 9300 (12.3459 iter/s, 8.09983s/100 iters), loss = 0.272152
I1007 12:46:31.556488  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.272153 (* 1 = 0.272153 loss)
I1007 12:46:31.556493  4874 sgd_solver.cpp:105] Iteration 9300, lr = 0.1
I1007 12:46:39.654431  4874 solver.cpp:218] Iteration 9400 (12.3489 iter/s, 8.09792s/100 iters), loss = 0.417193
I1007 12:46:39.654471  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.417193 (* 1 = 0.417193 loss)
I1007 12:46:39.654479  4874 sgd_solver.cpp:105] Iteration 9400, lr = 0.1
I1007 12:46:47.356122  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:46:47.680515  4874 solver.cpp:330] Iteration 9500, Testing net (#0)
I1007 12:46:49.573698  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:46:49.652626  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.799
I1007 12:46:49.652660  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.585592 (* 1 = 0.585592 loss)
I1007 12:46:49.733569  4874 solver.cpp:218] Iteration 9500 (9.92156 iter/s, 10.0791s/100 iters), loss = 0.27579
I1007 12:46:49.733611  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.27579 (* 1 = 0.27579 loss)
I1007 12:46:49.733618  4874 sgd_solver.cpp:105] Iteration 9500, lr = 0.1
I1007 12:46:57.838688  4874 solver.cpp:218] Iteration 9600 (12.338 iter/s, 8.10505s/100 iters), loss = 0.321951
I1007 12:46:57.838785  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.321951 (* 1 = 0.321951 loss)
I1007 12:46:57.838793  4874 sgd_solver.cpp:105] Iteration 9600, lr = 0.1
I1007 12:47:05.948601  4874 solver.cpp:218] Iteration 9700 (12.3308 iter/s, 8.10979s/100 iters), loss = 0.454535
I1007 12:47:05.948642  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.454536 (* 1 = 0.454536 loss)
I1007 12:47:05.948648  4874 sgd_solver.cpp:105] Iteration 9700, lr = 0.1
I1007 12:47:14.053110  4874 solver.cpp:218] Iteration 9800 (12.3389 iter/s, 8.10444s/100 iters), loss = 0.300347
I1007 12:47:14.053139  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.300347 (* 1 = 0.300347 loss)
I1007 12:47:14.053146  4874 sgd_solver.cpp:105] Iteration 9800, lr = 0.1
I1007 12:47:22.165618  4874 solver.cpp:218] Iteration 9900 (12.3267 iter/s, 8.11245s/100 iters), loss = 0.34653
I1007 12:47:22.165648  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.34653 (* 1 = 0.34653 loss)
I1007 12:47:22.165654  4874 sgd_solver.cpp:105] Iteration 9900, lr = 0.1
I1007 12:47:29.866664  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:47:30.192217  4874 solver.cpp:330] Iteration 10000, Testing net (#0)
I1007 12:47:32.085928  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:47:32.165026  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7358
I1007 12:47:32.165062  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.833776 (* 1 = 0.833776 loss)
I1007 12:47:32.246093  4874 solver.cpp:218] Iteration 10000 (9.92023 iter/s, 10.0804s/100 iters), loss = 0.338945
I1007 12:47:32.246125  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.338945 (* 1 = 0.338945 loss)
I1007 12:47:32.246134  4874 sgd_solver.cpp:105] Iteration 10000, lr = 0.1
I1007 12:47:40.347223  4874 solver.cpp:218] Iteration 10100 (12.344 iter/s, 8.10107s/100 iters), loss = 0.326908
I1007 12:47:40.347252  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.326909 (* 1 = 0.326909 loss)
I1007 12:47:40.347259  4874 sgd_solver.cpp:105] Iteration 10100, lr = 0.1
I1007 12:47:48.444303  4874 solver.cpp:218] Iteration 10200 (12.3502 iter/s, 8.09703s/100 iters), loss = 0.407325
I1007 12:47:48.444344  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.407325 (* 1 = 0.407325 loss)
I1007 12:47:48.444350  4874 sgd_solver.cpp:105] Iteration 10200, lr = 0.1
I1007 12:47:56.547230  4874 solver.cpp:218] Iteration 10300 (12.3413 iter/s, 8.10286s/100 iters), loss = 0.319794
I1007 12:47:56.547271  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.319795 (* 1 = 0.319795 loss)
I1007 12:47:56.547276  4874 sgd_solver.cpp:105] Iteration 10300, lr = 0.1
I1007 12:48:04.645737  4874 solver.cpp:218] Iteration 10400 (12.3481 iter/s, 8.09844s/100 iters), loss = 0.336558
I1007 12:48:04.645874  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.336558 (* 1 = 0.336558 loss)
I1007 12:48:04.645891  4874 sgd_solver.cpp:105] Iteration 10400, lr = 0.1
I1007 12:48:12.345760  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:48:12.670403  4874 solver.cpp:330] Iteration 10500, Testing net (#0)
I1007 12:48:14.562011  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:48:14.640956  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7303
I1007 12:48:14.640990  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.857496 (* 1 = 0.857496 loss)
I1007 12:48:14.721827  4874 solver.cpp:218] Iteration 10500 (9.92464 iter/s, 10.0759s/100 iters), loss = 0.229888
I1007 12:48:14.721854  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.229888 (* 1 = 0.229888 loss)
I1007 12:48:14.721861  4874 sgd_solver.cpp:105] Iteration 10500, lr = 0.1
I1007 12:48:22.820909  4874 solver.cpp:218] Iteration 10600 (12.3472 iter/s, 8.09903s/100 iters), loss = 0.228642
I1007 12:48:22.820938  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.228642 (* 1 = 0.228642 loss)
I1007 12:48:22.820945  4874 sgd_solver.cpp:105] Iteration 10600, lr = 0.1
I1007 12:48:30.925235  4874 solver.cpp:218] Iteration 10700 (12.3392 iter/s, 8.10427s/100 iters), loss = 0.308378
I1007 12:48:30.925272  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.308379 (* 1 = 0.308379 loss)
I1007 12:48:30.925290  4874 sgd_solver.cpp:105] Iteration 10700, lr = 0.1
I1007 12:48:39.030764  4874 solver.cpp:218] Iteration 10800 (12.3374 iter/s, 8.10547s/100 iters), loss = 0.305752
I1007 12:48:39.030875  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.305753 (* 1 = 0.305753 loss)
I1007 12:48:39.030882  4874 sgd_solver.cpp:105] Iteration 10800, lr = 0.1
I1007 12:48:47.133635  4874 solver.cpp:218] Iteration 10900 (12.3415 iter/s, 8.10275s/100 iters), loss = 0.198521
I1007 12:48:47.133666  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.198521 (* 1 = 0.198521 loss)
I1007 12:48:47.133671  4874 sgd_solver.cpp:105] Iteration 10900, lr = 0.1
I1007 12:48:54.832778  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:48:55.157155  4874 solver.cpp:330] Iteration 11000, Testing net (#0)
I1007 12:48:57.050215  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:48:57.129552  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8035
I1007 12:48:57.129587  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.597616 (* 1 = 0.597616 loss)
I1007 12:48:57.210480  4874 solver.cpp:218] Iteration 11000 (9.9238 iter/s, 10.0768s/100 iters), loss = 0.253615
I1007 12:48:57.210507  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.253615 (* 1 = 0.253615 loss)
I1007 12:48:57.210515  4874 sgd_solver.cpp:105] Iteration 11000, lr = 0.1
I1007 12:49:05.313865  4874 solver.cpp:218] Iteration 11100 (12.3406 iter/s, 8.10333s/100 iters), loss = 0.214237
I1007 12:49:05.313894  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.214237 (* 1 = 0.214237 loss)
I1007 12:49:05.313911  4874 sgd_solver.cpp:105] Iteration 11100, lr = 0.1
I1007 12:49:13.408347  4874 solver.cpp:218] Iteration 11200 (12.3542 iter/s, 8.09443s/100 iters), loss = 0.209378
I1007 12:49:13.408488  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.209378 (* 1 = 0.209378 loss)
I1007 12:49:13.408496  4874 sgd_solver.cpp:105] Iteration 11200, lr = 0.1
I1007 12:49:21.505956  4874 solver.cpp:218] Iteration 11300 (12.3496 iter/s, 8.09745s/100 iters), loss = 0.297106
I1007 12:49:21.505985  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.297106 (* 1 = 0.297106 loss)
I1007 12:49:21.505991  4874 sgd_solver.cpp:105] Iteration 11300, lr = 0.1
I1007 12:49:29.599994  4874 solver.cpp:218] Iteration 11400 (12.3549 iter/s, 8.09398s/100 iters), loss = 0.21631
I1007 12:49:29.600034  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.21631 (* 1 = 0.21631 loss)
I1007 12:49:29.600040  4874 sgd_solver.cpp:105] Iteration 11400, lr = 0.1
I1007 12:49:37.294387  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:49:37.618824  4874 solver.cpp:330] Iteration 11500, Testing net (#0)
I1007 12:49:39.511387  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:49:39.590682  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6687
I1007 12:49:39.590716  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.06373 (* 1 = 1.06373 loss)
I1007 12:49:39.671504  4874 solver.cpp:218] Iteration 11500 (9.92907 iter/s, 10.0714s/100 iters), loss = 0.268405
I1007 12:49:39.671531  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.268405 (* 1 = 0.268405 loss)
I1007 12:49:39.671540  4874 sgd_solver.cpp:105] Iteration 11500, lr = 0.1
I1007 12:49:47.762733  4874 solver.cpp:218] Iteration 11600 (12.3591 iter/s, 8.09118s/100 iters), loss = 0.230316
I1007 12:49:47.762850  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.230316 (* 1 = 0.230316 loss)
I1007 12:49:47.762856  4874 sgd_solver.cpp:105] Iteration 11600, lr = 0.1
I1007 12:49:55.861300  4874 solver.cpp:218] Iteration 11700 (12.3481 iter/s, 8.09843s/100 iters), loss = 0.349672
I1007 12:49:55.861330  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.349672 (* 1 = 0.349672 loss)
I1007 12:49:55.861335  4874 sgd_solver.cpp:105] Iteration 11700, lr = 0.1
I1007 12:50:03.954833  4874 solver.cpp:218] Iteration 11800 (12.3556 iter/s, 8.09348s/100 iters), loss = 0.363507
I1007 12:50:03.954874  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.363507 (* 1 = 0.363507 loss)
I1007 12:50:03.954879  4874 sgd_solver.cpp:105] Iteration 11800, lr = 0.1
I1007 12:50:12.048529  4874 solver.cpp:218] Iteration 11900 (12.3554 iter/s, 8.09363s/100 iters), loss = 0.314804
I1007 12:50:12.048558  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.314805 (* 1 = 0.314805 loss)
I1007 12:50:12.048563  4874 sgd_solver.cpp:105] Iteration 11900, lr = 0.1
I1007 12:50:19.742548  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:50:20.066828  4874 solver.cpp:330] Iteration 12000, Testing net (#0)
I1007 12:50:21.961369  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:50:22.040683  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.708
I1007 12:50:22.040717  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.860601 (* 1 = 0.860601 loss)
I1007 12:50:22.121629  4874 solver.cpp:218] Iteration 12000 (9.92749 iter/s, 10.073s/100 iters), loss = 0.230322
I1007 12:50:22.121655  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.230322 (* 1 = 0.230322 loss)
I1007 12:50:22.121662  4874 sgd_solver.cpp:105] Iteration 12000, lr = 0.1
I1007 12:50:30.221474  4874 solver.cpp:218] Iteration 12100 (12.346 iter/s, 8.09979s/100 iters), loss = 0.295301
I1007 12:50:30.221514  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.295301 (* 1 = 0.295301 loss)
I1007 12:50:30.221520  4874 sgd_solver.cpp:105] Iteration 12100, lr = 0.1
I1007 12:50:38.319856  4874 solver.cpp:218] Iteration 12200 (12.3482 iter/s, 8.09832s/100 iters), loss = 0.316864
I1007 12:50:38.319886  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.316865 (* 1 = 0.316865 loss)
I1007 12:50:38.319892  4874 sgd_solver.cpp:105] Iteration 12200, lr = 0.1
I1007 12:50:46.419899  4874 solver.cpp:218] Iteration 12300 (12.3457 iter/s, 8.09999s/100 iters), loss = 0.269913
I1007 12:50:46.419929  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.269913 (* 1 = 0.269913 loss)
I1007 12:50:46.419934  4874 sgd_solver.cpp:105] Iteration 12300, lr = 0.1
I1007 12:50:54.516445  4874 solver.cpp:218] Iteration 12400 (12.351 iter/s, 8.09649s/100 iters), loss = 0.278178
I1007 12:50:54.516542  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.278178 (* 1 = 0.278178 loss)
I1007 12:50:54.516561  4874 sgd_solver.cpp:105] Iteration 12400, lr = 0.1
I1007 12:51:02.217370  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:51:02.541820  4874 solver.cpp:330] Iteration 12500, Testing net (#0)
I1007 12:51:04.433485  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:51:04.512563  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7868
I1007 12:51:04.512598  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.64417 (* 1 = 0.64417 loss)
I1007 12:51:04.593510  4874 solver.cpp:218] Iteration 12500 (9.92365 iter/s, 10.0769s/100 iters), loss = 0.261171
I1007 12:51:04.593538  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.261171 (* 1 = 0.261171 loss)
I1007 12:51:04.593544  4874 sgd_solver.cpp:105] Iteration 12500, lr = 0.1
I1007 12:51:12.699414  4874 solver.cpp:218] Iteration 12600 (12.3368 iter/s, 8.10585s/100 iters), loss = 0.233726
I1007 12:51:12.699453  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.233726 (* 1 = 0.233726 loss)
I1007 12:51:12.699460  4874 sgd_solver.cpp:105] Iteration 12600, lr = 0.1
I1007 12:51:20.812475  4874 solver.cpp:218] Iteration 12700 (12.3259 iter/s, 8.113s/100 iters), loss = 0.308392
I1007 12:51:20.812516  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.308392 (* 1 = 0.308392 loss)
I1007 12:51:20.812522  4874 sgd_solver.cpp:105] Iteration 12700, lr = 0.1
I1007 12:51:28.917281  4874 solver.cpp:218] Iteration 12800 (12.3385 iter/s, 8.10474s/100 iters), loss = 0.289261
I1007 12:51:28.917399  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.289261 (* 1 = 0.289261 loss)
I1007 12:51:28.917405  4874 sgd_solver.cpp:105] Iteration 12800, lr = 0.1
I1007 12:51:37.030205  4874 solver.cpp:218] Iteration 12900 (12.3262 iter/s, 8.11279s/100 iters), loss = 0.26373
I1007 12:51:37.030234  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.26373 (* 1 = 0.26373 loss)
I1007 12:51:37.030241  4874 sgd_solver.cpp:105] Iteration 12900, lr = 0.1
I1007 12:51:44.732831  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:51:45.056527  4874 solver.cpp:330] Iteration 13000, Testing net (#0)
I1007 12:51:46.950263  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:51:47.029400  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8146
I1007 12:51:47.029436  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.568765 (* 1 = 0.568765 loss)
I1007 12:51:47.110535  4874 solver.cpp:218] Iteration 13000 (9.92037 iter/s, 10.0803s/100 iters), loss = 0.212387
I1007 12:51:47.110561  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.212387 (* 1 = 0.212387 loss)
I1007 12:51:47.110569  4874 sgd_solver.cpp:105] Iteration 13000, lr = 0.1
I1007 12:51:55.208433  4874 solver.cpp:218] Iteration 13100 (12.349 iter/s, 8.09785s/100 iters), loss = 0.216414
I1007 12:51:55.208473  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.216414 (* 1 = 0.216414 loss)
I1007 12:51:55.208479  4874 sgd_solver.cpp:105] Iteration 13100, lr = 0.1
I1007 12:52:03.304631  4874 solver.cpp:218] Iteration 13200 (12.3516 iter/s, 8.09613s/100 iters), loss = 0.277899
I1007 12:52:03.304738  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.277899 (* 1 = 0.277899 loss)
I1007 12:52:03.304744  4874 sgd_solver.cpp:105] Iteration 13200, lr = 0.1
I1007 12:52:11.403491  4874 solver.cpp:218] Iteration 13300 (12.3476 iter/s, 8.09873s/100 iters), loss = 0.205699
I1007 12:52:11.403532  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.205699 (* 1 = 0.205699 loss)
I1007 12:52:11.403538  4874 sgd_solver.cpp:105] Iteration 13300, lr = 0.1
I1007 12:52:19.499845  4874 solver.cpp:218] Iteration 13400 (12.3513 iter/s, 8.09629s/100 iters), loss = 0.244726
I1007 12:52:19.499873  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.244726 (* 1 = 0.244726 loss)
I1007 12:52:19.499879  4874 sgd_solver.cpp:105] Iteration 13400, lr = 0.1
I1007 12:52:27.196970  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:52:27.522390  4874 solver.cpp:330] Iteration 13500, Testing net (#0)
I1007 12:52:29.414150  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:52:29.493177  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7242
I1007 12:52:29.493212  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.862861 (* 1 = 0.862861 loss)
I1007 12:52:29.573632  4874 solver.cpp:218] Iteration 13500 (9.92681 iter/s, 10.0737s/100 iters), loss = 0.191907
I1007 12:52:29.573658  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.191907 (* 1 = 0.191907 loss)
I1007 12:52:29.573665  4874 sgd_solver.cpp:105] Iteration 13500, lr = 0.1
I1007 12:52:37.672510  4874 solver.cpp:218] Iteration 13600 (12.3475 iter/s, 8.09883s/100 iters), loss = 0.261436
I1007 12:52:37.672649  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.261436 (* 1 = 0.261436 loss)
I1007 12:52:37.672667  4874 sgd_solver.cpp:105] Iteration 13600, lr = 0.1
I1007 12:52:45.773542  4874 solver.cpp:218] Iteration 13700 (12.3444 iter/s, 8.10087s/100 iters), loss = 0.405287
I1007 12:52:45.773583  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.405287 (* 1 = 0.405287 loss)
I1007 12:52:45.773589  4874 sgd_solver.cpp:105] Iteration 13700, lr = 0.1
I1007 12:52:53.870210  4874 solver.cpp:218] Iteration 13800 (12.3509 iter/s, 8.0966s/100 iters), loss = 0.280256
I1007 12:52:53.870250  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.280256 (* 1 = 0.280256 loss)
I1007 12:52:53.870256  4874 sgd_solver.cpp:105] Iteration 13800, lr = 0.1
I1007 12:53:01.973274  4874 solver.cpp:218] Iteration 13900 (12.3411 iter/s, 8.103s/100 iters), loss = 0.283718
I1007 12:53:01.973304  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.283718 (* 1 = 0.283718 loss)
I1007 12:53:01.973309  4874 sgd_solver.cpp:105] Iteration 13900, lr = 0.1
I1007 12:53:09.667394  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:53:09.992645  4874 solver.cpp:330] Iteration 14000, Testing net (#0)
I1007 12:53:11.884917  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:53:11.964239  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6656
I1007 12:53:11.964274  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.10379 (* 1 = 1.10379 loss)
I1007 12:53:12.044733  4874 solver.cpp:218] Iteration 14000 (9.92911 iter/s, 10.0714s/100 iters), loss = 0.228425
I1007 12:53:12.044759  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.228425 (* 1 = 0.228425 loss)
I1007 12:53:12.044765  4874 sgd_solver.cpp:105] Iteration 14000, lr = 0.1
I1007 12:53:20.144090  4874 solver.cpp:218] Iteration 14100 (12.3467 iter/s, 8.0993s/100 iters), loss = 0.283267
I1007 12:53:20.144129  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.283267 (* 1 = 0.283267 loss)
I1007 12:53:20.144135  4874 sgd_solver.cpp:105] Iteration 14100, lr = 0.1
I1007 12:53:28.237046  4874 solver.cpp:218] Iteration 14200 (12.3565 iter/s, 8.09289s/100 iters), loss = 0.331117
I1007 12:53:28.237087  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.331117 (* 1 = 0.331117 loss)
I1007 12:53:28.237093  4874 sgd_solver.cpp:105] Iteration 14200, lr = 0.1
I1007 12:53:36.332859  4874 solver.cpp:218] Iteration 14300 (12.3522 iter/s, 8.09574s/100 iters), loss = 0.302316
I1007 12:53:36.332888  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.302316 (* 1 = 0.302316 loss)
I1007 12:53:36.332896  4874 sgd_solver.cpp:105] Iteration 14300, lr = 0.1
I1007 12:53:44.428503  4874 solver.cpp:218] Iteration 14400 (12.3524 iter/s, 8.09559s/100 iters), loss = 0.24498
I1007 12:53:44.428639  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.24498 (* 1 = 0.24498 loss)
I1007 12:53:44.428647  4874 sgd_solver.cpp:105] Iteration 14400, lr = 0.1
I1007 12:53:52.121461  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:53:52.446158  4874 solver.cpp:330] Iteration 14500, Testing net (#0)
I1007 12:53:54.338871  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:53:54.417973  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8212
I1007 12:53:54.417997  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.526507 (* 1 = 0.526507 loss)
I1007 12:53:54.499398  4874 solver.cpp:218] Iteration 14500 (9.92977 iter/s, 10.0707s/100 iters), loss = 0.218404
I1007 12:53:54.499428  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.218404 (* 1 = 0.218404 loss)
I1007 12:53:54.499433  4874 sgd_solver.cpp:105] Iteration 14500, lr = 0.1
I1007 12:54:02.596591  4874 solver.cpp:218] Iteration 14600 (12.35 iter/s, 8.09714s/100 iters), loss = 0.222247
I1007 12:54:02.596631  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.222247 (* 1 = 0.222247 loss)
I1007 12:54:02.596637  4874 sgd_solver.cpp:105] Iteration 14600, lr = 0.1
I1007 12:54:10.695603  4874 solver.cpp:218] Iteration 14700 (12.3473 iter/s, 8.09895s/100 iters), loss = 0.237729
I1007 12:54:10.695632  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.237729 (* 1 = 0.237729 loss)
I1007 12:54:10.695638  4874 sgd_solver.cpp:105] Iteration 14700, lr = 0.1
I1007 12:54:18.792085  4874 solver.cpp:218] Iteration 14800 (12.3511 iter/s, 8.09643s/100 iters), loss = 0.398478
I1007 12:54:18.792173  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.398477 (* 1 = 0.398477 loss)
I1007 12:54:18.792191  4874 sgd_solver.cpp:105] Iteration 14800, lr = 0.1
I1007 12:54:26.894840  4874 solver.cpp:218] Iteration 14900 (12.3417 iter/s, 8.10264s/100 iters), loss = 0.211701
I1007 12:54:26.894870  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.211701 (* 1 = 0.211701 loss)
I1007 12:54:26.894876  4874 sgd_solver.cpp:105] Iteration 14900, lr = 0.1
I1007 12:54:34.585563  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:54:34.909791  4874 solver.cpp:330] Iteration 15000, Testing net (#0)
I1007 12:54:36.804227  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:54:36.883119  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7553
I1007 12:54:36.883154  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.738164 (* 1 = 0.738164 loss)
I1007 12:54:36.964215  4874 solver.cpp:218] Iteration 15000 (9.93116 iter/s, 10.0693s/100 iters), loss = 0.211465
I1007 12:54:36.964241  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.211465 (* 1 = 0.211465 loss)
I1007 12:54:36.964248  4874 sgd_solver.cpp:105] Iteration 15000, lr = 0.1
I1007 12:54:45.061425  4874 solver.cpp:218] Iteration 15100 (12.35 iter/s, 8.09716s/100 iters), loss = 0.29794
I1007 12:54:45.061455  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.29794 (* 1 = 0.29794 loss)
I1007 12:54:45.061460  4874 sgd_solver.cpp:105] Iteration 15100, lr = 0.1
I1007 12:54:53.151038  4874 solver.cpp:218] Iteration 15200 (12.3616 iter/s, 8.08956s/100 iters), loss = 0.310418
I1007 12:54:53.151193  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.310418 (* 1 = 0.310418 loss)
I1007 12:54:53.151213  4874 sgd_solver.cpp:105] Iteration 15200, lr = 0.1
I1007 12:55:01.250560  4874 solver.cpp:218] Iteration 15300 (12.3467 iter/s, 8.09934s/100 iters), loss = 0.302295
I1007 12:55:01.250588  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.302295 (* 1 = 0.302295 loss)
I1007 12:55:01.250596  4874 sgd_solver.cpp:105] Iteration 15300, lr = 0.1
I1007 12:55:09.344753  4874 solver.cpp:218] Iteration 15400 (12.3546 iter/s, 8.09414s/100 iters), loss = 0.232867
I1007 12:55:09.344782  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.232867 (* 1 = 0.232867 loss)
I1007 12:55:09.344789  4874 sgd_solver.cpp:105] Iteration 15400, lr = 0.1
I1007 12:55:17.040086  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:55:17.363682  4874 solver.cpp:330] Iteration 15500, Testing net (#0)
I1007 12:55:19.256968  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:55:19.335860  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6629
I1007 12:55:19.335896  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.30671 (* 1 = 1.30671 loss)
I1007 12:55:19.416481  4874 solver.cpp:218] Iteration 15500 (9.92884 iter/s, 10.0717s/100 iters), loss = 0.17246
I1007 12:55:19.416508  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.17246 (* 1 = 0.17246 loss)
I1007 12:55:19.416515  4874 sgd_solver.cpp:105] Iteration 15500, lr = 0.1
I1007 12:55:27.515475  4874 solver.cpp:218] Iteration 15600 (12.3473 iter/s, 8.09894s/100 iters), loss = 0.248128
I1007 12:55:27.515614  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.248128 (* 1 = 0.248128 loss)
I1007 12:55:27.515620  4874 sgd_solver.cpp:105] Iteration 15600, lr = 0.1
I1007 12:55:35.620410  4874 solver.cpp:218] Iteration 15700 (12.3384 iter/s, 8.10477s/100 iters), loss = 0.402811
I1007 12:55:35.620442  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.402811 (* 1 = 0.402811 loss)
I1007 12:55:35.620448  4874 sgd_solver.cpp:105] Iteration 15700, lr = 0.1
I1007 12:55:43.721199  4874 solver.cpp:218] Iteration 15800 (12.3446 iter/s, 8.10073s/100 iters), loss = 0.286612
I1007 12:55:43.721228  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.286612 (* 1 = 0.286612 loss)
I1007 12:55:43.721235  4874 sgd_solver.cpp:105] Iteration 15800, lr = 0.1
I1007 12:55:51.826865  4874 solver.cpp:218] Iteration 15900 (12.3371 iter/s, 8.10561s/100 iters), loss = 0.222426
I1007 12:55:51.826895  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.222426 (* 1 = 0.222426 loss)
I1007 12:55:51.826911  4874 sgd_solver.cpp:105] Iteration 15900, lr = 0.1
I1007 12:55:59.522579  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:55:59.846249  4874 solver.cpp:330] Iteration 16000, Testing net (#0)
I1007 12:56:01.741195  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:56:01.820439  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7702
I1007 12:56:01.820474  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.701826 (* 1 = 0.701826 loss)
I1007 12:56:01.901193  4874 solver.cpp:218] Iteration 16000 (9.92628 iter/s, 10.0743s/100 iters), loss = 0.181489
I1007 12:56:01.901222  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.181489 (* 1 = 0.181489 loss)
I1007 12:56:01.901229  4874 sgd_solver.cpp:105] Iteration 16000, lr = 0.1
I1007 12:56:10.007375  4874 solver.cpp:218] Iteration 16100 (12.3364 iter/s, 8.10612s/100 iters), loss = 0.262079
I1007 12:56:10.007416  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.262079 (* 1 = 0.262079 loss)
I1007 12:56:10.007422  4874 sgd_solver.cpp:105] Iteration 16100, lr = 0.1
I1007 12:56:18.109526  4874 solver.cpp:218] Iteration 16200 (12.3425 iter/s, 8.10208s/100 iters), loss = 0.365996
I1007 12:56:18.109566  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.365996 (* 1 = 0.365996 loss)
I1007 12:56:18.109572  4874 sgd_solver.cpp:105] Iteration 16200, lr = 0.1
I1007 12:56:26.211530  4874 solver.cpp:218] Iteration 16300 (12.3427 iter/s, 8.10194s/100 iters), loss = 0.19685
I1007 12:56:26.211570  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.196849 (* 1 = 0.196849 loss)
I1007 12:56:26.211576  4874 sgd_solver.cpp:105] Iteration 16300, lr = 0.1
I1007 12:56:34.311945  4874 solver.cpp:218] Iteration 16400 (12.3451 iter/s, 8.10035s/100 iters), loss = 0.197235
I1007 12:56:34.312072  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.197235 (* 1 = 0.197235 loss)
I1007 12:56:34.312079  4874 sgd_solver.cpp:105] Iteration 16400, lr = 0.1
I1007 12:56:42.010802  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:56:42.335659  4874 solver.cpp:330] Iteration 16500, Testing net (#0)
I1007 12:56:44.229177  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:56:44.308157  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6159
I1007 12:56:44.308193  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.43536 (* 1 = 1.43536 loss)
I1007 12:56:44.388782  4874 solver.cpp:218] Iteration 16500 (9.92389 iter/s, 10.0767s/100 iters), loss = 0.183424
I1007 12:56:44.388811  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.183424 (* 1 = 0.183424 loss)
I1007 12:56:44.388818  4874 sgd_solver.cpp:105] Iteration 16500, lr = 0.1
I1007 12:56:52.484905  4874 solver.cpp:218] Iteration 16600 (12.3517 iter/s, 8.09607s/100 iters), loss = 0.260635
I1007 12:56:52.484946  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.260635 (* 1 = 0.260635 loss)
I1007 12:56:52.484952  4874 sgd_solver.cpp:105] Iteration 16600, lr = 0.1
I1007 12:57:00.589093  4874 solver.cpp:218] Iteration 16700 (12.3394 iter/s, 8.10412s/100 iters), loss = 0.24515
I1007 12:57:00.589134  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.24515 (* 1 = 0.24515 loss)
I1007 12:57:00.589140  4874 sgd_solver.cpp:105] Iteration 16700, lr = 0.1
I1007 12:57:08.684435  4874 solver.cpp:218] Iteration 16800 (12.3529 iter/s, 8.09527s/100 iters), loss = 0.248659
I1007 12:57:08.684542  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.248659 (* 1 = 0.248659 loss)
I1007 12:57:08.684548  4874 sgd_solver.cpp:105] Iteration 16800, lr = 0.1
I1007 12:57:16.780436  4874 solver.cpp:218] Iteration 16900 (12.352 iter/s, 8.09587s/100 iters), loss = 0.231564
I1007 12:57:16.780467  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.231564 (* 1 = 0.231564 loss)
I1007 12:57:16.780483  4874 sgd_solver.cpp:105] Iteration 16900, lr = 0.1
I1007 12:57:24.475862  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:57:24.800547  4874 solver.cpp:330] Iteration 17000, Testing net (#0)
I1007 12:57:26.694572  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:57:26.773545  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6367
I1007 12:57:26.773581  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.36045 (* 1 = 1.36045 loss)
I1007 12:57:26.854444  4874 solver.cpp:218] Iteration 17000 (9.92659 iter/s, 10.0739s/100 iters), loss = 0.233188
I1007 12:57:26.854473  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.233187 (* 1 = 0.233187 loss)
I1007 12:57:26.854480  4874 sgd_solver.cpp:105] Iteration 17000, lr = 0.1
I1007 12:57:34.952260  4874 solver.cpp:218] Iteration 17100 (12.3491 iter/s, 8.09776s/100 iters), loss = 0.322039
I1007 12:57:34.952291  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.322039 (* 1 = 0.322039 loss)
I1007 12:57:34.952297  4874 sgd_solver.cpp:105] Iteration 17100, lr = 0.1
I1007 12:57:43.044158  4874 solver.cpp:218] Iteration 17200 (12.3581 iter/s, 8.09184s/100 iters), loss = 0.231381
I1007 12:57:43.044255  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.231381 (* 1 = 0.231381 loss)
I1007 12:57:43.044262  4874 sgd_solver.cpp:105] Iteration 17200, lr = 0.1
I1007 12:57:51.140045  4874 solver.cpp:218] Iteration 17300 (12.3521 iter/s, 8.09576s/100 iters), loss = 0.290129
I1007 12:57:51.140075  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.290129 (* 1 = 0.290129 loss)
I1007 12:57:51.140081  4874 sgd_solver.cpp:105] Iteration 17300, lr = 0.1
I1007 12:57:59.233211  4874 solver.cpp:218] Iteration 17400 (12.3562 iter/s, 8.09311s/100 iters), loss = 0.236896
I1007 12:57:59.233240  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.236896 (* 1 = 0.236896 loss)
I1007 12:57:59.233247  4874 sgd_solver.cpp:105] Iteration 17400, lr = 0.1
I1007 12:58:06.934749  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:58:07.258674  4874 solver.cpp:330] Iteration 17500, Testing net (#0)
I1007 12:58:09.150296  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:58:09.229490  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7385
I1007 12:58:09.229526  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.764681 (* 1 = 0.764681 loss)
I1007 12:58:09.310518  4874 solver.cpp:218] Iteration 17500 (9.92335 iter/s, 10.0772s/100 iters), loss = 0.185947
I1007 12:58:09.310545  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.185947 (* 1 = 0.185947 loss)
I1007 12:58:09.310552  4874 sgd_solver.cpp:105] Iteration 17500, lr = 0.1
I1007 12:58:17.402773  4874 solver.cpp:218] Iteration 17600 (12.3576 iter/s, 8.0922s/100 iters), loss = 0.25999
I1007 12:58:17.402914  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.25999 (* 1 = 0.25999 loss)
I1007 12:58:17.402921  4874 sgd_solver.cpp:105] Iteration 17600, lr = 0.1
I1007 12:58:25.501425  4874 solver.cpp:218] Iteration 17700 (12.348 iter/s, 8.09849s/100 iters), loss = 0.311736
I1007 12:58:25.501466  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.311735 (* 1 = 0.311735 loss)
I1007 12:58:25.501471  4874 sgd_solver.cpp:105] Iteration 17700, lr = 0.1
I1007 12:58:33.599956  4874 solver.cpp:218] Iteration 17800 (12.348 iter/s, 8.09847s/100 iters), loss = 0.335026
I1007 12:58:33.599997  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.335026 (* 1 = 0.335026 loss)
I1007 12:58:33.600003  4874 sgd_solver.cpp:105] Iteration 17800, lr = 0.1
I1007 12:58:41.696452  4874 solver.cpp:218] Iteration 17900 (12.3511 iter/s, 8.09643s/100 iters), loss = 0.274538
I1007 12:58:41.696491  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.274538 (* 1 = 0.274538 loss)
I1007 12:58:41.696497  4874 sgd_solver.cpp:105] Iteration 17900, lr = 0.1
I1007 12:58:49.391780  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:58:49.714907  4874 solver.cpp:330] Iteration 18000, Testing net (#0)
I1007 12:58:51.606030  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:58:51.684909  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7314
I1007 12:58:51.684944  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.844318 (* 1 = 0.844318 loss)
I1007 12:58:51.766154  4874 solver.cpp:218] Iteration 18000 (9.93085 iter/s, 10.0696s/100 iters), loss = 0.269597
I1007 12:58:51.766180  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.269597 (* 1 = 0.269597 loss)
I1007 12:58:51.766186  4874 sgd_solver.cpp:105] Iteration 18000, lr = 0.1
I1007 12:58:59.859403  4874 solver.cpp:218] Iteration 18100 (12.3561 iter/s, 8.0932s/100 iters), loss = 0.21531
I1007 12:58:59.859433  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.21531 (* 1 = 0.21531 loss)
I1007 12:58:59.859439  4874 sgd_solver.cpp:105] Iteration 18100, lr = 0.1
I1007 12:59:07.952394  4874 solver.cpp:218] Iteration 18200 (12.3565 iter/s, 8.09293s/100 iters), loss = 0.316645
I1007 12:59:07.952441  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.316645 (* 1 = 0.316645 loss)
I1007 12:59:07.952448  4874 sgd_solver.cpp:105] Iteration 18200, lr = 0.1
I1007 12:59:16.045166  4874 solver.cpp:218] Iteration 18300 (12.3568 iter/s, 8.0927s/100 iters), loss = 0.167381
I1007 12:59:16.045213  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.167381 (* 1 = 0.167381 loss)
I1007 12:59:16.045220  4874 sgd_solver.cpp:105] Iteration 18300, lr = 0.1
I1007 12:59:24.136273  4874 solver.cpp:218] Iteration 18400 (12.3594 iter/s, 8.09103s/100 iters), loss = 0.317859
I1007 12:59:24.136406  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.317859 (* 1 = 0.317859 loss)
I1007 12:59:24.136415  4874 sgd_solver.cpp:105] Iteration 18400, lr = 0.1
I1007 12:59:31.826628  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:59:32.152004  4874 solver.cpp:330] Iteration 18500, Testing net (#0)
I1007 12:59:34.044167  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 12:59:34.122859  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7651
I1007 12:59:34.122894  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.723833 (* 1 = 0.723833 loss)
I1007 12:59:34.204041  4874 solver.cpp:218] Iteration 18500 (9.93285 iter/s, 10.0676s/100 iters), loss = 0.238791
I1007 12:59:34.204073  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.238791 (* 1 = 0.238791 loss)
I1007 12:59:34.204082  4874 sgd_solver.cpp:105] Iteration 18500, lr = 0.1
I1007 12:59:42.303339  4874 solver.cpp:218] Iteration 18600 (12.3468 iter/s, 8.09924s/100 iters), loss = 0.197768
I1007 12:59:42.303369  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.197768 (* 1 = 0.197768 loss)
I1007 12:59:42.303375  4874 sgd_solver.cpp:105] Iteration 18600, lr = 0.1
I1007 12:59:50.408859  4874 solver.cpp:218] Iteration 18700 (12.3374 iter/s, 8.10547s/100 iters), loss = 0.215817
I1007 12:59:50.408898  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.215816 (* 1 = 0.215816 loss)
I1007 12:59:50.408905  4874 sgd_solver.cpp:105] Iteration 18700, lr = 0.1
I1007 12:59:58.505146  4874 solver.cpp:218] Iteration 18800 (12.3514 iter/s, 8.09622s/100 iters), loss = 0.15581
I1007 12:59:58.505276  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.15581 (* 1 = 0.15581 loss)
I1007 12:59:58.505282  4874 sgd_solver.cpp:105] Iteration 18800, lr = 0.1
I1007 13:00:06.607827  4874 solver.cpp:218] Iteration 18900 (12.3418 iter/s, 8.10254s/100 iters), loss = 0.190981
I1007 13:00:06.607867  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.190981 (* 1 = 0.190981 loss)
I1007 13:00:06.607873  4874 sgd_solver.cpp:105] Iteration 18900, lr = 0.1
I1007 13:00:14.302901  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:00:14.627106  4874 solver.cpp:330] Iteration 19000, Testing net (#0)
I1007 13:00:16.518381  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:00:16.597434  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7655
I1007 13:00:16.597470  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.754287 (* 1 = 0.754287 loss)
I1007 13:00:16.678236  4874 solver.cpp:218] Iteration 19000 (9.93015 iter/s, 10.0703s/100 iters), loss = 0.178195
I1007 13:00:16.678262  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.178194 (* 1 = 0.178194 loss)
I1007 13:00:16.678269  4874 sgd_solver.cpp:105] Iteration 19000, lr = 0.1
I1007 13:00:24.781985  4874 solver.cpp:218] Iteration 19100 (12.34 iter/s, 8.1037s/100 iters), loss = 0.2244
I1007 13:00:24.782025  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.2244 (* 1 = 0.2244 loss)
I1007 13:00:24.782032  4874 sgd_solver.cpp:105] Iteration 19100, lr = 0.1
I1007 13:00:32.877269  4874 solver.cpp:218] Iteration 19200 (12.353 iter/s, 8.09522s/100 iters), loss = 0.327031
I1007 13:00:32.877355  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.32703 (* 1 = 0.32703 loss)
I1007 13:00:32.877372  4874 sgd_solver.cpp:105] Iteration 19200, lr = 0.1
I1007 13:00:40.978345  4874 solver.cpp:218] Iteration 19300 (12.3442 iter/s, 8.10096s/100 iters), loss = 0.22488
I1007 13:00:40.978385  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.22488 (* 1 = 0.22488 loss)
I1007 13:00:40.978391  4874 sgd_solver.cpp:105] Iteration 19300, lr = 0.1
I1007 13:00:49.080677  4874 solver.cpp:218] Iteration 19400 (12.3422 iter/s, 8.10226s/100 iters), loss = 0.251698
I1007 13:00:49.080716  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.251698 (* 1 = 0.251698 loss)
I1007 13:00:49.080723  4874 sgd_solver.cpp:105] Iteration 19400, lr = 0.1
I1007 13:00:56.782868  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:00:57.108381  4874 solver.cpp:330] Iteration 19500, Testing net (#0)
I1007 13:00:59.000424  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:00:59.079234  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6667
I1007 13:00:59.079268  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.11513 (* 1 = 1.11513 loss)
I1007 13:00:59.159934  4874 solver.cpp:218] Iteration 19500 (9.92144 iter/s, 10.0792s/100 iters), loss = 0.252277
I1007 13:00:59.159960  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.252277 (* 1 = 0.252277 loss)
I1007 13:00:59.159966  4874 sgd_solver.cpp:105] Iteration 19500, lr = 0.1
I1007 13:01:07.256181  4874 solver.cpp:218] Iteration 19600 (12.3515 iter/s, 8.09619s/100 iters), loss = 0.211616
I1007 13:01:07.256309  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.211615 (* 1 = 0.211615 loss)
I1007 13:01:07.256325  4874 sgd_solver.cpp:105] Iteration 19600, lr = 0.1
I1007 13:01:15.354145  4874 solver.cpp:218] Iteration 19700 (12.349 iter/s, 8.09782s/100 iters), loss = 0.274272
I1007 13:01:15.354173  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.274272 (* 1 = 0.274272 loss)
I1007 13:01:15.354179  4874 sgd_solver.cpp:105] Iteration 19700, lr = 0.1
I1007 13:01:23.449934  4874 solver.cpp:218] Iteration 19800 (12.3522 iter/s, 8.09573s/100 iters), loss = 0.185611
I1007 13:01:23.449962  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.185611 (* 1 = 0.185611 loss)
I1007 13:01:23.449980  4874 sgd_solver.cpp:105] Iteration 19800, lr = 0.1
I1007 13:01:31.549018  4874 solver.cpp:218] Iteration 19900 (12.3472 iter/s, 8.09903s/100 iters), loss = 0.180516
I1007 13:01:31.549048  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.180516 (* 1 = 0.180516 loss)
I1007 13:01:31.549054  4874 sgd_solver.cpp:105] Iteration 19900, lr = 0.1
I1007 13:01:39.245208  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:01:39.568739  4874 solver.cpp:330] Iteration 20000, Testing net (#0)
I1007 13:01:41.460278  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:01:41.539253  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7971
I1007 13:01:41.539288  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.61224 (* 1 = 0.61224 loss)
I1007 13:01:41.620059  4874 solver.cpp:218] Iteration 20000 (9.92952 iter/s, 10.071s/100 iters), loss = 0.207056
I1007 13:01:41.620085  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.207056 (* 1 = 0.207056 loss)
I1007 13:01:41.620091  4874 sgd_solver.cpp:105] Iteration 20000, lr = 0.1
I1007 13:01:49.719518  4874 solver.cpp:218] Iteration 20100 (12.3466 iter/s, 8.09941s/100 iters), loss = 0.223488
I1007 13:01:49.719559  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.223488 (* 1 = 0.223488 loss)
I1007 13:01:49.719565  4874 sgd_solver.cpp:105] Iteration 20100, lr = 0.1
I1007 13:01:57.809093  4874 solver.cpp:218] Iteration 20200 (12.3617 iter/s, 8.08951s/100 iters), loss = 0.274582
I1007 13:01:57.809132  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.274582 (* 1 = 0.274582 loss)
I1007 13:01:57.809139  4874 sgd_solver.cpp:105] Iteration 20200, lr = 0.1
I1007 13:02:05.907016  4874 solver.cpp:218] Iteration 20300 (12.3489 iter/s, 8.09786s/100 iters), loss = 0.268111
I1007 13:02:05.907045  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.268111 (* 1 = 0.268111 loss)
I1007 13:02:05.907061  4874 sgd_solver.cpp:105] Iteration 20300, lr = 0.1
I1007 13:02:14.000733  4874 solver.cpp:218] Iteration 20400 (12.3553 iter/s, 8.09366s/100 iters), loss = 0.348621
I1007 13:02:14.000833  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.348621 (* 1 = 0.348621 loss)
I1007 13:02:14.000840  4874 sgd_solver.cpp:105] Iteration 20400, lr = 0.1
I1007 13:02:21.695413  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:02:22.018940  4874 solver.cpp:330] Iteration 20500, Testing net (#0)
I1007 13:02:23.912266  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:02:23.991109  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6593
I1007 13:02:23.991145  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.37968 (* 1 = 1.37968 loss)
I1007 13:02:24.072018  4874 solver.cpp:218] Iteration 20500 (9.92934 iter/s, 10.0712s/100 iters), loss = 0.26826
I1007 13:02:24.072044  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.26826 (* 1 = 0.26826 loss)
I1007 13:02:24.072052  4874 sgd_solver.cpp:105] Iteration 20500, lr = 0.1
I1007 13:02:32.169250  4874 solver.cpp:218] Iteration 20600 (12.35 iter/s, 8.09718s/100 iters), loss = 0.157309
I1007 13:02:32.169281  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.157309 (* 1 = 0.157309 loss)
I1007 13:02:32.169287  4874 sgd_solver.cpp:105] Iteration 20600, lr = 0.1
I1007 13:02:40.265523  4874 solver.cpp:218] Iteration 20700 (12.3514 iter/s, 8.09622s/100 iters), loss = 0.315456
I1007 13:02:40.265560  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.315456 (* 1 = 0.315456 loss)
I1007 13:02:40.265568  4874 sgd_solver.cpp:105] Iteration 20700, lr = 0.1
I1007 13:02:48.360386  4874 solver.cpp:218] Iteration 20800 (12.3536 iter/s, 8.0948s/100 iters), loss = 0.242477
I1007 13:02:48.360509  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.242477 (* 1 = 0.242477 loss)
I1007 13:02:48.360517  4874 sgd_solver.cpp:105] Iteration 20800, lr = 0.1
I1007 13:02:56.458143  4874 solver.cpp:218] Iteration 20900 (12.3493 iter/s, 8.09761s/100 iters), loss = 0.227388
I1007 13:02:56.458184  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.227388 (* 1 = 0.227388 loss)
I1007 13:02:56.458189  4874 sgd_solver.cpp:105] Iteration 20900, lr = 0.1
I1007 13:03:04.152704  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:03:04.477603  4874 solver.cpp:330] Iteration 21000, Testing net (#0)
I1007 13:03:06.369303  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:03:06.448254  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7757
I1007 13:03:06.448289  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.661167 (* 1 = 0.661167 loss)
I1007 13:03:06.529438  4874 solver.cpp:218] Iteration 21000 (9.92928 iter/s, 10.0712s/100 iters), loss = 0.207719
I1007 13:03:06.529465  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.207719 (* 1 = 0.207719 loss)
I1007 13:03:06.529472  4874 sgd_solver.cpp:105] Iteration 21000, lr = 0.1
I1007 13:03:14.625679  4874 solver.cpp:218] Iteration 21100 (12.3515 iter/s, 8.09619s/100 iters), loss = 0.242218
I1007 13:03:14.625707  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.242218 (* 1 = 0.242218 loss)
I1007 13:03:14.625713  4874 sgd_solver.cpp:105] Iteration 21100, lr = 0.1
I1007 13:03:22.717128  4874 solver.cpp:218] Iteration 21200 (12.3588 iter/s, 8.09139s/100 iters), loss = 0.248069
I1007 13:03:22.717247  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.248069 (* 1 = 0.248069 loss)
I1007 13:03:22.717253  4874 sgd_solver.cpp:105] Iteration 21200, lr = 0.1
I1007 13:03:30.818336  4874 solver.cpp:218] Iteration 21300 (12.3441 iter/s, 8.10107s/100 iters), loss = 0.220959
I1007 13:03:30.818375  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.220959 (* 1 = 0.220959 loss)
I1007 13:03:30.818382  4874 sgd_solver.cpp:105] Iteration 21300, lr = 0.1
I1007 13:03:38.914857  4874 solver.cpp:218] Iteration 21400 (12.3511 iter/s, 8.09645s/100 iters), loss = 0.251405
I1007 13:03:38.914887  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.251405 (* 1 = 0.251405 loss)
I1007 13:03:38.914893  4874 sgd_solver.cpp:105] Iteration 21400, lr = 0.1
I1007 13:03:46.613538  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:03:46.936899  4874 solver.cpp:330] Iteration 21500, Testing net (#0)
I1007 13:03:48.829201  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:03:48.908465  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7791
I1007 13:03:48.908500  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.69893 (* 1 = 0.69893 loss)
I1007 13:03:48.989187  4874 solver.cpp:218] Iteration 21500 (9.92628 iter/s, 10.0743s/100 iters), loss = 0.280661
I1007 13:03:48.989212  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.280662 (* 1 = 0.280662 loss)
I1007 13:03:48.989218  4874 sgd_solver.cpp:105] Iteration 21500, lr = 0.1
I1007 13:03:57.089743  4874 solver.cpp:218] Iteration 21600 (12.3449 iter/s, 8.10051s/100 iters), loss = 0.210597
I1007 13:03:57.089877  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.210597 (* 1 = 0.210597 loss)
I1007 13:03:57.089884  4874 sgd_solver.cpp:105] Iteration 21600, lr = 0.1
I1007 13:04:05.193528  4874 solver.cpp:218] Iteration 21700 (12.3402 iter/s, 8.10363s/100 iters), loss = 0.28259
I1007 13:04:05.193558  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.28259 (* 1 = 0.28259 loss)
I1007 13:04:05.193564  4874 sgd_solver.cpp:105] Iteration 21700, lr = 0.1
I1007 13:04:13.295405  4874 solver.cpp:218] Iteration 21800 (12.3429 iter/s, 8.10182s/100 iters), loss = 0.135772
I1007 13:04:13.295435  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.135772 (* 1 = 0.135772 loss)
I1007 13:04:13.295452  4874 sgd_solver.cpp:105] Iteration 21800, lr = 0.1
I1007 13:04:21.398306  4874 solver.cpp:218] Iteration 21900 (12.3413 iter/s, 8.10284s/100 iters), loss = 0.209944
I1007 13:04:21.398336  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.209944 (* 1 = 0.209944 loss)
I1007 13:04:21.398342  4874 sgd_solver.cpp:105] Iteration 21900, lr = 0.1
I1007 13:04:29.093147  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:04:29.416918  4874 solver.cpp:330] Iteration 22000, Testing net (#0)
I1007 13:04:31.309145  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:04:31.387490  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7687
I1007 13:04:31.387516  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.78579 (* 1 = 0.78579 loss)
I1007 13:04:31.468760  4874 solver.cpp:218] Iteration 22000 (9.9301 iter/s, 10.0704s/100 iters), loss = 0.282364
I1007 13:04:31.468785  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.282365 (* 1 = 0.282365 loss)
I1007 13:04:31.468791  4874 sgd_solver.cpp:105] Iteration 22000, lr = 0.1
I1007 13:04:39.577853  4874 solver.cpp:218] Iteration 22100 (12.3319 iter/s, 8.10904s/100 iters), loss = 0.23431
I1007 13:04:39.577883  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.23431 (* 1 = 0.23431 loss)
I1007 13:04:39.577889  4874 sgd_solver.cpp:105] Iteration 22100, lr = 0.1
I1007 13:04:47.680763  4874 solver.cpp:218] Iteration 22200 (12.3413 iter/s, 8.10285s/100 iters), loss = 0.192301
I1007 13:04:47.680793  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.192301 (* 1 = 0.192301 loss)
I1007 13:04:47.680809  4874 sgd_solver.cpp:105] Iteration 22200, lr = 0.1
I1007 13:04:55.784044  4874 solver.cpp:218] Iteration 22300 (12.3408 iter/s, 8.10323s/100 iters), loss = 0.255819
I1007 13:04:55.784073  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.255819 (* 1 = 0.255819 loss)
I1007 13:04:55.784090  4874 sgd_solver.cpp:105] Iteration 22300, lr = 0.1
I1007 13:05:03.886518  4874 solver.cpp:218] Iteration 22400 (12.342 iter/s, 8.10241s/100 iters), loss = 0.129673
I1007 13:05:03.886637  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.129673 (* 1 = 0.129673 loss)
I1007 13:05:03.886653  4874 sgd_solver.cpp:105] Iteration 22400, lr = 0.1
I1007 13:05:11.589540  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:05:11.914034  4874 solver.cpp:330] Iteration 22500, Testing net (#0)
I1007 13:05:13.808454  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:05:13.887655  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7566
I1007 13:05:13.887689  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.775441 (* 1 = 0.775441 loss)
I1007 13:05:13.968518  4874 solver.cpp:218] Iteration 22500 (9.9188 iter/s, 10.0819s/100 iters), loss = 0.223131
I1007 13:05:13.968542  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.223131 (* 1 = 0.223131 loss)
I1007 13:05:13.968549  4874 sgd_solver.cpp:105] Iteration 22500, lr = 0.1
I1007 13:05:22.066623  4874 solver.cpp:218] Iteration 22600 (12.3486 iter/s, 8.09805s/100 iters), loss = 0.239758
I1007 13:05:22.066653  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.239758 (* 1 = 0.239758 loss)
I1007 13:05:22.066668  4874 sgd_solver.cpp:105] Iteration 22600, lr = 0.1
I1007 13:05:30.170763  4874 solver.cpp:218] Iteration 22700 (12.3395 iter/s, 8.10408s/100 iters), loss = 0.272757
I1007 13:05:30.170802  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.272757 (* 1 = 0.272757 loss)
I1007 13:05:30.170809  4874 sgd_solver.cpp:105] Iteration 22700, lr = 0.1
I1007 13:05:38.268653  4874 solver.cpp:218] Iteration 22800 (12.349 iter/s, 8.09783s/100 iters), loss = 0.31063
I1007 13:05:38.268811  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.31063 (* 1 = 0.31063 loss)
I1007 13:05:38.268831  4874 sgd_solver.cpp:105] Iteration 22800, lr = 0.1
I1007 13:05:46.372400  4874 solver.cpp:218] Iteration 22900 (12.3403 iter/s, 8.10356s/100 iters), loss = 0.153007
I1007 13:05:46.372440  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.153007 (* 1 = 0.153007 loss)
I1007 13:05:46.372447  4874 sgd_solver.cpp:105] Iteration 22900, lr = 0.1
I1007 13:05:54.073595  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:05:54.398183  4874 solver.cpp:330] Iteration 23000, Testing net (#0)
I1007 13:05:56.290297  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:05:56.369534  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7433
I1007 13:05:56.369568  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.851303 (* 1 = 0.851303 loss)
I1007 13:05:56.450729  4874 solver.cpp:218] Iteration 23000 (9.92235 iter/s, 10.0783s/100 iters), loss = 0.154175
I1007 13:05:56.450755  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.154175 (* 1 = 0.154175 loss)
I1007 13:05:56.450762  4874 sgd_solver.cpp:105] Iteration 23000, lr = 0.1
I1007 13:06:04.562018  4874 solver.cpp:218] Iteration 23100 (12.3286 iter/s, 8.11124s/100 iters), loss = 0.237569
I1007 13:06:04.562058  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.237569 (* 1 = 0.237569 loss)
I1007 13:06:04.562064  4874 sgd_solver.cpp:105] Iteration 23100, lr = 0.1
I1007 13:06:12.659257  4874 solver.cpp:218] Iteration 23200 (12.35 iter/s, 8.09717s/100 iters), loss = 0.294346
I1007 13:06:12.659376  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.294346 (* 1 = 0.294346 loss)
I1007 13:06:12.659394  4874 sgd_solver.cpp:105] Iteration 23200, lr = 0.1
I1007 13:06:20.762048  4874 solver.cpp:218] Iteration 23300 (12.3416 iter/s, 8.10265s/100 iters), loss = 0.239919
I1007 13:06:20.762087  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.239919 (* 1 = 0.239919 loss)
I1007 13:06:20.762094  4874 sgd_solver.cpp:105] Iteration 23300, lr = 0.1
I1007 13:06:28.861621  4874 solver.cpp:218] Iteration 23400 (12.3464 iter/s, 8.09951s/100 iters), loss = 0.238863
I1007 13:06:28.861661  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.238863 (* 1 = 0.238863 loss)
I1007 13:06:28.861667  4874 sgd_solver.cpp:105] Iteration 23400, lr = 0.1
I1007 13:06:36.560178  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:06:36.884737  4874 solver.cpp:330] Iteration 23500, Testing net (#0)
I1007 13:06:38.778441  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:06:38.857003  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7742
I1007 13:06:38.857038  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.680886 (* 1 = 0.680886 loss)
I1007 13:06:38.937947  4874 solver.cpp:218] Iteration 23500 (9.92432 iter/s, 10.0763s/100 iters), loss = 0.245519
I1007 13:06:38.937973  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.245519 (* 1 = 0.245519 loss)
I1007 13:06:38.937979  4874 sgd_solver.cpp:105] Iteration 23500, lr = 0.1
I1007 13:06:47.032063  4874 solver.cpp:218] Iteration 23600 (12.3547 iter/s, 8.09407s/100 iters), loss = 0.139466
I1007 13:06:47.032218  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.139466 (* 1 = 0.139466 loss)
I1007 13:06:47.032225  4874 sgd_solver.cpp:105] Iteration 23600, lr = 0.1
I1007 13:06:55.137961  4874 solver.cpp:218] Iteration 23700 (12.337 iter/s, 8.10573s/100 iters), loss = 0.19161
I1007 13:06:55.137991  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.19161 (* 1 = 0.19161 loss)
I1007 13:06:55.137997  4874 sgd_solver.cpp:105] Iteration 23700, lr = 0.1
I1007 13:07:03.238778  4874 solver.cpp:218] Iteration 23800 (12.3445 iter/s, 8.10076s/100 iters), loss = 0.169004
I1007 13:07:03.238826  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.169004 (* 1 = 0.169004 loss)
I1007 13:07:03.238833  4874 sgd_solver.cpp:105] Iteration 23800, lr = 0.1
I1007 13:07:11.345237  4874 solver.cpp:218] Iteration 23900 (12.336 iter/s, 8.10639s/100 iters), loss = 0.258321
I1007 13:07:11.345275  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.258321 (* 1 = 0.258321 loss)
I1007 13:07:11.345281  4874 sgd_solver.cpp:105] Iteration 23900, lr = 0.1
I1007 13:07:19.045639  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:07:19.369889  4874 solver.cpp:330] Iteration 24000, Testing net (#0)
I1007 13:07:21.262317  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:07:21.341063  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7496
I1007 13:07:21.341099  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.828159 (* 1 = 0.828159 loss)
I1007 13:07:21.422005  4874 solver.cpp:218] Iteration 24000 (9.92388 iter/s, 10.0767s/100 iters), loss = 0.180051
I1007 13:07:21.422030  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.180051 (* 1 = 0.180051 loss)
I1007 13:07:21.422037  4874 sgd_solver.cpp:105] Iteration 24000, lr = 0.1
I1007 13:07:29.529784  4874 solver.cpp:218] Iteration 24100 (12.3339 iter/s, 8.10773s/100 iters), loss = 0.231598
I1007 13:07:29.529825  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.231598 (* 1 = 0.231598 loss)
I1007 13:07:29.529831  4874 sgd_solver.cpp:105] Iteration 24100, lr = 0.1
I1007 13:07:37.628389  4874 solver.cpp:218] Iteration 24200 (12.3479 iter/s, 8.09854s/100 iters), loss = 0.402324
I1007 13:07:37.628420  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.402324 (* 1 = 0.402324 loss)
I1007 13:07:37.628427  4874 sgd_solver.cpp:105] Iteration 24200, lr = 0.1
I1007 13:07:45.735669  4874 solver.cpp:218] Iteration 24300 (12.3347 iter/s, 8.10722s/100 iters), loss = 0.160096
I1007 13:07:45.735710  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.160096 (* 1 = 0.160096 loss)
I1007 13:07:45.735716  4874 sgd_solver.cpp:105] Iteration 24300, lr = 0.1
I1007 13:07:53.834332  4874 solver.cpp:218] Iteration 24400 (12.3478 iter/s, 8.09859s/100 iters), loss = 0.167144
I1007 13:07:53.834408  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.167144 (* 1 = 0.167144 loss)
I1007 13:07:53.834414  4874 sgd_solver.cpp:105] Iteration 24400, lr = 0.1
I1007 13:08:01.534099  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:08:01.858990  4874 solver.cpp:330] Iteration 24500, Testing net (#0)
I1007 13:08:03.752884  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:08:03.832018  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8177
I1007 13:08:03.832053  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.542032 (* 1 = 0.542032 loss)
I1007 13:08:03.912732  4874 solver.cpp:218] Iteration 24500 (9.92231 iter/s, 10.0783s/100 iters), loss = 0.236631
I1007 13:08:03.912760  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.236631 (* 1 = 0.236631 loss)
I1007 13:08:03.912767  4874 sgd_solver.cpp:105] Iteration 24500, lr = 0.1
I1007 13:08:12.012236  4874 solver.cpp:218] Iteration 24600 (12.3465 iter/s, 8.09945s/100 iters), loss = 0.182765
I1007 13:08:12.012275  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.182765 (* 1 = 0.182765 loss)
I1007 13:08:12.012282  4874 sgd_solver.cpp:105] Iteration 24600, lr = 0.1
I1007 13:08:20.112124  4874 solver.cpp:218] Iteration 24700 (12.3459 iter/s, 8.09982s/100 iters), loss = 0.292732
I1007 13:08:20.112164  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.292732 (* 1 = 0.292732 loss)
I1007 13:08:20.112170  4874 sgd_solver.cpp:105] Iteration 24700, lr = 0.1
I1007 13:08:28.209390  4874 solver.cpp:218] Iteration 24800 (12.3499 iter/s, 8.0972s/100 iters), loss = 0.232833
I1007 13:08:28.209517  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.232833 (* 1 = 0.232833 loss)
I1007 13:08:28.209535  4874 sgd_solver.cpp:105] Iteration 24800, lr = 0.1
I1007 13:08:36.310199  4874 solver.cpp:218] Iteration 24900 (12.3447 iter/s, 8.10067s/100 iters), loss = 0.171893
I1007 13:08:36.310240  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.171893 (* 1 = 0.171893 loss)
I1007 13:08:36.310246  4874 sgd_solver.cpp:105] Iteration 24900, lr = 0.1
I1007 13:08:44.010123  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:08:44.334429  4874 solver.cpp:330] Iteration 25000, Testing net (#0)
I1007 13:08:46.227219  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:08:46.306190  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7712
I1007 13:08:46.306216  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.727749 (* 1 = 0.727749 loss)
I1007 13:08:46.386931  4874 solver.cpp:218] Iteration 25000 (9.92392 iter/s, 10.0767s/100 iters), loss = 0.215723
I1007 13:08:46.386956  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.215723 (* 1 = 0.215723 loss)
I1007 13:08:46.386963  4874 sgd_solver.cpp:105] Iteration 25000, lr = 0.1
I1007 13:08:54.493815  4874 solver.cpp:218] Iteration 25100 (12.3353 iter/s, 8.10683s/100 iters), loss = 0.272211
I1007 13:08:54.493845  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.272211 (* 1 = 0.272211 loss)
I1007 13:08:54.493861  4874 sgd_solver.cpp:105] Iteration 25100, lr = 0.1
I1007 13:09:02.592211  4874 solver.cpp:218] Iteration 25200 (12.3482 iter/s, 8.09834s/100 iters), loss = 0.233362
I1007 13:09:02.592296  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.233362 (* 1 = 0.233362 loss)
I1007 13:09:02.592303  4874 sgd_solver.cpp:105] Iteration 25200, lr = 0.1
I1007 13:09:10.698484  4874 solver.cpp:218] Iteration 25300 (12.3363 iter/s, 8.10617s/100 iters), loss = 0.338015
I1007 13:09:10.698514  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.338015 (* 1 = 0.338015 loss)
I1007 13:09:10.698530  4874 sgd_solver.cpp:105] Iteration 25300, lr = 0.1
I1007 13:09:18.800796  4874 solver.cpp:218] Iteration 25400 (12.3422 iter/s, 8.10225s/100 iters), loss = 0.30354
I1007 13:09:18.800825  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.30354 (* 1 = 0.30354 loss)
I1007 13:09:18.800832  4874 sgd_solver.cpp:105] Iteration 25400, lr = 0.1
I1007 13:09:26.502877  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:09:26.828382  4874 solver.cpp:330] Iteration 25500, Testing net (#0)
I1007 13:09:28.722605  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:09:28.801846  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8158
I1007 13:09:28.801880  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.590382 (* 1 = 0.590382 loss)
I1007 13:09:28.882836  4874 solver.cpp:218] Iteration 25500 (9.91868 iter/s, 10.082s/100 iters), loss = 0.247792
I1007 13:09:28.882863  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.247793 (* 1 = 0.247793 loss)
I1007 13:09:28.882869  4874 sgd_solver.cpp:105] Iteration 25500, lr = 0.1
I1007 13:09:36.984871  4874 solver.cpp:218] Iteration 25600 (12.3427 iter/s, 8.10198s/100 iters), loss = 0.158313
I1007 13:09:36.984956  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.158313 (* 1 = 0.158313 loss)
I1007 13:09:36.984972  4874 sgd_solver.cpp:105] Iteration 25600, lr = 0.1
I1007 13:09:45.094660  4874 solver.cpp:218] Iteration 25700 (12.3309 iter/s, 8.10969s/100 iters), loss = 0.305729
I1007 13:09:45.094691  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.305729 (* 1 = 0.305729 loss)
I1007 13:09:45.094707  4874 sgd_solver.cpp:105] Iteration 25700, lr = 0.1
I1007 13:09:53.193781  4874 solver.cpp:218] Iteration 25800 (12.3471 iter/s, 8.09907s/100 iters), loss = 0.217325
I1007 13:09:53.193811  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.217325 (* 1 = 0.217325 loss)
I1007 13:09:53.193817  4874 sgd_solver.cpp:105] Iteration 25800, lr = 0.1
I1007 13:10:01.303557  4874 solver.cpp:218] Iteration 25900 (12.3309 iter/s, 8.10972s/100 iters), loss = 0.265128
I1007 13:10:01.303588  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.265128 (* 1 = 0.265128 loss)
I1007 13:10:01.303604  4874 sgd_solver.cpp:105] Iteration 25900, lr = 0.1
I1007 13:10:09.004685  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:10:09.329615  4874 solver.cpp:330] Iteration 26000, Testing net (#0)
I1007 13:10:11.221084  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:10:11.299726  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7131
I1007 13:10:11.299762  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.905646 (* 1 = 0.905646 loss)
I1007 13:10:11.380197  4874 solver.cpp:218] Iteration 26000 (9.924 iter/s, 10.0766s/100 iters), loss = 0.153178
I1007 13:10:11.380223  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.153178 (* 1 = 0.153178 loss)
I1007 13:10:11.380229  4874 sgd_solver.cpp:105] Iteration 26000, lr = 0.1
I1007 13:10:19.482945  4874 solver.cpp:218] Iteration 26100 (12.3416 iter/s, 8.10269s/100 iters), loss = 0.136102
I1007 13:10:19.482975  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.136102 (* 1 = 0.136102 loss)
I1007 13:10:19.482980  4874 sgd_solver.cpp:105] Iteration 26100, lr = 0.1
I1007 13:10:27.578524  4874 solver.cpp:218] Iteration 26200 (12.3525 iter/s, 8.09552s/100 iters), loss = 0.186129
I1007 13:10:27.578564  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.186129 (* 1 = 0.186129 loss)
I1007 13:10:27.578570  4874 sgd_solver.cpp:105] Iteration 26200, lr = 0.1
I1007 13:10:35.676075  4874 solver.cpp:218] Iteration 26300 (12.3495 iter/s, 8.09749s/100 iters), loss = 0.181748
I1007 13:10:35.676105  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.181748 (* 1 = 0.181748 loss)
I1007 13:10:35.676110  4874 sgd_solver.cpp:105] Iteration 26300, lr = 0.1
I1007 13:10:43.770936  4874 solver.cpp:218] Iteration 26400 (12.3536 iter/s, 8.0948s/100 iters), loss = 0.135004
I1007 13:10:43.771075  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.135004 (* 1 = 0.135004 loss)
I1007 13:10:43.771081  4874 sgd_solver.cpp:105] Iteration 26400, lr = 0.1
I1007 13:10:51.463971  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:10:51.787595  4874 solver.cpp:330] Iteration 26500, Testing net (#0)
I1007 13:10:53.680899  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:10:53.759949  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7369
I1007 13:10:53.759985  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.805181 (* 1 = 0.805181 loss)
I1007 13:10:53.840493  4874 solver.cpp:218] Iteration 26500 (9.93109 iter/s, 10.0694s/100 iters), loss = 0.184737
I1007 13:10:53.840522  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.184737 (* 1 = 0.184737 loss)
I1007 13:10:53.840528  4874 sgd_solver.cpp:105] Iteration 26500, lr = 0.1
I1007 13:11:01.935001  4874 solver.cpp:218] Iteration 26600 (12.3541 iter/s, 8.09445s/100 iters), loss = 0.161381
I1007 13:11:01.935041  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.161381 (* 1 = 0.161381 loss)
I1007 13:11:01.935047  4874 sgd_solver.cpp:105] Iteration 26600, lr = 0.1
I1007 13:11:10.041066  4874 solver.cpp:218] Iteration 26700 (12.3365 iter/s, 8.106s/100 iters), loss = 0.310618
I1007 13:11:10.041105  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.310618 (* 1 = 0.310618 loss)
I1007 13:11:10.041111  4874 sgd_solver.cpp:105] Iteration 26700, lr = 0.1
I1007 13:11:18.138994  4874 solver.cpp:218] Iteration 26800 (12.3489 iter/s, 8.09787s/100 iters), loss = 0.193938
I1007 13:11:18.139135  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.193938 (* 1 = 0.193938 loss)
I1007 13:11:18.139153  4874 sgd_solver.cpp:105] Iteration 26800, lr = 0.1
I1007 13:11:26.239156  4874 solver.cpp:218] Iteration 26900 (12.3457 iter/s, 8.1s/100 iters), loss = 0.133032
I1007 13:11:26.239188  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.133032 (* 1 = 0.133032 loss)
I1007 13:11:26.239195  4874 sgd_solver.cpp:105] Iteration 26900, lr = 0.1
I1007 13:11:33.933861  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:11:34.258247  4874 solver.cpp:330] Iteration 27000, Testing net (#0)
I1007 13:11:36.150454  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:11:36.229670  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7849
I1007 13:11:36.229694  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.656989 (* 1 = 0.656989 loss)
I1007 13:11:36.310608  4874 solver.cpp:218] Iteration 27000 (9.92912 iter/s, 10.0714s/100 iters), loss = 0.271384
I1007 13:11:36.310636  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.271384 (* 1 = 0.271384 loss)
I1007 13:11:36.310642  4874 sgd_solver.cpp:105] Iteration 27000, lr = 0.1
I1007 13:11:44.406112  4874 solver.cpp:218] Iteration 27100 (12.3526 iter/s, 8.09545s/100 iters), loss = 0.148395
I1007 13:11:44.406152  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.148395 (* 1 = 0.148395 loss)
I1007 13:11:44.406158  4874 sgd_solver.cpp:105] Iteration 27100, lr = 0.1
I1007 13:11:52.494359  4874 solver.cpp:218] Iteration 27200 (12.3637 iter/s, 8.08818s/100 iters), loss = 0.288126
I1007 13:11:52.494508  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.288126 (* 1 = 0.288126 loss)
I1007 13:11:52.494516  4874 sgd_solver.cpp:105] Iteration 27200, lr = 0.1
I1007 13:12:00.592572  4874 solver.cpp:218] Iteration 27300 (12.3487 iter/s, 8.09804s/100 iters), loss = 0.223452
I1007 13:12:00.592613  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.223452 (* 1 = 0.223452 loss)
I1007 13:12:00.592619  4874 sgd_solver.cpp:105] Iteration 27300, lr = 0.1
I1007 13:12:08.686278  4874 solver.cpp:218] Iteration 27400 (12.3554 iter/s, 8.09364s/100 iters), loss = 0.218891
I1007 13:12:08.686308  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.218891 (* 1 = 0.218891 loss)
I1007 13:12:08.686314  4874 sgd_solver.cpp:105] Iteration 27400, lr = 0.1
I1007 13:12:16.377004  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:12:16.700477  4874 solver.cpp:330] Iteration 27500, Testing net (#0)
I1007 13:12:18.593714  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:12:18.672510  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7744
I1007 13:12:18.672544  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.724821 (* 1 = 0.724821 loss)
I1007 13:12:18.753293  4874 solver.cpp:218] Iteration 27500 (9.93349 iter/s, 10.067s/100 iters), loss = 0.202782
I1007 13:12:18.753325  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.202782 (* 1 = 0.202782 loss)
I1007 13:12:18.753332  4874 sgd_solver.cpp:105] Iteration 27500, lr = 0.1
I1007 13:12:26.849885  4874 solver.cpp:218] Iteration 27600 (12.351 iter/s, 8.09654s/100 iters), loss = 0.188952
I1007 13:12:26.850021  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.188952 (* 1 = 0.188952 loss)
I1007 13:12:26.850028  4874 sgd_solver.cpp:105] Iteration 27600, lr = 0.1
I1007 13:12:34.952571  4874 solver.cpp:218] Iteration 27700 (12.3418 iter/s, 8.10253s/100 iters), loss = 0.28455
I1007 13:12:34.952612  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.28455 (* 1 = 0.28455 loss)
I1007 13:12:34.952618  4874 sgd_solver.cpp:105] Iteration 27700, lr = 0.1
I1007 13:12:43.058778  4874 solver.cpp:218] Iteration 27800 (12.3363 iter/s, 8.10614s/100 iters), loss = 0.182404
I1007 13:12:43.058821  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.182404 (* 1 = 0.182404 loss)
I1007 13:12:43.058840  4874 sgd_solver.cpp:105] Iteration 27800, lr = 0.1
I1007 13:12:51.159159  4874 solver.cpp:218] Iteration 27900 (12.3453 iter/s, 8.10023s/100 iters), loss = 0.263476
I1007 13:12:51.159199  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.263476 (* 1 = 0.263476 loss)
I1007 13:12:51.159205  4874 sgd_solver.cpp:105] Iteration 27900, lr = 0.1
I1007 13:12:58.849968  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:12:59.173512  4874 solver.cpp:330] Iteration 28000, Testing net (#0)
I1007 13:13:01.065450  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:13:01.144215  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7872
I1007 13:13:01.144240  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.633131 (* 1 = 0.633131 loss)
I1007 13:13:01.224913  4874 solver.cpp:218] Iteration 28000 (9.93474 iter/s, 10.0657s/100 iters), loss = 0.289806
I1007 13:13:01.224944  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.289806 (* 1 = 0.289806 loss)
I1007 13:13:01.224951  4874 sgd_solver.cpp:105] Iteration 28000, lr = 0.1
I1007 13:13:09.330054  4874 solver.cpp:218] Iteration 28100 (12.3379 iter/s, 8.10509s/100 iters), loss = 0.170078
I1007 13:13:09.330094  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.170078 (* 1 = 0.170078 loss)
I1007 13:13:09.330101  4874 sgd_solver.cpp:105] Iteration 28100, lr = 0.1
I1007 13:13:17.423959  4874 solver.cpp:218] Iteration 28200 (12.3551 iter/s, 8.09384s/100 iters), loss = 0.15877
I1007 13:13:17.423990  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.15877 (* 1 = 0.15877 loss)
I1007 13:13:17.424005  4874 sgd_solver.cpp:105] Iteration 28200, lr = 0.1
I1007 13:13:25.527448  4874 solver.cpp:218] Iteration 28300 (12.3404 iter/s, 8.10344s/100 iters), loss = 0.250228
I1007 13:13:25.527479  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.250228 (* 1 = 0.250228 loss)
I1007 13:13:25.527485  4874 sgd_solver.cpp:105] Iteration 28300, lr = 0.1
I1007 13:13:33.631947  4874 solver.cpp:218] Iteration 28400 (12.3389 iter/s, 8.10444s/100 iters), loss = 0.183634
I1007 13:13:33.632051  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.183634 (* 1 = 0.183634 loss)
I1007 13:13:33.632068  4874 sgd_solver.cpp:105] Iteration 28400, lr = 0.1
I1007 13:13:41.333976  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:13:41.658614  4874 solver.cpp:330] Iteration 28500, Testing net (#0)
I1007 13:13:43.552209  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:13:43.631418  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8014
I1007 13:13:43.631444  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.570314 (* 1 = 0.570314 loss)
I1007 13:13:43.711994  4874 solver.cpp:218] Iteration 28500 (9.92072 iter/s, 10.0799s/100 iters), loss = 0.170596
I1007 13:13:43.712023  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.170596 (* 1 = 0.170596 loss)
I1007 13:13:43.712031  4874 sgd_solver.cpp:105] Iteration 28500, lr = 0.1
I1007 13:13:51.816782  4874 solver.cpp:218] Iteration 28600 (12.3385 iter/s, 8.10473s/100 iters), loss = 0.178877
I1007 13:13:51.816824  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.178877 (* 1 = 0.178877 loss)
I1007 13:13:51.816830  4874 sgd_solver.cpp:105] Iteration 28600, lr = 0.1
I1007 13:13:59.925160  4874 solver.cpp:218] Iteration 28700 (12.333 iter/s, 8.10831s/100 iters), loss = 0.215734
I1007 13:13:59.925201  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.215734 (* 1 = 0.215734 loss)
I1007 13:13:59.925207  4874 sgd_solver.cpp:105] Iteration 28700, lr = 0.1
I1007 13:14:08.029602  4874 solver.cpp:218] Iteration 28800 (12.339 iter/s, 8.10437s/100 iters), loss = 0.152816
I1007 13:14:08.029706  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.152816 (* 1 = 0.152816 loss)
I1007 13:14:08.029723  4874 sgd_solver.cpp:105] Iteration 28800, lr = 0.1
I1007 13:14:16.141341  4874 solver.cpp:218] Iteration 28900 (12.328 iter/s, 8.11161s/100 iters), loss = 0.158789
I1007 13:14:16.141381  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.158789 (* 1 = 0.158789 loss)
I1007 13:14:16.141386  4874 sgd_solver.cpp:105] Iteration 28900, lr = 0.1
I1007 13:14:23.845458  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:14:24.170874  4874 solver.cpp:330] Iteration 29000, Testing net (#0)
I1007 13:14:26.062779  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:14:26.141540  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7628
I1007 13:14:26.141564  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.76589 (* 1 = 0.76589 loss)
I1007 13:14:26.222620  4874 solver.cpp:218] Iteration 29000 (9.91944 iter/s, 10.0812s/100 iters), loss = 0.198156
I1007 13:14:26.222652  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.198156 (* 1 = 0.198156 loss)
I1007 13:14:26.222659  4874 sgd_solver.cpp:105] Iteration 29000, lr = 0.1
I1007 13:14:34.325456  4874 solver.cpp:218] Iteration 29100 (12.3414 iter/s, 8.10278s/100 iters), loss = 0.183576
I1007 13:14:34.325496  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.183575 (* 1 = 0.183575 loss)
I1007 13:14:34.325503  4874 sgd_solver.cpp:105] Iteration 29100, lr = 0.1
I1007 13:14:42.422915  4874 solver.cpp:218] Iteration 29200 (12.3497 iter/s, 8.09739s/100 iters), loss = 0.277739
I1007 13:14:42.423058  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.277739 (* 1 = 0.277739 loss)
I1007 13:14:42.423066  4874 sgd_solver.cpp:105] Iteration 29200, lr = 0.1
I1007 13:14:50.528578  4874 solver.cpp:218] Iteration 29300 (12.3373 iter/s, 8.1055s/100 iters), loss = 0.278409
I1007 13:14:50.528617  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.278409 (* 1 = 0.278409 loss)
I1007 13:14:50.528623  4874 sgd_solver.cpp:105] Iteration 29300, lr = 0.1
I1007 13:14:58.622421  4874 solver.cpp:218] Iteration 29400 (12.3552 iter/s, 8.09378s/100 iters), loss = 0.181436
I1007 13:14:58.622459  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.181436 (* 1 = 0.181436 loss)
I1007 13:14:58.622465  4874 sgd_solver.cpp:105] Iteration 29400, lr = 0.1
I1007 13:15:06.318981  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:15:06.643597  4874 solver.cpp:330] Iteration 29500, Testing net (#0)
I1007 13:15:08.536897  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:15:08.615996  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6908
I1007 13:15:08.616032  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.07689 (* 1 = 1.07689 loss)
I1007 13:15:08.696797  4874 solver.cpp:218] Iteration 29500 (9.92624 iter/s, 10.0743s/100 iters), loss = 0.20707
I1007 13:15:08.696825  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.20707 (* 1 = 0.20707 loss)
I1007 13:15:08.696832  4874 sgd_solver.cpp:105] Iteration 29500, lr = 0.1
I1007 13:15:16.794801  4874 solver.cpp:218] Iteration 29600 (12.3488 iter/s, 8.09795s/100 iters), loss = 0.213922
I1007 13:15:16.794898  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.213921 (* 1 = 0.213921 loss)
I1007 13:15:16.794905  4874 sgd_solver.cpp:105] Iteration 29600, lr = 0.1
I1007 13:15:24.896989  4874 solver.cpp:218] Iteration 29700 (12.3425 iter/s, 8.10207s/100 iters), loss = 0.19188
I1007 13:15:24.897018  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.19188 (* 1 = 0.19188 loss)
I1007 13:15:24.897024  4874 sgd_solver.cpp:105] Iteration 29700, lr = 0.1
I1007 13:15:32.994917  4874 solver.cpp:218] Iteration 29800 (12.3489 iter/s, 8.09787s/100 iters), loss = 0.201977
I1007 13:15:32.994947  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.201977 (* 1 = 0.201977 loss)
I1007 13:15:32.994953  4874 sgd_solver.cpp:105] Iteration 29800, lr = 0.1
I1007 13:15:41.101418  4874 solver.cpp:218] Iteration 29900 (12.3359 iter/s, 8.10645s/100 iters), loss = 0.160517
I1007 13:15:41.101457  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.160517 (* 1 = 0.160517 loss)
I1007 13:15:41.101464  4874 sgd_solver.cpp:105] Iteration 29900, lr = 0.1
I1007 13:15:48.798928  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:15:49.121611  4874 solver.cpp:330] Iteration 30000, Testing net (#0)
I1007 13:15:51.012298  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:15:51.091300  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7372
I1007 13:15:51.091334  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.864523 (* 1 = 0.864523 loss)
I1007 13:15:51.171999  4874 solver.cpp:218] Iteration 30000 (9.92998 iter/s, 10.0705s/100 iters), loss = 0.149273
I1007 13:15:51.172025  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.149273 (* 1 = 0.149273 loss)
I1007 13:15:51.172031  4874 sgd_solver.cpp:105] Iteration 30000, lr = 0.1
I1007 13:15:59.272595  4874 solver.cpp:218] Iteration 30100 (12.3448 iter/s, 8.10055s/100 iters), loss = 0.129676
I1007 13:15:59.272636  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.129676 (* 1 = 0.129676 loss)
I1007 13:15:59.272642  4874 sgd_solver.cpp:105] Iteration 30100, lr = 0.1
I1007 13:16:07.363768  4874 solver.cpp:218] Iteration 30200 (12.3592 iter/s, 8.09111s/100 iters), loss = 0.288612
I1007 13:16:07.363797  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.288611 (* 1 = 0.288611 loss)
I1007 13:16:07.363803  4874 sgd_solver.cpp:105] Iteration 30200, lr = 0.1
I1007 13:16:15.460481  4874 solver.cpp:218] Iteration 30300 (12.3508 iter/s, 8.09666s/100 iters), loss = 0.201465
I1007 13:16:15.460521  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.201465 (* 1 = 0.201465 loss)
I1007 13:16:15.460527  4874 sgd_solver.cpp:105] Iteration 30300, lr = 0.1
I1007 13:16:23.549314  4874 solver.cpp:218] Iteration 30400 (12.3628 iter/s, 8.08877s/100 iters), loss = 0.134843
I1007 13:16:23.549434  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.134843 (* 1 = 0.134843 loss)
I1007 13:16:23.549451  4874 sgd_solver.cpp:105] Iteration 30400, lr = 0.1
I1007 13:16:31.238947  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:16:31.563257  4874 solver.cpp:330] Iteration 30500, Testing net (#0)
I1007 13:16:33.455004  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:16:33.534075  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8046
I1007 13:16:33.534109  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.608481 (* 1 = 0.608481 loss)
I1007 13:16:33.615003  4874 solver.cpp:218] Iteration 30500 (9.93489 iter/s, 10.0655s/100 iters), loss = 0.134821
I1007 13:16:33.615031  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.13482 (* 1 = 0.13482 loss)
I1007 13:16:33.615037  4874 sgd_solver.cpp:105] Iteration 30500, lr = 0.1
I1007 13:16:41.710516  4874 solver.cpp:218] Iteration 30600 (12.3526 iter/s, 8.09546s/100 iters), loss = 0.216638
I1007 13:16:41.710556  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.216638 (* 1 = 0.216638 loss)
I1007 13:16:41.710562  4874 sgd_solver.cpp:105] Iteration 30600, lr = 0.1
I1007 13:16:49.813355  4874 solver.cpp:218] Iteration 30700 (12.3415 iter/s, 8.10277s/100 iters), loss = 0.298658
I1007 13:16:49.813395  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.298657 (* 1 = 0.298657 loss)
I1007 13:16:49.813400  4874 sgd_solver.cpp:105] Iteration 30700, lr = 0.1
I1007 13:16:57.909188  4874 solver.cpp:218] Iteration 30800 (12.3521 iter/s, 8.09577s/100 iters), loss = 0.206485
I1007 13:16:57.909349  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.206485 (* 1 = 0.206485 loss)
I1007 13:16:57.909359  4874 sgd_solver.cpp:105] Iteration 30800, lr = 0.1
I1007 13:17:06.014680  4874 solver.cpp:218] Iteration 30900 (12.3376 iter/s, 8.10531s/100 iters), loss = 0.161563
I1007 13:17:06.014711  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.161563 (* 1 = 0.161563 loss)
I1007 13:17:06.014716  4874 sgd_solver.cpp:105] Iteration 30900, lr = 0.1
I1007 13:17:13.710234  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:17:14.034304  4874 solver.cpp:330] Iteration 31000, Testing net (#0)
I1007 13:17:15.926012  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:17:16.005028  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7597
I1007 13:17:16.005062  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.853584 (* 1 = 0.853584 loss)
I1007 13:17:16.086016  4874 solver.cpp:218] Iteration 31000 (9.92923 iter/s, 10.0713s/100 iters), loss = 0.292954
I1007 13:17:16.086043  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.292954 (* 1 = 0.292954 loss)
I1007 13:17:16.086050  4874 sgd_solver.cpp:105] Iteration 31000, lr = 0.1
I1007 13:17:24.195808  4874 solver.cpp:218] Iteration 31100 (12.3309 iter/s, 8.10974s/100 iters), loss = 0.16577
I1007 13:17:24.195848  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.165769 (* 1 = 0.165769 loss)
I1007 13:17:24.195854  4874 sgd_solver.cpp:105] Iteration 31100, lr = 0.1
I1007 13:17:32.297202  4874 solver.cpp:218] Iteration 31200 (12.3437 iter/s, 8.10133s/100 iters), loss = 0.277003
I1007 13:17:32.297340  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.277003 (* 1 = 0.277003 loss)
I1007 13:17:32.297351  4874 sgd_solver.cpp:105] Iteration 31200, lr = 0.1
I1007 13:17:40.406879  4874 solver.cpp:218] Iteration 31300 (12.3312 iter/s, 8.10952s/100 iters), loss = 0.178685
I1007 13:17:40.406920  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.178685 (* 1 = 0.178685 loss)
I1007 13:17:40.406926  4874 sgd_solver.cpp:105] Iteration 31300, lr = 0.1
I1007 13:17:48.506240  4874 solver.cpp:218] Iteration 31400 (12.3468 iter/s, 8.09929s/100 iters), loss = 0.140137
I1007 13:17:48.506281  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.140137 (* 1 = 0.140137 loss)
I1007 13:17:48.506287  4874 sgd_solver.cpp:105] Iteration 31400, lr = 0.1
I1007 13:17:56.213361  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:17:56.538094  4874 solver.cpp:330] Iteration 31500, Testing net (#0)
I1007 13:17:58.428938  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:17:58.508033  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8279
I1007 13:17:58.508066  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.533363 (* 1 = 0.533363 loss)
I1007 13:17:58.592442  4874 solver.cpp:218] Iteration 31500 (9.9146 iter/s, 10.0861s/100 iters), loss = 0.193085
I1007 13:17:58.592473  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.193085 (* 1 = 0.193085 loss)
I1007 13:17:58.592480  4874 sgd_solver.cpp:105] Iteration 31500, lr = 0.1
I1007 13:18:06.695533  4874 solver.cpp:218] Iteration 31600 (12.3411 iter/s, 8.10303s/100 iters), loss = 0.182496
I1007 13:18:06.695618  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.182496 (* 1 = 0.182496 loss)
I1007 13:18:06.695626  4874 sgd_solver.cpp:105] Iteration 31600, lr = 0.1
I1007 13:18:14.804878  4874 solver.cpp:218] Iteration 31700 (12.3316 iter/s, 8.10925s/100 iters), loss = 0.228635
I1007 13:18:14.804919  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.228635 (* 1 = 0.228635 loss)
I1007 13:18:14.804924  4874 sgd_solver.cpp:105] Iteration 31700, lr = 0.1
I1007 13:18:22.908691  4874 solver.cpp:218] Iteration 31800 (12.34 iter/s, 8.10375s/100 iters), loss = 0.138181
I1007 13:18:22.908731  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.138181 (* 1 = 0.138181 loss)
I1007 13:18:22.908737  4874 sgd_solver.cpp:105] Iteration 31800, lr = 0.1
I1007 13:18:31.017652  4874 solver.cpp:218] Iteration 31900 (12.3321 iter/s, 8.1089s/100 iters), loss = 0.144972
I1007 13:18:31.017693  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.144972 (* 1 = 0.144972 loss)
I1007 13:18:31.017699  4874 sgd_solver.cpp:105] Iteration 31900, lr = 0.1
I1007 13:18:38.714257  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:18:39.039333  4874 solver.cpp:330] Iteration 32000, Testing net (#0)
I1007 13:18:40.929337  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:18:41.008167  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8006
I1007 13:18:41.008200  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.625853 (* 1 = 0.625853 loss)
I1007 13:18:41.088918  4874 solver.cpp:218] Iteration 32000 (9.92931 iter/s, 10.0712s/100 iters), loss = 0.196693
I1007 13:18:41.088944  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.196692 (* 1 = 0.196692 loss)
I1007 13:18:41.088951  4874 sgd_solver.cpp:105] Iteration 32000, lr = 0.1
I1007 13:18:49.189402  4874 solver.cpp:218] Iteration 32100 (12.345 iter/s, 8.10043s/100 iters), loss = 0.129573
I1007 13:18:49.189441  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.129573 (* 1 = 0.129573 loss)
I1007 13:18:49.189447  4874 sgd_solver.cpp:105] Iteration 32100, lr = 0.1
I1007 13:18:57.278808  4874 solver.cpp:218] Iteration 32200 (12.3619 iter/s, 8.08934s/100 iters), loss = 0.165122
I1007 13:18:57.278838  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.165122 (* 1 = 0.165122 loss)
I1007 13:18:57.278844  4874 sgd_solver.cpp:105] Iteration 32200, lr = 0.1
I1007 13:19:05.381330  4874 solver.cpp:218] Iteration 32300 (12.3419 iter/s, 8.10247s/100 iters), loss = 0.20725
I1007 13:19:05.381359  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.20725 (* 1 = 0.20725 loss)
I1007 13:19:05.381366  4874 sgd_solver.cpp:105] Iteration 32300, lr = 0.1
I1007 13:19:13.475325  4874 solver.cpp:218] Iteration 32400 (12.3549 iter/s, 8.09394s/100 iters), loss = 0.157944
I1007 13:19:13.475432  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.157944 (* 1 = 0.157944 loss)
I1007 13:19:13.475450  4874 sgd_solver.cpp:105] Iteration 32400, lr = 0.1
I1007 13:19:21.173085  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:19:21.497436  4874 solver.cpp:330] Iteration 32500, Testing net (#0)
I1007 13:19:23.387480  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:19:23.466662  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7532
I1007 13:19:23.466696  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.836019 (* 1 = 0.836019 loss)
I1007 13:19:23.547817  4874 solver.cpp:218] Iteration 32500 (9.92816 iter/s, 10.0724s/100 iters), loss = 0.186374
I1007 13:19:23.547842  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.186373 (* 1 = 0.186373 loss)
I1007 13:19:23.547849  4874 sgd_solver.cpp:105] Iteration 32500, lr = 0.1
I1007 13:19:31.647315  4874 solver.cpp:218] Iteration 32600 (12.3465 iter/s, 8.09945s/100 iters), loss = 0.139124
I1007 13:19:31.647353  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.139124 (* 1 = 0.139124 loss)
I1007 13:19:31.647359  4874 sgd_solver.cpp:105] Iteration 32600, lr = 0.1
I1007 13:19:39.753708  4874 solver.cpp:218] Iteration 32700 (12.336 iter/s, 8.10633s/100 iters), loss = 0.23908
I1007 13:19:39.753748  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.23908 (* 1 = 0.23908 loss)
I1007 13:19:39.753754  4874 sgd_solver.cpp:105] Iteration 32700, lr = 0.1
I1007 13:19:47.853065  4874 solver.cpp:218] Iteration 32800 (12.3468 iter/s, 8.09929s/100 iters), loss = 0.198579
I1007 13:19:47.853162  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.198579 (* 1 = 0.198579 loss)
I1007 13:19:47.853168  4874 sgd_solver.cpp:105] Iteration 32800, lr = 0.1
I1007 13:19:55.956029  4874 solver.cpp:218] Iteration 32900 (12.3413 iter/s, 8.10284s/100 iters), loss = 0.264844
I1007 13:19:55.956058  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.264844 (* 1 = 0.264844 loss)
I1007 13:19:55.956064  4874 sgd_solver.cpp:105] Iteration 32900, lr = 0.1
I1007 13:20:03.648309  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:20:03.975122  4874 solver.cpp:330] Iteration 33000, Testing net (#0)
I1007 13:20:05.866960  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:20:05.945989  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.773
I1007 13:20:05.946024  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.733234 (* 1 = 0.733234 loss)
I1007 13:20:06.027370  4874 solver.cpp:218] Iteration 33000 (9.92922 iter/s, 10.0713s/100 iters), loss = 0.246001
I1007 13:20:06.027398  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.246001 (* 1 = 0.246001 loss)
I1007 13:20:06.027405  4874 sgd_solver.cpp:105] Iteration 33000, lr = 0.1
I1007 13:20:14.123477  4874 solver.cpp:218] Iteration 33100 (12.3517 iter/s, 8.09605s/100 iters), loss = 0.187549
I1007 13:20:14.123507  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.187549 (* 1 = 0.187549 loss)
I1007 13:20:14.123513  4874 sgd_solver.cpp:105] Iteration 33100, lr = 0.1
I1007 13:20:22.206099  4874 solver.cpp:218] Iteration 33200 (12.3723 iter/s, 8.08257s/100 iters), loss = 0.272736
I1007 13:20:22.206246  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.272736 (* 1 = 0.272736 loss)
I1007 13:20:22.206254  4874 sgd_solver.cpp:105] Iteration 33200, lr = 0.1
I1007 13:20:30.302173  4874 solver.cpp:218] Iteration 33300 (12.3519 iter/s, 8.09591s/100 iters), loss = 0.155173
I1007 13:20:30.302209  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.155173 (* 1 = 0.155173 loss)
I1007 13:20:30.302217  4874 sgd_solver.cpp:105] Iteration 33300, lr = 0.1
I1007 13:20:38.389525  4874 solver.cpp:218] Iteration 33400 (12.3651 iter/s, 8.08729s/100 iters), loss = 0.194937
I1007 13:20:38.389555  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.194937 (* 1 = 0.194937 loss)
I1007 13:20:38.389561  4874 sgd_solver.cpp:105] Iteration 33400, lr = 0.1
I1007 13:20:46.087251  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:20:46.412320  4874 solver.cpp:330] Iteration 33500, Testing net (#0)
I1007 13:20:48.304085  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:20:48.382864  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8237
I1007 13:20:48.382900  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.524861 (* 1 = 0.524861 loss)
I1007 13:20:48.463743  4874 solver.cpp:218] Iteration 33500 (9.92639 iter/s, 10.0742s/100 iters), loss = 0.125706
I1007 13:20:48.463769  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.125706 (* 1 = 0.125706 loss)
I1007 13:20:48.463775  4874 sgd_solver.cpp:105] Iteration 33500, lr = 0.1
I1007 13:20:56.560082  4874 solver.cpp:218] Iteration 33600 (12.3513 iter/s, 8.09629s/100 iters), loss = 0.215973
I1007 13:20:56.560207  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.215973 (* 1 = 0.215973 loss)
I1007 13:20:56.560225  4874 sgd_solver.cpp:105] Iteration 33600, lr = 0.1
I1007 13:21:04.666239  4874 solver.cpp:218] Iteration 33700 (12.3365 iter/s, 8.10601s/100 iters), loss = 0.236808
I1007 13:21:04.666278  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.236808 (* 1 = 0.236808 loss)
I1007 13:21:04.666285  4874 sgd_solver.cpp:105] Iteration 33700, lr = 0.1
I1007 13:21:12.766396  4874 solver.cpp:218] Iteration 33800 (12.3455 iter/s, 8.10009s/100 iters), loss = 0.231866
I1007 13:21:12.766424  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.231866 (* 1 = 0.231866 loss)
I1007 13:21:12.766429  4874 sgd_solver.cpp:105] Iteration 33800, lr = 0.1
I1007 13:21:20.866659  4874 solver.cpp:218] Iteration 33900 (12.3454 iter/s, 8.10021s/100 iters), loss = 0.274759
I1007 13:21:20.866688  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.274759 (* 1 = 0.274759 loss)
I1007 13:21:20.866694  4874 sgd_solver.cpp:105] Iteration 33900, lr = 0.1
I1007 13:21:28.560001  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:21:28.885583  4874 solver.cpp:330] Iteration 34000, Testing net (#0)
I1007 13:21:30.776293  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:21:30.855741  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7378
I1007 13:21:30.855774  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.870564 (* 1 = 0.870564 loss)
I1007 13:21:30.936702  4874 solver.cpp:218] Iteration 34000 (9.9305 iter/s, 10.07s/100 iters), loss = 0.108774
I1007 13:21:30.936730  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.108774 (* 1 = 0.108774 loss)
I1007 13:21:30.936738  4874 sgd_solver.cpp:105] Iteration 34000, lr = 0.1
I1007 13:21:39.047019  4874 solver.cpp:218] Iteration 34100 (12.3301 iter/s, 8.11026s/100 iters), loss = 0.169674
I1007 13:21:39.047060  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.169674 (* 1 = 0.169674 loss)
I1007 13:21:39.047065  4874 sgd_solver.cpp:105] Iteration 34100, lr = 0.1
I1007 13:21:47.147828  4874 solver.cpp:218] Iteration 34200 (12.3445 iter/s, 8.10074s/100 iters), loss = 0.244502
I1007 13:21:47.147868  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.244502 (* 1 = 0.244502 loss)
I1007 13:21:47.147874  4874 sgd_solver.cpp:105] Iteration 34200, lr = 0.1
I1007 13:21:55.258816  4874 solver.cpp:218] Iteration 34300 (12.3291 iter/s, 8.11092s/100 iters), loss = 0.178513
I1007 13:21:55.258857  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.178513 (* 1 = 0.178513 loss)
I1007 13:21:55.258863  4874 sgd_solver.cpp:105] Iteration 34300, lr = 0.1
I1007 13:22:03.360433  4874 solver.cpp:218] Iteration 34400 (12.3433 iter/s, 8.10155s/100 iters), loss = 0.255785
I1007 13:22:03.360555  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.255785 (* 1 = 0.255785 loss)
I1007 13:22:03.360574  4874 sgd_solver.cpp:105] Iteration 34400, lr = 0.1
I1007 13:22:11.060573  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:22:11.385568  4874 solver.cpp:330] Iteration 34500, Testing net (#0)
I1007 13:22:13.277478  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:22:13.356564  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7907
I1007 13:22:13.356598  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.680182 (* 1 = 0.680182 loss)
I1007 13:22:13.437315  4874 solver.cpp:218] Iteration 34500 (9.92385 iter/s, 10.0767s/100 iters), loss = 0.204389
I1007 13:22:13.437341  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.204389 (* 1 = 0.204389 loss)
I1007 13:22:13.437348  4874 sgd_solver.cpp:105] Iteration 34500, lr = 0.1
I1007 13:22:21.539404  4874 solver.cpp:218] Iteration 34600 (12.3426 iter/s, 8.10203s/100 iters), loss = 0.215626
I1007 13:22:21.539444  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.215626 (* 1 = 0.215626 loss)
I1007 13:22:21.539450  4874 sgd_solver.cpp:105] Iteration 34600, lr = 0.1
I1007 13:22:29.646986  4874 solver.cpp:218] Iteration 34700 (12.3342 iter/s, 8.10752s/100 iters), loss = 0.174988
I1007 13:22:29.647017  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.174988 (* 1 = 0.174988 loss)
I1007 13:22:29.647022  4874 sgd_solver.cpp:105] Iteration 34700, lr = 0.1
I1007 13:22:37.747211  4874 solver.cpp:218] Iteration 34800 (12.3454 iter/s, 8.10017s/100 iters), loss = 0.275081
I1007 13:22:37.747346  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.275081 (* 1 = 0.275081 loss)
I1007 13:22:37.747354  4874 sgd_solver.cpp:105] Iteration 34800, lr = 0.1
I1007 13:22:45.858966  4874 solver.cpp:218] Iteration 34900 (12.328 iter/s, 8.1116s/100 iters), loss = 0.148812
I1007 13:22:45.858996  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.148812 (* 1 = 0.148812 loss)
I1007 13:22:45.859002  4874 sgd_solver.cpp:105] Iteration 34900, lr = 0.1
I1007 13:22:53.556846  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:22:53.880885  4874 solver.cpp:330] Iteration 35000, Testing net (#0)
I1007 13:22:55.772922  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:22:55.851624  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7479
I1007 13:22:55.851657  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.85736 (* 1 = 0.85736 loss)
I1007 13:22:55.932144  4874 solver.cpp:218] Iteration 35000 (9.92741 iter/s, 10.0731s/100 iters), loss = 0.185875
I1007 13:22:55.932171  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.185875 (* 1 = 0.185875 loss)
I1007 13:22:55.932178  4874 sgd_solver.cpp:105] Iteration 35000, lr = 0.1
I1007 13:23:04.027900  4874 solver.cpp:218] Iteration 35100 (12.3522 iter/s, 8.0957s/100 iters), loss = 0.10877
I1007 13:23:04.027931  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.10877 (* 1 = 0.10877 loss)
I1007 13:23:04.027938  4874 sgd_solver.cpp:105] Iteration 35100, lr = 0.1
I1007 13:23:12.120419  4874 solver.cpp:218] Iteration 35200 (12.3572 iter/s, 8.09242s/100 iters), loss = 0.233172
I1007 13:23:12.120504  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.233172 (* 1 = 0.233172 loss)
I1007 13:23:12.120520  4874 sgd_solver.cpp:105] Iteration 35200, lr = 0.1
I1007 13:23:20.217528  4874 solver.cpp:218] Iteration 35300 (12.3503 iter/s, 8.097s/100 iters), loss = 0.208554
I1007 13:23:20.217567  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.208554 (* 1 = 0.208554 loss)
I1007 13:23:20.217574  4874 sgd_solver.cpp:105] Iteration 35300, lr = 0.1
I1007 13:23:28.311852  4874 solver.cpp:218] Iteration 35400 (12.3544 iter/s, 8.09426s/100 iters), loss = 0.195724
I1007 13:23:28.311882  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.195724 (* 1 = 0.195724 loss)
I1007 13:23:28.311887  4874 sgd_solver.cpp:105] Iteration 35400, lr = 0.1
I1007 13:23:36.006924  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:23:36.330905  4874 solver.cpp:330] Iteration 35500, Testing net (#0)
I1007 13:23:38.223701  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:23:38.302414  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7749
I1007 13:23:38.302449  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.794821 (* 1 = 0.794821 loss)
I1007 13:23:38.383777  4874 solver.cpp:218] Iteration 35500 (9.92865 iter/s, 10.0719s/100 iters), loss = 0.160736
I1007 13:23:38.383805  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.160736 (* 1 = 0.160736 loss)
I1007 13:23:38.383811  4874 sgd_solver.cpp:105] Iteration 35500, lr = 0.1
I1007 13:23:46.486528  4874 solver.cpp:218] Iteration 35600 (12.3416 iter/s, 8.1027s/100 iters), loss = 0.198472
I1007 13:23:46.486636  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.198472 (* 1 = 0.198472 loss)
I1007 13:23:46.486644  4874 sgd_solver.cpp:105] Iteration 35600, lr = 0.1
I1007 13:23:54.588654  4874 solver.cpp:218] Iteration 35700 (12.3426 iter/s, 8.10199s/100 iters), loss = 0.268335
I1007 13:23:54.588693  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.268335 (* 1 = 0.268335 loss)
I1007 13:23:54.588699  4874 sgd_solver.cpp:105] Iteration 35700, lr = 0.1
I1007 13:24:02.690307  4874 solver.cpp:218] Iteration 35800 (12.3433 iter/s, 8.10159s/100 iters), loss = 0.220511
I1007 13:24:02.690347  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.220511 (* 1 = 0.220511 loss)
I1007 13:24:02.690353  4874 sgd_solver.cpp:105] Iteration 35800, lr = 0.1
I1007 13:24:10.794512  4874 solver.cpp:218] Iteration 35900 (12.3394 iter/s, 8.10414s/100 iters), loss = 0.2494
I1007 13:24:10.794543  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.2494 (* 1 = 0.2494 loss)
I1007 13:24:10.794548  4874 sgd_solver.cpp:105] Iteration 35900, lr = 0.1
I1007 13:24:18.497728  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:24:18.822649  4874 solver.cpp:330] Iteration 36000, Testing net (#0)
I1007 13:24:20.717528  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:24:20.796329  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7276
I1007 13:24:20.796353  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.952187 (* 1 = 0.952187 loss)
I1007 13:24:20.877046  4874 solver.cpp:218] Iteration 36000 (9.9182 iter/s, 10.0825s/100 iters), loss = 0.129194
I1007 13:24:20.877074  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.129194 (* 1 = 0.129194 loss)
I1007 13:24:20.877080  4874 sgd_solver.cpp:105] Iteration 36000, lr = 0.1
I1007 13:24:28.973642  4874 solver.cpp:218] Iteration 36100 (12.351 iter/s, 8.09654s/100 iters), loss = 0.16287
I1007 13:24:28.973673  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.16287 (* 1 = 0.16287 loss)
I1007 13:24:28.973680  4874 sgd_solver.cpp:105] Iteration 36100, lr = 0.1
I1007 13:24:37.065960  4874 solver.cpp:218] Iteration 36200 (12.3575 iter/s, 8.09226s/100 iters), loss = 0.37056
I1007 13:24:37.065999  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.37056 (* 1 = 0.37056 loss)
I1007 13:24:37.066005  4874 sgd_solver.cpp:105] Iteration 36200, lr = 0.1
I1007 13:24:45.159973  4874 solver.cpp:218] Iteration 36300 (12.3549 iter/s, 8.09395s/100 iters), loss = 0.167891
I1007 13:24:45.160003  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.167891 (* 1 = 0.167891 loss)
I1007 13:24:45.160009  4874 sgd_solver.cpp:105] Iteration 36300, lr = 0.1
I1007 13:24:53.247123  4874 solver.cpp:218] Iteration 36400 (12.3654 iter/s, 8.08709s/100 iters), loss = 0.148929
I1007 13:24:53.247263  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.148929 (* 1 = 0.148929 loss)
I1007 13:24:53.247282  4874 sgd_solver.cpp:105] Iteration 36400, lr = 0.1
I1007 13:25:00.940975  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:25:01.265166  4874 solver.cpp:330] Iteration 36500, Testing net (#0)
I1007 13:25:03.155319  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:25:03.234405  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8263
I1007 13:25:03.234441  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.512471 (* 1 = 0.512471 loss)
I1007 13:25:03.315214  4874 solver.cpp:218] Iteration 36500 (9.93254 iter/s, 10.0679s/100 iters), loss = 0.166843
I1007 13:25:03.315243  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.166843 (* 1 = 0.166843 loss)
I1007 13:25:03.315250  4874 sgd_solver.cpp:105] Iteration 36500, lr = 0.1
I1007 13:25:11.414680  4874 solver.cpp:218] Iteration 36600 (12.3466 iter/s, 8.09941s/100 iters), loss = 0.166453
I1007 13:25:11.414710  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.166453 (* 1 = 0.166453 loss)
I1007 13:25:11.414716  4874 sgd_solver.cpp:105] Iteration 36600, lr = 0.1
I1007 13:25:19.515544  4874 solver.cpp:218] Iteration 36700 (12.3444 iter/s, 8.10081s/100 iters), loss = 0.211953
I1007 13:25:19.515584  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.211953 (* 1 = 0.211953 loss)
I1007 13:25:19.515590  4874 sgd_solver.cpp:105] Iteration 36700, lr = 0.1
I1007 13:25:27.613008  4874 solver.cpp:218] Iteration 36800 (12.3496 iter/s, 8.0974s/100 iters), loss = 0.144481
I1007 13:25:27.613131  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.144481 (* 1 = 0.144481 loss)
I1007 13:25:27.613149  4874 sgd_solver.cpp:105] Iteration 36800, lr = 0.1
I1007 13:25:35.710912  4874 solver.cpp:218] Iteration 36900 (12.3491 iter/s, 8.09777s/100 iters), loss = 0.145933
I1007 13:25:35.710942  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.145933 (* 1 = 0.145933 loss)
I1007 13:25:35.710948  4874 sgd_solver.cpp:105] Iteration 36900, lr = 0.1
I1007 13:25:43.406754  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:25:43.730190  4874 solver.cpp:330] Iteration 37000, Testing net (#0)
I1007 13:25:45.623049  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:25:45.702190  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7445
I1007 13:25:45.702224  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.809168 (* 1 = 0.809168 loss)
I1007 13:25:45.782770  4874 solver.cpp:218] Iteration 37000 (9.92871 iter/s, 10.0718s/100 iters), loss = 0.34223
I1007 13:25:45.782795  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.34223 (* 1 = 0.34223 loss)
I1007 13:25:45.782802  4874 sgd_solver.cpp:105] Iteration 37000, lr = 0.1
I1007 13:25:53.889827  4874 solver.cpp:218] Iteration 37100 (12.335 iter/s, 8.10701s/100 iters), loss = 0.209642
I1007 13:25:53.889868  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.209642 (* 1 = 0.209642 loss)
I1007 13:25:53.889873  4874 sgd_solver.cpp:105] Iteration 37100, lr = 0.1
I1007 13:26:01.991366  4874 solver.cpp:218] Iteration 37200 (12.3434 iter/s, 8.10147s/100 iters), loss = 0.268215
I1007 13:26:01.991489  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.268215 (* 1 = 0.268215 loss)
I1007 13:26:01.991497  4874 sgd_solver.cpp:105] Iteration 37200, lr = 0.1
I1007 13:26:10.101933  4874 solver.cpp:218] Iteration 37300 (12.3298 iter/s, 8.11042s/100 iters), loss = 0.202576
I1007 13:26:10.101972  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.202576 (* 1 = 0.202576 loss)
I1007 13:26:10.101979  4874 sgd_solver.cpp:105] Iteration 37300, lr = 0.1
I1007 13:26:18.206923  4874 solver.cpp:218] Iteration 37400 (12.3382 iter/s, 8.10493s/100 iters), loss = 0.274351
I1007 13:26:18.206964  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.274351 (* 1 = 0.274351 loss)
I1007 13:26:18.206970  4874 sgd_solver.cpp:105] Iteration 37400, lr = 0.1
I1007 13:26:25.914347  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:26:26.239202  4874 solver.cpp:330] Iteration 37500, Testing net (#0)
I1007 13:26:28.130908  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:26:28.209864  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7657
I1007 13:26:28.209899  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.741879 (* 1 = 0.741879 loss)
I1007 13:26:28.290365  4874 solver.cpp:218] Iteration 37500 (9.91732 iter/s, 10.0834s/100 iters), loss = 0.181823
I1007 13:26:28.290397  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.181823 (* 1 = 0.181823 loss)
I1007 13:26:28.290405  4874 sgd_solver.cpp:105] Iteration 37500, lr = 0.1
I1007 13:26:36.393945  4874 solver.cpp:218] Iteration 37600 (12.3403 iter/s, 8.10352s/100 iters), loss = 0.143276
I1007 13:26:36.394058  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.143276 (* 1 = 0.143276 loss)
I1007 13:26:36.394075  4874 sgd_solver.cpp:105] Iteration 37600, lr = 0.1
I1007 13:26:44.499810  4874 solver.cpp:218] Iteration 37700 (12.337 iter/s, 8.10573s/100 iters), loss = 0.248566
I1007 13:26:44.499850  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.248566 (* 1 = 0.248566 loss)
I1007 13:26:44.499856  4874 sgd_solver.cpp:105] Iteration 37700, lr = 0.1
I1007 13:26:52.603951  4874 solver.cpp:218] Iteration 37800 (12.3395 iter/s, 8.10408s/100 iters), loss = 0.173546
I1007 13:26:52.603992  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.173546 (* 1 = 0.173546 loss)
I1007 13:26:52.603998  4874 sgd_solver.cpp:105] Iteration 37800, lr = 0.1
I1007 13:27:00.710532  4874 solver.cpp:218] Iteration 37900 (12.3358 iter/s, 8.10651s/100 iters), loss = 0.269383
I1007 13:27:00.710574  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.269383 (* 1 = 0.269383 loss)
I1007 13:27:00.710580  4874 sgd_solver.cpp:105] Iteration 37900, lr = 0.1
I1007 13:27:08.409865  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:27:08.734436  4874 solver.cpp:330] Iteration 38000, Testing net (#0)
I1007 13:27:10.627039  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:27:10.706151  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7904
I1007 13:27:10.706185  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.723876 (* 1 = 0.723876 loss)
I1007 13:27:10.787271  4874 solver.cpp:218] Iteration 38000 (9.92392 iter/s, 10.0767s/100 iters), loss = 0.284738
I1007 13:27:10.787298  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.284738 (* 1 = 0.284738 loss)
I1007 13:27:10.787305  4874 sgd_solver.cpp:105] Iteration 38000, lr = 0.1
I1007 13:27:18.887607  4874 solver.cpp:218] Iteration 38100 (12.3453 iter/s, 8.10028s/100 iters), loss = 0.174375
I1007 13:27:18.887636  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.174375 (* 1 = 0.174375 loss)
I1007 13:27:18.887642  4874 sgd_solver.cpp:105] Iteration 38100, lr = 0.1
I1007 13:27:26.982137  4874 solver.cpp:218] Iteration 38200 (12.3541 iter/s, 8.09447s/100 iters), loss = 0.235378
I1007 13:27:26.982177  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.235378 (* 1 = 0.235378 loss)
I1007 13:27:26.982182  4874 sgd_solver.cpp:105] Iteration 38200, lr = 0.1
I1007 13:27:35.082439  4874 solver.cpp:218] Iteration 38300 (12.3453 iter/s, 8.10024s/100 iters), loss = 0.31863
I1007 13:27:35.082479  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.31863 (* 1 = 0.31863 loss)
I1007 13:27:35.082485  4874 sgd_solver.cpp:105] Iteration 38300, lr = 0.1
I1007 13:27:43.176610  4874 solver.cpp:218] Iteration 38400 (12.3547 iter/s, 8.0941s/100 iters), loss = 0.218475
I1007 13:27:43.176762  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.218475 (* 1 = 0.218475 loss)
I1007 13:27:43.176769  4874 sgd_solver.cpp:105] Iteration 38400, lr = 0.1
I1007 13:27:50.872946  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:27:51.197577  4874 solver.cpp:330] Iteration 38500, Testing net (#0)
I1007 13:27:53.088441  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:27:53.167522  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7617
I1007 13:27:53.167557  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.882976 (* 1 = 0.882976 loss)
I1007 13:27:53.248271  4874 solver.cpp:218] Iteration 38500 (9.92902 iter/s, 10.0715s/100 iters), loss = 0.160541
I1007 13:27:53.248303  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.160541 (* 1 = 0.160541 loss)
I1007 13:27:53.248311  4874 sgd_solver.cpp:105] Iteration 38500, lr = 0.1
I1007 13:28:01.347446  4874 solver.cpp:218] Iteration 38600 (12.347 iter/s, 8.09912s/100 iters), loss = 0.286138
I1007 13:28:01.347487  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.286138 (* 1 = 0.286138 loss)
I1007 13:28:01.347493  4874 sgd_solver.cpp:105] Iteration 38600, lr = 0.1
I1007 13:28:09.449235  4874 solver.cpp:218] Iteration 38700 (12.3431 iter/s, 8.10172s/100 iters), loss = 0.273785
I1007 13:28:09.449275  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.273785 (* 1 = 0.273785 loss)
I1007 13:28:09.449280  4874 sgd_solver.cpp:105] Iteration 38700, lr = 0.1
I1007 13:28:17.549084  4874 solver.cpp:218] Iteration 38800 (12.346 iter/s, 8.09979s/100 iters), loss = 0.134516
I1007 13:28:17.549206  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.134516 (* 1 = 0.134516 loss)
I1007 13:28:17.549223  4874 sgd_solver.cpp:105] Iteration 38800, lr = 0.1
I1007 13:28:25.657778  4874 solver.cpp:218] Iteration 38900 (12.3327 iter/s, 8.10855s/100 iters), loss = 0.10322
I1007 13:28:25.657809  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.10322 (* 1 = 0.10322 loss)
I1007 13:28:25.657826  4874 sgd_solver.cpp:105] Iteration 38900, lr = 0.1
I1007 13:28:33.355197  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:28:33.679780  4874 solver.cpp:330] Iteration 39000, Testing net (#0)
I1007 13:28:35.571898  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:28:35.650889  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.75
I1007 13:28:35.650914  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.875454 (* 1 = 0.875454 loss)
I1007 13:28:35.732079  4874 solver.cpp:218] Iteration 39000 (9.92631 iter/s, 10.0742s/100 iters), loss = 0.168989
I1007 13:28:35.732105  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.168989 (* 1 = 0.168989 loss)
I1007 13:28:35.732111  4874 sgd_solver.cpp:105] Iteration 39000, lr = 0.1
I1007 13:28:43.828419  4874 solver.cpp:218] Iteration 39100 (12.3513 iter/s, 8.09629s/100 iters), loss = 0.19737
I1007 13:28:43.828461  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.19737 (* 1 = 0.19737 loss)
I1007 13:28:43.828467  4874 sgd_solver.cpp:105] Iteration 39100, lr = 0.1
I1007 13:28:51.914647  4874 solver.cpp:218] Iteration 39200 (12.3668 iter/s, 8.08616s/100 iters), loss = 0.228876
I1007 13:28:51.914784  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.228876 (* 1 = 0.228876 loss)
I1007 13:28:51.914791  4874 sgd_solver.cpp:105] Iteration 39200, lr = 0.1
I1007 13:29:00.011878  4874 solver.cpp:218] Iteration 39300 (12.3501 iter/s, 8.09708s/100 iters), loss = 0.221615
I1007 13:29:00.011919  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.221615 (* 1 = 0.221615 loss)
I1007 13:29:00.011924  4874 sgd_solver.cpp:105] Iteration 39300, lr = 0.1
I1007 13:29:08.106961  4874 solver.cpp:218] Iteration 39400 (12.3533 iter/s, 8.09502s/100 iters), loss = 0.163118
I1007 13:29:08.106999  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.163118 (* 1 = 0.163118 loss)
I1007 13:29:08.107005  4874 sgd_solver.cpp:105] Iteration 39400, lr = 0.1
I1007 13:29:15.801759  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:29:16.126719  4874 solver.cpp:330] Iteration 39500, Testing net (#0)
I1007 13:29:18.017627  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:29:18.096746  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7477
I1007 13:29:18.096781  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.816723 (* 1 = 0.816723 loss)
I1007 13:29:18.177521  4874 solver.cpp:218] Iteration 39500 (9.93 iter/s, 10.0705s/100 iters), loss = 0.154143
I1007 13:29:18.177551  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.154143 (* 1 = 0.154143 loss)
I1007 13:29:18.177557  4874 sgd_solver.cpp:105] Iteration 39500, lr = 0.1
I1007 13:29:26.275851  4874 solver.cpp:218] Iteration 39600 (12.3483 iter/s, 8.09827s/100 iters), loss = 0.229817
I1007 13:29:26.275936  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.229817 (* 1 = 0.229817 loss)
I1007 13:29:26.275952  4874 sgd_solver.cpp:105] Iteration 39600, lr = 0.1
I1007 13:29:34.379218  4874 solver.cpp:218] Iteration 39700 (12.3407 iter/s, 8.10326s/100 iters), loss = 0.22544
I1007 13:29:34.379258  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.22544 (* 1 = 0.22544 loss)
I1007 13:29:34.379264  4874 sgd_solver.cpp:105] Iteration 39700, lr = 0.1
I1007 13:29:42.479341  4874 solver.cpp:218] Iteration 39800 (12.3456 iter/s, 8.10006s/100 iters), loss = 0.192936
I1007 13:29:42.479370  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.192936 (* 1 = 0.192936 loss)
I1007 13:29:42.479377  4874 sgd_solver.cpp:105] Iteration 39800, lr = 0.1
I1007 13:29:50.581017  4874 solver.cpp:218] Iteration 39900 (12.3432 iter/s, 8.10162s/100 iters), loss = 0.174928
I1007 13:29:50.581046  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.174928 (* 1 = 0.174928 loss)
I1007 13:29:50.581053  4874 sgd_solver.cpp:105] Iteration 39900, lr = 0.1
I1007 13:29:58.276281  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:29:58.600585  4874 solver.cpp:330] Iteration 40000, Testing net (#0)
I1007 13:30:00.495271  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:30:00.573899  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.739
I1007 13:30:00.573935  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.850408 (* 1 = 0.850408 loss)
I1007 13:30:00.655200  4874 solver.cpp:218] Iteration 40000 (9.92642 iter/s, 10.0741s/100 iters), loss = 0.173088
I1007 13:30:00.655227  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.173088 (* 1 = 0.173088 loss)
I1007 13:30:00.655233  4874 sgd_solver.cpp:46] MultiStep Status: Iteration 40000, step = 1
I1007 13:30:00.655236  4874 sgd_solver.cpp:105] Iteration 40000, lr = 0.01
I1007 13:30:08.761209  4874 solver.cpp:218] Iteration 40100 (12.3366 iter/s, 8.10596s/100 iters), loss = 0.192467
I1007 13:30:08.761240  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.192467 (* 1 = 0.192467 loss)
I1007 13:30:08.761245  4874 sgd_solver.cpp:105] Iteration 40100, lr = 0.01
I1007 13:30:16.860157  4874 solver.cpp:218] Iteration 40200 (12.3474 iter/s, 8.09889s/100 iters), loss = 0.189704
I1007 13:30:16.860186  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.189704 (* 1 = 0.189704 loss)
I1007 13:30:16.860193  4874 sgd_solver.cpp:105] Iteration 40200, lr = 0.01
I1007 13:30:24.967861  4874 solver.cpp:218] Iteration 40300 (12.334 iter/s, 8.10765s/100 iters), loss = 0.128848
I1007 13:30:24.967891  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.128848 (* 1 = 0.128848 loss)
I1007 13:30:24.967897  4874 sgd_solver.cpp:105] Iteration 40300, lr = 0.01
I1007 13:30:33.069406  4874 solver.cpp:218] Iteration 40400 (12.3434 iter/s, 8.10149s/100 iters), loss = 0.104921
I1007 13:30:33.069536  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.104921 (* 1 = 0.104921 loss)
I1007 13:30:33.069543  4874 sgd_solver.cpp:105] Iteration 40400, lr = 0.01
I1007 13:30:40.771409  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:30:41.096082  4874 solver.cpp:330] Iteration 40500, Testing net (#0)
I1007 13:30:42.986799  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:30:43.065661  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9031
I1007 13:30:43.065696  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.28829 (* 1 = 0.28829 loss)
I1007 13:30:43.146677  4874 solver.cpp:218] Iteration 40500 (9.92347 iter/s, 10.0771s/100 iters), loss = 0.0555626
I1007 13:30:43.146704  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0555626 (* 1 = 0.0555626 loss)
I1007 13:30:43.146710  4874 sgd_solver.cpp:105] Iteration 40500, lr = 0.01
I1007 13:30:51.252398  4874 solver.cpp:218] Iteration 40600 (12.337 iter/s, 8.10567s/100 iters), loss = 0.0518657
I1007 13:30:51.252440  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0518656 (* 1 = 0.0518656 loss)
I1007 13:30:51.252446  4874 sgd_solver.cpp:105] Iteration 40600, lr = 0.01
I1007 13:30:59.359628  4874 solver.cpp:218] Iteration 40700 (12.3348 iter/s, 8.10716s/100 iters), loss = 0.109083
I1007 13:30:59.359664  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.109083 (* 1 = 0.109083 loss)
I1007 13:30:59.359671  4874 sgd_solver.cpp:105] Iteration 40700, lr = 0.01
I1007 13:31:07.460831  4874 solver.cpp:218] Iteration 40800 (12.3439 iter/s, 8.10114s/100 iters), loss = 0.089171
I1007 13:31:07.460970  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.089171 (* 1 = 0.089171 loss)
I1007 13:31:07.460978  4874 sgd_solver.cpp:105] Iteration 40800, lr = 0.01
I1007 13:31:15.570075  4874 solver.cpp:218] Iteration 40900 (12.3319 iter/s, 8.10908s/100 iters), loss = 0.0481481
I1007 13:31:15.570114  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.048148 (* 1 = 0.048148 loss)
I1007 13:31:15.570121  4874 sgd_solver.cpp:105] Iteration 40900, lr = 0.01
I1007 13:31:23.268437  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:31:23.592835  4874 solver.cpp:330] Iteration 41000, Testing net (#0)
I1007 13:31:25.485841  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:31:25.564177  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9092
I1007 13:31:25.564203  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.269384 (* 1 = 0.269384 loss)
I1007 13:31:25.645045  4874 solver.cpp:218] Iteration 41000 (9.92566 iter/s, 10.0749s/100 iters), loss = 0.0772598
I1007 13:31:25.645072  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0772597 (* 1 = 0.0772597 loss)
I1007 13:31:25.645079  4874 sgd_solver.cpp:105] Iteration 41000, lr = 0.01
I1007 13:31:33.743249  4874 solver.cpp:218] Iteration 41100 (12.3485 iter/s, 8.09815s/100 iters), loss = 0.0960129
I1007 13:31:33.743280  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0960128 (* 1 = 0.0960128 loss)
I1007 13:31:33.743286  4874 sgd_solver.cpp:105] Iteration 41100, lr = 0.01
I1007 13:31:41.835326  4874 solver.cpp:218] Iteration 41200 (12.3579 iter/s, 8.09202s/100 iters), loss = 0.0916114
I1007 13:31:41.835458  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0916113 (* 1 = 0.0916113 loss)
I1007 13:31:41.835464  4874 sgd_solver.cpp:105] Iteration 41200, lr = 0.01
I1007 13:31:49.937778  4874 solver.cpp:218] Iteration 41300 (12.3422 iter/s, 8.10231s/100 iters), loss = 0.0690973
I1007 13:31:49.937808  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0690972 (* 1 = 0.0690972 loss)
I1007 13:31:49.937815  4874 sgd_solver.cpp:105] Iteration 41300, lr = 0.01
I1007 13:31:58.033862  4874 solver.cpp:218] Iteration 41400 (12.3517 iter/s, 8.09603s/100 iters), loss = 0.0446726
I1007 13:31:58.033891  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0446725 (* 1 = 0.0446725 loss)
I1007 13:31:58.033907  4874 sgd_solver.cpp:105] Iteration 41400, lr = 0.01
I1007 13:32:05.735266  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:32:06.059768  4874 solver.cpp:330] Iteration 41500, Testing net (#0)
I1007 13:32:07.949307  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:32:08.028225  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9152
I1007 13:32:08.028260  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.262434 (* 1 = 0.262434 loss)
I1007 13:32:08.109297  4874 solver.cpp:218] Iteration 41500 (9.92519 iter/s, 10.0754s/100 iters), loss = 0.109128
I1007 13:32:08.109323  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.109128 (* 1 = 0.109128 loss)
I1007 13:32:08.109329  4874 sgd_solver.cpp:105] Iteration 41500, lr = 0.01
I1007 13:32:16.205153  4874 solver.cpp:218] Iteration 41600 (12.3521 iter/s, 8.0958s/100 iters), loss = 0.0700412
I1007 13:32:16.205265  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0700411 (* 1 = 0.0700411 loss)
I1007 13:32:16.205272  4874 sgd_solver.cpp:105] Iteration 41600, lr = 0.01
I1007 13:32:24.301497  4874 solver.cpp:218] Iteration 41700 (12.3514 iter/s, 8.09622s/100 iters), loss = 0.0805466
I1007 13:32:24.301527  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0805465 (* 1 = 0.0805465 loss)
I1007 13:32:24.301532  4874 sgd_solver.cpp:105] Iteration 41700, lr = 0.01
I1007 13:32:32.394790  4874 solver.cpp:218] Iteration 41800 (12.356 iter/s, 8.09324s/100 iters), loss = 0.109132
I1007 13:32:32.394829  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.109132 (* 1 = 0.109132 loss)
I1007 13:32:32.394835  4874 sgd_solver.cpp:105] Iteration 41800, lr = 0.01
I1007 13:32:40.495901  4874 solver.cpp:218] Iteration 41900 (12.3441 iter/s, 8.10105s/100 iters), loss = 0.0482854
I1007 13:32:40.495940  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0482854 (* 1 = 0.0482854 loss)
I1007 13:32:40.495946  4874 sgd_solver.cpp:105] Iteration 41900, lr = 0.01
I1007 13:32:48.187005  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:32:48.511934  4874 solver.cpp:330] Iteration 42000, Testing net (#0)
I1007 13:32:50.404232  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:32:50.483369  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9134
I1007 13:32:50.483408  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.259711 (* 1 = 0.259711 loss)
I1007 13:32:50.563376  4874 solver.cpp:218] Iteration 42000 (9.93305 iter/s, 10.0674s/100 iters), loss = 0.109953
I1007 13:32:50.563405  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.109953 (* 1 = 0.109953 loss)
I1007 13:32:50.563415  4874 sgd_solver.cpp:105] Iteration 42000, lr = 0.01
I1007 13:32:58.651526  4874 solver.cpp:218] Iteration 42100 (12.3639 iter/s, 8.08809s/100 iters), loss = 0.0561245
I1007 13:32:58.651566  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0561245 (* 1 = 0.0561245 loss)
I1007 13:32:58.651572  4874 sgd_solver.cpp:105] Iteration 42100, lr = 0.01
I1007 13:33:06.736881  4874 solver.cpp:218] Iteration 42200 (12.3681 iter/s, 8.08529s/100 iters), loss = 0.0614278
I1007 13:33:06.736922  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0614277 (* 1 = 0.0614277 loss)
I1007 13:33:06.736928  4874 sgd_solver.cpp:105] Iteration 42200, lr = 0.01
I1007 13:33:14.829732  4874 solver.cpp:218] Iteration 42300 (12.3567 iter/s, 8.09277s/100 iters), loss = 0.0654565
I1007 13:33:14.829772  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0654564 (* 1 = 0.0654564 loss)
I1007 13:33:14.829779  4874 sgd_solver.cpp:105] Iteration 42300, lr = 0.01
I1007 13:33:22.914901  4874 solver.cpp:218] Iteration 42400 (12.3684 iter/s, 8.08511s/100 iters), loss = 0.0610191
I1007 13:33:22.915030  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.061019 (* 1 = 0.061019 loss)
I1007 13:33:22.915045  4874 sgd_solver.cpp:105] Iteration 42400, lr = 0.01
I1007 13:33:30.606096  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:33:30.929975  4874 solver.cpp:330] Iteration 42500, Testing net (#0)
I1007 13:33:32.819852  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:33:32.899024  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9157
I1007 13:33:32.899058  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.257289 (* 1 = 0.257289 loss)
I1007 13:33:32.979627  4874 solver.cpp:218] Iteration 42500 (9.93583 iter/s, 10.0646s/100 iters), loss = 0.0404217
I1007 13:33:32.979653  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0404216 (* 1 = 0.0404216 loss)
I1007 13:33:32.979660  4874 sgd_solver.cpp:105] Iteration 42500, lr = 0.01
I1007 13:33:41.071753  4874 solver.cpp:218] Iteration 42600 (12.3578 iter/s, 8.09207s/100 iters), loss = 0.0417067
I1007 13:33:41.071792  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0417066 (* 1 = 0.0417066 loss)
I1007 13:33:41.071799  4874 sgd_solver.cpp:105] Iteration 42600, lr = 0.01
I1007 13:33:49.169018  4874 solver.cpp:218] Iteration 42700 (12.3499 iter/s, 8.0972s/100 iters), loss = 0.0628768
I1007 13:33:49.169049  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0628767 (* 1 = 0.0628767 loss)
I1007 13:33:49.169054  4874 sgd_solver.cpp:105] Iteration 42700, lr = 0.01
I1007 13:33:57.259758  4874 solver.cpp:218] Iteration 42800 (12.3599 iter/s, 8.09068s/100 iters), loss = 0.0438307
I1007 13:33:57.259867  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0438306 (* 1 = 0.0438306 loss)
I1007 13:33:57.259874  4874 sgd_solver.cpp:105] Iteration 42800, lr = 0.01
I1007 13:34:05.354054  4874 solver.cpp:218] Iteration 42900 (12.3546 iter/s, 8.09416s/100 iters), loss = 0.0620584
I1007 13:34:05.354095  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0620584 (* 1 = 0.0620584 loss)
I1007 13:34:05.354101  4874 sgd_solver.cpp:105] Iteration 42900, lr = 0.01
I1007 13:34:13.039078  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:34:13.362536  4874 solver.cpp:330] Iteration 43000, Testing net (#0)
I1007 13:34:15.254251  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:34:15.333508  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9177
I1007 13:34:15.333544  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.255186 (* 1 = 0.255186 loss)
I1007 13:34:15.414754  4874 solver.cpp:218] Iteration 43000 (9.93974 iter/s, 10.0606s/100 iters), loss = 0.0670797
I1007 13:34:15.414782  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0670796 (* 1 = 0.0670796 loss)
I1007 13:34:15.414788  4874 sgd_solver.cpp:105] Iteration 43000, lr = 0.01
I1007 13:34:23.518769  4874 solver.cpp:218] Iteration 43100 (12.3396 iter/s, 8.10396s/100 iters), loss = 0.105921
I1007 13:34:23.518810  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.105921 (* 1 = 0.105921 loss)
I1007 13:34:23.518815  4874 sgd_solver.cpp:105] Iteration 43100, lr = 0.01
I1007 13:34:31.615775  4874 solver.cpp:218] Iteration 43200 (12.3503 iter/s, 8.09694s/100 iters), loss = 0.0942226
I1007 13:34:31.615939  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0942226 (* 1 = 0.0942226 loss)
I1007 13:34:31.615947  4874 sgd_solver.cpp:105] Iteration 43200, lr = 0.01
I1007 13:34:39.719885  4874 solver.cpp:218] Iteration 43300 (12.3397 iter/s, 8.10392s/100 iters), loss = 0.0452353
I1007 13:34:39.719915  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0452353 (* 1 = 0.0452353 loss)
I1007 13:34:39.719931  4874 sgd_solver.cpp:105] Iteration 43300, lr = 0.01
I1007 13:34:47.815500  4874 solver.cpp:218] Iteration 43400 (12.3525 iter/s, 8.09556s/100 iters), loss = 0.0513135
I1007 13:34:47.815528  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0513135 (* 1 = 0.0513135 loss)
I1007 13:34:47.815534  4874 sgd_solver.cpp:105] Iteration 43400, lr = 0.01
I1007 13:34:55.514554  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:34:55.838624  4874 solver.cpp:330] Iteration 43500, Testing net (#0)
I1007 13:34:57.730643  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:34:57.809600  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9164
I1007 13:34:57.809634  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.260342 (* 1 = 0.260342 loss)
I1007 13:34:57.890396  4874 solver.cpp:218] Iteration 43500 (9.92572 iter/s, 10.0748s/100 iters), loss = 0.0166522
I1007 13:34:57.890424  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0166522 (* 1 = 0.0166522 loss)
I1007 13:34:57.890430  4874 sgd_solver.cpp:105] Iteration 43500, lr = 0.01
I1007 13:35:05.989223  4874 solver.cpp:218] Iteration 43600 (12.3475 iter/s, 8.09877s/100 iters), loss = 0.0398207
I1007 13:35:05.989329  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0398206 (* 1 = 0.0398206 loss)
I1007 13:35:05.989336  4874 sgd_solver.cpp:105] Iteration 43600, lr = 0.01
I1007 13:35:14.093950  4874 solver.cpp:218] Iteration 43700 (12.3387 iter/s, 8.1046s/100 iters), loss = 0.0611688
I1007 13:35:14.093978  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0611688 (* 1 = 0.0611688 loss)
I1007 13:35:14.093984  4874 sgd_solver.cpp:105] Iteration 43700, lr = 0.01
I1007 13:35:22.193248  4874 solver.cpp:218] Iteration 43800 (12.3468 iter/s, 8.09925s/100 iters), loss = 0.064545
I1007 13:35:22.193287  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.064545 (* 1 = 0.064545 loss)
I1007 13:35:22.193294  4874 sgd_solver.cpp:105] Iteration 43800, lr = 0.01
I1007 13:35:30.301828  4874 solver.cpp:218] Iteration 43900 (12.3327 iter/s, 8.10851s/100 iters), loss = 0.032962
I1007 13:35:30.301858  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.032962 (* 1 = 0.032962 loss)
I1007 13:35:30.301864  4874 sgd_solver.cpp:105] Iteration 43900, lr = 0.01
I1007 13:35:37.999286  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:35:38.323676  4874 solver.cpp:330] Iteration 44000, Testing net (#0)
I1007 13:35:40.216083  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:35:40.295218  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9119
I1007 13:35:40.295243  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.28117 (* 1 = 0.28117 loss)
I1007 13:35:40.375952  4874 solver.cpp:218] Iteration 44000 (9.92648 iter/s, 10.0741s/100 iters), loss = 0.033821
I1007 13:35:40.375979  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.033821 (* 1 = 0.033821 loss)
I1007 13:35:40.375988  4874 sgd_solver.cpp:105] Iteration 44000, lr = 0.01
I1007 13:35:48.473991  4874 solver.cpp:218] Iteration 44100 (12.3488 iter/s, 8.09799s/100 iters), loss = 0.0163458
I1007 13:35:48.474020  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0163459 (* 1 = 0.0163459 loss)
I1007 13:35:48.474026  4874 sgd_solver.cpp:105] Iteration 44100, lr = 0.01
I1007 13:35:56.566296  4874 solver.cpp:218] Iteration 44200 (12.3575 iter/s, 8.09225s/100 iters), loss = 0.110553
I1007 13:35:56.566325  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.110553 (* 1 = 0.110553 loss)
I1007 13:35:56.566330  4874 sgd_solver.cpp:105] Iteration 44200, lr = 0.01
I1007 13:36:04.665107  4874 solver.cpp:218] Iteration 44300 (12.3476 iter/s, 8.09876s/100 iters), loss = 0.0168684
I1007 13:36:04.665148  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0168684 (* 1 = 0.0168684 loss)
I1007 13:36:04.665153  4874 sgd_solver.cpp:105] Iteration 44300, lr = 0.01
I1007 13:36:12.763234  4874 solver.cpp:218] Iteration 44400 (12.3486 iter/s, 8.09806s/100 iters), loss = 0.0312519
I1007 13:36:12.763350  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.031252 (* 1 = 0.031252 loss)
I1007 13:36:12.763357  4874 sgd_solver.cpp:105] Iteration 44400, lr = 0.01
I1007 13:36:20.462178  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:36:20.787231  4874 solver.cpp:330] Iteration 44500, Testing net (#0)
I1007 13:36:22.675037  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:36:22.754369  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9135
I1007 13:36:22.754408  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.276912 (* 1 = 0.276912 loss)
I1007 13:36:22.834367  4874 solver.cpp:218] Iteration 44500 (9.92951 iter/s, 10.071s/100 iters), loss = 0.030406
I1007 13:36:22.834393  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0304061 (* 1 = 0.0304061 loss)
I1007 13:36:22.834400  4874 sgd_solver.cpp:105] Iteration 44500, lr = 0.01
I1007 13:36:30.931422  4874 solver.cpp:218] Iteration 44600 (12.3503 iter/s, 8.097s/100 iters), loss = 0.041787
I1007 13:36:30.931454  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.041787 (* 1 = 0.041787 loss)
I1007 13:36:30.931470  4874 sgd_solver.cpp:105] Iteration 44600, lr = 0.01
I1007 13:36:39.032529  4874 solver.cpp:218] Iteration 44700 (12.3441 iter/s, 8.10105s/100 iters), loss = 0.0577562
I1007 13:36:39.032569  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0577562 (* 1 = 0.0577562 loss)
I1007 13:36:39.032577  4874 sgd_solver.cpp:105] Iteration 44700, lr = 0.01
I1007 13:36:47.127003  4874 solver.cpp:218] Iteration 44800 (12.3542 iter/s, 8.09441s/100 iters), loss = 0.0300768
I1007 13:36:47.127099  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0300768 (* 1 = 0.0300768 loss)
I1007 13:36:47.127116  4874 sgd_solver.cpp:105] Iteration 44800, lr = 0.01
I1007 13:36:55.228257  4874 solver.cpp:218] Iteration 44900 (12.344 iter/s, 8.10113s/100 iters), loss = 0.0328539
I1007 13:36:55.228286  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0328539 (* 1 = 0.0328539 loss)
I1007 13:36:55.228291  4874 sgd_solver.cpp:105] Iteration 44900, lr = 0.01
I1007 13:37:02.923643  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:37:03.247532  4874 solver.cpp:330] Iteration 45000, Testing net (#0)
I1007 13:37:05.138362  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:37:05.217479  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9152
I1007 13:37:05.217514  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.268024 (* 1 = 0.268024 loss)
I1007 13:37:05.298708  4874 solver.cpp:218] Iteration 45000 (9.9301 iter/s, 10.0704s/100 iters), loss = 0.037686
I1007 13:37:05.298738  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.037686 (* 1 = 0.037686 loss)
I1007 13:37:05.298744  4874 sgd_solver.cpp:105] Iteration 45000, lr = 0.01
I1007 13:37:13.397449  4874 solver.cpp:218] Iteration 45100 (12.3477 iter/s, 8.09868s/100 iters), loss = 0.0330395
I1007 13:37:13.397476  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0330395 (* 1 = 0.0330395 loss)
I1007 13:37:13.397482  4874 sgd_solver.cpp:105] Iteration 45100, lr = 0.01
I1007 13:37:21.494534  4874 solver.cpp:218] Iteration 45200 (12.3502 iter/s, 8.09703s/100 iters), loss = 0.0660725
I1007 13:37:21.494652  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0660725 (* 1 = 0.0660725 loss)
I1007 13:37:21.494668  4874 sgd_solver.cpp:105] Iteration 45200, lr = 0.01
I1007 13:37:29.592648  4874 solver.cpp:218] Iteration 45300 (12.3488 iter/s, 8.09797s/100 iters), loss = 0.0528567
I1007 13:37:29.592686  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0528567 (* 1 = 0.0528567 loss)
I1007 13:37:29.592692  4874 sgd_solver.cpp:105] Iteration 45300, lr = 0.01
I1007 13:37:37.685305  4874 solver.cpp:218] Iteration 45400 (12.357 iter/s, 8.09259s/100 iters), loss = 0.0353341
I1007 13:37:37.685345  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0353342 (* 1 = 0.0353342 loss)
I1007 13:37:37.685351  4874 sgd_solver.cpp:105] Iteration 45400, lr = 0.01
I1007 13:37:45.383144  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:37:45.707123  4874 solver.cpp:330] Iteration 45500, Testing net (#0)
I1007 13:37:47.598320  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:37:47.677266  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9135
I1007 13:37:47.677301  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.280257 (* 1 = 0.280257 loss)
I1007 13:37:47.758141  4874 solver.cpp:218] Iteration 45500 (9.92776 iter/s, 10.0728s/100 iters), loss = 0.0281996
I1007 13:37:47.758168  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0281997 (* 1 = 0.0281997 loss)
I1007 13:37:47.758175  4874 sgd_solver.cpp:105] Iteration 45500, lr = 0.01
I1007 13:37:55.851877  4874 solver.cpp:218] Iteration 45600 (12.3553 iter/s, 8.09368s/100 iters), loss = 0.0354876
I1007 13:37:55.851999  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0354876 (* 1 = 0.0354876 loss)
I1007 13:37:55.852005  4874 sgd_solver.cpp:105] Iteration 45600, lr = 0.01
I1007 13:38:03.947921  4874 solver.cpp:218] Iteration 45700 (12.3519 iter/s, 8.0959s/100 iters), loss = 0.0514688
I1007 13:38:03.947952  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0514688 (* 1 = 0.0514688 loss)
I1007 13:38:03.947957  4874 sgd_solver.cpp:105] Iteration 45700, lr = 0.01
I1007 13:38:12.036906  4874 solver.cpp:218] Iteration 45800 (12.3626 iter/s, 8.08893s/100 iters), loss = 0.0343062
I1007 13:38:12.036934  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0343062 (* 1 = 0.0343062 loss)
I1007 13:38:12.036940  4874 sgd_solver.cpp:105] Iteration 45800, lr = 0.01
I1007 13:38:20.136349  4874 solver.cpp:218] Iteration 45900 (12.3466 iter/s, 8.09939s/100 iters), loss = 0.0214677
I1007 13:38:20.136389  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0214677 (* 1 = 0.0214677 loss)
I1007 13:38:20.136395  4874 sgd_solver.cpp:105] Iteration 45900, lr = 0.01
I1007 13:38:27.830132  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:38:28.154211  4874 solver.cpp:330] Iteration 46000, Testing net (#0)
I1007 13:38:30.045795  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:38:30.124555  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9154
I1007 13:38:30.124589  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.278106 (* 1 = 0.278106 loss)
I1007 13:38:30.204972  4874 solver.cpp:218] Iteration 46000 (9.93191 iter/s, 10.0686s/100 iters), loss = 0.0460297
I1007 13:38:30.204999  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0460297 (* 1 = 0.0460297 loss)
I1007 13:38:30.205005  4874 sgd_solver.cpp:105] Iteration 46000, lr = 0.01
I1007 13:38:38.319975  4874 solver.cpp:218] Iteration 46100 (12.3229 iter/s, 8.11495s/100 iters), loss = 0.0181821
I1007 13:38:38.320015  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0181821 (* 1 = 0.0181821 loss)
I1007 13:38:38.320022  4874 sgd_solver.cpp:105] Iteration 46100, lr = 0.01
I1007 13:38:46.431097  4874 solver.cpp:218] Iteration 46200 (12.3288 iter/s, 8.11106s/100 iters), loss = 0.0649755
I1007 13:38:46.431138  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0649755 (* 1 = 0.0649755 loss)
I1007 13:38:46.431143  4874 sgd_solver.cpp:105] Iteration 46200, lr = 0.01
I1007 13:38:54.539012  4874 solver.cpp:218] Iteration 46300 (12.3337 iter/s, 8.10785s/100 iters), loss = 0.042042
I1007 13:38:54.539042  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.042042 (* 1 = 0.042042 loss)
I1007 13:38:54.539048  4874 sgd_solver.cpp:105] Iteration 46300, lr = 0.01
I1007 13:39:02.646409  4874 solver.cpp:218] Iteration 46400 (12.3345 iter/s, 8.10734s/100 iters), loss = 0.0128043
I1007 13:39:02.646564  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0128042 (* 1 = 0.0128042 loss)
I1007 13:39:02.646571  4874 sgd_solver.cpp:105] Iteration 46400, lr = 0.01
I1007 13:39:10.353039  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:39:10.679896  4874 solver.cpp:330] Iteration 46500, Testing net (#0)
I1007 13:39:12.572013  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:39:12.651192  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9156
I1007 13:39:12.651227  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.274768 (* 1 = 0.274768 loss)
I1007 13:39:12.731772  4874 solver.cpp:218] Iteration 46500 (9.91553 iter/s, 10.0852s/100 iters), loss = 0.0109631
I1007 13:39:12.731797  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0109631 (* 1 = 0.0109631 loss)
I1007 13:39:12.731803  4874 sgd_solver.cpp:105] Iteration 46500, lr = 0.01
I1007 13:39:20.830734  4874 solver.cpp:218] Iteration 46600 (12.3473 iter/s, 8.09891s/100 iters), loss = 0.0809875
I1007 13:39:20.830773  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0809875 (* 1 = 0.0809875 loss)
I1007 13:39:20.830780  4874 sgd_solver.cpp:105] Iteration 46600, lr = 0.01
I1007 13:39:28.929503  4874 solver.cpp:218] Iteration 46700 (12.3477 iter/s, 8.09871s/100 iters), loss = 0.0345262
I1007 13:39:28.929533  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0345261 (* 1 = 0.0345261 loss)
I1007 13:39:28.929538  4874 sgd_solver.cpp:105] Iteration 46700, lr = 0.01
I1007 13:39:37.021595  4874 solver.cpp:218] Iteration 46800 (12.3578 iter/s, 8.09204s/100 iters), loss = 0.0286603
I1007 13:39:37.021697  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0286603 (* 1 = 0.0286603 loss)
I1007 13:39:37.021713  4874 sgd_solver.cpp:105] Iteration 46800, lr = 0.01
I1007 13:39:45.119745  4874 solver.cpp:218] Iteration 46900 (12.3487 iter/s, 8.09802s/100 iters), loss = 0.0227089
I1007 13:39:45.119773  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0227089 (* 1 = 0.0227089 loss)
I1007 13:39:45.119779  4874 sgd_solver.cpp:105] Iteration 46900, lr = 0.01
I1007 13:39:52.812386  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:39:53.137768  4874 solver.cpp:330] Iteration 47000, Testing net (#0)
I1007 13:39:55.027837  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:39:55.106946  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9161
I1007 13:39:55.106981  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.277648 (* 1 = 0.277648 loss)
I1007 13:39:55.187865  4874 solver.cpp:218] Iteration 47000 (9.9324 iter/s, 10.0681s/100 iters), loss = 0.0206168
I1007 13:39:55.187892  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0206168 (* 1 = 0.0206168 loss)
I1007 13:39:55.187899  4874 sgd_solver.cpp:105] Iteration 47000, lr = 0.01
I1007 13:40:03.297390  4874 solver.cpp:218] Iteration 47100 (12.3313 iter/s, 8.10947s/100 iters), loss = 0.0198807
I1007 13:40:03.297432  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0198807 (* 1 = 0.0198807 loss)
I1007 13:40:03.297438  4874 sgd_solver.cpp:105] Iteration 47100, lr = 0.01
I1007 13:40:11.396332  4874 solver.cpp:218] Iteration 47200 (12.3474 iter/s, 8.09887s/100 iters), loss = 0.0549072
I1007 13:40:11.396503  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0549072 (* 1 = 0.0549072 loss)
I1007 13:40:11.396512  4874 sgd_solver.cpp:105] Iteration 47200, lr = 0.01
I1007 13:40:19.501147  4874 solver.cpp:218] Iteration 47300 (12.3386 iter/s, 8.10462s/100 iters), loss = 0.0232754
I1007 13:40:19.501176  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0232754 (* 1 = 0.0232754 loss)
I1007 13:40:19.501183  4874 sgd_solver.cpp:105] Iteration 47300, lr = 0.01
I1007 13:40:27.601155  4874 solver.cpp:218] Iteration 47400 (12.3458 iter/s, 8.09995s/100 iters), loss = 0.00870616
I1007 13:40:27.601197  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00870617 (* 1 = 0.00870617 loss)
I1007 13:40:27.601202  4874 sgd_solver.cpp:105] Iteration 47400, lr = 0.01
I1007 13:40:35.300077  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:40:35.625449  4874 solver.cpp:330] Iteration 47500, Testing net (#0)
I1007 13:40:37.516674  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:40:37.595808  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9145
I1007 13:40:37.595844  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.287289 (* 1 = 0.287289 loss)
I1007 13:40:37.676733  4874 solver.cpp:218] Iteration 47500 (9.92506 iter/s, 10.0755s/100 iters), loss = 0.0516264
I1007 13:40:37.676759  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0516264 (* 1 = 0.0516264 loss)
I1007 13:40:37.676766  4874 sgd_solver.cpp:105] Iteration 47500, lr = 0.01
I1007 13:40:45.780885  4874 solver.cpp:218] Iteration 47600 (12.3394 iter/s, 8.1041s/100 iters), loss = 0.0392231
I1007 13:40:45.780997  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0392231 (* 1 = 0.0392231 loss)
I1007 13:40:45.781018  4874 sgd_solver.cpp:105] Iteration 47600, lr = 0.01
I1007 13:40:53.886867  4874 solver.cpp:218] Iteration 47700 (12.3368 iter/s, 8.10585s/100 iters), loss = 0.0417428
I1007 13:40:53.886895  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0417428 (* 1 = 0.0417428 loss)
I1007 13:40:53.886901  4874 sgd_solver.cpp:105] Iteration 47700, lr = 0.01
I1007 13:41:01.989902  4874 solver.cpp:218] Iteration 47800 (12.3411 iter/s, 8.10298s/100 iters), loss = 0.0297128
I1007 13:41:01.989949  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0297129 (* 1 = 0.0297129 loss)
I1007 13:41:01.989956  4874 sgd_solver.cpp:105] Iteration 47800, lr = 0.01
I1007 13:41:10.089208  4874 solver.cpp:218] Iteration 47900 (12.3468 iter/s, 8.09923s/100 iters), loss = 0.0146611
I1007 13:41:10.089249  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0146611 (* 1 = 0.0146611 loss)
I1007 13:41:10.089254  4874 sgd_solver.cpp:105] Iteration 47900, lr = 0.01
I1007 13:41:17.789758  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:41:18.114524  4874 solver.cpp:330] Iteration 48000, Testing net (#0)
I1007 13:41:20.007243  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:41:20.086134  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9161
I1007 13:41:20.086169  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.285847 (* 1 = 0.285847 loss)
I1007 13:41:20.166626  4874 solver.cpp:218] Iteration 48000 (9.92325 iter/s, 10.0773s/100 iters), loss = 0.0233161
I1007 13:41:20.166651  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0233161 (* 1 = 0.0233161 loss)
I1007 13:41:20.166657  4874 sgd_solver.cpp:105] Iteration 48000, lr = 0.01
I1007 13:41:28.269251  4874 solver.cpp:218] Iteration 48100 (12.3418 iter/s, 8.10257s/100 iters), loss = 0.024817
I1007 13:41:28.269291  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.024817 (* 1 = 0.024817 loss)
I1007 13:41:28.269297  4874 sgd_solver.cpp:105] Iteration 48100, lr = 0.01
I1007 13:41:36.356550  4874 solver.cpp:218] Iteration 48200 (12.3652 iter/s, 8.08723s/100 iters), loss = 0.0236623
I1007 13:41:36.356590  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0236623 (* 1 = 0.0236623 loss)
I1007 13:41:36.356595  4874 sgd_solver.cpp:105] Iteration 48200, lr = 0.01
I1007 13:41:44.449159  4874 solver.cpp:218] Iteration 48300 (12.3571 iter/s, 8.09254s/100 iters), loss = 0.0315322
I1007 13:41:44.449189  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0315322 (* 1 = 0.0315322 loss)
I1007 13:41:44.449195  4874 sgd_solver.cpp:105] Iteration 48300, lr = 0.01
I1007 13:41:52.542781  4874 solver.cpp:218] Iteration 48400 (12.3555 iter/s, 8.09357s/100 iters), loss = 0.0216222
I1007 13:41:52.542898  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0216221 (* 1 = 0.0216221 loss)
I1007 13:41:52.542915  4874 sgd_solver.cpp:105] Iteration 48400, lr = 0.01
I1007 13:42:00.236826  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:42:00.561076  4874 solver.cpp:330] Iteration 48500, Testing net (#0)
I1007 13:42:02.454354  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:42:02.533216  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9124
I1007 13:42:02.533251  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.305784 (* 1 = 0.305784 loss)
I1007 13:42:02.614109  4874 solver.cpp:218] Iteration 48500 (9.92932 iter/s, 10.0712s/100 iters), loss = 0.0346263
I1007 13:42:02.614135  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0346263 (* 1 = 0.0346263 loss)
I1007 13:42:02.614142  4874 sgd_solver.cpp:105] Iteration 48500, lr = 0.01
I1007 13:42:10.707509  4874 solver.cpp:218] Iteration 48600 (12.3558 iter/s, 8.09334s/100 iters), loss = 0.0228803
I1007 13:42:10.707540  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0228803 (* 1 = 0.0228803 loss)
I1007 13:42:10.707547  4874 sgd_solver.cpp:105] Iteration 48600, lr = 0.01
I1007 13:42:18.801918  4874 solver.cpp:218] Iteration 48700 (12.3543 iter/s, 8.09435s/100 iters), loss = 0.0172591
I1007 13:42:18.801960  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.017259 (* 1 = 0.017259 loss)
I1007 13:42:18.801966  4874 sgd_solver.cpp:105] Iteration 48700, lr = 0.01
I1007 13:42:26.895246  4874 solver.cpp:218] Iteration 48800 (12.356 iter/s, 8.09326s/100 iters), loss = 0.0217282
I1007 13:42:26.895364  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0217282 (* 1 = 0.0217282 loss)
I1007 13:42:26.895370  4874 sgd_solver.cpp:105] Iteration 48800, lr = 0.01
I1007 13:42:34.991443  4874 solver.cpp:218] Iteration 48900 (12.3517 iter/s, 8.09606s/100 iters), loss = 0.0105281
I1007 13:42:34.991483  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.010528 (* 1 = 0.010528 loss)
I1007 13:42:34.991489  4874 sgd_solver.cpp:105] Iteration 48900, lr = 0.01
I1007 13:42:42.685202  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:42:43.009729  4874 solver.cpp:330] Iteration 49000, Testing net (#0)
I1007 13:42:44.901376  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:42:44.980142  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9164
I1007 13:42:44.980178  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.294386 (* 1 = 0.294386 loss)
I1007 13:42:45.061024  4874 solver.cpp:218] Iteration 49000 (9.93097 iter/s, 10.0695s/100 iters), loss = 0.047798
I1007 13:42:45.061050  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.047798 (* 1 = 0.047798 loss)
I1007 13:42:45.061058  4874 sgd_solver.cpp:105] Iteration 49000, lr = 0.01
I1007 13:42:53.170596  4874 solver.cpp:218] Iteration 49100 (12.3312 iter/s, 8.10952s/100 iters), loss = 0.0517276
I1007 13:42:53.170636  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0517276 (* 1 = 0.0517276 loss)
I1007 13:42:53.170642  4874 sgd_solver.cpp:105] Iteration 49100, lr = 0.01
I1007 13:43:01.277353  4874 solver.cpp:218] Iteration 49200 (12.3355 iter/s, 8.10669s/100 iters), loss = 0.0420681
I1007 13:43:01.277447  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.042068 (* 1 = 0.042068 loss)
I1007 13:43:01.277453  4874 sgd_solver.cpp:105] Iteration 49200, lr = 0.01
I1007 13:43:09.387369  4874 solver.cpp:218] Iteration 49300 (12.3306 iter/s, 8.1099s/100 iters), loss = 0.0303259
I1007 13:43:09.387409  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0303258 (* 1 = 0.0303258 loss)
I1007 13:43:09.387415  4874 sgd_solver.cpp:105] Iteration 49300, lr = 0.01
I1007 13:43:17.493235  4874 solver.cpp:218] Iteration 49400 (12.3368 iter/s, 8.1058s/100 iters), loss = 0.0382561
I1007 13:43:17.493274  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0382561 (* 1 = 0.0382561 loss)
I1007 13:43:17.493280  4874 sgd_solver.cpp:105] Iteration 49400, lr = 0.01
I1007 13:43:25.199285  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:43:25.524441  4874 solver.cpp:330] Iteration 49500, Testing net (#0)
I1007 13:43:27.416889  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:43:27.495867  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9138
I1007 13:43:27.495900  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.295065 (* 1 = 0.295065 loss)
I1007 13:43:27.576581  4874 solver.cpp:218] Iteration 49500 (9.91741 iter/s, 10.0833s/100 iters), loss = 0.037795
I1007 13:43:27.576607  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.037795 (* 1 = 0.037795 loss)
I1007 13:43:27.576614  4874 sgd_solver.cpp:105] Iteration 49500, lr = 0.01
I1007 13:43:35.668721  4874 solver.cpp:218] Iteration 49600 (12.3577 iter/s, 8.09209s/100 iters), loss = 0.0103476
I1007 13:43:35.668841  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0103476 (* 1 = 0.0103476 loss)
I1007 13:43:35.668849  4874 sgd_solver.cpp:105] Iteration 49600, lr = 0.01
I1007 13:43:43.772073  4874 solver.cpp:218] Iteration 49700 (12.3408 iter/s, 8.10322s/100 iters), loss = 0.0137877
I1007 13:43:43.772104  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0137877 (* 1 = 0.0137877 loss)
I1007 13:43:43.772109  4874 sgd_solver.cpp:105] Iteration 49700, lr = 0.01
I1007 13:43:51.870437  4874 solver.cpp:218] Iteration 49800 (12.3483 iter/s, 8.09831s/100 iters), loss = 0.0243794
I1007 13:43:51.870466  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0243793 (* 1 = 0.0243793 loss)
I1007 13:43:51.870472  4874 sgd_solver.cpp:105] Iteration 49800, lr = 0.01
I1007 13:43:59.969789  4874 solver.cpp:218] Iteration 49900 (12.3468 iter/s, 8.0993s/100 iters), loss = 0.0102828
I1007 13:43:59.969818  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0102827 (* 1 = 0.0102827 loss)
I1007 13:43:59.969825  4874 sgd_solver.cpp:105] Iteration 49900, lr = 0.01
I1007 13:44:07.668470  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:44:07.992724  4874 solver.cpp:330] Iteration 50000, Testing net (#0)
I1007 13:44:09.882953  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:44:09.962119  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9127
I1007 13:44:09.962154  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.304808 (* 1 = 0.304808 loss)
I1007 13:44:10.043124  4874 solver.cpp:218] Iteration 50000 (9.92726 iter/s, 10.0733s/100 iters), loss = 0.0530412
I1007 13:44:10.043149  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0530412 (* 1 = 0.0530412 loss)
I1007 13:44:10.043156  4874 sgd_solver.cpp:105] Iteration 50000, lr = 0.01
I1007 13:44:18.147102  4874 solver.cpp:218] Iteration 50100 (12.3397 iter/s, 8.10393s/100 iters), loss = 0.0214974
I1007 13:44:18.147131  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0214973 (* 1 = 0.0214973 loss)
I1007 13:44:18.147137  4874 sgd_solver.cpp:105] Iteration 50100, lr = 0.01
I1007 13:44:26.247938  4874 solver.cpp:218] Iteration 50200 (12.3445 iter/s, 8.10078s/100 iters), loss = 0.0174923
I1007 13:44:26.247979  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0174922 (* 1 = 0.0174922 loss)
I1007 13:44:26.247985  4874 sgd_solver.cpp:105] Iteration 50200, lr = 0.01
I1007 13:44:34.350960  4874 solver.cpp:218] Iteration 50300 (12.3412 iter/s, 8.10296s/100 iters), loss = 0.012636
I1007 13:44:34.350991  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0126359 (* 1 = 0.0126359 loss)
I1007 13:44:34.350997  4874 sgd_solver.cpp:105] Iteration 50300, lr = 0.01
I1007 13:44:42.452108  4874 solver.cpp:218] Iteration 50400 (12.344 iter/s, 8.10109s/100 iters), loss = 0.0285223
I1007 13:44:42.452204  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0285222 (* 1 = 0.0285222 loss)
I1007 13:44:42.452211  4874 sgd_solver.cpp:105] Iteration 50400, lr = 0.01
I1007 13:44:50.149145  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:44:50.474175  4874 solver.cpp:330] Iteration 50500, Testing net (#0)
I1007 13:44:52.367498  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:44:52.446179  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9142
I1007 13:44:52.446203  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.311911 (* 1 = 0.311911 loss)
I1007 13:44:52.526182  4874 solver.cpp:218] Iteration 50500 (9.92659 iter/s, 10.0739s/100 iters), loss = 0.00707122
I1007 13:44:52.526211  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00707116 (* 1 = 0.00707116 loss)
I1007 13:44:52.526216  4874 sgd_solver.cpp:105] Iteration 50500, lr = 0.01
I1007 13:45:00.623299  4874 solver.cpp:218] Iteration 50600 (12.3502 iter/s, 8.09706s/100 iters), loss = 0.00939116
I1007 13:45:00.623339  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0093911 (* 1 = 0.0093911 loss)
I1007 13:45:00.623345  4874 sgd_solver.cpp:105] Iteration 50600, lr = 0.01
I1007 13:45:08.730285  4874 solver.cpp:218] Iteration 50700 (12.3351 iter/s, 8.10692s/100 iters), loss = 0.0433081
I1007 13:45:08.730315  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.043308 (* 1 = 0.043308 loss)
I1007 13:45:08.730321  4874 sgd_solver.cpp:105] Iteration 50700, lr = 0.01
I1007 13:45:16.835587  4874 solver.cpp:218] Iteration 50800 (12.3377 iter/s, 8.10524s/100 iters), loss = 0.0222833
I1007 13:45:16.835687  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0222832 (* 1 = 0.0222832 loss)
I1007 13:45:16.835695  4874 sgd_solver.cpp:105] Iteration 50800, lr = 0.01
I1007 13:45:24.941839  4874 solver.cpp:218] Iteration 50900 (12.3363 iter/s, 8.10613s/100 iters), loss = 0.00992623
I1007 13:45:24.941869  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00992616 (* 1 = 0.00992616 loss)
I1007 13:45:24.941885  4874 sgd_solver.cpp:105] Iteration 50900, lr = 0.01
I1007 13:45:32.640667  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:45:32.965198  4874 solver.cpp:330] Iteration 51000, Testing net (#0)
I1007 13:45:34.856811  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:45:34.935789  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9173
I1007 13:45:34.935823  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.295805 (* 1 = 0.295805 loss)
I1007 13:45:35.016432  4874 solver.cpp:218] Iteration 51000 (9.92602 iter/s, 10.0745s/100 iters), loss = 0.0056961
I1007 13:45:35.016458  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00569602 (* 1 = 0.00569602 loss)
I1007 13:45:35.016464  4874 sgd_solver.cpp:105] Iteration 51000, lr = 0.01
I1007 13:45:43.112344  4874 solver.cpp:218] Iteration 51100 (12.352 iter/s, 8.09586s/100 iters), loss = 0.0168396
I1007 13:45:43.112373  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0168395 (* 1 = 0.0168395 loss)
I1007 13:45:43.112378  4874 sgd_solver.cpp:105] Iteration 51100, lr = 0.01
I1007 13:45:51.197690  4874 solver.cpp:218] Iteration 51200 (12.3681 iter/s, 8.08529s/100 iters), loss = 0.0550879
I1007 13:45:51.197768  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0550879 (* 1 = 0.0550879 loss)
I1007 13:45:51.197785  4874 sgd_solver.cpp:105] Iteration 51200, lr = 0.01
I1007 13:45:59.287045  4874 solver.cpp:218] Iteration 51300 (12.3621 iter/s, 8.08925s/100 iters), loss = 0.0289463
I1007 13:45:59.287075  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0289462 (* 1 = 0.0289462 loss)
I1007 13:45:59.287081  4874 sgd_solver.cpp:105] Iteration 51300, lr = 0.01
I1007 13:46:07.381117  4874 solver.cpp:218] Iteration 51400 (12.3548 iter/s, 8.09401s/100 iters), loss = 0.0265395
I1007 13:46:07.381157  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0265394 (* 1 = 0.0265394 loss)
I1007 13:46:07.381163  4874 sgd_solver.cpp:105] Iteration 51400, lr = 0.01
I1007 13:46:15.072336  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:46:15.396967  4874 solver.cpp:330] Iteration 51500, Testing net (#0)
I1007 13:46:17.289101  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:46:17.367873  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9188
I1007 13:46:17.367909  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.299037 (* 1 = 0.299037 loss)
I1007 13:46:17.448468  4874 solver.cpp:218] Iteration 51500 (9.93317 iter/s, 10.0673s/100 iters), loss = 0.0177713
I1007 13:46:17.448496  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0177713 (* 1 = 0.0177713 loss)
I1007 13:46:17.448503  4874 sgd_solver.cpp:105] Iteration 51500, lr = 0.01
I1007 13:46:25.540482  4874 solver.cpp:218] Iteration 51600 (12.3579 iter/s, 8.09196s/100 iters), loss = 0.0216401
I1007 13:46:25.540645  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.02164 (* 1 = 0.02164 loss)
I1007 13:46:25.540653  4874 sgd_solver.cpp:105] Iteration 51600, lr = 0.01
I1007 13:46:33.637186  4874 solver.cpp:218] Iteration 51700 (12.351 iter/s, 8.09652s/100 iters), loss = 0.0184032
I1007 13:46:33.637224  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0184031 (* 1 = 0.0184031 loss)
I1007 13:46:33.637230  4874 sgd_solver.cpp:105] Iteration 51700, lr = 0.01
I1007 13:46:41.734069  4874 solver.cpp:218] Iteration 51800 (12.3505 iter/s, 8.09682s/100 iters), loss = 0.0299824
I1007 13:46:41.734109  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0299823 (* 1 = 0.0299823 loss)
I1007 13:46:41.734115  4874 sgd_solver.cpp:105] Iteration 51800, lr = 0.01
I1007 13:46:49.829599  4874 solver.cpp:218] Iteration 51900 (12.3526 iter/s, 8.09546s/100 iters), loss = 0.0102159
I1007 13:46:49.829629  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0102158 (* 1 = 0.0102158 loss)
I1007 13:46:49.829635  4874 sgd_solver.cpp:105] Iteration 51900, lr = 0.01
I1007 13:46:57.517932  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:46:57.841478  4874 solver.cpp:330] Iteration 52000, Testing net (#0)
I1007 13:46:59.732888  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:46:59.812192  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9156
I1007 13:46:59.812216  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.304734 (* 1 = 0.304734 loss)
I1007 13:46:59.892652  4874 solver.cpp:218] Iteration 52000 (9.9374 iter/s, 10.063s/100 iters), loss = 0.0278291
I1007 13:46:59.892680  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.027829 (* 1 = 0.027829 loss)
I1007 13:46:59.892688  4874 sgd_solver.cpp:105] Iteration 52000, lr = 0.01
I1007 13:47:08.005322  4874 solver.cpp:218] Iteration 52100 (12.3265 iter/s, 8.11262s/100 iters), loss = 0.0113604
I1007 13:47:08.005363  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0113603 (* 1 = 0.0113603 loss)
I1007 13:47:08.005369  4874 sgd_solver.cpp:105] Iteration 52100, lr = 0.01
I1007 13:47:16.111378  4874 solver.cpp:218] Iteration 52200 (12.3366 iter/s, 8.10599s/100 iters), loss = 0.0394015
I1007 13:47:16.111418  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0394014 (* 1 = 0.0394014 loss)
I1007 13:47:16.111424  4874 sgd_solver.cpp:105] Iteration 52200, lr = 0.01
I1007 13:47:24.220873  4874 solver.cpp:218] Iteration 52300 (12.3313 iter/s, 8.10943s/100 iters), loss = 0.00912088
I1007 13:47:24.220903  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00912082 (* 1 = 0.00912082 loss)
I1007 13:47:24.220909  4874 sgd_solver.cpp:105] Iteration 52300, lr = 0.01
I1007 13:47:32.323779  4874 solver.cpp:218] Iteration 52400 (12.3413 iter/s, 8.10285s/100 iters), loss = 0.0150244
I1007 13:47:32.323909  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0150244 (* 1 = 0.0150244 loss)
I1007 13:47:32.323915  4874 sgd_solver.cpp:105] Iteration 52400, lr = 0.01
I1007 13:47:40.031806  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:47:40.356770  4874 solver.cpp:330] Iteration 52500, Testing net (#0)
I1007 13:47:42.248591  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:47:42.327381  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9165
I1007 13:47:42.327416  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.3056 (* 1 = 0.3056 loss)
I1007 13:47:42.408572  4874 solver.cpp:218] Iteration 52500 (9.91607 iter/s, 10.0846s/100 iters), loss = 0.0575993
I1007 13:47:42.408601  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0575992 (* 1 = 0.0575992 loss)
I1007 13:47:42.408607  4874 sgd_solver.cpp:105] Iteration 52500, lr = 0.01
I1007 13:47:50.505059  4874 solver.cpp:218] Iteration 52600 (12.3511 iter/s, 8.09643s/100 iters), loss = 0.0441619
I1007 13:47:50.505087  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0441618 (* 1 = 0.0441618 loss)
I1007 13:47:50.505093  4874 sgd_solver.cpp:105] Iteration 52600, lr = 0.01
I1007 13:47:58.603193  4874 solver.cpp:218] Iteration 52700 (12.3486 iter/s, 8.09808s/100 iters), loss = 0.0201078
I1007 13:47:58.603232  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0201077 (* 1 = 0.0201077 loss)
I1007 13:47:58.603238  4874 sgd_solver.cpp:105] Iteration 52700, lr = 0.01
I1007 13:48:06.704308  4874 solver.cpp:218] Iteration 52800 (12.3441 iter/s, 8.10105s/100 iters), loss = 0.0116916
I1007 13:48:06.704386  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0116915 (* 1 = 0.0116915 loss)
I1007 13:48:06.704404  4874 sgd_solver.cpp:105] Iteration 52800, lr = 0.01
I1007 13:48:14.806180  4874 solver.cpp:218] Iteration 52900 (12.343 iter/s, 8.10177s/100 iters), loss = 0.0105188
I1007 13:48:14.806218  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0105188 (* 1 = 0.0105188 loss)
I1007 13:48:14.806226  4874 sgd_solver.cpp:105] Iteration 52900, lr = 0.01
I1007 13:48:22.495779  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:48:22.819936  4874 solver.cpp:330] Iteration 53000, Testing net (#0)
I1007 13:48:24.711088  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:48:24.790432  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9151
I1007 13:48:24.790467  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.310942 (* 1 = 0.310942 loss)
I1007 13:48:24.871070  4874 solver.cpp:218] Iteration 53000 (9.9356 iter/s, 10.0648s/100 iters), loss = 0.00489654
I1007 13:48:24.871099  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00489648 (* 1 = 0.00489648 loss)
I1007 13:48:24.871106  4874 sgd_solver.cpp:105] Iteration 53000, lr = 0.01
I1007 13:48:32.970680  4874 solver.cpp:218] Iteration 53100 (12.3464 iter/s, 8.09955s/100 iters), loss = 0.0216024
I1007 13:48:32.970721  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0216024 (* 1 = 0.0216024 loss)
I1007 13:48:32.970726  4874 sgd_solver.cpp:105] Iteration 53100, lr = 0.01
I1007 13:48:41.061552  4874 solver.cpp:218] Iteration 53200 (12.3597 iter/s, 8.09081s/100 iters), loss = 0.0115551
I1007 13:48:41.061655  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.011555 (* 1 = 0.011555 loss)
I1007 13:48:41.061669  4874 sgd_solver.cpp:105] Iteration 53200, lr = 0.01
I1007 13:48:49.158794  4874 solver.cpp:218] Iteration 53300 (12.3501 iter/s, 8.09712s/100 iters), loss = 0.0216117
I1007 13:48:49.158824  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0216116 (* 1 = 0.0216116 loss)
I1007 13:48:49.158830  4874 sgd_solver.cpp:105] Iteration 53300, lr = 0.01
I1007 13:48:57.254572  4874 solver.cpp:218] Iteration 53400 (12.3522 iter/s, 8.09572s/100 iters), loss = 0.0149647
I1007 13:48:57.254603  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0149646 (* 1 = 0.0149646 loss)
I1007 13:48:57.254609  4874 sgd_solver.cpp:105] Iteration 53400, lr = 0.01
I1007 13:49:04.950989  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:49:05.274911  4874 solver.cpp:330] Iteration 53500, Testing net (#0)
I1007 13:49:07.170104  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:49:07.249253  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9126
I1007 13:49:07.249286  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.333147 (* 1 = 0.333147 loss)
I1007 13:49:07.329609  4874 solver.cpp:218] Iteration 53500 (9.92559 iter/s, 10.075s/100 iters), loss = 0.0119661
I1007 13:49:07.329635  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0119661 (* 1 = 0.0119661 loss)
I1007 13:49:07.329643  4874 sgd_solver.cpp:105] Iteration 53500, lr = 0.01
I1007 13:49:15.425290  4874 solver.cpp:218] Iteration 53600 (12.3523 iter/s, 8.09563s/100 iters), loss = 0.0334558
I1007 13:49:15.425449  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0334557 (* 1 = 0.0334557 loss)
I1007 13:49:15.425457  4874 sgd_solver.cpp:105] Iteration 53600, lr = 0.01
I1007 13:49:23.530583  4874 solver.cpp:218] Iteration 53700 (12.3379 iter/s, 8.10512s/100 iters), loss = 0.031353
I1007 13:49:23.530612  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0313529 (* 1 = 0.0313529 loss)
I1007 13:49:23.530618  4874 sgd_solver.cpp:105] Iteration 53700, lr = 0.01
I1007 13:49:31.624640  4874 solver.cpp:218] Iteration 53800 (12.3548 iter/s, 8.094s/100 iters), loss = 0.0183308
I1007 13:49:31.624680  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0183307 (* 1 = 0.0183307 loss)
I1007 13:49:31.624686  4874 sgd_solver.cpp:105] Iteration 53800, lr = 0.01
I1007 13:49:39.721149  4874 solver.cpp:218] Iteration 53900 (12.3511 iter/s, 8.09644s/100 iters), loss = 0.0175379
I1007 13:49:39.721190  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0175378 (* 1 = 0.0175378 loss)
I1007 13:49:39.721196  4874 sgd_solver.cpp:105] Iteration 53900, lr = 0.01
I1007 13:49:47.421352  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:49:47.746179  4874 solver.cpp:330] Iteration 54000, Testing net (#0)
I1007 13:49:49.637105  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:49:49.716145  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9124
I1007 13:49:49.716181  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.320559 (* 1 = 0.320559 loss)
I1007 13:49:49.797060  4874 solver.cpp:218] Iteration 54000 (9.92474 iter/s, 10.0758s/100 iters), loss = 0.0108761
I1007 13:49:49.797085  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.010876 (* 1 = 0.010876 loss)
I1007 13:49:49.797091  4874 sgd_solver.cpp:105] Iteration 54000, lr = 0.01
I1007 13:49:57.902225  4874 solver.cpp:218] Iteration 54100 (12.3379 iter/s, 8.10511s/100 iters), loss = 0.0174143
I1007 13:49:57.902256  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0174142 (* 1 = 0.0174142 loss)
I1007 13:49:57.902272  4874 sgd_solver.cpp:105] Iteration 54100, lr = 0.01
I1007 13:50:06.000491  4874 solver.cpp:218] Iteration 54200 (12.3484 iter/s, 8.09821s/100 iters), loss = 0.0836583
I1007 13:50:06.000522  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0836582 (* 1 = 0.0836582 loss)
I1007 13:50:06.000540  4874 sgd_solver.cpp:105] Iteration 54200, lr = 0.01
I1007 13:50:14.104037  4874 solver.cpp:218] Iteration 54300 (12.3404 iter/s, 8.10349s/100 iters), loss = 0.0208519
I1007 13:50:14.104065  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0208518 (* 1 = 0.0208518 loss)
I1007 13:50:14.104071  4874 sgd_solver.cpp:105] Iteration 54300, lr = 0.01
I1007 13:50:22.204293  4874 solver.cpp:218] Iteration 54400 (12.3454 iter/s, 8.1002s/100 iters), loss = 0.00266888
I1007 13:50:22.204452  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00266883 (* 1 = 0.00266883 loss)
I1007 13:50:22.204461  4874 sgd_solver.cpp:105] Iteration 54400, lr = 0.01
I1007 13:50:29.898877  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:50:30.223464  4874 solver.cpp:330] Iteration 54500, Testing net (#0)
I1007 13:50:32.115289  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:50:32.194509  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9186
I1007 13:50:32.194545  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.30226 (* 1 = 0.30226 loss)
I1007 13:50:32.274989  4874 solver.cpp:218] Iteration 54500 (9.92998 iter/s, 10.0705s/100 iters), loss = 0.00455767
I1007 13:50:32.275022  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00455761 (* 1 = 0.00455761 loss)
I1007 13:50:32.275029  4874 sgd_solver.cpp:105] Iteration 54500, lr = 0.01
I1007 13:50:40.361155  4874 solver.cpp:218] Iteration 54600 (12.3669 iter/s, 8.08611s/100 iters), loss = 0.0131026
I1007 13:50:40.361194  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0131026 (* 1 = 0.0131026 loss)
I1007 13:50:40.361201  4874 sgd_solver.cpp:105] Iteration 54600, lr = 0.01
I1007 13:50:48.455966  4874 solver.cpp:218] Iteration 54700 (12.3537 iter/s, 8.09475s/100 iters), loss = 0.0205904
I1007 13:50:48.456008  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0205903 (* 1 = 0.0205903 loss)
I1007 13:50:48.456014  4874 sgd_solver.cpp:105] Iteration 54700, lr = 0.01
I1007 13:50:56.546332  4874 solver.cpp:218] Iteration 54800 (12.3605 iter/s, 8.0903s/100 iters), loss = 0.00492906
I1007 13:50:56.546432  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00492899 (* 1 = 0.00492899 loss)
I1007 13:50:56.546439  4874 sgd_solver.cpp:105] Iteration 54800, lr = 0.01
I1007 13:51:04.640574  4874 solver.cpp:218] Iteration 54900 (12.3547 iter/s, 8.09412s/100 iters), loss = 0.0310972
I1007 13:51:04.640614  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0310971 (* 1 = 0.0310971 loss)
I1007 13:51:04.640620  4874 sgd_solver.cpp:105] Iteration 54900, lr = 0.01
I1007 13:51:12.332734  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:51:12.657099  4874 solver.cpp:330] Iteration 55000, Testing net (#0)
I1007 13:51:14.548826  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:51:14.627784  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9174
I1007 13:51:14.627818  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.303601 (* 1 = 0.303601 loss)
I1007 13:51:14.708775  4874 solver.cpp:218] Iteration 55000 (9.93233 iter/s, 10.0681s/100 iters), loss = 0.0114228
I1007 13:51:14.708806  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0114227 (* 1 = 0.0114227 loss)
I1007 13:51:14.708811  4874 sgd_solver.cpp:105] Iteration 55000, lr = 0.01
I1007 13:51:22.810606  4874 solver.cpp:218] Iteration 55100 (12.343 iter/s, 8.10177s/100 iters), loss = 0.0163195
I1007 13:51:22.810647  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0163194 (* 1 = 0.0163194 loss)
I1007 13:51:22.810653  4874 sgd_solver.cpp:105] Iteration 55100, lr = 0.01
I1007 13:51:30.912189  4874 solver.cpp:218] Iteration 55200 (12.3434 iter/s, 8.10151s/100 iters), loss = 0.0345507
I1007 13:51:30.912297  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0345506 (* 1 = 0.0345506 loss)
I1007 13:51:30.912314  4874 sgd_solver.cpp:105] Iteration 55200, lr = 0.01
I1007 13:51:39.017680  4874 solver.cpp:218] Iteration 55300 (12.3375 iter/s, 8.10536s/100 iters), loss = 0.0375276
I1007 13:51:39.017720  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0375276 (* 1 = 0.0375276 loss)
I1007 13:51:39.017726  4874 sgd_solver.cpp:105] Iteration 55300, lr = 0.01
I1007 13:51:47.118762  4874 solver.cpp:218] Iteration 55400 (12.3441 iter/s, 8.10102s/100 iters), loss = 0.00575292
I1007 13:51:47.118803  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00575287 (* 1 = 0.00575287 loss)
I1007 13:51:47.118809  4874 sgd_solver.cpp:105] Iteration 55400, lr = 0.01
I1007 13:51:54.821884  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:51:55.146914  4874 solver.cpp:330] Iteration 55500, Testing net (#0)
I1007 13:51:57.039783  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:51:57.119041  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9163
I1007 13:51:57.119078  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.317877 (* 1 = 0.317877 loss)
I1007 13:51:57.200229  4874 solver.cpp:218] Iteration 55500 (9.91926 iter/s, 10.0814s/100 iters), loss = 0.00974106
I1007 13:51:57.200258  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00974101 (* 1 = 0.00974101 loss)
I1007 13:51:57.200265  4874 sgd_solver.cpp:105] Iteration 55500, lr = 0.01
I1007 13:52:05.302806  4874 solver.cpp:218] Iteration 55600 (12.3418 iter/s, 8.10252s/100 iters), loss = 0.0129884
I1007 13:52:05.302981  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0129884 (* 1 = 0.0129884 loss)
I1007 13:52:05.303000  4874 sgd_solver.cpp:105] Iteration 55600, lr = 0.01
I1007 13:52:13.409916  4874 solver.cpp:218] Iteration 55700 (12.3352 iter/s, 8.10691s/100 iters), loss = 0.0325427
I1007 13:52:13.409957  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0325426 (* 1 = 0.0325426 loss)
I1007 13:52:13.409963  4874 sgd_solver.cpp:105] Iteration 55700, lr = 0.01
I1007 13:52:21.511103  4874 solver.cpp:218] Iteration 55800 (12.344 iter/s, 8.10112s/100 iters), loss = 0.031374
I1007 13:52:21.511142  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.031374 (* 1 = 0.031374 loss)
I1007 13:52:21.511147  4874 sgd_solver.cpp:105] Iteration 55800, lr = 0.01
I1007 13:52:29.617897  4874 solver.cpp:218] Iteration 55900 (12.3354 iter/s, 8.10673s/100 iters), loss = 0.00314369
I1007 13:52:29.617935  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00314364 (* 1 = 0.00314364 loss)
I1007 13:52:29.617941  4874 sgd_solver.cpp:105] Iteration 55900, lr = 0.01
I1007 13:52:37.321990  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:52:37.646294  4874 solver.cpp:330] Iteration 56000, Testing net (#0)
I1007 13:52:39.536280  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:52:39.615519  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9149
I1007 13:52:39.615553  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.326346 (* 1 = 0.326346 loss)
I1007 13:52:39.695986  4874 solver.cpp:218] Iteration 56000 (9.92259 iter/s, 10.078s/100 iters), loss = 0.0154269
I1007 13:52:39.696019  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0154269 (* 1 = 0.0154269 loss)
I1007 13:52:39.696027  4874 sgd_solver.cpp:105] Iteration 56000, lr = 0.01
I1007 13:52:47.793874  4874 solver.cpp:218] Iteration 56100 (12.349 iter/s, 8.09783s/100 iters), loss = 0.00553151
I1007 13:52:47.793905  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00553145 (* 1 = 0.00553145 loss)
I1007 13:52:47.793920  4874 sgd_solver.cpp:105] Iteration 56100, lr = 0.01
I1007 13:52:55.890194  4874 solver.cpp:218] Iteration 56200 (12.3514 iter/s, 8.09626s/100 iters), loss = 0.00613844
I1007 13:52:55.890224  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00613839 (* 1 = 0.00613839 loss)
I1007 13:52:55.890240  4874 sgd_solver.cpp:105] Iteration 56200, lr = 0.01
I1007 13:53:03.994151  4874 solver.cpp:218] Iteration 56300 (12.3397 iter/s, 8.1039s/100 iters), loss = 0.0124818
I1007 13:53:03.994192  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0124818 (* 1 = 0.0124818 loss)
I1007 13:53:03.994199  4874 sgd_solver.cpp:105] Iteration 56300, lr = 0.01
I1007 13:53:12.090154  4874 solver.cpp:218] Iteration 56400 (12.3519 iter/s, 8.09594s/100 iters), loss = 0.0156534
I1007 13:53:12.090260  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0156533 (* 1 = 0.0156533 loss)
I1007 13:53:12.090276  4874 sgd_solver.cpp:105] Iteration 56400, lr = 0.01
I1007 13:53:19.785542  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:53:20.109874  4874 solver.cpp:330] Iteration 56500, Testing net (#0)
I1007 13:53:22.002163  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:53:22.080986  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9169
I1007 13:53:22.081022  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.319644 (* 1 = 0.319644 loss)
I1007 13:53:22.162222  4874 solver.cpp:218] Iteration 56500 (9.92858 iter/s, 10.0719s/100 iters), loss = 0.00814478
I1007 13:53:22.162251  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00814472 (* 1 = 0.00814472 loss)
I1007 13:53:22.162258  4874 sgd_solver.cpp:105] Iteration 56500, lr = 0.01
I1007 13:53:30.262315  4874 solver.cpp:218] Iteration 56600 (12.3456 iter/s, 8.10004s/100 iters), loss = 0.0108297
I1007 13:53:30.262356  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0108296 (* 1 = 0.0108296 loss)
I1007 13:53:30.262363  4874 sgd_solver.cpp:105] Iteration 56600, lr = 0.01
I1007 13:53:38.373006  4874 solver.cpp:218] Iteration 56700 (12.3295 iter/s, 8.11062s/100 iters), loss = 0.0168818
I1007 13:53:38.373046  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0168818 (* 1 = 0.0168818 loss)
I1007 13:53:38.373052  4874 sgd_solver.cpp:105] Iteration 56700, lr = 0.01
I1007 13:53:46.474544  4874 solver.cpp:218] Iteration 56800 (12.3434 iter/s, 8.10147s/100 iters), loss = 0.00765359
I1007 13:53:46.474663  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00765353 (* 1 = 0.00765353 loss)
I1007 13:53:46.474680  4874 sgd_solver.cpp:105] Iteration 56800, lr = 0.01
I1007 13:53:54.585428  4874 solver.cpp:218] Iteration 56900 (12.3293 iter/s, 8.11074s/100 iters), loss = 0.00661887
I1007 13:53:54.585469  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00661881 (* 1 = 0.00661881 loss)
I1007 13:53:54.585476  4874 sgd_solver.cpp:105] Iteration 56900, lr = 0.01
I1007 13:54:02.288672  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:54:02.613418  4874 solver.cpp:330] Iteration 57000, Testing net (#0)
I1007 13:54:04.505650  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:54:04.584607  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9172
I1007 13:54:04.584643  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.32539 (* 1 = 0.32539 loss)
I1007 13:54:04.664870  4874 solver.cpp:218] Iteration 57000 (9.92126 iter/s, 10.0794s/100 iters), loss = 0.0273006
I1007 13:54:04.664897  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0273005 (* 1 = 0.0273005 loss)
I1007 13:54:04.664903  4874 sgd_solver.cpp:105] Iteration 57000, lr = 0.01
I1007 13:54:12.774983  4874 solver.cpp:218] Iteration 57100 (12.3304 iter/s, 8.11006s/100 iters), loss = 0.0112961
I1007 13:54:12.775023  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0112961 (* 1 = 0.0112961 loss)
I1007 13:54:12.775029  4874 sgd_solver.cpp:105] Iteration 57100, lr = 0.01
I1007 13:54:20.874524  4874 solver.cpp:218] Iteration 57200 (12.3465 iter/s, 8.09947s/100 iters), loss = 0.0104516
I1007 13:54:20.874632  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0104515 (* 1 = 0.0104515 loss)
I1007 13:54:20.874639  4874 sgd_solver.cpp:105] Iteration 57200, lr = 0.01
I1007 13:54:28.981400  4874 solver.cpp:218] Iteration 57300 (12.3354 iter/s, 8.10675s/100 iters), loss = 0.0282032
I1007 13:54:28.981441  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0282031 (* 1 = 0.0282031 loss)
I1007 13:54:28.981446  4874 sgd_solver.cpp:105] Iteration 57300, lr = 0.01
I1007 13:54:37.086462  4874 solver.cpp:218] Iteration 57400 (12.3381 iter/s, 8.10499s/100 iters), loss = 0.0406276
I1007 13:54:37.086503  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0406275 (* 1 = 0.0406275 loss)
I1007 13:54:37.086509  4874 sgd_solver.cpp:105] Iteration 57400, lr = 0.01
I1007 13:54:44.792023  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:54:45.117216  4874 solver.cpp:330] Iteration 57500, Testing net (#0)
I1007 13:54:47.009423  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:54:47.088697  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9159
I1007 13:54:47.088721  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.331473 (* 1 = 0.331473 loss)
I1007 13:54:47.169505  4874 solver.cpp:218] Iteration 57500 (9.91771 iter/s, 10.083s/100 iters), loss = 0.00576828
I1007 13:54:47.169534  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00576823 (* 1 = 0.00576823 loss)
I1007 13:54:47.169541  4874 sgd_solver.cpp:105] Iteration 57500, lr = 0.01
I1007 13:54:55.258013  4874 solver.cpp:218] Iteration 57600 (12.3633 iter/s, 8.08845s/100 iters), loss = 0.00273619
I1007 13:54:55.258105  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00273616 (* 1 = 0.00273616 loss)
I1007 13:54:55.258113  4874 sgd_solver.cpp:105] Iteration 57600, lr = 0.01
I1007 13:55:03.353832  4874 solver.cpp:218] Iteration 57700 (12.3522 iter/s, 8.0957s/100 iters), loss = 0.0111672
I1007 13:55:03.353873  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0111672 (* 1 = 0.0111672 loss)
I1007 13:55:03.353879  4874 sgd_solver.cpp:105] Iteration 57700, lr = 0.01
I1007 13:55:11.442701  4874 solver.cpp:218] Iteration 57800 (12.3628 iter/s, 8.0888s/100 iters), loss = 0.0100268
I1007 13:55:11.442733  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0100267 (* 1 = 0.0100267 loss)
I1007 13:55:11.442739  4874 sgd_solver.cpp:105] Iteration 57800, lr = 0.01
I1007 13:55:19.537231  4874 solver.cpp:218] Iteration 57900 (12.3541 iter/s, 8.09447s/100 iters), loss = 0.020617
I1007 13:55:19.537262  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0206169 (* 1 = 0.0206169 loss)
I1007 13:55:19.537268  4874 sgd_solver.cpp:105] Iteration 57900, lr = 0.01
I1007 13:55:27.225610  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:55:27.549547  4874 solver.cpp:330] Iteration 58000, Testing net (#0)
I1007 13:55:29.439802  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:55:29.519174  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9168
I1007 13:55:29.519208  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.324158 (* 1 = 0.324158 loss)
I1007 13:55:29.600229  4874 solver.cpp:218] Iteration 58000 (9.93746 iter/s, 10.0629s/100 iters), loss = 0.0055315
I1007 13:55:29.600255  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00553147 (* 1 = 0.00553147 loss)
I1007 13:55:29.600262  4874 sgd_solver.cpp:105] Iteration 58000, lr = 0.01
I1007 13:55:37.703757  4874 solver.cpp:218] Iteration 58100 (12.3404 iter/s, 8.10348s/100 iters), loss = 0.00956867
I1007 13:55:37.703795  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00956864 (* 1 = 0.00956864 loss)
I1007 13:55:37.703801  4874 sgd_solver.cpp:105] Iteration 58100, lr = 0.01
I1007 13:55:45.800796  4874 solver.cpp:218] Iteration 58200 (12.3503 iter/s, 8.09698s/100 iters), loss = 0.0149138
I1007 13:55:45.800835  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0149137 (* 1 = 0.0149137 loss)
I1007 13:55:45.800842  4874 sgd_solver.cpp:105] Iteration 58200, lr = 0.01
I1007 13:55:53.903403  4874 solver.cpp:218] Iteration 58300 (12.3418 iter/s, 8.10254s/100 iters), loss = 0.0064357
I1007 13:55:53.903443  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00643565 (* 1 = 0.00643565 loss)
I1007 13:55:53.903448  4874 sgd_solver.cpp:105] Iteration 58300, lr = 0.01
I1007 13:56:02.003070  4874 solver.cpp:218] Iteration 58400 (12.3463 iter/s, 8.0996s/100 iters), loss = 0.0297839
I1007 13:56:02.003156  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0297838 (* 1 = 0.0297838 loss)
I1007 13:56:02.003180  4874 sgd_solver.cpp:105] Iteration 58400, lr = 0.01
I1007 13:56:09.700520  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:56:10.025053  4874 solver.cpp:330] Iteration 58500, Testing net (#0)
I1007 13:56:11.917057  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:56:11.995970  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9178
I1007 13:56:11.996006  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.325859 (* 1 = 0.325859 loss)
I1007 13:56:12.076905  4874 solver.cpp:218] Iteration 58500 (9.92682 iter/s, 10.0737s/100 iters), loss = 0.000861702
I1007 13:56:12.076931  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000861662 (* 1 = 0.000861662 loss)
I1007 13:56:12.076938  4874 sgd_solver.cpp:105] Iteration 58500, lr = 0.01
I1007 13:56:20.175221  4874 solver.cpp:218] Iteration 58600 (12.3483 iter/s, 8.09826s/100 iters), loss = 0.00401629
I1007 13:56:20.175261  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00401624 (* 1 = 0.00401624 loss)
I1007 13:56:20.175268  4874 sgd_solver.cpp:105] Iteration 58600, lr = 0.01
I1007 13:56:28.278846  4874 solver.cpp:218] Iteration 58700 (12.3403 iter/s, 8.10356s/100 iters), loss = 0.00958669
I1007 13:56:28.278885  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00958664 (* 1 = 0.00958664 loss)
I1007 13:56:28.278892  4874 sgd_solver.cpp:105] Iteration 58700, lr = 0.01
I1007 13:56:36.373358  4874 solver.cpp:218] Iteration 58800 (12.3541 iter/s, 8.09445s/100 iters), loss = 0.0161107
I1007 13:56:36.373513  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0161106 (* 1 = 0.0161106 loss)
I1007 13:56:36.373522  4874 sgd_solver.cpp:105] Iteration 58800, lr = 0.01
I1007 13:56:44.476670  4874 solver.cpp:218] Iteration 58900 (12.3409 iter/s, 8.10314s/100 iters), loss = 0.00145458
I1007 13:56:44.476711  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00145452 (* 1 = 0.00145452 loss)
I1007 13:56:44.476717  4874 sgd_solver.cpp:105] Iteration 58900, lr = 0.01
I1007 13:56:52.175582  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:56:52.500643  4874 solver.cpp:330] Iteration 59000, Testing net (#0)
I1007 13:56:54.391266  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:56:54.470716  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9124
I1007 13:56:54.470751  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.359724 (* 1 = 0.359724 loss)
I1007 13:56:54.551494  4874 solver.cpp:218] Iteration 59000 (9.9258 iter/s, 10.0748s/100 iters), loss = 0.0397157
I1007 13:56:54.551527  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0397156 (* 1 = 0.0397156 loss)
I1007 13:56:54.551535  4874 sgd_solver.cpp:105] Iteration 59000, lr = 0.01
I1007 13:57:02.658789  4874 solver.cpp:218] Iteration 59100 (12.3347 iter/s, 8.10724s/100 iters), loss = 0.00810136
I1007 13:57:02.658830  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00810131 (* 1 = 0.00810131 loss)
I1007 13:57:02.658838  4874 sgd_solver.cpp:105] Iteration 59100, lr = 0.01
I1007 13:57:10.754030  4874 solver.cpp:218] Iteration 59200 (12.353 iter/s, 8.09517s/100 iters), loss = 0.0159981
I1007 13:57:10.754163  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0159981 (* 1 = 0.0159981 loss)
I1007 13:57:10.754170  4874 sgd_solver.cpp:105] Iteration 59200, lr = 0.01
I1007 13:57:18.857108  4874 solver.cpp:218] Iteration 59300 (12.3412 iter/s, 8.10293s/100 iters), loss = 0.0141507
I1007 13:57:18.857156  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0141507 (* 1 = 0.0141507 loss)
I1007 13:57:18.857164  4874 sgd_solver.cpp:105] Iteration 59300, lr = 0.01
I1007 13:57:26.955139  4874 solver.cpp:218] Iteration 59400 (12.3488 iter/s, 8.09796s/100 iters), loss = 0.00686997
I1007 13:57:26.955183  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00686993 (* 1 = 0.00686993 loss)
I1007 13:57:26.955189  4874 sgd_solver.cpp:105] Iteration 59400, lr = 0.01
I1007 13:57:34.655092  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:57:34.980093  4874 solver.cpp:330] Iteration 59500, Testing net (#0)
I1007 13:57:36.870107  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:57:36.949201  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.912
I1007 13:57:36.949236  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.36416 (* 1 = 0.36416 loss)
I1007 13:57:37.030905  4874 solver.cpp:218] Iteration 59500 (9.92488 iter/s, 10.0757s/100 iters), loss = 0.0255018
I1007 13:57:37.030936  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0255017 (* 1 = 0.0255017 loss)
I1007 13:57:37.030943  4874 sgd_solver.cpp:105] Iteration 59500, lr = 0.01
I1007 13:57:45.137607  4874 solver.cpp:218] Iteration 59600 (12.3356 iter/s, 8.10665s/100 iters), loss = 0.0125751
I1007 13:57:45.137763  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0125751 (* 1 = 0.0125751 loss)
I1007 13:57:45.137770  4874 sgd_solver.cpp:105] Iteration 59600, lr = 0.01
I1007 13:57:53.247592  4874 solver.cpp:218] Iteration 59700 (12.3308 iter/s, 8.1098s/100 iters), loss = 0.00726059
I1007 13:57:53.247633  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00726053 (* 1 = 0.00726053 loss)
I1007 13:57:53.247639  4874 sgd_solver.cpp:105] Iteration 59700, lr = 0.01
I1007 13:58:01.352360  4874 solver.cpp:218] Iteration 59800 (12.3385 iter/s, 8.1047s/100 iters), loss = 0.0070435
I1007 13:58:01.352401  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00704343 (* 1 = 0.00704343 loss)
I1007 13:58:01.352406  4874 sgd_solver.cpp:105] Iteration 59800, lr = 0.01
I1007 13:58:09.461525  4874 solver.cpp:218] Iteration 59900 (12.3318 iter/s, 8.1091s/100 iters), loss = 0.00561849
I1007 13:58:09.461565  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00561841 (* 1 = 0.00561841 loss)
I1007 13:58:09.461571  4874 sgd_solver.cpp:105] Iteration 59900, lr = 0.01
I1007 13:58:17.159257  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:58:17.483150  4874 solver.cpp:330] Iteration 60000, Testing net (#0)
I1007 13:58:19.374647  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:58:19.453713  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9138
I1007 13:58:19.453747  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.355547 (* 1 = 0.355547 loss)
I1007 13:58:19.533918  4874 solver.cpp:218] Iteration 60000 (9.9282 iter/s, 10.0723s/100 iters), loss = 0.0477202
I1007 13:58:19.533962  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0477201 (* 1 = 0.0477201 loss)
I1007 13:58:19.533968  4874 sgd_solver.cpp:105] Iteration 60000, lr = 0.01
I1007 13:58:27.640377  4874 solver.cpp:218] Iteration 60100 (12.3359 iter/s, 8.10639s/100 iters), loss = 0.0154767
I1007 13:58:27.640417  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0154766 (* 1 = 0.0154766 loss)
I1007 13:58:27.640424  4874 sgd_solver.cpp:105] Iteration 60100, lr = 0.01
I1007 13:58:35.736281  4874 solver.cpp:218] Iteration 60200 (12.352 iter/s, 8.09584s/100 iters), loss = 0.0086937
I1007 13:58:35.736321  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00869363 (* 1 = 0.00869363 loss)
I1007 13:58:35.736327  4874 sgd_solver.cpp:105] Iteration 60200, lr = 0.01
I1007 13:58:43.851402  4874 solver.cpp:218] Iteration 60300 (12.3228 iter/s, 8.11506s/100 iters), loss = 0.0135208
I1007 13:58:43.851442  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0135207 (* 1 = 0.0135207 loss)
I1007 13:58:43.851449  4874 sgd_solver.cpp:105] Iteration 60300, lr = 0.01
I1007 13:58:51.954494  4874 solver.cpp:218] Iteration 60400 (12.3411 iter/s, 8.10303s/100 iters), loss = 0.00534174
I1007 13:58:51.954598  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00534166 (* 1 = 0.00534166 loss)
I1007 13:58:51.954607  4874 sgd_solver.cpp:105] Iteration 60400, lr = 0.01
I1007 13:58:59.659018  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:58:59.983930  4874 solver.cpp:330] Iteration 60500, Testing net (#0)
I1007 13:59:01.876504  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:59:01.955837  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9198
I1007 13:59:01.955871  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.311882 (* 1 = 0.311882 loss)
I1007 13:59:02.036269  4874 solver.cpp:218] Iteration 60500 (9.91902 iter/s, 10.0816s/100 iters), loss = 0.00858312
I1007 13:59:02.036298  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00858305 (* 1 = 0.00858305 loss)
I1007 13:59:02.036303  4874 sgd_solver.cpp:105] Iteration 60500, lr = 0.01
I1007 13:59:10.127871  4874 solver.cpp:218] Iteration 60600 (12.3586 iter/s, 8.09155s/100 iters), loss = 0.00177278
I1007 13:59:10.127910  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0017727 (* 1 = 0.0017727 loss)
I1007 13:59:10.127916  4874 sgd_solver.cpp:105] Iteration 60600, lr = 0.01
I1007 13:59:18.221366  4874 solver.cpp:218] Iteration 60700 (12.3557 iter/s, 8.09343s/100 iters), loss = 0.00986812
I1007 13:59:18.221406  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00986803 (* 1 = 0.00986803 loss)
I1007 13:59:18.221413  4874 sgd_solver.cpp:105] Iteration 60700, lr = 0.01
I1007 13:59:26.311173  4874 solver.cpp:218] Iteration 60800 (12.3613 iter/s, 8.08974s/100 iters), loss = 0.00326622
I1007 13:59:26.311336  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00326614 (* 1 = 0.00326614 loss)
I1007 13:59:26.311345  4874 sgd_solver.cpp:105] Iteration 60800, lr = 0.01
I1007 13:59:34.405637  4874 solver.cpp:218] Iteration 60900 (12.3544 iter/s, 8.09428s/100 iters), loss = 0.00850334
I1007 13:59:34.405676  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00850326 (* 1 = 0.00850326 loss)
I1007 13:59:34.405683  4874 sgd_solver.cpp:105] Iteration 60900, lr = 0.01
I1007 13:59:42.091928  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:59:42.417150  4874 solver.cpp:330] Iteration 61000, Testing net (#0)
I1007 13:59:44.308507  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 13:59:44.387033  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9168
I1007 13:59:44.387069  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.324359 (* 1 = 0.324359 loss)
I1007 13:59:44.467937  4874 solver.cpp:218] Iteration 61000 (9.93816 iter/s, 10.0622s/100 iters), loss = 0.00599442
I1007 13:59:44.467963  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00599434 (* 1 = 0.00599434 loss)
I1007 13:59:44.467970  4874 sgd_solver.cpp:105] Iteration 61000, lr = 0.01
I1007 13:59:52.572845  4874 solver.cpp:218] Iteration 61100 (12.3383 iter/s, 8.10486s/100 iters), loss = 0.0110059
I1007 13:59:52.572886  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0110058 (* 1 = 0.0110058 loss)
I1007 13:59:52.572892  4874 sgd_solver.cpp:105] Iteration 61100, lr = 0.01
I1007 14:00:00.669901  4874 solver.cpp:218] Iteration 61200 (12.3503 iter/s, 8.09699s/100 iters), loss = 0.00854918
I1007 14:00:00.669977  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00854909 (* 1 = 0.00854909 loss)
I1007 14:00:00.669984  4874 sgd_solver.cpp:105] Iteration 61200, lr = 0.01
I1007 14:00:08.772941  4874 solver.cpp:218] Iteration 61300 (12.3412 iter/s, 8.10294s/100 iters), loss = 0.0145362
I1007 14:00:08.772984  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0145361 (* 1 = 0.0145361 loss)
I1007 14:00:08.772989  4874 sgd_solver.cpp:105] Iteration 61300, lr = 0.01
I1007 14:00:16.868242  4874 solver.cpp:218] Iteration 61400 (12.3529 iter/s, 8.09523s/100 iters), loss = 0.0216742
I1007 14:00:16.868283  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0216741 (* 1 = 0.0216741 loss)
I1007 14:00:16.868289  4874 sgd_solver.cpp:105] Iteration 61400, lr = 0.01
I1007 14:00:24.569409  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:00:24.893849  4874 solver.cpp:330] Iteration 61500, Testing net (#0)
I1007 14:00:26.785217  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:00:26.864135  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9148
I1007 14:00:26.864168  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.330911 (* 1 = 0.330911 loss)
I1007 14:00:26.945047  4874 solver.cpp:218] Iteration 61500 (9.92385 iter/s, 10.0767s/100 iters), loss = 0.00271316
I1007 14:00:26.945075  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00271306 (* 1 = 0.00271306 loss)
I1007 14:00:26.945082  4874 sgd_solver.cpp:105] Iteration 61500, lr = 0.01
I1007 14:00:35.042183  4874 solver.cpp:218] Iteration 61600 (12.3501 iter/s, 8.09708s/100 iters), loss = 0.00956866
I1007 14:00:35.042317  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00956856 (* 1 = 0.00956856 loss)
I1007 14:00:35.042325  4874 sgd_solver.cpp:105] Iteration 61600, lr = 0.01
I1007 14:00:43.147200  4874 solver.cpp:218] Iteration 61700 (12.3383 iter/s, 8.10487s/100 iters), loss = 0.0677603
I1007 14:00:43.147240  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0677601 (* 1 = 0.0677601 loss)
I1007 14:00:43.147246  4874 sgd_solver.cpp:105] Iteration 61700, lr = 0.01
I1007 14:00:51.246758  4874 solver.cpp:218] Iteration 61800 (12.3465 iter/s, 8.09949s/100 iters), loss = 0.00974376
I1007 14:00:51.246799  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00974366 (* 1 = 0.00974366 loss)
I1007 14:00:51.246805  4874 sgd_solver.cpp:105] Iteration 61800, lr = 0.01
I1007 14:00:59.349146  4874 solver.cpp:218] Iteration 61900 (12.3421 iter/s, 8.10232s/100 iters), loss = 0.00513813
I1007 14:00:59.349186  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00513801 (* 1 = 0.00513801 loss)
I1007 14:00:59.349192  4874 sgd_solver.cpp:105] Iteration 61900, lr = 0.01
I1007 14:01:07.050467  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:01:07.376010  4874 solver.cpp:330] Iteration 62000, Testing net (#0)
I1007 14:01:09.265991  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:01:09.345137  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9175
I1007 14:01:09.345171  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.321675 (* 1 = 0.321675 loss)
I1007 14:01:09.425987  4874 solver.cpp:218] Iteration 62000 (9.92381 iter/s, 10.0768s/100 iters), loss = 0.0870869
I1007 14:01:09.426013  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0870868 (* 1 = 0.0870868 loss)
I1007 14:01:09.426019  4874 sgd_solver.cpp:105] Iteration 62000, lr = 0.01
I1007 14:01:17.533493  4874 solver.cpp:218] Iteration 62100 (12.3343 iter/s, 8.10745s/100 iters), loss = 0.00465348
I1007 14:01:17.533535  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00465335 (* 1 = 0.00465335 loss)
I1007 14:01:17.533540  4874 sgd_solver.cpp:105] Iteration 62100, lr = 0.01
I1007 14:01:25.633718  4874 solver.cpp:218] Iteration 62200 (12.3454 iter/s, 8.10016s/100 iters), loss = 0.00444952
I1007 14:01:25.633757  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00444939 (* 1 = 0.00444939 loss)
I1007 14:01:25.633764  4874 sgd_solver.cpp:105] Iteration 62200, lr = 0.01
I1007 14:01:33.737257  4874 solver.cpp:218] Iteration 62300 (12.3404 iter/s, 8.10347s/100 iters), loss = 0.00702856
I1007 14:01:33.737296  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00702843 (* 1 = 0.00702843 loss)
I1007 14:01:33.737303  4874 sgd_solver.cpp:105] Iteration 62300, lr = 0.01
I1007 14:01:41.834529  4874 solver.cpp:218] Iteration 62400 (12.3499 iter/s, 8.09721s/100 iters), loss = 0.0232146
I1007 14:01:41.834648  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0232145 (* 1 = 0.0232145 loss)
I1007 14:01:41.834666  4874 sgd_solver.cpp:105] Iteration 62400, lr = 0.01
I1007 14:01:49.532757  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:01:49.858064  4874 solver.cpp:330] Iteration 62500, Testing net (#0)
I1007 14:01:51.747432  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:01:51.826694  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9149
I1007 14:01:51.826727  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.347239 (* 1 = 0.347239 loss)
I1007 14:01:51.907655  4874 solver.cpp:218] Iteration 62500 (9.92755 iter/s, 10.073s/100 iters), loss = 0.00424193
I1007 14:01:51.907685  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0042418 (* 1 = 0.0042418 loss)
I1007 14:01:51.907691  4874 sgd_solver.cpp:105] Iteration 62500, lr = 0.01
I1007 14:02:00.013861  4874 solver.cpp:218] Iteration 62600 (12.3363 iter/s, 8.10615s/100 iters), loss = 0.0264061
I1007 14:02:00.013902  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.026406 (* 1 = 0.026406 loss)
I1007 14:02:00.013908  4874 sgd_solver.cpp:105] Iteration 62600, lr = 0.01
I1007 14:02:08.122467  4874 solver.cpp:218] Iteration 62700 (12.3327 iter/s, 8.10854s/100 iters), loss = 0.017058
I1007 14:02:08.122505  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0170579 (* 1 = 0.0170579 loss)
I1007 14:02:08.122511  4874 sgd_solver.cpp:105] Iteration 62700, lr = 0.01
I1007 14:02:16.229154  4874 solver.cpp:218] Iteration 62800 (12.3356 iter/s, 8.10662s/100 iters), loss = 0.00642016
I1007 14:02:16.229295  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00642003 (* 1 = 0.00642003 loss)
I1007 14:02:16.229312  4874 sgd_solver.cpp:105] Iteration 62800, lr = 0.01
I1007 14:02:24.335283  4874 solver.cpp:218] Iteration 62900 (12.3366 iter/s, 8.10596s/100 iters), loss = 0.0035224
I1007 14:02:24.335325  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00352228 (* 1 = 0.00352228 loss)
I1007 14:02:24.335330  4874 sgd_solver.cpp:105] Iteration 62900, lr = 0.01
I1007 14:02:32.039615  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:02:32.364775  4874 solver.cpp:330] Iteration 63000, Testing net (#0)
I1007 14:02:34.256952  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:02:34.335824  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9156
I1007 14:02:34.335849  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.333715 (* 1 = 0.333715 loss)
I1007 14:02:34.416931  4874 solver.cpp:218] Iteration 63000 (9.91908 iter/s, 10.0816s/100 iters), loss = 0.00690741
I1007 14:02:34.416960  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00690728 (* 1 = 0.00690728 loss)
I1007 14:02:34.416966  4874 sgd_solver.cpp:105] Iteration 63000, lr = 0.01
I1007 14:02:42.522071  4874 solver.cpp:218] Iteration 63100 (12.3379 iter/s, 8.10508s/100 iters), loss = 0.045015
I1007 14:02:42.522101  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0450148 (* 1 = 0.0450148 loss)
I1007 14:02:42.522109  4874 sgd_solver.cpp:105] Iteration 63100, lr = 0.01
I1007 14:02:50.617092  4874 solver.cpp:218] Iteration 63200 (12.3534 iter/s, 8.09496s/100 iters), loss = 0.0270243
I1007 14:02:50.617202  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0270241 (* 1 = 0.0270241 loss)
I1007 14:02:50.617221  4874 sgd_solver.cpp:105] Iteration 63200, lr = 0.01
I1007 14:02:58.719764  4874 solver.cpp:218] Iteration 63300 (12.3418 iter/s, 8.10254s/100 iters), loss = 0.0474123
I1007 14:02:58.719805  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0474121 (* 1 = 0.0474121 loss)
I1007 14:02:58.719810  4874 sgd_solver.cpp:105] Iteration 63300, lr = 0.01
I1007 14:03:06.818655  4874 solver.cpp:218] Iteration 63400 (12.3475 iter/s, 8.09882s/100 iters), loss = 0.0189401
I1007 14:03:06.818696  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0189399 (* 1 = 0.0189399 loss)
I1007 14:03:06.818701  4874 sgd_solver.cpp:105] Iteration 63400, lr = 0.01
I1007 14:03:14.523490  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:03:14.848837  4874 solver.cpp:330] Iteration 63500, Testing net (#0)
I1007 14:03:16.739176  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:03:16.818254  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.909
I1007 14:03:16.818289  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.35761 (* 1 = 0.35761 loss)
I1007 14:03:16.899299  4874 solver.cpp:218] Iteration 63500 (9.92007 iter/s, 10.0806s/100 iters), loss = 0.00218295
I1007 14:03:16.899328  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00218281 (* 1 = 0.00218281 loss)
I1007 14:03:16.899335  4874 sgd_solver.cpp:105] Iteration 63500, lr = 0.01
I1007 14:03:24.982092  4874 solver.cpp:218] Iteration 63600 (12.372 iter/s, 8.08274s/100 iters), loss = 0.00898036
I1007 14:03:24.982213  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00898023 (* 1 = 0.00898023 loss)
I1007 14:03:24.982219  4874 sgd_solver.cpp:105] Iteration 63600, lr = 0.01
I1007 14:03:33.074895  4874 solver.cpp:218] Iteration 63700 (12.3569 iter/s, 8.09266s/100 iters), loss = 0.00875727
I1007 14:03:33.074935  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00875714 (* 1 = 0.00875714 loss)
I1007 14:03:33.074941  4874 sgd_solver.cpp:105] Iteration 63700, lr = 0.01
I1007 14:03:41.168638  4874 solver.cpp:218] Iteration 63800 (12.3553 iter/s, 8.09368s/100 iters), loss = 0.00491196
I1007 14:03:41.168678  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00491183 (* 1 = 0.00491183 loss)
I1007 14:03:41.168684  4874 sgd_solver.cpp:105] Iteration 63800, lr = 0.01
I1007 14:03:49.262873  4874 solver.cpp:218] Iteration 63900 (12.3546 iter/s, 8.09417s/100 iters), loss = 0.00531734
I1007 14:03:49.262915  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0053172 (* 1 = 0.0053172 loss)
I1007 14:03:49.262922  4874 sgd_solver.cpp:105] Iteration 63900, lr = 0.01
I1007 14:03:56.953430  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:03:57.278095  4874 solver.cpp:330] Iteration 64000, Testing net (#0)
I1007 14:03:59.175009  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:03:59.254328  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9093
I1007 14:03:59.254364  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.359785 (* 1 = 0.359785 loss)
I1007 14:03:59.334929  4874 solver.cpp:218] Iteration 64000 (9.92853 iter/s, 10.072s/100 iters), loss = 0.00307935
I1007 14:03:59.334964  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0030792 (* 1 = 0.0030792 loss)
I1007 14:03:59.334970  4874 sgd_solver.cpp:105] Iteration 64000, lr = 0.01
I1007 14:04:07.435233  4874 solver.cpp:218] Iteration 64100 (12.3453 iter/s, 8.10024s/100 iters), loss = 0.00555726
I1007 14:04:07.435263  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00555712 (* 1 = 0.00555712 loss)
I1007 14:04:07.435269  4874 sgd_solver.cpp:105] Iteration 64100, lr = 0.01
I1007 14:04:15.529510  4874 solver.cpp:218] Iteration 64200 (12.3545 iter/s, 8.09422s/100 iters), loss = 0.00289903
I1007 14:04:15.529549  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00289888 (* 1 = 0.00289888 loss)
I1007 14:04:15.529556  4874 sgd_solver.cpp:105] Iteration 64200, lr = 0.01
I1007 14:04:23.630302  4874 solver.cpp:218] Iteration 64300 (12.3446 iter/s, 8.10073s/100 iters), loss = 0.0195501
I1007 14:04:23.630342  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.01955 (* 1 = 0.01955 loss)
I1007 14:04:23.630349  4874 sgd_solver.cpp:105] Iteration 64300, lr = 0.01
I1007 14:04:31.727644  4874 solver.cpp:218] Iteration 64400 (12.3498 iter/s, 8.09728s/100 iters), loss = 0.00505181
I1007 14:04:31.727764  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00505167 (* 1 = 0.00505167 loss)
I1007 14:04:31.727782  4874 sgd_solver.cpp:105] Iteration 64400, lr = 0.01
I1007 14:04:39.431533  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:04:39.756148  4874 solver.cpp:330] Iteration 64500, Testing net (#0)
I1007 14:04:41.646817  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:04:41.725791  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9165
I1007 14:04:41.725826  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.352744 (* 1 = 0.352744 loss)
I1007 14:04:41.807217  4874 solver.cpp:218] Iteration 64500 (9.9212 iter/s, 10.0794s/100 iters), loss = 0.00946808
I1007 14:04:41.807246  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00946795 (* 1 = 0.00946795 loss)
I1007 14:04:41.807253  4874 sgd_solver.cpp:105] Iteration 64500, lr = 0.01
I1007 14:04:49.909543  4874 solver.cpp:218] Iteration 64600 (12.3422 iter/s, 8.10227s/100 iters), loss = 0.00263984
I1007 14:04:49.909574  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0026397 (* 1 = 0.0026397 loss)
I1007 14:04:49.909579  4874 sgd_solver.cpp:105] Iteration 64600, lr = 0.01
I1007 14:04:58.015619  4874 solver.cpp:218] Iteration 64700 (12.3365 iter/s, 8.10602s/100 iters), loss = 0.0256417
I1007 14:04:58.015661  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0256416 (* 1 = 0.0256416 loss)
I1007 14:04:58.015666  4874 sgd_solver.cpp:105] Iteration 64700, lr = 0.01
I1007 14:05:06.120172  4874 solver.cpp:218] Iteration 64800 (12.3388 iter/s, 8.10449s/100 iters), loss = 0.00619114
I1007 14:05:06.120324  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00619099 (* 1 = 0.00619099 loss)
I1007 14:05:06.120332  4874 sgd_solver.cpp:105] Iteration 64800, lr = 0.01
I1007 14:05:14.225145  4874 solver.cpp:218] Iteration 64900 (12.3384 iter/s, 8.10481s/100 iters), loss = 0.0155288
I1007 14:05:14.225175  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0155286 (* 1 = 0.0155286 loss)
I1007 14:05:14.225181  4874 sgd_solver.cpp:105] Iteration 64900, lr = 0.01
I1007 14:05:21.922675  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:05:22.246803  4874 solver.cpp:330] Iteration 65000, Testing net (#0)
I1007 14:05:24.139087  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:05:24.218462  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9142
I1007 14:05:24.218487  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.344777 (* 1 = 0.344777 loss)
I1007 14:05:24.299376  4874 solver.cpp:218] Iteration 65000 (9.92638 iter/s, 10.0742s/100 iters), loss = 0.00146828
I1007 14:05:24.299404  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00146813 (* 1 = 0.00146813 loss)
I1007 14:05:24.299412  4874 sgd_solver.cpp:105] Iteration 65000, lr = 0.01
I1007 14:05:32.400748  4874 solver.cpp:218] Iteration 65100 (12.3437 iter/s, 8.10131s/100 iters), loss = 0.00784203
I1007 14:05:32.400779  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00784187 (* 1 = 0.00784187 loss)
I1007 14:05:32.400799  4874 sgd_solver.cpp:105] Iteration 65100, lr = 0.01
I1007 14:05:40.497913  4874 solver.cpp:218] Iteration 65200 (12.3501 iter/s, 8.09711s/100 iters), loss = 0.026471
I1007 14:05:40.498019  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0264708 (* 1 = 0.0264708 loss)
I1007 14:05:40.498026  4874 sgd_solver.cpp:105] Iteration 65200, lr = 0.01
I1007 14:05:48.603451  4874 solver.cpp:218] Iteration 65300 (12.3374 iter/s, 8.10541s/100 iters), loss = 0.00186792
I1007 14:05:48.603480  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00186776 (* 1 = 0.00186776 loss)
I1007 14:05:48.603487  4874 sgd_solver.cpp:105] Iteration 65300, lr = 0.01
I1007 14:05:56.698892  4874 solver.cpp:218] Iteration 65400 (12.3527 iter/s, 8.09539s/100 iters), loss = 0.00546841
I1007 14:05:56.698921  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00546827 (* 1 = 0.00546827 loss)
I1007 14:05:56.698930  4874 sgd_solver.cpp:105] Iteration 65400, lr = 0.01
I1007 14:06:04.401316  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:06:04.725584  4874 solver.cpp:330] Iteration 65500, Testing net (#0)
I1007 14:06:06.617066  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:06:06.696501  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9118
I1007 14:06:06.696542  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.3541 (* 1 = 0.3541 loss)
I1007 14:06:06.777398  4874 solver.cpp:218] Iteration 65500 (9.92216 iter/s, 10.0784s/100 iters), loss = 0.00278029
I1007 14:06:06.777426  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00278014 (* 1 = 0.00278014 loss)
I1007 14:06:06.777433  4874 sgd_solver.cpp:105] Iteration 65500, lr = 0.01
I1007 14:06:14.880349  4874 solver.cpp:218] Iteration 65600 (12.3413 iter/s, 8.1029s/100 iters), loss = 0.00479995
I1007 14:06:14.880493  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00479981 (* 1 = 0.00479981 loss)
I1007 14:06:14.880511  4874 sgd_solver.cpp:105] Iteration 65600, lr = 0.01
I1007 14:06:22.982322  4874 solver.cpp:218] Iteration 65700 (12.3429 iter/s, 8.1018s/100 iters), loss = 0.0328769
I1007 14:06:22.982363  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0328768 (* 1 = 0.0328768 loss)
I1007 14:06:22.982369  4874 sgd_solver.cpp:105] Iteration 65700, lr = 0.01
I1007 14:06:31.077431  4874 solver.cpp:218] Iteration 65800 (12.3532 iter/s, 8.09504s/100 iters), loss = 0.0576828
I1007 14:06:31.077471  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0576827 (* 1 = 0.0576827 loss)
I1007 14:06:31.077477  4874 sgd_solver.cpp:105] Iteration 65800, lr = 0.01
I1007 14:06:39.180364  4874 solver.cpp:218] Iteration 65900 (12.3413 iter/s, 8.10287s/100 iters), loss = 0.00423408
I1007 14:06:39.180394  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00423393 (* 1 = 0.00423393 loss)
I1007 14:06:39.180400  4874 sgd_solver.cpp:105] Iteration 65900, lr = 0.01
I1007 14:06:46.879920  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:06:47.203589  4874 solver.cpp:330] Iteration 66000, Testing net (#0)
I1007 14:06:49.095794  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:06:49.175019  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9094
I1007 14:06:49.175055  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.366187 (* 1 = 0.366187 loss)
I1007 14:06:49.255600  4874 solver.cpp:218] Iteration 66000 (9.92539 iter/s, 10.0752s/100 iters), loss = 0.0200362
I1007 14:06:49.255633  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.020036 (* 1 = 0.020036 loss)
I1007 14:06:49.255640  4874 sgd_solver.cpp:105] Iteration 66000, lr = 0.01
I1007 14:06:57.365676  4874 solver.cpp:218] Iteration 66100 (12.3304 iter/s, 8.11002s/100 iters), loss = 0.0190004
I1007 14:06:57.365717  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0190003 (* 1 = 0.0190003 loss)
I1007 14:06:57.365723  4874 sgd_solver.cpp:105] Iteration 66100, lr = 0.01
I1007 14:07:05.466460  4874 solver.cpp:218] Iteration 66200 (12.3446 iter/s, 8.10072s/100 iters), loss = 0.00802661
I1007 14:07:05.466500  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00802646 (* 1 = 0.00802646 loss)
I1007 14:07:05.466506  4874 sgd_solver.cpp:105] Iteration 66200, lr = 0.01
I1007 14:07:13.577874  4874 solver.cpp:218] Iteration 66300 (12.3284 iter/s, 8.11135s/100 iters), loss = 0.0095752
I1007 14:07:13.577903  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00957505 (* 1 = 0.00957505 loss)
I1007 14:07:13.577920  4874 sgd_solver.cpp:105] Iteration 66300, lr = 0.01
I1007 14:07:21.685451  4874 solver.cpp:218] Iteration 66400 (12.3342 iter/s, 8.10752s/100 iters), loss = 0.00323977
I1007 14:07:21.685534  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00323961 (* 1 = 0.00323961 loss)
I1007 14:07:21.685541  4874 sgd_solver.cpp:105] Iteration 66400, lr = 0.01
I1007 14:07:29.390702  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:07:29.714614  4874 solver.cpp:330] Iteration 66500, Testing net (#0)
I1007 14:07:31.605397  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:07:31.684877  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9153
I1007 14:07:31.684911  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.343335 (* 1 = 0.343335 loss)
I1007 14:07:31.765336  4874 solver.cpp:218] Iteration 66500 (9.92085 iter/s, 10.0798s/100 iters), loss = 0.0136699
I1007 14:07:31.765363  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0136698 (* 1 = 0.0136698 loss)
I1007 14:07:31.765372  4874 sgd_solver.cpp:105] Iteration 66500, lr = 0.01
I1007 14:07:39.860134  4874 solver.cpp:218] Iteration 66600 (12.3537 iter/s, 8.09474s/100 iters), loss = 0.00274085
I1007 14:07:39.860164  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00274069 (* 1 = 0.00274069 loss)
I1007 14:07:39.860170  4874 sgd_solver.cpp:105] Iteration 66600, lr = 0.01
I1007 14:07:47.963695  4874 solver.cpp:218] Iteration 66700 (12.3403 iter/s, 8.1035s/100 iters), loss = 0.00491549
I1007 14:07:47.963726  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00491533 (* 1 = 0.00491533 loss)
I1007 14:07:47.963732  4874 sgd_solver.cpp:105] Iteration 66700, lr = 0.01
I1007 14:07:56.061988  4874 solver.cpp:218] Iteration 66800 (12.3484 iter/s, 8.09824s/100 iters), loss = 0.0275291
I1007 14:07:56.062110  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0275289 (* 1 = 0.0275289 loss)
I1007 14:07:56.062119  4874 sgd_solver.cpp:105] Iteration 66800, lr = 0.01
I1007 14:08:04.170086  4874 solver.cpp:218] Iteration 66900 (12.3336 iter/s, 8.10795s/100 iters), loss = 0.00323527
I1007 14:08:04.170116  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00323511 (* 1 = 0.00323511 loss)
I1007 14:08:04.170122  4874 sgd_solver.cpp:105] Iteration 66900, lr = 0.01
I1007 14:08:11.861645  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:08:12.186609  4874 solver.cpp:330] Iteration 67000, Testing net (#0)
I1007 14:08:14.079390  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:08:14.158406  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9141
I1007 14:08:14.158442  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.347281 (* 1 = 0.347281 loss)
I1007 14:08:14.239286  4874 solver.cpp:218] Iteration 67000 (9.93134 iter/s, 10.0691s/100 iters), loss = 0.00346168
I1007 14:08:14.239320  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00346152 (* 1 = 0.00346152 loss)
I1007 14:08:14.239326  4874 sgd_solver.cpp:105] Iteration 67000, lr = 0.01
I1007 14:08:22.345782  4874 solver.cpp:218] Iteration 67100 (12.3359 iter/s, 8.10644s/100 iters), loss = 0.00369126
I1007 14:08:22.345815  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0036911 (* 1 = 0.0036911 loss)
I1007 14:08:22.345823  4874 sgd_solver.cpp:105] Iteration 67100, lr = 0.01
I1007 14:08:30.446899  4874 solver.cpp:218] Iteration 67200 (12.3441 iter/s, 8.10106s/100 iters), loss = 0.0236513
I1007 14:08:30.447005  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0236511 (* 1 = 0.0236511 loss)
I1007 14:08:30.447011  4874 sgd_solver.cpp:105] Iteration 67200, lr = 0.01
I1007 14:08:38.553715  4874 solver.cpp:218] Iteration 67300 (12.3355 iter/s, 8.10669s/100 iters), loss = 0.00108229
I1007 14:08:38.553755  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00108213 (* 1 = 0.00108213 loss)
I1007 14:08:38.553761  4874 sgd_solver.cpp:105] Iteration 67300, lr = 0.01
I1007 14:08:46.651079  4874 solver.cpp:218] Iteration 67400 (12.3498 iter/s, 8.0973s/100 iters), loss = 0.00156784
I1007 14:08:46.651118  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00156767 (* 1 = 0.00156767 loss)
I1007 14:08:46.651125  4874 sgd_solver.cpp:105] Iteration 67400, lr = 0.01
I1007 14:08:54.354812  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:08:54.679354  4874 solver.cpp:330] Iteration 67500, Testing net (#0)
I1007 14:08:56.570871  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:08:56.650002  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9141
I1007 14:08:56.650027  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.339702 (* 1 = 0.339702 loss)
I1007 14:08:56.730722  4874 solver.cpp:218] Iteration 67500 (9.92106 iter/s, 10.0796s/100 iters), loss = 0.00345305
I1007 14:08:56.730751  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00345288 (* 1 = 0.00345288 loss)
I1007 14:08:56.730757  4874 sgd_solver.cpp:105] Iteration 67500, lr = 0.01
I1007 14:09:04.840342  4874 solver.cpp:218] Iteration 67600 (12.3311 iter/s, 8.10956s/100 iters), loss = 0.00982683
I1007 14:09:04.840461  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00982666 (* 1 = 0.00982666 loss)
I1007 14:09:04.840467  4874 sgd_solver.cpp:105] Iteration 67600, lr = 0.01
I1007 14:09:12.951766  4874 solver.cpp:218] Iteration 67700 (12.3285 iter/s, 8.11128s/100 iters), loss = 0.0212265
I1007 14:09:12.951809  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0212264 (* 1 = 0.0212264 loss)
I1007 14:09:12.951815  4874 sgd_solver.cpp:105] Iteration 67700, lr = 0.01
I1007 14:09:21.062572  4874 solver.cpp:218] Iteration 67800 (12.3293 iter/s, 8.11074s/100 iters), loss = 0.0248447
I1007 14:09:21.062613  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0248446 (* 1 = 0.0248446 loss)
I1007 14:09:21.062619  4874 sgd_solver.cpp:105] Iteration 67800, lr = 0.01
I1007 14:09:29.170752  4874 solver.cpp:218] Iteration 67900 (12.3333 iter/s, 8.10811s/100 iters), loss = 0.00456585
I1007 14:09:29.170792  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00456568 (* 1 = 0.00456568 loss)
I1007 14:09:29.170799  4874 sgd_solver.cpp:105] Iteration 67900, lr = 0.01
I1007 14:09:36.877311  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:09:37.202643  4874 solver.cpp:330] Iteration 68000, Testing net (#0)
I1007 14:09:39.094987  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:09:39.173836  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9134
I1007 14:09:39.173871  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.341834 (* 1 = 0.341834 loss)
I1007 14:09:39.253783  4874 solver.cpp:218] Iteration 68000 (9.91773 iter/s, 10.083s/100 iters), loss = 0.00207418
I1007 14:09:39.253815  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00207401 (* 1 = 0.00207401 loss)
I1007 14:09:39.253823  4874 sgd_solver.cpp:105] Iteration 68000, lr = 0.01
I1007 14:09:47.354434  4874 solver.cpp:218] Iteration 68100 (12.3448 iter/s, 8.10059s/100 iters), loss = 0.014503
I1007 14:09:47.354475  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0145029 (* 1 = 0.0145029 loss)
I1007 14:09:47.354481  4874 sgd_solver.cpp:105] Iteration 68100, lr = 0.01
I1007 14:09:55.450284  4874 solver.cpp:218] Iteration 68200 (12.3521 iter/s, 8.09578s/100 iters), loss = 0.0137662
I1007 14:09:55.450325  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0137661 (* 1 = 0.0137661 loss)
I1007 14:09:55.450331  4874 sgd_solver.cpp:105] Iteration 68200, lr = 0.01
I1007 14:10:03.550648  4874 solver.cpp:218] Iteration 68300 (12.3452 iter/s, 8.1003s/100 iters), loss = 0.00532585
I1007 14:10:03.550688  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00532569 (* 1 = 0.00532569 loss)
I1007 14:10:03.550694  4874 sgd_solver.cpp:105] Iteration 68300, lr = 0.01
I1007 14:10:11.643939  4874 solver.cpp:218] Iteration 68400 (12.356 iter/s, 8.09322s/100 iters), loss = 0.0126304
I1007 14:10:11.644044  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0126302 (* 1 = 0.0126302 loss)
I1007 14:10:11.644052  4874 sgd_solver.cpp:105] Iteration 68400, lr = 0.01
I1007 14:10:19.342767  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:10:19.668244  4874 solver.cpp:330] Iteration 68500, Testing net (#0)
I1007 14:10:21.560312  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:10:21.639324  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9171
I1007 14:10:21.639350  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.33238 (* 1 = 0.33238 loss)
I1007 14:10:21.720291  4874 solver.cpp:218] Iteration 68500 (9.92436 iter/s, 10.0762s/100 iters), loss = 0.0277616
I1007 14:10:21.720319  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0277614 (* 1 = 0.0277614 loss)
I1007 14:10:21.720325  4874 sgd_solver.cpp:105] Iteration 68500, lr = 0.01
I1007 14:10:29.827524  4874 solver.cpp:218] Iteration 68600 (12.3347 iter/s, 8.10718s/100 iters), loss = 0.00205791
I1007 14:10:29.827554  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00205776 (* 1 = 0.00205776 loss)
I1007 14:10:29.827560  4874 sgd_solver.cpp:105] Iteration 68600, lr = 0.01
I1007 14:10:37.936426  4874 solver.cpp:218] Iteration 68700 (12.3322 iter/s, 8.10884s/100 iters), loss = 0.00827647
I1007 14:10:37.936466  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00827632 (* 1 = 0.00827632 loss)
I1007 14:10:37.936472  4874 sgd_solver.cpp:105] Iteration 68700, lr = 0.01
I1007 14:10:46.045085  4874 solver.cpp:218] Iteration 68800 (12.3326 iter/s, 8.10859s/100 iters), loss = 0.0233539
I1007 14:10:46.045164  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0233537 (* 1 = 0.0233537 loss)
I1007 14:10:46.045171  4874 sgd_solver.cpp:105] Iteration 68800, lr = 0.01
I1007 14:10:54.154953  4874 solver.cpp:218] Iteration 68900 (12.3308 iter/s, 8.10976s/100 iters), loss = 0.00523867
I1007 14:10:54.154994  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0052385 (* 1 = 0.0052385 loss)
I1007 14:10:54.154999  4874 sgd_solver.cpp:105] Iteration 68900, lr = 0.01
I1007 14:11:01.855347  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:11:02.179055  4874 solver.cpp:330] Iteration 69000, Testing net (#0)
I1007 14:11:04.071038  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:11:04.149766  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9151
I1007 14:11:04.149801  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.339491 (* 1 = 0.339491 loss)
I1007 14:11:04.230880  4874 solver.cpp:218] Iteration 69000 (9.92473 iter/s, 10.0758s/100 iters), loss = 0.00698387
I1007 14:11:04.230936  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0069837 (* 1 = 0.0069837 loss)
I1007 14:11:04.230943  4874 sgd_solver.cpp:105] Iteration 69000, lr = 0.01
I1007 14:11:12.335261  4874 solver.cpp:218] Iteration 69100 (12.3391 iter/s, 8.10431s/100 iters), loss = 0.00319476
I1007 14:11:12.335291  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00319459 (* 1 = 0.00319459 loss)
I1007 14:11:12.335309  4874 sgd_solver.cpp:105] Iteration 69100, lr = 0.01
I1007 14:11:20.427757  4874 solver.cpp:218] Iteration 69200 (12.3572 iter/s, 8.09244s/100 iters), loss = 0.0286741
I1007 14:11:20.427847  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.028674 (* 1 = 0.028674 loss)
I1007 14:11:20.427853  4874 sgd_solver.cpp:105] Iteration 69200, lr = 0.01
I1007 14:11:28.529165  4874 solver.cpp:218] Iteration 69300 (12.3437 iter/s, 8.10129s/100 iters), loss = 0.00754566
I1007 14:11:28.529194  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00754548 (* 1 = 0.00754548 loss)
I1007 14:11:28.529201  4874 sgd_solver.cpp:105] Iteration 69300, lr = 0.01
I1007 14:11:36.620870  4874 solver.cpp:218] Iteration 69400 (12.3584 iter/s, 8.09165s/100 iters), loss = 0.00241109
I1007 14:11:36.620910  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00241091 (* 1 = 0.00241091 loss)
I1007 14:11:36.620916  4874 sgd_solver.cpp:105] Iteration 69400, lr = 0.01
I1007 14:11:44.305668  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:11:44.629655  4874 solver.cpp:330] Iteration 69500, Testing net (#0)
I1007 14:11:46.520746  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:11:46.599756  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9157
I1007 14:11:46.599781  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.352793 (* 1 = 0.352793 loss)
I1007 14:11:46.680395  4874 solver.cpp:218] Iteration 69500 (9.9409 iter/s, 10.0595s/100 iters), loss = 0.00242317
I1007 14:11:46.680433  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00242299 (* 1 = 0.00242299 loss)
I1007 14:11:46.680438  4874 sgd_solver.cpp:105] Iteration 69500, lr = 0.01
I1007 14:11:54.777459  4874 solver.cpp:218] Iteration 69600 (12.3503 iter/s, 8.097s/100 iters), loss = 0.0129614
I1007 14:11:54.777577  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0129612 (* 1 = 0.0129612 loss)
I1007 14:11:54.777585  4874 sgd_solver.cpp:105] Iteration 69600, lr = 0.01
I1007 14:12:02.881759  4874 solver.cpp:218] Iteration 69700 (12.3393 iter/s, 8.10416s/100 iters), loss = 0.0133304
I1007 14:12:02.881788  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0133302 (* 1 = 0.0133302 loss)
I1007 14:12:02.881793  4874 sgd_solver.cpp:105] Iteration 69700, lr = 0.01
I1007 14:12:10.983017  4874 solver.cpp:218] Iteration 69800 (12.3438 iter/s, 8.1012s/100 iters), loss = 0.00371722
I1007 14:12:10.983047  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00371704 (* 1 = 0.00371704 loss)
I1007 14:12:10.983053  4874 sgd_solver.cpp:105] Iteration 69800, lr = 0.01
I1007 14:12:19.086830  4874 solver.cpp:218] Iteration 69900 (12.34 iter/s, 8.10376s/100 iters), loss = 0.00566609
I1007 14:12:19.086860  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00566591 (* 1 = 0.00566591 loss)
I1007 14:12:19.086877  4874 sgd_solver.cpp:105] Iteration 69900, lr = 0.01
I1007 14:12:26.779251  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:12:27.104358  4874 solver.cpp:330] Iteration 70000, Testing net (#0)
I1007 14:12:28.996575  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:12:29.075903  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9077
I1007 14:12:29.075928  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.366508 (* 1 = 0.366508 loss)
I1007 14:12:29.156937  4874 solver.cpp:218] Iteration 70000 (9.93044 iter/s, 10.07s/100 iters), loss = 0.0081896
I1007 14:12:29.156965  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00818942 (* 1 = 0.00818942 loss)
I1007 14:12:29.156972  4874 sgd_solver.cpp:105] Iteration 70000, lr = 0.01
I1007 14:12:37.252848  4874 solver.cpp:218] Iteration 70100 (12.352 iter/s, 8.09585s/100 iters), loss = 0.00545438
I1007 14:12:37.252878  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00545421 (* 1 = 0.00545421 loss)
I1007 14:12:37.252884  4874 sgd_solver.cpp:105] Iteration 70100, lr = 0.01
I1007 14:12:45.346369  4874 solver.cpp:218] Iteration 70200 (12.3557 iter/s, 8.09346s/100 iters), loss = 0.0260997
I1007 14:12:45.346400  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0260995 (* 1 = 0.0260995 loss)
I1007 14:12:45.346406  4874 sgd_solver.cpp:105] Iteration 70200, lr = 0.01
I1007 14:12:53.444267  4874 solver.cpp:218] Iteration 70300 (12.349 iter/s, 8.09784s/100 iters), loss = 0.0105493
I1007 14:12:53.444298  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0105491 (* 1 = 0.0105491 loss)
I1007 14:12:53.444303  4874 sgd_solver.cpp:105] Iteration 70300, lr = 0.01
I1007 14:13:01.543653  4874 solver.cpp:218] Iteration 70400 (12.3467 iter/s, 8.09933s/100 iters), loss = 0.00678396
I1007 14:13:01.543773  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00678379 (* 1 = 0.00678379 loss)
I1007 14:13:01.543792  4874 sgd_solver.cpp:105] Iteration 70400, lr = 0.01
I1007 14:13:09.244369  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:13:09.569262  4874 solver.cpp:330] Iteration 70500, Testing net (#0)
I1007 14:13:11.460000  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:13:11.539108  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9129
I1007 14:13:11.539142  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.357482 (* 1 = 0.357482 loss)
I1007 14:13:11.620031  4874 solver.cpp:218] Iteration 70500 (9.92435 iter/s, 10.0762s/100 iters), loss = 0.00150438
I1007 14:13:11.620060  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0015042 (* 1 = 0.0015042 loss)
I1007 14:13:11.620067  4874 sgd_solver.cpp:105] Iteration 70500, lr = 0.01
I1007 14:13:19.721402  4874 solver.cpp:218] Iteration 70600 (12.3437 iter/s, 8.10131s/100 iters), loss = 0.0055254
I1007 14:13:19.721432  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00552522 (* 1 = 0.00552522 loss)
I1007 14:13:19.721438  4874 sgd_solver.cpp:105] Iteration 70600, lr = 0.01
I1007 14:13:27.826349  4874 solver.cpp:218] Iteration 70700 (12.3382 iter/s, 8.10489s/100 iters), loss = 0.00655113
I1007 14:13:27.826390  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00655096 (* 1 = 0.00655096 loss)
I1007 14:13:27.826395  4874 sgd_solver.cpp:105] Iteration 70700, lr = 0.01
I1007 14:13:35.926739  4874 solver.cpp:218] Iteration 70800 (12.3452 iter/s, 8.10032s/100 iters), loss = 0.00502623
I1007 14:13:35.926895  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00502606 (* 1 = 0.00502606 loss)
I1007 14:13:35.926903  4874 sgd_solver.cpp:105] Iteration 70800, lr = 0.01
I1007 14:13:44.038842  4874 solver.cpp:218] Iteration 70900 (12.3275 iter/s, 8.11193s/100 iters), loss = 0.00299531
I1007 14:13:44.038882  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00299514 (* 1 = 0.00299514 loss)
I1007 14:13:44.038888  4874 sgd_solver.cpp:105] Iteration 70900, lr = 0.01
I1007 14:13:51.743196  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:13:52.067782  4874 solver.cpp:330] Iteration 71000, Testing net (#0)
I1007 14:13:53.960494  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:13:54.039400  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9158
I1007 14:13:54.039427  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.346595 (* 1 = 0.346595 loss)
I1007 14:13:54.120306  4874 solver.cpp:218] Iteration 71000 (9.91927 iter/s, 10.0814s/100 iters), loss = 0.0121698
I1007 14:13:54.120332  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0121697 (* 1 = 0.0121697 loss)
I1007 14:13:54.120337  4874 sgd_solver.cpp:105] Iteration 71000, lr = 0.01
I1007 14:14:02.218066  4874 solver.cpp:218] Iteration 71100 (12.3492 iter/s, 8.09771s/100 iters), loss = 0.0201978
I1007 14:14:02.218097  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0201976 (* 1 = 0.0201976 loss)
I1007 14:14:02.218103  4874 sgd_solver.cpp:105] Iteration 71100, lr = 0.01
I1007 14:14:10.312202  4874 solver.cpp:218] Iteration 71200 (12.3547 iter/s, 8.09408s/100 iters), loss = 0.0271657
I1007 14:14:10.312346  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0271655 (* 1 = 0.0271655 loss)
I1007 14:14:10.312353  4874 sgd_solver.cpp:105] Iteration 71200, lr = 0.01
I1007 14:14:18.408915  4874 solver.cpp:218] Iteration 71300 (12.351 iter/s, 8.09654s/100 iters), loss = 0.0046005
I1007 14:14:18.408943  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00460034 (* 1 = 0.00460034 loss)
I1007 14:14:18.408949  4874 sgd_solver.cpp:105] Iteration 71300, lr = 0.01
I1007 14:14:26.499800  4874 solver.cpp:218] Iteration 71400 (12.3597 iter/s, 8.09083s/100 iters), loss = 0.012966
I1007 14:14:26.499830  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0129659 (* 1 = 0.0129659 loss)
I1007 14:14:26.499836  4874 sgd_solver.cpp:105] Iteration 71400, lr = 0.01
I1007 14:14:34.189553  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:14:34.514288  4874 solver.cpp:330] Iteration 71500, Testing net (#0)
I1007 14:14:36.404656  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:14:36.483945  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9154
I1007 14:14:36.483969  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.339868 (* 1 = 0.339868 loss)
I1007 14:14:36.564973  4874 solver.cpp:218] Iteration 71500 (9.93531 iter/s, 10.0651s/100 iters), loss = 0.0054895
I1007 14:14:36.565001  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00548934 (* 1 = 0.00548934 loss)
I1007 14:14:36.565008  4874 sgd_solver.cpp:105] Iteration 71500, lr = 0.01
I1007 14:14:44.661125  4874 solver.cpp:218] Iteration 71600 (12.3516 iter/s, 8.0961s/100 iters), loss = 0.0130223
I1007 14:14:44.661273  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0130221 (* 1 = 0.0130221 loss)
I1007 14:14:44.661279  4874 sgd_solver.cpp:105] Iteration 71600, lr = 0.01
I1007 14:14:52.766860  4874 solver.cpp:218] Iteration 71700 (12.3372 iter/s, 8.10557s/100 iters), loss = 0.0237902
I1007 14:14:52.766901  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0237901 (* 1 = 0.0237901 loss)
I1007 14:14:52.766906  4874 sgd_solver.cpp:105] Iteration 71700, lr = 0.01
I1007 14:15:00.871160  4874 solver.cpp:218] Iteration 71800 (12.3392 iter/s, 8.10423s/100 iters), loss = 0.023375
I1007 14:15:00.871192  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0233749 (* 1 = 0.0233749 loss)
I1007 14:15:00.871209  4874 sgd_solver.cpp:105] Iteration 71800, lr = 0.01
I1007 14:15:08.977536  4874 solver.cpp:218] Iteration 71900 (12.3361 iter/s, 8.10632s/100 iters), loss = 0.00404088
I1007 14:15:08.977577  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00404071 (* 1 = 0.00404071 loss)
I1007 14:15:08.977583  4874 sgd_solver.cpp:105] Iteration 71900, lr = 0.01
I1007 14:15:16.675721  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:15:16.999799  4874 solver.cpp:330] Iteration 72000, Testing net (#0)
I1007 14:15:18.893060  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:15:18.972231  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9074
I1007 14:15:18.972257  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.390084 (* 1 = 0.390084 loss)
I1007 14:15:19.052839  4874 solver.cpp:218] Iteration 72000 (9.92533 iter/s, 10.0752s/100 iters), loss = 0.00162861
I1007 14:15:19.052866  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00162844 (* 1 = 0.00162844 loss)
I1007 14:15:19.052875  4874 sgd_solver.cpp:105] Iteration 72000, lr = 0.01
I1007 14:15:27.152112  4874 solver.cpp:218] Iteration 72100 (12.3469 iter/s, 8.09922s/100 iters), loss = 0.0580266
I1007 14:15:27.152140  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0580264 (* 1 = 0.0580264 loss)
I1007 14:15:27.152146  4874 sgd_solver.cpp:105] Iteration 72100, lr = 0.01
I1007 14:15:35.237932  4874 solver.cpp:218] Iteration 72200 (12.3674 iter/s, 8.08576s/100 iters), loss = 0.0133939
I1007 14:15:35.237973  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0133937 (* 1 = 0.0133937 loss)
I1007 14:15:35.237980  4874 sgd_solver.cpp:105] Iteration 72200, lr = 0.01
I1007 14:15:43.339706  4874 solver.cpp:218] Iteration 72300 (12.3431 iter/s, 8.10171s/100 iters), loss = 0.00479654
I1007 14:15:43.339735  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00479637 (* 1 = 0.00479637 loss)
I1007 14:15:43.339742  4874 sgd_solver.cpp:105] Iteration 72300, lr = 0.01
I1007 14:15:51.430694  4874 solver.cpp:218] Iteration 72400 (12.3595 iter/s, 8.09093s/100 iters), loss = 0.0181054
I1007 14:15:51.430784  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0181053 (* 1 = 0.0181053 loss)
I1007 14:15:51.430802  4874 sgd_solver.cpp:105] Iteration 72400, lr = 0.01
I1007 14:15:59.126168  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:15:59.451489  4874 solver.cpp:330] Iteration 72500, Testing net (#0)
I1007 14:16:01.341325  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:16:01.420379  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.906
I1007 14:16:01.420404  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.389785 (* 1 = 0.389785 loss)
I1007 14:16:01.501173  4874 solver.cpp:218] Iteration 72500 (9.93013 iter/s, 10.0704s/100 iters), loss = 0.00406007
I1007 14:16:01.501202  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0040599 (* 1 = 0.0040599 loss)
I1007 14:16:01.501209  4874 sgd_solver.cpp:105] Iteration 72500, lr = 0.01
I1007 14:16:09.601078  4874 solver.cpp:218] Iteration 72600 (12.3459 iter/s, 8.09985s/100 iters), loss = 0.00152759
I1007 14:16:09.601125  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00152742 (* 1 = 0.00152742 loss)
I1007 14:16:09.601132  4874 sgd_solver.cpp:105] Iteration 72600, lr = 0.01
I1007 14:16:17.689092  4874 solver.cpp:218] Iteration 72700 (12.3641 iter/s, 8.08794s/100 iters), loss = 0.0139794
I1007 14:16:17.689139  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0139792 (* 1 = 0.0139792 loss)
I1007 14:16:17.689146  4874 sgd_solver.cpp:105] Iteration 72700, lr = 0.01
I1007 14:16:25.782621  4874 solver.cpp:218] Iteration 72800 (12.3557 iter/s, 8.09345s/100 iters), loss = 0.00209971
I1007 14:16:25.782778  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00209954 (* 1 = 0.00209954 loss)
I1007 14:16:25.782796  4874 sgd_solver.cpp:105] Iteration 72800, lr = 0.01
I1007 14:16:33.883867  4874 solver.cpp:218] Iteration 72900 (12.3441 iter/s, 8.10106s/100 iters), loss = 0.0229105
I1007 14:16:33.883913  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0229103 (* 1 = 0.0229103 loss)
I1007 14:16:33.883919  4874 sgd_solver.cpp:105] Iteration 72900, lr = 0.01
I1007 14:16:41.580157  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:16:41.904187  4874 solver.cpp:330] Iteration 73000, Testing net (#0)
I1007 14:16:43.796233  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:16:43.875447  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9118
I1007 14:16:43.875483  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.349202 (* 1 = 0.349202 loss)
I1007 14:16:43.956086  4874 solver.cpp:218] Iteration 73000 (9.92837 iter/s, 10.0721s/100 iters), loss = 0.003598
I1007 14:16:43.956115  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00359785 (* 1 = 0.00359785 loss)
I1007 14:16:43.956121  4874 sgd_solver.cpp:105] Iteration 73000, lr = 0.01
I1007 14:16:52.052037  4874 solver.cpp:218] Iteration 73100 (12.3519 iter/s, 8.09589s/100 iters), loss = 0.00646177
I1007 14:16:52.052076  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00646161 (* 1 = 0.00646161 loss)
I1007 14:16:52.052081  4874 sgd_solver.cpp:105] Iteration 73100, lr = 0.01
I1007 14:17:00.144749  4874 solver.cpp:218] Iteration 73200 (12.3569 iter/s, 8.09265s/100 iters), loss = 0.0168837
I1007 14:17:00.144915  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0168835 (* 1 = 0.0168835 loss)
I1007 14:17:00.144923  4874 sgd_solver.cpp:105] Iteration 73200, lr = 0.01
I1007 14:17:08.240993  4874 solver.cpp:218] Iteration 73300 (12.3517 iter/s, 8.09605s/100 iters), loss = 0.00349764
I1007 14:17:08.241034  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00349746 (* 1 = 0.00349746 loss)
I1007 14:17:08.241040  4874 sgd_solver.cpp:105] Iteration 73300, lr = 0.01
I1007 14:17:16.337317  4874 solver.cpp:218] Iteration 73400 (12.3514 iter/s, 8.09626s/100 iters), loss = 0.00330094
I1007 14:17:16.337347  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00330077 (* 1 = 0.00330077 loss)
I1007 14:17:16.337352  4874 sgd_solver.cpp:105] Iteration 73400, lr = 0.01
I1007 14:17:24.035513  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:17:24.360585  4874 solver.cpp:330] Iteration 73500, Testing net (#0)
I1007 14:17:26.251829  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:17:26.330718  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9049
I1007 14:17:26.330754  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.401249 (* 1 = 0.401249 loss)
I1007 14:17:26.411320  4874 solver.cpp:218] Iteration 73500 (9.9266 iter/s, 10.0739s/100 iters), loss = 0.00214797
I1007 14:17:26.411348  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00214779 (* 1 = 0.00214779 loss)
I1007 14:17:26.411356  4874 sgd_solver.cpp:105] Iteration 73500, lr = 0.01
I1007 14:17:34.508240  4874 solver.cpp:218] Iteration 73600 (12.3505 iter/s, 8.09686s/100 iters), loss = 0.00986925
I1007 14:17:34.508385  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00986908 (* 1 = 0.00986908 loss)
I1007 14:17:34.508404  4874 sgd_solver.cpp:105] Iteration 73600, lr = 0.01
I1007 14:17:42.615301  4874 solver.cpp:218] Iteration 73700 (12.3352 iter/s, 8.10689s/100 iters), loss = 0.00817442
I1007 14:17:42.615342  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00817424 (* 1 = 0.00817424 loss)
I1007 14:17:42.615350  4874 sgd_solver.cpp:105] Iteration 73700, lr = 0.01
I1007 14:17:50.719090  4874 solver.cpp:218] Iteration 73800 (12.34 iter/s, 8.10372s/100 iters), loss = 0.00585026
I1007 14:17:50.719130  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00585007 (* 1 = 0.00585007 loss)
I1007 14:17:50.719136  4874 sgd_solver.cpp:105] Iteration 73800, lr = 0.01
I1007 14:17:58.828315  4874 solver.cpp:218] Iteration 73900 (12.3317 iter/s, 8.10916s/100 iters), loss = 0.00580453
I1007 14:17:58.828356  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00580434 (* 1 = 0.00580434 loss)
I1007 14:17:58.828363  4874 sgd_solver.cpp:105] Iteration 73900, lr = 0.01
I1007 14:18:06.531116  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:18:06.855850  4874 solver.cpp:330] Iteration 74000, Testing net (#0)
I1007 14:18:08.745962  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:18:08.826053  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9095
I1007 14:18:08.826077  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.376898 (* 1 = 0.376898 loss)
I1007 14:18:08.906220  4874 solver.cpp:218] Iteration 74000 (9.92277 iter/s, 10.0778s/100 iters), loss = 0.0277367
I1007 14:18:08.906247  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0277365 (* 1 = 0.0277365 loss)
I1007 14:18:08.906255  4874 sgd_solver.cpp:105] Iteration 74000, lr = 0.01
I1007 14:18:17.001739  4874 solver.cpp:218] Iteration 74100 (12.3526 iter/s, 8.09546s/100 iters), loss = 0.00234583
I1007 14:18:17.001780  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00234564 (* 1 = 0.00234564 loss)
I1007 14:18:17.001785  4874 sgd_solver.cpp:105] Iteration 74100, lr = 0.01
I1007 14:18:25.089642  4874 solver.cpp:218] Iteration 74200 (12.3642 iter/s, 8.08784s/100 iters), loss = 0.00328607
I1007 14:18:25.089670  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00328588 (* 1 = 0.00328588 loss)
I1007 14:18:25.089676  4874 sgd_solver.cpp:105] Iteration 74200, lr = 0.01
I1007 14:18:33.179450  4874 solver.cpp:218] Iteration 74300 (12.3613 iter/s, 8.08975s/100 iters), loss = 0.00617876
I1007 14:18:33.179481  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00617857 (* 1 = 0.00617857 loss)
I1007 14:18:33.179486  4874 sgd_solver.cpp:105] Iteration 74300, lr = 0.01
I1007 14:18:41.272621  4874 solver.cpp:218] Iteration 74400 (12.3562 iter/s, 8.09311s/100 iters), loss = 0.00653182
I1007 14:18:41.272761  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00653162 (* 1 = 0.00653162 loss)
I1007 14:18:41.272770  4874 sgd_solver.cpp:105] Iteration 74400, lr = 0.01
I1007 14:18:48.964725  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:18:49.289934  4874 solver.cpp:330] Iteration 74500, Testing net (#0)
I1007 14:18:51.181680  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:18:51.260637  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9063
I1007 14:18:51.260674  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.404892 (* 1 = 0.404892 loss)
I1007 14:18:51.341368  4874 solver.cpp:218] Iteration 74500 (9.93189 iter/s, 10.0686s/100 iters), loss = 0.00645687
I1007 14:18:51.341395  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00645668 (* 1 = 0.00645668 loss)
I1007 14:18:51.341401  4874 sgd_solver.cpp:105] Iteration 74500, lr = 0.01
I1007 14:18:59.440428  4874 solver.cpp:218] Iteration 74600 (12.3472 iter/s, 8.09901s/100 iters), loss = 0.00241119
I1007 14:18:59.440469  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00241101 (* 1 = 0.00241101 loss)
I1007 14:18:59.440474  4874 sgd_solver.cpp:105] Iteration 74600, lr = 0.01
I1007 14:19:07.545886  4874 solver.cpp:218] Iteration 74700 (12.3375 iter/s, 8.10539s/100 iters), loss = 0.0122873
I1007 14:19:07.545925  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0122871 (* 1 = 0.0122871 loss)
I1007 14:19:07.545931  4874 sgd_solver.cpp:105] Iteration 74700, lr = 0.01
I1007 14:19:15.638873  4874 solver.cpp:218] Iteration 74800 (12.3565 iter/s, 8.09292s/100 iters), loss = 0.0152046
I1007 14:19:15.638994  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0152045 (* 1 = 0.0152045 loss)
I1007 14:19:15.639001  4874 sgd_solver.cpp:105] Iteration 74800, lr = 0.01
I1007 14:19:23.741390  4874 solver.cpp:218] Iteration 74900 (12.342 iter/s, 8.10238s/100 iters), loss = 0.0174399
I1007 14:19:23.741420  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0174397 (* 1 = 0.0174397 loss)
I1007 14:19:23.741425  4874 sgd_solver.cpp:105] Iteration 74900, lr = 0.01
I1007 14:19:31.434398  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:19:31.759311  4874 solver.cpp:330] Iteration 75000, Testing net (#0)
I1007 14:19:33.650233  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:19:33.729233  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9061
I1007 14:19:33.729267  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.397188 (* 1 = 0.397188 loss)
I1007 14:19:33.810279  4874 solver.cpp:218] Iteration 75000 (9.93164 iter/s, 10.0688s/100 iters), loss = 0.00877971
I1007 14:19:33.810309  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00877951 (* 1 = 0.00877951 loss)
I1007 14:19:33.810317  4874 sgd_solver.cpp:105] Iteration 75000, lr = 0.01
I1007 14:19:41.907598  4874 solver.cpp:218] Iteration 75100 (12.3499 iter/s, 8.09726s/100 iters), loss = 0.00160822
I1007 14:19:41.907639  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00160801 (* 1 = 0.00160801 loss)
I1007 14:19:41.907644  4874 sgd_solver.cpp:105] Iteration 75100, lr = 0.01
I1007 14:19:50.004035  4874 solver.cpp:218] Iteration 75200 (12.3512 iter/s, 8.09637s/100 iters), loss = 0.0199691
I1007 14:19:50.004148  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0199689 (* 1 = 0.0199689 loss)
I1007 14:19:50.004155  4874 sgd_solver.cpp:105] Iteration 75200, lr = 0.01
I1007 14:19:58.103312  4874 solver.cpp:218] Iteration 75300 (12.347 iter/s, 8.09915s/100 iters), loss = 0.040348
I1007 14:19:58.103353  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0403478 (* 1 = 0.0403478 loss)
I1007 14:19:58.103358  4874 sgd_solver.cpp:105] Iteration 75300, lr = 0.01
I1007 14:20:06.198999  4874 solver.cpp:218] Iteration 75400 (12.3524 iter/s, 8.09562s/100 iters), loss = 0.00326032
I1007 14:20:06.199040  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0032601 (* 1 = 0.0032601 loss)
I1007 14:20:06.199046  4874 sgd_solver.cpp:105] Iteration 75400, lr = 0.01
I1007 14:20:13.891310  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:20:14.217671  4874 solver.cpp:330] Iteration 75500, Testing net (#0)
I1007 14:20:16.108973  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:20:16.188282  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9001
I1007 14:20:16.188318  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.437084 (* 1 = 0.437084 loss)
I1007 14:20:16.269546  4874 solver.cpp:218] Iteration 75500 (9.93002 iter/s, 10.0705s/100 iters), loss = 0.0265237
I1007 14:20:16.269578  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0265235 (* 1 = 0.0265235 loss)
I1007 14:20:16.269584  4874 sgd_solver.cpp:105] Iteration 75500, lr = 0.01
I1007 14:20:24.357966  4874 solver.cpp:218] Iteration 75600 (12.3634 iter/s, 8.08836s/100 iters), loss = 0.0117146
I1007 14:20:24.358106  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0117144 (* 1 = 0.0117144 loss)
I1007 14:20:24.358114  4874 sgd_solver.cpp:105] Iteration 75600, lr = 0.01
I1007 14:20:32.454999  4874 solver.cpp:218] Iteration 75700 (12.3505 iter/s, 8.09687s/100 iters), loss = 0.00324679
I1007 14:20:32.455039  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00324657 (* 1 = 0.00324657 loss)
I1007 14:20:32.455044  4874 sgd_solver.cpp:105] Iteration 75700, lr = 0.01
I1007 14:20:40.557927  4874 solver.cpp:218] Iteration 75800 (12.3413 iter/s, 8.10286s/100 iters), loss = 0.0177455
I1007 14:20:40.557966  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0177453 (* 1 = 0.0177453 loss)
I1007 14:20:40.557972  4874 sgd_solver.cpp:105] Iteration 75800, lr = 0.01
I1007 14:20:48.666484  4874 solver.cpp:218] Iteration 75900 (12.3327 iter/s, 8.10849s/100 iters), loss = 0.0106806
I1007 14:20:48.666524  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0106804 (* 1 = 0.0106804 loss)
I1007 14:20:48.666530  4874 sgd_solver.cpp:105] Iteration 75900, lr = 0.01
I1007 14:20:56.353245  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:20:56.677268  4874 solver.cpp:330] Iteration 76000, Testing net (#0)
I1007 14:20:58.567865  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:20:58.647187  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.904
I1007 14:20:58.647222  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.388913 (* 1 = 0.388913 loss)
I1007 14:20:58.727932  4874 solver.cpp:218] Iteration 76000 (9.939 iter/s, 10.0614s/100 iters), loss = 0.00914132
I1007 14:20:58.727960  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00914109 (* 1 = 0.00914109 loss)
I1007 14:20:58.727967  4874 sgd_solver.cpp:105] Iteration 76000, lr = 0.01
I1007 14:21:06.832427  4874 solver.cpp:218] Iteration 76100 (12.3389 iter/s, 8.10444s/100 iters), loss = 0.00514926
I1007 14:21:06.832466  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00514904 (* 1 = 0.00514904 loss)
I1007 14:21:06.832473  4874 sgd_solver.cpp:105] Iteration 76100, lr = 0.01
I1007 14:21:14.920274  4874 solver.cpp:218] Iteration 76200 (12.3643 iter/s, 8.08778s/100 iters), loss = 0.00957468
I1007 14:21:14.920305  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00957446 (* 1 = 0.00957446 loss)
I1007 14:21:14.920310  4874 sgd_solver.cpp:105] Iteration 76200, lr = 0.01
I1007 14:21:23.014235  4874 solver.cpp:218] Iteration 76300 (12.355 iter/s, 8.0939s/100 iters), loss = 0.0025145
I1007 14:21:23.014274  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00251428 (* 1 = 0.00251428 loss)
I1007 14:21:23.014281  4874 sgd_solver.cpp:105] Iteration 76300, lr = 0.01
I1007 14:21:31.110401  4874 solver.cpp:218] Iteration 76400 (12.3516 iter/s, 8.0961s/100 iters), loss = 0.0148498
I1007 14:21:31.110541  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0148496 (* 1 = 0.0148496 loss)
I1007 14:21:31.110548  4874 sgd_solver.cpp:105] Iteration 76400, lr = 0.01
I1007 14:21:38.805261  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:21:39.130995  4874 solver.cpp:330] Iteration 76500, Testing net (#0)
I1007 14:21:41.021564  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:21:41.100527  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9053
I1007 14:21:41.100561  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.389439 (* 1 = 0.389439 loss)
I1007 14:21:41.182013  4874 solver.cpp:218] Iteration 76500 (9.92905 iter/s, 10.0715s/100 iters), loss = 0.00481246
I1007 14:21:41.182040  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00481223 (* 1 = 0.00481223 loss)
I1007 14:21:41.182047  4874 sgd_solver.cpp:105] Iteration 76500, lr = 0.01
I1007 14:21:49.283221  4874 solver.cpp:218] Iteration 76600 (12.3439 iter/s, 8.10115s/100 iters), loss = 0.00676337
I1007 14:21:49.283259  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00676315 (* 1 = 0.00676315 loss)
I1007 14:21:49.283267  4874 sgd_solver.cpp:105] Iteration 76600, lr = 0.01
I1007 14:21:57.378206  4874 solver.cpp:218] Iteration 76700 (12.3534 iter/s, 8.09492s/100 iters), loss = 0.00184194
I1007 14:21:57.378247  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00184171 (* 1 = 0.00184171 loss)
I1007 14:21:57.378252  4874 sgd_solver.cpp:105] Iteration 76700, lr = 0.01
I1007 14:22:05.478440  4874 solver.cpp:218] Iteration 76800 (12.3454 iter/s, 8.10017s/100 iters), loss = 0.0314989
I1007 14:22:05.478601  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0314986 (* 1 = 0.0314986 loss)
I1007 14:22:05.478610  4874 sgd_solver.cpp:105] Iteration 76800, lr = 0.01
I1007 14:22:13.584431  4874 solver.cpp:218] Iteration 76900 (12.3368 iter/s, 8.10581s/100 iters), loss = 0.00666698
I1007 14:22:13.584471  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00666674 (* 1 = 0.00666674 loss)
I1007 14:22:13.584477  4874 sgd_solver.cpp:105] Iteration 76900, lr = 0.01
I1007 14:22:21.283373  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:22:21.608219  4874 solver.cpp:330] Iteration 77000, Testing net (#0)
I1007 14:22:23.498957  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:22:23.578306  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9127
I1007 14:22:23.578343  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.363979 (* 1 = 0.363979 loss)
I1007 14:22:23.659134  4874 solver.cpp:218] Iteration 77000 (9.92592 iter/s, 10.0746s/100 iters), loss = 0.00398797
I1007 14:22:23.659169  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00398774 (* 1 = 0.00398774 loss)
I1007 14:22:23.659178  4874 sgd_solver.cpp:105] Iteration 77000, lr = 0.01
I1007 14:22:31.765739  4874 solver.cpp:218] Iteration 77100 (12.3357 iter/s, 8.10655s/100 iters), loss = 0.00443058
I1007 14:22:31.765779  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00443035 (* 1 = 0.00443035 loss)
I1007 14:22:31.765784  4874 sgd_solver.cpp:105] Iteration 77100, lr = 0.01
I1007 14:22:39.867815  4874 solver.cpp:218] Iteration 77200 (12.3426 iter/s, 8.10201s/100 iters), loss = 0.027684
I1007 14:22:39.867892  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0276838 (* 1 = 0.0276838 loss)
I1007 14:22:39.867898  4874 sgd_solver.cpp:105] Iteration 77200, lr = 0.01
I1007 14:22:47.970679  4874 solver.cpp:218] Iteration 77300 (12.3415 iter/s, 8.10276s/100 iters), loss = 0.0270568
I1007 14:22:47.970719  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0270565 (* 1 = 0.0270565 loss)
I1007 14:22:47.970726  4874 sgd_solver.cpp:105] Iteration 77300, lr = 0.01
I1007 14:22:56.074879  4874 solver.cpp:218] Iteration 77400 (12.3394 iter/s, 8.10413s/100 iters), loss = 0.00436961
I1007 14:22:56.074909  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00436937 (* 1 = 0.00436937 loss)
I1007 14:22:56.074915  4874 sgd_solver.cpp:105] Iteration 77400, lr = 0.01
I1007 14:23:03.774281  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:23:04.099378  4874 solver.cpp:330] Iteration 77500, Testing net (#0)
I1007 14:23:05.992290  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:23:06.071377  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9098
I1007 14:23:06.071401  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.367319 (* 1 = 0.367319 loss)
I1007 14:23:06.152130  4874 solver.cpp:218] Iteration 77500 (9.9234 iter/s, 10.0772s/100 iters), loss = 0.00941406
I1007 14:23:06.152158  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00941382 (* 1 = 0.00941382 loss)
I1007 14:23:06.152165  4874 sgd_solver.cpp:105] Iteration 77500, lr = 0.01
I1007 14:23:14.252825  4874 solver.cpp:218] Iteration 77600 (12.3447 iter/s, 8.10063s/100 iters), loss = 0.0381555
I1007 14:23:14.252933  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0381552 (* 1 = 0.0381552 loss)
I1007 14:23:14.252952  4874 sgd_solver.cpp:105] Iteration 77600, lr = 0.01
I1007 14:23:22.355389  4874 solver.cpp:218] Iteration 77700 (12.342 iter/s, 8.10239s/100 iters), loss = 0.00450559
I1007 14:23:22.355428  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00450535 (* 1 = 0.00450535 loss)
I1007 14:23:22.355434  4874 sgd_solver.cpp:105] Iteration 77700, lr = 0.01
I1007 14:23:30.459092  4874 solver.cpp:218] Iteration 77800 (12.3401 iter/s, 8.10364s/100 iters), loss = 0.0035234
I1007 14:23:30.459122  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00352316 (* 1 = 0.00352316 loss)
I1007 14:23:30.459131  4874 sgd_solver.cpp:105] Iteration 77800, lr = 0.01
I1007 14:23:38.561069  4874 solver.cpp:218] Iteration 77900 (12.3428 iter/s, 8.10192s/100 iters), loss = 0.00270712
I1007 14:23:38.561110  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00270686 (* 1 = 0.00270686 loss)
I1007 14:23:38.561115  4874 sgd_solver.cpp:105] Iteration 77900, lr = 0.01
I1007 14:23:46.259970  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:23:46.583464  4874 solver.cpp:330] Iteration 78000, Testing net (#0)
I1007 14:23:48.475188  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:23:48.554337  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9167
I1007 14:23:48.554370  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.358733 (* 1 = 0.358733 loss)
I1007 14:23:48.635089  4874 solver.cpp:218] Iteration 78000 (9.92659 iter/s, 10.0739s/100 iters), loss = 0.0177277
I1007 14:23:48.635126  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0177274 (* 1 = 0.0177274 loss)
I1007 14:23:48.635133  4874 sgd_solver.cpp:105] Iteration 78000, lr = 0.01
I1007 14:23:56.740906  4874 solver.cpp:218] Iteration 78100 (12.3369 iter/s, 8.10575s/100 iters), loss = 0.00487884
I1007 14:23:56.740936  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00487857 (* 1 = 0.00487857 loss)
I1007 14:23:56.740942  4874 sgd_solver.cpp:105] Iteration 78100, lr = 0.01
I1007 14:24:04.837410  4874 solver.cpp:218] Iteration 78200 (12.3511 iter/s, 8.09645s/100 iters), loss = 0.00298089
I1007 14:24:04.837441  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00298062 (* 1 = 0.00298062 loss)
I1007 14:24:04.837457  4874 sgd_solver.cpp:105] Iteration 78200, lr = 0.01
I1007 14:24:12.939198  4874 solver.cpp:218] Iteration 78300 (12.343 iter/s, 8.10173s/100 iters), loss = 0.00886562
I1007 14:24:12.939229  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00886536 (* 1 = 0.00886536 loss)
I1007 14:24:12.939234  4874 sgd_solver.cpp:105] Iteration 78300, lr = 0.01
I1007 14:24:21.039901  4874 solver.cpp:218] Iteration 78400 (12.3447 iter/s, 8.10065s/100 iters), loss = 0.00883061
I1007 14:24:21.039989  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00883035 (* 1 = 0.00883035 loss)
I1007 14:24:21.040005  4874 sgd_solver.cpp:105] Iteration 78400, lr = 0.01
I1007 14:24:28.742530  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:24:29.067885  4874 solver.cpp:330] Iteration 78500, Testing net (#0)
I1007 14:24:30.960320  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:24:31.039280  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9137
I1007 14:24:31.039316  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.361939 (* 1 = 0.361939 loss)
I1007 14:24:31.120432  4874 solver.cpp:218] Iteration 78500 (9.92023 iter/s, 10.0804s/100 iters), loss = 0.00792066
I1007 14:24:31.120460  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0079204 (* 1 = 0.0079204 loss)
I1007 14:24:31.120467  4874 sgd_solver.cpp:105] Iteration 78500, lr = 0.01
I1007 14:24:39.218771  4874 solver.cpp:218] Iteration 78600 (12.3483 iter/s, 8.09828s/100 iters), loss = 0.0228877
I1007 14:24:39.218811  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0228875 (* 1 = 0.0228875 loss)
I1007 14:24:39.218817  4874 sgd_solver.cpp:105] Iteration 78600, lr = 0.01
I1007 14:24:47.327504  4874 solver.cpp:218] Iteration 78700 (12.3325 iter/s, 8.10867s/100 iters), loss = 0.00572276
I1007 14:24:47.327533  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00572251 (* 1 = 0.00572251 loss)
I1007 14:24:47.327539  4874 sgd_solver.cpp:105] Iteration 78700, lr = 0.01
I1007 14:24:55.428546  4874 solver.cpp:218] Iteration 78800 (12.3442 iter/s, 8.10099s/100 iters), loss = 0.0350737
I1007 14:24:55.428675  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0350735 (* 1 = 0.0350735 loss)
I1007 14:24:55.428692  4874 sgd_solver.cpp:105] Iteration 78800, lr = 0.01
I1007 14:25:03.534504  4874 solver.cpp:218] Iteration 78900 (12.3368 iter/s, 8.10581s/100 iters), loss = 0.000892195
I1007 14:25:03.534533  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000891949 (* 1 = 0.000891949 loss)
I1007 14:25:03.534538  4874 sgd_solver.cpp:105] Iteration 78900, lr = 0.01
I1007 14:25:11.232986  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:25:11.555707  4874 solver.cpp:330] Iteration 79000, Testing net (#0)
I1007 14:25:13.445993  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:25:13.525041  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9121
I1007 14:25:13.525076  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.376398 (* 1 = 0.376398 loss)
I1007 14:25:13.605767  4874 solver.cpp:218] Iteration 79000 (9.9293 iter/s, 10.0712s/100 iters), loss = 0.00593669
I1007 14:25:13.605794  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00593645 (* 1 = 0.00593645 loss)
I1007 14:25:13.605800  4874 sgd_solver.cpp:105] Iteration 79000, lr = 0.01
I1007 14:25:21.709982  4874 solver.cpp:218] Iteration 79100 (12.3393 iter/s, 8.10416s/100 iters), loss = 0.00529468
I1007 14:25:21.710013  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00529446 (* 1 = 0.00529446 loss)
I1007 14:25:21.710019  4874 sgd_solver.cpp:105] Iteration 79100, lr = 0.01
I1007 14:25:29.805619  4874 solver.cpp:218] Iteration 79200 (12.3524 iter/s, 8.09558s/100 iters), loss = 0.00827866
I1007 14:25:29.805757  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00827843 (* 1 = 0.00827843 loss)
I1007 14:25:29.805774  4874 sgd_solver.cpp:105] Iteration 79200, lr = 0.01
I1007 14:25:37.907146  4874 solver.cpp:218] Iteration 79300 (12.3436 iter/s, 8.10137s/100 iters), loss = 0.00909825
I1007 14:25:37.907177  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00909802 (* 1 = 0.00909802 loss)
I1007 14:25:37.907184  4874 sgd_solver.cpp:105] Iteration 79300, lr = 0.01
I1007 14:25:46.001085  4874 solver.cpp:218] Iteration 79400 (12.355 iter/s, 8.09388s/100 iters), loss = 0.00355484
I1007 14:25:46.001114  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00355461 (* 1 = 0.00355461 loss)
I1007 14:25:46.001121  4874 sgd_solver.cpp:105] Iteration 79400, lr = 0.01
I1007 14:25:53.700301  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:25:54.024332  4874 solver.cpp:330] Iteration 79500, Testing net (#0)
I1007 14:25:55.916680  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:25:55.996063  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9102
I1007 14:25:55.996088  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.382227 (* 1 = 0.382227 loss)
I1007 14:25:56.077320  4874 solver.cpp:218] Iteration 79500 (9.9244 iter/s, 10.0762s/100 iters), loss = 0.0110715
I1007 14:25:56.077349  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0110713 (* 1 = 0.0110713 loss)
I1007 14:25:56.077355  4874 sgd_solver.cpp:105] Iteration 79500, lr = 0.01
I1007 14:26:04.173418  4874 solver.cpp:218] Iteration 79600 (12.3517 iter/s, 8.09604s/100 iters), loss = 0.00679545
I1007 14:26:04.173503  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00679521 (* 1 = 0.00679521 loss)
I1007 14:26:04.173519  4874 sgd_solver.cpp:105] Iteration 79600, lr = 0.01
I1007 14:26:12.277791  4874 solver.cpp:218] Iteration 79700 (12.3392 iter/s, 8.10426s/100 iters), loss = 0.00458976
I1007 14:26:12.277820  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00458952 (* 1 = 0.00458952 loss)
I1007 14:26:12.277827  4874 sgd_solver.cpp:105] Iteration 79700, lr = 0.01
I1007 14:26:20.374512  4874 solver.cpp:218] Iteration 79800 (12.3508 iter/s, 8.09666s/100 iters), loss = 0.0178801
I1007 14:26:20.374542  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0178799 (* 1 = 0.0178799 loss)
I1007 14:26:20.374548  4874 sgd_solver.cpp:105] Iteration 79800, lr = 0.01
I1007 14:26:28.475426  4874 solver.cpp:218] Iteration 79900 (12.3444 iter/s, 8.10086s/100 iters), loss = 0.00845274
I1007 14:26:28.475456  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00845249 (* 1 = 0.00845249 loss)
I1007 14:26:28.475461  4874 sgd_solver.cpp:105] Iteration 79900, lr = 0.01
I1007 14:26:36.173122  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:26:36.498486  4874 solver.cpp:330] Iteration 80000, Testing net (#0)
I1007 14:26:38.385144  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:26:38.463902  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9146
I1007 14:26:38.463927  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.344951 (* 1 = 0.344951 loss)
I1007 14:26:38.544782  4874 solver.cpp:218] Iteration 80000 (9.93118 iter/s, 10.0693s/100 iters), loss = 0.0288852
I1007 14:26:38.544809  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0288849 (* 1 = 0.0288849 loss)
I1007 14:26:38.544816  4874 sgd_solver.cpp:46] MultiStep Status: Iteration 80000, step = 2
I1007 14:26:38.544818  4874 sgd_solver.cpp:105] Iteration 80000, lr = 0.001
I1007 14:26:46.655841  4874 solver.cpp:218] Iteration 80100 (12.3289 iter/s, 8.111s/100 iters), loss = 0.00409599
I1007 14:26:46.655880  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00409573 (* 1 = 0.00409573 loss)
I1007 14:26:46.655886  4874 sgd_solver.cpp:105] Iteration 80100, lr = 0.001
I1007 14:26:54.757815  4874 solver.cpp:218] Iteration 80200 (12.3428 iter/s, 8.10191s/100 iters), loss = 0.0105943
I1007 14:26:54.757856  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0105941 (* 1 = 0.0105941 loss)
I1007 14:26:54.757863  4874 sgd_solver.cpp:105] Iteration 80200, lr = 0.001
I1007 14:27:02.867612  4874 solver.cpp:218] Iteration 80300 (12.3309 iter/s, 8.10973s/100 iters), loss = 0.00336586
I1007 14:27:02.867651  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00336559 (* 1 = 0.00336559 loss)
I1007 14:27:02.867657  4874 sgd_solver.cpp:105] Iteration 80300, lr = 0.001
I1007 14:27:10.975121  4874 solver.cpp:218] Iteration 80400 (12.3343 iter/s, 8.10744s/100 iters), loss = 0.000770353
I1007 14:27:10.975227  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000770081 (* 1 = 0.000770081 loss)
I1007 14:27:10.975234  4874 sgd_solver.cpp:105] Iteration 80400, lr = 0.001
I1007 14:27:18.681464  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:27:19.006439  4874 solver.cpp:330] Iteration 80500, Testing net (#0)
I1007 14:27:20.899864  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:27:20.978651  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9189
I1007 14:27:20.978684  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.325464 (* 1 = 0.325464 loss)
I1007 14:27:21.059602  4874 solver.cpp:218] Iteration 80500 (9.91636 iter/s, 10.0843s/100 iters), loss = 0.00729284
I1007 14:27:21.059629  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00729257 (* 1 = 0.00729257 loss)
I1007 14:27:21.059636  4874 sgd_solver.cpp:105] Iteration 80500, lr = 0.001
I1007 14:27:29.151863  4874 solver.cpp:218] Iteration 80600 (12.3576 iter/s, 8.09221s/100 iters), loss = 0.00691492
I1007 14:27:29.151892  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00691465 (* 1 = 0.00691465 loss)
I1007 14:27:29.151898  4874 sgd_solver.cpp:105] Iteration 80600, lr = 0.001
I1007 14:27:37.256753  4874 solver.cpp:218] Iteration 80700 (12.3383 iter/s, 8.10483s/100 iters), loss = 0.00878567
I1007 14:27:37.256804  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0087854 (* 1 = 0.0087854 loss)
I1007 14:27:37.256810  4874 sgd_solver.cpp:105] Iteration 80700, lr = 0.001
I1007 14:27:45.351466  4874 solver.cpp:218] Iteration 80800 (12.3538 iter/s, 8.09464s/100 iters), loss = 0.00589296
I1007 14:27:45.351589  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0058927 (* 1 = 0.0058927 loss)
I1007 14:27:45.351608  4874 sgd_solver.cpp:105] Iteration 80800, lr = 0.001
I1007 14:27:53.443383  4874 solver.cpp:218] Iteration 80900 (12.3582 iter/s, 8.09178s/100 iters), loss = 0.00796395
I1007 14:27:53.443419  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00796367 (* 1 = 0.00796367 loss)
I1007 14:27:53.443426  4874 sgd_solver.cpp:105] Iteration 80900, lr = 0.001
I1007 14:28:01.134928  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:28:01.458523  4874 solver.cpp:330] Iteration 81000, Testing net (#0)
I1007 14:28:03.349469  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:28:03.428575  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9192
I1007 14:28:03.428611  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.322119 (* 1 = 0.322119 loss)
I1007 14:28:03.509704  4874 solver.cpp:218] Iteration 81000 (9.93418 iter/s, 10.0663s/100 iters), loss = 0.00223699
I1007 14:28:03.509730  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00223672 (* 1 = 0.00223672 loss)
I1007 14:28:03.509737  4874 sgd_solver.cpp:105] Iteration 81000, lr = 0.001
I1007 14:28:11.612408  4874 solver.cpp:218] Iteration 81100 (12.3416 iter/s, 8.10265s/100 iters), loss = 0.000525994
I1007 14:28:11.612437  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000525722 (* 1 = 0.000525722 loss)
I1007 14:28:11.612444  4874 sgd_solver.cpp:105] Iteration 81100, lr = 0.001
I1007 14:28:19.712281  4874 solver.cpp:218] Iteration 81200 (12.346 iter/s, 8.09982s/100 iters), loss = 0.00366707
I1007 14:28:19.712401  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0036668 (* 1 = 0.0036668 loss)
I1007 14:28:19.712409  4874 sgd_solver.cpp:105] Iteration 81200, lr = 0.001
I1007 14:28:27.813921  4874 solver.cpp:218] Iteration 81300 (12.3434 iter/s, 8.1015s/100 iters), loss = 0.00378525
I1007 14:28:27.813951  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00378497 (* 1 = 0.00378497 loss)
I1007 14:28:27.813957  4874 sgd_solver.cpp:105] Iteration 81300, lr = 0.001
I1007 14:28:35.912190  4874 solver.cpp:218] Iteration 81400 (12.3484 iter/s, 8.09821s/100 iters), loss = 0.00262514
I1007 14:28:35.912220  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00262486 (* 1 = 0.00262486 loss)
I1007 14:28:35.912226  4874 sgd_solver.cpp:105] Iteration 81400, lr = 0.001
I1007 14:28:43.612397  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:28:43.937296  4874 solver.cpp:330] Iteration 81500, Testing net (#0)
I1007 14:28:45.830199  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:28:45.909662  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9222
I1007 14:28:45.909698  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.320312 (* 1 = 0.320312 loss)
I1007 14:28:45.990907  4874 solver.cpp:218] Iteration 81500 (9.92196 iter/s, 10.0787s/100 iters), loss = 0.0113597
I1007 14:28:45.990934  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0113594 (* 1 = 0.0113594 loss)
I1007 14:28:45.990942  4874 sgd_solver.cpp:105] Iteration 81500, lr = 0.001
I1007 14:28:54.087327  4874 solver.cpp:218] Iteration 81600 (12.3512 iter/s, 8.09636s/100 iters), loss = 0.00578299
I1007 14:28:54.087461  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0057827 (* 1 = 0.0057827 loss)
I1007 14:28:54.087468  4874 sgd_solver.cpp:105] Iteration 81600, lr = 0.001
I1007 14:29:02.186266  4874 solver.cpp:218] Iteration 81700 (12.3475 iter/s, 8.09878s/100 iters), loss = 0.0093991
I1007 14:29:02.186295  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00939882 (* 1 = 0.00939882 loss)
I1007 14:29:02.186300  4874 sgd_solver.cpp:105] Iteration 81700, lr = 0.001
I1007 14:29:10.283370  4874 solver.cpp:218] Iteration 81800 (12.3502 iter/s, 8.09705s/100 iters), loss = 0.000842717
I1007 14:29:10.283401  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000842436 (* 1 = 0.000842436 loss)
I1007 14:29:10.283407  4874 sgd_solver.cpp:105] Iteration 81800, lr = 0.001
I1007 14:29:18.385697  4874 solver.cpp:218] Iteration 81900 (12.3422 iter/s, 8.10227s/100 iters), loss = 0.00318439
I1007 14:29:18.385726  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00318411 (* 1 = 0.00318411 loss)
I1007 14:29:18.385732  4874 sgd_solver.cpp:105] Iteration 81900, lr = 0.001
I1007 14:29:26.081740  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:29:26.406003  4874 solver.cpp:330] Iteration 82000, Testing net (#0)
I1007 14:29:28.297860  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:29:28.376667  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9214
I1007 14:29:28.376701  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.319194 (* 1 = 0.319194 loss)
I1007 14:29:28.457655  4874 solver.cpp:218] Iteration 82000 (9.92862 iter/s, 10.0719s/100 iters), loss = 0.00429101
I1007 14:29:28.457680  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00429073 (* 1 = 0.00429073 loss)
I1007 14:29:28.457687  4874 sgd_solver.cpp:105] Iteration 82000, lr = 0.001
I1007 14:29:36.563982  4874 solver.cpp:218] Iteration 82100 (12.3361 iter/s, 8.10627s/100 iters), loss = 0.00354932
I1007 14:29:36.564021  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00354904 (* 1 = 0.00354904 loss)
I1007 14:29:36.564028  4874 sgd_solver.cpp:105] Iteration 82100, lr = 0.001
I1007 14:29:44.655622  4874 solver.cpp:218] Iteration 82200 (12.3585 iter/s, 8.09157s/100 iters), loss = 0.0329827
I1007 14:29:44.655661  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0329824 (* 1 = 0.0329824 loss)
I1007 14:29:44.655668  4874 sgd_solver.cpp:105] Iteration 82200, lr = 0.001
I1007 14:29:52.756355  4874 solver.cpp:218] Iteration 82300 (12.3447 iter/s, 8.10067s/100 iters), loss = 0.00153409
I1007 14:29:52.756394  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0015338 (* 1 = 0.0015338 loss)
I1007 14:29:52.756400  4874 sgd_solver.cpp:105] Iteration 82300, lr = 0.001
I1007 14:30:00.853262  4874 solver.cpp:218] Iteration 82400 (12.3505 iter/s, 8.09684s/100 iters), loss = 0.00202482
I1007 14:30:00.853391  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00202453 (* 1 = 0.00202453 loss)
I1007 14:30:00.853399  4874 sgd_solver.cpp:105] Iteration 82400, lr = 0.001
I1007 14:30:08.549684  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:30:08.874295  4874 solver.cpp:330] Iteration 82500, Testing net (#0)
I1007 14:30:10.765471  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:30:10.844877  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9221
I1007 14:30:10.844900  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.317463 (* 1 = 0.317463 loss)
I1007 14:30:10.925854  4874 solver.cpp:218] Iteration 82500 (9.92808 iter/s, 10.0724s/100 iters), loss = 0.0018424
I1007 14:30:10.925880  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00184211 (* 1 = 0.00184211 loss)
I1007 14:30:10.925887  4874 sgd_solver.cpp:105] Iteration 82500, lr = 0.001
I1007 14:30:19.022575  4874 solver.cpp:218] Iteration 82600 (12.3508 iter/s, 8.09666s/100 iters), loss = 0.00210247
I1007 14:30:19.022615  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00210217 (* 1 = 0.00210217 loss)
I1007 14:30:19.022621  4874 sgd_solver.cpp:105] Iteration 82600, lr = 0.001
I1007 14:30:27.125136  4874 solver.cpp:218] Iteration 82700 (12.3419 iter/s, 8.1025s/100 iters), loss = 0.0124025
I1007 14:30:27.125165  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0124022 (* 1 = 0.0124022 loss)
I1007 14:30:27.125171  4874 sgd_solver.cpp:105] Iteration 82700, lr = 0.001
I1007 14:30:35.225018  4874 solver.cpp:218] Iteration 82800 (12.3459 iter/s, 8.09983s/100 iters), loss = 0.00178993
I1007 14:30:35.225198  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00178964 (* 1 = 0.00178964 loss)
I1007 14:30:35.225205  4874 sgd_solver.cpp:105] Iteration 82800, lr = 0.001
I1007 14:30:43.327406  4874 solver.cpp:218] Iteration 82900 (12.3423 iter/s, 8.1022s/100 iters), loss = 0.00214718
I1007 14:30:43.327442  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00214689 (* 1 = 0.00214689 loss)
I1007 14:30:43.327450  4874 sgd_solver.cpp:105] Iteration 82900, lr = 0.001
I1007 14:30:51.023059  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:30:51.346472  4874 solver.cpp:330] Iteration 83000, Testing net (#0)
I1007 14:30:53.237433  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:30:53.316409  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9225
I1007 14:30:53.316444  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.317461 (* 1 = 0.317461 loss)
I1007 14:30:53.397286  4874 solver.cpp:218] Iteration 83000 (9.93067 iter/s, 10.0698s/100 iters), loss = 0.00113482
I1007 14:30:53.397313  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00113453 (* 1 = 0.00113453 loss)
I1007 14:30:53.397320  4874 sgd_solver.cpp:105] Iteration 83000, lr = 0.001
I1007 14:31:01.499214  4874 solver.cpp:218] Iteration 83100 (12.3428 iter/s, 8.10187s/100 iters), loss = 0.0141821
I1007 14:31:01.499253  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0141818 (* 1 = 0.0141818 loss)
I1007 14:31:01.499259  4874 sgd_solver.cpp:105] Iteration 83100, lr = 0.001
I1007 14:31:09.593020  4874 solver.cpp:218] Iteration 83200 (12.3552 iter/s, 8.09374s/100 iters), loss = 0.00452538
I1007 14:31:09.593127  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00452509 (* 1 = 0.00452509 loss)
I1007 14:31:09.593143  4874 sgd_solver.cpp:105] Iteration 83200, lr = 0.001
I1007 14:31:17.695104  4874 solver.cpp:218] Iteration 83300 (12.3427 iter/s, 8.10195s/100 iters), loss = 0.00111715
I1007 14:31:17.695134  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00111686 (* 1 = 0.00111686 loss)
I1007 14:31:17.695139  4874 sgd_solver.cpp:105] Iteration 83300, lr = 0.001
I1007 14:31:25.789538  4874 solver.cpp:218] Iteration 83400 (12.3543 iter/s, 8.09438s/100 iters), loss = 0.0165699
I1007 14:31:25.789567  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0165696 (* 1 = 0.0165696 loss)
I1007 14:31:25.789573  4874 sgd_solver.cpp:105] Iteration 83400, lr = 0.001
I1007 14:31:33.484460  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:31:33.808753  4874 solver.cpp:330] Iteration 83500, Testing net (#0)
I1007 14:31:35.700009  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:31:35.779368  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9231
I1007 14:31:35.779403  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.317183 (* 1 = 0.317183 loss)
I1007 14:31:35.860071  4874 solver.cpp:218] Iteration 83500 (9.93002 iter/s, 10.0705s/100 iters), loss = 0.00338424
I1007 14:31:35.860102  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00338396 (* 1 = 0.00338396 loss)
I1007 14:31:35.860110  4874 sgd_solver.cpp:105] Iteration 83500, lr = 0.001
I1007 14:31:43.948067  4874 solver.cpp:218] Iteration 83600 (12.3641 iter/s, 8.08794s/100 iters), loss = 0.00121004
I1007 14:31:43.948202  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00120976 (* 1 = 0.00120976 loss)
I1007 14:31:43.948210  4874 sgd_solver.cpp:105] Iteration 83600, lr = 0.001
I1007 14:31:52.046066  4874 solver.cpp:218] Iteration 83700 (12.349 iter/s, 8.09784s/100 iters), loss = 0.0018823
I1007 14:31:52.046094  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00188202 (* 1 = 0.00188202 loss)
I1007 14:31:52.046100  4874 sgd_solver.cpp:105] Iteration 83700, lr = 0.001
I1007 14:32:00.141067  4874 solver.cpp:218] Iteration 83800 (12.3534 iter/s, 8.09495s/100 iters), loss = 0.0025428
I1007 14:32:00.141098  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00254251 (* 1 = 0.00254251 loss)
I1007 14:32:00.141104  4874 sgd_solver.cpp:105] Iteration 83800, lr = 0.001
I1007 14:32:08.237377  4874 solver.cpp:218] Iteration 83900 (12.3514 iter/s, 8.09625s/100 iters), loss = 0.00479772
I1007 14:32:08.237408  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00479743 (* 1 = 0.00479743 loss)
I1007 14:32:08.237414  4874 sgd_solver.cpp:105] Iteration 83900, lr = 0.001
I1007 14:32:15.932873  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:32:16.257473  4874 solver.cpp:330] Iteration 84000, Testing net (#0)
I1007 14:32:18.148370  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:32:18.227687  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9229
I1007 14:32:18.227721  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.318382 (* 1 = 0.318382 loss)
I1007 14:32:18.308501  4874 solver.cpp:218] Iteration 84000 (9.92944 iter/s, 10.0711s/100 iters), loss = 0.00226663
I1007 14:32:18.308534  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00226634 (* 1 = 0.00226634 loss)
I1007 14:32:18.308542  4874 sgd_solver.cpp:105] Iteration 84000, lr = 0.001
I1007 14:32:26.408720  4874 solver.cpp:218] Iteration 84100 (12.3454 iter/s, 8.10016s/100 iters), loss = 0.0015013
I1007 14:32:26.408761  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00150101 (* 1 = 0.00150101 loss)
I1007 14:32:26.408766  4874 sgd_solver.cpp:105] Iteration 84100, lr = 0.001
I1007 14:32:34.495723  4874 solver.cpp:218] Iteration 84200 (12.3656 iter/s, 8.08694s/100 iters), loss = 0.00733835
I1007 14:32:34.495753  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00733806 (* 1 = 0.00733806 loss)
I1007 14:32:34.495759  4874 sgd_solver.cpp:105] Iteration 84200, lr = 0.001
I1007 14:32:42.595885  4874 solver.cpp:218] Iteration 84300 (12.3455 iter/s, 8.10011s/100 iters), loss = 0.00738852
I1007 14:32:42.595924  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00738824 (* 1 = 0.00738824 loss)
I1007 14:32:42.595930  4874 sgd_solver.cpp:105] Iteration 84300, lr = 0.001
I1007 14:32:50.686974  4874 solver.cpp:218] Iteration 84400 (12.3594 iter/s, 8.09102s/100 iters), loss = 0.00564954
I1007 14:32:50.687091  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00564926 (* 1 = 0.00564926 loss)
I1007 14:32:50.687098  4874 sgd_solver.cpp:105] Iteration 84400, lr = 0.001
I1007 14:32:58.380517  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:32:58.704744  4874 solver.cpp:330] Iteration 84500, Testing net (#0)
I1007 14:33:00.599052  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:33:00.678032  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9226
I1007 14:33:00.678057  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.319242 (* 1 = 0.319242 loss)
I1007 14:33:00.759137  4874 solver.cpp:218] Iteration 84500 (9.9285 iter/s, 10.072s/100 iters), loss = 0.00209445
I1007 14:33:00.759183  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00209416 (* 1 = 0.00209416 loss)
I1007 14:33:00.759201  4874 sgd_solver.cpp:105] Iteration 84500, lr = 0.001
I1007 14:33:08.854341  4874 solver.cpp:218] Iteration 84600 (12.3531 iter/s, 8.09515s/100 iters), loss = 0.00301753
I1007 14:33:08.854380  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00301724 (* 1 = 0.00301724 loss)
I1007 14:33:08.854387  4874 sgd_solver.cpp:105] Iteration 84600, lr = 0.001
I1007 14:33:16.960172  4874 solver.cpp:218] Iteration 84700 (12.3369 iter/s, 8.10577s/100 iters), loss = 0.00832859
I1007 14:33:16.960203  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0083283 (* 1 = 0.0083283 loss)
I1007 14:33:16.960218  4874 sgd_solver.cpp:105] Iteration 84700, lr = 0.001
I1007 14:33:25.055200  4874 solver.cpp:218] Iteration 84800 (12.3533 iter/s, 8.09497s/100 iters), loss = 0.000883166
I1007 14:33:25.055342  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000882878 (* 1 = 0.000882878 loss)
I1007 14:33:25.055359  4874 sgd_solver.cpp:105] Iteration 84800, lr = 0.001
I1007 14:33:33.159252  4874 solver.cpp:218] Iteration 84900 (12.3398 iter/s, 8.10388s/100 iters), loss = 0.0030977
I1007 14:33:33.159283  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00309741 (* 1 = 0.00309741 loss)
I1007 14:33:33.159289  4874 sgd_solver.cpp:105] Iteration 84900, lr = 0.001
I1007 14:33:40.853210  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:33:41.177639  4874 solver.cpp:330] Iteration 85000, Testing net (#0)
I1007 14:33:43.068702  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:33:43.147928  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9224
I1007 14:33:43.147964  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.319861 (* 1 = 0.319861 loss)
I1007 14:33:43.228868  4874 solver.cpp:218] Iteration 85000 (9.93093 iter/s, 10.0695s/100 iters), loss = 0.00192284
I1007 14:33:43.228899  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00192255 (* 1 = 0.00192255 loss)
I1007 14:33:43.228906  4874 sgd_solver.cpp:105] Iteration 85000, lr = 0.001
I1007 14:33:51.332726  4874 solver.cpp:218] Iteration 85100 (12.3399 iter/s, 8.1038s/100 iters), loss = 0.00297044
I1007 14:33:51.332754  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00297016 (* 1 = 0.00297016 loss)
I1007 14:33:51.332762  4874 sgd_solver.cpp:105] Iteration 85100, lr = 0.001
I1007 14:33:59.426242  4874 solver.cpp:218] Iteration 85200 (12.3557 iter/s, 8.09346s/100 iters), loss = 0.00653543
I1007 14:33:59.426337  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00653514 (* 1 = 0.00653514 loss)
I1007 14:33:59.426343  4874 sgd_solver.cpp:105] Iteration 85200, lr = 0.001
I1007 14:34:07.530616  4874 solver.cpp:218] Iteration 85300 (12.3392 iter/s, 8.10425s/100 iters), loss = 0.00138249
I1007 14:34:07.530645  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0013822 (* 1 = 0.0013822 loss)
I1007 14:34:07.530652  4874 sgd_solver.cpp:105] Iteration 85300, lr = 0.001
I1007 14:34:15.626171  4874 solver.cpp:218] Iteration 85400 (12.3525 iter/s, 8.0955s/100 iters), loss = 0.00653893
I1007 14:34:15.626212  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00653865 (* 1 = 0.00653865 loss)
I1007 14:34:15.626219  4874 sgd_solver.cpp:105] Iteration 85400, lr = 0.001
I1007 14:34:23.322340  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:34:23.647567  4874 solver.cpp:330] Iteration 85500, Testing net (#0)
I1007 14:34:25.540362  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:34:25.619416  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9233
I1007 14:34:25.619451  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.318803 (* 1 = 0.318803 loss)
I1007 14:34:25.700285  4874 solver.cpp:218] Iteration 85500 (9.9265 iter/s, 10.074s/100 iters), loss = 0.000349181
I1007 14:34:25.700312  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000348891 (* 1 = 0.000348891 loss)
I1007 14:34:25.700320  4874 sgd_solver.cpp:105] Iteration 85500, lr = 0.001
I1007 14:34:33.794047  4874 solver.cpp:218] Iteration 85600 (12.3553 iter/s, 8.09371s/100 iters), loss = 0.0026116
I1007 14:34:33.794142  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00261131 (* 1 = 0.00261131 loss)
I1007 14:34:33.794148  4874 sgd_solver.cpp:105] Iteration 85600, lr = 0.001
I1007 14:34:41.896602  4874 solver.cpp:218] Iteration 85700 (12.342 iter/s, 8.10243s/100 iters), loss = 0.00899434
I1007 14:34:41.896631  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00899405 (* 1 = 0.00899405 loss)
I1007 14:34:41.896637  4874 sgd_solver.cpp:105] Iteration 85700, lr = 0.001
I1007 14:34:49.994029  4874 solver.cpp:218] Iteration 85800 (12.3497 iter/s, 8.09737s/100 iters), loss = 0.00279115
I1007 14:34:49.994058  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00279086 (* 1 = 0.00279086 loss)
I1007 14:34:49.994065  4874 sgd_solver.cpp:105] Iteration 85800, lr = 0.001
I1007 14:34:58.097195  4874 solver.cpp:218] Iteration 85900 (12.3409 iter/s, 8.10311s/100 iters), loss = 0.000908314
I1007 14:34:58.097225  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000908026 (* 1 = 0.000908026 loss)
I1007 14:34:58.097241  4874 sgd_solver.cpp:105] Iteration 85900, lr = 0.001
I1007 14:35:05.793908  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:35:06.118731  4874 solver.cpp:330] Iteration 86000, Testing net (#0)
I1007 14:35:08.010332  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:35:08.089534  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9232
I1007 14:35:08.089567  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.319383 (* 1 = 0.319383 loss)
I1007 14:35:08.170835  4874 solver.cpp:218] Iteration 86000 (9.92696 iter/s, 10.0736s/100 iters), loss = 0.000915003
I1007 14:35:08.170863  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000914715 (* 1 = 0.000914715 loss)
I1007 14:35:08.170869  4874 sgd_solver.cpp:105] Iteration 86000, lr = 0.001
I1007 14:35:16.274410  4874 solver.cpp:218] Iteration 86100 (12.3403 iter/s, 8.10352s/100 iters), loss = 0.00522621
I1007 14:35:16.274451  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00522592 (* 1 = 0.00522592 loss)
I1007 14:35:16.274457  4874 sgd_solver.cpp:105] Iteration 86100, lr = 0.001
I1007 14:35:24.365131  4874 solver.cpp:218] Iteration 86200 (12.3599 iter/s, 8.09065s/100 iters), loss = 0.0231346
I1007 14:35:24.365171  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0231343 (* 1 = 0.0231343 loss)
I1007 14:35:24.365177  4874 sgd_solver.cpp:105] Iteration 86200, lr = 0.001
I1007 14:35:32.463093  4874 solver.cpp:218] Iteration 86300 (12.3489 iter/s, 8.0979s/100 iters), loss = 0.00884238
I1007 14:35:32.463135  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00884208 (* 1 = 0.00884208 loss)
I1007 14:35:32.463140  4874 sgd_solver.cpp:105] Iteration 86300, lr = 0.001
I1007 14:35:40.560529  4874 solver.cpp:218] Iteration 86400 (12.3497 iter/s, 8.09737s/100 iters), loss = 0.00406441
I1007 14:35:40.560653  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00406411 (* 1 = 0.00406411 loss)
I1007 14:35:40.560660  4874 sgd_solver.cpp:105] Iteration 86400, lr = 0.001
I1007 14:35:48.258791  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:35:48.583232  4874 solver.cpp:330] Iteration 86500, Testing net (#0)
I1007 14:35:50.475970  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:35:50.555244  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9227
I1007 14:35:50.555279  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.320119 (* 1 = 0.320119 loss)
I1007 14:35:50.635939  4874 solver.cpp:218] Iteration 86500 (9.9253 iter/s, 10.0753s/100 iters), loss = 0.00168665
I1007 14:35:50.635967  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00168636 (* 1 = 0.00168636 loss)
I1007 14:35:50.635973  4874 sgd_solver.cpp:105] Iteration 86500, lr = 0.001
I1007 14:35:58.729975  4874 solver.cpp:218] Iteration 86600 (12.3549 iter/s, 8.09398s/100 iters), loss = 0.00062391
I1007 14:35:58.730005  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000623615 (* 1 = 0.000623615 loss)
I1007 14:35:58.730010  4874 sgd_solver.cpp:105] Iteration 86600, lr = 0.001
I1007 14:36:06.834838  4874 solver.cpp:218] Iteration 86700 (12.3384 iter/s, 8.10481s/100 iters), loss = 0.00521176
I1007 14:36:06.834867  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00521147 (* 1 = 0.00521147 loss)
I1007 14:36:06.834872  4874 sgd_solver.cpp:105] Iteration 86700, lr = 0.001
I1007 14:36:14.924731  4874 solver.cpp:218] Iteration 86800 (12.3612 iter/s, 8.08984s/100 iters), loss = 0.00583034
I1007 14:36:14.924861  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00583005 (* 1 = 0.00583005 loss)
I1007 14:36:14.924877  4874 sgd_solver.cpp:105] Iteration 86800, lr = 0.001
I1007 14:36:23.028442  4874 solver.cpp:218] Iteration 86900 (12.3402 iter/s, 8.10357s/100 iters), loss = 0.000932088
I1007 14:36:23.028481  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000931792 (* 1 = 0.000931792 loss)
I1007 14:36:23.028487  4874 sgd_solver.cpp:105] Iteration 86900, lr = 0.001
I1007 14:36:30.722759  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:36:31.046664  4874 solver.cpp:330] Iteration 87000, Testing net (#0)
I1007 14:36:32.938410  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:36:33.017439  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9228
I1007 14:36:33.017473  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.319357 (* 1 = 0.319357 loss)
I1007 14:36:33.098382  4874 solver.cpp:218] Iteration 87000 (9.93062 iter/s, 10.0699s/100 iters), loss = 0.000547608
I1007 14:36:33.098409  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000547313 (* 1 = 0.000547313 loss)
I1007 14:36:33.098417  4874 sgd_solver.cpp:105] Iteration 87000, lr = 0.001
I1007 14:36:41.200654  4874 solver.cpp:218] Iteration 87100 (12.3423 iter/s, 8.10222s/100 iters), loss = 0.00193108
I1007 14:36:41.200695  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00193079 (* 1 = 0.00193079 loss)
I1007 14:36:41.200701  4874 sgd_solver.cpp:105] Iteration 87100, lr = 0.001
I1007 14:36:49.290658  4874 solver.cpp:218] Iteration 87200 (12.361 iter/s, 8.08994s/100 iters), loss = 0.00871457
I1007 14:36:49.290766  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00871428 (* 1 = 0.00871428 loss)
I1007 14:36:49.290773  4874 sgd_solver.cpp:105] Iteration 87200, lr = 0.001
I1007 14:36:57.388975  4874 solver.cpp:218] Iteration 87300 (12.3484 iter/s, 8.09818s/100 iters), loss = 0.00267547
I1007 14:36:57.389004  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00267518 (* 1 = 0.00267518 loss)
I1007 14:36:57.389010  4874 sgd_solver.cpp:105] Iteration 87300, lr = 0.001
I1007 14:37:05.480487  4874 solver.cpp:218] Iteration 87400 (12.3587 iter/s, 8.09145s/100 iters), loss = 0.0054295
I1007 14:37:05.480520  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00542921 (* 1 = 0.00542921 loss)
I1007 14:37:05.480527  4874 sgd_solver.cpp:105] Iteration 87400, lr = 0.001
I1007 14:37:13.175854  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:37:13.500350  4874 solver.cpp:330] Iteration 87500, Testing net (#0)
I1007 14:37:15.391459  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:37:15.470917  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9228
I1007 14:37:15.470942  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.319862 (* 1 = 0.319862 loss)
I1007 14:37:15.551873  4874 solver.cpp:218] Iteration 87500 (9.92918 iter/s, 10.0713s/100 iters), loss = 0.0019029
I1007 14:37:15.551906  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00190261 (* 1 = 0.00190261 loss)
I1007 14:37:15.551913  4874 sgd_solver.cpp:105] Iteration 87500, lr = 0.001
I1007 14:37:23.647008  4874 solver.cpp:218] Iteration 87600 (12.3532 iter/s, 8.09508s/100 iters), loss = 0.00724585
I1007 14:37:23.647080  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00724556 (* 1 = 0.00724556 loss)
I1007 14:37:23.647089  4874 sgd_solver.cpp:105] Iteration 87600, lr = 0.001
I1007 14:37:31.751518  4874 solver.cpp:218] Iteration 87700 (12.339 iter/s, 8.10441s/100 iters), loss = 0.00318471
I1007 14:37:31.751560  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00318442 (* 1 = 0.00318442 loss)
I1007 14:37:31.751566  4874 sgd_solver.cpp:105] Iteration 87700, lr = 0.001
I1007 14:37:39.849496  4874 solver.cpp:218] Iteration 87800 (12.3489 iter/s, 8.09791s/100 iters), loss = 0.00353639
I1007 14:37:39.849524  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0035361 (* 1 = 0.0035361 loss)
I1007 14:37:39.849530  4874 sgd_solver.cpp:105] Iteration 87800, lr = 0.001
I1007 14:37:47.954399  4874 solver.cpp:218] Iteration 87900 (12.3383 iter/s, 8.10485s/100 iters), loss = 0.00165767
I1007 14:37:47.954428  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00165738 (* 1 = 0.00165738 loss)
I1007 14:37:47.954434  4874 sgd_solver.cpp:105] Iteration 87900, lr = 0.001
I1007 14:37:55.645861  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:37:55.969769  4874 solver.cpp:330] Iteration 88000, Testing net (#0)
I1007 14:37:57.860679  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:37:57.939831  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9235
I1007 14:37:57.939864  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.320044 (* 1 = 0.320044 loss)
I1007 14:37:58.020378  4874 solver.cpp:218] Iteration 88000 (9.93451 iter/s, 10.0659s/100 iters), loss = 0.00159934
I1007 14:37:58.020406  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00159905 (* 1 = 0.00159905 loss)
I1007 14:37:58.020413  4874 sgd_solver.cpp:105] Iteration 88000, lr = 0.001
I1007 14:38:06.120609  4874 solver.cpp:218] Iteration 88100 (12.3454 iter/s, 8.10018s/100 iters), loss = 0.0013484
I1007 14:38:06.120640  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00134811 (* 1 = 0.00134811 loss)
I1007 14:38:06.120645  4874 sgd_solver.cpp:105] Iteration 88100, lr = 0.001
I1007 14:38:14.215433  4874 solver.cpp:218] Iteration 88200 (12.3537 iter/s, 8.09477s/100 iters), loss = 0.0125813
I1007 14:38:14.215462  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.012581 (* 1 = 0.012581 loss)
I1007 14:38:14.215469  4874 sgd_solver.cpp:105] Iteration 88200, lr = 0.001
I1007 14:38:22.319512  4874 solver.cpp:218] Iteration 88300 (12.3396 iter/s, 8.10402s/100 iters), loss = 0.00121249
I1007 14:38:22.319542  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0012122 (* 1 = 0.0012122 loss)
I1007 14:38:22.319548  4874 sgd_solver.cpp:105] Iteration 88300, lr = 0.001
I1007 14:38:30.416643  4874 solver.cpp:218] Iteration 88400 (12.3501 iter/s, 8.09707s/100 iters), loss = 0.000311691
I1007 14:38:30.416733  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000311397 (* 1 = 0.000311397 loss)
I1007 14:38:30.416739  4874 sgd_solver.cpp:105] Iteration 88400, lr = 0.001
I1007 14:38:38.116575  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:38:38.440630  4874 solver.cpp:330] Iteration 88500, Testing net (#0)
I1007 14:38:40.332310  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:38:40.411706  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9234
I1007 14:38:40.411741  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.319808 (* 1 = 0.319808 loss)
I1007 14:38:40.492473  4874 solver.cpp:218] Iteration 88500 (9.92486 iter/s, 10.0757s/100 iters), loss = 0.0010599
I1007 14:38:40.492501  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00105961 (* 1 = 0.00105961 loss)
I1007 14:38:40.492508  4874 sgd_solver.cpp:105] Iteration 88500, lr = 0.001
I1007 14:38:48.594723  4874 solver.cpp:218] Iteration 88600 (12.3423 iter/s, 8.1022s/100 iters), loss = 0.00555896
I1007 14:38:48.594754  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00555867 (* 1 = 0.00555867 loss)
I1007 14:38:48.594760  4874 sgd_solver.cpp:105] Iteration 88600, lr = 0.001
I1007 14:38:56.700268  4874 solver.cpp:218] Iteration 88700 (12.3373 iter/s, 8.10548s/100 iters), loss = 0.002354
I1007 14:38:56.700315  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00235371 (* 1 = 0.00235371 loss)
I1007 14:38:56.700322  4874 sgd_solver.cpp:105] Iteration 88700, lr = 0.001
I1007 14:39:04.793232  4874 solver.cpp:218] Iteration 88800 (12.3565 iter/s, 8.09289s/100 iters), loss = 0.00154138
I1007 14:39:04.793361  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00154108 (* 1 = 0.00154108 loss)
I1007 14:39:04.793370  4874 sgd_solver.cpp:105] Iteration 88800, lr = 0.001
I1007 14:39:12.886023  4874 solver.cpp:218] Iteration 88900 (12.3569 iter/s, 8.09264s/100 iters), loss = 0.000912424
I1007 14:39:12.886070  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000912131 (* 1 = 0.000912131 loss)
I1007 14:39:12.886077  4874 sgd_solver.cpp:105] Iteration 88900, lr = 0.001
I1007 14:39:20.575186  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:39:20.898895  4874 solver.cpp:330] Iteration 89000, Testing net (#0)
I1007 14:39:22.789186  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:39:22.868199  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9229
I1007 14:39:22.868234  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.320612 (* 1 = 0.320612 loss)
I1007 14:39:22.949082  4874 solver.cpp:218] Iteration 89000 (9.93741 iter/s, 10.063s/100 iters), loss = 0.000812012
I1007 14:39:22.949111  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000811719 (* 1 = 0.000811719 loss)
I1007 14:39:22.949118  4874 sgd_solver.cpp:105] Iteration 89000, lr = 0.001
I1007 14:39:31.045619  4874 solver.cpp:218] Iteration 89100 (12.351 iter/s, 8.09648s/100 iters), loss = 0.000640173
I1007 14:39:31.045660  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000639878 (* 1 = 0.000639878 loss)
I1007 14:39:31.045665  4874 sgd_solver.cpp:105] Iteration 89100, lr = 0.001
I1007 14:39:39.126632  4874 solver.cpp:218] Iteration 89200 (12.3748 iter/s, 8.08095s/100 iters), loss = 0.0199934
I1007 14:39:39.126760  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0199931 (* 1 = 0.0199931 loss)
I1007 14:39:39.126766  4874 sgd_solver.cpp:105] Iteration 89200, lr = 0.001
I1007 14:39:47.225870  4874 solver.cpp:218] Iteration 89300 (12.3471 iter/s, 8.09909s/100 iters), loss = 0.00281888
I1007 14:39:47.225911  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00281858 (* 1 = 0.00281858 loss)
I1007 14:39:47.225917  4874 sgd_solver.cpp:105] Iteration 89300, lr = 0.001
I1007 14:39:55.322145  4874 solver.cpp:218] Iteration 89400 (12.3515 iter/s, 8.09621s/100 iters), loss = 0.00127149
I1007 14:39:55.322185  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00127119 (* 1 = 0.00127119 loss)
I1007 14:39:55.322192  4874 sgd_solver.cpp:105] Iteration 89400, lr = 0.001
I1007 14:40:03.026273  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:40:03.351336  4874 solver.cpp:330] Iteration 89500, Testing net (#0)
I1007 14:40:05.241552  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:40:05.320503  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.924
I1007 14:40:05.320539  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.319613 (* 1 = 0.319613 loss)
I1007 14:40:05.401644  4874 solver.cpp:218] Iteration 89500 (9.9212 iter/s, 10.0794s/100 iters), loss = 0.00185013
I1007 14:40:05.401671  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00184984 (* 1 = 0.00184984 loss)
I1007 14:40:05.401679  4874 sgd_solver.cpp:105] Iteration 89500, lr = 0.001
I1007 14:40:13.504700  4874 solver.cpp:218] Iteration 89600 (12.3411 iter/s, 8.103s/100 iters), loss = 0.00204195
I1007 14:40:13.504806  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00204166 (* 1 = 0.00204166 loss)
I1007 14:40:13.504822  4874 sgd_solver.cpp:105] Iteration 89600, lr = 0.001
I1007 14:40:21.609470  4874 solver.cpp:218] Iteration 89700 (12.3386 iter/s, 8.10464s/100 iters), loss = 0.00203664
I1007 14:40:21.609510  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00203635 (* 1 = 0.00203635 loss)
I1007 14:40:21.609516  4874 sgd_solver.cpp:105] Iteration 89700, lr = 0.001
I1007 14:40:29.709391  4874 solver.cpp:218] Iteration 89800 (12.3459 iter/s, 8.09985s/100 iters), loss = 0.0108843
I1007 14:40:29.709431  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.010884 (* 1 = 0.010884 loss)
I1007 14:40:29.709437  4874 sgd_solver.cpp:105] Iteration 89800, lr = 0.001
I1007 14:40:37.814486  4874 solver.cpp:218] Iteration 89900 (12.338 iter/s, 8.10502s/100 iters), loss = 0.002836
I1007 14:40:37.814525  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00283571 (* 1 = 0.00283571 loss)
I1007 14:40:37.814532  4874 sgd_solver.cpp:105] Iteration 89900, lr = 0.001
I1007 14:40:45.509096  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:40:45.834553  4874 solver.cpp:330] Iteration 90000, Testing net (#0)
I1007 14:40:47.726215  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:40:47.805161  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.923
I1007 14:40:47.805197  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.320562 (* 1 = 0.320562 loss)
I1007 14:40:47.885789  4874 solver.cpp:218] Iteration 90000 (9.92927 iter/s, 10.0712s/100 iters), loss = 0.000353146
I1007 14:40:47.885818  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000352853 (* 1 = 0.000352853 loss)
I1007 14:40:47.885825  4874 sgd_solver.cpp:105] Iteration 90000, lr = 0.001
I1007 14:40:55.993412  4874 solver.cpp:218] Iteration 90100 (12.3342 iter/s, 8.10757s/100 iters), loss = 0.00193092
I1007 14:40:55.993443  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00193063 (* 1 = 0.00193063 loss)
I1007 14:40:55.993448  4874 sgd_solver.cpp:105] Iteration 90100, lr = 0.001
I1007 14:41:04.094552  4874 solver.cpp:218] Iteration 90200 (12.344 iter/s, 8.10108s/100 iters), loss = 0.0118148
I1007 14:41:04.094593  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0118145 (* 1 = 0.0118145 loss)
I1007 14:41:04.094599  4874 sgd_solver.cpp:105] Iteration 90200, lr = 0.001
I1007 14:41:12.199328  4874 solver.cpp:218] Iteration 90300 (12.3385 iter/s, 8.10471s/100 iters), loss = 0.00145929
I1007 14:41:12.199368  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.001459 (* 1 = 0.001459 loss)
I1007 14:41:12.199374  4874 sgd_solver.cpp:105] Iteration 90300, lr = 0.001
I1007 14:41:20.300024  4874 solver.cpp:218] Iteration 90400 (12.3447 iter/s, 8.10063s/100 iters), loss = 0.00462002
I1007 14:41:20.300135  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00461973 (* 1 = 0.00461973 loss)
I1007 14:41:20.300142  4874 sgd_solver.cpp:105] Iteration 90400, lr = 0.001
I1007 14:41:28.004878  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:41:28.330036  4874 solver.cpp:330] Iteration 90500, Testing net (#0)
I1007 14:41:30.220401  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:41:30.300032  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9225
I1007 14:41:30.300068  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.318663 (* 1 = 0.318663 loss)
I1007 14:41:30.380650  4874 solver.cpp:218] Iteration 90500 (9.92015 iter/s, 10.0805s/100 iters), loss = 0.00150978
I1007 14:41:30.380674  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00150949 (* 1 = 0.00150949 loss)
I1007 14:41:30.380681  4874 sgd_solver.cpp:105] Iteration 90500, lr = 0.001
I1007 14:41:38.483973  4874 solver.cpp:218] Iteration 90600 (12.3407 iter/s, 8.10327s/100 iters), loss = 0.00920554
I1007 14:41:38.484014  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00920525 (* 1 = 0.00920525 loss)
I1007 14:41:38.484019  4874 sgd_solver.cpp:105] Iteration 90600, lr = 0.001
I1007 14:41:46.591053  4874 solver.cpp:218] Iteration 90700 (12.335 iter/s, 8.10701s/100 iters), loss = 0.00324596
I1007 14:41:46.591092  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00324566 (* 1 = 0.00324566 loss)
I1007 14:41:46.591099  4874 sgd_solver.cpp:105] Iteration 90700, lr = 0.001
I1007 14:41:54.692500  4874 solver.cpp:218] Iteration 90800 (12.3436 iter/s, 8.10138s/100 iters), loss = 0.00166887
I1007 14:41:54.692677  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00166858 (* 1 = 0.00166858 loss)
I1007 14:41:54.692685  4874 sgd_solver.cpp:105] Iteration 90800, lr = 0.001
I1007 14:42:02.801795  4874 solver.cpp:218] Iteration 90900 (12.3318 iter/s, 8.1091s/100 iters), loss = 0.000697736
I1007 14:42:02.801836  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000697439 (* 1 = 0.000697439 loss)
I1007 14:42:02.801842  4874 sgd_solver.cpp:105] Iteration 90900, lr = 0.001
I1007 14:42:10.501668  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:42:10.824831  4874 solver.cpp:330] Iteration 91000, Testing net (#0)
I1007 14:42:12.715967  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:42:12.795399  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9221
I1007 14:42:12.795434  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.31877 (* 1 = 0.31877 loss)
I1007 14:42:12.875598  4874 solver.cpp:218] Iteration 91000 (9.92681 iter/s, 10.0737s/100 iters), loss = 0.00089137
I1007 14:42:12.875627  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000891075 (* 1 = 0.000891075 loss)
I1007 14:42:12.875633  4874 sgd_solver.cpp:105] Iteration 91000, lr = 0.001
I1007 14:42:20.971179  4874 solver.cpp:218] Iteration 91100 (12.3525 iter/s, 8.09552s/100 iters), loss = 0.0123644
I1007 14:42:20.971209  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0123641 (* 1 = 0.0123641 loss)
I1007 14:42:20.971215  4874 sgd_solver.cpp:105] Iteration 91100, lr = 0.001
I1007 14:42:29.057037  4874 solver.cpp:218] Iteration 91200 (12.3674 iter/s, 8.0858s/100 iters), loss = 0.00550114
I1007 14:42:29.057138  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00550084 (* 1 = 0.00550084 loss)
I1007 14:42:29.057145  4874 sgd_solver.cpp:105] Iteration 91200, lr = 0.001
I1007 14:42:37.155225  4874 solver.cpp:218] Iteration 91300 (12.3486 iter/s, 8.09806s/100 iters), loss = 0.00298261
I1007 14:42:37.155256  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00298231 (* 1 = 0.00298231 loss)
I1007 14:42:37.155261  4874 sgd_solver.cpp:105] Iteration 91300, lr = 0.001
I1007 14:42:45.245419  4874 solver.cpp:218] Iteration 91400 (12.3607 iter/s, 8.09014s/100 iters), loss = 0.000832467
I1007 14:42:45.245450  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000832172 (* 1 = 0.000832172 loss)
I1007 14:42:45.245456  4874 sgd_solver.cpp:105] Iteration 91400, lr = 0.001
I1007 14:42:52.940138  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:42:53.264827  4874 solver.cpp:330] Iteration 91500, Testing net (#0)
I1007 14:42:55.156637  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:42:55.235641  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9235
I1007 14:42:55.235666  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.320715 (* 1 = 0.320715 loss)
I1007 14:42:55.317214  4874 solver.cpp:218] Iteration 91500 (9.92878 iter/s, 10.0717s/100 iters), loss = 0.00337529
I1007 14:42:55.317246  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.003375 (* 1 = 0.003375 loss)
I1007 14:42:55.317255  4874 sgd_solver.cpp:105] Iteration 91500, lr = 0.001
I1007 14:43:03.412653  4874 solver.cpp:218] Iteration 91600 (12.3527 iter/s, 8.09538s/100 iters), loss = 0.00304314
I1007 14:43:03.412791  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00304285 (* 1 = 0.00304285 loss)
I1007 14:43:03.412799  4874 sgd_solver.cpp:105] Iteration 91600, lr = 0.001
I1007 14:43:11.507752  4874 solver.cpp:218] Iteration 91700 (12.3534 iter/s, 8.09493s/100 iters), loss = 0.000976915
I1007 14:43:11.507781  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000976625 (* 1 = 0.000976625 loss)
I1007 14:43:11.507787  4874 sgd_solver.cpp:105] Iteration 91700, lr = 0.001
I1007 14:43:19.598712  4874 solver.cpp:218] Iteration 91800 (12.3596 iter/s, 8.0909s/100 iters), loss = 0.00243061
I1007 14:43:19.598753  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00243032 (* 1 = 0.00243032 loss)
I1007 14:43:19.598759  4874 sgd_solver.cpp:105] Iteration 91800, lr = 0.001
I1007 14:43:27.700031  4874 solver.cpp:218] Iteration 91900 (12.3438 iter/s, 8.10125s/100 iters), loss = 0.00127955
I1007 14:43:27.700060  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00127926 (* 1 = 0.00127926 loss)
I1007 14:43:27.700067  4874 sgd_solver.cpp:105] Iteration 91900, lr = 0.001
I1007 14:43:35.393370  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:43:35.717473  4874 solver.cpp:330] Iteration 92000, Testing net (#0)
I1007 14:43:37.613770  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:43:37.692351  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9225
I1007 14:43:37.692376  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.320587 (* 1 = 0.320587 loss)
I1007 14:43:37.773294  4874 solver.cpp:218] Iteration 92000 (9.92733 iter/s, 10.0732s/100 iters), loss = 0.000681325
I1007 14:43:37.773321  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000681034 (* 1 = 0.000681034 loss)
I1007 14:43:37.773329  4874 sgd_solver.cpp:105] Iteration 92000, lr = 0.001
I1007 14:43:45.874935  4874 solver.cpp:218] Iteration 92100 (12.3433 iter/s, 8.10159s/100 iters), loss = 0.000856816
I1007 14:43:45.874975  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000856526 (* 1 = 0.000856526 loss)
I1007 14:43:45.874981  4874 sgd_solver.cpp:105] Iteration 92100, lr = 0.001
I1007 14:43:53.969463  4874 solver.cpp:218] Iteration 92200 (12.3541 iter/s, 8.09446s/100 iters), loss = 0.00475107
I1007 14:43:53.969493  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00475078 (* 1 = 0.00475078 loss)
I1007 14:43:53.969499  4874 sgd_solver.cpp:105] Iteration 92200, lr = 0.001
I1007 14:44:02.067204  4874 solver.cpp:218] Iteration 92300 (12.3492 iter/s, 8.09769s/100 iters), loss = 0.00211053
I1007 14:44:02.067245  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00211024 (* 1 = 0.00211024 loss)
I1007 14:44:02.067250  4874 sgd_solver.cpp:105] Iteration 92300, lr = 0.001
I1007 14:44:10.158323  4874 solver.cpp:218] Iteration 92400 (12.3593 iter/s, 8.09105s/100 iters), loss = 0.00196562
I1007 14:44:10.158432  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00196533 (* 1 = 0.00196533 loss)
I1007 14:44:10.158438  4874 sgd_solver.cpp:105] Iteration 92400, lr = 0.001
I1007 14:44:17.854674  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:44:18.178830  4874 solver.cpp:330] Iteration 92500, Testing net (#0)
I1007 14:44:20.069424  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:44:20.148537  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9232
I1007 14:44:20.148572  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.319586 (* 1 = 0.319586 loss)
I1007 14:44:20.229202  4874 solver.cpp:218] Iteration 92500 (9.92975 iter/s, 10.0707s/100 iters), loss = 0.00846764
I1007 14:44:20.229236  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00846735 (* 1 = 0.00846735 loss)
I1007 14:44:20.229243  4874 sgd_solver.cpp:105] Iteration 92500, lr = 0.001
I1007 14:44:28.327219  4874 solver.cpp:218] Iteration 92600 (12.3488 iter/s, 8.09796s/100 iters), loss = 0.00191363
I1007 14:44:28.327250  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00191334 (* 1 = 0.00191334 loss)
I1007 14:44:28.327255  4874 sgd_solver.cpp:105] Iteration 92600, lr = 0.001
I1007 14:44:36.426610  4874 solver.cpp:218] Iteration 92700 (12.3467 iter/s, 8.09933s/100 iters), loss = 0.00112003
I1007 14:44:36.426640  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00111974 (* 1 = 0.00111974 loss)
I1007 14:44:36.426645  4874 sgd_solver.cpp:105] Iteration 92700, lr = 0.001
I1007 14:44:44.520562  4874 solver.cpp:218] Iteration 92800 (12.355 iter/s, 8.0939s/100 iters), loss = 0.00314328
I1007 14:44:44.520745  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00314298 (* 1 = 0.00314298 loss)
I1007 14:44:44.520754  4874 sgd_solver.cpp:105] Iteration 92800, lr = 0.001
I1007 14:44:52.620280  4874 solver.cpp:218] Iteration 92900 (12.3464 iter/s, 8.09952s/100 iters), loss = 0.00339638
I1007 14:44:52.620308  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00339608 (* 1 = 0.00339608 loss)
I1007 14:44:52.620314  4874 sgd_solver.cpp:105] Iteration 92900, lr = 0.001
I1007 14:45:00.310148  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:45:00.634464  4874 solver.cpp:330] Iteration 93000, Testing net (#0)
I1007 14:45:02.527972  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:45:02.606999  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9231
I1007 14:45:02.607034  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.320414 (* 1 = 0.320414 loss)
I1007 14:45:02.687882  4874 solver.cpp:218] Iteration 93000 (9.93291 iter/s, 10.0675s/100 iters), loss = 0.000755172
I1007 14:45:02.687909  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000754874 (* 1 = 0.000754874 loss)
I1007 14:45:02.687916  4874 sgd_solver.cpp:105] Iteration 93000, lr = 0.001
I1007 14:45:10.784984  4874 solver.cpp:218] Iteration 93100 (12.3502 iter/s, 8.09705s/100 iters), loss = 0.0011686
I1007 14:45:10.785014  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0011683 (* 1 = 0.0011683 loss)
I1007 14:45:10.785020  4874 sgd_solver.cpp:105] Iteration 93100, lr = 0.001
I1007 14:45:18.884348  4874 solver.cpp:218] Iteration 93200 (12.3467 iter/s, 8.09931s/100 iters), loss = 0.00294266
I1007 14:45:18.884462  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00294236 (* 1 = 0.00294236 loss)
I1007 14:45:18.884470  4874 sgd_solver.cpp:105] Iteration 93200, lr = 0.001
I1007 14:45:26.985618  4874 solver.cpp:218] Iteration 93300 (12.344 iter/s, 8.10113s/100 iters), loss = 0.0057224
I1007 14:45:26.985654  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0057221 (* 1 = 0.0057221 loss)
I1007 14:45:26.985662  4874 sgd_solver.cpp:105] Iteration 93300, lr = 0.001
I1007 14:45:35.067351  4874 solver.cpp:218] Iteration 93400 (12.3737 iter/s, 8.08167s/100 iters), loss = 0.00190769
I1007 14:45:35.067389  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00190739 (* 1 = 0.00190739 loss)
I1007 14:45:35.067406  4874 sgd_solver.cpp:105] Iteration 93400, lr = 0.001
I1007 14:45:42.753634  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:45:43.078327  4874 solver.cpp:330] Iteration 93500, Testing net (#0)
I1007 14:45:44.966958  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:45:45.046161  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9228
I1007 14:45:45.046202  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.320103 (* 1 = 0.320103 loss)
I1007 14:45:45.127493  4874 solver.cpp:218] Iteration 93500 (9.94028 iter/s, 10.0601s/100 iters), loss = 0.00203731
I1007 14:45:45.127521  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00203701 (* 1 = 0.00203701 loss)
I1007 14:45:45.127526  4874 sgd_solver.cpp:105] Iteration 93500, lr = 0.001
I1007 14:45:53.231148  4874 solver.cpp:218] Iteration 93600 (12.3402 iter/s, 8.1036s/100 iters), loss = 0.00153613
I1007 14:45:53.231245  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00153583 (* 1 = 0.00153583 loss)
I1007 14:45:53.231253  4874 sgd_solver.cpp:105] Iteration 93600, lr = 0.001
I1007 14:46:01.340785  4874 solver.cpp:218] Iteration 93700 (12.3312 iter/s, 8.10951s/100 iters), loss = 0.00499351
I1007 14:46:01.340826  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00499321 (* 1 = 0.00499321 loss)
I1007 14:46:01.340831  4874 sgd_solver.cpp:105] Iteration 93700, lr = 0.001
I1007 14:46:09.442440  4874 solver.cpp:218] Iteration 93800 (12.3433 iter/s, 8.10159s/100 iters), loss = 0.00100312
I1007 14:46:09.442469  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00100282 (* 1 = 0.00100282 loss)
I1007 14:46:09.442476  4874 sgd_solver.cpp:105] Iteration 93800, lr = 0.001
I1007 14:46:17.554255  4874 solver.cpp:218] Iteration 93900 (12.3278 iter/s, 8.11176s/100 iters), loss = 0.000426995
I1007 14:46:17.554283  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000426696 (* 1 = 0.000426696 loss)
I1007 14:46:17.554299  4874 sgd_solver.cpp:105] Iteration 93900, lr = 0.001
I1007 14:46:25.258671  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:46:25.582947  4874 solver.cpp:330] Iteration 94000, Testing net (#0)
I1007 14:46:27.476258  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:46:27.555200  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9231
I1007 14:46:27.555235  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.319933 (* 1 = 0.319933 loss)
I1007 14:46:27.636564  4874 solver.cpp:218] Iteration 94000 (9.91842 iter/s, 10.0822s/100 iters), loss = 0.00185676
I1007 14:46:27.636591  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00185646 (* 1 = 0.00185646 loss)
I1007 14:46:27.636598  4874 sgd_solver.cpp:105] Iteration 94000, lr = 0.001
I1007 14:46:35.748139  4874 solver.cpp:218] Iteration 94100 (12.3281 iter/s, 8.11152s/100 iters), loss = 0.00172573
I1007 14:46:35.748179  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00172544 (* 1 = 0.00172544 loss)
I1007 14:46:35.748185  4874 sgd_solver.cpp:105] Iteration 94100, lr = 0.001
I1007 14:46:43.850853  4874 solver.cpp:218] Iteration 94200 (12.3416 iter/s, 8.10265s/100 iters), loss = 0.0100857
I1007 14:46:43.850893  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0100854 (* 1 = 0.0100854 loss)
I1007 14:46:43.850898  4874 sgd_solver.cpp:105] Iteration 94200, lr = 0.001
I1007 14:46:51.961017  4874 solver.cpp:218] Iteration 94300 (12.3303 iter/s, 8.1101s/100 iters), loss = 0.00322166
I1007 14:46:51.961048  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00322136 (* 1 = 0.00322136 loss)
I1007 14:46:51.961055  4874 sgd_solver.cpp:105] Iteration 94300, lr = 0.001
I1007 14:47:00.062105  4874 solver.cpp:218] Iteration 94400 (12.3441 iter/s, 8.10103s/100 iters), loss = 0.00180123
I1007 14:47:00.062217  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00180093 (* 1 = 0.00180093 loss)
I1007 14:47:00.062234  4874 sgd_solver.cpp:105] Iteration 94400, lr = 0.001
I1007 14:47:07.772809  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:47:08.097056  4874 solver.cpp:330] Iteration 94500, Testing net (#0)
I1007 14:47:09.988570  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:47:10.067996  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9234
I1007 14:47:10.068029  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.320235 (* 1 = 0.320235 loss)
I1007 14:47:10.148469  4874 solver.cpp:218] Iteration 94500 (9.91451 iter/s, 10.0862s/100 iters), loss = 0.000624028
I1007 14:47:10.148496  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000623731 (* 1 = 0.000623731 loss)
I1007 14:47:10.148504  4874 sgd_solver.cpp:105] Iteration 94500, lr = 0.001
I1007 14:47:18.246098  4874 solver.cpp:218] Iteration 94600 (12.3494 iter/s, 8.09757s/100 iters), loss = 0.00153095
I1007 14:47:18.246137  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00153065 (* 1 = 0.00153065 loss)
I1007 14:47:18.246145  4874 sgd_solver.cpp:105] Iteration 94600, lr = 0.001
I1007 14:47:26.347245  4874 solver.cpp:218] Iteration 94700 (12.344 iter/s, 8.10108s/100 iters), loss = 0.0030203
I1007 14:47:26.347286  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00302 (* 1 = 0.00302 loss)
I1007 14:47:26.347292  4874 sgd_solver.cpp:105] Iteration 94700, lr = 0.001
I1007 14:47:34.447742  4874 solver.cpp:218] Iteration 94800 (12.345 iter/s, 8.10043s/100 iters), loss = 0.00165231
I1007 14:47:34.447813  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00165201 (* 1 = 0.00165201 loss)
I1007 14:47:34.447818  4874 sgd_solver.cpp:105] Iteration 94800, lr = 0.001
I1007 14:47:42.551901  4874 solver.cpp:218] Iteration 94900 (12.3395 iter/s, 8.10406s/100 iters), loss = 0.00100573
I1007 14:47:42.551941  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00100543 (* 1 = 0.00100543 loss)
I1007 14:47:42.551947  4874 sgd_solver.cpp:105] Iteration 94900, lr = 0.001
I1007 14:47:50.245296  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:47:50.570511  4874 solver.cpp:330] Iteration 95000, Testing net (#0)
I1007 14:47:52.462576  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:47:52.541877  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9232
I1007 14:47:52.541911  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.319697 (* 1 = 0.319697 loss)
I1007 14:47:52.622952  4874 solver.cpp:218] Iteration 95000 (9.92952 iter/s, 10.071s/100 iters), loss = 0.000889971
I1007 14:47:52.622982  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000889672 (* 1 = 0.000889672 loss)
I1007 14:47:52.622988  4874 sgd_solver.cpp:105] Iteration 95000, lr = 0.001
I1007 14:48:00.720283  4874 solver.cpp:218] Iteration 95100 (12.3498 iter/s, 8.09727s/100 iters), loss = 0.00165674
I1007 14:48:00.720322  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00165644 (* 1 = 0.00165644 loss)
I1007 14:48:00.720329  4874 sgd_solver.cpp:105] Iteration 95100, lr = 0.001
I1007 14:48:08.811839  4874 solver.cpp:218] Iteration 95200 (12.3587 iter/s, 8.09149s/100 iters), loss = 0.00612065
I1007 14:48:08.811955  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00612035 (* 1 = 0.00612035 loss)
I1007 14:48:08.811972  4874 sgd_solver.cpp:105] Iteration 95200, lr = 0.001
I1007 14:48:16.911612  4874 solver.cpp:218] Iteration 95300 (12.3462 iter/s, 8.09963s/100 iters), loss = 0.00246238
I1007 14:48:16.911641  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00246208 (* 1 = 0.00246208 loss)
I1007 14:48:16.911648  4874 sgd_solver.cpp:105] Iteration 95300, lr = 0.001
I1007 14:48:25.003959  4874 solver.cpp:218] Iteration 95400 (12.3574 iter/s, 8.09229s/100 iters), loss = 0.000865457
I1007 14:48:25.003989  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000865159 (* 1 = 0.000865159 loss)
I1007 14:48:25.003995  4874 sgd_solver.cpp:105] Iteration 95400, lr = 0.001
I1007 14:48:32.700284  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:48:33.025419  4874 solver.cpp:330] Iteration 95500, Testing net (#0)
I1007 14:48:34.917379  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:48:34.996078  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9233
I1007 14:48:34.996112  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.320888 (* 1 = 0.320888 loss)
I1007 14:48:35.077033  4874 solver.cpp:218] Iteration 95500 (9.92752 iter/s, 10.073s/100 iters), loss = 0.00109766
I1007 14:48:35.077059  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00109736 (* 1 = 0.00109736 loss)
I1007 14:48:35.077066  4874 sgd_solver.cpp:105] Iteration 95500, lr = 0.001
I1007 14:48:43.181293  4874 solver.cpp:218] Iteration 95600 (12.3393 iter/s, 8.10421s/100 iters), loss = 0.00128301
I1007 14:48:43.181356  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00128271 (* 1 = 0.00128271 loss)
I1007 14:48:43.181375  4874 sgd_solver.cpp:105] Iteration 95600, lr = 0.001
I1007 14:48:51.289585  4874 solver.cpp:218] Iteration 95700 (12.3332 iter/s, 8.1082s/100 iters), loss = 0.00728372
I1007 14:48:51.289616  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00728342 (* 1 = 0.00728342 loss)
I1007 14:48:51.289633  4874 sgd_solver.cpp:105] Iteration 95700, lr = 0.001
I1007 14:48:59.394834  4874 solver.cpp:218] Iteration 95800 (12.3378 iter/s, 8.10519s/100 iters), loss = 0.000924078
I1007 14:48:59.394862  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000923778 (* 1 = 0.000923778 loss)
I1007 14:48:59.394868  4874 sgd_solver.cpp:105] Iteration 95800, lr = 0.001
I1007 14:49:07.510476  4874 solver.cpp:218] Iteration 95900 (12.322 iter/s, 8.11559s/100 iters), loss = 0.00114838
I1007 14:49:07.510506  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00114808 (* 1 = 0.00114808 loss)
I1007 14:49:07.510522  4874 sgd_solver.cpp:105] Iteration 95900, lr = 0.001
I1007 14:49:15.216457  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:49:15.541262  4874 solver.cpp:330] Iteration 96000, Testing net (#0)
I1007 14:49:17.434921  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:49:17.513859  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9241
I1007 14:49:17.513882  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.320227 (* 1 = 0.320227 loss)
I1007 14:49:17.594940  4874 solver.cpp:218] Iteration 96000 (9.9163 iter/s, 10.0844s/100 iters), loss = 0.0010202
I1007 14:49:17.594969  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0010199 (* 1 = 0.0010199 loss)
I1007 14:49:17.594976  4874 sgd_solver.cpp:105] Iteration 96000, lr = 0.001
I1007 14:49:25.698657  4874 solver.cpp:218] Iteration 96100 (12.3401 iter/s, 8.10366s/100 iters), loss = 0.00126348
I1007 14:49:25.698688  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00126319 (* 1 = 0.00126319 loss)
I1007 14:49:25.698693  4874 sgd_solver.cpp:105] Iteration 96100, lr = 0.001
I1007 14:49:33.790648  4874 solver.cpp:218] Iteration 96200 (12.358 iter/s, 8.09193s/100 iters), loss = 0.0025922
I1007 14:49:33.790689  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00259191 (* 1 = 0.00259191 loss)
I1007 14:49:33.790695  4874 sgd_solver.cpp:105] Iteration 96200, lr = 0.001
I1007 14:49:41.887019  4874 solver.cpp:218] Iteration 96300 (12.3513 iter/s, 8.0963s/100 iters), loss = 0.00202282
I1007 14:49:41.887058  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00202252 (* 1 = 0.00202252 loss)
I1007 14:49:41.887064  4874 sgd_solver.cpp:105] Iteration 96300, lr = 0.001
I1007 14:49:49.982686  4874 solver.cpp:218] Iteration 96400 (12.3524 iter/s, 8.0956s/100 iters), loss = 0.00109152
I1007 14:49:49.982754  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00109122 (* 1 = 0.00109122 loss)
I1007 14:49:49.982772  4874 sgd_solver.cpp:105] Iteration 96400, lr = 0.001
I1007 14:49:57.685494  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:49:58.010689  4874 solver.cpp:330] Iteration 96500, Testing net (#0)
I1007 14:49:59.903040  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:49:59.982164  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9234
I1007 14:49:59.982190  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.320855 (* 1 = 0.320855 loss)
I1007 14:50:00.062997  4874 solver.cpp:218] Iteration 96500 (9.92043 iter/s, 10.0802s/100 iters), loss = 0.000356714
I1007 14:50:00.063024  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000356422 (* 1 = 0.000356422 loss)
I1007 14:50:00.063030  4874 sgd_solver.cpp:105] Iteration 96500, lr = 0.001
I1007 14:50:08.162142  4874 solver.cpp:218] Iteration 96600 (12.3471 iter/s, 8.09909s/100 iters), loss = 0.00467325
I1007 14:50:08.162184  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00467296 (* 1 = 0.00467296 loss)
I1007 14:50:08.162189  4874 sgd_solver.cpp:105] Iteration 96600, lr = 0.001
I1007 14:50:16.264892  4874 solver.cpp:218] Iteration 96700 (12.3416 iter/s, 8.10268s/100 iters), loss = 0.00191337
I1007 14:50:16.264924  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00191308 (* 1 = 0.00191308 loss)
I1007 14:50:16.264930  4874 sgd_solver.cpp:105] Iteration 96700, lr = 0.001
I1007 14:50:24.367444  4874 solver.cpp:218] Iteration 96800 (12.3419 iter/s, 8.10249s/100 iters), loss = 0.00509837
I1007 14:50:24.367547  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00509808 (* 1 = 0.00509808 loss)
I1007 14:50:24.367555  4874 sgd_solver.cpp:105] Iteration 96800, lr = 0.001
I1007 14:50:32.471699  4874 solver.cpp:218] Iteration 96900 (12.3394 iter/s, 8.10413s/100 iters), loss = 0.00137351
I1007 14:50:32.471729  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00137322 (* 1 = 0.00137322 loss)
I1007 14:50:32.471745  4874 sgd_solver.cpp:105] Iteration 96900, lr = 0.001
I1007 14:50:40.170958  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:50:40.495517  4874 solver.cpp:330] Iteration 97000, Testing net (#0)
I1007 14:50:42.389024  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:50:42.468253  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.924
I1007 14:50:42.468279  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.320465 (* 1 = 0.320465 loss)
I1007 14:50:42.548955  4874 solver.cpp:218] Iteration 97000 (9.92339 iter/s, 10.0772s/100 iters), loss = 0.00122117
I1007 14:50:42.548985  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00122088 (* 1 = 0.00122088 loss)
I1007 14:50:42.548992  4874 sgd_solver.cpp:105] Iteration 97000, lr = 0.001
I1007 14:50:50.657069  4874 solver.cpp:218] Iteration 97100 (12.3334 iter/s, 8.10806s/100 iters), loss = 0.000228994
I1007 14:50:50.657099  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000228709 (* 1 = 0.000228709 loss)
I1007 14:50:50.657104  4874 sgd_solver.cpp:105] Iteration 97100, lr = 0.001
I1007 14:50:58.766212  4874 solver.cpp:218] Iteration 97200 (12.3318 iter/s, 8.10909s/100 iters), loss = 0.0067589
I1007 14:50:58.766337  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00675862 (* 1 = 0.00675862 loss)
I1007 14:50:58.766345  4874 sgd_solver.cpp:105] Iteration 97200, lr = 0.001
I1007 14:51:06.875774  4874 solver.cpp:218] Iteration 97300 (12.3314 iter/s, 8.10941s/100 iters), loss = 0.000971137
I1007 14:51:06.875805  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000970852 (* 1 = 0.000970852 loss)
I1007 14:51:06.875821  4874 sgd_solver.cpp:105] Iteration 97300, lr = 0.001
I1007 14:51:14.977115  4874 solver.cpp:218] Iteration 97400 (12.3437 iter/s, 8.10128s/100 iters), loss = 0.000446972
I1007 14:51:14.977145  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000446685 (* 1 = 0.000446685 loss)
I1007 14:51:14.977151  4874 sgd_solver.cpp:105] Iteration 97400, lr = 0.001
I1007 14:51:22.676385  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:51:23.001008  4874 solver.cpp:330] Iteration 97500, Testing net (#0)
I1007 14:51:24.892767  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:51:24.971824  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.924
I1007 14:51:24.971856  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.321398 (* 1 = 0.321398 loss)
I1007 14:51:25.052382  4874 solver.cpp:218] Iteration 97500 (9.92535 iter/s, 10.0752s/100 iters), loss = 0.00121661
I1007 14:51:25.052409  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00121632 (* 1 = 0.00121632 loss)
I1007 14:51:25.052417  4874 sgd_solver.cpp:105] Iteration 97500, lr = 0.001
I1007 14:51:33.148365  4874 solver.cpp:218] Iteration 97600 (12.3519 iter/s, 8.09593s/100 iters), loss = 0.00460174
I1007 14:51:33.148452  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00460145 (* 1 = 0.00460145 loss)
I1007 14:51:33.148460  4874 sgd_solver.cpp:105] Iteration 97600, lr = 0.001
I1007 14:51:41.244855  4874 solver.cpp:218] Iteration 97700 (12.3512 iter/s, 8.09638s/100 iters), loss = 0.00648536
I1007 14:51:41.244885  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00648507 (* 1 = 0.00648507 loss)
I1007 14:51:41.244892  4874 sgd_solver.cpp:105] Iteration 97700, lr = 0.001
I1007 14:51:49.337394  4874 solver.cpp:218] Iteration 97800 (12.3572 iter/s, 8.09248s/100 iters), loss = 0.00432685
I1007 14:51:49.337430  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00432657 (* 1 = 0.00432657 loss)
I1007 14:51:49.337438  4874 sgd_solver.cpp:105] Iteration 97800, lr = 0.001
I1007 14:51:57.432416  4874 solver.cpp:218] Iteration 97900 (12.3534 iter/s, 8.09496s/100 iters), loss = 0.000855093
I1007 14:51:57.432456  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000854807 (* 1 = 0.000854807 loss)
I1007 14:51:57.432462  4874 sgd_solver.cpp:105] Iteration 97900, lr = 0.001
I1007 14:52:05.132318  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:52:05.456733  4874 solver.cpp:330] Iteration 98000, Testing net (#0)
I1007 14:52:07.349397  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:52:07.428697  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9237
I1007 14:52:07.428731  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.320071 (* 1 = 0.320071 loss)
I1007 14:52:07.509251  4874 solver.cpp:218] Iteration 98000 (9.92382 iter/s, 10.0768s/100 iters), loss = 0.000539038
I1007 14:52:07.509279  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000538751 (* 1 = 0.000538751 loss)
I1007 14:52:07.509285  4874 sgd_solver.cpp:105] Iteration 98000, lr = 0.001
I1007 14:52:15.609669  4874 solver.cpp:218] Iteration 98100 (12.3451 iter/s, 8.10036s/100 iters), loss = 0.00212342
I1007 14:52:15.609702  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00212313 (* 1 = 0.00212313 loss)
I1007 14:52:15.609709  4874 sgd_solver.cpp:105] Iteration 98100, lr = 0.001
I1007 14:52:23.706959  4874 solver.cpp:218] Iteration 98200 (12.3499 iter/s, 8.09723s/100 iters), loss = 0.00225012
I1007 14:52:23.707000  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00224983 (* 1 = 0.00224983 loss)
I1007 14:52:23.707005  4874 sgd_solver.cpp:105] Iteration 98200, lr = 0.001
I1007 14:52:31.807098  4874 solver.cpp:218] Iteration 98300 (12.3456 iter/s, 8.10007s/100 iters), loss = 0.00202263
I1007 14:52:31.807137  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00202235 (* 1 = 0.00202235 loss)
I1007 14:52:31.807143  4874 sgd_solver.cpp:105] Iteration 98300, lr = 0.001
I1007 14:52:39.906266  4874 solver.cpp:218] Iteration 98400 (12.347 iter/s, 8.0991s/100 iters), loss = 0.000419223
I1007 14:52:39.906343  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000418938 (* 1 = 0.000418938 loss)
I1007 14:52:39.906359  4874 sgd_solver.cpp:105] Iteration 98400, lr = 0.001
I1007 14:52:47.608242  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:52:47.933336  4874 solver.cpp:330] Iteration 98500, Testing net (#0)
I1007 14:52:49.824826  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:52:49.903911  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.924
I1007 14:52:49.903936  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.319572 (* 1 = 0.319572 loss)
I1007 14:52:49.984674  4874 solver.cpp:218] Iteration 98500 (9.9223 iter/s, 10.0783s/100 iters), loss = 0.00163642
I1007 14:52:49.984700  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00163613 (* 1 = 0.00163613 loss)
I1007 14:52:49.984707  4874 sgd_solver.cpp:105] Iteration 98500, lr = 0.001
I1007 14:52:58.077322  4874 solver.cpp:218] Iteration 98600 (12.357 iter/s, 8.09259s/100 iters), loss = 0.0025773
I1007 14:52:58.077353  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00257701 (* 1 = 0.00257701 loss)
I1007 14:52:58.077358  4874 sgd_solver.cpp:105] Iteration 98600, lr = 0.001
I1007 14:53:06.178066  4874 solver.cpp:218] Iteration 98700 (12.3446 iter/s, 8.10069s/100 iters), loss = 0.00221913
I1007 14:53:06.178097  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00221885 (* 1 = 0.00221885 loss)
I1007 14:53:06.178102  4874 sgd_solver.cpp:105] Iteration 98700, lr = 0.001
I1007 14:53:14.275624  4874 solver.cpp:218] Iteration 98800 (12.3495 iter/s, 8.0975s/100 iters), loss = 0.00133022
I1007 14:53:14.275704  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00132994 (* 1 = 0.00132994 loss)
I1007 14:53:14.275719  4874 sgd_solver.cpp:105] Iteration 98800, lr = 0.001
I1007 14:53:22.380686  4874 solver.cpp:218] Iteration 98900 (12.3381 iter/s, 8.10496s/100 iters), loss = 0.00104503
I1007 14:53:22.380717  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00104474 (* 1 = 0.00104474 loss)
I1007 14:53:22.380722  4874 sgd_solver.cpp:105] Iteration 98900, lr = 0.001
I1007 14:53:30.068527  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:53:30.392361  4874 solver.cpp:330] Iteration 99000, Testing net (#0)
I1007 14:53:32.281112  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:53:32.359830  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9231
I1007 14:53:32.359866  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.31984 (* 1 = 0.31984 loss)
I1007 14:53:32.441190  4874 solver.cpp:218] Iteration 99000 (9.93992 iter/s, 10.0604s/100 iters), loss = 0.00142094
I1007 14:53:32.441217  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00142065 (* 1 = 0.00142065 loss)
I1007 14:53:32.441224  4874 sgd_solver.cpp:105] Iteration 99000, lr = 0.001
I1007 14:53:40.540915  4874 solver.cpp:218] Iteration 99100 (12.3462 iter/s, 8.09967s/100 iters), loss = 0.00285245
I1007 14:53:40.540956  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00285216 (* 1 = 0.00285216 loss)
I1007 14:53:40.540961  4874 sgd_solver.cpp:105] Iteration 99100, lr = 0.001
I1007 14:53:48.637708  4874 solver.cpp:218] Iteration 99200 (12.3507 iter/s, 8.09673s/100 iters), loss = 0.00629687
I1007 14:53:48.637850  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00629659 (* 1 = 0.00629659 loss)
I1007 14:53:48.637869  4874 sgd_solver.cpp:105] Iteration 99200, lr = 0.001
I1007 14:53:56.739084  4874 solver.cpp:218] Iteration 99300 (12.3438 iter/s, 8.10122s/100 iters), loss = 0.000931112
I1007 14:53:56.739123  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000930823 (* 1 = 0.000930823 loss)
I1007 14:53:56.739130  4874 sgd_solver.cpp:105] Iteration 99300, lr = 0.001
I1007 14:54:04.846029  4874 solver.cpp:218] Iteration 99400 (12.3352 iter/s, 8.10688s/100 iters), loss = 0.000650558
I1007 14:54:04.846058  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00065027 (* 1 = 0.00065027 loss)
I1007 14:54:04.846063  4874 sgd_solver.cpp:105] Iteration 99400, lr = 0.001
I1007 14:54:12.540870  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:54:12.865690  4874 solver.cpp:330] Iteration 99500, Testing net (#0)
I1007 14:54:14.757287  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:54:14.836484  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.923
I1007 14:54:14.836519  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.320065 (* 1 = 0.320065 loss)
I1007 14:54:14.917381  4874 solver.cpp:218] Iteration 99500 (9.92921 iter/s, 10.0713s/100 iters), loss = 0.00191214
I1007 14:54:14.917408  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00191185 (* 1 = 0.00191185 loss)
I1007 14:54:14.917414  4874 sgd_solver.cpp:105] Iteration 99500, lr = 0.001
I1007 14:54:23.008747  4874 solver.cpp:218] Iteration 99600 (12.3589 iter/s, 8.09131s/100 iters), loss = 0.000944711
I1007 14:54:23.008864  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000944422 (* 1 = 0.000944422 loss)
I1007 14:54:23.008882  4874 sgd_solver.cpp:105] Iteration 99600, lr = 0.001
I1007 14:54:31.097012  4874 solver.cpp:218] Iteration 99700 (12.3638 iter/s, 8.08812s/100 iters), loss = 0.0169977
I1007 14:54:31.097039  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0169974 (* 1 = 0.0169974 loss)
I1007 14:54:31.097045  4874 sgd_solver.cpp:105] Iteration 99700, lr = 0.001
I1007 14:54:39.199980  4874 solver.cpp:218] Iteration 99800 (12.3412 iter/s, 8.10291s/100 iters), loss = 0.00115237
I1007 14:54:39.200009  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00115208 (* 1 = 0.00115208 loss)
I1007 14:54:39.200016  4874 sgd_solver.cpp:105] Iteration 99800, lr = 0.001
I1007 14:54:47.304893  4874 solver.cpp:218] Iteration 99900 (12.3383 iter/s, 8.10486s/100 iters), loss = 0.0047306
I1007 14:54:47.304934  4874 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00473031 (* 1 = 0.00473031 loss)
I1007 14:54:47.304939  4874 sgd_solver.cpp:105] Iteration 99900, lr = 0.001
I1007 14:54:55.005908  4882 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:54:55.329376  4874 solver.cpp:447] Snapshotting to binary proto file xn/PENLU/snapshot/resnet/res32/res32_mpelu_alpha0.25_beta1_2study_2decay_gauss_iter_100000.caffemodel
I1007 14:54:55.341665  4874 sgd_solver.cpp:273] Snapshotting solver state to binary proto file xn/PENLU/snapshot/resnet/res32/res32_mpelu_alpha0.25_beta1_2study_2decay_gauss_iter_100000.solverstate
I1007 14:54:55.364531  4874 solver.cpp:310] Iteration 100000, loss = 0.00190454
I1007 14:54:55.364550  4874 solver.cpp:330] Iteration 100000, Testing net (#0)
I1007 14:54:57.256397  4883 data_layer.cpp:73] Restarting data prefetching from start.
I1007 14:54:57.335790  4874 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9245
I1007 14:54:57.335824  4874 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.320407 (* 1 = 0.320407 loss)
I1007 14:54:57.335829  4874 solver.cpp:315] Optimization Done.
I1007 14:54:57.335831  4874 caffe.cpp:259] Optimization Done.
