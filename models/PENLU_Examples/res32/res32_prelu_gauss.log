I1006 20:10:33.763945  3817 caffe.cpp:218] Using GPUs 0
I1006 20:10:33.788563  3817 caffe.cpp:223] GPU 0: GeForce GTX 1080
I1006 20:10:34.018276  3817 solver.cpp:44] Initializing solver from parameters: 
test_iter: 100
test_interval: 500
base_lr: 0.1
display: 100
max_iter: 100000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0001
snapshot: 100000
snapshot_prefix: "xn/PENLU/snapshot/resnet/res32/res32_prelu_gauss"
solver_mode: GPU
device_id: 0
net: "/home/x306/caffe/xn/PENLU/neural/resnet/res32/res32_prelu_train_test.prototxt"
train_state {
  level: 0
  stage: ""
}
stepvalue: 40000
stepvalue: 80000
I1006 20:10:34.018429  3817 solver.cpp:87] Creating training net from net file: /home/x306/caffe/xn/PENLU/neural/resnet/res32/res32_prelu_train_test.prototxt
I1006 20:10:34.020200  3817 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: /home/x306/caffe/xn/PENLU/neural/resnet/res32/res32_prelu_train_test.prototxt
I1006 20:10:34.020210  3817 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I1006 20:10:34.020376  3817 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer Data1
I1006 20:10:34.020449  3817 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer Accuracy1
I1006 20:10:34.020967  3817 net.cpp:51] Initializing net from parameters: 
name: "resnet_cifar10"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "Data1"
  type: "Data"
  top: "Data1"
  top: "Data2"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 28
    mean_file: "/home/x306/caffe/xn/PENLU/data/cifar10/mean.binaryproto"
  }
  data_param {
    source: "/home/x306/caffe/xn/PENLU/data/cifar10/cifar10_train_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "Convolution1"
  type: "Convolution"
  bottom: "Data1"
  top: "Convolution1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm1"
  type: "BatchNorm"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1"
  type: "Scale"
  bottom: "Convolution1"
  top: "Convolution1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "PReLU1"
  type: "PReLU"
  bottom: "Convolution1"
  top: "Convolution1"
}
layer {
  name: "Convolution2"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm2"
  type: "BatchNorm"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale2"
  type: "Scale"
  bottom: "Convolution2"
  top: "Convolution2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "PReLU2"
  type: "PReLU"
  bottom: "Convolution2"
  top: "Convolution2"
}
layer {
  name: "Convolution3"
  type: "Convolution"
  bottom: "Convolution2"
  top: "Convolution3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm3"
  type: "BatchNorm"
  bottom: "Convolution3"
  top: "Convolution3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale3"
  type: "Scale"
  bottom: "Convolution3"
  top: "Convolution3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise1"
  type: "Eltwise"
  bottom: "Convolution1"
  bottom: "Convolution3"
  top: "Eltwise1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "PReLU3"
  type: "PReLU"
  bottom: "Eltwise1"
  top: "Eltwise1"
}
layer {
  name: "Convolution4"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm4"
  type: "BatchNorm"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale4"
  type: "Scale"
  bottom: "Convolution4"
  top: "Convolution4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "PReLU4"
  type: "PReLU"
  bottom: "Convolution4"
  top: "Convolution4"
}
layer {
  name: "Convolution5"
  type: "Convolution"
  bottom: "Convolution4"
  top: "Convolution5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm5"
  type: "BatchNorm"
  bottom: "Convolution5"
  top: "Convolution5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale5"
  type: "Scale"
  bottom: "Convolution5"
  top: "Convolution5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise2"
  type: "Eltwise"
  bottom: "Eltwise1"
  bottom: "Convolution5"
  top: "Eltwise2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "PReLU5"
  type: "PReLU"
  bottom: "Eltwise2"
  top: "Eltwise2"
}
layer {
  name: "Convolution6"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm6"
  type: "BatchNorm"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale6"
  type: "Scale"
  bottom: "Convolution6"
  top: "Convolution6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "PReLU6"
  type: "PReLU"
  bottom: "Convolution6"
  top: "Convolution6"
}
layer {
  name: "Convolution7"
  type: "Convolution"
  bottom: "Convolution6"
  top: "Convolution7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm7"
  type: "BatchNorm"
  bottom: "Convolution7"
  top: "Convolution7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale7"
  type: "Scale"
  bottom: "Convolution7"
  top: "Convolution7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise3"
  type: "Eltwise"
  bottom: "Eltwise2"
  bottom: "Convolution7"
  top: "Eltwise3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "PReLU7"
  type: "PReLU"
  bottom: "Eltwise3"
  top: "Eltwise3"
}
layer {
  name: "Convolution8"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm8"
  type: "BatchNorm"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale8"
  type: "Scale"
  bottom: "Convolution8"
  top: "Convolution8"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "PReLU8"
  type: "PReLU"
  bottom: "Convolution8"
  top: "Convolution8"
}
layer {
  name: "Convolution9"
  type: "Convolution"
  bottom: "Convolution8"
  top: "Convolution9"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm9"
  type: "BatchNorm"
  bottom: "Convolution9"
  top: "Convolution9"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale9"
  type: "Scale"
  bottom: "Convolution9"
  top: "Convolution9"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise4"
  type: "Eltwise"
  bottom: "Eltwise3"
  bottom: "Convolution9"
  top: "Eltwise4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "PReLU9"
  type: "PReLU"
  bottom: "Eltwise4"
  top: "Eltwise4"
}
layer {
  name: "Convolution10"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution10"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm10"
  type: "BatchNorm"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale10"
  type: "Scale"
  bottom: "Convolution10"
  top: "Convolution10"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "PReLU10"
  type: "PReLU"
  bottom: "Convolution10"
  top: "Convolution10"
}
layer {
  name: "Convolution11"
  type: "Convolution"
  bottom: "Convolution10"
  top: "Convolution11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm11"
  type: "BatchNorm"
  bottom: "Convolution11"
  top: "Convolution11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale11"
  type: "Scale"
  bottom: "Convolution11"
  top: "Convolution11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise5"
  type: "Eltwise"
  bottom: "Eltwise4"
  bottom: "Convolution11"
  top: "Eltwise5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "PReLU11"
  type: "PReLU"
  bottom: "Eltwise5"
  top: "Eltwise5"
}
layer {
  name: "Convolution12"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.25
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm12"
  type: "BatchNorm"
  bottom: "Convolution12"
  top: "Convolution12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale12"
  type: "Scale"
  bottom: "Convolution12"
  top: "Convolution12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution13"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution13"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm13"
  type: "BatchNorm"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale13"
  type: "Scale"
  bottom: "Convolution13"
  top: "Convolution13"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "PReLU12"
  type: "PReLU"
  bottom: "Convolution13"
  top: "Convolution13"
}
layer {
  name: "Convolution14"
  type: "Convolution"
  bottom: "Convolution13"
  top: "Convolution14"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm14"
  type: "BatchNorm"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale14"
  type: "Scale"
  bottom: "Convolution14"
  top: "Convolution14"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise6"
  type: "Eltwise"
  bottom: "Convolution12"
  bottom: "Convolution14"
  top: "Eltwise6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "PReLU13"
  type: "PReLU"
  bottom: "Eltwise6"
  top: "Eltwise6"
}
layer {
  name: "Convolution15"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution15"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm15"
  type: "BatchNorm"
  bottom: "Convolution15"
  top: "Convolution15"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale15"
  type: "Scale"
  bottom: "Convolution15"
  top: "Convolution15"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "PReLU14"
  type: "PReLU"
  bottom: "Convolution15"
  top: "Convolution15"
}
layer {
  name: "Convolution16"
  type: "Convolution"
  bottom: "Convolution15"
  top: "Convolution16"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm16"
  type: "BatchNorm"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale16"
  type: "Scale"
  bottom: "Convolution16"
  top: "Convolution16"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise7"
  type: "Eltwise"
  bottom: "Eltwise6"
  bottom: "Convolution16"
  top: "Eltwise7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "PReLU15"
  type: "PReLU"
  bottom: "Eltwise7"
  top: "Eltwise7"
}
layer {
  name: "Convolution17"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution17"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm17"
  type: "BatchNorm"
  bottom: "Convolution17"
  top: "Convolution17"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale17"
  type: "Scale"
  bottom: "Convolution17"
  top: "Convolution17"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "PReLU16"
  type: "PReLU"
  bottom: "Convolution17"
  top: "Convolution17"
}
layer {
  name: "Convolution18"
  type: "Convolution"
  bottom: "Convolution17"
  top: "Convolution18"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm18"
  type: "BatchNorm"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale18"
  type: "Scale"
  bottom: "Convolution18"
  top: "Convolution18"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise8"
  type: "Eltwise"
  bottom: "Eltwise7"
  bottom: "Convolution18"
  top: "Eltwise8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "PReLU17"
  type: "PReLU"
  bottom: "Eltwise8"
  top: "Eltwise8"
}
layer {
  name: "Convolution19"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution19"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm19"
  type: "BatchNorm"
  bottom: "Convolution19"
  top: "Convolution19"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale19"
  type: "Scale"
  bottom: "Convolution19"
  top: "Convolution19"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "PReLU18"
  type: "PReLU"
  bottom: "Convolution19"
  top: "Convolution19"
}
layer {
  name: "Convolution20"
  type: "Convolution"
  bottom: "Convolution19"
  top: "Convolution20"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm20"
  type: "BatchNorm"
  bottom: "Convolution20"
  top: "Convolution20"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale20"
  type: "Scale"
  bottom: "Convolution20"
  top: "Convolution20"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise9"
  type: "Eltwise"
  bottom: "Eltwise8"
  bottom: "Convolution20"
  top: "Eltwise9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "PReLU19"
  type: "PReLU"
  bottom: "Eltwise9"
  top: "Eltwise9"
}
layer {
  name: "Convolution21"
  type: "Convolution"
  bottom: "Eltwise9"
  top: "Convolution21"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm21"
  type: "BatchNorm"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale21"
  type: "Scale"
  bottom: "Convolution21"
  top: "Convolution21"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "PReLU20"
  type: "PReLU"
  bottom: "Convolution21"
  top: "Convolution21"
}
layer {
  name: "Convolution22"
  type: "Convolution"
  bottom: "Convolution21"
  top: "Convolution22"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm22"
  type: "BatchNorm"
  bottom: "Convolution22"
  top: "Convolution22"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale22"
  type: "Scale"
  bottom: "Convolution22"
  top: "Convolution22"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise10"
  type: "Eltwise"
  bottom: "Eltwise9"
  bottom: "Convolution22"
  top: "Eltwise10"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "PReLU21"
  type: "PReLU"
  bottom: "Eltwise10"
  top: "Eltwise10"
}
layer {
  name: "Convolution23"
  type: "Convolution"
  bottom: "Eltwise10"
  top: "Convolution23"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.17677669
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm23"
  type: "BatchNorm"
  bottom: "Convolution23"
  top: "Convolution23"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale23"
  type: "Scale"
  bottom: "Convolution23"
  top: "Convolution23"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution24"
  type: "Convolution"
  bottom: "Eltwise10"
  top: "Convolution24"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm24"
  type: "BatchNorm"
  bottom: "Convolution24"
  top: "Convolution24"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale24"
  type: "Scale"
  bottom: "Convolution24"
  top: "Convolution24"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "PReLU22"
  type: "PReLU"
  bottom: "Convolution24"
  top: "Convolution24"
}
layer {
  name: "Convolution25"
  type: "Convolution"
  bottom: "Convolution24"
  top: "Convolution25"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm25"
  type: "BatchNorm"
  bottom: "Convolution25"
  top: "Convolution25"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale25"
  type: "Scale"
  bottom: "Convolution25"
  top: "Convolution25"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise11"
  type: "Eltwise"
  bottom: "Convolution23"
  bottom: "Convolution25"
  top: "Eltwise11"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "PReLU23"
  type: "PReLU"
  bottom: "Eltwise11"
  top: "Eltwise11"
}
layer {
  name: "Convolution26"
  type: "Convolution"
  bottom: "Eltwise11"
  top: "Convolution26"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm26"
  type: "BatchNorm"
  bottom: "Convolution26"
  top: "Convolution26"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale26"
  type: "Scale"
  bottom: "Convolution26"
  top: "Convolution26"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "PReLU24"
  type: "PReLU"
  bottom: "Convolution26"
  top: "Convolution26"
}
layer {
  name: "Convolution27"
  type: "Convolution"
  bottom: "Convolution26"
  top: "Convolution27"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm27"
  type: "BatchNorm"
  bottom: "Convolution27"
  top: "Convolution27"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale27"
  type: "Scale"
  bottom: "Convolution27"
  top: "Convolution27"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise12"
  type: "Eltwise"
  bottom: "Eltwise11"
  bottom: "Convolution27"
  top: "Eltwise12"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "PReLU25"
  type: "PReLU"
  bottom: "Eltwise12"
  top: "Eltwise12"
}
layer {
  name: "Convolution28"
  type: "Convolution"
  bottom: "Eltwise12"
  top: "Convolution28"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm28"
  type: "BatchNorm"
  bottom: "Convolution28"
  top: "Convolution28"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale28"
  type: "Scale"
  bottom: "Convolution28"
  top: "Convolution28"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "PReLU26"
  type: "PReLU"
  bottom: "Convolution28"
  top: "Convolution28"
}
layer {
  name: "Convolution29"
  type: "Convolution"
  bottom: "Convolution28"
  top: "Convolution29"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm29"
  type: "BatchNorm"
  bottom: "Convolution29"
  top: "Convolution29"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale29"
  type: "Scale"
  bottom: "Convolution29"
  top: "Convolution29"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise13"
  type: "Eltwise"
  bottom: "Eltwise12"
  bottom: "Convolution29"
  top: "Eltwise13"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "PReLU27"
  type: "PReLU"
  bottom: "Eltwise13"
  top: "Eltwise13"
}
layer {
  name: "Convolution30"
  type: "Convolution"
  bottom: "Eltwise13"
  top: "Convolution30"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm30"
  type: "BatchNorm"
  bottom: "Convolution30"
  top: "Convolution30"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale30"
  type: "Scale"
  bottom: "Convolution30"
  top: "Convolution30"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "PReLU28"
  type: "PReLU"
  bottom: "Convolution30"
  top: "Convolution30"
}
layer {
  name: "Convolution31"
  type: "Convolution"
  bottom: "Convolution30"
  top: "Convolution31"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm31"
  type: "BatchNorm"
  bottom: "Convolution31"
  top: "Convolution31"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale31"
  type: "Scale"
  bottom: "Convolution31"
  top: "Convolution31"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise14"
  type: "Eltwise"
  bottom: "Eltwise13"
  bottom: "Convolution31"
  top: "Eltwise14"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "PReLU29"
  type: "PReLU"
  bottom: "Eltwise14"
  top: "Eltwise14"
}
layer {
  name: "Convolution32"
  type: "Convolution"
  bottom: "Eltwise14"
  top: "Convolution32"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    
I1006 20:10:34.021384  3817 layer_factory.hpp:77] Creating layer Data1
I1006 20:10:34.021459  3817 db_lmdb.cpp:35] Opened lmdb /home/x306/caffe/xn/PENLU/data/cifar10/cifar10_train_lmdb
I1006 20:10:34.021479  3817 net.cpp:84] Creating Layer Data1
I1006 20:10:34.021484  3817 net.cpp:380] Data1 -> Data1
I1006 20:10:34.021502  3817 net.cpp:380] Data1 -> Data2
I1006 20:10:34.021514  3817 data_transformer.cpp:25] Loading mean file from: /home/x306/caffe/xn/PENLU/data/cifar10/mean.binaryproto
I1006 20:10:34.022927  3817 data_layer.cpp:45] output data size: 100,3,28,28
I1006 20:10:34.025241  3817 net.cpp:122] Setting up Data1
I1006 20:10:34.025254  3817 net.cpp:129] Top shape: 100 3 28 28 (235200)
I1006 20:10:34.025259  3817 net.cpp:129] Top shape: 100 (100)
I1006 20:10:34.025261  3817 net.cpp:137] Memory required for data: 941200
I1006 20:10:34.025267  3817 layer_factory.hpp:77] Creating layer Convolution1
I1006 20:10:34.025283  3817 net.cpp:84] Creating Layer Convolution1
I1006 20:10:34.025287  3817 net.cpp:406] Convolution1 <- Data1
I1006 20:10:34.025296  3817 net.cpp:380] Convolution1 -> Convolution1
I1006 20:10:34.171078  3817 net.cpp:122] Setting up Convolution1
I1006 20:10:34.171105  3817 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 20:10:34.171108  3817 net.cpp:137] Memory required for data: 5958800
I1006 20:10:34.171123  3817 layer_factory.hpp:77] Creating layer BatchNorm1
I1006 20:10:34.171135  3817 net.cpp:84] Creating Layer BatchNorm1
I1006 20:10:34.171150  3817 net.cpp:406] BatchNorm1 <- Convolution1
I1006 20:10:34.171188  3817 net.cpp:367] BatchNorm1 -> Convolution1 (in-place)
I1006 20:10:34.171335  3817 net.cpp:122] Setting up BatchNorm1
I1006 20:10:34.171341  3817 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 20:10:34.171344  3817 net.cpp:137] Memory required for data: 10976400
I1006 20:10:34.171351  3817 layer_factory.hpp:77] Creating layer Scale1
I1006 20:10:34.171362  3817 net.cpp:84] Creating Layer Scale1
I1006 20:10:34.171378  3817 net.cpp:406] Scale1 <- Convolution1
I1006 20:10:34.171383  3817 net.cpp:367] Scale1 -> Convolution1 (in-place)
I1006 20:10:34.171427  3817 layer_factory.hpp:77] Creating layer Scale1
I1006 20:10:34.171521  3817 net.cpp:122] Setting up Scale1
I1006 20:10:34.171526  3817 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 20:10:34.171528  3817 net.cpp:137] Memory required for data: 15994000
I1006 20:10:34.171532  3817 layer_factory.hpp:77] Creating layer PReLU1
I1006 20:10:34.171537  3817 net.cpp:84] Creating Layer PReLU1
I1006 20:10:34.171540  3817 net.cpp:406] PReLU1 <- Convolution1
I1006 20:10:34.171542  3817 net.cpp:367] PReLU1 -> Convolution1 (in-place)
I1006 20:10:34.172113  3817 net.cpp:122] Setting up PReLU1
I1006 20:10:34.172122  3817 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 20:10:34.172125  3817 net.cpp:137] Memory required for data: 21011600
I1006 20:10:34.172128  3817 layer_factory.hpp:77] Creating layer Convolution1_PReLU1_0_split
I1006 20:10:34.172133  3817 net.cpp:84] Creating Layer Convolution1_PReLU1_0_split
I1006 20:10:34.172137  3817 net.cpp:406] Convolution1_PReLU1_0_split <- Convolution1
I1006 20:10:34.172139  3817 net.cpp:380] Convolution1_PReLU1_0_split -> Convolution1_PReLU1_0_split_0
I1006 20:10:34.172154  3817 net.cpp:380] Convolution1_PReLU1_0_split -> Convolution1_PReLU1_0_split_1
I1006 20:10:34.172178  3817 net.cpp:122] Setting up Convolution1_PReLU1_0_split
I1006 20:10:34.172183  3817 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 20:10:34.172185  3817 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 20:10:34.172188  3817 net.cpp:137] Memory required for data: 31046800
I1006 20:10:34.172199  3817 layer_factory.hpp:77] Creating layer Convolution2
I1006 20:10:34.172216  3817 net.cpp:84] Creating Layer Convolution2
I1006 20:10:34.172220  3817 net.cpp:406] Convolution2 <- Convolution1_PReLU1_0_split_0
I1006 20:10:34.172224  3817 net.cpp:380] Convolution2 -> Convolution2
I1006 20:10:34.173058  3817 net.cpp:122] Setting up Convolution2
I1006 20:10:34.173069  3817 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 20:10:34.173072  3817 net.cpp:137] Memory required for data: 36064400
I1006 20:10:34.173089  3817 layer_factory.hpp:77] Creating layer BatchNorm2
I1006 20:10:34.173095  3817 net.cpp:84] Creating Layer BatchNorm2
I1006 20:10:34.173099  3817 net.cpp:406] BatchNorm2 <- Convolution2
I1006 20:10:34.173104  3817 net.cpp:367] BatchNorm2 -> Convolution2 (in-place)
I1006 20:10:34.173233  3817 net.cpp:122] Setting up BatchNorm2
I1006 20:10:34.173238  3817 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 20:10:34.173240  3817 net.cpp:137] Memory required for data: 41082000
I1006 20:10:34.173255  3817 layer_factory.hpp:77] Creating layer Scale2
I1006 20:10:34.173262  3817 net.cpp:84] Creating Layer Scale2
I1006 20:10:34.173265  3817 net.cpp:406] Scale2 <- Convolution2
I1006 20:10:34.173269  3817 net.cpp:367] Scale2 -> Convolution2 (in-place)
I1006 20:10:34.173305  3817 layer_factory.hpp:77] Creating layer Scale2
I1006 20:10:34.173396  3817 net.cpp:122] Setting up Scale2
I1006 20:10:34.173403  3817 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 20:10:34.173404  3817 net.cpp:137] Memory required for data: 46099600
I1006 20:10:34.173418  3817 layer_factory.hpp:77] Creating layer PReLU2
I1006 20:10:34.173424  3817 net.cpp:84] Creating Layer PReLU2
I1006 20:10:34.173426  3817 net.cpp:406] PReLU2 <- Convolution2
I1006 20:10:34.173429  3817 net.cpp:367] PReLU2 -> Convolution2 (in-place)
I1006 20:10:34.173493  3817 net.cpp:122] Setting up PReLU2
I1006 20:10:34.173498  3817 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 20:10:34.173508  3817 net.cpp:137] Memory required for data: 51117200
I1006 20:10:34.173512  3817 layer_factory.hpp:77] Creating layer Convolution3
I1006 20:10:34.173521  3817 net.cpp:84] Creating Layer Convolution3
I1006 20:10:34.173523  3817 net.cpp:406] Convolution3 <- Convolution2
I1006 20:10:34.173527  3817 net.cpp:380] Convolution3 -> Convolution3
I1006 20:10:34.174367  3817 net.cpp:122] Setting up Convolution3
I1006 20:10:34.174377  3817 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 20:10:34.174381  3817 net.cpp:137] Memory required for data: 56134800
I1006 20:10:34.174388  3817 layer_factory.hpp:77] Creating layer BatchNorm3
I1006 20:10:34.174393  3817 net.cpp:84] Creating Layer BatchNorm3
I1006 20:10:34.174397  3817 net.cpp:406] BatchNorm3 <- Convolution3
I1006 20:10:34.174401  3817 net.cpp:367] BatchNorm3 -> Convolution3 (in-place)
I1006 20:10:34.174517  3817 net.cpp:122] Setting up BatchNorm3
I1006 20:10:34.174522  3817 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 20:10:34.174525  3817 net.cpp:137] Memory required for data: 61152400
I1006 20:10:34.174530  3817 layer_factory.hpp:77] Creating layer Scale3
I1006 20:10:34.174535  3817 net.cpp:84] Creating Layer Scale3
I1006 20:10:34.174536  3817 net.cpp:406] Scale3 <- Convolution3
I1006 20:10:34.174540  3817 net.cpp:367] Scale3 -> Convolution3 (in-place)
I1006 20:10:34.174563  3817 layer_factory.hpp:77] Creating layer Scale3
I1006 20:10:34.174631  3817 net.cpp:122] Setting up Scale3
I1006 20:10:34.174636  3817 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 20:10:34.174638  3817 net.cpp:137] Memory required for data: 66170000
I1006 20:10:34.174643  3817 layer_factory.hpp:77] Creating layer Eltwise1
I1006 20:10:34.174648  3817 net.cpp:84] Creating Layer Eltwise1
I1006 20:10:34.174649  3817 net.cpp:406] Eltwise1 <- Convolution1_PReLU1_0_split_1
I1006 20:10:34.174652  3817 net.cpp:406] Eltwise1 <- Convolution3
I1006 20:10:34.174655  3817 net.cpp:380] Eltwise1 -> Eltwise1
I1006 20:10:34.174672  3817 net.cpp:122] Setting up Eltwise1
I1006 20:10:34.174676  3817 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 20:10:34.174679  3817 net.cpp:137] Memory required for data: 71187600
I1006 20:10:34.174681  3817 layer_factory.hpp:77] Creating layer PReLU3
I1006 20:10:34.174685  3817 net.cpp:84] Creating Layer PReLU3
I1006 20:10:34.174687  3817 net.cpp:406] PReLU3 <- Eltwise1
I1006 20:10:34.174690  3817 net.cpp:367] PReLU3 -> Eltwise1 (in-place)
I1006 20:10:34.174743  3817 net.cpp:122] Setting up PReLU3
I1006 20:10:34.174748  3817 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 20:10:34.174751  3817 net.cpp:137] Memory required for data: 76205200
I1006 20:10:34.174753  3817 layer_factory.hpp:77] Creating layer Eltwise1_PReLU3_0_split
I1006 20:10:34.174757  3817 net.cpp:84] Creating Layer Eltwise1_PReLU3_0_split
I1006 20:10:34.174762  3817 net.cpp:406] Eltwise1_PReLU3_0_split <- Eltwise1
I1006 20:10:34.174764  3817 net.cpp:380] Eltwise1_PReLU3_0_split -> Eltwise1_PReLU3_0_split_0
I1006 20:10:34.174768  3817 net.cpp:380] Eltwise1_PReLU3_0_split -> Eltwise1_PReLU3_0_split_1
I1006 20:10:34.174788  3817 net.cpp:122] Setting up Eltwise1_PReLU3_0_split
I1006 20:10:34.174793  3817 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 20:10:34.174796  3817 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 20:10:34.174799  3817 net.cpp:137] Memory required for data: 86240400
I1006 20:10:34.174801  3817 layer_factory.hpp:77] Creating layer Convolution4
I1006 20:10:34.174808  3817 net.cpp:84] Creating Layer Convolution4
I1006 20:10:34.174811  3817 net.cpp:406] Convolution4 <- Eltwise1_PReLU3_0_split_0
I1006 20:10:34.174815  3817 net.cpp:380] Convolution4 -> Convolution4
I1006 20:10:34.175626  3817 net.cpp:122] Setting up Convolution4
I1006 20:10:34.175637  3817 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 20:10:34.175639  3817 net.cpp:137] Memory required for data: 91258000
I1006 20:10:34.175644  3817 layer_factory.hpp:77] Creating layer BatchNorm4
I1006 20:10:34.175649  3817 net.cpp:84] Creating Layer BatchNorm4
I1006 20:10:34.175659  3817 net.cpp:406] BatchNorm4 <- Convolution4
I1006 20:10:34.175664  3817 net.cpp:367] BatchNorm4 -> Convolution4 (in-place)
I1006 20:10:34.175777  3817 net.cpp:122] Setting up BatchNorm4
I1006 20:10:34.175782  3817 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 20:10:34.175786  3817 net.cpp:137] Memory required for data: 96275600
I1006 20:10:34.175791  3817 layer_factory.hpp:77] Creating layer Scale4
I1006 20:10:34.175794  3817 net.cpp:84] Creating Layer Scale4
I1006 20:10:34.175798  3817 net.cpp:406] Scale4 <- Convolution4
I1006 20:10:34.175801  3817 net.cpp:367] Scale4 -> Convolution4 (in-place)
I1006 20:10:34.175825  3817 layer_factory.hpp:77] Creating layer Scale4
I1006 20:10:34.175892  3817 net.cpp:122] Setting up Scale4
I1006 20:10:34.175897  3817 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 20:10:34.175899  3817 net.cpp:137] Memory required for data: 101293200
I1006 20:10:34.175904  3817 layer_factory.hpp:77] Creating layer PReLU4
I1006 20:10:34.175907  3817 net.cpp:84] Creating Layer PReLU4
I1006 20:10:34.175910  3817 net.cpp:406] PReLU4 <- Convolution4
I1006 20:10:34.175914  3817 net.cpp:367] PReLU4 -> Convolution4 (in-place)
I1006 20:10:34.175964  3817 net.cpp:122] Setting up PReLU4
I1006 20:10:34.175969  3817 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 20:10:34.175971  3817 net.cpp:137] Memory required for data: 106310800
I1006 20:10:34.175974  3817 layer_factory.hpp:77] Creating layer Convolution5
I1006 20:10:34.175981  3817 net.cpp:84] Creating Layer Convolution5
I1006 20:10:34.175983  3817 net.cpp:406] Convolution5 <- Convolution4
I1006 20:10:34.175987  3817 net.cpp:380] Convolution5 -> Convolution5
I1006 20:10:34.176795  3817 net.cpp:122] Setting up Convolution5
I1006 20:10:34.176805  3817 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 20:10:34.176807  3817 net.cpp:137] Memory required for data: 111328400
I1006 20:10:34.176815  3817 layer_factory.hpp:77] Creating layer BatchNorm5
I1006 20:10:34.176820  3817 net.cpp:84] Creating Layer BatchNorm5
I1006 20:10:34.176823  3817 net.cpp:406] BatchNorm5 <- Convolution5
I1006 20:10:34.176827  3817 net.cpp:367] BatchNorm5 -> Convolution5 (in-place)
I1006 20:10:34.176939  3817 net.cpp:122] Setting up BatchNorm5
I1006 20:10:34.176944  3817 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 20:10:34.176947  3817 net.cpp:137] Memory required for data: 116346000
I1006 20:10:34.176951  3817 layer_factory.hpp:77] Creating layer Scale5
I1006 20:10:34.176956  3817 net.cpp:84] Creating Layer Scale5
I1006 20:10:34.176959  3817 net.cpp:406] Scale5 <- Convolution5
I1006 20:10:34.176964  3817 net.cpp:367] Scale5 -> Convolution5 (in-place)
I1006 20:10:34.176986  3817 layer_factory.hpp:77] Creating layer Scale5
I1006 20:10:34.177053  3817 net.cpp:122] Setting up Scale5
I1006 20:10:34.177058  3817 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 20:10:34.177060  3817 net.cpp:137] Memory required for data: 121363600
I1006 20:10:34.177064  3817 layer_factory.hpp:77] Creating layer Eltwise2
I1006 20:10:34.177069  3817 net.cpp:84] Creating Layer Eltwise2
I1006 20:10:34.177073  3817 net.cpp:406] Eltwise2 <- Eltwise1_PReLU3_0_split_1
I1006 20:10:34.177075  3817 net.cpp:406] Eltwise2 <- Convolution5
I1006 20:10:34.177078  3817 net.cpp:380] Eltwise2 -> Eltwise2
I1006 20:10:34.177093  3817 net.cpp:122] Setting up Eltwise2
I1006 20:10:34.177096  3817 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 20:10:34.177098  3817 net.cpp:137] Memory required for data: 126381200
I1006 20:10:34.177101  3817 layer_factory.hpp:77] Creating layer PReLU5
I1006 20:10:34.177104  3817 net.cpp:84] Creating Layer PReLU5
I1006 20:10:34.177106  3817 net.cpp:406] PReLU5 <- Eltwise2
I1006 20:10:34.177109  3817 net.cpp:367] PReLU5 -> Eltwise2 (in-place)
I1006 20:10:34.177162  3817 net.cpp:122] Setting up PReLU5
I1006 20:10:34.177167  3817 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 20:10:34.177170  3817 net.cpp:137] Memory required for data: 131398800
I1006 20:10:34.177172  3817 layer_factory.hpp:77] Creating layer Eltwise2_PReLU5_0_split
I1006 20:10:34.177182  3817 net.cpp:84] Creating Layer Eltwise2_PReLU5_0_split
I1006 20:10:34.177186  3817 net.cpp:406] Eltwise2_PReLU5_0_split <- Eltwise2
I1006 20:10:34.177188  3817 net.cpp:380] Eltwise2_PReLU5_0_split -> Eltwise2_PReLU5_0_split_0
I1006 20:10:34.177192  3817 net.cpp:380] Eltwise2_PReLU5_0_split -> Eltwise2_PReLU5_0_split_1
I1006 20:10:34.177214  3817 net.cpp:122] Setting up Eltwise2_PReLU5_0_split
I1006 20:10:34.177219  3817 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 20:10:34.177222  3817 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 20:10:34.177225  3817 net.cpp:137] Memory required for data: 141434000
I1006 20:10:34.177227  3817 layer_factory.hpp:77] Creating layer Convolution6
I1006 20:10:34.177233  3817 net.cpp:84] Creating Layer Convolution6
I1006 20:10:34.177237  3817 net.cpp:406] Convolution6 <- Eltwise2_PReLU5_0_split_0
I1006 20:10:34.177240  3817 net.cpp:380] Convolution6 -> Convolution6
I1006 20:10:34.178045  3817 net.cpp:122] Setting up Convolution6
I1006 20:10:34.178055  3817 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 20:10:34.178058  3817 net.cpp:137] Memory required for data: 146451600
I1006 20:10:34.178063  3817 layer_factory.hpp:77] Creating layer BatchNorm6
I1006 20:10:34.178068  3817 net.cpp:84] Creating Layer BatchNorm6
I1006 20:10:34.178071  3817 net.cpp:406] BatchNorm6 <- Convolution6
I1006 20:10:34.178076  3817 net.cpp:367] BatchNorm6 -> Convolution6 (in-place)
I1006 20:10:34.178190  3817 net.cpp:122] Setting up BatchNorm6
I1006 20:10:34.178195  3817 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 20:10:34.178197  3817 net.cpp:137] Memory required for data: 151469200
I1006 20:10:34.178202  3817 layer_factory.hpp:77] Creating layer Scale6
I1006 20:10:34.178206  3817 net.cpp:84] Creating Layer Scale6
I1006 20:10:34.178210  3817 net.cpp:406] Scale6 <- Convolution6
I1006 20:10:34.178213  3817 net.cpp:367] Scale6 -> Convolution6 (in-place)
I1006 20:10:34.178236  3817 layer_factory.hpp:77] Creating layer Scale6
I1006 20:10:34.178305  3817 net.cpp:122] Setting up Scale6
I1006 20:10:34.178310  3817 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 20:10:34.178313  3817 net.cpp:137] Memory required for data: 156486800
I1006 20:10:34.178316  3817 layer_factory.hpp:77] Creating layer PReLU6
I1006 20:10:34.178320  3817 net.cpp:84] Creating Layer PReLU6
I1006 20:10:34.178323  3817 net.cpp:406] PReLU6 <- Convolution6
I1006 20:10:34.178325  3817 net.cpp:367] PReLU6 -> Convolution6 (in-place)
I1006 20:10:34.178380  3817 net.cpp:122] Setting up PReLU6
I1006 20:10:34.178385  3817 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 20:10:34.178386  3817 net.cpp:137] Memory required for data: 161504400
I1006 20:10:34.178390  3817 layer_factory.hpp:77] Creating layer Convolution7
I1006 20:10:34.178395  3817 net.cpp:84] Creating Layer Convolution7
I1006 20:10:34.178398  3817 net.cpp:406] Convolution7 <- Convolution6
I1006 20:10:34.178401  3817 net.cpp:380] Convolution7 -> Convolution7
I1006 20:10:34.178887  3817 net.cpp:122] Setting up Convolution7
I1006 20:10:34.178896  3817 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 20:10:34.178900  3817 net.cpp:137] Memory required for data: 166522000
I1006 20:10:34.178903  3817 layer_factory.hpp:77] Creating layer BatchNorm7
I1006 20:10:34.178908  3817 net.cpp:84] Creating Layer BatchNorm7
I1006 20:10:34.178911  3817 net.cpp:406] BatchNorm7 <- Convolution7
I1006 20:10:34.178915  3817 net.cpp:367] BatchNorm7 -> Convolution7 (in-place)
I1006 20:10:34.179029  3817 net.cpp:122] Setting up BatchNorm7
I1006 20:10:34.179034  3817 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 20:10:34.179036  3817 net.cpp:137] Memory required for data: 171539600
I1006 20:10:34.179040  3817 layer_factory.hpp:77] Creating layer Scale7
I1006 20:10:34.179047  3817 net.cpp:84] Creating Layer Scale7
I1006 20:10:34.179050  3817 net.cpp:406] Scale7 <- Convolution7
I1006 20:10:34.179054  3817 net.cpp:367] Scale7 -> Convolution7 (in-place)
I1006 20:10:34.179076  3817 layer_factory.hpp:77] Creating layer Scale7
I1006 20:10:34.179142  3817 net.cpp:122] Setting up Scale7
I1006 20:10:34.179155  3817 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 20:10:34.179158  3817 net.cpp:137] Memory required for data: 176557200
I1006 20:10:34.179162  3817 layer_factory.hpp:77] Creating layer Eltwise3
I1006 20:10:34.179169  3817 net.cpp:84] Creating Layer Eltwise3
I1006 20:10:34.179172  3817 net.cpp:406] Eltwise3 <- Eltwise2_PReLU5_0_split_1
I1006 20:10:34.179175  3817 net.cpp:406] Eltwise3 <- Convolution7
I1006 20:10:34.179178  3817 net.cpp:380] Eltwise3 -> Eltwise3
I1006 20:10:34.179193  3817 net.cpp:122] Setting up Eltwise3
I1006 20:10:34.179198  3817 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 20:10:34.179200  3817 net.cpp:137] Memory required for data: 181574800
I1006 20:10:34.179203  3817 layer_factory.hpp:77] Creating layer PReLU7
I1006 20:10:34.179206  3817 net.cpp:84] Creating Layer PReLU7
I1006 20:10:34.179208  3817 net.cpp:406] PReLU7 <- Eltwise3
I1006 20:10:34.179211  3817 net.cpp:367] PReLU7 -> Eltwise3 (in-place)
I1006 20:10:34.179263  3817 net.cpp:122] Setting up PReLU7
I1006 20:10:34.179268  3817 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 20:10:34.179271  3817 net.cpp:137] Memory required for data: 186592400
I1006 20:10:34.179275  3817 layer_factory.hpp:77] Creating layer Eltwise3_PReLU7_0_split
I1006 20:10:34.179278  3817 net.cpp:84] Creating Layer Eltwise3_PReLU7_0_split
I1006 20:10:34.179281  3817 net.cpp:406] Eltwise3_PReLU7_0_split <- Eltwise3
I1006 20:10:34.179285  3817 net.cpp:380] Eltwise3_PReLU7_0_split -> Eltwise3_PReLU7_0_split_0
I1006 20:10:34.179288  3817 net.cpp:380] Eltwise3_PReLU7_0_split -> Eltwise3_PReLU7_0_split_1
I1006 20:10:34.179309  3817 net.cpp:122] Setting up Eltwise3_PReLU7_0_split
I1006 20:10:34.179313  3817 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 20:10:34.179316  3817 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 20:10:34.179318  3817 net.cpp:137] Memory required for data: 196627600
I1006 20:10:34.179321  3817 layer_factory.hpp:77] Creating layer Convolution8
I1006 20:10:34.179327  3817 net.cpp:84] Creating Layer Convolution8
I1006 20:10:34.179329  3817 net.cpp:406] Convolution8 <- Eltwise3_PReLU7_0_split_0
I1006 20:10:34.179333  3817 net.cpp:380] Convolution8 -> Convolution8
I1006 20:10:34.180150  3817 net.cpp:122] Setting up Convolution8
I1006 20:10:34.180160  3817 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 20:10:34.180163  3817 net.cpp:137] Memory required for data: 201645200
I1006 20:10:34.180167  3817 layer_factory.hpp:77] Creating layer BatchNorm8
I1006 20:10:34.180173  3817 net.cpp:84] Creating Layer BatchNorm8
I1006 20:10:34.180176  3817 net.cpp:406] BatchNorm8 <- Convolution8
I1006 20:10:34.180181  3817 net.cpp:367] BatchNorm8 -> Convolution8 (in-place)
I1006 20:10:34.180294  3817 net.cpp:122] Setting up BatchNorm8
I1006 20:10:34.180299  3817 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 20:10:34.180301  3817 net.cpp:137] Memory required for data: 206662800
I1006 20:10:34.180306  3817 layer_factory.hpp:77] Creating layer Scale8
I1006 20:10:34.180310  3817 net.cpp:84] Creating Layer Scale8
I1006 20:10:34.180313  3817 net.cpp:406] Scale8 <- Convolution8
I1006 20:10:34.180316  3817 net.cpp:367] Scale8 -> Convolution8 (in-place)
I1006 20:10:34.180339  3817 layer_factory.hpp:77] Creating layer Scale8
I1006 20:10:34.180408  3817 net.cpp:122] Setting up Scale8
I1006 20:10:34.180413  3817 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 20:10:34.180414  3817 net.cpp:137] Memory required for data: 211680400
I1006 20:10:34.180418  3817 layer_factory.hpp:77] Creating layer PReLU8
I1006 20:10:34.180423  3817 net.cpp:84] Creating Layer PReLU8
I1006 20:10:34.180424  3817 net.cpp:406] PReLU8 <- Convolution8
I1006 20:10:34.180428  3817 net.cpp:367] PReLU8 -> Convolution8 (in-place)
I1006 20:10:34.180481  3817 net.cpp:122] Setting up PReLU8
I1006 20:10:34.180486  3817 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 20:10:34.180488  3817 net.cpp:137] Memory required for data: 216698000
I1006 20:10:34.180491  3817 layer_factory.hpp:77] Creating layer Convolution9
I1006 20:10:34.180498  3817 net.cpp:84] Creating Layer Convolution9
I1006 20:10:34.180508  3817 net.cpp:406] Convolution9 <- Convolution8
I1006 20:10:34.180513  3817 net.cpp:380] Convolution9 -> Convolution9
I1006 20:10:34.181336  3817 net.cpp:122] Setting up Convolution9
I1006 20:10:34.181346  3817 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 20:10:34.181350  3817 net.cpp:137] Memory required for data: 221715600
I1006 20:10:34.181370  3817 layer_factory.hpp:77] Creating layer BatchNorm9
I1006 20:10:34.181375  3817 net.cpp:84] Creating Layer BatchNorm9
I1006 20:10:34.181378  3817 net.cpp:406] BatchNorm9 <- Convolution9
I1006 20:10:34.181381  3817 net.cpp:367] BatchNorm9 -> Convolution9 (in-place)
I1006 20:10:34.181517  3817 net.cpp:122] Setting up BatchNorm9
I1006 20:10:34.181522  3817 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 20:10:34.181524  3817 net.cpp:137] Memory required for data: 226733200
I1006 20:10:34.181529  3817 layer_factory.hpp:77] Creating layer Scale9
I1006 20:10:34.181535  3817 net.cpp:84] Creating Layer Scale9
I1006 20:10:34.181537  3817 net.cpp:406] Scale9 <- Convolution9
I1006 20:10:34.181541  3817 net.cpp:367] Scale9 -> Convolution9 (in-place)
I1006 20:10:34.181565  3817 layer_factory.hpp:77] Creating layer Scale9
I1006 20:10:34.181635  3817 net.cpp:122] Setting up Scale9
I1006 20:10:34.181640  3817 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 20:10:34.181643  3817 net.cpp:137] Memory required for data: 231750800
I1006 20:10:34.181646  3817 layer_factory.hpp:77] Creating layer Eltwise4
I1006 20:10:34.181651  3817 net.cpp:84] Creating Layer Eltwise4
I1006 20:10:34.181654  3817 net.cpp:406] Eltwise4 <- Eltwise3_PReLU7_0_split_1
I1006 20:10:34.181658  3817 net.cpp:406] Eltwise4 <- Convolution9
I1006 20:10:34.181661  3817 net.cpp:380] Eltwise4 -> Eltwise4
I1006 20:10:34.181676  3817 net.cpp:122] Setting up Eltwise4
I1006 20:10:34.181680  3817 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 20:10:34.181682  3817 net.cpp:137] Memory required for data: 236768400
I1006 20:10:34.181684  3817 layer_factory.hpp:77] Creating layer PReLU9
I1006 20:10:34.181689  3817 net.cpp:84] Creating Layer PReLU9
I1006 20:10:34.181690  3817 net.cpp:406] PReLU9 <- Eltwise4
I1006 20:10:34.181694  3817 net.cpp:367] PReLU9 -> Eltwise4 (in-place)
I1006 20:10:34.181749  3817 net.cpp:122] Setting up PReLU9
I1006 20:10:34.181754  3817 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 20:10:34.181756  3817 net.cpp:137] Memory required for data: 241786000
I1006 20:10:34.181759  3817 layer_factory.hpp:77] Creating layer Eltwise4_PReLU9_0_split
I1006 20:10:34.181763  3817 net.cpp:84] Creating Layer Eltwise4_PReLU9_0_split
I1006 20:10:34.181766  3817 net.cpp:406] Eltwise4_PReLU9_0_split <- Eltwise4
I1006 20:10:34.181769  3817 net.cpp:380] Eltwise4_PReLU9_0_split -> Eltwise4_PReLU9_0_split_0
I1006 20:10:34.181773  3817 net.cpp:380] Eltwise4_PReLU9_0_split -> Eltwise4_PReLU9_0_split_1
I1006 20:10:34.181794  3817 net.cpp:122] Setting up Eltwise4_PReLU9_0_split
I1006 20:10:34.181798  3817 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 20:10:34.181802  3817 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 20:10:34.181803  3817 net.cpp:137] Memory required for data: 251821200
I1006 20:10:34.181805  3817 layer_factory.hpp:77] Creating layer Convolution10
I1006 20:10:34.181812  3817 net.cpp:84] Creating Layer Convolution10
I1006 20:10:34.181814  3817 net.cpp:406] Convolution10 <- Eltwise4_PReLU9_0_split_0
I1006 20:10:34.181819  3817 net.cpp:380] Convolution10 -> Convolution10
I1006 20:10:34.182801  3817 net.cpp:122] Setting up Convolution10
I1006 20:10:34.182813  3817 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 20:10:34.182819  3817 net.cpp:137] Memory required for data: 256838800
I1006 20:10:34.182827  3817 layer_factory.hpp:77] Creating layer BatchNorm10
I1006 20:10:34.182853  3817 net.cpp:84] Creating Layer BatchNorm10
I1006 20:10:34.182859  3817 net.cpp:406] BatchNorm10 <- Convolution10
I1006 20:10:34.182867  3817 net.cpp:367] BatchNorm10 -> Convolution10 (in-place)
I1006 20:10:34.183010  3817 net.cpp:122] Setting up BatchNorm10
I1006 20:10:34.183024  3817 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 20:10:34.183029  3817 net.cpp:137] Memory required for data: 261856400
I1006 20:10:34.183038  3817 layer_factory.hpp:77] Creating layer Scale10
I1006 20:10:34.183045  3817 net.cpp:84] Creating Layer Scale10
I1006 20:10:34.183051  3817 net.cpp:406] Scale10 <- Convolution10
I1006 20:10:34.183058  3817 net.cpp:367] Scale10 -> Convolution10 (in-place)
I1006 20:10:34.183090  3817 layer_factory.hpp:77] Creating layer Scale10
I1006 20:10:34.183183  3817 net.cpp:122] Setting up Scale10
I1006 20:10:34.183192  3817 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 20:10:34.183195  3817 net.cpp:137] Memory required for data: 266874000
I1006 20:10:34.183212  3817 layer_factory.hpp:77] Creating layer PReLU10
I1006 20:10:34.183219  3817 net.cpp:84] Creating Layer PReLU10
I1006 20:10:34.183224  3817 net.cpp:406] PReLU10 <- Convolution10
I1006 20:10:34.183231  3817 net.cpp:367] PReLU10 -> Convolution10 (in-place)
I1006 20:10:34.183297  3817 net.cpp:122] Setting up PReLU10
I1006 20:10:34.183305  3817 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 20:10:34.183310  3817 net.cpp:137] Memory required for data: 271891600
I1006 20:10:34.183316  3817 layer_factory.hpp:77] Creating layer Convolution11
I1006 20:10:34.183327  3817 net.cpp:84] Creating Layer Convolution11
I1006 20:10:34.183331  3817 net.cpp:406] Convolution11 <- Convolution10
I1006 20:10:34.183338  3817 net.cpp:380] Convolution11 -> Convolution11
I1006 20:10:34.184190  3817 net.cpp:122] Setting up Convolution11
I1006 20:10:34.184201  3817 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 20:10:34.184206  3817 net.cpp:137] Memory required for data: 276909200
I1006 20:10:34.184224  3817 layer_factory.hpp:77] Creating layer BatchNorm11
I1006 20:10:34.184233  3817 net.cpp:84] Creating Layer BatchNorm11
I1006 20:10:34.184239  3817 net.cpp:406] BatchNorm11 <- Convolution11
I1006 20:10:34.184247  3817 net.cpp:367] BatchNorm11 -> Convolution11 (in-place)
I1006 20:10:34.184389  3817 net.cpp:122] Setting up BatchNorm11
I1006 20:10:34.184396  3817 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 20:10:34.184401  3817 net.cpp:137] Memory required for data: 281926800
I1006 20:10:34.184411  3817 layer_factory.hpp:77] Creating layer Scale11
I1006 20:10:34.184417  3817 net.cpp:84] Creating Layer Scale11
I1006 20:10:34.184423  3817 net.cpp:406] Scale11 <- Convolution11
I1006 20:10:34.184429  3817 net.cpp:367] Scale11 -> Convolution11 (in-place)
I1006 20:10:34.184460  3817 layer_factory.hpp:77] Creating layer Scale11
I1006 20:10:34.184536  3817 net.cpp:122] Setting up Scale11
I1006 20:10:34.184543  3817 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 20:10:34.184547  3817 net.cpp:137] Memory required for data: 286944400
I1006 20:10:34.184556  3817 layer_factory.hpp:77] Creating layer Eltwise5
I1006 20:10:34.184563  3817 net.cpp:84] Creating Layer Eltwise5
I1006 20:10:34.184568  3817 net.cpp:406] Eltwise5 <- Eltwise4_PReLU9_0_split_1
I1006 20:10:34.184574  3817 net.cpp:406] Eltwise5 <- Convolution11
I1006 20:10:34.184581  3817 net.cpp:380] Eltwise5 -> Eltwise5
I1006 20:10:34.184602  3817 net.cpp:122] Setting up Eltwise5
I1006 20:10:34.184607  3817 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 20:10:34.184613  3817 net.cpp:137] Memory required for data: 291962000
I1006 20:10:34.184618  3817 layer_factory.hpp:77] Creating layer PReLU11
I1006 20:10:34.184625  3817 net.cpp:84] Creating Layer PReLU11
I1006 20:10:34.184630  3817 net.cpp:406] PReLU11 <- Eltwise5
I1006 20:10:34.184636  3817 net.cpp:367] PReLU11 -> Eltwise5 (in-place)
I1006 20:10:34.184702  3817 net.cpp:122] Setting up PReLU11
I1006 20:10:34.184710  3817 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 20:10:34.184713  3817 net.cpp:137] Memory required for data: 296979600
I1006 20:10:34.184720  3817 layer_factory.hpp:77] Creating layer Eltwise5_PReLU11_0_split
I1006 20:10:34.184727  3817 net.cpp:84] Creating Layer Eltwise5_PReLU11_0_split
I1006 20:10:34.184732  3817 net.cpp:406] Eltwise5_PReLU11_0_split <- Eltwise5
I1006 20:10:34.184746  3817 net.cpp:380] Eltwise5_PReLU11_0_split -> Eltwise5_PReLU11_0_split_0
I1006 20:10:34.184756  3817 net.cpp:380] Eltwise5_PReLU11_0_split -> Eltwise5_PReLU11_0_split_1
I1006 20:10:34.184782  3817 net.cpp:122] Setting up Eltwise5_PReLU11_0_split
I1006 20:10:34.184789  3817 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 20:10:34.184797  3817 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 20:10:34.184801  3817 net.cpp:137] Memory required for data: 307014800
I1006 20:10:34.184806  3817 layer_factory.hpp:77] Creating layer Convolution12
I1006 20:10:34.184816  3817 net.cpp:84] Creating Layer Convolution12
I1006 20:10:34.184821  3817 net.cpp:406] Convolution12 <- Eltwise5_PReLU11_0_split_0
I1006 20:10:34.184828  3817 net.cpp:380] Convolution12 -> Convolution12
I1006 20:10:34.185937  3817 net.cpp:122] Setting up Convolution12
I1006 20:10:34.185948  3817 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 20:10:34.185953  3817 net.cpp:137] Memory required for data: 309523600
I1006 20:10:34.185961  3817 layer_factory.hpp:77] Creating layer BatchNorm12
I1006 20:10:34.185971  3817 net.cpp:84] Creating Layer BatchNorm12
I1006 20:10:34.185976  3817 net.cpp:406] BatchNorm12 <- Convolution12
I1006 20:10:34.185983  3817 net.cpp:367] BatchNorm12 -> Convolution12 (in-place)
I1006 20:10:34.186115  3817 net.cpp:122] Setting up BatchNorm12
I1006 20:10:34.186122  3817 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 20:10:34.186126  3817 net.cpp:137] Memory required for data: 312032400
I1006 20:10:34.186136  3817 layer_factory.hpp:77] Creating layer Scale12
I1006 20:10:34.186143  3817 net.cpp:84] Creating Layer Scale12
I1006 20:10:34.186149  3817 net.cpp:406] Scale12 <- Convolution12
I1006 20:10:34.186156  3817 net.cpp:367] Scale12 -> Convolution12 (in-place)
I1006 20:10:34.186187  3817 layer_factory.hpp:77] Creating layer Scale12
I1006 20:10:34.186264  3817 net.cpp:122] Setting up Scale12
I1006 20:10:34.186270  3817 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 20:10:34.186275  3817 net.cpp:137] Memory required for data: 314541200
I1006 20:10:34.186283  3817 layer_factory.hpp:77] Creating layer Convolution13
I1006 20:10:34.186293  3817 net.cpp:84] Creating Layer Convolution13
I1006 20:10:34.186298  3817 net.cpp:406] Convolution13 <- Eltwise5_PReLU11_0_split_1
I1006 20:10:34.186305  3817 net.cpp:380] Convolution13 -> Convolution13
I1006 20:10:34.187530  3817 net.cpp:122] Setting up Convolution13
I1006 20:10:34.187541  3817 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 20:10:34.187546  3817 net.cpp:137] Memory required for data: 317050000
I1006 20:10:34.187554  3817 layer_factory.hpp:77] Creating layer BatchNorm13
I1006 20:10:34.187562  3817 net.cpp:84] Creating Layer BatchNorm13
I1006 20:10:34.187569  3817 net.cpp:406] BatchNorm13 <- Convolution13
I1006 20:10:34.187577  3817 net.cpp:367] BatchNorm13 -> Convolution13 (in-place)
I1006 20:10:34.187705  3817 net.cpp:122] Setting up BatchNorm13
I1006 20:10:34.187713  3817 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 20:10:34.187717  3817 net.cpp:137] Memory required for data: 319558800
I1006 20:10:34.187727  3817 layer_factory.hpp:77] Creating layer Scale13
I1006 20:10:34.187734  3817 net.cpp:84] Creating Layer Scale13
I1006 20:10:34.187739  3817 net.cpp:406] Scale13 <- Convolution13
I1006 20:10:34.187747  3817 net.cpp:367] Scale13 -> Convolution13 (in-place)
I1006 20:10:34.187778  3817 layer_factory.hpp:77] Creating layer Scale13
I1006 20:10:34.187855  3817 net.cpp:122] Setting up Scale13
I1006 20:10:34.187862  3817 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 20:10:34.187866  3817 net.cpp:137] Memory required for data: 322067600
I1006 20:10:34.187875  3817 layer_factory.hpp:77] Creating layer PReLU12
I1006 20:10:34.187881  3817 net.cpp:84] Creating Layer PReLU12
I1006 20:10:34.187886  3817 net.cpp:406] PReLU12 <- Convolution13
I1006 20:10:34.187893  3817 net.cpp:367] PReLU12 -> Convolution13 (in-place)
I1006 20:10:34.187955  3817 net.cpp:122] Setting up PReLU12
I1006 20:10:34.187963  3817 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 20:10:34.187975  3817 net.cpp:137] Memory required for data: 324576400
I1006 20:10:34.187983  3817 layer_factory.hpp:77] Creating layer Convolution14
I1006 20:10:34.187995  3817 net.cpp:84] Creating Layer Convolution14
I1006 20:10:34.187999  3817 net.cpp:406] Convolution14 <- Convolution13
I1006 20:10:34.188006  3817 net.cpp:380] Convolution14 -> Convolution14
I1006 20:10:34.189015  3817 net.cpp:122] Setting up Convolution14
I1006 20:10:34.189028  3817 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 20:10:34.189033  3817 net.cpp:137] Memory required for data: 327085200
I1006 20:10:34.189040  3817 layer_factory.hpp:77] Creating layer BatchNorm14
I1006 20:10:34.189054  3817 net.cpp:84] Creating Layer BatchNorm14
I1006 20:10:34.189059  3817 net.cpp:406] BatchNorm14 <- Convolution14
I1006 20:10:34.189064  3817 net.cpp:367] BatchNorm14 -> Convolution14 (in-place)
I1006 20:10:34.189191  3817 net.cpp:122] Setting up BatchNorm14
I1006 20:10:34.189199  3817 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 20:10:34.189203  3817 net.cpp:137] Memory required for data: 329594000
I1006 20:10:34.189213  3817 layer_factory.hpp:77] Creating layer Scale14
I1006 20:10:34.189220  3817 net.cpp:84] Creating Layer Scale14
I1006 20:10:34.189226  3817 net.cpp:406] Scale14 <- Convolution14
I1006 20:10:34.189231  3817 net.cpp:367] Scale14 -> Convolution14 (in-place)
I1006 20:10:34.189262  3817 layer_factory.hpp:77] Creating layer Scale14
I1006 20:10:34.189338  3817 net.cpp:122] Setting up Scale14
I1006 20:10:34.189345  3817 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 20:10:34.189350  3817 net.cpp:137] Memory required for data: 332102800
I1006 20:10:34.189358  3817 layer_factory.hpp:77] Creating layer Eltwise6
I1006 20:10:34.189366  3817 net.cpp:84] Creating Layer Eltwise6
I1006 20:10:34.189371  3817 net.cpp:406] Eltwise6 <- Convolution12
I1006 20:10:34.189378  3817 net.cpp:406] Eltwise6 <- Convolution14
I1006 20:10:34.189383  3817 net.cpp:380] Eltwise6 -> Eltwise6
I1006 20:10:34.189399  3817 net.cpp:122] Setting up Eltwise6
I1006 20:10:34.189404  3817 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 20:10:34.189405  3817 net.cpp:137] Memory required for data: 334611600
I1006 20:10:34.189407  3817 layer_factory.hpp:77] Creating layer PReLU13
I1006 20:10:34.189411  3817 net.cpp:84] Creating Layer PReLU13
I1006 20:10:34.189414  3817 net.cpp:406] PReLU13 <- Eltwise6
I1006 20:10:34.189416  3817 net.cpp:367] PReLU13 -> Eltwise6 (in-place)
I1006 20:10:34.189471  3817 net.cpp:122] Setting up PReLU13
I1006 20:10:34.189476  3817 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 20:10:34.189477  3817 net.cpp:137] Memory required for data: 337120400
I1006 20:10:34.189481  3817 layer_factory.hpp:77] Creating layer Eltwise6_PReLU13_0_split
I1006 20:10:34.189484  3817 net.cpp:84] Creating Layer Eltwise6_PReLU13_0_split
I1006 20:10:34.189486  3817 net.cpp:406] Eltwise6_PReLU13_0_split <- Eltwise6
I1006 20:10:34.189489  3817 net.cpp:380] Eltwise6_PReLU13_0_split -> Eltwise6_PReLU13_0_split_0
I1006 20:10:34.189493  3817 net.cpp:380] Eltwise6_PReLU13_0_split -> Eltwise6_PReLU13_0_split_1
I1006 20:10:34.189514  3817 net.cpp:122] Setting up Eltwise6_PReLU13_0_split
I1006 20:10:34.189517  3817 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 20:10:34.189520  3817 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 20:10:34.189522  3817 net.cpp:137] Memory required for data: 342138000
I1006 20:10:34.189524  3817 layer_factory.hpp:77] Creating layer Convolution15
I1006 20:10:34.189530  3817 net.cpp:84] Creating Layer Convolution15
I1006 20:10:34.189533  3817 net.cpp:406] Convolution15 <- Eltwise6_PReLU13_0_split_0
I1006 20:10:34.189538  3817 net.cpp:380] Convolution15 -> Convolution15
I1006 20:10:34.190522  3817 net.cpp:122] Setting up Convolution15
I1006 20:10:34.190531  3817 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 20:10:34.190533  3817 net.cpp:137] Memory required for data: 344646800
I1006 20:10:34.190538  3817 layer_factory.hpp:77] Creating layer BatchNorm15
I1006 20:10:34.190543  3817 net.cpp:84] Creating Layer BatchNorm15
I1006 20:10:34.190552  3817 net.cpp:406] BatchNorm15 <- Convolution15
I1006 20:10:34.190557  3817 net.cpp:367] BatchNorm15 -> Convolution15 (in-place)
I1006 20:10:34.190678  3817 net.cpp:122] Setting up BatchNorm15
I1006 20:10:34.190683  3817 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 20:10:34.190685  3817 net.cpp:137] Memory required for data: 347155600
I1006 20:10:34.190690  3817 layer_factory.hpp:77] Creating layer Scale15
I1006 20:10:34.190693  3817 net.cpp:84] Creating Layer Scale15
I1006 20:10:34.190696  3817 net.cpp:406] Scale15 <- Convolution15
I1006 20:10:34.190699  3817 net.cpp:367] Scale15 -> Convolution15 (in-place)
I1006 20:10:34.190723  3817 layer_factory.hpp:77] Creating layer Scale15
I1006 20:10:34.190793  3817 net.cpp:122] Setting up Scale15
I1006 20:10:34.190796  3817 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 20:10:34.190798  3817 net.cpp:137] Memory required for data: 349664400
I1006 20:10:34.190803  3817 layer_factory.hpp:77] Creating layer PReLU14
I1006 20:10:34.190805  3817 net.cpp:84] Creating Layer PReLU14
I1006 20:10:34.190809  3817 net.cpp:406] PReLU14 <- Convolution15
I1006 20:10:34.190811  3817 net.cpp:367] PReLU14 -> Convolution15 (in-place)
I1006 20:10:34.190865  3817 net.cpp:122] Setting up PReLU14
I1006 20:10:34.190868  3817 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 20:10:34.190871  3817 net.cpp:137] Memory required for data: 352173200
I1006 20:10:34.190874  3817 layer_factory.hpp:77] Creating layer Convolution16
I1006 20:10:34.190881  3817 net.cpp:84] Creating Layer Convolution16
I1006 20:10:34.190882  3817 net.cpp:406] Convolution16 <- Convolution15
I1006 20:10:34.190886  3817 net.cpp:380] Convolution16 -> Convolution16
I1006 20:10:34.191898  3817 net.cpp:122] Setting up Convolution16
I1006 20:10:34.191907  3817 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 20:10:34.191910  3817 net.cpp:137] Memory required for data: 354682000
I1006 20:10:34.191915  3817 layer_factory.hpp:77] Creating layer BatchNorm16
I1006 20:10:34.191920  3817 net.cpp:84] Creating Layer BatchNorm16
I1006 20:10:34.191923  3817 net.cpp:406] BatchNorm16 <- Convolution16
I1006 20:10:34.191926  3817 net.cpp:367] BatchNorm16 -> Convolution16 (in-place)
I1006 20:10:34.192049  3817 net.cpp:122] Setting up BatchNorm16
I1006 20:10:34.192054  3817 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 20:10:34.192055  3817 net.cpp:137] Memory required for data: 357190800
I1006 20:10:34.192060  3817 layer_factory.hpp:77] Creating layer Scale16
I1006 20:10:34.192065  3817 net.cpp:84] Creating Layer Scale16
I1006 20:10:34.192066  3817 net.cpp:406] Scale16 <- Convolution16
I1006 20:10:34.192070  3817 net.cpp:367] Scale16 -> Convolution16 (in-place)
I1006 20:10:34.192093  3817 layer_factory.hpp:77] Creating layer Scale16
I1006 20:10:34.192162  3817 net.cpp:122] Setting up Scale16
I1006 20:10:34.192167  3817 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 20:10:34.192168  3817 net.cpp:137] Memory required for data: 359699600
I1006 20:10:34.192173  3817 layer_factory.hpp:77] Creating layer Eltwise7
I1006 20:10:34.192175  3817 net.cpp:84] Creating Layer Eltwise7
I1006 20:10:34.192178  3817 net.cpp:406] Eltwise7 <- Eltwise6_PReLU13_0_split_1
I1006 20:10:34.192181  3817 net.cpp:406] Eltwise7 <- Convolution16
I1006 20:10:34.192184  3817 net.cpp:380] Eltwise7 -> Eltwise7
I1006 20:10:34.192199  3817 net.cpp:122] Setting up Eltwise7
I1006 20:10:34.192203  3817 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 20:10:34.192204  3817 net.cpp:137] Memory required for data: 362208400
I1006 20:10:34.192206  3817 layer_factory.hpp:77] Creating layer PReLU15
I1006 20:10:34.192209  3817 net.cpp:84] Creating Layer PReLU15
I1006 20:10:34.192212  3817 net.cpp:406] PReLU15 <- Eltwise7
I1006 20:10:34.192215  3817 net.cpp:367] PReLU15 -> Eltwise7 (in-place)
I1006 20:10:34.192271  3817 net.cpp:122] Setting up PReLU15
I1006 20:10:34.192276  3817 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 20:10:34.192277  3817 net.cpp:137] Memory required for data: 364717200
I1006 20:10:34.192281  3817 layer_factory.hpp:77] Creating layer Eltwise7_PReLU15_0_split
I1006 20:10:34.192291  3817 net.cpp:84] Creating Layer Eltwise7_PReLU15_0_split
I1006 20:10:34.192293  3817 net.cpp:406] Eltwise7_PReLU15_0_split <- Eltwise7
I1006 20:10:34.192297  3817 net.cpp:380] Eltwise7_PReLU15_0_split -> Eltwise7_PReLU15_0_split_0
I1006 20:10:34.192301  3817 net.cpp:380] Eltwise7_PReLU15_0_split -> Eltwise7_PReLU15_0_split_1
I1006 20:10:34.192323  3817 net.cpp:122] Setting up Eltwise7_PReLU15_0_split
I1006 20:10:34.192327  3817 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 20:10:34.192329  3817 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 20:10:34.192332  3817 net.cpp:137] Memory required for data: 369734800
I1006 20:10:34.192333  3817 layer_factory.hpp:77] Creating layer Convolution17
I1006 20:10:34.192339  3817 net.cpp:84] Creating Layer Convolution17
I1006 20:10:34.192342  3817 net.cpp:406] Convolution17 <- Eltwise7_PReLU15_0_split_0
I1006 20:10:34.192345  3817 net.cpp:380] Convolution17 -> Convolution17
I1006 20:10:34.193012  3817 net.cpp:122] Setting up Convolution17
I1006 20:10:34.193019  3817 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 20:10:34.193022  3817 net.cpp:137] Memory required for data: 372243600
I1006 20:10:34.193034  3817 layer_factory.hpp:77] Creating layer BatchNorm17
I1006 20:10:34.193038  3817 net.cpp:84] Creating Layer BatchNorm17
I1006 20:10:34.193042  3817 net.cpp:406] BatchNorm17 <- Convolution17
I1006 20:10:34.193045  3817 net.cpp:367] BatchNorm17 -> Convolution17 (in-place)
I1006 20:10:34.193166  3817 net.cpp:122] Setting up BatchNorm17
I1006 20:10:34.193169  3817 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 20:10:34.193171  3817 net.cpp:137] Memory required for data: 374752400
I1006 20:10:34.193176  3817 layer_factory.hpp:77] Creating layer Scale17
I1006 20:10:34.193181  3817 net.cpp:84] Creating Layer Scale17
I1006 20:10:34.193183  3817 net.cpp:406] Scale17 <- Convolution17
I1006 20:10:34.193186  3817 net.cpp:367] Scale17 -> Convolution17 (in-place)
I1006 20:10:34.193212  3817 layer_factory.hpp:77] Creating layer Scale17
I1006 20:10:34.193281  3817 net.cpp:122] Setting up Scale17
I1006 20:10:34.193285  3817 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 20:10:34.193287  3817 net.cpp:137] Memory required for data: 377261200
I1006 20:10:34.193291  3817 layer_factory.hpp:77] Creating layer PReLU16
I1006 20:10:34.193295  3817 net.cpp:84] Creating Layer PReLU16
I1006 20:10:34.193296  3817 net.cpp:406] PReLU16 <- Convolution17
I1006 20:10:34.193300  3817 net.cpp:367] PReLU16 -> Convolution17 (in-place)
I1006 20:10:34.193353  3817 net.cpp:122] Setting up PReLU16
I1006 20:10:34.193357  3817 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 20:10:34.193359  3817 net.cpp:137] Memory required for data: 379770000
I1006 20:10:34.193362  3817 layer_factory.hpp:77] Creating layer Convolution18
I1006 20:10:34.193368  3817 net.cpp:84] Creating Layer Convolution18
I1006 20:10:34.193372  3817 net.cpp:406] Convolution18 <- Convolution17
I1006 20:10:34.193374  3817 net.cpp:380] Convolution18 -> Convolution18
I1006 20:10:34.194356  3817 net.cpp:122] Setting up Convolution18
I1006 20:10:34.194365  3817 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 20:10:34.194367  3817 net.cpp:137] Memory required for data: 382278800
I1006 20:10:34.194372  3817 layer_factory.hpp:77] Creating layer BatchNorm18
I1006 20:10:34.194376  3817 net.cpp:84] Creating Layer BatchNorm18
I1006 20:10:34.194380  3817 net.cpp:406] BatchNorm18 <- Convolution18
I1006 20:10:34.194382  3817 net.cpp:367] BatchNorm18 -> Convolution18 (in-place)
I1006 20:10:34.194501  3817 net.cpp:122] Setting up BatchNorm18
I1006 20:10:34.194505  3817 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 20:10:34.194507  3817 net.cpp:137] Memory required for data: 384787600
I1006 20:10:34.194512  3817 layer_factory.hpp:77] Creating layer Scale18
I1006 20:10:34.194516  3817 net.cpp:84] Creating Layer Scale18
I1006 20:10:34.194519  3817 net.cpp:406] Scale18 <- Convolution18
I1006 20:10:34.194521  3817 net.cpp:367] Scale18 -> Convolution18 (in-place)
I1006 20:10:34.194545  3817 layer_factory.hpp:77] Creating layer Scale18
I1006 20:10:34.194622  3817 net.cpp:122] Setting up Scale18
I1006 20:10:34.194628  3817 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 20:10:34.194629  3817 net.cpp:137] Memory required for data: 387296400
I1006 20:10:34.194633  3817 layer_factory.hpp:77] Creating layer Eltwise8
I1006 20:10:34.194636  3817 net.cpp:84] Creating Layer Eltwise8
I1006 20:10:34.194639  3817 net.cpp:406] Eltwise8 <- Eltwise7_PReLU15_0_split_1
I1006 20:10:34.194643  3817 net.cpp:406] Eltwise8 <- Convolution18
I1006 20:10:34.194645  3817 net.cpp:380] Eltwise8 -> Eltwise8
I1006 20:10:34.194659  3817 net.cpp:122] Setting up Eltwise8
I1006 20:10:34.194663  3817 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 20:10:34.194664  3817 net.cpp:137] Memory required for data: 389805200
I1006 20:10:34.194666  3817 layer_factory.hpp:77] Creating layer PReLU17
I1006 20:10:34.194670  3817 net.cpp:84] Creating Layer PReLU17
I1006 20:10:34.194672  3817 net.cpp:406] PReLU17 <- Eltwise8
I1006 20:10:34.194684  3817 net.cpp:367] PReLU17 -> Eltwise8 (in-place)
I1006 20:10:34.194738  3817 net.cpp:122] Setting up PReLU17
I1006 20:10:34.194742  3817 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 20:10:34.194744  3817 net.cpp:137] Memory required for data: 392314000
I1006 20:10:34.194747  3817 layer_factory.hpp:77] Creating layer Eltwise8_PReLU17_0_split
I1006 20:10:34.194751  3817 net.cpp:84] Creating Layer Eltwise8_PReLU17_0_split
I1006 20:10:34.194753  3817 net.cpp:406] Eltwise8_PReLU17_0_split <- Eltwise8
I1006 20:10:34.194756  3817 net.cpp:380] Eltwise8_PReLU17_0_split -> Eltwise8_PReLU17_0_split_0
I1006 20:10:34.194761  3817 net.cpp:380] Eltwise8_PReLU17_0_split -> Eltwise8_PReLU17_0_split_1
I1006 20:10:34.194782  3817 net.cpp:122] Setting up Eltwise8_PReLU17_0_split
I1006 20:10:34.194785  3817 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 20:10:34.194787  3817 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 20:10:34.194789  3817 net.cpp:137] Memory required for data: 397331600
I1006 20:10:34.194792  3817 layer_factory.hpp:77] Creating layer Convolution19
I1006 20:10:34.194797  3817 net.cpp:84] Creating Layer Convolution19
I1006 20:10:34.194799  3817 net.cpp:406] Convolution19 <- Eltwise8_PReLU17_0_split_0
I1006 20:10:34.194803  3817 net.cpp:380] Convolution19 -> Convolution19
I1006 20:10:34.196141  3817 net.cpp:122] Setting up Convolution19
I1006 20:10:34.196148  3817 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 20:10:34.196151  3817 net.cpp:137] Memory required for data: 399840400
I1006 20:10:34.196156  3817 layer_factory.hpp:77] Creating layer BatchNorm19
I1006 20:10:34.196161  3817 net.cpp:84] Creating Layer BatchNorm19
I1006 20:10:34.196163  3817 net.cpp:406] BatchNorm19 <- Convolution19
I1006 20:10:34.196167  3817 net.cpp:367] BatchNorm19 -> Convolution19 (in-place)
I1006 20:10:34.196290  3817 net.cpp:122] Setting up BatchNorm19
I1006 20:10:34.196295  3817 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 20:10:34.196297  3817 net.cpp:137] Memory required for data: 402349200
I1006 20:10:34.196301  3817 layer_factory.hpp:77] Creating layer Scale19
I1006 20:10:34.196305  3817 net.cpp:84] Creating Layer Scale19
I1006 20:10:34.196307  3817 net.cpp:406] Scale19 <- Convolution19
I1006 20:10:34.196310  3817 net.cpp:367] Scale19 -> Convolution19 (in-place)
I1006 20:10:34.196334  3817 layer_factory.hpp:77] Creating layer Scale19
I1006 20:10:34.196403  3817 net.cpp:122] Setting up Scale19
I1006 20:10:34.196406  3817 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 20:10:34.196408  3817 net.cpp:137] Memory required for data: 404858000
I1006 20:10:34.196413  3817 layer_factory.hpp:77] Creating layer PReLU18
I1006 20:10:34.196415  3817 net.cpp:84] Creating Layer PReLU18
I1006 20:10:34.196418  3817 net.cpp:406] PReLU18 <- Convolution19
I1006 20:10:34.196420  3817 net.cpp:367] PReLU18 -> Convolution19 (in-place)
I1006 20:10:34.196475  3817 net.cpp:122] Setting up PReLU18
I1006 20:10:34.196478  3817 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 20:10:34.196480  3817 net.cpp:137] Memory required for data: 407366800
I1006 20:10:34.196490  3817 layer_factory.hpp:77] Creating layer Convolution20
I1006 20:10:34.196496  3817 net.cpp:84] Creating Layer Convolution20
I1006 20:10:34.196498  3817 net.cpp:406] Convolution20 <- Convolution19
I1006 20:10:34.196502  3817 net.cpp:380] Convolution20 -> Convolution20
I1006 20:10:34.197572  3817 net.cpp:122] Setting up Convolution20
I1006 20:10:34.197582  3817 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 20:10:34.197584  3817 net.cpp:137] Memory required for data: 409875600
I1006 20:10:34.197588  3817 layer_factory.hpp:77] Creating layer BatchNorm20
I1006 20:10:34.197593  3817 net.cpp:84] Creating Layer BatchNorm20
I1006 20:10:34.197597  3817 net.cpp:406] BatchNorm20 <- Convolution20
I1006 20:10:34.197600  3817 net.cpp:367] BatchNorm20 -> Convolution20 (in-place)
I1006 20:10:34.197723  3817 net.cpp:122] Setting up BatchNorm20
I1006 20:10:34.197727  3817 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 20:10:34.197729  3817 net.cpp:137] Memory required for data: 412384400
I1006 20:10:34.197734  3817 layer_factory.hpp:77] Creating layer Scale20
I1006 20:10:34.197738  3817 net.cpp:84] Creating Layer Scale20
I1006 20:10:34.197741  3817 net.cpp:406] Scale20 <- Convolution20
I1006 20:10:34.197743  3817 net.cpp:367] Scale20 -> Convolution20 (in-place)
I1006 20:10:34.197768  3817 layer_factory.hpp:77] Creating layer Scale20
I1006 20:10:34.197839  3817 net.cpp:122] Setting up Scale20
I1006 20:10:34.197842  3817 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 20:10:34.197844  3817 net.cpp:137] Memory required for data: 414893200
I1006 20:10:34.197849  3817 layer_factory.hpp:77] Creating layer Eltwise9
I1006 20:10:34.197852  3817 net.cpp:84] Creating Layer Eltwise9
I1006 20:10:34.197855  3817 net.cpp:406] Eltwise9 <- Eltwise8_PReLU17_0_split_1
I1006 20:10:34.197857  3817 net.cpp:406] Eltwise9 <- Convolution20
I1006 20:10:34.197861  3817 net.cpp:380] Eltwise9 -> Eltwise9
I1006 20:10:34.197875  3817 net.cpp:122] Setting up Eltwise9
I1006 20:10:34.197878  3817 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 20:10:34.197880  3817 net.cpp:137] Memory required for data: 417402000
I1006 20:10:34.197882  3817 layer_factory.hpp:77] Creating layer PReLU19
I1006 20:10:34.197886  3817 net.cpp:84] Creating Layer PReLU19
I1006 20:10:34.197888  3817 net.cpp:406] PReLU19 <- Eltwise9
I1006 20:10:34.197891  3817 net.cpp:367] PReLU19 -> Eltwise9 (in-place)
I1006 20:10:34.197947  3817 net.cpp:122] Setting up PReLU19
I1006 20:10:34.197952  3817 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 20:10:34.197953  3817 net.cpp:137] Memory required for data: 419910800
I1006 20:10:34.197957  3817 layer_factory.hpp:77] Creating layer Eltwise9_PReLU19_0_split
I1006 20:10:34.197960  3817 net.cpp:84] Creating Layer Eltwise9_PReLU19_0_split
I1006 20:10:34.197962  3817 net.cpp:406] Eltwise9_PReLU19_0_split <- Eltwise9
I1006 20:10:34.197965  3817 net.cpp:380] Eltwise9_PReLU19_0_split -> Eltwise9_PReLU19_0_split_0
I1006 20:10:34.197979  3817 net.cpp:380] Eltwise9_PReLU19_0_split -> Eltwise9_PReLU19_0_split_1
I1006 20:10:34.198009  3817 net.cpp:122] Setting up Eltwise9_PReLU19_0_split
I1006 20:10:34.198012  3817 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 20:10:34.198015  3817 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 20:10:34.198017  3817 net.cpp:137] Memory required for data: 424928400
I1006 20:10:34.198019  3817 layer_factory.hpp:77] Creating layer Convolution21
I1006 20:10:34.198025  3817 net.cpp:84] Creating Layer Convolution21
I1006 20:10:34.198027  3817 net.cpp:406] Convolution21 <- Eltwise9_PReLU19_0_split_0
I1006 20:10:34.198031  3817 net.cpp:380] Convolution21 -> Convolution21
I1006 20:10:34.199483  3817 net.cpp:122] Setting up Convolution21
I1006 20:10:34.199492  3817 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 20:10:34.199496  3817 net.cpp:137] Memory required for data: 427437200
I1006 20:10:34.199499  3817 layer_factory.hpp:77] Creating layer BatchNorm21
I1006 20:10:34.199506  3817 net.cpp:84] Creating Layer BatchNorm21
I1006 20:10:34.199508  3817 net.cpp:406] BatchNorm21 <- Convolution21
I1006 20:10:34.199519  3817 net.cpp:367] BatchNorm21 -> Convolution21 (in-place)
I1006 20:10:34.199654  3817 net.cpp:122] Setting up BatchNorm21
I1006 20:10:34.199658  3817 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 20:10:34.199661  3817 net.cpp:137] Memory required for data: 429946000
I1006 20:10:34.199666  3817 layer_factory.hpp:77] Creating layer Scale21
I1006 20:10:34.199671  3817 net.cpp:84] Creating Layer Scale21
I1006 20:10:34.199673  3817 net.cpp:406] Scale21 <- Convolution21
I1006 20:10:34.199676  3817 net.cpp:367] Scale21 -> Convolution21 (in-place)
I1006 20:10:34.199702  3817 layer_factory.hpp:77] Creating layer Scale21
I1006 20:10:34.199776  3817 net.cpp:122] Setting up Scale21
I1006 20:10:34.199780  3817 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 20:10:34.199784  3817 net.cpp:137] Memory required for data: 432454800
I1006 20:10:34.199786  3817 layer_factory.hpp:77] Creating layer PReLU20
I1006 20:10:34.199790  3817 net.cpp:84] Creating Layer PReLU20
I1006 20:10:34.199793  3817 net.cpp:406] PReLU20 <- Convolution21
I1006 20:10:34.199796  3817 net.cpp:367] PReLU20 -> Convolution21 (in-place)
I1006 20:10:34.199853  3817 net.cpp:122] Setting up PReLU20
I1006 20:10:34.199857  3817 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 20:10:34.199859  3817 net.cpp:137] Memory required for data: 434963600
I1006 20:10:34.199862  3817 layer_factory.hpp:77] Creating layer Convolution22
I1006 20:10:34.199868  3817 net.cpp:84] Creating Layer Convolution22
I1006 20:10:34.199872  3817 net.cpp:406] Convolution22 <- Convolution21
I1006 20:10:34.199875  3817 net.cpp:380] Convolution22 -> Convolution22
I1006 20:10:34.201001  3817 net.cpp:122] Setting up Convolution22
I1006 20:10:34.201010  3817 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 20:10:34.201014  3817 net.cpp:137] Memory required for data: 437472400
I1006 20:10:34.201017  3817 layer_factory.hpp:77] Creating layer BatchNorm22
I1006 20:10:34.201023  3817 net.cpp:84] Creating Layer BatchNorm22
I1006 20:10:34.201026  3817 net.cpp:406] BatchNorm22 <- Convolution22
I1006 20:10:34.201030  3817 net.cpp:367] BatchNorm22 -> Convolution22 (in-place)
I1006 20:10:34.201166  3817 net.cpp:122] Setting up BatchNorm22
I1006 20:10:34.201170  3817 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 20:10:34.201174  3817 net.cpp:137] Memory required for data: 439981200
I1006 20:10:34.201177  3817 layer_factory.hpp:77] Creating layer Scale22
I1006 20:10:34.201182  3817 net.cpp:84] Creating Layer Scale22
I1006 20:10:34.201185  3817 net.cpp:406] Scale22 <- Convolution22
I1006 20:10:34.201189  3817 net.cpp:367] Scale22 -> Convolution22 (in-place)
I1006 20:10:34.201215  3817 layer_factory.hpp:77] Creating layer Scale22
I1006 20:10:34.201292  3817 net.cpp:122] Setting up Scale22
I1006 20:10:34.201297  3817 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 20:10:34.201298  3817 net.cpp:137] Memory required for data: 442490000
I1006 20:10:34.201303  3817 layer_factory.hpp:77] Creating layer Eltwise10
I1006 20:10:34.201308  3817 net.cpp:84] Creating Layer Eltwise10
I1006 20:10:34.201310  3817 net.cpp:406] Eltwise10 <- Eltwise9_PReLU19_0_split_1
I1006 20:10:34.201313  3817 net.cpp:406] Eltwise10 <- Convolution22
I1006 20:10:34.201316  3817 net.cpp:380] Eltwise10 -> Eltwise10
I1006 20:10:34.201333  3817 net.cpp:122] Setting up Eltwise10
I1006 20:10:34.201336  3817 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 20:10:34.201339  3817 net.cpp:137] Memory required for data: 444998800
I1006 20:10:34.201340  3817 layer_factory.hpp:77] Creating layer PReLU21
I1006 20:10:34.201344  3817 net.cpp:84] Creating Layer PReLU21
I1006 20:10:34.201345  3817 net.cpp:406] PReLU21 <- Eltwise10
I1006 20:10:34.201349  3817 net.cpp:367] PReLU21 -> Eltwise10 (in-place)
I1006 20:10:34.201408  3817 net.cpp:122] Setting up PReLU21
I1006 20:10:34.201412  3817 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 20:10:34.201414  3817 net.cpp:137] Memory required for data: 447507600
I1006 20:10:34.201417  3817 layer_factory.hpp:77] Creating layer Eltwise10_PReLU21_0_split
I1006 20:10:34.201427  3817 net.cpp:84] Creating Layer Eltwise10_PReLU21_0_split
I1006 20:10:34.201431  3817 net.cpp:406] Eltwise10_PReLU21_0_split <- Eltwise10
I1006 20:10:34.201433  3817 net.cpp:380] Eltwise10_PReLU21_0_split -> Eltwise10_PReLU21_0_split_0
I1006 20:10:34.201438  3817 net.cpp:380] Eltwise10_PReLU21_0_split -> Eltwise10_PReLU21_0_split_1
I1006 20:10:34.201463  3817 net.cpp:122] Setting up Eltwise10_PReLU21_0_split
I1006 20:10:34.201467  3817 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 20:10:34.201470  3817 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 20:10:34.201472  3817 net.cpp:137] Memory required for data: 452525200
I1006 20:10:34.201474  3817 layer_factory.hpp:77] Creating layer Convolution23
I1006 20:10:34.201481  3817 net.cpp:84] Creating Layer Convolution23
I1006 20:10:34.201484  3817 net.cpp:406] Convolution23 <- Eltwise10_PReLU21_0_split_0
I1006 20:10:34.201488  3817 net.cpp:380] Convolution23 -> Convolution23
I1006 20:10:34.202399  3817 net.cpp:122] Setting up Convolution23
I1006 20:10:34.202407  3817 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 20:10:34.202409  3817 net.cpp:137] Memory required for data: 453779600
I1006 20:10:34.202414  3817 layer_factory.hpp:77] Creating layer BatchNorm23
I1006 20:10:34.202419  3817 net.cpp:84] Creating Layer BatchNorm23
I1006 20:10:34.202422  3817 net.cpp:406] BatchNorm23 <- Convolution23
I1006 20:10:34.202427  3817 net.cpp:367] BatchNorm23 -> Convolution23 (in-place)
I1006 20:10:34.202561  3817 net.cpp:122] Setting up BatchNorm23
I1006 20:10:34.202565  3817 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 20:10:34.202569  3817 net.cpp:137] Memory required for data: 455034000
I1006 20:10:34.202574  3817 layer_factory.hpp:77] Creating layer Scale23
I1006 20:10:34.202579  3817 net.cpp:84] Creating Layer Scale23
I1006 20:10:34.202580  3817 net.cpp:406] Scale23 <- Convolution23
I1006 20:10:34.202584  3817 net.cpp:367] Scale23 -> Convolution23 (in-place)
I1006 20:10:34.202610  3817 layer_factory.hpp:77] Creating layer Scale23
I1006 20:10:34.202687  3817 net.cpp:122] Setting up Scale23
I1006 20:10:34.202692  3817 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 20:10:34.202694  3817 net.cpp:137] Memory required for data: 456288400
I1006 20:10:34.202698  3817 layer_factory.hpp:77] Creating layer Convolution24
I1006 20:10:34.202704  3817 net.cpp:84] Creating Layer Convolution24
I1006 20:10:34.202708  3817 net.cpp:406] Convolution24 <- Eltwise10_PReLU21_0_split_1
I1006 20:10:34.202711  3817 net.cpp:380] Convolution24 -> Convolution24
I1006 20:10:34.204524  3817 net.cpp:122] Setting up Convolution24
I1006 20:10:34.204533  3817 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 20:10:34.204536  3817 net.cpp:137] Memory required for data: 457542800
I1006 20:10:34.204540  3817 layer_factory.hpp:77] Creating layer BatchNorm24
I1006 20:10:34.204546  3817 net.cpp:84] Creating Layer BatchNorm24
I1006 20:10:34.204550  3817 net.cpp:406] BatchNorm24 <- Convolution24
I1006 20:10:34.204555  3817 net.cpp:367] BatchNorm24 -> Convolution24 (in-place)
I1006 20:10:34.204689  3817 net.cpp:122] Setting up BatchNorm24
I1006 20:10:34.204694  3817 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 20:10:34.204696  3817 net.cpp:137] Memory required for data: 458797200
I1006 20:10:34.204701  3817 layer_factory.hpp:77] Creating layer Scale24
I1006 20:10:34.204705  3817 net.cpp:84] Creating Layer Scale24
I1006 20:10:34.204708  3817 net.cpp:406] Scale24 <- Convolution24
I1006 20:10:34.204711  3817 net.cpp:367] Scale24 -> Convolution24 (in-place)
I1006 20:10:34.204738  3817 layer_factory.hpp:77] Creating layer Scale24
I1006 20:10:34.204818  3817 net.cpp:122] Setting up Scale24
I1006 20:10:34.204823  3817 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 20:10:34.204824  3817 net.cpp:137] Memory required for data: 460051600
I1006 20:10:34.204828  3817 layer_factory.hpp:77] Creating layer PReLU22
I1006 20:10:34.204831  3817 net.cpp:84] Creating Layer PReLU22
I1006 20:10:34.204834  3817 net.cpp:406] PReLU22 <- Convolution24
I1006 20:10:34.204838  3817 net.cpp:367] PReLU22 -> Convolution24 (in-place)
I1006 20:10:34.204905  3817 net.cpp:122] Setting up PReLU22
I1006 20:10:34.204910  3817 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 20:10:34.204911  3817 net.cpp:137] Memory required for data: 461306000
I1006 20:10:34.204915  3817 layer_factory.hpp:77] Creating layer Convolution25
I1006 20:10:34.204922  3817 net.cpp:84] Creating Layer Convolution25
I1006 20:10:34.204926  3817 net.cpp:406] Convolution25 <- Convolution24
I1006 20:10:34.204929  3817 net.cpp:380] Convolution25 -> Convolution25
I1006 20:10:34.206929  3817 net.cpp:122] Setting up Convolution25
I1006 20:10:34.206939  3817 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 20:10:34.206943  3817 net.cpp:137] Memory required for data: 462560400
I1006 20:10:34.206948  3817 layer_factory.hpp:77] Creating layer BatchNorm25
I1006 20:10:34.206951  3817 net.cpp:84] Creating Layer BatchNorm25
I1006 20:10:34.206954  3817 net.cpp:406] BatchNorm25 <- Convolution25
I1006 20:10:34.206959  3817 net.cpp:367] BatchNorm25 -> Convolution25 (in-place)
I1006 20:10:34.207105  3817 net.cpp:122] Setting up BatchNorm25
I1006 20:10:34.207110  3817 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 20:10:34.207113  3817 net.cpp:137] Memory required for data: 463814800
I1006 20:10:34.207118  3817 layer_factory.hpp:77] Creating layer Scale25
I1006 20:10:34.207121  3817 net.cpp:84] Creating Layer Scale25
I1006 20:10:34.207123  3817 net.cpp:406] Scale25 <- Convolution25
I1006 20:10:34.207128  3817 net.cpp:367] Scale25 -> Convolution25 (in-place)
I1006 20:10:34.207154  3817 layer_factory.hpp:77] Creating layer Scale25
I1006 20:10:34.207257  3817 net.cpp:122] Setting up Scale25
I1006 20:10:34.207262  3817 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 20:10:34.207264  3817 net.cpp:137] Memory required for data: 465069200
I1006 20:10:34.207268  3817 layer_factory.hpp:77] Creating layer Eltwise11
I1006 20:10:34.207271  3817 net.cpp:84] Creating Layer Eltwise11
I1006 20:10:34.207274  3817 net.cpp:406] Eltwise11 <- Convolution23
I1006 20:10:34.207276  3817 net.cpp:406] Eltwise11 <- Convolution25
I1006 20:10:34.207280  3817 net.cpp:380] Eltwise11 -> Eltwise11
I1006 20:10:34.207296  3817 net.cpp:122] Setting up Eltwise11
I1006 20:10:34.207300  3817 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 20:10:34.207304  3817 net.cpp:137] Memory required for data: 466323600
I1006 20:10:34.207305  3817 layer_factory.hpp:77] Creating layer PReLU23
I1006 20:10:34.207309  3817 net.cpp:84] Creating Layer PReLU23
I1006 20:10:34.207310  3817 net.cpp:406] PReLU23 <- Eltwise11
I1006 20:10:34.207314  3817 net.cpp:367] PReLU23 -> Eltwise11 (in-place)
I1006 20:10:34.207373  3817 net.cpp:122] Setting up PReLU23
I1006 20:10:34.207377  3817 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 20:10:34.207379  3817 net.cpp:137] Memory required for data: 467578000
I1006 20:10:34.207382  3817 layer_factory.hpp:77] Creating layer Eltwise11_PReLU23_0_split
I1006 20:10:34.207386  3817 net.cpp:84] Creating Layer Eltwise11_PReLU23_0_split
I1006 20:10:34.207388  3817 net.cpp:406] Eltwise11_PReLU23_0_split <- Eltwise11
I1006 20:10:34.207391  3817 net.cpp:380] Eltwise11_PReLU23_0_split -> Eltwise11_PReLU23_0_split_0
I1006 20:10:34.207396  3817 net.cpp:380] Eltwise11_PReLU23_0_split -> Eltwise11_PReLU23_0_split_1
I1006 20:10:34.207429  3817 net.cpp:122] Setting up Eltwise11_PReLU23_0_split
I1006 20:10:34.207433  3817 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 20:10:34.207435  3817 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 20:10:34.207438  3817 net.cpp:137] Memory required for data: 470086800
I1006 20:10:34.207440  3817 layer_factory.hpp:77] Creating layer Convolution26
I1006 20:10:34.207455  3817 net.cpp:84] Creating Layer Convolution26
I1006 20:10:34.207458  3817 net.cpp:406] Convolution26 <- Eltwise11_PReLU23_0_split_0
I1006 20:10:34.207463  3817 net.cpp:380] Convolution26 -> Convolution26
I1006 20:10:34.209113  3817 net.cpp:122] Setting up Convolution26
I1006 20:10:34.209121  3817 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 20:10:34.209125  3817 net.cpp:137] Memory required for data: 471341200
I1006 20:10:34.209136  3817 layer_factory.hpp:77] Creating layer BatchNorm26
I1006 20:10:34.209141  3817 net.cpp:84] Creating Layer BatchNorm26
I1006 20:10:34.209144  3817 net.cpp:406] BatchNorm26 <- Convolution26
I1006 20:10:34.209149  3817 net.cpp:367] BatchNorm26 -> Convolution26 (in-place)
I1006 20:10:34.209283  3817 net.cpp:122] Setting up BatchNorm26
I1006 20:10:34.209287  3817 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 20:10:34.209290  3817 net.cpp:137] Memory required for data: 472595600
I1006 20:10:34.209295  3817 layer_factory.hpp:77] Creating layer Scale26
I1006 20:10:34.209300  3817 net.cpp:84] Creating Layer Scale26
I1006 20:10:34.209301  3817 net.cpp:406] Scale26 <- Convolution26
I1006 20:10:34.209305  3817 net.cpp:367] Scale26 -> Convolution26 (in-place)
I1006 20:10:34.209331  3817 layer_factory.hpp:77] Creating layer Scale26
I1006 20:10:34.209408  3817 net.cpp:122] Setting up Scale26
I1006 20:10:34.209414  3817 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 20:10:34.209415  3817 net.cpp:137] Memory required for data: 473850000
I1006 20:10:34.209419  3817 layer_factory.hpp:77] Creating layer PReLU24
I1006 20:10:34.209424  3817 net.cpp:84] Creating Layer PReLU24
I1006 20:10:34.209426  3817 net.cpp:406] PReLU24 <- Convolution26
I1006 20:10:34.209429  3817 net.cpp:367] PReLU24 -> Convolution26 (in-place)
I1006 20:10:34.209488  3817 net.cpp:122] Setting up PReLU24
I1006 20:10:34.209493  3817 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 20:10:34.209496  3817 net.cpp:137] Memory required for data: 475104400
I1006 20:10:34.209497  3817 layer_factory.hpp:77] Creating layer Convolution27
I1006 20:10:34.209506  3817 net.cpp:84] Creating Layer Convolution27
I1006 20:10:34.209508  3817 net.cpp:406] Convolution27 <- Convolution26
I1006 20:10:34.209511  3817 net.cpp:380] Convolution27 -> Convolution27
I1006 20:10:34.211146  3817 net.cpp:122] Setting up Convolution27
I1006 20:10:34.211155  3817 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 20:10:34.211158  3817 net.cpp:137] Memory required for data: 476358800
I1006 20:10:34.211168  3817 layer_factory.hpp:77] Creating layer BatchNorm27
I1006 20:10:34.211184  3817 net.cpp:84] Creating Layer BatchNorm27
I1006 20:10:34.211187  3817 net.cpp:406] BatchNorm27 <- Convolution27
I1006 20:10:34.211191  3817 net.cpp:367] BatchNorm27 -> Convolution27 (in-place)
I1006 20:10:34.211340  3817 net.cpp:122] Setting up BatchNorm27
I1006 20:10:34.211345  3817 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 20:10:34.211347  3817 net.cpp:137] Memory required for data: 477613200
I1006 20:10:34.211352  3817 layer_factory.hpp:77] Creating layer Scale27
I1006 20:10:34.211364  3817 net.cpp:84] Creating Layer Scale27
I1006 20:10:34.211367  3817 net.cpp:406] Scale27 <- Convolution27
I1006 20:10:34.211370  3817 net.cpp:367] Scale27 -> Convolution27 (in-place)
I1006 20:10:34.211397  3817 layer_factory.hpp:77] Creating layer Scale27
I1006 20:10:34.211475  3817 net.cpp:122] Setting up Scale27
I1006 20:10:34.211480  3817 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 20:10:34.211483  3817 net.cpp:137] Memory required for data: 478867600
I1006 20:10:34.211486  3817 layer_factory.hpp:77] Creating layer Eltwise12
I1006 20:10:34.211491  3817 net.cpp:84] Creating Layer Eltwise12
I1006 20:10:34.211493  3817 net.cpp:406] Eltwise12 <- Eltwise11_PReLU23_0_split_1
I1006 20:10:34.211496  3817 net.cpp:406] Eltwise12 <- Convolution27
I1006 20:10:34.211499  3817 net.cpp:380] Eltwise12 -> Eltwise12
I1006 20:10:34.211519  3817 net.cpp:122] Setting up Eltwise12
I1006 20:10:34.211524  3817 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 20:10:34.211525  3817 net.cpp:137] Memory required for data: 480122000
I1006 20:10:34.211529  3817 layer_factory.hpp:77] Creating layer PReLU25
I1006 20:10:34.211531  3817 net.cpp:84] Creating Layer PReLU25
I1006 20:10:34.211534  3817 net.cpp:406] PReLU25 <- Eltwise12
I1006 20:10:34.211536  3817 net.cpp:367] PReLU25 -> Eltwise12 (in-place)
I1006 20:10:34.211597  3817 net.cpp:122] Setting up PReLU25
I1006 20:10:34.211602  3817 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 20:10:34.211611  3817 net.cpp:137] Memory required for data: 481376400
I1006 20:10:34.211614  3817 layer_factory.hpp:77] Creating layer Eltwise12_PReLU25_0_split
I1006 20:10:34.211617  3817 net.cpp:84] Creating Layer Eltwise12_PReLU25_0_split
I1006 20:10:34.211619  3817 net.cpp:406] Eltwise12_PReLU25_0_split <- Eltwise12
I1006 20:10:34.211623  3817 net.cpp:380] Eltwise12_PReLU25_0_split -> Eltwise12_PReLU25_0_split_0
I1006 20:10:34.211627  3817 net.cpp:380] Eltwise12_PReLU25_0_split -> Eltwise12_PReLU25_0_split_1
I1006 20:10:34.211652  3817 net.cpp:122] Setting up Eltwise12_PReLU25_0_split
I1006 20:10:34.211658  3817 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 20:10:34.211660  3817 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 20:10:34.211663  3817 net.cpp:137] Memory required for data: 483885200
I1006 20:10:34.211664  3817 layer_factory.hpp:77] Creating layer Convolution28
I1006 20:10:34.211670  3817 net.cpp:84] Creating Layer Convolution28
I1006 20:10:34.211673  3817 net.cpp:406] Convolution28 <- Eltwise12_PReLU25_0_split_0
I1006 20:10:34.211676  3817 net.cpp:380] Convolution28 -> Convolution28
I1006 20:10:34.213318  3817 net.cpp:122] Setting up Convolution28
I1006 20:10:34.213328  3817 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 20:10:34.213331  3817 net.cpp:137] Memory required for data: 485139600
I1006 20:10:34.213335  3817 layer_factory.hpp:77] Creating layer BatchNorm28
I1006 20:10:34.213340  3817 net.cpp:84] Creating Layer BatchNorm28
I1006 20:10:34.213343  3817 net.cpp:406] BatchNorm28 <- Convolution28
I1006 20:10:34.213347  3817 net.cpp:367] BatchNorm28 -> Convolution28 (in-place)
I1006 20:10:34.213485  3817 net.cpp:122] Setting up BatchNorm28
I1006 20:10:34.213488  3817 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 20:10:34.213491  3817 net.cpp:137] Memory required for data: 486394000
I1006 20:10:34.213495  3817 layer_factory.hpp:77] Creating layer Scale28
I1006 20:10:34.213500  3817 net.cpp:84] Creating Layer Scale28
I1006 20:10:34.213502  3817 net.cpp:406] Scale28 <- Convolution28
I1006 20:10:34.213505  3817 net.cpp:367] Scale28 -> Convolution28 (in-place)
I1006 20:10:34.213531  3817 layer_factory.hpp:77] Creating layer Scale28
I1006 20:10:34.213610  3817 net.cpp:122] Setting up Scale28
I1006 20:10:34.213615  3817 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 20:10:34.213618  3817 net.cpp:137] Memory required for data: 487648400
I1006 20:10:34.213621  3817 layer_factory.hpp:77] Creating layer PReLU26
I1006 20:10:34.213624  3817 net.cpp:84] Creating Layer PReLU26
I1006 20:10:34.213626  3817 net.cpp:406] PReLU26 <- Convolution28
I1006 20:10:34.213629  3817 net.cpp:367] PReLU26 -> Convolution28 (in-place)
I1006 20:10:34.213690  3817 net.cpp:122] Setting up PReLU26
I1006 20:10:34.213695  3817 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 20:10:34.213696  3817 net.cpp:137] Memory required for data: 488902800
I1006 20:10:34.213699  3817 layer_factory.hpp:77] Creating layer Convolution29
I1006 20:10:34.213706  3817 net.cpp:84] Creating Layer Convolution29
I1006 20:10:34.213708  3817 net.cpp:406] Convolution29 <- Convolution28
I1006 20:10:34.213712  3817 net.cpp:380] Convolution29 -> Convolution29
I1006 20:10:34.215694  3817 net.cpp:122] Setting up Convolution29
I1006 20:10:34.215703  3817 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 20:10:34.215706  3817 net.cpp:137] Memory required for data: 490157200
I1006 20:10:34.215711  3817 layer_factory.hpp:77] Creating layer BatchNorm29
I1006 20:10:34.215716  3817 net.cpp:84] Creating Layer BatchNorm29
I1006 20:10:34.215719  3817 net.cpp:406] BatchNorm29 <- Convolution29
I1006 20:10:34.215723  3817 net.cpp:367] BatchNorm29 -> Convolution29 (in-place)
I1006 20:10:34.215862  3817 net.cpp:122] Setting up BatchNorm29
I1006 20:10:34.215867  3817 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 20:10:34.215868  3817 net.cpp:137] Memory required for data: 491411600
I1006 20:10:34.215873  3817 layer_factory.hpp:77] Creating layer Scale29
I1006 20:10:34.215878  3817 net.cpp:84] Creating Layer Scale29
I1006 20:10:34.215879  3817 net.cpp:406] Scale29 <- Convolution29
I1006 20:10:34.215889  3817 net.cpp:367] Scale29 -> Convolution29 (in-place)
I1006 20:10:34.215919  3817 layer_factory.hpp:77] Creating layer Scale29
I1006 20:10:34.215997  3817 net.cpp:122] Setting up Scale29
I1006 20:10:34.216002  3817 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 20:10:34.216004  3817 net.cpp:137] Memory required for data: 492666000
I1006 20:10:34.216007  3817 layer_factory.hpp:77] Creating layer Eltwise13
I1006 20:10:34.216012  3817 net.cpp:84] Creating Layer Eltwise13
I1006 20:10:34.216015  3817 net.cpp:406] Eltwise13 <- Eltwise12_PReLU25_0_split_1
I1006 20:10:34.216017  3817 net.cpp:406] Eltwise13 <- Convolution29
I1006 20:10:34.216022  3817 net.cpp:380] Eltwise13 -> Eltwise13
I1006 20:10:34.216037  3817 net.cpp:122] Setting up Eltwise13
I1006 20:10:34.216042  3817 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 20:10:34.216043  3817 net.cpp:137] Memory required for data: 493920400
I1006 20:10:34.216045  3817 layer_factory.hpp:77] Creating layer PReLU27
I1006 20:10:34.216048  3817 net.cpp:84] Creating Layer PReLU27
I1006 20:10:34.216050  3817 net.cpp:406] PReLU27 <- Eltwise13
I1006 20:10:34.216054  3817 net.cpp:367] PReLU27 -> Eltwise13 (in-place)
I1006 20:10:34.216115  3817 net.cpp:122] Setting up PReLU27
I1006 20:10:34.216120  3817 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 20:10:34.216121  3817 net.cpp:137] Memory required for data: 495174800
I1006 20:10:34.216125  3817 layer_factory.hpp:77] Creating layer Eltwise13_PReLU27_0_split
I1006 20:10:34.216128  3817 net.cpp:84] Creating Layer Eltwise13_PReLU27_0_split
I1006 20:10:34.216130  3817 net.cpp:406] Eltwise13_PReLU27_0_split <- Eltwise13
I1006 20:10:34.216135  3817 net.cpp:380] Eltwise13_PReLU27_0_split -> Eltwise13_PReLU27_0_split_0
I1006 20:10:34.216138  3817 net.cpp:380] Eltwise13_PReLU27_0_split -> Eltwise13_PReLU27_0_split_1
I1006 20:10:34.216161  3817 net.cpp:122] Setting up Eltwise13_PReLU27_0_split
I1006 20:10:34.216166  3817 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 20:10:34.216169  3817 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 20:10:34.216171  3817 net.cpp:137] Memory required for data: 497683600
I1006 20:10:34.216173  3817 layer_factory.hpp:77] Creating layer Convolution30
I1006 20:10:34.216179  3817 net.cpp:84] Creating Layer Convolution30
I1006 20:10:34.216182  3817 net.cpp:406] Convolution30 <- Eltwise13_PReLU27_0_split_0
I1006 20:10:34.216187  3817 net.cpp:380] Convolution30 -> Convolution30
I1006 20:10:34.217836  3817 net.cpp:122] Setting up Convolution30
I1006 20:10:34.217844  3817 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 20:10:34.217847  3817 net.cpp:137] Memory required for data: 498938000
I1006 20:10:34.217851  3817 layer_factory.hpp:77] Creating layer BatchNorm30
I1006 20:10:34.217857  3817 net.cpp:84] Creating Layer BatchNorm30
I1006 20:10:34.217860  3817 net.cpp:406] BatchNorm30 <- Convolution30
I1006 20:10:34.217864  3817 net.cpp:367] BatchNorm30 -> Convolution30 (in-place)
I1006 20:10:34.218000  3817 net.cpp:122] Setting up BatchNorm30
I1006 20:10:34.218004  3817 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 20:10:34.218006  3817 net.cpp:137] Memory required for data: 500192400
I1006 20:10:34.218011  3817 layer_factory.hpp:77] Creating layer Scale30
I1006 20:10:34.218015  3817 net.cpp:84] Creating Layer Scale30
I1006 20:10:34.218017  3817 net.cpp:406] Scale30 <- Convolution30
I1006 20:10:34.218020  3817 net.cpp:367] Scale30 -> Convolution30 (in-place)
I1006 20:10:34.218049  3817 layer_factory.hpp:77] Creating layer Scale30
I1006 20:10:34.218124  3817 net.cpp:122] Setting up Scale30
I1006 20:10:34.218129  3817 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 20:10:34.218132  3817 net.cpp:137] Memory required for data: 501446800
I1006 20:10:34.218135  3817 layer_factory.hpp:77] Creating layer PReLU28
I1006 20:10:34.218139  3817 net.cpp:84] Creating Layer PReLU28
I1006 20:10:34.218142  3817 net.cpp:406] PReLU28 <- Convolution30
I1006 20:10:34.218144  3817 net.cpp:367] PReLU28 -> Convolution30 (in-place)
I1006 20:10:34.218205  3817 net.cpp:122] Setting up PReLU28
I1006 20:10:34.218216  3817 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 20:10:34.218219  3817 net.cpp:137] Memory required for data: 502701200
I1006 20:10:34.218221  3817 layer_factory.hpp:77] Creating layer Convolution31
I1006 20:10:34.218228  3817 net.cpp:84] Creating Layer Convolution31
I1006 20:10:34.218231  3817 net.cpp:406] Convolution31 <- Convolution30
I1006 20:10:34.218235  3817 net.cpp:380] Convolution31 -> Convolution31
I1006 20:10:34.220228  3817 net.cpp:122] Setting up Convolution31
I1006 20:10:34.220237  3817 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 20:10:34.220239  3817 net.cpp:137] Memory required for data: 503955600
I1006 20:10:34.220244  3817 layer_factory.hpp:77] Creating layer BatchNorm31
I1006 20:10:34.220249  3817 net.cpp:84] Creating Layer BatchNorm31
I1006 20:10:34.220252  3817 net.cpp:406] BatchNorm31 <- Convolution31
I1006 20:10:34.220257  3817 net.cpp:367] BatchNorm31 -> Convolution31 (in-place)
I1006 20:10:34.220396  3817 net.cpp:122] Setting up BatchNorm31
I1006 20:10:34.220401  3817 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 20:10:34.220402  3817 net.cpp:137] Memory required for data: 505210000
I1006 20:10:34.220407  3817 layer_factory.hpp:77] Creating layer Scale31
I1006 20:10:34.220412  3817 net.cpp:84] Creating Layer Scale31
I1006 20:10:34.220413  3817 net.cpp:406] Scale31 <- Convolution31
I1006 20:10:34.220417  3817 net.cpp:367] Scale31 -> Convolution31 (in-place)
I1006 20:10:34.220444  3817 layer_factory.hpp:77] Creating layer Scale31
I1006 20:10:34.220522  3817 net.cpp:122] Setting up Scale31
I1006 20:10:34.220527  3817 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 20:10:34.220530  3817 net.cpp:137] Memory required for data: 506464400
I1006 20:10:34.220533  3817 layer_factory.hpp:77] Creating layer Eltwise14
I1006 20:10:34.220537  3817 net.cpp:84] Creating Layer Eltwise14
I1006 20:10:34.220541  3817 net.cpp:406] Eltwise14 <- Eltwise13_PReLU27_0_split_1
I1006 20:10:34.220542  3817 net.cpp:406] Eltwise14 <- Convolution31
I1006 20:10:34.220546  3817 net.cpp:380] Eltwise14 -> Eltwise14
I1006 20:10:34.220563  3817 net.cpp:122] Setting up Eltwise14
I1006 20:10:34.220567  3817 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 20:10:34.220569  3817 net.cpp:137] Memory required for data: 507718800
I1006 20:10:34.220571  3817 layer_factory.hpp:77] Creating layer PReLU29
I1006 20:10:34.220574  3817 net.cpp:84] Creating Layer PReLU29
I1006 20:10:34.220577  3817 net.cpp:406] PReLU29 <- Eltwise14
I1006 20:10:34.220579  3817 net.cpp:367] PReLU29 -> Eltwise14 (in-place)
I1006 20:10:34.220641  3817 net.cpp:122] Setting up PReLU29
I1006 20:10:34.220645  3817 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 20:10:34.220648  3817 net.cpp:137] Memory required for data: 508973200
I1006 20:10:34.220650  3817 layer_factory.hpp:77] Creating layer Eltwise14_PReLU29_0_split
I1006 20:10:34.220654  3817 net.cpp:84] Creating Layer Eltwise14_PReLU29_0_split
I1006 20:10:34.220656  3817 net.cpp:406] Eltwise14_PReLU29_0_split <- Eltwise14
I1006 20:10:34.220660  3817 net.cpp:380] Eltwise14_PReLU29_0_split -> Eltwise14_PReLU29_0_split_0
I1006 20:10:34.220664  3817 net.cpp:380] Eltwise14_PReLU29_0_split -> Eltwise14_PReLU29_0_split_1
I1006 20:10:34.220686  3817 net.cpp:122] Setting up Eltwise14_PReLU29_0_split
I1006 20:10:34.220690  3817 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 20:10:34.220693  3817 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 20:10:34.220695  3817 net.cpp:137] Memory required for data: 511482000
I1006 20:10:34.220697  3817 layer_factory.hpp:77] Creating layer Convolution32
I1006 20:10:34.220703  3817 net.cpp:84] Creating Layer Convolution32
I1006 20:10:34.220706  3817 net.cpp:406] Convolution32 <- Eltwise14_PReLU29_0_split_0
I1006 20:10:34.220710  3817 net.cpp:380] Convolution32 -> Convolution32
I1006 20:10:34.222373  3817 net.cpp:122] Setting up Convolution32
I1006 20:10:34.222383  3817 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 20:10:34.222385  3817 net.cpp:137] Memory required for data: 512736400
I1006 20:10:34.222390  3817 layer_factory.hpp:77] Creating layer BatchNorm32
I1006 20:10:34.222401  3817 net.cpp:84] Creating Layer BatchNorm32
I1006 20:10:34.222404  3817 net.cpp:406] BatchNorm32 <- Convolution32
I1006 20:10:34.222409  3817 net.cpp:367] BatchNorm32 -> Convolution32 (in-place)
I1006 20:10:34.222550  3817 net.cpp:122] Setting up BatchNorm32
I1006 20:10:34.222554  3817 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 20:10:34.222556  3817 net.cpp:137] Memory required for data: 513990800
I1006 20:10:34.222561  3817 layer_factory.hpp:77] Creating layer Scale32
I1006 20:10:34.222565  3817 net.cpp:84] Creating Layer Scale32
I1006 20:10:34.222568  3817 net.cpp:406] Scale32 <- Convolution32
I1006 20:10:34.222571  3817 net.cpp:367] Scale32 -> Convolution32 (in-place)
I1006 20:10:34.222599  3817 layer_factory.hpp:77] Creating layer Scale32
I1006 20:10:34.222678  3817 net.cpp:122] Setting up Scale32
I1006 20:10:34.222682  3817 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 20:10:34.222684  3817 net.cpp:137] Memory required for data: 515245200
I1006 20:10:34.222688  3817 layer_factory.hpp:77] Creating layer PReLU30
I1006 20:10:34.222692  3817 net.cpp:84] Creating Layer PReLU30
I1006 20:10:34.222694  3817 net.cpp:406] PReLU30 <- Convolution32
I1006 20:10:34.222697  3817 net.cpp:367] PReLU30 -> Convolution32 (in-place)
I1006 20:10:34.222759  3817 net.cpp:122] Setting up PReLU30
I1006 20:10:34.222764  3817 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 20:10:34.222765  3817 net.cpp:137] Memory required for data: 516499600
I1006 20:10:34.222769  3817 layer_factory.hpp:77] Creating layer Convolution33
I1006 20:10:34.222775  3817 net.cpp:84] Creating Layer Convolution33
I1006 20:10:34.222777  3817 net.cpp:406] Convolution33 <- Convolution32
I1006 20:10:34.222782  3817 net.cpp:380] Convolution33 -> Convolution33
I1006 20:10:34.224805  3817 net.cpp:122] Setting up Convolution33
I1006 20:10:34.224813  3817 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 20:10:34.224817  3817 net.cpp:137] Memory required for data: 517754000
I1006 20:10:34.224822  3817 layer_factory.hpp:77] Creating layer BatchNorm33
I1006 20:10:34.224826  3817 net.cpp:84] Creating Layer BatchNorm33
I1006 20:10:34.224829  3817 net.cpp:406] BatchNorm33 <- Convolution33
I1006 20:10:34.224833  3817 net.cpp:367] BatchNorm33 -> Convolution33 (in-place)
I1006 20:10:34.224972  3817 net.cpp:122] Setting up BatchNorm33
I1006 20:10:34.224977  3817 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 20:10:34.224978  3817 net.cpp:137] Memory required for data: 519008400
I1006 20:10:34.225002  3817 layer_factory.hpp:77] Creating layer Scale33
I1006 20:10:34.225005  3817 net.cpp:84] Creating Layer Scale33
I1006 20:10:34.225008  3817 net.cpp:406] Scale33 <- Convolution33
I1006 20:10:34.225011  3817 net.cpp:367] Scale33 -> Convolution33 (in-place)
I1006 20:10:34.225040  3817 layer_factory.hpp:77] Creating layer Scale33
I1006 20:10:34.225118  3817 net.cpp:122] Setting up Scale33
I1006 20:10:34.225122  3817 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 20:10:34.225124  3817 net.cpp:137] Memory required for data: 520262800
I1006 20:10:34.225127  3817 layer_factory.hpp:77] Creating layer Eltwise15
I1006 20:10:34.225131  3817 net.cpp:84] Creating Layer Eltwise15
I1006 20:10:34.225133  3817 net.cpp:406] Eltwise15 <- Eltwise14_PReLU29_0_split_1
I1006 20:10:34.225136  3817 net.cpp:406] Eltwise15 <- Convolution33
I1006 20:10:34.225141  3817 net.cpp:380] Eltwise15 -> Eltwise15
I1006 20:10:34.225157  3817 net.cpp:122] Setting up Eltwise15
I1006 20:10:34.225160  3817 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 20:10:34.225162  3817 net.cpp:137] Memory required for data: 521517200
I1006 20:10:34.225164  3817 layer_factory.hpp:77] Creating layer PReLU31
I1006 20:10:34.225167  3817 net.cpp:84] Creating Layer PReLU31
I1006 20:10:34.225169  3817 net.cpp:406] PReLU31 <- Eltwise15
I1006 20:10:34.225172  3817 net.cpp:367] PReLU31 -> Eltwise15 (in-place)
I1006 20:10:34.225235  3817 net.cpp:122] Setting up PReLU31
I1006 20:10:34.225240  3817 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 20:10:34.225242  3817 net.cpp:137] Memory required for data: 522771600
I1006 20:10:34.225251  3817 layer_factory.hpp:77] Creating layer Pooling1
I1006 20:10:34.225256  3817 net.cpp:84] Creating Layer Pooling1
I1006 20:10:34.225258  3817 net.cpp:406] Pooling1 <- Eltwise15
I1006 20:10:34.225261  3817 net.cpp:380] Pooling1 -> Pooling1
I1006 20:10:34.225411  3817 net.cpp:122] Setting up Pooling1
I1006 20:10:34.225417  3817 net.cpp:129] Top shape: 100 64 1 1 (6400)
I1006 20:10:34.225419  3817 net.cpp:137] Memory required for data: 522797200
I1006 20:10:34.225421  3817 layer_factory.hpp:77] Creating layer InnerProduct1
I1006 20:10:34.225431  3817 net.cpp:84] Creating Layer InnerProduct1
I1006 20:10:34.225433  3817 net.cpp:406] InnerProduct1 <- Pooling1
I1006 20:10:34.225437  3817 net.cpp:380] InnerProduct1 -> InnerProduct1
I1006 20:10:34.225533  3817 net.cpp:122] Setting up InnerProduct1
I1006 20:10:34.225538  3817 net.cpp:129] Top shape: 100 10 (1000)
I1006 20:10:34.225539  3817 net.cpp:137] Memory required for data: 522801200
I1006 20:10:34.225543  3817 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I1006 20:10:34.225546  3817 net.cpp:84] Creating Layer SoftmaxWithLoss1
I1006 20:10:34.225549  3817 net.cpp:406] SoftmaxWithLoss1 <- InnerProduct1
I1006 20:10:34.225551  3817 net.cpp:406] SoftmaxWithLoss1 <- Data2
I1006 20:10:34.225555  3817 net.cpp:380] SoftmaxWithLoss1 -> SoftmaxWithLoss1
I1006 20:10:34.225561  3817 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I1006 20:10:34.225744  3817 net.cpp:122] Setting up SoftmaxWithLoss1
I1006 20:10:34.225749  3817 net.cpp:129] Top shape: (1)
I1006 20:10:34.225752  3817 net.cpp:132]     with loss weight 1
I1006 20:10:34.225764  3817 net.cpp:137] Memory required for data: 522801204
I1006 20:10:34.225766  3817 net.cpp:198] SoftmaxWithLoss1 needs backward computation.
I1006 20:10:34.225769  3817 net.cpp:198] InnerProduct1 needs backward computation.
I1006 20:10:34.225771  3817 net.cpp:198] Pooling1 needs backward computation.
I1006 20:10:34.225774  3817 net.cpp:198] PReLU31 needs backward computation.
I1006 20:10:34.225775  3817 net.cpp:198] Eltwise15 needs backward computation.
I1006 20:10:34.225777  3817 net.cpp:198] Scale33 needs backward computation.
I1006 20:10:34.225780  3817 net.cpp:198] BatchNorm33 needs backward computation.
I1006 20:10:34.225781  3817 net.cpp:198] Convolution33 needs backward computation.
I1006 20:10:34.225783  3817 net.cpp:198] PReLU30 needs backward computation.
I1006 20:10:34.225785  3817 net.cpp:198] Scale32 needs backward computation.
I1006 20:10:34.225786  3817 net.cpp:198] BatchNorm32 needs backward computation.
I1006 20:10:34.225788  3817 net.cpp:198] Convolution32 needs backward computation.
I1006 20:10:34.225790  3817 net.cpp:198] Eltwise14_PReLU29_0_split needs backward computation.
I1006 20:10:34.225793  3817 net.cpp:198] PReLU29 needs backward computation.
I1006 20:10:34.225795  3817 net.cpp:198] Eltwise14 needs backward computation.
I1006 20:10:34.225797  3817 net.cpp:198] Scale31 needs backward computation.
I1006 20:10:34.225800  3817 net.cpp:198] BatchNorm31 needs backward computation.
I1006 20:10:34.225800  3817 net.cpp:198] Convolution31 needs backward computation.
I1006 20:10:34.225802  3817 net.cpp:198] PReLU28 needs backward computation.
I1006 20:10:34.225805  3817 net.cpp:198] Scale30 needs backward computation.
I1006 20:10:34.225806  3817 net.cpp:198] BatchNorm30 needs backward computation.
I1006 20:10:34.225808  3817 net.cpp:198] Convolution30 needs backward computation.
I1006 20:10:34.225811  3817 net.cpp:198] Eltwise13_PReLU27_0_split needs backward computation.
I1006 20:10:34.225812  3817 net.cpp:198] PReLU27 needs backward computation.
I1006 20:10:34.225814  3817 net.cpp:198] Eltwise13 needs backward computation.
I1006 20:10:34.225816  3817 net.cpp:198] Scale29 needs backward computation.
I1006 20:10:34.225818  3817 net.cpp:198] BatchNorm29 needs backward computation.
I1006 20:10:34.225821  3817 net.cpp:198] Convolution29 needs backward computation.
I1006 20:10:34.225822  3817 net.cpp:198] PReLU26 needs backward computation.
I1006 20:10:34.225831  3817 net.cpp:198] Scale28 needs backward computation.
I1006 20:10:34.225832  3817 net.cpp:198] BatchNorm28 needs backward computation.
I1006 20:10:34.225834  3817 net.cpp:198] Convolution28 needs backward computation.
I1006 20:10:34.225836  3817 net.cpp:198] Eltwise12_PReLU25_0_split needs backward computation.
I1006 20:10:34.225838  3817 net.cpp:198] PReLU25 needs backward computation.
I1006 20:10:34.225841  3817 net.cpp:198] Eltwise12 needs backward computation.
I1006 20:10:34.225842  3817 net.cpp:198] Scale27 needs backward computation.
I1006 20:10:34.225844  3817 net.cpp:198] BatchNorm27 needs backward computation.
I1006 20:10:34.225847  3817 net.cpp:198] Convolution27 needs backward computation.
I1006 20:10:34.225848  3817 net.cpp:198] PReLU24 needs backward computation.
I1006 20:10:34.225850  3817 net.cpp:198] Scale26 needs backward computation.
I1006 20:10:34.225852  3817 net.cpp:198] BatchNorm26 needs backward computation.
I1006 20:10:34.225854  3817 net.cpp:198] Convolution26 needs backward computation.
I1006 20:10:34.225857  3817 net.cpp:198] Eltwise11_PReLU23_0_split needs backward computation.
I1006 20:10:34.225858  3817 net.cpp:198] PReLU23 needs backward computation.
I1006 20:10:34.225860  3817 net.cpp:198] Eltwise11 needs backward computation.
I1006 20:10:34.225862  3817 net.cpp:198] Scale25 needs backward computation.
I1006 20:10:34.225864  3817 net.cpp:198] BatchNorm25 needs backward computation.
I1006 20:10:34.225867  3817 net.cpp:198] Convolution25 needs backward computation.
I1006 20:10:34.225868  3817 net.cpp:198] PReLU22 needs backward computation.
I1006 20:10:34.225870  3817 net.cpp:198] Scale24 needs backward computation.
I1006 20:10:34.225872  3817 net.cpp:198] BatchNorm24 needs backward computation.
I1006 20:10:34.225874  3817 net.cpp:198] Convolution24 needs backward computation.
I1006 20:10:34.225877  3817 net.cpp:198] Scale23 needs backward computation.
I1006 20:10:34.225878  3817 net.cpp:198] BatchNorm23 needs backward computation.
I1006 20:10:34.225880  3817 net.cpp:198] Convolution23 needs backward computation.
I1006 20:10:34.225883  3817 net.cpp:198] Eltwise10_PReLU21_0_split needs backward computation.
I1006 20:10:34.225884  3817 net.cpp:198] PReLU21 needs backward computation.
I1006 20:10:34.225886  3817 net.cpp:198] Eltwise10 needs backward computation.
I1006 20:10:34.225888  3817 net.cpp:198] Scale22 needs backward computation.
I1006 20:10:34.225890  3817 net.cpp:198] BatchNorm22 needs backward computation.
I1006 20:10:34.225893  3817 net.cpp:198] Convolution22 needs backward computation.
I1006 20:10:34.225895  3817 net.cpp:198] PReLU20 needs backward computation.
I1006 20:10:34.225898  3817 net.cpp:198] Scale21 needs backward computation.
I1006 20:10:34.225899  3817 net.cpp:198] BatchNorm21 needs backward computation.
I1006 20:10:34.225901  3817 net.cpp:198] Convolution21 needs backward computation.
I1006 20:10:34.225903  3817 net.cpp:198] Eltwise9_PReLU19_0_split needs backward computation.
I1006 20:10:34.225905  3817 net.cpp:198] PReLU19 needs backward computation.
I1006 20:10:34.225908  3817 net.cpp:198] Eltwise9 needs backward computation.
I1006 20:10:34.225910  3817 net.cpp:198] Scale20 needs backward computation.
I1006 20:10:34.225913  3817 net.cpp:198] BatchNorm20 needs backward computation.
I1006 20:10:34.225914  3817 net.cpp:198] Convolution20 needs backward computation.
I1006 20:10:34.225916  3817 net.cpp:198] PReLU18 needs backward computation.
I1006 20:10:34.225919  3817 net.cpp:198] Scale19 needs backward computation.
I1006 20:10:34.225920  3817 net.cpp:198] BatchNorm19 needs backward computation.
I1006 20:10:34.225924  3817 net.cpp:198] Convolution19 needs backward computation.
I1006 20:10:34.225925  3817 net.cpp:198] Eltwise8_PReLU17_0_split needs backward computation.
I1006 20:10:34.225927  3817 net.cpp:198] PReLU17 needs backward computation.
I1006 20:10:34.225929  3817 net.cpp:198] Eltwise8 needs backward computation.
I1006 20:10:34.225932  3817 net.cpp:198] Scale18 needs backward computation.
I1006 20:10:34.225934  3817 net.cpp:198] BatchNorm18 needs backward computation.
I1006 20:10:34.225939  3817 net.cpp:198] Convolution18 needs backward computation.
I1006 20:10:34.225942  3817 net.cpp:198] PReLU16 needs backward computation.
I1006 20:10:34.225944  3817 net.cpp:198] Scale17 needs backward computation.
I1006 20:10:34.225946  3817 net.cpp:198] BatchNorm17 needs backward computation.
I1006 20:10:34.225949  3817 net.cpp:198] Convolution17 needs backward computation.
I1006 20:10:34.225950  3817 net.cpp:198] Eltwise7_PReLU15_0_split needs backward computation.
I1006 20:10:34.225952  3817 net.cpp:198] PReLU15 needs backward computation.
I1006 20:10:34.225955  3817 net.cpp:198] Eltwise7 needs backward computation.
I1006 20:10:34.225957  3817 net.cpp:198] Scale16 needs backward computation.
I1006 20:10:34.225960  3817 net.cpp:198] BatchNorm16 needs backward computation.
I1006 20:10:34.225961  3817 net.cpp:198] Convolution16 needs backward computation.
I1006 20:10:34.225965  3817 net.cpp:198] PReLU14 needs backward computation.
I1006 20:10:34.225966  3817 net.cpp:198] Scale15 needs backward computation.
I1006 20:10:34.225968  3817 net.cpp:198] BatchNorm15 needs backward computation.
I1006 20:10:34.225970  3817 net.cpp:198] Convolution15 needs backward computation.
I1006 20:10:34.225972  3817 net.cpp:198] Eltwise6_PReLU13_0_split needs backward computation.
I1006 20:10:34.225975  3817 net.cpp:198] PReLU13 needs backward computation.
I1006 20:10:34.225977  3817 net.cpp:198] Eltwise6 needs backward computation.
I1006 20:10:34.225980  3817 net.cpp:198] Scale14 needs backward computation.
I1006 20:10:34.225982  3817 net.cpp:198] BatchNorm14 needs backward computation.
I1006 20:10:34.225985  3817 net.cpp:198] Convolution14 needs backward computation.
I1006 20:10:34.225986  3817 net.cpp:198] PReLU12 needs backward computation.
I1006 20:10:34.225988  3817 net.cpp:198] Scale13 needs backward computation.
I1006 20:10:34.225991  3817 net.cpp:198] BatchNorm13 needs backward computation.
I1006 20:10:34.225992  3817 net.cpp:198] Convolution13 needs backward computation.
I1006 20:10:34.225994  3817 net.cpp:198] Scale12 needs backward computation.
I1006 20:10:34.225997  3817 net.cpp:198] BatchNorm12 needs backward computation.
I1006 20:10:34.225998  3817 net.cpp:198] Convolution12 needs backward computation.
I1006 20:10:34.226001  3817 net.cpp:198] Eltwise5_PReLU11_0_split needs backward computation.
I1006 20:10:34.226003  3817 net.cpp:198] PReLU11 needs backward computation.
I1006 20:10:34.226006  3817 net.cpp:198] Eltwise5 needs backward computation.
I1006 20:10:34.226008  3817 net.cpp:198] Scale11 needs backward computation.
I1006 20:10:34.226011  3817 net.cpp:198] BatchNorm11 needs backward computation.
I1006 20:10:34.226013  3817 net.cpp:198] Convolution11 needs backward computation.
I1006 20:10:34.226016  3817 net.cpp:198] PReLU10 needs backward computation.
I1006 20:10:34.226017  3817 net.cpp:198] Scale10 needs backward computation.
I1006 20:10:34.226019  3817 net.cpp:198] BatchNorm10 needs backward computation.
I1006 20:10:34.226022  3817 net.cpp:198] Convolution10 needs backward computation.
I1006 20:10:34.226023  3817 net.cpp:198] Eltwise4_PReLU9_0_split needs backward computation.
I1006 20:10:34.226027  3817 net.cpp:198] PReLU9 needs backward computation.
I1006 20:10:34.226028  3817 net.cpp:198] Eltwise4 needs backward computation.
I1006 20:10:34.226032  3817 net.cpp:198] Scale9 needs backward computation.
I1006 20:10:34.226033  3817 net.cpp:198] BatchNorm9 needs backward computation.
I1006 20:10:34.226037  3817 net.cpp:198] Convolution9 needs backward computation.
I1006 20:10:34.226038  3817 net.cpp:198] PReLU8 needs backward computation.
I1006 20:10:34.226040  3817 net.cpp:198] Scale8 needs backward computation.
I1006 20:10:34.226042  3817 net.cpp:198] BatchNorm8 needs backward computation.
I1006 20:10:34.226044  3817 net.cpp:198] Convolution8 needs backward computation.
I1006 20:10:34.226047  3817 net.cpp:198] Eltwise3_PReLU7_0_split needs backward computation.
I1006 20:10:34.226049  3817 net.cpp:198] PReLU7 needs backward computation.
I1006 20:10:34.226052  3817 net.cpp:198] Eltwise3 needs backward computation.
I1006 20:10:34.226056  3817 net.cpp:198] Scale7 needs backward computation.
I1006 20:10:34.226059  3817 net.cpp:198] BatchNorm7 needs backward computation.
I1006 20:10:34.226061  3817 net.cpp:198] Convolution7 needs backward computation.
I1006 20:10:34.226063  3817 net.cpp:198] PReLU6 needs backward computation.
I1006 20:10:34.226065  3817 net.cpp:198] Scale6 needs backward computation.
I1006 20:10:34.226068  3817 net.cpp:198] BatchNorm6 needs backward computation.
I1006 20:10:34.226069  3817 net.cpp:198] Convolution6 needs backward computation.
I1006 20:10:34.226071  3817 net.cpp:198] Eltwise2_PReLU5_0_split needs backward computation.
I1006 20:10:34.226074  3817 net.cpp:198] PReLU5 needs backward computation.
I1006 20:10:34.226076  3817 net.cpp:198] Eltwise2 needs backward computation.
I1006 20:10:34.226078  3817 net.cpp:198] Scale5 needs backward computation.
I1006 20:10:34.226080  3817 net.cpp:198] BatchNorm5 needs backward computation.
I1006 20:10:34.226083  3817 net.cpp:198] Convolution5 needs backward computation.
I1006 20:10:34.226085  3817 net.cpp:198] PReLU4 needs backward computation.
I1006 20:10:34.226088  3817 net.cpp:198] Scale4 needs backward computation.
I1006 20:10:34.226089  3817 net.cpp:198] BatchNorm4 needs backward computation.
I1006 20:10:34.226091  3817 net.cpp:198] Convolution4 needs backward computation.
I1006 20:10:34.226094  3817 net.cpp:198] Eltwise1_PReLU3_0_split needs backward computation.
I1006 20:10:34.226096  3817 net.cpp:198] PReLU3 needs backward computation.
I1006 20:10:34.226099  3817 net.cpp:198] Eltwise1 needs backward computation.
I1006 20:10:34.226101  3817 net.cpp:198] Scale3 needs backward computation.
I1006 20:10:34.226104  3817 net.cpp:198] BatchNorm3 needs backward computation.
I1006 20:10:34.226105  3817 net.cpp:198] Convolution3 needs backward computation.
I1006 20:10:34.226107  3817 net.cpp:198] PReLU2 needs backward computation.
I1006 20:10:34.226109  3817 net.cpp:198] Scale2 needs backward computation.
I1006 20:10:34.226112  3817 net.cpp:198] BatchNorm2 needs backward computation.
I1006 20:10:34.226114  3817 net.cpp:198] Convolution2 needs backward computation.
I1006 20:10:34.226116  3817 net.cpp:198] Convolution1_PReLU1_0_split needs backward computation.
I1006 20:10:34.226119  3817 net.cpp:198] PReLU1 needs backward computation.
I1006 20:10:34.226121  3817 net.cpp:198] Scale1 needs backward computation.
I1006 20:10:34.226124  3817 net.cpp:198] BatchNorm1 needs backward computation.
I1006 20:10:34.226125  3817 net.cpp:198] Convolution1 needs backward computation.
I1006 20:10:34.226127  3817 net.cpp:200] Data1 does not need backward computation.
I1006 20:10:34.226130  3817 net.cpp:242] This network produces output SoftmaxWithLoss1
I1006 20:10:34.226181  3817 net.cpp:255] Network initialization done.
I1006 20:10:34.228204  3817 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: /home/x306/caffe/xn/PENLU/neural/resnet/res32/res32_prelu_train_test.prototxt
I1006 20:10:34.228212  3817 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I1006 20:10:34.228216  3817 solver.cpp:172] Creating test net (#0) specified by net file: /home/x306/caffe/xn/PENLU/neural/resnet/res32/res32_prelu_train_test.prototxt
I1006 20:10:34.228317  3817 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer Data1
I1006 20:10:34.228862  3817 net.cpp:51] Initializing net from parameters: 
name: "resnet_cifar10"
state {
  phase: TEST
}
layer {
  name: "Data1"
  type: "Data"
  top: "Data1"
  top: "Data2"
  include {
    phase: TEST
  }
  transform_param {
    mean_file: "/home/x306/caffe/xn/PENLU/data/cifar10/mean.binaryproto"
  }
  data_param {
    source: "/home/x306/caffe/xn/PENLU/data/cifar10/cifar10_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "Convolution1"
  type: "Convolution"
  bottom: "Data1"
  top: "Convolution1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm1"
  type: "BatchNorm"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1"
  type: "Scale"
  bottom: "Convolution1"
  top: "Convolution1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "PReLU1"
  type: "PReLU"
  bottom: "Convolution1"
  top: "Convolution1"
}
layer {
  name: "Convolution2"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm2"
  type: "BatchNorm"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale2"
  type: "Scale"
  bottom: "Convolution2"
  top: "Convolution2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "PReLU2"
  type: "PReLU"
  bottom: "Convolution2"
  top: "Convolution2"
}
layer {
  name: "Convolution3"
  type: "Convolution"
  bottom: "Convolution2"
  top: "Convolution3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm3"
  type: "BatchNorm"
  bottom: "Convolution3"
  top: "Convolution3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale3"
  type: "Scale"
  bottom: "Convolution3"
  top: "Convolution3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise1"
  type: "Eltwise"
  bottom: "Convolution1"
  bottom: "Convolution3"
  top: "Eltwise1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "PReLU3"
  type: "PReLU"
  bottom: "Eltwise1"
  top: "Eltwise1"
}
layer {
  name: "Convolution4"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm4"
  type: "BatchNorm"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale4"
  type: "Scale"
  bottom: "Convolution4"
  top: "Convolution4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "PReLU4"
  type: "PReLU"
  bottom: "Convolution4"
  top: "Convolution4"
}
layer {
  name: "Convolution5"
  type: "Convolution"
  bottom: "Convolution4"
  top: "Convolution5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm5"
  type: "BatchNorm"
  bottom: "Convolution5"
  top: "Convolution5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale5"
  type: "Scale"
  bottom: "Convolution5"
  top: "Convolution5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise2"
  type: "Eltwise"
  bottom: "Eltwise1"
  bottom: "Convolution5"
  top: "Eltwise2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "PReLU5"
  type: "PReLU"
  bottom: "Eltwise2"
  top: "Eltwise2"
}
layer {
  name: "Convolution6"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm6"
  type: "BatchNorm"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale6"
  type: "Scale"
  bottom: "Convolution6"
  top: "Convolution6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "PReLU6"
  type: "PReLU"
  bottom: "Convolution6"
  top: "Convolution6"
}
layer {
  name: "Convolution7"
  type: "Convolution"
  bottom: "Convolution6"
  top: "Convolution7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm7"
  type: "BatchNorm"
  bottom: "Convolution7"
  top: "Convolution7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale7"
  type: "Scale"
  bottom: "Convolution7"
  top: "Convolution7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise3"
  type: "Eltwise"
  bottom: "Eltwise2"
  bottom: "Convolution7"
  top: "Eltwise3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "PReLU7"
  type: "PReLU"
  bottom: "Eltwise3"
  top: "Eltwise3"
}
layer {
  name: "Convolution8"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm8"
  type: "BatchNorm"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale8"
  type: "Scale"
  bottom: "Convolution8"
  top: "Convolution8"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "PReLU8"
  type: "PReLU"
  bottom: "Convolution8"
  top: "Convolution8"
}
layer {
  name: "Convolution9"
  type: "Convolution"
  bottom: "Convolution8"
  top: "Convolution9"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm9"
  type: "BatchNorm"
  bottom: "Convolution9"
  top: "Convolution9"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale9"
  type: "Scale"
  bottom: "Convolution9"
  top: "Convolution9"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise4"
  type: "Eltwise"
  bottom: "Eltwise3"
  bottom: "Convolution9"
  top: "Eltwise4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "PReLU9"
  type: "PReLU"
  bottom: "Eltwise4"
  top: "Eltwise4"
}
layer {
  name: "Convolution10"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution10"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm10"
  type: "BatchNorm"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale10"
  type: "Scale"
  bottom: "Convolution10"
  top: "Convolution10"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "PReLU10"
  type: "PReLU"
  bottom: "Convolution10"
  top: "Convolution10"
}
layer {
  name: "Convolution11"
  type: "Convolution"
  bottom: "Convolution10"
  top: "Convolution11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm11"
  type: "BatchNorm"
  bottom: "Convolution11"
  top: "Convolution11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale11"
  type: "Scale"
  bottom: "Convolution11"
  top: "Convolution11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise5"
  type: "Eltwise"
  bottom: "Eltwise4"
  bottom: "Convolution11"
  top: "Eltwise5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "PReLU11"
  type: "PReLU"
  bottom: "Eltwise5"
  top: "Eltwise5"
}
layer {
  name: "Convolution12"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.25
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm12"
  type: "BatchNorm"
  bottom: "Convolution12"
  top: "Convolution12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale12"
  type: "Scale"
  bottom: "Convolution12"
  top: "Convolution12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution13"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution13"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm13"
  type: "BatchNorm"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale13"
  type: "Scale"
  bottom: "Convolution13"
  top: "Convolution13"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "PReLU12"
  type: "PReLU"
  bottom: "Convolution13"
  top: "Convolution13"
}
layer {
  name: "Convolution14"
  type: "Convolution"
  bottom: "Convolution13"
  top: "Convolution14"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm14"
  type: "BatchNorm"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale14"
  type: "Scale"
  bottom: "Convolution14"
  top: "Convolution14"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise6"
  type: "Eltwise"
  bottom: "Convolution12"
  bottom: "Convolution14"
  top: "Eltwise6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "PReLU13"
  type: "PReLU"
  bottom: "Eltwise6"
  top: "Eltwise6"
}
layer {
  name: "Convolution15"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution15"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm15"
  type: "BatchNorm"
  bottom: "Convolution15"
  top: "Convolution15"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale15"
  type: "Scale"
  bottom: "Convolution15"
  top: "Convolution15"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "PReLU14"
  type: "PReLU"
  bottom: "Convolution15"
  top: "Convolution15"
}
layer {
  name: "Convolution16"
  type: "Convolution"
  bottom: "Convolution15"
  top: "Convolution16"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm16"
  type: "BatchNorm"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale16"
  type: "Scale"
  bottom: "Convolution16"
  top: "Convolution16"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise7"
  type: "Eltwise"
  bottom: "Eltwise6"
  bottom: "Convolution16"
  top: "Eltwise7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "PReLU15"
  type: "PReLU"
  bottom: "Eltwise7"
  top: "Eltwise7"
}
layer {
  name: "Convolution17"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution17"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm17"
  type: "BatchNorm"
  bottom: "Convolution17"
  top: "Convolution17"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale17"
  type: "Scale"
  bottom: "Convolution17"
  top: "Convolution17"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "PReLU16"
  type: "PReLU"
  bottom: "Convolution17"
  top: "Convolution17"
}
layer {
  name: "Convolution18"
  type: "Convolution"
  bottom: "Convolution17"
  top: "Convolution18"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm18"
  type: "BatchNorm"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale18"
  type: "Scale"
  bottom: "Convolution18"
  top: "Convolution18"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise8"
  type: "Eltwise"
  bottom: "Eltwise7"
  bottom: "Convolution18"
  top: "Eltwise8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "PReLU17"
  type: "PReLU"
  bottom: "Eltwise8"
  top: "Eltwise8"
}
layer {
  name: "Convolution19"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution19"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm19"
  type: "BatchNorm"
  bottom: "Convolution19"
  top: "Convolution19"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale19"
  type: "Scale"
  bottom: "Convolution19"
  top: "Convolution19"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "PReLU18"
  type: "PReLU"
  bottom: "Convolution19"
  top: "Convolution19"
}
layer {
  name: "Convolution20"
  type: "Convolution"
  bottom: "Convolution19"
  top: "Convolution20"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm20"
  type: "BatchNorm"
  bottom: "Convolution20"
  top: "Convolution20"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale20"
  type: "Scale"
  bottom: "Convolution20"
  top: "Convolution20"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise9"
  type: "Eltwise"
  bottom: "Eltwise8"
  bottom: "Convolution20"
  top: "Eltwise9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "PReLU19"
  type: "PReLU"
  bottom: "Eltwise9"
  top: "Eltwise9"
}
layer {
  name: "Convolution21"
  type: "Convolution"
  bottom: "Eltwise9"
  top: "Convolution21"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm21"
  type: "BatchNorm"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale21"
  type: "Scale"
  bottom: "Convolution21"
  top: "Convolution21"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "PReLU20"
  type: "PReLU"
  bottom: "Convolution21"
  top: "Convolution21"
}
layer {
  name: "Convolution22"
  type: "Convolution"
  bottom: "Convolution21"
  top: "Convolution22"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm22"
  type: "BatchNorm"
  bottom: "Convolution22"
  top: "Convolution22"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale22"
  type: "Scale"
  bottom: "Convolution22"
  top: "Convolution22"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise10"
  type: "Eltwise"
  bottom: "Eltwise9"
  bottom: "Convolution22"
  top: "Eltwise10"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "PReLU21"
  type: "PReLU"
  bottom: "Eltwise10"
  top: "Eltwise10"
}
layer {
  name: "Convolution23"
  type: "Convolution"
  bottom: "Eltwise10"
  top: "Convolution23"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.17677669
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm23"
  type: "BatchNorm"
  bottom: "Convolution23"
  top: "Convolution23"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale23"
  type: "Scale"
  bottom: "Convolution23"
  top: "Convolution23"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution24"
  type: "Convolution"
  bottom: "Eltwise10"
  top: "Convolution24"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm24"
  type: "BatchNorm"
  bottom: "Convolution24"
  top: "Convolution24"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale24"
  type: "Scale"
  bottom: "Convolution24"
  top: "Convolution24"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "PReLU22"
  type: "PReLU"
  bottom: "Convolution24"
  top: "Convolution24"
}
layer {
  name: "Convolution25"
  type: "Convolution"
  bottom: "Convolution24"
  top: "Convolution25"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm25"
  type: "BatchNorm"
  bottom: "Convolution25"
  top: "Convolution25"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale25"
  type: "Scale"
  bottom: "Convolution25"
  top: "Convolution25"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise11"
  type: "Eltwise"
  bottom: "Convolution23"
  bottom: "Convolution25"
  top: "Eltwise11"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "PReLU23"
  type: "PReLU"
  bottom: "Eltwise11"
  top: "Eltwise11"
}
layer {
  name: "Convolution26"
  type: "Convolution"
  bottom: "Eltwise11"
  top: "Convolution26"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm26"
  type: "BatchNorm"
  bottom: "Convolution26"
  top: "Convolution26"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale26"
  type: "Scale"
  bottom: "Convolution26"
  top: "Convolution26"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "PReLU24"
  type: "PReLU"
  bottom: "Convolution26"
  top: "Convolution26"
}
layer {
  name: "Convolution27"
  type: "Convolution"
  bottom: "Convolution26"
  top: "Convolution27"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm27"
  type: "BatchNorm"
  bottom: "Convolution27"
  top: "Convolution27"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale27"
  type: "Scale"
  bottom: "Convolution27"
  top: "Convolution27"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise12"
  type: "Eltwise"
  bottom: "Eltwise11"
  bottom: "Convolution27"
  top: "Eltwise12"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "PReLU25"
  type: "PReLU"
  bottom: "Eltwise12"
  top: "Eltwise12"
}
layer {
  name: "Convolution28"
  type: "Convolution"
  bottom: "Eltwise12"
  top: "Convolution28"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm28"
  type: "BatchNorm"
  bottom: "Convolution28"
  top: "Convolution28"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale28"
  type: "Scale"
  bottom: "Convolution28"
  top: "Convolution28"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "PReLU26"
  type: "PReLU"
  bottom: "Convolution28"
  top: "Convolution28"
}
layer {
  name: "Convolution29"
  type: "Convolution"
  bottom: "Convolution28"
  top: "Convolution29"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm29"
  type: "BatchNorm"
  bottom: "Convolution29"
  top: "Convolution29"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale29"
  type: "Scale"
  bottom: "Convolution29"
  top: "Convolution29"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise13"
  type: "Eltwise"
  bottom: "Eltwise12"
  bottom: "Convolution29"
  top: "Eltwise13"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "PReLU27"
  type: "PReLU"
  bottom: "Eltwise13"
  top: "Eltwise13"
}
layer {
  name: "Convolution30"
  type: "Convolution"
  bottom: "Eltwise13"
  top: "Convolution30"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm30"
  type: "BatchNorm"
  bottom: "Convolution30"
  top: "Convolution30"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale30"
  type: "Scale"
  bottom: "Convolution30"
  top: "Convolution30"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "PReLU28"
  type: "PReLU"
  bottom: "Convolution30"
  top: "Convolution30"
}
layer {
  name: "Convolution31"
  type: "Convolution"
  bottom: "Convolution30"
  top: "Convolution31"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm31"
  type: "BatchNorm"
  bottom: "Convolution31"
  top: "Convolution31"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale31"
  type: "Scale"
  bottom: "Convolution31"
  top: "Convolution31"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise14"
  type: "Eltwise"
  bottom: "Eltwise13"
  bottom: "Convolution31"
  top: "Eltwise14"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "PReLU29"
  type: "PReLU"
  bottom: "Eltwise14"
  top: "Eltwise14"
}
layer {
  name: "Convolution32"
  type: "Convolution"
  bottom: "Eltwise14"
  top: "Convolution32"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm32"
  type: "BatchNorm"
  b
I1006 20:10:34.231823  3817 layer_factory.hpp:77] Creating layer Data1
I1006 20:10:34.259585  3817 db_lmdb.cpp:35] Opened lmdb /home/x306/caffe/xn/PENLU/data/cifar10/cifar10_test_lmdb
I1006 20:10:34.259604  3817 net.cpp:84] Creating Layer Data1
I1006 20:10:34.259613  3817 net.cpp:380] Data1 -> Data1
I1006 20:10:34.259625  3817 net.cpp:380] Data1 -> Data2
I1006 20:10:34.259631  3817 data_transformer.cpp:25] Loading mean file from: /home/x306/caffe/xn/PENLU/data/cifar10/mean.binaryproto
I1006 20:10:34.259804  3817 data_layer.cpp:45] output data size: 100,3,32,32
I1006 20:10:34.264394  3817 net.cpp:122] Setting up Data1
I1006 20:10:34.264413  3817 net.cpp:129] Top shape: 100 3 32 32 (307200)
I1006 20:10:34.264417  3817 net.cpp:129] Top shape: 100 (100)
I1006 20:10:34.264420  3817 net.cpp:137] Memory required for data: 1229200
I1006 20:10:34.264425  3817 layer_factory.hpp:77] Creating layer Data2_Data1_1_split
I1006 20:10:34.264434  3817 net.cpp:84] Creating Layer Data2_Data1_1_split
I1006 20:10:34.264437  3817 net.cpp:406] Data2_Data1_1_split <- Data2
I1006 20:10:34.264442  3817 net.cpp:380] Data2_Data1_1_split -> Data2_Data1_1_split_0
I1006 20:10:34.264451  3817 net.cpp:380] Data2_Data1_1_split -> Data2_Data1_1_split_1
I1006 20:10:34.264511  3817 net.cpp:122] Setting up Data2_Data1_1_split
I1006 20:10:34.264518  3817 net.cpp:129] Top shape: 100 (100)
I1006 20:10:34.264519  3817 net.cpp:129] Top shape: 100 (100)
I1006 20:10:34.264521  3817 net.cpp:137] Memory required for data: 1230000
I1006 20:10:34.264524  3817 layer_factory.hpp:77] Creating layer Convolution1
I1006 20:10:34.264533  3817 net.cpp:84] Creating Layer Convolution1
I1006 20:10:34.264536  3817 net.cpp:406] Convolution1 <- Data1
I1006 20:10:34.264540  3817 net.cpp:380] Convolution1 -> Convolution1
I1006 20:10:34.265626  3817 net.cpp:122] Setting up Convolution1
I1006 20:10:34.265635  3817 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 20:10:34.265637  3817 net.cpp:137] Memory required for data: 7783600
I1006 20:10:34.265645  3817 layer_factory.hpp:77] Creating layer BatchNorm1
I1006 20:10:34.265651  3817 net.cpp:84] Creating Layer BatchNorm1
I1006 20:10:34.265655  3817 net.cpp:406] BatchNorm1 <- Convolution1
I1006 20:10:34.265657  3817 net.cpp:367] BatchNorm1 -> Convolution1 (in-place)
I1006 20:10:34.265795  3817 net.cpp:122] Setting up BatchNorm1
I1006 20:10:34.265799  3817 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 20:10:34.265801  3817 net.cpp:137] Memory required for data: 14337200
I1006 20:10:34.265808  3817 layer_factory.hpp:77] Creating layer Scale1
I1006 20:10:34.265815  3817 net.cpp:84] Creating Layer Scale1
I1006 20:10:34.265820  3817 net.cpp:406] Scale1 <- Convolution1
I1006 20:10:34.265822  3817 net.cpp:367] Scale1 -> Convolution1 (in-place)
I1006 20:10:34.265851  3817 layer_factory.hpp:77] Creating layer Scale1
I1006 20:10:34.265928  3817 net.cpp:122] Setting up Scale1
I1006 20:10:34.265933  3817 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 20:10:34.265936  3817 net.cpp:137] Memory required for data: 20890800
I1006 20:10:34.265940  3817 layer_factory.hpp:77] Creating layer PReLU1
I1006 20:10:34.265944  3817 net.cpp:84] Creating Layer PReLU1
I1006 20:10:34.265946  3817 net.cpp:406] PReLU1 <- Convolution1
I1006 20:10:34.265954  3817 net.cpp:367] PReLU1 -> Convolution1 (in-place)
I1006 20:10:34.266026  3817 net.cpp:122] Setting up PReLU1
I1006 20:10:34.266031  3817 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 20:10:34.266044  3817 net.cpp:137] Memory required for data: 27444400
I1006 20:10:34.266048  3817 layer_factory.hpp:77] Creating layer Convolution1_PReLU1_0_split
I1006 20:10:34.266052  3817 net.cpp:84] Creating Layer Convolution1_PReLU1_0_split
I1006 20:10:34.266053  3817 net.cpp:406] Convolution1_PReLU1_0_split <- Convolution1
I1006 20:10:34.266057  3817 net.cpp:380] Convolution1_PReLU1_0_split -> Convolution1_PReLU1_0_split_0
I1006 20:10:34.266060  3817 net.cpp:380] Convolution1_PReLU1_0_split -> Convolution1_PReLU1_0_split_1
I1006 20:10:34.266088  3817 net.cpp:122] Setting up Convolution1_PReLU1_0_split
I1006 20:10:34.266091  3817 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 20:10:34.266094  3817 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 20:10:34.266096  3817 net.cpp:137] Memory required for data: 40551600
I1006 20:10:34.266099  3817 layer_factory.hpp:77] Creating layer Convolution2
I1006 20:10:34.266105  3817 net.cpp:84] Creating Layer Convolution2
I1006 20:10:34.266108  3817 net.cpp:406] Convolution2 <- Convolution1_PReLU1_0_split_0
I1006 20:10:34.266113  3817 net.cpp:380] Convolution2 -> Convolution2
I1006 20:10:34.267156  3817 net.cpp:122] Setting up Convolution2
I1006 20:10:34.267184  3817 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 20:10:34.267187  3817 net.cpp:137] Memory required for data: 47105200
I1006 20:10:34.267194  3817 layer_factory.hpp:77] Creating layer BatchNorm2
I1006 20:10:34.267199  3817 net.cpp:84] Creating Layer BatchNorm2
I1006 20:10:34.267201  3817 net.cpp:406] BatchNorm2 <- Convolution2
I1006 20:10:34.267215  3817 net.cpp:367] BatchNorm2 -> Convolution2 (in-place)
I1006 20:10:34.267351  3817 net.cpp:122] Setting up BatchNorm2
I1006 20:10:34.267357  3817 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 20:10:34.267360  3817 net.cpp:137] Memory required for data: 53658800
I1006 20:10:34.267364  3817 layer_factory.hpp:77] Creating layer Scale2
I1006 20:10:34.267369  3817 net.cpp:84] Creating Layer Scale2
I1006 20:10:34.267371  3817 net.cpp:406] Scale2 <- Convolution2
I1006 20:10:34.267374  3817 net.cpp:367] Scale2 -> Convolution2 (in-place)
I1006 20:10:34.267402  3817 layer_factory.hpp:77] Creating layer Scale2
I1006 20:10:34.267479  3817 net.cpp:122] Setting up Scale2
I1006 20:10:34.267483  3817 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 20:10:34.267485  3817 net.cpp:137] Memory required for data: 60212400
I1006 20:10:34.267493  3817 layer_factory.hpp:77] Creating layer PReLU2
I1006 20:10:34.267498  3817 net.cpp:84] Creating Layer PReLU2
I1006 20:10:34.267503  3817 net.cpp:406] PReLU2 <- Convolution2
I1006 20:10:34.267505  3817 net.cpp:367] PReLU2 -> Convolution2 (in-place)
I1006 20:10:34.267575  3817 net.cpp:122] Setting up PReLU2
I1006 20:10:34.267578  3817 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 20:10:34.267580  3817 net.cpp:137] Memory required for data: 66766000
I1006 20:10:34.267583  3817 layer_factory.hpp:77] Creating layer Convolution3
I1006 20:10:34.267590  3817 net.cpp:84] Creating Layer Convolution3
I1006 20:10:34.267591  3817 net.cpp:406] Convolution3 <- Convolution2
I1006 20:10:34.267596  3817 net.cpp:380] Convolution3 -> Convolution3
I1006 20:10:34.268636  3817 net.cpp:122] Setting up Convolution3
I1006 20:10:34.268646  3817 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 20:10:34.268647  3817 net.cpp:137] Memory required for data: 73319600
I1006 20:10:34.268656  3817 layer_factory.hpp:77] Creating layer BatchNorm3
I1006 20:10:34.268662  3817 net.cpp:84] Creating Layer BatchNorm3
I1006 20:10:34.268664  3817 net.cpp:406] BatchNorm3 <- Convolution3
I1006 20:10:34.268669  3817 net.cpp:367] BatchNorm3 -> Convolution3 (in-place)
I1006 20:10:34.268805  3817 net.cpp:122] Setting up BatchNorm3
I1006 20:10:34.268808  3817 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 20:10:34.268810  3817 net.cpp:137] Memory required for data: 79873200
I1006 20:10:34.268815  3817 layer_factory.hpp:77] Creating layer Scale3
I1006 20:10:34.268820  3817 net.cpp:84] Creating Layer Scale3
I1006 20:10:34.268828  3817 net.cpp:406] Scale3 <- Convolution3
I1006 20:10:34.268832  3817 net.cpp:367] Scale3 -> Convolution3 (in-place)
I1006 20:10:34.268860  3817 layer_factory.hpp:77] Creating layer Scale3
I1006 20:10:34.268939  3817 net.cpp:122] Setting up Scale3
I1006 20:10:34.268944  3817 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 20:10:34.268946  3817 net.cpp:137] Memory required for data: 86426800
I1006 20:10:34.268949  3817 layer_factory.hpp:77] Creating layer Eltwise1
I1006 20:10:34.268954  3817 net.cpp:84] Creating Layer Eltwise1
I1006 20:10:34.268956  3817 net.cpp:406] Eltwise1 <- Convolution1_PReLU1_0_split_1
I1006 20:10:34.268959  3817 net.cpp:406] Eltwise1 <- Convolution3
I1006 20:10:34.268968  3817 net.cpp:380] Eltwise1 -> Eltwise1
I1006 20:10:34.268985  3817 net.cpp:122] Setting up Eltwise1
I1006 20:10:34.268990  3817 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 20:10:34.268991  3817 net.cpp:137] Memory required for data: 92980400
I1006 20:10:34.268993  3817 layer_factory.hpp:77] Creating layer PReLU3
I1006 20:10:34.268998  3817 net.cpp:84] Creating Layer PReLU3
I1006 20:10:34.269001  3817 net.cpp:406] PReLU3 <- Eltwise1
I1006 20:10:34.269003  3817 net.cpp:367] PReLU3 -> Eltwise1 (in-place)
I1006 20:10:34.269071  3817 net.cpp:122] Setting up PReLU3
I1006 20:10:34.269076  3817 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 20:10:34.269078  3817 net.cpp:137] Memory required for data: 99534000
I1006 20:10:34.269081  3817 layer_factory.hpp:77] Creating layer Eltwise1_PReLU3_0_split
I1006 20:10:34.269086  3817 net.cpp:84] Creating Layer Eltwise1_PReLU3_0_split
I1006 20:10:34.269089  3817 net.cpp:406] Eltwise1_PReLU3_0_split <- Eltwise1
I1006 20:10:34.269093  3817 net.cpp:380] Eltwise1_PReLU3_0_split -> Eltwise1_PReLU3_0_split_0
I1006 20:10:34.269095  3817 net.cpp:380] Eltwise1_PReLU3_0_split -> Eltwise1_PReLU3_0_split_1
I1006 20:10:34.269120  3817 net.cpp:122] Setting up Eltwise1_PReLU3_0_split
I1006 20:10:34.269124  3817 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 20:10:34.269127  3817 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 20:10:34.269130  3817 net.cpp:137] Memory required for data: 112641200
I1006 20:10:34.269132  3817 layer_factory.hpp:77] Creating layer Convolution4
I1006 20:10:34.269138  3817 net.cpp:84] Creating Layer Convolution4
I1006 20:10:34.269141  3817 net.cpp:406] Convolution4 <- Eltwise1_PReLU3_0_split_0
I1006 20:10:34.269146  3817 net.cpp:380] Convolution4 -> Convolution4
I1006 20:10:34.270207  3817 net.cpp:122] Setting up Convolution4
I1006 20:10:34.270218  3817 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 20:10:34.270221  3817 net.cpp:137] Memory required for data: 119194800
I1006 20:10:34.270226  3817 layer_factory.hpp:77] Creating layer BatchNorm4
I1006 20:10:34.270231  3817 net.cpp:84] Creating Layer BatchNorm4
I1006 20:10:34.270233  3817 net.cpp:406] BatchNorm4 <- Convolution4
I1006 20:10:34.270241  3817 net.cpp:367] BatchNorm4 -> Convolution4 (in-place)
I1006 20:10:34.270378  3817 net.cpp:122] Setting up BatchNorm4
I1006 20:10:34.270385  3817 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 20:10:34.270386  3817 net.cpp:137] Memory required for data: 125748400
I1006 20:10:34.270391  3817 layer_factory.hpp:77] Creating layer Scale4
I1006 20:10:34.270401  3817 net.cpp:84] Creating Layer Scale4
I1006 20:10:34.270403  3817 net.cpp:406] Scale4 <- Convolution4
I1006 20:10:34.270407  3817 net.cpp:367] Scale4 -> Convolution4 (in-place)
I1006 20:10:34.270437  3817 layer_factory.hpp:77] Creating layer Scale4
I1006 20:10:34.270515  3817 net.cpp:122] Setting up Scale4
I1006 20:10:34.270520  3817 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 20:10:34.270524  3817 net.cpp:137] Memory required for data: 132302000
I1006 20:10:34.270526  3817 layer_factory.hpp:77] Creating layer PReLU4
I1006 20:10:34.270530  3817 net.cpp:84] Creating Layer PReLU4
I1006 20:10:34.270532  3817 net.cpp:406] PReLU4 <- Convolution4
I1006 20:10:34.270536  3817 net.cpp:367] PReLU4 -> Convolution4 (in-place)
I1006 20:10:34.270603  3817 net.cpp:122] Setting up PReLU4
I1006 20:10:34.270614  3817 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 20:10:34.270617  3817 net.cpp:137] Memory required for data: 138855600
I1006 20:10:34.270623  3817 layer_factory.hpp:77] Creating layer Convolution5
I1006 20:10:34.270630  3817 net.cpp:84] Creating Layer Convolution5
I1006 20:10:34.270632  3817 net.cpp:406] Convolution5 <- Convolution4
I1006 20:10:34.270637  3817 net.cpp:380] Convolution5 -> Convolution5
I1006 20:10:34.271605  3817 net.cpp:122] Setting up Convolution5
I1006 20:10:34.271615  3817 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 20:10:34.271616  3817 net.cpp:137] Memory required for data: 145409200
I1006 20:10:34.271625  3817 layer_factory.hpp:77] Creating layer BatchNorm5
I1006 20:10:34.271630  3817 net.cpp:84] Creating Layer BatchNorm5
I1006 20:10:34.271632  3817 net.cpp:406] BatchNorm5 <- Convolution5
I1006 20:10:34.271636  3817 net.cpp:367] BatchNorm5 -> Convolution5 (in-place)
I1006 20:10:34.271773  3817 net.cpp:122] Setting up BatchNorm5
I1006 20:10:34.271777  3817 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 20:10:34.271780  3817 net.cpp:137] Memory required for data: 151962800
I1006 20:10:34.271785  3817 layer_factory.hpp:77] Creating layer Scale5
I1006 20:10:34.271790  3817 net.cpp:84] Creating Layer Scale5
I1006 20:10:34.271791  3817 net.cpp:406] Scale5 <- Convolution5
I1006 20:10:34.271795  3817 net.cpp:367] Scale5 -> Convolution5 (in-place)
I1006 20:10:34.271822  3817 layer_factory.hpp:77] Creating layer Scale5
I1006 20:10:34.271899  3817 net.cpp:122] Setting up Scale5
I1006 20:10:34.271903  3817 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 20:10:34.271905  3817 net.cpp:137] Memory required for data: 158516400
I1006 20:10:34.271909  3817 layer_factory.hpp:77] Creating layer Eltwise2
I1006 20:10:34.271914  3817 net.cpp:84] Creating Layer Eltwise2
I1006 20:10:34.271915  3817 net.cpp:406] Eltwise2 <- Eltwise1_PReLU3_0_split_1
I1006 20:10:34.271919  3817 net.cpp:406] Eltwise2 <- Convolution5
I1006 20:10:34.271921  3817 net.cpp:380] Eltwise2 -> Eltwise2
I1006 20:10:34.271937  3817 net.cpp:122] Setting up Eltwise2
I1006 20:10:34.271941  3817 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 20:10:34.271944  3817 net.cpp:137] Memory required for data: 165070000
I1006 20:10:34.271945  3817 layer_factory.hpp:77] Creating layer PReLU5
I1006 20:10:34.271950  3817 net.cpp:84] Creating Layer PReLU5
I1006 20:10:34.271951  3817 net.cpp:406] PReLU5 <- Eltwise2
I1006 20:10:34.271955  3817 net.cpp:367] PReLU5 -> Eltwise2 (in-place)
I1006 20:10:34.272020  3817 net.cpp:122] Setting up PReLU5
I1006 20:10:34.272025  3817 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 20:10:34.272027  3817 net.cpp:137] Memory required for data: 171623600
I1006 20:10:34.272030  3817 layer_factory.hpp:77] Creating layer Eltwise2_PReLU5_0_split
I1006 20:10:34.272033  3817 net.cpp:84] Creating Layer Eltwise2_PReLU5_0_split
I1006 20:10:34.272035  3817 net.cpp:406] Eltwise2_PReLU5_0_split <- Eltwise2
I1006 20:10:34.272038  3817 net.cpp:380] Eltwise2_PReLU5_0_split -> Eltwise2_PReLU5_0_split_0
I1006 20:10:34.272042  3817 net.cpp:380] Eltwise2_PReLU5_0_split -> Eltwise2_PReLU5_0_split_1
I1006 20:10:34.272068  3817 net.cpp:122] Setting up Eltwise2_PReLU5_0_split
I1006 20:10:34.272073  3817 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 20:10:34.272075  3817 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 20:10:34.272078  3817 net.cpp:137] Memory required for data: 184730800
I1006 20:10:34.272079  3817 layer_factory.hpp:77] Creating layer Convolution6
I1006 20:10:34.272086  3817 net.cpp:84] Creating Layer Convolution6
I1006 20:10:34.272089  3817 net.cpp:406] Convolution6 <- Eltwise2_PReLU5_0_split_0
I1006 20:10:34.272094  3817 net.cpp:380] Convolution6 -> Convolution6
I1006 20:10:34.273016  3817 net.cpp:122] Setting up Convolution6
I1006 20:10:34.273025  3817 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 20:10:34.273027  3817 net.cpp:137] Memory required for data: 191284400
I1006 20:10:34.273032  3817 layer_factory.hpp:77] Creating layer BatchNorm6
I1006 20:10:34.273036  3817 net.cpp:84] Creating Layer BatchNorm6
I1006 20:10:34.273046  3817 net.cpp:406] BatchNorm6 <- Convolution6
I1006 20:10:34.273051  3817 net.cpp:367] BatchNorm6 -> Convolution6 (in-place)
I1006 20:10:34.273192  3817 net.cpp:122] Setting up BatchNorm6
I1006 20:10:34.273196  3817 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 20:10:34.273198  3817 net.cpp:137] Memory required for data: 197838000
I1006 20:10:34.273203  3817 layer_factory.hpp:77] Creating layer Scale6
I1006 20:10:34.273207  3817 net.cpp:84] Creating Layer Scale6
I1006 20:10:34.273210  3817 net.cpp:406] Scale6 <- Convolution6
I1006 20:10:34.289997  3817 net.cpp:367] Scale6 -> Convolution6 (in-place)
I1006 20:10:34.290048  3817 layer_factory.hpp:77] Creating layer Scale6
I1006 20:10:34.290140  3817 net.cpp:122] Setting up Scale6
I1006 20:10:34.290146  3817 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 20:10:34.290148  3817 net.cpp:137] Memory required for data: 204391600
I1006 20:10:34.290153  3817 layer_factory.hpp:77] Creating layer PReLU6
I1006 20:10:34.290158  3817 net.cpp:84] Creating Layer PReLU6
I1006 20:10:34.290159  3817 net.cpp:406] PReLU6 <- Convolution6
I1006 20:10:34.290163  3817 net.cpp:367] PReLU6 -> Convolution6 (in-place)
I1006 20:10:34.290238  3817 net.cpp:122] Setting up PReLU6
I1006 20:10:34.290242  3817 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 20:10:34.290246  3817 net.cpp:137] Memory required for data: 210945200
I1006 20:10:34.290248  3817 layer_factory.hpp:77] Creating layer Convolution7
I1006 20:10:34.290256  3817 net.cpp:84] Creating Layer Convolution7
I1006 20:10:34.290257  3817 net.cpp:406] Convolution7 <- Convolution6
I1006 20:10:34.290262  3817 net.cpp:380] Convolution7 -> Convolution7
I1006 20:10:34.291273  3817 net.cpp:122] Setting up Convolution7
I1006 20:10:34.291282  3817 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 20:10:34.291285  3817 net.cpp:137] Memory required for data: 217498800
I1006 20:10:34.291290  3817 layer_factory.hpp:77] Creating layer BatchNorm7
I1006 20:10:34.291299  3817 net.cpp:84] Creating Layer BatchNorm7
I1006 20:10:34.291302  3817 net.cpp:406] BatchNorm7 <- Convolution7
I1006 20:10:34.291306  3817 net.cpp:367] BatchNorm7 -> Convolution7 (in-place)
I1006 20:10:34.291476  3817 net.cpp:122] Setting up BatchNorm7
I1006 20:10:34.291481  3817 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 20:10:34.291482  3817 net.cpp:137] Memory required for data: 224052400
I1006 20:10:34.291486  3817 layer_factory.hpp:77] Creating layer Scale7
I1006 20:10:34.291491  3817 net.cpp:84] Creating Layer Scale7
I1006 20:10:34.291493  3817 net.cpp:406] Scale7 <- Convolution7
I1006 20:10:34.291496  3817 net.cpp:367] Scale7 -> Convolution7 (in-place)
I1006 20:10:34.291525  3817 layer_factory.hpp:77] Creating layer Scale7
I1006 20:10:34.291638  3817 net.cpp:122] Setting up Scale7
I1006 20:10:34.291648  3817 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 20:10:34.291652  3817 net.cpp:137] Memory required for data: 230606000
I1006 20:10:34.291659  3817 layer_factory.hpp:77] Creating layer Eltwise3
I1006 20:10:34.291666  3817 net.cpp:84] Creating Layer Eltwise3
I1006 20:10:34.291671  3817 net.cpp:406] Eltwise3 <- Eltwise2_PReLU5_0_split_1
I1006 20:10:34.291676  3817 net.cpp:406] Eltwise3 <- Convolution7
I1006 20:10:34.291682  3817 net.cpp:380] Eltwise3 -> Eltwise3
I1006 20:10:34.291710  3817 net.cpp:122] Setting up Eltwise3
I1006 20:10:34.291716  3817 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 20:10:34.291718  3817 net.cpp:137] Memory required for data: 237159600
I1006 20:10:34.291721  3817 layer_factory.hpp:77] Creating layer PReLU7
I1006 20:10:34.291724  3817 net.cpp:84] Creating Layer PReLU7
I1006 20:10:34.291728  3817 net.cpp:406] PReLU7 <- Eltwise3
I1006 20:10:34.291731  3817 net.cpp:367] PReLU7 -> Eltwise3 (in-place)
I1006 20:10:34.291846  3817 net.cpp:122] Setting up PReLU7
I1006 20:10:34.291851  3817 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 20:10:34.291854  3817 net.cpp:137] Memory required for data: 243713200
I1006 20:10:34.291857  3817 layer_factory.hpp:77] Creating layer Eltwise3_PReLU7_0_split
I1006 20:10:34.291867  3817 net.cpp:84] Creating Layer Eltwise3_PReLU7_0_split
I1006 20:10:34.291870  3817 net.cpp:406] Eltwise3_PReLU7_0_split <- Eltwise3
I1006 20:10:34.291873  3817 net.cpp:380] Eltwise3_PReLU7_0_split -> Eltwise3_PReLU7_0_split_0
I1006 20:10:34.291878  3817 net.cpp:380] Eltwise3_PReLU7_0_split -> Eltwise3_PReLU7_0_split_1
I1006 20:10:34.291905  3817 net.cpp:122] Setting up Eltwise3_PReLU7_0_split
I1006 20:10:34.291909  3817 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 20:10:34.291913  3817 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 20:10:34.291914  3817 net.cpp:137] Memory required for data: 256820400
I1006 20:10:34.291918  3817 layer_factory.hpp:77] Creating layer Convolution8
I1006 20:10:34.291924  3817 net.cpp:84] Creating Layer Convolution8
I1006 20:10:34.291926  3817 net.cpp:406] Convolution8 <- Eltwise3_PReLU7_0_split_0
I1006 20:10:34.291930  3817 net.cpp:380] Convolution8 -> Convolution8
I1006 20:10:34.292924  3817 net.cpp:122] Setting up Convolution8
I1006 20:10:34.292933  3817 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 20:10:34.292937  3817 net.cpp:137] Memory required for data: 263374000
I1006 20:10:34.292940  3817 layer_factory.hpp:77] Creating layer BatchNorm8
I1006 20:10:34.292945  3817 net.cpp:84] Creating Layer BatchNorm8
I1006 20:10:34.292948  3817 net.cpp:406] BatchNorm8 <- Convolution8
I1006 20:10:34.292953  3817 net.cpp:367] BatchNorm8 -> Convolution8 (in-place)
I1006 20:10:34.293095  3817 net.cpp:122] Setting up BatchNorm8
I1006 20:10:34.293100  3817 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 20:10:34.293102  3817 net.cpp:137] Memory required for data: 269927600
I1006 20:10:34.293107  3817 layer_factory.hpp:77] Creating layer Scale8
I1006 20:10:34.293112  3817 net.cpp:84] Creating Layer Scale8
I1006 20:10:34.293113  3817 net.cpp:406] Scale8 <- Convolution8
I1006 20:10:34.293117  3817 net.cpp:367] Scale8 -> Convolution8 (in-place)
I1006 20:10:34.293145  3817 layer_factory.hpp:77] Creating layer Scale8
I1006 20:10:34.293223  3817 net.cpp:122] Setting up Scale8
I1006 20:10:34.293227  3817 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 20:10:34.293229  3817 net.cpp:137] Memory required for data: 276481200
I1006 20:10:34.293233  3817 layer_factory.hpp:77] Creating layer PReLU8
I1006 20:10:34.293237  3817 net.cpp:84] Creating Layer PReLU8
I1006 20:10:34.293241  3817 net.cpp:406] PReLU8 <- Convolution8
I1006 20:10:34.293242  3817 net.cpp:367] PReLU8 -> Convolution8 (in-place)
I1006 20:10:34.293311  3817 net.cpp:122] Setting up PReLU8
I1006 20:10:34.293315  3817 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 20:10:34.293318  3817 net.cpp:137] Memory required for data: 283034800
I1006 20:10:34.293320  3817 layer_factory.hpp:77] Creating layer Convolution9
I1006 20:10:34.293328  3817 net.cpp:84] Creating Layer Convolution9
I1006 20:10:34.293329  3817 net.cpp:406] Convolution9 <- Convolution8
I1006 20:10:34.293334  3817 net.cpp:380] Convolution9 -> Convolution9
I1006 20:10:34.294832  3817 net.cpp:122] Setting up Convolution9
I1006 20:10:34.294842  3817 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 20:10:34.294845  3817 net.cpp:137] Memory required for data: 289588400
I1006 20:10:34.294857  3817 layer_factory.hpp:77] Creating layer BatchNorm9
I1006 20:10:34.294862  3817 net.cpp:84] Creating Layer BatchNorm9
I1006 20:10:34.294864  3817 net.cpp:406] BatchNorm9 <- Convolution9
I1006 20:10:34.294868  3817 net.cpp:367] BatchNorm9 -> Convolution9 (in-place)
I1006 20:10:34.295013  3817 net.cpp:122] Setting up BatchNorm9
I1006 20:10:34.295018  3817 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 20:10:34.295020  3817 net.cpp:137] Memory required for data: 296142000
I1006 20:10:34.295024  3817 layer_factory.hpp:77] Creating layer Scale9
I1006 20:10:34.295028  3817 net.cpp:84] Creating Layer Scale9
I1006 20:10:34.295032  3817 net.cpp:406] Scale9 <- Convolution9
I1006 20:10:34.295034  3817 net.cpp:367] Scale9 -> Convolution9 (in-place)
I1006 20:10:34.295063  3817 layer_factory.hpp:77] Creating layer Scale9
I1006 20:10:34.295150  3817 net.cpp:122] Setting up Scale9
I1006 20:10:34.295155  3817 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 20:10:34.295156  3817 net.cpp:137] Memory required for data: 302695600
I1006 20:10:34.295161  3817 layer_factory.hpp:77] Creating layer Eltwise4
I1006 20:10:34.295168  3817 net.cpp:84] Creating Layer Eltwise4
I1006 20:10:34.295172  3817 net.cpp:406] Eltwise4 <- Eltwise3_PReLU7_0_split_1
I1006 20:10:34.295176  3817 net.cpp:406] Eltwise4 <- Convolution9
I1006 20:10:34.295179  3817 net.cpp:380] Eltwise4 -> Eltwise4
I1006 20:10:34.295197  3817 net.cpp:122] Setting up Eltwise4
I1006 20:10:34.295199  3817 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 20:10:34.295202  3817 net.cpp:137] Memory required for data: 309249200
I1006 20:10:34.295203  3817 layer_factory.hpp:77] Creating layer PReLU9
I1006 20:10:34.295209  3817 net.cpp:84] Creating Layer PReLU9
I1006 20:10:34.295212  3817 net.cpp:406] PReLU9 <- Eltwise4
I1006 20:10:34.295217  3817 net.cpp:367] PReLU9 -> Eltwise4 (in-place)
I1006 20:10:34.295286  3817 net.cpp:122] Setting up PReLU9
I1006 20:10:34.295291  3817 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 20:10:34.295294  3817 net.cpp:137] Memory required for data: 315802800
I1006 20:10:34.295296  3817 layer_factory.hpp:77] Creating layer Eltwise4_PReLU9_0_split
I1006 20:10:34.295300  3817 net.cpp:84] Creating Layer Eltwise4_PReLU9_0_split
I1006 20:10:34.295303  3817 net.cpp:406] Eltwise4_PReLU9_0_split <- Eltwise4
I1006 20:10:34.295306  3817 net.cpp:380] Eltwise4_PReLU9_0_split -> Eltwise4_PReLU9_0_split_0
I1006 20:10:34.295310  3817 net.cpp:380] Eltwise4_PReLU9_0_split -> Eltwise4_PReLU9_0_split_1
I1006 20:10:34.295336  3817 net.cpp:122] Setting up Eltwise4_PReLU9_0_split
I1006 20:10:34.295339  3817 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 20:10:34.295342  3817 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 20:10:34.295344  3817 net.cpp:137] Memory required for data: 328910000
I1006 20:10:34.295346  3817 layer_factory.hpp:77] Creating layer Convolution10
I1006 20:10:34.295352  3817 net.cpp:84] Creating Layer Convolution10
I1006 20:10:34.295356  3817 net.cpp:406] Convolution10 <- Eltwise4_PReLU9_0_split_0
I1006 20:10:34.295359  3817 net.cpp:380] Convolution10 -> Convolution10
I1006 20:10:34.295953  3817 net.cpp:122] Setting up Convolution10
I1006 20:10:34.295961  3817 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 20:10:34.295964  3817 net.cpp:137] Memory required for data: 335463600
I1006 20:10:34.295969  3817 layer_factory.hpp:77] Creating layer BatchNorm10
I1006 20:10:34.295972  3817 net.cpp:84] Creating Layer BatchNorm10
I1006 20:10:34.295974  3817 net.cpp:406] BatchNorm10 <- Convolution10
I1006 20:10:34.295979  3817 net.cpp:367] BatchNorm10 -> Convolution10 (in-place)
I1006 20:10:34.296124  3817 net.cpp:122] Setting up BatchNorm10
I1006 20:10:34.296129  3817 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 20:10:34.296131  3817 net.cpp:137] Memory required for data: 342017200
I1006 20:10:34.296135  3817 layer_factory.hpp:77] Creating layer Scale10
I1006 20:10:34.296139  3817 net.cpp:84] Creating Layer Scale10
I1006 20:10:34.296141  3817 net.cpp:406] Scale10 <- Convolution10
I1006 20:10:34.296144  3817 net.cpp:367] Scale10 -> Convolution10 (in-place)
I1006 20:10:34.296172  3817 layer_factory.hpp:77] Creating layer Scale10
I1006 20:10:34.296252  3817 net.cpp:122] Setting up Scale10
I1006 20:10:34.296257  3817 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 20:10:34.296258  3817 net.cpp:137] Memory required for data: 348570800
I1006 20:10:34.296262  3817 layer_factory.hpp:77] Creating layer PReLU10
I1006 20:10:34.296265  3817 net.cpp:84] Creating Layer PReLU10
I1006 20:10:34.296267  3817 net.cpp:406] PReLU10 <- Convolution10
I1006 20:10:34.296272  3817 net.cpp:367] PReLU10 -> Convolution10 (in-place)
I1006 20:10:34.296340  3817 net.cpp:122] Setting up PReLU10
I1006 20:10:34.296344  3817 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 20:10:34.296346  3817 net.cpp:137] Memory required for data: 355124400
I1006 20:10:34.296350  3817 layer_factory.hpp:77] Creating layer Convolution11
I1006 20:10:34.296362  3817 net.cpp:84] Creating Layer Convolution11
I1006 20:10:34.296365  3817 net.cpp:406] Convolution11 <- Convolution10
I1006 20:10:34.296370  3817 net.cpp:380] Convolution11 -> Convolution11
I1006 20:10:34.297291  3817 net.cpp:122] Setting up Convolution11
I1006 20:10:34.297300  3817 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 20:10:34.297303  3817 net.cpp:137] Memory required for data: 361678000
I1006 20:10:34.297307  3817 layer_factory.hpp:77] Creating layer BatchNorm11
I1006 20:10:34.297312  3817 net.cpp:84] Creating Layer BatchNorm11
I1006 20:10:34.297315  3817 net.cpp:406] BatchNorm11 <- Convolution11
I1006 20:10:34.297319  3817 net.cpp:367] BatchNorm11 -> Convolution11 (in-place)
I1006 20:10:34.297464  3817 net.cpp:122] Setting up BatchNorm11
I1006 20:10:34.297469  3817 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 20:10:34.297472  3817 net.cpp:137] Memory required for data: 368231600
I1006 20:10:34.297477  3817 layer_factory.hpp:77] Creating layer Scale11
I1006 20:10:34.297480  3817 net.cpp:84] Creating Layer Scale11
I1006 20:10:34.297483  3817 net.cpp:406] Scale11 <- Convolution11
I1006 20:10:34.297487  3817 net.cpp:367] Scale11 -> Convolution11 (in-place)
I1006 20:10:34.297515  3817 layer_factory.hpp:77] Creating layer Scale11
I1006 20:10:34.297595  3817 net.cpp:122] Setting up Scale11
I1006 20:10:34.297600  3817 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 20:10:34.297601  3817 net.cpp:137] Memory required for data: 374785200
I1006 20:10:34.297605  3817 layer_factory.hpp:77] Creating layer Eltwise5
I1006 20:10:34.297608  3817 net.cpp:84] Creating Layer Eltwise5
I1006 20:10:34.297611  3817 net.cpp:406] Eltwise5 <- Eltwise4_PReLU9_0_split_1
I1006 20:10:34.297614  3817 net.cpp:406] Eltwise5 <- Convolution11
I1006 20:10:34.297618  3817 net.cpp:380] Eltwise5 -> Eltwise5
I1006 20:10:34.297634  3817 net.cpp:122] Setting up Eltwise5
I1006 20:10:34.297639  3817 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 20:10:34.297641  3817 net.cpp:137] Memory required for data: 381338800
I1006 20:10:34.297643  3817 layer_factory.hpp:77] Creating layer PReLU11
I1006 20:10:34.297646  3817 net.cpp:84] Creating Layer PReLU11
I1006 20:10:34.297648  3817 net.cpp:406] PReLU11 <- Eltwise5
I1006 20:10:34.297652  3817 net.cpp:367] PReLU11 -> Eltwise5 (in-place)
I1006 20:10:34.297721  3817 net.cpp:122] Setting up PReLU11
I1006 20:10:34.297725  3817 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 20:10:34.297727  3817 net.cpp:137] Memory required for data: 387892400
I1006 20:10:34.297730  3817 layer_factory.hpp:77] Creating layer Eltwise5_PReLU11_0_split
I1006 20:10:34.297734  3817 net.cpp:84] Creating Layer Eltwise5_PReLU11_0_split
I1006 20:10:34.297736  3817 net.cpp:406] Eltwise5_PReLU11_0_split <- Eltwise5
I1006 20:10:34.297739  3817 net.cpp:380] Eltwise5_PReLU11_0_split -> Eltwise5_PReLU11_0_split_0
I1006 20:10:34.297744  3817 net.cpp:380] Eltwise5_PReLU11_0_split -> Eltwise5_PReLU11_0_split_1
I1006 20:10:34.297767  3817 net.cpp:122] Setting up Eltwise5_PReLU11_0_split
I1006 20:10:34.297771  3817 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 20:10:34.297775  3817 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 20:10:34.297776  3817 net.cpp:137] Memory required for data: 400999600
I1006 20:10:34.297778  3817 layer_factory.hpp:77] Creating layer Convolution12
I1006 20:10:34.297785  3817 net.cpp:84] Creating Layer Convolution12
I1006 20:10:34.297787  3817 net.cpp:406] Convolution12 <- Eltwise5_PReLU11_0_split_0
I1006 20:10:34.297791  3817 net.cpp:380] Convolution12 -> Convolution12
I1006 20:10:34.298691  3817 net.cpp:122] Setting up Convolution12
I1006 20:10:34.298699  3817 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 20:10:34.298702  3817 net.cpp:137] Memory required for data: 404276400
I1006 20:10:34.298707  3817 layer_factory.hpp:77] Creating layer BatchNorm12
I1006 20:10:34.298712  3817 net.cpp:84] Creating Layer BatchNorm12
I1006 20:10:34.298714  3817 net.cpp:406] BatchNorm12 <- Convolution12
I1006 20:10:34.298718  3817 net.cpp:367] BatchNorm12 -> Convolution12 (in-place)
I1006 20:10:34.298866  3817 net.cpp:122] Setting up BatchNorm12
I1006 20:10:34.298871  3817 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 20:10:34.298872  3817 net.cpp:137] Memory required for data: 407553200
I1006 20:10:34.298877  3817 layer_factory.hpp:77] Creating layer Scale12
I1006 20:10:34.298882  3817 net.cpp:84] Creating Layer Scale12
I1006 20:10:34.298884  3817 net.cpp:406] Scale12 <- Convolution12
I1006 20:10:34.298887  3817 net.cpp:367] Scale12 -> Convolution12 (in-place)
I1006 20:10:34.320646  3817 layer_factory.hpp:77] Creating layer Scale12
I1006 20:10:34.320777  3817 net.cpp:122] Setting up Scale12
I1006 20:10:34.320786  3817 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 20:10:34.320791  3817 net.cpp:137] Memory required for data: 410830000
I1006 20:10:34.320797  3817 layer_factory.hpp:77] Creating layer Convolution13
I1006 20:10:34.320807  3817 net.cpp:84] Creating Layer Convolution13
I1006 20:10:34.320812  3817 net.cpp:406] Convolution13 <- Eltwise5_PReLU11_0_split_1
I1006 20:10:34.320821  3817 net.cpp:380] Convolution13 -> Convolution13
I1006 20:10:34.321893  3817 net.cpp:122] Setting up Convolution13
I1006 20:10:34.321904  3817 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 20:10:34.321907  3817 net.cpp:137] Memory required for data: 414106800
I1006 20:10:34.321912  3817 layer_factory.hpp:77] Creating layer BatchNorm13
I1006 20:10:34.321916  3817 net.cpp:84] Creating Layer BatchNorm13
I1006 20:10:34.321919  3817 net.cpp:406] BatchNorm13 <- Convolution13
I1006 20:10:34.321925  3817 net.cpp:367] BatchNorm13 -> Convolution13 (in-place)
I1006 20:10:34.322090  3817 net.cpp:122] Setting up BatchNorm13
I1006 20:10:34.322098  3817 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 20:10:34.322101  3817 net.cpp:137] Memory required for data: 417383600
I1006 20:10:34.322110  3817 layer_factory.hpp:77] Creating layer Scale13
I1006 20:10:34.322118  3817 net.cpp:84] Creating Layer Scale13
I1006 20:10:34.322130  3817 net.cpp:406] Scale13 <- Convolution13
I1006 20:10:34.322136  3817 net.cpp:367] Scale13 -> Convolution13 (in-place)
I1006 20:10:34.322193  3817 layer_factory.hpp:77] Creating layer Scale13
I1006 20:10:34.322316  3817 net.cpp:122] Setting up Scale13
I1006 20:10:34.322331  3817 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 20:10:34.322335  3817 net.cpp:137] Memory required for data: 420660400
I1006 20:10:34.322338  3817 layer_factory.hpp:77] Creating layer PReLU12
I1006 20:10:34.322342  3817 net.cpp:84] Creating Layer PReLU12
I1006 20:10:34.322345  3817 net.cpp:406] PReLU12 <- Convolution13
I1006 20:10:34.322348  3817 net.cpp:367] PReLU12 -> Convolution13 (in-place)
I1006 20:10:34.322417  3817 net.cpp:122] Setting up PReLU12
I1006 20:10:34.322420  3817 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 20:10:34.322422  3817 net.cpp:137] Memory required for data: 423937200
I1006 20:10:34.322425  3817 layer_factory.hpp:77] Creating layer Convolution14
I1006 20:10:34.322435  3817 net.cpp:84] Creating Layer Convolution14
I1006 20:10:34.322438  3817 net.cpp:406] Convolution14 <- Convolution13
I1006 20:10:34.322443  3817 net.cpp:380] Convolution14 -> Convolution14
I1006 20:10:34.323688  3817 net.cpp:122] Setting up Convolution14
I1006 20:10:34.323698  3817 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 20:10:34.323700  3817 net.cpp:137] Memory required for data: 427214000
I1006 20:10:34.323705  3817 layer_factory.hpp:77] Creating layer BatchNorm14
I1006 20:10:34.323710  3817 net.cpp:84] Creating Layer BatchNorm14
I1006 20:10:34.323714  3817 net.cpp:406] BatchNorm14 <- Convolution14
I1006 20:10:34.323719  3817 net.cpp:367] BatchNorm14 -> Convolution14 (in-place)
I1006 20:10:34.323873  3817 net.cpp:122] Setting up BatchNorm14
I1006 20:10:34.323882  3817 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 20:10:34.323886  3817 net.cpp:137] Memory required for data: 430490800
I1006 20:10:34.323894  3817 layer_factory.hpp:77] Creating layer Scale14
I1006 20:10:34.323900  3817 net.cpp:84] Creating Layer Scale14
I1006 20:10:34.323905  3817 net.cpp:406] Scale14 <- Convolution14
I1006 20:10:34.323920  3817 net.cpp:367] Scale14 -> Convolution14 (in-place)
I1006 20:10:34.323966  3817 layer_factory.hpp:77] Creating layer Scale14
I1006 20:10:34.324095  3817 net.cpp:122] Setting up Scale14
I1006 20:10:34.324105  3817 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 20:10:34.324110  3817 net.cpp:137] Memory required for data: 433767600
I1006 20:10:34.324117  3817 layer_factory.hpp:77] Creating layer Eltwise6
I1006 20:10:34.324124  3817 net.cpp:84] Creating Layer Eltwise6
I1006 20:10:34.324129  3817 net.cpp:406] Eltwise6 <- Convolution12
I1006 20:10:34.324134  3817 net.cpp:406] Eltwise6 <- Convolution14
I1006 20:10:34.324142  3817 net.cpp:380] Eltwise6 -> Eltwise6
I1006 20:10:34.324167  3817 net.cpp:122] Setting up Eltwise6
I1006 20:10:34.324175  3817 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 20:10:34.324179  3817 net.cpp:137] Memory required for data: 437044400
I1006 20:10:34.324182  3817 layer_factory.hpp:77] Creating layer PReLU13
I1006 20:10:34.324190  3817 net.cpp:84] Creating Layer PReLU13
I1006 20:10:34.324194  3817 net.cpp:406] PReLU13 <- Eltwise6
I1006 20:10:34.324199  3817 net.cpp:367] PReLU13 -> Eltwise6 (in-place)
I1006 20:10:34.324306  3817 net.cpp:122] Setting up PReLU13
I1006 20:10:34.324316  3817 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 20:10:34.324321  3817 net.cpp:137] Memory required for data: 440321200
I1006 20:10:34.324326  3817 layer_factory.hpp:77] Creating layer Eltwise6_PReLU13_0_split
I1006 20:10:34.324331  3817 net.cpp:84] Creating Layer Eltwise6_PReLU13_0_split
I1006 20:10:34.324335  3817 net.cpp:406] Eltwise6_PReLU13_0_split <- Eltwise6
I1006 20:10:34.324342  3817 net.cpp:380] Eltwise6_PReLU13_0_split -> Eltwise6_PReLU13_0_split_0
I1006 20:10:34.324348  3817 net.cpp:380] Eltwise6_PReLU13_0_split -> Eltwise6_PReLU13_0_split_1
I1006 20:10:34.324394  3817 net.cpp:122] Setting up Eltwise6_PReLU13_0_split
I1006 20:10:34.324404  3817 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 20:10:34.324409  3817 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 20:10:34.324411  3817 net.cpp:137] Memory required for data: 446874800
I1006 20:10:34.324415  3817 layer_factory.hpp:77] Creating layer Convolution15
I1006 20:10:34.324427  3817 net.cpp:84] Creating Layer Convolution15
I1006 20:10:34.324432  3817 net.cpp:406] Convolution15 <- Eltwise6_PReLU13_0_split_0
I1006 20:10:34.324439  3817 net.cpp:380] Convolution15 -> Convolution15
I1006 20:10:34.325893  3817 net.cpp:122] Setting up Convolution15
I1006 20:10:34.325902  3817 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 20:10:34.325906  3817 net.cpp:137] Memory required for data: 450151600
I1006 20:10:34.325909  3817 layer_factory.hpp:77] Creating layer BatchNorm15
I1006 20:10:34.325915  3817 net.cpp:84] Creating Layer BatchNorm15
I1006 20:10:34.325918  3817 net.cpp:406] BatchNorm15 <- Convolution15
I1006 20:10:34.325922  3817 net.cpp:367] BatchNorm15 -> Convolution15 (in-place)
I1006 20:10:34.326068  3817 net.cpp:122] Setting up BatchNorm15
I1006 20:10:34.326072  3817 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 20:10:34.326074  3817 net.cpp:137] Memory required for data: 453428400
I1006 20:10:34.326079  3817 layer_factory.hpp:77] Creating layer Scale15
I1006 20:10:34.326083  3817 net.cpp:84] Creating Layer Scale15
I1006 20:10:34.326086  3817 net.cpp:406] Scale15 <- Convolution15
I1006 20:10:34.326089  3817 net.cpp:367] Scale15 -> Convolution15 (in-place)
I1006 20:10:34.326118  3817 layer_factory.hpp:77] Creating layer Scale15
I1006 20:10:34.326200  3817 net.cpp:122] Setting up Scale15
I1006 20:10:34.326205  3817 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 20:10:34.326206  3817 net.cpp:137] Memory required for data: 456705200
I1006 20:10:34.326210  3817 layer_factory.hpp:77] Creating layer PReLU14
I1006 20:10:34.326215  3817 net.cpp:84] Creating Layer PReLU14
I1006 20:10:34.326217  3817 net.cpp:406] PReLU14 <- Convolution15
I1006 20:10:34.326220  3817 net.cpp:367] PReLU14 -> Convolution15 (in-place)
I1006 20:10:34.326287  3817 net.cpp:122] Setting up PReLU14
I1006 20:10:34.326298  3817 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 20:10:34.326300  3817 net.cpp:137] Memory required for data: 459982000
I1006 20:10:34.326304  3817 layer_factory.hpp:77] Creating layer Convolution16
I1006 20:10:34.326310  3817 net.cpp:84] Creating Layer Convolution16
I1006 20:10:34.326313  3817 net.cpp:406] Convolution16 <- Convolution15
I1006 20:10:34.326318  3817 net.cpp:380] Convolution16 -> Convolution16
I1006 20:10:34.327962  3817 net.cpp:122] Setting up Convolution16
I1006 20:10:34.327972  3817 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 20:10:34.327975  3817 net.cpp:137] Memory required for data: 463258800
I1006 20:10:34.327980  3817 layer_factory.hpp:77] Creating layer BatchNorm16
I1006 20:10:34.327985  3817 net.cpp:84] Creating Layer BatchNorm16
I1006 20:10:34.327987  3817 net.cpp:406] BatchNorm16 <- Convolution16
I1006 20:10:34.327991  3817 net.cpp:367] BatchNorm16 -> Convolution16 (in-place)
I1006 20:10:34.328135  3817 net.cpp:122] Setting up BatchNorm16
I1006 20:10:34.328138  3817 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 20:10:34.328140  3817 net.cpp:137] Memory required for data: 466535600
I1006 20:10:34.328145  3817 layer_factory.hpp:77] Creating layer Scale16
I1006 20:10:34.328150  3817 net.cpp:84] Creating Layer Scale16
I1006 20:10:34.328151  3817 net.cpp:406] Scale16 <- Convolution16
I1006 20:10:34.328155  3817 net.cpp:367] Scale16 -> Convolution16 (in-place)
I1006 20:10:34.328183  3817 layer_factory.hpp:77] Creating layer Scale16
I1006 20:10:34.328264  3817 net.cpp:122] Setting up Scale16
I1006 20:10:34.328269  3817 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 20:10:34.328270  3817 net.cpp:137] Memory required for data: 469812400
I1006 20:10:34.328274  3817 layer_factory.hpp:77] Creating layer Eltwise7
I1006 20:10:34.328279  3817 net.cpp:84] Creating Layer Eltwise7
I1006 20:10:34.328282  3817 net.cpp:406] Eltwise7 <- Eltwise6_PReLU13_0_split_1
I1006 20:10:34.328285  3817 net.cpp:406] Eltwise7 <- Convolution16
I1006 20:10:34.328289  3817 net.cpp:380] Eltwise7 -> Eltwise7
I1006 20:10:34.328301  3817 net.cpp:122] Setting up Eltwise7
I1006 20:10:34.328305  3817 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 20:10:34.328307  3817 net.cpp:137] Memory required for data: 473089200
I1006 20:10:34.328310  3817 layer_factory.hpp:77] Creating layer PReLU15
I1006 20:10:34.328315  3817 net.cpp:84] Creating Layer PReLU15
I1006 20:10:34.328317  3817 net.cpp:406] PReLU15 <- Eltwise7
I1006 20:10:34.328321  3817 net.cpp:367] PReLU15 -> Eltwise7 (in-place)
I1006 20:10:34.328385  3817 net.cpp:122] Setting up PReLU15
I1006 20:10:34.328390  3817 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 20:10:34.328392  3817 net.cpp:137] Memory required for data: 476366000
I1006 20:10:34.328395  3817 layer_factory.hpp:77] Creating layer Eltwise7_PReLU15_0_split
I1006 20:10:34.328398  3817 net.cpp:84] Creating Layer Eltwise7_PReLU15_0_split
I1006 20:10:34.328400  3817 net.cpp:406] Eltwise7_PReLU15_0_split <- Eltwise7
I1006 20:10:34.328404  3817 net.cpp:380] Eltwise7_PReLU15_0_split -> Eltwise7_PReLU15_0_split_0
I1006 20:10:34.328408  3817 net.cpp:380] Eltwise7_PReLU15_0_split -> Eltwise7_PReLU15_0_split_1
I1006 20:10:34.328434  3817 net.cpp:122] Setting up Eltwise7_PReLU15_0_split
I1006 20:10:34.328438  3817 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 20:10:34.328440  3817 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 20:10:34.328443  3817 net.cpp:137] Memory required for data: 482919600
I1006 20:10:34.328444  3817 layer_factory.hpp:77] Creating layer Convolution17
I1006 20:10:34.328451  3817 net.cpp:84] Creating Layer Convolution17
I1006 20:10:34.328454  3817 net.cpp:406] Convolution17 <- Eltwise7_PReLU15_0_split_0
I1006 20:10:34.328459  3817 net.cpp:380] Convolution17 -> Convolution17
I1006 20:10:34.329540  3817 net.cpp:122] Setting up Convolution17
I1006 20:10:34.329548  3817 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 20:10:34.329551  3817 net.cpp:137] Memory required for data: 486196400
I1006 20:10:34.329569  3817 layer_factory.hpp:77] Creating layer BatchNorm17
I1006 20:10:34.329581  3817 net.cpp:84] Creating Layer BatchNorm17
I1006 20:10:34.329586  3817 net.cpp:406] BatchNorm17 <- Convolution17
I1006 20:10:34.329589  3817 net.cpp:367] BatchNorm17 -> Convolution17 (in-place)
I1006 20:10:34.329736  3817 net.cpp:122] Setting up BatchNorm17
I1006 20:10:34.329741  3817 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 20:10:34.329744  3817 net.cpp:137] Memory required for data: 489473200
I1006 20:10:34.329749  3817 layer_factory.hpp:77] Creating layer Scale17
I1006 20:10:34.329753  3817 net.cpp:84] Creating Layer Scale17
I1006 20:10:34.329756  3817 net.cpp:406] Scale17 <- Convolution17
I1006 20:10:34.329759  3817 net.cpp:367] Scale17 -> Convolution17 (in-place)
I1006 20:10:34.329789  3817 layer_factory.hpp:77] Creating layer Scale17
I1006 20:10:34.329872  3817 net.cpp:122] Setting up Scale17
I1006 20:10:34.329876  3817 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 20:10:34.329879  3817 net.cpp:137] Memory required for data: 492750000
I1006 20:10:34.329882  3817 layer_factory.hpp:77] Creating layer PReLU16
I1006 20:10:34.329885  3817 net.cpp:84] Creating Layer PReLU16
I1006 20:10:34.329887  3817 net.cpp:406] PReLU16 <- Convolution17
I1006 20:10:34.329891  3817 net.cpp:367] PReLU16 -> Convolution17 (in-place)
I1006 20:10:34.329955  3817 net.cpp:122] Setting up PReLU16
I1006 20:10:34.329959  3817 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 20:10:34.329962  3817 net.cpp:137] Memory required for data: 496026800
I1006 20:10:34.329964  3817 layer_factory.hpp:77] Creating layer Convolution18
I1006 20:10:34.329970  3817 net.cpp:84] Creating Layer Convolution18
I1006 20:10:34.329972  3817 net.cpp:406] Convolution18 <- Convolution17
I1006 20:10:34.329977  3817 net.cpp:380] Convolution18 -> Convolution18
I1006 20:10:34.331068  3817 net.cpp:122] Setting up Convolution18
I1006 20:10:34.331076  3817 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 20:10:34.331079  3817 net.cpp:137] Memory required for data: 499303600
I1006 20:10:34.331084  3817 layer_factory.hpp:77] Creating layer BatchNorm18
I1006 20:10:34.331089  3817 net.cpp:84] Creating Layer BatchNorm18
I1006 20:10:34.331090  3817 net.cpp:406] BatchNorm18 <- Convolution18
I1006 20:10:34.331094  3817 net.cpp:367] BatchNorm18 -> Convolution18 (in-place)
I1006 20:10:34.331244  3817 net.cpp:122] Setting up BatchNorm18
I1006 20:10:34.331249  3817 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 20:10:34.331252  3817 net.cpp:137] Memory required for data: 502580400
I1006 20:10:34.331256  3817 layer_factory.hpp:77] Creating layer Scale18
I1006 20:10:34.331261  3817 net.cpp:84] Creating Layer Scale18
I1006 20:10:34.331264  3817 net.cpp:406] Scale18 <- Convolution18
I1006 20:10:34.331267  3817 net.cpp:367] Scale18 -> Convolution18 (in-place)
I1006 20:10:34.331297  3817 layer_factory.hpp:77] Creating layer Scale18
I1006 20:10:34.331380  3817 net.cpp:122] Setting up Scale18
I1006 20:10:34.331384  3817 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 20:10:34.331387  3817 net.cpp:137] Memory required for data: 505857200
I1006 20:10:34.331390  3817 layer_factory.hpp:77] Creating layer Eltwise8
I1006 20:10:34.331395  3817 net.cpp:84] Creating Layer Eltwise8
I1006 20:10:34.331398  3817 net.cpp:406] Eltwise8 <- Eltwise7_PReLU15_0_split_1
I1006 20:10:34.331401  3817 net.cpp:406] Eltwise8 <- Convolution18
I1006 20:10:34.331405  3817 net.cpp:380] Eltwise8 -> Eltwise8
I1006 20:10:34.331418  3817 net.cpp:122] Setting up Eltwise8
I1006 20:10:34.331423  3817 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 20:10:34.331424  3817 net.cpp:137] Memory required for data: 509134000
I1006 20:10:34.331426  3817 layer_factory.hpp:77] Creating layer PReLU17
I1006 20:10:34.331429  3817 net.cpp:84] Creating Layer PReLU17
I1006 20:10:34.331431  3817 net.cpp:406] PReLU17 <- Eltwise8
I1006 20:10:34.331436  3817 net.cpp:367] PReLU17 -> Eltwise8 (in-place)
I1006 20:10:34.331501  3817 net.cpp:122] Setting up PReLU17
I1006 20:10:34.331504  3817 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 20:10:34.331506  3817 net.cpp:137] Memory required for data: 512410800
I1006 20:10:34.331516  3817 layer_factory.hpp:77] Creating layer Eltwise8_PReLU17_0_split
I1006 20:10:34.331521  3817 net.cpp:84] Creating Layer Eltwise8_PReLU17_0_split
I1006 20:10:34.331523  3817 net.cpp:406] Eltwise8_PReLU17_0_split <- Eltwise8
I1006 20:10:34.331526  3817 net.cpp:380] Eltwise8_PReLU17_0_split -> Eltwise8_PReLU17_0_split_0
I1006 20:10:34.351056  3817 net.cpp:380] Eltwise8_PReLU17_0_split -> Eltwise8_PReLU17_0_split_1
I1006 20:10:34.351114  3817 net.cpp:122] Setting up Eltwise8_PReLU17_0_split
I1006 20:10:34.351121  3817 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 20:10:34.351127  3817 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 20:10:34.351131  3817 net.cpp:137] Memory required for data: 518964400
I1006 20:10:34.351135  3817 layer_factory.hpp:77] Creating layer Convolution19
I1006 20:10:34.351145  3817 net.cpp:84] Creating Layer Convolution19
I1006 20:10:34.351151  3817 net.cpp:406] Convolution19 <- Eltwise8_PReLU17_0_split_0
I1006 20:10:34.351158  3817 net.cpp:380] Convolution19 -> Convolution19
I1006 20:10:34.352396  3817 net.cpp:122] Setting up Convolution19
I1006 20:10:34.352406  3817 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 20:10:34.352408  3817 net.cpp:137] Memory required for data: 522241200
I1006 20:10:34.352413  3817 layer_factory.hpp:77] Creating layer BatchNorm19
I1006 20:10:34.352419  3817 net.cpp:84] Creating Layer BatchNorm19
I1006 20:10:34.352422  3817 net.cpp:406] BatchNorm19 <- Convolution19
I1006 20:10:34.352427  3817 net.cpp:367] BatchNorm19 -> Convolution19 (in-place)
I1006 20:10:34.352628  3817 net.cpp:122] Setting up BatchNorm19
I1006 20:10:34.352638  3817 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 20:10:34.352641  3817 net.cpp:137] Memory required for data: 525518000
I1006 20:10:34.352650  3817 layer_factory.hpp:77] Creating layer Scale19
I1006 20:10:34.352658  3817 net.cpp:84] Creating Layer Scale19
I1006 20:10:34.352663  3817 net.cpp:406] Scale19 <- Convolution19
I1006 20:10:34.352669  3817 net.cpp:367] Scale19 -> Convolution19 (in-place)
I1006 20:10:34.352708  3817 layer_factory.hpp:77] Creating layer Scale19
I1006 20:10:34.352864  3817 net.cpp:122] Setting up Scale19
I1006 20:10:34.352872  3817 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 20:10:34.352874  3817 net.cpp:137] Memory required for data: 528794800
I1006 20:10:34.352879  3817 layer_factory.hpp:77] Creating layer PReLU18
I1006 20:10:34.352882  3817 net.cpp:84] Creating Layer PReLU18
I1006 20:10:34.352885  3817 net.cpp:406] PReLU18 <- Convolution19
I1006 20:10:34.352890  3817 net.cpp:367] PReLU18 -> Convolution19 (in-place)
I1006 20:10:34.352985  3817 net.cpp:122] Setting up PReLU18
I1006 20:10:34.352993  3817 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 20:10:34.352996  3817 net.cpp:137] Memory required for data: 532071600
I1006 20:10:34.353001  3817 layer_factory.hpp:77] Creating layer Convolution20
I1006 20:10:34.353009  3817 net.cpp:84] Creating Layer Convolution20
I1006 20:10:34.353013  3817 net.cpp:406] Convolution20 <- Convolution19
I1006 20:10:34.353020  3817 net.cpp:380] Convolution20 -> Convolution20
I1006 20:10:34.353860  3817 net.cpp:122] Setting up Convolution20
I1006 20:10:34.353868  3817 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 20:10:34.353871  3817 net.cpp:137] Memory required for data: 535348400
I1006 20:10:34.353878  3817 layer_factory.hpp:77] Creating layer BatchNorm20
I1006 20:10:34.353888  3817 net.cpp:84] Creating Layer BatchNorm20
I1006 20:10:34.353893  3817 net.cpp:406] BatchNorm20 <- Convolution20
I1006 20:10:34.353899  3817 net.cpp:367] BatchNorm20 -> Convolution20 (in-place)
I1006 20:10:34.354102  3817 net.cpp:122] Setting up BatchNorm20
I1006 20:10:34.354112  3817 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 20:10:34.354116  3817 net.cpp:137] Memory required for data: 538625200
I1006 20:10:34.354125  3817 layer_factory.hpp:77] Creating layer Scale20
I1006 20:10:34.354130  3817 net.cpp:84] Creating Layer Scale20
I1006 20:10:34.354135  3817 net.cpp:406] Scale20 <- Convolution20
I1006 20:10:34.354151  3817 net.cpp:367] Scale20 -> Convolution20 (in-place)
I1006 20:10:34.354200  3817 layer_factory.hpp:77] Creating layer Scale20
I1006 20:10:34.354339  3817 net.cpp:122] Setting up Scale20
I1006 20:10:34.354351  3817 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 20:10:34.354354  3817 net.cpp:137] Memory required for data: 541902000
I1006 20:10:34.354362  3817 layer_factory.hpp:77] Creating layer Eltwise9
I1006 20:10:34.354367  3817 net.cpp:84] Creating Layer Eltwise9
I1006 20:10:34.354372  3817 net.cpp:406] Eltwise9 <- Eltwise8_PReLU17_0_split_1
I1006 20:10:34.354377  3817 net.cpp:406] Eltwise9 <- Convolution20
I1006 20:10:34.354384  3817 net.cpp:380] Eltwise9 -> Eltwise9
I1006 20:10:34.354408  3817 net.cpp:122] Setting up Eltwise9
I1006 20:10:34.354413  3817 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 20:10:34.354418  3817 net.cpp:137] Memory required for data: 545178800
I1006 20:10:34.354420  3817 layer_factory.hpp:77] Creating layer PReLU19
I1006 20:10:34.354426  3817 net.cpp:84] Creating Layer PReLU19
I1006 20:10:34.354430  3817 net.cpp:406] PReLU19 <- Eltwise9
I1006 20:10:34.354435  3817 net.cpp:367] PReLU19 -> Eltwise9 (in-place)
I1006 20:10:34.354540  3817 net.cpp:122] Setting up PReLU19
I1006 20:10:34.354550  3817 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 20:10:34.354554  3817 net.cpp:137] Memory required for data: 548455600
I1006 20:10:34.354560  3817 layer_factory.hpp:77] Creating layer Eltwise9_PReLU19_0_split
I1006 20:10:34.354567  3817 net.cpp:84] Creating Layer Eltwise9_PReLU19_0_split
I1006 20:10:34.354570  3817 net.cpp:406] Eltwise9_PReLU19_0_split <- Eltwise9
I1006 20:10:34.354576  3817 net.cpp:380] Eltwise9_PReLU19_0_split -> Eltwise9_PReLU19_0_split_0
I1006 20:10:34.354583  3817 net.cpp:380] Eltwise9_PReLU19_0_split -> Eltwise9_PReLU19_0_split_1
I1006 20:10:34.354627  3817 net.cpp:122] Setting up Eltwise9_PReLU19_0_split
I1006 20:10:34.354637  3817 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 20:10:34.354642  3817 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 20:10:34.354646  3817 net.cpp:137] Memory required for data: 555009200
I1006 20:10:34.354650  3817 layer_factory.hpp:77] Creating layer Convolution21
I1006 20:10:34.354658  3817 net.cpp:84] Creating Layer Convolution21
I1006 20:10:34.354661  3817 net.cpp:406] Convolution21 <- Eltwise9_PReLU19_0_split_0
I1006 20:10:34.354666  3817 net.cpp:380] Convolution21 -> Convolution21
I1006 20:10:34.355799  3817 net.cpp:122] Setting up Convolution21
I1006 20:10:34.355808  3817 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 20:10:34.355811  3817 net.cpp:137] Memory required for data: 558286000
I1006 20:10:34.355815  3817 layer_factory.hpp:77] Creating layer BatchNorm21
I1006 20:10:34.355821  3817 net.cpp:84] Creating Layer BatchNorm21
I1006 20:10:34.355824  3817 net.cpp:406] BatchNorm21 <- Convolution21
I1006 20:10:34.355828  3817 net.cpp:367] BatchNorm21 -> Convolution21 (in-place)
I1006 20:10:34.355973  3817 net.cpp:122] Setting up BatchNorm21
I1006 20:10:34.355978  3817 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 20:10:34.355980  3817 net.cpp:137] Memory required for data: 561562800
I1006 20:10:34.355985  3817 layer_factory.hpp:77] Creating layer Scale21
I1006 20:10:34.355989  3817 net.cpp:84] Creating Layer Scale21
I1006 20:10:34.355993  3817 net.cpp:406] Scale21 <- Convolution21
I1006 20:10:34.355995  3817 net.cpp:367] Scale21 -> Convolution21 (in-place)
I1006 20:10:34.356025  3817 layer_factory.hpp:77] Creating layer Scale21
I1006 20:10:34.356111  3817 net.cpp:122] Setting up Scale21
I1006 20:10:34.356114  3817 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 20:10:34.356117  3817 net.cpp:137] Memory required for data: 564839600
I1006 20:10:34.356120  3817 layer_factory.hpp:77] Creating layer PReLU20
I1006 20:10:34.356125  3817 net.cpp:84] Creating Layer PReLU20
I1006 20:10:34.356128  3817 net.cpp:406] PReLU20 <- Convolution21
I1006 20:10:34.356132  3817 net.cpp:367] PReLU20 -> Convolution21 (in-place)
I1006 20:10:34.356195  3817 net.cpp:122] Setting up PReLU20
I1006 20:10:34.356199  3817 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 20:10:34.356209  3817 net.cpp:137] Memory required for data: 568116400
I1006 20:10:34.356212  3817 layer_factory.hpp:77] Creating layer Convolution22
I1006 20:10:34.356220  3817 net.cpp:84] Creating Layer Convolution22
I1006 20:10:34.356221  3817 net.cpp:406] Convolution22 <- Convolution21
I1006 20:10:34.356226  3817 net.cpp:380] Convolution22 -> Convolution22
I1006 20:10:34.357321  3817 net.cpp:122] Setting up Convolution22
I1006 20:10:34.357329  3817 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 20:10:34.357332  3817 net.cpp:137] Memory required for data: 571393200
I1006 20:10:34.357336  3817 layer_factory.hpp:77] Creating layer BatchNorm22
I1006 20:10:34.357342  3817 net.cpp:84] Creating Layer BatchNorm22
I1006 20:10:34.357344  3817 net.cpp:406] BatchNorm22 <- Convolution22
I1006 20:10:34.357349  3817 net.cpp:367] BatchNorm22 -> Convolution22 (in-place)
I1006 20:10:34.357493  3817 net.cpp:122] Setting up BatchNorm22
I1006 20:10:34.357497  3817 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 20:10:34.357499  3817 net.cpp:137] Memory required for data: 574670000
I1006 20:10:34.357504  3817 layer_factory.hpp:77] Creating layer Scale22
I1006 20:10:34.357508  3817 net.cpp:84] Creating Layer Scale22
I1006 20:10:34.357511  3817 net.cpp:406] Scale22 <- Convolution22
I1006 20:10:34.357516  3817 net.cpp:367] Scale22 -> Convolution22 (in-place)
I1006 20:10:34.357543  3817 layer_factory.hpp:77] Creating layer Scale22
I1006 20:10:34.357627  3817 net.cpp:122] Setting up Scale22
I1006 20:10:34.357631  3817 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 20:10:34.357633  3817 net.cpp:137] Memory required for data: 577946800
I1006 20:10:34.357637  3817 layer_factory.hpp:77] Creating layer Eltwise10
I1006 20:10:34.357641  3817 net.cpp:84] Creating Layer Eltwise10
I1006 20:10:34.357643  3817 net.cpp:406] Eltwise10 <- Eltwise9_PReLU19_0_split_1
I1006 20:10:34.357646  3817 net.cpp:406] Eltwise10 <- Convolution22
I1006 20:10:34.357650  3817 net.cpp:380] Eltwise10 -> Eltwise10
I1006 20:10:34.357664  3817 net.cpp:122] Setting up Eltwise10
I1006 20:10:34.357668  3817 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 20:10:34.357671  3817 net.cpp:137] Memory required for data: 581223600
I1006 20:10:34.357672  3817 layer_factory.hpp:77] Creating layer PReLU21
I1006 20:10:34.357676  3817 net.cpp:84] Creating Layer PReLU21
I1006 20:10:34.357678  3817 net.cpp:406] PReLU21 <- Eltwise10
I1006 20:10:34.357681  3817 net.cpp:367] PReLU21 -> Eltwise10 (in-place)
I1006 20:10:34.357750  3817 net.cpp:122] Setting up PReLU21
I1006 20:10:34.357754  3817 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 20:10:34.357756  3817 net.cpp:137] Memory required for data: 584500400
I1006 20:10:34.357759  3817 layer_factory.hpp:77] Creating layer Eltwise10_PReLU21_0_split
I1006 20:10:34.357764  3817 net.cpp:84] Creating Layer Eltwise10_PReLU21_0_split
I1006 20:10:34.357766  3817 net.cpp:406] Eltwise10_PReLU21_0_split <- Eltwise10
I1006 20:10:34.357769  3817 net.cpp:380] Eltwise10_PReLU21_0_split -> Eltwise10_PReLU21_0_split_0
I1006 20:10:34.357775  3817 net.cpp:380] Eltwise10_PReLU21_0_split -> Eltwise10_PReLU21_0_split_1
I1006 20:10:34.357800  3817 net.cpp:122] Setting up Eltwise10_PReLU21_0_split
I1006 20:10:34.357805  3817 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 20:10:34.357806  3817 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 20:10:34.357808  3817 net.cpp:137] Memory required for data: 591054000
I1006 20:10:34.357811  3817 layer_factory.hpp:77] Creating layer Convolution23
I1006 20:10:34.357817  3817 net.cpp:84] Creating Layer Convolution23
I1006 20:10:34.357820  3817 net.cpp:406] Convolution23 <- Eltwise10_PReLU21_0_split_0
I1006 20:10:34.357825  3817 net.cpp:380] Convolution23 -> Convolution23
I1006 20:10:34.358781  3817 net.cpp:122] Setting up Convolution23
I1006 20:10:34.358790  3817 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 20:10:34.358793  3817 net.cpp:137] Memory required for data: 592692400
I1006 20:10:34.358798  3817 layer_factory.hpp:77] Creating layer BatchNorm23
I1006 20:10:34.358808  3817 net.cpp:84] Creating Layer BatchNorm23
I1006 20:10:34.358811  3817 net.cpp:406] BatchNorm23 <- Convolution23
I1006 20:10:34.358816  3817 net.cpp:367] BatchNorm23 -> Convolution23 (in-place)
I1006 20:10:34.358966  3817 net.cpp:122] Setting up BatchNorm23
I1006 20:10:34.358971  3817 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 20:10:34.358973  3817 net.cpp:137] Memory required for data: 594330800
I1006 20:10:34.358978  3817 layer_factory.hpp:77] Creating layer Scale23
I1006 20:10:34.358983  3817 net.cpp:84] Creating Layer Scale23
I1006 20:10:34.358985  3817 net.cpp:406] Scale23 <- Convolution23
I1006 20:10:34.358989  3817 net.cpp:367] Scale23 -> Convolution23 (in-place)
I1006 20:10:34.359017  3817 layer_factory.hpp:77] Creating layer Scale23
I1006 20:10:34.359104  3817 net.cpp:122] Setting up Scale23
I1006 20:10:34.359108  3817 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 20:10:34.359112  3817 net.cpp:137] Memory required for data: 595969200
I1006 20:10:34.359114  3817 layer_factory.hpp:77] Creating layer Convolution24
I1006 20:10:34.359122  3817 net.cpp:84] Creating Layer Convolution24
I1006 20:10:34.359124  3817 net.cpp:406] Convolution24 <- Eltwise10_PReLU21_0_split_1
I1006 20:10:34.359129  3817 net.cpp:380] Convolution24 -> Convolution24
I1006 20:10:34.360473  3817 net.cpp:122] Setting up Convolution24
I1006 20:10:34.360482  3817 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 20:10:34.360486  3817 net.cpp:137] Memory required for data: 597607600
I1006 20:10:34.360489  3817 layer_factory.hpp:77] Creating layer BatchNorm24
I1006 20:10:34.360494  3817 net.cpp:84] Creating Layer BatchNorm24
I1006 20:10:34.360497  3817 net.cpp:406] BatchNorm24 <- Convolution24
I1006 20:10:34.360502  3817 net.cpp:367] BatchNorm24 -> Convolution24 (in-place)
I1006 20:10:34.360653  3817 net.cpp:122] Setting up BatchNorm24
I1006 20:10:34.360657  3817 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 20:10:34.360659  3817 net.cpp:137] Memory required for data: 599246000
I1006 20:10:34.360664  3817 layer_factory.hpp:77] Creating layer Scale24
I1006 20:10:34.360668  3817 net.cpp:84] Creating Layer Scale24
I1006 20:10:34.360671  3817 net.cpp:406] Scale24 <- Convolution24
I1006 20:10:34.360674  3817 net.cpp:367] Scale24 -> Convolution24 (in-place)
I1006 20:10:34.360704  3817 layer_factory.hpp:77] Creating layer Scale24
I1006 20:10:34.360790  3817 net.cpp:122] Setting up Scale24
I1006 20:10:34.360795  3817 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 20:10:34.360796  3817 net.cpp:137] Memory required for data: 600884400
I1006 20:10:34.360800  3817 layer_factory.hpp:77] Creating layer PReLU22
I1006 20:10:34.360805  3817 net.cpp:84] Creating Layer PReLU22
I1006 20:10:34.360806  3817 net.cpp:406] PReLU22 <- Convolution24
I1006 20:10:34.360810  3817 net.cpp:367] PReLU22 -> Convolution24 (in-place)
I1006 20:10:34.360877  3817 net.cpp:122] Setting up PReLU22
I1006 20:10:34.360880  3817 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 20:10:34.360882  3817 net.cpp:137] Memory required for data: 602522800
I1006 20:10:34.360885  3817 layer_factory.hpp:77] Creating layer Convolution25
I1006 20:10:34.360893  3817 net.cpp:84] Creating Layer Convolution25
I1006 20:10:34.360894  3817 net.cpp:406] Convolution25 <- Convolution24
I1006 20:10:34.360898  3817 net.cpp:380] Convolution25 -> Convolution25
I1006 20:10:34.362632  3817 net.cpp:122] Setting up Convolution25
I1006 20:10:34.362640  3817 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 20:10:34.362643  3817 net.cpp:137] Memory required for data: 604161200
I1006 20:10:34.362648  3817 layer_factory.hpp:77] Creating layer BatchNorm25
I1006 20:10:34.362653  3817 net.cpp:84] Creating Layer BatchNorm25
I1006 20:10:34.362655  3817 net.cpp:406] BatchNorm25 <- Convolution25
I1006 20:10:34.362658  3817 net.cpp:367] BatchNorm25 -> Convolution25 (in-place)
I1006 20:10:34.362807  3817 net.cpp:122] Setting up BatchNorm25
I1006 20:10:34.362810  3817 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 20:10:34.362812  3817 net.cpp:137] Memory required for data: 605799600
I1006 20:10:34.362824  3817 layer_factory.hpp:77] Creating layer Scale25
I1006 20:10:34.362830  3817 net.cpp:84] Creating Layer Scale25
I1006 20:10:34.362833  3817 net.cpp:406] Scale25 <- Convolution25
I1006 20:10:34.362836  3817 net.cpp:367] Scale25 -> Convolution25 (in-place)
I1006 20:10:34.382169  3817 layer_factory.hpp:77] Creating layer Scale25
I1006 20:10:34.382273  3817 net.cpp:122] Setting up Scale25
I1006 20:10:34.382279  3817 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 20:10:34.382282  3817 net.cpp:137] Memory required for data: 607438000
I1006 20:10:34.382287  3817 layer_factory.hpp:77] Creating layer Eltwise11
I1006 20:10:34.382292  3817 net.cpp:84] Creating Layer Eltwise11
I1006 20:10:34.382295  3817 net.cpp:406] Eltwise11 <- Convolution23
I1006 20:10:34.382299  3817 net.cpp:406] Eltwise11 <- Convolution25
I1006 20:10:34.382302  3817 net.cpp:380] Eltwise11 -> Eltwise11
I1006 20:10:34.382323  3817 net.cpp:122] Setting up Eltwise11
I1006 20:10:34.382328  3817 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 20:10:34.382330  3817 net.cpp:137] Memory required for data: 609076400
I1006 20:10:34.382333  3817 layer_factory.hpp:77] Creating layer PReLU23
I1006 20:10:34.382336  3817 net.cpp:84] Creating Layer PReLU23
I1006 20:10:34.382339  3817 net.cpp:406] PReLU23 <- Eltwise11
I1006 20:10:34.382344  3817 net.cpp:367] PReLU23 -> Eltwise11 (in-place)
I1006 20:10:34.382416  3817 net.cpp:122] Setting up PReLU23
I1006 20:10:34.382421  3817 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 20:10:34.382423  3817 net.cpp:137] Memory required for data: 610714800
I1006 20:10:34.382427  3817 layer_factory.hpp:77] Creating layer Eltwise11_PReLU23_0_split
I1006 20:10:34.382431  3817 net.cpp:84] Creating Layer Eltwise11_PReLU23_0_split
I1006 20:10:34.382433  3817 net.cpp:406] Eltwise11_PReLU23_0_split <- Eltwise11
I1006 20:10:34.382436  3817 net.cpp:380] Eltwise11_PReLU23_0_split -> Eltwise11_PReLU23_0_split_0
I1006 20:10:34.382441  3817 net.cpp:380] Eltwise11_PReLU23_0_split -> Eltwise11_PReLU23_0_split_1
I1006 20:10:34.382469  3817 net.cpp:122] Setting up Eltwise11_PReLU23_0_split
I1006 20:10:34.382473  3817 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 20:10:34.382477  3817 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 20:10:34.382479  3817 net.cpp:137] Memory required for data: 613991600
I1006 20:10:34.382481  3817 layer_factory.hpp:77] Creating layer Convolution26
I1006 20:10:34.382489  3817 net.cpp:84] Creating Layer Convolution26
I1006 20:10:34.382493  3817 net.cpp:406] Convolution26 <- Eltwise11_PReLU23_0_split_0
I1006 20:10:34.382498  3817 net.cpp:380] Convolution26 -> Convolution26
I1006 20:10:34.384596  3817 net.cpp:122] Setting up Convolution26
I1006 20:10:34.384606  3817 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 20:10:34.384608  3817 net.cpp:137] Memory required for data: 615630000
I1006 20:10:34.384613  3817 layer_factory.hpp:77] Creating layer BatchNorm26
I1006 20:10:34.384618  3817 net.cpp:84] Creating Layer BatchNorm26
I1006 20:10:34.384621  3817 net.cpp:406] BatchNorm26 <- Convolution26
I1006 20:10:34.384625  3817 net.cpp:367] BatchNorm26 -> Convolution26 (in-place)
I1006 20:10:34.384773  3817 net.cpp:122] Setting up BatchNorm26
I1006 20:10:34.384778  3817 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 20:10:34.384779  3817 net.cpp:137] Memory required for data: 617268400
I1006 20:10:34.384784  3817 layer_factory.hpp:77] Creating layer Scale26
I1006 20:10:34.384788  3817 net.cpp:84] Creating Layer Scale26
I1006 20:10:34.384791  3817 net.cpp:406] Scale26 <- Convolution26
I1006 20:10:34.384794  3817 net.cpp:367] Scale26 -> Convolution26 (in-place)
I1006 20:10:34.384824  3817 layer_factory.hpp:77] Creating layer Scale26
I1006 20:10:34.384909  3817 net.cpp:122] Setting up Scale26
I1006 20:10:34.384913  3817 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 20:10:34.384917  3817 net.cpp:137] Memory required for data: 618906800
I1006 20:10:34.384919  3817 layer_factory.hpp:77] Creating layer PReLU24
I1006 20:10:34.384923  3817 net.cpp:84] Creating Layer PReLU24
I1006 20:10:34.384927  3817 net.cpp:406] PReLU24 <- Convolution26
I1006 20:10:34.384935  3817 net.cpp:367] PReLU24 -> Convolution26 (in-place)
I1006 20:10:34.385004  3817 net.cpp:122] Setting up PReLU24
I1006 20:10:34.385009  3817 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 20:10:34.385011  3817 net.cpp:137] Memory required for data: 620545200
I1006 20:10:34.385015  3817 layer_factory.hpp:77] Creating layer Convolution27
I1006 20:10:34.385020  3817 net.cpp:84] Creating Layer Convolution27
I1006 20:10:34.385022  3817 net.cpp:406] Convolution27 <- Convolution26
I1006 20:10:34.385026  3817 net.cpp:380] Convolution27 -> Convolution27
I1006 20:10:34.386931  3817 net.cpp:122] Setting up Convolution27
I1006 20:10:34.386941  3817 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 20:10:34.386943  3817 net.cpp:137] Memory required for data: 622183600
I1006 20:10:34.386948  3817 layer_factory.hpp:77] Creating layer BatchNorm27
I1006 20:10:34.386966  3817 net.cpp:84] Creating Layer BatchNorm27
I1006 20:10:34.386970  3817 net.cpp:406] BatchNorm27 <- Convolution27
I1006 20:10:34.386973  3817 net.cpp:367] BatchNorm27 -> Convolution27 (in-place)
I1006 20:10:34.387121  3817 net.cpp:122] Setting up BatchNorm27
I1006 20:10:34.387125  3817 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 20:10:34.387127  3817 net.cpp:137] Memory required for data: 623822000
I1006 20:10:34.387133  3817 layer_factory.hpp:77] Creating layer Scale27
I1006 20:10:34.387137  3817 net.cpp:84] Creating Layer Scale27
I1006 20:10:34.387140  3817 net.cpp:406] Scale27 <- Convolution27
I1006 20:10:34.387143  3817 net.cpp:367] Scale27 -> Convolution27 (in-place)
I1006 20:10:34.387188  3817 layer_factory.hpp:77] Creating layer Scale27
I1006 20:10:34.387293  3817 net.cpp:122] Setting up Scale27
I1006 20:10:34.387297  3817 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 20:10:34.387300  3817 net.cpp:137] Memory required for data: 625460400
I1006 20:10:34.387303  3817 layer_factory.hpp:77] Creating layer Eltwise12
I1006 20:10:34.387307  3817 net.cpp:84] Creating Layer Eltwise12
I1006 20:10:34.387310  3817 net.cpp:406] Eltwise12 <- Eltwise11_PReLU23_0_split_1
I1006 20:10:34.387313  3817 net.cpp:406] Eltwise12 <- Convolution27
I1006 20:10:34.387317  3817 net.cpp:380] Eltwise12 -> Eltwise12
I1006 20:10:34.387334  3817 net.cpp:122] Setting up Eltwise12
I1006 20:10:34.387338  3817 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 20:10:34.387341  3817 net.cpp:137] Memory required for data: 627098800
I1006 20:10:34.387342  3817 layer_factory.hpp:77] Creating layer PReLU25
I1006 20:10:34.387346  3817 net.cpp:84] Creating Layer PReLU25
I1006 20:10:34.387348  3817 net.cpp:406] PReLU25 <- Eltwise12
I1006 20:10:34.387351  3817 net.cpp:367] PReLU25 -> Eltwise12 (in-place)
I1006 20:10:34.387415  3817 net.cpp:122] Setting up PReLU25
I1006 20:10:34.387419  3817 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 20:10:34.387421  3817 net.cpp:137] Memory required for data: 628737200
I1006 20:10:34.387424  3817 layer_factory.hpp:77] Creating layer Eltwise12_PReLU25_0_split
I1006 20:10:34.387428  3817 net.cpp:84] Creating Layer Eltwise12_PReLU25_0_split
I1006 20:10:34.387429  3817 net.cpp:406] Eltwise12_PReLU25_0_split <- Eltwise12
I1006 20:10:34.387434  3817 net.cpp:380] Eltwise12_PReLU25_0_split -> Eltwise12_PReLU25_0_split_0
I1006 20:10:34.387437  3817 net.cpp:380] Eltwise12_PReLU25_0_split -> Eltwise12_PReLU25_0_split_1
I1006 20:10:34.387462  3817 net.cpp:122] Setting up Eltwise12_PReLU25_0_split
I1006 20:10:34.387466  3817 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 20:10:34.387470  3817 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 20:10:34.387471  3817 net.cpp:137] Memory required for data: 632014000
I1006 20:10:34.387473  3817 layer_factory.hpp:77] Creating layer Convolution28
I1006 20:10:34.387480  3817 net.cpp:84] Creating Layer Convolution28
I1006 20:10:34.387482  3817 net.cpp:406] Convolution28 <- Eltwise12_PReLU25_0_split_0
I1006 20:10:34.387486  3817 net.cpp:380] Convolution28 -> Convolution28
I1006 20:10:34.389467  3817 net.cpp:122] Setting up Convolution28
I1006 20:10:34.389474  3817 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 20:10:34.389484  3817 net.cpp:137] Memory required for data: 633652400
I1006 20:10:34.389489  3817 layer_factory.hpp:77] Creating layer BatchNorm28
I1006 20:10:34.389495  3817 net.cpp:84] Creating Layer BatchNorm28
I1006 20:10:34.389498  3817 net.cpp:406] BatchNorm28 <- Convolution28
I1006 20:10:34.389502  3817 net.cpp:367] BatchNorm28 -> Convolution28 (in-place)
I1006 20:10:34.389652  3817 net.cpp:122] Setting up BatchNorm28
I1006 20:10:34.389657  3817 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 20:10:34.389658  3817 net.cpp:137] Memory required for data: 635290800
I1006 20:10:34.389663  3817 layer_factory.hpp:77] Creating layer Scale28
I1006 20:10:34.389668  3817 net.cpp:84] Creating Layer Scale28
I1006 20:10:34.389670  3817 net.cpp:406] Scale28 <- Convolution28
I1006 20:10:34.389673  3817 net.cpp:367] Scale28 -> Convolution28 (in-place)
I1006 20:10:34.389703  3817 layer_factory.hpp:77] Creating layer Scale28
I1006 20:10:34.389787  3817 net.cpp:122] Setting up Scale28
I1006 20:10:34.389791  3817 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 20:10:34.389793  3817 net.cpp:137] Memory required for data: 636929200
I1006 20:10:34.389797  3817 layer_factory.hpp:77] Creating layer PReLU26
I1006 20:10:34.389801  3817 net.cpp:84] Creating Layer PReLU26
I1006 20:10:34.389803  3817 net.cpp:406] PReLU26 <- Convolution28
I1006 20:10:34.389806  3817 net.cpp:367] PReLU26 -> Convolution28 (in-place)
I1006 20:10:34.389871  3817 net.cpp:122] Setting up PReLU26
I1006 20:10:34.389875  3817 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 20:10:34.389878  3817 net.cpp:137] Memory required for data: 638567600
I1006 20:10:34.389879  3817 layer_factory.hpp:77] Creating layer Convolution29
I1006 20:10:34.389886  3817 net.cpp:84] Creating Layer Convolution29
I1006 20:10:34.389889  3817 net.cpp:406] Convolution29 <- Convolution28
I1006 20:10:34.389892  3817 net.cpp:380] Convolution29 -> Convolution29
I1006 20:10:34.392119  3817 net.cpp:122] Setting up Convolution29
I1006 20:10:34.392128  3817 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 20:10:34.392130  3817 net.cpp:137] Memory required for data: 640206000
I1006 20:10:34.392135  3817 layer_factory.hpp:77] Creating layer BatchNorm29
I1006 20:10:34.392140  3817 net.cpp:84] Creating Layer BatchNorm29
I1006 20:10:34.392143  3817 net.cpp:406] BatchNorm29 <- Convolution29
I1006 20:10:34.392148  3817 net.cpp:367] BatchNorm29 -> Convolution29 (in-place)
I1006 20:10:34.392318  3817 net.cpp:122] Setting up BatchNorm29
I1006 20:10:34.392321  3817 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 20:10:34.392323  3817 net.cpp:137] Memory required for data: 641844400
I1006 20:10:34.392328  3817 layer_factory.hpp:77] Creating layer Scale29
I1006 20:10:34.392331  3817 net.cpp:84] Creating Layer Scale29
I1006 20:10:34.392334  3817 net.cpp:406] Scale29 <- Convolution29
I1006 20:10:34.392338  3817 net.cpp:367] Scale29 -> Convolution29 (in-place)
I1006 20:10:34.392367  3817 layer_factory.hpp:77] Creating layer Scale29
I1006 20:10:34.392452  3817 net.cpp:122] Setting up Scale29
I1006 20:10:34.392457  3817 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 20:10:34.392458  3817 net.cpp:137] Memory required for data: 643482800
I1006 20:10:34.392462  3817 layer_factory.hpp:77] Creating layer Eltwise13
I1006 20:10:34.392467  3817 net.cpp:84] Creating Layer Eltwise13
I1006 20:10:34.392468  3817 net.cpp:406] Eltwise13 <- Eltwise12_PReLU25_0_split_1
I1006 20:10:34.392472  3817 net.cpp:406] Eltwise13 <- Convolution29
I1006 20:10:34.392474  3817 net.cpp:380] Eltwise13 -> Eltwise13
I1006 20:10:34.392493  3817 net.cpp:122] Setting up Eltwise13
I1006 20:10:34.392496  3817 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 20:10:34.392498  3817 net.cpp:137] Memory required for data: 645121200
I1006 20:10:34.392500  3817 layer_factory.hpp:77] Creating layer PReLU27
I1006 20:10:34.392503  3817 net.cpp:84] Creating Layer PReLU27
I1006 20:10:34.392505  3817 net.cpp:406] PReLU27 <- Eltwise13
I1006 20:10:34.392509  3817 net.cpp:367] PReLU27 -> Eltwise13 (in-place)
I1006 20:10:34.392585  3817 net.cpp:122] Setting up PReLU27
I1006 20:10:34.392590  3817 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 20:10:34.392592  3817 net.cpp:137] Memory required for data: 646759600
I1006 20:10:34.392596  3817 layer_factory.hpp:77] Creating layer Eltwise13_PReLU27_0_split
I1006 20:10:34.392601  3817 net.cpp:84] Creating Layer Eltwise13_PReLU27_0_split
I1006 20:10:34.392602  3817 net.cpp:406] Eltwise13_PReLU27_0_split <- Eltwise13
I1006 20:10:34.392606  3817 net.cpp:380] Eltwise13_PReLU27_0_split -> Eltwise13_PReLU27_0_split_0
I1006 20:10:34.392611  3817 net.cpp:380] Eltwise13_PReLU27_0_split -> Eltwise13_PReLU27_0_split_1
I1006 20:10:34.392637  3817 net.cpp:122] Setting up Eltwise13_PReLU27_0_split
I1006 20:10:34.392642  3817 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 20:10:34.392643  3817 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 20:10:34.392645  3817 net.cpp:137] Memory required for data: 650036400
I1006 20:10:34.392647  3817 layer_factory.hpp:77] Creating layer Convolution30
I1006 20:10:34.392654  3817 net.cpp:84] Creating Layer Convolution30
I1006 20:10:34.392657  3817 net.cpp:406] Convolution30 <- Eltwise13_PReLU27_0_split_0
I1006 20:10:34.392662  3817 net.cpp:380] Convolution30 -> Convolution30
I1006 20:10:34.394656  3817 net.cpp:122] Setting up Convolution30
I1006 20:10:34.394665  3817 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 20:10:34.394667  3817 net.cpp:137] Memory required for data: 651674800
I1006 20:10:34.394672  3817 layer_factory.hpp:77] Creating layer BatchNorm30
I1006 20:10:34.394677  3817 net.cpp:84] Creating Layer BatchNorm30
I1006 20:10:34.394680  3817 net.cpp:406] BatchNorm30 <- Convolution30
I1006 20:10:34.394685  3817 net.cpp:367] BatchNorm30 -> Convolution30 (in-place)
I1006 20:10:34.394835  3817 net.cpp:122] Setting up BatchNorm30
I1006 20:10:34.394840  3817 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 20:10:34.394841  3817 net.cpp:137] Memory required for data: 653313200
I1006 20:10:34.394846  3817 layer_factory.hpp:77] Creating layer Scale30
I1006 20:10:34.394851  3817 net.cpp:84] Creating Layer Scale30
I1006 20:10:34.394853  3817 net.cpp:406] Scale30 <- Convolution30
I1006 20:10:34.394856  3817 net.cpp:367] Scale30 -> Convolution30 (in-place)
I1006 20:10:34.394886  3817 layer_factory.hpp:77] Creating layer Scale30
I1006 20:10:34.394974  3817 net.cpp:122] Setting up Scale30
I1006 20:10:34.394979  3817 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 20:10:34.394980  3817 net.cpp:137] Memory required for data: 654951600
I1006 20:10:34.394984  3817 layer_factory.hpp:77] Creating layer PReLU28
I1006 20:10:34.394987  3817 net.cpp:84] Creating Layer PReLU28
I1006 20:10:34.394989  3817 net.cpp:406] PReLU28 <- Convolution30
I1006 20:10:34.394994  3817 net.cpp:367] PReLU28 -> Convolution30 (in-place)
I1006 20:10:34.395059  3817 net.cpp:122] Setting up PReLU28
I1006 20:10:34.395063  3817 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 20:10:34.395066  3817 net.cpp:137] Memory required for data: 656590000
I1006 20:10:34.395068  3817 layer_factory.hpp:77] Creating layer Convolution31
I1006 20:10:34.395076  3817 net.cpp:84] Creating Layer Convolution31
I1006 20:10:34.395077  3817 net.cpp:406] Convolution31 <- Convolution30
I1006 20:10:34.395081  3817 net.cpp:380] Convolution31 -> Convolution31
I1006 20:10:34.396800  3817 net.cpp:122] Setting up Convolution31
I1006 20:10:34.396808  3817 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 20:10:34.396811  3817 net.cpp:137] Memory required for data: 658228400
I1006 20:10:34.396816  3817 layer_factory.hpp:77] Creating layer BatchNorm31
I1006 20:10:34.396821  3817 net.cpp:84] Creating Layer BatchNorm31
I1006 20:10:34.396824  3817 net.cpp:406] BatchNorm31 <- Convolution31
I1006 20:10:34.396827  3817 net.cpp:367] BatchNorm31 -> Convolution31 (in-place)
I1006 20:10:34.396975  3817 net.cpp:122] Setting up BatchNorm31
I1006 20:10:34.396980  3817 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 20:10:34.396981  3817 net.cpp:137] Memory required for data: 659866800
I1006 20:10:34.396986  3817 layer_factory.hpp:77] Creating layer Scale31
I1006 20:10:34.396997  3817 net.cpp:84] Creating Layer Scale31
I1006 20:10:34.412295  3817 net.cpp:406] Scale31 <- Convolution31
I1006 20:10:34.412305  3817 net.cpp:367] Scale31 -> Convolution31 (in-place)
I1006 20:10:34.412353  3817 layer_factory.hpp:77] Creating layer Scale31
I1006 20:10:34.412452  3817 net.cpp:122] Setting up Scale31
I1006 20:10:34.412457  3817 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 20:10:34.412459  3817 net.cpp:137] Memory required for data: 661505200
I1006 20:10:34.412464  3817 layer_factory.hpp:77] Creating layer Eltwise14
I1006 20:10:34.412468  3817 net.cpp:84] Creating Layer Eltwise14
I1006 20:10:34.412472  3817 net.cpp:406] Eltwise14 <- Eltwise13_PReLU27_0_split_1
I1006 20:10:34.412474  3817 net.cpp:406] Eltwise14 <- Convolution31
I1006 20:10:34.412478  3817 net.cpp:380] Eltwise14 -> Eltwise14
I1006 20:10:34.412498  3817 net.cpp:122] Setting up Eltwise14
I1006 20:10:34.412503  3817 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 20:10:34.412504  3817 net.cpp:137] Memory required for data: 663143600
I1006 20:10:34.412506  3817 layer_factory.hpp:77] Creating layer PReLU29
I1006 20:10:34.412511  3817 net.cpp:84] Creating Layer PReLU29
I1006 20:10:34.412514  3817 net.cpp:406] PReLU29 <- Eltwise14
I1006 20:10:34.412518  3817 net.cpp:367] PReLU29 -> Eltwise14 (in-place)
I1006 20:10:34.412588  3817 net.cpp:122] Setting up PReLU29
I1006 20:10:34.412593  3817 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 20:10:34.412595  3817 net.cpp:137] Memory required for data: 664782000
I1006 20:10:34.412598  3817 layer_factory.hpp:77] Creating layer Eltwise14_PReLU29_0_split
I1006 20:10:34.412601  3817 net.cpp:84] Creating Layer Eltwise14_PReLU29_0_split
I1006 20:10:34.412605  3817 net.cpp:406] Eltwise14_PReLU29_0_split <- Eltwise14
I1006 20:10:34.412608  3817 net.cpp:380] Eltwise14_PReLU29_0_split -> Eltwise14_PReLU29_0_split_0
I1006 20:10:34.412612  3817 net.cpp:380] Eltwise14_PReLU29_0_split -> Eltwise14_PReLU29_0_split_1
I1006 20:10:34.412641  3817 net.cpp:122] Setting up Eltwise14_PReLU29_0_split
I1006 20:10:34.412644  3817 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 20:10:34.412648  3817 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 20:10:34.412650  3817 net.cpp:137] Memory required for data: 668058800
I1006 20:10:34.412652  3817 layer_factory.hpp:77] Creating layer Convolution32
I1006 20:10:34.412659  3817 net.cpp:84] Creating Layer Convolution32
I1006 20:10:34.412662  3817 net.cpp:406] Convolution32 <- Eltwise14_PReLU29_0_split_0
I1006 20:10:34.412667  3817 net.cpp:380] Convolution32 -> Convolution32
I1006 20:10:34.415323  3817 net.cpp:122] Setting up Convolution32
I1006 20:10:34.415333  3817 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 20:10:34.415335  3817 net.cpp:137] Memory required for data: 669697200
I1006 20:10:34.415340  3817 layer_factory.hpp:77] Creating layer BatchNorm32
I1006 20:10:34.415344  3817 net.cpp:84] Creating Layer BatchNorm32
I1006 20:10:34.415347  3817 net.cpp:406] BatchNorm32 <- Convolution32
I1006 20:10:34.415352  3817 net.cpp:367] BatchNorm32 -> Convolution32 (in-place)
I1006 20:10:34.415513  3817 net.cpp:122] Setting up BatchNorm32
I1006 20:10:34.415518  3817 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 20:10:34.415519  3817 net.cpp:137] Memory required for data: 671335600
I1006 20:10:34.415524  3817 layer_factory.hpp:77] Creating layer Scale32
I1006 20:10:34.415529  3817 net.cpp:84] Creating Layer Scale32
I1006 20:10:34.415530  3817 net.cpp:406] Scale32 <- Convolution32
I1006 20:10:34.415535  3817 net.cpp:367] Scale32 -> Convolution32 (in-place)
I1006 20:10:34.415566  3817 layer_factory.hpp:77] Creating layer Scale32
I1006 20:10:34.415654  3817 net.cpp:122] Setting up Scale32
I1006 20:10:34.415658  3817 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 20:10:34.415660  3817 net.cpp:137] Memory required for data: 672974000
I1006 20:10:34.415664  3817 layer_factory.hpp:77] Creating layer PReLU30
I1006 20:10:34.415668  3817 net.cpp:84] Creating Layer PReLU30
I1006 20:10:34.415670  3817 net.cpp:406] PReLU30 <- Convolution32
I1006 20:10:34.415680  3817 net.cpp:367] PReLU30 -> Convolution32 (in-place)
I1006 20:10:34.415751  3817 net.cpp:122] Setting up PReLU30
I1006 20:10:34.415755  3817 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 20:10:34.415757  3817 net.cpp:137] Memory required for data: 674612400
I1006 20:10:34.415760  3817 layer_factory.hpp:77] Creating layer Convolution33
I1006 20:10:34.415767  3817 net.cpp:84] Creating Layer Convolution33
I1006 20:10:34.415771  3817 net.cpp:406] Convolution33 <- Convolution32
I1006 20:10:34.415774  3817 net.cpp:380] Convolution33 -> Convolution33
I1006 20:10:34.417697  3817 net.cpp:122] Setting up Convolution33
I1006 20:10:34.417706  3817 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 20:10:34.417709  3817 net.cpp:137] Memory required for data: 676250800
I1006 20:10:34.417714  3817 layer_factory.hpp:77] Creating layer BatchNorm33
I1006 20:10:34.417719  3817 net.cpp:84] Creating Layer BatchNorm33
I1006 20:10:34.417722  3817 net.cpp:406] BatchNorm33 <- Convolution33
I1006 20:10:34.417726  3817 net.cpp:367] BatchNorm33 -> Convolution33 (in-place)
I1006 20:10:34.417924  3817 net.cpp:122] Setting up BatchNorm33
I1006 20:10:34.417933  3817 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 20:10:34.417937  3817 net.cpp:137] Memory required for data: 677889200
I1006 20:10:34.417973  3817 layer_factory.hpp:77] Creating layer Scale33
I1006 20:10:34.417979  3817 net.cpp:84] Creating Layer Scale33
I1006 20:10:34.417984  3817 net.cpp:406] Scale33 <- Convolution33
I1006 20:10:34.417989  3817 net.cpp:367] Scale33 -> Convolution33 (in-place)
I1006 20:10:34.418035  3817 layer_factory.hpp:77] Creating layer Scale33
I1006 20:10:34.418160  3817 net.cpp:122] Setting up Scale33
I1006 20:10:34.418167  3817 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 20:10:34.418171  3817 net.cpp:137] Memory required for data: 679527600
I1006 20:10:34.418177  3817 layer_factory.hpp:77] Creating layer Eltwise15
I1006 20:10:34.418185  3817 net.cpp:84] Creating Layer Eltwise15
I1006 20:10:34.418190  3817 net.cpp:406] Eltwise15 <- Eltwise14_PReLU29_0_split_1
I1006 20:10:34.418195  3817 net.cpp:406] Eltwise15 <- Convolution33
I1006 20:10:34.418200  3817 net.cpp:380] Eltwise15 -> Eltwise15
I1006 20:10:34.418226  3817 net.cpp:122] Setting up Eltwise15
I1006 20:10:34.418232  3817 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 20:10:34.418236  3817 net.cpp:137] Memory required for data: 681166000
I1006 20:10:34.418238  3817 layer_factory.hpp:77] Creating layer PReLU31
I1006 20:10:34.418243  3817 net.cpp:84] Creating Layer PReLU31
I1006 20:10:34.418247  3817 net.cpp:406] PReLU31 <- Eltwise15
I1006 20:10:34.418253  3817 net.cpp:367] PReLU31 -> Eltwise15 (in-place)
I1006 20:10:34.418347  3817 net.cpp:122] Setting up PReLU31
I1006 20:10:34.418354  3817 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 20:10:34.418357  3817 net.cpp:137] Memory required for data: 682804400
I1006 20:10:34.418362  3817 layer_factory.hpp:77] Creating layer Pooling1
I1006 20:10:34.418370  3817 net.cpp:84] Creating Layer Pooling1
I1006 20:10:34.418373  3817 net.cpp:406] Pooling1 <- Eltwise15
I1006 20:10:34.418380  3817 net.cpp:380] Pooling1 -> Pooling1
I1006 20:10:34.418620  3817 net.cpp:122] Setting up Pooling1
I1006 20:10:34.418643  3817 net.cpp:129] Top shape: 100 64 1 1 (6400)
I1006 20:10:34.418655  3817 net.cpp:137] Memory required for data: 682830000
I1006 20:10:34.418658  3817 layer_factory.hpp:77] Creating layer InnerProduct1
I1006 20:10:34.418664  3817 net.cpp:84] Creating Layer InnerProduct1
I1006 20:10:34.418682  3817 net.cpp:406] InnerProduct1 <- Pooling1
I1006 20:10:34.418699  3817 net.cpp:380] InnerProduct1 -> InnerProduct1
I1006 20:10:34.418936  3817 net.cpp:122] Setting up InnerProduct1
I1006 20:10:34.418942  3817 net.cpp:129] Top shape: 100 10 (1000)
I1006 20:10:34.418946  3817 net.cpp:137] Memory required for data: 682834000
I1006 20:10:34.418952  3817 layer_factory.hpp:77] Creating layer InnerProduct1_InnerProduct1_0_split
I1006 20:10:34.418959  3817 net.cpp:84] Creating Layer InnerProduct1_InnerProduct1_0_split
I1006 20:10:34.418963  3817 net.cpp:406] InnerProduct1_InnerProduct1_0_split <- InnerProduct1
I1006 20:10:34.418978  3817 net.cpp:380] InnerProduct1_InnerProduct1_0_split -> InnerProduct1_InnerProduct1_0_split_0
I1006 20:10:34.418987  3817 net.cpp:380] InnerProduct1_InnerProduct1_0_split -> InnerProduct1_InnerProduct1_0_split_1
I1006 20:10:34.419028  3817 net.cpp:122] Setting up InnerProduct1_InnerProduct1_0_split
I1006 20:10:34.419034  3817 net.cpp:129] Top shape: 100 10 (1000)
I1006 20:10:34.419039  3817 net.cpp:129] Top shape: 100 10 (1000)
I1006 20:10:34.419042  3817 net.cpp:137] Memory required for data: 682842000
I1006 20:10:34.419045  3817 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I1006 20:10:34.419052  3817 net.cpp:84] Creating Layer SoftmaxWithLoss1
I1006 20:10:34.419056  3817 net.cpp:406] SoftmaxWithLoss1 <- InnerProduct1_InnerProduct1_0_split_0
I1006 20:10:34.419060  3817 net.cpp:406] SoftmaxWithLoss1 <- Data2_Data1_1_split_0
I1006 20:10:34.419065  3817 net.cpp:380] SoftmaxWithLoss1 -> SoftmaxWithLoss1
I1006 20:10:34.419072  3817 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I1006 20:10:34.419682  3817 net.cpp:122] Setting up SoftmaxWithLoss1
I1006 20:10:34.419690  3817 net.cpp:129] Top shape: (1)
I1006 20:10:34.419692  3817 net.cpp:132]     with loss weight 1
I1006 20:10:34.419699  3817 net.cpp:137] Memory required for data: 682842004
I1006 20:10:34.419701  3817 layer_factory.hpp:77] Creating layer Accuracy1
I1006 20:10:34.419708  3817 net.cpp:84] Creating Layer Accuracy1
I1006 20:10:34.419709  3817 net.cpp:406] Accuracy1 <- InnerProduct1_InnerProduct1_0_split_1
I1006 20:10:34.419713  3817 net.cpp:406] Accuracy1 <- Data2_Data1_1_split_1
I1006 20:10:34.419718  3817 net.cpp:380] Accuracy1 -> Accuracy1
I1006 20:10:34.419723  3817 net.cpp:122] Setting up Accuracy1
I1006 20:10:34.419728  3817 net.cpp:129] Top shape: (1)
I1006 20:10:34.419729  3817 net.cpp:137] Memory required for data: 682842008
I1006 20:10:34.419731  3817 net.cpp:200] Accuracy1 does not need backward computation.
I1006 20:10:34.419734  3817 net.cpp:198] SoftmaxWithLoss1 needs backward computation.
I1006 20:10:34.419736  3817 net.cpp:198] InnerProduct1_InnerProduct1_0_split needs backward computation.
I1006 20:10:34.419739  3817 net.cpp:198] InnerProduct1 needs backward computation.
I1006 20:10:34.419741  3817 net.cpp:198] Pooling1 needs backward computation.
I1006 20:10:34.419744  3817 net.cpp:198] PReLU31 needs backward computation.
I1006 20:10:34.419745  3817 net.cpp:198] Eltwise15 needs backward computation.
I1006 20:10:34.419749  3817 net.cpp:198] Scale33 needs backward computation.
I1006 20:10:34.419750  3817 net.cpp:198] BatchNorm33 needs backward computation.
I1006 20:10:34.419752  3817 net.cpp:198] Convolution33 needs backward computation.
I1006 20:10:34.419754  3817 net.cpp:198] PReLU30 needs backward computation.
I1006 20:10:34.419756  3817 net.cpp:198] Scale32 needs backward computation.
I1006 20:10:34.419759  3817 net.cpp:198] BatchNorm32 needs backward computation.
I1006 20:10:34.419760  3817 net.cpp:198] Convolution32 needs backward computation.
I1006 20:10:34.419762  3817 net.cpp:198] Eltwise14_PReLU29_0_split needs backward computation.
I1006 20:10:34.419765  3817 net.cpp:198] PReLU29 needs backward computation.
I1006 20:10:34.419767  3817 net.cpp:198] Eltwise14 needs backward computation.
I1006 20:10:34.419770  3817 net.cpp:198] Scale31 needs backward computation.
I1006 20:10:34.419772  3817 net.cpp:198] BatchNorm31 needs backward computation.
I1006 20:10:34.419775  3817 net.cpp:198] Convolution31 needs backward computation.
I1006 20:10:34.419777  3817 net.cpp:198] PReLU28 needs backward computation.
I1006 20:10:34.419780  3817 net.cpp:198] Scale30 needs backward computation.
I1006 20:10:34.419781  3817 net.cpp:198] BatchNorm30 needs backward computation.
I1006 20:10:34.419783  3817 net.cpp:198] Convolution30 needs backward computation.
I1006 20:10:34.419785  3817 net.cpp:198] Eltwise13_PReLU27_0_split needs backward computation.
I1006 20:10:34.419788  3817 net.cpp:198] PReLU27 needs backward computation.
I1006 20:10:34.419790  3817 net.cpp:198] Eltwise13 needs backward computation.
I1006 20:10:34.419800  3817 net.cpp:198] Scale29 needs backward computation.
I1006 20:10:34.419802  3817 net.cpp:198] BatchNorm29 needs backward computation.
I1006 20:10:34.419805  3817 net.cpp:198] Convolution29 needs backward computation.
I1006 20:10:34.419807  3817 net.cpp:198] PReLU26 needs backward computation.
I1006 20:10:34.419809  3817 net.cpp:198] Scale28 needs backward computation.
I1006 20:10:34.419811  3817 net.cpp:198] BatchNorm28 needs backward computation.
I1006 20:10:34.419813  3817 net.cpp:198] Convolution28 needs backward computation.
I1006 20:10:34.419816  3817 net.cpp:198] Eltwise12_PReLU25_0_split needs backward computation.
I1006 20:10:34.419818  3817 net.cpp:198] PReLU25 needs backward computation.
I1006 20:10:34.419821  3817 net.cpp:198] Eltwise12 needs backward computation.
I1006 20:10:34.419823  3817 net.cpp:198] Scale27 needs backward computation.
I1006 20:10:34.419826  3817 net.cpp:198] BatchNorm27 needs backward computation.
I1006 20:10:34.419828  3817 net.cpp:198] Convolution27 needs backward computation.
I1006 20:10:34.419831  3817 net.cpp:198] PReLU24 needs backward computation.
I1006 20:10:34.419832  3817 net.cpp:198] Scale26 needs backward computation.
I1006 20:10:34.419834  3817 net.cpp:198] BatchNorm26 needs backward computation.
I1006 20:10:34.419837  3817 net.cpp:198] Convolution26 needs backward computation.
I1006 20:10:34.419839  3817 net.cpp:198] Eltwise11_PReLU23_0_split needs backward computation.
I1006 20:10:34.419842  3817 net.cpp:198] PReLU23 needs backward computation.
I1006 20:10:34.419844  3817 net.cpp:198] Eltwise11 needs backward computation.
I1006 20:10:34.419847  3817 net.cpp:198] Scale25 needs backward computation.
I1006 20:10:34.419849  3817 net.cpp:198] BatchNorm25 needs backward computation.
I1006 20:10:34.419852  3817 net.cpp:198] Convolution25 needs backward computation.
I1006 20:10:34.419853  3817 net.cpp:198] PReLU22 needs backward computation.
I1006 20:10:34.419855  3817 net.cpp:198] Scale24 needs backward computation.
I1006 20:10:34.419857  3817 net.cpp:198] BatchNorm24 needs backward computation.
I1006 20:10:34.419860  3817 net.cpp:198] Convolution24 needs backward computation.
I1006 20:10:34.419862  3817 net.cpp:198] Scale23 needs backward computation.
I1006 20:10:34.419864  3817 net.cpp:198] BatchNorm23 needs backward computation.
I1006 20:10:34.419867  3817 net.cpp:198] Convolution23 needs backward computation.
I1006 20:10:34.419869  3817 net.cpp:198] Eltwise10_PReLU21_0_split needs backward computation.
I1006 20:10:34.419872  3817 net.cpp:198] PReLU21 needs backward computation.
I1006 20:10:34.419874  3817 net.cpp:198] Eltwise10 needs backward computation.
I1006 20:10:34.419878  3817 net.cpp:198] Scale22 needs backward computation.
I1006 20:10:34.419880  3817 net.cpp:198] BatchNorm22 needs backward computation.
I1006 20:10:34.419883  3817 net.cpp:198] Convolution22 needs backward computation.
I1006 20:10:34.419885  3817 net.cpp:198] PReLU20 needs backward computation.
I1006 20:10:34.419888  3817 net.cpp:198] Scale21 needs backward computation.
I1006 20:10:34.419889  3817 net.cpp:198] BatchNorm21 needs backward computation.
I1006 20:10:34.419891  3817 net.cpp:198] Convolution21 needs backward computation.
I1006 20:10:34.419894  3817 net.cpp:198] Eltwise9_PReLU19_0_split needs backward computation.
I1006 20:10:34.419896  3817 net.cpp:198] PReLU19 needs backward computation.
I1006 20:10:34.419898  3817 net.cpp:198] Eltwise9 needs backward computation.
I1006 20:10:34.419901  3817 net.cpp:198] Scale20 needs backward computation.
I1006 20:10:34.419903  3817 net.cpp:198] BatchNorm20 needs backward computation.
I1006 20:10:34.419905  3817 net.cpp:198] Convolution20 needs backward computation.
I1006 20:10:34.419909  3817 net.cpp:198] PReLU18 needs backward computation.
I1006 20:10:34.419910  3817 net.cpp:198] Scale19 needs backward computation.
I1006 20:10:34.419912  3817 net.cpp:198] BatchNorm19 needs backward computation.
I1006 20:10:34.419914  3817 net.cpp:198] Convolution19 needs backward computation.
I1006 20:10:34.443001  3817 net.cpp:198] Eltwise8_PReLU17_0_split needs backward computation.
I1006 20:10:34.443018  3817 net.cpp:198] PReLU17 needs backward computation.
I1006 20:10:34.443024  3817 net.cpp:198] Eltwise8 needs backward computation.
I1006 20:10:34.443029  3817 net.cpp:198] Scale18 needs backward computation.
I1006 20:10:34.443033  3817 net.cpp:198] BatchNorm18 needs backward computation.
I1006 20:10:34.443037  3817 net.cpp:198] Convolution18 needs backward computation.
I1006 20:10:34.443042  3817 net.cpp:198] PReLU16 needs backward computation.
I1006 20:10:34.443045  3817 net.cpp:198] Scale17 needs backward computation.
I1006 20:10:34.443048  3817 net.cpp:198] BatchNorm17 needs backward computation.
I1006 20:10:34.443050  3817 net.cpp:198] Convolution17 needs backward computation.
I1006 20:10:34.443053  3817 net.cpp:198] Eltwise7_PReLU15_0_split needs backward computation.
I1006 20:10:34.443056  3817 net.cpp:198] PReLU15 needs backward computation.
I1006 20:10:34.443058  3817 net.cpp:198] Eltwise7 needs backward computation.
I1006 20:10:34.443061  3817 net.cpp:198] Scale16 needs backward computation.
I1006 20:10:34.443063  3817 net.cpp:198] BatchNorm16 needs backward computation.
I1006 20:10:34.443066  3817 net.cpp:198] Convolution16 needs backward computation.
I1006 20:10:34.443068  3817 net.cpp:198] PReLU14 needs backward computation.
I1006 20:10:34.443070  3817 net.cpp:198] Scale15 needs backward computation.
I1006 20:10:34.443073  3817 net.cpp:198] BatchNorm15 needs backward computation.
I1006 20:10:34.443075  3817 net.cpp:198] Convolution15 needs backward computation.
I1006 20:10:34.443078  3817 net.cpp:198] Eltwise6_PReLU13_0_split needs backward computation.
I1006 20:10:34.443081  3817 net.cpp:198] PReLU13 needs backward computation.
I1006 20:10:34.443084  3817 net.cpp:198] Eltwise6 needs backward computation.
I1006 20:10:34.443086  3817 net.cpp:198] Scale14 needs backward computation.
I1006 20:10:34.443089  3817 net.cpp:198] BatchNorm14 needs backward computation.
I1006 20:10:34.443091  3817 net.cpp:198] Convolution14 needs backward computation.
I1006 20:10:34.443094  3817 net.cpp:198] PReLU12 needs backward computation.
I1006 20:10:34.443096  3817 net.cpp:198] Scale13 needs backward computation.
I1006 20:10:34.443099  3817 net.cpp:198] BatchNorm13 needs backward computation.
I1006 20:10:34.443100  3817 net.cpp:198] Convolution13 needs backward computation.
I1006 20:10:34.443104  3817 net.cpp:198] Scale12 needs backward computation.
I1006 20:10:34.443105  3817 net.cpp:198] BatchNorm12 needs backward computation.
I1006 20:10:34.443107  3817 net.cpp:198] Convolution12 needs backward computation.
I1006 20:10:34.443110  3817 net.cpp:198] Eltwise5_PReLU11_0_split needs backward computation.
I1006 20:10:34.443114  3817 net.cpp:198] PReLU11 needs backward computation.
I1006 20:10:34.443115  3817 net.cpp:198] Eltwise5 needs backward computation.
I1006 20:10:34.443119  3817 net.cpp:198] Scale11 needs backward computation.
I1006 20:10:34.443121  3817 net.cpp:198] BatchNorm11 needs backward computation.
I1006 20:10:34.443123  3817 net.cpp:198] Convolution11 needs backward computation.
I1006 20:10:34.443126  3817 net.cpp:198] PReLU10 needs backward computation.
I1006 20:10:34.443128  3817 net.cpp:198] Scale10 needs backward computation.
I1006 20:10:34.443130  3817 net.cpp:198] BatchNorm10 needs backward computation.
I1006 20:10:34.443132  3817 net.cpp:198] Convolution10 needs backward computation.
I1006 20:10:34.443135  3817 net.cpp:198] Eltwise4_PReLU9_0_split needs backward computation.
I1006 20:10:34.443138  3817 net.cpp:198] PReLU9 needs backward computation.
I1006 20:10:34.443140  3817 net.cpp:198] Eltwise4 needs backward computation.
I1006 20:10:34.443145  3817 net.cpp:198] Scale9 needs backward computation.
I1006 20:10:34.443146  3817 net.cpp:198] BatchNorm9 needs backward computation.
I1006 20:10:34.443148  3817 net.cpp:198] Convolution9 needs backward computation.
I1006 20:10:34.443151  3817 net.cpp:198] PReLU8 needs backward computation.
I1006 20:10:34.443155  3817 net.cpp:198] Scale8 needs backward computation.
I1006 20:10:34.443161  3817 net.cpp:198] BatchNorm8 needs backward computation.
I1006 20:10:34.443171  3817 net.cpp:198] Convolution8 needs backward computation.
I1006 20:10:34.443176  3817 net.cpp:198] Eltwise3_PReLU7_0_split needs backward computation.
I1006 20:10:34.443177  3817 net.cpp:198] PReLU7 needs backward computation.
I1006 20:10:34.443181  3817 net.cpp:198] Eltwise3 needs backward computation.
I1006 20:10:34.443183  3817 net.cpp:198] Scale7 needs backward computation.
I1006 20:10:34.443186  3817 net.cpp:198] BatchNorm7 needs backward computation.
I1006 20:10:34.443187  3817 net.cpp:198] Convolution7 needs backward computation.
I1006 20:10:34.443190  3817 net.cpp:198] PReLU6 needs backward computation.
I1006 20:10:34.443192  3817 net.cpp:198] Scale6 needs backward computation.
I1006 20:10:34.443195  3817 net.cpp:198] BatchNorm6 needs backward computation.
I1006 20:10:34.443197  3817 net.cpp:198] Convolution6 needs backward computation.
I1006 20:10:34.443199  3817 net.cpp:198] Eltwise2_PReLU5_0_split needs backward computation.
I1006 20:10:34.443202  3817 net.cpp:198] PReLU5 needs backward computation.
I1006 20:10:34.443204  3817 net.cpp:198] Eltwise2 needs backward computation.
I1006 20:10:34.443207  3817 net.cpp:198] Scale5 needs backward computation.
I1006 20:10:34.443210  3817 net.cpp:198] BatchNorm5 needs backward computation.
I1006 20:10:34.443212  3817 net.cpp:198] Convolution5 needs backward computation.
I1006 20:10:34.443214  3817 net.cpp:198] PReLU4 needs backward computation.
I1006 20:10:34.443217  3817 net.cpp:198] Scale4 needs backward computation.
I1006 20:10:34.443219  3817 net.cpp:198] BatchNorm4 needs backward computation.
I1006 20:10:34.443222  3817 net.cpp:198] Convolution4 needs backward computation.
I1006 20:10:34.443224  3817 net.cpp:198] Eltwise1_PReLU3_0_split needs backward computation.
I1006 20:10:34.443228  3817 net.cpp:198] PReLU3 needs backward computation.
I1006 20:10:34.443229  3817 net.cpp:198] Eltwise1 needs backward computation.
I1006 20:10:34.443233  3817 net.cpp:198] Scale3 needs backward computation.
I1006 20:10:34.443235  3817 net.cpp:198] BatchNorm3 needs backward computation.
I1006 20:10:34.443238  3817 net.cpp:198] Convolution3 needs backward computation.
I1006 20:10:34.443240  3817 net.cpp:198] PReLU2 needs backward computation.
I1006 20:10:34.443243  3817 net.cpp:198] Scale2 needs backward computation.
I1006 20:10:34.443244  3817 net.cpp:198] BatchNorm2 needs backward computation.
I1006 20:10:34.443248  3817 net.cpp:198] Convolution2 needs backward computation.
I1006 20:10:34.443250  3817 net.cpp:198] Convolution1_PReLU1_0_split needs backward computation.
I1006 20:10:34.443253  3817 net.cpp:198] PReLU1 needs backward computation.
I1006 20:10:34.443255  3817 net.cpp:198] Scale1 needs backward computation.
I1006 20:10:34.443258  3817 net.cpp:198] BatchNorm1 needs backward computation.
I1006 20:10:34.443259  3817 net.cpp:198] Convolution1 needs backward computation.
I1006 20:10:34.443264  3817 net.cpp:200] Data2_Data1_1_split does not need backward computation.
I1006 20:10:34.443267  3817 net.cpp:200] Data1 does not need backward computation.
I1006 20:10:34.443270  3817 net.cpp:242] This network produces output Accuracy1
I1006 20:10:34.443272  3817 net.cpp:242] This network produces output SoftmaxWithLoss1
I1006 20:10:34.443332  3817 net.cpp:255] Network initialization done.
I1006 20:10:34.443704  3817 solver.cpp:56] Solver scaffolding done.
I1006 20:10:34.451604  3817 caffe.cpp:248] Starting Optimization
I1006 20:10:34.451617  3817 solver.cpp:272] Solving resnet_cifar10
I1006 20:10:34.451618  3817 solver.cpp:273] Learning Rate Policy: multistep
I1006 20:10:34.454592  3817 solver.cpp:330] Iteration 0, Testing net (#0)
I1006 20:10:36.375425  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:10:36.453394  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.1
I1006 20:10:36.453421  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 87.3365 (* 1 = 87.3365 loss)
I1006 20:10:36.564697  3817 solver.cpp:218] Iteration 0 (-2.46567e-32 iter/s, 2.113s/100 iters), loss = 2.3079
I1006 20:10:36.564741  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 2.3079 (* 1 = 2.3079 loss)
I1006 20:10:36.564784  3817 sgd_solver.cpp:105] Iteration 0, lr = 0.1
I1006 20:10:44.491076  3817 solver.cpp:218] Iteration 100 (12.6163 iter/s, 7.92627s/100 iters), loss = 1.62965
I1006 20:10:44.491109  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.62965 (* 1 = 1.62965 loss)
I1006 20:10:44.491127  3817 sgd_solver.cpp:105] Iteration 100, lr = 0.1
I1006 20:10:52.413449  3817 solver.cpp:218] Iteration 200 (12.6226 iter/s, 7.92228s/100 iters), loss = 1.73242
I1006 20:10:52.413480  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.73242 (* 1 = 1.73242 loss)
I1006 20:10:52.413498  3817 sgd_solver.cpp:105] Iteration 200, lr = 0.1
I1006 20:11:00.328939  3817 solver.cpp:218] Iteration 300 (12.6336 iter/s, 7.91539s/100 iters), loss = 1.24901
I1006 20:11:00.328970  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.24901 (* 1 = 1.24901 loss)
I1006 20:11:00.328989  3817 sgd_solver.cpp:105] Iteration 300, lr = 0.1
I1006 20:11:08.250272  3817 solver.cpp:218] Iteration 400 (12.6243 iter/s, 7.92124s/100 iters), loss = 1.14332
I1006 20:11:08.250349  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.14332 (* 1 = 1.14332 loss)
I1006 20:11:08.250358  3817 sgd_solver.cpp:105] Iteration 400, lr = 0.1
I1006 20:11:15.785758  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:11:16.104825  3817 solver.cpp:330] Iteration 500, Testing net (#0)
I1006 20:11:17.976186  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:11:18.054066  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.3101
I1006 20:11:18.054093  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 3.21336 (* 1 = 3.21336 loss)
I1006 20:11:18.133518  3817 solver.cpp:218] Iteration 500 (10.1183 iter/s, 9.88309s/100 iters), loss = 1.21852
I1006 20:11:18.133546  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.21852 (* 1 = 1.21852 loss)
I1006 20:11:18.133556  3817 sgd_solver.cpp:105] Iteration 500, lr = 0.1
I1006 20:11:26.066792  3817 solver.cpp:218] Iteration 600 (12.6053 iter/s, 7.93318s/100 iters), loss = 1.03293
I1006 20:11:26.066823  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.03293 (* 1 = 1.03293 loss)
I1006 20:11:26.066840  3817 sgd_solver.cpp:105] Iteration 600, lr = 0.1
I1006 20:11:34.004876  3817 solver.cpp:218] Iteration 700 (12.5977 iter/s, 7.93799s/100 iters), loss = 1.19124
I1006 20:11:34.004912  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.19124 (* 1 = 1.19124 loss)
I1006 20:11:34.004920  3817 sgd_solver.cpp:105] Iteration 700, lr = 0.1
I1006 20:11:41.927088  3817 solver.cpp:218] Iteration 800 (12.6229 iter/s, 7.92212s/100 iters), loss = 1.11789
I1006 20:11:41.927177  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.11789 (* 1 = 1.11789 loss)
I1006 20:11:41.927188  3817 sgd_solver.cpp:105] Iteration 800, lr = 0.1
I1006 20:11:49.862969  3817 solver.cpp:218] Iteration 900 (12.6012 iter/s, 7.93574s/100 iters), loss = 0.895984
I1006 20:11:49.863000  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.895984 (* 1 = 0.895984 loss)
I1006 20:11:49.863009  3817 sgd_solver.cpp:105] Iteration 900, lr = 0.1
I1006 20:11:57.396477  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:11:57.714125  3817 solver.cpp:330] Iteration 1000, Testing net (#0)
I1006 20:11:59.585747  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:11:59.663882  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.3802
I1006 20:11:59.663908  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 2.35676 (* 1 = 2.35676 loss)
I1006 20:11:59.743636  3817 solver.cpp:218] Iteration 1000 (10.1209 iter/s, 9.88056s/100 iters), loss = 0.955844
I1006 20:11:59.743664  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.955844 (* 1 = 0.955844 loss)
I1006 20:11:59.743683  3817 sgd_solver.cpp:105] Iteration 1000, lr = 0.1
I1006 20:12:07.682976  3817 solver.cpp:218] Iteration 1100 (12.5956 iter/s, 7.93925s/100 iters), loss = 0.730971
I1006 20:12:07.683008  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.730971 (* 1 = 0.730971 loss)
I1006 20:12:07.683017  3817 sgd_solver.cpp:105] Iteration 1100, lr = 0.1
I1006 20:12:15.615053  3817 solver.cpp:218] Iteration 1200 (12.6072 iter/s, 7.93199s/100 iters), loss = 0.831154
I1006 20:12:15.615186  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.831154 (* 1 = 0.831154 loss)
I1006 20:12:15.615207  3817 sgd_solver.cpp:105] Iteration 1200, lr = 0.1
I1006 20:12:23.557605  3817 solver.cpp:218] Iteration 1300 (12.5907 iter/s, 7.94237s/100 iters), loss = 0.764208
I1006 20:12:23.557636  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.764208 (* 1 = 0.764208 loss)
I1006 20:12:23.557656  3817 sgd_solver.cpp:105] Iteration 1300, lr = 0.1
I1006 20:12:31.491590  3817 solver.cpp:218] Iteration 1400 (12.6041 iter/s, 7.9339s/100 iters), loss = 0.718283
I1006 20:12:31.491623  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.718283 (* 1 = 0.718283 loss)
I1006 20:12:31.491641  3817 sgd_solver.cpp:105] Iteration 1400, lr = 0.1
I1006 20:12:39.039605  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:12:39.358352  3817 solver.cpp:330] Iteration 1500, Testing net (#0)
I1006 20:12:41.230931  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:12:41.308894  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.4895
I1006 20:12:41.308923  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.57152 (* 1 = 1.57152 loss)
I1006 20:12:41.388535  3817 solver.cpp:218] Iteration 1500 (10.1042 iter/s, 9.89685s/100 iters), loss = 0.732345
I1006 20:12:41.388564  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.732345 (* 1 = 0.732345 loss)
I1006 20:12:41.388573  3817 sgd_solver.cpp:105] Iteration 1500, lr = 0.1
I1006 20:12:49.326776  3817 solver.cpp:218] Iteration 1600 (12.5974 iter/s, 7.93816s/100 iters), loss = 0.646984
I1006 20:12:49.326864  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.646984 (* 1 = 0.646984 loss)
I1006 20:12:49.326884  3817 sgd_solver.cpp:105] Iteration 1600, lr = 0.1
I1006 20:12:57.267047  3817 solver.cpp:218] Iteration 1700 (12.5942 iter/s, 7.94015s/100 iters), loss = 0.606299
I1006 20:12:57.267081  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.606299 (* 1 = 0.606299 loss)
I1006 20:12:57.267089  3817 sgd_solver.cpp:105] Iteration 1700, lr = 0.1
I1006 20:13:05.208730  3817 solver.cpp:218] Iteration 1800 (12.5919 iter/s, 7.94161s/100 iters), loss = 0.67338
I1006 20:13:05.208763  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.67338 (* 1 = 0.67338 loss)
I1006 20:13:05.208781  3817 sgd_solver.cpp:105] Iteration 1800, lr = 0.1
I1006 20:13:13.154789  3817 solver.cpp:218] Iteration 1900 (12.585 iter/s, 7.94599s/100 iters), loss = 0.480971
I1006 20:13:13.154822  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.480971 (* 1 = 0.480971 loss)
I1006 20:13:13.154840  3817 sgd_solver.cpp:105] Iteration 1900, lr = 0.1
I1006 20:13:20.701491  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:13:21.020081  3817 solver.cpp:330] Iteration 2000, Testing net (#0)
I1006 20:13:22.894639  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:13:22.972753  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.5658
I1006 20:13:22.972779  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.26433 (* 1 = 1.26433 loss)
I1006 20:13:23.052098  3817 solver.cpp:218] Iteration 2000 (10.1038 iter/s, 9.89723s/100 iters), loss = 0.73238
I1006 20:13:23.052132  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.73238 (* 1 = 0.73238 loss)
I1006 20:13:23.052141  3817 sgd_solver.cpp:105] Iteration 2000, lr = 0.1
I1006 20:13:30.998513  3817 solver.cpp:218] Iteration 2100 (12.5844 iter/s, 7.94634s/100 iters), loss = 0.581817
I1006 20:13:30.998551  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.581817 (* 1 = 0.581817 loss)
I1006 20:13:30.998560  3817 sgd_solver.cpp:105] Iteration 2100, lr = 0.1
I1006 20:13:38.941108  3817 solver.cpp:218] Iteration 2200 (12.5905 iter/s, 7.94252s/100 iters), loss = 0.707243
I1006 20:13:38.941140  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.707243 (* 1 = 0.707243 loss)
I1006 20:13:38.941148  3817 sgd_solver.cpp:105] Iteration 2200, lr = 0.1
I1006 20:13:46.888854  3817 solver.cpp:218] Iteration 2300 (12.5823 iter/s, 7.94768s/100 iters), loss = 0.600074
I1006 20:13:46.888885  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.600074 (* 1 = 0.600074 loss)
I1006 20:13:46.888907  3817 sgd_solver.cpp:105] Iteration 2300, lr = 0.1
I1006 20:13:54.838497  3817 solver.cpp:218] Iteration 2400 (12.5793 iter/s, 7.94958s/100 iters), loss = 0.495677
I1006 20:13:54.838639  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.495677 (* 1 = 0.495677 loss)
I1006 20:13:54.838665  3817 sgd_solver.cpp:105] Iteration 2400, lr = 0.1
I1006 20:14:02.398150  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:14:02.716513  3817 solver.cpp:330] Iteration 2500, Testing net (#0)
I1006 20:14:04.589112  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:14:04.667348  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6651
I1006 20:14:04.667374  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.03418 (* 1 = 1.03418 loss)
I1006 20:14:04.747066  3817 solver.cpp:218] Iteration 2500 (10.0925 iter/s, 9.90839s/100 iters), loss = 0.605203
I1006 20:14:04.747094  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.605203 (* 1 = 0.605203 loss)
I1006 20:14:04.747104  3817 sgd_solver.cpp:105] Iteration 2500, lr = 0.1
I1006 20:14:12.688519  3817 solver.cpp:218] Iteration 2600 (12.5923 iter/s, 7.94139s/100 iters), loss = 0.48363
I1006 20:14:12.688551  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.48363 (* 1 = 0.48363 loss)
I1006 20:14:12.688570  3817 sgd_solver.cpp:105] Iteration 2600, lr = 0.1
I1006 20:14:20.632117  3817 solver.cpp:218] Iteration 2700 (12.5889 iter/s, 7.94353s/100 iters), loss = 0.524742
I1006 20:14:20.632148  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.524742 (* 1 = 0.524742 loss)
I1006 20:14:20.632156  3817 sgd_solver.cpp:105] Iteration 2700, lr = 0.1
I1006 20:14:28.582177  3817 solver.cpp:218] Iteration 2800 (12.5786 iter/s, 7.95s/100 iters), loss = 0.520132
I1006 20:14:28.582304  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.520132 (* 1 = 0.520132 loss)
I1006 20:14:28.582312  3817 sgd_solver.cpp:105] Iteration 2800, lr = 0.1
I1006 20:14:36.529997  3817 solver.cpp:218] Iteration 2900 (12.5823 iter/s, 7.94766s/100 iters), loss = 0.40668
I1006 20:14:36.530030  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.40668 (* 1 = 0.40668 loss)
I1006 20:14:36.530038  3817 sgd_solver.cpp:105] Iteration 2900, lr = 0.1
I1006 20:14:44.071810  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:14:44.389856  3817 solver.cpp:330] Iteration 3000, Testing net (#0)
I1006 20:14:46.264344  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:14:46.342849  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.646
I1006 20:14:46.342876  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.07258 (* 1 = 1.07258 loss)
I1006 20:14:46.422632  3817 solver.cpp:218] Iteration 3000 (10.1086 iter/s, 9.89256s/100 iters), loss = 0.521901
I1006 20:14:46.422662  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.521901 (* 1 = 0.521901 loss)
I1006 20:14:46.422672  3817 sgd_solver.cpp:105] Iteration 3000, lr = 0.1
I1006 20:14:54.375874  3817 solver.cpp:218] Iteration 3100 (12.5736 iter/s, 7.95317s/100 iters), loss = 0.425337
I1006 20:14:54.375907  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.425337 (* 1 = 0.425337 loss)
I1006 20:14:54.375916  3817 sgd_solver.cpp:105] Iteration 3100, lr = 0.1
I1006 20:15:02.325426  3817 solver.cpp:218] Iteration 3200 (12.5794 iter/s, 7.94949s/100 iters), loss = 0.437849
I1006 20:15:02.325575  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.437849 (* 1 = 0.437849 loss)
I1006 20:15:02.325587  3817 sgd_solver.cpp:105] Iteration 3200, lr = 0.1
I1006 20:15:10.285696  3817 solver.cpp:218] Iteration 3300 (12.5627 iter/s, 7.96009s/100 iters), loss = 0.489091
I1006 20:15:10.285727  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.489091 (* 1 = 0.489091 loss)
I1006 20:15:10.285746  3817 sgd_solver.cpp:105] Iteration 3300, lr = 0.1
I1006 20:15:18.237462  3817 solver.cpp:218] Iteration 3400 (12.5759 iter/s, 7.9517s/100 iters), loss = 0.421741
I1006 20:15:18.237494  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.421741 (* 1 = 0.421741 loss)
I1006 20:15:18.237512  3817 sgd_solver.cpp:105] Iteration 3400, lr = 0.1
I1006 20:15:25.793083  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:15:26.112380  3817 solver.cpp:330] Iteration 3500, Testing net (#0)
I1006 20:15:27.986599  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:15:28.065059  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.5158
I1006 20:15:28.065086  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.45392 (* 1 = 1.45392 loss)
I1006 20:15:28.144929  3817 solver.cpp:218] Iteration 3500 (10.0935 iter/s, 9.9074s/100 iters), loss = 0.351457
I1006 20:15:28.144958  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.351457 (* 1 = 0.351457 loss)
I1006 20:15:28.144968  3817 sgd_solver.cpp:105] Iteration 3500, lr = 0.1
I1006 20:15:36.087788  3817 solver.cpp:218] Iteration 3600 (12.59 iter/s, 7.94279s/100 iters), loss = 0.386674
I1006 20:15:36.087888  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.386674 (* 1 = 0.386674 loss)
I1006 20:15:36.087898  3817 sgd_solver.cpp:105] Iteration 3600, lr = 0.1
I1006 20:15:44.034783  3817 solver.cpp:218] Iteration 3700 (12.5836 iter/s, 7.94686s/100 iters), loss = 0.483987
I1006 20:15:44.034816  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.483987 (* 1 = 0.483987 loss)
I1006 20:15:44.034834  3817 sgd_solver.cpp:105] Iteration 3700, lr = 0.1
I1006 20:15:51.979374  3817 solver.cpp:218] Iteration 3800 (12.5873 iter/s, 7.94453s/100 iters), loss = 0.507153
I1006 20:15:51.979408  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.507153 (* 1 = 0.507153 loss)
I1006 20:15:51.979425  3817 sgd_solver.cpp:105] Iteration 3800, lr = 0.1
I1006 20:15:59.926823  3817 solver.cpp:218] Iteration 3900 (12.5828 iter/s, 7.94738s/100 iters), loss = 0.424206
I1006 20:15:59.926856  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.424206 (* 1 = 0.424206 loss)
I1006 20:15:59.926874  3817 sgd_solver.cpp:105] Iteration 3900, lr = 0.1
I1006 20:16:07.470789  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:16:07.788462  3817 solver.cpp:330] Iteration 4000, Testing net (#0)
I1006 20:16:09.662845  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:16:09.741094  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.5493
I1006 20:16:09.741122  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.47398 (* 1 = 1.47398 loss)
I1006 20:16:09.820868  3817 solver.cpp:218] Iteration 4000 (10.1072 iter/s, 9.89397s/100 iters), loss = 0.405697
I1006 20:16:09.820899  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.405697 (* 1 = 0.405697 loss)
I1006 20:16:09.820909  3817 sgd_solver.cpp:105] Iteration 4000, lr = 0.1
I1006 20:16:17.779753  3817 solver.cpp:218] Iteration 4100 (12.5647 iter/s, 7.95882s/100 iters), loss = 0.35781
I1006 20:16:17.779786  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.35781 (* 1 = 0.35781 loss)
I1006 20:16:17.779805  3817 sgd_solver.cpp:105] Iteration 4100, lr = 0.1
I1006 20:16:25.721591  3817 solver.cpp:218] Iteration 4200 (12.5916 iter/s, 7.94177s/100 iters), loss = 0.372446
I1006 20:16:25.721622  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.372446 (* 1 = 0.372446 loss)
I1006 20:16:25.721632  3817 sgd_solver.cpp:105] Iteration 4200, lr = 0.1
I1006 20:16:33.674110  3817 solver.cpp:218] Iteration 4300 (12.5747 iter/s, 7.95246s/100 iters), loss = 0.438085
I1006 20:16:33.674141  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.438085 (* 1 = 0.438085 loss)
I1006 20:16:33.674150  3817 sgd_solver.cpp:105] Iteration 4300, lr = 0.1
I1006 20:16:41.613977  3817 solver.cpp:218] Iteration 4400 (12.5948 iter/s, 7.9398s/100 iters), loss = 0.371072
I1006 20:16:41.614120  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.371072 (* 1 = 0.371072 loss)
I1006 20:16:41.614151  3817 sgd_solver.cpp:105] Iteration 4400, lr = 0.1
I1006 20:16:49.164769  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:16:49.483392  3817 solver.cpp:330] Iteration 4500, Testing net (#0)
I1006 20:16:51.357499  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:16:51.435796  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.4209
I1006 20:16:51.435822  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 2.07506 (* 1 = 2.07506 loss)
I1006 20:16:51.515231  3817 solver.cpp:218] Iteration 4500 (10.0999 iter/s, 9.90108s/100 iters), loss = 0.415066
I1006 20:16:51.515260  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.415066 (* 1 = 0.415066 loss)
I1006 20:16:51.515269  3817 sgd_solver.cpp:105] Iteration 4500, lr = 0.1
I1006 20:16:59.472419  3817 solver.cpp:218] Iteration 4600 (12.5674 iter/s, 7.95713s/100 iters), loss = 0.371567
I1006 20:16:59.472450  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.371567 (* 1 = 0.371567 loss)
I1006 20:16:59.472458  3817 sgd_solver.cpp:105] Iteration 4600, lr = 0.1
I1006 20:17:07.435421  3817 solver.cpp:218] Iteration 4700 (12.5582 iter/s, 7.96294s/100 iters), loss = 0.40186
I1006 20:17:07.435454  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.40186 (* 1 = 0.40186 loss)
I1006 20:17:07.435462  3817 sgd_solver.cpp:105] Iteration 4700, lr = 0.1
I1006 20:17:15.387357  3817 solver.cpp:218] Iteration 4800 (12.5757 iter/s, 7.95187s/100 iters), loss = 0.426575
I1006 20:17:15.387473  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.426575 (* 1 = 0.426575 loss)
I1006 20:17:15.387482  3817 sgd_solver.cpp:105] Iteration 4800, lr = 0.1
I1006 20:17:23.349685  3817 solver.cpp:218] Iteration 4900 (12.5594 iter/s, 7.96219s/100 iters), loss = 0.452512
I1006 20:17:23.349717  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.452512 (* 1 = 0.452512 loss)
I1006 20:17:23.349725  3817 sgd_solver.cpp:105] Iteration 4900, lr = 0.1
I1006 20:17:30.914032  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:17:31.232013  3817 solver.cpp:330] Iteration 5000, Testing net (#0)
I1006 20:17:33.106438  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:17:33.184636  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.2149
I1006 20:17:33.184664  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 5.52211 (* 1 = 5.52211 loss)
I1006 20:17:33.264322  3817 solver.cpp:218] Iteration 5000 (10.0862 iter/s, 9.91456s/100 iters), loss = 0.35398
I1006 20:17:33.264356  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.35398 (* 1 = 0.35398 loss)
I1006 20:17:33.264365  3817 sgd_solver.cpp:105] Iteration 5000, lr = 0.1
I1006 20:17:41.217870  3817 solver.cpp:218] Iteration 5100 (12.5731 iter/s, 7.95348s/100 iters), loss = 0.28931
I1006 20:17:41.217907  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.28931 (* 1 = 0.28931 loss)
I1006 20:17:41.217926  3817 sgd_solver.cpp:105] Iteration 5100, lr = 0.1
I1006 20:17:49.165567  3817 solver.cpp:218] Iteration 5200 (12.5824 iter/s, 7.94763s/100 iters), loss = 0.378718
I1006 20:17:49.165702  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.378718 (* 1 = 0.378718 loss)
I1006 20:17:49.165722  3817 sgd_solver.cpp:105] Iteration 5200, lr = 0.1
I1006 20:17:57.114087  3817 solver.cpp:218] Iteration 5300 (12.5812 iter/s, 7.94836s/100 iters), loss = 0.400604
I1006 20:17:57.114120  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.400604 (* 1 = 0.400604 loss)
I1006 20:17:57.114127  3817 sgd_solver.cpp:105] Iteration 5300, lr = 0.1
I1006 20:18:05.065508  3817 solver.cpp:218] Iteration 5400 (12.5765 iter/s, 7.95136s/100 iters), loss = 0.31649
I1006 20:18:05.065541  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.31649 (* 1 = 0.31649 loss)
I1006 20:18:05.065558  3817 sgd_solver.cpp:105] Iteration 5400, lr = 0.1
I1006 20:18:12.622419  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:18:12.940066  3817 solver.cpp:330] Iteration 5500, Testing net (#0)
I1006 20:18:14.812032  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:18:14.889804  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.5577
I1006 20:18:14.889832  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.51677 (* 1 = 1.51677 loss)
I1006 20:18:14.969708  3817 solver.cpp:218] Iteration 5500 (10.0968 iter/s, 9.90413s/100 iters), loss = 0.338533
I1006 20:18:14.969735  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.338533 (* 1 = 0.338533 loss)
I1006 20:18:14.969745  3817 sgd_solver.cpp:105] Iteration 5500, lr = 0.1
I1006 20:18:22.918642  3817 solver.cpp:218] Iteration 5600 (12.5804 iter/s, 7.94888s/100 iters), loss = 0.337758
I1006 20:18:22.918730  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.337758 (* 1 = 0.337758 loss)
I1006 20:18:22.918748  3817 sgd_solver.cpp:105] Iteration 5600, lr = 0.1
I1006 20:18:30.874630  3817 solver.cpp:218] Iteration 5700 (12.5693 iter/s, 7.95588s/100 iters), loss = 0.366125
I1006 20:18:30.874662  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.366125 (* 1 = 0.366125 loss)
I1006 20:18:30.874670  3817 sgd_solver.cpp:105] Iteration 5700, lr = 0.1
I1006 20:18:38.830907  3817 solver.cpp:218] Iteration 5800 (12.5688 iter/s, 7.95621s/100 iters), loss = 0.394237
I1006 20:18:38.830940  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.394237 (* 1 = 0.394237 loss)
I1006 20:18:38.830947  3817 sgd_solver.cpp:105] Iteration 5800, lr = 0.1
I1006 20:18:46.787223  3817 solver.cpp:218] Iteration 5900 (12.5687 iter/s, 7.95625s/100 iters), loss = 0.312961
I1006 20:18:46.787256  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.312961 (* 1 = 0.312961 loss)
I1006 20:18:46.787264  3817 sgd_solver.cpp:105] Iteration 5900, lr = 0.1
I1006 20:18:54.340487  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:18:54.658572  3817 solver.cpp:330] Iteration 6000, Testing net (#0)
I1006 20:18:56.532896  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:18:56.611320  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6545
I1006 20:18:56.611346  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.10169 (* 1 = 1.10169 loss)
I1006 20:18:56.690806  3817 solver.cpp:218] Iteration 6000 (10.0974 iter/s, 9.90352s/100 iters), loss = 0.423996
I1006 20:18:56.690834  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.423996 (* 1 = 0.423996 loss)
I1006 20:18:56.690843  3817 sgd_solver.cpp:105] Iteration 6000, lr = 0.1
I1006 20:19:04.644876  3817 solver.cpp:218] Iteration 6100 (12.5723 iter/s, 7.95401s/100 iters), loss = 0.36018
I1006 20:19:04.644909  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.36018 (* 1 = 0.36018 loss)
I1006 20:19:04.644918  3817 sgd_solver.cpp:105] Iteration 6100, lr = 0.1
I1006 20:19:12.595142  3817 solver.cpp:218] Iteration 6200 (12.5783 iter/s, 7.9502s/100 iters), loss = 0.4727
I1006 20:19:12.595178  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.4727 (* 1 = 0.4727 loss)
I1006 20:19:12.595187  3817 sgd_solver.cpp:105] Iteration 6200, lr = 0.1
I1006 20:19:20.541978  3817 solver.cpp:218] Iteration 6300 (12.5837 iter/s, 7.94677s/100 iters), loss = 0.323442
I1006 20:19:20.542011  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.323442 (* 1 = 0.323442 loss)
I1006 20:19:20.542018  3817 sgd_solver.cpp:105] Iteration 6300, lr = 0.1
I1006 20:19:28.489641  3817 solver.cpp:218] Iteration 6400 (12.5824 iter/s, 7.9476s/100 iters), loss = 0.373334
I1006 20:19:28.489760  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.373334 (* 1 = 0.373334 loss)
I1006 20:19:28.489783  3817 sgd_solver.cpp:105] Iteration 6400, lr = 0.1
I1006 20:19:36.044059  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:19:36.362149  3817 solver.cpp:330] Iteration 6500, Testing net (#0)
I1006 20:19:38.236116  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:19:38.314642  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.5787
I1006 20:19:38.314669  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.59653 (* 1 = 1.59653 loss)
I1006 20:19:38.394384  3817 solver.cpp:218] Iteration 6500 (10.0963 iter/s, 9.90459s/100 iters), loss = 0.283278
I1006 20:19:38.394413  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.283278 (* 1 = 0.283278 loss)
I1006 20:19:38.394423  3817 sgd_solver.cpp:105] Iteration 6500, lr = 0.1
I1006 20:19:46.344980  3817 solver.cpp:218] Iteration 6600 (12.5778 iter/s, 7.95054s/100 iters), loss = 0.27629
I1006 20:19:46.345010  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.27629 (* 1 = 0.27629 loss)
I1006 20:19:46.345019  3817 sgd_solver.cpp:105] Iteration 6600, lr = 0.1
I1006 20:19:54.300814  3817 solver.cpp:218] Iteration 6700 (12.5695 iter/s, 7.95577s/100 iters), loss = 0.294328
I1006 20:19:54.300848  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.294328 (* 1 = 0.294328 loss)
I1006 20:19:54.300866  3817 sgd_solver.cpp:105] Iteration 6700, lr = 0.1
I1006 20:20:02.250289  3817 solver.cpp:218] Iteration 6800 (12.5795 iter/s, 7.94941s/100 iters), loss = 0.428771
I1006 20:20:02.250432  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.428771 (* 1 = 0.428771 loss)
I1006 20:20:02.250455  3817 sgd_solver.cpp:105] Iteration 6800, lr = 0.1
I1006 20:20:10.203361  3817 solver.cpp:218] Iteration 6900 (12.574 iter/s, 7.9529s/100 iters), loss = 0.367892
I1006 20:20:10.203393  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.367892 (* 1 = 0.367892 loss)
I1006 20:20:10.203402  3817 sgd_solver.cpp:105] Iteration 6900, lr = 0.1
I1006 20:20:17.763048  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:20:18.081504  3817 solver.cpp:330] Iteration 7000, Testing net (#0)
I1006 20:20:19.955582  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:20:20.033985  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6544
I1006 20:20:20.034011  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.0126 (* 1 = 1.0126 loss)
I1006 20:20:20.113656  3817 solver.cpp:218] Iteration 7000 (10.0906 iter/s, 9.91023s/100 iters), loss = 0.208703
I1006 20:20:20.113683  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.208703 (* 1 = 0.208703 loss)
I1006 20:20:20.113692  3817 sgd_solver.cpp:105] Iteration 7000, lr = 0.1
I1006 20:20:28.073928  3817 solver.cpp:218] Iteration 7100 (12.5625 iter/s, 7.96021s/100 iters), loss = 0.328979
I1006 20:20:28.073961  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.328979 (* 1 = 0.328979 loss)
I1006 20:20:28.073969  3817 sgd_solver.cpp:105] Iteration 7100, lr = 0.1
I1006 20:20:36.024526  3817 solver.cpp:218] Iteration 7200 (12.5778 iter/s, 7.95054s/100 iters), loss = 0.287403
I1006 20:20:36.024612  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.287403 (* 1 = 0.287403 loss)
I1006 20:20:36.024632  3817 sgd_solver.cpp:105] Iteration 7200, lr = 0.1
I1006 20:20:43.977634  3817 solver.cpp:218] Iteration 7300 (12.5739 iter/s, 7.953s/100 iters), loss = 0.374262
I1006 20:20:43.977665  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.374262 (* 1 = 0.374262 loss)
I1006 20:20:43.977674  3817 sgd_solver.cpp:105] Iteration 7300, lr = 0.1
I1006 20:20:51.921644  3817 solver.cpp:218] Iteration 7400 (12.5882 iter/s, 7.94395s/100 iters), loss = 0.247864
I1006 20:20:51.921677  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.247864 (* 1 = 0.247864 loss)
I1006 20:20:51.921695  3817 sgd_solver.cpp:105] Iteration 7400, lr = 0.1
I1006 20:20:59.477145  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:20:59.795553  3817 solver.cpp:330] Iteration 7500, Testing net (#0)
I1006 20:21:01.668568  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:21:01.746976  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.685
I1006 20:21:01.747004  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.97674 (* 1 = 0.97674 loss)
I1006 20:21:01.826391  3817 solver.cpp:218] Iteration 7500 (10.0962 iter/s, 9.90468s/100 iters), loss = 0.275137
I1006 20:21:01.826421  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.275137 (* 1 = 0.275137 loss)
I1006 20:21:01.826431  3817 sgd_solver.cpp:105] Iteration 7500, lr = 0.1
I1006 20:21:09.770534  3817 solver.cpp:218] Iteration 7600 (12.588 iter/s, 7.94408s/100 iters), loss = 0.303328
I1006 20:21:09.770674  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.303327 (* 1 = 0.303327 loss)
I1006 20:21:09.770695  3817 sgd_solver.cpp:105] Iteration 7600, lr = 0.1
I1006 20:21:17.718727  3817 solver.cpp:218] Iteration 7700 (12.5817 iter/s, 7.94803s/100 iters), loss = 0.322852
I1006 20:21:17.718760  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.322852 (* 1 = 0.322852 loss)
I1006 20:21:17.718770  3817 sgd_solver.cpp:105] Iteration 7700, lr = 0.1
I1006 20:21:25.662976  3817 solver.cpp:218] Iteration 7800 (12.5878 iter/s, 7.94419s/100 iters), loss = 0.383564
I1006 20:21:25.663008  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.383564 (* 1 = 0.383564 loss)
I1006 20:21:25.663025  3817 sgd_solver.cpp:105] Iteration 7800, lr = 0.1
I1006 20:21:33.609669  3817 solver.cpp:218] Iteration 7900 (12.5839 iter/s, 7.94663s/100 iters), loss = 0.454477
I1006 20:21:33.609701  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.454477 (* 1 = 0.454477 loss)
I1006 20:21:33.609710  3817 sgd_solver.cpp:105] Iteration 7900, lr = 0.1
I1006 20:21:41.161309  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:21:41.479887  3817 solver.cpp:330] Iteration 8000, Testing net (#0)
I1006 20:21:43.353875  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:21:43.431766  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6802
I1006 20:21:43.431792  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.07802 (* 1 = 1.07802 loss)
I1006 20:21:43.511566  3817 solver.cpp:218] Iteration 8000 (10.0991 iter/s, 9.90183s/100 iters), loss = 0.250277
I1006 20:21:43.511593  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.250277 (* 1 = 0.250277 loss)
I1006 20:21:43.511603  3817 sgd_solver.cpp:105] Iteration 8000, lr = 0.1
I1006 20:21:51.470782  3817 solver.cpp:218] Iteration 8100 (12.5641 iter/s, 7.95916s/100 iters), loss = 0.427667
I1006 20:21:51.470813  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.427667 (* 1 = 0.427667 loss)
I1006 20:21:51.470823  3817 sgd_solver.cpp:105] Iteration 8100, lr = 0.1
I1006 20:21:59.425103  3817 solver.cpp:218] Iteration 8200 (12.5719 iter/s, 7.95426s/100 iters), loss = 0.3191
I1006 20:21:59.425137  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.3191 (* 1 = 0.3191 loss)
I1006 20:21:59.425155  3817 sgd_solver.cpp:105] Iteration 8200, lr = 0.1
I1006 20:22:07.377966  3817 solver.cpp:218] Iteration 8300 (12.5742 iter/s, 7.9528s/100 iters), loss = 0.304995
I1006 20:22:07.377998  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.304995 (* 1 = 0.304995 loss)
I1006 20:22:07.378016  3817 sgd_solver.cpp:105] Iteration 8300, lr = 0.1
I1006 20:22:15.332752  3817 solver.cpp:218] Iteration 8400 (12.5711 iter/s, 7.95472s/100 iters), loss = 0.202962
I1006 20:22:15.332895  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.202962 (* 1 = 0.202962 loss)
I1006 20:22:15.332903  3817 sgd_solver.cpp:105] Iteration 8400, lr = 0.1
I1006 20:22:22.890970  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:22:23.210464  3817 solver.cpp:330] Iteration 8500, Testing net (#0)
I1006 20:22:25.083715  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:22:25.161777  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6749
I1006 20:22:25.161803  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.997597 (* 1 = 0.997597 loss)
I1006 20:22:25.241773  3817 solver.cpp:218] Iteration 8500 (10.092 iter/s, 9.90886s/100 iters), loss = 0.280853
I1006 20:22:25.241802  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.280852 (* 1 = 0.280852 loss)
I1006 20:22:25.241809  3817 sgd_solver.cpp:105] Iteration 8500, lr = 0.1
I1006 20:22:33.190412  3817 solver.cpp:218] Iteration 8600 (12.5809 iter/s, 7.94858s/100 iters), loss = 0.298538
I1006 20:22:33.190451  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.298538 (* 1 = 0.298538 loss)
I1006 20:22:33.190457  3817 sgd_solver.cpp:105] Iteration 8600, lr = 0.1
I1006 20:22:41.143023  3817 solver.cpp:218] Iteration 8700 (12.5746 iter/s, 7.95254s/100 iters), loss = 0.338383
I1006 20:22:41.143052  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.338383 (* 1 = 0.338383 loss)
I1006 20:22:41.143069  3817 sgd_solver.cpp:105] Iteration 8700, lr = 0.1
I1006 20:22:49.093372  3817 solver.cpp:218] Iteration 8800 (12.5782 iter/s, 7.95029s/100 iters), loss = 0.362305
I1006 20:22:49.093468  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.362305 (* 1 = 0.362305 loss)
I1006 20:22:49.093487  3817 sgd_solver.cpp:105] Iteration 8800, lr = 0.1
I1006 20:22:57.048919  3817 solver.cpp:218] Iteration 8900 (12.57 iter/s, 7.95542s/100 iters), loss = 0.317321
I1006 20:22:57.048949  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.317321 (* 1 = 0.317321 loss)
I1006 20:22:57.048966  3817 sgd_solver.cpp:105] Iteration 8900, lr = 0.1
I1006 20:23:04.607812  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:23:04.925843  3817 solver.cpp:330] Iteration 9000, Testing net (#0)
I1006 20:23:06.798720  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:23:06.877365  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7357
I1006 20:23:06.877391  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.897211 (* 1 = 0.897211 loss)
I1006 20:23:06.957099  3817 solver.cpp:218] Iteration 9000 (10.0927 iter/s, 9.90812s/100 iters), loss = 0.221233
I1006 20:23:06.957124  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.221233 (* 1 = 0.221233 loss)
I1006 20:23:06.957130  3817 sgd_solver.cpp:105] Iteration 9000, lr = 0.1
I1006 20:23:14.912773  3817 solver.cpp:218] Iteration 9100 (12.5697 iter/s, 7.95562s/100 iters), loss = 0.256851
I1006 20:23:14.912813  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.256851 (* 1 = 0.256851 loss)
I1006 20:23:14.912820  3817 sgd_solver.cpp:105] Iteration 9100, lr = 0.1
I1006 20:23:22.864203  3817 solver.cpp:218] Iteration 9200 (12.5765 iter/s, 7.95136s/100 iters), loss = 0.265394
I1006 20:23:22.864302  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.265394 (* 1 = 0.265394 loss)
I1006 20:23:22.864310  3817 sgd_solver.cpp:105] Iteration 9200, lr = 0.1
I1006 20:23:30.817268  3817 solver.cpp:218] Iteration 9300 (12.574 iter/s, 7.95294s/100 iters), loss = 0.257442
I1006 20:23:30.817299  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.257442 (* 1 = 0.257442 loss)
I1006 20:23:30.817306  3817 sgd_solver.cpp:105] Iteration 9300, lr = 0.1
I1006 20:23:38.773167  3817 solver.cpp:218] Iteration 9400 (12.5694 iter/s, 7.95584s/100 iters), loss = 0.220196
I1006 20:23:38.773205  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.220196 (* 1 = 0.220196 loss)
I1006 20:23:38.773211  3817 sgd_solver.cpp:105] Iteration 9400, lr = 0.1
I1006 20:23:46.343802  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:23:46.663079  3817 solver.cpp:330] Iteration 9500, Testing net (#0)
I1006 20:23:48.536514  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:23:48.614933  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6939
I1006 20:23:48.614967  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.00697 (* 1 = 1.00697 loss)
I1006 20:23:48.694903  3817 solver.cpp:218] Iteration 9500 (10.079 iter/s, 9.92167s/100 iters), loss = 0.172564
I1006 20:23:48.694927  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.172564 (* 1 = 0.172564 loss)
I1006 20:23:48.694933  3817 sgd_solver.cpp:105] Iteration 9500, lr = 0.1
I1006 20:23:56.639391  3817 solver.cpp:218] Iteration 9600 (12.5874 iter/s, 7.94444s/100 iters), loss = 0.27775
I1006 20:23:56.639513  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.27775 (* 1 = 0.27775 loss)
I1006 20:23:56.639521  3817 sgd_solver.cpp:105] Iteration 9600, lr = 0.1
I1006 20:24:04.591910  3817 solver.cpp:218] Iteration 9700 (12.5749 iter/s, 7.95237s/100 iters), loss = 0.253157
I1006 20:24:04.591950  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.253157 (* 1 = 0.253157 loss)
I1006 20:24:04.591956  3817 sgd_solver.cpp:105] Iteration 9700, lr = 0.1
I1006 20:24:12.538533  3817 solver.cpp:218] Iteration 9800 (12.5841 iter/s, 7.94656s/100 iters), loss = 0.284318
I1006 20:24:12.538563  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.284318 (* 1 = 0.284318 loss)
I1006 20:24:12.538569  3817 sgd_solver.cpp:105] Iteration 9800, lr = 0.1
I1006 20:24:20.489249  3817 solver.cpp:218] Iteration 9900 (12.5776 iter/s, 7.95066s/100 iters), loss = 0.255008
I1006 20:24:20.489279  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.255008 (* 1 = 0.255008 loss)
I1006 20:24:20.489284  3817 sgd_solver.cpp:105] Iteration 9900, lr = 0.1
I1006 20:24:28.111937  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:24:28.435046  3817 solver.cpp:330] Iteration 10000, Testing net (#0)
I1006 20:24:30.333806  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:24:30.413310  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.742
I1006 20:24:30.413345  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.832316 (* 1 = 0.832316 loss)
I1006 20:24:30.496587  3817 solver.cpp:218] Iteration 10000 (9.99273 iter/s, 10.0073s/100 iters), loss = 0.208078
I1006 20:24:30.496626  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.208078 (* 1 = 0.208078 loss)
I1006 20:24:30.496635  3817 sgd_solver.cpp:105] Iteration 10000, lr = 0.1
I1006 20:24:38.499581  3817 solver.cpp:218] Iteration 10100 (12.4956 iter/s, 8.00283s/100 iters), loss = 0.210827
I1006 20:24:38.499610  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.210827 (* 1 = 0.210827 loss)
I1006 20:24:38.499627  3817 sgd_solver.cpp:105] Iteration 10100, lr = 0.1
I1006 20:24:46.469900  3817 solver.cpp:218] Iteration 10200 (12.5466 iter/s, 7.97026s/100 iters), loss = 0.31784
I1006 20:24:46.469929  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.31784 (* 1 = 0.31784 loss)
I1006 20:24:46.469935  3817 sgd_solver.cpp:105] Iteration 10200, lr = 0.1
I1006 20:24:54.500068  3817 solver.cpp:218] Iteration 10300 (12.4531 iter/s, 8.03011s/100 iters), loss = 0.256424
I1006 20:24:54.500099  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.256424 (* 1 = 0.256424 loss)
I1006 20:24:54.500107  3817 sgd_solver.cpp:105] Iteration 10300, lr = 0.1
I1006 20:25:02.501757  3817 solver.cpp:218] Iteration 10400 (12.4975 iter/s, 8.00163s/100 iters), loss = 0.273666
I1006 20:25:02.501873  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.273665 (* 1 = 0.273665 loss)
I1006 20:25:02.501881  3817 sgd_solver.cpp:105] Iteration 10400, lr = 0.1
I1006 20:25:10.082916  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:25:10.400326  3817 solver.cpp:330] Iteration 10500, Testing net (#0)
I1006 20:25:12.296767  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:25:12.374675  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6259
I1006 20:25:12.374711  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.57128 (* 1 = 1.57128 loss)
I1006 20:25:12.454398  3817 solver.cpp:218] Iteration 10500 (10.0477 iter/s, 9.9525s/100 iters), loss = 0.27112
I1006 20:25:12.454422  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.27112 (* 1 = 0.27112 loss)
I1006 20:25:12.454429  3817 sgd_solver.cpp:105] Iteration 10500, lr = 0.1
I1006 20:25:20.474747  3817 solver.cpp:218] Iteration 10600 (12.4684 iter/s, 8.02029s/100 iters), loss = 0.287593
I1006 20:25:20.474779  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.287593 (* 1 = 0.287593 loss)
I1006 20:25:20.474786  3817 sgd_solver.cpp:105] Iteration 10600, lr = 0.1
I1006 20:25:28.452800  3817 solver.cpp:218] Iteration 10700 (12.5345 iter/s, 7.97799s/100 iters), loss = 0.213573
I1006 20:25:28.452831  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.213573 (* 1 = 0.213573 loss)
I1006 20:25:28.452837  3817 sgd_solver.cpp:105] Iteration 10700, lr = 0.1
I1006 20:25:36.518182  3817 solver.cpp:218] Iteration 10800 (12.3988 iter/s, 8.06532s/100 iters), loss = 0.278544
I1006 20:25:36.518319  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.278544 (* 1 = 0.278544 loss)
I1006 20:25:36.518327  3817 sgd_solver.cpp:105] Iteration 10800, lr = 0.1
I1006 20:25:44.489471  3817 solver.cpp:218] Iteration 10900 (12.5453 iter/s, 7.97113s/100 iters), loss = 0.313274
I1006 20:25:44.489513  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.313274 (* 1 = 0.313274 loss)
I1006 20:25:44.489519  3817 sgd_solver.cpp:105] Iteration 10900, lr = 0.1
I1006 20:25:52.095783  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:25:52.414229  3817 solver.cpp:330] Iteration 11000, Testing net (#0)
I1006 20:25:54.293587  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:25:54.371278  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7038
I1006 20:25:54.371312  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.914426 (* 1 = 0.914426 loss)
I1006 20:25:54.451514  3817 solver.cpp:218] Iteration 11000 (10.0382 iter/s, 9.96197s/100 iters), loss = 0.199992
I1006 20:25:54.451536  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.199992 (* 1 = 0.199992 loss)
I1006 20:25:54.451544  3817 sgd_solver.cpp:105] Iteration 11000, lr = 0.1
I1006 20:26:02.429556  3817 solver.cpp:218] Iteration 11100 (12.5345 iter/s, 7.97799s/100 iters), loss = 0.199091
I1006 20:26:02.429595  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.199091 (* 1 = 0.199091 loss)
I1006 20:26:02.429601  3817 sgd_solver.cpp:105] Iteration 11100, lr = 0.1
I1006 20:26:10.423203  3817 solver.cpp:218] Iteration 11200 (12.51 iter/s, 7.99358s/100 iters), loss = 0.291984
I1006 20:26:10.423348  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.291984 (* 1 = 0.291984 loss)
I1006 20:26:10.423357  3817 sgd_solver.cpp:105] Iteration 11200, lr = 0.1
I1006 20:26:18.405483  3817 solver.cpp:218] Iteration 11300 (12.528 iter/s, 7.98211s/100 iters), loss = 0.320708
I1006 20:26:18.405529  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.320708 (* 1 = 0.320708 loss)
I1006 20:26:18.405537  3817 sgd_solver.cpp:105] Iteration 11300, lr = 0.1
I1006 20:26:26.517215  3817 solver.cpp:218] Iteration 11400 (12.3279 iter/s, 8.11166s/100 iters), loss = 0.241965
I1006 20:26:26.517246  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.241964 (* 1 = 0.241964 loss)
I1006 20:26:26.517253  3817 sgd_solver.cpp:105] Iteration 11400, lr = 0.1
I1006 20:26:34.172693  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:26:34.491974  3817 solver.cpp:330] Iteration 11500, Testing net (#0)
I1006 20:26:36.369222  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:26:36.449028  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7482
I1006 20:26:36.449054  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.738466 (* 1 = 0.738466 loss)
I1006 20:26:36.528738  3817 solver.cpp:218] Iteration 11500 (9.98855 iter/s, 10.0115s/100 iters), loss = 0.19467
I1006 20:26:36.528762  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.19467 (* 1 = 0.19467 loss)
I1006 20:26:36.528769  3817 sgd_solver.cpp:105] Iteration 11500, lr = 0.1
I1006 20:26:44.532049  3817 solver.cpp:218] Iteration 11600 (12.4949 iter/s, 8.00326s/100 iters), loss = 0.196747
I1006 20:26:44.532156  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.196747 (* 1 = 0.196747 loss)
I1006 20:26:44.532165  3817 sgd_solver.cpp:105] Iteration 11600, lr = 0.1
I1006 20:26:52.575376  3817 solver.cpp:218] Iteration 11700 (12.4329 iter/s, 8.04319s/100 iters), loss = 0.194713
I1006 20:26:52.575405  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.194713 (* 1 = 0.194713 loss)
I1006 20:26:52.575412  3817 sgd_solver.cpp:105] Iteration 11700, lr = 0.1
I1006 20:27:00.551534  3817 solver.cpp:218] Iteration 11800 (12.5375 iter/s, 7.9761s/100 iters), loss = 0.246666
I1006 20:27:00.551574  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.246666 (* 1 = 0.246666 loss)
I1006 20:27:00.551581  3817 sgd_solver.cpp:105] Iteration 11800, lr = 0.1
I1006 20:27:08.574265  3817 solver.cpp:218] Iteration 11900 (12.4647 iter/s, 8.02266s/100 iters), loss = 0.233137
I1006 20:27:08.574306  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.233137 (* 1 = 0.233137 loss)
I1006 20:27:08.574311  3817 sgd_solver.cpp:105] Iteration 11900, lr = 0.1
I1006 20:27:16.182694  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:27:16.502862  3817 solver.cpp:330] Iteration 12000, Testing net (#0)
I1006 20:27:18.382182  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:27:18.460814  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6497
I1006 20:27:18.460849  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.2963 (* 1 = 1.2963 loss)
I1006 20:27:18.540707  3817 solver.cpp:218] Iteration 12000 (10.0337 iter/s, 9.96637s/100 iters), loss = 0.170217
I1006 20:27:18.540735  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.170217 (* 1 = 0.170217 loss)
I1006 20:27:18.540741  3817 sgd_solver.cpp:105] Iteration 12000, lr = 0.1
I1006 20:27:26.532810  3817 solver.cpp:218] Iteration 12100 (12.5124 iter/s, 7.99205s/100 iters), loss = 0.294411
I1006 20:27:26.532840  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.294411 (* 1 = 0.294411 loss)
I1006 20:27:26.532846  3817 sgd_solver.cpp:105] Iteration 12100, lr = 0.1
I1006 20:27:34.579339  3817 solver.cpp:218] Iteration 12200 (12.4278 iter/s, 8.04647s/100 iters), loss = 0.244285
I1006 20:27:34.579372  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.244285 (* 1 = 0.244285 loss)
I1006 20:27:34.579380  3817 sgd_solver.cpp:105] Iteration 12200, lr = 0.1
I1006 20:27:42.583858  3817 solver.cpp:218] Iteration 12300 (12.493 iter/s, 8.00446s/100 iters), loss = 0.276807
I1006 20:27:42.583890  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.276807 (* 1 = 0.276807 loss)
I1006 20:27:42.583909  3817 sgd_solver.cpp:105] Iteration 12300, lr = 0.1
I1006 20:27:50.694878  3817 solver.cpp:218] Iteration 12400 (12.329 iter/s, 8.11096s/100 iters), loss = 0.247899
I1006 20:27:50.695004  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.247898 (* 1 = 0.247898 loss)
I1006 20:27:50.695014  3817 sgd_solver.cpp:105] Iteration 12400, lr = 0.1
I1006 20:27:58.253407  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:27:58.573631  3817 solver.cpp:330] Iteration 12500, Testing net (#0)
I1006 20:28:00.448370  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:28:00.526752  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6186
I1006 20:28:00.526779  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.28244 (* 1 = 1.28244 loss)
I1006 20:28:00.606835  3817 solver.cpp:218] Iteration 12500 (10.089 iter/s, 9.91181s/100 iters), loss = 0.160229
I1006 20:28:00.606861  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.160229 (* 1 = 0.160229 loss)
I1006 20:28:00.606871  3817 sgd_solver.cpp:105] Iteration 12500, lr = 0.1
I1006 20:28:08.570852  3817 solver.cpp:218] Iteration 12600 (12.5566 iter/s, 7.96396s/100 iters), loss = 0.219578
I1006 20:28:08.570883  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.219577 (* 1 = 0.219577 loss)
I1006 20:28:08.570891  3817 sgd_solver.cpp:105] Iteration 12600, lr = 0.1
I1006 20:28:16.526587  3817 solver.cpp:218] Iteration 12700 (12.5696 iter/s, 7.95568s/100 iters), loss = 0.210124
I1006 20:28:16.526618  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.210124 (* 1 = 0.210124 loss)
I1006 20:28:16.526625  3817 sgd_solver.cpp:105] Iteration 12700, lr = 0.1
I1006 20:28:24.489662  3817 solver.cpp:218] Iteration 12800 (12.558 iter/s, 7.96302s/100 iters), loss = 0.31426
I1006 20:28:24.489799  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.31426 (* 1 = 0.31426 loss)
I1006 20:28:24.489807  3817 sgd_solver.cpp:105] Iteration 12800, lr = 0.1
I1006 20:28:32.450616  3817 solver.cpp:218] Iteration 12900 (12.5616 iter/s, 7.96079s/100 iters), loss = 0.285924
I1006 20:28:32.450645  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.285924 (* 1 = 0.285924 loss)
I1006 20:28:32.450651  3817 sgd_solver.cpp:105] Iteration 12900, lr = 0.1
I1006 20:28:40.146503  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:28:40.465685  3817 solver.cpp:330] Iteration 13000, Testing net (#0)
I1006 20:28:42.343047  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:28:42.421154  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7301
I1006 20:28:42.421188  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.935971 (* 1 = 0.935971 loss)
I1006 20:28:42.500934  3817 solver.cpp:218] Iteration 13000 (9.94999 iter/s, 10.0503s/100 iters), loss = 0.189897
I1006 20:28:42.500958  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.189897 (* 1 = 0.189897 loss)
I1006 20:28:42.500965  3817 sgd_solver.cpp:105] Iteration 13000, lr = 0.1
I1006 20:28:50.442101  3817 solver.cpp:218] Iteration 13100 (12.5927 iter/s, 7.94112s/100 iters), loss = 0.326387
I1006 20:28:50.442142  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.326387 (* 1 = 0.326387 loss)
I1006 20:28:50.442147  3817 sgd_solver.cpp:105] Iteration 13100, lr = 0.1
I1006 20:28:58.408083  3817 solver.cpp:218] Iteration 13200 (12.5535 iter/s, 7.96591s/100 iters), loss = 0.265605
I1006 20:28:58.408224  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.265604 (* 1 = 0.265604 loss)
I1006 20:28:58.408233  3817 sgd_solver.cpp:105] Iteration 13200, lr = 0.1
I1006 20:29:06.381906  3817 solver.cpp:218] Iteration 13300 (12.5414 iter/s, 7.97361s/100 iters), loss = 0.281644
I1006 20:29:06.381945  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.281644 (* 1 = 0.281644 loss)
I1006 20:29:06.381952  3817 sgd_solver.cpp:105] Iteration 13300, lr = 0.1
I1006 20:29:14.343119  3817 solver.cpp:218] Iteration 13400 (12.561 iter/s, 7.96115s/100 iters), loss = 0.32434
I1006 20:29:14.343149  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.32434 (* 1 = 0.32434 loss)
I1006 20:29:14.343155  3817 sgd_solver.cpp:105] Iteration 13400, lr = 0.1
I1006 20:29:21.906153  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:29:22.225546  3817 solver.cpp:330] Iteration 13500, Testing net (#0)
I1006 20:29:24.103606  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:29:24.182925  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6373
I1006 20:29:24.182950  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.32507 (* 1 = 1.32507 loss)
I1006 20:29:24.262284  3817 solver.cpp:218] Iteration 13500 (10.0816 iter/s, 9.91907s/100 iters), loss = 0.14435
I1006 20:29:24.262315  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.14435 (* 1 = 0.14435 loss)
I1006 20:29:24.262322  3817 sgd_solver.cpp:105] Iteration 13500, lr = 0.1
I1006 20:29:32.235781  3817 solver.cpp:218] Iteration 13600 (12.5417 iter/s, 7.97342s/100 iters), loss = 0.307008
I1006 20:29:32.235918  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.307008 (* 1 = 0.307008 loss)
I1006 20:29:32.235935  3817 sgd_solver.cpp:105] Iteration 13600, lr = 0.1
I1006 20:29:40.257763  3817 solver.cpp:218] Iteration 13700 (12.466 iter/s, 8.02183s/100 iters), loss = 0.270657
I1006 20:29:40.257799  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.270657 (* 1 = 0.270657 loss)
I1006 20:29:40.257807  3817 sgd_solver.cpp:105] Iteration 13700, lr = 0.1
I1006 20:29:48.285607  3817 solver.cpp:218] Iteration 13800 (12.4567 iter/s, 8.02778s/100 iters), loss = 0.306792
I1006 20:29:48.285639  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.306792 (* 1 = 0.306792 loss)
I1006 20:29:48.285645  3817 sgd_solver.cpp:105] Iteration 13800, lr = 0.1
I1006 20:29:56.279492  3817 solver.cpp:218] Iteration 13900 (12.5096 iter/s, 7.99383s/100 iters), loss = 0.255111
I1006 20:29:56.279533  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.255111 (* 1 = 0.255111 loss)
I1006 20:29:56.279539  3817 sgd_solver.cpp:105] Iteration 13900, lr = 0.1
I1006 20:30:03.871541  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:30:04.190064  3817 solver.cpp:330] Iteration 14000, Testing net (#0)
I1006 20:30:06.066947  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:30:06.144942  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6438
I1006 20:30:06.144968  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.28305 (* 1 = 1.28305 loss)
I1006 20:30:06.224557  3817 solver.cpp:218] Iteration 14000 (10.0553 iter/s, 9.94499s/100 iters), loss = 0.124583
I1006 20:30:06.224586  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.124583 (* 1 = 0.124583 loss)
I1006 20:30:06.224593  3817 sgd_solver.cpp:105] Iteration 14000, lr = 0.1
I1006 20:30:14.198863  3817 solver.cpp:218] Iteration 14100 (12.5404 iter/s, 7.97425s/100 iters), loss = 0.227398
I1006 20:30:14.198904  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.227398 (* 1 = 0.227398 loss)
I1006 20:30:14.198909  3817 sgd_solver.cpp:105] Iteration 14100, lr = 0.1
I1006 20:30:22.169493  3817 solver.cpp:218] Iteration 14200 (12.5462 iter/s, 7.97056s/100 iters), loss = 0.18689
I1006 20:30:22.169522  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.186889 (* 1 = 0.186889 loss)
I1006 20:30:22.169528  3817 sgd_solver.cpp:105] Iteration 14200, lr = 0.1
I1006 20:30:30.136715  3817 solver.cpp:218] Iteration 14300 (12.5515 iter/s, 7.96717s/100 iters), loss = 0.228378
I1006 20:30:30.136745  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.228377 (* 1 = 0.228377 loss)
I1006 20:30:30.136750  3817 sgd_solver.cpp:105] Iteration 14300, lr = 0.1
I1006 20:30:38.112228  3817 solver.cpp:218] Iteration 14400 (12.5385 iter/s, 7.97546s/100 iters), loss = 0.28239
I1006 20:30:38.112341  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.28239 (* 1 = 0.28239 loss)
I1006 20:30:38.112349  3817 sgd_solver.cpp:105] Iteration 14400, lr = 0.1
I1006 20:30:45.680918  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:30:45.999403  3817 solver.cpp:330] Iteration 14500, Testing net (#0)
I1006 20:30:47.877679  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:30:47.955106  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6338
I1006 20:30:47.955140  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.37 (* 1 = 1.37 loss)
I1006 20:30:48.035178  3817 solver.cpp:218] Iteration 14500 (10.0778 iter/s, 9.92282s/100 iters), loss = 0.188076
I1006 20:30:48.035218  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.188076 (* 1 = 0.188076 loss)
I1006 20:30:48.035233  3817 sgd_solver.cpp:105] Iteration 14500, lr = 0.1
I1006 20:30:56.006357  3817 solver.cpp:218] Iteration 14600 (12.5453 iter/s, 7.97111s/100 iters), loss = 0.269213
I1006 20:30:56.006386  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.269213 (* 1 = 0.269213 loss)
I1006 20:30:56.006392  3817 sgd_solver.cpp:105] Iteration 14600, lr = 0.1
I1006 20:31:03.984102  3817 solver.cpp:218] Iteration 14700 (12.535 iter/s, 7.97769s/100 iters), loss = 0.236872
I1006 20:31:03.984131  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.236871 (* 1 = 0.236871 loss)
I1006 20:31:03.984138  3817 sgd_solver.cpp:105] Iteration 14700, lr = 0.1
I1006 20:31:11.947577  3817 solver.cpp:218] Iteration 14800 (12.5574 iter/s, 7.96342s/100 iters), loss = 0.224399
I1006 20:31:11.947739  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.224399 (* 1 = 0.224399 loss)
I1006 20:31:11.947758  3817 sgd_solver.cpp:105] Iteration 14800, lr = 0.1
I1006 20:31:19.920944  3817 solver.cpp:218] Iteration 14900 (12.542 iter/s, 7.97318s/100 iters), loss = 0.221439
I1006 20:31:19.920984  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.221439 (* 1 = 0.221439 loss)
I1006 20:31:19.920990  3817 sgd_solver.cpp:105] Iteration 14900, lr = 0.1
I1006 20:31:27.520840  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:31:27.840193  3817 solver.cpp:330] Iteration 15000, Testing net (#0)
I1006 20:31:29.718941  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:31:29.796747  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7412
I1006 20:31:29.796772  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.898049 (* 1 = 0.898049 loss)
I1006 20:31:29.876468  3817 solver.cpp:218] Iteration 15000 (10.0447 iter/s, 9.95545s/100 iters), loss = 0.191254
I1006 20:31:29.876493  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.191254 (* 1 = 0.191254 loss)
I1006 20:31:29.876499  3817 sgd_solver.cpp:105] Iteration 15000, lr = 0.1
I1006 20:31:37.945003  3817 solver.cpp:218] Iteration 15100 (12.3939 iter/s, 8.06848s/100 iters), loss = 0.267788
I1006 20:31:37.945031  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.267788 (* 1 = 0.267788 loss)
I1006 20:31:37.945037  3817 sgd_solver.cpp:105] Iteration 15100, lr = 0.1
I1006 20:31:45.969168  3817 solver.cpp:218] Iteration 15200 (12.4624 iter/s, 8.02411s/100 iters), loss = 0.265259
I1006 20:31:45.969310  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.265259 (* 1 = 0.265259 loss)
I1006 20:31:45.969317  3817 sgd_solver.cpp:105] Iteration 15200, lr = 0.1
I1006 20:31:53.995815  3817 solver.cpp:218] Iteration 15300 (12.4588 iter/s, 8.02648s/100 iters), loss = 0.272154
I1006 20:31:53.995846  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.272154 (* 1 = 0.272154 loss)
I1006 20:31:53.995852  3817 sgd_solver.cpp:105] Iteration 15300, lr = 0.1
I1006 20:32:02.021359  3817 solver.cpp:218] Iteration 15400 (12.4603 iter/s, 8.02549s/100 iters), loss = 0.246051
I1006 20:32:02.021390  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.246051 (* 1 = 0.246051 loss)
I1006 20:32:02.021396  3817 sgd_solver.cpp:105] Iteration 15400, lr = 0.1
I1006 20:32:09.627856  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:32:09.946156  3817 solver.cpp:330] Iteration 15500, Testing net (#0)
I1006 20:32:11.822446  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:32:11.901029  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6665
I1006 20:32:11.901065  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.23821 (* 1 = 1.23821 loss)
I1006 20:32:11.981066  3817 solver.cpp:218] Iteration 15500 (10.0405 iter/s, 9.95965s/100 iters), loss = 0.229205
I1006 20:32:11.981092  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.229205 (* 1 = 0.229205 loss)
I1006 20:32:11.981099  3817 sgd_solver.cpp:105] Iteration 15500, lr = 0.1
I1006 20:32:19.945618  3817 solver.cpp:218] Iteration 15600 (12.5557 iter/s, 7.9645s/100 iters), loss = 0.190198
I1006 20:32:19.945713  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.190198 (* 1 = 0.190198 loss)
I1006 20:32:19.945719  3817 sgd_solver.cpp:105] Iteration 15600, lr = 0.1
I1006 20:32:27.906443  3817 solver.cpp:218] Iteration 15700 (12.5617 iter/s, 7.96071s/100 iters), loss = 0.297475
I1006 20:32:27.906473  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.297475 (* 1 = 0.297475 loss)
I1006 20:32:27.906491  3817 sgd_solver.cpp:105] Iteration 15700, lr = 0.1
I1006 20:32:35.863322  3817 solver.cpp:218] Iteration 15800 (12.5678 iter/s, 7.95682s/100 iters), loss = 0.206559
I1006 20:32:35.863349  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.206559 (* 1 = 0.206559 loss)
I1006 20:32:35.863355  3817 sgd_solver.cpp:105] Iteration 15800, lr = 0.1
I1006 20:32:43.823349  3817 solver.cpp:218] Iteration 15900 (12.5629 iter/s, 7.95997s/100 iters), loss = 0.255973
I1006 20:32:43.823379  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.255973 (* 1 = 0.255973 loss)
I1006 20:32:43.823385  3817 sgd_solver.cpp:105] Iteration 15900, lr = 0.1
I1006 20:32:51.407922  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:32:51.726855  3817 solver.cpp:330] Iteration 16000, Testing net (#0)
I1006 20:32:53.608338  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:32:53.685791  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7173
I1006 20:32:53.685817  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.978887 (* 1 = 0.978887 loss)
I1006 20:32:53.766374  3817 solver.cpp:218] Iteration 16000 (10.0574 iter/s, 9.94296s/100 iters), loss = 0.234171
I1006 20:32:53.766402  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.234171 (* 1 = 0.234171 loss)
I1006 20:32:53.766409  3817 sgd_solver.cpp:105] Iteration 16000, lr = 0.1
I1006 20:33:01.742038  3817 solver.cpp:218] Iteration 16100 (12.5382 iter/s, 7.97561s/100 iters), loss = 0.223348
I1006 20:33:01.742069  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.223348 (* 1 = 0.223348 loss)
I1006 20:33:01.742074  3817 sgd_solver.cpp:105] Iteration 16100, lr = 0.1
I1006 20:33:09.717721  3817 solver.cpp:218] Iteration 16200 (12.5382 iter/s, 7.97562s/100 iters), loss = 0.178121
I1006 20:33:09.717753  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.178121 (* 1 = 0.178121 loss)
I1006 20:33:09.717761  3817 sgd_solver.cpp:105] Iteration 16200, lr = 0.1
I1006 20:33:17.690784  3817 solver.cpp:218] Iteration 16300 (12.5423 iter/s, 7.97301s/100 iters), loss = 0.285056
I1006 20:33:17.690824  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.285056 (* 1 = 0.285056 loss)
I1006 20:33:17.690830  3817 sgd_solver.cpp:105] Iteration 16300, lr = 0.1
I1006 20:33:25.665045  3817 solver.cpp:218] Iteration 16400 (12.5405 iter/s, 7.9742s/100 iters), loss = 0.214538
I1006 20:33:25.665153  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.214538 (* 1 = 0.214538 loss)
I1006 20:33:25.665159  3817 sgd_solver.cpp:105] Iteration 16400, lr = 0.1
I1006 20:33:33.242065  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:33:33.561931  3817 solver.cpp:330] Iteration 16500, Testing net (#0)
I1006 20:33:35.440819  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:33:35.519412  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7749
I1006 20:33:35.519438  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.687417 (* 1 = 0.687417 loss)
I1006 20:33:35.598851  3817 solver.cpp:218] Iteration 16500 (10.0668 iter/s, 9.93367s/100 iters), loss = 0.193862
I1006 20:33:35.598876  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.193862 (* 1 = 0.193862 loss)
I1006 20:33:35.598883  3817 sgd_solver.cpp:105] Iteration 16500, lr = 0.1
I1006 20:33:43.637482  3817 solver.cpp:218] Iteration 16600 (12.44 iter/s, 8.03858s/100 iters), loss = 0.292072
I1006 20:33:43.637516  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.292072 (* 1 = 0.292072 loss)
I1006 20:33:43.637522  3817 sgd_solver.cpp:105] Iteration 16600, lr = 0.1
I1006 20:33:51.640419  3817 solver.cpp:218] Iteration 16700 (12.4955 iter/s, 8.00288s/100 iters), loss = 0.249118
I1006 20:33:51.640460  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.249118 (* 1 = 0.249118 loss)
I1006 20:33:51.640466  3817 sgd_solver.cpp:105] Iteration 16700, lr = 0.1
I1006 20:33:59.643659  3817 solver.cpp:218] Iteration 16800 (12.495 iter/s, 8.00318s/100 iters), loss = 0.243092
I1006 20:33:59.643798  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.243092 (* 1 = 0.243092 loss)
I1006 20:33:59.643817  3817 sgd_solver.cpp:105] Iteration 16800, lr = 0.1
I1006 20:34:07.604933  3817 solver.cpp:218] Iteration 16900 (12.5611 iter/s, 7.96111s/100 iters), loss = 0.219869
I1006 20:34:07.604964  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.219869 (* 1 = 0.219869 loss)
I1006 20:34:07.604979  3817 sgd_solver.cpp:105] Iteration 16900, lr = 0.1
I1006 20:34:15.222892  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:34:15.541924  3817 solver.cpp:330] Iteration 17000, Testing net (#0)
I1006 20:34:17.443696  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:34:17.522112  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6667
I1006 20:34:17.522137  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.06905 (* 1 = 1.06905 loss)
I1006 20:34:17.602319  3817 solver.cpp:218] Iteration 17000 (10.0027 iter/s, 9.99732s/100 iters), loss = 0.189923
I1006 20:34:17.602368  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.189923 (* 1 = 0.189923 loss)
I1006 20:34:17.602375  3817 sgd_solver.cpp:105] Iteration 17000, lr = 0.1
I1006 20:34:25.574906  3817 solver.cpp:218] Iteration 17100 (12.5431 iter/s, 7.97251s/100 iters), loss = 0.222588
I1006 20:34:25.574939  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.222588 (* 1 = 0.222588 loss)
I1006 20:34:25.574955  3817 sgd_solver.cpp:105] Iteration 17100, lr = 0.1
I1006 20:34:33.659420  3817 solver.cpp:218] Iteration 17200 (12.3694 iter/s, 8.08445s/100 iters), loss = 0.254666
I1006 20:34:33.659485  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.254666 (* 1 = 0.254666 loss)
I1006 20:34:33.659493  3817 sgd_solver.cpp:105] Iteration 17200, lr = 0.1
I1006 20:34:41.710072  3817 solver.cpp:218] Iteration 17300 (12.4215 iter/s, 8.05056s/100 iters), loss = 0.221658
I1006 20:34:41.710104  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.221658 (* 1 = 0.221658 loss)
I1006 20:34:41.710121  3817 sgd_solver.cpp:105] Iteration 17300, lr = 0.1
I1006 20:34:49.719537  3817 solver.cpp:218] Iteration 17400 (12.4853 iter/s, 8.00941s/100 iters), loss = 0.299969
I1006 20:34:49.719578  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.299969 (* 1 = 0.299969 loss)
I1006 20:34:49.719583  3817 sgd_solver.cpp:105] Iteration 17400, lr = 0.1
I1006 20:34:57.362782  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:34:57.686013  3817 solver.cpp:330] Iteration 17500, Testing net (#0)
I1006 20:34:59.570492  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:34:59.649488  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7137
I1006 20:34:59.649524  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.02435 (* 1 = 1.02435 loss)
I1006 20:34:59.728782  3817 solver.cpp:218] Iteration 17500 (9.99083 iter/s, 10.0092s/100 iters), loss = 0.174008
I1006 20:34:59.728808  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.174008 (* 1 = 0.174008 loss)
I1006 20:34:59.728814  3817 sgd_solver.cpp:105] Iteration 17500, lr = 0.1
I1006 20:35:07.786360  3817 solver.cpp:218] Iteration 17600 (12.4108 iter/s, 8.05752s/100 iters), loss = 0.274459
I1006 20:35:07.786495  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.274459 (* 1 = 0.274459 loss)
I1006 20:35:07.786505  3817 sgd_solver.cpp:105] Iteration 17600, lr = 0.1
I1006 20:35:15.780918  3817 solver.cpp:218] Iteration 17700 (12.5088 iter/s, 7.99438s/100 iters), loss = 0.21852
I1006 20:35:15.780959  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.21852 (* 1 = 0.21852 loss)
I1006 20:35:15.780966  3817 sgd_solver.cpp:105] Iteration 17700, lr = 0.1
I1006 20:35:23.827847  3817 solver.cpp:218] Iteration 17800 (12.4272 iter/s, 8.04686s/100 iters), loss = 0.207992
I1006 20:35:23.827888  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.207992 (* 1 = 0.207992 loss)
I1006 20:35:23.827894  3817 sgd_solver.cpp:105] Iteration 17800, lr = 0.1
I1006 20:35:31.831847  3817 solver.cpp:218] Iteration 17900 (12.4939 iter/s, 8.00393s/100 iters), loss = 0.17697
I1006 20:35:31.831877  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.17697 (* 1 = 0.17697 loss)
I1006 20:35:31.831883  3817 sgd_solver.cpp:105] Iteration 17900, lr = 0.1
I1006 20:35:39.536676  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:35:39.856662  3817 solver.cpp:330] Iteration 18000, Testing net (#0)
I1006 20:35:41.740414  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:35:41.818859  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6966
I1006 20:35:41.818884  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.1664 (* 1 = 1.1664 loss)
I1006 20:35:41.898689  3817 solver.cpp:218] Iteration 18000 (9.93366 iter/s, 10.0668s/100 iters), loss = 0.210009
I1006 20:35:41.898718  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.210009 (* 1 = 0.210009 loss)
I1006 20:35:41.898725  3817 sgd_solver.cpp:105] Iteration 18000, lr = 0.1
I1006 20:35:49.904103  3817 solver.cpp:218] Iteration 18100 (12.4916 iter/s, 8.00536s/100 iters), loss = 0.236893
I1006 20:35:49.904134  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.236894 (* 1 = 0.236894 loss)
I1006 20:35:49.904139  3817 sgd_solver.cpp:105] Iteration 18100, lr = 0.1
I1006 20:35:57.908108  3817 solver.cpp:218] Iteration 18200 (12.4938 iter/s, 8.00395s/100 iters), loss = 0.294855
I1006 20:35:57.908139  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.294855 (* 1 = 0.294855 loss)
I1006 20:35:57.908145  3817 sgd_solver.cpp:105] Iteration 18200, lr = 0.1
I1006 20:36:05.912920  3817 solver.cpp:218] Iteration 18300 (12.4926 iter/s, 8.00475s/100 iters), loss = 0.185256
I1006 20:36:05.912951  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.185256 (* 1 = 0.185256 loss)
I1006 20:36:05.912957  3817 sgd_solver.cpp:105] Iteration 18300, lr = 0.1
I1006 20:36:13.893455  3817 solver.cpp:218] Iteration 18400 (12.5306 iter/s, 7.98048s/100 iters), loss = 0.174401
I1006 20:36:13.893591  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.174401 (* 1 = 0.174401 loss)
I1006 20:36:13.893599  3817 sgd_solver.cpp:105] Iteration 18400, lr = 0.1
I1006 20:36:21.491225  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:36:21.812492  3817 solver.cpp:330] Iteration 18500, Testing net (#0)
I1006 20:36:23.701040  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:36:23.779417  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.664
I1006 20:36:23.779441  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.36325 (* 1 = 1.36325 loss)
I1006 20:36:23.859701  3817 solver.cpp:218] Iteration 18500 (10.034 iter/s, 9.96608s/100 iters), loss = 0.210541
I1006 20:36:23.859737  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.210541 (* 1 = 0.210541 loss)
I1006 20:36:23.859755  3817 sgd_solver.cpp:105] Iteration 18500, lr = 0.1
I1006 20:36:31.880436  3817 solver.cpp:218] Iteration 18600 (12.4678 iter/s, 8.02067s/100 iters), loss = 0.297599
I1006 20:36:31.880473  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.297599 (* 1 = 0.297599 loss)
I1006 20:36:31.880491  3817 sgd_solver.cpp:105] Iteration 18600, lr = 0.1
I1006 20:36:39.852573  3817 solver.cpp:218] Iteration 18700 (12.5438 iter/s, 7.97207s/100 iters), loss = 0.237932
I1006 20:36:39.852612  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.237932 (* 1 = 0.237932 loss)
I1006 20:36:39.852618  3817 sgd_solver.cpp:105] Iteration 18700, lr = 0.1
I1006 20:36:47.895073  3817 solver.cpp:218] Iteration 18800 (12.434 iter/s, 8.04244s/100 iters), loss = 0.314557
I1006 20:36:47.895213  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.314557 (* 1 = 0.314557 loss)
I1006 20:36:47.895241  3817 sgd_solver.cpp:105] Iteration 18800, lr = 0.1
I1006 20:36:55.912063  3817 solver.cpp:218] Iteration 18900 (12.4738 iter/s, 8.01683s/100 iters), loss = 0.326595
I1006 20:36:55.912096  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.326595 (* 1 = 0.326595 loss)
I1006 20:36:55.912103  3817 sgd_solver.cpp:105] Iteration 18900, lr = 0.1
I1006 20:37:03.523067  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:37:03.843500  3817 solver.cpp:330] Iteration 19000, Testing net (#0)
I1006 20:37:05.730468  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:37:05.808574  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7343
I1006 20:37:05.808601  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.887663 (* 1 = 0.887663 loss)
I1006 20:37:05.888025  3817 solver.cpp:218] Iteration 19000 (10.0242 iter/s, 9.9759s/100 iters), loss = 0.249513
I1006 20:37:05.888053  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.249513 (* 1 = 0.249513 loss)
I1006 20:37:05.888062  3817 sgd_solver.cpp:105] Iteration 19000, lr = 0.1
I1006 20:37:13.894265  3817 solver.cpp:218] Iteration 19100 (12.4903 iter/s, 8.00619s/100 iters), loss = 0.227914
I1006 20:37:13.894299  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.227915 (* 1 = 0.227915 loss)
I1006 20:37:13.894306  3817 sgd_solver.cpp:105] Iteration 19100, lr = 0.1
I1006 20:37:21.879813  3817 solver.cpp:218] Iteration 19200 (12.5227 iter/s, 7.98549s/100 iters), loss = 0.176902
I1006 20:37:21.879947  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.176902 (* 1 = 0.176902 loss)
I1006 20:37:21.879971  3817 sgd_solver.cpp:105] Iteration 19200, lr = 0.1
I1006 20:37:29.861851  3817 solver.cpp:218] Iteration 19300 (12.5284 iter/s, 7.98188s/100 iters), loss = 0.218228
I1006 20:37:29.861884  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.218228 (* 1 = 0.218228 loss)
I1006 20:37:29.861901  3817 sgd_solver.cpp:105] Iteration 19300, lr = 0.1
I1006 20:37:37.827664  3817 solver.cpp:218] Iteration 19400 (12.5537 iter/s, 7.96576s/100 iters), loss = 0.256311
I1006 20:37:37.827695  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.256311 (* 1 = 0.256311 loss)
I1006 20:37:37.827703  3817 sgd_solver.cpp:105] Iteration 19400, lr = 0.1
I1006 20:37:45.403116  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:37:45.722705  3817 solver.cpp:330] Iteration 19500, Testing net (#0)
I1006 20:37:47.633690  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:37:47.712030  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7161
I1006 20:37:47.712064  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.03398 (* 1 = 1.03398 loss)
I1006 20:37:47.791816  3817 solver.cpp:218] Iteration 19500 (10.036 iter/s, 9.96409s/100 iters), loss = 0.180882
I1006 20:37:47.791839  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.180883 (* 1 = 0.180883 loss)
I1006 20:37:47.791846  3817 sgd_solver.cpp:105] Iteration 19500, lr = 0.1
I1006 20:37:55.815558  3817 solver.cpp:218] Iteration 19600 (12.4631 iter/s, 8.02369s/100 iters), loss = 0.242233
I1006 20:37:55.815666  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.242234 (* 1 = 0.242234 loss)
I1006 20:37:55.815685  3817 sgd_solver.cpp:105] Iteration 19600, lr = 0.1
I1006 20:38:03.805816  3817 solver.cpp:218] Iteration 19700 (12.5154 iter/s, 7.99013s/100 iters), loss = 0.355836
I1006 20:38:03.805846  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.355836 (* 1 = 0.355836 loss)
I1006 20:38:03.805852  3817 sgd_solver.cpp:105] Iteration 19700, lr = 0.1
I1006 20:38:11.867043  3817 solver.cpp:218] Iteration 19800 (12.4051 iter/s, 8.06117s/100 iters), loss = 0.287619
I1006 20:38:11.867074  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.287619 (* 1 = 0.287619 loss)
I1006 20:38:11.867079  3817 sgd_solver.cpp:105] Iteration 19800, lr = 0.1
I1006 20:38:19.850538  3817 solver.cpp:218] Iteration 19900 (12.5259 iter/s, 7.98344s/100 iters), loss = 0.202006
I1006 20:38:19.850567  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.202006 (* 1 = 0.202006 loss)
I1006 20:38:19.850574  3817 sgd_solver.cpp:105] Iteration 19900, lr = 0.1
I1006 20:38:27.441529  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:38:27.760908  3817 solver.cpp:330] Iteration 20000, Testing net (#0)
I1006 20:38:29.645586  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:38:29.723989  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.582
I1006 20:38:29.724023  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.54886 (* 1 = 1.54886 loss)
I1006 20:38:29.803637  3817 solver.cpp:218] Iteration 20000 (10.0472 iter/s, 9.95304s/100 iters), loss = 0.213966
I1006 20:38:29.803661  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.213966 (* 1 = 0.213966 loss)
I1006 20:38:29.803668  3817 sgd_solver.cpp:105] Iteration 20000, lr = 0.1
I1006 20:38:37.792541  3817 solver.cpp:218] Iteration 20100 (12.5174 iter/s, 7.98885s/100 iters), loss = 0.162492
I1006 20:38:37.792574  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.162492 (* 1 = 0.162492 loss)
I1006 20:38:37.792580  3817 sgd_solver.cpp:105] Iteration 20100, lr = 0.1
I1006 20:38:45.835275  3817 solver.cpp:218] Iteration 20200 (12.4337 iter/s, 8.04267s/100 iters), loss = 0.324579
I1006 20:38:45.835306  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.324579 (* 1 = 0.324579 loss)
I1006 20:38:45.835312  3817 sgd_solver.cpp:105] Iteration 20200, lr = 0.1
I1006 20:38:53.800405  3817 solver.cpp:218] Iteration 20300 (12.5548 iter/s, 7.96507s/100 iters), loss = 0.254077
I1006 20:38:53.800436  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.254078 (* 1 = 0.254078 loss)
I1006 20:38:53.800441  3817 sgd_solver.cpp:105] Iteration 20300, lr = 0.1
I1006 20:39:01.798554  3817 solver.cpp:218] Iteration 20400 (12.503 iter/s, 7.99809s/100 iters), loss = 0.156071
I1006 20:39:01.798693  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.156071 (* 1 = 0.156071 loss)
I1006 20:39:01.798701  3817 sgd_solver.cpp:105] Iteration 20400, lr = 0.1
I1006 20:39:09.394860  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:39:09.713178  3817 solver.cpp:330] Iteration 20500, Testing net (#0)
I1006 20:39:11.590072  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:39:11.668602  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7844
I1006 20:39:11.668637  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.660289 (* 1 = 0.660289 loss)
I1006 20:39:11.747937  3817 solver.cpp:218] Iteration 20500 (10.051 iter/s, 9.94923s/100 iters), loss = 0.154608
I1006 20:39:11.747961  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.154608 (* 1 = 0.154608 loss)
I1006 20:39:11.747968  3817 sgd_solver.cpp:105] Iteration 20500, lr = 0.1
I1006 20:39:19.741186  3817 solver.cpp:218] Iteration 20600 (12.5107 iter/s, 7.99319s/100 iters), loss = 0.186015
I1006 20:39:19.741230  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.186015 (* 1 = 0.186015 loss)
I1006 20:39:19.741238  3817 sgd_solver.cpp:105] Iteration 20600, lr = 0.1
I1006 20:39:27.792070  3817 solver.cpp:218] Iteration 20700 (12.4218 iter/s, 8.05037s/100 iters), loss = 0.151101
I1006 20:39:27.792110  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.151102 (* 1 = 0.151102 loss)
I1006 20:39:27.792117  3817 sgd_solver.cpp:105] Iteration 20700, lr = 0.1
I1006 20:39:35.835382  3817 solver.cpp:218] Iteration 20800 (12.4328 iter/s, 8.04324s/100 iters), loss = 0.198331
I1006 20:39:35.835511  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.198331 (* 1 = 0.198331 loss)
I1006 20:39:35.835530  3817 sgd_solver.cpp:105] Iteration 20800, lr = 0.1
I1006 20:39:43.850940  3817 solver.cpp:218] Iteration 20900 (12.476 iter/s, 8.0154s/100 iters), loss = 0.134151
I1006 20:39:43.850980  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.134151 (* 1 = 0.134151 loss)
I1006 20:39:43.850987  3817 sgd_solver.cpp:105] Iteration 20900, lr = 0.1
I1006 20:39:51.499789  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:39:51.827977  3817 solver.cpp:330] Iteration 21000, Testing net (#0)
I1006 20:39:53.706125  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:39:53.784540  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.741
I1006 20:39:53.784574  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.842107 (* 1 = 0.842107 loss)
I1006 20:39:53.864297  3817 solver.cpp:218] Iteration 21000 (9.98673 iter/s, 10.0133s/100 iters), loss = 0.173851
I1006 20:39:53.864320  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.173851 (* 1 = 0.173851 loss)
I1006 20:39:53.864327  3817 sgd_solver.cpp:105] Iteration 21000, lr = 0.1
I1006 20:40:01.860081  3817 solver.cpp:218] Iteration 21100 (12.5067 iter/s, 7.99573s/100 iters), loss = 0.234626
I1006 20:40:01.860112  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.234626 (* 1 = 0.234626 loss)
I1006 20:40:01.860118  3817 sgd_solver.cpp:105] Iteration 21100, lr = 0.1
I1006 20:40:09.846241  3817 solver.cpp:218] Iteration 21200 (12.5218 iter/s, 7.9861s/100 iters), loss = 0.265395
I1006 20:40:09.846328  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.265395 (* 1 = 0.265395 loss)
I1006 20:40:09.846348  3817 sgd_solver.cpp:105] Iteration 21200, lr = 0.1
I1006 20:40:17.891074  3817 solver.cpp:218] Iteration 21300 (12.4305 iter/s, 8.04472s/100 iters), loss = 0.209925
I1006 20:40:17.891103  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.209926 (* 1 = 0.209926 loss)
I1006 20:40:17.891108  3817 sgd_solver.cpp:105] Iteration 21300, lr = 0.1
I1006 20:40:25.882405  3817 solver.cpp:218] Iteration 21400 (12.5137 iter/s, 7.99127s/100 iters), loss = 0.186436
I1006 20:40:25.882434  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.186436 (* 1 = 0.186436 loss)
I1006 20:40:25.882441  3817 sgd_solver.cpp:105] Iteration 21400, lr = 0.1
I1006 20:40:33.493850  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:40:33.816761  3817 solver.cpp:330] Iteration 21500, Testing net (#0)
I1006 20:40:35.703279  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:40:35.784387  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7038
I1006 20:40:35.784425  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.10228 (* 1 = 1.10228 loss)
I1006 20:40:35.864624  3817 solver.cpp:218] Iteration 21500 (10.0179 iter/s, 9.98216s/100 iters), loss = 0.160973
I1006 20:40:35.864652  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.160973 (* 1 = 0.160973 loss)
I1006 20:40:35.864660  3817 sgd_solver.cpp:105] Iteration 21500, lr = 0.1
I1006 20:40:43.870826  3817 solver.cpp:218] Iteration 21600 (12.4904 iter/s, 8.00615s/100 iters), loss = 0.145798
I1006 20:40:43.870923  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.145798 (* 1 = 0.145798 loss)
I1006 20:40:43.870929  3817 sgd_solver.cpp:105] Iteration 21600, lr = 0.1
I1006 20:40:51.890283  3817 solver.cpp:218] Iteration 21700 (12.4699 iter/s, 8.01934s/100 iters), loss = 0.155217
I1006 20:40:51.890312  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.155217 (* 1 = 0.155217 loss)
I1006 20:40:51.890318  3817 sgd_solver.cpp:105] Iteration 21700, lr = 0.1
I1006 20:40:59.904790  3817 solver.cpp:218] Iteration 21800 (12.4775 iter/s, 8.01445s/100 iters), loss = 0.293592
I1006 20:40:59.904821  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.293592 (* 1 = 0.293592 loss)
I1006 20:40:59.904827  3817 sgd_solver.cpp:105] Iteration 21800, lr = 0.1
I1006 20:41:07.927790  3817 solver.cpp:218] Iteration 21900 (12.4643 iter/s, 8.02294s/100 iters), loss = 0.219109
I1006 20:41:07.927820  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.219109 (* 1 = 0.219109 loss)
I1006 20:41:07.927826  3817 sgd_solver.cpp:105] Iteration 21900, lr = 0.1
I1006 20:41:15.543872  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:41:15.862443  3817 solver.cpp:330] Iteration 22000, Testing net (#0)
I1006 20:41:17.749802  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:41:17.827867  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6814
I1006 20:41:17.827901  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.23044 (* 1 = 1.23044 loss)
I1006 20:41:17.907507  3817 solver.cpp:218] Iteration 22000 (10.0204 iter/s, 9.97966s/100 iters), loss = 0.188583
I1006 20:41:17.907536  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.188583 (* 1 = 0.188583 loss)
I1006 20:41:17.907541  3817 sgd_solver.cpp:105] Iteration 22000, lr = 0.1
I1006 20:41:25.953451  3817 solver.cpp:218] Iteration 22100 (12.4287 iter/s, 8.04589s/100 iters), loss = 0.263804
I1006 20:41:25.953481  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.263804 (* 1 = 0.263804 loss)
I1006 20:41:25.953487  3817 sgd_solver.cpp:105] Iteration 22100, lr = 0.1
I1006 20:41:34.029870  3817 solver.cpp:218] Iteration 22200 (12.3818 iter/s, 8.07636s/100 iters), loss = 0.227591
I1006 20:41:34.029909  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.227591 (* 1 = 0.227591 loss)
I1006 20:41:34.029916  3817 sgd_solver.cpp:105] Iteration 22200, lr = 0.1
I1006 20:41:42.054761  3817 solver.cpp:218] Iteration 22300 (12.4613 iter/s, 8.02482s/100 iters), loss = 0.24046
I1006 20:41:42.054796  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.24046 (* 1 = 0.24046 loss)
I1006 20:41:42.054803  3817 sgd_solver.cpp:105] Iteration 22300, lr = 0.1
I1006 20:41:50.077708  3817 solver.cpp:218] Iteration 22400 (12.4643 iter/s, 8.02289s/100 iters), loss = 0.188911
I1006 20:41:50.077793  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.188911 (* 1 = 0.188911 loss)
I1006 20:41:50.077811  3817 sgd_solver.cpp:105] Iteration 22400, lr = 0.1
I1006 20:41:57.667873  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:41:57.987547  3817 solver.cpp:330] Iteration 22500, Testing net (#0)
I1006 20:41:59.866463  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:41:59.944814  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7469
I1006 20:41:59.944849  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.812703 (* 1 = 0.812703 loss)
I1006 20:42:00.024971  3817 solver.cpp:218] Iteration 22500 (10.0531 iter/s, 9.94715s/100 iters), loss = 0.135504
I1006 20:42:00.025001  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.135504 (* 1 = 0.135504 loss)
I1006 20:42:00.025007  3817 sgd_solver.cpp:105] Iteration 22500, lr = 0.1
I1006 20:42:08.080516  3817 solver.cpp:218] Iteration 22600 (12.4139 iter/s, 8.05549s/100 iters), loss = 0.21799
I1006 20:42:08.080574  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.21799 (* 1 = 0.21799 loss)
I1006 20:42:08.080592  3817 sgd_solver.cpp:105] Iteration 22600, lr = 0.1
I1006 20:42:16.116485  3817 solver.cpp:218] Iteration 22700 (12.4445 iter/s, 8.03569s/100 iters), loss = 0.217252
I1006 20:42:16.116525  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.217252 (* 1 = 0.217252 loss)
I1006 20:42:16.116533  3817 sgd_solver.cpp:105] Iteration 22700, lr = 0.1
I1006 20:42:24.137871  3817 solver.cpp:218] Iteration 22800 (12.4668 iter/s, 8.02132s/100 iters), loss = 0.132121
I1006 20:42:24.138006  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.132121 (* 1 = 0.132121 loss)
I1006 20:42:24.138015  3817 sgd_solver.cpp:105] Iteration 22800, lr = 0.1
I1006 20:42:32.211076  3817 solver.cpp:218] Iteration 22900 (12.3869 iter/s, 8.07305s/100 iters), loss = 0.193778
I1006 20:42:32.211107  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.193778 (* 1 = 0.193778 loss)
I1006 20:42:32.211112  3817 sgd_solver.cpp:105] Iteration 22900, lr = 0.1
I1006 20:42:39.906368  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:42:40.229375  3817 solver.cpp:330] Iteration 23000, Testing net (#0)
I1006 20:42:42.134371  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:42:42.213177  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6878
I1006 20:42:42.213203  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.09552 (* 1 = 1.09552 loss)
I1006 20:42:42.293051  3817 solver.cpp:218] Iteration 23000 (9.91875 iter/s, 10.0819s/100 iters), loss = 0.144915
I1006 20:42:42.293084  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.144916 (* 1 = 0.144916 loss)
I1006 20:42:42.293092  3817 sgd_solver.cpp:105] Iteration 23000, lr = 0.1
I1006 20:42:50.311391  3817 solver.cpp:218] Iteration 23100 (12.4715 iter/s, 8.01828s/100 iters), loss = 0.213043
I1006 20:42:50.311434  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.213043 (* 1 = 0.213043 loss)
I1006 20:42:50.311441  3817 sgd_solver.cpp:105] Iteration 23100, lr = 0.1
I1006 20:42:58.384817  3817 solver.cpp:218] Iteration 23200 (12.3864 iter/s, 8.07335s/100 iters), loss = 0.165999
I1006 20:42:58.384937  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.165999 (* 1 = 0.165999 loss)
I1006 20:42:58.384954  3817 sgd_solver.cpp:105] Iteration 23200, lr = 0.1
I1006 20:43:06.407053  3817 solver.cpp:218] Iteration 23300 (12.4656 iter/s, 8.0221s/100 iters), loss = 0.239435
I1006 20:43:06.407095  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.239435 (* 1 = 0.239435 loss)
I1006 20:43:06.407104  3817 sgd_solver.cpp:105] Iteration 23300, lr = 0.1
I1006 20:43:14.462031  3817 solver.cpp:218] Iteration 23400 (12.4148 iter/s, 8.05491s/100 iters), loss = 0.116527
I1006 20:43:14.462060  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.116527 (* 1 = 0.116527 loss)
I1006 20:43:14.462066  3817 sgd_solver.cpp:105] Iteration 23400, lr = 0.1
I1006 20:43:22.180135  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:43:22.498854  3817 solver.cpp:330] Iteration 23500, Testing net (#0)
I1006 20:43:24.378729  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:43:24.457159  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7661
I1006 20:43:24.457195  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.869045 (* 1 = 0.869045 loss)
I1006 20:43:24.537341  3817 solver.cpp:218] Iteration 23500 (9.92532 iter/s, 10.0752s/100 iters), loss = 0.164296
I1006 20:43:24.537417  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.164296 (* 1 = 0.164296 loss)
I1006 20:43:24.537431  3817 sgd_solver.cpp:105] Iteration 23500, lr = 0.1
I1006 20:43:32.570991  3817 solver.cpp:218] Iteration 23600 (12.4479 iter/s, 8.03346s/100 iters), loss = 0.16132
I1006 20:43:32.571130  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.16132 (* 1 = 0.16132 loss)
I1006 20:43:32.571140  3817 sgd_solver.cpp:105] Iteration 23600, lr = 0.1
I1006 20:43:40.632102  3817 solver.cpp:218] Iteration 23700 (12.4055 iter/s, 8.06095s/100 iters), loss = 0.187006
I1006 20:43:40.632139  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.187006 (* 1 = 0.187006 loss)
I1006 20:43:40.632148  3817 sgd_solver.cpp:105] Iteration 23700, lr = 0.1
I1006 20:43:48.722141  3817 solver.cpp:218] Iteration 23800 (12.361 iter/s, 8.08997s/100 iters), loss = 0.222664
I1006 20:43:48.722172  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.222665 (* 1 = 0.222665 loss)
I1006 20:43:48.722178  3817 sgd_solver.cpp:105] Iteration 23800, lr = 0.1
I1006 20:43:56.803968  3817 solver.cpp:218] Iteration 23900 (12.3735 iter/s, 8.08177s/100 iters), loss = 0.163519
I1006 20:43:56.804000  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.163519 (* 1 = 0.163519 loss)
I1006 20:43:56.804006  3817 sgd_solver.cpp:105] Iteration 23900, lr = 0.1
I1006 20:44:04.453331  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:44:04.774422  3817 solver.cpp:330] Iteration 24000, Testing net (#0)
I1006 20:44:06.671949  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:44:06.750468  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7513
I1006 20:44:06.750501  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.750856 (* 1 = 0.750856 loss)
I1006 20:44:06.829711  3817 solver.cpp:218] Iteration 24000 (9.97439 iter/s, 10.0257s/100 iters), loss = 0.268708
I1006 20:44:06.829738  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.268708 (* 1 = 0.268708 loss)
I1006 20:44:06.829746  3817 sgd_solver.cpp:105] Iteration 24000, lr = 0.1
I1006 20:44:14.827678  3817 solver.cpp:218] Iteration 24100 (12.5033 iter/s, 7.99791s/100 iters), loss = 0.163184
I1006 20:44:14.827708  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.163184 (* 1 = 0.163184 loss)
I1006 20:44:14.827714  3817 sgd_solver.cpp:105] Iteration 24100, lr = 0.1
I1006 20:44:22.839447  3817 solver.cpp:218] Iteration 24200 (12.4817 iter/s, 8.01171s/100 iters), loss = 0.173894
I1006 20:44:22.839493  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.173894 (* 1 = 0.173894 loss)
I1006 20:44:22.839500  3817 sgd_solver.cpp:105] Iteration 24200, lr = 0.1
I1006 20:44:30.862048  3817 solver.cpp:218] Iteration 24300 (12.4654 iter/s, 8.02221s/100 iters), loss = 0.222422
I1006 20:44:30.862079  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.222422 (* 1 = 0.222422 loss)
I1006 20:44:30.862087  3817 sgd_solver.cpp:105] Iteration 24300, lr = 0.1
I1006 20:44:38.881515  3817 solver.cpp:218] Iteration 24400 (12.4697 iter/s, 8.01941s/100 iters), loss = 0.217541
I1006 20:44:38.881628  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.217541 (* 1 = 0.217541 loss)
I1006 20:44:38.881652  3817 sgd_solver.cpp:105] Iteration 24400, lr = 0.1
I1006 20:44:46.462209  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:44:46.782883  3817 solver.cpp:330] Iteration 24500, Testing net (#0)
I1006 20:44:48.657979  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:44:48.736676  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6923
I1006 20:44:48.736709  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.14605 (* 1 = 1.14605 loss)
I1006 20:44:48.816565  3817 solver.cpp:218] Iteration 24500 (10.0655 iter/s, 9.93492s/100 iters), loss = 0.212578
I1006 20:44:48.816591  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.212578 (* 1 = 0.212578 loss)
I1006 20:44:48.816598  3817 sgd_solver.cpp:105] Iteration 24500, lr = 0.1
I1006 20:44:56.841930  3817 solver.cpp:218] Iteration 24600 (12.4606 iter/s, 8.02531s/100 iters), loss = 0.20271
I1006 20:44:56.841972  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.20271 (* 1 = 0.20271 loss)
I1006 20:44:56.841979  3817 sgd_solver.cpp:105] Iteration 24600, lr = 0.1
I1006 20:45:04.864415  3817 solver.cpp:218] Iteration 24700 (12.4651 iter/s, 8.02242s/100 iters), loss = 0.242577
I1006 20:45:04.864446  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.242577 (* 1 = 0.242577 loss)
I1006 20:45:04.864454  3817 sgd_solver.cpp:105] Iteration 24700, lr = 0.1
I1006 20:45:12.953667  3817 solver.cpp:218] Iteration 24800 (12.3622 iter/s, 8.08919s/100 iters), loss = 0.258114
I1006 20:45:12.953809  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.258114 (* 1 = 0.258114 loss)
I1006 20:45:12.953817  3817 sgd_solver.cpp:105] Iteration 24800, lr = 0.1
I1006 20:45:21.013777  3817 solver.cpp:218] Iteration 24900 (12.407 iter/s, 8.05994s/100 iters), loss = 0.182695
I1006 20:45:21.013814  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.182695 (* 1 = 0.182695 loss)
I1006 20:45:21.013823  3817 sgd_solver.cpp:105] Iteration 24900, lr = 0.1
I1006 20:45:28.713624  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:45:29.032253  3817 solver.cpp:330] Iteration 25000, Testing net (#0)
I1006 20:45:30.926815  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:45:31.006003  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6773
I1006 20:45:31.006028  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.05173 (* 1 = 1.05173 loss)
I1006 20:45:31.087232  3817 solver.cpp:218] Iteration 25000 (9.92715 iter/s, 10.0734s/100 iters), loss = 0.183919
I1006 20:45:31.087307  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.183919 (* 1 = 0.183919 loss)
I1006 20:45:31.087327  3817 sgd_solver.cpp:105] Iteration 25000, lr = 0.1
I1006 20:45:39.173516  3817 solver.cpp:218] Iteration 25100 (12.367 iter/s, 8.08606s/100 iters), loss = 0.278367
I1006 20:45:39.173547  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.278367 (* 1 = 0.278367 loss)
I1006 20:45:39.173553  3817 sgd_solver.cpp:105] Iteration 25100, lr = 0.1
I1006 20:45:47.247300  3817 solver.cpp:218] Iteration 25200 (12.3859 iter/s, 8.07372s/100 iters), loss = 0.211826
I1006 20:45:47.247437  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.211826 (* 1 = 0.211826 loss)
I1006 20:45:47.247454  3817 sgd_solver.cpp:105] Iteration 25200, lr = 0.1
I1006 20:45:55.337595  3817 solver.cpp:218] Iteration 25300 (12.3607 iter/s, 8.09015s/100 iters), loss = 0.210327
I1006 20:45:55.337625  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.210327 (* 1 = 0.210327 loss)
I1006 20:45:55.337632  3817 sgd_solver.cpp:105] Iteration 25300, lr = 0.1
I1006 20:46:03.419535  3817 solver.cpp:218] Iteration 25400 (12.3734 iter/s, 8.08188s/100 iters), loss = 0.173756
I1006 20:46:03.419565  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.173757 (* 1 = 0.173757 loss)
I1006 20:46:03.419572  3817 sgd_solver.cpp:105] Iteration 25400, lr = 0.1
I1006 20:46:11.104166  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:46:11.426168  3817 solver.cpp:330] Iteration 25500, Testing net (#0)
I1006 20:46:13.335284  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:46:13.413353  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.757
I1006 20:46:13.413378  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.785113 (* 1 = 0.785113 loss)
I1006 20:46:13.492702  3817 solver.cpp:218] Iteration 25500 (9.92743 iter/s, 10.0731s/100 iters), loss = 0.177484
I1006 20:46:13.492729  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.177484 (* 1 = 0.177484 loss)
I1006 20:46:13.492736  3817 sgd_solver.cpp:105] Iteration 25500, lr = 0.1
I1006 20:46:21.556450  3817 solver.cpp:218] Iteration 25600 (12.4013 iter/s, 8.06369s/100 iters), loss = 0.20389
I1006 20:46:21.556566  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.20389 (* 1 = 0.20389 loss)
I1006 20:46:21.556574  3817 sgd_solver.cpp:105] Iteration 25600, lr = 0.1
I1006 20:46:29.588976  3817 solver.cpp:218] Iteration 25700 (12.4496 iter/s, 8.03238s/100 iters), loss = 0.167016
I1006 20:46:29.589010  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.167016 (* 1 = 0.167016 loss)
I1006 20:46:29.589015  3817 sgd_solver.cpp:105] Iteration 25700, lr = 0.1
I1006 20:46:37.625859  3817 solver.cpp:218] Iteration 25800 (12.4427 iter/s, 8.03682s/100 iters), loss = 0.190411
I1006 20:46:37.625890  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.190411 (* 1 = 0.190411 loss)
I1006 20:46:37.625897  3817 sgd_solver.cpp:105] Iteration 25800, lr = 0.1
I1006 20:46:45.682041  3817 solver.cpp:218] Iteration 25900 (12.4129 iter/s, 8.05612s/100 iters), loss = 0.133023
I1006 20:46:45.682070  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.133023 (* 1 = 0.133023 loss)
I1006 20:46:45.682076  3817 sgd_solver.cpp:105] Iteration 25900, lr = 0.1
I1006 20:46:53.303648  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:46:53.623812  3817 solver.cpp:330] Iteration 26000, Testing net (#0)
I1006 20:46:55.515094  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:46:55.593735  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.677
I1006 20:46:55.593771  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.12986 (* 1 = 1.12986 loss)
I1006 20:46:55.673357  3817 solver.cpp:218] Iteration 26000 (10.0088 iter/s, 9.99125s/100 iters), loss = 0.129694
I1006 20:46:55.673385  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.129694 (* 1 = 0.129694 loss)
I1006 20:46:55.673393  3817 sgd_solver.cpp:105] Iteration 26000, lr = 0.1
I1006 20:47:03.717300  3817 solver.cpp:218] Iteration 26100 (12.4318 iter/s, 8.04389s/100 iters), loss = 0.154597
I1006 20:47:03.717330  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.154597 (* 1 = 0.154597 loss)
I1006 20:47:03.717346  3817 sgd_solver.cpp:105] Iteration 26100, lr = 0.1
I1006 20:47:11.764180  3817 solver.cpp:218] Iteration 26200 (12.4273 iter/s, 8.04682s/100 iters), loss = 0.16553
I1006 20:47:11.764209  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.16553 (* 1 = 0.16553 loss)
I1006 20:47:11.764214  3817 sgd_solver.cpp:105] Iteration 26200, lr = 0.1
I1006 20:47:19.786680  3817 solver.cpp:218] Iteration 26300 (12.465 iter/s, 8.02244s/100 iters), loss = 0.168274
I1006 20:47:19.786711  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.168274 (* 1 = 0.168274 loss)
I1006 20:47:19.786716  3817 sgd_solver.cpp:105] Iteration 26300, lr = 0.1
I1006 20:47:27.816603  3817 solver.cpp:218] Iteration 26400 (12.4535 iter/s, 8.02987s/100 iters), loss = 0.243641
I1006 20:47:27.816711  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.243641 (* 1 = 0.243641 loss)
I1006 20:47:27.816718  3817 sgd_solver.cpp:105] Iteration 26400, lr = 0.1
I1006 20:47:35.472738  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:47:35.791599  3817 solver.cpp:330] Iteration 26500, Testing net (#0)
I1006 20:47:37.674054  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:47:37.753007  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6372
I1006 20:47:37.753031  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.38333 (* 1 = 1.38333 loss)
I1006 20:47:37.833609  3817 solver.cpp:218] Iteration 26500 (9.98316 iter/s, 10.0169s/100 iters), loss = 0.174241
I1006 20:47:37.833637  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.174242 (* 1 = 0.174242 loss)
I1006 20:47:37.833644  3817 sgd_solver.cpp:105] Iteration 26500, lr = 0.1
I1006 20:47:45.892124  3817 solver.cpp:218] Iteration 26600 (12.4093 iter/s, 8.05846s/100 iters), loss = 0.139842
I1006 20:47:45.892161  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.139842 (* 1 = 0.139842 loss)
I1006 20:47:45.892168  3817 sgd_solver.cpp:105] Iteration 26600, lr = 0.1
I1006 20:47:53.911649  3817 solver.cpp:218] Iteration 26700 (12.4697 iter/s, 8.01946s/100 iters), loss = 0.20508
I1006 20:47:53.911680  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.20508 (* 1 = 0.20508 loss)
I1006 20:47:53.911686  3817 sgd_solver.cpp:105] Iteration 26700, lr = 0.1
I1006 20:48:01.891702  3817 solver.cpp:218] Iteration 26800 (12.5313 iter/s, 7.98s/100 iters), loss = 0.257733
I1006 20:48:01.891842  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.257733 (* 1 = 0.257733 loss)
I1006 20:48:01.891850  3817 sgd_solver.cpp:105] Iteration 26800, lr = 0.1
I1006 20:48:09.914705  3817 solver.cpp:218] Iteration 26900 (12.4644 iter/s, 8.02284s/100 iters), loss = 0.150376
I1006 20:48:09.914736  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.150376 (* 1 = 0.150376 loss)
I1006 20:48:09.914743  3817 sgd_solver.cpp:105] Iteration 26900, lr = 0.1
I1006 20:48:17.492697  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:48:17.812100  3817 solver.cpp:330] Iteration 27000, Testing net (#0)
I1006 20:48:19.687273  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:48:19.765715  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7625
I1006 20:48:19.765749  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.837079 (* 1 = 0.837079 loss)
I1006 20:48:19.845394  3817 solver.cpp:218] Iteration 27000 (10.0699 iter/s, 9.93063s/100 iters), loss = 0.148435
I1006 20:48:19.845420  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.148435 (* 1 = 0.148435 loss)
I1006 20:48:19.845427  3817 sgd_solver.cpp:105] Iteration 27000, lr = 0.1
I1006 20:48:27.817201  3817 solver.cpp:218] Iteration 27100 (12.5443 iter/s, 7.97175s/100 iters), loss = 0.211469
I1006 20:48:27.817241  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.211469 (* 1 = 0.211469 loss)
I1006 20:48:27.817247  3817 sgd_solver.cpp:105] Iteration 27100, lr = 0.1
I1006 20:48:35.779068  3817 solver.cpp:218] Iteration 27200 (12.56 iter/s, 7.9618s/100 iters), loss = 0.273954
I1006 20:48:35.779211  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.273954 (* 1 = 0.273954 loss)
I1006 20:48:35.779218  3817 sgd_solver.cpp:105] Iteration 27200, lr = 0.1
I1006 20:48:43.746104  3817 solver.cpp:218] Iteration 27300 (12.552 iter/s, 7.96688s/100 iters), loss = 0.220739
I1006 20:48:43.746143  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.22074 (* 1 = 0.22074 loss)
I1006 20:48:43.746150  3817 sgd_solver.cpp:105] Iteration 27300, lr = 0.1
I1006 20:48:51.714799  3817 solver.cpp:218] Iteration 27400 (12.5492 iter/s, 7.96863s/100 iters), loss = 0.156781
I1006 20:48:51.714838  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.156781 (* 1 = 0.156781 loss)
I1006 20:48:51.714844  3817 sgd_solver.cpp:105] Iteration 27400, lr = 0.1
I1006 20:48:59.290951  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:48:59.610101  3817 solver.cpp:330] Iteration 27500, Testing net (#0)
I1006 20:49:01.488837  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:49:01.567582  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6916
I1006 20:49:01.567617  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.10092 (* 1 = 1.10092 loss)
I1006 20:49:01.647948  3817 solver.cpp:218] Iteration 27500 (10.0674 iter/s, 9.93308s/100 iters), loss = 0.171671
I1006 20:49:01.647974  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.171671 (* 1 = 0.171671 loss)
I1006 20:49:01.647980  3817 sgd_solver.cpp:105] Iteration 27500, lr = 0.1
I1006 20:49:09.609865  3817 solver.cpp:218] Iteration 27600 (12.5599 iter/s, 7.96187s/100 iters), loss = 0.139494
I1006 20:49:09.610003  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.139494 (* 1 = 0.139494 loss)
I1006 20:49:09.610011  3817 sgd_solver.cpp:105] Iteration 27600, lr = 0.1
I1006 20:49:17.578114  3817 solver.cpp:218] Iteration 27700 (12.55 iter/s, 7.9681s/100 iters), loss = 0.184333
I1006 20:49:17.578152  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.184334 (* 1 = 0.184334 loss)
I1006 20:49:17.578158  3817 sgd_solver.cpp:105] Iteration 27700, lr = 0.1
I1006 20:49:25.545284  3817 solver.cpp:218] Iteration 27800 (12.5516 iter/s, 7.9671s/100 iters), loss = 0.154804
I1006 20:49:25.545325  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.154805 (* 1 = 0.154805 loss)
I1006 20:49:25.545331  3817 sgd_solver.cpp:105] Iteration 27800, lr = 0.1
I1006 20:49:33.509709  3817 solver.cpp:218] Iteration 27900 (12.5559 iter/s, 7.96436s/100 iters), loss = 0.0848954
I1006 20:49:33.509748  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0848957 (* 1 = 0.0848957 loss)
I1006 20:49:33.509754  3817 sgd_solver.cpp:105] Iteration 27900, lr = 0.1
I1006 20:49:41.082288  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:49:41.400928  3817 solver.cpp:330] Iteration 28000, Testing net (#0)
I1006 20:49:43.277298  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:49:43.355798  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.5263
I1006 20:49:43.355823  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.96526 (* 1 = 1.96526 loss)
I1006 20:49:43.435696  3817 solver.cpp:218] Iteration 28000 (10.0746 iter/s, 9.92592s/100 iters), loss = 0.203827
I1006 20:49:43.435719  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.203828 (* 1 = 0.203828 loss)
I1006 20:49:43.435726  3817 sgd_solver.cpp:105] Iteration 28000, lr = 0.1
I1006 20:49:51.403450  3817 solver.cpp:218] Iteration 28100 (12.5507 iter/s, 7.96771s/100 iters), loss = 0.160833
I1006 20:49:51.403479  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.160833 (* 1 = 0.160833 loss)
I1006 20:49:51.403486  3817 sgd_solver.cpp:105] Iteration 28100, lr = 0.1
I1006 20:49:59.363267  3817 solver.cpp:218] Iteration 28200 (12.5632 iter/s, 7.95976s/100 iters), loss = 0.161501
I1006 20:49:59.363296  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.161501 (* 1 = 0.161501 loss)
I1006 20:49:59.363301  3817 sgd_solver.cpp:105] Iteration 28200, lr = 0.1
I1006 20:50:07.328794  3817 solver.cpp:218] Iteration 28300 (12.5542 iter/s, 7.96547s/100 iters), loss = 0.26765
I1006 20:50:07.328833  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.26765 (* 1 = 0.26765 loss)
I1006 20:50:07.328840  3817 sgd_solver.cpp:105] Iteration 28300, lr = 0.1
I1006 20:50:15.295318  3817 solver.cpp:218] Iteration 28400 (12.5526 iter/s, 7.96647s/100 iters), loss = 0.15861
I1006 20:50:15.295415  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.15861 (* 1 = 0.15861 loss)
I1006 20:50:15.295433  3817 sgd_solver.cpp:105] Iteration 28400, lr = 0.1
I1006 20:50:22.870019  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:50:23.191041  3817 solver.cpp:330] Iteration 28500, Testing net (#0)
I1006 20:50:25.066951  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:50:25.144964  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7215
I1006 20:50:25.144999  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.966001 (* 1 = 0.966001 loss)
I1006 20:50:25.224905  3817 solver.cpp:218] Iteration 28500 (10.071 iter/s, 9.92946s/100 iters), loss = 0.132017
I1006 20:50:25.224931  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.132017 (* 1 = 0.132017 loss)
I1006 20:50:25.224938  3817 sgd_solver.cpp:105] Iteration 28500, lr = 0.1
I1006 20:50:33.187124  3817 solver.cpp:218] Iteration 28600 (12.5594 iter/s, 7.96217s/100 iters), loss = 0.19948
I1006 20:50:33.187165  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.19948 (* 1 = 0.19948 loss)
I1006 20:50:33.187171  3817 sgd_solver.cpp:105] Iteration 28600, lr = 0.1
I1006 20:50:41.156693  3817 solver.cpp:218] Iteration 28700 (12.5478 iter/s, 7.9695s/100 iters), loss = 0.170721
I1006 20:50:41.156721  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.170721 (* 1 = 0.170721 loss)
I1006 20:50:41.156728  3817 sgd_solver.cpp:105] Iteration 28700, lr = 0.1
I1006 20:50:49.124922  3817 solver.cpp:218] Iteration 28800 (12.5499 iter/s, 7.96817s/100 iters), loss = 0.257355
I1006 20:50:49.125039  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.257355 (* 1 = 0.257355 loss)
I1006 20:50:49.125051  3817 sgd_solver.cpp:105] Iteration 28800, lr = 0.1
I1006 20:50:57.090471  3817 solver.cpp:218] Iteration 28900 (12.5543 iter/s, 7.96542s/100 iters), loss = 0.194768
I1006 20:50:57.090502  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.194768 (* 1 = 0.194768 loss)
I1006 20:50:57.090507  3817 sgd_solver.cpp:105] Iteration 28900, lr = 0.1
I1006 20:51:04.652405  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:51:04.970985  3817 solver.cpp:330] Iteration 29000, Testing net (#0)
I1006 20:51:06.848120  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:51:06.926360  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7721
I1006 20:51:06.926394  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.780776 (* 1 = 0.780776 loss)
I1006 20:51:07.005915  3817 solver.cpp:218] Iteration 29000 (10.0853 iter/s, 9.91539s/100 iters), loss = 0.106105
I1006 20:51:07.005939  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.106105 (* 1 = 0.106105 loss)
I1006 20:51:07.005946  3817 sgd_solver.cpp:105] Iteration 29000, lr = 0.1
I1006 20:51:14.968780  3817 solver.cpp:218] Iteration 29100 (12.5584 iter/s, 7.96281s/100 iters), loss = 0.167617
I1006 20:51:14.968821  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.167617 (* 1 = 0.167617 loss)
I1006 20:51:14.968827  3817 sgd_solver.cpp:105] Iteration 29100, lr = 0.1
I1006 20:51:22.927170  3817 solver.cpp:218] Iteration 29200 (12.5655 iter/s, 7.95833s/100 iters), loss = 0.158307
I1006 20:51:22.927266  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.158307 (* 1 = 0.158307 loss)
I1006 20:51:22.927274  3817 sgd_solver.cpp:105] Iteration 29200, lr = 0.1
I1006 20:51:30.893837  3817 solver.cpp:218] Iteration 29300 (12.5525 iter/s, 7.96654s/100 iters), loss = 0.128399
I1006 20:51:30.893867  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.128399 (* 1 = 0.128399 loss)
I1006 20:51:30.893873  3817 sgd_solver.cpp:105] Iteration 29300, lr = 0.1
I1006 20:51:38.852452  3817 solver.cpp:218] Iteration 29400 (12.5651 iter/s, 7.95856s/100 iters), loss = 0.132755
I1006 20:51:38.852480  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.132755 (* 1 = 0.132755 loss)
I1006 20:51:38.852486  3817 sgd_solver.cpp:105] Iteration 29400, lr = 0.1
I1006 20:51:46.422344  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:51:46.741240  3817 solver.cpp:330] Iteration 29500, Testing net (#0)
I1006 20:51:48.617156  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:51:48.695230  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7884
I1006 20:51:48.695266  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.790865 (* 1 = 0.790865 loss)
I1006 20:51:48.775171  3817 solver.cpp:218] Iteration 29500 (10.0779 iter/s, 9.92266s/100 iters), loss = 0.202744
I1006 20:51:48.775197  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.202744 (* 1 = 0.202744 loss)
I1006 20:51:48.775203  3817 sgd_solver.cpp:105] Iteration 29500, lr = 0.1
I1006 20:51:56.735221  3817 solver.cpp:218] Iteration 29600 (12.5628 iter/s, 7.96s/100 iters), loss = 0.124766
I1006 20:51:56.735337  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.124766 (* 1 = 0.124766 loss)
I1006 20:51:56.735354  3817 sgd_solver.cpp:105] Iteration 29600, lr = 0.1
I1006 20:52:04.708854  3817 solver.cpp:218] Iteration 29700 (12.5415 iter/s, 7.9735s/100 iters), loss = 0.166185
I1006 20:52:04.708894  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.166185 (* 1 = 0.166185 loss)
I1006 20:52:04.708900  3817 sgd_solver.cpp:105] Iteration 29700, lr = 0.1
I1006 20:52:12.676085  3817 solver.cpp:218] Iteration 29800 (12.5515 iter/s, 7.96717s/100 iters), loss = 0.202945
I1006 20:52:12.676115  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.202945 (* 1 = 0.202945 loss)
I1006 20:52:12.676120  3817 sgd_solver.cpp:105] Iteration 29800, lr = 0.1
I1006 20:52:20.646708  3817 solver.cpp:218] Iteration 29900 (12.5462 iter/s, 7.97057s/100 iters), loss = 0.124179
I1006 20:52:20.646739  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.124179 (* 1 = 0.124179 loss)
I1006 20:52:20.646756  3817 sgd_solver.cpp:105] Iteration 29900, lr = 0.1
I1006 20:52:28.212633  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:52:28.530782  3817 solver.cpp:330] Iteration 30000, Testing net (#0)
I1006 20:52:30.407981  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:52:30.486095  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7411
I1006 20:52:30.486130  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.851338 (* 1 = 0.851338 loss)
I1006 20:52:30.565843  3817 solver.cpp:218] Iteration 30000 (10.0816 iter/s, 9.91908s/100 iters), loss = 0.212175
I1006 20:52:30.565881  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.212175 (* 1 = 0.212175 loss)
I1006 20:52:30.565887  3817 sgd_solver.cpp:105] Iteration 30000, lr = 0.1
I1006 20:52:38.529093  3817 solver.cpp:218] Iteration 30100 (12.5578 iter/s, 7.96318s/100 iters), loss = 0.184406
I1006 20:52:38.529124  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.184406 (* 1 = 0.184406 loss)
I1006 20:52:38.529139  3817 sgd_solver.cpp:105] Iteration 30100, lr = 0.1
I1006 20:52:46.485343  3817 solver.cpp:218] Iteration 30200 (12.5688 iter/s, 7.9562s/100 iters), loss = 0.236783
I1006 20:52:46.485371  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.236783 (* 1 = 0.236783 loss)
I1006 20:52:46.485378  3817 sgd_solver.cpp:105] Iteration 30200, lr = 0.1
I1006 20:52:54.457659  3817 solver.cpp:218] Iteration 30300 (12.5435 iter/s, 7.97226s/100 iters), loss = 0.246534
I1006 20:52:54.457689  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.246534 (* 1 = 0.246534 loss)
I1006 20:52:54.457705  3817 sgd_solver.cpp:105] Iteration 30300, lr = 0.1
I1006 20:53:02.417176  3817 solver.cpp:218] Iteration 30400 (12.5637 iter/s, 7.95946s/100 iters), loss = 0.178642
I1006 20:53:02.417289  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.178642 (* 1 = 0.178642 loss)
I1006 20:53:02.417305  3817 sgd_solver.cpp:105] Iteration 30400, lr = 0.1
I1006 20:53:09.986433  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:53:10.305536  3817 solver.cpp:330] Iteration 30500, Testing net (#0)
I1006 20:53:12.182725  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:53:12.260848  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7512
I1006 20:53:12.260881  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.769734 (* 1 = 0.769734 loss)
I1006 20:53:12.340477  3817 solver.cpp:218] Iteration 30500 (10.0774 iter/s, 9.92317s/100 iters), loss = 0.135955
I1006 20:53:12.340502  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.135955 (* 1 = 0.135955 loss)
I1006 20:53:12.340508  3817 sgd_solver.cpp:105] Iteration 30500, lr = 0.1
I1006 20:53:20.303972  3817 solver.cpp:218] Iteration 30600 (12.5574 iter/s, 7.96345s/100 iters), loss = 0.255932
I1006 20:53:20.304000  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.255932 (* 1 = 0.255932 loss)
I1006 20:53:20.304006  3817 sgd_solver.cpp:105] Iteration 30600, lr = 0.1
I1006 20:53:28.278748  3817 solver.cpp:218] Iteration 30700 (12.5396 iter/s, 7.97472s/100 iters), loss = 0.140293
I1006 20:53:28.278784  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.140293 (* 1 = 0.140293 loss)
I1006 20:53:28.278791  3817 sgd_solver.cpp:105] Iteration 30700, lr = 0.1
I1006 20:53:36.253372  3817 solver.cpp:218] Iteration 30800 (12.5399 iter/s, 7.97457s/100 iters), loss = 0.157296
I1006 20:53:36.253513  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.157296 (* 1 = 0.157296 loss)
I1006 20:53:36.253522  3817 sgd_solver.cpp:105] Iteration 30800, lr = 0.1
I1006 20:53:44.235443  3817 solver.cpp:218] Iteration 30900 (12.5283 iter/s, 7.98191s/100 iters), loss = 0.147392
I1006 20:53:44.235479  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.147392 (* 1 = 0.147392 loss)
I1006 20:53:44.235487  3817 sgd_solver.cpp:105] Iteration 30900, lr = 0.1
I1006 20:53:51.811442  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:53:52.130640  3817 solver.cpp:330] Iteration 31000, Testing net (#0)
I1006 20:53:54.007511  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:53:54.085897  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.5396
I1006 20:53:54.085933  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 2.00861 (* 1 = 2.00861 loss)
I1006 20:53:54.165464  3817 solver.cpp:218] Iteration 31000 (10.0705 iter/s, 9.92996s/100 iters), loss = 0.135611
I1006 20:53:54.165488  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.135611 (* 1 = 0.135611 loss)
I1006 20:53:54.165495  3817 sgd_solver.cpp:105] Iteration 31000, lr = 0.1
I1006 20:54:02.130262  3817 solver.cpp:218] Iteration 31100 (12.5553 iter/s, 7.96475s/100 iters), loss = 0.206268
I1006 20:54:02.130291  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.206268 (* 1 = 0.206268 loss)
I1006 20:54:02.130297  3817 sgd_solver.cpp:105] Iteration 31100, lr = 0.1
I1006 20:54:10.092727  3817 solver.cpp:218] Iteration 31200 (12.559 iter/s, 7.96241s/100 iters), loss = 0.224649
I1006 20:54:10.092836  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.224649 (* 1 = 0.224649 loss)
I1006 20:54:10.092844  3817 sgd_solver.cpp:105] Iteration 31200, lr = 0.1
I1006 20:54:18.061499  3817 solver.cpp:218] Iteration 31300 (12.5492 iter/s, 7.96864s/100 iters), loss = 0.114065
I1006 20:54:18.061539  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.114065 (* 1 = 0.114065 loss)
I1006 20:54:18.061545  3817 sgd_solver.cpp:105] Iteration 31300, lr = 0.1
I1006 20:54:26.022047  3817 solver.cpp:218] Iteration 31400 (12.5621 iter/s, 7.96048s/100 iters), loss = 0.133996
I1006 20:54:26.022088  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.133996 (* 1 = 0.133996 loss)
I1006 20:54:26.022094  3817 sgd_solver.cpp:105] Iteration 31400, lr = 0.1
I1006 20:54:33.590839  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:54:33.908654  3817 solver.cpp:330] Iteration 31500, Testing net (#0)
I1006 20:54:35.785104  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:54:35.863144  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7291
I1006 20:54:35.863183  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.889856 (* 1 = 0.889856 loss)
I1006 20:54:35.942986  3817 solver.cpp:218] Iteration 31500 (10.0798 iter/s, 9.92087s/100 iters), loss = 0.124429
I1006 20:54:35.943012  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.124429 (* 1 = 0.124429 loss)
I1006 20:54:35.943018  3817 sgd_solver.cpp:105] Iteration 31500, lr = 0.1
I1006 20:54:43.905095  3817 solver.cpp:218] Iteration 31600 (12.5596 iter/s, 7.96206s/100 iters), loss = 0.119941
I1006 20:54:43.905194  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.119941 (* 1 = 0.119941 loss)
I1006 20:54:43.905200  3817 sgd_solver.cpp:105] Iteration 31600, lr = 0.1
I1006 20:54:51.863029  3817 solver.cpp:218] Iteration 31700 (12.5663 iter/s, 7.95782s/100 iters), loss = 0.183089
I1006 20:54:51.863057  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.18309 (* 1 = 0.18309 loss)
I1006 20:54:51.863064  3817 sgd_solver.cpp:105] Iteration 31700, lr = 0.1
I1006 20:54:59.824693  3817 solver.cpp:218] Iteration 31800 (12.5603 iter/s, 7.96161s/100 iters), loss = 0.188541
I1006 20:54:59.824733  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.188541 (* 1 = 0.188541 loss)
I1006 20:54:59.824739  3817 sgd_solver.cpp:105] Iteration 31800, lr = 0.1
I1006 20:55:07.791075  3817 solver.cpp:218] Iteration 31900 (12.5529 iter/s, 7.96632s/100 iters), loss = 0.152186
I1006 20:55:07.791115  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.152186 (* 1 = 0.152186 loss)
I1006 20:55:07.791121  3817 sgd_solver.cpp:105] Iteration 31900, lr = 0.1
I1006 20:55:15.354776  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:55:15.674823  3817 solver.cpp:330] Iteration 32000, Testing net (#0)
I1006 20:55:17.549873  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:55:17.627905  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7115
I1006 20:55:17.627940  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.969966 (* 1 = 0.969966 loss)
I1006 20:55:17.707834  3817 solver.cpp:218] Iteration 32000 (10.084 iter/s, 9.91669s/100 iters), loss = 0.0667765
I1006 20:55:17.707859  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0667766 (* 1 = 0.0667766 loss)
I1006 20:55:17.707864  3817 sgd_solver.cpp:105] Iteration 32000, lr = 0.1
I1006 20:55:25.675794  3817 solver.cpp:218] Iteration 32100 (12.5503 iter/s, 7.96791s/100 iters), loss = 0.156117
I1006 20:55:25.675825  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.156117 (* 1 = 0.156117 loss)
I1006 20:55:25.675832  3817 sgd_solver.cpp:105] Iteration 32100, lr = 0.1
I1006 20:55:33.641193  3817 solver.cpp:218] Iteration 32200 (12.5544 iter/s, 7.96534s/100 iters), loss = 0.16756
I1006 20:55:33.641234  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.16756 (* 1 = 0.16756 loss)
I1006 20:55:33.641240  3817 sgd_solver.cpp:105] Iteration 32200, lr = 0.1
I1006 20:55:41.605505  3817 solver.cpp:218] Iteration 32300 (12.5561 iter/s, 7.96425s/100 iters), loss = 0.223338
I1006 20:55:41.605547  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.223338 (* 1 = 0.223338 loss)
I1006 20:55:41.605553  3817 sgd_solver.cpp:105] Iteration 32300, lr = 0.1
I1006 20:55:49.573555  3817 solver.cpp:218] Iteration 32400 (12.5502 iter/s, 7.96798s/100 iters), loss = 0.127913
I1006 20:55:49.573678  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.127913 (* 1 = 0.127913 loss)
I1006 20:55:49.573688  3817 sgd_solver.cpp:105] Iteration 32400, lr = 0.1
I1006 20:55:57.145290  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:55:57.463850  3817 solver.cpp:330] Iteration 32500, Testing net (#0)
I1006 20:55:59.339984  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:55:59.418329  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6797
I1006 20:55:59.418364  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.14945 (* 1 = 1.14945 loss)
I1006 20:55:59.497896  3817 solver.cpp:218] Iteration 32500 (10.0764 iter/s, 9.9242s/100 iters), loss = 0.156956
I1006 20:55:59.497921  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.156956 (* 1 = 0.156956 loss)
I1006 20:55:59.497928  3817 sgd_solver.cpp:105] Iteration 32500, lr = 0.1
I1006 20:56:07.456161  3817 solver.cpp:218] Iteration 32600 (12.5656 iter/s, 7.95822s/100 iters), loss = 0.196734
I1006 20:56:07.456192  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.196734 (* 1 = 0.196734 loss)
I1006 20:56:07.456197  3817 sgd_solver.cpp:105] Iteration 32600, lr = 0.1
I1006 20:56:15.420224  3817 solver.cpp:218] Iteration 32700 (12.5565 iter/s, 7.96401s/100 iters), loss = 0.191643
I1006 20:56:15.420264  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.191643 (* 1 = 0.191643 loss)
I1006 20:56:15.420270  3817 sgd_solver.cpp:105] Iteration 32700, lr = 0.1
I1006 20:56:23.369344  3817 solver.cpp:218] Iteration 32800 (12.5801 iter/s, 7.94906s/100 iters), loss = 0.161482
I1006 20:56:23.369488  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.161482 (* 1 = 0.161482 loss)
I1006 20:56:23.369496  3817 sgd_solver.cpp:105] Iteration 32800, lr = 0.1
I1006 20:56:31.338373  3817 solver.cpp:218] Iteration 32900 (12.5488 iter/s, 7.96886s/100 iters), loss = 0.235207
I1006 20:56:31.338403  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.235207 (* 1 = 0.235207 loss)
I1006 20:56:31.338409  3817 sgd_solver.cpp:105] Iteration 32900, lr = 0.1
I1006 20:56:38.907182  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:56:39.227108  3817 solver.cpp:330] Iteration 33000, Testing net (#0)
I1006 20:56:41.105254  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:56:41.183264  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.4943
I1006 20:56:41.183297  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 2.2195 (* 1 = 2.2195 loss)
I1006 20:56:41.262661  3817 solver.cpp:218] Iteration 33000 (10.0764 iter/s, 9.92423s/100 iters), loss = 0.211765
I1006 20:56:41.262691  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.211765 (* 1 = 0.211765 loss)
I1006 20:56:41.262697  3817 sgd_solver.cpp:105] Iteration 33000, lr = 0.1
I1006 20:56:49.227341  3817 solver.cpp:218] Iteration 33100 (12.5555 iter/s, 7.96463s/100 iters), loss = 0.261418
I1006 20:56:49.227382  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.261419 (* 1 = 0.261419 loss)
I1006 20:56:49.227388  3817 sgd_solver.cpp:105] Iteration 33100, lr = 0.1
I1006 20:56:57.186475  3817 solver.cpp:218] Iteration 33200 (12.5643 iter/s, 7.95907s/100 iters), loss = 0.153412
I1006 20:56:57.186627  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.153412 (* 1 = 0.153412 loss)
I1006 20:56:57.186635  3817 sgd_solver.cpp:105] Iteration 33200, lr = 0.1
I1006 20:57:05.144419  3817 solver.cpp:218] Iteration 33300 (12.5663 iter/s, 7.95778s/100 iters), loss = 0.18746
I1006 20:57:05.144450  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.18746 (* 1 = 0.18746 loss)
I1006 20:57:05.144456  3817 sgd_solver.cpp:105] Iteration 33300, lr = 0.1
I1006 20:57:13.106696  3817 solver.cpp:218] Iteration 33400 (12.5593 iter/s, 7.96222s/100 iters), loss = 0.155261
I1006 20:57:13.106725  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.155261 (* 1 = 0.155261 loss)
I1006 20:57:13.106731  3817 sgd_solver.cpp:105] Iteration 33400, lr = 0.1
I1006 20:57:20.677161  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:57:20.997134  3817 solver.cpp:330] Iteration 33500, Testing net (#0)
I1006 20:57:22.873158  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:57:22.951802  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7698
I1006 20:57:22.951838  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.830005 (* 1 = 0.830005 loss)
I1006 20:57:23.031810  3817 solver.cpp:218] Iteration 33500 (10.0755 iter/s, 9.92505s/100 iters), loss = 0.136952
I1006 20:57:23.031834  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.136952 (* 1 = 0.136952 loss)
I1006 20:57:23.031841  3817 sgd_solver.cpp:105] Iteration 33500, lr = 0.1
I1006 20:57:30.993891  3817 solver.cpp:218] Iteration 33600 (12.5596 iter/s, 7.96203s/100 iters), loss = 0.197914
I1006 20:57:30.994024  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.197914 (* 1 = 0.197914 loss)
I1006 20:57:30.994030  3817 sgd_solver.cpp:105] Iteration 33600, lr = 0.1
I1006 20:57:38.964016  3817 solver.cpp:218] Iteration 33700 (12.5471 iter/s, 7.96997s/100 iters), loss = 0.157152
I1006 20:57:38.964056  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.157152 (* 1 = 0.157152 loss)
I1006 20:57:38.964062  3817 sgd_solver.cpp:105] Iteration 33700, lr = 0.1
I1006 20:57:46.928409  3817 solver.cpp:218] Iteration 33800 (12.556 iter/s, 7.96433s/100 iters), loss = 0.186864
I1006 20:57:46.928439  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.186864 (* 1 = 0.186864 loss)
I1006 20:57:46.928445  3817 sgd_solver.cpp:105] Iteration 33800, lr = 0.1
I1006 20:57:54.901521  3817 solver.cpp:218] Iteration 33900 (12.5422 iter/s, 7.97306s/100 iters), loss = 0.126052
I1006 20:57:54.901552  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.126052 (* 1 = 0.126052 loss)
I1006 20:57:54.901558  3817 sgd_solver.cpp:105] Iteration 33900, lr = 0.1
I1006 20:58:02.466033  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:58:02.784637  3817 solver.cpp:330] Iteration 34000, Testing net (#0)
I1006 20:58:04.660609  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:58:04.738819  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6396
I1006 20:58:04.738857  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.38102 (* 1 = 1.38102 loss)
I1006 20:58:04.818804  3817 solver.cpp:218] Iteration 34000 (10.0835 iter/s, 9.91722s/100 iters), loss = 0.188472
I1006 20:58:04.818830  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.188472 (* 1 = 0.188472 loss)
I1006 20:58:04.818835  3817 sgd_solver.cpp:105] Iteration 34000, lr = 0.1
I1006 20:58:12.790833  3817 solver.cpp:218] Iteration 34100 (12.5439 iter/s, 7.97198s/100 iters), loss = 0.159067
I1006 20:58:12.790873  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.159067 (* 1 = 0.159067 loss)
I1006 20:58:12.790879  3817 sgd_solver.cpp:105] Iteration 34100, lr = 0.1
I1006 20:58:20.752794  3817 solver.cpp:218] Iteration 34200 (12.5598 iter/s, 7.9619s/100 iters), loss = 0.237649
I1006 20:58:20.752835  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.237649 (* 1 = 0.237649 loss)
I1006 20:58:20.752840  3817 sgd_solver.cpp:105] Iteration 34200, lr = 0.1
I1006 20:58:28.719210  3817 solver.cpp:218] Iteration 34300 (12.5528 iter/s, 7.96635s/100 iters), loss = 0.189411
I1006 20:58:28.719249  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.189411 (* 1 = 0.189411 loss)
I1006 20:58:28.719255  3817 sgd_solver.cpp:105] Iteration 34300, lr = 0.1
I1006 20:58:36.681776  3817 solver.cpp:218] Iteration 34400 (12.5589 iter/s, 7.96251s/100 iters), loss = 0.117789
I1006 20:58:36.681892  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.117789 (* 1 = 0.117789 loss)
I1006 20:58:36.681900  3817 sgd_solver.cpp:105] Iteration 34400, lr = 0.1
I1006 20:58:44.252646  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:58:44.571537  3817 solver.cpp:330] Iteration 34500, Testing net (#0)
I1006 20:58:46.450107  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:58:46.528385  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6894
I1006 20:58:46.528420  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.06141 (* 1 = 1.06141 loss)
I1006 20:58:46.608530  3817 solver.cpp:218] Iteration 34500 (10.0739 iter/s, 9.92661s/100 iters), loss = 0.186748
I1006 20:58:46.608553  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.186748 (* 1 = 0.186748 loss)
I1006 20:58:46.608561  3817 sgd_solver.cpp:105] Iteration 34500, lr = 0.1
I1006 20:58:54.572841  3817 solver.cpp:218] Iteration 34600 (12.5561 iter/s, 7.96426s/100 iters), loss = 0.2095
I1006 20:58:54.572882  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.209501 (* 1 = 0.209501 loss)
I1006 20:58:54.572888  3817 sgd_solver.cpp:105] Iteration 34600, lr = 0.1
I1006 20:59:02.536108  3817 solver.cpp:218] Iteration 34700 (12.5578 iter/s, 7.9632s/100 iters), loss = 0.226602
I1006 20:59:02.536147  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.226602 (* 1 = 0.226602 loss)
I1006 20:59:02.536154  3817 sgd_solver.cpp:105] Iteration 34700, lr = 0.1
I1006 20:59:10.497831  3817 solver.cpp:218] Iteration 34800 (12.5602 iter/s, 7.96166s/100 iters), loss = 0.243638
I1006 20:59:10.497948  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.243638 (* 1 = 0.243638 loss)
I1006 20:59:10.497967  3817 sgd_solver.cpp:105] Iteration 34800, lr = 0.1
I1006 20:59:18.463196  3817 solver.cpp:218] Iteration 34900 (12.5546 iter/s, 7.96523s/100 iters), loss = 0.132329
I1006 20:59:18.463224  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.13233 (* 1 = 0.13233 loss)
I1006 20:59:18.463230  3817 sgd_solver.cpp:105] Iteration 34900, lr = 0.1
I1006 20:59:26.034857  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:59:26.354399  3817 solver.cpp:330] Iteration 35000, Testing net (#0)
I1006 20:59:28.229982  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 20:59:28.308394  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7628
I1006 20:59:28.308430  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.861504 (* 1 = 0.861504 loss)
I1006 20:59:28.388200  3817 solver.cpp:218] Iteration 35000 (10.0756 iter/s, 9.92495s/100 iters), loss = 0.120447
I1006 20:59:28.388226  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.120447 (* 1 = 0.120447 loss)
I1006 20:59:28.388232  3817 sgd_solver.cpp:105] Iteration 35000, lr = 0.1
I1006 20:59:36.361500  3817 solver.cpp:218] Iteration 35100 (12.5419 iter/s, 7.97325s/100 iters), loss = 0.307543
I1006 20:59:36.361541  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.307543 (* 1 = 0.307543 loss)
I1006 20:59:36.361547  3817 sgd_solver.cpp:105] Iteration 35100, lr = 0.1
I1006 20:59:44.328609  3817 solver.cpp:218] Iteration 35200 (12.5517 iter/s, 7.96705s/100 iters), loss = 0.268681
I1006 20:59:44.328766  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.268681 (* 1 = 0.268681 loss)
I1006 20:59:44.328785  3817 sgd_solver.cpp:105] Iteration 35200, lr = 0.1
I1006 20:59:52.301364  3817 solver.cpp:218] Iteration 35300 (12.543 iter/s, 7.97258s/100 iters), loss = 0.195303
I1006 20:59:52.301404  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.195303 (* 1 = 0.195303 loss)
I1006 20:59:52.301410  3817 sgd_solver.cpp:105] Iteration 35300, lr = 0.1
I1006 21:00:00.274029  3817 solver.cpp:218] Iteration 35400 (12.543 iter/s, 7.9726s/100 iters), loss = 0.152437
I1006 21:00:00.274061  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.152438 (* 1 = 0.152438 loss)
I1006 21:00:00.274067  3817 sgd_solver.cpp:105] Iteration 35400, lr = 0.1
I1006 21:00:07.850270  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:00:08.169344  3817 solver.cpp:330] Iteration 35500, Testing net (#0)
I1006 21:00:10.046165  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:00:10.124665  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7289
I1006 21:00:10.124701  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.929186 (* 1 = 0.929186 loss)
I1006 21:00:10.204766  3817 solver.cpp:218] Iteration 35500 (10.0698 iter/s, 9.93068s/100 iters), loss = 0.0811861
I1006 21:00:10.204792  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0811863 (* 1 = 0.0811863 loss)
I1006 21:00:10.204797  3817 sgd_solver.cpp:105] Iteration 35500, lr = 0.1
I1006 21:00:18.170972  3817 solver.cpp:218] Iteration 35600 (12.5531 iter/s, 7.96616s/100 iters), loss = 0.224894
I1006 21:00:18.171118  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.224894 (* 1 = 0.224894 loss)
I1006 21:00:18.171136  3817 sgd_solver.cpp:105] Iteration 35600, lr = 0.1
I1006 21:00:26.139963  3817 solver.cpp:218] Iteration 35700 (12.5489 iter/s, 7.96883s/100 iters), loss = 0.237884
I1006 21:00:26.139993  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.237884 (* 1 = 0.237884 loss)
I1006 21:00:26.140000  3817 sgd_solver.cpp:105] Iteration 35700, lr = 0.1
I1006 21:00:34.103736  3817 solver.cpp:218] Iteration 35800 (12.5569 iter/s, 7.96372s/100 iters), loss = 0.190314
I1006 21:00:34.103767  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.190314 (* 1 = 0.190314 loss)
I1006 21:00:34.103773  3817 sgd_solver.cpp:105] Iteration 35800, lr = 0.1
I1006 21:00:42.066998  3817 solver.cpp:218] Iteration 35900 (12.5578 iter/s, 7.96321s/100 iters), loss = 0.112027
I1006 21:00:42.067028  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.112027 (* 1 = 0.112027 loss)
I1006 21:00:42.067034  3817 sgd_solver.cpp:105] Iteration 35900, lr = 0.1
I1006 21:00:49.637264  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:00:49.955910  3817 solver.cpp:330] Iteration 36000, Testing net (#0)
I1006 21:00:51.832830  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:00:51.910912  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7736
I1006 21:00:51.910948  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.724736 (* 1 = 0.724736 loss)
I1006 21:00:51.990643  3817 solver.cpp:218] Iteration 36000 (10.077 iter/s, 9.92359s/100 iters), loss = 0.194058
I1006 21:00:51.990669  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.194058 (* 1 = 0.194058 loss)
I1006 21:00:51.990686  3817 sgd_solver.cpp:105] Iteration 36000, lr = 0.1
I1006 21:00:59.955400  3817 solver.cpp:218] Iteration 36100 (12.5554 iter/s, 7.96471s/100 iters), loss = 0.181039
I1006 21:00:59.955440  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.181039 (* 1 = 0.181039 loss)
I1006 21:00:59.955446  3817 sgd_solver.cpp:105] Iteration 36100, lr = 0.1
I1006 21:01:07.916273  3817 solver.cpp:218] Iteration 36200 (12.5615 iter/s, 7.96081s/100 iters), loss = 0.153283
I1006 21:01:07.916313  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.153283 (* 1 = 0.153283 loss)
I1006 21:01:07.916321  3817 sgd_solver.cpp:105] Iteration 36200, lr = 0.1
I1006 21:01:15.882666  3817 solver.cpp:218] Iteration 36300 (12.5528 iter/s, 7.96633s/100 iters), loss = 0.17715
I1006 21:01:15.882697  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.17715 (* 1 = 0.17715 loss)
I1006 21:01:15.882704  3817 sgd_solver.cpp:105] Iteration 36300, lr = 0.1
I1006 21:01:23.848464  3817 solver.cpp:218] Iteration 36400 (12.5538 iter/s, 7.96574s/100 iters), loss = 0.1754
I1006 21:01:23.848572  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.1754 (* 1 = 0.1754 loss)
I1006 21:01:23.848580  3817 sgd_solver.cpp:105] Iteration 36400, lr = 0.1
I1006 21:01:31.420861  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:01:31.740805  3817 solver.cpp:330] Iteration 36500, Testing net (#0)
I1006 21:01:33.617061  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:01:33.695340  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.5564
I1006 21:01:33.695375  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 2.38588 (* 1 = 2.38588 loss)
I1006 21:01:33.775614  3817 solver.cpp:218] Iteration 36500 (10.0735 iter/s, 9.92702s/100 iters), loss = 0.1749
I1006 21:01:33.775640  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.1749 (* 1 = 0.1749 loss)
I1006 21:01:33.775647  3817 sgd_solver.cpp:105] Iteration 36500, lr = 0.1
I1006 21:01:41.740896  3817 solver.cpp:218] Iteration 36600 (12.5546 iter/s, 7.96523s/100 iters), loss = 0.191526
I1006 21:01:41.740928  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.191527 (* 1 = 0.191527 loss)
I1006 21:01:41.740936  3817 sgd_solver.cpp:105] Iteration 36600, lr = 0.1
I1006 21:01:49.753587  3817 solver.cpp:218] Iteration 36700 (12.4803 iter/s, 8.01263s/100 iters), loss = 0.136341
I1006 21:01:49.753626  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.136341 (* 1 = 0.136341 loss)
I1006 21:01:49.753633  3817 sgd_solver.cpp:105] Iteration 36700, lr = 0.1
I1006 21:01:57.741616  3817 solver.cpp:218] Iteration 36800 (12.5188 iter/s, 7.98797s/100 iters), loss = 0.130062
I1006 21:01:57.741780  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.130062 (* 1 = 0.130062 loss)
I1006 21:01:57.741787  3817 sgd_solver.cpp:105] Iteration 36800, lr = 0.1
I1006 21:02:05.712494  3817 solver.cpp:218] Iteration 36900 (12.546 iter/s, 7.97069s/100 iters), loss = 0.1399
I1006 21:02:05.712523  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.1399 (* 1 = 0.1399 loss)
I1006 21:02:05.712529  3817 sgd_solver.cpp:105] Iteration 36900, lr = 0.1
I1006 21:02:13.285534  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:02:13.604984  3817 solver.cpp:330] Iteration 37000, Testing net (#0)
I1006 21:02:15.479846  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:02:15.558331  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.5851
I1006 21:02:15.558365  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 2.15174 (* 1 = 2.15174 loss)
I1006 21:02:15.638447  3817 solver.cpp:218] Iteration 37000 (10.0747 iter/s, 9.9259s/100 iters), loss = 0.0931706
I1006 21:02:15.638471  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0931707 (* 1 = 0.0931707 loss)
I1006 21:02:15.638478  3817 sgd_solver.cpp:105] Iteration 37000, lr = 0.1
I1006 21:02:23.600108  3817 solver.cpp:218] Iteration 37100 (12.5603 iter/s, 7.96161s/100 iters), loss = 0.211375
I1006 21:02:23.600148  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.211375 (* 1 = 0.211375 loss)
I1006 21:02:23.600154  3817 sgd_solver.cpp:105] Iteration 37100, lr = 0.1
I1006 21:02:31.562865  3817 solver.cpp:218] Iteration 37200 (12.5586 iter/s, 7.96269s/100 iters), loss = 0.170654
I1006 21:02:31.562985  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.170655 (* 1 = 0.170655 loss)
I1006 21:02:31.562994  3817 sgd_solver.cpp:105] Iteration 37200, lr = 0.1
I1006 21:02:39.523978  3817 solver.cpp:218] Iteration 37300 (12.5613 iter/s, 7.96098s/100 iters), loss = 0.184637
I1006 21:02:39.524019  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.184638 (* 1 = 0.184638 loss)
I1006 21:02:39.524024  3817 sgd_solver.cpp:105] Iteration 37300, lr = 0.1
I1006 21:02:47.496531  3817 solver.cpp:218] Iteration 37400 (12.5431 iter/s, 7.97249s/100 iters), loss = 0.180295
I1006 21:02:47.496561  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.180295 (* 1 = 0.180295 loss)
I1006 21:02:47.496567  3817 sgd_solver.cpp:105] Iteration 37400, lr = 0.1
I1006 21:02:55.065408  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:02:55.383682  3817 solver.cpp:330] Iteration 37500, Testing net (#0)
I1006 21:02:57.261167  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:02:57.339720  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7997
I1006 21:02:57.339756  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.659711 (* 1 = 0.659711 loss)
I1006 21:02:57.420120  3817 solver.cpp:218] Iteration 37500 (10.0771 iter/s, 9.92353s/100 iters), loss = 0.135042
I1006 21:02:57.420145  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.135042 (* 1 = 0.135042 loss)
I1006 21:02:57.420152  3817 sgd_solver.cpp:105] Iteration 37500, lr = 0.1
I1006 21:03:05.395041  3817 solver.cpp:218] Iteration 37600 (12.5394 iter/s, 7.97487s/100 iters), loss = 0.216202
I1006 21:03:05.395196  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.216202 (* 1 = 0.216202 loss)
I1006 21:03:05.395215  3817 sgd_solver.cpp:105] Iteration 37600, lr = 0.1
I1006 21:03:13.365617  3817 solver.cpp:218] Iteration 37700 (12.5464 iter/s, 7.9704s/100 iters), loss = 0.140781
I1006 21:03:13.365658  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.140781 (* 1 = 0.140781 loss)
I1006 21:03:13.365664  3817 sgd_solver.cpp:105] Iteration 37700, lr = 0.1
I1006 21:03:21.340142  3817 solver.cpp:218] Iteration 37800 (12.54 iter/s, 7.97446s/100 iters), loss = 0.135997
I1006 21:03:21.340171  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.135997 (* 1 = 0.135997 loss)
I1006 21:03:21.340178  3817 sgd_solver.cpp:105] Iteration 37800, lr = 0.1
I1006 21:03:29.309991  3817 solver.cpp:218] Iteration 37900 (12.5474 iter/s, 7.96979s/100 iters), loss = 0.131635
I1006 21:03:29.310031  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.131636 (* 1 = 0.131636 loss)
I1006 21:03:29.310039  3817 sgd_solver.cpp:105] Iteration 37900, lr = 0.1
I1006 21:03:36.887848  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:03:37.207231  3817 solver.cpp:330] Iteration 38000, Testing net (#0)
I1006 21:03:39.082983  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:03:39.161057  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7837
I1006 21:03:39.161093  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.710497 (* 1 = 0.710497 loss)
I1006 21:03:39.240957  3817 solver.cpp:218] Iteration 38000 (10.0696 iter/s, 9.9309s/100 iters), loss = 0.11538
I1006 21:03:39.240986  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.11538 (* 1 = 0.11538 loss)
I1006 21:03:39.240993  3817 sgd_solver.cpp:105] Iteration 38000, lr = 0.1
I1006 21:03:47.206212  3817 solver.cpp:218] Iteration 38100 (12.5546 iter/s, 7.9652s/100 iters), loss = 0.269293
I1006 21:03:47.206240  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.269293 (* 1 = 0.269293 loss)
I1006 21:03:47.206246  3817 sgd_solver.cpp:105] Iteration 38100, lr = 0.1
I1006 21:03:55.166654  3817 solver.cpp:218] Iteration 38200 (12.5622 iter/s, 7.96039s/100 iters), loss = 0.224548
I1006 21:03:55.166683  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.224548 (* 1 = 0.224548 loss)
I1006 21:03:55.166689  3817 sgd_solver.cpp:105] Iteration 38200, lr = 0.1
I1006 21:04:03.126230  3817 solver.cpp:218] Iteration 38300 (12.5636 iter/s, 7.95952s/100 iters), loss = 0.154774
I1006 21:04:03.126269  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.154774 (* 1 = 0.154774 loss)
I1006 21:04:03.126276  3817 sgd_solver.cpp:105] Iteration 38300, lr = 0.1
I1006 21:04:11.092666  3817 solver.cpp:218] Iteration 38400 (12.5528 iter/s, 7.96637s/100 iters), loss = 0.189072
I1006 21:04:11.092825  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.189072 (* 1 = 0.189072 loss)
I1006 21:04:11.092844  3817 sgd_solver.cpp:105] Iteration 38400, lr = 0.1
I1006 21:04:18.663813  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:04:18.983196  3817 solver.cpp:330] Iteration 38500, Testing net (#0)
I1006 21:04:20.861657  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:04:20.940075  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6643
I1006 21:04:20.940110  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.09574 (* 1 = 1.09574 loss)
I1006 21:04:21.019996  3817 solver.cpp:218] Iteration 38500 (10.0734 iter/s, 9.92715s/100 iters), loss = 0.161272
I1006 21:04:21.020027  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.161272 (* 1 = 0.161272 loss)
I1006 21:04:21.020035  3817 sgd_solver.cpp:105] Iteration 38500, lr = 0.1
I1006 21:04:28.982760  3817 solver.cpp:218] Iteration 38600 (12.5585 iter/s, 7.96271s/100 iters), loss = 0.127251
I1006 21:04:28.982800  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.127251 (* 1 = 0.127251 loss)
I1006 21:04:28.982806  3817 sgd_solver.cpp:105] Iteration 38600, lr = 0.1
I1006 21:04:36.944819  3817 solver.cpp:218] Iteration 38700 (12.5597 iter/s, 7.962s/100 iters), loss = 0.247134
I1006 21:04:36.944849  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.247134 (* 1 = 0.247134 loss)
I1006 21:04:36.944854  3817 sgd_solver.cpp:105] Iteration 38700, lr = 0.1
I1006 21:04:44.903009  3817 solver.cpp:218] Iteration 38800 (12.5658 iter/s, 7.95814s/100 iters), loss = 0.179171
I1006 21:04:44.903141  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.179171 (* 1 = 0.179171 loss)
I1006 21:04:44.903148  3817 sgd_solver.cpp:105] Iteration 38800, lr = 0.1
I1006 21:04:52.862905  3817 solver.cpp:218] Iteration 38900 (12.5632 iter/s, 7.95974s/100 iters), loss = 0.153543
I1006 21:04:52.862933  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.153543 (* 1 = 0.153543 loss)
I1006 21:04:52.862939  3817 sgd_solver.cpp:105] Iteration 38900, lr = 0.1
I1006 21:05:00.428963  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:05:00.747237  3817 solver.cpp:330] Iteration 39000, Testing net (#0)
I1006 21:05:02.623706  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:05:02.701956  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7569
I1006 21:05:02.701990  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.846878 (* 1 = 0.846878 loss)
I1006 21:05:02.781318  3817 solver.cpp:218] Iteration 39000 (10.0823 iter/s, 9.91836s/100 iters), loss = 0.147753
I1006 21:05:02.781343  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.147754 (* 1 = 0.147754 loss)
I1006 21:05:02.781349  3817 sgd_solver.cpp:105] Iteration 39000, lr = 0.1
I1006 21:05:10.743839  3817 solver.cpp:218] Iteration 39100 (12.5589 iter/s, 7.96247s/100 iters), loss = 0.138363
I1006 21:05:10.743868  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.138363 (* 1 = 0.138363 loss)
I1006 21:05:10.743875  3817 sgd_solver.cpp:105] Iteration 39100, lr = 0.1
I1006 21:05:18.717692  3817 solver.cpp:218] Iteration 39200 (12.5411 iter/s, 7.9738s/100 iters), loss = 0.156189
I1006 21:05:18.717818  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.156189 (* 1 = 0.156189 loss)
I1006 21:05:18.717825  3817 sgd_solver.cpp:105] Iteration 39200, lr = 0.1
I1006 21:05:26.680759  3817 solver.cpp:218] Iteration 39300 (12.5582 iter/s, 7.96292s/100 iters), loss = 0.175264
I1006 21:05:26.680788  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.175264 (* 1 = 0.175264 loss)
I1006 21:05:26.680795  3817 sgd_solver.cpp:105] Iteration 39300, lr = 0.1
I1006 21:05:34.649124  3817 solver.cpp:218] Iteration 39400 (12.5497 iter/s, 7.96831s/100 iters), loss = 0.0970678
I1006 21:05:34.649154  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.097068 (* 1 = 0.097068 loss)
I1006 21:05:34.649160  3817 sgd_solver.cpp:105] Iteration 39400, lr = 0.1
I1006 21:05:42.213006  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:05:42.531347  3817 solver.cpp:330] Iteration 39500, Testing net (#0)
I1006 21:05:44.407752  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:05:44.486261  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.64
I1006 21:05:44.486296  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.3666 (* 1 = 1.3666 loss)
I1006 21:05:44.566177  3817 solver.cpp:218] Iteration 39500 (10.0837 iter/s, 9.917s/100 iters), loss = 0.17445
I1006 21:05:44.566203  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.174451 (* 1 = 0.174451 loss)
I1006 21:05:44.566210  3817 sgd_solver.cpp:105] Iteration 39500, lr = 0.1
I1006 21:05:52.532704  3817 solver.cpp:218] Iteration 39600 (12.5526 iter/s, 7.96648s/100 iters), loss = 0.232602
I1006 21:05:52.532814  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.232603 (* 1 = 0.232603 loss)
I1006 21:05:52.532824  3817 sgd_solver.cpp:105] Iteration 39600, lr = 0.1
I1006 21:06:00.502945  3817 solver.cpp:218] Iteration 39700 (12.5469 iter/s, 7.97012s/100 iters), loss = 0.200239
I1006 21:06:00.502986  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.20024 (* 1 = 0.20024 loss)
I1006 21:06:00.502992  3817 sgd_solver.cpp:105] Iteration 39700, lr = 0.1
I1006 21:06:08.471052  3817 solver.cpp:218] Iteration 39800 (12.5501 iter/s, 7.96804s/100 iters), loss = 0.149698
I1006 21:06:08.471081  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.149698 (* 1 = 0.149698 loss)
I1006 21:06:08.471087  3817 sgd_solver.cpp:105] Iteration 39800, lr = 0.1
I1006 21:06:16.434804  3817 solver.cpp:218] Iteration 39900 (12.557 iter/s, 7.9637s/100 iters), loss = 0.178358
I1006 21:06:16.434844  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.178358 (* 1 = 0.178358 loss)
I1006 21:06:16.434851  3817 sgd_solver.cpp:105] Iteration 39900, lr = 0.1
I1006 21:06:24.007201  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:06:24.326444  3817 solver.cpp:330] Iteration 40000, Testing net (#0)
I1006 21:06:26.202577  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:06:26.281059  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7949
I1006 21:06:26.281095  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.60105 (* 1 = 0.60105 loss)
I1006 21:06:26.360765  3817 solver.cpp:218] Iteration 40000 (10.0747 iter/s, 9.92589s/100 iters), loss = 0.116444
I1006 21:06:26.360791  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.116444 (* 1 = 0.116444 loss)
I1006 21:06:26.360797  3817 sgd_solver.cpp:46] MultiStep Status: Iteration 40000, step = 1
I1006 21:06:26.360800  3817 sgd_solver.cpp:105] Iteration 40000, lr = 0.01
I1006 21:06:34.331284  3817 solver.cpp:218] Iteration 40100 (12.5463 iter/s, 7.97047s/100 iters), loss = 0.182093
I1006 21:06:34.331324  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.182094 (* 1 = 0.182094 loss)
I1006 21:06:34.331331  3817 sgd_solver.cpp:105] Iteration 40100, lr = 0.01
I1006 21:06:42.304206  3817 solver.cpp:218] Iteration 40200 (12.5426 iter/s, 7.97286s/100 iters), loss = 0.120656
I1006 21:06:42.304247  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.120657 (* 1 = 0.120657 loss)
I1006 21:06:42.304253  3817 sgd_solver.cpp:105] Iteration 40200, lr = 0.01
I1006 21:06:50.272137  3817 solver.cpp:218] Iteration 40300 (12.5504 iter/s, 7.96787s/100 iters), loss = 0.128124
I1006 21:06:50.272177  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.128124 (* 1 = 0.128124 loss)
I1006 21:06:50.272184  3817 sgd_solver.cpp:105] Iteration 40300, lr = 0.01
I1006 21:06:58.246762  3817 solver.cpp:218] Iteration 40400 (12.5399 iter/s, 7.97455s/100 iters), loss = 0.0898618
I1006 21:06:58.246912  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.089862 (* 1 = 0.089862 loss)
I1006 21:06:58.246932  3817 sgd_solver.cpp:105] Iteration 40400, lr = 0.01
I1006 21:07:05.818373  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:07:06.137006  3817 solver.cpp:330] Iteration 40500, Testing net (#0)
I1006 21:07:08.015723  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:07:08.094044  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8983
I1006 21:07:08.094079  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.300282 (* 1 = 0.300282 loss)
I1006 21:07:08.174183  3817 solver.cpp:218] Iteration 40500 (10.0733 iter/s, 9.92726s/100 iters), loss = 0.0844218
I1006 21:07:08.174209  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.084422 (* 1 = 0.084422 loss)
I1006 21:07:08.174216  3817 sgd_solver.cpp:105] Iteration 40500, lr = 0.01
I1006 21:07:16.150377  3817 solver.cpp:218] Iteration 40600 (12.5374 iter/s, 7.97614s/100 iters), loss = 0.0958254
I1006 21:07:16.150418  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0958256 (* 1 = 0.0958256 loss)
I1006 21:07:16.150424  3817 sgd_solver.cpp:105] Iteration 40600, lr = 0.01
I1006 21:07:24.120708  3817 solver.cpp:218] Iteration 40700 (12.5466 iter/s, 7.97027s/100 iters), loss = 0.0732109
I1006 21:07:24.120748  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0732112 (* 1 = 0.0732112 loss)
I1006 21:07:24.120754  3817 sgd_solver.cpp:105] Iteration 40700, lr = 0.01
I1006 21:07:32.098871  3817 solver.cpp:218] Iteration 40800 (12.5343 iter/s, 7.9781s/100 iters), loss = 0.0992587
I1006 21:07:32.098970  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0992589 (* 1 = 0.0992589 loss)
I1006 21:07:32.098978  3817 sgd_solver.cpp:105] Iteration 40800, lr = 0.01
I1006 21:07:40.068945  3817 solver.cpp:218] Iteration 40900 (12.5471 iter/s, 7.96996s/100 iters), loss = 0.0577456
I1006 21:07:40.068985  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0577459 (* 1 = 0.0577459 loss)
I1006 21:07:40.068992  3817 sgd_solver.cpp:105] Iteration 40900, lr = 0.01
I1006 21:07:47.649396  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:07:47.968631  3817 solver.cpp:330] Iteration 41000, Testing net (#0)
I1006 21:07:49.841759  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:07:49.920172  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9106
I1006 21:07:49.920208  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.268593 (* 1 = 0.268593 loss)
I1006 21:07:50.000083  3817 solver.cpp:218] Iteration 41000 (10.0694 iter/s, 9.93107s/100 iters), loss = 0.0748527
I1006 21:07:50.000109  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.074853 (* 1 = 0.074853 loss)
I1006 21:07:50.000116  3817 sgd_solver.cpp:105] Iteration 41000, lr = 0.01
I1006 21:07:57.961334  3817 solver.cpp:218] Iteration 41100 (12.5609 iter/s, 7.9612s/100 iters), loss = 0.14806
I1006 21:07:57.961364  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.148061 (* 1 = 0.148061 loss)
I1006 21:07:57.961370  3817 sgd_solver.cpp:105] Iteration 41100, lr = 0.01
I1006 21:08:05.934607  3817 solver.cpp:218] Iteration 41200 (12.542 iter/s, 7.97322s/100 iters), loss = 0.158282
I1006 21:08:05.934679  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.158282 (* 1 = 0.158282 loss)
I1006 21:08:05.934685  3817 sgd_solver.cpp:105] Iteration 41200, lr = 0.01
I1006 21:08:13.906630  3817 solver.cpp:218] Iteration 41300 (12.544 iter/s, 7.97193s/100 iters), loss = 0.0794879
I1006 21:08:13.906672  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0794882 (* 1 = 0.0794882 loss)
I1006 21:08:13.906677  3817 sgd_solver.cpp:105] Iteration 41300, lr = 0.01
I1006 21:08:21.884186  3817 solver.cpp:218] Iteration 41400 (12.5353 iter/s, 7.97749s/100 iters), loss = 0.0564687
I1006 21:08:21.884225  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.056469 (* 1 = 0.056469 loss)
I1006 21:08:21.884232  3817 sgd_solver.cpp:105] Iteration 41400, lr = 0.01
I1006 21:08:29.457576  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:08:29.777379  3817 solver.cpp:330] Iteration 41500, Testing net (#0)
I1006 21:08:31.654932  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:08:31.733501  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9114
I1006 21:08:31.733536  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.264876 (* 1 = 0.264876 loss)
I1006 21:08:31.813822  3817 solver.cpp:218] Iteration 41500 (10.0709 iter/s, 9.92957s/100 iters), loss = 0.0357186
I1006 21:08:31.813854  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0357188 (* 1 = 0.0357188 loss)
I1006 21:08:31.813861  3817 sgd_solver.cpp:105] Iteration 41500, lr = 0.01
I1006 21:08:39.792934  3817 solver.cpp:218] Iteration 41600 (12.5328 iter/s, 7.97906s/100 iters), loss = 0.0996869
I1006 21:08:39.793061  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0996871 (* 1 = 0.0996871 loss)
I1006 21:08:39.793076  3817 sgd_solver.cpp:105] Iteration 41600, lr = 0.01
I1006 21:08:47.764468  3817 solver.cpp:218] Iteration 41700 (12.5449 iter/s, 7.9714s/100 iters), loss = 0.12107
I1006 21:08:47.764508  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.12107 (* 1 = 0.12107 loss)
I1006 21:08:47.764513  3817 sgd_solver.cpp:105] Iteration 41700, lr = 0.01
I1006 21:08:55.739773  3817 solver.cpp:218] Iteration 41800 (12.5388 iter/s, 7.97524s/100 iters), loss = 0.0597452
I1006 21:08:55.739804  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0597454 (* 1 = 0.0597454 loss)
I1006 21:08:55.739809  3817 sgd_solver.cpp:105] Iteration 41800, lr = 0.01
I1006 21:09:03.709044  3817 solver.cpp:218] Iteration 41900 (12.5483 iter/s, 7.96922s/100 iters), loss = 0.0557746
I1006 21:09:03.709084  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0557748 (* 1 = 0.0557748 loss)
I1006 21:09:03.709091  3817 sgd_solver.cpp:105] Iteration 41900, lr = 0.01
I1006 21:09:11.282544  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:09:11.602146  3817 solver.cpp:330] Iteration 42000, Testing net (#0)
I1006 21:09:13.479362  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:09:13.558288  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9141
I1006 21:09:13.558323  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.261346 (* 1 = 0.261346 loss)
I1006 21:09:13.638335  3817 solver.cpp:218] Iteration 42000 (10.0713 iter/s, 9.92922s/100 iters), loss = 0.0235227
I1006 21:09:13.638361  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.023523 (* 1 = 0.023523 loss)
I1006 21:09:13.638368  3817 sgd_solver.cpp:105] Iteration 42000, lr = 0.01
I1006 21:09:21.597080  3817 solver.cpp:218] Iteration 42100 (12.5649 iter/s, 7.9587s/100 iters), loss = 0.101815
I1006 21:09:21.597121  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.101816 (* 1 = 0.101816 loss)
I1006 21:09:21.597126  3817 sgd_solver.cpp:105] Iteration 42100, lr = 0.01
I1006 21:09:29.573784  3817 solver.cpp:218] Iteration 42200 (12.5366 iter/s, 7.97664s/100 iters), loss = 0.050713
I1006 21:09:29.573817  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0507132 (* 1 = 0.0507132 loss)
I1006 21:09:29.573823  3817 sgd_solver.cpp:105] Iteration 42200, lr = 0.01
I1006 21:09:37.538669  3817 solver.cpp:218] Iteration 42300 (12.5552 iter/s, 7.96483s/100 iters), loss = 0.0652403
I1006 21:09:37.538709  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0652405 (* 1 = 0.0652405 loss)
I1006 21:09:37.538715  3817 sgd_solver.cpp:105] Iteration 42300, lr = 0.01
I1006 21:09:45.501881  3817 solver.cpp:218] Iteration 42400 (12.5578 iter/s, 7.96315s/100 iters), loss = 0.0359276
I1006 21:09:45.502055  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0359278 (* 1 = 0.0359278 loss)
I1006 21:09:45.502064  3817 sgd_solver.cpp:105] Iteration 42400, lr = 0.01
I1006 21:09:53.072762  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:09:53.391161  3817 solver.cpp:330] Iteration 42500, Testing net (#0)
I1006 21:09:55.267601  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:09:55.346176  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.913
I1006 21:09:55.346211  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.269157 (* 1 = 0.269157 loss)
I1006 21:09:55.426084  3817 solver.cpp:218] Iteration 42500 (10.0766 iter/s, 9.92401s/100 iters), loss = 0.0655122
I1006 21:09:55.426110  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0655125 (* 1 = 0.0655125 loss)
I1006 21:09:55.426116  3817 sgd_solver.cpp:105] Iteration 42500, lr = 0.01
I1006 21:10:03.395797  3817 solver.cpp:218] Iteration 42600 (12.5476 iter/s, 7.96966s/100 iters), loss = 0.079062
I1006 21:10:03.395838  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0790622 (* 1 = 0.0790622 loss)
I1006 21:10:03.395844  3817 sgd_solver.cpp:105] Iteration 42600, lr = 0.01
I1006 21:10:11.357239  3817 solver.cpp:218] Iteration 42700 (12.5606 iter/s, 7.96138s/100 iters), loss = 0.0499463
I1006 21:10:11.357278  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0499465 (* 1 = 0.0499465 loss)
I1006 21:10:11.357285  3817 sgd_solver.cpp:105] Iteration 42700, lr = 0.01
I1006 21:10:19.379490  3817 solver.cpp:218] Iteration 42800 (12.4654 iter/s, 8.02219s/100 iters), loss = 0.0773922
I1006 21:10:19.379611  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0773924 (* 1 = 0.0773924 loss)
I1006 21:10:19.379633  3817 sgd_solver.cpp:105] Iteration 42800, lr = 0.01
I1006 21:10:27.350881  3817 solver.cpp:218] Iteration 42900 (12.5451 iter/s, 7.97126s/100 iters), loss = 0.0379815
I1006 21:10:27.350914  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0379817 (* 1 = 0.0379817 loss)
I1006 21:10:27.350931  3817 sgd_solver.cpp:105] Iteration 42900, lr = 0.01
I1006 21:10:34.924538  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:10:35.243976  3817 solver.cpp:330] Iteration 43000, Testing net (#0)
I1006 21:10:37.121520  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:10:37.200268  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9155
I1006 21:10:37.200304  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.260601 (* 1 = 0.260601 loss)
I1006 21:10:37.279774  3817 solver.cpp:218] Iteration 43000 (10.0717 iter/s, 9.92884s/100 iters), loss = 0.0492895
I1006 21:10:37.279805  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0492897 (* 1 = 0.0492897 loss)
I1006 21:10:37.279812  3817 sgd_solver.cpp:105] Iteration 43000, lr = 0.01
I1006 21:10:45.305515  3817 solver.cpp:218] Iteration 43100 (12.46 iter/s, 8.02569s/100 iters), loss = 0.0666081
I1006 21:10:45.305555  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0666083 (* 1 = 0.0666083 loss)
I1006 21:10:45.305562  3817 sgd_solver.cpp:105] Iteration 43100, lr = 0.01
I1006 21:10:53.280421  3817 solver.cpp:218] Iteration 43200 (12.5394 iter/s, 7.97484s/100 iters), loss = 0.0494519
I1006 21:10:53.280539  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0494521 (* 1 = 0.0494521 loss)
I1006 21:10:53.280556  3817 sgd_solver.cpp:105] Iteration 43200, lr = 0.01
I1006 21:11:01.249405  3817 solver.cpp:218] Iteration 43300 (12.5489 iter/s, 7.96885s/100 iters), loss = 0.044671
I1006 21:11:01.249446  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0446712 (* 1 = 0.0446712 loss)
I1006 21:11:01.249454  3817 sgd_solver.cpp:105] Iteration 43300, lr = 0.01
I1006 21:11:09.224462  3817 solver.cpp:218] Iteration 43400 (12.5392 iter/s, 7.97499s/100 iters), loss = 0.0258191
I1006 21:11:09.224493  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0258194 (* 1 = 0.0258194 loss)
I1006 21:11:09.224509  3817 sgd_solver.cpp:105] Iteration 43400, lr = 0.01
I1006 21:11:16.797300  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:11:17.118145  3817 solver.cpp:330] Iteration 43500, Testing net (#0)
I1006 21:11:18.994953  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:11:19.073482  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9107
I1006 21:11:19.073518  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.27819 (* 1 = 0.27819 loss)
I1006 21:11:19.152962  3817 solver.cpp:218] Iteration 43500 (10.0721 iter/s, 9.92844s/100 iters), loss = 0.0311503
I1006 21:11:19.152987  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0311505 (* 1 = 0.0311505 loss)
I1006 21:11:19.152993  3817 sgd_solver.cpp:105] Iteration 43500, lr = 0.01
I1006 21:11:27.127697  3817 solver.cpp:218] Iteration 43600 (12.5397 iter/s, 7.97469s/100 iters), loss = 0.0869728
I1006 21:11:27.127812  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.086973 (* 1 = 0.086973 loss)
I1006 21:11:27.127821  3817 sgd_solver.cpp:105] Iteration 43600, lr = 0.01
I1006 21:11:35.090255  3817 solver.cpp:218] Iteration 43700 (12.559 iter/s, 7.96243s/100 iters), loss = 0.0435829
I1006 21:11:35.090294  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0435832 (* 1 = 0.0435832 loss)
I1006 21:11:35.090301  3817 sgd_solver.cpp:105] Iteration 43700, lr = 0.01
I1006 21:11:43.059007  3817 solver.cpp:218] Iteration 43800 (12.5491 iter/s, 7.96869s/100 iters), loss = 0.0621688
I1006 21:11:43.059048  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0621691 (* 1 = 0.0621691 loss)
I1006 21:11:43.059054  3817 sgd_solver.cpp:105] Iteration 43800, lr = 0.01
I1006 21:11:51.024010  3817 solver.cpp:218] Iteration 43900 (12.555 iter/s, 7.96494s/100 iters), loss = 0.0396746
I1006 21:11:51.024050  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0396748 (* 1 = 0.0396748 loss)
I1006 21:11:51.024060  3817 sgd_solver.cpp:105] Iteration 43900, lr = 0.01
I1006 21:11:58.602650  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:11:58.921193  3817 solver.cpp:330] Iteration 44000, Testing net (#0)
I1006 21:12:00.798101  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:12:00.876534  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9173
I1006 21:12:00.876569  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.270311 (* 1 = 0.270311 loss)
I1006 21:12:00.956717  3817 solver.cpp:218] Iteration 44000 (10.0678 iter/s, 9.93264s/100 iters), loss = 0.0511321
I1006 21:12:00.956743  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0511323 (* 1 = 0.0511323 loss)
I1006 21:12:00.956749  3817 sgd_solver.cpp:105] Iteration 44000, lr = 0.01
I1006 21:12:08.926684  3817 solver.cpp:218] Iteration 44100 (12.5472 iter/s, 7.96991s/100 iters), loss = 0.0512143
I1006 21:12:08.926714  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0512145 (* 1 = 0.0512145 loss)
I1006 21:12:08.926720  3817 sgd_solver.cpp:105] Iteration 44100, lr = 0.01
I1006 21:12:16.900318  3817 solver.cpp:218] Iteration 44200 (12.5414 iter/s, 7.97358s/100 iters), loss = 0.0616701
I1006 21:12:16.900359  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0616702 (* 1 = 0.0616702 loss)
I1006 21:12:16.900365  3817 sgd_solver.cpp:105] Iteration 44200, lr = 0.01
I1006 21:12:24.867470  3817 solver.cpp:218] Iteration 44300 (12.5516 iter/s, 7.96709s/100 iters), loss = 0.0682398
I1006 21:12:24.867511  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.06824 (* 1 = 0.06824 loss)
I1006 21:12:24.867516  3817 sgd_solver.cpp:105] Iteration 44300, lr = 0.01
I1006 21:12:32.834022  3817 solver.cpp:218] Iteration 44400 (12.5526 iter/s, 7.96649s/100 iters), loss = 0.0207317
I1006 21:12:32.834137  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0207319 (* 1 = 0.0207319 loss)
I1006 21:12:32.834154  3817 sgd_solver.cpp:105] Iteration 44400, lr = 0.01
I1006 21:12:40.399551  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:12:40.718665  3817 solver.cpp:330] Iteration 44500, Testing net (#0)
I1006 21:12:42.596710  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:12:42.673916  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9116
I1006 21:12:42.673952  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.28393 (* 1 = 0.28393 loss)
I1006 21:12:42.753161  3817 solver.cpp:218] Iteration 44500 (10.0817 iter/s, 9.919s/100 iters), loss = 0.044183
I1006 21:12:42.753186  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0441832 (* 1 = 0.0441832 loss)
I1006 21:12:42.753192  3817 sgd_solver.cpp:105] Iteration 44500, lr = 0.01
I1006 21:12:50.721807  3817 solver.cpp:218] Iteration 44600 (12.5493 iter/s, 7.96859s/100 iters), loss = 0.0278032
I1006 21:12:50.721854  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0278034 (* 1 = 0.0278034 loss)
I1006 21:12:50.721861  3817 sgd_solver.cpp:105] Iteration 44600, lr = 0.01
I1006 21:12:58.685222  3817 solver.cpp:218] Iteration 44700 (12.5575 iter/s, 7.96334s/100 iters), loss = 0.0260848
I1006 21:12:58.685262  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.026085 (* 1 = 0.026085 loss)
I1006 21:12:58.685268  3817 sgd_solver.cpp:105] Iteration 44700, lr = 0.01
I1006 21:13:06.656574  3817 solver.cpp:218] Iteration 44800 (12.545 iter/s, 7.97129s/100 iters), loss = 0.0681012
I1006 21:13:06.656709  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0681014 (* 1 = 0.0681014 loss)
I1006 21:13:06.656718  3817 sgd_solver.cpp:105] Iteration 44800, lr = 0.01
I1006 21:13:14.622030  3817 solver.cpp:218] Iteration 44900 (12.5544 iter/s, 7.96531s/100 iters), loss = 0.0209087
I1006 21:13:14.622071  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.020909 (* 1 = 0.020909 loss)
I1006 21:13:14.622076  3817 sgd_solver.cpp:105] Iteration 44900, lr = 0.01
I1006 21:13:22.197691  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:13:22.517438  3817 solver.cpp:330] Iteration 45000, Testing net (#0)
I1006 21:13:24.392590  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:13:24.470958  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9107
I1006 21:13:24.470993  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.300749 (* 1 = 0.300749 loss)
I1006 21:13:24.550745  3817 solver.cpp:218] Iteration 45000 (10.0719 iter/s, 9.92865s/100 iters), loss = 0.0286822
I1006 21:13:24.550771  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0286824 (* 1 = 0.0286824 loss)
I1006 21:13:24.550778  3817 sgd_solver.cpp:105] Iteration 45000, lr = 0.01
I1006 21:13:32.506942  3817 solver.cpp:218] Iteration 45100 (12.5689 iter/s, 7.95615s/100 iters), loss = 0.0728333
I1006 21:13:32.506983  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0728336 (* 1 = 0.0728336 loss)
I1006 21:13:32.506989  3817 sgd_solver.cpp:105] Iteration 45100, lr = 0.01
I1006 21:13:40.477038  3817 solver.cpp:218] Iteration 45200 (12.547 iter/s, 7.97003s/100 iters), loss = 0.0291642
I1006 21:13:40.477159  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0291645 (* 1 = 0.0291645 loss)
I1006 21:13:40.477176  3817 sgd_solver.cpp:105] Iteration 45200, lr = 0.01
I1006 21:13:48.444177  3817 solver.cpp:218] Iteration 45300 (12.5518 iter/s, 7.967s/100 iters), loss = 0.0290622
I1006 21:13:48.444219  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0290624 (* 1 = 0.0290624 loss)
I1006 21:13:48.444226  3817 sgd_solver.cpp:105] Iteration 45300, lr = 0.01
I1006 21:13:56.411337  3817 solver.cpp:218] Iteration 45400 (12.5516 iter/s, 7.96709s/100 iters), loss = 0.0360976
I1006 21:13:56.411378  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0360978 (* 1 = 0.0360978 loss)
I1006 21:13:56.411384  3817 sgd_solver.cpp:105] Iteration 45400, lr = 0.01
I1006 21:14:03.981429  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:14:04.300550  3817 solver.cpp:330] Iteration 45500, Testing net (#0)
I1006 21:14:06.176930  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:14:06.255473  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9132
I1006 21:14:06.255509  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.287876 (* 1 = 0.287876 loss)
I1006 21:14:06.335520  3817 solver.cpp:218] Iteration 45500 (10.0765 iter/s, 9.92411s/100 iters), loss = 0.0230942
I1006 21:14:06.335544  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0230945 (* 1 = 0.0230945 loss)
I1006 21:14:06.335551  3817 sgd_solver.cpp:105] Iteration 45500, lr = 0.01
I1006 21:14:14.301262  3817 solver.cpp:218] Iteration 45600 (12.5538 iter/s, 7.96569s/100 iters), loss = 0.053668
I1006 21:14:14.301396  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0536683 (* 1 = 0.0536683 loss)
I1006 21:14:14.301403  3817 sgd_solver.cpp:105] Iteration 45600, lr = 0.01
I1006 21:14:22.270509  3817 solver.cpp:218] Iteration 45700 (12.5485 iter/s, 7.96909s/100 iters), loss = 0.031392
I1006 21:14:22.270550  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0313922 (* 1 = 0.0313922 loss)
I1006 21:14:22.270556  3817 sgd_solver.cpp:105] Iteration 45700, lr = 0.01
I1006 21:14:30.246645  3817 solver.cpp:218] Iteration 45800 (12.5375 iter/s, 7.97607s/100 iters), loss = 0.0556068
I1006 21:14:30.246675  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.055607 (* 1 = 0.055607 loss)
I1006 21:14:30.246680  3817 sgd_solver.cpp:105] Iteration 45800, lr = 0.01
I1006 21:14:38.220820  3817 solver.cpp:218] Iteration 45900 (12.5406 iter/s, 7.97412s/100 iters), loss = 0.0197366
I1006 21:14:38.220860  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0197368 (* 1 = 0.0197368 loss)
I1006 21:14:38.220866  3817 sgd_solver.cpp:105] Iteration 45900, lr = 0.01
I1006 21:14:45.789685  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:14:46.109632  3817 solver.cpp:330] Iteration 46000, Testing net (#0)
I1006 21:14:47.986932  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:14:48.065081  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9129
I1006 21:14:48.065106  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.299509 (* 1 = 0.299509 loss)
I1006 21:14:48.144436  3817 solver.cpp:218] Iteration 46000 (10.077 iter/s, 9.92355s/100 iters), loss = 0.0339042
I1006 21:14:48.144461  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0339044 (* 1 = 0.0339044 loss)
I1006 21:14:48.144469  3817 sgd_solver.cpp:105] Iteration 46000, lr = 0.01
I1006 21:14:56.105715  3817 solver.cpp:218] Iteration 46100 (12.5609 iter/s, 7.96123s/100 iters), loss = 0.0283123
I1006 21:14:56.105754  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0283125 (* 1 = 0.0283125 loss)
I1006 21:14:56.105760  3817 sgd_solver.cpp:105] Iteration 46100, lr = 0.01
I1006 21:15:04.073921  3817 solver.cpp:218] Iteration 46200 (12.55 iter/s, 7.96814s/100 iters), loss = 0.051827
I1006 21:15:04.073951  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0518273 (* 1 = 0.0518273 loss)
I1006 21:15:04.073958  3817 sgd_solver.cpp:105] Iteration 46200, lr = 0.01
I1006 21:15:12.039060  3817 solver.cpp:218] Iteration 46300 (12.5548 iter/s, 7.96508s/100 iters), loss = 0.0643491
I1006 21:15:12.039090  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0643493 (* 1 = 0.0643493 loss)
I1006 21:15:12.039096  3817 sgd_solver.cpp:105] Iteration 46300, lr = 0.01
I1006 21:15:20.003899  3817 solver.cpp:218] Iteration 46400 (12.5553 iter/s, 7.96479s/100 iters), loss = 0.0152126
I1006 21:15:20.004026  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0152128 (* 1 = 0.0152128 loss)
I1006 21:15:20.004045  3817 sgd_solver.cpp:105] Iteration 46400, lr = 0.01
I1006 21:15:27.572468  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:15:27.891223  3817 solver.cpp:330] Iteration 46500, Testing net (#0)
I1006 21:15:29.767663  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:15:29.846284  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9164
I1006 21:15:29.846318  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.29181 (* 1 = 0.29181 loss)
I1006 21:15:29.925881  3817 solver.cpp:218] Iteration 46500 (10.0788 iter/s, 9.92183s/100 iters), loss = 0.0202684
I1006 21:15:29.925909  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0202686 (* 1 = 0.0202686 loss)
I1006 21:15:29.925915  3817 sgd_solver.cpp:105] Iteration 46500, lr = 0.01
I1006 21:15:37.895051  3817 solver.cpp:218] Iteration 46600 (12.5484 iter/s, 7.96912s/100 iters), loss = 0.0230949
I1006 21:15:37.895081  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0230951 (* 1 = 0.0230951 loss)
I1006 21:15:37.895087  3817 sgd_solver.cpp:105] Iteration 46600, lr = 0.01
I1006 21:15:45.857848  3817 solver.cpp:218] Iteration 46700 (12.5585 iter/s, 7.96275s/100 iters), loss = 0.0304919
I1006 21:15:45.857888  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0304921 (* 1 = 0.0304921 loss)
I1006 21:15:45.857894  3817 sgd_solver.cpp:105] Iteration 46700, lr = 0.01
I1006 21:15:53.825371  3817 solver.cpp:218] Iteration 46800 (12.5511 iter/s, 7.96746s/100 iters), loss = 0.0127408
I1006 21:15:53.825510  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.012741 (* 1 = 0.012741 loss)
I1006 21:15:53.825517  3817 sgd_solver.cpp:105] Iteration 46800, lr = 0.01
I1006 21:16:01.788462  3817 solver.cpp:218] Iteration 46900 (12.5582 iter/s, 7.96293s/100 iters), loss = 0.0105418
I1006 21:16:01.788502  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.010542 (* 1 = 0.010542 loss)
I1006 21:16:01.788508  3817 sgd_solver.cpp:105] Iteration 46900, lr = 0.01
I1006 21:16:09.365087  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:16:09.683859  3817 solver.cpp:330] Iteration 47000, Testing net (#0)
I1006 21:16:11.560757  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:16:11.639412  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9158
I1006 21:16:11.639447  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.287007 (* 1 = 0.287007 loss)
I1006 21:16:11.718981  3817 solver.cpp:218] Iteration 47000 (10.07 iter/s, 9.93045s/100 iters), loss = 0.0192333
I1006 21:16:11.719008  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0192335 (* 1 = 0.0192335 loss)
I1006 21:16:11.719015  3817 sgd_solver.cpp:105] Iteration 47000, lr = 0.01
I1006 21:16:19.686693  3817 solver.cpp:218] Iteration 47100 (12.5507 iter/s, 7.96766s/100 iters), loss = 0.0703266
I1006 21:16:19.686733  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0703268 (* 1 = 0.0703268 loss)
I1006 21:16:19.686739  3817 sgd_solver.cpp:105] Iteration 47100, lr = 0.01
I1006 21:16:27.661496  3817 solver.cpp:218] Iteration 47200 (12.5396 iter/s, 7.97474s/100 iters), loss = 0.0102073
I1006 21:16:27.661579  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0102075 (* 1 = 0.0102075 loss)
I1006 21:16:27.661595  3817 sgd_solver.cpp:105] Iteration 47200, lr = 0.01
I1006 21:16:35.632529  3817 solver.cpp:218] Iteration 47300 (12.5456 iter/s, 7.97093s/100 iters), loss = 0.021102
I1006 21:16:35.632570  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0211022 (* 1 = 0.0211022 loss)
I1006 21:16:35.632575  3817 sgd_solver.cpp:105] Iteration 47300, lr = 0.01
I1006 21:16:43.636785  3817 solver.cpp:218] Iteration 47400 (12.4935 iter/s, 8.00419s/100 iters), loss = 0.00774277
I1006 21:16:43.636816  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00774296 (* 1 = 0.00774296 loss)
I1006 21:16:43.636823  3817 sgd_solver.cpp:105] Iteration 47400, lr = 0.01
I1006 21:16:51.267602  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:16:51.585963  3817 solver.cpp:330] Iteration 47500, Testing net (#0)
I1006 21:16:53.464264  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:16:53.542874  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9142
I1006 21:16:53.542909  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.300636 (* 1 = 0.300636 loss)
I1006 21:16:53.622758  3817 solver.cpp:218] Iteration 47500 (10.0141 iter/s, 9.98591s/100 iters), loss = 0.00465678
I1006 21:16:53.622783  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00465696 (* 1 = 0.00465696 loss)
I1006 21:16:53.622789  3817 sgd_solver.cpp:105] Iteration 47500, lr = 0.01
I1006 21:17:01.590034  3817 solver.cpp:218] Iteration 47600 (12.5514 iter/s, 7.96723s/100 iters), loss = 0.0244598
I1006 21:17:01.590169  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.02446 (* 1 = 0.02446 loss)
I1006 21:17:01.590188  3817 sgd_solver.cpp:105] Iteration 47600, lr = 0.01
I1006 21:17:09.552353  3817 solver.cpp:218] Iteration 47700 (12.5594 iter/s, 7.96216s/100 iters), loss = 0.0252347
I1006 21:17:09.552384  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0252348 (* 1 = 0.0252348 loss)
I1006 21:17:09.552392  3817 sgd_solver.cpp:105] Iteration 47700, lr = 0.01
I1006 21:17:17.516640  3817 solver.cpp:218] Iteration 47800 (12.5561 iter/s, 7.96423s/100 iters), loss = 0.0780714
I1006 21:17:17.516683  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0780716 (* 1 = 0.0780716 loss)
I1006 21:17:17.516690  3817 sgd_solver.cpp:105] Iteration 47800, lr = 0.01
I1006 21:17:25.479661  3817 solver.cpp:218] Iteration 47900 (12.5582 iter/s, 7.96296s/100 iters), loss = 0.0289308
I1006 21:17:25.479691  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.028931 (* 1 = 0.028931 loss)
I1006 21:17:25.479696  3817 sgd_solver.cpp:105] Iteration 47900, lr = 0.01
I1006 21:17:33.051555  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:17:33.370887  3817 solver.cpp:330] Iteration 48000, Testing net (#0)
I1006 21:17:35.247617  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:17:35.325798  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9153
I1006 21:17:35.325832  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.303532 (* 1 = 0.303532 loss)
I1006 21:17:35.405935  3817 solver.cpp:218] Iteration 48000 (10.0743 iter/s, 9.92621s/100 iters), loss = 0.00878398
I1006 21:17:35.405958  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00878417 (* 1 = 0.00878417 loss)
I1006 21:17:35.405966  3817 sgd_solver.cpp:105] Iteration 48000, lr = 0.01
I1006 21:17:43.364246  3817 solver.cpp:218] Iteration 48100 (12.5656 iter/s, 7.95826s/100 iters), loss = 0.00974302
I1006 21:17:43.364286  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0097432 (* 1 = 0.0097432 loss)
I1006 21:17:43.364292  3817 sgd_solver.cpp:105] Iteration 48100, lr = 0.01
I1006 21:17:51.331292  3817 solver.cpp:218] Iteration 48200 (12.5518 iter/s, 7.96698s/100 iters), loss = 0.0167725
I1006 21:17:51.331332  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0167727 (* 1 = 0.0167727 loss)
I1006 21:17:51.331338  3817 sgd_solver.cpp:105] Iteration 48200, lr = 0.01
I1006 21:17:59.292690  3817 solver.cpp:218] Iteration 48300 (12.5607 iter/s, 7.96134s/100 iters), loss = 0.0378417
I1006 21:17:59.292732  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0378419 (* 1 = 0.0378419 loss)
I1006 21:17:59.292737  3817 sgd_solver.cpp:105] Iteration 48300, lr = 0.01
I1006 21:18:07.258625  3817 solver.cpp:218] Iteration 48400 (12.5536 iter/s, 7.96587s/100 iters), loss = 0.0132739
I1006 21:18:07.258719  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0132741 (* 1 = 0.0132741 loss)
I1006 21:18:07.258738  3817 sgd_solver.cpp:105] Iteration 48400, lr = 0.01
I1006 21:18:14.827090  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:18:15.146639  3817 solver.cpp:330] Iteration 48500, Testing net (#0)
I1006 21:18:17.022904  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:18:17.101503  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9167
I1006 21:18:17.101527  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.291948 (* 1 = 0.291948 loss)
I1006 21:18:17.180804  3817 solver.cpp:218] Iteration 48500 (10.0786 iter/s, 9.92206s/100 iters), loss = 0.00493839
I1006 21:18:17.180830  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00493857 (* 1 = 0.00493857 loss)
I1006 21:18:17.180837  3817 sgd_solver.cpp:105] Iteration 48500, lr = 0.01
I1006 21:18:25.154579  3817 solver.cpp:218] Iteration 48600 (12.5412 iter/s, 7.97373s/100 iters), loss = 0.0131903
I1006 21:18:25.154620  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0131905 (* 1 = 0.0131905 loss)
I1006 21:18:25.154626  3817 sgd_solver.cpp:105] Iteration 48600, lr = 0.01
I1006 21:18:33.120602  3817 solver.cpp:218] Iteration 48700 (12.5534 iter/s, 7.96596s/100 iters), loss = 0.0316365
I1006 21:18:33.120631  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0316367 (* 1 = 0.0316367 loss)
I1006 21:18:33.120638  3817 sgd_solver.cpp:105] Iteration 48700, lr = 0.01
I1006 21:18:41.088996  3817 solver.cpp:218] Iteration 48800 (12.5497 iter/s, 7.96834s/100 iters), loss = 0.0229307
I1006 21:18:41.089097  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0229309 (* 1 = 0.0229309 loss)
I1006 21:18:41.089114  3817 sgd_solver.cpp:105] Iteration 48800, lr = 0.01
I1006 21:18:49.056284  3817 solver.cpp:218] Iteration 48900 (12.5515 iter/s, 7.96717s/100 iters), loss = 0.0257108
I1006 21:18:49.056313  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0257109 (* 1 = 0.0257109 loss)
I1006 21:18:49.056329  3817 sgd_solver.cpp:105] Iteration 48900, lr = 0.01
I1006 21:18:56.628263  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:18:56.947260  3817 solver.cpp:330] Iteration 49000, Testing net (#0)
I1006 21:18:58.824524  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:18:58.903167  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9157
I1006 21:18:58.903203  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.313863 (* 1 = 0.313863 loss)
I1006 21:18:58.982916  3817 solver.cpp:218] Iteration 49000 (10.074 iter/s, 9.92658s/100 iters), loss = 0.0171256
I1006 21:18:58.982941  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0171258 (* 1 = 0.0171258 loss)
I1006 21:18:58.982947  3817 sgd_solver.cpp:105] Iteration 49000, lr = 0.01
I1006 21:19:06.945822  3817 solver.cpp:218] Iteration 49100 (12.5583 iter/s, 7.96286s/100 iters), loss = 0.0290504
I1006 21:19:06.945863  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0290506 (* 1 = 0.0290506 loss)
I1006 21:19:06.945868  3817 sgd_solver.cpp:105] Iteration 49100, lr = 0.01
I1006 21:19:14.920338  3817 solver.cpp:218] Iteration 49200 (12.54 iter/s, 7.97445s/100 iters), loss = 0.0132629
I1006 21:19:14.920477  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0132631 (* 1 = 0.0132631 loss)
I1006 21:19:14.920485  3817 sgd_solver.cpp:105] Iteration 49200, lr = 0.01
I1006 21:19:22.890698  3817 solver.cpp:218] Iteration 49300 (12.5467 iter/s, 7.97021s/100 iters), loss = 0.0244197
I1006 21:19:22.890729  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0244199 (* 1 = 0.0244199 loss)
I1006 21:19:22.890735  3817 sgd_solver.cpp:105] Iteration 49300, lr = 0.01
I1006 21:19:30.861377  3817 solver.cpp:218] Iteration 49400 (12.5461 iter/s, 7.97063s/100 iters), loss = 0.00764343
I1006 21:19:30.861407  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00764359 (* 1 = 0.00764359 loss)
I1006 21:19:30.861413  3817 sgd_solver.cpp:105] Iteration 49400, lr = 0.01
I1006 21:19:38.433154  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:19:38.751551  3817 solver.cpp:330] Iteration 49500, Testing net (#0)
I1006 21:19:40.627666  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:19:40.706049  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9166
I1006 21:19:40.706075  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.313817 (* 1 = 0.313817 loss)
I1006 21:19:40.785472  3817 solver.cpp:218] Iteration 49500 (10.0765 iter/s, 9.92404s/100 iters), loss = 0.0232344
I1006 21:19:40.785501  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0232346 (* 1 = 0.0232346 loss)
I1006 21:19:40.785507  3817 sgd_solver.cpp:105] Iteration 49500, lr = 0.01
I1006 21:19:48.747323  3817 solver.cpp:218] Iteration 49600 (12.56 iter/s, 7.9618s/100 iters), loss = 0.0311089
I1006 21:19:48.747465  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0311091 (* 1 = 0.0311091 loss)
I1006 21:19:48.747485  3817 sgd_solver.cpp:105] Iteration 49600, lr = 0.01
I1006 21:19:56.697067  3817 solver.cpp:218] Iteration 49700 (12.5793 iter/s, 7.94958s/100 iters), loss = 0.0227724
I1006 21:19:56.697098  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0227726 (* 1 = 0.0227726 loss)
I1006 21:19:56.697113  3817 sgd_solver.cpp:105] Iteration 49700, lr = 0.01
I1006 21:20:04.655290  3817 solver.cpp:218] Iteration 49800 (12.5657 iter/s, 7.95817s/100 iters), loss = 0.00525116
I1006 21:20:04.655320  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00525133 (* 1 = 0.00525133 loss)
I1006 21:20:04.655336  3817 sgd_solver.cpp:105] Iteration 49800, lr = 0.01
I1006 21:20:12.610335  3817 solver.cpp:218] Iteration 49900 (12.5707 iter/s, 7.95499s/100 iters), loss = 0.0100281
I1006 21:20:12.610365  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0100283 (* 1 = 0.0100283 loss)
I1006 21:20:12.610381  3817 sgd_solver.cpp:105] Iteration 49900, lr = 0.01
I1006 21:20:20.184759  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:20:20.504170  3817 solver.cpp:330] Iteration 50000, Testing net (#0)
I1006 21:20:22.380699  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:20:22.459306  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9096
I1006 21:20:22.459342  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.329287 (* 1 = 0.329287 loss)
I1006 21:20:22.539379  3817 solver.cpp:218] Iteration 50000 (10.0715 iter/s, 9.92899s/100 iters), loss = 0.0102899
I1006 21:20:22.539405  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0102901 (* 1 = 0.0102901 loss)
I1006 21:20:22.539412  3817 sgd_solver.cpp:105] Iteration 50000, lr = 0.01
I1006 21:20:30.504781  3817 solver.cpp:218] Iteration 50100 (12.5544 iter/s, 7.96535s/100 iters), loss = 0.0121249
I1006 21:20:30.504822  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0121251 (* 1 = 0.0121251 loss)
I1006 21:20:30.504827  3817 sgd_solver.cpp:105] Iteration 50100, lr = 0.01
I1006 21:20:38.474684  3817 solver.cpp:218] Iteration 50200 (12.5473 iter/s, 7.96984s/100 iters), loss = 0.0284361
I1006 21:20:38.474725  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0284363 (* 1 = 0.0284363 loss)
I1006 21:20:38.474730  3817 sgd_solver.cpp:105] Iteration 50200, lr = 0.01
I1006 21:20:46.436939  3817 solver.cpp:218] Iteration 50300 (12.5594 iter/s, 7.96219s/100 iters), loss = 0.0226216
I1006 21:20:46.436977  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0226218 (* 1 = 0.0226218 loss)
I1006 21:20:46.436983  3817 sgd_solver.cpp:105] Iteration 50300, lr = 0.01
I1006 21:20:54.404727  3817 solver.cpp:218] Iteration 50400 (12.5506 iter/s, 7.96773s/100 iters), loss = 0.00676324
I1006 21:20:54.404829  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00676343 (* 1 = 0.00676343 loss)
I1006 21:20:54.404836  3817 sgd_solver.cpp:105] Iteration 50400, lr = 0.01
I1006 21:21:01.967500  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:21:02.286206  3817 solver.cpp:330] Iteration 50500, Testing net (#0)
I1006 21:21:04.162598  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:21:04.240952  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9103
I1006 21:21:04.240988  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.356538 (* 1 = 0.356538 loss)
I1006 21:21:04.320986  3817 solver.cpp:218] Iteration 50500 (10.0846 iter/s, 9.91614s/100 iters), loss = 0.00323655
I1006 21:21:04.321012  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00323674 (* 1 = 0.00323674 loss)
I1006 21:21:04.321017  3817 sgd_solver.cpp:105] Iteration 50500, lr = 0.01
I1006 21:21:12.288074  3817 solver.cpp:218] Iteration 50600 (12.5517 iter/s, 7.96704s/100 iters), loss = 0.00614316
I1006 21:21:12.288115  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00614335 (* 1 = 0.00614335 loss)
I1006 21:21:12.288120  3817 sgd_solver.cpp:105] Iteration 50600, lr = 0.01
I1006 21:21:20.246428  3817 solver.cpp:218] Iteration 50700 (12.5655 iter/s, 7.95829s/100 iters), loss = 0.00912363
I1006 21:21:20.246467  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00912382 (* 1 = 0.00912382 loss)
I1006 21:21:20.246474  3817 sgd_solver.cpp:105] Iteration 50700, lr = 0.01
I1006 21:21:28.208818  3817 solver.cpp:218] Iteration 50800 (12.5591 iter/s, 7.96233s/100 iters), loss = 0.010082
I1006 21:21:28.208932  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0100822 (* 1 = 0.0100822 loss)
I1006 21:21:28.208941  3817 sgd_solver.cpp:105] Iteration 50800, lr = 0.01
I1006 21:21:36.165755  3817 solver.cpp:218] Iteration 50900 (12.5678 iter/s, 7.95681s/100 iters), loss = 0.00252931
I1006 21:21:36.165784  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0025295 (* 1 = 0.0025295 loss)
I1006 21:21:36.165791  3817 sgd_solver.cpp:105] Iteration 50900, lr = 0.01
I1006 21:21:43.742100  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:21:44.068224  3817 solver.cpp:330] Iteration 51000, Testing net (#0)
I1006 21:21:46.039429  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:21:46.119005  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9138
I1006 21:21:46.119031  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.319884 (* 1 = 0.319884 loss)
I1006 21:21:46.200270  3817 solver.cpp:218] Iteration 51000 (9.96566 iter/s, 10.0345s/100 iters), loss = 0.0152568
I1006 21:21:46.200299  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.015257 (* 1 = 0.015257 loss)
I1006 21:21:46.200305  3817 sgd_solver.cpp:105] Iteration 51000, lr = 0.01
I1006 21:21:57.624835  3817 solver.cpp:218] Iteration 51100 (8.75311 iter/s, 11.4245s/100 iters), loss = 0.0408605
I1006 21:21:57.624868  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0408607 (* 1 = 0.0408607 loss)
I1006 21:21:57.624886  3817 sgd_solver.cpp:105] Iteration 51100, lr = 0.01
I1006 21:22:14.768921  3817 solver.cpp:218] Iteration 51200 (5.83345 iter/s, 17.1425s/100 iters), loss = 0.0390407
I1006 21:22:14.769049  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0390409 (* 1 = 0.0390409 loss)
I1006 21:22:14.769067  3817 sgd_solver.cpp:105] Iteration 51200, lr = 0.01
I1006 21:22:31.881898  3817 solver.cpp:218] Iteration 51300 (5.84427 iter/s, 17.1108s/100 iters), loss = 0.0134672
I1006 21:22:31.881940  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0134673 (* 1 = 0.0134673 loss)
I1006 21:22:31.881947  3817 sgd_solver.cpp:105] Iteration 51300, lr = 0.01
I1006 21:22:48.973150  3817 solver.cpp:218] Iteration 51400 (5.85172 iter/s, 17.089s/100 iters), loss = 0.00852303
I1006 21:22:48.973217  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00852322 (* 1 = 0.00852322 loss)
I1006 21:22:48.973235  3817 sgd_solver.cpp:105] Iteration 51400, lr = 0.01
I1006 21:23:05.229373  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:23:05.910068  3817 solver.cpp:330] Iteration 51500, Testing net (#0)
I1006 21:23:09.433157  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:23:09.588548  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.915
I1006 21:23:09.588577  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.31296 (* 1 = 0.31296 loss)
I1006 21:23:09.685642  3817 solver.cpp:218] Iteration 51500 (4.82852 iter/s, 20.7103s/100 iters), loss = 0.0253254
I1006 21:23:09.685679  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0253256 (* 1 = 0.0253256 loss)
I1006 21:23:09.685685  3817 sgd_solver.cpp:105] Iteration 51500, lr = 0.01
I1006 21:23:27.105906  3817 solver.cpp:218] Iteration 51600 (5.74048 iter/s, 17.4202s/100 iters), loss = 0.0186508
I1006 21:23:27.106034  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.018651 (* 1 = 0.018651 loss)
I1006 21:23:27.106053  3817 sgd_solver.cpp:105] Iteration 51600, lr = 0.01
I1006 21:23:44.161083  3817 solver.cpp:218] Iteration 51700 (5.86339 iter/s, 17.055s/100 iters), loss = 0.0150121
I1006 21:23:44.161115  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0150123 (* 1 = 0.0150123 loss)
I1006 21:23:44.161133  3817 sgd_solver.cpp:105] Iteration 51700, lr = 0.01
I1006 21:24:01.227953  3817 solver.cpp:218] Iteration 51800 (5.86008 iter/s, 17.0646s/100 iters), loss = 0.0142251
I1006 21:24:01.228070  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0142253 (* 1 = 0.0142253 loss)
I1006 21:24:01.228082  3817 sgd_solver.cpp:105] Iteration 51800, lr = 0.01
I1006 21:24:18.294404  3817 solver.cpp:218] Iteration 51900 (5.86021 iter/s, 17.0642s/100 iters), loss = 0.00680973
I1006 21:24:18.294450  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00680993 (* 1 = 0.00680993 loss)
I1006 21:24:18.294456  3817 sgd_solver.cpp:105] Iteration 51900, lr = 0.01
I1006 21:24:34.512255  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:24:35.194787  3817 solver.cpp:330] Iteration 52000, Testing net (#0)
I1006 21:24:38.722024  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:24:38.859736  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9153
I1006 21:24:38.859763  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.323015 (* 1 = 0.323015 loss)
I1006 21:24:38.972826  3817 solver.cpp:218] Iteration 52000 (4.83648 iter/s, 20.6762s/100 iters), loss = 0.00517102
I1006 21:24:38.972865  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00517121 (* 1 = 0.00517121 loss)
I1006 21:24:38.972872  3817 sgd_solver.cpp:105] Iteration 52000, lr = 0.01
I1006 21:24:56.446597  3817 solver.cpp:218] Iteration 52100 (5.7229 iter/s, 17.4737s/100 iters), loss = 0.00887986
I1006 21:24:56.446640  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00888003 (* 1 = 0.00888003 loss)
I1006 21:24:56.446645  3817 sgd_solver.cpp:105] Iteration 52100, lr = 0.01
I1006 21:25:13.546677  3817 solver.cpp:218] Iteration 52200 (5.84868 iter/s, 17.0979s/100 iters), loss = 0.0169847
I1006 21:25:13.546787  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0169848 (* 1 = 0.0169848 loss)
I1006 21:25:13.546805  3817 sgd_solver.cpp:105] Iteration 52200, lr = 0.01
I1006 21:25:30.620293  3817 solver.cpp:218] Iteration 52300 (5.85775 iter/s, 17.0714s/100 iters), loss = 0.03152
I1006 21:25:30.620326  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0315202 (* 1 = 0.0315202 loss)
I1006 21:25:30.620345  3817 sgd_solver.cpp:105] Iteration 52300, lr = 0.01
I1006 21:25:47.704473  3817 solver.cpp:218] Iteration 52400 (5.85413 iter/s, 17.082s/100 iters), loss = 0.00211065
I1006 21:25:47.704583  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0021108 (* 1 = 0.0021108 loss)
I1006 21:25:47.704591  3817 sgd_solver.cpp:105] Iteration 52400, lr = 0.01
I1006 21:26:03.929574  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:26:04.609805  3817 solver.cpp:330] Iteration 52500, Testing net (#0)
I1006 21:26:08.136515  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:26:08.274894  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9186
I1006 21:26:08.274931  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.303286 (* 1 = 0.303286 loss)
I1006 21:26:08.388520  3817 solver.cpp:218] Iteration 52500 (4.83499 iter/s, 20.6826s/100 iters), loss = 0.0516564
I1006 21:26:08.388559  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0516566 (* 1 = 0.0516566 loss)
I1006 21:26:08.388566  3817 sgd_solver.cpp:105] Iteration 52500, lr = 0.01
I1006 21:26:25.808750  3817 solver.cpp:218] Iteration 52600 (5.74049 iter/s, 17.4201s/100 iters), loss = 0.00962308
I1006 21:26:25.808867  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00962324 (* 1 = 0.00962324 loss)
I1006 21:26:25.808887  3817 sgd_solver.cpp:105] Iteration 52600, lr = 0.01
I1006 21:26:42.880370  3817 solver.cpp:218] Iteration 52700 (5.85825 iter/s, 17.0699s/100 iters), loss = 0.0311234
I1006 21:26:42.880412  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0311236 (* 1 = 0.0311236 loss)
I1006 21:26:42.880419  3817 sgd_solver.cpp:105] Iteration 52700, lr = 0.01
I1006 21:26:59.957746  3817 solver.cpp:218] Iteration 52800 (5.85632 iter/s, 17.0756s/100 iters), loss = 0.0127369
I1006 21:26:59.957835  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0127371 (* 1 = 0.0127371 loss)
I1006 21:26:59.957844  3817 sgd_solver.cpp:105] Iteration 52800, lr = 0.01
I1006 21:27:17.048049  3817 solver.cpp:218] Iteration 52900 (5.85204 iter/s, 17.088s/100 iters), loss = 0.0395293
I1006 21:27:17.048081  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0395294 (* 1 = 0.0395294 loss)
I1006 21:27:17.048089  3817 sgd_solver.cpp:105] Iteration 52900, lr = 0.01
I1006 21:27:33.286005  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:27:33.968410  3817 solver.cpp:330] Iteration 53000, Testing net (#0)
I1006 21:27:37.494818  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:27:37.643625  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.915
I1006 21:27:37.643661  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.324783 (* 1 = 0.324783 loss)
I1006 21:27:37.746234  3817 solver.cpp:218] Iteration 53000 (4.83186 iter/s, 20.696s/100 iters), loss = 0.0617684
I1006 21:27:37.746273  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0617686 (* 1 = 0.0617686 loss)
I1006 21:27:37.746279  3817 sgd_solver.cpp:105] Iteration 53000, lr = 0.01
I1006 21:27:55.165475  3817 solver.cpp:218] Iteration 53100 (5.74082 iter/s, 17.4191s/100 iters), loss = 0.0154694
I1006 21:27:55.165518  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0154696 (* 1 = 0.0154696 loss)
I1006 21:27:55.165524  3817 sgd_solver.cpp:105] Iteration 53100, lr = 0.01
I1006 21:28:12.250335  3817 solver.cpp:218] Iteration 53200 (5.85318 iter/s, 17.0847s/100 iters), loss = 0.00926381
I1006 21:28:12.250442  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00926398 (* 1 = 0.00926398 loss)
I1006 21:28:12.250450  3817 sgd_solver.cpp:105] Iteration 53200, lr = 0.01
I1006 21:28:29.328948  3817 solver.cpp:218] Iteration 53300 (5.85604 iter/s, 17.0764s/100 iters), loss = 0.00766153
I1006 21:28:29.328991  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00766169 (* 1 = 0.00766169 loss)
I1006 21:28:29.328999  3817 sgd_solver.cpp:105] Iteration 53300, lr = 0.01
I1006 21:28:46.404047  3817 solver.cpp:218] Iteration 53400 (5.85724 iter/s, 17.0729s/100 iters), loss = 0.008905
I1006 21:28:46.404106  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00890516 (* 1 = 0.00890516 loss)
I1006 21:28:46.404124  3817 sgd_solver.cpp:105] Iteration 53400, lr = 0.01
I1006 21:29:02.637472  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:29:03.321048  3817 solver.cpp:330] Iteration 53500, Testing net (#0)
I1006 21:29:06.849741  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:29:06.985900  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9172
I1006 21:29:06.985929  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.30688 (* 1 = 0.30688 loss)
I1006 21:29:07.101276  3817 solver.cpp:218] Iteration 53500 (4.83209 iter/s, 20.695s/100 iters), loss = 0.00255612
I1006 21:29:07.101308  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00255627 (* 1 = 0.00255627 loss)
I1006 21:29:07.101327  3817 sgd_solver.cpp:105] Iteration 53500, lr = 0.01
I1006 21:29:24.527986  3817 solver.cpp:218] Iteration 53600 (5.73836 iter/s, 17.4266s/100 iters), loss = 0.0163254
I1006 21:29:24.528157  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0163256 (* 1 = 0.0163256 loss)
I1006 21:29:24.528167  3817 sgd_solver.cpp:105] Iteration 53600, lr = 0.01
I1006 21:29:41.555268  3817 solver.cpp:218] Iteration 53700 (5.87301 iter/s, 17.027s/100 iters), loss = 0.0694518
I1006 21:29:41.555310  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0694519 (* 1 = 0.0694519 loss)
I1006 21:29:41.555317  3817 sgd_solver.cpp:105] Iteration 53700, lr = 0.01
I1006 21:29:58.632187  3817 solver.cpp:218] Iteration 53800 (5.85662 iter/s, 17.0747s/100 iters), loss = 0.0301442
I1006 21:29:58.638337  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0301443 (* 1 = 0.0301443 loss)
I1006 21:29:58.638357  3817 sgd_solver.cpp:105] Iteration 53800, lr = 0.01
I1006 21:30:15.695658  3817 solver.cpp:218] Iteration 53900 (5.86261 iter/s, 17.0573s/100 iters), loss = 0.0161443
I1006 21:30:15.695691  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0161444 (* 1 = 0.0161444 loss)
I1006 21:30:15.695698  3817 sgd_solver.cpp:105] Iteration 53900, lr = 0.01
I1006 21:30:31.950975  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:30:32.634348  3817 solver.cpp:330] Iteration 54000, Testing net (#0)
I1006 21:30:36.152382  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:30:36.263489  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9151
I1006 21:30:36.263515  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.33397 (* 1 = 0.33397 loss)
I1006 21:30:36.408586  3817 solver.cpp:218] Iteration 54000 (4.82842 iter/s, 20.7107s/100 iters), loss = 0.0155674
I1006 21:30:36.408627  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0155675 (* 1 = 0.0155675 loss)
I1006 21:30:36.408634  3817 sgd_solver.cpp:105] Iteration 54000, lr = 0.01
I1006 21:30:53.833257  3817 solver.cpp:218] Iteration 54100 (5.73903 iter/s, 17.4246s/100 iters), loss = 0.00488258
I1006 21:30:53.833287  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00488271 (* 1 = 0.00488271 loss)
I1006 21:30:53.833293  3817 sgd_solver.cpp:105] Iteration 54100, lr = 0.01
I1006 21:31:10.901417  3817 solver.cpp:218] Iteration 54200 (5.8589 iter/s, 17.0681s/100 iters), loss = 0.0428771
I1006 21:31:10.901506  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0428772 (* 1 = 0.0428772 loss)
I1006 21:31:10.901525  3817 sgd_solver.cpp:105] Iteration 54200, lr = 0.01
I1006 21:31:27.982090  3817 solver.cpp:218] Iteration 54300 (5.85533 iter/s, 17.0785s/100 iters), loss = 0.0212986
I1006 21:31:27.982132  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0212988 (* 1 = 0.0212988 loss)
I1006 21:31:27.982139  3817 sgd_solver.cpp:105] Iteration 54300, lr = 0.01
I1006 21:31:45.051949  3817 solver.cpp:218] Iteration 54400 (5.85858 iter/s, 17.069s/100 iters), loss = 0.0172449
I1006 21:31:45.052060  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0172451 (* 1 = 0.0172451 loss)
I1006 21:31:45.052079  3817 sgd_solver.cpp:105] Iteration 54400, lr = 0.01
I1006 21:32:01.278892  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:32:01.962373  3817 solver.cpp:330] Iteration 54500, Testing net (#0)
I1006 21:32:05.488284  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:32:05.613811  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9182
I1006 21:32:05.613848  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.318498 (* 1 = 0.318498 loss)
I1006 21:32:05.740267  3817 solver.cpp:218] Iteration 54500 (4.83391 iter/s, 20.6872s/100 iters), loss = 0.00403248
I1006 21:32:05.740305  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00403262 (* 1 = 0.00403262 loss)
I1006 21:32:05.740312  3817 sgd_solver.cpp:105] Iteration 54500, lr = 0.01
I1006 21:32:23.101363  3817 solver.cpp:218] Iteration 54600 (5.76004 iter/s, 17.361s/100 iters), loss = 0.00905236
I1006 21:32:23.101522  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00905251 (* 1 = 0.00905251 loss)
I1006 21:32:23.101536  3817 sgd_solver.cpp:105] Iteration 54600, lr = 0.01
I1006 21:32:40.226698  3817 solver.cpp:218] Iteration 54700 (5.83938 iter/s, 17.1251s/100 iters), loss = 0.0078409
I1006 21:32:40.226740  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00784105 (* 1 = 0.00784105 loss)
I1006 21:32:40.226747  3817 sgd_solver.cpp:105] Iteration 54700, lr = 0.01
I1006 21:32:57.291263  3817 solver.cpp:218] Iteration 54800 (5.86075 iter/s, 17.0627s/100 iters), loss = 0.0242562
I1006 21:32:57.291371  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0242564 (* 1 = 0.0242564 loss)
I1006 21:32:57.291379  3817 sgd_solver.cpp:105] Iteration 54800, lr = 0.01
I1006 21:33:14.346446  3817 solver.cpp:218] Iteration 54900 (5.86338 iter/s, 17.055s/100 iters), loss = 0.00385002
I1006 21:33:14.346487  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00385017 (* 1 = 0.00385017 loss)
I1006 21:33:14.346493  3817 sgd_solver.cpp:105] Iteration 54900, lr = 0.01
I1006 21:33:30.557399  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:33:31.236292  3817 solver.cpp:330] Iteration 55000, Testing net (#0)
I1006 21:33:34.760836  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:33:34.920063  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9164
I1006 21:33:34.920092  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.315116 (* 1 = 0.315116 loss)
I1006 21:33:35.011471  3817 solver.cpp:218] Iteration 55000 (4.83952 iter/s, 20.6632s/100 iters), loss = 0.00615549
I1006 21:33:35.011505  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00615564 (* 1 = 0.00615564 loss)
I1006 21:33:35.011524  3817 sgd_solver.cpp:105] Iteration 55000, lr = 0.01
I1006 21:33:52.344800  3817 solver.cpp:218] Iteration 55100 (5.76927 iter/s, 17.3332s/100 iters), loss = 0.0231521
I1006 21:33:52.344836  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0231522 (* 1 = 0.0231522 loss)
I1006 21:33:52.344846  3817 sgd_solver.cpp:105] Iteration 55100, lr = 0.01
I1006 21:34:09.480696  3817 solver.cpp:218] Iteration 55200 (5.83574 iter/s, 17.1358s/100 iters), loss = 0.0152143
I1006 21:34:09.480798  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0152145 (* 1 = 0.0152145 loss)
I1006 21:34:09.480806  3817 sgd_solver.cpp:105] Iteration 55200, lr = 0.01
I1006 21:34:26.557554  3817 solver.cpp:218] Iteration 55300 (5.85664 iter/s, 17.0746s/100 iters), loss = 0.00654402
I1006 21:34:26.557596  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00654418 (* 1 = 0.00654418 loss)
I1006 21:34:26.557603  3817 sgd_solver.cpp:105] Iteration 55300, lr = 0.01
I1006 21:34:43.651639  3817 solver.cpp:218] Iteration 55400 (5.85054 iter/s, 17.0924s/100 iters), loss = 0.00732432
I1006 21:34:43.651731  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00732448 (* 1 = 0.00732448 loss)
I1006 21:34:43.651751  3817 sgd_solver.cpp:105] Iteration 55400, lr = 0.01
I1006 21:34:59.903724  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:35:00.587083  3817 solver.cpp:330] Iteration 55500, Testing net (#0)
I1006 21:35:04.110827  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:35:04.246323  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9156
I1006 21:35:04.246351  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.333345 (* 1 = 0.333345 loss)
I1006 21:35:04.361639  3817 solver.cpp:218] Iteration 55500 (4.82914 iter/s, 20.7076s/100 iters), loss = 0.00334979
I1006 21:35:04.361677  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00334996 (* 1 = 0.00334996 loss)
I1006 21:35:04.361685  3817 sgd_solver.cpp:105] Iteration 55500, lr = 0.01
I1006 21:35:21.646214  3817 solver.cpp:218] Iteration 55600 (5.78554 iter/s, 17.2845s/100 iters), loss = 0.0110176
I1006 21:35:21.646319  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0110178 (* 1 = 0.0110178 loss)
I1006 21:35:21.646329  3817 sgd_solver.cpp:105] Iteration 55600, lr = 0.01
I1006 21:35:38.833528  3817 solver.cpp:218] Iteration 55700 (5.81861 iter/s, 17.1862s/100 iters), loss = 0.00266488
I1006 21:35:38.833569  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00266505 (* 1 = 0.00266505 loss)
I1006 21:35:38.833575  3817 sgd_solver.cpp:105] Iteration 55700, lr = 0.01
I1006 21:35:55.905704  3817 solver.cpp:218] Iteration 55800 (5.85824 iter/s, 17.07s/100 iters), loss = 0.00506457
I1006 21:35:55.905814  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00506474 (* 1 = 0.00506474 loss)
I1006 21:35:55.905823  3817 sgd_solver.cpp:105] Iteration 55800, lr = 0.01
I1006 21:36:12.987157  3817 solver.cpp:218] Iteration 55900 (5.85507 iter/s, 17.0792s/100 iters), loss = 0.00643888
I1006 21:36:12.987201  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00643905 (* 1 = 0.00643905 loss)
I1006 21:36:12.987208  3817 sgd_solver.cpp:105] Iteration 55900, lr = 0.01
I1006 21:36:29.212656  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:36:29.895184  3817 solver.cpp:330] Iteration 56000, Testing net (#0)
I1006 21:36:33.416805  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:36:33.571743  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9167
I1006 21:36:33.571779  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.333076 (* 1 = 0.333076 loss)
I1006 21:36:33.667829  3817 solver.cpp:218] Iteration 56000 (4.83595 iter/s, 20.6785s/100 iters), loss = 0.0191565
I1006 21:36:33.667868  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0191566 (* 1 = 0.0191566 loss)
I1006 21:36:33.667876  3817 sgd_solver.cpp:105] Iteration 56000, lr = 0.01
I1006 21:36:51.006397  3817 solver.cpp:218] Iteration 56100 (5.76753 iter/s, 17.3385s/100 iters), loss = 0.0130693
I1006 21:36:51.006431  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0130695 (* 1 = 0.0130695 loss)
I1006 21:36:51.006439  3817 sgd_solver.cpp:105] Iteration 56100, lr = 0.01
I1006 21:37:08.269856  3817 solver.cpp:218] Iteration 56200 (5.79333 iter/s, 17.2612s/100 iters), loss = 0.00430176
I1006 21:37:08.269963  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00430192 (* 1 = 0.00430192 loss)
I1006 21:37:08.269980  3817 sgd_solver.cpp:105] Iteration 56200, lr = 0.01
I1006 21:37:25.346601  3817 solver.cpp:218] Iteration 56300 (5.85651 iter/s, 17.075s/100 iters), loss = 0.00776819
I1006 21:37:25.346647  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00776835 (* 1 = 0.00776835 loss)
I1006 21:37:25.346653  3817 sgd_solver.cpp:105] Iteration 56300, lr = 0.01
I1006 21:37:42.427845  3817 solver.cpp:218] Iteration 56400 (5.85514 iter/s, 17.079s/100 iters), loss = 0.00678327
I1006 21:37:42.427942  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00678343 (* 1 = 0.00678343 loss)
I1006 21:37:42.427953  3817 sgd_solver.cpp:105] Iteration 56400, lr = 0.01
I1006 21:37:58.653043  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:37:59.335599  3817 solver.cpp:330] Iteration 56500, Testing net (#0)
I1006 21:38:02.865231  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:38:02.979809  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.914
I1006 21:38:02.979843  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.336221 (* 1 = 0.336221 loss)
I1006 21:38:03.117574  3817 solver.cpp:218] Iteration 56500 (4.83384 iter/s, 20.6875s/100 iters), loss = 0.00420916
I1006 21:38:03.117611  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00420932 (* 1 = 0.00420932 loss)
I1006 21:38:03.117617  3817 sgd_solver.cpp:105] Iteration 56500, lr = 0.01
I1006 21:38:20.388437  3817 solver.cpp:218] Iteration 56600 (5.79014 iter/s, 17.2707s/100 iters), loss = 0.0384433
I1006 21:38:20.388547  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0384435 (* 1 = 0.0384435 loss)
I1006 21:38:20.388556  3817 sgd_solver.cpp:105] Iteration 56600, lr = 0.01
I1006 21:38:37.606879  3817 solver.cpp:218] Iteration 56700 (5.80812 iter/s, 17.2173s/100 iters), loss = 0.00925165
I1006 21:38:37.606921  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00925181 (* 1 = 0.00925181 loss)
I1006 21:38:37.606928  3817 sgd_solver.cpp:105] Iteration 56700, lr = 0.01
I1006 21:38:54.673216  3817 solver.cpp:218] Iteration 56800 (5.85997 iter/s, 17.0649s/100 iters), loss = 0.00214439
I1006 21:38:54.673300  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00214455 (* 1 = 0.00214455 loss)
I1006 21:38:54.673318  3817 sgd_solver.cpp:105] Iteration 56800, lr = 0.01
I1006 21:39:11.766218  3817 solver.cpp:218] Iteration 56900 (5.85111 iter/s, 17.0908s/100 iters), loss = 0.00942472
I1006 21:39:11.766260  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00942488 (* 1 = 0.00942488 loss)
I1006 21:39:11.766268  3817 sgd_solver.cpp:105] Iteration 56900, lr = 0.01
I1006 21:39:28.000082  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:39:28.684116  3817 solver.cpp:330] Iteration 57000, Testing net (#0)
I1006 21:39:32.211213  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:39:32.348284  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9182
I1006 21:39:32.348312  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.325637 (* 1 = 0.325637 loss)
I1006 21:39:32.463726  3817 solver.cpp:218] Iteration 57000 (4.83191 iter/s, 20.6957s/100 iters), loss = 0.00176673
I1006 21:39:32.463764  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00176689 (* 1 = 0.00176689 loss)
I1006 21:39:32.463771  3817 sgd_solver.cpp:105] Iteration 57000, lr = 0.01
I1006 21:39:49.679947  3817 solver.cpp:218] Iteration 57100 (5.80852 iter/s, 17.2161s/100 iters), loss = 0.00749894
I1006 21:39:49.679980  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0074991 (* 1 = 0.0074991 loss)
I1006 21:39:49.679998  3817 sgd_solver.cpp:105] Iteration 57100, lr = 0.01
I1006 21:40:06.966457  3817 solver.cpp:218] Iteration 57200 (5.78489 iter/s, 17.2864s/100 iters), loss = 0.00798061
I1006 21:40:06.966550  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00798077 (* 1 = 0.00798077 loss)
I1006 21:40:06.966567  3817 sgd_solver.cpp:105] Iteration 57200, lr = 0.01
I1006 21:40:24.051131  3817 solver.cpp:218] Iteration 57300 (5.8538 iter/s, 17.0829s/100 iters), loss = 0.00281666
I1006 21:40:24.051165  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00281683 (* 1 = 0.00281683 loss)
I1006 21:40:24.051172  3817 sgd_solver.cpp:105] Iteration 57300, lr = 0.01
I1006 21:40:41.139178  3817 solver.cpp:218] Iteration 57400 (5.8528 iter/s, 17.0858s/100 iters), loss = 0.00257393
I1006 21:40:41.139333  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00257409 (* 1 = 0.00257409 loss)
I1006 21:40:41.139343  3817 sgd_solver.cpp:105] Iteration 57400, lr = 0.01
I1006 21:40:57.366832  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:40:58.046483  3817 solver.cpp:330] Iteration 57500, Testing net (#0)
I1006 21:41:01.579319  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:41:01.693877  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9157
I1006 21:41:01.693913  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.339699 (* 1 = 0.339699 loss)
I1006 21:41:01.831244  3817 solver.cpp:218] Iteration 57500 (4.83324 iter/s, 20.69s/100 iters), loss = 0.00752183
I1006 21:41:01.831282  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.007522 (* 1 = 0.007522 loss)
I1006 21:41:01.831288  3817 sgd_solver.cpp:105] Iteration 57500, lr = 0.01
I1006 21:41:19.008951  3817 solver.cpp:218] Iteration 57600 (5.82154 iter/s, 17.1776s/100 iters), loss = 0.00831106
I1006 21:41:19.009083  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00831123 (* 1 = 0.00831123 loss)
I1006 21:41:19.009102  3817 sgd_solver.cpp:105] Iteration 57600, lr = 0.01
I1006 21:41:36.338987  3817 solver.cpp:218] Iteration 57700 (5.7704 iter/s, 17.3298s/100 iters), loss = 0.00893394
I1006 21:41:36.339030  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00893411 (* 1 = 0.00893411 loss)
I1006 21:41:36.339036  3817 sgd_solver.cpp:105] Iteration 57700, lr = 0.01
I1006 21:41:53.423692  3817 solver.cpp:218] Iteration 57800 (5.85364 iter/s, 17.0834s/100 iters), loss = 0.00612582
I1006 21:41:53.423787  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00612599 (* 1 = 0.00612599 loss)
I1006 21:41:53.423807  3817 sgd_solver.cpp:105] Iteration 57800, lr = 0.01
I1006 21:42:10.520138  3817 solver.cpp:218] Iteration 57900 (5.84994 iter/s, 17.0942s/100 iters), loss = 0.00662646
I1006 21:42:10.520185  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00662663 (* 1 = 0.00662663 loss)
I1006 21:42:10.520192  3817 sgd_solver.cpp:105] Iteration 57900, lr = 0.01
I1006 21:42:26.752387  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:42:27.433619  3817 solver.cpp:330] Iteration 58000, Testing net (#0)
I1006 21:42:30.963110  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:42:31.130249  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9149
I1006 21:42:31.130285  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.349202 (* 1 = 0.349202 loss)
I1006 21:42:31.223063  3817 solver.cpp:218] Iteration 58000 (4.83065 iter/s, 20.7011s/100 iters), loss = 0.0053355
I1006 21:42:31.223098  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00533565 (* 1 = 0.00533565 loss)
I1006 21:42:31.223105  3817 sgd_solver.cpp:105] Iteration 58000, lr = 0.01
I1006 21:42:48.337790  3817 solver.cpp:218] Iteration 58100 (5.84367 iter/s, 17.1125s/100 iters), loss = 0.00675933
I1006 21:42:48.337822  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00675948 (* 1 = 0.00675948 loss)
I1006 21:42:48.337841  3817 sgd_solver.cpp:105] Iteration 58100, lr = 0.01
I1006 21:43:05.715631  3817 solver.cpp:218] Iteration 58200 (5.75449 iter/s, 17.3777s/100 iters), loss = 0.0128833
I1006 21:43:05.715741  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0128835 (* 1 = 0.0128835 loss)
I1006 21:43:05.715749  3817 sgd_solver.cpp:105] Iteration 58200, lr = 0.01
I1006 21:43:22.799187  3817 solver.cpp:218] Iteration 58300 (5.85419 iter/s, 17.0818s/100 iters), loss = 0.013263
I1006 21:43:22.799232  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0132631 (* 1 = 0.0132631 loss)
I1006 21:43:22.799239  3817 sgd_solver.cpp:105] Iteration 58300, lr = 0.01
I1006 21:43:39.893956  3817 solver.cpp:218] Iteration 58400 (5.85051 iter/s, 17.0925s/100 iters), loss = 0.00568545
I1006 21:43:39.894057  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00568559 (* 1 = 0.00568559 loss)
I1006 21:43:39.894067  3817 sgd_solver.cpp:105] Iteration 58400, lr = 0.01
I1006 21:43:56.139130  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:43:56.820771  3817 solver.cpp:330] Iteration 58500, Testing net (#0)
I1006 21:44:00.350950  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:44:00.488967  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9056
I1006 21:44:00.489004  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.398833 (* 1 = 0.398833 loss)
I1006 21:44:00.601922  3817 solver.cpp:218] Iteration 58500 (4.82958 iter/s, 20.7057s/100 iters), loss = 0.00987287
I1006 21:44:00.601960  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.009873 (* 1 = 0.009873 loss)
I1006 21:44:00.601968  3817 sgd_solver.cpp:105] Iteration 58500, lr = 0.01
I1006 21:44:17.698092  3817 solver.cpp:218] Iteration 58600 (5.8493 iter/s, 17.0961s/100 iters), loss = 0.0165604
I1006 21:44:17.698186  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0165605 (* 1 = 0.0165605 loss)
I1006 21:44:17.698199  3817 sgd_solver.cpp:105] Iteration 58600, lr = 0.01
I1006 21:44:35.080056  3817 solver.cpp:218] Iteration 58700 (5.75346 iter/s, 17.3808s/100 iters), loss = 0.00371411
I1006 21:44:35.080101  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00371426 (* 1 = 0.00371426 loss)
I1006 21:44:35.080107  3817 sgd_solver.cpp:105] Iteration 58700, lr = 0.01
I1006 21:44:52.151759  3817 solver.cpp:218] Iteration 58800 (5.85842 iter/s, 17.0695s/100 iters), loss = 0.00598825
I1006 21:44:52.151892  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0059884 (* 1 = 0.0059884 loss)
I1006 21:44:52.151901  3817 sgd_solver.cpp:105] Iteration 58800, lr = 0.01
I1006 21:45:09.235756  3817 solver.cpp:218] Iteration 58900 (5.8542 iter/s, 17.0818s/100 iters), loss = 0.016115
I1006 21:45:09.235800  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0161151 (* 1 = 0.0161151 loss)
I1006 21:45:09.235807  3817 sgd_solver.cpp:105] Iteration 58900, lr = 0.01
I1006 21:45:25.458194  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:45:26.139333  3817 solver.cpp:330] Iteration 59000, Testing net (#0)
I1006 21:45:29.668170  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:45:29.775571  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9191
I1006 21:45:29.775606  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.321869 (* 1 = 0.321869 loss)
I1006 21:45:29.919790  3817 solver.cpp:218] Iteration 59000 (4.83517 iter/s, 20.6818s/100 iters), loss = 0.00164366
I1006 21:45:29.919828  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00164381 (* 1 = 0.00164381 loss)
I1006 21:45:29.919834  3817 sgd_solver.cpp:105] Iteration 59000, lr = 0.01
I1006 21:45:46.996975  3817 solver.cpp:218] Iteration 59100 (5.85581 iter/s, 17.0771s/100 iters), loss = 0.0159779
I1006 21:45:46.997020  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0159781 (* 1 = 0.0159781 loss)
I1006 21:45:46.997027  3817 sgd_solver.cpp:105] Iteration 59100, lr = 0.01
I1006 21:46:04.511806  3817 solver.cpp:218] Iteration 59200 (5.70949 iter/s, 17.5147s/100 iters), loss = 0.0105492
I1006 21:46:04.511883  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0105494 (* 1 = 0.0105494 loss)
I1006 21:46:04.511893  3817 sgd_solver.cpp:105] Iteration 59200, lr = 0.01
I1006 21:46:21.596087  3817 solver.cpp:218] Iteration 59300 (5.85409 iter/s, 17.0821s/100 iters), loss = 0.00396841
I1006 21:46:21.596120  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00396858 (* 1 = 0.00396858 loss)
I1006 21:46:21.596127  3817 sgd_solver.cpp:105] Iteration 59300, lr = 0.01
I1006 21:46:38.676611  3817 solver.cpp:218] Iteration 59400 (5.8553 iter/s, 17.0785s/100 iters), loss = 0.00407821
I1006 21:46:38.676712  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00407837 (* 1 = 0.00407837 loss)
I1006 21:46:38.676730  3817 sgd_solver.cpp:105] Iteration 59400, lr = 0.01
I1006 21:46:54.927119  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:46:55.612242  3817 solver.cpp:330] Iteration 59500, Testing net (#0)
I1006 21:46:59.125264  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:46:59.240407  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9156
I1006 21:46:59.240442  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.333074 (* 1 = 0.333074 loss)
I1006 21:46:59.389400  3817 solver.cpp:218] Iteration 59500 (4.82851 iter/s, 20.7103s/100 iters), loss = 0.0152461
I1006 21:46:59.389430  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0152463 (* 1 = 0.0152463 loss)
I1006 21:46:59.389438  3817 sgd_solver.cpp:105] Iteration 59500, lr = 0.01
I1006 21:47:16.417598  3817 solver.cpp:218] Iteration 59600 (5.87265 iter/s, 17.0281s/100 iters), loss = 0.00610074
I1006 21:47:16.417726  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00610089 (* 1 = 0.00610089 loss)
I1006 21:47:16.417745  3817 sgd_solver.cpp:105] Iteration 59600, lr = 0.01
I1006 21:47:33.890250  3817 solver.cpp:218] Iteration 59700 (5.72329 iter/s, 17.4725s/100 iters), loss = 0.0123681
I1006 21:47:33.890285  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0123682 (* 1 = 0.0123682 loss)
I1006 21:47:33.890292  3817 sgd_solver.cpp:105] Iteration 59700, lr = 0.01
I1006 21:47:50.972354  3817 solver.cpp:218] Iteration 59800 (5.85476 iter/s, 17.0801s/100 iters), loss = 0.0206906
I1006 21:47:50.972460  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0206907 (* 1 = 0.0206907 loss)
I1006 21:47:50.972467  3817 sgd_solver.cpp:105] Iteration 59800, lr = 0.01
I1006 21:48:08.029142  3817 solver.cpp:218] Iteration 59900 (5.86343 iter/s, 17.0549s/100 iters), loss = 0.00297121
I1006 21:48:08.029176  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00297136 (* 1 = 0.00297136 loss)
I1006 21:48:08.029184  3817 sgd_solver.cpp:105] Iteration 59900, lr = 0.01
I1006 21:48:24.303601  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:48:24.986887  3817 solver.cpp:330] Iteration 60000, Testing net (#0)
I1006 21:48:28.516628  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:48:28.653962  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9188
I1006 21:48:28.653998  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.327865 (* 1 = 0.327865 loss)
I1006 21:48:28.769548  3817 solver.cpp:218] Iteration 60000 (4.82202 iter/s, 20.7382s/100 iters), loss = 0.00384426
I1006 21:48:28.769587  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00384441 (* 1 = 0.00384441 loss)
I1006 21:48:28.769593  3817 sgd_solver.cpp:105] Iteration 60000, lr = 0.01
I1006 21:48:45.853173  3817 solver.cpp:218] Iteration 60100 (5.8536 iter/s, 17.0835s/100 iters), loss = 0.00318041
I1006 21:48:45.853215  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00318055 (* 1 = 0.00318055 loss)
I1006 21:48:45.853222  3817 sgd_solver.cpp:105] Iteration 60100, lr = 0.01
I1006 21:49:03.276661  3817 solver.cpp:218] Iteration 60200 (5.73942 iter/s, 17.4234s/100 iters), loss = 0.0223531
I1006 21:49:03.276787  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0223533 (* 1 = 0.0223533 loss)
I1006 21:49:03.276805  3817 sgd_solver.cpp:105] Iteration 60200, lr = 0.01
I1006 21:49:20.363176  3817 solver.cpp:218] Iteration 60300 (5.85332 iter/s, 17.0843s/100 iters), loss = 0.022299
I1006 21:49:20.363221  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0222992 (* 1 = 0.0222992 loss)
I1006 21:49:20.363229  3817 sgd_solver.cpp:105] Iteration 60300, lr = 0.01
I1006 21:49:37.435005  3817 solver.cpp:218] Iteration 60400 (5.85829 iter/s, 17.0698s/100 iters), loss = 0.0165693
I1006 21:49:37.435073  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0165695 (* 1 = 0.0165695 loss)
I1006 21:49:37.435081  3817 sgd_solver.cpp:105] Iteration 60400, lr = 0.01
I1006 21:49:53.664454  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:49:54.346578  3817 solver.cpp:330] Iteration 60500, Testing net (#0)
I1006 21:49:57.876750  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:49:57.997555  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9193
I1006 21:49:57.997591  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.322154 (* 1 = 0.322154 loss)
I1006 21:49:58.128006  3817 solver.cpp:218] Iteration 60500 (4.83258 iter/s, 20.6929s/100 iters), loss = 0.00385619
I1006 21:49:58.128046  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00385635 (* 1 = 0.00385635 loss)
I1006 21:49:58.128052  3817 sgd_solver.cpp:105] Iteration 60500, lr = 0.01
I1006 21:50:15.203457  3817 solver.cpp:218] Iteration 60600 (5.8564 iter/s, 17.0753s/100 iters), loss = 0.0166362
I1006 21:50:15.203608  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0166363 (* 1 = 0.0166363 loss)
I1006 21:50:15.203618  3817 sgd_solver.cpp:105] Iteration 60600, lr = 0.01
I1006 21:50:32.722692  3817 solver.cpp:218] Iteration 60700 (5.70873 iter/s, 17.517s/100 iters), loss = 0.00265581
I1006 21:50:32.722733  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00265596 (* 1 = 0.00265596 loss)
I1006 21:50:32.722739  3817 sgd_solver.cpp:105] Iteration 60700, lr = 0.01
I1006 21:50:49.777758  3817 solver.cpp:218] Iteration 60800 (5.86412 iter/s, 17.0528s/100 iters), loss = 0.0134547
I1006 21:50:49.777894  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0134549 (* 1 = 0.0134549 loss)
I1006 21:50:49.777901  3817 sgd_solver.cpp:105] Iteration 60800, lr = 0.01
I1006 21:51:06.866572  3817 solver.cpp:218] Iteration 60900 (5.85254 iter/s, 17.0866s/100 iters), loss = 0.0177789
I1006 21:51:06.866613  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0177791 (* 1 = 0.0177791 loss)
I1006 21:51:06.866619  3817 sgd_solver.cpp:105] Iteration 60900, lr = 0.01
I1006 21:51:23.129693  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:51:23.814468  3817 solver.cpp:330] Iteration 61000, Testing net (#0)
I1006 21:51:27.340936  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:51:27.477032  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9137
I1006 21:51:27.477059  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.347092 (* 1 = 0.347092 loss)
I1006 21:51:27.592108  3817 solver.cpp:218] Iteration 61000 (4.82548 iter/s, 20.7233s/100 iters), loss = 0.00242304
I1006 21:51:27.592149  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00242319 (* 1 = 0.00242319 loss)
I1006 21:51:27.592154  3817 sgd_solver.cpp:105] Iteration 61000, lr = 0.01
I1006 21:51:44.667780  3817 solver.cpp:218] Iteration 61100 (5.85632 iter/s, 17.0756s/100 iters), loss = 0.00267307
I1006 21:51:44.667824  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00267321 (* 1 = 0.00267321 loss)
I1006 21:51:44.667830  3817 sgd_solver.cpp:105] Iteration 61100, lr = 0.01
I1006 21:52:02.089388  3817 solver.cpp:218] Iteration 61200 (5.74062 iter/s, 17.4197s/100 iters), loss = 0.0121298
I1006 21:52:02.089468  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0121299 (* 1 = 0.0121299 loss)
I1006 21:52:02.089475  3817 sgd_solver.cpp:105] Iteration 61200, lr = 0.01
I1006 21:52:19.173599  3817 solver.cpp:218] Iteration 61300 (5.85413 iter/s, 17.082s/100 iters), loss = 0.00394893
I1006 21:52:19.173640  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00394908 (* 1 = 0.00394908 loss)
I1006 21:52:19.173645  3817 sgd_solver.cpp:105] Iteration 61300, lr = 0.01
I1006 21:52:36.268553  3817 solver.cpp:218] Iteration 61400 (5.85045 iter/s, 17.0927s/100 iters), loss = 0.0112371
I1006 21:52:36.268662  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0112373 (* 1 = 0.0112373 loss)
I1006 21:52:36.268671  3817 sgd_solver.cpp:105] Iteration 61400, lr = 0.01
I1006 21:52:52.519587  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:52:53.202232  3817 solver.cpp:330] Iteration 61500, Testing net (#0)
I1006 21:52:56.731904  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:52:56.899534  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9178
I1006 21:52:56.899570  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.329995 (* 1 = 0.329995 loss)
I1006 21:52:56.992429  3817 solver.cpp:218] Iteration 61500 (4.82587 iter/s, 20.7217s/100 iters), loss = 0.00666461
I1006 21:52:56.992473  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00666476 (* 1 = 0.00666476 loss)
I1006 21:52:56.992480  3817 sgd_solver.cpp:105] Iteration 61500, lr = 0.01
I1006 21:53:14.045469  3817 solver.cpp:218] Iteration 61600 (5.86481 iter/s, 17.0508s/100 iters), loss = 0.0195358
I1006 21:53:14.045609  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.019536 (* 1 = 0.019536 loss)
I1006 21:53:14.045627  3817 sgd_solver.cpp:105] Iteration 61600, lr = 0.01
I1006 21:53:31.485646  3817 solver.cpp:218] Iteration 61700 (5.73462 iter/s, 17.4379s/100 iters), loss = 0.00780276
I1006 21:53:31.485689  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0078029 (* 1 = 0.0078029 loss)
I1006 21:53:31.485697  3817 sgd_solver.cpp:105] Iteration 61700, lr = 0.01
I1006 21:53:48.561435  3817 solver.cpp:218] Iteration 61800 (5.85684 iter/s, 17.074s/100 iters), loss = 0.00401689
I1006 21:53:48.561527  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00401703 (* 1 = 0.00401703 loss)
I1006 21:53:48.561538  3817 sgd_solver.cpp:105] Iteration 61800, lr = 0.01
I1006 21:54:05.641228  3817 solver.cpp:218] Iteration 61900 (5.85541 iter/s, 17.0782s/100 iters), loss = 0.00158413
I1006 21:54:05.641270  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00158427 (* 1 = 0.00158427 loss)
I1006 21:54:05.641278  3817 sgd_solver.cpp:105] Iteration 61900, lr = 0.01
I1006 21:54:21.883452  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:54:22.564268  3817 solver.cpp:330] Iteration 62000, Testing net (#0)
I1006 21:54:26.089051  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:54:26.244397  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9171
I1006 21:54:26.244434  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.339592 (* 1 = 0.339592 loss)
I1006 21:54:26.340968  3817 solver.cpp:218] Iteration 62000 (4.8315 iter/s, 20.6975s/100 iters), loss = 0.00503637
I1006 21:54:26.341006  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00503651 (* 1 = 0.00503651 loss)
I1006 21:54:26.341012  3817 sgd_solver.cpp:105] Iteration 62000, lr = 0.01
I1006 21:54:43.408051  3817 solver.cpp:218] Iteration 62100 (5.85927 iter/s, 17.067s/100 iters), loss = 0.00466568
I1006 21:54:43.408084  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00466582 (* 1 = 0.00466582 loss)
I1006 21:54:43.408100  3817 sgd_solver.cpp:105] Iteration 62100, lr = 0.01
I1006 21:55:00.841790  3817 solver.cpp:218] Iteration 62200 (5.73673 iter/s, 17.4315s/100 iters), loss = 0.0094016
I1006 21:55:00.841935  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00940173 (* 1 = 0.00940173 loss)
I1006 21:55:00.841943  3817 sgd_solver.cpp:105] Iteration 62200, lr = 0.01
I1006 21:55:17.924263  3817 solver.cpp:218] Iteration 62300 (5.85471 iter/s, 17.0803s/100 iters), loss = 0.00187423
I1006 21:55:17.924296  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00187437 (* 1 = 0.00187437 loss)
I1006 21:55:17.924304  3817 sgd_solver.cpp:105] Iteration 62300, lr = 0.01
I1006 21:55:34.988713  3817 solver.cpp:218] Iteration 62400 (5.86017 iter/s, 17.0643s/100 iters), loss = 0.00975344
I1006 21:55:34.988780  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00975358 (* 1 = 0.00975358 loss)
I1006 21:55:34.988790  3817 sgd_solver.cpp:105] Iteration 62400, lr = 0.01
I1006 21:55:51.225129  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:55:51.907821  3817 solver.cpp:330] Iteration 62500, Testing net (#0)
I1006 21:55:55.433226  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:55:55.600152  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9183
I1006 21:55:55.600178  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.327361 (* 1 = 0.327361 loss)
I1006 21:55:55.691167  3817 solver.cpp:218] Iteration 62500 (4.83087 iter/s, 20.7002s/100 iters), loss = 0.0186739
I1006 21:55:55.691201  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.018674 (* 1 = 0.018674 loss)
I1006 21:55:55.691211  3817 sgd_solver.cpp:105] Iteration 62500, lr = 0.01
I1006 21:56:12.729019  3817 solver.cpp:218] Iteration 62600 (5.87004 iter/s, 17.0357s/100 iters), loss = 0.00321563
I1006 21:56:12.729147  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00321577 (* 1 = 0.00321577 loss)
I1006 21:56:12.729173  3817 sgd_solver.cpp:105] Iteration 62600, lr = 0.01
I1006 21:56:30.153574  3817 solver.cpp:218] Iteration 62700 (5.73977 iter/s, 17.4223s/100 iters), loss = 0.0286893
I1006 21:56:30.153615  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0286895 (* 1 = 0.0286895 loss)
I1006 21:56:30.153621  3817 sgd_solver.cpp:105] Iteration 62700, lr = 0.01
I1006 21:56:47.242908  3817 solver.cpp:218] Iteration 62800 (5.85164 iter/s, 17.0892s/100 iters), loss = 0.0109563
I1006 21:56:47.242998  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0109564 (* 1 = 0.0109564 loss)
I1006 21:56:47.243006  3817 sgd_solver.cpp:105] Iteration 62800, lr = 0.01
I1006 21:57:04.320106  3817 solver.cpp:218] Iteration 62900 (5.85581 iter/s, 17.0771s/100 iters), loss = 0.00485306
I1006 21:57:04.320148  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00485321 (* 1 = 0.00485321 loss)
I1006 21:57:04.320155  3817 sgd_solver.cpp:105] Iteration 62900, lr = 0.01
I1006 21:57:20.559934  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:57:21.242676  3817 solver.cpp:330] Iteration 63000, Testing net (#0)
I1006 21:57:24.770758  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:57:24.909096  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9186
I1006 21:57:24.909122  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.337435 (* 1 = 0.337435 loss)
I1006 21:57:25.021698  3817 solver.cpp:218] Iteration 63000 (4.83107 iter/s, 20.6993s/100 iters), loss = 0.00334641
I1006 21:57:25.021744  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00334656 (* 1 = 0.00334656 loss)
I1006 21:57:25.021750  3817 sgd_solver.cpp:105] Iteration 63000, lr = 0.01
I1006 21:57:42.084162  3817 solver.cpp:218] Iteration 63100 (5.86086 iter/s, 17.0624s/100 iters), loss = 0.00660729
I1006 21:57:42.084205  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00660743 (* 1 = 0.00660743 loss)
I1006 21:57:42.084213  3817 sgd_solver.cpp:105] Iteration 63100, lr = 0.01
I1006 21:57:59.597142  3817 solver.cpp:218] Iteration 63200 (5.7107 iter/s, 17.511s/100 iters), loss = 0.00524692
I1006 21:57:59.597260  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00524706 (* 1 = 0.00524706 loss)
I1006 21:57:59.597268  3817 sgd_solver.cpp:105] Iteration 63200, lr = 0.01
I1006 21:58:16.662760  3817 solver.cpp:218] Iteration 63300 (5.86051 iter/s, 17.0634s/100 iters), loss = 0.00493418
I1006 21:58:16.662791  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00493432 (* 1 = 0.00493432 loss)
I1006 21:58:16.662807  3817 sgd_solver.cpp:105] Iteration 63300, lr = 0.01
I1006 21:58:33.732215  3817 solver.cpp:218] Iteration 63400 (5.85918 iter/s, 17.0672s/100 iters), loss = 0.00140609
I1006 21:58:33.732286  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00140623 (* 1 = 0.00140623 loss)
I1006 21:58:33.732295  3817 sgd_solver.cpp:105] Iteration 63400, lr = 0.01
I1006 21:58:49.964011  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:58:50.643407  3817 solver.cpp:330] Iteration 63500, Testing net (#0)
I1006 21:58:54.168534  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:58:54.276576  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9133
I1006 21:58:54.276602  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.370344 (* 1 = 0.370344 loss)
I1006 21:58:54.419701  3817 solver.cpp:218] Iteration 63500 (4.83436 iter/s, 20.6853s/100 iters), loss = 0.00246801
I1006 21:58:54.419740  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00246815 (* 1 = 0.00246815 loss)
I1006 21:58:54.419747  3817 sgd_solver.cpp:105] Iteration 63500, lr = 0.01
I1006 21:59:11.484035  3817 solver.cpp:218] Iteration 63600 (5.86022 iter/s, 17.0642s/100 iters), loss = 0.00581818
I1006 21:59:11.484194  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00581831 (* 1 = 0.00581831 loss)
I1006 21:59:11.484212  3817 sgd_solver.cpp:105] Iteration 63600, lr = 0.01
I1006 21:59:28.914597  3817 solver.cpp:218] Iteration 63700 (5.73779 iter/s, 17.4283s/100 iters), loss = 0.00881444
I1006 21:59:28.914628  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00881458 (* 1 = 0.00881458 loss)
I1006 21:59:28.914645  3817 sgd_solver.cpp:105] Iteration 63700, lr = 0.01
I1006 21:59:46.007984  3817 solver.cpp:218] Iteration 63800 (5.85098 iter/s, 17.0911s/100 iters), loss = 0.0109115
I1006 21:59:46.008095  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0109116 (* 1 = 0.0109116 loss)
I1006 21:59:46.008113  3817 sgd_solver.cpp:105] Iteration 63800, lr = 0.01
I1006 22:00:03.074018  3817 solver.cpp:218] Iteration 63900 (5.86027 iter/s, 17.0641s/100 iters), loss = 0.00350562
I1006 22:00:03.074064  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00350575 (* 1 = 0.00350575 loss)
I1006 22:00:03.074069  3817 sgd_solver.cpp:105] Iteration 63900, lr = 0.01
I1006 22:00:19.319403  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:00:19.998366  3817 solver.cpp:330] Iteration 64000, Testing net (#0)
I1006 22:00:23.523428  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:00:23.663827  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9162
I1006 22:00:23.663863  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.350629 (* 1 = 0.350629 loss)
I1006 22:00:23.774193  3817 solver.cpp:218] Iteration 64000 (4.8314 iter/s, 20.6979s/100 iters), loss = 0.0162987
I1006 22:00:23.774230  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0162989 (* 1 = 0.0162989 loss)
I1006 22:00:23.774236  3817 sgd_solver.cpp:105] Iteration 64000, lr = 0.01
I1006 22:00:40.829391  3817 solver.cpp:218] Iteration 64100 (5.86336 iter/s, 17.0551s/100 iters), loss = 0.00815702
I1006 22:00:40.829433  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00815715 (* 1 = 0.00815715 loss)
I1006 22:00:40.829439  3817 sgd_solver.cpp:105] Iteration 64100, lr = 0.01
I1006 22:00:58.247560  3817 solver.cpp:218] Iteration 64200 (5.74187 iter/s, 17.4159s/100 iters), loss = 0.00182347
I1006 22:00:58.247689  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00182359 (* 1 = 0.00182359 loss)
I1006 22:00:58.247709  3817 sgd_solver.cpp:105] Iteration 64200, lr = 0.01
I1006 22:01:15.327464  3817 solver.cpp:218] Iteration 64300 (5.85559 iter/s, 17.0777s/100 iters), loss = 0.00250315
I1006 22:01:15.327507  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00250327 (* 1 = 0.00250327 loss)
I1006 22:01:15.327513  3817 sgd_solver.cpp:105] Iteration 64300, lr = 0.01
I1006 22:01:32.401435  3817 solver.cpp:218] Iteration 64400 (5.85764 iter/s, 17.0717s/100 iters), loss = 0.00495839
I1006 22:01:32.401546  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00495852 (* 1 = 0.00495852 loss)
I1006 22:01:32.401562  3817 sgd_solver.cpp:105] Iteration 64400, lr = 0.01
I1006 22:01:48.626940  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:01:49.308596  3817 solver.cpp:330] Iteration 64500, Testing net (#0)
I1006 22:01:52.816633  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:01:52.937551  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9166
I1006 22:01:52.937587  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.347004 (* 1 = 0.347004 loss)
I1006 22:01:53.084977  3817 solver.cpp:218] Iteration 64500 (4.83529 iter/s, 20.6813s/100 iters), loss = 0.00356887
I1006 22:01:53.085019  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.003569 (* 1 = 0.003569 loss)
I1006 22:01:53.085026  3817 sgd_solver.cpp:105] Iteration 64500, lr = 0.01
I1006 22:02:10.142946  3817 solver.cpp:218] Iteration 64600 (5.8624 iter/s, 17.0579s/100 iters), loss = 0.00250759
I1006 22:02:10.143087  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00250772 (* 1 = 0.00250772 loss)
I1006 22:02:10.143106  3817 sgd_solver.cpp:105] Iteration 64600, lr = 0.01
I1006 22:02:27.559126  3817 solver.cpp:218] Iteration 64700 (5.74253 iter/s, 17.4139s/100 iters), loss = 0.0166107
I1006 22:02:27.559170  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0166109 (* 1 = 0.0166109 loss)
I1006 22:02:27.559176  3817 sgd_solver.cpp:105] Iteration 64700, lr = 0.01
I1006 22:02:44.637429  3817 solver.cpp:218] Iteration 64800 (5.85615 iter/s, 17.0761s/100 iters), loss = 0.00618306
I1006 22:02:44.637506  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00618319 (* 1 = 0.00618319 loss)
I1006 22:02:44.637524  3817 sgd_solver.cpp:105] Iteration 64800, lr = 0.01
I1006 22:03:01.702430  3817 solver.cpp:218] Iteration 64900 (5.86042 iter/s, 17.0636s/100 iters), loss = 0.00372806
I1006 22:03:01.702472  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00372819 (* 1 = 0.00372819 loss)
I1006 22:03:01.702479  3817 sgd_solver.cpp:105] Iteration 64900, lr = 0.01
I1006 22:03:17.925130  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:03:18.606204  3817 solver.cpp:330] Iteration 65000, Testing net (#0)
I1006 22:03:22.125780  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:03:22.262091  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9158
I1006 22:03:22.262128  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.348943 (* 1 = 0.348943 loss)
I1006 22:03:22.377640  3817 solver.cpp:218] Iteration 65000 (4.83719 iter/s, 20.6731s/100 iters), loss = 0.00728351
I1006 22:03:22.377679  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00728363 (* 1 = 0.00728363 loss)
I1006 22:03:22.377686  3817 sgd_solver.cpp:105] Iteration 65000, lr = 0.01
I1006 22:03:39.446895  3817 solver.cpp:218] Iteration 65100 (5.85852 iter/s, 17.0691s/100 iters), loss = 0.0348042
I1006 22:03:39.446934  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0348043 (* 1 = 0.0348043 loss)
I1006 22:03:39.446940  3817 sgd_solver.cpp:105] Iteration 65100, lr = 0.01
I1006 22:03:56.867621  3817 solver.cpp:218] Iteration 65200 (5.74101 iter/s, 17.4185s/100 iters), loss = 0.00718099
I1006 22:03:56.867727  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00718111 (* 1 = 0.00718111 loss)
I1006 22:03:56.867745  3817 sgd_solver.cpp:105] Iteration 65200, lr = 0.01
I1006 22:04:13.937863  3817 solver.cpp:218] Iteration 65300 (5.85892 iter/s, 17.068s/100 iters), loss = 0.00867822
I1006 22:04:13.937906  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00867835 (* 1 = 0.00867835 loss)
I1006 22:04:13.937911  3817 sgd_solver.cpp:105] Iteration 65300, lr = 0.01
I1006 22:04:31.011806  3817 solver.cpp:218] Iteration 65400 (5.85691 iter/s, 17.0738s/100 iters), loss = 0.0033919
I1006 22:04:31.011903  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00339202 (* 1 = 0.00339202 loss)
I1006 22:04:31.011921  3817 sgd_solver.cpp:105] Iteration 65400, lr = 0.01
I1006 22:04:47.244009  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:04:47.924918  3817 solver.cpp:330] Iteration 65500, Testing net (#0)
I1006 22:04:51.446818  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:04:51.601402  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9171
I1006 22:04:51.601431  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.338273 (* 1 = 0.338273 loss)
I1006 22:04:51.697295  3817 solver.cpp:218] Iteration 65500 (4.83472 iter/s, 20.6837s/100 iters), loss = 0.000950838
I1006 22:04:51.697326  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000950963 (* 1 = 0.000950963 loss)
I1006 22:04:51.697346  3817 sgd_solver.cpp:105] Iteration 65500, lr = 0.01
I1006 22:05:08.750975  3817 solver.cpp:218] Iteration 65600 (5.86387 iter/s, 17.0536s/100 iters), loss = 0.00177138
I1006 22:05:08.751085  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00177151 (* 1 = 0.00177151 loss)
I1006 22:05:08.751107  3817 sgd_solver.cpp:105] Iteration 65600, lr = 0.01
I1006 22:05:26.174072  3817 solver.cpp:218] Iteration 65700 (5.74025 iter/s, 17.4209s/100 iters), loss = 0.0021616
I1006 22:05:26.174104  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00216172 (* 1 = 0.00216172 loss)
I1006 22:05:26.174124  3817 sgd_solver.cpp:105] Iteration 65700, lr = 0.01
I1006 22:05:43.269230  3817 solver.cpp:218] Iteration 65800 (5.85037 iter/s, 17.0929s/100 iters), loss = 0.00430087
I1006 22:05:43.269371  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00430099 (* 1 = 0.00430099 loss)
I1006 22:05:43.269379  3817 sgd_solver.cpp:105] Iteration 65800, lr = 0.01
I1006 22:06:00.343108  3817 solver.cpp:218] Iteration 65900 (5.85766 iter/s, 17.0717s/100 iters), loss = 0.00478018
I1006 22:06:00.343142  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00478031 (* 1 = 0.00478031 loss)
I1006 22:06:00.343148  3817 sgd_solver.cpp:105] Iteration 65900, lr = 0.01
I1006 22:06:16.584072  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:06:17.266173  3817 solver.cpp:330] Iteration 66000, Testing net (#0)
I1006 22:06:20.781525  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:06:20.900569  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9134
I1006 22:06:20.900593  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.36978 (* 1 = 0.36978 loss)
I1006 22:06:21.048400  3817 solver.cpp:218] Iteration 66000 (4.83021 iter/s, 20.703s/100 iters), loss = 0.00138393
I1006 22:06:21.048429  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00138405 (* 1 = 0.00138405 loss)
I1006 22:06:21.048445  3817 sgd_solver.cpp:105] Iteration 66000, lr = 0.01
I1006 22:06:38.121945  3817 solver.cpp:218] Iteration 66100 (5.85705 iter/s, 17.0734s/100 iters), loss = 0.00325138
I1006 22:06:38.121978  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00325151 (* 1 = 0.00325151 loss)
I1006 22:06:38.121994  3817 sgd_solver.cpp:105] Iteration 66100, lr = 0.01
I1006 22:06:55.528353  3817 solver.cpp:218] Iteration 66200 (5.74552 iter/s, 17.4049s/100 iters), loss = 0.00456868
I1006 22:06:55.528439  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00456881 (* 1 = 0.00456881 loss)
I1006 22:06:55.528457  3817 sgd_solver.cpp:105] Iteration 66200, lr = 0.01
I1006 22:07:12.600879  3817 solver.cpp:218] Iteration 66300 (5.85802 iter/s, 17.0706s/100 iters), loss = 0.00270691
I1006 22:07:12.600920  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00270703 (* 1 = 0.00270703 loss)
I1006 22:07:12.600926  3817 sgd_solver.cpp:105] Iteration 66300, lr = 0.01
I1006 22:07:29.673431  3817 solver.cpp:218] Iteration 66400 (5.85787 iter/s, 17.071s/100 iters), loss = 0.00754606
I1006 22:07:29.673516  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00754619 (* 1 = 0.00754619 loss)
I1006 22:07:29.673528  3817 sgd_solver.cpp:105] Iteration 66400, lr = 0.01
I1006 22:07:45.906922  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:07:46.587954  3817 solver.cpp:330] Iteration 66500, Testing net (#0)
I1006 22:07:50.113126  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:07:50.249267  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9154
I1006 22:07:50.249295  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.352711 (* 1 = 0.352711 loss)
I1006 22:07:50.364091  3817 solver.cpp:218] Iteration 66500 (4.83349 iter/s, 20.689s/100 iters), loss = 0.00211048
I1006 22:07:50.364120  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00211061 (* 1 = 0.00211061 loss)
I1006 22:07:50.364136  3817 sgd_solver.cpp:105] Iteration 66500, lr = 0.01
I1006 22:08:07.435464  3817 solver.cpp:218] Iteration 66600 (5.8578 iter/s, 17.0713s/100 iters), loss = 0.0125594
I1006 22:08:07.435559  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0125596 (* 1 = 0.0125596 loss)
I1006 22:08:07.435567  3817 sgd_solver.cpp:105] Iteration 66600, lr = 0.01
I1006 22:08:24.862643  3817 solver.cpp:218] Iteration 66700 (5.73889 iter/s, 17.425s/100 iters), loss = 0.0122479
I1006 22:08:24.862684  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.012248 (* 1 = 0.012248 loss)
I1006 22:08:24.862690  3817 sgd_solver.cpp:105] Iteration 66700, lr = 0.01
I1006 22:08:41.941344  3817 solver.cpp:218] Iteration 66800 (5.85601 iter/s, 17.0765s/100 iters), loss = 0.00837503
I1006 22:08:41.941478  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00837516 (* 1 = 0.00837516 loss)
I1006 22:08:41.941485  3817 sgd_solver.cpp:105] Iteration 66800, lr = 0.01
I1006 22:08:59.014183  3817 solver.cpp:218] Iteration 66900 (5.85732 iter/s, 17.0726s/100 iters), loss = 0.0147269
I1006 22:08:59.014226  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0147271 (* 1 = 0.0147271 loss)
I1006 22:08:59.014233  3817 sgd_solver.cpp:105] Iteration 66900, lr = 0.01
I1006 22:09:15.251142  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:09:15.931571  3817 solver.cpp:330] Iteration 67000, Testing net (#0)
I1006 22:09:19.457027  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:09:19.593008  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9187
I1006 22:09:19.593034  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.330805 (* 1 = 0.330805 loss)
I1006 22:09:19.707778  3817 solver.cpp:218] Iteration 67000 (4.83276 iter/s, 20.6921s/100 iters), loss = 0.00364942
I1006 22:09:19.707815  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00364956 (* 1 = 0.00364956 loss)
I1006 22:09:19.707821  3817 sgd_solver.cpp:105] Iteration 67000, lr = 0.01
I1006 22:09:36.767145  3817 solver.cpp:218] Iteration 67100 (5.86192 iter/s, 17.0593s/100 iters), loss = 0.00278518
I1006 22:09:36.767187  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00278532 (* 1 = 0.00278532 loss)
I1006 22:09:36.767194  3817 sgd_solver.cpp:105] Iteration 67100, lr = 0.01
I1006 22:09:54.204277  3817 solver.cpp:218] Iteration 67200 (5.73547 iter/s, 17.4354s/100 iters), loss = 0.00110715
I1006 22:09:54.204432  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0011073 (* 1 = 0.0011073 loss)
I1006 22:09:54.204452  3817 sgd_solver.cpp:105] Iteration 67200, lr = 0.01
I1006 22:10:11.282613  3817 solver.cpp:218] Iteration 67300 (5.85545 iter/s, 17.0781s/100 iters), loss = 0.00479047
I1006 22:10:11.282655  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00479061 (* 1 = 0.00479061 loss)
I1006 22:10:11.282662  3817 sgd_solver.cpp:105] Iteration 67300, lr = 0.01
I1006 22:10:28.384697  3817 solver.cpp:218] Iteration 67400 (5.84801 iter/s, 17.0998s/100 iters), loss = 0.00187223
I1006 22:10:28.384805  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00187237 (* 1 = 0.00187237 loss)
I1006 22:10:28.384824  3817 sgd_solver.cpp:105] Iteration 67400, lr = 0.01
I1006 22:10:44.620499  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:10:45.302757  3817 solver.cpp:330] Iteration 67500, Testing net (#0)
I1006 22:10:48.831634  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:10:48.986593  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9121
I1006 22:10:48.986619  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.39076 (* 1 = 0.39076 loss)
I1006 22:10:49.082712  3817 solver.cpp:218] Iteration 67500 (4.83191 iter/s, 20.6958s/100 iters), loss = 0.00133138
I1006 22:10:49.082751  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00133152 (* 1 = 0.00133152 loss)
I1006 22:10:49.082757  3817 sgd_solver.cpp:105] Iteration 67500, lr = 0.01
I1006 22:11:06.152840  3817 solver.cpp:218] Iteration 67600 (5.85822 iter/s, 17.07s/100 iters), loss = 0.00409534
I1006 22:11:06.152948  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00409548 (* 1 = 0.00409548 loss)
I1006 22:11:06.152966  3817 sgd_solver.cpp:105] Iteration 67600, lr = 0.01
I1006 22:11:23.567479  3817 solver.cpp:218] Iteration 67700 (5.74283 iter/s, 17.413s/100 iters), loss = 0.0141049
I1006 22:11:23.567510  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.014105 (* 1 = 0.014105 loss)
I1006 22:11:23.567528  3817 sgd_solver.cpp:105] Iteration 67700, lr = 0.01
I1006 22:11:40.643056  3817 solver.cpp:218] Iteration 67800 (5.85709 iter/s, 17.0733s/100 iters), loss = 0.00134227
I1006 22:11:40.643193  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0013424 (* 1 = 0.0013424 loss)
I1006 22:11:40.643213  3817 sgd_solver.cpp:105] Iteration 67800, lr = 0.01
I1006 22:11:57.719383  3817 solver.cpp:218] Iteration 67900 (5.85683 iter/s, 17.0741s/100 iters), loss = 0.000837691
I1006 22:11:57.719416  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000837821 (* 1 = 0.000837821 loss)
I1006 22:11:57.719434  3817 sgd_solver.cpp:105] Iteration 67900, lr = 0.01
I1006 22:12:13.935465  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:12:14.616961  3817 solver.cpp:330] Iteration 68000, Testing net (#0)
I1006 22:12:18.142582  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:12:18.295331  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9133
I1006 22:12:18.295356  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.365197 (* 1 = 0.365197 loss)
I1006 22:12:18.393901  3817 solver.cpp:218] Iteration 68000 (4.83718 iter/s, 20.6732s/100 iters), loss = 0.00539559
I1006 22:12:18.393939  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00539572 (* 1 = 0.00539572 loss)
I1006 22:12:18.393945  3817 sgd_solver.cpp:105] Iteration 68000, lr = 0.01
I1006 22:12:35.464664  3817 solver.cpp:218] Iteration 68100 (5.85801 iter/s, 17.0707s/100 iters), loss = 0.00344734
I1006 22:12:35.464706  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00344748 (* 1 = 0.00344748 loss)
I1006 22:12:35.464712  3817 sgd_solver.cpp:105] Iteration 68100, lr = 0.01
I1006 22:12:52.896564  3817 solver.cpp:218] Iteration 68200 (5.73723 iter/s, 17.43s/100 iters), loss = 0.0114903
I1006 22:12:52.896667  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0114904 (* 1 = 0.0114904 loss)
I1006 22:12:52.896677  3817 sgd_solver.cpp:105] Iteration 68200, lr = 0.01
I1006 22:13:09.985501  3817 solver.cpp:218] Iteration 68300 (5.85227 iter/s, 17.0874s/100 iters), loss = 0.00715217
I1006 22:13:09.985545  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0071523 (* 1 = 0.0071523 loss)
I1006 22:13:09.985553  3817 sgd_solver.cpp:105] Iteration 68300, lr = 0.01
I1006 22:13:27.065840  3817 solver.cpp:218] Iteration 68400 (5.85545 iter/s, 17.0781s/100 iters), loss = 0.0055756
I1006 22:13:27.065918  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00557574 (* 1 = 0.00557574 loss)
I1006 22:13:27.065925  3817 sgd_solver.cpp:105] Iteration 68400, lr = 0.01
I1006 22:13:43.295212  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:13:43.978749  3817 solver.cpp:330] Iteration 68500, Testing net (#0)
I1006 22:13:47.505000  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:13:47.672281  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9136
I1006 22:13:47.672307  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.363726 (* 1 = 0.363726 loss)
I1006 22:13:47.763137  3817 solver.cpp:218] Iteration 68500 (4.83207 iter/s, 20.695s/100 iters), loss = 0.00102337
I1006 22:13:47.763169  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0010235 (* 1 = 0.0010235 loss)
I1006 22:13:47.763175  3817 sgd_solver.cpp:105] Iteration 68500, lr = 0.01
I1006 22:14:04.808969  3817 solver.cpp:218] Iteration 68600 (5.86731 iter/s, 17.0436s/100 iters), loss = 0.0122704
I1006 22:14:04.809090  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0122705 (* 1 = 0.0122705 loss)
I1006 22:14:04.809108  3817 sgd_solver.cpp:105] Iteration 68600, lr = 0.01
I1006 22:14:22.227352  3817 solver.cpp:218] Iteration 68700 (5.74141 iter/s, 17.4173s/100 iters), loss = 0.00328617
I1006 22:14:22.227396  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00328629 (* 1 = 0.00328629 loss)
I1006 22:14:22.227401  3817 sgd_solver.cpp:105] Iteration 68700, lr = 0.01
I1006 22:14:39.311779  3817 solver.cpp:218] Iteration 68800 (5.85405 iter/s, 17.0822s/100 iters), loss = 0.00250244
I1006 22:14:39.311913  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00250256 (* 1 = 0.00250256 loss)
I1006 22:14:39.311923  3817 sgd_solver.cpp:105] Iteration 68800, lr = 0.01
I1006 22:14:56.404553  3817 solver.cpp:218] Iteration 68900 (5.85113 iter/s, 17.0907s/100 iters), loss = 0.0024103
I1006 22:14:56.404585  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00241043 (* 1 = 0.00241043 loss)
I1006 22:14:56.404603  3817 sgd_solver.cpp:105] Iteration 68900, lr = 0.01
I1006 22:15:12.645496  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:15:13.327929  3817 solver.cpp:330] Iteration 69000, Testing net (#0)
I1006 22:15:16.855610  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:15:16.976987  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.918
I1006 22:15:16.977022  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.343397 (* 1 = 0.343397 loss)
I1006 22:15:17.108243  3817 solver.cpp:218] Iteration 69000 (4.83008 iter/s, 20.7036s/100 iters), loss = 0.000931362
I1006 22:15:17.108283  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000931487 (* 1 = 0.000931487 loss)
I1006 22:15:17.108289  3817 sgd_solver.cpp:105] Iteration 69000, lr = 0.01
I1006 22:15:34.167711  3817 solver.cpp:218] Iteration 69100 (5.86189 iter/s, 17.0594s/100 iters), loss = 0.00164804
I1006 22:15:34.167754  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00164817 (* 1 = 0.00164817 loss)
I1006 22:15:34.167762  3817 sgd_solver.cpp:105] Iteration 69100, lr = 0.01
I1006 22:15:51.590909  3817 solver.cpp:218] Iteration 69200 (5.74021 iter/s, 17.421s/100 iters), loss = 0.0336651
I1006 22:15:51.591006  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0336653 (* 1 = 0.0336653 loss)
I1006 22:15:51.591014  3817 sgd_solver.cpp:105] Iteration 69200, lr = 0.01
I1006 22:16:08.659821  3817 solver.cpp:218] Iteration 69300 (5.85937 iter/s, 17.0667s/100 iters), loss = 0.00391505
I1006 22:16:08.659862  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00391518 (* 1 = 0.00391518 loss)
I1006 22:16:08.659868  3817 sgd_solver.cpp:105] Iteration 69300, lr = 0.01
I1006 22:16:25.724526  3817 solver.cpp:218] Iteration 69400 (5.86082 iter/s, 17.0625s/100 iters), loss = 0.018936
I1006 22:16:25.724673  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0189361 (* 1 = 0.0189361 loss)
I1006 22:16:25.724681  3817 sgd_solver.cpp:105] Iteration 69400, lr = 0.01
I1006 22:16:41.967308  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:16:42.650125  3817 solver.cpp:330] Iteration 69500, Testing net (#0)
I1006 22:16:46.176591  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:16:46.334228  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9187
I1006 22:16:46.334265  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.358894 (* 1 = 0.358894 loss)
I1006 22:16:46.428021  3817 solver.cpp:218] Iteration 69500 (4.83063 iter/s, 20.7012s/100 iters), loss = 0.00118151
I1006 22:16:46.428059  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00118165 (* 1 = 0.00118165 loss)
I1006 22:16:46.428066  3817 sgd_solver.cpp:105] Iteration 69500, lr = 0.01
I1006 22:17:03.492385  3817 solver.cpp:218] Iteration 69600 (5.8602 iter/s, 17.0643s/100 iters), loss = 0.00751367
I1006 22:17:03.492532  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0075138 (* 1 = 0.0075138 loss)
I1006 22:17:03.492549  3817 sgd_solver.cpp:105] Iteration 69600, lr = 0.01
I1006 22:17:21.005585  3817 solver.cpp:218] Iteration 69700 (5.7107 iter/s, 17.511s/100 iters), loss = 0.0025027
I1006 22:17:21.005619  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00250284 (* 1 = 0.00250284 loss)
I1006 22:17:21.005635  3817 sgd_solver.cpp:105] Iteration 69700, lr = 0.01
I1006 22:17:38.089328  3817 solver.cpp:218] Iteration 69800 (5.85429 iter/s, 17.0815s/100 iters), loss = 0.00933032
I1006 22:17:38.089463  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00933045 (* 1 = 0.00933045 loss)
I1006 22:17:38.089484  3817 sgd_solver.cpp:105] Iteration 69800, lr = 0.01
I1006 22:17:55.162633  3817 solver.cpp:218] Iteration 69900 (5.85756 iter/s, 17.072s/100 iters), loss = 0.00243839
I1006 22:17:55.162675  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00243852 (* 1 = 0.00243852 loss)
I1006 22:17:55.162683  3817 sgd_solver.cpp:105] Iteration 69900, lr = 0.01
I1006 22:18:11.405848  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:18:12.090032  3817 solver.cpp:330] Iteration 70000, Testing net (#0)
I1006 22:18:15.593549  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:18:15.717747  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9172
I1006 22:18:15.717784  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.352058 (* 1 = 0.352058 loss)
I1006 22:18:15.865763  3817 solver.cpp:218] Iteration 70000 (4.83068 iter/s, 20.701s/100 iters), loss = 0.00952372
I1006 22:18:15.865803  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00952385 (* 1 = 0.00952385 loss)
I1006 22:18:15.865810  3817 sgd_solver.cpp:105] Iteration 70000, lr = 0.01
I1006 22:18:32.945333  3817 solver.cpp:218] Iteration 70100 (5.85499 iter/s, 17.0795s/100 iters), loss = 0.00354675
I1006 22:18:32.945377  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00354688 (* 1 = 0.00354688 loss)
I1006 22:18:32.945384  3817 sgd_solver.cpp:105] Iteration 70100, lr = 0.01
I1006 22:18:50.376001  3817 solver.cpp:218] Iteration 70200 (5.73758 iter/s, 17.429s/100 iters), loss = 0.00169126
I1006 22:18:50.376114  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00169138 (* 1 = 0.00169138 loss)
I1006 22:18:50.376133  3817 sgd_solver.cpp:105] Iteration 70200, lr = 0.01
I1006 22:19:07.447525  3817 solver.cpp:218] Iteration 70300 (5.85827 iter/s, 17.0699s/100 iters), loss = 0.0031111
I1006 22:19:07.447566  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00311122 (* 1 = 0.00311122 loss)
I1006 22:19:07.447572  3817 sgd_solver.cpp:105] Iteration 70300, lr = 0.01
I1006 22:19:24.529847  3817 solver.cpp:218] Iteration 70400 (5.85476 iter/s, 17.0801s/100 iters), loss = 0.00156286
I1006 22:19:24.529955  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00156298 (* 1 = 0.00156298 loss)
I1006 22:19:24.529963  3817 sgd_solver.cpp:105] Iteration 70400, lr = 0.01
I1006 22:19:40.767947  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:19:41.450268  3817 solver.cpp:330] Iteration 70500, Testing net (#0)
I1006 22:19:44.975798  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:19:45.126724  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9153
I1006 22:19:45.126762  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.37104 (* 1 = 0.37104 loss)
I1006 22:19:45.227841  3817 solver.cpp:218] Iteration 70500 (4.8319 iter/s, 20.6958s/100 iters), loss = 0.0105144
I1006 22:19:45.227881  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0105145 (* 1 = 0.0105145 loss)
I1006 22:19:45.227887  3817 sgd_solver.cpp:105] Iteration 70500, lr = 0.01
I1006 22:20:02.297866  3817 solver.cpp:218] Iteration 70600 (5.85826 iter/s, 17.0699s/100 iters), loss = 0.00574996
I1006 22:20:02.297991  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00575008 (* 1 = 0.00575008 loss)
I1006 22:20:02.298008  3817 sgd_solver.cpp:105] Iteration 70600, lr = 0.01
I1006 22:20:19.738639  3817 solver.cpp:218] Iteration 70700 (5.73442 iter/s, 17.4386s/100 iters), loss = 0.00281909
I1006 22:20:19.738682  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0028192 (* 1 = 0.0028192 loss)
I1006 22:20:19.738688  3817 sgd_solver.cpp:105] Iteration 70700, lr = 0.01
I1006 22:20:36.837363  3817 solver.cpp:218] Iteration 70800 (5.84879 iter/s, 17.0975s/100 iters), loss = 0.00161099
I1006 22:20:36.837522  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0016111 (* 1 = 0.0016111 loss)
I1006 22:20:36.837532  3817 sgd_solver.cpp:105] Iteration 70800, lr = 0.01
I1006 22:20:53.930685  3817 solver.cpp:218] Iteration 70900 (5.85081 iter/s, 17.0917s/100 iters), loss = 0.00232664
I1006 22:20:53.930719  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00232675 (* 1 = 0.00232675 loss)
I1006 22:20:53.930738  3817 sgd_solver.cpp:105] Iteration 70900, lr = 0.01
I1006 22:21:10.174302  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:21:10.856434  3817 solver.cpp:330] Iteration 71000, Testing net (#0)
I1006 22:21:14.387285  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:21:14.554973  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9149
I1006 22:21:14.555009  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.350721 (* 1 = 0.350721 loss)
I1006 22:21:14.647105  3817 solver.cpp:218] Iteration 71000 (4.8276 iter/s, 20.7142s/100 iters), loss = 0.00315954
I1006 22:21:14.647137  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00315965 (* 1 = 0.00315965 loss)
I1006 22:21:14.647145  3817 sgd_solver.cpp:105] Iteration 71000, lr = 0.01
I1006 22:21:31.707389  3817 solver.cpp:218] Iteration 71100 (5.86232 iter/s, 17.0581s/100 iters), loss = 0.00246311
I1006 22:21:31.707422  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00246322 (* 1 = 0.00246322 loss)
I1006 22:21:31.707427  3817 sgd_solver.cpp:105] Iteration 71100, lr = 0.01
I1006 22:21:49.125318  3817 solver.cpp:218] Iteration 71200 (5.7417 iter/s, 17.4165s/100 iters), loss = 0.00912289
I1006 22:21:49.125428  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.009123 (* 1 = 0.009123 loss)
I1006 22:21:49.125447  3817 sgd_solver.cpp:105] Iteration 71200, lr = 0.01
I1006 22:22:06.212743  3817 solver.cpp:218] Iteration 71300 (5.85301 iter/s, 17.0852s/100 iters), loss = 0.0073351
I1006 22:22:06.212793  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00733522 (* 1 = 0.00733522 loss)
I1006 22:22:06.212802  3817 sgd_solver.cpp:105] Iteration 71300, lr = 0.01
I1006 22:22:23.297384  3817 solver.cpp:218] Iteration 71400 (5.85398 iter/s, 17.0824s/100 iters), loss = 0.00191533
I1006 22:22:23.297520  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00191544 (* 1 = 0.00191544 loss)
I1006 22:22:23.297538  3817 sgd_solver.cpp:105] Iteration 71400, lr = 0.01
I1006 22:22:39.520313  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:22:40.202760  3817 solver.cpp:330] Iteration 71500, Testing net (#0)
I1006 22:22:43.729451  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:22:43.897516  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9156
I1006 22:22:43.897552  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.346145 (* 1 = 0.346145 loss)
I1006 22:22:43.988450  3817 solver.cpp:218] Iteration 71500 (4.8334 iter/s, 20.6894s/100 iters), loss = 0.0022341
I1006 22:22:43.988493  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00223421 (* 1 = 0.00223421 loss)
I1006 22:22:43.988502  3817 sgd_solver.cpp:105] Iteration 71500, lr = 0.01
I1006 22:23:01.042098  3817 solver.cpp:218] Iteration 71600 (5.86462 iter/s, 17.0514s/100 iters), loss = 0.00824917
I1006 22:23:01.042204  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00824928 (* 1 = 0.00824928 loss)
I1006 22:23:01.042222  3817 sgd_solver.cpp:105] Iteration 71600, lr = 0.01
I1006 22:23:18.551555  3817 solver.cpp:218] Iteration 71700 (5.71193 iter/s, 17.5072s/100 iters), loss = 0.0129353
I1006 22:23:18.551601  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0129354 (* 1 = 0.0129354 loss)
I1006 22:23:18.551609  3817 sgd_solver.cpp:105] Iteration 71700, lr = 0.01
I1006 22:23:35.641140  3817 solver.cpp:218] Iteration 71800 (5.85207 iter/s, 17.088s/100 iters), loss = 0.0139299
I1006 22:23:35.641266  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.01393 (* 1 = 0.01393 loss)
I1006 22:23:35.641285  3817 sgd_solver.cpp:105] Iteration 71800, lr = 0.01
I1006 22:23:52.701568  3817 solver.cpp:218] Iteration 71900 (5.86229 iter/s, 17.0582s/100 iters), loss = 0.00307226
I1006 22:23:52.701608  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00307237 (* 1 = 0.00307237 loss)
I1006 22:23:52.701614  3817 sgd_solver.cpp:105] Iteration 71900, lr = 0.01
I1006 22:24:08.932852  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:24:09.615090  3817 solver.cpp:330] Iteration 72000, Testing net (#0)
I1006 22:24:13.141811  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:24:13.259789  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9189
I1006 22:24:13.259826  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.341218 (* 1 = 0.341218 loss)
I1006 22:24:13.394439  3817 solver.cpp:218] Iteration 72000 (4.83292 iter/s, 20.6914s/100 iters), loss = 0.0112923
I1006 22:24:13.394480  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0112924 (* 1 = 0.0112924 loss)
I1006 22:24:13.394486  3817 sgd_solver.cpp:105] Iteration 72000, lr = 0.01
I1006 22:24:30.456552  3817 solver.cpp:218] Iteration 72100 (5.86098 iter/s, 17.062s/100 iters), loss = 0.00721028
I1006 22:24:30.456595  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00721039 (* 1 = 0.00721039 loss)
I1006 22:24:30.456603  3817 sgd_solver.cpp:105] Iteration 72100, lr = 0.01
I1006 22:24:47.869276  3817 solver.cpp:218] Iteration 72200 (5.7434 iter/s, 17.4113s/100 iters), loss = 0.00119577
I1006 22:24:47.869370  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00119587 (* 1 = 0.00119587 loss)
I1006 22:24:47.869390  3817 sgd_solver.cpp:105] Iteration 72200, lr = 0.01
I1006 22:25:04.934176  3817 solver.cpp:218] Iteration 72300 (5.86051 iter/s, 17.0634s/100 iters), loss = 0.00400566
I1006 22:25:04.934219  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00400576 (* 1 = 0.00400576 loss)
I1006 22:25:04.934226  3817 sgd_solver.cpp:105] Iteration 72300, lr = 0.01
I1006 22:25:21.994513  3817 solver.cpp:218] Iteration 72400 (5.86211 iter/s, 17.0587s/100 iters), loss = 0.00270943
I1006 22:25:21.994634  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00270953 (* 1 = 0.00270953 loss)
I1006 22:25:21.994643  3817 sgd_solver.cpp:105] Iteration 72400, lr = 0.01
I1006 22:25:38.223265  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:25:38.905462  3817 solver.cpp:330] Iteration 72500, Testing net (#0)
I1006 22:25:42.429078  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:25:42.586057  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9146
I1006 22:25:42.586084  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.374636 (* 1 = 0.374636 loss)
I1006 22:25:42.680647  3817 solver.cpp:218] Iteration 72500 (4.83468 iter/s, 20.6839s/100 iters), loss = 0.00129641
I1006 22:25:42.680678  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00129652 (* 1 = 0.00129652 loss)
I1006 22:25:42.680698  3817 sgd_solver.cpp:105] Iteration 72500, lr = 0.01
I1006 22:25:59.744877  3817 solver.cpp:218] Iteration 72600 (5.86025 iter/s, 17.0641s/100 iters), loss = 0.0111998
I1006 22:25:59.744973  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0111999 (* 1 = 0.0111999 loss)
I1006 22:25:59.744992  3817 sgd_solver.cpp:105] Iteration 72600, lr = 0.01
I1006 22:26:17.174619  3817 solver.cpp:218] Iteration 72700 (5.73806 iter/s, 17.4275s/100 iters), loss = 0.00482288
I1006 22:26:17.174661  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00482299 (* 1 = 0.00482299 loss)
I1006 22:26:17.174669  3817 sgd_solver.cpp:105] Iteration 72700, lr = 0.01
I1006 22:26:34.263766  3817 solver.cpp:218] Iteration 72800 (5.85242 iter/s, 17.0869s/100 iters), loss = 0.00911399
I1006 22:26:34.263893  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0091141 (* 1 = 0.0091141 loss)
I1006 22:26:34.263912  3817 sgd_solver.cpp:105] Iteration 72800, lr = 0.01
I1006 22:26:51.339759  3817 solver.cpp:218] Iteration 72900 (5.8568 iter/s, 17.0742s/100 iters), loss = 0.00358849
I1006 22:26:51.339812  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0035886 (* 1 = 0.0035886 loss)
I1006 22:26:51.339819  3817 sgd_solver.cpp:105] Iteration 72900, lr = 0.01
I1006 22:27:07.581007  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:27:08.264317  3817 solver.cpp:330] Iteration 73000, Testing net (#0)
I1006 22:27:11.787556  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:27:11.912703  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9138
I1006 22:27:11.912741  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.364028 (* 1 = 0.364028 loss)
I1006 22:27:12.039593  3817 solver.cpp:218] Iteration 73000 (4.83148 iter/s, 20.6976s/100 iters), loss = 0.00530862
I1006 22:27:12.039633  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00530872 (* 1 = 0.00530872 loss)
I1006 22:27:12.039639  3817 sgd_solver.cpp:105] Iteration 73000, lr = 0.01
I1006 22:27:29.109545  3817 solver.cpp:218] Iteration 73100 (5.85829 iter/s, 17.0698s/100 iters), loss = 0.0113843
I1006 22:27:29.109588  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0113844 (* 1 = 0.0113844 loss)
I1006 22:27:29.109594  3817 sgd_solver.cpp:105] Iteration 73100, lr = 0.01
I1006 22:27:46.533083  3817 solver.cpp:218] Iteration 73200 (5.74009 iter/s, 17.4213s/100 iters), loss = 0.0299418
I1006 22:27:46.533249  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0299419 (* 1 = 0.0299419 loss)
I1006 22:27:46.533273  3817 sgd_solver.cpp:105] Iteration 73200, lr = 0.01
I1006 22:28:03.609810  3817 solver.cpp:218] Iteration 73300 (5.85659 iter/s, 17.0748s/100 iters), loss = 0.00844789
I1006 22:28:03.609845  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00844799 (* 1 = 0.00844799 loss)
I1006 22:28:03.609853  3817 sgd_solver.cpp:105] Iteration 73300, lr = 0.01
I1006 22:28:20.690780  3817 solver.cpp:218] Iteration 73400 (5.85524 iter/s, 17.0787s/100 iters), loss = 0.00155033
I1006 22:28:20.690848  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00155044 (* 1 = 0.00155044 loss)
I1006 22:28:20.690865  3817 sgd_solver.cpp:105] Iteration 73400, lr = 0.01
I1006 22:28:36.934880  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:28:37.617511  3817 solver.cpp:330] Iteration 73500, Testing net (#0)
I1006 22:28:41.132308  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:28:41.247009  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9153
I1006 22:28:41.247046  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.372614 (* 1 = 0.372614 loss)
I1006 22:28:41.393739  3817 solver.cpp:218] Iteration 73500 (4.83047 iter/s, 20.7019s/100 iters), loss = 0.00320746
I1006 22:28:41.393780  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00320757 (* 1 = 0.00320757 loss)
I1006 22:28:41.393787  3817 sgd_solver.cpp:105] Iteration 73500, lr = 0.01
I1006 22:28:58.459466  3817 solver.cpp:218] Iteration 73600 (5.85973 iter/s, 17.0656s/100 iters), loss = 0.00340584
I1006 22:28:58.459569  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00340594 (* 1 = 0.00340594 loss)
I1006 22:28:58.459576  3817 sgd_solver.cpp:105] Iteration 73600, lr = 0.01
I1006 22:29:15.889191  3817 solver.cpp:218] Iteration 73700 (5.73805 iter/s, 17.4275s/100 iters), loss = 0.0029785
I1006 22:29:15.889233  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0029786 (* 1 = 0.0029786 loss)
I1006 22:29:15.889240  3817 sgd_solver.cpp:105] Iteration 73700, lr = 0.01
I1006 22:29:32.954818  3817 solver.cpp:218] Iteration 73800 (5.8603 iter/s, 17.064s/100 iters), loss = 0.00333984
I1006 22:29:32.954969  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00333994 (* 1 = 0.00333994 loss)
I1006 22:29:32.955029  3817 sgd_solver.cpp:105] Iteration 73800, lr = 0.01
I1006 22:29:50.027588  3817 solver.cpp:218] Iteration 73900 (5.85804 iter/s, 17.0706s/100 iters), loss = 0.00226579
I1006 22:29:50.027622  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00226588 (* 1 = 0.00226588 loss)
I1006 22:29:50.027628  3817 sgd_solver.cpp:105] Iteration 73900, lr = 0.01
I1006 22:30:06.267539  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:30:06.948441  3817 solver.cpp:330] Iteration 74000, Testing net (#0)
I1006 22:30:10.476258  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:30:10.643735  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.921
I1006 22:30:10.643761  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.333484 (* 1 = 0.333484 loss)
I1006 22:30:10.749660  3817 solver.cpp:218] Iteration 74000 (4.82629 iter/s, 20.7199s/100 iters), loss = 0.00152675
I1006 22:30:10.749688  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00152685 (* 1 = 0.00152685 loss)
I1006 22:30:10.749706  3817 sgd_solver.cpp:105] Iteration 74000, lr = 0.01
I1006 22:30:27.872978  3817 solver.cpp:218] Iteration 74100 (5.84074 iter/s, 17.1211s/100 iters), loss = 0.0102447
I1006 22:30:27.873009  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0102448 (* 1 = 0.0102448 loss)
I1006 22:30:27.873015  3817 sgd_solver.cpp:105] Iteration 74100, lr = 0.01
I1006 22:30:45.311058  3817 solver.cpp:218] Iteration 74200 (5.73531 iter/s, 17.4359s/100 iters), loss = 0.00466046
I1006 22:30:45.311154  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00466056 (* 1 = 0.00466056 loss)
I1006 22:30:45.311182  3817 sgd_solver.cpp:105] Iteration 74200, lr = 0.01
I1006 22:31:02.385689  3817 solver.cpp:218] Iteration 74300 (5.8574 iter/s, 17.0724s/100 iters), loss = 0.0157209
I1006 22:31:02.385726  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.015721 (* 1 = 0.015721 loss)
I1006 22:31:02.385746  3817 sgd_solver.cpp:105] Iteration 74300, lr = 0.01
I1006 22:31:19.462949  3817 solver.cpp:218] Iteration 74400 (5.85651 iter/s, 17.075s/100 iters), loss = 0.0112042
I1006 22:31:19.463057  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0112043 (* 1 = 0.0112043 loss)
I1006 22:31:19.463069  3817 sgd_solver.cpp:105] Iteration 74400, lr = 0.01
I1006 22:31:35.701588  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:31:36.384639  3817 solver.cpp:330] Iteration 74500, Testing net (#0)
I1006 22:31:39.909730  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:31:40.069108  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9207
I1006 22:31:40.069136  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.334019 (* 1 = 0.334019 loss)
I1006 22:31:40.161396  3817 solver.cpp:218] Iteration 74500 (4.8318 iter/s, 20.6962s/100 iters), loss = 0.00490158
I1006 22:31:40.161445  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00490168 (* 1 = 0.00490168 loss)
I1006 22:31:40.161464  3817 sgd_solver.cpp:105] Iteration 74500, lr = 0.01
I1006 22:31:57.226296  3817 solver.cpp:218] Iteration 74600 (5.86004 iter/s, 17.0647s/100 iters), loss = 0.00842487
I1006 22:31:57.226433  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00842497 (* 1 = 0.00842497 loss)
I1006 22:31:57.226460  3817 sgd_solver.cpp:105] Iteration 74600, lr = 0.01
I1006 22:32:14.651968  3817 solver.cpp:218] Iteration 74700 (5.73939 iter/s, 17.4235s/100 iters), loss = 0.00167361
I1006 22:32:14.652000  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00167371 (* 1 = 0.00167371 loss)
I1006 22:32:14.652017  3817 sgd_solver.cpp:105] Iteration 74700, lr = 0.01
I1006 22:32:31.713368  3817 solver.cpp:218] Iteration 74800 (5.86155 iter/s, 17.0603s/100 iters), loss = 0.00174747
I1006 22:32:31.713480  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00174757 (* 1 = 0.00174757 loss)
I1006 22:32:31.713495  3817 sgd_solver.cpp:105] Iteration 74800, lr = 0.01
I1006 22:32:48.779283  3817 solver.cpp:218] Iteration 74900 (5.86041 iter/s, 17.0637s/100 iters), loss = 0.00248366
I1006 22:32:48.779325  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00248376 (* 1 = 0.00248376 loss)
I1006 22:32:48.779331  3817 sgd_solver.cpp:105] Iteration 74900, lr = 0.01
I1006 22:33:04.985236  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:33:05.664937  3817 solver.cpp:330] Iteration 75000, Testing net (#0)
I1006 22:33:09.176419  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:33:09.295959  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.916
I1006 22:33:09.295984  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.356148 (* 1 = 0.356148 loss)
I1006 22:33:09.443372  3817 solver.cpp:218] Iteration 75000 (4.83983 iter/s, 20.6619s/100 iters), loss = 0.00130306
I1006 22:33:09.443410  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00130316 (* 1 = 0.00130316 loss)
I1006 22:33:09.443416  3817 sgd_solver.cpp:105] Iteration 75000, lr = 0.01
I1006 22:33:26.493696  3817 solver.cpp:218] Iteration 75100 (5.86503 iter/s, 17.0502s/100 iters), loss = 0.00497156
I1006 22:33:26.493737  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00497166 (* 1 = 0.00497166 loss)
I1006 22:33:26.493743  3817 sgd_solver.cpp:105] Iteration 75100, lr = 0.01
I1006 22:33:43.908668  3817 solver.cpp:218] Iteration 75200 (5.74293 iter/s, 17.4127s/100 iters), loss = 0.00593198
I1006 22:33:43.908756  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00593208 (* 1 = 0.00593208 loss)
I1006 22:33:43.908773  3817 sgd_solver.cpp:105] Iteration 75200, lr = 0.01
I1006 22:34:00.978015  3817 solver.cpp:218] Iteration 75300 (5.85921 iter/s, 17.0671s/100 iters), loss = 0.0021043
I1006 22:34:00.978058  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0021044 (* 1 = 0.0021044 loss)
I1006 22:34:00.978065  3817 sgd_solver.cpp:105] Iteration 75300, lr = 0.01
I1006 22:34:18.059221  3817 solver.cpp:218] Iteration 75400 (5.85489 iter/s, 17.0797s/100 iters), loss = 0.0054915
I1006 22:34:18.059340  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0054916 (* 1 = 0.0054916 loss)
I1006 22:34:18.059357  3817 sgd_solver.cpp:105] Iteration 75400, lr = 0.01
I1006 22:34:34.306273  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:34:34.987538  3817 solver.cpp:330] Iteration 75500, Testing net (#0)
I1006 22:34:38.510207  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:34:38.633640  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9153
I1006 22:34:38.633667  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.363581 (* 1 = 0.363581 loss)
I1006 22:34:38.762315  3817 solver.cpp:218] Iteration 75500 (4.83054 iter/s, 20.7016s/100 iters), loss = 0.000759663
I1006 22:34:38.762353  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000759766 (* 1 = 0.000759766 loss)
I1006 22:34:38.762359  3817 sgd_solver.cpp:105] Iteration 75500, lr = 0.01
I1006 22:34:55.835011  3817 solver.cpp:218] Iteration 75600 (5.85734 iter/s, 17.0726s/100 iters), loss = 0.00197623
I1006 22:34:55.835086  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00197634 (* 1 = 0.00197634 loss)
I1006 22:34:55.835093  3817 sgd_solver.cpp:105] Iteration 75600, lr = 0.01
I1006 22:35:13.344482  3817 solver.cpp:218] Iteration 75700 (5.71193 iter/s, 17.5072s/100 iters), loss = 0.00240528
I1006 22:35:13.344516  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00240539 (* 1 = 0.00240539 loss)
I1006 22:35:13.344532  3817 sgd_solver.cpp:105] Iteration 75700, lr = 0.01
I1006 22:35:30.432989  3817 solver.cpp:218] Iteration 75800 (5.85265 iter/s, 17.0863s/100 iters), loss = 0.0101893
I1006 22:35:30.433091  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0101894 (* 1 = 0.0101894 loss)
I1006 22:35:30.433110  3817 sgd_solver.cpp:105] Iteration 75800, lr = 0.01
I1006 22:35:47.507570  3817 solver.cpp:218] Iteration 75900 (5.8573 iter/s, 17.0727s/100 iters), loss = 0.000840189
I1006 22:35:47.507611  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0008403 (* 1 = 0.0008403 loss)
I1006 22:35:47.507619  3817 sgd_solver.cpp:105] Iteration 75900, lr = 0.01
I1006 22:36:03.741657  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:36:04.424123  3817 solver.cpp:330] Iteration 76000, Testing net (#0)
I1006 22:36:07.939927  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:36:08.059623  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9166
I1006 22:36:08.059648  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.353961 (* 1 = 0.353961 loss)
I1006 22:36:08.207553  3817 solver.cpp:218] Iteration 76000 (4.83123 iter/s, 20.6987s/100 iters), loss = 0.000678937
I1006 22:36:08.207594  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000679052 (* 1 = 0.000679052 loss)
I1006 22:36:08.207600  3817 sgd_solver.cpp:105] Iteration 76000, lr = 0.01
I1006 22:36:25.277122  3817 solver.cpp:218] Iteration 76100 (5.85842 iter/s, 17.0695s/100 iters), loss = 0.0110256
I1006 22:36:25.277155  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0110257 (* 1 = 0.0110257 loss)
I1006 22:36:25.277165  3817 sgd_solver.cpp:105] Iteration 76100, lr = 0.01
I1006 22:36:42.706895  3817 solver.cpp:218] Iteration 76200 (5.73805 iter/s, 17.4275s/100 iters), loss = 0.00182073
I1006 22:36:42.706987  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00182084 (* 1 = 0.00182084 loss)
I1006 22:36:42.707006  3817 sgd_solver.cpp:105] Iteration 76200, lr = 0.01
I1006 22:36:59.797199  3817 solver.cpp:218] Iteration 76300 (5.85202 iter/s, 17.0881s/100 iters), loss = 0.00713639
I1006 22:36:59.797230  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00713651 (* 1 = 0.00713651 loss)
I1006 22:36:59.797247  3817 sgd_solver.cpp:105] Iteration 76300, lr = 0.01
I1006 22:37:16.870268  3817 solver.cpp:218] Iteration 76400 (5.85762 iter/s, 17.0718s/100 iters), loss = 0.000774489
I1006 22:37:16.870363  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000774605 (* 1 = 0.000774605 loss)
I1006 22:37:16.870381  3817 sgd_solver.cpp:105] Iteration 76400, lr = 0.01
I1006 22:37:33.109730  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:37:33.792965  3817 solver.cpp:330] Iteration 76500, Testing net (#0)
I1006 22:37:37.321288  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:37:37.459632  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9164
I1006 22:37:37.459661  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.348708 (* 1 = 0.348708 loss)
I1006 22:37:37.572401  3817 solver.cpp:218] Iteration 76500 (4.83093 iter/s, 20.6999s/100 iters), loss = 0.00268507
I1006 22:37:37.572441  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00268519 (* 1 = 0.00268519 loss)
I1006 22:37:37.572448  3817 sgd_solver.cpp:105] Iteration 76500, lr = 0.01
I1006 22:37:54.643666  3817 solver.cpp:218] Iteration 76600 (5.85784 iter/s, 17.0711s/100 iters), loss = 0.00656648
I1006 22:37:54.643748  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00656659 (* 1 = 0.00656659 loss)
I1006 22:37:54.643765  3817 sgd_solver.cpp:105] Iteration 76600, lr = 0.01
I1006 22:38:12.072816  3817 solver.cpp:218] Iteration 76700 (5.73824 iter/s, 17.427s/100 iters), loss = 0.0014124
I1006 22:38:12.072859  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00141251 (* 1 = 0.00141251 loss)
I1006 22:38:12.072865  3817 sgd_solver.cpp:105] Iteration 76700, lr = 0.01
I1006 22:38:29.155485  3817 solver.cpp:218] Iteration 76800 (5.85392 iter/s, 17.0826s/100 iters), loss = 0.0023983
I1006 22:38:29.155609  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00239841 (* 1 = 0.00239841 loss)
I1006 22:38:29.155628  3817 sgd_solver.cpp:105] Iteration 76800, lr = 0.01
I1006 22:38:46.231726  3817 solver.cpp:218] Iteration 76900 (5.8567 iter/s, 17.0745s/100 iters), loss = 0.00515522
I1006 22:38:46.231771  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00515533 (* 1 = 0.00515533 loss)
I1006 22:38:46.231779  3817 sgd_solver.cpp:105] Iteration 76900, lr = 0.01
I1006 22:39:02.471582  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:39:03.155079  3817 solver.cpp:330] Iteration 77000, Testing net (#0)
I1006 22:39:06.685772  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:39:06.809291  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9157
I1006 22:39:06.809327  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.357258 (* 1 = 0.357258 loss)
I1006 22:39:06.938022  3817 solver.cpp:218] Iteration 77000 (4.8298 iter/s, 20.7048s/100 iters), loss = 0.00323011
I1006 22:39:06.938066  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00323023 (* 1 = 0.00323023 loss)
I1006 22:39:06.938073  3817 sgd_solver.cpp:105] Iteration 77000, lr = 0.01
I1006 22:39:24.018398  3817 solver.cpp:218] Iteration 77100 (5.85471 iter/s, 17.0803s/100 iters), loss = 0.00417511
I1006 22:39:24.018441  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00417523 (* 1 = 0.00417523 loss)
I1006 22:39:24.018447  3817 sgd_solver.cpp:105] Iteration 77100, lr = 0.01
I1006 22:39:41.446939  3817 solver.cpp:218] Iteration 77200 (5.73826 iter/s, 17.4269s/100 iters), loss = 0.00438527
I1006 22:39:41.447052  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00438538 (* 1 = 0.00438538 loss)
I1006 22:39:41.447059  3817 sgd_solver.cpp:105] Iteration 77200, lr = 0.01
I1006 22:39:58.531713  3817 solver.cpp:218] Iteration 77300 (5.85393 iter/s, 17.0825s/100 iters), loss = 0.00116759
I1006 22:39:58.531754  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0011677 (* 1 = 0.0011677 loss)
I1006 22:39:58.531759  3817 sgd_solver.cpp:105] Iteration 77300, lr = 0.01
I1006 22:40:15.606725  3817 solver.cpp:218] Iteration 77400 (5.85728 iter/s, 17.0728s/100 iters), loss = 0.00117222
I1006 22:40:15.606812  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00117234 (* 1 = 0.00117234 loss)
I1006 22:40:15.606829  3817 sgd_solver.cpp:105] Iteration 77400, lr = 0.01
I1006 22:40:31.844377  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:40:32.524897  3817 solver.cpp:330] Iteration 77500, Testing net (#0)
I1006 22:40:36.049898  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:40:36.204613  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9153
I1006 22:40:36.204650  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.362904 (* 1 = 0.362904 loss)
I1006 22:40:36.301498  3817 solver.cpp:218] Iteration 77500 (4.83266 iter/s, 20.6925s/100 iters), loss = 0.00455601
I1006 22:40:36.301538  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00455613 (* 1 = 0.00455613 loss)
I1006 22:40:36.301545  3817 sgd_solver.cpp:105] Iteration 77500, lr = 0.01
I1006 22:40:53.361572  3817 solver.cpp:218] Iteration 77600 (5.86168 iter/s, 17.06s/100 iters), loss = 0.00517043
I1006 22:40:53.361641  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00517055 (* 1 = 0.00517055 loss)
I1006 22:40:53.361659  3817 sgd_solver.cpp:105] Iteration 77600, lr = 0.01
I1006 22:41:10.792090  3817 solver.cpp:218] Iteration 77700 (5.73779 iter/s, 17.4283s/100 iters), loss = 0.00299471
I1006 22:41:10.792131  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00299483 (* 1 = 0.00299483 loss)
I1006 22:41:10.792138  3817 sgd_solver.cpp:105] Iteration 77700, lr = 0.01
I1006 22:41:27.841354  3817 solver.cpp:218] Iteration 77800 (5.86598 iter/s, 17.0475s/100 iters), loss = 0.00196429
I1006 22:41:27.841459  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00196441 (* 1 = 0.00196441 loss)
I1006 22:41:27.841466  3817 sgd_solver.cpp:105] Iteration 77800, lr = 0.01
I1006 22:41:44.920375  3817 solver.cpp:218] Iteration 77900 (5.85589 iter/s, 17.0768s/100 iters), loss = 0.00167803
I1006 22:41:44.920419  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00167815 (* 1 = 0.00167815 loss)
I1006 22:41:44.920426  3817 sgd_solver.cpp:105] Iteration 77900, lr = 0.01
I1006 22:42:01.151754  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:42:01.834688  3817 solver.cpp:330] Iteration 78000, Testing net (#0)
I1006 22:42:05.362740  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:42:05.500995  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.914
I1006 22:42:05.501032  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.365435 (* 1 = 0.365435 loss)
I1006 22:42:05.614490  3817 solver.cpp:218] Iteration 78000 (4.83267 iter/s, 20.6925s/100 iters), loss = 0.00559237
I1006 22:42:05.614529  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00559249 (* 1 = 0.00559249 loss)
I1006 22:42:05.614537  3817 sgd_solver.cpp:105] Iteration 78000, lr = 0.01
I1006 22:42:22.689456  3817 solver.cpp:218] Iteration 78100 (5.85657 iter/s, 17.0749s/100 iters), loss = 0.00598262
I1006 22:42:22.689497  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00598274 (* 1 = 0.00598274 loss)
I1006 22:42:22.689504  3817 sgd_solver.cpp:105] Iteration 78100, lr = 0.01
I1006 22:42:40.118324  3817 solver.cpp:218] Iteration 78200 (5.73813 iter/s, 17.4273s/100 iters), loss = 0.00107657
I1006 22:42:40.118427  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00107669 (* 1 = 0.00107669 loss)
I1006 22:42:40.118435  3817 sgd_solver.cpp:105] Iteration 78200, lr = 0.01
I1006 22:42:57.211303  3817 solver.cpp:218] Iteration 78300 (5.85094 iter/s, 17.0913s/100 iters), loss = 0.00349864
I1006 22:42:57.211335  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00349875 (* 1 = 0.00349875 loss)
I1006 22:42:57.211354  3817 sgd_solver.cpp:105] Iteration 78300, lr = 0.01
I1006 22:43:14.290853  3817 solver.cpp:218] Iteration 78400 (5.85563 iter/s, 17.0776s/100 iters), loss = 0.00189586
I1006 22:43:14.290971  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00189597 (* 1 = 0.00189597 loss)
I1006 22:43:14.290978  3817 sgd_solver.cpp:105] Iteration 78400, lr = 0.01
I1006 22:43:30.536660  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:43:31.219310  3817 solver.cpp:330] Iteration 78500, Testing net (#0)
I1006 22:43:34.744853  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:43:34.902103  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9156
I1006 22:43:34.902140  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.354816 (* 1 = 0.354816 loss)
I1006 22:43:34.996307  3817 solver.cpp:218] Iteration 78500 (4.83016 iter/s, 20.7032s/100 iters), loss = 0.00123444
I1006 22:43:34.996348  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00123455 (* 1 = 0.00123455 loss)
I1006 22:43:34.996356  3817 sgd_solver.cpp:105] Iteration 78500, lr = 0.01
I1006 22:43:52.072211  3817 solver.cpp:218] Iteration 78600 (5.85624 iter/s, 17.0758s/100 iters), loss = 0.00134738
I1006 22:43:52.072343  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00134748 (* 1 = 0.00134748 loss)
I1006 22:43:52.072351  3817 sgd_solver.cpp:105] Iteration 78600, lr = 0.01
I1006 22:44:09.506003  3817 solver.cpp:218] Iteration 78700 (5.73649 iter/s, 17.4323s/100 iters), loss = 0.00814893
I1006 22:44:09.506052  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00814903 (* 1 = 0.00814903 loss)
I1006 22:44:09.506060  3817 sgd_solver.cpp:105] Iteration 78700, lr = 0.01
I1006 22:44:26.586339  3817 solver.cpp:218] Iteration 78800 (5.85544 iter/s, 17.0781s/100 iters), loss = 0.00204839
I1006 22:44:26.586453  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0020485 (* 1 = 0.0020485 loss)
I1006 22:44:26.586460  3817 sgd_solver.cpp:105] Iteration 78800, lr = 0.01
I1006 22:44:43.648036  3817 solver.cpp:218] Iteration 78900 (5.86185 iter/s, 17.0595s/100 iters), loss = 0.00673469
I1006 22:44:43.648071  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0067348 (* 1 = 0.0067348 loss)
I1006 22:44:43.648088  3817 sgd_solver.cpp:105] Iteration 78900, lr = 0.01
I1006 22:44:59.870787  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:45:00.556413  3817 solver.cpp:330] Iteration 79000, Testing net (#0)
I1006 22:45:04.081346  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:45:04.249225  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9116
I1006 22:45:04.249251  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.406952 (* 1 = 0.406952 loss)
I1006 22:45:04.340103  3817 solver.cpp:218] Iteration 79000 (4.83329 iter/s, 20.6898s/100 iters), loss = 0.0019494
I1006 22:45:04.340132  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0019495 (* 1 = 0.0019495 loss)
I1006 22:45:04.340139  3817 sgd_solver.cpp:105] Iteration 79000, lr = 0.01
I1006 22:45:21.404439  3817 solver.cpp:218] Iteration 79100 (5.86094 iter/s, 17.0621s/100 iters), loss = 0.00474261
I1006 22:45:21.404480  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00474271 (* 1 = 0.00474271 loss)
I1006 22:45:21.404487  3817 sgd_solver.cpp:105] Iteration 79100, lr = 0.01
I1006 22:45:38.835535  3817 solver.cpp:218] Iteration 79200 (5.73691 iter/s, 17.431s/100 iters), loss = 0.00277353
I1006 22:45:38.835654  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00277363 (* 1 = 0.00277363 loss)
I1006 22:45:38.835661  3817 sgd_solver.cpp:105] Iteration 79200, lr = 0.01
I1006 22:45:55.897982  3817 solver.cpp:218] Iteration 79300 (5.86154 iter/s, 17.0604s/100 iters), loss = 0.00122734
I1006 22:45:55.898023  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00122744 (* 1 = 0.00122744 loss)
I1006 22:45:55.898030  3817 sgd_solver.cpp:105] Iteration 79300, lr = 0.01
I1006 22:46:12.975585  3817 solver.cpp:218] Iteration 79400 (5.85638 iter/s, 17.0754s/100 iters), loss = 0.00610919
I1006 22:46:12.975675  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00610929 (* 1 = 0.00610929 loss)
I1006 22:46:12.975693  3817 sgd_solver.cpp:105] Iteration 79400, lr = 0.01
I1006 22:46:29.199465  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:46:29.881371  3817 solver.cpp:330] Iteration 79500, Testing net (#0)
I1006 22:46:33.411082  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:46:33.577785  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9117
I1006 22:46:33.577821  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.374838 (* 1 = 0.374838 loss)
I1006 22:46:33.668951  3817 solver.cpp:218] Iteration 79500 (4.8325 iter/s, 20.6932s/100 iters), loss = 0.00831054
I1006 22:46:33.668983  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00831064 (* 1 = 0.00831064 loss)
I1006 22:46:33.668990  3817 sgd_solver.cpp:105] Iteration 79500, lr = 0.01
I1006 22:46:50.723122  3817 solver.cpp:218] Iteration 79600 (5.86444 iter/s, 17.0519s/100 iters), loss = 0.00511524
I1006 22:46:50.723212  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00511534 (* 1 = 0.00511534 loss)
I1006 22:46:50.723229  3817 sgd_solver.cpp:105] Iteration 79600, lr = 0.01
I1006 22:47:08.151819  3817 solver.cpp:218] Iteration 79700 (5.7384 iter/s, 17.4264s/100 iters), loss = 0.00294804
I1006 22:47:08.151850  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00294815 (* 1 = 0.00294815 loss)
I1006 22:47:08.151856  3817 sgd_solver.cpp:105] Iteration 79700, lr = 0.01
I1006 22:47:25.236467  3817 solver.cpp:218] Iteration 79800 (5.85398 iter/s, 17.0824s/100 iters), loss = 0.0144344
I1006 22:47:25.236559  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0144345 (* 1 = 0.0144345 loss)
I1006 22:47:25.236577  3817 sgd_solver.cpp:105] Iteration 79800, lr = 0.01
I1006 22:47:42.309705  3817 solver.cpp:218] Iteration 79900 (5.85789 iter/s, 17.071s/100 iters), loss = 0.00319232
I1006 22:47:42.309747  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00319243 (* 1 = 0.00319243 loss)
I1006 22:47:42.309754  3817 sgd_solver.cpp:105] Iteration 79900, lr = 0.01
I1006 22:47:58.541102  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:47:59.223366  3817 solver.cpp:330] Iteration 80000, Testing net (#0)
I1006 22:48:02.751271  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:48:02.887825  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9157
I1006 22:48:02.887851  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.361114 (* 1 = 0.361114 loss)
I1006 22:48:03.002956  3817 solver.cpp:218] Iteration 80000 (4.83302 iter/s, 20.691s/100 iters), loss = 0.00291639
I1006 22:48:03.002988  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00291649 (* 1 = 0.00291649 loss)
I1006 22:48:03.003006  3817 sgd_solver.cpp:46] MultiStep Status: Iteration 80000, step = 2
I1006 22:48:03.003011  3817 sgd_solver.cpp:105] Iteration 80000, lr = 0.001
I1006 22:48:20.078428  3817 solver.cpp:218] Iteration 80100 (5.85639 iter/s, 17.0754s/100 iters), loss = 0.00304935
I1006 22:48:20.078462  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00304945 (* 1 = 0.00304945 loss)
I1006 22:48:20.078481  3817 sgd_solver.cpp:105] Iteration 80100, lr = 0.001
I1006 22:48:37.506842  3817 solver.cpp:218] Iteration 80200 (5.73834 iter/s, 17.4266s/100 iters), loss = 0.000707832
I1006 22:48:37.506979  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000707929 (* 1 = 0.000707929 loss)
I1006 22:48:37.506988  3817 sgd_solver.cpp:105] Iteration 80200, lr = 0.001
I1006 22:48:54.588197  3817 solver.cpp:218] Iteration 80300 (5.8544 iter/s, 17.0812s/100 iters), loss = 0.00105466
I1006 22:48:54.588229  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00105475 (* 1 = 0.00105475 loss)
I1006 22:48:54.588245  3817 sgd_solver.cpp:105] Iteration 80300, lr = 0.001
I1006 22:49:11.653640  3817 solver.cpp:218] Iteration 80400 (5.85983 iter/s, 17.0653s/100 iters), loss = 0.00187608
I1006 22:49:11.653698  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00187618 (* 1 = 0.00187618 loss)
I1006 22:49:11.653717  3817 sgd_solver.cpp:105] Iteration 80400, lr = 0.001
I1006 22:49:27.895880  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:49:28.579588  3817 solver.cpp:330] Iteration 80500, Testing net (#0)
I1006 22:49:32.106667  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:49:32.266263  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9205
I1006 22:49:32.266299  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.328841 (* 1 = 0.328841 loss)
I1006 22:49:32.358852  3817 solver.cpp:218] Iteration 80500 (4.83023 iter/s, 20.703s/100 iters), loss = 0.00106724
I1006 22:49:32.358891  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00106733 (* 1 = 0.00106733 loss)
I1006 22:49:32.358896  3817 sgd_solver.cpp:105] Iteration 80500, lr = 0.001
I1006 22:49:49.422375  3817 solver.cpp:218] Iteration 80600 (5.86049 iter/s, 17.0634s/100 iters), loss = 0.00181795
I1006 22:49:49.422483  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00181804 (* 1 = 0.00181804 loss)
I1006 22:49:49.422502  3817 sgd_solver.cpp:105] Iteration 80600, lr = 0.001
I1006 22:50:06.897949  3817 solver.cpp:218] Iteration 80700 (5.72301 iter/s, 17.4733s/100 iters), loss = 0.00953241
I1006 22:50:06.897992  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0095325 (* 1 = 0.0095325 loss)
I1006 22:50:06.898000  3817 sgd_solver.cpp:105] Iteration 80700, lr = 0.001
I1006 22:50:24.001968  3817 solver.cpp:218] Iteration 80800 (5.84734 iter/s, 17.1018s/100 iters), loss = 0.00150726
I1006 22:50:24.002054  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00150735 (* 1 = 0.00150735 loss)
I1006 22:50:24.002064  3817 sgd_solver.cpp:105] Iteration 80800, lr = 0.001
I1006 22:50:41.079694  3817 solver.cpp:218] Iteration 80900 (5.85634 iter/s, 17.0755s/100 iters), loss = 0.00572968
I1006 22:50:41.079735  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00572977 (* 1 = 0.00572977 loss)
I1006 22:50:41.079741  3817 sgd_solver.cpp:105] Iteration 80900, lr = 0.001
I1006 22:50:57.306215  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:50:57.988411  3817 solver.cpp:330] Iteration 81000, Testing net (#0)
I1006 22:51:01.516464  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:51:01.657342  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9225
I1006 22:51:01.657376  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.326443 (* 1 = 0.326443 loss)
I1006 22:51:01.768334  3817 solver.cpp:218] Iteration 81000 (4.83409 iter/s, 20.6864s/100 iters), loss = 0.00128414
I1006 22:51:01.768366  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00128423 (* 1 = 0.00128423 loss)
I1006 22:51:01.768384  3817 sgd_solver.cpp:105] Iteration 81000, lr = 0.001
I1006 22:51:18.829574  3817 solver.cpp:218] Iteration 81100 (5.86128 iter/s, 17.0611s/100 iters), loss = 0.000988271
I1006 22:51:18.829614  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000988359 (* 1 = 0.000988359 loss)
I1006 22:51:18.829622  3817 sgd_solver.cpp:105] Iteration 81100, lr = 0.001
I1006 22:51:36.260607  3817 solver.cpp:218] Iteration 81200 (5.73745 iter/s, 17.4294s/100 iters), loss = 0.00204521
I1006 22:51:36.260713  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0020453 (* 1 = 0.0020453 loss)
I1006 22:51:36.260731  3817 sgd_solver.cpp:105] Iteration 81200, lr = 0.001
I1006 22:51:53.349622  3817 solver.cpp:218] Iteration 81300 (5.85177 iter/s, 17.0889s/100 iters), loss = 0.00315479
I1006 22:51:53.349669  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00315488 (* 1 = 0.00315488 loss)
I1006 22:51:53.349676  3817 sgd_solver.cpp:105] Iteration 81300, lr = 0.001
I1006 22:52:10.420094  3817 solver.cpp:218] Iteration 81400 (5.85882 iter/s, 17.0683s/100 iters), loss = 0.00193129
I1006 22:52:10.420218  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00193138 (* 1 = 0.00193138 loss)
I1006 22:52:10.420231  3817 sgd_solver.cpp:105] Iteration 81400, lr = 0.001
I1006 22:52:26.659819  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:52:27.343003  3817 solver.cpp:330] Iteration 81500, Testing net (#0)
I1006 22:52:30.869823  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:52:31.020426  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9241
I1006 22:52:31.020463  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.324941 (* 1 = 0.324941 loss)
I1006 22:52:31.120404  3817 solver.cpp:218] Iteration 81500 (4.83136 iter/s, 20.6981s/100 iters), loss = 0.00237654
I1006 22:52:31.120441  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00237663 (* 1 = 0.00237663 loss)
I1006 22:52:31.120448  3817 sgd_solver.cpp:105] Iteration 81500, lr = 0.001
I1006 22:52:48.193398  3817 solver.cpp:218] Iteration 81600 (5.85724 iter/s, 17.0729s/100 iters), loss = 0.0041098
I1006 22:52:48.193503  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00410989 (* 1 = 0.00410989 loss)
I1006 22:52:48.193512  3817 sgd_solver.cpp:105] Iteration 81600, lr = 0.001
I1006 22:53:05.640743  3817 solver.cpp:218] Iteration 81700 (5.73225 iter/s, 17.4451s/100 iters), loss = 0.00401542
I1006 22:53:05.640787  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00401551 (* 1 = 0.00401551 loss)
I1006 22:53:05.640794  3817 sgd_solver.cpp:105] Iteration 81700, lr = 0.001
I1006 22:53:22.708683  3817 solver.cpp:218] Iteration 81800 (5.85898 iter/s, 17.0678s/100 iters), loss = 0.00212513
I1006 22:53:22.708780  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00212523 (* 1 = 0.00212523 loss)
I1006 22:53:22.708801  3817 sgd_solver.cpp:105] Iteration 81800, lr = 0.001
I1006 22:53:39.790132  3817 solver.cpp:218] Iteration 81900 (5.85506 iter/s, 17.0792s/100 iters), loss = 0.0108863
I1006 22:53:39.790166  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0108864 (* 1 = 0.0108864 loss)
I1006 22:53:39.790182  3817 sgd_solver.cpp:105] Iteration 81900, lr = 0.001
I1006 22:53:56.039103  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:53:56.718340  3817 solver.cpp:330] Iteration 82000, Testing net (#0)
I1006 22:54:00.217761  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:54:00.344391  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9251
I1006 22:54:00.344420  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.32671 (* 1 = 0.32671 loss)
I1006 22:54:00.497330  3817 solver.cpp:218] Iteration 82000 (4.82967 iter/s, 20.7053s/100 iters), loss = 0.00168538
I1006 22:54:00.497373  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00168547 (* 1 = 0.00168547 loss)
I1006 22:54:00.497380  3817 sgd_solver.cpp:105] Iteration 82000, lr = 0.001
I1006 22:54:17.590919  3817 solver.cpp:218] Iteration 82100 (5.85019 iter/s, 17.0935s/100 iters), loss = 0.00152594
I1006 22:54:17.590963  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00152603 (* 1 = 0.00152603 loss)
I1006 22:54:17.590970  3817 sgd_solver.cpp:105] Iteration 82100, lr = 0.001
I1006 22:54:34.988257  3817 solver.cpp:218] Iteration 82200 (5.74876 iter/s, 17.3951s/100 iters), loss = 0.00756367
I1006 22:54:34.988353  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00756377 (* 1 = 0.00756377 loss)
I1006 22:54:34.988363  3817 sgd_solver.cpp:105] Iteration 82200, lr = 0.001
I1006 22:54:52.091174  3817 solver.cpp:218] Iteration 82300 (5.84701 iter/s, 17.1028s/100 iters), loss = 0.00163021
I1006 22:54:52.091207  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00163031 (* 1 = 0.00163031 loss)
I1006 22:54:52.091217  3817 sgd_solver.cpp:105] Iteration 82300, lr = 0.001
I1006 22:55:09.166939  3817 solver.cpp:218] Iteration 82400 (5.85701 iter/s, 17.0735s/100 iters), loss = 0.00155875
I1006 22:55:09.167048  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00155885 (* 1 = 0.00155885 loss)
I1006 22:55:09.167057  3817 sgd_solver.cpp:105] Iteration 82400, lr = 0.001
I1006 22:55:25.406242  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:55:26.087115  3817 solver.cpp:330] Iteration 82500, Testing net (#0)
I1006 22:55:29.613790  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:55:29.752406  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9253
I1006 22:55:29.752445  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.328368 (* 1 = 0.328368 loss)
I1006 22:55:29.865274  3817 solver.cpp:218] Iteration 82500 (4.83182 iter/s, 20.6961s/100 iters), loss = 0.00109485
I1006 22:55:29.865314  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00109495 (* 1 = 0.00109495 loss)
I1006 22:55:29.865321  3817 sgd_solver.cpp:105] Iteration 82500, lr = 0.001
I1006 22:55:46.940378  3817 solver.cpp:218] Iteration 82600 (5.85652 iter/s, 17.075s/100 iters), loss = 0.0190111
I1006 22:55:46.940485  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0190112 (* 1 = 0.0190112 loss)
I1006 22:55:46.940492  3817 sgd_solver.cpp:105] Iteration 82600, lr = 0.001
I1006 22:56:04.296679  3817 solver.cpp:218] Iteration 82700 (5.76233 iter/s, 17.3541s/100 iters), loss = 0.00205494
I1006 22:56:04.296723  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00205504 (* 1 = 0.00205504 loss)
I1006 22:56:04.296730  3817 sgd_solver.cpp:105] Iteration 82700, lr = 0.001
I1006 22:56:21.452464  3817 solver.cpp:218] Iteration 82800 (5.82897 iter/s, 17.1557s/100 iters), loss = 0.00198571
I1006 22:56:21.452575  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00198581 (* 1 = 0.00198581 loss)
I1006 22:56:21.452596  3817 sgd_solver.cpp:105] Iteration 82800, lr = 0.001
I1006 22:56:38.526243  3817 solver.cpp:218] Iteration 82900 (5.8577 iter/s, 17.0716s/100 iters), loss = 0.00102965
I1006 22:56:38.526278  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00102975 (* 1 = 0.00102975 loss)
I1006 22:56:38.526286  3817 sgd_solver.cpp:105] Iteration 82900, lr = 0.001
I1006 22:56:54.752053  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:56:55.433277  3817 solver.cpp:330] Iteration 83000, Testing net (#0)
I1006 22:56:58.951318  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:56:59.070199  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9242
I1006 22:56:59.070222  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.328266 (* 1 = 0.328266 loss)
I1006 22:56:59.217490  3817 solver.cpp:218] Iteration 83000 (4.83349 iter/s, 20.689s/100 iters), loss = 0.000917622
I1006 22:56:59.217525  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000917721 (* 1 = 0.000917721 loss)
I1006 22:56:59.217540  3817 sgd_solver.cpp:105] Iteration 83000, lr = 0.001
I1006 22:57:16.273922  3817 solver.cpp:218] Iteration 83100 (5.86293 iter/s, 17.0563s/100 iters), loss = 0.00642136
I1006 22:57:16.273955  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00642146 (* 1 = 0.00642146 loss)
I1006 22:57:16.273972  3817 sgd_solver.cpp:105] Iteration 83100, lr = 0.001
I1006 22:57:33.560426  3817 solver.cpp:218] Iteration 83200 (5.78562 iter/s, 17.2842s/100 iters), loss = 0.00223773
I1006 22:57:33.560501  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00223783 (* 1 = 0.00223783 loss)
I1006 22:57:33.560520  3817 sgd_solver.cpp:105] Iteration 83200, lr = 0.001
I1006 22:57:50.748610  3817 solver.cpp:218] Iteration 83300 (5.81837 iter/s, 17.1869s/100 iters), loss = 0.000672262
I1006 22:57:50.748641  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000672362 (* 1 = 0.000672362 loss)
I1006 22:57:50.748646  3817 sgd_solver.cpp:105] Iteration 83300, lr = 0.001
I1006 22:58:07.809204  3817 solver.cpp:218] Iteration 83400 (5.86223 iter/s, 17.0583s/100 iters), loss = 0.00186755
I1006 22:58:07.809306  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00186765 (* 1 = 0.00186765 loss)
I1006 22:58:07.809324  3817 sgd_solver.cpp:105] Iteration 83400, lr = 0.001
I1006 22:58:24.032342  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:58:24.714069  3817 solver.cpp:330] Iteration 83500, Testing net (#0)
I1006 22:58:28.246043  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:58:28.371187  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9243
I1006 22:58:28.371214  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.327743 (* 1 = 0.327743 loss)
I1006 22:58:28.497220  3817 solver.cpp:218] Iteration 83500 (4.83423 iter/s, 20.6858s/100 iters), loss = 0.00147778
I1006 22:58:28.497257  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00147788 (* 1 = 0.00147788 loss)
I1006 22:58:28.497263  3817 sgd_solver.cpp:105] Iteration 83500, lr = 0.001
I1006 22:58:45.571348  3817 solver.cpp:218] Iteration 83600 (5.85685 iter/s, 17.074s/100 iters), loss = 0.00110013
I1006 22:58:45.571456  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00110023 (* 1 = 0.00110023 loss)
I1006 22:58:45.571475  3817 sgd_solver.cpp:105] Iteration 83600, lr = 0.001
I1006 22:59:02.836459  3817 solver.cpp:218] Iteration 83700 (5.79264 iter/s, 17.2633s/100 iters), loss = 0.0107158
I1006 22:59:02.836493  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0107159 (* 1 = 0.0107159 loss)
I1006 22:59:02.836511  3817 sgd_solver.cpp:105] Iteration 83700, lr = 0.001
I1006 22:59:20.090107  3817 solver.cpp:218] Iteration 83800 (5.79663 iter/s, 17.2514s/100 iters), loss = 0.00137254
I1006 22:59:20.090210  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00137264 (* 1 = 0.00137264 loss)
I1006 22:59:20.090219  3817 sgd_solver.cpp:105] Iteration 83800, lr = 0.001
I1006 22:59:37.182324  3817 solver.cpp:218] Iteration 83900 (5.85118 iter/s, 17.0906s/100 iters), loss = 0.00188584
I1006 22:59:37.182366  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00188594 (* 1 = 0.00188594 loss)
I1006 22:59:37.182373  3817 sgd_solver.cpp:105] Iteration 83900, lr = 0.001
I1006 22:59:53.413939  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:59:54.094797  3817 solver.cpp:330] Iteration 84000, Testing net (#0)
I1006 22:59:57.622764  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:59:57.790880  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9248
I1006 22:59:57.790922  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.327756 (* 1 = 0.327756 loss)
I1006 22:59:57.884790  3817 solver.cpp:218] Iteration 84000 (4.83037 iter/s, 20.7024s/100 iters), loss = 0.0093177
I1006 22:59:57.884841  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00931779 (* 1 = 0.00931779 loss)
I1006 22:59:57.884851  3817 sgd_solver.cpp:105] Iteration 84000, lr = 0.001
I1006 23:00:14.927886  3817 solver.cpp:218] Iteration 84100 (5.86823 iter/s, 17.0409s/100 iters), loss = 0.00250102
I1006 23:00:14.927929  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00250111 (* 1 = 0.00250111 loss)
I1006 23:00:14.927937  3817 sgd_solver.cpp:105] Iteration 84100, lr = 0.001
I1006 23:00:32.175640  3817 solver.cpp:218] Iteration 84200 (5.79861 iter/s, 17.2455s/100 iters), loss = 0.00526054
I1006 23:00:32.175722  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00526063 (* 1 = 0.00526063 loss)
I1006 23:00:32.175731  3817 sgd_solver.cpp:105] Iteration 84200, lr = 0.001
I1006 23:00:49.456084  3817 solver.cpp:218] Iteration 84300 (5.78694 iter/s, 17.2803s/100 iters), loss = 0.00102301
I1006 23:00:49.456125  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0010231 (* 1 = 0.0010231 loss)
I1006 23:00:49.456132  3817 sgd_solver.cpp:105] Iteration 84300, lr = 0.001
I1006 23:01:06.524770  3817 solver.cpp:218] Iteration 84400 (5.85944 iter/s, 17.0665s/100 iters), loss = 0.000438489
I1006 23:01:06.524863  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000438581 (* 1 = 0.000438581 loss)
I1006 23:01:06.524883  3817 sgd_solver.cpp:105] Iteration 84400, lr = 0.001
I1006 23:01:22.770277  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:01:23.452839  3817 solver.cpp:330] Iteration 84500, Testing net (#0)
I1006 23:01:26.980911  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:01:27.148315  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9245
I1006 23:01:27.148351  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.328947 (* 1 = 0.328947 loss)
I1006 23:01:27.239015  3817 solver.cpp:218] Iteration 84500 (4.82811 iter/s, 20.712s/100 iters), loss = 0.000466491
I1006 23:01:27.239056  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000466585 (* 1 = 0.000466585 loss)
I1006 23:01:27.239063  3817 sgd_solver.cpp:105] Iteration 84500, lr = 0.001
I1006 23:01:44.282387  3817 solver.cpp:218] Iteration 84600 (5.86817 iter/s, 17.0411s/100 iters), loss = 0.00240816
I1006 23:01:44.282477  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00240825 (* 1 = 0.00240825 loss)
I1006 23:01:44.282498  3817 sgd_solver.cpp:105] Iteration 84600, lr = 0.001
I1006 23:02:01.439533  3817 solver.cpp:218] Iteration 84700 (5.82852 iter/s, 17.157s/100 iters), loss = 0.00136751
I1006 23:02:01.439566  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0013676 (* 1 = 0.0013676 loss)
I1006 23:02:01.439576  3817 sgd_solver.cpp:105] Iteration 84700, lr = 0.001
I1006 23:02:18.755838  3817 solver.cpp:218] Iteration 84800 (5.77494 iter/s, 17.3162s/100 iters), loss = 0.00122292
I1006 23:02:18.755959  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00122301 (* 1 = 0.00122301 loss)
I1006 23:02:18.755980  3817 sgd_solver.cpp:105] Iteration 84800, lr = 0.001
I1006 23:02:35.843072  3817 solver.cpp:218] Iteration 84900 (5.85309 iter/s, 17.085s/100 iters), loss = 0.00230943
I1006 23:02:35.843116  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00230952 (* 1 = 0.00230952 loss)
I1006 23:02:35.843122  3817 sgd_solver.cpp:105] Iteration 84900, lr = 0.001
I1006 23:02:52.069154  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:02:52.750346  3817 solver.cpp:330] Iteration 85000, Testing net (#0)
I1006 23:02:56.272092  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:02:56.397888  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9241
I1006 23:02:56.397917  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.328822 (* 1 = 0.328822 loss)
I1006 23:02:56.525398  3817 solver.cpp:218] Iteration 85000 (4.83546 iter/s, 20.6805s/100 iters), loss = 0.00141894
I1006 23:02:56.525436  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00141903 (* 1 = 0.00141903 loss)
I1006 23:02:56.525442  3817 sgd_solver.cpp:105] Iteration 85000, lr = 0.001
I1006 23:03:13.582882  3817 solver.cpp:218] Iteration 85100 (5.86257 iter/s, 17.0574s/100 iters), loss = 0.00359427
I1006 23:03:13.582924  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00359436 (* 1 = 0.00359436 loss)
I1006 23:03:13.582931  3817 sgd_solver.cpp:105] Iteration 85100, lr = 0.001
I1006 23:03:30.732553  3817 solver.cpp:218] Iteration 85200 (5.83177 iter/s, 17.1475s/100 iters), loss = 0.00107591
I1006 23:03:30.732625  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.001076 (* 1 = 0.001076 loss)
I1006 23:03:30.732638  3817 sgd_solver.cpp:105] Iteration 85200, lr = 0.001
I1006 23:03:48.080546  3817 solver.cpp:218] Iteration 85300 (5.7644 iter/s, 17.3479s/100 iters), loss = 0.00114141
I1006 23:03:48.080588  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0011415 (* 1 = 0.0011415 loss)
I1006 23:03:48.080595  3817 sgd_solver.cpp:105] Iteration 85300, lr = 0.001
I1006 23:04:05.162084  3817 solver.cpp:218] Iteration 85400 (5.85504 iter/s, 17.0793s/100 iters), loss = 0.00179021
I1006 23:04:05.162147  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0017903 (* 1 = 0.0017903 loss)
I1006 23:04:05.162158  3817 sgd_solver.cpp:105] Iteration 85400, lr = 0.001
I1006 23:04:21.401491  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:04:22.085886  3817 solver.cpp:330] Iteration 85500, Testing net (#0)
I1006 23:04:25.612808  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:04:25.761176  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.924
I1006 23:04:25.761206  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.327776 (* 1 = 0.327776 loss)
I1006 23:04:25.864128  3817 solver.cpp:218] Iteration 85500 (4.83097 iter/s, 20.6998s/100 iters), loss = 0.00149783
I1006 23:04:25.864166  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00149792 (* 1 = 0.00149792 loss)
I1006 23:04:25.864173  3817 sgd_solver.cpp:105] Iteration 85500, lr = 0.001
I1006 23:04:42.937278  3817 solver.cpp:218] Iteration 85600 (5.85719 iter/s, 17.073s/100 iters), loss = 0.00285066
I1006 23:04:42.937330  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00285075 (* 1 = 0.00285075 loss)
I1006 23:04:42.937347  3817 sgd_solver.cpp:105] Iteration 85600, lr = 0.001
I1006 23:05:00.039904  3817 solver.cpp:218] Iteration 85700 (5.84781 iter/s, 17.1004s/100 iters), loss = 0.000736763
I1006 23:05:00.039937  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000736852 (* 1 = 0.000736852 loss)
I1006 23:05:00.039944  3817 sgd_solver.cpp:105] Iteration 85700, lr = 0.001
I1006 23:05:17.520958  3817 solver.cpp:218] Iteration 85800 (5.72051 iter/s, 17.4809s/100 iters), loss = 0.00165762
I1006 23:05:17.521081  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0016577 (* 1 = 0.0016577 loss)
I1006 23:05:17.521090  3817 sgd_solver.cpp:105] Iteration 85800, lr = 0.001
I1006 23:05:34.597836  3817 solver.cpp:218] Iteration 85900 (5.85648 iter/s, 17.0751s/100 iters), loss = 0.00538006
I1006 23:05:34.597868  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00538015 (* 1 = 0.00538015 loss)
I1006 23:05:34.597874  3817 sgd_solver.cpp:105] Iteration 85900, lr = 0.001
I1006 23:05:50.818104  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:05:51.500905  3817 solver.cpp:330] Iteration 86000, Testing net (#0)
I1006 23:05:55.026798  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:05:55.164033  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9257
I1006 23:05:55.164060  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.326034 (* 1 = 0.326034 loss)
I1006 23:05:55.279522  3817 solver.cpp:218] Iteration 86000 (4.83544 iter/s, 20.6806s/100 iters), loss = 0.00132363
I1006 23:05:55.279549  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00132372 (* 1 = 0.00132372 loss)
I1006 23:05:55.279567  3817 sgd_solver.cpp:105] Iteration 86000, lr = 0.001
I1006 23:06:12.337852  3817 solver.cpp:218] Iteration 86100 (5.86228 iter/s, 17.0582s/100 iters), loss = 0.00164825
I1006 23:06:12.337883  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00164834 (* 1 = 0.00164834 loss)
I1006 23:06:12.337890  3817 sgd_solver.cpp:105] Iteration 86100, lr = 0.001
I1006 23:06:29.429716  3817 solver.cpp:218] Iteration 86200 (5.85149 iter/s, 17.0897s/100 iters), loss = 0.0013055
I1006 23:06:29.429790  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00130559 (* 1 = 0.00130559 loss)
I1006 23:06:29.429797  3817 sgd_solver.cpp:105] Iteration 86200, lr = 0.001
I1006 23:06:46.845736  3817 solver.cpp:218] Iteration 86300 (5.74189 iter/s, 17.4159s/100 iters), loss = 0.00103844
I1006 23:06:46.845769  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00103853 (* 1 = 0.00103853 loss)
I1006 23:06:46.845777  3817 sgd_solver.cpp:105] Iteration 86300, lr = 0.001
I1006 23:07:03.935072  3817 solver.cpp:218] Iteration 86400 (5.85227 iter/s, 17.0874s/100 iters), loss = 0.00170645
I1006 23:07:03.935184  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00170654 (* 1 = 0.00170654 loss)
I1006 23:07:03.935192  3817 sgd_solver.cpp:105] Iteration 86400, lr = 0.001
I1006 23:07:20.182504  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:07:20.864003  3817 solver.cpp:330] Iteration 86500, Testing net (#0)
I1006 23:07:24.373231  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:07:24.495896  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9252
I1006 23:07:24.495925  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.326314 (* 1 = 0.326314 loss)
I1006 23:07:24.644433  3817 solver.cpp:218] Iteration 86500 (4.82912 iter/s, 20.7077s/100 iters), loss = 0.000503511
I1006 23:07:24.644460  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000503601 (* 1 = 0.000503601 loss)
I1006 23:07:24.644480  3817 sgd_solver.cpp:105] Iteration 86500, lr = 0.001
I1006 23:07:41.732913  3817 solver.cpp:218] Iteration 86600 (5.85193 iter/s, 17.0884s/100 iters), loss = 0.00245033
I1006 23:07:41.732996  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00245042 (* 1 = 0.00245042 loss)
I1006 23:07:41.733005  3817 sgd_solver.cpp:105] Iteration 86600, lr = 0.001
I1006 23:07:58.801040  3817 solver.cpp:218] Iteration 86700 (5.85909 iter/s, 17.0675s/100 iters), loss = 0.00133613
I1006 23:07:58.801077  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00133623 (* 1 = 0.00133623 loss)
I1006 23:07:58.801097  3817 sgd_solver.cpp:105] Iteration 86700, lr = 0.001
I1006 23:08:16.245342  3817 solver.cpp:218] Iteration 86800 (5.73256 iter/s, 17.4442s/100 iters), loss = 0.00161029
I1006 23:08:16.245435  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00161039 (* 1 = 0.00161039 loss)
I1006 23:08:16.245446  3817 sgd_solver.cpp:105] Iteration 86800, lr = 0.001
I1006 23:08:33.324625  3817 solver.cpp:218] Iteration 86900 (5.85581 iter/s, 17.0771s/100 iters), loss = 0.000947354
I1006 23:08:33.324661  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000947448 (* 1 = 0.000947448 loss)
I1006 23:08:33.324681  3817 sgd_solver.cpp:105] Iteration 86900, lr = 0.001
I1006 23:08:49.550448  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:08:50.230216  3817 solver.cpp:330] Iteration 87000, Testing net (#0)
I1006 23:08:53.754272  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:08:53.875594  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9258
I1006 23:08:53.875623  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.32747 (* 1 = 0.32747 loss)
I1006 23:08:54.006686  3817 solver.cpp:218] Iteration 87000 (4.83563 iter/s, 20.6798s/100 iters), loss = 0.000277016
I1006 23:08:54.006726  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00027711 (* 1 = 0.00027711 loss)
I1006 23:08:54.006733  3817 sgd_solver.cpp:105] Iteration 87000, lr = 0.001
I1006 23:09:11.084338  3817 solver.cpp:218] Iteration 87100 (5.85565 iter/s, 17.0775s/100 iters), loss = 0.00250745
I1006 23:09:11.084372  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00250754 (* 1 = 0.00250754 loss)
I1006 23:09:11.084388  3817 sgd_solver.cpp:105] Iteration 87100, lr = 0.001
I1006 23:09:28.162631  3817 solver.cpp:218] Iteration 87200 (5.85598 iter/s, 17.0765s/100 iters), loss = 0.00163941
I1006 23:09:28.162708  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0016395 (* 1 = 0.0016395 loss)
I1006 23:09:28.162724  3817 sgd_solver.cpp:105] Iteration 87200, lr = 0.001
I1006 23:09:45.690445  3817 solver.cpp:218] Iteration 87300 (5.70568 iter/s, 17.5264s/100 iters), loss = 0.00281347
I1006 23:09:45.690479  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00281356 (* 1 = 0.00281356 loss)
I1006 23:09:45.690486  3817 sgd_solver.cpp:105] Iteration 87300, lr = 0.001
I1006 23:10:02.767936  3817 solver.cpp:218] Iteration 87400 (5.85622 iter/s, 17.0759s/100 iters), loss = 0.00103731
I1006 23:10:02.768074  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0010374 (* 1 = 0.0010374 loss)
I1006 23:10:02.768084  3817 sgd_solver.cpp:105] Iteration 87400, lr = 0.001
I1006 23:10:19.002315  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:10:19.686203  3817 solver.cpp:330] Iteration 87500, Testing net (#0)
I1006 23:10:23.213322  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:10:23.380740  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9249
I1006 23:10:23.380776  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.329029 (* 1 = 0.329029 loss)
I1006 23:10:23.487026  3817 solver.cpp:218] Iteration 87500 (4.82699 iter/s, 20.7168s/100 iters), loss = 0.000721433
I1006 23:10:23.487067  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00072152 (* 1 = 0.00072152 loss)
I1006 23:10:23.487074  3817 sgd_solver.cpp:105] Iteration 87500, lr = 0.001
I1006 23:10:40.607134  3817 solver.cpp:218] Iteration 87600 (5.84183 iter/s, 17.1179s/100 iters), loss = 0.00257719
I1006 23:10:40.607242  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00257728 (* 1 = 0.00257728 loss)
I1006 23:10:40.607249  3817 sgd_solver.cpp:105] Iteration 87600, lr = 0.001
I1006 23:10:57.702672  3817 solver.cpp:218] Iteration 87700 (5.85023 iter/s, 17.0933s/100 iters), loss = 0.00203116
I1006 23:10:57.702713  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00203125 (* 1 = 0.00203125 loss)
I1006 23:10:57.702719  3817 sgd_solver.cpp:105] Iteration 87700, lr = 0.001
I1006 23:11:15.125239  3817 solver.cpp:218] Iteration 87800 (5.74042 iter/s, 17.4203s/100 iters), loss = 0.00458369
I1006 23:11:15.125347  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00458378 (* 1 = 0.00458378 loss)
I1006 23:11:15.125355  3817 sgd_solver.cpp:105] Iteration 87800, lr = 0.001
I1006 23:11:32.200225  3817 solver.cpp:218] Iteration 87900 (5.85729 iter/s, 17.0728s/100 iters), loss = 0.00222977
I1006 23:11:32.200258  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00222986 (* 1 = 0.00222986 loss)
I1006 23:11:32.200275  3817 sgd_solver.cpp:105] Iteration 87900, lr = 0.001
I1006 23:11:48.434257  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:11:49.114018  3817 solver.cpp:330] Iteration 88000, Testing net (#0)
I1006 23:11:52.632969  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:11:52.752547  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9256
I1006 23:11:52.752570  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.32782 (* 1 = 0.32782 loss)
I1006 23:11:52.900879  3817 solver.cpp:218] Iteration 88000 (4.8311 iter/s, 20.6992s/100 iters), loss = 0.000500256
I1006 23:11:52.900918  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000500343 (* 1 = 0.000500343 loss)
I1006 23:11:52.900925  3817 sgd_solver.cpp:105] Iteration 88000, lr = 0.001
I1006 23:12:09.983284  3817 solver.cpp:218] Iteration 88100 (5.85401 iter/s, 17.0823s/100 iters), loss = 0.00181397
I1006 23:12:09.983327  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00181406 (* 1 = 0.00181406 loss)
I1006 23:12:09.983335  3817 sgd_solver.cpp:105] Iteration 88100, lr = 0.001
I1006 23:12:27.057870  3817 solver.cpp:218] Iteration 88200 (5.85726 iter/s, 17.0728s/100 iters), loss = 0.00299645
I1006 23:12:27.057934  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00299654 (* 1 = 0.00299654 loss)
I1006 23:12:27.057940  3817 sgd_solver.cpp:105] Iteration 88200, lr = 0.001
I1006 23:12:44.488224  3817 solver.cpp:218] Iteration 88300 (5.73716 iter/s, 17.4302s/100 iters), loss = 0.0043723
I1006 23:12:44.488268  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00437239 (* 1 = 0.00437239 loss)
I1006 23:12:44.488276  3817 sgd_solver.cpp:105] Iteration 88300, lr = 0.001
I1006 23:13:01.591536  3817 solver.cpp:218] Iteration 88400 (5.84759 iter/s, 17.1011s/100 iters), loss = 0.00222372
I1006 23:13:01.591604  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00222381 (* 1 = 0.00222381 loss)
I1006 23:13:01.591614  3817 sgd_solver.cpp:105] Iteration 88400, lr = 0.001
I1006 23:13:17.832274  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:13:18.514189  3817 solver.cpp:330] Iteration 88500, Testing net (#0)
I1006 23:13:22.043829  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:13:22.164585  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9244
I1006 23:13:22.164623  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.327619 (* 1 = 0.327619 loss)
I1006 23:13:22.294984  3817 solver.cpp:218] Iteration 88500 (4.83015 iter/s, 20.7033s/100 iters), loss = 0.00125563
I1006 23:13:22.295025  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00125572 (* 1 = 0.00125572 loss)
I1006 23:13:22.295032  3817 sgd_solver.cpp:105] Iteration 88500, lr = 0.001
I1006 23:13:39.366179  3817 solver.cpp:218] Iteration 88600 (5.85786 iter/s, 17.0711s/100 iters), loss = 0.00331966
I1006 23:13:39.366255  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00331975 (* 1 = 0.00331975 loss)
I1006 23:13:39.366271  3817 sgd_solver.cpp:105] Iteration 88600, lr = 0.001
I1006 23:13:56.431082  3817 solver.cpp:218] Iteration 88700 (5.86071 iter/s, 17.0628s/100 iters), loss = 0.000781263
I1006 23:13:56.431113  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000781353 (* 1 = 0.000781353 loss)
I1006 23:13:56.431129  3817 sgd_solver.cpp:105] Iteration 88700, lr = 0.001
I1006 23:14:13.854709  3817 solver.cpp:218] Iteration 88800 (5.74007 iter/s, 17.4214s/100 iters), loss = 0.00249162
I1006 23:14:13.854792  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00249171 (* 1 = 0.00249171 loss)
I1006 23:14:13.854799  3817 sgd_solver.cpp:105] Iteration 88800, lr = 0.001
I1006 23:14:30.931500  3817 solver.cpp:218] Iteration 88900 (5.85666 iter/s, 17.0746s/100 iters), loss = 0.00190714
I1006 23:14:30.931543  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00190723 (* 1 = 0.00190723 loss)
I1006 23:14:30.931550  3817 sgd_solver.cpp:105] Iteration 88900, lr = 0.001
I1006 23:14:47.169849  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:14:47.851155  3817 solver.cpp:330] Iteration 89000, Testing net (#0)
I1006 23:14:51.354274  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:14:51.471607  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9244
I1006 23:14:51.471642  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.327757 (* 1 = 0.327757 loss)
I1006 23:14:51.632567  3817 solver.cpp:218] Iteration 89000 (4.83119 iter/s, 20.6988s/100 iters), loss = 0.002486
I1006 23:14:51.632606  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00248608 (* 1 = 0.00248608 loss)
I1006 23:14:51.632612  3817 sgd_solver.cpp:105] Iteration 89000, lr = 0.001
I1006 23:15:08.704248  3817 solver.cpp:218] Iteration 89100 (5.85769 iter/s, 17.0716s/100 iters), loss = 0.00328313
I1006 23:15:08.704279  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00328322 (* 1 = 0.00328322 loss)
I1006 23:15:08.704286  3817 sgd_solver.cpp:105] Iteration 89100, lr = 0.001
I1006 23:15:25.776881  3817 solver.cpp:218] Iteration 89200 (5.85808 iter/s, 17.0704s/100 iters), loss = 0.00406529
I1006 23:15:25.776974  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00406538 (* 1 = 0.00406538 loss)
I1006 23:15:25.776983  3817 sgd_solver.cpp:105] Iteration 89200, lr = 0.001
I1006 23:15:43.203137  3817 solver.cpp:218] Iteration 89300 (5.73906 iter/s, 17.4244s/100 iters), loss = 0.00103634
I1006 23:15:43.203182  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00103643 (* 1 = 0.00103643 loss)
I1006 23:15:43.203191  3817 sgd_solver.cpp:105] Iteration 89300, lr = 0.001
I1006 23:16:00.291661  3817 solver.cpp:218] Iteration 89400 (5.85245 iter/s, 17.0869s/100 iters), loss = 0.00105307
I1006 23:16:00.291785  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00105315 (* 1 = 0.00105315 loss)
I1006 23:16:00.291802  3817 sgd_solver.cpp:105] Iteration 89400, lr = 0.001
I1006 23:16:16.540347  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:16:17.223232  3817 solver.cpp:330] Iteration 89500, Testing net (#0)
I1006 23:16:20.746999  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:16:20.871170  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9247
I1006 23:16:20.871206  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.32793 (* 1 = 0.32793 loss)
I1006 23:16:21.001065  3817 solver.cpp:218] Iteration 89500 (4.82924 iter/s, 20.7072s/100 iters), loss = 0.00146138
I1006 23:16:21.001102  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00146147 (* 1 = 0.00146147 loss)
I1006 23:16:21.001109  3817 sgd_solver.cpp:105] Iteration 89500, lr = 0.001
I1006 23:16:38.085002  3817 solver.cpp:218] Iteration 89600 (5.85349 iter/s, 17.0838s/100 iters), loss = 0.00416846
I1006 23:16:38.085149  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00416854 (* 1 = 0.00416854 loss)
I1006 23:16:38.085156  3817 sgd_solver.cpp:105] Iteration 89600, lr = 0.001
I1006 23:16:55.173040  3817 solver.cpp:218] Iteration 89700 (5.8527 iter/s, 17.0861s/100 iters), loss = 0.0014183
I1006 23:16:55.173074  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00141838 (* 1 = 0.00141838 loss)
I1006 23:16:55.173081  3817 sgd_solver.cpp:105] Iteration 89700, lr = 0.001
I1006 23:17:12.602427  3817 solver.cpp:218] Iteration 89800 (5.73802 iter/s, 17.4276s/100 iters), loss = 0.00183826
I1006 23:17:12.602509  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00183835 (* 1 = 0.00183835 loss)
I1006 23:17:12.602525  3817 sgd_solver.cpp:105] Iteration 89800, lr = 0.001
I1006 23:17:29.676002  3817 solver.cpp:218] Iteration 89900 (5.85745 iter/s, 17.0723s/100 iters), loss = 0.00142766
I1006 23:17:29.676033  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00142775 (* 1 = 0.00142775 loss)
I1006 23:17:29.676040  3817 sgd_solver.cpp:105] Iteration 89900, lr = 0.001
I1006 23:17:45.909557  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:17:46.587484  3817 solver.cpp:330] Iteration 90000, Testing net (#0)
I1006 23:17:50.105408  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:17:50.224390  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9247
I1006 23:17:50.224424  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.327783 (* 1 = 0.327783 loss)
I1006 23:17:50.372412  3817 solver.cpp:218] Iteration 90000 (4.83212 iter/s, 20.6948s/100 iters), loss = 0.00211243
I1006 23:17:50.372462  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00211252 (* 1 = 0.00211252 loss)
I1006 23:17:50.372470  3817 sgd_solver.cpp:105] Iteration 90000, lr = 0.001
I1006 23:18:07.445344  3817 solver.cpp:218] Iteration 90100 (5.85726 iter/s, 17.0728s/100 iters), loss = 0.00134129
I1006 23:18:07.445385  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00134137 (* 1 = 0.00134137 loss)
I1006 23:18:07.445392  3817 sgd_solver.cpp:105] Iteration 90100, lr = 0.001
I1006 23:18:24.533359  3817 solver.cpp:218] Iteration 90200 (5.85209 iter/s, 17.0879s/100 iters), loss = 0.0015156
I1006 23:18:24.533427  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00151569 (* 1 = 0.00151569 loss)
I1006 23:18:24.533447  3817 sgd_solver.cpp:105] Iteration 90200, lr = 0.001
I1006 23:18:41.954320  3817 solver.cpp:218] Iteration 90300 (5.74077 iter/s, 17.4193s/100 iters), loss = 0.00139556
I1006 23:18:41.954355  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00139564 (* 1 = 0.00139564 loss)
I1006 23:18:41.954365  3817 sgd_solver.cpp:105] Iteration 90300, lr = 0.001
I1006 23:18:59.041263  3817 solver.cpp:218] Iteration 90400 (5.85297 iter/s, 17.0853s/100 iters), loss = 0.00123926
I1006 23:18:59.041337  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00123934 (* 1 = 0.00123934 loss)
I1006 23:18:59.041345  3817 sgd_solver.cpp:105] Iteration 90400, lr = 0.001
I1006 23:19:15.263836  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:19:15.945964  3817 solver.cpp:330] Iteration 90500, Testing net (#0)
I1006 23:19:19.473245  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:19:19.611069  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9243
I1006 23:19:19.611097  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.327737 (* 1 = 0.327737 loss)
I1006 23:19:19.722332  3817 solver.cpp:218] Iteration 90500 (4.83573 iter/s, 20.6794s/100 iters), loss = 0.00227304
I1006 23:19:19.722362  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00227313 (* 1 = 0.00227313 loss)
I1006 23:19:19.722380  3817 sgd_solver.cpp:105] Iteration 90500, lr = 0.001
I1006 23:19:36.789006  3817 solver.cpp:218] Iteration 90600 (5.85941 iter/s, 17.0666s/100 iters), loss = 0.00222878
I1006 23:19:36.789134  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00222886 (* 1 = 0.00222886 loss)
I1006 23:19:36.789163  3817 sgd_solver.cpp:105] Iteration 90600, lr = 0.001
I1006 23:19:53.881516  3817 solver.cpp:218] Iteration 90700 (5.85127 iter/s, 17.0903s/100 iters), loss = 0.00157568
I1006 23:19:53.881558  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00157576 (* 1 = 0.00157576 loss)
I1006 23:19:53.881577  3817 sgd_solver.cpp:105] Iteration 90700, lr = 0.001
I1006 23:20:11.288502  3817 solver.cpp:218] Iteration 90800 (5.74555 iter/s, 17.4048s/100 iters), loss = 0.00322745
I1006 23:20:11.288609  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00322754 (* 1 = 0.00322754 loss)
I1006 23:20:11.288620  3817 sgd_solver.cpp:105] Iteration 90800, lr = 0.001
I1006 23:20:28.348404  3817 solver.cpp:218] Iteration 90900 (5.86246 iter/s, 17.0577s/100 iters), loss = 0.000453953
I1006 23:20:28.348438  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000454037 (* 1 = 0.000454037 loss)
I1006 23:20:28.348446  3817 sgd_solver.cpp:105] Iteration 90900, lr = 0.001
I1006 23:20:44.557241  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:20:45.237968  3817 solver.cpp:330] Iteration 91000, Testing net (#0)
I1006 23:20:48.761898  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:20:48.883277  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9244
I1006 23:20:48.883306  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.327904 (* 1 = 0.327904 loss)
I1006 23:20:49.014986  3817 solver.cpp:218] Iteration 91000 (4.83912 iter/s, 20.6649s/100 iters), loss = 0.00242164
I1006 23:20:49.015020  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00242173 (* 1 = 0.00242173 loss)
I1006 23:20:49.015029  3817 sgd_solver.cpp:105] Iteration 91000, lr = 0.001
I1006 23:21:06.064298  3817 solver.cpp:218] Iteration 91100 (5.86537 iter/s, 17.0492s/100 iters), loss = 0.00178158
I1006 23:21:06.064332  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00178167 (* 1 = 0.00178167 loss)
I1006 23:21:06.064352  3817 sgd_solver.cpp:105] Iteration 91100, lr = 0.001
I1006 23:21:23.134536  3817 solver.cpp:218] Iteration 91200 (5.85892 iter/s, 17.068s/100 iters), loss = 0.00592826
I1006 23:21:23.134650  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00592834 (* 1 = 0.00592834 loss)
I1006 23:21:23.134660  3817 sgd_solver.cpp:105] Iteration 91200, lr = 0.001
I1006 23:21:40.563736  3817 solver.cpp:218] Iteration 91300 (5.73803 iter/s, 17.4276s/100 iters), loss = 0.00245713
I1006 23:21:40.563771  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00245721 (* 1 = 0.00245721 loss)
I1006 23:21:40.563788  3817 sgd_solver.cpp:105] Iteration 91300, lr = 0.001
I1006 23:21:57.625571  3817 solver.cpp:218] Iteration 91400 (5.8618 iter/s, 17.0596s/100 iters), loss = 0.00134331
I1006 23:21:57.625695  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00134339 (* 1 = 0.00134339 loss)
I1006 23:21:57.625702  3817 sgd_solver.cpp:105] Iteration 91400, lr = 0.001
I1006 23:22:13.859634  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:22:14.541651  3817 solver.cpp:330] Iteration 91500, Testing net (#0)
I1006 23:22:18.068122  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:22:18.204717  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9249
I1006 23:22:18.204752  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.328096 (* 1 = 0.328096 loss)
I1006 23:22:18.319983  3817 solver.cpp:218] Iteration 91500 (4.83274 iter/s, 20.6922s/100 iters), loss = 0.00177186
I1006 23:22:18.320020  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00177194 (* 1 = 0.00177194 loss)
I1006 23:22:18.320040  3817 sgd_solver.cpp:105] Iteration 91500, lr = 0.001
I1006 23:22:35.395889  3817 solver.cpp:218] Iteration 91600 (5.85624 iter/s, 17.0758s/100 iters), loss = 0.00363769
I1006 23:22:35.396014  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00363777 (* 1 = 0.00363777 loss)
I1006 23:22:35.396040  3817 sgd_solver.cpp:105] Iteration 91600, lr = 0.001
I1006 23:22:52.472311  3817 solver.cpp:218] Iteration 91700 (5.85638 iter/s, 17.0754s/100 iters), loss = 0.00210461
I1006 23:22:52.472344  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00210469 (* 1 = 0.00210469 loss)
I1006 23:22:52.472363  3817 sgd_solver.cpp:105] Iteration 91700, lr = 0.001
I1006 23:23:09.911056  3817 solver.cpp:218] Iteration 91800 (5.73509 iter/s, 17.4365s/100 iters), loss = 0.0152188
I1006 23:23:09.911177  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0152189 (* 1 = 0.0152189 loss)
I1006 23:23:09.911201  3817 sgd_solver.cpp:105] Iteration 91800, lr = 0.001
I1006 23:23:26.992915  3817 solver.cpp:218] Iteration 91900 (5.85492 iter/s, 17.0797s/100 iters), loss = 0.00426141
I1006 23:23:26.992949  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00426149 (* 1 = 0.00426149 loss)
I1006 23:23:26.992967  3817 sgd_solver.cpp:105] Iteration 91900, lr = 0.001
I1006 23:23:43.232236  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:23:43.915921  3817 solver.cpp:330] Iteration 92000, Testing net (#0)
I1006 23:23:47.442863  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:23:47.610733  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9241
I1006 23:23:47.610769  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.329757 (* 1 = 0.329757 loss)
I1006 23:23:47.699370  3817 solver.cpp:218] Iteration 92000 (4.82994 iter/s, 20.7042s/100 iters), loss = 0.0010131
I1006 23:23:47.699410  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00101318 (* 1 = 0.00101318 loss)
I1006 23:23:47.699417  3817 sgd_solver.cpp:105] Iteration 92000, lr = 0.001
I1006 23:24:04.765656  3817 solver.cpp:218] Iteration 92100 (5.86028 iter/s, 17.064s/100 iters), loss = 0.00731666
I1006 23:24:04.765698  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00731674 (* 1 = 0.00731674 loss)
I1006 23:24:04.765705  3817 sgd_solver.cpp:105] Iteration 92100, lr = 0.001
I1006 23:24:21.832110  3817 solver.cpp:218] Iteration 92200 (5.86009 iter/s, 17.0646s/100 iters), loss = 0.0005675
I1006 23:24:21.832242  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000567582 (* 1 = 0.000567582 loss)
I1006 23:24:21.832249  3817 sgd_solver.cpp:105] Iteration 92200, lr = 0.001
I1006 23:24:39.266584  3817 solver.cpp:218] Iteration 92300 (5.7365 iter/s, 17.4322s/100 iters), loss = 0.00220782
I1006 23:24:39.266624  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0022079 (* 1 = 0.0022079 loss)
I1006 23:24:39.266631  3817 sgd_solver.cpp:105] Iteration 92300, lr = 0.001
I1006 23:24:56.328510  3817 solver.cpp:218] Iteration 92400 (5.86177 iter/s, 17.0597s/100 iters), loss = 0.00104278
I1006 23:24:56.328632  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00104286 (* 1 = 0.00104286 loss)
I1006 23:24:56.328649  3817 sgd_solver.cpp:105] Iteration 92400, lr = 0.001
I1006 23:25:12.572382  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:25:13.254370  3817 solver.cpp:330] Iteration 92500, Testing net (#0)
I1006 23:25:16.781101  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:25:16.917425  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9249
I1006 23:25:16.917461  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.327236 (* 1 = 0.327236 loss)
I1006 23:25:17.032740  3817 solver.cpp:218] Iteration 92500 (4.83046 iter/s, 20.702s/100 iters), loss = 0.00125854
I1006 23:25:17.032778  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00125862 (* 1 = 0.00125862 loss)
I1006 23:25:17.032785  3817 sgd_solver.cpp:105] Iteration 92500, lr = 0.001
I1006 23:25:34.119882  3817 solver.cpp:218] Iteration 92600 (5.85239 iter/s, 17.087s/100 iters), loss = 0.00356335
I1006 23:25:34.119985  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00356343 (* 1 = 0.00356343 loss)
I1006 23:25:34.120003  3817 sgd_solver.cpp:105] Iteration 92600, lr = 0.001
I1006 23:25:51.200570  3817 solver.cpp:218] Iteration 92700 (5.85514 iter/s, 17.079s/100 iters), loss = 0.00432412
I1006 23:25:51.200615  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0043242 (* 1 = 0.0043242 loss)
I1006 23:25:51.200623  3817 sgd_solver.cpp:105] Iteration 92700, lr = 0.001
I1006 23:26:08.629925  3817 solver.cpp:218] Iteration 92800 (5.73817 iter/s, 17.4271s/100 iters), loss = 0.000893652
I1006 23:26:08.630009  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000893733 (* 1 = 0.000893733 loss)
I1006 23:26:08.630026  3817 sgd_solver.cpp:105] Iteration 92800, lr = 0.001
I1006 23:26:25.725241  3817 solver.cpp:218] Iteration 92900 (5.85032 iter/s, 17.0931s/100 iters), loss = 0.000487896
I1006 23:26:25.725275  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000487976 (* 1 = 0.000487976 loss)
I1006 23:26:25.725291  3817 sgd_solver.cpp:105] Iteration 92900, lr = 0.001
I1006 23:26:41.967087  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:26:42.646407  3817 solver.cpp:330] Iteration 93000, Testing net (#0)
I1006 23:26:46.171664  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:26:46.308279  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9253
I1006 23:26:46.308308  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.326964 (* 1 = 0.326964 loss)
I1006 23:26:46.424190  3817 solver.cpp:218] Iteration 93000 (4.83168 iter/s, 20.6967s/100 iters), loss = 0.00103258
I1006 23:26:46.424233  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00103266 (* 1 = 0.00103266 loss)
I1006 23:26:46.424242  3817 sgd_solver.cpp:105] Iteration 93000, lr = 0.001
I1006 23:27:03.489331  3817 solver.cpp:218] Iteration 93100 (5.85993 iter/s, 17.065s/100 iters), loss = 0.00308955
I1006 23:27:03.489385  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00308962 (* 1 = 0.00308962 loss)
I1006 23:27:03.489392  3817 sgd_solver.cpp:105] Iteration 93100, lr = 0.001
I1006 23:27:20.572592  3817 solver.cpp:218] Iteration 93200 (5.85417 iter/s, 17.0818s/100 iters), loss = 0.00076309
I1006 23:27:20.572702  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000763169 (* 1 = 0.000763169 loss)
I1006 23:27:20.572721  3817 sgd_solver.cpp:105] Iteration 93200, lr = 0.001
I1006 23:27:37.992893  3817 solver.cpp:218] Iteration 93300 (5.74117 iter/s, 17.4181s/100 iters), loss = 0.0017766
I1006 23:27:37.992926  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00177668 (* 1 = 0.00177668 loss)
I1006 23:27:37.992933  3817 sgd_solver.cpp:105] Iteration 93300, lr = 0.001
I1006 23:27:55.054294  3817 solver.cpp:218] Iteration 93400 (5.86194 iter/s, 17.0592s/100 iters), loss = 0.00137748
I1006 23:27:55.054414  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00137756 (* 1 = 0.00137756 loss)
I1006 23:27:55.054430  3817 sgd_solver.cpp:105] Iteration 93400, lr = 0.001
I1006 23:28:11.272408  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:28:11.954605  3817 solver.cpp:330] Iteration 93500, Testing net (#0)
I1006 23:28:15.480851  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:28:15.648012  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9246
I1006 23:28:15.648039  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.327491 (* 1 = 0.327491 loss)
I1006 23:28:15.738440  3817 solver.cpp:218] Iteration 93500 (4.83504 iter/s, 20.6824s/100 iters), loss = 0.0014891
I1006 23:28:15.738471  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00148918 (* 1 = 0.00148918 loss)
I1006 23:28:15.738492  3817 sgd_solver.cpp:105] Iteration 93500, lr = 0.001
I1006 23:28:32.781321  3817 solver.cpp:218] Iteration 93600 (5.86832 iter/s, 17.0406s/100 iters), loss = 0.0016304
I1006 23:28:32.781414  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00163048 (* 1 = 0.00163048 loss)
I1006 23:28:32.781435  3817 sgd_solver.cpp:105] Iteration 93600, lr = 0.001
I1006 23:28:49.854555  3817 solver.cpp:218] Iteration 93700 (5.85789 iter/s, 17.071s/100 iters), loss = 0.00194728
I1006 23:28:49.854586  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00194736 (* 1 = 0.00194736 loss)
I1006 23:28:49.854593  3817 sgd_solver.cpp:105] Iteration 93700, lr = 0.001
I1006 23:29:07.293448  3817 solver.cpp:218] Iteration 93800 (5.73505 iter/s, 17.4366s/100 iters), loss = 0.00187988
I1006 23:29:07.293565  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00187996 (* 1 = 0.00187996 loss)
I1006 23:29:07.293583  3817 sgd_solver.cpp:105] Iteration 93800, lr = 0.001
I1006 23:29:24.375103  3817 solver.cpp:218] Iteration 93900 (5.855 iter/s, 17.0794s/100 iters), loss = 0.00108193
I1006 23:29:24.375138  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00108201 (* 1 = 0.00108201 loss)
I1006 23:29:24.375154  3817 sgd_solver.cpp:105] Iteration 93900, lr = 0.001
I1006 23:29:40.618438  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:29:41.299700  3817 solver.cpp:330] Iteration 94000, Testing net (#0)
I1006 23:29:44.827064  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:29:44.982821  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9247
I1006 23:29:44.982848  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.326709 (* 1 = 0.326709 loss)
I1006 23:29:45.079495  3817 solver.cpp:218] Iteration 94000 (4.83041 iter/s, 20.7022s/100 iters), loss = 0.00118083
I1006 23:29:45.079532  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00118091 (* 1 = 0.00118091 loss)
I1006 23:29:45.079538  3817 sgd_solver.cpp:105] Iteration 94000, lr = 0.001
I1006 23:30:02.140769  3817 solver.cpp:218] Iteration 94100 (5.86126 iter/s, 17.0612s/100 iters), loss = 0.00467291
I1006 23:30:02.140802  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00467299 (* 1 = 0.00467299 loss)
I1006 23:30:02.140821  3817 sgd_solver.cpp:105] Iteration 94100, lr = 0.001
I1006 23:30:19.202425  3817 solver.cpp:218] Iteration 94200 (5.86186 iter/s, 17.0594s/100 iters), loss = 0.00226853
I1006 23:30:19.202528  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00226861 (* 1 = 0.00226861 loss)
I1006 23:30:19.202536  3817 sgd_solver.cpp:105] Iteration 94200, lr = 0.001
I1006 23:30:36.627288  3817 solver.cpp:218] Iteration 94300 (5.73965 iter/s, 17.4227s/100 iters), loss = 0.000940426
I1006 23:30:36.627331  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000940507 (* 1 = 0.000940507 loss)
I1006 23:30:36.627338  3817 sgd_solver.cpp:105] Iteration 94300, lr = 0.001
I1006 23:30:53.709775  3817 solver.cpp:218] Iteration 94400 (5.85444 iter/s, 17.0811s/100 iters), loss = 0.00172949
I1006 23:30:53.709867  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00172957 (* 1 = 0.00172957 loss)
I1006 23:30:53.709887  3817 sgd_solver.cpp:105] Iteration 94400, lr = 0.001
I1006 23:31:09.961836  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:31:10.644492  3817 solver.cpp:330] Iteration 94500, Testing net (#0)
I1006 23:31:14.141675  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:31:14.267413  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9247
I1006 23:31:14.267449  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.326781 (* 1 = 0.326781 loss)
I1006 23:31:14.414469  3817 solver.cpp:218] Iteration 94500 (4.83018 iter/s, 20.7032s/100 iters), loss = 0.00149456
I1006 23:31:14.414510  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00149464 (* 1 = 0.00149464 loss)
I1006 23:31:14.414517  3817 sgd_solver.cpp:105] Iteration 94500, lr = 0.001
I1006 23:31:31.484655  3817 solver.cpp:218] Iteration 94600 (5.85821 iter/s, 17.0701s/100 iters), loss = 0.00877339
I1006 23:31:31.484777  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00877347 (* 1 = 0.00877347 loss)
I1006 23:31:31.484796  3817 sgd_solver.cpp:105] Iteration 94600, lr = 0.001
I1006 23:31:48.545893  3817 solver.cpp:218] Iteration 94700 (5.86169 iter/s, 17.0599s/100 iters), loss = 0.00062091
I1006 23:31:48.545935  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000620992 (* 1 = 0.000620992 loss)
I1006 23:31:48.545943  3817 sgd_solver.cpp:105] Iteration 94700, lr = 0.001
I1006 23:32:05.975445  3817 solver.cpp:218] Iteration 94800 (5.73805 iter/s, 17.4275s/100 iters), loss = 0.00418962
I1006 23:32:05.975548  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0041897 (* 1 = 0.0041897 loss)
I1006 23:32:05.975555  3817 sgd_solver.cpp:105] Iteration 94800, lr = 0.001
I1006 23:32:22.980726  3817 solver.cpp:218] Iteration 94900 (5.88124 iter/s, 17.0032s/100 iters), loss = 0.00215169
I1006 23:32:22.980759  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00215177 (* 1 = 0.00215177 loss)
I1006 23:32:22.980777  3817 sgd_solver.cpp:105] Iteration 94900, lr = 0.001
I1006 23:32:39.249414  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:32:39.933157  3817 solver.cpp:330] Iteration 95000, Testing net (#0)
I1006 23:32:43.455298  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:32:43.570487  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9252
I1006 23:32:43.570524  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.327247 (* 1 = 0.327247 loss)
I1006 23:32:43.716058  3817 solver.cpp:218] Iteration 95000 (4.82318 iter/s, 20.7332s/100 iters), loss = 0.000723473
I1006 23:32:43.716099  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000723555 (* 1 = 0.000723555 loss)
I1006 23:32:43.716104  3817 sgd_solver.cpp:105] Iteration 95000, lr = 0.001
I1006 23:33:00.803948  3817 solver.cpp:218] Iteration 95100 (5.85213 iter/s, 17.0878s/100 iters), loss = 0.00161743
I1006 23:33:00.803989  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00161751 (* 1 = 0.00161751 loss)
I1006 23:33:00.803997  3817 sgd_solver.cpp:105] Iteration 95100, lr = 0.001
I1006 23:33:17.905022  3817 solver.cpp:218] Iteration 95200 (5.84813 iter/s, 17.0995s/100 iters), loss = 0.00218734
I1006 23:33:17.905120  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00218743 (* 1 = 0.00218743 loss)
I1006 23:33:17.905140  3817 sgd_solver.cpp:105] Iteration 95200, lr = 0.001
I1006 23:33:35.330107  3817 solver.cpp:218] Iteration 95300 (5.7393 iter/s, 17.4237s/100 iters), loss = 0.00269715
I1006 23:33:35.330149  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00269724 (* 1 = 0.00269724 loss)
I1006 23:33:35.330157  3817 sgd_solver.cpp:105] Iteration 95300, lr = 0.001
I1006 23:33:52.406981  3817 solver.cpp:218] Iteration 95400 (5.85664 iter/s, 17.0746s/100 iters), loss = 0.00126202
I1006 23:33:52.407057  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0012621 (* 1 = 0.0012621 loss)
I1006 23:33:52.407073  3817 sgd_solver.cpp:105] Iteration 95400, lr = 0.001
I1006 23:34:08.637465  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:34:09.321372  3817 solver.cpp:330] Iteration 95500, Testing net (#0)
I1006 23:34:12.827920  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:34:12.953552  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9244
I1006 23:34:12.953588  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.327322 (* 1 = 0.327322 loss)
I1006 23:34:13.100848  3817 solver.cpp:218] Iteration 95500 (4.83287 iter/s, 20.6916s/100 iters), loss = 0.000661669
I1006 23:34:13.100885  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000661754 (* 1 = 0.000661754 loss)
I1006 23:34:13.100891  3817 sgd_solver.cpp:105] Iteration 95500, lr = 0.001
I1006 23:34:30.171835  3817 solver.cpp:218] Iteration 95600 (5.85793 iter/s, 17.0709s/100 iters), loss = 0.00109895
I1006 23:34:30.171902  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00109903 (* 1 = 0.00109903 loss)
I1006 23:34:30.171921  3817 sgd_solver.cpp:105] Iteration 95600, lr = 0.001
I1006 23:34:47.252888  3817 solver.cpp:218] Iteration 95700 (5.85493 iter/s, 17.0796s/100 iters), loss = 0.00239679
I1006 23:34:47.252936  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00239687 (* 1 = 0.00239687 loss)
I1006 23:34:47.252943  3817 sgd_solver.cpp:105] Iteration 95700, lr = 0.001
I1006 23:35:04.672147  3817 solver.cpp:218] Iteration 95800 (5.7415 iter/s, 17.4171s/100 iters), loss = 0.0013749
I1006 23:35:04.672250  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00137498 (* 1 = 0.00137498 loss)
I1006 23:35:04.672257  3817 sgd_solver.cpp:105] Iteration 95800, lr = 0.001
I1006 23:35:21.729254  3817 solver.cpp:218] Iteration 95900 (5.86343 iter/s, 17.0549s/100 iters), loss = 0.000508517
I1006 23:35:21.729295  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000508601 (* 1 = 0.000508601 loss)
I1006 23:35:21.729300  3817 sgd_solver.cpp:105] Iteration 95900, lr = 0.001
I1006 23:35:37.965139  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:35:38.647236  3817 solver.cpp:330] Iteration 96000, Testing net (#0)
I1006 23:35:42.174861  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:35:42.332674  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9246
I1006 23:35:42.332700  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.326948 (* 1 = 0.326948 loss)
I1006 23:35:42.427994  3817 solver.cpp:218] Iteration 96000 (4.83173 iter/s, 20.6965s/100 iters), loss = 0.00153609
I1006 23:35:42.428030  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00153617 (* 1 = 0.00153617 loss)
I1006 23:35:42.428036  3817 sgd_solver.cpp:105] Iteration 96000, lr = 0.001
I1006 23:35:59.496711  3817 solver.cpp:218] Iteration 96100 (5.85871 iter/s, 17.0686s/100 iters), loss = 0.00290709
I1006 23:35:59.496750  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00290718 (* 1 = 0.00290718 loss)
I1006 23:35:59.496757  3817 sgd_solver.cpp:105] Iteration 96100, lr = 0.001
I1006 23:36:16.573352  3817 solver.cpp:218] Iteration 96200 (5.85671 iter/s, 17.0744s/100 iters), loss = 0.00290697
I1006 23:36:16.573464  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00290705 (* 1 = 0.00290705 loss)
I1006 23:36:16.573484  3817 sgd_solver.cpp:105] Iteration 96200, lr = 0.001
I1006 23:36:33.996151  3817 solver.cpp:218] Iteration 96300 (5.74035 iter/s, 17.4205s/100 iters), loss = 0.00130381
I1006 23:36:33.996183  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00130389 (* 1 = 0.00130389 loss)
I1006 23:36:33.996191  3817 sgd_solver.cpp:105] Iteration 96300, lr = 0.001
I1006 23:36:51.062688  3817 solver.cpp:218] Iteration 96400 (5.86001 iter/s, 17.0648s/100 iters), loss = 0.000629067
I1006 23:36:51.062779  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000629147 (* 1 = 0.000629147 loss)
I1006 23:36:51.062798  3817 sgd_solver.cpp:105] Iteration 96400, lr = 0.001
I1006 23:37:07.282951  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:37:07.964534  3817 solver.cpp:330] Iteration 96500, Testing net (#0)
I1006 23:37:11.491611  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:37:11.619256  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.925
I1006 23:37:11.619284  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.327604 (* 1 = 0.327604 loss)
I1006 23:37:11.743214  3817 solver.cpp:218] Iteration 96500 (4.83599 iter/s, 20.6783s/100 iters), loss = 0.00138775
I1006 23:37:11.743255  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00138783 (* 1 = 0.00138783 loss)
I1006 23:37:11.743261  3817 sgd_solver.cpp:105] Iteration 96500, lr = 0.001
I1006 23:37:28.812330  3817 solver.cpp:218] Iteration 96600 (5.85857 iter/s, 17.069s/100 iters), loss = 0.00138124
I1006 23:37:28.812407  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00138132 (* 1 = 0.00138132 loss)
I1006 23:37:28.812415  3817 sgd_solver.cpp:105] Iteration 96600, lr = 0.001
I1006 23:37:45.891178  3817 solver.cpp:218] Iteration 96700 (5.85576 iter/s, 17.0772s/100 iters), loss = 0.00374081
I1006 23:37:45.891212  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00374089 (* 1 = 0.00374089 loss)
I1006 23:37:45.891228  3817 sgd_solver.cpp:105] Iteration 96700, lr = 0.001
I1006 23:38:03.305838  3817 solver.cpp:218] Iteration 96800 (5.74232 iter/s, 17.4146s/100 iters), loss = 0.00113695
I1006 23:38:03.305959  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00113703 (* 1 = 0.00113703 loss)
I1006 23:38:03.305977  3817 sgd_solver.cpp:105] Iteration 96800, lr = 0.001
I1006 23:38:20.393877  3817 solver.cpp:218] Iteration 96900 (5.85282 iter/s, 17.0858s/100 iters), loss = 0.00107527
I1006 23:38:20.393918  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00107535 (* 1 = 0.00107535 loss)
I1006 23:38:20.393924  3817 sgd_solver.cpp:105] Iteration 96900, lr = 0.001
I1006 23:38:36.624274  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:38:37.304174  3817 solver.cpp:330] Iteration 97000, Testing net (#0)
I1006 23:38:40.834105  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:38:40.970909  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9246
I1006 23:38:40.970945  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.327206 (* 1 = 0.327206 loss)
I1006 23:38:41.085779  3817 solver.cpp:218] Iteration 97000 (4.83333 iter/s, 20.6897s/100 iters), loss = 0.00042392
I1006 23:38:41.085817  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000423997 (* 1 = 0.000423997 loss)
I1006 23:38:41.085824  3817 sgd_solver.cpp:105] Iteration 97000, lr = 0.001
I1006 23:38:58.157315  3817 solver.cpp:218] Iteration 97100 (5.85774 iter/s, 17.0714s/100 iters), loss = 0.00238585
I1006 23:38:58.157357  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00238592 (* 1 = 0.00238592 loss)
I1006 23:38:58.157364  3817 sgd_solver.cpp:105] Iteration 97100, lr = 0.001
I1006 23:39:15.229063  3817 solver.cpp:218] Iteration 97200 (5.85767 iter/s, 17.0716s/100 iters), loss = 0.00126915
I1006 23:39:15.229212  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00126923 (* 1 = 0.00126923 loss)
I1006 23:39:15.229221  3817 sgd_solver.cpp:105] Iteration 97200, lr = 0.001
I1006 23:39:32.658478  3817 solver.cpp:218] Iteration 97300 (5.73815 iter/s, 17.4272s/100 iters), loss = 0.0005377
I1006 23:39:32.658519  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000537775 (* 1 = 0.000537775 loss)
I1006 23:39:32.658526  3817 sgd_solver.cpp:105] Iteration 97300, lr = 0.001
I1006 23:39:49.744745  3817 solver.cpp:218] Iteration 97400 (5.85342 iter/s, 17.084s/100 iters), loss = 0.000773308
I1006 23:39:49.744870  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000773382 (* 1 = 0.000773382 loss)
I1006 23:39:49.744889  3817 sgd_solver.cpp:105] Iteration 97400, lr = 0.001
I1006 23:40:05.986300  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:40:06.668027  3817 solver.cpp:330] Iteration 97500, Testing net (#0)
I1006 23:40:10.197350  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:40:10.338279  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9245
I1006 23:40:10.338316  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.327963 (* 1 = 0.327963 loss)
I1006 23:40:10.449355  3817 solver.cpp:218] Iteration 97500 (4.83022 iter/s, 20.703s/100 iters), loss = 0.00156842
I1006 23:40:10.449395  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0015685 (* 1 = 0.0015685 loss)
I1006 23:40:10.449403  3817 sgd_solver.cpp:105] Iteration 97500, lr = 0.001
I1006 23:40:27.527760  3817 solver.cpp:218] Iteration 97600 (5.85539 iter/s, 17.0783s/100 iters), loss = 0.0019938
I1006 23:40:27.527882  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00199388 (* 1 = 0.00199388 loss)
I1006 23:40:27.527889  3817 sgd_solver.cpp:105] Iteration 97600, lr = 0.001
I1006 23:40:44.603173  3817 solver.cpp:218] Iteration 97700 (5.85698 iter/s, 17.0736s/100 iters), loss = 0.000552119
I1006 23:40:44.603205  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000552195 (* 1 = 0.000552195 loss)
I1006 23:40:44.603221  3817 sgd_solver.cpp:105] Iteration 97700, lr = 0.001
I1006 23:41:02.018638  3817 solver.cpp:218] Iteration 97800 (5.74205 iter/s, 17.4154s/100 iters), loss = 0.00198927
I1006 23:41:02.018741  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00198935 (* 1 = 0.00198935 loss)
I1006 23:41:02.018749  3817 sgd_solver.cpp:105] Iteration 97800, lr = 0.001
I1006 23:41:19.101827  3817 solver.cpp:218] Iteration 97900 (5.85419 iter/s, 17.0818s/100 iters), loss = 0.00140837
I1006 23:41:19.101871  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00140844 (* 1 = 0.00140844 loss)
I1006 23:41:19.101877  3817 sgd_solver.cpp:105] Iteration 97900, lr = 0.001
I1006 23:41:35.345757  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:41:36.028312  3817 solver.cpp:330] Iteration 98000, Testing net (#0)
I1006 23:41:39.555761  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:41:39.677474  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9256
I1006 23:41:39.677501  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.325323 (* 1 = 0.325323 loss)
I1006 23:41:39.808598  3817 solver.cpp:218] Iteration 98000 (4.82985 iter/s, 20.7046s/100 iters), loss = 0.00788328
I1006 23:41:39.808637  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00788335 (* 1 = 0.00788335 loss)
I1006 23:41:39.808643  3817 sgd_solver.cpp:105] Iteration 98000, lr = 0.001
I1006 23:41:56.893450  3817 solver.cpp:218] Iteration 98100 (5.85318 iter/s, 17.0847s/100 iters), loss = 0.00179845
I1006 23:41:56.893493  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00179852 (* 1 = 0.00179852 loss)
I1006 23:41:56.893501  3817 sgd_solver.cpp:105] Iteration 98100, lr = 0.001
I1006 23:42:13.976907  3817 solver.cpp:218] Iteration 98200 (5.85411 iter/s, 17.082s/100 iters), loss = 0.00189319
I1006 23:42:13.977037  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00189327 (* 1 = 0.00189327 loss)
I1006 23:42:13.977056  3817 sgd_solver.cpp:105] Iteration 98200, lr = 0.001
I1006 23:42:31.405550  3817 solver.cpp:218] Iteration 98300 (5.73774 iter/s, 17.4285s/100 iters), loss = 0.00418979
I1006 23:42:31.405593  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00418986 (* 1 = 0.00418986 loss)
I1006 23:42:31.405601  3817 sgd_solver.cpp:105] Iteration 98300, lr = 0.001
I1006 23:42:48.479197  3817 solver.cpp:218] Iteration 98400 (5.8575 iter/s, 17.0721s/100 iters), loss = 0.00146024
I1006 23:42:48.479311  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00146031 (* 1 = 0.00146031 loss)
I1006 23:42:48.479320  3817 sgd_solver.cpp:105] Iteration 98400, lr = 0.001
I1006 23:43:04.745512  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:43:05.430096  3817 solver.cpp:330] Iteration 98500, Testing net (#0)
I1006 23:43:08.959854  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:43:09.127419  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.925
I1006 23:43:09.127454  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.325734 (* 1 = 0.325734 loss)
I1006 23:43:09.218277  3817 solver.cpp:218] Iteration 98500 (4.82234 iter/s, 20.7368s/100 iters), loss = 0.000620837
I1006 23:43:09.218319  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000620912 (* 1 = 0.000620912 loss)
I1006 23:43:09.218327  3817 sgd_solver.cpp:105] Iteration 98500, lr = 0.001
I1006 23:43:26.284971  3817 solver.cpp:218] Iteration 98600 (5.86014 iter/s, 17.0645s/100 iters), loss = 0.00239773
I1006 23:43:26.285075  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0023978 (* 1 = 0.0023978 loss)
I1006 23:43:26.285084  3817 sgd_solver.cpp:105] Iteration 98600, lr = 0.001
I1006 23:43:43.318397  3817 solver.cpp:218] Iteration 98700 (5.87133 iter/s, 17.0319s/100 iters), loss = 0.00112597
I1006 23:43:43.318439  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00112605 (* 1 = 0.00112605 loss)
I1006 23:43:43.318445  3817 sgd_solver.cpp:105] Iteration 98700, lr = 0.001
I1006 23:44:00.775794  3817 solver.cpp:218] Iteration 98800 (5.72896 iter/s, 17.4552s/100 iters), loss = 0.00135469
I1006 23:44:00.775878  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00135477 (* 1 = 0.00135477 loss)
I1006 23:44:00.775898  3817 sgd_solver.cpp:105] Iteration 98800, lr = 0.001
I1006 23:44:17.843571  3817 solver.cpp:218] Iteration 98900 (5.85935 iter/s, 17.0667s/100 iters), loss = 0.000857418
I1006 23:44:17.843607  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000857493 (* 1 = 0.000857493 loss)
I1006 23:44:17.843613  3817 sgd_solver.cpp:105] Iteration 98900, lr = 0.001
I1006 23:44:34.072538  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:44:34.753955  3817 solver.cpp:330] Iteration 99000, Testing net (#0)
I1006 23:44:38.278515  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:44:38.432974  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9246
I1006 23:44:38.433001  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.32655 (* 1 = 0.32655 loss)
I1006 23:44:38.529255  3817 solver.cpp:218] Iteration 99000 (4.83477 iter/s, 20.6835s/100 iters), loss = 0.00119166
I1006 23:44:38.529294  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00119173 (* 1 = 0.00119173 loss)
I1006 23:44:38.529301  3817 sgd_solver.cpp:105] Iteration 99000, lr = 0.001
I1006 23:44:55.593626  3817 solver.cpp:218] Iteration 99100 (5.86021 iter/s, 17.0642s/100 iters), loss = 0.0103187
I1006 23:44:55.593668  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0103188 (* 1 = 0.0103188 loss)
I1006 23:44:55.593674  3817 sgd_solver.cpp:105] Iteration 99100, lr = 0.001
I1006 23:45:12.661511  3817 solver.cpp:218] Iteration 99200 (5.85973 iter/s, 17.0656s/100 iters), loss = 0.0014906
I1006 23:45:12.661618  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00149068 (* 1 = 0.00149068 loss)
I1006 23:45:12.661628  3817 sgd_solver.cpp:105] Iteration 99200, lr = 0.001
I1006 23:45:30.081984  3817 solver.cpp:218] Iteration 99300 (5.7411 iter/s, 17.4183s/100 iters), loss = 0.00060391
I1006 23:45:30.082026  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000603984 (* 1 = 0.000603984 loss)
I1006 23:45:30.082031  3817 sgd_solver.cpp:105] Iteration 99300, lr = 0.001
I1006 23:45:47.163820  3817 solver.cpp:218] Iteration 99400 (5.85476 iter/s, 17.0801s/100 iters), loss = 0.00189767
I1006 23:45:47.163897  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00189774 (* 1 = 0.00189774 loss)
I1006 23:45:47.163904  3817 sgd_solver.cpp:105] Iteration 99400, lr = 0.001
I1006 23:46:03.408879  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:46:04.091702  3817 solver.cpp:330] Iteration 99500, Testing net (#0)
I1006 23:46:07.618293  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:46:07.754473  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9243
I1006 23:46:07.754500  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.32683 (* 1 = 0.32683 loss)
I1006 23:46:07.869706  3817 solver.cpp:218] Iteration 99500 (4.83006 iter/s, 20.7037s/100 iters), loss = 0.000828944
I1006 23:46:07.869750  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000829018 (* 1 = 0.000829018 loss)
I1006 23:46:07.869756  3817 sgd_solver.cpp:105] Iteration 99500, lr = 0.001
I1006 23:46:24.946048  3817 solver.cpp:218] Iteration 99600 (5.85609 iter/s, 17.0762s/100 iters), loss = 0.010305
I1006 23:46:24.946147  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0103051 (* 1 = 0.0103051 loss)
I1006 23:46:24.946168  3817 sgd_solver.cpp:105] Iteration 99600, lr = 0.001
I1006 23:46:42.022512  3817 solver.cpp:218] Iteration 99700 (5.85652 iter/s, 17.075s/100 iters), loss = 0.00149576
I1006 23:46:42.022545  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00149583 (* 1 = 0.00149583 loss)
I1006 23:46:42.022552  3817 sgd_solver.cpp:105] Iteration 99700, lr = 0.001
I1006 23:46:59.547333  3817 solver.cpp:218] Iteration 99800 (5.70692 iter/s, 17.5226s/100 iters), loss = 0.00123758
I1006 23:46:59.547428  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00123765 (* 1 = 0.00123765 loss)
I1006 23:46:59.547447  3817 sgd_solver.cpp:105] Iteration 99800, lr = 0.001
I1006 23:47:16.636955  3817 solver.cpp:218] Iteration 99900 (5.85199 iter/s, 17.0882s/100 iters), loss = 0.000861351
I1006 23:47:16.636997  3817 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000861428 (* 1 = 0.000861428 loss)
I1006 23:47:16.637004  3817 sgd_solver.cpp:105] Iteration 99900, lr = 0.001
I1006 23:47:32.887953  3827 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:47:33.570191  3817 solver.cpp:447] Snapshotting to binary proto file xn/PENLU/snapshot/resnet/res32/res32_prelu_gauss_iter_100000.caffemodel
I1006 23:47:33.584856  3817 sgd_solver.cpp:273] Snapshotting solver state to binary proto file xn/PENLU/snapshot/resnet/res32/res32_prelu_gauss_iter_100000.solverstate
I1006 23:47:33.632395  3817 solver.cpp:310] Iteration 100000, loss = 0.00210921
I1006 23:47:33.632417  3817 solver.cpp:330] Iteration 100000, Testing net (#0)
I1006 23:47:37.121356  3828 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:47:37.288305  3817 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9242
I1006 23:47:37.288341  3817 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.327438 (* 1 = 0.327438 loss)
I1006 23:47:37.288347  3817 solver.cpp:315] Optimization Done.
I1006 23:47:37.288349  3817 caffe.cpp:259] Optimization Done.
