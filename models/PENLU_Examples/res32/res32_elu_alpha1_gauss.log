I1007 22:14:13.052737  5289 caffe.cpp:218] Using GPUs 0
I1007 22:14:13.092227  5289 caffe.cpp:223] GPU 0: GeForce GTX 1080
I1007 22:14:13.320816  5289 solver.cpp:44] Initializing solver from parameters: 
test_iter: 100
test_interval: 500
base_lr: 0.1
display: 100
max_iter: 100000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0001
snapshot: 100000
snapshot_prefix: "xn/PENLU/snapshot/resnet/res32/res32_elu_alpha1_gauss"
solver_mode: GPU
device_id: 0
net: "/home/x306/caffe/xn/PENLU/neural/resnet/res32/res32_elu_train_test.prototxt"
train_state {
  level: 0
  stage: ""
}
stepvalue: 40000
stepvalue: 80000
I1007 22:14:13.320945  5289 solver.cpp:87] Creating training net from net file: /home/x306/caffe/xn/PENLU/neural/resnet/res32/res32_elu_train_test.prototxt
I1007 22:14:13.322789  5289 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: /home/x306/caffe/xn/PENLU/neural/resnet/res32/res32_elu_train_test.prototxt
I1007 22:14:13.322800  5289 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I1007 22:14:13.322973  5289 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer Data1
I1007 22:14:13.323053  5289 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer Accuracy1
I1007 22:14:13.323628  5289 net.cpp:51] Initializing net from parameters: 
name: "resnet_cifar10"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "Data1"
  type: "Data"
  top: "Data1"
  top: "Data2"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 28
    mean_file: "/home/x306/caffe/xn/PENLU/data/cifar10/mean.binaryproto"
  }
  data_param {
    source: "/home/x306/caffe/xn/PENLU/data/cifar10/cifar10_train_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "Convolution1"
  type: "Convolution"
  bottom: "Data1"
  top: "Convolution1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm1"
  type: "BatchNorm"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1"
  type: "Scale"
  bottom: "Convolution1"
  top: "Convolution1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "elu1"
  type: "ELU"
  bottom: "Convolution1"
  top: "Convolution1"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution2"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm2"
  type: "BatchNorm"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale2"
  type: "Scale"
  bottom: "Convolution2"
  top: "Convolution2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "elu2"
  type: "ELU"
  bottom: "Convolution2"
  top: "Convolution2"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution3"
  type: "Convolution"
  bottom: "Convolution2"
  top: "Convolution3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm3"
  type: "BatchNorm"
  bottom: "Convolution3"
  top: "Convolution3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale3"
  type: "Scale"
  bottom: "Convolution3"
  top: "Convolution3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise1"
  type: "Eltwise"
  bottom: "Convolution1"
  bottom: "Convolution3"
  top: "Eltwise1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "elu3"
  type: "ELU"
  bottom: "Eltwise1"
  top: "Eltwise1"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution4"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm4"
  type: "BatchNorm"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale4"
  type: "Scale"
  bottom: "Convolution4"
  top: "Convolution4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "elu4"
  type: "ELU"
  bottom: "Convolution4"
  top: "Convolution4"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution5"
  type: "Convolution"
  bottom: "Convolution4"
  top: "Convolution5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm5"
  type: "BatchNorm"
  bottom: "Convolution5"
  top: "Convolution5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale5"
  type: "Scale"
  bottom: "Convolution5"
  top: "Convolution5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise2"
  type: "Eltwise"
  bottom: "Eltwise1"
  bottom: "Convolution5"
  top: "Eltwise2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "elu5"
  type: "ELU"
  bottom: "Eltwise2"
  top: "Eltwise2"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution6"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm6"
  type: "BatchNorm"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale6"
  type: "Scale"
  bottom: "Convolution6"
  top: "Convolution6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "elu6"
  type: "ELU"
  bottom: "Convolution6"
  top: "Convolution6"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution7"
  type: "Convolution"
  bottom: "Convolution6"
  top: "Convolution7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm7"
  type: "BatchNorm"
  bottom: "Convolution7"
  top: "Convolution7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale7"
  type: "Scale"
  bottom: "Convolution7"
  top: "Convolution7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise3"
  type: "Eltwise"
  bottom: "Eltwise2"
  bottom: "Convolution7"
  top: "Eltwise3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "elu7"
  type: "ELU"
  bottom: "Eltwise3"
  top: "Eltwise3"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution8"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm8"
  type: "BatchNorm"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale8"
  type: "Scale"
  bottom: "Convolution8"
  top: "Convolution8"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "elu8"
  type: "ELU"
  bottom: "Convolution8"
  top: "Convolution8"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution9"
  type: "Convolution"
  bottom: "Convolution8"
  top: "Convolution9"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm9"
  type: "BatchNorm"
  bottom: "Convolution9"
  top: "Convolution9"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale9"
  type: "Scale"
  bottom: "Convolution9"
  top: "Convolution9"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise4"
  type: "Eltwise"
  bottom: "Eltwise3"
  bottom: "Convolution9"
  top: "Eltwise4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "elu9"
  type: "ELU"
  bottom: "Eltwise4"
  top: "Eltwise4"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution10"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution10"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm10"
  type: "BatchNorm"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale10"
  type: "Scale"
  bottom: "Convolution10"
  top: "Convolution10"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "elu10"
  type: "ELU"
  bottom: "Convolution10"
  top: "Convolution10"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution11"
  type: "Convolution"
  bottom: "Convolution10"
  top: "Convolution11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm11"
  type: "BatchNorm"
  bottom: "Convolution11"
  top: "Convolution11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale11"
  type: "Scale"
  bottom: "Convolution11"
  top: "Convolution11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise5"
  type: "Eltwise"
  bottom: "Eltwise4"
  bottom: "Convolution11"
  top: "Eltwise5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "elu11"
  type: "ELU"
  bottom: "Eltwise5"
  top: "Eltwise5"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution12"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.25
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm12"
  type: "BatchNorm"
  bottom: "Convolution12"
  top: "Convolution12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale12"
  type: "Scale"
  bottom: "Convolution12"
  top: "Convolution12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution13"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution13"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm13"
  type: "BatchNorm"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale13"
  type: "Scale"
  bottom: "Convolution13"
  top: "Convolution13"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "elu12"
  type: "ELU"
  bottom: "Convolution13"
  top: "Convolution13"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution14"
  type: "Convolution"
  bottom: "Convolution13"
  top: "Convolution14"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm14"
  type: "BatchNorm"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale14"
  type: "Scale"
  bottom: "Convolution14"
  top: "Convolution14"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise6"
  type: "Eltwise"
  bottom: "Convolution12"
  bottom: "Convolution14"
  top: "Eltwise6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "elu13"
  type: "ELU"
  bottom: "Eltwise6"
  top: "Eltwise6"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution15"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution15"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm15"
  type: "BatchNorm"
  bottom: "Convolution15"
  top: "Convolution15"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale15"
  type: "Scale"
  bottom: "Convolution15"
  top: "Convolution15"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "elu14"
  type: "ELU"
  bottom: "Convolution15"
  top: "Convolution15"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution16"
  type: "Convolution"
  bottom: "Convolution15"
  top: "Convolution16"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm16"
  type: "BatchNorm"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale16"
  type: "Scale"
  bottom: "Convolution16"
  top: "Convolution16"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise7"
  type: "Eltwise"
  bottom: "Eltwise6"
  bottom: "Convolution16"
  top: "Eltwise7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "elu15"
  type: "ELU"
  bottom: "Eltwise7"
  top: "Eltwise7"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution17"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution17"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm17"
  type: "BatchNorm"
  bottom: "Convolution17"
  top: "Convolution17"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale17"
  type: "Scale"
  bottom: "Convolution17"
  top: "Convolution17"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "elu16"
  type: "ELU"
  bottom: "Convolution17"
  top: "Convolution17"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution18"
  type: "Convolution"
  bottom: "Convolution17"
  top: "Convolution18"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm18"
  type: "BatchNorm"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale18"
  type: "Scale"
  bottom: "Convolution18"
  top: "Convolution18"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise8"
  type: "Eltwise"
  bottom: "Eltwise7"
  bottom: "Convolution18"
  top: "Eltwise8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "elu17"
  type: "ELU"
  bottom: "Eltwise8"
  top: "Eltwise8"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution19"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution19"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm19"
  type: "BatchNorm"
  bottom: "Convolution19"
  top: "Convolution19"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale19"
  type: "Scale"
  bottom: "Convolution19"
  top: "Convolution19"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "elu18"
  type: "ELU"
  bottom: "Convolution19"
  top: "Convolution19"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution20"
  type: "Convolution"
  bottom: "Convolution19"
  top: "Convolution20"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm20"
  type: "BatchNorm"
  bottom: "Convolution20"
  top: "Convolution20"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale20"
  type: "Scale"
  bottom: "Convolution20"
  top: "Convolution20"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise9"
  type: "Eltwise"
  bottom: "Eltwise8"
  bottom: "Convolution20"
  top: "Eltwise9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "elu19"
  type: "ELU"
  bottom: "Eltwise9"
  top: "Eltwise9"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution21"
  type: "Convolution"
  bottom: "Eltwise9"
  top: "Convolution21"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm21"
  type: "BatchNorm"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale21"
  type: "Scale"
  bottom: "Convolution21"
  top: "Convolution21"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "elu20"
  type: "ELU"
  bottom: "Convolution21"
  top: "Convolution21"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution22"
  type: "Convolution"
  bottom: "Convolution21"
  top: "Convolution22"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm22"
  type: "BatchNorm"
  bottom: "Convolution22"
  top: "Convolution22"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale22"
  type: "Scale"
  bottom: "Convolution22"
  top: "Convolution22"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise10"
  type: "Eltwise"
  bottom: "Eltwise9"
  bottom: "Convolution22"
  top: "Eltwise10"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "elu21"
  type: "ELU"
  bottom: "Eltwise10"
  top: "Eltwise10"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution23"
  type: "Convolution"
  bottom: "Eltwise10"
  top: "Convolution23"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.17677669
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm23"
  type: "BatchNorm"
  bottom: "Convolution23"
  top: "Convolution23"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale23"
  type: "Scale"
  bottom: "Convolution23"
  top: "Convolution23"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution24"
  type: "Convolution"
  bottom: "Eltwise10"
  top: "Convolution24"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm24"
  type: "BatchNorm"
  bottom: "Convolution24"
  top: "Convolution24"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale24"
  type: "Scale"
  bottom: "Convolution24"
  top: "Convolution24"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "elu22"
  type: "ELU"
  bottom: "Convolution24"
  top: "Convolution24"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution25"
  type: "Convolution"
  bottom: "Convolution24"
  top: "Convolution25"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm25"
  type: "BatchNorm"
  bottom: "Convolution25"
  top: "Convolution25"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale25"
  type: "Scale"
  bottom: "Convolution25"
  top: "Convolution25"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise11"
  type: "Eltwise"
  bottom: "Convolution23"
  bottom: "Convolution25"
  top: "Eltwise11"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "elu23"
  type: "ELU"
  bottom: "Eltwise11"
  top: "Eltwise11"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution26"
  type: "Convolution"
  bottom: "Eltwise11"
  top: "Convolution26"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm26"
  type: "BatchNorm"
  bottom: "Convolution26"
  top: "Convolution26"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale26"
  type: "Scale"
  bottom: "Convolution26"
  top: "Convolution26"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "elu24"
  type: "ELU"
  bottom: "Convolution26"
  top: "Convolution26"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution27"
  type: "Convolution"
  bottom: "Convolution26"
  top: "Convolution27"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm27"
  type: "BatchNorm"
  bottom: "Convolution27"
  top: "Convolution27"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale27"
  type: "Scale"
  bottom: "Convolution27"
  top: "Convolution27"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise12"
  type: "Eltwise"
  bottom: "Eltwise11"
  bottom: "Convolution27"
  top: "Eltwise12"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "elu25"
  type: "ELU"
  bottom: "Eltwise12"
  top: "Eltwise12"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution28"
  type: "Convolution"
  bottom: "Eltwise12"
  top: "Convolution28"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm28"
  type: "BatchNorm"
  bottom: "Convolution28"
  top: "Convolution28"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale28"
  type: "Scale"
  bottom: "Convolution28"
  top: "Convolution28"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "elu26"
  type: "ELU"
  bottom: "Convolution28"
  top: "Convolution28"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution29"
  type: "Convolution"
  bottom: "Convolution28"
  top: "Convolution29"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm29"
  type: "BatchNorm"
  bottom: "Convolution29"
  top: "Convolution29"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale29"
  type: "Scale"
  bottom: "Convolution29"
  top: "Convolution29"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise13"
  type: "Eltwise"
  bottom: "Eltwise12"
  bottom: "Convolution29"
  top: "Eltwise13"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "elu27"
  type: "ELU"
  bottom: "Eltwise13"
  top: "Eltwise13"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution30"
  type: "Convolution"
  bottom: "Eltwise13"
  top: "Convolution30"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm30"
  type: "BatchNorm"
  bottom: "Convolution30"
  top: "Convolution30"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale30"
  type: "Scale"
  bottom: "Convolution30"
  top: "Convolution30"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "elu28"
  type: "ELU"
  bottom: "Convolution30"
  top: "Convolution30"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution31"
  type: "Convolution"
  bottom: "Convolution30"
  top: "Convolution31"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm31"
  type: "BatchNorm"
  bottom: "Convolution31"
  top: "Convolution31"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale
I1007 22:14:13.324190  5289 layer_factory.hpp:77] Creating layer Data1
I1007 22:14:13.324286  5289 db_lmdb.cpp:35] Opened lmdb /home/x306/caffe/xn/PENLU/data/cifar10/cifar10_train_lmdb
I1007 22:14:13.324311  5289 net.cpp:84] Creating Layer Data1
I1007 22:14:13.324318  5289 net.cpp:380] Data1 -> Data1
I1007 22:14:13.324340  5289 net.cpp:380] Data1 -> Data2
I1007 22:14:13.324352  5289 data_transformer.cpp:25] Loading mean file from: /home/x306/caffe/xn/PENLU/data/cifar10/mean.binaryproto
I1007 22:14:13.325742  5289 data_layer.cpp:45] output data size: 100,3,28,28
I1007 22:14:13.328029  5289 net.cpp:122] Setting up Data1
I1007 22:14:13.328042  5289 net.cpp:129] Top shape: 100 3 28 28 (235200)
I1007 22:14:13.328047  5289 net.cpp:129] Top shape: 100 (100)
I1007 22:14:13.328048  5289 net.cpp:137] Memory required for data: 941200
I1007 22:14:13.328054  5289 layer_factory.hpp:77] Creating layer Convolution1
I1007 22:14:13.328073  5289 net.cpp:84] Creating Layer Convolution1
I1007 22:14:13.328078  5289 net.cpp:406] Convolution1 <- Data1
I1007 22:14:13.328085  5289 net.cpp:380] Convolution1 -> Convolution1
I1007 22:14:13.474184  5289 net.cpp:122] Setting up Convolution1
I1007 22:14:13.474217  5289 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:14:13.474221  5289 net.cpp:137] Memory required for data: 5958800
I1007 22:14:13.474237  5289 layer_factory.hpp:77] Creating layer BatchNorm1
I1007 22:14:13.474261  5289 net.cpp:84] Creating Layer BatchNorm1
I1007 22:14:13.474278  5289 net.cpp:406] BatchNorm1 <- Convolution1
I1007 22:14:13.474311  5289 net.cpp:367] BatchNorm1 -> Convolution1 (in-place)
I1007 22:14:13.474474  5289 net.cpp:122] Setting up BatchNorm1
I1007 22:14:13.474480  5289 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:14:13.474493  5289 net.cpp:137] Memory required for data: 10976400
I1007 22:14:13.474500  5289 layer_factory.hpp:77] Creating layer Scale1
I1007 22:14:13.474524  5289 net.cpp:84] Creating Layer Scale1
I1007 22:14:13.474526  5289 net.cpp:406] Scale1 <- Convolution1
I1007 22:14:13.474530  5289 net.cpp:367] Scale1 -> Convolution1 (in-place)
I1007 22:14:13.474591  5289 layer_factory.hpp:77] Creating layer Scale1
I1007 22:14:13.474737  5289 net.cpp:122] Setting up Scale1
I1007 22:14:13.474742  5289 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:14:13.474745  5289 net.cpp:137] Memory required for data: 15994000
I1007 22:14:13.474750  5289 layer_factory.hpp:77] Creating layer elu1
I1007 22:14:13.474753  5289 net.cpp:84] Creating Layer elu1
I1007 22:14:13.474756  5289 net.cpp:406] elu1 <- Convolution1
I1007 22:14:13.474759  5289 net.cpp:367] elu1 -> Convolution1 (in-place)
I1007 22:14:13.474777  5289 net.cpp:122] Setting up elu1
I1007 22:14:13.474781  5289 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:14:13.474797  5289 net.cpp:137] Memory required for data: 21011600
I1007 22:14:13.474800  5289 layer_factory.hpp:77] Creating layer Convolution1_elu1_0_split
I1007 22:14:13.474815  5289 net.cpp:84] Creating Layer Convolution1_elu1_0_split
I1007 22:14:13.474818  5289 net.cpp:406] Convolution1_elu1_0_split <- Convolution1
I1007 22:14:13.474822  5289 net.cpp:380] Convolution1_elu1_0_split -> Convolution1_elu1_0_split_0
I1007 22:14:13.474839  5289 net.cpp:380] Convolution1_elu1_0_split -> Convolution1_elu1_0_split_1
I1007 22:14:13.474881  5289 net.cpp:122] Setting up Convolution1_elu1_0_split
I1007 22:14:13.474895  5289 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:14:13.474897  5289 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:14:13.474910  5289 net.cpp:137] Memory required for data: 31046800
I1007 22:14:13.474911  5289 layer_factory.hpp:77] Creating layer Convolution2
I1007 22:14:13.474920  5289 net.cpp:84] Creating Layer Convolution2
I1007 22:14:13.474923  5289 net.cpp:406] Convolution2 <- Convolution1_elu1_0_split_0
I1007 22:14:13.474930  5289 net.cpp:380] Convolution2 -> Convolution2
I1007 22:14:13.475797  5289 net.cpp:122] Setting up Convolution2
I1007 22:14:13.475816  5289 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:14:13.475821  5289 net.cpp:137] Memory required for data: 36064400
I1007 22:14:13.475841  5289 layer_factory.hpp:77] Creating layer BatchNorm2
I1007 22:14:13.475848  5289 net.cpp:84] Creating Layer BatchNorm2
I1007 22:14:13.475853  5289 net.cpp:406] BatchNorm2 <- Convolution2
I1007 22:14:13.475859  5289 net.cpp:367] BatchNorm2 -> Convolution2 (in-place)
I1007 22:14:13.476009  5289 net.cpp:122] Setting up BatchNorm2
I1007 22:14:13.476016  5289 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:14:13.476018  5289 net.cpp:137] Memory required for data: 41082000
I1007 22:14:13.476034  5289 layer_factory.hpp:77] Creating layer Scale2
I1007 22:14:13.476056  5289 net.cpp:84] Creating Layer Scale2
I1007 22:14:13.476059  5289 net.cpp:406] Scale2 <- Convolution2
I1007 22:14:13.476063  5289 net.cpp:367] Scale2 -> Convolution2 (in-place)
I1007 22:14:13.476097  5289 layer_factory.hpp:77] Creating layer Scale2
I1007 22:14:13.476220  5289 net.cpp:122] Setting up Scale2
I1007 22:14:13.476225  5289 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:14:13.476228  5289 net.cpp:137] Memory required for data: 46099600
I1007 22:14:13.476243  5289 layer_factory.hpp:77] Creating layer elu2
I1007 22:14:13.476246  5289 net.cpp:84] Creating Layer elu2
I1007 22:14:13.476261  5289 net.cpp:406] elu2 <- Convolution2
I1007 22:14:13.476264  5289 net.cpp:367] elu2 -> Convolution2 (in-place)
I1007 22:14:13.476269  5289 net.cpp:122] Setting up elu2
I1007 22:14:13.476276  5289 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:14:13.476296  5289 net.cpp:137] Memory required for data: 51117200
I1007 22:14:13.476300  5289 layer_factory.hpp:77] Creating layer Convolution3
I1007 22:14:13.476318  5289 net.cpp:84] Creating Layer Convolution3
I1007 22:14:13.476321  5289 net.cpp:406] Convolution3 <- Convolution2
I1007 22:14:13.476326  5289 net.cpp:380] Convolution3 -> Convolution3
I1007 22:14:13.477149  5289 net.cpp:122] Setting up Convolution3
I1007 22:14:13.477159  5289 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:14:13.477165  5289 net.cpp:137] Memory required for data: 56134800
I1007 22:14:13.477172  5289 layer_factory.hpp:77] Creating layer BatchNorm3
I1007 22:14:13.477180  5289 net.cpp:84] Creating Layer BatchNorm3
I1007 22:14:13.477183  5289 net.cpp:406] BatchNorm3 <- Convolution3
I1007 22:14:13.477190  5289 net.cpp:367] BatchNorm3 -> Convolution3 (in-place)
I1007 22:14:13.477304  5289 net.cpp:122] Setting up BatchNorm3
I1007 22:14:13.477310  5289 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:14:13.477314  5289 net.cpp:137] Memory required for data: 61152400
I1007 22:14:13.477324  5289 layer_factory.hpp:77] Creating layer Scale3
I1007 22:14:13.477329  5289 net.cpp:84] Creating Layer Scale3
I1007 22:14:13.477334  5289 net.cpp:406] Scale3 <- Convolution3
I1007 22:14:13.477339  5289 net.cpp:367] Scale3 -> Convolution3 (in-place)
I1007 22:14:13.477365  5289 layer_factory.hpp:77] Creating layer Scale3
I1007 22:14:13.477437  5289 net.cpp:122] Setting up Scale3
I1007 22:14:13.477443  5289 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:14:13.477447  5289 net.cpp:137] Memory required for data: 66170000
I1007 22:14:13.477454  5289 layer_factory.hpp:77] Creating layer Eltwise1
I1007 22:14:13.477459  5289 net.cpp:84] Creating Layer Eltwise1
I1007 22:14:13.477463  5289 net.cpp:406] Eltwise1 <- Convolution1_elu1_0_split_1
I1007 22:14:13.477468  5289 net.cpp:406] Eltwise1 <- Convolution3
I1007 22:14:13.477473  5289 net.cpp:380] Eltwise1 -> Eltwise1
I1007 22:14:13.477494  5289 net.cpp:122] Setting up Eltwise1
I1007 22:14:13.477497  5289 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:14:13.477502  5289 net.cpp:137] Memory required for data: 71187600
I1007 22:14:13.477506  5289 layer_factory.hpp:77] Creating layer elu3
I1007 22:14:13.477511  5289 net.cpp:84] Creating Layer elu3
I1007 22:14:13.477515  5289 net.cpp:406] elu3 <- Eltwise1
I1007 22:14:13.477520  5289 net.cpp:367] elu3 -> Eltwise1 (in-place)
I1007 22:14:13.477525  5289 net.cpp:122] Setting up elu3
I1007 22:14:13.477530  5289 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:14:13.477535  5289 net.cpp:137] Memory required for data: 76205200
I1007 22:14:13.477538  5289 layer_factory.hpp:77] Creating layer Eltwise1_elu3_0_split
I1007 22:14:13.477545  5289 net.cpp:84] Creating Layer Eltwise1_elu3_0_split
I1007 22:14:13.477547  5289 net.cpp:406] Eltwise1_elu3_0_split <- Eltwise1
I1007 22:14:13.477551  5289 net.cpp:380] Eltwise1_elu3_0_split -> Eltwise1_elu3_0_split_0
I1007 22:14:13.477558  5289 net.cpp:380] Eltwise1_elu3_0_split -> Eltwise1_elu3_0_split_1
I1007 22:14:13.477581  5289 net.cpp:122] Setting up Eltwise1_elu3_0_split
I1007 22:14:13.477586  5289 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:14:13.477591  5289 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:14:13.477594  5289 net.cpp:137] Memory required for data: 86240400
I1007 22:14:13.477597  5289 layer_factory.hpp:77] Creating layer Convolution4
I1007 22:14:13.477607  5289 net.cpp:84] Creating Layer Convolution4
I1007 22:14:13.477610  5289 net.cpp:406] Convolution4 <- Eltwise1_elu3_0_split_0
I1007 22:14:13.477615  5289 net.cpp:380] Convolution4 -> Convolution4
I1007 22:14:13.478435  5289 net.cpp:122] Setting up Convolution4
I1007 22:14:13.478446  5289 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:14:13.478451  5289 net.cpp:137] Memory required for data: 91258000
I1007 22:14:13.478457  5289 layer_factory.hpp:77] Creating layer BatchNorm4
I1007 22:14:13.478464  5289 net.cpp:84] Creating Layer BatchNorm4
I1007 22:14:13.478468  5289 net.cpp:406] BatchNorm4 <- Convolution4
I1007 22:14:13.478482  5289 net.cpp:367] BatchNorm4 -> Convolution4 (in-place)
I1007 22:14:13.478596  5289 net.cpp:122] Setting up BatchNorm4
I1007 22:14:13.478602  5289 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:14:13.478607  5289 net.cpp:137] Memory required for data: 96275600
I1007 22:14:13.478615  5289 layer_factory.hpp:77] Creating layer Scale4
I1007 22:14:13.478621  5289 net.cpp:84] Creating Layer Scale4
I1007 22:14:13.478624  5289 net.cpp:406] Scale4 <- Convolution4
I1007 22:14:13.478631  5289 net.cpp:367] Scale4 -> Convolution4 (in-place)
I1007 22:14:13.478657  5289 layer_factory.hpp:77] Creating layer Scale4
I1007 22:14:13.478725  5289 net.cpp:122] Setting up Scale4
I1007 22:14:13.478731  5289 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:14:13.478735  5289 net.cpp:137] Memory required for data: 101293200
I1007 22:14:13.478741  5289 layer_factory.hpp:77] Creating layer elu4
I1007 22:14:13.478746  5289 net.cpp:84] Creating Layer elu4
I1007 22:14:13.478750  5289 net.cpp:406] elu4 <- Convolution4
I1007 22:14:13.478755  5289 net.cpp:367] elu4 -> Convolution4 (in-place)
I1007 22:14:13.478761  5289 net.cpp:122] Setting up elu4
I1007 22:14:13.478765  5289 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:14:13.478770  5289 net.cpp:137] Memory required for data: 106310800
I1007 22:14:13.478773  5289 layer_factory.hpp:77] Creating layer Convolution5
I1007 22:14:13.478781  5289 net.cpp:84] Creating Layer Convolution5
I1007 22:14:13.478785  5289 net.cpp:406] Convolution5 <- Convolution4
I1007 22:14:13.478790  5289 net.cpp:380] Convolution5 -> Convolution5
I1007 22:14:13.479634  5289 net.cpp:122] Setting up Convolution5
I1007 22:14:13.479643  5289 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:14:13.479650  5289 net.cpp:137] Memory required for data: 111328400
I1007 22:14:13.479656  5289 layer_factory.hpp:77] Creating layer BatchNorm5
I1007 22:14:13.479663  5289 net.cpp:84] Creating Layer BatchNorm5
I1007 22:14:13.479667  5289 net.cpp:406] BatchNorm5 <- Convolution5
I1007 22:14:13.479673  5289 net.cpp:367] BatchNorm5 -> Convolution5 (in-place)
I1007 22:14:13.479790  5289 net.cpp:122] Setting up BatchNorm5
I1007 22:14:13.479796  5289 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:14:13.479800  5289 net.cpp:137] Memory required for data: 116346000
I1007 22:14:13.479811  5289 layer_factory.hpp:77] Creating layer Scale5
I1007 22:14:13.479816  5289 net.cpp:84] Creating Layer Scale5
I1007 22:14:13.479820  5289 net.cpp:406] Scale5 <- Convolution5
I1007 22:14:13.479825  5289 net.cpp:367] Scale5 -> Convolution5 (in-place)
I1007 22:14:13.479852  5289 layer_factory.hpp:77] Creating layer Scale5
I1007 22:14:13.479923  5289 net.cpp:122] Setting up Scale5
I1007 22:14:13.479928  5289 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:14:13.479933  5289 net.cpp:137] Memory required for data: 121363600
I1007 22:14:13.479939  5289 layer_factory.hpp:77] Creating layer Eltwise2
I1007 22:14:13.479945  5289 net.cpp:84] Creating Layer Eltwise2
I1007 22:14:13.479949  5289 net.cpp:406] Eltwise2 <- Eltwise1_elu3_0_split_1
I1007 22:14:13.479954  5289 net.cpp:406] Eltwise2 <- Convolution5
I1007 22:14:13.479959  5289 net.cpp:380] Eltwise2 -> Eltwise2
I1007 22:14:13.479976  5289 net.cpp:122] Setting up Eltwise2
I1007 22:14:13.479981  5289 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:14:13.479985  5289 net.cpp:137] Memory required for data: 126381200
I1007 22:14:13.479990  5289 layer_factory.hpp:77] Creating layer elu5
I1007 22:14:13.479995  5289 net.cpp:84] Creating Layer elu5
I1007 22:14:13.480000  5289 net.cpp:406] elu5 <- Eltwise2
I1007 22:14:13.480003  5289 net.cpp:367] elu5 -> Eltwise2 (in-place)
I1007 22:14:13.480010  5289 net.cpp:122] Setting up elu5
I1007 22:14:13.480013  5289 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:14:13.480017  5289 net.cpp:137] Memory required for data: 131398800
I1007 22:14:13.480021  5289 layer_factory.hpp:77] Creating layer Eltwise2_elu5_0_split
I1007 22:14:13.480026  5289 net.cpp:84] Creating Layer Eltwise2_elu5_0_split
I1007 22:14:13.480031  5289 net.cpp:406] Eltwise2_elu5_0_split <- Eltwise2
I1007 22:14:13.480042  5289 net.cpp:380] Eltwise2_elu5_0_split -> Eltwise2_elu5_0_split_0
I1007 22:14:13.480049  5289 net.cpp:380] Eltwise2_elu5_0_split -> Eltwise2_elu5_0_split_1
I1007 22:14:13.480072  5289 net.cpp:122] Setting up Eltwise2_elu5_0_split
I1007 22:14:13.480077  5289 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:14:13.480082  5289 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:14:13.480087  5289 net.cpp:137] Memory required for data: 141434000
I1007 22:14:13.480089  5289 layer_factory.hpp:77] Creating layer Convolution6
I1007 22:14:13.480098  5289 net.cpp:84] Creating Layer Convolution6
I1007 22:14:13.480101  5289 net.cpp:406] Convolution6 <- Eltwise2_elu5_0_split_0
I1007 22:14:13.480108  5289 net.cpp:380] Convolution6 -> Convolution6
I1007 22:14:13.480928  5289 net.cpp:122] Setting up Convolution6
I1007 22:14:13.480939  5289 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:14:13.480944  5289 net.cpp:137] Memory required for data: 146451600
I1007 22:14:13.480952  5289 layer_factory.hpp:77] Creating layer BatchNorm6
I1007 22:14:13.480958  5289 net.cpp:84] Creating Layer BatchNorm6
I1007 22:14:13.480962  5289 net.cpp:406] BatchNorm6 <- Convolution6
I1007 22:14:13.480968  5289 net.cpp:367] BatchNorm6 -> Convolution6 (in-place)
I1007 22:14:13.481088  5289 net.cpp:122] Setting up BatchNorm6
I1007 22:14:13.481094  5289 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:14:13.481098  5289 net.cpp:137] Memory required for data: 151469200
I1007 22:14:13.481106  5289 layer_factory.hpp:77] Creating layer Scale6
I1007 22:14:13.481112  5289 net.cpp:84] Creating Layer Scale6
I1007 22:14:13.481115  5289 net.cpp:406] Scale6 <- Convolution6
I1007 22:14:13.481122  5289 net.cpp:367] Scale6 -> Convolution6 (in-place)
I1007 22:14:13.481148  5289 layer_factory.hpp:77] Creating layer Scale6
I1007 22:14:13.481218  5289 net.cpp:122] Setting up Scale6
I1007 22:14:13.481225  5289 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:14:13.481228  5289 net.cpp:137] Memory required for data: 156486800
I1007 22:14:13.481235  5289 layer_factory.hpp:77] Creating layer elu6
I1007 22:14:13.481240  5289 net.cpp:84] Creating Layer elu6
I1007 22:14:13.481245  5289 net.cpp:406] elu6 <- Convolution6
I1007 22:14:13.481250  5289 net.cpp:367] elu6 -> Convolution6 (in-place)
I1007 22:14:13.481256  5289 net.cpp:122] Setting up elu6
I1007 22:14:13.481261  5289 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:14:13.481264  5289 net.cpp:137] Memory required for data: 161504400
I1007 22:14:13.481267  5289 layer_factory.hpp:77] Creating layer Convolution7
I1007 22:14:13.481276  5289 net.cpp:84] Creating Layer Convolution7
I1007 22:14:13.481279  5289 net.cpp:406] Convolution7 <- Convolution6
I1007 22:14:13.481284  5289 net.cpp:380] Convolution7 -> Convolution7
I1007 22:14:13.481789  5289 net.cpp:122] Setting up Convolution7
I1007 22:14:13.481798  5289 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:14:13.481803  5289 net.cpp:137] Memory required for data: 166522000
I1007 22:14:13.481811  5289 layer_factory.hpp:77] Creating layer BatchNorm7
I1007 22:14:13.481817  5289 net.cpp:84] Creating Layer BatchNorm7
I1007 22:14:13.481820  5289 net.cpp:406] BatchNorm7 <- Convolution7
I1007 22:14:13.481825  5289 net.cpp:367] BatchNorm7 -> Convolution7 (in-place)
I1007 22:14:13.481945  5289 net.cpp:122] Setting up BatchNorm7
I1007 22:14:13.481951  5289 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:14:13.481956  5289 net.cpp:137] Memory required for data: 171539600
I1007 22:14:13.481963  5289 layer_factory.hpp:77] Creating layer Scale7
I1007 22:14:13.481971  5289 net.cpp:84] Creating Layer Scale7
I1007 22:14:13.481973  5289 net.cpp:406] Scale7 <- Convolution7
I1007 22:14:13.481978  5289 net.cpp:367] Scale7 -> Convolution7 (in-place)
I1007 22:14:13.482004  5289 layer_factory.hpp:77] Creating layer Scale7
I1007 22:14:13.482076  5289 net.cpp:122] Setting up Scale7
I1007 22:14:13.482081  5289 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:14:13.482085  5289 net.cpp:137] Memory required for data: 176557200
I1007 22:14:13.482100  5289 layer_factory.hpp:77] Creating layer Eltwise3
I1007 22:14:13.482105  5289 net.cpp:84] Creating Layer Eltwise3
I1007 22:14:13.482110  5289 net.cpp:406] Eltwise3 <- Eltwise2_elu5_0_split_1
I1007 22:14:13.482115  5289 net.cpp:406] Eltwise3 <- Convolution7
I1007 22:14:13.482120  5289 net.cpp:380] Eltwise3 -> Eltwise3
I1007 22:14:13.482137  5289 net.cpp:122] Setting up Eltwise3
I1007 22:14:13.482142  5289 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:14:13.482146  5289 net.cpp:137] Memory required for data: 181574800
I1007 22:14:13.482149  5289 layer_factory.hpp:77] Creating layer elu7
I1007 22:14:13.482156  5289 net.cpp:84] Creating Layer elu7
I1007 22:14:13.482159  5289 net.cpp:406] elu7 <- Eltwise3
I1007 22:14:13.482163  5289 net.cpp:367] elu7 -> Eltwise3 (in-place)
I1007 22:14:13.482169  5289 net.cpp:122] Setting up elu7
I1007 22:14:13.482173  5289 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:14:13.482177  5289 net.cpp:137] Memory required for data: 186592400
I1007 22:14:13.482180  5289 layer_factory.hpp:77] Creating layer Eltwise3_elu7_0_split
I1007 22:14:13.482185  5289 net.cpp:84] Creating Layer Eltwise3_elu7_0_split
I1007 22:14:13.482189  5289 net.cpp:406] Eltwise3_elu7_0_split <- Eltwise3
I1007 22:14:13.482194  5289 net.cpp:380] Eltwise3_elu7_0_split -> Eltwise3_elu7_0_split_0
I1007 22:14:13.482199  5289 net.cpp:380] Eltwise3_elu7_0_split -> Eltwise3_elu7_0_split_1
I1007 22:14:13.482223  5289 net.cpp:122] Setting up Eltwise3_elu7_0_split
I1007 22:14:13.482228  5289 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:14:13.482233  5289 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:14:13.482236  5289 net.cpp:137] Memory required for data: 196627600
I1007 22:14:13.482239  5289 layer_factory.hpp:77] Creating layer Convolution8
I1007 22:14:13.482247  5289 net.cpp:84] Creating Layer Convolution8
I1007 22:14:13.482251  5289 net.cpp:406] Convolution8 <- Eltwise3_elu7_0_split_0
I1007 22:14:13.482256  5289 net.cpp:380] Convolution8 -> Convolution8
I1007 22:14:13.483069  5289 net.cpp:122] Setting up Convolution8
I1007 22:14:13.483079  5289 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:14:13.483084  5289 net.cpp:137] Memory required for data: 201645200
I1007 22:14:13.483093  5289 layer_factory.hpp:77] Creating layer BatchNorm8
I1007 22:14:13.483098  5289 net.cpp:84] Creating Layer BatchNorm8
I1007 22:14:13.483103  5289 net.cpp:406] BatchNorm8 <- Convolution8
I1007 22:14:13.483108  5289 net.cpp:367] BatchNorm8 -> Convolution8 (in-place)
I1007 22:14:13.483255  5289 net.cpp:122] Setting up BatchNorm8
I1007 22:14:13.483261  5289 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:14:13.483265  5289 net.cpp:137] Memory required for data: 206662800
I1007 22:14:13.483273  5289 layer_factory.hpp:77] Creating layer Scale8
I1007 22:14:13.483279  5289 net.cpp:84] Creating Layer Scale8
I1007 22:14:13.483283  5289 net.cpp:406] Scale8 <- Convolution8
I1007 22:14:13.483289  5289 net.cpp:367] Scale8 -> Convolution8 (in-place)
I1007 22:14:13.483316  5289 layer_factory.hpp:77] Creating layer Scale8
I1007 22:14:13.483389  5289 net.cpp:122] Setting up Scale8
I1007 22:14:13.483394  5289 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:14:13.483398  5289 net.cpp:137] Memory required for data: 211680400
I1007 22:14:13.483404  5289 layer_factory.hpp:77] Creating layer elu8
I1007 22:14:13.483409  5289 net.cpp:84] Creating Layer elu8
I1007 22:14:13.483414  5289 net.cpp:406] elu8 <- Convolution8
I1007 22:14:13.483419  5289 net.cpp:367] elu8 -> Convolution8 (in-place)
I1007 22:14:13.483425  5289 net.cpp:122] Setting up elu8
I1007 22:14:13.483430  5289 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:14:13.483434  5289 net.cpp:137] Memory required for data: 216698000
I1007 22:14:13.483438  5289 layer_factory.hpp:77] Creating layer Convolution9
I1007 22:14:13.483448  5289 net.cpp:84] Creating Layer Convolution9
I1007 22:14:13.483450  5289 net.cpp:406] Convolution9 <- Convolution8
I1007 22:14:13.483455  5289 net.cpp:380] Convolution9 -> Convolution9
I1007 22:14:13.484295  5289 net.cpp:122] Setting up Convolution9
I1007 22:14:13.484305  5289 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:14:13.484310  5289 net.cpp:137] Memory required for data: 221715600
I1007 22:14:13.484318  5289 layer_factory.hpp:77] Creating layer BatchNorm9
I1007 22:14:13.484324  5289 net.cpp:84] Creating Layer BatchNorm9
I1007 22:14:13.484328  5289 net.cpp:406] BatchNorm9 <- Convolution9
I1007 22:14:13.484334  5289 net.cpp:367] BatchNorm9 -> Convolution9 (in-place)
I1007 22:14:13.484458  5289 net.cpp:122] Setting up BatchNorm9
I1007 22:14:13.484463  5289 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:14:13.484468  5289 net.cpp:137] Memory required for data: 226733200
I1007 22:14:13.484477  5289 layer_factory.hpp:77] Creating layer Scale9
I1007 22:14:13.484482  5289 net.cpp:84] Creating Layer Scale9
I1007 22:14:13.484485  5289 net.cpp:406] Scale9 <- Convolution9
I1007 22:14:13.484491  5289 net.cpp:367] Scale9 -> Convolution9 (in-place)
I1007 22:14:13.484519  5289 layer_factory.hpp:77] Creating layer Scale9
I1007 22:14:13.484599  5289 net.cpp:122] Setting up Scale9
I1007 22:14:13.484606  5289 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:14:13.484609  5289 net.cpp:137] Memory required for data: 231750800
I1007 22:14:13.484616  5289 layer_factory.hpp:77] Creating layer Eltwise4
I1007 22:14:13.484622  5289 net.cpp:84] Creating Layer Eltwise4
I1007 22:14:13.484627  5289 net.cpp:406] Eltwise4 <- Eltwise3_elu7_0_split_1
I1007 22:14:13.484630  5289 net.cpp:406] Eltwise4 <- Convolution9
I1007 22:14:13.484637  5289 net.cpp:380] Eltwise4 -> Eltwise4
I1007 22:14:13.484653  5289 net.cpp:122] Setting up Eltwise4
I1007 22:14:13.484658  5289 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:14:13.484663  5289 net.cpp:137] Memory required for data: 236768400
I1007 22:14:13.484665  5289 layer_factory.hpp:77] Creating layer elu9
I1007 22:14:13.484673  5289 net.cpp:84] Creating Layer elu9
I1007 22:14:13.484675  5289 net.cpp:406] elu9 <- Eltwise4
I1007 22:14:13.484679  5289 net.cpp:367] elu9 -> Eltwise4 (in-place)
I1007 22:14:13.484685  5289 net.cpp:122] Setting up elu9
I1007 22:14:13.484689  5289 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:14:13.484694  5289 net.cpp:137] Memory required for data: 241786000
I1007 22:14:13.484697  5289 layer_factory.hpp:77] Creating layer Eltwise4_elu9_0_split
I1007 22:14:13.484702  5289 net.cpp:84] Creating Layer Eltwise4_elu9_0_split
I1007 22:14:13.484705  5289 net.cpp:406] Eltwise4_elu9_0_split <- Eltwise4
I1007 22:14:13.484711  5289 net.cpp:380] Eltwise4_elu9_0_split -> Eltwise4_elu9_0_split_0
I1007 22:14:13.484715  5289 net.cpp:380] Eltwise4_elu9_0_split -> Eltwise4_elu9_0_split_1
I1007 22:14:13.484736  5289 net.cpp:122] Setting up Eltwise4_elu9_0_split
I1007 22:14:13.484740  5289 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:14:13.484743  5289 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:14:13.484745  5289 net.cpp:137] Memory required for data: 251821200
I1007 22:14:13.484747  5289 layer_factory.hpp:77] Creating layer Convolution10
I1007 22:14:13.484753  5289 net.cpp:84] Creating Layer Convolution10
I1007 22:14:13.484756  5289 net.cpp:406] Convolution10 <- Eltwise4_elu9_0_split_0
I1007 22:14:13.484760  5289 net.cpp:380] Convolution10 -> Convolution10
I1007 22:14:13.485630  5289 net.cpp:122] Setting up Convolution10
I1007 22:14:13.485637  5289 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:14:13.485641  5289 net.cpp:137] Memory required for data: 256838800
I1007 22:14:13.485651  5289 layer_factory.hpp:77] Creating layer BatchNorm10
I1007 22:14:13.485656  5289 net.cpp:84] Creating Layer BatchNorm10
I1007 22:14:13.485658  5289 net.cpp:406] BatchNorm10 <- Convolution10
I1007 22:14:13.485663  5289 net.cpp:367] BatchNorm10 -> Convolution10 (in-place)
I1007 22:14:13.485792  5289 net.cpp:122] Setting up BatchNorm10
I1007 22:14:13.485796  5289 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:14:13.485798  5289 net.cpp:137] Memory required for data: 261856400
I1007 22:14:13.485803  5289 layer_factory.hpp:77] Creating layer Scale10
I1007 22:14:13.485815  5289 net.cpp:84] Creating Layer Scale10
I1007 22:14:13.485816  5289 net.cpp:406] Scale10 <- Convolution10
I1007 22:14:13.485821  5289 net.cpp:367] Scale10 -> Convolution10 (in-place)
I1007 22:14:13.485847  5289 layer_factory.hpp:77] Creating layer Scale10
I1007 22:14:13.485924  5289 net.cpp:122] Setting up Scale10
I1007 22:14:13.485927  5289 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:14:13.485929  5289 net.cpp:137] Memory required for data: 266874000
I1007 22:14:13.485934  5289 layer_factory.hpp:77] Creating layer elu10
I1007 22:14:13.485936  5289 net.cpp:84] Creating Layer elu10
I1007 22:14:13.485939  5289 net.cpp:406] elu10 <- Convolution10
I1007 22:14:13.485941  5289 net.cpp:367] elu10 -> Convolution10 (in-place)
I1007 22:14:13.485945  5289 net.cpp:122] Setting up elu10
I1007 22:14:13.485949  5289 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:14:13.485950  5289 net.cpp:137] Memory required for data: 271891600
I1007 22:14:13.485952  5289 layer_factory.hpp:77] Creating layer Convolution11
I1007 22:14:13.485960  5289 net.cpp:84] Creating Layer Convolution11
I1007 22:14:13.485963  5289 net.cpp:406] Convolution11 <- Convolution10
I1007 22:14:13.485966  5289 net.cpp:380] Convolution11 -> Convolution11
I1007 22:14:13.486989  5289 net.cpp:122] Setting up Convolution11
I1007 22:14:13.486999  5289 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:14:13.487001  5289 net.cpp:137] Memory required for data: 276909200
I1007 22:14:13.487005  5289 layer_factory.hpp:77] Creating layer BatchNorm11
I1007 22:14:13.487010  5289 net.cpp:84] Creating Layer BatchNorm11
I1007 22:14:13.487023  5289 net.cpp:406] BatchNorm11 <- Convolution11
I1007 22:14:13.487030  5289 net.cpp:367] BatchNorm11 -> Convolution11 (in-place)
I1007 22:14:13.487195  5289 net.cpp:122] Setting up BatchNorm11
I1007 22:14:13.487200  5289 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:14:13.487203  5289 net.cpp:137] Memory required for data: 281926800
I1007 22:14:13.487207  5289 layer_factory.hpp:77] Creating layer Scale11
I1007 22:14:13.487212  5289 net.cpp:84] Creating Layer Scale11
I1007 22:14:13.487226  5289 net.cpp:406] Scale11 <- Convolution11
I1007 22:14:13.487229  5289 net.cpp:367] Scale11 -> Convolution11 (in-place)
I1007 22:14:13.487264  5289 layer_factory.hpp:77] Creating layer Scale11
I1007 22:14:13.487365  5289 net.cpp:122] Setting up Scale11
I1007 22:14:13.487370  5289 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:14:13.487372  5289 net.cpp:137] Memory required for data: 286944400
I1007 22:14:13.487375  5289 layer_factory.hpp:77] Creating layer Eltwise5
I1007 22:14:13.487380  5289 net.cpp:84] Creating Layer Eltwise5
I1007 22:14:13.487382  5289 net.cpp:406] Eltwise5 <- Eltwise4_elu9_0_split_1
I1007 22:14:13.487397  5289 net.cpp:406] Eltwise5 <- Convolution11
I1007 22:14:13.487401  5289 net.cpp:380] Eltwise5 -> Eltwise5
I1007 22:14:13.487416  5289 net.cpp:122] Setting up Eltwise5
I1007 22:14:13.487419  5289 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:14:13.487422  5289 net.cpp:137] Memory required for data: 291962000
I1007 22:14:13.487433  5289 layer_factory.hpp:77] Creating layer elu11
I1007 22:14:13.487438  5289 net.cpp:84] Creating Layer elu11
I1007 22:14:13.487452  5289 net.cpp:406] elu11 <- Eltwise5
I1007 22:14:13.487455  5289 net.cpp:367] elu11 -> Eltwise5 (in-place)
I1007 22:14:13.487462  5289 net.cpp:122] Setting up elu11
I1007 22:14:13.487468  5289 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:14:13.487479  5289 net.cpp:137] Memory required for data: 296979600
I1007 22:14:13.487483  5289 layer_factory.hpp:77] Creating layer Eltwise5_elu11_0_split
I1007 22:14:13.487489  5289 net.cpp:84] Creating Layer Eltwise5_elu11_0_split
I1007 22:14:13.487493  5289 net.cpp:406] Eltwise5_elu11_0_split <- Eltwise5
I1007 22:14:13.487498  5289 net.cpp:380] Eltwise5_elu11_0_split -> Eltwise5_elu11_0_split_0
I1007 22:14:13.487504  5289 net.cpp:380] Eltwise5_elu11_0_split -> Eltwise5_elu11_0_split_1
I1007 22:14:13.487529  5289 net.cpp:122] Setting up Eltwise5_elu11_0_split
I1007 22:14:13.487540  5289 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:14:13.487545  5289 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:14:13.487550  5289 net.cpp:137] Memory required for data: 307014800
I1007 22:14:13.487553  5289 layer_factory.hpp:77] Creating layer Convolution12
I1007 22:14:13.487562  5289 net.cpp:84] Creating Layer Convolution12
I1007 22:14:13.487565  5289 net.cpp:406] Convolution12 <- Eltwise5_elu11_0_split_0
I1007 22:14:13.487572  5289 net.cpp:380] Convolution12 -> Convolution12
I1007 22:14:13.488822  5289 net.cpp:122] Setting up Convolution12
I1007 22:14:13.488832  5289 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:14:13.488837  5289 net.cpp:137] Memory required for data: 309523600
I1007 22:14:13.488844  5289 layer_factory.hpp:77] Creating layer BatchNorm12
I1007 22:14:13.488850  5289 net.cpp:84] Creating Layer BatchNorm12
I1007 22:14:13.488854  5289 net.cpp:406] BatchNorm12 <- Convolution12
I1007 22:14:13.488860  5289 net.cpp:367] BatchNorm12 -> Convolution12 (in-place)
I1007 22:14:13.488996  5289 net.cpp:122] Setting up BatchNorm12
I1007 22:14:13.489001  5289 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:14:13.489006  5289 net.cpp:137] Memory required for data: 312032400
I1007 22:14:13.489014  5289 layer_factory.hpp:77] Creating layer Scale12
I1007 22:14:13.489019  5289 net.cpp:84] Creating Layer Scale12
I1007 22:14:13.489023  5289 net.cpp:406] Scale12 <- Convolution12
I1007 22:14:13.489028  5289 net.cpp:367] Scale12 -> Convolution12 (in-place)
I1007 22:14:13.489058  5289 layer_factory.hpp:77] Creating layer Scale12
I1007 22:14:13.489131  5289 net.cpp:122] Setting up Scale12
I1007 22:14:13.489137  5289 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:14:13.489141  5289 net.cpp:137] Memory required for data: 314541200
I1007 22:14:13.489147  5289 layer_factory.hpp:77] Creating layer Convolution13
I1007 22:14:13.489156  5289 net.cpp:84] Creating Layer Convolution13
I1007 22:14:13.489159  5289 net.cpp:406] Convolution13 <- Eltwise5_elu11_0_split_1
I1007 22:14:13.489166  5289 net.cpp:380] Convolution13 -> Convolution13
I1007 22:14:13.490881  5289 net.cpp:122] Setting up Convolution13
I1007 22:14:13.490891  5289 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:14:13.490896  5289 net.cpp:137] Memory required for data: 317050000
I1007 22:14:13.490905  5289 layer_factory.hpp:77] Creating layer BatchNorm13
I1007 22:14:13.490911  5289 net.cpp:84] Creating Layer BatchNorm13
I1007 22:14:13.490914  5289 net.cpp:406] BatchNorm13 <- Convolution13
I1007 22:14:13.490922  5289 net.cpp:367] BatchNorm13 -> Convolution13 (in-place)
I1007 22:14:13.491053  5289 net.cpp:122] Setting up BatchNorm13
I1007 22:14:13.491060  5289 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:14:13.491063  5289 net.cpp:137] Memory required for data: 319558800
I1007 22:14:13.491070  5289 layer_factory.hpp:77] Creating layer Scale13
I1007 22:14:13.491076  5289 net.cpp:84] Creating Layer Scale13
I1007 22:14:13.491080  5289 net.cpp:406] Scale13 <- Convolution13
I1007 22:14:13.491086  5289 net.cpp:367] Scale13 -> Convolution13 (in-place)
I1007 22:14:13.491116  5289 layer_factory.hpp:77] Creating layer Scale13
I1007 22:14:13.491225  5289 net.cpp:122] Setting up Scale13
I1007 22:14:13.491231  5289 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:14:13.491235  5289 net.cpp:137] Memory required for data: 322067600
I1007 22:14:13.491242  5289 layer_factory.hpp:77] Creating layer elu12
I1007 22:14:13.491248  5289 net.cpp:84] Creating Layer elu12
I1007 22:14:13.491252  5289 net.cpp:406] elu12 <- Convolution13
I1007 22:14:13.491258  5289 net.cpp:367] elu12 -> Convolution13 (in-place)
I1007 22:14:13.491264  5289 net.cpp:122] Setting up elu12
I1007 22:14:13.491269  5289 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:14:13.491273  5289 net.cpp:137] Memory required for data: 324576400
I1007 22:14:13.491276  5289 layer_factory.hpp:77] Creating layer Convolution14
I1007 22:14:13.491286  5289 net.cpp:84] Creating Layer Convolution14
I1007 22:14:13.491295  5289 net.cpp:406] Convolution14 <- Convolution13
I1007 22:14:13.491302  5289 net.cpp:380] Convolution14 -> Convolution14
I1007 22:14:13.492321  5289 net.cpp:122] Setting up Convolution14
I1007 22:14:13.492332  5289 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:14:13.492337  5289 net.cpp:137] Memory required for data: 327085200
I1007 22:14:13.492344  5289 layer_factory.hpp:77] Creating layer BatchNorm14
I1007 22:14:13.492357  5289 net.cpp:84] Creating Layer BatchNorm14
I1007 22:14:13.492360  5289 net.cpp:406] BatchNorm14 <- Convolution14
I1007 22:14:13.492367  5289 net.cpp:367] BatchNorm14 -> Convolution14 (in-place)
I1007 22:14:13.492496  5289 net.cpp:122] Setting up BatchNorm14
I1007 22:14:13.492502  5289 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:14:13.492506  5289 net.cpp:137] Memory required for data: 329594000
I1007 22:14:13.492513  5289 layer_factory.hpp:77] Creating layer Scale14
I1007 22:14:13.492518  5289 net.cpp:84] Creating Layer Scale14
I1007 22:14:13.492522  5289 net.cpp:406] Scale14 <- Convolution14
I1007 22:14:13.492528  5289 net.cpp:367] Scale14 -> Convolution14 (in-place)
I1007 22:14:13.492557  5289 layer_factory.hpp:77] Creating layer Scale14
I1007 22:14:13.492633  5289 net.cpp:122] Setting up Scale14
I1007 22:14:13.492640  5289 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:14:13.492643  5289 net.cpp:137] Memory required for data: 332102800
I1007 22:14:13.492650  5289 layer_factory.hpp:77] Creating layer Eltwise6
I1007 22:14:13.492655  5289 net.cpp:84] Creating Layer Eltwise6
I1007 22:14:13.492658  5289 net.cpp:406] Eltwise6 <- Convolution12
I1007 22:14:13.492663  5289 net.cpp:406] Eltwise6 <- Convolution14
I1007 22:14:13.492669  5289 net.cpp:380] Eltwise6 -> Eltwise6
I1007 22:14:13.492684  5289 net.cpp:122] Setting up Eltwise6
I1007 22:14:13.492688  5289 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:14:13.492691  5289 net.cpp:137] Memory required for data: 334611600
I1007 22:14:13.492692  5289 layer_factory.hpp:77] Creating layer elu13
I1007 22:14:13.492697  5289 net.cpp:84] Creating Layer elu13
I1007 22:14:13.492698  5289 net.cpp:406] elu13 <- Eltwise6
I1007 22:14:13.492702  5289 net.cpp:367] elu13 -> Eltwise6 (in-place)
I1007 22:14:13.492705  5289 net.cpp:122] Setting up elu13
I1007 22:14:13.492707  5289 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:14:13.492709  5289 net.cpp:137] Memory required for data: 337120400
I1007 22:14:13.492712  5289 layer_factory.hpp:77] Creating layer Eltwise6_elu13_0_split
I1007 22:14:13.492715  5289 net.cpp:84] Creating Layer Eltwise6_elu13_0_split
I1007 22:14:13.492717  5289 net.cpp:406] Eltwise6_elu13_0_split <- Eltwise6
I1007 22:14:13.492720  5289 net.cpp:380] Eltwise6_elu13_0_split -> Eltwise6_elu13_0_split_0
I1007 22:14:13.492724  5289 net.cpp:380] Eltwise6_elu13_0_split -> Eltwise6_elu13_0_split_1
I1007 22:14:13.492744  5289 net.cpp:122] Setting up Eltwise6_elu13_0_split
I1007 22:14:13.492748  5289 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:14:13.492750  5289 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:14:13.492753  5289 net.cpp:137] Memory required for data: 342138000
I1007 22:14:13.492755  5289 layer_factory.hpp:77] Creating layer Convolution15
I1007 22:14:13.492761  5289 net.cpp:84] Creating Layer Convolution15
I1007 22:14:13.492763  5289 net.cpp:406] Convolution15 <- Eltwise6_elu13_0_split_0
I1007 22:14:13.492768  5289 net.cpp:380] Convolution15 -> Convolution15
I1007 22:14:13.493769  5289 net.cpp:122] Setting up Convolution15
I1007 22:14:13.493778  5289 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:14:13.493780  5289 net.cpp:137] Memory required for data: 344646800
I1007 22:14:13.493785  5289 layer_factory.hpp:77] Creating layer BatchNorm15
I1007 22:14:13.493790  5289 net.cpp:84] Creating Layer BatchNorm15
I1007 22:14:13.493793  5289 net.cpp:406] BatchNorm15 <- Convolution15
I1007 22:14:13.493798  5289 net.cpp:367] BatchNorm15 -> Convolution15 (in-place)
I1007 22:14:13.493922  5289 net.cpp:122] Setting up BatchNorm15
I1007 22:14:13.493927  5289 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:14:13.493934  5289 net.cpp:137] Memory required for data: 347155600
I1007 22:14:13.493940  5289 layer_factory.hpp:77] Creating layer Scale15
I1007 22:14:13.493944  5289 net.cpp:84] Creating Layer Scale15
I1007 22:14:13.493947  5289 net.cpp:406] Scale15 <- Convolution15
I1007 22:14:13.493949  5289 net.cpp:367] Scale15 -> Convolution15 (in-place)
I1007 22:14:13.493976  5289 layer_factory.hpp:77] Creating layer Scale15
I1007 22:14:13.494046  5289 net.cpp:122] Setting up Scale15
I1007 22:14:13.494050  5289 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:14:13.494052  5289 net.cpp:137] Memory required for data: 349664400
I1007 22:14:13.494056  5289 layer_factory.hpp:77] Creating layer elu14
I1007 22:14:13.494060  5289 net.cpp:84] Creating Layer elu14
I1007 22:14:13.494062  5289 net.cpp:406] elu14 <- Convolution15
I1007 22:14:13.494065  5289 net.cpp:367] elu14 -> Convolution15 (in-place)
I1007 22:14:13.494069  5289 net.cpp:122] Setting up elu14
I1007 22:14:13.494072  5289 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:14:13.494074  5289 net.cpp:137] Memory required for data: 352173200
I1007 22:14:13.494076  5289 layer_factory.hpp:77] Creating layer Convolution16
I1007 22:14:13.494083  5289 net.cpp:84] Creating Layer Convolution16
I1007 22:14:13.494086  5289 net.cpp:406] Convolution16 <- Convolution15
I1007 22:14:13.494091  5289 net.cpp:380] Convolution16 -> Convolution16
I1007 22:14:13.495093  5289 net.cpp:122] Setting up Convolution16
I1007 22:14:13.495102  5289 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:14:13.495105  5289 net.cpp:137] Memory required for data: 354682000
I1007 22:14:13.495110  5289 layer_factory.hpp:77] Creating layer BatchNorm16
I1007 22:14:13.495115  5289 net.cpp:84] Creating Layer BatchNorm16
I1007 22:14:13.495118  5289 net.cpp:406] BatchNorm16 <- Convolution16
I1007 22:14:13.495121  5289 net.cpp:367] BatchNorm16 -> Convolution16 (in-place)
I1007 22:14:13.495272  5289 net.cpp:122] Setting up BatchNorm16
I1007 22:14:13.495277  5289 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:14:13.495280  5289 net.cpp:137] Memory required for data: 357190800
I1007 22:14:13.495285  5289 layer_factory.hpp:77] Creating layer Scale16
I1007 22:14:13.495288  5289 net.cpp:84] Creating Layer Scale16
I1007 22:14:13.495290  5289 net.cpp:406] Scale16 <- Convolution16
I1007 22:14:13.495295  5289 net.cpp:367] Scale16 -> Convolution16 (in-place)
I1007 22:14:13.495318  5289 layer_factory.hpp:77] Creating layer Scale16
I1007 22:14:13.495390  5289 net.cpp:122] Setting up Scale16
I1007 22:14:13.495394  5289 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:14:13.495396  5289 net.cpp:137] Memory required for data: 359699600
I1007 22:14:13.495399  5289 layer_factory.hpp:77] Creating layer Eltwise7
I1007 22:14:13.495404  5289 net.cpp:84] Creating Layer Eltwise7
I1007 22:14:13.495406  5289 net.cpp:406] Eltwise7 <- Eltwise6_elu13_0_split_1
I1007 22:14:13.495409  5289 net.cpp:406] Eltwise7 <- Convolution16
I1007 22:14:13.495412  5289 net.cpp:380] Eltwise7 -> Eltwise7
I1007 22:14:13.495427  5289 net.cpp:122] Setting up Eltwise7
I1007 22:14:13.495430  5289 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:14:13.495432  5289 net.cpp:137] Memory required for data: 362208400
I1007 22:14:13.495434  5289 layer_factory.hpp:77] Creating layer elu15
I1007 22:14:13.495438  5289 net.cpp:84] Creating Layer elu15
I1007 22:14:13.495440  5289 net.cpp:406] elu15 <- Eltwise7
I1007 22:14:13.495443  5289 net.cpp:367] elu15 -> Eltwise7 (in-place)
I1007 22:14:13.495446  5289 net.cpp:122] Setting up elu15
I1007 22:14:13.495450  5289 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:14:13.495451  5289 net.cpp:137] Memory required for data: 364717200
I1007 22:14:13.495453  5289 layer_factory.hpp:77] Creating layer Eltwise7_elu15_0_split
I1007 22:14:13.495457  5289 net.cpp:84] Creating Layer Eltwise7_elu15_0_split
I1007 22:14:13.495460  5289 net.cpp:406] Eltwise7_elu15_0_split <- Eltwise7
I1007 22:14:13.495462  5289 net.cpp:380] Eltwise7_elu15_0_split -> Eltwise7_elu15_0_split_0
I1007 22:14:13.495472  5289 net.cpp:380] Eltwise7_elu15_0_split -> Eltwise7_elu15_0_split_1
I1007 22:14:13.495496  5289 net.cpp:122] Setting up Eltwise7_elu15_0_split
I1007 22:14:13.495499  5289 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:14:13.495502  5289 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:14:13.495504  5289 net.cpp:137] Memory required for data: 369734800
I1007 22:14:13.495507  5289 layer_factory.hpp:77] Creating layer Convolution17
I1007 22:14:13.495512  5289 net.cpp:84] Creating Layer Convolution17
I1007 22:14:13.495514  5289 net.cpp:406] Convolution17 <- Eltwise7_elu15_0_split_0
I1007 22:14:13.495519  5289 net.cpp:380] Convolution17 -> Convolution17
I1007 22:14:13.496228  5289 net.cpp:122] Setting up Convolution17
I1007 22:14:13.496237  5289 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:14:13.496238  5289 net.cpp:137] Memory required for data: 372243600
I1007 22:14:13.496243  5289 layer_factory.hpp:77] Creating layer BatchNorm17
I1007 22:14:13.496248  5289 net.cpp:84] Creating Layer BatchNorm17
I1007 22:14:13.496250  5289 net.cpp:406] BatchNorm17 <- Convolution17
I1007 22:14:13.496253  5289 net.cpp:367] BatchNorm17 -> Convolution17 (in-place)
I1007 22:14:13.496378  5289 net.cpp:122] Setting up BatchNorm17
I1007 22:14:13.496382  5289 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:14:13.496384  5289 net.cpp:137] Memory required for data: 374752400
I1007 22:14:13.496388  5289 layer_factory.hpp:77] Creating layer Scale17
I1007 22:14:13.496392  5289 net.cpp:84] Creating Layer Scale17
I1007 22:14:13.496395  5289 net.cpp:406] Scale17 <- Convolution17
I1007 22:14:13.496399  5289 net.cpp:367] Scale17 -> Convolution17 (in-place)
I1007 22:14:13.496423  5289 layer_factory.hpp:77] Creating layer Scale17
I1007 22:14:13.496497  5289 net.cpp:122] Setting up Scale17
I1007 22:14:13.496501  5289 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:14:13.496503  5289 net.cpp:137] Memory required for data: 377261200
I1007 22:14:13.496506  5289 layer_factory.hpp:77] Creating layer elu16
I1007 22:14:13.496510  5289 net.cpp:84] Creating Layer elu16
I1007 22:14:13.496512  5289 net.cpp:406] elu16 <- Convolution17
I1007 22:14:13.496516  5289 net.cpp:367] elu16 -> Convolution17 (in-place)
I1007 22:14:13.496520  5289 net.cpp:122] Setting up elu16
I1007 22:14:13.496522  5289 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:14:13.496525  5289 net.cpp:137] Memory required for data: 379770000
I1007 22:14:13.496526  5289 layer_factory.hpp:77] Creating layer Convolution18
I1007 22:14:13.496532  5289 net.cpp:84] Creating Layer Convolution18
I1007 22:14:13.496534  5289 net.cpp:406] Convolution18 <- Convolution17
I1007 22:14:13.496538  5289 net.cpp:380] Convolution18 -> Convolution18
I1007 22:14:13.497536  5289 net.cpp:122] Setting up Convolution18
I1007 22:14:13.497545  5289 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:14:13.497547  5289 net.cpp:137] Memory required for data: 382278800
I1007 22:14:13.497552  5289 layer_factory.hpp:77] Creating layer BatchNorm18
I1007 22:14:13.497557  5289 net.cpp:84] Creating Layer BatchNorm18
I1007 22:14:13.497560  5289 net.cpp:406] BatchNorm18 <- Convolution18
I1007 22:14:13.497563  5289 net.cpp:367] BatchNorm18 -> Convolution18 (in-place)
I1007 22:14:13.497691  5289 net.cpp:122] Setting up BatchNorm18
I1007 22:14:13.497695  5289 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:14:13.497699  5289 net.cpp:137] Memory required for data: 384787600
I1007 22:14:13.497702  5289 layer_factory.hpp:77] Creating layer Scale18
I1007 22:14:13.497706  5289 net.cpp:84] Creating Layer Scale18
I1007 22:14:13.497709  5289 net.cpp:406] Scale18 <- Convolution18
I1007 22:14:13.497711  5289 net.cpp:367] Scale18 -> Convolution18 (in-place)
I1007 22:14:13.497737  5289 layer_factory.hpp:77] Creating layer Scale18
I1007 22:14:13.497809  5289 net.cpp:122] Setting up Scale18
I1007 22:14:13.497813  5289 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:14:13.497815  5289 net.cpp:137] Memory required for data: 387296400
I1007 22:14:13.497819  5289 layer_factory.hpp:77] Creating layer Eltwise8
I1007 22:14:13.497829  5289 net.cpp:84] Creating Layer Eltwise8
I1007 22:14:13.497833  5289 net.cpp:406] Eltwise8 <- Eltwise7_elu15_0_split_1
I1007 22:14:13.497835  5289 net.cpp:406] Eltwise8 <- Convolution18
I1007 22:14:13.497839  5289 net.cpp:380] Eltwise8 -> Eltwise8
I1007 22:14:13.497855  5289 net.cpp:122] Setting up Eltwise8
I1007 22:14:13.497859  5289 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:14:13.497861  5289 net.cpp:137] Memory required for data: 389805200
I1007 22:14:13.497864  5289 layer_factory.hpp:77] Creating layer elu17
I1007 22:14:13.497866  5289 net.cpp:84] Creating Layer elu17
I1007 22:14:13.497869  5289 net.cpp:406] elu17 <- Eltwise8
I1007 22:14:13.497871  5289 net.cpp:367] elu17 -> Eltwise8 (in-place)
I1007 22:14:13.497874  5289 net.cpp:122] Setting up elu17
I1007 22:14:13.497877  5289 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:14:13.497879  5289 net.cpp:137] Memory required for data: 392314000
I1007 22:14:13.497881  5289 layer_factory.hpp:77] Creating layer Eltwise8_elu17_0_split
I1007 22:14:13.497885  5289 net.cpp:84] Creating Layer Eltwise8_elu17_0_split
I1007 22:14:13.497887  5289 net.cpp:406] Eltwise8_elu17_0_split <- Eltwise8
I1007 22:14:13.497889  5289 net.cpp:380] Eltwise8_elu17_0_split -> Eltwise8_elu17_0_split_0
I1007 22:14:13.497894  5289 net.cpp:380] Eltwise8_elu17_0_split -> Eltwise8_elu17_0_split_1
I1007 22:14:13.497915  5289 net.cpp:122] Setting up Eltwise8_elu17_0_split
I1007 22:14:13.497918  5289 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:14:13.497921  5289 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:14:13.497923  5289 net.cpp:137] Memory required for data: 397331600
I1007 22:14:13.497925  5289 layer_factory.hpp:77] Creating layer Convolution19
I1007 22:14:13.497931  5289 net.cpp:84] Creating Layer Convolution19
I1007 22:14:13.497933  5289 net.cpp:406] Convolution19 <- Eltwise8_elu17_0_split_0
I1007 22:14:13.497937  5289 net.cpp:380] Convolution19 -> Convolution19
I1007 22:14:13.499280  5289 net.cpp:122] Setting up Convolution19
I1007 22:14:13.499289  5289 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:14:13.499291  5289 net.cpp:137] Memory required for data: 399840400
I1007 22:14:13.499296  5289 layer_factory.hpp:77] Creating layer BatchNorm19
I1007 22:14:13.499301  5289 net.cpp:84] Creating Layer BatchNorm19
I1007 22:14:13.499305  5289 net.cpp:406] BatchNorm19 <- Convolution19
I1007 22:14:13.499307  5289 net.cpp:367] BatchNorm19 -> Convolution19 (in-place)
I1007 22:14:13.499440  5289 net.cpp:122] Setting up BatchNorm19
I1007 22:14:13.499444  5289 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:14:13.499446  5289 net.cpp:137] Memory required for data: 402349200
I1007 22:14:13.499464  5289 layer_factory.hpp:77] Creating layer Scale19
I1007 22:14:13.499469  5289 net.cpp:84] Creating Layer Scale19
I1007 22:14:13.499471  5289 net.cpp:406] Scale19 <- Convolution19
I1007 22:14:13.499475  5289 net.cpp:367] Scale19 -> Convolution19 (in-place)
I1007 22:14:13.499502  5289 layer_factory.hpp:77] Creating layer Scale19
I1007 22:14:13.499577  5289 net.cpp:122] Setting up Scale19
I1007 22:14:13.499581  5289 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:14:13.499583  5289 net.cpp:137] Memory required for data: 404858000
I1007 22:14:13.499588  5289 layer_factory.hpp:77] Creating layer elu18
I1007 22:14:13.499590  5289 net.cpp:84] Creating Layer elu18
I1007 22:14:13.499593  5289 net.cpp:406] elu18 <- Convolution19
I1007 22:14:13.499595  5289 net.cpp:367] elu18 -> Convolution19 (in-place)
I1007 22:14:13.499599  5289 net.cpp:122] Setting up elu18
I1007 22:14:13.499603  5289 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:14:13.499604  5289 net.cpp:137] Memory required for data: 407366800
I1007 22:14:13.499606  5289 layer_factory.hpp:77] Creating layer Convolution20
I1007 22:14:13.499613  5289 net.cpp:84] Creating Layer Convolution20
I1007 22:14:13.499614  5289 net.cpp:406] Convolution20 <- Convolution19
I1007 22:14:13.499619  5289 net.cpp:380] Convolution20 -> Convolution20
I1007 22:14:13.500660  5289 net.cpp:122] Setting up Convolution20
I1007 22:14:13.500682  5289 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:14:13.500687  5289 net.cpp:137] Memory required for data: 409875600
I1007 22:14:13.500694  5289 layer_factory.hpp:77] Creating layer BatchNorm20
I1007 22:14:13.500701  5289 net.cpp:84] Creating Layer BatchNorm20
I1007 22:14:13.500705  5289 net.cpp:406] BatchNorm20 <- Convolution20
I1007 22:14:13.500712  5289 net.cpp:367] BatchNorm20 -> Convolution20 (in-place)
I1007 22:14:13.500860  5289 net.cpp:122] Setting up BatchNorm20
I1007 22:14:13.500865  5289 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:14:13.500869  5289 net.cpp:137] Memory required for data: 412384400
I1007 22:14:13.500874  5289 layer_factory.hpp:77] Creating layer Scale20
I1007 22:14:13.500877  5289 net.cpp:84] Creating Layer Scale20
I1007 22:14:13.500880  5289 net.cpp:406] Scale20 <- Convolution20
I1007 22:14:13.500882  5289 net.cpp:367] Scale20 -> Convolution20 (in-place)
I1007 22:14:13.500908  5289 layer_factory.hpp:77] Creating layer Scale20
I1007 22:14:13.500984  5289 net.cpp:122] Setting up Scale20
I1007 22:14:13.500988  5289 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:14:13.500990  5289 net.cpp:137] Memory required for data: 414893200
I1007 22:14:13.500994  5289 layer_factory.hpp:77] Creating layer Eltwise9
I1007 22:14:13.500998  5289 net.cpp:84] Creating Layer Eltwise9
I1007 22:14:13.501000  5289 net.cpp:406] Eltwise9 <- Eltwise8_elu17_0_split_1
I1007 22:14:13.501003  5289 net.cpp:406] Eltwise9 <- Convolution20
I1007 22:14:13.501008  5289 net.cpp:380] Eltwise9 -> Eltwise9
I1007 22:14:13.501022  5289 net.cpp:122] Setting up Eltwise9
I1007 22:14:13.501026  5289 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:14:13.501029  5289 net.cpp:137] Memory required for data: 417402000
I1007 22:14:13.501030  5289 layer_factory.hpp:77] Creating layer elu19
I1007 22:14:13.501034  5289 net.cpp:84] Creating Layer elu19
I1007 22:14:13.501036  5289 net.cpp:406] elu19 <- Eltwise9
I1007 22:14:13.501039  5289 net.cpp:367] elu19 -> Eltwise9 (in-place)
I1007 22:14:13.501042  5289 net.cpp:122] Setting up elu19
I1007 22:14:13.501045  5289 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:14:13.501047  5289 net.cpp:137] Memory required for data: 419910800
I1007 22:14:13.501050  5289 layer_factory.hpp:77] Creating layer Eltwise9_elu19_0_split
I1007 22:14:13.501054  5289 net.cpp:84] Creating Layer Eltwise9_elu19_0_split
I1007 22:14:13.501055  5289 net.cpp:406] Eltwise9_elu19_0_split <- Eltwise9
I1007 22:14:13.501058  5289 net.cpp:380] Eltwise9_elu19_0_split -> Eltwise9_elu19_0_split_0
I1007 22:14:13.501062  5289 net.cpp:380] Eltwise9_elu19_0_split -> Eltwise9_elu19_0_split_1
I1007 22:14:13.501083  5289 net.cpp:122] Setting up Eltwise9_elu19_0_split
I1007 22:14:13.501086  5289 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:14:13.501090  5289 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:14:13.501091  5289 net.cpp:137] Memory required for data: 424928400
I1007 22:14:13.501093  5289 layer_factory.hpp:77] Creating layer Convolution21
I1007 22:14:13.501101  5289 net.cpp:84] Creating Layer Convolution21
I1007 22:14:13.501102  5289 net.cpp:406] Convolution21 <- Eltwise9_elu19_0_split_0
I1007 22:14:13.501106  5289 net.cpp:380] Convolution21 -> Convolution21
I1007 22:14:13.502574  5289 net.cpp:122] Setting up Convolution21
I1007 22:14:13.502584  5289 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:14:13.502586  5289 net.cpp:137] Memory required for data: 427437200
I1007 22:14:13.502591  5289 layer_factory.hpp:77] Creating layer BatchNorm21
I1007 22:14:13.502596  5289 net.cpp:84] Creating Layer BatchNorm21
I1007 22:14:13.502599  5289 net.cpp:406] BatchNorm21 <- Convolution21
I1007 22:14:13.502604  5289 net.cpp:367] BatchNorm21 -> Convolution21 (in-place)
I1007 22:14:13.502739  5289 net.cpp:122] Setting up BatchNorm21
I1007 22:14:13.502744  5289 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:14:13.502746  5289 net.cpp:137] Memory required for data: 429946000
I1007 22:14:13.502751  5289 layer_factory.hpp:77] Creating layer Scale21
I1007 22:14:13.502763  5289 net.cpp:84] Creating Layer Scale21
I1007 22:14:13.502766  5289 net.cpp:406] Scale21 <- Convolution21
I1007 22:14:13.502770  5289 net.cpp:367] Scale21 -> Convolution21 (in-place)
I1007 22:14:13.502797  5289 layer_factory.hpp:77] Creating layer Scale21
I1007 22:14:13.502928  5289 net.cpp:122] Setting up Scale21
I1007 22:14:13.502935  5289 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:14:13.502938  5289 net.cpp:137] Memory required for data: 432454800
I1007 22:14:13.502943  5289 layer_factory.hpp:77] Creating layer elu20
I1007 22:14:13.502948  5289 net.cpp:84] Creating Layer elu20
I1007 22:14:13.502950  5289 net.cpp:406] elu20 <- Convolution21
I1007 22:14:13.502956  5289 net.cpp:367] elu20 -> Convolution21 (in-place)
I1007 22:14:13.502962  5289 net.cpp:122] Setting up elu20
I1007 22:14:13.502965  5289 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:14:13.502967  5289 net.cpp:137] Memory required for data: 434963600
I1007 22:14:13.502969  5289 layer_factory.hpp:77] Creating layer Convolution22
I1007 22:14:13.502985  5289 net.cpp:84] Creating Layer Convolution22
I1007 22:14:13.502987  5289 net.cpp:406] Convolution22 <- Convolution21
I1007 22:14:13.502991  5289 net.cpp:380] Convolution22 -> Convolution22
I1007 22:14:13.504062  5289 net.cpp:122] Setting up Convolution22
I1007 22:14:13.504071  5289 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:14:13.504073  5289 net.cpp:137] Memory required for data: 437472400
I1007 22:14:13.504078  5289 layer_factory.hpp:77] Creating layer BatchNorm22
I1007 22:14:13.504083  5289 net.cpp:84] Creating Layer BatchNorm22
I1007 22:14:13.504086  5289 net.cpp:406] BatchNorm22 <- Convolution22
I1007 22:14:13.504091  5289 net.cpp:367] BatchNorm22 -> Convolution22 (in-place)
I1007 22:14:13.504218  5289 net.cpp:122] Setting up BatchNorm22
I1007 22:14:13.504223  5289 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:14:13.504225  5289 net.cpp:137] Memory required for data: 439981200
I1007 22:14:13.504230  5289 layer_factory.hpp:77] Creating layer Scale22
I1007 22:14:13.504235  5289 net.cpp:84] Creating Layer Scale22
I1007 22:14:13.504236  5289 net.cpp:406] Scale22 <- Convolution22
I1007 22:14:13.504240  5289 net.cpp:367] Scale22 -> Convolution22 (in-place)
I1007 22:14:13.504276  5289 layer_factory.hpp:77] Creating layer Scale22
I1007 22:14:13.504361  5289 net.cpp:122] Setting up Scale22
I1007 22:14:13.504365  5289 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:14:13.504367  5289 net.cpp:137] Memory required for data: 442490000
I1007 22:14:13.504371  5289 layer_factory.hpp:77] Creating layer Eltwise10
I1007 22:14:13.504375  5289 net.cpp:84] Creating Layer Eltwise10
I1007 22:14:13.504379  5289 net.cpp:406] Eltwise10 <- Eltwise9_elu19_0_split_1
I1007 22:14:13.504381  5289 net.cpp:406] Eltwise10 <- Convolution22
I1007 22:14:13.504384  5289 net.cpp:380] Eltwise10 -> Eltwise10
I1007 22:14:13.504400  5289 net.cpp:122] Setting up Eltwise10
I1007 22:14:13.504402  5289 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:14:13.504405  5289 net.cpp:137] Memory required for data: 444998800
I1007 22:14:13.504406  5289 layer_factory.hpp:77] Creating layer elu21
I1007 22:14:13.504410  5289 net.cpp:84] Creating Layer elu21
I1007 22:14:13.504412  5289 net.cpp:406] elu21 <- Eltwise10
I1007 22:14:13.504416  5289 net.cpp:367] elu21 -> Eltwise10 (in-place)
I1007 22:14:13.504420  5289 net.cpp:122] Setting up elu21
I1007 22:14:13.504422  5289 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:14:13.504425  5289 net.cpp:137] Memory required for data: 447507600
I1007 22:14:13.504426  5289 layer_factory.hpp:77] Creating layer Eltwise10_elu21_0_split
I1007 22:14:13.504429  5289 net.cpp:84] Creating Layer Eltwise10_elu21_0_split
I1007 22:14:13.504431  5289 net.cpp:406] Eltwise10_elu21_0_split <- Eltwise10
I1007 22:14:13.504434  5289 net.cpp:380] Eltwise10_elu21_0_split -> Eltwise10_elu21_0_split_0
I1007 22:14:13.504438  5289 net.cpp:380] Eltwise10_elu21_0_split -> Eltwise10_elu21_0_split_1
I1007 22:14:13.504459  5289 net.cpp:122] Setting up Eltwise10_elu21_0_split
I1007 22:14:13.504470  5289 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:14:13.504473  5289 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:14:13.504475  5289 net.cpp:137] Memory required for data: 452525200
I1007 22:14:13.504477  5289 layer_factory.hpp:77] Creating layer Convolution23
I1007 22:14:13.504483  5289 net.cpp:84] Creating Layer Convolution23
I1007 22:14:13.504487  5289 net.cpp:406] Convolution23 <- Eltwise10_elu21_0_split_0
I1007 22:14:13.504489  5289 net.cpp:380] Convolution23 -> Convolution23
I1007 22:14:13.505383  5289 net.cpp:122] Setting up Convolution23
I1007 22:14:13.505393  5289 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:14:13.505395  5289 net.cpp:137] Memory required for data: 453779600
I1007 22:14:13.505399  5289 layer_factory.hpp:77] Creating layer BatchNorm23
I1007 22:14:13.505404  5289 net.cpp:84] Creating Layer BatchNorm23
I1007 22:14:13.505406  5289 net.cpp:406] BatchNorm23 <- Convolution23
I1007 22:14:13.505410  5289 net.cpp:367] BatchNorm23 -> Convolution23 (in-place)
I1007 22:14:13.505542  5289 net.cpp:122] Setting up BatchNorm23
I1007 22:14:13.505547  5289 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:14:13.505548  5289 net.cpp:137] Memory required for data: 455034000
I1007 22:14:13.505553  5289 layer_factory.hpp:77] Creating layer Scale23
I1007 22:14:13.505558  5289 net.cpp:84] Creating Layer Scale23
I1007 22:14:13.505559  5289 net.cpp:406] Scale23 <- Convolution23
I1007 22:14:13.505563  5289 net.cpp:367] Scale23 -> Convolution23 (in-place)
I1007 22:14:13.505589  5289 layer_factory.hpp:77] Creating layer Scale23
I1007 22:14:13.505662  5289 net.cpp:122] Setting up Scale23
I1007 22:14:13.505667  5289 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:14:13.505669  5289 net.cpp:137] Memory required for data: 456288400
I1007 22:14:13.505672  5289 layer_factory.hpp:77] Creating layer Convolution24
I1007 22:14:13.505679  5289 net.cpp:84] Creating Layer Convolution24
I1007 22:14:13.505681  5289 net.cpp:406] Convolution24 <- Eltwise10_elu21_0_split_1
I1007 22:14:13.505686  5289 net.cpp:380] Convolution24 -> Convolution24
I1007 22:14:13.507411  5289 net.cpp:122] Setting up Convolution24
I1007 22:14:13.507421  5289 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:14:13.507423  5289 net.cpp:137] Memory required for data: 457542800
I1007 22:14:13.507428  5289 layer_factory.hpp:77] Creating layer BatchNorm24
I1007 22:14:13.507432  5289 net.cpp:84] Creating Layer BatchNorm24
I1007 22:14:13.507436  5289 net.cpp:406] BatchNorm24 <- Convolution24
I1007 22:14:13.507439  5289 net.cpp:367] BatchNorm24 -> Convolution24 (in-place)
I1007 22:14:13.507570  5289 net.cpp:122] Setting up BatchNorm24
I1007 22:14:13.507573  5289 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:14:13.507575  5289 net.cpp:137] Memory required for data: 458797200
I1007 22:14:13.507580  5289 layer_factory.hpp:77] Creating layer Scale24
I1007 22:14:13.507585  5289 net.cpp:84] Creating Layer Scale24
I1007 22:14:13.507586  5289 net.cpp:406] Scale24 <- Convolution24
I1007 22:14:13.507591  5289 net.cpp:367] Scale24 -> Convolution24 (in-place)
I1007 22:14:13.507616  5289 layer_factory.hpp:77] Creating layer Scale24
I1007 22:14:13.507688  5289 net.cpp:122] Setting up Scale24
I1007 22:14:13.507692  5289 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:14:13.507694  5289 net.cpp:137] Memory required for data: 460051600
I1007 22:14:13.507699  5289 layer_factory.hpp:77] Creating layer elu22
I1007 22:14:13.507701  5289 net.cpp:84] Creating Layer elu22
I1007 22:14:13.507704  5289 net.cpp:406] elu22 <- Convolution24
I1007 22:14:13.507709  5289 net.cpp:367] elu22 -> Convolution24 (in-place)
I1007 22:14:13.507712  5289 net.cpp:122] Setting up elu22
I1007 22:14:13.507715  5289 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:14:13.507717  5289 net.cpp:137] Memory required for data: 461306000
I1007 22:14:13.507719  5289 layer_factory.hpp:77] Creating layer Convolution25
I1007 22:14:13.507725  5289 net.cpp:84] Creating Layer Convolution25
I1007 22:14:13.507727  5289 net.cpp:406] Convolution25 <- Convolution24
I1007 22:14:13.507740  5289 net.cpp:380] Convolution25 -> Convolution25
I1007 22:14:13.509655  5289 net.cpp:122] Setting up Convolution25
I1007 22:14:13.509665  5289 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:14:13.509667  5289 net.cpp:137] Memory required for data: 462560400
I1007 22:14:13.509672  5289 layer_factory.hpp:77] Creating layer BatchNorm25
I1007 22:14:13.509676  5289 net.cpp:84] Creating Layer BatchNorm25
I1007 22:14:13.509680  5289 net.cpp:406] BatchNorm25 <- Convolution25
I1007 22:14:13.509683  5289 net.cpp:367] BatchNorm25 -> Convolution25 (in-place)
I1007 22:14:13.509819  5289 net.cpp:122] Setting up BatchNorm25
I1007 22:14:13.509822  5289 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:14:13.509824  5289 net.cpp:137] Memory required for data: 463814800
I1007 22:14:13.509829  5289 layer_factory.hpp:77] Creating layer Scale25
I1007 22:14:13.509833  5289 net.cpp:84] Creating Layer Scale25
I1007 22:14:13.509836  5289 net.cpp:406] Scale25 <- Convolution25
I1007 22:14:13.509840  5289 net.cpp:367] Scale25 -> Convolution25 (in-place)
I1007 22:14:13.509865  5289 layer_factory.hpp:77] Creating layer Scale25
I1007 22:14:13.509941  5289 net.cpp:122] Setting up Scale25
I1007 22:14:13.509946  5289 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:14:13.509948  5289 net.cpp:137] Memory required for data: 465069200
I1007 22:14:13.509951  5289 layer_factory.hpp:77] Creating layer Eltwise11
I1007 22:14:13.509955  5289 net.cpp:84] Creating Layer Eltwise11
I1007 22:14:13.509958  5289 net.cpp:406] Eltwise11 <- Convolution23
I1007 22:14:13.509960  5289 net.cpp:406] Eltwise11 <- Convolution25
I1007 22:14:13.509964  5289 net.cpp:380] Eltwise11 -> Eltwise11
I1007 22:14:13.509979  5289 net.cpp:122] Setting up Eltwise11
I1007 22:14:13.509984  5289 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:14:13.509986  5289 net.cpp:137] Memory required for data: 466323600
I1007 22:14:13.509989  5289 layer_factory.hpp:77] Creating layer elu23
I1007 22:14:13.509991  5289 net.cpp:84] Creating Layer elu23
I1007 22:14:13.509994  5289 net.cpp:406] elu23 <- Eltwise11
I1007 22:14:13.509996  5289 net.cpp:367] elu23 -> Eltwise11 (in-place)
I1007 22:14:13.510000  5289 net.cpp:122] Setting up elu23
I1007 22:14:13.510004  5289 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:14:13.510005  5289 net.cpp:137] Memory required for data: 467578000
I1007 22:14:13.510007  5289 layer_factory.hpp:77] Creating layer Eltwise11_elu23_0_split
I1007 22:14:13.510010  5289 net.cpp:84] Creating Layer Eltwise11_elu23_0_split
I1007 22:14:13.510012  5289 net.cpp:406] Eltwise11_elu23_0_split <- Eltwise11
I1007 22:14:13.510016  5289 net.cpp:380] Eltwise11_elu23_0_split -> Eltwise11_elu23_0_split_0
I1007 22:14:13.510020  5289 net.cpp:380] Eltwise11_elu23_0_split -> Eltwise11_elu23_0_split_1
I1007 22:14:13.510040  5289 net.cpp:122] Setting up Eltwise11_elu23_0_split
I1007 22:14:13.510044  5289 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:14:13.510046  5289 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:14:13.510048  5289 net.cpp:137] Memory required for data: 470086800
I1007 22:14:13.510051  5289 layer_factory.hpp:77] Creating layer Convolution26
I1007 22:14:13.510056  5289 net.cpp:84] Creating Layer Convolution26
I1007 22:14:13.510059  5289 net.cpp:406] Convolution26 <- Eltwise11_elu23_0_split_0
I1007 22:14:13.510062  5289 net.cpp:380] Convolution26 -> Convolution26
I1007 22:14:13.511684  5289 net.cpp:122] Setting up Convolution26
I1007 22:14:13.511693  5289 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:14:13.511696  5289 net.cpp:137] Memory required for data: 471341200
I1007 22:14:13.511700  5289 layer_factory.hpp:77] Creating layer BatchNorm26
I1007 22:14:13.511705  5289 net.cpp:84] Creating Layer BatchNorm26
I1007 22:14:13.511708  5289 net.cpp:406] BatchNorm26 <- Convolution26
I1007 22:14:13.511713  5289 net.cpp:367] BatchNorm26 -> Convolution26 (in-place)
I1007 22:14:13.511843  5289 net.cpp:122] Setting up BatchNorm26
I1007 22:14:13.511848  5289 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:14:13.511850  5289 net.cpp:137] Memory required for data: 472595600
I1007 22:14:13.511862  5289 layer_factory.hpp:77] Creating layer Scale26
I1007 22:14:13.511867  5289 net.cpp:84] Creating Layer Scale26
I1007 22:14:13.511868  5289 net.cpp:406] Scale26 <- Convolution26
I1007 22:14:13.511871  5289 net.cpp:367] Scale26 -> Convolution26 (in-place)
I1007 22:14:13.511900  5289 layer_factory.hpp:77] Creating layer Scale26
I1007 22:14:13.511975  5289 net.cpp:122] Setting up Scale26
I1007 22:14:13.511978  5289 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:14:13.511981  5289 net.cpp:137] Memory required for data: 473850000
I1007 22:14:13.511984  5289 layer_factory.hpp:77] Creating layer elu24
I1007 22:14:13.511988  5289 net.cpp:84] Creating Layer elu24
I1007 22:14:13.511991  5289 net.cpp:406] elu24 <- Convolution26
I1007 22:14:13.511994  5289 net.cpp:367] elu24 -> Convolution26 (in-place)
I1007 22:14:13.511997  5289 net.cpp:122] Setting up elu24
I1007 22:14:13.512001  5289 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:14:13.512002  5289 net.cpp:137] Memory required for data: 475104400
I1007 22:14:13.512004  5289 layer_factory.hpp:77] Creating layer Convolution27
I1007 22:14:13.512010  5289 net.cpp:84] Creating Layer Convolution27
I1007 22:14:13.512013  5289 net.cpp:406] Convolution27 <- Convolution26
I1007 22:14:13.512017  5289 net.cpp:380] Convolution27 -> Convolution27
I1007 22:14:13.513619  5289 net.cpp:122] Setting up Convolution27
I1007 22:14:13.513628  5289 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:14:13.513630  5289 net.cpp:137] Memory required for data: 476358800
I1007 22:14:13.513634  5289 layer_factory.hpp:77] Creating layer BatchNorm27
I1007 22:14:13.513640  5289 net.cpp:84] Creating Layer BatchNorm27
I1007 22:14:13.513643  5289 net.cpp:406] BatchNorm27 <- Convolution27
I1007 22:14:13.513646  5289 net.cpp:367] BatchNorm27 -> Convolution27 (in-place)
I1007 22:14:13.513805  5289 net.cpp:122] Setting up BatchNorm27
I1007 22:14:13.513810  5289 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:14:13.513813  5289 net.cpp:137] Memory required for data: 477613200
I1007 22:14:13.513816  5289 layer_factory.hpp:77] Creating layer Scale27
I1007 22:14:13.513829  5289 net.cpp:84] Creating Layer Scale27
I1007 22:14:13.513831  5289 net.cpp:406] Scale27 <- Convolution27
I1007 22:14:13.513835  5289 net.cpp:367] Scale27 -> Convolution27 (in-place)
I1007 22:14:13.513864  5289 layer_factory.hpp:77] Creating layer Scale27
I1007 22:14:13.513939  5289 net.cpp:122] Setting up Scale27
I1007 22:14:13.513943  5289 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:14:13.513945  5289 net.cpp:137] Memory required for data: 478867600
I1007 22:14:13.513950  5289 layer_factory.hpp:77] Creating layer Eltwise12
I1007 22:14:13.513953  5289 net.cpp:84] Creating Layer Eltwise12
I1007 22:14:13.513957  5289 net.cpp:406] Eltwise12 <- Eltwise11_elu23_0_split_1
I1007 22:14:13.513958  5289 net.cpp:406] Eltwise12 <- Convolution27
I1007 22:14:13.513962  5289 net.cpp:380] Eltwise12 -> Eltwise12
I1007 22:14:13.513981  5289 net.cpp:122] Setting up Eltwise12
I1007 22:14:13.513986  5289 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:14:13.513988  5289 net.cpp:137] Memory required for data: 480122000
I1007 22:14:13.513990  5289 layer_factory.hpp:77] Creating layer elu25
I1007 22:14:13.513994  5289 net.cpp:84] Creating Layer elu25
I1007 22:14:13.513996  5289 net.cpp:406] elu25 <- Eltwise12
I1007 22:14:13.513999  5289 net.cpp:367] elu25 -> Eltwise12 (in-place)
I1007 22:14:13.514003  5289 net.cpp:122] Setting up elu25
I1007 22:14:13.514006  5289 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:14:13.514008  5289 net.cpp:137] Memory required for data: 481376400
I1007 22:14:13.514009  5289 layer_factory.hpp:77] Creating layer Eltwise12_elu25_0_split
I1007 22:14:13.514014  5289 net.cpp:84] Creating Layer Eltwise12_elu25_0_split
I1007 22:14:13.514014  5289 net.cpp:406] Eltwise12_elu25_0_split <- Eltwise12
I1007 22:14:13.514017  5289 net.cpp:380] Eltwise12_elu25_0_split -> Eltwise12_elu25_0_split_0
I1007 22:14:13.514021  5289 net.cpp:380] Eltwise12_elu25_0_split -> Eltwise12_elu25_0_split_1
I1007 22:14:13.514051  5289 net.cpp:122] Setting up Eltwise12_elu25_0_split
I1007 22:14:13.514056  5289 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:14:13.514060  5289 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:14:13.514060  5289 net.cpp:137] Memory required for data: 483885200
I1007 22:14:13.514062  5289 layer_factory.hpp:77] Creating layer Convolution28
I1007 22:14:13.514070  5289 net.cpp:84] Creating Layer Convolution28
I1007 22:14:13.514071  5289 net.cpp:406] Convolution28 <- Eltwise12_elu25_0_split_0
I1007 22:14:13.514075  5289 net.cpp:380] Convolution28 -> Convolution28
I1007 22:14:13.515704  5289 net.cpp:122] Setting up Convolution28
I1007 22:14:13.515713  5289 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:14:13.515717  5289 net.cpp:137] Memory required for data: 485139600
I1007 22:14:13.515722  5289 layer_factory.hpp:77] Creating layer BatchNorm28
I1007 22:14:13.515725  5289 net.cpp:84] Creating Layer BatchNorm28
I1007 22:14:13.515728  5289 net.cpp:406] BatchNorm28 <- Convolution28
I1007 22:14:13.515733  5289 net.cpp:367] BatchNorm28 -> Convolution28 (in-place)
I1007 22:14:13.515864  5289 net.cpp:122] Setting up BatchNorm28
I1007 22:14:13.515869  5289 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:14:13.515871  5289 net.cpp:137] Memory required for data: 486394000
I1007 22:14:13.515875  5289 layer_factory.hpp:77] Creating layer Scale28
I1007 22:14:13.515879  5289 net.cpp:84] Creating Layer Scale28
I1007 22:14:13.515882  5289 net.cpp:406] Scale28 <- Convolution28
I1007 22:14:13.515884  5289 net.cpp:367] Scale28 -> Convolution28 (in-place)
I1007 22:14:13.515911  5289 layer_factory.hpp:77] Creating layer Scale28
I1007 22:14:13.515988  5289 net.cpp:122] Setting up Scale28
I1007 22:14:13.515992  5289 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:14:13.515995  5289 net.cpp:137] Memory required for data: 487648400
I1007 22:14:13.515998  5289 layer_factory.hpp:77] Creating layer elu26
I1007 22:14:13.516001  5289 net.cpp:84] Creating Layer elu26
I1007 22:14:13.516003  5289 net.cpp:406] elu26 <- Convolution28
I1007 22:14:13.516006  5289 net.cpp:367] elu26 -> Convolution28 (in-place)
I1007 22:14:13.516010  5289 net.cpp:122] Setting up elu26
I1007 22:14:13.516013  5289 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:14:13.516016  5289 net.cpp:137] Memory required for data: 488902800
I1007 22:14:13.516017  5289 layer_factory.hpp:77] Creating layer Convolution29
I1007 22:14:13.516026  5289 net.cpp:84] Creating Layer Convolution29
I1007 22:14:13.516027  5289 net.cpp:406] Convolution29 <- Convolution28
I1007 22:14:13.516031  5289 net.cpp:380] Convolution29 -> Convolution29
I1007 22:14:13.517943  5289 net.cpp:122] Setting up Convolution29
I1007 22:14:13.517952  5289 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:14:13.517956  5289 net.cpp:137] Memory required for data: 490157200
I1007 22:14:13.517961  5289 layer_factory.hpp:77] Creating layer BatchNorm29
I1007 22:14:13.517964  5289 net.cpp:84] Creating Layer BatchNorm29
I1007 22:14:13.517967  5289 net.cpp:406] BatchNorm29 <- Convolution29
I1007 22:14:13.517971  5289 net.cpp:367] BatchNorm29 -> Convolution29 (in-place)
I1007 22:14:13.518110  5289 net.cpp:122] Setting up BatchNorm29
I1007 22:14:13.518113  5289 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:14:13.518116  5289 net.cpp:137] Memory required for data: 491411600
I1007 22:14:13.518121  5289 layer_factory.hpp:77] Creating layer Scale29
I1007 22:14:13.518124  5289 net.cpp:84] Creating Layer Scale29
I1007 22:14:13.518126  5289 net.cpp:406] Scale29 <- Convolution29
I1007 22:14:13.518131  5289 net.cpp:367] Scale29 -> Convolution29 (in-place)
I1007 22:14:13.518157  5289 layer_factory.hpp:77] Creating layer Scale29
I1007 22:14:13.518234  5289 net.cpp:122] Setting up Scale29
I1007 22:14:13.518239  5289 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:14:13.518240  5289 net.cpp:137] Memory required for data: 492666000
I1007 22:14:13.518244  5289 layer_factory.hpp:77] Creating layer Eltwise13
I1007 22:14:13.518247  5289 net.cpp:84] Creating Layer Eltwise13
I1007 22:14:13.518257  5289 net.cpp:406] Eltwise13 <- Eltwise12_elu25_0_split_1
I1007 22:14:13.518260  5289 net.cpp:406] Eltwise13 <- Convolution29
I1007 22:14:13.518265  5289 net.cpp:380] Eltwise13 -> Eltwise13
I1007 22:14:13.518280  5289 net.cpp:122] Setting up Eltwise13
I1007 22:14:13.518285  5289 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:14:13.518287  5289 net.cpp:137] Memory required for data: 493920400
I1007 22:14:13.518290  5289 layer_factory.hpp:77] Creating layer elu27
I1007 22:14:13.518293  5289 net.cpp:84] Creating Layer elu27
I1007 22:14:13.518296  5289 net.cpp:406] elu27 <- Eltwise13
I1007 22:14:13.518298  5289 net.cpp:367] elu27 -> Eltwise13 (in-place)
I1007 22:14:13.518302  5289 net.cpp:122] Setting up elu27
I1007 22:14:13.518306  5289 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:14:13.518307  5289 net.cpp:137] Memory required for data: 495174800
I1007 22:14:13.518309  5289 layer_factory.hpp:77] Creating layer Eltwise13_elu27_0_split
I1007 22:14:13.518312  5289 net.cpp:84] Creating Layer Eltwise13_elu27_0_split
I1007 22:14:13.518314  5289 net.cpp:406] Eltwise13_elu27_0_split <- Eltwise13
I1007 22:14:13.518317  5289 net.cpp:380] Eltwise13_elu27_0_split -> Eltwise13_elu27_0_split_0
I1007 22:14:13.518321  5289 net.cpp:380] Eltwise13_elu27_0_split -> Eltwise13_elu27_0_split_1
I1007 22:14:13.518342  5289 net.cpp:122] Setting up Eltwise13_elu27_0_split
I1007 22:14:13.518347  5289 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:14:13.518349  5289 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:14:13.518352  5289 net.cpp:137] Memory required for data: 497683600
I1007 22:14:13.518353  5289 layer_factory.hpp:77] Creating layer Convolution30
I1007 22:14:13.518359  5289 net.cpp:84] Creating Layer Convolution30
I1007 22:14:13.518362  5289 net.cpp:406] Convolution30 <- Eltwise13_elu27_0_split_0
I1007 22:14:13.518365  5289 net.cpp:380] Convolution30 -> Convolution30
I1007 22:14:13.519987  5289 net.cpp:122] Setting up Convolution30
I1007 22:14:13.519996  5289 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:14:13.519999  5289 net.cpp:137] Memory required for data: 498938000
I1007 22:14:13.520002  5289 layer_factory.hpp:77] Creating layer BatchNorm30
I1007 22:14:13.520009  5289 net.cpp:84] Creating Layer BatchNorm30
I1007 22:14:13.520011  5289 net.cpp:406] BatchNorm30 <- Convolution30
I1007 22:14:13.520015  5289 net.cpp:367] BatchNorm30 -> Convolution30 (in-place)
I1007 22:14:13.520150  5289 net.cpp:122] Setting up BatchNorm30
I1007 22:14:13.520154  5289 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:14:13.520156  5289 net.cpp:137] Memory required for data: 500192400
I1007 22:14:13.520160  5289 layer_factory.hpp:77] Creating layer Scale30
I1007 22:14:13.520165  5289 net.cpp:84] Creating Layer Scale30
I1007 22:14:13.520169  5289 net.cpp:406] Scale30 <- Convolution30
I1007 22:14:13.520171  5289 net.cpp:367] Scale30 -> Convolution30 (in-place)
I1007 22:14:13.520197  5289 layer_factory.hpp:77] Creating layer Scale30
I1007 22:14:13.520274  5289 net.cpp:122] Setting up Scale30
I1007 22:14:13.520278  5289 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:14:13.520280  5289 net.cpp:137] Memory required for data: 501446800
I1007 22:14:13.520284  5289 layer_factory.hpp:77] Creating layer elu28
I1007 22:14:13.520287  5289 net.cpp:84] Creating Layer elu28
I1007 22:14:13.520290  5289 net.cpp:406] elu28 <- Convolution30
I1007 22:14:13.520293  5289 net.cpp:367] elu28 -> Convolution30 (in-place)
I1007 22:14:13.520298  5289 net.cpp:122] Setting up elu28
I1007 22:14:13.520300  5289 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:14:13.520303  5289 net.cpp:137] Memory required for data: 502701200
I1007 22:14:13.520304  5289 layer_factory.hpp:77] Creating layer Convolution31
I1007 22:14:13.520310  5289 net.cpp:84] Creating Layer Convolution31
I1007 22:14:13.520313  5289 net.cpp:406] Convolution31 <- Convolution30
I1007 22:14:13.520316  5289 net.cpp:380] Convolution31 -> Convolution31
I1007 22:14:13.522238  5289 net.cpp:122] Setting up Convolution31
I1007 22:14:13.522248  5289 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:14:13.522256  5289 net.cpp:137] Memory required for data: 503955600
I1007 22:14:13.522263  5289 layer_factory.hpp:77] Creating layer BatchNorm31
I1007 22:14:13.522267  5289 net.cpp:84] Creating Layer BatchNorm31
I1007 22:14:13.522270  5289 net.cpp:406] BatchNorm31 <- Convolution31
I1007 22:14:13.522274  5289 net.cpp:367] BatchNorm31 -> Convolution31 (in-place)
I1007 22:14:13.522411  5289 net.cpp:122] Setting up BatchNorm31
I1007 22:14:13.522416  5289 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:14:13.522418  5289 net.cpp:137] Memory required for data: 505210000
I1007 22:14:13.522423  5289 layer_factory.hpp:77] Creating layer Scale31
I1007 22:14:13.522426  5289 net.cpp:84] Creating Layer Scale31
I1007 22:14:13.522429  5289 net.cpp:406] Scale31 <- Convolution31
I1007 22:14:13.522433  5289 net.cpp:367] Scale31 -> Convolution31 (in-place)
I1007 22:14:13.522459  5289 layer_factory.hpp:77] Creating layer Scale31
I1007 22:14:13.522536  5289 net.cpp:122] Setting up Scale31
I1007 22:14:13.522541  5289 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:14:13.522542  5289 net.cpp:137] Memory required for data: 506464400
I1007 22:14:13.522547  5289 layer_factory.hpp:77] Creating layer Eltwise14
I1007 22:14:13.522552  5289 net.cpp:84] Creating Layer Eltwise14
I1007 22:14:13.522554  5289 net.cpp:406] Eltwise14 <- Eltwise13_elu27_0_split_1
I1007 22:14:13.522557  5289 net.cpp:406] Eltwise14 <- Convolution31
I1007 22:14:13.522560  5289 net.cpp:380] Eltwise14 -> Eltwise14
I1007 22:14:13.522575  5289 net.cpp:122] Setting up Eltwise14
I1007 22:14:13.522579  5289 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:14:13.522580  5289 net.cpp:137] Memory required for data: 507718800
I1007 22:14:13.522583  5289 layer_factory.hpp:77] Creating layer elu29
I1007 22:14:13.522588  5289 net.cpp:84] Creating Layer elu29
I1007 22:14:13.522589  5289 net.cpp:406] elu29 <- Eltwise14
I1007 22:14:13.522593  5289 net.cpp:367] elu29 -> Eltwise14 (in-place)
I1007 22:14:13.522595  5289 net.cpp:122] Setting up elu29
I1007 22:14:13.522598  5289 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:14:13.522600  5289 net.cpp:137] Memory required for data: 508973200
I1007 22:14:13.522603  5289 layer_factory.hpp:77] Creating layer Eltwise14_elu29_0_split
I1007 22:14:13.522606  5289 net.cpp:84] Creating Layer Eltwise14_elu29_0_split
I1007 22:14:13.522608  5289 net.cpp:406] Eltwise14_elu29_0_split <- Eltwise14
I1007 22:14:13.522611  5289 net.cpp:380] Eltwise14_elu29_0_split -> Eltwise14_elu29_0_split_0
I1007 22:14:13.522614  5289 net.cpp:380] Eltwise14_elu29_0_split -> Eltwise14_elu29_0_split_1
I1007 22:14:13.522637  5289 net.cpp:122] Setting up Eltwise14_elu29_0_split
I1007 22:14:13.522640  5289 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:14:13.522644  5289 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:14:13.522645  5289 net.cpp:137] Memory required for data: 511482000
I1007 22:14:13.522647  5289 layer_factory.hpp:77] Creating layer Convolution32
I1007 22:14:13.522653  5289 net.cpp:84] Creating Layer Convolution32
I1007 22:14:13.522655  5289 net.cpp:406] Convolution32 <- Eltwise14_elu29_0_split_0
I1007 22:14:13.522660  5289 net.cpp:380] Convolution32 -> Convolution32
I1007 22:14:13.524296  5289 net.cpp:122] Setting up Convolution32
I1007 22:14:13.524304  5289 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:14:13.524307  5289 net.cpp:137] Memory required for data: 512736400
I1007 22:14:13.524312  5289 layer_factory.hpp:77] Creating layer BatchNorm32
I1007 22:14:13.524317  5289 net.cpp:84] Creating Layer BatchNorm32
I1007 22:14:13.524319  5289 net.cpp:406] BatchNorm32 <- Convolution32
I1007 22:14:13.524323  5289 net.cpp:367] BatchNorm32 -> Convolution32 (in-place)
I1007 22:14:13.524457  5289 net.cpp:122] Setting up BatchNorm32
I1007 22:14:13.524462  5289 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:14:13.524464  5289 net.cpp:137] Memory required for data: 513990800
I1007 22:14:13.524468  5289 layer_factory.hpp:77] Creating layer Scale32
I1007 22:14:13.524473  5289 net.cpp:84] Creating Layer Scale32
I1007 22:14:13.524482  5289 net.cpp:406] Scale32 <- Convolution32
I1007 22:14:13.524487  5289 net.cpp:367] Scale32 -> Convolution32 (in-place)
I1007 22:14:13.524515  5289 layer_factory.hpp:77] Creating layer Scale32
I1007 22:14:13.524593  5289 net.cpp:122] Setting up Scale32
I1007 22:14:13.524597  5289 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:14:13.524600  5289 net.cpp:137] Memory required for data: 515245200
I1007 22:14:13.524603  5289 layer_factory.hpp:77] Creating layer elu30
I1007 22:14:13.524607  5289 net.cpp:84] Creating Layer elu30
I1007 22:14:13.524610  5289 net.cpp:406] elu30 <- Convolution32
I1007 22:14:13.524613  5289 net.cpp:367] elu30 -> Convolution32 (in-place)
I1007 22:14:13.524617  5289 net.cpp:122] Setting up elu30
I1007 22:14:13.524621  5289 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:14:13.524622  5289 net.cpp:137] Memory required for data: 516499600
I1007 22:14:13.524624  5289 layer_factory.hpp:77] Creating layer Convolution33
I1007 22:14:13.524631  5289 net.cpp:84] Creating Layer Convolution33
I1007 22:14:13.524632  5289 net.cpp:406] Convolution33 <- Convolution32
I1007 22:14:13.524636  5289 net.cpp:380] Convolution33 -> Convolution33
I1007 22:14:13.526567  5289 net.cpp:122] Setting up Convolution33
I1007 22:14:13.526576  5289 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:14:13.526578  5289 net.cpp:137] Memory required for data: 517754000
I1007 22:14:13.526583  5289 layer_factory.hpp:77] Creating layer BatchNorm33
I1007 22:14:13.526588  5289 net.cpp:84] Creating Layer BatchNorm33
I1007 22:14:13.526592  5289 net.cpp:406] BatchNorm33 <- Convolution33
I1007 22:14:13.526594  5289 net.cpp:367] BatchNorm33 -> Convolution33 (in-place)
I1007 22:14:13.526736  5289 net.cpp:122] Setting up BatchNorm33
I1007 22:14:13.526741  5289 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:14:13.526743  5289 net.cpp:137] Memory required for data: 519008400
I1007 22:14:13.526748  5289 layer_factory.hpp:77] Creating layer Scale33
I1007 22:14:13.526752  5289 net.cpp:84] Creating Layer Scale33
I1007 22:14:13.526754  5289 net.cpp:406] Scale33 <- Convolution33
I1007 22:14:13.526758  5289 net.cpp:367] Scale33 -> Convolution33 (in-place)
I1007 22:14:13.526785  5289 layer_factory.hpp:77] Creating layer Scale33
I1007 22:14:13.526865  5289 net.cpp:122] Setting up Scale33
I1007 22:14:13.526870  5289 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:14:13.526871  5289 net.cpp:137] Memory required for data: 520262800
I1007 22:14:13.526875  5289 layer_factory.hpp:77] Creating layer Eltwise15
I1007 22:14:13.526878  5289 net.cpp:84] Creating Layer Eltwise15
I1007 22:14:13.526881  5289 net.cpp:406] Eltwise15 <- Eltwise14_elu29_0_split_1
I1007 22:14:13.526885  5289 net.cpp:406] Eltwise15 <- Convolution33
I1007 22:14:13.526887  5289 net.cpp:380] Eltwise15 -> Eltwise15
I1007 22:14:13.526904  5289 net.cpp:122] Setting up Eltwise15
I1007 22:14:13.526908  5289 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:14:13.526911  5289 net.cpp:137] Memory required for data: 521517200
I1007 22:14:13.526912  5289 layer_factory.hpp:77] Creating layer elu31
I1007 22:14:13.526916  5289 net.cpp:84] Creating Layer elu31
I1007 22:14:13.526917  5289 net.cpp:406] elu31 <- Eltwise15
I1007 22:14:13.526921  5289 net.cpp:367] elu31 -> Eltwise15 (in-place)
I1007 22:14:13.526924  5289 net.cpp:122] Setting up elu31
I1007 22:14:13.526926  5289 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:14:13.526928  5289 net.cpp:137] Memory required for data: 522771600
I1007 22:14:13.526931  5289 layer_factory.hpp:77] Creating layer Pooling1
I1007 22:14:13.526935  5289 net.cpp:84] Creating Layer Pooling1
I1007 22:14:13.526937  5289 net.cpp:406] Pooling1 <- Eltwise15
I1007 22:14:13.526940  5289 net.cpp:380] Pooling1 -> Pooling1
I1007 22:14:13.527087  5289 net.cpp:122] Setting up Pooling1
I1007 22:14:13.527094  5289 net.cpp:129] Top shape: 100 64 1 1 (6400)
I1007 22:14:13.527096  5289 net.cpp:137] Memory required for data: 522797200
I1007 22:14:13.527098  5289 layer_factory.hpp:77] Creating layer InnerProduct1
I1007 22:14:13.527114  5289 net.cpp:84] Creating Layer InnerProduct1
I1007 22:14:13.527118  5289 net.cpp:406] InnerProduct1 <- Pooling1
I1007 22:14:13.527122  5289 net.cpp:380] InnerProduct1 -> InnerProduct1
I1007 22:14:13.527227  5289 net.cpp:122] Setting up InnerProduct1
I1007 22:14:13.527232  5289 net.cpp:129] Top shape: 100 10 (1000)
I1007 22:14:13.527235  5289 net.cpp:137] Memory required for data: 522801200
I1007 22:14:13.527240  5289 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I1007 22:14:13.527245  5289 net.cpp:84] Creating Layer SoftmaxWithLoss1
I1007 22:14:13.527246  5289 net.cpp:406] SoftmaxWithLoss1 <- InnerProduct1
I1007 22:14:13.527249  5289 net.cpp:406] SoftmaxWithLoss1 <- Data2
I1007 22:14:13.527253  5289 net.cpp:380] SoftmaxWithLoss1 -> SoftmaxWithLoss1
I1007 22:14:13.527258  5289 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I1007 22:14:13.527441  5289 net.cpp:122] Setting up SoftmaxWithLoss1
I1007 22:14:13.527446  5289 net.cpp:129] Top shape: (1)
I1007 22:14:13.527448  5289 net.cpp:132]     with loss weight 1
I1007 22:14:13.527459  5289 net.cpp:137] Memory required for data: 522801204
I1007 22:14:13.527462  5289 net.cpp:198] SoftmaxWithLoss1 needs backward computation.
I1007 22:14:13.527464  5289 net.cpp:198] InnerProduct1 needs backward computation.
I1007 22:14:13.527467  5289 net.cpp:198] Pooling1 needs backward computation.
I1007 22:14:13.527468  5289 net.cpp:198] elu31 needs backward computation.
I1007 22:14:13.527470  5289 net.cpp:198] Eltwise15 needs backward computation.
I1007 22:14:13.527473  5289 net.cpp:198] Scale33 needs backward computation.
I1007 22:14:13.527475  5289 net.cpp:198] BatchNorm33 needs backward computation.
I1007 22:14:13.527477  5289 net.cpp:198] Convolution33 needs backward computation.
I1007 22:14:13.527478  5289 net.cpp:198] elu30 needs backward computation.
I1007 22:14:13.527480  5289 net.cpp:198] Scale32 needs backward computation.
I1007 22:14:13.527482  5289 net.cpp:198] BatchNorm32 needs backward computation.
I1007 22:14:13.527484  5289 net.cpp:198] Convolution32 needs backward computation.
I1007 22:14:13.527487  5289 net.cpp:198] Eltwise14_elu29_0_split needs backward computation.
I1007 22:14:13.527488  5289 net.cpp:198] elu29 needs backward computation.
I1007 22:14:13.527490  5289 net.cpp:198] Eltwise14 needs backward computation.
I1007 22:14:13.527493  5289 net.cpp:198] Scale31 needs backward computation.
I1007 22:14:13.527494  5289 net.cpp:198] BatchNorm31 needs backward computation.
I1007 22:14:13.527496  5289 net.cpp:198] Convolution31 needs backward computation.
I1007 22:14:13.527498  5289 net.cpp:198] elu28 needs backward computation.
I1007 22:14:13.527500  5289 net.cpp:198] Scale30 needs backward computation.
I1007 22:14:13.527503  5289 net.cpp:198] BatchNorm30 needs backward computation.
I1007 22:14:13.527504  5289 net.cpp:198] Convolution30 needs backward computation.
I1007 22:14:13.527506  5289 net.cpp:198] Eltwise13_elu27_0_split needs backward computation.
I1007 22:14:13.527508  5289 net.cpp:198] elu27 needs backward computation.
I1007 22:14:13.527510  5289 net.cpp:198] Eltwise13 needs backward computation.
I1007 22:14:13.527513  5289 net.cpp:198] Scale29 needs backward computation.
I1007 22:14:13.527514  5289 net.cpp:198] BatchNorm29 needs backward computation.
I1007 22:14:13.527516  5289 net.cpp:198] Convolution29 needs backward computation.
I1007 22:14:13.527518  5289 net.cpp:198] elu26 needs backward computation.
I1007 22:14:13.527520  5289 net.cpp:198] Scale28 needs backward computation.
I1007 22:14:13.527523  5289 net.cpp:198] BatchNorm28 needs backward computation.
I1007 22:14:13.527524  5289 net.cpp:198] Convolution28 needs backward computation.
I1007 22:14:13.527526  5289 net.cpp:198] Eltwise12_elu25_0_split needs backward computation.
I1007 22:14:13.527529  5289 net.cpp:198] elu25 needs backward computation.
I1007 22:14:13.527530  5289 net.cpp:198] Eltwise12 needs backward computation.
I1007 22:14:13.527532  5289 net.cpp:198] Scale27 needs backward computation.
I1007 22:14:13.527534  5289 net.cpp:198] BatchNorm27 needs backward computation.
I1007 22:14:13.527544  5289 net.cpp:198] Convolution27 needs backward computation.
I1007 22:14:13.527545  5289 net.cpp:198] elu24 needs backward computation.
I1007 22:14:13.527547  5289 net.cpp:198] Scale26 needs backward computation.
I1007 22:14:13.527549  5289 net.cpp:198] BatchNorm26 needs backward computation.
I1007 22:14:13.527551  5289 net.cpp:198] Convolution26 needs backward computation.
I1007 22:14:13.527555  5289 net.cpp:198] Eltwise11_elu23_0_split needs backward computation.
I1007 22:14:13.527557  5289 net.cpp:198] elu23 needs backward computation.
I1007 22:14:13.527559  5289 net.cpp:198] Eltwise11 needs backward computation.
I1007 22:14:13.527561  5289 net.cpp:198] Scale25 needs backward computation.
I1007 22:14:13.527564  5289 net.cpp:198] BatchNorm25 needs backward computation.
I1007 22:14:13.527565  5289 net.cpp:198] Convolution25 needs backward computation.
I1007 22:14:13.527567  5289 net.cpp:198] elu22 needs backward computation.
I1007 22:14:13.527570  5289 net.cpp:198] Scale24 needs backward computation.
I1007 22:14:13.527571  5289 net.cpp:198] BatchNorm24 needs backward computation.
I1007 22:14:13.527573  5289 net.cpp:198] Convolution24 needs backward computation.
I1007 22:14:13.527575  5289 net.cpp:198] Scale23 needs backward computation.
I1007 22:14:13.527577  5289 net.cpp:198] BatchNorm23 needs backward computation.
I1007 22:14:13.527580  5289 net.cpp:198] Convolution23 needs backward computation.
I1007 22:14:13.527581  5289 net.cpp:198] Eltwise10_elu21_0_split needs backward computation.
I1007 22:14:13.527583  5289 net.cpp:198] elu21 needs backward computation.
I1007 22:14:13.527585  5289 net.cpp:198] Eltwise10 needs backward computation.
I1007 22:14:13.527588  5289 net.cpp:198] Scale22 needs backward computation.
I1007 22:14:13.527590  5289 net.cpp:198] BatchNorm22 needs backward computation.
I1007 22:14:13.527592  5289 net.cpp:198] Convolution22 needs backward computation.
I1007 22:14:13.527595  5289 net.cpp:198] elu20 needs backward computation.
I1007 22:14:13.527596  5289 net.cpp:198] Scale21 needs backward computation.
I1007 22:14:13.527598  5289 net.cpp:198] BatchNorm21 needs backward computation.
I1007 22:14:13.527601  5289 net.cpp:198] Convolution21 needs backward computation.
I1007 22:14:13.527603  5289 net.cpp:198] Eltwise9_elu19_0_split needs backward computation.
I1007 22:14:13.527606  5289 net.cpp:198] elu19 needs backward computation.
I1007 22:14:13.527607  5289 net.cpp:198] Eltwise9 needs backward computation.
I1007 22:14:13.527609  5289 net.cpp:198] Scale20 needs backward computation.
I1007 22:14:13.527612  5289 net.cpp:198] BatchNorm20 needs backward computation.
I1007 22:14:13.527614  5289 net.cpp:198] Convolution20 needs backward computation.
I1007 22:14:13.527616  5289 net.cpp:198] elu18 needs backward computation.
I1007 22:14:13.527618  5289 net.cpp:198] Scale19 needs backward computation.
I1007 22:14:13.527621  5289 net.cpp:198] BatchNorm19 needs backward computation.
I1007 22:14:13.527622  5289 net.cpp:198] Convolution19 needs backward computation.
I1007 22:14:13.527624  5289 net.cpp:198] Eltwise8_elu17_0_split needs backward computation.
I1007 22:14:13.527627  5289 net.cpp:198] elu17 needs backward computation.
I1007 22:14:13.527629  5289 net.cpp:198] Eltwise8 needs backward computation.
I1007 22:14:13.527631  5289 net.cpp:198] Scale18 needs backward computation.
I1007 22:14:13.527634  5289 net.cpp:198] BatchNorm18 needs backward computation.
I1007 22:14:13.527637  5289 net.cpp:198] Convolution18 needs backward computation.
I1007 22:14:13.527638  5289 net.cpp:198] elu16 needs backward computation.
I1007 22:14:13.527640  5289 net.cpp:198] Scale17 needs backward computation.
I1007 22:14:13.527642  5289 net.cpp:198] BatchNorm17 needs backward computation.
I1007 22:14:13.527644  5289 net.cpp:198] Convolution17 needs backward computation.
I1007 22:14:13.527647  5289 net.cpp:198] Eltwise7_elu15_0_split needs backward computation.
I1007 22:14:13.527648  5289 net.cpp:198] elu15 needs backward computation.
I1007 22:14:13.527650  5289 net.cpp:198] Eltwise7 needs backward computation.
I1007 22:14:13.527657  5289 net.cpp:198] Scale16 needs backward computation.
I1007 22:14:13.527658  5289 net.cpp:198] BatchNorm16 needs backward computation.
I1007 22:14:13.527662  5289 net.cpp:198] Convolution16 needs backward computation.
I1007 22:14:13.527663  5289 net.cpp:198] elu14 needs backward computation.
I1007 22:14:13.527665  5289 net.cpp:198] Scale15 needs backward computation.
I1007 22:14:13.527667  5289 net.cpp:198] BatchNorm15 needs backward computation.
I1007 22:14:13.527669  5289 net.cpp:198] Convolution15 needs backward computation.
I1007 22:14:13.527673  5289 net.cpp:198] Eltwise6_elu13_0_split needs backward computation.
I1007 22:14:13.527674  5289 net.cpp:198] elu13 needs backward computation.
I1007 22:14:13.527676  5289 net.cpp:198] Eltwise6 needs backward computation.
I1007 22:14:13.527679  5289 net.cpp:198] Scale14 needs backward computation.
I1007 22:14:13.527681  5289 net.cpp:198] BatchNorm14 needs backward computation.
I1007 22:14:13.527683  5289 net.cpp:198] Convolution14 needs backward computation.
I1007 22:14:13.527685  5289 net.cpp:198] elu12 needs backward computation.
I1007 22:14:13.527688  5289 net.cpp:198] Scale13 needs backward computation.
I1007 22:14:13.527689  5289 net.cpp:198] BatchNorm13 needs backward computation.
I1007 22:14:13.527691  5289 net.cpp:198] Convolution13 needs backward computation.
I1007 22:14:13.527694  5289 net.cpp:198] Scale12 needs backward computation.
I1007 22:14:13.527696  5289 net.cpp:198] BatchNorm12 needs backward computation.
I1007 22:14:13.527698  5289 net.cpp:198] Convolution12 needs backward computation.
I1007 22:14:13.527700  5289 net.cpp:198] Eltwise5_elu11_0_split needs backward computation.
I1007 22:14:13.527703  5289 net.cpp:198] elu11 needs backward computation.
I1007 22:14:13.527704  5289 net.cpp:198] Eltwise5 needs backward computation.
I1007 22:14:13.527707  5289 net.cpp:198] Scale11 needs backward computation.
I1007 22:14:13.527710  5289 net.cpp:198] BatchNorm11 needs backward computation.
I1007 22:14:13.527712  5289 net.cpp:198] Convolution11 needs backward computation.
I1007 22:14:13.527714  5289 net.cpp:198] elu10 needs backward computation.
I1007 22:14:13.527716  5289 net.cpp:198] Scale10 needs backward computation.
I1007 22:14:13.527719  5289 net.cpp:198] BatchNorm10 needs backward computation.
I1007 22:14:13.527720  5289 net.cpp:198] Convolution10 needs backward computation.
I1007 22:14:13.527722  5289 net.cpp:198] Eltwise4_elu9_0_split needs backward computation.
I1007 22:14:13.527725  5289 net.cpp:198] elu9 needs backward computation.
I1007 22:14:13.527727  5289 net.cpp:198] Eltwise4 needs backward computation.
I1007 22:14:13.527730  5289 net.cpp:198] Scale9 needs backward computation.
I1007 22:14:13.527732  5289 net.cpp:198] BatchNorm9 needs backward computation.
I1007 22:14:13.527734  5289 net.cpp:198] Convolution9 needs backward computation.
I1007 22:14:13.527736  5289 net.cpp:198] elu8 needs backward computation.
I1007 22:14:13.527739  5289 net.cpp:198] Scale8 needs backward computation.
I1007 22:14:13.527740  5289 net.cpp:198] BatchNorm8 needs backward computation.
I1007 22:14:13.527743  5289 net.cpp:198] Convolution8 needs backward computation.
I1007 22:14:13.527745  5289 net.cpp:198] Eltwise3_elu7_0_split needs backward computation.
I1007 22:14:13.527747  5289 net.cpp:198] elu7 needs backward computation.
I1007 22:14:13.527750  5289 net.cpp:198] Eltwise3 needs backward computation.
I1007 22:14:13.527752  5289 net.cpp:198] Scale7 needs backward computation.
I1007 22:14:13.527755  5289 net.cpp:198] BatchNorm7 needs backward computation.
I1007 22:14:13.527756  5289 net.cpp:198] Convolution7 needs backward computation.
I1007 22:14:13.527758  5289 net.cpp:198] elu6 needs backward computation.
I1007 22:14:13.527760  5289 net.cpp:198] Scale6 needs backward computation.
I1007 22:14:13.527762  5289 net.cpp:198] BatchNorm6 needs backward computation.
I1007 22:14:13.527765  5289 net.cpp:198] Convolution6 needs backward computation.
I1007 22:14:13.527767  5289 net.cpp:198] Eltwise2_elu5_0_split needs backward computation.
I1007 22:14:13.527772  5289 net.cpp:198] elu5 needs backward computation.
I1007 22:14:13.527775  5289 net.cpp:198] Eltwise2 needs backward computation.
I1007 22:14:13.527777  5289 net.cpp:198] Scale5 needs backward computation.
I1007 22:14:13.527779  5289 net.cpp:198] BatchNorm5 needs backward computation.
I1007 22:14:13.527782  5289 net.cpp:198] Convolution5 needs backward computation.
I1007 22:14:13.527784  5289 net.cpp:198] elu4 needs backward computation.
I1007 22:14:13.527786  5289 net.cpp:198] Scale4 needs backward computation.
I1007 22:14:13.527788  5289 net.cpp:198] BatchNorm4 needs backward computation.
I1007 22:14:13.527791  5289 net.cpp:198] Convolution4 needs backward computation.
I1007 22:14:13.527792  5289 net.cpp:198] Eltwise1_elu3_0_split needs backward computation.
I1007 22:14:13.527796  5289 net.cpp:198] elu3 needs backward computation.
I1007 22:14:13.527797  5289 net.cpp:198] Eltwise1 needs backward computation.
I1007 22:14:13.527799  5289 net.cpp:198] Scale3 needs backward computation.
I1007 22:14:13.527801  5289 net.cpp:198] BatchNorm3 needs backward computation.
I1007 22:14:13.527804  5289 net.cpp:198] Convolution3 needs backward computation.
I1007 22:14:13.527806  5289 net.cpp:198] elu2 needs backward computation.
I1007 22:14:13.527808  5289 net.cpp:198] Scale2 needs backward computation.
I1007 22:14:13.527811  5289 net.cpp:198] BatchNorm2 needs backward computation.
I1007 22:14:13.527812  5289 net.cpp:198] Convolution2 needs backward computation.
I1007 22:14:13.527815  5289 net.cpp:198] Convolution1_elu1_0_split needs backward computation.
I1007 22:14:13.527817  5289 net.cpp:198] elu1 needs backward computation.
I1007 22:14:13.527819  5289 net.cpp:198] Scale1 needs backward computation.
I1007 22:14:13.527822  5289 net.cpp:198] BatchNorm1 needs backward computation.
I1007 22:14:13.527823  5289 net.cpp:198] Convolution1 needs backward computation.
I1007 22:14:13.527827  5289 net.cpp:200] Data1 does not need backward computation.
I1007 22:14:13.527828  5289 net.cpp:242] This network produces output SoftmaxWithLoss1
I1007 22:14:13.527879  5289 net.cpp:255] Network initialization done.
I1007 22:14:13.529947  5289 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: /home/x306/caffe/xn/PENLU/neural/resnet/res32/res32_elu_train_test.prototxt
I1007 22:14:13.529954  5289 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I1007 22:14:13.529958  5289 solver.cpp:172] Creating test net (#0) specified by net file: /home/x306/caffe/xn/PENLU/neural/resnet/res32/res32_elu_train_test.prototxt
I1007 22:14:13.530058  5289 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer Data1
I1007 22:14:13.530612  5289 net.cpp:51] Initializing net from parameters: 
name: "resnet_cifar10"
state {
  phase: TEST
}
layer {
  name: "Data1"
  type: "Data"
  top: "Data1"
  top: "Data2"
  include {
    phase: TEST
  }
  transform_param {
    mean_file: "/home/x306/caffe/xn/PENLU/data/cifar10/mean.binaryproto"
  }
  data_param {
    source: "/home/x306/caffe/xn/PENLU/data/cifar10/cifar10_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "Convolution1"
  type: "Convolution"
  bottom: "Data1"
  top: "Convolution1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm1"
  type: "BatchNorm"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1"
  type: "Scale"
  bottom: "Convolution1"
  top: "Convolution1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "elu1"
  type: "ELU"
  bottom: "Convolution1"
  top: "Convolution1"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution2"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm2"
  type: "BatchNorm"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale2"
  type: "Scale"
  bottom: "Convolution2"
  top: "Convolution2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "elu2"
  type: "ELU"
  bottom: "Convolution2"
  top: "Convolution2"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution3"
  type: "Convolution"
  bottom: "Convolution2"
  top: "Convolution3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm3"
  type: "BatchNorm"
  bottom: "Convolution3"
  top: "Convolution3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale3"
  type: "Scale"
  bottom: "Convolution3"
  top: "Convolution3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise1"
  type: "Eltwise"
  bottom: "Convolution1"
  bottom: "Convolution3"
  top: "Eltwise1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "elu3"
  type: "ELU"
  bottom: "Eltwise1"
  top: "Eltwise1"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution4"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm4"
  type: "BatchNorm"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale4"
  type: "Scale"
  bottom: "Convolution4"
  top: "Convolution4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "elu4"
  type: "ELU"
  bottom: "Convolution4"
  top: "Convolution4"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution5"
  type: "Convolution"
  bottom: "Convolution4"
  top: "Convolution5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm5"
  type: "BatchNorm"
  bottom: "Convolution5"
  top: "Convolution5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale5"
  type: "Scale"
  bottom: "Convolution5"
  top: "Convolution5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise2"
  type: "Eltwise"
  bottom: "Eltwise1"
  bottom: "Convolution5"
  top: "Eltwise2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "elu5"
  type: "ELU"
  bottom: "Eltwise2"
  top: "Eltwise2"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution6"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm6"
  type: "BatchNorm"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale6"
  type: "Scale"
  bottom: "Convolution6"
  top: "Convolution6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "elu6"
  type: "ELU"
  bottom: "Convolution6"
  top: "Convolution6"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution7"
  type: "Convolution"
  bottom: "Convolution6"
  top: "Convolution7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm7"
  type: "BatchNorm"
  bottom: "Convolution7"
  top: "Convolution7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale7"
  type: "Scale"
  bottom: "Convolution7"
  top: "Convolution7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise3"
  type: "Eltwise"
  bottom: "Eltwise2"
  bottom: "Convolution7"
  top: "Eltwise3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "elu7"
  type: "ELU"
  bottom: "Eltwise3"
  top: "Eltwise3"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution8"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm8"
  type: "BatchNorm"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale8"
  type: "Scale"
  bottom: "Convolution8"
  top: "Convolution8"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "elu8"
  type: "ELU"
  bottom: "Convolution8"
  top: "Convolution8"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution9"
  type: "Convolution"
  bottom: "Convolution8"
  top: "Convolution9"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm9"
  type: "BatchNorm"
  bottom: "Convolution9"
  top: "Convolution9"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale9"
  type: "Scale"
  bottom: "Convolution9"
  top: "Convolution9"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise4"
  type: "Eltwise"
  bottom: "Eltwise3"
  bottom: "Convolution9"
  top: "Eltwise4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "elu9"
  type: "ELU"
  bottom: "Eltwise4"
  top: "Eltwise4"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution10"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution10"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm10"
  type: "BatchNorm"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale10"
  type: "Scale"
  bottom: "Convolution10"
  top: "Convolution10"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "elu10"
  type: "ELU"
  bottom: "Convolution10"
  top: "Convolution10"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution11"
  type: "Convolution"
  bottom: "Convolution10"
  top: "Convolution11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm11"
  type: "BatchNorm"
  bottom: "Convolution11"
  top: "Convolution11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale11"
  type: "Scale"
  bottom: "Convolution11"
  top: "Convolution11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise5"
  type: "Eltwise"
  bottom: "Eltwise4"
  bottom: "Convolution11"
  top: "Eltwise5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "elu11"
  type: "ELU"
  bottom: "Eltwise5"
  top: "Eltwise5"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution12"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.25
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm12"
  type: "BatchNorm"
  bottom: "Convolution12"
  top: "Convolution12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale12"
  type: "Scale"
  bottom: "Convolution12"
  top: "Convolution12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution13"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution13"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm13"
  type: "BatchNorm"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale13"
  type: "Scale"
  bottom: "Convolution13"
  top: "Convolution13"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "elu12"
  type: "ELU"
  bottom: "Convolution13"
  top: "Convolution13"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution14"
  type: "Convolution"
  bottom: "Convolution13"
  top: "Convolution14"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm14"
  type: "BatchNorm"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale14"
  type: "Scale"
  bottom: "Convolution14"
  top: "Convolution14"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise6"
  type: "Eltwise"
  bottom: "Convolution12"
  bottom: "Convolution14"
  top: "Eltwise6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "elu13"
  type: "ELU"
  bottom: "Eltwise6"
  top: "Eltwise6"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution15"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution15"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm15"
  type: "BatchNorm"
  bottom: "Convolution15"
  top: "Convolution15"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale15"
  type: "Scale"
  bottom: "Convolution15"
  top: "Convolution15"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "elu14"
  type: "ELU"
  bottom: "Convolution15"
  top: "Convolution15"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution16"
  type: "Convolution"
  bottom: "Convolution15"
  top: "Convolution16"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm16"
  type: "BatchNorm"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale16"
  type: "Scale"
  bottom: "Convolution16"
  top: "Convolution16"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise7"
  type: "Eltwise"
  bottom: "Eltwise6"
  bottom: "Convolution16"
  top: "Eltwise7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "elu15"
  type: "ELU"
  bottom: "Eltwise7"
  top: "Eltwise7"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution17"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution17"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm17"
  type: "BatchNorm"
  bottom: "Convolution17"
  top: "Convolution17"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale17"
  type: "Scale"
  bottom: "Convolution17"
  top: "Convolution17"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "elu16"
  type: "ELU"
  bottom: "Convolution17"
  top: "Convolution17"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution18"
  type: "Convolution"
  bottom: "Convolution17"
  top: "Convolution18"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm18"
  type: "BatchNorm"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale18"
  type: "Scale"
  bottom: "Convolution18"
  top: "Convolution18"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise8"
  type: "Eltwise"
  bottom: "Eltwise7"
  bottom: "Convolution18"
  top: "Eltwise8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "elu17"
  type: "ELU"
  bottom: "Eltwise8"
  top: "Eltwise8"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution19"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution19"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm19"
  type: "BatchNorm"
  bottom: "Convolution19"
  top: "Convolution19"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale19"
  type: "Scale"
  bottom: "Convolution19"
  top: "Convolution19"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "elu18"
  type: "ELU"
  bottom: "Convolution19"
  top: "Convolution19"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution20"
  type: "Convolution"
  bottom: "Convolution19"
  top: "Convolution20"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm20"
  type: "BatchNorm"
  bottom: "Convolution20"
  top: "Convolution20"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale20"
  type: "Scale"
  bottom: "Convolution20"
  top: "Convolution20"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise9"
  type: "Eltwise"
  bottom: "Eltwise8"
  bottom: "Convolution20"
  top: "Eltwise9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "elu19"
  type: "ELU"
  bottom: "Eltwise9"
  top: "Eltwise9"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution21"
  type: "Convolution"
  bottom: "Eltwise9"
  top: "Convolution21"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm21"
  type: "BatchNorm"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale21"
  type: "Scale"
  bottom: "Convolution21"
  top: "Convolution21"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "elu20"
  type: "ELU"
  bottom: "Convolution21"
  top: "Convolution21"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution22"
  type: "Convolution"
  bottom: "Convolution21"
  top: "Convolution22"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm22"
  type: "BatchNorm"
  bottom: "Convolution22"
  top: "Convolution22"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale22"
  type: "Scale"
  bottom: "Convolution22"
  top: "Convolution22"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise10"
  type: "Eltwise"
  bottom: "Eltwise9"
  bottom: "Convolution22"
  top: "Eltwise10"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "elu21"
  type: "ELU"
  bottom: "Eltwise10"
  top: "Eltwise10"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution23"
  type: "Convolution"
  bottom: "Eltwise10"
  top: "Convolution23"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.17677669
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm23"
  type: "BatchNorm"
  bottom: "Convolution23"
  top: "Convolution23"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale23"
  type: "Scale"
  bottom: "Convolution23"
  top: "Convolution23"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution24"
  type: "Convolution"
  bottom: "Eltwise10"
  top: "Convolution24"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm24"
  type: "BatchNorm"
  bottom: "Convolution24"
  top: "Convolution24"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale24"
  type: "Scale"
  bottom: "Convolution24"
  top: "Convolution24"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "elu22"
  type: "ELU"
  bottom: "Convolution24"
  top: "Convolution24"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution25"
  type: "Convolution"
  bottom: "Convolution24"
  top: "Convolution25"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm25"
  type: "BatchNorm"
  bottom: "Convolution25"
  top: "Convolution25"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale25"
  type: "Scale"
  bottom: "Convolution25"
  top: "Convolution25"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise11"
  type: "Eltwise"
  bottom: "Convolution23"
  bottom: "Convolution25"
  top: "Eltwise11"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "elu23"
  type: "ELU"
  bottom: "Eltwise11"
  top: "Eltwise11"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution26"
  type: "Convolution"
  bottom: "Eltwise11"
  top: "Convolution26"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm26"
  type: "BatchNorm"
  bottom: "Convolution26"
  top: "Convolution26"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale26"
  type: "Scale"
  bottom: "Convolution26"
  top: "Convolution26"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "elu24"
  type: "ELU"
  bottom: "Convolution26"
  top: "Convolution26"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution27"
  type: "Convolution"
  bottom: "Convolution26"
  top: "Convolution27"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm27"
  type: "BatchNorm"
  bottom: "Convolution27"
  top: "Convolution27"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale27"
  type: "Scale"
  bottom: "Convolution27"
  top: "Convolution27"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise12"
  type: "Eltwise"
  bottom: "Eltwise11"
  bottom: "Convolution27"
  top: "Eltwise12"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "elu25"
  type: "ELU"
  bottom: "Eltwise12"
  top: "Eltwise12"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution28"
  type: "Convolution"
  bottom: "Eltwise12"
  top: "Convolution28"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm28"
  type: "BatchNorm"
  bottom: "Convolution28"
  top: "Convolution28"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale28"
  type: "Scale"
  bottom: "Convolution28"
  top: "Convolution28"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "elu26"
  type: "ELU"
  bottom: "Convolution28"
  top: "Convolution28"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution29"
  type: "Convolution"
  bottom: "Convolution28"
  top: "Convolution29"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm29"
  type: "BatchNorm"
  bottom: "Convolution29"
  top: "Convolution29"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale29"
  type: "Scale"
  bottom: "Convolution29"
  top: "Convolution29"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise13"
  type: "Eltwise"
  bottom: "Eltwise12"
  bottom: "Convolution29"
  top: "Eltwise13"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "elu27"
  type: "ELU"
  bottom: "Eltwise13"
  top: "Eltwise13"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution30"
  type: "Convolution"
  bottom: "Eltwise13"
  top: "Convolution30"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm30"
  type: "BatchNorm"
  bottom: "Convolution30"
  top: "Convolution30"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale30"
  type: "Scale"
  bottom: "Convolution30"
  top: "Convolution30"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "elu28"
  type: "ELU"
  bottom: "Convolution30"
  top: "Convolution30"
  elu_param {
    alpha: 1
  }
}
layer {
  name: "Convolution31"
  type: "Convolution"
  bottom: "Convolution30"
  top: "Convolution31"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm31"
  type: "BatchNorm"
  bottom: "Convolution31"
  top: "Convolution31"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale31"
  type: "Scale"
  bottom: "Convolution31"
  top: "Convolu
I1007 22:14:13.535821  5289 layer_factory.hpp:77] Creating layer Data1
I1007 22:14:13.535873  5289 db_lmdb.cpp:35] Opened lmdb /home/x306/caffe/xn/PENLU/data/cifar10/cifar10_test_lmdb
I1007 22:14:13.535886  5289 net.cpp:84] Creating Layer Data1
I1007 22:14:13.535889  5289 net.cpp:380] Data1 -> Data1
I1007 22:14:13.535895  5289 net.cpp:380] Data1 -> Data2
I1007 22:14:13.535902  5289 data_transformer.cpp:25] Loading mean file from: /home/x306/caffe/xn/PENLU/data/cifar10/mean.binaryproto
I1007 22:14:13.536032  5289 data_layer.cpp:45] output data size: 100,3,32,32
I1007 22:14:13.540067  5289 net.cpp:122] Setting up Data1
I1007 22:14:13.540087  5289 net.cpp:129] Top shape: 100 3 32 32 (307200)
I1007 22:14:13.540092  5289 net.cpp:129] Top shape: 100 (100)
I1007 22:14:13.540094  5289 net.cpp:137] Memory required for data: 1229200
I1007 22:14:13.540098  5289 layer_factory.hpp:77] Creating layer Data2_Data1_1_split
I1007 22:14:13.540107  5289 net.cpp:84] Creating Layer Data2_Data1_1_split
I1007 22:14:13.540110  5289 net.cpp:406] Data2_Data1_1_split <- Data2
I1007 22:14:13.540114  5289 net.cpp:380] Data2_Data1_1_split -> Data2_Data1_1_split_0
I1007 22:14:13.540122  5289 net.cpp:380] Data2_Data1_1_split -> Data2_Data1_1_split_1
I1007 22:14:13.540195  5289 net.cpp:122] Setting up Data2_Data1_1_split
I1007 22:14:13.540201  5289 net.cpp:129] Top shape: 100 (100)
I1007 22:14:13.540205  5289 net.cpp:129] Top shape: 100 (100)
I1007 22:14:13.540206  5289 net.cpp:137] Memory required for data: 1230000
I1007 22:14:13.540208  5289 layer_factory.hpp:77] Creating layer Convolution1
I1007 22:14:13.540218  5289 net.cpp:84] Creating Layer Convolution1
I1007 22:14:13.540220  5289 net.cpp:406] Convolution1 <- Data1
I1007 22:14:13.540225  5289 net.cpp:380] Convolution1 -> Convolution1
I1007 22:14:13.541380  5289 net.cpp:122] Setting up Convolution1
I1007 22:14:13.541391  5289 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:14:13.541393  5289 net.cpp:137] Memory required for data: 7783600
I1007 22:14:13.541402  5289 layer_factory.hpp:77] Creating layer BatchNorm1
I1007 22:14:13.541409  5289 net.cpp:84] Creating Layer BatchNorm1
I1007 22:14:13.541412  5289 net.cpp:406] BatchNorm1 <- Convolution1
I1007 22:14:13.541416  5289 net.cpp:367] BatchNorm1 -> Convolution1 (in-place)
I1007 22:14:13.541559  5289 net.cpp:122] Setting up BatchNorm1
I1007 22:14:13.541564  5289 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:14:13.541568  5289 net.cpp:137] Memory required for data: 14337200
I1007 22:14:13.541575  5289 layer_factory.hpp:77] Creating layer Scale1
I1007 22:14:13.541580  5289 net.cpp:84] Creating Layer Scale1
I1007 22:14:13.541584  5289 net.cpp:406] Scale1 <- Convolution1
I1007 22:14:13.541586  5289 net.cpp:367] Scale1 -> Convolution1 (in-place)
I1007 22:14:13.541616  5289 layer_factory.hpp:77] Creating layer Scale1
I1007 22:14:13.541698  5289 net.cpp:122] Setting up Scale1
I1007 22:14:13.541703  5289 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:14:13.541705  5289 net.cpp:137] Memory required for data: 20890800
I1007 22:14:13.541709  5289 layer_factory.hpp:77] Creating layer elu1
I1007 22:14:13.541715  5289 net.cpp:84] Creating Layer elu1
I1007 22:14:13.541718  5289 net.cpp:406] elu1 <- Convolution1
I1007 22:14:13.541720  5289 net.cpp:367] elu1 -> Convolution1 (in-place)
I1007 22:14:13.541724  5289 net.cpp:122] Setting up elu1
I1007 22:14:13.541728  5289 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:14:13.541729  5289 net.cpp:137] Memory required for data: 27444400
I1007 22:14:13.541731  5289 layer_factory.hpp:77] Creating layer Convolution1_elu1_0_split
I1007 22:14:13.541740  5289 net.cpp:84] Creating Layer Convolution1_elu1_0_split
I1007 22:14:13.541743  5289 net.cpp:406] Convolution1_elu1_0_split <- Convolution1
I1007 22:14:13.541746  5289 net.cpp:380] Convolution1_elu1_0_split -> Convolution1_elu1_0_split_0
I1007 22:14:13.541754  5289 net.cpp:380] Convolution1_elu1_0_split -> Convolution1_elu1_0_split_1
I1007 22:14:13.541784  5289 net.cpp:122] Setting up Convolution1_elu1_0_split
I1007 22:14:13.541787  5289 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:14:13.563581  5289 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:14:13.563591  5289 net.cpp:137] Memory required for data: 40551600
I1007 22:14:13.563596  5289 layer_factory.hpp:77] Creating layer Convolution2
I1007 22:14:13.563608  5289 net.cpp:84] Creating Layer Convolution2
I1007 22:14:13.563612  5289 net.cpp:406] Convolution2 <- Convolution1_elu1_0_split_0
I1007 22:14:13.563617  5289 net.cpp:380] Convolution2 -> Convolution2
I1007 22:14:13.564694  5289 net.cpp:122] Setting up Convolution2
I1007 22:14:13.564704  5289 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:14:13.564707  5289 net.cpp:137] Memory required for data: 47105200
I1007 22:14:13.564716  5289 layer_factory.hpp:77] Creating layer BatchNorm2
I1007 22:14:13.564723  5289 net.cpp:84] Creating Layer BatchNorm2
I1007 22:14:13.564725  5289 net.cpp:406] BatchNorm2 <- Convolution2
I1007 22:14:13.564730  5289 net.cpp:367] BatchNorm2 -> Convolution2 (in-place)
I1007 22:14:13.564901  5289 net.cpp:122] Setting up BatchNorm2
I1007 22:14:13.564911  5289 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:14:13.564915  5289 net.cpp:137] Memory required for data: 53658800
I1007 22:14:13.564924  5289 layer_factory.hpp:77] Creating layer Scale2
I1007 22:14:13.564932  5289 net.cpp:84] Creating Layer Scale2
I1007 22:14:13.564936  5289 net.cpp:406] Scale2 <- Convolution2
I1007 22:14:13.564942  5289 net.cpp:367] Scale2 -> Convolution2 (in-place)
I1007 22:14:13.564995  5289 layer_factory.hpp:77] Creating layer Scale2
I1007 22:14:13.565129  5289 net.cpp:122] Setting up Scale2
I1007 22:14:13.565140  5289 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:14:13.565145  5289 net.cpp:137] Memory required for data: 60212400
I1007 22:14:13.565153  5289 layer_factory.hpp:77] Creating layer elu2
I1007 22:14:13.565160  5289 net.cpp:84] Creating Layer elu2
I1007 22:14:13.565165  5289 net.cpp:406] elu2 <- Convolution2
I1007 22:14:13.565172  5289 net.cpp:367] elu2 -> Convolution2 (in-place)
I1007 22:14:13.565181  5289 net.cpp:122] Setting up elu2
I1007 22:14:13.565186  5289 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:14:13.565189  5289 net.cpp:137] Memory required for data: 66766000
I1007 22:14:13.565193  5289 layer_factory.hpp:77] Creating layer Convolution3
I1007 22:14:13.565204  5289 net.cpp:84] Creating Layer Convolution3
I1007 22:14:13.565209  5289 net.cpp:406] Convolution3 <- Convolution2
I1007 22:14:13.565217  5289 net.cpp:380] Convolution3 -> Convolution3
I1007 22:14:13.566324  5289 net.cpp:122] Setting up Convolution3
I1007 22:14:13.566334  5289 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:14:13.566337  5289 net.cpp:137] Memory required for data: 73319600
I1007 22:14:13.566341  5289 layer_factory.hpp:77] Creating layer BatchNorm3
I1007 22:14:13.566346  5289 net.cpp:84] Creating Layer BatchNorm3
I1007 22:14:13.566349  5289 net.cpp:406] BatchNorm3 <- Convolution3
I1007 22:14:13.566354  5289 net.cpp:367] BatchNorm3 -> Convolution3 (in-place)
I1007 22:14:13.566496  5289 net.cpp:122] Setting up BatchNorm3
I1007 22:14:13.566500  5289 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:14:13.566503  5289 net.cpp:137] Memory required for data: 79873200
I1007 22:14:13.566509  5289 layer_factory.hpp:77] Creating layer Scale3
I1007 22:14:13.566514  5289 net.cpp:84] Creating Layer Scale3
I1007 22:14:13.566516  5289 net.cpp:406] Scale3 <- Convolution3
I1007 22:14:13.566520  5289 net.cpp:367] Scale3 -> Convolution3 (in-place)
I1007 22:14:13.566547  5289 layer_factory.hpp:77] Creating layer Scale3
I1007 22:14:13.566628  5289 net.cpp:122] Setting up Scale3
I1007 22:14:13.566633  5289 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:14:13.566635  5289 net.cpp:137] Memory required for data: 86426800
I1007 22:14:13.566639  5289 layer_factory.hpp:77] Creating layer Eltwise1
I1007 22:14:13.566644  5289 net.cpp:84] Creating Layer Eltwise1
I1007 22:14:13.566646  5289 net.cpp:406] Eltwise1 <- Convolution1_elu1_0_split_1
I1007 22:14:13.566649  5289 net.cpp:406] Eltwise1 <- Convolution3
I1007 22:14:13.566653  5289 net.cpp:380] Eltwise1 -> Eltwise1
I1007 22:14:13.566679  5289 net.cpp:122] Setting up Eltwise1
I1007 22:14:13.566684  5289 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:14:13.566686  5289 net.cpp:137] Memory required for data: 92980400
I1007 22:14:13.566689  5289 layer_factory.hpp:77] Creating layer elu3
I1007 22:14:13.566692  5289 net.cpp:84] Creating Layer elu3
I1007 22:14:13.566695  5289 net.cpp:406] elu3 <- Eltwise1
I1007 22:14:13.566699  5289 net.cpp:367] elu3 -> Eltwise1 (in-place)
I1007 22:14:13.566702  5289 net.cpp:122] Setting up elu3
I1007 22:14:13.566705  5289 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:14:13.566707  5289 net.cpp:137] Memory required for data: 99534000
I1007 22:14:13.566709  5289 layer_factory.hpp:77] Creating layer Eltwise1_elu3_0_split
I1007 22:14:13.566715  5289 net.cpp:84] Creating Layer Eltwise1_elu3_0_split
I1007 22:14:13.566716  5289 net.cpp:406] Eltwise1_elu3_0_split <- Eltwise1
I1007 22:14:13.566720  5289 net.cpp:380] Eltwise1_elu3_0_split -> Eltwise1_elu3_0_split_0
I1007 22:14:13.566723  5289 net.cpp:380] Eltwise1_elu3_0_split -> Eltwise1_elu3_0_split_1
I1007 22:14:13.566747  5289 net.cpp:122] Setting up Eltwise1_elu3_0_split
I1007 22:14:13.566751  5289 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:14:13.566753  5289 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:14:13.566756  5289 net.cpp:137] Memory required for data: 112641200
I1007 22:14:13.566757  5289 layer_factory.hpp:77] Creating layer Convolution4
I1007 22:14:13.566764  5289 net.cpp:84] Creating Layer Convolution4
I1007 22:14:13.566766  5289 net.cpp:406] Convolution4 <- Eltwise1_elu3_0_split_0
I1007 22:14:13.566771  5289 net.cpp:380] Convolution4 -> Convolution4
I1007 22:14:13.567863  5289 net.cpp:122] Setting up Convolution4
I1007 22:14:13.567872  5289 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:14:13.567874  5289 net.cpp:137] Memory required for data: 119194800
I1007 22:14:13.567878  5289 layer_factory.hpp:77] Creating layer BatchNorm4
I1007 22:14:13.567884  5289 net.cpp:84] Creating Layer BatchNorm4
I1007 22:14:13.567886  5289 net.cpp:406] BatchNorm4 <- Convolution4
I1007 22:14:13.567891  5289 net.cpp:367] BatchNorm4 -> Convolution4 (in-place)
I1007 22:14:13.568029  5289 net.cpp:122] Setting up BatchNorm4
I1007 22:14:13.568034  5289 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:14:13.568037  5289 net.cpp:137] Memory required for data: 125748400
I1007 22:14:13.568040  5289 layer_factory.hpp:77] Creating layer Scale4
I1007 22:14:13.568045  5289 net.cpp:84] Creating Layer Scale4
I1007 22:14:13.568048  5289 net.cpp:406] Scale4 <- Convolution4
I1007 22:14:13.568051  5289 net.cpp:367] Scale4 -> Convolution4 (in-place)
I1007 22:14:13.568078  5289 layer_factory.hpp:77] Creating layer Scale4
I1007 22:14:13.568157  5289 net.cpp:122] Setting up Scale4
I1007 22:14:13.568161  5289 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:14:13.568163  5289 net.cpp:137] Memory required for data: 132302000
I1007 22:14:13.568166  5289 layer_factory.hpp:77] Creating layer elu4
I1007 22:14:13.568171  5289 net.cpp:84] Creating Layer elu4
I1007 22:14:13.568172  5289 net.cpp:406] elu4 <- Convolution4
I1007 22:14:13.568176  5289 net.cpp:367] elu4 -> Convolution4 (in-place)
I1007 22:14:13.568178  5289 net.cpp:122] Setting up elu4
I1007 22:14:13.568181  5289 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:14:13.568183  5289 net.cpp:137] Memory required for data: 138855600
I1007 22:14:13.568186  5289 layer_factory.hpp:77] Creating layer Convolution5
I1007 22:14:13.568192  5289 net.cpp:84] Creating Layer Convolution5
I1007 22:14:13.568195  5289 net.cpp:406] Convolution5 <- Convolution4
I1007 22:14:13.568198  5289 net.cpp:380] Convolution5 -> Convolution5
I1007 22:14:13.569124  5289 net.cpp:122] Setting up Convolution5
I1007 22:14:13.569133  5289 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:14:13.569135  5289 net.cpp:137] Memory required for data: 145409200
I1007 22:14:13.569140  5289 layer_factory.hpp:77] Creating layer BatchNorm5
I1007 22:14:13.569145  5289 net.cpp:84] Creating Layer BatchNorm5
I1007 22:14:13.569154  5289 net.cpp:406] BatchNorm5 <- Convolution5
I1007 22:14:13.569159  5289 net.cpp:367] BatchNorm5 -> Convolution5 (in-place)
I1007 22:14:13.569301  5289 net.cpp:122] Setting up BatchNorm5
I1007 22:14:13.569305  5289 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:14:13.569308  5289 net.cpp:137] Memory required for data: 151962800
I1007 22:14:13.569315  5289 layer_factory.hpp:77] Creating layer Scale5
I1007 22:14:13.569320  5289 net.cpp:84] Creating Layer Scale5
I1007 22:14:13.569322  5289 net.cpp:406] Scale5 <- Convolution5
I1007 22:14:13.569325  5289 net.cpp:367] Scale5 -> Convolution5 (in-place)
I1007 22:14:13.569353  5289 layer_factory.hpp:77] Creating layer Scale5
I1007 22:14:13.569432  5289 net.cpp:122] Setting up Scale5
I1007 22:14:13.569435  5289 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:14:13.569437  5289 net.cpp:137] Memory required for data: 158516400
I1007 22:14:13.569442  5289 layer_factory.hpp:77] Creating layer Eltwise2
I1007 22:14:13.569445  5289 net.cpp:84] Creating Layer Eltwise2
I1007 22:14:13.569448  5289 net.cpp:406] Eltwise2 <- Eltwise1_elu3_0_split_1
I1007 22:14:13.569450  5289 net.cpp:406] Eltwise2 <- Convolution5
I1007 22:14:13.569453  5289 net.cpp:380] Eltwise2 -> Eltwise2
I1007 22:14:13.569469  5289 net.cpp:122] Setting up Eltwise2
I1007 22:14:13.569473  5289 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:14:13.569475  5289 net.cpp:137] Memory required for data: 165070000
I1007 22:14:13.569478  5289 layer_factory.hpp:77] Creating layer elu5
I1007 22:14:13.569480  5289 net.cpp:84] Creating Layer elu5
I1007 22:14:13.569483  5289 net.cpp:406] elu5 <- Eltwise2
I1007 22:14:13.569486  5289 net.cpp:367] elu5 -> Eltwise2 (in-place)
I1007 22:14:13.569490  5289 net.cpp:122] Setting up elu5
I1007 22:14:13.569492  5289 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:14:13.569494  5289 net.cpp:137] Memory required for data: 171623600
I1007 22:14:13.569497  5289 layer_factory.hpp:77] Creating layer Eltwise2_elu5_0_split
I1007 22:14:13.569500  5289 net.cpp:84] Creating Layer Eltwise2_elu5_0_split
I1007 22:14:13.569502  5289 net.cpp:406] Eltwise2_elu5_0_split <- Eltwise2
I1007 22:14:13.569505  5289 net.cpp:380] Eltwise2_elu5_0_split -> Eltwise2_elu5_0_split_0
I1007 22:14:13.569509  5289 net.cpp:380] Eltwise2_elu5_0_split -> Eltwise2_elu5_0_split_1
I1007 22:14:13.569532  5289 net.cpp:122] Setting up Eltwise2_elu5_0_split
I1007 22:14:13.569536  5289 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:14:13.569540  5289 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:14:13.569541  5289 net.cpp:137] Memory required for data: 184730800
I1007 22:14:13.569543  5289 layer_factory.hpp:77] Creating layer Convolution6
I1007 22:14:13.569548  5289 net.cpp:84] Creating Layer Convolution6
I1007 22:14:13.569550  5289 net.cpp:406] Convolution6 <- Eltwise2_elu5_0_split_0
I1007 22:14:13.569555  5289 net.cpp:380] Convolution6 -> Convolution6
I1007 22:14:13.570459  5289 net.cpp:122] Setting up Convolution6
I1007 22:14:13.570468  5289 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:14:13.570471  5289 net.cpp:137] Memory required for data: 191284400
I1007 22:14:13.570474  5289 layer_factory.hpp:77] Creating layer BatchNorm6
I1007 22:14:13.570480  5289 net.cpp:84] Creating Layer BatchNorm6
I1007 22:14:13.570482  5289 net.cpp:406] BatchNorm6 <- Convolution6
I1007 22:14:13.570487  5289 net.cpp:367] BatchNorm6 -> Convolution6 (in-place)
I1007 22:14:13.570627  5289 net.cpp:122] Setting up BatchNorm6
I1007 22:14:13.570631  5289 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:14:13.570633  5289 net.cpp:137] Memory required for data: 197838000
I1007 22:14:13.570638  5289 layer_factory.hpp:77] Creating layer Scale6
I1007 22:14:13.570642  5289 net.cpp:84] Creating Layer Scale6
I1007 22:14:13.570644  5289 net.cpp:406] Scale6 <- Convolution6
I1007 22:14:13.570647  5289 net.cpp:367] Scale6 -> Convolution6 (in-place)
I1007 22:14:13.570675  5289 layer_factory.hpp:77] Creating layer Scale6
I1007 22:14:13.570755  5289 net.cpp:122] Setting up Scale6
I1007 22:14:13.570765  5289 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:14:13.570767  5289 net.cpp:137] Memory required for data: 204391600
I1007 22:14:13.570771  5289 layer_factory.hpp:77] Creating layer elu6
I1007 22:14:13.570776  5289 net.cpp:84] Creating Layer elu6
I1007 22:14:13.570778  5289 net.cpp:406] elu6 <- Convolution6
I1007 22:14:13.570781  5289 net.cpp:367] elu6 -> Convolution6 (in-place)
I1007 22:14:13.570785  5289 net.cpp:122] Setting up elu6
I1007 22:14:13.570788  5289 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:14:13.570791  5289 net.cpp:137] Memory required for data: 210945200
I1007 22:14:13.570792  5289 layer_factory.hpp:77] Creating layer Convolution7
I1007 22:14:13.570798  5289 net.cpp:84] Creating Layer Convolution7
I1007 22:14:13.570801  5289 net.cpp:406] Convolution7 <- Convolution6
I1007 22:14:13.570806  5289 net.cpp:380] Convolution7 -> Convolution7
I1007 22:14:13.571719  5289 net.cpp:122] Setting up Convolution7
I1007 22:14:13.571728  5289 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:14:13.571730  5289 net.cpp:137] Memory required for data: 217498800
I1007 22:14:13.571735  5289 layer_factory.hpp:77] Creating layer BatchNorm7
I1007 22:14:13.571741  5289 net.cpp:84] Creating Layer BatchNorm7
I1007 22:14:13.571744  5289 net.cpp:406] BatchNorm7 <- Convolution7
I1007 22:14:13.571748  5289 net.cpp:367] BatchNorm7 -> Convolution7 (in-place)
I1007 22:14:13.571892  5289 net.cpp:122] Setting up BatchNorm7
I1007 22:14:13.571895  5289 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:14:13.571897  5289 net.cpp:137] Memory required for data: 224052400
I1007 22:14:13.571902  5289 layer_factory.hpp:77] Creating layer Scale7
I1007 22:14:13.571907  5289 net.cpp:84] Creating Layer Scale7
I1007 22:14:13.571908  5289 net.cpp:406] Scale7 <- Convolution7
I1007 22:14:13.571912  5289 net.cpp:367] Scale7 -> Convolution7 (in-place)
I1007 22:14:13.571940  5289 layer_factory.hpp:77] Creating layer Scale7
I1007 22:14:13.572018  5289 net.cpp:122] Setting up Scale7
I1007 22:14:13.572023  5289 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:14:13.572026  5289 net.cpp:137] Memory required for data: 230606000
I1007 22:14:13.572028  5289 layer_factory.hpp:77] Creating layer Eltwise3
I1007 22:14:13.572032  5289 net.cpp:84] Creating Layer Eltwise3
I1007 22:14:13.572034  5289 net.cpp:406] Eltwise3 <- Eltwise2_elu5_0_split_1
I1007 22:14:13.572037  5289 net.cpp:406] Eltwise3 <- Convolution7
I1007 22:14:13.572041  5289 net.cpp:380] Eltwise3 -> Eltwise3
I1007 22:14:13.572057  5289 net.cpp:122] Setting up Eltwise3
I1007 22:14:13.572059  5289 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:14:13.572062  5289 net.cpp:137] Memory required for data: 237159600
I1007 22:14:13.572063  5289 layer_factory.hpp:77] Creating layer elu7
I1007 22:14:13.572069  5289 net.cpp:84] Creating Layer elu7
I1007 22:14:13.572072  5289 net.cpp:406] elu7 <- Eltwise3
I1007 22:14:13.572074  5289 net.cpp:367] elu7 -> Eltwise3 (in-place)
I1007 22:14:13.572078  5289 net.cpp:122] Setting up elu7
I1007 22:14:13.572082  5289 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:14:13.572083  5289 net.cpp:137] Memory required for data: 243713200
I1007 22:14:13.572085  5289 layer_factory.hpp:77] Creating layer Eltwise3_elu7_0_split
I1007 22:14:13.572088  5289 net.cpp:84] Creating Layer Eltwise3_elu7_0_split
I1007 22:14:13.572090  5289 net.cpp:406] Eltwise3_elu7_0_split <- Eltwise3
I1007 22:14:13.572093  5289 net.cpp:380] Eltwise3_elu7_0_split -> Eltwise3_elu7_0_split_0
I1007 22:14:13.572098  5289 net.cpp:380] Eltwise3_elu7_0_split -> Eltwise3_elu7_0_split_1
I1007 22:14:13.572121  5289 net.cpp:122] Setting up Eltwise3_elu7_0_split
I1007 22:14:13.572125  5289 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:14:13.572127  5289 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:14:13.572129  5289 net.cpp:137] Memory required for data: 256820400
I1007 22:14:13.572131  5289 layer_factory.hpp:77] Creating layer Convolution8
I1007 22:14:13.594070  5289 net.cpp:84] Creating Layer Convolution8
I1007 22:14:13.594080  5289 net.cpp:406] Convolution8 <- Eltwise3_elu7_0_split_0
I1007 22:14:13.594094  5289 net.cpp:380] Convolution8 -> Convolution8
I1007 22:14:13.595118  5289 net.cpp:122] Setting up Convolution8
I1007 22:14:13.595129  5289 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:14:13.595131  5289 net.cpp:137] Memory required for data: 263374000
I1007 22:14:13.595136  5289 layer_factory.hpp:77] Creating layer BatchNorm8
I1007 22:14:13.595142  5289 net.cpp:84] Creating Layer BatchNorm8
I1007 22:14:13.595145  5289 net.cpp:406] BatchNorm8 <- Convolution8
I1007 22:14:13.595149  5289 net.cpp:367] BatchNorm8 -> Convolution8 (in-place)
I1007 22:14:13.595315  5289 net.cpp:122] Setting up BatchNorm8
I1007 22:14:13.595321  5289 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:14:13.595324  5289 net.cpp:137] Memory required for data: 269927600
I1007 22:14:13.595329  5289 layer_factory.hpp:77] Creating layer Scale8
I1007 22:14:13.595335  5289 net.cpp:84] Creating Layer Scale8
I1007 22:14:13.595337  5289 net.cpp:406] Scale8 <- Convolution8
I1007 22:14:13.595340  5289 net.cpp:367] Scale8 -> Convolution8 (in-place)
I1007 22:14:13.595372  5289 layer_factory.hpp:77] Creating layer Scale8
I1007 22:14:13.595460  5289 net.cpp:122] Setting up Scale8
I1007 22:14:13.595464  5289 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:14:13.595468  5289 net.cpp:137] Memory required for data: 276481200
I1007 22:14:13.595471  5289 layer_factory.hpp:77] Creating layer elu8
I1007 22:14:13.595476  5289 net.cpp:84] Creating Layer elu8
I1007 22:14:13.595479  5289 net.cpp:406] elu8 <- Convolution8
I1007 22:14:13.595482  5289 net.cpp:367] elu8 -> Convolution8 (in-place)
I1007 22:14:13.595486  5289 net.cpp:122] Setting up elu8
I1007 22:14:13.595489  5289 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:14:13.595491  5289 net.cpp:137] Memory required for data: 283034800
I1007 22:14:13.595494  5289 layer_factory.hpp:77] Creating layer Convolution9
I1007 22:14:13.595500  5289 net.cpp:84] Creating Layer Convolution9
I1007 22:14:13.595504  5289 net.cpp:406] Convolution9 <- Convolution8
I1007 22:14:13.595508  5289 net.cpp:380] Convolution9 -> Convolution9
I1007 22:14:13.597019  5289 net.cpp:122] Setting up Convolution9
I1007 22:14:13.597028  5289 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:14:13.597031  5289 net.cpp:137] Memory required for data: 289588400
I1007 22:14:13.597035  5289 layer_factory.hpp:77] Creating layer BatchNorm9
I1007 22:14:13.597040  5289 net.cpp:84] Creating Layer BatchNorm9
I1007 22:14:13.597043  5289 net.cpp:406] BatchNorm9 <- Convolution9
I1007 22:14:13.597048  5289 net.cpp:367] BatchNorm9 -> Convolution9 (in-place)
I1007 22:14:13.597193  5289 net.cpp:122] Setting up BatchNorm9
I1007 22:14:13.597198  5289 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:14:13.597200  5289 net.cpp:137] Memory required for data: 296142000
I1007 22:14:13.597205  5289 layer_factory.hpp:77] Creating layer Scale9
I1007 22:14:13.597219  5289 net.cpp:84] Creating Layer Scale9
I1007 22:14:13.597223  5289 net.cpp:406] Scale9 <- Convolution9
I1007 22:14:13.597226  5289 net.cpp:367] Scale9 -> Convolution9 (in-place)
I1007 22:14:13.597265  5289 layer_factory.hpp:77] Creating layer Scale9
I1007 22:14:13.597368  5289 net.cpp:122] Setting up Scale9
I1007 22:14:13.597373  5289 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:14:13.597376  5289 net.cpp:137] Memory required for data: 302695600
I1007 22:14:13.597379  5289 layer_factory.hpp:77] Creating layer Eltwise4
I1007 22:14:13.597393  5289 net.cpp:84] Creating Layer Eltwise4
I1007 22:14:13.597395  5289 net.cpp:406] Eltwise4 <- Eltwise3_elu7_0_split_1
I1007 22:14:13.597398  5289 net.cpp:406] Eltwise4 <- Convolution9
I1007 22:14:13.597401  5289 net.cpp:380] Eltwise4 -> Eltwise4
I1007 22:14:13.597419  5289 net.cpp:122] Setting up Eltwise4
I1007 22:14:13.597424  5289 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:14:13.597425  5289 net.cpp:137] Memory required for data: 309249200
I1007 22:14:13.597427  5289 layer_factory.hpp:77] Creating layer elu9
I1007 22:14:13.597430  5289 net.cpp:84] Creating Layer elu9
I1007 22:14:13.597440  5289 net.cpp:406] elu9 <- Eltwise4
I1007 22:14:13.597445  5289 net.cpp:367] elu9 -> Eltwise4 (in-place)
I1007 22:14:13.597448  5289 net.cpp:122] Setting up elu9
I1007 22:14:13.597451  5289 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:14:13.597453  5289 net.cpp:137] Memory required for data: 315802800
I1007 22:14:13.597456  5289 layer_factory.hpp:77] Creating layer Eltwise4_elu9_0_split
I1007 22:14:13.597460  5289 net.cpp:84] Creating Layer Eltwise4_elu9_0_split
I1007 22:14:13.597461  5289 net.cpp:406] Eltwise4_elu9_0_split <- Eltwise4
I1007 22:14:13.597465  5289 net.cpp:380] Eltwise4_elu9_0_split -> Eltwise4_elu9_0_split_0
I1007 22:14:13.597468  5289 net.cpp:380] Eltwise4_elu9_0_split -> Eltwise4_elu9_0_split_1
I1007 22:14:13.597494  5289 net.cpp:122] Setting up Eltwise4_elu9_0_split
I1007 22:14:13.597498  5289 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:14:13.597501  5289 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:14:13.597502  5289 net.cpp:137] Memory required for data: 328910000
I1007 22:14:13.597504  5289 layer_factory.hpp:77] Creating layer Convolution10
I1007 22:14:13.597512  5289 net.cpp:84] Creating Layer Convolution10
I1007 22:14:13.597513  5289 net.cpp:406] Convolution10 <- Eltwise4_elu9_0_split_0
I1007 22:14:13.597517  5289 net.cpp:380] Convolution10 -> Convolution10
I1007 22:14:13.598242  5289 net.cpp:122] Setting up Convolution10
I1007 22:14:13.598250  5289 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:14:13.598253  5289 net.cpp:137] Memory required for data: 335463600
I1007 22:14:13.598263  5289 layer_factory.hpp:77] Creating layer BatchNorm10
I1007 22:14:13.598268  5289 net.cpp:84] Creating Layer BatchNorm10
I1007 22:14:13.598271  5289 net.cpp:406] BatchNorm10 <- Convolution10
I1007 22:14:13.598274  5289 net.cpp:367] BatchNorm10 -> Convolution10 (in-place)
I1007 22:14:13.598415  5289 net.cpp:122] Setting up BatchNorm10
I1007 22:14:13.598420  5289 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:14:13.598423  5289 net.cpp:137] Memory required for data: 342017200
I1007 22:14:13.598428  5289 layer_factory.hpp:77] Creating layer Scale10
I1007 22:14:13.598431  5289 net.cpp:84] Creating Layer Scale10
I1007 22:14:13.598434  5289 net.cpp:406] Scale10 <- Convolution10
I1007 22:14:13.598438  5289 net.cpp:367] Scale10 -> Convolution10 (in-place)
I1007 22:14:13.598465  5289 layer_factory.hpp:77] Creating layer Scale10
I1007 22:14:13.598544  5289 net.cpp:122] Setting up Scale10
I1007 22:14:13.598549  5289 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:14:13.598551  5289 net.cpp:137] Memory required for data: 348570800
I1007 22:14:13.598554  5289 layer_factory.hpp:77] Creating layer elu10
I1007 22:14:13.598558  5289 net.cpp:84] Creating Layer elu10
I1007 22:14:13.598561  5289 net.cpp:406] elu10 <- Convolution10
I1007 22:14:13.598565  5289 net.cpp:367] elu10 -> Convolution10 (in-place)
I1007 22:14:13.598568  5289 net.cpp:122] Setting up elu10
I1007 22:14:13.598572  5289 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:14:13.598573  5289 net.cpp:137] Memory required for data: 355124400
I1007 22:14:13.598575  5289 layer_factory.hpp:77] Creating layer Convolution11
I1007 22:14:13.598582  5289 net.cpp:84] Creating Layer Convolution11
I1007 22:14:13.598584  5289 net.cpp:406] Convolution11 <- Convolution10
I1007 22:14:13.598587  5289 net.cpp:380] Convolution11 -> Convolution11
I1007 22:14:13.599520  5289 net.cpp:122] Setting up Convolution11
I1007 22:14:13.599529  5289 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:14:13.599531  5289 net.cpp:137] Memory required for data: 361678000
I1007 22:14:13.599536  5289 layer_factory.hpp:77] Creating layer BatchNorm11
I1007 22:14:13.599541  5289 net.cpp:84] Creating Layer BatchNorm11
I1007 22:14:13.599545  5289 net.cpp:406] BatchNorm11 <- Convolution11
I1007 22:14:13.599548  5289 net.cpp:367] BatchNorm11 -> Convolution11 (in-place)
I1007 22:14:13.599697  5289 net.cpp:122] Setting up BatchNorm11
I1007 22:14:13.599701  5289 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:14:13.599710  5289 net.cpp:137] Memory required for data: 368231600
I1007 22:14:13.599716  5289 layer_factory.hpp:77] Creating layer Scale11
I1007 22:14:13.599721  5289 net.cpp:84] Creating Layer Scale11
I1007 22:14:13.599723  5289 net.cpp:406] Scale11 <- Convolution11
I1007 22:14:13.599726  5289 net.cpp:367] Scale11 -> Convolution11 (in-place)
I1007 22:14:13.599757  5289 layer_factory.hpp:77] Creating layer Scale11
I1007 22:14:13.599840  5289 net.cpp:122] Setting up Scale11
I1007 22:14:13.599844  5289 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:14:13.599846  5289 net.cpp:137] Memory required for data: 374785200
I1007 22:14:13.599850  5289 layer_factory.hpp:77] Creating layer Eltwise5
I1007 22:14:13.599854  5289 net.cpp:84] Creating Layer Eltwise5
I1007 22:14:13.599858  5289 net.cpp:406] Eltwise5 <- Eltwise4_elu9_0_split_1
I1007 22:14:13.599860  5289 net.cpp:406] Eltwise5 <- Convolution11
I1007 22:14:13.599864  5289 net.cpp:380] Eltwise5 -> Eltwise5
I1007 22:14:13.599880  5289 net.cpp:122] Setting up Eltwise5
I1007 22:14:13.599884  5289 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:14:13.599886  5289 net.cpp:137] Memory required for data: 381338800
I1007 22:14:13.599889  5289 layer_factory.hpp:77] Creating layer elu11
I1007 22:14:13.599891  5289 net.cpp:84] Creating Layer elu11
I1007 22:14:13.599895  5289 net.cpp:406] elu11 <- Eltwise5
I1007 22:14:13.599896  5289 net.cpp:367] elu11 -> Eltwise5 (in-place)
I1007 22:14:13.599900  5289 net.cpp:122] Setting up elu11
I1007 22:14:13.599903  5289 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:14:13.599905  5289 net.cpp:137] Memory required for data: 387892400
I1007 22:14:13.599907  5289 layer_factory.hpp:77] Creating layer Eltwise5_elu11_0_split
I1007 22:14:13.599911  5289 net.cpp:84] Creating Layer Eltwise5_elu11_0_split
I1007 22:14:13.599913  5289 net.cpp:406] Eltwise5_elu11_0_split <- Eltwise5
I1007 22:14:13.599916  5289 net.cpp:380] Eltwise5_elu11_0_split -> Eltwise5_elu11_0_split_0
I1007 22:14:13.599920  5289 net.cpp:380] Eltwise5_elu11_0_split -> Eltwise5_elu11_0_split_1
I1007 22:14:13.599944  5289 net.cpp:122] Setting up Eltwise5_elu11_0_split
I1007 22:14:13.599948  5289 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:14:13.599951  5289 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:14:13.599952  5289 net.cpp:137] Memory required for data: 400999600
I1007 22:14:13.599956  5289 layer_factory.hpp:77] Creating layer Convolution12
I1007 22:14:13.599961  5289 net.cpp:84] Creating Layer Convolution12
I1007 22:14:13.599963  5289 net.cpp:406] Convolution12 <- Eltwise5_elu11_0_split_0
I1007 22:14:13.599967  5289 net.cpp:380] Convolution12 -> Convolution12
I1007 22:14:13.600872  5289 net.cpp:122] Setting up Convolution12
I1007 22:14:13.600883  5289 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:14:13.600885  5289 net.cpp:137] Memory required for data: 404276400
I1007 22:14:13.600889  5289 layer_factory.hpp:77] Creating layer BatchNorm12
I1007 22:14:13.600894  5289 net.cpp:84] Creating Layer BatchNorm12
I1007 22:14:13.600896  5289 net.cpp:406] BatchNorm12 <- Convolution12
I1007 22:14:13.600901  5289 net.cpp:367] BatchNorm12 -> Convolution12 (in-place)
I1007 22:14:13.601045  5289 net.cpp:122] Setting up BatchNorm12
I1007 22:14:13.601049  5289 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:14:13.601052  5289 net.cpp:137] Memory required for data: 407553200
I1007 22:14:13.601056  5289 layer_factory.hpp:77] Creating layer Scale12
I1007 22:14:13.601060  5289 net.cpp:84] Creating Layer Scale12
I1007 22:14:13.601063  5289 net.cpp:406] Scale12 <- Convolution12
I1007 22:14:13.601066  5289 net.cpp:367] Scale12 -> Convolution12 (in-place)
I1007 22:14:13.601095  5289 layer_factory.hpp:77] Creating layer Scale12
I1007 22:14:13.601176  5289 net.cpp:122] Setting up Scale12
I1007 22:14:13.601181  5289 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:14:13.601182  5289 net.cpp:137] Memory required for data: 410830000
I1007 22:14:13.601186  5289 layer_factory.hpp:77] Creating layer Convolution13
I1007 22:14:13.601193  5289 net.cpp:84] Creating Layer Convolution13
I1007 22:14:13.601202  5289 net.cpp:406] Convolution13 <- Eltwise5_elu11_0_split_1
I1007 22:14:13.601208  5289 net.cpp:380] Convolution13 -> Convolution13
I1007 22:14:13.602203  5289 net.cpp:122] Setting up Convolution13
I1007 22:14:13.602211  5289 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:14:13.602214  5289 net.cpp:137] Memory required for data: 414106800
I1007 22:14:13.602218  5289 layer_factory.hpp:77] Creating layer BatchNorm13
I1007 22:14:13.602224  5289 net.cpp:84] Creating Layer BatchNorm13
I1007 22:14:13.602227  5289 net.cpp:406] BatchNorm13 <- Convolution13
I1007 22:14:13.602231  5289 net.cpp:367] BatchNorm13 -> Convolution13 (in-place)
I1007 22:14:13.602373  5289 net.cpp:122] Setting up BatchNorm13
I1007 22:14:13.602378  5289 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:14:13.602380  5289 net.cpp:137] Memory required for data: 417383600
I1007 22:14:13.602385  5289 layer_factory.hpp:77] Creating layer Scale13
I1007 22:14:13.602391  5289 net.cpp:84] Creating Layer Scale13
I1007 22:14:13.602392  5289 net.cpp:406] Scale13 <- Convolution13
I1007 22:14:13.602396  5289 net.cpp:367] Scale13 -> Convolution13 (in-place)
I1007 22:14:13.602425  5289 layer_factory.hpp:77] Creating layer Scale13
I1007 22:14:13.602509  5289 net.cpp:122] Setting up Scale13
I1007 22:14:13.602514  5289 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:14:13.602515  5289 net.cpp:137] Memory required for data: 420660400
I1007 22:14:13.602519  5289 layer_factory.hpp:77] Creating layer elu12
I1007 22:14:13.602524  5289 net.cpp:84] Creating Layer elu12
I1007 22:14:13.602525  5289 net.cpp:406] elu12 <- Convolution13
I1007 22:14:13.602530  5289 net.cpp:367] elu12 -> Convolution13 (in-place)
I1007 22:14:13.602533  5289 net.cpp:122] Setting up elu12
I1007 22:14:13.602536  5289 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:14:13.602538  5289 net.cpp:137] Memory required for data: 423937200
I1007 22:14:13.602540  5289 layer_factory.hpp:77] Creating layer Convolution14
I1007 22:14:13.602551  5289 net.cpp:84] Creating Layer Convolution14
I1007 22:14:13.602553  5289 net.cpp:406] Convolution14 <- Convolution13
I1007 22:14:13.602557  5289 net.cpp:380] Convolution14 -> Convolution14
I1007 22:14:13.603636  5289 net.cpp:122] Setting up Convolution14
I1007 22:14:13.603646  5289 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:14:13.603648  5289 net.cpp:137] Memory required for data: 427214000
I1007 22:14:13.603653  5289 layer_factory.hpp:77] Creating layer BatchNorm14
I1007 22:14:13.603658  5289 net.cpp:84] Creating Layer BatchNorm14
I1007 22:14:13.603660  5289 net.cpp:406] BatchNorm14 <- Convolution14
I1007 22:14:13.603665  5289 net.cpp:367] BatchNorm14 -> Convolution14 (in-place)
I1007 22:14:13.603811  5289 net.cpp:122] Setting up BatchNorm14
I1007 22:14:13.603814  5289 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:14:13.603816  5289 net.cpp:137] Memory required for data: 430490800
I1007 22:14:13.603821  5289 layer_factory.hpp:77] Creating layer Scale14
I1007 22:14:13.603826  5289 net.cpp:84] Creating Layer Scale14
I1007 22:14:13.603827  5289 net.cpp:406] Scale14 <- Convolution14
I1007 22:14:13.603830  5289 net.cpp:367] Scale14 -> Convolution14 (in-place)
I1007 22:14:13.603860  5289 layer_factory.hpp:77] Creating layer Scale14
I1007 22:14:13.603943  5289 net.cpp:122] Setting up Scale14
I1007 22:14:13.603947  5289 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:14:13.603950  5289 net.cpp:137] Memory required for data: 433767600
I1007 22:14:13.603953  5289 layer_factory.hpp:77] Creating layer Eltwise6
I1007 22:14:13.603957  5289 net.cpp:84] Creating Layer Eltwise6
I1007 22:14:13.603960  5289 net.cpp:406] Eltwise6 <- Convolution12
I1007 22:14:13.603962  5289 net.cpp:406] Eltwise6 <- Convolution14
I1007 22:14:13.603966  5289 net.cpp:380] Eltwise6 -> Eltwise6
I1007 22:14:13.624552  5289 net.cpp:122] Setting up Eltwise6
I1007 22:14:13.624563  5289 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:14:13.624568  5289 net.cpp:137] Memory required for data: 437044400
I1007 22:14:13.624581  5289 layer_factory.hpp:77] Creating layer elu13
I1007 22:14:13.624588  5289 net.cpp:84] Creating Layer elu13
I1007 22:14:13.624591  5289 net.cpp:406] elu13 <- Eltwise6
I1007 22:14:13.624598  5289 net.cpp:367] elu13 -> Eltwise6 (in-place)
I1007 22:14:13.624601  5289 net.cpp:122] Setting up elu13
I1007 22:14:13.624605  5289 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:14:13.624608  5289 net.cpp:137] Memory required for data: 440321200
I1007 22:14:13.624610  5289 layer_factory.hpp:77] Creating layer Eltwise6_elu13_0_split
I1007 22:14:13.624614  5289 net.cpp:84] Creating Layer Eltwise6_elu13_0_split
I1007 22:14:13.624616  5289 net.cpp:406] Eltwise6_elu13_0_split <- Eltwise6
I1007 22:14:13.624619  5289 net.cpp:380] Eltwise6_elu13_0_split -> Eltwise6_elu13_0_split_0
I1007 22:14:13.624624  5289 net.cpp:380] Eltwise6_elu13_0_split -> Eltwise6_elu13_0_split_1
I1007 22:14:13.624656  5289 net.cpp:122] Setting up Eltwise6_elu13_0_split
I1007 22:14:13.624660  5289 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:14:13.624663  5289 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:14:13.624665  5289 net.cpp:137] Memory required for data: 446874800
I1007 22:14:13.624668  5289 layer_factory.hpp:77] Creating layer Convolution15
I1007 22:14:13.624675  5289 net.cpp:84] Creating Layer Convolution15
I1007 22:14:13.624676  5289 net.cpp:406] Convolution15 <- Eltwise6_elu13_0_split_0
I1007 22:14:13.624682  5289 net.cpp:380] Convolution15 -> Convolution15
I1007 22:14:13.626252  5289 net.cpp:122] Setting up Convolution15
I1007 22:14:13.626261  5289 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:14:13.626265  5289 net.cpp:137] Memory required for data: 450151600
I1007 22:14:13.626271  5289 layer_factory.hpp:77] Creating layer BatchNorm15
I1007 22:14:13.626276  5289 net.cpp:84] Creating Layer BatchNorm15
I1007 22:14:13.626279  5289 net.cpp:406] BatchNorm15 <- Convolution15
I1007 22:14:13.626283  5289 net.cpp:367] BatchNorm15 -> Convolution15 (in-place)
I1007 22:14:13.626443  5289 net.cpp:122] Setting up BatchNorm15
I1007 22:14:13.626448  5289 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:14:13.626451  5289 net.cpp:137] Memory required for data: 453428400
I1007 22:14:13.626456  5289 layer_factory.hpp:77] Creating layer Scale15
I1007 22:14:13.626459  5289 net.cpp:84] Creating Layer Scale15
I1007 22:14:13.626462  5289 net.cpp:406] Scale15 <- Convolution15
I1007 22:14:13.626466  5289 net.cpp:367] Scale15 -> Convolution15 (in-place)
I1007 22:14:13.626497  5289 layer_factory.hpp:77] Creating layer Scale15
I1007 22:14:13.626581  5289 net.cpp:122] Setting up Scale15
I1007 22:14:13.626585  5289 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:14:13.626587  5289 net.cpp:137] Memory required for data: 456705200
I1007 22:14:13.626591  5289 layer_factory.hpp:77] Creating layer elu14
I1007 22:14:13.626595  5289 net.cpp:84] Creating Layer elu14
I1007 22:14:13.626597  5289 net.cpp:406] elu14 <- Convolution15
I1007 22:14:13.626600  5289 net.cpp:367] elu14 -> Convolution15 (in-place)
I1007 22:14:13.626605  5289 net.cpp:122] Setting up elu14
I1007 22:14:13.626608  5289 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:14:13.626610  5289 net.cpp:137] Memory required for data: 459982000
I1007 22:14:13.626612  5289 layer_factory.hpp:77] Creating layer Convolution16
I1007 22:14:13.626634  5289 net.cpp:84] Creating Layer Convolution16
I1007 22:14:13.626638  5289 net.cpp:406] Convolution16 <- Convolution15
I1007 22:14:13.626653  5289 net.cpp:380] Convolution16 -> Convolution16
I1007 22:14:13.627856  5289 net.cpp:122] Setting up Convolution16
I1007 22:14:13.627864  5289 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:14:13.627867  5289 net.cpp:137] Memory required for data: 463258800
I1007 22:14:13.627872  5289 layer_factory.hpp:77] Creating layer BatchNorm16
I1007 22:14:13.627877  5289 net.cpp:84] Creating Layer BatchNorm16
I1007 22:14:13.627881  5289 net.cpp:406] BatchNorm16 <- Convolution16
I1007 22:14:13.627885  5289 net.cpp:367] BatchNorm16 -> Convolution16 (in-place)
I1007 22:14:13.628034  5289 net.cpp:122] Setting up BatchNorm16
I1007 22:14:13.628039  5289 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:14:13.628041  5289 net.cpp:137] Memory required for data: 466535600
I1007 22:14:13.628046  5289 layer_factory.hpp:77] Creating layer Scale16
I1007 22:14:13.628051  5289 net.cpp:84] Creating Layer Scale16
I1007 22:14:13.628053  5289 net.cpp:406] Scale16 <- Convolution16
I1007 22:14:13.628057  5289 net.cpp:367] Scale16 -> Convolution16 (in-place)
I1007 22:14:13.628085  5289 layer_factory.hpp:77] Creating layer Scale16
I1007 22:14:13.628170  5289 net.cpp:122] Setting up Scale16
I1007 22:14:13.628173  5289 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:14:13.628175  5289 net.cpp:137] Memory required for data: 469812400
I1007 22:14:13.628180  5289 layer_factory.hpp:77] Creating layer Eltwise7
I1007 22:14:13.628183  5289 net.cpp:84] Creating Layer Eltwise7
I1007 22:14:13.628185  5289 net.cpp:406] Eltwise7 <- Eltwise6_elu13_0_split_1
I1007 22:14:13.628188  5289 net.cpp:406] Eltwise7 <- Convolution16
I1007 22:14:13.628192  5289 net.cpp:380] Eltwise7 -> Eltwise7
I1007 22:14:13.628206  5289 net.cpp:122] Setting up Eltwise7
I1007 22:14:13.628209  5289 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:14:13.628211  5289 net.cpp:137] Memory required for data: 473089200
I1007 22:14:13.628213  5289 layer_factory.hpp:77] Creating layer elu15
I1007 22:14:13.628217  5289 net.cpp:84] Creating Layer elu15
I1007 22:14:13.628221  5289 net.cpp:406] elu15 <- Eltwise7
I1007 22:14:13.628223  5289 net.cpp:367] elu15 -> Eltwise7 (in-place)
I1007 22:14:13.628227  5289 net.cpp:122] Setting up elu15
I1007 22:14:13.628231  5289 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:14:13.628232  5289 net.cpp:137] Memory required for data: 476366000
I1007 22:14:13.628234  5289 layer_factory.hpp:77] Creating layer Eltwise7_elu15_0_split
I1007 22:14:13.628237  5289 net.cpp:84] Creating Layer Eltwise7_elu15_0_split
I1007 22:14:13.628239  5289 net.cpp:406] Eltwise7_elu15_0_split <- Eltwise7
I1007 22:14:13.628242  5289 net.cpp:380] Eltwise7_elu15_0_split -> Eltwise7_elu15_0_split_0
I1007 22:14:13.628247  5289 net.cpp:380] Eltwise7_elu15_0_split -> Eltwise7_elu15_0_split_1
I1007 22:14:13.628270  5289 net.cpp:122] Setting up Eltwise7_elu15_0_split
I1007 22:14:13.628274  5289 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:14:13.628278  5289 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:14:13.628279  5289 net.cpp:137] Memory required for data: 482919600
I1007 22:14:13.628281  5289 layer_factory.hpp:77] Creating layer Convolution17
I1007 22:14:13.628288  5289 net.cpp:84] Creating Layer Convolution17
I1007 22:14:13.628289  5289 net.cpp:406] Convolution17 <- Eltwise7_elu15_0_split_0
I1007 22:14:13.628293  5289 net.cpp:380] Convolution17 -> Convolution17
I1007 22:14:13.629382  5289 net.cpp:122] Setting up Convolution17
I1007 22:14:13.629391  5289 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:14:13.629393  5289 net.cpp:137] Memory required for data: 486196400
I1007 22:14:13.629397  5289 layer_factory.hpp:77] Creating layer BatchNorm17
I1007 22:14:13.629405  5289 net.cpp:84] Creating Layer BatchNorm17
I1007 22:14:13.629407  5289 net.cpp:406] BatchNorm17 <- Convolution17
I1007 22:14:13.629411  5289 net.cpp:367] BatchNorm17 -> Convolution17 (in-place)
I1007 22:14:13.629557  5289 net.cpp:122] Setting up BatchNorm17
I1007 22:14:13.629561  5289 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:14:13.629565  5289 net.cpp:137] Memory required for data: 489473200
I1007 22:14:13.629568  5289 layer_factory.hpp:77] Creating layer Scale17
I1007 22:14:13.629572  5289 net.cpp:84] Creating Layer Scale17
I1007 22:14:13.629575  5289 net.cpp:406] Scale17 <- Convolution17
I1007 22:14:13.629580  5289 net.cpp:367] Scale17 -> Convolution17 (in-place)
I1007 22:14:13.629608  5289 layer_factory.hpp:77] Creating layer Scale17
I1007 22:14:13.629691  5289 net.cpp:122] Setting up Scale17
I1007 22:14:13.629695  5289 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:14:13.629698  5289 net.cpp:137] Memory required for data: 492750000
I1007 22:14:13.629709  5289 layer_factory.hpp:77] Creating layer elu16
I1007 22:14:13.629712  5289 net.cpp:84] Creating Layer elu16
I1007 22:14:13.629714  5289 net.cpp:406] elu16 <- Convolution17
I1007 22:14:13.629719  5289 net.cpp:367] elu16 -> Convolution17 (in-place)
I1007 22:14:13.629724  5289 net.cpp:122] Setting up elu16
I1007 22:14:13.629726  5289 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:14:13.629729  5289 net.cpp:137] Memory required for data: 496026800
I1007 22:14:13.629730  5289 layer_factory.hpp:77] Creating layer Convolution18
I1007 22:14:13.629736  5289 net.cpp:84] Creating Layer Convolution18
I1007 22:14:13.629739  5289 net.cpp:406] Convolution18 <- Convolution17
I1007 22:14:13.629742  5289 net.cpp:380] Convolution18 -> Convolution18
I1007 22:14:13.630831  5289 net.cpp:122] Setting up Convolution18
I1007 22:14:13.630838  5289 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:14:13.630841  5289 net.cpp:137] Memory required for data: 499303600
I1007 22:14:13.630846  5289 layer_factory.hpp:77] Creating layer BatchNorm18
I1007 22:14:13.630851  5289 net.cpp:84] Creating Layer BatchNorm18
I1007 22:14:13.630854  5289 net.cpp:406] BatchNorm18 <- Convolution18
I1007 22:14:13.630857  5289 net.cpp:367] BatchNorm18 -> Convolution18 (in-place)
I1007 22:14:13.631001  5289 net.cpp:122] Setting up BatchNorm18
I1007 22:14:13.631006  5289 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:14:13.631008  5289 net.cpp:137] Memory required for data: 502580400
I1007 22:14:13.631013  5289 layer_factory.hpp:77] Creating layer Scale18
I1007 22:14:13.631017  5289 net.cpp:84] Creating Layer Scale18
I1007 22:14:13.631019  5289 net.cpp:406] Scale18 <- Convolution18
I1007 22:14:13.631022  5289 net.cpp:367] Scale18 -> Convolution18 (in-place)
I1007 22:14:13.631052  5289 layer_factory.hpp:77] Creating layer Scale18
I1007 22:14:13.631134  5289 net.cpp:122] Setting up Scale18
I1007 22:14:13.631139  5289 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:14:13.631141  5289 net.cpp:137] Memory required for data: 505857200
I1007 22:14:13.631145  5289 layer_factory.hpp:77] Creating layer Eltwise8
I1007 22:14:13.631150  5289 net.cpp:84] Creating Layer Eltwise8
I1007 22:14:13.631151  5289 net.cpp:406] Eltwise8 <- Eltwise7_elu15_0_split_1
I1007 22:14:13.631155  5289 net.cpp:406] Eltwise8 <- Convolution18
I1007 22:14:13.631157  5289 net.cpp:380] Eltwise8 -> Eltwise8
I1007 22:14:13.631176  5289 net.cpp:122] Setting up Eltwise8
I1007 22:14:13.631181  5289 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:14:13.631183  5289 net.cpp:137] Memory required for data: 509134000
I1007 22:14:13.631186  5289 layer_factory.hpp:77] Creating layer elu17
I1007 22:14:13.631189  5289 net.cpp:84] Creating Layer elu17
I1007 22:14:13.631191  5289 net.cpp:406] elu17 <- Eltwise8
I1007 22:14:13.631196  5289 net.cpp:367] elu17 -> Eltwise8 (in-place)
I1007 22:14:13.631198  5289 net.cpp:122] Setting up elu17
I1007 22:14:13.631201  5289 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:14:13.631203  5289 net.cpp:137] Memory required for data: 512410800
I1007 22:14:13.631206  5289 layer_factory.hpp:77] Creating layer Eltwise8_elu17_0_split
I1007 22:14:13.631209  5289 net.cpp:84] Creating Layer Eltwise8_elu17_0_split
I1007 22:14:13.631211  5289 net.cpp:406] Eltwise8_elu17_0_split <- Eltwise8
I1007 22:14:13.631214  5289 net.cpp:380] Eltwise8_elu17_0_split -> Eltwise8_elu17_0_split_0
I1007 22:14:13.631217  5289 net.cpp:380] Eltwise8_elu17_0_split -> Eltwise8_elu17_0_split_1
I1007 22:14:13.631243  5289 net.cpp:122] Setting up Eltwise8_elu17_0_split
I1007 22:14:13.631247  5289 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:14:13.631249  5289 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:14:13.631252  5289 net.cpp:137] Memory required for data: 518964400
I1007 22:14:13.631254  5289 layer_factory.hpp:77] Creating layer Convolution19
I1007 22:14:13.631260  5289 net.cpp:84] Creating Layer Convolution19
I1007 22:14:13.631263  5289 net.cpp:406] Convolution19 <- Eltwise8_elu17_0_split_0
I1007 22:14:13.631268  5289 net.cpp:380] Convolution19 -> Convolution19
I1007 22:14:13.632367  5289 net.cpp:122] Setting up Convolution19
I1007 22:14:13.632376  5289 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:14:13.632380  5289 net.cpp:137] Memory required for data: 522241200
I1007 22:14:13.632383  5289 layer_factory.hpp:77] Creating layer BatchNorm19
I1007 22:14:13.632388  5289 net.cpp:84] Creating Layer BatchNorm19
I1007 22:14:13.632391  5289 net.cpp:406] BatchNorm19 <- Convolution19
I1007 22:14:13.632395  5289 net.cpp:367] BatchNorm19 -> Convolution19 (in-place)
I1007 22:14:13.632542  5289 net.cpp:122] Setting up BatchNorm19
I1007 22:14:13.632547  5289 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:14:13.632550  5289 net.cpp:137] Memory required for data: 525518000
I1007 22:14:13.632565  5289 layer_factory.hpp:77] Creating layer Scale19
I1007 22:14:13.632570  5289 net.cpp:84] Creating Layer Scale19
I1007 22:14:13.632571  5289 net.cpp:406] Scale19 <- Convolution19
I1007 22:14:13.632575  5289 net.cpp:367] Scale19 -> Convolution19 (in-place)
I1007 22:14:13.632607  5289 layer_factory.hpp:77] Creating layer Scale19
I1007 22:14:13.632691  5289 net.cpp:122] Setting up Scale19
I1007 22:14:13.632695  5289 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:14:13.632697  5289 net.cpp:137] Memory required for data: 528794800
I1007 22:14:13.632701  5289 layer_factory.hpp:77] Creating layer elu18
I1007 22:14:13.632705  5289 net.cpp:84] Creating Layer elu18
I1007 22:14:13.632707  5289 net.cpp:406] elu18 <- Convolution19
I1007 22:14:13.632710  5289 net.cpp:367] elu18 -> Convolution19 (in-place)
I1007 22:14:13.632714  5289 net.cpp:122] Setting up elu18
I1007 22:14:13.632717  5289 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:14:13.632719  5289 net.cpp:137] Memory required for data: 532071600
I1007 22:14:13.632721  5289 layer_factory.hpp:77] Creating layer Convolution20
I1007 22:14:13.632728  5289 net.cpp:84] Creating Layer Convolution20
I1007 22:14:13.632730  5289 net.cpp:406] Convolution20 <- Convolution19
I1007 22:14:13.632735  5289 net.cpp:380] Convolution20 -> Convolution20
I1007 22:14:13.633487  5289 net.cpp:122] Setting up Convolution20
I1007 22:14:13.633496  5289 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:14:13.633497  5289 net.cpp:137] Memory required for data: 535348400
I1007 22:14:13.633502  5289 layer_factory.hpp:77] Creating layer BatchNorm20
I1007 22:14:13.633507  5289 net.cpp:84] Creating Layer BatchNorm20
I1007 22:14:13.633509  5289 net.cpp:406] BatchNorm20 <- Convolution20
I1007 22:14:13.633513  5289 net.cpp:367] BatchNorm20 -> Convolution20 (in-place)
I1007 22:14:13.633657  5289 net.cpp:122] Setting up BatchNorm20
I1007 22:14:13.633661  5289 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:14:13.633663  5289 net.cpp:137] Memory required for data: 538625200
I1007 22:14:13.633667  5289 layer_factory.hpp:77] Creating layer Scale20
I1007 22:14:13.633672  5289 net.cpp:84] Creating Layer Scale20
I1007 22:14:13.633674  5289 net.cpp:406] Scale20 <- Convolution20
I1007 22:14:13.633677  5289 net.cpp:367] Scale20 -> Convolution20 (in-place)
I1007 22:14:13.633707  5289 layer_factory.hpp:77] Creating layer Scale20
I1007 22:14:13.633788  5289 net.cpp:122] Setting up Scale20
I1007 22:14:13.633793  5289 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:14:13.633795  5289 net.cpp:137] Memory required for data: 541902000
I1007 22:14:13.633798  5289 layer_factory.hpp:77] Creating layer Eltwise9
I1007 22:14:13.633802  5289 net.cpp:84] Creating Layer Eltwise9
I1007 22:14:13.633805  5289 net.cpp:406] Eltwise9 <- Eltwise8_elu17_0_split_1
I1007 22:14:13.633808  5289 net.cpp:406] Eltwise9 <- Convolution20
I1007 22:14:13.633811  5289 net.cpp:380] Eltwise9 -> Eltwise9
I1007 22:14:13.655006  5289 net.cpp:122] Setting up Eltwise9
I1007 22:14:13.655014  5289 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:14:13.655019  5289 net.cpp:137] Memory required for data: 545178800
I1007 22:14:13.655022  5289 layer_factory.hpp:77] Creating layer elu19
I1007 22:14:13.655030  5289 net.cpp:84] Creating Layer elu19
I1007 22:14:13.655035  5289 net.cpp:406] elu19 <- Eltwise9
I1007 22:14:13.655047  5289 net.cpp:367] elu19 -> Eltwise9 (in-place)
I1007 22:14:13.655055  5289 net.cpp:122] Setting up elu19
I1007 22:14:13.655059  5289 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:14:13.655061  5289 net.cpp:137] Memory required for data: 548455600
I1007 22:14:13.655063  5289 layer_factory.hpp:77] Creating layer Eltwise9_elu19_0_split
I1007 22:14:13.655067  5289 net.cpp:84] Creating Layer Eltwise9_elu19_0_split
I1007 22:14:13.655069  5289 net.cpp:406] Eltwise9_elu19_0_split <- Eltwise9
I1007 22:14:13.655074  5289 net.cpp:380] Eltwise9_elu19_0_split -> Eltwise9_elu19_0_split_0
I1007 22:14:13.655078  5289 net.cpp:380] Eltwise9_elu19_0_split -> Eltwise9_elu19_0_split_1
I1007 22:14:13.655107  5289 net.cpp:122] Setting up Eltwise9_elu19_0_split
I1007 22:14:13.655112  5289 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:14:13.655114  5289 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:14:13.655117  5289 net.cpp:137] Memory required for data: 555009200
I1007 22:14:13.655118  5289 layer_factory.hpp:77] Creating layer Convolution21
I1007 22:14:13.655127  5289 net.cpp:84] Creating Layer Convolution21
I1007 22:14:13.655128  5289 net.cpp:406] Convolution21 <- Eltwise9_elu19_0_split_0
I1007 22:14:13.655133  5289 net.cpp:380] Convolution21 -> Convolution21
I1007 22:14:13.656390  5289 net.cpp:122] Setting up Convolution21
I1007 22:14:13.656399  5289 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:14:13.656402  5289 net.cpp:137] Memory required for data: 558286000
I1007 22:14:13.656409  5289 layer_factory.hpp:77] Creating layer BatchNorm21
I1007 22:14:13.656417  5289 net.cpp:84] Creating Layer BatchNorm21
I1007 22:14:13.656422  5289 net.cpp:406] BatchNorm21 <- Convolution21
I1007 22:14:13.656428  5289 net.cpp:367] BatchNorm21 -> Convolution21 (in-place)
I1007 22:14:13.656617  5289 net.cpp:122] Setting up BatchNorm21
I1007 22:14:13.656625  5289 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:14:13.656628  5289 net.cpp:137] Memory required for data: 561562800
I1007 22:14:13.656636  5289 layer_factory.hpp:77] Creating layer Scale21
I1007 22:14:13.656642  5289 net.cpp:84] Creating Layer Scale21
I1007 22:14:13.656646  5289 net.cpp:406] Scale21 <- Convolution21
I1007 22:14:13.656652  5289 net.cpp:367] Scale21 -> Convolution21 (in-place)
I1007 22:14:13.656693  5289 layer_factory.hpp:77] Creating layer Scale21
I1007 22:14:13.656814  5289 net.cpp:122] Setting up Scale21
I1007 22:14:13.656819  5289 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:14:13.656821  5289 net.cpp:137] Memory required for data: 564839600
I1007 22:14:13.656826  5289 layer_factory.hpp:77] Creating layer elu20
I1007 22:14:13.656829  5289 net.cpp:84] Creating Layer elu20
I1007 22:14:13.656831  5289 net.cpp:406] elu20 <- Convolution21
I1007 22:14:13.656834  5289 net.cpp:367] elu20 -> Convolution21 (in-place)
I1007 22:14:13.656838  5289 net.cpp:122] Setting up elu20
I1007 22:14:13.656841  5289 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:14:13.656843  5289 net.cpp:137] Memory required for data: 568116400
I1007 22:14:13.656846  5289 layer_factory.hpp:77] Creating layer Convolution22
I1007 22:14:13.656852  5289 net.cpp:84] Creating Layer Convolution22
I1007 22:14:13.656855  5289 net.cpp:406] Convolution22 <- Convolution21
I1007 22:14:13.656858  5289 net.cpp:380] Convolution22 -> Convolution22
I1007 22:14:13.657951  5289 net.cpp:122] Setting up Convolution22
I1007 22:14:13.657959  5289 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:14:13.657963  5289 net.cpp:137] Memory required for data: 571393200
I1007 22:14:13.657968  5289 layer_factory.hpp:77] Creating layer BatchNorm22
I1007 22:14:13.657972  5289 net.cpp:84] Creating Layer BatchNorm22
I1007 22:14:13.657975  5289 net.cpp:406] BatchNorm22 <- Convolution22
I1007 22:14:13.657979  5289 net.cpp:367] BatchNorm22 -> Convolution22 (in-place)
I1007 22:14:13.658126  5289 net.cpp:122] Setting up BatchNorm22
I1007 22:14:13.658130  5289 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:14:13.658133  5289 net.cpp:137] Memory required for data: 574670000
I1007 22:14:13.658144  5289 layer_factory.hpp:77] Creating layer Scale22
I1007 22:14:13.658149  5289 net.cpp:84] Creating Layer Scale22
I1007 22:14:13.658151  5289 net.cpp:406] Scale22 <- Convolution22
I1007 22:14:13.658155  5289 net.cpp:367] Scale22 -> Convolution22 (in-place)
I1007 22:14:13.658185  5289 layer_factory.hpp:77] Creating layer Scale22
I1007 22:14:13.658269  5289 net.cpp:122] Setting up Scale22
I1007 22:14:13.658274  5289 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:14:13.658277  5289 net.cpp:137] Memory required for data: 577946800
I1007 22:14:13.658280  5289 layer_factory.hpp:77] Creating layer Eltwise10
I1007 22:14:13.658283  5289 net.cpp:84] Creating Layer Eltwise10
I1007 22:14:13.658287  5289 net.cpp:406] Eltwise10 <- Eltwise9_elu19_0_split_1
I1007 22:14:13.658289  5289 net.cpp:406] Eltwise10 <- Convolution22
I1007 22:14:13.658293  5289 net.cpp:380] Eltwise10 -> Eltwise10
I1007 22:14:13.658308  5289 net.cpp:122] Setting up Eltwise10
I1007 22:14:13.658310  5289 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:14:13.658313  5289 net.cpp:137] Memory required for data: 581223600
I1007 22:14:13.658314  5289 layer_factory.hpp:77] Creating layer elu21
I1007 22:14:13.658318  5289 net.cpp:84] Creating Layer elu21
I1007 22:14:13.658321  5289 net.cpp:406] elu21 <- Eltwise10
I1007 22:14:13.658324  5289 net.cpp:367] elu21 -> Eltwise10 (in-place)
I1007 22:14:13.658329  5289 net.cpp:122] Setting up elu21
I1007 22:14:13.658331  5289 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:14:13.658334  5289 net.cpp:137] Memory required for data: 584500400
I1007 22:14:13.658335  5289 layer_factory.hpp:77] Creating layer Eltwise10_elu21_0_split
I1007 22:14:13.658339  5289 net.cpp:84] Creating Layer Eltwise10_elu21_0_split
I1007 22:14:13.658340  5289 net.cpp:406] Eltwise10_elu21_0_split <- Eltwise10
I1007 22:14:13.658344  5289 net.cpp:380] Eltwise10_elu21_0_split -> Eltwise10_elu21_0_split_0
I1007 22:14:13.658347  5289 net.cpp:380] Eltwise10_elu21_0_split -> Eltwise10_elu21_0_split_1
I1007 22:14:13.658373  5289 net.cpp:122] Setting up Eltwise10_elu21_0_split
I1007 22:14:13.658377  5289 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:14:13.658380  5289 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:14:13.658381  5289 net.cpp:137] Memory required for data: 591054000
I1007 22:14:13.658385  5289 layer_factory.hpp:77] Creating layer Convolution23
I1007 22:14:13.658390  5289 net.cpp:84] Creating Layer Convolution23
I1007 22:14:13.658392  5289 net.cpp:406] Convolution23 <- Eltwise10_elu21_0_split_0
I1007 22:14:13.658396  5289 net.cpp:380] Convolution23 -> Convolution23
I1007 22:14:13.659364  5289 net.cpp:122] Setting up Convolution23
I1007 22:14:13.659373  5289 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:14:13.659376  5289 net.cpp:137] Memory required for data: 592692400
I1007 22:14:13.659380  5289 layer_factory.hpp:77] Creating layer BatchNorm23
I1007 22:14:13.659386  5289 net.cpp:84] Creating Layer BatchNorm23
I1007 22:14:13.659389  5289 net.cpp:406] BatchNorm23 <- Convolution23
I1007 22:14:13.659394  5289 net.cpp:367] BatchNorm23 -> Convolution23 (in-place)
I1007 22:14:13.659543  5289 net.cpp:122] Setting up BatchNorm23
I1007 22:14:13.659548  5289 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:14:13.659550  5289 net.cpp:137] Memory required for data: 594330800
I1007 22:14:13.659555  5289 layer_factory.hpp:77] Creating layer Scale23
I1007 22:14:13.659560  5289 net.cpp:84] Creating Layer Scale23
I1007 22:14:13.659564  5289 net.cpp:406] Scale23 <- Convolution23
I1007 22:14:13.659566  5289 net.cpp:367] Scale23 -> Convolution23 (in-place)
I1007 22:14:13.659596  5289 layer_factory.hpp:77] Creating layer Scale23
I1007 22:14:13.659682  5289 net.cpp:122] Setting up Scale23
I1007 22:14:13.659687  5289 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:14:13.659688  5289 net.cpp:137] Memory required for data: 595969200
I1007 22:14:13.659693  5289 layer_factory.hpp:77] Creating layer Convolution24
I1007 22:14:13.659698  5289 net.cpp:84] Creating Layer Convolution24
I1007 22:14:13.659708  5289 net.cpp:406] Convolution24 <- Eltwise10_elu21_0_split_1
I1007 22:14:13.659713  5289 net.cpp:380] Convolution24 -> Convolution24
I1007 22:14:13.661026  5289 net.cpp:122] Setting up Convolution24
I1007 22:14:13.661036  5289 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:14:13.661037  5289 net.cpp:137] Memory required for data: 597607600
I1007 22:14:13.661042  5289 layer_factory.hpp:77] Creating layer BatchNorm24
I1007 22:14:13.661047  5289 net.cpp:84] Creating Layer BatchNorm24
I1007 22:14:13.661051  5289 net.cpp:406] BatchNorm24 <- Convolution24
I1007 22:14:13.661054  5289 net.cpp:367] BatchNorm24 -> Convolution24 (in-place)
I1007 22:14:13.661202  5289 net.cpp:122] Setting up BatchNorm24
I1007 22:14:13.661207  5289 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:14:13.661209  5289 net.cpp:137] Memory required for data: 599246000
I1007 22:14:13.661214  5289 layer_factory.hpp:77] Creating layer Scale24
I1007 22:14:13.661218  5289 net.cpp:84] Creating Layer Scale24
I1007 22:14:13.661221  5289 net.cpp:406] Scale24 <- Convolution24
I1007 22:14:13.661223  5289 net.cpp:367] Scale24 -> Convolution24 (in-place)
I1007 22:14:13.661254  5289 layer_factory.hpp:77] Creating layer Scale24
I1007 22:14:13.661339  5289 net.cpp:122] Setting up Scale24
I1007 22:14:13.661342  5289 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:14:13.661345  5289 net.cpp:137] Memory required for data: 600884400
I1007 22:14:13.661348  5289 layer_factory.hpp:77] Creating layer elu22
I1007 22:14:13.661355  5289 net.cpp:84] Creating Layer elu22
I1007 22:14:13.661356  5289 net.cpp:406] elu22 <- Convolution24
I1007 22:14:13.661360  5289 net.cpp:367] elu22 -> Convolution24 (in-place)
I1007 22:14:13.661363  5289 net.cpp:122] Setting up elu22
I1007 22:14:13.661366  5289 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:14:13.661368  5289 net.cpp:137] Memory required for data: 602522800
I1007 22:14:13.661370  5289 layer_factory.hpp:77] Creating layer Convolution25
I1007 22:14:13.661376  5289 net.cpp:84] Creating Layer Convolution25
I1007 22:14:13.661379  5289 net.cpp:406] Convolution25 <- Convolution24
I1007 22:14:13.661383  5289 net.cpp:380] Convolution25 -> Convolution25
I1007 22:14:13.663094  5289 net.cpp:122] Setting up Convolution25
I1007 22:14:13.663102  5289 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:14:13.663105  5289 net.cpp:137] Memory required for data: 604161200
I1007 22:14:13.663110  5289 layer_factory.hpp:77] Creating layer BatchNorm25
I1007 22:14:13.663115  5289 net.cpp:84] Creating Layer BatchNorm25
I1007 22:14:13.663117  5289 net.cpp:406] BatchNorm25 <- Convolution25
I1007 22:14:13.663121  5289 net.cpp:367] BatchNorm25 -> Convolution25 (in-place)
I1007 22:14:13.663276  5289 net.cpp:122] Setting up BatchNorm25
I1007 22:14:13.663282  5289 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:14:13.663285  5289 net.cpp:137] Memory required for data: 605799600
I1007 22:14:13.663290  5289 layer_factory.hpp:77] Creating layer Scale25
I1007 22:14:13.663293  5289 net.cpp:84] Creating Layer Scale25
I1007 22:14:13.663295  5289 net.cpp:406] Scale25 <- Convolution25
I1007 22:14:13.663300  5289 net.cpp:367] Scale25 -> Convolution25 (in-place)
I1007 22:14:13.663331  5289 layer_factory.hpp:77] Creating layer Scale25
I1007 22:14:13.663415  5289 net.cpp:122] Setting up Scale25
I1007 22:14:13.663419  5289 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:14:13.663421  5289 net.cpp:137] Memory required for data: 607438000
I1007 22:14:13.663425  5289 layer_factory.hpp:77] Creating layer Eltwise11
I1007 22:14:13.663429  5289 net.cpp:84] Creating Layer Eltwise11
I1007 22:14:13.663432  5289 net.cpp:406] Eltwise11 <- Convolution23
I1007 22:14:13.663435  5289 net.cpp:406] Eltwise11 <- Convolution25
I1007 22:14:13.663439  5289 net.cpp:380] Eltwise11 -> Eltwise11
I1007 22:14:13.663456  5289 net.cpp:122] Setting up Eltwise11
I1007 22:14:13.663460  5289 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:14:13.663462  5289 net.cpp:137] Memory required for data: 609076400
I1007 22:14:13.663465  5289 layer_factory.hpp:77] Creating layer elu23
I1007 22:14:13.663475  5289 net.cpp:84] Creating Layer elu23
I1007 22:14:13.663477  5289 net.cpp:406] elu23 <- Eltwise11
I1007 22:14:13.663480  5289 net.cpp:367] elu23 -> Eltwise11 (in-place)
I1007 22:14:13.663485  5289 net.cpp:122] Setting up elu23
I1007 22:14:13.663488  5289 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:14:13.663491  5289 net.cpp:137] Memory required for data: 610714800
I1007 22:14:13.663492  5289 layer_factory.hpp:77] Creating layer Eltwise11_elu23_0_split
I1007 22:14:13.663496  5289 net.cpp:84] Creating Layer Eltwise11_elu23_0_split
I1007 22:14:13.663497  5289 net.cpp:406] Eltwise11_elu23_0_split <- Eltwise11
I1007 22:14:13.663501  5289 net.cpp:380] Eltwise11_elu23_0_split -> Eltwise11_elu23_0_split_0
I1007 22:14:13.663504  5289 net.cpp:380] Eltwise11_elu23_0_split -> Eltwise11_elu23_0_split_1
I1007 22:14:13.663532  5289 net.cpp:122] Setting up Eltwise11_elu23_0_split
I1007 22:14:13.663535  5289 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:14:13.663537  5289 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:14:13.663539  5289 net.cpp:137] Memory required for data: 613991600
I1007 22:14:13.663542  5289 layer_factory.hpp:77] Creating layer Convolution26
I1007 22:14:13.663547  5289 net.cpp:84] Creating Layer Convolution26
I1007 22:14:13.663549  5289 net.cpp:406] Convolution26 <- Eltwise11_elu23_0_split_0
I1007 22:14:13.663554  5289 net.cpp:380] Convolution26 -> Convolution26
I1007 22:14:13.665271  5289 net.cpp:122] Setting up Convolution26
I1007 22:14:13.665280  5289 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:14:13.665283  5289 net.cpp:137] Memory required for data: 615630000
I1007 22:14:13.665288  5289 layer_factory.hpp:77] Creating layer BatchNorm26
I1007 22:14:13.665292  5289 net.cpp:84] Creating Layer BatchNorm26
I1007 22:14:13.665295  5289 net.cpp:406] BatchNorm26 <- Convolution26
I1007 22:14:13.665299  5289 net.cpp:367] BatchNorm26 -> Convolution26 (in-place)
I1007 22:14:13.665449  5289 net.cpp:122] Setting up BatchNorm26
I1007 22:14:13.665454  5289 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:14:13.665457  5289 net.cpp:137] Memory required for data: 617268400
I1007 22:14:13.665460  5289 layer_factory.hpp:77] Creating layer Scale26
I1007 22:14:13.665464  5289 net.cpp:84] Creating Layer Scale26
I1007 22:14:13.665467  5289 net.cpp:406] Scale26 <- Convolution26
I1007 22:14:13.665472  5289 net.cpp:367] Scale26 -> Convolution26 (in-place)
I1007 22:14:13.665499  5289 layer_factory.hpp:77] Creating layer Scale26
I1007 22:14:13.665585  5289 net.cpp:122] Setting up Scale26
I1007 22:14:13.665590  5289 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:14:13.665591  5289 net.cpp:137] Memory required for data: 618906800
I1007 22:14:13.665596  5289 layer_factory.hpp:77] Creating layer elu24
I1007 22:14:13.665599  5289 net.cpp:84] Creating Layer elu24
I1007 22:14:13.665601  5289 net.cpp:406] elu24 <- Convolution26
I1007 22:14:13.665604  5289 net.cpp:367] elu24 -> Convolution26 (in-place)
I1007 22:14:13.665608  5289 net.cpp:122] Setting up elu24
I1007 22:14:13.665611  5289 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:14:13.665614  5289 net.cpp:137] Memory required for data: 620545200
I1007 22:14:13.665616  5289 layer_factory.hpp:77] Creating layer Convolution27
I1007 22:14:13.665622  5289 net.cpp:84] Creating Layer Convolution27
I1007 22:14:13.665624  5289 net.cpp:406] Convolution27 <- Convolution26
I1007 22:14:13.665628  5289 net.cpp:380] Convolution27 -> Convolution27
I1007 22:14:13.667341  5289 net.cpp:122] Setting up Convolution27
I1007 22:14:13.685763  5289 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:14:13.685771  5289 net.cpp:137] Memory required for data: 622183600
I1007 22:14:13.685776  5289 layer_factory.hpp:77] Creating layer BatchNorm27
I1007 22:14:13.685796  5289 net.cpp:84] Creating Layer BatchNorm27
I1007 22:14:13.685799  5289 net.cpp:406] BatchNorm27 <- Convolution27
I1007 22:14:13.685803  5289 net.cpp:367] BatchNorm27 -> Convolution27 (in-place)
I1007 22:14:13.685983  5289 net.cpp:122] Setting up BatchNorm27
I1007 22:14:13.685997  5289 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:14:13.686000  5289 net.cpp:137] Memory required for data: 623822000
I1007 22:14:13.686007  5289 layer_factory.hpp:77] Creating layer Scale27
I1007 22:14:13.686012  5289 net.cpp:84] Creating Layer Scale27
I1007 22:14:13.686014  5289 net.cpp:406] Scale27 <- Convolution27
I1007 22:14:13.686018  5289 net.cpp:367] Scale27 -> Convolution27 (in-place)
I1007 22:14:13.686053  5289 layer_factory.hpp:77] Creating layer Scale27
I1007 22:14:13.686149  5289 net.cpp:122] Setting up Scale27
I1007 22:14:13.686154  5289 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:14:13.686156  5289 net.cpp:137] Memory required for data: 625460400
I1007 22:14:13.686161  5289 layer_factory.hpp:77] Creating layer Eltwise12
I1007 22:14:13.686167  5289 net.cpp:84] Creating Layer Eltwise12
I1007 22:14:13.686169  5289 net.cpp:406] Eltwise12 <- Eltwise11_elu23_0_split_1
I1007 22:14:13.686172  5289 net.cpp:406] Eltwise12 <- Convolution27
I1007 22:14:13.686175  5289 net.cpp:380] Eltwise12 -> Eltwise12
I1007 22:14:13.686195  5289 net.cpp:122] Setting up Eltwise12
I1007 22:14:13.686199  5289 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:14:13.686202  5289 net.cpp:137] Memory required for data: 627098800
I1007 22:14:13.686204  5289 layer_factory.hpp:77] Creating layer elu25
I1007 22:14:13.686208  5289 net.cpp:84] Creating Layer elu25
I1007 22:14:13.686210  5289 net.cpp:406] elu25 <- Eltwise12
I1007 22:14:13.686214  5289 net.cpp:367] elu25 -> Eltwise12 (in-place)
I1007 22:14:13.686218  5289 net.cpp:122] Setting up elu25
I1007 22:14:13.686223  5289 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:14:13.686224  5289 net.cpp:137] Memory required for data: 628737200
I1007 22:14:13.686226  5289 layer_factory.hpp:77] Creating layer Eltwise12_elu25_0_split
I1007 22:14:13.686230  5289 net.cpp:84] Creating Layer Eltwise12_elu25_0_split
I1007 22:14:13.686233  5289 net.cpp:406] Eltwise12_elu25_0_split <- Eltwise12
I1007 22:14:13.686235  5289 net.cpp:380] Eltwise12_elu25_0_split -> Eltwise12_elu25_0_split_0
I1007 22:14:13.686239  5289 net.cpp:380] Eltwise12_elu25_0_split -> Eltwise12_elu25_0_split_1
I1007 22:14:13.686267  5289 net.cpp:122] Setting up Eltwise12_elu25_0_split
I1007 22:14:13.686271  5289 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:14:13.686275  5289 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:14:13.686276  5289 net.cpp:137] Memory required for data: 632014000
I1007 22:14:13.686278  5289 layer_factory.hpp:77] Creating layer Convolution28
I1007 22:14:13.686285  5289 net.cpp:84] Creating Layer Convolution28
I1007 22:14:13.686287  5289 net.cpp:406] Convolution28 <- Eltwise12_elu25_0_split_0
I1007 22:14:13.686292  5289 net.cpp:380] Convolution28 -> Convolution28
I1007 22:14:13.688647  5289 net.cpp:122] Setting up Convolution28
I1007 22:14:13.688657  5289 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:14:13.688658  5289 net.cpp:137] Memory required for data: 633652400
I1007 22:14:13.688664  5289 layer_factory.hpp:77] Creating layer BatchNorm28
I1007 22:14:13.688669  5289 net.cpp:84] Creating Layer BatchNorm28
I1007 22:14:13.688673  5289 net.cpp:406] BatchNorm28 <- Convolution28
I1007 22:14:13.688678  5289 net.cpp:367] BatchNorm28 -> Convolution28 (in-place)
I1007 22:14:13.688838  5289 net.cpp:122] Setting up BatchNorm28
I1007 22:14:13.688843  5289 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:14:13.688844  5289 net.cpp:137] Memory required for data: 635290800
I1007 22:14:13.688849  5289 layer_factory.hpp:77] Creating layer Scale28
I1007 22:14:13.688853  5289 net.cpp:84] Creating Layer Scale28
I1007 22:14:13.688856  5289 net.cpp:406] Scale28 <- Convolution28
I1007 22:14:13.688859  5289 net.cpp:367] Scale28 -> Convolution28 (in-place)
I1007 22:14:13.688896  5289 layer_factory.hpp:77] Creating layer Scale28
I1007 22:14:13.689034  5289 net.cpp:122] Setting up Scale28
I1007 22:14:13.689043  5289 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:14:13.689044  5289 net.cpp:137] Memory required for data: 636929200
I1007 22:14:13.689059  5289 layer_factory.hpp:77] Creating layer elu26
I1007 22:14:13.689080  5289 net.cpp:84] Creating Layer elu26
I1007 22:14:13.689083  5289 net.cpp:406] elu26 <- Convolution28
I1007 22:14:13.689088  5289 net.cpp:367] elu26 -> Convolution28 (in-place)
I1007 22:14:13.689092  5289 net.cpp:122] Setting up elu26
I1007 22:14:13.689096  5289 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:14:13.689098  5289 net.cpp:137] Memory required for data: 638567600
I1007 22:14:13.689100  5289 layer_factory.hpp:77] Creating layer Convolution29
I1007 22:14:13.689107  5289 net.cpp:84] Creating Layer Convolution29
I1007 22:14:13.689110  5289 net.cpp:406] Convolution29 <- Convolution28
I1007 22:14:13.689123  5289 net.cpp:380] Convolution29 -> Convolution29
I1007 22:14:13.691475  5289 net.cpp:122] Setting up Convolution29
I1007 22:14:13.691484  5289 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:14:13.691488  5289 net.cpp:137] Memory required for data: 640206000
I1007 22:14:13.691493  5289 layer_factory.hpp:77] Creating layer BatchNorm29
I1007 22:14:13.691498  5289 net.cpp:84] Creating Layer BatchNorm29
I1007 22:14:13.691501  5289 net.cpp:406] BatchNorm29 <- Convolution29
I1007 22:14:13.691505  5289 net.cpp:367] BatchNorm29 -> Convolution29 (in-place)
I1007 22:14:13.691660  5289 net.cpp:122] Setting up BatchNorm29
I1007 22:14:13.691665  5289 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:14:13.691668  5289 net.cpp:137] Memory required for data: 641844400
I1007 22:14:13.691673  5289 layer_factory.hpp:77] Creating layer Scale29
I1007 22:14:13.691676  5289 net.cpp:84] Creating Layer Scale29
I1007 22:14:13.691679  5289 net.cpp:406] Scale29 <- Convolution29
I1007 22:14:13.691682  5289 net.cpp:367] Scale29 -> Convolution29 (in-place)
I1007 22:14:13.691715  5289 layer_factory.hpp:77] Creating layer Scale29
I1007 22:14:13.691802  5289 net.cpp:122] Setting up Scale29
I1007 22:14:13.691807  5289 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:14:13.691808  5289 net.cpp:137] Memory required for data: 643482800
I1007 22:14:13.691812  5289 layer_factory.hpp:77] Creating layer Eltwise13
I1007 22:14:13.691817  5289 net.cpp:84] Creating Layer Eltwise13
I1007 22:14:13.691819  5289 net.cpp:406] Eltwise13 <- Eltwise12_elu25_0_split_1
I1007 22:14:13.691823  5289 net.cpp:406] Eltwise13 <- Convolution29
I1007 22:14:13.691826  5289 net.cpp:380] Eltwise13 -> Eltwise13
I1007 22:14:13.691844  5289 net.cpp:122] Setting up Eltwise13
I1007 22:14:13.691848  5289 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:14:13.691849  5289 net.cpp:137] Memory required for data: 645121200
I1007 22:14:13.691853  5289 layer_factory.hpp:77] Creating layer elu27
I1007 22:14:13.691856  5289 net.cpp:84] Creating Layer elu27
I1007 22:14:13.691859  5289 net.cpp:406] elu27 <- Eltwise13
I1007 22:14:13.691861  5289 net.cpp:367] elu27 -> Eltwise13 (in-place)
I1007 22:14:13.691865  5289 net.cpp:122] Setting up elu27
I1007 22:14:13.691869  5289 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:14:13.691870  5289 net.cpp:137] Memory required for data: 646759600
I1007 22:14:13.691872  5289 layer_factory.hpp:77] Creating layer Eltwise13_elu27_0_split
I1007 22:14:13.691876  5289 net.cpp:84] Creating Layer Eltwise13_elu27_0_split
I1007 22:14:13.691879  5289 net.cpp:406] Eltwise13_elu27_0_split <- Eltwise13
I1007 22:14:13.691881  5289 net.cpp:380] Eltwise13_elu27_0_split -> Eltwise13_elu27_0_split_0
I1007 22:14:13.691884  5289 net.cpp:380] Eltwise13_elu27_0_split -> Eltwise13_elu27_0_split_1
I1007 22:14:13.691910  5289 net.cpp:122] Setting up Eltwise13_elu27_0_split
I1007 22:14:13.691915  5289 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:14:13.691917  5289 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:14:13.691920  5289 net.cpp:137] Memory required for data: 650036400
I1007 22:14:13.691921  5289 layer_factory.hpp:77] Creating layer Convolution30
I1007 22:14:13.691928  5289 net.cpp:84] Creating Layer Convolution30
I1007 22:14:13.691931  5289 net.cpp:406] Convolution30 <- Eltwise13_elu27_0_split_0
I1007 22:14:13.691934  5289 net.cpp:380] Convolution30 -> Convolution30
I1007 22:14:13.693974  5289 net.cpp:122] Setting up Convolution30
I1007 22:14:13.693984  5289 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:14:13.693985  5289 net.cpp:137] Memory required for data: 651674800
I1007 22:14:13.693990  5289 layer_factory.hpp:77] Creating layer BatchNorm30
I1007 22:14:13.693996  5289 net.cpp:84] Creating Layer BatchNorm30
I1007 22:14:13.693998  5289 net.cpp:406] BatchNorm30 <- Convolution30
I1007 22:14:13.694002  5289 net.cpp:367] BatchNorm30 -> Convolution30 (in-place)
I1007 22:14:13.694160  5289 net.cpp:122] Setting up BatchNorm30
I1007 22:14:13.694165  5289 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:14:13.694167  5289 net.cpp:137] Memory required for data: 653313200
I1007 22:14:13.694172  5289 layer_factory.hpp:77] Creating layer Scale30
I1007 22:14:13.694176  5289 net.cpp:84] Creating Layer Scale30
I1007 22:14:13.694178  5289 net.cpp:406] Scale30 <- Convolution30
I1007 22:14:13.694181  5289 net.cpp:367] Scale30 -> Convolution30 (in-place)
I1007 22:14:13.694213  5289 layer_factory.hpp:77] Creating layer Scale30
I1007 22:14:13.694300  5289 net.cpp:122] Setting up Scale30
I1007 22:14:13.694304  5289 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:14:13.694306  5289 net.cpp:137] Memory required for data: 654951600
I1007 22:14:13.694310  5289 layer_factory.hpp:77] Creating layer elu28
I1007 22:14:13.694314  5289 net.cpp:84] Creating Layer elu28
I1007 22:14:13.694317  5289 net.cpp:406] elu28 <- Convolution30
I1007 22:14:13.694320  5289 net.cpp:367] elu28 -> Convolution30 (in-place)
I1007 22:14:13.694324  5289 net.cpp:122] Setting up elu28
I1007 22:14:13.694326  5289 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:14:13.694329  5289 net.cpp:137] Memory required for data: 656590000
I1007 22:14:13.694331  5289 layer_factory.hpp:77] Creating layer Convolution31
I1007 22:14:13.694337  5289 net.cpp:84] Creating Layer Convolution31
I1007 22:14:13.694340  5289 net.cpp:406] Convolution31 <- Convolution30
I1007 22:14:13.694344  5289 net.cpp:380] Convolution31 -> Convolution31
I1007 22:14:13.696075  5289 net.cpp:122] Setting up Convolution31
I1007 22:14:13.696092  5289 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:14:13.696095  5289 net.cpp:137] Memory required for data: 658228400
I1007 22:14:13.696100  5289 layer_factory.hpp:77] Creating layer BatchNorm31
I1007 22:14:13.696105  5289 net.cpp:84] Creating Layer BatchNorm31
I1007 22:14:13.696108  5289 net.cpp:406] BatchNorm31 <- Convolution31
I1007 22:14:13.696112  5289 net.cpp:367] BatchNorm31 -> Convolution31 (in-place)
I1007 22:14:13.696272  5289 net.cpp:122] Setting up BatchNorm31
I1007 22:14:13.696277  5289 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:14:13.696280  5289 net.cpp:137] Memory required for data: 659866800
I1007 22:14:13.696285  5289 layer_factory.hpp:77] Creating layer Scale31
I1007 22:14:13.696288  5289 net.cpp:84] Creating Layer Scale31
I1007 22:14:13.696291  5289 net.cpp:406] Scale31 <- Convolution31
I1007 22:14:13.696295  5289 net.cpp:367] Scale31 -> Convolution31 (in-place)
I1007 22:14:13.696326  5289 layer_factory.hpp:77] Creating layer Scale31
I1007 22:14:13.696418  5289 net.cpp:122] Setting up Scale31
I1007 22:14:13.696421  5289 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:14:13.696424  5289 net.cpp:137] Memory required for data: 661505200
I1007 22:14:13.696427  5289 layer_factory.hpp:77] Creating layer Eltwise14
I1007 22:14:13.696432  5289 net.cpp:84] Creating Layer Eltwise14
I1007 22:14:13.696435  5289 net.cpp:406] Eltwise14 <- Eltwise13_elu27_0_split_1
I1007 22:14:13.696439  5289 net.cpp:406] Eltwise14 <- Convolution31
I1007 22:14:13.696441  5289 net.cpp:380] Eltwise14 -> Eltwise14
I1007 22:14:13.696460  5289 net.cpp:122] Setting up Eltwise14
I1007 22:14:13.696465  5289 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:14:13.696466  5289 net.cpp:137] Memory required for data: 663143600
I1007 22:14:13.696470  5289 layer_factory.hpp:77] Creating layer elu29
I1007 22:14:13.696472  5289 net.cpp:84] Creating Layer elu29
I1007 22:14:13.696475  5289 net.cpp:406] elu29 <- Eltwise14
I1007 22:14:13.696485  5289 net.cpp:367] elu29 -> Eltwise14 (in-place)
I1007 22:14:13.696491  5289 net.cpp:122] Setting up elu29
I1007 22:14:13.696493  5289 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:14:13.696496  5289 net.cpp:137] Memory required for data: 664782000
I1007 22:14:13.696498  5289 layer_factory.hpp:77] Creating layer Eltwise14_elu29_0_split
I1007 22:14:13.696501  5289 net.cpp:84] Creating Layer Eltwise14_elu29_0_split
I1007 22:14:13.696503  5289 net.cpp:406] Eltwise14_elu29_0_split <- Eltwise14
I1007 22:14:13.696506  5289 net.cpp:380] Eltwise14_elu29_0_split -> Eltwise14_elu29_0_split_0
I1007 22:14:13.696511  5289 net.cpp:380] Eltwise14_elu29_0_split -> Eltwise14_elu29_0_split_1
I1007 22:14:13.696538  5289 net.cpp:122] Setting up Eltwise14_elu29_0_split
I1007 22:14:13.696542  5289 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:14:13.696545  5289 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:14:13.696547  5289 net.cpp:137] Memory required for data: 668058800
I1007 22:14:13.696549  5289 layer_factory.hpp:77] Creating layer Convolution32
I1007 22:14:13.696555  5289 net.cpp:84] Creating Layer Convolution32
I1007 22:14:13.696557  5289 net.cpp:406] Convolution32 <- Eltwise14_elu29_0_split_0
I1007 22:14:13.696563  5289 net.cpp:380] Convolution32 -> Convolution32
I1007 22:14:13.698611  5289 net.cpp:122] Setting up Convolution32
I1007 22:14:13.698619  5289 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:14:13.698621  5289 net.cpp:137] Memory required for data: 669697200
I1007 22:14:13.698626  5289 layer_factory.hpp:77] Creating layer BatchNorm32
I1007 22:14:13.698632  5289 net.cpp:84] Creating Layer BatchNorm32
I1007 22:14:13.698635  5289 net.cpp:406] BatchNorm32 <- Convolution32
I1007 22:14:13.698639  5289 net.cpp:367] BatchNorm32 -> Convolution32 (in-place)
I1007 22:14:13.698798  5289 net.cpp:122] Setting up BatchNorm32
I1007 22:14:13.698802  5289 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:14:13.698804  5289 net.cpp:137] Memory required for data: 671335600
I1007 22:14:13.698809  5289 layer_factory.hpp:77] Creating layer Scale32
I1007 22:14:13.698814  5289 net.cpp:84] Creating Layer Scale32
I1007 22:14:13.698817  5289 net.cpp:406] Scale32 <- Convolution32
I1007 22:14:13.698819  5289 net.cpp:367] Scale32 -> Convolution32 (in-place)
I1007 22:14:13.698850  5289 layer_factory.hpp:77] Creating layer Scale32
I1007 22:14:13.698938  5289 net.cpp:122] Setting up Scale32
I1007 22:14:13.698942  5289 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:14:13.698945  5289 net.cpp:137] Memory required for data: 672974000
I1007 22:14:13.698948  5289 layer_factory.hpp:77] Creating layer elu30
I1007 22:14:13.698952  5289 net.cpp:84] Creating Layer elu30
I1007 22:14:13.698956  5289 net.cpp:406] elu30 <- Convolution32
I1007 22:14:13.698958  5289 net.cpp:367] elu30 -> Convolution32 (in-place)
I1007 22:14:13.698961  5289 net.cpp:122] Setting up elu30
I1007 22:14:13.698964  5289 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:14:13.698966  5289 net.cpp:137] Memory required for data: 674612400
I1007 22:14:13.698969  5289 layer_factory.hpp:77] Creating layer Convolution33
I1007 22:14:13.698976  5289 net.cpp:84] Creating Layer Convolution33
I1007 22:14:13.698977  5289 net.cpp:406] Convolution33 <- Convolution32
I1007 22:14:13.698982  5289 net.cpp:380] Convolution33 -> Convolution33
I1007 22:14:13.700742  5289 net.cpp:122] Setting up Convolution33
I1007 22:14:13.700752  5289 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:14:13.715870  5289 net.cpp:137] Memory required for data: 676250800
I1007 22:14:13.715881  5289 layer_factory.hpp:77] Creating layer BatchNorm33
I1007 22:14:13.715889  5289 net.cpp:84] Creating Layer BatchNorm33
I1007 22:14:13.715893  5289 net.cpp:406] BatchNorm33 <- Convolution33
I1007 22:14:13.715896  5289 net.cpp:367] BatchNorm33 -> Convolution33 (in-place)
I1007 22:14:13.716080  5289 net.cpp:122] Setting up BatchNorm33
I1007 22:14:13.716086  5289 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:14:13.716089  5289 net.cpp:137] Memory required for data: 677889200
I1007 22:14:13.716101  5289 layer_factory.hpp:77] Creating layer Scale33
I1007 22:14:13.716107  5289 net.cpp:84] Creating Layer Scale33
I1007 22:14:13.716109  5289 net.cpp:406] Scale33 <- Convolution33
I1007 22:14:13.716114  5289 net.cpp:367] Scale33 -> Convolution33 (in-place)
I1007 22:14:13.716151  5289 layer_factory.hpp:77] Creating layer Scale33
I1007 22:14:13.716248  5289 net.cpp:122] Setting up Scale33
I1007 22:14:13.716253  5289 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:14:13.716255  5289 net.cpp:137] Memory required for data: 679527600
I1007 22:14:13.716259  5289 layer_factory.hpp:77] Creating layer Eltwise15
I1007 22:14:13.716264  5289 net.cpp:84] Creating Layer Eltwise15
I1007 22:14:13.716267  5289 net.cpp:406] Eltwise15 <- Eltwise14_elu29_0_split_1
I1007 22:14:13.716270  5289 net.cpp:406] Eltwise15 <- Convolution33
I1007 22:14:13.716274  5289 net.cpp:380] Eltwise15 -> Eltwise15
I1007 22:14:13.716295  5289 net.cpp:122] Setting up Eltwise15
I1007 22:14:13.716298  5289 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:14:13.716300  5289 net.cpp:137] Memory required for data: 681166000
I1007 22:14:13.716303  5289 layer_factory.hpp:77] Creating layer elu31
I1007 22:14:13.716306  5289 net.cpp:84] Creating Layer elu31
I1007 22:14:13.716310  5289 net.cpp:406] elu31 <- Eltwise15
I1007 22:14:13.716313  5289 net.cpp:367] elu31 -> Eltwise15 (in-place)
I1007 22:14:13.716317  5289 net.cpp:122] Setting up elu31
I1007 22:14:13.716320  5289 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:14:13.716322  5289 net.cpp:137] Memory required for data: 682804400
I1007 22:14:13.716325  5289 layer_factory.hpp:77] Creating layer Pooling1
I1007 22:14:13.716329  5289 net.cpp:84] Creating Layer Pooling1
I1007 22:14:13.716331  5289 net.cpp:406] Pooling1 <- Eltwise15
I1007 22:14:13.716336  5289 net.cpp:380] Pooling1 -> Pooling1
I1007 22:14:13.716491  5289 net.cpp:122] Setting up Pooling1
I1007 22:14:13.716498  5289 net.cpp:129] Top shape: 100 64 1 1 (6400)
I1007 22:14:13.716500  5289 net.cpp:137] Memory required for data: 682830000
I1007 22:14:13.716503  5289 layer_factory.hpp:77] Creating layer InnerProduct1
I1007 22:14:13.716509  5289 net.cpp:84] Creating Layer InnerProduct1
I1007 22:14:13.716512  5289 net.cpp:406] InnerProduct1 <- Pooling1
I1007 22:14:13.716516  5289 net.cpp:380] InnerProduct1 -> InnerProduct1
I1007 22:14:13.716632  5289 net.cpp:122] Setting up InnerProduct1
I1007 22:14:13.716637  5289 net.cpp:129] Top shape: 100 10 (1000)
I1007 22:14:13.716639  5289 net.cpp:137] Memory required for data: 682834000
I1007 22:14:13.716644  5289 layer_factory.hpp:77] Creating layer InnerProduct1_InnerProduct1_0_split
I1007 22:14:13.716647  5289 net.cpp:84] Creating Layer InnerProduct1_InnerProduct1_0_split
I1007 22:14:13.716650  5289 net.cpp:406] InnerProduct1_InnerProduct1_0_split <- InnerProduct1
I1007 22:14:13.716653  5289 net.cpp:380] InnerProduct1_InnerProduct1_0_split -> InnerProduct1_InnerProduct1_0_split_0
I1007 22:14:13.716660  5289 net.cpp:380] InnerProduct1_InnerProduct1_0_split -> InnerProduct1_InnerProduct1_0_split_1
I1007 22:14:13.716691  5289 net.cpp:122] Setting up InnerProduct1_InnerProduct1_0_split
I1007 22:14:13.716694  5289 net.cpp:129] Top shape: 100 10 (1000)
I1007 22:14:13.716697  5289 net.cpp:129] Top shape: 100 10 (1000)
I1007 22:14:13.716699  5289 net.cpp:137] Memory required for data: 682842000
I1007 22:14:13.716701  5289 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I1007 22:14:13.716706  5289 net.cpp:84] Creating Layer SoftmaxWithLoss1
I1007 22:14:13.716709  5289 net.cpp:406] SoftmaxWithLoss1 <- InnerProduct1_InnerProduct1_0_split_0
I1007 22:14:13.716712  5289 net.cpp:406] SoftmaxWithLoss1 <- Data2_Data1_1_split_0
I1007 22:14:13.716717  5289 net.cpp:380] SoftmaxWithLoss1 -> SoftmaxWithLoss1
I1007 22:14:13.716722  5289 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I1007 22:14:13.717288  5289 net.cpp:122] Setting up SoftmaxWithLoss1
I1007 22:14:13.717295  5289 net.cpp:129] Top shape: (1)
I1007 22:14:13.717298  5289 net.cpp:132]     with loss weight 1
I1007 22:14:13.717314  5289 net.cpp:137] Memory required for data: 682842004
I1007 22:14:13.717324  5289 layer_factory.hpp:77] Creating layer Accuracy1
I1007 22:14:13.717329  5289 net.cpp:84] Creating Layer Accuracy1
I1007 22:14:13.717332  5289 net.cpp:406] Accuracy1 <- InnerProduct1_InnerProduct1_0_split_1
I1007 22:14:13.717346  5289 net.cpp:406] Accuracy1 <- Data2_Data1_1_split_1
I1007 22:14:13.717350  5289 net.cpp:380] Accuracy1 -> Accuracy1
I1007 22:14:13.717356  5289 net.cpp:122] Setting up Accuracy1
I1007 22:14:13.717360  5289 net.cpp:129] Top shape: (1)
I1007 22:14:13.717361  5289 net.cpp:137] Memory required for data: 682842008
I1007 22:14:13.717363  5289 net.cpp:200] Accuracy1 does not need backward computation.
I1007 22:14:13.717366  5289 net.cpp:198] SoftmaxWithLoss1 needs backward computation.
I1007 22:14:13.717368  5289 net.cpp:198] InnerProduct1_InnerProduct1_0_split needs backward computation.
I1007 22:14:13.717371  5289 net.cpp:198] InnerProduct1 needs backward computation.
I1007 22:14:13.717373  5289 net.cpp:198] Pooling1 needs backward computation.
I1007 22:14:13.717375  5289 net.cpp:198] elu31 needs backward computation.
I1007 22:14:13.717378  5289 net.cpp:198] Eltwise15 needs backward computation.
I1007 22:14:13.717381  5289 net.cpp:198] Scale33 needs backward computation.
I1007 22:14:13.717382  5289 net.cpp:198] BatchNorm33 needs backward computation.
I1007 22:14:13.717384  5289 net.cpp:198] Convolution33 needs backward computation.
I1007 22:14:13.717386  5289 net.cpp:198] elu30 needs backward computation.
I1007 22:14:13.717388  5289 net.cpp:198] Scale32 needs backward computation.
I1007 22:14:13.717391  5289 net.cpp:198] BatchNorm32 needs backward computation.
I1007 22:14:13.717392  5289 net.cpp:198] Convolution32 needs backward computation.
I1007 22:14:13.717396  5289 net.cpp:198] Eltwise14_elu29_0_split needs backward computation.
I1007 22:14:13.717397  5289 net.cpp:198] elu29 needs backward computation.
I1007 22:14:13.717399  5289 net.cpp:198] Eltwise14 needs backward computation.
I1007 22:14:13.717402  5289 net.cpp:198] Scale31 needs backward computation.
I1007 22:14:13.717404  5289 net.cpp:198] BatchNorm31 needs backward computation.
I1007 22:14:13.717406  5289 net.cpp:198] Convolution31 needs backward computation.
I1007 22:14:13.717408  5289 net.cpp:198] elu28 needs backward computation.
I1007 22:14:13.717411  5289 net.cpp:198] Scale30 needs backward computation.
I1007 22:14:13.717412  5289 net.cpp:198] BatchNorm30 needs backward computation.
I1007 22:14:13.717414  5289 net.cpp:198] Convolution30 needs backward computation.
I1007 22:14:13.717417  5289 net.cpp:198] Eltwise13_elu27_0_split needs backward computation.
I1007 22:14:13.717418  5289 net.cpp:198] elu27 needs backward computation.
I1007 22:14:13.717420  5289 net.cpp:198] Eltwise13 needs backward computation.
I1007 22:14:13.717423  5289 net.cpp:198] Scale29 needs backward computation.
I1007 22:14:13.717425  5289 net.cpp:198] BatchNorm29 needs backward computation.
I1007 22:14:13.717437  5289 net.cpp:198] Convolution29 needs backward computation.
I1007 22:14:13.717438  5289 net.cpp:198] elu26 needs backward computation.
I1007 22:14:13.717442  5289 net.cpp:198] Scale28 needs backward computation.
I1007 22:14:13.717443  5289 net.cpp:198] BatchNorm28 needs backward computation.
I1007 22:14:13.717455  5289 net.cpp:198] Convolution28 needs backward computation.
I1007 22:14:13.717458  5289 net.cpp:198] Eltwise12_elu25_0_split needs backward computation.
I1007 22:14:13.746541  5289 net.cpp:198] elu25 needs backward computation.
I1007 22:14:13.746549  5289 net.cpp:198] Eltwise12 needs backward computation.
I1007 22:14:13.746553  5289 net.cpp:198] Scale27 needs backward computation.
I1007 22:14:13.746556  5289 net.cpp:198] BatchNorm27 needs backward computation.
I1007 22:14:13.746558  5289 net.cpp:198] Convolution27 needs backward computation.
I1007 22:14:13.746563  5289 net.cpp:198] elu24 needs backward computation.
I1007 22:14:13.746567  5289 net.cpp:198] Scale26 needs backward computation.
I1007 22:14:13.746572  5289 net.cpp:198] BatchNorm26 needs backward computation.
I1007 22:14:13.746575  5289 net.cpp:198] Convolution26 needs backward computation.
I1007 22:14:13.746590  5289 net.cpp:198] Eltwise11_elu23_0_split needs backward computation.
I1007 22:14:13.746595  5289 net.cpp:198] elu23 needs backward computation.
I1007 22:14:13.746598  5289 net.cpp:198] Eltwise11 needs backward computation.
I1007 22:14:13.746601  5289 net.cpp:198] Scale25 needs backward computation.
I1007 22:14:13.746604  5289 net.cpp:198] BatchNorm25 needs backward computation.
I1007 22:14:13.746606  5289 net.cpp:198] Convolution25 needs backward computation.
I1007 22:14:13.746609  5289 net.cpp:198] elu22 needs backward computation.
I1007 22:14:13.746611  5289 net.cpp:198] Scale24 needs backward computation.
I1007 22:14:13.746613  5289 net.cpp:198] BatchNorm24 needs backward computation.
I1007 22:14:13.746616  5289 net.cpp:198] Convolution24 needs backward computation.
I1007 22:14:13.746619  5289 net.cpp:198] Scale23 needs backward computation.
I1007 22:14:13.746621  5289 net.cpp:198] BatchNorm23 needs backward computation.
I1007 22:14:13.746624  5289 net.cpp:198] Convolution23 needs backward computation.
I1007 22:14:13.746628  5289 net.cpp:198] Eltwise10_elu21_0_split needs backward computation.
I1007 22:14:13.746630  5289 net.cpp:198] elu21 needs backward computation.
I1007 22:14:13.746634  5289 net.cpp:198] Eltwise10 needs backward computation.
I1007 22:14:13.746636  5289 net.cpp:198] Scale22 needs backward computation.
I1007 22:14:13.746639  5289 net.cpp:198] BatchNorm22 needs backward computation.
I1007 22:14:13.746641  5289 net.cpp:198] Convolution22 needs backward computation.
I1007 22:14:13.746645  5289 net.cpp:198] elu20 needs backward computation.
I1007 22:14:13.746647  5289 net.cpp:198] Scale21 needs backward computation.
I1007 22:14:13.746649  5289 net.cpp:198] BatchNorm21 needs backward computation.
I1007 22:14:13.746652  5289 net.cpp:198] Convolution21 needs backward computation.
I1007 22:14:13.746654  5289 net.cpp:198] Eltwise9_elu19_0_split needs backward computation.
I1007 22:14:13.746657  5289 net.cpp:198] elu19 needs backward computation.
I1007 22:14:13.746660  5289 net.cpp:198] Eltwise9 needs backward computation.
I1007 22:14:13.746662  5289 net.cpp:198] Scale20 needs backward computation.
I1007 22:14:13.746665  5289 net.cpp:198] BatchNorm20 needs backward computation.
I1007 22:14:13.746667  5289 net.cpp:198] Convolution20 needs backward computation.
I1007 22:14:13.746670  5289 net.cpp:198] elu18 needs backward computation.
I1007 22:14:13.746672  5289 net.cpp:198] Scale19 needs backward computation.
I1007 22:14:13.746675  5289 net.cpp:198] BatchNorm19 needs backward computation.
I1007 22:14:13.746677  5289 net.cpp:198] Convolution19 needs backward computation.
I1007 22:14:13.746680  5289 net.cpp:198] Eltwise8_elu17_0_split needs backward computation.
I1007 22:14:13.746682  5289 net.cpp:198] elu17 needs backward computation.
I1007 22:14:13.746685  5289 net.cpp:198] Eltwise8 needs backward computation.
I1007 22:14:13.746688  5289 net.cpp:198] Scale18 needs backward computation.
I1007 22:14:13.746690  5289 net.cpp:198] BatchNorm18 needs backward computation.
I1007 22:14:13.746692  5289 net.cpp:198] Convolution18 needs backward computation.
I1007 22:14:13.746695  5289 net.cpp:198] elu16 needs backward computation.
I1007 22:14:13.746697  5289 net.cpp:198] Scale17 needs backward computation.
I1007 22:14:13.746701  5289 net.cpp:198] BatchNorm17 needs backward computation.
I1007 22:14:13.746702  5289 net.cpp:198] Convolution17 needs backward computation.
I1007 22:14:13.746706  5289 net.cpp:198] Eltwise7_elu15_0_split needs backward computation.
I1007 22:14:13.746707  5289 net.cpp:198] elu15 needs backward computation.
I1007 22:14:13.746711  5289 net.cpp:198] Eltwise7 needs backward computation.
I1007 22:14:13.746712  5289 net.cpp:198] Scale16 needs backward computation.
I1007 22:14:13.746716  5289 net.cpp:198] BatchNorm16 needs backward computation.
I1007 22:14:13.746717  5289 net.cpp:198] Convolution16 needs backward computation.
I1007 22:14:13.746721  5289 net.cpp:198] elu14 needs backward computation.
I1007 22:14:13.746722  5289 net.cpp:198] Scale15 needs backward computation.
I1007 22:14:13.746729  5289 net.cpp:198] BatchNorm15 needs backward computation.
I1007 22:14:13.746731  5289 net.cpp:198] Convolution15 needs backward computation.
I1007 22:14:13.746734  5289 net.cpp:198] Eltwise6_elu13_0_split needs backward computation.
I1007 22:14:13.746737  5289 net.cpp:198] elu13 needs backward computation.
I1007 22:14:13.746739  5289 net.cpp:198] Eltwise6 needs backward computation.
I1007 22:14:13.746742  5289 net.cpp:198] Scale14 needs backward computation.
I1007 22:14:13.746744  5289 net.cpp:198] BatchNorm14 needs backward computation.
I1007 22:14:13.746747  5289 net.cpp:198] Convolution14 needs backward computation.
I1007 22:14:13.746749  5289 net.cpp:198] elu12 needs backward computation.
I1007 22:14:13.746752  5289 net.cpp:198] Scale13 needs backward computation.
I1007 22:14:13.746754  5289 net.cpp:198] BatchNorm13 needs backward computation.
I1007 22:14:13.746757  5289 net.cpp:198] Convolution13 needs backward computation.
I1007 22:14:13.746759  5289 net.cpp:198] Scale12 needs backward computation.
I1007 22:14:13.746762  5289 net.cpp:198] BatchNorm12 needs backward computation.
I1007 22:14:13.746764  5289 net.cpp:198] Convolution12 needs backward computation.
I1007 22:14:13.746767  5289 net.cpp:198] Eltwise5_elu11_0_split needs backward computation.
I1007 22:14:13.746769  5289 net.cpp:198] elu11 needs backward computation.
I1007 22:14:13.746772  5289 net.cpp:198] Eltwise5 needs backward computation.
I1007 22:14:13.746774  5289 net.cpp:198] Scale11 needs backward computation.
I1007 22:14:13.746778  5289 net.cpp:198] BatchNorm11 needs backward computation.
I1007 22:14:13.746779  5289 net.cpp:198] Convolution11 needs backward computation.
I1007 22:14:13.746783  5289 net.cpp:198] elu10 needs backward computation.
I1007 22:14:13.746784  5289 net.cpp:198] Scale10 needs backward computation.
I1007 22:14:13.746786  5289 net.cpp:198] BatchNorm10 needs backward computation.
I1007 22:14:13.746788  5289 net.cpp:198] Convolution10 needs backward computation.
I1007 22:14:13.746791  5289 net.cpp:198] Eltwise4_elu9_0_split needs backward computation.
I1007 22:14:13.746794  5289 net.cpp:198] elu9 needs backward computation.
I1007 22:14:13.746796  5289 net.cpp:198] Eltwise4 needs backward computation.
I1007 22:14:13.746799  5289 net.cpp:198] Scale9 needs backward computation.
I1007 22:14:13.746803  5289 net.cpp:198] BatchNorm9 needs backward computation.
I1007 22:14:13.746804  5289 net.cpp:198] Convolution9 needs backward computation.
I1007 22:14:13.746807  5289 net.cpp:198] elu8 needs backward computation.
I1007 22:14:13.746809  5289 net.cpp:198] Scale8 needs backward computation.
I1007 22:14:13.746811  5289 net.cpp:198] BatchNorm8 needs backward computation.
I1007 22:14:13.746814  5289 net.cpp:198] Convolution8 needs backward computation.
I1007 22:14:13.746816  5289 net.cpp:198] Eltwise3_elu7_0_split needs backward computation.
I1007 22:14:13.746819  5289 net.cpp:198] elu7 needs backward computation.
I1007 22:14:13.746822  5289 net.cpp:198] Eltwise3 needs backward computation.
I1007 22:14:13.746824  5289 net.cpp:198] Scale7 needs backward computation.
I1007 22:14:13.746829  5289 net.cpp:198] BatchNorm7 needs backward computation.
I1007 22:14:13.746830  5289 net.cpp:198] Convolution7 needs backward computation.
I1007 22:14:13.746834  5289 net.cpp:198] elu6 needs backward computation.
I1007 22:14:13.746835  5289 net.cpp:198] Scale6 needs backward computation.
I1007 22:14:13.746837  5289 net.cpp:198] BatchNorm6 needs backward computation.
I1007 22:14:13.746840  5289 net.cpp:198] Convolution6 needs backward computation.
I1007 22:14:13.746842  5289 net.cpp:198] Eltwise2_elu5_0_split needs backward computation.
I1007 22:14:13.746845  5289 net.cpp:198] elu5 needs backward computation.
I1007 22:14:13.746847  5289 net.cpp:198] Eltwise2 needs backward computation.
I1007 22:14:13.746850  5289 net.cpp:198] Scale5 needs backward computation.
I1007 22:14:13.746853  5289 net.cpp:198] BatchNorm5 needs backward computation.
I1007 22:14:13.746855  5289 net.cpp:198] Convolution5 needs backward computation.
I1007 22:14:13.746861  5289 net.cpp:198] elu4 needs backward computation.
I1007 22:14:13.746865  5289 net.cpp:198] Scale4 needs backward computation.
I1007 22:14:13.746866  5289 net.cpp:198] BatchNorm4 needs backward computation.
I1007 22:14:13.746870  5289 net.cpp:198] Convolution4 needs backward computation.
I1007 22:14:13.746871  5289 net.cpp:198] Eltwise1_elu3_0_split needs backward computation.
I1007 22:14:13.746875  5289 net.cpp:198] elu3 needs backward computation.
I1007 22:14:13.746876  5289 net.cpp:198] Eltwise1 needs backward computation.
I1007 22:14:13.746879  5289 net.cpp:198] Scale3 needs backward computation.
I1007 22:14:13.746882  5289 net.cpp:198] BatchNorm3 needs backward computation.
I1007 22:14:13.746884  5289 net.cpp:198] Convolution3 needs backward computation.
I1007 22:14:13.746886  5289 net.cpp:198] elu2 needs backward computation.
I1007 22:14:13.746889  5289 net.cpp:198] Scale2 needs backward computation.
I1007 22:14:13.746891  5289 net.cpp:198] BatchNorm2 needs backward computation.
I1007 22:14:13.746893  5289 net.cpp:198] Convolution2 needs backward computation.
I1007 22:14:13.746896  5289 net.cpp:198] Convolution1_elu1_0_split needs backward computation.
I1007 22:14:13.746899  5289 net.cpp:198] elu1 needs backward computation.
I1007 22:14:13.746901  5289 net.cpp:198] Scale1 needs backward computation.
I1007 22:14:13.746904  5289 net.cpp:198] BatchNorm1 needs backward computation.
I1007 22:14:13.746906  5289 net.cpp:198] Convolution1 needs backward computation.
I1007 22:14:13.746909  5289 net.cpp:200] Data2_Data1_1_split does not need backward computation.
I1007 22:14:13.746913  5289 net.cpp:200] Data1 does not need backward computation.
I1007 22:14:13.746915  5289 net.cpp:242] This network produces output Accuracy1
I1007 22:14:13.746918  5289 net.cpp:242] This network produces output SoftmaxWithLoss1
I1007 22:14:13.746978  5289 net.cpp:255] Network initialization done.
I1007 22:14:13.747362  5289 solver.cpp:56] Solver scaffolding done.
I1007 22:14:13.754006  5289 caffe.cpp:248] Starting Optimization
I1007 22:14:13.754014  5289 solver.cpp:272] Solving resnet_cifar10
I1007 22:14:13.754017  5289 solver.cpp:273] Learning Rate Policy: multistep
I1007 22:14:13.756706  5289 solver.cpp:330] Iteration 0, Testing net (#0)
I1007 22:14:15.545717  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1007 22:14:15.619184  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.1
I1007 22:14:15.619210  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 87.3365 (* 1 = 87.3365 loss)
I1007 22:14:15.722010  5289 solver.cpp:218] Iteration 0 (0.115681 iter/s, 1.96791s/100 iters), loss = 2.30855
I1007 22:14:15.722043  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 2.30855 (* 1 = 2.30855 loss)
I1007 22:14:15.722057  5289 sgd_solver.cpp:105] Iteration 0, lr = 0.1
I1007 22:14:23.487422  5289 solver.cpp:218] Iteration 100 (12.8778 iter/s, 7.7653s/100 iters), loss = 1.55822
I1007 22:14:23.487460  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.55822 (* 1 = 1.55822 loss)
I1007 22:14:23.487467  5289 sgd_solver.cpp:105] Iteration 100, lr = 0.1
I1007 22:14:33.119639  5289 solver.cpp:218] Iteration 200 (10.382 iter/s, 9.63205s/100 iters), loss = 1.54198
I1007 22:14:33.119678  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.54198 (* 1 = 1.54198 loss)
I1007 22:14:33.119684  5289 sgd_solver.cpp:105] Iteration 200, lr = 0.1
I1007 22:14:49.143013  5289 solver.cpp:218] Iteration 300 (6.24097 iter/s, 16.0232s/100 iters), loss = 1.32483
I1007 22:14:49.143102  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.32483 (* 1 = 1.32483 loss)
I1007 22:14:49.143110  5289 sgd_solver.cpp:105] Iteration 300, lr = 0.1
I1007 22:15:05.642346  5289 solver.cpp:218] Iteration 400 (6.06171 iter/s, 16.497s/100 iters), loss = 1.03767
I1007 22:15:05.642377  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.03767 (* 1 = 1.03767 loss)
I1007 22:15:05.642385  5289 sgd_solver.cpp:105] Iteration 400, lr = 0.1
I1007 22:15:21.360800  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1007 22:15:22.017037  5289 solver.cpp:330] Iteration 500, Testing net (#0)
I1007 22:15:25.211745  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1007 22:15:25.348680  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.2956
I1007 22:15:25.348706  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 3.62485 (* 1 = 3.62485 loss)
I1007 22:15:25.483435  5289 solver.cpp:218] Iteration 500 (5.04064 iter/s, 19.8387s/100 iters), loss = 1.17937
I1007 22:15:25.483466  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.17937 (* 1 = 1.17937 loss)
I1007 22:15:25.483484  5289 sgd_solver.cpp:105] Iteration 500, lr = 0.1
I1007 22:15:42.005260  5289 solver.cpp:218] Iteration 600 (6.05347 iter/s, 16.5195s/100 iters), loss = 1.06075
I1007 22:15:42.005290  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.06075 (* 1 = 1.06075 loss)
I1007 22:15:42.005296  5289 sgd_solver.cpp:105] Iteration 600, lr = 0.1
I1007 22:15:58.597316  5289 solver.cpp:218] Iteration 700 (6.02783 iter/s, 16.5897s/100 iters), loss = 1.10542
I1007 22:15:58.597425  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.10542 (* 1 = 1.10542 loss)
I1007 22:15:58.597445  5289 sgd_solver.cpp:105] Iteration 700, lr = 0.1
I1007 22:16:15.340473  5289 solver.cpp:218] Iteration 800 (5.97296 iter/s, 16.7421s/100 iters), loss = 0.978111
I1007 22:16:15.340525  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.978111 (* 1 = 0.978111 loss)
I1007 22:16:15.340534  5289 sgd_solver.cpp:105] Iteration 800, lr = 0.1
I1007 22:16:31.984877  5289 solver.cpp:218] Iteration 900 (6.00886 iter/s, 16.6421s/100 iters), loss = 0.806917
I1007 22:16:31.984998  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.806917 (* 1 = 0.806917 loss)
I1007 22:16:31.985018  5289 sgd_solver.cpp:105] Iteration 900, lr = 0.1
I1007 22:16:47.691517  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1007 22:16:48.350733  5289 solver.cpp:330] Iteration 1000, Testing net (#0)
I1007 22:16:51.608289  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1007 22:16:51.735582  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.3718
I1007 22:16:51.735618  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 2.59614 (* 1 = 2.59614 loss)
I1007 22:16:51.846334  5289 solver.cpp:218] Iteration 1000 (5.03548 iter/s, 19.8591s/100 iters), loss = 0.909735
I1007 22:16:51.846376  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.909735 (* 1 = 0.909735 loss)
I1007 22:16:51.846382  5289 sgd_solver.cpp:105] Iteration 1000, lr = 0.1
I1007 22:17:10.792184  5289 solver.cpp:218] Iteration 1100 (5.27826 iter/s, 18.9456s/100 iters), loss = 0.733317
I1007 22:17:10.792282  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.733317 (* 1 = 0.733317 loss)
I1007 22:17:10.792305  5289 sgd_solver.cpp:105] Iteration 1100, lr = 0.1
I1007 22:17:35.583009  5289 solver.cpp:218] Iteration 1200 (4.03415 iter/s, 24.7884s/100 iters), loss = 0.876116
I1007 22:17:35.583040  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.876116 (* 1 = 0.876116 loss)
I1007 22:17:35.583047  5289 sgd_solver.cpp:105] Iteration 1200, lr = 0.1
I1007 22:18:00.639981  5289 solver.cpp:218] Iteration 1300 (3.99117 iter/s, 25.0553s/100 iters), loss = 0.836156
I1007 22:18:00.640064  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.836156 (* 1 = 0.836156 loss)
I1007 22:18:00.640072  5289 sgd_solver.cpp:105] Iteration 1300, lr = 0.1
I1007 22:18:25.232233  5289 solver.cpp:218] Iteration 1400 (4.06672 iter/s, 24.5899s/100 iters), loss = 0.746069
I1007 22:18:25.232290  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.746069 (* 1 = 0.746069 loss)
I1007 22:18:25.232309  5289 sgd_solver.cpp:105] Iteration 1400, lr = 0.1
I1007 22:18:48.629823  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1007 22:18:49.610106  5289 solver.cpp:330] Iteration 1500, Testing net (#0)
I1007 22:18:54.233419  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1007 22:18:54.410851  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.4688
I1007 22:18:54.410877  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.92491 (* 1 = 1.92491 loss)
I1007 22:18:54.582784  5289 solver.cpp:218] Iteration 1500 (3.40744 iter/s, 29.3476s/100 iters), loss = 0.853406
I1007 22:18:54.582821  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.853406 (* 1 = 0.853406 loss)
I1007 22:18:54.582842  5289 sgd_solver.cpp:105] Iteration 1500, lr = 0.1
I1007 22:19:19.561151  5289 solver.cpp:218] Iteration 1600 (4.00383 iter/s, 24.9761s/100 iters), loss = 0.675851
I1007 22:19:19.561225  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.675851 (* 1 = 0.675851 loss)
I1007 22:19:19.561238  5289 sgd_solver.cpp:105] Iteration 1600, lr = 0.1
I1007 22:19:44.103269  5289 solver.cpp:218] Iteration 1700 (4.07503 iter/s, 24.5397s/100 iters), loss = 0.756991
I1007 22:19:44.103312  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.756991 (* 1 = 0.756991 loss)
I1007 22:19:44.103319  5289 sgd_solver.cpp:105] Iteration 1700, lr = 0.1
I1007 22:20:09.073916  5289 solver.cpp:218] Iteration 1800 (4.00507 iter/s, 24.9683s/100 iters), loss = 0.72339
I1007 22:20:09.074020  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.72339 (* 1 = 0.72339 loss)
I1007 22:20:09.074029  5289 sgd_solver.cpp:105] Iteration 1800, lr = 0.1
I1007 22:20:33.663825  5289 solver.cpp:218] Iteration 1900 (4.06709 iter/s, 24.5876s/100 iters), loss = 0.616684
I1007 22:20:33.663869  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.616684 (* 1 = 0.616684 loss)
I1007 22:20:33.663877  5289 sgd_solver.cpp:105] Iteration 1900, lr = 0.1
I1007 22:20:57.075345  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1007 22:20:58.058091  5289 solver.cpp:330] Iteration 2000, Testing net (#0)
I1007 22:21:02.708940  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1007 22:21:02.882499  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.517
I1007 22:21:02.882526  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.71307 (* 1 = 1.71307 loss)
I1007 22:21:03.054744  5289 solver.cpp:218] Iteration 2000 (3.40293 iter/s, 29.3865s/100 iters), loss = 0.726106
I1007 22:21:03.054785  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.726106 (* 1 = 0.726106 loss)
I1007 22:21:03.054792  5289 sgd_solver.cpp:105] Iteration 2000, lr = 0.1
I1007 22:21:28.055331  5289 solver.cpp:218] Iteration 2100 (4.00028 iter/s, 24.9983s/100 iters), loss = 0.505503
I1007 22:21:28.055408  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.505503 (* 1 = 0.505503 loss)
I1007 22:21:28.055415  5289 sgd_solver.cpp:105] Iteration 2100, lr = 0.1
I1007 22:21:52.651191  5289 solver.cpp:218] Iteration 2200 (4.06576 iter/s, 24.5957s/100 iters), loss = 0.636771
I1007 22:21:52.651237  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.636771 (* 1 = 0.636771 loss)
I1007 22:21:52.651247  5289 sgd_solver.cpp:105] Iteration 2200, lr = 0.1
I1007 22:22:17.681361  5289 solver.cpp:218] Iteration 2300 (3.99581 iter/s, 25.0262s/100 iters), loss = 0.623365
I1007 22:22:17.681473  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.623365 (* 1 = 0.623365 loss)
I1007 22:22:17.681480  5289 sgd_solver.cpp:105] Iteration 2300, lr = 0.1
I1007 22:22:42.241350  5289 solver.cpp:218] Iteration 2400 (4.07205 iter/s, 24.5577s/100 iters), loss = 0.536728
I1007 22:22:42.241384  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.536728 (* 1 = 0.536728 loss)
I1007 22:22:42.241401  5289 sgd_solver.cpp:105] Iteration 2400, lr = 0.1
I1007 22:23:05.616811  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1007 22:23:06.597440  5289 solver.cpp:330] Iteration 2500, Testing net (#0)
I1007 22:23:11.233716  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1007 22:23:11.406642  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7015
I1007 22:23:11.406680  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.872888 (* 1 = 0.872888 loss)
I1007 22:23:11.579942  5289 solver.cpp:218] Iteration 2500 (3.40889 iter/s, 29.335s/100 iters), loss = 0.708446
I1007 22:23:11.579984  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.708446 (* 1 = 0.708446 loss)
I1007 22:23:11.579991  5289 sgd_solver.cpp:105] Iteration 2500, lr = 0.1
I1007 22:23:36.599920  5289 solver.cpp:218] Iteration 2600 (3.99717 iter/s, 25.0177s/100 iters), loss = 0.463216
I1007 22:23:36.600020  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.463216 (* 1 = 0.463216 loss)
I1007 22:23:36.600029  5289 sgd_solver.cpp:105] Iteration 2600, lr = 0.1
I1007 22:24:01.159000  5289 solver.cpp:218] Iteration 2700 (4.0722 iter/s, 24.5567s/100 iters), loss = 0.5312
I1007 22:24:01.159046  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.5312 (* 1 = 0.5312 loss)
I1007 22:24:01.159054  5289 sgd_solver.cpp:105] Iteration 2700, lr = 0.1
I1007 22:24:26.121127  5289 solver.cpp:218] Iteration 2800 (4.00644 iter/s, 24.9598s/100 iters), loss = 0.580034
I1007 22:24:26.121212  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.580034 (* 1 = 0.580034 loss)
I1007 22:24:26.121219  5289 sgd_solver.cpp:105] Iteration 2800, lr = 0.1
I1007 22:24:50.696808  5289 solver.cpp:218] Iteration 2900 (4.06969 iter/s, 24.5719s/100 iters), loss = 0.545489
I1007 22:24:50.696844  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.545489 (* 1 = 0.545489 loss)
I1007 22:24:50.696851  5289 sgd_solver.cpp:105] Iteration 2900, lr = 0.1
I1007 22:25:14.022474  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1007 22:25:14.970528  5289 solver.cpp:330] Iteration 3000, Testing net (#0)
I1007 22:25:19.626411  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1007 22:25:19.780985  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7532
I1007 22:25:19.781013  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.727026 (* 1 = 0.727026 loss)
I1007 22:25:19.981786  5289 solver.cpp:218] Iteration 3000 (3.41499 iter/s, 29.2826s/100 iters), loss = 0.528584
I1007 22:25:19.981822  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.528584 (* 1 = 0.528584 loss)
I1007 22:25:19.981839  5289 sgd_solver.cpp:105] Iteration 3000, lr = 0.1
I1007 22:25:44.978864  5289 solver.cpp:218] Iteration 3100 (4.00083 iter/s, 24.9948s/100 iters), loss = 0.468297
I1007 22:25:44.978956  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.468297 (* 1 = 0.468297 loss)
I1007 22:25:44.978979  5289 sgd_solver.cpp:105] Iteration 3100, lr = 0.1
I1007 22:26:09.590090  5289 solver.cpp:218] Iteration 3200 (4.06323 iter/s, 24.611s/100 iters), loss = 0.534511
I1007 22:26:09.590123  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.534511 (* 1 = 0.534511 loss)
I1007 22:26:09.590142  5289 sgd_solver.cpp:105] Iteration 3200, lr = 0.1
I1007 22:26:34.553369  5289 solver.cpp:218] Iteration 3300 (4.00625 iter/s, 24.961s/100 iters), loss = 0.565185
I1007 22:26:34.553450  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.565185 (* 1 = 0.565185 loss)
I1007 22:26:34.553469  5289 sgd_solver.cpp:105] Iteration 3300, lr = 0.1
I1007 22:26:59.151262  5289 solver.cpp:218] Iteration 3400 (4.06576 iter/s, 24.5956s/100 iters), loss = 0.574322
I1007 22:26:59.151298  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.574322 (* 1 = 0.574322 loss)
I1007 22:26:59.151316  5289 sgd_solver.cpp:105] Iteration 3400, lr = 0.1
I1007 22:27:22.551147  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1007 22:27:23.533519  5289 solver.cpp:330] Iteration 3500, Testing net (#0)
I1007 22:27:28.157186  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1007 22:27:28.341423  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7525
I1007 22:27:28.341449  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.684706 (* 1 = 0.684706 loss)
I1007 22:27:28.508653  5289 solver.cpp:218] Iteration 3500 (3.40673 iter/s, 29.3536s/100 iters), loss = 0.604031
I1007 22:27:28.508687  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.604031 (* 1 = 0.604031 loss)
I1007 22:27:28.508694  5289 sgd_solver.cpp:105] Iteration 3500, lr = 0.1
I1007 22:27:53.589129  5289 solver.cpp:218] Iteration 3600 (3.98742 iter/s, 25.0788s/100 iters), loss = 0.492761
I1007 22:27:53.589238  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.492761 (* 1 = 0.492761 loss)
I1007 22:27:53.589249  5289 sgd_solver.cpp:105] Iteration 3600, lr = 0.1
I1007 22:28:18.231690  5289 solver.cpp:218] Iteration 3700 (4.05806 iter/s, 24.6423s/100 iters), loss = 0.547516
I1007 22:28:18.231729  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.547516 (* 1 = 0.547516 loss)
I1007 22:28:18.231739  5289 sgd_solver.cpp:105] Iteration 3700, lr = 0.1
I1007 22:28:43.225874  5289 solver.cpp:218] Iteration 3800 (4.0013 iter/s, 24.9919s/100 iters), loss = 0.564618
I1007 22:28:43.225999  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.564618 (* 1 = 0.564618 loss)
I1007 22:28:43.226017  5289 sgd_solver.cpp:105] Iteration 3800, lr = 0.1
I1007 22:29:07.874783  5289 solver.cpp:218] Iteration 3900 (4.05735 iter/s, 24.6466s/100 iters), loss = 0.601155
I1007 22:29:07.874814  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.601155 (* 1 = 0.601155 loss)
I1007 22:29:07.874821  5289 sgd_solver.cpp:105] Iteration 3900, lr = 0.1
I1007 22:29:31.306376  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1007 22:29:32.292603  5289 solver.cpp:330] Iteration 4000, Testing net (#0)
I1007 22:29:36.906076  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1007 22:29:37.094418  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7919
I1007 22:29:37.094445  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.59909 (* 1 = 0.59909 loss)
I1007 22:29:37.279698  5289 solver.cpp:218] Iteration 4000 (3.40106 iter/s, 29.4026s/100 iters), loss = 0.509116
I1007 22:29:37.279743  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.509116 (* 1 = 0.509116 loss)
I1007 22:29:37.279750  5289 sgd_solver.cpp:105] Iteration 4000, lr = 0.1
I1007 22:30:02.368000  5289 solver.cpp:218] Iteration 4100 (3.98628 iter/s, 25.086s/100 iters), loss = 0.407206
I1007 22:30:02.368084  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.407206 (* 1 = 0.407206 loss)
I1007 22:30:02.368105  5289 sgd_solver.cpp:105] Iteration 4100, lr = 0.1
I1007 22:30:27.051877  5289 solver.cpp:218] Iteration 4200 (4.05127 iter/s, 24.6836s/100 iters), loss = 0.505742
I1007 22:30:27.051908  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.505742 (* 1 = 0.505742 loss)
I1007 22:30:27.051916  5289 sgd_solver.cpp:105] Iteration 4200, lr = 0.1
I1007 22:30:52.051512  5289 solver.cpp:218] Iteration 4300 (4.00042 iter/s, 24.9974s/100 iters), loss = 0.559766
I1007 22:30:52.051605  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.559766 (* 1 = 0.559766 loss)
I1007 22:30:52.051614  5289 sgd_solver.cpp:105] Iteration 4300, lr = 0.1
I1007 22:31:16.681685  5289 solver.cpp:218] Iteration 4400 (4.06044 iter/s, 24.6279s/100 iters), loss = 0.433853
I1007 22:31:16.681722  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.433853 (* 1 = 0.433853 loss)
I1007 22:31:16.681743  5289 sgd_solver.cpp:105] Iteration 4400, lr = 0.1
I1007 22:31:40.098662  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1007 22:31:41.081001  5289 solver.cpp:330] Iteration 4500, Testing net (#0)
I1007 22:31:45.703467  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1007 22:31:45.889740  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8033
I1007 22:31:45.889767  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.56575 (* 1 = 0.56575 loss)
I1007 22:31:46.063585  5289 solver.cpp:218] Iteration 4500 (3.40373 iter/s, 29.3796s/100 iters), loss = 0.443361
I1007 22:31:46.063628  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.443361 (* 1 = 0.443361 loss)
I1007 22:31:46.063635  5289 sgd_solver.cpp:105] Iteration 4500, lr = 0.1
I1007 22:32:11.136916  5289 solver.cpp:218] Iteration 4600 (3.9886 iter/s, 25.0715s/100 iters), loss = 0.35051
I1007 22:32:11.137001  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.35051 (* 1 = 0.35051 loss)
I1007 22:32:11.137009  5289 sgd_solver.cpp:105] Iteration 4600, lr = 0.1
I1007 22:32:35.685398  5289 solver.cpp:218] Iteration 4700 (4.0736 iter/s, 24.5483s/100 iters), loss = 0.540299
I1007 22:32:35.685432  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.540299 (* 1 = 0.540299 loss)
I1007 22:32:35.685441  5289 sgd_solver.cpp:105] Iteration 4700, lr = 0.1
I1007 22:33:00.687404  5289 solver.cpp:218] Iteration 4800 (4.00025 iter/s, 24.9984s/100 iters), loss = 0.486314
I1007 22:33:00.687503  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.486314 (* 1 = 0.486314 loss)
I1007 22:33:00.687522  5289 sgd_solver.cpp:105] Iteration 4800, lr = 0.1
I1007 22:33:25.337229  5289 solver.cpp:218] Iteration 4900 (4.0575 iter/s, 24.6457s/100 iters), loss = 0.48332
I1007 22:33:25.337265  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.48332 (* 1 = 0.48332 loss)
I1007 22:33:25.337281  5289 sgd_solver.cpp:105] Iteration 4900, lr = 0.1
I1007 22:33:48.764788  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1007 22:33:49.749945  5289 solver.cpp:330] Iteration 5000, Testing net (#0)
I1007 22:33:54.361999  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1007 22:33:54.547220  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8102
I1007 22:33:54.547246  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.560647 (* 1 = 0.560647 loss)
I1007 22:33:54.722911  5289 solver.cpp:218] Iteration 5000 (3.40328 iter/s, 29.3834s/100 iters), loss = 0.438962
I1007 22:33:54.722954  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.438962 (* 1 = 0.438962 loss)
I1007 22:33:54.722960  5289 sgd_solver.cpp:105] Iteration 5000, lr = 0.1
I1007 22:34:19.911891  5289 solver.cpp:218] Iteration 5100 (3.97059 iter/s, 25.1852s/100 iters), loss = 0.375064
I1007 22:34:19.911998  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.375064 (* 1 = 0.375064 loss)
I1007 22:34:19.912006  5289 sgd_solver.cpp:105] Iteration 5100, lr = 0.1
I1007 22:34:44.592088  5289 solver.cpp:218] Iteration 5200 (4.0522 iter/s, 24.6779s/100 iters), loss = 0.497565
I1007 22:34:44.592130  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.497565 (* 1 = 0.497565 loss)
I1007 22:34:44.592137  5289 sgd_solver.cpp:105] Iteration 5200, lr = 0.1
I1007 22:35:09.592169  5289 solver.cpp:218] Iteration 5300 (4.00059 iter/s, 24.9963s/100 iters), loss = 0.440528
I1007 22:35:09.592253  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.440528 (* 1 = 0.440528 loss)
I1007 22:35:09.592262  5289 sgd_solver.cpp:105] Iteration 5300, lr = 0.1
I1007 22:35:34.259977  5289 solver.cpp:218] Iteration 5400 (4.05424 iter/s, 24.6655s/100 iters), loss = 0.397374
I1007 22:35:34.260023  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.397374 (* 1 = 0.397374 loss)
I1007 22:35:34.260030  5289 sgd_solver.cpp:105] Iteration 5400, lr = 0.1
I1007 22:35:57.697182  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1007 22:35:58.679246  5289 solver.cpp:330] Iteration 5500, Testing net (#0)
I1007 22:36:03.172487  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1007 22:36:03.365157  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8139
I1007 22:36:03.365195  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.547187 (* 1 = 0.547187 loss)
I1007 22:36:03.524031  5289 solver.cpp:218] Iteration 5500 (3.41743 iter/s, 29.2618s/100 iters), loss = 0.341555
I1007 22:36:03.524071  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.341555 (* 1 = 0.341555 loss)
I1007 22:36:03.524078  5289 sgd_solver.cpp:105] Iteration 5500, lr = 0.1
I1007 22:36:28.660786  5289 solver.cpp:218] Iteration 5600 (3.9786 iter/s, 25.1345s/100 iters), loss = 0.406514
I1007 22:36:28.660889  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.406514 (* 1 = 0.406514 loss)
I1007 22:36:28.660898  5289 sgd_solver.cpp:105] Iteration 5600, lr = 0.1
I1007 22:36:53.340724  5289 solver.cpp:218] Iteration 5700 (4.05252 iter/s, 24.676s/100 iters), loss = 0.446038
I1007 22:36:53.340767  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.446038 (* 1 = 0.446038 loss)
I1007 22:36:53.340773  5289 sgd_solver.cpp:105] Iteration 5700, lr = 0.1
I1007 22:37:18.335153  5289 solver.cpp:218] Iteration 5800 (4.00147 iter/s, 24.9908s/100 iters), loss = 0.444551
I1007 22:37:18.335237  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.444551 (* 1 = 0.444551 loss)
I1007 22:37:18.335244  5289 sgd_solver.cpp:105] Iteration 5800, lr = 0.1
I1007 22:37:42.949975  5289 solver.cpp:218] Iteration 5900 (4.06297 iter/s, 24.6126s/100 iters), loss = 0.437505
I1007 22:37:42.950016  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.437505 (* 1 = 0.437505 loss)
I1007 22:37:42.950021  5289 sgd_solver.cpp:105] Iteration 5900, lr = 0.1
I1007 22:38:06.383553  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1007 22:38:07.366534  5289 solver.cpp:330] Iteration 6000, Testing net (#0)
I1007 22:38:12.028659  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1007 22:38:12.193032  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8128
I1007 22:38:12.193058  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.547994 (* 1 = 0.547994 loss)
I1007 22:38:12.388977  5289 solver.cpp:218] Iteration 6000 (3.39723 iter/s, 29.4358s/100 iters), loss = 0.429273
I1007 22:38:12.389008  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.429273 (* 1 = 0.429273 loss)
I1007 22:38:12.389014  5289 sgd_solver.cpp:105] Iteration 6000, lr = 0.1
I1007 22:38:37.422819  5289 solver.cpp:218] Iteration 6100 (3.99496 iter/s, 25.0315s/100 iters), loss = 0.385988
I1007 22:38:37.422914  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.385989 (* 1 = 0.385989 loss)
I1007 22:38:37.422925  5289 sgd_solver.cpp:105] Iteration 6100, lr = 0.1
I1007 22:39:01.978278  5289 solver.cpp:218] Iteration 6200 (4.07245 iter/s, 24.5552s/100 iters), loss = 0.426356
I1007 22:39:01.978313  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.426356 (* 1 = 0.426356 loss)
I1007 22:39:01.978320  5289 sgd_solver.cpp:105] Iteration 6200, lr = 0.1
I1007 22:39:27.065485  5289 solver.cpp:218] Iteration 6300 (3.98646 iter/s, 25.0849s/100 iters), loss = 0.509653
I1007 22:39:27.065582  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.509653 (* 1 = 0.509653 loss)
I1007 22:39:27.065599  5289 sgd_solver.cpp:105] Iteration 6300, lr = 0.1
I1007 22:39:51.706856  5289 solver.cpp:218] Iteration 6400 (4.05859 iter/s, 24.6391s/100 iters), loss = 0.32631
I1007 22:39:51.706900  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.32631 (* 1 = 0.32631 loss)
I1007 22:39:51.706907  5289 sgd_solver.cpp:105] Iteration 6400, lr = 0.1
I1007 22:40:15.108258  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1007 22:40:16.089602  5289 solver.cpp:330] Iteration 6500, Testing net (#0)
I1007 22:40:20.731379  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1007 22:40:20.910791  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8237
I1007 22:40:20.910817  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.520355 (* 1 = 0.520355 loss)
I1007 22:40:21.084581  5289 solver.cpp:218] Iteration 6500 (3.40421 iter/s, 29.3754s/100 iters), loss = 0.503526
I1007 22:40:21.084612  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.503526 (* 1 = 0.503526 loss)
I1007 22:40:21.084619  5289 sgd_solver.cpp:105] Iteration 6500, lr = 0.1
I1007 22:40:46.148427  5289 solver.cpp:218] Iteration 6600 (3.99017 iter/s, 25.0616s/100 iters), loss = 0.358653
I1007 22:40:46.148524  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.358653 (* 1 = 0.358653 loss)
I1007 22:40:46.148533  5289 sgd_solver.cpp:105] Iteration 6600, lr = 0.1
I1007 22:41:10.726032  5289 solver.cpp:218] Iteration 6700 (4.06913 iter/s, 24.5753s/100 iters), loss = 0.422768
I1007 22:41:10.726070  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.422768 (* 1 = 0.422768 loss)
I1007 22:41:10.726078  5289 sgd_solver.cpp:105] Iteration 6700, lr = 0.1
I1007 22:41:35.714957  5289 solver.cpp:218] Iteration 6800 (4.00238 iter/s, 24.9852s/100 iters), loss = 0.453902
I1007 22:41:35.715059  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.453902 (* 1 = 0.453902 loss)
I1007 22:41:35.715066  5289 sgd_solver.cpp:105] Iteration 6800, lr = 0.1
I1007 22:42:00.332562  5289 solver.cpp:218] Iteration 6900 (4.0625 iter/s, 24.6154s/100 iters), loss = 0.380984
I1007 22:42:00.332595  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.380984 (* 1 = 0.380984 loss)
I1007 22:42:00.332602  5289 sgd_solver.cpp:105] Iteration 6900, lr = 0.1
I1007 22:42:23.724972  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1007 22:42:24.706511  5289 solver.cpp:330] Iteration 7000, Testing net (#0)
I1007 22:42:29.308080  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1007 22:42:29.496254  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8216
I1007 22:42:29.496282  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.522633 (* 1 = 0.522633 loss)
I1007 22:42:29.662447  5289 solver.cpp:218] Iteration 7000 (3.40976 iter/s, 29.3276s/100 iters), loss = 0.404182
I1007 22:42:29.662485  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.404182 (* 1 = 0.404182 loss)
I1007 22:42:29.662493  5289 sgd_solver.cpp:105] Iteration 7000, lr = 0.1
I1007 22:42:54.778312  5289 solver.cpp:218] Iteration 7100 (3.98224 iter/s, 25.1115s/100 iters), loss = 0.441342
I1007 22:42:54.778374  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.441342 (* 1 = 0.441342 loss)
I1007 22:42:54.778388  5289 sgd_solver.cpp:105] Iteration 7100, lr = 0.1
I1007 22:43:19.404947  5289 solver.cpp:218] Iteration 7200 (4.06102 iter/s, 24.6244s/100 iters), loss = 0.327567
I1007 22:43:19.404983  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.327567 (* 1 = 0.327567 loss)
I1007 22:43:19.404990  5289 sgd_solver.cpp:105] Iteration 7200, lr = 0.1
I1007 22:43:44.480692  5289 solver.cpp:218] Iteration 7300 (3.98828 iter/s, 25.0735s/100 iters), loss = 0.410333
I1007 22:43:44.480778  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.410333 (* 1 = 0.410333 loss)
I1007 22:43:44.480787  5289 sgd_solver.cpp:105] Iteration 7300, lr = 0.1
I1007 22:44:09.116364  5289 solver.cpp:218] Iteration 7400 (4.05953 iter/s, 24.6334s/100 iters), loss = 0.437241
I1007 22:44:09.116397  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.437241 (* 1 = 0.437241 loss)
I1007 22:44:09.116405  5289 sgd_solver.cpp:105] Iteration 7400, lr = 0.1
I1007 22:44:32.552927  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1007 22:44:33.534665  5289 solver.cpp:330] Iteration 7500, Testing net (#0)
I1007 22:44:38.086529  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1007 22:44:38.297951  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8118
I1007 22:44:38.297981  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.556034 (* 1 = 0.556034 loss)
I1007 22:44:38.426894  5289 solver.cpp:218] Iteration 7500 (3.41201 iter/s, 29.3083s/100 iters), loss = 0.363723
I1007 22:44:38.426928  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.363723 (* 1 = 0.363723 loss)
I1007 22:44:38.426936  5289 sgd_solver.cpp:105] Iteration 7500, lr = 0.1
I1007 22:45:03.438094  5289 solver.cpp:218] Iteration 7600 (3.99823 iter/s, 25.011s/100 iters), loss = 0.340327
I1007 22:45:03.438202  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.340327 (* 1 = 0.340327 loss)
I1007 22:45:03.438221  5289 sgd_solver.cpp:105] Iteration 7600, lr = 0.1
I1007 22:45:28.126399  5289 solver.cpp:218] Iteration 7700 (4.05087 iter/s, 24.686s/100 iters), loss = 0.370145
I1007 22:45:28.126442  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.370145 (* 1 = 0.370145 loss)
I1007 22:45:28.126449  5289 sgd_solver.cpp:105] Iteration 7700, lr = 0.1
I1007 22:45:53.215879  5289 solver.cpp:218] Iteration 7800 (3.98609 iter/s, 25.0872s/100 iters), loss = 0.415049
I1007 22:45:53.215952  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.41505 (* 1 = 0.41505 loss)
I1007 22:45:53.215961  5289 sgd_solver.cpp:105] Iteration 7800, lr = 0.1
I1007 22:46:17.861730  5289 solver.cpp:218] Iteration 7900 (4.0582 iter/s, 24.6415s/100 iters), loss = 0.379511
I1007 22:46:17.861764  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.379511 (* 1 = 0.379511 loss)
I1007 22:46:17.861771  5289 sgd_solver.cpp:105] Iteration 7900, lr = 0.1
I1007 22:46:41.312283  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1007 22:46:42.296901  5289 solver.cpp:330] Iteration 8000, Testing net (#0)
I1007 22:46:46.919162  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1007 22:46:47.105336  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8348
I1007 22:46:47.105373  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.480965 (* 1 = 0.480965 loss)
I1007 22:46:47.262264  5289 solver.cpp:218] Iteration 8000 (3.40181 iter/s, 29.3961s/100 iters), loss = 0.386553
I1007 22:46:47.262300  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.386553 (* 1 = 0.386553 loss)
I1007 22:46:47.262310  5289 sgd_solver.cpp:105] Iteration 8000, lr = 0.1
I1007 22:47:12.390280  5289 solver.cpp:218] Iteration 8100 (3.97998 iter/s, 25.1258s/100 iters), loss = 0.36212
I1007 22:47:12.390358  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.36212 (* 1 = 0.36212 loss)
I1007 22:47:12.390367  5289 sgd_solver.cpp:105] Iteration 8100, lr = 0.1
I1007 22:47:37.054378  5289 solver.cpp:218] Iteration 8200 (4.05485 iter/s, 24.6618s/100 iters), loss = 0.419885
I1007 22:47:37.054417  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.419885 (* 1 = 0.419885 loss)
I1007 22:47:37.054427  5289 sgd_solver.cpp:105] Iteration 8200, lr = 0.1
I1007 22:48:02.037271  5289 solver.cpp:218] Iteration 8300 (4.0031 iter/s, 24.9806s/100 iters), loss = 0.43183
I1007 22:48:02.037339  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.43183 (* 1 = 0.43183 loss)
I1007 22:48:02.037348  5289 sgd_solver.cpp:105] Iteration 8300, lr = 0.1
I1007 22:48:26.627595  5289 solver.cpp:218] Iteration 8400 (4.06702 iter/s, 24.588s/100 iters), loss = 0.386226
I1007 22:48:26.627629  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.386227 (* 1 = 0.386227 loss)
I1007 22:48:26.627647  5289 sgd_solver.cpp:105] Iteration 8400, lr = 0.1
I1007 22:48:50.063640  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1007 22:48:51.047888  5289 solver.cpp:330] Iteration 8500, Testing net (#0)
I1007 22:48:55.715950  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1007 22:48:55.872011  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8356
I1007 22:48:55.872037  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.488496 (* 1 = 0.488496 loss)
I1007 22:48:56.071380  5289 solver.cpp:218] Iteration 8500 (3.39681 iter/s, 29.4394s/100 iters), loss = 0.364001
I1007 22:48:56.071413  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.364001 (* 1 = 0.364001 loss)
I1007 22:48:56.071419  5289 sgd_solver.cpp:105] Iteration 8500, lr = 0.1
I1007 22:49:21.238672  5289 solver.cpp:218] Iteration 8600 (3.97377 iter/s, 25.165s/100 iters), loss = 0.32927
I1007 22:49:21.238777  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.32927 (* 1 = 0.32927 loss)
I1007 22:49:21.238787  5289 sgd_solver.cpp:105] Iteration 8600, lr = 0.1
I1007 22:49:45.894944  5289 solver.cpp:218] Iteration 8700 (4.05614 iter/s, 24.654s/100 iters), loss = 0.412499
I1007 22:49:45.894986  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.412499 (* 1 = 0.412499 loss)
I1007 22:49:45.894994  5289 sgd_solver.cpp:105] Iteration 8700, lr = 0.1
I1007 22:50:10.999126  5289 solver.cpp:218] Iteration 8800 (3.98376 iter/s, 25.1019s/100 iters), loss = 0.40949
I1007 22:50:10.999238  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.40949 (* 1 = 0.40949 loss)
I1007 22:50:10.999248  5289 sgd_solver.cpp:105] Iteration 8800, lr = 0.1
I1007 22:50:35.664198  5289 solver.cpp:218] Iteration 8900 (4.05469 iter/s, 24.6628s/100 iters), loss = 0.395849
I1007 22:50:35.664244  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.395849 (* 1 = 0.395849 loss)
I1007 22:50:35.664252  5289 sgd_solver.cpp:105] Iteration 8900, lr = 0.1
I1007 22:50:59.096124  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1007 22:51:00.080541  5289 solver.cpp:330] Iteration 9000, Testing net (#0)
I1007 22:51:04.611717  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1007 22:51:04.797628  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8101
I1007 22:51:04.797654  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.570552 (* 1 = 0.570552 loss)
I1007 22:51:04.956847  5289 solver.cpp:218] Iteration 9000 (3.41422 iter/s, 29.2892s/100 iters), loss = 0.334705
I1007 22:51:04.956879  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.334705 (* 1 = 0.334705 loss)
I1007 22:51:04.956885  5289 sgd_solver.cpp:105] Iteration 9000, lr = 0.1
I1007 22:51:29.951805  5289 solver.cpp:218] Iteration 9100 (4.00083 iter/s, 24.9948s/100 iters), loss = 0.281933
I1007 22:51:29.951890  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.281933 (* 1 = 0.281933 loss)
I1007 22:51:29.951898  5289 sgd_solver.cpp:105] Iteration 9100, lr = 0.1
I1007 22:51:54.589293  5289 solver.cpp:218] Iteration 9200 (4.05923 iter/s, 24.6352s/100 iters), loss = 0.320778
I1007 22:51:54.589328  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.320778 (* 1 = 0.320778 loss)
I1007 22:51:54.589334  5289 sgd_solver.cpp:105] Iteration 9200, lr = 0.1
I1007 22:52:19.616508  5289 solver.cpp:218] Iteration 9300 (3.99627 iter/s, 25.0234s/100 iters), loss = 0.30422
I1007 22:52:19.616610  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.30422 (* 1 = 0.30422 loss)
I1007 22:52:19.616621  5289 sgd_solver.cpp:105] Iteration 9300, lr = 0.1
I1007 22:52:44.232981  5289 solver.cpp:218] Iteration 9400 (4.06269 iter/s, 24.6142s/100 iters), loss = 0.309779
I1007 22:52:44.233018  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.309779 (* 1 = 0.309779 loss)
I1007 22:52:44.233026  5289 sgd_solver.cpp:105] Iteration 9400, lr = 0.1
I1007 22:53:07.659709  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1007 22:53:08.644932  5289 solver.cpp:330] Iteration 9500, Testing net (#0)
I1007 22:53:13.255584  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1007 22:53:13.441988  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.79
I1007 22:53:13.442032  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.629082 (* 1 = 0.629082 loss)
I1007 22:53:13.602627  5289 solver.cpp:218] Iteration 9500 (3.40514 iter/s, 29.3674s/100 iters), loss = 0.344839
I1007 22:53:13.602668  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.344839 (* 1 = 0.344839 loss)
I1007 22:53:13.602676  5289 sgd_solver.cpp:105] Iteration 9500, lr = 0.1
I1007 22:53:38.746031  5289 solver.cpp:218] Iteration 9600 (3.97754 iter/s, 25.1412s/100 iters), loss = 0.287336
I1007 22:53:38.746107  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.287336 (* 1 = 0.287336 loss)
I1007 22:53:38.746114  5289 sgd_solver.cpp:105] Iteration 9600, lr = 0.1
I1007 22:54:03.364735  5289 solver.cpp:218] Iteration 9700 (4.06199 iter/s, 24.6185s/100 iters), loss = 0.28303
I1007 22:54:03.364770  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.28303 (* 1 = 0.28303 loss)
I1007 22:54:03.364778  5289 sgd_solver.cpp:105] Iteration 9700, lr = 0.1
I1007 22:54:28.433831  5289 solver.cpp:218] Iteration 9800 (3.98934 iter/s, 25.0668s/100 iters), loss = 0.386998
I1007 22:54:28.433930  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.386998 (* 1 = 0.386998 loss)
I1007 22:54:28.433939  5289 sgd_solver.cpp:105] Iteration 9800, lr = 0.1
I1007 22:54:53.065094  5289 solver.cpp:218] Iteration 9900 (4.06061 iter/s, 24.6269s/100 iters), loss = 0.381396
I1007 22:54:53.065129  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.381396 (* 1 = 0.381396 loss)
I1007 22:54:53.065136  5289 sgd_solver.cpp:105] Iteration 9900, lr = 0.1
I1007 22:55:16.476582  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1007 22:55:17.460005  5289 solver.cpp:330] Iteration 10000, Testing net (#0)
I1007 22:55:22.126268  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1007 22:55:22.322643  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8167
I1007 22:55:22.322680  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.554444 (* 1 = 0.554444 loss)
I1007 22:55:22.477677  5289 solver.cpp:218] Iteration 10000 (3.40017 iter/s, 29.4103s/100 iters), loss = 0.432593
I1007 22:55:22.477720  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.432593 (* 1 = 0.432593 loss)
I1007 22:55:22.477726  5289 sgd_solver.cpp:105] Iteration 10000, lr = 0.1
I1007 22:55:47.479977  5289 solver.cpp:218] Iteration 10100 (4 iter/s, 25s/100 iters), loss = 0.311161
I1007 22:55:47.480038  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.311161 (* 1 = 0.311161 loss)
I1007 22:55:47.480047  5289 sgd_solver.cpp:105] Iteration 10100, lr = 0.1
I1007 22:56:12.094432  5289 solver.cpp:218] Iteration 10200 (4.06268 iter/s, 24.6143s/100 iters), loss = 0.349549
I1007 22:56:12.094475  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.349549 (* 1 = 0.349549 loss)
I1007 22:56:12.094481  5289 sgd_solver.cpp:105] Iteration 10200, lr = 0.1
I1007 22:56:37.195785  5289 solver.cpp:218] Iteration 10300 (3.98421 iter/s, 25.0991s/100 iters), loss = 0.373719
I1007 22:56:37.195852  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.373719 (* 1 = 0.373719 loss)
I1007 22:56:37.195870  5289 sgd_solver.cpp:105] Iteration 10300, lr = 0.1
I1007 22:57:01.790360  5289 solver.cpp:218] Iteration 10400 (4.06631 iter/s, 24.5923s/100 iters), loss = 0.282308
I1007 22:57:01.790396  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.282308 (* 1 = 0.282308 loss)
I1007 22:57:01.790403  5289 sgd_solver.cpp:105] Iteration 10400, lr = 0.1
I1007 22:57:25.214941  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1007 22:57:26.197566  5289 solver.cpp:330] Iteration 10500, Testing net (#0)
I1007 22:57:30.863158  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1007 22:57:31.065732  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8234
I1007 22:57:31.065758  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.521328 (* 1 = 0.521328 loss)
I1007 22:57:31.212443  5289 solver.cpp:218] Iteration 10500 (3.39932 iter/s, 29.4177s/100 iters), loss = 0.297805
I1007 22:57:31.212476  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.297805 (* 1 = 0.297805 loss)
I1007 22:57:31.212484  5289 sgd_solver.cpp:105] Iteration 10500, lr = 0.1
I1007 22:57:56.285425  5289 solver.cpp:218] Iteration 10600 (3.98872 iter/s, 25.0707s/100 iters), loss = 0.344833
I1007 22:57:56.285519  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.344833 (* 1 = 0.344833 loss)
I1007 22:57:56.285528  5289 sgd_solver.cpp:105] Iteration 10600, lr = 0.1
I1007 22:58:20.940991  5289 solver.cpp:218] Iteration 10700 (4.05626 iter/s, 24.6533s/100 iters), loss = 0.389775
I1007 22:58:20.941025  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.389775 (* 1 = 0.389775 loss)
I1007 22:58:20.941032  5289 sgd_solver.cpp:105] Iteration 10700, lr = 0.1
I1007 22:58:45.930713  5289 solver.cpp:218] Iteration 10800 (4.00201 iter/s, 24.9875s/100 iters), loss = 0.346649
I1007 22:58:45.930843  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.346649 (* 1 = 0.346649 loss)
I1007 22:58:45.930855  5289 sgd_solver.cpp:105] Iteration 10800, lr = 0.1
I1007 22:59:10.555721  5289 solver.cpp:218] Iteration 10900 (4.06128 iter/s, 24.6228s/100 iters), loss = 0.310489
I1007 22:59:10.555757  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.310489 (* 1 = 0.310489 loss)
I1007 22:59:10.555766  5289 sgd_solver.cpp:105] Iteration 10900, lr = 0.1
I1007 22:59:33.990144  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1007 22:59:34.973428  5289 solver.cpp:330] Iteration 11000, Testing net (#0)
I1007 22:59:39.522076  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1007 22:59:39.729343  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8388
I1007 22:59:39.729369  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.46773 (* 1 = 0.46773 loss)
I1007 22:59:39.864982  5289 solver.cpp:218] Iteration 11000 (3.41231 iter/s, 29.3057s/100 iters), loss = 0.394887
I1007 22:59:39.865015  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.394887 (* 1 = 0.394887 loss)
I1007 22:59:39.865022  5289 sgd_solver.cpp:105] Iteration 11000, lr = 0.1
I1007 23:00:04.874035  5289 solver.cpp:218] Iteration 11100 (3.99891 iter/s, 25.0068s/100 iters), loss = 0.357657
I1007 23:00:04.874127  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.357657 (* 1 = 0.357657 loss)
I1007 23:00:04.874145  5289 sgd_solver.cpp:105] Iteration 11100, lr = 0.1
I1007 23:00:29.535095  5289 solver.cpp:218] Iteration 11200 (4.05536 iter/s, 24.6587s/100 iters), loss = 0.321543
I1007 23:00:29.535127  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.321543 (* 1 = 0.321543 loss)
I1007 23:00:29.535135  5289 sgd_solver.cpp:105] Iteration 11200, lr = 0.1
I1007 23:00:54.621280  5289 solver.cpp:218] Iteration 11300 (3.98662 iter/s, 25.0839s/100 iters), loss = 0.339493
I1007 23:00:54.621369  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.339493 (* 1 = 0.339493 loss)
I1007 23:00:54.621387  5289 sgd_solver.cpp:105] Iteration 11300, lr = 0.1
I1007 23:01:19.282107  5289 solver.cpp:218] Iteration 11400 (4.05539 iter/s, 24.6586s/100 iters), loss = 0.325508
I1007 23:01:19.282145  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.325508 (* 1 = 0.325508 loss)
I1007 23:01:19.282150  5289 sgd_solver.cpp:105] Iteration 11400, lr = 0.1
I1007 23:01:42.708649  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:01:43.690896  5289 solver.cpp:330] Iteration 11500, Testing net (#0)
I1007 23:01:48.276877  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:01:48.431344  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8292
I1007 23:01:48.431370  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.51231 (* 1 = 0.51231 loss)
I1007 23:01:48.625771  5289 solver.cpp:218] Iteration 11500 (3.40815 iter/s, 29.3414s/100 iters), loss = 0.383353
I1007 23:01:48.625804  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.383353 (* 1 = 0.383353 loss)
I1007 23:01:48.625811  5289 sgd_solver.cpp:105] Iteration 11500, lr = 0.1
I1007 23:02:13.565368  5289 solver.cpp:218] Iteration 11600 (4.01005 iter/s, 24.9373s/100 iters), loss = 0.344363
I1007 23:02:13.565441  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.344363 (* 1 = 0.344363 loss)
I1007 23:02:13.565449  5289 sgd_solver.cpp:105] Iteration 11600, lr = 0.1
I1007 23:02:38.185274  5289 solver.cpp:218] Iteration 11700 (4.06178 iter/s, 24.6198s/100 iters), loss = 0.424498
I1007 23:02:38.185304  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.424498 (* 1 = 0.424498 loss)
I1007 23:02:38.185310  5289 sgd_solver.cpp:105] Iteration 11700, lr = 0.1
I1007 23:03:03.249660  5289 solver.cpp:218] Iteration 11800 (3.99008 iter/s, 25.0621s/100 iters), loss = 0.376341
I1007 23:03:03.249765  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.376341 (* 1 = 0.376341 loss)
I1007 23:03:03.249774  5289 sgd_solver.cpp:105] Iteration 11800, lr = 0.1
I1007 23:03:27.856089  5289 solver.cpp:218] Iteration 11900 (4.06435 iter/s, 24.6042s/100 iters), loss = 0.274404
I1007 23:03:27.856120  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.274404 (* 1 = 0.274404 loss)
I1007 23:03:27.856127  5289 sgd_solver.cpp:105] Iteration 11900, lr = 0.1
I1007 23:03:51.258494  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:03:52.241008  5289 solver.cpp:330] Iteration 12000, Testing net (#0)
I1007 23:03:56.864873  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:03:57.049818  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8282
I1007 23:03:57.049854  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.528754 (* 1 = 0.528754 loss)
I1007 23:03:57.204511  5289 solver.cpp:218] Iteration 12000 (3.4076 iter/s, 29.3462s/100 iters), loss = 0.306052
I1007 23:03:57.204553  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.306052 (* 1 = 0.306052 loss)
I1007 23:03:57.204560  5289 sgd_solver.cpp:105] Iteration 12000, lr = 0.1
I1007 23:04:22.269712  5289 solver.cpp:218] Iteration 12100 (3.98995 iter/s, 25.0629s/100 iters), loss = 0.229496
I1007 23:04:22.269795  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.229496 (* 1 = 0.229496 loss)
I1007 23:04:22.269804  5289 sgd_solver.cpp:105] Iteration 12100, lr = 0.1
I1007 23:04:46.871251  5289 solver.cpp:218] Iteration 12200 (4.06516 iter/s, 24.5993s/100 iters), loss = 0.34248
I1007 23:04:46.871289  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.34248 (* 1 = 0.34248 loss)
I1007 23:04:46.871296  5289 sgd_solver.cpp:105] Iteration 12200, lr = 0.1
I1007 23:05:11.925024  5289 solver.cpp:218] Iteration 12300 (3.99178 iter/s, 25.0515s/100 iters), loss = 0.403735
I1007 23:05:11.925098  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.403735 (* 1 = 0.403735 loss)
I1007 23:05:11.925107  5289 sgd_solver.cpp:105] Iteration 12300, lr = 0.1
I1007 23:05:36.493093  5289 solver.cpp:218] Iteration 12400 (4.07048 iter/s, 24.5672s/100 iters), loss = 0.240009
I1007 23:05:36.493129  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.240009 (* 1 = 0.240009 loss)
I1007 23:05:36.493137  5289 sgd_solver.cpp:105] Iteration 12400, lr = 0.1
I1007 23:05:59.940347  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:06:00.923805  5289 solver.cpp:330] Iteration 12500, Testing net (#0)
I1007 23:06:05.421377  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:06:05.629010  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8165
I1007 23:06:05.629036  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.571252 (* 1 = 0.571252 loss)
I1007 23:06:05.773059  5289 solver.cpp:218] Iteration 12500 (3.41582 iter/s, 29.2755s/100 iters), loss = 0.343503
I1007 23:06:05.773092  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.343503 (* 1 = 0.343503 loss)
I1007 23:06:05.773098  5289 sgd_solver.cpp:105] Iteration 12500, lr = 0.1
I1007 23:06:30.773393  5289 solver.cpp:218] Iteration 12600 (4.00031 iter/s, 24.998s/100 iters), loss = 0.292332
I1007 23:06:30.773463  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.292332 (* 1 = 0.292332 loss)
I1007 23:06:30.773471  5289 sgd_solver.cpp:105] Iteration 12600, lr = 0.1
I1007 23:06:55.411854  5289 solver.cpp:218] Iteration 12700 (4.05872 iter/s, 24.6383s/100 iters), loss = 0.297854
I1007 23:06:55.411890  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.297853 (* 1 = 0.297853 loss)
I1007 23:06:55.411896  5289 sgd_solver.cpp:105] Iteration 12700, lr = 0.1
I1007 23:07:20.320719  5289 solver.cpp:218] Iteration 12800 (4.015 iter/s, 24.9066s/100 iters), loss = 0.293008
I1007 23:07:20.320860  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.293008 (* 1 = 0.293008 loss)
I1007 23:07:20.320873  5289 sgd_solver.cpp:105] Iteration 12800, lr = 0.1
I1007 23:07:45.043035  5289 solver.cpp:218] Iteration 12900 (4.04531 iter/s, 24.72s/100 iters), loss = 0.23565
I1007 23:07:45.043067  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.23565 (* 1 = 0.23565 loss)
I1007 23:07:45.043074  5289 sgd_solver.cpp:105] Iteration 12900, lr = 0.1
I1007 23:08:08.485666  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:08:09.469779  5289 solver.cpp:330] Iteration 13000, Testing net (#0)
I1007 23:08:14.047200  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:08:14.242079  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7996
I1007 23:08:14.242110  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.623827 (* 1 = 0.623827 loss)
I1007 23:08:14.392045  5289 solver.cpp:218] Iteration 13000 (3.40778 iter/s, 29.3446s/100 iters), loss = 0.2457
I1007 23:08:14.392078  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.2457 (* 1 = 0.2457 loss)
I1007 23:08:14.392086  5289 sgd_solver.cpp:105] Iteration 13000, lr = 0.1
I1007 23:08:39.343443  5289 solver.cpp:218] Iteration 13100 (4.00815 iter/s, 24.9491s/100 iters), loss = 0.262908
I1007 23:08:39.343510  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.262908 (* 1 = 0.262908 loss)
I1007 23:08:39.343519  5289 sgd_solver.cpp:105] Iteration 13100, lr = 0.1
I1007 23:09:03.984556  5289 solver.cpp:218] Iteration 13200 (4.05828 iter/s, 24.641s/100 iters), loss = 0.3153
I1007 23:09:03.984598  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.315299 (* 1 = 0.315299 loss)
I1007 23:09:03.984606  5289 sgd_solver.cpp:105] Iteration 13200, lr = 0.1
I1007 23:09:28.784633  5289 solver.cpp:218] Iteration 13300 (4.03261 iter/s, 24.7978s/100 iters), loss = 0.265196
I1007 23:09:28.784716  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.265196 (* 1 = 0.265196 loss)
I1007 23:09:28.784725  5289 sgd_solver.cpp:105] Iteration 13300, lr = 0.1
I1007 23:09:53.674208  5289 solver.cpp:218] Iteration 13400 (4.01812 iter/s, 24.8873s/100 iters), loss = 0.300077
I1007 23:09:53.674243  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.300077 (* 1 = 0.300077 loss)
I1007 23:09:53.674250  5289 sgd_solver.cpp:105] Iteration 13400, lr = 0.1
I1007 23:10:17.110661  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:10:18.095980  5289 solver.cpp:330] Iteration 13500, Testing net (#0)
I1007 23:10:22.707912  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:10:22.892184  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8397
I1007 23:10:22.892210  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.479395 (* 1 = 0.479395 loss)
I1007 23:10:23.069876  5289 solver.cpp:218] Iteration 13500 (3.40212 iter/s, 29.3934s/100 iters), loss = 0.28429
I1007 23:10:23.069911  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.28429 (* 1 = 0.28429 loss)
I1007 23:10:23.069917  5289 sgd_solver.cpp:105] Iteration 13500, lr = 0.1
I1007 23:10:48.122004  5289 solver.cpp:218] Iteration 13600 (3.99227 iter/s, 25.0484s/100 iters), loss = 0.330383
I1007 23:10:48.122083  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.330383 (* 1 = 0.330383 loss)
I1007 23:10:48.122092  5289 sgd_solver.cpp:105] Iteration 13600, lr = 0.1
I1007 23:11:12.836678  5289 solver.cpp:218] Iteration 13700 (4.04622 iter/s, 24.7144s/100 iters), loss = 0.357752
I1007 23:11:12.836709  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.357752 (* 1 = 0.357752 loss)
I1007 23:11:12.836715  5289 sgd_solver.cpp:105] Iteration 13700, lr = 0.1
I1007 23:11:37.588266  5289 solver.cpp:218] Iteration 13800 (4.04052 iter/s, 24.7493s/100 iters), loss = 0.337744
I1007 23:11:37.588336  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.337744 (* 1 = 0.337744 loss)
I1007 23:11:37.588345  5289 sgd_solver.cpp:105] Iteration 13800, lr = 0.1
I1007 23:12:02.511878  5289 solver.cpp:218] Iteration 13900 (4.01263 iter/s, 24.9213s/100 iters), loss = 0.317954
I1007 23:12:02.511922  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.317954 (* 1 = 0.317954 loss)
I1007 23:12:02.511931  5289 sgd_solver.cpp:105] Iteration 13900, lr = 0.1
I1007 23:12:25.912103  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:12:26.894709  5289 solver.cpp:330] Iteration 14000, Testing net (#0)
I1007 23:12:31.579820  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:12:31.751154  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8263
I1007 23:12:31.751194  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.528478 (* 1 = 0.528478 loss)
I1007 23:12:31.937134  5289 solver.cpp:218] Iteration 14000 (3.3987 iter/s, 29.423s/100 iters), loss = 0.24406
I1007 23:12:31.937176  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.24406 (* 1 = 0.24406 loss)
I1007 23:12:31.937182  5289 sgd_solver.cpp:105] Iteration 14000, lr = 0.1
I1007 23:12:57.061141  5289 solver.cpp:218] Iteration 14100 (3.98062 iter/s, 25.1217s/100 iters), loss = 0.315184
I1007 23:12:57.061219  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.315184 (* 1 = 0.315184 loss)
I1007 23:12:57.061231  5289 sgd_solver.cpp:105] Iteration 14100, lr = 0.1
I1007 23:13:21.695914  5289 solver.cpp:218] Iteration 14200 (4.05989 iter/s, 24.6312s/100 iters), loss = 0.438168
I1007 23:13:21.695951  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.438168 (* 1 = 0.438168 loss)
I1007 23:13:21.695960  5289 sgd_solver.cpp:105] Iteration 14200, lr = 0.1
I1007 23:13:46.391340  5289 solver.cpp:218] Iteration 14300 (4.04971 iter/s, 24.6931s/100 iters), loss = 0.38053
I1007 23:13:46.391418  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.38053 (* 1 = 0.38053 loss)
I1007 23:13:46.391427  5289 sgd_solver.cpp:105] Iteration 14300, lr = 0.1
I1007 23:14:11.345784  5289 solver.cpp:218] Iteration 14400 (4.00734 iter/s, 24.9542s/100 iters), loss = 0.276749
I1007 23:14:11.345819  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.276749 (* 1 = 0.276749 loss)
I1007 23:14:11.345829  5289 sgd_solver.cpp:105] Iteration 14400, lr = 0.1
I1007 23:14:34.775480  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:14:35.759407  5289 solver.cpp:330] Iteration 14500, Testing net (#0)
I1007 23:14:40.329741  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:14:40.492630  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.82
I1007 23:14:40.492657  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.531031 (* 1 = 0.531031 loss)
I1007 23:14:40.675312  5289 solver.cpp:218] Iteration 14500 (3.4098 iter/s, 29.3273s/100 iters), loss = 0.308862
I1007 23:14:40.675343  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.308862 (* 1 = 0.308862 loss)
I1007 23:14:40.675350  5289 sgd_solver.cpp:105] Iteration 14500, lr = 0.1
I1007 23:15:05.643477  5289 solver.cpp:218] Iteration 14600 (4.00547 iter/s, 24.9659s/100 iters), loss = 0.365893
I1007 23:15:05.643597  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.365893 (* 1 = 0.365893 loss)
I1007 23:15:05.643607  5289 sgd_solver.cpp:105] Iteration 14600, lr = 0.1
I1007 23:15:30.327939  5289 solver.cpp:218] Iteration 14700 (4.05151 iter/s, 24.6822s/100 iters), loss = 0.292635
I1007 23:15:30.327975  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.292635 (* 1 = 0.292635 loss)
I1007 23:15:30.327981  5289 sgd_solver.cpp:105] Iteration 14700, lr = 0.1
I1007 23:15:54.981364  5289 solver.cpp:218] Iteration 14800 (4.0566 iter/s, 24.6512s/100 iters), loss = 0.375252
I1007 23:15:54.981428  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.375252 (* 1 = 0.375252 loss)
I1007 23:15:54.981436  5289 sgd_solver.cpp:105] Iteration 14800, lr = 0.1
I1007 23:16:20.041966  5289 solver.cpp:218] Iteration 14900 (3.99069 iter/s, 25.0583s/100 iters), loss = 0.22142
I1007 23:16:20.041999  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.22142 (* 1 = 0.22142 loss)
I1007 23:16:20.042006  5289 sgd_solver.cpp:105] Iteration 14900, lr = 0.1
I1007 23:16:43.438109  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:16:44.421808  5289 solver.cpp:330] Iteration 15000, Testing net (#0)
I1007 23:16:48.976274  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:16:49.160836  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8425
I1007 23:16:49.160861  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.473577 (* 1 = 0.473577 loss)
I1007 23:16:49.316606  5289 solver.cpp:218] Iteration 15000 (3.41619 iter/s, 29.2724s/100 iters), loss = 0.243609
I1007 23:16:49.316646  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.243609 (* 1 = 0.243609 loss)
I1007 23:16:49.316653  5289 sgd_solver.cpp:105] Iteration 15000, lr = 0.1
I1007 23:17:14.420414  5289 solver.cpp:218] Iteration 15100 (3.98348 iter/s, 25.1037s/100 iters), loss = 0.305704
I1007 23:17:14.420517  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.305704 (* 1 = 0.305704 loss)
I1007 23:17:14.420536  5289 sgd_solver.cpp:105] Iteration 15100, lr = 0.1
I1007 23:17:39.110273  5289 solver.cpp:218] Iteration 15200 (4.05097 iter/s, 24.6855s/100 iters), loss = 0.322145
I1007 23:17:39.110309  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.322145 (* 1 = 0.322145 loss)
I1007 23:17:39.110325  5289 sgd_solver.cpp:105] Iteration 15200, lr = 0.1
I1007 23:18:03.772903  5289 solver.cpp:218] Iteration 15300 (4.05509 iter/s, 24.6604s/100 iters), loss = 0.355962
I1007 23:18:03.772956  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.355961 (* 1 = 0.355961 loss)
I1007 23:18:03.772974  5289 sgd_solver.cpp:105] Iteration 15300, lr = 0.1
I1007 23:18:28.837327  5289 solver.cpp:218] Iteration 15400 (3.99008 iter/s, 25.0622s/100 iters), loss = 0.218342
I1007 23:18:28.837368  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.218342 (* 1 = 0.218342 loss)
I1007 23:18:28.837375  5289 sgd_solver.cpp:105] Iteration 15400, lr = 0.1
I1007 23:18:52.271188  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:18:53.256805  5289 solver.cpp:330] Iteration 15500, Testing net (#0)
I1007 23:18:57.874809  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:18:58.061843  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8488
I1007 23:18:58.061869  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.444915 (* 1 = 0.444915 loss)
I1007 23:18:58.246713  5289 solver.cpp:218] Iteration 15500 (3.40054 iter/s, 29.4071s/100 iters), loss = 0.280921
I1007 23:18:58.246745  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.280921 (* 1 = 0.280921 loss)
I1007 23:18:58.246752  5289 sgd_solver.cpp:105] Iteration 15500, lr = 0.1
I1007 23:19:23.282547  5289 solver.cpp:218] Iteration 15600 (3.99464 iter/s, 25.0335s/100 iters), loss = 0.24028
I1007 23:19:23.282642  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.24028 (* 1 = 0.24028 loss)
I1007 23:19:23.282652  5289 sgd_solver.cpp:105] Iteration 15600, lr = 0.1
I1007 23:19:47.913504  5289 solver.cpp:218] Iteration 15700 (4.06031 iter/s, 24.6287s/100 iters), loss = 0.375499
I1007 23:19:47.913538  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.375499 (* 1 = 0.375499 loss)
I1007 23:19:47.913545  5289 sgd_solver.cpp:105] Iteration 15700, lr = 0.1
I1007 23:20:12.521666  5289 solver.cpp:218] Iteration 15800 (4.06407 iter/s, 24.6059s/100 iters), loss = 0.424951
I1007 23:20:12.521771  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.424951 (* 1 = 0.424951 loss)
I1007 23:20:12.521780  5289 sgd_solver.cpp:105] Iteration 15800, lr = 0.1
I1007 23:20:37.535357  5289 solver.cpp:218] Iteration 15900 (3.99851 iter/s, 25.0093s/100 iters), loss = 0.252126
I1007 23:20:37.535403  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.252126 (* 1 = 0.252126 loss)
I1007 23:20:37.535409  5289 sgd_solver.cpp:105] Iteration 15900, lr = 0.1
I1007 23:21:00.938910  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:21:01.922942  5289 solver.cpp:330] Iteration 16000, Testing net (#0)
I1007 23:21:06.495364  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:21:06.693862  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8344
I1007 23:21:06.693892  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.490708 (* 1 = 0.490708 loss)
I1007 23:21:06.838835  5289 solver.cpp:218] Iteration 16000 (3.41303 iter/s, 29.2995s/100 iters), loss = 0.248887
I1007 23:21:06.838868  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.248887 (* 1 = 0.248887 loss)
I1007 23:21:06.838876  5289 sgd_solver.cpp:105] Iteration 16000, lr = 0.1
I1007 23:21:31.679188  5289 solver.cpp:218] Iteration 16100 (4.02608 iter/s, 24.8381s/100 iters), loss = 0.332507
I1007 23:21:31.679271  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.332507 (* 1 = 0.332507 loss)
I1007 23:21:31.679281  5289 sgd_solver.cpp:105] Iteration 16100, lr = 0.1
I1007 23:21:56.321382  5289 solver.cpp:218] Iteration 16200 (4.05845 iter/s, 24.6399s/100 iters), loss = 0.243674
I1007 23:21:56.321415  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.243674 (* 1 = 0.243674 loss)
I1007 23:21:56.321432  5289 sgd_solver.cpp:105] Iteration 16200, lr = 0.1
I1007 23:22:20.976070  5289 solver.cpp:218] Iteration 16300 (4.0564 iter/s, 24.6524s/100 iters), loss = 0.264096
I1007 23:22:20.976156  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.264096 (* 1 = 0.264096 loss)
I1007 23:22:20.976187  5289 sgd_solver.cpp:105] Iteration 16300, lr = 0.1
I1007 23:22:46.054410  5289 solver.cpp:218] Iteration 16400 (3.98816 iter/s, 25.0742s/100 iters), loss = 0.290593
I1007 23:22:46.054443  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.290593 (* 1 = 0.290593 loss)
I1007 23:22:46.054450  5289 sgd_solver.cpp:105] Iteration 16400, lr = 0.1
I1007 23:23:09.484068  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:23:10.466125  5289 solver.cpp:330] Iteration 16500, Testing net (#0)
I1007 23:23:15.087453  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:23:15.269469  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8136
I1007 23:23:15.269500  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.559578 (* 1 = 0.559578 loss)
I1007 23:23:15.430066  5289 solver.cpp:218] Iteration 16500 (3.40444 iter/s, 29.3734s/100 iters), loss = 0.238677
I1007 23:23:15.430100  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.238677 (* 1 = 0.238677 loss)
I1007 23:23:15.430107  5289 sgd_solver.cpp:105] Iteration 16500, lr = 0.1
I1007 23:23:40.441781  5289 solver.cpp:218] Iteration 16600 (3.99849 iter/s, 25.0095s/100 iters), loss = 0.204478
I1007 23:23:40.441857  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.204478 (* 1 = 0.204478 loss)
I1007 23:23:40.441866  5289 sgd_solver.cpp:105] Iteration 16600, lr = 0.1
I1007 23:24:05.109210  5289 solver.cpp:218] Iteration 16700 (4.05464 iter/s, 24.6631s/100 iters), loss = 0.339825
I1007 23:24:05.109239  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.339825 (* 1 = 0.339825 loss)
I1007 23:24:05.109246  5289 sgd_solver.cpp:105] Iteration 16700, lr = 0.1
I1007 23:24:29.730420  5289 solver.cpp:218] Iteration 16800 (4.06191 iter/s, 24.619s/100 iters), loss = 0.315911
I1007 23:24:29.730504  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.315911 (* 1 = 0.315911 loss)
I1007 23:24:29.730514  5289 sgd_solver.cpp:105] Iteration 16800, lr = 0.1
I1007 23:24:54.798631  5289 solver.cpp:218] Iteration 16900 (3.98948 iter/s, 25.0659s/100 iters), loss = 0.192772
I1007 23:24:54.798667  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.192772 (* 1 = 0.192772 loss)
I1007 23:24:54.798674  5289 sgd_solver.cpp:105] Iteration 16900, lr = 0.1
I1007 23:25:18.212572  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:25:19.195847  5289 solver.cpp:330] Iteration 17000, Testing net (#0)
I1007 23:25:23.748401  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:25:23.941328  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8274
I1007 23:25:23.941354  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.524487 (* 1 = 0.524487 loss)
I1007 23:25:24.091578  5289 solver.cpp:218] Iteration 17000 (3.41405 iter/s, 29.2907s/100 iters), loss = 0.207113
I1007 23:25:24.091608  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.207113 (* 1 = 0.207113 loss)
I1007 23:25:24.091614  5289 sgd_solver.cpp:105] Iteration 17000, lr = 0.1
I1007 23:25:49.080349  5289 solver.cpp:218] Iteration 17100 (4.00182 iter/s, 24.9886s/100 iters), loss = 0.27587
I1007 23:25:49.080427  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.27587 (* 1 = 0.27587 loss)
I1007 23:25:49.080436  5289 sgd_solver.cpp:105] Iteration 17100, lr = 0.1
I1007 23:26:13.777209  5289 solver.cpp:218] Iteration 17200 (4.04947 iter/s, 24.6946s/100 iters), loss = 0.313424
I1007 23:26:13.777254  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.313424 (* 1 = 0.313424 loss)
I1007 23:26:13.777261  5289 sgd_solver.cpp:105] Iteration 17200, lr = 0.1
I1007 23:26:38.411572  5289 solver.cpp:218] Iteration 17300 (4.05974 iter/s, 24.6321s/100 iters), loss = 0.255605
I1007 23:26:38.411695  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.255605 (* 1 = 0.255605 loss)
I1007 23:26:38.411716  5289 sgd_solver.cpp:105] Iteration 17300, lr = 0.1
I1007 23:27:03.484233  5289 solver.cpp:218] Iteration 17400 (3.98877 iter/s, 25.0704s/100 iters), loss = 0.247529
I1007 23:27:03.484272  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.247529 (* 1 = 0.247529 loss)
I1007 23:27:03.484279  5289 sgd_solver.cpp:105] Iteration 17400, lr = 0.1
I1007 23:27:26.894484  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:27:27.876004  5289 solver.cpp:330] Iteration 17500, Testing net (#0)
I1007 23:27:32.454426  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:27:32.643980  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8227
I1007 23:27:32.644007  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.557973 (* 1 = 0.557973 loss)
I1007 23:27:32.797432  5289 solver.cpp:218] Iteration 17500 (3.4117 iter/s, 29.3109s/100 iters), loss = 0.311765
I1007 23:27:32.797475  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.311765 (* 1 = 0.311765 loss)
I1007 23:27:32.797483  5289 sgd_solver.cpp:105] Iteration 17500, lr = 0.1
I1007 23:27:57.742405  5289 solver.cpp:218] Iteration 17600 (4.00918 iter/s, 24.9427s/100 iters), loss = 0.239215
I1007 23:27:57.742489  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.239215 (* 1 = 0.239215 loss)
I1007 23:27:57.742497  5289 sgd_solver.cpp:105] Iteration 17600, lr = 0.1
I1007 23:28:22.372293  5289 solver.cpp:218] Iteration 17700 (4.06065 iter/s, 24.6266s/100 iters), loss = 0.287015
I1007 23:28:22.372328  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.287015 (* 1 = 0.287015 loss)
I1007 23:28:22.372344  5289 sgd_solver.cpp:105] Iteration 17700, lr = 0.1
I1007 23:28:47.004168  5289 solver.cpp:218] Iteration 17800 (4.0605 iter/s, 24.6275s/100 iters), loss = 0.361316
I1007 23:28:47.004243  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.361316 (* 1 = 0.361316 loss)
I1007 23:28:47.004256  5289 sgd_solver.cpp:105] Iteration 17800, lr = 0.1
I1007 23:29:12.069427  5289 solver.cpp:218] Iteration 17900 (3.98995 iter/s, 25.063s/100 iters), loss = 0.209357
I1007 23:29:12.069460  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.209357 (* 1 = 0.209357 loss)
I1007 23:29:12.069468  5289 sgd_solver.cpp:105] Iteration 17900, lr = 0.1
I1007 23:29:35.497361  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:29:36.482272  5289 solver.cpp:330] Iteration 18000, Testing net (#0)
I1007 23:29:41.057512  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:29:41.260181  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8481
I1007 23:29:41.260208  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.457989 (* 1 = 0.457989 loss)
I1007 23:29:41.403760  5289 solver.cpp:218] Iteration 18000 (3.40949 iter/s, 29.3299s/100 iters), loss = 0.211682
I1007 23:29:41.403790  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.211682 (* 1 = 0.211682 loss)
I1007 23:29:41.403797  5289 sgd_solver.cpp:105] Iteration 18000, lr = 0.1
I1007 23:30:06.370460  5289 solver.cpp:218] Iteration 18100 (4.0057 iter/s, 24.9645s/100 iters), loss = 0.323178
I1007 23:30:06.370558  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.323178 (* 1 = 0.323178 loss)
I1007 23:30:06.370576  5289 sgd_solver.cpp:105] Iteration 18100, lr = 0.1
I1007 23:30:31.008533  5289 solver.cpp:218] Iteration 18200 (4.0588 iter/s, 24.6378s/100 iters), loss = 0.251865
I1007 23:30:31.008564  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.251865 (* 1 = 0.251865 loss)
I1007 23:30:31.008570  5289 sgd_solver.cpp:105] Iteration 18200, lr = 0.1
I1007 23:30:55.681932  5289 solver.cpp:218] Iteration 18300 (4.0535 iter/s, 24.67s/100 iters), loss = 0.238823
I1007 23:30:55.682009  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.238823 (* 1 = 0.238823 loss)
I1007 23:30:55.682018  5289 sgd_solver.cpp:105] Iteration 18300, lr = 0.1
I1007 23:31:20.756199  5289 solver.cpp:218] Iteration 18400 (3.98852 iter/s, 25.072s/100 iters), loss = 0.189079
I1007 23:31:20.756237  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.189079 (* 1 = 0.189079 loss)
I1007 23:31:20.756256  5289 sgd_solver.cpp:105] Iteration 18400, lr = 0.1
I1007 23:31:44.174322  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:31:45.156347  5289 solver.cpp:330] Iteration 18500, Testing net (#0)
I1007 23:31:49.787955  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:31:49.951515  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7788
I1007 23:31:49.951540  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.687208 (* 1 = 0.687208 loss)
I1007 23:31:50.160409  5289 solver.cpp:218] Iteration 18500 (3.40113 iter/s, 29.402s/100 iters), loss = 0.299491
I1007 23:31:50.160442  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.299491 (* 1 = 0.299491 loss)
I1007 23:31:50.160465  5289 sgd_solver.cpp:105] Iteration 18500, lr = 0.1
I1007 23:32:15.285086  5289 solver.cpp:218] Iteration 18600 (3.98075 iter/s, 25.1209s/100 iters), loss = 0.219277
I1007 23:32:15.285156  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.219277 (* 1 = 0.219277 loss)
I1007 23:32:15.285164  5289 sgd_solver.cpp:105] Iteration 18600, lr = 0.1
I1007 23:32:39.918545  5289 solver.cpp:218] Iteration 18700 (4.0599 iter/s, 24.6312s/100 iters), loss = 0.310805
I1007 23:32:39.918603  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.310806 (* 1 = 0.310806 loss)
I1007 23:32:39.918614  5289 sgd_solver.cpp:105] Iteration 18700, lr = 0.1
I1007 23:33:04.581689  5289 solver.cpp:218] Iteration 18800 (4.055 iter/s, 24.6609s/100 iters), loss = 0.228384
I1007 23:33:04.581773  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.228385 (* 1 = 0.228385 loss)
I1007 23:33:04.581782  5289 sgd_solver.cpp:105] Iteration 18800, lr = 0.1
I1007 23:33:29.668426  5289 solver.cpp:218] Iteration 18900 (3.98653 iter/s, 25.0845s/100 iters), loss = 0.215338
I1007 23:33:29.668470  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.215338 (* 1 = 0.215338 loss)
I1007 23:33:29.668478  5289 sgd_solver.cpp:105] Iteration 18900, lr = 0.1
I1007 23:33:53.120404  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:33:54.105945  5289 solver.cpp:330] Iteration 19000, Testing net (#0)
I1007 23:33:58.786012  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:33:58.932406  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8292
I1007 23:33:58.932443  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.50125 (* 1 = 0.50125 loss)
I1007 23:33:59.142704  5289 solver.cpp:218] Iteration 19000 (3.39305 iter/s, 29.472s/100 iters), loss = 0.264074
I1007 23:33:59.142735  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.264074 (* 1 = 0.264074 loss)
I1007 23:33:59.142741  5289 sgd_solver.cpp:105] Iteration 19000, lr = 0.1
I1007 23:34:24.222528  5289 solver.cpp:218] Iteration 19100 (3.98763 iter/s, 25.0775s/100 iters), loss = 0.264131
I1007 23:34:24.222628  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.264131 (* 1 = 0.264131 loss)
I1007 23:34:24.222636  5289 sgd_solver.cpp:105] Iteration 19100, lr = 0.1
I1007 23:34:48.891623  5289 solver.cpp:218] Iteration 19200 (4.05403 iter/s, 24.6668s/100 iters), loss = 0.350702
I1007 23:34:48.891655  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.350702 (* 1 = 0.350702 loss)
I1007 23:34:48.891662  5289 sgd_solver.cpp:105] Iteration 19200, lr = 0.1
I1007 23:35:13.547648  5289 solver.cpp:218] Iteration 19300 (4.05618 iter/s, 24.6537s/100 iters), loss = 0.243946
I1007 23:35:13.547756  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.243946 (* 1 = 0.243946 loss)
I1007 23:35:13.547765  5289 sgd_solver.cpp:105] Iteration 19300, lr = 0.1
I1007 23:35:38.628731  5289 solver.cpp:218] Iteration 19400 (3.98743 iter/s, 25.0788s/100 iters), loss = 0.206607
I1007 23:35:38.628763  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.206608 (* 1 = 0.206608 loss)
I1007 23:35:38.628769  5289 sgd_solver.cpp:105] Iteration 19400, lr = 0.1
I1007 23:36:02.050019  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:36:03.031198  5289 solver.cpp:330] Iteration 19500, Testing net (#0)
I1007 23:36:07.703212  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:36:07.892601  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7791
I1007 23:36:07.892637  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.718896 (* 1 = 0.718896 loss)
I1007 23:36:08.056488  5289 solver.cpp:218] Iteration 19500 (3.39842 iter/s, 29.4255s/100 iters), loss = 0.262783
I1007 23:36:08.056517  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.262783 (* 1 = 0.262783 loss)
I1007 23:36:08.056524  5289 sgd_solver.cpp:105] Iteration 19500, lr = 0.1
I1007 23:36:33.115619  5289 solver.cpp:218] Iteration 19600 (3.99093 iter/s, 25.0568s/100 iters), loss = 0.275683
I1007 23:36:33.115725  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.275684 (* 1 = 0.275684 loss)
I1007 23:36:33.115733  5289 sgd_solver.cpp:105] Iteration 19600, lr = 0.1
I1007 23:36:57.766016  5289 solver.cpp:218] Iteration 19700 (4.0571 iter/s, 24.6481s/100 iters), loss = 0.360716
I1007 23:36:57.766048  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.360716 (* 1 = 0.360716 loss)
I1007 23:36:57.766054  5289 sgd_solver.cpp:105] Iteration 19700, lr = 0.1
I1007 23:37:22.385903  5289 solver.cpp:218] Iteration 19800 (4.06234 iter/s, 24.6164s/100 iters), loss = 0.263369
I1007 23:37:22.385996  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.263369 (* 1 = 0.263369 loss)
I1007 23:37:22.386014  5289 sgd_solver.cpp:105] Iteration 19800, lr = 0.1
I1007 23:37:47.449578  5289 solver.cpp:218] Iteration 19900 (3.9902 iter/s, 25.0614s/100 iters), loss = 0.187282
I1007 23:37:47.449615  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.187282 (* 1 = 0.187282 loss)
I1007 23:37:47.449623  5289 sgd_solver.cpp:105] Iteration 19900, lr = 0.1
I1007 23:38:10.868280  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:38:11.850378  5289 solver.cpp:330] Iteration 20000, Testing net (#0)
I1007 23:38:16.539587  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:38:16.673251  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.828
I1007 23:38:16.673280  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.529333 (* 1 = 0.529333 loss)
I1007 23:38:16.892989  5289 solver.cpp:218] Iteration 20000 (3.39661 iter/s, 29.4411s/100 iters), loss = 0.33469
I1007 23:38:16.893024  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.33469 (* 1 = 0.33469 loss)
I1007 23:38:16.893034  5289 sgd_solver.cpp:105] Iteration 20000, lr = 0.1
I1007 23:38:41.979725  5289 solver.cpp:218] Iteration 20100 (3.98619 iter/s, 25.0866s/100 iters), loss = 0.23177
I1007 23:38:41.979822  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.23177 (* 1 = 0.23177 loss)
I1007 23:38:41.979835  5289 sgd_solver.cpp:105] Iteration 20100, lr = 0.1
I1007 23:39:06.591802  5289 solver.cpp:218] Iteration 20200 (4.06308 iter/s, 24.6119s/100 iters), loss = 0.271375
I1007 23:39:06.591835  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.271375 (* 1 = 0.271375 loss)
I1007 23:39:06.591855  5289 sgd_solver.cpp:105] Iteration 20200, lr = 0.1
I1007 23:39:31.237211  5289 solver.cpp:218] Iteration 20300 (4.05792 iter/s, 24.6431s/100 iters), loss = 0.289492
I1007 23:39:31.237300  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.289492 (* 1 = 0.289492 loss)
I1007 23:39:31.237314  5289 sgd_solver.cpp:105] Iteration 20300, lr = 0.1
I1007 23:39:56.308586  5289 solver.cpp:218] Iteration 20400 (3.98897 iter/s, 25.0691s/100 iters), loss = 0.2123
I1007 23:39:56.308622  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.2123 (* 1 = 0.2123 loss)
I1007 23:39:56.308630  5289 sgd_solver.cpp:105] Iteration 20400, lr = 0.1
I1007 23:40:19.772951  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:40:20.761582  5289 solver.cpp:330] Iteration 20500, Testing net (#0)
I1007 23:40:25.339701  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:40:25.542291  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8137
I1007 23:40:25.542317  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.54154 (* 1 = 0.54154 loss)
I1007 23:40:25.687449  5289 solver.cpp:218] Iteration 20500 (3.40422 iter/s, 29.3753s/100 iters), loss = 0.317818
I1007 23:40:25.687481  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.317818 (* 1 = 0.317818 loss)
I1007 23:40:25.687489  5289 sgd_solver.cpp:105] Iteration 20500, lr = 0.1
I1007 23:40:50.872947  5289 solver.cpp:218] Iteration 20600 (3.97089 iter/s, 25.1832s/100 iters), loss = 0.306457
I1007 23:40:50.873039  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.306457 (* 1 = 0.306457 loss)
I1007 23:40:50.873049  5289 sgd_solver.cpp:105] Iteration 20600, lr = 0.1
I1007 23:41:15.529839  5289 solver.cpp:218] Iteration 20700 (4.05603 iter/s, 24.6546s/100 iters), loss = 0.244391
I1007 23:41:15.529880  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.244392 (* 1 = 0.244392 loss)
I1007 23:41:15.529886  5289 sgd_solver.cpp:105] Iteration 20700, lr = 0.1
I1007 23:41:40.188501  5289 solver.cpp:218] Iteration 20800 (4.05574 iter/s, 24.6564s/100 iters), loss = 0.349028
I1007 23:41:40.188597  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.349028 (* 1 = 0.349028 loss)
I1007 23:41:40.188619  5289 sgd_solver.cpp:105] Iteration 20800, lr = 0.1
I1007 23:42:05.284672  5289 solver.cpp:218] Iteration 20900 (3.98503 iter/s, 25.0939s/100 iters), loss = 0.208829
I1007 23:42:05.284713  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.208829 (* 1 = 0.208829 loss)
I1007 23:42:05.284732  5289 sgd_solver.cpp:105] Iteration 20900, lr = 0.1
I1007 23:42:28.718883  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:42:29.703930  5289 solver.cpp:330] Iteration 21000, Testing net (#0)
I1007 23:42:34.260768  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:42:34.453809  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.853
I1007 23:42:34.453840  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.430307 (* 1 = 0.430307 loss)
I1007 23:42:34.603615  5289 solver.cpp:218] Iteration 21000 (3.41114 iter/s, 29.3157s/100 iters), loss = 0.230045
I1007 23:42:34.603651  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.230046 (* 1 = 0.230046 loss)
I1007 23:42:34.603662  5289 sgd_solver.cpp:105] Iteration 21000, lr = 0.1
I1007 23:42:59.643971  5289 solver.cpp:218] Iteration 21100 (3.99358 iter/s, 25.0402s/100 iters), loss = 0.250798
I1007 23:42:59.644074  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.250798 (* 1 = 0.250798 loss)
I1007 23:42:59.644086  5289 sgd_solver.cpp:105] Iteration 21100, lr = 0.1
I1007 23:43:24.302171  5289 solver.cpp:218] Iteration 21200 (4.05582 iter/s, 24.6559s/100 iters), loss = 0.259034
I1007 23:43:24.302213  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.259034 (* 1 = 0.259034 loss)
I1007 23:43:24.302233  5289 sgd_solver.cpp:105] Iteration 21200, lr = 0.1
I1007 23:43:48.937691  5289 solver.cpp:218] Iteration 21300 (4.05955 iter/s, 24.6333s/100 iters), loss = 0.265099
I1007 23:43:48.937778  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.265099 (* 1 = 0.265099 loss)
I1007 23:43:48.937790  5289 sgd_solver.cpp:105] Iteration 21300, lr = 0.1
I1007 23:44:13.929747  5289 solver.cpp:218] Iteration 21400 (4.00163 iter/s, 24.9898s/100 iters), loss = 0.19634
I1007 23:44:13.929781  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.196341 (* 1 = 0.196341 loss)
I1007 23:44:13.929790  5289 sgd_solver.cpp:105] Iteration 21400, lr = 0.1
I1007 23:44:37.348248  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:44:38.332831  5289 solver.cpp:330] Iteration 21500, Testing net (#0)
I1007 23:44:42.949506  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:44:43.138622  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.844
I1007 23:44:43.138651  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.477194 (* 1 = 0.477194 loss)
I1007 23:44:43.324041  5289 solver.cpp:218] Iteration 21500 (3.40228 iter/s, 29.392s/100 iters), loss = 0.242814
I1007 23:44:43.324076  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.242814 (* 1 = 0.242814 loss)
I1007 23:44:43.324095  5289 sgd_solver.cpp:105] Iteration 21500, lr = 0.1
I1007 23:45:08.378444  5289 solver.cpp:218] Iteration 21600 (3.99168 iter/s, 25.0521s/100 iters), loss = 0.219084
I1007 23:45:08.378540  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.219084 (* 1 = 0.219084 loss)
I1007 23:45:08.378563  5289 sgd_solver.cpp:105] Iteration 21600, lr = 0.1
I1007 23:45:32.931167  5289 solver.cpp:218] Iteration 21700 (4.07349 iter/s, 24.549s/100 iters), loss = 0.358796
I1007 23:45:32.931201  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.358796 (* 1 = 0.358796 loss)
I1007 23:45:32.931221  5289 sgd_solver.cpp:105] Iteration 21700, lr = 0.1
I1007 23:45:57.613720  5289 solver.cpp:218] Iteration 21800 (4.05216 iter/s, 24.6782s/100 iters), loss = 0.281414
I1007 23:45:57.613798  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.281414 (* 1 = 0.281414 loss)
I1007 23:45:57.613806  5289 sgd_solver.cpp:105] Iteration 21800, lr = 0.1
I1007 23:46:22.615631  5289 solver.cpp:218] Iteration 21900 (4.00005 iter/s, 24.9997s/100 iters), loss = 0.167634
I1007 23:46:22.615665  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.167634 (* 1 = 0.167634 loss)
I1007 23:46:22.615674  5289 sgd_solver.cpp:105] Iteration 21900, lr = 0.1
I1007 23:46:46.081679  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:46:47.063417  5289 solver.cpp:330] Iteration 22000, Testing net (#0)
I1007 23:46:51.644434  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:46:51.816161  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8152
I1007 23:46:51.816190  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.56399 (* 1 = 0.56399 loss)
I1007 23:46:51.997172  5289 solver.cpp:218] Iteration 22000 (3.40376 iter/s, 29.3793s/100 iters), loss = 0.268801
I1007 23:46:51.997201  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.268802 (* 1 = 0.268802 loss)
I1007 23:46:51.997208  5289 sgd_solver.cpp:105] Iteration 22000, lr = 0.1
I1007 23:47:16.989246  5289 solver.cpp:218] Iteration 22100 (4.00163 iter/s, 24.9898s/100 iters), loss = 0.173498
I1007 23:47:16.989352  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.173498 (* 1 = 0.173498 loss)
I1007 23:47:16.989361  5289 sgd_solver.cpp:105] Iteration 22100, lr = 0.1
I1007 23:47:41.640233  5289 solver.cpp:218] Iteration 22200 (4.05723 iter/s, 24.6473s/100 iters), loss = 0.273634
I1007 23:47:41.640264  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.273634 (* 1 = 0.273634 loss)
I1007 23:47:41.640270  5289 sgd_solver.cpp:105] Iteration 22200, lr = 0.1
I1007 23:48:06.272626  5289 solver.cpp:218] Iteration 22300 (4.06007 iter/s, 24.6301s/100 iters), loss = 0.299909
I1007 23:48:06.272716  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.299909 (* 1 = 0.299909 loss)
I1007 23:48:06.272725  5289 sgd_solver.cpp:105] Iteration 22300, lr = 0.1
I1007 23:48:31.263741  5289 solver.cpp:218] Iteration 22400 (4.00178 iter/s, 24.9889s/100 iters), loss = 0.214795
I1007 23:48:31.263787  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.214795 (* 1 = 0.214795 loss)
I1007 23:48:31.263793  5289 sgd_solver.cpp:105] Iteration 22400, lr = 0.1
I1007 23:48:54.690881  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:48:55.674996  5289 solver.cpp:330] Iteration 22500, Testing net (#0)
I1007 23:49:00.205286  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:49:00.390290  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8391
I1007 23:49:00.390316  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.485679 (* 1 = 0.485679 loss)
I1007 23:49:00.554170  5289 solver.cpp:218] Iteration 22500 (3.41435 iter/s, 29.2882s/100 iters), loss = 0.163039
I1007 23:49:00.554203  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.16304 (* 1 = 0.16304 loss)
I1007 23:49:00.554209  5289 sgd_solver.cpp:105] Iteration 22500, lr = 0.1
I1007 23:49:25.703599  5289 solver.cpp:218] Iteration 22600 (3.97659 iter/s, 25.1472s/100 iters), loss = 0.327416
I1007 23:49:25.703688  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.327416 (* 1 = 0.327416 loss)
I1007 23:49:25.703696  5289 sgd_solver.cpp:105] Iteration 22600, lr = 0.1
I1007 23:49:50.357012  5289 solver.cpp:218] Iteration 22700 (4.05661 iter/s, 24.6511s/100 iters), loss = 0.294666
I1007 23:49:50.357050  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.294666 (* 1 = 0.294666 loss)
I1007 23:49:50.357060  5289 sgd_solver.cpp:105] Iteration 22700, lr = 0.1
I1007 23:50:15.021708  5289 solver.cpp:218] Iteration 22800 (4.05475 iter/s, 24.6624s/100 iters), loss = 0.269984
I1007 23:50:15.021821  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.269984 (* 1 = 0.269984 loss)
I1007 23:50:15.021833  5289 sgd_solver.cpp:105] Iteration 22800, lr = 0.1
I1007 23:50:39.987972  5289 solver.cpp:218] Iteration 22900 (4.00577 iter/s, 24.964s/100 iters), loss = 0.209134
I1007 23:50:39.988003  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.209134 (* 1 = 0.209134 loss)
I1007 23:50:39.988009  5289 sgd_solver.cpp:105] Iteration 22900, lr = 0.1
I1007 23:51:03.450143  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:51:04.432313  5289 solver.cpp:330] Iteration 23000, Testing net (#0)
I1007 23:51:08.984954  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:51:09.169522  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8361
I1007 23:51:09.169549  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.498891 (* 1 = 0.498891 loss)
I1007 23:51:09.323204  5289 solver.cpp:218] Iteration 23000 (3.40938 iter/s, 29.3308s/100 iters), loss = 0.181094
I1007 23:51:09.323246  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.181094 (* 1 = 0.181094 loss)
I1007 23:51:09.323252  5289 sgd_solver.cpp:105] Iteration 23000, lr = 0.1
I1007 23:51:34.339061  5289 solver.cpp:218] Iteration 23100 (3.99749 iter/s, 25.0157s/100 iters), loss = 0.249915
I1007 23:51:34.339157  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.249916 (* 1 = 0.249916 loss)
I1007 23:51:34.339170  5289 sgd_solver.cpp:105] Iteration 23100, lr = 0.1
I1007 23:51:59.010541  5289 solver.cpp:218] Iteration 23200 (4.05364 iter/s, 24.6692s/100 iters), loss = 0.340882
I1007 23:51:59.010584  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.340882 (* 1 = 0.340882 loss)
I1007 23:51:59.010591  5289 sgd_solver.cpp:105] Iteration 23200, lr = 0.1
I1007 23:52:23.703749  5289 solver.cpp:218] Iteration 23300 (4.05041 iter/s, 24.6889s/100 iters), loss = 0.349966
I1007 23:52:23.703851  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.349966 (* 1 = 0.349966 loss)
I1007 23:52:23.703860  5289 sgd_solver.cpp:105] Iteration 23300, lr = 0.1
I1007 23:52:48.784395  5289 solver.cpp:218] Iteration 23400 (3.9875 iter/s, 25.0784s/100 iters), loss = 0.256132
I1007 23:52:48.784433  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.256132 (* 1 = 0.256132 loss)
I1007 23:52:48.784445  5289 sgd_solver.cpp:105] Iteration 23400, lr = 0.1
I1007 23:53:12.192246  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:53:13.177681  5289 solver.cpp:330] Iteration 23500, Testing net (#0)
I1007 23:53:17.838119  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:53:18.000236  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8341
I1007 23:53:18.000262  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.504406 (* 1 = 0.504406 loss)
I1007 23:53:18.186187  5289 solver.cpp:218] Iteration 23500 (3.40142 iter/s, 29.3995s/100 iters), loss = 0.220546
I1007 23:53:18.186218  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.220546 (* 1 = 0.220546 loss)
I1007 23:53:18.186226  5289 sgd_solver.cpp:105] Iteration 23500, lr = 0.1
I1007 23:53:43.227531  5289 solver.cpp:218] Iteration 23600 (3.99376 iter/s, 25.039s/100 iters), loss = 0.225559
I1007 23:53:43.227599  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.225559 (* 1 = 0.225559 loss)
I1007 23:53:43.227607  5289 sgd_solver.cpp:105] Iteration 23600, lr = 0.1
I1007 23:54:07.854807  5289 solver.cpp:218] Iteration 23700 (4.06091 iter/s, 24.625s/100 iters), loss = 0.209477
I1007 23:54:07.854845  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.209477 (* 1 = 0.209477 loss)
I1007 23:54:07.854851  5289 sgd_solver.cpp:105] Iteration 23700, lr = 0.1
I1007 23:54:32.472209  5289 solver.cpp:218] Iteration 23800 (4.06254 iter/s, 24.6151s/100 iters), loss = 0.281781
I1007 23:54:32.472291  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.281781 (* 1 = 0.281781 loss)
I1007 23:54:32.472298  5289 sgd_solver.cpp:105] Iteration 23800, lr = 0.1
I1007 23:54:57.443015  5289 solver.cpp:218] Iteration 23900 (4.00504 iter/s, 24.9686s/100 iters), loss = 0.154635
I1007 23:54:57.443048  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.154635 (* 1 = 0.154635 loss)
I1007 23:54:57.443055  5289 sgd_solver.cpp:105] Iteration 23900, lr = 0.1
I1007 23:55:20.832216  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:55:21.816573  5289 solver.cpp:330] Iteration 24000, Testing net (#0)
I1007 23:55:26.485312  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:55:26.696640  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8569
I1007 23:55:26.696666  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.419611 (* 1 = 0.419611 loss)
I1007 23:55:26.851768  5289 solver.cpp:218] Iteration 24000 (3.40037 iter/s, 29.4086s/100 iters), loss = 0.206667
I1007 23:55:26.851802  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.206668 (* 1 = 0.206668 loss)
I1007 23:55:26.851809  5289 sgd_solver.cpp:105] Iteration 24000, lr = 0.1
I1007 23:55:51.994541  5289 solver.cpp:218] Iteration 24100 (3.97797 iter/s, 25.1384s/100 iters), loss = 0.260863
I1007 23:55:51.994652  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.260863 (* 1 = 0.260863 loss)
I1007 23:55:51.994659  5289 sgd_solver.cpp:105] Iteration 24100, lr = 0.1
I1007 23:56:16.610245  5289 solver.cpp:218] Iteration 24200 (4.06282 iter/s, 24.6135s/100 iters), loss = 0.238864
I1007 23:56:16.610276  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.238864 (* 1 = 0.238864 loss)
I1007 23:56:16.610283  5289 sgd_solver.cpp:105] Iteration 24200, lr = 0.1
I1007 23:56:41.230217  5289 solver.cpp:218] Iteration 24300 (4.06212 iter/s, 24.6177s/100 iters), loss = 0.362549
I1007 23:56:41.230293  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.362549 (* 1 = 0.362549 loss)
I1007 23:56:41.230300  5289 sgd_solver.cpp:105] Iteration 24300, lr = 0.1
I1007 23:57:06.290607  5289 solver.cpp:218] Iteration 24400 (3.99073 iter/s, 25.0581s/100 iters), loss = 0.10135
I1007 23:57:06.290645  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.10135 (* 1 = 0.10135 loss)
I1007 23:57:06.290652  5289 sgd_solver.cpp:105] Iteration 24400, lr = 0.1
I1007 23:57:29.729177  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:57:30.714550  5289 solver.cpp:330] Iteration 24500, Testing net (#0)
I1007 23:57:35.249430  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:57:35.438051  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8435
I1007 23:57:35.438079  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.475621 (* 1 = 0.475621 loss)
I1007 23:57:35.592257  5289 solver.cpp:218] Iteration 24500 (3.41325 iter/s, 29.2976s/100 iters), loss = 0.317838
I1007 23:57:35.592288  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.317838 (* 1 = 0.317838 loss)
I1007 23:57:35.592295  5289 sgd_solver.cpp:105] Iteration 24500, lr = 0.1
I1007 23:58:00.543781  5289 solver.cpp:218] Iteration 24600 (4.00814 iter/s, 24.9492s/100 iters), loss = 0.217306
I1007 23:58:00.543857  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.217306 (* 1 = 0.217306 loss)
I1007 23:58:00.543865  5289 sgd_solver.cpp:105] Iteration 24600, lr = 0.1
I1007 23:58:25.200562  5289 solver.cpp:218] Iteration 24700 (4.05605 iter/s, 24.6545s/100 iters), loss = 0.193016
I1007 23:58:25.200598  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.193017 (* 1 = 0.193017 loss)
I1007 23:58:25.200605  5289 sgd_solver.cpp:105] Iteration 24700, lr = 0.1
I1007 23:58:49.822895  5289 solver.cpp:218] Iteration 24800 (4.06208 iter/s, 24.6179s/100 iters), loss = 0.256719
I1007 23:58:49.822993  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.256719 (* 1 = 0.256719 loss)
I1007 23:58:49.823002  5289 sgd_solver.cpp:105] Iteration 24800, lr = 0.1
I1007 23:59:14.692055  5289 solver.cpp:218] Iteration 24900 (4.02141 iter/s, 24.8669s/100 iters), loss = 0.291017
I1007 23:59:14.692087  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.291017 (* 1 = 0.291017 loss)
I1007 23:59:14.692095  5289 sgd_solver.cpp:105] Iteration 24900, lr = 0.1
I1007 23:59:38.139221  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:59:39.125685  5289 solver.cpp:330] Iteration 25000, Testing net (#0)
I1007 23:59:43.644937  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:59:43.836182  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8164
I1007 23:59:43.836217  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.551881 (* 1 = 0.551881 loss)
I1007 23:59:44.002193  5289 solver.cpp:218] Iteration 25000 (3.412 iter/s, 29.3083s/100 iters), loss = 0.256525
I1007 23:59:44.002226  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.256525 (* 1 = 0.256525 loss)
I1007 23:59:44.002233  5289 sgd_solver.cpp:105] Iteration 25000, lr = 0.1
I1008 00:00:08.997139  5289 solver.cpp:218] Iteration 25100 (4.00118 iter/s, 24.9926s/100 iters), loss = 0.181014
I1008 00:00:08.997226  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.181014 (* 1 = 0.181014 loss)
I1008 00:00:08.997239  5289 sgd_solver.cpp:105] Iteration 25100, lr = 0.1
I1008 00:00:33.630233  5289 solver.cpp:218] Iteration 25200 (4.05995 iter/s, 24.6308s/100 iters), loss = 0.239171
I1008 00:00:33.630265  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.239171 (* 1 = 0.239171 loss)
I1008 00:00:33.630273  5289 sgd_solver.cpp:105] Iteration 25200, lr = 0.1
I1008 00:00:58.266501  5289 solver.cpp:218] Iteration 25300 (4.05943 iter/s, 24.634s/100 iters), loss = 0.23818
I1008 00:00:58.266611  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.23818 (* 1 = 0.23818 loss)
I1008 00:00:58.266620  5289 sgd_solver.cpp:105] Iteration 25300, lr = 0.1
I1008 00:01:23.228655  5289 solver.cpp:218] Iteration 25400 (4.00677 iter/s, 24.9577s/100 iters), loss = 0.150425
I1008 00:01:23.228699  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.150425 (* 1 = 0.150425 loss)
I1008 00:01:23.228706  5289 sgd_solver.cpp:105] Iteration 25400, lr = 0.1
I1008 00:01:46.700129  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:01:47.683985  5289 solver.cpp:330] Iteration 25500, Testing net (#0)
I1008 00:01:52.350463  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:01:52.522058  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8416
I1008 00:01:52.522094  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.467818 (* 1 = 0.467818 loss)
I1008 00:01:52.708901  5289 solver.cpp:218] Iteration 25500 (3.39261 iter/s, 29.4758s/100 iters), loss = 0.240798
I1008 00:01:52.708943  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.240798 (* 1 = 0.240798 loss)
I1008 00:01:52.708950  5289 sgd_solver.cpp:105] Iteration 25500, lr = 0.1
I1008 00:02:17.715991  5289 solver.cpp:218] Iteration 25600 (3.99923 iter/s, 25.0048s/100 iters), loss = 0.241096
I1008 00:02:17.716076  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.241096 (* 1 = 0.241096 loss)
I1008 00:02:17.716087  5289 sgd_solver.cpp:105] Iteration 25600, lr = 0.1
I1008 00:02:42.283569  5289 solver.cpp:218] Iteration 25700 (4.07078 iter/s, 24.5653s/100 iters), loss = 0.327224
I1008 00:02:42.283609  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.327224 (* 1 = 0.327224 loss)
I1008 00:02:42.283619  5289 sgd_solver.cpp:105] Iteration 25700, lr = 0.1
I1008 00:03:06.923426  5289 solver.cpp:218] Iteration 25800 (4.05884 iter/s, 24.6376s/100 iters), loss = 0.260717
I1008 00:03:06.923504  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.260718 (* 1 = 0.260718 loss)
I1008 00:03:06.923512  5289 sgd_solver.cpp:105] Iteration 25800, lr = 0.1
I1008 00:03:31.880722  5289 solver.cpp:218] Iteration 25900 (4.00721 iter/s, 24.955s/100 iters), loss = 0.178963
I1008 00:03:31.880755  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.178963 (* 1 = 0.178963 loss)
I1008 00:03:31.880762  5289 sgd_solver.cpp:105] Iteration 25900, lr = 0.1
I1008 00:03:55.457767  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:03:56.438802  5289 solver.cpp:330] Iteration 26000, Testing net (#0)
I1008 00:04:01.123981  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:04:01.265944  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8459
I1008 00:04:01.265970  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.458538 (* 1 = 0.458538 loss)
I1008 00:04:01.480212  5289 solver.cpp:218] Iteration 26000 (3.37869 iter/s, 29.5972s/100 iters), loss = 0.173763
I1008 00:04:01.480242  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.173763 (* 1 = 0.173763 loss)
I1008 00:04:01.480248  5289 sgd_solver.cpp:105] Iteration 26000, lr = 0.1
I1008 00:04:26.540760  5289 solver.cpp:218] Iteration 26100 (3.9907 iter/s, 25.0583s/100 iters), loss = 0.277678
I1008 00:04:26.540837  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.277678 (* 1 = 0.277678 loss)
I1008 00:04:26.540844  5289 sgd_solver.cpp:105] Iteration 26100, lr = 0.1
I1008 00:04:51.189286  5289 solver.cpp:218] Iteration 26200 (4.05741 iter/s, 24.6463s/100 iters), loss = 0.315088
I1008 00:04:51.189317  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.315088 (* 1 = 0.315088 loss)
I1008 00:04:51.189324  5289 sgd_solver.cpp:105] Iteration 26200, lr = 0.1
I1008 00:05:15.812507  5289 solver.cpp:218] Iteration 26300 (4.06159 iter/s, 24.6209s/100 iters), loss = 0.242963
I1008 00:05:15.812615  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.242963 (* 1 = 0.242963 loss)
I1008 00:05:15.812623  5289 sgd_solver.cpp:105] Iteration 26300, lr = 0.1
I1008 00:05:40.705760  5289 solver.cpp:218] Iteration 26400 (4.01786 iter/s, 24.8889s/100 iters), loss = 0.192948
I1008 00:05:40.705793  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.192948 (* 1 = 0.192948 loss)
I1008 00:05:40.705801  5289 sgd_solver.cpp:105] Iteration 26400, lr = 0.1
I1008 00:06:04.387945  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:06:05.370251  5289 solver.cpp:330] Iteration 26500, Testing net (#0)
I1008 00:06:09.925827  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:06:10.130980  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8146
I1008 00:06:10.131008  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.55516 (* 1 = 0.55516 loss)
I1008 00:06:10.267546  5289 solver.cpp:218] Iteration 26500 (3.38324 iter/s, 29.5574s/100 iters), loss = 0.224317
I1008 00:06:10.267583  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.224317 (* 1 = 0.224317 loss)
I1008 00:06:10.267591  5289 sgd_solver.cpp:105] Iteration 26500, lr = 0.1
I1008 00:06:35.260598  5289 solver.cpp:218] Iteration 26600 (4.00113 iter/s, 24.9929s/100 iters), loss = 0.268932
I1008 00:06:35.260704  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.268932 (* 1 = 0.268932 loss)
I1008 00:06:35.260715  5289 sgd_solver.cpp:105] Iteration 26600, lr = 0.1
I1008 00:06:59.950778  5289 solver.cpp:218] Iteration 26700 (4.05091 iter/s, 24.6858s/100 iters), loss = 0.253651
I1008 00:06:59.950819  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.253651 (* 1 = 0.253651 loss)
I1008 00:06:59.950826  5289 sgd_solver.cpp:105] Iteration 26700, lr = 0.1
I1008 00:07:24.650315  5289 solver.cpp:218] Iteration 26800 (4.04938 iter/s, 24.6952s/100 iters), loss = 0.23175
I1008 00:07:24.650403  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.23175 (* 1 = 0.23175 loss)
I1008 00:07:24.650410  5289 sgd_solver.cpp:105] Iteration 26800, lr = 0.1
I1008 00:07:49.407172  5289 solver.cpp:218] Iteration 26900 (4.0399 iter/s, 24.7531s/100 iters), loss = 0.170767
I1008 00:07:49.407208  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.170767 (* 1 = 0.170767 loss)
I1008 00:07:49.407217  5289 sgd_solver.cpp:105] Iteration 26900, lr = 0.1
I1008 00:08:13.105371  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:08:14.088807  5289 solver.cpp:330] Iteration 27000, Testing net (#0)
I1008 00:08:18.628897  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:08:18.816153  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8358
I1008 00:08:18.816179  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.495828 (* 1 = 0.495828 loss)
I1008 00:08:18.983918  5289 solver.cpp:218] Iteration 27000 (3.38133 iter/s, 29.5742s/100 iters), loss = 0.279037
I1008 00:08:18.983959  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.279037 (* 1 = 0.279037 loss)
I1008 00:08:18.983965  5289 sgd_solver.cpp:105] Iteration 27000, lr = 0.1
I1008 00:08:43.970741  5289 solver.cpp:218] Iteration 27100 (4.00213 iter/s, 24.9867s/100 iters), loss = 0.305532
I1008 00:08:43.970832  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.305532 (* 1 = 0.305532 loss)
I1008 00:08:43.970842  5289 sgd_solver.cpp:105] Iteration 27100, lr = 0.1
I1008 00:09:08.589758  5289 solver.cpp:218] Iteration 27200 (4.06228 iter/s, 24.6167s/100 iters), loss = 0.312257
I1008 00:09:08.589793  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.312257 (* 1 = 0.312257 loss)
I1008 00:09:08.589802  5289 sgd_solver.cpp:105] Iteration 27200, lr = 0.1
I1008 00:09:33.258005  5289 solver.cpp:218] Iteration 27300 (4.05451 iter/s, 24.6639s/100 iters), loss = 0.274114
I1008 00:09:33.258112  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.274114 (* 1 = 0.274114 loss)
I1008 00:09:33.258121  5289 sgd_solver.cpp:105] Iteration 27300, lr = 0.1
I1008 00:09:57.873888  5289 solver.cpp:218] Iteration 27400 (4.06307 iter/s, 24.6119s/100 iters), loss = 0.122305
I1008 00:09:57.873920  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.122305 (* 1 = 0.122305 loss)
I1008 00:09:57.873929  5289 sgd_solver.cpp:105] Iteration 27400, lr = 0.1
I1008 00:10:21.760417  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:10:22.747663  5289 solver.cpp:330] Iteration 27500, Testing net (#0)
I1008 00:10:27.299531  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:10:27.487613  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8158
I1008 00:10:27.487642  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.571172 (* 1 = 0.571172 loss)
I1008 00:10:27.642014  5289 solver.cpp:218] Iteration 27500 (3.35931 iter/s, 29.768s/100 iters), loss = 0.252808
I1008 00:10:27.642046  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.252808 (* 1 = 0.252808 loss)
I1008 00:10:27.642055  5289 sgd_solver.cpp:105] Iteration 27500, lr = 0.1
I1008 00:10:52.680727  5289 solver.cpp:218] Iteration 27600 (3.99418 iter/s, 25.0365s/100 iters), loss = 0.220401
I1008 00:10:52.680799  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.220401 (* 1 = 0.220401 loss)
I1008 00:10:52.680807  5289 sgd_solver.cpp:105] Iteration 27600, lr = 0.1
I1008 00:11:17.349659  5289 solver.cpp:218] Iteration 27700 (4.0544 iter/s, 24.6645s/100 iters), loss = 0.263235
I1008 00:11:17.349697  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.263235 (* 1 = 0.263235 loss)
I1008 00:11:17.349706  5289 sgd_solver.cpp:105] Iteration 27700, lr = 0.1
I1008 00:11:42.001687  5289 solver.cpp:218] Iteration 27800 (4.05684 iter/s, 24.6497s/100 iters), loss = 0.282077
I1008 00:11:42.001773  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.282077 (* 1 = 0.282077 loss)
I1008 00:11:42.001786  5289 sgd_solver.cpp:105] Iteration 27800, lr = 0.1
I1008 00:12:06.642644  5289 solver.cpp:218] Iteration 27900 (4.05866 iter/s, 24.6387s/100 iters), loss = 0.228202
I1008 00:12:06.642679  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.228202 (* 1 = 0.228202 loss)
I1008 00:12:06.642686  5289 sgd_solver.cpp:105] Iteration 27900, lr = 0.1
I1008 00:12:30.500192  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:12:31.482841  5289 solver.cpp:330] Iteration 28000, Testing net (#0)
I1008 00:12:36.139780  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:12:36.306530  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8462
I1008 00:12:36.306558  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.46664 (* 1 = 0.46664 loss)
I1008 00:12:36.487303  5289 solver.cpp:218] Iteration 28000 (3.35094 iter/s, 29.8424s/100 iters), loss = 0.213559
I1008 00:12:36.487332  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.213559 (* 1 = 0.213559 loss)
I1008 00:12:36.487339  5289 sgd_solver.cpp:105] Iteration 28000, lr = 0.1
I1008 00:13:01.536725  5289 solver.cpp:218] Iteration 28100 (3.99247 iter/s, 25.0472s/100 iters), loss = 0.243367
I1008 00:13:01.536798  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.243367 (* 1 = 0.243367 loss)
I1008 00:13:01.536806  5289 sgd_solver.cpp:105] Iteration 28100, lr = 0.1
I1008 00:13:26.146152  5289 solver.cpp:218] Iteration 28200 (4.06386 iter/s, 24.6071s/100 iters), loss = 0.18566
I1008 00:13:26.146185  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.18566 (* 1 = 0.18566 loss)
I1008 00:13:26.146193  5289 sgd_solver.cpp:105] Iteration 28200, lr = 0.1
I1008 00:13:50.773939  5289 solver.cpp:218] Iteration 28300 (4.06083 iter/s, 24.6255s/100 iters), loss = 0.237118
I1008 00:13:50.774050  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.237118 (* 1 = 0.237118 loss)
I1008 00:13:50.774063  5289 sgd_solver.cpp:105] Iteration 28300, lr = 0.1
I1008 00:14:15.386569  5289 solver.cpp:218] Iteration 28400 (4.06333 iter/s, 24.6104s/100 iters), loss = 0.18144
I1008 00:14:15.386608  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.18144 (* 1 = 0.18144 loss)
I1008 00:14:15.386628  5289 sgd_solver.cpp:105] Iteration 28400, lr = 0.1
I1008 00:14:39.142498  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:14:40.128101  5289 solver.cpp:330] Iteration 28500, Testing net (#0)
I1008 00:14:44.656316  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:14:44.839797  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7778
I1008 00:14:44.839824  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.744358 (* 1 = 0.744358 loss)
I1008 00:14:45.000648  5289 solver.cpp:218] Iteration 28500 (3.37703 iter/s, 29.6118s/100 iters), loss = 0.202373
I1008 00:14:45.000681  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.202373 (* 1 = 0.202373 loss)
I1008 00:14:45.000689  5289 sgd_solver.cpp:105] Iteration 28500, lr = 0.1
I1008 00:15:10.061619  5289 solver.cpp:218] Iteration 28600 (3.99029 iter/s, 25.0608s/100 iters), loss = 0.255859
I1008 00:15:10.061703  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.25586 (* 1 = 0.25586 loss)
I1008 00:15:10.061712  5289 sgd_solver.cpp:105] Iteration 28600, lr = 0.1
I1008 00:15:34.724735  5289 solver.cpp:218] Iteration 28700 (4.05537 iter/s, 24.6587s/100 iters), loss = 0.271305
I1008 00:15:34.724771  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.271305 (* 1 = 0.271305 loss)
I1008 00:15:34.724778  5289 sgd_solver.cpp:105] Iteration 28700, lr = 0.1
I1008 00:15:59.380604  5289 solver.cpp:218] Iteration 28800 (4.05645 iter/s, 24.6521s/100 iters), loss = 0.231342
I1008 00:15:59.380692  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.231342 (* 1 = 0.231342 loss)
I1008 00:15:59.380700  5289 sgd_solver.cpp:105] Iteration 28800, lr = 0.1
I1008 00:16:24.047379  5289 solver.cpp:218] Iteration 28900 (4.05464 iter/s, 24.6631s/100 iters), loss = 0.132363
I1008 00:16:24.047420  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.132363 (* 1 = 0.132363 loss)
I1008 00:16:24.047427  5289 sgd_solver.cpp:105] Iteration 28900, lr = 0.1
I1008 00:16:47.826905  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:16:48.809909  5289 solver.cpp:330] Iteration 29000, Testing net (#0)
I1008 00:16:53.338847  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:16:53.526397  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8297
I1008 00:16:53.526427  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.548073 (* 1 = 0.548073 loss)
I1008 00:16:53.680560  5289 solver.cpp:218] Iteration 29000 (3.37485 iter/s, 29.6309s/100 iters), loss = 0.192649
I1008 00:16:53.680601  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.192649 (* 1 = 0.192649 loss)
I1008 00:16:53.680608  5289 sgd_solver.cpp:105] Iteration 29000, lr = 0.1
I1008 00:17:18.751559  5289 solver.cpp:218] Iteration 29100 (3.9887 iter/s, 25.0709s/100 iters), loss = 0.255592
I1008 00:17:18.751629  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.255592 (* 1 = 0.255592 loss)
I1008 00:17:18.751639  5289 sgd_solver.cpp:105] Iteration 29100, lr = 0.1
I1008 00:17:43.391753  5289 solver.cpp:218] Iteration 29200 (4.05903 iter/s, 24.6364s/100 iters), loss = 0.225887
I1008 00:17:43.391791  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.225887 (* 1 = 0.225887 loss)
I1008 00:17:43.391810  5289 sgd_solver.cpp:105] Iteration 29200, lr = 0.1
I1008 00:18:08.043664  5289 solver.cpp:218] Iteration 29300 (4.05707 iter/s, 24.6483s/100 iters), loss = 0.248164
I1008 00:18:08.043778  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.248164 (* 1 = 0.248164 loss)
I1008 00:18:08.043787  5289 sgd_solver.cpp:105] Iteration 29300, lr = 0.1
I1008 00:18:32.681232  5289 solver.cpp:218] Iteration 29400 (4.05921 iter/s, 24.6353s/100 iters), loss = 0.17615
I1008 00:18:32.681269  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.176151 (* 1 = 0.176151 loss)
I1008 00:18:32.681278  5289 sgd_solver.cpp:105] Iteration 29400, lr = 0.1
I1008 00:18:56.451704  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:18:57.433660  5289 solver.cpp:330] Iteration 29500, Testing net (#0)
I1008 00:19:01.931385  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:19:02.142400  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8196
I1008 00:19:02.142427  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.553482 (* 1 = 0.553482 loss)
I1008 00:19:02.280282  5289 solver.cpp:218] Iteration 29500 (3.37874 iter/s, 29.5968s/100 iters), loss = 0.201075
I1008 00:19:02.280316  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.201076 (* 1 = 0.201076 loss)
I1008 00:19:02.280323  5289 sgd_solver.cpp:105] Iteration 29500, lr = 0.1
I1008 00:19:27.310474  5289 solver.cpp:218] Iteration 29600 (3.99554 iter/s, 25.0279s/100 iters), loss = 0.218152
I1008 00:19:27.310561  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.218152 (* 1 = 0.218152 loss)
I1008 00:19:27.310570  5289 sgd_solver.cpp:105] Iteration 29600, lr = 0.1
I1008 00:19:51.965260  5289 solver.cpp:218] Iteration 29700 (4.05638 iter/s, 24.6525s/100 iters), loss = 0.178607
I1008 00:19:51.965303  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.178607 (* 1 = 0.178607 loss)
I1008 00:19:51.965311  5289 sgd_solver.cpp:105] Iteration 29700, lr = 0.1
I1008 00:20:16.615340  5289 solver.cpp:218] Iteration 29800 (4.05748 iter/s, 24.6458s/100 iters), loss = 0.273949
I1008 00:20:16.615422  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.273949 (* 1 = 0.273949 loss)
I1008 00:20:16.615429  5289 sgd_solver.cpp:105] Iteration 29800, lr = 0.1
I1008 00:20:41.283115  5289 solver.cpp:218] Iteration 29900 (4.05449 iter/s, 24.664s/100 iters), loss = 0.111056
I1008 00:20:41.283165  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.111056 (* 1 = 0.111056 loss)
I1008 00:20:41.283172  5289 sgd_solver.cpp:105] Iteration 29900, lr = 0.1
I1008 00:21:05.061661  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:21:06.045698  5289 solver.cpp:330] Iteration 30000, Testing net (#0)
I1008 00:21:10.707618  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:21:10.887012  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8443
I1008 00:21:10.887038  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.480926 (* 1 = 0.480926 loss)
I1008 00:21:11.052223  5289 solver.cpp:218] Iteration 30000 (3.35961 iter/s, 29.7654s/100 iters), loss = 0.176088
I1008 00:21:11.052254  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.176088 (* 1 = 0.176088 loss)
I1008 00:21:11.052263  5289 sgd_solver.cpp:105] Iteration 30000, lr = 0.1
I1008 00:21:36.100517  5289 solver.cpp:218] Iteration 30100 (3.99265 iter/s, 25.046s/100 iters), loss = 0.250563
I1008 00:21:36.100591  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.250563 (* 1 = 0.250563 loss)
I1008 00:21:36.100599  5289 sgd_solver.cpp:105] Iteration 30100, lr = 0.1
I1008 00:22:00.746979  5289 solver.cpp:218] Iteration 30200 (4.05811 iter/s, 24.642s/100 iters), loss = 0.294706
I1008 00:22:00.747014  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.294706 (* 1 = 0.294706 loss)
I1008 00:22:00.747021  5289 sgd_solver.cpp:105] Iteration 30200, lr = 0.1
I1008 00:22:25.359899  5289 solver.cpp:218] Iteration 30300 (4.06328 iter/s, 24.6107s/100 iters), loss = 0.207066
I1008 00:22:25.360023  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.207066 (* 1 = 0.207066 loss)
I1008 00:22:25.360034  5289 sgd_solver.cpp:105] Iteration 30300, lr = 0.1
I1008 00:22:50.002676  5289 solver.cpp:218] Iteration 30400 (4.05859 iter/s, 24.6391s/100 iters), loss = 0.265663
I1008 00:22:50.002709  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.265663 (* 1 = 0.265663 loss)
I1008 00:22:50.002715  5289 sgd_solver.cpp:105] Iteration 30400, lr = 0.1
I1008 00:23:13.861049  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:23:14.844676  5289 solver.cpp:330] Iteration 30500, Testing net (#0)
I1008 00:23:19.510215  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:23:19.694059  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8311
I1008 00:23:19.694097  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.498207 (* 1 = 0.498207 loss)
I1008 00:23:19.869985  5289 solver.cpp:218] Iteration 30500 (3.34864 iter/s, 29.8629s/100 iters), loss = 0.234604
I1008 00:23:19.870028  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.234604 (* 1 = 0.234604 loss)
I1008 00:23:19.870033  5289 sgd_solver.cpp:105] Iteration 30500, lr = 0.1
I1008 00:23:44.883257  5289 solver.cpp:218] Iteration 30600 (3.99824 iter/s, 25.011s/100 iters), loss = 0.207824
I1008 00:23:44.883340  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.207824 (* 1 = 0.207824 loss)
I1008 00:23:44.883348  5289 sgd_solver.cpp:105] Iteration 30600, lr = 0.1
I1008 00:24:09.487493  5289 solver.cpp:218] Iteration 30700 (4.06472 iter/s, 24.602s/100 iters), loss = 0.260727
I1008 00:24:09.487530  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.260727 (* 1 = 0.260727 loss)
I1008 00:24:09.487538  5289 sgd_solver.cpp:105] Iteration 30700, lr = 0.1
I1008 00:24:34.222079  5289 solver.cpp:218] Iteration 30800 (4.04364 iter/s, 24.7302s/100 iters), loss = 0.226931
I1008 00:24:34.222162  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.226931 (* 1 = 0.226931 loss)
I1008 00:24:34.222169  5289 sgd_solver.cpp:105] Iteration 30800, lr = 0.1
I1008 00:24:58.869932  5289 solver.cpp:218] Iteration 30900 (4.05752 iter/s, 24.6456s/100 iters), loss = 0.151872
I1008 00:24:58.869976  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.151872 (* 1 = 0.151872 loss)
I1008 00:24:58.869982  5289 sgd_solver.cpp:105] Iteration 30900, lr = 0.1
I1008 00:25:22.669937  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:25:23.654498  5289 solver.cpp:330] Iteration 31000, Testing net (#0)
I1008 00:25:28.233800  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:25:28.426810  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8042
I1008 00:25:28.426841  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.618447 (* 1 = 0.618447 loss)
I1008 00:25:28.576268  5289 solver.cpp:218] Iteration 31000 (3.36654 iter/s, 29.704s/100 iters), loss = 0.22957
I1008 00:25:28.576301  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.229571 (* 1 = 0.229571 loss)
I1008 00:25:28.576309  5289 sgd_solver.cpp:105] Iteration 31000, lr = 0.1
I1008 00:25:53.519070  5289 solver.cpp:218] Iteration 31100 (4.00954 iter/s, 24.9405s/100 iters), loss = 0.230489
I1008 00:25:53.519146  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.230489 (* 1 = 0.230489 loss)
I1008 00:25:53.519155  5289 sgd_solver.cpp:105] Iteration 31100, lr = 0.1
I1008 00:26:18.175691  5289 solver.cpp:218] Iteration 31200 (4.05608 iter/s, 24.6544s/100 iters), loss = 0.360406
I1008 00:26:18.175722  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.360406 (* 1 = 0.360406 loss)
I1008 00:26:18.175729  5289 sgd_solver.cpp:105] Iteration 31200, lr = 0.1
I1008 00:26:42.841161  5289 solver.cpp:218] Iteration 31300 (4.05463 iter/s, 24.6632s/100 iters), loss = 0.120772
I1008 00:26:42.841253  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.120772 (* 1 = 0.120772 loss)
I1008 00:26:42.841260  5289 sgd_solver.cpp:105] Iteration 31300, lr = 0.1
I1008 00:27:07.492326  5289 solver.cpp:218] Iteration 31400 (4.05697 iter/s, 24.6489s/100 iters), loss = 0.114468
I1008 00:27:07.492358  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.114468 (* 1 = 0.114468 loss)
I1008 00:27:07.492365  5289 sgd_solver.cpp:105] Iteration 31400, lr = 0.1
I1008 00:27:31.285363  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:27:32.270009  5289 solver.cpp:330] Iteration 31500, Testing net (#0)
I1008 00:27:36.924751  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:27:37.099320  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8422
I1008 00:27:37.099346  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.506798 (* 1 = 0.506798 loss)
I1008 00:27:37.270059  5289 solver.cpp:218] Iteration 31500 (3.35847 iter/s, 29.7754s/100 iters), loss = 0.192474
I1008 00:27:37.270092  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.192474 (* 1 = 0.192474 loss)
I1008 00:27:37.270098  5289 sgd_solver.cpp:105] Iteration 31500, lr = 0.1
I1008 00:28:02.357048  5289 solver.cpp:218] Iteration 31600 (3.98649 iter/s, 25.0847s/100 iters), loss = 0.261764
I1008 00:28:02.357132  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.261764 (* 1 = 0.261764 loss)
I1008 00:28:02.357141  5289 sgd_solver.cpp:105] Iteration 31600, lr = 0.1
I1008 00:28:27.051256  5289 solver.cpp:218] Iteration 31700 (4.04991 iter/s, 24.6919s/100 iters), loss = 0.244207
I1008 00:28:27.051300  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.244207 (* 1 = 0.244207 loss)
I1008 00:28:27.051306  5289 sgd_solver.cpp:105] Iteration 31700, lr = 0.1
I1008 00:28:51.697993  5289 solver.cpp:218] Iteration 31800 (4.05788 iter/s, 24.6434s/100 iters), loss = 0.215812
I1008 00:28:51.698071  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.215812 (* 1 = 0.215812 loss)
I1008 00:28:51.698084  5289 sgd_solver.cpp:105] Iteration 31800, lr = 0.1
I1008 00:29:16.365864  5289 solver.cpp:218] Iteration 31900 (4.05458 iter/s, 24.6635s/100 iters), loss = 0.1931
I1008 00:29:16.365900  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.1931 (* 1 = 0.1931 loss)
I1008 00:29:16.365907  5289 sgd_solver.cpp:105] Iteration 31900, lr = 0.1
I1008 00:29:40.150971  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:29:41.133872  5289 solver.cpp:330] Iteration 32000, Testing net (#0)
I1008 00:29:45.711418  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:29:45.922338  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8345
I1008 00:29:45.922366  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.512021 (* 1 = 0.512021 loss)
I1008 00:29:46.058439  5289 solver.cpp:218] Iteration 32000 (3.3681 iter/s, 29.6903s/100 iters), loss = 0.164525
I1008 00:29:46.058477  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.164525 (* 1 = 0.164525 loss)
I1008 00:29:46.058485  5289 sgd_solver.cpp:105] Iteration 32000, lr = 0.1
I1008 00:30:11.014304  5289 solver.cpp:218] Iteration 32100 (4.00743 iter/s, 24.9536s/100 iters), loss = 0.201382
I1008 00:30:11.014400  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.201382 (* 1 = 0.201382 loss)
I1008 00:30:11.014420  5289 sgd_solver.cpp:105] Iteration 32100, lr = 0.1
I1008 00:30:35.644659  5289 solver.cpp:218] Iteration 32200 (4.0604 iter/s, 24.6281s/100 iters), loss = 0.255695
I1008 00:30:35.644697  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.255695 (* 1 = 0.255695 loss)
I1008 00:30:35.644704  5289 sgd_solver.cpp:105] Iteration 32200, lr = 0.1
I1008 00:31:00.299929  5289 solver.cpp:218] Iteration 32300 (4.05665 iter/s, 24.6509s/100 iters), loss = 0.256547
I1008 00:31:00.300035  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.256547 (* 1 = 0.256547 loss)
I1008 00:31:00.300045  5289 sgd_solver.cpp:105] Iteration 32300, lr = 0.1
I1008 00:31:24.941356  5289 solver.cpp:218] Iteration 32400 (4.05858 iter/s, 24.6392s/100 iters), loss = 0.173534
I1008 00:31:24.941391  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.173534 (* 1 = 0.173534 loss)
I1008 00:31:24.941398  5289 sgd_solver.cpp:105] Iteration 32400, lr = 0.1
I1008 00:31:48.712752  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:31:49.695669  5289 solver.cpp:330] Iteration 32500, Testing net (#0)
I1008 00:31:54.196485  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:31:54.409828  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8391
I1008 00:31:54.409862  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.47685 (* 1 = 0.47685 loss)
I1008 00:31:54.565505  5289 solver.cpp:218] Iteration 32500 (3.37588 iter/s, 29.6219s/100 iters), loss = 0.177547
I1008 00:31:54.565547  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.177547 (* 1 = 0.177547 loss)
I1008 00:31:54.565559  5289 sgd_solver.cpp:105] Iteration 32500, lr = 0.1
I1008 00:32:19.649303  5289 solver.cpp:218] Iteration 32600 (3.987 iter/s, 25.0815s/100 iters), loss = 0.261301
I1008 00:32:19.649405  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.261301 (* 1 = 0.261301 loss)
I1008 00:32:19.649425  5289 sgd_solver.cpp:105] Iteration 32600, lr = 0.1
I1008 00:32:44.289916  5289 solver.cpp:218] Iteration 32700 (4.05894 iter/s, 24.637s/100 iters), loss = 0.211549
I1008 00:32:44.289957  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.211549 (* 1 = 0.211549 loss)
I1008 00:32:44.289965  5289 sgd_solver.cpp:105] Iteration 32700, lr = 0.1
I1008 00:33:08.972091  5289 solver.cpp:218] Iteration 32800 (4.05226 iter/s, 24.6776s/100 iters), loss = 0.312679
I1008 00:33:08.972180  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.312679 (* 1 = 0.312679 loss)
I1008 00:33:08.972188  5289 sgd_solver.cpp:105] Iteration 32800, lr = 0.1
I1008 00:33:33.633190  5289 solver.cpp:218] Iteration 32900 (4.0557 iter/s, 24.6567s/100 iters), loss = 0.205517
I1008 00:33:33.633222  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.205517 (* 1 = 0.205517 loss)
I1008 00:33:33.633229  5289 sgd_solver.cpp:105] Iteration 32900, lr = 0.1
I1008 00:33:57.500192  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:33:58.482692  5289 solver.cpp:330] Iteration 33000, Testing net (#0)
I1008 00:34:02.990711  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:34:03.180932  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8413
I1008 00:34:03.180958  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.473596 (* 1 = 0.473596 loss)
I1008 00:34:03.340451  5289 solver.cpp:218] Iteration 33000 (3.36644 iter/s, 29.705s/100 iters), loss = 0.17255
I1008 00:34:03.340484  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.17255 (* 1 = 0.17255 loss)
I1008 00:34:03.340490  5289 sgd_solver.cpp:105] Iteration 33000, lr = 0.1
I1008 00:34:28.375433  5289 solver.cpp:218] Iteration 33100 (3.99477 iter/s, 25.0327s/100 iters), loss = 0.28389
I1008 00:34:28.375516  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.28389 (* 1 = 0.28389 loss)
I1008 00:34:28.375525  5289 sgd_solver.cpp:105] Iteration 33100, lr = 0.1
I1008 00:34:53.050752  5289 solver.cpp:218] Iteration 33200 (4.053 iter/s, 24.6731s/100 iters), loss = 0.301721
I1008 00:34:53.050786  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.301721 (* 1 = 0.301721 loss)
I1008 00:34:53.050793  5289 sgd_solver.cpp:105] Iteration 33200, lr = 0.1
I1008 00:35:17.695976  5289 solver.cpp:218] Iteration 33300 (4.05817 iter/s, 24.6416s/100 iters), loss = 0.214345
I1008 00:35:17.696069  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.214345 (* 1 = 0.214345 loss)
I1008 00:35:17.696079  5289 sgd_solver.cpp:105] Iteration 33300, lr = 0.1
I1008 00:35:42.336861  5289 solver.cpp:218] Iteration 33400 (4.05867 iter/s, 24.6386s/100 iters), loss = 0.212406
I1008 00:35:42.336899  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.212406 (* 1 = 0.212406 loss)
I1008 00:35:42.336907  5289 sgd_solver.cpp:105] Iteration 33400, lr = 0.1
I1008 00:36:06.202329  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:36:07.187695  5289 solver.cpp:330] Iteration 33500, Testing net (#0)
I1008 00:36:11.869884  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:36:12.040926  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8052
I1008 00:36:12.040953  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.610914 (* 1 = 0.610914 loss)
I1008 00:36:12.226323  5289 solver.cpp:218] Iteration 33500 (3.34591 iter/s, 29.8872s/100 iters), loss = 0.184975
I1008 00:36:12.226357  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.184975 (* 1 = 0.184975 loss)
I1008 00:36:12.226363  5289 sgd_solver.cpp:105] Iteration 33500, lr = 0.1
I1008 00:36:37.233889  5289 solver.cpp:218] Iteration 33600 (3.99915 iter/s, 25.0053s/100 iters), loss = 0.196723
I1008 00:36:37.233978  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.196723 (* 1 = 0.196723 loss)
I1008 00:36:37.233986  5289 sgd_solver.cpp:105] Iteration 33600, lr = 0.1
I1008 00:37:01.882519  5289 solver.cpp:218] Iteration 33700 (4.05706 iter/s, 24.6484s/100 iters), loss = 0.259268
I1008 00:37:01.882555  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.259267 (* 1 = 0.259267 loss)
I1008 00:37:01.882562  5289 sgd_solver.cpp:105] Iteration 33700, lr = 0.1
I1008 00:37:26.539481  5289 solver.cpp:218] Iteration 33800 (4.05603 iter/s, 24.6547s/100 iters), loss = 0.312721
I1008 00:37:26.539594  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.312721 (* 1 = 0.312721 loss)
I1008 00:37:26.539608  5289 sgd_solver.cpp:105] Iteration 33800, lr = 0.1
I1008 00:37:51.194257  5289 solver.cpp:218] Iteration 33900 (4.05638 iter/s, 24.6525s/100 iters), loss = 0.140095
I1008 00:37:51.194296  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.140094 (* 1 = 0.140094 loss)
I1008 00:37:51.194314  5289 sgd_solver.cpp:105] Iteration 33900, lr = 0.1
I1008 00:38:15.070322  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:38:16.054906  5289 solver.cpp:330] Iteration 34000, Testing net (#0)
I1008 00:38:20.605660  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:38:20.826123  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7941
I1008 00:38:20.826150  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.640476 (* 1 = 0.640476 loss)
I1008 00:38:20.947715  5289 solver.cpp:218] Iteration 34000 (3.36121 iter/s, 29.7512s/100 iters), loss = 0.212624
I1008 00:38:20.947747  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.212624 (* 1 = 0.212624 loss)
I1008 00:38:20.947754  5289 sgd_solver.cpp:105] Iteration 34000, lr = 0.1
I1008 00:38:45.895747  5289 solver.cpp:218] Iteration 34100 (4.00836 iter/s, 24.9479s/100 iters), loss = 0.309674
I1008 00:38:45.895841  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.309674 (* 1 = 0.309674 loss)
I1008 00:38:45.895855  5289 sgd_solver.cpp:105] Iteration 34100, lr = 0.1
I1008 00:39:10.504393  5289 solver.cpp:218] Iteration 34200 (4.06433 iter/s, 24.6043s/100 iters), loss = 0.254175
I1008 00:39:10.504426  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.254174 (* 1 = 0.254174 loss)
I1008 00:39:10.504432  5289 sgd_solver.cpp:105] Iteration 34200, lr = 0.1
I1008 00:39:35.171237  5289 solver.cpp:218] Iteration 34300 (4.0544 iter/s, 24.6645s/100 iters), loss = 0.229703
I1008 00:39:35.171316  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.229703 (* 1 = 0.229703 loss)
I1008 00:39:35.171324  5289 sgd_solver.cpp:105] Iteration 34300, lr = 0.1
I1008 00:39:59.730234  5289 solver.cpp:218] Iteration 34400 (4.0722 iter/s, 24.5568s/100 iters), loss = 0.135564
I1008 00:39:59.730268  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.135564 (* 1 = 0.135564 loss)
I1008 00:39:59.730275  5289 sgd_solver.cpp:105] Iteration 34400, lr = 0.1
I1008 00:40:23.604684  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:40:24.588742  5289 solver.cpp:330] Iteration 34500, Testing net (#0)
I1008 00:40:29.220532  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:40:29.409356  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8331
I1008 00:40:29.409381  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.520676 (* 1 = 0.520676 loss)
I1008 00:40:29.583369  5289 solver.cpp:218] Iteration 34500 (3.35023 iter/s, 29.8487s/100 iters), loss = 0.22347
I1008 00:40:29.583400  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.22347 (* 1 = 0.22347 loss)
I1008 00:40:29.583407  5289 sgd_solver.cpp:105] Iteration 34500, lr = 0.1
I1008 00:40:54.785177  5289 solver.cpp:218] Iteration 34600 (3.96833 iter/s, 25.1995s/100 iters), loss = 0.181666
I1008 00:40:54.785264  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.181666 (* 1 = 0.181666 loss)
I1008 00:40:54.785274  5289 sgd_solver.cpp:105] Iteration 34600, lr = 0.1
I1008 00:41:19.316671  5289 solver.cpp:218] Iteration 34700 (4.07676 iter/s, 24.5293s/100 iters), loss = 0.343917
I1008 00:41:19.316705  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.343917 (* 1 = 0.343917 loss)
I1008 00:41:19.316714  5289 sgd_solver.cpp:105] Iteration 34700, lr = 0.1
I1008 00:41:44.014580  5289 solver.cpp:218] Iteration 34800 (4.04965 iter/s, 24.6935s/100 iters), loss = 0.280354
I1008 00:41:44.014667  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.280354 (* 1 = 0.280354 loss)
I1008 00:41:44.014677  5289 sgd_solver.cpp:105] Iteration 34800, lr = 0.1
I1008 00:42:08.649224  5289 solver.cpp:218] Iteration 34900 (4.0597 iter/s, 24.6323s/100 iters), loss = 0.20937
I1008 00:42:08.649257  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.20937 (* 1 = 0.20937 loss)
I1008 00:42:08.649274  5289 sgd_solver.cpp:105] Iteration 34900, lr = 0.1
I1008 00:42:32.583534  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:42:33.566853  5289 solver.cpp:330] Iteration 35000, Testing net (#0)
I1008 00:42:38.119472  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:42:38.355530  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.832
I1008 00:42:38.355566  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.523154 (* 1 = 0.523154 loss)
I1008 00:42:38.471941  5289 solver.cpp:218] Iteration 35000 (3.35364 iter/s, 29.8184s/100 iters), loss = 0.16647
I1008 00:42:38.471976  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.16647 (* 1 = 0.16647 loss)
I1008 00:42:38.471985  5289 sgd_solver.cpp:105] Iteration 35000, lr = 0.1
I1008 00:43:03.553800  5289 solver.cpp:218] Iteration 35100 (3.98764 iter/s, 25.0775s/100 iters), loss = 0.227003
I1008 00:43:03.553870  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.227003 (* 1 = 0.227003 loss)
I1008 00:43:03.553879  5289 sgd_solver.cpp:105] Iteration 35100, lr = 0.1
I1008 00:43:28.252073  5289 solver.cpp:218] Iteration 35200 (4.04925 iter/s, 24.696s/100 iters), loss = 0.216723
I1008 00:43:28.252117  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.216723 (* 1 = 0.216723 loss)
I1008 00:43:28.252125  5289 sgd_solver.cpp:105] Iteration 35200, lr = 0.1
I1008 00:43:52.895758  5289 solver.cpp:218] Iteration 35300 (4.05845 iter/s, 24.64s/100 iters), loss = 0.219204
I1008 00:43:52.895858  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.219204 (* 1 = 0.219204 loss)
I1008 00:43:52.895866  5289 sgd_solver.cpp:105] Iteration 35300, lr = 0.1
I1008 00:44:17.556268  5289 solver.cpp:218] Iteration 35400 (4.05579 iter/s, 24.6561s/100 iters), loss = 0.200607
I1008 00:44:17.556303  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.200607 (* 1 = 0.200607 loss)
I1008 00:44:17.556313  5289 sgd_solver.cpp:105] Iteration 35400, lr = 0.1
I1008 00:44:41.426924  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:44:42.411882  5289 solver.cpp:330] Iteration 35500, Testing net (#0)
I1008 00:44:46.904935  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:44:47.118882  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7939
I1008 00:44:47.118911  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.68101 (* 1 = 0.68101 loss)
I1008 00:44:47.252780  5289 solver.cpp:218] Iteration 35500 (3.36792 iter/s, 29.6919s/100 iters), loss = 0.197611
I1008 00:44:47.252812  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.197611 (* 1 = 0.197611 loss)
I1008 00:44:47.252820  5289 sgd_solver.cpp:105] Iteration 35500, lr = 0.1
I1008 00:45:12.323390  5289 solver.cpp:218] Iteration 35600 (3.9891 iter/s, 25.0683s/100 iters), loss = 0.165727
I1008 00:45:12.323495  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.165727 (* 1 = 0.165727 loss)
I1008 00:45:12.323504  5289 sgd_solver.cpp:105] Iteration 35600, lr = 0.1
I1008 00:45:37.000430  5289 solver.cpp:218] Iteration 35700 (4.05273 iter/s, 24.6748s/100 iters), loss = 0.255878
I1008 00:45:37.000463  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.255878 (* 1 = 0.255878 loss)
I1008 00:45:37.000470  5289 sgd_solver.cpp:105] Iteration 35700, lr = 0.1
I1008 00:46:01.630350  5289 solver.cpp:218] Iteration 35800 (4.06047 iter/s, 24.6277s/100 iters), loss = 0.175184
I1008 00:46:01.630463  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.175184 (* 1 = 0.175184 loss)
I1008 00:46:01.630471  5289 sgd_solver.cpp:105] Iteration 35800, lr = 0.1
I1008 00:46:26.281152  5289 solver.cpp:218] Iteration 35900 (4.05739 iter/s, 24.6464s/100 iters), loss = 0.15765
I1008 00:46:26.281199  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.15765 (* 1 = 0.15765 loss)
I1008 00:46:26.281206  5289 sgd_solver.cpp:105] Iteration 35900, lr = 0.1
I1008 00:46:50.093756  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:46:51.057245  5289 solver.cpp:330] Iteration 36000, Testing net (#0)
I1008 00:46:55.597379  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:46:55.768558  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8142
I1008 00:46:55.768584  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.597846 (* 1 = 0.597846 loss)
I1008 00:46:55.950050  5289 solver.cpp:218] Iteration 36000 (3.37097 iter/s, 29.6651s/100 iters), loss = 0.263152
I1008 00:46:55.950083  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.263152 (* 1 = 0.263152 loss)
I1008 00:46:55.950093  5289 sgd_solver.cpp:105] Iteration 36000, lr = 0.1
I1008 00:47:20.965724  5289 solver.cpp:218] Iteration 36100 (3.99785 iter/s, 25.0134s/100 iters), loss = 0.196804
I1008 00:47:20.965819  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.196803 (* 1 = 0.196803 loss)
I1008 00:47:20.965838  5289 sgd_solver.cpp:105] Iteration 36100, lr = 0.1
I1008 00:47:45.561393  5289 solver.cpp:218] Iteration 36200 (4.06613 iter/s, 24.5934s/100 iters), loss = 0.201806
I1008 00:47:45.561425  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.201806 (* 1 = 0.201806 loss)
I1008 00:47:45.561434  5289 sgd_solver.cpp:105] Iteration 36200, lr = 0.1
I1008 00:48:10.196264  5289 solver.cpp:218] Iteration 36300 (4.05966 iter/s, 24.6326s/100 iters), loss = 0.261417
I1008 00:48:10.196344  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.261417 (* 1 = 0.261417 loss)
I1008 00:48:10.196357  5289 sgd_solver.cpp:105] Iteration 36300, lr = 0.1
I1008 00:48:34.818403  5289 solver.cpp:218] Iteration 36400 (4.06176 iter/s, 24.6199s/100 iters), loss = 0.180799
I1008 00:48:34.818439  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.180799 (* 1 = 0.180799 loss)
I1008 00:48:34.818457  5289 sgd_solver.cpp:105] Iteration 36400, lr = 0.1
I1008 00:48:58.691681  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:48:59.675675  5289 solver.cpp:330] Iteration 36500, Testing net (#0)
I1008 00:49:04.245875  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:49:04.462144  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8215
I1008 00:49:04.462172  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.565592 (* 1 = 0.565592 loss)
I1008 00:49:04.598968  5289 solver.cpp:218] Iteration 36500 (3.35815 iter/s, 29.7783s/100 iters), loss = 0.203258
I1008 00:49:04.599001  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.203258 (* 1 = 0.203258 loss)
I1008 00:49:04.599010  5289 sgd_solver.cpp:105] Iteration 36500, lr = 0.1
I1008 00:49:29.815382  5289 solver.cpp:218] Iteration 36600 (3.96635 iter/s, 25.2121s/100 iters), loss = 0.291355
I1008 00:49:29.815485  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.291355 (* 1 = 0.291355 loss)
I1008 00:49:29.815495  5289 sgd_solver.cpp:105] Iteration 36600, lr = 0.1
I1008 00:49:54.448448  5289 solver.cpp:218] Iteration 36700 (4.05996 iter/s, 24.6308s/100 iters), loss = 0.207076
I1008 00:49:54.448483  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.207076 (* 1 = 0.207076 loss)
I1008 00:49:54.448490  5289 sgd_solver.cpp:105] Iteration 36700, lr = 0.1
I1008 00:50:19.105717  5289 solver.cpp:218] Iteration 36800 (4.05597 iter/s, 24.655s/100 iters), loss = 0.202375
I1008 00:50:19.105787  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.202375 (* 1 = 0.202375 loss)
I1008 00:50:19.105796  5289 sgd_solver.cpp:105] Iteration 36800, lr = 0.1
I1008 00:50:43.751080  5289 solver.cpp:218] Iteration 36900 (4.05793 iter/s, 24.6431s/100 iters), loss = 0.145493
I1008 00:50:43.751114  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.145493 (* 1 = 0.145493 loss)
I1008 00:50:43.751124  5289 sgd_solver.cpp:105] Iteration 36900, lr = 0.1
I1008 00:51:07.631424  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:51:08.616360  5289 solver.cpp:330] Iteration 37000, Testing net (#0)
I1008 00:51:13.143633  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:51:13.302464  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8631
I1008 00:51:13.302492  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.405428 (* 1 = 0.405428 loss)
I1008 00:51:13.490114  5289 solver.cpp:218] Iteration 37000 (3.36302 iter/s, 29.7351s/100 iters), loss = 0.160332
I1008 00:51:13.490155  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.160332 (* 1 = 0.160332 loss)
I1008 00:51:13.490161  5289 sgd_solver.cpp:105] Iteration 37000, lr = 0.1
I1008 00:51:38.460125  5289 solver.cpp:218] Iteration 37100 (4.00483 iter/s, 24.9699s/100 iters), loss = 0.161757
I1008 00:51:38.460218  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.161757 (* 1 = 0.161757 loss)
I1008 00:51:38.460232  5289 sgd_solver.cpp:105] Iteration 37100, lr = 0.1
I1008 00:52:03.139735  5289 solver.cpp:218] Iteration 37200 (4.05265 iter/s, 24.6752s/100 iters), loss = 0.365906
I1008 00:52:03.139773  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.365906 (* 1 = 0.365906 loss)
I1008 00:52:03.139783  5289 sgd_solver.cpp:105] Iteration 37200, lr = 0.1
I1008 00:52:27.813096  5289 solver.cpp:218] Iteration 37300 (4.05333 iter/s, 24.6711s/100 iters), loss = 0.255392
I1008 00:52:27.813220  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.255392 (* 1 = 0.255392 loss)
I1008 00:52:27.813244  5289 sgd_solver.cpp:105] Iteration 37300, lr = 0.1
I1008 00:52:52.487696  5289 solver.cpp:218] Iteration 37400 (4.05312 iter/s, 24.6723s/100 iters), loss = 0.216768
I1008 00:52:52.487730  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.216768 (* 1 = 0.216768 loss)
I1008 00:52:52.487740  5289 sgd_solver.cpp:105] Iteration 37400, lr = 0.1
I1008 00:53:16.280606  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:53:17.275411  5289 solver.cpp:330] Iteration 37500, Testing net (#0)
I1008 00:53:21.886296  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:53:22.084098  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7847
I1008 00:53:22.084126  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.689646 (* 1 = 0.689646 loss)
I1008 00:53:22.212116  5289 solver.cpp:218] Iteration 37500 (3.36466 iter/s, 29.7206s/100 iters), loss = 0.211222
I1008 00:53:22.212148  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.211222 (* 1 = 0.211222 loss)
I1008 00:53:22.212154  5289 sgd_solver.cpp:105] Iteration 37500, lr = 0.1
I1008 00:53:47.281507  5289 solver.cpp:218] Iteration 37600 (3.98929 iter/s, 25.0671s/100 iters), loss = 0.308533
I1008 00:53:47.281605  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.308533 (* 1 = 0.308533 loss)
I1008 00:53:47.281615  5289 sgd_solver.cpp:105] Iteration 37600, lr = 0.1
I1008 00:54:11.984050  5289 solver.cpp:218] Iteration 37700 (4.04853 iter/s, 24.7003s/100 iters), loss = 0.226943
I1008 00:54:11.984086  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.226943 (* 1 = 0.226943 loss)
I1008 00:54:11.984092  5289 sgd_solver.cpp:105] Iteration 37700, lr = 0.1
I1008 00:54:36.636936  5289 solver.cpp:218] Iteration 37800 (4.0567 iter/s, 24.6506s/100 iters), loss = 0.209335
I1008 00:54:36.637035  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.209335 (* 1 = 0.209335 loss)
I1008 00:54:36.637045  5289 sgd_solver.cpp:105] Iteration 37800, lr = 0.1
I1008 00:55:01.262677  5289 solver.cpp:218] Iteration 37900 (4.06116 iter/s, 24.6235s/100 iters), loss = 0.118252
I1008 00:55:01.262713  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.118252 (* 1 = 0.118252 loss)
I1008 00:55:01.262722  5289 sgd_solver.cpp:105] Iteration 37900, lr = 0.1
I1008 00:55:24.948678  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:55:25.994199  5289 solver.cpp:330] Iteration 38000, Testing net (#0)
I1008 00:55:30.654870  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:55:30.889209  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7437
I1008 00:55:30.889243  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.833586 (* 1 = 0.833586 loss)
I1008 00:55:31.000221  5289 solver.cpp:218] Iteration 38000 (3.36301 iter/s, 29.7353s/100 iters), loss = 0.201003
I1008 00:55:31.000274  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.201003 (* 1 = 0.201003 loss)
I1008 00:55:31.000294  5289 sgd_solver.cpp:105] Iteration 38000, lr = 0.1
I1008 00:55:56.031262  5289 solver.cpp:218] Iteration 38100 (3.99541 iter/s, 25.0287s/100 iters), loss = 0.303573
I1008 00:55:56.031339  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.303573 (* 1 = 0.303573 loss)
I1008 00:55:56.031347  5289 sgd_solver.cpp:105] Iteration 38100, lr = 0.1
I1008 00:56:20.661278  5289 solver.cpp:218] Iteration 38200 (4.06081 iter/s, 24.6256s/100 iters), loss = 0.178736
I1008 00:56:20.661315  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.178736 (* 1 = 0.178736 loss)
I1008 00:56:20.661324  5289 sgd_solver.cpp:105] Iteration 38200, lr = 0.1
I1008 00:56:45.280611  5289 solver.cpp:218] Iteration 38300 (4.06223 iter/s, 24.617s/100 iters), loss = 0.266407
I1008 00:56:45.280717  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.266407 (* 1 = 0.266407 loss)
I1008 00:56:45.280730  5289 sgd_solver.cpp:105] Iteration 38300, lr = 0.1
I1008 00:57:09.896554  5289 solver.cpp:218] Iteration 38400 (4.06278 iter/s, 24.6137s/100 iters), loss = 0.122163
I1008 00:57:09.896589  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.122163 (* 1 = 0.122163 loss)
I1008 00:57:09.896595  5289 sgd_solver.cpp:105] Iteration 38400, lr = 0.1
I1008 00:57:33.499132  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:57:34.538897  5289 solver.cpp:330] Iteration 38500, Testing net (#0)
I1008 00:57:39.237938  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:57:39.424257  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8284
I1008 00:57:39.424285  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.535873 (* 1 = 0.535873 loss)
I1008 00:57:39.603179  5289 solver.cpp:218] Iteration 38500 (3.36651 iter/s, 29.7044s/100 iters), loss = 0.256038
I1008 00:57:39.603210  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.256038 (* 1 = 0.256038 loss)
I1008 00:57:39.603217  5289 sgd_solver.cpp:105] Iteration 38500, lr = 0.1
I1008 00:58:04.649924  5289 solver.cpp:218] Iteration 38600 (3.99289 iter/s, 25.0445s/100 iters), loss = 0.285456
I1008 00:58:04.650030  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.285456 (* 1 = 0.285456 loss)
I1008 00:58:04.650039  5289 sgd_solver.cpp:105] Iteration 38600, lr = 0.1
I1008 00:58:29.323454  5289 solver.cpp:218] Iteration 38700 (4.0533 iter/s, 24.6712s/100 iters), loss = 0.219098
I1008 00:58:29.323501  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.219098 (* 1 = 0.219098 loss)
I1008 00:58:29.323513  5289 sgd_solver.cpp:105] Iteration 38700, lr = 0.1
I1008 00:58:53.960608  5289 solver.cpp:218] Iteration 38800 (4.05928 iter/s, 24.6349s/100 iters), loss = 0.213542
I1008 00:58:53.960688  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.213542 (* 1 = 0.213542 loss)
I1008 00:58:53.960697  5289 sgd_solver.cpp:105] Iteration 38800, lr = 0.1
I1008 00:59:18.598825  5289 solver.cpp:218] Iteration 38900 (4.05911 iter/s, 24.6359s/100 iters), loss = 0.160127
I1008 00:59:18.598860  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.160127 (* 1 = 0.160127 loss)
I1008 00:59:18.598866  5289 sgd_solver.cpp:105] Iteration 38900, lr = 0.1
I1008 00:59:42.231462  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:59:43.297559  5289 solver.cpp:330] Iteration 39000, Testing net (#0)
I1008 00:59:48.132189  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:59:48.365108  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8409
I1008 00:59:48.365134  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.493179 (* 1 = 0.493179 loss)
I1008 00:59:48.501014  5289 solver.cpp:218] Iteration 39000 (3.34449 iter/s, 29.8999s/100 iters), loss = 0.208032
I1008 00:59:48.501046  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.208032 (* 1 = 0.208032 loss)
I1008 00:59:48.501054  5289 sgd_solver.cpp:105] Iteration 39000, lr = 0.1
I1008 01:00:13.595350  5289 solver.cpp:218] Iteration 39100 (3.98532 iter/s, 25.0921s/100 iters), loss = 0.245069
I1008 01:00:13.595425  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.245069 (* 1 = 0.245069 loss)
I1008 01:00:13.595439  5289 sgd_solver.cpp:105] Iteration 39100, lr = 0.1
I1008 01:00:38.234845  5289 solver.cpp:218] Iteration 39200 (4.05855 iter/s, 24.6393s/100 iters), loss = 0.244082
I1008 01:00:38.234881  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.244082 (* 1 = 0.244082 loss)
I1008 01:00:38.234889  5289 sgd_solver.cpp:105] Iteration 39200, lr = 0.1
I1008 01:01:02.892943  5289 solver.cpp:218] Iteration 39300 (4.05583 iter/s, 24.6558s/100 iters), loss = 0.26865
I1008 01:01:02.893030  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.26865 (* 1 = 0.26865 loss)
I1008 01:01:02.893038  5289 sgd_solver.cpp:105] Iteration 39300, lr = 0.1
I1008 01:01:27.561465  5289 solver.cpp:218] Iteration 39400 (4.05441 iter/s, 24.6645s/100 iters), loss = 0.16471
I1008 01:01:27.561498  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.16471 (* 1 = 0.16471 loss)
I1008 01:01:27.561506  5289 sgd_solver.cpp:105] Iteration 39400, lr = 0.1
I1008 01:01:51.082659  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:01:52.154101  5289 solver.cpp:330] Iteration 39500, Testing net (#0)
I1008 01:01:57.069737  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:01:57.282807  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8062
I1008 01:01:57.282835  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.613673 (* 1 = 0.613673 loss)
I1008 01:01:57.410420  5289 solver.cpp:218] Iteration 39500 (3.35045 iter/s, 29.8467s/100 iters), loss = 0.185084
I1008 01:01:57.410450  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.185084 (* 1 = 0.185084 loss)
I1008 01:01:57.410457  5289 sgd_solver.cpp:105] Iteration 39500, lr = 0.1
I1008 01:02:22.530118  5289 solver.cpp:218] Iteration 39600 (3.9813 iter/s, 25.1174s/100 iters), loss = 0.172453
I1008 01:02:22.530215  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.172453 (* 1 = 0.172453 loss)
I1008 01:02:22.530223  5289 sgd_solver.cpp:105] Iteration 39600, lr = 0.1
I1008 01:02:47.194291  5289 solver.cpp:218] Iteration 39700 (4.05484 iter/s, 24.6619s/100 iters), loss = 0.148883
I1008 01:02:47.194325  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.148883 (* 1 = 0.148883 loss)
I1008 01:02:47.194342  5289 sgd_solver.cpp:105] Iteration 39700, lr = 0.1
I1008 01:03:11.729266  5289 solver.cpp:218] Iteration 39800 (4.07641 iter/s, 24.5314s/100 iters), loss = 0.229849
I1008 01:03:11.729334  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.229849 (* 1 = 0.229849 loss)
I1008 01:03:11.729343  5289 sgd_solver.cpp:105] Iteration 39800, lr = 0.1
I1008 01:03:36.258107  5289 solver.cpp:218] Iteration 39900 (4.07756 iter/s, 24.5244s/100 iters), loss = 0.119659
I1008 01:03:36.258146  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.119659 (* 1 = 0.119659 loss)
I1008 01:03:36.258153  5289 sgd_solver.cpp:105] Iteration 39900, lr = 0.1
I1008 01:03:59.715705  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:04:00.724377  5289 solver.cpp:330] Iteration 40000, Testing net (#0)
I1008 01:04:05.735960  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:04:05.979431  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8407
I1008 01:04:05.979459  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.482024 (* 1 = 0.482024 loss)
I1008 01:04:06.098130  5289 solver.cpp:218] Iteration 40000 (3.3517 iter/s, 29.8356s/100 iters), loss = 0.20514
I1008 01:04:06.098161  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.205139 (* 1 = 0.205139 loss)
I1008 01:04:06.098167  5289 sgd_solver.cpp:46] MultiStep Status: Iteration 40000, step = 1
I1008 01:04:06.098171  5289 sgd_solver.cpp:105] Iteration 40000, lr = 0.01
I1008 01:04:31.238487  5289 solver.cpp:218] Iteration 40100 (3.97802 iter/s, 25.1381s/100 iters), loss = 0.147366
I1008 01:04:31.238570  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.147366 (* 1 = 0.147366 loss)
I1008 01:04:31.238580  5289 sgd_solver.cpp:105] Iteration 40100, lr = 0.01
I1008 01:04:55.895160  5289 solver.cpp:218] Iteration 40200 (4.05607 iter/s, 24.6544s/100 iters), loss = 0.192358
I1008 01:04:55.895196  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.192358 (* 1 = 0.192358 loss)
I1008 01:04:55.895203  5289 sgd_solver.cpp:105] Iteration 40200, lr = 0.01
I1008 01:05:20.542371  5289 solver.cpp:218] Iteration 40300 (4.05762 iter/s, 24.645s/100 iters), loss = 0.223507
I1008 01:05:20.542451  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.223507 (* 1 = 0.223507 loss)
I1008 01:05:20.542459  5289 sgd_solver.cpp:105] Iteration 40300, lr = 0.01
I1008 01:05:45.175990  5289 solver.cpp:218] Iteration 40400 (4.05987 iter/s, 24.6313s/100 iters), loss = 0.07801
I1008 01:05:45.176028  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0780099 (* 1 = 0.0780099 loss)
I1008 01:05:45.176035  5289 sgd_solver.cpp:105] Iteration 40400, lr = 0.01
I1008 01:06:08.615007  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:06:09.593727  5289 solver.cpp:330] Iteration 40500, Testing net (#0)
I1008 01:06:14.701227  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:06:14.872069  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8959
I1008 01:06:14.872095  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.300977 (* 1 = 0.300977 loss)
I1008 01:06:15.069216  5289 solver.cpp:218] Iteration 40500 (3.34549 iter/s, 29.8909s/100 iters), loss = 0.074613
I1008 01:06:15.069247  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0746129 (* 1 = 0.0746129 loss)
I1008 01:06:15.069254  5289 sgd_solver.cpp:105] Iteration 40500, lr = 0.01
I1008 01:06:40.071091  5289 solver.cpp:218] Iteration 40600 (4.00006 iter/s, 24.9996s/100 iters), loss = 0.165065
I1008 01:06:40.071200  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.165065 (* 1 = 0.165065 loss)
I1008 01:06:40.071209  5289 sgd_solver.cpp:105] Iteration 40600, lr = 0.01
I1008 01:07:04.730352  5289 solver.cpp:218] Iteration 40700 (4.05564 iter/s, 24.657s/100 iters), loss = 0.135117
I1008 01:07:04.730389  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.135117 (* 1 = 0.135117 loss)
I1008 01:07:04.730396  5289 sgd_solver.cpp:105] Iteration 40700, lr = 0.01
I1008 01:07:29.388223  5289 solver.cpp:218] Iteration 40800 (4.05587 iter/s, 24.6556s/100 iters), loss = 0.142205
I1008 01:07:29.388314  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.142205 (* 1 = 0.142205 loss)
I1008 01:07:29.388322  5289 sgd_solver.cpp:105] Iteration 40800, lr = 0.01
I1008 01:07:54.024493  5289 solver.cpp:218] Iteration 40900 (4.05943 iter/s, 24.634s/100 iters), loss = 0.0931744
I1008 01:07:54.024535  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0931742 (* 1 = 0.0931742 loss)
I1008 01:07:54.024543  5289 sgd_solver.cpp:105] Iteration 40900, lr = 0.01
I1008 01:08:17.462676  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:08:18.446944  5289 solver.cpp:330] Iteration 41000, Testing net (#0)
I1008 01:08:23.333851  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:08:23.541193  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9004
I1008 01:08:23.541227  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.290745 (* 1 = 0.290745 loss)
I1008 01:08:23.694524  5289 solver.cpp:218] Iteration 41000 (3.37066 iter/s, 29.6678s/100 iters), loss = 0.103455
I1008 01:08:23.694560  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.103454 (* 1 = 0.103454 loss)
I1008 01:08:23.694571  5289 sgd_solver.cpp:105] Iteration 41000, lr = 0.01
I1008 01:08:48.859720  5289 solver.cpp:218] Iteration 41100 (3.9741 iter/s, 25.1629s/100 iters), loss = 0.126194
I1008 01:08:48.859812  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.126193 (* 1 = 0.126193 loss)
I1008 01:08:48.859820  5289 sgd_solver.cpp:105] Iteration 41100, lr = 0.01
I1008 01:09:13.539818  5289 solver.cpp:218] Iteration 41200 (4.05248 iter/s, 24.6762s/100 iters), loss = 0.144356
I1008 01:09:13.539862  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.144356 (* 1 = 0.144356 loss)
I1008 01:09:13.539870  5289 sgd_solver.cpp:105] Iteration 41200, lr = 0.01
I1008 01:09:38.222921  5289 solver.cpp:218] Iteration 41300 (4.05172 iter/s, 24.6809s/100 iters), loss = 0.139791
I1008 01:09:38.223011  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.139791 (* 1 = 0.139791 loss)
I1008 01:09:38.223021  5289 sgd_solver.cpp:105] Iteration 41300, lr = 0.01
I1008 01:10:02.808878  5289 solver.cpp:218] Iteration 41400 (4.06774 iter/s, 24.5837s/100 iters), loss = 0.0428198
I1008 01:10:02.808917  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0428197 (* 1 = 0.0428197 loss)
I1008 01:10:02.808924  5289 sgd_solver.cpp:105] Iteration 41400, lr = 0.01
I1008 01:10:26.251265  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:10:27.234550  5289 solver.cpp:330] Iteration 41500, Testing net (#0)
I1008 01:10:32.109735  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:10:32.296672  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9032
I1008 01:10:32.296700  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.284196 (* 1 = 0.284196 loss)
I1008 01:10:32.502985  5289 solver.cpp:218] Iteration 41500 (3.36793 iter/s, 29.6918s/100 iters), loss = 0.102795
I1008 01:10:32.503017  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.102794 (* 1 = 0.102794 loss)
I1008 01:10:32.503026  5289 sgd_solver.cpp:105] Iteration 41500, lr = 0.01
I1008 01:10:57.720253  5289 solver.cpp:218] Iteration 41600 (3.96622 iter/s, 25.2129s/100 iters), loss = 0.154386
I1008 01:10:57.720366  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.154386 (* 1 = 0.154386 loss)
I1008 01:10:57.720376  5289 sgd_solver.cpp:105] Iteration 41600, lr = 0.01
I1008 01:11:22.362428  5289 solver.cpp:218] Iteration 41700 (4.05846 iter/s, 24.6399s/100 iters), loss = 0.175524
I1008 01:11:22.362470  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.175524 (* 1 = 0.175524 loss)
I1008 01:11:22.362478  5289 sgd_solver.cpp:105] Iteration 41700, lr = 0.01
I1008 01:11:47.024411  5289 solver.cpp:218] Iteration 41800 (4.05519 iter/s, 24.6597s/100 iters), loss = 0.104593
I1008 01:11:47.024499  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.104592 (* 1 = 0.104592 loss)
I1008 01:11:47.024508  5289 sgd_solver.cpp:105] Iteration 41800, lr = 0.01
I1008 01:12:11.672034  5289 solver.cpp:218] Iteration 41900 (4.05756 iter/s, 24.6454s/100 iters), loss = 0.0334608
I1008 01:12:11.672070  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0334606 (* 1 = 0.0334606 loss)
I1008 01:12:11.672080  5289 sgd_solver.cpp:105] Iteration 41900, lr = 0.01
I1008 01:12:35.110007  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:12:36.093210  5289 solver.cpp:330] Iteration 42000, Testing net (#0)
I1008 01:12:40.732456  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:12:40.898890  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9023
I1008 01:12:40.898919  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.282859 (* 1 = 0.282859 loss)
I1008 01:12:41.116271  5289 solver.cpp:218] Iteration 42000 (3.39651 iter/s, 29.4419s/100 iters), loss = 0.0931389
I1008 01:12:41.116307  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0931387 (* 1 = 0.0931387 loss)
I1008 01:12:41.116325  5289 sgd_solver.cpp:105] Iteration 42000, lr = 0.01
I1008 01:13:06.407258  5289 solver.cpp:218] Iteration 42100 (3.954 iter/s, 25.2908s/100 iters), loss = 0.101538
I1008 01:13:06.407340  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.101538 (* 1 = 0.101538 loss)
I1008 01:13:06.407351  5289 sgd_solver.cpp:105] Iteration 42100, lr = 0.01
I1008 01:13:31.074090  5289 solver.cpp:218] Iteration 42200 (4.0544 iter/s, 24.6646s/100 iters), loss = 0.211904
I1008 01:13:31.074123  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.211903 (* 1 = 0.211903 loss)
I1008 01:13:31.074131  5289 sgd_solver.cpp:105] Iteration 42200, lr = 0.01
I1008 01:13:55.751333  5289 solver.cpp:218] Iteration 42300 (4.05304 iter/s, 24.6728s/100 iters), loss = 0.0597653
I1008 01:13:55.751411  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0597651 (* 1 = 0.0597651 loss)
I1008 01:13:55.751420  5289 sgd_solver.cpp:105] Iteration 42300, lr = 0.01
I1008 01:14:20.421946  5289 solver.cpp:218] Iteration 42400 (4.05413 iter/s, 24.6662s/100 iters), loss = 0.102413
I1008 01:14:20.421986  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.102412 (* 1 = 0.102412 loss)
I1008 01:14:20.421993  5289 sgd_solver.cpp:105] Iteration 42400, lr = 0.01
I1008 01:14:43.862226  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:14:44.847435  5289 solver.cpp:330] Iteration 42500, Testing net (#0)
I1008 01:14:49.386859  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:14:49.542744  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9041
I1008 01:14:49.542774  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.288418 (* 1 = 0.288418 loss)
I1008 01:14:49.758039  5289 solver.cpp:218] Iteration 42500 (3.40905 iter/s, 29.3337s/100 iters), loss = 0.0747254
I1008 01:14:49.758078  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0747252 (* 1 = 0.0747252 loss)
I1008 01:14:49.758087  5289 sgd_solver.cpp:105] Iteration 42500, lr = 0.01
I1008 01:15:15.144357  5289 solver.cpp:218] Iteration 42600 (3.93948 iter/s, 25.3841s/100 iters), loss = 0.104071
I1008 01:15:15.144460  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.104071 (* 1 = 0.104071 loss)
I1008 01:15:15.144476  5289 sgd_solver.cpp:105] Iteration 42600, lr = 0.01
I1008 01:15:39.774478  5289 solver.cpp:218] Iteration 42700 (4.06044 iter/s, 24.6279s/100 iters), loss = 0.119638
I1008 01:15:39.774513  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.119638 (* 1 = 0.119638 loss)
I1008 01:15:39.774521  5289 sgd_solver.cpp:105] Iteration 42700, lr = 0.01
I1008 01:16:04.409535  5289 solver.cpp:218] Iteration 42800 (4.05963 iter/s, 24.6328s/100 iters), loss = 0.100154
I1008 01:16:04.409639  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.100154 (* 1 = 0.100154 loss)
I1008 01:16:04.409648  5289 sgd_solver.cpp:105] Iteration 42800, lr = 0.01
I1008 01:16:29.055661  5289 solver.cpp:218] Iteration 42900 (4.05781 iter/s, 24.6438s/100 iters), loss = 0.0640808
I1008 01:16:29.055706  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0640807 (* 1 = 0.0640807 loss)
I1008 01:16:29.055712  5289 sgd_solver.cpp:105] Iteration 42900, lr = 0.01
I1008 01:16:52.495615  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:16:53.478242  5289 solver.cpp:330] Iteration 43000, Testing net (#0)
I1008 01:16:58.141367  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:16:58.319242  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9061
I1008 01:16:58.319269  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.292412 (* 1 = 0.292412 loss)
I1008 01:16:58.487381  5289 solver.cpp:218] Iteration 43000 (3.39814 iter/s, 29.4278s/100 iters), loss = 0.0984176
I1008 01:16:58.487412  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0984174 (* 1 = 0.0984174 loss)
I1008 01:16:58.487419  5289 sgd_solver.cpp:105] Iteration 43000, lr = 0.01
I1008 01:17:23.812607  5289 solver.cpp:218] Iteration 43100 (3.94898 iter/s, 25.323s/100 iters), loss = 0.0820011
I1008 01:17:23.812675  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0820009 (* 1 = 0.0820009 loss)
I1008 01:17:23.812685  5289 sgd_solver.cpp:105] Iteration 43100, lr = 0.01
I1008 01:17:48.469025  5289 solver.cpp:218] Iteration 43200 (4.05577 iter/s, 24.6562s/100 iters), loss = 0.122194
I1008 01:17:48.469069  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.122194 (* 1 = 0.122194 loss)
I1008 01:17:48.469076  5289 sgd_solver.cpp:105] Iteration 43200, lr = 0.01
I1008 01:18:13.138239  5289 solver.cpp:218] Iteration 43300 (4.05435 iter/s, 24.6648s/100 iters), loss = 0.115226
I1008 01:18:13.138324  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.115225 (* 1 = 0.115225 loss)
I1008 01:18:13.138334  5289 sgd_solver.cpp:105] Iteration 43300, lr = 0.01
I1008 01:18:37.786100  5289 solver.cpp:218] Iteration 43400 (4.05752 iter/s, 24.6456s/100 iters), loss = 0.0816088
I1008 01:18:37.786137  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0816087 (* 1 = 0.0816087 loss)
I1008 01:18:37.786156  5289 sgd_solver.cpp:105] Iteration 43400, lr = 0.01
I1008 01:19:01.217525  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:19:02.201464  5289 solver.cpp:330] Iteration 43500, Testing net (#0)
I1008 01:19:06.894600  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:19:07.055922  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.903
I1008 01:19:07.055949  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.304386 (* 1 = 0.304386 loss)
I1008 01:19:07.245782  5289 solver.cpp:218] Iteration 43500 (3.3949 iter/s, 29.456s/100 iters), loss = 0.0342261
I1008 01:19:07.245817  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.034226 (* 1 = 0.034226 loss)
I1008 01:19:07.245824  5289 sgd_solver.cpp:105] Iteration 43500, lr = 0.01
I1008 01:19:32.655182  5289 solver.cpp:218] Iteration 43600 (3.93557 iter/s, 25.4093s/100 iters), loss = 0.0942812
I1008 01:19:32.655270  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.094281 (* 1 = 0.094281 loss)
I1008 01:19:32.655278  5289 sgd_solver.cpp:105] Iteration 43600, lr = 0.01
I1008 01:19:57.308377  5289 solver.cpp:218] Iteration 43700 (4.05664 iter/s, 24.6509s/100 iters), loss = 0.141266
I1008 01:19:57.308411  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.141266 (* 1 = 0.141266 loss)
I1008 01:19:57.308418  5289 sgd_solver.cpp:105] Iteration 43700, lr = 0.01
I1008 01:20:21.980024  5289 solver.cpp:218] Iteration 43800 (4.05389 iter/s, 24.6677s/100 iters), loss = 0.11689
I1008 01:20:21.980109  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.11689 (* 1 = 0.11689 loss)
I1008 01:20:21.980118  5289 sgd_solver.cpp:105] Iteration 43800, lr = 0.01
I1008 01:20:46.626904  5289 solver.cpp:218] Iteration 43900 (4.05768 iter/s, 24.6446s/100 iters), loss = 0.0832571
I1008 01:20:46.626936  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0832569 (* 1 = 0.0832569 loss)
I1008 01:20:46.626943  5289 sgd_solver.cpp:105] Iteration 43900, lr = 0.01
I1008 01:21:10.065932  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:21:11.047261  5289 solver.cpp:330] Iteration 44000, Testing net (#0)
I1008 01:21:15.608428  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:21:15.794827  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9044
I1008 01:21:15.794854  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.290597 (* 1 = 0.290597 loss)
I1008 01:21:15.945588  5289 solver.cpp:218] Iteration 44000 (3.41131 iter/s, 29.3143s/100 iters), loss = 0.036354
I1008 01:21:15.945619  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0363538 (* 1 = 0.0363538 loss)
I1008 01:21:15.945626  5289 sgd_solver.cpp:105] Iteration 44000, lr = 0.01
I1008 01:21:41.273465  5289 solver.cpp:218] Iteration 44100 (3.94857 iter/s, 25.3256s/100 iters), loss = 0.0725608
I1008 01:21:41.273541  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0725606 (* 1 = 0.0725606 loss)
I1008 01:21:41.273550  5289 sgd_solver.cpp:105] Iteration 44100, lr = 0.01
I1008 01:22:05.936431  5289 solver.cpp:218] Iteration 44200 (4.05527 iter/s, 24.6593s/100 iters), loss = 0.100919
I1008 01:22:05.936475  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.100919 (* 1 = 0.100919 loss)
I1008 01:22:05.936480  5289 sgd_solver.cpp:105] Iteration 44200, lr = 0.01
I1008 01:22:30.606597  5289 solver.cpp:218] Iteration 44300 (4.05385 iter/s, 24.6679s/100 iters), loss = 0.0652393
I1008 01:22:30.606710  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0652391 (* 1 = 0.0652391 loss)
I1008 01:22:30.606724  5289 sgd_solver.cpp:105] Iteration 44300, lr = 0.01
I1008 01:22:55.241608  5289 solver.cpp:218] Iteration 44400 (4.05964 iter/s, 24.6328s/100 iters), loss = 0.0474948
I1008 01:22:55.241643  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0474946 (* 1 = 0.0474946 loss)
I1008 01:22:55.241652  5289 sgd_solver.cpp:105] Iteration 44400, lr = 0.01
I1008 01:23:18.630209  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:23:19.612810  5289 solver.cpp:330] Iteration 44500, Testing net (#0)
I1008 01:23:24.292243  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:23:24.440650  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9025
I1008 01:23:24.440675  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.299198 (* 1 = 0.299198 loss)
I1008 01:23:24.648636  5289 solver.cpp:218] Iteration 44500 (3.40106 iter/s, 29.4026s/100 iters), loss = 0.0466864
I1008 01:23:24.648682  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0466862 (* 1 = 0.0466862 loss)
I1008 01:23:24.648689  5289 sgd_solver.cpp:105] Iteration 44500, lr = 0.01
I1008 01:23:50.049157  5289 solver.cpp:218] Iteration 44600 (3.93728 iter/s, 25.3983s/100 iters), loss = 0.066435
I1008 01:23:50.049237  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0664348 (* 1 = 0.0664348 loss)
I1008 01:23:50.049247  5289 sgd_solver.cpp:105] Iteration 44600, lr = 0.01
I1008 01:24:14.675034  5289 solver.cpp:218] Iteration 44700 (4.06114 iter/s, 24.6236s/100 iters), loss = 0.12749
I1008 01:24:14.675070  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.12749 (* 1 = 0.12749 loss)
I1008 01:24:14.675076  5289 sgd_solver.cpp:105] Iteration 44700, lr = 0.01
I1008 01:24:39.302855  5289 solver.cpp:218] Iteration 44800 (4.06109 iter/s, 24.6239s/100 iters), loss = 0.0779866
I1008 01:24:39.302973  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0779864 (* 1 = 0.0779864 loss)
I1008 01:24:39.302983  5289 sgd_solver.cpp:105] Iteration 44800, lr = 0.01
I1008 01:25:03.943248  5289 solver.cpp:218] Iteration 44900 (4.05875 iter/s, 24.6381s/100 iters), loss = 0.0488022
I1008 01:25:03.943281  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.048802 (* 1 = 0.048802 loss)
I1008 01:25:03.943289  5289 sgd_solver.cpp:105] Iteration 44900, lr = 0.01
I1008 01:25:27.365475  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:25:28.347690  5289 solver.cpp:330] Iteration 45000, Testing net (#0)
I1008 01:25:33.015650  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:25:33.203322  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9044
I1008 01:25:33.203347  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.298622 (* 1 = 0.298622 loss)
I1008 01:25:33.370988  5289 solver.cpp:218] Iteration 45000 (3.39842 iter/s, 29.4255s/100 iters), loss = 0.0666355
I1008 01:25:33.371021  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0666353 (* 1 = 0.0666353 loss)
I1008 01:25:33.371027  5289 sgd_solver.cpp:105] Iteration 45000, lr = 0.01
I1008 01:25:58.805203  5289 solver.cpp:218] Iteration 45100 (3.93206 iter/s, 25.432s/100 iters), loss = 0.0752097
I1008 01:25:58.805279  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0752094 (* 1 = 0.0752094 loss)
I1008 01:25:58.805286  5289 sgd_solver.cpp:105] Iteration 45100, lr = 0.01
I1008 01:26:23.405535  5289 solver.cpp:218] Iteration 45200 (4.06501 iter/s, 24.6002s/100 iters), loss = 0.127016
I1008 01:26:23.405581  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.127016 (* 1 = 0.127016 loss)
I1008 01:26:23.405591  5289 sgd_solver.cpp:105] Iteration 45200, lr = 0.01
I1008 01:26:48.044776  5289 solver.cpp:218] Iteration 45300 (4.05909 iter/s, 24.6361s/100 iters), loss = 0.0503346
I1008 01:26:48.044852  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0503344 (* 1 = 0.0503344 loss)
I1008 01:26:48.044859  5289 sgd_solver.cpp:105] Iteration 45300, lr = 0.01
I1008 01:27:12.694057  5289 solver.cpp:218] Iteration 45400 (4.05729 iter/s, 24.647s/100 iters), loss = 0.0617409
I1008 01:27:12.694092  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0617407 (* 1 = 0.0617407 loss)
I1008 01:27:12.694099  5289 sgd_solver.cpp:105] Iteration 45400, lr = 0.01
I1008 01:27:36.122596  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:27:37.106915  5289 solver.cpp:330] Iteration 45500, Testing net (#0)
I1008 01:27:41.773743  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:27:41.964100  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9057
I1008 01:27:41.964126  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.295993 (* 1 = 0.295993 loss)
I1008 01:27:42.127526  5289 solver.cpp:218] Iteration 45500 (3.39775 iter/s, 29.4312s/100 iters), loss = 0.0405603
I1008 01:27:42.127566  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0405601 (* 1 = 0.0405601 loss)
I1008 01:27:42.127573  5289 sgd_solver.cpp:105] Iteration 45500, lr = 0.01
I1008 01:28:07.572244  5289 solver.cpp:218] Iteration 45600 (3.93045 iter/s, 25.4424s/100 iters), loss = 0.0369727
I1008 01:28:07.572329  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0369725 (* 1 = 0.0369725 loss)
I1008 01:28:07.572338  5289 sgd_solver.cpp:105] Iteration 45600, lr = 0.01
I1008 01:28:32.241909  5289 solver.cpp:218] Iteration 45700 (4.05394 iter/s, 24.6674s/100 iters), loss = 0.0939634
I1008 01:28:32.241942  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0939632 (* 1 = 0.0939632 loss)
I1008 01:28:32.241951  5289 sgd_solver.cpp:105] Iteration 45700, lr = 0.01
I1008 01:28:56.863613  5289 solver.cpp:218] Iteration 45800 (4.06183 iter/s, 24.6195s/100 iters), loss = 0.0437411
I1008 01:28:56.863725  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0437408 (* 1 = 0.0437408 loss)
I1008 01:28:56.863737  5289 sgd_solver.cpp:105] Iteration 45800, lr = 0.01
I1008 01:29:21.505101  5289 solver.cpp:218] Iteration 45900 (4.05858 iter/s, 24.6392s/100 iters), loss = 0.0597741
I1008 01:29:21.505134  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0597739 (* 1 = 0.0597739 loss)
I1008 01:29:21.505142  5289 sgd_solver.cpp:105] Iteration 45900, lr = 0.01
I1008 01:29:44.922215  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:29:45.907032  5289 solver.cpp:330] Iteration 46000, Testing net (#0)
I1008 01:29:50.432356  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:29:50.620589  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9018
I1008 01:29:50.620618  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.318247 (* 1 = 0.318247 loss)
I1008 01:29:50.781029  5289 solver.cpp:218] Iteration 46000 (3.41604 iter/s, 29.2737s/100 iters), loss = 0.0746293
I1008 01:29:50.781064  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0746291 (* 1 = 0.0746291 loss)
I1008 01:29:50.781071  5289 sgd_solver.cpp:105] Iteration 46000, lr = 0.01
I1008 01:30:16.126343  5289 solver.cpp:218] Iteration 46100 (3.94552 iter/s, 25.3452s/100 iters), loss = 0.101976
I1008 01:30:16.126408  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.101976 (* 1 = 0.101976 loss)
I1008 01:30:16.126416  5289 sgd_solver.cpp:105] Iteration 46100, lr = 0.01
I1008 01:30:40.669139  5289 solver.cpp:218] Iteration 46200 (4.07489 iter/s, 24.5405s/100 iters), loss = 0.143675
I1008 01:30:40.669186  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.143675 (* 1 = 0.143675 loss)
I1008 01:30:40.669193  5289 sgd_solver.cpp:105] Iteration 46200, lr = 0.01
I1008 01:31:05.335634  5289 solver.cpp:218] Iteration 46300 (4.05469 iter/s, 24.6628s/100 iters), loss = 0.0759684
I1008 01:31:05.335708  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0759682 (* 1 = 0.0759682 loss)
I1008 01:31:05.335716  5289 sgd_solver.cpp:105] Iteration 46300, lr = 0.01
I1008 01:31:30.006657  5289 solver.cpp:218] Iteration 46400 (4.05371 iter/s, 24.6688s/100 iters), loss = 0.014184
I1008 01:31:30.006700  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0141838 (* 1 = 0.0141838 loss)
I1008 01:31:30.006707  5289 sgd_solver.cpp:105] Iteration 46400, lr = 0.01
I1008 01:31:53.445276  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:31:54.430740  5289 solver.cpp:330] Iteration 46500, Testing net (#0)
I1008 01:31:58.936661  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:31:59.140108  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9071
I1008 01:31:59.140135  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.294469 (* 1 = 0.294469 loss)
I1008 01:31:59.286785  5289 solver.cpp:218] Iteration 46500 (3.41555 iter/s, 29.2779s/100 iters), loss = 0.0357224
I1008 01:31:59.286828  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0357222 (* 1 = 0.0357222 loss)
I1008 01:31:59.286834  5289 sgd_solver.cpp:105] Iteration 46500, lr = 0.01
I1008 01:32:24.675467  5289 solver.cpp:218] Iteration 46600 (3.93911 iter/s, 25.3864s/100 iters), loss = 0.0997535
I1008 01:32:24.675546  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0997533 (* 1 = 0.0997533 loss)
I1008 01:32:24.675555  5289 sgd_solver.cpp:105] Iteration 46600, lr = 0.01
I1008 01:32:49.380704  5289 solver.cpp:218] Iteration 46700 (4.0481 iter/s, 24.7029s/100 iters), loss = 0.0511885
I1008 01:32:49.380748  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0511883 (* 1 = 0.0511883 loss)
I1008 01:32:49.380756  5289 sgd_solver.cpp:105] Iteration 46700, lr = 0.01
I1008 01:33:14.031373  5289 solver.cpp:218] Iteration 46800 (4.05726 iter/s, 24.6472s/100 iters), loss = 0.0416167
I1008 01:33:14.031488  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0416165 (* 1 = 0.0416165 loss)
I1008 01:33:14.031502  5289 sgd_solver.cpp:105] Iteration 46800, lr = 0.01
I1008 01:33:38.664727  5289 solver.cpp:218] Iteration 46900 (4.05993 iter/s, 24.631s/100 iters), loss = 0.0359009
I1008 01:33:38.664764  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0359007 (* 1 = 0.0359007 loss)
I1008 01:33:38.664772  5289 sgd_solver.cpp:105] Iteration 46900, lr = 0.01
I1008 01:34:02.099757  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:34:03.080842  5289 solver.cpp:330] Iteration 47000, Testing net (#0)
I1008 01:34:07.634543  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:34:07.831200  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.905
I1008 01:34:07.831225  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.30702 (* 1 = 0.30702 loss)
I1008 01:34:07.976101  5289 solver.cpp:218] Iteration 47000 (3.41191 iter/s, 29.3091s/100 iters), loss = 0.0800056
I1008 01:34:07.976142  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0800054 (* 1 = 0.0800054 loss)
I1008 01:34:07.976150  5289 sgd_solver.cpp:105] Iteration 47000, lr = 0.01
I1008 01:34:33.304841  5289 solver.cpp:218] Iteration 47100 (3.94844 iter/s, 25.3265s/100 iters), loss = 0.108359
I1008 01:34:33.304915  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.108359 (* 1 = 0.108359 loss)
I1008 01:34:33.304924  5289 sgd_solver.cpp:105] Iteration 47100, lr = 0.01
I1008 01:34:57.949070  5289 solver.cpp:218] Iteration 47200 (4.05812 iter/s, 24.642s/100 iters), loss = 0.0900396
I1008 01:34:57.949105  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0900395 (* 1 = 0.0900395 loss)
I1008 01:34:57.949110  5289 sgd_solver.cpp:105] Iteration 47200, lr = 0.01
I1008 01:35:22.602880  5289 solver.cpp:218] Iteration 47300 (4.05654 iter/s, 24.6516s/100 iters), loss = 0.0889192
I1008 01:35:22.602975  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.088919 (* 1 = 0.088919 loss)
I1008 01:35:22.602998  5289 sgd_solver.cpp:105] Iteration 47300, lr = 0.01
I1008 01:35:47.259951  5289 solver.cpp:218] Iteration 47400 (4.056 iter/s, 24.6548s/100 iters), loss = 0.0258563
I1008 01:35:47.259992  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0258561 (* 1 = 0.0258561 loss)
I1008 01:35:47.260012  5289 sgd_solver.cpp:105] Iteration 47400, lr = 0.01
I1008 01:36:10.698132  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:36:11.681963  5289 solver.cpp:330] Iteration 47500, Testing net (#0)
I1008 01:36:16.314468  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:36:16.498621  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9032
I1008 01:36:16.498647  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.316775 (* 1 = 0.316775 loss)
I1008 01:36:16.643918  5289 solver.cpp:218] Iteration 47500 (3.40348 iter/s, 29.3817s/100 iters), loss = 0.0360878
I1008 01:36:16.643951  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0360876 (* 1 = 0.0360876 loss)
I1008 01:36:16.643957  5289 sgd_solver.cpp:105] Iteration 47500, lr = 0.01
I1008 01:36:42.132095  5289 solver.cpp:218] Iteration 47600 (3.92374 iter/s, 25.4859s/100 iters), loss = 0.038203
I1008 01:36:42.132169  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0382028 (* 1 = 0.0382028 loss)
I1008 01:36:42.132176  5289 sgd_solver.cpp:105] Iteration 47600, lr = 0.01
I1008 01:37:06.807759  5289 solver.cpp:218] Iteration 47700 (4.05295 iter/s, 24.6734s/100 iters), loss = 0.0754668
I1008 01:37:06.807790  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0754667 (* 1 = 0.0754667 loss)
I1008 01:37:06.807797  5289 sgd_solver.cpp:105] Iteration 47700, lr = 0.01
I1008 01:37:31.455886  5289 solver.cpp:218] Iteration 47800 (4.05747 iter/s, 24.6459s/100 iters), loss = 0.0701718
I1008 01:37:31.455991  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0701716 (* 1 = 0.0701716 loss)
I1008 01:37:31.456001  5289 sgd_solver.cpp:105] Iteration 47800, lr = 0.01
I1008 01:37:56.100754  5289 solver.cpp:218] Iteration 47900 (4.05802 iter/s, 24.6426s/100 iters), loss = 0.0343368
I1008 01:37:56.100796  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0343367 (* 1 = 0.0343367 loss)
I1008 01:37:56.100803  5289 sgd_solver.cpp:105] Iteration 47900, lr = 0.01
I1008 01:38:19.520882  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:38:20.502950  5289 solver.cpp:330] Iteration 48000, Testing net (#0)
I1008 01:38:25.117826  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:38:25.303186  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.905
I1008 01:38:25.303215  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.31275 (* 1 = 0.31275 loss)
I1008 01:38:25.457257  5289 solver.cpp:218] Iteration 48000 (3.40666 iter/s, 29.3542s/100 iters), loss = 0.0332166
I1008 01:38:25.457299  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0332165 (* 1 = 0.0332165 loss)
I1008 01:38:25.457305  5289 sgd_solver.cpp:105] Iteration 48000, lr = 0.01
I1008 01:38:51.038805  5289 solver.cpp:218] Iteration 48100 (3.90942 iter/s, 25.5793s/100 iters), loss = 0.0487376
I1008 01:38:51.038935  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0487375 (* 1 = 0.0487375 loss)
I1008 01:38:51.038955  5289 sgd_solver.cpp:105] Iteration 48100, lr = 0.01
I1008 01:39:15.639235  5289 solver.cpp:218] Iteration 48200 (4.06551 iter/s, 24.5972s/100 iters), loss = 0.0820657
I1008 01:39:15.639278  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0820656 (* 1 = 0.0820656 loss)
I1008 01:39:15.639286  5289 sgd_solver.cpp:105] Iteration 48200, lr = 0.01
I1008 01:39:40.297359  5289 solver.cpp:218] Iteration 48300 (4.05583 iter/s, 24.6558s/100 iters), loss = 0.0720979
I1008 01:39:40.297493  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0720977 (* 1 = 0.0720977 loss)
I1008 01:39:40.297502  5289 sgd_solver.cpp:105] Iteration 48300, lr = 0.01
I1008 01:40:04.913640  5289 solver.cpp:218] Iteration 48400 (4.06273 iter/s, 24.614s/100 iters), loss = 0.0418087
I1008 01:40:04.913672  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0418085 (* 1 = 0.0418085 loss)
I1008 01:40:04.913679  5289 sgd_solver.cpp:105] Iteration 48400, lr = 0.01
I1008 01:40:28.299296  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:40:29.277688  5289 solver.cpp:330] Iteration 48500, Testing net (#0)
I1008 01:40:33.877518  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:40:34.062922  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9054
I1008 01:40:34.062949  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.328494 (* 1 = 0.328494 loss)
I1008 01:40:34.227752  5289 solver.cpp:218] Iteration 48500 (3.41159 iter/s, 29.3119s/100 iters), loss = 0.0156799
I1008 01:40:34.227787  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0156798 (* 1 = 0.0156798 loss)
I1008 01:40:34.227807  5289 sgd_solver.cpp:105] Iteration 48500, lr = 0.01
I1008 01:40:59.659180  5289 solver.cpp:218] Iteration 48600 (3.93249 iter/s, 25.4292s/100 iters), loss = 0.130274
I1008 01:40:59.659270  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.130273 (* 1 = 0.130273 loss)
I1008 01:40:59.659281  5289 sgd_solver.cpp:105] Iteration 48600, lr = 0.01
I1008 01:41:24.251021  5289 solver.cpp:218] Iteration 48700 (4.06711 iter/s, 24.5875s/100 iters), loss = 0.0863854
I1008 01:41:24.251066  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0863852 (* 1 = 0.0863852 loss)
I1008 01:41:24.251075  5289 sgd_solver.cpp:105] Iteration 48700, lr = 0.01
I1008 01:41:48.899824  5289 solver.cpp:218] Iteration 48800 (4.05736 iter/s, 24.6465s/100 iters), loss = 0.0299277
I1008 01:41:48.899935  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0299276 (* 1 = 0.0299276 loss)
I1008 01:41:48.899945  5289 sgd_solver.cpp:105] Iteration 48800, lr = 0.01
I1008 01:42:13.528609  5289 solver.cpp:218] Iteration 48900 (4.06093 iter/s, 24.6249s/100 iters), loss = 0.0474349
I1008 01:42:13.528661  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0474347 (* 1 = 0.0474347 loss)
I1008 01:42:13.528679  5289 sgd_solver.cpp:105] Iteration 48900, lr = 0.01
I1008 01:42:36.957154  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:42:37.939654  5289 solver.cpp:330] Iteration 49000, Testing net (#0)
I1008 01:42:42.506017  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:42:42.673094  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9067
I1008 01:42:42.673121  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.323638 (* 1 = 0.323638 loss)
I1008 01:42:42.836462  5289 solver.cpp:218] Iteration 49000 (3.41257 iter/s, 29.3034s/100 iters), loss = 0.0576501
I1008 01:42:42.836493  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0576499 (* 1 = 0.0576499 loss)
I1008 01:42:42.836499  5289 sgd_solver.cpp:105] Iteration 49000, lr = 0.01
I1008 01:43:08.305622  5289 solver.cpp:218] Iteration 49100 (3.92667 iter/s, 25.4669s/100 iters), loss = 0.0583117
I1008 01:43:08.305711  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0583115 (* 1 = 0.0583115 loss)
I1008 01:43:08.305719  5289 sgd_solver.cpp:105] Iteration 49100, lr = 0.01
I1008 01:43:32.908555  5289 solver.cpp:218] Iteration 49200 (4.06517 iter/s, 24.5992s/100 iters), loss = 0.0509557
I1008 01:43:32.908588  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0509556 (* 1 = 0.0509556 loss)
I1008 01:43:32.908596  5289 sgd_solver.cpp:105] Iteration 49200, lr = 0.01
I1008 01:43:57.533752  5289 solver.cpp:218] Iteration 49300 (4.06161 iter/s, 24.6208s/100 iters), loss = 0.0501358
I1008 01:43:57.533849  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0501357 (* 1 = 0.0501357 loss)
I1008 01:43:57.533859  5289 sgd_solver.cpp:105] Iteration 49300, lr = 0.01
I1008 01:44:22.148800  5289 solver.cpp:218] Iteration 49400 (4.06293 iter/s, 24.6128s/100 iters), loss = 0.0360558
I1008 01:44:22.148836  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0360556 (* 1 = 0.0360556 loss)
I1008 01:44:22.148844  5289 sgd_solver.cpp:105] Iteration 49400, lr = 0.01
I1008 01:44:45.570188  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:44:46.552579  5289 solver.cpp:330] Iteration 49500, Testing net (#0)
I1008 01:44:51.067663  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:44:51.253618  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9046
I1008 01:44:51.253645  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.336343 (* 1 = 0.336343 loss)
I1008 01:44:51.422605  5289 solver.cpp:218] Iteration 49500 (3.41629 iter/s, 29.2716s/100 iters), loss = 0.0490729
I1008 01:44:51.422639  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0490728 (* 1 = 0.0490728 loss)
I1008 01:44:51.422646  5289 sgd_solver.cpp:105] Iteration 49500, lr = 0.01
I1008 01:45:16.823827  5289 solver.cpp:218] Iteration 49600 (3.93717 iter/s, 25.399s/100 iters), loss = 0.0370298
I1008 01:45:16.823906  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0370297 (* 1 = 0.0370297 loss)
I1008 01:45:16.823915  5289 sgd_solver.cpp:105] Iteration 49600, lr = 0.01
I1008 01:45:41.450826  5289 solver.cpp:218] Iteration 49700 (4.06096 iter/s, 24.6247s/100 iters), loss = 0.0472061
I1008 01:45:41.450872  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.047206 (* 1 = 0.047206 loss)
I1008 01:45:41.450884  5289 sgd_solver.cpp:105] Iteration 49700, lr = 0.01
I1008 01:46:06.093349  5289 solver.cpp:218] Iteration 49800 (4.0584 iter/s, 24.6403s/100 iters), loss = 0.0400655
I1008 01:46:06.093456  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0400654 (* 1 = 0.0400654 loss)
I1008 01:46:06.093466  5289 sgd_solver.cpp:105] Iteration 49800, lr = 0.01
I1008 01:46:30.710938  5289 solver.cpp:218] Iteration 49900 (4.06251 iter/s, 24.6153s/100 iters), loss = 0.04641
I1008 01:46:30.710975  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0464099 (* 1 = 0.0464099 loss)
I1008 01:46:30.710983  5289 sgd_solver.cpp:105] Iteration 49900, lr = 0.01
I1008 01:46:54.123791  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:46:55.110416  5289 solver.cpp:330] Iteration 50000, Testing net (#0)
I1008 01:46:59.651990  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:46:59.846401  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9102
I1008 01:46:59.846436  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.312508 (* 1 = 0.312508 loss)
I1008 01:46:59.974081  5289 solver.cpp:218] Iteration 50000 (3.41754 iter/s, 29.2608s/100 iters), loss = 0.0323046
I1008 01:46:59.974114  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0323045 (* 1 = 0.0323045 loss)
I1008 01:46:59.974122  5289 sgd_solver.cpp:105] Iteration 50000, lr = 0.01
I1008 01:47:25.448272  5289 solver.cpp:218] Iteration 50100 (3.92557 iter/s, 25.474s/100 iters), loss = 0.103997
I1008 01:47:25.448350  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.103997 (* 1 = 0.103997 loss)
I1008 01:47:25.448359  5289 sgd_solver.cpp:105] Iteration 50100, lr = 0.01
I1008 01:47:50.040460  5289 solver.cpp:218] Iteration 50200 (4.06671 iter/s, 24.5899s/100 iters), loss = 0.0667438
I1008 01:47:50.040498  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0667437 (* 1 = 0.0667437 loss)
I1008 01:47:50.040505  5289 sgd_solver.cpp:105] Iteration 50200, lr = 0.01
I1008 01:48:14.649013  5289 solver.cpp:218] Iteration 50300 (4.06425 iter/s, 24.6048s/100 iters), loss = 0.0367858
I1008 01:48:14.649099  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0367856 (* 1 = 0.0367856 loss)
I1008 01:48:14.649107  5289 sgd_solver.cpp:105] Iteration 50300, lr = 0.01
I1008 01:48:39.251889  5289 solver.cpp:218] Iteration 50400 (4.06494 iter/s, 24.6006s/100 iters), loss = 0.0702232
I1008 01:48:39.251936  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0702231 (* 1 = 0.0702231 loss)
I1008 01:48:39.251945  5289 sgd_solver.cpp:105] Iteration 50400, lr = 0.01
I1008 01:49:02.664432  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:49:03.647395  5289 solver.cpp:330] Iteration 50500, Testing net (#0)
I1008 01:49:08.306650  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:49:08.476248  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9079
I1008 01:49:08.476285  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.331567 (* 1 = 0.331567 loss)
I1008 01:49:08.652438  5289 solver.cpp:218] Iteration 50500 (3.40156 iter/s, 29.3982s/100 iters), loss = 0.0218387
I1008 01:49:08.652472  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0218385 (* 1 = 0.0218385 loss)
I1008 01:49:08.652480  5289 sgd_solver.cpp:105] Iteration 50500, lr = 0.01
I1008 01:49:34.155659  5289 solver.cpp:218] Iteration 50600 (3.92142 iter/s, 25.5009s/100 iters), loss = 0.0475634
I1008 01:49:34.155740  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0475633 (* 1 = 0.0475633 loss)
I1008 01:49:34.155748  5289 sgd_solver.cpp:105] Iteration 50600, lr = 0.01
I1008 01:49:58.809545  5289 solver.cpp:218] Iteration 50700 (4.05653 iter/s, 24.6516s/100 iters), loss = 0.0708158
I1008 01:49:58.809581  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0708156 (* 1 = 0.0708156 loss)
I1008 01:49:58.809588  5289 sgd_solver.cpp:105] Iteration 50700, lr = 0.01
I1008 01:50:23.453078  5289 solver.cpp:218] Iteration 50800 (4.05823 iter/s, 24.6413s/100 iters), loss = 0.0709576
I1008 01:50:23.453197  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0709575 (* 1 = 0.0709575 loss)
I1008 01:50:23.453207  5289 sgd_solver.cpp:105] Iteration 50800, lr = 0.01
I1008 01:50:48.104591  5289 solver.cpp:218] Iteration 50900 (4.0572 iter/s, 24.6475s/100 iters), loss = 0.0607626
I1008 01:50:48.104624  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0607625 (* 1 = 0.0607625 loss)
I1008 01:50:48.104631  5289 sgd_solver.cpp:105] Iteration 50900, lr = 0.01
I1008 01:51:11.517086  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:51:12.498620  5289 solver.cpp:330] Iteration 51000, Testing net (#0)
I1008 01:51:17.049926  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:51:17.229759  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9079
I1008 01:51:17.229786  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.333961 (* 1 = 0.333961 loss)
I1008 01:51:17.391661  5289 solver.cpp:218] Iteration 51000 (3.41474 iter/s, 29.2848s/100 iters), loss = 0.0296777
I1008 01:51:17.391703  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0296776 (* 1 = 0.0296776 loss)
I1008 01:51:17.391710  5289 sgd_solver.cpp:105] Iteration 51000, lr = 0.01
I1008 01:51:42.875980  5289 solver.cpp:218] Iteration 51100 (3.924 iter/s, 25.4842s/100 iters), loss = 0.0451491
I1008 01:51:42.876061  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.045149 (* 1 = 0.045149 loss)
I1008 01:51:42.876078  5289 sgd_solver.cpp:105] Iteration 51100, lr = 0.01
I1008 01:52:07.503096  5289 solver.cpp:218] Iteration 51200 (4.06113 iter/s, 24.6237s/100 iters), loss = 0.0595345
I1008 01:52:07.503129  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0595343 (* 1 = 0.0595343 loss)
I1008 01:52:07.503135  5289 sgd_solver.cpp:105] Iteration 51200, lr = 0.01
I1008 01:52:32.163353  5289 solver.cpp:218] Iteration 51300 (4.05548 iter/s, 24.658s/100 iters), loss = 0.0281176
I1008 01:52:32.163429  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0281175 (* 1 = 0.0281175 loss)
I1008 01:52:32.163437  5289 sgd_solver.cpp:105] Iteration 51300, lr = 0.01
I1008 01:52:56.776976  5289 solver.cpp:218] Iteration 51400 (4.06317 iter/s, 24.6113s/100 iters), loss = 0.0295451
I1008 01:52:56.777011  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.029545 (* 1 = 0.029545 loss)
I1008 01:52:56.777019  5289 sgd_solver.cpp:105] Iteration 51400, lr = 0.01
I1008 01:53:20.221046  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:53:21.205773  5289 solver.cpp:330] Iteration 51500, Testing net (#0)
I1008 01:53:25.894363  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:53:26.084358  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9018
I1008 01:53:26.084386  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.342721 (* 1 = 0.342721 loss)
I1008 01:53:26.244295  5289 solver.cpp:218] Iteration 51500 (3.39385 iter/s, 29.4651s/100 iters), loss = 0.0380515
I1008 01:53:26.244328  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0380514 (* 1 = 0.0380514 loss)
I1008 01:53:26.244334  5289 sgd_solver.cpp:105] Iteration 51500, lr = 0.01
I1008 01:53:51.735458  5289 solver.cpp:218] Iteration 51600 (3.92317 iter/s, 25.4896s/100 iters), loss = 0.0560005
I1008 01:53:51.735536  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0560003 (* 1 = 0.0560003 loss)
I1008 01:53:51.735551  5289 sgd_solver.cpp:105] Iteration 51600, lr = 0.01
I1008 01:54:16.327499  5289 solver.cpp:218] Iteration 51700 (4.06708 iter/s, 24.5876s/100 iters), loss = 0.0361751
I1008 01:54:16.327538  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0361749 (* 1 = 0.0361749 loss)
I1008 01:54:16.327546  5289 sgd_solver.cpp:105] Iteration 51700, lr = 0.01
I1008 01:54:40.984366  5289 solver.cpp:218] Iteration 51800 (4.05604 iter/s, 24.6546s/100 iters), loss = 0.0289711
I1008 01:54:40.984463  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0289709 (* 1 = 0.0289709 loss)
I1008 01:54:40.984486  5289 sgd_solver.cpp:105] Iteration 51800, lr = 0.01
I1008 01:55:05.630748  5289 solver.cpp:218] Iteration 51900 (4.05776 iter/s, 24.6441s/100 iters), loss = 0.0267635
I1008 01:55:05.630780  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0267634 (* 1 = 0.0267634 loss)
I1008 01:55:05.630789  5289 sgd_solver.cpp:105] Iteration 51900, lr = 0.01
I1008 01:55:29.088470  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:55:30.072407  5289 solver.cpp:330] Iteration 52000, Testing net (#0)
I1008 01:55:34.593844  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:55:34.781169  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9016
I1008 01:55:34.781198  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.342142 (* 1 = 0.342142 loss)
I1008 01:55:34.947058  5289 solver.cpp:218] Iteration 52000 (3.41159 iter/s, 29.3119s/100 iters), loss = 0.0455779
I1008 01:55:34.947093  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0455778 (* 1 = 0.0455778 loss)
I1008 01:55:34.947101  5289 sgd_solver.cpp:105] Iteration 52000, lr = 0.01
I1008 01:56:00.456192  5289 solver.cpp:218] Iteration 52100 (3.92051 iter/s, 25.5069s/100 iters), loss = 0.0541428
I1008 01:56:00.456269  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0541427 (* 1 = 0.0541427 loss)
I1008 01:56:00.456276  5289 sgd_solver.cpp:105] Iteration 52100, lr = 0.01
I1008 01:56:25.028093  5289 solver.cpp:218] Iteration 52200 (4.07007 iter/s, 24.5696s/100 iters), loss = 0.0389157
I1008 01:56:25.028126  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0389156 (* 1 = 0.0389156 loss)
I1008 01:56:25.028132  5289 sgd_solver.cpp:105] Iteration 52200, lr = 0.01
I1008 01:56:49.673177  5289 solver.cpp:218] Iteration 52300 (4.05798 iter/s, 24.6428s/100 iters), loss = 0.0228787
I1008 01:56:49.673261  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0228786 (* 1 = 0.0228786 loss)
I1008 01:56:49.673270  5289 sgd_solver.cpp:105] Iteration 52300, lr = 0.01
I1008 01:57:14.314520  5289 solver.cpp:218] Iteration 52400 (4.0586 iter/s, 24.6391s/100 iters), loss = 0.0364363
I1008 01:57:14.314556  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0364362 (* 1 = 0.0364362 loss)
I1008 01:57:14.314564  5289 sgd_solver.cpp:105] Iteration 52400, lr = 0.01
I1008 01:57:37.754382  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:57:38.740623  5289 solver.cpp:330] Iteration 52500, Testing net (#0)
I1008 01:57:43.411934  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:57:43.604285  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9042
I1008 01:57:43.604312  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.336254 (* 1 = 0.336254 loss)
I1008 01:57:43.766345  5289 solver.cpp:218] Iteration 52500 (3.39588 iter/s, 29.4474s/100 iters), loss = 0.0309608
I1008 01:57:43.766377  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0309607 (* 1 = 0.0309607 loss)
I1008 01:57:43.766384  5289 sgd_solver.cpp:105] Iteration 52500, lr = 0.01
I1008 01:58:09.277531  5289 solver.cpp:218] Iteration 52600 (3.92019 iter/s, 25.5089s/100 iters), loss = 0.0432096
I1008 01:58:09.277611  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0432095 (* 1 = 0.0432095 loss)
I1008 01:58:09.277621  5289 sgd_solver.cpp:105] Iteration 52600, lr = 0.01
I1008 01:58:33.940302  5289 solver.cpp:218] Iteration 52700 (4.05506 iter/s, 24.6605s/100 iters), loss = 0.0416166
I1008 01:58:33.940343  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0416165 (* 1 = 0.0416165 loss)
I1008 01:58:33.940356  5289 sgd_solver.cpp:105] Iteration 52700, lr = 0.01
I1008 01:58:58.551589  5289 solver.cpp:218] Iteration 52800 (4.06355 iter/s, 24.609s/100 iters), loss = 0.0553878
I1008 01:58:58.551679  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0553877 (* 1 = 0.0553877 loss)
I1008 01:58:58.551692  5289 sgd_solver.cpp:105] Iteration 52800, lr = 0.01
I1008 01:59:23.175696  5289 solver.cpp:218] Iteration 52900 (4.06143 iter/s, 24.6218s/100 iters), loss = 0.00725072
I1008 01:59:23.175732  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00725059 (* 1 = 0.00725059 loss)
I1008 01:59:23.175741  5289 sgd_solver.cpp:105] Iteration 52900, lr = 0.01
I1008 01:59:46.578768  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:59:47.562515  5289 solver.cpp:330] Iteration 53000, Testing net (#0)
I1008 01:59:52.171331  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:59:52.358414  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9031
I1008 01:59:52.358440  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.344369 (* 1 = 0.344369 loss)
I1008 01:59:52.537570  5289 solver.cpp:218] Iteration 53000 (3.40604 iter/s, 29.3596s/100 iters), loss = 0.02328
I1008 01:59:52.537606  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0232798 (* 1 = 0.0232798 loss)
I1008 01:59:52.537613  5289 sgd_solver.cpp:105] Iteration 53000, lr = 0.01
I1008 02:00:18.058476  5289 solver.cpp:218] Iteration 53100 (3.91892 iter/s, 25.5173s/100 iters), loss = 0.024916
I1008 02:00:18.058578  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0249159 (* 1 = 0.0249159 loss)
I1008 02:00:18.058588  5289 sgd_solver.cpp:105] Iteration 53100, lr = 0.01
I1008 02:00:42.795673  5289 solver.cpp:218] Iteration 53200 (4.04296 iter/s, 24.7343s/100 iters), loss = 0.0296487
I1008 02:00:42.795713  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0296486 (* 1 = 0.0296486 loss)
I1008 02:00:42.795720  5289 sgd_solver.cpp:105] Iteration 53200, lr = 0.01
I1008 02:01:07.418063  5289 solver.cpp:218] Iteration 53300 (4.06172 iter/s, 24.6201s/100 iters), loss = 0.0315759
I1008 02:01:07.418166  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0315757 (* 1 = 0.0315757 loss)
I1008 02:01:07.418190  5289 sgd_solver.cpp:105] Iteration 53300, lr = 0.01
I1008 02:01:32.068738  5289 solver.cpp:218] Iteration 53400 (4.05706 iter/s, 24.6484s/100 iters), loss = 0.057088
I1008 02:01:32.068773  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0570878 (* 1 = 0.0570878 loss)
I1008 02:01:32.068792  5289 sgd_solver.cpp:105] Iteration 53400, lr = 0.01
I1008 02:01:55.503301  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:01:56.487653  5289 solver.cpp:330] Iteration 53500, Testing net (#0)
I1008 02:02:01.132942  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:02:01.297473  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9075
I1008 02:02:01.297500  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.339905 (* 1 = 0.339905 loss)
I1008 02:02:01.521405  5289 solver.cpp:218] Iteration 53500 (3.39554 iter/s, 29.4504s/100 iters), loss = 0.0156438
I1008 02:02:01.521437  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0156437 (* 1 = 0.0156437 loss)
I1008 02:02:01.521445  5289 sgd_solver.cpp:105] Iteration 53500, lr = 0.01
I1008 02:02:26.952739  5289 solver.cpp:218] Iteration 53600 (3.93251 iter/s, 25.4291s/100 iters), loss = 0.0265154
I1008 02:02:26.952831  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0265152 (* 1 = 0.0265152 loss)
I1008 02:02:26.952841  5289 sgd_solver.cpp:105] Iteration 53600, lr = 0.01
I1008 02:02:51.595908  5289 solver.cpp:218] Iteration 53700 (4.05809 iter/s, 24.6421s/100 iters), loss = 0.0535999
I1008 02:02:51.595942  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0535998 (* 1 = 0.0535998 loss)
I1008 02:02:51.595949  5289 sgd_solver.cpp:105] Iteration 53700, lr = 0.01
I1008 02:03:16.217195  5289 solver.cpp:218] Iteration 53800 (4.0619 iter/s, 24.619s/100 iters), loss = 0.0748717
I1008 02:03:16.217289  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0748715 (* 1 = 0.0748715 loss)
I1008 02:03:16.217299  5289 sgd_solver.cpp:105] Iteration 53800, lr = 0.01
I1008 02:03:40.857805  5289 solver.cpp:218] Iteration 53900 (4.05871 iter/s, 24.6384s/100 iters), loss = 0.0493334
I1008 02:03:40.857841  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0493333 (* 1 = 0.0493333 loss)
I1008 02:03:40.857847  5289 sgd_solver.cpp:105] Iteration 53900, lr = 0.01
I1008 02:04:04.287845  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:04:05.272398  5289 solver.cpp:330] Iteration 54000, Testing net (#0)
I1008 02:04:09.764955  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:04:09.961043  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8997
I1008 02:04:09.961069  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.370317 (* 1 = 0.370317 loss)
I1008 02:04:10.109205  5289 solver.cpp:218] Iteration 54000 (3.4189 iter/s, 29.2492s/100 iters), loss = 0.0684734
I1008 02:04:10.109243  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0684733 (* 1 = 0.0684733 loss)
I1008 02:04:10.109253  5289 sgd_solver.cpp:105] Iteration 54000, lr = 0.01
I1008 02:04:35.530277  5289 solver.cpp:218] Iteration 54100 (3.9341 iter/s, 25.4188s/100 iters), loss = 0.0470063
I1008 02:04:35.530349  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0470062 (* 1 = 0.0470062 loss)
I1008 02:04:35.530357  5289 sgd_solver.cpp:105] Iteration 54100, lr = 0.01
I1008 02:05:00.385982  5289 solver.cpp:218] Iteration 54200 (4.02334 iter/s, 24.855s/100 iters), loss = 0.0511077
I1008 02:05:00.386027  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0511077 (* 1 = 0.0511077 loss)
I1008 02:05:00.386034  5289 sgd_solver.cpp:105] Iteration 54200, lr = 0.01
I1008 02:05:25.030844  5289 solver.cpp:218] Iteration 54300 (4.05801 iter/s, 24.6426s/100 iters), loss = 0.0533315
I1008 02:05:25.030928  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0533314 (* 1 = 0.0533314 loss)
I1008 02:05:25.030936  5289 sgd_solver.cpp:105] Iteration 54300, lr = 0.01
I1008 02:05:49.684383  5289 solver.cpp:218] Iteration 54400 (4.05659 iter/s, 24.6513s/100 iters), loss = 0.0167863
I1008 02:05:49.684427  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0167862 (* 1 = 0.0167862 loss)
I1008 02:05:49.684434  5289 sgd_solver.cpp:105] Iteration 54400, lr = 0.01
I1008 02:06:13.113090  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:06:14.093149  5289 solver.cpp:330] Iteration 54500, Testing net (#0)
I1008 02:06:18.771929  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:06:18.916923  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9047
I1008 02:06:18.916949  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.345336 (* 1 = 0.345336 loss)
I1008 02:06:19.127434  5289 solver.cpp:218] Iteration 54500 (3.39665 iter/s, 29.4408s/100 iters), loss = 0.029305
I1008 02:06:19.127468  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0293049 (* 1 = 0.0293049 loss)
I1008 02:06:19.127475  5289 sgd_solver.cpp:105] Iteration 54500, lr = 0.01
I1008 02:06:44.403728  5289 solver.cpp:218] Iteration 54600 (3.95663 iter/s, 25.274s/100 iters), loss = 0.043858
I1008 02:06:44.403805  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0438579 (* 1 = 0.0438579 loss)
I1008 02:06:44.403816  5289 sgd_solver.cpp:105] Iteration 54600, lr = 0.01
I1008 02:07:09.302924  5289 solver.cpp:218] Iteration 54700 (4.01656 iter/s, 24.8969s/100 iters), loss = 0.036288
I1008 02:07:09.302963  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0362879 (* 1 = 0.0362879 loss)
I1008 02:07:09.302973  5289 sgd_solver.cpp:105] Iteration 54700, lr = 0.01
I1008 02:07:33.950675  5289 solver.cpp:218] Iteration 54800 (4.05754 iter/s, 24.6455s/100 iters), loss = 0.016774
I1008 02:07:33.950768  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0167739 (* 1 = 0.0167739 loss)
I1008 02:07:33.950791  5289 sgd_solver.cpp:105] Iteration 54800, lr = 0.01
I1008 02:07:58.592440  5289 solver.cpp:218] Iteration 54900 (4.05872 iter/s, 24.6383s/100 iters), loss = 0.0467421
I1008 02:07:58.592473  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.046742 (* 1 = 0.046742 loss)
I1008 02:07:58.592483  5289 sgd_solver.cpp:105] Iteration 54900, lr = 0.01
I1008 02:08:22.037041  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:08:23.019145  5289 solver.cpp:330] Iteration 55000, Testing net (#0)
I1008 02:08:27.682359  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:08:27.892014  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9035
I1008 02:08:27.892050  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.353798 (* 1 = 0.353798 loss)
I1008 02:08:28.038781  5289 solver.cpp:218] Iteration 55000 (3.39643 iter/s, 29.4427s/100 iters), loss = 0.0249873
I1008 02:08:28.038811  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0249872 (* 1 = 0.0249872 loss)
I1008 02:08:28.038817  5289 sgd_solver.cpp:105] Iteration 55000, lr = 0.01
I1008 02:08:53.341840  5289 solver.cpp:218] Iteration 55100 (3.95245 iter/s, 25.3008s/100 iters), loss = 0.0292001
I1008 02:08:53.341917  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0292 (* 1 = 0.0292 loss)
I1008 02:08:53.341925  5289 sgd_solver.cpp:105] Iteration 55100, lr = 0.01
I1008 02:09:18.294916  5289 solver.cpp:218] Iteration 55200 (4.00788 iter/s, 24.9508s/100 iters), loss = 0.0772816
I1008 02:09:18.294955  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0772815 (* 1 = 0.0772815 loss)
I1008 02:09:18.294972  5289 sgd_solver.cpp:105] Iteration 55200, lr = 0.01
I1008 02:09:42.952083  5289 solver.cpp:218] Iteration 55300 (4.05626 iter/s, 24.6533s/100 iters), loss = 0.0195068
I1008 02:09:42.952163  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0195067 (* 1 = 0.0195067 loss)
I1008 02:09:42.952172  5289 sgd_solver.cpp:105] Iteration 55300, lr = 0.01
I1008 02:10:07.610756  5289 solver.cpp:218] Iteration 55400 (4.05605 iter/s, 24.6545s/100 iters), loss = 0.0313121
I1008 02:10:07.610792  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.031312 (* 1 = 0.031312 loss)
I1008 02:10:07.610800  5289 sgd_solver.cpp:105] Iteration 55400, lr = 0.01
I1008 02:10:31.067853  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:10:32.053437  5289 solver.cpp:330] Iteration 55500, Testing net (#0)
I1008 02:10:36.609417  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:10:36.803606  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9035
I1008 02:10:36.803635  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.355135 (* 1 = 0.355135 loss)
I1008 02:10:36.950330  5289 solver.cpp:218] Iteration 55500 (3.40888 iter/s, 29.3352s/100 iters), loss = 0.0290194
I1008 02:10:36.950366  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0290193 (* 1 = 0.0290193 loss)
I1008 02:10:36.950373  5289 sgd_solver.cpp:105] Iteration 55500, lr = 0.01
I1008 02:11:02.003659  5289 solver.cpp:218] Iteration 55600 (3.99151 iter/s, 25.0532s/100 iters), loss = 0.0206085
I1008 02:11:02.003739  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0206084 (* 1 = 0.0206084 loss)
I1008 02:11:02.003747  5289 sgd_solver.cpp:105] Iteration 55600, lr = 0.01
I1008 02:11:26.982339  5289 solver.cpp:218] Iteration 55700 (4.00345 iter/s, 24.9785s/100 iters), loss = 0.0469048
I1008 02:11:26.982373  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0469047 (* 1 = 0.0469047 loss)
I1008 02:11:26.982379  5289 sgd_solver.cpp:105] Iteration 55700, lr = 0.01
I1008 02:11:51.621752  5289 solver.cpp:218] Iteration 55800 (4.05891 iter/s, 24.6372s/100 iters), loss = 0.0115294
I1008 02:11:51.621855  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0115292 (* 1 = 0.0115292 loss)
I1008 02:11:51.621868  5289 sgd_solver.cpp:105] Iteration 55800, lr = 0.01
I1008 02:12:16.261217  5289 solver.cpp:218] Iteration 55900 (4.0589 iter/s, 24.6372s/100 iters), loss = 0.0602028
I1008 02:12:16.261267  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0602027 (* 1 = 0.0602027 loss)
I1008 02:12:16.261274  5289 sgd_solver.cpp:105] Iteration 55900, lr = 0.01
I1008 02:12:39.706866  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:12:40.691486  5289 solver.cpp:330] Iteration 56000, Testing net (#0)
I1008 02:12:45.317339  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:12:45.490468  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9064
I1008 02:12:45.490492  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.352918 (* 1 = 0.352918 loss)
I1008 02:12:45.689952  5289 solver.cpp:218] Iteration 56000 (3.3983 iter/s, 29.4265s/100 iters), loss = 0.0313814
I1008 02:12:45.689988  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0313812 (* 1 = 0.0313812 loss)
I1008 02:12:45.689996  5289 sgd_solver.cpp:105] Iteration 56000, lr = 0.01
I1008 02:13:10.767035  5289 solver.cpp:218] Iteration 56100 (3.98806 iter/s, 25.0748s/100 iters), loss = 0.0676213
I1008 02:13:10.767104  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0676212 (* 1 = 0.0676212 loss)
I1008 02:13:10.767117  5289 sgd_solver.cpp:105] Iteration 56100, lr = 0.01
I1008 02:13:35.809186  5289 solver.cpp:218] Iteration 56200 (3.99396 iter/s, 25.0378s/100 iters), loss = 0.0986593
I1008 02:13:35.809219  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0986592 (* 1 = 0.0986592 loss)
I1008 02:13:35.809226  5289 sgd_solver.cpp:105] Iteration 56200, lr = 0.01
I1008 02:14:00.443568  5289 solver.cpp:218] Iteration 56300 (4.05993 iter/s, 24.631s/100 iters), loss = 0.0298948
I1008 02:14:00.443655  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0298946 (* 1 = 0.0298946 loss)
I1008 02:14:00.443663  5289 sgd_solver.cpp:105] Iteration 56300, lr = 0.01
I1008 02:14:25.089912  5289 solver.cpp:218] Iteration 56400 (4.05777 iter/s, 24.6441s/100 iters), loss = 0.0178245
I1008 02:14:25.089956  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0178244 (* 1 = 0.0178244 loss)
I1008 02:14:25.089962  5289 sgd_solver.cpp:105] Iteration 56400, lr = 0.01
I1008 02:14:48.540189  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:14:49.525285  5289 solver.cpp:330] Iteration 56500, Testing net (#0)
I1008 02:14:54.101320  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:14:54.313146  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9042
I1008 02:14:54.313175  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.35434 (* 1 = 0.35434 loss)
I1008 02:14:54.452605  5289 solver.cpp:218] Iteration 56500 (3.40594 iter/s, 29.3604s/100 iters), loss = 0.0310745
I1008 02:14:54.452639  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0310743 (* 1 = 0.0310743 loss)
I1008 02:14:54.452649  5289 sgd_solver.cpp:105] Iteration 56500, lr = 0.01
I1008 02:15:19.460882  5289 solver.cpp:218] Iteration 56600 (3.99904 iter/s, 25.006s/100 iters), loss = 0.0233125
I1008 02:15:19.460983  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0233124 (* 1 = 0.0233124 loss)
I1008 02:15:19.460994  5289 sgd_solver.cpp:105] Iteration 56600, lr = 0.01
I1008 02:15:44.545902  5289 solver.cpp:218] Iteration 56700 (3.98714 iter/s, 25.0806s/100 iters), loss = 0.0356185
I1008 02:15:44.545946  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0356184 (* 1 = 0.0356184 loss)
I1008 02:15:44.545953  5289 sgd_solver.cpp:105] Iteration 56700, lr = 0.01
I1008 02:16:09.191519  5289 solver.cpp:218] Iteration 56800 (4.05823 iter/s, 24.6413s/100 iters), loss = 0.0927569
I1008 02:16:09.191597  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0927567 (* 1 = 0.0927567 loss)
I1008 02:16:09.191606  5289 sgd_solver.cpp:105] Iteration 56800, lr = 0.01
I1008 02:16:33.826238  5289 solver.cpp:218] Iteration 56900 (4.05968 iter/s, 24.6325s/100 iters), loss = 0.0273548
I1008 02:16:33.826272  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0273547 (* 1 = 0.0273547 loss)
I1008 02:16:33.826279  5289 sgd_solver.cpp:105] Iteration 56900, lr = 0.01
I1008 02:16:57.234807  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:16:58.217432  5289 solver.cpp:330] Iteration 57000, Testing net (#0)
I1008 02:17:02.776787  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:17:02.954845  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8935
I1008 02:17:02.954875  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.422522 (* 1 = 0.422522 loss)
I1008 02:17:03.112709  5289 solver.cpp:218] Iteration 57000 (3.41481 iter/s, 29.2842s/100 iters), loss = 0.010475
I1008 02:17:03.112741  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0104749 (* 1 = 0.0104749 loss)
I1008 02:17:03.112749  5289 sgd_solver.cpp:105] Iteration 57000, lr = 0.01
I1008 02:17:28.101613  5289 solver.cpp:218] Iteration 57100 (4.00214 iter/s, 24.9867s/100 iters), loss = 0.0345919
I1008 02:17:28.101686  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0345918 (* 1 = 0.0345918 loss)
I1008 02:17:28.101696  5289 sgd_solver.cpp:105] Iteration 57100, lr = 0.01
I1008 02:17:53.228688  5289 solver.cpp:218] Iteration 57200 (3.98013 iter/s, 25.1248s/100 iters), loss = 0.00595206
I1008 02:17:53.228727  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00595194 (* 1 = 0.00595194 loss)
I1008 02:17:53.228746  5289 sgd_solver.cpp:105] Iteration 57200, lr = 0.01
I1008 02:18:17.845772  5289 solver.cpp:218] Iteration 57300 (4.06259 iter/s, 24.6148s/100 iters), loss = 0.0285026
I1008 02:18:17.845857  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0285025 (* 1 = 0.0285025 loss)
I1008 02:18:17.845870  5289 sgd_solver.cpp:105] Iteration 57300, lr = 0.01
I1008 02:18:42.440183  5289 solver.cpp:218] Iteration 57400 (4.06634 iter/s, 24.5921s/100 iters), loss = 0.0399779
I1008 02:18:42.440222  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0399778 (* 1 = 0.0399778 loss)
I1008 02:18:42.440232  5289 sgd_solver.cpp:105] Iteration 57400, lr = 0.01
I1008 02:19:05.853333  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:19:06.838022  5289 solver.cpp:330] Iteration 57500, Testing net (#0)
I1008 02:19:11.496435  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:19:11.667975  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9016
I1008 02:19:11.668011  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.369615 (* 1 = 0.369615 loss)
I1008 02:19:11.854485  5289 solver.cpp:218] Iteration 57500 (3.40021 iter/s, 29.4099s/100 iters), loss = 0.0193252
I1008 02:19:11.854516  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.019325 (* 1 = 0.019325 loss)
I1008 02:19:11.854521  5289 sgd_solver.cpp:105] Iteration 57500, lr = 0.01
I1008 02:19:36.938541  5289 solver.cpp:218] Iteration 57600 (3.98696 iter/s, 25.0818s/100 iters), loss = 0.081562
I1008 02:19:36.938613  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0815619 (* 1 = 0.0815619 loss)
I1008 02:19:36.938623  5289 sgd_solver.cpp:105] Iteration 57600, lr = 0.01
I1008 02:20:02.009579  5289 solver.cpp:218] Iteration 57700 (3.98936 iter/s, 25.0667s/100 iters), loss = 0.0261072
I1008 02:20:02.009611  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0261071 (* 1 = 0.0261071 loss)
I1008 02:20:02.009618  5289 sgd_solver.cpp:105] Iteration 57700, lr = 0.01
I1008 02:20:26.633834  5289 solver.cpp:218] Iteration 57800 (4.06141 iter/s, 24.622s/100 iters), loss = 0.0275481
I1008 02:20:26.633927  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0275479 (* 1 = 0.0275479 loss)
I1008 02:20:26.633945  5289 sgd_solver.cpp:105] Iteration 57800, lr = 0.01
I1008 02:20:51.272658  5289 solver.cpp:218] Iteration 57900 (4.05901 iter/s, 24.6365s/100 iters), loss = 0.0206338
I1008 02:20:51.272693  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0206337 (* 1 = 0.0206337 loss)
I1008 02:20:51.272701  5289 sgd_solver.cpp:105] Iteration 57900, lr = 0.01
I1008 02:21:14.686516  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:21:15.671761  5289 solver.cpp:330] Iteration 58000, Testing net (#0)
I1008 02:21:20.329512  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:21:20.502760  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9078
I1008 02:21:20.502787  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.34506 (* 1 = 0.34506 loss)
I1008 02:21:20.674648  5289 solver.cpp:218] Iteration 58000 (3.40155 iter/s, 29.3984s/100 iters), loss = 0.0220652
I1008 02:21:20.674690  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0220651 (* 1 = 0.0220651 loss)
I1008 02:21:20.674696  5289 sgd_solver.cpp:105] Iteration 58000, lr = 0.01
I1008 02:21:45.766682  5289 solver.cpp:218] Iteration 58100 (3.98569 iter/s, 25.0898s/100 iters), loss = 0.0142489
I1008 02:21:45.766763  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0142488 (* 1 = 0.0142488 loss)
I1008 02:21:45.766772  5289 sgd_solver.cpp:105] Iteration 58100, lr = 0.01
I1008 02:22:10.853307  5289 solver.cpp:218] Iteration 58200 (3.98689 iter/s, 25.0822s/100 iters), loss = 0.0449481
I1008 02:22:10.853343  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.044948 (* 1 = 0.044948 loss)
I1008 02:22:10.853350  5289 sgd_solver.cpp:105] Iteration 58200, lr = 0.01
I1008 02:22:35.497660  5289 solver.cpp:218] Iteration 58300 (4.05844 iter/s, 24.64s/100 iters), loss = 0.0494039
I1008 02:22:35.497748  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0494038 (* 1 = 0.0494038 loss)
I1008 02:22:35.497757  5289 sgd_solver.cpp:105] Iteration 58300, lr = 0.01
I1008 02:23:00.157131  5289 solver.cpp:218] Iteration 58400 (4.05561 iter/s, 24.6572s/100 iters), loss = 0.0496124
I1008 02:23:00.157181  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0496123 (* 1 = 0.0496123 loss)
I1008 02:23:00.157188  5289 sgd_solver.cpp:105] Iteration 58400, lr = 0.01
I1008 02:23:23.575049  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:23:24.558403  5289 solver.cpp:330] Iteration 58500, Testing net (#0)
I1008 02:23:29.129374  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:23:29.290652  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9068
I1008 02:23:29.290679  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.359266 (* 1 = 0.359266 loss)
I1008 02:23:29.477486  5289 solver.cpp:218] Iteration 58500 (3.41086 iter/s, 29.3181s/100 iters), loss = 0.00754587
I1008 02:23:29.477519  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00754577 (* 1 = 0.00754577 loss)
I1008 02:23:29.477525  5289 sgd_solver.cpp:105] Iteration 58500, lr = 0.01
I1008 02:23:54.589836  5289 solver.cpp:218] Iteration 58600 (3.98247 iter/s, 25.1101s/100 iters), loss = 0.0497963
I1008 02:23:54.589922  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0497962 (* 1 = 0.0497962 loss)
I1008 02:23:54.589944  5289 sgd_solver.cpp:105] Iteration 58600, lr = 0.01
I1008 02:24:19.599385  5289 solver.cpp:218] Iteration 58700 (3.99883 iter/s, 25.0073s/100 iters), loss = 0.0710436
I1008 02:24:19.599419  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0710435 (* 1 = 0.0710435 loss)
I1008 02:24:19.599426  5289 sgd_solver.cpp:105] Iteration 58700, lr = 0.01
I1008 02:24:44.263779  5289 solver.cpp:218] Iteration 58800 (4.0548 iter/s, 24.6621s/100 iters), loss = 0.0277264
I1008 02:24:44.263869  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0277263 (* 1 = 0.0277263 loss)
I1008 02:24:44.263876  5289 sgd_solver.cpp:105] Iteration 58800, lr = 0.01
I1008 02:25:08.920414  5289 solver.cpp:218] Iteration 58900 (4.05607 iter/s, 24.6544s/100 iters), loss = 0.0410336
I1008 02:25:08.920451  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0410335 (* 1 = 0.0410335 loss)
I1008 02:25:08.920461  5289 sgd_solver.cpp:105] Iteration 58900, lr = 0.01
I1008 02:25:32.381539  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:25:33.365203  5289 solver.cpp:330] Iteration 59000, Testing net (#0)
I1008 02:25:37.937103  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:25:38.099431  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9034
I1008 02:25:38.099458  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.375056 (* 1 = 0.375056 loss)
I1008 02:25:38.277689  5289 solver.cpp:218] Iteration 59000 (3.40677 iter/s, 29.3533s/100 iters), loss = 0.0218709
I1008 02:25:38.277726  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0218708 (* 1 = 0.0218708 loss)
I1008 02:25:38.277734  5289 sgd_solver.cpp:105] Iteration 59000, lr = 0.01
I1008 02:26:03.320544  5289 solver.cpp:218] Iteration 59100 (3.99351 iter/s, 25.0406s/100 iters), loss = 0.0234973
I1008 02:26:03.320623  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0234972 (* 1 = 0.0234972 loss)
I1008 02:26:03.320632  5289 sgd_solver.cpp:105] Iteration 59100, lr = 0.01
I1008 02:26:28.318408  5289 solver.cpp:218] Iteration 59200 (4.0007 iter/s, 24.9956s/100 iters), loss = 0.0364005
I1008 02:26:28.318444  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0364005 (* 1 = 0.0364005 loss)
I1008 02:26:28.318451  5289 sgd_solver.cpp:105] Iteration 59200, lr = 0.01
I1008 02:26:52.922672  5289 solver.cpp:218] Iteration 59300 (4.06471 iter/s, 24.602s/100 iters), loss = 0.0770532
I1008 02:26:52.922776  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0770532 (* 1 = 0.0770532 loss)
I1008 02:26:52.922785  5289 sgd_solver.cpp:105] Iteration 59300, lr = 0.01
I1008 02:27:17.609783  5289 solver.cpp:218] Iteration 59400 (4.05142 iter/s, 24.6827s/100 iters), loss = 0.0146289
I1008 02:27:17.609818  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0146289 (* 1 = 0.0146289 loss)
I1008 02:27:17.609825  5289 sgd_solver.cpp:105] Iteration 59400, lr = 0.01
I1008 02:27:41.042475  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:27:42.026720  5289 solver.cpp:330] Iteration 59500, Testing net (#0)
I1008 02:27:46.563884  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:27:46.755224  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8975
I1008 02:27:46.755252  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.404912 (* 1 = 0.404912 loss)
I1008 02:27:46.901103  5289 solver.cpp:218] Iteration 59500 (3.41434 iter/s, 29.2882s/100 iters), loss = 0.0121486
I1008 02:27:46.901141  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0121485 (* 1 = 0.0121485 loss)
I1008 02:27:46.901147  5289 sgd_solver.cpp:105] Iteration 59500, lr = 0.01
I1008 02:28:12.026868  5289 solver.cpp:218] Iteration 59600 (3.98001 iter/s, 25.1256s/100 iters), loss = 0.02597
I1008 02:28:12.026932  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.02597 (* 1 = 0.02597 loss)
I1008 02:28:12.026954  5289 sgd_solver.cpp:105] Iteration 59600, lr = 0.01
I1008 02:28:37.048665  5289 solver.cpp:218] Iteration 59700 (3.99721 iter/s, 25.0174s/100 iters), loss = 0.0296404
I1008 02:28:37.048698  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0296404 (* 1 = 0.0296404 loss)
I1008 02:28:37.048707  5289 sgd_solver.cpp:105] Iteration 59700, lr = 0.01
I1008 02:29:01.689468  5289 solver.cpp:218] Iteration 59800 (4.05892 iter/s, 24.6371s/100 iters), loss = 0.0119733
I1008 02:29:01.689568  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0119733 (* 1 = 0.0119733 loss)
I1008 02:29:01.689577  5289 sgd_solver.cpp:105] Iteration 59800, lr = 0.01
I1008 02:29:26.335968  5289 solver.cpp:218] Iteration 59900 (4.05797 iter/s, 24.6429s/100 iters), loss = 0.0314376
I1008 02:29:26.336004  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0314375 (* 1 = 0.0314375 loss)
I1008 02:29:26.336010  5289 sgd_solver.cpp:105] Iteration 59900, lr = 0.01
I1008 02:29:49.766002  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:29:50.749047  5289 solver.cpp:330] Iteration 60000, Testing net (#0)
I1008 02:29:55.311442  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:29:55.489522  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9068
I1008 02:29:55.489558  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.36455 (* 1 = 0.36455 loss)
I1008 02:29:55.646592  5289 solver.cpp:218] Iteration 60000 (3.41225 iter/s, 29.3062s/100 iters), loss = 0.0131301
I1008 02:29:55.646627  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.01313 (* 1 = 0.01313 loss)
I1008 02:29:55.646634  5289 sgd_solver.cpp:105] Iteration 60000, lr = 0.01
I1008 02:30:20.738200  5289 solver.cpp:218] Iteration 60100 (3.98576 iter/s, 25.0893s/100 iters), loss = 0.0218455
I1008 02:30:20.738302  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0218454 (* 1 = 0.0218454 loss)
I1008 02:30:20.738312  5289 sgd_solver.cpp:105] Iteration 60100, lr = 0.01
I1008 02:30:45.751368  5289 solver.cpp:218] Iteration 60200 (3.9986 iter/s, 25.0088s/100 iters), loss = 0.0247403
I1008 02:30:45.751406  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0247402 (* 1 = 0.0247402 loss)
I1008 02:30:45.751413  5289 sgd_solver.cpp:105] Iteration 60200, lr = 0.01
I1008 02:31:10.365355  5289 solver.cpp:218] Iteration 60300 (4.0631 iter/s, 24.6117s/100 iters), loss = 0.0358653
I1008 02:31:10.365445  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0358652 (* 1 = 0.0358652 loss)
I1008 02:31:10.365455  5289 sgd_solver.cpp:105] Iteration 60300, lr = 0.01
I1008 02:31:35.029553  5289 solver.cpp:218] Iteration 60400 (4.05518 iter/s, 24.6598s/100 iters), loss = 0.0109962
I1008 02:31:35.029587  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0109962 (* 1 = 0.0109962 loss)
I1008 02:31:35.029594  5289 sgd_solver.cpp:105] Iteration 60400, lr = 0.01
I1008 02:31:58.476045  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:31:59.459663  5289 solver.cpp:330] Iteration 60500, Testing net (#0)
I1008 02:32:04.120427  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:32:04.285238  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8927
I1008 02:32:04.285262  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.422065 (* 1 = 0.422065 loss)
I1008 02:32:04.472218  5289 solver.cpp:218] Iteration 60500 (3.39685 iter/s, 29.439s/100 iters), loss = 0.00757803
I1008 02:32:04.472249  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00757798 (* 1 = 0.00757798 loss)
I1008 02:32:04.472256  5289 sgd_solver.cpp:105] Iteration 60500, lr = 0.01
I1008 02:32:29.535326  5289 solver.cpp:218] Iteration 60600 (3.99029 iter/s, 25.0609s/100 iters), loss = 0.050937
I1008 02:32:29.535405  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.050937 (* 1 = 0.050937 loss)
I1008 02:32:29.535415  5289 sgd_solver.cpp:105] Iteration 60600, lr = 0.01
I1008 02:32:54.660954  5289 solver.cpp:218] Iteration 60700 (3.98036 iter/s, 25.1233s/100 iters), loss = 0.0422372
I1008 02:32:54.661000  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0422371 (* 1 = 0.0422371 loss)
I1008 02:32:54.661008  5289 sgd_solver.cpp:105] Iteration 60700, lr = 0.01
I1008 02:33:19.295234  5289 solver.cpp:218] Iteration 60800 (4.06005 iter/s, 24.6303s/100 iters), loss = 0.0147368
I1008 02:33:19.295322  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0147367 (* 1 = 0.0147367 loss)
I1008 02:33:19.295332  5289 sgd_solver.cpp:105] Iteration 60800, lr = 0.01
I1008 02:33:43.933066  5289 solver.cpp:218] Iteration 60900 (4.05918 iter/s, 24.6355s/100 iters), loss = 0.031506
I1008 02:33:43.933102  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.031506 (* 1 = 0.031506 loss)
I1008 02:33:43.933110  5289 sgd_solver.cpp:105] Iteration 60900, lr = 0.01
I1008 02:34:07.347048  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:34:08.330277  5289 solver.cpp:330] Iteration 61000, Testing net (#0)
I1008 02:34:12.923784  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:34:13.126372  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9019
I1008 02:34:13.126399  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.383981 (* 1 = 0.383981 loss)
I1008 02:34:13.310168  5289 solver.cpp:218] Iteration 61000 (3.40427 iter/s, 29.3748s/100 iters), loss = 0.0128386
I1008 02:34:13.310204  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0128385 (* 1 = 0.0128385 loss)
I1008 02:34:13.310210  5289 sgd_solver.cpp:105] Iteration 61000, lr = 0.01
I1008 02:34:38.316462  5289 solver.cpp:218] Iteration 61100 (3.99969 iter/s, 25.0019s/100 iters), loss = 0.0664591
I1008 02:34:38.316568  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0664591 (* 1 = 0.0664591 loss)
I1008 02:34:38.316584  5289 sgd_solver.cpp:105] Iteration 61100, lr = 0.01
I1008 02:35:03.341246  5289 solver.cpp:218] Iteration 61200 (3.99674 iter/s, 25.0204s/100 iters), loss = 0.0455479
I1008 02:35:03.341280  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0455479 (* 1 = 0.0455479 loss)
I1008 02:35:03.341289  5289 sgd_solver.cpp:105] Iteration 61200, lr = 0.01
I1008 02:35:27.941707  5289 solver.cpp:218] Iteration 61300 (4.06534 iter/s, 24.5982s/100 iters), loss = 0.0469288
I1008 02:35:27.941820  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0469287 (* 1 = 0.0469287 loss)
I1008 02:35:27.941833  5289 sgd_solver.cpp:105] Iteration 61300, lr = 0.01
I1008 02:35:52.601793  5289 solver.cpp:218] Iteration 61400 (4.05551 iter/s, 24.6578s/100 iters), loss = 0.0388026
I1008 02:35:52.601826  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0388025 (* 1 = 0.0388025 loss)
I1008 02:35:52.601835  5289 sgd_solver.cpp:105] Iteration 61400, lr = 0.01
I1008 02:36:16.002900  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:36:16.987005  5289 solver.cpp:330] Iteration 61500, Testing net (#0)
I1008 02:36:21.680199  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:36:21.845546  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9063
I1008 02:36:21.845574  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.373406 (* 1 = 0.373406 loss)
I1008 02:36:22.029160  5289 solver.cpp:218] Iteration 61500 (3.39846 iter/s, 29.4251s/100 iters), loss = 0.0227996
I1008 02:36:22.029191  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0227995 (* 1 = 0.0227995 loss)
I1008 02:36:22.029198  5289 sgd_solver.cpp:105] Iteration 61500, lr = 0.01
I1008 02:36:47.019114  5289 solver.cpp:218] Iteration 61600 (4.00163 iter/s, 24.9898s/100 iters), loss = 0.031867
I1008 02:36:47.019186  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0318669 (* 1 = 0.0318669 loss)
I1008 02:36:47.019196  5289 sgd_solver.cpp:105] Iteration 61600, lr = 0.01
I1008 02:37:12.016809  5289 solver.cpp:218] Iteration 61700 (4.00074 iter/s, 24.9954s/100 iters), loss = 0.0347424
I1008 02:37:12.016841  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0347423 (* 1 = 0.0347423 loss)
I1008 02:37:12.016858  5289 sgd_solver.cpp:105] Iteration 61700, lr = 0.01
I1008 02:37:36.659842  5289 solver.cpp:218] Iteration 61800 (4.05853 iter/s, 24.6395s/100 iters), loss = 0.0152862
I1008 02:37:36.659936  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0152861 (* 1 = 0.0152861 loss)
I1008 02:37:36.659946  5289 sgd_solver.cpp:105] Iteration 61800, lr = 0.01
I1008 02:38:01.311771  5289 solver.cpp:218] Iteration 61900 (4.05712 iter/s, 24.648s/100 iters), loss = 0.0338929
I1008 02:38:01.311807  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0338928 (* 1 = 0.0338928 loss)
I1008 02:38:01.311815  5289 sgd_solver.cpp:105] Iteration 61900, lr = 0.01
I1008 02:38:24.735889  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:38:25.720084  5289 solver.cpp:330] Iteration 62000, Testing net (#0)
I1008 02:38:30.380874  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:38:30.541378  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9023
I1008 02:38:30.541404  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.373756 (* 1 = 0.373756 loss)
I1008 02:38:30.725476  5289 solver.cpp:218] Iteration 62000 (3.40021 iter/s, 29.41s/100 iters), loss = 0.0239335
I1008 02:38:30.725513  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0239334 (* 1 = 0.0239334 loss)
I1008 02:38:30.725522  5289 sgd_solver.cpp:105] Iteration 62000, lr = 0.01
I1008 02:38:55.837361  5289 solver.cpp:218] Iteration 62100 (3.98254 iter/s, 25.1096s/100 iters), loss = 0.115665
I1008 02:38:55.837472  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.115665 (* 1 = 0.115665 loss)
I1008 02:38:55.837481  5289 sgd_solver.cpp:105] Iteration 62100, lr = 0.01
I1008 02:39:20.917583  5289 solver.cpp:218] Iteration 62200 (3.98783 iter/s, 25.0763s/100 iters), loss = 0.00824921
I1008 02:39:20.917620  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0082491 (* 1 = 0.0082491 loss)
I1008 02:39:20.917629  5289 sgd_solver.cpp:105] Iteration 62200, lr = 0.01
I1008 02:39:45.550346  5289 solver.cpp:218] Iteration 62300 (4.06001 iter/s, 24.6305s/100 iters), loss = 0.0317587
I1008 02:39:45.550437  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0317586 (* 1 = 0.0317586 loss)
I1008 02:39:45.550451  5289 sgd_solver.cpp:105] Iteration 62300, lr = 0.01
I1008 02:40:10.194330  5289 solver.cpp:218] Iteration 62400 (4.05816 iter/s, 24.6417s/100 iters), loss = 0.017747
I1008 02:40:10.194375  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0177469 (* 1 = 0.0177469 loss)
I1008 02:40:10.194381  5289 sgd_solver.cpp:105] Iteration 62400, lr = 0.01
I1008 02:40:33.609884  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:40:34.592705  5289 solver.cpp:330] Iteration 62500, Testing net (#0)
I1008 02:40:39.233211  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:40:39.419348  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9048
I1008 02:40:39.419374  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.376138 (* 1 = 0.376138 loss)
I1008 02:40:39.575477  5289 solver.cpp:218] Iteration 62500 (3.4038 iter/s, 29.3789s/100 iters), loss = 0.0573264
I1008 02:40:39.575520  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0573262 (* 1 = 0.0573262 loss)
I1008 02:40:39.575526  5289 sgd_solver.cpp:105] Iteration 62500, lr = 0.01
I1008 02:41:04.606199  5289 solver.cpp:218] Iteration 62600 (3.99512 iter/s, 25.0305s/100 iters), loss = 0.0258006
I1008 02:41:04.606293  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0258005 (* 1 = 0.0258005 loss)
I1008 02:41:04.606304  5289 sgd_solver.cpp:105] Iteration 62600, lr = 0.01
I1008 02:41:29.639263  5289 solver.cpp:218] Iteration 62700 (3.99541 iter/s, 25.0287s/100 iters), loss = 0.044065
I1008 02:41:29.639299  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0440649 (* 1 = 0.0440649 loss)
I1008 02:41:29.639305  5289 sgd_solver.cpp:105] Iteration 62700, lr = 0.01
I1008 02:41:54.306304  5289 solver.cpp:218] Iteration 62800 (4.05437 iter/s, 24.6648s/100 iters), loss = 0.00941444
I1008 02:41:54.306401  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00941434 (* 1 = 0.00941434 loss)
I1008 02:41:54.306412  5289 sgd_solver.cpp:105] Iteration 62800, lr = 0.01
I1008 02:42:18.947676  5289 solver.cpp:218] Iteration 62900 (4.05859 iter/s, 24.6391s/100 iters), loss = 0.00959066
I1008 02:42:18.947720  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00959056 (* 1 = 0.00959056 loss)
I1008 02:42:18.947726  5289 sgd_solver.cpp:105] Iteration 62900, lr = 0.01
I1008 02:42:42.372107  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:42:43.355048  5289 solver.cpp:330] Iteration 63000, Testing net (#0)
I1008 02:42:47.966022  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:42:48.149684  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9048
I1008 02:42:48.149719  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.35491 (* 1 = 0.35491 loss)
I1008 02:42:48.340664  5289 solver.cpp:218] Iteration 63000 (3.40244 iter/s, 29.3907s/100 iters), loss = 0.0119955
I1008 02:42:48.340706  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0119954 (* 1 = 0.0119954 loss)
I1008 02:42:48.340713  5289 sgd_solver.cpp:105] Iteration 63000, lr = 0.01
I1008 02:43:13.385253  5289 solver.cpp:218] Iteration 63100 (3.99324 iter/s, 25.0423s/100 iters), loss = 0.0304048
I1008 02:43:13.385352  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0304047 (* 1 = 0.0304047 loss)
I1008 02:43:13.385366  5289 sgd_solver.cpp:105] Iteration 63100, lr = 0.01
I1008 02:43:38.455122  5289 solver.cpp:218] Iteration 63200 (3.9895 iter/s, 25.0658s/100 iters), loss = 0.00568184
I1008 02:43:38.455169  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00568176 (* 1 = 0.00568176 loss)
I1008 02:43:38.455176  5289 sgd_solver.cpp:105] Iteration 63200, lr = 0.01
I1008 02:44:03.075775  5289 solver.cpp:218] Iteration 63300 (4.06201 iter/s, 24.6184s/100 iters), loss = 0.0244427
I1008 02:44:03.075866  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0244427 (* 1 = 0.0244427 loss)
I1008 02:44:03.075878  5289 sgd_solver.cpp:105] Iteration 63300, lr = 0.01
I1008 02:44:27.734650  5289 solver.cpp:218] Iteration 63400 (4.05601 iter/s, 24.6548s/100 iters), loss = 0.019238
I1008 02:44:27.734683  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0192379 (* 1 = 0.0192379 loss)
I1008 02:44:27.734690  5289 sgd_solver.cpp:105] Iteration 63400, lr = 0.01
I1008 02:44:51.151692  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:44:52.137701  5289 solver.cpp:330] Iteration 63500, Testing net (#0)
I1008 02:44:56.796149  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:44:56.958952  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9048
I1008 02:44:56.958978  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.372084 (* 1 = 0.372084 loss)
I1008 02:44:57.140611  5289 solver.cpp:218] Iteration 63500 (3.40093 iter/s, 29.4037s/100 iters), loss = 0.0184608
I1008 02:44:57.140663  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0184607 (* 1 = 0.0184607 loss)
I1008 02:44:57.140676  5289 sgd_solver.cpp:105] Iteration 63500, lr = 0.01
I1008 02:45:22.269650  5289 solver.cpp:218] Iteration 63600 (3.97984 iter/s, 25.1267s/100 iters), loss = 0.0171667
I1008 02:45:22.269743  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0171667 (* 1 = 0.0171667 loss)
I1008 02:45:22.269757  5289 sgd_solver.cpp:105] Iteration 63600, lr = 0.01
I1008 02:45:47.359728  5289 solver.cpp:218] Iteration 63700 (3.98625 iter/s, 25.0863s/100 iters), loss = 0.0286707
I1008 02:45:47.359769  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0286707 (* 1 = 0.0286707 loss)
I1008 02:45:47.359779  5289 sgd_solver.cpp:105] Iteration 63700, lr = 0.01
I1008 02:46:11.995999  5289 solver.cpp:218] Iteration 63800 (4.05943 iter/s, 24.634s/100 iters), loss = 0.0589047
I1008 02:46:11.996084  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0589047 (* 1 = 0.0589047 loss)
I1008 02:46:11.996098  5289 sgd_solver.cpp:105] Iteration 63800, lr = 0.01
I1008 02:46:36.656970  5289 solver.cpp:218] Iteration 63900 (4.05559 iter/s, 24.6573s/100 iters), loss = 0.00826812
I1008 02:46:36.657007  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00826806 (* 1 = 0.00826806 loss)
I1008 02:46:36.657017  5289 sgd_solver.cpp:105] Iteration 63900, lr = 0.01
I1008 02:47:00.072126  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:47:01.055326  5289 solver.cpp:330] Iteration 64000, Testing net (#0)
I1008 02:47:05.668260  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:47:05.855047  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9055
I1008 02:47:05.855073  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.395688 (* 1 = 0.395688 loss)
I1008 02:47:06.025681  5289 solver.cpp:218] Iteration 64000 (3.40525 iter/s, 29.3665s/100 iters), loss = 0.0336908
I1008 02:47:06.025714  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0336907 (* 1 = 0.0336907 loss)
I1008 02:47:06.025722  5289 sgd_solver.cpp:105] Iteration 64000, lr = 0.01
I1008 02:47:31.192210  5289 solver.cpp:218] Iteration 64100 (3.97422 iter/s, 25.1622s/100 iters), loss = 0.0391592
I1008 02:47:31.192303  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0391592 (* 1 = 0.0391592 loss)
I1008 02:47:31.192317  5289 sgd_solver.cpp:105] Iteration 64100, lr = 0.01
I1008 02:47:56.182993  5289 solver.cpp:218] Iteration 64200 (4.00183 iter/s, 24.9885s/100 iters), loss = 0.0368393
I1008 02:47:56.183027  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0368393 (* 1 = 0.0368393 loss)
I1008 02:47:56.183033  5289 sgd_solver.cpp:105] Iteration 64200, lr = 0.01
I1008 02:48:20.825734  5289 solver.cpp:218] Iteration 64300 (4.05863 iter/s, 24.6388s/100 iters), loss = 0.0205483
I1008 02:48:20.825830  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0205482 (* 1 = 0.0205482 loss)
I1008 02:48:20.825844  5289 sgd_solver.cpp:105] Iteration 64300, lr = 0.01
I1008 02:48:45.462890  5289 solver.cpp:218] Iteration 64400 (4.05928 iter/s, 24.6349s/100 iters), loss = 0.0485573
I1008 02:48:45.462923  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0485572 (* 1 = 0.0485572 loss)
I1008 02:48:45.462939  5289 sgd_solver.cpp:105] Iteration 64400, lr = 0.01
I1008 02:49:08.879251  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:49:09.864032  5289 solver.cpp:330] Iteration 64500, Testing net (#0)
I1008 02:49:14.397240  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:49:14.571631  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9004
I1008 02:49:14.571657  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.404088 (* 1 = 0.404088 loss)
I1008 02:49:14.751611  5289 solver.cpp:218] Iteration 64500 (3.41479 iter/s, 29.2843s/100 iters), loss = 0.00873157
I1008 02:49:14.751646  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00873151 (* 1 = 0.00873151 loss)
I1008 02:49:14.751653  5289 sgd_solver.cpp:105] Iteration 64500, lr = 0.01
I1008 02:49:39.839917  5289 solver.cpp:218] Iteration 64600 (3.98628 iter/s, 25.0861s/100 iters), loss = 0.0367215
I1008 02:49:39.839999  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0367214 (* 1 = 0.0367214 loss)
I1008 02:49:39.840009  5289 sgd_solver.cpp:105] Iteration 64600, lr = 0.01
I1008 02:50:04.923707  5289 solver.cpp:218] Iteration 64700 (3.987 iter/s, 25.0815s/100 iters), loss = 0.0580132
I1008 02:50:04.923743  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0580131 (* 1 = 0.0580131 loss)
I1008 02:50:04.923754  5289 sgd_solver.cpp:105] Iteration 64700, lr = 0.01
I1008 02:50:29.583812  5289 solver.cpp:218] Iteration 64800 (4.05586 iter/s, 24.6557s/100 iters), loss = 0.0499568
I1008 02:50:29.583894  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0499568 (* 1 = 0.0499568 loss)
I1008 02:50:29.583901  5289 sgd_solver.cpp:105] Iteration 64800, lr = 0.01
I1008 02:50:54.231936  5289 solver.cpp:218] Iteration 64900 (4.05779 iter/s, 24.644s/100 iters), loss = 0.0125088
I1008 02:50:54.231976  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0125088 (* 1 = 0.0125088 loss)
I1008 02:50:54.231986  5289 sgd_solver.cpp:105] Iteration 64900, lr = 0.01
I1008 02:51:17.664593  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:51:18.651095  5289 solver.cpp:330] Iteration 65000, Testing net (#0)
I1008 02:51:23.306663  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:51:23.492543  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8994
I1008 02:51:23.492569  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.398332 (* 1 = 0.398332 loss)
I1008 02:51:23.649502  5289 solver.cpp:218] Iteration 65000 (3.39974 iter/s, 29.414s/100 iters), loss = 0.103716
I1008 02:51:23.649533  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.103716 (* 1 = 0.103716 loss)
I1008 02:51:23.649539  5289 sgd_solver.cpp:105] Iteration 65000, lr = 0.01
I1008 02:51:48.687574  5289 solver.cpp:218] Iteration 65100 (3.99428 iter/s, 25.0358s/100 iters), loss = 0.0138071
I1008 02:51:48.687695  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0138071 (* 1 = 0.0138071 loss)
I1008 02:51:48.687705  5289 sgd_solver.cpp:105] Iteration 65100, lr = 0.01
I1008 02:52:13.727880  5289 solver.cpp:218] Iteration 65200 (3.99392 iter/s, 25.0381s/100 iters), loss = 0.00968503
I1008 02:52:13.727922  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00968501 (* 1 = 0.00968501 loss)
I1008 02:52:13.727929  5289 sgd_solver.cpp:105] Iteration 65200, lr = 0.01
I1008 02:52:38.399415  5289 solver.cpp:218] Iteration 65300 (4.05397 iter/s, 24.6671s/100 iters), loss = 0.0287065
I1008 02:52:38.399518  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0287065 (* 1 = 0.0287065 loss)
I1008 02:52:38.399528  5289 sgd_solver.cpp:105] Iteration 65300, lr = 0.01
I1008 02:53:03.051486  5289 solver.cpp:218] Iteration 65400 (4.05683 iter/s, 24.6498s/100 iters), loss = 0.044367
I1008 02:53:03.051522  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0443671 (* 1 = 0.0443671 loss)
I1008 02:53:03.051528  5289 sgd_solver.cpp:105] Iteration 65400, lr = 0.01
I1008 02:53:26.492287  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:53:27.473168  5289 solver.cpp:330] Iteration 65500, Testing net (#0)
I1008 02:53:32.005739  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:53:32.197072  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8992
I1008 02:53:32.197100  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.413078 (* 1 = 0.413078 loss)
I1008 02:53:32.346587  5289 solver.cpp:218] Iteration 65500 (3.4138 iter/s, 29.2929s/100 iters), loss = 0.0423394
I1008 02:53:32.346618  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0423394 (* 1 = 0.0423394 loss)
I1008 02:53:32.346624  5289 sgd_solver.cpp:105] Iteration 65500, lr = 0.01
I1008 02:53:57.346410  5289 solver.cpp:218] Iteration 65600 (4.00005 iter/s, 24.9997s/100 iters), loss = 0.0227743
I1008 02:53:57.346501  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0227743 (* 1 = 0.0227743 loss)
I1008 02:53:57.346510  5289 sgd_solver.cpp:105] Iteration 65600, lr = 0.01
I1008 02:54:22.435271  5289 solver.cpp:218] Iteration 65700 (3.98619 iter/s, 25.0866s/100 iters), loss = 0.0218792
I1008 02:54:22.435302  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0218792 (* 1 = 0.0218792 loss)
I1008 02:54:22.435309  5289 sgd_solver.cpp:105] Iteration 65700, lr = 0.01
I1008 02:54:47.049322  5289 solver.cpp:218] Iteration 65800 (4.0631 iter/s, 24.6118s/100 iters), loss = 0.0154361
I1008 02:54:47.049404  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0154362 (* 1 = 0.0154362 loss)
I1008 02:54:47.049417  5289 sgd_solver.cpp:105] Iteration 65800, lr = 0.01
I1008 02:55:11.691740  5289 solver.cpp:218] Iteration 65900 (4.05842 iter/s, 24.6401s/100 iters), loss = 0.0118874
I1008 02:55:11.691779  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0118874 (* 1 = 0.0118874 loss)
I1008 02:55:11.691789  5289 sgd_solver.cpp:105] Iteration 65900, lr = 0.01
I1008 02:55:35.126660  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:55:36.113113  5289 solver.cpp:330] Iteration 66000, Testing net (#0)
I1008 02:55:40.664724  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:55:40.845398  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8968
I1008 02:55:40.845427  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.431096 (* 1 = 0.431096 loss)
I1008 02:55:40.986436  5289 solver.cpp:218] Iteration 66000 (3.41385 iter/s, 29.2924s/100 iters), loss = 0.0107771
I1008 02:55:40.986482  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0107771 (* 1 = 0.0107771 loss)
I1008 02:55:40.986490  5289 sgd_solver.cpp:105] Iteration 66000, lr = 0.01
I1008 02:56:06.118484  5289 solver.cpp:218] Iteration 66100 (3.97901 iter/s, 25.1319s/100 iters), loss = 0.0123926
I1008 02:56:06.118603  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0123926 (* 1 = 0.0123926 loss)
I1008 02:56:06.118626  5289 sgd_solver.cpp:105] Iteration 66100, lr = 0.01
I1008 02:56:31.208173  5289 solver.cpp:218] Iteration 66200 (3.98606 iter/s, 25.0874s/100 iters), loss = 0.0781239
I1008 02:56:31.208210  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0781239 (* 1 = 0.0781239 loss)
I1008 02:56:31.208220  5289 sgd_solver.cpp:105] Iteration 66200, lr = 0.01
I1008 02:56:55.837894  5289 solver.cpp:218] Iteration 66300 (4.06051 iter/s, 24.6275s/100 iters), loss = 0.0177717
I1008 02:56:55.837980  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0177717 (* 1 = 0.0177717 loss)
I1008 02:56:55.837987  5289 sgd_solver.cpp:105] Iteration 66300, lr = 0.01
I1008 02:57:20.458287  5289 solver.cpp:218] Iteration 66400 (4.06205 iter/s, 24.6181s/100 iters), loss = 0.015471
I1008 02:57:20.458329  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.015471 (* 1 = 0.015471 loss)
I1008 02:57:20.458336  5289 sgd_solver.cpp:105] Iteration 66400, lr = 0.01
I1008 02:57:43.859771  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:57:44.842253  5289 solver.cpp:330] Iteration 66500, Testing net (#0)
I1008 02:57:49.492791  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:57:49.673566  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8937
I1008 02:57:49.673593  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.426882 (* 1 = 0.426882 loss)
I1008 02:57:49.838536  5289 solver.cpp:218] Iteration 66500 (3.40391 iter/s, 29.378s/100 iters), loss = 0.0276837
I1008 02:57:49.838567  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0276838 (* 1 = 0.0276838 loss)
I1008 02:57:49.838574  5289 sgd_solver.cpp:105] Iteration 66500, lr = 0.01
I1008 02:58:15.049175  5289 solver.cpp:218] Iteration 66600 (3.96694 iter/s, 25.2084s/100 iters), loss = 0.0395853
I1008 02:58:15.049273  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0395853 (* 1 = 0.0395853 loss)
I1008 02:58:15.049281  5289 sgd_solver.cpp:105] Iteration 66600, lr = 0.01
I1008 02:58:40.047332  5289 solver.cpp:218] Iteration 66700 (4.00066 iter/s, 24.9959s/100 iters), loss = 0.0654718
I1008 02:58:40.047366  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0654718 (* 1 = 0.0654718 loss)
I1008 02:58:40.047372  5289 sgd_solver.cpp:105] Iteration 66700, lr = 0.01
I1008 02:59:04.703783  5289 solver.cpp:218] Iteration 66800 (4.05611 iter/s, 24.6542s/100 iters), loss = 0.0295715
I1008 02:59:04.703846  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0295715 (* 1 = 0.0295715 loss)
I1008 02:59:04.703855  5289 sgd_solver.cpp:105] Iteration 66800, lr = 0.01
I1008 02:59:29.355810  5289 solver.cpp:218] Iteration 66900 (4.05683 iter/s, 24.6498s/100 iters), loss = 0.0301363
I1008 02:59:29.355845  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0301363 (* 1 = 0.0301363 loss)
I1008 02:59:29.355852  5289 sgd_solver.cpp:105] Iteration 66900, lr = 0.01
I1008 02:59:52.797566  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:59:53.779355  5289 solver.cpp:330] Iteration 67000, Testing net (#0)
I1008 02:59:58.452749  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:59:58.606251  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8964
I1008 02:59:58.606277  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.409233 (* 1 = 0.409233 loss)
I1008 02:59:58.806078  5289 solver.cpp:218] Iteration 67000 (3.39582 iter/s, 29.448s/100 iters), loss = 0.0111328
I1008 02:59:58.806110  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0111328 (* 1 = 0.0111328 loss)
I1008 02:59:58.806118  5289 sgd_solver.cpp:105] Iteration 67000, lr = 0.01
I1008 03:00:23.989599  5289 solver.cpp:218] Iteration 67100 (3.97121 iter/s, 25.1813s/100 iters), loss = 0.0208998
I1008 03:00:23.989709  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0208998 (* 1 = 0.0208998 loss)
I1008 03:00:23.989722  5289 sgd_solver.cpp:105] Iteration 67100, lr = 0.01
I1008 03:00:49.058976  5289 solver.cpp:218] Iteration 67200 (3.98929 iter/s, 25.0671s/100 iters), loss = 0.0638841
I1008 03:00:49.059011  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0638841 (* 1 = 0.0638841 loss)
I1008 03:00:49.059018  5289 sgd_solver.cpp:105] Iteration 67200, lr = 0.01
I1008 03:01:13.681856  5289 solver.cpp:218] Iteration 67300 (4.06183 iter/s, 24.6195s/100 iters), loss = 0.0130639
I1008 03:01:13.681932  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0130639 (* 1 = 0.0130639 loss)
I1008 03:01:13.681941  5289 sgd_solver.cpp:105] Iteration 67300, lr = 0.01
I1008 03:01:38.302587  5289 solver.cpp:218] Iteration 67400 (4.06199 iter/s, 24.6185s/100 iters), loss = 0.0122196
I1008 03:01:38.302623  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0122196 (* 1 = 0.0122196 loss)
I1008 03:01:38.302628  5289 sgd_solver.cpp:105] Iteration 67400, lr = 0.01
I1008 03:02:01.694417  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:02:02.676075  5289 solver.cpp:330] Iteration 67500, Testing net (#0)
I1008 03:02:07.182184  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:02:07.388169  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9051
I1008 03:02:07.388206  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.392034 (* 1 = 0.392034 loss)
I1008 03:02:07.551245  5289 solver.cpp:218] Iteration 67500 (3.41922 iter/s, 29.2464s/100 iters), loss = 0.0229452
I1008 03:02:07.551287  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0229452 (* 1 = 0.0229452 loss)
I1008 03:02:07.551295  5289 sgd_solver.cpp:105] Iteration 67500, lr = 0.01
I1008 03:02:32.601944  5289 solver.cpp:218] Iteration 67600 (3.99261 iter/s, 25.0463s/100 iters), loss = 0.0416262
I1008 03:02:32.602010  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0416262 (* 1 = 0.0416262 loss)
I1008 03:02:32.602018  5289 sgd_solver.cpp:105] Iteration 67600, lr = 0.01
I1008 03:02:57.583626  5289 solver.cpp:218] Iteration 67700 (4.00329 iter/s, 24.9794s/100 iters), loss = 0.0171353
I1008 03:02:57.583657  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0171353 (* 1 = 0.0171353 loss)
I1008 03:02:57.583667  5289 sgd_solver.cpp:105] Iteration 67700, lr = 0.01
I1008 03:03:22.225806  5289 solver.cpp:218] Iteration 67800 (4.05811 iter/s, 24.642s/100 iters), loss = 0.0361516
I1008 03:03:22.225883  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0361516 (* 1 = 0.0361516 loss)
I1008 03:03:22.225894  5289 sgd_solver.cpp:105] Iteration 67800, lr = 0.01
I1008 03:03:46.814971  5289 solver.cpp:218] Iteration 67900 (4.06721 iter/s, 24.5869s/100 iters), loss = 0.041663
I1008 03:03:46.815003  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.041663 (* 1 = 0.041663 loss)
I1008 03:03:46.815011  5289 sgd_solver.cpp:105] Iteration 67900, lr = 0.01
I1008 03:04:10.323945  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:04:11.305804  5289 solver.cpp:330] Iteration 68000, Testing net (#0)
I1008 03:04:15.834832  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:04:16.016243  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9027
I1008 03:04:16.016270  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.37061 (* 1 = 0.37061 loss)
I1008 03:04:16.180377  5289 solver.cpp:218] Iteration 68000 (3.40563 iter/s, 29.3631s/100 iters), loss = 0.00749252
I1008 03:04:16.180408  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00749254 (* 1 = 0.00749254 loss)
I1008 03:04:16.180415  5289 sgd_solver.cpp:105] Iteration 68000, lr = 0.01
I1008 03:04:41.175135  5289 solver.cpp:218] Iteration 68100 (4.00086 iter/s, 24.9946s/100 iters), loss = 0.0293954
I1008 03:04:41.175252  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0293954 (* 1 = 0.0293954 loss)
I1008 03:04:41.175271  5289 sgd_solver.cpp:105] Iteration 68100, lr = 0.01
I1008 03:05:06.065829  5289 solver.cpp:218] Iteration 68200 (4.01793 iter/s, 24.8884s/100 iters), loss = 0.011001
I1008 03:05:06.065860  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.011001 (* 1 = 0.011001 loss)
I1008 03:05:06.065867  5289 sgd_solver.cpp:105] Iteration 68200, lr = 0.01
I1008 03:05:30.805968  5289 solver.cpp:218] Iteration 68300 (4.04213 iter/s, 24.7394s/100 iters), loss = 0.0306534
I1008 03:05:30.806058  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0306534 (* 1 = 0.0306534 loss)
I1008 03:05:30.806069  5289 sgd_solver.cpp:105] Iteration 68300, lr = 0.01
I1008 03:05:55.430991  5289 solver.cpp:218] Iteration 68400 (4.06128 iter/s, 24.6228s/100 iters), loss = 0.0318084
I1008 03:05:55.431036  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0318084 (* 1 = 0.0318084 loss)
I1008 03:05:55.431044  5289 sgd_solver.cpp:105] Iteration 68400, lr = 0.01
I1008 03:06:18.839638  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:06:19.824064  5289 solver.cpp:330] Iteration 68500, Testing net (#0)
I1008 03:06:24.320396  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:06:24.532246  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8989
I1008 03:06:24.532274  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.403042 (* 1 = 0.403042 loss)
I1008 03:06:24.669955  5289 solver.cpp:218] Iteration 68500 (3.42036 iter/s, 29.2367s/100 iters), loss = 0.00713897
I1008 03:06:24.669986  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00713901 (* 1 = 0.00713901 loss)
I1008 03:06:24.669992  5289 sgd_solver.cpp:105] Iteration 68500, lr = 0.01
I1008 03:06:49.677870  5289 solver.cpp:218] Iteration 68600 (3.99909 iter/s, 25.0057s/100 iters), loss = 0.015599
I1008 03:06:49.677949  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0155991 (* 1 = 0.0155991 loss)
I1008 03:06:49.677958  5289 sgd_solver.cpp:105] Iteration 68600, lr = 0.01
I1008 03:07:14.480721  5289 solver.cpp:218] Iteration 68700 (4.03183 iter/s, 24.8026s/100 iters), loss = 0.0483362
I1008 03:07:14.480765  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0483363 (* 1 = 0.0483363 loss)
I1008 03:07:14.480777  5289 sgd_solver.cpp:105] Iteration 68700, lr = 0.01
I1008 03:07:39.353056  5289 solver.cpp:218] Iteration 68800 (4.02056 iter/s, 24.8722s/100 iters), loss = 0.0088036
I1008 03:07:39.353149  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00880365 (* 1 = 0.00880365 loss)
I1008 03:07:39.353163  5289 sgd_solver.cpp:105] Iteration 68800, lr = 0.01
I1008 03:08:03.944281  5289 solver.cpp:218] Iteration 68900 (4.0671 iter/s, 24.5876s/100 iters), loss = 0.00816726
I1008 03:08:03.944316  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0081673 (* 1 = 0.0081673 loss)
I1008 03:08:03.944325  5289 sgd_solver.cpp:105] Iteration 68900, lr = 0.01
I1008 03:08:27.391744  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:08:28.373530  5289 solver.cpp:330] Iteration 69000, Testing net (#0)
I1008 03:08:32.978267  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:08:33.165166  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8921
I1008 03:08:33.165194  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.434959 (* 1 = 0.434959 loss)
I1008 03:08:33.337425  5289 solver.cpp:218] Iteration 69000 (3.40266 iter/s, 29.3888s/100 iters), loss = 0.023357
I1008 03:08:33.337458  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.023357 (* 1 = 0.023357 loss)
I1008 03:08:33.337466  5289 sgd_solver.cpp:105] Iteration 69000, lr = 0.01
I1008 03:08:58.500924  5289 solver.cpp:218] Iteration 69100 (3.9747 iter/s, 25.1592s/100 iters), loss = 0.0388799
I1008 03:08:58.501049  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0388799 (* 1 = 0.0388799 loss)
I1008 03:08:58.501071  5289 sgd_solver.cpp:105] Iteration 69100, lr = 0.01
I1008 03:09:23.277240  5289 solver.cpp:218] Iteration 69200 (4.03674 iter/s, 24.7725s/100 iters), loss = 0.0549243
I1008 03:09:23.277273  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0549244 (* 1 = 0.0549244 loss)
I1008 03:09:23.277281  5289 sgd_solver.cpp:105] Iteration 69200, lr = 0.01
I1008 03:09:48.110342  5289 solver.cpp:218] Iteration 69300 (4.02691 iter/s, 24.833s/100 iters), loss = 0.0166734
I1008 03:09:48.110440  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0166735 (* 1 = 0.0166735 loss)
I1008 03:09:48.110453  5289 sgd_solver.cpp:105] Iteration 69300, lr = 0.01
I1008 03:10:12.728821  5289 solver.cpp:218] Iteration 69400 (4.06237 iter/s, 24.6162s/100 iters), loss = 0.0105016
I1008 03:10:12.728860  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0105016 (* 1 = 0.0105016 loss)
I1008 03:10:12.728870  5289 sgd_solver.cpp:105] Iteration 69400, lr = 0.01
I1008 03:10:36.051425  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:10:37.032030  5289 solver.cpp:330] Iteration 69500, Testing net (#0)
I1008 03:10:41.697926  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:10:41.860527  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8956
I1008 03:10:41.860553  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.420529 (* 1 = 0.420529 loss)
I1008 03:10:42.042768  5289 solver.cpp:218] Iteration 69500 (3.41161 iter/s, 29.3116s/100 iters), loss = 0.0174551
I1008 03:10:42.042799  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0174551 (* 1 = 0.0174551 loss)
I1008 03:10:42.042806  5289 sgd_solver.cpp:105] Iteration 69500, lr = 0.01
I1008 03:11:07.141510  5289 solver.cpp:218] Iteration 69600 (3.98462 iter/s, 25.0965s/100 iters), loss = 0.0252481
I1008 03:11:07.141602  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0252481 (* 1 = 0.0252481 loss)
I1008 03:11:07.141611  5289 sgd_solver.cpp:105] Iteration 69600, lr = 0.01
I1008 03:11:31.783396  5289 solver.cpp:218] Iteration 69700 (4.05885 iter/s, 24.6375s/100 iters), loss = 0.0466321
I1008 03:11:31.783430  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0466321 (* 1 = 0.0466321 loss)
I1008 03:11:31.783437  5289 sgd_solver.cpp:105] Iteration 69700, lr = 0.01
I1008 03:11:56.867085  5289 solver.cpp:218] Iteration 69800 (3.98693 iter/s, 25.082s/100 iters), loss = 0.0173835
I1008 03:11:56.867172  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0173835 (* 1 = 0.0173835 loss)
I1008 03:11:56.867180  5289 sgd_solver.cpp:105] Iteration 69800, lr = 0.01
I1008 03:12:21.516806  5289 solver.cpp:218] Iteration 69900 (4.05721 iter/s, 24.6475s/100 iters), loss = 0.0224322
I1008 03:12:21.516837  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0224322 (* 1 = 0.0224322 loss)
I1008 03:12:21.516845  5289 sgd_solver.cpp:105] Iteration 69900, lr = 0.01
I1008 03:12:44.971827  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:12:45.955559  5289 solver.cpp:330] Iteration 70000, Testing net (#0)
I1008 03:12:50.617244  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:12:50.778125  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8955
I1008 03:12:50.778151  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.431745 (* 1 = 0.431745 loss)
I1008 03:12:50.964578  5289 solver.cpp:218] Iteration 70000 (3.39611 iter/s, 29.4455s/100 iters), loss = 0.0160486
I1008 03:12:50.964608  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0160486 (* 1 = 0.0160486 loss)
I1008 03:12:50.964614  5289 sgd_solver.cpp:105] Iteration 70000, lr = 0.01
I1008 03:13:16.070529  5289 solver.cpp:218] Iteration 70100 (3.98348 iter/s, 25.1037s/100 iters), loss = 0.0404246
I1008 03:13:16.070619  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0404245 (* 1 = 0.0404245 loss)
I1008 03:13:16.070627  5289 sgd_solver.cpp:105] Iteration 70100, lr = 0.01
I1008 03:13:40.725286  5289 solver.cpp:218] Iteration 70200 (4.05638 iter/s, 24.6525s/100 iters), loss = 0.0591313
I1008 03:13:40.725319  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0591313 (* 1 = 0.0591313 loss)
I1008 03:13:40.725327  5289 sgd_solver.cpp:105] Iteration 70200, lr = 0.01
I1008 03:14:05.810778  5289 solver.cpp:218] Iteration 70300 (3.98673 iter/s, 25.0832s/100 iters), loss = 0.0146688
I1008 03:14:05.810845  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0146688 (* 1 = 0.0146688 loss)
I1008 03:14:05.810853  5289 sgd_solver.cpp:105] Iteration 70300, lr = 0.01
I1008 03:14:30.462363  5289 solver.cpp:218] Iteration 70400 (4.05691 iter/s, 24.6493s/100 iters), loss = 0.0319742
I1008 03:14:30.462404  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0319742 (* 1 = 0.0319742 loss)
I1008 03:14:30.462410  5289 sgd_solver.cpp:105] Iteration 70400, lr = 0.01
I1008 03:14:53.885582  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:14:54.869254  5289 solver.cpp:330] Iteration 70500, Testing net (#0)
I1008 03:14:59.547951  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:14:59.691520  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9026
I1008 03:14:59.691547  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.403343 (* 1 = 0.403343 loss)
I1008 03:14:59.904240  5289 solver.cpp:218] Iteration 70500 (3.39678 iter/s, 29.4396s/100 iters), loss = 0.0388372
I1008 03:14:59.904273  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0388372 (* 1 = 0.0388372 loss)
I1008 03:14:59.904280  5289 sgd_solver.cpp:105] Iteration 70500, lr = 0.01
I1008 03:15:24.894547  5289 solver.cpp:218] Iteration 70600 (4.00192 iter/s, 24.988s/100 iters), loss = 0.0330298
I1008 03:15:24.894613  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0330298 (* 1 = 0.0330298 loss)
I1008 03:15:24.894621  5289 sgd_solver.cpp:105] Iteration 70600, lr = 0.01
I1008 03:15:49.544930  5289 solver.cpp:218] Iteration 70700 (4.0571 iter/s, 24.6481s/100 iters), loss = 0.00863367
I1008 03:15:49.544965  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00863368 (* 1 = 0.00863368 loss)
I1008 03:15:49.544971  5289 sgd_solver.cpp:105] Iteration 70700, lr = 0.01
I1008 03:16:14.640745  5289 solver.cpp:218] Iteration 70800 (3.98509 iter/s, 25.0936s/100 iters), loss = 0.045152
I1008 03:16:14.640825  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.045152 (* 1 = 0.045152 loss)
I1008 03:16:14.640833  5289 sgd_solver.cpp:105] Iteration 70800, lr = 0.01
I1008 03:16:39.279105  5289 solver.cpp:218] Iteration 70900 (4.05908 iter/s, 24.6361s/100 iters), loss = 0.0277059
I1008 03:16:39.279140  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0277059 (* 1 = 0.0277059 loss)
I1008 03:16:39.279146  5289 sgd_solver.cpp:105] Iteration 70900, lr = 0.01
I1008 03:17:02.692252  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:17:03.676008  5289 solver.cpp:330] Iteration 71000, Testing net (#0)
I1008 03:17:08.367904  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:17:08.501093  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8999
I1008 03:17:08.501121  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.420023 (* 1 = 0.420023 loss)
I1008 03:17:08.720463  5289 solver.cpp:218] Iteration 71000 (3.39684 iter/s, 29.4391s/100 iters), loss = 0.0163629
I1008 03:17:08.720495  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0163629 (* 1 = 0.0163629 loss)
I1008 03:17:08.720502  5289 sgd_solver.cpp:105] Iteration 71000, lr = 0.01
I1008 03:17:33.804764  5289 solver.cpp:218] Iteration 71100 (3.98658 iter/s, 25.0842s/100 iters), loss = 0.017594
I1008 03:17:33.804848  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.017594 (* 1 = 0.017594 loss)
I1008 03:17:33.804857  5289 sgd_solver.cpp:105] Iteration 71100, lr = 0.01
I1008 03:17:58.450259  5289 solver.cpp:218] Iteration 71200 (4.05791 iter/s, 24.6432s/100 iters), loss = 0.0365267
I1008 03:17:58.450307  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0365267 (* 1 = 0.0365267 loss)
I1008 03:17:58.450314  5289 sgd_solver.cpp:105] Iteration 71200, lr = 0.01
I1008 03:18:23.533511  5289 solver.cpp:218] Iteration 71300 (3.98708 iter/s, 25.081s/100 iters), loss = 0.0329181
I1008 03:18:23.533625  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0329181 (* 1 = 0.0329181 loss)
I1008 03:18:23.533635  5289 sgd_solver.cpp:105] Iteration 71300, lr = 0.01
I1008 03:18:48.175379  5289 solver.cpp:218] Iteration 71400 (4.05851 iter/s, 24.6396s/100 iters), loss = 0.0171409
I1008 03:18:48.175420  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0171409 (* 1 = 0.0171409 loss)
I1008 03:18:48.175426  5289 sgd_solver.cpp:105] Iteration 71400, lr = 0.01
I1008 03:19:11.639122  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:19:12.605445  5289 solver.cpp:330] Iteration 71500, Testing net (#0)
I1008 03:19:17.154574  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:19:17.357154  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8937
I1008 03:19:17.357183  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.433236 (* 1 = 0.433236 loss)
I1008 03:19:17.475704  5289 solver.cpp:218] Iteration 71500 (3.41338 iter/s, 29.2964s/100 iters), loss = 0.00350781
I1008 03:19:17.475738  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00350783 (* 1 = 0.00350783 loss)
I1008 03:19:17.475744  5289 sgd_solver.cpp:105] Iteration 71500, lr = 0.01
I1008 03:19:42.477519  5289 solver.cpp:218] Iteration 71600 (3.99974 iter/s, 25.0016s/100 iters), loss = 0.0269548
I1008 03:19:42.477615  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0269548 (* 1 = 0.0269548 loss)
I1008 03:19:42.477625  5289 sgd_solver.cpp:105] Iteration 71600, lr = 0.01
I1008 03:20:07.127559  5289 solver.cpp:218] Iteration 71700 (4.05742 iter/s, 24.6462s/100 iters), loss = 0.0275348
I1008 03:20:07.127595  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0275348 (* 1 = 0.0275348 loss)
I1008 03:20:07.127602  5289 sgd_solver.cpp:105] Iteration 71700, lr = 0.01
I1008 03:20:32.188868  5289 solver.cpp:218] Iteration 71800 (3.99057 iter/s, 25.0591s/100 iters), loss = 0.0081232
I1008 03:20:32.188943  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00812322 (* 1 = 0.00812322 loss)
I1008 03:20:32.188956  5289 sgd_solver.cpp:105] Iteration 71800, lr = 0.01
I1008 03:20:56.837857  5289 solver.cpp:218] Iteration 71900 (4.05733 iter/s, 24.6467s/100 iters), loss = 0.00755335
I1008 03:20:56.837893  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00755337 (* 1 = 0.00755337 loss)
I1008 03:20:56.837900  5289 sgd_solver.cpp:105] Iteration 71900, lr = 0.01
I1008 03:21:20.252861  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:21:21.238261  5289 solver.cpp:330] Iteration 72000, Testing net (#0)
I1008 03:21:25.904238  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:21:26.060909  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9016
I1008 03:21:26.060936  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.422163 (* 1 = 0.422163 loss)
I1008 03:21:26.259600  5289 solver.cpp:218] Iteration 72000 (3.39911 iter/s, 29.4195s/100 iters), loss = 0.0312548
I1008 03:21:26.259635  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0312548 (* 1 = 0.0312548 loss)
I1008 03:21:26.259642  5289 sgd_solver.cpp:105] Iteration 72000, lr = 0.01
I1008 03:21:51.346804  5289 solver.cpp:218] Iteration 72100 (3.98646 iter/s, 25.0849s/100 iters), loss = 0.0259859
I1008 03:21:51.346890  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0259859 (* 1 = 0.0259859 loss)
I1008 03:21:51.346899  5289 sgd_solver.cpp:105] Iteration 72100, lr = 0.01
I1008 03:22:15.993535  5289 solver.cpp:218] Iteration 72200 (4.05806 iter/s, 24.6423s/100 iters), loss = 0.0189468
I1008 03:22:15.993566  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0189468 (* 1 = 0.0189468 loss)
I1008 03:22:15.993573  5289 sgd_solver.cpp:105] Iteration 72200, lr = 0.01
I1008 03:22:40.979140  5289 solver.cpp:218] Iteration 72300 (4.00293 iter/s, 24.9817s/100 iters), loss = 0.0342459
I1008 03:22:40.979262  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0342459 (* 1 = 0.0342459 loss)
I1008 03:22:40.979272  5289 sgd_solver.cpp:105] Iteration 72300, lr = 0.01
I1008 03:23:05.593669  5289 solver.cpp:218] Iteration 72400 (4.06301 iter/s, 24.6123s/100 iters), loss = 0.0114342
I1008 03:23:05.593706  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0114342 (* 1 = 0.0114342 loss)
I1008 03:23:05.593713  5289 sgd_solver.cpp:105] Iteration 72400, lr = 0.01
I1008 03:23:29.001353  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:23:29.985335  5289 solver.cpp:330] Iteration 72500, Testing net (#0)
I1008 03:23:34.600464  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:23:34.782579  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8876
I1008 03:23:34.782608  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.467103 (* 1 = 0.467103 loss)
I1008 03:23:34.965988  5289 solver.cpp:218] Iteration 72500 (3.40508 iter/s, 29.3679s/100 iters), loss = 0.079638
I1008 03:23:34.966018  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.079638 (* 1 = 0.079638 loss)
I1008 03:23:34.966024  5289 sgd_solver.cpp:105] Iteration 72500, lr = 0.01
I1008 03:24:00.078229  5289 solver.cpp:218] Iteration 72600 (3.98248 iter/s, 25.11s/100 iters), loss = 0.0180619
I1008 03:24:00.078311  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0180618 (* 1 = 0.0180618 loss)
I1008 03:24:00.078321  5289 sgd_solver.cpp:105] Iteration 72600, lr = 0.01
I1008 03:24:24.706694  5289 solver.cpp:218] Iteration 72700 (4.06072 iter/s, 24.6262s/100 iters), loss = 0.00979865
I1008 03:24:24.706729  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00979864 (* 1 = 0.00979864 loss)
I1008 03:24:24.706737  5289 sgd_solver.cpp:105] Iteration 72700, lr = 0.01
I1008 03:24:49.765064  5289 solver.cpp:218] Iteration 72800 (3.99105 iter/s, 25.0561s/100 iters), loss = 0.0826579
I1008 03:24:49.765170  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0826578 (* 1 = 0.0826578 loss)
I1008 03:24:49.765180  5289 sgd_solver.cpp:105] Iteration 72800, lr = 0.01
I1008 03:25:14.379667  5289 solver.cpp:218] Iteration 72900 (4.06301 iter/s, 24.6123s/100 iters), loss = 0.0150792
I1008 03:25:14.379711  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0150792 (* 1 = 0.0150792 loss)
I1008 03:25:14.379719  5289 sgd_solver.cpp:105] Iteration 72900, lr = 0.01
I1008 03:25:37.780177  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:25:38.766229  5289 solver.cpp:330] Iteration 73000, Testing net (#0)
I1008 03:25:43.275131  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:25:43.478878  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9008
I1008 03:25:43.478912  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.40208 (* 1 = 0.40208 loss)
I1008 03:25:43.635948  5289 solver.cpp:218] Iteration 73000 (3.41833 iter/s, 29.254s/100 iters), loss = 0.0170179
I1008 03:25:43.635992  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0170179 (* 1 = 0.0170179 loss)
I1008 03:25:43.635998  5289 sgd_solver.cpp:105] Iteration 73000, lr = 0.01
I1008 03:26:08.700721  5289 solver.cpp:218] Iteration 73100 (3.99037 iter/s, 25.0604s/100 iters), loss = 0.0375397
I1008 03:26:08.700809  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0375397 (* 1 = 0.0375397 loss)
I1008 03:26:08.700819  5289 sgd_solver.cpp:105] Iteration 73100, lr = 0.01
I1008 03:26:33.342314  5289 solver.cpp:218] Iteration 73200 (4.0589 iter/s, 24.6372s/100 iters), loss = 0.0192328
I1008 03:26:33.342353  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0192328 (* 1 = 0.0192328 loss)
I1008 03:26:33.342377  5289 sgd_solver.cpp:105] Iteration 73200, lr = 0.01
I1008 03:26:58.422353  5289 solver.cpp:218] Iteration 73300 (3.98793 iter/s, 25.0757s/100 iters), loss = 0.0177335
I1008 03:26:58.422502  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0177335 (* 1 = 0.0177335 loss)
I1008 03:26:58.422525  5289 sgd_solver.cpp:105] Iteration 73300, lr = 0.01
I1008 03:27:23.029800  5289 solver.cpp:218] Iteration 73400 (4.06453 iter/s, 24.6031s/100 iters), loss = 0.0110598
I1008 03:27:23.029834  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0110598 (* 1 = 0.0110598 loss)
I1008 03:27:23.029840  5289 sgd_solver.cpp:105] Iteration 73400, lr = 0.01
I1008 03:27:46.476909  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:27:47.456076  5289 solver.cpp:330] Iteration 73500, Testing net (#0)
I1008 03:27:52.033427  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:27:52.251956  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8889
I1008 03:27:52.251983  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.464037 (* 1 = 0.464037 loss)
I1008 03:27:52.382257  5289 solver.cpp:218] Iteration 73500 (3.40714 iter/s, 29.3502s/100 iters), loss = 0.0331058
I1008 03:27:52.382299  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0331058 (* 1 = 0.0331058 loss)
I1008 03:27:52.382308  5289 sgd_solver.cpp:105] Iteration 73500, lr = 0.01
I1008 03:28:17.504309  5289 solver.cpp:218] Iteration 73600 (3.98126 iter/s, 25.1177s/100 iters), loss = 0.0220206
I1008 03:28:17.504379  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0220206 (* 1 = 0.0220206 loss)
I1008 03:28:17.504387  5289 sgd_solver.cpp:105] Iteration 73600, lr = 0.01
I1008 03:28:42.067201  5289 solver.cpp:218] Iteration 73700 (4.07155 iter/s, 24.5606s/100 iters), loss = 0.0615457
I1008 03:28:42.067239  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0615457 (* 1 = 0.0615457 loss)
I1008 03:28:42.067246  5289 sgd_solver.cpp:105] Iteration 73700, lr = 0.01
I1008 03:29:07.164679  5289 solver.cpp:218] Iteration 73800 (3.98516 iter/s, 25.0931s/100 iters), loss = 0.0255162
I1008 03:29:07.164750  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0255162 (* 1 = 0.0255162 loss)
I1008 03:29:07.164758  5289 sgd_solver.cpp:105] Iteration 73800, lr = 0.01
I1008 03:29:31.787986  5289 solver.cpp:218] Iteration 73900 (4.06191 iter/s, 24.619s/100 iters), loss = 0.0345222
I1008 03:29:31.788023  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0345222 (* 1 = 0.0345222 loss)
I1008 03:29:31.788030  5289 sgd_solver.cpp:105] Iteration 73900, lr = 0.01
I1008 03:29:55.220631  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:29:56.200996  5289 solver.cpp:330] Iteration 74000, Testing net (#0)
I1008 03:30:00.864585  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:30:01.038550  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.887
I1008 03:30:01.038576  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.490314 (* 1 = 0.490314 loss)
I1008 03:30:01.223321  5289 solver.cpp:218] Iteration 74000 (3.39778 iter/s, 29.4309s/100 iters), loss = 0.0459642
I1008 03:30:01.223353  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0459643 (* 1 = 0.0459643 loss)
I1008 03:30:01.223361  5289 sgd_solver.cpp:105] Iteration 74000, lr = 0.01
I1008 03:30:26.243777  5289 solver.cpp:218] Iteration 74100 (3.9971 iter/s, 25.0182s/100 iters), loss = 0.0345312
I1008 03:30:26.243871  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0345312 (* 1 = 0.0345312 loss)
I1008 03:30:26.243880  5289 sgd_solver.cpp:105] Iteration 74100, lr = 0.01
I1008 03:30:50.893795  5289 solver.cpp:218] Iteration 74200 (4.05716 iter/s, 24.6478s/100 iters), loss = 0.0221489
I1008 03:30:50.893837  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0221489 (* 1 = 0.0221489 loss)
I1008 03:30:50.893844  5289 sgd_solver.cpp:105] Iteration 74200, lr = 0.01
I1008 03:31:15.968166  5289 solver.cpp:218] Iteration 74300 (3.98873 iter/s, 25.0706s/100 iters), loss = 0.0341092
I1008 03:31:15.968263  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0341093 (* 1 = 0.0341093 loss)
I1008 03:31:15.968272  5289 sgd_solver.cpp:105] Iteration 74300, lr = 0.01
I1008 03:31:40.597151  5289 solver.cpp:218] Iteration 74400 (4.06063 iter/s, 24.6267s/100 iters), loss = 0.0374426
I1008 03:31:40.597195  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0374426 (* 1 = 0.0374426 loss)
I1008 03:31:40.597201  5289 sgd_solver.cpp:105] Iteration 74400, lr = 0.01
I1008 03:32:04.032640  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:32:05.016429  5289 solver.cpp:330] Iteration 74500, Testing net (#0)
I1008 03:32:09.543103  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:32:09.731056  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8844
I1008 03:32:09.731087  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.482925 (* 1 = 0.482925 loss)
I1008 03:32:09.888984  5289 solver.cpp:218] Iteration 74500 (3.41444 iter/s, 29.2874s/100 iters), loss = 0.01139
I1008 03:32:09.889014  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.01139 (* 1 = 0.01139 loss)
I1008 03:32:09.889020  5289 sgd_solver.cpp:105] Iteration 74500, lr = 0.01
I1008 03:32:35.008604  5289 solver.cpp:218] Iteration 74600 (3.98097 iter/s, 25.1195s/100 iters), loss = 0.0215032
I1008 03:32:35.008674  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0215032 (* 1 = 0.0215032 loss)
I1008 03:32:35.008682  5289 sgd_solver.cpp:105] Iteration 74600, lr = 0.01
I1008 03:32:59.600618  5289 solver.cpp:218] Iteration 74700 (4.06709 iter/s, 24.5876s/100 iters), loss = 0.0182563
I1008 03:32:59.600659  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0182563 (* 1 = 0.0182563 loss)
I1008 03:32:59.600666  5289 sgd_solver.cpp:105] Iteration 74700, lr = 0.01
I1008 03:33:24.592200  5289 solver.cpp:218] Iteration 74800 (4.00171 iter/s, 24.9893s/100 iters), loss = 0.0143159
I1008 03:33:24.592360  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0143159 (* 1 = 0.0143159 loss)
I1008 03:33:24.592370  5289 sgd_solver.cpp:105] Iteration 74800, lr = 0.01
I1008 03:33:49.180609  5289 solver.cpp:218] Iteration 74900 (4.06755 iter/s, 24.5848s/100 iters), loss = 0.0127303
I1008 03:33:49.180642  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0127303 (* 1 = 0.0127303 loss)
I1008 03:33:49.180649  5289 sgd_solver.cpp:105] Iteration 74900, lr = 0.01
I1008 03:34:12.661665  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:34:13.644381  5289 solver.cpp:330] Iteration 75000, Testing net (#0)
I1008 03:34:18.279258  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:34:18.447393  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8864
I1008 03:34:18.447422  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.477464 (* 1 = 0.477464 loss)
I1008 03:34:18.653446  5289 solver.cpp:218] Iteration 75000 (3.39321 iter/s, 29.4706s/100 iters), loss = 0.0255741
I1008 03:34:18.653476  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0255742 (* 1 = 0.0255742 loss)
I1008 03:34:18.653483  5289 sgd_solver.cpp:105] Iteration 75000, lr = 0.01
I1008 03:34:43.680512  5289 solver.cpp:218] Iteration 75100 (3.99603 iter/s, 25.0248s/100 iters), loss = 0.0368517
I1008 03:34:43.680618  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0368518 (* 1 = 0.0368518 loss)
I1008 03:34:43.680627  5289 sgd_solver.cpp:105] Iteration 75100, lr = 0.01
I1008 03:35:08.334142  5289 solver.cpp:218] Iteration 75200 (4.05657 iter/s, 24.6514s/100 iters), loss = 0.0364056
I1008 03:35:08.334180  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0364056 (* 1 = 0.0364056 loss)
I1008 03:35:08.334199  5289 sgd_solver.cpp:105] Iteration 75200, lr = 0.01
I1008 03:35:33.327097  5289 solver.cpp:218] Iteration 75300 (4.00149 iter/s, 24.9907s/100 iters), loss = 0.0209755
I1008 03:35:33.327215  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0209755 (* 1 = 0.0209755 loss)
I1008 03:35:33.327236  5289 sgd_solver.cpp:105] Iteration 75300, lr = 0.01
I1008 03:35:57.970057  5289 solver.cpp:218] Iteration 75400 (4.05833 iter/s, 24.6407s/100 iters), loss = 0.0397934
I1008 03:35:57.970088  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0397933 (* 1 = 0.0397933 loss)
I1008 03:35:57.970094  5289 sgd_solver.cpp:105] Iteration 75400, lr = 0.01
I1008 03:36:21.391716  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:36:22.375910  5289 solver.cpp:330] Iteration 75500, Testing net (#0)
I1008 03:36:27.050774  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:36:27.222710  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8997
I1008 03:36:27.222746  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.42608 (* 1 = 0.42608 loss)
I1008 03:36:27.406409  5289 solver.cpp:218] Iteration 75500 (3.39742 iter/s, 29.4341s/100 iters), loss = 0.00995532
I1008 03:36:27.406453  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0099553 (* 1 = 0.0099553 loss)
I1008 03:36:27.406460  5289 sgd_solver.cpp:105] Iteration 75500, lr = 0.01
I1008 03:36:52.504084  5289 solver.cpp:218] Iteration 75600 (3.9848 iter/s, 25.0954s/100 iters), loss = 0.0101925
I1008 03:36:52.504161  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0101925 (* 1 = 0.0101925 loss)
I1008 03:36:52.504173  5289 sgd_solver.cpp:105] Iteration 75600, lr = 0.01
I1008 03:37:17.148857  5289 solver.cpp:218] Iteration 75700 (4.05802 iter/s, 24.6425s/100 iters), loss = 0.0200529
I1008 03:37:17.148900  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0200529 (* 1 = 0.0200529 loss)
I1008 03:37:17.148906  5289 sgd_solver.cpp:105] Iteration 75700, lr = 0.01
I1008 03:37:42.199970  5289 solver.cpp:218] Iteration 75800 (3.9922 iter/s, 25.0489s/100 iters), loss = 0.039344
I1008 03:37:42.200070  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.039344 (* 1 = 0.039344 loss)
I1008 03:37:42.200078  5289 sgd_solver.cpp:105] Iteration 75800, lr = 0.01
I1008 03:38:06.829932  5289 solver.cpp:218] Iteration 75900 (4.06047 iter/s, 24.6277s/100 iters), loss = 0.00449718
I1008 03:38:06.829967  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00449718 (* 1 = 0.00449718 loss)
I1008 03:38:06.829973  5289 sgd_solver.cpp:105] Iteration 75900, lr = 0.01
I1008 03:38:30.265523  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:38:31.249683  5289 solver.cpp:330] Iteration 76000, Testing net (#0)
I1008 03:38:35.825544  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:38:36.000844  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.902
I1008 03:38:36.000871  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.427206 (* 1 = 0.427206 loss)
I1008 03:38:36.168217  5289 solver.cpp:218] Iteration 76000 (3.40878 iter/s, 29.336s/100 iters), loss = 0.0180998
I1008 03:38:36.168249  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0180998 (* 1 = 0.0180998 loss)
I1008 03:38:36.168257  5289 sgd_solver.cpp:105] Iteration 76000, lr = 0.01
I1008 03:39:01.102905  5289 solver.cpp:218] Iteration 76100 (4.01084 iter/s, 24.9324s/100 iters), loss = 0.056176
I1008 03:39:01.103008  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.056176 (* 1 = 0.056176 loss)
I1008 03:39:01.103018  5289 sgd_solver.cpp:105] Iteration 76100, lr = 0.01
I1008 03:39:25.760159  5289 solver.cpp:218] Iteration 76200 (4.05632 iter/s, 24.6529s/100 iters), loss = 0.0153003
I1008 03:39:25.760205  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0153002 (* 1 = 0.0153002 loss)
I1008 03:39:25.760213  5289 sgd_solver.cpp:105] Iteration 76200, lr = 0.01
I1008 03:39:50.804976  5289 solver.cpp:218] Iteration 76300 (3.9932 iter/s, 25.0426s/100 iters), loss = 0.0241818
I1008 03:39:50.805089  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0241817 (* 1 = 0.0241817 loss)
I1008 03:39:50.805105  5289 sgd_solver.cpp:105] Iteration 76300, lr = 0.01
I1008 03:40:15.456419  5289 solver.cpp:218] Iteration 76400 (4.05728 iter/s, 24.6471s/100 iters), loss = 0.0946088
I1008 03:40:15.456475  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0946088 (* 1 = 0.0946088 loss)
I1008 03:40:15.456495  5289 sgd_solver.cpp:105] Iteration 76400, lr = 0.01
I1008 03:40:38.908973  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:40:39.892649  5289 solver.cpp:330] Iteration 76500, Testing net (#0)
I1008 03:40:44.451309  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:40:44.641999  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8929
I1008 03:40:44.642026  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.456442 (* 1 = 0.456442 loss)
I1008 03:40:44.791894  5289 solver.cpp:218] Iteration 76500 (3.40929 iter/s, 29.3317s/100 iters), loss = 0.0396907
I1008 03:40:44.791930  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0396908 (* 1 = 0.0396908 loss)
I1008 03:40:44.791950  5289 sgd_solver.cpp:105] Iteration 76500, lr = 0.01
I1008 03:41:09.830878  5289 solver.cpp:218] Iteration 76600 (3.99414 iter/s, 25.0367s/100 iters), loss = 0.071856
I1008 03:41:09.830970  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.071856 (* 1 = 0.071856 loss)
I1008 03:41:09.830992  5289 sgd_solver.cpp:105] Iteration 76600, lr = 0.01
I1008 03:41:34.490447  5289 solver.cpp:218] Iteration 76700 (4.05595 iter/s, 24.6552s/100 iters), loss = 0.0166571
I1008 03:41:34.490479  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0166571 (* 1 = 0.0166571 loss)
I1008 03:41:34.490486  5289 sgd_solver.cpp:105] Iteration 76700, lr = 0.01
I1008 03:41:59.472595  5289 solver.cpp:218] Iteration 76800 (4.0035 iter/s, 24.9781s/100 iters), loss = 0.0196451
I1008 03:41:59.472669  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0196451 (* 1 = 0.0196451 loss)
I1008 03:41:59.472677  5289 sgd_solver.cpp:105] Iteration 76800, lr = 0.01
I1008 03:42:24.110749  5289 solver.cpp:218] Iteration 76900 (4.05924 iter/s, 24.6351s/100 iters), loss = 0.051878
I1008 03:42:24.110790  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.051878 (* 1 = 0.051878 loss)
I1008 03:42:24.110797  5289 sgd_solver.cpp:105] Iteration 76900, lr = 0.01
I1008 03:42:47.565428  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:42:48.548203  5289 solver.cpp:330] Iteration 77000, Testing net (#0)
I1008 03:42:53.099843  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:42:53.277173  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8974
I1008 03:42:53.277202  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.426499 (* 1 = 0.426499 loss)
I1008 03:42:53.434676  5289 solver.cpp:218] Iteration 77000 (3.41064 iter/s, 29.32s/100 iters), loss = 0.0274573
I1008 03:42:53.434710  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0274573 (* 1 = 0.0274573 loss)
I1008 03:42:53.434718  5289 sgd_solver.cpp:105] Iteration 77000, lr = 0.01
I1008 03:43:18.486645  5289 solver.cpp:218] Iteration 77100 (3.99172 iter/s, 25.0518s/100 iters), loss = 0.0521748
I1008 03:43:18.486719  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0521748 (* 1 = 0.0521748 loss)
I1008 03:43:18.486727  5289 sgd_solver.cpp:105] Iteration 77100, lr = 0.01
I1008 03:43:43.138284  5289 solver.cpp:218] Iteration 77200 (4.05725 iter/s, 24.6473s/100 iters), loss = 0.0371584
I1008 03:43:43.138319  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0371585 (* 1 = 0.0371585 loss)
I1008 03:43:43.138325  5289 sgd_solver.cpp:105] Iteration 77200, lr = 0.01
I1008 03:44:08.210610  5289 solver.cpp:218] Iteration 77300 (3.98882 iter/s, 25.0701s/100 iters), loss = 0.0141416
I1008 03:44:08.210707  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0141417 (* 1 = 0.0141417 loss)
I1008 03:44:08.210716  5289 sgd_solver.cpp:105] Iteration 77300, lr = 0.01
I1008 03:44:32.847738  5289 solver.cpp:218] Iteration 77400 (4.05929 iter/s, 24.6349s/100 iters), loss = 0.0083657
I1008 03:44:32.847775  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00836575 (* 1 = 0.00836575 loss)
I1008 03:44:32.847782  5289 sgd_solver.cpp:105] Iteration 77400, lr = 0.01
I1008 03:44:56.289893  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:44:57.275547  5289 solver.cpp:330] Iteration 77500, Testing net (#0)
I1008 03:45:01.811980  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:45:01.998332  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8944
I1008 03:45:01.998359  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.42073 (* 1 = 0.42073 loss)
I1008 03:45:02.148341  5289 solver.cpp:218] Iteration 77500 (3.41341 iter/s, 29.2962s/100 iters), loss = 0.0198995
I1008 03:45:02.148373  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0198995 (* 1 = 0.0198995 loss)
I1008 03:45:02.148380  5289 sgd_solver.cpp:105] Iteration 77500, lr = 0.01
I1008 03:45:27.110522  5289 solver.cpp:218] Iteration 77600 (4.00608 iter/s, 24.962s/100 iters), loss = 0.0159911
I1008 03:45:27.110607  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0159911 (* 1 = 0.0159911 loss)
I1008 03:45:27.110616  5289 sgd_solver.cpp:105] Iteration 77600, lr = 0.01
I1008 03:45:51.790263  5289 solver.cpp:218] Iteration 77700 (4.05263 iter/s, 24.6753s/100 iters), loss = 0.0125634
I1008 03:45:51.790300  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0125635 (* 1 = 0.0125635 loss)
I1008 03:45:51.790308  5289 sgd_solver.cpp:105] Iteration 77700, lr = 0.01
I1008 03:46:16.721629  5289 solver.cpp:218] Iteration 77800 (4.01138 iter/s, 24.9291s/100 iters), loss = 0.0127671
I1008 03:46:16.721715  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0127671 (* 1 = 0.0127671 loss)
I1008 03:46:16.721724  5289 sgd_solver.cpp:105] Iteration 77800, lr = 0.01
I1008 03:46:41.377375  5289 solver.cpp:218] Iteration 77900 (4.05648 iter/s, 24.6519s/100 iters), loss = 0.0202741
I1008 03:46:41.377419  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0202741 (* 1 = 0.0202741 loss)
I1008 03:46:41.377426  5289 sgd_solver.cpp:105] Iteration 77900, lr = 0.01
I1008 03:47:04.706620  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:47:05.687638  5289 solver.cpp:330] Iteration 78000, Testing net (#0)
I1008 03:47:10.260433  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:47:10.454924  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8987
I1008 03:47:10.454951  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.419099 (* 1 = 0.419099 loss)
I1008 03:47:10.608775  5289 solver.cpp:218] Iteration 78000 (3.42124 iter/s, 29.2291s/100 iters), loss = 0.00944673
I1008 03:47:10.608806  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00944678 (* 1 = 0.00944678 loss)
I1008 03:47:10.608814  5289 sgd_solver.cpp:105] Iteration 78000, lr = 0.01
I1008 03:47:35.532253  5289 solver.cpp:218] Iteration 78100 (4.01265 iter/s, 24.9212s/100 iters), loss = 0.0363079
I1008 03:47:35.532335  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0363079 (* 1 = 0.0363079 loss)
I1008 03:47:35.532344  5289 sgd_solver.cpp:105] Iteration 78100, lr = 0.01
I1008 03:48:00.179524  5289 solver.cpp:218] Iteration 78200 (4.05796 iter/s, 24.6429s/100 iters), loss = 0.0227103
I1008 03:48:00.179571  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0227104 (* 1 = 0.0227104 loss)
I1008 03:48:00.179580  5289 sgd_solver.cpp:105] Iteration 78200, lr = 0.01
I1008 03:48:25.174967  5289 solver.cpp:218] Iteration 78300 (4.00126 iter/s, 24.9921s/100 iters), loss = 0.0151978
I1008 03:48:25.175076  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0151979 (* 1 = 0.0151979 loss)
I1008 03:48:25.175084  5289 sgd_solver.cpp:105] Iteration 78300, lr = 0.01
I1008 03:48:49.787235  5289 solver.cpp:218] Iteration 78400 (4.06305 iter/s, 24.612s/100 iters), loss = 0.0141636
I1008 03:48:49.787271  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0141636 (* 1 = 0.0141636 loss)
I1008 03:48:49.787277  5289 sgd_solver.cpp:105] Iteration 78400, lr = 0.01
I1008 03:49:13.263309  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:49:14.246459  5289 solver.cpp:330] Iteration 78500, Testing net (#0)
I1008 03:49:18.807379  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:49:18.978598  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8972
I1008 03:49:18.978633  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.431598 (* 1 = 0.431598 loss)
I1008 03:49:19.152834  5289 solver.cpp:218] Iteration 78500 (3.40586 iter/s, 29.3612s/100 iters), loss = 0.0119881
I1008 03:49:19.152875  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0119881 (* 1 = 0.0119881 loss)
I1008 03:49:19.152885  5289 sgd_solver.cpp:105] Iteration 78500, lr = 0.01
I1008 03:49:44.188302  5289 solver.cpp:218] Iteration 78600 (3.99469 iter/s, 25.0332s/100 iters), loss = 0.0464367
I1008 03:49:44.188380  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0464367 (* 1 = 0.0464367 loss)
I1008 03:49:44.188390  5289 sgd_solver.cpp:105] Iteration 78600, lr = 0.01
I1008 03:50:08.827844  5289 solver.cpp:218] Iteration 78700 (4.05914 iter/s, 24.6358s/100 iters), loss = 0.0184941
I1008 03:50:08.827886  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0184941 (* 1 = 0.0184941 loss)
I1008 03:50:08.827893  5289 sgd_solver.cpp:105] Iteration 78700, lr = 0.01
I1008 03:50:33.819725  5289 solver.cpp:218] Iteration 78800 (4.00167 iter/s, 24.9896s/100 iters), loss = 0.0629234
I1008 03:50:33.819825  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0629234 (* 1 = 0.0629234 loss)
I1008 03:50:33.819835  5289 sgd_solver.cpp:105] Iteration 78800, lr = 0.01
I1008 03:50:58.385540  5289 solver.cpp:218] Iteration 78900 (4.07107 iter/s, 24.5636s/100 iters), loss = 0.00459213
I1008 03:50:58.385574  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00459218 (* 1 = 0.00459218 loss)
I1008 03:50:58.385582  5289 sgd_solver.cpp:105] Iteration 78900, lr = 0.01
I1008 03:51:21.867411  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:51:22.851289  5289 solver.cpp:330] Iteration 79000, Testing net (#0)
I1008 03:51:27.527336  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:51:27.676465  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8812
I1008 03:51:27.676501  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.508596 (* 1 = 0.508596 loss)
I1008 03:51:27.880146  5289 solver.cpp:218] Iteration 79000 (3.39095 iter/s, 29.4902s/100 iters), loss = 0.00429182
I1008 03:51:27.880179  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00429187 (* 1 = 0.00429187 loss)
I1008 03:51:27.880187  5289 sgd_solver.cpp:105] Iteration 79000, lr = 0.01
I1008 03:51:52.967941  5289 solver.cpp:218] Iteration 79100 (3.98637 iter/s, 25.0855s/100 iters), loss = 0.0155879
I1008 03:51:52.968024  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0155879 (* 1 = 0.0155879 loss)
I1008 03:51:52.968032  5289 sgd_solver.cpp:105] Iteration 79100, lr = 0.01
I1008 03:52:17.526630  5289 solver.cpp:218] Iteration 79200 (4.07261 iter/s, 24.5543s/100 iters), loss = 0.0275041
I1008 03:52:17.526672  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0275041 (* 1 = 0.0275041 loss)
I1008 03:52:17.526679  5289 sgd_solver.cpp:105] Iteration 79200, lr = 0.01
I1008 03:52:42.507398  5289 solver.cpp:218] Iteration 79300 (4.00378 iter/s, 24.9764s/100 iters), loss = 0.0131849
I1008 03:52:42.507499  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0131849 (* 1 = 0.0131849 loss)
I1008 03:52:42.507517  5289 sgd_solver.cpp:105] Iteration 79300, lr = 0.01
I1008 03:53:07.154691  5289 solver.cpp:218] Iteration 79400 (4.05728 iter/s, 24.6471s/100 iters), loss = 0.0241622
I1008 03:53:07.154723  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0241622 (* 1 = 0.0241622 loss)
I1008 03:53:07.154731  5289 sgd_solver.cpp:105] Iteration 79400, lr = 0.01
I1008 03:53:30.569545  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:53:31.551518  5289 solver.cpp:330] Iteration 79500, Testing net (#0)
I1008 03:53:36.068084  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:53:36.262682  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8827
I1008 03:53:36.262708  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.458885 (* 1 = 0.458885 loss)
I1008 03:53:36.441208  5289 solver.cpp:218] Iteration 79500 (3.4148 iter/s, 29.2843s/100 iters), loss = 0.0207408
I1008 03:53:36.441239  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0207408 (* 1 = 0.0207408 loss)
I1008 03:53:36.441246  5289 sgd_solver.cpp:105] Iteration 79500, lr = 0.01
I1008 03:54:01.566576  5289 solver.cpp:218] Iteration 79600 (3.98039 iter/s, 25.1232s/100 iters), loss = 0.0287474
I1008 03:54:01.566668  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0287474 (* 1 = 0.0287474 loss)
I1008 03:54:01.566686  5289 sgd_solver.cpp:105] Iteration 79600, lr = 0.01
I1008 03:54:26.205615  5289 solver.cpp:218] Iteration 79700 (4.05899 iter/s, 24.6367s/100 iters), loss = 0.0184142
I1008 03:54:26.205647  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0184142 (* 1 = 0.0184142 loss)
I1008 03:54:26.205654  5289 sgd_solver.cpp:105] Iteration 79700, lr = 0.01
I1008 03:54:51.208410  5289 solver.cpp:218] Iteration 79800 (3.99992 iter/s, 25.0005s/100 iters), loss = 0.00797166
I1008 03:54:51.208479  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00797168 (* 1 = 0.00797168 loss)
I1008 03:54:51.208487  5289 sgd_solver.cpp:105] Iteration 79800, lr = 0.01
I1008 03:55:15.924867  5289 solver.cpp:218] Iteration 79900 (4.04626 iter/s, 24.7142s/100 iters), loss = 0.0521699
I1008 03:55:15.924901  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0521699 (* 1 = 0.0521699 loss)
I1008 03:55:15.924908  5289 sgd_solver.cpp:105] Iteration 79900, lr = 0.01
I1008 03:55:39.369204  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:55:40.354403  5289 solver.cpp:330] Iteration 80000, Testing net (#0)
I1008 03:55:44.894723  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:55:45.085209  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8958
I1008 03:55:45.085244  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.43724 (* 1 = 0.43724 loss)
I1008 03:55:45.228127  5289 solver.cpp:218] Iteration 80000 (3.4131 iter/s, 29.2989s/100 iters), loss = 0.013396
I1008 03:55:45.228163  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.013396 (* 1 = 0.013396 loss)
I1008 03:55:45.228170  5289 sgd_solver.cpp:46] MultiStep Status: Iteration 80000, step = 2
I1008 03:55:45.228174  5289 sgd_solver.cpp:105] Iteration 80000, lr = 0.001
I1008 03:56:10.216415  5289 solver.cpp:218] Iteration 80100 (4.0019 iter/s, 24.9881s/100 iters), loss = 0.0249228
I1008 03:56:10.216481  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0249228 (* 1 = 0.0249228 loss)
I1008 03:56:10.216490  5289 sgd_solver.cpp:105] Iteration 80100, lr = 0.001
I1008 03:56:34.871616  5289 solver.cpp:218] Iteration 80200 (4.05666 iter/s, 24.6508s/100 iters), loss = 0.0137861
I1008 03:56:34.871652  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0137861 (* 1 = 0.0137861 loss)
I1008 03:56:34.871659  5289 sgd_solver.cpp:105] Iteration 80200, lr = 0.001
I1008 03:56:59.712638  5289 solver.cpp:218] Iteration 80300 (4.02631 iter/s, 24.8366s/100 iters), loss = 0.0189622
I1008 03:56:59.712726  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0189622 (* 1 = 0.0189622 loss)
I1008 03:56:59.712734  5289 sgd_solver.cpp:105] Iteration 80300, lr = 0.001
I1008 03:57:24.488840  5289 solver.cpp:218] Iteration 80400 (4.03653 iter/s, 24.7738s/100 iters), loss = 0.0113557
I1008 03:57:24.488873  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0113558 (* 1 = 0.0113558 loss)
I1008 03:57:24.488879  5289 sgd_solver.cpp:105] Iteration 80400, lr = 0.001
I1008 03:57:47.885588  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:57:48.868862  5289 solver.cpp:330] Iteration 80500, Testing net (#0)
I1008 03:57:53.530366  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:57:53.689292  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9139
I1008 03:57:53.689318  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.353937 (* 1 = 0.353937 loss)
I1008 03:57:53.875727  5289 solver.cpp:218] Iteration 80500 (3.40314 iter/s, 29.3846s/100 iters), loss = 0.00697469
I1008 03:57:53.875761  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00697472 (* 1 = 0.00697472 loss)
I1008 03:57:53.875767  5289 sgd_solver.cpp:105] Iteration 80500, lr = 0.001
I1008 03:58:19.079830  5289 solver.cpp:218] Iteration 80600 (3.96797 iter/s, 25.2018s/100 iters), loss = 0.00556746
I1008 03:58:19.079910  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00556749 (* 1 = 0.00556749 loss)
I1008 03:58:19.079918  5289 sgd_solver.cpp:105] Iteration 80600, lr = 0.001
I1008 03:58:43.718904  5289 solver.cpp:218] Iteration 80700 (4.05897 iter/s, 24.6368s/100 iters), loss = 0.0285345
I1008 03:58:43.718940  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0285345 (* 1 = 0.0285345 loss)
I1008 03:58:43.718947  5289 sgd_solver.cpp:105] Iteration 80700, lr = 0.001
I1008 03:59:08.574502  5289 solver.cpp:218] Iteration 80800 (4.02361 iter/s, 24.8533s/100 iters), loss = 0.00158978
I1008 03:59:08.574584  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00158981 (* 1 = 0.00158981 loss)
I1008 03:59:08.574592  5289 sgd_solver.cpp:105] Iteration 80800, lr = 0.001
I1008 03:59:33.439157  5289 solver.cpp:218] Iteration 80900 (4.02214 iter/s, 24.8624s/100 iters), loss = 0.0213445
I1008 03:59:33.439193  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0213445 (* 1 = 0.0213445 loss)
I1008 03:59:33.439200  5289 sgd_solver.cpp:105] Iteration 80900, lr = 0.001
I1008 03:59:56.853556  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:59:57.836458  5289 solver.cpp:330] Iteration 81000, Testing net (#0)
I1008 04:00:02.480403  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:00:02.654389  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9148
I1008 04:00:02.654417  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.347076 (* 1 = 0.347076 loss)
I1008 04:00:02.820649  5289 solver.cpp:218] Iteration 81000 (3.40376 iter/s, 29.3792s/100 iters), loss = 0.00406742
I1008 04:00:02.820682  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00406745 (* 1 = 0.00406745 loss)
I1008 04:00:02.820689  5289 sgd_solver.cpp:105] Iteration 81000, lr = 0.001
I1008 04:00:27.845003  5289 solver.cpp:218] Iteration 81100 (3.99647 iter/s, 25.0221s/100 iters), loss = 0.00758252
I1008 04:00:27.845084  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00758254 (* 1 = 0.00758254 loss)
I1008 04:00:27.845094  5289 sgd_solver.cpp:105] Iteration 81100, lr = 0.001
I1008 04:00:52.520427  5289 solver.cpp:218] Iteration 81200 (4.05299 iter/s, 24.6731s/100 iters), loss = 0.00929678
I1008 04:00:52.520468  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0092968 (* 1 = 0.0092968 loss)
I1008 04:00:52.520475  5289 sgd_solver.cpp:105] Iteration 81200, lr = 0.001
I1008 04:01:17.283643  5289 solver.cpp:218] Iteration 81300 (4.03861 iter/s, 24.761s/100 iters), loss = 0.0245875
I1008 04:01:17.283751  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0245875 (* 1 = 0.0245875 loss)
I1008 04:01:17.283768  5289 sgd_solver.cpp:105] Iteration 81300, lr = 0.001
I1008 04:01:42.263211  5289 solver.cpp:218] Iteration 81400 (4.00331 iter/s, 24.9793s/100 iters), loss = 0.0238881
I1008 04:01:42.263247  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0238881 (* 1 = 0.0238881 loss)
I1008 04:01:42.263264  5289 sgd_solver.cpp:105] Iteration 81400, lr = 0.001
I1008 04:02:05.712075  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:02:06.695142  5289 solver.cpp:330] Iteration 81500, Testing net (#0)
I1008 04:02:11.207633  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:02:11.403220  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9157
I1008 04:02:11.403249  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.343995 (* 1 = 0.343995 loss)
I1008 04:02:11.558462  5289 solver.cpp:218] Iteration 81500 (3.41379 iter/s, 29.293s/100 iters), loss = 0.00450427
I1008 04:02:11.558495  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00450428 (* 1 = 0.00450428 loss)
I1008 04:02:11.558501  5289 sgd_solver.cpp:105] Iteration 81500, lr = 0.001
I1008 04:02:36.707698  5289 solver.cpp:218] Iteration 81600 (3.97662 iter/s, 25.147s/100 iters), loss = 0.0283474
I1008 04:02:36.707795  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0283474 (* 1 = 0.0283474 loss)
I1008 04:02:36.707804  5289 sgd_solver.cpp:105] Iteration 81600, lr = 0.001
I1008 04:03:01.398180  5289 solver.cpp:218] Iteration 81700 (4.05077 iter/s, 24.6867s/100 iters), loss = 0.00582816
I1008 04:03:01.398216  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00582818 (* 1 = 0.00582818 loss)
I1008 04:03:01.398236  5289 sgd_solver.cpp:105] Iteration 81700, lr = 0.001
I1008 04:03:26.086777  5289 solver.cpp:218] Iteration 81800 (4.05082 iter/s, 24.6863s/100 iters), loss = 0.00303824
I1008 04:03:26.086856  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00303825 (* 1 = 0.00303825 loss)
I1008 04:03:26.086874  5289 sgd_solver.cpp:105] Iteration 81800, lr = 0.001
I1008 04:03:51.124682  5289 solver.cpp:218] Iteration 81900 (3.99402 iter/s, 25.0374s/100 iters), loss = 0.00164235
I1008 04:03:51.124718  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00164235 (* 1 = 0.00164235 loss)
I1008 04:03:51.124725  5289 sgd_solver.cpp:105] Iteration 81900, lr = 0.001
I1008 04:04:14.556999  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:04:15.538784  5289 solver.cpp:330] Iteration 82000, Testing net (#0)
I1008 04:04:20.130851  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:04:20.336207  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9164
I1008 04:04:20.336232  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.345334 (* 1 = 0.345334 loss)
I1008 04:04:20.492482  5289 solver.cpp:218] Iteration 82000 (3.40535 iter/s, 29.3655s/100 iters), loss = 0.00260177
I1008 04:04:20.492514  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00260178 (* 1 = 0.00260178 loss)
I1008 04:04:20.492522  5289 sgd_solver.cpp:105] Iteration 82000, lr = 0.001
I1008 04:04:45.559574  5289 solver.cpp:218] Iteration 82100 (3.98999 iter/s, 25.0627s/100 iters), loss = 0.0153552
I1008 04:04:45.559680  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0153552 (* 1 = 0.0153552 loss)
I1008 04:04:45.559689  5289 sgd_solver.cpp:105] Iteration 82100, lr = 0.001
I1008 04:05:10.192042  5289 solver.cpp:218] Iteration 82200 (4.0603 iter/s, 24.6287s/100 iters), loss = 0.00362833
I1008 04:05:10.192100  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00362835 (* 1 = 0.00362835 loss)
I1008 04:05:10.192119  5289 sgd_solver.cpp:105] Iteration 82200, lr = 0.001
I1008 04:05:34.803300  5289 solver.cpp:218] Iteration 82300 (4.06356 iter/s, 24.609s/100 iters), loss = 0.00533089
I1008 04:05:34.803383  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00533091 (* 1 = 0.00533091 loss)
I1008 04:05:34.803391  5289 sgd_solver.cpp:105] Iteration 82300, lr = 0.001
I1008 04:05:59.899507  5289 solver.cpp:218] Iteration 82400 (3.98502 iter/s, 25.094s/100 iters), loss = 0.00657068
I1008 04:05:59.899540  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00657071 (* 1 = 0.00657071 loss)
I1008 04:05:59.899547  5289 sgd_solver.cpp:105] Iteration 82400, lr = 0.001
I1008 04:06:23.331084  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:06:24.315359  5289 solver.cpp:330] Iteration 82500, Testing net (#0)
I1008 04:06:28.873337  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:06:29.059275  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9155
I1008 04:06:29.059311  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.350665 (* 1 = 0.350665 loss)
I1008 04:06:29.214063  5289 solver.cpp:218] Iteration 82500 (3.41154 iter/s, 29.3123s/100 iters), loss = 0.00625949
I1008 04:06:29.214104  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00625951 (* 1 = 0.00625951 loss)
I1008 04:06:29.214112  5289 sgd_solver.cpp:105] Iteration 82500, lr = 0.001
I1008 04:06:54.158113  5289 solver.cpp:218] Iteration 82600 (4.00899 iter/s, 24.9439s/100 iters), loss = 0.0129668
I1008 04:06:54.158187  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0129669 (* 1 = 0.0129669 loss)
I1008 04:06:54.158195  5289 sgd_solver.cpp:105] Iteration 82600, lr = 0.001
I1008 04:07:18.731335  5289 solver.cpp:218] Iteration 82700 (4.06984 iter/s, 24.571s/100 iters), loss = 0.00716833
I1008 04:07:18.731365  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00716835 (* 1 = 0.00716835 loss)
I1008 04:07:18.731371  5289 sgd_solver.cpp:105] Iteration 82700, lr = 0.001
I1008 04:07:43.403344  5289 solver.cpp:218] Iteration 82800 (4.05355 iter/s, 24.6698s/100 iters), loss = 0.00304734
I1008 04:07:43.403426  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00304735 (* 1 = 0.00304735 loss)
I1008 04:07:43.403434  5289 sgd_solver.cpp:105] Iteration 82800, lr = 0.001
I1008 04:08:08.466763  5289 solver.cpp:218] Iteration 82900 (3.99024 iter/s, 25.0612s/100 iters), loss = 0.0104371
I1008 04:08:08.466796  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0104371 (* 1 = 0.0104371 loss)
I1008 04:08:08.466804  5289 sgd_solver.cpp:105] Iteration 82900, lr = 0.001
I1008 04:08:31.936524  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:08:32.921242  5289 solver.cpp:330] Iteration 83000, Testing net (#0)
I1008 04:08:37.590342  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:08:37.748570  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9159
I1008 04:08:37.748596  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.347801 (* 1 = 0.347801 loss)
I1008 04:08:37.934433  5289 solver.cpp:218] Iteration 83000 (3.39399 iter/s, 29.4638s/100 iters), loss = 0.00644609
I1008 04:08:37.934464  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0064461 (* 1 = 0.0064461 loss)
I1008 04:08:37.934471  5289 sgd_solver.cpp:105] Iteration 83000, lr = 0.001
I1008 04:09:03.064636  5289 solver.cpp:218] Iteration 83100 (3.97964 iter/s, 25.1279s/100 iters), loss = 0.00501247
I1008 04:09:03.064745  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00501247 (* 1 = 0.00501247 loss)
I1008 04:09:03.064754  5289 sgd_solver.cpp:105] Iteration 83100, lr = 0.001
I1008 04:09:27.697839  5289 solver.cpp:218] Iteration 83200 (4.05993 iter/s, 24.6309s/100 iters), loss = 0.00693381
I1008 04:09:27.697871  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00693382 (* 1 = 0.00693382 loss)
I1008 04:09:27.697878  5289 sgd_solver.cpp:105] Iteration 83200, lr = 0.001
I1008 04:09:52.366459  5289 solver.cpp:218] Iteration 83300 (4.05445 iter/s, 24.6642s/100 iters), loss = 0.00597212
I1008 04:09:52.366561  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00597213 (* 1 = 0.00597213 loss)
I1008 04:09:52.366571  5289 sgd_solver.cpp:105] Iteration 83300, lr = 0.001
I1008 04:10:17.455799  5289 solver.cpp:218] Iteration 83400 (3.98645 iter/s, 25.085s/100 iters), loss = 0.00248035
I1008 04:10:17.455837  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00248036 (* 1 = 0.00248036 loss)
I1008 04:10:17.455847  5289 sgd_solver.cpp:105] Iteration 83400, lr = 0.001
I1008 04:10:40.901638  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:10:41.885740  5289 solver.cpp:330] Iteration 83500, Testing net (#0)
I1008 04:10:46.389999  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:10:46.586462  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9169
I1008 04:10:46.586486  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.34832 (* 1 = 0.34832 loss)
I1008 04:10:46.737179  5289 solver.cpp:218] Iteration 83500 (3.4154 iter/s, 29.2791s/100 iters), loss = 0.00874944
I1008 04:10:46.737221  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00874946 (* 1 = 0.00874946 loss)
I1008 04:10:46.737228  5289 sgd_solver.cpp:105] Iteration 83500, lr = 0.001
I1008 04:11:11.898651  5289 solver.cpp:218] Iteration 83600 (3.97469 iter/s, 25.1592s/100 iters), loss = 0.00480024
I1008 04:11:11.898739  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00480025 (* 1 = 0.00480025 loss)
I1008 04:11:11.898749  5289 sgd_solver.cpp:105] Iteration 83600, lr = 0.001
I1008 04:11:36.556164  5289 solver.cpp:218] Iteration 83700 (4.05629 iter/s, 24.6531s/100 iters), loss = 0.017923
I1008 04:11:36.556196  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.017923 (* 1 = 0.017923 loss)
I1008 04:11:36.556203  5289 sgd_solver.cpp:105] Iteration 83700, lr = 0.001
I1008 04:12:01.196144  5289 solver.cpp:218] Iteration 83800 (4.05917 iter/s, 24.6356s/100 iters), loss = 0.00642189
I1008 04:12:01.196250  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00642191 (* 1 = 0.00642191 loss)
I1008 04:12:01.196260  5289 sgd_solver.cpp:105] Iteration 83800, lr = 0.001
I1008 04:12:26.177975  5289 solver.cpp:218] Iteration 83900 (4.00328 iter/s, 24.9795s/100 iters), loss = 0.00700674
I1008 04:12:26.178009  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00700676 (* 1 = 0.00700676 loss)
I1008 04:12:26.178015  5289 sgd_solver.cpp:105] Iteration 83900, lr = 0.001
I1008 04:12:49.633604  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:12:50.613749  5289 solver.cpp:330] Iteration 84000, Testing net (#0)
I1008 04:12:55.168198  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:12:55.388968  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9154
I1008 04:12:55.388995  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.351683 (* 1 = 0.351683 loss)
I1008 04:12:55.509579  5289 solver.cpp:218] Iteration 84000 (3.40955 iter/s, 29.3294s/100 iters), loss = 0.00430996
I1008 04:12:55.509611  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00430998 (* 1 = 0.00430998 loss)
I1008 04:12:55.509618  5289 sgd_solver.cpp:105] Iteration 84000, lr = 0.001
I1008 04:13:20.558967  5289 solver.cpp:218] Iteration 84100 (3.99229 iter/s, 25.0483s/100 iters), loss = 0.00914534
I1008 04:13:20.559044  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00914536 (* 1 = 0.00914536 loss)
I1008 04:13:20.559053  5289 sgd_solver.cpp:105] Iteration 84100, lr = 0.001
I1008 04:13:45.198657  5289 solver.cpp:218] Iteration 84200 (4.05887 iter/s, 24.6374s/100 iters), loss = 0.0177381
I1008 04:13:45.198690  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0177382 (* 1 = 0.0177382 loss)
I1008 04:13:45.198696  5289 sgd_solver.cpp:105] Iteration 84200, lr = 0.001
I1008 04:14:09.852978  5289 solver.cpp:218] Iteration 84300 (4.05681 iter/s, 24.6499s/100 iters), loss = 0.00226469
I1008 04:14:09.853055  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00226472 (* 1 = 0.00226472 loss)
I1008 04:14:09.853065  5289 sgd_solver.cpp:105] Iteration 84300, lr = 0.001
I1008 04:14:34.950343  5289 solver.cpp:218] Iteration 84400 (3.98517 iter/s, 25.093s/100 iters), loss = 0.0126344
I1008 04:14:34.950382  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0126344 (* 1 = 0.0126344 loss)
I1008 04:14:34.950392  5289 sgd_solver.cpp:105] Iteration 84400, lr = 0.001
I1008 04:14:58.403964  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:14:59.387353  5289 solver.cpp:330] Iteration 84500, Testing net (#0)
I1008 04:15:03.919078  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:15:04.104681  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9147
I1008 04:15:04.104708  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.351482 (* 1 = 0.351482 loss)
I1008 04:15:04.266593  5289 solver.cpp:218] Iteration 84500 (3.41147 iter/s, 29.3129s/100 iters), loss = 0.0099019
I1008 04:15:04.266628  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00990193 (* 1 = 0.00990193 loss)
I1008 04:15:04.266635  5289 sgd_solver.cpp:105] Iteration 84500, lr = 0.001
I1008 04:15:29.229827  5289 solver.cpp:218] Iteration 84600 (4.00626 iter/s, 24.9609s/100 iters), loss = 0.0138943
I1008 04:15:29.232642  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0138943 (* 1 = 0.0138943 loss)
I1008 04:15:29.232655  5289 sgd_solver.cpp:105] Iteration 84600, lr = 0.001
I1008 04:15:53.899457  5289 solver.cpp:218] Iteration 84700 (4.0543 iter/s, 24.6652s/100 iters), loss = 0.0156
I1008 04:15:53.899488  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0156 (* 1 = 0.0156 loss)
I1008 04:15:53.899495  5289 sgd_solver.cpp:105] Iteration 84700, lr = 0.001
I1008 04:16:18.545375  5289 solver.cpp:218] Iteration 84800 (4.05784 iter/s, 24.6436s/100 iters), loss = 0.00392868
I1008 04:16:18.545459  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00392871 (* 1 = 0.00392871 loss)
I1008 04:16:18.545467  5289 sgd_solver.cpp:105] Iteration 84800, lr = 0.001
I1008 04:16:43.546345  5289 solver.cpp:218] Iteration 84900 (4.00021 iter/s, 24.9987s/100 iters), loss = 0.00372867
I1008 04:16:43.546397  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0037287 (* 1 = 0.0037287 loss)
I1008 04:16:43.546407  5289 sgd_solver.cpp:105] Iteration 84900, lr = 0.001
I1008 04:17:07.005765  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:17:07.991435  5289 solver.cpp:330] Iteration 85000, Testing net (#0)
I1008 04:17:12.579010  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:17:12.791636  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9166
I1008 04:17:12.791671  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.353851 (* 1 = 0.353851 loss)
I1008 04:17:12.920090  5289 solver.cpp:218] Iteration 85000 (3.40466 iter/s, 29.3715s/100 iters), loss = 0.0155469
I1008 04:17:12.920132  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0155469 (* 1 = 0.0155469 loss)
I1008 04:17:12.920140  5289 sgd_solver.cpp:105] Iteration 85000, lr = 0.001
I1008 04:17:38.028759  5289 solver.cpp:218] Iteration 85100 (3.98338 iter/s, 25.1043s/100 iters), loss = 0.0187335
I1008 04:17:38.028847  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0187336 (* 1 = 0.0187336 loss)
I1008 04:17:38.028856  5289 sgd_solver.cpp:105] Iteration 85100, lr = 0.001
I1008 04:18:02.691998  5289 solver.cpp:218] Iteration 85200 (4.055 iter/s, 24.6609s/100 iters), loss = 0.0272891
I1008 04:18:02.692030  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0272891 (* 1 = 0.0272891 loss)
I1008 04:18:02.692037  5289 sgd_solver.cpp:105] Iteration 85200, lr = 0.001
I1008 04:18:27.342195  5289 solver.cpp:218] Iteration 85300 (4.05714 iter/s, 24.6479s/100 iters), loss = 0.00234862
I1008 04:18:27.342283  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00234866 (* 1 = 0.00234866 loss)
I1008 04:18:27.342291  5289 sgd_solver.cpp:105] Iteration 85300, lr = 0.001
I1008 04:18:52.427237  5289 solver.cpp:218] Iteration 85400 (3.9868 iter/s, 25.0828s/100 iters), loss = 0.00500614
I1008 04:18:52.427278  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00500618 (* 1 = 0.00500618 loss)
I1008 04:18:52.427289  5289 sgd_solver.cpp:105] Iteration 85400, lr = 0.001
I1008 04:19:15.878463  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:19:16.861621  5289 solver.cpp:330] Iteration 85500, Testing net (#0)
I1008 04:19:21.525352  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:19:21.689324  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9163
I1008 04:19:21.689352  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.353099 (* 1 = 0.353099 loss)
I1008 04:19:21.884891  5289 solver.cpp:218] Iteration 85500 (3.39496 iter/s, 29.4554s/100 iters), loss = 0.00366703
I1008 04:19:21.884922  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00366706 (* 1 = 0.00366706 loss)
I1008 04:19:21.884929  5289 sgd_solver.cpp:105] Iteration 85500, lr = 0.001
I1008 04:19:47.072129  5289 solver.cpp:218] Iteration 85600 (3.97062 iter/s, 25.185s/100 iters), loss = 0.00298001
I1008 04:19:47.072193  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00298004 (* 1 = 0.00298004 loss)
I1008 04:19:47.072201  5289 sgd_solver.cpp:105] Iteration 85600, lr = 0.001
I1008 04:20:11.743777  5289 solver.cpp:218] Iteration 85700 (4.05361 iter/s, 24.6694s/100 iters), loss = 0.0094397
I1008 04:20:11.743809  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00943972 (* 1 = 0.00943972 loss)
I1008 04:20:11.743816  5289 sgd_solver.cpp:105] Iteration 85700, lr = 0.001
I1008 04:20:36.420660  5289 solver.cpp:218] Iteration 85800 (4.05299 iter/s, 24.6731s/100 iters), loss = 0.0136053
I1008 04:20:36.420750  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0136053 (* 1 = 0.0136053 loss)
I1008 04:20:36.420761  5289 sgd_solver.cpp:105] Iteration 85800, lr = 0.001
I1008 04:21:01.519278  5289 solver.cpp:218] Iteration 85900 (3.98493 iter/s, 25.0945s/100 iters), loss = 0.00279436
I1008 04:21:01.519310  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00279437 (* 1 = 0.00279437 loss)
I1008 04:21:01.519317  5289 sgd_solver.cpp:105] Iteration 85900, lr = 0.001
I1008 04:21:24.949659  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:21:25.931982  5289 solver.cpp:330] Iteration 86000, Testing net (#0)
I1008 04:21:30.595187  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:21:30.760334  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9157
I1008 04:21:30.760371  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.350338 (* 1 = 0.350338 loss)
I1008 04:21:30.953800  5289 solver.cpp:218] Iteration 86000 (3.39764 iter/s, 29.4322s/100 iters), loss = 0.00505819
I1008 04:21:30.953841  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00505819 (* 1 = 0.00505819 loss)
I1008 04:21:30.953848  5289 sgd_solver.cpp:105] Iteration 86000, lr = 0.001
I1008 04:21:56.026432  5289 solver.cpp:218] Iteration 86100 (3.98877 iter/s, 25.0704s/100 iters), loss = 0.0051733
I1008 04:21:56.026509  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0051733 (* 1 = 0.0051733 loss)
I1008 04:21:56.026516  5289 sgd_solver.cpp:105] Iteration 86100, lr = 0.001
I1008 04:22:20.660331  5289 solver.cpp:218] Iteration 86200 (4.05982 iter/s, 24.6316s/100 iters), loss = 0.0120728
I1008 04:22:20.660365  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0120728 (* 1 = 0.0120728 loss)
I1008 04:22:20.660372  5289 sgd_solver.cpp:105] Iteration 86200, lr = 0.001
I1008 04:22:45.312623  5289 solver.cpp:218] Iteration 86300 (4.05679 iter/s, 24.65s/100 iters), loss = 0.00350488
I1008 04:22:45.312700  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00350488 (* 1 = 0.00350488 loss)
I1008 04:22:45.312708  5289 sgd_solver.cpp:105] Iteration 86300, lr = 0.001
I1008 04:23:10.356081  5289 solver.cpp:218] Iteration 86400 (3.99342 iter/s, 25.0412s/100 iters), loss = 0.00589191
I1008 04:23:10.356122  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00589192 (* 1 = 0.00589192 loss)
I1008 04:23:10.356132  5289 sgd_solver.cpp:105] Iteration 86400, lr = 0.001
I1008 04:23:33.793540  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:23:34.773723  5289 solver.cpp:330] Iteration 86500, Testing net (#0)
I1008 04:23:39.431764  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:23:39.621934  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9158
I1008 04:23:39.621961  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.347603 (* 1 = 0.347603 loss)
I1008 04:23:39.786319  5289 solver.cpp:218] Iteration 86500 (3.39813 iter/s, 29.4279s/100 iters), loss = 0.000807753
I1008 04:23:39.786351  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000807748 (* 1 = 0.000807748 loss)
I1008 04:23:39.786358  5289 sgd_solver.cpp:105] Iteration 86500, lr = 0.001
I1008 04:24:04.875294  5289 solver.cpp:218] Iteration 86600 (3.98617 iter/s, 25.0867s/100 iters), loss = 0.00503905
I1008 04:24:04.875366  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00503904 (* 1 = 0.00503904 loss)
I1008 04:24:04.875375  5289 sgd_solver.cpp:105] Iteration 86600, lr = 0.001
I1008 04:24:29.520391  5289 solver.cpp:218] Iteration 86700 (4.05797 iter/s, 24.6428s/100 iters), loss = 0.0102649
I1008 04:24:29.520436  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0102649 (* 1 = 0.0102649 loss)
I1008 04:24:29.520442  5289 sgd_solver.cpp:105] Iteration 86700, lr = 0.001
I1008 04:24:54.156488  5289 solver.cpp:218] Iteration 86800 (4.05945 iter/s, 24.6339s/100 iters), loss = 0.00541208
I1008 04:24:54.156570  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00541207 (* 1 = 0.00541207 loss)
I1008 04:24:54.156579  5289 sgd_solver.cpp:105] Iteration 86800, lr = 0.001
I1008 04:25:19.242705  5289 solver.cpp:218] Iteration 86900 (3.98661 iter/s, 25.084s/100 iters), loss = 0.0034661
I1008 04:25:19.242739  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00346609 (* 1 = 0.00346609 loss)
I1008 04:25:19.242746  5289 sgd_solver.cpp:105] Iteration 86900, lr = 0.001
I1008 04:25:42.659281  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:25:43.642853  5289 solver.cpp:330] Iteration 87000, Testing net (#0)
I1008 04:25:48.307965  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:25:48.466194  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9154
I1008 04:25:48.466220  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.349227 (* 1 = 0.349227 loss)
I1008 04:25:48.663166  5289 solver.cpp:218] Iteration 87000 (3.39926 iter/s, 29.4182s/100 iters), loss = 0.00540812
I1008 04:25:48.663200  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00540811 (* 1 = 0.00540811 loss)
I1008 04:25:48.663208  5289 sgd_solver.cpp:105] Iteration 87000, lr = 0.001
I1008 04:26:13.763902  5289 solver.cpp:218] Iteration 87100 (3.9843 iter/s, 25.0985s/100 iters), loss = 0.00878558
I1008 04:26:13.763986  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00878557 (* 1 = 0.00878557 loss)
I1008 04:26:13.763995  5289 sgd_solver.cpp:105] Iteration 87100, lr = 0.001
I1008 04:26:38.396021  5289 solver.cpp:218] Iteration 87200 (4.0604 iter/s, 24.6281s/100 iters), loss = 0.0109814
I1008 04:26:38.396056  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0109814 (* 1 = 0.0109814 loss)
I1008 04:26:38.396064  5289 sgd_solver.cpp:105] Iteration 87200, lr = 0.001
I1008 04:27:03.027559  5289 solver.cpp:218] Iteration 87300 (4.06021 iter/s, 24.6293s/100 iters), loss = 0.0136722
I1008 04:27:03.027634  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0136722 (* 1 = 0.0136722 loss)
I1008 04:27:03.027642  5289 sgd_solver.cpp:105] Iteration 87300, lr = 0.001
I1008 04:27:28.090126  5289 solver.cpp:218] Iteration 87400 (3.99065 iter/s, 25.0586s/100 iters), loss = 0.0078778
I1008 04:27:28.090160  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00787779 (* 1 = 0.00787779 loss)
I1008 04:27:28.090167  5289 sgd_solver.cpp:105] Iteration 87400, lr = 0.001
I1008 04:27:51.512249  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:27:52.496369  5289 solver.cpp:330] Iteration 87500, Testing net (#0)
I1008 04:27:57.123750  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:27:57.292135  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9155
I1008 04:27:57.292161  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.351438 (* 1 = 0.351438 loss)
I1008 04:27:57.494832  5289 solver.cpp:218] Iteration 87500 (3.40123 iter/s, 29.4011s/100 iters), loss = 0.00136829
I1008 04:27:57.494868  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00136828 (* 1 = 0.00136828 loss)
I1008 04:27:57.494879  5289 sgd_solver.cpp:105] Iteration 87500, lr = 0.001
I1008 04:28:22.533749  5289 solver.cpp:218] Iteration 87600 (3.99442 iter/s, 25.0349s/100 iters), loss = 0.00528524
I1008 04:28:22.533843  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00528522 (* 1 = 0.00528522 loss)
I1008 04:28:22.533860  5289 sgd_solver.cpp:105] Iteration 87600, lr = 0.001
I1008 04:28:47.173475  5289 solver.cpp:218] Iteration 87700 (4.05887 iter/s, 24.6374s/100 iters), loss = 0.0295215
I1008 04:28:47.173507  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0295215 (* 1 = 0.0295215 loss)
I1008 04:28:47.173514  5289 sgd_solver.cpp:105] Iteration 87700, lr = 0.001
I1008 04:29:11.846210  5289 solver.cpp:218] Iteration 87800 (4.05378 iter/s, 24.6684s/100 iters), loss = 0.00964028
I1008 04:29:11.846290  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00964026 (* 1 = 0.00964026 loss)
I1008 04:29:11.846299  5289 sgd_solver.cpp:105] Iteration 87800, lr = 0.001
I1008 04:29:36.725270  5289 solver.cpp:218] Iteration 87900 (4.01981 iter/s, 24.8768s/100 iters), loss = 0.00289953
I1008 04:29:36.725306  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00289951 (* 1 = 0.00289951 loss)
I1008 04:29:36.725314  5289 sgd_solver.cpp:105] Iteration 87900, lr = 0.001
I1008 04:30:00.113376  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:30:01.098372  5289 solver.cpp:330] Iteration 88000, Testing net (#0)
I1008 04:30:05.662308  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:30:05.835507  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9153
I1008 04:30:05.835535  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.348257 (* 1 = 0.348257 loss)
I1008 04:30:05.996768  5289 solver.cpp:218] Iteration 88000 (3.4168 iter/s, 29.2671s/100 iters), loss = 0.00652166
I1008 04:30:05.996803  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00652164 (* 1 = 0.00652164 loss)
I1008 04:30:05.996810  5289 sgd_solver.cpp:105] Iteration 88000, lr = 0.001
I1008 04:30:31.035709  5289 solver.cpp:218] Iteration 88100 (3.99383 iter/s, 25.0386s/100 iters), loss = 0.0182062
I1008 04:30:31.035774  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0182062 (* 1 = 0.0182062 loss)
I1008 04:30:31.035782  5289 sgd_solver.cpp:105] Iteration 88100, lr = 0.001
I1008 04:30:55.687346  5289 solver.cpp:218] Iteration 88200 (4.05708 iter/s, 24.6483s/100 iters), loss = 0.0137927
I1008 04:30:55.687382  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0137927 (* 1 = 0.0137927 loss)
I1008 04:30:55.687389  5289 sgd_solver.cpp:105] Iteration 88200, lr = 0.001
I1008 04:31:20.343767  5289 solver.cpp:218] Iteration 88300 (4.05646 iter/s, 24.652s/100 iters), loss = 0.0124109
I1008 04:31:20.343847  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0124109 (* 1 = 0.0124109 loss)
I1008 04:31:20.343854  5289 sgd_solver.cpp:105] Iteration 88300, lr = 0.001
I1008 04:31:45.429953  5289 solver.cpp:218] Iteration 88400 (3.98662 iter/s, 25.0839s/100 iters), loss = 0.00351203
I1008 04:31:45.429988  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.003512 (* 1 = 0.003512 loss)
I1008 04:31:45.430008  5289 sgd_solver.cpp:105] Iteration 88400, lr = 0.001
I1008 04:32:08.870148  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:32:09.855043  5289 solver.cpp:330] Iteration 88500, Testing net (#0)
I1008 04:32:14.521656  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:32:14.680647  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.917
I1008 04:32:14.680682  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.350182 (* 1 = 0.350182 loss)
I1008 04:32:14.867300  5289 solver.cpp:218] Iteration 88500 (3.39751 iter/s, 29.4333s/100 iters), loss = 0.0110232
I1008 04:32:14.867336  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0110232 (* 1 = 0.0110232 loss)
I1008 04:32:14.867343  5289 sgd_solver.cpp:105] Iteration 88500, lr = 0.001
I1008 04:32:40.066460  5289 solver.cpp:218] Iteration 88600 (3.96875 iter/s, 25.1969s/100 iters), loss = 0.00771558
I1008 04:32:40.066539  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00771556 (* 1 = 0.00771556 loss)
I1008 04:32:40.066546  5289 sgd_solver.cpp:105] Iteration 88600, lr = 0.001
I1008 04:33:04.676635  5289 solver.cpp:218] Iteration 88700 (4.06373 iter/s, 24.6079s/100 iters), loss = 0.0263761
I1008 04:33:04.676671  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0263761 (* 1 = 0.0263761 loss)
I1008 04:33:04.676677  5289 sgd_solver.cpp:105] Iteration 88700, lr = 0.001
I1008 04:33:29.305480  5289 solver.cpp:218] Iteration 88800 (4.06066 iter/s, 24.6266s/100 iters), loss = 0.00790829
I1008 04:33:29.305579  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00790827 (* 1 = 0.00790827 loss)
I1008 04:33:29.305591  5289 sgd_solver.cpp:105] Iteration 88800, lr = 0.001
I1008 04:33:54.375316  5289 solver.cpp:218] Iteration 88900 (3.98922 iter/s, 25.0676s/100 iters), loss = 0.00365881
I1008 04:33:54.375352  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00365878 (* 1 = 0.00365878 loss)
I1008 04:33:54.375360  5289 sgd_solver.cpp:105] Iteration 88900, lr = 0.001
I1008 04:34:17.811025  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:34:18.795545  5289 solver.cpp:330] Iteration 89000, Testing net (#0)
I1008 04:34:23.480873  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:34:23.620378  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9162
I1008 04:34:23.620409  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.352281 (* 1 = 0.352281 loss)
I1008 04:34:23.840512  5289 solver.cpp:218] Iteration 89000 (3.3941 iter/s, 29.4629s/100 iters), loss = 0.00291348
I1008 04:34:23.840546  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00291346 (* 1 = 0.00291346 loss)
I1008 04:34:23.840554  5289 sgd_solver.cpp:105] Iteration 89000, lr = 0.001
I1008 04:34:48.901808  5289 solver.cpp:218] Iteration 89100 (3.99024 iter/s, 25.0612s/100 iters), loss = 0.00879847
I1008 04:34:48.901892  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00879844 (* 1 = 0.00879844 loss)
I1008 04:34:48.901901  5289 sgd_solver.cpp:105] Iteration 89100, lr = 0.001
I1008 04:35:13.548512  5289 solver.cpp:218] Iteration 89200 (4.05771 iter/s, 24.6445s/100 iters), loss = 0.0135626
I1008 04:35:13.548544  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0135626 (* 1 = 0.0135626 loss)
I1008 04:35:13.548552  5289 sgd_solver.cpp:105] Iteration 89200, lr = 0.001
I1008 04:35:38.189545  5289 solver.cpp:218] Iteration 89300 (4.05864 iter/s, 24.6388s/100 iters), loss = 0.00237989
I1008 04:35:38.189625  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00237987 (* 1 = 0.00237987 loss)
I1008 04:35:38.189636  5289 sgd_solver.cpp:105] Iteration 89300, lr = 0.001
I1008 04:36:03.284059  5289 solver.cpp:218] Iteration 89400 (3.9853 iter/s, 25.0922s/100 iters), loss = 0.0117616
I1008 04:36:03.284096  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0117616 (* 1 = 0.0117616 loss)
I1008 04:36:03.284104  5289 sgd_solver.cpp:105] Iteration 89400, lr = 0.001
I1008 04:36:26.710347  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:36:27.692747  5289 solver.cpp:330] Iteration 89500, Testing net (#0)
I1008 04:36:32.301456  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:36:32.487222  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9171
I1008 04:36:32.487248  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.35352 (* 1 = 0.35352 loss)
I1008 04:36:32.653406  5289 solver.cpp:218] Iteration 89500 (3.40518 iter/s, 29.367s/100 iters), loss = 0.0120912
I1008 04:36:32.653440  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0120912 (* 1 = 0.0120912 loss)
I1008 04:36:32.653447  5289 sgd_solver.cpp:105] Iteration 89500, lr = 0.001
I1008 04:36:57.789067  5289 solver.cpp:218] Iteration 89600 (3.9791 iter/s, 25.1313s/100 iters), loss = 0.00552727
I1008 04:36:57.789157  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00552724 (* 1 = 0.00552724 loss)
I1008 04:36:57.789165  5289 sgd_solver.cpp:105] Iteration 89600, lr = 0.001
I1008 04:37:22.434717  5289 solver.cpp:218] Iteration 89700 (4.05788 iter/s, 24.6434s/100 iters), loss = 0.0082752
I1008 04:37:22.434753  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00827516 (* 1 = 0.00827516 loss)
I1008 04:37:22.434761  5289 sgd_solver.cpp:105] Iteration 89700, lr = 0.001
I1008 04:37:47.068760  5289 solver.cpp:218] Iteration 89800 (4.0598 iter/s, 24.6318s/100 iters), loss = 0.0126996
I1008 04:37:47.068856  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0126995 (* 1 = 0.0126995 loss)
I1008 04:37:47.068864  5289 sgd_solver.cpp:105] Iteration 89800, lr = 0.001
I1008 04:38:12.127609  5289 solver.cpp:218] Iteration 89900 (3.99096 iter/s, 25.0566s/100 iters), loss = 0.00521923
I1008 04:38:12.127650  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0052192 (* 1 = 0.0052192 loss)
I1008 04:38:12.127657  5289 sgd_solver.cpp:105] Iteration 89900, lr = 0.001
I1008 04:38:35.528697  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:38:36.510906  5289 solver.cpp:330] Iteration 90000, Testing net (#0)
I1008 04:38:41.084137  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:38:41.271383  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9158
I1008 04:38:41.271420  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.352482 (* 1 = 0.352482 loss)
I1008 04:38:41.424690  5289 solver.cpp:218] Iteration 90000 (3.41357 iter/s, 29.2948s/100 iters), loss = 0.00339488
I1008 04:38:41.424729  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00339484 (* 1 = 0.00339484 loss)
I1008 04:38:41.424737  5289 sgd_solver.cpp:105] Iteration 90000, lr = 0.001
I1008 04:39:06.446101  5289 solver.cpp:218] Iteration 90100 (3.99694 iter/s, 25.0192s/100 iters), loss = 0.00644959
I1008 04:39:06.446204  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00644955 (* 1 = 0.00644955 loss)
I1008 04:39:06.446214  5289 sgd_solver.cpp:105] Iteration 90100, lr = 0.001
I1008 04:39:31.088817  5289 solver.cpp:218] Iteration 90200 (4.05837 iter/s, 24.6404s/100 iters), loss = 0.00871215
I1008 04:39:31.088860  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00871211 (* 1 = 0.00871211 loss)
I1008 04:39:31.088865  5289 sgd_solver.cpp:105] Iteration 90200, lr = 0.001
I1008 04:39:55.731847  5289 solver.cpp:218] Iteration 90300 (4.05831 iter/s, 24.6408s/100 iters), loss = 0.0059057
I1008 04:39:55.731930  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00590566 (* 1 = 0.00590566 loss)
I1008 04:39:55.731940  5289 sgd_solver.cpp:105] Iteration 90300, lr = 0.001
I1008 04:40:20.819363  5289 solver.cpp:218] Iteration 90400 (3.98674 iter/s, 25.0831s/100 iters), loss = 0.00651556
I1008 04:40:20.819404  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00651552 (* 1 = 0.00651552 loss)
I1008 04:40:20.819413  5289 sgd_solver.cpp:105] Iteration 90400, lr = 0.001
I1008 04:40:44.225939  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:40:45.209728  5289 solver.cpp:330] Iteration 90500, Testing net (#0)
I1008 04:40:49.734468  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:40:49.924571  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9171
I1008 04:40:49.924602  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.35201 (* 1 = 0.35201 loss)
I1008 04:40:50.077935  5289 solver.cpp:218] Iteration 90500 (3.41807 iter/s, 29.2563s/100 iters), loss = 0.00213414
I1008 04:40:50.077965  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0021341 (* 1 = 0.0021341 loss)
I1008 04:40:50.077972  5289 sgd_solver.cpp:105] Iteration 90500, lr = 0.001
I1008 04:41:15.159852  5289 solver.cpp:218] Iteration 90600 (3.98696 iter/s, 25.0818s/100 iters), loss = 0.00808452
I1008 04:41:15.159961  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00808448 (* 1 = 0.00808448 loss)
I1008 04:41:15.159974  5289 sgd_solver.cpp:105] Iteration 90600, lr = 0.001
I1008 04:41:39.789153  5289 solver.cpp:218] Iteration 90700 (4.06057 iter/s, 24.6271s/100 iters), loss = 0.00625569
I1008 04:41:39.789186  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00625564 (* 1 = 0.00625564 loss)
I1008 04:41:39.789192  5289 sgd_solver.cpp:105] Iteration 90700, lr = 0.001
I1008 04:42:04.444934  5289 solver.cpp:218] Iteration 90800 (4.05657 iter/s, 24.6514s/100 iters), loss = 0.00726953
I1008 04:42:04.445103  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00726949 (* 1 = 0.00726949 loss)
I1008 04:42:04.445113  5289 sgd_solver.cpp:105] Iteration 90800, lr = 0.001
I1008 04:42:29.418838  5289 solver.cpp:218] Iteration 90900 (4.00454 iter/s, 24.9716s/100 iters), loss = 0.0080547
I1008 04:42:29.418876  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00805465 (* 1 = 0.00805465 loss)
I1008 04:42:29.418884  5289 sgd_solver.cpp:105] Iteration 90900, lr = 0.001
I1008 04:42:52.871088  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:42:53.854414  5289 solver.cpp:330] Iteration 91000, Testing net (#0)
I1008 04:42:58.519549  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:42:58.688663  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9168
I1008 04:42:58.688690  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.354768 (* 1 = 0.354768 loss)
I1008 04:42:58.864910  5289 solver.cpp:218] Iteration 91000 (3.39654 iter/s, 29.4417s/100 iters), loss = 0.00497654
I1008 04:42:58.864943  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00497649 (* 1 = 0.00497649 loss)
I1008 04:42:58.864950  5289 sgd_solver.cpp:105] Iteration 91000, lr = 0.001
I1008 04:43:23.981871  5289 solver.cpp:218] Iteration 91100 (3.98174 iter/s, 25.1147s/100 iters), loss = 0.0224283
I1008 04:43:23.981945  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0224282 (* 1 = 0.0224282 loss)
I1008 04:43:23.981956  5289 sgd_solver.cpp:105] Iteration 91100, lr = 0.001
I1008 04:43:48.535248  5289 solver.cpp:218] Iteration 91200 (4.07313 iter/s, 24.5511s/100 iters), loss = 0.00234923
I1008 04:43:48.535280  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00234919 (* 1 = 0.00234919 loss)
I1008 04:43:48.535287  5289 sgd_solver.cpp:105] Iteration 91200, lr = 0.001
I1008 04:44:13.193686  5289 solver.cpp:218] Iteration 91300 (4.05601 iter/s, 24.6548s/100 iters), loss = 0.0184454
I1008 04:44:13.193758  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0184453 (* 1 = 0.0184453 loss)
I1008 04:44:13.193765  5289 sgd_solver.cpp:105] Iteration 91300, lr = 0.001
I1008 04:44:38.172536  5289 solver.cpp:218] Iteration 91400 (4.00375 iter/s, 24.9766s/100 iters), loss = 0.00270212
I1008 04:44:38.172574  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00270207 (* 1 = 0.00270207 loss)
I1008 04:44:38.172583  5289 sgd_solver.cpp:105] Iteration 91400, lr = 0.001
I1008 04:45:01.607636  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:45:02.590092  5289 solver.cpp:330] Iteration 91500, Testing net (#0)
I1008 04:45:07.226438  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:45:07.389166  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9163
I1008 04:45:07.389192  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.353812 (* 1 = 0.353812 loss)
I1008 04:45:07.604452  5289 solver.cpp:218] Iteration 91500 (3.39818 iter/s, 29.4275s/100 iters), loss = 0.00384664
I1008 04:45:07.604493  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0038466 (* 1 = 0.0038466 loss)
I1008 04:45:07.604499  5289 sgd_solver.cpp:105] Iteration 91500, lr = 0.001
I1008 04:45:32.614715  5289 solver.cpp:218] Iteration 91600 (3.99872 iter/s, 25.008s/100 iters), loss = 0.00451548
I1008 04:45:32.614789  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00451544 (* 1 = 0.00451544 loss)
I1008 04:45:32.614796  5289 sgd_solver.cpp:105] Iteration 91600, lr = 0.001
I1008 04:45:57.262151  5289 solver.cpp:218] Iteration 91700 (4.05759 iter/s, 24.6452s/100 iters), loss = 0.00461142
I1008 04:45:57.262198  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00461138 (* 1 = 0.00461138 loss)
I1008 04:45:57.262205  5289 sgd_solver.cpp:105] Iteration 91700, lr = 0.001
I1008 04:46:21.911618  5289 solver.cpp:218] Iteration 91800 (4.05725 iter/s, 24.6472s/100 iters), loss = 0.0105629
I1008 04:46:21.911691  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0105629 (* 1 = 0.0105629 loss)
I1008 04:46:21.911700  5289 sgd_solver.cpp:105] Iteration 91800, lr = 0.001
I1008 04:46:47.009557  5289 solver.cpp:218] Iteration 91900 (3.98475 iter/s, 25.0957s/100 iters), loss = 0.0103467
I1008 04:46:47.009590  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0103466 (* 1 = 0.0103466 loss)
I1008 04:46:47.009598  5289 sgd_solver.cpp:105] Iteration 91900, lr = 0.001
I1008 04:47:10.434777  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:47:11.415485  5289 solver.cpp:330] Iteration 92000, Testing net (#0)
I1008 04:47:16.052175  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:47:16.230425  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9162
I1008 04:47:16.230451  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.352909 (* 1 = 0.352909 loss)
I1008 04:47:16.380071  5289 solver.cpp:218] Iteration 92000 (3.40522 iter/s, 29.3667s/100 iters), loss = 0.00200177
I1008 04:47:16.380102  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00200172 (* 1 = 0.00200172 loss)
I1008 04:47:16.380110  5289 sgd_solver.cpp:105] Iteration 92000, lr = 0.001
I1008 04:47:41.524966  5289 solver.cpp:218] Iteration 92100 (3.97731 iter/s, 25.1426s/100 iters), loss = 0.00445747
I1008 04:47:41.525046  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00445741 (* 1 = 0.00445741 loss)
I1008 04:47:41.525055  5289 sgd_solver.cpp:105] Iteration 92100, lr = 0.001
I1008 04:48:06.170256  5289 solver.cpp:218] Iteration 92200 (4.05814 iter/s, 24.6418s/100 iters), loss = 0.01662
I1008 04:48:06.170291  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0166199 (* 1 = 0.0166199 loss)
I1008 04:48:06.170298  5289 sgd_solver.cpp:105] Iteration 92200, lr = 0.001
I1008 04:48:30.799119  5289 solver.cpp:218] Iteration 92300 (4.06065 iter/s, 24.6266s/100 iters), loss = 0.00794174
I1008 04:48:30.799218  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00794168 (* 1 = 0.00794168 loss)
I1008 04:48:30.799226  5289 sgd_solver.cpp:105] Iteration 92300, lr = 0.001
I1008 04:48:55.888902  5289 solver.cpp:218] Iteration 92400 (3.98605 iter/s, 25.0875s/100 iters), loss = 0.00282828
I1008 04:48:55.888936  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00282823 (* 1 = 0.00282823 loss)
I1008 04:48:55.888942  5289 sgd_solver.cpp:105] Iteration 92400, lr = 0.001
I1008 04:49:19.287618  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:49:20.267225  5289 solver.cpp:330] Iteration 92500, Testing net (#0)
I1008 04:49:24.865322  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:49:25.053858  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9155
I1008 04:49:25.053887  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.353745 (* 1 = 0.353745 loss)
I1008 04:49:25.210687  5289 solver.cpp:218] Iteration 92500 (3.41064 iter/s, 29.32s/100 iters), loss = 0.00164186
I1008 04:49:25.210718  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0016418 (* 1 = 0.0016418 loss)
I1008 04:49:25.210726  5289 sgd_solver.cpp:105] Iteration 92500, lr = 0.001
I1008 04:49:50.179190  5289 solver.cpp:218] Iteration 92600 (4.00541 iter/s, 24.9662s/100 iters), loss = 0.0176796
I1008 04:49:50.179283  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0176796 (* 1 = 0.0176796 loss)
I1008 04:49:50.179296  5289 sgd_solver.cpp:105] Iteration 92600, lr = 0.001
I1008 04:50:14.743950  5289 solver.cpp:218] Iteration 92700 (4.07124 iter/s, 24.5625s/100 iters), loss = 0.0103302
I1008 04:50:14.743995  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0103301 (* 1 = 0.0103301 loss)
I1008 04:50:14.744004  5289 sgd_solver.cpp:105] Iteration 92700, lr = 0.001
I1008 04:50:39.369374  5289 solver.cpp:218] Iteration 92800 (4.06122 iter/s, 24.6232s/100 iters), loss = 0.0120252
I1008 04:50:39.369462  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0120252 (* 1 = 0.0120252 loss)
I1008 04:50:39.369470  5289 sgd_solver.cpp:105] Iteration 92800, lr = 0.001
I1008 04:51:04.450418  5289 solver.cpp:218] Iteration 92900 (3.98757 iter/s, 25.0779s/100 iters), loss = 0.0063078
I1008 04:51:04.450464  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00630774 (* 1 = 0.00630774 loss)
I1008 04:51:04.450471  5289 sgd_solver.cpp:105] Iteration 92900, lr = 0.001
I1008 04:51:27.915506  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:51:28.894708  5289 solver.cpp:330] Iteration 93000, Testing net (#0)
I1008 04:51:33.444721  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:51:33.667623  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9162
I1008 04:51:33.667650  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.354892 (* 1 = 0.354892 loss)
I1008 04:51:33.786120  5289 solver.cpp:218] Iteration 93000 (3.40921 iter/s, 29.3323s/100 iters), loss = 0.00233922
I1008 04:51:33.786154  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00233916 (* 1 = 0.00233916 loss)
I1008 04:51:33.786160  5289 sgd_solver.cpp:105] Iteration 93000, lr = 0.001
I1008 04:51:58.740193  5289 solver.cpp:218] Iteration 93100 (4.00739 iter/s, 24.9539s/100 iters), loss = 0.00529181
I1008 04:51:58.740278  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00529175 (* 1 = 0.00529175 loss)
I1008 04:51:58.740288  5289 sgd_solver.cpp:105] Iteration 93100, lr = 0.001
I1008 04:52:23.372440  5289 solver.cpp:218] Iteration 93200 (4.06045 iter/s, 24.6278s/100 iters), loss = 0.00918011
I1008 04:52:23.372478  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00918005 (* 1 = 0.00918005 loss)
I1008 04:52:23.372485  5289 sgd_solver.cpp:105] Iteration 93200, lr = 0.001
I1008 04:52:48.006290  5289 solver.cpp:218] Iteration 93300 (4.06007 iter/s, 24.6301s/100 iters), loss = 0.00453417
I1008 04:52:48.006363  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00453411 (* 1 = 0.00453411 loss)
I1008 04:52:48.006372  5289 sgd_solver.cpp:105] Iteration 93300, lr = 0.001
I1008 04:53:13.023185  5289 solver.cpp:218] Iteration 93400 (3.99787 iter/s, 25.0133s/100 iters), loss = 0.00581154
I1008 04:53:13.023218  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00581148 (* 1 = 0.00581148 loss)
I1008 04:53:13.023226  5289 sgd_solver.cpp:105] Iteration 93400, lr = 0.001
I1008 04:53:36.483214  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:53:37.468471  5289 solver.cpp:330] Iteration 93500, Testing net (#0)
I1008 04:53:42.042678  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:53:42.198305  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9152
I1008 04:53:42.198333  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.354995 (* 1 = 0.354995 loss)
I1008 04:53:42.386342  5289 solver.cpp:218] Iteration 93500 (3.40589 iter/s, 29.3609s/100 iters), loss = 0.00239894
I1008 04:53:42.386374  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00239888 (* 1 = 0.00239888 loss)
I1008 04:53:42.386382  5289 sgd_solver.cpp:105] Iteration 93500, lr = 0.001
I1008 04:54:07.361660  5289 solver.cpp:218] Iteration 93600 (4.00431 iter/s, 24.9731s/100 iters), loss = 0.00842469
I1008 04:54:07.361784  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00842464 (* 1 = 0.00842464 loss)
I1008 04:54:07.361809  5289 sgd_solver.cpp:105] Iteration 93600, lr = 0.001
I1008 04:54:32.018040  5289 solver.cpp:218] Iteration 93700 (4.05637 iter/s, 24.6526s/100 iters), loss = 0.00118918
I1008 04:54:32.018074  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00118912 (* 1 = 0.00118912 loss)
I1008 04:54:32.018080  5289 sgd_solver.cpp:105] Iteration 93700, lr = 0.001
I1008 04:54:56.679898  5289 solver.cpp:218] Iteration 93800 (4.05543 iter/s, 24.6583s/100 iters), loss = 0.00152371
I1008 04:54:56.679973  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00152365 (* 1 = 0.00152365 loss)
I1008 04:54:56.679981  5289 sgd_solver.cpp:105] Iteration 93800, lr = 0.001
I1008 04:55:21.558549  5289 solver.cpp:218] Iteration 93900 (4.01988 iter/s, 24.8764s/100 iters), loss = 0.00886205
I1008 04:55:21.558583  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.008862 (* 1 = 0.008862 loss)
I1008 04:55:21.558589  5289 sgd_solver.cpp:105] Iteration 93900, lr = 0.001
I1008 04:55:45.176851  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:55:46.159586  5289 solver.cpp:330] Iteration 94000, Testing net (#0)
I1008 04:55:50.700322  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:55:50.861569  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9155
I1008 04:55:50.861608  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.355989 (* 1 = 0.355989 loss)
I1008 04:55:51.034255  5289 solver.cpp:218] Iteration 94000 (3.39312 iter/s, 29.4714s/100 iters), loss = 0.00523641
I1008 04:55:51.034301  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00523636 (* 1 = 0.00523636 loss)
I1008 04:55:51.034307  5289 sgd_solver.cpp:105] Iteration 94000, lr = 0.001
I1008 04:56:16.087409  5289 solver.cpp:218] Iteration 94100 (3.99154 iter/s, 25.053s/100 iters), loss = 0.0132014
I1008 04:56:16.087476  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0132013 (* 1 = 0.0132013 loss)
I1008 04:56:16.087486  5289 sgd_solver.cpp:105] Iteration 94100, lr = 0.001
I1008 04:56:40.763556  5289 solver.cpp:218] Iteration 94200 (4.05315 iter/s, 24.6722s/100 iters), loss = 0.00264295
I1008 04:56:40.763589  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00264289 (* 1 = 0.00264289 loss)
I1008 04:56:40.763597  5289 sgd_solver.cpp:105] Iteration 94200, lr = 0.001
I1008 04:57:05.399425  5289 solver.cpp:218] Iteration 94300 (4.05984 iter/s, 24.6315s/100 iters), loss = 0.00815398
I1008 04:57:05.399588  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00815392 (* 1 = 0.00815392 loss)
I1008 04:57:05.399598  5289 sgd_solver.cpp:105] Iteration 94300, lr = 0.001
I1008 04:57:30.227300  5289 solver.cpp:218] Iteration 94400 (4.02832 iter/s, 24.8243s/100 iters), loss = 0.00221006
I1008 04:57:30.227336  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00221 (* 1 = 0.00221 loss)
I1008 04:57:30.227344  5289 sgd_solver.cpp:105] Iteration 94400, lr = 0.001
I1008 04:57:53.920842  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:57:54.904877  5289 solver.cpp:330] Iteration 94500, Testing net (#0)
I1008 04:57:59.461324  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:57:59.650094  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9164
I1008 04:57:59.650123  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.355567 (* 1 = 0.355567 loss)
I1008 04:57:59.801935  5289 solver.cpp:218] Iteration 94500 (3.38129 iter/s, 29.5745s/100 iters), loss = 0.0054764
I1008 04:57:59.801976  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00547634 (* 1 = 0.00547634 loss)
I1008 04:57:59.801983  5289 sgd_solver.cpp:105] Iteration 94500, lr = 0.001
I1008 04:58:24.859751  5289 solver.cpp:218] Iteration 94600 (3.99079 iter/s, 25.0577s/100 iters), loss = 0.0126668
I1008 04:58:24.859858  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0126667 (* 1 = 0.0126667 loss)
I1008 04:58:24.859869  5289 sgd_solver.cpp:105] Iteration 94600, lr = 0.001
I1008 04:58:49.508656  5289 solver.cpp:218] Iteration 94700 (4.05735 iter/s, 24.6467s/100 iters), loss = 0.00851745
I1008 04:58:49.508690  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00851738 (* 1 = 0.00851738 loss)
I1008 04:58:49.508699  5289 sgd_solver.cpp:105] Iteration 94700, lr = 0.001
I1008 04:59:14.159431  5289 solver.cpp:218] Iteration 94800 (4.05704 iter/s, 24.6485s/100 iters), loss = 0.00438679
I1008 04:59:14.159531  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00438673 (* 1 = 0.00438673 loss)
I1008 04:59:14.159548  5289 sgd_solver.cpp:105] Iteration 94800, lr = 0.001
I1008 04:59:38.924677  5289 solver.cpp:218] Iteration 94900 (4.03828 iter/s, 24.763s/100 iters), loss = 0.0064188
I1008 04:59:38.924712  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00641874 (* 1 = 0.00641874 loss)
I1008 04:59:38.924722  5289 sgd_solver.cpp:105] Iteration 94900, lr = 0.001
I1008 05:00:02.666800  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 05:00:03.647487  5289 solver.cpp:330] Iteration 95000, Testing net (#0)
I1008 05:00:08.304679  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 05:00:08.469127  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9167
I1008 05:00:08.469154  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.354119 (* 1 = 0.354119 loss)
I1008 05:00:08.662745  5289 solver.cpp:218] Iteration 95000 (3.36312 iter/s, 29.7343s/100 iters), loss = 0.0111753
I1008 05:00:08.662781  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0111752 (* 1 = 0.0111752 loss)
I1008 05:00:08.662787  5289 sgd_solver.cpp:105] Iteration 95000, lr = 0.001
I1008 05:00:33.579229  5289 solver.cpp:218] Iteration 95100 (4.01377 iter/s, 24.9142s/100 iters), loss = 0.00191355
I1008 05:00:33.579319  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00191349 (* 1 = 0.00191349 loss)
I1008 05:00:33.579327  5289 sgd_solver.cpp:105] Iteration 95100, lr = 0.001
I1008 05:00:58.179338  5289 solver.cpp:218] Iteration 95200 (4.06506 iter/s, 24.5999s/100 iters), loss = 0.00412931
I1008 05:00:58.179383  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00412925 (* 1 = 0.00412925 loss)
I1008 05:00:58.179389  5289 sgd_solver.cpp:105] Iteration 95200, lr = 0.001
I1008 05:01:22.800730  5289 solver.cpp:218] Iteration 95300 (4.06188 iter/s, 24.6191s/100 iters), loss = 0.0042559
I1008 05:01:22.800824  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00425584 (* 1 = 0.00425584 loss)
I1008 05:01:22.800833  5289 sgd_solver.cpp:105] Iteration 95300, lr = 0.001
I1008 05:01:47.440630  5289 solver.cpp:218] Iteration 95400 (4.05884 iter/s, 24.6376s/100 iters), loss = 0.00381616
I1008 05:01:47.440665  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00381609 (* 1 = 0.00381609 loss)
I1008 05:01:47.440672  5289 sgd_solver.cpp:105] Iteration 95400, lr = 0.001
I1008 05:02:11.205936  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 05:02:12.187932  5289 solver.cpp:330] Iteration 95500, Testing net (#0)
I1008 05:02:16.853641  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 05:02:17.038362  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.917
I1008 05:02:17.038389  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.356012 (* 1 = 0.356012 loss)
I1008 05:02:17.217123  5289 solver.cpp:218] Iteration 95500 (3.35837 iter/s, 29.7763s/100 iters), loss = 0.00223542
I1008 05:02:17.217154  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00223536 (* 1 = 0.00223536 loss)
I1008 05:02:17.217160  5289 sgd_solver.cpp:105] Iteration 95500, lr = 0.001
I1008 05:02:42.304427  5289 solver.cpp:218] Iteration 95600 (3.98644 iter/s, 25.085s/100 iters), loss = 0.0057396
I1008 05:02:42.304548  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00573953 (* 1 = 0.00573953 loss)
I1008 05:02:42.304558  5289 sgd_solver.cpp:105] Iteration 95600, lr = 0.001
I1008 05:03:06.922278  5289 solver.cpp:218] Iteration 95700 (4.06274 iter/s, 24.614s/100 iters), loss = 0.00411351
I1008 05:03:06.922323  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00411344 (* 1 = 0.00411344 loss)
I1008 05:03:06.922333  5289 sgd_solver.cpp:105] Iteration 95700, lr = 0.001
I1008 05:03:31.539183  5289 solver.cpp:218] Iteration 95800 (4.06262 iter/s, 24.6146s/100 iters), loss = 0.00242522
I1008 05:03:31.539270  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00242516 (* 1 = 0.00242516 loss)
I1008 05:03:31.539279  5289 sgd_solver.cpp:105] Iteration 95800, lr = 0.001
I1008 05:03:56.192621  5289 solver.cpp:218] Iteration 95900 (4.05695 iter/s, 24.649s/100 iters), loss = 0.00873375
I1008 05:03:56.192664  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00873369 (* 1 = 0.00873369 loss)
I1008 05:03:56.192673  5289 sgd_solver.cpp:105] Iteration 95900, lr = 0.001
I1008 05:04:20.045023  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 05:04:21.031829  5289 solver.cpp:330] Iteration 96000, Testing net (#0)
I1008 05:04:25.693081  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 05:04:25.856770  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9167
I1008 05:04:25.856797  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.355836 (* 1 = 0.355836 loss)
I1008 05:04:26.045008  5289 solver.cpp:218] Iteration 96000 (3.35031 iter/s, 29.848s/100 iters), loss = 0.0163198
I1008 05:04:26.045040  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0163197 (* 1 = 0.0163197 loss)
I1008 05:04:26.045047  5289 sgd_solver.cpp:105] Iteration 96000, lr = 0.001
I1008 05:04:51.060761  5289 solver.cpp:218] Iteration 96100 (3.99784 iter/s, 25.0135s/100 iters), loss = 0.00252244
I1008 05:04:51.060842  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00252237 (* 1 = 0.00252237 loss)
I1008 05:04:51.060852  5289 sgd_solver.cpp:105] Iteration 96100, lr = 0.001
I1008 05:05:15.707043  5289 solver.cpp:218] Iteration 96200 (4.05778 iter/s, 24.644s/100 iters), loss = 0.00219028
I1008 05:05:15.707079  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00219022 (* 1 = 0.00219022 loss)
I1008 05:05:15.707088  5289 sgd_solver.cpp:105] Iteration 96200, lr = 0.001
I1008 05:05:40.335067  5289 solver.cpp:218] Iteration 96300 (4.06079 iter/s, 24.6257s/100 iters), loss = 0.0061131
I1008 05:05:40.335161  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00611303 (* 1 = 0.00611303 loss)
I1008 05:05:40.335181  5289 sgd_solver.cpp:105] Iteration 96300, lr = 0.001
I1008 05:06:04.996719  5289 solver.cpp:218] Iteration 96400 (4.05549 iter/s, 24.6579s/100 iters), loss = 0.00253948
I1008 05:06:04.996764  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00253941 (* 1 = 0.00253941 loss)
I1008 05:06:04.996773  5289 sgd_solver.cpp:105] Iteration 96400, lr = 0.001
I1008 05:06:28.850831  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 05:06:29.833848  5289 solver.cpp:330] Iteration 96500, Testing net (#0)
I1008 05:06:34.439749  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 05:06:34.626377  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9162
I1008 05:06:34.626411  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.357197 (* 1 = 0.357197 loss)
I1008 05:06:34.793417  5289 solver.cpp:218] Iteration 96500 (3.35633 iter/s, 29.7944s/100 iters), loss = 0.00162778
I1008 05:06:34.793450  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00162771 (* 1 = 0.00162771 loss)
I1008 05:06:34.793457  5289 sgd_solver.cpp:105] Iteration 96500, lr = 0.001
I1008 05:06:59.830130  5289 solver.cpp:218] Iteration 96600 (3.99484 iter/s, 25.0323s/100 iters), loss = 0.00348322
I1008 05:06:59.830220  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00348315 (* 1 = 0.00348315 loss)
I1008 05:06:59.830229  5289 sgd_solver.cpp:105] Iteration 96600, lr = 0.001
I1008 05:07:24.492815  5289 solver.cpp:218] Iteration 96700 (4.05543 iter/s, 24.6583s/100 iters), loss = 0.00733988
I1008 05:07:24.492851  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00733981 (* 1 = 0.00733981 loss)
I1008 05:07:24.492857  5289 sgd_solver.cpp:105] Iteration 96700, lr = 0.001
I1008 05:07:49.142511  5289 solver.cpp:218] Iteration 96800 (4.05722 iter/s, 24.6474s/100 iters), loss = 0.00208182
I1008 05:07:49.142596  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00208175 (* 1 = 0.00208175 loss)
I1008 05:07:49.142604  5289 sgd_solver.cpp:105] Iteration 96800, lr = 0.001
I1008 05:08:13.693125  5289 solver.cpp:218] Iteration 96900 (4.07359 iter/s, 24.5484s/100 iters), loss = 0.00385581
I1008 05:08:13.693158  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00385574 (* 1 = 0.00385574 loss)
I1008 05:08:13.693166  5289 sgd_solver.cpp:105] Iteration 96900, lr = 0.001
I1008 05:08:37.487604  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 05:08:38.472693  5289 solver.cpp:330] Iteration 97000, Testing net (#0)
I1008 05:08:43.140180  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 05:08:43.312551  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9168
I1008 05:08:43.312577  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.359838 (* 1 = 0.359838 loss)
I1008 05:08:43.497184  5289 solver.cpp:218] Iteration 97000 (3.35551 iter/s, 29.8018s/100 iters), loss = 0.000733468
I1008 05:08:43.497217  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000733395 (* 1 = 0.000733395 loss)
I1008 05:08:43.497223  5289 sgd_solver.cpp:105] Iteration 97000, lr = 0.001
I1008 05:09:08.600389  5289 solver.cpp:218] Iteration 97100 (3.98392 iter/s, 25.1009s/100 iters), loss = 0.00541923
I1008 05:09:08.600471  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00541916 (* 1 = 0.00541916 loss)
I1008 05:09:08.600478  5289 sgd_solver.cpp:105] Iteration 97100, lr = 0.001
I1008 05:09:33.248030  5289 solver.cpp:218] Iteration 97200 (4.05756 iter/s, 24.6454s/100 iters), loss = 0.00414454
I1008 05:09:33.248069  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00414447 (* 1 = 0.00414447 loss)
I1008 05:09:33.248076  5289 sgd_solver.cpp:105] Iteration 97200, lr = 0.001
I1008 05:09:57.893113  5289 solver.cpp:218] Iteration 97300 (4.05798 iter/s, 24.6428s/100 iters), loss = 0.00385903
I1008 05:09:57.893188  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00385895 (* 1 = 0.00385895 loss)
I1008 05:09:57.893196  5289 sgd_solver.cpp:105] Iteration 97300, lr = 0.001
I1008 05:10:22.533083  5289 solver.cpp:218] Iteration 97400 (4.05882 iter/s, 24.6377s/100 iters), loss = 0.00321701
I1008 05:10:22.533118  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00321693 (* 1 = 0.00321693 loss)
I1008 05:10:22.533124  5289 sgd_solver.cpp:105] Iteration 97400, lr = 0.001
I1008 05:10:46.387421  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 05:10:47.364401  5289 solver.cpp:330] Iteration 97500, Testing net (#0)
I1008 05:10:52.042100  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 05:10:52.186069  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9166
I1008 05:10:52.186094  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.359392 (* 1 = 0.359392 loss)
I1008 05:10:52.398290  5289 solver.cpp:218] Iteration 97500 (3.34864 iter/s, 29.8629s/100 iters), loss = 0.002412
I1008 05:10:52.398324  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00241192 (* 1 = 0.00241192 loss)
I1008 05:10:52.398331  5289 sgd_solver.cpp:105] Iteration 97500, lr = 0.001
I1008 05:11:17.478603  5289 solver.cpp:218] Iteration 97600 (3.98755 iter/s, 25.078s/100 iters), loss = 0.00399648
I1008 05:11:17.478726  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00399641 (* 1 = 0.00399641 loss)
I1008 05:11:17.478735  5289 sgd_solver.cpp:105] Iteration 97600, lr = 0.001
I1008 05:11:42.109798  5289 solver.cpp:218] Iteration 97700 (4.06026 iter/s, 24.6289s/100 iters), loss = 0.00845638
I1008 05:11:42.109829  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00845631 (* 1 = 0.00845631 loss)
I1008 05:11:42.109836  5289 sgd_solver.cpp:105] Iteration 97700, lr = 0.001
I1008 05:12:06.728375  5289 solver.cpp:218] Iteration 97800 (4.06234 iter/s, 24.6163s/100 iters), loss = 0.00482972
I1008 05:12:06.728469  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00482965 (* 1 = 0.00482965 loss)
I1008 05:12:06.728477  5289 sgd_solver.cpp:105] Iteration 97800, lr = 0.001
I1008 05:12:31.372702  5289 solver.cpp:218] Iteration 97900 (4.05845 iter/s, 24.64s/100 iters), loss = 0.00356113
I1008 05:12:31.372736  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00356106 (* 1 = 0.00356106 loss)
I1008 05:12:31.372752  5289 sgd_solver.cpp:105] Iteration 97900, lr = 0.001
I1008 05:12:55.255055  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 05:12:56.239930  5289 solver.cpp:330] Iteration 98000, Testing net (#0)
I1008 05:13:00.896893  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 05:13:01.083245  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9159
I1008 05:13:01.083272  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.361477 (* 1 = 0.361477 loss)
I1008 05:13:01.244911  5289 solver.cpp:218] Iteration 98000 (3.34803 iter/s, 29.8683s/100 iters), loss = 0.013151
I1008 05:13:01.244943  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0131509 (* 1 = 0.0131509 loss)
I1008 05:13:01.244951  5289 sgd_solver.cpp:105] Iteration 98000, lr = 0.001
I1008 05:13:26.356921  5289 solver.cpp:218] Iteration 98100 (3.98251 iter/s, 25.1098s/100 iters), loss = 0.00523374
I1008 05:13:26.357003  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00523367 (* 1 = 0.00523367 loss)
I1008 05:13:26.357012  5289 sgd_solver.cpp:105] Iteration 98100, lr = 0.001
I1008 05:13:51.008496  5289 solver.cpp:218] Iteration 98200 (4.05713 iter/s, 24.648s/100 iters), loss = 0.00398087
I1008 05:13:51.008533  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00398079 (* 1 = 0.00398079 loss)
I1008 05:13:51.008539  5289 sgd_solver.cpp:105] Iteration 98200, lr = 0.001
I1008 05:14:15.652730  5289 solver.cpp:218] Iteration 98300 (4.05847 iter/s, 24.6398s/100 iters), loss = 0.0170986
I1008 05:14:15.652807  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0170985 (* 1 = 0.0170985 loss)
I1008 05:14:15.652817  5289 sgd_solver.cpp:105] Iteration 98300, lr = 0.001
I1008 05:14:40.256155  5289 solver.cpp:218] Iteration 98400 (4.06485 iter/s, 24.6012s/100 iters), loss = 0.00218191
I1008 05:14:40.256202  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00218184 (* 1 = 0.00218184 loss)
I1008 05:14:40.256211  5289 sgd_solver.cpp:105] Iteration 98400, lr = 0.001
I1008 05:15:04.105057  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 05:15:05.086123  5289 solver.cpp:330] Iteration 98500, Testing net (#0)
I1008 05:15:09.581419  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 05:15:09.796722  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9167
I1008 05:15:09.796748  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.359025 (* 1 = 0.359025 loss)
I1008 05:15:09.930049  5289 solver.cpp:218] Iteration 98500 (3.37022 iter/s, 29.6716s/100 iters), loss = 0.00318405
I1008 05:15:09.930091  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00318398 (* 1 = 0.00318398 loss)
I1008 05:15:09.930099  5289 sgd_solver.cpp:105] Iteration 98500, lr = 0.001
I1008 05:15:34.899611  5289 solver.cpp:218] Iteration 98600 (4.00558 iter/s, 24.9652s/100 iters), loss = 0.00192039
I1008 05:15:34.899749  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00192032 (* 1 = 0.00192032 loss)
I1008 05:15:34.899758  5289 sgd_solver.cpp:105] Iteration 98600, lr = 0.001
I1008 05:15:59.595633  5289 solver.cpp:218] Iteration 98700 (4.04996 iter/s, 24.6916s/100 iters), loss = 0.0114885
I1008 05:15:59.595669  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0114885 (* 1 = 0.0114885 loss)
I1008 05:15:59.595676  5289 sgd_solver.cpp:105] Iteration 98700, lr = 0.001
I1008 05:16:24.256755  5289 solver.cpp:218] Iteration 98800 (4.05569 iter/s, 24.6567s/100 iters), loss = 0.00129411
I1008 05:16:24.256852  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00129404 (* 1 = 0.00129404 loss)
I1008 05:16:24.256861  5289 sgd_solver.cpp:105] Iteration 98800, lr = 0.001
I1008 05:16:48.907302  5289 solver.cpp:218] Iteration 98900 (4.05743 iter/s, 24.6462s/100 iters), loss = 0.00129248
I1008 05:16:48.907338  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0012924 (* 1 = 0.0012924 loss)
I1008 05:16:48.907346  5289 sgd_solver.cpp:105] Iteration 98900, lr = 0.001
I1008 05:17:12.778035  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 05:17:13.761586  5289 solver.cpp:330] Iteration 99000, Testing net (#0)
I1008 05:17:18.428570  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 05:17:18.625504  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9159
I1008 05:17:18.625530  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.358089 (* 1 = 0.358089 loss)
I1008 05:17:18.780139  5289 solver.cpp:218] Iteration 99000 (3.34802 iter/s, 29.8684s/100 iters), loss = 0.00272755
I1008 05:17:18.780180  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00272747 (* 1 = 0.00272747 loss)
I1008 05:17:18.780187  5289 sgd_solver.cpp:105] Iteration 99000, lr = 0.001
I1008 05:17:43.938050  5289 solver.cpp:218] Iteration 99100 (3.97525 iter/s, 25.1557s/100 iters), loss = 0.0034979
I1008 05:17:43.938139  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00349782 (* 1 = 0.00349782 loss)
I1008 05:17:43.938148  5289 sgd_solver.cpp:105] Iteration 99100, lr = 0.001
I1008 05:18:08.585227  5289 solver.cpp:218] Iteration 99200 (4.05764 iter/s, 24.6449s/100 iters), loss = 0.00968491
I1008 05:18:08.585260  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00968483 (* 1 = 0.00968483 loss)
I1008 05:18:08.585268  5289 sgd_solver.cpp:105] Iteration 99200, lr = 0.001
I1008 05:18:33.200316  5289 solver.cpp:218] Iteration 99300 (4.06292 iter/s, 24.6128s/100 iters), loss = 0.00773661
I1008 05:18:33.200384  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00773653 (* 1 = 0.00773653 loss)
I1008 05:18:33.200392  5289 sgd_solver.cpp:105] Iteration 99300, lr = 0.001
I1008 05:18:57.828022  5289 solver.cpp:218] Iteration 99400 (4.06084 iter/s, 24.6255s/100 iters), loss = 0.00285598
I1008 05:18:57.828063  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0028559 (* 1 = 0.0028559 loss)
I1008 05:18:57.828069  5289 sgd_solver.cpp:105] Iteration 99400, lr = 0.001
I1008 05:19:21.707800  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 05:19:22.693069  5289 solver.cpp:330] Iteration 99500, Testing net (#0)
I1008 05:19:27.266110  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 05:19:27.430202  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9164
I1008 05:19:27.430232  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.359479 (* 1 = 0.359479 loss)
I1008 05:19:27.608453  5289 solver.cpp:218] Iteration 99500 (3.35817 iter/s, 29.7781s/100 iters), loss = 0.00457951
I1008 05:19:27.608484  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00457943 (* 1 = 0.00457943 loss)
I1008 05:19:27.608490  5289 sgd_solver.cpp:105] Iteration 99500, lr = 0.001
I1008 05:19:52.555543  5289 solver.cpp:218] Iteration 99600 (4.00885 iter/s, 24.9448s/100 iters), loss = 0.00673105
I1008 05:19:52.555652  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00673098 (* 1 = 0.00673098 loss)
I1008 05:19:52.555660  5289 sgd_solver.cpp:105] Iteration 99600, lr = 0.001
I1008 05:20:17.218355  5289 solver.cpp:218] Iteration 99700 (4.05506 iter/s, 24.6606s/100 iters), loss = 0.00724401
I1008 05:20:17.218396  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00724393 (* 1 = 0.00724393 loss)
I1008 05:20:17.218403  5289 sgd_solver.cpp:105] Iteration 99700, lr = 0.001
I1008 05:20:41.871035  5289 solver.cpp:218] Iteration 99800 (4.05672 iter/s, 24.6504s/100 iters), loss = 0.0024501
I1008 05:20:41.871116  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00245002 (* 1 = 0.00245002 loss)
I1008 05:20:41.871124  5289 sgd_solver.cpp:105] Iteration 99800, lr = 0.001
I1008 05:21:06.528077  5289 solver.cpp:218] Iteration 99900 (4.05635 iter/s, 24.6527s/100 iters), loss = 0.00609713
I1008 05:21:06.528120  5289 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00609704 (* 1 = 0.00609704 loss)
I1008 05:21:06.528126  5289 sgd_solver.cpp:105] Iteration 99900, lr = 0.001
I1008 05:21:30.399477  5297 data_layer.cpp:73] Restarting data prefetching from start.
I1008 05:21:31.383129  5289 solver.cpp:447] Snapshotting to binary proto file xn/PENLU/snapshot/resnet/res32/res32_elu_alpha1_gauss_iter_100000.caffemodel
I1008 05:21:31.396595  5289 sgd_solver.cpp:273] Snapshotting solver state to binary proto file xn/PENLU/snapshot/resnet/res32/res32_elu_alpha1_gauss_iter_100000.solverstate
I1008 05:21:31.457841  5289 solver.cpp:310] Iteration 100000, loss = 0.00612203
I1008 05:21:31.457865  5289 solver.cpp:330] Iteration 100000, Testing net (#0)
I1008 05:21:35.978117  5298 data_layer.cpp:73] Restarting data prefetching from start.
I1008 05:21:36.183346  5289 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9166
I1008 05:21:36.183373  5289 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.358127 (* 1 = 0.358127 loss)
I1008 05:21:36.183379  5289 solver.cpp:315] Optimization Done.
I1008 05:21:36.183382  5289 caffe.cpp:259] Optimization Done.
