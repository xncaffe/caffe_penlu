I1006 15:09:05.280755  2964 caffe.cpp:218] Using GPUs 0
I1006 15:09:05.322767  2964 caffe.cpp:223] GPU 0: GeForce GTX 1080
I1006 15:09:05.548822  2964 solver.cpp:44] Initializing solver from parameters: 
test_iter: 100
test_interval: 500
base_lr: 0.1
display: 100
max_iter: 100000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0001
snapshot: 100000
snapshot_prefix: "xn/PENLU/snapshot/resnet/res32/res32_penlu_alpha0.25_beta1_etanostudy_2study_2decay_gauss"
solver_mode: GPU
device_id: 0
net: "/home/x306/caffe/xn/PENLU/neural/resnet/res32/res32_penlu_decay_gauss.prototxt"
train_state {
  level: 0
  stage: ""
}
stepvalue: 40000
stepvalue: 80000
I1006 15:09:05.548962  2964 solver.cpp:87] Creating training net from net file: /home/x306/caffe/xn/PENLU/neural/resnet/res32/res32_penlu_decay_gauss.prototxt
I1006 15:09:05.551286  2964 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: /home/x306/caffe/xn/PENLU/neural/resnet/res32/res32_penlu_decay_gauss.prototxt
I1006 15:09:05.551297  2964 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I1006 15:09:05.551489  2964 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer Data1
I1006 15:09:05.551585  2964 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer Accuracy1
I1006 15:09:05.552304  2964 net.cpp:51] Initializing net from parameters: 
name: "resnet_cifar10"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "Data1"
  type: "Data"
  top: "Data1"
  top: "Data2"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 28
    mean_file: "/home/x306/caffe/xn/PENLU/data/cifar10/mean.binaryproto"
  }
  data_param {
    source: "/home/x306/caffe/xn/PENLU/data/cifar10/cifar10_train_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "Convolution1"
  type: "Convolution"
  bottom: "Data1"
  top: "Convolution1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm1"
  type: "BatchNorm"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1"
  type: "Scale"
  bottom: "Convolution1"
  top: "Convolution1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu1"
  type: "PENLU"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution2"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm2"
  type: "BatchNorm"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale2"
  type: "Scale"
  bottom: "Convolution2"
  top: "Convolution2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu2"
  type: "PENLU"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution3"
  type: "Convolution"
  bottom: "Convolution2"
  top: "Convolution3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm3"
  type: "BatchNorm"
  bottom: "Convolution3"
  top: "Convolution3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale3"
  type: "Scale"
  bottom: "Convolution3"
  top: "Convolution3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise1"
  type: "Eltwise"
  bottom: "Convolution1"
  bottom: "Convolution3"
  top: "Eltwise1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu3"
  type: "PENLU"
  bottom: "Eltwise1"
  top: "Eltwise1"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution4"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm4"
  type: "BatchNorm"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale4"
  type: "Scale"
  bottom: "Convolution4"
  top: "Convolution4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu4"
  type: "PENLU"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution5"
  type: "Convolution"
  bottom: "Convolution4"
  top: "Convolution5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm5"
  type: "BatchNorm"
  bottom: "Convolution5"
  top: "Convolution5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale5"
  type: "Scale"
  bottom: "Convolution5"
  top: "Convolution5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise2"
  type: "Eltwise"
  bottom: "Eltwise1"
  bottom: "Convolution5"
  top: "Eltwise2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu5"
  type: "PENLU"
  bottom: "Eltwise2"
  top: "Eltwise2"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution6"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm6"
  type: "BatchNorm"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale6"
  type: "Scale"
  bottom: "Convolution6"
  top: "Convolution6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu6"
  type: "PENLU"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution7"
  type: "Convolution"
  bottom: "Convolution6"
  top: "Convolution7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm7"
  type: "BatchNorm"
  bottom: "Convolution7"
  top: "Convolution7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale7"
  type: "Scale"
  bottom: "Convolution7"
  top: "Convolution7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise3"
  type: "Eltwise"
  bottom: "Eltwise2"
  bottom: "Convolution7"
  top: "Eltwise3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu7"
  type: "PENLU"
  bottom: "Eltwise3"
  top: "Eltwise3"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution8"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm8"
  type: "BatchNorm"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale8"
  type: "Scale"
  bottom: "Convolution8"
  top: "Convolution8"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu8"
  type: "PENLU"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution9"
  type: "Convolution"
  bottom: "Convolution8"
  top: "Convolution9"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm9"
  type: "BatchNorm"
  bottom: "Convolution9"
  top: "Convolution9"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale9"
  type: "Scale"
  bottom: "Convolution9"
  top: "Convolution9"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise4"
  type: "Eltwise"
  bottom: "Eltwise3"
  bottom: "Convolution9"
  top: "Eltwise4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu9"
  type: "PENLU"
  bottom: "Eltwise4"
  top: "Eltwise4"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution10"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution10"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm10"
  type: "BatchNorm"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale10"
  type: "Scale"
  bottom: "Convolution10"
  top: "Convolution10"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu10"
  type: "PENLU"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution11"
  type: "Convolution"
  bottom: "Convolution10"
  top: "Convolution11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm11"
  type: "BatchNorm"
  bottom: "Convolution11"
  top: "Convolution11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale11"
  type: "Scale"
  bottom: "Convolution11"
  top: "Convolution11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise5"
  type: "Eltwise"
  bottom: "Eltwise4"
  bottom: "Convolution11"
  top: "Eltwise5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu11"
  type: "PENLU"
  bottom: "Eltwise5"
  top: "Eltwise5"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution12"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.25
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm12"
  type: "BatchNorm"
  bottom: "Convolution12"
  top: "Convolution12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale12"
  type: "Scale"
  bottom: "Convolution12"
  top: "Convolution12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution13"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution13"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm13"
  type: "BatchNorm"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale13"
  type: "Scale"
  bottom: "Convolution13"
  top: "Convolution13"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu12"
  type: "PENLU"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution14"
  type: "Convolution"
  bottom: "Convolution13"
  top: "Convolution14"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm14"
  type: "BatchNorm"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale14"
  type: "Scale"
  bottom: "Convolution14"
  top: "Convolution14"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise6"
  type: "Eltwise"
  bottom: "Convolution12"
  bottom: "Convolution14"
  top: "Eltwise6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu13"
  type: "PENLU"
  bottom: "Eltwise6"
  top: "Eltwise6"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution15"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution15"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm15"
  type: "BatchNorm"
  bottom: "Convolution15"
  top: "Convolution15"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale15"
  type: "Scale"
  bottom: "Convolution15"
  top: "Convolution15"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu14"
  type: "PENLU"
  bottom: "Convolution15"
  top: "Convolution15"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution16"
  type: "Convolution"
  bottom: "Convolution15"
  top: "Convolution16"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm16"
  type: "BatchNorm"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale16"
  type: "Scale"
  bottom: "Convolution16"
  top: "Convolution16"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise7"
  type: "Eltwise"
  bottom: "Eltwise6"
  bottom: "Convolution16"
  top: "Eltwise7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu15"
  type: "PENLU"
  bottom: "Eltwise7"
  top: "Eltwise7"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution17"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution17"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm17"
  type: "BatchNorm"
  bottom: "Convolution17"
  top: "Convolution17"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale17"
  type: "Scale"
  bottom: "Convolution17"
  top: "Convolution17"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu16"
  type: "PENLU"
  bottom: "Convolution17"
  top: "Convolution17"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution18"
  type: "Convolution"
  bottom: "Convolution17"
  top: "Convolution18"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm18"
  type: "BatchNorm"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale18"
  type: "Scale"
  bottom: "Convolution18"
  top: "Convolution18"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise8"
  type: "Eltwise"
  bottom: "Eltwise7"
  bottom: "Convolution18"
  top: "Eltwise8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu17"
  type: "PENLU"
  bottom: "Eltwise8"
  top: "Eltwise8"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution19"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution19"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm19"
  type: "BatchNorm"
  bottom: "Convolution19"
  top: "Convolution19"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale19"
  type: "Scale"
  bottom: "Convolution19"
  top: "Convolution19"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu18"
  type: "PENLU"
  bottom: "Convolution19"
  top: "Convolution19"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution20"
  type: "Convolution"
  bottom: "Convolution19"
  top: "Convolution20"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm20"
  type: "BatchNorm"
  bottom: "Convolution20"
  top: "Convolution20"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale20"
  type: "Scale"
  bottom: "Convolution20"
  top: "Convolution20"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise9"
  type: "Eltwise"
  bottom: "Eltwise8"
  bottom: "Convolution20"
  top: "Eltwise9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu19"
  type: "PENLU"
  bottom: "Eltwise9"
  top: "Eltwise9"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution21"
  type: "Convolution"
  bottom: "Eltwise9"
  top: "Convolution21"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm21"
  type: "BatchNorm"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale21"
  type: "Scale"
  bottom: "Convolution21"
  top: "Convolution21"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu20"
  type: "PENLU"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution22"
  type: "Convolution"
  bottom: "Convolution21"
  top: "Convolution22"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm22"
  type: "BatchNorm"
  bottom: "Convolution22"
  top: "Convolution22"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale22"
  type: "Scale"
  bottom: "Convolution22"
  top: "Convolution22"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise10"
  type: "Eltwise"
  bottom: "Eltwise9"
  bottom: "Convolution22"
  top: "Eltwise10"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu21"
  type: "PENLU"
  bottom: "Eltwise10"
  top: "Eltwise10"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution23"
  type: "Convolution"
  bottom: "Eltwise10"
  top: "Convolution23"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.17677669
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm23"
  type: "BatchNorm"
  bottom: "Convolution23"
  top: "Convolution23"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale23"
  type: "Scale"
  bottom: "Convolution23"
  top: "Convolution23"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution24"
  type: "Convolution"
  bottom: "Eltwise10"
  top: "Convolution24"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm24"
  type: "BatchNorm"
  bottom: "Convolution24"
  top: "Convolution24"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale24"
  type: "Scale"
  bottom: 
I1006 15:09:05.552814  2964 layer_factory.hpp:77] Creating layer Data1
I1006 15:09:05.552892  2964 db_lmdb.cpp:35] Opened lmdb /home/x306/caffe/xn/PENLU/data/cifar10/cifar10_train_lmdb
I1006 15:09:05.552911  2964 net.cpp:84] Creating Layer Data1
I1006 15:09:05.552917  2964 net.cpp:380] Data1 -> Data1
I1006 15:09:05.552932  2964 net.cpp:380] Data1 -> Data2
I1006 15:09:05.552940  2964 data_transformer.cpp:25] Loading mean file from: /home/x306/caffe/xn/PENLU/data/cifar10/mean.binaryproto
I1006 15:09:05.554330  2964 data_layer.cpp:45] output data size: 100,3,28,28
I1006 15:09:05.556682  2964 net.cpp:122] Setting up Data1
I1006 15:09:05.556696  2964 net.cpp:129] Top shape: 100 3 28 28 (235200)
I1006 15:09:05.556700  2964 net.cpp:129] Top shape: 100 (100)
I1006 15:09:05.556702  2964 net.cpp:137] Memory required for data: 941200
I1006 15:09:05.556708  2964 layer_factory.hpp:77] Creating layer Convolution1
I1006 15:09:05.556725  2964 net.cpp:84] Creating Layer Convolution1
I1006 15:09:05.556731  2964 net.cpp:406] Convolution1 <- Data1
I1006 15:09:05.556740  2964 net.cpp:380] Convolution1 -> Convolution1
I1006 15:09:05.703609  2964 net.cpp:122] Setting up Convolution1
I1006 15:09:05.703644  2964 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 15:09:05.703647  2964 net.cpp:137] Memory required for data: 5958800
I1006 15:09:05.703662  2964 layer_factory.hpp:77] Creating layer BatchNorm1
I1006 15:09:05.703675  2964 net.cpp:84] Creating Layer BatchNorm1
I1006 15:09:05.703692  2964 net.cpp:406] BatchNorm1 <- Convolution1
I1006 15:09:05.703701  2964 net.cpp:367] BatchNorm1 -> Convolution1 (in-place)
I1006 15:09:05.703845  2964 net.cpp:122] Setting up BatchNorm1
I1006 15:09:05.703851  2964 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 15:09:05.703863  2964 net.cpp:137] Memory required for data: 10976400
I1006 15:09:05.703872  2964 layer_factory.hpp:77] Creating layer Scale1
I1006 15:09:05.703883  2964 net.cpp:84] Creating Layer Scale1
I1006 15:09:05.703889  2964 net.cpp:406] Scale1 <- Convolution1
I1006 15:09:05.703903  2964 net.cpp:367] Scale1 -> Convolution1 (in-place)
I1006 15:09:05.703963  2964 layer_factory.hpp:77] Creating layer Scale1
I1006 15:09:05.704068  2964 net.cpp:122] Setting up Scale1
I1006 15:09:05.704074  2964 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 15:09:05.704087  2964 net.cpp:137] Memory required for data: 15994000
I1006 15:09:05.704092  2964 layer_factory.hpp:77] Creating layer penlu1
I1006 15:09:05.704103  2964 net.cpp:84] Creating Layer penlu1
I1006 15:09:05.704109  2964 net.cpp:406] penlu1 <- Convolution1
I1006 15:09:05.704116  2964 net.cpp:367] penlu1 -> Convolution1 (in-place)
I1006 15:09:05.704728  2964 net.cpp:122] Setting up penlu1
I1006 15:09:05.704737  2964 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 15:09:05.704742  2964 net.cpp:137] Memory required for data: 21011600
I1006 15:09:05.704753  2964 layer_factory.hpp:77] Creating layer Convolution1_penlu1_0_split
I1006 15:09:05.704762  2964 net.cpp:84] Creating Layer Convolution1_penlu1_0_split
I1006 15:09:05.704766  2964 net.cpp:406] Convolution1_penlu1_0_split <- Convolution1
I1006 15:09:05.704773  2964 net.cpp:380] Convolution1_penlu1_0_split -> Convolution1_penlu1_0_split_0
I1006 15:09:05.704793  2964 net.cpp:380] Convolution1_penlu1_0_split -> Convolution1_penlu1_0_split_1
I1006 15:09:05.704845  2964 net.cpp:122] Setting up Convolution1_penlu1_0_split
I1006 15:09:05.704864  2964 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 15:09:05.704879  2964 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 15:09:05.704882  2964 net.cpp:137] Memory required for data: 31046800
I1006 15:09:05.704885  2964 layer_factory.hpp:77] Creating layer Convolution2
I1006 15:09:05.704896  2964 net.cpp:84] Creating Layer Convolution2
I1006 15:09:05.704902  2964 net.cpp:406] Convolution2 <- Convolution1_penlu1_0_split_0
I1006 15:09:05.704917  2964 net.cpp:380] Convolution2 -> Convolution2
I1006 15:09:05.705796  2964 net.cpp:122] Setting up Convolution2
I1006 15:09:05.705807  2964 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 15:09:05.705821  2964 net.cpp:137] Memory required for data: 36064400
I1006 15:09:05.705826  2964 layer_factory.hpp:77] Creating layer BatchNorm2
I1006 15:09:05.705834  2964 net.cpp:84] Creating Layer BatchNorm2
I1006 15:09:05.705840  2964 net.cpp:406] BatchNorm2 <- Convolution2
I1006 15:09:05.705847  2964 net.cpp:367] BatchNorm2 -> Convolution2 (in-place)
I1006 15:09:05.705976  2964 net.cpp:122] Setting up BatchNorm2
I1006 15:09:05.705983  2964 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 15:09:05.705987  2964 net.cpp:137] Memory required for data: 41082000
I1006 15:09:05.705997  2964 layer_factory.hpp:77] Creating layer Scale2
I1006 15:09:05.706007  2964 net.cpp:84] Creating Layer Scale2
I1006 15:09:05.706012  2964 net.cpp:406] Scale2 <- Convolution2
I1006 15:09:05.706019  2964 net.cpp:367] Scale2 -> Convolution2 (in-place)
I1006 15:09:05.706054  2964 layer_factory.hpp:77] Creating layer Scale2
I1006 15:09:05.706137  2964 net.cpp:122] Setting up Scale2
I1006 15:09:05.706145  2964 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 15:09:05.706148  2964 net.cpp:137] Memory required for data: 46099600
I1006 15:09:05.706158  2964 layer_factory.hpp:77] Creating layer penlu2
I1006 15:09:05.706168  2964 net.cpp:84] Creating Layer penlu2
I1006 15:09:05.706174  2964 net.cpp:406] penlu2 <- Convolution2
I1006 15:09:05.706179  2964 net.cpp:367] penlu2 -> Convolution2 (in-place)
I1006 15:09:05.706279  2964 net.cpp:122] Setting up penlu2
I1006 15:09:05.706292  2964 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 15:09:05.706295  2964 net.cpp:137] Memory required for data: 51117200
I1006 15:09:05.706300  2964 layer_factory.hpp:77] Creating layer Convolution3
I1006 15:09:05.706308  2964 net.cpp:84] Creating Layer Convolution3
I1006 15:09:05.706311  2964 net.cpp:406] Convolution3 <- Convolution2
I1006 15:09:05.706315  2964 net.cpp:380] Convolution3 -> Convolution3
I1006 15:09:05.707204  2964 net.cpp:122] Setting up Convolution3
I1006 15:09:05.707216  2964 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 15:09:05.707219  2964 net.cpp:137] Memory required for data: 56134800
I1006 15:09:05.707223  2964 layer_factory.hpp:77] Creating layer BatchNorm3
I1006 15:09:05.707229  2964 net.cpp:84] Creating Layer BatchNorm3
I1006 15:09:05.707232  2964 net.cpp:406] BatchNorm3 <- Convolution3
I1006 15:09:05.707237  2964 net.cpp:367] BatchNorm3 -> Convolution3 (in-place)
I1006 15:09:05.707365  2964 net.cpp:122] Setting up BatchNorm3
I1006 15:09:05.707370  2964 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 15:09:05.707373  2964 net.cpp:137] Memory required for data: 61152400
I1006 15:09:05.707378  2964 layer_factory.hpp:77] Creating layer Scale3
I1006 15:09:05.707383  2964 net.cpp:84] Creating Layer Scale3
I1006 15:09:05.707386  2964 net.cpp:406] Scale3 <- Convolution3
I1006 15:09:05.707391  2964 net.cpp:367] Scale3 -> Convolution3 (in-place)
I1006 15:09:05.707415  2964 layer_factory.hpp:77] Creating layer Scale3
I1006 15:09:05.707490  2964 net.cpp:122] Setting up Scale3
I1006 15:09:05.707495  2964 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 15:09:05.707499  2964 net.cpp:137] Memory required for data: 66170000
I1006 15:09:05.707502  2964 layer_factory.hpp:77] Creating layer Eltwise1
I1006 15:09:05.707507  2964 net.cpp:84] Creating Layer Eltwise1
I1006 15:09:05.707510  2964 net.cpp:406] Eltwise1 <- Convolution1_penlu1_0_split_1
I1006 15:09:05.707514  2964 net.cpp:406] Eltwise1 <- Convolution3
I1006 15:09:05.707517  2964 net.cpp:380] Eltwise1 -> Eltwise1
I1006 15:09:05.707535  2964 net.cpp:122] Setting up Eltwise1
I1006 15:09:05.707540  2964 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 15:09:05.707542  2964 net.cpp:137] Memory required for data: 71187600
I1006 15:09:05.707545  2964 layer_factory.hpp:77] Creating layer penlu3
I1006 15:09:05.707550  2964 net.cpp:84] Creating Layer penlu3
I1006 15:09:05.707552  2964 net.cpp:406] penlu3 <- Eltwise1
I1006 15:09:05.707557  2964 net.cpp:367] penlu3 -> Eltwise1 (in-place)
I1006 15:09:05.707659  2964 net.cpp:122] Setting up penlu3
I1006 15:09:05.707664  2964 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 15:09:05.707665  2964 net.cpp:137] Memory required for data: 76205200
I1006 15:09:05.707670  2964 layer_factory.hpp:77] Creating layer Eltwise1_penlu3_0_split
I1006 15:09:05.707674  2964 net.cpp:84] Creating Layer Eltwise1_penlu3_0_split
I1006 15:09:05.707677  2964 net.cpp:406] Eltwise1_penlu3_0_split <- Eltwise1
I1006 15:09:05.707680  2964 net.cpp:380] Eltwise1_penlu3_0_split -> Eltwise1_penlu3_0_split_0
I1006 15:09:05.707686  2964 net.cpp:380] Eltwise1_penlu3_0_split -> Eltwise1_penlu3_0_split_1
I1006 15:09:05.707707  2964 net.cpp:122] Setting up Eltwise1_penlu3_0_split
I1006 15:09:05.707712  2964 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 15:09:05.707716  2964 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 15:09:05.707718  2964 net.cpp:137] Memory required for data: 86240400
I1006 15:09:05.707720  2964 layer_factory.hpp:77] Creating layer Convolution4
I1006 15:09:05.707728  2964 net.cpp:84] Creating Layer Convolution4
I1006 15:09:05.707731  2964 net.cpp:406] Convolution4 <- Eltwise1_penlu3_0_split_0
I1006 15:09:05.707736  2964 net.cpp:380] Convolution4 -> Convolution4
I1006 15:09:05.708622  2964 net.cpp:122] Setting up Convolution4
I1006 15:09:05.708633  2964 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 15:09:05.708636  2964 net.cpp:137] Memory required for data: 91258000
I1006 15:09:05.708642  2964 layer_factory.hpp:77] Creating layer BatchNorm4
I1006 15:09:05.708647  2964 net.cpp:84] Creating Layer BatchNorm4
I1006 15:09:05.708657  2964 net.cpp:406] BatchNorm4 <- Convolution4
I1006 15:09:05.708662  2964 net.cpp:367] BatchNorm4 -> Convolution4 (in-place)
I1006 15:09:05.708786  2964 net.cpp:122] Setting up BatchNorm4
I1006 15:09:05.708791  2964 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 15:09:05.708794  2964 net.cpp:137] Memory required for data: 96275600
I1006 15:09:05.708802  2964 layer_factory.hpp:77] Creating layer Scale4
I1006 15:09:05.708807  2964 net.cpp:84] Creating Layer Scale4
I1006 15:09:05.708811  2964 net.cpp:406] Scale4 <- Convolution4
I1006 15:09:05.708814  2964 net.cpp:367] Scale4 -> Convolution4 (in-place)
I1006 15:09:05.708840  2964 layer_factory.hpp:77] Creating layer Scale4
I1006 15:09:05.708914  2964 net.cpp:122] Setting up Scale4
I1006 15:09:05.708920  2964 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 15:09:05.708922  2964 net.cpp:137] Memory required for data: 101293200
I1006 15:09:05.708926  2964 layer_factory.hpp:77] Creating layer penlu4
I1006 15:09:05.708932  2964 net.cpp:84] Creating Layer penlu4
I1006 15:09:05.708935  2964 net.cpp:406] penlu4 <- Convolution4
I1006 15:09:05.708940  2964 net.cpp:367] penlu4 -> Convolution4 (in-place)
I1006 15:09:05.709038  2964 net.cpp:122] Setting up penlu4
I1006 15:09:05.709043  2964 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 15:09:05.709046  2964 net.cpp:137] Memory required for data: 106310800
I1006 15:09:05.709051  2964 layer_factory.hpp:77] Creating layer Convolution5
I1006 15:09:05.709059  2964 net.cpp:84] Creating Layer Convolution5
I1006 15:09:05.709061  2964 net.cpp:406] Convolution5 <- Convolution4
I1006 15:09:05.709065  2964 net.cpp:380] Convolution5 -> Convolution5
I1006 15:09:05.709956  2964 net.cpp:122] Setting up Convolution5
I1006 15:09:05.709967  2964 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 15:09:05.709970  2964 net.cpp:137] Memory required for data: 111328400
I1006 15:09:05.709975  2964 layer_factory.hpp:77] Creating layer BatchNorm5
I1006 15:09:05.709980  2964 net.cpp:84] Creating Layer BatchNorm5
I1006 15:09:05.709983  2964 net.cpp:406] BatchNorm5 <- Convolution5
I1006 15:09:05.709988  2964 net.cpp:367] BatchNorm5 -> Convolution5 (in-place)
I1006 15:09:05.710115  2964 net.cpp:122] Setting up BatchNorm5
I1006 15:09:05.710120  2964 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 15:09:05.710124  2964 net.cpp:137] Memory required for data: 116346000
I1006 15:09:05.710129  2964 layer_factory.hpp:77] Creating layer Scale5
I1006 15:09:05.710134  2964 net.cpp:84] Creating Layer Scale5
I1006 15:09:05.710136  2964 net.cpp:406] Scale5 <- Convolution5
I1006 15:09:05.710139  2964 net.cpp:367] Scale5 -> Convolution5 (in-place)
I1006 15:09:05.710165  2964 layer_factory.hpp:77] Creating layer Scale5
I1006 15:09:05.710242  2964 net.cpp:122] Setting up Scale5
I1006 15:09:05.710247  2964 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 15:09:05.710248  2964 net.cpp:137] Memory required for data: 121363600
I1006 15:09:05.710253  2964 layer_factory.hpp:77] Creating layer Eltwise2
I1006 15:09:05.710258  2964 net.cpp:84] Creating Layer Eltwise2
I1006 15:09:05.710260  2964 net.cpp:406] Eltwise2 <- Eltwise1_penlu3_0_split_1
I1006 15:09:05.710263  2964 net.cpp:406] Eltwise2 <- Convolution5
I1006 15:09:05.710266  2964 net.cpp:380] Eltwise2 -> Eltwise2
I1006 15:09:05.710283  2964 net.cpp:122] Setting up Eltwise2
I1006 15:09:05.710288  2964 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 15:09:05.710289  2964 net.cpp:137] Memory required for data: 126381200
I1006 15:09:05.710291  2964 layer_factory.hpp:77] Creating layer penlu5
I1006 15:09:05.710297  2964 net.cpp:84] Creating Layer penlu5
I1006 15:09:05.710300  2964 net.cpp:406] penlu5 <- Eltwise2
I1006 15:09:05.710304  2964 net.cpp:367] penlu5 -> Eltwise2 (in-place)
I1006 15:09:05.710407  2964 net.cpp:122] Setting up penlu5
I1006 15:09:05.710412  2964 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 15:09:05.710414  2964 net.cpp:137] Memory required for data: 131398800
I1006 15:09:05.710419  2964 layer_factory.hpp:77] Creating layer Eltwise2_penlu5_0_split
I1006 15:09:05.710430  2964 net.cpp:84] Creating Layer Eltwise2_penlu5_0_split
I1006 15:09:05.710433  2964 net.cpp:406] Eltwise2_penlu5_0_split <- Eltwise2
I1006 15:09:05.710438  2964 net.cpp:380] Eltwise2_penlu5_0_split -> Eltwise2_penlu5_0_split_0
I1006 15:09:05.710441  2964 net.cpp:380] Eltwise2_penlu5_0_split -> Eltwise2_penlu5_0_split_1
I1006 15:09:05.710466  2964 net.cpp:122] Setting up Eltwise2_penlu5_0_split
I1006 15:09:05.710470  2964 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 15:09:05.710474  2964 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 15:09:05.710476  2964 net.cpp:137] Memory required for data: 141434000
I1006 15:09:05.710479  2964 layer_factory.hpp:77] Creating layer Convolution6
I1006 15:09:05.710485  2964 net.cpp:84] Creating Layer Convolution6
I1006 15:09:05.710489  2964 net.cpp:406] Convolution6 <- Eltwise2_penlu5_0_split_0
I1006 15:09:05.710492  2964 net.cpp:380] Convolution6 -> Convolution6
I1006 15:09:05.711395  2964 net.cpp:122] Setting up Convolution6
I1006 15:09:05.711405  2964 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 15:09:05.711410  2964 net.cpp:137] Memory required for data: 146451600
I1006 15:09:05.711414  2964 layer_factory.hpp:77] Creating layer BatchNorm6
I1006 15:09:05.711421  2964 net.cpp:84] Creating Layer BatchNorm6
I1006 15:09:05.711423  2964 net.cpp:406] BatchNorm6 <- Convolution6
I1006 15:09:05.711427  2964 net.cpp:367] BatchNorm6 -> Convolution6 (in-place)
I1006 15:09:05.711560  2964 net.cpp:122] Setting up BatchNorm6
I1006 15:09:05.711565  2964 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 15:09:05.711567  2964 net.cpp:137] Memory required for data: 151469200
I1006 15:09:05.711572  2964 layer_factory.hpp:77] Creating layer Scale6
I1006 15:09:05.711580  2964 net.cpp:84] Creating Layer Scale6
I1006 15:09:05.711583  2964 net.cpp:406] Scale6 <- Convolution6
I1006 15:09:05.711586  2964 net.cpp:367] Scale6 -> Convolution6 (in-place)
I1006 15:09:05.711613  2964 layer_factory.hpp:77] Creating layer Scale6
I1006 15:09:05.711689  2964 net.cpp:122] Setting up Scale6
I1006 15:09:05.711694  2964 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 15:09:05.711697  2964 net.cpp:137] Memory required for data: 156486800
I1006 15:09:05.711700  2964 layer_factory.hpp:77] Creating layer penlu6
I1006 15:09:05.711707  2964 net.cpp:84] Creating Layer penlu6
I1006 15:09:05.711710  2964 net.cpp:406] penlu6 <- Convolution6
I1006 15:09:05.711714  2964 net.cpp:367] penlu6 -> Convolution6 (in-place)
I1006 15:09:05.711817  2964 net.cpp:122] Setting up penlu6
I1006 15:09:05.711822  2964 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 15:09:05.711825  2964 net.cpp:137] Memory required for data: 161504400
I1006 15:09:05.711829  2964 layer_factory.hpp:77] Creating layer Convolution7
I1006 15:09:05.711838  2964 net.cpp:84] Creating Layer Convolution7
I1006 15:09:05.711840  2964 net.cpp:406] Convolution7 <- Convolution6
I1006 15:09:05.711844  2964 net.cpp:380] Convolution7 -> Convolution7
I1006 15:09:05.712407  2964 net.cpp:122] Setting up Convolution7
I1006 15:09:05.712416  2964 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 15:09:05.712419  2964 net.cpp:137] Memory required for data: 166522000
I1006 15:09:05.712424  2964 layer_factory.hpp:77] Creating layer BatchNorm7
I1006 15:09:05.712430  2964 net.cpp:84] Creating Layer BatchNorm7
I1006 15:09:05.712433  2964 net.cpp:406] BatchNorm7 <- Convolution7
I1006 15:09:05.712436  2964 net.cpp:367] BatchNorm7 -> Convolution7 (in-place)
I1006 15:09:05.712566  2964 net.cpp:122] Setting up BatchNorm7
I1006 15:09:05.712571  2964 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 15:09:05.712574  2964 net.cpp:137] Memory required for data: 171539600
I1006 15:09:05.712584  2964 layer_factory.hpp:77] Creating layer Scale7
I1006 15:09:05.712591  2964 net.cpp:84] Creating Layer Scale7
I1006 15:09:05.712594  2964 net.cpp:406] Scale7 <- Convolution7
I1006 15:09:05.712597  2964 net.cpp:367] Scale7 -> Convolution7 (in-place)
I1006 15:09:05.712625  2964 layer_factory.hpp:77] Creating layer Scale7
I1006 15:09:05.712710  2964 net.cpp:122] Setting up Scale7
I1006 15:09:05.712718  2964 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 15:09:05.712720  2964 net.cpp:137] Memory required for data: 176557200
I1006 15:09:05.712724  2964 layer_factory.hpp:77] Creating layer Eltwise3
I1006 15:09:05.712728  2964 net.cpp:84] Creating Layer Eltwise3
I1006 15:09:05.712731  2964 net.cpp:406] Eltwise3 <- Eltwise2_penlu5_0_split_1
I1006 15:09:05.712734  2964 net.cpp:406] Eltwise3 <- Convolution7
I1006 15:09:05.712738  2964 net.cpp:380] Eltwise3 -> Eltwise3
I1006 15:09:05.712754  2964 net.cpp:122] Setting up Eltwise3
I1006 15:09:05.712759  2964 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 15:09:05.712760  2964 net.cpp:137] Memory required for data: 181574800
I1006 15:09:05.712762  2964 layer_factory.hpp:77] Creating layer penlu7
I1006 15:09:05.712767  2964 net.cpp:84] Creating Layer penlu7
I1006 15:09:05.712770  2964 net.cpp:406] penlu7 <- Eltwise3
I1006 15:09:05.712775  2964 net.cpp:367] penlu7 -> Eltwise3 (in-place)
I1006 15:09:05.712882  2964 net.cpp:122] Setting up penlu7
I1006 15:09:05.712888  2964 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 15:09:05.712889  2964 net.cpp:137] Memory required for data: 186592400
I1006 15:09:05.712894  2964 layer_factory.hpp:77] Creating layer Eltwise3_penlu7_0_split
I1006 15:09:05.712899  2964 net.cpp:84] Creating Layer Eltwise3_penlu7_0_split
I1006 15:09:05.712903  2964 net.cpp:406] Eltwise3_penlu7_0_split <- Eltwise3
I1006 15:09:05.712905  2964 net.cpp:380] Eltwise3_penlu7_0_split -> Eltwise3_penlu7_0_split_0
I1006 15:09:05.712909  2964 net.cpp:380] Eltwise3_penlu7_0_split -> Eltwise3_penlu7_0_split_1
I1006 15:09:05.712932  2964 net.cpp:122] Setting up Eltwise3_penlu7_0_split
I1006 15:09:05.712936  2964 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 15:09:05.712939  2964 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 15:09:05.712942  2964 net.cpp:137] Memory required for data: 196627600
I1006 15:09:05.712944  2964 layer_factory.hpp:77] Creating layer Convolution8
I1006 15:09:05.712950  2964 net.cpp:84] Creating Layer Convolution8
I1006 15:09:05.712954  2964 net.cpp:406] Convolution8 <- Eltwise3_penlu7_0_split_0
I1006 15:09:05.712958  2964 net.cpp:380] Convolution8 -> Convolution8
I1006 15:09:05.713845  2964 net.cpp:122] Setting up Convolution8
I1006 15:09:05.713855  2964 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 15:09:05.713857  2964 net.cpp:137] Memory required for data: 201645200
I1006 15:09:05.713862  2964 layer_factory.hpp:77] Creating layer BatchNorm8
I1006 15:09:05.713867  2964 net.cpp:84] Creating Layer BatchNorm8
I1006 15:09:05.713871  2964 net.cpp:406] BatchNorm8 <- Convolution8
I1006 15:09:05.713876  2964 net.cpp:367] BatchNorm8 -> Convolution8 (in-place)
I1006 15:09:05.714005  2964 net.cpp:122] Setting up BatchNorm8
I1006 15:09:05.714010  2964 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 15:09:05.714013  2964 net.cpp:137] Memory required for data: 206662800
I1006 15:09:05.714018  2964 layer_factory.hpp:77] Creating layer Scale8
I1006 15:09:05.714022  2964 net.cpp:84] Creating Layer Scale8
I1006 15:09:05.714025  2964 net.cpp:406] Scale8 <- Convolution8
I1006 15:09:05.714030  2964 net.cpp:367] Scale8 -> Convolution8 (in-place)
I1006 15:09:05.714056  2964 layer_factory.hpp:77] Creating layer Scale8
I1006 15:09:05.714133  2964 net.cpp:122] Setting up Scale8
I1006 15:09:05.714138  2964 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 15:09:05.714140  2964 net.cpp:137] Memory required for data: 211680400
I1006 15:09:05.714145  2964 layer_factory.hpp:77] Creating layer penlu8
I1006 15:09:05.714150  2964 net.cpp:84] Creating Layer penlu8
I1006 15:09:05.714154  2964 net.cpp:406] penlu8 <- Convolution8
I1006 15:09:05.714157  2964 net.cpp:367] penlu8 -> Convolution8 (in-place)
I1006 15:09:05.714284  2964 net.cpp:122] Setting up penlu8
I1006 15:09:05.714293  2964 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 15:09:05.714298  2964 net.cpp:137] Memory required for data: 216698000
I1006 15:09:05.714306  2964 layer_factory.hpp:77] Creating layer Convolution9
I1006 15:09:05.714326  2964 net.cpp:84] Creating Layer Convolution9
I1006 15:09:05.714332  2964 net.cpp:406] Convolution9 <- Convolution8
I1006 15:09:05.714340  2964 net.cpp:380] Convolution9 -> Convolution9
I1006 15:09:05.715613  2964 net.cpp:122] Setting up Convolution9
I1006 15:09:05.715627  2964 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 15:09:05.715633  2964 net.cpp:137] Memory required for data: 221715600
I1006 15:09:05.715641  2964 layer_factory.hpp:77] Creating layer BatchNorm9
I1006 15:09:05.715651  2964 net.cpp:84] Creating Layer BatchNorm9
I1006 15:09:05.715656  2964 net.cpp:406] BatchNorm9 <- Convolution9
I1006 15:09:05.715662  2964 net.cpp:367] BatchNorm9 -> Convolution9 (in-place)
I1006 15:09:05.715852  2964 net.cpp:122] Setting up BatchNorm9
I1006 15:09:05.715864  2964 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 15:09:05.715868  2964 net.cpp:137] Memory required for data: 226733200
I1006 15:09:05.715876  2964 layer_factory.hpp:77] Creating layer Scale9
I1006 15:09:05.715885  2964 net.cpp:84] Creating Layer Scale9
I1006 15:09:05.715890  2964 net.cpp:406] Scale9 <- Convolution9
I1006 15:09:05.715898  2964 net.cpp:367] Scale9 -> Convolution9 (in-place)
I1006 15:09:05.715943  2964 layer_factory.hpp:77] Creating layer Scale9
I1006 15:09:05.716065  2964 net.cpp:122] Setting up Scale9
I1006 15:09:05.716074  2964 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 15:09:05.716076  2964 net.cpp:137] Memory required for data: 231750800
I1006 15:09:05.716081  2964 layer_factory.hpp:77] Creating layer Eltwise4
I1006 15:09:05.716086  2964 net.cpp:84] Creating Layer Eltwise4
I1006 15:09:05.716089  2964 net.cpp:406] Eltwise4 <- Eltwise3_penlu7_0_split_1
I1006 15:09:05.716092  2964 net.cpp:406] Eltwise4 <- Convolution9
I1006 15:09:05.716097  2964 net.cpp:380] Eltwise4 -> Eltwise4
I1006 15:09:05.716115  2964 net.cpp:122] Setting up Eltwise4
I1006 15:09:05.716120  2964 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 15:09:05.716122  2964 net.cpp:137] Memory required for data: 236768400
I1006 15:09:05.716125  2964 layer_factory.hpp:77] Creating layer penlu9
I1006 15:09:05.716130  2964 net.cpp:84] Creating Layer penlu9
I1006 15:09:05.716133  2964 net.cpp:406] penlu9 <- Eltwise4
I1006 15:09:05.716137  2964 net.cpp:367] penlu9 -> Eltwise4 (in-place)
I1006 15:09:05.716248  2964 net.cpp:122] Setting up penlu9
I1006 15:09:05.716253  2964 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 15:09:05.716255  2964 net.cpp:137] Memory required for data: 241786000
I1006 15:09:05.716260  2964 layer_factory.hpp:77] Creating layer Eltwise4_penlu9_0_split
I1006 15:09:05.716264  2964 net.cpp:84] Creating Layer Eltwise4_penlu9_0_split
I1006 15:09:05.716267  2964 net.cpp:406] Eltwise4_penlu9_0_split <- Eltwise4
I1006 15:09:05.716272  2964 net.cpp:380] Eltwise4_penlu9_0_split -> Eltwise4_penlu9_0_split_0
I1006 15:09:05.716276  2964 net.cpp:380] Eltwise4_penlu9_0_split -> Eltwise4_penlu9_0_split_1
I1006 15:09:05.716298  2964 net.cpp:122] Setting up Eltwise4_penlu9_0_split
I1006 15:09:05.716303  2964 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 15:09:05.716306  2964 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 15:09:05.716308  2964 net.cpp:137] Memory required for data: 251821200
I1006 15:09:05.716311  2964 layer_factory.hpp:77] Creating layer Convolution10
I1006 15:09:05.716318  2964 net.cpp:84] Creating Layer Convolution10
I1006 15:09:05.716321  2964 net.cpp:406] Convolution10 <- Eltwise4_penlu9_0_split_0
I1006 15:09:05.716326  2964 net.cpp:380] Convolution10 -> Convolution10
I1006 15:09:05.717233  2964 net.cpp:122] Setting up Convolution10
I1006 15:09:05.717244  2964 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 15:09:05.717247  2964 net.cpp:137] Memory required for data: 256838800
I1006 15:09:05.717252  2964 layer_factory.hpp:77] Creating layer BatchNorm10
I1006 15:09:05.717258  2964 net.cpp:84] Creating Layer BatchNorm10
I1006 15:09:05.717262  2964 net.cpp:406] BatchNorm10 <- Convolution10
I1006 15:09:05.717267  2964 net.cpp:367] BatchNorm10 -> Convolution10 (in-place)
I1006 15:09:05.717406  2964 net.cpp:122] Setting up BatchNorm10
I1006 15:09:05.717411  2964 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 15:09:05.717414  2964 net.cpp:137] Memory required for data: 261856400
I1006 15:09:05.717419  2964 layer_factory.hpp:77] Creating layer Scale10
I1006 15:09:05.717424  2964 net.cpp:84] Creating Layer Scale10
I1006 15:09:05.717427  2964 net.cpp:406] Scale10 <- Convolution10
I1006 15:09:05.717432  2964 net.cpp:367] Scale10 -> Convolution10 (in-place)
I1006 15:09:05.717458  2964 layer_factory.hpp:77] Creating layer Scale10
I1006 15:09:05.717535  2964 net.cpp:122] Setting up Scale10
I1006 15:09:05.717540  2964 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 15:09:05.717543  2964 net.cpp:137] Memory required for data: 266874000
I1006 15:09:05.717547  2964 layer_factory.hpp:77] Creating layer penlu10
I1006 15:09:05.717553  2964 net.cpp:84] Creating Layer penlu10
I1006 15:09:05.717556  2964 net.cpp:406] penlu10 <- Convolution10
I1006 15:09:05.717561  2964 net.cpp:367] penlu10 -> Convolution10 (in-place)
I1006 15:09:05.717667  2964 net.cpp:122] Setting up penlu10
I1006 15:09:05.717672  2964 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 15:09:05.717675  2964 net.cpp:137] Memory required for data: 271891600
I1006 15:09:05.717680  2964 layer_factory.hpp:77] Creating layer Convolution11
I1006 15:09:05.717689  2964 net.cpp:84] Creating Layer Convolution11
I1006 15:09:05.717691  2964 net.cpp:406] Convolution11 <- Convolution10
I1006 15:09:05.717695  2964 net.cpp:380] Convolution11 -> Convolution11
I1006 15:09:05.718617  2964 net.cpp:122] Setting up Convolution11
I1006 15:09:05.718627  2964 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 15:09:05.718639  2964 net.cpp:137] Memory required for data: 276909200
I1006 15:09:05.718644  2964 layer_factory.hpp:77] Creating layer BatchNorm11
I1006 15:09:05.718650  2964 net.cpp:84] Creating Layer BatchNorm11
I1006 15:09:05.718654  2964 net.cpp:406] BatchNorm11 <- Convolution11
I1006 15:09:05.718658  2964 net.cpp:367] BatchNorm11 -> Convolution11 (in-place)
I1006 15:09:05.718798  2964 net.cpp:122] Setting up BatchNorm11
I1006 15:09:05.718804  2964 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 15:09:05.718806  2964 net.cpp:137] Memory required for data: 281926800
I1006 15:09:05.718821  2964 layer_factory.hpp:77] Creating layer Scale11
I1006 15:09:05.718827  2964 net.cpp:84] Creating Layer Scale11
I1006 15:09:05.718829  2964 net.cpp:406] Scale11 <- Convolution11
I1006 15:09:05.718832  2964 net.cpp:367] Scale11 -> Convolution11 (in-place)
I1006 15:09:05.718868  2964 layer_factory.hpp:77] Creating layer Scale11
I1006 15:09:05.718966  2964 net.cpp:122] Setting up Scale11
I1006 15:09:05.718969  2964 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 15:09:05.718972  2964 net.cpp:137] Memory required for data: 286944400
I1006 15:09:05.718986  2964 layer_factory.hpp:77] Creating layer Eltwise5
I1006 15:09:05.718989  2964 net.cpp:84] Creating Layer Eltwise5
I1006 15:09:05.718992  2964 net.cpp:406] Eltwise5 <- Eltwise4_penlu9_0_split_1
I1006 15:09:05.718996  2964 net.cpp:406] Eltwise5 <- Convolution11
I1006 15:09:05.718999  2964 net.cpp:380] Eltwise5 -> Eltwise5
I1006 15:09:05.719015  2964 net.cpp:122] Setting up Eltwise5
I1006 15:09:05.719019  2964 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 15:09:05.719022  2964 net.cpp:137] Memory required for data: 291962000
I1006 15:09:05.719024  2964 layer_factory.hpp:77] Creating layer penlu11
I1006 15:09:05.719029  2964 net.cpp:84] Creating Layer penlu11
I1006 15:09:05.719033  2964 net.cpp:406] penlu11 <- Eltwise5
I1006 15:09:05.719036  2964 net.cpp:367] penlu11 -> Eltwise5 (in-place)
I1006 15:09:05.719146  2964 net.cpp:122] Setting up penlu11
I1006 15:09:05.719151  2964 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 15:09:05.719154  2964 net.cpp:137] Memory required for data: 296979600
I1006 15:09:05.719158  2964 layer_factory.hpp:77] Creating layer Eltwise5_penlu11_0_split
I1006 15:09:05.719167  2964 net.cpp:84] Creating Layer Eltwise5_penlu11_0_split
I1006 15:09:05.719172  2964 net.cpp:406] Eltwise5_penlu11_0_split <- Eltwise5
I1006 15:09:05.719182  2964 net.cpp:380] Eltwise5_penlu11_0_split -> Eltwise5_penlu11_0_split_0
I1006 15:09:05.719188  2964 net.cpp:380] Eltwise5_penlu11_0_split -> Eltwise5_penlu11_0_split_1
I1006 15:09:05.719213  2964 net.cpp:122] Setting up Eltwise5_penlu11_0_split
I1006 15:09:05.719218  2964 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 15:09:05.719221  2964 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 15:09:05.719223  2964 net.cpp:137] Memory required for data: 307014800
I1006 15:09:05.719226  2964 layer_factory.hpp:77] Creating layer Convolution12
I1006 15:09:05.719233  2964 net.cpp:84] Creating Layer Convolution12
I1006 15:09:05.719236  2964 net.cpp:406] Convolution12 <- Eltwise5_penlu11_0_split_0
I1006 15:09:05.719240  2964 net.cpp:380] Convolution12 -> Convolution12
I1006 15:09:05.720433  2964 net.cpp:122] Setting up Convolution12
I1006 15:09:05.720444  2964 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 15:09:05.720448  2964 net.cpp:137] Memory required for data: 309523600
I1006 15:09:05.720453  2964 layer_factory.hpp:77] Creating layer BatchNorm12
I1006 15:09:05.720458  2964 net.cpp:84] Creating Layer BatchNorm12
I1006 15:09:05.720461  2964 net.cpp:406] BatchNorm12 <- Convolution12
I1006 15:09:05.720465  2964 net.cpp:367] BatchNorm12 -> Convolution12 (in-place)
I1006 15:09:05.720610  2964 net.cpp:122] Setting up BatchNorm12
I1006 15:09:05.720615  2964 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 15:09:05.720619  2964 net.cpp:137] Memory required for data: 312032400
I1006 15:09:05.720624  2964 layer_factory.hpp:77] Creating layer Scale12
I1006 15:09:05.720629  2964 net.cpp:84] Creating Layer Scale12
I1006 15:09:05.720633  2964 net.cpp:406] Scale12 <- Convolution12
I1006 15:09:05.720636  2964 net.cpp:367] Scale12 -> Convolution12 (in-place)
I1006 15:09:05.720662  2964 layer_factory.hpp:77] Creating layer Scale12
I1006 15:09:05.720739  2964 net.cpp:122] Setting up Scale12
I1006 15:09:05.720744  2964 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 15:09:05.720747  2964 net.cpp:137] Memory required for data: 314541200
I1006 15:09:05.720752  2964 layer_factory.hpp:77] Creating layer Convolution13
I1006 15:09:05.720758  2964 net.cpp:84] Creating Layer Convolution13
I1006 15:09:05.720762  2964 net.cpp:406] Convolution13 <- Eltwise5_penlu11_0_split_1
I1006 15:09:05.720767  2964 net.cpp:380] Convolution13 -> Convolution13
I1006 15:09:05.722046  2964 net.cpp:122] Setting up Convolution13
I1006 15:09:05.722056  2964 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 15:09:05.722059  2964 net.cpp:137] Memory required for data: 317050000
I1006 15:09:05.722065  2964 layer_factory.hpp:77] Creating layer BatchNorm13
I1006 15:09:05.722071  2964 net.cpp:84] Creating Layer BatchNorm13
I1006 15:09:05.722074  2964 net.cpp:406] BatchNorm13 <- Convolution13
I1006 15:09:05.722079  2964 net.cpp:367] BatchNorm13 -> Convolution13 (in-place)
I1006 15:09:05.722216  2964 net.cpp:122] Setting up BatchNorm13
I1006 15:09:05.722221  2964 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 15:09:05.722224  2964 net.cpp:137] Memory required for data: 319558800
I1006 15:09:05.722229  2964 layer_factory.hpp:77] Creating layer Scale13
I1006 15:09:05.722234  2964 net.cpp:84] Creating Layer Scale13
I1006 15:09:05.722237  2964 net.cpp:406] Scale13 <- Convolution13
I1006 15:09:05.722241  2964 net.cpp:367] Scale13 -> Convolution13 (in-place)
I1006 15:09:05.722268  2964 layer_factory.hpp:77] Creating layer Scale13
I1006 15:09:05.722345  2964 net.cpp:122] Setting up Scale13
I1006 15:09:05.722350  2964 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 15:09:05.722353  2964 net.cpp:137] Memory required for data: 322067600
I1006 15:09:05.722357  2964 layer_factory.hpp:77] Creating layer penlu12
I1006 15:09:05.722362  2964 net.cpp:84] Creating Layer penlu12
I1006 15:09:05.722365  2964 net.cpp:406] penlu12 <- Convolution13
I1006 15:09:05.722370  2964 net.cpp:367] penlu12 -> Convolution13 (in-place)
I1006 15:09:05.722478  2964 net.cpp:122] Setting up penlu12
I1006 15:09:05.722483  2964 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 15:09:05.722493  2964 net.cpp:137] Memory required for data: 324576400
I1006 15:09:05.722498  2964 layer_factory.hpp:77] Creating layer Convolution14
I1006 15:09:05.722506  2964 net.cpp:84] Creating Layer Convolution14
I1006 15:09:05.722509  2964 net.cpp:406] Convolution14 <- Convolution13
I1006 15:09:05.722514  2964 net.cpp:380] Convolution14 -> Convolution14
I1006 15:09:05.723595  2964 net.cpp:122] Setting up Convolution14
I1006 15:09:05.723606  2964 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 15:09:05.723609  2964 net.cpp:137] Memory required for data: 327085200
I1006 15:09:05.723625  2964 layer_factory.hpp:77] Creating layer BatchNorm14
I1006 15:09:05.723635  2964 net.cpp:84] Creating Layer BatchNorm14
I1006 15:09:05.723639  2964 net.cpp:406] BatchNorm14 <- Convolution14
I1006 15:09:05.723642  2964 net.cpp:367] BatchNorm14 -> Convolution14 (in-place)
I1006 15:09:05.723778  2964 net.cpp:122] Setting up BatchNorm14
I1006 15:09:05.723783  2964 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 15:09:05.723785  2964 net.cpp:137] Memory required for data: 329594000
I1006 15:09:05.723791  2964 layer_factory.hpp:77] Creating layer Scale14
I1006 15:09:05.723796  2964 net.cpp:84] Creating Layer Scale14
I1006 15:09:05.723799  2964 net.cpp:406] Scale14 <- Convolution14
I1006 15:09:05.723803  2964 net.cpp:367] Scale14 -> Convolution14 (in-place)
I1006 15:09:05.723829  2964 layer_factory.hpp:77] Creating layer Scale14
I1006 15:09:05.723906  2964 net.cpp:122] Setting up Scale14
I1006 15:09:05.723911  2964 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 15:09:05.723913  2964 net.cpp:137] Memory required for data: 332102800
I1006 15:09:05.723917  2964 layer_factory.hpp:77] Creating layer Eltwise6
I1006 15:09:05.723922  2964 net.cpp:84] Creating Layer Eltwise6
I1006 15:09:05.723924  2964 net.cpp:406] Eltwise6 <- Convolution12
I1006 15:09:05.723927  2964 net.cpp:406] Eltwise6 <- Convolution14
I1006 15:09:05.723932  2964 net.cpp:380] Eltwise6 -> Eltwise6
I1006 15:09:05.723948  2964 net.cpp:122] Setting up Eltwise6
I1006 15:09:05.723951  2964 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 15:09:05.723953  2964 net.cpp:137] Memory required for data: 334611600
I1006 15:09:05.723955  2964 layer_factory.hpp:77] Creating layer penlu13
I1006 15:09:05.723960  2964 net.cpp:84] Creating Layer penlu13
I1006 15:09:05.723963  2964 net.cpp:406] penlu13 <- Eltwise6
I1006 15:09:05.723966  2964 net.cpp:367] penlu13 -> Eltwise6 (in-place)
I1006 15:09:05.724073  2964 net.cpp:122] Setting up penlu13
I1006 15:09:05.724077  2964 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 15:09:05.724079  2964 net.cpp:137] Memory required for data: 337120400
I1006 15:09:05.724084  2964 layer_factory.hpp:77] Creating layer Eltwise6_penlu13_0_split
I1006 15:09:05.724087  2964 net.cpp:84] Creating Layer Eltwise6_penlu13_0_split
I1006 15:09:05.724090  2964 net.cpp:406] Eltwise6_penlu13_0_split <- Eltwise6
I1006 15:09:05.724093  2964 net.cpp:380] Eltwise6_penlu13_0_split -> Eltwise6_penlu13_0_split_0
I1006 15:09:05.724097  2964 net.cpp:380] Eltwise6_penlu13_0_split -> Eltwise6_penlu13_0_split_1
I1006 15:09:05.724119  2964 net.cpp:122] Setting up Eltwise6_penlu13_0_split
I1006 15:09:05.724123  2964 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 15:09:05.724126  2964 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 15:09:05.724128  2964 net.cpp:137] Memory required for data: 342138000
I1006 15:09:05.724130  2964 layer_factory.hpp:77] Creating layer Convolution15
I1006 15:09:05.724136  2964 net.cpp:84] Creating Layer Convolution15
I1006 15:09:05.724138  2964 net.cpp:406] Convolution15 <- Eltwise6_penlu13_0_split_0
I1006 15:09:05.724143  2964 net.cpp:380] Convolution15 -> Convolution15
I1006 15:09:05.725205  2964 net.cpp:122] Setting up Convolution15
I1006 15:09:05.725215  2964 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 15:09:05.725217  2964 net.cpp:137] Memory required for data: 344646800
I1006 15:09:05.725222  2964 layer_factory.hpp:77] Creating layer BatchNorm15
I1006 15:09:05.725227  2964 net.cpp:84] Creating Layer BatchNorm15
I1006 15:09:05.725236  2964 net.cpp:406] BatchNorm15 <- Convolution15
I1006 15:09:05.725241  2964 net.cpp:367] BatchNorm15 -> Convolution15 (in-place)
I1006 15:09:05.725378  2964 net.cpp:122] Setting up BatchNorm15
I1006 15:09:05.725383  2964 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 15:09:05.725384  2964 net.cpp:137] Memory required for data: 347155600
I1006 15:09:05.725389  2964 layer_factory.hpp:77] Creating layer Scale15
I1006 15:09:05.725394  2964 net.cpp:84] Creating Layer Scale15
I1006 15:09:05.725396  2964 net.cpp:406] Scale15 <- Convolution15
I1006 15:09:05.725400  2964 net.cpp:367] Scale15 -> Convolution15 (in-place)
I1006 15:09:05.725425  2964 layer_factory.hpp:77] Creating layer Scale15
I1006 15:09:05.725502  2964 net.cpp:122] Setting up Scale15
I1006 15:09:05.725507  2964 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 15:09:05.725508  2964 net.cpp:137] Memory required for data: 349664400
I1006 15:09:05.725512  2964 layer_factory.hpp:77] Creating layer penlu14
I1006 15:09:05.725517  2964 net.cpp:84] Creating Layer penlu14
I1006 15:09:05.725519  2964 net.cpp:406] penlu14 <- Convolution15
I1006 15:09:05.725523  2964 net.cpp:367] penlu14 -> Convolution15 (in-place)
I1006 15:09:05.725630  2964 net.cpp:122] Setting up penlu14
I1006 15:09:05.725634  2964 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 15:09:05.725636  2964 net.cpp:137] Memory required for data: 352173200
I1006 15:09:05.725641  2964 layer_factory.hpp:77] Creating layer Convolution16
I1006 15:09:05.725647  2964 net.cpp:84] Creating Layer Convolution16
I1006 15:09:05.725651  2964 net.cpp:406] Convolution16 <- Convolution15
I1006 15:09:05.725654  2964 net.cpp:380] Convolution16 -> Convolution16
I1006 15:09:05.726714  2964 net.cpp:122] Setting up Convolution16
I1006 15:09:05.726723  2964 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 15:09:05.726727  2964 net.cpp:137] Memory required for data: 354682000
I1006 15:09:05.726732  2964 layer_factory.hpp:77] Creating layer BatchNorm16
I1006 15:09:05.726737  2964 net.cpp:84] Creating Layer BatchNorm16
I1006 15:09:05.726739  2964 net.cpp:406] BatchNorm16 <- Convolution16
I1006 15:09:05.726743  2964 net.cpp:367] BatchNorm16 -> Convolution16 (in-place)
I1006 15:09:05.726877  2964 net.cpp:122] Setting up BatchNorm16
I1006 15:09:05.726882  2964 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 15:09:05.726884  2964 net.cpp:137] Memory required for data: 357190800
I1006 15:09:05.726889  2964 layer_factory.hpp:77] Creating layer Scale16
I1006 15:09:05.726893  2964 net.cpp:84] Creating Layer Scale16
I1006 15:09:05.726897  2964 net.cpp:406] Scale16 <- Convolution16
I1006 15:09:05.726899  2964 net.cpp:367] Scale16 -> Convolution16 (in-place)
I1006 15:09:05.726925  2964 layer_factory.hpp:77] Creating layer Scale16
I1006 15:09:05.727002  2964 net.cpp:122] Setting up Scale16
I1006 15:09:05.727006  2964 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 15:09:05.727010  2964 net.cpp:137] Memory required for data: 359699600
I1006 15:09:05.727012  2964 layer_factory.hpp:77] Creating layer Eltwise7
I1006 15:09:05.727016  2964 net.cpp:84] Creating Layer Eltwise7
I1006 15:09:05.727020  2964 net.cpp:406] Eltwise7 <- Eltwise6_penlu13_0_split_1
I1006 15:09:05.727022  2964 net.cpp:406] Eltwise7 <- Convolution16
I1006 15:09:05.727025  2964 net.cpp:380] Eltwise7 -> Eltwise7
I1006 15:09:05.727041  2964 net.cpp:122] Setting up Eltwise7
I1006 15:09:05.727044  2964 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 15:09:05.727046  2964 net.cpp:137] Memory required for data: 362208400
I1006 15:09:05.727048  2964 layer_factory.hpp:77] Creating layer penlu15
I1006 15:09:05.727054  2964 net.cpp:84] Creating Layer penlu15
I1006 15:09:05.727056  2964 net.cpp:406] penlu15 <- Eltwise7
I1006 15:09:05.727061  2964 net.cpp:367] penlu15 -> Eltwise7 (in-place)
I1006 15:09:05.727177  2964 net.cpp:122] Setting up penlu15
I1006 15:09:05.727182  2964 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 15:09:05.727185  2964 net.cpp:137] Memory required for data: 364717200
I1006 15:09:05.727195  2964 layer_factory.hpp:77] Creating layer Eltwise7_penlu15_0_split
I1006 15:09:05.727200  2964 net.cpp:84] Creating Layer Eltwise7_penlu15_0_split
I1006 15:09:05.727203  2964 net.cpp:406] Eltwise7_penlu15_0_split <- Eltwise7
I1006 15:09:05.727206  2964 net.cpp:380] Eltwise7_penlu15_0_split -> Eltwise7_penlu15_0_split_0
I1006 15:09:05.727210  2964 net.cpp:380] Eltwise7_penlu15_0_split -> Eltwise7_penlu15_0_split_1
I1006 15:09:05.727236  2964 net.cpp:122] Setting up Eltwise7_penlu15_0_split
I1006 15:09:05.727239  2964 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 15:09:05.727242  2964 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 15:09:05.727244  2964 net.cpp:137] Memory required for data: 369734800
I1006 15:09:05.727246  2964 layer_factory.hpp:77] Creating layer Convolution17
I1006 15:09:05.727252  2964 net.cpp:84] Creating Layer Convolution17
I1006 15:09:05.727254  2964 net.cpp:406] Convolution17 <- Eltwise7_penlu15_0_split_0
I1006 15:09:05.727259  2964 net.cpp:380] Convolution17 -> Convolution17
I1006 15:09:05.727993  2964 net.cpp:122] Setting up Convolution17
I1006 15:09:05.727999  2964 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 15:09:05.728001  2964 net.cpp:137] Memory required for data: 372243600
I1006 15:09:05.728006  2964 layer_factory.hpp:77] Creating layer BatchNorm17
I1006 15:09:05.728011  2964 net.cpp:84] Creating Layer BatchNorm17
I1006 15:09:05.728013  2964 net.cpp:406] BatchNorm17 <- Convolution17
I1006 15:09:05.728018  2964 net.cpp:367] BatchNorm17 -> Convolution17 (in-place)
I1006 15:09:05.728152  2964 net.cpp:122] Setting up BatchNorm17
I1006 15:09:05.728155  2964 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 15:09:05.728157  2964 net.cpp:137] Memory required for data: 374752400
I1006 15:09:05.728163  2964 layer_factory.hpp:77] Creating layer Scale17
I1006 15:09:05.728168  2964 net.cpp:84] Creating Layer Scale17
I1006 15:09:05.728169  2964 net.cpp:406] Scale17 <- Convolution17
I1006 15:09:05.728173  2964 net.cpp:367] Scale17 -> Convolution17 (in-place)
I1006 15:09:05.728199  2964 layer_factory.hpp:77] Creating layer Scale17
I1006 15:09:05.728276  2964 net.cpp:122] Setting up Scale17
I1006 15:09:05.728281  2964 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 15:09:05.728282  2964 net.cpp:137] Memory required for data: 377261200
I1006 15:09:05.728286  2964 layer_factory.hpp:77] Creating layer penlu16
I1006 15:09:05.728291  2964 net.cpp:84] Creating Layer penlu16
I1006 15:09:05.728293  2964 net.cpp:406] penlu16 <- Convolution17
I1006 15:09:05.728298  2964 net.cpp:367] penlu16 -> Convolution17 (in-place)
I1006 15:09:05.728404  2964 net.cpp:122] Setting up penlu16
I1006 15:09:05.728408  2964 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 15:09:05.728410  2964 net.cpp:137] Memory required for data: 379770000
I1006 15:09:05.728415  2964 layer_factory.hpp:77] Creating layer Convolution18
I1006 15:09:05.728421  2964 net.cpp:84] Creating Layer Convolution18
I1006 15:09:05.728425  2964 net.cpp:406] Convolution18 <- Convolution17
I1006 15:09:05.728427  2964 net.cpp:380] Convolution18 -> Convolution18
I1006 15:09:05.729490  2964 net.cpp:122] Setting up Convolution18
I1006 15:09:05.729498  2964 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 15:09:05.729501  2964 net.cpp:137] Memory required for data: 382278800
I1006 15:09:05.729506  2964 layer_factory.hpp:77] Creating layer BatchNorm18
I1006 15:09:05.729511  2964 net.cpp:84] Creating Layer BatchNorm18
I1006 15:09:05.729514  2964 net.cpp:406] BatchNorm18 <- Convolution18
I1006 15:09:05.729517  2964 net.cpp:367] BatchNorm18 -> Convolution18 (in-place)
I1006 15:09:05.729652  2964 net.cpp:122] Setting up BatchNorm18
I1006 15:09:05.729656  2964 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 15:09:05.729660  2964 net.cpp:137] Memory required for data: 384787600
I1006 15:09:05.729663  2964 layer_factory.hpp:77] Creating layer Scale18
I1006 15:09:05.729667  2964 net.cpp:84] Creating Layer Scale18
I1006 15:09:05.729671  2964 net.cpp:406] Scale18 <- Convolution18
I1006 15:09:05.729676  2964 net.cpp:367] Scale18 -> Convolution18 (in-place)
I1006 15:09:05.729708  2964 layer_factory.hpp:77] Creating layer Scale18
I1006 15:09:05.729789  2964 net.cpp:122] Setting up Scale18
I1006 15:09:05.729794  2964 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 15:09:05.729795  2964 net.cpp:137] Memory required for data: 387296400
I1006 15:09:05.729799  2964 layer_factory.hpp:77] Creating layer Eltwise8
I1006 15:09:05.729804  2964 net.cpp:84] Creating Layer Eltwise8
I1006 15:09:05.729806  2964 net.cpp:406] Eltwise8 <- Eltwise7_penlu15_0_split_1
I1006 15:09:05.729810  2964 net.cpp:406] Eltwise8 <- Convolution18
I1006 15:09:05.729813  2964 net.cpp:380] Eltwise8 -> Eltwise8
I1006 15:09:05.729830  2964 net.cpp:122] Setting up Eltwise8
I1006 15:09:05.729833  2964 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 15:09:05.729835  2964 net.cpp:137] Memory required for data: 389805200
I1006 15:09:05.729837  2964 layer_factory.hpp:77] Creating layer penlu17
I1006 15:09:05.729842  2964 net.cpp:84] Creating Layer penlu17
I1006 15:09:05.729846  2964 net.cpp:406] penlu17 <- Eltwise8
I1006 15:09:05.729848  2964 net.cpp:367] penlu17 -> Eltwise8 (in-place)
I1006 15:09:05.729955  2964 net.cpp:122] Setting up penlu17
I1006 15:09:05.729959  2964 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 15:09:05.729961  2964 net.cpp:137] Memory required for data: 392314000
I1006 15:09:05.729966  2964 layer_factory.hpp:77] Creating layer Eltwise8_penlu17_0_split
I1006 15:09:05.729970  2964 net.cpp:84] Creating Layer Eltwise8_penlu17_0_split
I1006 15:09:05.729972  2964 net.cpp:406] Eltwise8_penlu17_0_split <- Eltwise8
I1006 15:09:05.729975  2964 net.cpp:380] Eltwise8_penlu17_0_split -> Eltwise8_penlu17_0_split_0
I1006 15:09:05.729979  2964 net.cpp:380] Eltwise8_penlu17_0_split -> Eltwise8_penlu17_0_split_1
I1006 15:09:05.730002  2964 net.cpp:122] Setting up Eltwise8_penlu17_0_split
I1006 15:09:05.730006  2964 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 15:09:05.730010  2964 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 15:09:05.730011  2964 net.cpp:137] Memory required for data: 397331600
I1006 15:09:05.730013  2964 layer_factory.hpp:77] Creating layer Convolution19
I1006 15:09:05.730020  2964 net.cpp:84] Creating Layer Convolution19
I1006 15:09:05.730022  2964 net.cpp:406] Convolution19 <- Eltwise8_penlu17_0_split_0
I1006 15:09:05.730026  2964 net.cpp:380] Convolution19 -> Convolution19
I1006 15:09:05.731935  2964 net.cpp:122] Setting up Convolution19
I1006 15:09:05.731946  2964 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 15:09:05.731950  2964 net.cpp:137] Memory required for data: 399840400
I1006 15:09:05.731957  2964 layer_factory.hpp:77] Creating layer BatchNorm19
I1006 15:09:05.731966  2964 net.cpp:84] Creating Layer BatchNorm19
I1006 15:09:05.731969  2964 net.cpp:406] BatchNorm19 <- Convolution19
I1006 15:09:05.731976  2964 net.cpp:367] BatchNorm19 -> Convolution19 (in-place)
I1006 15:09:05.732178  2964 net.cpp:122] Setting up BatchNorm19
I1006 15:09:05.732188  2964 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 15:09:05.732192  2964 net.cpp:137] Memory required for data: 402349200
I1006 15:09:05.732200  2964 layer_factory.hpp:77] Creating layer Scale19
I1006 15:09:05.732208  2964 net.cpp:84] Creating Layer Scale19
I1006 15:09:05.732211  2964 net.cpp:406] Scale19 <- Convolution19
I1006 15:09:05.732218  2964 net.cpp:367] Scale19 -> Convolution19 (in-place)
I1006 15:09:05.732259  2964 layer_factory.hpp:77] Creating layer Scale19
I1006 15:09:05.732378  2964 net.cpp:122] Setting up Scale19
I1006 15:09:05.732388  2964 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 15:09:05.732391  2964 net.cpp:137] Memory required for data: 404858000
I1006 15:09:05.732398  2964 layer_factory.hpp:77] Creating layer penlu18
I1006 15:09:05.732416  2964 net.cpp:84] Creating Layer penlu18
I1006 15:09:05.732420  2964 net.cpp:406] penlu18 <- Convolution19
I1006 15:09:05.732427  2964 net.cpp:367] penlu18 -> Convolution19 (in-place)
I1006 15:09:05.732602  2964 net.cpp:122] Setting up penlu18
I1006 15:09:05.732620  2964 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 15:09:05.732643  2964 net.cpp:137] Memory required for data: 407366800
I1006 15:09:05.732652  2964 layer_factory.hpp:77] Creating layer Convolution20
I1006 15:09:05.732663  2964 net.cpp:84] Creating Layer Convolution20
I1006 15:09:05.732668  2964 net.cpp:406] Convolution20 <- Convolution19
I1006 15:09:05.732676  2964 net.cpp:380] Convolution20 -> Convolution20
I1006 15:09:05.733925  2964 net.cpp:122] Setting up Convolution20
I1006 15:09:05.733935  2964 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 15:09:05.733948  2964 net.cpp:137] Memory required for data: 409875600
I1006 15:09:05.733952  2964 layer_factory.hpp:77] Creating layer BatchNorm20
I1006 15:09:05.733969  2964 net.cpp:84] Creating Layer BatchNorm20
I1006 15:09:05.733974  2964 net.cpp:406] BatchNorm20 <- Convolution20
I1006 15:09:05.733978  2964 net.cpp:367] BatchNorm20 -> Convolution20 (in-place)
I1006 15:09:05.734127  2964 net.cpp:122] Setting up BatchNorm20
I1006 15:09:05.734133  2964 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 15:09:05.734144  2964 net.cpp:137] Memory required for data: 412384400
I1006 15:09:05.734149  2964 layer_factory.hpp:77] Creating layer Scale20
I1006 15:09:05.734154  2964 net.cpp:84] Creating Layer Scale20
I1006 15:09:05.734156  2964 net.cpp:406] Scale20 <- Convolution20
I1006 15:09:05.734170  2964 net.cpp:367] Scale20 -> Convolution20 (in-place)
I1006 15:09:05.734207  2964 layer_factory.hpp:77] Creating layer Scale20
I1006 15:09:05.734284  2964 net.cpp:122] Setting up Scale20
I1006 15:09:05.734288  2964 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 15:09:05.734290  2964 net.cpp:137] Memory required for data: 414893200
I1006 15:09:05.734294  2964 layer_factory.hpp:77] Creating layer Eltwise9
I1006 15:09:05.734298  2964 net.cpp:84] Creating Layer Eltwise9
I1006 15:09:05.734300  2964 net.cpp:406] Eltwise9 <- Eltwise8_penlu17_0_split_1
I1006 15:09:05.734303  2964 net.cpp:406] Eltwise9 <- Convolution20
I1006 15:09:05.734308  2964 net.cpp:380] Eltwise9 -> Eltwise9
I1006 15:09:05.734323  2964 net.cpp:122] Setting up Eltwise9
I1006 15:09:05.734325  2964 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 15:09:05.734328  2964 net.cpp:137] Memory required for data: 417402000
I1006 15:09:05.734329  2964 layer_factory.hpp:77] Creating layer penlu19
I1006 15:09:05.734335  2964 net.cpp:84] Creating Layer penlu19
I1006 15:09:05.734338  2964 net.cpp:406] penlu19 <- Eltwise9
I1006 15:09:05.734340  2964 net.cpp:367] penlu19 -> Eltwise9 (in-place)
I1006 15:09:05.734447  2964 net.cpp:122] Setting up penlu19
I1006 15:09:05.734450  2964 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 15:09:05.734452  2964 net.cpp:137] Memory required for data: 419910800
I1006 15:09:05.734457  2964 layer_factory.hpp:77] Creating layer Eltwise9_penlu19_0_split
I1006 15:09:05.734460  2964 net.cpp:84] Creating Layer Eltwise9_penlu19_0_split
I1006 15:09:05.734462  2964 net.cpp:406] Eltwise9_penlu19_0_split <- Eltwise9
I1006 15:09:05.734467  2964 net.cpp:380] Eltwise9_penlu19_0_split -> Eltwise9_penlu19_0_split_0
I1006 15:09:05.734470  2964 net.cpp:380] Eltwise9_penlu19_0_split -> Eltwise9_penlu19_0_split_1
I1006 15:09:05.734491  2964 net.cpp:122] Setting up Eltwise9_penlu19_0_split
I1006 15:09:05.734495  2964 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 15:09:05.734498  2964 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 15:09:05.734500  2964 net.cpp:137] Memory required for data: 424928400
I1006 15:09:05.734503  2964 layer_factory.hpp:77] Creating layer Convolution21
I1006 15:09:05.734508  2964 net.cpp:84] Creating Layer Convolution21
I1006 15:09:05.734520  2964 net.cpp:406] Convolution21 <- Eltwise9_penlu19_0_split_0
I1006 15:09:05.734524  2964 net.cpp:380] Convolution21 -> Convolution21
I1006 15:09:05.735950  2964 net.cpp:122] Setting up Convolution21
I1006 15:09:05.735960  2964 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 15:09:05.735962  2964 net.cpp:137] Memory required for data: 427437200
I1006 15:09:05.735966  2964 layer_factory.hpp:77] Creating layer BatchNorm21
I1006 15:09:05.735971  2964 net.cpp:84] Creating Layer BatchNorm21
I1006 15:09:05.735980  2964 net.cpp:406] BatchNorm21 <- Convolution21
I1006 15:09:05.735985  2964 net.cpp:367] BatchNorm21 -> Convolution21 (in-place)
I1006 15:09:05.736120  2964 net.cpp:122] Setting up BatchNorm21
I1006 15:09:05.736124  2964 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 15:09:05.736126  2964 net.cpp:137] Memory required for data: 429946000
I1006 15:09:05.736131  2964 layer_factory.hpp:77] Creating layer Scale21
I1006 15:09:05.736135  2964 net.cpp:84] Creating Layer Scale21
I1006 15:09:05.736137  2964 net.cpp:406] Scale21 <- Convolution21
I1006 15:09:05.736142  2964 net.cpp:367] Scale21 -> Convolution21 (in-place)
I1006 15:09:05.736168  2964 layer_factory.hpp:77] Creating layer Scale21
I1006 15:09:05.736243  2964 net.cpp:122] Setting up Scale21
I1006 15:09:05.736248  2964 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 15:09:05.736249  2964 net.cpp:137] Memory required for data: 432454800
I1006 15:09:05.736253  2964 layer_factory.hpp:77] Creating layer penlu20
I1006 15:09:05.736258  2964 net.cpp:84] Creating Layer penlu20
I1006 15:09:05.736261  2964 net.cpp:406] penlu20 <- Convolution21
I1006 15:09:05.736264  2964 net.cpp:367] penlu20 -> Convolution21 (in-place)
I1006 15:09:05.736371  2964 net.cpp:122] Setting up penlu20
I1006 15:09:05.736376  2964 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 15:09:05.736377  2964 net.cpp:137] Memory required for data: 434963600
I1006 15:09:05.736382  2964 layer_factory.hpp:77] Creating layer Convolution22
I1006 15:09:05.736388  2964 net.cpp:84] Creating Layer Convolution22
I1006 15:09:05.736390  2964 net.cpp:406] Convolution22 <- Convolution21
I1006 15:09:05.736394  2964 net.cpp:380] Convolution22 -> Convolution22
I1006 15:09:05.737431  2964 net.cpp:122] Setting up Convolution22
I1006 15:09:05.737439  2964 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 15:09:05.737442  2964 net.cpp:137] Memory required for data: 437472400
I1006 15:09:05.737447  2964 layer_factory.hpp:77] Creating layer BatchNorm22
I1006 15:09:05.737452  2964 net.cpp:84] Creating Layer BatchNorm22
I1006 15:09:05.737454  2964 net.cpp:406] BatchNorm22 <- Convolution22
I1006 15:09:05.737457  2964 net.cpp:367] BatchNorm22 -> Convolution22 (in-place)
I1006 15:09:05.737589  2964 net.cpp:122] Setting up BatchNorm22
I1006 15:09:05.737593  2964 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 15:09:05.737596  2964 net.cpp:137] Memory required for data: 439981200
I1006 15:09:05.737601  2964 layer_factory.hpp:77] Creating layer Scale22
I1006 15:09:05.737604  2964 net.cpp:84] Creating Layer Scale22
I1006 15:09:05.737607  2964 net.cpp:406] Scale22 <- Convolution22
I1006 15:09:05.737609  2964 net.cpp:367] Scale22 -> Convolution22 (in-place)
I1006 15:09:05.737635  2964 layer_factory.hpp:77] Creating layer Scale22
I1006 15:09:05.737709  2964 net.cpp:122] Setting up Scale22
I1006 15:09:05.737713  2964 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 15:09:05.737715  2964 net.cpp:137] Memory required for data: 442490000
I1006 15:09:05.737720  2964 layer_factory.hpp:77] Creating layer Eltwise10
I1006 15:09:05.737723  2964 net.cpp:84] Creating Layer Eltwise10
I1006 15:09:05.737726  2964 net.cpp:406] Eltwise10 <- Eltwise9_penlu19_0_split_1
I1006 15:09:05.737730  2964 net.cpp:406] Eltwise10 <- Convolution22
I1006 15:09:05.737732  2964 net.cpp:380] Eltwise10 -> Eltwise10
I1006 15:09:05.737748  2964 net.cpp:122] Setting up Eltwise10
I1006 15:09:05.737751  2964 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 15:09:05.737753  2964 net.cpp:137] Memory required for data: 444998800
I1006 15:09:05.737756  2964 layer_factory.hpp:77] Creating layer penlu21
I1006 15:09:05.737761  2964 net.cpp:84] Creating Layer penlu21
I1006 15:09:05.737762  2964 net.cpp:406] penlu21 <- Eltwise10
I1006 15:09:05.737766  2964 net.cpp:367] penlu21 -> Eltwise10 (in-place)
I1006 15:09:05.737871  2964 net.cpp:122] Setting up penlu21
I1006 15:09:05.737875  2964 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 15:09:05.737877  2964 net.cpp:137] Memory required for data: 447507600
I1006 15:09:05.737881  2964 layer_factory.hpp:77] Creating layer Eltwise10_penlu21_0_split
I1006 15:09:05.737892  2964 net.cpp:84] Creating Layer Eltwise10_penlu21_0_split
I1006 15:09:05.737895  2964 net.cpp:406] Eltwise10_penlu21_0_split <- Eltwise10
I1006 15:09:05.737898  2964 net.cpp:380] Eltwise10_penlu21_0_split -> Eltwise10_penlu21_0_split_0
I1006 15:09:05.737902  2964 net.cpp:380] Eltwise10_penlu21_0_split -> Eltwise10_penlu21_0_split_1
I1006 15:09:05.737927  2964 net.cpp:122] Setting up Eltwise10_penlu21_0_split
I1006 15:09:05.737931  2964 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 15:09:05.737933  2964 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 15:09:05.737936  2964 net.cpp:137] Memory required for data: 452525200
I1006 15:09:05.737938  2964 layer_factory.hpp:77] Creating layer Convolution23
I1006 15:09:05.737943  2964 net.cpp:84] Creating Layer Convolution23
I1006 15:09:05.737946  2964 net.cpp:406] Convolution23 <- Eltwise10_penlu21_0_split_0
I1006 15:09:05.737951  2964 net.cpp:380] Convolution23 -> Convolution23
I1006 15:09:05.738826  2964 net.cpp:122] Setting up Convolution23
I1006 15:09:05.738836  2964 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 15:09:05.738838  2964 net.cpp:137] Memory required for data: 453779600
I1006 15:09:05.738842  2964 layer_factory.hpp:77] Creating layer BatchNorm23
I1006 15:09:05.738847  2964 net.cpp:84] Creating Layer BatchNorm23
I1006 15:09:05.738850  2964 net.cpp:406] BatchNorm23 <- Convolution23
I1006 15:09:05.738853  2964 net.cpp:367] BatchNorm23 -> Convolution23 (in-place)
I1006 15:09:05.738982  2964 net.cpp:122] Setting up BatchNorm23
I1006 15:09:05.738986  2964 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 15:09:05.738988  2964 net.cpp:137] Memory required for data: 455034000
I1006 15:09:05.738993  2964 layer_factory.hpp:77] Creating layer Scale23
I1006 15:09:05.738997  2964 net.cpp:84] Creating Layer Scale23
I1006 15:09:05.738999  2964 net.cpp:406] Scale23 <- Convolution23
I1006 15:09:05.739002  2964 net.cpp:367] Scale23 -> Convolution23 (in-place)
I1006 15:09:05.739028  2964 layer_factory.hpp:77] Creating layer Scale23
I1006 15:09:05.739102  2964 net.cpp:122] Setting up Scale23
I1006 15:09:05.739106  2964 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 15:09:05.739109  2964 net.cpp:137] Memory required for data: 456288400
I1006 15:09:05.739112  2964 layer_factory.hpp:77] Creating layer Convolution24
I1006 15:09:05.739120  2964 net.cpp:84] Creating Layer Convolution24
I1006 15:09:05.739121  2964 net.cpp:406] Convolution24 <- Eltwise10_penlu21_0_split_1
I1006 15:09:05.739126  2964 net.cpp:380] Convolution24 -> Convolution24
I1006 15:09:05.740873  2964 net.cpp:122] Setting up Convolution24
I1006 15:09:05.740882  2964 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 15:09:05.740885  2964 net.cpp:137] Memory required for data: 457542800
I1006 15:09:05.740890  2964 layer_factory.hpp:77] Creating layer BatchNorm24
I1006 15:09:05.740895  2964 net.cpp:84] Creating Layer BatchNorm24
I1006 15:09:05.740898  2964 net.cpp:406] BatchNorm24 <- Convolution24
I1006 15:09:05.740901  2964 net.cpp:367] BatchNorm24 -> Convolution24 (in-place)
I1006 15:09:05.741037  2964 net.cpp:122] Setting up BatchNorm24
I1006 15:09:05.741042  2964 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 15:09:05.741044  2964 net.cpp:137] Memory required for data: 458797200
I1006 15:09:05.741048  2964 layer_factory.hpp:77] Creating layer Scale24
I1006 15:09:05.741052  2964 net.cpp:84] Creating Layer Scale24
I1006 15:09:05.741055  2964 net.cpp:406] Scale24 <- Convolution24
I1006 15:09:05.741058  2964 net.cpp:367] Scale24 -> Convolution24 (in-place)
I1006 15:09:05.741086  2964 layer_factory.hpp:77] Creating layer Scale24
I1006 15:09:05.741163  2964 net.cpp:122] Setting up Scale24
I1006 15:09:05.741168  2964 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 15:09:05.741170  2964 net.cpp:137] Memory required for data: 460051600
I1006 15:09:05.741174  2964 layer_factory.hpp:77] Creating layer penlu22
I1006 15:09:05.741179  2964 net.cpp:84] Creating Layer penlu22
I1006 15:09:05.741183  2964 net.cpp:406] penlu22 <- Convolution24
I1006 15:09:05.741194  2964 net.cpp:367] penlu22 -> Convolution24 (in-place)
I1006 15:09:05.741304  2964 net.cpp:122] Setting up penlu22
I1006 15:09:05.741309  2964 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 15:09:05.741312  2964 net.cpp:137] Memory required for data: 461306000
I1006 15:09:05.741315  2964 layer_factory.hpp:77] Creating layer Convolution25
I1006 15:09:05.741322  2964 net.cpp:84] Creating Layer Convolution25
I1006 15:09:05.741325  2964 net.cpp:406] Convolution25 <- Convolution24
I1006 15:09:05.741329  2964 net.cpp:380] Convolution25 -> Convolution25
I1006 15:09:05.743283  2964 net.cpp:122] Setting up Convolution25
I1006 15:09:05.743293  2964 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 15:09:05.743294  2964 net.cpp:137] Memory required for data: 462560400
I1006 15:09:05.743299  2964 layer_factory.hpp:77] Creating layer BatchNorm25
I1006 15:09:05.743304  2964 net.cpp:84] Creating Layer BatchNorm25
I1006 15:09:05.743307  2964 net.cpp:406] BatchNorm25 <- Convolution25
I1006 15:09:05.743311  2964 net.cpp:367] BatchNorm25 -> Convolution25 (in-place)
I1006 15:09:05.743448  2964 net.cpp:122] Setting up BatchNorm25
I1006 15:09:05.743453  2964 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 15:09:05.743454  2964 net.cpp:137] Memory required for data: 463814800
I1006 15:09:05.743459  2964 layer_factory.hpp:77] Creating layer Scale25
I1006 15:09:05.743463  2964 net.cpp:84] Creating Layer Scale25
I1006 15:09:05.743466  2964 net.cpp:406] Scale25 <- Convolution25
I1006 15:09:05.743469  2964 net.cpp:367] Scale25 -> Convolution25 (in-place)
I1006 15:09:05.743495  2964 layer_factory.hpp:77] Creating layer Scale25
I1006 15:09:05.743572  2964 net.cpp:122] Setting up Scale25
I1006 15:09:05.743577  2964 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 15:09:05.743578  2964 net.cpp:137] Memory required for data: 465069200
I1006 15:09:05.743582  2964 layer_factory.hpp:77] Creating layer Eltwise11
I1006 15:09:05.743585  2964 net.cpp:84] Creating Layer Eltwise11
I1006 15:09:05.743587  2964 net.cpp:406] Eltwise11 <- Convolution23
I1006 15:09:05.743590  2964 net.cpp:406] Eltwise11 <- Convolution25
I1006 15:09:05.743594  2964 net.cpp:380] Eltwise11 -> Eltwise11
I1006 15:09:05.743610  2964 net.cpp:122] Setting up Eltwise11
I1006 15:09:05.743614  2964 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 15:09:05.743616  2964 net.cpp:137] Memory required for data: 466323600
I1006 15:09:05.743618  2964 layer_factory.hpp:77] Creating layer penlu23
I1006 15:09:05.743623  2964 net.cpp:84] Creating Layer penlu23
I1006 15:09:05.743625  2964 net.cpp:406] penlu23 <- Eltwise11
I1006 15:09:05.743629  2964 net.cpp:367] penlu23 -> Eltwise11 (in-place)
I1006 15:09:05.743736  2964 net.cpp:122] Setting up penlu23
I1006 15:09:05.743741  2964 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 15:09:05.743742  2964 net.cpp:137] Memory required for data: 467578000
I1006 15:09:05.743746  2964 layer_factory.hpp:77] Creating layer Eltwise11_penlu23_0_split
I1006 15:09:05.743749  2964 net.cpp:84] Creating Layer Eltwise11_penlu23_0_split
I1006 15:09:05.743752  2964 net.cpp:406] Eltwise11_penlu23_0_split <- Eltwise11
I1006 15:09:05.743755  2964 net.cpp:380] Eltwise11_penlu23_0_split -> Eltwise11_penlu23_0_split_0
I1006 15:09:05.743759  2964 net.cpp:380] Eltwise11_penlu23_0_split -> Eltwise11_penlu23_0_split_1
I1006 15:09:05.743782  2964 net.cpp:122] Setting up Eltwise11_penlu23_0_split
I1006 15:09:05.743784  2964 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 15:09:05.743788  2964 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 15:09:05.743789  2964 net.cpp:137] Memory required for data: 470086800
I1006 15:09:05.743791  2964 layer_factory.hpp:77] Creating layer Convolution26
I1006 15:09:05.743798  2964 net.cpp:84] Creating Layer Convolution26
I1006 15:09:05.743800  2964 net.cpp:406] Convolution26 <- Eltwise11_penlu23_0_split_0
I1006 15:09:05.743803  2964 net.cpp:380] Convolution26 -> Convolution26
I1006 15:09:05.745425  2964 net.cpp:122] Setting up Convolution26
I1006 15:09:05.745434  2964 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 15:09:05.745442  2964 net.cpp:137] Memory required for data: 471341200
I1006 15:09:05.745447  2964 layer_factory.hpp:77] Creating layer BatchNorm26
I1006 15:09:05.745453  2964 net.cpp:84] Creating Layer BatchNorm26
I1006 15:09:05.745456  2964 net.cpp:406] BatchNorm26 <- Convolution26
I1006 15:09:05.745460  2964 net.cpp:367] BatchNorm26 -> Convolution26 (in-place)
I1006 15:09:05.745594  2964 net.cpp:122] Setting up BatchNorm26
I1006 15:09:05.745599  2964 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 15:09:05.745601  2964 net.cpp:137] Memory required for data: 472595600
I1006 15:09:05.745606  2964 layer_factory.hpp:77] Creating layer Scale26
I1006 15:09:05.745610  2964 net.cpp:84] Creating Layer Scale26
I1006 15:09:05.745613  2964 net.cpp:406] Scale26 <- Convolution26
I1006 15:09:05.745616  2964 net.cpp:367] Scale26 -> Convolution26 (in-place)
I1006 15:09:05.745643  2964 layer_factory.hpp:77] Creating layer Scale26
I1006 15:09:05.745721  2964 net.cpp:122] Setting up Scale26
I1006 15:09:05.745725  2964 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 15:09:05.745728  2964 net.cpp:137] Memory required for data: 473850000
I1006 15:09:05.745731  2964 layer_factory.hpp:77] Creating layer penlu24
I1006 15:09:05.745736  2964 net.cpp:84] Creating Layer penlu24
I1006 15:09:05.745739  2964 net.cpp:406] penlu24 <- Convolution26
I1006 15:09:05.745743  2964 net.cpp:367] penlu24 -> Convolution26 (in-place)
I1006 15:09:05.745851  2964 net.cpp:122] Setting up penlu24
I1006 15:09:05.745854  2964 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 15:09:05.745857  2964 net.cpp:137] Memory required for data: 475104400
I1006 15:09:05.745862  2964 layer_factory.hpp:77] Creating layer Convolution27
I1006 15:09:05.745867  2964 net.cpp:84] Creating Layer Convolution27
I1006 15:09:05.745869  2964 net.cpp:406] Convolution27 <- Convolution26
I1006 15:09:05.745873  2964 net.cpp:380] Convolution27 -> Convolution27
I1006 15:09:05.747491  2964 net.cpp:122] Setting up Convolution27
I1006 15:09:05.747500  2964 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 15:09:05.747503  2964 net.cpp:137] Memory required for data: 476358800
I1006 15:09:05.747508  2964 layer_factory.hpp:77] Creating layer BatchNorm27
I1006 15:09:05.747514  2964 net.cpp:84] Creating Layer BatchNorm27
I1006 15:09:05.747515  2964 net.cpp:406] BatchNorm27 <- Convolution27
I1006 15:09:05.747519  2964 net.cpp:367] BatchNorm27 -> Convolution27 (in-place)
I1006 15:09:05.747656  2964 net.cpp:122] Setting up BatchNorm27
I1006 15:09:05.747661  2964 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 15:09:05.747663  2964 net.cpp:137] Memory required for data: 477613200
I1006 15:09:05.747689  2964 layer_factory.hpp:77] Creating layer Scale27
I1006 15:09:05.747700  2964 net.cpp:84] Creating Layer Scale27
I1006 15:09:05.747704  2964 net.cpp:406] Scale27 <- Convolution27
I1006 15:09:05.747706  2964 net.cpp:367] Scale27 -> Convolution27 (in-place)
I1006 15:09:05.747735  2964 layer_factory.hpp:77] Creating layer Scale27
I1006 15:09:05.747812  2964 net.cpp:122] Setting up Scale27
I1006 15:09:05.747815  2964 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 15:09:05.747817  2964 net.cpp:137] Memory required for data: 478867600
I1006 15:09:05.747822  2964 layer_factory.hpp:77] Creating layer Eltwise12
I1006 15:09:05.747826  2964 net.cpp:84] Creating Layer Eltwise12
I1006 15:09:05.747828  2964 net.cpp:406] Eltwise12 <- Eltwise11_penlu23_0_split_1
I1006 15:09:05.747831  2964 net.cpp:406] Eltwise12 <- Convolution27
I1006 15:09:05.747834  2964 net.cpp:380] Eltwise12 -> Eltwise12
I1006 15:09:05.747854  2964 net.cpp:122] Setting up Eltwise12
I1006 15:09:05.747859  2964 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 15:09:05.747860  2964 net.cpp:137] Memory required for data: 480122000
I1006 15:09:05.747862  2964 layer_factory.hpp:77] Creating layer penlu25
I1006 15:09:05.747867  2964 net.cpp:84] Creating Layer penlu25
I1006 15:09:05.747869  2964 net.cpp:406] penlu25 <- Eltwise12
I1006 15:09:05.747874  2964 net.cpp:367] penlu25 -> Eltwise12 (in-place)
I1006 15:09:05.747984  2964 net.cpp:122] Setting up penlu25
I1006 15:09:05.747997  2964 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 15:09:05.747998  2964 net.cpp:137] Memory required for data: 481376400
I1006 15:09:05.748003  2964 layer_factory.hpp:77] Creating layer Eltwise12_penlu25_0_split
I1006 15:09:05.748006  2964 net.cpp:84] Creating Layer Eltwise12_penlu25_0_split
I1006 15:09:05.748008  2964 net.cpp:406] Eltwise12_penlu25_0_split <- Eltwise12
I1006 15:09:05.748013  2964 net.cpp:380] Eltwise12_penlu25_0_split -> Eltwise12_penlu25_0_split_0
I1006 15:09:05.748016  2964 net.cpp:380] Eltwise12_penlu25_0_split -> Eltwise12_penlu25_0_split_1
I1006 15:09:05.748040  2964 net.cpp:122] Setting up Eltwise12_penlu25_0_split
I1006 15:09:05.748044  2964 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 15:09:05.748047  2964 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 15:09:05.748049  2964 net.cpp:137] Memory required for data: 483885200
I1006 15:09:05.748051  2964 layer_factory.hpp:77] Creating layer Convolution28
I1006 15:09:05.748057  2964 net.cpp:84] Creating Layer Convolution28
I1006 15:09:05.748059  2964 net.cpp:406] Convolution28 <- Eltwise12_penlu25_0_split_0
I1006 15:09:05.748064  2964 net.cpp:380] Convolution28 -> Convolution28
I1006 15:09:05.749680  2964 net.cpp:122] Setting up Convolution28
I1006 15:09:05.749689  2964 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 15:09:05.749691  2964 net.cpp:137] Memory required for data: 485139600
I1006 15:09:05.749696  2964 layer_factory.hpp:77] Creating layer BatchNorm28
I1006 15:09:05.749701  2964 net.cpp:84] Creating Layer BatchNorm28
I1006 15:09:05.749704  2964 net.cpp:406] BatchNorm28 <- Convolution28
I1006 15:09:05.749708  2964 net.cpp:367] BatchNorm28 -> Convolution28 (in-place)
I1006 15:09:05.749845  2964 net.cpp:122] Setting up BatchNorm28
I1006 15:09:05.749848  2964 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 15:09:05.749850  2964 net.cpp:137] Memory required for data: 486394000
I1006 15:09:05.749855  2964 layer_factory.hpp:77] Creating layer Scale28
I1006 15:09:05.749858  2964 net.cpp:84] Creating Layer Scale28
I1006 15:09:05.749861  2964 net.cpp:406] Scale28 <- Convolution28
I1006 15:09:05.749864  2964 net.cpp:367] Scale28 -> Convolution28 (in-place)
I1006 15:09:05.749891  2964 layer_factory.hpp:77] Creating layer Scale28
I1006 15:09:05.749969  2964 net.cpp:122] Setting up Scale28
I1006 15:09:05.749972  2964 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 15:09:05.749974  2964 net.cpp:137] Memory required for data: 487648400
I1006 15:09:05.749977  2964 layer_factory.hpp:77] Creating layer penlu26
I1006 15:09:05.749982  2964 net.cpp:84] Creating Layer penlu26
I1006 15:09:05.749985  2964 net.cpp:406] penlu26 <- Convolution28
I1006 15:09:05.749989  2964 net.cpp:367] penlu26 -> Convolution28 (in-place)
I1006 15:09:05.750100  2964 net.cpp:122] Setting up penlu26
I1006 15:09:05.750104  2964 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 15:09:05.750107  2964 net.cpp:137] Memory required for data: 488902800
I1006 15:09:05.750110  2964 layer_factory.hpp:77] Creating layer Convolution29
I1006 15:09:05.750116  2964 net.cpp:84] Creating Layer Convolution29
I1006 15:09:05.750119  2964 net.cpp:406] Convolution29 <- Convolution28
I1006 15:09:05.750123  2964 net.cpp:380] Convolution29 -> Convolution29
I1006 15:09:05.752063  2964 net.cpp:122] Setting up Convolution29
I1006 15:09:05.752070  2964 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 15:09:05.752074  2964 net.cpp:137] Memory required for data: 490157200
I1006 15:09:05.752079  2964 layer_factory.hpp:77] Creating layer BatchNorm29
I1006 15:09:05.752084  2964 net.cpp:84] Creating Layer BatchNorm29
I1006 15:09:05.752086  2964 net.cpp:406] BatchNorm29 <- Convolution29
I1006 15:09:05.752089  2964 net.cpp:367] BatchNorm29 -> Convolution29 (in-place)
I1006 15:09:05.752231  2964 net.cpp:122] Setting up BatchNorm29
I1006 15:09:05.752235  2964 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 15:09:05.752238  2964 net.cpp:137] Memory required for data: 491411600
I1006 15:09:05.752243  2964 layer_factory.hpp:77] Creating layer Scale29
I1006 15:09:05.752246  2964 net.cpp:84] Creating Layer Scale29
I1006 15:09:05.752255  2964 net.cpp:406] Scale29 <- Convolution29
I1006 15:09:05.752259  2964 net.cpp:367] Scale29 -> Convolution29 (in-place)
I1006 15:09:05.752288  2964 layer_factory.hpp:77] Creating layer Scale29
I1006 15:09:05.752369  2964 net.cpp:122] Setting up Scale29
I1006 15:09:05.752374  2964 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 15:09:05.752377  2964 net.cpp:137] Memory required for data: 492666000
I1006 15:09:05.752380  2964 layer_factory.hpp:77] Creating layer Eltwise13
I1006 15:09:05.752384  2964 net.cpp:84] Creating Layer Eltwise13
I1006 15:09:05.752387  2964 net.cpp:406] Eltwise13 <- Eltwise12_penlu25_0_split_1
I1006 15:09:05.752389  2964 net.cpp:406] Eltwise13 <- Convolution29
I1006 15:09:05.752393  2964 net.cpp:380] Eltwise13 -> Eltwise13
I1006 15:09:05.752409  2964 net.cpp:122] Setting up Eltwise13
I1006 15:09:05.752413  2964 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 15:09:05.752414  2964 net.cpp:137] Memory required for data: 493920400
I1006 15:09:05.752416  2964 layer_factory.hpp:77] Creating layer penlu27
I1006 15:09:05.752423  2964 net.cpp:84] Creating Layer penlu27
I1006 15:09:05.752424  2964 net.cpp:406] penlu27 <- Eltwise13
I1006 15:09:05.752429  2964 net.cpp:367] penlu27 -> Eltwise13 (in-place)
I1006 15:09:05.752539  2964 net.cpp:122] Setting up penlu27
I1006 15:09:05.752543  2964 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 15:09:05.752545  2964 net.cpp:137] Memory required for data: 495174800
I1006 15:09:05.752549  2964 layer_factory.hpp:77] Creating layer Eltwise13_penlu27_0_split
I1006 15:09:05.752553  2964 net.cpp:84] Creating Layer Eltwise13_penlu27_0_split
I1006 15:09:05.752555  2964 net.cpp:406] Eltwise13_penlu27_0_split <- Eltwise13
I1006 15:09:05.752558  2964 net.cpp:380] Eltwise13_penlu27_0_split -> Eltwise13_penlu27_0_split_0
I1006 15:09:05.752562  2964 net.cpp:380] Eltwise13_penlu27_0_split -> Eltwise13_penlu27_0_split_1
I1006 15:09:05.752585  2964 net.cpp:122] Setting up Eltwise13_penlu27_0_split
I1006 15:09:05.752589  2964 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 15:09:05.752591  2964 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 15:09:05.752593  2964 net.cpp:137] Memory required for data: 497683600
I1006 15:09:05.752595  2964 layer_factory.hpp:77] Creating layer Convolution30
I1006 15:09:05.752601  2964 net.cpp:84] Creating Layer Convolution30
I1006 15:09:05.752604  2964 net.cpp:406] Convolution30 <- Eltwise13_penlu27_0_split_0
I1006 15:09:05.752609  2964 net.cpp:380] Convolution30 -> Convolution30
I1006 15:09:05.754238  2964 net.cpp:122] Setting up Convolution30
I1006 15:09:05.754247  2964 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 15:09:05.754250  2964 net.cpp:137] Memory required for data: 498938000
I1006 15:09:05.754254  2964 layer_factory.hpp:77] Creating layer BatchNorm30
I1006 15:09:05.754259  2964 net.cpp:84] Creating Layer BatchNorm30
I1006 15:09:05.754262  2964 net.cpp:406] BatchNorm30 <- Convolution30
I1006 15:09:05.754266  2964 net.cpp:367] BatchNorm30 -> Convolution30 (in-place)
I1006 15:09:05.754405  2964 net.cpp:122] Setting up BatchNorm30
I1006 15:09:05.754410  2964 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 15:09:05.754411  2964 net.cpp:137] Memory required for data: 500192400
I1006 15:09:05.754416  2964 layer_factory.hpp:77] Creating layer Scale30
I1006 15:09:05.754420  2964 net.cpp:84] Creating Layer Scale30
I1006 15:09:05.754422  2964 net.cpp:406] Scale30 <- Convolution30
I1006 15:09:05.754426  2964 net.cpp:367] Scale30 -> Convolution30 (in-place)
I1006 15:09:05.754453  2964 layer_factory.hpp:77] Creating layer Scale30
I1006 15:09:05.754531  2964 net.cpp:122] Setting up Scale30
I1006 15:09:05.754536  2964 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 15:09:05.754539  2964 net.cpp:137] Memory required for data: 501446800
I1006 15:09:05.754542  2964 layer_factory.hpp:77] Creating layer penlu28
I1006 15:09:05.754546  2964 net.cpp:84] Creating Layer penlu28
I1006 15:09:05.754549  2964 net.cpp:406] penlu28 <- Convolution30
I1006 15:09:05.754554  2964 net.cpp:367] penlu28 -> Convolution30 (in-place)
I1006 15:09:05.754672  2964 net.cpp:122] Setting up penlu28
I1006 15:09:05.754676  2964 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 15:09:05.754678  2964 net.cpp:137] Memory required for data: 502701200
I1006 15:09:05.754683  2964 layer_factory.hpp:77] Creating layer Convolution31
I1006 15:09:05.754688  2964 net.cpp:84] Creating Layer Convolution31
I1006 15:09:05.754691  2964 net.cpp:406] Convolution31 <- Convolution30
I1006 15:09:05.754695  2964 net.cpp:380] Convolution31 -> Convolution31
I1006 15:09:05.756642  2964 net.cpp:122] Setting up Convolution31
I1006 15:09:05.756651  2964 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 15:09:05.756654  2964 net.cpp:137] Memory required for data: 503955600
I1006 15:09:05.756659  2964 layer_factory.hpp:77] Creating layer BatchNorm31
I1006 15:09:05.756664  2964 net.cpp:84] Creating Layer BatchNorm31
I1006 15:09:05.756666  2964 net.cpp:406] BatchNorm31 <- Convolution31
I1006 15:09:05.756670  2964 net.cpp:367] BatchNorm31 -> Convolution31 (in-place)
I1006 15:09:05.756810  2964 net.cpp:122] Setting up BatchNorm31
I1006 15:09:05.756814  2964 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 15:09:05.756817  2964 net.cpp:137] Memory required for data: 505210000
I1006 15:09:05.756822  2964 layer_factory.hpp:77] Creating layer Scale31
I1006 15:09:05.756826  2964 net.cpp:84] Creating Layer Scale31
I1006 15:09:05.756829  2964 net.cpp:406] Scale31 <- Convolution31
I1006 15:09:05.756832  2964 net.cpp:367] Scale31 -> Convolution31 (in-place)
I1006 15:09:05.756860  2964 layer_factory.hpp:77] Creating layer Scale31
I1006 15:09:05.756937  2964 net.cpp:122] Setting up Scale31
I1006 15:09:05.756942  2964 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 15:09:05.756944  2964 net.cpp:137] Memory required for data: 506464400
I1006 15:09:05.756947  2964 layer_factory.hpp:77] Creating layer Eltwise14
I1006 15:09:05.756953  2964 net.cpp:84] Creating Layer Eltwise14
I1006 15:09:05.756954  2964 net.cpp:406] Eltwise14 <- Eltwise13_penlu27_0_split_1
I1006 15:09:05.756958  2964 net.cpp:406] Eltwise14 <- Convolution31
I1006 15:09:05.756961  2964 net.cpp:380] Eltwise14 -> Eltwise14
I1006 15:09:05.756976  2964 net.cpp:122] Setting up Eltwise14
I1006 15:09:05.756980  2964 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 15:09:05.756981  2964 net.cpp:137] Memory required for data: 507718800
I1006 15:09:05.756983  2964 layer_factory.hpp:77] Creating layer penlu29
I1006 15:09:05.756989  2964 net.cpp:84] Creating Layer penlu29
I1006 15:09:05.756992  2964 net.cpp:406] penlu29 <- Eltwise14
I1006 15:09:05.756995  2964 net.cpp:367] penlu29 -> Eltwise14 (in-place)
I1006 15:09:05.757105  2964 net.cpp:122] Setting up penlu29
I1006 15:09:05.757109  2964 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 15:09:05.757112  2964 net.cpp:137] Memory required for data: 508973200
I1006 15:09:05.757115  2964 layer_factory.hpp:77] Creating layer Eltwise14_penlu29_0_split
I1006 15:09:05.757118  2964 net.cpp:84] Creating Layer Eltwise14_penlu29_0_split
I1006 15:09:05.757122  2964 net.cpp:406] Eltwise14_penlu29_0_split <- Eltwise14
I1006 15:09:05.757124  2964 net.cpp:380] Eltwise14_penlu29_0_split -> Eltwise14_penlu29_0_split_0
I1006 15:09:05.757128  2964 net.cpp:380] Eltwise14_penlu29_0_split -> Eltwise14_penlu29_0_split_1
I1006 15:09:05.757150  2964 net.cpp:122] Setting up Eltwise14_penlu29_0_split
I1006 15:09:05.757154  2964 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 15:09:05.757158  2964 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 15:09:05.757158  2964 net.cpp:137] Memory required for data: 511482000
I1006 15:09:05.757160  2964 layer_factory.hpp:77] Creating layer Convolution32
I1006 15:09:05.757167  2964 net.cpp:84] Creating Layer Convolution32
I1006 15:09:05.757169  2964 net.cpp:406] Convolution32 <- Eltwise14_penlu29_0_split_0
I1006 15:09:05.757174  2964 net.cpp:380] Convolution32 -> Convolution32
I1006 15:09:05.758806  2964 net.cpp:122] Setting up Convolution32
I1006 15:09:05.758816  2964 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 15:09:05.758817  2964 net.cpp:137] Memory required for data: 512736400
I1006 15:09:05.758829  2964 layer_factory.hpp:77] Creating layer BatchNorm32
I1006 15:09:05.758836  2964 net.cpp:84] Creating Layer BatchNorm32
I1006 15:09:05.758838  2964 net.cpp:406] BatchNorm32 <- Convolution32
I1006 15:09:05.758841  2964 net.cpp:367] BatchNorm32 -> Convolution32 (in-place)
I1006 15:09:05.758981  2964 net.cpp:122] Setting up BatchNorm32
I1006 15:09:05.758985  2964 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 15:09:05.758988  2964 net.cpp:137] Memory required for data: 513990800
I1006 15:09:05.758992  2964 layer_factory.hpp:77] Creating layer Scale32
I1006 15:09:05.758996  2964 net.cpp:84] Creating Layer Scale32
I1006 15:09:05.758999  2964 net.cpp:406] Scale32 <- Convolution32
I1006 15:09:05.759002  2964 net.cpp:367] Scale32 -> Convolution32 (in-place)
I1006 15:09:05.759032  2964 layer_factory.hpp:77] Creating layer Scale32
I1006 15:09:05.759109  2964 net.cpp:122] Setting up Scale32
I1006 15:09:05.759114  2964 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 15:09:05.759116  2964 net.cpp:137] Memory required for data: 515245200
I1006 15:09:05.759120  2964 layer_factory.hpp:77] Creating layer penlu30
I1006 15:09:05.759125  2964 net.cpp:84] Creating Layer penlu30
I1006 15:09:05.759129  2964 net.cpp:406] penlu30 <- Convolution32
I1006 15:09:05.759131  2964 net.cpp:367] penlu30 -> Convolution32 (in-place)
I1006 15:09:05.759250  2964 net.cpp:122] Setting up penlu30
I1006 15:09:05.759255  2964 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 15:09:05.759258  2964 net.cpp:137] Memory required for data: 516499600
I1006 15:09:05.759263  2964 layer_factory.hpp:77] Creating layer Convolution33
I1006 15:09:05.759268  2964 net.cpp:84] Creating Layer Convolution33
I1006 15:09:05.759271  2964 net.cpp:406] Convolution33 <- Convolution32
I1006 15:09:05.759275  2964 net.cpp:380] Convolution33 -> Convolution33
I1006 15:09:05.761215  2964 net.cpp:122] Setting up Convolution33
I1006 15:09:05.761224  2964 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 15:09:05.761225  2964 net.cpp:137] Memory required for data: 517754000
I1006 15:09:05.761230  2964 layer_factory.hpp:77] Creating layer BatchNorm33
I1006 15:09:05.761234  2964 net.cpp:84] Creating Layer BatchNorm33
I1006 15:09:05.761237  2964 net.cpp:406] BatchNorm33 <- Convolution33
I1006 15:09:05.761241  2964 net.cpp:367] BatchNorm33 -> Convolution33 (in-place)
I1006 15:09:05.761384  2964 net.cpp:122] Setting up BatchNorm33
I1006 15:09:05.761387  2964 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 15:09:05.761389  2964 net.cpp:137] Memory required for data: 519008400
I1006 15:09:05.761394  2964 layer_factory.hpp:77] Creating layer Scale33
I1006 15:09:05.761399  2964 net.cpp:84] Creating Layer Scale33
I1006 15:09:05.761400  2964 net.cpp:406] Scale33 <- Convolution33
I1006 15:09:05.761404  2964 net.cpp:367] Scale33 -> Convolution33 (in-place)
I1006 15:09:05.761431  2964 layer_factory.hpp:77] Creating layer Scale33
I1006 15:09:05.761509  2964 net.cpp:122] Setting up Scale33
I1006 15:09:05.761514  2964 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 15:09:05.761517  2964 net.cpp:137] Memory required for data: 520262800
I1006 15:09:05.761519  2964 layer_factory.hpp:77] Creating layer Eltwise15
I1006 15:09:05.761523  2964 net.cpp:84] Creating Layer Eltwise15
I1006 15:09:05.761526  2964 net.cpp:406] Eltwise15 <- Eltwise14_penlu29_0_split_1
I1006 15:09:05.761528  2964 net.cpp:406] Eltwise15 <- Convolution33
I1006 15:09:05.761533  2964 net.cpp:380] Eltwise15 -> Eltwise15
I1006 15:09:05.761549  2964 net.cpp:122] Setting up Eltwise15
I1006 15:09:05.761553  2964 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 15:09:05.761554  2964 net.cpp:137] Memory required for data: 521517200
I1006 15:09:05.761556  2964 layer_factory.hpp:77] Creating layer penlu31
I1006 15:09:05.761561  2964 net.cpp:84] Creating Layer penlu31
I1006 15:09:05.761564  2964 net.cpp:406] penlu31 <- Eltwise15
I1006 15:09:05.761567  2964 net.cpp:367] penlu31 -> Eltwise15 (in-place)
I1006 15:09:05.761678  2964 net.cpp:122] Setting up penlu31
I1006 15:09:05.761682  2964 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 15:09:05.761690  2964 net.cpp:137] Memory required for data: 522771600
I1006 15:09:05.761695  2964 layer_factory.hpp:77] Creating layer Pooling1
I1006 15:09:05.761700  2964 net.cpp:84] Creating Layer Pooling1
I1006 15:09:05.761703  2964 net.cpp:406] Pooling1 <- Eltwise15
I1006 15:09:05.761705  2964 net.cpp:380] Pooling1 -> Pooling1
I1006 15:09:05.761859  2964 net.cpp:122] Setting up Pooling1
I1006 15:09:05.761865  2964 net.cpp:129] Top shape: 100 64 1 1 (6400)
I1006 15:09:05.761868  2964 net.cpp:137] Memory required for data: 522797200
I1006 15:09:05.761870  2964 layer_factory.hpp:77] Creating layer InnerProduct1
I1006 15:09:05.761880  2964 net.cpp:84] Creating Layer InnerProduct1
I1006 15:09:05.761883  2964 net.cpp:406] InnerProduct1 <- Pooling1
I1006 15:09:05.761888  2964 net.cpp:380] InnerProduct1 -> InnerProduct1
I1006 15:09:05.761981  2964 net.cpp:122] Setting up InnerProduct1
I1006 15:09:05.761987  2964 net.cpp:129] Top shape: 100 10 (1000)
I1006 15:09:05.761989  2964 net.cpp:137] Memory required for data: 522801200
I1006 15:09:05.761992  2964 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I1006 15:09:05.761997  2964 net.cpp:84] Creating Layer SoftmaxWithLoss1
I1006 15:09:05.761999  2964 net.cpp:406] SoftmaxWithLoss1 <- InnerProduct1
I1006 15:09:05.762002  2964 net.cpp:406] SoftmaxWithLoss1 <- Data2
I1006 15:09:05.762006  2964 net.cpp:380] SoftmaxWithLoss1 -> SoftmaxWithLoss1
I1006 15:09:05.762012  2964 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I1006 15:09:05.762192  2964 net.cpp:122] Setting up SoftmaxWithLoss1
I1006 15:09:05.762198  2964 net.cpp:129] Top shape: (1)
I1006 15:09:05.762200  2964 net.cpp:132]     with loss weight 1
I1006 15:09:05.762212  2964 net.cpp:137] Memory required for data: 522801204
I1006 15:09:05.762214  2964 net.cpp:198] SoftmaxWithLoss1 needs backward computation.
I1006 15:09:05.762217  2964 net.cpp:198] InnerProduct1 needs backward computation.
I1006 15:09:05.762219  2964 net.cpp:198] Pooling1 needs backward computation.
I1006 15:09:05.762221  2964 net.cpp:198] penlu31 needs backward computation.
I1006 15:09:05.762223  2964 net.cpp:198] Eltwise15 needs backward computation.
I1006 15:09:05.762225  2964 net.cpp:198] Scale33 needs backward computation.
I1006 15:09:05.762228  2964 net.cpp:198] BatchNorm33 needs backward computation.
I1006 15:09:05.762229  2964 net.cpp:198] Convolution33 needs backward computation.
I1006 15:09:05.762231  2964 net.cpp:198] penlu30 needs backward computation.
I1006 15:09:05.762233  2964 net.cpp:198] Scale32 needs backward computation.
I1006 15:09:05.762235  2964 net.cpp:198] BatchNorm32 needs backward computation.
I1006 15:09:05.762238  2964 net.cpp:198] Convolution32 needs backward computation.
I1006 15:09:05.762239  2964 net.cpp:198] Eltwise14_penlu29_0_split needs backward computation.
I1006 15:09:05.762241  2964 net.cpp:198] penlu29 needs backward computation.
I1006 15:09:05.762243  2964 net.cpp:198] Eltwise14 needs backward computation.
I1006 15:09:05.762245  2964 net.cpp:198] Scale31 needs backward computation.
I1006 15:09:05.762248  2964 net.cpp:198] BatchNorm31 needs backward computation.
I1006 15:09:05.762249  2964 net.cpp:198] Convolution31 needs backward computation.
I1006 15:09:05.762251  2964 net.cpp:198] penlu28 needs backward computation.
I1006 15:09:05.762253  2964 net.cpp:198] Scale30 needs backward computation.
I1006 15:09:05.762255  2964 net.cpp:198] BatchNorm30 needs backward computation.
I1006 15:09:05.762256  2964 net.cpp:198] Convolution30 needs backward computation.
I1006 15:09:05.762259  2964 net.cpp:198] Eltwise13_penlu27_0_split needs backward computation.
I1006 15:09:05.762261  2964 net.cpp:198] penlu27 needs backward computation.
I1006 15:09:05.762264  2964 net.cpp:198] Eltwise13 needs backward computation.
I1006 15:09:05.762265  2964 net.cpp:198] Scale29 needs backward computation.
I1006 15:09:05.762267  2964 net.cpp:198] BatchNorm29 needs backward computation.
I1006 15:09:05.762269  2964 net.cpp:198] Convolution29 needs backward computation.
I1006 15:09:05.762271  2964 net.cpp:198] penlu26 needs backward computation.
I1006 15:09:05.762279  2964 net.cpp:198] Scale28 needs backward computation.
I1006 15:09:05.762281  2964 net.cpp:198] BatchNorm28 needs backward computation.
I1006 15:09:05.762284  2964 net.cpp:198] Convolution28 needs backward computation.
I1006 15:09:05.762285  2964 net.cpp:198] Eltwise12_penlu25_0_split needs backward computation.
I1006 15:09:05.762287  2964 net.cpp:198] penlu25 needs backward computation.
I1006 15:09:05.762290  2964 net.cpp:198] Eltwise12 needs backward computation.
I1006 15:09:05.762291  2964 net.cpp:198] Scale27 needs backward computation.
I1006 15:09:05.762295  2964 net.cpp:198] BatchNorm27 needs backward computation.
I1006 15:09:05.762296  2964 net.cpp:198] Convolution27 needs backward computation.
I1006 15:09:05.762298  2964 net.cpp:198] penlu24 needs backward computation.
I1006 15:09:05.762300  2964 net.cpp:198] Scale26 needs backward computation.
I1006 15:09:05.762302  2964 net.cpp:198] BatchNorm26 needs backward computation.
I1006 15:09:05.762305  2964 net.cpp:198] Convolution26 needs backward computation.
I1006 15:09:05.762307  2964 net.cpp:198] Eltwise11_penlu23_0_split needs backward computation.
I1006 15:09:05.762310  2964 net.cpp:198] penlu23 needs backward computation.
I1006 15:09:05.762311  2964 net.cpp:198] Eltwise11 needs backward computation.
I1006 15:09:05.762313  2964 net.cpp:198] Scale25 needs backward computation.
I1006 15:09:05.762315  2964 net.cpp:198] BatchNorm25 needs backward computation.
I1006 15:09:05.762317  2964 net.cpp:198] Convolution25 needs backward computation.
I1006 15:09:05.762320  2964 net.cpp:198] penlu22 needs backward computation.
I1006 15:09:05.762321  2964 net.cpp:198] Scale24 needs backward computation.
I1006 15:09:05.762323  2964 net.cpp:198] BatchNorm24 needs backward computation.
I1006 15:09:05.762325  2964 net.cpp:198] Convolution24 needs backward computation.
I1006 15:09:05.762327  2964 net.cpp:198] Scale23 needs backward computation.
I1006 15:09:05.762329  2964 net.cpp:198] BatchNorm23 needs backward computation.
I1006 15:09:05.762331  2964 net.cpp:198] Convolution23 needs backward computation.
I1006 15:09:05.762333  2964 net.cpp:198] Eltwise10_penlu21_0_split needs backward computation.
I1006 15:09:05.762336  2964 net.cpp:198] penlu21 needs backward computation.
I1006 15:09:05.762337  2964 net.cpp:198] Eltwise10 needs backward computation.
I1006 15:09:05.762339  2964 net.cpp:198] Scale22 needs backward computation.
I1006 15:09:05.762341  2964 net.cpp:198] BatchNorm22 needs backward computation.
I1006 15:09:05.762343  2964 net.cpp:198] Convolution22 needs backward computation.
I1006 15:09:05.762346  2964 net.cpp:198] penlu20 needs backward computation.
I1006 15:09:05.762347  2964 net.cpp:198] Scale21 needs backward computation.
I1006 15:09:05.762349  2964 net.cpp:198] BatchNorm21 needs backward computation.
I1006 15:09:05.762351  2964 net.cpp:198] Convolution21 needs backward computation.
I1006 15:09:05.762353  2964 net.cpp:198] Eltwise9_penlu19_0_split needs backward computation.
I1006 15:09:05.762356  2964 net.cpp:198] penlu19 needs backward computation.
I1006 15:09:05.762358  2964 net.cpp:198] Eltwise9 needs backward computation.
I1006 15:09:05.762361  2964 net.cpp:198] Scale20 needs backward computation.
I1006 15:09:05.762362  2964 net.cpp:198] BatchNorm20 needs backward computation.
I1006 15:09:05.762364  2964 net.cpp:198] Convolution20 needs backward computation.
I1006 15:09:05.762367  2964 net.cpp:198] penlu18 needs backward computation.
I1006 15:09:05.762368  2964 net.cpp:198] Scale19 needs backward computation.
I1006 15:09:05.762370  2964 net.cpp:198] BatchNorm19 needs backward computation.
I1006 15:09:05.762372  2964 net.cpp:198] Convolution19 needs backward computation.
I1006 15:09:05.762375  2964 net.cpp:198] Eltwise8_penlu17_0_split needs backward computation.
I1006 15:09:05.762377  2964 net.cpp:198] penlu17 needs backward computation.
I1006 15:09:05.762379  2964 net.cpp:198] Eltwise8 needs backward computation.
I1006 15:09:05.762382  2964 net.cpp:198] Scale18 needs backward computation.
I1006 15:09:05.762384  2964 net.cpp:198] BatchNorm18 needs backward computation.
I1006 15:09:05.762389  2964 net.cpp:198] Convolution18 needs backward computation.
I1006 15:09:05.762392  2964 net.cpp:198] penlu16 needs backward computation.
I1006 15:09:05.762393  2964 net.cpp:198] Scale17 needs backward computation.
I1006 15:09:05.762395  2964 net.cpp:198] BatchNorm17 needs backward computation.
I1006 15:09:05.762398  2964 net.cpp:198] Convolution17 needs backward computation.
I1006 15:09:05.762400  2964 net.cpp:198] Eltwise7_penlu15_0_split needs backward computation.
I1006 15:09:05.762403  2964 net.cpp:198] penlu15 needs backward computation.
I1006 15:09:05.762404  2964 net.cpp:198] Eltwise7 needs backward computation.
I1006 15:09:05.762406  2964 net.cpp:198] Scale16 needs backward computation.
I1006 15:09:05.762408  2964 net.cpp:198] BatchNorm16 needs backward computation.
I1006 15:09:05.762410  2964 net.cpp:198] Convolution16 needs backward computation.
I1006 15:09:05.762413  2964 net.cpp:198] penlu14 needs backward computation.
I1006 15:09:05.762415  2964 net.cpp:198] Scale15 needs backward computation.
I1006 15:09:05.762418  2964 net.cpp:198] BatchNorm15 needs backward computation.
I1006 15:09:05.762419  2964 net.cpp:198] Convolution15 needs backward computation.
I1006 15:09:05.762421  2964 net.cpp:198] Eltwise6_penlu13_0_split needs backward computation.
I1006 15:09:05.762424  2964 net.cpp:198] penlu13 needs backward computation.
I1006 15:09:05.762426  2964 net.cpp:198] Eltwise6 needs backward computation.
I1006 15:09:05.762428  2964 net.cpp:198] Scale14 needs backward computation.
I1006 15:09:05.762430  2964 net.cpp:198] BatchNorm14 needs backward computation.
I1006 15:09:05.762432  2964 net.cpp:198] Convolution14 needs backward computation.
I1006 15:09:05.762434  2964 net.cpp:198] penlu12 needs backward computation.
I1006 15:09:05.762436  2964 net.cpp:198] Scale13 needs backward computation.
I1006 15:09:05.762439  2964 net.cpp:198] BatchNorm13 needs backward computation.
I1006 15:09:05.762440  2964 net.cpp:198] Convolution13 needs backward computation.
I1006 15:09:05.762444  2964 net.cpp:198] Scale12 needs backward computation.
I1006 15:09:05.762445  2964 net.cpp:198] BatchNorm12 needs backward computation.
I1006 15:09:05.762447  2964 net.cpp:198] Convolution12 needs backward computation.
I1006 15:09:05.762449  2964 net.cpp:198] Eltwise5_penlu11_0_split needs backward computation.
I1006 15:09:05.762451  2964 net.cpp:198] penlu11 needs backward computation.
I1006 15:09:05.762454  2964 net.cpp:198] Eltwise5 needs backward computation.
I1006 15:09:05.762456  2964 net.cpp:198] Scale11 needs backward computation.
I1006 15:09:05.762459  2964 net.cpp:198] BatchNorm11 needs backward computation.
I1006 15:09:05.762460  2964 net.cpp:198] Convolution11 needs backward computation.
I1006 15:09:05.762462  2964 net.cpp:198] penlu10 needs backward computation.
I1006 15:09:05.762465  2964 net.cpp:198] Scale10 needs backward computation.
I1006 15:09:05.762466  2964 net.cpp:198] BatchNorm10 needs backward computation.
I1006 15:09:05.762468  2964 net.cpp:198] Convolution10 needs backward computation.
I1006 15:09:05.762471  2964 net.cpp:198] Eltwise4_penlu9_0_split needs backward computation.
I1006 15:09:05.762473  2964 net.cpp:198] penlu9 needs backward computation.
I1006 15:09:05.762475  2964 net.cpp:198] Eltwise4 needs backward computation.
I1006 15:09:05.762477  2964 net.cpp:198] Scale9 needs backward computation.
I1006 15:09:05.762480  2964 net.cpp:198] BatchNorm9 needs backward computation.
I1006 15:09:05.762482  2964 net.cpp:198] Convolution9 needs backward computation.
I1006 15:09:05.762485  2964 net.cpp:198] penlu8 needs backward computation.
I1006 15:09:05.762486  2964 net.cpp:198] Scale8 needs backward computation.
I1006 15:09:05.762488  2964 net.cpp:198] BatchNorm8 needs backward computation.
I1006 15:09:05.762490  2964 net.cpp:198] Convolution8 needs backward computation.
I1006 15:09:05.762493  2964 net.cpp:198] Eltwise3_penlu7_0_split needs backward computation.
I1006 15:09:05.762495  2964 net.cpp:198] penlu7 needs backward computation.
I1006 15:09:05.762501  2964 net.cpp:198] Eltwise3 needs backward computation.
I1006 15:09:05.762502  2964 net.cpp:198] Scale7 needs backward computation.
I1006 15:09:05.762506  2964 net.cpp:198] BatchNorm7 needs backward computation.
I1006 15:09:05.762506  2964 net.cpp:198] Convolution7 needs backward computation.
I1006 15:09:05.762509  2964 net.cpp:198] penlu6 needs backward computation.
I1006 15:09:05.762511  2964 net.cpp:198] Scale6 needs backward computation.
I1006 15:09:05.762513  2964 net.cpp:198] BatchNorm6 needs backward computation.
I1006 15:09:05.762516  2964 net.cpp:198] Convolution6 needs backward computation.
I1006 15:09:05.762517  2964 net.cpp:198] Eltwise2_penlu5_0_split needs backward computation.
I1006 15:09:05.762519  2964 net.cpp:198] penlu5 needs backward computation.
I1006 15:09:05.762521  2964 net.cpp:198] Eltwise2 needs backward computation.
I1006 15:09:05.762524  2964 net.cpp:198] Scale5 needs backward computation.
I1006 15:09:05.762527  2964 net.cpp:198] BatchNorm5 needs backward computation.
I1006 15:09:05.762529  2964 net.cpp:198] Convolution5 needs backward computation.
I1006 15:09:05.762531  2964 net.cpp:198] penlu4 needs backward computation.
I1006 15:09:05.762533  2964 net.cpp:198] Scale4 needs backward computation.
I1006 15:09:05.762536  2964 net.cpp:198] BatchNorm4 needs backward computation.
I1006 15:09:05.762537  2964 net.cpp:198] Convolution4 needs backward computation.
I1006 15:09:05.762540  2964 net.cpp:198] Eltwise1_penlu3_0_split needs backward computation.
I1006 15:09:05.762542  2964 net.cpp:198] penlu3 needs backward computation.
I1006 15:09:05.762544  2964 net.cpp:198] Eltwise1 needs backward computation.
I1006 15:09:05.762547  2964 net.cpp:198] Scale3 needs backward computation.
I1006 15:09:05.762549  2964 net.cpp:198] BatchNorm3 needs backward computation.
I1006 15:09:05.762552  2964 net.cpp:198] Convolution3 needs backward computation.
I1006 15:09:05.762554  2964 net.cpp:198] penlu2 needs backward computation.
I1006 15:09:05.762557  2964 net.cpp:198] Scale2 needs backward computation.
I1006 15:09:05.762558  2964 net.cpp:198] BatchNorm2 needs backward computation.
I1006 15:09:05.762560  2964 net.cpp:198] Convolution2 needs backward computation.
I1006 15:09:05.762562  2964 net.cpp:198] Convolution1_penlu1_0_split needs backward computation.
I1006 15:09:05.762565  2964 net.cpp:198] penlu1 needs backward computation.
I1006 15:09:05.762567  2964 net.cpp:198] Scale1 needs backward computation.
I1006 15:09:05.762569  2964 net.cpp:198] BatchNorm1 needs backward computation.
I1006 15:09:05.762572  2964 net.cpp:198] Convolution1 needs backward computation.
I1006 15:09:05.762573  2964 net.cpp:200] Data1 does not need backward computation.
I1006 15:09:05.762575  2964 net.cpp:242] This network produces output SoftmaxWithLoss1
I1006 15:09:05.762624  2964 net.cpp:255] Network initialization done.
I1006 15:09:05.766633  2964 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: /home/x306/caffe/xn/PENLU/neural/resnet/res32/res32_penlu_decay_gauss.prototxt
I1006 15:09:05.766645  2964 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I1006 15:09:05.766649  2964 solver.cpp:172] Creating test net (#0) specified by net file: /home/x306/caffe/xn/PENLU/neural/resnet/res32/res32_penlu_decay_gauss.prototxt
I1006 15:09:05.766763  2964 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer Data1
I1006 15:09:05.767624  2964 net.cpp:51] Initializing net from parameters: 
name: "resnet_cifar10"
state {
  phase: TEST
}
layer {
  name: "Data1"
  type: "Data"
  top: "Data1"
  top: "Data2"
  include {
    phase: TEST
  }
  transform_param {
    mean_file: "/home/x306/caffe/xn/PENLU/data/cifar10/mean.binaryproto"
  }
  data_param {
    source: "/home/x306/caffe/xn/PENLU/data/cifar10/cifar10_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "Convolution1"
  type: "Convolution"
  bottom: "Data1"
  top: "Convolution1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm1"
  type: "BatchNorm"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1"
  type: "Scale"
  bottom: "Convolution1"
  top: "Convolution1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu1"
  type: "PENLU"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution2"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm2"
  type: "BatchNorm"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale2"
  type: "Scale"
  bottom: "Convolution2"
  top: "Convolution2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu2"
  type: "PENLU"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution3"
  type: "Convolution"
  bottom: "Convolution2"
  top: "Convolution3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm3"
  type: "BatchNorm"
  bottom: "Convolution3"
  top: "Convolution3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale3"
  type: "Scale"
  bottom: "Convolution3"
  top: "Convolution3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise1"
  type: "Eltwise"
  bottom: "Convolution1"
  bottom: "Convolution3"
  top: "Eltwise1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu3"
  type: "PENLU"
  bottom: "Eltwise1"
  top: "Eltwise1"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution4"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm4"
  type: "BatchNorm"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale4"
  type: "Scale"
  bottom: "Convolution4"
  top: "Convolution4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu4"
  type: "PENLU"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution5"
  type: "Convolution"
  bottom: "Convolution4"
  top: "Convolution5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm5"
  type: "BatchNorm"
  bottom: "Convolution5"
  top: "Convolution5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale5"
  type: "Scale"
  bottom: "Convolution5"
  top: "Convolution5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise2"
  type: "Eltwise"
  bottom: "Eltwise1"
  bottom: "Convolution5"
  top: "Eltwise2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu5"
  type: "PENLU"
  bottom: "Eltwise2"
  top: "Eltwise2"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution6"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm6"
  type: "BatchNorm"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale6"
  type: "Scale"
  bottom: "Convolution6"
  top: "Convolution6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu6"
  type: "PENLU"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution7"
  type: "Convolution"
  bottom: "Convolution6"
  top: "Convolution7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm7"
  type: "BatchNorm"
  bottom: "Convolution7"
  top: "Convolution7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale7"
  type: "Scale"
  bottom: "Convolution7"
  top: "Convolution7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise3"
  type: "Eltwise"
  bottom: "Eltwise2"
  bottom: "Convolution7"
  top: "Eltwise3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu7"
  type: "PENLU"
  bottom: "Eltwise3"
  top: "Eltwise3"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution8"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm8"
  type: "BatchNorm"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale8"
  type: "Scale"
  bottom: "Convolution8"
  top: "Convolution8"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu8"
  type: "PENLU"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution9"
  type: "Convolution"
  bottom: "Convolution8"
  top: "Convolution9"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm9"
  type: "BatchNorm"
  bottom: "Convolution9"
  top: "Convolution9"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale9"
  type: "Scale"
  bottom: "Convolution9"
  top: "Convolution9"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise4"
  type: "Eltwise"
  bottom: "Eltwise3"
  bottom: "Convolution9"
  top: "Eltwise4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu9"
  type: "PENLU"
  bottom: "Eltwise4"
  top: "Eltwise4"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution10"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution10"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm10"
  type: "BatchNorm"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale10"
  type: "Scale"
  bottom: "Convolution10"
  top: "Convolution10"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu10"
  type: "PENLU"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution11"
  type: "Convolution"
  bottom: "Convolution10"
  top: "Convolution11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm11"
  type: "BatchNorm"
  bottom: "Convolution11"
  top: "Convolution11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale11"
  type: "Scale"
  bottom: "Convolution11"
  top: "Convolution11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise5"
  type: "Eltwise"
  bottom: "Eltwise4"
  bottom: "Convolution11"
  top: "Eltwise5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu11"
  type: "PENLU"
  bottom: "Eltwise5"
  top: "Eltwise5"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution12"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.25
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm12"
  type: "BatchNorm"
  bottom: "Convolution12"
  top: "Convolution12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale12"
  type: "Scale"
  bottom: "Convolution12"
  top: "Convolution12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution13"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution13"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm13"
  type: "BatchNorm"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale13"
  type: "Scale"
  bottom: "Convolution13"
  top: "Convolution13"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu12"
  type: "PENLU"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution14"
  type: "Convolution"
  bottom: "Convolution13"
  top: "Convolution14"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm14"
  type: "BatchNorm"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale14"
  type: "Scale"
  bottom: "Convolution14"
  top: "Convolution14"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise6"
  type: "Eltwise"
  bottom: "Convolution12"
  bottom: "Convolution14"
  top: "Eltwise6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu13"
  type: "PENLU"
  bottom: "Eltwise6"
  top: "Eltwise6"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution15"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution15"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm15"
  type: "BatchNorm"
  bottom: "Convolution15"
  top: "Convolution15"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale15"
  type: "Scale"
  bottom: "Convolution15"
  top: "Convolution15"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu14"
  type: "PENLU"
  bottom: "Convolution15"
  top: "Convolution15"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution16"
  type: "Convolution"
  bottom: "Convolution15"
  top: "Convolution16"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm16"
  type: "BatchNorm"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale16"
  type: "Scale"
  bottom: "Convolution16"
  top: "Convolution16"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise7"
  type: "Eltwise"
  bottom: "Eltwise6"
  bottom: "Convolution16"
  top: "Eltwise7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu15"
  type: "PENLU"
  bottom: "Eltwise7"
  top: "Eltwise7"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution17"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution17"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm17"
  type: "BatchNorm"
  bottom: "Convolution17"
  top: "Convolution17"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale17"
  type: "Scale"
  bottom: "Convolution17"
  top: "Convolution17"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu16"
  type: "PENLU"
  bottom: "Convolution17"
  top: "Convolution17"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution18"
  type: "Convolution"
  bottom: "Convolution17"
  top: "Convolution18"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm18"
  type: "BatchNorm"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale18"
  type: "Scale"
  bottom: "Convolution18"
  top: "Convolution18"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise8"
  type: "Eltwise"
  bottom: "Eltwise7"
  bottom: "Convolution18"
  top: "Eltwise8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu17"
  type: "PENLU"
  bottom: "Eltwise8"
  top: "Eltwise8"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution19"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution19"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm19"
  type: "BatchNorm"
  bottom: "Convolution19"
  top: "Convolution19"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale19"
  type: "Scale"
  bottom: "Convolution19"
  top: "Convolution19"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu18"
  type: "PENLU"
  bottom: "Convolution19"
  top: "Convolution19"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution20"
  type: "Convolution"
  bottom: "Convolution19"
  top: "Convolution20"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm20"
  type: "BatchNorm"
  bottom: "Convolution20"
  top: "Convolution20"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale20"
  type: "Scale"
  bottom: "Convolution20"
  top: "Convolution20"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise9"
  type: "Eltwise"
  bottom: "Eltwise8"
  bottom: "Convolution20"
  top: "Eltwise9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu19"
  type: "PENLU"
  bottom: "Eltwise9"
  top: "Eltwise9"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution21"
  type: "Convolution"
  bottom: "Eltwise9"
  top: "Convolution21"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm21"
  type: "BatchNorm"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale21"
  type: "Scale"
  bottom: "Convolution21"
  top: "Convolution21"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu20"
  type: "PENLU"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution22"
  type: "Convolution"
  bottom: "Convolution21"
  top: "Convolution22"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm22"
  type: "BatchNorm"
  bottom: "Convolution22"
  top: "Convolution22"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale22"
  type: "Scale"
  bottom: "Convolution22"
  top: "Convolution22"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise10"
  type: "Eltwise"
  bottom: "Eltwise9"
  bottom: "Convolution22"
  top: "Eltwise10"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu21"
  type: "PENLU"
  bottom: "Eltwise10"
  top: "Eltwise10"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 0.25
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution23"
  type: "Convolution"
  bottom: "Eltwise10"
  top: "Convolution23"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.17677669
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm23"
  type: "BatchNorm"
  bottom: "Convolution23"
  top: "Convolution23"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale23"
  type: "Scale"
  bottom: "Convolution23"
  top: "Convolution23"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution24"
  type: "Convolution"
  bottom: "Eltwise10"
  top: "Convolution24"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm24"
  type: "BatchNorm"
  bottom: "Convolution24"
  top: "Convolution24"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale24"
  type: "Scale"
  bottom: "Convolution24"
  top: "Convolution24"
  scale_param {
    bi
I1006 15:09:05.768033  2964 layer_factory.hpp:77] Creating layer Data1
I1006 15:09:05.794373  2964 db_lmdb.cpp:35] Opened lmdb /home/x306/caffe/xn/PENLU/data/cifar10/cifar10_test_lmdb
I1006 15:09:05.794390  2964 net.cpp:84] Creating Layer Data1
I1006 15:09:05.794399  2964 net.cpp:380] Data1 -> Data1
I1006 15:09:05.794409  2964 net.cpp:380] Data1 -> Data2
I1006 15:09:05.794419  2964 data_transformer.cpp:25] Loading mean file from: /home/x306/caffe/xn/PENLU/data/cifar10/mean.binaryproto
I1006 15:09:05.794617  2964 data_layer.cpp:45] output data size: 100,3,32,32
I1006 15:09:05.799949  2964 net.cpp:122] Setting up Data1
I1006 15:09:05.799969  2964 net.cpp:129] Top shape: 100 3 32 32 (307200)
I1006 15:09:05.799973  2964 net.cpp:129] Top shape: 100 (100)
I1006 15:09:05.799976  2964 net.cpp:137] Memory required for data: 1229200
I1006 15:09:05.799981  2964 layer_factory.hpp:77] Creating layer Data2_Data1_1_split
I1006 15:09:05.799990  2964 net.cpp:84] Creating Layer Data2_Data1_1_split
I1006 15:09:05.799993  2964 net.cpp:406] Data2_Data1_1_split <- Data2
I1006 15:09:05.799998  2964 net.cpp:380] Data2_Data1_1_split -> Data2_Data1_1_split_0
I1006 15:09:05.800005  2964 net.cpp:380] Data2_Data1_1_split -> Data2_Data1_1_split_1
I1006 15:09:05.800110  2964 net.cpp:122] Setting up Data2_Data1_1_split
I1006 15:09:05.800128  2964 net.cpp:129] Top shape: 100 (100)
I1006 15:09:05.800143  2964 net.cpp:129] Top shape: 100 (100)
I1006 15:09:05.800144  2964 net.cpp:137] Memory required for data: 1230000
I1006 15:09:05.800148  2964 layer_factory.hpp:77] Creating layer Convolution1
I1006 15:09:05.800166  2964 net.cpp:84] Creating Layer Convolution1
I1006 15:09:05.800170  2964 net.cpp:406] Convolution1 <- Data1
I1006 15:09:05.800174  2964 net.cpp:380] Convolution1 -> Convolution1
I1006 15:09:05.801384  2964 net.cpp:122] Setting up Convolution1
I1006 15:09:05.801398  2964 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 15:09:05.801400  2964 net.cpp:137] Memory required for data: 7783600
I1006 15:09:05.801409  2964 layer_factory.hpp:77] Creating layer BatchNorm1
I1006 15:09:05.801414  2964 net.cpp:84] Creating Layer BatchNorm1
I1006 15:09:05.801416  2964 net.cpp:406] BatchNorm1 <- Convolution1
I1006 15:09:05.801420  2964 net.cpp:367] BatchNorm1 -> Convolution1 (in-place)
I1006 15:09:05.801564  2964 net.cpp:122] Setting up BatchNorm1
I1006 15:09:05.801568  2964 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 15:09:05.801571  2964 net.cpp:137] Memory required for data: 14337200
I1006 15:09:05.801578  2964 layer_factory.hpp:77] Creating layer Scale1
I1006 15:09:05.801584  2964 net.cpp:84] Creating Layer Scale1
I1006 15:09:05.801587  2964 net.cpp:406] Scale1 <- Convolution1
I1006 15:09:05.801590  2964 net.cpp:367] Scale1 -> Convolution1 (in-place)
I1006 15:09:05.801620  2964 layer_factory.hpp:77] Creating layer Scale1
I1006 15:09:05.801704  2964 net.cpp:122] Setting up Scale1
I1006 15:09:05.801709  2964 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 15:09:05.801712  2964 net.cpp:137] Memory required for data: 20890800
I1006 15:09:05.801715  2964 layer_factory.hpp:77] Creating layer penlu1
I1006 15:09:05.801723  2964 net.cpp:84] Creating Layer penlu1
I1006 15:09:05.801725  2964 net.cpp:406] penlu1 <- Convolution1
I1006 15:09:05.801729  2964 net.cpp:367] penlu1 -> Convolution1 (in-place)
I1006 15:09:05.801854  2964 net.cpp:122] Setting up penlu1
I1006 15:09:05.801868  2964 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 15:09:05.801872  2964 net.cpp:137] Memory required for data: 27444400
I1006 15:09:05.801877  2964 layer_factory.hpp:77] Creating layer Convolution1_penlu1_0_split
I1006 15:09:05.801882  2964 net.cpp:84] Creating Layer Convolution1_penlu1_0_split
I1006 15:09:05.801883  2964 net.cpp:406] Convolution1_penlu1_0_split <- Convolution1
I1006 15:09:05.801888  2964 net.cpp:380] Convolution1_penlu1_0_split -> Convolution1_penlu1_0_split_0
I1006 15:09:05.801892  2964 net.cpp:380] Convolution1_penlu1_0_split -> Convolution1_penlu1_0_split_1
I1006 15:09:05.801918  2964 net.cpp:122] Setting up Convolution1_penlu1_0_split
I1006 15:09:05.801921  2964 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 15:09:05.801924  2964 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 15:09:05.801926  2964 net.cpp:137] Memory required for data: 40551600
I1006 15:09:05.801930  2964 layer_factory.hpp:77] Creating layer Convolution2
I1006 15:09:05.801946  2964 net.cpp:84] Creating Layer Convolution2
I1006 15:09:05.801949  2964 net.cpp:406] Convolution2 <- Convolution1_penlu1_0_split_0
I1006 15:09:05.801954  2964 net.cpp:380] Convolution2 -> Convolution2
I1006 15:09:05.803021  2964 net.cpp:122] Setting up Convolution2
I1006 15:09:05.803030  2964 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 15:09:05.803033  2964 net.cpp:137] Memory required for data: 47105200
I1006 15:09:05.803037  2964 layer_factory.hpp:77] Creating layer BatchNorm2
I1006 15:09:05.803045  2964 net.cpp:84] Creating Layer BatchNorm2
I1006 15:09:05.803047  2964 net.cpp:406] BatchNorm2 <- Convolution2
I1006 15:09:05.803052  2964 net.cpp:367] BatchNorm2 -> Convolution2 (in-place)
I1006 15:09:05.803225  2964 net.cpp:122] Setting up BatchNorm2
I1006 15:09:05.803231  2964 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 15:09:05.803232  2964 net.cpp:137] Memory required for data: 53658800
I1006 15:09:05.803238  2964 layer_factory.hpp:77] Creating layer Scale2
I1006 15:09:05.803244  2964 net.cpp:84] Creating Layer Scale2
I1006 15:09:05.803246  2964 net.cpp:406] Scale2 <- Convolution2
I1006 15:09:05.803251  2964 net.cpp:367] Scale2 -> Convolution2 (in-place)
I1006 15:09:05.803282  2964 layer_factory.hpp:77] Creating layer Scale2
I1006 15:09:05.803361  2964 net.cpp:122] Setting up Scale2
I1006 15:09:05.803366  2964 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 15:09:05.803369  2964 net.cpp:137] Memory required for data: 60212400
I1006 15:09:05.803375  2964 layer_factory.hpp:77] Creating layer penlu2
I1006 15:09:05.803380  2964 net.cpp:84] Creating Layer penlu2
I1006 15:09:05.803383  2964 net.cpp:406] penlu2 <- Convolution2
I1006 15:09:05.803388  2964 net.cpp:367] penlu2 -> Convolution2 (in-place)
I1006 15:09:05.803508  2964 net.cpp:122] Setting up penlu2
I1006 15:09:05.803514  2964 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 15:09:05.803519  2964 net.cpp:137] Memory required for data: 66766000
I1006 15:09:05.803524  2964 layer_factory.hpp:77] Creating layer Convolution3
I1006 15:09:05.803531  2964 net.cpp:84] Creating Layer Convolution3
I1006 15:09:05.803534  2964 net.cpp:406] Convolution3 <- Convolution2
I1006 15:09:05.803537  2964 net.cpp:380] Convolution3 -> Convolution3
I1006 15:09:05.804611  2964 net.cpp:122] Setting up Convolution3
I1006 15:09:05.804621  2964 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 15:09:05.804625  2964 net.cpp:137] Memory required for data: 73319600
I1006 15:09:05.804628  2964 layer_factory.hpp:77] Creating layer BatchNorm3
I1006 15:09:05.804633  2964 net.cpp:84] Creating Layer BatchNorm3
I1006 15:09:05.804636  2964 net.cpp:406] BatchNorm3 <- Convolution3
I1006 15:09:05.804641  2964 net.cpp:367] BatchNorm3 -> Convolution3 (in-place)
I1006 15:09:05.804780  2964 net.cpp:122] Setting up BatchNorm3
I1006 15:09:05.804785  2964 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 15:09:05.804786  2964 net.cpp:137] Memory required for data: 79873200
I1006 15:09:05.804791  2964 layer_factory.hpp:77] Creating layer Scale3
I1006 15:09:05.804795  2964 net.cpp:84] Creating Layer Scale3
I1006 15:09:05.804805  2964 net.cpp:406] Scale3 <- Convolution3
I1006 15:09:05.804808  2964 net.cpp:367] Scale3 -> Convolution3 (in-place)
I1006 15:09:05.804837  2964 layer_factory.hpp:77] Creating layer Scale3
I1006 15:09:05.804914  2964 net.cpp:122] Setting up Scale3
I1006 15:09:05.804919  2964 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 15:09:05.804922  2964 net.cpp:137] Memory required for data: 86426800
I1006 15:09:05.804932  2964 layer_factory.hpp:77] Creating layer Eltwise1
I1006 15:09:05.804936  2964 net.cpp:84] Creating Layer Eltwise1
I1006 15:09:05.804942  2964 net.cpp:406] Eltwise1 <- Convolution1_penlu1_0_split_1
I1006 15:09:05.804945  2964 net.cpp:406] Eltwise1 <- Convolution3
I1006 15:09:05.804949  2964 net.cpp:380] Eltwise1 -> Eltwise1
I1006 15:09:05.804966  2964 net.cpp:122] Setting up Eltwise1
I1006 15:09:05.804970  2964 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 15:09:05.804972  2964 net.cpp:137] Memory required for data: 92980400
I1006 15:09:05.804976  2964 layer_factory.hpp:77] Creating layer penlu3
I1006 15:09:05.804982  2964 net.cpp:84] Creating Layer penlu3
I1006 15:09:05.804986  2964 net.cpp:406] penlu3 <- Eltwise1
I1006 15:09:05.804988  2964 net.cpp:367] penlu3 -> Eltwise1 (in-place)
I1006 15:09:05.805107  2964 net.cpp:122] Setting up penlu3
I1006 15:09:05.805111  2964 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 15:09:05.805114  2964 net.cpp:137] Memory required for data: 99534000
I1006 15:09:05.805117  2964 layer_factory.hpp:77] Creating layer Eltwise1_penlu3_0_split
I1006 15:09:05.805124  2964 net.cpp:84] Creating Layer Eltwise1_penlu3_0_split
I1006 15:09:05.805125  2964 net.cpp:406] Eltwise1_penlu3_0_split <- Eltwise1
I1006 15:09:05.805130  2964 net.cpp:380] Eltwise1_penlu3_0_split -> Eltwise1_penlu3_0_split_0
I1006 15:09:05.805133  2964 net.cpp:380] Eltwise1_penlu3_0_split -> Eltwise1_penlu3_0_split_1
I1006 15:09:05.805158  2964 net.cpp:122] Setting up Eltwise1_penlu3_0_split
I1006 15:09:05.805164  2964 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 15:09:05.805166  2964 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 15:09:05.805168  2964 net.cpp:137] Memory required for data: 112641200
I1006 15:09:05.805171  2964 layer_factory.hpp:77] Creating layer Convolution4
I1006 15:09:05.805176  2964 net.cpp:84] Creating Layer Convolution4
I1006 15:09:05.805179  2964 net.cpp:406] Convolution4 <- Eltwise1_penlu3_0_split_0
I1006 15:09:05.805183  2964 net.cpp:380] Convolution4 -> Convolution4
I1006 15:09:05.806246  2964 net.cpp:122] Setting up Convolution4
I1006 15:09:05.806255  2964 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 15:09:05.806258  2964 net.cpp:137] Memory required for data: 119194800
I1006 15:09:05.806262  2964 layer_factory.hpp:77] Creating layer BatchNorm4
I1006 15:09:05.806268  2964 net.cpp:84] Creating Layer BatchNorm4
I1006 15:09:05.806272  2964 net.cpp:406] BatchNorm4 <- Convolution4
I1006 15:09:05.806277  2964 net.cpp:367] BatchNorm4 -> Convolution4 (in-place)
I1006 15:09:05.806416  2964 net.cpp:122] Setting up BatchNorm4
I1006 15:09:05.806424  2964 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 15:09:05.806427  2964 net.cpp:137] Memory required for data: 125748400
I1006 15:09:05.806435  2964 layer_factory.hpp:77] Creating layer Scale4
I1006 15:09:05.806439  2964 net.cpp:84] Creating Layer Scale4
I1006 15:09:05.806442  2964 net.cpp:406] Scale4 <- Convolution4
I1006 15:09:05.806445  2964 net.cpp:367] Scale4 -> Convolution4 (in-place)
I1006 15:09:05.806474  2964 layer_factory.hpp:77] Creating layer Scale4
I1006 15:09:05.806551  2964 net.cpp:122] Setting up Scale4
I1006 15:09:05.806556  2964 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 15:09:05.806558  2964 net.cpp:137] Memory required for data: 132302000
I1006 15:09:05.806562  2964 layer_factory.hpp:77] Creating layer penlu4
I1006 15:09:05.806568  2964 net.cpp:84] Creating Layer penlu4
I1006 15:09:05.806574  2964 net.cpp:406] penlu4 <- Convolution4
I1006 15:09:05.806578  2964 net.cpp:367] penlu4 -> Convolution4 (in-place)
I1006 15:09:05.806697  2964 net.cpp:122] Setting up penlu4
I1006 15:09:05.806708  2964 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 15:09:05.806710  2964 net.cpp:137] Memory required for data: 138855600
I1006 15:09:05.806715  2964 layer_factory.hpp:77] Creating layer Convolution5
I1006 15:09:05.806725  2964 net.cpp:84] Creating Layer Convolution5
I1006 15:09:05.806727  2964 net.cpp:406] Convolution5 <- Convolution4
I1006 15:09:05.806732  2964 net.cpp:380] Convolution5 -> Convolution5
I1006 15:09:05.807718  2964 net.cpp:122] Setting up Convolution5
I1006 15:09:05.807727  2964 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 15:09:05.807730  2964 net.cpp:137] Memory required for data: 145409200
I1006 15:09:05.807734  2964 layer_factory.hpp:77] Creating layer BatchNorm5
I1006 15:09:05.807740  2964 net.cpp:84] Creating Layer BatchNorm5
I1006 15:09:05.807742  2964 net.cpp:406] BatchNorm5 <- Convolution5
I1006 15:09:05.807746  2964 net.cpp:367] BatchNorm5 -> Convolution5 (in-place)
I1006 15:09:05.807886  2964 net.cpp:122] Setting up BatchNorm5
I1006 15:09:05.807890  2964 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 15:09:05.807893  2964 net.cpp:137] Memory required for data: 151962800
I1006 15:09:05.807898  2964 layer_factory.hpp:77] Creating layer Scale5
I1006 15:09:05.807901  2964 net.cpp:84] Creating Layer Scale5
I1006 15:09:05.807904  2964 net.cpp:406] Scale5 <- Convolution5
I1006 15:09:05.807909  2964 net.cpp:367] Scale5 -> Convolution5 (in-place)
I1006 15:09:05.807935  2964 layer_factory.hpp:77] Creating layer Scale5
I1006 15:09:05.808013  2964 net.cpp:122] Setting up Scale5
I1006 15:09:05.808017  2964 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 15:09:05.808019  2964 net.cpp:137] Memory required for data: 158516400
I1006 15:09:05.808023  2964 layer_factory.hpp:77] Creating layer Eltwise2
I1006 15:09:05.808027  2964 net.cpp:84] Creating Layer Eltwise2
I1006 15:09:05.808030  2964 net.cpp:406] Eltwise2 <- Eltwise1_penlu3_0_split_1
I1006 15:09:05.808033  2964 net.cpp:406] Eltwise2 <- Convolution5
I1006 15:09:05.808037  2964 net.cpp:380] Eltwise2 -> Eltwise2
I1006 15:09:05.808053  2964 net.cpp:122] Setting up Eltwise2
I1006 15:09:05.808056  2964 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 15:09:05.808058  2964 net.cpp:137] Memory required for data: 165070000
I1006 15:09:05.808060  2964 layer_factory.hpp:77] Creating layer penlu5
I1006 15:09:05.808065  2964 net.cpp:84] Creating Layer penlu5
I1006 15:09:05.808068  2964 net.cpp:406] penlu5 <- Eltwise2
I1006 15:09:05.808071  2964 net.cpp:367] penlu5 -> Eltwise2 (in-place)
I1006 15:09:05.808192  2964 net.cpp:122] Setting up penlu5
I1006 15:09:05.808195  2964 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 15:09:05.808197  2964 net.cpp:137] Memory required for data: 171623600
I1006 15:09:05.808202  2964 layer_factory.hpp:77] Creating layer Eltwise2_penlu5_0_split
I1006 15:09:05.808205  2964 net.cpp:84] Creating Layer Eltwise2_penlu5_0_split
I1006 15:09:05.808207  2964 net.cpp:406] Eltwise2_penlu5_0_split <- Eltwise2
I1006 15:09:05.808212  2964 net.cpp:380] Eltwise2_penlu5_0_split -> Eltwise2_penlu5_0_split_0
I1006 15:09:05.808214  2964 net.cpp:380] Eltwise2_penlu5_0_split -> Eltwise2_penlu5_0_split_1
I1006 15:09:05.808240  2964 net.cpp:122] Setting up Eltwise2_penlu5_0_split
I1006 15:09:05.808243  2964 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 15:09:05.808248  2964 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 15:09:05.808249  2964 net.cpp:137] Memory required for data: 184730800
I1006 15:09:05.808251  2964 layer_factory.hpp:77] Creating layer Convolution6
I1006 15:09:05.808256  2964 net.cpp:84] Creating Layer Convolution6
I1006 15:09:05.808259  2964 net.cpp:406] Convolution6 <- Eltwise2_penlu5_0_split_0
I1006 15:09:05.808264  2964 net.cpp:380] Convolution6 -> Convolution6
I1006 15:09:05.809208  2964 net.cpp:122] Setting up Convolution6
I1006 15:09:05.809217  2964 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 15:09:05.809221  2964 net.cpp:137] Memory required for data: 191284400
I1006 15:09:05.809226  2964 layer_factory.hpp:77] Creating layer BatchNorm6
I1006 15:09:05.809238  2964 net.cpp:84] Creating Layer BatchNorm6
I1006 15:09:05.809242  2964 net.cpp:406] BatchNorm6 <- Convolution6
I1006 15:09:05.809245  2964 net.cpp:367] BatchNorm6 -> Convolution6 (in-place)
I1006 15:09:05.809403  2964 net.cpp:122] Setting up BatchNorm6
I1006 15:09:05.809408  2964 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 15:09:05.809411  2964 net.cpp:137] Memory required for data: 197838000
I1006 15:09:05.809417  2964 layer_factory.hpp:77] Creating layer Scale6
I1006 15:09:05.809420  2964 net.cpp:84] Creating Layer Scale6
I1006 15:09:05.809423  2964 net.cpp:406] Scale6 <- Convolution6
I1006 15:09:05.824949  2964 net.cpp:367] Scale6 -> Convolution6 (in-place)
I1006 15:09:05.825012  2964 layer_factory.hpp:77] Creating layer Scale6
I1006 15:09:05.825140  2964 net.cpp:122] Setting up Scale6
I1006 15:09:05.825150  2964 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 15:09:05.825153  2964 net.cpp:137] Memory required for data: 204391600
I1006 15:09:05.825161  2964 layer_factory.hpp:77] Creating layer penlu6
I1006 15:09:05.825170  2964 net.cpp:84] Creating Layer penlu6
I1006 15:09:05.825176  2964 net.cpp:406] penlu6 <- Convolution6
I1006 15:09:05.825183  2964 net.cpp:367] penlu6 -> Convolution6 (in-place)
I1006 15:09:05.825376  2964 net.cpp:122] Setting up penlu6
I1006 15:09:05.825384  2964 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 15:09:05.825388  2964 net.cpp:137] Memory required for data: 210945200
I1006 15:09:05.825397  2964 layer_factory.hpp:77] Creating layer Convolution7
I1006 15:09:05.825408  2964 net.cpp:84] Creating Layer Convolution7
I1006 15:09:05.825413  2964 net.cpp:406] Convolution7 <- Convolution6
I1006 15:09:05.825420  2964 net.cpp:380] Convolution7 -> Convolution7
I1006 15:09:05.826788  2964 net.cpp:122] Setting up Convolution7
I1006 15:09:05.826799  2964 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 15:09:05.826803  2964 net.cpp:137] Memory required for data: 217498800
I1006 15:09:05.826810  2964 layer_factory.hpp:77] Creating layer BatchNorm7
I1006 15:09:05.826819  2964 net.cpp:84] Creating Layer BatchNorm7
I1006 15:09:05.826823  2964 net.cpp:406] BatchNorm7 <- Convolution7
I1006 15:09:05.826829  2964 net.cpp:367] BatchNorm7 -> Convolution7 (in-place)
I1006 15:09:05.827047  2964 net.cpp:122] Setting up BatchNorm7
I1006 15:09:05.827057  2964 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 15:09:05.827061  2964 net.cpp:137] Memory required for data: 224052400
I1006 15:09:05.827076  2964 layer_factory.hpp:77] Creating layer Scale7
I1006 15:09:05.827083  2964 net.cpp:84] Creating Layer Scale7
I1006 15:09:05.827088  2964 net.cpp:406] Scale7 <- Convolution7
I1006 15:09:05.827095  2964 net.cpp:367] Scale7 -> Convolution7 (in-place)
I1006 15:09:05.827139  2964 layer_factory.hpp:77] Creating layer Scale7
I1006 15:09:05.827255  2964 net.cpp:122] Setting up Scale7
I1006 15:09:05.827265  2964 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 15:09:05.827270  2964 net.cpp:137] Memory required for data: 230606000
I1006 15:09:05.827276  2964 layer_factory.hpp:77] Creating layer Eltwise3
I1006 15:09:05.827283  2964 net.cpp:84] Creating Layer Eltwise3
I1006 15:09:05.827287  2964 net.cpp:406] Eltwise3 <- Eltwise2_penlu5_0_split_1
I1006 15:09:05.827292  2964 net.cpp:406] Eltwise3 <- Convolution7
I1006 15:09:05.827297  2964 net.cpp:380] Eltwise3 -> Eltwise3
I1006 15:09:05.827325  2964 net.cpp:122] Setting up Eltwise3
I1006 15:09:05.827332  2964 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 15:09:05.827337  2964 net.cpp:137] Memory required for data: 237159600
I1006 15:09:05.827339  2964 layer_factory.hpp:77] Creating layer penlu7
I1006 15:09:05.827347  2964 net.cpp:84] Creating Layer penlu7
I1006 15:09:05.827349  2964 net.cpp:406] penlu7 <- Eltwise3
I1006 15:09:05.827355  2964 net.cpp:367] penlu7 -> Eltwise3 (in-place)
I1006 15:09:05.827561  2964 net.cpp:122] Setting up penlu7
I1006 15:09:05.827571  2964 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 15:09:05.827575  2964 net.cpp:137] Memory required for data: 243713200
I1006 15:09:05.827591  2964 layer_factory.hpp:77] Creating layer Eltwise3_penlu7_0_split
I1006 15:09:05.827600  2964 net.cpp:84] Creating Layer Eltwise3_penlu7_0_split
I1006 15:09:05.827605  2964 net.cpp:406] Eltwise3_penlu7_0_split <- Eltwise3
I1006 15:09:05.827610  2964 net.cpp:380] Eltwise3_penlu7_0_split -> Eltwise3_penlu7_0_split_0
I1006 15:09:05.827617  2964 net.cpp:380] Eltwise3_penlu7_0_split -> Eltwise3_penlu7_0_split_1
I1006 15:09:05.827675  2964 net.cpp:122] Setting up Eltwise3_penlu7_0_split
I1006 15:09:05.827682  2964 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 15:09:05.827687  2964 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 15:09:05.827693  2964 net.cpp:137] Memory required for data: 256820400
I1006 15:09:05.827697  2964 layer_factory.hpp:77] Creating layer Convolution8
I1006 15:09:05.827716  2964 net.cpp:84] Creating Layer Convolution8
I1006 15:09:05.827721  2964 net.cpp:406] Convolution8 <- Eltwise3_penlu7_0_split_0
I1006 15:09:05.827730  2964 net.cpp:380] Convolution8 -> Convolution8
I1006 15:09:05.829035  2964 net.cpp:122] Setting up Convolution8
I1006 15:09:05.829044  2964 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 15:09:05.829047  2964 net.cpp:137] Memory required for data: 263374000
I1006 15:09:05.829051  2964 layer_factory.hpp:77] Creating layer BatchNorm8
I1006 15:09:05.829057  2964 net.cpp:84] Creating Layer BatchNorm8
I1006 15:09:05.829059  2964 net.cpp:406] BatchNorm8 <- Convolution8
I1006 15:09:05.829064  2964 net.cpp:367] BatchNorm8 -> Convolution8 (in-place)
I1006 15:09:05.829206  2964 net.cpp:122] Setting up BatchNorm8
I1006 15:09:05.829210  2964 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 15:09:05.829212  2964 net.cpp:137] Memory required for data: 269927600
I1006 15:09:05.829217  2964 layer_factory.hpp:77] Creating layer Scale8
I1006 15:09:05.829221  2964 net.cpp:84] Creating Layer Scale8
I1006 15:09:05.829223  2964 net.cpp:406] Scale8 <- Convolution8
I1006 15:09:05.829229  2964 net.cpp:367] Scale8 -> Convolution8 (in-place)
I1006 15:09:05.829257  2964 layer_factory.hpp:77] Creating layer Scale8
I1006 15:09:05.829336  2964 net.cpp:122] Setting up Scale8
I1006 15:09:05.829340  2964 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 15:09:05.829342  2964 net.cpp:137] Memory required for data: 276481200
I1006 15:09:05.829345  2964 layer_factory.hpp:77] Creating layer penlu8
I1006 15:09:05.829350  2964 net.cpp:84] Creating Layer penlu8
I1006 15:09:05.829352  2964 net.cpp:406] penlu8 <- Convolution8
I1006 15:09:05.829356  2964 net.cpp:367] penlu8 -> Convolution8 (in-place)
I1006 15:09:05.829488  2964 net.cpp:122] Setting up penlu8
I1006 15:09:05.829491  2964 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 15:09:05.829493  2964 net.cpp:137] Memory required for data: 283034800
I1006 15:09:05.829497  2964 layer_factory.hpp:77] Creating layer Convolution9
I1006 15:09:05.829504  2964 net.cpp:84] Creating Layer Convolution9
I1006 15:09:05.829507  2964 net.cpp:406] Convolution9 <- Convolution8
I1006 15:09:05.829511  2964 net.cpp:380] Convolution9 -> Convolution9
I1006 15:09:05.830905  2964 net.cpp:122] Setting up Convolution9
I1006 15:09:05.830914  2964 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 15:09:05.830916  2964 net.cpp:137] Memory required for data: 289588400
I1006 15:09:05.830921  2964 layer_factory.hpp:77] Creating layer BatchNorm9
I1006 15:09:05.830926  2964 net.cpp:84] Creating Layer BatchNorm9
I1006 15:09:05.830929  2964 net.cpp:406] BatchNorm9 <- Convolution9
I1006 15:09:05.830932  2964 net.cpp:367] BatchNorm9 -> Convolution9 (in-place)
I1006 15:09:05.831075  2964 net.cpp:122] Setting up BatchNorm9
I1006 15:09:05.831080  2964 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 15:09:05.831082  2964 net.cpp:137] Memory required for data: 296142000
I1006 15:09:05.831086  2964 layer_factory.hpp:77] Creating layer Scale9
I1006 15:09:05.831090  2964 net.cpp:84] Creating Layer Scale9
I1006 15:09:05.831094  2964 net.cpp:406] Scale9 <- Convolution9
I1006 15:09:05.831096  2964 net.cpp:367] Scale9 -> Convolution9 (in-place)
I1006 15:09:05.831125  2964 layer_factory.hpp:77] Creating layer Scale9
I1006 15:09:05.831219  2964 net.cpp:122] Setting up Scale9
I1006 15:09:05.831225  2964 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 15:09:05.831228  2964 net.cpp:137] Memory required for data: 302695600
I1006 15:09:05.831231  2964 layer_factory.hpp:77] Creating layer Eltwise4
I1006 15:09:05.831235  2964 net.cpp:84] Creating Layer Eltwise4
I1006 15:09:05.831238  2964 net.cpp:406] Eltwise4 <- Eltwise3_penlu7_0_split_1
I1006 15:09:05.831241  2964 net.cpp:406] Eltwise4 <- Convolution9
I1006 15:09:05.831244  2964 net.cpp:380] Eltwise4 -> Eltwise4
I1006 15:09:05.831261  2964 net.cpp:122] Setting up Eltwise4
I1006 15:09:05.831265  2964 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 15:09:05.831267  2964 net.cpp:137] Memory required for data: 309249200
I1006 15:09:05.831269  2964 layer_factory.hpp:77] Creating layer penlu9
I1006 15:09:05.831274  2964 net.cpp:84] Creating Layer penlu9
I1006 15:09:05.831276  2964 net.cpp:406] penlu9 <- Eltwise4
I1006 15:09:05.831280  2964 net.cpp:367] penlu9 -> Eltwise4 (in-place)
I1006 15:09:05.831403  2964 net.cpp:122] Setting up penlu9
I1006 15:09:05.831406  2964 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 15:09:05.831408  2964 net.cpp:137] Memory required for data: 315802800
I1006 15:09:05.831413  2964 layer_factory.hpp:77] Creating layer Eltwise4_penlu9_0_split
I1006 15:09:05.831418  2964 net.cpp:84] Creating Layer Eltwise4_penlu9_0_split
I1006 15:09:05.831420  2964 net.cpp:406] Eltwise4_penlu9_0_split <- Eltwise4
I1006 15:09:05.831424  2964 net.cpp:380] Eltwise4_penlu9_0_split -> Eltwise4_penlu9_0_split_0
I1006 15:09:05.831429  2964 net.cpp:380] Eltwise4_penlu9_0_split -> Eltwise4_penlu9_0_split_1
I1006 15:09:05.831452  2964 net.cpp:122] Setting up Eltwise4_penlu9_0_split
I1006 15:09:05.831456  2964 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 15:09:05.831459  2964 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 15:09:05.831461  2964 net.cpp:137] Memory required for data: 328910000
I1006 15:09:05.831463  2964 layer_factory.hpp:77] Creating layer Convolution10
I1006 15:09:05.831468  2964 net.cpp:84] Creating Layer Convolution10
I1006 15:09:05.831471  2964 net.cpp:406] Convolution10 <- Eltwise4_penlu9_0_split_0
I1006 15:09:05.831475  2964 net.cpp:380] Convolution10 -> Convolution10
I1006 15:09:05.832058  2964 net.cpp:122] Setting up Convolution10
I1006 15:09:05.832065  2964 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 15:09:05.832067  2964 net.cpp:137] Memory required for data: 335463600
I1006 15:09:05.832072  2964 layer_factory.hpp:77] Creating layer BatchNorm10
I1006 15:09:05.832075  2964 net.cpp:84] Creating Layer BatchNorm10
I1006 15:09:05.832078  2964 net.cpp:406] BatchNorm10 <- Convolution10
I1006 15:09:05.832082  2964 net.cpp:367] BatchNorm10 -> Convolution10 (in-place)
I1006 15:09:05.832223  2964 net.cpp:122] Setting up BatchNorm10
I1006 15:09:05.832227  2964 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 15:09:05.832229  2964 net.cpp:137] Memory required for data: 342017200
I1006 15:09:05.832234  2964 layer_factory.hpp:77] Creating layer Scale10
I1006 15:09:05.832238  2964 net.cpp:84] Creating Layer Scale10
I1006 15:09:05.832240  2964 net.cpp:406] Scale10 <- Convolution10
I1006 15:09:05.832243  2964 net.cpp:367] Scale10 -> Convolution10 (in-place)
I1006 15:09:05.832271  2964 layer_factory.hpp:77] Creating layer Scale10
I1006 15:09:05.832350  2964 net.cpp:122] Setting up Scale10
I1006 15:09:05.832353  2964 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 15:09:05.832355  2964 net.cpp:137] Memory required for data: 348570800
I1006 15:09:05.832360  2964 layer_factory.hpp:77] Creating layer penlu10
I1006 15:09:05.832365  2964 net.cpp:84] Creating Layer penlu10
I1006 15:09:05.832366  2964 net.cpp:406] penlu10 <- Convolution10
I1006 15:09:05.832370  2964 net.cpp:367] penlu10 -> Convolution10 (in-place)
I1006 15:09:05.832494  2964 net.cpp:122] Setting up penlu10
I1006 15:09:05.832499  2964 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 15:09:05.832500  2964 net.cpp:137] Memory required for data: 355124400
I1006 15:09:05.832511  2964 layer_factory.hpp:77] Creating layer Convolution11
I1006 15:09:05.832518  2964 net.cpp:84] Creating Layer Convolution11
I1006 15:09:05.832521  2964 net.cpp:406] Convolution11 <- Convolution10
I1006 15:09:05.832525  2964 net.cpp:380] Convolution11 -> Convolution11
I1006 15:09:05.833431  2964 net.cpp:122] Setting up Convolution11
I1006 15:09:05.833441  2964 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 15:09:05.833442  2964 net.cpp:137] Memory required for data: 361678000
I1006 15:09:05.833447  2964 layer_factory.hpp:77] Creating layer BatchNorm11
I1006 15:09:05.833452  2964 net.cpp:84] Creating Layer BatchNorm11
I1006 15:09:05.833456  2964 net.cpp:406] BatchNorm11 <- Convolution11
I1006 15:09:05.833459  2964 net.cpp:367] BatchNorm11 -> Convolution11 (in-place)
I1006 15:09:05.833601  2964 net.cpp:122] Setting up BatchNorm11
I1006 15:09:05.833606  2964 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 15:09:05.833607  2964 net.cpp:137] Memory required for data: 368231600
I1006 15:09:05.833612  2964 layer_factory.hpp:77] Creating layer Scale11
I1006 15:09:05.833616  2964 net.cpp:84] Creating Layer Scale11
I1006 15:09:05.833619  2964 net.cpp:406] Scale11 <- Convolution11
I1006 15:09:05.833622  2964 net.cpp:367] Scale11 -> Convolution11 (in-place)
I1006 15:09:05.833650  2964 layer_factory.hpp:77] Creating layer Scale11
I1006 15:09:05.833731  2964 net.cpp:122] Setting up Scale11
I1006 15:09:05.833735  2964 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 15:09:05.833737  2964 net.cpp:137] Memory required for data: 374785200
I1006 15:09:05.833741  2964 layer_factory.hpp:77] Creating layer Eltwise5
I1006 15:09:05.833745  2964 net.cpp:84] Creating Layer Eltwise5
I1006 15:09:05.833747  2964 net.cpp:406] Eltwise5 <- Eltwise4_penlu9_0_split_1
I1006 15:09:05.833750  2964 net.cpp:406] Eltwise5 <- Convolution11
I1006 15:09:05.833753  2964 net.cpp:380] Eltwise5 -> Eltwise5
I1006 15:09:05.833770  2964 net.cpp:122] Setting up Eltwise5
I1006 15:09:05.833775  2964 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 15:09:05.833776  2964 net.cpp:137] Memory required for data: 381338800
I1006 15:09:05.833778  2964 layer_factory.hpp:77] Creating layer penlu11
I1006 15:09:05.833782  2964 net.cpp:84] Creating Layer penlu11
I1006 15:09:05.833784  2964 net.cpp:406] penlu11 <- Eltwise5
I1006 15:09:05.833788  2964 net.cpp:367] penlu11 -> Eltwise5 (in-place)
I1006 15:09:05.833909  2964 net.cpp:122] Setting up penlu11
I1006 15:09:05.833912  2964 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 15:09:05.833914  2964 net.cpp:137] Memory required for data: 387892400
I1006 15:09:05.833919  2964 layer_factory.hpp:77] Creating layer Eltwise5_penlu11_0_split
I1006 15:09:05.833921  2964 net.cpp:84] Creating Layer Eltwise5_penlu11_0_split
I1006 15:09:05.833925  2964 net.cpp:406] Eltwise5_penlu11_0_split <- Eltwise5
I1006 15:09:05.833927  2964 net.cpp:380] Eltwise5_penlu11_0_split -> Eltwise5_penlu11_0_split_0
I1006 15:09:05.833931  2964 net.cpp:380] Eltwise5_penlu11_0_split -> Eltwise5_penlu11_0_split_1
I1006 15:09:05.833956  2964 net.cpp:122] Setting up Eltwise5_penlu11_0_split
I1006 15:09:05.833958  2964 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 15:09:05.833961  2964 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 15:09:05.833963  2964 net.cpp:137] Memory required for data: 400999600
I1006 15:09:05.833966  2964 layer_factory.hpp:77] Creating layer Convolution12
I1006 15:09:05.833971  2964 net.cpp:84] Creating Layer Convolution12
I1006 15:09:05.833973  2964 net.cpp:406] Convolution12 <- Eltwise5_penlu11_0_split_0
I1006 15:09:05.833977  2964 net.cpp:380] Convolution12 -> Convolution12
I1006 15:09:05.834862  2964 net.cpp:122] Setting up Convolution12
I1006 15:09:05.834870  2964 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 15:09:05.834873  2964 net.cpp:137] Memory required for data: 404276400
I1006 15:09:05.834877  2964 layer_factory.hpp:77] Creating layer BatchNorm12
I1006 15:09:05.834882  2964 net.cpp:84] Creating Layer BatchNorm12
I1006 15:09:05.834885  2964 net.cpp:406] BatchNorm12 <- Convolution12
I1006 15:09:05.834895  2964 net.cpp:367] BatchNorm12 -> Convolution12 (in-place)
I1006 15:09:05.835036  2964 net.cpp:122] Setting up BatchNorm12
I1006 15:09:05.835041  2964 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 15:09:05.835042  2964 net.cpp:137] Memory required for data: 407553200
I1006 15:09:05.835047  2964 layer_factory.hpp:77] Creating layer Scale12
I1006 15:09:05.835050  2964 net.cpp:84] Creating Layer Scale12
I1006 15:09:05.835053  2964 net.cpp:406] Scale12 <- Convolution12
I1006 15:09:05.835057  2964 net.cpp:367] Scale12 -> Convolution12 (in-place)
I1006 15:09:05.855697  2964 layer_factory.hpp:77] Creating layer Scale12
I1006 15:09:05.855835  2964 net.cpp:122] Setting up Scale12
I1006 15:09:05.855844  2964 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 15:09:05.855849  2964 net.cpp:137] Memory required for data: 410830000
I1006 15:09:05.855856  2964 layer_factory.hpp:77] Creating layer Convolution13
I1006 15:09:05.855867  2964 net.cpp:84] Creating Layer Convolution13
I1006 15:09:05.855872  2964 net.cpp:406] Convolution13 <- Eltwise5_penlu11_0_split_1
I1006 15:09:05.855880  2964 net.cpp:380] Convolution13 -> Convolution13
I1006 15:09:05.857398  2964 net.cpp:122] Setting up Convolution13
I1006 15:09:05.857421  2964 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 15:09:05.857425  2964 net.cpp:137] Memory required for data: 414106800
I1006 15:09:05.857432  2964 layer_factory.hpp:77] Creating layer BatchNorm13
I1006 15:09:05.857439  2964 net.cpp:84] Creating Layer BatchNorm13
I1006 15:09:05.857444  2964 net.cpp:406] BatchNorm13 <- Convolution13
I1006 15:09:05.857451  2964 net.cpp:367] BatchNorm13 -> Convolution13 (in-place)
I1006 15:09:05.857658  2964 net.cpp:122] Setting up BatchNorm13
I1006 15:09:05.857668  2964 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 15:09:05.857672  2964 net.cpp:137] Memory required for data: 417383600
I1006 15:09:05.857681  2964 layer_factory.hpp:77] Creating layer Scale13
I1006 15:09:05.857687  2964 net.cpp:84] Creating Layer Scale13
I1006 15:09:05.857692  2964 net.cpp:406] Scale13 <- Convolution13
I1006 15:09:05.857697  2964 net.cpp:367] Scale13 -> Convolution13 (in-place)
I1006 15:09:05.857744  2964 layer_factory.hpp:77] Creating layer Scale13
I1006 15:09:05.857874  2964 net.cpp:122] Setting up Scale13
I1006 15:09:05.857882  2964 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 15:09:05.857885  2964 net.cpp:137] Memory required for data: 420660400
I1006 15:09:05.857892  2964 layer_factory.hpp:77] Creating layer penlu12
I1006 15:09:05.857910  2964 net.cpp:84] Creating Layer penlu12
I1006 15:09:05.857914  2964 net.cpp:406] penlu12 <- Convolution13
I1006 15:09:05.857920  2964 net.cpp:367] penlu12 -> Convolution13 (in-place)
I1006 15:09:05.858144  2964 net.cpp:122] Setting up penlu12
I1006 15:09:05.858155  2964 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 15:09:05.858158  2964 net.cpp:137] Memory required for data: 423937200
I1006 15:09:05.858167  2964 layer_factory.hpp:77] Creating layer Convolution14
I1006 15:09:05.858183  2964 net.cpp:84] Creating Layer Convolution14
I1006 15:09:05.858188  2964 net.cpp:406] Convolution14 <- Convolution13
I1006 15:09:05.858196  2964 net.cpp:380] Convolution14 -> Convolution14
I1006 15:09:05.859592  2964 net.cpp:122] Setting up Convolution14
I1006 15:09:05.859602  2964 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 15:09:05.859604  2964 net.cpp:137] Memory required for data: 427214000
I1006 15:09:05.859621  2964 layer_factory.hpp:77] Creating layer BatchNorm14
I1006 15:09:05.859625  2964 net.cpp:84] Creating Layer BatchNorm14
I1006 15:09:05.859628  2964 net.cpp:406] BatchNorm14 <- Convolution14
I1006 15:09:05.859632  2964 net.cpp:367] BatchNorm14 -> Convolution14 (in-place)
I1006 15:09:05.859777  2964 net.cpp:122] Setting up BatchNorm14
I1006 15:09:05.859782  2964 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 15:09:05.859784  2964 net.cpp:137] Memory required for data: 430490800
I1006 15:09:05.859789  2964 layer_factory.hpp:77] Creating layer Scale14
I1006 15:09:05.859794  2964 net.cpp:84] Creating Layer Scale14
I1006 15:09:05.859803  2964 net.cpp:406] Scale14 <- Convolution14
I1006 15:09:05.859807  2964 net.cpp:367] Scale14 -> Convolution14 (in-place)
I1006 15:09:05.859838  2964 layer_factory.hpp:77] Creating layer Scale14
I1006 15:09:05.859920  2964 net.cpp:122] Setting up Scale14
I1006 15:09:05.859925  2964 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 15:09:05.859926  2964 net.cpp:137] Memory required for data: 433767600
I1006 15:09:05.859930  2964 layer_factory.hpp:77] Creating layer Eltwise6
I1006 15:09:05.859935  2964 net.cpp:84] Creating Layer Eltwise6
I1006 15:09:05.859936  2964 net.cpp:406] Eltwise6 <- Convolution12
I1006 15:09:05.859939  2964 net.cpp:406] Eltwise6 <- Convolution14
I1006 15:09:05.859943  2964 net.cpp:380] Eltwise6 -> Eltwise6
I1006 15:09:05.859957  2964 net.cpp:122] Setting up Eltwise6
I1006 15:09:05.859961  2964 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 15:09:05.859962  2964 net.cpp:137] Memory required for data: 437044400
I1006 15:09:05.859964  2964 layer_factory.hpp:77] Creating layer penlu13
I1006 15:09:05.859969  2964 net.cpp:84] Creating Layer penlu13
I1006 15:09:05.859972  2964 net.cpp:406] penlu13 <- Eltwise6
I1006 15:09:05.859977  2964 net.cpp:367] penlu13 -> Eltwise6 (in-place)
I1006 15:09:05.860110  2964 net.cpp:122] Setting up penlu13
I1006 15:09:05.860116  2964 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 15:09:05.860126  2964 net.cpp:137] Memory required for data: 440321200
I1006 15:09:05.860131  2964 layer_factory.hpp:77] Creating layer Eltwise6_penlu13_0_split
I1006 15:09:05.860136  2964 net.cpp:84] Creating Layer Eltwise6_penlu13_0_split
I1006 15:09:05.860138  2964 net.cpp:406] Eltwise6_penlu13_0_split <- Eltwise6
I1006 15:09:05.860141  2964 net.cpp:380] Eltwise6_penlu13_0_split -> Eltwise6_penlu13_0_split_0
I1006 15:09:05.860146  2964 net.cpp:380] Eltwise6_penlu13_0_split -> Eltwise6_penlu13_0_split_1
I1006 15:09:05.860183  2964 net.cpp:122] Setting up Eltwise6_penlu13_0_split
I1006 15:09:05.860186  2964 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 15:09:05.860189  2964 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 15:09:05.860191  2964 net.cpp:137] Memory required for data: 446874800
I1006 15:09:05.860193  2964 layer_factory.hpp:77] Creating layer Convolution15
I1006 15:09:05.860199  2964 net.cpp:84] Creating Layer Convolution15
I1006 15:09:05.860203  2964 net.cpp:406] Convolution15 <- Eltwise6_penlu13_0_split_0
I1006 15:09:05.860206  2964 net.cpp:380] Convolution15 -> Convolution15
I1006 15:09:05.861681  2964 net.cpp:122] Setting up Convolution15
I1006 15:09:05.861690  2964 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 15:09:05.861693  2964 net.cpp:137] Memory required for data: 450151600
I1006 15:09:05.861697  2964 layer_factory.hpp:77] Creating layer BatchNorm15
I1006 15:09:05.861703  2964 net.cpp:84] Creating Layer BatchNorm15
I1006 15:09:05.861706  2964 net.cpp:406] BatchNorm15 <- Convolution15
I1006 15:09:05.861711  2964 net.cpp:367] BatchNorm15 -> Convolution15 (in-place)
I1006 15:09:05.861856  2964 net.cpp:122] Setting up BatchNorm15
I1006 15:09:05.861861  2964 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 15:09:05.861863  2964 net.cpp:137] Memory required for data: 453428400
I1006 15:09:05.861868  2964 layer_factory.hpp:77] Creating layer Scale15
I1006 15:09:05.861872  2964 net.cpp:84] Creating Layer Scale15
I1006 15:09:05.861874  2964 net.cpp:406] Scale15 <- Convolution15
I1006 15:09:05.861878  2964 net.cpp:367] Scale15 -> Convolution15 (in-place)
I1006 15:09:05.861907  2964 layer_factory.hpp:77] Creating layer Scale15
I1006 15:09:05.861991  2964 net.cpp:122] Setting up Scale15
I1006 15:09:05.861995  2964 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 15:09:05.861997  2964 net.cpp:137] Memory required for data: 456705200
I1006 15:09:05.862001  2964 layer_factory.hpp:77] Creating layer penlu14
I1006 15:09:05.862007  2964 net.cpp:84] Creating Layer penlu14
I1006 15:09:05.862010  2964 net.cpp:406] penlu14 <- Convolution15
I1006 15:09:05.862012  2964 net.cpp:367] penlu14 -> Convolution15 (in-place)
I1006 15:09:05.862139  2964 net.cpp:122] Setting up penlu14
I1006 15:09:05.862143  2964 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 15:09:05.862145  2964 net.cpp:137] Memory required for data: 459982000
I1006 15:09:05.862150  2964 layer_factory.hpp:77] Creating layer Convolution16
I1006 15:09:05.862157  2964 net.cpp:84] Creating Layer Convolution16
I1006 15:09:05.862159  2964 net.cpp:406] Convolution16 <- Convolution15
I1006 15:09:05.862164  2964 net.cpp:380] Convolution16 -> Convolution16
I1006 15:09:05.863796  2964 net.cpp:122] Setting up Convolution16
I1006 15:09:05.863806  2964 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 15:09:05.863808  2964 net.cpp:137] Memory required for data: 463258800
I1006 15:09:05.863813  2964 layer_factory.hpp:77] Creating layer BatchNorm16
I1006 15:09:05.863818  2964 net.cpp:84] Creating Layer BatchNorm16
I1006 15:09:05.863821  2964 net.cpp:406] BatchNorm16 <- Convolution16
I1006 15:09:05.863826  2964 net.cpp:367] BatchNorm16 -> Convolution16 (in-place)
I1006 15:09:05.863970  2964 net.cpp:122] Setting up BatchNorm16
I1006 15:09:05.863973  2964 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 15:09:05.863976  2964 net.cpp:137] Memory required for data: 466535600
I1006 15:09:05.863981  2964 layer_factory.hpp:77] Creating layer Scale16
I1006 15:09:05.863986  2964 net.cpp:84] Creating Layer Scale16
I1006 15:09:05.863987  2964 net.cpp:406] Scale16 <- Convolution16
I1006 15:09:05.863991  2964 net.cpp:367] Scale16 -> Convolution16 (in-place)
I1006 15:09:05.864020  2964 layer_factory.hpp:77] Creating layer Scale16
I1006 15:09:05.864104  2964 net.cpp:122] Setting up Scale16
I1006 15:09:05.864109  2964 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 15:09:05.864110  2964 net.cpp:137] Memory required for data: 469812400
I1006 15:09:05.864114  2964 layer_factory.hpp:77] Creating layer Eltwise7
I1006 15:09:05.864118  2964 net.cpp:84] Creating Layer Eltwise7
I1006 15:09:05.864121  2964 net.cpp:406] Eltwise7 <- Eltwise6_penlu13_0_split_1
I1006 15:09:05.864125  2964 net.cpp:406] Eltwise7 <- Convolution16
I1006 15:09:05.864127  2964 net.cpp:380] Eltwise7 -> Eltwise7
I1006 15:09:05.864142  2964 net.cpp:122] Setting up Eltwise7
I1006 15:09:05.864146  2964 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 15:09:05.864148  2964 net.cpp:137] Memory required for data: 473089200
I1006 15:09:05.864151  2964 layer_factory.hpp:77] Creating layer penlu15
I1006 15:09:05.864156  2964 net.cpp:84] Creating Layer penlu15
I1006 15:09:05.864158  2964 net.cpp:406] penlu15 <- Eltwise7
I1006 15:09:05.864161  2964 net.cpp:367] penlu15 -> Eltwise7 (in-place)
I1006 15:09:05.864279  2964 net.cpp:122] Setting up penlu15
I1006 15:09:05.864284  2964 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 15:09:05.864286  2964 net.cpp:137] Memory required for data: 476366000
I1006 15:09:05.864290  2964 layer_factory.hpp:77] Creating layer Eltwise7_penlu15_0_split
I1006 15:09:05.864295  2964 net.cpp:84] Creating Layer Eltwise7_penlu15_0_split
I1006 15:09:05.864296  2964 net.cpp:406] Eltwise7_penlu15_0_split <- Eltwise7
I1006 15:09:05.864300  2964 net.cpp:380] Eltwise7_penlu15_0_split -> Eltwise7_penlu15_0_split_0
I1006 15:09:05.864305  2964 net.cpp:380] Eltwise7_penlu15_0_split -> Eltwise7_penlu15_0_split_1
I1006 15:09:05.864328  2964 net.cpp:122] Setting up Eltwise7_penlu15_0_split
I1006 15:09:05.864333  2964 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 15:09:05.864336  2964 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 15:09:05.864338  2964 net.cpp:137] Memory required for data: 482919600
I1006 15:09:05.864341  2964 layer_factory.hpp:77] Creating layer Convolution17
I1006 15:09:05.864346  2964 net.cpp:84] Creating Layer Convolution17
I1006 15:09:05.864348  2964 net.cpp:406] Convolution17 <- Eltwise7_penlu15_0_split_0
I1006 15:09:05.864352  2964 net.cpp:380] Convolution17 -> Convolution17
I1006 15:09:05.865447  2964 net.cpp:122] Setting up Convolution17
I1006 15:09:05.865455  2964 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 15:09:05.865458  2964 net.cpp:137] Memory required for data: 486196400
I1006 15:09:05.865468  2964 layer_factory.hpp:77] Creating layer BatchNorm17
I1006 15:09:05.865475  2964 net.cpp:84] Creating Layer BatchNorm17
I1006 15:09:05.865478  2964 net.cpp:406] BatchNorm17 <- Convolution17
I1006 15:09:05.865483  2964 net.cpp:367] BatchNorm17 -> Convolution17 (in-place)
I1006 15:09:05.865629  2964 net.cpp:122] Setting up BatchNorm17
I1006 15:09:05.865633  2964 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 15:09:05.865636  2964 net.cpp:137] Memory required for data: 489473200
I1006 15:09:05.865641  2964 layer_factory.hpp:77] Creating layer Scale17
I1006 15:09:05.865646  2964 net.cpp:84] Creating Layer Scale17
I1006 15:09:05.865648  2964 net.cpp:406] Scale17 <- Convolution17
I1006 15:09:05.865651  2964 net.cpp:367] Scale17 -> Convolution17 (in-place)
I1006 15:09:05.865681  2964 layer_factory.hpp:77] Creating layer Scale17
I1006 15:09:05.865766  2964 net.cpp:122] Setting up Scale17
I1006 15:09:05.865769  2964 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 15:09:05.865772  2964 net.cpp:137] Memory required for data: 492750000
I1006 15:09:05.865775  2964 layer_factory.hpp:77] Creating layer penlu16
I1006 15:09:05.865780  2964 net.cpp:84] Creating Layer penlu16
I1006 15:09:05.865783  2964 net.cpp:406] penlu16 <- Convolution17
I1006 15:09:05.865787  2964 net.cpp:367] penlu16 -> Convolution17 (in-place)
I1006 15:09:05.865902  2964 net.cpp:122] Setting up penlu16
I1006 15:09:05.865906  2964 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 15:09:05.865908  2964 net.cpp:137] Memory required for data: 496026800
I1006 15:09:05.865912  2964 layer_factory.hpp:77] Creating layer Convolution18
I1006 15:09:05.865919  2964 net.cpp:84] Creating Layer Convolution18
I1006 15:09:05.865922  2964 net.cpp:406] Convolution18 <- Convolution17
I1006 15:09:05.865926  2964 net.cpp:380] Convolution18 -> Convolution18
I1006 15:09:05.867024  2964 net.cpp:122] Setting up Convolution18
I1006 15:09:05.867033  2964 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 15:09:05.867035  2964 net.cpp:137] Memory required for data: 499303600
I1006 15:09:05.867040  2964 layer_factory.hpp:77] Creating layer BatchNorm18
I1006 15:09:05.867045  2964 net.cpp:84] Creating Layer BatchNorm18
I1006 15:09:05.867048  2964 net.cpp:406] BatchNorm18 <- Convolution18
I1006 15:09:05.867053  2964 net.cpp:367] BatchNorm18 -> Convolution18 (in-place)
I1006 15:09:05.867207  2964 net.cpp:122] Setting up BatchNorm18
I1006 15:09:05.867211  2964 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 15:09:05.867213  2964 net.cpp:137] Memory required for data: 502580400
I1006 15:09:05.867218  2964 layer_factory.hpp:77] Creating layer Scale18
I1006 15:09:05.867223  2964 net.cpp:84] Creating Layer Scale18
I1006 15:09:05.867225  2964 net.cpp:406] Scale18 <- Convolution18
I1006 15:09:05.867228  2964 net.cpp:367] Scale18 -> Convolution18 (in-place)
I1006 15:09:05.867259  2964 layer_factory.hpp:77] Creating layer Scale18
I1006 15:09:05.867346  2964 net.cpp:122] Setting up Scale18
I1006 15:09:05.867349  2964 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 15:09:05.867352  2964 net.cpp:137] Memory required for data: 505857200
I1006 15:09:05.867355  2964 layer_factory.hpp:77] Creating layer Eltwise8
I1006 15:09:05.867358  2964 net.cpp:84] Creating Layer Eltwise8
I1006 15:09:05.867362  2964 net.cpp:406] Eltwise8 <- Eltwise7_penlu15_0_split_1
I1006 15:09:05.867364  2964 net.cpp:406] Eltwise8 <- Convolution18
I1006 15:09:05.867368  2964 net.cpp:380] Eltwise8 -> Eltwise8
I1006 15:09:05.867382  2964 net.cpp:122] Setting up Eltwise8
I1006 15:09:05.867385  2964 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 15:09:05.867388  2964 net.cpp:137] Memory required for data: 509134000
I1006 15:09:05.867389  2964 layer_factory.hpp:77] Creating layer penlu17
I1006 15:09:05.867395  2964 net.cpp:84] Creating Layer penlu17
I1006 15:09:05.867398  2964 net.cpp:406] penlu17 <- Eltwise8
I1006 15:09:05.867401  2964 net.cpp:367] penlu17 -> Eltwise8 (in-place)
I1006 15:09:05.867523  2964 net.cpp:122] Setting up penlu17
I1006 15:09:05.867527  2964 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 15:09:05.867537  2964 net.cpp:137] Memory required for data: 512410800
I1006 15:09:05.867542  2964 layer_factory.hpp:77] Creating layer Eltwise8_penlu17_0_split
I1006 15:09:05.867545  2964 net.cpp:84] Creating Layer Eltwise8_penlu17_0_split
I1006 15:09:05.867547  2964 net.cpp:406] Eltwise8_penlu17_0_split <- Eltwise8
I1006 15:09:05.867552  2964 net.cpp:380] Eltwise8_penlu17_0_split -> Eltwise8_penlu17_0_split_0
I1006 15:09:05.886263  2964 net.cpp:380] Eltwise8_penlu17_0_split -> Eltwise8_penlu17_0_split_1
I1006 15:09:05.886320  2964 net.cpp:122] Setting up Eltwise8_penlu17_0_split
I1006 15:09:05.886329  2964 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 15:09:05.886334  2964 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 15:09:05.886338  2964 net.cpp:137] Memory required for data: 518964400
I1006 15:09:05.886343  2964 layer_factory.hpp:77] Creating layer Convolution19
I1006 15:09:05.886353  2964 net.cpp:84] Creating Layer Convolution19
I1006 15:09:05.886358  2964 net.cpp:406] Convolution19 <- Eltwise8_penlu17_0_split_0
I1006 15:09:05.886366  2964 net.cpp:380] Convolution19 -> Convolution19
I1006 15:09:05.888054  2964 net.cpp:122] Setting up Convolution19
I1006 15:09:05.888067  2964 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 15:09:05.888072  2964 net.cpp:137] Memory required for data: 522241200
I1006 15:09:05.888078  2964 layer_factory.hpp:77] Creating layer BatchNorm19
I1006 15:09:05.888087  2964 net.cpp:84] Creating Layer BatchNorm19
I1006 15:09:05.888092  2964 net.cpp:406] BatchNorm19 <- Convolution19
I1006 15:09:05.888099  2964 net.cpp:367] BatchNorm19 -> Convolution19 (in-place)
I1006 15:09:05.888314  2964 net.cpp:122] Setting up BatchNorm19
I1006 15:09:05.888324  2964 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 15:09:05.888327  2964 net.cpp:137] Memory required for data: 525518000
I1006 15:09:05.888335  2964 layer_factory.hpp:77] Creating layer Scale19
I1006 15:09:05.888342  2964 net.cpp:84] Creating Layer Scale19
I1006 15:09:05.888346  2964 net.cpp:406] Scale19 <- Convolution19
I1006 15:09:05.888355  2964 net.cpp:367] Scale19 -> Convolution19 (in-place)
I1006 15:09:05.888411  2964 layer_factory.hpp:77] Creating layer Scale19
I1006 15:09:05.888548  2964 net.cpp:122] Setting up Scale19
I1006 15:09:05.888558  2964 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 15:09:05.888562  2964 net.cpp:137] Memory required for data: 528794800
I1006 15:09:05.888569  2964 layer_factory.hpp:77] Creating layer penlu18
I1006 15:09:05.888576  2964 net.cpp:84] Creating Layer penlu18
I1006 15:09:05.888581  2964 net.cpp:406] penlu18 <- Convolution19
I1006 15:09:05.888589  2964 net.cpp:367] penlu18 -> Convolution19 (in-place)
I1006 15:09:05.888801  2964 net.cpp:122] Setting up penlu18
I1006 15:09:05.888811  2964 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 15:09:05.888816  2964 net.cpp:137] Memory required for data: 532071600
I1006 15:09:05.888824  2964 layer_factory.hpp:77] Creating layer Convolution20
I1006 15:09:05.888845  2964 net.cpp:84] Creating Layer Convolution20
I1006 15:09:05.888851  2964 net.cpp:406] Convolution20 <- Convolution19
I1006 15:09:05.888859  2964 net.cpp:380] Convolution20 -> Convolution20
I1006 15:09:05.889726  2964 net.cpp:122] Setting up Convolution20
I1006 15:09:05.889735  2964 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 15:09:05.889737  2964 net.cpp:137] Memory required for data: 535348400
I1006 15:09:05.889742  2964 layer_factory.hpp:77] Creating layer BatchNorm20
I1006 15:09:05.889747  2964 net.cpp:84] Creating Layer BatchNorm20
I1006 15:09:05.889750  2964 net.cpp:406] BatchNorm20 <- Convolution20
I1006 15:09:05.889755  2964 net.cpp:367] BatchNorm20 -> Convolution20 (in-place)
I1006 15:09:05.889902  2964 net.cpp:122] Setting up BatchNorm20
I1006 15:09:05.889907  2964 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 15:09:05.889909  2964 net.cpp:137] Memory required for data: 538625200
I1006 15:09:05.889914  2964 layer_factory.hpp:77] Creating layer Scale20
I1006 15:09:05.889917  2964 net.cpp:84] Creating Layer Scale20
I1006 15:09:05.889920  2964 net.cpp:406] Scale20 <- Convolution20
I1006 15:09:05.889930  2964 net.cpp:367] Scale20 -> Convolution20 (in-place)
I1006 15:09:05.889962  2964 layer_factory.hpp:77] Creating layer Scale20
I1006 15:09:05.890046  2964 net.cpp:122] Setting up Scale20
I1006 15:09:05.890051  2964 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 15:09:05.890053  2964 net.cpp:137] Memory required for data: 541902000
I1006 15:09:05.890058  2964 layer_factory.hpp:77] Creating layer Eltwise9
I1006 15:09:05.890061  2964 net.cpp:84] Creating Layer Eltwise9
I1006 15:09:05.890064  2964 net.cpp:406] Eltwise9 <- Eltwise8_penlu17_0_split_1
I1006 15:09:05.890067  2964 net.cpp:406] Eltwise9 <- Convolution20
I1006 15:09:05.890070  2964 net.cpp:380] Eltwise9 -> Eltwise9
I1006 15:09:05.890084  2964 net.cpp:122] Setting up Eltwise9
I1006 15:09:05.890087  2964 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 15:09:05.890089  2964 net.cpp:137] Memory required for data: 545178800
I1006 15:09:05.890091  2964 layer_factory.hpp:77] Creating layer penlu19
I1006 15:09:05.890097  2964 net.cpp:84] Creating Layer penlu19
I1006 15:09:05.890100  2964 net.cpp:406] penlu19 <- Eltwise9
I1006 15:09:05.890103  2964 net.cpp:367] penlu19 -> Eltwise9 (in-place)
I1006 15:09:05.890259  2964 net.cpp:122] Setting up penlu19
I1006 15:09:05.890264  2964 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 15:09:05.890266  2964 net.cpp:137] Memory required for data: 548455600
I1006 15:09:05.890270  2964 layer_factory.hpp:77] Creating layer Eltwise9_penlu19_0_split
I1006 15:09:05.890274  2964 net.cpp:84] Creating Layer Eltwise9_penlu19_0_split
I1006 15:09:05.890276  2964 net.cpp:406] Eltwise9_penlu19_0_split <- Eltwise9
I1006 15:09:05.890290  2964 net.cpp:380] Eltwise9_penlu19_0_split -> Eltwise9_penlu19_0_split_0
I1006 15:09:05.890295  2964 net.cpp:380] Eltwise9_penlu19_0_split -> Eltwise9_penlu19_0_split_1
I1006 15:09:05.890319  2964 net.cpp:122] Setting up Eltwise9_penlu19_0_split
I1006 15:09:05.890322  2964 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 15:09:05.890326  2964 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 15:09:05.890327  2964 net.cpp:137] Memory required for data: 555009200
I1006 15:09:05.890329  2964 layer_factory.hpp:77] Creating layer Convolution21
I1006 15:09:05.890337  2964 net.cpp:84] Creating Layer Convolution21
I1006 15:09:05.890339  2964 net.cpp:406] Convolution21 <- Eltwise9_penlu19_0_split_0
I1006 15:09:05.890343  2964 net.cpp:380] Convolution21 -> Convolution21
I1006 15:09:05.891518  2964 net.cpp:122] Setting up Convolution21
I1006 15:09:05.891528  2964 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 15:09:05.891530  2964 net.cpp:137] Memory required for data: 558286000
I1006 15:09:05.891535  2964 layer_factory.hpp:77] Creating layer BatchNorm21
I1006 15:09:05.891541  2964 net.cpp:84] Creating Layer BatchNorm21
I1006 15:09:05.891543  2964 net.cpp:406] BatchNorm21 <- Convolution21
I1006 15:09:05.891547  2964 net.cpp:367] BatchNorm21 -> Convolution21 (in-place)
I1006 15:09:05.891693  2964 net.cpp:122] Setting up BatchNorm21
I1006 15:09:05.891698  2964 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 15:09:05.891700  2964 net.cpp:137] Memory required for data: 561562800
I1006 15:09:05.891705  2964 layer_factory.hpp:77] Creating layer Scale21
I1006 15:09:05.891710  2964 net.cpp:84] Creating Layer Scale21
I1006 15:09:05.891711  2964 net.cpp:406] Scale21 <- Convolution21
I1006 15:09:05.891716  2964 net.cpp:367] Scale21 -> Convolution21 (in-place)
I1006 15:09:05.891746  2964 layer_factory.hpp:77] Creating layer Scale21
I1006 15:09:05.891829  2964 net.cpp:122] Setting up Scale21
I1006 15:09:05.891834  2964 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 15:09:05.891835  2964 net.cpp:137] Memory required for data: 564839600
I1006 15:09:05.891839  2964 layer_factory.hpp:77] Creating layer penlu20
I1006 15:09:05.891844  2964 net.cpp:84] Creating Layer penlu20
I1006 15:09:05.891847  2964 net.cpp:406] penlu20 <- Convolution21
I1006 15:09:05.891851  2964 net.cpp:367] penlu20 -> Convolution21 (in-place)
I1006 15:09:05.891968  2964 net.cpp:122] Setting up penlu20
I1006 15:09:05.891979  2964 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 15:09:05.891981  2964 net.cpp:137] Memory required for data: 568116400
I1006 15:09:05.891986  2964 layer_factory.hpp:77] Creating layer Convolution22
I1006 15:09:05.891993  2964 net.cpp:84] Creating Layer Convolution22
I1006 15:09:05.891995  2964 net.cpp:406] Convolution22 <- Convolution21
I1006 15:09:05.892000  2964 net.cpp:380] Convolution22 -> Convolution22
I1006 15:09:05.893105  2964 net.cpp:122] Setting up Convolution22
I1006 15:09:05.893115  2964 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 15:09:05.893116  2964 net.cpp:137] Memory required for data: 571393200
I1006 15:09:05.893121  2964 layer_factory.hpp:77] Creating layer BatchNorm22
I1006 15:09:05.893126  2964 net.cpp:84] Creating Layer BatchNorm22
I1006 15:09:05.893129  2964 net.cpp:406] BatchNorm22 <- Convolution22
I1006 15:09:05.893132  2964 net.cpp:367] BatchNorm22 -> Convolution22 (in-place)
I1006 15:09:05.893280  2964 net.cpp:122] Setting up BatchNorm22
I1006 15:09:05.893285  2964 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 15:09:05.893286  2964 net.cpp:137] Memory required for data: 574670000
I1006 15:09:05.893291  2964 layer_factory.hpp:77] Creating layer Scale22
I1006 15:09:05.893296  2964 net.cpp:84] Creating Layer Scale22
I1006 15:09:05.893298  2964 net.cpp:406] Scale22 <- Convolution22
I1006 15:09:05.893301  2964 net.cpp:367] Scale22 -> Convolution22 (in-place)
I1006 15:09:05.893332  2964 layer_factory.hpp:77] Creating layer Scale22
I1006 15:09:05.893416  2964 net.cpp:122] Setting up Scale22
I1006 15:09:05.893420  2964 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 15:09:05.893422  2964 net.cpp:137] Memory required for data: 577946800
I1006 15:09:05.893426  2964 layer_factory.hpp:77] Creating layer Eltwise10
I1006 15:09:05.893431  2964 net.cpp:84] Creating Layer Eltwise10
I1006 15:09:05.893434  2964 net.cpp:406] Eltwise10 <- Eltwise9_penlu19_0_split_1
I1006 15:09:05.893436  2964 net.cpp:406] Eltwise10 <- Convolution22
I1006 15:09:05.893440  2964 net.cpp:380] Eltwise10 -> Eltwise10
I1006 15:09:05.893455  2964 net.cpp:122] Setting up Eltwise10
I1006 15:09:05.893458  2964 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 15:09:05.893460  2964 net.cpp:137] Memory required for data: 581223600
I1006 15:09:05.893462  2964 layer_factory.hpp:77] Creating layer penlu21
I1006 15:09:05.893468  2964 net.cpp:84] Creating Layer penlu21
I1006 15:09:05.893471  2964 net.cpp:406] penlu21 <- Eltwise10
I1006 15:09:05.893474  2964 net.cpp:367] penlu21 -> Eltwise10 (in-place)
I1006 15:09:05.893596  2964 net.cpp:122] Setting up penlu21
I1006 15:09:05.893601  2964 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 15:09:05.893604  2964 net.cpp:137] Memory required for data: 584500400
I1006 15:09:05.893607  2964 layer_factory.hpp:77] Creating layer Eltwise10_penlu21_0_split
I1006 15:09:05.893610  2964 net.cpp:84] Creating Layer Eltwise10_penlu21_0_split
I1006 15:09:05.893613  2964 net.cpp:406] Eltwise10_penlu21_0_split <- Eltwise10
I1006 15:09:05.893616  2964 net.cpp:380] Eltwise10_penlu21_0_split -> Eltwise10_penlu21_0_split_0
I1006 15:09:05.893620  2964 net.cpp:380] Eltwise10_penlu21_0_split -> Eltwise10_penlu21_0_split_1
I1006 15:09:05.893646  2964 net.cpp:122] Setting up Eltwise10_penlu21_0_split
I1006 15:09:05.893649  2964 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 15:09:05.893652  2964 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 15:09:05.893654  2964 net.cpp:137] Memory required for data: 591054000
I1006 15:09:05.893656  2964 layer_factory.hpp:77] Creating layer Convolution23
I1006 15:09:05.893662  2964 net.cpp:84] Creating Layer Convolution23
I1006 15:09:05.893666  2964 net.cpp:406] Convolution23 <- Eltwise10_penlu21_0_split_0
I1006 15:09:05.893669  2964 net.cpp:380] Convolution23 -> Convolution23
I1006 15:09:05.894637  2964 net.cpp:122] Setting up Convolution23
I1006 15:09:05.894646  2964 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 15:09:05.894649  2964 net.cpp:137] Memory required for data: 592692400
I1006 15:09:05.894654  2964 layer_factory.hpp:77] Creating layer BatchNorm23
I1006 15:09:05.894665  2964 net.cpp:84] Creating Layer BatchNorm23
I1006 15:09:05.894668  2964 net.cpp:406] BatchNorm23 <- Convolution23
I1006 15:09:05.894673  2964 net.cpp:367] BatchNorm23 -> Convolution23 (in-place)
I1006 15:09:05.894824  2964 net.cpp:122] Setting up BatchNorm23
I1006 15:09:05.894829  2964 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 15:09:05.894830  2964 net.cpp:137] Memory required for data: 594330800
I1006 15:09:05.894835  2964 layer_factory.hpp:77] Creating layer Scale23
I1006 15:09:05.894840  2964 net.cpp:84] Creating Layer Scale23
I1006 15:09:05.894842  2964 net.cpp:406] Scale23 <- Convolution23
I1006 15:09:05.894845  2964 net.cpp:367] Scale23 -> Convolution23 (in-place)
I1006 15:09:05.894876  2964 layer_factory.hpp:77] Creating layer Scale23
I1006 15:09:05.894963  2964 net.cpp:122] Setting up Scale23
I1006 15:09:05.894966  2964 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 15:09:05.894968  2964 net.cpp:137] Memory required for data: 595969200
I1006 15:09:05.894973  2964 layer_factory.hpp:77] Creating layer Convolution24
I1006 15:09:05.894979  2964 net.cpp:84] Creating Layer Convolution24
I1006 15:09:05.894982  2964 net.cpp:406] Convolution24 <- Eltwise10_penlu21_0_split_1
I1006 15:09:05.894986  2964 net.cpp:380] Convolution24 -> Convolution24
I1006 15:09:05.896317  2964 net.cpp:122] Setting up Convolution24
I1006 15:09:05.896327  2964 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 15:09:05.896329  2964 net.cpp:137] Memory required for data: 597607600
I1006 15:09:05.896333  2964 layer_factory.hpp:77] Creating layer BatchNorm24
I1006 15:09:05.896338  2964 net.cpp:84] Creating Layer BatchNorm24
I1006 15:09:05.896342  2964 net.cpp:406] BatchNorm24 <- Convolution24
I1006 15:09:05.896345  2964 net.cpp:367] BatchNorm24 -> Convolution24 (in-place)
I1006 15:09:05.896498  2964 net.cpp:122] Setting up BatchNorm24
I1006 15:09:05.896503  2964 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 15:09:05.896505  2964 net.cpp:137] Memory required for data: 599246000
I1006 15:09:05.896509  2964 layer_factory.hpp:77] Creating layer Scale24
I1006 15:09:05.896514  2964 net.cpp:84] Creating Layer Scale24
I1006 15:09:05.896517  2964 net.cpp:406] Scale24 <- Convolution24
I1006 15:09:05.896520  2964 net.cpp:367] Scale24 -> Convolution24 (in-place)
I1006 15:09:05.896550  2964 layer_factory.hpp:77] Creating layer Scale24
I1006 15:09:05.896637  2964 net.cpp:122] Setting up Scale24
I1006 15:09:05.896641  2964 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 15:09:05.896643  2964 net.cpp:137] Memory required for data: 600884400
I1006 15:09:05.896647  2964 layer_factory.hpp:77] Creating layer penlu22
I1006 15:09:05.896652  2964 net.cpp:84] Creating Layer penlu22
I1006 15:09:05.896654  2964 net.cpp:406] penlu22 <- Convolution24
I1006 15:09:05.896658  2964 net.cpp:367] penlu22 -> Convolution24 (in-place)
I1006 15:09:05.896777  2964 net.cpp:122] Setting up penlu22
I1006 15:09:05.896781  2964 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 15:09:05.896783  2964 net.cpp:137] Memory required for data: 602522800
I1006 15:09:05.896788  2964 layer_factory.hpp:77] Creating layer Convolution25
I1006 15:09:05.896795  2964 net.cpp:84] Creating Layer Convolution25
I1006 15:09:05.896797  2964 net.cpp:406] Convolution25 <- Convolution24
I1006 15:09:05.896801  2964 net.cpp:380] Convolution25 -> Convolution25
I1006 15:09:05.898526  2964 net.cpp:122] Setting up Convolution25
I1006 15:09:05.898535  2964 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 15:09:05.898537  2964 net.cpp:137] Memory required for data: 604161200
I1006 15:09:05.898541  2964 layer_factory.hpp:77] Creating layer BatchNorm25
I1006 15:09:05.898546  2964 net.cpp:84] Creating Layer BatchNorm25
I1006 15:09:05.898550  2964 net.cpp:406] BatchNorm25 <- Convolution25
I1006 15:09:05.898555  2964 net.cpp:367] BatchNorm25 -> Convolution25 (in-place)
I1006 15:09:05.898705  2964 net.cpp:122] Setting up BatchNorm25
I1006 15:09:05.898708  2964 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 15:09:05.898710  2964 net.cpp:137] Memory required for data: 605799600
I1006 15:09:05.898722  2964 layer_factory.hpp:77] Creating layer Scale25
I1006 15:09:05.898728  2964 net.cpp:84] Creating Layer Scale25
I1006 15:09:05.898731  2964 net.cpp:406] Scale25 <- Convolution25
I1006 15:09:05.898735  2964 net.cpp:367] Scale25 -> Convolution25 (in-place)
I1006 15:09:05.917361  2964 layer_factory.hpp:77] Creating layer Scale25
I1006 15:09:05.917502  2964 net.cpp:122] Setting up Scale25
I1006 15:09:05.917511  2964 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 15:09:05.917515  2964 net.cpp:137] Memory required for data: 607438000
I1006 15:09:05.917523  2964 layer_factory.hpp:77] Creating layer Eltwise11
I1006 15:09:05.917531  2964 net.cpp:84] Creating Layer Eltwise11
I1006 15:09:05.917536  2964 net.cpp:406] Eltwise11 <- Convolution23
I1006 15:09:05.917541  2964 net.cpp:406] Eltwise11 <- Convolution25
I1006 15:09:05.917548  2964 net.cpp:380] Eltwise11 -> Eltwise11
I1006 15:09:05.917577  2964 net.cpp:122] Setting up Eltwise11
I1006 15:09:05.917583  2964 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 15:09:05.917587  2964 net.cpp:137] Memory required for data: 609076400
I1006 15:09:05.917592  2964 layer_factory.hpp:77] Creating layer penlu23
I1006 15:09:05.917600  2964 net.cpp:84] Creating Layer penlu23
I1006 15:09:05.917605  2964 net.cpp:406] penlu23 <- Eltwise11
I1006 15:09:05.917611  2964 net.cpp:367] penlu23 -> Eltwise11 (in-place)
I1006 15:09:05.917801  2964 net.cpp:122] Setting up penlu23
I1006 15:09:05.917809  2964 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 15:09:05.917814  2964 net.cpp:137] Memory required for data: 610714800
I1006 15:09:05.917822  2964 layer_factory.hpp:77] Creating layer Eltwise11_penlu23_0_split
I1006 15:09:05.917829  2964 net.cpp:84] Creating Layer Eltwise11_penlu23_0_split
I1006 15:09:05.917834  2964 net.cpp:406] Eltwise11_penlu23_0_split <- Eltwise11
I1006 15:09:05.917840  2964 net.cpp:380] Eltwise11_penlu23_0_split -> Eltwise11_penlu23_0_split_0
I1006 15:09:05.917847  2964 net.cpp:380] Eltwise11_penlu23_0_split -> Eltwise11_penlu23_0_split_1
I1006 15:09:05.917888  2964 net.cpp:122] Setting up Eltwise11_penlu23_0_split
I1006 15:09:05.917896  2964 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 15:09:05.917901  2964 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 15:09:05.917906  2964 net.cpp:137] Memory required for data: 613991600
I1006 15:09:05.917909  2964 layer_factory.hpp:77] Creating layer Convolution26
I1006 15:09:05.917920  2964 net.cpp:84] Creating Layer Convolution26
I1006 15:09:05.917927  2964 net.cpp:406] Convolution26 <- Eltwise11_penlu23_0_split_0
I1006 15:09:05.917933  2964 net.cpp:380] Convolution26 -> Convolution26
I1006 15:09:05.920502  2964 net.cpp:122] Setting up Convolution26
I1006 15:09:05.920512  2964 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 15:09:05.920514  2964 net.cpp:137] Memory required for data: 615630000
I1006 15:09:05.920519  2964 layer_factory.hpp:77] Creating layer BatchNorm26
I1006 15:09:05.920524  2964 net.cpp:84] Creating Layer BatchNorm26
I1006 15:09:05.920527  2964 net.cpp:406] BatchNorm26 <- Convolution26
I1006 15:09:05.920531  2964 net.cpp:367] BatchNorm26 -> Convolution26 (in-place)
I1006 15:09:05.920678  2964 net.cpp:122] Setting up BatchNorm26
I1006 15:09:05.920683  2964 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 15:09:05.920686  2964 net.cpp:137] Memory required for data: 617268400
I1006 15:09:05.920689  2964 layer_factory.hpp:77] Creating layer Scale26
I1006 15:09:05.920693  2964 net.cpp:84] Creating Layer Scale26
I1006 15:09:05.920696  2964 net.cpp:406] Scale26 <- Convolution26
I1006 15:09:05.920699  2964 net.cpp:367] Scale26 -> Convolution26 (in-place)
I1006 15:09:05.920730  2964 layer_factory.hpp:77] Creating layer Scale26
I1006 15:09:05.920814  2964 net.cpp:122] Setting up Scale26
I1006 15:09:05.920819  2964 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 15:09:05.920820  2964 net.cpp:137] Memory required for data: 618906800
I1006 15:09:05.920825  2964 layer_factory.hpp:77] Creating layer penlu24
I1006 15:09:05.920830  2964 net.cpp:84] Creating Layer penlu24
I1006 15:09:05.920838  2964 net.cpp:406] penlu24 <- Convolution26
I1006 15:09:05.920843  2964 net.cpp:367] penlu24 -> Convolution26 (in-place)
I1006 15:09:05.920964  2964 net.cpp:122] Setting up penlu24
I1006 15:09:05.920969  2964 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 15:09:05.920971  2964 net.cpp:137] Memory required for data: 620545200
I1006 15:09:05.920975  2964 layer_factory.hpp:77] Creating layer Convolution27
I1006 15:09:05.920982  2964 net.cpp:84] Creating Layer Convolution27
I1006 15:09:05.920985  2964 net.cpp:406] Convolution27 <- Convolution26
I1006 15:09:05.920989  2964 net.cpp:380] Convolution27 -> Convolution27
I1006 15:09:05.922854  2964 net.cpp:122] Setting up Convolution27
I1006 15:09:05.922863  2964 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 15:09:05.922865  2964 net.cpp:137] Memory required for data: 622183600
I1006 15:09:05.922870  2964 layer_factory.hpp:77] Creating layer BatchNorm27
I1006 15:09:05.922886  2964 net.cpp:84] Creating Layer BatchNorm27
I1006 15:09:05.922889  2964 net.cpp:406] BatchNorm27 <- Convolution27
I1006 15:09:05.922894  2964 net.cpp:367] BatchNorm27 -> Convolution27 (in-place)
I1006 15:09:05.923046  2964 net.cpp:122] Setting up BatchNorm27
I1006 15:09:05.923051  2964 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 15:09:05.923053  2964 net.cpp:137] Memory required for data: 623822000
I1006 15:09:05.923077  2964 layer_factory.hpp:77] Creating layer Scale27
I1006 15:09:05.923082  2964 net.cpp:84] Creating Layer Scale27
I1006 15:09:05.923085  2964 net.cpp:406] Scale27 <- Convolution27
I1006 15:09:05.923089  2964 net.cpp:367] Scale27 -> Convolution27 (in-place)
I1006 15:09:05.923121  2964 layer_factory.hpp:77] Creating layer Scale27
I1006 15:09:05.923239  2964 net.cpp:122] Setting up Scale27
I1006 15:09:05.923245  2964 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 15:09:05.923247  2964 net.cpp:137] Memory required for data: 625460400
I1006 15:09:05.923251  2964 layer_factory.hpp:77] Creating layer Eltwise12
I1006 15:09:05.923255  2964 net.cpp:84] Creating Layer Eltwise12
I1006 15:09:05.923259  2964 net.cpp:406] Eltwise12 <- Eltwise11_penlu23_0_split_1
I1006 15:09:05.923261  2964 net.cpp:406] Eltwise12 <- Convolution27
I1006 15:09:05.923264  2964 net.cpp:380] Eltwise12 -> Eltwise12
I1006 15:09:05.923283  2964 net.cpp:122] Setting up Eltwise12
I1006 15:09:05.923287  2964 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 15:09:05.923290  2964 net.cpp:137] Memory required for data: 627098800
I1006 15:09:05.923291  2964 layer_factory.hpp:77] Creating layer penlu25
I1006 15:09:05.923296  2964 net.cpp:84] Creating Layer penlu25
I1006 15:09:05.923300  2964 net.cpp:406] penlu25 <- Eltwise12
I1006 15:09:05.923302  2964 net.cpp:367] penlu25 -> Eltwise12 (in-place)
I1006 15:09:05.923426  2964 net.cpp:122] Setting up penlu25
I1006 15:09:05.923430  2964 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 15:09:05.923432  2964 net.cpp:137] Memory required for data: 628737200
I1006 15:09:05.923436  2964 layer_factory.hpp:77] Creating layer Eltwise12_penlu25_0_split
I1006 15:09:05.923440  2964 net.cpp:84] Creating Layer Eltwise12_penlu25_0_split
I1006 15:09:05.923442  2964 net.cpp:406] Eltwise12_penlu25_0_split <- Eltwise12
I1006 15:09:05.923446  2964 net.cpp:380] Eltwise12_penlu25_0_split -> Eltwise12_penlu25_0_split_0
I1006 15:09:05.923450  2964 net.cpp:380] Eltwise12_penlu25_0_split -> Eltwise12_penlu25_0_split_1
I1006 15:09:05.923476  2964 net.cpp:122] Setting up Eltwise12_penlu25_0_split
I1006 15:09:05.923480  2964 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 15:09:05.923483  2964 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 15:09:05.923485  2964 net.cpp:137] Memory required for data: 632014000
I1006 15:09:05.923487  2964 layer_factory.hpp:77] Creating layer Convolution28
I1006 15:09:05.923492  2964 net.cpp:84] Creating Layer Convolution28
I1006 15:09:05.923496  2964 net.cpp:406] Convolution28 <- Eltwise12_penlu25_0_split_0
I1006 15:09:05.923501  2964 net.cpp:380] Convolution28 -> Convolution28
I1006 15:09:05.925547  2964 net.cpp:122] Setting up Convolution28
I1006 15:09:05.925562  2964 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 15:09:05.925566  2964 net.cpp:137] Memory required for data: 633652400
I1006 15:09:05.925570  2964 layer_factory.hpp:77] Creating layer BatchNorm28
I1006 15:09:05.925577  2964 net.cpp:84] Creating Layer BatchNorm28
I1006 15:09:05.925580  2964 net.cpp:406] BatchNorm28 <- Convolution28
I1006 15:09:05.925585  2964 net.cpp:367] BatchNorm28 -> Convolution28 (in-place)
I1006 15:09:05.925740  2964 net.cpp:122] Setting up BatchNorm28
I1006 15:09:05.925745  2964 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 15:09:05.925746  2964 net.cpp:137] Memory required for data: 635290800
I1006 15:09:05.925751  2964 layer_factory.hpp:77] Creating layer Scale28
I1006 15:09:05.925756  2964 net.cpp:84] Creating Layer Scale28
I1006 15:09:05.925758  2964 net.cpp:406] Scale28 <- Convolution28
I1006 15:09:05.925761  2964 net.cpp:367] Scale28 -> Convolution28 (in-place)
I1006 15:09:05.925792  2964 layer_factory.hpp:77] Creating layer Scale28
I1006 15:09:05.925880  2964 net.cpp:122] Setting up Scale28
I1006 15:09:05.925885  2964 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 15:09:05.925887  2964 net.cpp:137] Memory required for data: 636929200
I1006 15:09:05.925890  2964 layer_factory.hpp:77] Creating layer penlu26
I1006 15:09:05.925896  2964 net.cpp:84] Creating Layer penlu26
I1006 15:09:05.925899  2964 net.cpp:406] penlu26 <- Convolution28
I1006 15:09:05.925902  2964 net.cpp:367] penlu26 -> Convolution28 (in-place)
I1006 15:09:05.926025  2964 net.cpp:122] Setting up penlu26
I1006 15:09:05.926030  2964 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 15:09:05.926033  2964 net.cpp:137] Memory required for data: 638567600
I1006 15:09:05.926036  2964 layer_factory.hpp:77] Creating layer Convolution29
I1006 15:09:05.926043  2964 net.cpp:84] Creating Layer Convolution29
I1006 15:09:05.926046  2964 net.cpp:406] Convolution29 <- Convolution28
I1006 15:09:05.926049  2964 net.cpp:380] Convolution29 -> Convolution29
I1006 15:09:05.928351  2964 net.cpp:122] Setting up Convolution29
I1006 15:09:05.928360  2964 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 15:09:05.928364  2964 net.cpp:137] Memory required for data: 640206000
I1006 15:09:05.928367  2964 layer_factory.hpp:77] Creating layer BatchNorm29
I1006 15:09:05.928373  2964 net.cpp:84] Creating Layer BatchNorm29
I1006 15:09:05.928376  2964 net.cpp:406] BatchNorm29 <- Convolution29
I1006 15:09:05.928380  2964 net.cpp:367] BatchNorm29 -> Convolution29 (in-place)
I1006 15:09:05.928536  2964 net.cpp:122] Setting up BatchNorm29
I1006 15:09:05.928541  2964 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 15:09:05.928544  2964 net.cpp:137] Memory required for data: 641844400
I1006 15:09:05.928548  2964 layer_factory.hpp:77] Creating layer Scale29
I1006 15:09:05.928551  2964 net.cpp:84] Creating Layer Scale29
I1006 15:09:05.928555  2964 net.cpp:406] Scale29 <- Convolution29
I1006 15:09:05.928557  2964 net.cpp:367] Scale29 -> Convolution29 (in-place)
I1006 15:09:05.928589  2964 layer_factory.hpp:77] Creating layer Scale29
I1006 15:09:05.928678  2964 net.cpp:122] Setting up Scale29
I1006 15:09:05.928683  2964 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 15:09:05.928685  2964 net.cpp:137] Memory required for data: 643482800
I1006 15:09:05.928689  2964 layer_factory.hpp:77] Creating layer Eltwise13
I1006 15:09:05.928692  2964 net.cpp:84] Creating Layer Eltwise13
I1006 15:09:05.928695  2964 net.cpp:406] Eltwise13 <- Eltwise12_penlu25_0_split_1
I1006 15:09:05.928699  2964 net.cpp:406] Eltwise13 <- Convolution29
I1006 15:09:05.928701  2964 net.cpp:380] Eltwise13 -> Eltwise13
I1006 15:09:05.928720  2964 net.cpp:122] Setting up Eltwise13
I1006 15:09:05.928725  2964 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 15:09:05.928726  2964 net.cpp:137] Memory required for data: 645121200
I1006 15:09:05.928728  2964 layer_factory.hpp:77] Creating layer penlu27
I1006 15:09:05.928733  2964 net.cpp:84] Creating Layer penlu27
I1006 15:09:05.928735  2964 net.cpp:406] penlu27 <- Eltwise13
I1006 15:09:05.928740  2964 net.cpp:367] penlu27 -> Eltwise13 (in-place)
I1006 15:09:05.928874  2964 net.cpp:122] Setting up penlu27
I1006 15:09:05.928879  2964 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 15:09:05.928882  2964 net.cpp:137] Memory required for data: 646759600
I1006 15:09:05.928886  2964 layer_factory.hpp:77] Creating layer Eltwise13_penlu27_0_split
I1006 15:09:05.928890  2964 net.cpp:84] Creating Layer Eltwise13_penlu27_0_split
I1006 15:09:05.928894  2964 net.cpp:406] Eltwise13_penlu27_0_split <- Eltwise13
I1006 15:09:05.928896  2964 net.cpp:380] Eltwise13_penlu27_0_split -> Eltwise13_penlu27_0_split_0
I1006 15:09:05.928900  2964 net.cpp:380] Eltwise13_penlu27_0_split -> Eltwise13_penlu27_0_split_1
I1006 15:09:05.928927  2964 net.cpp:122] Setting up Eltwise13_penlu27_0_split
I1006 15:09:05.928931  2964 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 15:09:05.928935  2964 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 15:09:05.928936  2964 net.cpp:137] Memory required for data: 650036400
I1006 15:09:05.928938  2964 layer_factory.hpp:77] Creating layer Convolution30
I1006 15:09:05.928944  2964 net.cpp:84] Creating Layer Convolution30
I1006 15:09:05.928946  2964 net.cpp:406] Convolution30 <- Eltwise13_penlu27_0_split_0
I1006 15:09:05.928951  2964 net.cpp:380] Convolution30 -> Convolution30
I1006 15:09:05.930994  2964 net.cpp:122] Setting up Convolution30
I1006 15:09:05.931002  2964 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 15:09:05.931005  2964 net.cpp:137] Memory required for data: 651674800
I1006 15:09:05.931010  2964 layer_factory.hpp:77] Creating layer BatchNorm30
I1006 15:09:05.931015  2964 net.cpp:84] Creating Layer BatchNorm30
I1006 15:09:05.931017  2964 net.cpp:406] BatchNorm30 <- Convolution30
I1006 15:09:05.931021  2964 net.cpp:367] BatchNorm30 -> Convolution30 (in-place)
I1006 15:09:05.931211  2964 net.cpp:122] Setting up BatchNorm30
I1006 15:09:05.931217  2964 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 15:09:05.931219  2964 net.cpp:137] Memory required for data: 653313200
I1006 15:09:05.931224  2964 layer_factory.hpp:77] Creating layer Scale30
I1006 15:09:05.931229  2964 net.cpp:84] Creating Layer Scale30
I1006 15:09:05.931232  2964 net.cpp:406] Scale30 <- Convolution30
I1006 15:09:05.931236  2964 net.cpp:367] Scale30 -> Convolution30 (in-place)
I1006 15:09:05.931269  2964 layer_factory.hpp:77] Creating layer Scale30
I1006 15:09:05.931361  2964 net.cpp:122] Setting up Scale30
I1006 15:09:05.931365  2964 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 15:09:05.931367  2964 net.cpp:137] Memory required for data: 654951600
I1006 15:09:05.931371  2964 layer_factory.hpp:77] Creating layer penlu28
I1006 15:09:05.931376  2964 net.cpp:84] Creating Layer penlu28
I1006 15:09:05.931380  2964 net.cpp:406] penlu28 <- Convolution30
I1006 15:09:05.931382  2964 net.cpp:367] penlu28 -> Convolution30 (in-place)
I1006 15:09:05.931506  2964 net.cpp:122] Setting up penlu28
I1006 15:09:05.931510  2964 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 15:09:05.931512  2964 net.cpp:137] Memory required for data: 656590000
I1006 15:09:05.931516  2964 layer_factory.hpp:77] Creating layer Convolution31
I1006 15:09:05.931524  2964 net.cpp:84] Creating Layer Convolution31
I1006 15:09:05.931526  2964 net.cpp:406] Convolution31 <- Convolution30
I1006 15:09:05.931530  2964 net.cpp:380] Convolution31 -> Convolution31
I1006 15:09:05.933248  2964 net.cpp:122] Setting up Convolution31
I1006 15:09:05.933257  2964 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 15:09:05.933259  2964 net.cpp:137] Memory required for data: 658228400
I1006 15:09:05.933264  2964 layer_factory.hpp:77] Creating layer BatchNorm31
I1006 15:09:05.933269  2964 net.cpp:84] Creating Layer BatchNorm31
I1006 15:09:05.933272  2964 net.cpp:406] BatchNorm31 <- Convolution31
I1006 15:09:05.933277  2964 net.cpp:367] BatchNorm31 -> Convolution31 (in-place)
I1006 15:09:05.933432  2964 net.cpp:122] Setting up BatchNorm31
I1006 15:09:05.933437  2964 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 15:09:05.933439  2964 net.cpp:137] Memory required for data: 659866800
I1006 15:09:05.933451  2964 layer_factory.hpp:77] Creating layer Scale31
I1006 15:09:05.933456  2964 net.cpp:84] Creating Layer Scale31
I1006 15:09:05.947502  2964 net.cpp:406] Scale31 <- Convolution31
I1006 15:09:05.947515  2964 net.cpp:367] Scale31 -> Convolution31 (in-place)
I1006 15:09:05.947577  2964 layer_factory.hpp:77] Creating layer Scale31
I1006 15:09:05.947721  2964 net.cpp:122] Setting up Scale31
I1006 15:09:05.947728  2964 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 15:09:05.947732  2964 net.cpp:137] Memory required for data: 661505200
I1006 15:09:05.947739  2964 layer_factory.hpp:77] Creating layer Eltwise14
I1006 15:09:05.947747  2964 net.cpp:84] Creating Layer Eltwise14
I1006 15:09:05.947752  2964 net.cpp:406] Eltwise14 <- Eltwise13_penlu27_0_split_1
I1006 15:09:05.947757  2964 net.cpp:406] Eltwise14 <- Convolution31
I1006 15:09:05.947762  2964 net.cpp:380] Eltwise14 -> Eltwise14
I1006 15:09:05.947791  2964 net.cpp:122] Setting up Eltwise14
I1006 15:09:05.947798  2964 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 15:09:05.947803  2964 net.cpp:137] Memory required for data: 663143600
I1006 15:09:05.947808  2964 layer_factory.hpp:77] Creating layer penlu29
I1006 15:09:05.947816  2964 net.cpp:84] Creating Layer penlu29
I1006 15:09:05.947820  2964 net.cpp:406] penlu29 <- Eltwise14
I1006 15:09:05.947826  2964 net.cpp:367] penlu29 -> Eltwise14 (in-place)
I1006 15:09:05.948019  2964 net.cpp:122] Setting up penlu29
I1006 15:09:05.948026  2964 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 15:09:05.948030  2964 net.cpp:137] Memory required for data: 664782000
I1006 15:09:05.948038  2964 layer_factory.hpp:77] Creating layer Eltwise14_penlu29_0_split
I1006 15:09:05.948045  2964 net.cpp:84] Creating Layer Eltwise14_penlu29_0_split
I1006 15:09:05.948050  2964 net.cpp:406] Eltwise14_penlu29_0_split <- Eltwise14
I1006 15:09:05.948055  2964 net.cpp:380] Eltwise14_penlu29_0_split -> Eltwise14_penlu29_0_split_0
I1006 15:09:05.948062  2964 net.cpp:380] Eltwise14_penlu29_0_split -> Eltwise14_penlu29_0_split_1
I1006 15:09:05.948109  2964 net.cpp:122] Setting up Eltwise14_penlu29_0_split
I1006 15:09:05.948119  2964 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 15:09:05.948125  2964 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 15:09:05.948129  2964 net.cpp:137] Memory required for data: 668058800
I1006 15:09:05.948133  2964 layer_factory.hpp:77] Creating layer Convolution32
I1006 15:09:05.948144  2964 net.cpp:84] Creating Layer Convolution32
I1006 15:09:05.948149  2964 net.cpp:406] Convolution32 <- Eltwise14_penlu29_0_split_0
I1006 15:09:05.948158  2964 net.cpp:380] Convolution32 -> Convolution32
I1006 15:09:05.951053  2964 net.cpp:122] Setting up Convolution32
I1006 15:09:05.951063  2964 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 15:09:05.951076  2964 net.cpp:137] Memory required for data: 669697200
I1006 15:09:05.951083  2964 layer_factory.hpp:77] Creating layer BatchNorm32
I1006 15:09:05.951090  2964 net.cpp:84] Creating Layer BatchNorm32
I1006 15:09:05.951093  2964 net.cpp:406] BatchNorm32 <- Convolution32
I1006 15:09:05.951097  2964 net.cpp:367] BatchNorm32 -> Convolution32 (in-place)
I1006 15:09:05.951380  2964 net.cpp:122] Setting up BatchNorm32
I1006 15:09:05.951397  2964 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 15:09:05.951400  2964 net.cpp:137] Memory required for data: 671335600
I1006 15:09:05.951405  2964 layer_factory.hpp:77] Creating layer Scale32
I1006 15:09:05.951409  2964 net.cpp:84] Creating Layer Scale32
I1006 15:09:05.951411  2964 net.cpp:406] Scale32 <- Convolution32
I1006 15:09:05.951416  2964 net.cpp:367] Scale32 -> Convolution32 (in-place)
I1006 15:09:05.951448  2964 layer_factory.hpp:77] Creating layer Scale32
I1006 15:09:05.951536  2964 net.cpp:122] Setting up Scale32
I1006 15:09:05.951541  2964 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 15:09:05.951544  2964 net.cpp:137] Memory required for data: 672974000
I1006 15:09:05.951547  2964 layer_factory.hpp:77] Creating layer penlu30
I1006 15:09:05.951551  2964 net.cpp:84] Creating Layer penlu30
I1006 15:09:05.951555  2964 net.cpp:406] penlu30 <- Convolution32
I1006 15:09:05.951565  2964 net.cpp:367] penlu30 -> Convolution32 (in-place)
I1006 15:09:05.951690  2964 net.cpp:122] Setting up penlu30
I1006 15:09:05.951694  2964 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 15:09:05.951696  2964 net.cpp:137] Memory required for data: 674612400
I1006 15:09:05.951701  2964 layer_factory.hpp:77] Creating layer Convolution33
I1006 15:09:05.951707  2964 net.cpp:84] Creating Layer Convolution33
I1006 15:09:05.951710  2964 net.cpp:406] Convolution33 <- Convolution32
I1006 15:09:05.951715  2964 net.cpp:380] Convolution33 -> Convolution33
I1006 15:09:05.953620  2964 net.cpp:122] Setting up Convolution33
I1006 15:09:05.953629  2964 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 15:09:05.953632  2964 net.cpp:137] Memory required for data: 676250800
I1006 15:09:05.953636  2964 layer_factory.hpp:77] Creating layer BatchNorm33
I1006 15:09:05.953641  2964 net.cpp:84] Creating Layer BatchNorm33
I1006 15:09:05.953644  2964 net.cpp:406] BatchNorm33 <- Convolution33
I1006 15:09:05.953649  2964 net.cpp:367] BatchNorm33 -> Convolution33 (in-place)
I1006 15:09:05.953801  2964 net.cpp:122] Setting up BatchNorm33
I1006 15:09:05.953805  2964 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 15:09:05.953807  2964 net.cpp:137] Memory required for data: 677889200
I1006 15:09:05.953812  2964 layer_factory.hpp:77] Creating layer Scale33
I1006 15:09:05.953816  2964 net.cpp:84] Creating Layer Scale33
I1006 15:09:05.953819  2964 net.cpp:406] Scale33 <- Convolution33
I1006 15:09:05.953821  2964 net.cpp:367] Scale33 -> Convolution33 (in-place)
I1006 15:09:05.953852  2964 layer_factory.hpp:77] Creating layer Scale33
I1006 15:09:05.953940  2964 net.cpp:122] Setting up Scale33
I1006 15:09:05.953945  2964 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 15:09:05.953946  2964 net.cpp:137] Memory required for data: 679527600
I1006 15:09:05.953950  2964 layer_factory.hpp:77] Creating layer Eltwise15
I1006 15:09:05.953955  2964 net.cpp:84] Creating Layer Eltwise15
I1006 15:09:05.953958  2964 net.cpp:406] Eltwise15 <- Eltwise14_penlu29_0_split_1
I1006 15:09:05.953961  2964 net.cpp:406] Eltwise15 <- Convolution33
I1006 15:09:05.953964  2964 net.cpp:380] Eltwise15 -> Eltwise15
I1006 15:09:05.953984  2964 net.cpp:122] Setting up Eltwise15
I1006 15:09:05.953987  2964 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 15:09:05.953989  2964 net.cpp:137] Memory required for data: 681166000
I1006 15:09:05.953991  2964 layer_factory.hpp:77] Creating layer penlu31
I1006 15:09:05.953996  2964 net.cpp:84] Creating Layer penlu31
I1006 15:09:05.953999  2964 net.cpp:406] penlu31 <- Eltwise15
I1006 15:09:05.954002  2964 net.cpp:367] penlu31 -> Eltwise15 (in-place)
I1006 15:09:05.954123  2964 net.cpp:122] Setting up penlu31
I1006 15:09:05.954128  2964 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 15:09:05.954129  2964 net.cpp:137] Memory required for data: 682804400
I1006 15:09:05.954134  2964 layer_factory.hpp:77] Creating layer Pooling1
I1006 15:09:05.954139  2964 net.cpp:84] Creating Layer Pooling1
I1006 15:09:05.954141  2964 net.cpp:406] Pooling1 <- Eltwise15
I1006 15:09:05.954145  2964 net.cpp:380] Pooling1 -> Pooling1
I1006 15:09:05.954285  2964 net.cpp:122] Setting up Pooling1
I1006 15:09:05.954293  2964 net.cpp:129] Top shape: 100 64 1 1 (6400)
I1006 15:09:05.954295  2964 net.cpp:137] Memory required for data: 682830000
I1006 15:09:05.954298  2964 layer_factory.hpp:77] Creating layer InnerProduct1
I1006 15:09:05.954303  2964 net.cpp:84] Creating Layer InnerProduct1
I1006 15:09:05.954305  2964 net.cpp:406] InnerProduct1 <- Pooling1
I1006 15:09:05.954310  2964 net.cpp:380] InnerProduct1 -> InnerProduct1
I1006 15:09:05.954416  2964 net.cpp:122] Setting up InnerProduct1
I1006 15:09:05.954421  2964 net.cpp:129] Top shape: 100 10 (1000)
I1006 15:09:05.954422  2964 net.cpp:137] Memory required for data: 682834000
I1006 15:09:05.954427  2964 layer_factory.hpp:77] Creating layer InnerProduct1_InnerProduct1_0_split
I1006 15:09:05.954432  2964 net.cpp:84] Creating Layer InnerProduct1_InnerProduct1_0_split
I1006 15:09:05.954439  2964 net.cpp:406] InnerProduct1_InnerProduct1_0_split <- InnerProduct1
I1006 15:09:05.954444  2964 net.cpp:380] InnerProduct1_InnerProduct1_0_split -> InnerProduct1_InnerProduct1_0_split_0
I1006 15:09:05.954448  2964 net.cpp:380] InnerProduct1_InnerProduct1_0_split -> InnerProduct1_InnerProduct1_0_split_1
I1006 15:09:05.954478  2964 net.cpp:122] Setting up InnerProduct1_InnerProduct1_0_split
I1006 15:09:05.954483  2964 net.cpp:129] Top shape: 100 10 (1000)
I1006 15:09:05.954484  2964 net.cpp:129] Top shape: 100 10 (1000)
I1006 15:09:05.954486  2964 net.cpp:137] Memory required for data: 682842000
I1006 15:09:05.954488  2964 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I1006 15:09:05.954493  2964 net.cpp:84] Creating Layer SoftmaxWithLoss1
I1006 15:09:05.954494  2964 net.cpp:406] SoftmaxWithLoss1 <- InnerProduct1_InnerProduct1_0_split_0
I1006 15:09:05.954497  2964 net.cpp:406] SoftmaxWithLoss1 <- Data2_Data1_1_split_0
I1006 15:09:05.954501  2964 net.cpp:380] SoftmaxWithLoss1 -> SoftmaxWithLoss1
I1006 15:09:05.954505  2964 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I1006 15:09:05.955024  2964 net.cpp:122] Setting up SoftmaxWithLoss1
I1006 15:09:05.955032  2964 net.cpp:129] Top shape: (1)
I1006 15:09:05.955034  2964 net.cpp:132]     with loss weight 1
I1006 15:09:05.955041  2964 net.cpp:137] Memory required for data: 682842004
I1006 15:09:05.955044  2964 layer_factory.hpp:77] Creating layer Accuracy1
I1006 15:09:05.955049  2964 net.cpp:84] Creating Layer Accuracy1
I1006 15:09:05.955051  2964 net.cpp:406] Accuracy1 <- InnerProduct1_InnerProduct1_0_split_1
I1006 15:09:05.955055  2964 net.cpp:406] Accuracy1 <- Data2_Data1_1_split_1
I1006 15:09:05.955058  2964 net.cpp:380] Accuracy1 -> Accuracy1
I1006 15:09:05.955065  2964 net.cpp:122] Setting up Accuracy1
I1006 15:09:05.955067  2964 net.cpp:129] Top shape: (1)
I1006 15:09:05.955070  2964 net.cpp:137] Memory required for data: 682842008
I1006 15:09:05.955071  2964 net.cpp:200] Accuracy1 does not need backward computation.
I1006 15:09:05.955073  2964 net.cpp:198] SoftmaxWithLoss1 needs backward computation.
I1006 15:09:05.955076  2964 net.cpp:198] InnerProduct1_InnerProduct1_0_split needs backward computation.
I1006 15:09:05.955080  2964 net.cpp:198] InnerProduct1 needs backward computation.
I1006 15:09:05.955082  2964 net.cpp:198] Pooling1 needs backward computation.
I1006 15:09:05.955085  2964 net.cpp:198] penlu31 needs backward computation.
I1006 15:09:05.955086  2964 net.cpp:198] Eltwise15 needs backward computation.
I1006 15:09:05.955088  2964 net.cpp:198] Scale33 needs backward computation.
I1006 15:09:05.955090  2964 net.cpp:198] BatchNorm33 needs backward computation.
I1006 15:09:05.955092  2964 net.cpp:198] Convolution33 needs backward computation.
I1006 15:09:05.955094  2964 net.cpp:198] penlu30 needs backward computation.
I1006 15:09:05.955096  2964 net.cpp:198] Scale32 needs backward computation.
I1006 15:09:05.955098  2964 net.cpp:198] BatchNorm32 needs backward computation.
I1006 15:09:05.955101  2964 net.cpp:198] Convolution32 needs backward computation.
I1006 15:09:05.955102  2964 net.cpp:198] Eltwise14_penlu29_0_split needs backward computation.
I1006 15:09:05.955106  2964 net.cpp:198] penlu29 needs backward computation.
I1006 15:09:05.955107  2964 net.cpp:198] Eltwise14 needs backward computation.
I1006 15:09:05.955109  2964 net.cpp:198] Scale31 needs backward computation.
I1006 15:09:05.955111  2964 net.cpp:198] BatchNorm31 needs backward computation.
I1006 15:09:05.955113  2964 net.cpp:198] Convolution31 needs backward computation.
I1006 15:09:05.955116  2964 net.cpp:198] penlu28 needs backward computation.
I1006 15:09:05.955117  2964 net.cpp:198] Scale30 needs backward computation.
I1006 15:09:05.955119  2964 net.cpp:198] BatchNorm30 needs backward computation.
I1006 15:09:05.955121  2964 net.cpp:198] Convolution30 needs backward computation.
I1006 15:09:05.955123  2964 net.cpp:198] Eltwise13_penlu27_0_split needs backward computation.
I1006 15:09:05.955126  2964 net.cpp:198] penlu27 needs backward computation.
I1006 15:09:05.955133  2964 net.cpp:198] Eltwise13 needs backward computation.
I1006 15:09:05.955137  2964 net.cpp:198] Scale29 needs backward computation.
I1006 15:09:05.955139  2964 net.cpp:198] BatchNorm29 needs backward computation.
I1006 15:09:05.955142  2964 net.cpp:198] Convolution29 needs backward computation.
I1006 15:09:05.955143  2964 net.cpp:198] penlu26 needs backward computation.
I1006 15:09:05.955145  2964 net.cpp:198] Scale28 needs backward computation.
I1006 15:09:05.955147  2964 net.cpp:198] BatchNorm28 needs backward computation.
I1006 15:09:05.955149  2964 net.cpp:198] Convolution28 needs backward computation.
I1006 15:09:05.955152  2964 net.cpp:198] Eltwise12_penlu25_0_split needs backward computation.
I1006 15:09:05.955154  2964 net.cpp:198] penlu25 needs backward computation.
I1006 15:09:05.955157  2964 net.cpp:198] Eltwise12 needs backward computation.
I1006 15:09:05.955158  2964 net.cpp:198] Scale27 needs backward computation.
I1006 15:09:05.955160  2964 net.cpp:198] BatchNorm27 needs backward computation.
I1006 15:09:05.955166  2964 net.cpp:198] Convolution27 needs backward computation.
I1006 15:09:05.955171  2964 net.cpp:198] penlu24 needs backward computation.
I1006 15:09:05.955175  2964 net.cpp:198] Scale26 needs backward computation.
I1006 15:09:05.955178  2964 net.cpp:198] BatchNorm26 needs backward computation.
I1006 15:09:05.955180  2964 net.cpp:198] Convolution26 needs backward computation.
I1006 15:09:05.955183  2964 net.cpp:198] Eltwise11_penlu23_0_split needs backward computation.
I1006 15:09:05.955184  2964 net.cpp:198] penlu23 needs backward computation.
I1006 15:09:05.955186  2964 net.cpp:198] Eltwise11 needs backward computation.
I1006 15:09:05.955189  2964 net.cpp:198] Scale25 needs backward computation.
I1006 15:09:05.955191  2964 net.cpp:198] BatchNorm25 needs backward computation.
I1006 15:09:05.955193  2964 net.cpp:198] Convolution25 needs backward computation.
I1006 15:09:05.955196  2964 net.cpp:198] penlu22 needs backward computation.
I1006 15:09:05.955199  2964 net.cpp:198] Scale24 needs backward computation.
I1006 15:09:05.955200  2964 net.cpp:198] BatchNorm24 needs backward computation.
I1006 15:09:05.955202  2964 net.cpp:198] Convolution24 needs backward computation.
I1006 15:09:05.955204  2964 net.cpp:198] Scale23 needs backward computation.
I1006 15:09:05.955206  2964 net.cpp:198] BatchNorm23 needs backward computation.
I1006 15:09:05.955209  2964 net.cpp:198] Convolution23 needs backward computation.
I1006 15:09:05.955211  2964 net.cpp:198] Eltwise10_penlu21_0_split needs backward computation.
I1006 15:09:05.955214  2964 net.cpp:198] penlu21 needs backward computation.
I1006 15:09:05.955215  2964 net.cpp:198] Eltwise10 needs backward computation.
I1006 15:09:05.955219  2964 net.cpp:198] Scale22 needs backward computation.
I1006 15:09:05.955220  2964 net.cpp:198] BatchNorm22 needs backward computation.
I1006 15:09:05.955222  2964 net.cpp:198] Convolution22 needs backward computation.
I1006 15:09:05.955224  2964 net.cpp:198] penlu20 needs backward computation.
I1006 15:09:05.955226  2964 net.cpp:198] Scale21 needs backward computation.
I1006 15:09:05.955229  2964 net.cpp:198] BatchNorm21 needs backward computation.
I1006 15:09:05.955231  2964 net.cpp:198] Convolution21 needs backward computation.
I1006 15:09:05.955234  2964 net.cpp:198] Eltwise9_penlu19_0_split needs backward computation.
I1006 15:09:05.955235  2964 net.cpp:198] penlu19 needs backward computation.
I1006 15:09:05.955238  2964 net.cpp:198] Eltwise9 needs backward computation.
I1006 15:09:05.955240  2964 net.cpp:198] Scale20 needs backward computation.
I1006 15:09:05.955242  2964 net.cpp:198] BatchNorm20 needs backward computation.
I1006 15:09:05.955245  2964 net.cpp:198] Convolution20 needs backward computation.
I1006 15:09:05.955247  2964 net.cpp:198] penlu18 needs backward computation.
I1006 15:09:05.955250  2964 net.cpp:198] Scale19 needs backward computation.
I1006 15:09:05.955251  2964 net.cpp:198] BatchNorm19 needs backward computation.
I1006 15:09:05.955253  2964 net.cpp:198] Convolution19 needs backward computation.
I1006 15:09:05.978441  2964 net.cpp:198] Eltwise8_penlu17_0_split needs backward computation.
I1006 15:09:05.978451  2964 net.cpp:198] penlu17 needs backward computation.
I1006 15:09:05.978456  2964 net.cpp:198] Eltwise8 needs backward computation.
I1006 15:09:05.978461  2964 net.cpp:198] Scale18 needs backward computation.
I1006 15:09:05.978468  2964 net.cpp:198] BatchNorm18 needs backward computation.
I1006 15:09:05.978472  2964 net.cpp:198] Convolution18 needs backward computation.
I1006 15:09:05.978477  2964 net.cpp:198] penlu16 needs backward computation.
I1006 15:09:05.978482  2964 net.cpp:198] Scale17 needs backward computation.
I1006 15:09:05.978484  2964 net.cpp:198] BatchNorm17 needs backward computation.
I1006 15:09:05.978488  2964 net.cpp:198] Convolution17 needs backward computation.
I1006 15:09:05.978493  2964 net.cpp:198] Eltwise7_penlu15_0_split needs backward computation.
I1006 15:09:05.978497  2964 net.cpp:198] penlu15 needs backward computation.
I1006 15:09:05.978502  2964 net.cpp:198] Eltwise7 needs backward computation.
I1006 15:09:05.978507  2964 net.cpp:198] Scale16 needs backward computation.
I1006 15:09:05.978510  2964 net.cpp:198] BatchNorm16 needs backward computation.
I1006 15:09:05.978514  2964 net.cpp:198] Convolution16 needs backward computation.
I1006 15:09:05.978518  2964 net.cpp:198] penlu14 needs backward computation.
I1006 15:09:05.978523  2964 net.cpp:198] Scale15 needs backward computation.
I1006 15:09:05.978528  2964 net.cpp:198] BatchNorm15 needs backward computation.
I1006 15:09:05.978530  2964 net.cpp:198] Convolution15 needs backward computation.
I1006 15:09:05.978535  2964 net.cpp:198] Eltwise6_penlu13_0_split needs backward computation.
I1006 15:09:05.978539  2964 net.cpp:198] penlu13 needs backward computation.
I1006 15:09:05.978543  2964 net.cpp:198] Eltwise6 needs backward computation.
I1006 15:09:05.978549  2964 net.cpp:198] Scale14 needs backward computation.
I1006 15:09:05.978552  2964 net.cpp:198] BatchNorm14 needs backward computation.
I1006 15:09:05.978556  2964 net.cpp:198] Convolution14 needs backward computation.
I1006 15:09:05.978560  2964 net.cpp:198] penlu12 needs backward computation.
I1006 15:09:05.978564  2964 net.cpp:198] Scale13 needs backward computation.
I1006 15:09:05.978569  2964 net.cpp:198] BatchNorm13 needs backward computation.
I1006 15:09:05.978572  2964 net.cpp:198] Convolution13 needs backward computation.
I1006 15:09:05.978577  2964 net.cpp:198] Scale12 needs backward computation.
I1006 15:09:05.978581  2964 net.cpp:198] BatchNorm12 needs backward computation.
I1006 15:09:05.978585  2964 net.cpp:198] Convolution12 needs backward computation.
I1006 15:09:05.978590  2964 net.cpp:198] Eltwise5_penlu11_0_split needs backward computation.
I1006 15:09:05.978593  2964 net.cpp:198] penlu11 needs backward computation.
I1006 15:09:05.978597  2964 net.cpp:198] Eltwise5 needs backward computation.
I1006 15:09:05.978602  2964 net.cpp:198] Scale11 needs backward computation.
I1006 15:09:05.978606  2964 net.cpp:198] BatchNorm11 needs backward computation.
I1006 15:09:05.978611  2964 net.cpp:198] Convolution11 needs backward computation.
I1006 15:09:05.978615  2964 net.cpp:198] penlu10 needs backward computation.
I1006 15:09:05.978619  2964 net.cpp:198] Scale10 needs backward computation.
I1006 15:09:05.978624  2964 net.cpp:198] BatchNorm10 needs backward computation.
I1006 15:09:05.978628  2964 net.cpp:198] Convolution10 needs backward computation.
I1006 15:09:05.978633  2964 net.cpp:198] Eltwise4_penlu9_0_split needs backward computation.
I1006 15:09:05.978637  2964 net.cpp:198] penlu9 needs backward computation.
I1006 15:09:05.978642  2964 net.cpp:198] Eltwise4 needs backward computation.
I1006 15:09:05.978647  2964 net.cpp:198] Scale9 needs backward computation.
I1006 15:09:05.978652  2964 net.cpp:198] BatchNorm9 needs backward computation.
I1006 15:09:05.978655  2964 net.cpp:198] Convolution9 needs backward computation.
I1006 15:09:05.978660  2964 net.cpp:198] penlu8 needs backward computation.
I1006 15:09:05.978665  2964 net.cpp:198] Scale8 needs backward computation.
I1006 15:09:05.978677  2964 net.cpp:198] BatchNorm8 needs backward computation.
I1006 15:09:05.978682  2964 net.cpp:198] Convolution8 needs backward computation.
I1006 15:09:05.978687  2964 net.cpp:198] Eltwise3_penlu7_0_split needs backward computation.
I1006 15:09:05.978691  2964 net.cpp:198] penlu7 needs backward computation.
I1006 15:09:05.978695  2964 net.cpp:198] Eltwise3 needs backward computation.
I1006 15:09:05.978700  2964 net.cpp:198] Scale7 needs backward computation.
I1006 15:09:05.978705  2964 net.cpp:198] BatchNorm7 needs backward computation.
I1006 15:09:05.978709  2964 net.cpp:198] Convolution7 needs backward computation.
I1006 15:09:05.978713  2964 net.cpp:198] penlu6 needs backward computation.
I1006 15:09:05.978718  2964 net.cpp:198] Scale6 needs backward computation.
I1006 15:09:05.978723  2964 net.cpp:198] BatchNorm6 needs backward computation.
I1006 15:09:05.978726  2964 net.cpp:198] Convolution6 needs backward computation.
I1006 15:09:05.978731  2964 net.cpp:198] Eltwise2_penlu5_0_split needs backward computation.
I1006 15:09:05.978735  2964 net.cpp:198] penlu5 needs backward computation.
I1006 15:09:05.978740  2964 net.cpp:198] Eltwise2 needs backward computation.
I1006 15:09:05.978745  2964 net.cpp:198] Scale5 needs backward computation.
I1006 15:09:05.978749  2964 net.cpp:198] BatchNorm5 needs backward computation.
I1006 15:09:05.978754  2964 net.cpp:198] Convolution5 needs backward computation.
I1006 15:09:05.978759  2964 net.cpp:198] penlu4 needs backward computation.
I1006 15:09:05.978762  2964 net.cpp:198] Scale4 needs backward computation.
I1006 15:09:05.978766  2964 net.cpp:198] BatchNorm4 needs backward computation.
I1006 15:09:05.978770  2964 net.cpp:198] Convolution4 needs backward computation.
I1006 15:09:05.978775  2964 net.cpp:198] Eltwise1_penlu3_0_split needs backward computation.
I1006 15:09:05.978780  2964 net.cpp:198] penlu3 needs backward computation.
I1006 15:09:05.978785  2964 net.cpp:198] Eltwise1 needs backward computation.
I1006 15:09:05.978790  2964 net.cpp:198] Scale3 needs backward computation.
I1006 15:09:05.978793  2964 net.cpp:198] BatchNorm3 needs backward computation.
I1006 15:09:05.978798  2964 net.cpp:198] Convolution3 needs backward computation.
I1006 15:09:05.978802  2964 net.cpp:198] penlu2 needs backward computation.
I1006 15:09:05.978807  2964 net.cpp:198] Scale2 needs backward computation.
I1006 15:09:05.978811  2964 net.cpp:198] BatchNorm2 needs backward computation.
I1006 15:09:05.978816  2964 net.cpp:198] Convolution2 needs backward computation.
I1006 15:09:05.978821  2964 net.cpp:198] Convolution1_penlu1_0_split needs backward computation.
I1006 15:09:05.978824  2964 net.cpp:198] penlu1 needs backward computation.
I1006 15:09:05.978829  2964 net.cpp:198] Scale1 needs backward computation.
I1006 15:09:05.978833  2964 net.cpp:198] BatchNorm1 needs backward computation.
I1006 15:09:05.978837  2964 net.cpp:198] Convolution1 needs backward computation.
I1006 15:09:05.978842  2964 net.cpp:200] Data2_Data1_1_split does not need backward computation.
I1006 15:09:05.978848  2964 net.cpp:200] Data1 does not need backward computation.
I1006 15:09:05.978852  2964 net.cpp:242] This network produces output Accuracy1
I1006 15:09:05.978857  2964 net.cpp:242] This network produces output SoftmaxWithLoss1
I1006 15:09:05.978948  2964 net.cpp:255] Network initialization done.
I1006 15:09:05.979585  2964 solver.cpp:56] Solver scaffolding done.
I1006 15:09:05.989141  2964 caffe.cpp:248] Starting Optimization
I1006 15:09:05.989154  2964 solver.cpp:272] Solving resnet_cifar10
I1006 15:09:05.989156  2964 solver.cpp:273] Learning Rate Policy: multistep
I1006 15:09:05.992710  2964 solver.cpp:330] Iteration 0, Testing net (#0)
I1006 15:09:07.957883  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 15:09:08.037392  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.1
I1006 15:09:08.037420  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 87.3365 (* 1 = 87.3365 loss)
I1006 15:09:08.152185  2964 solver.cpp:218] Iteration 0 (0.10525 iter/s, 2.16294s/100 iters), loss = 2.29523
I1006 15:09:08.152227  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 2.29523 (* 1 = 2.29523 loss)
I1006 15:09:08.152237  2964 sgd_solver.cpp:105] Iteration 0, lr = 0.1
I1006 15:09:16.512428  2964 solver.cpp:218] Iteration 100 (11.9616 iter/s, 8.36012s/100 iters), loss = 1.70478
I1006 15:09:16.512460  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.70478 (* 1 = 1.70478 loss)
I1006 15:09:16.512476  2964 sgd_solver.cpp:105] Iteration 100, lr = 0.1
I1006 15:09:24.869088  2964 solver.cpp:218] Iteration 200 (11.9667 iter/s, 8.35655s/100 iters), loss = 1.76354
I1006 15:09:24.869120  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.76354 (* 1 = 1.76354 loss)
I1006 15:09:24.869127  2964 sgd_solver.cpp:105] Iteration 200, lr = 0.1
I1006 15:09:33.175895  2964 solver.cpp:218] Iteration 300 (12.0385 iter/s, 8.30669s/100 iters), loss = 1.52095
I1006 15:09:33.175925  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.52095 (* 1 = 1.52095 loss)
I1006 15:09:33.175931  2964 sgd_solver.cpp:105] Iteration 300, lr = 0.1
I1006 15:09:41.492022  2964 solver.cpp:218] Iteration 400 (12.025 iter/s, 8.31602s/100 iters), loss = 1.25243
I1006 15:09:41.492107  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.25243 (* 1 = 1.25243 loss)
I1006 15:09:41.492113  2964 sgd_solver.cpp:105] Iteration 400, lr = 0.1
I1006 15:09:49.394584  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 15:09:49.726850  2964 solver.cpp:330] Iteration 500, Testing net (#0)
I1006 15:09:51.639192  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 15:09:51.718857  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.1559
I1006 15:09:51.718880  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 4.93255 (* 1 = 4.93255 loss)
I1006 15:09:51.801661  2964 solver.cpp:218] Iteration 500 (9.69983 iter/s, 10.3095s/100 iters), loss = 1.41069
I1006 15:09:51.801683  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.41069 (* 1 = 1.41069 loss)
I1006 15:09:51.801692  2964 sgd_solver.cpp:105] Iteration 500, lr = 0.1
I1006 15:10:00.195485  2964 solver.cpp:218] Iteration 600 (11.9137 iter/s, 8.39372s/100 iters), loss = 1.22452
I1006 15:10:00.195514  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.22452 (* 1 = 1.22452 loss)
I1006 15:10:00.195520  2964 sgd_solver.cpp:105] Iteration 600, lr = 0.1
I1006 15:10:08.655665  2964 solver.cpp:218] Iteration 700 (11.8202 iter/s, 8.46007s/100 iters), loss = 1.12321
I1006 15:10:08.655706  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.12321 (* 1 = 1.12321 loss)
I1006 15:10:08.655714  2964 sgd_solver.cpp:105] Iteration 700, lr = 0.1
I1006 15:10:16.959568  2964 solver.cpp:218] Iteration 800 (12.0427 iter/s, 8.30378s/100 iters), loss = 0.996735
I1006 15:10:16.959682  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.996735 (* 1 = 0.996735 loss)
I1006 15:10:16.959691  2964 sgd_solver.cpp:105] Iteration 800, lr = 0.1
I1006 15:10:25.265336  2964 solver.cpp:218] Iteration 900 (12.0401 iter/s, 8.30557s/100 iters), loss = 0.905806
I1006 15:10:25.265383  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.905806 (* 1 = 0.905806 loss)
I1006 15:10:25.265390  2964 sgd_solver.cpp:105] Iteration 900, lr = 0.1
I1006 15:10:33.159711  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 15:10:33.492429  2964 solver.cpp:330] Iteration 1000, Testing net (#0)
I1006 15:10:35.407449  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 15:10:35.487311  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.1872
I1006 15:10:35.487346  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 4.55684 (* 1 = 4.55684 loss)
I1006 15:10:35.570024  2964 solver.cpp:218] Iteration 1000 (9.70446 iter/s, 10.3045s/100 iters), loss = 0.929661
I1006 15:10:35.570045  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.929661 (* 1 = 0.929661 loss)
I1006 15:10:35.570052  2964 sgd_solver.cpp:105] Iteration 1000, lr = 0.1
I1006 15:10:43.877671  2964 solver.cpp:218] Iteration 1100 (12.0373 iter/s, 8.30754s/100 iters), loss = 0.688169
I1006 15:10:43.877712  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.688169 (* 1 = 0.688169 loss)
I1006 15:10:43.877718  2964 sgd_solver.cpp:105] Iteration 1100, lr = 0.1
I1006 15:10:52.188370  2964 solver.cpp:218] Iteration 1200 (12.0329 iter/s, 8.31058s/100 iters), loss = 0.940603
I1006 15:10:52.188468  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.940603 (* 1 = 0.940603 loss)
I1006 15:10:52.188477  2964 sgd_solver.cpp:105] Iteration 1200, lr = 0.1
I1006 15:11:00.503078  2964 solver.cpp:218] Iteration 1300 (12.0271 iter/s, 8.31454s/100 iters), loss = 0.715381
I1006 15:11:00.503109  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.715381 (* 1 = 0.715381 loss)
I1006 15:11:00.503114  2964 sgd_solver.cpp:105] Iteration 1300, lr = 0.1
I1006 15:11:08.828055  2964 solver.cpp:218] Iteration 1400 (12.0122 iter/s, 8.32487s/100 iters), loss = 0.639217
I1006 15:11:08.828096  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.639217 (* 1 = 0.639217 loss)
I1006 15:11:08.828104  2964 sgd_solver.cpp:105] Iteration 1400, lr = 0.1
I1006 15:11:16.859958  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 15:11:17.200058  2964 solver.cpp:330] Iteration 1500, Testing net (#0)
I1006 15:11:19.173146  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 15:11:19.256944  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.5089
I1006 15:11:19.256971  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.53576 (* 1 = 1.53576 loss)
I1006 15:11:19.339946  2964 solver.cpp:218] Iteration 1500 (9.51316 iter/s, 10.5118s/100 iters), loss = 0.86138
I1006 15:11:19.339968  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.86138 (* 1 = 0.86138 loss)
I1006 15:11:19.339975  2964 sgd_solver.cpp:105] Iteration 1500, lr = 0.1
I1006 15:11:27.879688  2964 solver.cpp:218] Iteration 1600 (11.7101 iter/s, 8.53964s/100 iters), loss = 0.618033
I1006 15:11:27.879803  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.618033 (* 1 = 0.618033 loss)
I1006 15:11:27.879812  2964 sgd_solver.cpp:105] Iteration 1600, lr = 0.1
I1006 15:11:36.384239  2964 solver.cpp:218] Iteration 1700 (11.7587 iter/s, 8.50437s/100 iters), loss = 0.713632
I1006 15:11:36.384289  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.713632 (* 1 = 0.713632 loss)
I1006 15:11:36.384296  2964 sgd_solver.cpp:105] Iteration 1700, lr = 0.1
I1006 15:11:44.856587  2964 solver.cpp:218] Iteration 1800 (11.8033 iter/s, 8.47222s/100 iters), loss = 0.628355
I1006 15:11:44.856631  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.628355 (* 1 = 0.628355 loss)
I1006 15:11:44.856639  2964 sgd_solver.cpp:105] Iteration 1800, lr = 0.1
I1006 15:11:53.290102  2964 solver.cpp:218] Iteration 1900 (11.8576 iter/s, 8.43339s/100 iters), loss = 0.586165
I1006 15:11:53.290149  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.586165 (* 1 = 0.586165 loss)
I1006 15:11:53.290158  2964 sgd_solver.cpp:105] Iteration 1900, lr = 0.1
I1006 15:12:01.298677  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 15:12:01.634785  2964 solver.cpp:330] Iteration 2000, Testing net (#0)
I1006 15:12:03.577567  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 15:12:03.657758  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6017
I1006 15:12:03.657793  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.14575 (* 1 = 1.14575 loss)
I1006 15:12:03.747438  2964 solver.cpp:218] Iteration 2000 (9.56279 iter/s, 10.4572s/100 iters), loss = 0.694791
I1006 15:12:03.747474  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.694791 (* 1 = 0.694791 loss)
I1006 15:12:03.747491  2964 sgd_solver.cpp:105] Iteration 2000, lr = 0.1
I1006 15:12:12.167928  2964 solver.cpp:218] Iteration 2100 (11.8759 iter/s, 8.42038s/100 iters), loss = 0.548198
I1006 15:12:12.167961  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.548198 (* 1 = 0.548198 loss)
I1006 15:12:12.167968  2964 sgd_solver.cpp:105] Iteration 2100, lr = 0.1
I1006 15:12:20.587877  2964 solver.cpp:218] Iteration 2200 (11.8767 iter/s, 8.41984s/100 iters), loss = 0.549827
I1006 15:12:20.587908  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.549827 (* 1 = 0.549827 loss)
I1006 15:12:20.587915  2964 sgd_solver.cpp:105] Iteration 2200, lr = 0.1
I1006 15:12:29.122503  2964 solver.cpp:218] Iteration 2300 (11.7171 iter/s, 8.53452s/100 iters), loss = 0.61827
I1006 15:12:29.122534  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.61827 (* 1 = 0.61827 loss)
I1006 15:12:29.122541  2964 sgd_solver.cpp:105] Iteration 2300, lr = 0.1
I1006 15:12:37.733261  2964 solver.cpp:218] Iteration 2400 (11.6135 iter/s, 8.61066s/100 iters), loss = 0.489291
I1006 15:12:37.733407  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.489291 (* 1 = 0.489291 loss)
I1006 15:12:37.733425  2964 sgd_solver.cpp:105] Iteration 2400, lr = 0.1
I1006 15:12:45.746567  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 15:12:46.080528  2964 solver.cpp:330] Iteration 2500, Testing net (#0)
I1006 15:12:47.998270  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 15:12:48.078183  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6682
I1006 15:12:48.078219  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.948105 (* 1 = 0.948105 loss)
I1006 15:12:48.161365  2964 solver.cpp:218] Iteration 2500 (9.58967 iter/s, 10.4279s/100 iters), loss = 0.613174
I1006 15:12:48.161387  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.613174 (* 1 = 0.613174 loss)
I1006 15:12:48.161394  2964 sgd_solver.cpp:105] Iteration 2500, lr = 0.1
I1006 15:12:56.496246  2964 solver.cpp:218] Iteration 2600 (11.9979 iter/s, 8.3348s/100 iters), loss = 0.406456
I1006 15:12:56.496287  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.406456 (* 1 = 0.406456 loss)
I1006 15:12:56.496294  2964 sgd_solver.cpp:105] Iteration 2600, lr = 0.1
I1006 15:13:04.841388  2964 solver.cpp:218] Iteration 2700 (11.9832 iter/s, 8.34504s/100 iters), loss = 0.623556
I1006 15:13:04.841421  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.623556 (* 1 = 0.623556 loss)
I1006 15:13:04.841428  2964 sgd_solver.cpp:105] Iteration 2700, lr = 0.1
I1006 15:13:13.235867  2964 solver.cpp:218] Iteration 2800 (11.9127 iter/s, 8.39438s/100 iters), loss = 0.546118
I1006 15:13:13.235954  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.546118 (* 1 = 0.546118 loss)
I1006 15:13:13.235972  2964 sgd_solver.cpp:105] Iteration 2800, lr = 0.1
I1006 15:13:21.613243  2964 solver.cpp:218] Iteration 2900 (11.9372 iter/s, 8.3772s/100 iters), loss = 0.503797
I1006 15:13:21.613281  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.503797 (* 1 = 0.503797 loss)
I1006 15:13:21.613288  2964 sgd_solver.cpp:105] Iteration 2900, lr = 0.1
I1006 15:13:29.614359  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 15:13:29.949712  2964 solver.cpp:330] Iteration 3000, Testing net (#0)
I1006 15:13:31.903978  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 15:13:31.985647  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7262
I1006 15:13:31.985684  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.824088 (* 1 = 0.824088 loss)
I1006 15:13:32.069140  2964 solver.cpp:218] Iteration 3000 (9.56407 iter/s, 10.4558s/100 iters), loss = 0.544271
I1006 15:13:32.069166  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.544271 (* 1 = 0.544271 loss)
I1006 15:13:32.069173  2964 sgd_solver.cpp:105] Iteration 3000, lr = 0.1
I1006 15:13:40.571988  2964 solver.cpp:218] Iteration 3100 (11.7609 iter/s, 8.50277s/100 iters), loss = 0.387208
I1006 15:13:40.572031  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.387208 (* 1 = 0.387208 loss)
I1006 15:13:40.572039  2964 sgd_solver.cpp:105] Iteration 3100, lr = 0.1
I1006 15:13:49.227756  2964 solver.cpp:218] Iteration 3200 (11.5534 iter/s, 8.65549s/100 iters), loss = 0.532413
I1006 15:13:49.227926  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.532413 (* 1 = 0.532413 loss)
I1006 15:13:49.227936  2964 sgd_solver.cpp:105] Iteration 3200, lr = 0.1
I1006 15:13:57.815989  2964 solver.cpp:218] Iteration 3300 (11.6441 iter/s, 8.58802s/100 iters), loss = 0.587725
I1006 15:13:57.816030  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.587725 (* 1 = 0.587725 loss)
I1006 15:13:57.816037  2964 sgd_solver.cpp:105] Iteration 3300, lr = 0.1
I1006 15:14:06.277627  2964 solver.cpp:218] Iteration 3400 (11.8182 iter/s, 8.46155s/100 iters), loss = 0.489057
I1006 15:14:06.277669  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.489057 (* 1 = 0.489057 loss)
I1006 15:14:06.277675  2964 sgd_solver.cpp:105] Iteration 3400, lr = 0.1
I1006 15:14:14.268579  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 15:14:14.604550  2964 solver.cpp:330] Iteration 3500, Testing net (#0)
I1006 15:14:16.523300  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 15:14:16.603162  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.666
I1006 15:14:16.603197  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.979771 (* 1 = 0.979771 loss)
I1006 15:14:16.687394  2964 solver.cpp:218] Iteration 3500 (9.60645 iter/s, 10.4097s/100 iters), loss = 0.53839
I1006 15:14:16.687422  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.53839 (* 1 = 0.53839 loss)
I1006 15:14:16.687429  2964 sgd_solver.cpp:105] Iteration 3500, lr = 0.1
I1006 15:14:25.069504  2964 solver.cpp:218] Iteration 3600 (11.9303 iter/s, 8.38203s/100 iters), loss = 0.334745
I1006 15:14:25.069620  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.334745 (* 1 = 0.334745 loss)
I1006 15:14:25.069640  2964 sgd_solver.cpp:105] Iteration 3600, lr = 0.1
I1006 15:14:33.461307  2964 solver.cpp:218] Iteration 3700 (11.9166 iter/s, 8.39165s/100 iters), loss = 0.441198
I1006 15:14:33.461338  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.441198 (* 1 = 0.441198 loss)
I1006 15:14:33.461344  2964 sgd_solver.cpp:105] Iteration 3700, lr = 0.1
I1006 15:14:41.854975  2964 solver.cpp:218] Iteration 3800 (11.9138 iter/s, 8.3936s/100 iters), loss = 0.5759
I1006 15:14:41.855015  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.5759 (* 1 = 0.5759 loss)
I1006 15:14:41.855021  2964 sgd_solver.cpp:105] Iteration 3800, lr = 0.1
I1006 15:14:50.227558  2964 solver.cpp:218] Iteration 3900 (11.9439 iter/s, 8.3725s/100 iters), loss = 0.447774
I1006 15:14:50.227593  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.447774 (* 1 = 0.447774 loss)
I1006 15:14:50.227602  2964 sgd_solver.cpp:105] Iteration 3900, lr = 0.1
I1006 15:14:58.205865  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 15:14:58.539722  2964 solver.cpp:330] Iteration 4000, Testing net (#0)
I1006 15:15:00.477574  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 15:15:00.557611  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6254
I1006 15:15:00.557646  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.03011 (* 1 = 1.03011 loss)
I1006 15:15:00.640390  2964 solver.cpp:218] Iteration 4000 (9.60361 iter/s, 10.4128s/100 iters), loss = 0.408647
I1006 15:15:00.640415  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.408647 (* 1 = 0.408647 loss)
I1006 15:15:00.640422  2964 sgd_solver.cpp:105] Iteration 4000, lr = 0.1
I1006 15:15:09.039799  2964 solver.cpp:218] Iteration 4100 (11.9057 iter/s, 8.39934s/100 iters), loss = 0.353256
I1006 15:15:09.039830  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.353256 (* 1 = 0.353256 loss)
I1006 15:15:09.039836  2964 sgd_solver.cpp:105] Iteration 4100, lr = 0.1
I1006 15:15:17.416683  2964 solver.cpp:218] Iteration 4200 (11.9377 iter/s, 8.37681s/100 iters), loss = 0.482016
I1006 15:15:17.416724  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.482016 (* 1 = 0.482016 loss)
I1006 15:15:17.416730  2964 sgd_solver.cpp:105] Iteration 4200, lr = 0.1
I1006 15:15:25.818627  2964 solver.cpp:218] Iteration 4300 (11.9021 iter/s, 8.40186s/100 iters), loss = 0.511486
I1006 15:15:25.818658  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.511486 (* 1 = 0.511486 loss)
I1006 15:15:25.818665  2964 sgd_solver.cpp:105] Iteration 4300, lr = 0.1
I1006 15:15:34.197844  2964 solver.cpp:218] Iteration 4400 (11.9344 iter/s, 8.37914s/100 iters), loss = 0.374192
I1006 15:15:34.198004  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.374192 (* 1 = 0.374192 loss)
I1006 15:15:34.198022  2964 sgd_solver.cpp:105] Iteration 4400, lr = 0.1
I1006 15:15:42.173988  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 15:15:42.513183  2964 solver.cpp:330] Iteration 4500, Testing net (#0)
I1006 15:15:44.443814  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 15:15:44.525878  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6995
I1006 15:15:44.525903  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.868888 (* 1 = 0.868888 loss)
I1006 15:15:44.608148  2964 solver.cpp:218] Iteration 4500 (9.60604 iter/s, 10.4101s/100 iters), loss = 0.453458
I1006 15:15:44.608170  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.453458 (* 1 = 0.453458 loss)
I1006 15:15:44.608176  2964 sgd_solver.cpp:105] Iteration 4500, lr = 0.1
I1006 15:15:52.995581  2964 solver.cpp:218] Iteration 4600 (11.9227 iter/s, 8.38737s/100 iters), loss = 0.379304
I1006 15:15:52.995615  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.379304 (* 1 = 0.379304 loss)
I1006 15:15:52.995630  2964 sgd_solver.cpp:105] Iteration 4600, lr = 0.1
I1006 15:16:01.384600  2964 solver.cpp:218] Iteration 4700 (11.9204 iter/s, 8.38895s/100 iters), loss = 0.349221
I1006 15:16:01.384639  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.349221 (* 1 = 0.349221 loss)
I1006 15:16:01.384647  2964 sgd_solver.cpp:105] Iteration 4700, lr = 0.1
I1006 15:16:09.777999  2964 solver.cpp:218] Iteration 4800 (11.9142 iter/s, 8.39332s/100 iters), loss = 0.607948
I1006 15:16:09.778115  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.607948 (* 1 = 0.607948 loss)
I1006 15:16:09.778132  2964 sgd_solver.cpp:105] Iteration 4800, lr = 0.1
I1006 15:16:18.172865  2964 solver.cpp:218] Iteration 4900 (11.9123 iter/s, 8.39472s/100 iters), loss = 0.359984
I1006 15:16:18.172910  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.359984 (* 1 = 0.359984 loss)
I1006 15:16:18.172917  2964 sgd_solver.cpp:105] Iteration 4900, lr = 0.1
I1006 15:16:26.151645  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 15:16:26.490267  2964 solver.cpp:330] Iteration 5000, Testing net (#0)
I1006 15:16:28.417238  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 15:16:28.498044  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7007
I1006 15:16:28.498071  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.852644 (* 1 = 0.852644 loss)
I1006 15:16:28.582038  2964 solver.cpp:218] Iteration 5000 (9.60699 iter/s, 10.4091s/100 iters), loss = 0.376138
I1006 15:16:28.582070  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.376138 (* 1 = 0.376138 loss)
I1006 15:16:28.582082  2964 sgd_solver.cpp:105] Iteration 5000, lr = 0.1
I1006 15:16:36.995276  2964 solver.cpp:218] Iteration 5100 (11.8861 iter/s, 8.41317s/100 iters), loss = 0.298849
I1006 15:16:36.995312  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.298849 (* 1 = 0.298849 loss)
I1006 15:16:36.995332  2964 sgd_solver.cpp:105] Iteration 5100, lr = 0.1
I1006 15:16:45.381757  2964 solver.cpp:218] Iteration 5200 (11.9241 iter/s, 8.38641s/100 iters), loss = 0.375358
I1006 15:16:45.381867  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.375358 (* 1 = 0.375358 loss)
I1006 15:16:45.381880  2964 sgd_solver.cpp:105] Iteration 5200, lr = 0.1
I1006 15:16:53.765769  2964 solver.cpp:218] Iteration 5300 (11.9277 iter/s, 8.38387s/100 iters), loss = 0.354598
I1006 15:16:53.765801  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.354598 (* 1 = 0.354598 loss)
I1006 15:16:53.765810  2964 sgd_solver.cpp:105] Iteration 5300, lr = 0.1
I1006 15:17:02.163591  2964 solver.cpp:218] Iteration 5400 (11.9079 iter/s, 8.39775s/100 iters), loss = 0.318707
I1006 15:17:02.163628  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.318707 (* 1 = 0.318707 loss)
I1006 15:17:02.163638  2964 sgd_solver.cpp:105] Iteration 5400, lr = 0.1
I1006 15:17:10.150537  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 15:17:10.484951  2964 solver.cpp:330] Iteration 5500, Testing net (#0)
I1006 15:17:12.422634  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 15:17:12.502825  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7065
I1006 15:17:12.502852  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.866609 (* 1 = 0.866609 loss)
I1006 15:17:12.585930  2964 solver.cpp:218] Iteration 5500 (9.59485 iter/s, 10.4223s/100 iters), loss = 0.367467
I1006 15:17:12.585958  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.367467 (* 1 = 0.367467 loss)
I1006 15:17:12.585969  2964 sgd_solver.cpp:105] Iteration 5500, lr = 0.1
I1006 15:17:20.991612  2964 solver.cpp:218] Iteration 5600 (11.8968 iter/s, 8.40562s/100 iters), loss = 0.333131
I1006 15:17:20.991734  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.333131 (* 1 = 0.333131 loss)
I1006 15:17:20.991758  2964 sgd_solver.cpp:105] Iteration 5600, lr = 0.1
I1006 15:17:29.491763  2964 solver.cpp:218] Iteration 5700 (11.7647 iter/s, 8.5s/100 iters), loss = 0.432554
I1006 15:17:29.491797  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.432554 (* 1 = 0.432554 loss)
I1006 15:17:29.491816  2964 sgd_solver.cpp:105] Iteration 5700, lr = 0.1
I1006 15:17:37.852448  2964 solver.cpp:218] Iteration 5800 (11.9608 iter/s, 8.36062s/100 iters), loss = 0.413926
I1006 15:17:37.852480  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.413926 (* 1 = 0.413926 loss)
I1006 15:17:37.852488  2964 sgd_solver.cpp:105] Iteration 5800, lr = 0.1
I1006 15:17:46.194290  2964 solver.cpp:218] Iteration 5900 (11.9879 iter/s, 8.34177s/100 iters), loss = 0.337124
I1006 15:17:46.194324  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.337124 (* 1 = 0.337124 loss)
I1006 15:17:46.194340  2964 sgd_solver.cpp:105] Iteration 5900, lr = 0.1
I1006 15:17:54.121125  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 15:17:54.454958  2964 solver.cpp:330] Iteration 6000, Testing net (#0)
I1006 15:17:56.374311  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 15:17:56.454258  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7441
I1006 15:17:56.454284  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.738064 (* 1 = 0.738064 loss)
I1006 15:17:56.537690  2964 solver.cpp:218] Iteration 6000 (9.66807 iter/s, 10.3433s/100 iters), loss = 0.35309
I1006 15:17:56.537717  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.35309 (* 1 = 0.35309 loss)
I1006 15:17:56.537727  2964 sgd_solver.cpp:105] Iteration 6000, lr = 0.1
I1006 15:18:04.868193  2964 solver.cpp:218] Iteration 6100 (12.0042 iter/s, 8.33044s/100 iters), loss = 0.337954
I1006 15:18:04.868227  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.337954 (* 1 = 0.337954 loss)
I1006 15:18:04.868233  2964 sgd_solver.cpp:105] Iteration 6100, lr = 0.1
I1006 15:18:13.195070  2964 solver.cpp:218] Iteration 6200 (12.0094 iter/s, 8.32681s/100 iters), loss = 0.439462
I1006 15:18:13.195103  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.439462 (* 1 = 0.439462 loss)
I1006 15:18:13.195111  2964 sgd_solver.cpp:105] Iteration 6200, lr = 0.1
I1006 15:18:21.524412  2964 solver.cpp:218] Iteration 6300 (12.0058 iter/s, 8.32927s/100 iters), loss = 0.442108
I1006 15:18:21.524446  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.442108 (* 1 = 0.442108 loss)
I1006 15:18:21.524463  2964 sgd_solver.cpp:105] Iteration 6300, lr = 0.1
I1006 15:18:29.854895  2964 solver.cpp:218] Iteration 6400 (12.0042 iter/s, 8.33041s/100 iters), loss = 0.351233
I1006 15:18:29.855037  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.351233 (* 1 = 0.351233 loss)
I1006 15:18:29.855059  2964 sgd_solver.cpp:105] Iteration 6400, lr = 0.1
I1006 15:18:37.768638  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 15:18:38.101503  2964 solver.cpp:330] Iteration 6500, Testing net (#0)
I1006 15:18:40.024243  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 15:18:40.104311  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7763
I1006 15:18:40.104338  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.658924 (* 1 = 0.658924 loss)
I1006 15:18:40.187610  2964 solver.cpp:218] Iteration 6500 (9.67817 iter/s, 10.3325s/100 iters), loss = 0.313248
I1006 15:18:40.187635  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.313248 (* 1 = 0.313248 loss)
I1006 15:18:40.187645  2964 sgd_solver.cpp:105] Iteration 6500, lr = 0.1
I1006 15:18:48.530176  2964 solver.cpp:218] Iteration 6600 (11.9868 iter/s, 8.34251s/100 iters), loss = 0.276294
I1006 15:18:48.530210  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.276294 (* 1 = 0.276294 loss)
I1006 15:18:48.530217  2964 sgd_solver.cpp:105] Iteration 6600, lr = 0.1
I1006 15:18:56.873039  2964 solver.cpp:218] Iteration 6700 (11.9864 iter/s, 8.34279s/100 iters), loss = 0.357238
I1006 15:18:56.873072  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.357238 (* 1 = 0.357238 loss)
I1006 15:18:56.873080  2964 sgd_solver.cpp:105] Iteration 6700, lr = 0.1
I1006 15:19:05.220341  2964 solver.cpp:218] Iteration 6800 (11.98 iter/s, 8.34723s/100 iters), loss = 0.381207
I1006 15:19:05.220461  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.381207 (* 1 = 0.381207 loss)
I1006 15:19:05.220470  2964 sgd_solver.cpp:105] Iteration 6800, lr = 0.1
I1006 15:19:13.565376  2964 solver.cpp:218] Iteration 6900 (11.9834 iter/s, 8.34489s/100 iters), loss = 0.428152
I1006 15:19:13.565409  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.428152 (* 1 = 0.428152 loss)
I1006 15:19:13.565416  2964 sgd_solver.cpp:105] Iteration 6900, lr = 0.1
I1006 15:19:21.495714  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 15:19:21.830534  2964 solver.cpp:330] Iteration 7000, Testing net (#0)
I1006 15:19:23.752183  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 15:19:23.832471  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7608
I1006 15:19:23.832499  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.705229 (* 1 = 0.705229 loss)
I1006 15:19:23.915522  2964 solver.cpp:218] Iteration 7000 (9.66177 iter/s, 10.3501s/100 iters), loss = 0.376509
I1006 15:19:23.915549  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.376509 (* 1 = 0.376509 loss)
I1006 15:19:23.915558  2964 sgd_solver.cpp:105] Iteration 7000, lr = 0.1
I1006 15:19:32.247067  2964 solver.cpp:218] Iteration 7100 (12.0027 iter/s, 8.33148s/100 iters), loss = 0.349995
I1006 15:19:32.247100  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.349995 (* 1 = 0.349995 loss)
I1006 15:19:32.247117  2964 sgd_solver.cpp:105] Iteration 7100, lr = 0.1
I1006 15:19:40.725136  2964 solver.cpp:218] Iteration 7200 (11.7952 iter/s, 8.478s/100 iters), loss = 0.41216
I1006 15:19:40.725244  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.41216 (* 1 = 0.41216 loss)
I1006 15:19:40.725268  2964 sgd_solver.cpp:105] Iteration 7200, lr = 0.1
I1006 15:19:49.115140  2964 solver.cpp:218] Iteration 7300 (11.9191 iter/s, 8.38986s/100 iters), loss = 0.436358
I1006 15:19:49.115173  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.436358 (* 1 = 0.436358 loss)
I1006 15:19:49.115182  2964 sgd_solver.cpp:105] Iteration 7300, lr = 0.1
I1006 15:19:57.674662  2964 solver.cpp:218] Iteration 7400 (11.683 iter/s, 8.55944s/100 iters), loss = 0.403849
I1006 15:19:57.674723  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.403849 (* 1 = 0.403849 loss)
I1006 15:19:57.674736  2964 sgd_solver.cpp:105] Iteration 7400, lr = 0.1
I1006 15:20:05.656029  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 15:20:05.991724  2964 solver.cpp:330] Iteration 7500, Testing net (#0)
I1006 15:20:07.920022  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 15:20:08.000030  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6651
I1006 15:20:08.000063  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.05715 (* 1 = 1.05715 loss)
I1006 15:20:08.083513  2964 solver.cpp:218] Iteration 7500 (9.60734 iter/s, 10.4087s/100 iters), loss = 0.353316
I1006 15:20:08.083550  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.353316 (* 1 = 0.353316 loss)
I1006 15:20:08.083557  2964 sgd_solver.cpp:105] Iteration 7500, lr = 0.1
I1006 15:20:16.474967  2964 solver.cpp:218] Iteration 7600 (11.917 iter/s, 8.39138s/100 iters), loss = 0.335285
I1006 15:20:16.475127  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.335285 (* 1 = 0.335285 loss)
I1006 15:20:16.475136  2964 sgd_solver.cpp:105] Iteration 7600, lr = 0.1
I1006 15:20:24.959471  2964 solver.cpp:218] Iteration 7700 (11.7865 iter/s, 8.48431s/100 iters), loss = 0.335356
I1006 15:20:24.959504  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.335357 (* 1 = 0.335357 loss)
I1006 15:20:24.959511  2964 sgd_solver.cpp:105] Iteration 7700, lr = 0.1
I1006 15:20:33.469491  2964 solver.cpp:218] Iteration 7800 (11.7509 iter/s, 8.50995s/100 iters), loss = 0.35028
I1006 15:20:33.469533  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.35028 (* 1 = 0.35028 loss)
I1006 15:20:33.469540  2964 sgd_solver.cpp:105] Iteration 7800, lr = 0.1
I1006 15:20:41.983294  2964 solver.cpp:218] Iteration 7900 (11.7457 iter/s, 8.51372s/100 iters), loss = 0.359899
I1006 15:20:41.983338  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.359899 (* 1 = 0.359899 loss)
I1006 15:20:41.983345  2964 sgd_solver.cpp:105] Iteration 7900, lr = 0.1
I1006 15:20:50.113389  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 15:20:50.448464  2964 solver.cpp:330] Iteration 8000, Testing net (#0)
I1006 15:20:52.372205  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 15:20:52.453416  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7225
I1006 15:20:52.453454  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.853194 (* 1 = 0.853194 loss)
I1006 15:20:52.536345  2964 solver.cpp:218] Iteration 8000 (9.47604 iter/s, 10.5529s/100 iters), loss = 0.367594
I1006 15:20:52.536370  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.367594 (* 1 = 0.367594 loss)
I1006 15:20:52.536375  2964 sgd_solver.cpp:105] Iteration 8000, lr = 0.1
I1006 15:21:00.906208  2964 solver.cpp:218] Iteration 8100 (11.9477 iter/s, 8.3698s/100 iters), loss = 0.319943
I1006 15:21:00.906247  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.319943 (* 1 = 0.319943 loss)
I1006 15:21:00.906253  2964 sgd_solver.cpp:105] Iteration 8100, lr = 0.1
I1006 15:21:09.286587  2964 solver.cpp:218] Iteration 8200 (11.9327 iter/s, 8.3803s/100 iters), loss = 0.351202
I1006 15:21:09.286628  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.351202 (* 1 = 0.351202 loss)
I1006 15:21:09.286634  2964 sgd_solver.cpp:105] Iteration 8200, lr = 0.1
I1006 15:21:17.659363  2964 solver.cpp:218] Iteration 8300 (11.9436 iter/s, 8.3727s/100 iters), loss = 0.295331
I1006 15:21:17.659399  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.295331 (* 1 = 0.295331 loss)
I1006 15:21:17.659405  2964 sgd_solver.cpp:105] Iteration 8300, lr = 0.1
I1006 15:21:26.038321  2964 solver.cpp:218] Iteration 8400 (11.9348 iter/s, 8.37889s/100 iters), loss = 0.261063
I1006 15:21:26.038455  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.261063 (* 1 = 0.261063 loss)
I1006 15:21:26.038465  2964 sgd_solver.cpp:105] Iteration 8400, lr = 0.1
I1006 15:21:34.016440  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 15:21:34.356932  2964 solver.cpp:330] Iteration 8500, Testing net (#0)
I1006 15:21:36.287973  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 15:21:36.368613  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7774
I1006 15:21:36.368641  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.687186 (* 1 = 0.687186 loss)
I1006 15:21:36.452446  2964 solver.cpp:218] Iteration 8500 (9.6025 iter/s, 10.414s/100 iters), loss = 0.353482
I1006 15:21:36.452478  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.353482 (* 1 = 0.353482 loss)
I1006 15:21:36.452495  2964 sgd_solver.cpp:105] Iteration 8500, lr = 0.1
I1006 15:21:44.914396  2964 solver.cpp:218] Iteration 8600 (11.8177 iter/s, 8.46188s/100 iters), loss = 0.264762
I1006 15:21:44.914435  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.264762 (* 1 = 0.264762 loss)
I1006 15:21:44.914443  2964 sgd_solver.cpp:105] Iteration 8600, lr = 0.1
I1006 15:21:53.365506  2964 solver.cpp:218] Iteration 8700 (11.8329 iter/s, 8.45103s/100 iters), loss = 0.378773
I1006 15:21:53.365545  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.378773 (* 1 = 0.378773 loss)
I1006 15:21:53.365551  2964 sgd_solver.cpp:105] Iteration 8700, lr = 0.1
I1006 15:22:01.781556  2964 solver.cpp:218] Iteration 8800 (11.8822 iter/s, 8.41598s/100 iters), loss = 0.332489
I1006 15:22:01.781684  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.332489 (* 1 = 0.332489 loss)
I1006 15:22:01.781702  2964 sgd_solver.cpp:105] Iteration 8800, lr = 0.1
I1006 15:22:10.313549  2964 solver.cpp:218] Iteration 8900 (11.7208 iter/s, 8.53182s/100 iters), loss = 0.296886
I1006 15:22:10.313611  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.296886 (* 1 = 0.296886 loss)
I1006 15:22:10.313623  2964 sgd_solver.cpp:105] Iteration 8900, lr = 0.1
I1006 15:22:18.374790  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 15:22:18.709028  2964 solver.cpp:330] Iteration 9000, Testing net (#0)
I1006 15:22:20.632889  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 15:22:20.713451  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.714
I1006 15:22:20.713488  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.995068 (* 1 = 0.995068 loss)
I1006 15:22:20.796736  2964 solver.cpp:218] Iteration 9000 (9.5392 iter/s, 10.4831s/100 iters), loss = 0.343942
I1006 15:22:20.796782  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.343942 (* 1 = 0.343942 loss)
I1006 15:22:20.796788  2964 sgd_solver.cpp:105] Iteration 9000, lr = 0.1
I1006 15:22:29.398216  2964 solver.cpp:218] Iteration 9100 (11.626 iter/s, 8.6014s/100 iters), loss = 0.288886
I1006 15:22:29.398272  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.288886 (* 1 = 0.288886 loss)
I1006 15:22:29.398280  2964 sgd_solver.cpp:105] Iteration 9100, lr = 0.1
I1006 15:22:38.132709  2964 solver.cpp:218] Iteration 9200 (11.449 iter/s, 8.73437s/100 iters), loss = 0.267761
I1006 15:22:38.132848  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.267761 (* 1 = 0.267761 loss)
I1006 15:22:38.132858  2964 sgd_solver.cpp:105] Iteration 9200, lr = 0.1
I1006 15:22:46.721819  2964 solver.cpp:218] Iteration 9300 (11.6429 iter/s, 8.58891s/100 iters), loss = 0.384045
I1006 15:22:46.721921  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.384045 (* 1 = 0.384045 loss)
I1006 15:22:46.721942  2964 sgd_solver.cpp:105] Iteration 9300, lr = 0.1
I1006 15:22:55.313830  2964 solver.cpp:218] Iteration 9400 (11.6389 iter/s, 8.59184s/100 iters), loss = 0.390193
I1006 15:22:55.313886  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.390194 (* 1 = 0.390194 loss)
I1006 15:22:55.313895  2964 sgd_solver.cpp:105] Iteration 9400, lr = 0.1
I1006 15:23:03.506156  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 15:23:03.840781  2964 solver.cpp:330] Iteration 9500, Testing net (#0)
I1006 15:23:05.813618  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 15:23:05.893939  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6951
I1006 15:23:05.893975  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.05294 (* 1 = 1.05294 loss)
I1006 15:23:05.977419  2964 solver.cpp:218] Iteration 9500 (9.37781 iter/s, 10.6635s/100 iters), loss = 0.302527
I1006 15:23:05.977450  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.302528 (* 1 = 0.302528 loss)
I1006 15:23:05.977458  2964 sgd_solver.cpp:105] Iteration 9500, lr = 0.1
I1006 15:23:14.408752  2964 solver.cpp:218] Iteration 9600 (11.8606 iter/s, 8.43127s/100 iters), loss = 0.328755
I1006 15:23:14.408892  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.328755 (* 1 = 0.328755 loss)
I1006 15:23:14.408900  2964 sgd_solver.cpp:105] Iteration 9600, lr = 0.1
I1006 15:23:22.910763  2964 solver.cpp:218] Iteration 9700 (11.7622 iter/s, 8.50183s/100 iters), loss = 0.319066
I1006 15:23:22.910805  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.319066 (* 1 = 0.319066 loss)
I1006 15:23:22.910825  2964 sgd_solver.cpp:105] Iteration 9700, lr = 0.1
I1006 15:23:31.290207  2964 solver.cpp:218] Iteration 9800 (11.9341 iter/s, 8.37938s/100 iters), loss = 0.293474
I1006 15:23:31.290241  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.293474 (* 1 = 0.293474 loss)
I1006 15:23:31.290258  2964 sgd_solver.cpp:105] Iteration 9800, lr = 0.1
I1006 15:23:39.690244  2964 solver.cpp:218] Iteration 9900 (11.9048 iter/s, 8.39997s/100 iters), loss = 0.286453
I1006 15:23:39.690279  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.286453 (* 1 = 0.286453 loss)
I1006 15:23:39.690296  2964 sgd_solver.cpp:105] Iteration 9900, lr = 0.1
I1006 15:23:47.613077  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 15:23:47.948088  2964 solver.cpp:330] Iteration 10000, Testing net (#0)
I1006 15:23:49.869724  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 15:23:49.950233  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7443
I1006 15:23:49.950259  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.795583 (* 1 = 0.795583 loss)
I1006 15:23:50.033891  2964 solver.cpp:218] Iteration 10000 (9.66783 iter/s, 10.3436s/100 iters), loss = 0.366287
I1006 15:23:50.033917  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.366287 (* 1 = 0.366287 loss)
I1006 15:23:50.033936  2964 sgd_solver.cpp:105] Iteration 10000, lr = 0.1
I1006 15:23:58.383464  2964 solver.cpp:218] Iteration 10100 (11.9767 iter/s, 8.34952s/100 iters), loss = 0.268194
I1006 15:23:58.383496  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.268194 (* 1 = 0.268194 loss)
I1006 15:23:58.383513  2964 sgd_solver.cpp:105] Iteration 10100, lr = 0.1
I1006 15:24:06.792102  2964 solver.cpp:218] Iteration 10200 (11.8926 iter/s, 8.40857s/100 iters), loss = 0.29775
I1006 15:24:06.792166  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.29775 (* 1 = 0.29775 loss)
I1006 15:24:06.792188  2964 sgd_solver.cpp:105] Iteration 10200, lr = 0.1
I1006 15:24:15.545831  2964 solver.cpp:218] Iteration 10300 (11.4239 iter/s, 8.7536s/100 iters), loss = 0.432258
I1006 15:24:15.545871  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.432258 (* 1 = 0.432258 loss)
I1006 15:24:15.545889  2964 sgd_solver.cpp:105] Iteration 10300, lr = 0.1
I1006 15:24:23.890010  2964 solver.cpp:218] Iteration 10400 (11.9845 iter/s, 8.34411s/100 iters), loss = 0.244527
I1006 15:24:23.890157  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.244527 (* 1 = 0.244527 loss)
I1006 15:24:23.890177  2964 sgd_solver.cpp:105] Iteration 10400, lr = 0.1
I1006 15:24:31.871634  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 15:24:32.205138  2964 solver.cpp:330] Iteration 10500, Testing net (#0)
I1006 15:24:34.143329  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 15:24:34.223763  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7343
I1006 15:24:34.223798  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.848703 (* 1 = 0.848703 loss)
I1006 15:24:34.306854  2964 solver.cpp:218] Iteration 10500 (9.6 iter/s, 10.4167s/100 iters), loss = 0.268314
I1006 15:24:34.306879  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.268314 (* 1 = 0.268314 loss)
I1006 15:24:34.306885  2964 sgd_solver.cpp:105] Iteration 10500, lr = 0.1
I1006 15:24:42.732271  2964 solver.cpp:218] Iteration 10600 (11.8689 iter/s, 8.42535s/100 iters), loss = 0.201832
I1006 15:24:42.732332  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.201832 (* 1 = 0.201832 loss)
I1006 15:24:42.732342  2964 sgd_solver.cpp:105] Iteration 10600, lr = 0.1
I1006 15:24:51.171416  2964 solver.cpp:218] Iteration 10700 (11.8497 iter/s, 8.43902s/100 iters), loss = 0.358344
I1006 15:24:51.171454  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.358344 (* 1 = 0.358344 loss)
I1006 15:24:51.171474  2964 sgd_solver.cpp:105] Iteration 10700, lr = 0.1
I1006 15:24:59.607672  2964 solver.cpp:218] Iteration 10800 (11.8537 iter/s, 8.43619s/100 iters), loss = 0.242627
I1006 15:24:59.607789  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.242627 (* 1 = 0.242627 loss)
I1006 15:24:59.607810  2964 sgd_solver.cpp:105] Iteration 10800, lr = 0.1
I1006 15:25:08.045437  2964 solver.cpp:218] Iteration 10900 (11.8517 iter/s, 8.43763s/100 iters), loss = 0.315275
I1006 15:25:08.045471  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.315275 (* 1 = 0.315275 loss)
I1006 15:25:08.045478  2964 sgd_solver.cpp:105] Iteration 10900, lr = 0.1
I1006 15:25:16.062476  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 15:25:16.399837  2964 solver.cpp:330] Iteration 11000, Testing net (#0)
I1006 15:25:18.341403  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 15:25:18.422540  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7801
I1006 15:25:18.422567  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.650797 (* 1 = 0.650797 loss)
I1006 15:25:18.506062  2964 solver.cpp:218] Iteration 11000 (9.55972 iter/s, 10.4606s/100 iters), loss = 0.231188
I1006 15:25:18.506098  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.231188 (* 1 = 0.231188 loss)
I1006 15:25:18.506106  2964 sgd_solver.cpp:105] Iteration 11000, lr = 0.1
I1006 15:25:26.932942  2964 solver.cpp:218] Iteration 11100 (11.8669 iter/s, 8.42681s/100 iters), loss = 0.259548
I1006 15:25:26.932976  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.259548 (* 1 = 0.259548 loss)
I1006 15:25:26.932982  2964 sgd_solver.cpp:105] Iteration 11100, lr = 0.1
I1006 15:25:35.356845  2964 solver.cpp:218] Iteration 11200 (11.8711 iter/s, 8.42381s/100 iters), loss = 0.385845
I1006 15:25:35.356946  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.385846 (* 1 = 0.385846 loss)
I1006 15:25:35.356953  2964 sgd_solver.cpp:105] Iteration 11200, lr = 0.1
I1006 15:25:43.788009  2964 solver.cpp:218] Iteration 11300 (11.8609 iter/s, 8.43103s/100 iters), loss = 0.380172
I1006 15:25:43.788041  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.380172 (* 1 = 0.380172 loss)
I1006 15:25:43.788048  2964 sgd_solver.cpp:105] Iteration 11300, lr = 0.1
I1006 15:25:52.209030  2964 solver.cpp:218] Iteration 11400 (11.8751 iter/s, 8.42096s/100 iters), loss = 0.182356
I1006 15:25:52.209064  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.182356 (* 1 = 0.182356 loss)
I1006 15:25:52.209069  2964 sgd_solver.cpp:105] Iteration 11400, lr = 0.1
I1006 15:26:00.221427  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 15:26:00.563731  2964 solver.cpp:330] Iteration 11500, Testing net (#0)
I1006 15:26:02.506964  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 15:26:02.588106  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.786
I1006 15:26:02.588141  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.63315 (* 1 = 0.63315 loss)
I1006 15:26:02.671527  2964 solver.cpp:218] Iteration 11500 (9.55801 iter/s, 10.4624s/100 iters), loss = 0.267362
I1006 15:26:02.671560  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.267362 (* 1 = 0.267362 loss)
I1006 15:26:02.671566  2964 sgd_solver.cpp:105] Iteration 11500, lr = 0.1
I1006 15:26:11.104920  2964 solver.cpp:218] Iteration 11600 (11.8577 iter/s, 8.43333s/100 iters), loss = 0.296918
I1006 15:26:11.105046  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.296918 (* 1 = 0.296918 loss)
I1006 15:26:11.105062  2964 sgd_solver.cpp:105] Iteration 11600, lr = 0.1
I1006 15:26:19.527284  2964 solver.cpp:218] Iteration 11700 (11.8734 iter/s, 8.42222s/100 iters), loss = 0.29956
I1006 15:26:19.527317  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.29956 (* 1 = 0.29956 loss)
I1006 15:26:19.527323  2964 sgd_solver.cpp:105] Iteration 11700, lr = 0.1
I1006 15:26:27.956152  2964 solver.cpp:218] Iteration 11800 (11.8641 iter/s, 8.4288s/100 iters), loss = 0.31594
I1006 15:26:27.956184  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.31594 (* 1 = 0.31594 loss)
I1006 15:26:27.956190  2964 sgd_solver.cpp:105] Iteration 11800, lr = 0.1
I1006 15:26:36.374555  2964 solver.cpp:218] Iteration 11900 (11.8788 iter/s, 8.41834s/100 iters), loss = 0.250986
I1006 15:26:36.374601  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.250986 (* 1 = 0.250986 loss)
I1006 15:26:36.374608  2964 sgd_solver.cpp:105] Iteration 11900, lr = 0.1
I1006 15:26:44.380903  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 15:26:44.717912  2964 solver.cpp:330] Iteration 12000, Testing net (#0)
I1006 15:26:46.660333  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 15:26:46.741319  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7212
I1006 15:26:46.741355  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.830793 (* 1 = 0.830793 loss)
I1006 15:26:46.824592  2964 solver.cpp:218] Iteration 12000 (9.56942 iter/s, 10.45s/100 iters), loss = 0.358873
I1006 15:26:46.824625  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.358873 (* 1 = 0.358873 loss)
I1006 15:26:46.824630  2964 sgd_solver.cpp:105] Iteration 12000, lr = 0.1
I1006 15:26:55.258527  2964 solver.cpp:218] Iteration 12100 (11.857 iter/s, 8.43387s/100 iters), loss = 0.216041
I1006 15:26:55.258569  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.216041 (* 1 = 0.216041 loss)
I1006 15:26:55.258575  2964 sgd_solver.cpp:105] Iteration 12100, lr = 0.1
I1006 15:27:03.691051  2964 solver.cpp:218] Iteration 12200 (11.8589 iter/s, 8.43245s/100 iters), loss = 0.256031
I1006 15:27:03.691085  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.256031 (* 1 = 0.256031 loss)
I1006 15:27:03.691092  2964 sgd_solver.cpp:105] Iteration 12200, lr = 0.1
I1006 15:27:12.122750  2964 solver.cpp:218] Iteration 12300 (11.8601 iter/s, 8.43163s/100 iters), loss = 0.424682
I1006 15:27:12.122782  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.424682 (* 1 = 0.424682 loss)
I1006 15:27:12.122789  2964 sgd_solver.cpp:105] Iteration 12300, lr = 0.1
I1006 15:27:20.558347  2964 solver.cpp:218] Iteration 12400 (11.8546 iter/s, 8.43553s/100 iters), loss = 0.204654
I1006 15:27:20.558490  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.204654 (* 1 = 0.204654 loss)
I1006 15:27:20.558497  2964 sgd_solver.cpp:105] Iteration 12400, lr = 0.1
I1006 15:27:28.577458  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 15:27:28.915930  2964 solver.cpp:330] Iteration 12500, Testing net (#0)
I1006 15:27:30.859374  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 15:27:30.940645  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.726
I1006 15:27:30.940670  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.902141 (* 1 = 0.902141 loss)
I1006 15:27:31.023947  2964 solver.cpp:218] Iteration 12500 (9.55528 iter/s, 10.4654s/100 iters), loss = 0.236247
I1006 15:27:31.023979  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.236247 (* 1 = 0.236247 loss)
I1006 15:27:31.023986  2964 sgd_solver.cpp:105] Iteration 12500, lr = 0.1
I1006 15:27:39.446364  2964 solver.cpp:218] Iteration 12600 (11.8732 iter/s, 8.42235s/100 iters), loss = 0.301922
I1006 15:27:39.446398  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.301922 (* 1 = 0.301922 loss)
I1006 15:27:39.446404  2964 sgd_solver.cpp:105] Iteration 12600, lr = 0.1
I1006 15:27:47.869771  2964 solver.cpp:218] Iteration 12700 (11.8718 iter/s, 8.42334s/100 iters), loss = 0.215491
I1006 15:27:47.869802  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.215491 (* 1 = 0.215491 loss)
I1006 15:27:47.869808  2964 sgd_solver.cpp:105] Iteration 12700, lr = 0.1
I1006 15:27:56.284041  2964 solver.cpp:218] Iteration 12800 (11.8847 iter/s, 8.41421s/100 iters), loss = 0.305931
I1006 15:27:56.284173  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.305931 (* 1 = 0.305931 loss)
I1006 15:27:56.284181  2964 sgd_solver.cpp:105] Iteration 12800, lr = 0.1
I1006 15:28:04.707973  2964 solver.cpp:218] Iteration 12900 (11.8714 iter/s, 8.42363s/100 iters), loss = 0.269426
I1006 15:28:04.708006  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.269426 (* 1 = 0.269426 loss)
I1006 15:28:04.708014  2964 sgd_solver.cpp:105] Iteration 12900, lr = 0.1
I1006 15:28:12.715605  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 15:28:13.052304  2964 solver.cpp:330] Iteration 13000, Testing net (#0)
I1006 15:28:14.996219  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 15:28:15.076800  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7536
I1006 15:28:15.076836  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.752685 (* 1 = 0.752685 loss)
I1006 15:28:15.160688  2964 solver.cpp:218] Iteration 13000 (9.56696 iter/s, 10.4526s/100 iters), loss = 0.25841
I1006 15:28:15.160719  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.25841 (* 1 = 0.25841 loss)
I1006 15:28:15.160725  2964 sgd_solver.cpp:105] Iteration 13000, lr = 0.1
I1006 15:28:23.585645  2964 solver.cpp:218] Iteration 13100 (11.8696 iter/s, 8.42489s/100 iters), loss = 0.151513
I1006 15:28:23.585678  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.151513 (* 1 = 0.151513 loss)
I1006 15:28:23.585686  2964 sgd_solver.cpp:105] Iteration 13100, lr = 0.1
I1006 15:28:32.005609  2964 solver.cpp:218] Iteration 13200 (11.8766 iter/s, 8.4199s/100 iters), loss = 0.285424
I1006 15:28:32.005744  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.285425 (* 1 = 0.285425 loss)
I1006 15:28:32.005766  2964 sgd_solver.cpp:105] Iteration 13200, lr = 0.1
I1006 15:28:40.430349  2964 solver.cpp:218] Iteration 13300 (11.87 iter/s, 8.42458s/100 iters), loss = 0.246792
I1006 15:28:40.430384  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.246792 (* 1 = 0.246792 loss)
I1006 15:28:40.430392  2964 sgd_solver.cpp:105] Iteration 13300, lr = 0.1
I1006 15:28:48.853060  2964 solver.cpp:218] Iteration 13400 (11.8728 iter/s, 8.42264s/100 iters), loss = 0.18052
I1006 15:28:48.853096  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.18052 (* 1 = 0.18052 loss)
I1006 15:28:48.853114  2964 sgd_solver.cpp:105] Iteration 13400, lr = 0.1
I1006 15:28:56.861274  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 15:28:57.198793  2964 solver.cpp:330] Iteration 13500, Testing net (#0)
I1006 15:28:59.140017  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 15:28:59.220749  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6533
I1006 15:28:59.220785  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.24687 (* 1 = 1.24687 loss)
I1006 15:28:59.304323  2964 solver.cpp:218] Iteration 13500 (9.56829 iter/s, 10.4512s/100 iters), loss = 0.286672
I1006 15:28:59.304354  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.286672 (* 1 = 0.286672 loss)
I1006 15:28:59.304361  2964 sgd_solver.cpp:105] Iteration 13500, lr = 0.1
I1006 15:29:07.740356  2964 solver.cpp:218] Iteration 13600 (11.854 iter/s, 8.43597s/100 iters), loss = 0.295271
I1006 15:29:07.740494  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.295271 (* 1 = 0.295271 loss)
I1006 15:29:07.740512  2964 sgd_solver.cpp:105] Iteration 13600, lr = 0.1
I1006 15:29:16.180208  2964 solver.cpp:218] Iteration 13700 (11.8488 iter/s, 8.4397s/100 iters), loss = 0.259051
I1006 15:29:16.180241  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.259051 (* 1 = 0.259051 loss)
I1006 15:29:16.180248  2964 sgd_solver.cpp:105] Iteration 13700, lr = 0.1
I1006 15:29:24.620784  2964 solver.cpp:218] Iteration 13800 (11.8476 iter/s, 8.44051s/100 iters), loss = 0.265736
I1006 15:29:24.620815  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.265736 (* 1 = 0.265736 loss)
I1006 15:29:24.620821  2964 sgd_solver.cpp:105] Iteration 13800, lr = 0.1
I1006 15:29:33.057153  2964 solver.cpp:218] Iteration 13900 (11.8535 iter/s, 8.43631s/100 iters), loss = 0.30536
I1006 15:29:33.057186  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.30536 (* 1 = 0.30536 loss)
I1006 15:29:33.057193  2964 sgd_solver.cpp:105] Iteration 13900, lr = 0.1
I1006 15:29:41.070147  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 15:29:41.409103  2964 solver.cpp:330] Iteration 14000, Testing net (#0)
I1006 15:29:43.350896  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 15:29:43.431439  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7501
I1006 15:29:43.431475  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.818788 (* 1 = 0.818788 loss)
I1006 15:29:43.515173  2964 solver.cpp:218] Iteration 14000 (9.5621 iter/s, 10.458s/100 iters), loss = 0.267527
I1006 15:29:43.515204  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.267527 (* 1 = 0.267527 loss)
I1006 15:29:43.515211  2964 sgd_solver.cpp:105] Iteration 14000, lr = 0.1
I1006 15:29:51.942600  2964 solver.cpp:218] Iteration 14100 (11.8661 iter/s, 8.42736s/100 iters), loss = 0.253392
I1006 15:29:51.942633  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.253392 (* 1 = 0.253392 loss)
I1006 15:29:51.942639  2964 sgd_solver.cpp:105] Iteration 14100, lr = 0.1
I1006 15:30:00.378509  2964 solver.cpp:218] Iteration 14200 (11.8542 iter/s, 8.43584s/100 iters), loss = 0.253815
I1006 15:30:00.378551  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.253815 (* 1 = 0.253815 loss)
I1006 15:30:00.378558  2964 sgd_solver.cpp:105] Iteration 14200, lr = 0.1
I1006 15:30:08.808771  2964 solver.cpp:218] Iteration 14300 (11.8621 iter/s, 8.43019s/100 iters), loss = 0.277328
I1006 15:30:08.808804  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.277328 (* 1 = 0.277328 loss)
I1006 15:30:08.808811  2964 sgd_solver.cpp:105] Iteration 14300, lr = 0.1
I1006 15:30:17.238920  2964 solver.cpp:218] Iteration 14400 (11.8623 iter/s, 8.43009s/100 iters), loss = 0.225459
I1006 15:30:17.239019  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.225459 (* 1 = 0.225459 loss)
I1006 15:30:17.239027  2964 sgd_solver.cpp:105] Iteration 14400, lr = 0.1
I1006 15:30:25.258404  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 15:30:25.595846  2964 solver.cpp:330] Iteration 14500, Testing net (#0)
I1006 15:30:27.540439  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 15:30:27.621285  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7536
I1006 15:30:27.621321  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.740369 (* 1 = 0.740369 loss)
I1006 15:30:27.704689  2964 solver.cpp:218] Iteration 14500 (9.55508 iter/s, 10.4656s/100 iters), loss = 0.263604
I1006 15:30:27.704720  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.263603 (* 1 = 0.263603 loss)
I1006 15:30:27.704728  2964 sgd_solver.cpp:105] Iteration 14500, lr = 0.1
I1006 15:30:36.136044  2964 solver.cpp:218] Iteration 14600 (11.8606 iter/s, 8.43129s/100 iters), loss = 0.280746
I1006 15:30:36.136076  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.280746 (* 1 = 0.280746 loss)
I1006 15:30:36.136083  2964 sgd_solver.cpp:105] Iteration 14600, lr = 0.1
I1006 15:30:44.563511  2964 solver.cpp:218] Iteration 14700 (11.866 iter/s, 8.4274s/100 iters), loss = 0.337028
I1006 15:30:44.563544  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.337028 (* 1 = 0.337028 loss)
I1006 15:30:44.563550  2964 sgd_solver.cpp:105] Iteration 14700, lr = 0.1
I1006 15:30:52.979655  2964 solver.cpp:218] Iteration 14800 (11.882 iter/s, 8.41608s/100 iters), loss = 0.218965
I1006 15:30:52.979787  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.218965 (* 1 = 0.218965 loss)
I1006 15:30:52.979805  2964 sgd_solver.cpp:105] Iteration 14800, lr = 0.1
I1006 15:31:01.408350  2964 solver.cpp:218] Iteration 14900 (11.8645 iter/s, 8.42854s/100 iters), loss = 0.240884
I1006 15:31:01.408396  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.240884 (* 1 = 0.240884 loss)
I1006 15:31:01.408403  2964 sgd_solver.cpp:105] Iteration 14900, lr = 0.1
I1006 15:31:09.412968  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 15:31:09.750013  2964 solver.cpp:330] Iteration 15000, Testing net (#0)
I1006 15:31:11.694238  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 15:31:11.775252  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7359
I1006 15:31:11.775277  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.874884 (* 1 = 0.874884 loss)
I1006 15:31:11.858541  2964 solver.cpp:218] Iteration 15000 (9.56928 iter/s, 10.4501s/100 iters), loss = 0.198784
I1006 15:31:11.858572  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.198784 (* 1 = 0.198784 loss)
I1006 15:31:11.858578  2964 sgd_solver.cpp:105] Iteration 15000, lr = 0.1
I1006 15:31:20.285915  2964 solver.cpp:218] Iteration 15100 (11.8662 iter/s, 8.42731s/100 iters), loss = 0.179697
I1006 15:31:20.285949  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.179697 (* 1 = 0.179697 loss)
I1006 15:31:20.285966  2964 sgd_solver.cpp:105] Iteration 15100, lr = 0.1
I1006 15:31:28.721388  2964 solver.cpp:218] Iteration 15200 (11.8548 iter/s, 8.43541s/100 iters), loss = 0.256546
I1006 15:31:28.721523  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.256546 (* 1 = 0.256546 loss)
I1006 15:31:28.721531  2964 sgd_solver.cpp:105] Iteration 15200, lr = 0.1
I1006 15:31:37.150888  2964 solver.cpp:218] Iteration 15300 (11.8633 iter/s, 8.42935s/100 iters), loss = 0.303072
I1006 15:31:37.150921  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.303072 (* 1 = 0.303072 loss)
I1006 15:31:37.150928  2964 sgd_solver.cpp:105] Iteration 15300, lr = 0.1
I1006 15:31:45.579882  2964 solver.cpp:218] Iteration 15400 (11.8639 iter/s, 8.42893s/100 iters), loss = 0.241766
I1006 15:31:45.579916  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.241766 (* 1 = 0.241766 loss)
I1006 15:31:45.579921  2964 sgd_solver.cpp:105] Iteration 15400, lr = 0.1
I1006 15:31:53.591442  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 15:31:53.928828  2964 solver.cpp:330] Iteration 15500, Testing net (#0)
I1006 15:31:55.871217  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 15:31:55.951912  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8173
I1006 15:31:55.951937  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.538096 (* 1 = 0.538096 loss)
I1006 15:31:56.037135  2964 solver.cpp:218] Iteration 15500 (9.56281 iter/s, 10.4572s/100 iters), loss = 0.342968
I1006 15:31:56.037169  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.342968 (* 1 = 0.342968 loss)
I1006 15:31:56.037178  2964 sgd_solver.cpp:105] Iteration 15500, lr = 0.1
I1006 15:32:04.460434  2964 solver.cpp:218] Iteration 15600 (11.8719 iter/s, 8.42323s/100 iters), loss = 0.367426
I1006 15:32:04.460590  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.367426 (* 1 = 0.367426 loss)
I1006 15:32:04.460609  2964 sgd_solver.cpp:105] Iteration 15600, lr = 0.1
I1006 15:32:12.887418  2964 solver.cpp:218] Iteration 15700 (11.8669 iter/s, 8.42681s/100 iters), loss = 0.314226
I1006 15:32:12.887451  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.314226 (* 1 = 0.314226 loss)
I1006 15:32:12.887459  2964 sgd_solver.cpp:105] Iteration 15700, lr = 0.1
I1006 15:32:21.310791  2964 solver.cpp:218] Iteration 15800 (11.8718 iter/s, 8.42331s/100 iters), loss = 0.325555
I1006 15:32:21.310823  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.325555 (* 1 = 0.325555 loss)
I1006 15:32:21.310839  2964 sgd_solver.cpp:105] Iteration 15800, lr = 0.1
I1006 15:32:29.740321  2964 solver.cpp:218] Iteration 15900 (11.8631 iter/s, 8.42947s/100 iters), loss = 0.2392
I1006 15:32:29.740353  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.2392 (* 1 = 0.2392 loss)
I1006 15:32:29.740360  2964 sgd_solver.cpp:105] Iteration 15900, lr = 0.1
I1006 15:32:37.753003  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 15:32:38.090965  2964 solver.cpp:330] Iteration 16000, Testing net (#0)
I1006 15:32:40.034556  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 15:32:40.114670  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7842
I1006 15:32:40.114704  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.682828 (* 1 = 0.682828 loss)
I1006 15:32:40.198545  2964 solver.cpp:218] Iteration 16000 (9.56192 iter/s, 10.4582s/100 iters), loss = 0.222048
I1006 15:32:40.198580  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.222048 (* 1 = 0.222048 loss)
I1006 15:32:40.198585  2964 sgd_solver.cpp:105] Iteration 16000, lr = 0.1
I1006 15:32:48.636716  2964 solver.cpp:218] Iteration 16100 (11.851 iter/s, 8.4381s/100 iters), loss = 0.221313
I1006 15:32:48.636749  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.221313 (* 1 = 0.221313 loss)
I1006 15:32:48.636755  2964 sgd_solver.cpp:105] Iteration 16100, lr = 0.1
I1006 15:32:57.067023  2964 solver.cpp:218] Iteration 16200 (11.8621 iter/s, 8.43024s/100 iters), loss = 0.226067
I1006 15:32:57.067055  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.226067 (* 1 = 0.226067 loss)
I1006 15:32:57.067061  2964 sgd_solver.cpp:105] Iteration 16200, lr = 0.1
I1006 15:33:05.503275  2964 solver.cpp:218] Iteration 16300 (11.8537 iter/s, 8.43619s/100 iters), loss = 0.325854
I1006 15:33:05.503307  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.325854 (* 1 = 0.325854 loss)
I1006 15:33:05.503314  2964 sgd_solver.cpp:105] Iteration 16300, lr = 0.1
I1006 15:33:13.937402  2964 solver.cpp:218] Iteration 16400 (11.8567 iter/s, 8.43406s/100 iters), loss = 0.216001
I1006 15:33:13.937531  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.216001 (* 1 = 0.216001 loss)
I1006 15:33:13.937539  2964 sgd_solver.cpp:105] Iteration 16400, lr = 0.1
I1006 15:33:21.961645  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 15:33:22.300401  2964 solver.cpp:330] Iteration 16500, Testing net (#0)
I1006 15:33:24.243818  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 15:33:24.324602  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7654
I1006 15:33:24.324630  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.780277 (* 1 = 0.780277 loss)
I1006 15:33:24.408335  2964 solver.cpp:218] Iteration 16500 (9.5504 iter/s, 10.4708s/100 iters), loss = 0.234139
I1006 15:33:24.408368  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.234139 (* 1 = 0.234139 loss)
I1006 15:33:24.408377  2964 sgd_solver.cpp:105] Iteration 16500, lr = 0.1
I1006 15:33:32.837487  2964 solver.cpp:218] Iteration 16600 (11.8637 iter/s, 8.42909s/100 iters), loss = 0.16811
I1006 15:33:32.837525  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.16811 (* 1 = 0.16811 loss)
I1006 15:33:32.837534  2964 sgd_solver.cpp:105] Iteration 16600, lr = 0.1
I1006 15:33:41.264814  2964 solver.cpp:218] Iteration 16700 (11.8663 iter/s, 8.42726s/100 iters), loss = 0.249433
I1006 15:33:41.264847  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.249433 (* 1 = 0.249433 loss)
I1006 15:33:41.264853  2964 sgd_solver.cpp:105] Iteration 16700, lr = 0.1
I1006 15:33:49.695472  2964 solver.cpp:218] Iteration 16800 (11.8616 iter/s, 8.43059s/100 iters), loss = 0.259549
I1006 15:33:49.695616  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.259549 (* 1 = 0.259549 loss)
I1006 15:33:49.695633  2964 sgd_solver.cpp:105] Iteration 16800, lr = 0.1
I1006 15:33:58.121652  2964 solver.cpp:218] Iteration 16900 (11.868 iter/s, 8.42601s/100 iters), loss = 0.245574
I1006 15:33:58.121683  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.245574 (* 1 = 0.245574 loss)
I1006 15:33:58.121690  2964 sgd_solver.cpp:105] Iteration 16900, lr = 0.1
I1006 15:34:06.133419  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 15:34:06.473850  2964 solver.cpp:330] Iteration 17000, Testing net (#0)
I1006 15:34:08.417397  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 15:34:08.498401  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7988
I1006 15:34:08.498427  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.637911 (* 1 = 0.637911 loss)
I1006 15:34:08.582324  2964 solver.cpp:218] Iteration 17000 (9.55968 iter/s, 10.4606s/100 iters), loss = 0.297826
I1006 15:34:08.582355  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.297826 (* 1 = 0.297826 loss)
I1006 15:34:08.582362  2964 sgd_solver.cpp:105] Iteration 17000, lr = 0.1
I1006 15:34:17.019938  2964 solver.cpp:218] Iteration 17100 (11.8518 iter/s, 8.43752s/100 iters), loss = 0.150198
I1006 15:34:17.019970  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.150198 (* 1 = 0.150198 loss)
I1006 15:34:17.019976  2964 sgd_solver.cpp:105] Iteration 17100, lr = 0.1
I1006 15:34:25.452807  2964 solver.cpp:218] Iteration 17200 (11.8584 iter/s, 8.43281s/100 iters), loss = 0.395444
I1006 15:34:25.452952  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.395444 (* 1 = 0.395444 loss)
I1006 15:34:25.452961  2964 sgd_solver.cpp:105] Iteration 17200, lr = 0.1
I1006 15:34:33.893218  2964 solver.cpp:218] Iteration 17300 (11.848 iter/s, 8.44024s/100 iters), loss = 0.23694
I1006 15:34:33.893250  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.23694 (* 1 = 0.23694 loss)
I1006 15:34:33.893257  2964 sgd_solver.cpp:105] Iteration 17300, lr = 0.1
I1006 15:34:42.328522  2964 solver.cpp:218] Iteration 17400 (11.855 iter/s, 8.43524s/100 iters), loss = 0.256362
I1006 15:34:42.328554  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.256362 (* 1 = 0.256362 loss)
I1006 15:34:42.328562  2964 sgd_solver.cpp:105] Iteration 17400, lr = 0.1
I1006 15:34:50.341713  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 15:34:50.678771  2964 solver.cpp:330] Iteration 17500, Testing net (#0)
I1006 15:34:52.624994  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 15:34:52.705632  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7893
I1006 15:34:52.705667  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.64866 (* 1 = 0.64866 loss)
I1006 15:34:52.789363  2964 solver.cpp:218] Iteration 17500 (9.55952 iter/s, 10.4608s/100 iters), loss = 0.221335
I1006 15:34:52.789397  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.221335 (* 1 = 0.221335 loss)
I1006 15:34:52.789404  2964 sgd_solver.cpp:105] Iteration 17500, lr = 0.1
I1006 15:35:01.221442  2964 solver.cpp:218] Iteration 17600 (11.8596 iter/s, 8.43201s/100 iters), loss = 0.229714
I1006 15:35:01.221576  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.229714 (* 1 = 0.229714 loss)
I1006 15:35:01.221596  2964 sgd_solver.cpp:105] Iteration 17600, lr = 0.1
I1006 15:35:09.652591  2964 solver.cpp:218] Iteration 17700 (11.861 iter/s, 8.43099s/100 iters), loss = 0.341267
I1006 15:35:09.652629  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.341267 (* 1 = 0.341267 loss)
I1006 15:35:09.652638  2964 sgd_solver.cpp:105] Iteration 17700, lr = 0.1
I1006 15:35:18.085486  2964 solver.cpp:218] Iteration 17800 (11.8585 iter/s, 8.43279s/100 iters), loss = 0.300073
I1006 15:35:18.085520  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.300072 (* 1 = 0.300072 loss)
I1006 15:35:18.085527  2964 sgd_solver.cpp:105] Iteration 17800, lr = 0.1
I1006 15:35:26.519687  2964 solver.cpp:218] Iteration 17900 (11.8566 iter/s, 8.43414s/100 iters), loss = 0.198018
I1006 15:35:26.519722  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.198018 (* 1 = 0.198018 loss)
I1006 15:35:26.519728  2964 sgd_solver.cpp:105] Iteration 17900, lr = 0.1
I1006 15:35:34.530028  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 15:35:34.867765  2964 solver.cpp:330] Iteration 18000, Testing net (#0)
I1006 15:35:36.812178  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 15:35:36.893684  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8361
I1006 15:35:36.893720  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.477911 (* 1 = 0.477911 loss)
I1006 15:35:36.977689  2964 solver.cpp:218] Iteration 18000 (9.56212 iter/s, 10.4579s/100 iters), loss = 0.295091
I1006 15:35:36.977721  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.295091 (* 1 = 0.295091 loss)
I1006 15:35:36.977727  2964 sgd_solver.cpp:105] Iteration 18000, lr = 0.1
I1006 15:35:45.414470  2964 solver.cpp:218] Iteration 18100 (11.8529 iter/s, 8.43672s/100 iters), loss = 0.261982
I1006 15:35:45.414513  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.261982 (* 1 = 0.261982 loss)
I1006 15:35:45.414520  2964 sgd_solver.cpp:105] Iteration 18100, lr = 0.1
I1006 15:35:53.843125  2964 solver.cpp:218] Iteration 18200 (11.8644 iter/s, 8.42858s/100 iters), loss = 0.216308
I1006 15:35:53.843181  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.216308 (* 1 = 0.216308 loss)
I1006 15:35:53.843190  2964 sgd_solver.cpp:105] Iteration 18200, lr = 0.1
I1006 15:36:02.268612  2964 solver.cpp:218] Iteration 18300 (11.8689 iter/s, 8.42542s/100 iters), loss = 0.362716
I1006 15:36:02.268646  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.362716 (* 1 = 0.362716 loss)
I1006 15:36:02.268653  2964 sgd_solver.cpp:105] Iteration 18300, lr = 0.1
I1006 15:36:10.691200  2964 solver.cpp:218] Iteration 18400 (11.8729 iter/s, 8.42252s/100 iters), loss = 0.249623
I1006 15:36:10.691356  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.249623 (* 1 = 0.249623 loss)
I1006 15:36:10.691377  2964 sgd_solver.cpp:105] Iteration 18400, lr = 0.1
I1006 15:36:18.704377  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 15:36:19.042079  2964 solver.cpp:330] Iteration 18500, Testing net (#0)
I1006 15:36:20.984699  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 15:36:21.065454  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7615
I1006 15:36:21.065480  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.782755 (* 1 = 0.782755 loss)
I1006 15:36:21.149581  2964 solver.cpp:218] Iteration 18500 (9.56188 iter/s, 10.4582s/100 iters), loss = 0.410135
I1006 15:36:21.149613  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.410135 (* 1 = 0.410135 loss)
I1006 15:36:21.149621  2964 sgd_solver.cpp:105] Iteration 18500, lr = 0.1
I1006 15:36:29.592706  2964 solver.cpp:218] Iteration 18600 (11.844 iter/s, 8.44306s/100 iters), loss = 0.262898
I1006 15:36:29.592738  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.262898 (* 1 = 0.262898 loss)
I1006 15:36:29.592746  2964 sgd_solver.cpp:105] Iteration 18600, lr = 0.1
I1006 15:36:38.027626  2964 solver.cpp:218] Iteration 18700 (11.8556 iter/s, 8.43486s/100 iters), loss = 0.263069
I1006 15:36:38.027658  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.263069 (* 1 = 0.263069 loss)
I1006 15:36:38.027665  2964 sgd_solver.cpp:105] Iteration 18700, lr = 0.1
I1006 15:36:46.467504  2964 solver.cpp:218] Iteration 18800 (11.8486 iter/s, 8.43982s/100 iters), loss = 0.182584
I1006 15:36:46.467618  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.182584 (* 1 = 0.182584 loss)
I1006 15:36:46.467628  2964 sgd_solver.cpp:105] Iteration 18800, lr = 0.1
I1006 15:36:54.901634  2964 solver.cpp:218] Iteration 18900 (11.8568 iter/s, 8.434s/100 iters), loss = 0.204004
I1006 15:36:54.901666  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.204004 (* 1 = 0.204004 loss)
I1006 15:36:54.901674  2964 sgd_solver.cpp:105] Iteration 18900, lr = 0.1
I1006 15:37:02.917873  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 15:37:03.255574  2964 solver.cpp:330] Iteration 19000, Testing net (#0)
I1006 15:37:05.198168  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 15:37:05.278686  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7843
I1006 15:37:05.278726  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.647258 (* 1 = 0.647258 loss)
I1006 15:37:05.362819  2964 solver.cpp:218] Iteration 19000 (9.55921 iter/s, 10.4611s/100 iters), loss = 0.269992
I1006 15:37:05.362851  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.269992 (* 1 = 0.269992 loss)
I1006 15:37:05.362859  2964 sgd_solver.cpp:105] Iteration 19000, lr = 0.1
I1006 15:37:13.799479  2964 solver.cpp:218] Iteration 19100 (11.8531 iter/s, 8.43659s/100 iters), loss = 0.188875
I1006 15:37:13.799522  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.188875 (* 1 = 0.188875 loss)
I1006 15:37:13.799530  2964 sgd_solver.cpp:105] Iteration 19100, lr = 0.1
I1006 15:37:22.234012  2964 solver.cpp:218] Iteration 19200 (11.8561 iter/s, 8.43446s/100 iters), loss = 0.274187
I1006 15:37:22.234220  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.274187 (* 1 = 0.274187 loss)
I1006 15:37:22.234231  2964 sgd_solver.cpp:105] Iteration 19200, lr = 0.1
I1006 15:37:30.670950  2964 solver.cpp:218] Iteration 19300 (11.853 iter/s, 8.43667s/100 iters), loss = 0.230552
I1006 15:37:30.670991  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.230552 (* 1 = 0.230552 loss)
I1006 15:37:30.670999  2964 sgd_solver.cpp:105] Iteration 19300, lr = 0.1
I1006 15:37:39.104449  2964 solver.cpp:218] Iteration 19400 (11.8576 iter/s, 8.43343s/100 iters), loss = 0.222802
I1006 15:37:39.104480  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.222802 (* 1 = 0.222802 loss)
I1006 15:37:39.104487  2964 sgd_solver.cpp:105] Iteration 19400, lr = 0.1
I1006 15:37:47.127426  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 15:37:47.464085  2964 solver.cpp:330] Iteration 19500, Testing net (#0)
I1006 15:37:49.406296  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 15:37:49.487851  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7827
I1006 15:37:49.487876  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.660938 (* 1 = 0.660938 loss)
I1006 15:37:49.571661  2964 solver.cpp:218] Iteration 19500 (9.5537 iter/s, 10.4671s/100 iters), loss = 0.216856
I1006 15:37:49.571692  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.216856 (* 1 = 0.216856 loss)
I1006 15:37:49.571698  2964 sgd_solver.cpp:105] Iteration 19500, lr = 0.1
I1006 15:37:58.002135  2964 solver.cpp:218] Iteration 19600 (11.8618 iter/s, 8.43041s/100 iters), loss = 0.24185
I1006 15:37:58.002279  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.24185 (* 1 = 0.24185 loss)
I1006 15:37:58.002288  2964 sgd_solver.cpp:105] Iteration 19600, lr = 0.1
I1006 15:38:06.423122  2964 solver.cpp:218] Iteration 19700 (11.8753 iter/s, 8.42082s/100 iters), loss = 0.247943
I1006 15:38:06.423168  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.247943 (* 1 = 0.247943 loss)
I1006 15:38:06.423176  2964 sgd_solver.cpp:105] Iteration 19700, lr = 0.1
I1006 15:38:14.854038  2964 solver.cpp:218] Iteration 19800 (11.8612 iter/s, 8.43084s/100 iters), loss = 0.26259
I1006 15:38:14.854073  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.26259 (* 1 = 0.26259 loss)
I1006 15:38:14.854079  2964 sgd_solver.cpp:105] Iteration 19800, lr = 0.1
I1006 15:38:23.281431  2964 solver.cpp:218] Iteration 19900 (11.8662 iter/s, 8.42733s/100 iters), loss = 0.195542
I1006 15:38:23.281463  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.195542 (* 1 = 0.195542 loss)
I1006 15:38:23.281471  2964 sgd_solver.cpp:105] Iteration 19900, lr = 0.1
I1006 15:38:31.288440  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 15:38:31.626811  2964 solver.cpp:330] Iteration 20000, Testing net (#0)
I1006 15:38:33.571723  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 15:38:33.652798  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8166
I1006 15:38:33.652824  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.51828 (* 1 = 0.51828 loss)
I1006 15:38:33.736933  2964 solver.cpp:218] Iteration 20000 (9.5644 iter/s, 10.4554s/100 iters), loss = 0.234231
I1006 15:38:33.736966  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.234231 (* 1 = 0.234231 loss)
I1006 15:38:33.736974  2964 sgd_solver.cpp:105] Iteration 20000, lr = 0.1
I1006 15:38:42.164448  2964 solver.cpp:218] Iteration 20100 (11.866 iter/s, 8.42745s/100 iters), loss = 0.219818
I1006 15:38:42.164479  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.219818 (* 1 = 0.219818 loss)
I1006 15:38:42.164485  2964 sgd_solver.cpp:105] Iteration 20100, lr = 0.1
I1006 15:38:50.589454  2964 solver.cpp:218] Iteration 20200 (11.8695 iter/s, 8.42494s/100 iters), loss = 0.208765
I1006 15:38:50.589486  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.208765 (* 1 = 0.208765 loss)
I1006 15:38:50.589493  2964 sgd_solver.cpp:105] Iteration 20200, lr = 0.1
I1006 15:38:59.068114  2964 solver.cpp:218] Iteration 20300 (11.7944 iter/s, 8.4786s/100 iters), loss = 0.221758
I1006 15:38:59.068150  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.221758 (* 1 = 0.221758 loss)
I1006 15:38:59.068157  2964 sgd_solver.cpp:105] Iteration 20300, lr = 0.1
I1006 15:39:07.485616  2964 solver.cpp:218] Iteration 20400 (11.8801 iter/s, 8.41743s/100 iters), loss = 0.168653
I1006 15:39:07.485761  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.168653 (* 1 = 0.168653 loss)
I1006 15:39:07.485780  2964 sgd_solver.cpp:105] Iteration 20400, lr = 0.1
I1006 15:39:15.433966  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 15:39:15.767952  2964 solver.cpp:330] Iteration 20500, Testing net (#0)
I1006 15:39:17.690343  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 15:39:17.770828  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8027
I1006 15:39:17.770864  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.585779 (* 1 = 0.585779 loss)
I1006 15:39:17.854290  2964 solver.cpp:218] Iteration 20500 (9.64469 iter/s, 10.3684s/100 iters), loss = 0.229429
I1006 15:39:17.854313  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.229429 (* 1 = 0.229429 loss)
I1006 15:39:17.854321  2964 sgd_solver.cpp:105] Iteration 20500, lr = 0.1
I1006 15:39:26.201011  2964 solver.cpp:218] Iteration 20600 (11.9808 iter/s, 8.34667s/100 iters), loss = 0.214831
I1006 15:39:26.201053  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.214831 (* 1 = 0.214831 loss)
I1006 15:39:26.201061  2964 sgd_solver.cpp:105] Iteration 20600, lr = 0.1
I1006 15:39:34.578146  2964 solver.cpp:218] Iteration 20700 (11.9374 iter/s, 8.37706s/100 iters), loss = 0.323934
I1006 15:39:34.578177  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.323934 (* 1 = 0.323934 loss)
I1006 15:39:34.578183  2964 sgd_solver.cpp:105] Iteration 20700, lr = 0.1
I1006 15:39:42.982489  2964 solver.cpp:218] Iteration 20800 (11.8987 iter/s, 8.40428s/100 iters), loss = 0.253089
I1006 15:39:42.982595  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.253089 (* 1 = 0.253089 loss)
I1006 15:39:42.982614  2964 sgd_solver.cpp:105] Iteration 20800, lr = 0.1
I1006 15:39:51.381492  2964 solver.cpp:218] Iteration 20900 (11.9064 iter/s, 8.39887s/100 iters), loss = 0.192548
I1006 15:39:51.381522  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.192548 (* 1 = 0.192548 loss)
I1006 15:39:51.381528  2964 sgd_solver.cpp:105] Iteration 20900, lr = 0.1
I1006 15:39:59.348729  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 15:39:59.683914  2964 solver.cpp:330] Iteration 21000, Testing net (#0)
I1006 15:40:01.635596  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 15:40:01.716009  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7702
I1006 15:40:01.716044  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.698805 (* 1 = 0.698805 loss)
I1006 15:40:01.798997  2964 solver.cpp:218] Iteration 21000 (9.59929 iter/s, 10.4174s/100 iters), loss = 0.159066
I1006 15:40:01.799024  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.159066 (* 1 = 0.159066 loss)
I1006 15:40:01.799031  2964 sgd_solver.cpp:105] Iteration 21000, lr = 0.1
I1006 15:40:10.171072  2964 solver.cpp:218] Iteration 21100 (11.9446 iter/s, 8.37202s/100 iters), loss = 0.295714
I1006 15:40:10.171102  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.295714 (* 1 = 0.295714 loss)
I1006 15:40:10.171108  2964 sgd_solver.cpp:105] Iteration 21100, lr = 0.1
I1006 15:40:18.549713  2964 solver.cpp:218] Iteration 21200 (11.9352 iter/s, 8.37858s/100 iters), loss = 0.19336
I1006 15:40:18.549840  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.19336 (* 1 = 0.19336 loss)
I1006 15:40:18.549859  2964 sgd_solver.cpp:105] Iteration 21200, lr = 0.1
I1006 15:40:26.925576  2964 solver.cpp:218] Iteration 21300 (11.9393 iter/s, 8.37572s/100 iters), loss = 0.243109
I1006 15:40:26.925608  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.243109 (* 1 = 0.243109 loss)
I1006 15:40:26.925616  2964 sgd_solver.cpp:105] Iteration 21300, lr = 0.1
I1006 15:40:35.308852  2964 solver.cpp:218] Iteration 21400 (11.9286 iter/s, 8.38321s/100 iters), loss = 0.157043
I1006 15:40:35.308887  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.157043 (* 1 = 0.157043 loss)
I1006 15:40:35.308895  2964 sgd_solver.cpp:105] Iteration 21400, lr = 0.1
I1006 15:40:43.356631  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 15:40:43.692225  2964 solver.cpp:330] Iteration 21500, Testing net (#0)
I1006 15:40:45.613201  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 15:40:45.693091  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7208
I1006 15:40:45.693126  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.956192 (* 1 = 0.956192 loss)
I1006 15:40:45.776181  2964 solver.cpp:218] Iteration 21500 (9.5536 iter/s, 10.4673s/100 iters), loss = 0.198359
I1006 15:40:45.776203  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.198359 (* 1 = 0.198359 loss)
I1006 15:40:45.776209  2964 sgd_solver.cpp:105] Iteration 21500, lr = 0.1
I1006 15:40:54.165712  2964 solver.cpp:218] Iteration 21600 (11.9197 iter/s, 8.38948s/100 iters), loss = 0.198824
I1006 15:40:54.165833  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.198824 (* 1 = 0.198824 loss)
I1006 15:40:54.165849  2964 sgd_solver.cpp:105] Iteration 21600, lr = 0.1
I1006 15:41:02.550844  2964 solver.cpp:218] Iteration 21700 (11.9261 iter/s, 8.38498s/100 iters), loss = 0.250753
I1006 15:41:02.550875  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.250753 (* 1 = 0.250753 loss)
I1006 15:41:02.550880  2964 sgd_solver.cpp:105] Iteration 21700, lr = 0.1
I1006 15:41:10.958035  2964 solver.cpp:218] Iteration 21800 (11.8947 iter/s, 8.40713s/100 iters), loss = 0.249879
I1006 15:41:10.958066  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.249879 (* 1 = 0.249879 loss)
I1006 15:41:10.958073  2964 sgd_solver.cpp:105] Iteration 21800, lr = 0.1
I1006 15:41:19.354033  2964 solver.cpp:218] Iteration 21900 (11.9105 iter/s, 8.39594s/100 iters), loss = 0.302226
I1006 15:41:19.354075  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.302226 (* 1 = 0.302226 loss)
I1006 15:41:19.354081  2964 sgd_solver.cpp:105] Iteration 21900, lr = 0.1
I1006 15:41:27.330873  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 15:41:27.676467  2964 solver.cpp:330] Iteration 22000, Testing net (#0)
I1006 15:41:29.603788  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 15:41:29.683847  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7937
I1006 15:41:29.683887  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.654538 (* 1 = 0.654538 loss)
I1006 15:41:29.766976  2964 solver.cpp:218] Iteration 22000 (9.6035 iter/s, 10.4129s/100 iters), loss = 0.180219
I1006 15:41:29.766999  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.180219 (* 1 = 0.180219 loss)
I1006 15:41:29.767006  2964 sgd_solver.cpp:105] Iteration 22000, lr = 0.1
I1006 15:41:38.185369  2964 solver.cpp:218] Iteration 22100 (11.8788 iter/s, 8.41834s/100 iters), loss = 0.233259
I1006 15:41:38.185400  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.233259 (* 1 = 0.233259 loss)
I1006 15:41:38.185406  2964 sgd_solver.cpp:105] Iteration 22100, lr = 0.1
I1006 15:41:46.591588  2964 solver.cpp:218] Iteration 22200 (11.896 iter/s, 8.40616s/100 iters), loss = 0.276329
I1006 15:41:46.591619  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.276329 (* 1 = 0.276329 loss)
I1006 15:41:46.591624  2964 sgd_solver.cpp:105] Iteration 22200, lr = 0.1
I1006 15:41:54.984241  2964 solver.cpp:218] Iteration 22300 (11.9153 iter/s, 8.39259s/100 iters), loss = 0.237725
I1006 15:41:54.984269  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.237725 (* 1 = 0.237725 loss)
I1006 15:41:54.984277  2964 sgd_solver.cpp:105] Iteration 22300, lr = 0.1
I1006 15:42:03.391027  2964 solver.cpp:218] Iteration 22400 (11.8952 iter/s, 8.40673s/100 iters), loss = 0.26031
I1006 15:42:03.391175  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.26031 (* 1 = 0.26031 loss)
I1006 15:42:03.391194  2964 sgd_solver.cpp:105] Iteration 22400, lr = 0.1
I1006 15:42:11.372965  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 15:42:11.707226  2964 solver.cpp:330] Iteration 22500, Testing net (#0)
I1006 15:42:13.658833  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 15:42:13.739776  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7929
I1006 15:42:13.739802  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.603997 (* 1 = 0.603997 loss)
I1006 15:42:13.822754  2964 solver.cpp:218] Iteration 22500 (9.5863 iter/s, 10.4316s/100 iters), loss = 0.255012
I1006 15:42:13.822782  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.255012 (* 1 = 0.255012 loss)
I1006 15:42:13.822789  2964 sgd_solver.cpp:105] Iteration 22500, lr = 0.1
I1006 15:42:22.241171  2964 solver.cpp:218] Iteration 22600 (11.8788 iter/s, 8.41836s/100 iters), loss = 0.253875
I1006 15:42:22.241205  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.253875 (* 1 = 0.253875 loss)
I1006 15:42:22.241212  2964 sgd_solver.cpp:105] Iteration 22600, lr = 0.1
I1006 15:42:30.643167  2964 solver.cpp:218] Iteration 22700 (11.902 iter/s, 8.40193s/100 iters), loss = 0.284783
I1006 15:42:30.643199  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.284783 (* 1 = 0.284783 loss)
I1006 15:42:30.643205  2964 sgd_solver.cpp:105] Iteration 22700, lr = 0.1
I1006 15:42:39.054060  2964 solver.cpp:218] Iteration 22800 (11.8894 iter/s, 8.41083s/100 iters), loss = 0.214091
I1006 15:42:39.054165  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.214091 (* 1 = 0.214091 loss)
I1006 15:42:39.054183  2964 sgd_solver.cpp:105] Iteration 22800, lr = 0.1
I1006 15:42:47.461477  2964 solver.cpp:218] Iteration 22900 (11.8944 iter/s, 8.40729s/100 iters), loss = 0.228786
I1006 15:42:47.461519  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.228786 (* 1 = 0.228786 loss)
I1006 15:42:47.461524  2964 sgd_solver.cpp:105] Iteration 22900, lr = 0.1
I1006 15:42:55.439548  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 15:42:55.776468  2964 solver.cpp:330] Iteration 23000, Testing net (#0)
I1006 15:42:57.710630  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 15:42:57.791844  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7736
I1006 15:42:57.791870  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.735656 (* 1 = 0.735656 loss)
I1006 15:42:57.878382  2964 solver.cpp:218] Iteration 23000 (9.59985 iter/s, 10.4168s/100 iters), loss = 0.209526
I1006 15:42:57.878415  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.209526 (* 1 = 0.209526 loss)
I1006 15:42:57.878423  2964 sgd_solver.cpp:105] Iteration 23000, lr = 0.1
I1006 15:43:06.290747  2964 solver.cpp:218] Iteration 23100 (11.8874 iter/s, 8.4123s/100 iters), loss = 0.146912
I1006 15:43:06.290781  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.146912 (* 1 = 0.146912 loss)
I1006 15:43:06.290788  2964 sgd_solver.cpp:105] Iteration 23100, lr = 0.1
I1006 15:43:14.711094  2964 solver.cpp:218] Iteration 23200 (11.8761 iter/s, 8.42029s/100 iters), loss = 0.225988
I1006 15:43:14.711220  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.225988 (* 1 = 0.225988 loss)
I1006 15:43:14.711227  2964 sgd_solver.cpp:105] Iteration 23200, lr = 0.1
I1006 15:43:23.120834  2964 solver.cpp:218] Iteration 23300 (11.8912 iter/s, 8.40958s/100 iters), loss = 0.235606
I1006 15:43:23.120885  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.235606 (* 1 = 0.235606 loss)
I1006 15:43:23.120894  2964 sgd_solver.cpp:105] Iteration 23300, lr = 0.1
I1006 15:43:31.519045  2964 solver.cpp:218] Iteration 23400 (11.9075 iter/s, 8.3981s/100 iters), loss = 0.18432
I1006 15:43:31.519076  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.18432 (* 1 = 0.18432 loss)
I1006 15:43:31.519086  2964 sgd_solver.cpp:105] Iteration 23400, lr = 0.1
I1006 15:43:39.515539  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 15:43:39.849385  2964 solver.cpp:330] Iteration 23500, Testing net (#0)
I1006 15:43:41.775991  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 15:43:41.856108  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7578
I1006 15:43:41.856144  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.788889 (* 1 = 0.788889 loss)
I1006 15:43:41.939419  2964 solver.cpp:218] Iteration 23500 (9.59664 iter/s, 10.4203s/100 iters), loss = 0.148139
I1006 15:43:41.939445  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.148139 (* 1 = 0.148139 loss)
I1006 15:43:41.939452  2964 sgd_solver.cpp:105] Iteration 23500, lr = 0.1
I1006 15:43:50.343298  2964 solver.cpp:218] Iteration 23600 (11.8993 iter/s, 8.40382s/100 iters), loss = 0.260575
I1006 15:43:50.343410  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.260575 (* 1 = 0.260575 loss)
I1006 15:43:50.343427  2964 sgd_solver.cpp:105] Iteration 23600, lr = 0.1
I1006 15:43:58.764897  2964 solver.cpp:218] Iteration 23700 (11.8744 iter/s, 8.42147s/100 iters), loss = 0.285151
I1006 15:43:58.764930  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.285151 (* 1 = 0.285151 loss)
I1006 15:43:58.764936  2964 sgd_solver.cpp:105] Iteration 23700, lr = 0.1
I1006 15:44:07.172577  2964 solver.cpp:218] Iteration 23800 (11.894 iter/s, 8.40761s/100 iters), loss = 0.223157
I1006 15:44:07.172611  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.223157 (* 1 = 0.223157 loss)
I1006 15:44:07.172618  2964 sgd_solver.cpp:105] Iteration 23800, lr = 0.1
I1006 15:44:15.573715  2964 solver.cpp:218] Iteration 23900 (11.9032 iter/s, 8.40108s/100 iters), loss = 0.163671
I1006 15:44:15.573746  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.163671 (* 1 = 0.163671 loss)
I1006 15:44:15.573755  2964 sgd_solver.cpp:105] Iteration 23900, lr = 0.1
I1006 15:44:23.562486  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 15:44:23.897923  2964 solver.cpp:330] Iteration 24000, Testing net (#0)
I1006 15:44:25.822077  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 15:44:25.902326  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8023
I1006 15:44:25.902351  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.573166 (* 1 = 0.573166 loss)
I1006 15:44:25.986294  2964 solver.cpp:218] Iteration 24000 (9.60383 iter/s, 10.4125s/100 iters), loss = 0.196496
I1006 15:44:25.986320  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.196496 (* 1 = 0.196496 loss)
I1006 15:44:25.986326  2964 sgd_solver.cpp:105] Iteration 24000, lr = 0.1
I1006 15:44:34.378268  2964 solver.cpp:218] Iteration 24100 (11.9162 iter/s, 8.39192s/100 iters), loss = 0.25532
I1006 15:44:34.378298  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.25532 (* 1 = 0.25532 loss)
I1006 15:44:34.378304  2964 sgd_solver.cpp:105] Iteration 24100, lr = 0.1
I1006 15:44:42.790804  2964 solver.cpp:218] Iteration 24200 (11.8871 iter/s, 8.41248s/100 iters), loss = 0.241919
I1006 15:44:42.790835  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.241919 (* 1 = 0.241919 loss)
I1006 15:44:42.790843  2964 sgd_solver.cpp:105] Iteration 24200, lr = 0.1
I1006 15:44:51.187098  2964 solver.cpp:218] Iteration 24300 (11.9101 iter/s, 8.39623s/100 iters), loss = 0.26798
I1006 15:44:51.187134  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.26798 (* 1 = 0.26798 loss)
I1006 15:44:51.187141  2964 sgd_solver.cpp:105] Iteration 24300, lr = 0.1
I1006 15:44:59.586540  2964 solver.cpp:218] Iteration 24400 (11.9057 iter/s, 8.39934s/100 iters), loss = 0.185722
I1006 15:44:59.586663  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.185722 (* 1 = 0.185722 loss)
I1006 15:44:59.586680  2964 sgd_solver.cpp:105] Iteration 24400, lr = 0.1
I1006 15:45:07.555948  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 15:45:07.892897  2964 solver.cpp:330] Iteration 24500, Testing net (#0)
I1006 15:45:09.818377  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 15:45:09.899363  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7992
I1006 15:45:09.899389  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.618444 (* 1 = 0.618444 loss)
I1006 15:45:09.983279  2964 solver.cpp:218] Iteration 24500 (9.61854 iter/s, 10.3966s/100 iters), loss = 0.217325
I1006 15:45:09.983309  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.217325 (* 1 = 0.217325 loss)
I1006 15:45:09.983315  2964 sgd_solver.cpp:105] Iteration 24500, lr = 0.1
I1006 15:45:18.386544  2964 solver.cpp:218] Iteration 24600 (11.9002 iter/s, 8.40321s/100 iters), loss = 0.313938
I1006 15:45:18.386577  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.313938 (* 1 = 0.313938 loss)
I1006 15:45:18.386584  2964 sgd_solver.cpp:105] Iteration 24600, lr = 0.1
I1006 15:45:26.816035  2964 solver.cpp:218] Iteration 24700 (11.8632 iter/s, 8.42943s/100 iters), loss = 0.215289
I1006 15:45:26.816066  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.215289 (* 1 = 0.215289 loss)
I1006 15:45:26.816072  2964 sgd_solver.cpp:105] Iteration 24700, lr = 0.1
I1006 15:45:35.235348  2964 solver.cpp:218] Iteration 24800 (11.8775 iter/s, 8.41925s/100 iters), loss = 0.272715
I1006 15:45:35.235476  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.272715 (* 1 = 0.272715 loss)
I1006 15:45:35.235483  2964 sgd_solver.cpp:105] Iteration 24800, lr = 0.1
I1006 15:45:43.633919  2964 solver.cpp:218] Iteration 24900 (11.907 iter/s, 8.39842s/100 iters), loss = 0.164938
I1006 15:45:43.633950  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.164938 (* 1 = 0.164938 loss)
I1006 15:45:43.633956  2964 sgd_solver.cpp:105] Iteration 24900, lr = 0.1
I1006 15:45:51.612721  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 15:45:51.952168  2964 solver.cpp:330] Iteration 25000, Testing net (#0)
I1006 15:45:53.881129  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 15:45:53.961460  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.781
I1006 15:45:53.961496  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.670714 (* 1 = 0.670714 loss)
I1006 15:45:54.044631  2964 solver.cpp:218] Iteration 25000 (9.60555 iter/s, 10.4106s/100 iters), loss = 0.225404
I1006 15:45:54.044656  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.225404 (* 1 = 0.225404 loss)
I1006 15:45:54.044661  2964 sgd_solver.cpp:105] Iteration 25000, lr = 0.1
I1006 15:46:02.449761  2964 solver.cpp:218] Iteration 25100 (11.8976 iter/s, 8.40508s/100 iters), loss = 0.169487
I1006 15:46:02.449796  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.169487 (* 1 = 0.169487 loss)
I1006 15:46:02.449805  2964 sgd_solver.cpp:105] Iteration 25100, lr = 0.1
I1006 15:46:10.851236  2964 solver.cpp:218] Iteration 25200 (11.9028 iter/s, 8.40141s/100 iters), loss = 0.194368
I1006 15:46:10.851347  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.194368 (* 1 = 0.194368 loss)
I1006 15:46:10.851366  2964 sgd_solver.cpp:105] Iteration 25200, lr = 0.1
I1006 15:46:19.264642  2964 solver.cpp:218] Iteration 25300 (11.886 iter/s, 8.41327s/100 iters), loss = 0.28423
I1006 15:46:19.264684  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.28423 (* 1 = 0.28423 loss)
I1006 15:46:19.264690  2964 sgd_solver.cpp:105] Iteration 25300, lr = 0.1
I1006 15:46:27.663056  2964 solver.cpp:218] Iteration 25400 (11.9071 iter/s, 8.39834s/100 iters), loss = 0.193442
I1006 15:46:27.663096  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.193443 (* 1 = 0.193443 loss)
I1006 15:46:27.663102  2964 sgd_solver.cpp:105] Iteration 25400, lr = 0.1
I1006 15:46:35.644034  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 15:46:35.977847  2964 solver.cpp:330] Iteration 25500, Testing net (#0)
I1006 15:46:37.909159  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 15:46:37.989344  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8192
I1006 15:46:37.989369  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.583028 (* 1 = 0.583028 loss)
I1006 15:46:38.072506  2964 solver.cpp:218] Iteration 25500 (9.60672 iter/s, 10.4094s/100 iters), loss = 0.202639
I1006 15:46:38.072533  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.202639 (* 1 = 0.202639 loss)
I1006 15:46:38.072540  2964 sgd_solver.cpp:105] Iteration 25500, lr = 0.1
I1006 15:46:46.498548  2964 solver.cpp:218] Iteration 25600 (11.868 iter/s, 8.42599s/100 iters), loss = 0.249861
I1006 15:46:46.498672  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.249861 (* 1 = 0.249861 loss)
I1006 15:46:46.498682  2964 sgd_solver.cpp:105] Iteration 25600, lr = 0.1
I1006 15:46:54.897403  2964 solver.cpp:218] Iteration 25700 (11.9066 iter/s, 8.39871s/100 iters), loss = 0.151795
I1006 15:46:54.897434  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.151795 (* 1 = 0.151795 loss)
I1006 15:46:54.897440  2964 sgd_solver.cpp:105] Iteration 25700, lr = 0.1
I1006 15:47:03.317056  2964 solver.cpp:218] Iteration 25800 (11.8771 iter/s, 8.41959s/100 iters), loss = 0.239916
I1006 15:47:03.317106  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.239916 (* 1 = 0.239916 loss)
I1006 15:47:03.317113  2964 sgd_solver.cpp:105] Iteration 25800, lr = 0.1
I1006 15:47:11.727226  2964 solver.cpp:218] Iteration 25900 (11.8905 iter/s, 8.41009s/100 iters), loss = 0.200989
I1006 15:47:11.727259  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.200989 (* 1 = 0.200989 loss)
I1006 15:47:11.727267  2964 sgd_solver.cpp:105] Iteration 25900, lr = 0.1
I1006 15:47:19.715867  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 15:47:20.049186  2964 solver.cpp:330] Iteration 26000, Testing net (#0)
I1006 15:47:21.987853  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 15:47:22.067903  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8067
I1006 15:47:22.067937  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.604176 (* 1 = 0.604176 loss)
I1006 15:47:22.154980  2964 solver.cpp:218] Iteration 26000 (9.58986 iter/s, 10.4277s/100 iters), loss = 0.168572
I1006 15:47:22.155014  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.168572 (* 1 = 0.168572 loss)
I1006 15:47:22.155020  2964 sgd_solver.cpp:105] Iteration 26000, lr = 0.1
I1006 15:47:30.544869  2964 solver.cpp:218] Iteration 26100 (11.9192 iter/s, 8.38983s/100 iters), loss = 0.229268
I1006 15:47:30.544901  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.229268 (* 1 = 0.229268 loss)
I1006 15:47:30.544909  2964 sgd_solver.cpp:105] Iteration 26100, lr = 0.1
I1006 15:47:38.939311  2964 solver.cpp:218] Iteration 26200 (11.9127 iter/s, 8.39438s/100 iters), loss = 0.194182
I1006 15:47:38.939353  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.194182 (* 1 = 0.194182 loss)
I1006 15:47:38.939359  2964 sgd_solver.cpp:105] Iteration 26200, lr = 0.1
I1006 15:47:47.332159  2964 solver.cpp:218] Iteration 26300 (11.915 iter/s, 8.39278s/100 iters), loss = 0.221583
I1006 15:47:47.332197  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.221583 (* 1 = 0.221583 loss)
I1006 15:47:47.332204  2964 sgd_solver.cpp:105] Iteration 26300, lr = 0.1
I1006 15:47:55.743978  2964 solver.cpp:218] Iteration 26400 (11.8881 iter/s, 8.41176s/100 iters), loss = 0.167303
I1006 15:47:55.744082  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.167303 (* 1 = 0.167303 loss)
I1006 15:47:55.744089  2964 sgd_solver.cpp:105] Iteration 26400, lr = 0.1
I1006 15:48:03.700323  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 15:48:04.038751  2964 solver.cpp:330] Iteration 26500, Testing net (#0)
I1006 15:48:05.980299  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 15:48:06.060474  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7829
I1006 15:48:06.060499  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.705283 (* 1 = 0.705283 loss)
I1006 15:48:06.143514  2964 solver.cpp:218] Iteration 26500 (9.61594 iter/s, 10.3994s/100 iters), loss = 0.20728
I1006 15:48:06.143539  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.20728 (* 1 = 0.20728 loss)
I1006 15:48:06.143546  2964 sgd_solver.cpp:105] Iteration 26500, lr = 0.1
I1006 15:48:14.569062  2964 solver.cpp:218] Iteration 26600 (11.8687 iter/s, 8.42549s/100 iters), loss = 0.277
I1006 15:48:14.569094  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.277 (* 1 = 0.277 loss)
I1006 15:48:14.569111  2964 sgd_solver.cpp:105] Iteration 26600, lr = 0.1
I1006 15:48:23.013204  2964 solver.cpp:218] Iteration 26700 (11.8426 iter/s, 8.44408s/100 iters), loss = 0.303687
I1006 15:48:23.013239  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.303687 (* 1 = 0.303687 loss)
I1006 15:48:23.013245  2964 sgd_solver.cpp:105] Iteration 26700, lr = 0.1
I1006 15:48:31.447396  2964 solver.cpp:218] Iteration 26800 (11.8566 iter/s, 8.43413s/100 iters), loss = 0.210874
I1006 15:48:31.447495  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.210874 (* 1 = 0.210874 loss)
I1006 15:48:31.447513  2964 sgd_solver.cpp:105] Iteration 26800, lr = 0.1
I1006 15:48:39.885006  2964 solver.cpp:218] Iteration 26900 (11.8519 iter/s, 8.4375s/100 iters), loss = 0.190811
I1006 15:48:39.885037  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.190811 (* 1 = 0.190811 loss)
I1006 15:48:39.885044  2964 sgd_solver.cpp:105] Iteration 26900, lr = 0.1
I1006 15:48:47.902624  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 15:48:48.241906  2964 solver.cpp:330] Iteration 27000, Testing net (#0)
I1006 15:48:50.170718  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 15:48:50.250972  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7554
I1006 15:48:50.251006  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.766457 (* 1 = 0.766457 loss)
I1006 15:48:50.335536  2964 solver.cpp:218] Iteration 27000 (9.56895 iter/s, 10.4505s/100 iters), loss = 0.214904
I1006 15:48:50.335566  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.214904 (* 1 = 0.214904 loss)
I1006 15:48:50.335572  2964 sgd_solver.cpp:105] Iteration 27000, lr = 0.1
I1006 15:48:58.752842  2964 solver.cpp:218] Iteration 27100 (11.8804 iter/s, 8.41725s/100 iters), loss = 0.197947
I1006 15:48:58.752874  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.197947 (* 1 = 0.197947 loss)
I1006 15:48:58.752881  2964 sgd_solver.cpp:105] Iteration 27100, lr = 0.1
I1006 15:49:07.159706  2964 solver.cpp:218] Iteration 27200 (11.8951 iter/s, 8.40681s/100 iters), loss = 0.168699
I1006 15:49:07.159848  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.168699 (* 1 = 0.168699 loss)
I1006 15:49:07.159868  2964 sgd_solver.cpp:105] Iteration 27200, lr = 0.1
I1006 15:49:15.575502  2964 solver.cpp:218] Iteration 27300 (11.8827 iter/s, 8.41563s/100 iters), loss = 0.196136
I1006 15:49:15.575534  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.196136 (* 1 = 0.196136 loss)
I1006 15:49:15.575541  2964 sgd_solver.cpp:105] Iteration 27300, lr = 0.1
I1006 15:49:23.948966  2964 solver.cpp:218] Iteration 27400 (11.9426 iter/s, 8.3734s/100 iters), loss = 0.189065
I1006 15:49:23.949008  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.189065 (* 1 = 0.189065 loss)
I1006 15:49:23.949014  2964 sgd_solver.cpp:105] Iteration 27400, lr = 0.1
I1006 15:49:31.913995  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 15:49:32.247161  2964 solver.cpp:330] Iteration 27500, Testing net (#0)
I1006 15:49:34.175810  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 15:49:34.256633  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8159
I1006 15:49:34.256659  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.582973 (* 1 = 0.582973 loss)
I1006 15:49:34.343885  2964 solver.cpp:218] Iteration 27500 (9.62015 iter/s, 10.3948s/100 iters), loss = 0.160412
I1006 15:49:34.343930  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.160413 (* 1 = 0.160413 loss)
I1006 15:49:34.343937  2964 sgd_solver.cpp:105] Iteration 27500, lr = 0.1
I1006 15:49:42.719358  2964 solver.cpp:218] Iteration 27600 (11.9397 iter/s, 8.3754s/100 iters), loss = 0.139325
I1006 15:49:42.719481  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.139325 (* 1 = 0.139325 loss)
I1006 15:49:42.719489  2964 sgd_solver.cpp:105] Iteration 27600, lr = 0.1
I1006 15:49:51.093072  2964 solver.cpp:218] Iteration 27700 (11.9423 iter/s, 8.37357s/100 iters), loss = 0.306694
I1006 15:49:51.093104  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.306694 (* 1 = 0.306694 loss)
I1006 15:49:51.093120  2964 sgd_solver.cpp:105] Iteration 27700, lr = 0.1
I1006 15:49:59.471359  2964 solver.cpp:218] Iteration 27800 (11.9357 iter/s, 8.37823s/100 iters), loss = 0.259124
I1006 15:49:59.471400  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.259125 (* 1 = 0.259125 loss)
I1006 15:49:59.471407  2964 sgd_solver.cpp:105] Iteration 27800, lr = 0.1
I1006 15:50:07.847028  2964 solver.cpp:218] Iteration 27900 (11.9394 iter/s, 8.3756s/100 iters), loss = 0.158764
I1006 15:50:07.847064  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.158764 (* 1 = 0.158764 loss)
I1006 15:50:07.847070  2964 sgd_solver.cpp:105] Iteration 27900, lr = 0.1
I1006 15:50:15.810086  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 15:50:16.144943  2964 solver.cpp:330] Iteration 28000, Testing net (#0)
I1006 15:50:18.072651  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 15:50:18.152858  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7652
I1006 15:50:18.152882  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.77333 (* 1 = 0.77333 loss)
I1006 15:50:18.235553  2964 solver.cpp:218] Iteration 28000 (9.62607 iter/s, 10.3885s/100 iters), loss = 0.266649
I1006 15:50:18.235577  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.266649 (* 1 = 0.266649 loss)
I1006 15:50:18.235584  2964 sgd_solver.cpp:105] Iteration 28000, lr = 0.1
I1006 15:50:26.631880  2964 solver.cpp:218] Iteration 28100 (11.91 iter/s, 8.39627s/100 iters), loss = 0.234884
I1006 15:50:26.631911  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.234884 (* 1 = 0.234884 loss)
I1006 15:50:26.631918  2964 sgd_solver.cpp:105] Iteration 28100, lr = 0.1
I1006 15:50:35.016404  2964 solver.cpp:218] Iteration 28200 (11.9268 iter/s, 8.38447s/100 iters), loss = 0.242878
I1006 15:50:35.016435  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.242878 (* 1 = 0.242878 loss)
I1006 15:50:35.016441  2964 sgd_solver.cpp:105] Iteration 28200, lr = 0.1
I1006 15:50:43.410264  2964 solver.cpp:218] Iteration 28300 (11.9136 iter/s, 8.3938s/100 iters), loss = 0.229712
I1006 15:50:43.410296  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.229712 (* 1 = 0.229712 loss)
I1006 15:50:43.410303  2964 sgd_solver.cpp:105] Iteration 28300, lr = 0.1
I1006 15:50:51.795192  2964 solver.cpp:218] Iteration 28400 (11.9262 iter/s, 8.38487s/100 iters), loss = 0.15204
I1006 15:50:51.795303  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.15204 (* 1 = 0.15204 loss)
I1006 15:50:51.795313  2964 sgd_solver.cpp:105] Iteration 28400, lr = 0.1
I1006 15:50:59.766486  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 15:51:00.102587  2964 solver.cpp:330] Iteration 28500, Testing net (#0)
I1006 15:51:02.039347  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 15:51:02.119688  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7705
I1006 15:51:02.119722  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.802125 (* 1 = 0.802125 loss)
I1006 15:51:02.203671  2964 solver.cpp:218] Iteration 28500 (9.60767 iter/s, 10.4083s/100 iters), loss = 0.171255
I1006 15:51:02.203701  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.171255 (* 1 = 0.171255 loss)
I1006 15:51:02.203708  2964 sgd_solver.cpp:105] Iteration 28500, lr = 0.1
I1006 15:51:10.588982  2964 solver.cpp:218] Iteration 28600 (11.9257 iter/s, 8.38525s/100 iters), loss = 0.142742
I1006 15:51:10.589025  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.142742 (* 1 = 0.142742 loss)
I1006 15:51:10.589030  2964 sgd_solver.cpp:105] Iteration 28600, lr = 0.1
I1006 15:51:18.994721  2964 solver.cpp:218] Iteration 28700 (11.8967 iter/s, 8.40567s/100 iters), loss = 0.280599
I1006 15:51:18.994758  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.280599 (* 1 = 0.280599 loss)
I1006 15:51:18.994765  2964 sgd_solver.cpp:105] Iteration 28700, lr = 0.1
I1006 15:51:27.406296  2964 solver.cpp:218] Iteration 28800 (11.8885 iter/s, 8.41151s/100 iters), loss = 0.294329
I1006 15:51:27.406443  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.294329 (* 1 = 0.294329 loss)
I1006 15:51:27.406451  2964 sgd_solver.cpp:105] Iteration 28800, lr = 0.1
I1006 15:51:35.780143  2964 solver.cpp:218] Iteration 28900 (11.9422 iter/s, 8.37367s/100 iters), loss = 0.230163
I1006 15:51:35.780184  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.230164 (* 1 = 0.230164 loss)
I1006 15:51:35.780190  2964 sgd_solver.cpp:105] Iteration 28900, lr = 0.1
I1006 15:51:43.701511  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 15:51:44.034327  2964 solver.cpp:330] Iteration 29000, Testing net (#0)
I1006 15:51:45.957094  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 15:51:46.037286  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7709
I1006 15:51:46.037322  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.71606 (* 1 = 0.71606 loss)
I1006 15:51:46.120334  2964 solver.cpp:218] Iteration 29000 (9.67107 iter/s, 10.3401s/100 iters), loss = 0.179518
I1006 15:51:46.120358  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.179518 (* 1 = 0.179518 loss)
I1006 15:51:46.120365  2964 sgd_solver.cpp:105] Iteration 29000, lr = 0.1
I1006 15:51:54.464691  2964 solver.cpp:218] Iteration 29100 (11.9842 iter/s, 8.34431s/100 iters), loss = 0.222123
I1006 15:51:54.464721  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.222123 (* 1 = 0.222123 loss)
I1006 15:51:54.464727  2964 sgd_solver.cpp:105] Iteration 29100, lr = 0.1
I1006 15:52:02.833773  2964 solver.cpp:218] Iteration 29200 (11.9488 iter/s, 8.36902s/100 iters), loss = 0.248836
I1006 15:52:02.833891  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.248836 (* 1 = 0.248836 loss)
I1006 15:52:02.833899  2964 sgd_solver.cpp:105] Iteration 29200, lr = 0.1
I1006 15:52:11.188369  2964 solver.cpp:218] Iteration 29300 (11.9697 iter/s, 8.35445s/100 iters), loss = 0.236439
I1006 15:52:11.188400  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.236439 (* 1 = 0.236439 loss)
I1006 15:52:11.188405  2964 sgd_solver.cpp:105] Iteration 29300, lr = 0.1
I1006 15:52:19.541043  2964 solver.cpp:218] Iteration 29400 (11.9723 iter/s, 8.35262s/100 iters), loss = 0.145275
I1006 15:52:19.541083  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.145275 (* 1 = 0.145275 loss)
I1006 15:52:19.541090  2964 sgd_solver.cpp:105] Iteration 29400, lr = 0.1
I1006 15:52:27.480093  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 15:52:27.814810  2964 solver.cpp:330] Iteration 29500, Testing net (#0)
I1006 15:52:29.741169  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 15:52:29.822415  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7858
I1006 15:52:29.822443  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.680587 (* 1 = 0.680587 loss)
I1006 15:52:29.905457  2964 solver.cpp:218] Iteration 29500 (9.64847 iter/s, 10.3643s/100 iters), loss = 0.188633
I1006 15:52:29.905483  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.188633 (* 1 = 0.188633 loss)
I1006 15:52:29.905490  2964 sgd_solver.cpp:105] Iteration 29500, lr = 0.1
I1006 15:52:38.240540  2964 solver.cpp:218] Iteration 29600 (11.9976 iter/s, 8.33503s/100 iters), loss = 0.150085
I1006 15:52:38.240602  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.150085 (* 1 = 0.150085 loss)
I1006 15:52:38.240618  2964 sgd_solver.cpp:105] Iteration 29600, lr = 0.1
I1006 15:52:46.581404  2964 solver.cpp:218] Iteration 29700 (11.9893 iter/s, 8.34078s/100 iters), loss = 0.298393
I1006 15:52:46.581435  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.298393 (* 1 = 0.298393 loss)
I1006 15:52:46.581451  2964 sgd_solver.cpp:105] Iteration 29700, lr = 0.1
I1006 15:52:54.918218  2964 solver.cpp:218] Iteration 29800 (11.9951 iter/s, 8.33676s/100 iters), loss = 0.22639
I1006 15:52:54.918251  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.22639 (* 1 = 0.22639 loss)
I1006 15:52:54.918257  2964 sgd_solver.cpp:105] Iteration 29800, lr = 0.1
I1006 15:53:03.263285  2964 solver.cpp:218] Iteration 29900 (11.9832 iter/s, 8.34501s/100 iters), loss = 0.216943
I1006 15:53:03.263317  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.216943 (* 1 = 0.216943 loss)
I1006 15:53:03.263334  2964 sgd_solver.cpp:105] Iteration 29900, lr = 0.1
I1006 15:53:11.191942  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 15:53:11.526161  2964 solver.cpp:330] Iteration 30000, Testing net (#0)
I1006 15:53:13.450318  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 15:53:13.530828  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8648
I1006 15:53:13.530864  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.420286 (* 1 = 0.420286 loss)
I1006 15:53:13.614886  2964 solver.cpp:218] Iteration 30000 (9.6604 iter/s, 10.3515s/100 iters), loss = 0.220385
I1006 15:53:13.614912  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.220385 (* 1 = 0.220385 loss)
I1006 15:53:13.614919  2964 sgd_solver.cpp:105] Iteration 30000, lr = 0.1
I1006 15:53:21.965128  2964 solver.cpp:218] Iteration 30100 (11.9758 iter/s, 8.35019s/100 iters), loss = 0.244942
I1006 15:53:21.965169  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.244942 (* 1 = 0.244942 loss)
I1006 15:53:21.965175  2964 sgd_solver.cpp:105] Iteration 30100, lr = 0.1
I1006 15:53:30.310324  2964 solver.cpp:218] Iteration 30200 (11.983 iter/s, 8.34513s/100 iters), loss = 0.265356
I1006 15:53:30.310365  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.265356 (* 1 = 0.265356 loss)
I1006 15:53:30.310371  2964 sgd_solver.cpp:105] Iteration 30200, lr = 0.1
I1006 15:53:38.674296  2964 solver.cpp:218] Iteration 30300 (11.9561 iter/s, 8.3639s/100 iters), loss = 0.203539
I1006 15:53:38.674338  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.203539 (* 1 = 0.203539 loss)
I1006 15:53:38.674343  2964 sgd_solver.cpp:105] Iteration 30300, lr = 0.1
I1006 15:53:47.019649  2964 solver.cpp:218] Iteration 30400 (11.9828 iter/s, 8.34528s/100 iters), loss = 0.168299
I1006 15:53:47.019776  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.168299 (* 1 = 0.168299 loss)
I1006 15:53:47.019783  2964 sgd_solver.cpp:105] Iteration 30400, lr = 0.1
I1006 15:53:54.959362  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 15:53:55.293541  2964 solver.cpp:330] Iteration 30500, Testing net (#0)
I1006 15:53:57.217844  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 15:53:57.298842  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8149
I1006 15:53:57.298877  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.568876 (* 1 = 0.568876 loss)
I1006 15:53:57.381785  2964 solver.cpp:218] Iteration 30500 (9.65066 iter/s, 10.362s/100 iters), loss = 0.21584
I1006 15:53:57.381820  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.21584 (* 1 = 0.21584 loss)
I1006 15:53:57.381827  2964 sgd_solver.cpp:105] Iteration 30500, lr = 0.1
I1006 15:54:05.731366  2964 solver.cpp:218] Iteration 30600 (11.9767 iter/s, 8.34952s/100 iters), loss = 0.254744
I1006 15:54:05.731400  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.254743 (* 1 = 0.254743 loss)
I1006 15:54:05.731406  2964 sgd_solver.cpp:105] Iteration 30600, lr = 0.1
I1006 15:54:14.086408  2964 solver.cpp:218] Iteration 30700 (11.9689 iter/s, 8.35498s/100 iters), loss = 0.234844
I1006 15:54:14.086457  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.234844 (* 1 = 0.234844 loss)
I1006 15:54:14.086464  2964 sgd_solver.cpp:105] Iteration 30700, lr = 0.1
I1006 15:54:22.439281  2964 solver.cpp:218] Iteration 30800 (11.972 iter/s, 8.3528s/100 iters), loss = 0.25473
I1006 15:54:22.439352  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.25473 (* 1 = 0.25473 loss)
I1006 15:54:22.439359  2964 sgd_solver.cpp:105] Iteration 30800, lr = 0.1
I1006 15:54:30.793757  2964 solver.cpp:218] Iteration 30900 (11.9698 iter/s, 8.35437s/100 iters), loss = 0.287364
I1006 15:54:30.793798  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.287364 (* 1 = 0.287364 loss)
I1006 15:54:30.793804  2964 sgd_solver.cpp:105] Iteration 30900, lr = 0.1
I1006 15:54:38.730178  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 15:54:39.064355  2964 solver.cpp:330] Iteration 31000, Testing net (#0)
I1006 15:54:40.987318  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 15:54:41.067314  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7907
I1006 15:54:41.067349  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.648049 (* 1 = 0.648049 loss)
I1006 15:54:41.151384  2964 solver.cpp:218] Iteration 31000 (9.65479 iter/s, 10.3576s/100 iters), loss = 0.217636
I1006 15:54:41.151409  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.217636 (* 1 = 0.217636 loss)
I1006 15:54:41.151417  2964 sgd_solver.cpp:105] Iteration 31000, lr = 0.1
I1006 15:54:49.507915  2964 solver.cpp:218] Iteration 31100 (11.9668 iter/s, 8.35648s/100 iters), loss = 0.245736
I1006 15:54:49.507956  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.245736 (* 1 = 0.245736 loss)
I1006 15:54:49.507961  2964 sgd_solver.cpp:105] Iteration 31100, lr = 0.1
I1006 15:54:57.850623  2964 solver.cpp:218] Iteration 31200 (11.9866 iter/s, 8.34264s/100 iters), loss = 0.304139
I1006 15:54:57.850718  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.304139 (* 1 = 0.304139 loss)
I1006 15:54:57.850726  2964 sgd_solver.cpp:105] Iteration 31200, lr = 0.1
I1006 15:55:06.204991  2964 solver.cpp:218] Iteration 31300 (11.97 iter/s, 8.35425s/100 iters), loss = 0.203005
I1006 15:55:06.205032  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.203005 (* 1 = 0.203005 loss)
I1006 15:55:06.205037  2964 sgd_solver.cpp:105] Iteration 31300, lr = 0.1
I1006 15:55:14.561004  2964 solver.cpp:218] Iteration 31400 (11.9675 iter/s, 8.35594s/100 iters), loss = 0.144835
I1006 15:55:14.561043  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.144834 (* 1 = 0.144834 loss)
I1006 15:55:14.561050  2964 sgd_solver.cpp:105] Iteration 31400, lr = 0.1
I1006 15:55:22.503935  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 15:55:22.838151  2964 solver.cpp:330] Iteration 31500, Testing net (#0)
I1006 15:55:24.763152  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 15:55:24.843484  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8246
I1006 15:55:24.843519  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.530681 (* 1 = 0.530681 loss)
I1006 15:55:24.926307  2964 solver.cpp:218] Iteration 31500 (9.64764 iter/s, 10.3652s/100 iters), loss = 0.124606
I1006 15:55:24.926332  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.124606 (* 1 = 0.124606 loss)
I1006 15:55:24.926338  2964 sgd_solver.cpp:105] Iteration 31500, lr = 0.1
I1006 15:55:33.262864  2964 solver.cpp:218] Iteration 31600 (11.9954 iter/s, 8.3365s/100 iters), loss = 0.140643
I1006 15:55:33.262948  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.140643 (* 1 = 0.140643 loss)
I1006 15:55:33.262966  2964 sgd_solver.cpp:105] Iteration 31600, lr = 0.1
I1006 15:55:41.612264  2964 solver.cpp:218] Iteration 31700 (11.9771 iter/s, 8.34929s/100 iters), loss = 0.196761
I1006 15:55:41.612305  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.196761 (* 1 = 0.196761 loss)
I1006 15:55:41.612310  2964 sgd_solver.cpp:105] Iteration 31700, lr = 0.1
I1006 15:55:49.956009  2964 solver.cpp:218] Iteration 31800 (11.9851 iter/s, 8.34368s/100 iters), loss = 0.147084
I1006 15:55:49.956050  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.147084 (* 1 = 0.147084 loss)
I1006 15:55:49.956056  2964 sgd_solver.cpp:105] Iteration 31800, lr = 0.1
I1006 15:55:58.300973  2964 solver.cpp:218] Iteration 31900 (11.9834 iter/s, 8.3449s/100 iters), loss = 0.122254
I1006 15:55:58.301002  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.122254 (* 1 = 0.122254 loss)
I1006 15:55:58.301008  2964 sgd_solver.cpp:105] Iteration 31900, lr = 0.1
I1006 15:56:06.232942  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 15:56:06.566609  2964 solver.cpp:330] Iteration 32000, Testing net (#0)
I1006 15:56:08.490785  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 15:56:08.571414  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7585
I1006 15:56:08.571450  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.831403 (* 1 = 0.831403 loss)
I1006 15:56:08.655366  2964 solver.cpp:218] Iteration 32000 (9.65779 iter/s, 10.3543s/100 iters), loss = 0.235848
I1006 15:56:08.655392  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.235848 (* 1 = 0.235848 loss)
I1006 15:56:08.655400  2964 sgd_solver.cpp:105] Iteration 32000, lr = 0.1
I1006 15:56:17.004242  2964 solver.cpp:218] Iteration 32100 (11.9778 iter/s, 8.34878s/100 iters), loss = 0.223809
I1006 15:56:17.004274  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.223809 (* 1 = 0.223809 loss)
I1006 15:56:17.004279  2964 sgd_solver.cpp:105] Iteration 32100, lr = 0.1
I1006 15:56:25.349962  2964 solver.cpp:218] Iteration 32200 (11.9823 iter/s, 8.34566s/100 iters), loss = 0.203709
I1006 15:56:25.350003  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.203709 (* 1 = 0.203709 loss)
I1006 15:56:25.350008  2964 sgd_solver.cpp:105] Iteration 32200, lr = 0.1
I1006 15:56:33.701881  2964 solver.cpp:218] Iteration 32300 (11.9734 iter/s, 8.35185s/100 iters), loss = 0.248227
I1006 15:56:33.701923  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.248227 (* 1 = 0.248227 loss)
I1006 15:56:33.701928  2964 sgd_solver.cpp:105] Iteration 32300, lr = 0.1
I1006 15:56:42.046924  2964 solver.cpp:218] Iteration 32400 (11.9833 iter/s, 8.34498s/100 iters), loss = 0.128572
I1006 15:56:42.047011  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.128572 (* 1 = 0.128572 loss)
I1006 15:56:42.047032  2964 sgd_solver.cpp:105] Iteration 32400, lr = 0.1
I1006 15:56:49.979996  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 15:56:50.314599  2964 solver.cpp:330] Iteration 32500, Testing net (#0)
I1006 15:56:52.236598  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 15:56:52.317751  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7864
I1006 15:56:52.317775  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.73036 (* 1 = 0.73036 loss)
I1006 15:56:52.400786  2964 solver.cpp:218] Iteration 32500 (9.65834 iter/s, 10.3537s/100 iters), loss = 0.241754
I1006 15:56:52.400810  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.241754 (* 1 = 0.241754 loss)
I1006 15:56:52.400815  2964 sgd_solver.cpp:105] Iteration 32500, lr = 0.1
I1006 15:57:00.746942  2964 solver.cpp:218] Iteration 32600 (11.9816 iter/s, 8.3461s/100 iters), loss = 0.191402
I1006 15:57:00.746984  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.191402 (* 1 = 0.191402 loss)
I1006 15:57:00.746989  2964 sgd_solver.cpp:105] Iteration 32600, lr = 0.1
I1006 15:57:09.101235  2964 solver.cpp:218] Iteration 32700 (11.97 iter/s, 8.35423s/100 iters), loss = 0.210424
I1006 15:57:09.101267  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.210424 (* 1 = 0.210424 loss)
I1006 15:57:09.101274  2964 sgd_solver.cpp:105] Iteration 32700, lr = 0.1
I1006 15:57:17.449203  2964 solver.cpp:218] Iteration 32800 (11.979 iter/s, 8.34791s/100 iters), loss = 0.253191
I1006 15:57:17.449304  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.253191 (* 1 = 0.253191 loss)
I1006 15:57:17.449311  2964 sgd_solver.cpp:105] Iteration 32800, lr = 0.1
I1006 15:57:25.800792  2964 solver.cpp:218] Iteration 32900 (11.9739 iter/s, 8.35147s/100 iters), loss = 0.187373
I1006 15:57:25.800823  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.187373 (* 1 = 0.187373 loss)
I1006 15:57:25.800828  2964 sgd_solver.cpp:105] Iteration 32900, lr = 0.1
I1006 15:57:33.731312  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 15:57:34.065129  2964 solver.cpp:330] Iteration 33000, Testing net (#0)
I1006 15:57:35.988999  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 15:57:36.068997  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.727
I1006 15:57:36.069023  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.909899 (* 1 = 0.909899 loss)
I1006 15:57:36.152801  2964 solver.cpp:218] Iteration 33000 (9.66002 iter/s, 10.3519s/100 iters), loss = 0.169401
I1006 15:57:36.152825  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.169401 (* 1 = 0.169401 loss)
I1006 15:57:36.152832  2964 sgd_solver.cpp:105] Iteration 33000, lr = 0.1
I1006 15:57:44.505048  2964 solver.cpp:218] Iteration 33100 (11.9729 iter/s, 8.35219s/100 iters), loss = 0.259868
I1006 15:57:44.505087  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.259868 (* 1 = 0.259868 loss)
I1006 15:57:44.505092  2964 sgd_solver.cpp:105] Iteration 33100, lr = 0.1
I1006 15:57:52.843490  2964 solver.cpp:218] Iteration 33200 (11.9927 iter/s, 8.33838s/100 iters), loss = 0.225603
I1006 15:57:52.843580  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.225603 (* 1 = 0.225603 loss)
I1006 15:57:52.843587  2964 sgd_solver.cpp:105] Iteration 33200, lr = 0.1
I1006 15:58:01.196130  2964 solver.cpp:218] Iteration 33300 (11.9724 iter/s, 8.35253s/100 iters), loss = 0.222484
I1006 15:58:01.196171  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.222484 (* 1 = 0.222484 loss)
I1006 15:58:01.196177  2964 sgd_solver.cpp:105] Iteration 33300, lr = 0.1
I1006 15:58:09.542819  2964 solver.cpp:218] Iteration 33400 (11.9809 iter/s, 8.34662s/100 iters), loss = 0.124561
I1006 15:58:09.542860  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.124561 (* 1 = 0.124561 loss)
I1006 15:58:09.542866  2964 sgd_solver.cpp:105] Iteration 33400, lr = 0.1
I1006 15:58:17.478283  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 15:58:17.812115  2964 solver.cpp:330] Iteration 33500, Testing net (#0)
I1006 15:58:19.734808  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 15:58:19.815820  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7999
I1006 15:58:19.815845  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.643105 (* 1 = 0.643105 loss)
I1006 15:58:19.898293  2964 solver.cpp:218] Iteration 33500 (9.6568 iter/s, 10.3554s/100 iters), loss = 0.16822
I1006 15:58:19.898317  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.16822 (* 1 = 0.16822 loss)
I1006 15:58:19.898324  2964 sgd_solver.cpp:105] Iteration 33500, lr = 0.1
I1006 15:58:28.236091  2964 solver.cpp:218] Iteration 33600 (11.9936 iter/s, 8.33775s/100 iters), loss = 0.289978
I1006 15:58:28.236215  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.289977 (* 1 = 0.289977 loss)
I1006 15:58:28.236223  2964 sgd_solver.cpp:105] Iteration 33600, lr = 0.1
I1006 15:58:36.579630  2964 solver.cpp:218] Iteration 33700 (11.9855 iter/s, 8.3434s/100 iters), loss = 0.185864
I1006 15:58:36.579671  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.185864 (* 1 = 0.185864 loss)
I1006 15:58:36.579676  2964 sgd_solver.cpp:105] Iteration 33700, lr = 0.1
I1006 15:58:44.924505  2964 solver.cpp:218] Iteration 33800 (11.9835 iter/s, 8.34481s/100 iters), loss = 0.159208
I1006 15:58:44.924536  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.159208 (* 1 = 0.159208 loss)
I1006 15:58:44.924541  2964 sgd_solver.cpp:105] Iteration 33800, lr = 0.1
I1006 15:58:53.270864  2964 solver.cpp:218] Iteration 33900 (11.9814 iter/s, 8.3463s/100 iters), loss = 0.173232
I1006 15:58:53.270905  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.173232 (* 1 = 0.173232 loss)
I1006 15:58:53.270910  2964 sgd_solver.cpp:105] Iteration 33900, lr = 0.1
I1006 15:59:01.198593  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 15:59:01.532618  2964 solver.cpp:330] Iteration 34000, Testing net (#0)
I1006 15:59:03.454926  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 15:59:03.535244  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7918
I1006 15:59:03.535269  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.666775 (* 1 = 0.666775 loss)
I1006 15:59:03.619884  2964 solver.cpp:218] Iteration 34000 (9.66282 iter/s, 10.3489s/100 iters), loss = 0.192246
I1006 15:59:03.619910  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.192246 (* 1 = 0.192246 loss)
I1006 15:59:03.619916  2964 sgd_solver.cpp:105] Iteration 34000, lr = 0.1
I1006 15:59:11.969269  2964 solver.cpp:218] Iteration 34100 (11.977 iter/s, 8.34933s/100 iters), loss = 0.116816
I1006 15:59:11.969310  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.116815 (* 1 = 0.116815 loss)
I1006 15:59:11.969317  2964 sgd_solver.cpp:105] Iteration 34100, lr = 0.1
I1006 15:59:20.315073  2964 solver.cpp:218] Iteration 34200 (11.9822 iter/s, 8.34574s/100 iters), loss = 0.273697
I1006 15:59:20.315112  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.273697 (* 1 = 0.273697 loss)
I1006 15:59:20.315119  2964 sgd_solver.cpp:105] Iteration 34200, lr = 0.1
I1006 15:59:28.670564  2964 solver.cpp:218] Iteration 34300 (11.9683 iter/s, 8.35542s/100 iters), loss = 0.206155
I1006 15:59:28.670595  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.206155 (* 1 = 0.206155 loss)
I1006 15:59:28.670600  2964 sgd_solver.cpp:105] Iteration 34300, lr = 0.1
I1006 15:59:37.013164  2964 solver.cpp:218] Iteration 34400 (11.9868 iter/s, 8.34254s/100 iters), loss = 0.144443
I1006 15:59:37.013267  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.144443 (* 1 = 0.144443 loss)
I1006 15:59:37.013274  2964 sgd_solver.cpp:105] Iteration 34400, lr = 0.1
I1006 15:59:44.946486  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 15:59:45.280994  2964 solver.cpp:330] Iteration 34500, Testing net (#0)
I1006 15:59:47.202828  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 15:59:47.283305  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8073
I1006 15:59:47.283330  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.592754 (* 1 = 0.592754 loss)
I1006 15:59:47.366545  2964 solver.cpp:218] Iteration 34500 (9.65881 iter/s, 10.3532s/100 iters), loss = 0.178254
I1006 15:59:47.366567  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.178254 (* 1 = 0.178254 loss)
I1006 15:59:47.366575  2964 sgd_solver.cpp:105] Iteration 34500, lr = 0.1
I1006 15:59:55.713024  2964 solver.cpp:218] Iteration 34600 (11.9812 iter/s, 8.34643s/100 iters), loss = 0.240263
I1006 15:59:55.713065  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.240263 (* 1 = 0.240263 loss)
I1006 15:59:55.713071  2964 sgd_solver.cpp:105] Iteration 34600, lr = 0.1
I1006 16:00:04.065170  2964 solver.cpp:218] Iteration 34700 (11.9731 iter/s, 8.35208s/100 iters), loss = 0.28337
I1006 16:00:04.065201  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.28337 (* 1 = 0.28337 loss)
I1006 16:00:04.065207  2964 sgd_solver.cpp:105] Iteration 34700, lr = 0.1
I1006 16:00:12.409271  2964 solver.cpp:218] Iteration 34800 (11.9846 iter/s, 8.34404s/100 iters), loss = 0.168126
I1006 16:00:12.409394  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.168126 (* 1 = 0.168126 loss)
I1006 16:00:12.409399  2964 sgd_solver.cpp:105] Iteration 34800, lr = 0.1
I1006 16:00:20.764645  2964 solver.cpp:218] Iteration 34900 (11.9686 iter/s, 8.35523s/100 iters), loss = 0.204672
I1006 16:00:20.764686  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.204672 (* 1 = 0.204672 loss)
I1006 16:00:20.764691  2964 sgd_solver.cpp:105] Iteration 34900, lr = 0.1
I1006 16:00:28.696600  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:00:29.036378  2964 solver.cpp:330] Iteration 35000, Testing net (#0)
I1006 16:00:30.958616  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:00:31.038516  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7587
I1006 16:00:31.038542  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.709807 (* 1 = 0.709807 loss)
I1006 16:00:31.122651  2964 solver.cpp:218] Iteration 35000 (9.65444 iter/s, 10.3579s/100 iters), loss = 0.180959
I1006 16:00:31.122675  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.180959 (* 1 = 0.180959 loss)
I1006 16:00:31.122683  2964 sgd_solver.cpp:105] Iteration 35000, lr = 0.1
I1006 16:00:39.484081  2964 solver.cpp:218] Iteration 35100 (11.9598 iter/s, 8.36134s/100 iters), loss = 0.226786
I1006 16:00:39.484122  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.226786 (* 1 = 0.226786 loss)
I1006 16:00:39.484127  2964 sgd_solver.cpp:105] Iteration 35100, lr = 0.1
I1006 16:00:47.840651  2964 solver.cpp:218] Iteration 35200 (11.9667 iter/s, 8.3565s/100 iters), loss = 0.261711
I1006 16:00:47.840786  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.261711 (* 1 = 0.261711 loss)
I1006 16:00:47.840803  2964 sgd_solver.cpp:105] Iteration 35200, lr = 0.1
I1006 16:00:56.202224  2964 solver.cpp:218] Iteration 35300 (11.9597 iter/s, 8.36141s/100 iters), loss = 0.224143
I1006 16:00:56.202266  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.224143 (* 1 = 0.224143 loss)
I1006 16:00:56.202272  2964 sgd_solver.cpp:105] Iteration 35300, lr = 0.1
I1006 16:01:04.562311  2964 solver.cpp:218] Iteration 35400 (11.9617 iter/s, 8.36002s/100 iters), loss = 0.16522
I1006 16:01:04.562351  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.16522 (* 1 = 0.16522 loss)
I1006 16:01:04.562356  2964 sgd_solver.cpp:105] Iteration 35400, lr = 0.1
I1006 16:01:12.506759  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:01:12.840673  2964 solver.cpp:330] Iteration 35500, Testing net (#0)
I1006 16:01:14.764667  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:01:14.845367  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7378
I1006 16:01:14.845392  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.06503 (* 1 = 1.06503 loss)
I1006 16:01:14.928704  2964 solver.cpp:218] Iteration 35500 (9.64662 iter/s, 10.3663s/100 iters), loss = 0.209263
I1006 16:01:14.928730  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.209263 (* 1 = 0.209263 loss)
I1006 16:01:14.928735  2964 sgd_solver.cpp:105] Iteration 35500, lr = 0.1
I1006 16:01:23.280632  2964 solver.cpp:218] Iteration 35600 (11.9734 iter/s, 8.35187s/100 iters), loss = 0.228933
I1006 16:01:23.280751  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.228933 (* 1 = 0.228933 loss)
I1006 16:01:23.280768  2964 sgd_solver.cpp:105] Iteration 35600, lr = 0.1
I1006 16:01:31.637486  2964 solver.cpp:218] Iteration 35700 (11.9664 iter/s, 8.35671s/100 iters), loss = 0.198744
I1006 16:01:31.637527  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.198744 (* 1 = 0.198744 loss)
I1006 16:01:31.637533  2964 sgd_solver.cpp:105] Iteration 35700, lr = 0.1
I1006 16:01:39.987897  2964 solver.cpp:218] Iteration 35800 (11.9756 iter/s, 8.35034s/100 iters), loss = 0.229216
I1006 16:01:39.987941  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.229216 (* 1 = 0.229216 loss)
I1006 16:01:39.987946  2964 sgd_solver.cpp:105] Iteration 35800, lr = 0.1
I1006 16:01:48.335501  2964 solver.cpp:218] Iteration 35900 (11.9796 iter/s, 8.34753s/100 iters), loss = 0.193889
I1006 16:01:48.335543  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.193889 (* 1 = 0.193889 loss)
I1006 16:01:48.335548  2964 sgd_solver.cpp:105] Iteration 35900, lr = 0.1
I1006 16:01:56.276340  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:01:56.609552  2964 solver.cpp:330] Iteration 36000, Testing net (#0)
I1006 16:01:58.531204  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:01:58.611618  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8227
I1006 16:01:58.611644  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.546188 (* 1 = 0.546188 loss)
I1006 16:01:58.695394  2964 solver.cpp:218] Iteration 36000 (9.65268 iter/s, 10.3598s/100 iters), loss = 0.219916
I1006 16:01:58.695417  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.219916 (* 1 = 0.219916 loss)
I1006 16:01:58.695425  2964 sgd_solver.cpp:105] Iteration 36000, lr = 0.1
I1006 16:02:07.051899  2964 solver.cpp:218] Iteration 36100 (11.9668 iter/s, 8.35645s/100 iters), loss = 0.136995
I1006 16:02:07.051931  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.136995 (* 1 = 0.136995 loss)
I1006 16:02:07.051947  2964 sgd_solver.cpp:105] Iteration 36100, lr = 0.1
I1006 16:02:15.404075  2964 solver.cpp:218] Iteration 36200 (11.973 iter/s, 8.35212s/100 iters), loss = 0.254437
I1006 16:02:15.404106  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.254437 (* 1 = 0.254437 loss)
I1006 16:02:15.404112  2964 sgd_solver.cpp:105] Iteration 36200, lr = 0.1
I1006 16:02:23.755960  2964 solver.cpp:218] Iteration 36300 (11.9734 iter/s, 8.35183s/100 iters), loss = 0.190143
I1006 16:02:23.755991  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.190143 (* 1 = 0.190143 loss)
I1006 16:02:23.755997  2964 sgd_solver.cpp:105] Iteration 36300, lr = 0.1
I1006 16:02:32.109227  2964 solver.cpp:218] Iteration 36400 (11.9714 iter/s, 8.35321s/100 iters), loss = 0.198576
I1006 16:02:32.109342  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.198576 (* 1 = 0.198576 loss)
I1006 16:02:32.109349  2964 sgd_solver.cpp:105] Iteration 36400, lr = 0.1
I1006 16:02:40.054225  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:02:40.388329  2964 solver.cpp:330] Iteration 36500, Testing net (#0)
I1006 16:02:42.311236  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:02:42.391242  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7821
I1006 16:02:42.391278  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.705534 (* 1 = 0.705534 loss)
I1006 16:02:42.474370  2964 solver.cpp:218] Iteration 36500 (9.64786 iter/s, 10.365s/100 iters), loss = 0.139789
I1006 16:02:42.474395  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.139789 (* 1 = 0.139789 loss)
I1006 16:02:42.474400  2964 sgd_solver.cpp:105] Iteration 36500, lr = 0.1
I1006 16:02:50.827427  2964 solver.cpp:218] Iteration 36600 (11.9717 iter/s, 8.353s/100 iters), loss = 0.207052
I1006 16:02:50.827458  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.207052 (* 1 = 0.207052 loss)
I1006 16:02:50.827466  2964 sgd_solver.cpp:105] Iteration 36600, lr = 0.1
I1006 16:02:59.175196  2964 solver.cpp:218] Iteration 36700 (11.9793 iter/s, 8.34771s/100 iters), loss = 0.198052
I1006 16:02:59.175227  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.198052 (* 1 = 0.198052 loss)
I1006 16:02:59.175233  2964 sgd_solver.cpp:105] Iteration 36700, lr = 0.1
I1006 16:03:07.521944  2964 solver.cpp:218] Iteration 36800 (11.9808 iter/s, 8.34669s/100 iters), loss = 0.133183
I1006 16:03:07.522053  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.133183 (* 1 = 0.133183 loss)
I1006 16:03:07.522059  2964 sgd_solver.cpp:105] Iteration 36800, lr = 0.1
I1006 16:03:15.871079  2964 solver.cpp:218] Iteration 36900 (11.9775 iter/s, 8.349s/100 iters), loss = 0.176259
I1006 16:03:15.871110  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.176259 (* 1 = 0.176259 loss)
I1006 16:03:15.871116  2964 sgd_solver.cpp:105] Iteration 36900, lr = 0.1
I1006 16:03:23.804448  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:03:24.139993  2964 solver.cpp:330] Iteration 37000, Testing net (#0)
I1006 16:03:26.063045  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:03:26.143122  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7503
I1006 16:03:26.143158  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.842979 (* 1 = 0.842979 loss)
I1006 16:03:26.226605  2964 solver.cpp:218] Iteration 37000 (9.65674 iter/s, 10.3555s/100 iters), loss = 0.14389
I1006 16:03:26.226631  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.14389 (* 1 = 0.14389 loss)
I1006 16:03:26.226637  2964 sgd_solver.cpp:105] Iteration 37000, lr = 0.1
I1006 16:03:34.577445  2964 solver.cpp:218] Iteration 37100 (11.9749 iter/s, 8.35079s/100 iters), loss = 0.237679
I1006 16:03:34.577487  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.237679 (* 1 = 0.237679 loss)
I1006 16:03:34.577493  2964 sgd_solver.cpp:105] Iteration 37100, lr = 0.1
I1006 16:03:42.915848  2964 solver.cpp:218] Iteration 37200 (11.9928 iter/s, 8.33833s/100 iters), loss = 0.185317
I1006 16:03:42.915946  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.185317 (* 1 = 0.185317 loss)
I1006 16:03:42.915953  2964 sgd_solver.cpp:105] Iteration 37200, lr = 0.1
I1006 16:03:51.270344  2964 solver.cpp:218] Iteration 37300 (11.9698 iter/s, 8.35437s/100 iters), loss = 0.170264
I1006 16:03:51.270376  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.170264 (* 1 = 0.170264 loss)
I1006 16:03:51.270382  2964 sgd_solver.cpp:105] Iteration 37300, lr = 0.1
I1006 16:03:59.614365  2964 solver.cpp:218] Iteration 37400 (11.9847 iter/s, 8.34396s/100 iters), loss = 0.179434
I1006 16:03:59.614408  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.179434 (* 1 = 0.179434 loss)
I1006 16:03:59.614413  2964 sgd_solver.cpp:105] Iteration 37400, lr = 0.1
I1006 16:04:07.547262  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:04:07.881402  2964 solver.cpp:330] Iteration 37500, Testing net (#0)
I1006 16:04:09.805229  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:04:09.886279  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7935
I1006 16:04:09.886314  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.719714 (* 1 = 0.719714 loss)
I1006 16:04:09.968794  2964 solver.cpp:218] Iteration 37500 (9.65777 iter/s, 10.3544s/100 iters), loss = 0.201242
I1006 16:04:09.968817  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.201242 (* 1 = 0.201242 loss)
I1006 16:04:09.968824  2964 sgd_solver.cpp:105] Iteration 37500, lr = 0.1
I1006 16:04:18.313158  2964 solver.cpp:218] Iteration 37600 (11.9842 iter/s, 8.34431s/100 iters), loss = 0.132365
I1006 16:04:18.313303  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.132365 (* 1 = 0.132365 loss)
I1006 16:04:18.313313  2964 sgd_solver.cpp:105] Iteration 37600, lr = 0.1
I1006 16:04:26.668236  2964 solver.cpp:218] Iteration 37700 (11.969 iter/s, 8.35491s/100 iters), loss = 0.184385
I1006 16:04:26.668277  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.184385 (* 1 = 0.184385 loss)
I1006 16:04:26.668283  2964 sgd_solver.cpp:105] Iteration 37700, lr = 0.1
I1006 16:04:35.014266  2964 solver.cpp:218] Iteration 37800 (11.9818 iter/s, 8.34596s/100 iters), loss = 0.264117
I1006 16:04:35.014297  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.264117 (* 1 = 0.264117 loss)
I1006 16:04:35.014302  2964 sgd_solver.cpp:105] Iteration 37800, lr = 0.1
I1006 16:04:43.365082  2964 solver.cpp:218] Iteration 37900 (11.975 iter/s, 8.35076s/100 iters), loss = 0.179178
I1006 16:04:43.365114  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.179178 (* 1 = 0.179178 loss)
I1006 16:04:43.365131  2964 sgd_solver.cpp:105] Iteration 37900, lr = 0.1
I1006 16:04:51.296059  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:04:51.629992  2964 solver.cpp:330] Iteration 38000, Testing net (#0)
I1006 16:04:53.552415  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:04:53.632673  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6972
I1006 16:04:53.632699  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.944128 (* 1 = 0.944128 loss)
I1006 16:04:53.716620  2964 solver.cpp:218] Iteration 38000 (9.66046 iter/s, 10.3515s/100 iters), loss = 0.199214
I1006 16:04:53.716645  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.199214 (* 1 = 0.199214 loss)
I1006 16:04:53.716652  2964 sgd_solver.cpp:105] Iteration 38000, lr = 0.1
I1006 16:05:02.069865  2964 solver.cpp:218] Iteration 38100 (11.9715 iter/s, 8.35319s/100 iters), loss = 0.0752149
I1006 16:05:02.069895  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0752152 (* 1 = 0.0752152 loss)
I1006 16:05:02.069901  2964 sgd_solver.cpp:105] Iteration 38100, lr = 0.1
I1006 16:05:10.421660  2964 solver.cpp:218] Iteration 38200 (11.9736 iter/s, 8.35174s/100 iters), loss = 0.224083
I1006 16:05:10.421702  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.224083 (* 1 = 0.224083 loss)
I1006 16:05:10.421708  2964 sgd_solver.cpp:105] Iteration 38200, lr = 0.1
I1006 16:05:18.770359  2964 solver.cpp:218] Iteration 38300 (11.978 iter/s, 8.34863s/100 iters), loss = 0.201955
I1006 16:05:18.770401  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.201956 (* 1 = 0.201956 loss)
I1006 16:05:18.770408  2964 sgd_solver.cpp:105] Iteration 38300, lr = 0.1
I1006 16:05:27.119335  2964 solver.cpp:218] Iteration 38400 (11.9776 iter/s, 8.34891s/100 iters), loss = 0.180522
I1006 16:05:27.119488  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.180523 (* 1 = 0.180523 loss)
I1006 16:05:27.119506  2964 sgd_solver.cpp:105] Iteration 38400, lr = 0.1
I1006 16:05:35.053011  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:05:35.387574  2964 solver.cpp:330] Iteration 38500, Testing net (#0)
I1006 16:05:37.310533  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:05:37.391304  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7952
I1006 16:05:37.391330  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.637849 (* 1 = 0.637849 loss)
I1006 16:05:37.474115  2964 solver.cpp:218] Iteration 38500 (9.65754 iter/s, 10.3546s/100 iters), loss = 0.287067
I1006 16:05:37.474140  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.287067 (* 1 = 0.287067 loss)
I1006 16:05:37.474148  2964 sgd_solver.cpp:105] Iteration 38500, lr = 0.1
I1006 16:05:45.825472  2964 solver.cpp:218] Iteration 38600 (11.9742 iter/s, 8.3513s/100 iters), loss = 0.223208
I1006 16:05:45.825522  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.223208 (* 1 = 0.223208 loss)
I1006 16:05:45.825529  2964 sgd_solver.cpp:105] Iteration 38600, lr = 0.1
I1006 16:05:54.181418  2964 solver.cpp:218] Iteration 38700 (11.9676 iter/s, 8.35587s/100 iters), loss = 0.140485
I1006 16:05:54.181449  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.140486 (* 1 = 0.140486 loss)
I1006 16:05:54.181455  2964 sgd_solver.cpp:105] Iteration 38700, lr = 0.1
I1006 16:06:02.538650  2964 solver.cpp:218] Iteration 38800 (11.9658 iter/s, 8.35717s/100 iters), loss = 0.183269
I1006 16:06:02.538727  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.183269 (* 1 = 0.183269 loss)
I1006 16:06:02.538734  2964 sgd_solver.cpp:105] Iteration 38800, lr = 0.1
I1006 16:06:10.895936  2964 solver.cpp:218] Iteration 38900 (11.9658 iter/s, 8.35718s/100 iters), loss = 0.264499
I1006 16:06:10.895977  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.2645 (* 1 = 0.2645 loss)
I1006 16:06:10.895982  2964 sgd_solver.cpp:105] Iteration 38900, lr = 0.1
I1006 16:06:18.837357  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:06:19.172722  2964 solver.cpp:330] Iteration 39000, Testing net (#0)
I1006 16:06:21.095885  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:06:21.176134  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7852
I1006 16:06:21.176159  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.731271 (* 1 = 0.731271 loss)
I1006 16:06:21.260429  2964 solver.cpp:218] Iteration 39000 (9.64839 iter/s, 10.3644s/100 iters), loss = 0.188079
I1006 16:06:21.260454  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.188079 (* 1 = 0.188079 loss)
I1006 16:06:21.260462  2964 sgd_solver.cpp:105] Iteration 39000, lr = 0.1
I1006 16:06:29.614323  2964 solver.cpp:218] Iteration 39100 (11.9705 iter/s, 8.35384s/100 iters), loss = 0.152611
I1006 16:06:29.614367  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.152612 (* 1 = 0.152612 loss)
I1006 16:06:29.614372  2964 sgd_solver.cpp:105] Iteration 39100, lr = 0.1
I1006 16:06:37.960170  2964 solver.cpp:218] Iteration 39200 (11.9821 iter/s, 8.34578s/100 iters), loss = 0.191592
I1006 16:06:37.960316  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.191593 (* 1 = 0.191593 loss)
I1006 16:06:37.960324  2964 sgd_solver.cpp:105] Iteration 39200, lr = 0.1
I1006 16:06:46.315099  2964 solver.cpp:218] Iteration 39300 (11.9692 iter/s, 8.35477s/100 iters), loss = 0.17666
I1006 16:06:46.315140  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.176661 (* 1 = 0.176661 loss)
I1006 16:06:46.315146  2964 sgd_solver.cpp:105] Iteration 39300, lr = 0.1
I1006 16:06:54.663944  2964 solver.cpp:218] Iteration 39400 (11.9778 iter/s, 8.34878s/100 iters), loss = 0.311415
I1006 16:06:54.663985  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.311416 (* 1 = 0.311416 loss)
I1006 16:06:54.663991  2964 sgd_solver.cpp:105] Iteration 39400, lr = 0.1
I1006 16:07:02.606803  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:07:02.941567  2964 solver.cpp:330] Iteration 39500, Testing net (#0)
I1006 16:07:04.866104  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:07:04.946171  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8081
I1006 16:07:04.946197  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.594903 (* 1 = 0.594903 loss)
I1006 16:07:05.028976  2964 solver.cpp:218] Iteration 39500 (9.64789 iter/s, 10.365s/100 iters), loss = 0.159056
I1006 16:07:05.029000  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.159056 (* 1 = 0.159056 loss)
I1006 16:07:05.029007  2964 sgd_solver.cpp:105] Iteration 39500, lr = 0.1
I1006 16:07:13.375514  2964 solver.cpp:218] Iteration 39600 (11.9811 iter/s, 8.34649s/100 iters), loss = 0.227918
I1006 16:07:13.375640  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.227919 (* 1 = 0.227919 loss)
I1006 16:07:13.375648  2964 sgd_solver.cpp:105] Iteration 39600, lr = 0.1
I1006 16:07:21.735345  2964 solver.cpp:218] Iteration 39700 (11.9622 iter/s, 8.35968s/100 iters), loss = 0.268797
I1006 16:07:21.735386  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.268797 (* 1 = 0.268797 loss)
I1006 16:07:21.735394  2964 sgd_solver.cpp:105] Iteration 39700, lr = 0.1
I1006 16:07:30.082212  2964 solver.cpp:218] Iteration 39800 (11.9806 iter/s, 8.3468s/100 iters), loss = 0.174381
I1006 16:07:30.082244  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.174381 (* 1 = 0.174381 loss)
I1006 16:07:30.082250  2964 sgd_solver.cpp:105] Iteration 39800, lr = 0.1
I1006 16:07:38.437151  2964 solver.cpp:218] Iteration 39900 (11.9691 iter/s, 8.35488s/100 iters), loss = 0.122103
I1006 16:07:38.437182  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.122103 (* 1 = 0.122103 loss)
I1006 16:07:38.437188  2964 sgd_solver.cpp:105] Iteration 39900, lr = 0.1
I1006 16:07:46.375191  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:07:46.709789  2964 solver.cpp:330] Iteration 40000, Testing net (#0)
I1006 16:07:48.631392  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:07:48.711872  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7746
I1006 16:07:48.711899  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.716509 (* 1 = 0.716509 loss)
I1006 16:07:48.795464  2964 solver.cpp:218] Iteration 40000 (9.65414 iter/s, 10.3582s/100 iters), loss = 0.186138
I1006 16:07:48.795490  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.186139 (* 1 = 0.186139 loss)
I1006 16:07:48.795495  2964 sgd_solver.cpp:46] MultiStep Status: Iteration 40000, step = 1
I1006 16:07:48.795498  2964 sgd_solver.cpp:105] Iteration 40000, lr = 0.01
I1006 16:07:57.145856  2964 solver.cpp:218] Iteration 40100 (11.9756 iter/s, 8.35034s/100 iters), loss = 0.153778
I1006 16:07:57.145887  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.153779 (* 1 = 0.153779 loss)
I1006 16:07:57.145894  2964 sgd_solver.cpp:105] Iteration 40100, lr = 0.01
I1006 16:08:05.494287  2964 solver.cpp:218] Iteration 40200 (11.9784 iter/s, 8.34837s/100 iters), loss = 0.213887
I1006 16:08:05.494328  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.213887 (* 1 = 0.213887 loss)
I1006 16:08:05.494334  2964 sgd_solver.cpp:105] Iteration 40200, lr = 0.01
I1006 16:08:13.844447  2964 solver.cpp:218] Iteration 40300 (11.9759 iter/s, 8.35009s/100 iters), loss = 0.131311
I1006 16:08:13.844489  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.131311 (* 1 = 0.131311 loss)
I1006 16:08:13.844496  2964 sgd_solver.cpp:105] Iteration 40300, lr = 0.01
I1006 16:08:22.192621  2964 solver.cpp:218] Iteration 40400 (11.9788 iter/s, 8.34811s/100 iters), loss = 0.0879309
I1006 16:08:22.192764  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0879313 (* 1 = 0.0879313 loss)
I1006 16:08:22.192771  2964 sgd_solver.cpp:105] Iteration 40400, lr = 0.01
I1006 16:08:30.129120  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:08:30.463135  2964 solver.cpp:330] Iteration 40500, Testing net (#0)
I1006 16:08:32.385541  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:08:32.466485  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8994
I1006 16:08:32.466509  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.29635 (* 1 = 0.29635 loss)
I1006 16:08:32.548990  2964 solver.cpp:218] Iteration 40500 (9.65605 iter/s, 10.3562s/100 iters), loss = 0.0463051
I1006 16:08:32.549013  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0463054 (* 1 = 0.0463054 loss)
I1006 16:08:32.549021  2964 sgd_solver.cpp:105] Iteration 40500, lr = 0.01
I1006 16:08:40.897651  2964 solver.cpp:218] Iteration 40600 (11.978 iter/s, 8.34861s/100 iters), loss = 0.151279
I1006 16:08:40.897682  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.15128 (* 1 = 0.15128 loss)
I1006 16:08:40.897687  2964 sgd_solver.cpp:105] Iteration 40600, lr = 0.01
I1006 16:08:49.252948  2964 solver.cpp:218] Iteration 40700 (11.9685 iter/s, 8.35524s/100 iters), loss = 0.120382
I1006 16:08:49.252987  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.120383 (* 1 = 0.120383 loss)
I1006 16:08:49.252993  2964 sgd_solver.cpp:105] Iteration 40700, lr = 0.01
I1006 16:08:57.604245  2964 solver.cpp:218] Iteration 40800 (11.9743 iter/s, 8.35123s/100 iters), loss = 0.108465
I1006 16:08:57.604320  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.108466 (* 1 = 0.108466 loss)
I1006 16:08:57.604326  2964 sgd_solver.cpp:105] Iteration 40800, lr = 0.01
I1006 16:09:05.965792  2964 solver.cpp:218] Iteration 40900 (11.9597 iter/s, 8.36145s/100 iters), loss = 0.046304
I1006 16:09:05.965834  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0463044 (* 1 = 0.0463044 loss)
I1006 16:09:05.965840  2964 sgd_solver.cpp:105] Iteration 40900, lr = 0.01
I1006 16:09:13.894814  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:09:14.228631  2964 solver.cpp:330] Iteration 41000, Testing net (#0)
I1006 16:09:16.152420  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:09:16.232592  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.915
I1006 16:09:16.232619  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.255722 (* 1 = 0.255722 loss)
I1006 16:09:16.315948  2964 solver.cpp:218] Iteration 41000 (9.66176 iter/s, 10.3501s/100 iters), loss = 0.056619
I1006 16:09:16.315973  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0566194 (* 1 = 0.0566194 loss)
I1006 16:09:16.315979  2964 sgd_solver.cpp:105] Iteration 41000, lr = 0.01
I1006 16:09:24.664939  2964 solver.cpp:218] Iteration 41100 (11.9776 iter/s, 8.34894s/100 iters), loss = 0.142535
I1006 16:09:24.664970  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.142536 (* 1 = 0.142536 loss)
I1006 16:09:24.664976  2964 sgd_solver.cpp:105] Iteration 41100, lr = 0.01
I1006 16:09:33.013253  2964 solver.cpp:218] Iteration 41200 (11.9785 iter/s, 8.34826s/100 iters), loss = 0.0768065
I1006 16:09:33.013329  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0768069 (* 1 = 0.0768069 loss)
I1006 16:09:33.013335  2964 sgd_solver.cpp:105] Iteration 41200, lr = 0.01
I1006 16:09:41.360988  2964 solver.cpp:218] Iteration 41300 (11.9794 iter/s, 8.34763s/100 iters), loss = 0.0689418
I1006 16:09:41.361027  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0689422 (* 1 = 0.0689422 loss)
I1006 16:09:41.361033  2964 sgd_solver.cpp:105] Iteration 41300, lr = 0.01
I1006 16:09:49.706632  2964 solver.cpp:218] Iteration 41400 (11.9824 iter/s, 8.34558s/100 iters), loss = 0.0601382
I1006 16:09:49.706665  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0601386 (* 1 = 0.0601386 loss)
I1006 16:09:49.706670  2964 sgd_solver.cpp:105] Iteration 41400, lr = 0.01
I1006 16:09:57.635828  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:09:57.970711  2964 solver.cpp:330] Iteration 41500, Testing net (#0)
I1006 16:09:59.895478  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:09:59.976326  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9166
I1006 16:09:59.976352  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.247917 (* 1 = 0.247917 loss)
I1006 16:10:00.058826  2964 solver.cpp:218] Iteration 41500 (9.65985 iter/s, 10.3521s/100 iters), loss = 0.0796544
I1006 16:10:00.058861  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0796548 (* 1 = 0.0796548 loss)
I1006 16:10:00.058868  2964 sgd_solver.cpp:105] Iteration 41500, lr = 0.01
I1006 16:10:08.406781  2964 solver.cpp:218] Iteration 41600 (11.9791 iter/s, 8.34789s/100 iters), loss = 0.106157
I1006 16:10:08.406874  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.106157 (* 1 = 0.106157 loss)
I1006 16:10:08.406883  2964 sgd_solver.cpp:105] Iteration 41600, lr = 0.01
I1006 16:10:16.746647  2964 solver.cpp:218] Iteration 41700 (11.9908 iter/s, 8.33975s/100 iters), loss = 0.0800282
I1006 16:10:16.746696  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0800286 (* 1 = 0.0800286 loss)
I1006 16:10:16.746704  2964 sgd_solver.cpp:105] Iteration 41700, lr = 0.01
I1006 16:10:25.094439  2964 solver.cpp:218] Iteration 41800 (11.9793 iter/s, 8.34772s/100 iters), loss = 0.0771376
I1006 16:10:25.094470  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.077138 (* 1 = 0.077138 loss)
I1006 16:10:25.094475  2964 sgd_solver.cpp:105] Iteration 41800, lr = 0.01
I1006 16:10:33.436842  2964 solver.cpp:218] Iteration 41900 (11.987 iter/s, 8.34235s/100 iters), loss = 0.0599226
I1006 16:10:33.436879  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.059923 (* 1 = 0.059923 loss)
I1006 16:10:33.436887  2964 sgd_solver.cpp:105] Iteration 41900, lr = 0.01
I1006 16:10:41.358353  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:10:41.692562  2964 solver.cpp:330] Iteration 42000, Testing net (#0)
I1006 16:10:43.614198  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:10:43.694547  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9128
I1006 16:10:43.694574  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.268219 (* 1 = 0.268219 loss)
I1006 16:10:43.778053  2964 solver.cpp:218] Iteration 42000 (9.67011 iter/s, 10.3411s/100 iters), loss = 0.089315
I1006 16:10:43.778079  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0893153 (* 1 = 0.0893153 loss)
I1006 16:10:43.778085  2964 sgd_solver.cpp:105] Iteration 42000, lr = 0.01
I1006 16:10:52.129135  2964 solver.cpp:218] Iteration 42100 (11.9746 iter/s, 8.35103s/100 iters), loss = 0.0591656
I1006 16:10:52.129165  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.059166 (* 1 = 0.059166 loss)
I1006 16:10:52.129171  2964 sgd_solver.cpp:105] Iteration 42100, lr = 0.01
I1006 16:11:00.479194  2964 solver.cpp:218] Iteration 42200 (11.976 iter/s, 8.35s/100 iters), loss = 0.0677124
I1006 16:11:00.479236  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0677128 (* 1 = 0.0677128 loss)
I1006 16:11:00.479243  2964 sgd_solver.cpp:105] Iteration 42200, lr = 0.01
I1006 16:11:08.831717  2964 solver.cpp:218] Iteration 42300 (11.9725 iter/s, 8.35246s/100 iters), loss = 0.0794542
I1006 16:11:08.831759  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0794545 (* 1 = 0.0794545 loss)
I1006 16:11:08.831765  2964 sgd_solver.cpp:105] Iteration 42300, lr = 0.01
I1006 16:11:17.179636  2964 solver.cpp:218] Iteration 42400 (11.9791 iter/s, 8.34785s/100 iters), loss = 0.0414517
I1006 16:11:17.179735  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0414521 (* 1 = 0.0414521 loss)
I1006 16:11:17.179752  2964 sgd_solver.cpp:105] Iteration 42400, lr = 0.01
I1006 16:11:25.118573  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:11:25.452817  2964 solver.cpp:330] Iteration 42500, Testing net (#0)
I1006 16:11:27.376448  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:11:27.457304  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9148
I1006 16:11:27.457339  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.255497 (* 1 = 0.255497 loss)
I1006 16:11:27.540186  2964 solver.cpp:218] Iteration 42500 (9.65211 iter/s, 10.3604s/100 iters), loss = 0.0288201
I1006 16:11:27.540211  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0288204 (* 1 = 0.0288204 loss)
I1006 16:11:27.540218  2964 sgd_solver.cpp:105] Iteration 42500, lr = 0.01
I1006 16:11:35.889341  2964 solver.cpp:218] Iteration 42600 (11.9773 iter/s, 8.3491s/100 iters), loss = 0.0453004
I1006 16:11:35.889371  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0453007 (* 1 = 0.0453007 loss)
I1006 16:11:35.889377  2964 sgd_solver.cpp:105] Iteration 42600, lr = 0.01
I1006 16:11:44.238461  2964 solver.cpp:218] Iteration 42700 (11.9774 iter/s, 8.34906s/100 iters), loss = 0.0728209
I1006 16:11:44.238502  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0728213 (* 1 = 0.0728213 loss)
I1006 16:11:44.238508  2964 sgd_solver.cpp:105] Iteration 42700, lr = 0.01
I1006 16:11:52.581460  2964 solver.cpp:218] Iteration 42800 (11.9862 iter/s, 8.34293s/100 iters), loss = 0.0758209
I1006 16:11:52.581593  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0758212 (* 1 = 0.0758212 loss)
I1006 16:11:52.581601  2964 sgd_solver.cpp:105] Iteration 42800, lr = 0.01
I1006 16:12:00.940922  2964 solver.cpp:218] Iteration 42900 (11.9627 iter/s, 8.35932s/100 iters), loss = 0.0704407
I1006 16:12:00.940964  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.070441 (* 1 = 0.070441 loss)
I1006 16:12:00.940970  2964 sgd_solver.cpp:105] Iteration 42900, lr = 0.01
I1006 16:12:08.871018  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:12:09.205196  2964 solver.cpp:330] Iteration 43000, Testing net (#0)
I1006 16:12:11.129637  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:12:11.209745  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9179
I1006 16:12:11.209780  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.25577 (* 1 = 0.25577 loss)
I1006 16:12:11.292846  2964 solver.cpp:218] Iteration 43000 (9.66011 iter/s, 10.3519s/100 iters), loss = 0.0364447
I1006 16:12:11.292871  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.036445 (* 1 = 0.036445 loss)
I1006 16:12:11.292878  2964 sgd_solver.cpp:105] Iteration 43000, lr = 0.01
I1006 16:12:19.639698  2964 solver.cpp:218] Iteration 43100 (11.9806 iter/s, 8.3468s/100 iters), loss = 0.0673316
I1006 16:12:19.639730  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0673319 (* 1 = 0.0673319 loss)
I1006 16:12:19.639736  2964 sgd_solver.cpp:105] Iteration 43100, lr = 0.01
I1006 16:12:27.983242  2964 solver.cpp:218] Iteration 43200 (11.9854 iter/s, 8.34348s/100 iters), loss = 0.10501
I1006 16:12:27.983351  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.105011 (* 1 = 0.105011 loss)
I1006 16:12:27.983367  2964 sgd_solver.cpp:105] Iteration 43200, lr = 0.01
I1006 16:12:36.337363  2964 solver.cpp:218] Iteration 43300 (11.9703 iter/s, 8.354s/100 iters), loss = 0.0264363
I1006 16:12:36.337405  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0264366 (* 1 = 0.0264366 loss)
I1006 16:12:36.337411  2964 sgd_solver.cpp:105] Iteration 43300, lr = 0.01
I1006 16:12:44.684478  2964 solver.cpp:218] Iteration 43400 (11.9803 iter/s, 8.34705s/100 iters), loss = 0.0131717
I1006 16:12:44.684518  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.013172 (* 1 = 0.013172 loss)
I1006 16:12:44.684525  2964 sgd_solver.cpp:105] Iteration 43400, lr = 0.01
I1006 16:12:52.626469  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:12:52.960863  2964 solver.cpp:330] Iteration 43500, Testing net (#0)
I1006 16:12:54.882308  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:12:54.966372  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.915
I1006 16:12:54.966408  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.267925 (* 1 = 0.267925 loss)
I1006 16:12:55.049187  2964 solver.cpp:218] Iteration 43500 (9.64819 iter/s, 10.3646s/100 iters), loss = 0.0317778
I1006 16:12:55.049209  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0317781 (* 1 = 0.0317781 loss)
I1006 16:12:55.049216  2964 sgd_solver.cpp:105] Iteration 43500, lr = 0.01
I1006 16:13:03.393908  2964 solver.cpp:218] Iteration 43600 (11.9837 iter/s, 8.34467s/100 iters), loss = 0.0752662
I1006 16:13:03.393997  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0752665 (* 1 = 0.0752665 loss)
I1006 16:13:03.394016  2964 sgd_solver.cpp:105] Iteration 43600, lr = 0.01
I1006 16:13:11.741533  2964 solver.cpp:218] Iteration 43700 (11.9796 iter/s, 8.34751s/100 iters), loss = 0.0435291
I1006 16:13:11.741576  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0435294 (* 1 = 0.0435294 loss)
I1006 16:13:11.741582  2964 sgd_solver.cpp:105] Iteration 43700, lr = 0.01
I1006 16:13:20.085690  2964 solver.cpp:218] Iteration 43800 (11.9845 iter/s, 8.34409s/100 iters), loss = 0.0536286
I1006 16:13:20.085721  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0536288 (* 1 = 0.0536288 loss)
I1006 16:13:20.085726  2964 sgd_solver.cpp:105] Iteration 43800, lr = 0.01
I1006 16:13:28.432449  2964 solver.cpp:218] Iteration 43900 (11.9808 iter/s, 8.3467s/100 iters), loss = 0.0107086
I1006 16:13:28.432481  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0107089 (* 1 = 0.0107089 loss)
I1006 16:13:28.432487  2964 sgd_solver.cpp:105] Iteration 43900, lr = 0.01
I1006 16:13:36.365036  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:13:36.699594  2964 solver.cpp:330] Iteration 44000, Testing net (#0)
I1006 16:13:38.622201  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:13:38.702703  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9166
I1006 16:13:38.702729  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.262262 (* 1 = 0.262262 loss)
I1006 16:13:38.786695  2964 solver.cpp:218] Iteration 44000 (9.65793 iter/s, 10.3542s/100 iters), loss = 0.0354591
I1006 16:13:38.786721  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0354593 (* 1 = 0.0354593 loss)
I1006 16:13:38.786728  2964 sgd_solver.cpp:105] Iteration 44000, lr = 0.01
I1006 16:13:47.192080  2964 solver.cpp:218] Iteration 44100 (11.8972 iter/s, 8.40533s/100 iters), loss = 0.0117495
I1006 16:13:47.192111  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0117498 (* 1 = 0.0117498 loss)
I1006 16:13:47.192117  2964 sgd_solver.cpp:105] Iteration 44100, lr = 0.01
I1006 16:13:55.624637  2964 solver.cpp:218] Iteration 44200 (11.8589 iter/s, 8.4325s/100 iters), loss = 0.0490357
I1006 16:13:55.624678  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.049036 (* 1 = 0.049036 loss)
I1006 16:13:55.624685  2964 sgd_solver.cpp:105] Iteration 44200, lr = 0.01
I1006 16:14:04.080133  2964 solver.cpp:218] Iteration 44300 (11.8267 iter/s, 8.45543s/100 iters), loss = 0.0659939
I1006 16:14:04.080165  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0659941 (* 1 = 0.0659941 loss)
I1006 16:14:04.080173  2964 sgd_solver.cpp:105] Iteration 44300, lr = 0.01
I1006 16:14:12.447755  2964 solver.cpp:218] Iteration 44400 (11.9509 iter/s, 8.36756s/100 iters), loss = 0.0373655
I1006 16:14:12.447917  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0373658 (* 1 = 0.0373658 loss)
I1006 16:14:12.447926  2964 sgd_solver.cpp:105] Iteration 44400, lr = 0.01
I1006 16:14:20.405700  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:14:20.739569  2964 solver.cpp:330] Iteration 44500, Testing net (#0)
I1006 16:14:22.662389  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:14:22.742842  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9184
I1006 16:14:22.742879  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.261793 (* 1 = 0.261793 loss)
I1006 16:14:22.825789  2964 solver.cpp:218] Iteration 44500 (9.63591 iter/s, 10.3778s/100 iters), loss = 0.0329556
I1006 16:14:22.825814  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0329558 (* 1 = 0.0329558 loss)
I1006 16:14:22.825820  2964 sgd_solver.cpp:105] Iteration 44500, lr = 0.01
I1006 16:14:31.194344  2964 solver.cpp:218] Iteration 44600 (11.9496 iter/s, 8.3685s/100 iters), loss = 0.038226
I1006 16:14:31.194375  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0382263 (* 1 = 0.0382263 loss)
I1006 16:14:31.194382  2964 sgd_solver.cpp:105] Iteration 44600, lr = 0.01
I1006 16:14:39.580711  2964 solver.cpp:218] Iteration 44700 (11.9242 iter/s, 8.38631s/100 iters), loss = 0.0366944
I1006 16:14:39.580755  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0366946 (* 1 = 0.0366946 loss)
I1006 16:14:39.580762  2964 sgd_solver.cpp:105] Iteration 44700, lr = 0.01
I1006 16:14:47.976748  2964 solver.cpp:218] Iteration 44800 (11.9105 iter/s, 8.39597s/100 iters), loss = 0.0127896
I1006 16:14:47.976810  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0127899 (* 1 = 0.0127899 loss)
I1006 16:14:47.976827  2964 sgd_solver.cpp:105] Iteration 44800, lr = 0.01
I1006 16:14:56.362678  2964 solver.cpp:218] Iteration 44900 (11.9249 iter/s, 8.38584s/100 iters), loss = 0.0799502
I1006 16:14:56.362720  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0799504 (* 1 = 0.0799504 loss)
I1006 16:14:56.362726  2964 sgd_solver.cpp:105] Iteration 44900, lr = 0.01
I1006 16:15:04.301827  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:15:04.637117  2964 solver.cpp:330] Iteration 45000, Testing net (#0)
I1006 16:15:06.569041  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:15:06.649435  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9163
I1006 16:15:06.649469  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.27412 (* 1 = 0.27412 loss)
I1006 16:15:06.732888  2964 solver.cpp:218] Iteration 45000 (9.64308 iter/s, 10.3701s/100 iters), loss = 0.0238714
I1006 16:15:06.732916  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0238716 (* 1 = 0.0238716 loss)
I1006 16:15:06.732924  2964 sgd_solver.cpp:105] Iteration 45000, lr = 0.01
I1006 16:15:15.216357  2964 solver.cpp:218] Iteration 45100 (11.7877 iter/s, 8.48341s/100 iters), loss = 0.0544107
I1006 16:15:15.216390  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.054411 (* 1 = 0.054411 loss)
I1006 16:15:15.216399  2964 sgd_solver.cpp:105] Iteration 45100, lr = 0.01
I1006 16:15:23.579939  2964 solver.cpp:218] Iteration 45200 (11.9567 iter/s, 8.36352s/100 iters), loss = 0.0422188
I1006 16:15:23.580054  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.042219 (* 1 = 0.042219 loss)
I1006 16:15:23.580085  2964 sgd_solver.cpp:105] Iteration 45200, lr = 0.01
I1006 16:15:31.971902  2964 solver.cpp:218] Iteration 45300 (11.9164 iter/s, 8.39183s/100 iters), loss = 0.0417665
I1006 16:15:31.971935  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0417668 (* 1 = 0.0417668 loss)
I1006 16:15:31.971942  2964 sgd_solver.cpp:105] Iteration 45300, lr = 0.01
I1006 16:15:40.453217  2964 solver.cpp:218] Iteration 45400 (11.7907 iter/s, 8.48125s/100 iters), loss = 0.0741997
I1006 16:15:40.453249  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0742 (* 1 = 0.0742 loss)
I1006 16:15:40.453256  2964 sgd_solver.cpp:105] Iteration 45400, lr = 0.01
I1006 16:15:48.547138  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:15:48.885677  2964 solver.cpp:330] Iteration 45500, Testing net (#0)
I1006 16:15:50.840648  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:15:50.921927  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9144
I1006 16:15:50.921952  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.282375 (* 1 = 0.282375 loss)
I1006 16:15:51.005463  2964 solver.cpp:218] Iteration 45500 (9.47672 iter/s, 10.5522s/100 iters), loss = 0.0504719
I1006 16:15:51.005493  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0504721 (* 1 = 0.0504721 loss)
I1006 16:15:51.005501  2964 sgd_solver.cpp:105] Iteration 45500, lr = 0.01
I1006 16:15:59.531183  2964 solver.cpp:218] Iteration 45600 (11.7293 iter/s, 8.52566s/100 iters), loss = 0.0670346
I1006 16:15:59.531319  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0670348 (* 1 = 0.0670348 loss)
I1006 16:15:59.531337  2964 sgd_solver.cpp:105] Iteration 45600, lr = 0.01
I1006 16:16:07.935153  2964 solver.cpp:218] Iteration 45700 (11.8994 iter/s, 8.40381s/100 iters), loss = 0.0480869
I1006 16:16:07.935230  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0480871 (* 1 = 0.0480871 loss)
I1006 16:16:07.935252  2964 sgd_solver.cpp:105] Iteration 45700, lr = 0.01
I1006 16:16:16.361340  2964 solver.cpp:218] Iteration 45800 (11.8679 iter/s, 8.42609s/100 iters), loss = 0.0538275
I1006 16:16:16.361371  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0538278 (* 1 = 0.0538278 loss)
I1006 16:16:16.361377  2964 sgd_solver.cpp:105] Iteration 45800, lr = 0.01
I1006 16:16:24.775346  2964 solver.cpp:218] Iteration 45900 (11.885 iter/s, 8.41394s/100 iters), loss = 0.0228335
I1006 16:16:24.775382  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0228337 (* 1 = 0.0228337 loss)
I1006 16:16:24.775400  2964 sgd_solver.cpp:105] Iteration 45900, lr = 0.01
I1006 16:16:32.830386  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:16:33.166532  2964 solver.cpp:330] Iteration 46000, Testing net (#0)
I1006 16:16:35.096577  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:16:35.176460  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9159
I1006 16:16:35.176486  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.287179 (* 1 = 0.287179 loss)
I1006 16:16:35.261546  2964 solver.cpp:218] Iteration 46000 (9.53641 iter/s, 10.4861s/100 iters), loss = 0.0274131
I1006 16:16:35.261589  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0274133 (* 1 = 0.0274133 loss)
I1006 16:16:35.261595  2964 sgd_solver.cpp:105] Iteration 46000, lr = 0.01
I1006 16:16:43.763767  2964 solver.cpp:218] Iteration 46100 (11.7618 iter/s, 8.50212s/100 iters), loss = 0.032605
I1006 16:16:43.763797  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0326053 (* 1 = 0.0326053 loss)
I1006 16:16:43.763803  2964 sgd_solver.cpp:105] Iteration 46100, lr = 0.01
I1006 16:16:52.175637  2964 solver.cpp:218] Iteration 46200 (11.888 iter/s, 8.41181s/100 iters), loss = 0.0258476
I1006 16:16:52.175667  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0258478 (* 1 = 0.0258478 loss)
I1006 16:16:52.175673  2964 sgd_solver.cpp:105] Iteration 46200, lr = 0.01
I1006 16:17:00.586611  2964 solver.cpp:218] Iteration 46300 (11.8893 iter/s, 8.41092s/100 iters), loss = 0.026474
I1006 16:17:00.586643  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0264742 (* 1 = 0.0264742 loss)
I1006 16:17:00.586650  2964 sgd_solver.cpp:105] Iteration 46300, lr = 0.01
I1006 16:17:09.005928  2964 solver.cpp:218] Iteration 46400 (11.8775 iter/s, 8.41926s/100 iters), loss = 0.0215178
I1006 16:17:09.006047  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.021518 (* 1 = 0.021518 loss)
I1006 16:17:09.006059  2964 sgd_solver.cpp:105] Iteration 46400, lr = 0.01
I1006 16:17:17.019418  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:17:17.354599  2964 solver.cpp:330] Iteration 46500, Testing net (#0)
I1006 16:17:19.281785  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:17:19.364608  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9182
I1006 16:17:19.364635  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.270046 (* 1 = 0.270046 loss)
I1006 16:17:19.447377  2964 solver.cpp:218] Iteration 46500 (9.57735 iter/s, 10.4413s/100 iters), loss = 0.0430754
I1006 16:17:19.447410  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0430756 (* 1 = 0.0430756 loss)
I1006 16:17:19.447418  2964 sgd_solver.cpp:105] Iteration 46500, lr = 0.01
I1006 16:17:27.855134  2964 solver.cpp:218] Iteration 46600 (11.8939 iter/s, 8.40769s/100 iters), loss = 0.0271259
I1006 16:17:27.855192  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0271261 (* 1 = 0.0271261 loss)
I1006 16:17:27.855206  2964 sgd_solver.cpp:105] Iteration 46600, lr = 0.01
I1006 16:17:36.241371  2964 solver.cpp:218] Iteration 46700 (11.9244 iter/s, 8.38615s/100 iters), loss = 0.0535129
I1006 16:17:36.241402  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0535132 (* 1 = 0.0535132 loss)
I1006 16:17:36.241408  2964 sgd_solver.cpp:105] Iteration 46700, lr = 0.01
I1006 16:17:44.709364  2964 solver.cpp:218] Iteration 46800 (11.8093 iter/s, 8.46793s/100 iters), loss = 0.0517933
I1006 16:17:44.709448  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0517935 (* 1 = 0.0517935 loss)
I1006 16:17:44.709468  2964 sgd_solver.cpp:105] Iteration 46800, lr = 0.01
I1006 16:17:53.177023  2964 solver.cpp:218] Iteration 46900 (11.8098 iter/s, 8.46755s/100 iters), loss = 0.016467
I1006 16:17:53.177055  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0164672 (* 1 = 0.0164672 loss)
I1006 16:17:53.177062  2964 sgd_solver.cpp:105] Iteration 46900, lr = 0.01
I1006 16:18:01.190435  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:18:01.525815  2964 solver.cpp:330] Iteration 47000, Testing net (#0)
I1006 16:18:03.484869  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:18:03.565027  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9163
I1006 16:18:03.565062  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.279571 (* 1 = 0.279571 loss)
I1006 16:18:03.648280  2964 solver.cpp:218] Iteration 47000 (9.55001 iter/s, 10.4712s/100 iters), loss = 0.0153259
I1006 16:18:03.648308  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0153261 (* 1 = 0.0153261 loss)
I1006 16:18:03.648314  2964 sgd_solver.cpp:105] Iteration 47000, lr = 0.01
I1006 16:18:12.008020  2964 solver.cpp:218] Iteration 47100 (11.9622 iter/s, 8.35968s/100 iters), loss = 0.0180447
I1006 16:18:12.008062  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0180449 (* 1 = 0.0180449 loss)
I1006 16:18:12.008069  2964 sgd_solver.cpp:105] Iteration 47100, lr = 0.01
I1006 16:18:20.506566  2964 solver.cpp:218] Iteration 47200 (11.7668 iter/s, 8.49847s/100 iters), loss = 0.019414
I1006 16:18:20.506721  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0194143 (* 1 = 0.0194143 loss)
I1006 16:18:20.506736  2964 sgd_solver.cpp:105] Iteration 47200, lr = 0.01
I1006 16:18:28.902037  2964 solver.cpp:218] Iteration 47300 (11.9114 iter/s, 8.39529s/100 iters), loss = 0.0279298
I1006 16:18:28.902081  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.02793 (* 1 = 0.02793 loss)
I1006 16:18:28.902086  2964 sgd_solver.cpp:105] Iteration 47300, lr = 0.01
I1006 16:18:37.366645  2964 solver.cpp:218] Iteration 47400 (11.814 iter/s, 8.46453s/100 iters), loss = 0.0180418
I1006 16:18:37.366680  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.018042 (* 1 = 0.018042 loss)
I1006 16:18:37.366688  2964 sgd_solver.cpp:105] Iteration 47400, lr = 0.01
I1006 16:18:45.393018  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:18:45.728440  2964 solver.cpp:330] Iteration 47500, Testing net (#0)
I1006 16:18:47.649503  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:18:47.729917  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9135
I1006 16:18:47.729951  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.297753 (* 1 = 0.297753 loss)
I1006 16:18:47.813200  2964 solver.cpp:218] Iteration 47500 (9.5726 iter/s, 10.4465s/100 iters), loss = 0.031247
I1006 16:18:47.813227  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0312472 (* 1 = 0.0312472 loss)
I1006 16:18:47.813235  2964 sgd_solver.cpp:105] Iteration 47500, lr = 0.01
I1006 16:18:56.165514  2964 solver.cpp:218] Iteration 47600 (11.9728 iter/s, 8.35226s/100 iters), loss = 0.0632013
I1006 16:18:56.165666  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0632016 (* 1 = 0.0632016 loss)
I1006 16:18:56.165674  2964 sgd_solver.cpp:105] Iteration 47600, lr = 0.01
I1006 16:19:04.520336  2964 solver.cpp:218] Iteration 47700 (11.9694 iter/s, 8.35464s/100 iters), loss = 0.0241472
I1006 16:19:04.520366  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0241474 (* 1 = 0.0241474 loss)
I1006 16:19:04.520371  2964 sgd_solver.cpp:105] Iteration 47700, lr = 0.01
I1006 16:19:12.874100  2964 solver.cpp:218] Iteration 47800 (11.9707 iter/s, 8.35371s/100 iters), loss = 0.00967188
I1006 16:19:12.874142  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00967209 (* 1 = 0.00967209 loss)
I1006 16:19:12.874148  2964 sgd_solver.cpp:105] Iteration 47800, lr = 0.01
I1006 16:19:21.227097  2964 solver.cpp:218] Iteration 47900 (11.9718 iter/s, 8.35293s/100 iters), loss = 0.00952464
I1006 16:19:21.227138  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00952485 (* 1 = 0.00952485 loss)
I1006 16:19:21.227144  2964 sgd_solver.cpp:105] Iteration 47900, lr = 0.01
I1006 16:19:29.200577  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:19:29.540396  2964 solver.cpp:330] Iteration 48000, Testing net (#0)
I1006 16:19:31.479027  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:19:31.558683  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9131
I1006 16:19:31.558710  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.29685 (* 1 = 0.29685 loss)
I1006 16:19:31.641618  2964 solver.cpp:218] Iteration 48000 (9.60205 iter/s, 10.4144s/100 iters), loss = 0.0174674
I1006 16:19:31.641651  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0174676 (* 1 = 0.0174676 loss)
I1006 16:19:31.641657  2964 sgd_solver.cpp:105] Iteration 48000, lr = 0.01
I1006 16:19:40.139166  2964 solver.cpp:218] Iteration 48100 (11.7682 iter/s, 8.49748s/100 iters), loss = 0.0579505
I1006 16:19:40.139204  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0579507 (* 1 = 0.0579507 loss)
I1006 16:19:40.139222  2964 sgd_solver.cpp:105] Iteration 48100, lr = 0.01
I1006 16:19:48.779255  2964 solver.cpp:218] Iteration 48200 (11.574 iter/s, 8.64002s/100 iters), loss = 0.0133033
I1006 16:19:48.779289  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0133035 (* 1 = 0.0133035 loss)
I1006 16:19:48.779294  2964 sgd_solver.cpp:105] Iteration 48200, lr = 0.01
I1006 16:19:57.390306  2964 solver.cpp:218] Iteration 48300 (11.6131 iter/s, 8.61099s/100 iters), loss = 0.0231996
I1006 16:19:57.390353  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0231998 (* 1 = 0.0231998 loss)
I1006 16:19:57.390360  2964 sgd_solver.cpp:105] Iteration 48300, lr = 0.01
I1006 16:20:05.961232  2964 solver.cpp:218] Iteration 48400 (11.6675 iter/s, 8.5708s/100 iters), loss = 0.0465156
I1006 16:20:05.961359  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0465158 (* 1 = 0.0465158 loss)
I1006 16:20:05.961367  2964 sgd_solver.cpp:105] Iteration 48400, lr = 0.01
I1006 16:20:14.116084  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:20:14.463040  2964 solver.cpp:330] Iteration 48500, Testing net (#0)
I1006 16:20:16.449488  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:20:16.531431  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.913
I1006 16:20:16.531458  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.304986 (* 1 = 0.304986 loss)
I1006 16:20:16.615640  2964 solver.cpp:218] Iteration 48500 (9.38592 iter/s, 10.6543s/100 iters), loss = 0.0138867
I1006 16:20:16.615676  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0138869 (* 1 = 0.0138869 loss)
I1006 16:20:16.615684  2964 sgd_solver.cpp:105] Iteration 48500, lr = 0.01
I1006 16:20:25.184906  2964 solver.cpp:218] Iteration 48600 (11.6697 iter/s, 8.5692s/100 iters), loss = 0.0187193
I1006 16:20:25.184947  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0187195 (* 1 = 0.0187195 loss)
I1006 16:20:25.184955  2964 sgd_solver.cpp:105] Iteration 48600, lr = 0.01
I1006 16:20:33.654911  2964 solver.cpp:218] Iteration 48700 (11.8065 iter/s, 8.46993s/100 iters), loss = 0.0297103
I1006 16:20:33.654958  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0297105 (* 1 = 0.0297105 loss)
I1006 16:20:33.654969  2964 sgd_solver.cpp:105] Iteration 48700, lr = 0.01
I1006 16:20:42.267858  2964 solver.cpp:218] Iteration 48800 (11.6105 iter/s, 8.61287s/100 iters), loss = 0.0139989
I1006 16:20:42.267961  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0139991 (* 1 = 0.0139991 loss)
I1006 16:20:42.267983  2964 sgd_solver.cpp:105] Iteration 48800, lr = 0.01
I1006 16:20:50.869112  2964 solver.cpp:218] Iteration 48900 (11.6264 iter/s, 8.60113s/100 iters), loss = 0.0385183
I1006 16:20:50.869150  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0385186 (* 1 = 0.0385186 loss)
I1006 16:20:50.869170  2964 sgd_solver.cpp:105] Iteration 48900, lr = 0.01
I1006 16:20:59.053267  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:20:59.398161  2964 solver.cpp:330] Iteration 49000, Testing net (#0)
I1006 16:21:01.390549  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:21:01.472470  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.912
I1006 16:21:01.472497  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.315637 (* 1 = 0.315637 loss)
I1006 16:21:01.557762  2964 solver.cpp:218] Iteration 49000 (9.35578 iter/s, 10.6886s/100 iters), loss = 0.0182614
I1006 16:21:01.557796  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0182616 (* 1 = 0.0182616 loss)
I1006 16:21:01.557803  2964 sgd_solver.cpp:105] Iteration 49000, lr = 0.01
I1006 16:21:10.201095  2964 solver.cpp:218] Iteration 49100 (11.5697 iter/s, 8.64327s/100 iters), loss = 0.00949984
I1006 16:21:10.201133  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00950007 (* 1 = 0.00950007 loss)
I1006 16:21:10.201153  2964 sgd_solver.cpp:105] Iteration 49100, lr = 0.01
I1006 16:21:18.734096  2964 solver.cpp:218] Iteration 49200 (11.7193 iter/s, 8.53293s/100 iters), loss = 0.00984804
I1006 16:21:18.734196  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00984826 (* 1 = 0.00984826 loss)
I1006 16:21:18.734212  2964 sgd_solver.cpp:105] Iteration 49200, lr = 0.01
I1006 16:21:27.135761  2964 solver.cpp:218] Iteration 49300 (11.9026 iter/s, 8.40154s/100 iters), loss = 0.0152305
I1006 16:21:27.135802  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0152307 (* 1 = 0.0152307 loss)
I1006 16:21:27.135812  2964 sgd_solver.cpp:105] Iteration 49300, lr = 0.01
I1006 16:21:35.520856  2964 solver.cpp:218] Iteration 49400 (11.926 iter/s, 8.38503s/100 iters), loss = 0.0223797
I1006 16:21:35.520887  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0223799 (* 1 = 0.0223799 loss)
I1006 16:21:35.520894  2964 sgd_solver.cpp:105] Iteration 49400, lr = 0.01
I1006 16:21:43.521003  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:21:43.861444  2964 solver.cpp:330] Iteration 49500, Testing net (#0)
I1006 16:21:45.807771  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:21:45.887739  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9126
I1006 16:21:45.887775  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.307031 (* 1 = 0.307031 loss)
I1006 16:21:45.971040  2964 solver.cpp:218] Iteration 49500 (9.56927 iter/s, 10.4501s/100 iters), loss = 0.0142936
I1006 16:21:45.971067  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0142938 (* 1 = 0.0142938 loss)
I1006 16:21:45.971074  2964 sgd_solver.cpp:105] Iteration 49500, lr = 0.01
I1006 16:21:54.364408  2964 solver.cpp:218] Iteration 49600 (11.9142 iter/s, 8.39331s/100 iters), loss = 0.0438667
I1006 16:21:54.364516  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.043867 (* 1 = 0.043867 loss)
I1006 16:21:54.364533  2964 sgd_solver.cpp:105] Iteration 49600, lr = 0.01
I1006 16:22:02.710232  2964 solver.cpp:218] Iteration 49700 (11.9822 iter/s, 8.34569s/100 iters), loss = 0.041695
I1006 16:22:02.710273  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0416952 (* 1 = 0.0416952 loss)
I1006 16:22:02.710279  2964 sgd_solver.cpp:105] Iteration 49700, lr = 0.01
I1006 16:22:11.137717  2964 solver.cpp:218] Iteration 49800 (11.866 iter/s, 8.42742s/100 iters), loss = 0.0423401
I1006 16:22:11.137749  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0423403 (* 1 = 0.0423403 loss)
I1006 16:22:11.137766  2964 sgd_solver.cpp:105] Iteration 49800, lr = 0.01
I1006 16:22:19.501945  2964 solver.cpp:218] Iteration 49900 (11.9558 iter/s, 8.36417s/100 iters), loss = 0.033205
I1006 16:22:19.501986  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0332052 (* 1 = 0.0332052 loss)
I1006 16:22:19.501991  2964 sgd_solver.cpp:105] Iteration 49900, lr = 0.01
I1006 16:22:27.424723  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:22:27.758705  2964 solver.cpp:330] Iteration 50000, Testing net (#0)
I1006 16:22:29.678850  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:22:29.758718  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9167
I1006 16:22:29.758752  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.302168 (* 1 = 0.302168 loss)
I1006 16:22:29.842057  2964 solver.cpp:218] Iteration 50000 (9.67114 iter/s, 10.34s/100 iters), loss = 0.02257
I1006 16:22:29.842082  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0225702 (* 1 = 0.0225702 loss)
I1006 16:22:29.842088  2964 sgd_solver.cpp:105] Iteration 50000, lr = 0.01
I1006 16:22:38.268913  2964 solver.cpp:218] Iteration 50100 (11.8669 iter/s, 8.4268s/100 iters), loss = 0.017011
I1006 16:22:38.268945  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0170112 (* 1 = 0.0170112 loss)
I1006 16:22:38.268951  2964 sgd_solver.cpp:105] Iteration 50100, lr = 0.01
I1006 16:22:46.690179  2964 solver.cpp:218] Iteration 50200 (11.8748 iter/s, 8.42121s/100 iters), loss = 0.0172062
I1006 16:22:46.690209  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0172065 (* 1 = 0.0172065 loss)
I1006 16:22:46.690225  2964 sgd_solver.cpp:105] Iteration 50200, lr = 0.01
I1006 16:22:55.046414  2964 solver.cpp:218] Iteration 50300 (11.9672 iter/s, 8.35617s/100 iters), loss = 0.0143798
I1006 16:22:55.046448  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.01438 (* 1 = 0.01438 loss)
I1006 16:22:55.046455  2964 sgd_solver.cpp:105] Iteration 50300, lr = 0.01
I1006 16:23:03.404211  2964 solver.cpp:218] Iteration 50400 (11.965 iter/s, 8.35773s/100 iters), loss = 0.0649712
I1006 16:23:03.404352  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0649714 (* 1 = 0.0649714 loss)
I1006 16:23:03.404361  2964 sgd_solver.cpp:105] Iteration 50400, lr = 0.01
I1006 16:23:11.356093  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:23:11.690495  2964 solver.cpp:330] Iteration 50500, Testing net (#0)
I1006 16:23:13.613328  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:23:13.694242  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9132
I1006 16:23:13.694278  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.302135 (* 1 = 0.302135 loss)
I1006 16:23:13.777868  2964 solver.cpp:218] Iteration 50500 (9.63996 iter/s, 10.3735s/100 iters), loss = 0.00849558
I1006 16:23:13.777895  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00849582 (* 1 = 0.00849582 loss)
I1006 16:23:13.777902  2964 sgd_solver.cpp:105] Iteration 50500, lr = 0.01
I1006 16:23:22.143854  2964 solver.cpp:218] Iteration 50600 (11.9532 iter/s, 8.36593s/100 iters), loss = 0.0116108
I1006 16:23:22.143887  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0116111 (* 1 = 0.0116111 loss)
I1006 16:23:22.143893  2964 sgd_solver.cpp:105] Iteration 50600, lr = 0.01
I1006 16:23:30.498059  2964 solver.cpp:218] Iteration 50700 (11.9701 iter/s, 8.35415s/100 iters), loss = 0.0217293
I1006 16:23:30.498090  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0217295 (* 1 = 0.0217295 loss)
I1006 16:23:30.498097  2964 sgd_solver.cpp:105] Iteration 50700, lr = 0.01
I1006 16:23:38.880578  2964 solver.cpp:218] Iteration 50800 (11.9297 iter/s, 8.38246s/100 iters), loss = 0.00825791
I1006 16:23:38.880735  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00825812 (* 1 = 0.00825812 loss)
I1006 16:23:38.880756  2964 sgd_solver.cpp:105] Iteration 50800, lr = 0.01
I1006 16:23:47.237287  2964 solver.cpp:218] Iteration 50900 (11.9667 iter/s, 8.35653s/100 iters), loss = 0.00615959
I1006 16:23:47.237320  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0061598 (* 1 = 0.0061598 loss)
I1006 16:23:47.237329  2964 sgd_solver.cpp:105] Iteration 50900, lr = 0.01
I1006 16:23:55.209832  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:23:55.543555  2964 solver.cpp:330] Iteration 51000, Testing net (#0)
I1006 16:23:57.468304  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:23:57.548687  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9207
I1006 16:23:57.548714  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.286433 (* 1 = 0.286433 loss)
I1006 16:23:57.631815  2964 solver.cpp:218] Iteration 51000 (9.62051 iter/s, 10.3945s/100 iters), loss = 0.0222949
I1006 16:23:57.631844  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0222951 (* 1 = 0.0222951 loss)
I1006 16:23:57.631852  2964 sgd_solver.cpp:105] Iteration 51000, lr = 0.01
I1006 16:24:06.061704  2964 solver.cpp:218] Iteration 51100 (11.8626 iter/s, 8.42983s/100 iters), loss = 0.0296347
I1006 16:24:06.061743  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.029635 (* 1 = 0.029635 loss)
I1006 16:24:06.061760  2964 sgd_solver.cpp:105] Iteration 51100, lr = 0.01
I1006 16:24:14.620740  2964 solver.cpp:218] Iteration 51200 (11.6837 iter/s, 8.55897s/100 iters), loss = 0.0136026
I1006 16:24:14.620872  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0136029 (* 1 = 0.0136029 loss)
I1006 16:24:14.620880  2964 sgd_solver.cpp:105] Iteration 51200, lr = 0.01
I1006 16:24:23.233165  2964 solver.cpp:218] Iteration 51300 (11.6114 iter/s, 8.61222s/100 iters), loss = 0.00960014
I1006 16:24:23.233219  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00960037 (* 1 = 0.00960037 loss)
I1006 16:24:23.233228  2964 sgd_solver.cpp:105] Iteration 51300, lr = 0.01
I1006 16:24:31.659646  2964 solver.cpp:218] Iteration 51400 (11.8675 iter/s, 8.42638s/100 iters), loss = 0.0144922
I1006 16:24:31.659680  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0144924 (* 1 = 0.0144924 loss)
I1006 16:24:31.659688  2964 sgd_solver.cpp:105] Iteration 51400, lr = 0.01
I1006 16:24:39.602814  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:24:39.938019  2964 solver.cpp:330] Iteration 51500, Testing net (#0)
I1006 16:24:41.859611  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:24:41.940531  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.916
I1006 16:24:41.940557  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.294828 (* 1 = 0.294828 loss)
I1006 16:24:42.023733  2964 solver.cpp:218] Iteration 51500 (9.64876 iter/s, 10.364s/100 iters), loss = 0.0131174
I1006 16:24:42.023761  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0131177 (* 1 = 0.0131177 loss)
I1006 16:24:42.023771  2964 sgd_solver.cpp:105] Iteration 51500, lr = 0.01
I1006 16:24:50.427455  2964 solver.cpp:218] Iteration 51600 (11.8996 iter/s, 8.40367s/100 iters), loss = 0.0278786
I1006 16:24:50.427587  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0278789 (* 1 = 0.0278789 loss)
I1006 16:24:50.427610  2964 sgd_solver.cpp:105] Iteration 51600, lr = 0.01
I1006 16:24:58.819021  2964 solver.cpp:218] Iteration 51700 (11.9169 iter/s, 8.39142s/100 iters), loss = 0.0162233
I1006 16:24:58.819052  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0162235 (* 1 = 0.0162235 loss)
I1006 16:24:58.819058  2964 sgd_solver.cpp:105] Iteration 51700, lr = 0.01
I1006 16:25:07.178335  2964 solver.cpp:218] Iteration 51800 (11.9628 iter/s, 8.35925s/100 iters), loss = 0.00881249
I1006 16:25:07.178367  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00881273 (* 1 = 0.00881273 loss)
I1006 16:25:07.178373  2964 sgd_solver.cpp:105] Iteration 51800, lr = 0.01
I1006 16:25:15.532063  2964 solver.cpp:218] Iteration 51900 (11.9708 iter/s, 8.35367s/100 iters), loss = 0.0377995
I1006 16:25:15.532094  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0377997 (* 1 = 0.0377997 loss)
I1006 16:25:15.532109  2964 sgd_solver.cpp:105] Iteration 51900, lr = 0.01
I1006 16:25:23.492380  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:25:23.829206  2964 solver.cpp:330] Iteration 52000, Testing net (#0)
I1006 16:25:25.754437  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:25:25.835002  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9193
I1006 16:25:25.835037  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.291223 (* 1 = 0.291223 loss)
I1006 16:25:25.917908  2964 solver.cpp:218] Iteration 52000 (9.62855 iter/s, 10.3858s/100 iters), loss = 0.0257509
I1006 16:25:25.917934  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0257511 (* 1 = 0.0257511 loss)
I1006 16:25:25.917940  2964 sgd_solver.cpp:105] Iteration 52000, lr = 0.01
I1006 16:25:34.290093  2964 solver.cpp:218] Iteration 52100 (11.9444 iter/s, 8.37213s/100 iters), loss = 0.0266895
I1006 16:25:34.290134  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0266897 (* 1 = 0.0266897 loss)
I1006 16:25:34.290141  2964 sgd_solver.cpp:105] Iteration 52100, lr = 0.01
I1006 16:25:42.646764  2964 solver.cpp:218] Iteration 52200 (11.9666 iter/s, 8.3566s/100 iters), loss = 0.00622359
I1006 16:25:42.646805  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00622383 (* 1 = 0.00622383 loss)
I1006 16:25:42.646811  2964 sgd_solver.cpp:105] Iteration 52200, lr = 0.01
I1006 16:25:51.037609  2964 solver.cpp:218] Iteration 52300 (11.9178 iter/s, 8.39078s/100 iters), loss = 0.0330343
I1006 16:25:51.037649  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0330346 (* 1 = 0.0330346 loss)
I1006 16:25:51.037655  2964 sgd_solver.cpp:105] Iteration 52300, lr = 0.01
I1006 16:25:59.434731  2964 solver.cpp:218] Iteration 52400 (11.9089 iter/s, 8.39705s/100 iters), loss = 0.00727515
I1006 16:25:59.434835  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00727537 (* 1 = 0.00727537 loss)
I1006 16:25:59.434844  2964 sgd_solver.cpp:105] Iteration 52400, lr = 0.01
I1006 16:26:07.428997  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:26:07.763661  2964 solver.cpp:330] Iteration 52500, Testing net (#0)
I1006 16:26:09.691875  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:26:09.772039  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9176
I1006 16:26:09.772065  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.301599 (* 1 = 0.301599 loss)
I1006 16:26:09.854970  2964 solver.cpp:218] Iteration 52500 (9.59683 iter/s, 10.4201s/100 iters), loss = 0.00503598
I1006 16:26:09.854997  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00503621 (* 1 = 0.00503621 loss)
I1006 16:26:09.855005  2964 sgd_solver.cpp:105] Iteration 52500, lr = 0.01
I1006 16:26:18.282493  2964 solver.cpp:218] Iteration 52600 (11.866 iter/s, 8.42747s/100 iters), loss = 0.0178629
I1006 16:26:18.282524  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0178631 (* 1 = 0.0178631 loss)
I1006 16:26:18.282531  2964 sgd_solver.cpp:105] Iteration 52600, lr = 0.01
I1006 16:26:26.674193  2964 solver.cpp:218] Iteration 52700 (11.9166 iter/s, 8.39164s/100 iters), loss = 0.0112791
I1006 16:26:26.674226  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0112793 (* 1 = 0.0112793 loss)
I1006 16:26:26.674232  2964 sgd_solver.cpp:105] Iteration 52700, lr = 0.01
I1006 16:26:35.051050  2964 solver.cpp:218] Iteration 52800 (11.9377 iter/s, 8.37679s/100 iters), loss = 0.00596041
I1006 16:26:35.051190  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00596062 (* 1 = 0.00596062 loss)
I1006 16:26:35.051199  2964 sgd_solver.cpp:105] Iteration 52800, lr = 0.01
I1006 16:26:43.486016  2964 solver.cpp:218] Iteration 52900 (11.8556 iter/s, 8.4348s/100 iters), loss = 0.0289228
I1006 16:26:43.486055  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.028923 (* 1 = 0.028923 loss)
I1006 16:26:43.486062  2964 sgd_solver.cpp:105] Iteration 52900, lr = 0.01
I1006 16:26:51.436143  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:26:51.770457  2964 solver.cpp:330] Iteration 53000, Testing net (#0)
I1006 16:26:53.707192  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:26:53.788372  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9171
I1006 16:26:53.788398  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.316481 (* 1 = 0.316481 loss)
I1006 16:26:53.871541  2964 solver.cpp:218] Iteration 53000 (9.62885 iter/s, 10.3855s/100 iters), loss = 0.0115299
I1006 16:26:53.871569  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0115301 (* 1 = 0.0115301 loss)
I1006 16:26:53.871577  2964 sgd_solver.cpp:105] Iteration 53000, lr = 0.01
I1006 16:27:02.344179  2964 solver.cpp:218] Iteration 53100 (11.8028 iter/s, 8.47258s/100 iters), loss = 0.0127624
I1006 16:27:02.344210  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0127626 (* 1 = 0.0127626 loss)
I1006 16:27:02.344228  2964 sgd_solver.cpp:105] Iteration 53100, lr = 0.01
I1006 16:27:10.728461  2964 solver.cpp:218] Iteration 53200 (11.9272 iter/s, 8.38422s/100 iters), loss = 0.0251247
I1006 16:27:10.728586  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.025125 (* 1 = 0.025125 loss)
I1006 16:27:10.728595  2964 sgd_solver.cpp:105] Iteration 53200, lr = 0.01
I1006 16:27:19.145750  2964 solver.cpp:218] Iteration 53300 (11.8805 iter/s, 8.41714s/100 iters), loss = 0.0100904
I1006 16:27:19.145790  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0100906 (* 1 = 0.0100906 loss)
I1006 16:27:19.145797  2964 sgd_solver.cpp:105] Iteration 53300, lr = 0.01
I1006 16:27:27.514751  2964 solver.cpp:218] Iteration 53400 (11.949 iter/s, 8.36894s/100 iters), loss = 0.0230075
I1006 16:27:27.514781  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0230077 (* 1 = 0.0230077 loss)
I1006 16:27:27.514787  2964 sgd_solver.cpp:105] Iteration 53400, lr = 0.01
I1006 16:27:35.517303  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:27:35.856402  2964 solver.cpp:330] Iteration 53500, Testing net (#0)
I1006 16:27:37.808274  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:27:37.888407  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9152
I1006 16:27:37.888432  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.320524 (* 1 = 0.320524 loss)
I1006 16:27:37.971657  2964 solver.cpp:218] Iteration 53500 (9.56312 iter/s, 10.4568s/100 iters), loss = 0.0340726
I1006 16:27:37.971681  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0340728 (* 1 = 0.0340728 loss)
I1006 16:27:37.971688  2964 sgd_solver.cpp:105] Iteration 53500, lr = 0.01
I1006 16:27:46.317528  2964 solver.cpp:218] Iteration 53600 (11.982 iter/s, 8.34582s/100 iters), loss = 0.0117777
I1006 16:27:46.317692  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0117779 (* 1 = 0.0117779 loss)
I1006 16:27:46.317700  2964 sgd_solver.cpp:105] Iteration 53600, lr = 0.01
I1006 16:27:54.730491  2964 solver.cpp:218] Iteration 53700 (11.8867 iter/s, 8.41278s/100 iters), loss = 0.0136541
I1006 16:27:54.730528  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0136543 (* 1 = 0.0136543 loss)
I1006 16:27:54.730536  2964 sgd_solver.cpp:105] Iteration 53700, lr = 0.01
I1006 16:28:03.116505  2964 solver.cpp:218] Iteration 53800 (11.9248 iter/s, 8.38592s/100 iters), loss = 0.0151139
I1006 16:28:03.116535  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0151141 (* 1 = 0.0151141 loss)
I1006 16:28:03.116541  2964 sgd_solver.cpp:105] Iteration 53800, lr = 0.01
I1006 16:28:11.477188  2964 solver.cpp:218] Iteration 53900 (11.9608 iter/s, 8.36063s/100 iters), loss = 0.00867907
I1006 16:28:11.477228  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00867928 (* 1 = 0.00867928 loss)
I1006 16:28:11.477234  2964 sgd_solver.cpp:105] Iteration 53900, lr = 0.01
I1006 16:28:19.413863  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:28:19.747951  2964 solver.cpp:330] Iteration 54000, Testing net (#0)
I1006 16:28:21.670572  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:28:21.751003  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9202
I1006 16:28:21.751027  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.302573 (* 1 = 0.302573 loss)
I1006 16:28:21.834074  2964 solver.cpp:218] Iteration 54000 (9.65548 iter/s, 10.3568s/100 iters), loss = 0.0122682
I1006 16:28:21.834103  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0122684 (* 1 = 0.0122684 loss)
I1006 16:28:21.834110  2964 sgd_solver.cpp:105] Iteration 54000, lr = 0.01
I1006 16:28:30.197371  2964 solver.cpp:218] Iteration 54100 (11.9571 iter/s, 8.36324s/100 iters), loss = 0.0209277
I1006 16:28:30.197401  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0209279 (* 1 = 0.0209279 loss)
I1006 16:28:30.197407  2964 sgd_solver.cpp:105] Iteration 54100, lr = 0.01
I1006 16:28:38.619423  2964 solver.cpp:218] Iteration 54200 (11.8737 iter/s, 8.422s/100 iters), loss = 0.0190243
I1006 16:28:38.619464  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0190245 (* 1 = 0.0190245 loss)
I1006 16:28:38.619472  2964 sgd_solver.cpp:105] Iteration 54200, lr = 0.01
I1006 16:28:47.015198  2964 solver.cpp:218] Iteration 54300 (11.9109 iter/s, 8.39571s/100 iters), loss = 0.0275789
I1006 16:28:47.015229  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0275791 (* 1 = 0.0275791 loss)
I1006 16:28:47.015235  2964 sgd_solver.cpp:105] Iteration 54300, lr = 0.01
I1006 16:28:55.433609  2964 solver.cpp:218] Iteration 54400 (11.8788 iter/s, 8.41835s/100 iters), loss = 0.0131485
I1006 16:28:55.433753  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0131488 (* 1 = 0.0131488 loss)
I1006 16:28:55.433761  2964 sgd_solver.cpp:105] Iteration 54400, lr = 0.01
I1006 16:29:03.504833  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:29:03.842372  2964 solver.cpp:330] Iteration 54500, Testing net (#0)
I1006 16:29:05.766880  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:29:05.846997  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9179
I1006 16:29:05.847020  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.31614 (* 1 = 0.31614 loss)
I1006 16:29:05.930055  2964 solver.cpp:218] Iteration 54500 (9.52719 iter/s, 10.4963s/100 iters), loss = 0.00858269
I1006 16:29:05.930080  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00858291 (* 1 = 0.00858291 loss)
I1006 16:29:05.930086  2964 sgd_solver.cpp:105] Iteration 54500, lr = 0.01
I1006 16:29:14.318554  2964 solver.cpp:218] Iteration 54600 (11.9212 iter/s, 8.38845s/100 iters), loss = 0.00447686
I1006 16:29:14.318585  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00447708 (* 1 = 0.00447708 loss)
I1006 16:29:14.318591  2964 sgd_solver.cpp:105] Iteration 54600, lr = 0.01
I1006 16:29:22.751443  2964 solver.cpp:218] Iteration 54700 (11.8584 iter/s, 8.43283s/100 iters), loss = 0.0273685
I1006 16:29:22.751474  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0273687 (* 1 = 0.0273687 loss)
I1006 16:29:22.751482  2964 sgd_solver.cpp:105] Iteration 54700, lr = 0.01
I1006 16:29:31.145946  2964 solver.cpp:218] Iteration 54800 (11.9126 iter/s, 8.39444s/100 iters), loss = 0.0240849
I1006 16:29:31.146047  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0240851 (* 1 = 0.0240851 loss)
I1006 16:29:31.146056  2964 sgd_solver.cpp:105] Iteration 54800, lr = 0.01
I1006 16:29:39.550437  2964 solver.cpp:218] Iteration 54900 (11.8986 iter/s, 8.40437s/100 iters), loss = 0.00567487
I1006 16:29:39.550477  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00567507 (* 1 = 0.00567507 loss)
I1006 16:29:39.550484  2964 sgd_solver.cpp:105] Iteration 54900, lr = 0.01
I1006 16:29:47.513115  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:29:47.848369  2964 solver.cpp:330] Iteration 55000, Testing net (#0)
I1006 16:29:49.771313  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:29:49.851521  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9155
I1006 16:29:49.851543  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.328276 (* 1 = 0.328276 loss)
I1006 16:29:49.934851  2964 solver.cpp:218] Iteration 55000 (9.62988 iter/s, 10.3843s/100 iters), loss = 0.00505659
I1006 16:29:49.934875  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00505679 (* 1 = 0.00505679 loss)
I1006 16:29:49.934882  2964 sgd_solver.cpp:105] Iteration 55000, lr = 0.01
I1006 16:29:58.307171  2964 solver.cpp:218] Iteration 55100 (11.9442 iter/s, 8.37227s/100 iters), loss = 0.0296613
I1006 16:29:58.307201  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0296615 (* 1 = 0.0296615 loss)
I1006 16:29:58.307209  2964 sgd_solver.cpp:105] Iteration 55100, lr = 0.01
I1006 16:30:06.674440  2964 solver.cpp:218] Iteration 55200 (11.9514 iter/s, 8.36721s/100 iters), loss = 0.0100529
I1006 16:30:06.674587  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0100531 (* 1 = 0.0100531 loss)
I1006 16:30:06.674595  2964 sgd_solver.cpp:105] Iteration 55200, lr = 0.01
I1006 16:30:15.091003  2964 solver.cpp:218] Iteration 55300 (11.8816 iter/s, 8.41639s/100 iters), loss = 0.00796344
I1006 16:30:15.091033  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00796365 (* 1 = 0.00796365 loss)
I1006 16:30:15.091039  2964 sgd_solver.cpp:105] Iteration 55300, lr = 0.01
I1006 16:30:23.513204  2964 solver.cpp:218] Iteration 55400 (11.8735 iter/s, 8.42215s/100 iters), loss = 0.0499616
I1006 16:30:23.513237  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0499618 (* 1 = 0.0499618 loss)
I1006 16:30:23.513245  2964 sgd_solver.cpp:105] Iteration 55400, lr = 0.01
I1006 16:30:31.505096  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:30:31.840073  2964 solver.cpp:330] Iteration 55500, Testing net (#0)
I1006 16:30:33.761255  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:30:33.841820  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9202
I1006 16:30:33.841856  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.31122 (* 1 = 0.31122 loss)
I1006 16:30:33.924899  2964 solver.cpp:218] Iteration 55500 (9.60464 iter/s, 10.4116s/100 iters), loss = 0.00483624
I1006 16:30:33.924926  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00483644 (* 1 = 0.00483644 loss)
I1006 16:30:33.924932  2964 sgd_solver.cpp:105] Iteration 55500, lr = 0.01
I1006 16:30:42.285161  2964 solver.cpp:218] Iteration 55600 (11.9614 iter/s, 8.36021s/100 iters), loss = 0.0137299
I1006 16:30:42.285297  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0137301 (* 1 = 0.0137301 loss)
I1006 16:30:42.285306  2964 sgd_solver.cpp:105] Iteration 55600, lr = 0.01
I1006 16:30:50.701835  2964 solver.cpp:218] Iteration 55700 (11.8814 iter/s, 8.41651s/100 iters), loss = 0.0145345
I1006 16:30:50.701867  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0145347 (* 1 = 0.0145347 loss)
I1006 16:30:50.701874  2964 sgd_solver.cpp:105] Iteration 55700, lr = 0.01
I1006 16:30:59.151938  2964 solver.cpp:218] Iteration 55800 (11.8343 iter/s, 8.45004s/100 iters), loss = 0.00721687
I1006 16:30:59.151969  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00721706 (* 1 = 0.00721706 loss)
I1006 16:30:59.151975  2964 sgd_solver.cpp:105] Iteration 55800, lr = 0.01
I1006 16:31:07.516422  2964 solver.cpp:218] Iteration 55900 (11.9554 iter/s, 8.36443s/100 iters), loss = 0.0113622
I1006 16:31:07.516453  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0113624 (* 1 = 0.0113624 loss)
I1006 16:31:07.516469  2964 sgd_solver.cpp:105] Iteration 55900, lr = 0.01
I1006 16:31:15.466692  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:31:15.806030  2964 solver.cpp:330] Iteration 56000, Testing net (#0)
I1006 16:31:17.751258  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:31:17.833520  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.919
I1006 16:31:17.833545  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.31195 (* 1 = 0.31195 loss)
I1006 16:31:17.918700  2964 solver.cpp:218] Iteration 56000 (9.61334 iter/s, 10.4022s/100 iters), loss = 0.0255179
I1006 16:31:17.918731  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0255181 (* 1 = 0.0255181 loss)
I1006 16:31:17.918737  2964 sgd_solver.cpp:105] Iteration 56000, lr = 0.01
I1006 16:31:26.384452  2964 solver.cpp:218] Iteration 56100 (11.8124 iter/s, 8.46569s/100 iters), loss = 0.00771177
I1006 16:31:26.384482  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00771195 (* 1 = 0.00771195 loss)
I1006 16:31:26.384488  2964 sgd_solver.cpp:105] Iteration 56100, lr = 0.01
I1006 16:31:34.813408  2964 solver.cpp:218] Iteration 56200 (11.8639 iter/s, 8.4289s/100 iters), loss = 0.0134221
I1006 16:31:34.813449  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0134222 (* 1 = 0.0134222 loss)
I1006 16:31:34.813455  2964 sgd_solver.cpp:105] Iteration 56200, lr = 0.01
I1006 16:31:43.196104  2964 solver.cpp:218] Iteration 56300 (11.9294 iter/s, 8.38263s/100 iters), loss = 0.00210828
I1006 16:31:43.196151  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00210845 (* 1 = 0.00210845 loss)
I1006 16:31:43.196159  2964 sgd_solver.cpp:105] Iteration 56300, lr = 0.01
I1006 16:31:51.602674  2964 solver.cpp:218] Iteration 56400 (11.8956 iter/s, 8.40649s/100 iters), loss = 0.0071279
I1006 16:31:51.602802  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00712806 (* 1 = 0.00712806 loss)
I1006 16:31:51.602809  2964 sgd_solver.cpp:105] Iteration 56400, lr = 0.01
I1006 16:31:59.543907  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:31:59.877866  2964 solver.cpp:330] Iteration 56500, Testing net (#0)
I1006 16:32:01.805928  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:32:01.886929  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9144
I1006 16:32:01.886965  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.325648 (* 1 = 0.325648 loss)
I1006 16:32:01.970147  2964 solver.cpp:218] Iteration 56500 (9.6457 iter/s, 10.3673s/100 iters), loss = 0.0317268
I1006 16:32:01.970175  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.031727 (* 1 = 0.031727 loss)
I1006 16:32:01.970180  2964 sgd_solver.cpp:105] Iteration 56500, lr = 0.01
I1006 16:32:10.383934  2964 solver.cpp:218] Iteration 56600 (11.8853 iter/s, 8.41373s/100 iters), loss = 0.0117424
I1006 16:32:10.383980  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0117426 (* 1 = 0.0117426 loss)
I1006 16:32:10.383986  2964 sgd_solver.cpp:105] Iteration 56600, lr = 0.01
I1006 16:32:18.787161  2964 solver.cpp:218] Iteration 56700 (11.9003 iter/s, 8.40312s/100 iters), loss = 0.0147757
I1006 16:32:18.787215  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0147759 (* 1 = 0.0147759 loss)
I1006 16:32:18.787221  2964 sgd_solver.cpp:105] Iteration 56700, lr = 0.01
I1006 16:32:27.211266  2964 solver.cpp:218] Iteration 56800 (11.8708 iter/s, 8.42402s/100 iters), loss = 0.0038576
I1006 16:32:27.211383  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00385776 (* 1 = 0.00385776 loss)
I1006 16:32:27.211401  2964 sgd_solver.cpp:105] Iteration 56800, lr = 0.01
I1006 16:32:35.652796  2964 solver.cpp:218] Iteration 56900 (11.8464 iter/s, 8.4414s/100 iters), loss = 0.0221738
I1006 16:32:35.652825  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.022174 (* 1 = 0.022174 loss)
I1006 16:32:35.652832  2964 sgd_solver.cpp:105] Iteration 56900, lr = 0.01
I1006 16:32:43.612220  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:32:43.948103  2964 solver.cpp:330] Iteration 57000, Testing net (#0)
I1006 16:32:45.871624  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:32:45.951784  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9148
I1006 16:32:45.951818  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.325098 (* 1 = 0.325098 loss)
I1006 16:32:46.036279  2964 solver.cpp:218] Iteration 57000 (9.63073 iter/s, 10.3834s/100 iters), loss = 0.0118775
I1006 16:32:46.036317  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0118777 (* 1 = 0.0118777 loss)
I1006 16:32:46.036324  2964 sgd_solver.cpp:105] Iteration 57000, lr = 0.01
I1006 16:32:54.397944  2964 solver.cpp:218] Iteration 57100 (11.9594 iter/s, 8.3616s/100 iters), loss = 0.0274061
I1006 16:32:54.397974  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0274063 (* 1 = 0.0274063 loss)
I1006 16:32:54.397980  2964 sgd_solver.cpp:105] Iteration 57100, lr = 0.01
I1006 16:33:02.766952  2964 solver.cpp:218] Iteration 57200 (11.9489 iter/s, 8.36895s/100 iters), loss = 0.0204006
I1006 16:33:02.767040  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0204007 (* 1 = 0.0204007 loss)
I1006 16:33:02.767055  2964 sgd_solver.cpp:105] Iteration 57200, lr = 0.01
I1006 16:33:11.178490  2964 solver.cpp:218] Iteration 57300 (11.8886 iter/s, 8.41142s/100 iters), loss = 0.01634
I1006 16:33:11.178524  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0163401 (* 1 = 0.0163401 loss)
I1006 16:33:11.178530  2964 sgd_solver.cpp:105] Iteration 57300, lr = 0.01
I1006 16:33:19.616149  2964 solver.cpp:218] Iteration 57400 (11.8517 iter/s, 8.4376s/100 iters), loss = 0.00539666
I1006 16:33:19.616212  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00539683 (* 1 = 0.00539683 loss)
I1006 16:33:19.616220  2964 sgd_solver.cpp:105] Iteration 57400, lr = 0.01
I1006 16:33:27.605489  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:33:27.941644  2964 solver.cpp:330] Iteration 57500, Testing net (#0)
I1006 16:33:29.876375  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:33:29.958637  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9137
I1006 16:33:29.958662  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.337443 (* 1 = 0.337443 loss)
I1006 16:33:30.041927  2964 solver.cpp:218] Iteration 57500 (9.59169 iter/s, 10.4257s/100 iters), loss = 0.00814238
I1006 16:33:30.041962  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00814256 (* 1 = 0.00814256 loss)
I1006 16:33:30.041980  2964 sgd_solver.cpp:105] Iteration 57500, lr = 0.01
I1006 16:33:38.420938  2964 solver.cpp:218] Iteration 57600 (11.9347 iter/s, 8.37895s/100 iters), loss = 0.00172277
I1006 16:33:38.421102  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00172296 (* 1 = 0.00172296 loss)
I1006 16:33:38.421121  2964 sgd_solver.cpp:105] Iteration 57600, lr = 0.01
I1006 16:33:46.875813  2964 solver.cpp:218] Iteration 57700 (11.8278 iter/s, 8.45469s/100 iters), loss = 0.0271714
I1006 16:33:46.875846  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0271716 (* 1 = 0.0271716 loss)
I1006 16:33:46.875854  2964 sgd_solver.cpp:105] Iteration 57700, lr = 0.01
I1006 16:33:55.273794  2964 solver.cpp:218] Iteration 57800 (11.9077 iter/s, 8.39792s/100 iters), loss = 0.0108729
I1006 16:33:55.273825  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0108731 (* 1 = 0.0108731 loss)
I1006 16:33:55.273833  2964 sgd_solver.cpp:105] Iteration 57800, lr = 0.01
I1006 16:34:03.712975  2964 solver.cpp:218] Iteration 57900 (11.8496 iter/s, 8.43912s/100 iters), loss = 0.00658302
I1006 16:34:03.713006  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00658321 (* 1 = 0.00658321 loss)
I1006 16:34:03.713013  2964 sgd_solver.cpp:105] Iteration 57900, lr = 0.01
I1006 16:34:11.739118  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:34:12.077711  2964 solver.cpp:330] Iteration 58000, Testing net (#0)
I1006 16:34:14.015733  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:34:14.099268  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.914
I1006 16:34:14.099294  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.339607 (* 1 = 0.339607 loss)
I1006 16:34:14.185746  2964 solver.cpp:218] Iteration 58000 (9.54863 iter/s, 10.4727s/100 iters), loss = 0.018299
I1006 16:34:14.185781  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0182992 (* 1 = 0.0182992 loss)
I1006 16:34:14.185787  2964 sgd_solver.cpp:105] Iteration 58000, lr = 0.01
I1006 16:34:22.561475  2964 solver.cpp:218] Iteration 58100 (11.9393 iter/s, 8.37567s/100 iters), loss = 0.0041438
I1006 16:34:22.561517  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00414399 (* 1 = 0.00414399 loss)
I1006 16:34:22.561524  2964 sgd_solver.cpp:105] Iteration 58100, lr = 0.01
I1006 16:34:30.912366  2964 solver.cpp:218] Iteration 58200 (11.9749 iter/s, 8.35082s/100 iters), loss = 0.0061168
I1006 16:34:30.912407  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00611698 (* 1 = 0.00611698 loss)
I1006 16:34:30.912415  2964 sgd_solver.cpp:105] Iteration 58200, lr = 0.01
I1006 16:34:39.265455  2964 solver.cpp:218] Iteration 58300 (11.9717 iter/s, 8.35302s/100 iters), loss = 0.0186992
I1006 16:34:39.265499  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0186994 (* 1 = 0.0186994 loss)
I1006 16:34:39.265506  2964 sgd_solver.cpp:105] Iteration 58300, lr = 0.01
I1006 16:34:47.694355  2964 solver.cpp:218] Iteration 58400 (11.864 iter/s, 8.42883s/100 iters), loss = 0.00419439
I1006 16:34:47.694479  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00419457 (* 1 = 0.00419457 loss)
I1006 16:34:47.694488  2964 sgd_solver.cpp:105] Iteration 58400, lr = 0.01
I1006 16:34:55.753438  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:34:56.087620  2964 solver.cpp:330] Iteration 58500, Testing net (#0)
I1006 16:34:58.011027  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:34:58.091605  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9152
I1006 16:34:58.091629  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.331279 (* 1 = 0.331279 loss)
I1006 16:34:58.174913  2964 solver.cpp:218] Iteration 58500 (9.54162 iter/s, 10.4804s/100 iters), loss = 0.0269987
I1006 16:34:58.174943  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0269989 (* 1 = 0.0269989 loss)
I1006 16:34:58.174950  2964 sgd_solver.cpp:105] Iteration 58500, lr = 0.01
I1006 16:35:06.528955  2964 solver.cpp:218] Iteration 58600 (11.9703 iter/s, 8.35399s/100 iters), loss = 0.0060192
I1006 16:35:06.528985  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00601938 (* 1 = 0.00601938 loss)
I1006 16:35:06.528990  2964 sgd_solver.cpp:105] Iteration 58600, lr = 0.01
I1006 16:35:14.882506  2964 solver.cpp:218] Iteration 58700 (11.971 iter/s, 8.3535s/100 iters), loss = 0.019922
I1006 16:35:14.882546  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0199222 (* 1 = 0.0199222 loss)
I1006 16:35:14.882552  2964 sgd_solver.cpp:105] Iteration 58700, lr = 0.01
I1006 16:35:23.236465  2964 solver.cpp:218] Iteration 58800 (11.9705 iter/s, 8.35389s/100 iters), loss = 0.0118085
I1006 16:35:23.236569  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0118087 (* 1 = 0.0118087 loss)
I1006 16:35:23.236577  2964 sgd_solver.cpp:105] Iteration 58800, lr = 0.01
I1006 16:35:31.591626  2964 solver.cpp:218] Iteration 58900 (11.9688 iter/s, 8.35503s/100 iters), loss = 0.00612836
I1006 16:35:31.591657  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00612854 (* 1 = 0.00612854 loss)
I1006 16:35:31.591665  2964 sgd_solver.cpp:105] Iteration 58900, lr = 0.01
I1006 16:35:39.531147  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:35:39.865167  2964 solver.cpp:330] Iteration 59000, Testing net (#0)
I1006 16:35:41.785320  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:35:41.865483  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9139
I1006 16:35:41.865520  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.350933 (* 1 = 0.350933 loss)
I1006 16:35:41.948042  2964 solver.cpp:218] Iteration 59000 (9.65591 iter/s, 10.3564s/100 iters), loss = 0.00394171
I1006 16:35:41.948067  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00394188 (* 1 = 0.00394188 loss)
I1006 16:35:41.948074  2964 sgd_solver.cpp:105] Iteration 59000, lr = 0.01
I1006 16:35:50.292954  2964 solver.cpp:218] Iteration 59100 (11.9834 iter/s, 8.34486s/100 iters), loss = 0.00671922
I1006 16:35:50.292996  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0067194 (* 1 = 0.0067194 loss)
I1006 16:35:50.293004  2964 sgd_solver.cpp:105] Iteration 59100, lr = 0.01
I1006 16:35:58.646849  2964 solver.cpp:218] Iteration 59200 (11.9706 iter/s, 8.35383s/100 iters), loss = 0.0166034
I1006 16:35:58.646925  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0166036 (* 1 = 0.0166036 loss)
I1006 16:35:58.646934  2964 sgd_solver.cpp:105] Iteration 59200, lr = 0.01
I1006 16:36:06.991348  2964 solver.cpp:218] Iteration 59300 (11.9841 iter/s, 8.3444s/100 iters), loss = 0.0130099
I1006 16:36:06.991389  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0130101 (* 1 = 0.0130101 loss)
I1006 16:36:06.991395  2964 sgd_solver.cpp:105] Iteration 59300, lr = 0.01
I1006 16:36:15.343703  2964 solver.cpp:218] Iteration 59400 (11.9728 iter/s, 8.35229s/100 iters), loss = 0.0118541
I1006 16:36:15.343734  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0118543 (* 1 = 0.0118543 loss)
I1006 16:36:15.343739  2964 sgd_solver.cpp:105] Iteration 59400, lr = 0.01
I1006 16:36:23.279299  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:36:23.614295  2964 solver.cpp:330] Iteration 59500, Testing net (#0)
I1006 16:36:25.535583  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:36:25.616046  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9156
I1006 16:36:25.616071  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.340122 (* 1 = 0.340122 loss)
I1006 16:36:25.699255  2964 solver.cpp:218] Iteration 59500 (9.65671 iter/s, 10.3555s/100 iters), loss = 0.00557463
I1006 16:36:25.699280  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00557482 (* 1 = 0.00557482 loss)
I1006 16:36:25.699287  2964 sgd_solver.cpp:105] Iteration 59500, lr = 0.01
I1006 16:36:34.046499  2964 solver.cpp:218] Iteration 59600 (11.9801 iter/s, 8.34719s/100 iters), loss = 0.0234288
I1006 16:36:34.046630  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.023429 (* 1 = 0.023429 loss)
I1006 16:36:34.046648  2964 sgd_solver.cpp:105] Iteration 59600, lr = 0.01
I1006 16:36:42.396484  2964 solver.cpp:218] Iteration 59700 (11.9763 iter/s, 8.34984s/100 iters), loss = 0.0216473
I1006 16:36:42.396513  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0216474 (* 1 = 0.0216474 loss)
I1006 16:36:42.396520  2964 sgd_solver.cpp:105] Iteration 59700, lr = 0.01
I1006 16:36:50.741439  2964 solver.cpp:218] Iteration 59800 (11.9834 iter/s, 8.3449s/100 iters), loss = 0.00882209
I1006 16:36:50.741468  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00882227 (* 1 = 0.00882227 loss)
I1006 16:36:50.741474  2964 sgd_solver.cpp:105] Iteration 59800, lr = 0.01
I1006 16:36:59.084341  2964 solver.cpp:218] Iteration 59900 (11.9863 iter/s, 8.34284s/100 iters), loss = 0.00698326
I1006 16:36:59.084370  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00698344 (* 1 = 0.00698344 loss)
I1006 16:36:59.084377  2964 sgd_solver.cpp:105] Iteration 59900, lr = 0.01
I1006 16:37:07.010083  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:37:07.345512  2964 solver.cpp:330] Iteration 60000, Testing net (#0)
I1006 16:37:09.266333  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:37:09.346751  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9181
I1006 16:37:09.346786  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.326662 (* 1 = 0.326662 loss)
I1006 16:37:09.430053  2964 solver.cpp:218] Iteration 60000 (9.6659 iter/s, 10.3457s/100 iters), loss = 0.00547215
I1006 16:37:09.430078  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00547234 (* 1 = 0.00547234 loss)
I1006 16:37:09.430085  2964 sgd_solver.cpp:105] Iteration 60000, lr = 0.01
I1006 16:37:17.774598  2964 solver.cpp:218] Iteration 60100 (11.984 iter/s, 8.34449s/100 iters), loss = 0.00669852
I1006 16:37:17.774629  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0066987 (* 1 = 0.0066987 loss)
I1006 16:37:17.774636  2964 sgd_solver.cpp:105] Iteration 60100, lr = 0.01
I1006 16:37:26.122581  2964 solver.cpp:218] Iteration 60200 (11.979 iter/s, 8.34793s/100 iters), loss = 0.0110575
I1006 16:37:26.122622  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0110577 (* 1 = 0.0110577 loss)
I1006 16:37:26.122627  2964 sgd_solver.cpp:105] Iteration 60200, lr = 0.01
I1006 16:37:34.469935  2964 solver.cpp:218] Iteration 60300 (11.9799 iter/s, 8.34729s/100 iters), loss = 0.0249202
I1006 16:37:34.469976  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0249203 (* 1 = 0.0249203 loss)
I1006 16:37:34.469982  2964 sgd_solver.cpp:105] Iteration 60300, lr = 0.01
I1006 16:37:42.820430  2964 solver.cpp:218] Iteration 60400 (11.9754 iter/s, 8.35043s/100 iters), loss = 0.0216
I1006 16:37:42.820530  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0216002 (* 1 = 0.0216002 loss)
I1006 16:37:42.820538  2964 sgd_solver.cpp:105] Iteration 60400, lr = 0.01
I1006 16:37:50.752952  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:37:51.087237  2964 solver.cpp:330] Iteration 60500, Testing net (#0)
I1006 16:37:53.007392  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:37:53.087826  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9168
I1006 16:37:53.087849  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.331643 (* 1 = 0.331643 loss)
I1006 16:37:53.171075  2964 solver.cpp:218] Iteration 60500 (9.66135 iter/s, 10.3505s/100 iters), loss = 0.00360134
I1006 16:37:53.171100  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00360153 (* 1 = 0.00360153 loss)
I1006 16:37:53.171108  2964 sgd_solver.cpp:105] Iteration 60500, lr = 0.01
I1006 16:38:01.512089  2964 solver.cpp:218] Iteration 60600 (11.989 iter/s, 8.34096s/100 iters), loss = 0.0187769
I1006 16:38:01.512125  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0187771 (* 1 = 0.0187771 loss)
I1006 16:38:01.512132  2964 sgd_solver.cpp:105] Iteration 60600, lr = 0.01
I1006 16:38:09.858325  2964 solver.cpp:218] Iteration 60700 (11.9815 iter/s, 8.34618s/100 iters), loss = 0.039768
I1006 16:38:09.858364  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0397682 (* 1 = 0.0397682 loss)
I1006 16:38:09.858371  2964 sgd_solver.cpp:105] Iteration 60700, lr = 0.01
I1006 16:38:18.203951  2964 solver.cpp:218] Iteration 60800 (11.9824 iter/s, 8.34556s/100 iters), loss = 0.0158423
I1006 16:38:18.204083  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0158425 (* 1 = 0.0158425 loss)
I1006 16:38:18.204103  2964 sgd_solver.cpp:105] Iteration 60800, lr = 0.01
I1006 16:38:26.542834  2964 solver.cpp:218] Iteration 60900 (11.9922 iter/s, 8.33873s/100 iters), loss = 0.00306763
I1006 16:38:26.542865  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00306782 (* 1 = 0.00306782 loss)
I1006 16:38:26.542870  2964 sgd_solver.cpp:105] Iteration 60900, lr = 0.01
I1006 16:38:34.471803  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:38:34.805438  2964 solver.cpp:330] Iteration 61000, Testing net (#0)
I1006 16:38:36.726253  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:38:36.806437  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9166
I1006 16:38:36.806463  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.325169 (* 1 = 0.325169 loss)
I1006 16:38:36.889300  2964 solver.cpp:218] Iteration 61000 (9.66519 iter/s, 10.3464s/100 iters), loss = 0.0143522
I1006 16:38:36.889343  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0143524 (* 1 = 0.0143524 loss)
I1006 16:38:36.889350  2964 sgd_solver.cpp:105] Iteration 61000, lr = 0.01
I1006 16:38:45.235088  2964 solver.cpp:218] Iteration 61100 (11.9822 iter/s, 8.34572s/100 iters), loss = 0.00615051
I1006 16:38:45.235119  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0061507 (* 1 = 0.0061507 loss)
I1006 16:38:45.235124  2964 sgd_solver.cpp:105] Iteration 61100, lr = 0.01
I1006 16:38:53.580986  2964 solver.cpp:218] Iteration 61200 (11.982 iter/s, 8.34584s/100 iters), loss = 0.0342555
I1006 16:38:53.581102  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0342557 (* 1 = 0.0342557 loss)
I1006 16:38:53.581118  2964 sgd_solver.cpp:105] Iteration 61200, lr = 0.01
I1006 16:39:01.926301  2964 solver.cpp:218] Iteration 61300 (11.983 iter/s, 8.34518s/100 iters), loss = 0.00205664
I1006 16:39:01.926342  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00205684 (* 1 = 0.00205684 loss)
I1006 16:39:01.926348  2964 sgd_solver.cpp:105] Iteration 61300, lr = 0.01
I1006 16:39:10.269412  2964 solver.cpp:218] Iteration 61400 (11.986 iter/s, 8.34304s/100 iters), loss = 0.00498157
I1006 16:39:10.269459  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00498177 (* 1 = 0.00498177 loss)
I1006 16:39:10.269467  2964 sgd_solver.cpp:105] Iteration 61400, lr = 0.01
I1006 16:39:18.204732  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:39:18.539474  2964 solver.cpp:330] Iteration 61500, Testing net (#0)
I1006 16:39:20.460469  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:39:20.540988  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9085
I1006 16:39:20.541024  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.367676 (* 1 = 0.367676 loss)
I1006 16:39:20.623980  2964 solver.cpp:218] Iteration 61500 (9.65764 iter/s, 10.3545s/100 iters), loss = 0.0106208
I1006 16:39:20.624004  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0106211 (* 1 = 0.0106211 loss)
I1006 16:39:20.624011  2964 sgd_solver.cpp:105] Iteration 61500, lr = 0.01
I1006 16:39:28.979753  2964 solver.cpp:218] Iteration 61600 (11.9678 iter/s, 8.35572s/100 iters), loss = 0.00345374
I1006 16:39:28.979887  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00345394 (* 1 = 0.00345394 loss)
I1006 16:39:28.979904  2964 sgd_solver.cpp:105] Iteration 61600, lr = 0.01
I1006 16:39:37.332710  2964 solver.cpp:218] Iteration 61700 (11.972 iter/s, 8.35281s/100 iters), loss = 0.0142464
I1006 16:39:37.332741  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0142466 (* 1 = 0.0142466 loss)
I1006 16:39:37.332746  2964 sgd_solver.cpp:105] Iteration 61700, lr = 0.01
I1006 16:39:45.688326  2964 solver.cpp:218] Iteration 61800 (11.9681 iter/s, 8.35556s/100 iters), loss = 0.0211898
I1006 16:39:45.688356  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.02119 (* 1 = 0.02119 loss)
I1006 16:39:45.688362  2964 sgd_solver.cpp:105] Iteration 61800, lr = 0.01
I1006 16:39:54.036855  2964 solver.cpp:218] Iteration 61900 (11.9782 iter/s, 8.34847s/100 iters), loss = 0.046201
I1006 16:39:54.036886  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0462012 (* 1 = 0.0462012 loss)
I1006 16:39:54.036903  2964 sgd_solver.cpp:105] Iteration 61900, lr = 0.01
I1006 16:40:01.979125  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:40:02.313197  2964 solver.cpp:330] Iteration 62000, Testing net (#0)
I1006 16:40:04.235031  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:40:04.315382  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9095
I1006 16:40:04.315418  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.372682 (* 1 = 0.372682 loss)
I1006 16:40:04.398617  2964 solver.cpp:218] Iteration 62000 (9.65092 iter/s, 10.3617s/100 iters), loss = 0.0144164
I1006 16:40:04.398643  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0144166 (* 1 = 0.0144166 loss)
I1006 16:40:04.398649  2964 sgd_solver.cpp:105] Iteration 62000, lr = 0.01
I1006 16:40:12.750278  2964 solver.cpp:218] Iteration 62100 (11.9737 iter/s, 8.35161s/100 iters), loss = 0.00460271
I1006 16:40:12.750309  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00460291 (* 1 = 0.00460291 loss)
I1006 16:40:12.750315  2964 sgd_solver.cpp:105] Iteration 62100, lr = 0.01
I1006 16:40:21.100262  2964 solver.cpp:218] Iteration 62200 (11.9761 iter/s, 8.34993s/100 iters), loss = 0.0125368
I1006 16:40:21.100292  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.012537 (* 1 = 0.012537 loss)
I1006 16:40:21.100298  2964 sgd_solver.cpp:105] Iteration 62200, lr = 0.01
I1006 16:40:29.453250  2964 solver.cpp:218] Iteration 62300 (11.9718 iter/s, 8.35293s/100 iters), loss = 0.00295404
I1006 16:40:29.453280  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00295424 (* 1 = 0.00295424 loss)
I1006 16:40:29.453287  2964 sgd_solver.cpp:105] Iteration 62300, lr = 0.01
I1006 16:40:37.800743  2964 solver.cpp:218] Iteration 62400 (11.9797 iter/s, 8.34744s/100 iters), loss = 0.0157267
I1006 16:40:37.800861  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.015727 (* 1 = 0.015727 loss)
I1006 16:40:37.800868  2964 sgd_solver.cpp:105] Iteration 62400, lr = 0.01
I1006 16:40:45.735126  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:40:46.069116  2964 solver.cpp:330] Iteration 62500, Testing net (#0)
I1006 16:40:47.992266  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:40:48.072801  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.919
I1006 16:40:48.072836  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.325619 (* 1 = 0.325619 loss)
I1006 16:40:48.155952  2964 solver.cpp:218] Iteration 62500 (9.6571 iter/s, 10.3551s/100 iters), loss = 0.00332735
I1006 16:40:48.155982  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00332756 (* 1 = 0.00332756 loss)
I1006 16:40:48.155988  2964 sgd_solver.cpp:105] Iteration 62500, lr = 0.01
I1006 16:40:56.502008  2964 solver.cpp:218] Iteration 62600 (11.9818 iter/s, 8.346s/100 iters), loss = 0.0264605
I1006 16:40:56.502049  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0264608 (* 1 = 0.0264608 loss)
I1006 16:40:56.502055  2964 sgd_solver.cpp:105] Iteration 62600, lr = 0.01
I1006 16:41:04.842826  2964 solver.cpp:218] Iteration 62700 (11.9893 iter/s, 8.34075s/100 iters), loss = 0.0289717
I1006 16:41:04.842856  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0289719 (* 1 = 0.0289719 loss)
I1006 16:41:04.842862  2964 sgd_solver.cpp:105] Iteration 62700, lr = 0.01
I1006 16:41:13.187258  2964 solver.cpp:218] Iteration 62800 (11.9841 iter/s, 8.34437s/100 iters), loss = 0.0131079
I1006 16:41:13.187400  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0131082 (* 1 = 0.0131082 loss)
I1006 16:41:13.187418  2964 sgd_solver.cpp:105] Iteration 62800, lr = 0.01
I1006 16:41:21.532580  2964 solver.cpp:218] Iteration 62900 (11.983 iter/s, 8.34516s/100 iters), loss = 0.00345054
I1006 16:41:21.532627  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00345077 (* 1 = 0.00345077 loss)
I1006 16:41:21.532635  2964 sgd_solver.cpp:105] Iteration 62900, lr = 0.01
I1006 16:41:29.464562  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:41:29.799175  2964 solver.cpp:330] Iteration 63000, Testing net (#0)
I1006 16:41:31.719029  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:41:31.799288  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9172
I1006 16:41:31.799324  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.336254 (* 1 = 0.336254 loss)
I1006 16:41:31.882033  2964 solver.cpp:218] Iteration 63000 (9.66242 iter/s, 10.3494s/100 iters), loss = 0.00252266
I1006 16:41:31.882060  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00252289 (* 1 = 0.00252289 loss)
I1006 16:41:31.882066  2964 sgd_solver.cpp:105] Iteration 63000, lr = 0.01
I1006 16:41:40.227901  2964 solver.cpp:218] Iteration 63100 (11.9821 iter/s, 8.34582s/100 iters), loss = 0.00782747
I1006 16:41:40.227942  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0078277 (* 1 = 0.0078277 loss)
I1006 16:41:40.227948  2964 sgd_solver.cpp:105] Iteration 63100, lr = 0.01
I1006 16:41:48.577162  2964 solver.cpp:218] Iteration 63200 (11.9772 iter/s, 8.34919s/100 iters), loss = 0.00297799
I1006 16:41:48.577306  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00297822 (* 1 = 0.00297822 loss)
I1006 16:41:48.577314  2964 sgd_solver.cpp:105] Iteration 63200, lr = 0.01
I1006 16:41:56.924234  2964 solver.cpp:218] Iteration 63300 (11.9805 iter/s, 8.3469s/100 iters), loss = 0.00446614
I1006 16:41:56.924266  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00446636 (* 1 = 0.00446636 loss)
I1006 16:41:56.924283  2964 sgd_solver.cpp:105] Iteration 63300, lr = 0.01
I1006 16:42:05.268134  2964 solver.cpp:218] Iteration 63400 (11.9849 iter/s, 8.34384s/100 iters), loss = 0.00639169
I1006 16:42:05.268163  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00639192 (* 1 = 0.00639192 loss)
I1006 16:42:05.268169  2964 sgd_solver.cpp:105] Iteration 63400, lr = 0.01
I1006 16:42:13.199709  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:42:13.533478  2964 solver.cpp:330] Iteration 63500, Testing net (#0)
I1006 16:42:15.453721  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:42:15.534219  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9187
I1006 16:42:15.534255  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.328316 (* 1 = 0.328316 loss)
I1006 16:42:15.617442  2964 solver.cpp:218] Iteration 63500 (9.66254 iter/s, 10.3492s/100 iters), loss = 0.00591855
I1006 16:42:15.617470  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00591878 (* 1 = 0.00591878 loss)
I1006 16:42:15.617476  2964 sgd_solver.cpp:105] Iteration 63500, lr = 0.01
I1006 16:42:23.965091  2964 solver.cpp:218] Iteration 63600 (11.9795 iter/s, 8.3476s/100 iters), loss = 0.00248919
I1006 16:42:23.965206  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00248942 (* 1 = 0.00248942 loss)
I1006 16:42:23.965224  2964 sgd_solver.cpp:105] Iteration 63600, lr = 0.01
I1006 16:42:32.311558  2964 solver.cpp:218] Iteration 63700 (11.9813 iter/s, 8.34633s/100 iters), loss = 0.00919009
I1006 16:42:32.311599  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00919032 (* 1 = 0.00919032 loss)
I1006 16:42:32.311606  2964 sgd_solver.cpp:105] Iteration 63700, lr = 0.01
I1006 16:42:40.655254  2964 solver.cpp:218] Iteration 63800 (11.9852 iter/s, 8.34363s/100 iters), loss = 0.00742999
I1006 16:42:40.655294  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00743022 (* 1 = 0.00743022 loss)
I1006 16:42:40.655300  2964 sgd_solver.cpp:105] Iteration 63800, lr = 0.01
I1006 16:42:48.996922  2964 solver.cpp:218] Iteration 63900 (11.9881 iter/s, 8.3416s/100 iters), loss = 0.00560382
I1006 16:42:48.996953  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00560404 (* 1 = 0.00560404 loss)
I1006 16:42:48.996960  2964 sgd_solver.cpp:105] Iteration 63900, lr = 0.01
I1006 16:42:56.928490  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:42:57.262707  2964 solver.cpp:330] Iteration 64000, Testing net (#0)
I1006 16:42:59.185577  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:42:59.266508  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9156
I1006 16:42:59.266543  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.339562 (* 1 = 0.339562 loss)
I1006 16:42:59.349330  2964 solver.cpp:218] Iteration 64000 (9.65965 iter/s, 10.3523s/100 iters), loss = 0.0160986
I1006 16:42:59.349354  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0160988 (* 1 = 0.0160988 loss)
I1006 16:42:59.349360  2964 sgd_solver.cpp:105] Iteration 64000, lr = 0.01
I1006 16:43:07.698628  2964 solver.cpp:218] Iteration 64100 (11.9771 iter/s, 8.34924s/100 iters), loss = 0.00523819
I1006 16:43:07.698659  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00523842 (* 1 = 0.00523842 loss)
I1006 16:43:07.698665  2964 sgd_solver.cpp:105] Iteration 64100, lr = 0.01
I1006 16:43:16.045038  2964 solver.cpp:218] Iteration 64200 (11.9813 iter/s, 8.34635s/100 iters), loss = 0.020843
I1006 16:43:16.045069  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0208432 (* 1 = 0.0208432 loss)
I1006 16:43:16.045091  2964 sgd_solver.cpp:105] Iteration 64200, lr = 0.01
I1006 16:43:24.392037  2964 solver.cpp:218] Iteration 64300 (11.9804 iter/s, 8.34694s/100 iters), loss = 0.00409329
I1006 16:43:24.392078  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00409353 (* 1 = 0.00409353 loss)
I1006 16:43:24.392086  2964 sgd_solver.cpp:105] Iteration 64300, lr = 0.01
I1006 16:43:32.735899  2964 solver.cpp:218] Iteration 64400 (11.985 iter/s, 8.34379s/100 iters), loss = 0.0226586
I1006 16:43:32.736019  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0226588 (* 1 = 0.0226588 loss)
I1006 16:43:32.736027  2964 sgd_solver.cpp:105] Iteration 64400, lr = 0.01
I1006 16:43:40.666247  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:43:40.999614  2964 solver.cpp:330] Iteration 64500, Testing net (#0)
I1006 16:43:42.921612  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:43:43.002167  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9193
I1006 16:43:43.002202  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.334313 (* 1 = 0.334313 loss)
I1006 16:43:43.084805  2964 solver.cpp:218] Iteration 64500 (9.66303 iter/s, 10.3487s/100 iters), loss = 0.00617682
I1006 16:43:43.084827  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00617707 (* 1 = 0.00617707 loss)
I1006 16:43:43.084834  2964 sgd_solver.cpp:105] Iteration 64500, lr = 0.01
I1006 16:43:51.431937  2964 solver.cpp:218] Iteration 64600 (11.9802 iter/s, 8.34708s/100 iters), loss = 0.0616507
I1006 16:43:51.431967  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.061651 (* 1 = 0.061651 loss)
I1006 16:43:51.431973  2964 sgd_solver.cpp:105] Iteration 64600, lr = 0.01
I1006 16:43:59.779675  2964 solver.cpp:218] Iteration 64700 (11.9794 iter/s, 8.34768s/100 iters), loss = 0.00408517
I1006 16:43:59.779705  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00408542 (* 1 = 0.00408542 loss)
I1006 16:43:59.779711  2964 sgd_solver.cpp:105] Iteration 64700, lr = 0.01
I1006 16:44:08.127876  2964 solver.cpp:218] Iteration 64800 (11.9787 iter/s, 8.34815s/100 iters), loss = 0.00413439
I1006 16:44:08.128005  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00413463 (* 1 = 0.00413463 loss)
I1006 16:44:08.128015  2964 sgd_solver.cpp:105] Iteration 64800, lr = 0.01
I1006 16:44:16.474093  2964 solver.cpp:218] Iteration 64900 (11.9817 iter/s, 8.34607s/100 iters), loss = 0.0115004
I1006 16:44:16.474134  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0115007 (* 1 = 0.0115007 loss)
I1006 16:44:16.474140  2964 sgd_solver.cpp:105] Iteration 64900, lr = 0.01
I1006 16:44:24.409234  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:44:24.744137  2964 solver.cpp:330] Iteration 65000, Testing net (#0)
I1006 16:44:26.665515  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:44:26.745960  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9178
I1006 16:44:26.745996  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.324757 (* 1 = 0.324757 loss)
I1006 16:44:26.829222  2964 solver.cpp:218] Iteration 65000 (9.65712 iter/s, 10.3551s/100 iters), loss = 0.0126555
I1006 16:44:26.829247  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0126557 (* 1 = 0.0126557 loss)
I1006 16:44:26.829254  2964 sgd_solver.cpp:105] Iteration 65000, lr = 0.01
I1006 16:44:35.168779  2964 solver.cpp:218] Iteration 65100 (11.9911 iter/s, 8.3395s/100 iters), loss = 0.0183129
I1006 16:44:35.168817  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0183131 (* 1 = 0.0183131 loss)
I1006 16:44:35.168823  2964 sgd_solver.cpp:105] Iteration 65100, lr = 0.01
I1006 16:44:43.518082  2964 solver.cpp:218] Iteration 65200 (11.9771 iter/s, 8.34924s/100 iters), loss = 0.0077217
I1006 16:44:43.518203  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00772196 (* 1 = 0.00772196 loss)
I1006 16:44:43.518220  2964 sgd_solver.cpp:105] Iteration 65200, lr = 0.01
I1006 16:44:51.858654  2964 solver.cpp:218] Iteration 65300 (11.9898 iter/s, 8.34043s/100 iters), loss = 0.00773604
I1006 16:44:51.858685  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0077363 (* 1 = 0.0077363 loss)
I1006 16:44:51.858690  2964 sgd_solver.cpp:105] Iteration 65300, lr = 0.01
I1006 16:45:00.209077  2964 solver.cpp:218] Iteration 65400 (11.9755 iter/s, 8.35036s/100 iters), loss = 0.00737895
I1006 16:45:00.209110  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0073792 (* 1 = 0.0073792 loss)
I1006 16:45:00.209117  2964 sgd_solver.cpp:105] Iteration 65400, lr = 0.01
I1006 16:45:08.147037  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:45:08.481034  2964 solver.cpp:330] Iteration 65500, Testing net (#0)
I1006 16:45:10.402281  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:45:10.482934  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9196
I1006 16:45:10.482975  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.330992 (* 1 = 0.330992 loss)
I1006 16:45:10.565148  2964 solver.cpp:218] Iteration 65500 (9.65623 iter/s, 10.356s/100 iters), loss = 0.00603013
I1006 16:45:10.565176  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00603038 (* 1 = 0.00603038 loss)
I1006 16:45:10.565183  2964 sgd_solver.cpp:105] Iteration 65500, lr = 0.01
I1006 16:45:18.915289  2964 solver.cpp:218] Iteration 65600 (11.9759 iter/s, 8.35009s/100 iters), loss = 0.0293844
I1006 16:45:18.915408  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0293846 (* 1 = 0.0293846 loss)
I1006 16:45:18.915426  2964 sgd_solver.cpp:105] Iteration 65600, lr = 0.01
I1006 16:45:27.265954  2964 solver.cpp:218] Iteration 65700 (11.9753 iter/s, 8.35052s/100 iters), loss = 0.0123703
I1006 16:45:27.265983  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0123706 (* 1 = 0.0123706 loss)
I1006 16:45:27.265990  2964 sgd_solver.cpp:105] Iteration 65700, lr = 0.01
I1006 16:45:35.617195  2964 solver.cpp:218] Iteration 65800 (11.9743 iter/s, 8.35119s/100 iters), loss = 0.0211373
I1006 16:45:35.617236  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0211375 (* 1 = 0.0211375 loss)
I1006 16:45:35.617242  2964 sgd_solver.cpp:105] Iteration 65800, lr = 0.01
I1006 16:45:43.970703  2964 solver.cpp:218] Iteration 65900 (11.9711 iter/s, 8.35344s/100 iters), loss = 0.00785313
I1006 16:45:43.970746  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00785341 (* 1 = 0.00785341 loss)
I1006 16:45:43.970752  2964 sgd_solver.cpp:105] Iteration 65900, lr = 0.01
I1006 16:45:51.904752  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:45:52.239261  2964 solver.cpp:330] Iteration 66000, Testing net (#0)
I1006 16:45:54.162812  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:45:54.243290  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9172
I1006 16:45:54.243327  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.327206 (* 1 = 0.327206 loss)
I1006 16:45:54.326398  2964 solver.cpp:218] Iteration 66000 (9.65659 iter/s, 10.3556s/100 iters), loss = 0.0108185
I1006 16:45:54.326423  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0108188 (* 1 = 0.0108188 loss)
I1006 16:45:54.326431  2964 sgd_solver.cpp:105] Iteration 66000, lr = 0.01
I1006 16:46:02.670997  2964 solver.cpp:218] Iteration 66100 (11.9839 iter/s, 8.34455s/100 iters), loss = 0.00864543
I1006 16:46:02.671034  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00864572 (* 1 = 0.00864572 loss)
I1006 16:46:02.671042  2964 sgd_solver.cpp:105] Iteration 66100, lr = 0.01
I1006 16:46:11.011289  2964 solver.cpp:218] Iteration 66200 (11.9901 iter/s, 8.34023s/100 iters), loss = 0.0101415
I1006 16:46:11.011332  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0101418 (* 1 = 0.0101418 loss)
I1006 16:46:11.011338  2964 sgd_solver.cpp:105] Iteration 66200, lr = 0.01
I1006 16:46:19.356533  2964 solver.cpp:218] Iteration 66300 (11.983 iter/s, 8.34517s/100 iters), loss = 0.0118796
I1006 16:46:19.356562  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0118799 (* 1 = 0.0118799 loss)
I1006 16:46:19.356570  2964 sgd_solver.cpp:105] Iteration 66300, lr = 0.01
I1006 16:46:27.700623  2964 solver.cpp:218] Iteration 66400 (11.9846 iter/s, 8.34403s/100 iters), loss = 0.00713352
I1006 16:46:27.700731  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00713382 (* 1 = 0.00713382 loss)
I1006 16:46:27.700748  2964 sgd_solver.cpp:105] Iteration 66400, lr = 0.01
I1006 16:46:35.636328  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:46:35.970875  2964 solver.cpp:330] Iteration 66500, Testing net (#0)
I1006 16:46:37.891338  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:46:37.971809  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9193
I1006 16:46:37.971844  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.322163 (* 1 = 0.322163 loss)
I1006 16:46:38.056345  2964 solver.cpp:218] Iteration 66500 (9.65663 iter/s, 10.3556s/100 iters), loss = 0.00503197
I1006 16:46:38.056371  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00503227 (* 1 = 0.00503227 loss)
I1006 16:46:38.056378  2964 sgd_solver.cpp:105] Iteration 66500, lr = 0.01
I1006 16:46:46.410027  2964 solver.cpp:218] Iteration 66600 (11.9708 iter/s, 8.35363s/100 iters), loss = 0.04941
I1006 16:46:46.410068  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0494103 (* 1 = 0.0494103 loss)
I1006 16:46:46.410074  2964 sgd_solver.cpp:105] Iteration 66600, lr = 0.01
I1006 16:46:54.782883  2964 solver.cpp:218] Iteration 66700 (11.9435 iter/s, 8.37279s/100 iters), loss = 0.0141881
I1006 16:46:54.782913  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0141884 (* 1 = 0.0141884 loss)
I1006 16:46:54.782920  2964 sgd_solver.cpp:105] Iteration 66700, lr = 0.01
I1006 16:47:03.173298  2964 solver.cpp:218] Iteration 66800 (11.9184 iter/s, 8.39036s/100 iters), loss = 0.00234763
I1006 16:47:03.173446  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00234793 (* 1 = 0.00234793 loss)
I1006 16:47:03.173455  2964 sgd_solver.cpp:105] Iteration 66800, lr = 0.01
I1006 16:47:11.556674  2964 solver.cpp:218] Iteration 66900 (11.9286 iter/s, 8.38321s/100 iters), loss = 0.00411845
I1006 16:47:11.556704  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00411875 (* 1 = 0.00411875 loss)
I1006 16:47:11.556710  2964 sgd_solver.cpp:105] Iteration 66900, lr = 0.01
I1006 16:47:19.523329  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:47:19.862565  2964 solver.cpp:330] Iteration 67000, Testing net (#0)
I1006 16:47:21.814893  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:47:21.895258  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.915
I1006 16:47:21.895303  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.351647 (* 1 = 0.351647 loss)
I1006 16:47:21.978442  2964 solver.cpp:218] Iteration 67000 (9.59536 iter/s, 10.4217s/100 iters), loss = 0.0234354
I1006 16:47:21.978471  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0234357 (* 1 = 0.0234357 loss)
I1006 16:47:21.978478  2964 sgd_solver.cpp:105] Iteration 67000, lr = 0.01
I1006 16:47:30.406358  2964 solver.cpp:218] Iteration 67100 (11.8654 iter/s, 8.42786s/100 iters), loss = 0.0115542
I1006 16:47:30.406388  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0115545 (* 1 = 0.0115545 loss)
I1006 16:47:30.406394  2964 sgd_solver.cpp:105] Iteration 67100, lr = 0.01
I1006 16:47:38.812280  2964 solver.cpp:218] Iteration 67200 (11.8965 iter/s, 8.40587s/100 iters), loss = 0.0131491
I1006 16:47:38.812422  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0131494 (* 1 = 0.0131494 loss)
I1006 16:47:38.812428  2964 sgd_solver.cpp:105] Iteration 67200, lr = 0.01
I1006 16:47:47.207499  2964 solver.cpp:218] Iteration 67300 (11.9118 iter/s, 8.39505s/100 iters), loss = 0.00350139
I1006 16:47:47.207528  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0035017 (* 1 = 0.0035017 loss)
I1006 16:47:47.207535  2964 sgd_solver.cpp:105] Iteration 67300, lr = 0.01
I1006 16:47:55.596863  2964 solver.cpp:218] Iteration 67400 (11.9199 iter/s, 8.38931s/100 iters), loss = 0.013339
I1006 16:47:55.596904  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0133393 (* 1 = 0.0133393 loss)
I1006 16:47:55.596909  2964 sgd_solver.cpp:105] Iteration 67400, lr = 0.01
I1006 16:48:03.523769  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:48:03.856943  2964 solver.cpp:330] Iteration 67500, Testing net (#0)
I1006 16:48:05.776502  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:48:05.855561  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9176
I1006 16:48:05.855595  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.337748 (* 1 = 0.337748 loss)
I1006 16:48:05.937328  2964 solver.cpp:218] Iteration 67500 (9.67081 iter/s, 10.3404s/100 iters), loss = 0.00522539
I1006 16:48:05.937350  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00522568 (* 1 = 0.00522568 loss)
I1006 16:48:05.937356  2964 sgd_solver.cpp:105] Iteration 67500, lr = 0.01
I1006 16:48:14.318641  2964 solver.cpp:218] Iteration 67600 (11.9314 iter/s, 8.38126s/100 iters), loss = 0.0179076
I1006 16:48:14.318787  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0179079 (* 1 = 0.0179079 loss)
I1006 16:48:14.318796  2964 sgd_solver.cpp:105] Iteration 67600, lr = 0.01
I1006 16:48:22.698823  2964 solver.cpp:218] Iteration 67700 (11.9332 iter/s, 8.38001s/100 iters), loss = 0.00375536
I1006 16:48:22.698863  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00375565 (* 1 = 0.00375565 loss)
I1006 16:48:22.698868  2964 sgd_solver.cpp:105] Iteration 67700, lr = 0.01
I1006 16:48:31.086681  2964 solver.cpp:218] Iteration 67800 (11.9221 iter/s, 8.38779s/100 iters), loss = 0.0130877
I1006 16:48:31.086721  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.013088 (* 1 = 0.013088 loss)
I1006 16:48:31.086727  2964 sgd_solver.cpp:105] Iteration 67800, lr = 0.01
I1006 16:48:39.473564  2964 solver.cpp:218] Iteration 67900 (11.9235 iter/s, 8.38682s/100 iters), loss = 0.0125726
I1006 16:48:39.473605  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0125729 (* 1 = 0.0125729 loss)
I1006 16:48:39.473611  2964 sgd_solver.cpp:105] Iteration 67900, lr = 0.01
I1006 16:48:47.414567  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:48:47.749223  2964 solver.cpp:330] Iteration 68000, Testing net (#0)
I1006 16:48:49.675281  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:48:49.755116  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9145
I1006 16:48:49.755151  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.344873 (* 1 = 0.344873 loss)
I1006 16:48:49.837288  2964 solver.cpp:218] Iteration 68000 (9.64911 iter/s, 10.3636s/100 iters), loss = 0.00522685
I1006 16:48:49.837321  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00522716 (* 1 = 0.00522716 loss)
I1006 16:48:49.837339  2964 sgd_solver.cpp:105] Iteration 68000, lr = 0.01
I1006 16:48:58.186242  2964 solver.cpp:218] Iteration 68100 (11.9776 iter/s, 8.34889s/100 iters), loss = 0.00274679
I1006 16:48:58.186282  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00274711 (* 1 = 0.00274711 loss)
I1006 16:48:58.186288  2964 sgd_solver.cpp:105] Iteration 68100, lr = 0.01
I1006 16:49:06.571408  2964 solver.cpp:218] Iteration 68200 (11.9259 iter/s, 8.3851s/100 iters), loss = 0.0248192
I1006 16:49:06.571441  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0248195 (* 1 = 0.0248195 loss)
I1006 16:49:06.571449  2964 sgd_solver.cpp:105] Iteration 68200, lr = 0.01
I1006 16:49:14.956487  2964 solver.cpp:218] Iteration 68300 (11.926 iter/s, 8.38502s/100 iters), loss = 0.0025945
I1006 16:49:14.956521  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00259481 (* 1 = 0.00259481 loss)
I1006 16:49:14.956527  2964 sgd_solver.cpp:105] Iteration 68300, lr = 0.01
I1006 16:49:23.312328  2964 solver.cpp:218] Iteration 68400 (11.9678 iter/s, 8.35578s/100 iters), loss = 0.0053707
I1006 16:49:23.312430  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00537101 (* 1 = 0.00537101 loss)
I1006 16:49:23.312448  2964 sgd_solver.cpp:105] Iteration 68400, lr = 0.01
I1006 16:49:31.256247  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:49:31.588958  2964 solver.cpp:330] Iteration 68500, Testing net (#0)
I1006 16:49:33.513345  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:49:33.592656  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9178
I1006 16:49:33.592691  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.355128 (* 1 = 0.355128 loss)
I1006 16:49:33.674654  2964 solver.cpp:218] Iteration 68500 (9.65047 iter/s, 10.3622s/100 iters), loss = 0.00747826
I1006 16:49:33.674679  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00747856 (* 1 = 0.00747856 loss)
I1006 16:49:33.674685  2964 sgd_solver.cpp:105] Iteration 68500, lr = 0.01
I1006 16:49:42.070683  2964 solver.cpp:218] Iteration 68600 (11.9105 iter/s, 8.39598s/100 iters), loss = 0.00524751
I1006 16:49:42.070724  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00524782 (* 1 = 0.00524782 loss)
I1006 16:49:42.070731  2964 sgd_solver.cpp:105] Iteration 68600, lr = 0.01
I1006 16:49:50.433503  2964 solver.cpp:218] Iteration 68700 (11.9578 iter/s, 8.36275s/100 iters), loss = 0.00430211
I1006 16:49:50.433532  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00430241 (* 1 = 0.00430241 loss)
I1006 16:49:50.433539  2964 sgd_solver.cpp:105] Iteration 68700, lr = 0.01
I1006 16:49:58.791823  2964 solver.cpp:218] Iteration 68800 (11.9642 iter/s, 8.35826s/100 iters), loss = 0.00625977
I1006 16:49:58.791925  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00626007 (* 1 = 0.00626007 loss)
I1006 16:49:58.791942  2964 sgd_solver.cpp:105] Iteration 68800, lr = 0.01
I1006 16:50:07.169729  2964 solver.cpp:218] Iteration 68900 (11.9363 iter/s, 8.37779s/100 iters), loss = 0.0131898
I1006 16:50:07.169759  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0131901 (* 1 = 0.0131901 loss)
I1006 16:50:07.169775  2964 sgd_solver.cpp:105] Iteration 68900, lr = 0.01
I1006 16:50:15.125910  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:50:15.460180  2964 solver.cpp:330] Iteration 69000, Testing net (#0)
I1006 16:50:17.397691  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:50:17.476549  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9155
I1006 16:50:17.476573  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.350802 (* 1 = 0.350802 loss)
I1006 16:50:17.558499  2964 solver.cpp:218] Iteration 69000 (9.62583 iter/s, 10.3887s/100 iters), loss = 0.00399447
I1006 16:50:17.558526  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00399478 (* 1 = 0.00399478 loss)
I1006 16:50:17.558531  2964 sgd_solver.cpp:105] Iteration 69000, lr = 0.01
I1006 16:50:25.923082  2964 solver.cpp:218] Iteration 69100 (11.9552 iter/s, 8.36453s/100 iters), loss = 0.0149968
I1006 16:50:25.923123  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0149971 (* 1 = 0.0149971 loss)
I1006 16:50:25.923130  2964 sgd_solver.cpp:105] Iteration 69100, lr = 0.01
I1006 16:50:34.294853  2964 solver.cpp:218] Iteration 69200 (11.945 iter/s, 8.3717s/100 iters), loss = 0.0101213
I1006 16:50:34.294975  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0101216 (* 1 = 0.0101216 loss)
I1006 16:50:34.294996  2964 sgd_solver.cpp:105] Iteration 69200, lr = 0.01
I1006 16:50:42.664547  2964 solver.cpp:218] Iteration 69300 (11.9481 iter/s, 8.36956s/100 iters), loss = 0.003589
I1006 16:50:42.664577  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00358931 (* 1 = 0.00358931 loss)
I1006 16:50:42.664584  2964 sgd_solver.cpp:105] Iteration 69300, lr = 0.01
I1006 16:50:51.033751  2964 solver.cpp:218] Iteration 69400 (11.9487 iter/s, 8.36914s/100 iters), loss = 0.00656446
I1006 16:50:51.033782  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00656477 (* 1 = 0.00656477 loss)
I1006 16:50:51.033787  2964 sgd_solver.cpp:105] Iteration 69400, lr = 0.01
I1006 16:50:58.992980  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:50:59.326201  2964 solver.cpp:330] Iteration 69500, Testing net (#0)
I1006 16:51:01.247203  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:51:01.326773  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9198
I1006 16:51:01.326807  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.329858 (* 1 = 0.329858 loss)
I1006 16:51:01.408565  2964 solver.cpp:218] Iteration 69500 (9.63878 iter/s, 10.3748s/100 iters), loss = 0.0036099
I1006 16:51:01.408588  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00361021 (* 1 = 0.00361021 loss)
I1006 16:51:01.408594  2964 sgd_solver.cpp:105] Iteration 69500, lr = 0.01
I1006 16:51:09.767673  2964 solver.cpp:218] Iteration 69600 (11.9631 iter/s, 8.35906s/100 iters), loss = 0.0161386
I1006 16:51:09.767779  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0161389 (* 1 = 0.0161389 loss)
I1006 16:51:09.767786  2964 sgd_solver.cpp:105] Iteration 69600, lr = 0.01
I1006 16:51:18.127110  2964 solver.cpp:218] Iteration 69700 (11.9627 iter/s, 8.35931s/100 iters), loss = 0.00297785
I1006 16:51:18.127151  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00297817 (* 1 = 0.00297817 loss)
I1006 16:51:18.127156  2964 sgd_solver.cpp:105] Iteration 69700, lr = 0.01
I1006 16:51:26.504204  2964 solver.cpp:218] Iteration 69800 (11.9374 iter/s, 8.37703s/100 iters), loss = 0.00684544
I1006 16:51:26.504236  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00684576 (* 1 = 0.00684576 loss)
I1006 16:51:26.504245  2964 sgd_solver.cpp:105] Iteration 69800, lr = 0.01
I1006 16:51:34.906872  2964 solver.cpp:218] Iteration 69900 (11.9011 iter/s, 8.4026s/100 iters), loss = 0.0116038
I1006 16:51:34.906913  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0116041 (* 1 = 0.0116041 loss)
I1006 16:51:34.906919  2964 sgd_solver.cpp:105] Iteration 69900, lr = 0.01
I1006 16:51:42.841596  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:51:43.175087  2964 solver.cpp:330] Iteration 70000, Testing net (#0)
I1006 16:51:45.104372  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:51:45.183477  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.915
I1006 16:51:45.183512  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.3543 (* 1 = 0.3543 loss)
I1006 16:51:45.265316  2964 solver.cpp:218] Iteration 70000 (9.65402 iter/s, 10.3584s/100 iters), loss = 0.00276238
I1006 16:51:45.265341  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00276271 (* 1 = 0.00276271 loss)
I1006 16:51:45.265347  2964 sgd_solver.cpp:105] Iteration 70000, lr = 0.01
I1006 16:51:53.710417  2964 solver.cpp:218] Iteration 70100 (11.8413 iter/s, 8.44505s/100 iters), loss = 0.00571304
I1006 16:51:53.710449  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00571336 (* 1 = 0.00571336 loss)
I1006 16:51:53.710458  2964 sgd_solver.cpp:105] Iteration 70100, lr = 0.01
I1006 16:52:02.193603  2964 solver.cpp:218] Iteration 70200 (11.7881 iter/s, 8.48312s/100 iters), loss = 0.00570274
I1006 16:52:02.193635  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00570307 (* 1 = 0.00570307 loss)
I1006 16:52:02.193642  2964 sgd_solver.cpp:105] Iteration 70200, lr = 0.01
I1006 16:52:10.570379  2964 solver.cpp:218] Iteration 70300 (11.9378 iter/s, 8.37672s/100 iters), loss = 0.0139242
I1006 16:52:10.570410  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0139245 (* 1 = 0.0139245 loss)
I1006 16:52:10.570416  2964 sgd_solver.cpp:105] Iteration 70300, lr = 0.01
I1006 16:52:18.945395  2964 solver.cpp:218] Iteration 70400 (11.9404 iter/s, 8.37496s/100 iters), loss = 0.0101856
I1006 16:52:18.945502  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0101859 (* 1 = 0.0101859 loss)
I1006 16:52:18.945519  2964 sgd_solver.cpp:105] Iteration 70400, lr = 0.01
I1006 16:52:26.913838  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:52:27.247673  2964 solver.cpp:330] Iteration 70500, Testing net (#0)
I1006 16:52:29.226846  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:52:29.306005  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9125
I1006 16:52:29.306041  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.371839 (* 1 = 0.371839 loss)
I1006 16:52:29.388133  2964 solver.cpp:218] Iteration 70500 (9.57616 iter/s, 10.4426s/100 iters), loss = 0.00297442
I1006 16:52:29.388157  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00297474 (* 1 = 0.00297474 loss)
I1006 16:52:29.388164  2964 sgd_solver.cpp:105] Iteration 70500, lr = 0.01
I1006 16:52:37.782218  2964 solver.cpp:218] Iteration 70600 (11.9132 iter/s, 8.39403s/100 iters), loss = 0.00199963
I1006 16:52:37.782259  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00199995 (* 1 = 0.00199995 loss)
I1006 16:52:37.782266  2964 sgd_solver.cpp:105] Iteration 70600, lr = 0.01
I1006 16:52:46.233359  2964 solver.cpp:218] Iteration 70700 (11.8328 iter/s, 8.45107s/100 iters), loss = 0.0125257
I1006 16:52:46.233391  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.012526 (* 1 = 0.012526 loss)
I1006 16:52:46.233397  2964 sgd_solver.cpp:105] Iteration 70700, lr = 0.01
I1006 16:52:54.679112  2964 solver.cpp:218] Iteration 70800 (11.8404 iter/s, 8.44569s/100 iters), loss = 0.0129666
I1006 16:52:54.679258  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0129669 (* 1 = 0.0129669 loss)
I1006 16:52:54.679266  2964 sgd_solver.cpp:105] Iteration 70800, lr = 0.01
I1006 16:53:03.061379  2964 solver.cpp:218] Iteration 70900 (11.9302 iter/s, 8.38209s/100 iters), loss = 0.00228496
I1006 16:53:03.061408  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00228527 (* 1 = 0.00228527 loss)
I1006 16:53:03.061414  2964 sgd_solver.cpp:105] Iteration 70900, lr = 0.01
I1006 16:53:11.037299  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:53:11.370381  2964 solver.cpp:330] Iteration 71000, Testing net (#0)
I1006 16:53:13.289563  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:53:13.370018  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9143
I1006 16:53:13.370052  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.358063 (* 1 = 0.358063 loss)
I1006 16:53:13.452886  2964 solver.cpp:218] Iteration 71000 (9.6233 iter/s, 10.3914s/100 iters), loss = 0.0113344
I1006 16:53:13.452911  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0113347 (* 1 = 0.0113347 loss)
I1006 16:53:13.452917  2964 sgd_solver.cpp:105] Iteration 71000, lr = 0.01
I1006 16:53:21.863955  2964 solver.cpp:218] Iteration 71100 (11.8892 iter/s, 8.41102s/100 iters), loss = 0.00490265
I1006 16:53:21.863996  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00490297 (* 1 = 0.00490297 loss)
I1006 16:53:21.864002  2964 sgd_solver.cpp:105] Iteration 71100, lr = 0.01
I1006 16:53:30.302664  2964 solver.cpp:218] Iteration 71200 (11.8503 iter/s, 8.43864s/100 iters), loss = 0.00712278
I1006 16:53:30.302778  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0071231 (* 1 = 0.0071231 loss)
I1006 16:53:30.302786  2964 sgd_solver.cpp:105] Iteration 71200, lr = 0.01
I1006 16:53:38.707111  2964 solver.cpp:218] Iteration 71300 (11.8986 iter/s, 8.40432s/100 iters), loss = 0.0181826
I1006 16:53:38.707142  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0181829 (* 1 = 0.0181829 loss)
I1006 16:53:38.707159  2964 sgd_solver.cpp:105] Iteration 71300, lr = 0.01
I1006 16:53:47.153216  2964 solver.cpp:218] Iteration 71400 (11.8399 iter/s, 8.44605s/100 iters), loss = 0.00975079
I1006 16:53:47.153250  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0097511 (* 1 = 0.0097511 loss)
I1006 16:53:47.153268  2964 sgd_solver.cpp:105] Iteration 71400, lr = 0.01
I1006 16:53:55.180966  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:53:55.515100  2964 solver.cpp:330] Iteration 71500, Testing net (#0)
I1006 16:53:57.462476  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:53:57.541615  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9127
I1006 16:53:57.541651  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.362232 (* 1 = 0.362232 loss)
I1006 16:53:57.623787  2964 solver.cpp:218] Iteration 71500 (9.55064 iter/s, 10.4705s/100 iters), loss = 0.0031222
I1006 16:53:57.623828  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00312251 (* 1 = 0.00312251 loss)
I1006 16:53:57.623836  2964 sgd_solver.cpp:105] Iteration 71500, lr = 0.01
I1006 16:54:06.061733  2964 solver.cpp:218] Iteration 71600 (11.8513 iter/s, 8.43788s/100 iters), loss = 0.00341372
I1006 16:54:06.061872  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00341403 (* 1 = 0.00341403 loss)
I1006 16:54:06.061882  2964 sgd_solver.cpp:105] Iteration 71600, lr = 0.01
I1006 16:54:14.642436  2964 solver.cpp:218] Iteration 71700 (11.6543 iter/s, 8.58051s/100 iters), loss = 0.0068071
I1006 16:54:14.642464  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00680741 (* 1 = 0.00680741 loss)
I1006 16:54:14.642470  2964 sgd_solver.cpp:105] Iteration 71700, lr = 0.01
I1006 16:54:23.081360  2964 solver.cpp:218] Iteration 71800 (11.8499 iter/s, 8.43887s/100 iters), loss = 0.00298674
I1006 16:54:23.081390  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00298704 (* 1 = 0.00298704 loss)
I1006 16:54:23.081398  2964 sgd_solver.cpp:105] Iteration 71800, lr = 0.01
I1006 16:54:31.503506  2964 solver.cpp:218] Iteration 71900 (11.8735 iter/s, 8.42209s/100 iters), loss = 0.000995659
I1006 16:54:31.503549  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000995959 (* 1 = 0.000995959 loss)
I1006 16:54:31.503556  2964 sgd_solver.cpp:105] Iteration 71900, lr = 0.01
I1006 16:54:39.533262  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:54:39.870481  2964 solver.cpp:330] Iteration 72000, Testing net (#0)
I1006 16:54:41.807725  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:54:41.886713  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9163
I1006 16:54:41.886737  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.34654 (* 1 = 0.34654 loss)
I1006 16:54:41.968909  2964 solver.cpp:218] Iteration 72000 (9.55537 iter/s, 10.4653s/100 iters), loss = 0.00567912
I1006 16:54:41.968960  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00567942 (* 1 = 0.00567942 loss)
I1006 16:54:41.968966  2964 sgd_solver.cpp:105] Iteration 72000, lr = 0.01
I1006 16:54:50.411388  2964 solver.cpp:218] Iteration 72100 (11.845 iter/s, 8.4424s/100 iters), loss = 0.0275111
I1006 16:54:50.411435  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0275114 (* 1 = 0.0275114 loss)
I1006 16:54:50.411458  2964 sgd_solver.cpp:105] Iteration 72100, lr = 0.01
I1006 16:54:58.784209  2964 solver.cpp:218] Iteration 72200 (11.9435 iter/s, 8.37275s/100 iters), loss = 0.00444766
I1006 16:54:58.784240  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00444795 (* 1 = 0.00444795 loss)
I1006 16:54:58.784246  2964 sgd_solver.cpp:105] Iteration 72200, lr = 0.01
I1006 16:55:07.234897  2964 solver.cpp:218] Iteration 72300 (11.8335 iter/s, 8.45062s/100 iters), loss = 0.0160953
I1006 16:55:07.234943  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0160956 (* 1 = 0.0160956 loss)
I1006 16:55:07.234961  2964 sgd_solver.cpp:105] Iteration 72300, lr = 0.01
I1006 16:55:15.678207  2964 solver.cpp:218] Iteration 72400 (11.844 iter/s, 8.44312s/100 iters), loss = 0.0189466
I1006 16:55:15.678297  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0189469 (* 1 = 0.0189469 loss)
I1006 16:55:15.678306  2964 sgd_solver.cpp:105] Iteration 72400, lr = 0.01
I1006 16:55:23.663478  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:55:23.998809  2964 solver.cpp:330] Iteration 72500, Testing net (#0)
I1006 16:55:25.919281  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:55:25.998651  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9144
I1006 16:55:25.998684  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.355373 (* 1 = 0.355373 loss)
I1006 16:55:26.080868  2964 solver.cpp:218] Iteration 72500 (9.61304 iter/s, 10.4025s/100 iters), loss = 0.0101279
I1006 16:55:26.080891  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0101282 (* 1 = 0.0101282 loss)
I1006 16:55:26.080899  2964 sgd_solver.cpp:105] Iteration 72500, lr = 0.01
I1006 16:55:34.491080  2964 solver.cpp:218] Iteration 72600 (11.8904 iter/s, 8.41016s/100 iters), loss = 0.00832467
I1006 16:55:34.491109  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00832497 (* 1 = 0.00832497 loss)
I1006 16:55:34.491116  2964 sgd_solver.cpp:105] Iteration 72600, lr = 0.01
I1006 16:55:42.914265  2964 solver.cpp:218] Iteration 72700 (11.8721 iter/s, 8.42313s/100 iters), loss = 0.021258
I1006 16:55:42.914299  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0212584 (* 1 = 0.0212584 loss)
I1006 16:55:42.914305  2964 sgd_solver.cpp:105] Iteration 72700, lr = 0.01
I1006 16:55:51.304301  2964 solver.cpp:218] Iteration 72800 (11.919 iter/s, 8.38998s/100 iters), loss = 0.0039434
I1006 16:55:51.304431  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00394371 (* 1 = 0.00394371 loss)
I1006 16:55:51.304451  2964 sgd_solver.cpp:105] Iteration 72800, lr = 0.01
I1006 16:55:59.690511  2964 solver.cpp:218] Iteration 72900 (11.9245 iter/s, 8.38607s/100 iters), loss = 0.0045767
I1006 16:55:59.690541  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.004577 (* 1 = 0.004577 loss)
I1006 16:55:59.690557  2964 sgd_solver.cpp:105] Iteration 72900, lr = 0.01
I1006 16:56:07.638532  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:56:07.972008  2964 solver.cpp:330] Iteration 73000, Testing net (#0)
I1006 16:56:09.899613  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:56:09.978760  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9102
I1006 16:56:09.978783  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.379627 (* 1 = 0.379627 loss)
I1006 16:56:10.060528  2964 solver.cpp:218] Iteration 73000 (9.64324 iter/s, 10.37s/100 iters), loss = 0.00334422
I1006 16:56:10.060552  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00334453 (* 1 = 0.00334453 loss)
I1006 16:56:10.060559  2964 sgd_solver.cpp:105] Iteration 73000, lr = 0.01
I1006 16:56:18.446540  2964 solver.cpp:218] Iteration 73100 (11.9247 iter/s, 8.38596s/100 iters), loss = 0.00269815
I1006 16:56:18.446570  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00269846 (* 1 = 0.00269846 loss)
I1006 16:56:18.446576  2964 sgd_solver.cpp:105] Iteration 73100, lr = 0.01
I1006 16:56:26.830791  2964 solver.cpp:218] Iteration 73200 (11.9272 iter/s, 8.38419s/100 iters), loss = 0.0181517
I1006 16:56:26.830907  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0181521 (* 1 = 0.0181521 loss)
I1006 16:56:26.830914  2964 sgd_solver.cpp:105] Iteration 73200, lr = 0.01
I1006 16:56:35.198633  2964 solver.cpp:218] Iteration 73300 (11.9507 iter/s, 8.3677s/100 iters), loss = 0.016244
I1006 16:56:35.198664  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0162443 (* 1 = 0.0162443 loss)
I1006 16:56:35.198670  2964 sgd_solver.cpp:105] Iteration 73300, lr = 0.01
I1006 16:56:43.595433  2964 solver.cpp:218] Iteration 73400 (11.9094 iter/s, 8.39674s/100 iters), loss = 0.0103389
I1006 16:56:43.595463  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0103392 (* 1 = 0.0103392 loss)
I1006 16:56:43.595468  2964 sgd_solver.cpp:105] Iteration 73400, lr = 0.01
I1006 16:56:51.608793  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:56:51.943770  2964 solver.cpp:330] Iteration 73500, Testing net (#0)
I1006 16:56:53.897598  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:56:53.979588  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9184
I1006 16:56:53.979614  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.338288 (* 1 = 0.338288 loss)
I1006 16:56:54.064606  2964 solver.cpp:218] Iteration 73500 (9.55191 iter/s, 10.4691s/100 iters), loss = 0.00609486
I1006 16:56:54.064653  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00609519 (* 1 = 0.00609519 loss)
I1006 16:56:54.064661  2964 sgd_solver.cpp:105] Iteration 73500, lr = 0.01
I1006 16:57:02.465137  2964 solver.cpp:218] Iteration 73600 (11.9044 iter/s, 8.40023s/100 iters), loss = 0.0145439
I1006 16:57:02.465283  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0145442 (* 1 = 0.0145442 loss)
I1006 16:57:02.465293  2964 sgd_solver.cpp:105] Iteration 73600, lr = 0.01
I1006 16:57:10.894985  2964 solver.cpp:218] Iteration 73700 (11.8628 iter/s, 8.42968s/100 iters), loss = 0.0133186
I1006 16:57:10.895020  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0133189 (* 1 = 0.0133189 loss)
I1006 16:57:10.895037  2964 sgd_solver.cpp:105] Iteration 73700, lr = 0.01
I1006 16:57:19.322026  2964 solver.cpp:218] Iteration 73800 (11.8666 iter/s, 8.42698s/100 iters), loss = 0.0219516
I1006 16:57:19.322057  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0219519 (* 1 = 0.0219519 loss)
I1006 16:57:19.322064  2964 sgd_solver.cpp:105] Iteration 73800, lr = 0.01
I1006 16:57:27.720113  2964 solver.cpp:218] Iteration 73900 (11.9076 iter/s, 8.39802s/100 iters), loss = 0.00551078
I1006 16:57:27.720147  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00551111 (* 1 = 0.00551111 loss)
I1006 16:57:27.720165  2964 sgd_solver.cpp:105] Iteration 73900, lr = 0.01
I1006 16:57:35.711251  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:57:36.045415  2964 solver.cpp:330] Iteration 74000, Testing net (#0)
I1006 16:57:37.969411  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:57:38.049713  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9098
I1006 16:57:38.049748  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.381556 (* 1 = 0.381556 loss)
I1006 16:57:38.131770  2964 solver.cpp:218] Iteration 74000 (9.60468 iter/s, 10.4116s/100 iters), loss = 0.00401634
I1006 16:57:38.131793  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00401666 (* 1 = 0.00401666 loss)
I1006 16:57:38.131800  2964 sgd_solver.cpp:105] Iteration 74000, lr = 0.01
I1006 16:57:46.604651  2964 solver.cpp:218] Iteration 74100 (11.8025 iter/s, 8.47281s/100 iters), loss = 0.0131116
I1006 16:57:46.604746  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0131119 (* 1 = 0.0131119 loss)
I1006 16:57:46.604773  2964 sgd_solver.cpp:105] Iteration 74100, lr = 0.01
I1006 16:57:55.038221  2964 solver.cpp:218] Iteration 74200 (11.8576 iter/s, 8.43343s/100 iters), loss = 0.054652
I1006 16:57:55.038252  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0546523 (* 1 = 0.0546523 loss)
I1006 16:57:55.038259  2964 sgd_solver.cpp:105] Iteration 74200, lr = 0.01
I1006 16:58:03.456804  2964 solver.cpp:218] Iteration 74300 (11.8786 iter/s, 8.41852s/100 iters), loss = 0.0148341
I1006 16:58:03.456835  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0148344 (* 1 = 0.0148344 loss)
I1006 16:58:03.456841  2964 sgd_solver.cpp:105] Iteration 74300, lr = 0.01
I1006 16:58:11.824136  2964 solver.cpp:218] Iteration 74400 (11.9513 iter/s, 8.36728s/100 iters), loss = 0.0116218
I1006 16:58:11.824275  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0116221 (* 1 = 0.0116221 loss)
I1006 16:58:11.824282  2964 sgd_solver.cpp:105] Iteration 74400, lr = 0.01
I1006 16:58:19.772639  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:58:20.108510  2964 solver.cpp:330] Iteration 74500, Testing net (#0)
I1006 16:58:22.035909  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:58:22.114524  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9143
I1006 16:58:22.114549  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.351405 (* 1 = 0.351405 loss)
I1006 16:58:22.199044  2964 solver.cpp:218] Iteration 74500 (9.63879 iter/s, 10.3747s/100 iters), loss = 0.0077038
I1006 16:58:22.199090  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00770413 (* 1 = 0.00770413 loss)
I1006 16:58:22.199097  2964 sgd_solver.cpp:105] Iteration 74500, lr = 0.01
I1006 16:58:30.570438  2964 solver.cpp:218] Iteration 74600 (11.946 iter/s, 8.37104s/100 iters), loss = 0.0556092
I1006 16:58:30.570469  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0556095 (* 1 = 0.0556095 loss)
I1006 16:58:30.570487  2964 sgd_solver.cpp:105] Iteration 74600, lr = 0.01
I1006 16:58:38.971338  2964 solver.cpp:218] Iteration 74700 (11.9036 iter/s, 8.40084s/100 iters), loss = 0.0158108
I1006 16:58:38.971379  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0158111 (* 1 = 0.0158111 loss)
I1006 16:58:38.971385  2964 sgd_solver.cpp:105] Iteration 74700, lr = 0.01
I1006 16:58:47.399617  2964 solver.cpp:218] Iteration 74800 (11.8649 iter/s, 8.42821s/100 iters), loss = 0.0120015
I1006 16:58:47.399739  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0120019 (* 1 = 0.0120019 loss)
I1006 16:58:47.399749  2964 sgd_solver.cpp:105] Iteration 74800, lr = 0.01
I1006 16:58:55.809063  2964 solver.cpp:218] Iteration 74900 (11.8916 iter/s, 8.4093s/100 iters), loss = 0.0102754
I1006 16:58:55.809094  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0102757 (* 1 = 0.0102757 loss)
I1006 16:58:55.809100  2964 sgd_solver.cpp:105] Iteration 74900, lr = 0.01
I1006 16:59:03.811512  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:59:04.146445  2964 solver.cpp:330] Iteration 75000, Testing net (#0)
I1006 16:59:06.079905  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:59:06.159433  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9138
I1006 16:59:06.159468  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.345551 (* 1 = 0.345551 loss)
I1006 16:59:06.241839  2964 solver.cpp:218] Iteration 75000 (9.58523 iter/s, 10.4327s/100 iters), loss = 0.00321843
I1006 16:59:06.241870  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00321876 (* 1 = 0.00321876 loss)
I1006 16:59:06.241878  2964 sgd_solver.cpp:105] Iteration 75000, lr = 0.01
I1006 16:59:14.674880  2964 solver.cpp:218] Iteration 75100 (11.8582 iter/s, 8.43298s/100 iters), loss = 0.0118951
I1006 16:59:14.674921  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0118955 (* 1 = 0.0118955 loss)
I1006 16:59:14.674928  2964 sgd_solver.cpp:105] Iteration 75100, lr = 0.01
I1006 16:59:23.085680  2964 solver.cpp:218] Iteration 75200 (11.8896 iter/s, 8.41073s/100 iters), loss = 0.0167669
I1006 16:59:23.085798  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0167672 (* 1 = 0.0167672 loss)
I1006 16:59:23.085816  2964 sgd_solver.cpp:105] Iteration 75200, lr = 0.01
I1006 16:59:31.499227  2964 solver.cpp:218] Iteration 75300 (11.8858 iter/s, 8.41341s/100 iters), loss = 0.00215463
I1006 16:59:31.499255  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00215496 (* 1 = 0.00215496 loss)
I1006 16:59:31.499261  2964 sgd_solver.cpp:105] Iteration 75300, lr = 0.01
I1006 16:59:39.919030  2964 solver.cpp:218] Iteration 75400 (11.8768 iter/s, 8.41975s/100 iters), loss = 0.0187563
I1006 16:59:39.919060  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0187566 (* 1 = 0.0187566 loss)
I1006 16:59:39.919066  2964 sgd_solver.cpp:105] Iteration 75400, lr = 0.01
I1006 16:59:47.894609  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:59:48.236235  2964 solver.cpp:330] Iteration 75500, Testing net (#0)
I1006 16:59:50.165309  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 16:59:50.244482  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9104
I1006 16:59:50.244508  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.37327 (* 1 = 0.37327 loss)
I1006 16:59:50.326799  2964 solver.cpp:218] Iteration 75500 (9.60826 iter/s, 10.4077s/100 iters), loss = 0.00483678
I1006 16:59:50.326822  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00483711 (* 1 = 0.00483711 loss)
I1006 16:59:50.326828  2964 sgd_solver.cpp:105] Iteration 75500, lr = 0.01
I1006 16:59:58.734777  2964 solver.cpp:218] Iteration 75600 (11.8935 iter/s, 8.40793s/100 iters), loss = 0.00339598
I1006 16:59:58.734905  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00339631 (* 1 = 0.00339631 loss)
I1006 16:59:58.734923  2964 sgd_solver.cpp:105] Iteration 75600, lr = 0.01
I1006 17:00:07.146001  2964 solver.cpp:218] Iteration 75700 (11.8891 iter/s, 8.41107s/100 iters), loss = 0.00985292
I1006 17:00:07.146033  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00985326 (* 1 = 0.00985326 loss)
I1006 17:00:07.146039  2964 sgd_solver.cpp:105] Iteration 75700, lr = 0.01
I1006 17:00:15.553405  2964 solver.cpp:218] Iteration 75800 (11.8944 iter/s, 8.40734s/100 iters), loss = 0.00446352
I1006 17:00:15.553447  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00446385 (* 1 = 0.00446385 loss)
I1006 17:00:15.553452  2964 sgd_solver.cpp:105] Iteration 75800, lr = 0.01
I1006 17:00:23.918265  2964 solver.cpp:218] Iteration 75900 (11.9549 iter/s, 8.36479s/100 iters), loss = 0.0135826
I1006 17:00:23.918304  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0135829 (* 1 = 0.0135829 loss)
I1006 17:00:23.918310  2964 sgd_solver.cpp:105] Iteration 75900, lr = 0.01
I1006 17:00:31.883558  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:00:32.228427  2964 solver.cpp:330] Iteration 76000, Testing net (#0)
I1006 17:00:34.176123  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:00:34.258950  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9172
I1006 17:00:34.258975  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.341402 (* 1 = 0.341402 loss)
I1006 17:00:34.341122  2964 solver.cpp:218] Iteration 76000 (9.59436 iter/s, 10.4228s/100 iters), loss = 0.000667936
I1006 17:00:34.341147  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00066826 (* 1 = 0.00066826 loss)
I1006 17:00:34.341153  2964 sgd_solver.cpp:105] Iteration 76000, lr = 0.01
I1006 17:00:42.796237  2964 solver.cpp:218] Iteration 76100 (11.8272 iter/s, 8.45506s/100 iters), loss = 0.00625168
I1006 17:00:42.796279  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.006252 (* 1 = 0.006252 loss)
I1006 17:00:42.796286  2964 sgd_solver.cpp:105] Iteration 76100, lr = 0.01
I1006 17:00:51.257251  2964 solver.cpp:218] Iteration 76200 (11.819 iter/s, 8.46094s/100 iters), loss = 0.00620653
I1006 17:00:51.257285  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00620685 (* 1 = 0.00620685 loss)
I1006 17:00:51.257293  2964 sgd_solver.cpp:105] Iteration 76200, lr = 0.01
I1006 17:00:59.725838  2964 solver.cpp:218] Iteration 76300 (11.8084 iter/s, 8.46853s/100 iters), loss = 0.0105625
I1006 17:00:59.725879  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0105628 (* 1 = 0.0105628 loss)
I1006 17:00:59.725885  2964 sgd_solver.cpp:105] Iteration 76300, lr = 0.01
I1006 17:01:08.191242  2964 solver.cpp:218] Iteration 76400 (11.8129 iter/s, 8.46533s/100 iters), loss = 0.00832025
I1006 17:01:08.191362  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00832056 (* 1 = 0.00832056 loss)
I1006 17:01:08.191381  2964 sgd_solver.cpp:105] Iteration 76400, lr = 0.01
I1006 17:01:16.244738  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:01:16.583114  2964 solver.cpp:330] Iteration 76500, Testing net (#0)
I1006 17:01:18.526671  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:01:18.608651  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.911
I1006 17:01:18.608677  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.382683 (* 1 = 0.382683 loss)
I1006 17:01:18.693351  2964 solver.cpp:218] Iteration 76500 (9.52203 iter/s, 10.502s/100 iters), loss = 0.00454946
I1006 17:01:18.693383  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00454977 (* 1 = 0.00454977 loss)
I1006 17:01:18.693390  2964 sgd_solver.cpp:105] Iteration 76500, lr = 0.01
I1006 17:01:27.142248  2964 solver.cpp:218] Iteration 76600 (11.8359 iter/s, 8.44884s/100 iters), loss = 0.0350896
I1006 17:01:27.142279  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0350899 (* 1 = 0.0350899 loss)
I1006 17:01:27.142285  2964 sgd_solver.cpp:105] Iteration 76600, lr = 0.01
I1006 17:01:35.604372  2964 solver.cpp:218] Iteration 76700 (11.8174 iter/s, 8.46206s/100 iters), loss = 0.00701857
I1006 17:01:35.604416  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0070189 (* 1 = 0.0070189 loss)
I1006 17:01:35.604424  2964 sgd_solver.cpp:105] Iteration 76700, lr = 0.01
I1006 17:01:44.037222  2964 solver.cpp:218] Iteration 76800 (11.8585 iter/s, 8.43278s/100 iters), loss = 0.0241584
I1006 17:01:44.037343  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0241587 (* 1 = 0.0241587 loss)
I1006 17:01:44.037362  2964 sgd_solver.cpp:105] Iteration 76800, lr = 0.01
I1006 17:01:52.502404  2964 solver.cpp:218] Iteration 76900 (11.8133 iter/s, 8.465s/100 iters), loss = 0.00914452
I1006 17:01:52.502435  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00914485 (* 1 = 0.00914485 loss)
I1006 17:01:52.502441  2964 sgd_solver.cpp:105] Iteration 76900, lr = 0.01
I1006 17:02:00.574450  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:02:00.912856  2964 solver.cpp:330] Iteration 77000, Testing net (#0)
I1006 17:02:02.852951  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:02:02.932196  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9144
I1006 17:02:02.932219  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.35918 (* 1 = 0.35918 loss)
I1006 17:02:03.014262  2964 solver.cpp:218] Iteration 77000 (9.51312 iter/s, 10.5118s/100 iters), loss = 0.0372892
I1006 17:02:03.014286  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0372896 (* 1 = 0.0372896 loss)
I1006 17:02:03.014292  2964 sgd_solver.cpp:105] Iteration 77000, lr = 0.01
I1006 17:02:11.395963  2964 solver.cpp:218] Iteration 77100 (11.9308 iter/s, 8.38165s/100 iters), loss = 0.00873303
I1006 17:02:11.395994  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00873336 (* 1 = 0.00873336 loss)
I1006 17:02:11.396000  2964 sgd_solver.cpp:105] Iteration 77100, lr = 0.01
I1006 17:02:19.876201  2964 solver.cpp:218] Iteration 77200 (11.7922 iter/s, 8.48018s/100 iters), loss = 0.00318526
I1006 17:02:19.876368  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00318559 (* 1 = 0.00318559 loss)
I1006 17:02:19.876379  2964 sgd_solver.cpp:105] Iteration 77200, lr = 0.01
I1006 17:02:28.375010  2964 solver.cpp:218] Iteration 77300 (11.7666 iter/s, 8.49862s/100 iters), loss = 0.013202
I1006 17:02:28.375041  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0132023 (* 1 = 0.0132023 loss)
I1006 17:02:28.375046  2964 sgd_solver.cpp:105] Iteration 77300, lr = 0.01
I1006 17:02:36.751050  2964 solver.cpp:218] Iteration 77400 (11.9389 iter/s, 8.37598s/100 iters), loss = 0.00736448
I1006 17:02:36.751083  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00736482 (* 1 = 0.00736482 loss)
I1006 17:02:36.751090  2964 sgd_solver.cpp:105] Iteration 77400, lr = 0.01
I1006 17:02:44.808393  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:02:45.142117  2964 solver.cpp:330] Iteration 77500, Testing net (#0)
I1006 17:02:47.080018  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:02:47.164135  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9182
I1006 17:02:47.164162  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.336829 (* 1 = 0.336829 loss)
I1006 17:02:47.247239  2964 solver.cpp:218] Iteration 77500 (9.52733 iter/s, 10.4961s/100 iters), loss = 0.00386324
I1006 17:02:47.247274  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00386358 (* 1 = 0.00386358 loss)
I1006 17:02:47.247282  2964 sgd_solver.cpp:105] Iteration 77500, lr = 0.01
I1006 17:02:55.727843  2964 solver.cpp:218] Iteration 77600 (11.7917 iter/s, 8.48054s/100 iters), loss = 0.00716764
I1006 17:02:55.727931  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00716797 (* 1 = 0.00716797 loss)
I1006 17:02:55.727939  2964 sgd_solver.cpp:105] Iteration 77600, lr = 0.01
I1006 17:03:04.167618  2964 solver.cpp:218] Iteration 77700 (11.8488 iter/s, 8.43967s/100 iters), loss = 0.00386087
I1006 17:03:04.167666  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00386119 (* 1 = 0.00386119 loss)
I1006 17:03:04.167675  2964 sgd_solver.cpp:105] Iteration 77700, lr = 0.01
I1006 17:03:12.585067  2964 solver.cpp:218] Iteration 77800 (11.8802 iter/s, 8.41737s/100 iters), loss = 0.00653401
I1006 17:03:12.585098  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00653434 (* 1 = 0.00653434 loss)
I1006 17:03:12.585108  2964 sgd_solver.cpp:105] Iteration 77800, lr = 0.01
I1006 17:03:21.021870  2964 solver.cpp:218] Iteration 77900 (11.8529 iter/s, 8.43674s/100 iters), loss = 0.00572355
I1006 17:03:21.021903  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00572388 (* 1 = 0.00572388 loss)
I1006 17:03:21.021924  2964 sgd_solver.cpp:105] Iteration 77900, lr = 0.01
I1006 17:03:29.017213  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:03:29.350366  2964 solver.cpp:330] Iteration 78000, Testing net (#0)
I1006 17:03:31.307938  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:03:31.387792  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9119
I1006 17:03:31.387826  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.370136 (* 1 = 0.370136 loss)
I1006 17:03:31.470288  2964 solver.cpp:218] Iteration 78000 (9.57088 iter/s, 10.4484s/100 iters), loss = 0.00376383
I1006 17:03:31.470309  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00376417 (* 1 = 0.00376417 loss)
I1006 17:03:31.470316  2964 sgd_solver.cpp:105] Iteration 78000, lr = 0.01
I1006 17:03:40.005568  2964 solver.cpp:218] Iteration 78100 (11.7162 iter/s, 8.53522s/100 iters), loss = 0.00746822
I1006 17:03:40.005616  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00746856 (* 1 = 0.00746856 loss)
I1006 17:03:40.005625  2964 sgd_solver.cpp:105] Iteration 78100, lr = 0.01
I1006 17:03:48.439160  2964 solver.cpp:218] Iteration 78200 (11.8574 iter/s, 8.43352s/100 iters), loss = 0.0040162
I1006 17:03:48.439193  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00401654 (* 1 = 0.00401654 loss)
I1006 17:03:48.439199  2964 sgd_solver.cpp:105] Iteration 78200, lr = 0.01
I1006 17:03:56.856498  2964 solver.cpp:218] Iteration 78300 (11.8803 iter/s, 8.41727s/100 iters), loss = 0.00561991
I1006 17:03:56.856533  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00562026 (* 1 = 0.00562026 loss)
I1006 17:03:56.856554  2964 sgd_solver.cpp:105] Iteration 78300, lr = 0.01
I1006 17:04:05.241911  2964 solver.cpp:218] Iteration 78400 (11.9256 iter/s, 8.38535s/100 iters), loss = 0.00510698
I1006 17:04:05.242040  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00510733 (* 1 = 0.00510733 loss)
I1006 17:04:05.242060  2964 sgd_solver.cpp:105] Iteration 78400, lr = 0.01
I1006 17:04:13.234851  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:04:13.567589  2964 solver.cpp:330] Iteration 78500, Testing net (#0)
I1006 17:04:15.491456  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:04:15.570611  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9171
I1006 17:04:15.570646  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.338147 (* 1 = 0.338147 loss)
I1006 17:04:15.652489  2964 solver.cpp:218] Iteration 78500 (9.60576 iter/s, 10.4104s/100 iters), loss = 0.00196449
I1006 17:04:15.652523  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00196483 (* 1 = 0.00196483 loss)
I1006 17:04:15.652529  2964 sgd_solver.cpp:105] Iteration 78500, lr = 0.01
I1006 17:04:24.019381  2964 solver.cpp:218] Iteration 78600 (11.952 iter/s, 8.36683s/100 iters), loss = 0.00526686
I1006 17:04:24.019410  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0052672 (* 1 = 0.0052672 loss)
I1006 17:04:24.019417  2964 sgd_solver.cpp:105] Iteration 78600, lr = 0.01
I1006 17:04:32.452126  2964 solver.cpp:218] Iteration 78700 (11.8586 iter/s, 8.43269s/100 iters), loss = 0.0187081
I1006 17:04:32.452155  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0187084 (* 1 = 0.0187084 loss)
I1006 17:04:32.452162  2964 sgd_solver.cpp:105] Iteration 78700, lr = 0.01
I1006 17:04:40.840211  2964 solver.cpp:218] Iteration 78800 (11.9218 iter/s, 8.38803s/100 iters), loss = 0.0126546
I1006 17:04:40.840292  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0126549 (* 1 = 0.0126549 loss)
I1006 17:04:40.840299  2964 sgd_solver.cpp:105] Iteration 78800, lr = 0.01
I1006 17:04:49.270944  2964 solver.cpp:218] Iteration 78900 (11.8615 iter/s, 8.43062s/100 iters), loss = 0.00792796
I1006 17:04:49.270977  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0079283 (* 1 = 0.0079283 loss)
I1006 17:04:49.270983  2964 sgd_solver.cpp:105] Iteration 78900, lr = 0.01
I1006 17:04:57.422935  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:04:57.757859  2964 solver.cpp:330] Iteration 79000, Testing net (#0)
I1006 17:04:59.709326  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:04:59.788511  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9136
I1006 17:04:59.788550  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.349822 (* 1 = 0.349822 loss)
I1006 17:04:59.872658  2964 solver.cpp:218] Iteration 79000 (9.4325 iter/s, 10.6016s/100 iters), loss = 0.00528185
I1006 17:04:59.872704  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0052822 (* 1 = 0.0052822 loss)
I1006 17:04:59.872715  2964 sgd_solver.cpp:105] Iteration 79000, lr = 0.01
I1006 17:05:08.315783  2964 solver.cpp:218] Iteration 79100 (11.8441 iter/s, 8.44306s/100 iters), loss = 0.00821923
I1006 17:05:08.315812  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00821958 (* 1 = 0.00821958 loss)
I1006 17:05:08.315819  2964 sgd_solver.cpp:105] Iteration 79100, lr = 0.01
I1006 17:05:16.766886  2964 solver.cpp:218] Iteration 79200 (11.8329 iter/s, 8.45105s/100 iters), loss = 0.00314891
I1006 17:05:16.767021  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00314925 (* 1 = 0.00314925 loss)
I1006 17:05:16.767035  2964 sgd_solver.cpp:105] Iteration 79200, lr = 0.01
I1006 17:05:25.229655  2964 solver.cpp:218] Iteration 79300 (11.8167 iter/s, 8.46262s/100 iters), loss = 0.00734419
I1006 17:05:25.229687  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00734453 (* 1 = 0.00734453 loss)
I1006 17:05:25.229694  2964 sgd_solver.cpp:105] Iteration 79300, lr = 0.01
I1006 17:05:33.690536  2964 solver.cpp:218] Iteration 79400 (11.8192 iter/s, 8.46082s/100 iters), loss = 0.0287407
I1006 17:05:33.690577  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0287411 (* 1 = 0.0287411 loss)
I1006 17:05:33.690583  2964 sgd_solver.cpp:105] Iteration 79400, lr = 0.01
I1006 17:05:41.708633  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:05:42.041245  2964 solver.cpp:330] Iteration 79500, Testing net (#0)
I1006 17:05:43.989750  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:05:44.069200  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.915
I1006 17:05:44.069224  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.343772 (* 1 = 0.343772 loss)
I1006 17:05:44.151461  2964 solver.cpp:218] Iteration 79500 (9.55945 iter/s, 10.4609s/100 iters), loss = 0.00118204
I1006 17:05:44.151485  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00118238 (* 1 = 0.00118238 loss)
I1006 17:05:44.151492  2964 sgd_solver.cpp:105] Iteration 79500, lr = 0.01
I1006 17:05:52.522800  2964 solver.cpp:218] Iteration 79600 (11.9456 iter/s, 8.37129s/100 iters), loss = 0.00316641
I1006 17:05:52.522915  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00316675 (* 1 = 0.00316675 loss)
I1006 17:05:52.522923  2964 sgd_solver.cpp:105] Iteration 79600, lr = 0.01
I1006 17:06:00.975752  2964 solver.cpp:218] Iteration 79700 (11.8304 iter/s, 8.45281s/100 iters), loss = 0.014796
I1006 17:06:00.975790  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0147964 (* 1 = 0.0147964 loss)
I1006 17:06:00.975797  2964 sgd_solver.cpp:105] Iteration 79700, lr = 0.01
I1006 17:06:09.421717  2964 solver.cpp:218] Iteration 79800 (11.8401 iter/s, 8.4459s/100 iters), loss = 0.00217274
I1006 17:06:09.421756  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00217307 (* 1 = 0.00217307 loss)
I1006 17:06:09.421763  2964 sgd_solver.cpp:105] Iteration 79800, lr = 0.01
I1006 17:06:17.876189  2964 solver.cpp:218] Iteration 79900 (11.8281 iter/s, 8.45441s/100 iters), loss = 0.00211787
I1006 17:06:17.876219  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0021182 (* 1 = 0.0021182 loss)
I1006 17:06:17.876226  2964 sgd_solver.cpp:105] Iteration 79900, lr = 0.01
I1006 17:06:25.916113  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:06:26.252454  2964 solver.cpp:330] Iteration 80000, Testing net (#0)
I1006 17:06:28.200031  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:06:28.281003  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.913
I1006 17:06:28.281028  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.370212 (* 1 = 0.370212 loss)
I1006 17:06:28.363425  2964 solver.cpp:218] Iteration 80000 (9.53546 iter/s, 10.4872s/100 iters), loss = 0.00811643
I1006 17:06:28.363450  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00811677 (* 1 = 0.00811677 loss)
I1006 17:06:28.363456  2964 sgd_solver.cpp:46] MultiStep Status: Iteration 80000, step = 2
I1006 17:06:28.363459  2964 sgd_solver.cpp:105] Iteration 80000, lr = 0.001
I1006 17:06:36.818711  2964 solver.cpp:218] Iteration 80100 (11.827 iter/s, 8.45523s/100 iters), loss = 0.0160572
I1006 17:06:36.818742  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0160575 (* 1 = 0.0160575 loss)
I1006 17:06:36.818747  2964 sgd_solver.cpp:105] Iteration 80100, lr = 0.001
I1006 17:06:45.241467  2964 solver.cpp:218] Iteration 80200 (11.8727 iter/s, 8.4227s/100 iters), loss = 0.00962871
I1006 17:06:45.241508  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00962905 (* 1 = 0.00962905 loss)
I1006 17:06:45.241515  2964 sgd_solver.cpp:105] Iteration 80200, lr = 0.001
I1006 17:06:53.626469  2964 solver.cpp:218] Iteration 80300 (11.9262 iter/s, 8.38493s/100 iters), loss = 0.002298
I1006 17:06:53.626499  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00229835 (* 1 = 0.00229835 loss)
I1006 17:06:53.626515  2964 sgd_solver.cpp:105] Iteration 80300, lr = 0.001
I1006 17:07:01.991039  2964 solver.cpp:218] Iteration 80400 (11.9553 iter/s, 8.36451s/100 iters), loss = 0.00189965
I1006 17:07:01.991144  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00189999 (* 1 = 0.00189999 loss)
I1006 17:07:01.991161  2964 sgd_solver.cpp:105] Iteration 80400, lr = 0.001
I1006 17:07:09.933681  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:07:10.267549  2964 solver.cpp:330] Iteration 80500, Testing net (#0)
I1006 17:07:12.189456  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:07:12.270256  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9178
I1006 17:07:12.270289  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.328572 (* 1 = 0.328572 loss)
I1006 17:07:12.354069  2964 solver.cpp:218] Iteration 80500 (9.64981 iter/s, 10.3629s/100 iters), loss = 0.000890661
I1006 17:07:12.354095  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000890999 (* 1 = 0.000890999 loss)
I1006 17:07:12.354102  2964 sgd_solver.cpp:105] Iteration 80500, lr = 0.001
I1006 17:07:20.711520  2964 solver.cpp:218] Iteration 80600 (11.9654 iter/s, 8.3574s/100 iters), loss = 0.00708519
I1006 17:07:20.711560  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00708553 (* 1 = 0.00708553 loss)
I1006 17:07:20.711565  2964 sgd_solver.cpp:105] Iteration 80600, lr = 0.001
I1006 17:07:29.067113  2964 solver.cpp:218] Iteration 80700 (11.9681 iter/s, 8.35553s/100 iters), loss = 0.00306671
I1006 17:07:29.067143  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00306706 (* 1 = 0.00306706 loss)
I1006 17:07:29.067149  2964 sgd_solver.cpp:105] Iteration 80700, lr = 0.001
I1006 17:07:37.538616  2964 solver.cpp:218] Iteration 80800 (11.8044 iter/s, 8.47144s/100 iters), loss = 0.0113762
I1006 17:07:37.538718  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0113765 (* 1 = 0.0113765 loss)
I1006 17:07:37.538735  2964 sgd_solver.cpp:105] Iteration 80800, lr = 0.001
I1006 17:07:45.924911  2964 solver.cpp:218] Iteration 80900 (11.9244 iter/s, 8.38616s/100 iters), loss = 0.00318991
I1006 17:07:45.924949  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00319025 (* 1 = 0.00319025 loss)
I1006 17:07:45.924957  2964 sgd_solver.cpp:105] Iteration 80900, lr = 0.001
I1006 17:07:53.861022  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:07:54.195580  2964 solver.cpp:330] Iteration 81000, Testing net (#0)
I1006 17:07:56.116911  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:07:56.197227  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9208
I1006 17:07:56.197263  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.318831 (* 1 = 0.318831 loss)
I1006 17:07:56.280190  2964 solver.cpp:218] Iteration 81000 (9.65697 iter/s, 10.3552s/100 iters), loss = 0.00393281
I1006 17:07:56.280215  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00393316 (* 1 = 0.00393316 loss)
I1006 17:07:56.280221  2964 sgd_solver.cpp:105] Iteration 81000, lr = 0.001
I1006 17:08:04.630106  2964 solver.cpp:218] Iteration 81100 (11.9762 iter/s, 8.34986s/100 iters), loss = 0.0068508
I1006 17:08:04.630146  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00685115 (* 1 = 0.00685115 loss)
I1006 17:08:04.630151  2964 sgd_solver.cpp:105] Iteration 81100, lr = 0.001
I1006 17:08:13.013581  2964 solver.cpp:218] Iteration 81200 (11.9283 iter/s, 8.38341s/100 iters), loss = 0.00177939
I1006 17:08:13.013720  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00177974 (* 1 = 0.00177974 loss)
I1006 17:08:13.013742  2964 sgd_solver.cpp:105] Iteration 81200, lr = 0.001
I1006 17:08:21.443435  2964 solver.cpp:218] Iteration 81300 (11.8628 iter/s, 8.4297s/100 iters), loss = 0.00114561
I1006 17:08:21.443467  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00114595 (* 1 = 0.00114595 loss)
I1006 17:08:21.443473  2964 sgd_solver.cpp:105] Iteration 81300, lr = 0.001
I1006 17:08:29.969219  2964 solver.cpp:218] Iteration 81400 (11.7292 iter/s, 8.52572s/100 iters), loss = 0.0289863
I1006 17:08:29.969254  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0289867 (* 1 = 0.0289867 loss)
I1006 17:08:29.969261  2964 sgd_solver.cpp:105] Iteration 81400, lr = 0.001
I1006 17:08:37.909703  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:08:38.243968  2964 solver.cpp:330] Iteration 81500, Testing net (#0)
I1006 17:08:40.173238  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:08:40.253844  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9205
I1006 17:08:40.253880  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.314779 (* 1 = 0.314779 loss)
I1006 17:08:40.336680  2964 solver.cpp:218] Iteration 81500 (9.64562 iter/s, 10.3674s/100 iters), loss = 0.000947935
I1006 17:08:40.336709  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000948278 (* 1 = 0.000948278 loss)
I1006 17:08:40.336716  2964 sgd_solver.cpp:105] Iteration 81500, lr = 0.001
I1006 17:08:48.802840  2964 solver.cpp:218] Iteration 81600 (11.8118 iter/s, 8.4661s/100 iters), loss = 0.00758101
I1006 17:08:48.802979  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00758135 (* 1 = 0.00758135 loss)
I1006 17:08:48.802987  2964 sgd_solver.cpp:105] Iteration 81600, lr = 0.001
I1006 17:08:57.200348  2964 solver.cpp:218] Iteration 81700 (11.9085 iter/s, 8.39734s/100 iters), loss = 0.00183283
I1006 17:08:57.200392  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00183317 (* 1 = 0.00183317 loss)
I1006 17:08:57.200408  2964 sgd_solver.cpp:105] Iteration 81700, lr = 0.001
I1006 17:09:05.678761  2964 solver.cpp:218] Iteration 81800 (11.7948 iter/s, 8.47834s/100 iters), loss = 0.00719292
I1006 17:09:05.678794  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00719327 (* 1 = 0.00719327 loss)
I1006 17:09:05.678813  2964 sgd_solver.cpp:105] Iteration 81800, lr = 0.001
I1006 17:09:14.085438  2964 solver.cpp:218] Iteration 81900 (11.8954 iter/s, 8.40662s/100 iters), loss = 0.00362099
I1006 17:09:14.085474  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00362134 (* 1 = 0.00362134 loss)
I1006 17:09:14.085482  2964 sgd_solver.cpp:105] Iteration 81900, lr = 0.001
I1006 17:09:22.089660  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:09:22.423593  2964 solver.cpp:330] Iteration 82000, Testing net (#0)
I1006 17:09:24.358446  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:09:24.440971  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9206
I1006 17:09:24.441001  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.313219 (* 1 = 0.313219 loss)
I1006 17:09:24.526499  2964 solver.cpp:218] Iteration 82000 (9.57763 iter/s, 10.441s/100 iters), loss = 0.00549035
I1006 17:09:24.526533  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0054907 (* 1 = 0.0054907 loss)
I1006 17:09:24.526543  2964 sgd_solver.cpp:105] Iteration 82000, lr = 0.001
I1006 17:09:32.887095  2964 solver.cpp:218] Iteration 82100 (11.961 iter/s, 8.36053s/100 iters), loss = 0.00829431
I1006 17:09:32.887132  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00829466 (* 1 = 0.00829466 loss)
I1006 17:09:32.887142  2964 sgd_solver.cpp:105] Iteration 82100, lr = 0.001
I1006 17:09:41.294306  2964 solver.cpp:218] Iteration 82200 (11.8946 iter/s, 8.40715s/100 iters), loss = 0.00315584
I1006 17:09:41.294342  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00315618 (* 1 = 0.00315618 loss)
I1006 17:09:41.294351  2964 sgd_solver.cpp:105] Iteration 82200, lr = 0.001
I1006 17:09:49.666216  2964 solver.cpp:218] Iteration 82300 (11.9448 iter/s, 8.37185s/100 iters), loss = 0.00422219
I1006 17:09:49.666250  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00422253 (* 1 = 0.00422253 loss)
I1006 17:09:49.666268  2964 sgd_solver.cpp:105] Iteration 82300, lr = 0.001
I1006 17:09:58.079921  2964 solver.cpp:218] Iteration 82400 (11.8855 iter/s, 8.41365s/100 iters), loss = 0.00550406
I1006 17:09:58.080101  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0055044 (* 1 = 0.0055044 loss)
I1006 17:09:58.080114  2964 sgd_solver.cpp:105] Iteration 82400, lr = 0.001
I1006 17:10:06.068665  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:10:06.411244  2964 solver.cpp:330] Iteration 82500, Testing net (#0)
I1006 17:10:08.361407  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:10:08.445945  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9216
I1006 17:10:08.445973  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.312272 (* 1 = 0.312272 loss)
I1006 17:10:08.531730  2964 solver.cpp:218] Iteration 82500 (9.5679 iter/s, 10.4516s/100 iters), loss = 0.0013417
I1006 17:10:08.531769  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00134204 (* 1 = 0.00134204 loss)
I1006 17:10:08.531780  2964 sgd_solver.cpp:105] Iteration 82500, lr = 0.001
I1006 17:10:17.008105  2964 solver.cpp:218] Iteration 82600 (11.7976 iter/s, 8.47627s/100 iters), loss = 0.00908196
I1006 17:10:17.008147  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00908229 (* 1 = 0.00908229 loss)
I1006 17:10:17.008154  2964 sgd_solver.cpp:105] Iteration 82600, lr = 0.001
I1006 17:10:25.454154  2964 solver.cpp:218] Iteration 82700 (11.84 iter/s, 8.44598s/100 iters), loss = 0.00347551
I1006 17:10:25.454185  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00347584 (* 1 = 0.00347584 loss)
I1006 17:10:25.454191  2964 sgd_solver.cpp:105] Iteration 82700, lr = 0.001
I1006 17:10:33.889248  2964 solver.cpp:218] Iteration 82800 (11.8553 iter/s, 8.43503s/100 iters), loss = 0.0058521
I1006 17:10:33.889387  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00585243 (* 1 = 0.00585243 loss)
I1006 17:10:33.889395  2964 sgd_solver.cpp:105] Iteration 82800, lr = 0.001
I1006 17:10:42.330440  2964 solver.cpp:218] Iteration 82900 (11.8469 iter/s, 8.44103s/100 iters), loss = 0.00280431
I1006 17:10:42.330476  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00280465 (* 1 = 0.00280465 loss)
I1006 17:10:42.330482  2964 sgd_solver.cpp:105] Iteration 82900, lr = 0.001
I1006 17:10:50.378609  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:10:50.715761  2964 solver.cpp:330] Iteration 83000, Testing net (#0)
I1006 17:10:52.656661  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:10:52.737157  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9222
I1006 17:10:52.737181  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.313273 (* 1 = 0.313273 loss)
I1006 17:10:52.820458  2964 solver.cpp:218] Iteration 83000 (9.53293 iter/s, 10.49s/100 iters), loss = 0.00237729
I1006 17:10:52.820487  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00237763 (* 1 = 0.00237763 loss)
I1006 17:10:52.820494  2964 sgd_solver.cpp:105] Iteration 83000, lr = 0.001
I1006 17:11:01.292033  2964 solver.cpp:218] Iteration 83100 (11.8043 iter/s, 8.47151s/100 iters), loss = 0.00294864
I1006 17:11:01.292065  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00294898 (* 1 = 0.00294898 loss)
I1006 17:11:01.292071  2964 sgd_solver.cpp:105] Iteration 83100, lr = 0.001
I1006 17:11:09.754676  2964 solver.cpp:218] Iteration 83200 (11.8167 iter/s, 8.46258s/100 iters), loss = 0.00769598
I1006 17:11:09.754796  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00769632 (* 1 = 0.00769632 loss)
I1006 17:11:09.754815  2964 sgd_solver.cpp:105] Iteration 83200, lr = 0.001
I1006 17:11:18.213899  2964 solver.cpp:218] Iteration 83300 (11.8216 iter/s, 8.45908s/100 iters), loss = 0.0134743
I1006 17:11:18.213932  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0134747 (* 1 = 0.0134747 loss)
I1006 17:11:18.213940  2964 sgd_solver.cpp:105] Iteration 83300, lr = 0.001
I1006 17:11:26.684500  2964 solver.cpp:218] Iteration 83400 (11.8056 iter/s, 8.47054s/100 iters), loss = 0.00113386
I1006 17:11:26.684530  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0011342 (* 1 = 0.0011342 loss)
I1006 17:11:26.684537  2964 sgd_solver.cpp:105] Iteration 83400, lr = 0.001
I1006 17:11:34.660086  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:11:34.993772  2964 solver.cpp:330] Iteration 83500, Testing net (#0)
I1006 17:11:36.926287  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:11:37.006345  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.922
I1006 17:11:37.006381  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.313797 (* 1 = 0.313797 loss)
I1006 17:11:37.088563  2964 solver.cpp:218] Iteration 83500 (9.61168 iter/s, 10.404s/100 iters), loss = 0.00114594
I1006 17:11:37.088598  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00114628 (* 1 = 0.00114628 loss)
I1006 17:11:37.088604  2964 sgd_solver.cpp:105] Iteration 83500, lr = 0.001
I1006 17:11:45.471191  2964 solver.cpp:218] Iteration 83600 (11.9295 iter/s, 8.38256s/100 iters), loss = 0.0105833
I1006 17:11:45.471264  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0105837 (* 1 = 0.0105837 loss)
I1006 17:11:45.471271  2964 sgd_solver.cpp:105] Iteration 83600, lr = 0.001
I1006 17:11:53.816910  2964 solver.cpp:218] Iteration 83700 (11.9823 iter/s, 8.34562s/100 iters), loss = 0.0026879
I1006 17:11:53.816939  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00268824 (* 1 = 0.00268824 loss)
I1006 17:11:53.816956  2964 sgd_solver.cpp:105] Iteration 83700, lr = 0.001
I1006 17:12:02.171398  2964 solver.cpp:218] Iteration 83800 (11.9697 iter/s, 8.35443s/100 iters), loss = 0.00169328
I1006 17:12:02.171429  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00169363 (* 1 = 0.00169363 loss)
I1006 17:12:02.171445  2964 sgd_solver.cpp:105] Iteration 83800, lr = 0.001
I1006 17:12:10.516019  2964 solver.cpp:218] Iteration 83900 (11.9839 iter/s, 8.34456s/100 iters), loss = 0.00244291
I1006 17:12:10.516049  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00244326 (* 1 = 0.00244326 loss)
I1006 17:12:10.516065  2964 sgd_solver.cpp:105] Iteration 83900, lr = 0.001
I1006 17:12:18.457859  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:12:18.791849  2964 solver.cpp:330] Iteration 84000, Testing net (#0)
I1006 17:12:20.715711  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:12:20.796280  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9222
I1006 17:12:20.796314  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.313461 (* 1 = 0.313461 loss)
I1006 17:12:20.879391  2964 solver.cpp:218] Iteration 84000 (9.64943 iter/s, 10.3633s/100 iters), loss = 0.00649068
I1006 17:12:20.879416  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00649102 (* 1 = 0.00649102 loss)
I1006 17:12:20.879423  2964 sgd_solver.cpp:105] Iteration 84000, lr = 0.001
I1006 17:12:29.230656  2964 solver.cpp:218] Iteration 84100 (11.9743 iter/s, 8.35121s/100 iters), loss = 0.00170331
I1006 17:12:29.230697  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00170365 (* 1 = 0.00170365 loss)
I1006 17:12:29.230703  2964 sgd_solver.cpp:105] Iteration 84100, lr = 0.001
I1006 17:12:37.586570  2964 solver.cpp:218] Iteration 84200 (11.9677 iter/s, 8.35585s/100 iters), loss = 0.00657121
I1006 17:12:37.586611  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00657156 (* 1 = 0.00657156 loss)
I1006 17:12:37.586618  2964 sgd_solver.cpp:105] Iteration 84200, lr = 0.001
I1006 17:12:45.946527  2964 solver.cpp:218] Iteration 84300 (11.9619 iter/s, 8.35989s/100 iters), loss = 0.0044868
I1006 17:12:45.946569  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00448714 (* 1 = 0.00448714 loss)
I1006 17:12:45.946576  2964 sgd_solver.cpp:105] Iteration 84300, lr = 0.001
I1006 17:12:54.300107  2964 solver.cpp:218] Iteration 84400 (11.971 iter/s, 8.35351s/100 iters), loss = 0.00243017
I1006 17:12:54.300226  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00243051 (* 1 = 0.00243051 loss)
I1006 17:12:54.300233  2964 sgd_solver.cpp:105] Iteration 84400, lr = 0.001
I1006 17:13:02.250929  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:13:02.584746  2964 solver.cpp:330] Iteration 84500, Testing net (#0)
I1006 17:13:04.507503  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:13:04.587817  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9221
I1006 17:13:04.587853  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.314179 (* 1 = 0.314179 loss)
I1006 17:13:04.671380  2964 solver.cpp:218] Iteration 84500 (9.64216 iter/s, 10.3711s/100 iters), loss = 0.00462895
I1006 17:13:04.671406  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0046293 (* 1 = 0.0046293 loss)
I1006 17:13:04.671413  2964 sgd_solver.cpp:105] Iteration 84500, lr = 0.001
I1006 17:13:13.027395  2964 solver.cpp:218] Iteration 84600 (11.9675 iter/s, 8.35596s/100 iters), loss = 0.00458882
I1006 17:13:13.027436  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00458917 (* 1 = 0.00458917 loss)
I1006 17:13:13.027441  2964 sgd_solver.cpp:105] Iteration 84600, lr = 0.001
I1006 17:13:21.376104  2964 solver.cpp:218] Iteration 84700 (11.978 iter/s, 8.34864s/100 iters), loss = 0.019848
I1006 17:13:21.376145  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0198483 (* 1 = 0.0198483 loss)
I1006 17:13:21.376152  2964 sgd_solver.cpp:105] Iteration 84700, lr = 0.001
I1006 17:13:29.732064  2964 solver.cpp:218] Iteration 84800 (11.9676 iter/s, 8.35589s/100 iters), loss = 0.00149541
I1006 17:13:29.732182  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00149576 (* 1 = 0.00149576 loss)
I1006 17:13:29.732199  2964 sgd_solver.cpp:105] Iteration 84800, lr = 0.001
I1006 17:13:38.082330  2964 solver.cpp:218] Iteration 84900 (11.9759 iter/s, 8.35013s/100 iters), loss = 0.00396226
I1006 17:13:38.082372  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00396261 (* 1 = 0.00396261 loss)
I1006 17:13:38.082378  2964 sgd_solver.cpp:105] Iteration 84900, lr = 0.001
I1006 17:13:46.026396  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:13:46.361008  2964 solver.cpp:330] Iteration 85000, Testing net (#0)
I1006 17:13:48.283118  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:13:48.363961  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9224
I1006 17:13:48.363996  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.314214 (* 1 = 0.314214 loss)
I1006 17:13:48.447015  2964 solver.cpp:218] Iteration 85000 (9.64821 iter/s, 10.3646s/100 iters), loss = 0.0130771
I1006 17:13:48.447038  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0130774 (* 1 = 0.0130774 loss)
I1006 17:13:48.447046  2964 sgd_solver.cpp:105] Iteration 85000, lr = 0.001
I1006 17:13:56.800343  2964 solver.cpp:218] Iteration 85100 (11.9713 iter/s, 8.35328s/100 iters), loss = 0.00486209
I1006 17:13:56.800382  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00486244 (* 1 = 0.00486244 loss)
I1006 17:13:56.800388  2964 sgd_solver.cpp:105] Iteration 85100, lr = 0.001
I1006 17:14:05.159090  2964 solver.cpp:218] Iteration 85200 (11.9636 iter/s, 8.35868s/100 iters), loss = 0.00376473
I1006 17:14:05.159248  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00376508 (* 1 = 0.00376508 loss)
I1006 17:14:05.159270  2964 sgd_solver.cpp:105] Iteration 85200, lr = 0.001
I1006 17:14:13.510970  2964 solver.cpp:218] Iteration 85300 (11.9736 iter/s, 8.35171s/100 iters), loss = 0.00273386
I1006 17:14:13.511011  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00273421 (* 1 = 0.00273421 loss)
I1006 17:14:13.511018  2964 sgd_solver.cpp:105] Iteration 85300, lr = 0.001
I1006 17:14:21.873116  2964 solver.cpp:218] Iteration 85400 (11.9587 iter/s, 8.36208s/100 iters), loss = 0.0079024
I1006 17:14:21.873157  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00790275 (* 1 = 0.00790275 loss)
I1006 17:14:21.873162  2964 sgd_solver.cpp:105] Iteration 85400, lr = 0.001
I1006 17:14:29.811970  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:14:30.146963  2964 solver.cpp:330] Iteration 85500, Testing net (#0)
I1006 17:14:32.070755  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:14:32.151057  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9227
I1006 17:14:32.151082  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.314852 (* 1 = 0.314852 loss)
I1006 17:14:32.234153  2964 solver.cpp:218] Iteration 85500 (9.65161 iter/s, 10.361s/100 iters), loss = 0.00825904
I1006 17:14:32.234180  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00825939 (* 1 = 0.00825939 loss)
I1006 17:14:32.234186  2964 sgd_solver.cpp:105] Iteration 85500, lr = 0.001
I1006 17:14:40.588235  2964 solver.cpp:218] Iteration 85600 (11.9703 iter/s, 8.35403s/100 iters), loss = 0.00117311
I1006 17:14:40.588351  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00117346 (* 1 = 0.00117346 loss)
I1006 17:14:40.588358  2964 sgd_solver.cpp:105] Iteration 85600, lr = 0.001
I1006 17:14:48.937242  2964 solver.cpp:218] Iteration 85700 (11.9777 iter/s, 8.34887s/100 iters), loss = 0.000741278
I1006 17:14:48.937281  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000741622 (* 1 = 0.000741622 loss)
I1006 17:14:48.937288  2964 sgd_solver.cpp:105] Iteration 85700, lr = 0.001
I1006 17:14:57.295454  2964 solver.cpp:218] Iteration 85800 (11.9644 iter/s, 8.35815s/100 iters), loss = 0.00418586
I1006 17:14:57.295493  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0041862 (* 1 = 0.0041862 loss)
I1006 17:14:57.295500  2964 sgd_solver.cpp:105] Iteration 85800, lr = 0.001
I1006 17:15:05.652087  2964 solver.cpp:218] Iteration 85900 (11.9666 iter/s, 8.35657s/100 iters), loss = 0.00411362
I1006 17:15:05.652127  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00411397 (* 1 = 0.00411397 loss)
I1006 17:15:05.652133  2964 sgd_solver.cpp:105] Iteration 85900, lr = 0.001
I1006 17:15:13.587658  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:15:13.922118  2964 solver.cpp:330] Iteration 86000, Testing net (#0)
I1006 17:15:15.845691  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:15:15.926879  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9229
I1006 17:15:15.926914  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.31466 (* 1 = 0.31466 loss)
I1006 17:15:16.009778  2964 solver.cpp:218] Iteration 86000 (9.65473 iter/s, 10.3576s/100 iters), loss = 0.00343516
I1006 17:15:16.009801  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0034355 (* 1 = 0.0034355 loss)
I1006 17:15:16.009809  2964 sgd_solver.cpp:105] Iteration 86000, lr = 0.001
I1006 17:15:24.355929  2964 solver.cpp:218] Iteration 86100 (11.9816 iter/s, 8.3461s/100 iters), loss = 0.00103415
I1006 17:15:24.355968  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00103449 (* 1 = 0.00103449 loss)
I1006 17:15:24.355974  2964 sgd_solver.cpp:105] Iteration 86100, lr = 0.001
I1006 17:15:32.707080  2964 solver.cpp:218] Iteration 86200 (11.9745 iter/s, 8.35109s/100 iters), loss = 0.0073807
I1006 17:15:32.707120  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00738104 (* 1 = 0.00738104 loss)
I1006 17:15:32.707126  2964 sgd_solver.cpp:105] Iteration 86200, lr = 0.001
I1006 17:15:41.058388  2964 solver.cpp:218] Iteration 86300 (11.9743 iter/s, 8.35124s/100 iters), loss = 0.000630063
I1006 17:15:41.058418  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000630394 (* 1 = 0.000630394 loss)
I1006 17:15:41.058424  2964 sgd_solver.cpp:105] Iteration 86300, lr = 0.001
I1006 17:15:49.412029  2964 solver.cpp:218] Iteration 86400 (11.9709 iter/s, 8.35359s/100 iters), loss = 0.00285707
I1006 17:15:49.412173  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0028574 (* 1 = 0.0028574 loss)
I1006 17:15:49.412181  2964 sgd_solver.cpp:105] Iteration 86400, lr = 0.001
I1006 17:15:57.350433  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:15:57.684512  2964 solver.cpp:330] Iteration 86500, Testing net (#0)
I1006 17:15:59.607025  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:15:59.687618  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9239
I1006 17:15:59.687654  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.312318 (* 1 = 0.312318 loss)
I1006 17:15:59.771426  2964 solver.cpp:218] Iteration 86500 (9.65322 iter/s, 10.3592s/100 iters), loss = 0.00558248
I1006 17:15:59.771453  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00558281 (* 1 = 0.00558281 loss)
I1006 17:15:59.771461  2964 sgd_solver.cpp:105] Iteration 86500, lr = 0.001
I1006 17:16:08.128083  2964 solver.cpp:218] Iteration 86600 (11.9666 iter/s, 8.3566s/100 iters), loss = 0.00161557
I1006 17:16:08.128123  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0016159 (* 1 = 0.0016159 loss)
I1006 17:16:08.128129  2964 sgd_solver.cpp:105] Iteration 86600, lr = 0.001
I1006 17:16:16.478379  2964 solver.cpp:218] Iteration 86700 (11.9757 iter/s, 8.35023s/100 iters), loss = 0.00160504
I1006 17:16:16.478420  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00160538 (* 1 = 0.00160538 loss)
I1006 17:16:16.478425  2964 sgd_solver.cpp:105] Iteration 86700, lr = 0.001
I1006 17:16:24.836102  2964 solver.cpp:218] Iteration 86800 (11.9651 iter/s, 8.35766s/100 iters), loss = 0.00291088
I1006 17:16:24.836220  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00291122 (* 1 = 0.00291122 loss)
I1006 17:16:24.836236  2964 sgd_solver.cpp:105] Iteration 86800, lr = 0.001
I1006 17:16:33.189306  2964 solver.cpp:218] Iteration 86900 (11.9717 iter/s, 8.35306s/100 iters), loss = 0.0059433
I1006 17:16:33.189344  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00594364 (* 1 = 0.00594364 loss)
I1006 17:16:33.189350  2964 sgd_solver.cpp:105] Iteration 86900, lr = 0.001
I1006 17:16:41.127118  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:16:41.461968  2964 solver.cpp:330] Iteration 87000, Testing net (#0)
I1006 17:16:43.385704  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:16:43.466373  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9237
I1006 17:16:43.466398  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.312757 (* 1 = 0.312757 loss)
I1006 17:16:43.549049  2964 solver.cpp:218] Iteration 87000 (9.65281 iter/s, 10.3597s/100 iters), loss = 0.00147651
I1006 17:16:43.549074  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00147685 (* 1 = 0.00147685 loss)
I1006 17:16:43.549082  2964 sgd_solver.cpp:105] Iteration 87000, lr = 0.001
I1006 17:16:51.902030  2964 solver.cpp:218] Iteration 87100 (11.9718 iter/s, 8.35293s/100 iters), loss = 0.00172231
I1006 17:16:51.902072  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00172264 (* 1 = 0.00172264 loss)
I1006 17:16:51.902078  2964 sgd_solver.cpp:105] Iteration 87100, lr = 0.001
I1006 17:17:00.260926  2964 solver.cpp:218] Iteration 87200 (11.9634 iter/s, 8.35883s/100 iters), loss = 0.00838498
I1006 17:17:00.261068  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00838532 (* 1 = 0.00838532 loss)
I1006 17:17:00.261088  2964 sgd_solver.cpp:105] Iteration 87200, lr = 0.001
I1006 17:17:08.611752  2964 solver.cpp:218] Iteration 87300 (11.9751 iter/s, 8.35066s/100 iters), loss = 0.00192022
I1006 17:17:08.611793  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00192056 (* 1 = 0.00192056 loss)
I1006 17:17:08.611799  2964 sgd_solver.cpp:105] Iteration 87300, lr = 0.001
I1006 17:17:16.966822  2964 solver.cpp:218] Iteration 87400 (11.9689 iter/s, 8.35501s/100 iters), loss = 0.00496241
I1006 17:17:16.966861  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00496275 (* 1 = 0.00496275 loss)
I1006 17:17:16.966868  2964 sgd_solver.cpp:105] Iteration 87400, lr = 0.001
I1006 17:17:24.901401  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:17:25.236199  2964 solver.cpp:330] Iteration 87500, Testing net (#0)
I1006 17:17:27.161360  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:17:27.241713  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9238
I1006 17:17:27.241749  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.31198 (* 1 = 0.31198 loss)
I1006 17:17:27.324550  2964 solver.cpp:218] Iteration 87500 (9.65469 iter/s, 10.3577s/100 iters), loss = 0.000654011
I1006 17:17:27.324581  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000654353 (* 1 = 0.000654353 loss)
I1006 17:17:27.324587  2964 sgd_solver.cpp:105] Iteration 87500, lr = 0.001
I1006 17:17:35.681798  2964 solver.cpp:218] Iteration 87600 (11.9657 iter/s, 8.35719s/100 iters), loss = 0.00347169
I1006 17:17:35.681915  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00347203 (* 1 = 0.00347203 loss)
I1006 17:17:35.681921  2964 sgd_solver.cpp:105] Iteration 87600, lr = 0.001
I1006 17:17:44.024286  2964 solver.cpp:218] Iteration 87700 (11.987 iter/s, 8.34235s/100 iters), loss = 0.00272303
I1006 17:17:44.024314  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00272337 (* 1 = 0.00272337 loss)
I1006 17:17:44.024320  2964 sgd_solver.cpp:105] Iteration 87700, lr = 0.001
I1006 17:17:52.383361  2964 solver.cpp:218] Iteration 87800 (11.9631 iter/s, 8.35902s/100 iters), loss = 0.00568007
I1006 17:17:52.383391  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00568042 (* 1 = 0.00568042 loss)
I1006 17:17:52.383397  2964 sgd_solver.cpp:105] Iteration 87800, lr = 0.001
I1006 17:18:00.737664  2964 solver.cpp:218] Iteration 87900 (11.97 iter/s, 8.35425s/100 iters), loss = 0.00366495
I1006 17:18:00.737694  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00366528 (* 1 = 0.00366528 loss)
I1006 17:18:00.737700  2964 sgd_solver.cpp:105] Iteration 87900, lr = 0.001
I1006 17:18:08.681546  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:18:09.015789  2964 solver.cpp:330] Iteration 88000, Testing net (#0)
I1006 17:18:10.940495  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:18:11.021461  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9241
I1006 17:18:11.021486  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.312911 (* 1 = 0.312911 loss)
I1006 17:18:11.104401  2964 solver.cpp:218] Iteration 88000 (9.64629 iter/s, 10.3667s/100 iters), loss = 0.00279995
I1006 17:18:11.104426  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0028003 (* 1 = 0.0028003 loss)
I1006 17:18:11.104434  2964 sgd_solver.cpp:105] Iteration 88000, lr = 0.001
I1006 17:18:19.458354  2964 solver.cpp:218] Iteration 88100 (11.9705 iter/s, 8.3539s/100 iters), loss = 0.00170834
I1006 17:18:19.458384  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00170868 (* 1 = 0.00170868 loss)
I1006 17:18:19.458390  2964 sgd_solver.cpp:105] Iteration 88100, lr = 0.001
I1006 17:18:27.815747  2964 solver.cpp:218] Iteration 88200 (11.9655 iter/s, 8.35734s/100 iters), loss = 0.00174739
I1006 17:18:27.815788  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00174773 (* 1 = 0.00174773 loss)
I1006 17:18:27.815794  2964 sgd_solver.cpp:105] Iteration 88200, lr = 0.001
I1006 17:18:36.169909  2964 solver.cpp:218] Iteration 88300 (11.9702 iter/s, 8.35409s/100 iters), loss = 0.00359529
I1006 17:18:36.169950  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00359563 (* 1 = 0.00359563 loss)
I1006 17:18:36.169955  2964 sgd_solver.cpp:105] Iteration 88300, lr = 0.001
I1006 17:18:44.524233  2964 solver.cpp:218] Iteration 88400 (11.9699 iter/s, 8.35426s/100 iters), loss = 0.00262112
I1006 17:18:44.524363  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00262145 (* 1 = 0.00262145 loss)
I1006 17:18:44.524369  2964 sgd_solver.cpp:105] Iteration 88400, lr = 0.001
I1006 17:18:52.467550  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:18:52.801143  2964 solver.cpp:330] Iteration 88500, Testing net (#0)
I1006 17:18:54.724661  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:18:54.805320  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9241
I1006 17:18:54.805353  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.312839 (* 1 = 0.312839 loss)
I1006 17:18:54.888723  2964 solver.cpp:218] Iteration 88500 (9.64848 iter/s, 10.3643s/100 iters), loss = 0.000608924
I1006 17:18:54.888749  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000609265 (* 1 = 0.000609265 loss)
I1006 17:18:54.888756  2964 sgd_solver.cpp:105] Iteration 88500, lr = 0.001
I1006 17:19:03.244501  2964 solver.cpp:218] Iteration 88600 (11.9678 iter/s, 8.35573s/100 iters), loss = 0.00184844
I1006 17:19:03.244532  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00184879 (* 1 = 0.00184879 loss)
I1006 17:19:03.244539  2964 sgd_solver.cpp:105] Iteration 88600, lr = 0.001
I1006 17:19:11.594260  2964 solver.cpp:218] Iteration 88700 (11.9765 iter/s, 8.3497s/100 iters), loss = 0.00226008
I1006 17:19:11.594290  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00226043 (* 1 = 0.00226043 loss)
I1006 17:19:11.594296  2964 sgd_solver.cpp:105] Iteration 88700, lr = 0.001
I1006 17:19:19.945543  2964 solver.cpp:218] Iteration 88800 (11.9743 iter/s, 8.35123s/100 iters), loss = 0.00596066
I1006 17:19:19.945662  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.005961 (* 1 = 0.005961 loss)
I1006 17:19:19.945670  2964 sgd_solver.cpp:105] Iteration 88800, lr = 0.001
I1006 17:19:28.294337  2964 solver.cpp:218] Iteration 88900 (11.978 iter/s, 8.34865s/100 iters), loss = 0.000940239
I1006 17:19:28.294366  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000940587 (* 1 = 0.000940587 loss)
I1006 17:19:28.294373  2964 sgd_solver.cpp:105] Iteration 88900, lr = 0.001
I1006 17:19:36.235452  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:19:36.569885  2964 solver.cpp:330] Iteration 89000, Testing net (#0)
I1006 17:19:38.491552  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:19:38.572525  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9239
I1006 17:19:38.572561  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.312252 (* 1 = 0.312252 loss)
I1006 17:19:38.654974  2964 solver.cpp:218] Iteration 89000 (9.65197 iter/s, 10.3606s/100 iters), loss = 0.00186714
I1006 17:19:38.654999  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00186749 (* 1 = 0.00186749 loss)
I1006 17:19:38.655005  2964 sgd_solver.cpp:105] Iteration 89000, lr = 0.001
I1006 17:19:47.001129  2964 solver.cpp:218] Iteration 89100 (11.9816 iter/s, 8.3461s/100 iters), loss = 0.00390971
I1006 17:19:47.001171  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00391005 (* 1 = 0.00391005 loss)
I1006 17:19:47.001178  2964 sgd_solver.cpp:105] Iteration 89100, lr = 0.001
I1006 17:19:55.353338  2964 solver.cpp:218] Iteration 89200 (11.973 iter/s, 8.35214s/100 iters), loss = 0.0108484
I1006 17:19:55.353487  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0108488 (* 1 = 0.0108488 loss)
I1006 17:19:55.353494  2964 sgd_solver.cpp:105] Iteration 89200, lr = 0.001
I1006 17:20:03.705137  2964 solver.cpp:218] Iteration 89300 (11.9737 iter/s, 8.35164s/100 iters), loss = 0.00218425
I1006 17:20:03.705178  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0021846 (* 1 = 0.0021846 loss)
I1006 17:20:03.705183  2964 sgd_solver.cpp:105] Iteration 89300, lr = 0.001
I1006 17:20:12.089027  2964 solver.cpp:218] Iteration 89400 (11.9277 iter/s, 8.38382s/100 iters), loss = 0.00353073
I1006 17:20:12.089057  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00353108 (* 1 = 0.00353108 loss)
I1006 17:20:12.089063  2964 sgd_solver.cpp:105] Iteration 89400, lr = 0.001
I1006 17:20:20.089784  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:20:20.424293  2964 solver.cpp:330] Iteration 89500, Testing net (#0)
I1006 17:20:22.348675  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:20:22.429039  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9235
I1006 17:20:22.429074  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.313244 (* 1 = 0.313244 loss)
I1006 17:20:22.512423  2964 solver.cpp:218] Iteration 89500 (9.59386 iter/s, 10.4233s/100 iters), loss = 0.00143924
I1006 17:20:22.512447  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00143959 (* 1 = 0.00143959 loss)
I1006 17:20:22.512454  2964 sgd_solver.cpp:105] Iteration 89500, lr = 0.001
I1006 17:20:30.863073  2964 solver.cpp:218] Iteration 89600 (11.9752 iter/s, 8.3506s/100 iters), loss = 0.00208033
I1006 17:20:30.863194  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00208068 (* 1 = 0.00208068 loss)
I1006 17:20:30.863214  2964 sgd_solver.cpp:105] Iteration 89600, lr = 0.001
I1006 17:20:39.209028  2964 solver.cpp:218] Iteration 89700 (11.9821 iter/s, 8.34581s/100 iters), loss = 0.0022541
I1006 17:20:39.209069  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00225445 (* 1 = 0.00225445 loss)
I1006 17:20:39.209075  2964 sgd_solver.cpp:105] Iteration 89700, lr = 0.001
I1006 17:20:47.566094  2964 solver.cpp:218] Iteration 89800 (11.966 iter/s, 8.357s/100 iters), loss = 0.00316582
I1006 17:20:47.566124  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00316616 (* 1 = 0.00316616 loss)
I1006 17:20:47.566131  2964 sgd_solver.cpp:105] Iteration 89800, lr = 0.001
I1006 17:20:55.921859  2964 solver.cpp:218] Iteration 89900 (11.9679 iter/s, 8.35571s/100 iters), loss = 0.00635843
I1006 17:20:55.921900  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00635877 (* 1 = 0.00635877 loss)
I1006 17:20:55.921906  2964 sgd_solver.cpp:105] Iteration 89900, lr = 0.001
I1006 17:21:03.870633  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:21:04.206401  2964 solver.cpp:330] Iteration 90000, Testing net (#0)
I1006 17:21:06.130486  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:21:06.210912  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9237
I1006 17:21:06.210947  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.31312 (* 1 = 0.31312 loss)
I1006 17:21:06.293793  2964 solver.cpp:218] Iteration 90000 (9.64147 iter/s, 10.3719s/100 iters), loss = 0.000917996
I1006 17:21:06.293824  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000918341 (* 1 = 0.000918341 loss)
I1006 17:21:06.293831  2964 sgd_solver.cpp:105] Iteration 90000, lr = 0.001
I1006 17:21:14.641605  2964 solver.cpp:218] Iteration 90100 (11.9793 iter/s, 8.34775s/100 iters), loss = 0.00181183
I1006 17:21:14.641646  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00181217 (* 1 = 0.00181217 loss)
I1006 17:21:14.641652  2964 sgd_solver.cpp:105] Iteration 90100, lr = 0.001
I1006 17:21:22.995072  2964 solver.cpp:218] Iteration 90200 (11.9712 iter/s, 8.3534s/100 iters), loss = 0.00337093
I1006 17:21:22.995105  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00337128 (* 1 = 0.00337128 loss)
I1006 17:21:22.995121  2964 sgd_solver.cpp:105] Iteration 90200, lr = 0.001
I1006 17:21:31.344652  2964 solver.cpp:218] Iteration 90300 (11.9767 iter/s, 8.34952s/100 iters), loss = 0.0039033
I1006 17:21:31.344683  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00390365 (* 1 = 0.00390365 loss)
I1006 17:21:31.344689  2964 sgd_solver.cpp:105] Iteration 90300, lr = 0.001
I1006 17:21:39.696117  2964 solver.cpp:218] Iteration 90400 (11.974 iter/s, 8.35141s/100 iters), loss = 0.00439934
I1006 17:21:39.696238  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00439968 (* 1 = 0.00439968 loss)
I1006 17:21:39.696256  2964 sgd_solver.cpp:105] Iteration 90400, lr = 0.001
I1006 17:21:47.630512  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:21:47.964928  2964 solver.cpp:330] Iteration 90500, Testing net (#0)
I1006 17:21:49.887624  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:21:49.968068  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9238
I1006 17:21:49.968102  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.313233 (* 1 = 0.313233 loss)
I1006 17:21:50.051749  2964 solver.cpp:218] Iteration 90500 (9.65672 iter/s, 10.3555s/100 iters), loss = 0.00310262
I1006 17:21:50.051779  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00310297 (* 1 = 0.00310297 loss)
I1006 17:21:50.051786  2964 sgd_solver.cpp:105] Iteration 90500, lr = 0.001
I1006 17:21:58.409471  2964 solver.cpp:218] Iteration 90600 (11.9651 iter/s, 8.35767s/100 iters), loss = 0.00567138
I1006 17:21:58.409502  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00567173 (* 1 = 0.00567173 loss)
I1006 17:21:58.409507  2964 sgd_solver.cpp:105] Iteration 90600, lr = 0.001
I1006 17:22:06.763738  2964 solver.cpp:218] Iteration 90700 (11.97 iter/s, 8.35421s/100 iters), loss = 0.00815961
I1006 17:22:06.763780  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00815995 (* 1 = 0.00815995 loss)
I1006 17:22:06.763787  2964 sgd_solver.cpp:105] Iteration 90700, lr = 0.001
I1006 17:22:15.119412  2964 solver.cpp:218] Iteration 90800 (11.968 iter/s, 8.3556s/100 iters), loss = 0.00852679
I1006 17:22:15.119549  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00852714 (* 1 = 0.00852714 loss)
I1006 17:22:15.119557  2964 sgd_solver.cpp:105] Iteration 90800, lr = 0.001
I1006 17:22:23.472460  2964 solver.cpp:218] Iteration 90900 (11.9719 iter/s, 8.35288s/100 iters), loss = 0.00322502
I1006 17:22:23.472501  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00322536 (* 1 = 0.00322536 loss)
I1006 17:22:23.472506  2964 sgd_solver.cpp:105] Iteration 90900, lr = 0.001
I1006 17:22:31.417971  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:22:31.753401  2964 solver.cpp:330] Iteration 91000, Testing net (#0)
I1006 17:22:33.675549  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:22:33.755971  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9238
I1006 17:22:33.756006  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.310827 (* 1 = 0.310827 loss)
I1006 17:22:33.838901  2964 solver.cpp:218] Iteration 91000 (9.64658 iter/s, 10.3664s/100 iters), loss = 0.00203456
I1006 17:22:33.838927  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0020349 (* 1 = 0.0020349 loss)
I1006 17:22:33.838932  2964 sgd_solver.cpp:105] Iteration 91000, lr = 0.001
I1006 17:22:42.194355  2964 solver.cpp:218] Iteration 91100 (11.9683 iter/s, 8.3554s/100 iters), loss = 0.00120313
I1006 17:22:42.194396  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00120347 (* 1 = 0.00120347 loss)
I1006 17:22:42.194401  2964 sgd_solver.cpp:105] Iteration 91100, lr = 0.001
I1006 17:22:50.550290  2964 solver.cpp:218] Iteration 91200 (11.9676 iter/s, 8.35587s/100 iters), loss = 0.00182167
I1006 17:22:50.550395  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00182202 (* 1 = 0.00182202 loss)
I1006 17:22:50.550402  2964 sgd_solver.cpp:105] Iteration 91200, lr = 0.001
I1006 17:22:58.906646  2964 solver.cpp:218] Iteration 91300 (11.9671 iter/s, 8.35623s/100 iters), loss = 0.00309309
I1006 17:22:58.906687  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00309343 (* 1 = 0.00309343 loss)
I1006 17:22:58.906692  2964 sgd_solver.cpp:105] Iteration 91300, lr = 0.001
I1006 17:23:07.266366  2964 solver.cpp:218] Iteration 91400 (11.9622 iter/s, 8.35965s/100 iters), loss = 0.0012848
I1006 17:23:07.266397  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00128515 (* 1 = 0.00128515 loss)
I1006 17:23:07.266404  2964 sgd_solver.cpp:105] Iteration 91400, lr = 0.001
I1006 17:23:15.209203  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:23:15.544266  2964 solver.cpp:330] Iteration 91500, Testing net (#0)
I1006 17:23:17.468364  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:23:17.548779  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.924
I1006 17:23:17.548812  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.312501 (* 1 = 0.312501 loss)
I1006 17:23:17.632814  2964 solver.cpp:218] Iteration 91500 (9.64656 iter/s, 10.3664s/100 iters), loss = 0.0022804
I1006 17:23:17.632839  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00228074 (* 1 = 0.00228074 loss)
I1006 17:23:17.632845  2964 sgd_solver.cpp:105] Iteration 91500, lr = 0.001
I1006 17:23:25.988521  2964 solver.cpp:218] Iteration 91600 (11.9679 iter/s, 8.35565s/100 iters), loss = 0.00228893
I1006 17:23:25.988618  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00228928 (* 1 = 0.00228928 loss)
I1006 17:23:25.988634  2964 sgd_solver.cpp:105] Iteration 91600, lr = 0.001
I1006 17:23:34.340953  2964 solver.cpp:218] Iteration 91700 (11.9727 iter/s, 8.35231s/100 iters), loss = 0.0017528
I1006 17:23:34.340994  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00175315 (* 1 = 0.00175315 loss)
I1006 17:23:34.341001  2964 sgd_solver.cpp:105] Iteration 91700, lr = 0.001
I1006 17:23:42.698431  2964 solver.cpp:218] Iteration 91800 (11.9654 iter/s, 8.35741s/100 iters), loss = 0.0021435
I1006 17:23:42.698463  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00214384 (* 1 = 0.00214384 loss)
I1006 17:23:42.698470  2964 sgd_solver.cpp:105] Iteration 91800, lr = 0.001
I1006 17:23:51.046763  2964 solver.cpp:218] Iteration 91900 (11.9785 iter/s, 8.34827s/100 iters), loss = 0.00271081
I1006 17:23:51.046804  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00271116 (* 1 = 0.00271116 loss)
I1006 17:23:51.046810  2964 sgd_solver.cpp:105] Iteration 91900, lr = 0.001
I1006 17:23:58.989847  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:23:59.324342  2964 solver.cpp:330] Iteration 92000, Testing net (#0)
I1006 17:24:01.249131  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:24:01.329576  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9241
I1006 17:24:01.329610  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.311656 (* 1 = 0.311656 loss)
I1006 17:24:01.412914  2964 solver.cpp:218] Iteration 92000 (9.64685 iter/s, 10.3661s/100 iters), loss = 0.00150608
I1006 17:24:01.412940  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00150642 (* 1 = 0.00150642 loss)
I1006 17:24:01.412947  2964 sgd_solver.cpp:105] Iteration 92000, lr = 0.001
I1006 17:24:09.761651  2964 solver.cpp:218] Iteration 92100 (11.9779 iter/s, 8.34868s/100 iters), loss = 0.00207168
I1006 17:24:09.761693  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00207202 (* 1 = 0.00207202 loss)
I1006 17:24:09.761698  2964 sgd_solver.cpp:105] Iteration 92100, lr = 0.001
I1006 17:24:18.116535  2964 solver.cpp:218] Iteration 92200 (11.9692 iter/s, 8.35481s/100 iters), loss = 0.0040597
I1006 17:24:18.116575  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00406005 (* 1 = 0.00406005 loss)
I1006 17:24:18.116582  2964 sgd_solver.cpp:105] Iteration 92200, lr = 0.001
I1006 17:24:26.467314  2964 solver.cpp:218] Iteration 92300 (11.975 iter/s, 8.35071s/100 iters), loss = 0.00530894
I1006 17:24:26.467355  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00530929 (* 1 = 0.00530929 loss)
I1006 17:24:26.467362  2964 sgd_solver.cpp:105] Iteration 92300, lr = 0.001
I1006 17:24:34.825101  2964 solver.cpp:218] Iteration 92400 (11.965 iter/s, 8.35772s/100 iters), loss = 0.00308309
I1006 17:24:34.825230  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00308344 (* 1 = 0.00308344 loss)
I1006 17:24:34.825237  2964 sgd_solver.cpp:105] Iteration 92400, lr = 0.001
I1006 17:24:42.762008  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:24:43.095427  2964 solver.cpp:330] Iteration 92500, Testing net (#0)
I1006 17:24:45.019517  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:24:45.099779  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9246
I1006 17:24:45.099804  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.312998 (* 1 = 0.312998 loss)
I1006 17:24:45.182857  2964 solver.cpp:218] Iteration 92500 (9.65475 iter/s, 10.3576s/100 iters), loss = 0.00384215
I1006 17:24:45.182886  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0038425 (* 1 = 0.0038425 loss)
I1006 17:24:45.182893  2964 sgd_solver.cpp:105] Iteration 92500, lr = 0.001
I1006 17:24:53.535627  2964 solver.cpp:218] Iteration 92600 (11.9722 iter/s, 8.35271s/100 iters), loss = 0.00122921
I1006 17:24:53.535656  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00122956 (* 1 = 0.00122956 loss)
I1006 17:24:53.535662  2964 sgd_solver.cpp:105] Iteration 92600, lr = 0.001
I1006 17:25:01.881696  2964 solver.cpp:218] Iteration 92700 (11.9818 iter/s, 8.34601s/100 iters), loss = 0.00324104
I1006 17:25:01.881726  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0032414 (* 1 = 0.0032414 loss)
I1006 17:25:01.881742  2964 sgd_solver.cpp:105] Iteration 92700, lr = 0.001
I1006 17:25:10.239644  2964 solver.cpp:218] Iteration 92800 (11.9647 iter/s, 8.35789s/100 iters), loss = 0.00331122
I1006 17:25:10.239766  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00331157 (* 1 = 0.00331157 loss)
I1006 17:25:10.239773  2964 sgd_solver.cpp:105] Iteration 92800, lr = 0.001
I1006 17:25:18.592387  2964 solver.cpp:218] Iteration 92900 (11.9723 iter/s, 8.3526s/100 iters), loss = 0.00188403
I1006 17:25:18.592434  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00188439 (* 1 = 0.00188439 loss)
I1006 17:25:18.592442  2964 sgd_solver.cpp:105] Iteration 92900, lr = 0.001
I1006 17:25:26.536062  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:25:26.869048  2964 solver.cpp:330] Iteration 93000, Testing net (#0)
I1006 17:25:28.791136  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:25:28.871687  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9247
I1006 17:25:28.871722  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.312034 (* 1 = 0.312034 loss)
I1006 17:25:28.955103  2964 solver.cpp:218] Iteration 93000 (9.65005 iter/s, 10.3626s/100 iters), loss = 0.00278442
I1006 17:25:28.955129  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00278477 (* 1 = 0.00278477 loss)
I1006 17:25:28.955135  2964 sgd_solver.cpp:105] Iteration 93000, lr = 0.001
I1006 17:25:37.309641  2964 solver.cpp:218] Iteration 93100 (11.9696 iter/s, 8.35449s/100 iters), loss = 0.00183345
I1006 17:25:37.309670  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00183381 (* 1 = 0.00183381 loss)
I1006 17:25:37.309676  2964 sgd_solver.cpp:105] Iteration 93100, lr = 0.001
I1006 17:25:45.666937  2964 solver.cpp:218] Iteration 93200 (11.9657 iter/s, 8.35724s/100 iters), loss = 0.00262192
I1006 17:25:45.667083  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00262228 (* 1 = 0.00262228 loss)
I1006 17:25:45.667091  2964 sgd_solver.cpp:105] Iteration 93200, lr = 0.001
I1006 17:25:54.027503  2964 solver.cpp:218] Iteration 93300 (11.9611 iter/s, 8.3604s/100 iters), loss = 0.00114525
I1006 17:25:54.027534  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00114561 (* 1 = 0.00114561 loss)
I1006 17:25:54.027550  2964 sgd_solver.cpp:105] Iteration 93300, lr = 0.001
I1006 17:26:02.393349  2964 solver.cpp:218] Iteration 93400 (11.9534 iter/s, 8.36579s/100 iters), loss = 0.000964083
I1006 17:26:02.393379  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00096444 (* 1 = 0.00096444 loss)
I1006 17:26:02.393386  2964 sgd_solver.cpp:105] Iteration 93400, lr = 0.001
I1006 17:26:10.329583  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:26:10.664258  2964 solver.cpp:330] Iteration 93500, Testing net (#0)
I1006 17:26:12.588690  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:26:12.668925  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9248
I1006 17:26:12.668961  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.31216 (* 1 = 0.31216 loss)
I1006 17:26:12.752629  2964 solver.cpp:218] Iteration 93500 (9.65324 iter/s, 10.3592s/100 iters), loss = 0.000827766
I1006 17:26:12.752660  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000828125 (* 1 = 0.000828125 loss)
I1006 17:26:12.752666  2964 sgd_solver.cpp:105] Iteration 93500, lr = 0.001
I1006 17:26:21.111371  2964 solver.cpp:218] Iteration 93600 (11.9636 iter/s, 8.35868s/100 iters), loss = 0.00131748
I1006 17:26:21.111485  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00131783 (* 1 = 0.00131783 loss)
I1006 17:26:21.111491  2964 sgd_solver.cpp:105] Iteration 93600, lr = 0.001
I1006 17:26:29.461077  2964 solver.cpp:218] Iteration 93700 (11.9767 iter/s, 8.34958s/100 iters), loss = 0.00126018
I1006 17:26:29.461117  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00126053 (* 1 = 0.00126053 loss)
I1006 17:26:29.461122  2964 sgd_solver.cpp:105] Iteration 93700, lr = 0.001
I1006 17:26:37.821619  2964 solver.cpp:218] Iteration 93800 (11.961 iter/s, 8.36048s/100 iters), loss = 0.00705706
I1006 17:26:37.821660  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00705741 (* 1 = 0.00705741 loss)
I1006 17:26:37.821666  2964 sgd_solver.cpp:105] Iteration 93800, lr = 0.001
I1006 17:26:46.169864  2964 solver.cpp:218] Iteration 93900 (11.9787 iter/s, 8.34818s/100 iters), loss = 0.00189682
I1006 17:26:46.169905  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00189717 (* 1 = 0.00189717 loss)
I1006 17:26:46.169911  2964 sgd_solver.cpp:105] Iteration 93900, lr = 0.001
I1006 17:26:54.115104  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:26:54.449024  2964 solver.cpp:330] Iteration 94000, Testing net (#0)
I1006 17:26:56.370750  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:26:56.451093  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9256
I1006 17:26:56.451117  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.312043 (* 1 = 0.312043 loss)
I1006 17:26:56.534854  2964 solver.cpp:218] Iteration 94000 (9.64793 iter/s, 10.3649s/100 iters), loss = 0.00246058
I1006 17:26:56.534883  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00246094 (* 1 = 0.00246094 loss)
I1006 17:26:56.534889  2964 sgd_solver.cpp:105] Iteration 94000, lr = 0.001
I1006 17:27:04.885843  2964 solver.cpp:218] Iteration 94100 (11.9747 iter/s, 8.35093s/100 iters), loss = 0.00127495
I1006 17:27:04.885884  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00127531 (* 1 = 0.00127531 loss)
I1006 17:27:04.885890  2964 sgd_solver.cpp:105] Iteration 94100, lr = 0.001
I1006 17:27:13.245997  2964 solver.cpp:218] Iteration 94200 (11.9616 iter/s, 8.36009s/100 iters), loss = 0.0011585
I1006 17:27:13.246029  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00115886 (* 1 = 0.00115886 loss)
I1006 17:27:13.246035  2964 sgd_solver.cpp:105] Iteration 94200, lr = 0.001
I1006 17:27:21.599819  2964 solver.cpp:218] Iteration 94300 (11.9707 iter/s, 8.35376s/100 iters), loss = 0.00112147
I1006 17:27:21.599849  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00112182 (* 1 = 0.00112182 loss)
I1006 17:27:21.599855  2964 sgd_solver.cpp:105] Iteration 94300, lr = 0.001
I1006 17:27:29.954151  2964 solver.cpp:218] Iteration 94400 (11.9699 iter/s, 8.35428s/100 iters), loss = 0.00183476
I1006 17:27:29.954282  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00183512 (* 1 = 0.00183512 loss)
I1006 17:27:29.954289  2964 sgd_solver.cpp:105] Iteration 94400, lr = 0.001
I1006 17:27:37.892861  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:27:38.227694  2964 solver.cpp:330] Iteration 94500, Testing net (#0)
I1006 17:27:40.151667  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:27:40.232406  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9249
I1006 17:27:40.232442  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.311121 (* 1 = 0.311121 loss)
I1006 17:27:40.315672  2964 solver.cpp:218] Iteration 94500 (9.65124 iter/s, 10.3614s/100 iters), loss = 0.00422429
I1006 17:27:40.315701  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00422464 (* 1 = 0.00422464 loss)
I1006 17:27:40.315707  2964 sgd_solver.cpp:105] Iteration 94500, lr = 0.001
I1006 17:27:48.674367  2964 solver.cpp:218] Iteration 94600 (11.9637 iter/s, 8.35864s/100 iters), loss = 0.00227422
I1006 17:27:48.674397  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00227456 (* 1 = 0.00227456 loss)
I1006 17:27:48.674403  2964 sgd_solver.cpp:105] Iteration 94600, lr = 0.001
I1006 17:27:57.025604  2964 solver.cpp:218] Iteration 94700 (11.9744 iter/s, 8.35118s/100 iters), loss = 0.00322945
I1006 17:27:57.025645  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0032298 (* 1 = 0.0032298 loss)
I1006 17:27:57.025650  2964 sgd_solver.cpp:105] Iteration 94700, lr = 0.001
I1006 17:28:05.385941  2964 solver.cpp:218] Iteration 94800 (11.9613 iter/s, 8.36027s/100 iters), loss = 0.000972859
I1006 17:28:05.386077  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00097321 (* 1 = 0.00097321 loss)
I1006 17:28:05.386086  2964 sgd_solver.cpp:105] Iteration 94800, lr = 0.001
I1006 17:28:13.741817  2964 solver.cpp:218] Iteration 94900 (11.9678 iter/s, 8.35573s/100 iters), loss = 0.00375107
I1006 17:28:13.741856  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00375143 (* 1 = 0.00375143 loss)
I1006 17:28:13.741863  2964 sgd_solver.cpp:105] Iteration 94900, lr = 0.001
I1006 17:28:21.686321  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:28:22.019950  2964 solver.cpp:330] Iteration 95000, Testing net (#0)
I1006 17:28:23.943543  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:28:24.024065  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9243
I1006 17:28:24.024098  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.311322 (* 1 = 0.311322 loss)
I1006 17:28:24.107234  2964 solver.cpp:218] Iteration 95000 (9.64753 iter/s, 10.3653s/100 iters), loss = 0.00237193
I1006 17:28:24.107266  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00237228 (* 1 = 0.00237228 loss)
I1006 17:28:24.107273  2964 sgd_solver.cpp:105] Iteration 95000, lr = 0.001
I1006 17:28:32.451786  2964 solver.cpp:218] Iteration 95100 (11.984 iter/s, 8.34449s/100 iters), loss = 0.00116043
I1006 17:28:32.451817  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00116079 (* 1 = 0.00116079 loss)
I1006 17:28:32.451823  2964 sgd_solver.cpp:105] Iteration 95100, lr = 0.001
I1006 17:28:40.805258  2964 solver.cpp:218] Iteration 95200 (11.9712 iter/s, 8.35341s/100 iters), loss = 0.0196478
I1006 17:28:40.805397  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0196482 (* 1 = 0.0196482 loss)
I1006 17:28:40.805404  2964 sgd_solver.cpp:105] Iteration 95200, lr = 0.001
I1006 17:28:49.181372  2964 solver.cpp:218] Iteration 95300 (11.9389 iter/s, 8.37595s/100 iters), loss = 0.00158798
I1006 17:28:49.181404  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00158834 (* 1 = 0.00158834 loss)
I1006 17:28:49.181411  2964 sgd_solver.cpp:105] Iteration 95300, lr = 0.001
I1006 17:28:57.586405  2964 solver.cpp:218] Iteration 95400 (11.8977 iter/s, 8.40497s/100 iters), loss = 0.00561826
I1006 17:28:57.586436  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00561862 (* 1 = 0.00561862 loss)
I1006 17:28:57.586442  2964 sgd_solver.cpp:105] Iteration 95400, lr = 0.001
I1006 17:29:05.567013  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:29:05.900686  2964 solver.cpp:330] Iteration 95500, Testing net (#0)
I1006 17:29:07.824553  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:29:07.905002  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9248
I1006 17:29:07.905035  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.311682 (* 1 = 0.311682 loss)
I1006 17:29:07.988755  2964 solver.cpp:218] Iteration 95500 (9.61327 iter/s, 10.4023s/100 iters), loss = 0.00231913
I1006 17:29:07.988780  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00231948 (* 1 = 0.00231948 loss)
I1006 17:29:07.988787  2964 sgd_solver.cpp:105] Iteration 95500, lr = 0.001
I1006 17:29:16.341280  2964 solver.cpp:218] Iteration 95600 (11.9725 iter/s, 8.35247s/100 iters), loss = 0.00267106
I1006 17:29:16.341419  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00267141 (* 1 = 0.00267141 loss)
I1006 17:29:16.341428  2964 sgd_solver.cpp:105] Iteration 95600, lr = 0.001
I1006 17:29:24.693697  2964 solver.cpp:218] Iteration 95700 (11.9728 iter/s, 8.35226s/100 iters), loss = 0.00229302
I1006 17:29:24.693727  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00229337 (* 1 = 0.00229337 loss)
I1006 17:29:24.693734  2964 sgd_solver.cpp:105] Iteration 95700, lr = 0.001
I1006 17:29:33.048131  2964 solver.cpp:218] Iteration 95800 (11.9698 iter/s, 8.35438s/100 iters), loss = 0.00147172
I1006 17:29:33.048172  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00147207 (* 1 = 0.00147207 loss)
I1006 17:29:33.048179  2964 sgd_solver.cpp:105] Iteration 95800, lr = 0.001
I1006 17:29:41.401366  2964 solver.cpp:218] Iteration 95900 (11.9715 iter/s, 8.35317s/100 iters), loss = 0.00341485
I1006 17:29:41.401407  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0034152 (* 1 = 0.0034152 loss)
I1006 17:29:41.401412  2964 sgd_solver.cpp:105] Iteration 95900, lr = 0.001
I1006 17:29:49.494118  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:29:49.829354  2964 solver.cpp:330] Iteration 96000, Testing net (#0)
I1006 17:29:51.756008  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:29:51.836498  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9246
I1006 17:29:51.836524  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.311571 (* 1 = 0.311571 loss)
I1006 17:29:51.919380  2964 solver.cpp:218] Iteration 96000 (9.50756 iter/s, 10.5179s/100 iters), loss = 0.00279101
I1006 17:29:51.919404  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00279136 (* 1 = 0.00279136 loss)
I1006 17:29:51.919411  2964 sgd_solver.cpp:105] Iteration 96000, lr = 0.001
I1006 17:30:00.350136  2964 solver.cpp:218] Iteration 96100 (11.8614 iter/s, 8.4307s/100 iters), loss = 0.00168708
I1006 17:30:00.350165  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00168743 (* 1 = 0.00168743 loss)
I1006 17:30:00.350172  2964 sgd_solver.cpp:105] Iteration 96100, lr = 0.001
I1006 17:30:08.733301  2964 solver.cpp:218] Iteration 96200 (11.9287 iter/s, 8.38311s/100 iters), loss = 0.00578734
I1006 17:30:08.733340  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00578769 (* 1 = 0.00578769 loss)
I1006 17:30:08.733346  2964 sgd_solver.cpp:105] Iteration 96200, lr = 0.001
I1006 17:30:17.095088  2964 solver.cpp:218] Iteration 96300 (11.9593 iter/s, 8.36172s/100 iters), loss = 0.00133227
I1006 17:30:17.095118  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00133262 (* 1 = 0.00133262 loss)
I1006 17:30:17.095124  2964 sgd_solver.cpp:105] Iteration 96300, lr = 0.001
I1006 17:30:25.542940  2964 solver.cpp:218] Iteration 96400 (11.8374 iter/s, 8.44779s/100 iters), loss = 0.00244664
I1006 17:30:25.543115  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00244699 (* 1 = 0.00244699 loss)
I1006 17:30:25.543123  2964 sgd_solver.cpp:105] Iteration 96400, lr = 0.001
I1006 17:30:33.494940  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:30:33.829987  2964 solver.cpp:330] Iteration 96500, Testing net (#0)
I1006 17:30:35.751796  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:30:35.832197  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9246
I1006 17:30:35.832232  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.312662 (* 1 = 0.312662 loss)
I1006 17:30:35.915078  2964 solver.cpp:218] Iteration 96500 (9.64139 iter/s, 10.372s/100 iters), loss = 0.00156993
I1006 17:30:35.915102  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00157028 (* 1 = 0.00157028 loss)
I1006 17:30:35.915109  2964 sgd_solver.cpp:105] Iteration 96500, lr = 0.001
I1006 17:30:44.266662  2964 solver.cpp:218] Iteration 96600 (11.9739 iter/s, 8.35153s/100 iters), loss = 0.00115112
I1006 17:30:44.266703  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00115147 (* 1 = 0.00115147 loss)
I1006 17:30:44.266710  2964 sgd_solver.cpp:105] Iteration 96600, lr = 0.001
I1006 17:30:52.631431  2964 solver.cpp:218] Iteration 96700 (11.955 iter/s, 8.3647s/100 iters), loss = 0.0012592
I1006 17:30:52.631470  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00125955 (* 1 = 0.00125955 loss)
I1006 17:30:52.631476  2964 sgd_solver.cpp:105] Iteration 96700, lr = 0.001
I1006 17:31:00.987870  2964 solver.cpp:218] Iteration 96800 (11.9669 iter/s, 8.35637s/100 iters), loss = 0.00192048
I1006 17:31:00.987975  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00192083 (* 1 = 0.00192083 loss)
I1006 17:31:00.987982  2964 sgd_solver.cpp:105] Iteration 96800, lr = 0.001
I1006 17:31:09.338438  2964 solver.cpp:218] Iteration 96900 (11.9754 iter/s, 8.35044s/100 iters), loss = 0.00101413
I1006 17:31:09.338466  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00101448 (* 1 = 0.00101448 loss)
I1006 17:31:09.338472  2964 sgd_solver.cpp:105] Iteration 96900, lr = 0.001
I1006 17:31:17.274380  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:31:17.609994  2964 solver.cpp:330] Iteration 97000, Testing net (#0)
I1006 17:31:19.532487  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:31:19.612784  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9249
I1006 17:31:19.612819  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.313498 (* 1 = 0.313498 loss)
I1006 17:31:19.696290  2964 solver.cpp:218] Iteration 97000 (9.65457 iter/s, 10.3578s/100 iters), loss = 0.000498281
I1006 17:31:19.696317  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00049863 (* 1 = 0.00049863 loss)
I1006 17:31:19.696323  2964 sgd_solver.cpp:105] Iteration 97000, lr = 0.001
I1006 17:31:28.051447  2964 solver.cpp:218] Iteration 97100 (11.9687 iter/s, 8.3551s/100 iters), loss = 0.00165348
I1006 17:31:28.051477  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00165383 (* 1 = 0.00165383 loss)
I1006 17:31:28.051483  2964 sgd_solver.cpp:105] Iteration 97100, lr = 0.001
I1006 17:31:36.408047  2964 solver.cpp:218] Iteration 97200 (11.9667 iter/s, 8.35654s/100 iters), loss = 0.00656649
I1006 17:31:36.408221  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00656684 (* 1 = 0.00656684 loss)
I1006 17:31:36.408228  2964 sgd_solver.cpp:105] Iteration 97200, lr = 0.001
I1006 17:31:44.780920  2964 solver.cpp:218] Iteration 97300 (11.9436 iter/s, 8.37269s/100 iters), loss = 0.00412846
I1006 17:31:44.780959  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00412881 (* 1 = 0.00412881 loss)
I1006 17:31:44.780966  2964 sgd_solver.cpp:105] Iteration 97300, lr = 0.001
I1006 17:31:53.159660  2964 solver.cpp:218] Iteration 97400 (11.9351 iter/s, 8.37867s/100 iters), loss = 0.00195347
I1006 17:31:53.159690  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00195382 (* 1 = 0.00195382 loss)
I1006 17:31:53.159696  2964 sgd_solver.cpp:105] Iteration 97400, lr = 0.001
I1006 17:32:01.108258  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:32:01.444247  2964 solver.cpp:330] Iteration 97500, Testing net (#0)
I1006 17:32:03.367547  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:32:03.447486  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9242
I1006 17:32:03.447520  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.31327 (* 1 = 0.31327 loss)
I1006 17:32:03.530503  2964 solver.cpp:218] Iteration 97500 (9.64248 iter/s, 10.3708s/100 iters), loss = 0.00612058
I1006 17:32:03.530529  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00612094 (* 1 = 0.00612094 loss)
I1006 17:32:03.530534  2964 sgd_solver.cpp:105] Iteration 97500, lr = 0.001
I1006 17:32:11.916769  2964 solver.cpp:218] Iteration 97600 (11.9243 iter/s, 8.38622s/100 iters), loss = 0.00118772
I1006 17:32:11.916893  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00118808 (* 1 = 0.00118808 loss)
I1006 17:32:11.916900  2964 sgd_solver.cpp:105] Iteration 97600, lr = 0.001
I1006 17:32:20.281988  2964 solver.cpp:218] Iteration 97700 (11.9545 iter/s, 8.36507s/100 iters), loss = 0.00354488
I1006 17:32:20.282019  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00354523 (* 1 = 0.00354523 loss)
I1006 17:32:20.282025  2964 sgd_solver.cpp:105] Iteration 97700, lr = 0.001
I1006 17:32:28.637104  2964 solver.cpp:218] Iteration 97800 (11.9688 iter/s, 8.35506s/100 iters), loss = 0.000785321
I1006 17:32:28.637135  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00078567 (* 1 = 0.00078567 loss)
I1006 17:32:28.637140  2964 sgd_solver.cpp:105] Iteration 97800, lr = 0.001
I1006 17:32:37.054765  2964 solver.cpp:218] Iteration 97900 (11.8799 iter/s, 8.4176s/100 iters), loss = 0.00253862
I1006 17:32:37.054795  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00253897 (* 1 = 0.00253897 loss)
I1006 17:32:37.054802  2964 sgd_solver.cpp:105] Iteration 97900, lr = 0.001
I1006 17:32:44.984392  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:32:45.319152  2964 solver.cpp:330] Iteration 98000, Testing net (#0)
I1006 17:32:47.240979  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:32:47.320574  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.924
I1006 17:32:47.320610  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.314456 (* 1 = 0.314456 loss)
I1006 17:32:47.404021  2964 solver.cpp:218] Iteration 98000 (9.66259 iter/s, 10.3492s/100 iters), loss = 0.000540043
I1006 17:32:47.404047  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000540393 (* 1 = 0.000540393 loss)
I1006 17:32:47.404052  2964 sgd_solver.cpp:105] Iteration 98000, lr = 0.001
I1006 17:32:55.748348  2964 solver.cpp:218] Iteration 98100 (11.9843 iter/s, 8.34428s/100 iters), loss = 0.00102397
I1006 17:32:55.748389  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00102432 (* 1 = 0.00102432 loss)
I1006 17:32:55.748394  2964 sgd_solver.cpp:105] Iteration 98100, lr = 0.001
I1006 17:33:04.096004  2964 solver.cpp:218] Iteration 98200 (11.9795 iter/s, 8.34759s/100 iters), loss = 0.00101107
I1006 17:33:04.096045  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00101142 (* 1 = 0.00101142 loss)
I1006 17:33:04.096050  2964 sgd_solver.cpp:105] Iteration 98200, lr = 0.001
I1006 17:33:12.466687  2964 solver.cpp:218] Iteration 98300 (11.9466 iter/s, 8.37062s/100 iters), loss = 0.00133845
I1006 17:33:12.466719  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0013388 (* 1 = 0.0013388 loss)
I1006 17:33:12.466727  2964 sgd_solver.cpp:105] Iteration 98300, lr = 0.001
I1006 17:33:20.891028  2964 solver.cpp:218] Iteration 98400 (11.8704 iter/s, 8.42428s/100 iters), loss = 0.00626345
I1006 17:33:20.891176  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0062638 (* 1 = 0.0062638 loss)
I1006 17:33:20.891185  2964 sgd_solver.cpp:105] Iteration 98400, lr = 0.001
I1006 17:33:28.833942  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:33:29.166885  2964 solver.cpp:330] Iteration 98500, Testing net (#0)
I1006 17:33:31.103935  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:33:31.183841  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9232
I1006 17:33:31.183884  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.314042 (* 1 = 0.314042 loss)
I1006 17:33:31.268255  2964 solver.cpp:218] Iteration 98500 (9.63664 iter/s, 10.3771s/100 iters), loss = 0.00227926
I1006 17:33:31.268299  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00227961 (* 1 = 0.00227961 loss)
I1006 17:33:31.268306  2964 sgd_solver.cpp:105] Iteration 98500, lr = 0.001
I1006 17:33:39.626461  2964 solver.cpp:218] Iteration 98600 (11.9644 iter/s, 8.35814s/100 iters), loss = 0.0021234
I1006 17:33:39.626492  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00212375 (* 1 = 0.00212375 loss)
I1006 17:33:39.626498  2964 sgd_solver.cpp:105] Iteration 98600, lr = 0.001
I1006 17:33:47.981690  2964 solver.cpp:218] Iteration 98700 (11.9686 iter/s, 8.35517s/100 iters), loss = 0.00240203
I1006 17:33:47.981720  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00240238 (* 1 = 0.00240238 loss)
I1006 17:33:47.981726  2964 sgd_solver.cpp:105] Iteration 98700, lr = 0.001
I1006 17:33:56.342355  2964 solver.cpp:218] Iteration 98800 (11.9609 iter/s, 8.36061s/100 iters), loss = 0.0019272
I1006 17:33:56.342478  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00192755 (* 1 = 0.00192755 loss)
I1006 17:33:56.342495  2964 sgd_solver.cpp:105] Iteration 98800, lr = 0.001
I1006 17:34:04.695773  2964 solver.cpp:218] Iteration 98900 (11.9714 iter/s, 8.35327s/100 iters), loss = 0.00275976
I1006 17:34:04.695803  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00276011 (* 1 = 0.00276011 loss)
I1006 17:34:04.695809  2964 sgd_solver.cpp:105] Iteration 98900, lr = 0.001
I1006 17:34:12.642127  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:34:12.975353  2964 solver.cpp:330] Iteration 99000, Testing net (#0)
I1006 17:34:14.897241  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:34:14.977777  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9238
I1006 17:34:14.977813  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.31292 (* 1 = 0.31292 loss)
I1006 17:34:15.060767  2964 solver.cpp:218] Iteration 99000 (9.64792 iter/s, 10.3649s/100 iters), loss = 0.000811271
I1006 17:34:15.060791  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000811624 (* 1 = 0.000811624 loss)
I1006 17:34:15.060798  2964 sgd_solver.cpp:105] Iteration 99000, lr = 0.001
I1006 17:34:23.404144  2964 solver.cpp:218] Iteration 99100 (11.9856 iter/s, 8.34333s/100 iters), loss = 0.00397187
I1006 17:34:23.404173  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00397223 (* 1 = 0.00397223 loss)
I1006 17:34:23.404180  2964 sgd_solver.cpp:105] Iteration 99100, lr = 0.001
I1006 17:34:31.751031  2964 solver.cpp:218] Iteration 99200 (11.9806 iter/s, 8.34683s/100 iters), loss = 0.00270153
I1006 17:34:31.751183  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00270189 (* 1 = 0.00270189 loss)
I1006 17:34:31.751201  2964 sgd_solver.cpp:105] Iteration 99200, lr = 0.001
I1006 17:34:40.092535  2964 solver.cpp:218] Iteration 99300 (11.9885 iter/s, 8.34134s/100 iters), loss = 0.00295414
I1006 17:34:40.092567  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00295449 (* 1 = 0.00295449 loss)
I1006 17:34:40.092584  2964 sgd_solver.cpp:105] Iteration 99300, lr = 0.001
I1006 17:34:48.438434  2964 solver.cpp:218] Iteration 99400 (11.982 iter/s, 8.34584s/100 iters), loss = 0.000920909
I1006 17:34:48.438465  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000921269 (* 1 = 0.000921269 loss)
I1006 17:34:48.438472  2964 sgd_solver.cpp:105] Iteration 99400, lr = 0.001
I1006 17:34:56.373193  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:34:56.706126  2964 solver.cpp:330] Iteration 99500, Testing net (#0)
I1006 17:34:58.629364  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:34:58.708947  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9249
I1006 17:34:58.708982  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.313698 (* 1 = 0.313698 loss)
I1006 17:34:58.791815  2964 solver.cpp:218] Iteration 99500 (9.65874 iter/s, 10.3533s/100 iters), loss = 0.00122994
I1006 17:34:58.791839  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0012303 (* 1 = 0.0012303 loss)
I1006 17:34:58.791846  2964 sgd_solver.cpp:105] Iteration 99500, lr = 0.001
I1006 17:35:07.147230  2964 solver.cpp:218] Iteration 99600 (11.9684 iter/s, 8.35536s/100 iters), loss = 0.00131116
I1006 17:35:07.147372  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00131152 (* 1 = 0.00131152 loss)
I1006 17:35:07.147387  2964 sgd_solver.cpp:105] Iteration 99600, lr = 0.001
I1006 17:35:15.493320  2964 solver.cpp:218] Iteration 99700 (11.9819 iter/s, 8.34592s/100 iters), loss = 0.00172052
I1006 17:35:15.493361  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00172088 (* 1 = 0.00172088 loss)
I1006 17:35:15.493367  2964 sgd_solver.cpp:105] Iteration 99700, lr = 0.001
I1006 17:35:23.846495  2964 solver.cpp:218] Iteration 99800 (11.9716 iter/s, 8.35311s/100 iters), loss = 0.00326134
I1006 17:35:23.846536  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00326169 (* 1 = 0.00326169 loss)
I1006 17:35:23.846544  2964 sgd_solver.cpp:105] Iteration 99800, lr = 0.001
I1006 17:35:32.199640  2964 solver.cpp:218] Iteration 99900 (11.9716 iter/s, 8.35308s/100 iters), loss = 0.00371087
I1006 17:35:32.199678  2964 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00371123 (* 1 = 0.00371123 loss)
I1006 17:35:32.199686  2964 sgd_solver.cpp:105] Iteration 99900, lr = 0.001
I1006 17:35:40.145208  2972 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:35:40.479602  2964 solver.cpp:447] Snapshotting to binary proto file xn/PENLU/snapshot/resnet/res32/res32_penlu_alpha0.25_beta1_etanostudy_2study_2decay_gauss_iter_100000.caffemodel
I1006 17:35:40.493367  2964 sgd_solver.cpp:273] Snapshotting solver state to binary proto file xn/PENLU/snapshot/resnet/res32/res32_penlu_alpha0.25_beta1_etanostudy_2study_2decay_gauss_iter_100000.solverstate
I1006 17:35:40.516584  2964 solver.cpp:310] Iteration 100000, loss = 0.000831786
I1006 17:35:40.516604  2964 solver.cpp:330] Iteration 100000, Testing net (#0)
I1006 17:35:42.439360  2973 data_layer.cpp:73] Restarting data prefetching from start.
I1006 17:35:42.520001  2964 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9236
I1006 17:35:42.520027  2964 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.313272 (* 1 = 0.313272 loss)
I1006 17:35:42.520032  2964 solver.cpp:315] Optimization Done.
I1006 17:35:42.520035  2964 caffe.cpp:259] Optimization Done.
