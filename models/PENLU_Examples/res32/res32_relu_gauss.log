I1005 20:35:18.740175 10142 caffe.cpp:218] Using GPUs 0
I1005 20:35:18.743921 10142 caffe.cpp:223] GPU 0: GeForce GTX 1080
I1005 20:35:19.251837 10142 solver.cpp:44] Initializing solver from parameters: 
test_iter: 100
test_interval: 500
base_lr: 0.1
display: 100
max_iter: 100000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0001
snapshot: 100000
snapshot_prefix: "xn/PENLU/snapshot/resnet/res32/res32_relu_gauss"
solver_mode: GPU
device_id: 0
net: "/home/x306/caffe/xn/PENLU/neural/resnet/res32/res32_cifar_train_test.prototxt"
train_state {
  level: 0
  stage: ""
}
stepvalue: 40000
stepvalue: 80000
I1005 20:35:19.251981 10142 solver.cpp:87] Creating training net from net file: /home/x306/caffe/xn/PENLU/neural/resnet/res32/res32_cifar_train_test.prototxt
I1005 20:35:19.253792 10142 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: /home/x306/caffe/xn/PENLU/neural/resnet/res32/res32_cifar_train_test.prototxt
I1005 20:35:19.253803 10142 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I1005 20:35:19.253985 10142 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer Data1
I1005 20:35:19.254072 10142 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer Accuracy1
I1005 20:35:19.254609 10142 net.cpp:51] Initializing net from parameters: 
name: "resnet_cifar10"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "Data1"
  type: "Data"
  top: "Data1"
  top: "Data2"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 28
    mean_file: "/home/x306/caffe/xn/PENLU/data/cifar10/mean.binaryproto"
  }
  data_param {
    source: "/home/x306/caffe/xn/PENLU/data/cifar10/cifar10_train_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "Convolution1"
  type: "Convolution"
  bottom: "Data1"
  top: "Convolution1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm1"
  type: "BatchNorm"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1"
  type: "Scale"
  bottom: "Convolution1"
  top: "Convolution1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU1"
  type: "ReLU"
  bottom: "Convolution1"
  top: "Convolution1"
}
layer {
  name: "Convolution2"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm2"
  type: "BatchNorm"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale2"
  type: "Scale"
  bottom: "Convolution2"
  top: "Convolution2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU2"
  type: "ReLU"
  bottom: "Convolution2"
  top: "Convolution2"
}
layer {
  name: "Convolution3"
  type: "Convolution"
  bottom: "Convolution2"
  top: "Convolution3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm3"
  type: "BatchNorm"
  bottom: "Convolution3"
  top: "Convolution3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale3"
  type: "Scale"
  bottom: "Convolution3"
  top: "Convolution3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise1"
  type: "Eltwise"
  bottom: "Convolution1"
  bottom: "Convolution3"
  top: "Eltwise1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU3"
  type: "ReLU"
  bottom: "Eltwise1"
  top: "Eltwise1"
}
layer {
  name: "Convolution4"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm4"
  type: "BatchNorm"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale4"
  type: "Scale"
  bottom: "Convolution4"
  top: "Convolution4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU4"
  type: "ReLU"
  bottom: "Convolution4"
  top: "Convolution4"
}
layer {
  name: "Convolution5"
  type: "Convolution"
  bottom: "Convolution4"
  top: "Convolution5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm5"
  type: "BatchNorm"
  bottom: "Convolution5"
  top: "Convolution5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale5"
  type: "Scale"
  bottom: "Convolution5"
  top: "Convolution5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise2"
  type: "Eltwise"
  bottom: "Eltwise1"
  bottom: "Convolution5"
  top: "Eltwise2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU5"
  type: "ReLU"
  bottom: "Eltwise2"
  top: "Eltwise2"
}
layer {
  name: "Convolution6"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm6"
  type: "BatchNorm"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale6"
  type: "Scale"
  bottom: "Convolution6"
  top: "Convolution6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU6"
  type: "ReLU"
  bottom: "Convolution6"
  top: "Convolution6"
}
layer {
  name: "Convolution7"
  type: "Convolution"
  bottom: "Convolution6"
  top: "Convolution7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm7"
  type: "BatchNorm"
  bottom: "Convolution7"
  top: "Convolution7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale7"
  type: "Scale"
  bottom: "Convolution7"
  top: "Convolution7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise3"
  type: "Eltwise"
  bottom: "Eltwise2"
  bottom: "Convolution7"
  top: "Eltwise3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU7"
  type: "ReLU"
  bottom: "Eltwise3"
  top: "Eltwise3"
}
layer {
  name: "Convolution8"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm8"
  type: "BatchNorm"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale8"
  type: "Scale"
  bottom: "Convolution8"
  top: "Convolution8"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU8"
  type: "ReLU"
  bottom: "Convolution8"
  top: "Convolution8"
}
layer {
  name: "Convolution9"
  type: "Convolution"
  bottom: "Convolution8"
  top: "Convolution9"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm9"
  type: "BatchNorm"
  bottom: "Convolution9"
  top: "Convolution9"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale9"
  type: "Scale"
  bottom: "Convolution9"
  top: "Convolution9"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise4"
  type: "Eltwise"
  bottom: "Eltwise3"
  bottom: "Convolution9"
  top: "Eltwise4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU9"
  type: "ReLU"
  bottom: "Eltwise4"
  top: "Eltwise4"
}
layer {
  name: "Convolution10"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution10"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm10"
  type: "BatchNorm"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale10"
  type: "Scale"
  bottom: "Convolution10"
  top: "Convolution10"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU10"
  type: "ReLU"
  bottom: "Convolution10"
  top: "Convolution10"
}
layer {
  name: "Convolution11"
  type: "Convolution"
  bottom: "Convolution10"
  top: "Convolution11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm11"
  type: "BatchNorm"
  bottom: "Convolution11"
  top: "Convolution11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale11"
  type: "Scale"
  bottom: "Convolution11"
  top: "Convolution11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise5"
  type: "Eltwise"
  bottom: "Eltwise4"
  bottom: "Convolution11"
  top: "Eltwise5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU11"
  type: "ReLU"
  bottom: "Eltwise5"
  top: "Eltwise5"
}
layer {
  name: "Convolution12"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.25
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm12"
  type: "BatchNorm"
  bottom: "Convolution12"
  top: "Convolution12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale12"
  type: "Scale"
  bottom: "Convolution12"
  top: "Convolution12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution13"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution13"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm13"
  type: "BatchNorm"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale13"
  type: "Scale"
  bottom: "Convolution13"
  top: "Convolution13"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU12"
  type: "ReLU"
  bottom: "Convolution13"
  top: "Convolution13"
}
layer {
  name: "Convolution14"
  type: "Convolution"
  bottom: "Convolution13"
  top: "Convolution14"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm14"
  type: "BatchNorm"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale14"
  type: "Scale"
  bottom: "Convolution14"
  top: "Convolution14"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise6"
  type: "Eltwise"
  bottom: "Convolution12"
  bottom: "Convolution14"
  top: "Eltwise6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU13"
  type: "ReLU"
  bottom: "Eltwise6"
  top: "Eltwise6"
}
layer {
  name: "Convolution15"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution15"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm15"
  type: "BatchNorm"
  bottom: "Convolution15"
  top: "Convolution15"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale15"
  type: "Scale"
  bottom: "Convolution15"
  top: "Convolution15"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU14"
  type: "ReLU"
  bottom: "Convolution15"
  top: "Convolution15"
}
layer {
  name: "Convolution16"
  type: "Convolution"
  bottom: "Convolution15"
  top: "Convolution16"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm16"
  type: "BatchNorm"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale16"
  type: "Scale"
  bottom: "Convolution16"
  top: "Convolution16"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise7"
  type: "Eltwise"
  bottom: "Eltwise6"
  bottom: "Convolution16"
  top: "Eltwise7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU15"
  type: "ReLU"
  bottom: "Eltwise7"
  top: "Eltwise7"
}
layer {
  name: "Convolution17"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution17"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm17"
  type: "BatchNorm"
  bottom: "Convolution17"
  top: "Convolution17"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale17"
  type: "Scale"
  bottom: "Convolution17"
  top: "Convolution17"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU16"
  type: "ReLU"
  bottom: "Convolution17"
  top: "Convolution17"
}
layer {
  name: "Convolution18"
  type: "Convolution"
  bottom: "Convolution17"
  top: "Convolution18"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm18"
  type: "BatchNorm"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale18"
  type: "Scale"
  bottom: "Convolution18"
  top: "Convolution18"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise8"
  type: "Eltwise"
  bottom: "Eltwise7"
  bottom: "Convolution18"
  top: "Eltwise8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU17"
  type: "ReLU"
  bottom: "Eltwise8"
  top: "Eltwise8"
}
layer {
  name: "Convolution19"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution19"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm19"
  type: "BatchNorm"
  bottom: "Convolution19"
  top: "Convolution19"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale19"
  type: "Scale"
  bottom: "Convolution19"
  top: "Convolution19"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU18"
  type: "ReLU"
  bottom: "Convolution19"
  top: "Convolution19"
}
layer {
  name: "Convolution20"
  type: "Convolution"
  bottom: "Convolution19"
  top: "Convolution20"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm20"
  type: "BatchNorm"
  bottom: "Convolution20"
  top: "Convolution20"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale20"
  type: "Scale"
  bottom: "Convolution20"
  top: "Convolution20"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise9"
  type: "Eltwise"
  bottom: "Eltwise8"
  bottom: "Convolution20"
  top: "Eltwise9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU19"
  type: "ReLU"
  bottom: "Eltwise9"
  top: "Eltwise9"
}
layer {
  name: "Convolution21"
  type: "Convolution"
  bottom: "Eltwise9"
  top: "Convolution21"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm21"
  type: "BatchNorm"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale21"
  type: "Scale"
  bottom: "Convolution21"
  top: "Convolution21"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU20"
  type: "ReLU"
  bottom: "Convolution21"
  top: "Convolution21"
}
layer {
  name: "Convolution22"
  type: "Convolution"
  bottom: "Convolution21"
  top: "Convolution22"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm22"
  type: "BatchNorm"
  bottom: "Convolution22"
  top: "Convolution22"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale22"
  type: "Scale"
  bottom: "Convolution22"
  top: "Convolution22"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise10"
  type: "Eltwise"
  bottom: "Eltwise9"
  bottom: "Convolution22"
  top: "Eltwise10"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU21"
  type: "ReLU"
  bottom: "Eltwise10"
  top: "Eltwise10"
}
layer {
  name: "Convolution23"
  type: "Convolution"
  bottom: "Eltwise10"
  top: "Convolution23"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.17677669
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm23"
  type: "BatchNorm"
  bottom: "Convolution23"
  top: "Convolution23"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale23"
  type: "Scale"
  bottom: "Convolution23"
  top: "Convolution23"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution24"
  type: "Convolution"
  bottom: "Eltwise10"
  top: "Convolution24"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm24"
  type: "BatchNorm"
  bottom: "Convolution24"
  top: "Convolution24"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale24"
  type: "Scale"
  bottom: "Convolution24"
  top: "Convolution24"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU22"
  type: "ReLU"
  bottom: "Convolution24"
  top: "Convolution24"
}
layer {
  name: "Convolution25"
  type: "Convolution"
  bottom: "Convolution24"
  top: "Convolution25"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm25"
  type: "BatchNorm"
  bottom: "Convolution25"
  top: "Convolution25"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale25"
  type: "Scale"
  bottom: "Convolution25"
  top: "Convolution25"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise11"
  type: "Eltwise"
  bottom: "Convolution23"
  bottom: "Convolution25"
  top: "Eltwise11"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU23"
  type: "ReLU"
  bottom: "Eltwise11"
  top: "Eltwise11"
}
layer {
  name: "Convolution26"
  type: "Convolution"
  bottom: "Eltwise11"
  top: "Convolution26"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm26"
  type: "BatchNorm"
  bottom: "Convolution26"
  top: "Convolution26"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale26"
  type: "Scale"
  bottom: "Convolution26"
  top: "Convolution26"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU24"
  type: "ReLU"
  bottom: "Convolution26"
  top: "Convolution26"
}
layer {
  name: "Convolution27"
  type: "Convolution"
  bottom: "Convolution26"
  top: "Convolution27"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm27"
  type: "BatchNorm"
  bottom: "Convolution27"
  top: "Convolution27"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale27"
  type: "Scale"
  bottom: "Convolution27"
  top: "Convolution27"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise12"
  type: "Eltwise"
  bottom: "Eltwise11"
  bottom: "Convolution27"
  top: "Eltwise12"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU25"
  type: "ReLU"
  bottom: "Eltwise12"
  top: "Eltwise12"
}
layer {
  name: "Convolution28"
  type: "Convolution"
  bottom: "Eltwise12"
  top: "Convolution28"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm28"
  type: "BatchNorm"
  bottom: "Convolution28"
  top: "Convolution28"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale28"
  type: "Scale"
  bottom: "Convolution28"
  top: "Convolution28"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU26"
  type: "ReLU"
  bottom: "Convolution28"
  top: "Convolution28"
}
layer {
  name: "Convolution29"
  type: "Convolution"
  bottom: "Convolution28"
  top: "Convolution29"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm29"
  type: "BatchNorm"
  bottom: "Convolution29"
  top: "Convolution29"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale29"
  type: "Scale"
  bottom: "Convolution29"
  top: "Convolution29"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise13"
  type: "Eltwise"
  bottom: "Eltwise12"
  bottom: "Convolution29"
  top: "Eltwise13"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU27"
  type: "ReLU"
  bottom: "Eltwise13"
  top: "Eltwise13"
}
layer {
  name: "Convolution30"
  type: "Convolution"
  bottom: "Eltwise13"
  top: "Convolution30"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm30"
  type: "BatchNorm"
  bottom: "Convolution30"
  top: "Convolution30"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale30"
  type: "Scale"
  bottom: "Convolution30"
  top: "Convolution30"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU28"
  type: "ReLU"
  bottom: "Convolution30"
  top: "Convolution30"
}
layer {
  name: "Convolution31"
  type: "Convolution"
  bottom: "Convolution30"
  top: "Convolution31"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm31"
  type: "BatchNorm"
  bottom: "Convolution31"
  top: "Convolution31"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale31"
  type: "Scale"
  bottom: "Convolution31"
  top: "Convolution31"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise14"
  type: "Eltwise"
  bottom: "Eltwise13"
  bottom: "Convolution31"
  top: "Eltwise14"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU29"
  type: "ReLU"
  bottom: "Eltwise14"
  top: "Eltwise14"
}
layer {
  name: "Convolution32"
  type: "Convolution"
  bottom: "Eltwise14"
  top: "Convolution32"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm32"
  type: "BatchNorm"
I1005 20:35:19.255118 10142 layer_factory.hpp:77] Creating layer Data1
I1005 20:35:19.255187 10142 db_lmdb.cpp:35] Opened lmdb /home/x306/caffe/xn/PENLU/data/cifar10/cifar10_train_lmdb
I1005 20:35:19.255213 10142 net.cpp:84] Creating Layer Data1
I1005 20:35:19.255219 10142 net.cpp:380] Data1 -> Data1
I1005 20:35:19.255236 10142 net.cpp:380] Data1 -> Data2
I1005 20:35:19.255245 10142 data_transformer.cpp:25] Loading mean file from: /home/x306/caffe/xn/PENLU/data/cifar10/mean.binaryproto
I1005 20:35:19.256686 10142 data_layer.cpp:45] output data size: 100,3,28,28
I1005 20:35:19.275344 10142 net.cpp:122] Setting up Data1
I1005 20:35:19.275375 10142 net.cpp:129] Top shape: 100 3 28 28 (235200)
I1005 20:35:19.275380 10142 net.cpp:129] Top shape: 100 (100)
I1005 20:35:19.275383 10142 net.cpp:137] Memory required for data: 941200
I1005 20:35:19.275390 10142 layer_factory.hpp:77] Creating layer Convolution1
I1005 20:35:19.275413 10142 net.cpp:84] Creating Layer Convolution1
I1005 20:35:19.275418 10142 net.cpp:406] Convolution1 <- Data1
I1005 20:35:19.275427 10142 net.cpp:380] Convolution1 -> Convolution1
I1005 20:35:19.593055 10142 net.cpp:122] Setting up Convolution1
I1005 20:35:19.593080 10142 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 20:35:19.593082 10142 net.cpp:137] Memory required for data: 5958800
I1005 20:35:19.593098 10142 layer_factory.hpp:77] Creating layer BatchNorm1
I1005 20:35:19.593119 10142 net.cpp:84] Creating Layer BatchNorm1
I1005 20:35:19.593123 10142 net.cpp:406] BatchNorm1 <- Convolution1
I1005 20:35:19.593143 10142 net.cpp:367] BatchNorm1 -> Convolution1 (in-place)
I1005 20:35:19.593281 10142 net.cpp:122] Setting up BatchNorm1
I1005 20:35:19.593287 10142 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 20:35:19.593289 10142 net.cpp:137] Memory required for data: 10976400
I1005 20:35:19.593297 10142 layer_factory.hpp:77] Creating layer Scale1
I1005 20:35:19.593307 10142 net.cpp:84] Creating Layer Scale1
I1005 20:35:19.593310 10142 net.cpp:406] Scale1 <- Convolution1
I1005 20:35:19.593323 10142 net.cpp:367] Scale1 -> Convolution1 (in-place)
I1005 20:35:19.593364 10142 layer_factory.hpp:77] Creating layer Scale1
I1005 20:35:19.593461 10142 net.cpp:122] Setting up Scale1
I1005 20:35:19.593466 10142 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 20:35:19.593469 10142 net.cpp:137] Memory required for data: 15994000
I1005 20:35:19.593473 10142 layer_factory.hpp:77] Creating layer ReLU1
I1005 20:35:19.593488 10142 net.cpp:84] Creating Layer ReLU1
I1005 20:35:19.593492 10142 net.cpp:406] ReLU1 <- Convolution1
I1005 20:35:19.593495 10142 net.cpp:367] ReLU1 -> Convolution1 (in-place)
I1005 20:35:19.594804 10142 net.cpp:122] Setting up ReLU1
I1005 20:35:19.594810 10142 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 20:35:19.594813 10142 net.cpp:137] Memory required for data: 21011600
I1005 20:35:19.594816 10142 layer_factory.hpp:77] Creating layer Convolution1_ReLU1_0_split
I1005 20:35:19.594833 10142 net.cpp:84] Creating Layer Convolution1_ReLU1_0_split
I1005 20:35:19.594836 10142 net.cpp:406] Convolution1_ReLU1_0_split <- Convolution1
I1005 20:35:19.594841 10142 net.cpp:380] Convolution1_ReLU1_0_split -> Convolution1_ReLU1_0_split_0
I1005 20:35:19.594846 10142 net.cpp:380] Convolution1_ReLU1_0_split -> Convolution1_ReLU1_0_split_1
I1005 20:35:19.594871 10142 net.cpp:122] Setting up Convolution1_ReLU1_0_split
I1005 20:35:19.594877 10142 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 20:35:19.594888 10142 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 20:35:19.594890 10142 net.cpp:137] Memory required for data: 31046800
I1005 20:35:19.594892 10142 layer_factory.hpp:77] Creating layer Convolution2
I1005 20:35:19.594911 10142 net.cpp:84] Creating Layer Convolution2
I1005 20:35:19.594914 10142 net.cpp:406] Convolution2 <- Convolution1_ReLU1_0_split_0
I1005 20:35:19.594919 10142 net.cpp:380] Convolution2 -> Convolution2
I1005 20:35:19.601517 10142 net.cpp:122] Setting up Convolution2
I1005 20:35:19.601527 10142 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 20:35:19.601531 10142 net.cpp:137] Memory required for data: 36064400
I1005 20:35:19.601547 10142 layer_factory.hpp:77] Creating layer BatchNorm2
I1005 20:35:19.601554 10142 net.cpp:84] Creating Layer BatchNorm2
I1005 20:35:19.601558 10142 net.cpp:406] BatchNorm2 <- Convolution2
I1005 20:35:19.601562 10142 net.cpp:367] BatchNorm2 -> Convolution2 (in-place)
I1005 20:35:19.601692 10142 net.cpp:122] Setting up BatchNorm2
I1005 20:35:19.601698 10142 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 20:35:19.601701 10142 net.cpp:137] Memory required for data: 41082000
I1005 20:35:19.601716 10142 layer_factory.hpp:77] Creating layer Scale2
I1005 20:35:19.601722 10142 net.cpp:84] Creating Layer Scale2
I1005 20:35:19.601724 10142 net.cpp:406] Scale2 <- Convolution2
I1005 20:35:19.601727 10142 net.cpp:367] Scale2 -> Convolution2 (in-place)
I1005 20:35:19.601753 10142 layer_factory.hpp:77] Creating layer Scale2
I1005 20:35:19.601855 10142 net.cpp:122] Setting up Scale2
I1005 20:35:19.601861 10142 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 20:35:19.601862 10142 net.cpp:137] Memory required for data: 46099600
I1005 20:35:19.601866 10142 layer_factory.hpp:77] Creating layer ReLU2
I1005 20:35:19.601881 10142 net.cpp:84] Creating Layer ReLU2
I1005 20:35:19.601883 10142 net.cpp:406] ReLU2 <- Convolution2
I1005 20:35:19.601886 10142 net.cpp:367] ReLU2 -> Convolution2 (in-place)
I1005 20:35:19.603643 10142 net.cpp:122] Setting up ReLU2
I1005 20:35:19.603653 10142 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 20:35:19.603673 10142 net.cpp:137] Memory required for data: 51117200
I1005 20:35:19.603677 10142 layer_factory.hpp:77] Creating layer Convolution3
I1005 20:35:19.603687 10142 net.cpp:84] Creating Layer Convolution3
I1005 20:35:19.603689 10142 net.cpp:406] Convolution3 <- Convolution2
I1005 20:35:19.603694 10142 net.cpp:380] Convolution3 -> Convolution3
I1005 20:35:19.610487 10142 net.cpp:122] Setting up Convolution3
I1005 20:35:19.610510 10142 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 20:35:19.610513 10142 net.cpp:137] Memory required for data: 56134800
I1005 20:35:19.610519 10142 layer_factory.hpp:77] Creating layer BatchNorm3
I1005 20:35:19.610539 10142 net.cpp:84] Creating Layer BatchNorm3
I1005 20:35:19.610543 10142 net.cpp:406] BatchNorm3 <- Convolution3
I1005 20:35:19.610546 10142 net.cpp:367] BatchNorm3 -> Convolution3 (in-place)
I1005 20:35:19.610687 10142 net.cpp:122] Setting up BatchNorm3
I1005 20:35:19.610692 10142 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 20:35:19.610704 10142 net.cpp:137] Memory required for data: 61152400
I1005 20:35:19.610713 10142 layer_factory.hpp:77] Creating layer Scale3
I1005 20:35:19.610729 10142 net.cpp:84] Creating Layer Scale3
I1005 20:35:19.610733 10142 net.cpp:406] Scale3 <- Convolution3
I1005 20:35:19.610736 10142 net.cpp:367] Scale3 -> Convolution3 (in-place)
I1005 20:35:19.610774 10142 layer_factory.hpp:77] Creating layer Scale3
I1005 20:35:19.610896 10142 net.cpp:122] Setting up Scale3
I1005 20:35:19.610901 10142 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 20:35:19.610903 10142 net.cpp:137] Memory required for data: 66170000
I1005 20:35:19.610918 10142 layer_factory.hpp:77] Creating layer Eltwise1
I1005 20:35:19.610924 10142 net.cpp:84] Creating Layer Eltwise1
I1005 20:35:19.610926 10142 net.cpp:406] Eltwise1 <- Convolution1_ReLU1_0_split_1
I1005 20:35:19.610939 10142 net.cpp:406] Eltwise1 <- Convolution3
I1005 20:35:19.610945 10142 net.cpp:380] Eltwise1 -> Eltwise1
I1005 20:35:19.610972 10142 net.cpp:122] Setting up Eltwise1
I1005 20:35:19.610976 10142 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 20:35:19.610978 10142 net.cpp:137] Memory required for data: 71187600
I1005 20:35:19.610980 10142 layer_factory.hpp:77] Creating layer ReLU3
I1005 20:35:19.610996 10142 net.cpp:84] Creating Layer ReLU3
I1005 20:35:19.610998 10142 net.cpp:406] ReLU3 <- Eltwise1
I1005 20:35:19.611011 10142 net.cpp:367] ReLU3 -> Eltwise1 (in-place)
I1005 20:35:19.612632 10142 net.cpp:122] Setting up ReLU3
I1005 20:35:19.612643 10142 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 20:35:19.612655 10142 net.cpp:137] Memory required for data: 76205200
I1005 20:35:19.612658 10142 layer_factory.hpp:77] Creating layer Eltwise1_ReLU3_0_split
I1005 20:35:19.612663 10142 net.cpp:84] Creating Layer Eltwise1_ReLU3_0_split
I1005 20:35:19.612665 10142 net.cpp:406] Eltwise1_ReLU3_0_split <- Eltwise1
I1005 20:35:19.612679 10142 net.cpp:380] Eltwise1_ReLU3_0_split -> Eltwise1_ReLU3_0_split_0
I1005 20:35:19.612685 10142 net.cpp:380] Eltwise1_ReLU3_0_split -> Eltwise1_ReLU3_0_split_1
I1005 20:35:19.612722 10142 net.cpp:122] Setting up Eltwise1_ReLU3_0_split
I1005 20:35:19.612726 10142 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 20:35:19.612740 10142 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 20:35:19.612741 10142 net.cpp:137] Memory required for data: 86240400
I1005 20:35:19.612743 10142 layer_factory.hpp:77] Creating layer Convolution4
I1005 20:35:19.612762 10142 net.cpp:84] Creating Layer Convolution4
I1005 20:35:19.612766 10142 net.cpp:406] Convolution4 <- Eltwise1_ReLU3_0_split_0
I1005 20:35:19.612778 10142 net.cpp:380] Convolution4 -> Convolution4
I1005 20:35:19.618882 10142 net.cpp:122] Setting up Convolution4
I1005 20:35:19.618892 10142 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 20:35:19.618906 10142 net.cpp:137] Memory required for data: 91258000
I1005 20:35:19.618909 10142 layer_factory.hpp:77] Creating layer BatchNorm4
I1005 20:35:19.618916 10142 net.cpp:84] Creating Layer BatchNorm4
I1005 20:35:19.618917 10142 net.cpp:406] BatchNorm4 <- Convolution4
I1005 20:35:19.618940 10142 net.cpp:367] BatchNorm4 -> Convolution4 (in-place)
I1005 20:35:19.619086 10142 net.cpp:122] Setting up BatchNorm4
I1005 20:35:19.619091 10142 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 20:35:19.619102 10142 net.cpp:137] Memory required for data: 96275600
I1005 20:35:19.619107 10142 layer_factory.hpp:77] Creating layer Scale4
I1005 20:35:19.619112 10142 net.cpp:84] Creating Layer Scale4
I1005 20:35:19.619124 10142 net.cpp:406] Scale4 <- Convolution4
I1005 20:35:19.619128 10142 net.cpp:367] Scale4 -> Convolution4 (in-place)
I1005 20:35:19.619164 10142 layer_factory.hpp:77] Creating layer Scale4
I1005 20:35:19.619258 10142 net.cpp:122] Setting up Scale4
I1005 20:35:19.619263 10142 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 20:35:19.619266 10142 net.cpp:137] Memory required for data: 101293200
I1005 20:35:19.619280 10142 layer_factory.hpp:77] Creating layer ReLU4
I1005 20:35:19.619284 10142 net.cpp:84] Creating Layer ReLU4
I1005 20:35:19.619287 10142 net.cpp:406] ReLU4 <- Convolution4
I1005 20:35:19.619290 10142 net.cpp:367] ReLU4 -> Convolution4 (in-place)
I1005 20:35:19.619403 10142 net.cpp:122] Setting up ReLU4
I1005 20:35:19.619410 10142 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 20:35:19.619412 10142 net.cpp:137] Memory required for data: 106310800
I1005 20:35:19.619415 10142 layer_factory.hpp:77] Creating layer Convolution5
I1005 20:35:19.619423 10142 net.cpp:84] Creating Layer Convolution5
I1005 20:35:19.619426 10142 net.cpp:406] Convolution5 <- Convolution4
I1005 20:35:19.619431 10142 net.cpp:380] Convolution5 -> Convolution5
I1005 20:35:19.620368 10142 net.cpp:122] Setting up Convolution5
I1005 20:35:19.620378 10142 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 20:35:19.620381 10142 net.cpp:137] Memory required for data: 111328400
I1005 20:35:19.620386 10142 layer_factory.hpp:77] Creating layer BatchNorm5
I1005 20:35:19.620393 10142 net.cpp:84] Creating Layer BatchNorm5
I1005 20:35:19.620398 10142 net.cpp:406] BatchNorm5 <- Convolution5
I1005 20:35:19.620402 10142 net.cpp:367] BatchNorm5 -> Convolution5 (in-place)
I1005 20:35:19.620529 10142 net.cpp:122] Setting up BatchNorm5
I1005 20:35:19.620535 10142 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 20:35:19.620538 10142 net.cpp:137] Memory required for data: 116346000
I1005 20:35:19.620548 10142 layer_factory.hpp:77] Creating layer Scale5
I1005 20:35:19.620551 10142 net.cpp:84] Creating Layer Scale5
I1005 20:35:19.620555 10142 net.cpp:406] Scale5 <- Convolution5
I1005 20:35:19.620559 10142 net.cpp:367] Scale5 -> Convolution5 (in-place)
I1005 20:35:19.620586 10142 layer_factory.hpp:77] Creating layer Scale5
I1005 20:35:19.620663 10142 net.cpp:122] Setting up Scale5
I1005 20:35:19.620669 10142 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 20:35:19.620671 10142 net.cpp:137] Memory required for data: 121363600
I1005 20:35:19.620676 10142 layer_factory.hpp:77] Creating layer Eltwise2
I1005 20:35:19.620681 10142 net.cpp:84] Creating Layer Eltwise2
I1005 20:35:19.620683 10142 net.cpp:406] Eltwise2 <- Eltwise1_ReLU3_0_split_1
I1005 20:35:19.620687 10142 net.cpp:406] Eltwise2 <- Convolution5
I1005 20:35:19.620690 10142 net.cpp:380] Eltwise2 -> Eltwise2
I1005 20:35:19.620707 10142 net.cpp:122] Setting up Eltwise2
I1005 20:35:19.620710 10142 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 20:35:19.620712 10142 net.cpp:137] Memory required for data: 126381200
I1005 20:35:19.620715 10142 layer_factory.hpp:77] Creating layer ReLU5
I1005 20:35:19.620719 10142 net.cpp:84] Creating Layer ReLU5
I1005 20:35:19.620721 10142 net.cpp:406] ReLU5 <- Eltwise2
I1005 20:35:19.620724 10142 net.cpp:367] ReLU5 -> Eltwise2 (in-place)
I1005 20:35:19.622261 10142 net.cpp:122] Setting up ReLU5
I1005 20:35:19.622268 10142 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 20:35:19.622270 10142 net.cpp:137] Memory required for data: 131398800
I1005 20:35:19.622273 10142 layer_factory.hpp:77] Creating layer Eltwise2_ReLU5_0_split
I1005 20:35:19.622277 10142 net.cpp:84] Creating Layer Eltwise2_ReLU5_0_split
I1005 20:35:19.622287 10142 net.cpp:406] Eltwise2_ReLU5_0_split <- Eltwise2
I1005 20:35:19.622292 10142 net.cpp:380] Eltwise2_ReLU5_0_split -> Eltwise2_ReLU5_0_split_0
I1005 20:35:19.622297 10142 net.cpp:380] Eltwise2_ReLU5_0_split -> Eltwise2_ReLU5_0_split_1
I1005 20:35:19.622323 10142 net.cpp:122] Setting up Eltwise2_ReLU5_0_split
I1005 20:35:19.622328 10142 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 20:35:19.622331 10142 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 20:35:19.622334 10142 net.cpp:137] Memory required for data: 141434000
I1005 20:35:19.622335 10142 layer_factory.hpp:77] Creating layer Convolution6
I1005 20:35:19.622342 10142 net.cpp:84] Creating Layer Convolution6
I1005 20:35:19.622346 10142 net.cpp:406] Convolution6 <- Eltwise2_ReLU5_0_split_0
I1005 20:35:19.622350 10142 net.cpp:380] Convolution6 -> Convolution6
I1005 20:35:19.629915 10142 net.cpp:122] Setting up Convolution6
I1005 20:35:19.629936 10142 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 20:35:19.629940 10142 net.cpp:137] Memory required for data: 146451600
I1005 20:35:19.629945 10142 layer_factory.hpp:77] Creating layer BatchNorm6
I1005 20:35:19.629959 10142 net.cpp:84] Creating Layer BatchNorm6
I1005 20:35:19.629962 10142 net.cpp:406] BatchNorm6 <- Convolution6
I1005 20:35:19.629966 10142 net.cpp:367] BatchNorm6 -> Convolution6 (in-place)
I1005 20:35:19.630108 10142 net.cpp:122] Setting up BatchNorm6
I1005 20:35:19.630115 10142 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 20:35:19.630126 10142 net.cpp:137] Memory required for data: 151469200
I1005 20:35:19.630131 10142 layer_factory.hpp:77] Creating layer Scale6
I1005 20:35:19.630146 10142 net.cpp:84] Creating Layer Scale6
I1005 20:35:19.630151 10142 net.cpp:406] Scale6 <- Convolution6
I1005 20:35:19.630153 10142 net.cpp:367] Scale6 -> Convolution6 (in-place)
I1005 20:35:19.630198 10142 layer_factory.hpp:77] Creating layer Scale6
I1005 20:35:19.630313 10142 net.cpp:122] Setting up Scale6
I1005 20:35:19.630318 10142 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 20:35:19.630321 10142 net.cpp:137] Memory required for data: 156486800
I1005 20:35:19.630326 10142 layer_factory.hpp:77] Creating layer ReLU6
I1005 20:35:19.630331 10142 net.cpp:84] Creating Layer ReLU6
I1005 20:35:19.630333 10142 net.cpp:406] ReLU6 <- Convolution6
I1005 20:35:19.630337 10142 net.cpp:367] ReLU6 -> Convolution6 (in-place)
I1005 20:35:19.632053 10142 net.cpp:122] Setting up ReLU6
I1005 20:35:19.632061 10142 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 20:35:19.632063 10142 net.cpp:137] Memory required for data: 161504400
I1005 20:35:19.632076 10142 layer_factory.hpp:77] Creating layer Convolution7
I1005 20:35:19.632086 10142 net.cpp:84] Creating Layer Convolution7
I1005 20:35:19.632088 10142 net.cpp:406] Convolution7 <- Convolution6
I1005 20:35:19.632092 10142 net.cpp:380] Convolution7 -> Convolution7
I1005 20:35:19.635856 10142 net.cpp:122] Setting up Convolution7
I1005 20:35:19.635879 10142 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 20:35:19.635881 10142 net.cpp:137] Memory required for data: 166522000
I1005 20:35:19.635885 10142 layer_factory.hpp:77] Creating layer BatchNorm7
I1005 20:35:19.635901 10142 net.cpp:84] Creating Layer BatchNorm7
I1005 20:35:19.635905 10142 net.cpp:406] BatchNorm7 <- Convolution7
I1005 20:35:19.635908 10142 net.cpp:367] BatchNorm7 -> Convolution7 (in-place)
I1005 20:35:19.636052 10142 net.cpp:122] Setting up BatchNorm7
I1005 20:35:19.636057 10142 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 20:35:19.636070 10142 net.cpp:137] Memory required for data: 171539600
I1005 20:35:19.636075 10142 layer_factory.hpp:77] Creating layer Scale7
I1005 20:35:19.636091 10142 net.cpp:84] Creating Layer Scale7
I1005 20:35:19.636093 10142 net.cpp:406] Scale7 <- Convolution7
I1005 20:35:19.636096 10142 net.cpp:367] Scale7 -> Convolution7 (in-place)
I1005 20:35:19.636134 10142 layer_factory.hpp:77] Creating layer Scale7
I1005 20:35:19.636229 10142 net.cpp:122] Setting up Scale7
I1005 20:35:19.636234 10142 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 20:35:19.636255 10142 net.cpp:137] Memory required for data: 176557200
I1005 20:35:19.636258 10142 layer_factory.hpp:77] Creating layer Eltwise3
I1005 20:35:19.636263 10142 net.cpp:84] Creating Layer Eltwise3
I1005 20:35:19.636276 10142 net.cpp:406] Eltwise3 <- Eltwise2_ReLU5_0_split_1
I1005 20:35:19.636279 10142 net.cpp:406] Eltwise3 <- Convolution7
I1005 20:35:19.636283 10142 net.cpp:380] Eltwise3 -> Eltwise3
I1005 20:35:19.636319 10142 net.cpp:122] Setting up Eltwise3
I1005 20:35:19.636323 10142 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 20:35:19.636325 10142 net.cpp:137] Memory required for data: 181574800
I1005 20:35:19.636337 10142 layer_factory.hpp:77] Creating layer ReLU7
I1005 20:35:19.636342 10142 net.cpp:84] Creating Layer ReLU7
I1005 20:35:19.636343 10142 net.cpp:406] ReLU7 <- Eltwise3
I1005 20:35:19.636355 10142 net.cpp:367] ReLU7 -> Eltwise3 (in-place)
I1005 20:35:19.637970 10142 net.cpp:122] Setting up ReLU7
I1005 20:35:19.637977 10142 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 20:35:19.637989 10142 net.cpp:137] Memory required for data: 186592400
I1005 20:35:19.637991 10142 layer_factory.hpp:77] Creating layer Eltwise3_ReLU7_0_split
I1005 20:35:19.637996 10142 net.cpp:84] Creating Layer Eltwise3_ReLU7_0_split
I1005 20:35:19.638008 10142 net.cpp:406] Eltwise3_ReLU7_0_split <- Eltwise3
I1005 20:35:19.638012 10142 net.cpp:380] Eltwise3_ReLU7_0_split -> Eltwise3_ReLU7_0_split_0
I1005 20:35:19.638016 10142 net.cpp:380] Eltwise3_ReLU7_0_split -> Eltwise3_ReLU7_0_split_1
I1005 20:35:19.638072 10142 net.cpp:122] Setting up Eltwise3_ReLU7_0_split
I1005 20:35:19.638077 10142 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 20:35:19.638088 10142 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 20:35:19.638090 10142 net.cpp:137] Memory required for data: 196627600
I1005 20:35:19.638092 10142 layer_factory.hpp:77] Creating layer Convolution8
I1005 20:35:19.638108 10142 net.cpp:84] Creating Layer Convolution8
I1005 20:35:19.638111 10142 net.cpp:406] Convolution8 <- Eltwise3_ReLU7_0_split_0
I1005 20:35:19.638125 10142 net.cpp:380] Convolution8 -> Convolution8
I1005 20:35:19.644642 10142 net.cpp:122] Setting up Convolution8
I1005 20:35:19.644652 10142 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 20:35:19.644665 10142 net.cpp:137] Memory required for data: 201645200
I1005 20:35:19.644670 10142 layer_factory.hpp:77] Creating layer BatchNorm8
I1005 20:35:19.644675 10142 net.cpp:84] Creating Layer BatchNorm8
I1005 20:35:19.644678 10142 net.cpp:406] BatchNorm8 <- Convolution8
I1005 20:35:19.644682 10142 net.cpp:367] BatchNorm8 -> Convolution8 (in-place)
I1005 20:35:19.644847 10142 net.cpp:122] Setting up BatchNorm8
I1005 20:35:19.644851 10142 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 20:35:19.644865 10142 net.cpp:137] Memory required for data: 206662800
I1005 20:35:19.644870 10142 layer_factory.hpp:77] Creating layer Scale8
I1005 20:35:19.644873 10142 net.cpp:84] Creating Layer Scale8
I1005 20:35:19.644886 10142 net.cpp:406] Scale8 <- Convolution8
I1005 20:35:19.644889 10142 net.cpp:367] Scale8 -> Convolution8 (in-place)
I1005 20:35:19.644925 10142 layer_factory.hpp:77] Creating layer Scale8
I1005 20:35:19.645031 10142 net.cpp:122] Setting up Scale8
I1005 20:35:19.645036 10142 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 20:35:19.645050 10142 net.cpp:137] Memory required for data: 211680400
I1005 20:35:19.645053 10142 layer_factory.hpp:77] Creating layer ReLU8
I1005 20:35:19.645057 10142 net.cpp:84] Creating Layer ReLU8
I1005 20:35:19.645059 10142 net.cpp:406] ReLU8 <- Convolution8
I1005 20:35:19.645063 10142 net.cpp:367] ReLU8 -> Convolution8 (in-place)
I1005 20:35:19.646786 10142 net.cpp:122] Setting up ReLU8
I1005 20:35:19.646796 10142 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 20:35:19.646808 10142 net.cpp:137] Memory required for data: 216698000
I1005 20:35:19.646811 10142 layer_factory.hpp:77] Creating layer Convolution9
I1005 20:35:19.646818 10142 net.cpp:84] Creating Layer Convolution9
I1005 20:35:19.646831 10142 net.cpp:406] Convolution9 <- Convolution8
I1005 20:35:19.646844 10142 net.cpp:380] Convolution9 -> Convolution9
I1005 20:35:19.653429 10142 net.cpp:122] Setting up Convolution9
I1005 20:35:19.653439 10142 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 20:35:19.653440 10142 net.cpp:137] Memory required for data: 221715600
I1005 20:35:19.653445 10142 layer_factory.hpp:77] Creating layer BatchNorm9
I1005 20:35:19.653462 10142 net.cpp:84] Creating Layer BatchNorm9
I1005 20:35:19.653465 10142 net.cpp:406] BatchNorm9 <- Convolution9
I1005 20:35:19.653470 10142 net.cpp:367] BatchNorm9 -> Convolution9 (in-place)
I1005 20:35:19.653604 10142 net.cpp:122] Setting up BatchNorm9
I1005 20:35:19.653609 10142 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 20:35:19.653611 10142 net.cpp:137] Memory required for data: 226733200
I1005 20:35:19.653626 10142 layer_factory.hpp:77] Creating layer Scale9
I1005 20:35:19.653632 10142 net.cpp:84] Creating Layer Scale9
I1005 20:35:19.653635 10142 net.cpp:406] Scale9 <- Convolution9
I1005 20:35:19.653638 10142 net.cpp:367] Scale9 -> Convolution9 (in-place)
I1005 20:35:19.653673 10142 layer_factory.hpp:77] Creating layer Scale9
I1005 20:35:19.653769 10142 net.cpp:122] Setting up Scale9
I1005 20:35:19.653774 10142 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 20:35:19.653776 10142 net.cpp:137] Memory required for data: 231750800
I1005 20:35:19.653790 10142 layer_factory.hpp:77] Creating layer Eltwise4
I1005 20:35:19.653795 10142 net.cpp:84] Creating Layer Eltwise4
I1005 20:35:19.653800 10142 net.cpp:406] Eltwise4 <- Eltwise3_ReLU7_0_split_1
I1005 20:35:19.653802 10142 net.cpp:406] Eltwise4 <- Convolution9
I1005 20:35:19.653805 10142 net.cpp:380] Eltwise4 -> Eltwise4
I1005 20:35:19.653821 10142 net.cpp:122] Setting up Eltwise4
I1005 20:35:19.653825 10142 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 20:35:19.653827 10142 net.cpp:137] Memory required for data: 236768400
I1005 20:35:19.653831 10142 layer_factory.hpp:77] Creating layer ReLU9
I1005 20:35:19.653833 10142 net.cpp:84] Creating Layer ReLU9
I1005 20:35:19.653836 10142 net.cpp:406] ReLU9 <- Eltwise4
I1005 20:35:19.653839 10142 net.cpp:367] ReLU9 -> Eltwise4 (in-place)
I1005 20:35:19.655570 10142 net.cpp:122] Setting up ReLU9
I1005 20:35:19.655578 10142 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 20:35:19.655581 10142 net.cpp:137] Memory required for data: 241786000
I1005 20:35:19.655585 10142 layer_factory.hpp:77] Creating layer Eltwise4_ReLU9_0_split
I1005 20:35:19.655589 10142 net.cpp:84] Creating Layer Eltwise4_ReLU9_0_split
I1005 20:35:19.655593 10142 net.cpp:406] Eltwise4_ReLU9_0_split <- Eltwise4
I1005 20:35:19.655597 10142 net.cpp:380] Eltwise4_ReLU9_0_split -> Eltwise4_ReLU9_0_split_0
I1005 20:35:19.655602 10142 net.cpp:380] Eltwise4_ReLU9_0_split -> Eltwise4_ReLU9_0_split_1
I1005 20:35:19.655632 10142 net.cpp:122] Setting up Eltwise4_ReLU9_0_split
I1005 20:35:19.655637 10142 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 20:35:19.655639 10142 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 20:35:19.655642 10142 net.cpp:137] Memory required for data: 251821200
I1005 20:35:19.655644 10142 layer_factory.hpp:77] Creating layer Convolution10
I1005 20:35:19.655652 10142 net.cpp:84] Creating Layer Convolution10
I1005 20:35:19.655655 10142 net.cpp:406] Convolution10 <- Eltwise4_ReLU9_0_split_0
I1005 20:35:19.655660 10142 net.cpp:380] Convolution10 -> Convolution10
I1005 20:35:19.663058 10142 net.cpp:122] Setting up Convolution10
I1005 20:35:19.663069 10142 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 20:35:19.663081 10142 net.cpp:137] Memory required for data: 256838800
I1005 20:35:19.663105 10142 layer_factory.hpp:77] Creating layer BatchNorm10
I1005 20:35:19.663111 10142 net.cpp:84] Creating Layer BatchNorm10
I1005 20:35:19.663115 10142 net.cpp:406] BatchNorm10 <- Convolution10
I1005 20:35:19.663120 10142 net.cpp:367] BatchNorm10 -> Convolution10 (in-place)
I1005 20:35:19.663285 10142 net.cpp:122] Setting up BatchNorm10
I1005 20:35:19.663290 10142 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 20:35:19.663311 10142 net.cpp:137] Memory required for data: 261856400
I1005 20:35:19.663327 10142 layer_factory.hpp:77] Creating layer Scale10
I1005 20:35:19.663332 10142 net.cpp:84] Creating Layer Scale10
I1005 20:35:19.663336 10142 net.cpp:406] Scale10 <- Convolution10
I1005 20:35:19.663339 10142 net.cpp:367] Scale10 -> Convolution10 (in-place)
I1005 20:35:19.663378 10142 layer_factory.hpp:77] Creating layer Scale10
I1005 20:35:19.663503 10142 net.cpp:122] Setting up Scale10
I1005 20:35:19.663508 10142 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 20:35:19.663520 10142 net.cpp:137] Memory required for data: 266874000
I1005 20:35:19.663524 10142 layer_factory.hpp:77] Creating layer ReLU10
I1005 20:35:19.663528 10142 net.cpp:84] Creating Layer ReLU10
I1005 20:35:19.663530 10142 net.cpp:406] ReLU10 <- Convolution10
I1005 20:35:19.663544 10142 net.cpp:367] ReLU10 -> Convolution10 (in-place)
I1005 20:35:19.665191 10142 net.cpp:122] Setting up ReLU10
I1005 20:35:19.665199 10142 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 20:35:19.665210 10142 net.cpp:137] Memory required for data: 271891600
I1005 20:35:19.665213 10142 layer_factory.hpp:77] Creating layer Convolution11
I1005 20:35:19.665220 10142 net.cpp:84] Creating Layer Convolution11
I1005 20:35:19.665232 10142 net.cpp:406] Convolution11 <- Convolution10
I1005 20:35:19.665237 10142 net.cpp:380] Convolution11 -> Convolution11
I1005 20:35:19.671775 10142 net.cpp:122] Setting up Convolution11
I1005 20:35:19.671784 10142 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 20:35:19.671797 10142 net.cpp:137] Memory required for data: 276909200
I1005 20:35:19.671802 10142 layer_factory.hpp:77] Creating layer BatchNorm11
I1005 20:35:19.671808 10142 net.cpp:84] Creating Layer BatchNorm11
I1005 20:35:19.671820 10142 net.cpp:406] BatchNorm11 <- Convolution11
I1005 20:35:19.671824 10142 net.cpp:367] BatchNorm11 -> Convolution11 (in-place)
I1005 20:35:19.671972 10142 net.cpp:122] Setting up BatchNorm11
I1005 20:35:19.671977 10142 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 20:35:19.671989 10142 net.cpp:137] Memory required for data: 281926800
I1005 20:35:19.671994 10142 layer_factory.hpp:77] Creating layer Scale11
I1005 20:35:19.672009 10142 net.cpp:84] Creating Layer Scale11
I1005 20:35:19.672013 10142 net.cpp:406] Scale11 <- Convolution11
I1005 20:35:19.672016 10142 net.cpp:367] Scale11 -> Convolution11 (in-place)
I1005 20:35:19.672051 10142 layer_factory.hpp:77] Creating layer Scale11
I1005 20:35:19.672175 10142 net.cpp:122] Setting up Scale11
I1005 20:35:19.672180 10142 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 20:35:19.672193 10142 net.cpp:137] Memory required for data: 286944400
I1005 20:35:19.672196 10142 layer_factory.hpp:77] Creating layer Eltwise5
I1005 20:35:19.672211 10142 net.cpp:84] Creating Layer Eltwise5
I1005 20:35:19.672215 10142 net.cpp:406] Eltwise5 <- Eltwise4_ReLU9_0_split_1
I1005 20:35:19.672219 10142 net.cpp:406] Eltwise5 <- Convolution11
I1005 20:35:19.672221 10142 net.cpp:380] Eltwise5 -> Eltwise5
I1005 20:35:19.672247 10142 net.cpp:122] Setting up Eltwise5
I1005 20:35:19.672251 10142 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 20:35:19.672253 10142 net.cpp:137] Memory required for data: 291962000
I1005 20:35:19.672255 10142 layer_factory.hpp:77] Creating layer ReLU11
I1005 20:35:19.672268 10142 net.cpp:84] Creating Layer ReLU11
I1005 20:35:19.672271 10142 net.cpp:406] ReLU11 <- Eltwise5
I1005 20:35:19.672283 10142 net.cpp:367] ReLU11 -> Eltwise5 (in-place)
I1005 20:35:19.673398 10142 net.cpp:122] Setting up ReLU11
I1005 20:35:19.673405 10142 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 20:35:19.673408 10142 net.cpp:137] Memory required for data: 296979600
I1005 20:35:19.673410 10142 layer_factory.hpp:77] Creating layer Eltwise5_ReLU11_0_split
I1005 20:35:19.673414 10142 net.cpp:84] Creating Layer Eltwise5_ReLU11_0_split
I1005 20:35:19.673418 10142 net.cpp:406] Eltwise5_ReLU11_0_split <- Eltwise5
I1005 20:35:19.673430 10142 net.cpp:380] Eltwise5_ReLU11_0_split -> Eltwise5_ReLU11_0_split_0
I1005 20:35:19.673442 10142 net.cpp:380] Eltwise5_ReLU11_0_split -> Eltwise5_ReLU11_0_split_1
I1005 20:35:19.673480 10142 net.cpp:122] Setting up Eltwise5_ReLU11_0_split
I1005 20:35:19.673485 10142 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 20:35:19.673488 10142 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1005 20:35:19.673501 10142 net.cpp:137] Memory required for data: 307014800
I1005 20:35:19.673504 10142 layer_factory.hpp:77] Creating layer Convolution12
I1005 20:35:19.673511 10142 net.cpp:84] Creating Layer Convolution12
I1005 20:35:19.673514 10142 net.cpp:406] Convolution12 <- Eltwise5_ReLU11_0_split_0
I1005 20:35:19.673519 10142 net.cpp:380] Convolution12 -> Convolution12
I1005 20:35:19.674732 10142 net.cpp:122] Setting up Convolution12
I1005 20:35:19.674741 10142 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 20:35:19.674744 10142 net.cpp:137] Memory required for data: 309523600
I1005 20:35:19.674759 10142 layer_factory.hpp:77] Creating layer BatchNorm12
I1005 20:35:19.674764 10142 net.cpp:84] Creating Layer BatchNorm12
I1005 20:35:19.674768 10142 net.cpp:406] BatchNorm12 <- Convolution12
I1005 20:35:19.674772 10142 net.cpp:367] BatchNorm12 -> Convolution12 (in-place)
I1005 20:35:19.674922 10142 net.cpp:122] Setting up BatchNorm12
I1005 20:35:19.674927 10142 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 20:35:19.674929 10142 net.cpp:137] Memory required for data: 312032400
I1005 20:35:19.674944 10142 layer_factory.hpp:77] Creating layer Scale12
I1005 20:35:19.674949 10142 net.cpp:84] Creating Layer Scale12
I1005 20:35:19.674952 10142 net.cpp:406] Scale12 <- Convolution12
I1005 20:35:19.674957 10142 net.cpp:367] Scale12 -> Convolution12 (in-place)
I1005 20:35:19.674991 10142 layer_factory.hpp:77] Creating layer Scale12
I1005 20:35:19.675088 10142 net.cpp:122] Setting up Scale12
I1005 20:35:19.675093 10142 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 20:35:19.675096 10142 net.cpp:137] Memory required for data: 314541200
I1005 20:35:19.675109 10142 layer_factory.hpp:77] Creating layer Convolution13
I1005 20:35:19.675118 10142 net.cpp:84] Creating Layer Convolution13
I1005 20:35:19.675122 10142 net.cpp:406] Convolution13 <- Eltwise5_ReLU11_0_split_1
I1005 20:35:19.675127 10142 net.cpp:380] Convolution13 -> Convolution13
I1005 20:35:19.679438 10142 net.cpp:122] Setting up Convolution13
I1005 20:35:19.679450 10142 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 20:35:19.679452 10142 net.cpp:137] Memory required for data: 317050000
I1005 20:35:19.679467 10142 layer_factory.hpp:77] Creating layer BatchNorm13
I1005 20:35:19.679474 10142 net.cpp:84] Creating Layer BatchNorm13
I1005 20:35:19.679477 10142 net.cpp:406] BatchNorm13 <- Convolution13
I1005 20:35:19.679481 10142 net.cpp:367] BatchNorm13 -> Convolution13 (in-place)
I1005 20:35:19.679626 10142 net.cpp:122] Setting up BatchNorm13
I1005 20:35:19.679632 10142 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 20:35:19.679635 10142 net.cpp:137] Memory required for data: 319558800
I1005 20:35:19.679649 10142 layer_factory.hpp:77] Creating layer Scale13
I1005 20:35:19.679656 10142 net.cpp:84] Creating Layer Scale13
I1005 20:35:19.679658 10142 net.cpp:406] Scale13 <- Convolution13
I1005 20:35:19.679672 10142 net.cpp:367] Scale13 -> Convolution13 (in-place)
I1005 20:35:19.679719 10142 layer_factory.hpp:77] Creating layer Scale13
I1005 20:35:19.679816 10142 net.cpp:122] Setting up Scale13
I1005 20:35:19.679821 10142 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 20:35:19.679823 10142 net.cpp:137] Memory required for data: 322067600
I1005 20:35:19.679836 10142 layer_factory.hpp:77] Creating layer ReLU12
I1005 20:35:19.679842 10142 net.cpp:84] Creating Layer ReLU12
I1005 20:35:19.679846 10142 net.cpp:406] ReLU12 <- Convolution13
I1005 20:35:19.679848 10142 net.cpp:367] ReLU12 -> Convolution13 (in-place)
I1005 20:35:19.681239 10142 net.cpp:122] Setting up ReLU12
I1005 20:35:19.681247 10142 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 20:35:19.681251 10142 net.cpp:137] Memory required for data: 324576400
I1005 20:35:19.681253 10142 layer_factory.hpp:77] Creating layer Convolution14
I1005 20:35:19.681269 10142 net.cpp:84] Creating Layer Convolution14
I1005 20:35:19.681273 10142 net.cpp:406] Convolution14 <- Convolution13
I1005 20:35:19.681277 10142 net.cpp:380] Convolution14 -> Convolution14
I1005 20:35:19.687106 10142 net.cpp:122] Setting up Convolution14
I1005 20:35:19.687116 10142 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 20:35:19.687119 10142 net.cpp:137] Memory required for data: 327085200
I1005 20:35:19.687134 10142 layer_factory.hpp:77] Creating layer BatchNorm14
I1005 20:35:19.687144 10142 net.cpp:84] Creating Layer BatchNorm14
I1005 20:35:19.687149 10142 net.cpp:406] BatchNorm14 <- Convolution14
I1005 20:35:19.687151 10142 net.cpp:367] BatchNorm14 -> Convolution14 (in-place)
I1005 20:35:19.687294 10142 net.cpp:122] Setting up BatchNorm14
I1005 20:35:19.687299 10142 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 20:35:19.687301 10142 net.cpp:137] Memory required for data: 329594000
I1005 20:35:19.687316 10142 layer_factory.hpp:77] Creating layer Scale14
I1005 20:35:19.687322 10142 net.cpp:84] Creating Layer Scale14
I1005 20:35:19.687325 10142 net.cpp:406] Scale14 <- Convolution14
I1005 20:35:19.687328 10142 net.cpp:367] Scale14 -> Convolution14 (in-place)
I1005 20:35:19.687366 10142 layer_factory.hpp:77] Creating layer Scale14
I1005 20:35:19.687461 10142 net.cpp:122] Setting up Scale14
I1005 20:35:19.687466 10142 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 20:35:19.687469 10142 net.cpp:137] Memory required for data: 332102800
I1005 20:35:19.687484 10142 layer_factory.hpp:77] Creating layer Eltwise6
I1005 20:35:19.687489 10142 net.cpp:84] Creating Layer Eltwise6
I1005 20:35:19.687492 10142 net.cpp:406] Eltwise6 <- Convolution12
I1005 20:35:19.687495 10142 net.cpp:406] Eltwise6 <- Convolution14
I1005 20:35:19.687500 10142 net.cpp:380] Eltwise6 -> Eltwise6
I1005 20:35:19.687516 10142 net.cpp:122] Setting up Eltwise6
I1005 20:35:19.687530 10142 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 20:35:19.687532 10142 net.cpp:137] Memory required for data: 334611600
I1005 20:35:19.687535 10142 layer_factory.hpp:77] Creating layer ReLU13
I1005 20:35:19.687549 10142 net.cpp:84] Creating Layer ReLU13
I1005 20:35:19.687552 10142 net.cpp:406] ReLU13 <- Eltwise6
I1005 20:35:19.687556 10142 net.cpp:367] ReLU13 -> Eltwise6 (in-place)
I1005 20:35:19.687705 10142 net.cpp:122] Setting up ReLU13
I1005 20:35:19.687711 10142 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 20:35:19.687714 10142 net.cpp:137] Memory required for data: 337120400
I1005 20:35:19.687716 10142 layer_factory.hpp:77] Creating layer Eltwise6_ReLU13_0_split
I1005 20:35:19.687721 10142 net.cpp:84] Creating Layer Eltwise6_ReLU13_0_split
I1005 20:35:19.687724 10142 net.cpp:406] Eltwise6_ReLU13_0_split <- Eltwise6
I1005 20:35:19.687727 10142 net.cpp:380] Eltwise6_ReLU13_0_split -> Eltwise6_ReLU13_0_split_0
I1005 20:35:19.687732 10142 net.cpp:380] Eltwise6_ReLU13_0_split -> Eltwise6_ReLU13_0_split_1
I1005 20:35:19.687759 10142 net.cpp:122] Setting up Eltwise6_ReLU13_0_split
I1005 20:35:19.687764 10142 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 20:35:19.687767 10142 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 20:35:19.687769 10142 net.cpp:137] Memory required for data: 342138000
I1005 20:35:19.687772 10142 layer_factory.hpp:77] Creating layer Convolution15
I1005 20:35:19.687778 10142 net.cpp:84] Creating Layer Convolution15
I1005 20:35:19.687782 10142 net.cpp:406] Convolution15 <- Eltwise6_ReLU13_0_split_0
I1005 20:35:19.687786 10142 net.cpp:380] Convolution15 -> Convolution15
I1005 20:35:19.692587 10142 net.cpp:122] Setting up Convolution15
I1005 20:35:19.692600 10142 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 20:35:19.692602 10142 net.cpp:137] Memory required for data: 344646800
I1005 20:35:19.692607 10142 layer_factory.hpp:77] Creating layer BatchNorm15
I1005 20:35:19.692613 10142 net.cpp:84] Creating Layer BatchNorm15
I1005 20:35:19.692616 10142 net.cpp:406] BatchNorm15 <- Convolution15
I1005 20:35:19.692620 10142 net.cpp:367] BatchNorm15 -> Convolution15 (in-place)
I1005 20:35:19.692765 10142 net.cpp:122] Setting up BatchNorm15
I1005 20:35:19.692771 10142 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 20:35:19.692775 10142 net.cpp:137] Memory required for data: 347155600
I1005 20:35:19.692780 10142 layer_factory.hpp:77] Creating layer Scale15
I1005 20:35:19.692785 10142 net.cpp:84] Creating Layer Scale15
I1005 20:35:19.692788 10142 net.cpp:406] Scale15 <- Convolution15
I1005 20:35:19.692792 10142 net.cpp:367] Scale15 -> Convolution15 (in-place)
I1005 20:35:19.692822 10142 layer_factory.hpp:77] Creating layer Scale15
I1005 20:35:19.692900 10142 net.cpp:122] Setting up Scale15
I1005 20:35:19.692906 10142 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 20:35:19.692909 10142 net.cpp:137] Memory required for data: 349664400
I1005 20:35:19.692914 10142 layer_factory.hpp:77] Creating layer ReLU14
I1005 20:35:19.692919 10142 net.cpp:84] Creating Layer ReLU14
I1005 20:35:19.692921 10142 net.cpp:406] ReLU14 <- Convolution15
I1005 20:35:19.692924 10142 net.cpp:367] ReLU14 -> Convolution15 (in-place)
I1005 20:35:19.694732 10142 net.cpp:122] Setting up ReLU14
I1005 20:35:19.694739 10142 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 20:35:19.694742 10142 net.cpp:137] Memory required for data: 352173200
I1005 20:35:19.694744 10142 layer_factory.hpp:77] Creating layer Convolution16
I1005 20:35:19.694751 10142 net.cpp:84] Creating Layer Convolution16
I1005 20:35:19.694756 10142 net.cpp:406] Convolution16 <- Convolution15
I1005 20:35:19.694761 10142 net.cpp:380] Convolution16 -> Convolution16
I1005 20:35:19.701356 10142 net.cpp:122] Setting up Convolution16
I1005 20:35:19.701378 10142 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 20:35:19.701381 10142 net.cpp:137] Memory required for data: 354682000
I1005 20:35:19.701386 10142 layer_factory.hpp:77] Creating layer BatchNorm16
I1005 20:35:19.701390 10142 net.cpp:84] Creating Layer BatchNorm16
I1005 20:35:19.701393 10142 net.cpp:406] BatchNorm16 <- Convolution16
I1005 20:35:19.701407 10142 net.cpp:367] BatchNorm16 -> Convolution16 (in-place)
I1005 20:35:19.701550 10142 net.cpp:122] Setting up BatchNorm16
I1005 20:35:19.701555 10142 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 20:35:19.701557 10142 net.cpp:137] Memory required for data: 357190800
I1005 20:35:19.701561 10142 layer_factory.hpp:77] Creating layer Scale16
I1005 20:35:19.701566 10142 net.cpp:84] Creating Layer Scale16
I1005 20:35:19.701570 10142 net.cpp:406] Scale16 <- Convolution16
I1005 20:35:19.701573 10142 net.cpp:367] Scale16 -> Convolution16 (in-place)
I1005 20:35:19.701601 10142 layer_factory.hpp:77] Creating layer Scale16
I1005 20:35:19.701678 10142 net.cpp:122] Setting up Scale16
I1005 20:35:19.701683 10142 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 20:35:19.701684 10142 net.cpp:137] Memory required for data: 359699600
I1005 20:35:19.701689 10142 layer_factory.hpp:77] Creating layer Eltwise7
I1005 20:35:19.701694 10142 net.cpp:84] Creating Layer Eltwise7
I1005 20:35:19.701696 10142 net.cpp:406] Eltwise7 <- Eltwise6_ReLU13_0_split_1
I1005 20:35:19.701699 10142 net.cpp:406] Eltwise7 <- Convolution16
I1005 20:35:19.701704 10142 net.cpp:380] Eltwise7 -> Eltwise7
I1005 20:35:19.701720 10142 net.cpp:122] Setting up Eltwise7
I1005 20:35:19.701725 10142 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 20:35:19.701727 10142 net.cpp:137] Memory required for data: 362208400
I1005 20:35:19.701730 10142 layer_factory.hpp:77] Creating layer ReLU15
I1005 20:35:19.701733 10142 net.cpp:84] Creating Layer ReLU15
I1005 20:35:19.701735 10142 net.cpp:406] ReLU15 <- Eltwise7
I1005 20:35:19.701738 10142 net.cpp:367] ReLU15 -> Eltwise7 (in-place)
I1005 20:35:19.703776 10142 net.cpp:122] Setting up ReLU15
I1005 20:35:19.703785 10142 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 20:35:19.703788 10142 net.cpp:137] Memory required for data: 364717200
I1005 20:35:19.703790 10142 layer_factory.hpp:77] Creating layer Eltwise7_ReLU15_0_split
I1005 20:35:19.703795 10142 net.cpp:84] Creating Layer Eltwise7_ReLU15_0_split
I1005 20:35:19.703799 10142 net.cpp:406] Eltwise7_ReLU15_0_split <- Eltwise7
I1005 20:35:19.703809 10142 net.cpp:380] Eltwise7_ReLU15_0_split -> Eltwise7_ReLU15_0_split_0
I1005 20:35:19.703816 10142 net.cpp:380] Eltwise7_ReLU15_0_split -> Eltwise7_ReLU15_0_split_1
I1005 20:35:19.703846 10142 net.cpp:122] Setting up Eltwise7_ReLU15_0_split
I1005 20:35:19.703851 10142 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 20:35:19.703855 10142 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 20:35:19.703856 10142 net.cpp:137] Memory required for data: 369734800
I1005 20:35:19.703860 10142 layer_factory.hpp:77] Creating layer Convolution17
I1005 20:35:19.703866 10142 net.cpp:84] Creating Layer Convolution17
I1005 20:35:19.703869 10142 net.cpp:406] Convolution17 <- Eltwise7_ReLU15_0_split_0
I1005 20:35:19.703873 10142 net.cpp:380] Convolution17 -> Convolution17
I1005 20:35:19.710141 10142 net.cpp:122] Setting up Convolution17
I1005 20:35:19.710150 10142 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 20:35:19.710162 10142 net.cpp:137] Memory required for data: 372243600
I1005 20:35:19.710167 10142 layer_factory.hpp:77] Creating layer BatchNorm17
I1005 20:35:19.710173 10142 net.cpp:84] Creating Layer BatchNorm17
I1005 20:35:19.710175 10142 net.cpp:406] BatchNorm17 <- Convolution17
I1005 20:35:19.710180 10142 net.cpp:367] BatchNorm17 -> Convolution17 (in-place)
I1005 20:35:19.710310 10142 net.cpp:122] Setting up BatchNorm17
I1005 20:35:19.710315 10142 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 20:35:19.710317 10142 net.cpp:137] Memory required for data: 374752400
I1005 20:35:19.710322 10142 layer_factory.hpp:77] Creating layer Scale17
I1005 20:35:19.710327 10142 net.cpp:84] Creating Layer Scale17
I1005 20:35:19.710330 10142 net.cpp:406] Scale17 <- Convolution17
I1005 20:35:19.710333 10142 net.cpp:367] Scale17 -> Convolution17 (in-place)
I1005 20:35:19.710381 10142 layer_factory.hpp:77] Creating layer Scale17
I1005 20:35:19.710477 10142 net.cpp:122] Setting up Scale17
I1005 20:35:19.710484 10142 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 20:35:19.710495 10142 net.cpp:137] Memory required for data: 377261200
I1005 20:35:19.710500 10142 layer_factory.hpp:77] Creating layer ReLU16
I1005 20:35:19.710505 10142 net.cpp:84] Creating Layer ReLU16
I1005 20:35:19.710508 10142 net.cpp:406] ReLU16 <- Convolution17
I1005 20:35:19.710511 10142 net.cpp:367] ReLU16 -> Convolution17 (in-place)
I1005 20:35:19.712296 10142 net.cpp:122] Setting up ReLU16
I1005 20:35:19.712306 10142 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 20:35:19.712318 10142 net.cpp:137] Memory required for data: 379770000
I1005 20:35:19.712321 10142 layer_factory.hpp:77] Creating layer Convolution18
I1005 20:35:19.712329 10142 net.cpp:84] Creating Layer Convolution18
I1005 20:35:19.712333 10142 net.cpp:406] Convolution18 <- Convolution17
I1005 20:35:19.712337 10142 net.cpp:380] Convolution18 -> Convolution18
I1005 20:35:19.719583 10142 net.cpp:122] Setting up Convolution18
I1005 20:35:19.719604 10142 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 20:35:19.719617 10142 net.cpp:137] Memory required for data: 382278800
I1005 20:35:19.719622 10142 layer_factory.hpp:77] Creating layer BatchNorm18
I1005 20:35:19.719629 10142 net.cpp:84] Creating Layer BatchNorm18
I1005 20:35:19.719630 10142 net.cpp:406] BatchNorm18 <- Convolution18
I1005 20:35:19.719645 10142 net.cpp:367] BatchNorm18 -> Convolution18 (in-place)
I1005 20:35:19.719825 10142 net.cpp:122] Setting up BatchNorm18
I1005 20:35:19.719830 10142 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 20:35:19.719842 10142 net.cpp:137] Memory required for data: 384787600
I1005 20:35:19.719847 10142 layer_factory.hpp:77] Creating layer Scale18
I1005 20:35:19.719852 10142 net.cpp:84] Creating Layer Scale18
I1005 20:35:19.719856 10142 net.cpp:406] Scale18 <- Convolution18
I1005 20:35:19.719858 10142 net.cpp:367] Scale18 -> Convolution18 (in-place)
I1005 20:35:19.719897 10142 layer_factory.hpp:77] Creating layer Scale18
I1005 20:35:19.719992 10142 net.cpp:122] Setting up Scale18
I1005 20:35:19.719997 10142 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 20:35:19.720017 10142 net.cpp:137] Memory required for data: 387296400
I1005 20:35:19.720022 10142 layer_factory.hpp:77] Creating layer Eltwise8
I1005 20:35:19.720027 10142 net.cpp:84] Creating Layer Eltwise8
I1005 20:35:19.720031 10142 net.cpp:406] Eltwise8 <- Eltwise7_ReLU15_0_split_1
I1005 20:35:19.720034 10142 net.cpp:406] Eltwise8 <- Convolution18
I1005 20:35:19.720039 10142 net.cpp:380] Eltwise8 -> Eltwise8
I1005 20:35:19.720055 10142 net.cpp:122] Setting up Eltwise8
I1005 20:35:19.720060 10142 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 20:35:19.720062 10142 net.cpp:137] Memory required for data: 389805200
I1005 20:35:19.720064 10142 layer_factory.hpp:77] Creating layer ReLU17
I1005 20:35:19.720069 10142 net.cpp:84] Creating Layer ReLU17
I1005 20:35:19.720072 10142 net.cpp:406] ReLU17 <- Eltwise8
I1005 20:35:19.720075 10142 net.cpp:367] ReLU17 -> Eltwise8 (in-place)
I1005 20:35:19.721979 10142 net.cpp:122] Setting up ReLU17
I1005 20:35:19.721987 10142 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 20:35:19.721989 10142 net.cpp:137] Memory required for data: 392314000
I1005 20:35:19.721992 10142 layer_factory.hpp:77] Creating layer Eltwise8_ReLU17_0_split
I1005 20:35:19.721997 10142 net.cpp:84] Creating Layer Eltwise8_ReLU17_0_split
I1005 20:35:19.721999 10142 net.cpp:406] Eltwise8_ReLU17_0_split <- Eltwise8
I1005 20:35:19.722004 10142 net.cpp:380] Eltwise8_ReLU17_0_split -> Eltwise8_ReLU17_0_split_0
I1005 20:35:19.722009 10142 net.cpp:380] Eltwise8_ReLU17_0_split -> Eltwise8_ReLU17_0_split_1
I1005 20:35:19.722035 10142 net.cpp:122] Setting up Eltwise8_ReLU17_0_split
I1005 20:35:19.722039 10142 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 20:35:19.722043 10142 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 20:35:19.722044 10142 net.cpp:137] Memory required for data: 397331600
I1005 20:35:19.722046 10142 layer_factory.hpp:77] Creating layer Convolution19
I1005 20:35:19.722054 10142 net.cpp:84] Creating Layer Convolution19
I1005 20:35:19.722056 10142 net.cpp:406] Convolution19 <- Eltwise8_ReLU17_0_split_0
I1005 20:35:19.722061 10142 net.cpp:380] Convolution19 -> Convolution19
I1005 20:35:19.728358 10142 net.cpp:122] Setting up Convolution19
I1005 20:35:19.728368 10142 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 20:35:19.728370 10142 net.cpp:137] Memory required for data: 399840400
I1005 20:35:19.728375 10142 layer_factory.hpp:77] Creating layer BatchNorm19
I1005 20:35:19.728390 10142 net.cpp:84] Creating Layer BatchNorm19
I1005 20:35:19.728394 10142 net.cpp:406] BatchNorm19 <- Convolution19
I1005 20:35:19.728399 10142 net.cpp:367] BatchNorm19 -> Convolution19 (in-place)
I1005 20:35:19.728554 10142 net.cpp:122] Setting up BatchNorm19
I1005 20:35:19.728559 10142 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 20:35:19.728571 10142 net.cpp:137] Memory required for data: 402349200
I1005 20:35:19.728598 10142 layer_factory.hpp:77] Creating layer Scale19
I1005 20:35:19.728605 10142 net.cpp:84] Creating Layer Scale19
I1005 20:35:19.728607 10142 net.cpp:406] Scale19 <- Convolution19
I1005 20:35:19.728610 10142 net.cpp:367] Scale19 -> Convolution19 (in-place)
I1005 20:35:19.728683 10142 layer_factory.hpp:77] Creating layer Scale19
I1005 20:35:19.728801 10142 net.cpp:122] Setting up Scale19
I1005 20:35:19.728806 10142 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 20:35:19.728818 10142 net.cpp:137] Memory required for data: 404858000
I1005 20:35:19.728821 10142 layer_factory.hpp:77] Creating layer ReLU18
I1005 20:35:19.728826 10142 net.cpp:84] Creating Layer ReLU18
I1005 20:35:19.728829 10142 net.cpp:406] ReLU18 <- Convolution19
I1005 20:35:19.728842 10142 net.cpp:367] ReLU18 -> Convolution19 (in-place)
I1005 20:35:19.729001 10142 net.cpp:122] Setting up ReLU18
I1005 20:35:19.729008 10142 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 20:35:19.729020 10142 net.cpp:137] Memory required for data: 407366800
I1005 20:35:19.729023 10142 layer_factory.hpp:77] Creating layer Convolution20
I1005 20:35:19.729030 10142 net.cpp:84] Creating Layer Convolution20
I1005 20:35:19.729039 10142 net.cpp:406] Convolution20 <- Convolution19
I1005 20:35:19.729044 10142 net.cpp:380] Convolution20 -> Convolution20
I1005 20:35:19.733741 10142 net.cpp:122] Setting up Convolution20
I1005 20:35:19.733750 10142 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 20:35:19.733753 10142 net.cpp:137] Memory required for data: 409875600
I1005 20:35:19.733758 10142 layer_factory.hpp:77] Creating layer BatchNorm20
I1005 20:35:19.733765 10142 net.cpp:84] Creating Layer BatchNorm20
I1005 20:35:19.733768 10142 net.cpp:406] BatchNorm20 <- Convolution20
I1005 20:35:19.733773 10142 net.cpp:367] BatchNorm20 -> Convolution20 (in-place)
I1005 20:35:19.733913 10142 net.cpp:122] Setting up BatchNorm20
I1005 20:35:19.733918 10142 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 20:35:19.733922 10142 net.cpp:137] Memory required for data: 412384400
I1005 20:35:19.733927 10142 layer_factory.hpp:77] Creating layer Scale20
I1005 20:35:19.733932 10142 net.cpp:84] Creating Layer Scale20
I1005 20:35:19.733934 10142 net.cpp:406] Scale20 <- Convolution20
I1005 20:35:19.733938 10142 net.cpp:367] Scale20 -> Convolution20 (in-place)
I1005 20:35:19.733965 10142 layer_factory.hpp:77] Creating layer Scale20
I1005 20:35:19.734046 10142 net.cpp:122] Setting up Scale20
I1005 20:35:19.734052 10142 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 20:35:19.734055 10142 net.cpp:137] Memory required for data: 414893200
I1005 20:35:19.734058 10142 layer_factory.hpp:77] Creating layer Eltwise9
I1005 20:35:19.734064 10142 net.cpp:84] Creating Layer Eltwise9
I1005 20:35:19.734067 10142 net.cpp:406] Eltwise9 <- Eltwise8_ReLU17_0_split_1
I1005 20:35:19.734071 10142 net.cpp:406] Eltwise9 <- Convolution20
I1005 20:35:19.734074 10142 net.cpp:380] Eltwise9 -> Eltwise9
I1005 20:35:19.734091 10142 net.cpp:122] Setting up Eltwise9
I1005 20:35:19.734097 10142 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 20:35:19.734098 10142 net.cpp:137] Memory required for data: 417402000
I1005 20:35:19.734100 10142 layer_factory.hpp:77] Creating layer ReLU19
I1005 20:35:19.734105 10142 net.cpp:84] Creating Layer ReLU19
I1005 20:35:19.734108 10142 net.cpp:406] ReLU19 <- Eltwise9
I1005 20:35:19.734112 10142 net.cpp:367] ReLU19 -> Eltwise9 (in-place)
I1005 20:35:19.735838 10142 net.cpp:122] Setting up ReLU19
I1005 20:35:19.735846 10142 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 20:35:19.735847 10142 net.cpp:137] Memory required for data: 419910800
I1005 20:35:19.735851 10142 layer_factory.hpp:77] Creating layer Eltwise9_ReLU19_0_split
I1005 20:35:19.735855 10142 net.cpp:84] Creating Layer Eltwise9_ReLU19_0_split
I1005 20:35:19.735858 10142 net.cpp:406] Eltwise9_ReLU19_0_split <- Eltwise9
I1005 20:35:19.735862 10142 net.cpp:380] Eltwise9_ReLU19_0_split -> Eltwise9_ReLU19_0_split_0
I1005 20:35:19.735867 10142 net.cpp:380] Eltwise9_ReLU19_0_split -> Eltwise9_ReLU19_0_split_1
I1005 20:35:19.735894 10142 net.cpp:122] Setting up Eltwise9_ReLU19_0_split
I1005 20:35:19.735899 10142 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 20:35:19.735903 10142 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 20:35:19.735904 10142 net.cpp:137] Memory required for data: 424928400
I1005 20:35:19.735906 10142 layer_factory.hpp:77] Creating layer Convolution21
I1005 20:35:19.735913 10142 net.cpp:84] Creating Layer Convolution21
I1005 20:35:19.735916 10142 net.cpp:406] Convolution21 <- Eltwise9_ReLU19_0_split_0
I1005 20:35:19.735921 10142 net.cpp:380] Convolution21 -> Convolution21
I1005 20:35:19.741757 10142 net.cpp:122] Setting up Convolution21
I1005 20:35:19.741767 10142 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 20:35:19.741780 10142 net.cpp:137] Memory required for data: 427437200
I1005 20:35:19.741785 10142 layer_factory.hpp:77] Creating layer BatchNorm21
I1005 20:35:19.741789 10142 net.cpp:84] Creating Layer BatchNorm21
I1005 20:35:19.741792 10142 net.cpp:406] BatchNorm21 <- Convolution21
I1005 20:35:19.741806 10142 net.cpp:367] BatchNorm21 -> Convolution21 (in-place)
I1005 20:35:19.741955 10142 net.cpp:122] Setting up BatchNorm21
I1005 20:35:19.741961 10142 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 20:35:19.741979 10142 net.cpp:137] Memory required for data: 429946000
I1005 20:35:19.741986 10142 layer_factory.hpp:77] Creating layer Scale21
I1005 20:35:19.741991 10142 net.cpp:84] Creating Layer Scale21
I1005 20:35:19.741993 10142 net.cpp:406] Scale21 <- Convolution21
I1005 20:35:19.741997 10142 net.cpp:367] Scale21 -> Convolution21 (in-place)
I1005 20:35:19.742028 10142 layer_factory.hpp:77] Creating layer Scale21
I1005 20:35:19.742107 10142 net.cpp:122] Setting up Scale21
I1005 20:35:19.742115 10142 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 20:35:19.742116 10142 net.cpp:137] Memory required for data: 432454800
I1005 20:35:19.742121 10142 layer_factory.hpp:77] Creating layer ReLU20
I1005 20:35:19.742125 10142 net.cpp:84] Creating Layer ReLU20
I1005 20:35:19.742127 10142 net.cpp:406] ReLU20 <- Convolution21
I1005 20:35:19.742130 10142 net.cpp:367] ReLU20 -> Convolution21 (in-place)
I1005 20:35:19.742252 10142 net.cpp:122] Setting up ReLU20
I1005 20:35:19.742260 10142 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 20:35:19.742264 10142 net.cpp:137] Memory required for data: 434963600
I1005 20:35:19.742265 10142 layer_factory.hpp:77] Creating layer Convolution22
I1005 20:35:19.742272 10142 net.cpp:84] Creating Layer Convolution22
I1005 20:35:19.742275 10142 net.cpp:406] Convolution22 <- Convolution21
I1005 20:35:19.742280 10142 net.cpp:380] Convolution22 -> Convolution22
I1005 20:35:19.748569 10142 net.cpp:122] Setting up Convolution22
I1005 20:35:19.748580 10142 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 20:35:19.748584 10142 net.cpp:137] Memory required for data: 437472400
I1005 20:35:19.748598 10142 layer_factory.hpp:77] Creating layer BatchNorm22
I1005 20:35:19.748603 10142 net.cpp:84] Creating Layer BatchNorm22
I1005 20:35:19.748606 10142 net.cpp:406] BatchNorm22 <- Convolution22
I1005 20:35:19.748611 10142 net.cpp:367] BatchNorm22 -> Convolution22 (in-place)
I1005 20:35:19.748759 10142 net.cpp:122] Setting up BatchNorm22
I1005 20:35:19.748764 10142 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 20:35:19.748767 10142 net.cpp:137] Memory required for data: 439981200
I1005 20:35:19.748771 10142 layer_factory.hpp:77] Creating layer Scale22
I1005 20:35:19.748786 10142 net.cpp:84] Creating Layer Scale22
I1005 20:35:19.748790 10142 net.cpp:406] Scale22 <- Convolution22
I1005 20:35:19.748792 10142 net.cpp:367] Scale22 -> Convolution22 (in-place)
I1005 20:35:19.748829 10142 layer_factory.hpp:77] Creating layer Scale22
I1005 20:35:19.748929 10142 net.cpp:122] Setting up Scale22
I1005 20:35:19.748934 10142 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 20:35:19.748937 10142 net.cpp:137] Memory required for data: 442490000
I1005 20:35:19.748950 10142 layer_factory.hpp:77] Creating layer Eltwise10
I1005 20:35:19.748956 10142 net.cpp:84] Creating Layer Eltwise10
I1005 20:35:19.748960 10142 net.cpp:406] Eltwise10 <- Eltwise9_ReLU19_0_split_1
I1005 20:35:19.748962 10142 net.cpp:406] Eltwise10 <- Convolution22
I1005 20:35:19.748966 10142 net.cpp:380] Eltwise10 -> Eltwise10
I1005 20:35:19.748983 10142 net.cpp:122] Setting up Eltwise10
I1005 20:35:19.748988 10142 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 20:35:19.748991 10142 net.cpp:137] Memory required for data: 444998800
I1005 20:35:19.748992 10142 layer_factory.hpp:77] Creating layer ReLU21
I1005 20:35:19.748996 10142 net.cpp:84] Creating Layer ReLU21
I1005 20:35:19.748999 10142 net.cpp:406] ReLU21 <- Eltwise10
I1005 20:35:19.749002 10142 net.cpp:367] ReLU21 -> Eltwise10 (in-place)
I1005 20:35:19.751297 10142 net.cpp:122] Setting up ReLU21
I1005 20:35:19.751307 10142 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 20:35:19.751310 10142 net.cpp:137] Memory required for data: 447507600
I1005 20:35:19.751313 10142 layer_factory.hpp:77] Creating layer Eltwise10_ReLU21_0_split
I1005 20:35:19.751318 10142 net.cpp:84] Creating Layer Eltwise10_ReLU21_0_split
I1005 20:35:19.751322 10142 net.cpp:406] Eltwise10_ReLU21_0_split <- Eltwise10
I1005 20:35:19.751325 10142 net.cpp:380] Eltwise10_ReLU21_0_split -> Eltwise10_ReLU21_0_split_0
I1005 20:35:19.751340 10142 net.cpp:380] Eltwise10_ReLU21_0_split -> Eltwise10_ReLU21_0_split_1
I1005 20:35:19.751372 10142 net.cpp:122] Setting up Eltwise10_ReLU21_0_split
I1005 20:35:19.751377 10142 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 20:35:19.751380 10142 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1005 20:35:19.751382 10142 net.cpp:137] Memory required for data: 452525200
I1005 20:35:19.751385 10142 layer_factory.hpp:77] Creating layer Convolution23
I1005 20:35:19.751392 10142 net.cpp:84] Creating Layer Convolution23
I1005 20:35:19.751396 10142 net.cpp:406] Convolution23 <- Eltwise10_ReLU21_0_split_0
I1005 20:35:19.751401 10142 net.cpp:380] Convolution23 -> Convolution23
I1005 20:35:19.758240 10142 net.cpp:122] Setting up Convolution23
I1005 20:35:19.758249 10142 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 20:35:19.758261 10142 net.cpp:137] Memory required for data: 453779600
I1005 20:35:19.758266 10142 layer_factory.hpp:77] Creating layer BatchNorm23
I1005 20:35:19.758271 10142 net.cpp:84] Creating Layer BatchNorm23
I1005 20:35:19.758275 10142 net.cpp:406] BatchNorm23 <- Convolution23
I1005 20:35:19.758278 10142 net.cpp:367] BatchNorm23 -> Convolution23 (in-place)
I1005 20:35:19.758424 10142 net.cpp:122] Setting up BatchNorm23
I1005 20:35:19.758430 10142 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 20:35:19.758441 10142 net.cpp:137] Memory required for data: 455034000
I1005 20:35:19.758446 10142 layer_factory.hpp:77] Creating layer Scale23
I1005 20:35:19.758451 10142 net.cpp:84] Creating Layer Scale23
I1005 20:35:19.758455 10142 net.cpp:406] Scale23 <- Convolution23
I1005 20:35:19.758457 10142 net.cpp:367] Scale23 -> Convolution23 (in-place)
I1005 20:35:19.758496 10142 layer_factory.hpp:77] Creating layer Scale23
I1005 20:35:19.758599 10142 net.cpp:122] Setting up Scale23
I1005 20:35:19.758605 10142 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 20:35:19.758606 10142 net.cpp:137] Memory required for data: 456288400
I1005 20:35:19.758620 10142 layer_factory.hpp:77] Creating layer Convolution24
I1005 20:35:19.758628 10142 net.cpp:84] Creating Layer Convolution24
I1005 20:35:19.758631 10142 net.cpp:406] Convolution24 <- Eltwise10_ReLU21_0_split_1
I1005 20:35:19.758635 10142 net.cpp:380] Convolution24 -> Convolution24
I1005 20:35:19.764914 10142 net.cpp:122] Setting up Convolution24
I1005 20:35:19.764925 10142 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 20:35:19.764937 10142 net.cpp:137] Memory required for data: 457542800
I1005 20:35:19.764942 10142 layer_factory.hpp:77] Creating layer BatchNorm24
I1005 20:35:19.764948 10142 net.cpp:84] Creating Layer BatchNorm24
I1005 20:35:19.764951 10142 net.cpp:406] BatchNorm24 <- Convolution24
I1005 20:35:19.764956 10142 net.cpp:367] BatchNorm24 -> Convolution24 (in-place)
I1005 20:35:19.765102 10142 net.cpp:122] Setting up BatchNorm24
I1005 20:35:19.765107 10142 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 20:35:19.765110 10142 net.cpp:137] Memory required for data: 458797200
I1005 20:35:19.765125 10142 layer_factory.hpp:77] Creating layer Scale24
I1005 20:35:19.765130 10142 net.cpp:84] Creating Layer Scale24
I1005 20:35:19.765132 10142 net.cpp:406] Scale24 <- Convolution24
I1005 20:35:19.765136 10142 net.cpp:367] Scale24 -> Convolution24 (in-place)
I1005 20:35:19.765174 10142 layer_factory.hpp:77] Creating layer Scale24
I1005 20:35:19.765283 10142 net.cpp:122] Setting up Scale24
I1005 20:35:19.765288 10142 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 20:35:19.765290 10142 net.cpp:137] Memory required for data: 460051600
I1005 20:35:19.765295 10142 layer_factory.hpp:77] Creating layer ReLU22
I1005 20:35:19.765300 10142 net.cpp:84] Creating Layer ReLU22
I1005 20:35:19.765302 10142 net.cpp:406] ReLU22 <- Convolution24
I1005 20:35:19.765305 10142 net.cpp:367] ReLU22 -> Convolution24 (in-place)
I1005 20:35:19.767053 10142 net.cpp:122] Setting up ReLU22
I1005 20:35:19.767062 10142 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 20:35:19.767074 10142 net.cpp:137] Memory required for data: 461306000
I1005 20:35:19.767086 10142 layer_factory.hpp:77] Creating layer Convolution25
I1005 20:35:19.767097 10142 net.cpp:84] Creating Layer Convolution25
I1005 20:35:19.767101 10142 net.cpp:406] Convolution25 <- Convolution24
I1005 20:35:19.767107 10142 net.cpp:380] Convolution25 -> Convolution25
I1005 20:35:19.774005 10142 net.cpp:122] Setting up Convolution25
I1005 20:35:19.774015 10142 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 20:35:19.774029 10142 net.cpp:137] Memory required for data: 462560400
I1005 20:35:19.774034 10142 layer_factory.hpp:77] Creating layer BatchNorm25
I1005 20:35:19.774039 10142 net.cpp:84] Creating Layer BatchNorm25
I1005 20:35:19.774042 10142 net.cpp:406] BatchNorm25 <- Convolution25
I1005 20:35:19.774046 10142 net.cpp:367] BatchNorm25 -> Convolution25 (in-place)
I1005 20:35:19.774197 10142 net.cpp:122] Setting up BatchNorm25
I1005 20:35:19.774204 10142 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 20:35:19.774205 10142 net.cpp:137] Memory required for data: 463814800
I1005 20:35:19.774220 10142 layer_factory.hpp:77] Creating layer Scale25
I1005 20:35:19.774224 10142 net.cpp:84] Creating Layer Scale25
I1005 20:35:19.774227 10142 net.cpp:406] Scale25 <- Convolution25
I1005 20:35:19.774231 10142 net.cpp:367] Scale25 -> Convolution25 (in-place)
I1005 20:35:19.774268 10142 layer_factory.hpp:77] Creating layer Scale25
I1005 20:35:19.774379 10142 net.cpp:122] Setting up Scale25
I1005 20:35:19.774384 10142 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 20:35:19.774386 10142 net.cpp:137] Memory required for data: 465069200
I1005 20:35:19.774390 10142 layer_factory.hpp:77] Creating layer Eltwise11
I1005 20:35:19.774395 10142 net.cpp:84] Creating Layer Eltwise11
I1005 20:35:19.774399 10142 net.cpp:406] Eltwise11 <- Convolution23
I1005 20:35:19.774402 10142 net.cpp:406] Eltwise11 <- Convolution25
I1005 20:35:19.774407 10142 net.cpp:380] Eltwise11 -> Eltwise11
I1005 20:35:19.774425 10142 net.cpp:122] Setting up Eltwise11
I1005 20:35:19.774438 10142 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 20:35:19.774441 10142 net.cpp:137] Memory required for data: 466323600
I1005 20:35:19.774442 10142 layer_factory.hpp:77] Creating layer ReLU23
I1005 20:35:19.774457 10142 net.cpp:84] Creating Layer ReLU23
I1005 20:35:19.774461 10142 net.cpp:406] ReLU23 <- Eltwise11
I1005 20:35:19.774463 10142 net.cpp:367] ReLU23 -> Eltwise11 (in-place)
I1005 20:35:19.775811 10142 net.cpp:122] Setting up ReLU23
I1005 20:35:19.775820 10142 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 20:35:19.775831 10142 net.cpp:137] Memory required for data: 467578000
I1005 20:35:19.775835 10142 layer_factory.hpp:77] Creating layer Eltwise11_ReLU23_0_split
I1005 20:35:19.775840 10142 net.cpp:84] Creating Layer Eltwise11_ReLU23_0_split
I1005 20:35:19.775842 10142 net.cpp:406] Eltwise11_ReLU23_0_split <- Eltwise11
I1005 20:35:19.775846 10142 net.cpp:380] Eltwise11_ReLU23_0_split -> Eltwise11_ReLU23_0_split_0
I1005 20:35:19.775851 10142 net.cpp:380] Eltwise11_ReLU23_0_split -> Eltwise11_ReLU23_0_split_1
I1005 20:35:19.775888 10142 net.cpp:122] Setting up Eltwise11_ReLU23_0_split
I1005 20:35:19.775893 10142 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 20:35:19.775907 10142 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 20:35:19.775908 10142 net.cpp:137] Memory required for data: 470086800
I1005 20:35:19.775910 10142 layer_factory.hpp:77] Creating layer Convolution26
I1005 20:35:19.775918 10142 net.cpp:84] Creating Layer Convolution26
I1005 20:35:19.775919 10142 net.cpp:406] Convolution26 <- Eltwise11_ReLU23_0_split_0
I1005 20:35:19.775924 10142 net.cpp:380] Convolution26 -> Convolution26
I1005 20:35:19.782467 10142 net.cpp:122] Setting up Convolution26
I1005 20:35:19.782481 10142 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 20:35:19.782485 10142 net.cpp:137] Memory required for data: 471341200
I1005 20:35:19.782490 10142 layer_factory.hpp:77] Creating layer BatchNorm26
I1005 20:35:19.782495 10142 net.cpp:84] Creating Layer BatchNorm26
I1005 20:35:19.782498 10142 net.cpp:406] BatchNorm26 <- Convolution26
I1005 20:35:19.782513 10142 net.cpp:367] BatchNorm26 -> Convolution26 (in-place)
I1005 20:35:19.782712 10142 net.cpp:122] Setting up BatchNorm26
I1005 20:35:19.782719 10142 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 20:35:19.782722 10142 net.cpp:137] Memory required for data: 472595600
I1005 20:35:19.782732 10142 layer_factory.hpp:77] Creating layer Scale26
I1005 20:35:19.782749 10142 net.cpp:84] Creating Layer Scale26
I1005 20:35:19.782752 10142 net.cpp:406] Scale26 <- Convolution26
I1005 20:35:19.782755 10142 net.cpp:367] Scale26 -> Convolution26 (in-place)
I1005 20:35:19.782799 10142 layer_factory.hpp:77] Creating layer Scale26
I1005 20:35:19.782901 10142 net.cpp:122] Setting up Scale26
I1005 20:35:19.782905 10142 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 20:35:19.782907 10142 net.cpp:137] Memory required for data: 473850000
I1005 20:35:19.782920 10142 layer_factory.hpp:77] Creating layer ReLU24
I1005 20:35:19.782925 10142 net.cpp:84] Creating Layer ReLU24
I1005 20:35:19.782928 10142 net.cpp:406] ReLU24 <- Convolution26
I1005 20:35:19.782932 10142 net.cpp:367] ReLU24 -> Convolution26 (in-place)
I1005 20:35:19.783066 10142 net.cpp:122] Setting up ReLU24
I1005 20:35:19.783071 10142 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 20:35:19.783074 10142 net.cpp:137] Memory required for data: 475104400
I1005 20:35:19.783077 10142 layer_factory.hpp:77] Creating layer Convolution27
I1005 20:35:19.783093 10142 net.cpp:84] Creating Layer Convolution27
I1005 20:35:19.783097 10142 net.cpp:406] Convolution27 <- Convolution26
I1005 20:35:19.783102 10142 net.cpp:380] Convolution27 -> Convolution27
I1005 20:35:19.788564 10142 net.cpp:122] Setting up Convolution27
I1005 20:35:19.788574 10142 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 20:35:19.788578 10142 net.cpp:137] Memory required for data: 476358800
I1005 20:35:19.788594 10142 layer_factory.hpp:77] Creating layer BatchNorm27
I1005 20:35:19.788599 10142 net.cpp:84] Creating Layer BatchNorm27
I1005 20:35:19.788602 10142 net.cpp:406] BatchNorm27 <- Convolution27
I1005 20:35:19.788606 10142 net.cpp:367] BatchNorm27 -> Convolution27 (in-place)
I1005 20:35:19.788759 10142 net.cpp:122] Setting up BatchNorm27
I1005 20:35:19.788765 10142 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 20:35:19.788767 10142 net.cpp:137] Memory required for data: 477613200
I1005 20:35:19.788782 10142 layer_factory.hpp:77] Creating layer Scale27
I1005 20:35:19.788800 10142 net.cpp:84] Creating Layer Scale27
I1005 20:35:19.788802 10142 net.cpp:406] Scale27 <- Convolution27
I1005 20:35:19.788806 10142 net.cpp:367] Scale27 -> Convolution27 (in-place)
I1005 20:35:19.788857 10142 layer_factory.hpp:77] Creating layer Scale27
I1005 20:35:19.788969 10142 net.cpp:122] Setting up Scale27
I1005 20:35:19.788974 10142 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 20:35:19.788975 10142 net.cpp:137] Memory required for data: 478867600
I1005 20:35:19.788990 10142 layer_factory.hpp:77] Creating layer Eltwise12
I1005 20:35:19.788995 10142 net.cpp:84] Creating Layer Eltwise12
I1005 20:35:19.789000 10142 net.cpp:406] Eltwise12 <- Eltwise11_ReLU23_0_split_1
I1005 20:35:19.789003 10142 net.cpp:406] Eltwise12 <- Convolution27
I1005 20:35:19.789007 10142 net.cpp:380] Eltwise12 -> Eltwise12
I1005 20:35:19.789041 10142 net.cpp:122] Setting up Eltwise12
I1005 20:35:19.789047 10142 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 20:35:19.789049 10142 net.cpp:137] Memory required for data: 480122000
I1005 20:35:19.789052 10142 layer_factory.hpp:77] Creating layer ReLU25
I1005 20:35:19.789055 10142 net.cpp:84] Creating Layer ReLU25
I1005 20:35:19.789058 10142 net.cpp:406] ReLU25 <- Eltwise12
I1005 20:35:19.789062 10142 net.cpp:367] ReLU25 -> Eltwise12 (in-place)
I1005 20:35:19.790351 10142 net.cpp:122] Setting up ReLU25
I1005 20:35:19.790359 10142 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 20:35:19.790360 10142 net.cpp:137] Memory required for data: 481376400
I1005 20:35:19.790364 10142 layer_factory.hpp:77] Creating layer Eltwise12_ReLU25_0_split
I1005 20:35:19.790367 10142 net.cpp:84] Creating Layer Eltwise12_ReLU25_0_split
I1005 20:35:19.790379 10142 net.cpp:406] Eltwise12_ReLU25_0_split <- Eltwise12
I1005 20:35:19.790382 10142 net.cpp:380] Eltwise12_ReLU25_0_split -> Eltwise12_ReLU25_0_split_0
I1005 20:35:19.790387 10142 net.cpp:380] Eltwise12_ReLU25_0_split -> Eltwise12_ReLU25_0_split_1
I1005 20:35:19.790417 10142 net.cpp:122] Setting up Eltwise12_ReLU25_0_split
I1005 20:35:19.790422 10142 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 20:35:19.790426 10142 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 20:35:19.790428 10142 net.cpp:137] Memory required for data: 483885200
I1005 20:35:19.790431 10142 layer_factory.hpp:77] Creating layer Convolution28
I1005 20:35:19.790438 10142 net.cpp:84] Creating Layer Convolution28
I1005 20:35:19.790442 10142 net.cpp:406] Convolution28 <- Eltwise12_ReLU25_0_split_0
I1005 20:35:19.790446 10142 net.cpp:380] Convolution28 -> Convolution28
I1005 20:35:19.796228 10142 net.cpp:122] Setting up Convolution28
I1005 20:35:19.796238 10142 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 20:35:19.796241 10142 net.cpp:137] Memory required for data: 485139600
I1005 20:35:19.796247 10142 layer_factory.hpp:77] Creating layer BatchNorm28
I1005 20:35:19.796252 10142 net.cpp:84] Creating Layer BatchNorm28
I1005 20:35:19.796254 10142 net.cpp:406] BatchNorm28 <- Convolution28
I1005 20:35:19.796258 10142 net.cpp:367] BatchNorm28 -> Convolution28 (in-place)
I1005 20:35:19.796398 10142 net.cpp:122] Setting up BatchNorm28
I1005 20:35:19.796404 10142 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 20:35:19.796406 10142 net.cpp:137] Memory required for data: 486394000
I1005 20:35:19.796411 10142 layer_factory.hpp:77] Creating layer Scale28
I1005 20:35:19.796417 10142 net.cpp:84] Creating Layer Scale28
I1005 20:35:19.796420 10142 net.cpp:406] Scale28 <- Convolution28
I1005 20:35:19.796424 10142 net.cpp:367] Scale28 -> Convolution28 (in-place)
I1005 20:35:19.796452 10142 layer_factory.hpp:77] Creating layer Scale28
I1005 20:35:19.796532 10142 net.cpp:122] Setting up Scale28
I1005 20:35:19.796538 10142 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 20:35:19.796540 10142 net.cpp:137] Memory required for data: 487648400
I1005 20:35:19.796545 10142 layer_factory.hpp:77] Creating layer ReLU26
I1005 20:35:19.796550 10142 net.cpp:84] Creating Layer ReLU26
I1005 20:35:19.796552 10142 net.cpp:406] ReLU26 <- Convolution28
I1005 20:35:19.796555 10142 net.cpp:367] ReLU26 -> Convolution28 (in-place)
I1005 20:35:19.796676 10142 net.cpp:122] Setting up ReLU26
I1005 20:35:19.796684 10142 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 20:35:19.796686 10142 net.cpp:137] Memory required for data: 488902800
I1005 20:35:19.796689 10142 layer_factory.hpp:77] Creating layer Convolution29
I1005 20:35:19.796696 10142 net.cpp:84] Creating Layer Convolution29
I1005 20:35:19.796700 10142 net.cpp:406] Convolution29 <- Convolution28
I1005 20:35:19.796703 10142 net.cpp:380] Convolution29 -> Convolution29
I1005 20:35:19.803267 10142 net.cpp:122] Setting up Convolution29
I1005 20:35:19.803277 10142 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 20:35:19.803278 10142 net.cpp:137] Memory required for data: 490157200
I1005 20:35:19.803283 10142 layer_factory.hpp:77] Creating layer BatchNorm29
I1005 20:35:19.803298 10142 net.cpp:84] Creating Layer BatchNorm29
I1005 20:35:19.803303 10142 net.cpp:406] BatchNorm29 <- Convolution29
I1005 20:35:19.803306 10142 net.cpp:367] BatchNorm29 -> Convolution29 (in-place)
I1005 20:35:19.803459 10142 net.cpp:122] Setting up BatchNorm29
I1005 20:35:19.803465 10142 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 20:35:19.803467 10142 net.cpp:137] Memory required for data: 491411600
I1005 20:35:19.803472 10142 layer_factory.hpp:77] Creating layer Scale29
I1005 20:35:19.803477 10142 net.cpp:84] Creating Layer Scale29
I1005 20:35:19.803479 10142 net.cpp:406] Scale29 <- Convolution29
I1005 20:35:19.803483 10142 net.cpp:367] Scale29 -> Convolution29 (in-place)
I1005 20:35:19.803511 10142 layer_factory.hpp:77] Creating layer Scale29
I1005 20:35:19.803593 10142 net.cpp:122] Setting up Scale29
I1005 20:35:19.803606 10142 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 20:35:19.803608 10142 net.cpp:137] Memory required for data: 492666000
I1005 20:35:19.803612 10142 layer_factory.hpp:77] Creating layer Eltwise13
I1005 20:35:19.803617 10142 net.cpp:84] Creating Layer Eltwise13
I1005 20:35:19.803620 10142 net.cpp:406] Eltwise13 <- Eltwise12_ReLU25_0_split_1
I1005 20:35:19.803623 10142 net.cpp:406] Eltwise13 <- Convolution29
I1005 20:35:19.803628 10142 net.cpp:380] Eltwise13 -> Eltwise13
I1005 20:35:19.803647 10142 net.cpp:122] Setting up Eltwise13
I1005 20:35:19.803653 10142 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 20:35:19.803654 10142 net.cpp:137] Memory required for data: 493920400
I1005 20:35:19.803656 10142 layer_factory.hpp:77] Creating layer ReLU27
I1005 20:35:19.803660 10142 net.cpp:84] Creating Layer ReLU27
I1005 20:35:19.803663 10142 net.cpp:406] ReLU27 <- Eltwise13
I1005 20:35:19.803666 10142 net.cpp:367] ReLU27 -> Eltwise13 (in-place)
I1005 20:35:19.805080 10142 net.cpp:122] Setting up ReLU27
I1005 20:35:19.805088 10142 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 20:35:19.805090 10142 net.cpp:137] Memory required for data: 495174800
I1005 20:35:19.805093 10142 layer_factory.hpp:77] Creating layer Eltwise13_ReLU27_0_split
I1005 20:35:19.805096 10142 net.cpp:84] Creating Layer Eltwise13_ReLU27_0_split
I1005 20:35:19.805099 10142 net.cpp:406] Eltwise13_ReLU27_0_split <- Eltwise13
I1005 20:35:19.805104 10142 net.cpp:380] Eltwise13_ReLU27_0_split -> Eltwise13_ReLU27_0_split_0
I1005 20:35:19.805109 10142 net.cpp:380] Eltwise13_ReLU27_0_split -> Eltwise13_ReLU27_0_split_1
I1005 20:35:19.805137 10142 net.cpp:122] Setting up Eltwise13_ReLU27_0_split
I1005 20:35:19.805142 10142 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 20:35:19.805145 10142 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 20:35:19.805147 10142 net.cpp:137] Memory required for data: 497683600
I1005 20:35:19.805150 10142 layer_factory.hpp:77] Creating layer Convolution30
I1005 20:35:19.805158 10142 net.cpp:84] Creating Layer Convolution30
I1005 20:35:19.805161 10142 net.cpp:406] Convolution30 <- Eltwise13_ReLU27_0_split_0
I1005 20:35:19.805166 10142 net.cpp:380] Convolution30 -> Convolution30
I1005 20:35:19.812383 10142 net.cpp:122] Setting up Convolution30
I1005 20:35:19.812407 10142 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 20:35:19.812410 10142 net.cpp:137] Memory required for data: 498938000
I1005 20:35:19.812415 10142 layer_factory.hpp:77] Creating layer BatchNorm30
I1005 20:35:19.812422 10142 net.cpp:84] Creating Layer BatchNorm30
I1005 20:35:19.812436 10142 net.cpp:406] BatchNorm30 <- Convolution30
I1005 20:35:19.812441 10142 net.cpp:367] BatchNorm30 -> Convolution30 (in-place)
I1005 20:35:19.812616 10142 net.cpp:122] Setting up BatchNorm30
I1005 20:35:19.812623 10142 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 20:35:19.812624 10142 net.cpp:137] Memory required for data: 500192400
I1005 20:35:19.812629 10142 layer_factory.hpp:77] Creating layer Scale30
I1005 20:35:19.812635 10142 net.cpp:84] Creating Layer Scale30
I1005 20:35:19.812639 10142 net.cpp:406] Scale30 <- Convolution30
I1005 20:35:19.812642 10142 net.cpp:367] Scale30 -> Convolution30 (in-place)
I1005 20:35:19.812672 10142 layer_factory.hpp:77] Creating layer Scale30
I1005 20:35:19.812754 10142 net.cpp:122] Setting up Scale30
I1005 20:35:19.812759 10142 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 20:35:19.812762 10142 net.cpp:137] Memory required for data: 501446800
I1005 20:35:19.812765 10142 layer_factory.hpp:77] Creating layer ReLU28
I1005 20:35:19.812772 10142 net.cpp:84] Creating Layer ReLU28
I1005 20:35:19.812774 10142 net.cpp:406] ReLU28 <- Convolution30
I1005 20:35:19.812777 10142 net.cpp:367] ReLU28 -> Convolution30 (in-place)
I1005 20:35:19.814762 10142 net.cpp:122] Setting up ReLU28
I1005 20:35:19.814771 10142 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 20:35:19.814774 10142 net.cpp:137] Memory required for data: 502701200
I1005 20:35:19.814777 10142 layer_factory.hpp:77] Creating layer Convolution31
I1005 20:35:19.814795 10142 net.cpp:84] Creating Layer Convolution31
I1005 20:35:19.814808 10142 net.cpp:406] Convolution31 <- Convolution30
I1005 20:35:19.814815 10142 net.cpp:380] Convolution31 -> Convolution31
I1005 20:35:19.821787 10142 net.cpp:122] Setting up Convolution31
I1005 20:35:19.821796 10142 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 20:35:19.821810 10142 net.cpp:137] Memory required for data: 503955600
I1005 20:35:19.821815 10142 layer_factory.hpp:77] Creating layer BatchNorm31
I1005 20:35:19.821821 10142 net.cpp:84] Creating Layer BatchNorm31
I1005 20:35:19.821823 10142 net.cpp:406] BatchNorm31 <- Convolution31
I1005 20:35:19.821827 10142 net.cpp:367] BatchNorm31 -> Convolution31 (in-place)
I1005 20:35:19.821974 10142 net.cpp:122] Setting up BatchNorm31
I1005 20:35:19.821979 10142 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 20:35:19.821981 10142 net.cpp:137] Memory required for data: 505210000
I1005 20:35:19.821986 10142 layer_factory.hpp:77] Creating layer Scale31
I1005 20:35:19.821991 10142 net.cpp:84] Creating Layer Scale31
I1005 20:35:19.821995 10142 net.cpp:406] Scale31 <- Convolution31
I1005 20:35:19.821997 10142 net.cpp:367] Scale31 -> Convolution31 (in-place)
I1005 20:35:19.822027 10142 layer_factory.hpp:77] Creating layer Scale31
I1005 20:35:19.822109 10142 net.cpp:122] Setting up Scale31
I1005 20:35:19.822115 10142 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 20:35:19.822118 10142 net.cpp:137] Memory required for data: 506464400
I1005 20:35:19.822121 10142 layer_factory.hpp:77] Creating layer Eltwise14
I1005 20:35:19.822126 10142 net.cpp:84] Creating Layer Eltwise14
I1005 20:35:19.822130 10142 net.cpp:406] Eltwise14 <- Eltwise13_ReLU27_0_split_1
I1005 20:35:19.822134 10142 net.cpp:406] Eltwise14 <- Convolution31
I1005 20:35:19.822137 10142 net.cpp:380] Eltwise14 -> Eltwise14
I1005 20:35:19.822154 10142 net.cpp:122] Setting up Eltwise14
I1005 20:35:19.822160 10142 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 20:35:19.822161 10142 net.cpp:137] Memory required for data: 507718800
I1005 20:35:19.822163 10142 layer_factory.hpp:77] Creating layer ReLU29
I1005 20:35:19.822167 10142 net.cpp:84] Creating Layer ReLU29
I1005 20:35:19.822170 10142 net.cpp:406] ReLU29 <- Eltwise14
I1005 20:35:19.822173 10142 net.cpp:367] ReLU29 -> Eltwise14 (in-place)
I1005 20:35:19.823606 10142 net.cpp:122] Setting up ReLU29
I1005 20:35:19.823613 10142 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 20:35:19.823616 10142 net.cpp:137] Memory required for data: 508973200
I1005 20:35:19.823618 10142 layer_factory.hpp:77] Creating layer Eltwise14_ReLU29_0_split
I1005 20:35:19.823622 10142 net.cpp:84] Creating Layer Eltwise14_ReLU29_0_split
I1005 20:35:19.823626 10142 net.cpp:406] Eltwise14_ReLU29_0_split <- Eltwise14
I1005 20:35:19.823629 10142 net.cpp:380] Eltwise14_ReLU29_0_split -> Eltwise14_ReLU29_0_split_0
I1005 20:35:19.823634 10142 net.cpp:380] Eltwise14_ReLU29_0_split -> Eltwise14_ReLU29_0_split_1
I1005 20:35:19.823664 10142 net.cpp:122] Setting up Eltwise14_ReLU29_0_split
I1005 20:35:19.823669 10142 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 20:35:19.823673 10142 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 20:35:19.823674 10142 net.cpp:137] Memory required for data: 511482000
I1005 20:35:19.823676 10142 layer_factory.hpp:77] Creating layer Convolution32
I1005 20:35:19.823683 10142 net.cpp:84] Creating Layer Convolution32
I1005 20:35:19.823686 10142 net.cpp:406] Convolution32 <- Eltwise14_ReLU29_0_split_0
I1005 20:35:19.823690 10142 net.cpp:380] Convolution32 -> Convolution32
I1005 20:35:19.830329 10142 net.cpp:122] Setting up Convolution32
I1005 20:35:19.830339 10142 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 20:35:19.830343 10142 net.cpp:137] Memory required for data: 512736400
I1005 20:35:19.830358 10142 layer_factory.hpp:77] Creating layer BatchNorm32
I1005 20:35:19.830363 10142 net.cpp:84] Creating Layer BatchNorm32
I1005 20:35:19.830366 10142 net.cpp:406] BatchNorm32 <- Convolution32
I1005 20:35:19.830370 10142 net.cpp:367] BatchNorm32 -> Convolution32 (in-place)
I1005 20:35:19.830530 10142 net.cpp:122] Setting up BatchNorm32
I1005 20:35:19.830543 10142 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 20:35:19.830546 10142 net.cpp:137] Memory required for data: 513990800
I1005 20:35:19.830551 10142 layer_factory.hpp:77] Creating layer Scale32
I1005 20:35:19.830556 10142 net.cpp:84] Creating Layer Scale32
I1005 20:35:19.830559 10142 net.cpp:406] Scale32 <- Convolution32
I1005 20:35:19.830564 10142 net.cpp:367] Scale32 -> Convolution32 (in-place)
I1005 20:35:19.830595 10142 layer_factory.hpp:77] Creating layer Scale32
I1005 20:35:19.830677 10142 net.cpp:122] Setting up Scale32
I1005 20:35:19.830682 10142 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 20:35:19.830684 10142 net.cpp:137] Memory required for data: 515245200
I1005 20:35:19.830688 10142 layer_factory.hpp:77] Creating layer ReLU30
I1005 20:35:19.830693 10142 net.cpp:84] Creating Layer ReLU30
I1005 20:35:19.830695 10142 net.cpp:406] ReLU30 <- Convolution32
I1005 20:35:19.830700 10142 net.cpp:367] ReLU30 -> Convolution32 (in-place)
I1005 20:35:19.832464 10142 net.cpp:122] Setting up ReLU30
I1005 20:35:19.832471 10142 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 20:35:19.832474 10142 net.cpp:137] Memory required for data: 516499600
I1005 20:35:19.832476 10142 layer_factory.hpp:77] Creating layer Convolution33
I1005 20:35:19.832484 10142 net.cpp:84] Creating Layer Convolution33
I1005 20:35:19.832486 10142 net.cpp:406] Convolution33 <- Convolution32
I1005 20:35:19.832491 10142 net.cpp:380] Convolution33 -> Convolution33
I1005 20:35:19.836932 10142 net.cpp:122] Setting up Convolution33
I1005 20:35:19.836942 10142 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 20:35:19.836946 10142 net.cpp:137] Memory required for data: 517754000
I1005 20:35:19.836951 10142 layer_factory.hpp:77] Creating layer BatchNorm33
I1005 20:35:19.836956 10142 net.cpp:84] Creating Layer BatchNorm33
I1005 20:35:19.836961 10142 net.cpp:406] BatchNorm33 <- Convolution33
I1005 20:35:19.836964 10142 net.cpp:367] BatchNorm33 -> Convolution33 (in-place)
I1005 20:35:19.837112 10142 net.cpp:122] Setting up BatchNorm33
I1005 20:35:19.837118 10142 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 20:35:19.837121 10142 net.cpp:137] Memory required for data: 519008400
I1005 20:35:19.837126 10142 layer_factory.hpp:77] Creating layer Scale33
I1005 20:35:19.837131 10142 net.cpp:84] Creating Layer Scale33
I1005 20:35:19.837133 10142 net.cpp:406] Scale33 <- Convolution33
I1005 20:35:19.837137 10142 net.cpp:367] Scale33 -> Convolution33 (in-place)
I1005 20:35:19.837167 10142 layer_factory.hpp:77] Creating layer Scale33
I1005 20:35:19.837250 10142 net.cpp:122] Setting up Scale33
I1005 20:35:19.837256 10142 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 20:35:19.837260 10142 net.cpp:137] Memory required for data: 520262800
I1005 20:35:19.837273 10142 layer_factory.hpp:77] Creating layer Eltwise15
I1005 20:35:19.837278 10142 net.cpp:84] Creating Layer Eltwise15
I1005 20:35:19.837281 10142 net.cpp:406] Eltwise15 <- Eltwise14_ReLU29_0_split_1
I1005 20:35:19.837285 10142 net.cpp:406] Eltwise15 <- Convolution33
I1005 20:35:19.837297 10142 net.cpp:380] Eltwise15 -> Eltwise15
I1005 20:35:19.837326 10142 net.cpp:122] Setting up Eltwise15
I1005 20:35:19.837340 10142 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 20:35:19.837342 10142 net.cpp:137] Memory required for data: 521517200
I1005 20:35:19.837344 10142 layer_factory.hpp:77] Creating layer ReLU31
I1005 20:35:19.837348 10142 net.cpp:84] Creating Layer ReLU31
I1005 20:35:19.837350 10142 net.cpp:406] ReLU31 <- Eltwise15
I1005 20:35:19.837354 10142 net.cpp:367] ReLU31 -> Eltwise15 (in-place)
I1005 20:35:19.837534 10142 net.cpp:122] Setting up ReLU31
I1005 20:35:19.837540 10142 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1005 20:35:19.837553 10142 net.cpp:137] Memory required for data: 522771600
I1005 20:35:19.837555 10142 layer_factory.hpp:77] Creating layer Pooling1
I1005 20:35:19.837559 10142 net.cpp:84] Creating Layer Pooling1
I1005 20:35:19.837563 10142 net.cpp:406] Pooling1 <- Eltwise15
I1005 20:35:19.837568 10142 net.cpp:380] Pooling1 -> Pooling1
I1005 20:35:19.837733 10142 net.cpp:122] Setting up Pooling1
I1005 20:35:19.837740 10142 net.cpp:129] Top shape: 100 64 1 1 (6400)
I1005 20:35:19.837752 10142 net.cpp:137] Memory required for data: 522797200
I1005 20:35:19.837754 10142 layer_factory.hpp:77] Creating layer InnerProduct1
I1005 20:35:19.837765 10142 net.cpp:84] Creating Layer InnerProduct1
I1005 20:35:19.837769 10142 net.cpp:406] InnerProduct1 <- Pooling1
I1005 20:35:19.837783 10142 net.cpp:380] InnerProduct1 -> InnerProduct1
I1005 20:35:19.837900 10142 net.cpp:122] Setting up InnerProduct1
I1005 20:35:19.837905 10142 net.cpp:129] Top shape: 100 10 (1000)
I1005 20:35:19.837908 10142 net.cpp:137] Memory required for data: 522801200
I1005 20:35:19.837913 10142 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I1005 20:35:19.837918 10142 net.cpp:84] Creating Layer SoftmaxWithLoss1
I1005 20:35:19.837923 10142 net.cpp:406] SoftmaxWithLoss1 <- InnerProduct1
I1005 20:35:19.837925 10142 net.cpp:406] SoftmaxWithLoss1 <- Data2
I1005 20:35:19.837930 10142 net.cpp:380] SoftmaxWithLoss1 -> SoftmaxWithLoss1
I1005 20:35:19.837936 10142 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I1005 20:35:19.839867 10142 net.cpp:122] Setting up SoftmaxWithLoss1
I1005 20:35:19.839879 10142 net.cpp:129] Top shape: (1)
I1005 20:35:19.839881 10142 net.cpp:132]     with loss weight 1
I1005 20:35:19.839895 10142 net.cpp:137] Memory required for data: 522801204
I1005 20:35:19.839897 10142 net.cpp:198] SoftmaxWithLoss1 needs backward computation.
I1005 20:35:19.839900 10142 net.cpp:198] InnerProduct1 needs backward computation.
I1005 20:35:19.839902 10142 net.cpp:198] Pooling1 needs backward computation.
I1005 20:35:19.839905 10142 net.cpp:198] ReLU31 needs backward computation.
I1005 20:35:19.839906 10142 net.cpp:198] Eltwise15 needs backward computation.
I1005 20:35:19.839910 10142 net.cpp:198] Scale33 needs backward computation.
I1005 20:35:19.839911 10142 net.cpp:198] BatchNorm33 needs backward computation.
I1005 20:35:19.839913 10142 net.cpp:198] Convolution33 needs backward computation.
I1005 20:35:19.839916 10142 net.cpp:198] ReLU30 needs backward computation.
I1005 20:35:19.839918 10142 net.cpp:198] Scale32 needs backward computation.
I1005 20:35:19.839920 10142 net.cpp:198] BatchNorm32 needs backward computation.
I1005 20:35:19.839922 10142 net.cpp:198] Convolution32 needs backward computation.
I1005 20:35:19.839925 10142 net.cpp:198] Eltwise14_ReLU29_0_split needs backward computation.
I1005 20:35:19.839927 10142 net.cpp:198] ReLU29 needs backward computation.
I1005 20:35:19.839929 10142 net.cpp:198] Eltwise14 needs backward computation.
I1005 20:35:19.839932 10142 net.cpp:198] Scale31 needs backward computation.
I1005 20:35:19.839934 10142 net.cpp:198] BatchNorm31 needs backward computation.
I1005 20:35:19.839936 10142 net.cpp:198] Convolution31 needs backward computation.
I1005 20:35:19.839939 10142 net.cpp:198] ReLU28 needs backward computation.
I1005 20:35:19.839941 10142 net.cpp:198] Scale30 needs backward computation.
I1005 20:35:19.839943 10142 net.cpp:198] BatchNorm30 needs backward computation.
I1005 20:35:19.839946 10142 net.cpp:198] Convolution30 needs backward computation.
I1005 20:35:19.839948 10142 net.cpp:198] Eltwise13_ReLU27_0_split needs backward computation.
I1005 20:35:19.839951 10142 net.cpp:198] ReLU27 needs backward computation.
I1005 20:35:19.839953 10142 net.cpp:198] Eltwise13 needs backward computation.
I1005 20:35:19.839956 10142 net.cpp:198] Scale29 needs backward computation.
I1005 20:35:19.839958 10142 net.cpp:198] BatchNorm29 needs backward computation.
I1005 20:35:19.839960 10142 net.cpp:198] Convolution29 needs backward computation.
I1005 20:35:19.839963 10142 net.cpp:198] ReLU26 needs backward computation.
I1005 20:35:19.839965 10142 net.cpp:198] Scale28 needs backward computation.
I1005 20:35:19.839967 10142 net.cpp:198] BatchNorm28 needs backward computation.
I1005 20:35:19.839970 10142 net.cpp:198] Convolution28 needs backward computation.
I1005 20:35:19.839973 10142 net.cpp:198] Eltwise12_ReLU25_0_split needs backward computation.
I1005 20:35:19.839983 10142 net.cpp:198] ReLU25 needs backward computation.
I1005 20:35:19.839987 10142 net.cpp:198] Eltwise12 needs backward computation.
I1005 20:35:19.839989 10142 net.cpp:198] Scale27 needs backward computation.
I1005 20:35:19.839992 10142 net.cpp:198] BatchNorm27 needs backward computation.
I1005 20:35:19.839994 10142 net.cpp:198] Convolution27 needs backward computation.
I1005 20:35:19.839996 10142 net.cpp:198] ReLU24 needs backward computation.
I1005 20:35:19.839998 10142 net.cpp:198] Scale26 needs backward computation.
I1005 20:35:19.840001 10142 net.cpp:198] BatchNorm26 needs backward computation.
I1005 20:35:19.840003 10142 net.cpp:198] Convolution26 needs backward computation.
I1005 20:35:19.840005 10142 net.cpp:198] Eltwise11_ReLU23_0_split needs backward computation.
I1005 20:35:19.840008 10142 net.cpp:198] ReLU23 needs backward computation.
I1005 20:35:19.840010 10142 net.cpp:198] Eltwise11 needs backward computation.
I1005 20:35:19.840013 10142 net.cpp:198] Scale25 needs backward computation.
I1005 20:35:19.840016 10142 net.cpp:198] BatchNorm25 needs backward computation.
I1005 20:35:19.840020 10142 net.cpp:198] Convolution25 needs backward computation.
I1005 20:35:19.840023 10142 net.cpp:198] ReLU22 needs backward computation.
I1005 20:35:19.840026 10142 net.cpp:198] Scale24 needs backward computation.
I1005 20:35:19.840029 10142 net.cpp:198] BatchNorm24 needs backward computation.
I1005 20:35:19.840031 10142 net.cpp:198] Convolution24 needs backward computation.
I1005 20:35:19.840034 10142 net.cpp:198] Scale23 needs backward computation.
I1005 20:35:19.840036 10142 net.cpp:198] BatchNorm23 needs backward computation.
I1005 20:35:19.840039 10142 net.cpp:198] Convolution23 needs backward computation.
I1005 20:35:19.840041 10142 net.cpp:198] Eltwise10_ReLU21_0_split needs backward computation.
I1005 20:35:19.840044 10142 net.cpp:198] ReLU21 needs backward computation.
I1005 20:35:19.840046 10142 net.cpp:198] Eltwise10 needs backward computation.
I1005 20:35:19.840049 10142 net.cpp:198] Scale22 needs backward computation.
I1005 20:35:19.840051 10142 net.cpp:198] BatchNorm22 needs backward computation.
I1005 20:35:19.840054 10142 net.cpp:198] Convolution22 needs backward computation.
I1005 20:35:19.840056 10142 net.cpp:198] ReLU20 needs backward computation.
I1005 20:35:19.840059 10142 net.cpp:198] Scale21 needs backward computation.
I1005 20:35:19.840060 10142 net.cpp:198] BatchNorm21 needs backward computation.
I1005 20:35:19.840062 10142 net.cpp:198] Convolution21 needs backward computation.
I1005 20:35:19.840065 10142 net.cpp:198] Eltwise9_ReLU19_0_split needs backward computation.
I1005 20:35:19.840068 10142 net.cpp:198] ReLU19 needs backward computation.
I1005 20:35:19.840070 10142 net.cpp:198] Eltwise9 needs backward computation.
I1005 20:35:19.840073 10142 net.cpp:198] Scale20 needs backward computation.
I1005 20:35:19.840075 10142 net.cpp:198] BatchNorm20 needs backward computation.
I1005 20:35:19.840078 10142 net.cpp:198] Convolution20 needs backward computation.
I1005 20:35:19.840080 10142 net.cpp:198] ReLU18 needs backward computation.
I1005 20:35:19.840083 10142 net.cpp:198] Scale19 needs backward computation.
I1005 20:35:19.840085 10142 net.cpp:198] BatchNorm19 needs backward computation.
I1005 20:35:19.840088 10142 net.cpp:198] Convolution19 needs backward computation.
I1005 20:35:19.840090 10142 net.cpp:198] Eltwise8_ReLU17_0_split needs backward computation.
I1005 20:35:19.840093 10142 net.cpp:198] ReLU17 needs backward computation.
I1005 20:35:19.840095 10142 net.cpp:198] Eltwise8 needs backward computation.
I1005 20:35:19.840098 10142 net.cpp:198] Scale18 needs backward computation.
I1005 20:35:19.840101 10142 net.cpp:198] BatchNorm18 needs backward computation.
I1005 20:35:19.840102 10142 net.cpp:198] Convolution18 needs backward computation.
I1005 20:35:19.840106 10142 net.cpp:198] ReLU16 needs backward computation.
I1005 20:35:19.840107 10142 net.cpp:198] Scale17 needs backward computation.
I1005 20:35:19.840109 10142 net.cpp:198] BatchNorm17 needs backward computation.
I1005 20:35:19.840116 10142 net.cpp:198] Convolution17 needs backward computation.
I1005 20:35:19.840118 10142 net.cpp:198] Eltwise7_ReLU15_0_split needs backward computation.
I1005 20:35:19.840121 10142 net.cpp:198] ReLU15 needs backward computation.
I1005 20:35:19.840123 10142 net.cpp:198] Eltwise7 needs backward computation.
I1005 20:35:19.840126 10142 net.cpp:198] Scale16 needs backward computation.
I1005 20:35:19.840128 10142 net.cpp:198] BatchNorm16 needs backward computation.
I1005 20:35:19.840131 10142 net.cpp:198] Convolution16 needs backward computation.
I1005 20:35:19.840133 10142 net.cpp:198] ReLU14 needs backward computation.
I1005 20:35:19.840137 10142 net.cpp:198] Scale15 needs backward computation.
I1005 20:35:19.840138 10142 net.cpp:198] BatchNorm15 needs backward computation.
I1005 20:35:19.840140 10142 net.cpp:198] Convolution15 needs backward computation.
I1005 20:35:19.840143 10142 net.cpp:198] Eltwise6_ReLU13_0_split needs backward computation.
I1005 20:35:19.840147 10142 net.cpp:198] ReLU13 needs backward computation.
I1005 20:35:19.840148 10142 net.cpp:198] Eltwise6 needs backward computation.
I1005 20:35:19.840152 10142 net.cpp:198] Scale14 needs backward computation.
I1005 20:35:19.840153 10142 net.cpp:198] BatchNorm14 needs backward computation.
I1005 20:35:19.840157 10142 net.cpp:198] Convolution14 needs backward computation.
I1005 20:35:19.840158 10142 net.cpp:198] ReLU12 needs backward computation.
I1005 20:35:19.840160 10142 net.cpp:198] Scale13 needs backward computation.
I1005 20:35:19.840163 10142 net.cpp:198] BatchNorm13 needs backward computation.
I1005 20:35:19.840165 10142 net.cpp:198] Convolution13 needs backward computation.
I1005 20:35:19.840168 10142 net.cpp:198] Scale12 needs backward computation.
I1005 20:35:19.840170 10142 net.cpp:198] BatchNorm12 needs backward computation.
I1005 20:35:19.840173 10142 net.cpp:198] Convolution12 needs backward computation.
I1005 20:35:19.840175 10142 net.cpp:198] Eltwise5_ReLU11_0_split needs backward computation.
I1005 20:35:19.840178 10142 net.cpp:198] ReLU11 needs backward computation.
I1005 20:35:19.840180 10142 net.cpp:198] Eltwise5 needs backward computation.
I1005 20:35:19.840183 10142 net.cpp:198] Scale11 needs backward computation.
I1005 20:35:19.840185 10142 net.cpp:198] BatchNorm11 needs backward computation.
I1005 20:35:19.840188 10142 net.cpp:198] Convolution11 needs backward computation.
I1005 20:35:19.840190 10142 net.cpp:198] ReLU10 needs backward computation.
I1005 20:35:19.840193 10142 net.cpp:198] Scale10 needs backward computation.
I1005 20:35:19.840195 10142 net.cpp:198] BatchNorm10 needs backward computation.
I1005 20:35:19.840198 10142 net.cpp:198] Convolution10 needs backward computation.
I1005 20:35:19.840200 10142 net.cpp:198] Eltwise4_ReLU9_0_split needs backward computation.
I1005 20:35:19.840203 10142 net.cpp:198] ReLU9 needs backward computation.
I1005 20:35:19.840205 10142 net.cpp:198] Eltwise4 needs backward computation.
I1005 20:35:19.840209 10142 net.cpp:198] Scale9 needs backward computation.
I1005 20:35:19.840210 10142 net.cpp:198] BatchNorm9 needs backward computation.
I1005 20:35:19.840214 10142 net.cpp:198] Convolution9 needs backward computation.
I1005 20:35:19.840215 10142 net.cpp:198] ReLU8 needs backward computation.
I1005 20:35:19.840219 10142 net.cpp:198] Scale8 needs backward computation.
I1005 20:35:19.840220 10142 net.cpp:198] BatchNorm8 needs backward computation.
I1005 20:35:19.840222 10142 net.cpp:198] Convolution8 needs backward computation.
I1005 20:35:19.840225 10142 net.cpp:198] Eltwise3_ReLU7_0_split needs backward computation.
I1005 20:35:19.840229 10142 net.cpp:198] ReLU7 needs backward computation.
I1005 20:35:19.840230 10142 net.cpp:198] Eltwise3 needs backward computation.
I1005 20:35:19.840234 10142 net.cpp:198] Scale7 needs backward computation.
I1005 20:35:19.840236 10142 net.cpp:198] BatchNorm7 needs backward computation.
I1005 20:35:19.840239 10142 net.cpp:198] Convolution7 needs backward computation.
I1005 20:35:19.840241 10142 net.cpp:198] ReLU6 needs backward computation.
I1005 20:35:19.840245 10142 net.cpp:198] Scale6 needs backward computation.
I1005 20:35:19.840248 10142 net.cpp:198] BatchNorm6 needs backward computation.
I1005 20:35:19.840250 10142 net.cpp:198] Convolution6 needs backward computation.
I1005 20:35:19.840253 10142 net.cpp:198] Eltwise2_ReLU5_0_split needs backward computation.
I1005 20:35:19.840255 10142 net.cpp:198] ReLU5 needs backward computation.
I1005 20:35:19.840257 10142 net.cpp:198] Eltwise2 needs backward computation.
I1005 20:35:19.840260 10142 net.cpp:198] Scale5 needs backward computation.
I1005 20:35:19.840263 10142 net.cpp:198] BatchNorm5 needs backward computation.
I1005 20:35:19.840265 10142 net.cpp:198] Convolution5 needs backward computation.
I1005 20:35:19.840268 10142 net.cpp:198] ReLU4 needs backward computation.
I1005 20:35:19.840270 10142 net.cpp:198] Scale4 needs backward computation.
I1005 20:35:19.840273 10142 net.cpp:198] BatchNorm4 needs backward computation.
I1005 20:35:19.840276 10142 net.cpp:198] Convolution4 needs backward computation.
I1005 20:35:19.840278 10142 net.cpp:198] Eltwise1_ReLU3_0_split needs backward computation.
I1005 20:35:19.840281 10142 net.cpp:198] ReLU3 needs backward computation.
I1005 20:35:19.840282 10142 net.cpp:198] Eltwise1 needs backward computation.
I1005 20:35:19.840286 10142 net.cpp:198] Scale3 needs backward computation.
I1005 20:35:19.840288 10142 net.cpp:198] BatchNorm3 needs backward computation.
I1005 20:35:19.840291 10142 net.cpp:198] Convolution3 needs backward computation.
I1005 20:35:19.840293 10142 net.cpp:198] ReLU2 needs backward computation.
I1005 20:35:19.840296 10142 net.cpp:198] Scale2 needs backward computation.
I1005 20:35:19.840298 10142 net.cpp:198] BatchNorm2 needs backward computation.
I1005 20:35:19.840301 10142 net.cpp:198] Convolution2 needs backward computation.
I1005 20:35:19.840302 10142 net.cpp:198] Convolution1_ReLU1_0_split needs backward computation.
I1005 20:35:19.840306 10142 net.cpp:198] ReLU1 needs backward computation.
I1005 20:35:19.840307 10142 net.cpp:198] Scale1 needs backward computation.
I1005 20:35:19.840309 10142 net.cpp:198] BatchNorm1 needs backward computation.
I1005 20:35:19.840312 10142 net.cpp:198] Convolution1 needs backward computation.
I1005 20:35:19.840314 10142 net.cpp:200] Data1 does not need backward computation.
I1005 20:35:19.840317 10142 net.cpp:242] This network produces output SoftmaxWithLoss1
I1005 20:35:19.840369 10142 net.cpp:255] Network initialization done.
I1005 20:35:19.842506 10142 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: /home/x306/caffe/xn/PENLU/neural/resnet/res32/res32_cifar_train_test.prototxt
I1005 20:35:19.842516 10142 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I1005 20:35:19.842526 10142 solver.cpp:172] Creating test net (#0) specified by net file: /home/x306/caffe/xn/PENLU/neural/resnet/res32/res32_cifar_train_test.prototxt
I1005 20:35:19.842660 10142 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer Data1
I1005 20:35:19.843236 10142 net.cpp:51] Initializing net from parameters: 
name: "resnet_cifar10"
state {
  phase: TEST
}
layer {
  name: "Data1"
  type: "Data"
  top: "Data1"
  top: "Data2"
  include {
    phase: TEST
  }
  transform_param {
    mean_file: "/home/x306/caffe/xn/PENLU/data/cifar10/mean.binaryproto"
  }
  data_param {
    source: "/home/x306/caffe/xn/PENLU/data/cifar10/cifar10_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "Convolution1"
  type: "Convolution"
  bottom: "Data1"
  top: "Convolution1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm1"
  type: "BatchNorm"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1"
  type: "Scale"
  bottom: "Convolution1"
  top: "Convolution1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU1"
  type: "ReLU"
  bottom: "Convolution1"
  top: "Convolution1"
}
layer {
  name: "Convolution2"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm2"
  type: "BatchNorm"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale2"
  type: "Scale"
  bottom: "Convolution2"
  top: "Convolution2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU2"
  type: "ReLU"
  bottom: "Convolution2"
  top: "Convolution2"
}
layer {
  name: "Convolution3"
  type: "Convolution"
  bottom: "Convolution2"
  top: "Convolution3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm3"
  type: "BatchNorm"
  bottom: "Convolution3"
  top: "Convolution3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale3"
  type: "Scale"
  bottom: "Convolution3"
  top: "Convolution3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise1"
  type: "Eltwise"
  bottom: "Convolution1"
  bottom: "Convolution3"
  top: "Eltwise1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU3"
  type: "ReLU"
  bottom: "Eltwise1"
  top: "Eltwise1"
}
layer {
  name: "Convolution4"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm4"
  type: "BatchNorm"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale4"
  type: "Scale"
  bottom: "Convolution4"
  top: "Convolution4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU4"
  type: "ReLU"
  bottom: "Convolution4"
  top: "Convolution4"
}
layer {
  name: "Convolution5"
  type: "Convolution"
  bottom: "Convolution4"
  top: "Convolution5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm5"
  type: "BatchNorm"
  bottom: "Convolution5"
  top: "Convolution5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale5"
  type: "Scale"
  bottom: "Convolution5"
  top: "Convolution5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise2"
  type: "Eltwise"
  bottom: "Eltwise1"
  bottom: "Convolution5"
  top: "Eltwise2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU5"
  type: "ReLU"
  bottom: "Eltwise2"
  top: "Eltwise2"
}
layer {
  name: "Convolution6"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm6"
  type: "BatchNorm"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale6"
  type: "Scale"
  bottom: "Convolution6"
  top: "Convolution6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU6"
  type: "ReLU"
  bottom: "Convolution6"
  top: "Convolution6"
}
layer {
  name: "Convolution7"
  type: "Convolution"
  bottom: "Convolution6"
  top: "Convolution7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm7"
  type: "BatchNorm"
  bottom: "Convolution7"
  top: "Convolution7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale7"
  type: "Scale"
  bottom: "Convolution7"
  top: "Convolution7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise3"
  type: "Eltwise"
  bottom: "Eltwise2"
  bottom: "Convolution7"
  top: "Eltwise3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU7"
  type: "ReLU"
  bottom: "Eltwise3"
  top: "Eltwise3"
}
layer {
  name: "Convolution8"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm8"
  type: "BatchNorm"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale8"
  type: "Scale"
  bottom: "Convolution8"
  top: "Convolution8"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU8"
  type: "ReLU"
  bottom: "Convolution8"
  top: "Convolution8"
}
layer {
  name: "Convolution9"
  type: "Convolution"
  bottom: "Convolution8"
  top: "Convolution9"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm9"
  type: "BatchNorm"
  bottom: "Convolution9"
  top: "Convolution9"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale9"
  type: "Scale"
  bottom: "Convolution9"
  top: "Convolution9"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise4"
  type: "Eltwise"
  bottom: "Eltwise3"
  bottom: "Convolution9"
  top: "Eltwise4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU9"
  type: "ReLU"
  bottom: "Eltwise4"
  top: "Eltwise4"
}
layer {
  name: "Convolution10"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution10"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm10"
  type: "BatchNorm"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale10"
  type: "Scale"
  bottom: "Convolution10"
  top: "Convolution10"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU10"
  type: "ReLU"
  bottom: "Convolution10"
  top: "Convolution10"
}
layer {
  name: "Convolution11"
  type: "Convolution"
  bottom: "Convolution10"
  top: "Convolution11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm11"
  type: "BatchNorm"
  bottom: "Convolution11"
  top: "Convolution11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale11"
  type: "Scale"
  bottom: "Convolution11"
  top: "Convolution11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise5"
  type: "Eltwise"
  bottom: "Eltwise4"
  bottom: "Convolution11"
  top: "Eltwise5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU11"
  type: "ReLU"
  bottom: "Eltwise5"
  top: "Eltwise5"
}
layer {
  name: "Convolution12"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.25
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm12"
  type: "BatchNorm"
  bottom: "Convolution12"
  top: "Convolution12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale12"
  type: "Scale"
  bottom: "Convolution12"
  top: "Convolution12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution13"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution13"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm13"
  type: "BatchNorm"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale13"
  type: "Scale"
  bottom: "Convolution13"
  top: "Convolution13"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU12"
  type: "ReLU"
  bottom: "Convolution13"
  top: "Convolution13"
}
layer {
  name: "Convolution14"
  type: "Convolution"
  bottom: "Convolution13"
  top: "Convolution14"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm14"
  type: "BatchNorm"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale14"
  type: "Scale"
  bottom: "Convolution14"
  top: "Convolution14"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise6"
  type: "Eltwise"
  bottom: "Convolution12"
  bottom: "Convolution14"
  top: "Eltwise6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU13"
  type: "ReLU"
  bottom: "Eltwise6"
  top: "Eltwise6"
}
layer {
  name: "Convolution15"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution15"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm15"
  type: "BatchNorm"
  bottom: "Convolution15"
  top: "Convolution15"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale15"
  type: "Scale"
  bottom: "Convolution15"
  top: "Convolution15"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU14"
  type: "ReLU"
  bottom: "Convolution15"
  top: "Convolution15"
}
layer {
  name: "Convolution16"
  type: "Convolution"
  bottom: "Convolution15"
  top: "Convolution16"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm16"
  type: "BatchNorm"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale16"
  type: "Scale"
  bottom: "Convolution16"
  top: "Convolution16"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise7"
  type: "Eltwise"
  bottom: "Eltwise6"
  bottom: "Convolution16"
  top: "Eltwise7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU15"
  type: "ReLU"
  bottom: "Eltwise7"
  top: "Eltwise7"
}
layer {
  name: "Convolution17"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution17"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm17"
  type: "BatchNorm"
  bottom: "Convolution17"
  top: "Convolution17"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale17"
  type: "Scale"
  bottom: "Convolution17"
  top: "Convolution17"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU16"
  type: "ReLU"
  bottom: "Convolution17"
  top: "Convolution17"
}
layer {
  name: "Convolution18"
  type: "Convolution"
  bottom: "Convolution17"
  top: "Convolution18"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm18"
  type: "BatchNorm"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale18"
  type: "Scale"
  bottom: "Convolution18"
  top: "Convolution18"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise8"
  type: "Eltwise"
  bottom: "Eltwise7"
  bottom: "Convolution18"
  top: "Eltwise8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU17"
  type: "ReLU"
  bottom: "Eltwise8"
  top: "Eltwise8"
}
layer {
  name: "Convolution19"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution19"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm19"
  type: "BatchNorm"
  bottom: "Convolution19"
  top: "Convolution19"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale19"
  type: "Scale"
  bottom: "Convolution19"
  top: "Convolution19"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU18"
  type: "ReLU"
  bottom: "Convolution19"
  top: "Convolution19"
}
layer {
  name: "Convolution20"
  type: "Convolution"
  bottom: "Convolution19"
  top: "Convolution20"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm20"
  type: "BatchNorm"
  bottom: "Convolution20"
  top: "Convolution20"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale20"
  type: "Scale"
  bottom: "Convolution20"
  top: "Convolution20"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise9"
  type: "Eltwise"
  bottom: "Eltwise8"
  bottom: "Convolution20"
  top: "Eltwise9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU19"
  type: "ReLU"
  bottom: "Eltwise9"
  top: "Eltwise9"
}
layer {
  name: "Convolution21"
  type: "Convolution"
  bottom: "Eltwise9"
  top: "Convolution21"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm21"
  type: "BatchNorm"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale21"
  type: "Scale"
  bottom: "Convolution21"
  top: "Convolution21"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU20"
  type: "ReLU"
  bottom: "Convolution21"
  top: "Convolution21"
}
layer {
  name: "Convolution22"
  type: "Convolution"
  bottom: "Convolution21"
  top: "Convolution22"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm22"
  type: "BatchNorm"
  bottom: "Convolution22"
  top: "Convolution22"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale22"
  type: "Scale"
  bottom: "Convolution22"
  top: "Convolution22"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise10"
  type: "Eltwise"
  bottom: "Eltwise9"
  bottom: "Convolution22"
  top: "Eltwise10"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU21"
  type: "ReLU"
  bottom: "Eltwise10"
  top: "Eltwise10"
}
layer {
  name: "Convolution23"
  type: "Convolution"
  bottom: "Eltwise10"
  top: "Convolution23"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.17677669
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm23"
  type: "BatchNorm"
  bottom: "Convolution23"
  top: "Convolution23"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale23"
  type: "Scale"
  bottom: "Convolution23"
  top: "Convolution23"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution24"
  type: "Convolution"
  bottom: "Eltwise10"
  top: "Convolution24"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm24"
  type: "BatchNorm"
  bottom: "Convolution24"
  top: "Convolution24"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale24"
  type: "Scale"
  bottom: "Convolution24"
  top: "Convolution24"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU22"
  type: "ReLU"
  bottom: "Convolution24"
  top: "Convolution24"
}
layer {
  name: "Convolution25"
  type: "Convolution"
  bottom: "Convolution24"
  top: "Convolution25"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm25"
  type: "BatchNorm"
  bottom: "Convolution25"
  top: "Convolution25"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale25"
  type: "Scale"
  bottom: "Convolution25"
  top: "Convolution25"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise11"
  type: "Eltwise"
  bottom: "Convolution23"
  bottom: "Convolution25"
  top: "Eltwise11"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU23"
  type: "ReLU"
  bottom: "Eltwise11"
  top: "Eltwise11"
}
layer {
  name: "Convolution26"
  type: "Convolution"
  bottom: "Eltwise11"
  top: "Convolution26"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm26"
  type: "BatchNorm"
  bottom: "Convolution26"
  top: "Convolution26"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale26"
  type: "Scale"
  bottom: "Convolution26"
  top: "Convolution26"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU24"
  type: "ReLU"
  bottom: "Convolution26"
  top: "Convolution26"
}
layer {
  name: "Convolution27"
  type: "Convolution"
  bottom: "Convolution26"
  top: "Convolution27"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm27"
  type: "BatchNorm"
  bottom: "Convolution27"
  top: "Convolution27"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale27"
  type: "Scale"
  bottom: "Convolution27"
  top: "Convolution27"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise12"
  type: "Eltwise"
  bottom: "Eltwise11"
  bottom: "Convolution27"
  top: "Eltwise12"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU25"
  type: "ReLU"
  bottom: "Eltwise12"
  top: "Eltwise12"
}
layer {
  name: "Convolution28"
  type: "Convolution"
  bottom: "Eltwise12"
  top: "Convolution28"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm28"
  type: "BatchNorm"
  bottom: "Convolution28"
  top: "Convolution28"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale28"
  type: "Scale"
  bottom: "Convolution28"
  top: "Convolution28"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU26"
  type: "ReLU"
  bottom: "Convolution28"
  top: "Convolution28"
}
layer {
  name: "Convolution29"
  type: "Convolution"
  bottom: "Convolution28"
  top: "Convolution29"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm29"
  type: "BatchNorm"
  bottom: "Convolution29"
  top: "Convolution29"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale29"
  type: "Scale"
  bottom: "Convolution29"
  top: "Convolution29"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise13"
  type: "Eltwise"
  bottom: "Eltwise12"
  bottom: "Convolution29"
  top: "Eltwise13"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU27"
  type: "ReLU"
  bottom: "Eltwise13"
  top: "Eltwise13"
}
layer {
  name: "Convolution30"
  type: "Convolution"
  bottom: "Eltwise13"
  top: "Convolution30"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm30"
  type: "BatchNorm"
  bottom: "Convolution30"
  top: "Convolution30"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale30"
  type: "Scale"
  bottom: "Convolution30"
  top: "Convolution30"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "ReLU28"
  type: "ReLU"
  bottom: "Convolution30"
  top: "Convolution30"
}
layer {
  name: "Convolution31"
  type: "Convolution"
  bottom: "Convolution30"
  top: "Convolution31"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm31"
  type: "BatchNorm"
  bottom: "Convolution31"
  top: "Convolution31"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale31"
  type: "Scale"
  bottom: "Convolution31"
  top: "Convolution31"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise14"
  type: "Eltwise"
  bottom: "Eltwise13"
  bottom: "Convolution31"
  top: "Eltwise14"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "ReLU29"
  type: "ReLU"
  bottom: "Eltwise14"
  top: "Eltwise14"
}
layer {
  name: "Convolution32"
  type: "Convolution"
  bottom: "Eltwise14"
  top: "Convolution32"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm32"
  type: "BatchNorm"
  bottom: "Convolution32"
  top: "Convolution32"
  param {
  
I1005 20:35:19.843636 10142 layer_factory.hpp:77] Creating layer Data1
I1005 20:35:19.843672 10142 db_lmdb.cpp:35] Opened lmdb /home/x306/caffe/xn/PENLU/data/cifar10/cifar10_test_lmdb
I1005 20:35:19.843689 10142 net.cpp:84] Creating Layer Data1
I1005 20:35:19.843694 10142 net.cpp:380] Data1 -> Data1
I1005 20:35:19.843700 10142 net.cpp:380] Data1 -> Data2
I1005 20:35:19.843706 10142 data_transformer.cpp:25] Loading mean file from: /home/x306/caffe/xn/PENLU/data/cifar10/mean.binaryproto
I1005 20:35:19.843837 10142 data_layer.cpp:45] output data size: 100,3,32,32
I1005 20:35:19.853328 10142 net.cpp:122] Setting up Data1
I1005 20:35:19.853349 10142 net.cpp:129] Top shape: 100 3 32 32 (307200)
I1005 20:35:19.853353 10142 net.cpp:129] Top shape: 100 (100)
I1005 20:35:19.853355 10142 net.cpp:137] Memory required for data: 1229200
I1005 20:35:19.853360 10142 layer_factory.hpp:77] Creating layer Data2_Data1_1_split
I1005 20:35:19.853369 10142 net.cpp:84] Creating Layer Data2_Data1_1_split
I1005 20:35:19.853373 10142 net.cpp:406] Data2_Data1_1_split <- Data2
I1005 20:35:19.853377 10142 net.cpp:380] Data2_Data1_1_split -> Data2_Data1_1_split_0
I1005 20:35:19.853385 10142 net.cpp:380] Data2_Data1_1_split -> Data2_Data1_1_split_1
I1005 20:35:19.853457 10142 net.cpp:122] Setting up Data2_Data1_1_split
I1005 20:35:19.853471 10142 net.cpp:129] Top shape: 100 (100)
I1005 20:35:19.853474 10142 net.cpp:129] Top shape: 100 (100)
I1005 20:35:19.853477 10142 net.cpp:137] Memory required for data: 1230000
I1005 20:35:19.853488 10142 layer_factory.hpp:77] Creating layer Convolution1
I1005 20:35:19.853498 10142 net.cpp:84] Creating Layer Convolution1
I1005 20:35:19.853502 10142 net.cpp:406] Convolution1 <- Data1
I1005 20:35:19.853505 10142 net.cpp:380] Convolution1 -> Convolution1
I1005 20:35:19.860612 10142 net.cpp:122] Setting up Convolution1
I1005 20:35:19.860622 10142 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 20:35:19.860625 10142 net.cpp:137] Memory required for data: 7783600
I1005 20:35:19.860633 10142 layer_factory.hpp:77] Creating layer BatchNorm1
I1005 20:35:19.860638 10142 net.cpp:84] Creating Layer BatchNorm1
I1005 20:35:19.860641 10142 net.cpp:406] BatchNorm1 <- Convolution1
I1005 20:35:19.860646 10142 net.cpp:367] BatchNorm1 -> Convolution1 (in-place)
I1005 20:35:19.860793 10142 net.cpp:122] Setting up BatchNorm1
I1005 20:35:19.860798 10142 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 20:35:19.860800 10142 net.cpp:137] Memory required for data: 14337200
I1005 20:35:19.860807 10142 layer_factory.hpp:77] Creating layer Scale1
I1005 20:35:19.860813 10142 net.cpp:84] Creating Layer Scale1
I1005 20:35:19.860816 10142 net.cpp:406] Scale1 <- Convolution1
I1005 20:35:19.860819 10142 net.cpp:367] Scale1 -> Convolution1 (in-place)
I1005 20:35:19.860849 10142 layer_factory.hpp:77] Creating layer Scale1
I1005 20:35:19.860932 10142 net.cpp:122] Setting up Scale1
I1005 20:35:19.860936 10142 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 20:35:19.860939 10142 net.cpp:137] Memory required for data: 20890800
I1005 20:35:19.860944 10142 layer_factory.hpp:77] Creating layer ReLU1
I1005 20:35:19.860947 10142 net.cpp:84] Creating Layer ReLU1
I1005 20:35:19.860949 10142 net.cpp:406] ReLU1 <- Convolution1
I1005 20:35:19.860954 10142 net.cpp:367] ReLU1 -> Convolution1 (in-place)
I1005 20:35:19.862125 10142 net.cpp:122] Setting up ReLU1
I1005 20:35:19.862133 10142 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 20:35:19.862134 10142 net.cpp:137] Memory required for data: 27444400
I1005 20:35:19.862138 10142 layer_factory.hpp:77] Creating layer Convolution1_ReLU1_0_split
I1005 20:35:19.862143 10142 net.cpp:84] Creating Layer Convolution1_ReLU1_0_split
I1005 20:35:19.862144 10142 net.cpp:406] Convolution1_ReLU1_0_split <- Convolution1
I1005 20:35:19.862172 10142 net.cpp:380] Convolution1_ReLU1_0_split -> Convolution1_ReLU1_0_split_0
I1005 20:35:19.862179 10142 net.cpp:380] Convolution1_ReLU1_0_split -> Convolution1_ReLU1_0_split_1
I1005 20:35:19.862210 10142 net.cpp:122] Setting up Convolution1_ReLU1_0_split
I1005 20:35:19.862215 10142 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 20:35:19.862217 10142 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 20:35:19.862220 10142 net.cpp:137] Memory required for data: 40551600
I1005 20:35:19.862221 10142 layer_factory.hpp:77] Creating layer Convolution2
I1005 20:35:19.862229 10142 net.cpp:84] Creating Layer Convolution2
I1005 20:35:19.862232 10142 net.cpp:406] Convolution2 <- Convolution1_ReLU1_0_split_0
I1005 20:35:19.862237 10142 net.cpp:380] Convolution2 -> Convolution2
I1005 20:35:19.870944 10142 net.cpp:122] Setting up Convolution2
I1005 20:35:19.870955 10142 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 20:35:19.870957 10142 net.cpp:137] Memory required for data: 47105200
I1005 20:35:19.870966 10142 layer_factory.hpp:77] Creating layer BatchNorm2
I1005 20:35:19.870973 10142 net.cpp:84] Creating Layer BatchNorm2
I1005 20:35:19.870976 10142 net.cpp:406] BatchNorm2 <- Convolution2
I1005 20:35:19.870981 10142 net.cpp:367] BatchNorm2 -> Convolution2 (in-place)
I1005 20:35:19.871148 10142 net.cpp:122] Setting up BatchNorm2
I1005 20:35:19.871155 10142 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 20:35:19.871157 10142 net.cpp:137] Memory required for data: 53658800
I1005 20:35:19.871162 10142 layer_factory.hpp:77] Creating layer Scale2
I1005 20:35:19.871167 10142 net.cpp:84] Creating Layer Scale2
I1005 20:35:19.871170 10142 net.cpp:406] Scale2 <- Convolution2
I1005 20:35:19.871172 10142 net.cpp:367] Scale2 -> Convolution2 (in-place)
I1005 20:35:19.871206 10142 layer_factory.hpp:77] Creating layer Scale2
I1005 20:35:19.871290 10142 net.cpp:122] Setting up Scale2
I1005 20:35:19.871297 10142 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 20:35:19.871299 10142 net.cpp:137] Memory required for data: 60212400
I1005 20:35:19.871304 10142 layer_factory.hpp:77] Creating layer ReLU2
I1005 20:35:19.871307 10142 net.cpp:84] Creating Layer ReLU2
I1005 20:35:19.871310 10142 net.cpp:406] ReLU2 <- Convolution2
I1005 20:35:19.871315 10142 net.cpp:367] ReLU2 -> Convolution2 (in-place)
I1005 20:35:19.871446 10142 net.cpp:122] Setting up ReLU2
I1005 20:35:19.871453 10142 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 20:35:19.871454 10142 net.cpp:137] Memory required for data: 66766000
I1005 20:35:19.871457 10142 layer_factory.hpp:77] Creating layer Convolution3
I1005 20:35:19.871465 10142 net.cpp:84] Creating Layer Convolution3
I1005 20:35:19.871469 10142 net.cpp:406] Convolution3 <- Convolution2
I1005 20:35:19.871472 10142 net.cpp:380] Convolution3 -> Convolution3
I1005 20:35:19.878732 10142 net.cpp:122] Setting up Convolution3
I1005 20:35:19.878744 10142 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 20:35:19.878747 10142 net.cpp:137] Memory required for data: 73319600
I1005 20:35:19.878752 10142 layer_factory.hpp:77] Creating layer BatchNorm3
I1005 20:35:19.878758 10142 net.cpp:84] Creating Layer BatchNorm3
I1005 20:35:19.878762 10142 net.cpp:406] BatchNorm3 <- Convolution3
I1005 20:35:19.878765 10142 net.cpp:367] BatchNorm3 -> Convolution3 (in-place)
I1005 20:35:19.878913 10142 net.cpp:122] Setting up BatchNorm3
I1005 20:35:19.878921 10142 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 20:35:19.878923 10142 net.cpp:137] Memory required for data: 79873200
I1005 20:35:19.878931 10142 layer_factory.hpp:77] Creating layer Scale3
I1005 20:35:19.878935 10142 net.cpp:84] Creating Layer Scale3
I1005 20:35:19.878937 10142 net.cpp:406] Scale3 <- Convolution3
I1005 20:35:19.878942 10142 net.cpp:367] Scale3 -> Convolution3 (in-place)
I1005 20:35:19.878975 10142 layer_factory.hpp:77] Creating layer Scale3
I1005 20:35:19.879056 10142 net.cpp:122] Setting up Scale3
I1005 20:35:19.879061 10142 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 20:35:19.879063 10142 net.cpp:137] Memory required for data: 86426800
I1005 20:35:19.879079 10142 layer_factory.hpp:77] Creating layer Eltwise1
I1005 20:35:19.879086 10142 net.cpp:84] Creating Layer Eltwise1
I1005 20:35:19.879092 10142 net.cpp:406] Eltwise1 <- Convolution1_ReLU1_0_split_1
I1005 20:35:19.879096 10142 net.cpp:406] Eltwise1 <- Convolution3
I1005 20:35:19.879099 10142 net.cpp:380] Eltwise1 -> Eltwise1
I1005 20:35:19.879118 10142 net.cpp:122] Setting up Eltwise1
I1005 20:35:19.879122 10142 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 20:35:19.879124 10142 net.cpp:137] Memory required for data: 92980400
I1005 20:35:19.879127 10142 layer_factory.hpp:77] Creating layer ReLU3
I1005 20:35:19.879132 10142 net.cpp:84] Creating Layer ReLU3
I1005 20:35:19.879137 10142 net.cpp:406] ReLU3 <- Eltwise1
I1005 20:35:19.879140 10142 net.cpp:367] ReLU3 -> Eltwise1 (in-place)
I1005 20:35:19.880550 10142 net.cpp:122] Setting up ReLU3
I1005 20:35:19.880558 10142 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 20:35:19.880559 10142 net.cpp:137] Memory required for data: 99534000
I1005 20:35:19.880563 10142 layer_factory.hpp:77] Creating layer Eltwise1_ReLU3_0_split
I1005 20:35:19.880568 10142 net.cpp:84] Creating Layer Eltwise1_ReLU3_0_split
I1005 20:35:19.880569 10142 net.cpp:406] Eltwise1_ReLU3_0_split <- Eltwise1
I1005 20:35:19.880576 10142 net.cpp:380] Eltwise1_ReLU3_0_split -> Eltwise1_ReLU3_0_split_0
I1005 20:35:19.880580 10142 net.cpp:380] Eltwise1_ReLU3_0_split -> Eltwise1_ReLU3_0_split_1
I1005 20:35:19.880610 10142 net.cpp:122] Setting up Eltwise1_ReLU3_0_split
I1005 20:35:19.880615 10142 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 20:35:19.880619 10142 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 20:35:19.880620 10142 net.cpp:137] Memory required for data: 112641200
I1005 20:35:19.880622 10142 layer_factory.hpp:77] Creating layer Convolution4
I1005 20:35:19.880631 10142 net.cpp:84] Creating Layer Convolution4
I1005 20:35:19.880635 10142 net.cpp:406] Convolution4 <- Eltwise1_ReLU3_0_split_0
I1005 20:35:19.880638 10142 net.cpp:380] Convolution4 -> Convolution4
I1005 20:35:19.887188 10142 net.cpp:122] Setting up Convolution4
I1005 20:35:19.887197 10142 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 20:35:19.887200 10142 net.cpp:137] Memory required for data: 119194800
I1005 20:35:19.887205 10142 layer_factory.hpp:77] Creating layer BatchNorm4
I1005 20:35:19.887209 10142 net.cpp:84] Creating Layer BatchNorm4
I1005 20:35:19.887212 10142 net.cpp:406] BatchNorm4 <- Convolution4
I1005 20:35:19.887217 10142 net.cpp:367] BatchNorm4 -> Convolution4 (in-place)
I1005 20:35:19.887361 10142 net.cpp:122] Setting up BatchNorm4
I1005 20:35:19.887365 10142 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 20:35:19.887367 10142 net.cpp:137] Memory required for data: 125748400
I1005 20:35:19.887372 10142 layer_factory.hpp:77] Creating layer Scale4
I1005 20:35:19.887377 10142 net.cpp:84] Creating Layer Scale4
I1005 20:35:19.887378 10142 net.cpp:406] Scale4 <- Convolution4
I1005 20:35:19.887382 10142 net.cpp:367] Scale4 -> Convolution4 (in-place)
I1005 20:35:19.887410 10142 layer_factory.hpp:77] Creating layer Scale4
I1005 20:35:19.887490 10142 net.cpp:122] Setting up Scale4
I1005 20:35:19.887495 10142 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 20:35:19.887496 10142 net.cpp:137] Memory required for data: 132302000
I1005 20:35:19.887501 10142 layer_factory.hpp:77] Creating layer ReLU4
I1005 20:35:19.887504 10142 net.cpp:84] Creating Layer ReLU4
I1005 20:35:19.887506 10142 net.cpp:406] ReLU4 <- Convolution4
I1005 20:35:19.887509 10142 net.cpp:367] ReLU4 -> Convolution4 (in-place)
I1005 20:35:19.889288 10142 net.cpp:122] Setting up ReLU4
I1005 20:35:19.889294 10142 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 20:35:19.889297 10142 net.cpp:137] Memory required for data: 138855600
I1005 20:35:19.889298 10142 layer_factory.hpp:77] Creating layer Convolution5
I1005 20:35:19.889305 10142 net.cpp:84] Creating Layer Convolution5
I1005 20:35:19.889308 10142 net.cpp:406] Convolution5 <- Convolution4
I1005 20:35:19.889312 10142 net.cpp:380] Convolution5 -> Convolution5
I1005 20:35:19.891687 10142 net.cpp:122] Setting up Convolution5
I1005 20:35:19.891696 10142 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 20:35:19.891700 10142 net.cpp:137] Memory required for data: 145409200
I1005 20:35:19.891703 10142 layer_factory.hpp:77] Creating layer BatchNorm5
I1005 20:35:19.891708 10142 net.cpp:84] Creating Layer BatchNorm5
I1005 20:35:19.891711 10142 net.cpp:406] BatchNorm5 <- Convolution5
I1005 20:35:19.891716 10142 net.cpp:367] BatchNorm5 -> Convolution5 (in-place)
I1005 20:35:19.891858 10142 net.cpp:122] Setting up BatchNorm5
I1005 20:35:19.891862 10142 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 20:35:19.891865 10142 net.cpp:137] Memory required for data: 151962800
I1005 20:35:19.891875 10142 layer_factory.hpp:77] Creating layer Scale5
I1005 20:35:19.891878 10142 net.cpp:84] Creating Layer Scale5
I1005 20:35:19.891880 10142 net.cpp:406] Scale5 <- Convolution5
I1005 20:35:19.891885 10142 net.cpp:367] Scale5 -> Convolution5 (in-place)
I1005 20:35:19.891914 10142 layer_factory.hpp:77] Creating layer Scale5
I1005 20:35:19.891996 10142 net.cpp:122] Setting up Scale5
I1005 20:35:19.892001 10142 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 20:35:19.892004 10142 net.cpp:137] Memory required for data: 158516400
I1005 20:35:19.892006 10142 layer_factory.hpp:77] Creating layer Eltwise2
I1005 20:35:19.892010 10142 net.cpp:84] Creating Layer Eltwise2
I1005 20:35:19.892014 10142 net.cpp:406] Eltwise2 <- Eltwise1_ReLU3_0_split_1
I1005 20:35:19.892015 10142 net.cpp:406] Eltwise2 <- Convolution5
I1005 20:35:19.892019 10142 net.cpp:380] Eltwise2 -> Eltwise2
I1005 20:35:19.892035 10142 net.cpp:122] Setting up Eltwise2
I1005 20:35:19.892040 10142 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 20:35:19.892041 10142 net.cpp:137] Memory required for data: 165070000
I1005 20:35:19.892043 10142 layer_factory.hpp:77] Creating layer ReLU5
I1005 20:35:19.892047 10142 net.cpp:84] Creating Layer ReLU5
I1005 20:35:19.892050 10142 net.cpp:406] ReLU5 <- Eltwise2
I1005 20:35:19.892052 10142 net.cpp:367] ReLU5 -> Eltwise2 (in-place)
I1005 20:35:19.892570 10142 net.cpp:122] Setting up ReLU5
I1005 20:35:19.892577 10142 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 20:35:19.892580 10142 net.cpp:137] Memory required for data: 171623600
I1005 20:35:19.892583 10142 layer_factory.hpp:77] Creating layer Eltwise2_ReLU5_0_split
I1005 20:35:19.892587 10142 net.cpp:84] Creating Layer Eltwise2_ReLU5_0_split
I1005 20:35:19.892590 10142 net.cpp:406] Eltwise2_ReLU5_0_split <- Eltwise2
I1005 20:35:19.892593 10142 net.cpp:380] Eltwise2_ReLU5_0_split -> Eltwise2_ReLU5_0_split_0
I1005 20:35:19.892597 10142 net.cpp:380] Eltwise2_ReLU5_0_split -> Eltwise2_ReLU5_0_split_1
I1005 20:35:19.892630 10142 net.cpp:122] Setting up Eltwise2_ReLU5_0_split
I1005 20:35:19.892634 10142 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 20:35:19.892637 10142 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 20:35:19.892640 10142 net.cpp:137] Memory required for data: 184730800
I1005 20:35:19.892642 10142 layer_factory.hpp:77] Creating layer Convolution6
I1005 20:35:19.892649 10142 net.cpp:84] Creating Layer Convolution6
I1005 20:35:19.892652 10142 net.cpp:406] Convolution6 <- Eltwise2_ReLU5_0_split_0
I1005 20:35:19.892657 10142 net.cpp:380] Convolution6 -> Convolution6
I1005 20:35:19.897137 10142 net.cpp:122] Setting up Convolution6
I1005 20:35:19.897146 10142 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 20:35:19.897150 10142 net.cpp:137] Memory required for data: 191284400
I1005 20:35:19.897153 10142 layer_factory.hpp:77] Creating layer BatchNorm6
I1005 20:35:19.897158 10142 net.cpp:84] Creating Layer BatchNorm6
I1005 20:35:19.897161 10142 net.cpp:406] BatchNorm6 <- Convolution6
I1005 20:35:19.897166 10142 net.cpp:367] BatchNorm6 -> Convolution6 (in-place)
I1005 20:35:19.897311 10142 net.cpp:122] Setting up BatchNorm6
I1005 20:35:19.897316 10142 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 20:35:19.897318 10142 net.cpp:137] Memory required for data: 197838000
I1005 20:35:19.897330 10142 layer_factory.hpp:77] Creating layer Scale6
I1005 20:35:19.897334 10142 net.cpp:84] Creating Layer Scale6
I1005 20:35:19.897337 10142 net.cpp:406] Scale6 <- Convolution6
I1005 20:35:19.897341 10142 net.cpp:367] Scale6 -> Convolution6 (in-place)
I1005 20:35:19.897372 10142 layer_factory.hpp:77] Creating layer Scale6
I1005 20:35:19.897454 10142 net.cpp:122] Setting up Scale6
I1005 20:35:19.897459 10142 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 20:35:19.897461 10142 net.cpp:137] Memory required for data: 204391600
I1005 20:35:19.897465 10142 layer_factory.hpp:77] Creating layer ReLU6
I1005 20:35:19.897469 10142 net.cpp:84] Creating Layer ReLU6
I1005 20:35:19.897470 10142 net.cpp:406] ReLU6 <- Convolution6
I1005 20:35:19.897475 10142 net.cpp:367] ReLU6 -> Convolution6 (in-place)
I1005 20:35:19.899242 10142 net.cpp:122] Setting up ReLU6
I1005 20:35:19.899250 10142 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 20:35:19.899253 10142 net.cpp:137] Memory required for data: 210945200
I1005 20:35:19.899255 10142 layer_factory.hpp:77] Creating layer Convolution7
I1005 20:35:19.899262 10142 net.cpp:84] Creating Layer Convolution7
I1005 20:35:19.899266 10142 net.cpp:406] Convolution7 <- Convolution6
I1005 20:35:19.899271 10142 net.cpp:380] Convolution7 -> Convolution7
I1005 20:35:19.905505 10142 net.cpp:122] Setting up Convolution7
I1005 20:35:19.905516 10142 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 20:35:19.905519 10142 net.cpp:137] Memory required for data: 217498800
I1005 20:35:19.905524 10142 layer_factory.hpp:77] Creating layer BatchNorm7
I1005 20:35:19.905534 10142 net.cpp:84] Creating Layer BatchNorm7
I1005 20:35:19.905537 10142 net.cpp:406] BatchNorm7 <- Convolution7
I1005 20:35:19.905541 10142 net.cpp:367] BatchNorm7 -> Convolution7 (in-place)
I1005 20:35:19.905710 10142 net.cpp:122] Setting up BatchNorm7
I1005 20:35:19.905715 10142 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 20:35:19.905717 10142 net.cpp:137] Memory required for data: 224052400
I1005 20:35:19.905722 10142 layer_factory.hpp:77] Creating layer Scale7
I1005 20:35:19.905726 10142 net.cpp:84] Creating Layer Scale7
I1005 20:35:19.905728 10142 net.cpp:406] Scale7 <- Convolution7
I1005 20:35:19.905732 10142 net.cpp:367] Scale7 -> Convolution7 (in-place)
I1005 20:35:19.905763 10142 layer_factory.hpp:77] Creating layer Scale7
I1005 20:35:19.905845 10142 net.cpp:122] Setting up Scale7
I1005 20:35:19.905850 10142 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 20:35:19.905853 10142 net.cpp:137] Memory required for data: 230606000
I1005 20:35:19.905856 10142 layer_factory.hpp:77] Creating layer Eltwise3
I1005 20:35:19.905860 10142 net.cpp:84] Creating Layer Eltwise3
I1005 20:35:19.905864 10142 net.cpp:406] Eltwise3 <- Eltwise2_ReLU5_0_split_1
I1005 20:35:19.905866 10142 net.cpp:406] Eltwise3 <- Convolution7
I1005 20:35:19.905869 10142 net.cpp:380] Eltwise3 -> Eltwise3
I1005 20:35:19.905887 10142 net.cpp:122] Setting up Eltwise3
I1005 20:35:19.905890 10142 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 20:35:19.905892 10142 net.cpp:137] Memory required for data: 237159600
I1005 20:35:19.905894 10142 layer_factory.hpp:77] Creating layer ReLU7
I1005 20:35:19.905900 10142 net.cpp:84] Creating Layer ReLU7
I1005 20:35:19.905901 10142 net.cpp:406] ReLU7 <- Eltwise3
I1005 20:35:19.905905 10142 net.cpp:367] ReLU7 -> Eltwise3 (in-place)
I1005 20:35:19.906030 10142 net.cpp:122] Setting up ReLU7
I1005 20:35:19.906036 10142 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 20:35:19.906038 10142 net.cpp:137] Memory required for data: 243713200
I1005 20:35:19.906041 10142 layer_factory.hpp:77] Creating layer Eltwise3_ReLU7_0_split
I1005 20:35:19.906045 10142 net.cpp:84] Creating Layer Eltwise3_ReLU7_0_split
I1005 20:35:19.906049 10142 net.cpp:406] Eltwise3_ReLU7_0_split <- Eltwise3
I1005 20:35:19.906051 10142 net.cpp:380] Eltwise3_ReLU7_0_split -> Eltwise3_ReLU7_0_split_0
I1005 20:35:19.906055 10142 net.cpp:380] Eltwise3_ReLU7_0_split -> Eltwise3_ReLU7_0_split_1
I1005 20:35:19.906085 10142 net.cpp:122] Setting up Eltwise3_ReLU7_0_split
I1005 20:35:19.906097 10142 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 20:35:19.906100 10142 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 20:35:19.906102 10142 net.cpp:137] Memory required for data: 256820400
I1005 20:35:19.906105 10142 layer_factory.hpp:77] Creating layer Convolution8
I1005 20:35:19.906111 10142 net.cpp:84] Creating Layer Convolution8
I1005 20:35:19.906114 10142 net.cpp:406] Convolution8 <- Eltwise3_ReLU7_0_split_0
I1005 20:35:19.906119 10142 net.cpp:380] Convolution8 -> Convolution8
I1005 20:35:19.912518 10142 net.cpp:122] Setting up Convolution8
I1005 20:35:19.912528 10142 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 20:35:19.912530 10142 net.cpp:137] Memory required for data: 263374000
I1005 20:35:19.912534 10142 layer_factory.hpp:77] Creating layer BatchNorm8
I1005 20:35:19.912539 10142 net.cpp:84] Creating Layer BatchNorm8
I1005 20:35:19.912541 10142 net.cpp:406] BatchNorm8 <- Convolution8
I1005 20:35:19.912547 10142 net.cpp:367] BatchNorm8 -> Convolution8 (in-place)
I1005 20:35:19.912691 10142 net.cpp:122] Setting up BatchNorm8
I1005 20:35:19.912695 10142 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 20:35:19.912698 10142 net.cpp:137] Memory required for data: 269927600
I1005 20:35:19.912703 10142 layer_factory.hpp:77] Creating layer Scale8
I1005 20:35:19.912706 10142 net.cpp:84] Creating Layer Scale8
I1005 20:35:19.912708 10142 net.cpp:406] Scale8 <- Convolution8
I1005 20:35:19.912711 10142 net.cpp:367] Scale8 -> Convolution8 (in-place)
I1005 20:35:19.912740 10142 layer_factory.hpp:77] Creating layer Scale8
I1005 20:35:19.912820 10142 net.cpp:122] Setting up Scale8
I1005 20:35:19.912824 10142 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 20:35:19.912827 10142 net.cpp:137] Memory required for data: 276481200
I1005 20:35:19.912830 10142 layer_factory.hpp:77] Creating layer ReLU8
I1005 20:35:19.912833 10142 net.cpp:84] Creating Layer ReLU8
I1005 20:35:19.912835 10142 net.cpp:406] ReLU8 <- Convolution8
I1005 20:35:19.912839 10142 net.cpp:367] ReLU8 -> Convolution8 (in-place)
I1005 20:35:19.914623 10142 net.cpp:122] Setting up ReLU8
I1005 20:35:19.914630 10142 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 20:35:19.914633 10142 net.cpp:137] Memory required for data: 283034800
I1005 20:35:19.914634 10142 layer_factory.hpp:77] Creating layer Convolution9
I1005 20:35:19.914641 10142 net.cpp:84] Creating Layer Convolution9
I1005 20:35:19.914644 10142 net.cpp:406] Convolution9 <- Convolution8
I1005 20:35:19.914649 10142 net.cpp:380] Convolution9 -> Convolution9
I1005 20:35:19.921247 10142 net.cpp:122] Setting up Convolution9
I1005 20:35:19.921255 10142 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 20:35:19.921258 10142 net.cpp:137] Memory required for data: 289588400
I1005 20:35:19.921263 10142 layer_factory.hpp:77] Creating layer BatchNorm9
I1005 20:35:19.921268 10142 net.cpp:84] Creating Layer BatchNorm9
I1005 20:35:19.921272 10142 net.cpp:406] BatchNorm9 <- Convolution9
I1005 20:35:19.921274 10142 net.cpp:367] BatchNorm9 -> Convolution9 (in-place)
I1005 20:35:19.921418 10142 net.cpp:122] Setting up BatchNorm9
I1005 20:35:19.921423 10142 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 20:35:19.921425 10142 net.cpp:137] Memory required for data: 296142000
I1005 20:35:19.921430 10142 layer_factory.hpp:77] Creating layer Scale9
I1005 20:35:19.921434 10142 net.cpp:84] Creating Layer Scale9
I1005 20:35:19.921437 10142 net.cpp:406] Scale9 <- Convolution9
I1005 20:35:19.921440 10142 net.cpp:367] Scale9 -> Convolution9 (in-place)
I1005 20:35:19.921470 10142 layer_factory.hpp:77] Creating layer Scale9
I1005 20:35:19.921551 10142 net.cpp:122] Setting up Scale9
I1005 20:35:19.921555 10142 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 20:35:19.921557 10142 net.cpp:137] Memory required for data: 302695600
I1005 20:35:19.921561 10142 layer_factory.hpp:77] Creating layer Eltwise4
I1005 20:35:19.921566 10142 net.cpp:84] Creating Layer Eltwise4
I1005 20:35:19.921569 10142 net.cpp:406] Eltwise4 <- Eltwise3_ReLU7_0_split_1
I1005 20:35:19.921578 10142 net.cpp:406] Eltwise4 <- Convolution9
I1005 20:35:19.921582 10142 net.cpp:380] Eltwise4 -> Eltwise4
I1005 20:35:19.921602 10142 net.cpp:122] Setting up Eltwise4
I1005 20:35:19.921605 10142 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 20:35:19.921607 10142 net.cpp:137] Memory required for data: 309249200
I1005 20:35:19.921609 10142 layer_factory.hpp:77] Creating layer ReLU9
I1005 20:35:19.921612 10142 net.cpp:84] Creating Layer ReLU9
I1005 20:35:19.921614 10142 net.cpp:406] ReLU9 <- Eltwise4
I1005 20:35:19.921618 10142 net.cpp:367] ReLU9 -> Eltwise4 (in-place)
I1005 20:35:19.923348 10142 net.cpp:122] Setting up ReLU9
I1005 20:35:19.923355 10142 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 20:35:19.923357 10142 net.cpp:137] Memory required for data: 315802800
I1005 20:35:19.923359 10142 layer_factory.hpp:77] Creating layer Eltwise4_ReLU9_0_split
I1005 20:35:19.923363 10142 net.cpp:84] Creating Layer Eltwise4_ReLU9_0_split
I1005 20:35:19.923365 10142 net.cpp:406] Eltwise4_ReLU9_0_split <- Eltwise4
I1005 20:35:19.923370 10142 net.cpp:380] Eltwise4_ReLU9_0_split -> Eltwise4_ReLU9_0_split_0
I1005 20:35:19.923374 10142 net.cpp:380] Eltwise4_ReLU9_0_split -> Eltwise4_ReLU9_0_split_1
I1005 20:35:19.923404 10142 net.cpp:122] Setting up Eltwise4_ReLU9_0_split
I1005 20:35:19.923408 10142 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 20:35:19.923410 10142 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 20:35:19.923413 10142 net.cpp:137] Memory required for data: 328910000
I1005 20:35:19.923414 10142 layer_factory.hpp:77] Creating layer Convolution10
I1005 20:35:19.923422 10142 net.cpp:84] Creating Layer Convolution10
I1005 20:35:19.923424 10142 net.cpp:406] Convolution10 <- Eltwise4_ReLU9_0_split_0
I1005 20:35:19.923429 10142 net.cpp:380] Convolution10 -> Convolution10
I1005 20:35:19.930037 10142 net.cpp:122] Setting up Convolution10
I1005 20:35:19.930047 10142 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 20:35:19.930048 10142 net.cpp:137] Memory required for data: 335463600
I1005 20:35:19.930060 10142 layer_factory.hpp:77] Creating layer BatchNorm10
I1005 20:35:19.930066 10142 net.cpp:84] Creating Layer BatchNorm10
I1005 20:35:19.930069 10142 net.cpp:406] BatchNorm10 <- Convolution10
I1005 20:35:19.930073 10142 net.cpp:367] BatchNorm10 -> Convolution10 (in-place)
I1005 20:35:19.930218 10142 net.cpp:122] Setting up BatchNorm10
I1005 20:35:19.930222 10142 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 20:35:19.930225 10142 net.cpp:137] Memory required for data: 342017200
I1005 20:35:19.930230 10142 layer_factory.hpp:77] Creating layer Scale10
I1005 20:35:19.930233 10142 net.cpp:84] Creating Layer Scale10
I1005 20:35:19.930236 10142 net.cpp:406] Scale10 <- Convolution10
I1005 20:35:19.930239 10142 net.cpp:367] Scale10 -> Convolution10 (in-place)
I1005 20:35:19.930269 10142 layer_factory.hpp:77] Creating layer Scale10
I1005 20:35:19.930387 10142 net.cpp:122] Setting up Scale10
I1005 20:35:19.930395 10142 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 20:35:19.930399 10142 net.cpp:137] Memory required for data: 348570800
I1005 20:35:19.930405 10142 layer_factory.hpp:77] Creating layer ReLU10
I1005 20:35:19.930411 10142 net.cpp:84] Creating Layer ReLU10
I1005 20:35:19.930415 10142 net.cpp:406] ReLU10 <- Convolution10
I1005 20:35:19.930419 10142 net.cpp:367] ReLU10 -> Convolution10 (in-place)
I1005 20:35:19.932160 10142 net.cpp:122] Setting up ReLU10
I1005 20:35:19.932168 10142 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 20:35:19.932171 10142 net.cpp:137] Memory required for data: 355124400
I1005 20:35:19.932183 10142 layer_factory.hpp:77] Creating layer Convolution11
I1005 20:35:19.932189 10142 net.cpp:84] Creating Layer Convolution11
I1005 20:35:19.932193 10142 net.cpp:406] Convolution11 <- Convolution10
I1005 20:35:19.932196 10142 net.cpp:380] Convolution11 -> Convolution11
I1005 20:35:19.939375 10142 net.cpp:122] Setting up Convolution11
I1005 20:35:19.939385 10142 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 20:35:19.939388 10142 net.cpp:137] Memory required for data: 361678000
I1005 20:35:19.939401 10142 layer_factory.hpp:77] Creating layer BatchNorm11
I1005 20:35:19.939407 10142 net.cpp:84] Creating Layer BatchNorm11
I1005 20:35:19.939410 10142 net.cpp:406] BatchNorm11 <- Convolution11
I1005 20:35:19.939414 10142 net.cpp:367] BatchNorm11 -> Convolution11 (in-place)
I1005 20:35:19.939566 10142 net.cpp:122] Setting up BatchNorm11
I1005 20:35:19.939570 10142 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 20:35:19.939574 10142 net.cpp:137] Memory required for data: 368231600
I1005 20:35:19.939579 10142 layer_factory.hpp:77] Creating layer Scale11
I1005 20:35:19.939584 10142 net.cpp:84] Creating Layer Scale11
I1005 20:35:19.939585 10142 net.cpp:406] Scale11 <- Convolution11
I1005 20:35:19.939589 10142 net.cpp:367] Scale11 -> Convolution11 (in-place)
I1005 20:35:19.939620 10142 layer_factory.hpp:77] Creating layer Scale11
I1005 20:35:19.939705 10142 net.cpp:122] Setting up Scale11
I1005 20:35:19.939709 10142 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 20:35:19.939712 10142 net.cpp:137] Memory required for data: 374785200
I1005 20:35:19.939715 10142 layer_factory.hpp:77] Creating layer Eltwise5
I1005 20:35:19.939719 10142 net.cpp:84] Creating Layer Eltwise5
I1005 20:35:19.939723 10142 net.cpp:406] Eltwise5 <- Eltwise4_ReLU9_0_split_1
I1005 20:35:19.939725 10142 net.cpp:406] Eltwise5 <- Convolution11
I1005 20:35:19.939729 10142 net.cpp:380] Eltwise5 -> Eltwise5
I1005 20:35:19.939746 10142 net.cpp:122] Setting up Eltwise5
I1005 20:35:19.939750 10142 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 20:35:19.939752 10142 net.cpp:137] Memory required for data: 381338800
I1005 20:35:19.939754 10142 layer_factory.hpp:77] Creating layer ReLU11
I1005 20:35:19.939759 10142 net.cpp:84] Creating Layer ReLU11
I1005 20:35:19.939760 10142 net.cpp:406] ReLU11 <- Eltwise5
I1005 20:35:19.939764 10142 net.cpp:367] ReLU11 -> Eltwise5 (in-place)
I1005 20:35:19.941514 10142 net.cpp:122] Setting up ReLU11
I1005 20:35:19.941522 10142 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 20:35:19.941524 10142 net.cpp:137] Memory required for data: 387892400
I1005 20:35:19.941527 10142 layer_factory.hpp:77] Creating layer Eltwise5_ReLU11_0_split
I1005 20:35:19.941530 10142 net.cpp:84] Creating Layer Eltwise5_ReLU11_0_split
I1005 20:35:19.941534 10142 net.cpp:406] Eltwise5_ReLU11_0_split <- Eltwise5
I1005 20:35:19.941536 10142 net.cpp:380] Eltwise5_ReLU11_0_split -> Eltwise5_ReLU11_0_split_0
I1005 20:35:19.941541 10142 net.cpp:380] Eltwise5_ReLU11_0_split -> Eltwise5_ReLU11_0_split_1
I1005 20:35:19.941573 10142 net.cpp:122] Setting up Eltwise5_ReLU11_0_split
I1005 20:35:19.941578 10142 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 20:35:19.941581 10142 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1005 20:35:19.941582 10142 net.cpp:137] Memory required for data: 400999600
I1005 20:35:19.941584 10142 layer_factory.hpp:77] Creating layer Convolution12
I1005 20:35:19.941591 10142 net.cpp:84] Creating Layer Convolution12
I1005 20:35:19.941594 10142 net.cpp:406] Convolution12 <- Eltwise5_ReLU11_0_split_0
I1005 20:35:19.941598 10142 net.cpp:380] Convolution12 -> Convolution12
I1005 20:35:19.945471 10142 net.cpp:122] Setting up Convolution12
I1005 20:35:19.945479 10142 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 20:35:19.945482 10142 net.cpp:137] Memory required for data: 404276400
I1005 20:35:19.945485 10142 layer_factory.hpp:77] Creating layer BatchNorm12
I1005 20:35:19.945490 10142 net.cpp:84] Creating Layer BatchNorm12
I1005 20:35:19.945493 10142 net.cpp:406] BatchNorm12 <- Convolution12
I1005 20:35:19.945497 10142 net.cpp:367] BatchNorm12 -> Convolution12 (in-place)
I1005 20:35:19.945639 10142 net.cpp:122] Setting up BatchNorm12
I1005 20:35:19.945643 10142 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 20:35:19.945646 10142 net.cpp:137] Memory required for data: 407553200
I1005 20:35:19.945650 10142 layer_factory.hpp:77] Creating layer Scale12
I1005 20:35:19.945654 10142 net.cpp:84] Creating Layer Scale12
I1005 20:35:19.945657 10142 net.cpp:406] Scale12 <- Convolution12
I1005 20:35:19.945667 10142 net.cpp:367] Scale12 -> Convolution12 (in-place)
I1005 20:35:19.945698 10142 layer_factory.hpp:77] Creating layer Scale12
I1005 20:35:19.945780 10142 net.cpp:122] Setting up Scale12
I1005 20:35:19.945785 10142 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 20:35:19.945786 10142 net.cpp:137] Memory required for data: 410830000
I1005 20:35:19.945791 10142 layer_factory.hpp:77] Creating layer Convolution13
I1005 20:35:19.945798 10142 net.cpp:84] Creating Layer Convolution13
I1005 20:35:19.945801 10142 net.cpp:406] Convolution13 <- Eltwise5_ReLU11_0_split_1
I1005 20:35:19.945804 10142 net.cpp:380] Convolution13 -> Convolution13
I1005 20:35:19.950937 10142 net.cpp:122] Setting up Convolution13
I1005 20:35:19.950947 10142 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 20:35:19.950949 10142 net.cpp:137] Memory required for data: 414106800
I1005 20:35:19.950953 10142 layer_factory.hpp:77] Creating layer BatchNorm13
I1005 20:35:19.950958 10142 net.cpp:84] Creating Layer BatchNorm13
I1005 20:35:19.950961 10142 net.cpp:406] BatchNorm13 <- Convolution13
I1005 20:35:19.950965 10142 net.cpp:367] BatchNorm13 -> Convolution13 (in-place)
I1005 20:35:19.951107 10142 net.cpp:122] Setting up BatchNorm13
I1005 20:35:19.951110 10142 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 20:35:19.951113 10142 net.cpp:137] Memory required for data: 417383600
I1005 20:35:19.951118 10142 layer_factory.hpp:77] Creating layer Scale13
I1005 20:35:19.951122 10142 net.cpp:84] Creating Layer Scale13
I1005 20:35:19.951124 10142 net.cpp:406] Scale13 <- Convolution13
I1005 20:35:19.951128 10142 net.cpp:367] Scale13 -> Convolution13 (in-place)
I1005 20:35:19.951156 10142 layer_factory.hpp:77] Creating layer Scale13
I1005 20:35:19.951239 10142 net.cpp:122] Setting up Scale13
I1005 20:35:19.951243 10142 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 20:35:19.951246 10142 net.cpp:137] Memory required for data: 420660400
I1005 20:35:19.951248 10142 layer_factory.hpp:77] Creating layer ReLU12
I1005 20:35:19.951253 10142 net.cpp:84] Creating Layer ReLU12
I1005 20:35:19.951256 10142 net.cpp:406] ReLU12 <- Convolution13
I1005 20:35:19.951258 10142 net.cpp:367] ReLU12 -> Convolution13 (in-place)
I1005 20:35:19.953025 10142 net.cpp:122] Setting up ReLU12
I1005 20:35:19.953032 10142 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 20:35:19.953035 10142 net.cpp:137] Memory required for data: 423937200
I1005 20:35:19.953038 10142 layer_factory.hpp:77] Creating layer Convolution14
I1005 20:35:19.953049 10142 net.cpp:84] Creating Layer Convolution14
I1005 20:35:19.953052 10142 net.cpp:406] Convolution14 <- Convolution13
I1005 20:35:19.953058 10142 net.cpp:380] Convolution14 -> Convolution14
I1005 20:35:19.958750 10142 net.cpp:122] Setting up Convolution14
I1005 20:35:19.958760 10142 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 20:35:19.958761 10142 net.cpp:137] Memory required for data: 427214000
I1005 20:35:19.958766 10142 layer_factory.hpp:77] Creating layer BatchNorm14
I1005 20:35:19.958771 10142 net.cpp:84] Creating Layer BatchNorm14
I1005 20:35:19.958775 10142 net.cpp:406] BatchNorm14 <- Convolution14
I1005 20:35:19.958778 10142 net.cpp:367] BatchNorm14 -> Convolution14 (in-place)
I1005 20:35:19.958927 10142 net.cpp:122] Setting up BatchNorm14
I1005 20:35:19.958932 10142 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 20:35:19.958935 10142 net.cpp:137] Memory required for data: 430490800
I1005 20:35:19.958940 10142 layer_factory.hpp:77] Creating layer Scale14
I1005 20:35:19.958945 10142 net.cpp:84] Creating Layer Scale14
I1005 20:35:19.958946 10142 net.cpp:406] Scale14 <- Convolution14
I1005 20:35:19.958950 10142 net.cpp:367] Scale14 -> Convolution14 (in-place)
I1005 20:35:19.958978 10142 layer_factory.hpp:77] Creating layer Scale14
I1005 20:35:19.959060 10142 net.cpp:122] Setting up Scale14
I1005 20:35:19.959064 10142 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 20:35:19.959066 10142 net.cpp:137] Memory required for data: 433767600
I1005 20:35:19.959070 10142 layer_factory.hpp:77] Creating layer Eltwise6
I1005 20:35:19.959082 10142 net.cpp:84] Creating Layer Eltwise6
I1005 20:35:19.959084 10142 net.cpp:406] Eltwise6 <- Convolution12
I1005 20:35:19.959087 10142 net.cpp:406] Eltwise6 <- Convolution14
I1005 20:35:19.959091 10142 net.cpp:380] Eltwise6 -> Eltwise6
I1005 20:35:19.959107 10142 net.cpp:122] Setting up Eltwise6
I1005 20:35:19.959111 10142 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 20:35:19.959112 10142 net.cpp:137] Memory required for data: 437044400
I1005 20:35:19.959115 10142 layer_factory.hpp:77] Creating layer ReLU13
I1005 20:35:19.959120 10142 net.cpp:84] Creating Layer ReLU13
I1005 20:35:19.959121 10142 net.cpp:406] ReLU13 <- Eltwise6
I1005 20:35:19.959125 10142 net.cpp:367] ReLU13 -> Eltwise6 (in-place)
I1005 20:35:19.959244 10142 net.cpp:122] Setting up ReLU13
I1005 20:35:19.959250 10142 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 20:35:19.959252 10142 net.cpp:137] Memory required for data: 440321200
I1005 20:35:19.959255 10142 layer_factory.hpp:77] Creating layer Eltwise6_ReLU13_0_split
I1005 20:35:19.959259 10142 net.cpp:84] Creating Layer Eltwise6_ReLU13_0_split
I1005 20:35:19.959262 10142 net.cpp:406] Eltwise6_ReLU13_0_split <- Eltwise6
I1005 20:35:19.959265 10142 net.cpp:380] Eltwise6_ReLU13_0_split -> Eltwise6_ReLU13_0_split_0
I1005 20:35:19.959270 10142 net.cpp:380] Eltwise6_ReLU13_0_split -> Eltwise6_ReLU13_0_split_1
I1005 20:35:19.959298 10142 net.cpp:122] Setting up Eltwise6_ReLU13_0_split
I1005 20:35:19.959302 10142 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 20:35:19.959306 10142 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 20:35:19.959307 10142 net.cpp:137] Memory required for data: 446874800
I1005 20:35:19.959309 10142 layer_factory.hpp:77] Creating layer Convolution15
I1005 20:35:19.959316 10142 net.cpp:84] Creating Layer Convolution15
I1005 20:35:19.959318 10142 net.cpp:406] Convolution15 <- Eltwise6_ReLU13_0_split_0
I1005 20:35:19.959322 10142 net.cpp:380] Convolution15 -> Convolution15
I1005 20:35:19.966156 10142 net.cpp:122] Setting up Convolution15
I1005 20:35:19.966168 10142 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 20:35:19.966171 10142 net.cpp:137] Memory required for data: 450151600
I1005 20:35:19.966178 10142 layer_factory.hpp:77] Creating layer BatchNorm15
I1005 20:35:19.966187 10142 net.cpp:84] Creating Layer BatchNorm15
I1005 20:35:19.966192 10142 net.cpp:406] BatchNorm15 <- Convolution15
I1005 20:35:19.966194 10142 net.cpp:367] BatchNorm15 -> Convolution15 (in-place)
I1005 20:35:19.966351 10142 net.cpp:122] Setting up BatchNorm15
I1005 20:35:19.966356 10142 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 20:35:19.966359 10142 net.cpp:137] Memory required for data: 453428400
I1005 20:35:19.966363 10142 layer_factory.hpp:77] Creating layer Scale15
I1005 20:35:19.966368 10142 net.cpp:84] Creating Layer Scale15
I1005 20:35:19.966370 10142 net.cpp:406] Scale15 <- Convolution15
I1005 20:35:19.966374 10142 net.cpp:367] Scale15 -> Convolution15 (in-place)
I1005 20:35:19.966406 10142 layer_factory.hpp:77] Creating layer Scale15
I1005 20:35:19.966491 10142 net.cpp:122] Setting up Scale15
I1005 20:35:19.966496 10142 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 20:35:19.966498 10142 net.cpp:137] Memory required for data: 456705200
I1005 20:35:19.966502 10142 layer_factory.hpp:77] Creating layer ReLU14
I1005 20:35:19.966506 10142 net.cpp:84] Creating Layer ReLU14
I1005 20:35:19.966509 10142 net.cpp:406] ReLU14 <- Convolution15
I1005 20:35:19.966512 10142 net.cpp:367] ReLU14 -> Convolution15 (in-place)
I1005 20:35:19.968221 10142 net.cpp:122] Setting up ReLU14
I1005 20:35:19.968247 10142 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 20:35:19.968250 10142 net.cpp:137] Memory required for data: 459982000
I1005 20:35:19.968253 10142 layer_factory.hpp:77] Creating layer Convolution16
I1005 20:35:19.968266 10142 net.cpp:84] Creating Layer Convolution16
I1005 20:35:19.968278 10142 net.cpp:406] Convolution16 <- Convolution15
I1005 20:35:19.968284 10142 net.cpp:380] Convolution16 -> Convolution16
I1005 20:35:19.975144 10142 net.cpp:122] Setting up Convolution16
I1005 20:35:19.975172 10142 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 20:35:19.975175 10142 net.cpp:137] Memory required for data: 463258800
I1005 20:35:19.975181 10142 layer_factory.hpp:77] Creating layer BatchNorm16
I1005 20:35:19.975188 10142 net.cpp:84] Creating Layer BatchNorm16
I1005 20:35:19.975191 10142 net.cpp:406] BatchNorm16 <- Convolution16
I1005 20:35:19.975195 10142 net.cpp:367] BatchNorm16 -> Convolution16 (in-place)
I1005 20:35:19.975347 10142 net.cpp:122] Setting up BatchNorm16
I1005 20:35:19.975352 10142 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 20:35:19.975353 10142 net.cpp:137] Memory required for data: 466535600
I1005 20:35:19.975359 10142 layer_factory.hpp:77] Creating layer Scale16
I1005 20:35:19.975364 10142 net.cpp:84] Creating Layer Scale16
I1005 20:35:19.975366 10142 net.cpp:406] Scale16 <- Convolution16
I1005 20:35:19.975369 10142 net.cpp:367] Scale16 -> Convolution16 (in-place)
I1005 20:35:19.975404 10142 layer_factory.hpp:77] Creating layer Scale16
I1005 20:35:19.975491 10142 net.cpp:122] Setting up Scale16
I1005 20:35:19.975494 10142 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 20:35:19.975497 10142 net.cpp:137] Memory required for data: 469812400
I1005 20:35:19.975500 10142 layer_factory.hpp:77] Creating layer Eltwise7
I1005 20:35:19.975505 10142 net.cpp:84] Creating Layer Eltwise7
I1005 20:35:19.975508 10142 net.cpp:406] Eltwise7 <- Eltwise6_ReLU13_0_split_1
I1005 20:35:19.975512 10142 net.cpp:406] Eltwise7 <- Convolution16
I1005 20:35:19.975515 10142 net.cpp:380] Eltwise7 -> Eltwise7
I1005 20:35:19.975529 10142 net.cpp:122] Setting up Eltwise7
I1005 20:35:19.975533 10142 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 20:35:19.975535 10142 net.cpp:137] Memory required for data: 473089200
I1005 20:35:19.975538 10142 layer_factory.hpp:77] Creating layer ReLU15
I1005 20:35:19.975541 10142 net.cpp:84] Creating Layer ReLU15
I1005 20:35:19.975543 10142 net.cpp:406] ReLU15 <- Eltwise7
I1005 20:35:19.975548 10142 net.cpp:367] ReLU15 -> Eltwise7 (in-place)
I1005 20:35:19.977257 10142 net.cpp:122] Setting up ReLU15
I1005 20:35:19.977262 10142 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 20:35:19.977264 10142 net.cpp:137] Memory required for data: 476366000
I1005 20:35:19.977267 10142 layer_factory.hpp:77] Creating layer Eltwise7_ReLU15_0_split
I1005 20:35:19.977272 10142 net.cpp:84] Creating Layer Eltwise7_ReLU15_0_split
I1005 20:35:19.977273 10142 net.cpp:406] Eltwise7_ReLU15_0_split <- Eltwise7
I1005 20:35:19.977277 10142 net.cpp:380] Eltwise7_ReLU15_0_split -> Eltwise7_ReLU15_0_split_0
I1005 20:35:19.977282 10142 net.cpp:380] Eltwise7_ReLU15_0_split -> Eltwise7_ReLU15_0_split_1
I1005 20:35:19.977311 10142 net.cpp:122] Setting up Eltwise7_ReLU15_0_split
I1005 20:35:19.977315 10142 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 20:35:19.977319 10142 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 20:35:19.977319 10142 net.cpp:137] Memory required for data: 482919600
I1005 20:35:19.977322 10142 layer_factory.hpp:77] Creating layer Convolution17
I1005 20:35:19.977330 10142 net.cpp:84] Creating Layer Convolution17
I1005 20:35:19.977334 10142 net.cpp:406] Convolution17 <- Eltwise7_ReLU15_0_split_0
I1005 20:35:19.977337 10142 net.cpp:380] Convolution17 -> Convolution17
I1005 20:35:19.983952 10142 net.cpp:122] Setting up Convolution17
I1005 20:35:19.983961 10142 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 20:35:19.983964 10142 net.cpp:137] Memory required for data: 486196400
I1005 20:35:19.983968 10142 layer_factory.hpp:77] Creating layer BatchNorm17
I1005 20:35:19.983973 10142 net.cpp:84] Creating Layer BatchNorm17
I1005 20:35:19.983976 10142 net.cpp:406] BatchNorm17 <- Convolution17
I1005 20:35:19.983980 10142 net.cpp:367] BatchNorm17 -> Convolution17 (in-place)
I1005 20:35:19.984125 10142 net.cpp:122] Setting up BatchNorm17
I1005 20:35:19.984130 10142 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 20:35:19.984133 10142 net.cpp:137] Memory required for data: 489473200
I1005 20:35:19.984136 10142 layer_factory.hpp:77] Creating layer Scale17
I1005 20:35:19.984148 10142 net.cpp:84] Creating Layer Scale17
I1005 20:35:19.984151 10142 net.cpp:406] Scale17 <- Convolution17
I1005 20:35:19.984154 10142 net.cpp:367] Scale17 -> Convolution17 (in-place)
I1005 20:35:19.984186 10142 layer_factory.hpp:77] Creating layer Scale17
I1005 20:35:19.984271 10142 net.cpp:122] Setting up Scale17
I1005 20:35:19.984275 10142 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 20:35:19.984277 10142 net.cpp:137] Memory required for data: 492750000
I1005 20:35:19.984280 10142 layer_factory.hpp:77] Creating layer ReLU16
I1005 20:35:19.984284 10142 net.cpp:84] Creating Layer ReLU16
I1005 20:35:19.984287 10142 net.cpp:406] ReLU16 <- Convolution17
I1005 20:35:19.984290 10142 net.cpp:367] ReLU16 -> Convolution17 (in-place)
I1005 20:35:19.986066 10142 net.cpp:122] Setting up ReLU16
I1005 20:35:19.986073 10142 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 20:35:19.986074 10142 net.cpp:137] Memory required for data: 496026800
I1005 20:35:19.986078 10142 layer_factory.hpp:77] Creating layer Convolution18
I1005 20:35:19.986085 10142 net.cpp:84] Creating Layer Convolution18
I1005 20:35:19.986088 10142 net.cpp:406] Convolution18 <- Convolution17
I1005 20:35:19.986093 10142 net.cpp:380] Convolution18 -> Convolution18
I1005 20:35:19.992804 10142 net.cpp:122] Setting up Convolution18
I1005 20:35:19.992815 10142 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 20:35:19.992817 10142 net.cpp:137] Memory required for data: 499303600
I1005 20:35:19.992821 10142 layer_factory.hpp:77] Creating layer BatchNorm18
I1005 20:35:19.992827 10142 net.cpp:84] Creating Layer BatchNorm18
I1005 20:35:19.992830 10142 net.cpp:406] BatchNorm18 <- Convolution18
I1005 20:35:19.992835 10142 net.cpp:367] BatchNorm18 -> Convolution18 (in-place)
I1005 20:35:19.992990 10142 net.cpp:122] Setting up BatchNorm18
I1005 20:35:19.992995 10142 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 20:35:19.992996 10142 net.cpp:137] Memory required for data: 502580400
I1005 20:35:19.993001 10142 layer_factory.hpp:77] Creating layer Scale18
I1005 20:35:19.993005 10142 net.cpp:84] Creating Layer Scale18
I1005 20:35:19.993008 10142 net.cpp:406] Scale18 <- Convolution18
I1005 20:35:19.993011 10142 net.cpp:367] Scale18 -> Convolution18 (in-place)
I1005 20:35:19.993042 10142 layer_factory.hpp:77] Creating layer Scale18
I1005 20:35:19.993129 10142 net.cpp:122] Setting up Scale18
I1005 20:35:19.993134 10142 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 20:35:19.993137 10142 net.cpp:137] Memory required for data: 505857200
I1005 20:35:19.993140 10142 layer_factory.hpp:77] Creating layer Eltwise8
I1005 20:35:19.993144 10142 net.cpp:84] Creating Layer Eltwise8
I1005 20:35:19.993147 10142 net.cpp:406] Eltwise8 <- Eltwise7_ReLU15_0_split_1
I1005 20:35:19.993150 10142 net.cpp:406] Eltwise8 <- Convolution18
I1005 20:35:19.993154 10142 net.cpp:380] Eltwise8 -> Eltwise8
I1005 20:35:19.993168 10142 net.cpp:122] Setting up Eltwise8
I1005 20:35:19.993172 10142 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 20:35:19.993175 10142 net.cpp:137] Memory required for data: 509134000
I1005 20:35:19.993176 10142 layer_factory.hpp:77] Creating layer ReLU17
I1005 20:35:19.993180 10142 net.cpp:84] Creating Layer ReLU17
I1005 20:35:19.993182 10142 net.cpp:406] ReLU17 <- Eltwise8
I1005 20:35:19.993186 10142 net.cpp:367] ReLU17 -> Eltwise8 (in-place)
I1005 20:35:19.994905 10142 net.cpp:122] Setting up ReLU17
I1005 20:35:19.994912 10142 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 20:35:19.994915 10142 net.cpp:137] Memory required for data: 512410800
I1005 20:35:19.994917 10142 layer_factory.hpp:77] Creating layer Eltwise8_ReLU17_0_split
I1005 20:35:19.994921 10142 net.cpp:84] Creating Layer Eltwise8_ReLU17_0_split
I1005 20:35:19.994923 10142 net.cpp:406] Eltwise8_ReLU17_0_split <- Eltwise8
I1005 20:35:19.994927 10142 net.cpp:380] Eltwise8_ReLU17_0_split -> Eltwise8_ReLU17_0_split_0
I1005 20:35:19.994932 10142 net.cpp:380] Eltwise8_ReLU17_0_split -> Eltwise8_ReLU17_0_split_1
I1005 20:35:19.994963 10142 net.cpp:122] Setting up Eltwise8_ReLU17_0_split
I1005 20:35:19.994976 10142 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 20:35:19.994981 10142 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 20:35:19.994982 10142 net.cpp:137] Memory required for data: 518964400
I1005 20:35:19.994984 10142 layer_factory.hpp:77] Creating layer Convolution19
I1005 20:35:19.994992 10142 net.cpp:84] Creating Layer Convolution19
I1005 20:35:19.994994 10142 net.cpp:406] Convolution19 <- Eltwise8_ReLU17_0_split_0
I1005 20:35:19.994998 10142 net.cpp:380] Convolution19 -> Convolution19
I1005 20:35:20.000177 10142 net.cpp:122] Setting up Convolution19
I1005 20:35:20.000187 10142 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 20:35:20.000200 10142 net.cpp:137] Memory required for data: 522241200
I1005 20:35:20.000205 10142 layer_factory.hpp:77] Creating layer BatchNorm19
I1005 20:35:20.000211 10142 net.cpp:84] Creating Layer BatchNorm19
I1005 20:35:20.000224 10142 net.cpp:406] BatchNorm19 <- Convolution19
I1005 20:35:20.000229 10142 net.cpp:367] BatchNorm19 -> Convolution19 (in-place)
I1005 20:35:20.000401 10142 net.cpp:122] Setting up BatchNorm19
I1005 20:35:20.000407 10142 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 20:35:20.000421 10142 net.cpp:137] Memory required for data: 525518000
I1005 20:35:20.000438 10142 layer_factory.hpp:77] Creating layer Scale19
I1005 20:35:20.000443 10142 net.cpp:84] Creating Layer Scale19
I1005 20:35:20.000455 10142 net.cpp:406] Scale19 <- Convolution19
I1005 20:35:20.000458 10142 net.cpp:367] Scale19 -> Convolution19 (in-place)
I1005 20:35:20.000514 10142 layer_factory.hpp:77] Creating layer Scale19
I1005 20:35:20.000624 10142 net.cpp:122] Setting up Scale19
I1005 20:35:20.000629 10142 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 20:35:20.000641 10142 net.cpp:137] Memory required for data: 528794800
I1005 20:35:20.000645 10142 layer_factory.hpp:77] Creating layer ReLU18
I1005 20:35:20.000651 10142 net.cpp:84] Creating Layer ReLU18
I1005 20:35:20.000656 10142 net.cpp:406] ReLU18 <- Convolution19
I1005 20:35:20.000661 10142 net.cpp:367] ReLU18 -> Convolution19 (in-place)
I1005 20:35:20.001133 10142 net.cpp:122] Setting up ReLU18
I1005 20:35:20.001143 10142 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 20:35:20.001157 10142 net.cpp:137] Memory required for data: 532071600
I1005 20:35:20.001159 10142 layer_factory.hpp:77] Creating layer Convolution20
I1005 20:35:20.001168 10142 net.cpp:84] Creating Layer Convolution20
I1005 20:35:20.001174 10142 net.cpp:406] Convolution20 <- Convolution19
I1005 20:35:20.001181 10142 net.cpp:380] Convolution20 -> Convolution20
I1005 20:35:20.005838 10142 net.cpp:122] Setting up Convolution20
I1005 20:35:20.005859 10142 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 20:35:20.005862 10142 net.cpp:137] Memory required for data: 535348400
I1005 20:35:20.005868 10142 layer_factory.hpp:77] Creating layer BatchNorm20
I1005 20:35:20.005875 10142 net.cpp:84] Creating Layer BatchNorm20
I1005 20:35:20.005880 10142 net.cpp:406] BatchNorm20 <- Convolution20
I1005 20:35:20.005887 10142 net.cpp:367] BatchNorm20 -> Convolution20 (in-place)
I1005 20:35:20.006052 10142 net.cpp:122] Setting up BatchNorm20
I1005 20:35:20.006058 10142 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 20:35:20.006070 10142 net.cpp:137] Memory required for data: 538625200
I1005 20:35:20.006076 10142 layer_factory.hpp:77] Creating layer Scale20
I1005 20:35:20.006083 10142 net.cpp:84] Creating Layer Scale20
I1005 20:35:20.006088 10142 net.cpp:406] Scale20 <- Convolution20
I1005 20:35:20.006093 10142 net.cpp:367] Scale20 -> Convolution20 (in-place)
I1005 20:35:20.006129 10142 layer_factory.hpp:77] Creating layer Scale20
I1005 20:35:20.006222 10142 net.cpp:122] Setting up Scale20
I1005 20:35:20.006228 10142 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 20:35:20.006232 10142 net.cpp:137] Memory required for data: 541902000
I1005 20:35:20.006239 10142 layer_factory.hpp:77] Creating layer Eltwise9
I1005 20:35:20.006244 10142 net.cpp:84] Creating Layer Eltwise9
I1005 20:35:20.006248 10142 net.cpp:406] Eltwise9 <- Eltwise8_ReLU17_0_split_1
I1005 20:35:20.006263 10142 net.cpp:406] Eltwise9 <- Convolution20
I1005 20:35:20.006271 10142 net.cpp:380] Eltwise9 -> Eltwise9
I1005 20:35:20.006290 10142 net.cpp:122] Setting up Eltwise9
I1005 20:35:20.006295 10142 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 20:35:20.006299 10142 net.cpp:137] Memory required for data: 545178800
I1005 20:35:20.006301 10142 layer_factory.hpp:77] Creating layer ReLU19
I1005 20:35:20.006309 10142 net.cpp:84] Creating Layer ReLU19
I1005 20:35:20.006312 10142 net.cpp:406] ReLU19 <- Eltwise9
I1005 20:35:20.006316 10142 net.cpp:367] ReLU19 -> Eltwise9 (in-place)
I1005 20:35:20.007958 10142 net.cpp:122] Setting up ReLU19
I1005 20:35:20.007967 10142 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 20:35:20.007972 10142 net.cpp:137] Memory required for data: 548455600
I1005 20:35:20.007977 10142 layer_factory.hpp:77] Creating layer Eltwise9_ReLU19_0_split
I1005 20:35:20.007984 10142 net.cpp:84] Creating Layer Eltwise9_ReLU19_0_split
I1005 20:35:20.007988 10142 net.cpp:406] Eltwise9_ReLU19_0_split <- Eltwise9
I1005 20:35:20.007993 10142 net.cpp:380] Eltwise9_ReLU19_0_split -> Eltwise9_ReLU19_0_split_0
I1005 20:35:20.007999 10142 net.cpp:380] Eltwise9_ReLU19_0_split -> Eltwise9_ReLU19_0_split_1
I1005 20:35:20.008035 10142 net.cpp:122] Setting up Eltwise9_ReLU19_0_split
I1005 20:35:20.008040 10142 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 20:35:20.008045 10142 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 20:35:20.008049 10142 net.cpp:137] Memory required for data: 555009200
I1005 20:35:20.008052 10142 layer_factory.hpp:77] Creating layer Convolution21
I1005 20:35:20.008062 10142 net.cpp:84] Creating Layer Convolution21
I1005 20:35:20.008066 10142 net.cpp:406] Convolution21 <- Eltwise9_ReLU19_0_split_0
I1005 20:35:20.008074 10142 net.cpp:380] Convolution21 -> Convolution21
I1005 20:35:20.013691 10142 net.cpp:122] Setting up Convolution21
I1005 20:35:20.013702 10142 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 20:35:20.013706 10142 net.cpp:137] Memory required for data: 558286000
I1005 20:35:20.013711 10142 layer_factory.hpp:77] Creating layer BatchNorm21
I1005 20:35:20.013716 10142 net.cpp:84] Creating Layer BatchNorm21
I1005 20:35:20.013720 10142 net.cpp:406] BatchNorm21 <- Convolution21
I1005 20:35:20.013723 10142 net.cpp:367] BatchNorm21 -> Convolution21 (in-place)
I1005 20:35:20.013873 10142 net.cpp:122] Setting up BatchNorm21
I1005 20:35:20.013878 10142 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 20:35:20.013880 10142 net.cpp:137] Memory required for data: 561562800
I1005 20:35:20.013885 10142 layer_factory.hpp:77] Creating layer Scale21
I1005 20:35:20.013890 10142 net.cpp:84] Creating Layer Scale21
I1005 20:35:20.013892 10142 net.cpp:406] Scale21 <- Convolution21
I1005 20:35:20.013895 10142 net.cpp:367] Scale21 -> Convolution21 (in-place)
I1005 20:35:20.013926 10142 layer_factory.hpp:77] Creating layer Scale21
I1005 20:35:20.014012 10142 net.cpp:122] Setting up Scale21
I1005 20:35:20.014016 10142 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 20:35:20.014019 10142 net.cpp:137] Memory required for data: 564839600
I1005 20:35:20.014022 10142 layer_factory.hpp:77] Creating layer ReLU20
I1005 20:35:20.014026 10142 net.cpp:84] Creating Layer ReLU20
I1005 20:35:20.014029 10142 net.cpp:406] ReLU20 <- Convolution21
I1005 20:35:20.014032 10142 net.cpp:367] ReLU20 -> Convolution21 (in-place)
I1005 20:35:20.014158 10142 net.cpp:122] Setting up ReLU20
I1005 20:35:20.014164 10142 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 20:35:20.014166 10142 net.cpp:137] Memory required for data: 568116400
I1005 20:35:20.014168 10142 layer_factory.hpp:77] Creating layer Convolution22
I1005 20:35:20.014176 10142 net.cpp:84] Creating Layer Convolution22
I1005 20:35:20.014179 10142 net.cpp:406] Convolution22 <- Convolution21
I1005 20:35:20.014183 10142 net.cpp:380] Convolution22 -> Convolution22
I1005 20:35:20.020431 10142 net.cpp:122] Setting up Convolution22
I1005 20:35:20.020440 10142 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 20:35:20.020449 10142 net.cpp:137] Memory required for data: 571393200
I1005 20:35:20.020454 10142 layer_factory.hpp:77] Creating layer BatchNorm22
I1005 20:35:20.020462 10142 net.cpp:84] Creating Layer BatchNorm22
I1005 20:35:20.020464 10142 net.cpp:406] BatchNorm22 <- Convolution22
I1005 20:35:20.020468 10142 net.cpp:367] BatchNorm22 -> Convolution22 (in-place)
I1005 20:35:20.020620 10142 net.cpp:122] Setting up BatchNorm22
I1005 20:35:20.020625 10142 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 20:35:20.020627 10142 net.cpp:137] Memory required for data: 574670000
I1005 20:35:20.020632 10142 layer_factory.hpp:77] Creating layer Scale22
I1005 20:35:20.020637 10142 net.cpp:84] Creating Layer Scale22
I1005 20:35:20.020638 10142 net.cpp:406] Scale22 <- Convolution22
I1005 20:35:20.020642 10142 net.cpp:367] Scale22 -> Convolution22 (in-place)
I1005 20:35:20.020673 10142 layer_factory.hpp:77] Creating layer Scale22
I1005 20:35:20.020759 10142 net.cpp:122] Setting up Scale22
I1005 20:35:20.020764 10142 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 20:35:20.020766 10142 net.cpp:137] Memory required for data: 577946800
I1005 20:35:20.020769 10142 layer_factory.hpp:77] Creating layer Eltwise10
I1005 20:35:20.020773 10142 net.cpp:84] Creating Layer Eltwise10
I1005 20:35:20.020776 10142 net.cpp:406] Eltwise10 <- Eltwise9_ReLU19_0_split_1
I1005 20:35:20.020779 10142 net.cpp:406] Eltwise10 <- Convolution22
I1005 20:35:20.020782 10142 net.cpp:380] Eltwise10 -> Eltwise10
I1005 20:35:20.020798 10142 net.cpp:122] Setting up Eltwise10
I1005 20:35:20.020802 10142 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 20:35:20.020803 10142 net.cpp:137] Memory required for data: 581223600
I1005 20:35:20.020805 10142 layer_factory.hpp:77] Creating layer ReLU21
I1005 20:35:20.020809 10142 net.cpp:84] Creating Layer ReLU21
I1005 20:35:20.020812 10142 net.cpp:406] ReLU21 <- Eltwise10
I1005 20:35:20.020815 10142 net.cpp:367] ReLU21 -> Eltwise10 (in-place)
I1005 20:35:20.022527 10142 net.cpp:122] Setting up ReLU21
I1005 20:35:20.022536 10142 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 20:35:20.022538 10142 net.cpp:137] Memory required for data: 584500400
I1005 20:35:20.022541 10142 layer_factory.hpp:77] Creating layer Eltwise10_ReLU21_0_split
I1005 20:35:20.022545 10142 net.cpp:84] Creating Layer Eltwise10_ReLU21_0_split
I1005 20:35:20.022547 10142 net.cpp:406] Eltwise10_ReLU21_0_split <- Eltwise10
I1005 20:35:20.022552 10142 net.cpp:380] Eltwise10_ReLU21_0_split -> Eltwise10_ReLU21_0_split_0
I1005 20:35:20.022557 10142 net.cpp:380] Eltwise10_ReLU21_0_split -> Eltwise10_ReLU21_0_split_1
I1005 20:35:20.022589 10142 net.cpp:122] Setting up Eltwise10_ReLU21_0_split
I1005 20:35:20.022593 10142 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 20:35:20.022596 10142 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1005 20:35:20.022598 10142 net.cpp:137] Memory required for data: 591054000
I1005 20:35:20.022600 10142 layer_factory.hpp:77] Creating layer Convolution23
I1005 20:35:20.022608 10142 net.cpp:84] Creating Layer Convolution23
I1005 20:35:20.022609 10142 net.cpp:406] Convolution23 <- Eltwise10_ReLU21_0_split_0
I1005 20:35:20.022614 10142 net.cpp:380] Convolution23 -> Convolution23
I1005 20:35:20.029856 10142 net.cpp:122] Setting up Convolution23
I1005 20:35:20.029883 10142 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 20:35:20.029886 10142 net.cpp:137] Memory required for data: 592692400
I1005 20:35:20.029892 10142 layer_factory.hpp:77] Creating layer BatchNorm23
I1005 20:35:20.029899 10142 net.cpp:84] Creating Layer BatchNorm23
I1005 20:35:20.029903 10142 net.cpp:406] BatchNorm23 <- Convolution23
I1005 20:35:20.029907 10142 net.cpp:367] BatchNorm23 -> Convolution23 (in-place)
I1005 20:35:20.030092 10142 net.cpp:122] Setting up BatchNorm23
I1005 20:35:20.030097 10142 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 20:35:20.030099 10142 net.cpp:137] Memory required for data: 594330800
I1005 20:35:20.030105 10142 layer_factory.hpp:77] Creating layer Scale23
I1005 20:35:20.030110 10142 net.cpp:84] Creating Layer Scale23
I1005 20:35:20.030123 10142 net.cpp:406] Scale23 <- Convolution23
I1005 20:35:20.030128 10142 net.cpp:367] Scale23 -> Convolution23 (in-place)
I1005 20:35:20.030164 10142 layer_factory.hpp:77] Creating layer Scale23
I1005 20:35:20.030256 10142 net.cpp:122] Setting up Scale23
I1005 20:35:20.030261 10142 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 20:35:20.030263 10142 net.cpp:137] Memory required for data: 595969200
I1005 20:35:20.030267 10142 layer_factory.hpp:77] Creating layer Convolution24
I1005 20:35:20.030275 10142 net.cpp:84] Creating Layer Convolution24
I1005 20:35:20.030279 10142 net.cpp:406] Convolution24 <- Eltwise10_ReLU21_0_split_1
I1005 20:35:20.030283 10142 net.cpp:380] Convolution24 -> Convolution24
I1005 20:35:20.036734 10142 net.cpp:122] Setting up Convolution24
I1005 20:35:20.036746 10142 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 20:35:20.036747 10142 net.cpp:137] Memory required for data: 597607600
I1005 20:35:20.036752 10142 layer_factory.hpp:77] Creating layer BatchNorm24
I1005 20:35:20.036768 10142 net.cpp:84] Creating Layer BatchNorm24
I1005 20:35:20.036772 10142 net.cpp:406] BatchNorm24 <- Convolution24
I1005 20:35:20.036777 10142 net.cpp:367] BatchNorm24 -> Convolution24 (in-place)
I1005 20:35:20.036942 10142 net.cpp:122] Setting up BatchNorm24
I1005 20:35:20.036947 10142 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 20:35:20.036950 10142 net.cpp:137] Memory required for data: 599246000
I1005 20:35:20.036965 10142 layer_factory.hpp:77] Creating layer Scale24
I1005 20:35:20.036972 10142 net.cpp:84] Creating Layer Scale24
I1005 20:35:20.036975 10142 net.cpp:406] Scale24 <- Convolution24
I1005 20:35:20.036978 10142 net.cpp:367] Scale24 -> Convolution24 (in-place)
I1005 20:35:20.037021 10142 layer_factory.hpp:77] Creating layer Scale24
I1005 20:35:20.037123 10142 net.cpp:122] Setting up Scale24
I1005 20:35:20.037129 10142 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 20:35:20.037132 10142 net.cpp:137] Memory required for data: 600884400
I1005 20:35:20.037137 10142 layer_factory.hpp:77] Creating layer ReLU22
I1005 20:35:20.037140 10142 net.cpp:84] Creating Layer ReLU22
I1005 20:35:20.037143 10142 net.cpp:406] ReLU22 <- Convolution24
I1005 20:35:20.037147 10142 net.cpp:367] ReLU22 -> Convolution24 (in-place)
I1005 20:35:20.038825 10142 net.cpp:122] Setting up ReLU22
I1005 20:35:20.038833 10142 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 20:35:20.038836 10142 net.cpp:137] Memory required for data: 602522800
I1005 20:35:20.038838 10142 layer_factory.hpp:77] Creating layer Convolution25
I1005 20:35:20.038846 10142 net.cpp:84] Creating Layer Convolution25
I1005 20:35:20.038851 10142 net.cpp:406] Convolution25 <- Convolution24
I1005 20:35:20.038856 10142 net.cpp:380] Convolution25 -> Convolution25
I1005 20:35:20.045469 10142 net.cpp:122] Setting up Convolution25
I1005 20:35:20.045480 10142 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 20:35:20.045481 10142 net.cpp:137] Memory required for data: 604161200
I1005 20:35:20.045496 10142 layer_factory.hpp:77] Creating layer BatchNorm25
I1005 20:35:20.045502 10142 net.cpp:84] Creating Layer BatchNorm25
I1005 20:35:20.045506 10142 net.cpp:406] BatchNorm25 <- Convolution25
I1005 20:35:20.045509 10142 net.cpp:367] BatchNorm25 -> Convolution25 (in-place)
I1005 20:35:20.045676 10142 net.cpp:122] Setting up BatchNorm25
I1005 20:35:20.045681 10142 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 20:35:20.045684 10142 net.cpp:137] Memory required for data: 605799600
I1005 20:35:20.045698 10142 layer_factory.hpp:77] Creating layer Scale25
I1005 20:35:20.045703 10142 net.cpp:84] Creating Layer Scale25
I1005 20:35:20.045706 10142 net.cpp:406] Scale25 <- Convolution25
I1005 20:35:20.045719 10142 net.cpp:367] Scale25 -> Convolution25 (in-place)
I1005 20:35:20.045770 10142 layer_factory.hpp:77] Creating layer Scale25
I1005 20:35:20.045871 10142 net.cpp:122] Setting up Scale25
I1005 20:35:20.045876 10142 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 20:35:20.045879 10142 net.cpp:137] Memory required for data: 607438000
I1005 20:35:20.045892 10142 layer_factory.hpp:77] Creating layer Eltwise11
I1005 20:35:20.045898 10142 net.cpp:84] Creating Layer Eltwise11
I1005 20:35:20.045902 10142 net.cpp:406] Eltwise11 <- Convolution23
I1005 20:35:20.045904 10142 net.cpp:406] Eltwise11 <- Convolution25
I1005 20:35:20.045908 10142 net.cpp:380] Eltwise11 -> Eltwise11
I1005 20:35:20.045930 10142 net.cpp:122] Setting up Eltwise11
I1005 20:35:20.045935 10142 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 20:35:20.045938 10142 net.cpp:137] Memory required for data: 609076400
I1005 20:35:20.045940 10142 layer_factory.hpp:77] Creating layer ReLU23
I1005 20:35:20.045944 10142 net.cpp:84] Creating Layer ReLU23
I1005 20:35:20.045948 10142 net.cpp:406] ReLU23 <- Eltwise11
I1005 20:35:20.045953 10142 net.cpp:367] ReLU23 -> Eltwise11 (in-place)
I1005 20:35:20.047607 10142 net.cpp:122] Setting up ReLU23
I1005 20:35:20.047616 10142 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 20:35:20.047618 10142 net.cpp:137] Memory required for data: 610714800
I1005 20:35:20.047621 10142 layer_factory.hpp:77] Creating layer Eltwise11_ReLU23_0_split
I1005 20:35:20.047626 10142 net.cpp:84] Creating Layer Eltwise11_ReLU23_0_split
I1005 20:35:20.047627 10142 net.cpp:406] Eltwise11_ReLU23_0_split <- Eltwise11
I1005 20:35:20.047632 10142 net.cpp:380] Eltwise11_ReLU23_0_split -> Eltwise11_ReLU23_0_split_0
I1005 20:35:20.047637 10142 net.cpp:380] Eltwise11_ReLU23_0_split -> Eltwise11_ReLU23_0_split_1
I1005 20:35:20.047680 10142 net.cpp:122] Setting up Eltwise11_ReLU23_0_split
I1005 20:35:20.047685 10142 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 20:35:20.047689 10142 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 20:35:20.047703 10142 net.cpp:137] Memory required for data: 613991600
I1005 20:35:20.047704 10142 layer_factory.hpp:77] Creating layer Convolution26
I1005 20:35:20.047713 10142 net.cpp:84] Creating Layer Convolution26
I1005 20:35:20.047718 10142 net.cpp:406] Convolution26 <- Eltwise11_ReLU23_0_split_0
I1005 20:35:20.047730 10142 net.cpp:380] Convolution26 -> Convolution26
I1005 20:35:20.053750 10142 net.cpp:122] Setting up Convolution26
I1005 20:35:20.053771 10142 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 20:35:20.053773 10142 net.cpp:137] Memory required for data: 615630000
I1005 20:35:20.053778 10142 layer_factory.hpp:77] Creating layer BatchNorm26
I1005 20:35:20.053793 10142 net.cpp:84] Creating Layer BatchNorm26
I1005 20:35:20.053797 10142 net.cpp:406] BatchNorm26 <- Convolution26
I1005 20:35:20.053802 10142 net.cpp:367] BatchNorm26 -> Convolution26 (in-place)
I1005 20:35:20.053983 10142 net.cpp:122] Setting up BatchNorm26
I1005 20:35:20.053988 10142 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 20:35:20.054000 10142 net.cpp:137] Memory required for data: 617268400
I1005 20:35:20.054006 10142 layer_factory.hpp:77] Creating layer Scale26
I1005 20:35:20.054010 10142 net.cpp:84] Creating Layer Scale26
I1005 20:35:20.054013 10142 net.cpp:406] Scale26 <- Convolution26
I1005 20:35:20.054016 10142 net.cpp:367] Scale26 -> Convolution26 (in-place)
I1005 20:35:20.054049 10142 layer_factory.hpp:77] Creating layer Scale26
I1005 20:35:20.054141 10142 net.cpp:122] Setting up Scale26
I1005 20:35:20.054147 10142 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 20:35:20.054149 10142 net.cpp:137] Memory required for data: 618906800
I1005 20:35:20.054153 10142 layer_factory.hpp:77] Creating layer ReLU24
I1005 20:35:20.054159 10142 net.cpp:84] Creating Layer ReLU24
I1005 20:35:20.054162 10142 net.cpp:406] ReLU24 <- Convolution26
I1005 20:35:20.054165 10142 net.cpp:367] ReLU24 -> Convolution26 (in-place)
I1005 20:35:20.054636 10142 net.cpp:122] Setting up ReLU24
I1005 20:35:20.054646 10142 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 20:35:20.054649 10142 net.cpp:137] Memory required for data: 620545200
I1005 20:35:20.054651 10142 layer_factory.hpp:77] Creating layer Convolution27
I1005 20:35:20.054659 10142 net.cpp:84] Creating Layer Convolution27
I1005 20:35:20.054671 10142 net.cpp:406] Convolution27 <- Convolution26
I1005 20:35:20.054677 10142 net.cpp:380] Convolution27 -> Convolution27
I1005 20:35:20.059962 10142 net.cpp:122] Setting up Convolution27
I1005 20:35:20.059978 10142 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 20:35:20.059980 10142 net.cpp:137] Memory required for data: 622183600
I1005 20:35:20.059986 10142 layer_factory.hpp:77] Creating layer BatchNorm27
I1005 20:35:20.060008 10142 net.cpp:84] Creating Layer BatchNorm27
I1005 20:35:20.060012 10142 net.cpp:406] BatchNorm27 <- Convolution27
I1005 20:35:20.060016 10142 net.cpp:367] BatchNorm27 -> Convolution27 (in-place)
I1005 20:35:20.060178 10142 net.cpp:122] Setting up BatchNorm27
I1005 20:35:20.060184 10142 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 20:35:20.060195 10142 net.cpp:137] Memory required for data: 623822000
I1005 20:35:20.060201 10142 layer_factory.hpp:77] Creating layer Scale27
I1005 20:35:20.060216 10142 net.cpp:84] Creating Layer Scale27
I1005 20:35:20.060220 10142 net.cpp:406] Scale27 <- Convolution27
I1005 20:35:20.060222 10142 net.cpp:367] Scale27 -> Convolution27 (in-place)
I1005 20:35:20.060268 10142 layer_factory.hpp:77] Creating layer Scale27
I1005 20:35:20.060372 10142 net.cpp:122] Setting up Scale27
I1005 20:35:20.060379 10142 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 20:35:20.060380 10142 net.cpp:137] Memory required for data: 625460400
I1005 20:35:20.060384 10142 layer_factory.hpp:77] Creating layer Eltwise12
I1005 20:35:20.060391 10142 net.cpp:84] Creating Layer Eltwise12
I1005 20:35:20.060395 10142 net.cpp:406] Eltwise12 <- Eltwise11_ReLU23_0_split_1
I1005 20:35:20.060398 10142 net.cpp:406] Eltwise12 <- Convolution27
I1005 20:35:20.060403 10142 net.cpp:380] Eltwise12 -> Eltwise12
I1005 20:35:20.060425 10142 net.cpp:122] Setting up Eltwise12
I1005 20:35:20.060428 10142 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 20:35:20.060431 10142 net.cpp:137] Memory required for data: 627098800
I1005 20:35:20.060433 10142 layer_factory.hpp:77] Creating layer ReLU25
I1005 20:35:20.060438 10142 net.cpp:84] Creating Layer ReLU25
I1005 20:35:20.060442 10142 net.cpp:406] ReLU25 <- Eltwise12
I1005 20:35:20.060446 10142 net.cpp:367] ReLU25 -> Eltwise12 (in-place)
I1005 20:35:20.062358 10142 net.cpp:122] Setting up ReLU25
I1005 20:35:20.062368 10142 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 20:35:20.062372 10142 net.cpp:137] Memory required for data: 628737200
I1005 20:35:20.062376 10142 layer_factory.hpp:77] Creating layer Eltwise12_ReLU25_0_split
I1005 20:35:20.062381 10142 net.cpp:84] Creating Layer Eltwise12_ReLU25_0_split
I1005 20:35:20.062383 10142 net.cpp:406] Eltwise12_ReLU25_0_split <- Eltwise12
I1005 20:35:20.062387 10142 net.cpp:380] Eltwise12_ReLU25_0_split -> Eltwise12_ReLU25_0_split_0
I1005 20:35:20.062392 10142 net.cpp:380] Eltwise12_ReLU25_0_split -> Eltwise12_ReLU25_0_split_1
I1005 20:35:20.062428 10142 net.cpp:122] Setting up Eltwise12_ReLU25_0_split
I1005 20:35:20.062433 10142 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 20:35:20.062438 10142 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 20:35:20.062439 10142 net.cpp:137] Memory required for data: 632014000
I1005 20:35:20.062443 10142 layer_factory.hpp:77] Creating layer Convolution28
I1005 20:35:20.062450 10142 net.cpp:84] Creating Layer Convolution28
I1005 20:35:20.062454 10142 net.cpp:406] Convolution28 <- Eltwise12_ReLU25_0_split_0
I1005 20:35:20.062459 10142 net.cpp:380] Convolution28 -> Convolution28
I1005 20:35:20.068475 10142 net.cpp:122] Setting up Convolution28
I1005 20:35:20.068485 10142 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 20:35:20.068487 10142 net.cpp:137] Memory required for data: 633652400
I1005 20:35:20.068492 10142 layer_factory.hpp:77] Creating layer BatchNorm28
I1005 20:35:20.068498 10142 net.cpp:84] Creating Layer BatchNorm28
I1005 20:35:20.068501 10142 net.cpp:406] BatchNorm28 <- Convolution28
I1005 20:35:20.068506 10142 net.cpp:367] BatchNorm28 -> Convolution28 (in-place)
I1005 20:35:20.068670 10142 net.cpp:122] Setting up BatchNorm28
I1005 20:35:20.068675 10142 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 20:35:20.068677 10142 net.cpp:137] Memory required for data: 635290800
I1005 20:35:20.068693 10142 layer_factory.hpp:77] Creating layer Scale28
I1005 20:35:20.068699 10142 net.cpp:84] Creating Layer Scale28
I1005 20:35:20.068702 10142 net.cpp:406] Scale28 <- Convolution28
I1005 20:35:20.068706 10142 net.cpp:367] Scale28 -> Convolution28 (in-place)
I1005 20:35:20.068740 10142 layer_factory.hpp:77] Creating layer Scale28
I1005 20:35:20.068832 10142 net.cpp:122] Setting up Scale28
I1005 20:35:20.068837 10142 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 20:35:20.068840 10142 net.cpp:137] Memory required for data: 636929200
I1005 20:35:20.068845 10142 layer_factory.hpp:77] Creating layer ReLU26
I1005 20:35:20.068848 10142 net.cpp:84] Creating Layer ReLU26
I1005 20:35:20.068852 10142 net.cpp:406] ReLU26 <- Convolution28
I1005 20:35:20.068856 10142 net.cpp:367] ReLU26 -> Convolution28 (in-place)
I1005 20:35:20.068989 10142 net.cpp:122] Setting up ReLU26
I1005 20:35:20.068996 10142 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 20:35:20.069000 10142 net.cpp:137] Memory required for data: 638567600
I1005 20:35:20.069001 10142 layer_factory.hpp:77] Creating layer Convolution29
I1005 20:35:20.069008 10142 net.cpp:84] Creating Layer Convolution29
I1005 20:35:20.069012 10142 net.cpp:406] Convolution29 <- Convolution28
I1005 20:35:20.069017 10142 net.cpp:380] Convolution29 -> Convolution29
I1005 20:35:20.074903 10142 net.cpp:122] Setting up Convolution29
I1005 20:35:20.074913 10142 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 20:35:20.074916 10142 net.cpp:137] Memory required for data: 640206000
I1005 20:35:20.074921 10142 layer_factory.hpp:77] Creating layer BatchNorm29
I1005 20:35:20.074937 10142 net.cpp:84] Creating Layer BatchNorm29
I1005 20:35:20.074941 10142 net.cpp:406] BatchNorm29 <- Convolution29
I1005 20:35:20.074946 10142 net.cpp:367] BatchNorm29 -> Convolution29 (in-place)
I1005 20:35:20.075115 10142 net.cpp:122] Setting up BatchNorm29
I1005 20:35:20.075121 10142 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 20:35:20.075124 10142 net.cpp:137] Memory required for data: 641844400
I1005 20:35:20.075129 10142 layer_factory.hpp:77] Creating layer Scale29
I1005 20:35:20.075134 10142 net.cpp:84] Creating Layer Scale29
I1005 20:35:20.075136 10142 net.cpp:406] Scale29 <- Convolution29
I1005 20:35:20.075139 10142 net.cpp:367] Scale29 -> Convolution29 (in-place)
I1005 20:35:20.075175 10142 layer_factory.hpp:77] Creating layer Scale29
I1005 20:35:20.075275 10142 net.cpp:122] Setting up Scale29
I1005 20:35:20.075281 10142 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 20:35:20.075284 10142 net.cpp:137] Memory required for data: 643482800
I1005 20:35:20.075287 10142 layer_factory.hpp:77] Creating layer Eltwise13
I1005 20:35:20.075294 10142 net.cpp:84] Creating Layer Eltwise13
I1005 20:35:20.075297 10142 net.cpp:406] Eltwise13 <- Eltwise12_ReLU25_0_split_1
I1005 20:35:20.075300 10142 net.cpp:406] Eltwise13 <- Convolution29
I1005 20:35:20.075304 10142 net.cpp:380] Eltwise13 -> Eltwise13
I1005 20:35:20.075333 10142 net.cpp:122] Setting up Eltwise13
I1005 20:35:20.075338 10142 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 20:35:20.075340 10142 net.cpp:137] Memory required for data: 645121200
I1005 20:35:20.075342 10142 layer_factory.hpp:77] Creating layer ReLU27
I1005 20:35:20.075346 10142 net.cpp:84] Creating Layer ReLU27
I1005 20:35:20.075348 10142 net.cpp:406] ReLU27 <- Eltwise13
I1005 20:35:20.075352 10142 net.cpp:367] ReLU27 -> Eltwise13 (in-place)
I1005 20:35:20.077030 10142 net.cpp:122] Setting up ReLU27
I1005 20:35:20.077038 10142 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 20:35:20.077040 10142 net.cpp:137] Memory required for data: 646759600
I1005 20:35:20.077042 10142 layer_factory.hpp:77] Creating layer Eltwise13_ReLU27_0_split
I1005 20:35:20.077047 10142 net.cpp:84] Creating Layer Eltwise13_ReLU27_0_split
I1005 20:35:20.077050 10142 net.cpp:406] Eltwise13_ReLU27_0_split <- Eltwise13
I1005 20:35:20.077054 10142 net.cpp:380] Eltwise13_ReLU27_0_split -> Eltwise13_ReLU27_0_split_0
I1005 20:35:20.077059 10142 net.cpp:380] Eltwise13_ReLU27_0_split -> Eltwise13_ReLU27_0_split_1
I1005 20:35:20.077101 10142 net.cpp:122] Setting up Eltwise13_ReLU27_0_split
I1005 20:35:20.077107 10142 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 20:35:20.077111 10142 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 20:35:20.077113 10142 net.cpp:137] Memory required for data: 650036400
I1005 20:35:20.077116 10142 layer_factory.hpp:77] Creating layer Convolution30
I1005 20:35:20.077123 10142 net.cpp:84] Creating Layer Convolution30
I1005 20:35:20.077126 10142 net.cpp:406] Convolution30 <- Eltwise13_ReLU27_0_split_0
I1005 20:35:20.077131 10142 net.cpp:380] Convolution30 -> Convolution30
I1005 20:35:20.083966 10142 net.cpp:122] Setting up Convolution30
I1005 20:35:20.083976 10142 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 20:35:20.083979 10142 net.cpp:137] Memory required for data: 651674800
I1005 20:35:20.083984 10142 layer_factory.hpp:77] Creating layer BatchNorm30
I1005 20:35:20.083992 10142 net.cpp:84] Creating Layer BatchNorm30
I1005 20:35:20.083994 10142 net.cpp:406] BatchNorm30 <- Convolution30
I1005 20:35:20.083998 10142 net.cpp:367] BatchNorm30 -> Convolution30 (in-place)
I1005 20:35:20.084183 10142 net.cpp:122] Setting up BatchNorm30
I1005 20:35:20.084189 10142 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 20:35:20.084192 10142 net.cpp:137] Memory required for data: 653313200
I1005 20:35:20.084206 10142 layer_factory.hpp:77] Creating layer Scale30
I1005 20:35:20.084211 10142 net.cpp:84] Creating Layer Scale30
I1005 20:35:20.084214 10142 net.cpp:406] Scale30 <- Convolution30
I1005 20:35:20.084218 10142 net.cpp:367] Scale30 -> Convolution30 (in-place)
I1005 20:35:20.084261 10142 layer_factory.hpp:77] Creating layer Scale30
I1005 20:35:20.084353 10142 net.cpp:122] Setting up Scale30
I1005 20:35:20.084358 10142 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 20:35:20.084362 10142 net.cpp:137] Memory required for data: 654951600
I1005 20:35:20.084365 10142 layer_factory.hpp:77] Creating layer ReLU28
I1005 20:35:20.084369 10142 net.cpp:84] Creating Layer ReLU28
I1005 20:35:20.084373 10142 net.cpp:406] ReLU28 <- Convolution30
I1005 20:35:20.084377 10142 net.cpp:367] ReLU28 -> Convolution30 (in-place)
I1005 20:35:20.085746 10142 net.cpp:122] Setting up ReLU28
I1005 20:35:20.085753 10142 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 20:35:20.085757 10142 net.cpp:137] Memory required for data: 656590000
I1005 20:35:20.085758 10142 layer_factory.hpp:77] Creating layer Convolution31
I1005 20:35:20.085777 10142 net.cpp:84] Creating Layer Convolution31
I1005 20:35:20.085779 10142 net.cpp:406] Convolution31 <- Convolution30
I1005 20:35:20.085784 10142 net.cpp:380] Convolution31 -> Convolution31
I1005 20:35:20.093430 10142 net.cpp:122] Setting up Convolution31
I1005 20:35:20.093453 10142 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 20:35:20.093456 10142 net.cpp:137] Memory required for data: 658228400
I1005 20:35:20.093462 10142 layer_factory.hpp:77] Creating layer BatchNorm31
I1005 20:35:20.093469 10142 net.cpp:84] Creating Layer BatchNorm31
I1005 20:35:20.093483 10142 net.cpp:406] BatchNorm31 <- Convolution31
I1005 20:35:20.093488 10142 net.cpp:367] BatchNorm31 -> Convolution31 (in-place)
I1005 20:35:20.093665 10142 net.cpp:122] Setting up BatchNorm31
I1005 20:35:20.093670 10142 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 20:35:20.093683 10142 net.cpp:137] Memory required for data: 659866800
I1005 20:35:20.093688 10142 layer_factory.hpp:77] Creating layer Scale31
I1005 20:35:20.093693 10142 net.cpp:84] Creating Layer Scale31
I1005 20:35:20.093695 10142 net.cpp:406] Scale31 <- Convolution31
I1005 20:35:20.093698 10142 net.cpp:367] Scale31 -> Convolution31 (in-place)
I1005 20:35:20.093744 10142 layer_factory.hpp:77] Creating layer Scale31
I1005 20:35:20.093852 10142 net.cpp:122] Setting up Scale31
I1005 20:35:20.093858 10142 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 20:35:20.093869 10142 net.cpp:137] Memory required for data: 661505200
I1005 20:35:20.093873 10142 layer_factory.hpp:77] Creating layer Eltwise14
I1005 20:35:20.093878 10142 net.cpp:84] Creating Layer Eltwise14
I1005 20:35:20.093892 10142 net.cpp:406] Eltwise14 <- Eltwise13_ReLU27_0_split_1
I1005 20:35:20.093896 10142 net.cpp:406] Eltwise14 <- Convolution31
I1005 20:35:20.093899 10142 net.cpp:380] Eltwise14 -> Eltwise14
I1005 20:35:20.093922 10142 net.cpp:122] Setting up Eltwise14
I1005 20:35:20.093936 10142 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 20:35:20.093938 10142 net.cpp:137] Memory required for data: 663143600
I1005 20:35:20.093940 10142 layer_factory.hpp:77] Creating layer ReLU29
I1005 20:35:20.093953 10142 net.cpp:84] Creating Layer ReLU29
I1005 20:35:20.093956 10142 net.cpp:406] ReLU29 <- Eltwise14
I1005 20:35:20.093961 10142 net.cpp:367] ReLU29 -> Eltwise14 (in-place)
I1005 20:35:20.095814 10142 net.cpp:122] Setting up ReLU29
I1005 20:35:20.095824 10142 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 20:35:20.095835 10142 net.cpp:137] Memory required for data: 664782000
I1005 20:35:20.095839 10142 layer_factory.hpp:77] Creating layer Eltwise14_ReLU29_0_split
I1005 20:35:20.095854 10142 net.cpp:84] Creating Layer Eltwise14_ReLU29_0_split
I1005 20:35:20.095857 10142 net.cpp:406] Eltwise14_ReLU29_0_split <- Eltwise14
I1005 20:35:20.095861 10142 net.cpp:380] Eltwise14_ReLU29_0_split -> Eltwise14_ReLU29_0_split_0
I1005 20:35:20.095866 10142 net.cpp:380] Eltwise14_ReLU29_0_split -> Eltwise14_ReLU29_0_split_1
I1005 20:35:20.095912 10142 net.cpp:122] Setting up Eltwise14_ReLU29_0_split
I1005 20:35:20.095917 10142 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 20:35:20.095921 10142 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 20:35:20.095923 10142 net.cpp:137] Memory required for data: 668058800
I1005 20:35:20.095935 10142 layer_factory.hpp:77] Creating layer Convolution32
I1005 20:35:20.095943 10142 net.cpp:84] Creating Layer Convolution32
I1005 20:35:20.095947 10142 net.cpp:406] Convolution32 <- Eltwise14_ReLU29_0_split_0
I1005 20:35:20.095952 10142 net.cpp:380] Convolution32 -> Convolution32
I1005 20:35:20.102423 10142 net.cpp:122] Setting up Convolution32
I1005 20:35:20.102433 10142 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 20:35:20.102437 10142 net.cpp:137] Memory required for data: 669697200
I1005 20:35:20.102442 10142 layer_factory.hpp:77] Creating layer BatchNorm32
I1005 20:35:20.102447 10142 net.cpp:84] Creating Layer BatchNorm32
I1005 20:35:20.102452 10142 net.cpp:406] BatchNorm32 <- Convolution32
I1005 20:35:20.102454 10142 net.cpp:367] BatchNorm32 -> Convolution32 (in-place)
I1005 20:35:20.102632 10142 net.cpp:122] Setting up BatchNorm32
I1005 20:35:20.102638 10142 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 20:35:20.102643 10142 net.cpp:137] Memory required for data: 671335600
I1005 20:35:20.102648 10142 layer_factory.hpp:77] Creating layer Scale32
I1005 20:35:20.102653 10142 net.cpp:84] Creating Layer Scale32
I1005 20:35:20.102656 10142 net.cpp:406] Scale32 <- Convolution32
I1005 20:35:20.102659 10142 net.cpp:367] Scale32 -> Convolution32 (in-place)
I1005 20:35:20.102694 10142 layer_factory.hpp:77] Creating layer Scale32
I1005 20:35:20.102787 10142 net.cpp:122] Setting up Scale32
I1005 20:35:20.102792 10142 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 20:35:20.102794 10142 net.cpp:137] Memory required for data: 672974000
I1005 20:35:20.102798 10142 layer_factory.hpp:77] Creating layer ReLU30
I1005 20:35:20.102803 10142 net.cpp:84] Creating Layer ReLU30
I1005 20:35:20.102807 10142 net.cpp:406] ReLU30 <- Convolution32
I1005 20:35:20.102810 10142 net.cpp:367] ReLU30 -> Convolution32 (in-place)
I1005 20:35:20.104228 10142 net.cpp:122] Setting up ReLU30
I1005 20:35:20.104238 10142 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 20:35:20.104240 10142 net.cpp:137] Memory required for data: 674612400
I1005 20:35:20.104243 10142 layer_factory.hpp:77] Creating layer Convolution33
I1005 20:35:20.104251 10142 net.cpp:84] Creating Layer Convolution33
I1005 20:35:20.104254 10142 net.cpp:406] Convolution33 <- Convolution32
I1005 20:35:20.104260 10142 net.cpp:380] Convolution33 -> Convolution33
I1005 20:35:20.108095 10142 net.cpp:122] Setting up Convolution33
I1005 20:35:20.108105 10142 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 20:35:20.108115 10142 net.cpp:137] Memory required for data: 676250800
I1005 20:35:20.108120 10142 layer_factory.hpp:77] Creating layer BatchNorm33
I1005 20:35:20.108126 10142 net.cpp:84] Creating Layer BatchNorm33
I1005 20:35:20.108130 10142 net.cpp:406] BatchNorm33 <- Convolution33
I1005 20:35:20.108134 10142 net.cpp:367] BatchNorm33 -> Convolution33 (in-place)
I1005 20:35:20.108309 10142 net.cpp:122] Setting up BatchNorm33
I1005 20:35:20.108314 10142 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 20:35:20.108316 10142 net.cpp:137] Memory required for data: 677889200
I1005 20:35:20.108321 10142 layer_factory.hpp:77] Creating layer Scale33
I1005 20:35:20.108326 10142 net.cpp:84] Creating Layer Scale33
I1005 20:35:20.108330 10142 net.cpp:406] Scale33 <- Convolution33
I1005 20:35:20.108333 10142 net.cpp:367] Scale33 -> Convolution33 (in-place)
I1005 20:35:20.108366 10142 layer_factory.hpp:77] Creating layer Scale33
I1005 20:35:20.108458 10142 net.cpp:122] Setting up Scale33
I1005 20:35:20.108464 10142 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 20:35:20.108466 10142 net.cpp:137] Memory required for data: 679527600
I1005 20:35:20.108470 10142 layer_factory.hpp:77] Creating layer Eltwise15
I1005 20:35:20.108475 10142 net.cpp:84] Creating Layer Eltwise15
I1005 20:35:20.108479 10142 net.cpp:406] Eltwise15 <- Eltwise14_ReLU29_0_split_1
I1005 20:35:20.108481 10142 net.cpp:406] Eltwise15 <- Convolution33
I1005 20:35:20.108487 10142 net.cpp:380] Eltwise15 -> Eltwise15
I1005 20:35:20.108506 10142 net.cpp:122] Setting up Eltwise15
I1005 20:35:20.108510 10142 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 20:35:20.108513 10142 net.cpp:137] Memory required for data: 681166000
I1005 20:35:20.108515 10142 layer_factory.hpp:77] Creating layer ReLU31
I1005 20:35:20.108520 10142 net.cpp:84] Creating Layer ReLU31
I1005 20:35:20.108523 10142 net.cpp:406] ReLU31 <- Eltwise15
I1005 20:35:20.108526 10142 net.cpp:367] ReLU31 -> Eltwise15 (in-place)
I1005 20:35:20.108989 10142 net.cpp:122] Setting up ReLU31
I1005 20:35:20.108999 10142 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1005 20:35:20.109002 10142 net.cpp:137] Memory required for data: 682804400
I1005 20:35:20.109005 10142 layer_factory.hpp:77] Creating layer Pooling1
I1005 20:35:20.109010 10142 net.cpp:84] Creating Layer Pooling1
I1005 20:35:20.109014 10142 net.cpp:406] Pooling1 <- Eltwise15
I1005 20:35:20.109017 10142 net.cpp:380] Pooling1 -> Pooling1
I1005 20:35:20.109166 10142 net.cpp:122] Setting up Pooling1
I1005 20:35:20.109174 10142 net.cpp:129] Top shape: 100 64 1 1 (6400)
I1005 20:35:20.109177 10142 net.cpp:137] Memory required for data: 682830000
I1005 20:35:20.109179 10142 layer_factory.hpp:77] Creating layer InnerProduct1
I1005 20:35:20.109185 10142 net.cpp:84] Creating Layer InnerProduct1
I1005 20:35:20.109189 10142 net.cpp:406] InnerProduct1 <- Pooling1
I1005 20:35:20.109194 10142 net.cpp:380] InnerProduct1 -> InnerProduct1
I1005 20:35:20.109311 10142 net.cpp:122] Setting up InnerProduct1
I1005 20:35:20.109318 10142 net.cpp:129] Top shape: 100 10 (1000)
I1005 20:35:20.109319 10142 net.cpp:137] Memory required for data: 682834000
I1005 20:35:20.109324 10142 layer_factory.hpp:77] Creating layer InnerProduct1_InnerProduct1_0_split
I1005 20:35:20.109328 10142 net.cpp:84] Creating Layer InnerProduct1_InnerProduct1_0_split
I1005 20:35:20.109331 10142 net.cpp:406] InnerProduct1_InnerProduct1_0_split <- InnerProduct1
I1005 20:35:20.109335 10142 net.cpp:380] InnerProduct1_InnerProduct1_0_split -> InnerProduct1_InnerProduct1_0_split_0
I1005 20:35:20.109340 10142 net.cpp:380] InnerProduct1_InnerProduct1_0_split -> InnerProduct1_InnerProduct1_0_split_1
I1005 20:35:20.109371 10142 net.cpp:122] Setting up InnerProduct1_InnerProduct1_0_split
I1005 20:35:20.109376 10142 net.cpp:129] Top shape: 100 10 (1000)
I1005 20:35:20.109380 10142 net.cpp:129] Top shape: 100 10 (1000)
I1005 20:35:20.109382 10142 net.cpp:137] Memory required for data: 682842000
I1005 20:35:20.109385 10142 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I1005 20:35:20.109396 10142 net.cpp:84] Creating Layer SoftmaxWithLoss1
I1005 20:35:20.109400 10142 net.cpp:406] SoftmaxWithLoss1 <- InnerProduct1_InnerProduct1_0_split_0
I1005 20:35:20.109405 10142 net.cpp:406] SoftmaxWithLoss1 <- Data2_Data1_1_split_0
I1005 20:35:20.109410 10142 net.cpp:380] SoftmaxWithLoss1 -> SoftmaxWithLoss1
I1005 20:35:20.109416 10142 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I1005 20:35:20.111353 10142 net.cpp:122] Setting up SoftmaxWithLoss1
I1005 20:35:20.111363 10142 net.cpp:129] Top shape: (1)
I1005 20:35:20.111366 10142 net.cpp:132]     with loss weight 1
I1005 20:35:20.111373 10142 net.cpp:137] Memory required for data: 682842004
I1005 20:35:20.111377 10142 layer_factory.hpp:77] Creating layer Accuracy1
I1005 20:35:20.111382 10142 net.cpp:84] Creating Layer Accuracy1
I1005 20:35:20.111384 10142 net.cpp:406] Accuracy1 <- InnerProduct1_InnerProduct1_0_split_1
I1005 20:35:20.111388 10142 net.cpp:406] Accuracy1 <- Data2_Data1_1_split_1
I1005 20:35:20.111393 10142 net.cpp:380] Accuracy1 -> Accuracy1
I1005 20:35:20.111400 10142 net.cpp:122] Setting up Accuracy1
I1005 20:35:20.111404 10142 net.cpp:129] Top shape: (1)
I1005 20:35:20.111407 10142 net.cpp:137] Memory required for data: 682842008
I1005 20:35:20.111409 10142 net.cpp:200] Accuracy1 does not need backward computation.
I1005 20:35:20.111413 10142 net.cpp:198] SoftmaxWithLoss1 needs backward computation.
I1005 20:35:20.111415 10142 net.cpp:198] InnerProduct1_InnerProduct1_0_split needs backward computation.
I1005 20:35:20.111418 10142 net.cpp:198] InnerProduct1 needs backward computation.
I1005 20:35:20.111420 10142 net.cpp:198] Pooling1 needs backward computation.
I1005 20:35:20.111423 10142 net.cpp:198] ReLU31 needs backward computation.
I1005 20:35:20.111425 10142 net.cpp:198] Eltwise15 needs backward computation.
I1005 20:35:20.111428 10142 net.cpp:198] Scale33 needs backward computation.
I1005 20:35:20.111431 10142 net.cpp:198] BatchNorm33 needs backward computation.
I1005 20:35:20.111433 10142 net.cpp:198] Convolution33 needs backward computation.
I1005 20:35:20.111435 10142 net.cpp:198] ReLU30 needs backward computation.
I1005 20:35:20.111438 10142 net.cpp:198] Scale32 needs backward computation.
I1005 20:35:20.111439 10142 net.cpp:198] BatchNorm32 needs backward computation.
I1005 20:35:20.111443 10142 net.cpp:198] Convolution32 needs backward computation.
I1005 20:35:20.111444 10142 net.cpp:198] Eltwise14_ReLU29_0_split needs backward computation.
I1005 20:35:20.111446 10142 net.cpp:198] ReLU29 needs backward computation.
I1005 20:35:20.111449 10142 net.cpp:198] Eltwise14 needs backward computation.
I1005 20:35:20.111451 10142 net.cpp:198] Scale31 needs backward computation.
I1005 20:35:20.111454 10142 net.cpp:198] BatchNorm31 needs backward computation.
I1005 20:35:20.111456 10142 net.cpp:198] Convolution31 needs backward computation.
I1005 20:35:20.111459 10142 net.cpp:198] ReLU28 needs backward computation.
I1005 20:35:20.111461 10142 net.cpp:198] Scale30 needs backward computation.
I1005 20:35:20.111464 10142 net.cpp:198] BatchNorm30 needs backward computation.
I1005 20:35:20.111465 10142 net.cpp:198] Convolution30 needs backward computation.
I1005 20:35:20.111469 10142 net.cpp:198] Eltwise13_ReLU27_0_split needs backward computation.
I1005 20:35:20.111471 10142 net.cpp:198] ReLU27 needs backward computation.
I1005 20:35:20.111474 10142 net.cpp:198] Eltwise13 needs backward computation.
I1005 20:35:20.111476 10142 net.cpp:198] Scale29 needs backward computation.
I1005 20:35:20.111479 10142 net.cpp:198] BatchNorm29 needs backward computation.
I1005 20:35:20.111482 10142 net.cpp:198] Convolution29 needs backward computation.
I1005 20:35:20.111485 10142 net.cpp:198] ReLU26 needs backward computation.
I1005 20:35:20.111487 10142 net.cpp:198] Scale28 needs backward computation.
I1005 20:35:20.111490 10142 net.cpp:198] BatchNorm28 needs backward computation.
I1005 20:35:20.111492 10142 net.cpp:198] Convolution28 needs backward computation.
I1005 20:35:20.111495 10142 net.cpp:198] Eltwise12_ReLU25_0_split needs backward computation.
I1005 20:35:20.111505 10142 net.cpp:198] ReLU25 needs backward computation.
I1005 20:35:20.111508 10142 net.cpp:198] Eltwise12 needs backward computation.
I1005 20:35:20.111511 10142 net.cpp:198] Scale27 needs backward computation.
I1005 20:35:20.111513 10142 net.cpp:198] BatchNorm27 needs backward computation.
I1005 20:35:20.111516 10142 net.cpp:198] Convolution27 needs backward computation.
I1005 20:35:20.111518 10142 net.cpp:198] ReLU24 needs backward computation.
I1005 20:35:20.111521 10142 net.cpp:198] Scale26 needs backward computation.
I1005 20:35:20.111523 10142 net.cpp:198] BatchNorm26 needs backward computation.
I1005 20:35:20.111526 10142 net.cpp:198] Convolution26 needs backward computation.
I1005 20:35:20.111527 10142 net.cpp:198] Eltwise11_ReLU23_0_split needs backward computation.
I1005 20:35:20.111531 10142 net.cpp:198] ReLU23 needs backward computation.
I1005 20:35:20.111533 10142 net.cpp:198] Eltwise11 needs backward computation.
I1005 20:35:20.111536 10142 net.cpp:198] Scale25 needs backward computation.
I1005 20:35:20.111539 10142 net.cpp:198] BatchNorm25 needs backward computation.
I1005 20:35:20.111541 10142 net.cpp:198] Convolution25 needs backward computation.
I1005 20:35:20.111544 10142 net.cpp:198] ReLU22 needs backward computation.
I1005 20:35:20.111547 10142 net.cpp:198] Scale24 needs backward computation.
I1005 20:35:20.111549 10142 net.cpp:198] BatchNorm24 needs backward computation.
I1005 20:35:20.111552 10142 net.cpp:198] Convolution24 needs backward computation.
I1005 20:35:20.111555 10142 net.cpp:198] Scale23 needs backward computation.
I1005 20:35:20.111557 10142 net.cpp:198] BatchNorm23 needs backward computation.
I1005 20:35:20.111559 10142 net.cpp:198] Convolution23 needs backward computation.
I1005 20:35:20.111562 10142 net.cpp:198] Eltwise10_ReLU21_0_split needs backward computation.
I1005 20:35:20.111565 10142 net.cpp:198] ReLU21 needs backward computation.
I1005 20:35:20.111568 10142 net.cpp:198] Eltwise10 needs backward computation.
I1005 20:35:20.111572 10142 net.cpp:198] Scale22 needs backward computation.
I1005 20:35:20.111575 10142 net.cpp:198] BatchNorm22 needs backward computation.
I1005 20:35:20.111577 10142 net.cpp:198] Convolution22 needs backward computation.
I1005 20:35:20.111579 10142 net.cpp:198] ReLU20 needs backward computation.
I1005 20:35:20.111582 10142 net.cpp:198] Scale21 needs backward computation.
I1005 20:35:20.111584 10142 net.cpp:198] BatchNorm21 needs backward computation.
I1005 20:35:20.111587 10142 net.cpp:198] Convolution21 needs backward computation.
I1005 20:35:20.111589 10142 net.cpp:198] Eltwise9_ReLU19_0_split needs backward computation.
I1005 20:35:20.111593 10142 net.cpp:198] ReLU19 needs backward computation.
I1005 20:35:20.111594 10142 net.cpp:198] Eltwise9 needs backward computation.
I1005 20:35:20.111598 10142 net.cpp:198] Scale20 needs backward computation.
I1005 20:35:20.111600 10142 net.cpp:198] BatchNorm20 needs backward computation.
I1005 20:35:20.111603 10142 net.cpp:198] Convolution20 needs backward computation.
I1005 20:35:20.111605 10142 net.cpp:198] ReLU18 needs backward computation.
I1005 20:35:20.111608 10142 net.cpp:198] Scale19 needs backward computation.
I1005 20:35:20.111610 10142 net.cpp:198] BatchNorm19 needs backward computation.
I1005 20:35:20.111613 10142 net.cpp:198] Convolution19 needs backward computation.
I1005 20:35:20.111615 10142 net.cpp:198] Eltwise8_ReLU17_0_split needs backward computation.
I1005 20:35:20.111618 10142 net.cpp:198] ReLU17 needs backward computation.
I1005 20:35:20.111621 10142 net.cpp:198] Eltwise8 needs backward computation.
I1005 20:35:20.111624 10142 net.cpp:198] Scale18 needs backward computation.
I1005 20:35:20.111626 10142 net.cpp:198] BatchNorm18 needs backward computation.
I1005 20:35:20.111629 10142 net.cpp:198] Convolution18 needs backward computation.
I1005 20:35:20.111631 10142 net.cpp:198] ReLU16 needs backward computation.
I1005 20:35:20.111634 10142 net.cpp:198] Scale17 needs backward computation.
I1005 20:35:20.111637 10142 net.cpp:198] BatchNorm17 needs backward computation.
I1005 20:35:20.111644 10142 net.cpp:198] Convolution17 needs backward computation.
I1005 20:35:20.111646 10142 net.cpp:198] Eltwise7_ReLU15_0_split needs backward computation.
I1005 20:35:20.111649 10142 net.cpp:198] ReLU15 needs backward computation.
I1005 20:35:20.111652 10142 net.cpp:198] Eltwise7 needs backward computation.
I1005 20:35:20.111655 10142 net.cpp:198] Scale16 needs backward computation.
I1005 20:35:20.111657 10142 net.cpp:198] BatchNorm16 needs backward computation.
I1005 20:35:20.111660 10142 net.cpp:198] Convolution16 needs backward computation.
I1005 20:35:20.111663 10142 net.cpp:198] ReLU14 needs backward computation.
I1005 20:35:20.111665 10142 net.cpp:198] Scale15 needs backward computation.
I1005 20:35:20.111667 10142 net.cpp:198] BatchNorm15 needs backward computation.
I1005 20:35:20.111670 10142 net.cpp:198] Convolution15 needs backward computation.
I1005 20:35:20.111673 10142 net.cpp:198] Eltwise6_ReLU13_0_split needs backward computation.
I1005 20:35:20.111676 10142 net.cpp:198] ReLU13 needs backward computation.
I1005 20:35:20.111678 10142 net.cpp:198] Eltwise6 needs backward computation.
I1005 20:35:20.111682 10142 net.cpp:198] Scale14 needs backward computation.
I1005 20:35:20.111685 10142 net.cpp:198] BatchNorm14 needs backward computation.
I1005 20:35:20.111687 10142 net.cpp:198] Convolution14 needs backward computation.
I1005 20:35:20.111690 10142 net.cpp:198] ReLU12 needs backward computation.
I1005 20:35:20.111693 10142 net.cpp:198] Scale13 needs backward computation.
I1005 20:35:20.111696 10142 net.cpp:198] BatchNorm13 needs backward computation.
I1005 20:35:20.111697 10142 net.cpp:198] Convolution13 needs backward computation.
I1005 20:35:20.111701 10142 net.cpp:198] Scale12 needs backward computation.
I1005 20:35:20.111702 10142 net.cpp:198] BatchNorm12 needs backward computation.
I1005 20:35:20.111704 10142 net.cpp:198] Convolution12 needs backward computation.
I1005 20:35:20.111707 10142 net.cpp:198] Eltwise5_ReLU11_0_split needs backward computation.
I1005 20:35:20.111709 10142 net.cpp:198] ReLU11 needs backward computation.
I1005 20:35:20.111711 10142 net.cpp:198] Eltwise5 needs backward computation.
I1005 20:35:20.111714 10142 net.cpp:198] Scale11 needs backward computation.
I1005 20:35:20.111716 10142 net.cpp:198] BatchNorm11 needs backward computation.
I1005 20:35:20.111719 10142 net.cpp:198] Convolution11 needs backward computation.
I1005 20:35:20.111721 10142 net.cpp:198] ReLU10 needs backward computation.
I1005 20:35:20.111724 10142 net.cpp:198] Scale10 needs backward computation.
I1005 20:35:20.111726 10142 net.cpp:198] BatchNorm10 needs backward computation.
I1005 20:35:20.111728 10142 net.cpp:198] Convolution10 needs backward computation.
I1005 20:35:20.111732 10142 net.cpp:198] Eltwise4_ReLU9_0_split needs backward computation.
I1005 20:35:20.111733 10142 net.cpp:198] ReLU9 needs backward computation.
I1005 20:35:20.111735 10142 net.cpp:198] Eltwise4 needs backward computation.
I1005 20:35:20.111739 10142 net.cpp:198] Scale9 needs backward computation.
I1005 20:35:20.111742 10142 net.cpp:198] BatchNorm9 needs backward computation.
I1005 20:35:20.111743 10142 net.cpp:198] Convolution9 needs backward computation.
I1005 20:35:20.111747 10142 net.cpp:198] ReLU8 needs backward computation.
I1005 20:35:20.111748 10142 net.cpp:198] Scale8 needs backward computation.
I1005 20:35:20.111752 10142 net.cpp:198] BatchNorm8 needs backward computation.
I1005 20:35:20.111753 10142 net.cpp:198] Convolution8 needs backward computation.
I1005 20:35:20.111757 10142 net.cpp:198] Eltwise3_ReLU7_0_split needs backward computation.
I1005 20:35:20.111758 10142 net.cpp:198] ReLU7 needs backward computation.
I1005 20:35:20.111760 10142 net.cpp:198] Eltwise3 needs backward computation.
I1005 20:35:20.111763 10142 net.cpp:198] Scale7 needs backward computation.
I1005 20:35:20.111766 10142 net.cpp:198] BatchNorm7 needs backward computation.
I1005 20:35:20.111768 10142 net.cpp:198] Convolution7 needs backward computation.
I1005 20:35:20.111770 10142 net.cpp:198] ReLU6 needs backward computation.
I1005 20:35:20.111778 10142 net.cpp:198] Scale6 needs backward computation.
I1005 20:35:20.111779 10142 net.cpp:198] BatchNorm6 needs backward computation.
I1005 20:35:20.111783 10142 net.cpp:198] Convolution6 needs backward computation.
I1005 20:35:20.111785 10142 net.cpp:198] Eltwise2_ReLU5_0_split needs backward computation.
I1005 20:35:20.111788 10142 net.cpp:198] ReLU5 needs backward computation.
I1005 20:35:20.111789 10142 net.cpp:198] Eltwise2 needs backward computation.
I1005 20:35:20.111793 10142 net.cpp:198] Scale5 needs backward computation.
I1005 20:35:20.111795 10142 net.cpp:198] BatchNorm5 needs backward computation.
I1005 20:35:20.111798 10142 net.cpp:198] Convolution5 needs backward computation.
I1005 20:35:20.111799 10142 net.cpp:198] ReLU4 needs backward computation.
I1005 20:35:20.111802 10142 net.cpp:198] Scale4 needs backward computation.
I1005 20:35:20.111804 10142 net.cpp:198] BatchNorm4 needs backward computation.
I1005 20:35:20.111806 10142 net.cpp:198] Convolution4 needs backward computation.
I1005 20:35:20.111809 10142 net.cpp:198] Eltwise1_ReLU3_0_split needs backward computation.
I1005 20:35:20.111812 10142 net.cpp:198] ReLU3 needs backward computation.
I1005 20:35:20.111814 10142 net.cpp:198] Eltwise1 needs backward computation.
I1005 20:35:20.111817 10142 net.cpp:198] Scale3 needs backward computation.
I1005 20:35:20.111819 10142 net.cpp:198] BatchNorm3 needs backward computation.
I1005 20:35:20.111821 10142 net.cpp:198] Convolution3 needs backward computation.
I1005 20:35:20.111824 10142 net.cpp:198] ReLU2 needs backward computation.
I1005 20:35:20.111827 10142 net.cpp:198] Scale2 needs backward computation.
I1005 20:35:20.111829 10142 net.cpp:198] BatchNorm2 needs backward computation.
I1005 20:35:20.111831 10142 net.cpp:198] Convolution2 needs backward computation.
I1005 20:35:20.111835 10142 net.cpp:198] Convolution1_ReLU1_0_split needs backward computation.
I1005 20:35:20.111836 10142 net.cpp:198] ReLU1 needs backward computation.
I1005 20:35:20.111840 10142 net.cpp:198] Scale1 needs backward computation.
I1005 20:35:20.111841 10142 net.cpp:198] BatchNorm1 needs backward computation.
I1005 20:35:20.111843 10142 net.cpp:198] Convolution1 needs backward computation.
I1005 20:35:20.111847 10142 net.cpp:200] Data2_Data1_1_split does not need backward computation.
I1005 20:35:20.111850 10142 net.cpp:200] Data1 does not need backward computation.
I1005 20:35:20.111852 10142 net.cpp:242] This network produces output Accuracy1
I1005 20:35:20.111855 10142 net.cpp:242] This network produces output SoftmaxWithLoss1
I1005 20:35:20.111910 10142 net.cpp:255] Network initialization done.
I1005 20:35:20.112272 10142 solver.cpp:56] Solver scaffolding done.
I1005 20:35:20.119081 10142 caffe.cpp:248] Starting Optimization
I1005 20:35:20.119087 10142 solver.cpp:272] Solving resnet_cifar10
I1005 20:35:20.119089 10142 solver.cpp:273] Learning Rate Policy: multistep
I1005 20:35:20.122040 10142 solver.cpp:330] Iteration 0, Testing net (#0)
I1005 20:35:23.799259 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 20:35:23.929183 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.1
I1005 20:35:23.929222 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 87.3365 (* 1 = 87.3365 loss)
I1005 20:35:24.224931 10142 solver.cpp:218] Iteration 0 (-2.92941e-33 iter/s, 4.10511s/100 iters), loss = 2.30468
I1005 20:35:24.224969 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 2.30468 (* 1 = 2.30468 loss)
I1005 20:35:24.224997 10142 sgd_solver.cpp:105] Iteration 0, lr = 0.1
I1005 20:35:40.346196 10142 solver.cpp:218] Iteration 100 (6.20312 iter/s, 16.1209s/100 iters), loss = 1.72729
I1005 20:35:40.346236 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.72729 (* 1 = 1.72729 loss)
I1005 20:35:40.346242 10142 sgd_solver.cpp:105] Iteration 100, lr = 0.1
I1005 20:35:56.239420 10142 solver.cpp:218] Iteration 200 (6.29203 iter/s, 15.8931s/100 iters), loss = 1.80688
I1005 20:35:56.239604 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.80688 (* 1 = 1.80688 loss)
I1005 20:35:56.239615 10142 sgd_solver.cpp:105] Iteration 200, lr = 0.1
I1005 20:36:12.093953 10142 solver.cpp:218] Iteration 300 (6.30744 iter/s, 15.8543s/100 iters), loss = 1.60838
I1005 20:36:12.093991 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.60838 (* 1 = 1.60838 loss)
I1005 20:36:12.093997 10142 sgd_solver.cpp:105] Iteration 300, lr = 0.1
I1005 20:36:27.932761 10142 solver.cpp:218] Iteration 400 (6.31365 iter/s, 15.8387s/100 iters), loss = 1.32661
I1005 20:36:27.932870 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.32661 (* 1 = 1.32661 loss)
I1005 20:36:27.932878 10142 sgd_solver.cpp:105] Iteration 400, lr = 0.1
I1005 20:36:42.998577 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 20:36:43.631124 10142 solver.cpp:330] Iteration 500, Testing net (#0)
I1005 20:36:46.910063 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 20:36:47.037238 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.2687
I1005 20:36:47.037263 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 2.70192 (* 1 = 2.70192 loss)
I1005 20:36:47.168067 10142 solver.cpp:218] Iteration 500 (5.19882 iter/s, 19.2351s/100 iters), loss = 1.36463
I1005 20:36:47.168098 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.36463 (* 1 = 1.36463 loss)
I1005 20:36:47.168105 10142 sgd_solver.cpp:105] Iteration 500, lr = 0.1
I1005 20:37:03.012656 10142 solver.cpp:218] Iteration 600 (6.31134 iter/s, 15.8445s/100 iters), loss = 1.1438
I1005 20:37:03.012745 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.1438 (* 1 = 1.1438 loss)
I1005 20:37:03.012763 10142 sgd_solver.cpp:105] Iteration 600, lr = 0.1
I1005 20:37:18.849861 10142 solver.cpp:218] Iteration 700 (6.31431 iter/s, 15.837s/100 iters), loss = 1.2183
I1005 20:37:18.849902 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.2183 (* 1 = 1.2183 loss)
I1005 20:37:18.849908 10142 sgd_solver.cpp:105] Iteration 700, lr = 0.1
I1005 20:37:34.673684 10142 solver.cpp:218] Iteration 800 (6.31963 iter/s, 15.8237s/100 iters), loss = 1.10635
I1005 20:37:34.673774 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.10635 (* 1 = 1.10635 loss)
I1005 20:37:34.673782 10142 sgd_solver.cpp:105] Iteration 800, lr = 0.1
I1005 20:37:50.583696 10142 solver.cpp:218] Iteration 900 (6.28541 iter/s, 15.9099s/100 iters), loss = 0.885059
I1005 20:37:50.583734 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.885059 (* 1 = 0.885059 loss)
I1005 20:37:50.583741 10142 sgd_solver.cpp:105] Iteration 900, lr = 0.1
I1005 20:38:05.693001 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 20:38:06.296613 10142 solver.cpp:330] Iteration 1000, Testing net (#0)
I1005 20:38:09.471454 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 20:38:09.606178 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.3674
I1005 20:38:09.606205 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 2.30493 (* 1 = 2.30493 loss)
I1005 20:38:09.714538 10142 solver.cpp:218] Iteration 1000 (5.22778 iter/s, 19.1286s/100 iters), loss = 1.01134
I1005 20:38:09.714571 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.01134 (* 1 = 1.01134 loss)
I1005 20:38:09.714588 10142 sgd_solver.cpp:105] Iteration 1000, lr = 0.1
I1005 20:38:25.591387 10142 solver.cpp:218] Iteration 1100 (6.29935 iter/s, 15.8747s/100 iters), loss = 0.694704
I1005 20:38:25.591421 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.694704 (* 1 = 0.694704 loss)
I1005 20:38:25.591439 10142 sgd_solver.cpp:105] Iteration 1100, lr = 0.1
I1005 20:38:41.560603 10142 solver.cpp:218] Iteration 1200 (6.26292 iter/s, 15.967s/100 iters), loss = 0.940447
I1005 20:38:41.560721 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.940447 (* 1 = 0.940447 loss)
I1005 20:38:41.560739 10142 sgd_solver.cpp:105] Iteration 1200, lr = 0.1
I1005 20:38:57.420609 10142 solver.cpp:218] Iteration 1300 (6.30527 iter/s, 15.8597s/100 iters), loss = 0.7444
I1005 20:38:57.420642 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.7444 (* 1 = 0.7444 loss)
I1005 20:38:57.420660 10142 sgd_solver.cpp:105] Iteration 1300, lr = 0.1
I1005 20:39:13.275634 10142 solver.cpp:218] Iteration 1400 (6.30804 iter/s, 15.8528s/100 iters), loss = 0.717343
I1005 20:39:13.275744 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.717343 (* 1 = 0.717343 loss)
I1005 20:39:13.275763 10142 sgd_solver.cpp:105] Iteration 1400, lr = 0.1
I1005 20:39:28.404789 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 20:39:29.013679 10142 solver.cpp:330] Iteration 1500, Testing net (#0)
I1005 20:39:32.271921 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 20:39:32.400825 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.5043
I1005 20:39:32.400863 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.56968 (* 1 = 1.56968 loss)
I1005 20:39:32.530393 10142 solver.cpp:218] Iteration 1500 (5.19365 iter/s, 19.2543s/100 iters), loss = 0.880613
I1005 20:39:32.530449 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.880613 (* 1 = 0.880613 loss)
I1005 20:39:32.530457 10142 sgd_solver.cpp:105] Iteration 1500, lr = 0.1
I1005 20:39:48.446504 10142 solver.cpp:218] Iteration 1600 (6.28299 iter/s, 15.916s/100 iters), loss = 0.513313
I1005 20:39:48.446593 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.513313 (* 1 = 0.513313 loss)
I1005 20:39:48.446601 10142 sgd_solver.cpp:105] Iteration 1600, lr = 0.1
I1005 20:40:04.306774 10142 solver.cpp:218] Iteration 1700 (6.30512 iter/s, 15.8601s/100 iters), loss = 0.770319
I1005 20:40:04.306815 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.770319 (* 1 = 0.770319 loss)
I1005 20:40:04.306821 10142 sgd_solver.cpp:105] Iteration 1700, lr = 0.1
I1005 20:40:20.168221 10142 solver.cpp:218] Iteration 1800 (6.30464 iter/s, 15.8613s/100 iters), loss = 0.711223
I1005 20:40:20.168328 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.711223 (* 1 = 0.711223 loss)
I1005 20:40:20.168344 10142 sgd_solver.cpp:105] Iteration 1800, lr = 0.1
I1005 20:40:36.155596 10142 solver.cpp:218] Iteration 1900 (6.255 iter/s, 15.9872s/100 iters), loss = 0.675926
I1005 20:40:36.155630 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.675926 (* 1 = 0.675926 loss)
I1005 20:40:36.155640 10142 sgd_solver.cpp:105] Iteration 1900, lr = 0.1
I1005 20:40:51.291968 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 20:40:51.897174 10142 solver.cpp:330] Iteration 2000, Testing net (#0)
I1005 20:40:55.107904 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 20:40:55.236421 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6193
I1005 20:40:55.236457 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.06367 (* 1 = 1.06367 loss)
I1005 20:40:55.367136 10142 solver.cpp:218] Iteration 2000 (5.20523 iter/s, 19.2114s/100 iters), loss = 0.747435
I1005 20:40:55.367177 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.747435 (* 1 = 0.747435 loss)
I1005 20:40:55.367184 10142 sgd_solver.cpp:105] Iteration 2000, lr = 0.1
I1005 20:41:11.249783 10142 solver.cpp:218] Iteration 2100 (6.29623 iter/s, 15.8825s/100 iters), loss = 0.486484
I1005 20:41:11.249833 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.486484 (* 1 = 0.486484 loss)
I1005 20:41:11.249842 10142 sgd_solver.cpp:105] Iteration 2100, lr = 0.1
I1005 20:41:27.234753 10142 solver.cpp:218] Iteration 2200 (6.25592 iter/s, 15.9849s/100 iters), loss = 0.651309
I1005 20:41:27.234863 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.651309 (* 1 = 0.651309 loss)
I1005 20:41:27.234870 10142 sgd_solver.cpp:105] Iteration 2200, lr = 0.1
I1005 20:41:43.117303 10142 solver.cpp:218] Iteration 2300 (6.29629 iter/s, 15.8824s/100 iters), loss = 0.633467
I1005 20:41:43.117343 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.633467 (* 1 = 0.633467 loss)
I1005 20:41:43.117349 10142 sgd_solver.cpp:105] Iteration 2300, lr = 0.1
I1005 20:41:58.993645 10142 solver.cpp:218] Iteration 2400 (6.29872 iter/s, 15.8762s/100 iters), loss = 0.534607
I1005 20:41:58.993777 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.534607 (* 1 = 0.534607 loss)
I1005 20:41:58.993794 10142 sgd_solver.cpp:105] Iteration 2400, lr = 0.1
I1005 20:42:14.104677 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 20:42:14.743767 10142 solver.cpp:330] Iteration 2500, Testing net (#0)
I1005 20:42:17.971838 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 20:42:18.108386 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6225
I1005 20:42:18.108415 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.10019 (* 1 = 1.10019 loss)
I1005 20:42:18.228804 10142 solver.cpp:218] Iteration 2500 (5.19887 iter/s, 19.235s/100 iters), loss = 0.660035
I1005 20:42:18.228843 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.660035 (* 1 = 0.660035 loss)
I1005 20:42:18.228864 10142 sgd_solver.cpp:105] Iteration 2500, lr = 0.1
I1005 20:42:34.200664 10142 solver.cpp:218] Iteration 2600 (6.26187 iter/s, 15.9697s/100 iters), loss = 0.363261
I1005 20:42:34.200775 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.363261 (* 1 = 0.363261 loss)
I1005 20:42:34.200783 10142 sgd_solver.cpp:105] Iteration 2600, lr = 0.1
I1005 20:42:50.066100 10142 solver.cpp:218] Iteration 2700 (6.30308 iter/s, 15.8653s/100 iters), loss = 0.529382
I1005 20:42:50.066148 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.529382 (* 1 = 0.529382 loss)
I1005 20:42:50.066156 10142 sgd_solver.cpp:105] Iteration 2700, lr = 0.1
I1005 20:43:05.941632 10142 solver.cpp:218] Iteration 2800 (6.29905 iter/s, 15.8754s/100 iters), loss = 0.541348
I1005 20:43:05.941727 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.541348 (* 1 = 0.541348 loss)
I1005 20:43:05.941746 10142 sgd_solver.cpp:105] Iteration 2800, lr = 0.1
I1005 20:43:21.923877 10142 solver.cpp:218] Iteration 2900 (6.257 iter/s, 15.9821s/100 iters), loss = 0.570763
I1005 20:43:21.923908 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.570763 (* 1 = 0.570763 loss)
I1005 20:43:21.923925 10142 sgd_solver.cpp:105] Iteration 2900, lr = 0.1
I1005 20:43:37.061895 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 20:43:37.663573 10142 solver.cpp:330] Iteration 3000, Testing net (#0)
I1005 20:43:40.880280 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 20:43:41.008245 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6922
I1005 20:43:41.008271 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.844346 (* 1 = 0.844346 loss)
I1005 20:43:41.139340 10142 solver.cpp:218] Iteration 3000 (5.20475 iter/s, 19.2132s/100 iters), loss = 0.490474
I1005 20:43:41.139384 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.490474 (* 1 = 0.490474 loss)
I1005 20:43:41.139390 10142 sgd_solver.cpp:105] Iteration 3000, lr = 0.1
I1005 20:43:56.988044 10142 solver.cpp:218] Iteration 3100 (6.30971 iter/s, 15.8486s/100 iters), loss = 0.429209
I1005 20:43:56.988086 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.429209 (* 1 = 0.429209 loss)
I1005 20:43:56.988093 10142 sgd_solver.cpp:105] Iteration 3100, lr = 0.1
I1005 20:44:12.972215 10142 solver.cpp:218] Iteration 3200 (6.25623 iter/s, 15.9841s/100 iters), loss = 0.519095
I1005 20:44:12.972302 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.519095 (* 1 = 0.519095 loss)
I1005 20:44:12.972321 10142 sgd_solver.cpp:105] Iteration 3200, lr = 0.1
I1005 20:44:28.833725 10142 solver.cpp:218] Iteration 3300 (6.30545 iter/s, 15.8593s/100 iters), loss = 0.555654
I1005 20:44:28.833767 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.555654 (* 1 = 0.555654 loss)
I1005 20:44:28.833775 10142 sgd_solver.cpp:105] Iteration 3300, lr = 0.1
I1005 20:44:44.706645 10142 solver.cpp:218] Iteration 3400 (6.30093 iter/s, 15.8707s/100 iters), loss = 0.427767
I1005 20:44:44.706789 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.427767 (* 1 = 0.427767 loss)
I1005 20:44:44.706809 10142 sgd_solver.cpp:105] Iteration 3400, lr = 0.1
I1005 20:44:59.845718 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 20:45:00.455719 10142 solver.cpp:330] Iteration 3500, Testing net (#0)
I1005 20:45:03.682162 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 20:45:03.816779 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6975
I1005 20:45:03.816817 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.842566 (* 1 = 0.842566 loss)
I1005 20:45:03.928848 10142 solver.cpp:218] Iteration 3500 (5.20291 iter/s, 19.22s/100 iters), loss = 0.428554
I1005 20:45:03.928886 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.428554 (* 1 = 0.428554 loss)
I1005 20:45:03.928894 10142 sgd_solver.cpp:105] Iteration 3500, lr = 0.1
I1005 20:45:19.959380 10142 solver.cpp:218] Iteration 3600 (6.23815 iter/s, 16.0304s/100 iters), loss = 0.428399
I1005 20:45:19.959475 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.428399 (* 1 = 0.428399 loss)
I1005 20:45:19.959491 10142 sgd_solver.cpp:105] Iteration 3600, lr = 0.1
I1005 20:45:35.839184 10142 solver.cpp:218] Iteration 3700 (6.29737 iter/s, 15.8796s/100 iters), loss = 0.427761
I1005 20:45:35.839228 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.427761 (* 1 = 0.427761 loss)
I1005 20:45:35.839236 10142 sgd_solver.cpp:105] Iteration 3700, lr = 0.1
I1005 20:45:51.714500 10142 solver.cpp:218] Iteration 3800 (6.29913 iter/s, 15.8752s/100 iters), loss = 0.538914
I1005 20:45:51.714623 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.538914 (* 1 = 0.538914 loss)
I1005 20:45:51.714633 10142 sgd_solver.cpp:105] Iteration 3800, lr = 0.1
I1005 20:46:07.701548 10142 solver.cpp:218] Iteration 3900 (6.25514 iter/s, 15.9869s/100 iters), loss = 0.459175
I1005 20:46:07.701588 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.459175 (* 1 = 0.459175 loss)
I1005 20:46:07.701596 10142 sgd_solver.cpp:105] Iteration 3900, lr = 0.1
I1005 20:46:22.841380 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 20:46:23.443073 10142 solver.cpp:330] Iteration 4000, Testing net (#0)
I1005 20:46:26.665042 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 20:46:26.793052 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.5265
I1005 20:46:26.793089 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.43976 (* 1 = 1.43976 loss)
I1005 20:46:26.924235 10142 solver.cpp:218] Iteration 4000 (5.20222 iter/s, 19.2226s/100 iters), loss = 0.437563
I1005 20:46:26.924278 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.437563 (* 1 = 0.437563 loss)
I1005 20:46:26.924285 10142 sgd_solver.cpp:105] Iteration 4000, lr = 0.1
I1005 20:46:42.781785 10142 solver.cpp:218] Iteration 4100 (6.30619 iter/s, 15.8574s/100 iters), loss = 0.362708
I1005 20:46:42.781826 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.362708 (* 1 = 0.362708 loss)
I1005 20:46:42.781832 10142 sgd_solver.cpp:105] Iteration 4100, lr = 0.1
I1005 20:46:58.740413 10142 solver.cpp:218] Iteration 4200 (6.26624 iter/s, 15.9585s/100 iters), loss = 0.508546
I1005 20:46:58.740522 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.508546 (* 1 = 0.508546 loss)
I1005 20:46:58.740531 10142 sgd_solver.cpp:105] Iteration 4200, lr = 0.1
I1005 20:47:14.604336 10142 solver.cpp:218] Iteration 4300 (6.30368 iter/s, 15.8638s/100 iters), loss = 0.55456
I1005 20:47:14.604385 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.55456 (* 1 = 0.55456 loss)
I1005 20:47:14.604393 10142 sgd_solver.cpp:105] Iteration 4300, lr = 0.1
I1005 20:47:30.453074 10142 solver.cpp:218] Iteration 4400 (6.30971 iter/s, 15.8486s/100 iters), loss = 0.458548
I1005 20:47:30.453181 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.458548 (* 1 = 0.458548 loss)
I1005 20:47:30.453199 10142 sgd_solver.cpp:105] Iteration 4400, lr = 0.1
I1005 20:47:45.537240 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 20:47:46.169162 10142 solver.cpp:330] Iteration 4500, Testing net (#0)
I1005 20:47:49.401177 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 20:47:49.528832 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6991
I1005 20:47:49.528868 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.858582 (* 1 = 0.858582 loss)
I1005 20:47:49.660284 10142 solver.cpp:218] Iteration 4500 (5.20643 iter/s, 19.207s/100 iters), loss = 0.436873
I1005 20:47:49.660327 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.436873 (* 1 = 0.436873 loss)
I1005 20:47:49.660334 10142 sgd_solver.cpp:105] Iteration 4500, lr = 0.1
I1005 20:48:05.617383 10142 solver.cpp:218] Iteration 4600 (6.26685 iter/s, 15.957s/100 iters), loss = 0.439978
I1005 20:48:05.617471 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.439978 (* 1 = 0.439978 loss)
I1005 20:48:05.617480 10142 sgd_solver.cpp:105] Iteration 4600, lr = 0.1
I1005 20:48:21.488664 10142 solver.cpp:218] Iteration 4700 (6.30077 iter/s, 15.8711s/100 iters), loss = 0.368024
I1005 20:48:21.488696 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.368024 (* 1 = 0.368024 loss)
I1005 20:48:21.488703 10142 sgd_solver.cpp:105] Iteration 4700, lr = 0.1
I1005 20:48:37.355649 10142 solver.cpp:218] Iteration 4800 (6.30243 iter/s, 15.8669s/100 iters), loss = 0.440352
I1005 20:48:37.355751 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.440352 (* 1 = 0.440352 loss)
I1005 20:48:37.355757 10142 sgd_solver.cpp:105] Iteration 4800, lr = 0.1
I1005 20:48:53.330304 10142 solver.cpp:218] Iteration 4900 (6.25998 iter/s, 15.9745s/100 iters), loss = 0.468176
I1005 20:48:53.330338 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.468176 (* 1 = 0.468176 loss)
I1005 20:48:53.330344 10142 sgd_solver.cpp:105] Iteration 4900, lr = 0.1
I1005 20:49:08.447329 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 20:49:09.086515 10142 solver.cpp:330] Iteration 5000, Testing net (#0)
I1005 20:49:12.318912 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 20:49:12.446804 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.702
I1005 20:49:12.446841 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.875551 (* 1 = 0.875551 loss)
I1005 20:49:12.578936 10142 solver.cpp:218] Iteration 5000 (5.1952 iter/s, 19.2485s/100 iters), loss = 0.411025
I1005 20:49:12.578981 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.411025 (* 1 = 0.411025 loss)
I1005 20:49:12.578989 10142 sgd_solver.cpp:105] Iteration 5000, lr = 0.1
I1005 20:49:28.385576 10142 solver.cpp:218] Iteration 5100 (6.3265 iter/s, 15.8065s/100 iters), loss = 0.352939
I1005 20:49:28.385609 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.352939 (* 1 = 0.352939 loss)
I1005 20:49:28.385617 10142 sgd_solver.cpp:105] Iteration 5100, lr = 0.1
I1005 20:49:44.300952 10142 solver.cpp:218] Iteration 5200 (6.28327 iter/s, 15.9153s/100 iters), loss = 0.250284
I1005 20:49:44.301038 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.250284 (* 1 = 0.250284 loss)
I1005 20:49:44.301046 10142 sgd_solver.cpp:105] Iteration 5200, lr = 0.1
I1005 20:50:00.194322 10142 solver.cpp:218] Iteration 5300 (6.29282 iter/s, 15.8911s/100 iters), loss = 0.426928
I1005 20:50:00.194367 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.426928 (* 1 = 0.426928 loss)
I1005 20:50:00.194375 10142 sgd_solver.cpp:105] Iteration 5300, lr = 0.1
I1005 20:50:16.047950 10142 solver.cpp:218] Iteration 5400 (6.30783 iter/s, 15.8533s/100 iters), loss = 0.378578
I1005 20:50:16.048032 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.378578 (* 1 = 0.378578 loss)
I1005 20:50:16.048050 10142 sgd_solver.cpp:105] Iteration 5400, lr = 0.1
I1005 20:50:31.132194 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 20:50:31.764309 10142 solver.cpp:330] Iteration 5500, Testing net (#0)
I1005 20:50:34.995328 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 20:50:35.125005 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6995
I1005 20:50:35.125035 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.895088 (* 1 = 0.895088 loss)
I1005 20:50:35.254578 10142 solver.cpp:218] Iteration 5500 (5.20658 iter/s, 19.2065s/100 iters), loss = 0.35333
I1005 20:50:35.254622 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.35333 (* 1 = 0.35333 loss)
I1005 20:50:35.254629 10142 sgd_solver.cpp:105] Iteration 5500, lr = 0.1
I1005 20:50:51.225502 10142 solver.cpp:218] Iteration 5600 (6.26142 iter/s, 15.9708s/100 iters), loss = 0.329296
I1005 20:50:51.225661 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.329296 (* 1 = 0.329296 loss)
I1005 20:50:51.225672 10142 sgd_solver.cpp:105] Iteration 5600, lr = 0.1
I1005 20:51:07.086988 10142 solver.cpp:218] Iteration 5700 (6.30467 iter/s, 15.8613s/100 iters), loss = 0.385746
I1005 20:51:07.087031 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.385746 (* 1 = 0.385746 loss)
I1005 20:51:07.087038 10142 sgd_solver.cpp:105] Iteration 5700, lr = 0.1
I1005 20:51:22.958642 10142 solver.cpp:218] Iteration 5800 (6.30058 iter/s, 15.8715s/100 iters), loss = 0.52686
I1005 20:51:22.958715 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.52686 (* 1 = 0.52686 loss)
I1005 20:51:22.958722 10142 sgd_solver.cpp:105] Iteration 5800, lr = 0.1
I1005 20:51:38.953342 10142 solver.cpp:218] Iteration 5900 (6.25212 iter/s, 15.9946s/100 iters), loss = 0.425762
I1005 20:51:38.953385 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.425762 (* 1 = 0.425762 loss)
I1005 20:51:38.953392 10142 sgd_solver.cpp:105] Iteration 5900, lr = 0.1
I1005 20:51:54.088102 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 20:51:54.689792 10142 solver.cpp:330] Iteration 6000, Testing net (#0)
I1005 20:51:57.907150 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 20:51:58.035969 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7667
I1005 20:51:58.036003 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.68119 (* 1 = 0.68119 loss)
I1005 20:51:58.149616 10142 solver.cpp:218] Iteration 6000 (5.20938 iter/s, 19.1962s/100 iters), loss = 0.408123
I1005 20:51:58.149658 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.408123 (* 1 = 0.408123 loss)
I1005 20:51:58.149664 10142 sgd_solver.cpp:105] Iteration 6000, lr = 0.1
I1005 20:52:14.005290 10142 solver.cpp:218] Iteration 6100 (6.30776 iter/s, 15.8535s/100 iters), loss = 0.338533
I1005 20:52:14.005331 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.338533 (* 1 = 0.338533 loss)
I1005 20:52:14.005336 10142 sgd_solver.cpp:105] Iteration 6100, lr = 0.1
I1005 20:52:29.925771 10142 solver.cpp:218] Iteration 6200 (6.28126 iter/s, 15.9204s/100 iters), loss = 0.349041
I1005 20:52:29.925878 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.349041 (* 1 = 0.349041 loss)
I1005 20:52:29.925896 10142 sgd_solver.cpp:105] Iteration 6200, lr = 0.1
I1005 20:52:45.880623 10142 solver.cpp:218] Iteration 6300 (6.26855 iter/s, 15.9527s/100 iters), loss = 0.425741
I1005 20:52:45.880656 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.425741 (* 1 = 0.425741 loss)
I1005 20:52:45.880661 10142 sgd_solver.cpp:105] Iteration 6300, lr = 0.1
I1005 20:53:01.746601 10142 solver.cpp:218] Iteration 6400 (6.30283 iter/s, 15.8659s/100 iters), loss = 0.305597
I1005 20:53:01.746747 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.305597 (* 1 = 0.305597 loss)
I1005 20:53:01.746757 10142 sgd_solver.cpp:105] Iteration 6400, lr = 0.1
I1005 20:53:16.846197 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 20:53:17.479504 10142 solver.cpp:330] Iteration 6500, Testing net (#0)
I1005 20:53:20.689318 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 20:53:20.837471 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7424
I1005 20:53:20.837517 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.769843 (* 1 = 0.769843 loss)
I1005 20:53:20.940567 10142 solver.cpp:218] Iteration 6500 (5.21003 iter/s, 19.1938s/100 iters), loss = 0.376195
I1005 20:53:20.940610 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.376195 (* 1 = 0.376195 loss)
I1005 20:53:20.940618 10142 sgd_solver.cpp:105] Iteration 6500, lr = 0.1
I1005 20:53:36.899679 10142 solver.cpp:218] Iteration 6600 (6.26689 iter/s, 15.9569s/100 iters), loss = 0.357713
I1005 20:53:36.899792 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.357713 (* 1 = 0.357713 loss)
I1005 20:53:36.899811 10142 sgd_solver.cpp:105] Iteration 6600, lr = 0.1
I1005 20:53:52.760351 10142 solver.cpp:218] Iteration 6700 (6.30581 iter/s, 15.8584s/100 iters), loss = 0.25535
I1005 20:53:52.760385 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.25535 (* 1 = 0.25535 loss)
I1005 20:53:52.760403 10142 sgd_solver.cpp:105] Iteration 6700, lr = 0.1
I1005 20:54:08.634961 10142 solver.cpp:218] Iteration 6800 (6.30024 iter/s, 15.8724s/100 iters), loss = 0.4629
I1005 20:54:08.635092 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.4629 (* 1 = 0.4629 loss)
I1005 20:54:08.635125 10142 sgd_solver.cpp:105] Iteration 6800, lr = 0.1
I1005 20:54:24.652530 10142 solver.cpp:218] Iteration 6900 (6.24404 iter/s, 16.0153s/100 iters), loss = 0.288297
I1005 20:54:24.652565 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.288298 (* 1 = 0.288298 loss)
I1005 20:54:24.652583 10142 sgd_solver.cpp:105] Iteration 6900, lr = 0.1
I1005 20:54:39.771893 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 20:54:40.404584 10142 solver.cpp:330] Iteration 7000, Testing net (#0)
I1005 20:54:43.637413 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 20:54:43.765424 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7627
I1005 20:54:43.765461 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.695109 (* 1 = 0.695109 loss)
I1005 20:54:43.897311 10142 solver.cpp:218] Iteration 7000 (5.19624 iter/s, 19.2447s/100 iters), loss = 0.448746
I1005 20:54:43.897352 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.448746 (* 1 = 0.448746 loss)
I1005 20:54:43.897358 10142 sgd_solver.cpp:105] Iteration 7000, lr = 0.1
I1005 20:54:59.777138 10142 solver.cpp:218] Iteration 7100 (6.29751 iter/s, 15.8793s/100 iters), loss = 0.340487
I1005 20:54:59.777185 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.340487 (* 1 = 0.340487 loss)
I1005 20:54:59.777192 10142 sgd_solver.cpp:105] Iteration 7100, lr = 0.1
I1005 20:55:15.652079 10142 solver.cpp:218] Iteration 7200 (6.29928 iter/s, 15.8748s/100 iters), loss = 0.433431
I1005 20:55:15.652144 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.433431 (* 1 = 0.433431 loss)
I1005 20:55:15.652164 10142 sgd_solver.cpp:105] Iteration 7200, lr = 0.1
I1005 20:55:31.649184 10142 solver.cpp:218] Iteration 7300 (6.25118 iter/s, 15.997s/100 iters), loss = 0.418664
I1005 20:55:31.649217 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.418664 (* 1 = 0.418664 loss)
I1005 20:55:31.649235 10142 sgd_solver.cpp:105] Iteration 7300, lr = 0.1
I1005 20:55:47.523862 10142 solver.cpp:218] Iteration 7400 (6.29938 iter/s, 15.8746s/100 iters), loss = 0.327787
I1005 20:55:47.523957 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.327787 (* 1 = 0.327787 loss)
I1005 20:55:47.523978 10142 sgd_solver.cpp:105] Iteration 7400, lr = 0.1
I1005 20:56:02.676637 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 20:56:03.285109 10142 solver.cpp:330] Iteration 7500, Testing net (#0)
I1005 20:56:06.499395 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 20:56:06.627530 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7583
I1005 20:56:06.627566 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.726943 (* 1 = 0.726943 loss)
I1005 20:56:06.757993 10142 solver.cpp:218] Iteration 7500 (5.19971 iter/s, 19.2319s/100 iters), loss = 0.312458
I1005 20:56:06.758038 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.312458 (* 1 = 0.312458 loss)
I1005 20:56:06.758044 10142 sgd_solver.cpp:105] Iteration 7500, lr = 0.1
I1005 20:56:22.746932 10142 solver.cpp:218] Iteration 7600 (6.25437 iter/s, 15.9888s/100 iters), loss = 0.342483
I1005 20:56:22.747056 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.342483 (* 1 = 0.342483 loss)
I1005 20:56:22.747064 10142 sgd_solver.cpp:105] Iteration 7600, lr = 0.1
I1005 20:56:38.611179 10142 solver.cpp:218] Iteration 7700 (6.30437 iter/s, 15.862s/100 iters), loss = 0.263131
I1005 20:56:38.611227 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.263131 (* 1 = 0.263131 loss)
I1005 20:56:38.611233 10142 sgd_solver.cpp:105] Iteration 7700, lr = 0.1
I1005 20:56:54.482693 10142 solver.cpp:218] Iteration 7800 (6.30065 iter/s, 15.8714s/100 iters), loss = 0.464224
I1005 20:56:54.482795 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.464224 (* 1 = 0.464224 loss)
I1005 20:56:54.482803 10142 sgd_solver.cpp:105] Iteration 7800, lr = 0.1
I1005 20:57:10.448616 10142 solver.cpp:218] Iteration 7900 (6.26421 iter/s, 15.9637s/100 iters), loss = 0.283796
I1005 20:57:10.448657 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.283796 (* 1 = 0.283796 loss)
I1005 20:57:10.448664 10142 sgd_solver.cpp:105] Iteration 7900, lr = 0.1
I1005 20:57:25.585026 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 20:57:26.190529 10142 solver.cpp:330] Iteration 8000, Testing net (#0)
I1005 20:57:29.400523 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 20:57:29.528939 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.703
I1005 20:57:29.528976 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.925379 (* 1 = 0.925379 loss)
I1005 20:57:29.661803 10142 solver.cpp:218] Iteration 8000 (5.20479 iter/s, 19.2131s/100 iters), loss = 0.304437
I1005 20:57:29.661849 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.304437 (* 1 = 0.304437 loss)
I1005 20:57:29.661856 10142 sgd_solver.cpp:105] Iteration 8000, lr = 0.1
I1005 20:57:45.518177 10142 solver.cpp:218] Iteration 8100 (6.30667 iter/s, 15.8562s/100 iters), loss = 0.328145
I1005 20:57:45.518219 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.328145 (* 1 = 0.328145 loss)
I1005 20:57:45.518226 10142 sgd_solver.cpp:105] Iteration 8100, lr = 0.1
I1005 20:58:01.379042 10142 solver.cpp:218] Iteration 8200 (6.30487 iter/s, 15.8608s/100 iters), loss = 0.306692
I1005 20:58:01.379189 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.306692 (* 1 = 0.306692 loss)
I1005 20:58:01.379197 10142 sgd_solver.cpp:105] Iteration 8200, lr = 0.1
I1005 20:58:17.305351 10142 solver.cpp:218] Iteration 8300 (6.279 iter/s, 15.9261s/100 iters), loss = 0.259811
I1005 20:58:17.305382 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.259811 (* 1 = 0.259811 loss)
I1005 20:58:17.305388 10142 sgd_solver.cpp:105] Iteration 8300, lr = 0.1
I1005 20:58:33.163192 10142 solver.cpp:218] Iteration 8400 (6.30607 iter/s, 15.8577s/100 iters), loss = 0.294678
I1005 20:58:33.163267 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.294678 (* 1 = 0.294678 loss)
I1005 20:58:33.163275 10142 sgd_solver.cpp:105] Iteration 8400, lr = 0.1
I1005 20:58:48.290503 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 20:58:48.898188 10142 solver.cpp:330] Iteration 8500, Testing net (#0)
I1005 20:58:52.116852 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 20:58:52.244174 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7775
I1005 20:58:52.244207 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.646036 (* 1 = 0.646036 loss)
I1005 20:58:52.375547 10142 solver.cpp:218] Iteration 8500 (5.20502 iter/s, 19.2122s/100 iters), loss = 0.294581
I1005 20:58:52.375589 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.294581 (* 1 = 0.294581 loss)
I1005 20:58:52.375596 10142 sgd_solver.cpp:105] Iteration 8500, lr = 0.1
I1005 20:59:08.336525 10142 solver.cpp:218] Iteration 8600 (6.26532 iter/s, 15.9609s/100 iters), loss = 0.325089
I1005 20:59:08.336660 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.325089 (* 1 = 0.325089 loss)
I1005 20:59:08.336668 10142 sgd_solver.cpp:105] Iteration 8600, lr = 0.1
I1005 20:59:24.202019 10142 solver.cpp:218] Iteration 8700 (6.30307 iter/s, 15.8653s/100 iters), loss = 0.314074
I1005 20:59:24.202061 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.314074 (* 1 = 0.314074 loss)
I1005 20:59:24.202067 10142 sgd_solver.cpp:105] Iteration 8700, lr = 0.1
I1005 20:59:40.068544 10142 solver.cpp:218] Iteration 8800 (6.30262 iter/s, 15.8664s/100 iters), loss = 0.335393
I1005 20:59:40.068653 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.335393 (* 1 = 0.335393 loss)
I1005 20:59:40.068661 10142 sgd_solver.cpp:105] Iteration 8800, lr = 0.1
I1005 20:59:55.992637 10142 solver.cpp:218] Iteration 8900 (6.27986 iter/s, 15.9239s/100 iters), loss = 0.288729
I1005 20:59:55.992676 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.288729 (* 1 = 0.288729 loss)
I1005 20:59:55.992683 10142 sgd_solver.cpp:105] Iteration 8900, lr = 0.1
I1005 21:00:11.123906 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 21:00:11.736127 10142 solver.cpp:330] Iteration 9000, Testing net (#0)
I1005 21:00:14.954869 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 21:00:15.083225 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.77
I1005 21:00:15.083259 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.698605 (* 1 = 0.698605 loss)
I1005 21:00:15.214993 10142 solver.cpp:218] Iteration 9000 (5.20232 iter/s, 19.2222s/100 iters), loss = 0.304671
I1005 21:00:15.215030 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.304671 (* 1 = 0.304671 loss)
I1005 21:00:15.215047 10142 sgd_solver.cpp:105] Iteration 9000, lr = 0.1
I1005 21:00:31.075975 10142 solver.cpp:218] Iteration 9100 (6.30482 iter/s, 15.8609s/100 iters), loss = 0.313711
I1005 21:00:31.076014 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.313711 (* 1 = 0.313711 loss)
I1005 21:00:31.076020 10142 sgd_solver.cpp:105] Iteration 9100, lr = 0.1
I1005 21:00:46.940040 10142 solver.cpp:218] Iteration 9200 (6.3036 iter/s, 15.864s/100 iters), loss = 0.238343
I1005 21:00:46.940158 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.238343 (* 1 = 0.238343 loss)
I1005 21:00:46.940176 10142 sgd_solver.cpp:105] Iteration 9200, lr = 0.1
I1005 21:01:02.874394 10142 solver.cpp:218] Iteration 9300 (6.27582 iter/s, 15.9342s/100 iters), loss = 0.283764
I1005 21:01:02.874428 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.283764 (* 1 = 0.283764 loss)
I1005 21:01:02.874436 10142 sgd_solver.cpp:105] Iteration 9300, lr = 0.1
I1005 21:01:18.745416 10142 solver.cpp:218] Iteration 9400 (6.30083 iter/s, 15.8709s/100 iters), loss = 0.235065
I1005 21:01:18.745537 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.235065 (* 1 = 0.235065 loss)
I1005 21:01:18.745554 10142 sgd_solver.cpp:105] Iteration 9400, lr = 0.1
I1005 21:01:33.838325 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 21:01:34.440902 10142 solver.cpp:330] Iteration 9500, Testing net (#0)
I1005 21:01:37.646430 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 21:01:37.774022 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8112
I1005 21:01:37.774049 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.554152 (* 1 = 0.554152 loss)
I1005 21:01:37.904001 10142 solver.cpp:218] Iteration 9500 (5.22022 iter/s, 19.1563s/100 iters), loss = 0.240727
I1005 21:01:37.904036 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.240727 (* 1 = 0.240727 loss)
I1005 21:01:37.904042 10142 sgd_solver.cpp:105] Iteration 9500, lr = 0.1
I1005 21:01:53.875138 10142 solver.cpp:218] Iteration 9600 (6.26133 iter/s, 15.971s/100 iters), loss = 0.253685
I1005 21:01:53.875258 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.253685 (* 1 = 0.253685 loss)
I1005 21:01:53.875277 10142 sgd_solver.cpp:105] Iteration 9600, lr = 0.1
I1005 21:02:09.753690 10142 solver.cpp:218] Iteration 9700 (6.29868 iter/s, 15.8763s/100 iters), loss = 0.370828
I1005 21:02:09.753731 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.370829 (* 1 = 0.370829 loss)
I1005 21:02:09.753737 10142 sgd_solver.cpp:105] Iteration 9700, lr = 0.1
I1005 21:02:25.626864 10142 solver.cpp:218] Iteration 9800 (6.30081 iter/s, 15.871s/100 iters), loss = 0.32482
I1005 21:02:25.626988 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.324821 (* 1 = 0.324821 loss)
I1005 21:02:25.627007 10142 sgd_solver.cpp:105] Iteration 9800, lr = 0.1
I1005 21:02:41.542575 10142 solver.cpp:218] Iteration 9900 (6.28398 iter/s, 15.9135s/100 iters), loss = 0.26824
I1005 21:02:41.542619 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.26824 (* 1 = 0.26824 loss)
I1005 21:02:41.542628 10142 sgd_solver.cpp:105] Iteration 9900, lr = 0.1
I1005 21:02:56.713783 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 21:02:57.349818 10142 solver.cpp:330] Iteration 10000, Testing net (#0)
I1005 21:03:00.559702 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 21:03:00.694250 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7817
I1005 21:03:00.694285 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.636906 (* 1 = 0.636906 loss)
I1005 21:03:00.802917 10142 solver.cpp:218] Iteration 10000 (5.19209 iter/s, 19.2601s/100 iters), loss = 0.23216
I1005 21:03:00.802956 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.23216 (* 1 = 0.23216 loss)
I1005 21:03:00.802963 10142 sgd_solver.cpp:105] Iteration 10000, lr = 0.1
I1005 21:03:16.656877 10142 solver.cpp:218] Iteration 10100 (6.30822 iter/s, 15.8523s/100 iters), loss = 0.279926
I1005 21:03:16.656918 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.279926 (* 1 = 0.279926 loss)
I1005 21:03:16.656924 10142 sgd_solver.cpp:105] Iteration 10100, lr = 0.1
I1005 21:03:32.512778 10142 solver.cpp:218] Iteration 10200 (6.30684 iter/s, 15.8558s/100 iters), loss = 0.272506
I1005 21:03:32.512864 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.272507 (* 1 = 0.272507 loss)
I1005 21:03:32.512881 10142 sgd_solver.cpp:105] Iteration 10200, lr = 0.1
I1005 21:03:48.518777 10142 solver.cpp:218] Iteration 10300 (6.24772 iter/s, 16.0058s/100 iters), loss = 0.314357
I1005 21:03:48.518820 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.314358 (* 1 = 0.314358 loss)
I1005 21:03:48.518826 10142 sgd_solver.cpp:105] Iteration 10300, lr = 0.1
I1005 21:04:04.391548 10142 solver.cpp:218] Iteration 10400 (6.30014 iter/s, 15.8727s/100 iters), loss = 0.268076
I1005 21:04:04.391696 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.268077 (* 1 = 0.268077 loss)
I1005 21:04:04.391705 10142 sgd_solver.cpp:105] Iteration 10400, lr = 0.1
I1005 21:04:19.485321 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 21:04:20.117620 10142 solver.cpp:330] Iteration 10500, Testing net (#0)
I1005 21:04:23.330839 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 21:04:23.463773 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7053
I1005 21:04:23.463809 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.00914 (* 1 = 1.00914 loss)
I1005 21:04:23.573942 10142 solver.cpp:218] Iteration 10500 (5.21317 iter/s, 19.1822s/100 iters), loss = 0.24226
I1005 21:04:23.573990 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.24226 (* 1 = 0.24226 loss)
I1005 21:04:23.573997 10142 sgd_solver.cpp:105] Iteration 10500, lr = 0.1
I1005 21:04:39.520015 10142 solver.cpp:218] Iteration 10600 (6.27119 iter/s, 15.9459s/100 iters), loss = 0.265813
I1005 21:04:39.520136 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.265813 (* 1 = 0.265813 loss)
I1005 21:04:39.520154 10142 sgd_solver.cpp:105] Iteration 10600, lr = 0.1
I1005 21:04:55.383855 10142 solver.cpp:218] Iteration 10700 (6.30372 iter/s, 15.8637s/100 iters), loss = 0.317092
I1005 21:04:55.383898 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.317092 (* 1 = 0.317092 loss)
I1005 21:04:55.383903 10142 sgd_solver.cpp:105] Iteration 10700, lr = 0.1
I1005 21:05:11.247591 10142 solver.cpp:218] Iteration 10800 (6.30373 iter/s, 15.8636s/100 iters), loss = 0.287734
I1005 21:05:11.247714 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.287734 (* 1 = 0.287734 loss)
I1005 21:05:11.247732 10142 sgd_solver.cpp:105] Iteration 10800, lr = 0.1
I1005 21:05:27.060125 10142 solver.cpp:218] Iteration 10900 (6.32417 iter/s, 15.8123s/100 iters), loss = 0.262036
I1005 21:05:27.060156 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.262036 (* 1 = 0.262036 loss)
I1005 21:05:27.060174 10142 sgd_solver.cpp:105] Iteration 10900, lr = 0.1
I1005 21:05:42.298496 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 21:05:42.904438 10142 solver.cpp:330] Iteration 11000, Testing net (#0)
I1005 21:05:46.121039 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 21:05:46.248999 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7909
I1005 21:05:46.249034 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.639941 (* 1 = 0.639941 loss)
I1005 21:05:46.380972 10142 solver.cpp:218] Iteration 11000 (5.17578 iter/s, 19.3207s/100 iters), loss = 0.274752
I1005 21:05:46.381017 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.274753 (* 1 = 0.274753 loss)
I1005 21:05:46.381024 10142 sgd_solver.cpp:105] Iteration 11000, lr = 0.1
I1005 21:06:02.221060 10142 solver.cpp:218] Iteration 11100 (6.31314 iter/s, 15.84s/100 iters), loss = 0.282734
I1005 21:06:02.221101 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.282734 (* 1 = 0.282734 loss)
I1005 21:06:02.221107 10142 sgd_solver.cpp:105] Iteration 11100, lr = 0.1
I1005 21:06:18.075508 10142 solver.cpp:218] Iteration 11200 (6.30742 iter/s, 15.8543s/100 iters), loss = 0.328464
I1005 21:06:18.075656 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.328464 (* 1 = 0.328464 loss)
I1005 21:06:18.075665 10142 sgd_solver.cpp:105] Iteration 11200, lr = 0.1
I1005 21:06:33.989723 10142 solver.cpp:218] Iteration 11300 (6.28377 iter/s, 15.914s/100 iters), loss = 0.338922
I1005 21:06:33.989753 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.338922 (* 1 = 0.338922 loss)
I1005 21:06:33.989760 10142 sgd_solver.cpp:105] Iteration 11300, lr = 0.1
I1005 21:06:49.836016 10142 solver.cpp:218] Iteration 11400 (6.31066 iter/s, 15.8462s/100 iters), loss = 0.325029
I1005 21:06:49.836086 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.325029 (* 1 = 0.325029 loss)
I1005 21:06:49.836096 10142 sgd_solver.cpp:105] Iteration 11400, lr = 0.1
I1005 21:07:04.928510 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 21:07:05.561394 10142 solver.cpp:330] Iteration 11500, Testing net (#0)
I1005 21:07:08.794483 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 21:07:08.924851 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7909
I1005 21:07:08.924882 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.681684 (* 1 = 0.681684 loss)
I1005 21:07:09.054785 10142 solver.cpp:218] Iteration 11500 (5.20328 iter/s, 19.2186s/100 iters), loss = 0.380178
I1005 21:07:09.054831 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.380178 (* 1 = 0.380178 loss)
I1005 21:07:09.054837 10142 sgd_solver.cpp:105] Iteration 11500, lr = 0.1
I1005 21:07:24.982677 10142 solver.cpp:218] Iteration 11600 (6.27834 iter/s, 15.9278s/100 iters), loss = 0.280086
I1005 21:07:24.982806 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.280086 (* 1 = 0.280086 loss)
I1005 21:07:24.982825 10142 sgd_solver.cpp:105] Iteration 11600, lr = 0.1
I1005 21:07:40.828644 10142 solver.cpp:218] Iteration 11700 (6.31165 iter/s, 15.8437s/100 iters), loss = 0.407745
I1005 21:07:40.828685 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.407745 (* 1 = 0.407745 loss)
I1005 21:07:40.828692 10142 sgd_solver.cpp:105] Iteration 11700, lr = 0.1
I1005 21:07:56.687489 10142 solver.cpp:218] Iteration 11800 (6.30567 iter/s, 15.8587s/100 iters), loss = 0.282314
I1005 21:07:56.687578 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.282314 (* 1 = 0.282314 loss)
I1005 21:07:56.687587 10142 sgd_solver.cpp:105] Iteration 11800, lr = 0.1
I1005 21:08:12.545258 10142 solver.cpp:218] Iteration 11900 (6.30614 iter/s, 15.8576s/100 iters), loss = 0.205613
I1005 21:08:12.545298 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.205613 (* 1 = 0.205613 loss)
I1005 21:08:12.545305 10142 sgd_solver.cpp:105] Iteration 11900, lr = 0.1
I1005 21:08:27.736428 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 21:08:28.367537 10142 solver.cpp:330] Iteration 12000, Testing net (#0)
I1005 21:08:31.594913 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 21:08:31.723012 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7481
I1005 21:08:31.723038 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.882965 (* 1 = 0.882965 loss)
I1005 21:08:31.854343 10142 solver.cpp:218] Iteration 12000 (5.17894 iter/s, 19.309s/100 iters), loss = 0.26741
I1005 21:08:31.854384 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.26741 (* 1 = 0.26741 loss)
I1005 21:08:31.854390 10142 sgd_solver.cpp:105] Iteration 12000, lr = 0.1
I1005 21:08:47.698092 10142 solver.cpp:218] Iteration 12100 (6.31168 iter/s, 15.8436s/100 iters), loss = 0.238692
I1005 21:08:47.698141 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.238693 (* 1 = 0.238693 loss)
I1005 21:08:47.698148 10142 sgd_solver.cpp:105] Iteration 12100, lr = 0.1
I1005 21:09:03.559366 10142 solver.cpp:218] Iteration 12200 (6.30472 iter/s, 15.8611s/100 iters), loss = 0.258118
I1005 21:09:03.559449 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.258119 (* 1 = 0.258119 loss)
I1005 21:09:03.559458 10142 sgd_solver.cpp:105] Iteration 12200, lr = 0.1
I1005 21:09:19.517683 10142 solver.cpp:218] Iteration 12300 (6.26638 iter/s, 15.9582s/100 iters), loss = 0.351186
I1005 21:09:19.517724 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.351186 (* 1 = 0.351186 loss)
I1005 21:09:19.517731 10142 sgd_solver.cpp:105] Iteration 12300, lr = 0.1
I1005 21:09:35.359802 10142 solver.cpp:218] Iteration 12400 (6.31233 iter/s, 15.842s/100 iters), loss = 0.233273
I1005 21:09:35.359874 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.233273 (* 1 = 0.233273 loss)
I1005 21:09:35.359891 10142 sgd_solver.cpp:105] Iteration 12400, lr = 0.1
I1005 21:09:50.450861 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 21:09:51.087739 10142 solver.cpp:330] Iteration 12500, Testing net (#0)
I1005 21:09:54.316068 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 21:09:54.444751 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6134
I1005 21:09:54.444787 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.65571 (* 1 = 1.65571 loss)
I1005 21:09:54.554806 10142 solver.cpp:218] Iteration 12500 (5.20973 iter/s, 19.1949s/100 iters), loss = 0.305298
I1005 21:09:54.554848 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.305298 (* 1 = 0.305298 loss)
I1005 21:09:54.554857 10142 sgd_solver.cpp:105] Iteration 12500, lr = 0.1
I1005 21:10:10.422536 10142 solver.cpp:218] Iteration 12600 (6.30297 iter/s, 15.8655s/100 iters), loss = 0.280367
I1005 21:10:10.422638 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.280367 (* 1 = 0.280367 loss)
I1005 21:10:10.422662 10142 sgd_solver.cpp:105] Iteration 12600, lr = 0.1
I1005 21:10:26.271128 10142 solver.cpp:218] Iteration 12700 (6.30977 iter/s, 15.8484s/100 iters), loss = 0.254399
I1005 21:10:26.271170 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.254399 (* 1 = 0.254399 loss)
I1005 21:10:26.271178 10142 sgd_solver.cpp:105] Iteration 12700, lr = 0.1
I1005 21:10:42.140367 10142 solver.cpp:218] Iteration 12800 (6.30154 iter/s, 15.8691s/100 iters), loss = 0.292699
I1005 21:10:42.140450 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.2927 (* 1 = 0.2927 loss)
I1005 21:10:42.140460 10142 sgd_solver.cpp:105] Iteration 12800, lr = 0.1
I1005 21:10:57.998306 10142 solver.cpp:218] Iteration 12900 (6.30605 iter/s, 15.8578s/100 iters), loss = 0.300395
I1005 21:10:57.998345 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.300396 (* 1 = 0.300396 loss)
I1005 21:10:57.998353 10142 sgd_solver.cpp:105] Iteration 12900, lr = 0.1
I1005 21:11:13.152798 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 21:11:13.787047 10142 solver.cpp:330] Iteration 13000, Testing net (#0)
I1005 21:11:17.014986 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 21:11:17.142678 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8215
I1005 21:11:17.142714 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.550949 (* 1 = 0.550949 loss)
I1005 21:11:17.275584 10142 solver.cpp:218] Iteration 13000 (5.18748 iter/s, 19.2772s/100 iters), loss = 0.194823
I1005 21:11:17.275627 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.194823 (* 1 = 0.194823 loss)
I1005 21:11:17.275634 10142 sgd_solver.cpp:105] Iteration 13000, lr = 0.1
I1005 21:11:33.131078 10142 solver.cpp:218] Iteration 13100 (6.307 iter/s, 15.8554s/100 iters), loss = 0.305103
I1005 21:11:33.131121 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.305103 (* 1 = 0.305103 loss)
I1005 21:11:33.131127 10142 sgd_solver.cpp:105] Iteration 13100, lr = 0.1
I1005 21:11:48.975047 10142 solver.cpp:218] Iteration 13200 (6.31159 iter/s, 15.8439s/100 iters), loss = 0.368985
I1005 21:11:48.975198 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.368985 (* 1 = 0.368985 loss)
I1005 21:11:48.975206 10142 sgd_solver.cpp:105] Iteration 13200, lr = 0.1
I1005 21:12:04.887287 10142 solver.cpp:218] Iteration 13300 (6.28455 iter/s, 15.912s/100 iters), loss = 0.239008
I1005 21:12:04.887328 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.239008 (* 1 = 0.239008 loss)
I1005 21:12:04.887336 10142 sgd_solver.cpp:105] Iteration 13300, lr = 0.1
I1005 21:12:20.757406 10142 solver.cpp:218] Iteration 13400 (6.3012 iter/s, 15.87s/100 iters), loss = 0.239321
I1005 21:12:20.757498 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.239321 (* 1 = 0.239321 loss)
I1005 21:12:20.757508 10142 sgd_solver.cpp:105] Iteration 13400, lr = 0.1
I1005 21:12:35.849992 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 21:12:36.482674 10142 solver.cpp:330] Iteration 13500, Testing net (#0)
I1005 21:12:39.706629 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 21:12:39.834530 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7189
I1005 21:12:39.834558 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.877205 (* 1 = 0.877205 loss)
I1005 21:12:39.966120 10142 solver.cpp:218] Iteration 13500 (5.20603 iter/s, 19.2085s/100 iters), loss = 0.249307
I1005 21:12:39.966156 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.249307 (* 1 = 0.249307 loss)
I1005 21:12:39.966164 10142 sgd_solver.cpp:105] Iteration 13500, lr = 0.1
I1005 21:12:55.882066 10142 solver.cpp:218] Iteration 13600 (6.28305 iter/s, 15.9158s/100 iters), loss = 0.233514
I1005 21:12:55.882176 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.233514 (* 1 = 0.233514 loss)
I1005 21:12:55.882194 10142 sgd_solver.cpp:105] Iteration 13600, lr = 0.1
I1005 21:13:11.734223 10142 solver.cpp:218] Iteration 13700 (6.3092 iter/s, 15.8499s/100 iters), loss = 0.239773
I1005 21:13:11.734271 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.239773 (* 1 = 0.239773 loss)
I1005 21:13:11.734282 10142 sgd_solver.cpp:105] Iteration 13700, lr = 0.1
I1005 21:13:27.573477 10142 solver.cpp:218] Iteration 13800 (6.31348 iter/s, 15.8391s/100 iters), loss = 0.274282
I1005 21:13:27.573566 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.274282 (* 1 = 0.274282 loss)
I1005 21:13:27.573575 10142 sgd_solver.cpp:105] Iteration 13800, lr = 0.1
I1005 21:13:43.426530 10142 solver.cpp:218] Iteration 13900 (6.30799 iter/s, 15.8529s/100 iters), loss = 0.217793
I1005 21:13:43.426573 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.217793 (* 1 = 0.217793 loss)
I1005 21:13:43.426579 10142 sgd_solver.cpp:105] Iteration 13900, lr = 0.1
I1005 21:13:58.667930 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 21:13:59.270702 10142 solver.cpp:330] Iteration 14000, Testing net (#0)
I1005 21:14:02.500650 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 21:14:02.637996 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.799
I1005 21:14:02.638038 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.640728 (* 1 = 0.640728 loss)
I1005 21:14:02.749711 10142 solver.cpp:218] Iteration 14000 (5.17516 iter/s, 19.3231s/100 iters), loss = 0.20096
I1005 21:14:02.749745 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.20096 (* 1 = 0.20096 loss)
I1005 21:14:02.749763 10142 sgd_solver.cpp:105] Iteration 14000, lr = 0.1
I1005 21:14:18.581755 10142 solver.cpp:218] Iteration 14100 (6.31719 iter/s, 15.8298s/100 iters), loss = 0.295841
I1005 21:14:18.581789 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.295841 (* 1 = 0.295841 loss)
I1005 21:14:18.581805 10142 sgd_solver.cpp:105] Iteration 14100, lr = 0.1
I1005 21:14:34.383139 10142 solver.cpp:218] Iteration 14200 (6.3286 iter/s, 15.8013s/100 iters), loss = 0.274934
I1005 21:14:34.383232 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.274934 (* 1 = 0.274934 loss)
I1005 21:14:34.383249 10142 sgd_solver.cpp:105] Iteration 14200, lr = 0.1
I1005 21:14:50.282783 10142 solver.cpp:218] Iteration 14300 (6.29032 iter/s, 15.8974s/100 iters), loss = 0.278833
I1005 21:14:50.282814 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.278833 (* 1 = 0.278833 loss)
I1005 21:14:50.282821 10142 sgd_solver.cpp:105] Iteration 14300, lr = 0.1
I1005 21:15:06.139570 10142 solver.cpp:218] Iteration 14400 (6.30734 iter/s, 15.8545s/100 iters), loss = 0.222711
I1005 21:15:06.139665 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.222711 (* 1 = 0.222711 loss)
I1005 21:15:06.139678 10142 sgd_solver.cpp:105] Iteration 14400, lr = 0.1
I1005 21:15:21.263854 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 21:15:21.872376 10142 solver.cpp:330] Iteration 14500, Testing net (#0)
I1005 21:15:25.085256 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 21:15:25.213021 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7518
I1005 21:15:25.213047 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.806032 (* 1 = 0.806032 loss)
I1005 21:15:25.344954 10142 solver.cpp:218] Iteration 14500 (5.20692 iter/s, 19.2052s/100 iters), loss = 0.230813
I1005 21:15:25.344987 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.230813 (* 1 = 0.230813 loss)
I1005 21:15:25.344995 10142 sgd_solver.cpp:105] Iteration 14500, lr = 0.1
I1005 21:15:41.291538 10142 solver.cpp:218] Iteration 14600 (6.27098 iter/s, 15.9465s/100 iters), loss = 0.207644
I1005 21:15:41.291676 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.207644 (* 1 = 0.207644 loss)
I1005 21:15:41.291687 10142 sgd_solver.cpp:105] Iteration 14600, lr = 0.1
I1005 21:15:57.142328 10142 solver.cpp:218] Iteration 14700 (6.30891 iter/s, 15.8506s/100 iters), loss = 0.400081
I1005 21:15:57.142364 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.400081 (* 1 = 0.400081 loss)
I1005 21:15:57.142374 10142 sgd_solver.cpp:105] Iteration 14700, lr = 0.1
I1005 21:16:13.004817 10142 solver.cpp:218] Iteration 14800 (6.30422 iter/s, 15.8624s/100 iters), loss = 0.273858
I1005 21:16:13.004945 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.273858 (* 1 = 0.273858 loss)
I1005 21:16:13.004963 10142 sgd_solver.cpp:105] Iteration 14800, lr = 0.1
I1005 21:16:28.855763 10142 solver.cpp:218] Iteration 14900 (6.30884 iter/s, 15.8508s/100 iters), loss = 0.216902
I1005 21:16:28.855806 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.216902 (* 1 = 0.216902 loss)
I1005 21:16:28.855813 10142 sgd_solver.cpp:105] Iteration 14900, lr = 0.1
I1005 21:16:44.053808 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 21:16:44.688124 10142 solver.cpp:330] Iteration 15000, Testing net (#0)
I1005 21:16:47.921784 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 21:16:48.049356 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7121
I1005 21:16:48.049392 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.967444 (* 1 = 0.967444 loss)
I1005 21:16:48.181305 10142 solver.cpp:218] Iteration 15000 (5.17453 iter/s, 19.3254s/100 iters), loss = 0.219422
I1005 21:16:48.181350 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.219422 (* 1 = 0.219422 loss)
I1005 21:16:48.181357 10142 sgd_solver.cpp:105] Iteration 15000, lr = 0.1
I1005 21:17:04.040383 10142 solver.cpp:218] Iteration 15100 (6.30558 iter/s, 15.859s/100 iters), loss = 0.236058
I1005 21:17:04.040424 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.236058 (* 1 = 0.236058 loss)
I1005 21:17:04.040431 10142 sgd_solver.cpp:105] Iteration 15100, lr = 0.1
I1005 21:17:19.900246 10142 solver.cpp:218] Iteration 15200 (6.30527 iter/s, 15.8598s/100 iters), loss = 0.324265
I1005 21:17:19.900326 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.324265 (* 1 = 0.324265 loss)
I1005 21:17:19.900343 10142 sgd_solver.cpp:105] Iteration 15200, lr = 0.1
I1005 21:17:35.853745 10142 solver.cpp:218] Iteration 15300 (6.26827 iter/s, 15.9534s/100 iters), loss = 0.338989
I1005 21:17:35.853793 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.338988 (* 1 = 0.338988 loss)
I1005 21:17:35.853801 10142 sgd_solver.cpp:105] Iteration 15300, lr = 0.1
I1005 21:17:51.644747 10142 solver.cpp:218] Iteration 15400 (6.33278 iter/s, 15.7909s/100 iters), loss = 0.194041
I1005 21:17:51.644834 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.194041 (* 1 = 0.194041 loss)
I1005 21:17:51.644852 10142 sgd_solver.cpp:105] Iteration 15400, lr = 0.1
I1005 21:18:06.775671 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 21:18:07.380410 10142 solver.cpp:330] Iteration 15500, Testing net (#0)
I1005 21:18:10.602615 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 21:18:10.735767 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6821
I1005 21:18:10.735805 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.16502 (* 1 = 1.16502 loss)
I1005 21:18:10.850741 10142 solver.cpp:218] Iteration 15500 (5.20675 iter/s, 19.2058s/100 iters), loss = 0.270992
I1005 21:18:10.850780 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.270992 (* 1 = 0.270992 loss)
I1005 21:18:10.850787 10142 sgd_solver.cpp:105] Iteration 15500, lr = 0.1
I1005 21:18:26.758942 10142 solver.cpp:218] Iteration 15600 (6.28614 iter/s, 15.908s/100 iters), loss = 0.298991
I1005 21:18:26.759065 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.298991 (* 1 = 0.298991 loss)
I1005 21:18:26.759075 10142 sgd_solver.cpp:105] Iteration 15600, lr = 0.1
I1005 21:18:42.627400 10142 solver.cpp:218] Iteration 15700 (6.30188 iter/s, 15.8683s/100 iters), loss = 0.234252
I1005 21:18:42.627441 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.234252 (* 1 = 0.234252 loss)
I1005 21:18:42.627460 10142 sgd_solver.cpp:105] Iteration 15700, lr = 0.1
I1005 21:18:58.427489 10142 solver.cpp:218] Iteration 15800 (6.32912 iter/s, 15.8s/100 iters), loss = 0.273528
I1005 21:18:58.427592 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.273528 (* 1 = 0.273528 loss)
I1005 21:18:58.427605 10142 sgd_solver.cpp:105] Iteration 15800, lr = 0.1
I1005 21:19:14.266335 10142 solver.cpp:218] Iteration 15900 (6.31449 iter/s, 15.8366s/100 iters), loss = 0.141163
I1005 21:19:14.266367 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.141163 (* 1 = 0.141163 loss)
I1005 21:19:14.266374 10142 sgd_solver.cpp:105] Iteration 15900, lr = 0.1
I1005 21:19:29.373364 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 21:19:30.011675 10142 solver.cpp:330] Iteration 16000, Testing net (#0)
I1005 21:19:33.221459 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 21:19:33.356413 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7678
I1005 21:19:33.356451 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.77646 (* 1 = 0.77646 loss)
I1005 21:19:33.464545 10142 solver.cpp:218] Iteration 16000 (5.20885 iter/s, 19.1981s/100 iters), loss = 0.246573
I1005 21:19:33.464586 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.246573 (* 1 = 0.246573 loss)
I1005 21:19:33.464593 10142 sgd_solver.cpp:105] Iteration 16000, lr = 0.1
I1005 21:19:49.303467 10142 solver.cpp:218] Iteration 16100 (6.3136 iter/s, 15.8388s/100 iters), loss = 0.220051
I1005 21:19:49.303508 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.220051 (* 1 = 0.220051 loss)
I1005 21:19:49.303516 10142 sgd_solver.cpp:105] Iteration 16100, lr = 0.1
I1005 21:20:05.138054 10142 solver.cpp:218] Iteration 16200 (6.31533 iter/s, 15.8345s/100 iters), loss = 0.41678
I1005 21:20:05.138151 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.416779 (* 1 = 0.416779 loss)
I1005 21:20:05.138170 10142 sgd_solver.cpp:105] Iteration 16200, lr = 0.1
I1005 21:20:21.083341 10142 solver.cpp:218] Iteration 16300 (6.27151 iter/s, 15.9451s/100 iters), loss = 0.325139
I1005 21:20:21.083384 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.325138 (* 1 = 0.325138 loss)
I1005 21:20:21.083390 10142 sgd_solver.cpp:105] Iteration 16300, lr = 0.1
I1005 21:20:36.907383 10142 solver.cpp:218] Iteration 16400 (6.31954 iter/s, 15.8239s/100 iters), loss = 0.182264
I1005 21:20:36.907474 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.182264 (* 1 = 0.182264 loss)
I1005 21:20:36.907491 10142 sgd_solver.cpp:105] Iteration 16400, lr = 0.1
I1005 21:20:52.013685 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 21:20:52.647004 10142 solver.cpp:330] Iteration 16500, Testing net (#0)
I1005 21:20:55.876730 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 21:20:56.004686 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8032
I1005 21:20:56.004712 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.603915 (* 1 = 0.603915 loss)
I1005 21:20:56.135578 10142 solver.cpp:218] Iteration 16500 (5.20088 iter/s, 19.2275s/100 iters), loss = 0.192265
I1005 21:20:56.135630 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.192265 (* 1 = 0.192265 loss)
I1005 21:20:56.135637 10142 sgd_solver.cpp:105] Iteration 16500, lr = 0.1
I1005 21:21:12.000502 10142 solver.cpp:218] Iteration 16600 (6.30327 iter/s, 15.8648s/100 iters), loss = 0.253599
I1005 21:21:12.000615 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.253599 (* 1 = 0.253599 loss)
I1005 21:21:12.000628 10142 sgd_solver.cpp:105] Iteration 16600, lr = 0.1
I1005 21:21:27.938179 10142 solver.cpp:218] Iteration 16700 (6.27532 iter/s, 15.9354s/100 iters), loss = 0.294675
I1005 21:21:27.938220 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.294675 (* 1 = 0.294675 loss)
I1005 21:21:27.938226 10142 sgd_solver.cpp:105] Iteration 16700, lr = 0.1
I1005 21:21:43.782531 10142 solver.cpp:218] Iteration 16800 (6.31144 iter/s, 15.8442s/100 iters), loss = 0.28464
I1005 21:21:43.782630 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.28464 (* 1 = 0.28464 loss)
I1005 21:21:43.782639 10142 sgd_solver.cpp:105] Iteration 16800, lr = 0.1
I1005 21:21:59.633246 10142 solver.cpp:218] Iteration 16900 (6.30977 iter/s, 15.8484s/100 iters), loss = 0.253148
I1005 21:21:59.633289 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.253148 (* 1 = 0.253148 loss)
I1005 21:21:59.633296 10142 sgd_solver.cpp:105] Iteration 16900, lr = 0.1
I1005 21:22:14.824271 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 21:22:15.430964 10142 solver.cpp:330] Iteration 17000, Testing net (#0)
I1005 21:22:18.648767 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 21:22:18.777156 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7758
I1005 21:22:18.777182 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.727721 (* 1 = 0.727721 loss)
I1005 21:22:18.908131 10142 solver.cpp:218] Iteration 17000 (5.18813 iter/s, 19.2748s/100 iters), loss = 0.182104
I1005 21:22:18.908165 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.182104 (* 1 = 0.182104 loss)
I1005 21:22:18.908183 10142 sgd_solver.cpp:105] Iteration 17000, lr = 0.1
I1005 21:22:34.763013 10142 solver.cpp:218] Iteration 17100 (6.30725 iter/s, 15.8548s/100 iters), loss = 0.219401
I1005 21:22:34.763056 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.219401 (* 1 = 0.219401 loss)
I1005 21:22:34.763062 10142 sgd_solver.cpp:105] Iteration 17100, lr = 0.1
I1005 21:22:50.609783 10142 solver.cpp:218] Iteration 17200 (6.31048 iter/s, 15.8467s/100 iters), loss = 0.430693
I1005 21:22:50.609905 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.430693 (* 1 = 0.430693 loss)
I1005 21:22:50.609913 10142 sgd_solver.cpp:105] Iteration 17200, lr = 0.1
I1005 21:23:06.578214 10142 solver.cpp:218] Iteration 17300 (6.26243 iter/s, 15.9682s/100 iters), loss = 0.250417
I1005 21:23:06.578248 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.250417 (* 1 = 0.250417 loss)
I1005 21:23:06.578254 10142 sgd_solver.cpp:105] Iteration 17300, lr = 0.1
I1005 21:23:22.442486 10142 solver.cpp:218] Iteration 17400 (6.30351 iter/s, 15.8642s/100 iters), loss = 0.220175
I1005 21:23:22.442579 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.220175 (* 1 = 0.220175 loss)
I1005 21:23:22.442595 10142 sgd_solver.cpp:105] Iteration 17400, lr = 0.1
I1005 21:23:37.569304 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 21:23:38.176666 10142 solver.cpp:330] Iteration 17500, Testing net (#0)
I1005 21:23:41.392460 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 21:23:41.519873 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7717
I1005 21:23:41.519909 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.697679 (* 1 = 0.697679 loss)
I1005 21:23:41.651392 10142 solver.cpp:218] Iteration 17500 (5.20653 iter/s, 19.2067s/100 iters), loss = 0.302695
I1005 21:23:41.651439 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.302694 (* 1 = 0.302694 loss)
I1005 21:23:41.651448 10142 sgd_solver.cpp:105] Iteration 17500, lr = 0.1
I1005 21:23:57.498553 10142 solver.cpp:218] Iteration 17600 (6.31032 iter/s, 15.847s/100 iters), loss = 0.235116
I1005 21:23:57.498682 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.235116 (* 1 = 0.235116 loss)
I1005 21:23:57.498700 10142 sgd_solver.cpp:105] Iteration 17600, lr = 0.1
I1005 21:24:13.434661 10142 solver.cpp:218] Iteration 17700 (6.27513 iter/s, 15.9359s/100 iters), loss = 0.255118
I1005 21:24:13.434692 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.255118 (* 1 = 0.255118 loss)
I1005 21:24:13.434700 10142 sgd_solver.cpp:105] Iteration 17700, lr = 0.1
I1005 21:24:29.298790 10142 solver.cpp:218] Iteration 17800 (6.3044 iter/s, 15.8619s/100 iters), loss = 0.232868
I1005 21:24:29.298905 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.232868 (* 1 = 0.232868 loss)
I1005 21:24:29.298923 10142 sgd_solver.cpp:105] Iteration 17800, lr = 0.1
I1005 21:24:45.148685 10142 solver.cpp:218] Iteration 17900 (6.3101 iter/s, 15.8476s/100 iters), loss = 0.318989
I1005 21:24:45.148716 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.318989 (* 1 = 0.318989 loss)
I1005 21:24:45.148735 10142 sgd_solver.cpp:105] Iteration 17900, lr = 0.1
I1005 21:25:00.380362 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 21:25:01.013978 10142 solver.cpp:330] Iteration 18000, Testing net (#0)
I1005 21:25:04.211763 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 21:25:04.341764 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7441
I1005 21:25:04.341799 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.90425 (* 1 = 0.90425 loss)
I1005 21:25:04.459146 10142 solver.cpp:218] Iteration 18000 (5.17888 iter/s, 19.3092s/100 iters), loss = 0.186086
I1005 21:25:04.459185 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.186085 (* 1 = 0.186085 loss)
I1005 21:25:04.459192 10142 sgd_solver.cpp:105] Iteration 18000, lr = 0.1
I1005 21:25:20.319537 10142 solver.cpp:218] Iteration 18100 (6.30506 iter/s, 15.8603s/100 iters), loss = 0.230238
I1005 21:25:20.319567 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.230238 (* 1 = 0.230238 loss)
I1005 21:25:20.319574 10142 sgd_solver.cpp:105] Iteration 18100, lr = 0.1
I1005 21:25:36.162047 10142 solver.cpp:218] Iteration 18200 (6.31217 iter/s, 15.8424s/100 iters), loss = 0.284373
I1005 21:25:36.162129 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.284373 (* 1 = 0.284373 loss)
I1005 21:25:36.162137 10142 sgd_solver.cpp:105] Iteration 18200, lr = 0.1
I1005 21:25:52.081118 10142 solver.cpp:218] Iteration 18300 (6.28186 iter/s, 15.9189s/100 iters), loss = 0.245248
I1005 21:25:52.081154 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.245248 (* 1 = 0.245248 loss)
I1005 21:25:52.081174 10142 sgd_solver.cpp:105] Iteration 18300, lr = 0.1
I1005 21:26:07.892537 10142 solver.cpp:218] Iteration 18400 (6.32542 iter/s, 15.8092s/100 iters), loss = 0.204975
I1005 21:26:07.892603 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.204975 (* 1 = 0.204975 loss)
I1005 21:26:07.892611 10142 sgd_solver.cpp:105] Iteration 18400, lr = 0.1
I1005 21:26:23.006279 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 21:26:23.607338 10142 solver.cpp:330] Iteration 18500, Testing net (#0)
I1005 21:26:26.828963 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 21:26:26.958631 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6804
I1005 21:26:26.958668 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.17489 (* 1 = 1.17489 loss)
I1005 21:26:27.089830 10142 solver.cpp:218] Iteration 18500 (5.2091 iter/s, 19.1972s/100 iters), loss = 0.164768
I1005 21:26:27.089875 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.164767 (* 1 = 0.164767 loss)
I1005 21:26:27.089882 10142 sgd_solver.cpp:105] Iteration 18500, lr = 0.1
I1005 21:26:42.948052 10142 solver.cpp:218] Iteration 18600 (6.30592 iter/s, 15.8581s/100 iters), loss = 0.20003
I1005 21:26:42.948143 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.20003 (* 1 = 0.20003 loss)
I1005 21:26:42.948150 10142 sgd_solver.cpp:105] Iteration 18600, lr = 0.1
I1005 21:26:58.921496 10142 solver.cpp:218] Iteration 18700 (6.26045 iter/s, 15.9733s/100 iters), loss = 0.338724
I1005 21:26:58.921536 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.338724 (* 1 = 0.338724 loss)
I1005 21:26:58.921543 10142 sgd_solver.cpp:105] Iteration 18700, lr = 0.1
I1005 21:27:14.785745 10142 solver.cpp:218] Iteration 18800 (6.30352 iter/s, 15.8641s/100 iters), loss = 0.248205
I1005 21:27:14.785898 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.248205 (* 1 = 0.248205 loss)
I1005 21:27:14.785909 10142 sgd_solver.cpp:105] Iteration 18800, lr = 0.1
I1005 21:27:30.650283 10142 solver.cpp:218] Iteration 18900 (6.30353 iter/s, 15.8641s/100 iters), loss = 0.231075
I1005 21:27:30.650315 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.231074 (* 1 = 0.231074 loss)
I1005 21:27:30.650323 10142 sgd_solver.cpp:105] Iteration 18900, lr = 0.1
I1005 21:27:45.828227 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 21:27:46.459812 10142 solver.cpp:330] Iteration 19000, Testing net (#0)
I1005 21:27:49.673691 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 21:27:49.816295 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7722
I1005 21:27:49.816321 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.737796 (* 1 = 0.737796 loss)
I1005 21:27:49.917075 10142 solver.cpp:218] Iteration 19000 (5.19087 iter/s, 19.2646s/100 iters), loss = 0.230818
I1005 21:27:49.917106 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.230818 (* 1 = 0.230818 loss)
I1005 21:27:49.917124 10142 sgd_solver.cpp:105] Iteration 19000, lr = 0.1
I1005 21:28:05.754544 10142 solver.cpp:218] Iteration 19100 (6.31502 iter/s, 15.8353s/100 iters), loss = 0.238425
I1005 21:28:05.754592 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.238425 (* 1 = 0.238425 loss)
I1005 21:28:05.754601 10142 sgd_solver.cpp:105] Iteration 19100, lr = 0.1
I1005 21:28:21.593246 10142 solver.cpp:218] Iteration 19200 (6.3137 iter/s, 15.8386s/100 iters), loss = 0.264726
I1005 21:28:21.593343 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.264726 (* 1 = 0.264726 loss)
I1005 21:28:21.593361 10142 sgd_solver.cpp:105] Iteration 19200, lr = 0.1
I1005 21:28:37.504957 10142 solver.cpp:218] Iteration 19300 (6.28477 iter/s, 15.9115s/100 iters), loss = 0.208124
I1005 21:28:37.504992 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.208124 (* 1 = 0.208124 loss)
I1005 21:28:37.505009 10142 sgd_solver.cpp:105] Iteration 19300, lr = 0.1
I1005 21:28:53.404460 10142 solver.cpp:218] Iteration 19400 (6.29037 iter/s, 15.8973s/100 iters), loss = 0.192556
I1005 21:28:53.404536 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.192555 (* 1 = 0.192555 loss)
I1005 21:28:53.404542 10142 sgd_solver.cpp:105] Iteration 19400, lr = 0.1
I1005 21:29:08.507513 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 21:29:09.144282 10142 solver.cpp:330] Iteration 19500, Testing net (#0)
I1005 21:29:12.351694 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 21:29:12.488504 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7663
I1005 21:29:12.488543 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.709439 (* 1 = 0.709439 loss)
I1005 21:29:12.597816 10142 solver.cpp:218] Iteration 19500 (5.21017 iter/s, 19.1932s/100 iters), loss = 0.249665
I1005 21:29:12.597849 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.249665 (* 1 = 0.249665 loss)
I1005 21:29:12.597867 10142 sgd_solver.cpp:105] Iteration 19500, lr = 0.1
I1005 21:29:28.460933 10142 solver.cpp:218] Iteration 19600 (6.30481 iter/s, 15.8609s/100 iters), loss = 0.30588
I1005 21:29:28.461001 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.30588 (* 1 = 0.30588 loss)
I1005 21:29:28.461009 10142 sgd_solver.cpp:105] Iteration 19600, lr = 0.1
I1005 21:29:44.394485 10142 solver.cpp:218] Iteration 19700 (6.27611 iter/s, 15.9334s/100 iters), loss = 0.300782
I1005 21:29:44.394531 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.300782 (* 1 = 0.300782 loss)
I1005 21:29:44.394537 10142 sgd_solver.cpp:105] Iteration 19700, lr = 0.1
I1005 21:30:00.261962 10142 solver.cpp:218] Iteration 19800 (6.30224 iter/s, 15.8674s/100 iters), loss = 0.215441
I1005 21:30:00.262079 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.215441 (* 1 = 0.215441 loss)
I1005 21:30:00.262097 10142 sgd_solver.cpp:105] Iteration 19800, lr = 0.1
I1005 21:30:16.097514 10142 solver.cpp:218] Iteration 19900 (6.31498 iter/s, 15.8354s/100 iters), loss = 0.225146
I1005 21:30:16.097548 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.225146 (* 1 = 0.225146 loss)
I1005 21:30:16.097564 10142 sgd_solver.cpp:105] Iteration 19900, lr = 0.1
I1005 21:30:31.288846 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 21:30:31.897060 10142 solver.cpp:330] Iteration 20000, Testing net (#0)
I1005 21:30:35.107928 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 21:30:35.236080 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7851
I1005 21:30:35.236116 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.677442 (* 1 = 0.677442 loss)
I1005 21:30:35.367609 10142 solver.cpp:218] Iteration 20000 (5.18942 iter/s, 19.27s/100 iters), loss = 0.250718
I1005 21:30:35.367652 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.250718 (* 1 = 0.250718 loss)
I1005 21:30:35.367660 10142 sgd_solver.cpp:105] Iteration 20000, lr = 0.1
I1005 21:30:51.231284 10142 solver.cpp:218] Iteration 20100 (6.30375 iter/s, 15.8636s/100 iters), loss = 0.213839
I1005 21:30:51.231318 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.213838 (* 1 = 0.213838 loss)
I1005 21:30:51.231335 10142 sgd_solver.cpp:105] Iteration 20100, lr = 0.1
I1005 21:31:07.097419 10142 solver.cpp:218] Iteration 20200 (6.30277 iter/s, 15.866s/100 iters), loss = 0.230954
I1005 21:31:07.097503 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.230953 (* 1 = 0.230953 loss)
I1005 21:31:07.097512 10142 sgd_solver.cpp:105] Iteration 20200, lr = 0.1
I1005 21:31:22.954730 10142 solver.cpp:218] Iteration 20300 (6.3063 iter/s, 15.8572s/100 iters), loss = 0.218619
I1005 21:31:22.954773 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.218619 (* 1 = 0.218619 loss)
I1005 21:31:22.954779 10142 sgd_solver.cpp:105] Iteration 20300, lr = 0.1
I1005 21:31:38.924021 10142 solver.cpp:218] Iteration 20400 (6.26206 iter/s, 15.9692s/100 iters), loss = 0.177959
I1005 21:31:38.924125 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.177958 (* 1 = 0.177958 loss)
I1005 21:31:38.924144 10142 sgd_solver.cpp:105] Iteration 20400, lr = 0.1
I1005 21:31:54.034742 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 21:31:54.668535 10142 solver.cpp:330] Iteration 20500, Testing net (#0)
I1005 21:31:57.881695 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 21:31:58.024994 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7833
I1005 21:31:58.025030 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.682056 (* 1 = 0.682056 loss)
I1005 21:31:58.126101 10142 solver.cpp:218] Iteration 20500 (5.20783 iter/s, 19.2019s/100 iters), loss = 0.230489
I1005 21:31:58.126142 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.230489 (* 1 = 0.230489 loss)
I1005 21:31:58.126150 10142 sgd_solver.cpp:105] Iteration 20500, lr = 0.1
I1005 21:32:13.976610 10142 solver.cpp:218] Iteration 20600 (6.30982 iter/s, 15.8483s/100 iters), loss = 0.238607
I1005 21:32:13.976691 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.238606 (* 1 = 0.238606 loss)
I1005 21:32:13.976709 10142 sgd_solver.cpp:105] Iteration 20600, lr = 0.1
I1005 21:32:29.924221 10142 solver.cpp:218] Iteration 20700 (6.27059 iter/s, 15.9475s/100 iters), loss = 0.319701
I1005 21:32:29.924268 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.3197 (* 1 = 0.3197 loss)
I1005 21:32:29.924275 10142 sgd_solver.cpp:105] Iteration 20700, lr = 0.1
I1005 21:32:45.785276 10142 solver.cpp:218] Iteration 20800 (6.30479 iter/s, 15.8609s/100 iters), loss = 0.301026
I1005 21:32:45.785400 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.301026 (* 1 = 0.301026 loss)
I1005 21:32:45.785418 10142 sgd_solver.cpp:105] Iteration 20800, lr = 0.1
I1005 21:33:01.605860 10142 solver.cpp:218] Iteration 20900 (6.32095 iter/s, 15.8204s/100 iters), loss = 0.21455
I1005 21:33:01.605902 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.21455 (* 1 = 0.21455 loss)
I1005 21:33:01.605908 10142 sgd_solver.cpp:105] Iteration 20900, lr = 0.1
I1005 21:33:16.805032 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 21:33:17.402834 10142 solver.cpp:330] Iteration 21000, Testing net (#0)
I1005 21:33:20.615772 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 21:33:20.743628 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7168
I1005 21:33:20.743683 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.984108 (* 1 = 0.984108 loss)
I1005 21:33:20.856855 10142 solver.cpp:218] Iteration 21000 (5.19457 iter/s, 19.2509s/100 iters), loss = 0.168305
I1005 21:33:20.856901 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.168305 (* 1 = 0.168305 loss)
I1005 21:33:20.856909 10142 sgd_solver.cpp:105] Iteration 21000, lr = 0.1
I1005 21:33:36.696665 10142 solver.cpp:218] Iteration 21100 (6.3141 iter/s, 15.8376s/100 iters), loss = 0.268119
I1005 21:33:36.696707 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.268119 (* 1 = 0.268119 loss)
I1005 21:33:36.696715 10142 sgd_solver.cpp:105] Iteration 21100, lr = 0.1
I1005 21:33:52.560914 10142 solver.cpp:218] Iteration 21200 (6.30352 iter/s, 15.8641s/100 iters), loss = 0.226878
I1005 21:33:52.561002 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.226878 (* 1 = 0.226878 loss)
I1005 21:33:52.561013 10142 sgd_solver.cpp:105] Iteration 21200, lr = 0.1
I1005 21:34:08.421741 10142 solver.cpp:218] Iteration 21300 (6.3049 iter/s, 15.8607s/100 iters), loss = 0.279608
I1005 21:34:08.421773 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.279607 (* 1 = 0.279607 loss)
I1005 21:34:08.421790 10142 sgd_solver.cpp:105] Iteration 21300, lr = 0.1
I1005 21:34:24.376126 10142 solver.cpp:218] Iteration 21400 (6.26791 iter/s, 15.9543s/100 iters), loss = 0.160126
I1005 21:34:24.376214 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.160125 (* 1 = 0.160125 loss)
I1005 21:34:24.376221 10142 sgd_solver.cpp:105] Iteration 21400, lr = 0.1
I1005 21:34:39.417982 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 21:34:40.038626 10142 solver.cpp:330] Iteration 21500, Testing net (#0)
I1005 21:34:43.239097 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 21:34:43.368273 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7028
I1005 21:34:43.368300 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.10697 (* 1 = 1.10697 loss)
I1005 21:34:43.479131 10142 solver.cpp:218] Iteration 21500 (5.23482 iter/s, 19.1028s/100 iters), loss = 0.254339
I1005 21:34:43.479173 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.254339 (* 1 = 0.254339 loss)
I1005 21:34:43.479179 10142 sgd_solver.cpp:105] Iteration 21500, lr = 0.1
I1005 21:34:59.338207 10142 solver.cpp:218] Iteration 21600 (6.30559 iter/s, 15.859s/100 iters), loss = 0.196768
I1005 21:34:59.338290 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.196767 (* 1 = 0.196767 loss)
I1005 21:34:59.338309 10142 sgd_solver.cpp:105] Iteration 21600, lr = 0.1
I1005 21:35:15.278867 10142 solver.cpp:218] Iteration 21700 (6.27332 iter/s, 15.9405s/100 iters), loss = 0.254525
I1005 21:35:15.278903 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.254525 (* 1 = 0.254525 loss)
I1005 21:35:15.278908 10142 sgd_solver.cpp:105] Iteration 21700, lr = 0.1
I1005 21:35:31.137446 10142 solver.cpp:218] Iteration 21800 (6.30577 iter/s, 15.8585s/100 iters), loss = 0.270435
I1005 21:35:31.137567 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.270435 (* 1 = 0.270435 loss)
I1005 21:35:31.137576 10142 sgd_solver.cpp:105] Iteration 21800, lr = 0.1
I1005 21:35:46.987368 10142 solver.cpp:218] Iteration 21900 (6.30925 iter/s, 15.8498s/100 iters), loss = 0.170098
I1005 21:35:46.987411 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.170098 (* 1 = 0.170098 loss)
I1005 21:35:46.987417 10142 sgd_solver.cpp:105] Iteration 21900, lr = 0.1
I1005 21:36:02.155268 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 21:36:02.809913 10142 solver.cpp:330] Iteration 22000, Testing net (#0)
I1005 21:36:06.038161 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 21:36:06.179131 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6291
I1005 21:36:06.179169 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.7398 (* 1 = 1.7398 loss)
I1005 21:36:06.280477 10142 solver.cpp:218] Iteration 22000 (5.18323 iter/s, 19.293s/100 iters), loss = 0.186874
I1005 21:36:06.280521 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.186874 (* 1 = 0.186874 loss)
I1005 21:36:06.280529 10142 sgd_solver.cpp:105] Iteration 22000, lr = 0.1
I1005 21:36:22.118988 10142 solver.cpp:218] Iteration 22100 (6.3146 iter/s, 15.8363s/100 iters), loss = 0.164429
I1005 21:36:22.119029 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.164428 (* 1 = 0.164428 loss)
I1005 21:36:22.119035 10142 sgd_solver.cpp:105] Iteration 22100, lr = 0.1
I1005 21:36:37.976256 10142 solver.cpp:218] Iteration 22200 (6.3063 iter/s, 15.8572s/100 iters), loss = 0.299482
I1005 21:36:37.976341 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.299481 (* 1 = 0.299481 loss)
I1005 21:36:37.976347 10142 sgd_solver.cpp:105] Iteration 22200, lr = 0.1
I1005 21:36:53.798635 10142 solver.cpp:218] Iteration 22300 (6.32022 iter/s, 15.8222s/100 iters), loss = 0.192533
I1005 21:36:53.798681 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.192532 (* 1 = 0.192532 loss)
I1005 21:36:53.798699 10142 sgd_solver.cpp:105] Iteration 22300, lr = 0.1
I1005 21:37:09.759286 10142 solver.cpp:218] Iteration 22400 (6.26549 iter/s, 15.9604s/100 iters), loss = 0.226685
I1005 21:37:09.759420 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.226685 (* 1 = 0.226685 loss)
I1005 21:37:09.759429 10142 sgd_solver.cpp:105] Iteration 22400, lr = 0.1
I1005 21:37:24.797997 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 21:37:25.431041 10142 solver.cpp:330] Iteration 22500, Testing net (#0)
I1005 21:37:28.658718 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 21:37:28.786824 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6781
I1005 21:37:28.786850 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.18399 (* 1 = 1.18399 loss)
I1005 21:37:28.918822 10142 solver.cpp:218] Iteration 22500 (5.21939 iter/s, 19.1593s/100 iters), loss = 0.276296
I1005 21:37:28.918865 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.276296 (* 1 = 0.276296 loss)
I1005 21:37:28.918871 10142 sgd_solver.cpp:105] Iteration 22500, lr = 0.1
I1005 21:37:44.767750 10142 solver.cpp:218] Iteration 22600 (6.30962 iter/s, 15.8488s/100 iters), loss = 0.158684
I1005 21:37:44.767844 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.158684 (* 1 = 0.158684 loss)
I1005 21:37:44.767853 10142 sgd_solver.cpp:105] Iteration 22600, lr = 0.1
I1005 21:38:00.669317 10142 solver.cpp:218] Iteration 22700 (6.28875 iter/s, 15.9014s/100 iters), loss = 0.313432
I1005 21:38:00.669360 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.313431 (* 1 = 0.313431 loss)
I1005 21:38:00.669380 10142 sgd_solver.cpp:105] Iteration 22700, lr = 0.1
I1005 21:38:16.457514 10142 solver.cpp:218] Iteration 22800 (6.33474 iter/s, 15.786s/100 iters), loss = 0.350038
I1005 21:38:16.457595 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.350037 (* 1 = 0.350037 loss)
I1005 21:38:16.457603 10142 sgd_solver.cpp:105] Iteration 22800, lr = 0.1
I1005 21:38:32.234519 10142 solver.cpp:218] Iteration 22900 (6.3384 iter/s, 15.7769s/100 iters), loss = 0.158176
I1005 21:38:32.234572 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.158176 (* 1 = 0.158176 loss)
I1005 21:38:32.234582 10142 sgd_solver.cpp:105] Iteration 22900, lr = 0.1
I1005 21:38:47.352659 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 21:38:47.986069 10142 solver.cpp:330] Iteration 23000, Testing net (#0)
I1005 21:38:51.251096 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 21:38:51.380563 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7668
I1005 21:38:51.380601 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.744893 (* 1 = 0.744893 loss)
I1005 21:38:51.489576 10142 solver.cpp:218] Iteration 23000 (5.19403 iter/s, 19.2529s/100 iters), loss = 0.219634
I1005 21:38:51.489619 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.219634 (* 1 = 0.219634 loss)
I1005 21:38:51.489625 10142 sgd_solver.cpp:105] Iteration 23000, lr = 0.1
I1005 21:39:07.344115 10142 solver.cpp:218] Iteration 23100 (6.30823 iter/s, 15.8523s/100 iters), loss = 0.193256
I1005 21:39:07.344157 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.193256 (* 1 = 0.193256 loss)
I1005 21:39:07.344164 10142 sgd_solver.cpp:105] Iteration 23100, lr = 0.1
I1005 21:39:23.189025 10142 solver.cpp:218] Iteration 23200 (6.31122 iter/s, 15.8448s/100 iters), loss = 0.193494
I1005 21:39:23.189127 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.193493 (* 1 = 0.193493 loss)
I1005 21:39:23.189148 10142 sgd_solver.cpp:105] Iteration 23200, lr = 0.1
I1005 21:39:39.042609 10142 solver.cpp:218] Iteration 23300 (6.30863 iter/s, 15.8513s/100 iters), loss = 0.235979
I1005 21:39:39.042649 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.235979 (* 1 = 0.235979 loss)
I1005 21:39:39.042659 10142 sgd_solver.cpp:105] Iteration 23300, lr = 0.1
I1005 21:39:54.990983 10142 solver.cpp:218] Iteration 23400 (6.27028 iter/s, 15.9482s/100 iters), loss = 0.171643
I1005 21:39:54.991077 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.171643 (* 1 = 0.171643 loss)
I1005 21:39:54.991097 10142 sgd_solver.cpp:105] Iteration 23400, lr = 0.1
I1005 21:40:10.079056 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 21:40:10.712093 10142 solver.cpp:330] Iteration 23500, Testing net (#0)
I1005 21:40:13.944703 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 21:40:14.072762 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8312
I1005 21:40:14.072798 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.518172 (* 1 = 0.518172 loss)
I1005 21:40:14.205135 10142 solver.cpp:218] Iteration 23500 (5.20454 iter/s, 19.214s/100 iters), loss = 0.154919
I1005 21:40:14.205180 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.154918 (* 1 = 0.154918 loss)
I1005 21:40:14.205188 10142 sgd_solver.cpp:105] Iteration 23500, lr = 0.1
I1005 21:40:30.068356 10142 solver.cpp:218] Iteration 23600 (6.30394 iter/s, 15.8631s/100 iters), loss = 0.172065
I1005 21:40:30.068469 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.172065 (* 1 = 0.172065 loss)
I1005 21:40:30.068487 10142 sgd_solver.cpp:105] Iteration 23600, lr = 0.1
I1005 21:40:45.979624 10142 solver.cpp:218] Iteration 23700 (6.28493 iter/s, 15.9111s/100 iters), loss = 0.28532
I1005 21:40:45.979665 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.28532 (* 1 = 0.28532 loss)
I1005 21:40:45.979672 10142 sgd_solver.cpp:105] Iteration 23700, lr = 0.1
I1005 21:41:01.841249 10142 solver.cpp:218] Iteration 23800 (6.30457 iter/s, 15.8615s/100 iters), loss = 0.193886
I1005 21:41:01.841332 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.193886 (* 1 = 0.193886 loss)
I1005 21:41:01.841341 10142 sgd_solver.cpp:105] Iteration 23800, lr = 0.1
I1005 21:41:17.702064 10142 solver.cpp:218] Iteration 23900 (6.30493 iter/s, 15.8606s/100 iters), loss = 0.213922
I1005 21:41:17.702097 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.213922 (* 1 = 0.213922 loss)
I1005 21:41:17.702117 10142 sgd_solver.cpp:105] Iteration 23900, lr = 0.1
I1005 21:41:32.818871 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 21:41:33.425251 10142 solver.cpp:330] Iteration 24000, Testing net (#0)
I1005 21:41:36.712916 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 21:41:36.844470 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7925
I1005 21:41:36.844497 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.685843 (* 1 = 0.685843 loss)
I1005 21:41:36.975841 10142 solver.cpp:218] Iteration 24000 (5.18843 iter/s, 19.2737s/100 iters), loss = 0.218375
I1005 21:41:36.975885 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.218375 (* 1 = 0.218375 loss)
I1005 21:41:36.975893 10142 sgd_solver.cpp:105] Iteration 24000, lr = 0.1
I1005 21:41:52.854950 10142 solver.cpp:218] Iteration 24100 (6.29762 iter/s, 15.879s/100 iters), loss = 0.225913
I1005 21:41:52.854991 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.225913 (* 1 = 0.225913 loss)
I1005 21:41:52.854997 10142 sgd_solver.cpp:105] Iteration 24100, lr = 0.1
I1005 21:42:08.725059 10142 solver.cpp:218] Iteration 24200 (6.3012 iter/s, 15.87s/100 iters), loss = 0.267778
I1005 21:42:08.725214 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.267778 (* 1 = 0.267778 loss)
I1005 21:42:08.725222 10142 sgd_solver.cpp:105] Iteration 24200, lr = 0.1
I1005 21:42:24.590427 10142 solver.cpp:218] Iteration 24300 (6.30312 iter/s, 15.8652s/100 iters), loss = 0.19234
I1005 21:42:24.590459 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.192339 (* 1 = 0.192339 loss)
I1005 21:42:24.590476 10142 sgd_solver.cpp:105] Iteration 24300, lr = 0.1
I1005 21:42:40.516063 10142 solver.cpp:218] Iteration 24400 (6.27922 iter/s, 15.9255s/100 iters), loss = 0.256981
I1005 21:42:40.516155 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.256981 (* 1 = 0.256981 loss)
I1005 21:42:40.516173 10142 sgd_solver.cpp:105] Iteration 24400, lr = 0.1
I1005 21:42:55.623757 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 21:42:56.256047 10142 solver.cpp:330] Iteration 24500, Testing net (#0)
I1005 21:42:59.487632 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 21:42:59.615473 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8038
I1005 21:42:59.615499 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.625549 (* 1 = 0.625549 loss)
I1005 21:42:59.726102 10142 solver.cpp:218] Iteration 24500 (5.20566 iter/s, 19.2099s/100 iters), loss = 0.157578
I1005 21:42:59.726146 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.157578 (* 1 = 0.157578 loss)
I1005 21:42:59.726155 10142 sgd_solver.cpp:105] Iteration 24500, lr = 0.1
I1005 21:43:15.543670 10142 solver.cpp:218] Iteration 24600 (6.32296 iter/s, 15.8154s/100 iters), loss = 0.250256
I1005 21:43:15.543776 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.250255 (* 1 = 0.250255 loss)
I1005 21:43:15.543794 10142 sgd_solver.cpp:105] Iteration 24600, lr = 0.1
I1005 21:43:31.491005 10142 solver.cpp:218] Iteration 24700 (6.2707 iter/s, 15.9472s/100 iters), loss = 0.279381
I1005 21:43:31.491039 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.27938 (* 1 = 0.27938 loss)
I1005 21:43:31.491044 10142 sgd_solver.cpp:105] Iteration 24700, lr = 0.1
I1005 21:43:47.350304 10142 solver.cpp:218] Iteration 24800 (6.30549 iter/s, 15.8592s/100 iters), loss = 0.285955
I1005 21:43:47.350395 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.285954 (* 1 = 0.285954 loss)
I1005 21:43:47.350406 10142 sgd_solver.cpp:105] Iteration 24800, lr = 0.1
I1005 21:44:03.208870 10142 solver.cpp:218] Iteration 24900 (6.30583 iter/s, 15.8583s/100 iters), loss = 0.130484
I1005 21:44:03.208905 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.130483 (* 1 = 0.130483 loss)
I1005 21:44:03.208925 10142 sgd_solver.cpp:105] Iteration 24900, lr = 0.1
I1005 21:44:18.326902 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 21:44:18.927911 10142 solver.cpp:330] Iteration 25000, Testing net (#0)
I1005 21:44:22.163300 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 21:44:22.299935 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7419
I1005 21:44:22.299973 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.963004 (* 1 = 0.963004 loss)
I1005 21:44:22.420409 10142 solver.cpp:218] Iteration 25000 (5.20523 iter/s, 19.2114s/100 iters), loss = 0.15723
I1005 21:44:22.420452 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.157229 (* 1 = 0.157229 loss)
I1005 21:44:22.420460 10142 sgd_solver.cpp:105] Iteration 25000, lr = 0.1
I1005 21:44:38.316975 10142 solver.cpp:218] Iteration 25100 (6.29153 iter/s, 15.8944s/100 iters), loss = 0.170549
I1005 21:44:38.317008 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.170548 (* 1 = 0.170548 loss)
I1005 21:44:38.317014 10142 sgd_solver.cpp:105] Iteration 25100, lr = 0.1
I1005 21:44:54.175437 10142 solver.cpp:218] Iteration 25200 (6.30582 iter/s, 15.8584s/100 iters), loss = 0.285545
I1005 21:44:54.175549 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.285545 (* 1 = 0.285545 loss)
I1005 21:44:54.175567 10142 sgd_solver.cpp:105] Iteration 25200, lr = 0.1
I1005 21:45:10.020048 10142 solver.cpp:218] Iteration 25300 (6.31221 iter/s, 15.8423s/100 iters), loss = 0.22149
I1005 21:45:10.020090 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.22149 (* 1 = 0.22149 loss)
I1005 21:45:10.020097 10142 sgd_solver.cpp:105] Iteration 25300, lr = 0.1
I1005 21:45:25.954773 10142 solver.cpp:218] Iteration 25400 (6.27565 iter/s, 15.9346s/100 iters), loss = 0.192783
I1005 21:45:25.954871 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.192782 (* 1 = 0.192782 loss)
I1005 21:45:25.954879 10142 sgd_solver.cpp:105] Iteration 25400, lr = 0.1
I1005 21:45:41.033879 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 21:45:41.665653 10142 solver.cpp:330] Iteration 25500, Testing net (#0)
I1005 21:45:44.865741 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 21:45:44.997189 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7948
I1005 21:45:44.997231 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.683929 (* 1 = 0.683929 loss)
I1005 21:45:45.108710 10142 solver.cpp:218] Iteration 25500 (5.2209 iter/s, 19.1538s/100 iters), loss = 0.209541
I1005 21:45:45.108753 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.209541 (* 1 = 0.209541 loss)
I1005 21:45:45.108760 10142 sgd_solver.cpp:105] Iteration 25500, lr = 0.1
I1005 21:46:00.977443 10142 solver.cpp:218] Iteration 25600 (6.30177 iter/s, 15.8686s/100 iters), loss = 0.267491
I1005 21:46:00.977521 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.267491 (* 1 = 0.267491 loss)
I1005 21:46:00.977530 10142 sgd_solver.cpp:105] Iteration 25600, lr = 0.1
I1005 21:46:16.942826 10142 solver.cpp:218] Iteration 25700 (6.26442 iter/s, 15.9632s/100 iters), loss = 0.281169
I1005 21:46:16.942859 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.281168 (* 1 = 0.281168 loss)
I1005 21:46:16.942868 10142 sgd_solver.cpp:105] Iteration 25700, lr = 0.1
I1005 21:46:32.799873 10142 solver.cpp:218] Iteration 25800 (6.30638 iter/s, 15.8569s/100 iters), loss = 0.361743
I1005 21:46:32.799962 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.361742 (* 1 = 0.361742 loss)
I1005 21:46:32.799979 10142 sgd_solver.cpp:105] Iteration 25800, lr = 0.1
I1005 21:46:48.663166 10142 solver.cpp:218] Iteration 25900 (6.30476 iter/s, 15.861s/100 iters), loss = 0.218131
I1005 21:46:48.663206 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.21813 (* 1 = 0.21813 loss)
I1005 21:46:48.663213 10142 sgd_solver.cpp:105] Iteration 25900, lr = 0.1
I1005 21:47:03.793032 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 21:47:04.393793 10142 solver.cpp:330] Iteration 26000, Testing net (#0)
I1005 21:47:07.614679 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 21:47:07.743455 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8504
I1005 21:47:07.743489 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.455925 (* 1 = 0.455925 loss)
I1005 21:47:07.874423 10142 solver.cpp:218] Iteration 26000 (5.20531 iter/s, 19.2111s/100 iters), loss = 0.322263
I1005 21:47:07.874464 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.322263 (* 1 = 0.322263 loss)
I1005 21:47:07.874471 10142 sgd_solver.cpp:105] Iteration 26000, lr = 0.1
I1005 21:47:23.759773 10142 solver.cpp:218] Iteration 26100 (6.29515 iter/s, 15.8852s/100 iters), loss = 0.184014
I1005 21:47:23.759817 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.184014 (* 1 = 0.184014 loss)
I1005 21:47:23.759824 10142 sgd_solver.cpp:105] Iteration 26100, lr = 0.1
I1005 21:47:39.602407 10142 solver.cpp:218] Iteration 26200 (6.31212 iter/s, 15.8425s/100 iters), loss = 0.243025
I1005 21:47:39.602612 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.243025 (* 1 = 0.243025 loss)
I1005 21:47:39.602648 10142 sgd_solver.cpp:105] Iteration 26200, lr = 0.1
I1005 21:47:55.443264 10142 solver.cpp:218] Iteration 26300 (6.31288 iter/s, 15.8406s/100 iters), loss = 0.270791
I1005 21:47:55.443308 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.270791 (* 1 = 0.270791 loss)
I1005 21:47:55.443315 10142 sgd_solver.cpp:105] Iteration 26300, lr = 0.1
I1005 21:48:11.431368 10142 solver.cpp:218] Iteration 26400 (6.25469 iter/s, 15.988s/100 iters), loss = 0.194541
I1005 21:48:11.431457 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.19454 (* 1 = 0.19454 loss)
I1005 21:48:11.431465 10142 sgd_solver.cpp:105] Iteration 26400, lr = 0.1
I1005 21:48:26.555124 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 21:48:27.165905 10142 solver.cpp:330] Iteration 26500, Testing net (#0)
I1005 21:48:30.384552 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 21:48:30.512313 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7801
I1005 21:48:30.512348 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.742927 (* 1 = 0.742927 loss)
I1005 21:48:30.644651 10142 solver.cpp:218] Iteration 26500 (5.20478 iter/s, 19.2131s/100 iters), loss = 0.229724
I1005 21:48:30.644693 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.229724 (* 1 = 0.229724 loss)
I1005 21:48:30.644701 10142 sgd_solver.cpp:105] Iteration 26500, lr = 0.1
I1005 21:48:46.503417 10142 solver.cpp:218] Iteration 26600 (6.3057 iter/s, 15.8587s/100 iters), loss = 0.238745
I1005 21:48:46.503505 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.238745 (* 1 = 0.238745 loss)
I1005 21:48:46.503512 10142 sgd_solver.cpp:105] Iteration 26600, lr = 0.1
I1005 21:49:02.418910 10142 solver.cpp:218] Iteration 26700 (6.28324 iter/s, 15.9154s/100 iters), loss = 0.260051
I1005 21:49:02.418939 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.26005 (* 1 = 0.26005 loss)
I1005 21:49:02.418956 10142 sgd_solver.cpp:105] Iteration 26700, lr = 0.1
I1005 21:49:18.282305 10142 solver.cpp:218] Iteration 26800 (6.30386 iter/s, 15.8633s/100 iters), loss = 0.197135
I1005 21:49:18.282371 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.197134 (* 1 = 0.197134 loss)
I1005 21:49:18.282378 10142 sgd_solver.cpp:105] Iteration 26800, lr = 0.1
I1005 21:49:34.133226 10142 solver.cpp:218] Iteration 26900 (6.30883 iter/s, 15.8508s/100 iters), loss = 0.166321
I1005 21:49:34.133266 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.16632 (* 1 = 0.16632 loss)
I1005 21:49:34.133272 10142 sgd_solver.cpp:105] Iteration 26900, lr = 0.1
I1005 21:49:49.231997 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 21:49:49.864343 10142 solver.cpp:330] Iteration 27000, Testing net (#0)
I1005 21:49:53.066745 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 21:49:53.195772 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7701
I1005 21:49:53.195797 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.761031 (* 1 = 0.761031 loss)
I1005 21:49:53.305032 10142 solver.cpp:218] Iteration 27000 (5.21602 iter/s, 19.1717s/100 iters), loss = 0.231956
I1005 21:49:53.305074 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.231956 (* 1 = 0.231956 loss)
I1005 21:49:53.305083 10142 sgd_solver.cpp:105] Iteration 27000, lr = 0.1
I1005 21:50:09.259788 10142 solver.cpp:218] Iteration 27100 (6.2686 iter/s, 15.9525s/100 iters), loss = 0.149895
I1005 21:50:09.259832 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.149894 (* 1 = 0.149894 loss)
I1005 21:50:09.259840 10142 sgd_solver.cpp:105] Iteration 27100, lr = 0.1
I1005 21:50:25.104408 10142 solver.cpp:218] Iteration 27200 (6.31133 iter/s, 15.8445s/100 iters), loss = 0.214816
I1005 21:50:25.104508 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.214816 (* 1 = 0.214816 loss)
I1005 21:50:25.104516 10142 sgd_solver.cpp:105] Iteration 27200, lr = 0.1
I1005 21:50:40.951213 10142 solver.cpp:218] Iteration 27300 (6.31048 iter/s, 15.8466s/100 iters), loss = 0.182189
I1005 21:50:40.951253 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.182189 (* 1 = 0.182189 loss)
I1005 21:50:40.951258 10142 sgd_solver.cpp:105] Iteration 27300, lr = 0.1
I1005 21:50:56.887168 10142 solver.cpp:218] Iteration 27400 (6.27516 iter/s, 15.9359s/100 iters), loss = 0.187122
I1005 21:50:56.887260 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.187121 (* 1 = 0.187121 loss)
I1005 21:50:56.887279 10142 sgd_solver.cpp:105] Iteration 27400, lr = 0.1
I1005 21:51:12.003304 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 21:51:12.604912 10142 solver.cpp:330] Iteration 27500, Testing net (#0)
I1005 21:51:15.821564 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 21:51:15.949708 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8295
I1005 21:51:15.949743 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.502584 (* 1 = 0.502584 loss)
I1005 21:51:16.061971 10142 solver.cpp:218] Iteration 27500 (5.21522 iter/s, 19.1747s/100 iters), loss = 0.177168
I1005 21:51:16.062012 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.177168 (* 1 = 0.177168 loss)
I1005 21:51:16.062018 10142 sgd_solver.cpp:105] Iteration 27500, lr = 0.1
I1005 21:51:31.928386 10142 solver.cpp:218] Iteration 27600 (6.3035 iter/s, 15.8642s/100 iters), loss = 0.260647
I1005 21:51:31.928491 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.260646 (* 1 = 0.260646 loss)
I1005 21:51:31.928509 10142 sgd_solver.cpp:105] Iteration 27600, lr = 0.1
I1005 21:51:47.880416 10142 solver.cpp:218] Iteration 27700 (6.26889 iter/s, 15.9518s/100 iters), loss = 0.276551
I1005 21:51:47.880458 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.27655 (* 1 = 0.27655 loss)
I1005 21:51:47.880468 10142 sgd_solver.cpp:105] Iteration 27700, lr = 0.1
I1005 21:52:03.708642 10142 solver.cpp:218] Iteration 27800 (6.31872 iter/s, 15.826s/100 iters), loss = 0.213611
I1005 21:52:03.708719 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.213611 (* 1 = 0.213611 loss)
I1005 21:52:03.708727 10142 sgd_solver.cpp:105] Iteration 27800, lr = 0.1
I1005 21:52:19.562819 10142 solver.cpp:218] Iteration 27900 (6.30754 iter/s, 15.854s/100 iters), loss = 0.151671
I1005 21:52:19.562849 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.151671 (* 1 = 0.151671 loss)
I1005 21:52:19.562855 10142 sgd_solver.cpp:105] Iteration 27900, lr = 0.1
I1005 21:52:34.697633 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 21:52:35.302345 10142 solver.cpp:330] Iteration 28000, Testing net (#0)
I1005 21:52:38.518744 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 21:52:38.646502 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7734
I1005 21:52:38.646528 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.744129 (* 1 = 0.744129 loss)
I1005 21:52:38.778103 10142 solver.cpp:218] Iteration 28000 (5.20422 iter/s, 19.2152s/100 iters), loss = 0.22005
I1005 21:52:38.778148 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.22005 (* 1 = 0.22005 loss)
I1005 21:52:38.778156 10142 sgd_solver.cpp:105] Iteration 28000, lr = 0.1
I1005 21:52:54.708520 10142 solver.cpp:218] Iteration 28100 (6.27734 iter/s, 15.9303s/100 iters), loss = 0.206576
I1005 21:52:54.708549 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.206576 (* 1 = 0.206576 loss)
I1005 21:52:54.708556 10142 sgd_solver.cpp:105] Iteration 28100, lr = 0.1
I1005 21:53:10.581410 10142 solver.cpp:218] Iteration 28200 (6.30009 iter/s, 15.8728s/100 iters), loss = 0.313879
I1005 21:53:10.581531 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.313878 (* 1 = 0.313878 loss)
I1005 21:53:10.581538 10142 sgd_solver.cpp:105] Iteration 28200, lr = 0.1
I1005 21:53:26.449369 10142 solver.cpp:218] Iteration 28300 (6.30292 iter/s, 15.8657s/100 iters), loss = 0.266928
I1005 21:53:26.449407 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.266927 (* 1 = 0.266927 loss)
I1005 21:53:26.449414 10142 sgd_solver.cpp:105] Iteration 28300, lr = 0.1
I1005 21:53:42.367655 10142 solver.cpp:218] Iteration 28400 (6.28213 iter/s, 15.9182s/100 iters), loss = 0.109045
I1005 21:53:42.367748 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.109044 (* 1 = 0.109044 loss)
I1005 21:53:42.367768 10142 sgd_solver.cpp:105] Iteration 28400, lr = 0.1
I1005 21:53:57.495839 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 21:53:58.101629 10142 solver.cpp:330] Iteration 28500, Testing net (#0)
I1005 21:54:01.320519 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 21:54:01.448557 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8107
I1005 21:54:01.448592 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.606552 (* 1 = 0.606552 loss)
I1005 21:54:01.580444 10142 solver.cpp:218] Iteration 28500 (5.20549 iter/s, 19.2105s/100 iters), loss = 0.133784
I1005 21:54:01.580488 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.133783 (* 1 = 0.133783 loss)
I1005 21:54:01.580495 10142 sgd_solver.cpp:105] Iteration 28500, lr = 0.1
I1005 21:54:17.388900 10142 solver.cpp:218] Iteration 28600 (6.32577 iter/s, 15.8083s/100 iters), loss = 0.281076
I1005 21:54:17.389024 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.281075 (* 1 = 0.281075 loss)
I1005 21:54:17.389041 10142 sgd_solver.cpp:105] Iteration 28600, lr = 0.1
I1005 21:54:33.264217 10142 solver.cpp:218] Iteration 28700 (6.29996 iter/s, 15.8731s/100 iters), loss = 0.296646
I1005 21:54:33.264259 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.296646 (* 1 = 0.296646 loss)
I1005 21:54:33.264266 10142 sgd_solver.cpp:105] Iteration 28700, lr = 0.1
I1005 21:54:49.186404 10142 solver.cpp:218] Iteration 28800 (6.28059 iter/s, 15.9221s/100 iters), loss = 0.188092
I1005 21:54:49.186486 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.188092 (* 1 = 0.188092 loss)
I1005 21:54:49.186493 10142 sgd_solver.cpp:105] Iteration 28800, lr = 0.1
I1005 21:55:05.030913 10142 solver.cpp:218] Iteration 28900 (6.31139 iter/s, 15.8444s/100 iters), loss = 0.177394
I1005 21:55:05.030953 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.177393 (* 1 = 0.177393 loss)
I1005 21:55:05.030959 10142 sgd_solver.cpp:105] Iteration 28900, lr = 0.1
I1005 21:55:20.121476 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 21:55:20.753731 10142 solver.cpp:330] Iteration 29000, Testing net (#0)
I1005 21:55:23.960009 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 21:55:24.094306 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7608
I1005 21:55:24.094344 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.885168 (* 1 = 0.885168 loss)
I1005 21:55:24.204499 10142 solver.cpp:218] Iteration 29000 (5.21554 iter/s, 19.1735s/100 iters), loss = 0.15121
I1005 21:55:24.204541 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.15121 (* 1 = 0.15121 loss)
I1005 21:55:24.204550 10142 sgd_solver.cpp:105] Iteration 29000, lr = 0.1
I1005 21:55:40.165321 10142 solver.cpp:218] Iteration 29100 (6.26622 iter/s, 15.9586s/100 iters), loss = 0.159763
I1005 21:55:40.165362 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.159763 (* 1 = 0.159763 loss)
I1005 21:55:40.165369 10142 sgd_solver.cpp:105] Iteration 29100, lr = 0.1
I1005 21:55:56.029240 10142 solver.cpp:218] Iteration 29200 (6.30365 iter/s, 15.8638s/100 iters), loss = 0.388374
I1005 21:55:56.029317 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.388373 (* 1 = 0.388373 loss)
I1005 21:55:56.029325 10142 sgd_solver.cpp:105] Iteration 29200, lr = 0.1
I1005 21:56:11.891604 10142 solver.cpp:218] Iteration 29300 (6.30429 iter/s, 15.8622s/100 iters), loss = 0.267075
I1005 21:56:11.891641 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.267075 (* 1 = 0.267075 loss)
I1005 21:56:11.891659 10142 sgd_solver.cpp:105] Iteration 29300, lr = 0.1
I1005 21:56:27.827925 10142 solver.cpp:218] Iteration 29400 (6.27503 iter/s, 15.9362s/100 iters), loss = 0.14964
I1005 21:56:27.828032 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.14964 (* 1 = 0.14964 loss)
I1005 21:56:27.828049 10142 sgd_solver.cpp:105] Iteration 29400, lr = 0.1
I1005 21:56:42.959062 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 21:56:43.564842 10142 solver.cpp:330] Iteration 29500, Testing net (#0)
I1005 21:56:46.781631 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 21:56:46.909193 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8089
I1005 21:56:46.909226 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.603691 (* 1 = 0.603691 loss)
I1005 21:56:47.038136 10142 solver.cpp:218] Iteration 29500 (5.20561 iter/s, 19.21s/100 iters), loss = 0.203617
I1005 21:56:47.038180 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.203617 (* 1 = 0.203617 loss)
I1005 21:56:47.038187 10142 sgd_solver.cpp:105] Iteration 29500, lr = 0.1
I1005 21:57:02.878806 10142 solver.cpp:218] Iteration 29600 (6.31374 iter/s, 15.8385s/100 iters), loss = 0.159213
I1005 21:57:02.878908 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.159213 (* 1 = 0.159213 loss)
I1005 21:57:02.878926 10142 sgd_solver.cpp:105] Iteration 29600, lr = 0.1
I1005 21:57:18.751668 10142 solver.cpp:218] Iteration 29700 (6.30097 iter/s, 15.8706s/100 iters), loss = 0.230605
I1005 21:57:18.751699 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.230604 (* 1 = 0.230604 loss)
I1005 21:57:18.751718 10142 sgd_solver.cpp:105] Iteration 29700, lr = 0.1
I1005 21:57:34.707182 10142 solver.cpp:218] Iteration 29800 (6.26746 iter/s, 15.9554s/100 iters), loss = 0.250666
I1005 21:57:34.707267 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.250665 (* 1 = 0.250665 loss)
I1005 21:57:34.707274 10142 sgd_solver.cpp:105] Iteration 29800, lr = 0.1
I1005 21:57:50.570057 10142 solver.cpp:218] Iteration 29900 (6.30408 iter/s, 15.8627s/100 iters), loss = 0.147006
I1005 21:57:50.570099 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.147005 (* 1 = 0.147005 loss)
I1005 21:57:50.570106 10142 sgd_solver.cpp:105] Iteration 29900, lr = 0.1
I1005 21:58:05.668551 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 21:58:06.304708 10142 solver.cpp:330] Iteration 30000, Testing net (#0)
I1005 21:58:09.533632 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 21:58:09.661252 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8539
I1005 21:58:09.661289 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.4584 (* 1 = 0.4584 loss)
I1005 21:58:09.773743 10142 solver.cpp:218] Iteration 30000 (5.20736 iter/s, 19.2036s/100 iters), loss = 0.169265
I1005 21:58:09.773787 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.169264 (* 1 = 0.169264 loss)
I1005 21:58:09.773794 10142 sgd_solver.cpp:105] Iteration 30000, lr = 0.1
I1005 21:58:25.693589 10142 solver.cpp:218] Iteration 30100 (6.28233 iter/s, 15.9177s/100 iters), loss = 0.234196
I1005 21:58:25.693624 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.234196 (* 1 = 0.234196 loss)
I1005 21:58:25.693641 10142 sgd_solver.cpp:105] Iteration 30100, lr = 0.1
I1005 21:58:41.548231 10142 solver.cpp:218] Iteration 30200 (6.30734 iter/s, 15.8545s/100 iters), loss = 0.306624
I1005 21:58:41.548399 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.306623 (* 1 = 0.306623 loss)
I1005 21:58:41.548420 10142 sgd_solver.cpp:105] Iteration 30200, lr = 0.1
I1005 21:58:57.406657 10142 solver.cpp:218] Iteration 30300 (6.30589 iter/s, 15.8582s/100 iters), loss = 0.271174
I1005 21:58:57.406693 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.271174 (* 1 = 0.271174 loss)
I1005 21:58:57.406713 10142 sgd_solver.cpp:105] Iteration 30300, lr = 0.1
I1005 21:59:13.331200 10142 solver.cpp:218] Iteration 30400 (6.27966 iter/s, 15.9244s/100 iters), loss = 0.155624
I1005 21:59:13.331333 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.155624 (* 1 = 0.155624 loss)
I1005 21:59:13.331344 10142 sgd_solver.cpp:105] Iteration 30400, lr = 0.1
I1005 21:59:28.451969 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 21:59:29.061697 10142 solver.cpp:330] Iteration 30500, Testing net (#0)
I1005 21:59:32.272379 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 21:59:32.400578 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8091
I1005 21:59:32.400614 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.593173 (* 1 = 0.593173 loss)
I1005 21:59:32.532438 10142 solver.cpp:218] Iteration 30500 (5.2086 iter/s, 19.199s/100 iters), loss = 0.192999
I1005 21:59:32.532480 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.192999 (* 1 = 0.192999 loss)
I1005 21:59:32.532486 10142 sgd_solver.cpp:105] Iteration 30500, lr = 0.1
I1005 21:59:48.402956 10142 solver.cpp:218] Iteration 30600 (6.30103 iter/s, 15.8704s/100 iters), loss = 0.160615
I1005 21:59:48.403064 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.160615 (* 1 = 0.160615 loss)
I1005 21:59:48.403081 10142 sgd_solver.cpp:105] Iteration 30600, lr = 0.1
I1005 22:00:04.281304 10142 solver.cpp:218] Iteration 30700 (6.29795 iter/s, 15.8782s/100 iters), loss = 0.2177
I1005 22:00:04.281345 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.217699 (* 1 = 0.217699 loss)
I1005 22:00:04.281352 10142 sgd_solver.cpp:105] Iteration 30700, lr = 0.1
I1005 22:00:20.270592 10142 solver.cpp:218] Iteration 30800 (6.25423 iter/s, 15.9892s/100 iters), loss = 0.322282
I1005 22:00:20.270700 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.322282 (* 1 = 0.322282 loss)
I1005 22:00:20.270718 10142 sgd_solver.cpp:105] Iteration 30800, lr = 0.1
I1005 22:00:36.154604 10142 solver.cpp:218] Iteration 30900 (6.29651 iter/s, 15.8818s/100 iters), loss = 0.160695
I1005 22:00:36.154650 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.160694 (* 1 = 0.160694 loss)
I1005 22:00:36.154659 10142 sgd_solver.cpp:105] Iteration 30900, lr = 0.1
I1005 22:00:51.283211 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 22:00:51.885341 10142 solver.cpp:330] Iteration 31000, Testing net (#0)
I1005 22:00:55.097851 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 22:00:55.226013 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8036
I1005 22:00:55.226039 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.657902 (* 1 = 0.657902 loss)
I1005 22:00:55.357395 10142 solver.cpp:218] Iteration 31000 (5.20818 iter/s, 19.2006s/100 iters), loss = 0.237909
I1005 22:00:55.357440 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.237908 (* 1 = 0.237908 loss)
I1005 22:00:55.357446 10142 sgd_solver.cpp:105] Iteration 31000, lr = 0.1
I1005 22:01:11.293550 10142 solver.cpp:218] Iteration 31100 (6.27508 iter/s, 15.936s/100 iters), loss = 0.296657
I1005 22:01:11.293581 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.296656 (* 1 = 0.296656 loss)
I1005 22:01:11.293588 10142 sgd_solver.cpp:105] Iteration 31100, lr = 0.1
I1005 22:01:27.158362 10142 solver.cpp:218] Iteration 31200 (6.3033 iter/s, 15.8647s/100 iters), loss = 0.225082
I1005 22:01:27.158483 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.225081 (* 1 = 0.225081 loss)
I1005 22:01:27.158505 10142 sgd_solver.cpp:105] Iteration 31200, lr = 0.1
I1005 22:01:43.041721 10142 solver.cpp:218] Iteration 31300 (6.29598 iter/s, 15.8832s/100 iters), loss = 0.198068
I1005 22:01:43.041754 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.198068 (* 1 = 0.198068 loss)
I1005 22:01:43.041772 10142 sgd_solver.cpp:105] Iteration 31300, lr = 0.1
I1005 22:01:58.982396 10142 solver.cpp:218] Iteration 31400 (6.2733 iter/s, 15.9406s/100 iters), loss = 0.261868
I1005 22:01:58.982494 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.261868 (* 1 = 0.261868 loss)
I1005 22:01:58.982516 10142 sgd_solver.cpp:105] Iteration 31400, lr = 0.1
I1005 22:02:14.172843 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 22:02:14.780354 10142 solver.cpp:330] Iteration 31500, Testing net (#0)
I1005 22:02:18.001106 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 22:02:18.134639 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8377
I1005 22:02:18.134677 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.500942 (* 1 = 0.500942 loss)
I1005 22:02:18.250982 10142 solver.cpp:218] Iteration 31500 (5.18984 iter/s, 19.2684s/100 iters), loss = 0.312126
I1005 22:02:18.251025 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.312125 (* 1 = 0.312125 loss)
I1005 22:02:18.251034 10142 sgd_solver.cpp:105] Iteration 31500, lr = 0.1
I1005 22:02:34.134747 10142 solver.cpp:218] Iteration 31600 (6.29578 iter/s, 15.8837s/100 iters), loss = 0.200408
I1005 22:02:34.134867 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.200407 (* 1 = 0.200407 loss)
I1005 22:02:34.134886 10142 sgd_solver.cpp:105] Iteration 31600, lr = 0.1
I1005 22:02:50.004279 10142 solver.cpp:218] Iteration 31700 (6.30228 iter/s, 15.8673s/100 iters), loss = 0.222067
I1005 22:02:50.004319 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.222067 (* 1 = 0.222067 loss)
I1005 22:02:50.004326 10142 sgd_solver.cpp:105] Iteration 31700, lr = 0.1
I1005 22:03:05.953014 10142 solver.cpp:218] Iteration 31800 (6.27097 iter/s, 15.9465s/100 iters), loss = 0.152782
I1005 22:03:05.953128 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.152782 (* 1 = 0.152782 loss)
I1005 22:03:05.953147 10142 sgd_solver.cpp:105] Iteration 31800, lr = 0.1
I1005 22:03:21.808974 10142 solver.cpp:218] Iteration 31900 (6.30685 iter/s, 15.8558s/100 iters), loss = 0.133045
I1005 22:03:21.809015 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.133044 (* 1 = 0.133044 loss)
I1005 22:03:21.809021 10142 sgd_solver.cpp:105] Iteration 31900, lr = 0.1
I1005 22:03:36.912978 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 22:03:37.544859 10142 solver.cpp:330] Iteration 32000, Testing net (#0)
I1005 22:03:40.775300 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 22:03:40.903406 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7916
I1005 22:03:40.903443 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.668523 (* 1 = 0.668523 loss)
I1005 22:03:41.034749 10142 solver.cpp:218] Iteration 32000 (5.20138 iter/s, 19.2257s/100 iters), loss = 0.128302
I1005 22:03:41.034792 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.128302 (* 1 = 0.128302 loss)
I1005 22:03:41.034799 10142 sgd_solver.cpp:105] Iteration 32000, lr = 0.1
I1005 22:03:56.943840 10142 solver.cpp:218] Iteration 32100 (6.28576 iter/s, 15.909s/100 iters), loss = 0.30693
I1005 22:03:56.943876 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.306929 (* 1 = 0.306929 loss)
I1005 22:03:56.943882 10142 sgd_solver.cpp:105] Iteration 32100, lr = 0.1
I1005 22:04:12.800226 10142 solver.cpp:218] Iteration 32200 (6.30666 iter/s, 15.8563s/100 iters), loss = 0.222534
I1005 22:04:12.800325 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.222533 (* 1 = 0.222533 loss)
I1005 22:04:12.800344 10142 sgd_solver.cpp:105] Iteration 32200, lr = 0.1
I1005 22:04:28.644174 10142 solver.cpp:218] Iteration 32300 (6.31247 iter/s, 15.8417s/100 iters), loss = 0.17806
I1005 22:04:28.644215 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.178059 (* 1 = 0.178059 loss)
I1005 22:04:28.644222 10142 sgd_solver.cpp:105] Iteration 32300, lr = 0.1
I1005 22:04:44.504437 10142 solver.cpp:218] Iteration 32400 (6.30511 iter/s, 15.8602s/100 iters), loss = 0.161999
I1005 22:04:44.504509 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.161999 (* 1 = 0.161999 loss)
I1005 22:04:44.504528 10142 sgd_solver.cpp:105] Iteration 32400, lr = 0.1
I1005 22:04:59.679200 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 22:05:00.317463 10142 solver.cpp:330] Iteration 32500, Testing net (#0)
I1005 22:05:03.548321 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 22:05:03.676251 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7508
I1005 22:05:03.676276 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.863538 (* 1 = 0.863538 loss)
I1005 22:05:03.807768 10142 solver.cpp:218] Iteration 32500 (5.18104 iter/s, 19.3011s/100 iters), loss = 0.198921
I1005 22:05:03.807802 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.198921 (* 1 = 0.198921 loss)
I1005 22:05:03.807808 10142 sgd_solver.cpp:105] Iteration 32500, lr = 0.1
I1005 22:05:19.669829 10142 solver.cpp:218] Iteration 32600 (6.30439 iter/s, 15.862s/100 iters), loss = 0.252433
I1005 22:05:19.669945 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.252433 (* 1 = 0.252433 loss)
I1005 22:05:19.669962 10142 sgd_solver.cpp:105] Iteration 32600, lr = 0.1
I1005 22:05:35.530616 10142 solver.cpp:218] Iteration 32700 (6.30493 iter/s, 15.8606s/100 iters), loss = 0.374897
I1005 22:05:35.530645 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.374897 (* 1 = 0.374897 loss)
I1005 22:05:35.530663 10142 sgd_solver.cpp:105] Iteration 32700, lr = 0.1
I1005 22:05:51.484566 10142 solver.cpp:218] Iteration 32800 (6.26808 iter/s, 15.9538s/100 iters), loss = 0.182325
I1005 22:05:51.484673 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.182325 (* 1 = 0.182325 loss)
I1005 22:05:51.484681 10142 sgd_solver.cpp:105] Iteration 32800, lr = 0.1
I1005 22:06:07.346652 10142 solver.cpp:218] Iteration 32900 (6.30441 iter/s, 15.8619s/100 iters), loss = 0.209521
I1005 22:06:07.346690 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.20952 (* 1 = 0.20952 loss)
I1005 22:06:07.346698 10142 sgd_solver.cpp:105] Iteration 32900, lr = 0.1
I1005 22:06:22.434624 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 22:06:23.067620 10142 solver.cpp:330] Iteration 33000, Testing net (#0)
I1005 22:06:26.292050 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 22:06:26.423657 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7628
I1005 22:06:26.423694 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.799477 (* 1 = 0.799477 loss)
I1005 22:06:26.531828 10142 solver.cpp:218] Iteration 33000 (5.21239 iter/s, 19.1851s/100 iters), loss = 0.18456
I1005 22:06:26.531873 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.18456 (* 1 = 0.18456 loss)
I1005 22:06:26.531880 10142 sgd_solver.cpp:105] Iteration 33000, lr = 0.1
I1005 22:06:42.472055 10142 solver.cpp:218] Iteration 33100 (6.2743 iter/s, 15.938s/100 iters), loss = 0.132196
I1005 22:06:42.472098 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.132195 (* 1 = 0.132195 loss)
I1005 22:06:42.472105 10142 sgd_solver.cpp:105] Iteration 33100, lr = 0.1
I1005 22:06:58.326313 10142 solver.cpp:218] Iteration 33200 (6.3075 iter/s, 15.8542s/100 iters), loss = 0.411475
I1005 22:06:58.326452 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.411474 (* 1 = 0.411474 loss)
I1005 22:06:58.326469 10142 sgd_solver.cpp:105] Iteration 33200, lr = 0.1
I1005 22:07:14.177127 10142 solver.cpp:218] Iteration 33300 (6.3089 iter/s, 15.8506s/100 iters), loss = 0.241094
I1005 22:07:14.177168 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.241093 (* 1 = 0.241093 loss)
I1005 22:07:14.177175 10142 sgd_solver.cpp:105] Iteration 33300, lr = 0.1
I1005 22:07:30.033610 10142 solver.cpp:218] Iteration 33400 (6.30661 iter/s, 15.8564s/100 iters), loss = 0.237191
I1005 22:07:30.033733 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.237191 (* 1 = 0.237191 loss)
I1005 22:07:30.033741 10142 sgd_solver.cpp:105] Iteration 33400, lr = 0.1
I1005 22:07:45.241392 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 22:07:45.876091 10142 solver.cpp:330] Iteration 33500, Testing net (#0)
I1005 22:07:49.101074 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 22:07:49.229050 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7943
I1005 22:07:49.229077 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.687126 (* 1 = 0.687126 loss)
I1005 22:07:49.343170 10142 solver.cpp:218] Iteration 33500 (5.17883 iter/s, 19.3094s/100 iters), loss = 0.203215
I1005 22:07:49.343201 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.203215 (* 1 = 0.203215 loss)
I1005 22:07:49.343219 10142 sgd_solver.cpp:105] Iteration 33500, lr = 0.1
I1005 22:08:05.171093 10142 solver.cpp:218] Iteration 33600 (6.31883 iter/s, 15.8257s/100 iters), loss = 0.204458
I1005 22:08:05.171188 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.204458 (* 1 = 0.204458 loss)
I1005 22:08:05.171206 10142 sgd_solver.cpp:105] Iteration 33600, lr = 0.1
I1005 22:08:21.012588 10142 solver.cpp:218] Iteration 33700 (6.31345 iter/s, 15.8392s/100 iters), loss = 0.242845
I1005 22:08:21.012636 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.242845 (* 1 = 0.242845 loss)
I1005 22:08:21.012645 10142 sgd_solver.cpp:105] Iteration 33700, lr = 0.1
I1005 22:08:36.916194 10142 solver.cpp:218] Iteration 33800 (6.28793 iter/s, 15.9035s/100 iters), loss = 0.222171
I1005 22:08:36.916266 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.222171 (* 1 = 0.222171 loss)
I1005 22:08:36.916285 10142 sgd_solver.cpp:105] Iteration 33800, lr = 0.1
I1005 22:08:52.763844 10142 solver.cpp:218] Iteration 33900 (6.31014 iter/s, 15.8475s/100 iters), loss = 0.161397
I1005 22:08:52.763876 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.161397 (* 1 = 0.161397 loss)
I1005 22:08:52.763895 10142 sgd_solver.cpp:105] Iteration 33900, lr = 0.1
I1005 22:09:07.879159 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 22:09:08.480435 10142 solver.cpp:330] Iteration 34000, Testing net (#0)
I1005 22:09:11.697607 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 22:09:11.825469 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7569
I1005 22:09:11.825495 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.794837 (* 1 = 0.794837 loss)
I1005 22:09:11.958351 10142 solver.cpp:218] Iteration 34000 (5.20985 iter/s, 19.1944s/100 iters), loss = 0.289827
I1005 22:09:11.958400 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.289827 (* 1 = 0.289827 loss)
I1005 22:09:11.958406 10142 sgd_solver.cpp:105] Iteration 34000, lr = 0.1
I1005 22:09:27.878222 10142 solver.cpp:218] Iteration 34100 (6.2815 iter/s, 15.9198s/100 iters), loss = 0.212112
I1005 22:09:27.878265 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.212112 (* 1 = 0.212112 loss)
I1005 22:09:27.878271 10142 sgd_solver.cpp:105] Iteration 34100, lr = 0.1
I1005 22:09:43.740820 10142 solver.cpp:218] Iteration 34200 (6.30418 iter/s, 15.8625s/100 iters), loss = 0.313047
I1005 22:09:43.740912 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.313046 (* 1 = 0.313046 loss)
I1005 22:09:43.740931 10142 sgd_solver.cpp:105] Iteration 34200, lr = 0.1
I1005 22:09:59.604470 10142 solver.cpp:218] Iteration 34300 (6.30378 iter/s, 15.8635s/100 iters), loss = 0.123198
I1005 22:09:59.604509 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.123198 (* 1 = 0.123198 loss)
I1005 22:09:59.604516 10142 sgd_solver.cpp:105] Iteration 34300, lr = 0.1
I1005 22:10:15.473248 10142 solver.cpp:218] Iteration 34400 (6.30172 iter/s, 15.8687s/100 iters), loss = 0.143167
I1005 22:10:15.473378 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.143167 (* 1 = 0.143167 loss)
I1005 22:10:15.473397 10142 sgd_solver.cpp:105] Iteration 34400, lr = 0.1
I1005 22:10:30.670079 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 22:10:31.276341 10142 solver.cpp:330] Iteration 34500, Testing net (#0)
I1005 22:10:34.493171 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 22:10:34.621331 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8001
I1005 22:10:34.621367 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.647468 (* 1 = 0.647468 loss)
I1005 22:10:34.752749 10142 solver.cpp:218] Iteration 34500 (5.18691 iter/s, 19.2793s/100 iters), loss = 0.230096
I1005 22:10:34.752794 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.230095 (* 1 = 0.230095 loss)
I1005 22:10:34.752799 10142 sgd_solver.cpp:105] Iteration 34500, lr = 0.1
I1005 22:10:50.579224 10142 solver.cpp:218] Iteration 34600 (6.31857 iter/s, 15.8264s/100 iters), loss = 0.221839
I1005 22:10:50.579310 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.221839 (* 1 = 0.221839 loss)
I1005 22:10:50.579319 10142 sgd_solver.cpp:105] Iteration 34600, lr = 0.1
I1005 22:11:06.455430 10142 solver.cpp:218] Iteration 34700 (6.29882 iter/s, 15.876s/100 iters), loss = 0.214474
I1005 22:11:06.455463 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.214474 (* 1 = 0.214474 loss)
I1005 22:11:06.455480 10142 sgd_solver.cpp:105] Iteration 34700, lr = 0.1
I1005 22:11:22.416384 10142 solver.cpp:218] Iteration 34800 (6.26533 iter/s, 15.9609s/100 iters), loss = 0.237975
I1005 22:11:22.416496 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.237975 (* 1 = 0.237975 loss)
I1005 22:11:22.416513 10142 sgd_solver.cpp:105] Iteration 34800, lr = 0.1
I1005 22:11:38.286608 10142 solver.cpp:218] Iteration 34900 (6.30118 iter/s, 15.87s/100 iters), loss = 0.168033
I1005 22:11:38.286638 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.168033 (* 1 = 0.168033 loss)
I1005 22:11:38.286654 10142 sgd_solver.cpp:105] Iteration 34900, lr = 0.1
I1005 22:11:53.401186 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 22:11:54.035887 10142 solver.cpp:330] Iteration 35000, Testing net (#0)
I1005 22:11:57.237370 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 22:11:57.367561 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8449
I1005 22:11:57.367599 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.471142 (* 1 = 0.471142 loss)
I1005 22:11:57.476773 10142 solver.cpp:218] Iteration 35000 (5.21103 iter/s, 19.1901s/100 iters), loss = 0.158447
I1005 22:11:57.476815 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.158447 (* 1 = 0.158447 loss)
I1005 22:11:57.476822 10142 sgd_solver.cpp:105] Iteration 35000, lr = 0.1
I1005 22:12:13.449564 10142 solver.cpp:218] Iteration 35100 (6.26151 iter/s, 15.9706s/100 iters), loss = 0.232047
I1005 22:12:13.449607 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.232047 (* 1 = 0.232047 loss)
I1005 22:12:13.449615 10142 sgd_solver.cpp:105] Iteration 35100, lr = 0.1
I1005 22:12:29.307538 10142 solver.cpp:218] Iteration 35200 (6.30602 iter/s, 15.8579s/100 iters), loss = 0.317875
I1005 22:12:29.307663 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.317875 (* 1 = 0.317875 loss)
I1005 22:12:29.307682 10142 sgd_solver.cpp:105] Iteration 35200, lr = 0.1
I1005 22:12:45.167971 10142 solver.cpp:218] Iteration 35300 (6.30591 iter/s, 15.8581s/100 iters), loss = 0.305423
I1005 22:12:45.168016 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.305423 (* 1 = 0.305423 loss)
I1005 22:12:45.168025 10142 sgd_solver.cpp:105] Iteration 35300, lr = 0.1
I1005 22:13:01.033622 10142 solver.cpp:218] Iteration 35400 (6.30381 iter/s, 15.8634s/100 iters), loss = 0.262019
I1005 22:13:01.033721 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.262019 (* 1 = 0.262019 loss)
I1005 22:13:01.033730 10142 sgd_solver.cpp:105] Iteration 35400, lr = 0.1
I1005 22:13:16.210253 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 22:13:16.841064 10142 solver.cpp:330] Iteration 35500, Testing net (#0)
I1005 22:13:20.039053 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 22:13:20.168958 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7997
I1005 22:13:20.168985 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.645626 (* 1 = 0.645626 loss)
I1005 22:13:20.279814 10142 solver.cpp:218] Iteration 35500 (5.19645 iter/s, 19.2439s/100 iters), loss = 0.19369
I1005 22:13:20.279853 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.19369 (* 1 = 0.19369 loss)
I1005 22:13:20.279860 10142 sgd_solver.cpp:105] Iteration 35500, lr = 0.1
I1005 22:13:36.140913 10142 solver.cpp:218] Iteration 35600 (6.30479 iter/s, 15.861s/100 iters), loss = 0.260216
I1005 22:13:36.141026 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.260216 (* 1 = 0.260216 loss)
I1005 22:13:36.141043 10142 sgd_solver.cpp:105] Iteration 35600, lr = 0.1
I1005 22:13:52.001087 10142 solver.cpp:218] Iteration 35700 (6.30519 iter/s, 15.8599s/100 iters), loss = 0.251681
I1005 22:13:52.001117 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.251681 (* 1 = 0.251681 loss)
I1005 22:13:52.001134 10142 sgd_solver.cpp:105] Iteration 35700, lr = 0.1
I1005 22:14:07.994307 10142 solver.cpp:218] Iteration 35800 (6.25269 iter/s, 15.9931s/100 iters), loss = 0.293736
I1005 22:14:07.994372 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.293736 (* 1 = 0.293736 loss)
I1005 22:14:07.994390 10142 sgd_solver.cpp:105] Iteration 35800, lr = 0.1
I1005 22:14:23.844748 10142 solver.cpp:218] Iteration 35900 (6.30903 iter/s, 15.8503s/100 iters), loss = 0.149289
I1005 22:14:23.844780 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.149289 (* 1 = 0.149289 loss)
I1005 22:14:23.844789 10142 sgd_solver.cpp:105] Iteration 35900, lr = 0.1
I1005 22:14:38.917294 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 22:14:39.555564 10142 solver.cpp:330] Iteration 36000, Testing net (#0)
I1005 22:14:42.782687 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 22:14:42.910143 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8328
I1005 22:14:42.910171 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.529128 (* 1 = 0.529128 loss)
I1005 22:14:43.041647 10142 solver.cpp:218] Iteration 36000 (5.2092 iter/s, 19.1968s/100 iters), loss = 0.195644
I1005 22:14:43.041692 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.195644 (* 1 = 0.195644 loss)
I1005 22:14:43.041698 10142 sgd_solver.cpp:105] Iteration 36000, lr = 0.1
I1005 22:14:58.969271 10142 solver.cpp:218] Iteration 36100 (6.27844 iter/s, 15.9275s/100 iters), loss = 0.316246
I1005 22:14:58.969312 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.316246 (* 1 = 0.316246 loss)
I1005 22:14:58.969319 10142 sgd_solver.cpp:105] Iteration 36100, lr = 0.1
I1005 22:15:14.809746 10142 solver.cpp:218] Iteration 36200 (6.31298 iter/s, 15.8404s/100 iters), loss = 0.282682
I1005 22:15:14.809847 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.282682 (* 1 = 0.282682 loss)
I1005 22:15:14.809856 10142 sgd_solver.cpp:105] Iteration 36200, lr = 0.1
I1005 22:15:30.676499 10142 solver.cpp:218] Iteration 36300 (6.30255 iter/s, 15.8666s/100 iters), loss = 0.19327
I1005 22:15:30.676542 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.193269 (* 1 = 0.193269 loss)
I1005 22:15:30.676548 10142 sgd_solver.cpp:105] Iteration 36300, lr = 0.1
I1005 22:15:46.533231 10142 solver.cpp:218] Iteration 36400 (6.30734 iter/s, 15.8545s/100 iters), loss = 0.164088
I1005 22:15:46.533365 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.164088 (* 1 = 0.164088 loss)
I1005 22:15:46.533375 10142 sgd_solver.cpp:105] Iteration 36400, lr = 0.1
I1005 22:16:01.719234 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 22:16:02.350780 10142 solver.cpp:330] Iteration 36500, Testing net (#0)
I1005 22:16:05.521795 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 22:16:05.649864 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7858
I1005 22:16:05.649900 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.736289 (* 1 = 0.736289 loss)
I1005 22:16:05.780686 10142 solver.cpp:218] Iteration 36500 (5.19563 iter/s, 19.247s/100 iters), loss = 0.210267
I1005 22:16:05.780730 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.210266 (* 1 = 0.210266 loss)
I1005 22:16:05.780736 10142 sgd_solver.cpp:105] Iteration 36500, lr = 0.1
I1005 22:16:21.651005 10142 solver.cpp:218] Iteration 36600 (6.30111 iter/s, 15.8702s/100 iters), loss = 0.216025
I1005 22:16:21.651130 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.216025 (* 1 = 0.216025 loss)
I1005 22:16:21.651149 10142 sgd_solver.cpp:105] Iteration 36600, lr = 0.1
I1005 22:16:37.514979 10142 solver.cpp:218] Iteration 36700 (6.30367 iter/s, 15.8638s/100 iters), loss = 0.301153
I1005 22:16:37.515022 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.301152 (* 1 = 0.301152 loss)
I1005 22:16:37.515028 10142 sgd_solver.cpp:105] Iteration 36700, lr = 0.1
I1005 22:16:53.427438 10142 solver.cpp:218] Iteration 36800 (6.28443 iter/s, 15.9124s/100 iters), loss = 0.189879
I1005 22:16:53.427530 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.189878 (* 1 = 0.189878 loss)
I1005 22:16:53.427547 10142 sgd_solver.cpp:105] Iteration 36800, lr = 0.1
I1005 22:17:09.274433 10142 solver.cpp:218] Iteration 36900 (6.3104 iter/s, 15.8468s/100 iters), loss = 0.118329
I1005 22:17:09.274475 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.118329 (* 1 = 0.118329 loss)
I1005 22:17:09.274485 10142 sgd_solver.cpp:105] Iteration 36900, lr = 0.1
I1005 22:17:24.346706 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 22:17:24.979478 10142 solver.cpp:330] Iteration 37000, Testing net (#0)
I1005 22:17:28.189012 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 22:17:28.332635 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.847
I1005 22:17:28.332660 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.499808 (* 1 = 0.499808 loss)
I1005 22:17:28.434128 10142 solver.cpp:218] Iteration 37000 (5.21932 iter/s, 19.1596s/100 iters), loss = 0.206249
I1005 22:17:28.434170 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.206249 (* 1 = 0.206249 loss)
I1005 22:17:28.434176 10142 sgd_solver.cpp:105] Iteration 37000, lr = 0.1
I1005 22:17:44.327486 10142 solver.cpp:218] Iteration 37100 (6.29281 iter/s, 15.8911s/100 iters), loss = 0.288891
I1005 22:17:44.327518 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.288891 (* 1 = 0.288891 loss)
I1005 22:17:44.327535 10142 sgd_solver.cpp:105] Iteration 37100, lr = 0.1
I1005 22:18:00.222071 10142 solver.cpp:218] Iteration 37200 (6.29149 iter/s, 15.8945s/100 iters), loss = 0.194137
I1005 22:18:00.222214 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.194137 (* 1 = 0.194137 loss)
I1005 22:18:00.222223 10142 sgd_solver.cpp:105] Iteration 37200, lr = 0.1
I1005 22:18:16.068089 10142 solver.cpp:218] Iteration 37300 (6.31081 iter/s, 15.8458s/100 iters), loss = 0.248424
I1005 22:18:16.068125 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.248424 (* 1 = 0.248424 loss)
I1005 22:18:16.068145 10142 sgd_solver.cpp:105] Iteration 37300, lr = 0.1
I1005 22:18:31.924716 10142 solver.cpp:218] Iteration 37400 (6.30655 iter/s, 15.8565s/100 iters), loss = 0.206648
I1005 22:18:31.924835 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.206648 (* 1 = 0.206648 loss)
I1005 22:18:31.924854 10142 sgd_solver.cpp:105] Iteration 37400, lr = 0.1
I1005 22:18:47.147207 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 22:18:47.781394 10142 solver.cpp:330] Iteration 37500, Testing net (#0)
I1005 22:18:50.982699 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 22:18:51.114217 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7474
I1005 22:18:51.114259 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.840686 (* 1 = 0.840686 loss)
I1005 22:18:51.226516 10142 solver.cpp:218] Iteration 37500 (5.18092 iter/s, 19.3016s/100 iters), loss = 0.203222
I1005 22:18:51.226573 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.203222 (* 1 = 0.203222 loss)
I1005 22:18:51.226590 10142 sgd_solver.cpp:105] Iteration 37500, lr = 0.1
I1005 22:19:07.105500 10142 solver.cpp:218] Iteration 37600 (6.29769 iter/s, 15.8789s/100 iters), loss = 0.273641
I1005 22:19:07.105585 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.27364 (* 1 = 0.27364 loss)
I1005 22:19:07.105593 10142 sgd_solver.cpp:105] Iteration 37600, lr = 0.1
I1005 22:19:22.969079 10142 solver.cpp:218] Iteration 37700 (6.30466 iter/s, 15.8613s/100 iters), loss = 0.198502
I1005 22:19:22.969111 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.198501 (* 1 = 0.198501 loss)
I1005 22:19:22.969128 10142 sgd_solver.cpp:105] Iteration 37700, lr = 0.1
I1005 22:19:38.924590 10142 solver.cpp:218] Iteration 37800 (6.26747 iter/s, 15.9554s/100 iters), loss = 0.264711
I1005 22:19:38.924690 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.264711 (* 1 = 0.264711 loss)
I1005 22:19:38.924710 10142 sgd_solver.cpp:105] Iteration 37800, lr = 0.1
I1005 22:19:54.777182 10142 solver.cpp:218] Iteration 37900 (6.30818 iter/s, 15.8524s/100 iters), loss = 0.196619
I1005 22:19:54.777214 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.196619 (* 1 = 0.196619 loss)
I1005 22:19:54.777220 10142 sgd_solver.cpp:105] Iteration 37900, lr = 0.1
I1005 22:20:09.863649 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 22:20:10.495965 10142 solver.cpp:330] Iteration 38000, Testing net (#0)
I1005 22:20:13.726359 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 22:20:13.853799 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8357
I1005 22:20:13.853827 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.49242 (* 1 = 0.49242 loss)
I1005 22:20:13.985054 10142 solver.cpp:218] Iteration 38000 (5.20623 iter/s, 19.2078s/100 iters), loss = 0.177489
I1005 22:20:13.985090 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.177489 (* 1 = 0.177489 loss)
I1005 22:20:13.985110 10142 sgd_solver.cpp:105] Iteration 38000, lr = 0.1
I1005 22:20:29.836907 10142 solver.cpp:218] Iteration 38100 (6.30845 iter/s, 15.8518s/100 iters), loss = 0.223254
I1005 22:20:29.836956 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.223254 (* 1 = 0.223254 loss)
I1005 22:20:29.836966 10142 sgd_solver.cpp:105] Iteration 38100, lr = 0.1
I1005 22:20:45.776335 10142 solver.cpp:218] Iteration 38200 (6.27463 iter/s, 15.9372s/100 iters), loss = 0.198857
I1005 22:20:45.776429 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.198857 (* 1 = 0.198857 loss)
I1005 22:20:45.776438 10142 sgd_solver.cpp:105] Iteration 38200, lr = 0.1
I1005 22:21:01.636883 10142 solver.cpp:218] Iteration 38300 (6.30501 iter/s, 15.8604s/100 iters), loss = 0.221198
I1005 22:21:01.636924 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.221198 (* 1 = 0.221198 loss)
I1005 22:21:01.636930 10142 sgd_solver.cpp:105] Iteration 38300, lr = 0.1
I1005 22:21:17.488924 10142 solver.cpp:218] Iteration 38400 (6.30838 iter/s, 15.8519s/100 iters), loss = 0.150917
I1005 22:21:17.489027 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.150917 (* 1 = 0.150917 loss)
I1005 22:21:17.489035 10142 sgd_solver.cpp:105] Iteration 38400, lr = 0.1
I1005 22:21:32.643873 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 22:21:33.268785 10142 solver.cpp:330] Iteration 38500, Testing net (#0)
I1005 22:21:36.439744 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 22:21:36.567971 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7224
I1005 22:21:36.568007 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.00072 (* 1 = 1.00072 loss)
I1005 22:21:36.687825 10142 solver.cpp:218] Iteration 38500 (5.20923 iter/s, 19.1967s/100 iters), loss = 0.204844
I1005 22:21:36.687871 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.204843 (* 1 = 0.204843 loss)
I1005 22:21:36.687877 10142 sgd_solver.cpp:105] Iteration 38500, lr = 0.1
I1005 22:21:52.522025 10142 solver.cpp:218] Iteration 38600 (6.31634 iter/s, 15.832s/100 iters), loss = 0.243448
I1005 22:21:52.522152 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.243447 (* 1 = 0.243447 loss)
I1005 22:21:52.522173 10142 sgd_solver.cpp:105] Iteration 38600, lr = 0.1
I1005 22:22:08.380508 10142 solver.cpp:218] Iteration 38700 (6.30666 iter/s, 15.8563s/100 iters), loss = 0.281616
I1005 22:22:08.380551 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.281616 (* 1 = 0.281616 loss)
I1005 22:22:08.380558 10142 sgd_solver.cpp:105] Iteration 38700, lr = 0.1
I1005 22:22:24.334180 10142 solver.cpp:218] Iteration 38800 (6.26904 iter/s, 15.9514s/100 iters), loss = 0.214349
I1005 22:22:24.334270 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.214349 (* 1 = 0.214349 loss)
I1005 22:22:24.334290 10142 sgd_solver.cpp:105] Iteration 38800, lr = 0.1
I1005 22:22:40.183900 10142 solver.cpp:218] Iteration 38900 (6.30932 iter/s, 15.8496s/100 iters), loss = 0.263758
I1005 22:22:40.183944 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.263758 (* 1 = 0.263758 loss)
I1005 22:22:40.183951 10142 sgd_solver.cpp:105] Iteration 38900, lr = 0.1
I1005 22:22:55.268955 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 22:22:55.902958 10142 solver.cpp:330] Iteration 39000, Testing net (#0)
I1005 22:22:59.131078 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 22:22:59.259397 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7737
I1005 22:22:59.259434 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.715238 (* 1 = 0.715238 loss)
I1005 22:22:59.390568 10142 solver.cpp:218] Iteration 39000 (5.20656 iter/s, 19.2066s/100 iters), loss = 0.184365
I1005 22:22:59.390609 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.184365 (* 1 = 0.184365 loss)
I1005 22:22:59.390615 10142 sgd_solver.cpp:105] Iteration 39000, lr = 0.1
I1005 22:23:15.239126 10142 solver.cpp:218] Iteration 39100 (6.30977 iter/s, 15.8484s/100 iters), loss = 0.157279
I1005 22:23:15.239172 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.157279 (* 1 = 0.157279 loss)
I1005 22:23:15.239179 10142 sgd_solver.cpp:105] Iteration 39100, lr = 0.1
I1005 22:23:31.157701 10142 solver.cpp:218] Iteration 39200 (6.28201 iter/s, 15.9185s/100 iters), loss = 0.171999
I1005 22:23:31.157790 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.171999 (* 1 = 0.171999 loss)
I1005 22:23:31.157809 10142 sgd_solver.cpp:105] Iteration 39200, lr = 0.1
I1005 22:23:46.993988 10142 solver.cpp:218] Iteration 39300 (6.31467 iter/s, 15.8361s/100 iters), loss = 0.227052
I1005 22:23:46.994021 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.227051 (* 1 = 0.227051 loss)
I1005 22:23:46.994027 10142 sgd_solver.cpp:105] Iteration 39300, lr = 0.1
I1005 22:24:02.844432 10142 solver.cpp:218] Iteration 39400 (6.30901 iter/s, 15.8503s/100 iters), loss = 0.101061
I1005 22:24:02.844545 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.10106 (* 1 = 0.10106 loss)
I1005 22:24:02.844553 10142 sgd_solver.cpp:105] Iteration 39400, lr = 0.1
I1005 22:24:18.037590 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 22:24:18.652731 10142 solver.cpp:330] Iteration 39500, Testing net (#0)
I1005 22:24:21.863531 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 22:24:22.000154 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8242
I1005 22:24:22.000190 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.552091 (* 1 = 0.552091 loss)
I1005 22:24:22.120578 10142 solver.cpp:218] Iteration 39500 (5.18781 iter/s, 19.276s/100 iters), loss = 0.1468
I1005 22:24:22.120618 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.146799 (* 1 = 0.146799 loss)
I1005 22:24:22.120625 10142 sgd_solver.cpp:105] Iteration 39500, lr = 0.1
I1005 22:24:37.971361 10142 solver.cpp:218] Iteration 39600 (6.30888 iter/s, 15.8507s/100 iters), loss = 0.201482
I1005 22:24:37.971479 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.201482 (* 1 = 0.201482 loss)
I1005 22:24:37.971496 10142 sgd_solver.cpp:105] Iteration 39600, lr = 0.1
I1005 22:24:53.814874 10142 solver.cpp:218] Iteration 39700 (6.3118 iter/s, 15.8433s/100 iters), loss = 0.329447
I1005 22:24:53.814906 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.329447 (* 1 = 0.329447 loss)
I1005 22:24:53.814915 10142 sgd_solver.cpp:105] Iteration 39700, lr = 0.1
I1005 22:25:09.708746 10142 solver.cpp:218] Iteration 39800 (6.29177 iter/s, 15.8938s/100 iters), loss = 0.18964
I1005 22:25:09.708844 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.18964 (* 1 = 0.18964 loss)
I1005 22:25:09.708854 10142 sgd_solver.cpp:105] Iteration 39800, lr = 0.1
I1005 22:25:25.539638 10142 solver.cpp:218] Iteration 39900 (6.31766 iter/s, 15.8287s/100 iters), loss = 0.146595
I1005 22:25:25.539680 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.146594 (* 1 = 0.146594 loss)
I1005 22:25:25.539686 10142 sgd_solver.cpp:105] Iteration 39900, lr = 0.1
I1005 22:25:40.649086 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 22:25:41.253147 10142 solver.cpp:330] Iteration 40000, Testing net (#0)
I1005 22:25:44.471276 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 22:25:44.604393 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8272
I1005 22:25:44.604429 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.531547 (* 1 = 0.531547 loss)
I1005 22:25:44.725126 10142 solver.cpp:218] Iteration 40000 (5.2123 iter/s, 19.1854s/100 iters), loss = 0.217971
I1005 22:25:44.725165 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.217971 (* 1 = 0.217971 loss)
I1005 22:25:44.725172 10142 sgd_solver.cpp:46] MultiStep Status: Iteration 40000, step = 1
I1005 22:25:44.725175 10142 sgd_solver.cpp:105] Iteration 40000, lr = 0.01
I1005 22:26:00.592170 10142 solver.cpp:218] Iteration 40100 (6.30241 iter/s, 15.8669s/100 iters), loss = 0.1801
I1005 22:26:00.592201 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.180099 (* 1 = 0.180099 loss)
I1005 22:26:00.592208 10142 sgd_solver.cpp:105] Iteration 40100, lr = 0.01
I1005 22:26:16.583811 10142 solver.cpp:218] Iteration 40200 (6.25331 iter/s, 15.9915s/100 iters), loss = 0.133594
I1005 22:26:16.583904 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.133594 (* 1 = 0.133594 loss)
I1005 22:26:16.583912 10142 sgd_solver.cpp:105] Iteration 40200, lr = 0.01
I1005 22:26:32.429551 10142 solver.cpp:218] Iteration 40300 (6.3109 iter/s, 15.8456s/100 iters), loss = 0.09901
I1005 22:26:32.429582 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0990098 (* 1 = 0.0990098 loss)
I1005 22:26:32.429599 10142 sgd_solver.cpp:105] Iteration 40300, lr = 0.01
I1005 22:26:48.282193 10142 solver.cpp:218] Iteration 40400 (6.30814 iter/s, 15.8525s/100 iters), loss = 0.100871
I1005 22:26:48.282289 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.100871 (* 1 = 0.100871 loss)
I1005 22:26:48.282296 10142 sgd_solver.cpp:105] Iteration 40400, lr = 0.01
I1005 22:27:03.478361 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 22:27:04.082069 10142 solver.cpp:330] Iteration 40500, Testing net (#0)
I1005 22:27:07.296716 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 22:27:07.432015 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9023
I1005 22:27:07.432044 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.28294 (* 1 = 0.28294 loss)
I1005 22:27:07.555371 10142 solver.cpp:218] Iteration 40500 (5.18861 iter/s, 19.273s/100 iters), loss = 0.115354
I1005 22:27:07.555426 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.115354 (* 1 = 0.115354 loss)
I1005 22:27:07.555447 10142 sgd_solver.cpp:105] Iteration 40500, lr = 0.01
I1005 22:27:23.401834 10142 solver.cpp:218] Iteration 40600 (6.3106 iter/s, 15.8463s/100 iters), loss = 0.111695
I1005 22:27:23.401978 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.111695 (* 1 = 0.111695 loss)
I1005 22:27:23.401996 10142 sgd_solver.cpp:105] Iteration 40600, lr = 0.01
I1005 22:27:39.261863 10142 solver.cpp:218] Iteration 40700 (6.30524 iter/s, 15.8598s/100 iters), loss = 0.094956
I1005 22:27:39.261901 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0949558 (* 1 = 0.0949558 loss)
I1005 22:27:39.261920 10142 sgd_solver.cpp:105] Iteration 40700, lr = 0.01
I1005 22:27:55.140117 10142 solver.cpp:218] Iteration 40800 (6.29797 iter/s, 15.8781s/100 iters), loss = 0.0787145
I1005 22:27:55.140233 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0787142 (* 1 = 0.0787142 loss)
I1005 22:27:55.140244 10142 sgd_solver.cpp:105] Iteration 40800, lr = 0.01
I1005 22:28:11.033646 10142 solver.cpp:218] Iteration 40900 (6.29275 iter/s, 15.8913s/100 iters), loss = 0.0953036
I1005 22:28:11.033679 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0953033 (* 1 = 0.0953033 loss)
I1005 22:28:11.033689 10142 sgd_solver.cpp:105] Iteration 40900, lr = 0.01
I1005 22:28:26.145722 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 22:28:26.748042 10142 solver.cpp:330] Iteration 41000, Testing net (#0)
I1005 22:28:29.967002 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 22:28:30.099408 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9119
I1005 22:28:30.099447 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.262418 (* 1 = 0.262418 loss)
I1005 22:28:30.221623 10142 solver.cpp:218] Iteration 41000 (5.21162 iter/s, 19.1879s/100 iters), loss = 0.0810808
I1005 22:28:30.221668 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0810806 (* 1 = 0.0810806 loss)
I1005 22:28:30.221675 10142 sgd_solver.cpp:105] Iteration 41000, lr = 0.01
I1005 22:28:46.080281 10142 solver.cpp:218] Iteration 41100 (6.30575 iter/s, 15.8585s/100 iters), loss = 0.106912
I1005 22:28:46.080323 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.106912 (* 1 = 0.106912 loss)
I1005 22:28:46.080330 10142 sgd_solver.cpp:105] Iteration 41100, lr = 0.01
I1005 22:29:02.007694 10142 solver.cpp:218] Iteration 41200 (6.27852 iter/s, 15.9273s/100 iters), loss = 0.0752633
I1005 22:29:02.007783 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0752631 (* 1 = 0.0752631 loss)
I1005 22:29:02.007800 10142 sgd_solver.cpp:105] Iteration 41200, lr = 0.01
I1005 22:29:17.869189 10142 solver.cpp:218] Iteration 41300 (6.30464 iter/s, 15.8613s/100 iters), loss = 0.0882114
I1005 22:29:17.869231 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0882112 (* 1 = 0.0882112 loss)
I1005 22:29:17.869238 10142 sgd_solver.cpp:105] Iteration 41300, lr = 0.01
I1005 22:29:33.721550 10142 solver.cpp:218] Iteration 41400 (6.30825 iter/s, 15.8523s/100 iters), loss = 0.0559798
I1005 22:29:33.721643 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0559795 (* 1 = 0.0559795 loss)
I1005 22:29:33.721665 10142 sgd_solver.cpp:105] Iteration 41400, lr = 0.01
I1005 22:29:48.900275 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 22:29:49.532459 10142 solver.cpp:330] Iteration 41500, Testing net (#0)
I1005 22:29:52.764153 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 22:29:52.892531 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9133
I1005 22:29:52.892560 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.261299 (* 1 = 0.261299 loss)
I1005 22:29:53.024164 10142 solver.cpp:218] Iteration 41500 (5.18069 iter/s, 19.3025s/100 iters), loss = 0.0871199
I1005 22:29:53.024200 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0871196 (* 1 = 0.0871196 loss)
I1005 22:29:53.024220 10142 sgd_solver.cpp:105] Iteration 41500, lr = 0.01
I1005 22:30:08.872056 10142 solver.cpp:218] Iteration 41600 (6.31003 iter/s, 15.8478s/100 iters), loss = 0.124811
I1005 22:30:08.872205 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.12481 (* 1 = 0.12481 loss)
I1005 22:30:08.872237 10142 sgd_solver.cpp:105] Iteration 41600, lr = 0.01
I1005 22:30:24.731190 10142 solver.cpp:218] Iteration 41700 (6.30559 iter/s, 15.8589s/100 iters), loss = 0.0805171
I1005 22:30:24.731223 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0805168 (* 1 = 0.0805168 loss)
I1005 22:30:24.731240 10142 sgd_solver.cpp:105] Iteration 41700, lr = 0.01
I1005 22:30:40.581717 10142 solver.cpp:218] Iteration 41800 (6.30898 iter/s, 15.8504s/100 iters), loss = 0.1271
I1005 22:30:40.581828 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.1271 (* 1 = 0.1271 loss)
I1005 22:30:40.581836 10142 sgd_solver.cpp:105] Iteration 41800, lr = 0.01
I1005 22:30:56.532279 10142 solver.cpp:218] Iteration 41900 (6.26944 iter/s, 15.9504s/100 iters), loss = 0.0488751
I1005 22:30:56.532310 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0488749 (* 1 = 0.0488749 loss)
I1005 22:30:56.532316 10142 sgd_solver.cpp:105] Iteration 41900, lr = 0.01
I1005 22:31:11.615761 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 22:31:12.250995 10142 solver.cpp:330] Iteration 42000, Testing net (#0)
I1005 22:31:15.483343 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 22:31:15.613160 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9147
I1005 22:31:15.613198 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.263134 (* 1 = 0.263134 loss)
I1005 22:31:15.721181 10142 solver.cpp:218] Iteration 42000 (5.21137 iter/s, 19.1888s/100 iters), loss = 0.0646238
I1005 22:31:15.721218 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0646237 (* 1 = 0.0646237 loss)
I1005 22:31:15.721236 10142 sgd_solver.cpp:105] Iteration 42000, lr = 0.01
I1005 22:31:31.568919 10142 solver.cpp:218] Iteration 42100 (6.31092 iter/s, 15.8455s/100 iters), loss = 0.0866379
I1005 22:31:31.568953 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0866377 (* 1 = 0.0866377 loss)
I1005 22:31:31.568971 10142 sgd_solver.cpp:105] Iteration 42100, lr = 0.01
I1005 22:31:47.517837 10142 solver.cpp:218] Iteration 42200 (6.27006 iter/s, 15.9488s/100 iters), loss = 0.0787886
I1005 22:31:47.517931 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0787884 (* 1 = 0.0787884 loss)
I1005 22:31:47.517952 10142 sgd_solver.cpp:105] Iteration 42200, lr = 0.01
I1005 22:32:03.376651 10142 solver.cpp:218] Iteration 42300 (6.30571 iter/s, 15.8587s/100 iters), loss = 0.144019
I1005 22:32:03.376690 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.144019 (* 1 = 0.144019 loss)
I1005 22:32:03.376710 10142 sgd_solver.cpp:105] Iteration 42300, lr = 0.01
I1005 22:32:19.243018 10142 solver.cpp:218] Iteration 42400 (6.30269 iter/s, 15.8662s/100 iters), loss = 0.0400864
I1005 22:32:19.243093 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0400862 (* 1 = 0.0400862 loss)
I1005 22:32:19.243101 10142 sgd_solver.cpp:105] Iteration 42400, lr = 0.01
I1005 22:32:34.412865 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 22:32:35.033581 10142 solver.cpp:330] Iteration 42500, Testing net (#0)
I1005 22:32:38.263526 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 22:32:38.391638 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9146
I1005 22:32:38.391675 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.263335 (* 1 = 0.263335 loss)
I1005 22:32:38.523277 10142 solver.cpp:218] Iteration 42500 (5.18669 iter/s, 19.2801s/100 iters), loss = 0.0394884
I1005 22:32:38.523320 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0394882 (* 1 = 0.0394882 loss)
I1005 22:32:38.523327 10142 sgd_solver.cpp:105] Iteration 42500, lr = 0.01
I1005 22:32:54.399190 10142 solver.cpp:218] Iteration 42600 (6.29889 iter/s, 15.8758s/100 iters), loss = 0.0955886
I1005 22:32:54.399348 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0955884 (* 1 = 0.0955884 loss)
I1005 22:32:54.399370 10142 sgd_solver.cpp:105] Iteration 42600, lr = 0.01
I1005 22:33:10.273638 10142 solver.cpp:218] Iteration 42700 (6.29952 iter/s, 15.8742s/100 iters), loss = 0.0615654
I1005 22:33:10.273681 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0615653 (* 1 = 0.0615653 loss)
I1005 22:33:10.273687 10142 sgd_solver.cpp:105] Iteration 42700, lr = 0.01
I1005 22:33:26.144735 10142 solver.cpp:218] Iteration 42800 (6.30081 iter/s, 15.871s/100 iters), loss = 0.0937957
I1005 22:33:26.144858 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0937955 (* 1 = 0.0937955 loss)
I1005 22:33:26.144876 10142 sgd_solver.cpp:105] Iteration 42800, lr = 0.01
I1005 22:33:42.058420 10142 solver.cpp:218] Iteration 42900 (6.28397 iter/s, 15.9135s/100 iters), loss = 0.0691313
I1005 22:33:42.058455 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0691311 (* 1 = 0.0691311 loss)
I1005 22:33:42.058464 10142 sgd_solver.cpp:105] Iteration 42900, lr = 0.01
I1005 22:33:57.173034 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 22:33:57.781028 10142 solver.cpp:330] Iteration 43000, Testing net (#0)
I1005 22:34:01.001539 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 22:34:01.129107 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9164
I1005 22:34:01.129143 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.260615 (* 1 = 0.260615 loss)
I1005 22:34:01.261993 10142 solver.cpp:218] Iteration 43000 (5.20739 iter/s, 19.2035s/100 iters), loss = 0.0513311
I1005 22:34:01.262038 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0513309 (* 1 = 0.0513309 loss)
I1005 22:34:01.262044 10142 sgd_solver.cpp:105] Iteration 43000, lr = 0.01
I1005 22:34:17.080255 10142 solver.cpp:218] Iteration 43100 (6.32185 iter/s, 15.8182s/100 iters), loss = 0.0685651
I1005 22:34:17.080307 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0685649 (* 1 = 0.0685649 loss)
I1005 22:34:17.080327 10142 sgd_solver.cpp:105] Iteration 43100, lr = 0.01
I1005 22:34:33.032863 10142 solver.cpp:218] Iteration 43200 (6.26861 iter/s, 15.9525s/100 iters), loss = 0.0730347
I1005 22:34:33.032960 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0730345 (* 1 = 0.0730345 loss)
I1005 22:34:33.032981 10142 sgd_solver.cpp:105] Iteration 43200, lr = 0.01
I1005 22:34:48.788849 10142 solver.cpp:218] Iteration 43300 (6.34685 iter/s, 15.7558s/100 iters), loss = 0.0499414
I1005 22:34:48.788884 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0499411 (* 1 = 0.0499411 loss)
I1005 22:34:48.788893 10142 sgd_solver.cpp:105] Iteration 43300, lr = 0.01
I1005 22:35:04.643311 10142 solver.cpp:218] Iteration 43400 (6.30741 iter/s, 15.8544s/100 iters), loss = 0.0590156
I1005 22:35:04.643405 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0590153 (* 1 = 0.0590153 loss)
I1005 22:35:04.643415 10142 sgd_solver.cpp:105] Iteration 43400, lr = 0.01
I1005 22:35:19.782770 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 22:35:20.429987 10142 solver.cpp:330] Iteration 43500, Testing net (#0)
I1005 22:35:23.665773 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 22:35:23.797832 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9185
I1005 22:35:23.797869 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.262505 (* 1 = 0.262505 loss)
I1005 22:35:23.919723 10142 solver.cpp:218] Iteration 43500 (5.18773 iter/s, 19.2763s/100 iters), loss = 0.0450158
I1005 22:35:23.919764 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0450155 (* 1 = 0.0450155 loss)
I1005 22:35:23.919770 10142 sgd_solver.cpp:105] Iteration 43500, lr = 0.01
I1005 22:35:39.794389 10142 solver.cpp:218] Iteration 43600 (6.29939 iter/s, 15.8746s/100 iters), loss = 0.126596
I1005 22:35:39.794525 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.126596 (* 1 = 0.126596 loss)
I1005 22:35:39.794534 10142 sgd_solver.cpp:105] Iteration 43600, lr = 0.01
I1005 22:35:55.662725 10142 solver.cpp:218] Iteration 43700 (6.30276 iter/s, 15.8661s/100 iters), loss = 0.0720308
I1005 22:35:55.662767 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0720305 (* 1 = 0.0720305 loss)
I1005 22:35:55.662775 10142 sgd_solver.cpp:105] Iteration 43700, lr = 0.01
I1005 22:36:11.512219 10142 solver.cpp:218] Iteration 43800 (6.31023 iter/s, 15.8473s/100 iters), loss = 0.0472607
I1005 22:36:11.512291 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0472605 (* 1 = 0.0472605 loss)
I1005 22:36:11.512300 10142 sgd_solver.cpp:105] Iteration 43800, lr = 0.01
I1005 22:36:27.463835 10142 solver.cpp:218] Iteration 43900 (6.26901 iter/s, 15.9515s/100 iters), loss = 0.0398364
I1005 22:36:27.463878 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0398361 (* 1 = 0.0398361 loss)
I1005 22:36:27.463886 10142 sgd_solver.cpp:105] Iteration 43900, lr = 0.01
I1005 22:36:42.545162 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 22:36:43.179177 10142 solver.cpp:330] Iteration 44000, Testing net (#0)
I1005 22:36:46.407856 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 22:36:46.535357 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9156
I1005 22:36:46.535392 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.270162 (* 1 = 0.270162 loss)
I1005 22:36:46.666370 10142 solver.cpp:218] Iteration 44000 (5.20768 iter/s, 19.2024s/100 iters), loss = 0.0668545
I1005 22:36:46.666414 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0668543 (* 1 = 0.0668543 loss)
I1005 22:36:46.666420 10142 sgd_solver.cpp:105] Iteration 44000, lr = 0.01
I1005 22:37:02.518255 10142 solver.cpp:218] Iteration 44100 (6.30844 iter/s, 15.8518s/100 iters), loss = 0.0968187
I1005 22:37:02.518307 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0968184 (* 1 = 0.0968184 loss)
I1005 22:37:02.518313 10142 sgd_solver.cpp:105] Iteration 44100, lr = 0.01
I1005 22:37:18.451417 10142 solver.cpp:218] Iteration 44200 (6.27627 iter/s, 15.933s/100 iters), loss = 0.0803702
I1005 22:37:18.451519 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0803699 (* 1 = 0.0803699 loss)
I1005 22:37:18.451529 10142 sgd_solver.cpp:105] Iteration 44200, lr = 0.01
I1005 22:37:34.306911 10142 solver.cpp:218] Iteration 44300 (6.30787 iter/s, 15.8532s/100 iters), loss = 0.0761492
I1005 22:37:34.306953 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.076149 (* 1 = 0.076149 loss)
I1005 22:37:34.306960 10142 sgd_solver.cpp:105] Iteration 44300, lr = 0.01
I1005 22:37:50.159457 10142 solver.cpp:218] Iteration 44400 (6.30818 iter/s, 15.8524s/100 iters), loss = 0.0132099
I1005 22:37:50.159557 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0132096 (* 1 = 0.0132096 loss)
I1005 22:37:50.159579 10142 sgd_solver.cpp:105] Iteration 44400, lr = 0.01
I1005 22:38:05.280434 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 22:38:05.899497 10142 solver.cpp:330] Iteration 44500, Testing net (#0)
I1005 22:38:09.159152 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 22:38:09.291628 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9172
I1005 22:38:09.291657 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.264861 (* 1 = 0.264861 loss)
I1005 22:38:09.415662 10142 solver.cpp:218] Iteration 44500 (5.19374 iter/s, 19.254s/100 iters), loss = 0.0775318
I1005 22:38:09.415702 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0775315 (* 1 = 0.0775315 loss)
I1005 22:38:09.415722 10142 sgd_solver.cpp:105] Iteration 44500, lr = 0.01
I1005 22:38:25.271097 10142 solver.cpp:218] Iteration 44600 (6.30703 iter/s, 15.8553s/100 iters), loss = 0.074055
I1005 22:38:25.271224 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0740547 (* 1 = 0.0740547 loss)
I1005 22:38:25.271237 10142 sgd_solver.cpp:105] Iteration 44600, lr = 0.01
I1005 22:38:41.138089 10142 solver.cpp:218] Iteration 44700 (6.3033 iter/s, 15.8647s/100 iters), loss = 0.0327053
I1005 22:38:41.138130 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.032705 (* 1 = 0.032705 loss)
I1005 22:38:41.138136 10142 sgd_solver.cpp:105] Iteration 44700, lr = 0.01
I1005 22:38:57.000433 10142 solver.cpp:218] Iteration 44800 (6.30428 iter/s, 15.8622s/100 iters), loss = 0.0558845
I1005 22:38:57.000548 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0558843 (* 1 = 0.0558843 loss)
I1005 22:38:57.000556 10142 sgd_solver.cpp:105] Iteration 44800, lr = 0.01
I1005 22:39:12.921034 10142 solver.cpp:218] Iteration 44900 (6.28204 iter/s, 15.9184s/100 iters), loss = 0.0453732
I1005 22:39:12.921075 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.045373 (* 1 = 0.045373 loss)
I1005 22:39:12.921082 10142 sgd_solver.cpp:105] Iteration 44900, lr = 0.01
I1005 22:39:28.062243 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 22:39:28.665908 10142 solver.cpp:330] Iteration 45000, Testing net (#0)
I1005 22:39:31.881549 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 22:39:32.009186 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9191
I1005 22:39:32.009222 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.262589 (* 1 = 0.262589 loss)
I1005 22:39:32.140806 10142 solver.cpp:218] Iteration 45000 (5.20301 iter/s, 19.2197s/100 iters), loss = 0.0223294
I1005 22:39:32.140851 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0223292 (* 1 = 0.0223292 loss)
I1005 22:39:32.140858 10142 sgd_solver.cpp:105] Iteration 45000, lr = 0.01
I1005 22:39:48.008635 10142 solver.cpp:218] Iteration 45100 (6.3021 iter/s, 15.8677s/100 iters), loss = 0.0568188
I1005 22:39:48.008679 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0568186 (* 1 = 0.0568186 loss)
I1005 22:39:48.008687 10142 sgd_solver.cpp:105] Iteration 45100, lr = 0.01
I1005 22:40:03.940812 10142 solver.cpp:218] Iteration 45200 (6.27665 iter/s, 15.9321s/100 iters), loss = 0.0312041
I1005 22:40:03.940883 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0312039 (* 1 = 0.0312039 loss)
I1005 22:40:03.940891 10142 sgd_solver.cpp:105] Iteration 45200, lr = 0.01
I1005 22:40:19.778098 10142 solver.cpp:218] Iteration 45300 (6.31427 iter/s, 15.8372s/100 iters), loss = 0.0787946
I1005 22:40:19.778129 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0787944 (* 1 = 0.0787944 loss)
I1005 22:40:19.778136 10142 sgd_solver.cpp:105] Iteration 45300, lr = 0.01
I1005 22:40:35.624897 10142 solver.cpp:218] Iteration 45400 (6.31046 iter/s, 15.8467s/100 iters), loss = 0.0308498
I1005 22:40:35.624979 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0308496 (* 1 = 0.0308496 loss)
I1005 22:40:35.624987 10142 sgd_solver.cpp:105] Iteration 45400, lr = 0.01
I1005 22:40:50.730901 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 22:40:51.339534 10142 solver.cpp:330] Iteration 45500, Testing net (#0)
I1005 22:40:54.596498 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 22:40:54.725373 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9153
I1005 22:40:54.725407 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.273706 (* 1 = 0.273706 loss)
I1005 22:40:54.854831 10142 solver.cpp:218] Iteration 45500 (5.20027 iter/s, 19.2298s/100 iters), loss = 0.0277583
I1005 22:40:54.854872 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0277581 (* 1 = 0.0277581 loss)
I1005 22:40:54.854879 10142 sgd_solver.cpp:105] Iteration 45500, lr = 0.01
I1005 22:41:10.704556 10142 solver.cpp:218] Iteration 45600 (6.3093 iter/s, 15.8496s/100 iters), loss = 0.0634253
I1005 22:41:10.704681 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0634251 (* 1 = 0.0634251 loss)
I1005 22:41:10.704699 10142 sgd_solver.cpp:105] Iteration 45600, lr = 0.01
I1005 22:41:26.555673 10142 solver.cpp:218] Iteration 45700 (6.30878 iter/s, 15.8509s/100 iters), loss = 0.0647443
I1005 22:41:26.555704 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0647441 (* 1 = 0.0647441 loss)
I1005 22:41:26.555721 10142 sgd_solver.cpp:105] Iteration 45700, lr = 0.01
I1005 22:41:42.405635 10142 solver.cpp:218] Iteration 45800 (6.3092 iter/s, 15.8499s/100 iters), loss = 0.0469085
I1005 22:41:42.405766 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0469083 (* 1 = 0.0469083 loss)
I1005 22:41:42.405784 10142 sgd_solver.cpp:105] Iteration 45800, lr = 0.01
I1005 22:41:58.325415 10142 solver.cpp:218] Iteration 45900 (6.28157 iter/s, 15.9196s/100 iters), loss = 0.027807
I1005 22:41:58.325450 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0278069 (* 1 = 0.0278069 loss)
I1005 22:41:58.325469 10142 sgd_solver.cpp:105] Iteration 45900, lr = 0.01
I1005 22:42:13.456707 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 22:42:14.063238 10142 solver.cpp:330] Iteration 46000, Testing net (#0)
I1005 22:42:17.275691 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 22:42:17.406083 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9211
I1005 22:42:17.406111 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.26357 (* 1 = 0.26357 loss)
I1005 22:42:17.535527 10142 solver.cpp:218] Iteration 46000 (5.20562 iter/s, 19.21s/100 iters), loss = 0.0249082
I1005 22:42:17.535571 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.024908 (* 1 = 0.024908 loss)
I1005 22:42:17.535578 10142 sgd_solver.cpp:105] Iteration 46000, lr = 0.01
I1005 22:42:33.397418 10142 solver.cpp:218] Iteration 46100 (6.30446 iter/s, 15.8618s/100 iters), loss = 0.048926
I1005 22:42:33.397464 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0489258 (* 1 = 0.0489258 loss)
I1005 22:42:33.397472 10142 sgd_solver.cpp:105] Iteration 46100, lr = 0.01
I1005 22:42:49.304875 10142 solver.cpp:218] Iteration 46200 (6.2864 iter/s, 15.9073s/100 iters), loss = 0.036579
I1005 22:42:49.305013 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0365788 (* 1 = 0.0365788 loss)
I1005 22:42:49.305022 10142 sgd_solver.cpp:105] Iteration 46200, lr = 0.01
I1005 22:43:05.169107 10142 solver.cpp:218] Iteration 46300 (6.30357 iter/s, 15.864s/100 iters), loss = 0.021251
I1005 22:43:05.169138 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0212508 (* 1 = 0.0212508 loss)
I1005 22:43:05.169145 10142 sgd_solver.cpp:105] Iteration 46300, lr = 0.01
I1005 22:43:21.031122 10142 solver.cpp:218] Iteration 46400 (6.30441 iter/s, 15.8619s/100 iters), loss = 0.0219085
I1005 22:43:21.031277 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0219083 (* 1 = 0.0219083 loss)
I1005 22:43:21.031287 10142 sgd_solver.cpp:105] Iteration 46400, lr = 0.01
I1005 22:43:36.129271 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 22:43:36.766769 10142 solver.cpp:330] Iteration 46500, Testing net (#0)
I1005 22:43:39.974378 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 22:43:40.107496 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9179
I1005 22:43:40.107542 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.272889 (* 1 = 0.272889 loss)
I1005 22:43:40.235751 10142 solver.cpp:218] Iteration 46500 (5.20714 iter/s, 19.2044s/100 iters), loss = 0.05193
I1005 22:43:40.235795 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0519298 (* 1 = 0.0519298 loss)
I1005 22:43:40.235802 10142 sgd_solver.cpp:105] Iteration 46500, lr = 0.01
I1005 22:43:56.154266 10142 solver.cpp:218] Iteration 46600 (6.28257 iter/s, 15.9171s/100 iters), loss = 0.0226822
I1005 22:43:56.154369 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.022682 (* 1 = 0.022682 loss)
I1005 22:43:56.154377 10142 sgd_solver.cpp:105] Iteration 46600, lr = 0.01
I1005 22:44:12.020853 10142 solver.cpp:218] Iteration 46700 (6.30262 iter/s, 15.8664s/100 iters), loss = 0.0783153
I1005 22:44:12.020895 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0783151 (* 1 = 0.0783151 loss)
I1005 22:44:12.020902 10142 sgd_solver.cpp:105] Iteration 46700, lr = 0.01
I1005 22:44:27.876698 10142 solver.cpp:218] Iteration 46800 (6.30686 iter/s, 15.8557s/100 iters), loss = 0.068349
I1005 22:44:27.876793 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0683488 (* 1 = 0.0683488 loss)
I1005 22:44:27.876811 10142 sgd_solver.cpp:105] Iteration 46800, lr = 0.01
I1005 22:44:43.796067 10142 solver.cpp:218] Iteration 46900 (6.28171 iter/s, 15.9192s/100 iters), loss = 0.033006
I1005 22:44:43.796108 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0330058 (* 1 = 0.0330058 loss)
I1005 22:44:43.796113 10142 sgd_solver.cpp:105] Iteration 46900, lr = 0.01
I1005 22:44:58.925253 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 22:44:59.531559 10142 solver.cpp:330] Iteration 47000, Testing net (#0)
I1005 22:45:02.745642 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 22:45:02.873693 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9139
I1005 22:45:02.873718 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.288492 (* 1 = 0.288492 loss)
I1005 22:45:03.005604 10142 solver.cpp:218] Iteration 47000 (5.20578 iter/s, 19.2094s/100 iters), loss = 0.0104434
I1005 22:45:03.005671 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0104432 (* 1 = 0.0104432 loss)
I1005 22:45:03.005693 10142 sgd_solver.cpp:105] Iteration 47000, lr = 0.01
I1005 22:45:18.874663 10142 solver.cpp:218] Iteration 47100 (6.30162 iter/s, 15.8689s/100 iters), loss = 0.049603
I1005 22:45:18.874698 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0496028 (* 1 = 0.0496028 loss)
I1005 22:45:18.874716 10142 sgd_solver.cpp:105] Iteration 47100, lr = 0.01
I1005 22:45:34.787309 10142 solver.cpp:218] Iteration 47200 (6.28435 iter/s, 15.9125s/100 iters), loss = 0.0221645
I1005 22:45:34.787380 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0221644 (* 1 = 0.0221644 loss)
I1005 22:45:34.787390 10142 sgd_solver.cpp:105] Iteration 47200, lr = 0.01
I1005 22:45:50.637213 10142 solver.cpp:218] Iteration 47300 (6.31007 iter/s, 15.8477s/100 iters), loss = 0.0293683
I1005 22:45:50.637244 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0293681 (* 1 = 0.0293681 loss)
I1005 22:45:50.637261 10142 sgd_solver.cpp:105] Iteration 47300, lr = 0.01
I1005 22:46:06.497265 10142 solver.cpp:218] Iteration 47400 (6.30519 iter/s, 15.86s/100 iters), loss = 0.0220445
I1005 22:46:06.497375 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0220443 (* 1 = 0.0220443 loss)
I1005 22:46:06.497385 10142 sgd_solver.cpp:105] Iteration 47400, lr = 0.01
I1005 22:46:21.626853 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 22:46:22.228945 10142 solver.cpp:330] Iteration 47500, Testing net (#0)
I1005 22:46:25.441998 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 22:46:25.577668 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9191
I1005 22:46:25.577695 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.275482 (* 1 = 0.275482 loss)
I1005 22:46:25.700448 10142 solver.cpp:218] Iteration 47500 (5.2076 iter/s, 19.2027s/100 iters), loss = 0.0306537
I1005 22:46:25.700487 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0306535 (* 1 = 0.0306535 loss)
I1005 22:46:25.700495 10142 sgd_solver.cpp:105] Iteration 47500, lr = 0.01
I1005 22:46:41.602305 10142 solver.cpp:218] Iteration 47600 (6.28861 iter/s, 15.9018s/100 iters), loss = 0.055243
I1005 22:46:41.602422 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0552427 (* 1 = 0.0552427 loss)
I1005 22:46:41.602432 10142 sgd_solver.cpp:105] Iteration 47600, lr = 0.01
I1005 22:46:57.451702 10142 solver.cpp:218] Iteration 47700 (6.30946 iter/s, 15.8492s/100 iters), loss = 0.0345225
I1005 22:46:57.451751 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0345223 (* 1 = 0.0345223 loss)
I1005 22:46:57.451759 10142 sgd_solver.cpp:105] Iteration 47700, lr = 0.01
I1005 22:47:13.283553 10142 solver.cpp:218] Iteration 47800 (6.31643 iter/s, 15.8317s/100 iters), loss = 0.0580291
I1005 22:47:13.283651 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.058029 (* 1 = 0.058029 loss)
I1005 22:47:13.283659 10142 sgd_solver.cpp:105] Iteration 47800, lr = 0.01
I1005 22:47:29.254839 10142 solver.cpp:218] Iteration 47900 (6.2613 iter/s, 15.9711s/100 iters), loss = 0.0270679
I1005 22:47:29.254876 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0270677 (* 1 = 0.0270677 loss)
I1005 22:47:29.254889 10142 sgd_solver.cpp:105] Iteration 47900, lr = 0.01
I1005 22:47:44.368695 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 22:47:44.969861 10142 solver.cpp:330] Iteration 48000, Testing net (#0)
I1005 22:47:48.153573 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 22:47:48.288851 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9141
I1005 22:47:48.288893 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.290509 (* 1 = 0.290509 loss)
I1005 22:47:48.400256 10142 solver.cpp:218] Iteration 48000 (5.22378 iter/s, 19.1432s/100 iters), loss = 0.00813346
I1005 22:47:48.400295 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00813327 (* 1 = 0.00813327 loss)
I1005 22:47:48.400303 10142 sgd_solver.cpp:105] Iteration 48000, lr = 0.01
I1005 22:48:04.257737 10142 solver.cpp:218] Iteration 48100 (6.30706 iter/s, 15.8553s/100 iters), loss = 0.040491
I1005 22:48:04.257769 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0404908 (* 1 = 0.0404908 loss)
I1005 22:48:04.257776 10142 sgd_solver.cpp:105] Iteration 48100, lr = 0.01
I1005 22:48:20.197640 10142 solver.cpp:218] Iteration 48200 (6.2736 iter/s, 15.9398s/100 iters), loss = 0.0476227
I1005 22:48:20.197751 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0476225 (* 1 = 0.0476225 loss)
I1005 22:48:20.197762 10142 sgd_solver.cpp:105] Iteration 48200, lr = 0.01
I1005 22:48:36.029553 10142 solver.cpp:218] Iteration 48300 (6.31642 iter/s, 15.8317s/100 iters), loss = 0.0355319
I1005 22:48:36.029597 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0355318 (* 1 = 0.0355318 loss)
I1005 22:48:36.029603 10142 sgd_solver.cpp:105] Iteration 48300, lr = 0.01
I1005 22:48:51.887642 10142 solver.cpp:218] Iteration 48400 (6.30597 iter/s, 15.858s/100 iters), loss = 0.00805424
I1005 22:48:51.887735 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00805407 (* 1 = 0.00805407 loss)
I1005 22:48:51.887754 10142 sgd_solver.cpp:105] Iteration 48400, lr = 0.01
I1005 22:49:06.974442 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 22:49:07.605881 10142 solver.cpp:330] Iteration 48500, Testing net (#0)
I1005 22:49:10.801538 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 22:49:10.934376 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9195
I1005 22:49:10.934412 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.273456 (* 1 = 0.273456 loss)
I1005 22:49:11.044123 10142 solver.cpp:218] Iteration 48500 (5.22021 iter/s, 19.1563s/100 iters), loss = 0.0346164
I1005 22:49:11.044162 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0346162 (* 1 = 0.0346162 loss)
I1005 22:49:11.044183 10142 sgd_solver.cpp:105] Iteration 48500, lr = 0.01
I1005 22:49:27.002964 10142 solver.cpp:218] Iteration 48600 (6.26699 iter/s, 15.9566s/100 iters), loss = 0.0491252
I1005 22:49:27.003080 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0491251 (* 1 = 0.0491251 loss)
I1005 22:49:27.003088 10142 sgd_solver.cpp:105] Iteration 48600, lr = 0.01
I1005 22:49:42.863785 10142 solver.cpp:218] Iteration 48700 (6.30491 iter/s, 15.8607s/100 iters), loss = 0.0267839
I1005 22:49:42.863827 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0267837 (* 1 = 0.0267837 loss)
I1005 22:49:42.863833 10142 sgd_solver.cpp:105] Iteration 48700, lr = 0.01
I1005 22:49:58.722378 10142 solver.cpp:218] Iteration 48800 (6.30577 iter/s, 15.8585s/100 iters), loss = 0.0450205
I1005 22:49:58.722476 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0450203 (* 1 = 0.0450203 loss)
I1005 22:49:58.722496 10142 sgd_solver.cpp:105] Iteration 48800, lr = 0.01
I1005 22:50:14.621124 10142 solver.cpp:218] Iteration 48900 (6.28986 iter/s, 15.8986s/100 iters), loss = 0.0178914
I1005 22:50:14.621165 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0178912 (* 1 = 0.0178912 loss)
I1005 22:50:14.621175 10142 sgd_solver.cpp:105] Iteration 48900, lr = 0.01
I1005 22:50:29.716994 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 22:50:30.323334 10142 solver.cpp:330] Iteration 49000, Testing net (#0)
I1005 22:50:33.536746 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 22:50:33.664634 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9186
I1005 22:50:33.664661 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.284142 (* 1 = 0.284142 loss)
I1005 22:50:33.795809 10142 solver.cpp:218] Iteration 49000 (5.21524 iter/s, 19.1746s/100 iters), loss = 0.0561343
I1005 22:50:33.795852 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0561341 (* 1 = 0.0561341 loss)
I1005 22:50:33.795859 10142 sgd_solver.cpp:105] Iteration 49000, lr = 0.01
I1005 22:50:49.633764 10142 solver.cpp:218] Iteration 49100 (6.31399 iter/s, 15.8378s/100 iters), loss = 0.0685782
I1005 22:50:49.633796 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.068578 (* 1 = 0.068578 loss)
I1005 22:50:49.633813 10142 sgd_solver.cpp:105] Iteration 49100, lr = 0.01
I1005 22:51:05.520735 10142 solver.cpp:218] Iteration 49200 (6.2945 iter/s, 15.8869s/100 iters), loss = 0.0241532
I1005 22:51:05.520822 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0241531 (* 1 = 0.0241531 loss)
I1005 22:51:05.520831 10142 sgd_solver.cpp:105] Iteration 49200, lr = 0.01
I1005 22:51:21.400940 10142 solver.cpp:218] Iteration 49300 (6.29802 iter/s, 15.878s/100 iters), loss = 0.0372709
I1005 22:51:21.400981 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0372707 (* 1 = 0.0372707 loss)
I1005 22:51:21.401010 10142 sgd_solver.cpp:105] Iteration 49300, lr = 0.01
I1005 22:51:37.254297 10142 solver.cpp:218] Iteration 49400 (6.3087 iter/s, 15.8511s/100 iters), loss = 0.0140789
I1005 22:51:37.254390 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0140788 (* 1 = 0.0140788 loss)
I1005 22:51:37.254398 10142 sgd_solver.cpp:105] Iteration 49400, lr = 0.01
I1005 22:51:52.390439 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 22:51:52.994240 10142 solver.cpp:330] Iteration 49500, Testing net (#0)
I1005 22:51:56.203246 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 22:51:56.331230 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9199
I1005 22:51:56.331255 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.285981 (* 1 = 0.285981 loss)
I1005 22:51:56.462203 10142 solver.cpp:218] Iteration 49500 (5.20681 iter/s, 19.2056s/100 iters), loss = 0.050636
I1005 22:51:56.462247 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0506359 (* 1 = 0.0506359 loss)
I1005 22:51:56.462255 10142 sgd_solver.cpp:105] Iteration 49500, lr = 0.01
I1005 22:52:12.421033 10142 solver.cpp:218] Iteration 49600 (6.26617 iter/s, 15.9587s/100 iters), loss = 0.0513359
I1005 22:52:12.421175 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0513357 (* 1 = 0.0513357 loss)
I1005 22:52:12.421185 10142 sgd_solver.cpp:105] Iteration 49600, lr = 0.01
I1005 22:52:28.293941 10142 solver.cpp:218] Iteration 49700 (6.30013 iter/s, 15.8727s/100 iters), loss = 0.0756985
I1005 22:52:28.293980 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0756984 (* 1 = 0.0756984 loss)
I1005 22:52:28.293987 10142 sgd_solver.cpp:105] Iteration 49700, lr = 0.01
I1005 22:52:44.147300 10142 solver.cpp:218] Iteration 49800 (6.30785 iter/s, 15.8533s/100 iters), loss = 0.0216211
I1005 22:52:44.147382 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0216209 (* 1 = 0.0216209 loss)
I1005 22:52:44.147388 10142 sgd_solver.cpp:105] Iteration 49800, lr = 0.01
I1005 22:53:00.077234 10142 solver.cpp:218] Iteration 49900 (6.27755 iter/s, 15.9298s/100 iters), loss = 0.0188371
I1005 22:53:00.077276 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0188369 (* 1 = 0.0188369 loss)
I1005 22:53:00.077283 10142 sgd_solver.cpp:105] Iteration 49900, lr = 0.01
I1005 22:53:15.230919 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 22:53:15.843204 10142 solver.cpp:330] Iteration 50000, Testing net (#0)
I1005 22:53:19.060183 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 22:53:19.192785 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9159
I1005 22:53:19.192821 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.301992 (* 1 = 0.301992 loss)
I1005 22:53:19.317857 10142 solver.cpp:218] Iteration 50000 (5.19793 iter/s, 19.2384s/100 iters), loss = 0.0465916
I1005 22:53:19.317901 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0465914 (* 1 = 0.0465914 loss)
I1005 22:53:19.317908 10142 sgd_solver.cpp:105] Iteration 50000, lr = 0.01
I1005 22:53:35.189893 10142 solver.cpp:218] Iteration 50100 (6.30043 iter/s, 15.8719s/100 iters), loss = 0.0145531
I1005 22:53:35.189924 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.014553 (* 1 = 0.014553 loss)
I1005 22:53:35.189941 10142 sgd_solver.cpp:105] Iteration 50100, lr = 0.01
I1005 22:53:51.064097 10142 solver.cpp:218] Iteration 50200 (6.29957 iter/s, 15.8741s/100 iters), loss = 0.0113532
I1005 22:53:51.064190 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.011353 (* 1 = 0.011353 loss)
I1005 22:53:51.064199 10142 sgd_solver.cpp:105] Iteration 50200, lr = 0.01
I1005 22:54:06.986615 10142 solver.cpp:218] Iteration 50300 (6.2813 iter/s, 15.9203s/100 iters), loss = 0.0440939
I1005 22:54:06.986649 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0440937 (* 1 = 0.0440937 loss)
I1005 22:54:06.986656 10142 sgd_solver.cpp:105] Iteration 50300, lr = 0.01
I1005 22:54:22.842728 10142 solver.cpp:218] Iteration 50400 (6.30675 iter/s, 15.856s/100 iters), loss = 0.0104765
I1005 22:54:22.842826 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0104763 (* 1 = 0.0104763 loss)
I1005 22:54:22.842844 10142 sgd_solver.cpp:105] Iteration 50400, lr = 0.01
I1005 22:54:37.949522 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 22:54:38.582244 10142 solver.cpp:330] Iteration 50500, Testing net (#0)
I1005 22:54:41.804675 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 22:54:41.941123 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9136
I1005 22:54:41.941160 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.312421 (* 1 = 0.312421 loss)
I1005 22:54:42.042313 10142 solver.cpp:218] Iteration 50500 (5.20849 iter/s, 19.1994s/100 iters), loss = 0.0103491
I1005 22:54:42.042356 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0103489 (* 1 = 0.0103489 loss)
I1005 22:54:42.042363 10142 sgd_solver.cpp:105] Iteration 50500, lr = 0.01
I1005 22:54:57.990197 10142 solver.cpp:218] Iteration 50600 (6.27129 iter/s, 15.9457s/100 iters), loss = 0.0343359
I1005 22:54:57.990325 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0343358 (* 1 = 0.0343358 loss)
I1005 22:54:57.990346 10142 sgd_solver.cpp:105] Iteration 50600, lr = 0.01
I1005 22:55:13.855094 10142 solver.cpp:218] Iteration 50700 (6.3033 iter/s, 15.8647s/100 iters), loss = 0.0412371
I1005 22:55:13.855129 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.041237 (* 1 = 0.041237 loss)
I1005 22:55:13.855139 10142 sgd_solver.cpp:105] Iteration 50700, lr = 0.01
I1005 22:55:29.719553 10142 solver.cpp:218] Iteration 50800 (6.30344 iter/s, 15.8644s/100 iters), loss = 0.0393394
I1005 22:55:29.719651 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0393393 (* 1 = 0.0393393 loss)
I1005 22:55:29.719669 10142 sgd_solver.cpp:105] Iteration 50800, lr = 0.01
I1005 22:55:45.643532 10142 solver.cpp:218] Iteration 50900 (6.2799 iter/s, 15.9238s/100 iters), loss = 0.0219172
I1005 22:55:45.643576 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.021917 (* 1 = 0.021917 loss)
I1005 22:55:45.643584 10142 sgd_solver.cpp:105] Iteration 50900, lr = 0.01
I1005 22:56:00.757747 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 22:56:01.370157 10142 solver.cpp:330] Iteration 51000, Testing net (#0)
I1005 22:56:04.607596 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 22:56:04.740751 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9179
I1005 22:56:04.740779 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.293631 (* 1 = 0.293631 loss)
I1005 22:56:04.851631 10142 solver.cpp:218] Iteration 51000 (5.20617 iter/s, 19.208s/100 iters), loss = 0.0456959
I1005 22:56:04.851673 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0456957 (* 1 = 0.0456957 loss)
I1005 22:56:04.851680 10142 sgd_solver.cpp:105] Iteration 51000, lr = 0.01
I1005 22:56:20.697188 10142 solver.cpp:218] Iteration 51100 (6.31179 iter/s, 15.8434s/100 iters), loss = 0.0347091
I1005 22:56:20.697221 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0347089 (* 1 = 0.0347089 loss)
I1005 22:56:20.697227 10142 sgd_solver.cpp:105] Iteration 51100, lr = 0.01
I1005 22:56:36.544251 10142 solver.cpp:218] Iteration 51200 (6.31036 iter/s, 15.847s/100 iters), loss = 0.0301267
I1005 22:56:36.544361 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0301266 (* 1 = 0.0301266 loss)
I1005 22:56:36.544370 10142 sgd_solver.cpp:105] Iteration 51200, lr = 0.01
I1005 22:56:45.928724 10142 solver.cpp:218] Iteration 51300 (10.6561 iter/s, 9.38431s/100 iters), loss = 0.0233134
I1005 22:56:45.928766 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0233133 (* 1 = 0.0233133 loss)
I1005 22:56:45.928773 10142 sgd_solver.cpp:105] Iteration 51300, lr = 0.01
I1005 22:56:53.571341 10142 solver.cpp:218] Iteration 51400 (13.0846 iter/s, 7.64255s/100 iters), loss = 0.0224343
I1005 22:56:53.571375 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0224342 (* 1 = 0.0224342 loss)
I1005 22:56:53.571382 10142 sgd_solver.cpp:105] Iteration 51400, lr = 0.01
I1005 22:57:00.860800 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 22:57:01.167196 10142 solver.cpp:330] Iteration 51500, Testing net (#0)
I1005 22:57:02.906374 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 22:57:02.979739 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9155
I1005 22:57:02.979773 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.307214 (* 1 = 0.307214 loss)
I1005 22:57:03.056367 10142 solver.cpp:218] Iteration 51500 (10.543 iter/s, 9.48497s/100 iters), loss = 0.0298094
I1005 22:57:03.056406 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0298092 (* 1 = 0.0298092 loss)
I1005 22:57:03.056423 10142 sgd_solver.cpp:105] Iteration 51500, lr = 0.01
I1005 22:57:10.720998 10142 solver.cpp:218] Iteration 51600 (13.0471 iter/s, 7.66457s/100 iters), loss = 0.024051
I1005 22:57:10.721160 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0240509 (* 1 = 0.0240509 loss)
I1005 22:57:10.721170 10142 sgd_solver.cpp:105] Iteration 51600, lr = 0.01
I1005 22:57:18.377403 10142 solver.cpp:218] Iteration 51700 (13.0613 iter/s, 7.65623s/100 iters), loss = 0.0147754
I1005 22:57:18.377440 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0147753 (* 1 = 0.0147753 loss)
I1005 22:57:18.377449 10142 sgd_solver.cpp:105] Iteration 51700, lr = 0.01
I1005 22:57:26.034602 10142 solver.cpp:218] Iteration 51800 (13.0597 iter/s, 7.65714s/100 iters), loss = 0.0194464
I1005 22:57:26.034632 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0194463 (* 1 = 0.0194463 loss)
I1005 22:57:26.034647 10142 sgd_solver.cpp:105] Iteration 51800, lr = 0.01
I1005 22:57:33.680536 10142 solver.cpp:218] Iteration 51900 (13.0789 iter/s, 7.64588s/100 iters), loss = 0.026439
I1005 22:57:33.680568 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0264388 (* 1 = 0.0264388 loss)
I1005 22:57:33.680575 10142 sgd_solver.cpp:105] Iteration 51900, lr = 0.01
I1005 22:57:40.946247 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 22:57:41.253099 10142 solver.cpp:330] Iteration 52000, Testing net (#0)
I1005 22:57:43.001243 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 22:57:43.074676 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9175
I1005 22:57:43.074702 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.298961 (* 1 = 0.298961 loss)
I1005 22:57:43.151422 10142 solver.cpp:218] Iteration 52000 (10.5587 iter/s, 9.47083s/100 iters), loss = 0.0101534
I1005 22:57:43.151454 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0101532 (* 1 = 0.0101532 loss)
I1005 22:57:43.151461 10142 sgd_solver.cpp:105] Iteration 52000, lr = 0.01
I1005 22:57:50.808634 10142 solver.cpp:218] Iteration 52100 (13.0597 iter/s, 7.65716s/100 iters), loss = 0.0694847
I1005 22:57:50.808665 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0694845 (* 1 = 0.0694845 loss)
I1005 22:57:50.808681 10142 sgd_solver.cpp:105] Iteration 52100, lr = 0.01
I1005 22:57:58.469101 10142 solver.cpp:218] Iteration 52200 (13.0541 iter/s, 7.66041s/100 iters), loss = 0.0307665
I1005 22:57:58.469130 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0307663 (* 1 = 0.0307663 loss)
I1005 22:57:58.469136 10142 sgd_solver.cpp:105] Iteration 52200, lr = 0.01
I1005 22:58:06.126081 10142 solver.cpp:218] Iteration 52300 (13.0601 iter/s, 7.65693s/100 iters), loss = 0.0187192
I1005 22:58:06.126112 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.018719 (* 1 = 0.018719 loss)
I1005 22:58:06.126118 10142 sgd_solver.cpp:105] Iteration 52300, lr = 0.01
I1005 22:58:13.772104 10142 solver.cpp:218] Iteration 52400 (13.0788 iter/s, 7.64597s/100 iters), loss = 0.00441272
I1005 22:58:13.772208 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00441256 (* 1 = 0.00441256 loss)
I1005 22:58:13.772215 10142 sgd_solver.cpp:105] Iteration 52400, lr = 0.01
I1005 22:58:21.047087 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 22:58:21.354735 10142 solver.cpp:330] Iteration 52500, Testing net (#0)
I1005 22:58:23.098695 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 22:58:23.172256 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9172
I1005 22:58:23.172291 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.304973 (* 1 = 0.304973 loss)
I1005 22:58:23.249331 10142 solver.cpp:218] Iteration 52500 (10.5517 iter/s, 9.4771s/100 iters), loss = 0.0219244
I1005 22:58:23.249361 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0219242 (* 1 = 0.0219242 loss)
I1005 22:58:23.249367 10142 sgd_solver.cpp:105] Iteration 52500, lr = 0.01
I1005 22:58:30.909890 10142 solver.cpp:218] Iteration 52600 (13.054 iter/s, 7.66051s/100 iters), loss = 0.0593514
I1005 22:58:30.909922 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0593512 (* 1 = 0.0593512 loss)
I1005 22:58:30.909929 10142 sgd_solver.cpp:105] Iteration 52600, lr = 0.01
I1005 22:58:38.561529 10142 solver.cpp:218] Iteration 52700 (13.0692 iter/s, 7.65159s/100 iters), loss = 0.0402621
I1005 22:58:38.561558 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.040262 (* 1 = 0.040262 loss)
I1005 22:58:38.561564 10142 sgd_solver.cpp:105] Iteration 52700, lr = 0.01
I1005 22:58:46.222355 10142 solver.cpp:218] Iteration 52800 (13.0535 iter/s, 7.66078s/100 iters), loss = 0.0660306
I1005 22:58:46.222530 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0660305 (* 1 = 0.0660305 loss)
I1005 22:58:46.222550 10142 sgd_solver.cpp:105] Iteration 52800, lr = 0.01
I1005 22:58:53.871372 10142 solver.cpp:218] Iteration 52900 (13.0739 iter/s, 7.64883s/100 iters), loss = 0.00886061
I1005 22:58:53.871402 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00886046 (* 1 = 0.00886046 loss)
I1005 22:58:53.871408 10142 sgd_solver.cpp:105] Iteration 52900, lr = 0.01
I1005 22:59:01.146865 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 22:59:01.452900 10142 solver.cpp:330] Iteration 53000, Testing net (#0)
I1005 22:59:03.193439 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 22:59:03.266804 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9189
I1005 22:59:03.266840 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.295534 (* 1 = 0.295534 loss)
I1005 22:59:03.345453 10142 solver.cpp:218] Iteration 53000 (10.5552 iter/s, 9.47403s/100 iters), loss = 0.0216386
I1005 22:59:03.345489 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0216385 (* 1 = 0.0216385 loss)
I1005 22:59:03.345495 10142 sgd_solver.cpp:105] Iteration 53000, lr = 0.01
I1005 22:59:10.996019 10142 solver.cpp:218] Iteration 53100 (13.071 iter/s, 7.65051s/100 iters), loss = 0.0122776
I1005 22:59:10.996060 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0122774 (* 1 = 0.0122774 loss)
I1005 22:59:10.996067 10142 sgd_solver.cpp:105] Iteration 53100, lr = 0.01
I1005 22:59:18.656793 10142 solver.cpp:218] Iteration 53200 (13.0536 iter/s, 7.66071s/100 iters), loss = 0.0255439
I1005 22:59:18.656951 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0255437 (* 1 = 0.0255437 loss)
I1005 22:59:18.656960 10142 sgd_solver.cpp:105] Iteration 53200, lr = 0.01
I1005 22:59:26.312984 10142 solver.cpp:218] Iteration 53300 (13.0616 iter/s, 7.65602s/100 iters), loss = 0.0150589
I1005 22:59:26.313012 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0150588 (* 1 = 0.0150588 loss)
I1005 22:59:26.313029 10142 sgd_solver.cpp:105] Iteration 53300, lr = 0.01
I1005 22:59:33.976301 10142 solver.cpp:218] Iteration 53400 (13.0493 iter/s, 7.66327s/100 iters), loss = 0.0185451
I1005 22:59:33.976332 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0185449 (* 1 = 0.0185449 loss)
I1005 22:59:33.976339 10142 sgd_solver.cpp:105] Iteration 53400, lr = 0.01
I1005 22:59:41.258419 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 22:59:41.564494 10142 solver.cpp:330] Iteration 53500, Testing net (#0)
I1005 22:59:43.311486 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 22:59:43.384781 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9186
I1005 22:59:43.384819 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.307219 (* 1 = 0.307219 loss)
I1005 22:59:43.461612 10142 solver.cpp:218] Iteration 53500 (10.5427 iter/s, 9.48526s/100 iters), loss = 0.0138948
I1005 22:59:43.461658 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0138946 (* 1 = 0.0138946 loss)
I1005 22:59:43.461675 10142 sgd_solver.cpp:105] Iteration 53500, lr = 0.01
I1005 22:59:51.110885 10142 solver.cpp:218] Iteration 53600 (13.0733 iter/s, 7.6492s/100 iters), loss = 0.0097512
I1005 22:59:51.111028 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00975102 (* 1 = 0.00975102 loss)
I1005 22:59:51.111035 10142 sgd_solver.cpp:105] Iteration 53600, lr = 0.01
I1005 22:59:58.775154 10142 solver.cpp:218] Iteration 53700 (13.0478 iter/s, 7.6641s/100 iters), loss = 0.0257361
I1005 22:59:58.775188 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.025736 (* 1 = 0.025736 loss)
I1005 22:59:58.775194 10142 sgd_solver.cpp:105] Iteration 53700, lr = 0.01
I1005 23:00:06.429479 10142 solver.cpp:218] Iteration 53800 (13.0646 iter/s, 7.65426s/100 iters), loss = 0.0103264
I1005 23:00:06.429534 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0103262 (* 1 = 0.0103262 loss)
I1005 23:00:06.429553 10142 sgd_solver.cpp:105] Iteration 53800, lr = 0.01
I1005 23:00:14.092983 10142 solver.cpp:218] Iteration 53900 (13.049 iter/s, 7.66343s/100 iters), loss = 0.00967528
I1005 23:00:14.093017 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00967509 (* 1 = 0.00967509 loss)
I1005 23:00:14.093025 10142 sgd_solver.cpp:105] Iteration 53900, lr = 0.01
I1005 23:00:21.374739 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:00:21.687101 10142 solver.cpp:330] Iteration 54000, Testing net (#0)
I1005 23:00:23.425680 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:00:23.498759 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9157
I1005 23:00:23.498785 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.313048 (* 1 = 0.313048 loss)
I1005 23:00:23.575430 10142 solver.cpp:218] Iteration 54000 (10.5459 iter/s, 9.48239s/100 iters), loss = 0.0322851
I1005 23:00:23.575461 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0322849 (* 1 = 0.0322849 loss)
I1005 23:00:23.575471 10142 sgd_solver.cpp:105] Iteration 54000, lr = 0.01
I1005 23:00:31.241356 10142 solver.cpp:218] Iteration 54100 (13.0448 iter/s, 7.66587s/100 iters), loss = 0.0203149
I1005 23:00:31.241389 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0203147 (* 1 = 0.0203147 loss)
I1005 23:00:31.241396 10142 sgd_solver.cpp:105] Iteration 54100, lr = 0.01
I1005 23:00:38.883779 10142 solver.cpp:218] Iteration 54200 (13.0849 iter/s, 7.64237s/100 iters), loss = 0.0407653
I1005 23:00:38.883810 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0407651 (* 1 = 0.0407651 loss)
I1005 23:00:38.883818 10142 sgd_solver.cpp:105] Iteration 54200, lr = 0.01
I1005 23:00:46.541563 10142 solver.cpp:218] Iteration 54300 (13.0587 iter/s, 7.65773s/100 iters), loss = 0.00658311
I1005 23:00:46.541594 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00658291 (* 1 = 0.00658291 loss)
I1005 23:00:46.541612 10142 sgd_solver.cpp:105] Iteration 54300, lr = 0.01
I1005 23:00:54.191145 10142 solver.cpp:218] Iteration 54400 (13.0727 iter/s, 7.64953s/100 iters), loss = 0.00978479
I1005 23:00:54.191289 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00978459 (* 1 = 0.00978459 loss)
I1005 23:00:54.191298 10142 sgd_solver.cpp:105] Iteration 54400, lr = 0.01
I1005 23:01:01.476244 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:01:01.781829 10142 solver.cpp:330] Iteration 54500, Testing net (#0)
I1005 23:01:03.528183 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:01:03.602891 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9178
I1005 23:01:03.602921 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.319316 (* 1 = 0.319316 loss)
I1005 23:01:03.679741 10142 solver.cpp:218] Iteration 54500 (10.5392 iter/s, 9.48843s/100 iters), loss = 0.0174765
I1005 23:01:03.679775 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0174763 (* 1 = 0.0174763 loss)
I1005 23:01:03.679785 10142 sgd_solver.cpp:105] Iteration 54500, lr = 0.01
I1005 23:01:11.329284 10142 solver.cpp:218] Iteration 54600 (13.0728 iter/s, 7.64949s/100 iters), loss = 0.0182107
I1005 23:01:11.329315 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0182105 (* 1 = 0.0182105 loss)
I1005 23:01:11.329321 10142 sgd_solver.cpp:105] Iteration 54600, lr = 0.01
I1005 23:01:18.992862 10142 solver.cpp:218] Iteration 54700 (13.0488 iter/s, 7.66352s/100 iters), loss = 0.0241809
I1005 23:01:18.992893 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0241807 (* 1 = 0.0241807 loss)
I1005 23:01:18.992900 10142 sgd_solver.cpp:105] Iteration 54700, lr = 0.01
I1005 23:01:26.638608 10142 solver.cpp:218] Iteration 54800 (13.0793 iter/s, 7.64569s/100 iters), loss = 0.0102916
I1005 23:01:26.638738 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0102914 (* 1 = 0.0102914 loss)
I1005 23:01:26.638746 10142 sgd_solver.cpp:105] Iteration 54800, lr = 0.01
I1005 23:01:34.302680 10142 solver.cpp:218] Iteration 54900 (13.0481 iter/s, 7.66392s/100 iters), loss = 0.00293625
I1005 23:01:34.302719 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00293609 (* 1 = 0.00293609 loss)
I1005 23:01:34.302726 10142 sgd_solver.cpp:105] Iteration 54900, lr = 0.01
I1005 23:01:41.580446 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:01:41.886862 10142 solver.cpp:330] Iteration 55000, Testing net (#0)
I1005 23:01:43.637454 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:01:43.710865 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9183
I1005 23:01:43.710901 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.308733 (* 1 = 0.308733 loss)
I1005 23:01:43.788084 10142 solver.cpp:218] Iteration 55000 (10.5426 iter/s, 9.48534s/100 iters), loss = 0.0127094
I1005 23:01:43.788112 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0127092 (* 1 = 0.0127092 loss)
I1005 23:01:43.788120 10142 sgd_solver.cpp:105] Iteration 55000, lr = 0.01
I1005 23:01:51.452419 10142 solver.cpp:218] Iteration 55100 (13.0475 iter/s, 7.66428s/100 iters), loss = 0.0112929
I1005 23:01:51.452460 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0112928 (* 1 = 0.0112928 loss)
I1005 23:01:51.452479 10142 sgd_solver.cpp:105] Iteration 55100, lr = 0.01
I1005 23:01:59.109036 10142 solver.cpp:218] Iteration 55200 (13.0608 iter/s, 7.65652s/100 iters), loss = 0.00631628
I1005 23:01:59.109155 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00631611 (* 1 = 0.00631611 loss)
I1005 23:01:59.109174 10142 sgd_solver.cpp:105] Iteration 55200, lr = 0.01
I1005 23:02:06.775532 10142 solver.cpp:218] Iteration 55300 (13.044 iter/s, 7.66637s/100 iters), loss = 0.027374
I1005 23:02:06.775566 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0273738 (* 1 = 0.0273738 loss)
I1005 23:02:06.775585 10142 sgd_solver.cpp:105] Iteration 55300, lr = 0.01
I1005 23:02:14.422966 10142 solver.cpp:218] Iteration 55400 (13.0764 iter/s, 7.64738s/100 iters), loss = 0.00583563
I1005 23:02:14.422998 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00583549 (* 1 = 0.00583549 loss)
I1005 23:02:14.423017 10142 sgd_solver.cpp:105] Iteration 55400, lr = 0.01
I1005 23:02:21.706802 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:02:22.012434 10142 solver.cpp:330] Iteration 55500, Testing net (#0)
I1005 23:02:23.752394 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:02:23.825033 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9179
I1005 23:02:23.825069 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.316971 (* 1 = 0.316971 loss)
I1005 23:02:23.901595 10142 solver.cpp:218] Iteration 55500 (10.5501 iter/s, 9.47857s/100 iters), loss = 0.0550934
I1005 23:02:23.901625 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0550932 (* 1 = 0.0550932 loss)
I1005 23:02:23.901633 10142 sgd_solver.cpp:105] Iteration 55500, lr = 0.01
I1005 23:02:31.558632 10142 solver.cpp:218] Iteration 55600 (13.06 iter/s, 7.65699s/100 iters), loss = 0.0224321
I1005 23:02:31.558746 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.022432 (* 1 = 0.022432 loss)
I1005 23:02:31.558753 10142 sgd_solver.cpp:105] Iteration 55600, lr = 0.01
I1005 23:02:39.203057 10142 solver.cpp:218] Iteration 55700 (13.0817 iter/s, 7.64429s/100 iters), loss = 0.0136374
I1005 23:02:39.203090 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0136373 (* 1 = 0.0136373 loss)
I1005 23:02:39.203099 10142 sgd_solver.cpp:105] Iteration 55700, lr = 0.01
I1005 23:02:46.857842 10142 solver.cpp:218] Iteration 55800 (13.0638 iter/s, 7.65473s/100 iters), loss = 0.0330234
I1005 23:02:46.857872 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0330232 (* 1 = 0.0330232 loss)
I1005 23:02:46.857878 10142 sgd_solver.cpp:105] Iteration 55800, lr = 0.01
I1005 23:02:54.520977 10142 solver.cpp:218] Iteration 55900 (13.0496 iter/s, 7.66308s/100 iters), loss = 0.00965858
I1005 23:02:54.521013 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00965843 (* 1 = 0.00965843 loss)
I1005 23:02:54.521020 10142 sgd_solver.cpp:105] Iteration 55900, lr = 0.01
I1005 23:03:01.794026 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:03:02.099838 10142 solver.cpp:330] Iteration 56000, Testing net (#0)
I1005 23:03:03.845798 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:03:03.919365 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.919
I1005 23:03:03.919400 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.312309 (* 1 = 0.312309 loss)
I1005 23:03:03.996292 10142 solver.cpp:218] Iteration 56000 (10.5538 iter/s, 9.47525s/100 iters), loss = 0.00478087
I1005 23:03:03.996325 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00478073 (* 1 = 0.00478073 loss)
I1005 23:03:03.996331 10142 sgd_solver.cpp:105] Iteration 56000, lr = 0.01
I1005 23:03:11.647290 10142 solver.cpp:218] Iteration 56100 (13.0703 iter/s, 7.65095s/100 iters), loss = 0.0152621
I1005 23:03:11.647321 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.015262 (* 1 = 0.015262 loss)
I1005 23:03:11.647326 10142 sgd_solver.cpp:105] Iteration 56100, lr = 0.01
I1005 23:03:19.306344 10142 solver.cpp:218] Iteration 56200 (13.0565 iter/s, 7.659s/100 iters), loss = 0.0185882
I1005 23:03:19.306385 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0185881 (* 1 = 0.0185881 loss)
I1005 23:03:19.306391 10142 sgd_solver.cpp:105] Iteration 56200, lr = 0.01
I1005 23:03:26.956938 10142 solver.cpp:218] Iteration 56300 (13.071 iter/s, 7.65053s/100 iters), loss = 0.0118153
I1005 23:03:26.956967 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0118152 (* 1 = 0.0118152 loss)
I1005 23:03:26.956972 10142 sgd_solver.cpp:105] Iteration 56300, lr = 0.01
I1005 23:03:34.617324 10142 solver.cpp:218] Iteration 56400 (13.0543 iter/s, 7.66033s/100 iters), loss = 0.0310384
I1005 23:03:34.617465 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0310383 (* 1 = 0.0310383 loss)
I1005 23:03:34.617472 10142 sgd_solver.cpp:105] Iteration 56400, lr = 0.01
I1005 23:03:41.892199 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:03:42.197646 10142 solver.cpp:330] Iteration 56500, Testing net (#0)
I1005 23:03:43.945003 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:03:44.018535 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9139
I1005 23:03:44.018571 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.330859 (* 1 = 0.330859 loss)
I1005 23:03:44.095541 10142 solver.cpp:218] Iteration 56500 (10.5507 iter/s, 9.47806s/100 iters), loss = 0.00473533
I1005 23:03:44.095566 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00473517 (* 1 = 0.00473517 loss)
I1005 23:03:44.095573 10142 sgd_solver.cpp:105] Iteration 56500, lr = 0.01
I1005 23:03:51.756497 10142 solver.cpp:218] Iteration 56600 (13.0533 iter/s, 7.6609s/100 iters), loss = 0.0115241
I1005 23:03:51.756536 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.011524 (* 1 = 0.011524 loss)
I1005 23:03:51.756546 10142 sgd_solver.cpp:105] Iteration 56600, lr = 0.01
I1005 23:03:59.411006 10142 solver.cpp:218] Iteration 56700 (13.0643 iter/s, 7.65445s/100 iters), loss = 0.0156171
I1005 23:03:59.411038 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.015617 (* 1 = 0.015617 loss)
I1005 23:03:59.411056 10142 sgd_solver.cpp:105] Iteration 56700, lr = 0.01
I1005 23:04:07.077759 10142 solver.cpp:218] Iteration 56800 (13.0434 iter/s, 7.6667s/100 iters), loss = 0.0111408
I1005 23:04:07.077924 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0111407 (* 1 = 0.0111407 loss)
I1005 23:04:07.077950 10142 sgd_solver.cpp:105] Iteration 56800, lr = 0.01
I1005 23:04:14.731406 10142 solver.cpp:218] Iteration 56900 (13.066 iter/s, 7.65347s/100 iters), loss = 0.00723756
I1005 23:04:14.731439 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00723739 (* 1 = 0.00723739 loss)
I1005 23:04:14.731447 10142 sgd_solver.cpp:105] Iteration 56900, lr = 0.01
I1005 23:04:22.017488 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:04:22.324187 10142 solver.cpp:330] Iteration 57000, Testing net (#0)
I1005 23:04:24.062078 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:04:24.135329 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9154
I1005 23:04:24.135365 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.31764 (* 1 = 0.31764 loss)
I1005 23:04:24.212285 10142 solver.cpp:218] Iteration 57000 (10.5476 iter/s, 9.48082s/100 iters), loss = 0.0134037
I1005 23:04:24.212316 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0134035 (* 1 = 0.0134035 loss)
I1005 23:04:24.212323 10142 sgd_solver.cpp:105] Iteration 57000, lr = 0.01
I1005 23:04:31.877442 10142 solver.cpp:218] Iteration 57100 (13.0461 iter/s, 7.6651s/100 iters), loss = 0.0374934
I1005 23:04:31.877475 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0374932 (* 1 = 0.0374932 loss)
I1005 23:04:31.877480 10142 sgd_solver.cpp:105] Iteration 57100, lr = 0.01
I1005 23:04:39.532016 10142 solver.cpp:218] Iteration 57200 (13.0642 iter/s, 7.65451s/100 iters), loss = 0.00758724
I1005 23:04:39.532100 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00758707 (* 1 = 0.00758707 loss)
I1005 23:04:39.532109 10142 sgd_solver.cpp:105] Iteration 57200, lr = 0.01
I1005 23:04:47.189144 10142 solver.cpp:218] Iteration 57300 (13.0599 iter/s, 7.65702s/100 iters), loss = 0.0387469
I1005 23:04:47.189177 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0387467 (* 1 = 0.0387467 loss)
I1005 23:04:47.189196 10142 sgd_solver.cpp:105] Iteration 57300, lr = 0.01
I1005 23:04:54.847688 10142 solver.cpp:218] Iteration 57400 (13.0574 iter/s, 7.65848s/100 iters), loss = 0.0120594
I1005 23:04:54.847723 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0120592 (* 1 = 0.0120592 loss)
I1005 23:04:54.847743 10142 sgd_solver.cpp:105] Iteration 57400, lr = 0.01
I1005 23:05:02.131055 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:05:02.436545 10142 solver.cpp:330] Iteration 57500, Testing net (#0)
I1005 23:05:04.185955 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:05:04.259233 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9169
I1005 23:05:04.259260 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.312106 (* 1 = 0.312106 loss)
I1005 23:05:04.336248 10142 solver.cpp:218] Iteration 57500 (10.5391 iter/s, 9.4885s/100 iters), loss = 0.0164679
I1005 23:05:04.336283 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0164677 (* 1 = 0.0164677 loss)
I1005 23:05:04.336293 10142 sgd_solver.cpp:105] Iteration 57500, lr = 0.01
I1005 23:05:11.984611 10142 solver.cpp:218] Iteration 57600 (13.0748 iter/s, 7.6483s/100 iters), loss = 0.0132829
I1005 23:05:11.984724 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0132827 (* 1 = 0.0132827 loss)
I1005 23:05:11.984730 10142 sgd_solver.cpp:105] Iteration 57600, lr = 0.01
I1005 23:05:19.647420 10142 solver.cpp:218] Iteration 57700 (13.0503 iter/s, 7.66268s/100 iters), loss = 0.00994764
I1005 23:05:19.647452 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00994745 (* 1 = 0.00994745 loss)
I1005 23:05:19.647459 10142 sgd_solver.cpp:105] Iteration 57700, lr = 0.01
I1005 23:05:27.295544 10142 solver.cpp:218] Iteration 57800 (13.0752 iter/s, 7.64807s/100 iters), loss = 0.0214466
I1005 23:05:27.295574 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0214464 (* 1 = 0.0214464 loss)
I1005 23:05:27.295580 10142 sgd_solver.cpp:105] Iteration 57800, lr = 0.01
I1005 23:05:34.959679 10142 solver.cpp:218] Iteration 57900 (13.0479 iter/s, 7.66408s/100 iters), loss = 0.0265905
I1005 23:05:34.959709 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0265903 (* 1 = 0.0265903 loss)
I1005 23:05:34.959725 10142 sgd_solver.cpp:105] Iteration 57900, lr = 0.01
I1005 23:05:42.238340 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:05:42.553086 10142 solver.cpp:330] Iteration 58000, Testing net (#0)
I1005 23:05:44.296674 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:05:44.369630 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9196
I1005 23:05:44.369657 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.314773 (* 1 = 0.314773 loss)
I1005 23:05:44.447047 10142 solver.cpp:218] Iteration 58000 (10.5404 iter/s, 9.48731s/100 iters), loss = 0.00952533
I1005 23:05:44.447077 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00952515 (* 1 = 0.00952515 loss)
I1005 23:05:44.447082 10142 sgd_solver.cpp:105] Iteration 58000, lr = 0.01
I1005 23:05:52.121637 10142 solver.cpp:218] Iteration 58100 (13.0301 iter/s, 7.67454s/100 iters), loss = 0.0156141
I1005 23:05:52.121667 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0156139 (* 1 = 0.0156139 loss)
I1005 23:05:52.121683 10142 sgd_solver.cpp:105] Iteration 58100, lr = 0.01
I1005 23:05:59.767457 10142 solver.cpp:218] Iteration 58200 (13.0791 iter/s, 7.64577s/100 iters), loss = 0.0300631
I1005 23:05:59.767488 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.030063 (* 1 = 0.030063 loss)
I1005 23:05:59.767493 10142 sgd_solver.cpp:105] Iteration 58200, lr = 0.01
I1005 23:06:07.432782 10142 solver.cpp:218] Iteration 58300 (13.0459 iter/s, 7.66527s/100 iters), loss = 0.0276454
I1005 23:06:07.432824 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0276452 (* 1 = 0.0276452 loss)
I1005 23:06:07.432831 10142 sgd_solver.cpp:105] Iteration 58300, lr = 0.01
I1005 23:06:15.086686 10142 solver.cpp:218] Iteration 58400 (13.0653 iter/s, 7.65384s/100 iters), loss = 0.00581566
I1005 23:06:15.086800 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00581546 (* 1 = 0.00581546 loss)
I1005 23:06:15.086807 10142 sgd_solver.cpp:105] Iteration 58400, lr = 0.01
I1005 23:06:22.368230 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:06:22.674165 10142 solver.cpp:330] Iteration 58500, Testing net (#0)
I1005 23:06:24.416435 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:06:24.491770 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.92
I1005 23:06:24.491796 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.306443 (* 1 = 0.306443 loss)
I1005 23:06:24.570576 10142 solver.cpp:218] Iteration 58500 (10.5443 iter/s, 9.48376s/100 iters), loss = 0.00483596
I1005 23:06:24.570628 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00483576 (* 1 = 0.00483576 loss)
I1005 23:06:24.570638 10142 sgd_solver.cpp:105] Iteration 58500, lr = 0.01
I1005 23:06:32.226269 10142 solver.cpp:218] Iteration 58600 (13.0623 iter/s, 7.6556s/100 iters), loss = 0.0189721
I1005 23:06:32.226302 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0189719 (* 1 = 0.0189719 loss)
I1005 23:06:32.226320 10142 sgd_solver.cpp:105] Iteration 58600, lr = 0.01
I1005 23:06:39.886592 10142 solver.cpp:218] Iteration 58700 (13.0544 iter/s, 7.66027s/100 iters), loss = 0.0228023
I1005 23:06:39.886633 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0228021 (* 1 = 0.0228021 loss)
I1005 23:06:39.886641 10142 sgd_solver.cpp:105] Iteration 58700, lr = 0.01
I1005 23:06:47.544028 10142 solver.cpp:218] Iteration 58800 (13.0593 iter/s, 7.65737s/100 iters), loss = 0.0266741
I1005 23:06:47.544178 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0266739 (* 1 = 0.0266739 loss)
I1005 23:06:47.544188 10142 sgd_solver.cpp:105] Iteration 58800, lr = 0.01
I1005 23:06:55.211161 10142 solver.cpp:218] Iteration 58900 (13.043 iter/s, 7.66696s/100 iters), loss = 0.00909919
I1005 23:06:55.211192 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00909899 (* 1 = 0.00909899 loss)
I1005 23:06:55.211199 10142 sgd_solver.cpp:105] Iteration 58900, lr = 0.01
I1005 23:07:02.482671 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:07:02.788031 10142 solver.cpp:330] Iteration 59000, Testing net (#0)
I1005 23:07:04.535298 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:07:04.607906 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9179
I1005 23:07:04.607941 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.319626 (* 1 = 0.319626 loss)
I1005 23:07:04.684965 10142 solver.cpp:218] Iteration 59000 (10.5555 iter/s, 9.47375s/100 iters), loss = 0.0143405
I1005 23:07:04.684995 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0143403 (* 1 = 0.0143403 loss)
I1005 23:07:04.685003 10142 sgd_solver.cpp:105] Iteration 59000, lr = 0.01
I1005 23:07:12.338172 10142 solver.cpp:218] Iteration 59100 (13.0665 iter/s, 7.65315s/100 iters), loss = 0.0156011
I1005 23:07:12.338205 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0156009 (* 1 = 0.0156009 loss)
I1005 23:07:12.338212 10142 sgd_solver.cpp:105] Iteration 59100, lr = 0.01
I1005 23:07:20.002442 10142 solver.cpp:218] Iteration 59200 (13.0477 iter/s, 7.66421s/100 iters), loss = 0.00396837
I1005 23:07:20.002584 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00396817 (* 1 = 0.00396817 loss)
I1005 23:07:20.002593 10142 sgd_solver.cpp:105] Iteration 59200, lr = 0.01
I1005 23:07:27.667749 10142 solver.cpp:218] Iteration 59300 (13.0461 iter/s, 7.66514s/100 iters), loss = 0.0298003
I1005 23:07:27.667784 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0298001 (* 1 = 0.0298001 loss)
I1005 23:07:27.667793 10142 sgd_solver.cpp:105] Iteration 59300, lr = 0.01
I1005 23:07:35.324004 10142 solver.cpp:218] Iteration 59400 (13.0613 iter/s, 7.6562s/100 iters), loss = 0.0102908
I1005 23:07:35.324044 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0102906 (* 1 = 0.0102906 loss)
I1005 23:07:35.324049 10142 sgd_solver.cpp:105] Iteration 59400, lr = 0.01
I1005 23:07:42.605469 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:07:42.912864 10142 solver.cpp:330] Iteration 59500, Testing net (#0)
I1005 23:07:44.653087 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:07:44.726039 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9168
I1005 23:07:44.726074 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.310159 (* 1 = 0.310159 loss)
I1005 23:07:44.803110 10142 solver.cpp:218] Iteration 59500 (10.5496 iter/s, 9.47904s/100 iters), loss = 0.0112325
I1005 23:07:44.803143 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0112323 (* 1 = 0.0112323 loss)
I1005 23:07:44.803148 10142 sgd_solver.cpp:105] Iteration 59500, lr = 0.01
I1005 23:07:52.456115 10142 solver.cpp:218] Iteration 59600 (13.0669 iter/s, 7.65295s/100 iters), loss = 0.0189889
I1005 23:07:52.456238 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0189887 (* 1 = 0.0189887 loss)
I1005 23:07:52.456255 10142 sgd_solver.cpp:105] Iteration 59600, lr = 0.01
I1005 23:08:00.105705 10142 solver.cpp:218] Iteration 59700 (13.0728 iter/s, 7.64945s/100 iters), loss = 0.0136908
I1005 23:08:00.105736 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0136906 (* 1 = 0.0136906 loss)
I1005 23:08:00.105741 10142 sgd_solver.cpp:105] Iteration 59700, lr = 0.01
I1005 23:08:07.768265 10142 solver.cpp:218] Iteration 59800 (13.0506 iter/s, 7.66251s/100 iters), loss = 0.00640916
I1005 23:08:07.768296 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00640895 (* 1 = 0.00640895 loss)
I1005 23:08:07.768301 10142 sgd_solver.cpp:105] Iteration 59800, lr = 0.01
I1005 23:08:15.421358 10142 solver.cpp:218] Iteration 59900 (13.0667 iter/s, 7.65304s/100 iters), loss = 0.00641553
I1005 23:08:15.421396 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00641534 (* 1 = 0.00641534 loss)
I1005 23:08:15.421404 10142 sgd_solver.cpp:105] Iteration 59900, lr = 0.01
I1005 23:08:22.703444 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:08:23.009510 10142 solver.cpp:330] Iteration 60000, Testing net (#0)
I1005 23:08:24.758481 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:08:24.831579 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9194
I1005 23:08:24.831604 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.319912 (* 1 = 0.319912 loss)
I1005 23:08:24.908107 10142 solver.cpp:218] Iteration 60000 (10.5411 iter/s, 9.48668s/100 iters), loss = 0.0217587
I1005 23:08:24.908139 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0217585 (* 1 = 0.0217585 loss)
I1005 23:08:24.908146 10142 sgd_solver.cpp:105] Iteration 60000, lr = 0.01
I1005 23:08:32.563280 10142 solver.cpp:218] Iteration 60100 (13.0632 iter/s, 7.65512s/100 iters), loss = 0.00598896
I1005 23:08:32.563310 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00598876 (* 1 = 0.00598876 loss)
I1005 23:08:32.563315 10142 sgd_solver.cpp:105] Iteration 60100, lr = 0.01
I1005 23:08:40.214505 10142 solver.cpp:218] Iteration 60200 (13.0699 iter/s, 7.65117s/100 iters), loss = 0.00543747
I1005 23:08:40.214550 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00543728 (* 1 = 0.00543728 loss)
I1005 23:08:40.214557 10142 sgd_solver.cpp:105] Iteration 60200, lr = 0.01
I1005 23:08:47.867635 10142 solver.cpp:218] Iteration 60300 (13.0667 iter/s, 7.65306s/100 iters), loss = 0.01172
I1005 23:08:47.867663 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0117198 (* 1 = 0.0117198 loss)
I1005 23:08:47.867669 10142 sgd_solver.cpp:105] Iteration 60300, lr = 0.01
I1005 23:08:55.527765 10142 solver.cpp:218] Iteration 60400 (13.0547 iter/s, 7.66008s/100 iters), loss = 0.0109592
I1005 23:08:55.527915 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.010959 (* 1 = 0.010959 loss)
I1005 23:08:55.527923 10142 sgd_solver.cpp:105] Iteration 60400, lr = 0.01
I1005 23:09:02.801210 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:09:03.106403 10142 solver.cpp:330] Iteration 60500, Testing net (#0)
I1005 23:09:04.855907 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:09:04.929077 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9165
I1005 23:09:04.929112 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.322288 (* 1 = 0.322288 loss)
I1005 23:09:05.006078 10142 solver.cpp:218] Iteration 60500 (10.5506 iter/s, 9.47814s/100 iters), loss = 0.00319501
I1005 23:09:05.006104 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00319481 (* 1 = 0.00319481 loss)
I1005 23:09:05.006111 10142 sgd_solver.cpp:105] Iteration 60500, lr = 0.01
I1005 23:09:12.669047 10142 solver.cpp:218] Iteration 60600 (13.0499 iter/s, 7.66292s/100 iters), loss = 0.0162353
I1005 23:09:12.669083 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0162351 (* 1 = 0.0162351 loss)
I1005 23:09:12.669092 10142 sgd_solver.cpp:105] Iteration 60600, lr = 0.01
I1005 23:09:20.323030 10142 solver.cpp:218] Iteration 60700 (13.0653 iter/s, 7.65389s/100 iters), loss = 0.00325527
I1005 23:09:20.323060 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00325507 (* 1 = 0.00325507 loss)
I1005 23:09:20.323067 10142 sgd_solver.cpp:105] Iteration 60700, lr = 0.01
I1005 23:09:27.982120 10142 solver.cpp:218] Iteration 60800 (13.0565 iter/s, 7.65903s/100 iters), loss = 0.0182501
I1005 23:09:27.982285 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0182499 (* 1 = 0.0182499 loss)
I1005 23:09:27.982292 10142 sgd_solver.cpp:105] Iteration 60800, lr = 0.01
I1005 23:09:35.625950 10142 solver.cpp:218] Iteration 60900 (13.0827 iter/s, 7.64366s/100 iters), loss = 0.00969775
I1005 23:09:35.625980 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00969756 (* 1 = 0.00969756 loss)
I1005 23:09:35.625986 10142 sgd_solver.cpp:105] Iteration 60900, lr = 0.01
I1005 23:09:42.910390 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:09:43.216239 10142 solver.cpp:330] Iteration 61000, Testing net (#0)
I1005 23:09:44.956060 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:09:45.029284 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9211
I1005 23:09:45.029309 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.311991 (* 1 = 0.311991 loss)
I1005 23:09:45.106395 10142 solver.cpp:218] Iteration 61000 (10.5481 iter/s, 9.48039s/100 iters), loss = 0.0164458
I1005 23:09:45.106420 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0164456 (* 1 = 0.0164456 loss)
I1005 23:09:45.106426 10142 sgd_solver.cpp:105] Iteration 61000, lr = 0.01
I1005 23:09:52.775203 10142 solver.cpp:218] Iteration 61100 (13.0399 iter/s, 7.66876s/100 iters), loss = 0.0218338
I1005 23:09:52.775244 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0218336 (* 1 = 0.0218336 loss)
I1005 23:09:52.775250 10142 sgd_solver.cpp:105] Iteration 61100, lr = 0.01
I1005 23:10:00.423331 10142 solver.cpp:218] Iteration 61200 (13.0752 iter/s, 7.64806s/100 iters), loss = 0.0365191
I1005 23:10:00.423449 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0365189 (* 1 = 0.0365189 loss)
I1005 23:10:00.423468 10142 sgd_solver.cpp:105] Iteration 61200, lr = 0.01
I1005 23:10:08.080597 10142 solver.cpp:218] Iteration 61300 (13.0597 iter/s, 7.65714s/100 iters), loss = 0.0223665
I1005 23:10:08.080627 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0223663 (* 1 = 0.0223663 loss)
I1005 23:10:08.080636 10142 sgd_solver.cpp:105] Iteration 61300, lr = 0.01
I1005 23:10:15.733640 10142 solver.cpp:218] Iteration 61400 (13.0668 iter/s, 7.65299s/100 iters), loss = 0.0580695
I1005 23:10:15.733675 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0580693 (* 1 = 0.0580693 loss)
I1005 23:10:15.733691 10142 sgd_solver.cpp:105] Iteration 61400, lr = 0.01
I1005 23:10:23.002547 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:10:23.308616 10142 solver.cpp:330] Iteration 61500, Testing net (#0)
I1005 23:10:25.057695 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:10:25.130771 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9209
I1005 23:10:25.130796 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.305161 (* 1 = 0.305161 loss)
I1005 23:10:25.207573 10142 solver.cpp:218] Iteration 61500 (10.5553 iter/s, 9.47387s/100 iters), loss = 0.0286689
I1005 23:10:25.207604 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0286686 (* 1 = 0.0286686 loss)
I1005 23:10:25.207612 10142 sgd_solver.cpp:105] Iteration 61500, lr = 0.01
I1005 23:10:32.855475 10142 solver.cpp:218] Iteration 61600 (13.0756 iter/s, 7.64785s/100 iters), loss = 0.00866294
I1005 23:10:32.855619 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0086627 (* 1 = 0.0086627 loss)
I1005 23:10:32.855628 10142 sgd_solver.cpp:105] Iteration 61600, lr = 0.01
I1005 23:10:40.519994 10142 solver.cpp:218] Iteration 61700 (13.0474 iter/s, 7.66436s/100 iters), loss = 0.00385265
I1005 23:10:40.520023 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00385242 (* 1 = 0.00385242 loss)
I1005 23:10:40.520040 10142 sgd_solver.cpp:105] Iteration 61700, lr = 0.01
I1005 23:10:48.175966 10142 solver.cpp:218] Iteration 61800 (13.0618 iter/s, 7.65592s/100 iters), loss = 0.0294573
I1005 23:10:48.175997 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.029457 (* 1 = 0.029457 loss)
I1005 23:10:48.176013 10142 sgd_solver.cpp:105] Iteration 61800, lr = 0.01
I1005 23:10:55.842175 10142 solver.cpp:218] Iteration 61900 (13.0443 iter/s, 7.66616s/100 iters), loss = 0.00383664
I1005 23:10:55.842206 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00383642 (* 1 = 0.00383642 loss)
I1005 23:10:55.842211 10142 sgd_solver.cpp:105] Iteration 61900, lr = 0.01
I1005 23:11:03.114972 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:11:03.423923 10142 solver.cpp:330] Iteration 62000, Testing net (#0)
I1005 23:11:05.168776 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:11:05.241606 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9207
I1005 23:11:05.241643 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.313053 (* 1 = 0.313053 loss)
I1005 23:11:05.318522 10142 solver.cpp:218] Iteration 62000 (10.5527 iter/s, 9.47629s/100 iters), loss = 0.0236564
I1005 23:11:05.318549 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0236562 (* 1 = 0.0236562 loss)
I1005 23:11:05.318557 10142 sgd_solver.cpp:105] Iteration 62000, lr = 0.01
I1005 23:11:12.982916 10142 solver.cpp:218] Iteration 62100 (13.0474 iter/s, 7.66434s/100 iters), loss = 0.0290693
I1005 23:11:12.982959 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0290691 (* 1 = 0.0290691 loss)
I1005 23:11:12.982965 10142 sgd_solver.cpp:105] Iteration 62100, lr = 0.01
I1005 23:11:20.638341 10142 solver.cpp:218] Iteration 62200 (13.0627 iter/s, 7.65536s/100 iters), loss = 0.00385373
I1005 23:11:20.638372 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0038535 (* 1 = 0.0038535 loss)
I1005 23:11:20.638378 10142 sgd_solver.cpp:105] Iteration 62200, lr = 0.01
I1005 23:11:28.307502 10142 solver.cpp:218] Iteration 62300 (13.0393 iter/s, 7.66911s/100 iters), loss = 0.0252853
I1005 23:11:28.307533 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0252851 (* 1 = 0.0252851 loss)
I1005 23:11:28.307539 10142 sgd_solver.cpp:105] Iteration 62300, lr = 0.01
I1005 23:11:35.960090 10142 solver.cpp:218] Iteration 62400 (13.0676 iter/s, 7.65253s/100 iters), loss = 0.00928428
I1005 23:11:35.960233 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00928407 (* 1 = 0.00928407 loss)
I1005 23:11:35.960240 10142 sgd_solver.cpp:105] Iteration 62400, lr = 0.01
I1005 23:11:43.242468 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:11:43.547930 10142 solver.cpp:330] Iteration 62500, Testing net (#0)
I1005 23:11:45.287330 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:11:45.359836 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9213
I1005 23:11:45.359871 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.317318 (* 1 = 0.317318 loss)
I1005 23:11:45.438288 10142 solver.cpp:218] Iteration 62500 (10.5507 iter/s, 9.47803s/100 iters), loss = 0.00523208
I1005 23:11:45.438325 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00523187 (* 1 = 0.00523187 loss)
I1005 23:11:45.438333 10142 sgd_solver.cpp:105] Iteration 62500, lr = 0.01
I1005 23:11:53.096289 10142 solver.cpp:218] Iteration 62600 (13.0583 iter/s, 7.65794s/100 iters), loss = 0.00475789
I1005 23:11:53.096330 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00475768 (* 1 = 0.00475768 loss)
I1005 23:11:53.096336 10142 sgd_solver.cpp:105] Iteration 62600, lr = 0.01
I1005 23:12:00.760396 10142 solver.cpp:218] Iteration 62700 (13.0479 iter/s, 7.66404s/100 iters), loss = 0.0160026
I1005 23:12:00.760426 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0160024 (* 1 = 0.0160024 loss)
I1005 23:12:00.760433 10142 sgd_solver.cpp:105] Iteration 62700, lr = 0.01
I1005 23:12:08.414317 10142 solver.cpp:218] Iteration 62800 (13.0653 iter/s, 7.65387s/100 iters), loss = 0.0310711
I1005 23:12:08.414456 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0310709 (* 1 = 0.0310709 loss)
I1005 23:12:08.414474 10142 sgd_solver.cpp:105] Iteration 62800, lr = 0.01
I1005 23:12:16.085922 10142 solver.cpp:218] Iteration 62900 (13.0354 iter/s, 7.67144s/100 iters), loss = 0.00423474
I1005 23:12:16.085954 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00423453 (* 1 = 0.00423453 loss)
I1005 23:12:16.085961 10142 sgd_solver.cpp:105] Iteration 62900, lr = 0.01
I1005 23:12:23.363517 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:12:23.669909 10142 solver.cpp:330] Iteration 63000, Testing net (#0)
I1005 23:12:25.419226 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:12:25.492449 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9172
I1005 23:12:25.492485 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.337871 (* 1 = 0.337871 loss)
I1005 23:12:25.569236 10142 solver.cpp:218] Iteration 63000 (10.5449 iter/s, 9.48326s/100 iters), loss = 0.0223181
I1005 23:12:25.569263 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0223179 (* 1 = 0.0223179 loss)
I1005 23:12:25.569269 10142 sgd_solver.cpp:105] Iteration 63000, lr = 0.01
I1005 23:12:33.225515 10142 solver.cpp:218] Iteration 63100 (13.0613 iter/s, 7.65623s/100 iters), loss = 0.00360438
I1005 23:12:33.225556 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00360417 (* 1 = 0.00360417 loss)
I1005 23:12:33.225563 10142 sgd_solver.cpp:105] Iteration 63100, lr = 0.01
I1005 23:12:40.878681 10142 solver.cpp:218] Iteration 63200 (13.0666 iter/s, 7.6531s/100 iters), loss = 0.0172915
I1005 23:12:40.878813 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0172913 (* 1 = 0.0172913 loss)
I1005 23:12:40.878829 10142 sgd_solver.cpp:105] Iteration 63200, lr = 0.01
I1005 23:12:48.537956 10142 solver.cpp:218] Iteration 63300 (13.0563 iter/s, 7.65912s/100 iters), loss = 0.0383376
I1005 23:12:48.537995 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0383374 (* 1 = 0.0383374 loss)
I1005 23:12:48.538003 10142 sgd_solver.cpp:105] Iteration 63300, lr = 0.01
I1005 23:12:56.193596 10142 solver.cpp:218] Iteration 63400 (13.0624 iter/s, 7.65558s/100 iters), loss = 0.0368291
I1005 23:12:56.193625 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0368289 (* 1 = 0.0368289 loss)
I1005 23:12:56.193631 10142 sgd_solver.cpp:105] Iteration 63400, lr = 0.01
I1005 23:13:03.471204 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:13:03.783663 10142 solver.cpp:330] Iteration 63500, Testing net (#0)
I1005 23:13:05.522894 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:13:05.595737 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9179
I1005 23:13:05.595772 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.329177 (* 1 = 0.329177 loss)
I1005 23:13:05.673156 10142 solver.cpp:218] Iteration 63500 (10.5491 iter/s, 9.4795s/100 iters), loss = 0.0108329
I1005 23:13:05.673187 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0108327 (* 1 = 0.0108327 loss)
I1005 23:13:05.673194 10142 sgd_solver.cpp:105] Iteration 63500, lr = 0.01
I1005 23:13:13.333387 10142 solver.cpp:218] Iteration 63600 (13.0545 iter/s, 7.66018s/100 iters), loss = 0.00828869
I1005 23:13:13.333492 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00828848 (* 1 = 0.00828848 loss)
I1005 23:13:13.333498 10142 sgd_solver.cpp:105] Iteration 63600, lr = 0.01
I1005 23:13:20.984879 10142 solver.cpp:218] Iteration 63700 (13.0696 iter/s, 7.65137s/100 iters), loss = 0.0112194
I1005 23:13:20.984910 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0112192 (* 1 = 0.0112192 loss)
I1005 23:13:20.984915 10142 sgd_solver.cpp:105] Iteration 63700, lr = 0.01
I1005 23:13:28.644701 10142 solver.cpp:218] Iteration 63800 (13.0552 iter/s, 7.65977s/100 iters), loss = 0.00509605
I1005 23:13:28.644742 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00509585 (* 1 = 0.00509585 loss)
I1005 23:13:28.644747 10142 sgd_solver.cpp:105] Iteration 63800, lr = 0.01
I1005 23:13:36.296949 10142 solver.cpp:218] Iteration 63900 (13.0682 iter/s, 7.65218s/100 iters), loss = 0.00800473
I1005 23:13:36.296993 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00800452 (* 1 = 0.00800452 loss)
I1005 23:13:36.296999 10142 sgd_solver.cpp:105] Iteration 63900, lr = 0.01
I1005 23:13:43.577072 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:13:43.884095 10142 solver.cpp:330] Iteration 64000, Testing net (#0)
I1005 23:13:45.632689 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:13:45.707797 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9171
I1005 23:13:45.707823 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.334496 (* 1 = 0.334496 loss)
I1005 23:13:45.784821 10142 solver.cpp:218] Iteration 64000 (10.5399 iter/s, 9.4878s/100 iters), loss = 0.0041745
I1005 23:13:45.784854 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00417429 (* 1 = 0.00417429 loss)
I1005 23:13:45.784862 10142 sgd_solver.cpp:105] Iteration 64000, lr = 0.01
I1005 23:13:53.445155 10142 solver.cpp:218] Iteration 64100 (13.0544 iter/s, 7.66028s/100 iters), loss = 0.00921356
I1005 23:13:53.445196 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00921335 (* 1 = 0.00921335 loss)
I1005 23:13:53.445202 10142 sgd_solver.cpp:105] Iteration 64100, lr = 0.01
I1005 23:14:01.109134 10142 solver.cpp:218] Iteration 64200 (13.0482 iter/s, 7.66392s/100 iters), loss = 0.00526866
I1005 23:14:01.109174 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00526845 (* 1 = 0.00526845 loss)
I1005 23:14:01.109181 10142 sgd_solver.cpp:105] Iteration 64200, lr = 0.01
I1005 23:14:08.764272 10142 solver.cpp:218] Iteration 64300 (13.0632 iter/s, 7.65508s/100 iters), loss = 0.0106861
I1005 23:14:08.764313 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0106858 (* 1 = 0.0106858 loss)
I1005 23:14:08.764319 10142 sgd_solver.cpp:105] Iteration 64300, lr = 0.01
I1005 23:14:16.422883 10142 solver.cpp:218] Iteration 64400 (13.0573 iter/s, 7.65855s/100 iters), loss = 0.00176356
I1005 23:14:16.423041 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00176335 (* 1 = 0.00176335 loss)
I1005 23:14:16.423050 10142 sgd_solver.cpp:105] Iteration 64400, lr = 0.01
I1005 23:14:23.701220 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:14:24.008127 10142 solver.cpp:330] Iteration 64500, Testing net (#0)
I1005 23:14:25.757155 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:14:25.830219 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9163
I1005 23:14:25.830255 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.331026 (* 1 = 0.331026 loss)
I1005 23:14:25.907518 10142 solver.cpp:218] Iteration 64500 (10.5436 iter/s, 9.48446s/100 iters), loss = 0.00341963
I1005 23:14:25.907548 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00341943 (* 1 = 0.00341943 loss)
I1005 23:14:25.907557 10142 sgd_solver.cpp:105] Iteration 64500, lr = 0.01
I1005 23:14:33.568073 10142 solver.cpp:218] Iteration 64600 (13.054 iter/s, 7.66049s/100 iters), loss = 0.0423427
I1005 23:14:33.568110 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0423425 (* 1 = 0.0423425 loss)
I1005 23:14:33.568117 10142 sgd_solver.cpp:105] Iteration 64600, lr = 0.01
I1005 23:14:41.226145 10142 solver.cpp:218] Iteration 64700 (13.0582 iter/s, 7.65801s/100 iters), loss = 0.00401431
I1005 23:14:41.226183 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0040141 (* 1 = 0.0040141 loss)
I1005 23:14:41.226189 10142 sgd_solver.cpp:105] Iteration 64700, lr = 0.01
I1005 23:14:48.881011 10142 solver.cpp:218] Iteration 64800 (13.0637 iter/s, 7.6548s/100 iters), loss = 0.00551976
I1005 23:14:48.881114 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00551956 (* 1 = 0.00551956 loss)
I1005 23:14:48.881129 10142 sgd_solver.cpp:105] Iteration 64800, lr = 0.01
I1005 23:14:56.525732 10142 solver.cpp:218] Iteration 64900 (13.0811 iter/s, 7.6446s/100 iters), loss = 0.00237669
I1005 23:14:56.525760 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00237649 (* 1 = 0.00237649 loss)
I1005 23:14:56.525776 10142 sgd_solver.cpp:105] Iteration 64900, lr = 0.01
I1005 23:15:03.802322 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:15:04.109311 10142 solver.cpp:330] Iteration 65000, Testing net (#0)
I1005 23:15:05.848132 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:15:05.921506 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9191
I1005 23:15:05.921541 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.318338 (* 1 = 0.318338 loss)
I1005 23:15:05.998121 10142 solver.cpp:218] Iteration 65000 (10.5571 iter/s, 9.47234s/100 iters), loss = 0.0292619
I1005 23:15:05.998149 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0292617 (* 1 = 0.0292617 loss)
I1005 23:15:05.998155 10142 sgd_solver.cpp:105] Iteration 65000, lr = 0.01
I1005 23:15:13.659394 10142 solver.cpp:218] Iteration 65100 (13.0527 iter/s, 7.66122s/100 iters), loss = 0.0528659
I1005 23:15:13.659435 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0528657 (* 1 = 0.0528657 loss)
I1005 23:15:13.659440 10142 sgd_solver.cpp:105] Iteration 65100, lr = 0.01
I1005 23:15:21.301131 10142 solver.cpp:218] Iteration 65200 (13.0861 iter/s, 7.64167s/100 iters), loss = 0.011839
I1005 23:15:21.301295 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0118388 (* 1 = 0.0118388 loss)
I1005 23:15:21.301304 10142 sgd_solver.cpp:105] Iteration 65200, lr = 0.01
I1005 23:15:28.964251 10142 solver.cpp:218] Iteration 65300 (13.0498 iter/s, 7.66295s/100 iters), loss = 0.00585417
I1005 23:15:28.964282 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00585397 (* 1 = 0.00585397 loss)
I1005 23:15:28.964287 10142 sgd_solver.cpp:105] Iteration 65300, lr = 0.01
I1005 23:15:36.626763 10142 solver.cpp:218] Iteration 65400 (13.0506 iter/s, 7.66246s/100 iters), loss = 0.00253284
I1005 23:15:36.626799 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00253264 (* 1 = 0.00253264 loss)
I1005 23:15:36.626806 10142 sgd_solver.cpp:105] Iteration 65400, lr = 0.01
I1005 23:15:43.902004 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:15:44.207500 10142 solver.cpp:330] Iteration 65500, Testing net (#0)
I1005 23:15:45.953820 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:15:46.027195 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9183
I1005 23:15:46.027220 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.33926 (* 1 = 0.33926 loss)
I1005 23:15:46.103976 10142 solver.cpp:218] Iteration 65500 (10.5517 iter/s, 9.47715s/100 iters), loss = 0.00522909
I1005 23:15:46.104009 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00522889 (* 1 = 0.00522889 loss)
I1005 23:15:46.104017 10142 sgd_solver.cpp:105] Iteration 65500, lr = 0.01
I1005 23:15:53.753054 10142 solver.cpp:218] Iteration 65600 (13.0736 iter/s, 7.64902s/100 iters), loss = 0.0053635
I1005 23:15:53.753181 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00536331 (* 1 = 0.00536331 loss)
I1005 23:15:53.753198 10142 sgd_solver.cpp:105] Iteration 65600, lr = 0.01
I1005 23:16:01.416185 10142 solver.cpp:218] Iteration 65700 (13.0497 iter/s, 7.66299s/100 iters), loss = 0.010556
I1005 23:16:01.416235 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0105558 (* 1 = 0.0105558 loss)
I1005 23:16:01.416252 10142 sgd_solver.cpp:105] Iteration 65700, lr = 0.01
I1005 23:16:09.067749 10142 solver.cpp:218] Iteration 65800 (13.0693 iter/s, 7.6515s/100 iters), loss = 0.0240998
I1005 23:16:09.067780 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0240997 (* 1 = 0.0240997 loss)
I1005 23:16:09.067786 10142 sgd_solver.cpp:105] Iteration 65800, lr = 0.01
I1005 23:16:16.733618 10142 solver.cpp:218] Iteration 65900 (13.0449 iter/s, 7.66581s/100 iters), loss = 0.0166717
I1005 23:16:16.733647 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0166715 (* 1 = 0.0166715 loss)
I1005 23:16:16.733652 10142 sgd_solver.cpp:105] Iteration 65900, lr = 0.01
I1005 23:16:24.005961 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:16:24.311348 10142 solver.cpp:330] Iteration 66000, Testing net (#0)
I1005 23:16:26.062770 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:16:26.135926 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9167
I1005 23:16:26.135951 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.345437 (* 1 = 0.345437 loss)
I1005 23:16:26.212918 10142 solver.cpp:218] Iteration 66000 (10.5494 iter/s, 9.47925s/100 iters), loss = 0.00934679
I1005 23:16:26.212947 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00934659 (* 1 = 0.00934659 loss)
I1005 23:16:26.212954 10142 sgd_solver.cpp:105] Iteration 66000, lr = 0.01
I1005 23:16:33.874855 10142 solver.cpp:218] Iteration 66100 (13.0516 iter/s, 7.66188s/100 iters), loss = 0.010694
I1005 23:16:33.874899 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0106938 (* 1 = 0.0106938 loss)
I1005 23:16:33.874907 10142 sgd_solver.cpp:105] Iteration 66100, lr = 0.01
I1005 23:16:41.520151 10142 solver.cpp:218] Iteration 66200 (13.0801 iter/s, 7.64523s/100 iters), loss = 0.02914
I1005 23:16:41.520180 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0291398 (* 1 = 0.0291398 loss)
I1005 23:16:41.520186 10142 sgd_solver.cpp:105] Iteration 66200, lr = 0.01
I1005 23:16:49.173712 10142 solver.cpp:218] Iteration 66300 (13.0659 iter/s, 7.65351s/100 iters), loss = 0.0196159
I1005 23:16:49.173743 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0196157 (* 1 = 0.0196157 loss)
I1005 23:16:49.173748 10142 sgd_solver.cpp:105] Iteration 66300, lr = 0.01
I1005 23:16:56.824658 10142 solver.cpp:218] Iteration 66400 (13.0704 iter/s, 7.65089s/100 iters), loss = 0.00353004
I1005 23:16:56.824762 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00352985 (* 1 = 0.00352985 loss)
I1005 23:16:56.824769 10142 sgd_solver.cpp:105] Iteration 66400, lr = 0.01
I1005 23:17:04.109899 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:17:04.415604 10142 solver.cpp:330] Iteration 66500, Testing net (#0)
I1005 23:17:06.155412 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:17:06.228771 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9125
I1005 23:17:06.228798 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.354673 (* 1 = 0.354673 loss)
I1005 23:17:06.306157 10142 solver.cpp:218] Iteration 66500 (10.547 iter/s, 9.48138s/100 iters), loss = 0.0230064
I1005 23:17:06.306191 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0230062 (* 1 = 0.0230062 loss)
I1005 23:17:06.306197 10142 sgd_solver.cpp:105] Iteration 66500, lr = 0.01
I1005 23:17:13.969547 10142 solver.cpp:218] Iteration 66600 (13.0492 iter/s, 7.66333s/100 iters), loss = 0.0426386
I1005 23:17:13.969576 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0426384 (* 1 = 0.0426384 loss)
I1005 23:17:13.969583 10142 sgd_solver.cpp:105] Iteration 66600, lr = 0.01
I1005 23:17:21.633970 10142 solver.cpp:218] Iteration 66700 (13.0474 iter/s, 7.66437s/100 iters), loss = 0.00938011
I1005 23:17:21.634006 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0093799 (* 1 = 0.0093799 loss)
I1005 23:17:21.634012 10142 sgd_solver.cpp:105] Iteration 66700, lr = 0.01
I1005 23:17:29.284710 10142 solver.cpp:218] Iteration 66800 (13.0707 iter/s, 7.65068s/100 iters), loss = 0.0143749
I1005 23:17:29.284831 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0143746 (* 1 = 0.0143746 loss)
I1005 23:17:29.284847 10142 sgd_solver.cpp:105] Iteration 66800, lr = 0.01
I1005 23:17:36.936908 10142 solver.cpp:218] Iteration 66900 (13.0684 iter/s, 7.65207s/100 iters), loss = 0.0115494
I1005 23:17:36.936939 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0115492 (* 1 = 0.0115492 loss)
I1005 23:17:36.936944 10142 sgd_solver.cpp:105] Iteration 66900, lr = 0.01
I1005 23:17:44.214838 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:17:44.519490 10142 solver.cpp:330] Iteration 67000, Testing net (#0)
I1005 23:17:46.269697 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:17:46.342877 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9189
I1005 23:17:46.342913 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.338785 (* 1 = 0.338785 loss)
I1005 23:17:46.419872 10142 solver.cpp:218] Iteration 67000 (10.5453 iter/s, 9.48291s/100 iters), loss = 0.00431303
I1005 23:17:46.419903 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00431282 (* 1 = 0.00431282 loss)
I1005 23:17:46.419911 10142 sgd_solver.cpp:105] Iteration 67000, lr = 0.01
I1005 23:17:54.076932 10142 solver.cpp:218] Iteration 67100 (13.0599 iter/s, 7.65701s/100 iters), loss = 0.003208
I1005 23:17:54.076961 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00320779 (* 1 = 0.00320779 loss)
I1005 23:17:54.076967 10142 sgd_solver.cpp:105] Iteration 67100, lr = 0.01
I1005 23:18:01.739774 10142 solver.cpp:218] Iteration 67200 (13.0501 iter/s, 7.66279s/100 iters), loss = 0.0473551
I1005 23:18:01.739913 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0473549 (* 1 = 0.0473549 loss)
I1005 23:18:01.739931 10142 sgd_solver.cpp:105] Iteration 67200, lr = 0.01
I1005 23:18:09.391894 10142 solver.cpp:218] Iteration 67300 (13.0685 iter/s, 7.65196s/100 iters), loss = 0.0683592
I1005 23:18:09.391935 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.068359 (* 1 = 0.068359 loss)
I1005 23:18:09.391942 10142 sgd_solver.cpp:105] Iteration 67300, lr = 0.01
I1005 23:18:17.046037 10142 solver.cpp:218] Iteration 67400 (13.0649 iter/s, 7.65408s/100 iters), loss = 0.00141778
I1005 23:18:17.046070 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00141756 (* 1 = 0.00141756 loss)
I1005 23:18:17.046077 10142 sgd_solver.cpp:105] Iteration 67400, lr = 0.01
I1005 23:18:24.315135 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:18:24.626719 10142 solver.cpp:330] Iteration 67500, Testing net (#0)
I1005 23:18:26.369107 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:18:26.442463 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9184
I1005 23:18:26.442489 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.33184 (* 1 = 0.33184 loss)
I1005 23:18:26.519804 10142 solver.cpp:218] Iteration 67500 (10.5555 iter/s, 9.47371s/100 iters), loss = 0.00552181
I1005 23:18:26.519832 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00552159 (* 1 = 0.00552159 loss)
I1005 23:18:26.519840 10142 sgd_solver.cpp:105] Iteration 67500, lr = 0.01
I1005 23:18:34.178042 10142 solver.cpp:218] Iteration 67600 (13.0579 iter/s, 7.65819s/100 iters), loss = 0.00530612
I1005 23:18:34.178149 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00530591 (* 1 = 0.00530591 loss)
I1005 23:18:34.178158 10142 sgd_solver.cpp:105] Iteration 67600, lr = 0.01
I1005 23:18:41.830096 10142 solver.cpp:218] Iteration 67700 (13.0686 iter/s, 7.65193s/100 iters), loss = 0.00334081
I1005 23:18:41.830137 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00334059 (* 1 = 0.00334059 loss)
I1005 23:18:41.830143 10142 sgd_solver.cpp:105] Iteration 67700, lr = 0.01
I1005 23:18:49.488111 10142 solver.cpp:218] Iteration 67800 (13.0583 iter/s, 7.65795s/100 iters), loss = 0.0169356
I1005 23:18:49.488140 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0169354 (* 1 = 0.0169354 loss)
I1005 23:18:49.488145 10142 sgd_solver.cpp:105] Iteration 67800, lr = 0.01
I1005 23:18:57.134902 10142 solver.cpp:218] Iteration 67900 (13.0775 iter/s, 7.64673s/100 iters), loss = 0.0396551
I1005 23:18:57.134932 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0396549 (* 1 = 0.0396549 loss)
I1005 23:18:57.134938 10142 sgd_solver.cpp:105] Iteration 67900, lr = 0.01
I1005 23:19:04.410647 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:19:04.717027 10142 solver.cpp:330] Iteration 68000, Testing net (#0)
I1005 23:19:06.456316 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:19:06.531159 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9129
I1005 23:19:06.531186 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.36027 (* 1 = 0.36027 loss)
I1005 23:19:06.609205 10142 solver.cpp:218] Iteration 68000 (10.5549 iter/s, 9.47425s/100 iters), loss = 0.0343405
I1005 23:19:06.609239 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0343403 (* 1 = 0.0343403 loss)
I1005 23:19:06.609246 10142 sgd_solver.cpp:105] Iteration 68000, lr = 0.01
I1005 23:19:14.263960 10142 solver.cpp:218] Iteration 68100 (13.0639 iter/s, 7.6547s/100 iters), loss = 0.0139924
I1005 23:19:14.263990 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0139922 (* 1 = 0.0139922 loss)
I1005 23:19:14.263996 10142 sgd_solver.cpp:105] Iteration 68100, lr = 0.01
I1005 23:19:21.924048 10142 solver.cpp:218] Iteration 68200 (13.0548 iter/s, 7.66003s/100 iters), loss = 0.0339835
I1005 23:19:21.924082 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0339833 (* 1 = 0.0339833 loss)
I1005 23:19:21.924091 10142 sgd_solver.cpp:105] Iteration 68200, lr = 0.01
I1005 23:19:29.575181 10142 solver.cpp:218] Iteration 68300 (13.0701 iter/s, 7.65108s/100 iters), loss = 0.0194485
I1005 23:19:29.575222 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0194483 (* 1 = 0.0194483 loss)
I1005 23:19:29.575227 10142 sgd_solver.cpp:105] Iteration 68300, lr = 0.01
I1005 23:19:37.235340 10142 solver.cpp:218] Iteration 68400 (13.0547 iter/s, 7.6601s/100 iters), loss = 0.00695043
I1005 23:19:37.235457 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00695019 (* 1 = 0.00695019 loss)
I1005 23:19:37.235465 10142 sgd_solver.cpp:105] Iteration 68400, lr = 0.01
I1005 23:19:44.508271 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:19:44.813592 10142 solver.cpp:330] Iteration 68500, Testing net (#0)
I1005 23:19:46.561445 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:19:46.634694 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9185
I1005 23:19:46.634729 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.338307 (* 1 = 0.338307 loss)
I1005 23:19:46.712028 10142 solver.cpp:218] Iteration 68500 (10.5524 iter/s, 9.47656s/100 iters), loss = 0.00423476
I1005 23:19:46.712056 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00423453 (* 1 = 0.00423453 loss)
I1005 23:19:46.712064 10142 sgd_solver.cpp:105] Iteration 68500, lr = 0.01
I1005 23:19:54.359128 10142 solver.cpp:218] Iteration 68600 (13.0769 iter/s, 7.64705s/100 iters), loss = 0.0256439
I1005 23:19:54.359160 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0256437 (* 1 = 0.0256437 loss)
I1005 23:19:54.359166 10142 sgd_solver.cpp:105] Iteration 68600, lr = 0.01
I1005 23:20:02.015233 10142 solver.cpp:218] Iteration 68700 (13.0616 iter/s, 7.65605s/100 iters), loss = 0.0153161
I1005 23:20:02.015261 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0153159 (* 1 = 0.0153159 loss)
I1005 23:20:02.015276 10142 sgd_solver.cpp:105] Iteration 68700, lr = 0.01
I1005 23:20:09.675618 10142 solver.cpp:218] Iteration 68800 (13.0543 iter/s, 7.66033s/100 iters), loss = 0.0482269
I1005 23:20:09.675731 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0482266 (* 1 = 0.0482266 loss)
I1005 23:20:09.675750 10142 sgd_solver.cpp:105] Iteration 68800, lr = 0.01
I1005 23:20:17.330119 10142 solver.cpp:218] Iteration 68900 (13.0645 iter/s, 7.65434s/100 iters), loss = 0.0421781
I1005 23:20:17.330149 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0421779 (* 1 = 0.0421779 loss)
I1005 23:20:17.330155 10142 sgd_solver.cpp:105] Iteration 68900, lr = 0.01
I1005 23:20:24.608229 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:20:24.918170 10142 solver.cpp:330] Iteration 69000, Testing net (#0)
I1005 23:20:26.658824 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:20:26.731992 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9148
I1005 23:20:26.732025 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.352943 (* 1 = 0.352943 loss)
I1005 23:20:26.808897 10142 solver.cpp:218] Iteration 69000 (10.5499 iter/s, 9.47872s/100 iters), loss = 0.0134004
I1005 23:20:26.808923 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0134002 (* 1 = 0.0134002 loss)
I1005 23:20:26.808928 10142 sgd_solver.cpp:105] Iteration 69000, lr = 0.01
I1005 23:20:34.471209 10142 solver.cpp:218] Iteration 69100 (13.051 iter/s, 7.66225s/100 iters), loss = 0.0270376
I1005 23:20:34.471238 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0270374 (* 1 = 0.0270374 loss)
I1005 23:20:34.471246 10142 sgd_solver.cpp:105] Iteration 69100, lr = 0.01
I1005 23:20:42.112853 10142 solver.cpp:218] Iteration 69200 (13.0863 iter/s, 7.64159s/100 iters), loss = 0.0234549
I1005 23:20:42.113008 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0234546 (* 1 = 0.0234546 loss)
I1005 23:20:42.113029 10142 sgd_solver.cpp:105] Iteration 69200, lr = 0.01
I1005 23:20:49.770880 10142 solver.cpp:218] Iteration 69300 (13.0585 iter/s, 7.65786s/100 iters), loss = 0.0180376
I1005 23:20:49.770921 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0180374 (* 1 = 0.0180374 loss)
I1005 23:20:49.770927 10142 sgd_solver.cpp:105] Iteration 69300, lr = 0.01
I1005 23:20:57.426439 10142 solver.cpp:218] Iteration 69400 (13.0625 iter/s, 7.65549s/100 iters), loss = 0.00222447
I1005 23:20:57.426470 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00222423 (* 1 = 0.00222423 loss)
I1005 23:20:57.426476 10142 sgd_solver.cpp:105] Iteration 69400, lr = 0.01
I1005 23:21:04.713332 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:21:05.019349 10142 solver.cpp:330] Iteration 69500, Testing net (#0)
I1005 23:21:06.767184 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:21:06.839927 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9172
I1005 23:21:06.839964 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.337504 (* 1 = 0.337504 loss)
I1005 23:21:06.917067 10142 solver.cpp:218] Iteration 69500 (10.5368 iter/s, 9.49057s/100 iters), loss = 0.00953321
I1005 23:21:06.917101 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00953297 (* 1 = 0.00953297 loss)
I1005 23:21:06.917109 10142 sgd_solver.cpp:105] Iteration 69500, lr = 0.01
I1005 23:21:14.563571 10142 solver.cpp:218] Iteration 69600 (13.078 iter/s, 7.64645s/100 iters), loss = 0.015032
I1005 23:21:14.563642 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0150318 (* 1 = 0.0150318 loss)
I1005 23:21:14.563650 10142 sgd_solver.cpp:105] Iteration 69600, lr = 0.01
I1005 23:21:22.221676 10142 solver.cpp:218] Iteration 69700 (13.0582 iter/s, 7.65801s/100 iters), loss = 0.00205395
I1005 23:21:22.221706 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00205372 (* 1 = 0.00205372 loss)
I1005 23:21:22.221712 10142 sgd_solver.cpp:105] Iteration 69700, lr = 0.01
I1005 23:21:29.865384 10142 solver.cpp:218] Iteration 69800 (13.0827 iter/s, 7.64365s/100 iters), loss = 0.00738696
I1005 23:21:29.865414 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00738673 (* 1 = 0.00738673 loss)
I1005 23:21:29.865420 10142 sgd_solver.cpp:105] Iteration 69800, lr = 0.01
I1005 23:21:37.518658 10142 solver.cpp:218] Iteration 69900 (13.0664 iter/s, 7.65322s/100 iters), loss = 0.0228747
I1005 23:21:37.518687 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0228745 (* 1 = 0.0228745 loss)
I1005 23:21:37.518693 10142 sgd_solver.cpp:105] Iteration 69900, lr = 0.01
I1005 23:21:44.788457 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:21:45.094311 10142 solver.cpp:330] Iteration 70000, Testing net (#0)
I1005 23:21:46.844684 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:21:46.917536 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9192
I1005 23:21:46.917572 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.334854 (* 1 = 0.334854 loss)
I1005 23:21:46.994904 10142 solver.cpp:218] Iteration 70000 (10.5528 iter/s, 9.47619s/100 iters), loss = 0.00203665
I1005 23:21:46.994935 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00203641 (* 1 = 0.00203641 loss)
I1005 23:21:46.994941 10142 sgd_solver.cpp:105] Iteration 70000, lr = 0.01
I1005 23:21:54.661692 10142 solver.cpp:218] Iteration 70100 (13.0434 iter/s, 7.66673s/100 iters), loss = 0.0065325
I1005 23:21:54.661728 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00653226 (* 1 = 0.00653226 loss)
I1005 23:21:54.661736 10142 sgd_solver.cpp:105] Iteration 70100, lr = 0.01
I1005 23:22:02.312801 10142 solver.cpp:218] Iteration 70200 (13.0701 iter/s, 7.65105s/100 iters), loss = 0.0497792
I1005 23:22:02.312842 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0497789 (* 1 = 0.0497789 loss)
I1005 23:22:02.312849 10142 sgd_solver.cpp:105] Iteration 70200, lr = 0.01
I1005 23:22:09.973750 10142 solver.cpp:218] Iteration 70300 (13.0533 iter/s, 7.66089s/100 iters), loss = 0.00205632
I1005 23:22:09.973781 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00205608 (* 1 = 0.00205608 loss)
I1005 23:22:09.973788 10142 sgd_solver.cpp:105] Iteration 70300, lr = 0.01
I1005 23:22:17.626013 10142 solver.cpp:218] Iteration 70400 (13.0681 iter/s, 7.65221s/100 iters), loss = 0.00155522
I1005 23:22:17.626137 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00155498 (* 1 = 0.00155498 loss)
I1005 23:22:17.626145 10142 sgd_solver.cpp:105] Iteration 70400, lr = 0.01
I1005 23:22:24.901206 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:22:25.207700 10142 solver.cpp:330] Iteration 70500, Testing net (#0)
I1005 23:22:26.947284 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:22:27.020423 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9174
I1005 23:22:27.020458 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.338662 (* 1 = 0.338662 loss)
I1005 23:22:27.097304 10142 solver.cpp:218] Iteration 70500 (10.5584 iter/s, 9.47114s/100 iters), loss = 0.00476496
I1005 23:22:27.097337 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00476472 (* 1 = 0.00476472 loss)
I1005 23:22:27.097344 10142 sgd_solver.cpp:105] Iteration 70500, lr = 0.01
I1005 23:22:34.761615 10142 solver.cpp:218] Iteration 70600 (13.0476 iter/s, 7.66426s/100 iters), loss = 0.00957183
I1005 23:22:34.761656 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00957159 (* 1 = 0.00957159 loss)
I1005 23:22:34.761660 10142 sgd_solver.cpp:105] Iteration 70600, lr = 0.01
I1005 23:22:42.407999 10142 solver.cpp:218] Iteration 70700 (13.0782 iter/s, 7.64632s/100 iters), loss = 0.0108753
I1005 23:22:42.408030 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.010875 (* 1 = 0.010875 loss)
I1005 23:22:42.408035 10142 sgd_solver.cpp:105] Iteration 70700, lr = 0.01
I1005 23:22:50.069125 10142 solver.cpp:218] Iteration 70800 (13.053 iter/s, 7.66107s/100 iters), loss = 0.0284559
I1005 23:22:50.069272 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0284557 (* 1 = 0.0284557 loss)
I1005 23:22:50.069279 10142 sgd_solver.cpp:105] Iteration 70800, lr = 0.01
I1005 23:22:57.728695 10142 solver.cpp:218] Iteration 70900 (13.0559 iter/s, 7.6594s/100 iters), loss = 0.0226816
I1005 23:22:57.728742 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0226814 (* 1 = 0.0226814 loss)
I1005 23:22:57.728749 10142 sgd_solver.cpp:105] Iteration 70900, lr = 0.01
I1005 23:23:05.002104 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:23:05.307507 10142 solver.cpp:330] Iteration 71000, Testing net (#0)
I1005 23:23:07.054735 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:23:07.127616 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9168
I1005 23:23:07.127652 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.35011 (* 1 = 0.35011 loss)
I1005 23:23:07.204449 10142 solver.cpp:218] Iteration 71000 (10.5534 iter/s, 9.47565s/100 iters), loss = 0.0162319
I1005 23:23:07.204478 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0162317 (* 1 = 0.0162317 loss)
I1005 23:23:07.204485 10142 sgd_solver.cpp:105] Iteration 71000, lr = 0.01
I1005 23:23:14.851704 10142 solver.cpp:218] Iteration 71100 (13.0767 iter/s, 7.6472s/100 iters), loss = 0.0107617
I1005 23:23:14.851745 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0107614 (* 1 = 0.0107614 loss)
I1005 23:23:14.851752 10142 sgd_solver.cpp:105] Iteration 71100, lr = 0.01
I1005 23:23:22.510403 10142 solver.cpp:218] Iteration 71200 (13.0572 iter/s, 7.65863s/100 iters), loss = 0.00859239
I1005 23:23:22.510571 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00859216 (* 1 = 0.00859216 loss)
I1005 23:23:22.510579 10142 sgd_solver.cpp:105] Iteration 71200, lr = 0.01
I1005 23:23:30.162420 10142 solver.cpp:218] Iteration 71300 (13.0688 iter/s, 7.65183s/100 iters), loss = 0.00448661
I1005 23:23:30.162449 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00448638 (* 1 = 0.00448638 loss)
I1005 23:23:30.162456 10142 sgd_solver.cpp:105] Iteration 71300, lr = 0.01
I1005 23:23:37.827031 10142 solver.cpp:218] Iteration 71400 (13.0471 iter/s, 7.66456s/100 iters), loss = 0.00559071
I1005 23:23:37.827071 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00559047 (* 1 = 0.00559047 loss)
I1005 23:23:37.827077 10142 sgd_solver.cpp:105] Iteration 71400, lr = 0.01
I1005 23:23:45.087159 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:23:45.392395 10142 solver.cpp:330] Iteration 71500, Testing net (#0)
I1005 23:23:47.138878 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:23:47.212075 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9095
I1005 23:23:47.212106 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.385365 (* 1 = 0.385365 loss)
I1005 23:23:47.287773 10142 solver.cpp:218] Iteration 71500 (10.5701 iter/s, 9.46068s/100 iters), loss = 0.000766156
I1005 23:23:47.287806 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000765911 (* 1 = 0.000765911 loss)
I1005 23:23:47.287816 10142 sgd_solver.cpp:105] Iteration 71500, lr = 0.01
I1005 23:23:54.932384 10142 solver.cpp:218] Iteration 71600 (13.0812 iter/s, 7.64455s/100 iters), loss = 0.00610624
I1005 23:23:54.932502 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.006106 (* 1 = 0.006106 loss)
I1005 23:23:54.932509 10142 sgd_solver.cpp:105] Iteration 71600, lr = 0.01
I1005 23:24:02.573362 10142 solver.cpp:218] Iteration 71700 (13.0876 iter/s, 7.64084s/100 iters), loss = 0.0051475
I1005 23:24:02.573392 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00514726 (* 1 = 0.00514726 loss)
I1005 23:24:02.573398 10142 sgd_solver.cpp:105] Iteration 71700, lr = 0.01
I1005 23:24:10.226068 10142 solver.cpp:218] Iteration 71800 (13.0674 iter/s, 7.65265s/100 iters), loss = 0.0354045
I1005 23:24:10.226099 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0354043 (* 1 = 0.0354043 loss)
I1005 23:24:10.226104 10142 sgd_solver.cpp:105] Iteration 71800, lr = 0.01
I1005 23:24:17.871042 10142 solver.cpp:218] Iteration 71900 (13.0806 iter/s, 7.64492s/100 iters), loss = 0.00728985
I1005 23:24:17.871073 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00728962 (* 1 = 0.00728962 loss)
I1005 23:24:17.871078 10142 sgd_solver.cpp:105] Iteration 71900, lr = 0.01
I1005 23:24:25.143748 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:24:25.449353 10142 solver.cpp:330] Iteration 72000, Testing net (#0)
I1005 23:24:27.187949 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:24:27.261186 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9185
I1005 23:24:27.261211 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.328815 (* 1 = 0.328815 loss)
I1005 23:24:27.337662 10142 solver.cpp:218] Iteration 72000 (10.5635 iter/s, 9.46656s/100 iters), loss = 0.00456792
I1005 23:24:27.337694 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00456769 (* 1 = 0.00456769 loss)
I1005 23:24:27.337702 10142 sgd_solver.cpp:105] Iteration 72000, lr = 0.01
I1005 23:24:35.004237 10142 solver.cpp:218] Iteration 72100 (13.0437 iter/s, 7.66652s/100 iters), loss = 0.017691
I1005 23:24:35.004268 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0176908 (* 1 = 0.0176908 loss)
I1005 23:24:35.004274 10142 sgd_solver.cpp:105] Iteration 72100, lr = 0.01
I1005 23:24:42.658140 10142 solver.cpp:218] Iteration 72200 (13.0653 iter/s, 7.65384s/100 iters), loss = 0.00913329
I1005 23:24:42.658176 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00913306 (* 1 = 0.00913306 loss)
I1005 23:24:42.658183 10142 sgd_solver.cpp:105] Iteration 72200, lr = 0.01
I1005 23:24:50.317818 10142 solver.cpp:218] Iteration 72300 (13.0555 iter/s, 7.65961s/100 iters), loss = 0.0403658
I1005 23:24:50.317858 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0403655 (* 1 = 0.0403655 loss)
I1005 23:24:50.317864 10142 sgd_solver.cpp:105] Iteration 72300, lr = 0.01
I1005 23:24:57.984657 10142 solver.cpp:218] Iteration 72400 (13.0433 iter/s, 7.66677s/100 iters), loss = 0.00277663
I1005 23:24:57.984750 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0027764 (* 1 = 0.0027764 loss)
I1005 23:24:57.984758 10142 sgd_solver.cpp:105] Iteration 72400, lr = 0.01
I1005 23:25:05.268376 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:25:05.574370 10142 solver.cpp:330] Iteration 72500, Testing net (#0)
I1005 23:25:07.322993 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:25:07.395964 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9179
I1005 23:25:07.396000 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.327044 (* 1 = 0.327044 loss)
I1005 23:25:07.473120 10142 solver.cpp:218] Iteration 72500 (10.5392 iter/s, 9.48835s/100 iters), loss = 0.00816073
I1005 23:25:07.473153 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0081605 (* 1 = 0.0081605 loss)
I1005 23:25:07.473160 10142 sgd_solver.cpp:105] Iteration 72500, lr = 0.01
I1005 23:25:15.135998 10142 solver.cpp:218] Iteration 72600 (13.05 iter/s, 7.66282s/100 iters), loss = 0.00206002
I1005 23:25:15.136039 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00205978 (* 1 = 0.00205978 loss)
I1005 23:25:15.136044 10142 sgd_solver.cpp:105] Iteration 72600, lr = 0.01
I1005 23:25:22.794066 10142 solver.cpp:218] Iteration 72700 (13.0582 iter/s, 7.658s/100 iters), loss = 0.0128351
I1005 23:25:22.794113 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0128349 (* 1 = 0.0128349 loss)
I1005 23:25:22.794121 10142 sgd_solver.cpp:105] Iteration 72700, lr = 0.01
I1005 23:25:30.439050 10142 solver.cpp:218] Iteration 72800 (13.0806 iter/s, 7.64491s/100 iters), loss = 0.00832274
I1005 23:25:30.439194 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00832251 (* 1 = 0.00832251 loss)
I1005 23:25:30.439203 10142 sgd_solver.cpp:105] Iteration 72800, lr = 0.01
I1005 23:25:38.108814 10142 solver.cpp:218] Iteration 72900 (13.0385 iter/s, 7.6696s/100 iters), loss = 0.00317676
I1005 23:25:38.108844 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00317653 (* 1 = 0.00317653 loss)
I1005 23:25:38.108851 10142 sgd_solver.cpp:105] Iteration 72900, lr = 0.01
I1005 23:25:45.389458 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:25:45.704979 10142 solver.cpp:330] Iteration 73000, Testing net (#0)
I1005 23:25:47.446113 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:25:47.519341 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9176
I1005 23:25:47.519366 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.344575 (* 1 = 0.344575 loss)
I1005 23:25:47.596401 10142 solver.cpp:218] Iteration 73000 (10.5401 iter/s, 9.48753s/100 iters), loss = 0.00430305
I1005 23:25:47.596431 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00430281 (* 1 = 0.00430281 loss)
I1005 23:25:47.596437 10142 sgd_solver.cpp:105] Iteration 73000, lr = 0.01
I1005 23:25:55.264572 10142 solver.cpp:218] Iteration 73100 (13.041 iter/s, 7.66811s/100 iters), loss = 0.0114079
I1005 23:25:55.264605 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0114076 (* 1 = 0.0114076 loss)
I1005 23:25:55.264621 10142 sgd_solver.cpp:105] Iteration 73100, lr = 0.01
I1005 23:26:02.916985 10142 solver.cpp:218] Iteration 73200 (13.0679 iter/s, 7.65236s/100 iters), loss = 0.0115963
I1005 23:26:02.917127 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.011596 (* 1 = 0.011596 loss)
I1005 23:26:02.917135 10142 sgd_solver.cpp:105] Iteration 73200, lr = 0.01
I1005 23:26:10.579865 10142 solver.cpp:218] Iteration 73300 (13.0502 iter/s, 7.66273s/100 iters), loss = 0.019196
I1005 23:26:10.579896 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0191958 (* 1 = 0.0191958 loss)
I1005 23:26:10.579912 10142 sgd_solver.cpp:105] Iteration 73300, lr = 0.01
I1005 23:26:18.233216 10142 solver.cpp:218] Iteration 73400 (13.0663 iter/s, 7.6533s/100 iters), loss = 0.0081602
I1005 23:26:18.233247 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00815995 (* 1 = 0.00815995 loss)
I1005 23:26:18.233253 10142 sgd_solver.cpp:105] Iteration 73400, lr = 0.01
I1005 23:26:25.512625 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:26:25.819736 10142 solver.cpp:330] Iteration 73500, Testing net (#0)
I1005 23:26:27.563791 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:26:27.638907 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9189
I1005 23:26:27.638936 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.334101 (* 1 = 0.334101 loss)
I1005 23:26:27.718343 10142 solver.cpp:218] Iteration 73500 (10.5429 iter/s, 9.48507s/100 iters), loss = 0.00158325
I1005 23:26:27.718379 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00158301 (* 1 = 0.00158301 loss)
I1005 23:26:27.718385 10142 sgd_solver.cpp:105] Iteration 73500, lr = 0.01
I1005 23:26:35.374547 10142 solver.cpp:218] Iteration 73600 (13.0614 iter/s, 7.65615s/100 iters), loss = 0.0208467
I1005 23:26:35.374626 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0208465 (* 1 = 0.0208465 loss)
I1005 23:26:35.374634 10142 sgd_solver.cpp:105] Iteration 73600, lr = 0.01
I1005 23:26:43.037487 10142 solver.cpp:218] Iteration 73700 (13.05 iter/s, 7.66283s/100 iters), loss = 0.00386578
I1005 23:26:43.037518 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00386554 (* 1 = 0.00386554 loss)
I1005 23:26:43.037525 10142 sgd_solver.cpp:105] Iteration 73700, lr = 0.01
I1005 23:26:50.690944 10142 solver.cpp:218] Iteration 73800 (13.0661 iter/s, 7.6534s/100 iters), loss = 0.00558177
I1005 23:26:50.690984 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00558154 (* 1 = 0.00558154 loss)
I1005 23:26:50.690991 10142 sgd_solver.cpp:105] Iteration 73800, lr = 0.01
I1005 23:26:58.347649 10142 solver.cpp:218] Iteration 73900 (13.0606 iter/s, 7.65664s/100 iters), loss = 0.00436626
I1005 23:26:58.347681 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00436602 (* 1 = 0.00436602 loss)
I1005 23:26:58.347697 10142 sgd_solver.cpp:105] Iteration 73900, lr = 0.01
I1005 23:27:05.617022 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:27:05.923621 10142 solver.cpp:330] Iteration 74000, Testing net (#0)
I1005 23:27:07.671339 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:27:07.744551 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9049
I1005 23:27:07.744587 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.389334 (* 1 = 0.389334 loss)
I1005 23:27:07.821784 10142 solver.cpp:218] Iteration 74000 (10.5551 iter/s, 9.47408s/100 iters), loss = 0.00312223
I1005 23:27:07.821810 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00312198 (* 1 = 0.00312198 loss)
I1005 23:27:07.821818 10142 sgd_solver.cpp:105] Iteration 74000, lr = 0.01
I1005 23:27:15.477319 10142 solver.cpp:218] Iteration 74100 (13.0625 iter/s, 7.65548s/100 iters), loss = 0.00939378
I1005 23:27:15.477351 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00939354 (* 1 = 0.00939354 loss)
I1005 23:27:15.477358 10142 sgd_solver.cpp:105] Iteration 74100, lr = 0.01
I1005 23:27:23.139330 10142 solver.cpp:218] Iteration 74200 (13.0515 iter/s, 7.66195s/100 iters), loss = 0.0401597
I1005 23:27:23.139359 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0401595 (* 1 = 0.0401595 loss)
I1005 23:27:23.139365 10142 sgd_solver.cpp:105] Iteration 74200, lr = 0.01
I1005 23:27:30.807060 10142 solver.cpp:218] Iteration 74300 (13.0418 iter/s, 7.66767s/100 iters), loss = 0.00472601
I1005 23:27:30.807095 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00472578 (* 1 = 0.00472578 loss)
I1005 23:27:30.807111 10142 sgd_solver.cpp:105] Iteration 74300, lr = 0.01
I1005 23:27:38.461063 10142 solver.cpp:218] Iteration 74400 (13.0652 iter/s, 7.65395s/100 iters), loss = 0.039406
I1005 23:27:38.461213 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0394057 (* 1 = 0.0394057 loss)
I1005 23:27:38.461230 10142 sgd_solver.cpp:105] Iteration 74400, lr = 0.01
I1005 23:27:45.742964 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:27:46.049851 10142 solver.cpp:330] Iteration 74500, Testing net (#0)
I1005 23:27:47.789752 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:27:47.862888 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9185
I1005 23:27:47.862922 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.335674 (* 1 = 0.335674 loss)
I1005 23:27:47.939671 10142 solver.cpp:218] Iteration 74500 (10.5503 iter/s, 9.47844s/100 iters), loss = 0.00512049
I1005 23:27:47.939700 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00512026 (* 1 = 0.00512026 loss)
I1005 23:27:47.939707 10142 sgd_solver.cpp:105] Iteration 74500, lr = 0.01
I1005 23:27:55.595788 10142 solver.cpp:218] Iteration 74600 (13.0615 iter/s, 7.65606s/100 iters), loss = 0.00443403
I1005 23:27:55.595818 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00443381 (* 1 = 0.00443381 loss)
I1005 23:27:55.595834 10142 sgd_solver.cpp:105] Iteration 74600, lr = 0.01
I1005 23:28:03.250177 10142 solver.cpp:218] Iteration 74700 (13.0645 iter/s, 7.65434s/100 iters), loss = 0.0451324
I1005 23:28:03.250207 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0451322 (* 1 = 0.0451322 loss)
I1005 23:28:03.250213 10142 sgd_solver.cpp:105] Iteration 74700, lr = 0.01
I1005 23:28:10.916528 10142 solver.cpp:218] Iteration 74800 (13.0441 iter/s, 7.6663s/100 iters), loss = 0.00459931
I1005 23:28:10.916645 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00459908 (* 1 = 0.00459908 loss)
I1005 23:28:10.916651 10142 sgd_solver.cpp:105] Iteration 74800, lr = 0.01
I1005 23:28:18.575935 10142 solver.cpp:218] Iteration 74900 (13.0561 iter/s, 7.65927s/100 iters), loss = 0.00287281
I1005 23:28:18.575973 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00287259 (* 1 = 0.00287259 loss)
I1005 23:28:18.575980 10142 sgd_solver.cpp:105] Iteration 74900, lr = 0.01
I1005 23:28:25.856454 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:28:26.163008 10142 solver.cpp:330] Iteration 75000, Testing net (#0)
I1005 23:28:27.909687 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:28:27.982998 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9153
I1005 23:28:27.983036 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.334702 (* 1 = 0.334702 loss)
I1005 23:28:28.060106 10142 solver.cpp:218] Iteration 75000 (10.544 iter/s, 9.48408s/100 iters), loss = 0.00673666
I1005 23:28:28.060138 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00673644 (* 1 = 0.00673644 loss)
I1005 23:28:28.060147 10142 sgd_solver.cpp:105] Iteration 75000, lr = 0.01
I1005 23:28:35.709331 10142 solver.cpp:218] Iteration 75100 (13.0733 iter/s, 7.64917s/100 iters), loss = 0.0137027
I1005 23:28:35.709372 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0137024 (* 1 = 0.0137024 loss)
I1005 23:28:35.709378 10142 sgd_solver.cpp:105] Iteration 75100, lr = 0.01
I1005 23:28:43.364038 10142 solver.cpp:218] Iteration 75200 (13.064 iter/s, 7.65464s/100 iters), loss = 0.00511882
I1005 23:28:43.364176 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00511859 (* 1 = 0.00511859 loss)
I1005 23:28:43.364182 10142 sgd_solver.cpp:105] Iteration 75200, lr = 0.01
I1005 23:28:51.021708 10142 solver.cpp:218] Iteration 75300 (13.0591 iter/s, 7.65751s/100 iters), loss = 0.021521
I1005 23:28:51.021737 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0215208 (* 1 = 0.0215208 loss)
I1005 23:28:51.021744 10142 sgd_solver.cpp:105] Iteration 75300, lr = 0.01
I1005 23:28:58.682765 10142 solver.cpp:218] Iteration 75400 (13.0531 iter/s, 7.661s/100 iters), loss = 0.00549732
I1005 23:28:58.682795 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0054971 (* 1 = 0.0054971 loss)
I1005 23:28:58.682801 10142 sgd_solver.cpp:105] Iteration 75400, lr = 0.01
I1005 23:29:05.964046 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:29:06.270671 10142 solver.cpp:330] Iteration 75500, Testing net (#0)
I1005 23:29:08.020464 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:29:08.093380 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9111
I1005 23:29:08.093415 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.370998 (* 1 = 0.370998 loss)
I1005 23:29:08.170855 10142 solver.cpp:218] Iteration 75500 (10.5396 iter/s, 9.48804s/100 iters), loss = 0.017825
I1005 23:29:08.170881 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0178247 (* 1 = 0.0178247 loss)
I1005 23:29:08.170887 10142 sgd_solver.cpp:105] Iteration 75500, lr = 0.01
I1005 23:29:15.833916 10142 solver.cpp:218] Iteration 75600 (13.0497 iter/s, 7.66301s/100 iters), loss = 0.00783777
I1005 23:29:15.834034 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00783753 (* 1 = 0.00783753 loss)
I1005 23:29:15.834043 10142 sgd_solver.cpp:105] Iteration 75600, lr = 0.01
I1005 23:29:23.483125 10142 solver.cpp:218] Iteration 75700 (13.0735 iter/s, 7.64907s/100 iters), loss = 0.0181252
I1005 23:29:23.483155 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.018125 (* 1 = 0.018125 loss)
I1005 23:29:23.483160 10142 sgd_solver.cpp:105] Iteration 75700, lr = 0.01
I1005 23:29:31.132418 10142 solver.cpp:218] Iteration 75800 (13.0732 iter/s, 7.64924s/100 iters), loss = 0.00338509
I1005 23:29:31.132448 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00338486 (* 1 = 0.00338486 loss)
I1005 23:29:31.132455 10142 sgd_solver.cpp:105] Iteration 75800, lr = 0.01
I1005 23:29:38.794638 10142 solver.cpp:218] Iteration 75900 (13.0511 iter/s, 7.66217s/100 iters), loss = 0.0140141
I1005 23:29:38.794679 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0140139 (* 1 = 0.0140139 loss)
I1005 23:29:38.794685 10142 sgd_solver.cpp:105] Iteration 75900, lr = 0.01
I1005 23:29:46.084377 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:29:46.391482 10142 solver.cpp:330] Iteration 76000, Testing net (#0)
I1005 23:29:48.130117 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:29:48.203140 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9165
I1005 23:29:48.203176 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.339037 (* 1 = 0.339037 loss)
I1005 23:29:48.280459 10142 solver.cpp:218] Iteration 76000 (10.5421 iter/s, 9.48575s/100 iters), loss = 0.0420527
I1005 23:29:48.280493 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0420524 (* 1 = 0.0420524 loss)
I1005 23:29:48.280499 10142 sgd_solver.cpp:105] Iteration 76000, lr = 0.01
I1005 23:29:55.953589 10142 solver.cpp:218] Iteration 76100 (13.0326 iter/s, 7.67307s/100 iters), loss = 0.00885953
I1005 23:29:55.953619 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0088593 (* 1 = 0.0088593 loss)
I1005 23:29:55.953625 10142 sgd_solver.cpp:105] Iteration 76100, lr = 0.01
I1005 23:30:03.607291 10142 solver.cpp:218] Iteration 76200 (13.0657 iter/s, 7.65365s/100 iters), loss = 0.00351265
I1005 23:30:03.607331 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00351242 (* 1 = 0.00351242 loss)
I1005 23:30:03.607348 10142 sgd_solver.cpp:105] Iteration 76200, lr = 0.01
I1005 23:30:11.265019 10142 solver.cpp:218] Iteration 76300 (13.0588 iter/s, 7.65767s/100 iters), loss = 0.00886095
I1005 23:30:11.265049 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00886072 (* 1 = 0.00886072 loss)
I1005 23:30:11.265055 10142 sgd_solver.cpp:105] Iteration 76300, lr = 0.01
I1005 23:30:18.918895 10142 solver.cpp:218] Iteration 76400 (13.0654 iter/s, 7.65382s/100 iters), loss = 0.0404331
I1005 23:30:18.919028 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0404328 (* 1 = 0.0404328 loss)
I1005 23:30:18.919034 10142 sgd_solver.cpp:105] Iteration 76400, lr = 0.01
I1005 23:30:26.196934 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:30:26.502740 10142 solver.cpp:330] Iteration 76500, Testing net (#0)
I1005 23:30:28.251910 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:30:28.325079 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9098
I1005 23:30:28.325114 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.362356 (* 1 = 0.362356 loss)
I1005 23:30:28.401711 10142 solver.cpp:218] Iteration 76500 (10.5456 iter/s, 9.48267s/100 iters), loss = 0.00787099
I1005 23:30:28.401746 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00787076 (* 1 = 0.00787076 loss)
I1005 23:30:28.401753 10142 sgd_solver.cpp:105] Iteration 76500, lr = 0.01
I1005 23:30:36.057446 10142 solver.cpp:218] Iteration 76600 (13.0622 iter/s, 7.65568s/100 iters), loss = 0.00331511
I1005 23:30:36.057476 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00331488 (* 1 = 0.00331488 loss)
I1005 23:30:36.057482 10142 sgd_solver.cpp:105] Iteration 76600, lr = 0.01
I1005 23:30:43.716437 10142 solver.cpp:218] Iteration 76700 (13.0566 iter/s, 7.65894s/100 iters), loss = 0.00774137
I1005 23:30:43.716477 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00774116 (* 1 = 0.00774116 loss)
I1005 23:30:43.716483 10142 sgd_solver.cpp:105] Iteration 76700, lr = 0.01
I1005 23:30:51.369108 10142 solver.cpp:218] Iteration 76800 (13.0674 iter/s, 7.65261s/100 iters), loss = 0.00742622
I1005 23:30:51.369220 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00742601 (* 1 = 0.00742601 loss)
I1005 23:30:51.369235 10142 sgd_solver.cpp:105] Iteration 76800, lr = 0.01
I1005 23:30:59.027185 10142 solver.cpp:218] Iteration 76900 (13.0583 iter/s, 7.65796s/100 iters), loss = 0.0157153
I1005 23:30:59.027216 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0157151 (* 1 = 0.0157151 loss)
I1005 23:30:59.027222 10142 sgd_solver.cpp:105] Iteration 76900, lr = 0.01
I1005 23:31:06.294865 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:31:06.604346 10142 solver.cpp:330] Iteration 77000, Testing net (#0)
I1005 23:31:08.348242 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:31:08.421265 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9063
I1005 23:31:08.421300 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.384743 (* 1 = 0.384743 loss)
I1005 23:31:08.498432 10142 solver.cpp:218] Iteration 77000 (10.5583 iter/s, 9.47119s/100 iters), loss = 0.00122968
I1005 23:31:08.498459 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00122947 (* 1 = 0.00122947 loss)
I1005 23:31:08.498466 10142 sgd_solver.cpp:105] Iteration 77000, lr = 0.01
I1005 23:31:16.165451 10142 solver.cpp:218] Iteration 77100 (13.043 iter/s, 7.66697s/100 iters), loss = 0.0233073
I1005 23:31:16.165482 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0233071 (* 1 = 0.0233071 loss)
I1005 23:31:16.165498 10142 sgd_solver.cpp:105] Iteration 77100, lr = 0.01
I1005 23:31:23.819967 10142 solver.cpp:218] Iteration 77200 (13.0643 iter/s, 7.65446s/100 iters), loss = 0.00605619
I1005 23:31:23.820101 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00605597 (* 1 = 0.00605597 loss)
I1005 23:31:23.820107 10142 sgd_solver.cpp:105] Iteration 77200, lr = 0.01
I1005 23:31:31.492686 10142 solver.cpp:218] Iteration 77300 (13.0334 iter/s, 7.67257s/100 iters), loss = 0.00584194
I1005 23:31:31.492715 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00584171 (* 1 = 0.00584171 loss)
I1005 23:31:31.492733 10142 sgd_solver.cpp:105] Iteration 77300, lr = 0.01
I1005 23:31:39.149420 10142 solver.cpp:218] Iteration 77400 (13.0605 iter/s, 7.65668s/100 iters), loss = 0.00489186
I1005 23:31:39.149448 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00489162 (* 1 = 0.00489162 loss)
I1005 23:31:39.149454 10142 sgd_solver.cpp:105] Iteration 77400, lr = 0.01
I1005 23:31:46.436810 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:31:46.743919 10142 solver.cpp:330] Iteration 77500, Testing net (#0)
I1005 23:31:48.482663 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:31:48.557201 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9139
I1005 23:31:48.557229 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.367521 (* 1 = 0.367521 loss)
I1005 23:31:48.635325 10142 solver.cpp:218] Iteration 77500 (10.542 iter/s, 9.48585s/100 iters), loss = 0.0155357
I1005 23:31:48.635361 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0155354 (* 1 = 0.0155354 loss)
I1005 23:31:48.635368 10142 sgd_solver.cpp:105] Iteration 77500, lr = 0.01
I1005 23:31:56.282402 10142 solver.cpp:218] Iteration 77600 (13.077 iter/s, 7.64702s/100 iters), loss = 0.0128263
I1005 23:31:56.282513 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0128261 (* 1 = 0.0128261 loss)
I1005 23:31:56.282536 10142 sgd_solver.cpp:105] Iteration 77600, lr = 0.01
I1005 23:32:03.946084 10142 solver.cpp:218] Iteration 77700 (13.0488 iter/s, 7.66356s/100 iters), loss = 0.00348685
I1005 23:32:03.946115 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00348661 (* 1 = 0.00348661 loss)
I1005 23:32:03.946120 10142 sgd_solver.cpp:105] Iteration 77700, lr = 0.01
I1005 23:32:11.596145 10142 solver.cpp:218] Iteration 77800 (13.0719 iter/s, 7.65001s/100 iters), loss = 0.0465531
I1005 23:32:11.596176 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0465529 (* 1 = 0.0465529 loss)
I1005 23:32:11.596195 10142 sgd_solver.cpp:105] Iteration 77800, lr = 0.01
I1005 23:32:19.262526 10142 solver.cpp:218] Iteration 77900 (13.0441 iter/s, 7.66632s/100 iters), loss = 0.0166258
I1005 23:32:19.262558 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0166256 (* 1 = 0.0166256 loss)
I1005 23:32:19.262567 10142 sgd_solver.cpp:105] Iteration 77900, lr = 0.01
I1005 23:32:26.527848 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:32:26.834254 10142 solver.cpp:330] Iteration 78000, Testing net (#0)
I1005 23:32:28.582506 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:32:28.655844 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9148
I1005 23:32:28.655885 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.344457 (* 1 = 0.344457 loss)
I1005 23:32:28.732643 10142 solver.cpp:218] Iteration 78000 (10.5596 iter/s, 9.47006s/100 iters), loss = 0.00826817
I1005 23:32:28.732674 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00826792 (* 1 = 0.00826792 loss)
I1005 23:32:28.732681 10142 sgd_solver.cpp:105] Iteration 78000, lr = 0.01
I1005 23:32:36.385082 10142 solver.cpp:218] Iteration 78100 (13.0678 iter/s, 7.65238s/100 iters), loss = 0.0281364
I1005 23:32:36.385113 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0281362 (* 1 = 0.0281362 loss)
I1005 23:32:36.385119 10142 sgd_solver.cpp:105] Iteration 78100, lr = 0.01
I1005 23:32:44.044529 10142 solver.cpp:218] Iteration 78200 (13.0559 iter/s, 7.65939s/100 iters), loss = 0.0077791
I1005 23:32:44.044558 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00777884 (* 1 = 0.00777884 loss)
I1005 23:32:44.044564 10142 sgd_solver.cpp:105] Iteration 78200, lr = 0.01
I1005 23:32:51.706322 10142 solver.cpp:218] Iteration 78300 (13.0519 iter/s, 7.66174s/100 iters), loss = 0.00711551
I1005 23:32:51.706359 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00711525 (* 1 = 0.00711525 loss)
I1005 23:32:51.706367 10142 sgd_solver.cpp:105] Iteration 78300, lr = 0.01
I1005 23:32:59.356283 10142 solver.cpp:218] Iteration 78400 (13.0721 iter/s, 7.64987s/100 iters), loss = 0.00132513
I1005 23:32:59.356384 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00132488 (* 1 = 0.00132488 loss)
I1005 23:32:59.356400 10142 sgd_solver.cpp:105] Iteration 78400, lr = 0.01
I1005 23:33:06.643384 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:33:06.954284 10142 solver.cpp:330] Iteration 78500, Testing net (#0)
I1005 23:33:08.693256 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:33:08.766543 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9184
I1005 23:33:08.766569 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.315568 (* 1 = 0.315568 loss)
I1005 23:33:08.843704 10142 solver.cpp:218] Iteration 78500 (10.5404 iter/s, 9.4873s/100 iters), loss = 0.0138043
I1005 23:33:08.843731 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.013804 (* 1 = 0.013804 loss)
I1005 23:33:08.843739 10142 sgd_solver.cpp:105] Iteration 78500, lr = 0.01
I1005 23:33:16.500427 10142 solver.cpp:218] Iteration 78600 (13.0605 iter/s, 7.65667s/100 iters), loss = 0.00142944
I1005 23:33:16.500458 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00142918 (* 1 = 0.00142918 loss)
I1005 23:33:16.500464 10142 sgd_solver.cpp:105] Iteration 78600, lr = 0.01
I1005 23:33:24.152040 10142 solver.cpp:218] Iteration 78700 (13.0692 iter/s, 7.65155s/100 iters), loss = 0.0205776
I1005 23:33:24.152067 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0205773 (* 1 = 0.0205773 loss)
I1005 23:33:24.152073 10142 sgd_solver.cpp:105] Iteration 78700, lr = 0.01
I1005 23:33:31.806179 10142 solver.cpp:218] Iteration 78800 (13.0649 iter/s, 7.65408s/100 iters), loss = 0.00856772
I1005 23:33:31.806325 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00856746 (* 1 = 0.00856746 loss)
I1005 23:33:31.806334 10142 sgd_solver.cpp:105] Iteration 78800, lr = 0.01
I1005 23:33:39.454792 10142 solver.cpp:218] Iteration 78900 (13.0746 iter/s, 7.64844s/100 iters), loss = 0.015525
I1005 23:33:39.454823 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0155248 (* 1 = 0.0155248 loss)
I1005 23:33:39.454830 10142 sgd_solver.cpp:105] Iteration 78900, lr = 0.01
I1005 23:33:46.735827 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:33:47.043545 10142 solver.cpp:330] Iteration 79000, Testing net (#0)
I1005 23:33:48.790742 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:33:48.864159 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9138
I1005 23:33:48.864197 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.349202 (* 1 = 0.349202 loss)
I1005 23:33:48.941314 10142 solver.cpp:218] Iteration 79000 (10.5413 iter/s, 9.48646s/100 iters), loss = 0.0248976
I1005 23:33:48.941349 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0248973 (* 1 = 0.0248973 loss)
I1005 23:33:48.941355 10142 sgd_solver.cpp:105] Iteration 79000, lr = 0.01
I1005 23:33:56.605113 10142 solver.cpp:218] Iteration 79100 (13.0485 iter/s, 7.66374s/100 iters), loss = 0.0198425
I1005 23:33:56.605141 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0198423 (* 1 = 0.0198423 loss)
I1005 23:33:56.605147 10142 sgd_solver.cpp:105] Iteration 79100, lr = 0.01
I1005 23:34:04.266487 10142 solver.cpp:218] Iteration 79200 (13.0526 iter/s, 7.66132s/100 iters), loss = 0.00719539
I1005 23:34:04.266656 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00719513 (* 1 = 0.00719513 loss)
I1005 23:34:04.266667 10142 sgd_solver.cpp:105] Iteration 79200, lr = 0.01
I1005 23:34:11.914136 10142 solver.cpp:218] Iteration 79300 (13.0762 iter/s, 7.64746s/100 iters), loss = 0.00205085
I1005 23:34:11.914166 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00205059 (* 1 = 0.00205059 loss)
I1005 23:34:11.914172 10142 sgd_solver.cpp:105] Iteration 79300, lr = 0.01
I1005 23:34:19.570983 10142 solver.cpp:218] Iteration 79400 (13.0603 iter/s, 7.65679s/100 iters), loss = 0.015019
I1005 23:34:19.571023 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0150188 (* 1 = 0.0150188 loss)
I1005 23:34:19.571029 10142 sgd_solver.cpp:105] Iteration 79400, lr = 0.01
I1005 23:34:26.844683 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:34:27.150900 10142 solver.cpp:330] Iteration 79500, Testing net (#0)
I1005 23:34:28.901283 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:34:28.974553 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9001
I1005 23:34:28.974588 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.406412 (* 1 = 0.406412 loss)
I1005 23:34:29.051679 10142 solver.cpp:218] Iteration 79500 (10.5478 iter/s, 9.48063s/100 iters), loss = 0.00144805
I1005 23:34:29.051712 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00144781 (* 1 = 0.00144781 loss)
I1005 23:34:29.051718 10142 sgd_solver.cpp:105] Iteration 79500, lr = 0.01
I1005 23:34:36.711333 10142 solver.cpp:218] Iteration 79600 (13.0555 iter/s, 7.65959s/100 iters), loss = 0.00477165
I1005 23:34:36.711485 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0047714 (* 1 = 0.0047714 loss)
I1005 23:34:36.711495 10142 sgd_solver.cpp:105] Iteration 79600, lr = 0.01
I1005 23:34:44.372489 10142 solver.cpp:218] Iteration 79700 (13.0532 iter/s, 7.66096s/100 iters), loss = 0.0119692
I1005 23:34:44.372519 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.011969 (* 1 = 0.011969 loss)
I1005 23:34:44.372524 10142 sgd_solver.cpp:105] Iteration 79700, lr = 0.01
I1005 23:34:52.035022 10142 solver.cpp:218] Iteration 79800 (13.0506 iter/s, 7.66248s/100 iters), loss = 0.00472821
I1005 23:34:52.035053 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00472797 (* 1 = 0.00472797 loss)
I1005 23:34:52.035059 10142 sgd_solver.cpp:105] Iteration 79800, lr = 0.01
I1005 23:34:59.685492 10142 solver.cpp:218] Iteration 79900 (13.0712 iter/s, 7.65042s/100 iters), loss = 0.000944787
I1005 23:34:59.685523 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000944549 (* 1 = 0.000944549 loss)
I1005 23:34:59.685539 10142 sgd_solver.cpp:105] Iteration 79900, lr = 0.01
I1005 23:35:06.956192 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:35:07.262917 10142 solver.cpp:330] Iteration 80000, Testing net (#0)
I1005 23:35:09.002197 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:35:09.075212 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9126
I1005 23:35:09.075237 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.368672 (* 1 = 0.368672 loss)
I1005 23:35:09.152000 10142 solver.cpp:218] Iteration 80000 (10.5636 iter/s, 9.46645s/100 iters), loss = 0.0151692
I1005 23:35:09.152032 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.015169 (* 1 = 0.015169 loss)
I1005 23:35:09.152040 10142 sgd_solver.cpp:46] MultiStep Status: Iteration 80000, step = 2
I1005 23:35:09.152042 10142 sgd_solver.cpp:105] Iteration 80000, lr = 0.001
I1005 23:35:16.828814 10142 solver.cpp:218] Iteration 80100 (13.0263 iter/s, 7.67676s/100 iters), loss = 0.00571073
I1005 23:35:16.828845 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00571049 (* 1 = 0.00571049 loss)
I1005 23:35:16.828860 10142 sgd_solver.cpp:105] Iteration 80100, lr = 0.001
I1005 23:35:24.488664 10142 solver.cpp:218] Iteration 80200 (13.0552 iter/s, 7.65979s/100 iters), loss = 0.00671816
I1005 23:35:24.488695 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00671791 (* 1 = 0.00671791 loss)
I1005 23:35:24.488711 10142 sgd_solver.cpp:105] Iteration 80200, lr = 0.001
I1005 23:35:32.164654 10142 solver.cpp:218] Iteration 80300 (13.0277 iter/s, 7.67594s/100 iters), loss = 0.00658016
I1005 23:35:32.164683 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00657992 (* 1 = 0.00657992 loss)
I1005 23:35:32.164700 10142 sgd_solver.cpp:105] Iteration 80300, lr = 0.001
I1005 23:35:39.828757 10142 solver.cpp:218] Iteration 80400 (13.0479 iter/s, 7.66405s/100 iters), loss = 0.00190791
I1005 23:35:39.828893 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00190766 (* 1 = 0.00190766 loss)
I1005 23:35:39.828912 10142 sgd_solver.cpp:105] Iteration 80400, lr = 0.001
I1005 23:35:47.104122 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:35:47.409919 10142 solver.cpp:330] Iteration 80500, Testing net (#0)
I1005 23:35:49.157903 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:35:49.230931 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9208
I1005 23:35:49.230967 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.316578 (* 1 = 0.316578 loss)
I1005 23:35:49.308392 10142 solver.cpp:218] Iteration 80500 (10.5491 iter/s, 9.47948s/100 iters), loss = 0.007059
I1005 23:35:49.308423 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00705876 (* 1 = 0.00705876 loss)
I1005 23:35:49.308429 10142 sgd_solver.cpp:105] Iteration 80500, lr = 0.001
I1005 23:35:56.954331 10142 solver.cpp:218] Iteration 80600 (13.0789 iter/s, 7.64589s/100 iters), loss = 0.0091188
I1005 23:35:56.954360 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00911857 (* 1 = 0.00911857 loss)
I1005 23:35:56.954366 10142 sgd_solver.cpp:105] Iteration 80600, lr = 0.001
I1005 23:36:04.615947 10142 solver.cpp:218] Iteration 80700 (13.0522 iter/s, 7.66156s/100 iters), loss = 0.00209882
I1005 23:36:04.615978 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00209859 (* 1 = 0.00209859 loss)
I1005 23:36:04.615993 10142 sgd_solver.cpp:105] Iteration 80700, lr = 0.001
I1005 23:36:12.264467 10142 solver.cpp:218] Iteration 80800 (13.0745 iter/s, 7.64846s/100 iters), loss = 0.00258037
I1005 23:36:12.264574 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00258014 (* 1 = 0.00258014 loss)
I1005 23:36:12.264588 10142 sgd_solver.cpp:105] Iteration 80800, lr = 0.001
I1005 23:36:19.930064 10142 solver.cpp:218] Iteration 80900 (13.0455 iter/s, 7.66547s/100 iters), loss = 0.00226387
I1005 23:36:19.930093 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00226365 (* 1 = 0.00226365 loss)
I1005 23:36:19.930099 10142 sgd_solver.cpp:105] Iteration 80900, lr = 0.001
I1005 23:36:27.205624 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:36:27.511600 10142 solver.cpp:330] Iteration 81000, Testing net (#0)
I1005 23:36:29.259068 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:36:29.331903 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9231
I1005 23:36:29.331938 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.308572 (* 1 = 0.308572 loss)
I1005 23:36:29.409035 10142 solver.cpp:218] Iteration 81000 (10.5497 iter/s, 9.47892s/100 iters), loss = 0.0037389
I1005 23:36:29.409065 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00373867 (* 1 = 0.00373867 loss)
I1005 23:36:29.409071 10142 sgd_solver.cpp:105] Iteration 81000, lr = 0.001
I1005 23:36:37.064865 10142 solver.cpp:218] Iteration 81100 (13.062 iter/s, 7.65578s/100 iters), loss = 0.0075512
I1005 23:36:37.064908 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00755097 (* 1 = 0.00755097 loss)
I1005 23:36:37.064914 10142 sgd_solver.cpp:105] Iteration 81100, lr = 0.001
I1005 23:36:44.711727 10142 solver.cpp:218] Iteration 81200 (13.0774 iter/s, 7.6468s/100 iters), loss = 0.0154486
I1005 23:36:44.711875 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0154484 (* 1 = 0.0154484 loss)
I1005 23:36:44.711892 10142 sgd_solver.cpp:105] Iteration 81200, lr = 0.001
I1005 23:36:52.372373 10142 solver.cpp:218] Iteration 81300 (13.054 iter/s, 7.66048s/100 iters), loss = 0.00271076
I1005 23:36:52.372402 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00271053 (* 1 = 0.00271053 loss)
I1005 23:36:52.372409 10142 sgd_solver.cpp:105] Iteration 81300, lr = 0.001
I1005 23:37:00.018045 10142 solver.cpp:218] Iteration 81400 (13.0794 iter/s, 7.64562s/100 iters), loss = 0.00256242
I1005 23:37:00.018074 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00256219 (* 1 = 0.00256219 loss)
I1005 23:37:00.018080 10142 sgd_solver.cpp:105] Iteration 81400, lr = 0.001
I1005 23:37:07.304069 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:37:07.609725 10142 solver.cpp:330] Iteration 81500, Testing net (#0)
I1005 23:37:09.349149 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:37:09.422484 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9249
I1005 23:37:09.422544 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.302672 (* 1 = 0.302672 loss)
I1005 23:37:09.500092 10142 solver.cpp:218] Iteration 81500 (10.5463 iter/s, 9.48199s/100 iters), loss = 0.0348252
I1005 23:37:09.500126 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.034825 (* 1 = 0.034825 loss)
I1005 23:37:09.500133 10142 sgd_solver.cpp:105] Iteration 81500, lr = 0.001
I1005 23:37:17.157997 10142 solver.cpp:218] Iteration 81600 (13.0585 iter/s, 7.65785s/100 iters), loss = 0.00233113
I1005 23:37:17.158143 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0023309 (* 1 = 0.0023309 loss)
I1005 23:37:17.158150 10142 sgd_solver.cpp:105] Iteration 81600, lr = 0.001
I1005 23:37:24.807816 10142 solver.cpp:218] Iteration 81700 (13.0725 iter/s, 7.64965s/100 iters), loss = 0.00641908
I1005 23:37:24.807850 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00641885 (* 1 = 0.00641885 loss)
I1005 23:37:24.807857 10142 sgd_solver.cpp:105] Iteration 81700, lr = 0.001
I1005 23:37:32.451381 10142 solver.cpp:218] Iteration 81800 (13.083 iter/s, 7.64351s/100 iters), loss = 0.0062046
I1005 23:37:32.451411 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00620437 (* 1 = 0.00620437 loss)
I1005 23:37:32.451416 10142 sgd_solver.cpp:105] Iteration 81800, lr = 0.001
I1005 23:37:40.113879 10142 solver.cpp:218] Iteration 81900 (13.0507 iter/s, 7.66244s/100 iters), loss = 0.00697992
I1005 23:37:40.113911 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0069797 (* 1 = 0.0069797 loss)
I1005 23:37:40.113927 10142 sgd_solver.cpp:105] Iteration 81900, lr = 0.001
I1005 23:37:47.392374 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:37:47.698631 10142 solver.cpp:330] Iteration 82000, Testing net (#0)
I1005 23:37:49.446919 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:37:49.520089 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9246
I1005 23:37:49.520125 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.303384 (* 1 = 0.303384 loss)
I1005 23:37:49.597465 10142 solver.cpp:218] Iteration 82000 (10.5446 iter/s, 9.48353s/100 iters), loss = 0.0091251
I1005 23:37:49.597493 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00912487 (* 1 = 0.00912487 loss)
I1005 23:37:49.597501 10142 sgd_solver.cpp:105] Iteration 82000, lr = 0.001
I1005 23:37:57.257969 10142 solver.cpp:218] Iteration 82100 (13.0541 iter/s, 7.66045s/100 iters), loss = 0.00777831
I1005 23:37:57.258000 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00777809 (* 1 = 0.00777809 loss)
I1005 23:37:57.258007 10142 sgd_solver.cpp:105] Iteration 82100, lr = 0.001
I1005 23:38:04.922449 10142 solver.cpp:218] Iteration 82200 (13.0473 iter/s, 7.66443s/100 iters), loss = 0.00710159
I1005 23:38:04.922480 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00710136 (* 1 = 0.00710136 loss)
I1005 23:38:04.922488 10142 sgd_solver.cpp:105] Iteration 82200, lr = 0.001
I1005 23:38:12.582422 10142 solver.cpp:218] Iteration 82300 (13.055 iter/s, 7.65992s/100 iters), loss = 0.00710561
I1005 23:38:12.582466 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00710539 (* 1 = 0.00710539 loss)
I1005 23:38:12.582474 10142 sgd_solver.cpp:105] Iteration 82300, lr = 0.001
I1005 23:38:20.238553 10142 solver.cpp:218] Iteration 82400 (13.0616 iter/s, 7.65603s/100 iters), loss = 0.0160762
I1005 23:38:20.238651 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.016076 (* 1 = 0.016076 loss)
I1005 23:38:20.238667 10142 sgd_solver.cpp:105] Iteration 82400, lr = 0.001
I1005 23:38:27.515794 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:38:27.832188 10142 solver.cpp:330] Iteration 82500, Testing net (#0)
I1005 23:38:29.572986 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:38:29.646317 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9246
I1005 23:38:29.646342 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.303563 (* 1 = 0.303563 loss)
I1005 23:38:29.723577 10142 solver.cpp:218] Iteration 82500 (10.5431 iter/s, 9.4849s/100 iters), loss = 0.00279985
I1005 23:38:29.723608 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00279963 (* 1 = 0.00279963 loss)
I1005 23:38:29.723615 10142 sgd_solver.cpp:105] Iteration 82500, lr = 0.001
I1005 23:38:37.392017 10142 solver.cpp:218] Iteration 82600 (13.0405 iter/s, 7.66839s/100 iters), loss = 0.00171571
I1005 23:38:37.392060 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00171549 (* 1 = 0.00171549 loss)
I1005 23:38:37.392066 10142 sgd_solver.cpp:105] Iteration 82600, lr = 0.001
I1005 23:38:45.052237 10142 solver.cpp:218] Iteration 82700 (13.0546 iter/s, 7.66015s/100 iters), loss = 0.00314436
I1005 23:38:45.052268 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00314414 (* 1 = 0.00314414 loss)
I1005 23:38:45.052284 10142 sgd_solver.cpp:105] Iteration 82700, lr = 0.001
I1005 23:38:52.721009 10142 solver.cpp:218] Iteration 82800 (13.04 iter/s, 7.66872s/100 iters), loss = 0.00589743
I1005 23:38:52.721146 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0058972 (* 1 = 0.0058972 loss)
I1005 23:38:52.721164 10142 sgd_solver.cpp:105] Iteration 82800, lr = 0.001
I1005 23:39:00.377163 10142 solver.cpp:218] Iteration 82900 (13.0617 iter/s, 7.656s/100 iters), loss = 0.00421025
I1005 23:39:00.377193 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00421003 (* 1 = 0.00421003 loss)
I1005 23:39:00.377199 10142 sgd_solver.cpp:105] Iteration 82900, lr = 0.001
I1005 23:39:07.662997 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:39:07.968660 10142 solver.cpp:330] Iteration 83000, Testing net (#0)
I1005 23:39:09.711401 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:39:09.786546 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9249
I1005 23:39:09.786581 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.302329 (* 1 = 0.302329 loss)
I1005 23:39:09.864733 10142 solver.cpp:218] Iteration 83000 (10.5402 iter/s, 9.48751s/100 iters), loss = 0.00425399
I1005 23:39:09.864770 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00425378 (* 1 = 0.00425378 loss)
I1005 23:39:09.864778 10142 sgd_solver.cpp:105] Iteration 83000, lr = 0.001
I1005 23:39:17.524837 10142 solver.cpp:218] Iteration 83100 (13.0548 iter/s, 7.66004s/100 iters), loss = 0.0101453
I1005 23:39:17.524876 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0101451 (* 1 = 0.0101451 loss)
I1005 23:39:17.524883 10142 sgd_solver.cpp:105] Iteration 83100, lr = 0.001
I1005 23:39:25.192898 10142 solver.cpp:218] Iteration 83200 (13.0412 iter/s, 7.668s/100 iters), loss = 0.0109616
I1005 23:39:25.193080 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0109613 (* 1 = 0.0109613 loss)
I1005 23:39:25.193090 10142 sgd_solver.cpp:105] Iteration 83200, lr = 0.001
I1005 23:39:32.847240 10142 solver.cpp:218] Iteration 83300 (13.0648 iter/s, 7.65416s/100 iters), loss = 0.00424138
I1005 23:39:32.847270 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00424116 (* 1 = 0.00424116 loss)
I1005 23:39:32.847276 10142 sgd_solver.cpp:105] Iteration 83300, lr = 0.001
I1005 23:39:40.514725 10142 solver.cpp:218] Iteration 83400 (13.0422 iter/s, 7.66743s/100 iters), loss = 0.00188588
I1005 23:39:40.514753 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00188566 (* 1 = 0.00188566 loss)
I1005 23:39:40.514760 10142 sgd_solver.cpp:105] Iteration 83400, lr = 0.001
I1005 23:39:47.788740 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:39:48.093919 10142 solver.cpp:330] Iteration 83500, Testing net (#0)
I1005 23:39:49.841029 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:39:49.914063 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9258
I1005 23:39:49.914088 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.299813 (* 1 = 0.299813 loss)
I1005 23:39:49.990284 10142 solver.cpp:218] Iteration 83500 (10.5535 iter/s, 9.4755s/100 iters), loss = 0.0012295
I1005 23:39:49.990312 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00122927 (* 1 = 0.00122927 loss)
I1005 23:39:49.990319 10142 sgd_solver.cpp:105] Iteration 83500, lr = 0.001
I1005 23:39:57.639081 10142 solver.cpp:218] Iteration 83600 (13.074 iter/s, 7.64874s/100 iters), loss = 0.0105531
I1005 23:39:57.639207 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0105529 (* 1 = 0.0105529 loss)
I1005 23:39:57.639216 10142 sgd_solver.cpp:105] Iteration 83600, lr = 0.001
I1005 23:40:05.300165 10142 solver.cpp:218] Iteration 83700 (13.0533 iter/s, 7.66091s/100 iters), loss = 0.00501294
I1005 23:40:05.300195 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00501271 (* 1 = 0.00501271 loss)
I1005 23:40:05.300201 10142 sgd_solver.cpp:105] Iteration 83700, lr = 0.001
I1005 23:40:12.961724 10142 solver.cpp:218] Iteration 83800 (13.0523 iter/s, 7.66151s/100 iters), loss = 0.00483377
I1005 23:40:12.961755 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00483354 (* 1 = 0.00483354 loss)
I1005 23:40:12.961762 10142 sgd_solver.cpp:105] Iteration 83800, lr = 0.001
I1005 23:40:20.615075 10142 solver.cpp:218] Iteration 83900 (13.0663 iter/s, 7.65329s/100 iters), loss = 0.000960328
I1005 23:40:20.615104 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000960101 (* 1 = 0.000960101 loss)
I1005 23:40:20.615120 10142 sgd_solver.cpp:105] Iteration 83900, lr = 0.001
I1005 23:40:27.898058 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:40:28.204706 10142 solver.cpp:330] Iteration 84000, Testing net (#0)
I1005 23:40:29.943938 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:40:30.017122 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9252
I1005 23:40:30.017158 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.303122 (* 1 = 0.303122 loss)
I1005 23:40:30.094112 10142 solver.cpp:218] Iteration 84000 (10.5497 iter/s, 9.47898s/100 iters), loss = 0.00204863
I1005 23:40:30.094138 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00204841 (* 1 = 0.00204841 loss)
I1005 23:40:30.094146 10142 sgd_solver.cpp:105] Iteration 84000, lr = 0.001
I1005 23:40:37.756968 10142 solver.cpp:218] Iteration 84100 (13.0501 iter/s, 7.6628s/100 iters), loss = 0.00850075
I1005 23:40:37.757009 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00850052 (* 1 = 0.00850052 loss)
I1005 23:40:37.757014 10142 sgd_solver.cpp:105] Iteration 84100, lr = 0.001
I1005 23:40:45.403122 10142 solver.cpp:218] Iteration 84200 (13.0786 iter/s, 7.64609s/100 iters), loss = 0.00757072
I1005 23:40:45.403154 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0075705 (* 1 = 0.0075705 loss)
I1005 23:40:45.403161 10142 sgd_solver.cpp:105] Iteration 84200, lr = 0.001
I1005 23:40:53.069926 10142 solver.cpp:218] Iteration 84300 (13.0433 iter/s, 7.66675s/100 iters), loss = 0.00147047
I1005 23:40:53.069955 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00147024 (* 1 = 0.00147024 loss)
I1005 23:40:53.069962 10142 sgd_solver.cpp:105] Iteration 84300, lr = 0.001
I1005 23:41:00.727295 10142 solver.cpp:218] Iteration 84400 (13.0594 iter/s, 7.65731s/100 iters), loss = 0.0188091
I1005 23:41:00.727473 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0188088 (* 1 = 0.0188088 loss)
I1005 23:41:00.727483 10142 sgd_solver.cpp:105] Iteration 84400, lr = 0.001
I1005 23:41:08.012831 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:41:08.319816 10142 solver.cpp:330] Iteration 84500, Testing net (#0)
I1005 23:41:10.070713 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:41:10.143831 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9261
I1005 23:41:10.143868 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.300435 (* 1 = 0.300435 loss)
I1005 23:41:10.220937 10142 solver.cpp:218] Iteration 84500 (10.5336 iter/s, 9.49345s/100 iters), loss = 0.00256317
I1005 23:41:10.220969 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00256295 (* 1 = 0.00256295 loss)
I1005 23:41:10.220978 10142 sgd_solver.cpp:105] Iteration 84500, lr = 0.001
I1005 23:41:17.877717 10142 solver.cpp:218] Iteration 84600 (13.0604 iter/s, 7.65672s/100 iters), loss = 0.00322438
I1005 23:41:17.877746 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00322416 (* 1 = 0.00322416 loss)
I1005 23:41:17.877753 10142 sgd_solver.cpp:105] Iteration 84600, lr = 0.001
I1005 23:41:25.537384 10142 solver.cpp:218] Iteration 84700 (13.0555 iter/s, 7.65961s/100 iters), loss = 0.00554024
I1005 23:41:25.537415 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00554002 (* 1 = 0.00554002 loss)
I1005 23:41:25.537420 10142 sgd_solver.cpp:105] Iteration 84700, lr = 0.001
I1005 23:41:33.186229 10142 solver.cpp:218] Iteration 84800 (13.074 iter/s, 7.64879s/100 iters), loss = 0.00228443
I1005 23:41:33.186352 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00228421 (* 1 = 0.00228421 loss)
I1005 23:41:33.186369 10142 sgd_solver.cpp:105] Iteration 84800, lr = 0.001
I1005 23:41:40.854295 10142 solver.cpp:218] Iteration 84900 (13.0413 iter/s, 7.66792s/100 iters), loss = 0.00385681
I1005 23:41:40.854323 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00385659 (* 1 = 0.00385659 loss)
I1005 23:41:40.854329 10142 sgd_solver.cpp:105] Iteration 84900, lr = 0.001
I1005 23:41:48.132225 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:41:48.438473 10142 solver.cpp:330] Iteration 85000, Testing net (#0)
I1005 23:41:50.186679 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:41:50.259836 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9264
I1005 23:41:50.259861 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.300482 (* 1 = 0.300482 loss)
I1005 23:41:50.337139 10142 solver.cpp:218] Iteration 85000 (10.5454 iter/s, 9.48279s/100 iters), loss = 0.00541107
I1005 23:41:50.337167 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00541085 (* 1 = 0.00541085 loss)
I1005 23:41:50.337175 10142 sgd_solver.cpp:105] Iteration 85000, lr = 0.001
I1005 23:41:58.008441 10142 solver.cpp:218] Iteration 85100 (13.0357 iter/s, 7.67125s/100 iters), loss = 0.00709333
I1005 23:41:58.008472 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00709311 (* 1 = 0.00709311 loss)
I1005 23:41:58.008478 10142 sgd_solver.cpp:105] Iteration 85100, lr = 0.001
I1005 23:42:05.665603 10142 solver.cpp:218] Iteration 85200 (13.0598 iter/s, 7.65711s/100 iters), loss = 0.00252606
I1005 23:42:05.665750 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00252584 (* 1 = 0.00252584 loss)
I1005 23:42:05.665767 10142 sgd_solver.cpp:105] Iteration 85200, lr = 0.001
I1005 23:42:13.332579 10142 solver.cpp:218] Iteration 85300 (13.0432 iter/s, 7.66681s/100 iters), loss = 0.00524556
I1005 23:42:13.332608 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00524534 (* 1 = 0.00524534 loss)
I1005 23:42:13.332615 10142 sgd_solver.cpp:105] Iteration 85300, lr = 0.001
I1005 23:42:20.983619 10142 solver.cpp:218] Iteration 85400 (13.0702 iter/s, 7.65098s/100 iters), loss = 0.00154778
I1005 23:42:20.983649 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00154757 (* 1 = 0.00154757 loss)
I1005 23:42:20.983665 10142 sgd_solver.cpp:105] Iteration 85400, lr = 0.001
I1005 23:42:28.263703 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:42:28.570200 10142 solver.cpp:330] Iteration 85500, Testing net (#0)
I1005 23:42:30.310194 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:42:30.383532 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9262
I1005 23:42:30.383566 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.301614 (* 1 = 0.301614 loss)
I1005 23:42:30.460852 10142 solver.cpp:218] Iteration 85500 (10.5517 iter/s, 9.47718s/100 iters), loss = 0.0013901
I1005 23:42:30.460886 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00138988 (* 1 = 0.00138988 loss)
I1005 23:42:30.460892 10142 sgd_solver.cpp:105] Iteration 85500, lr = 0.001
I1005 23:42:38.128393 10142 solver.cpp:218] Iteration 85600 (13.0421 iter/s, 7.66749s/100 iters), loss = 0.0117732
I1005 23:42:38.128535 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.011773 (* 1 = 0.011773 loss)
I1005 23:42:38.128557 10142 sgd_solver.cpp:105] Iteration 85600, lr = 0.001
I1005 23:42:45.805269 10142 solver.cpp:218] Iteration 85700 (13.0264 iter/s, 7.67671s/100 iters), loss = 0.0010296
I1005 23:42:45.805305 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00102938 (* 1 = 0.00102938 loss)
I1005 23:42:45.805312 10142 sgd_solver.cpp:105] Iteration 85700, lr = 0.001
I1005 23:42:53.468387 10142 solver.cpp:218] Iteration 85800 (13.0496 iter/s, 7.66306s/100 iters), loss = 0.00487453
I1005 23:42:53.468428 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00487432 (* 1 = 0.00487432 loss)
I1005 23:42:53.468436 10142 sgd_solver.cpp:105] Iteration 85800, lr = 0.001
I1005 23:43:01.135949 10142 solver.cpp:218] Iteration 85900 (13.0421 iter/s, 7.6675s/100 iters), loss = 0.00376683
I1005 23:43:01.135990 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00376662 (* 1 = 0.00376662 loss)
I1005 23:43:01.135998 10142 sgd_solver.cpp:105] Iteration 85900, lr = 0.001
I1005 23:43:08.413182 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:43:08.718603 10142 solver.cpp:330] Iteration 86000, Testing net (#0)
I1005 23:43:10.466003 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:43:10.539275 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9258
I1005 23:43:10.539310 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.301819 (* 1 = 0.301819 loss)
I1005 23:43:10.616348 10142 solver.cpp:218] Iteration 86000 (10.5482 iter/s, 9.48033s/100 iters), loss = 0.00168171
I1005 23:43:10.616377 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00168149 (* 1 = 0.00168149 loss)
I1005 23:43:10.616384 10142 sgd_solver.cpp:105] Iteration 86000, lr = 0.001
I1005 23:43:18.276265 10142 solver.cpp:218] Iteration 86100 (13.0551 iter/s, 7.65986s/100 iters), loss = 0.00426819
I1005 23:43:18.276305 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00426797 (* 1 = 0.00426797 loss)
I1005 23:43:18.276311 10142 sgd_solver.cpp:105] Iteration 86100, lr = 0.001
I1005 23:43:25.943245 10142 solver.cpp:218] Iteration 86200 (13.0431 iter/s, 7.66692s/100 iters), loss = 0.0189614
I1005 23:43:25.943286 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0189612 (* 1 = 0.0189612 loss)
I1005 23:43:25.943292 10142 sgd_solver.cpp:105] Iteration 86200, lr = 0.001
I1005 23:43:33.602831 10142 solver.cpp:218] Iteration 86300 (13.0556 iter/s, 7.65952s/100 iters), loss = 0.00223487
I1005 23:43:33.602876 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00223466 (* 1 = 0.00223466 loss)
I1005 23:43:33.602885 10142 sgd_solver.cpp:105] Iteration 86300, lr = 0.001
I1005 23:43:41.273895 10142 solver.cpp:218] Iteration 86400 (13.0361 iter/s, 7.671s/100 iters), loss = 0.00167619
I1005 23:43:41.273991 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00167597 (* 1 = 0.00167597 loss)
I1005 23:43:41.274009 10142 sgd_solver.cpp:105] Iteration 86400, lr = 0.001
I1005 23:43:48.551607 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:43:48.863575 10142 solver.cpp:330] Iteration 86500, Testing net (#0)
I1005 23:43:50.602998 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:43:50.676123 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9268
I1005 23:43:50.676157 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.302383 (* 1 = 0.302383 loss)
I1005 23:43:50.753577 10142 solver.cpp:218] Iteration 86500 (10.549 iter/s, 9.47956s/100 iters), loss = 0.0175933
I1005 23:43:50.753607 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0175931 (* 1 = 0.0175931 loss)
I1005 23:43:50.753614 10142 sgd_solver.cpp:105] Iteration 86500, lr = 0.001
I1005 23:43:58.414080 10142 solver.cpp:218] Iteration 86600 (13.0541 iter/s, 7.66045s/100 iters), loss = 0.0107509
I1005 23:43:58.414109 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0107507 (* 1 = 0.0107507 loss)
I1005 23:43:58.414114 10142 sgd_solver.cpp:105] Iteration 86600, lr = 0.001
I1005 23:44:06.067629 10142 solver.cpp:218] Iteration 86700 (13.0659 iter/s, 7.65349s/100 iters), loss = 0.00438093
I1005 23:44:06.067658 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00438072 (* 1 = 0.00438072 loss)
I1005 23:44:06.067664 10142 sgd_solver.cpp:105] Iteration 86700, lr = 0.001
I1005 23:44:13.728307 10142 solver.cpp:218] Iteration 86800 (13.0538 iter/s, 7.66063s/100 iters), loss = 0.00389634
I1005 23:44:13.728447 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00389613 (* 1 = 0.00389613 loss)
I1005 23:44:13.728454 10142 sgd_solver.cpp:105] Iteration 86800, lr = 0.001
I1005 23:44:21.385135 10142 solver.cpp:218] Iteration 86900 (13.0605 iter/s, 7.65667s/100 iters), loss = 0.0012345
I1005 23:44:21.385175 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00123428 (* 1 = 0.00123428 loss)
I1005 23:44:21.385181 10142 sgd_solver.cpp:105] Iteration 86900, lr = 0.001
I1005 23:44:28.667430 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:44:28.973232 10142 solver.cpp:330] Iteration 87000, Testing net (#0)
I1005 23:44:30.714510 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:44:30.789515 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9273
I1005 23:44:30.789541 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.302881 (* 1 = 0.302881 loss)
I1005 23:44:30.867269 10142 solver.cpp:218] Iteration 87000 (10.5462 iter/s, 9.48206s/100 iters), loss = 0.001881
I1005 23:44:30.867305 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00188079 (* 1 = 0.00188079 loss)
I1005 23:44:30.867313 10142 sgd_solver.cpp:105] Iteration 87000, lr = 0.001
I1005 23:44:38.521447 10142 solver.cpp:218] Iteration 87100 (13.0649 iter/s, 7.65412s/100 iters), loss = 0.00205198
I1005 23:44:38.521487 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00205178 (* 1 = 0.00205178 loss)
I1005 23:44:38.521493 10142 sgd_solver.cpp:105] Iteration 87100, lr = 0.001
I1005 23:44:46.181370 10142 solver.cpp:218] Iteration 87200 (13.0551 iter/s, 7.65985s/100 iters), loss = 0.00136863
I1005 23:44:46.181498 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00136842 (* 1 = 0.00136842 loss)
I1005 23:44:46.181507 10142 sgd_solver.cpp:105] Iteration 87200, lr = 0.001
I1005 23:44:53.846143 10142 solver.cpp:218] Iteration 87300 (13.0469 iter/s, 7.66463s/100 iters), loss = 0.00236628
I1005 23:44:53.846174 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00236607 (* 1 = 0.00236607 loss)
I1005 23:44:53.846180 10142 sgd_solver.cpp:105] Iteration 87300, lr = 0.001
I1005 23:45:01.512264 10142 solver.cpp:218] Iteration 87400 (13.0445 iter/s, 7.66607s/100 iters), loss = 0.00120069
I1005 23:45:01.512295 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00120048 (* 1 = 0.00120048 loss)
I1005 23:45:01.512301 10142 sgd_solver.cpp:105] Iteration 87400, lr = 0.001
I1005 23:45:08.787014 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:45:09.093849 10142 solver.cpp:330] Iteration 87500, Testing net (#0)
I1005 23:45:10.844141 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:45:10.917182 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.926
I1005 23:45:10.917218 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.302596 (* 1 = 0.302596 loss)
I1005 23:45:10.994223 10142 solver.cpp:218] Iteration 87500 (10.5464 iter/s, 9.4819s/100 iters), loss = 0.0107535
I1005 23:45:10.994251 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0107533 (* 1 = 0.0107533 loss)
I1005 23:45:10.994258 10142 sgd_solver.cpp:105] Iteration 87500, lr = 0.001
I1005 23:45:18.642963 10142 solver.cpp:218] Iteration 87600 (13.0741 iter/s, 7.64868s/100 iters), loss = 0.00489455
I1005 23:45:18.643052 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00489436 (* 1 = 0.00489436 loss)
I1005 23:45:18.643061 10142 sgd_solver.cpp:105] Iteration 87600, lr = 0.001
I1005 23:45:26.300577 10142 solver.cpp:218] Iteration 87700 (13.0591 iter/s, 7.65747s/100 iters), loss = 0.00278357
I1005 23:45:26.300607 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00278337 (* 1 = 0.00278337 loss)
I1005 23:45:26.300613 10142 sgd_solver.cpp:105] Iteration 87700, lr = 0.001
I1005 23:45:33.956142 10142 solver.cpp:218] Iteration 87800 (13.0625 iter/s, 7.65551s/100 iters), loss = 0.00528995
I1005 23:45:33.956176 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00528975 (* 1 = 0.00528975 loss)
I1005 23:45:33.956183 10142 sgd_solver.cpp:105] Iteration 87800, lr = 0.001
I1005 23:45:41.608162 10142 solver.cpp:218] Iteration 87900 (13.0685 iter/s, 7.65196s/100 iters), loss = 0.00705849
I1005 23:45:41.608202 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0070583 (* 1 = 0.0070583 loss)
I1005 23:45:41.608208 10142 sgd_solver.cpp:105] Iteration 87900, lr = 0.001
I1005 23:45:48.893296 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:45:49.200527 10142 solver.cpp:330] Iteration 88000, Testing net (#0)
I1005 23:45:50.939033 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:45:51.011744 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9265
I1005 23:45:51.011777 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.301802 (* 1 = 0.301802 loss)
I1005 23:45:51.088899 10142 solver.cpp:218] Iteration 88000 (10.5478 iter/s, 9.48067s/100 iters), loss = 0.00186567
I1005 23:45:51.088932 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00186547 (* 1 = 0.00186547 loss)
I1005 23:45:51.088939 10142 sgd_solver.cpp:105] Iteration 88000, lr = 0.001
I1005 23:45:58.760068 10142 solver.cpp:218] Iteration 88100 (13.0359 iter/s, 7.67111s/100 iters), loss = 0.00146982
I1005 23:45:58.760098 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00146962 (* 1 = 0.00146962 loss)
I1005 23:45:58.760104 10142 sgd_solver.cpp:105] Iteration 88100, lr = 0.001
I1005 23:46:06.414177 10142 solver.cpp:218] Iteration 88200 (13.065 iter/s, 7.65406s/100 iters), loss = 0.00227408
I1005 23:46:06.414218 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00227388 (* 1 = 0.00227388 loss)
I1005 23:46:06.414225 10142 sgd_solver.cpp:105] Iteration 88200, lr = 0.001
I1005 23:46:14.069597 10142 solver.cpp:218] Iteration 88300 (13.0628 iter/s, 7.65536s/100 iters), loss = 0.0029407
I1005 23:46:14.069638 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0029405 (* 1 = 0.0029405 loss)
I1005 23:46:14.069643 10142 sgd_solver.cpp:105] Iteration 88300, lr = 0.001
I1005 23:46:21.723317 10142 solver.cpp:218] Iteration 88400 (13.0657 iter/s, 7.65365s/100 iters), loss = 0.00310012
I1005 23:46:21.723484 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00309992 (* 1 = 0.00309992 loss)
I1005 23:46:21.723495 10142 sgd_solver.cpp:105] Iteration 88400, lr = 0.001
I1005 23:46:29.006166 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:46:29.312927 10142 solver.cpp:330] Iteration 88500, Testing net (#0)
I1005 23:46:31.061905 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:46:31.135012 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9262
I1005 23:46:31.135048 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.301003 (* 1 = 0.301003 loss)
I1005 23:46:31.212235 10142 solver.cpp:218] Iteration 88500 (10.5388 iter/s, 9.48873s/100 iters), loss = 0.00249963
I1005 23:46:31.212268 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00249943 (* 1 = 0.00249943 loss)
I1005 23:46:31.212276 10142 sgd_solver.cpp:105] Iteration 88500, lr = 0.001
I1005 23:46:38.866322 10142 solver.cpp:218] Iteration 88600 (13.065 iter/s, 7.65403s/100 iters), loss = 0.00165337
I1005 23:46:38.866364 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00165316 (* 1 = 0.00165316 loss)
I1005 23:46:38.866370 10142 sgd_solver.cpp:105] Iteration 88600, lr = 0.001
I1005 23:46:46.523300 10142 solver.cpp:218] Iteration 88700 (13.0601 iter/s, 7.65691s/100 iters), loss = 0.00283878
I1005 23:46:46.523332 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00283858 (* 1 = 0.00283858 loss)
I1005 23:46:46.523339 10142 sgd_solver.cpp:105] Iteration 88700, lr = 0.001
I1005 23:46:54.170370 10142 solver.cpp:218] Iteration 88800 (13.077 iter/s, 7.64701s/100 iters), loss = 0.0053247
I1005 23:46:54.170495 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0053245 (* 1 = 0.0053245 loss)
I1005 23:46:54.170513 10142 sgd_solver.cpp:105] Iteration 88800, lr = 0.001
I1005 23:47:01.828954 10142 solver.cpp:218] Iteration 88900 (13.0575 iter/s, 7.65844s/100 iters), loss = 0.00161429
I1005 23:47:01.828994 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00161409 (* 1 = 0.00161409 loss)
I1005 23:47:01.829000 10142 sgd_solver.cpp:105] Iteration 88900, lr = 0.001
I1005 23:47:09.091496 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:47:09.397157 10142 solver.cpp:330] Iteration 89000, Testing net (#0)
I1005 23:47:11.144104 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:47:11.217274 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9278
I1005 23:47:11.217308 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.302094 (* 1 = 0.302094 loss)
I1005 23:47:11.294158 10142 solver.cpp:218] Iteration 89000 (10.5651 iter/s, 9.46514s/100 iters), loss = 0.012677
I1005 23:47:11.294191 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0126768 (* 1 = 0.0126768 loss)
I1005 23:47:11.294198 10142 sgd_solver.cpp:105] Iteration 89000, lr = 0.001
I1005 23:47:18.959095 10142 solver.cpp:218] Iteration 89100 (13.0465 iter/s, 7.66488s/100 iters), loss = 0.00750207
I1005 23:47:18.959128 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00750187 (* 1 = 0.00750187 loss)
I1005 23:47:18.959136 10142 sgd_solver.cpp:105] Iteration 89100, lr = 0.001
I1005 23:47:26.608896 10142 solver.cpp:218] Iteration 89200 (13.0723 iter/s, 7.64974s/100 iters), loss = 0.010675
I1005 23:47:26.609028 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0106748 (* 1 = 0.0106748 loss)
I1005 23:47:26.609045 10142 sgd_solver.cpp:105] Iteration 89200, lr = 0.001
I1005 23:47:34.272013 10142 solver.cpp:218] Iteration 89300 (13.0498 iter/s, 7.66297s/100 iters), loss = 0.00313509
I1005 23:47:34.272044 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00313489 (* 1 = 0.00313489 loss)
I1005 23:47:34.272050 10142 sgd_solver.cpp:105] Iteration 89300, lr = 0.001
I1005 23:47:41.921672 10142 solver.cpp:218] Iteration 89400 (13.0726 iter/s, 7.6496s/100 iters), loss = 0.00302181
I1005 23:47:41.921713 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00302161 (* 1 = 0.00302161 loss)
I1005 23:47:41.921720 10142 sgd_solver.cpp:105] Iteration 89400, lr = 0.001
I1005 23:47:49.198473 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:47:49.504559 10142 solver.cpp:330] Iteration 89500, Testing net (#0)
I1005 23:47:51.244076 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:47:51.317226 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9275
I1005 23:47:51.317262 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.301118 (* 1 = 0.301118 loss)
I1005 23:47:51.394109 10142 solver.cpp:218] Iteration 89500 (10.557 iter/s, 9.47237s/100 iters), loss = 0.00366757
I1005 23:47:51.394155 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00366737 (* 1 = 0.00366737 loss)
I1005 23:47:51.394162 10142 sgd_solver.cpp:105] Iteration 89500, lr = 0.001
I1005 23:47:59.050217 10142 solver.cpp:218] Iteration 89600 (13.0616 iter/s, 7.65604s/100 iters), loss = 0.00353456
I1005 23:47:59.050331 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00353436 (* 1 = 0.00353436 loss)
I1005 23:47:59.050338 10142 sgd_solver.cpp:105] Iteration 89600, lr = 0.001
I1005 23:48:06.703276 10142 solver.cpp:218] Iteration 89700 (13.0669 iter/s, 7.65293s/100 iters), loss = 0.00256288
I1005 23:48:06.703326 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00256268 (* 1 = 0.00256268 loss)
I1005 23:48:06.703343 10142 sgd_solver.cpp:105] Iteration 89700, lr = 0.001
I1005 23:48:14.371840 10142 solver.cpp:218] Iteration 89800 (13.0404 iter/s, 7.66846s/100 iters), loss = 0.00277789
I1005 23:48:14.371870 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00277769 (* 1 = 0.00277769 loss)
I1005 23:48:14.371876 10142 sgd_solver.cpp:105] Iteration 89800, lr = 0.001
I1005 23:48:22.042800 10142 solver.cpp:218] Iteration 89900 (13.0363 iter/s, 7.6709s/100 iters), loss = 0.00119901
I1005 23:48:22.042841 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00119881 (* 1 = 0.00119881 loss)
I1005 23:48:22.042847 10142 sgd_solver.cpp:105] Iteration 89900, lr = 0.001
I1005 23:48:29.323132 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:48:29.629616 10142 solver.cpp:330] Iteration 90000, Testing net (#0)
I1005 23:48:31.375921 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:48:31.448789 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9267
I1005 23:48:31.448824 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.302207 (* 1 = 0.302207 loss)
I1005 23:48:31.525586 10142 solver.cpp:218] Iteration 90000 (10.5455 iter/s, 9.48272s/100 iters), loss = 0.0187412
I1005 23:48:31.525619 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.018741 (* 1 = 0.018741 loss)
I1005 23:48:31.525625 10142 sgd_solver.cpp:105] Iteration 90000, lr = 0.001
I1005 23:48:39.173498 10142 solver.cpp:218] Iteration 90100 (13.0756 iter/s, 7.64785s/100 iters), loss = 0.00168491
I1005 23:48:39.173528 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00168471 (* 1 = 0.00168471 loss)
I1005 23:48:39.173534 10142 sgd_solver.cpp:105] Iteration 90100, lr = 0.001
I1005 23:48:46.825871 10142 solver.cpp:218] Iteration 90200 (13.0679 iter/s, 7.65232s/100 iters), loss = 0.00300827
I1005 23:48:46.825901 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00300807 (* 1 = 0.00300807 loss)
I1005 23:48:46.825907 10142 sgd_solver.cpp:105] Iteration 90200, lr = 0.001
I1005 23:48:54.476864 10142 solver.cpp:218] Iteration 90300 (13.0703 iter/s, 7.65094s/100 iters), loss = 0.00277415
I1005 23:48:54.476902 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00277395 (* 1 = 0.00277395 loss)
I1005 23:48:54.476910 10142 sgd_solver.cpp:105] Iteration 90300, lr = 0.001
I1005 23:49:02.123638 10142 solver.cpp:218] Iteration 90400 (13.0775 iter/s, 7.64671s/100 iters), loss = 0.00139857
I1005 23:49:02.123770 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00139837 (* 1 = 0.00139837 loss)
I1005 23:49:02.123787 10142 sgd_solver.cpp:105] Iteration 90400, lr = 0.001
I1005 23:49:09.403488 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:49:09.713136 10142 solver.cpp:330] Iteration 90500, Testing net (#0)
I1005 23:49:11.460360 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:49:11.533445 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.927
I1005 23:49:11.533479 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.303554 (* 1 = 0.303554 loss)
I1005 23:49:11.610378 10142 solver.cpp:218] Iteration 90500 (10.5412 iter/s, 9.4866s/100 iters), loss = 0.00201283
I1005 23:49:11.610405 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00201263 (* 1 = 0.00201263 loss)
I1005 23:49:11.610412 10142 sgd_solver.cpp:105] Iteration 90500, lr = 0.001
I1005 23:49:19.270223 10142 solver.cpp:218] Iteration 90600 (13.0552 iter/s, 7.65979s/100 iters), loss = 0.0030277
I1005 23:49:19.270253 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0030275 (* 1 = 0.0030275 loss)
I1005 23:49:19.270259 10142 sgd_solver.cpp:105] Iteration 90600, lr = 0.001
I1005 23:49:26.926467 10142 solver.cpp:218] Iteration 90700 (13.0613 iter/s, 7.65619s/100 iters), loss = 0.00270344
I1005 23:49:26.926507 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00270324 (* 1 = 0.00270324 loss)
I1005 23:49:26.926513 10142 sgd_solver.cpp:105] Iteration 90700, lr = 0.001
I1005 23:49:34.582243 10142 solver.cpp:218] Iteration 90800 (13.0621 iter/s, 7.65571s/100 iters), loss = 0.00239662
I1005 23:49:34.582370 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00239643 (* 1 = 0.00239643 loss)
I1005 23:49:34.582387 10142 sgd_solver.cpp:105] Iteration 90800, lr = 0.001
I1005 23:49:42.238941 10142 solver.cpp:218] Iteration 90900 (13.0607 iter/s, 7.65656s/100 iters), loss = 0.00110087
I1005 23:49:42.238983 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00110068 (* 1 = 0.00110068 loss)
I1005 23:49:42.238989 10142 sgd_solver.cpp:105] Iteration 90900, lr = 0.001
I1005 23:49:49.525138 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:49:49.831324 10142 solver.cpp:330] Iteration 91000, Testing net (#0)
I1005 23:49:51.571455 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:49:51.644740 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9273
I1005 23:49:51.644778 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.303511 (* 1 = 0.303511 loss)
I1005 23:49:51.724731 10142 solver.cpp:218] Iteration 91000 (10.5422 iter/s, 9.48572s/100 iters), loss = 0.0017477
I1005 23:49:51.724768 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0017475 (* 1 = 0.0017475 loss)
I1005 23:49:51.724776 10142 sgd_solver.cpp:105] Iteration 91000, lr = 0.001
I1005 23:49:59.392524 10142 solver.cpp:218] Iteration 91100 (13.0417 iter/s, 7.6677s/100 iters), loss = 0.00225678
I1005 23:49:59.392563 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00225659 (* 1 = 0.00225659 loss)
I1005 23:49:59.392570 10142 sgd_solver.cpp:105] Iteration 91100, lr = 0.001
I1005 23:50:07.055213 10142 solver.cpp:218] Iteration 91200 (13.0504 iter/s, 7.66262s/100 iters), loss = 0.0124706
I1005 23:50:07.055372 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0124704 (* 1 = 0.0124704 loss)
I1005 23:50:07.055379 10142 sgd_solver.cpp:105] Iteration 91200, lr = 0.001
I1005 23:50:14.710809 10142 solver.cpp:218] Iteration 91300 (13.0627 iter/s, 7.65541s/100 iters), loss = 0.00107028
I1005 23:50:14.710839 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00107009 (* 1 = 0.00107009 loss)
I1005 23:50:14.710845 10142 sgd_solver.cpp:105] Iteration 91300, lr = 0.001
I1005 23:50:22.366937 10142 solver.cpp:218] Iteration 91400 (13.0615 iter/s, 7.65608s/100 iters), loss = 0.00505197
I1005 23:50:22.366977 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00505178 (* 1 = 0.00505178 loss)
I1005 23:50:22.366983 10142 sgd_solver.cpp:105] Iteration 91400, lr = 0.001
I1005 23:50:29.643541 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:50:29.950220 10142 solver.cpp:330] Iteration 91500, Testing net (#0)
I1005 23:50:31.700680 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:50:31.773967 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9258
I1005 23:50:31.774003 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.305084 (* 1 = 0.305084 loss)
I1005 23:50:31.850849 10142 solver.cpp:218] Iteration 91500 (10.5442 iter/s, 9.48385s/100 iters), loss = 0.0191445
I1005 23:50:31.850879 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0191443 (* 1 = 0.0191443 loss)
I1005 23:50:31.850886 10142 sgd_solver.cpp:105] Iteration 91500, lr = 0.001
I1005 23:50:39.499586 10142 solver.cpp:218] Iteration 91600 (13.0741 iter/s, 7.64868s/100 iters), loss = 0.00224239
I1005 23:50:39.499699 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0022422 (* 1 = 0.0022422 loss)
I1005 23:50:39.499707 10142 sgd_solver.cpp:105] Iteration 91600, lr = 0.001
I1005 23:50:47.157568 10142 solver.cpp:218] Iteration 91700 (13.0585 iter/s, 7.65785s/100 iters), loss = 0.00628453
I1005 23:50:47.157599 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00628434 (* 1 = 0.00628434 loss)
I1005 23:50:47.157605 10142 sgd_solver.cpp:105] Iteration 91700, lr = 0.001
I1005 23:50:54.804595 10142 solver.cpp:218] Iteration 91800 (13.0771 iter/s, 7.64697s/100 iters), loss = 0.000889577
I1005 23:50:54.804630 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000889381 (* 1 = 0.000889381 loss)
I1005 23:50:54.804637 10142 sgd_solver.cpp:105] Iteration 91800, lr = 0.001
I1005 23:51:02.453594 10142 solver.cpp:218] Iteration 91900 (13.0737 iter/s, 7.64894s/100 iters), loss = 0.00135223
I1005 23:51:02.453624 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00135203 (* 1 = 0.00135203 loss)
I1005 23:51:02.453629 10142 sgd_solver.cpp:105] Iteration 91900, lr = 0.001
I1005 23:51:09.721032 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:51:10.032351 10142 solver.cpp:330] Iteration 92000, Testing net (#0)
I1005 23:51:11.772259 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:51:11.845458 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9258
I1005 23:51:11.845491 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.305019 (* 1 = 0.305019 loss)
I1005 23:51:11.922533 10142 solver.cpp:218] Iteration 92000 (10.5609 iter/s, 9.46888s/100 iters), loss = 0.00260572
I1005 23:51:11.922559 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00260552 (* 1 = 0.00260552 loss)
I1005 23:51:11.922566 10142 sgd_solver.cpp:105] Iteration 92000, lr = 0.001
I1005 23:51:19.589417 10142 solver.cpp:218] Iteration 92100 (13.0432 iter/s, 7.66683s/100 iters), loss = 0.00232449
I1005 23:51:19.589448 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0023243 (* 1 = 0.0023243 loss)
I1005 23:51:19.589454 10142 sgd_solver.cpp:105] Iteration 92100, lr = 0.001
I1005 23:51:27.245543 10142 solver.cpp:218] Iteration 92200 (13.0615 iter/s, 7.65607s/100 iters), loss = 0.00208906
I1005 23:51:27.245573 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00208886 (* 1 = 0.00208886 loss)
I1005 23:51:27.245579 10142 sgd_solver.cpp:105] Iteration 92200, lr = 0.001
I1005 23:51:34.908138 10142 solver.cpp:218] Iteration 92300 (13.0505 iter/s, 7.66254s/100 iters), loss = 0.000731323
I1005 23:51:34.908169 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000731126 (* 1 = 0.000731126 loss)
I1005 23:51:34.908185 10142 sgd_solver.cpp:105] Iteration 92300, lr = 0.001
I1005 23:51:42.560217 10142 solver.cpp:218] Iteration 92400 (13.0684 iter/s, 7.65203s/100 iters), loss = 0.0011994
I1005 23:51:42.560358 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0011992 (* 1 = 0.0011992 loss)
I1005 23:51:42.560364 10142 sgd_solver.cpp:105] Iteration 92400, lr = 0.001
I1005 23:51:49.836649 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:51:50.142238 10142 solver.cpp:330] Iteration 92500, Testing net (#0)
I1005 23:51:51.888615 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:51:51.962239 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9274
I1005 23:51:51.962265 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.303972 (* 1 = 0.303972 loss)
I1005 23:51:52.039304 10142 solver.cpp:218] Iteration 92500 (10.5497 iter/s, 9.47893s/100 iters), loss = 0.000839952
I1005 23:51:52.039335 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000839752 (* 1 = 0.000839752 loss)
I1005 23:51:52.039343 10142 sgd_solver.cpp:105] Iteration 92500, lr = 0.001
I1005 23:51:59.690882 10142 solver.cpp:218] Iteration 92600 (13.0693 iter/s, 7.65152s/100 iters), loss = 0.00392776
I1005 23:51:59.690923 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00392756 (* 1 = 0.00392756 loss)
I1005 23:51:59.690929 10142 sgd_solver.cpp:105] Iteration 92600, lr = 0.001
I1005 23:52:07.358229 10142 solver.cpp:218] Iteration 92700 (13.0424 iter/s, 7.66727s/100 iters), loss = 0.00343575
I1005 23:52:07.358259 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00343554 (* 1 = 0.00343554 loss)
I1005 23:52:07.358275 10142 sgd_solver.cpp:105] Iteration 92700, lr = 0.001
I1005 23:52:15.014309 10142 solver.cpp:218] Iteration 92800 (13.0616 iter/s, 7.65603s/100 iters), loss = 0.00143108
I1005 23:52:15.014410 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00143087 (* 1 = 0.00143087 loss)
I1005 23:52:15.014428 10142 sgd_solver.cpp:105] Iteration 92800, lr = 0.001
I1005 23:52:22.686190 10142 solver.cpp:218] Iteration 92900 (13.0348 iter/s, 7.67176s/100 iters), loss = 0.00200484
I1005 23:52:22.686224 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00200463 (* 1 = 0.00200463 loss)
I1005 23:52:22.686230 10142 sgd_solver.cpp:105] Iteration 92900, lr = 0.001
I1005 23:52:29.968828 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:52:30.276042 10142 solver.cpp:330] Iteration 93000, Testing net (#0)
I1005 23:52:32.022656 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:52:32.095069 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9276
I1005 23:52:32.095104 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.303418 (* 1 = 0.303418 loss)
I1005 23:52:32.172022 10142 solver.cpp:218] Iteration 93000 (10.5421 iter/s, 9.48577s/100 iters), loss = 0.00155565
I1005 23:52:32.172055 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00155544 (* 1 = 0.00155544 loss)
I1005 23:52:32.172062 10142 sgd_solver.cpp:105] Iteration 93000, lr = 0.001
I1005 23:52:39.831584 10142 solver.cpp:218] Iteration 93100 (13.0557 iter/s, 7.6595s/100 iters), loss = 0.0025286
I1005 23:52:39.831631 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0025284 (* 1 = 0.0025284 loss)
I1005 23:52:39.831638 10142 sgd_solver.cpp:105] Iteration 93100, lr = 0.001
I1005 23:52:47.477632 10142 solver.cpp:218] Iteration 93200 (13.0788 iter/s, 7.64595s/100 iters), loss = 0.00198652
I1005 23:52:47.477790 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00198632 (* 1 = 0.00198632 loss)
I1005 23:52:47.477798 10142 sgd_solver.cpp:105] Iteration 93200, lr = 0.001
I1005 23:52:55.142406 10142 solver.cpp:218] Iteration 93300 (13.047 iter/s, 7.6646s/100 iters), loss = 0.013119
I1005 23:52:55.142437 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0131187 (* 1 = 0.0131187 loss)
I1005 23:52:55.142443 10142 sgd_solver.cpp:105] Iteration 93300, lr = 0.001
I1005 23:53:02.794792 10142 solver.cpp:218] Iteration 93400 (13.0679 iter/s, 7.65233s/100 iters), loss = 0.00194466
I1005 23:53:02.794822 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00194445 (* 1 = 0.00194445 loss)
I1005 23:53:02.794828 10142 sgd_solver.cpp:105] Iteration 93400, lr = 0.001
I1005 23:53:10.079571 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:53:10.385982 10142 solver.cpp:330] Iteration 93500, Testing net (#0)
I1005 23:53:12.125761 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:53:12.198933 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9279
I1005 23:53:12.198961 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.303999 (* 1 = 0.303999 loss)
I1005 23:53:12.275667 10142 solver.cpp:218] Iteration 93500 (10.5476 iter/s, 9.48082s/100 iters), loss = 0.00225331
I1005 23:53:12.275699 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00225311 (* 1 = 0.00225311 loss)
I1005 23:53:12.275707 10142 sgd_solver.cpp:105] Iteration 93500, lr = 0.001
I1005 23:53:19.934319 10142 solver.cpp:218] Iteration 93600 (13.0572 iter/s, 7.6586s/100 iters), loss = 0.000898872
I1005 23:53:19.934438 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000898665 (* 1 = 0.000898665 loss)
I1005 23:53:19.934447 10142 sgd_solver.cpp:105] Iteration 93600, lr = 0.001
I1005 23:53:27.587018 10142 solver.cpp:218] Iteration 93700 (13.0675 iter/s, 7.65256s/100 iters), loss = 0.00176994
I1005 23:53:27.587049 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00176974 (* 1 = 0.00176974 loss)
I1005 23:53:27.587055 10142 sgd_solver.cpp:105] Iteration 93700, lr = 0.001
I1005 23:53:35.242663 10142 solver.cpp:218] Iteration 93800 (13.0624 iter/s, 7.65559s/100 iters), loss = 0.000917363
I1005 23:53:35.242694 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000917157 (* 1 = 0.000917157 loss)
I1005 23:53:35.242700 10142 sgd_solver.cpp:105] Iteration 93800, lr = 0.001
I1005 23:53:42.902845 10142 solver.cpp:218] Iteration 93900 (13.0546 iter/s, 7.66013s/100 iters), loss = 0.00593561
I1005 23:53:42.902881 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00593541 (* 1 = 0.00593541 loss)
I1005 23:53:42.902889 10142 sgd_solver.cpp:105] Iteration 93900, lr = 0.001
I1005 23:53:50.181583 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:53:50.487277 10142 solver.cpp:330] Iteration 94000, Testing net (#0)
I1005 23:53:52.236899 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:53:52.310048 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9267
I1005 23:53:52.310084 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.302712 (* 1 = 0.302712 loss)
I1005 23:53:52.386445 10142 solver.cpp:218] Iteration 94000 (10.5446 iter/s, 9.48354s/100 iters), loss = 0.00144037
I1005 23:53:52.386474 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00144017 (* 1 = 0.00144017 loss)
I1005 23:53:52.386482 10142 sgd_solver.cpp:105] Iteration 94000, lr = 0.001
I1005 23:54:00.040969 10142 solver.cpp:218] Iteration 94100 (13.0643 iter/s, 7.65447s/100 iters), loss = 0.00552181
I1005 23:54:00.041000 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0055216 (* 1 = 0.0055216 loss)
I1005 23:54:00.041007 10142 sgd_solver.cpp:105] Iteration 94100, lr = 0.001
I1005 23:54:07.700810 10142 solver.cpp:218] Iteration 94200 (13.0552 iter/s, 7.65979s/100 iters), loss = 0.0062933
I1005 23:54:07.700840 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00629309 (* 1 = 0.00629309 loss)
I1005 23:54:07.700846 10142 sgd_solver.cpp:105] Iteration 94200, lr = 0.001
I1005 23:54:15.350901 10142 solver.cpp:218] Iteration 94300 (13.0718 iter/s, 7.65004s/100 iters), loss = 0.00200055
I1005 23:54:15.350930 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00200035 (* 1 = 0.00200035 loss)
I1005 23:54:15.350936 10142 sgd_solver.cpp:105] Iteration 94300, lr = 0.001
I1005 23:54:23.011899 10142 solver.cpp:218] Iteration 94400 (13.0532 iter/s, 7.66094s/100 iters), loss = 0.00131038
I1005 23:54:23.011991 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00131017 (* 1 = 0.00131017 loss)
I1005 23:54:23.011998 10142 sgd_solver.cpp:105] Iteration 94400, lr = 0.001
I1005 23:54:30.287526 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:54:30.594126 10142 solver.cpp:330] Iteration 94500, Testing net (#0)
I1005 23:54:32.343195 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:54:32.415755 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9264
I1005 23:54:32.415781 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.304497 (* 1 = 0.304497 loss)
I1005 23:54:32.492669 10142 solver.cpp:218] Iteration 94500 (10.5478 iter/s, 9.48065s/100 iters), loss = 0.00102615
I1005 23:54:32.492696 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00102595 (* 1 = 0.00102595 loss)
I1005 23:54:32.492703 10142 sgd_solver.cpp:105] Iteration 94500, lr = 0.001
I1005 23:54:40.148613 10142 solver.cpp:218] Iteration 94600 (13.0618 iter/s, 7.65589s/100 iters), loss = 0.00467492
I1005 23:54:40.148668 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00467472 (* 1 = 0.00467472 loss)
I1005 23:54:40.148684 10142 sgd_solver.cpp:105] Iteration 94600, lr = 0.001
I1005 23:54:47.807554 10142 solver.cpp:218] Iteration 94700 (13.0568 iter/s, 7.65886s/100 iters), loss = 0.00139708
I1005 23:54:47.807593 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00139688 (* 1 = 0.00139688 loss)
I1005 23:54:47.807600 10142 sgd_solver.cpp:105] Iteration 94700, lr = 0.001
I1005 23:54:55.463271 10142 solver.cpp:218] Iteration 94800 (13.0622 iter/s, 7.65566s/100 iters), loss = 0.0019614
I1005 23:54:55.463387 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00196119 (* 1 = 0.00196119 loss)
I1005 23:54:55.463393 10142 sgd_solver.cpp:105] Iteration 94800, lr = 0.001
I1005 23:55:03.114163 10142 solver.cpp:218] Iteration 94900 (13.0706 iter/s, 7.65076s/100 iters), loss = 0.000615482
I1005 23:55:03.114192 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000615273 (* 1 = 0.000615273 loss)
I1005 23:55:03.114198 10142 sgd_solver.cpp:105] Iteration 94900, lr = 0.001
I1005 23:55:10.386057 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:55:10.691823 10142 solver.cpp:330] Iteration 95000, Testing net (#0)
I1005 23:55:12.431506 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:55:12.504719 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9261
I1005 23:55:12.504756 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.305109 (* 1 = 0.305109 loss)
I1005 23:55:12.581791 10142 solver.cpp:218] Iteration 95000 (10.5624 iter/s, 9.46757s/100 iters), loss = 0.00180158
I1005 23:55:12.581825 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00180137 (* 1 = 0.00180137 loss)
I1005 23:55:12.581833 10142 sgd_solver.cpp:105] Iteration 95000, lr = 0.001
I1005 23:55:20.255731 10142 solver.cpp:218] Iteration 95100 (13.0312 iter/s, 7.67388s/100 iters), loss = 0.00124668
I1005 23:55:20.255761 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00124647 (* 1 = 0.00124647 loss)
I1005 23:55:20.255777 10142 sgd_solver.cpp:105] Iteration 95100, lr = 0.001
I1005 23:55:27.924131 10142 solver.cpp:218] Iteration 95200 (13.0406 iter/s, 7.66834s/100 iters), loss = 0.00527685
I1005 23:55:27.924309 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00527665 (* 1 = 0.00527665 loss)
I1005 23:55:27.924329 10142 sgd_solver.cpp:105] Iteration 95200, lr = 0.001
I1005 23:55:35.593041 10142 solver.cpp:218] Iteration 95300 (13.04 iter/s, 7.66871s/100 iters), loss = 0.0311084
I1005 23:55:35.593072 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0311082 (* 1 = 0.0311082 loss)
I1005 23:55:35.593088 10142 sgd_solver.cpp:105] Iteration 95300, lr = 0.001
I1005 23:55:43.261237 10142 solver.cpp:218] Iteration 95400 (13.041 iter/s, 7.66814s/100 iters), loss = 0.00152192
I1005 23:55:43.261271 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00152171 (* 1 = 0.00152171 loss)
I1005 23:55:43.261287 10142 sgd_solver.cpp:105] Iteration 95400, lr = 0.001
I1005 23:55:50.546368 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:55:50.852012 10142 solver.cpp:330] Iteration 95500, Testing net (#0)
I1005 23:55:52.599604 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:55:52.672466 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.926601
I1005 23:55:52.672493 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.305193 (* 1 = 0.305193 loss)
I1005 23:55:52.748705 10142 solver.cpp:218] Iteration 95500 (10.5403 iter/s, 9.48741s/100 iters), loss = 0.0035108
I1005 23:55:52.748741 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00351059 (* 1 = 0.00351059 loss)
I1005 23:55:52.748750 10142 sgd_solver.cpp:105] Iteration 95500, lr = 0.001
I1005 23:56:00.396256 10142 solver.cpp:218] Iteration 95600 (13.0762 iter/s, 7.64749s/100 iters), loss = 0.00917247
I1005 23:56:00.396368 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00917226 (* 1 = 0.00917226 loss)
I1005 23:56:00.396375 10142 sgd_solver.cpp:105] Iteration 95600, lr = 0.001
I1005 23:56:08.059270 10142 solver.cpp:218] Iteration 95700 (13.0499 iter/s, 7.66289s/100 iters), loss = 0.0022054
I1005 23:56:08.059310 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00220519 (* 1 = 0.00220519 loss)
I1005 23:56:08.059316 10142 sgd_solver.cpp:105] Iteration 95700, lr = 0.001
I1005 23:56:15.711835 10142 solver.cpp:218] Iteration 95800 (13.0676 iter/s, 7.6525s/100 iters), loss = 0.00308738
I1005 23:56:15.711881 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00308717 (* 1 = 0.00308717 loss)
I1005 23:56:15.711889 10142 sgd_solver.cpp:105] Iteration 95800, lr = 0.001
I1005 23:56:23.378571 10142 solver.cpp:218] Iteration 95900 (13.0435 iter/s, 7.66663s/100 iters), loss = 0.00223844
I1005 23:56:23.378599 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00223823 (* 1 = 0.00223823 loss)
I1005 23:56:23.378605 10142 sgd_solver.cpp:105] Iteration 95900, lr = 0.001
I1005 23:56:30.651218 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:56:30.964920 10142 solver.cpp:330] Iteration 96000, Testing net (#0)
I1005 23:56:32.704506 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:56:32.777335 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9268
I1005 23:56:32.777371 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.304639 (* 1 = 0.304639 loss)
I1005 23:56:32.854360 10142 solver.cpp:218] Iteration 96000 (10.5533 iter/s, 9.47574s/100 iters), loss = 0.00169246
I1005 23:56:32.854387 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00169225 (* 1 = 0.00169225 loss)
I1005 23:56:32.854394 10142 sgd_solver.cpp:105] Iteration 96000, lr = 0.001
I1005 23:56:40.510226 10142 solver.cpp:218] Iteration 96100 (13.062 iter/s, 7.65582s/100 iters), loss = 0.00162515
I1005 23:56:40.510257 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00162494 (* 1 = 0.00162494 loss)
I1005 23:56:40.510262 10142 sgd_solver.cpp:105] Iteration 96100, lr = 0.001
I1005 23:56:48.148885 10142 solver.cpp:218] Iteration 96200 (13.0914 iter/s, 7.63861s/100 iters), loss = 0.00281058
I1005 23:56:48.148914 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00281038 (* 1 = 0.00281038 loss)
I1005 23:56:48.148921 10142 sgd_solver.cpp:105] Iteration 96200, lr = 0.001
I1005 23:56:55.806779 10142 solver.cpp:218] Iteration 96300 (13.0585 iter/s, 7.65784s/100 iters), loss = 0.00196806
I1005 23:56:55.806820 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00196785 (* 1 = 0.00196785 loss)
I1005 23:56:55.806826 10142 sgd_solver.cpp:105] Iteration 96300, lr = 0.001
I1005 23:57:03.457450 10142 solver.cpp:218] Iteration 96400 (13.0709 iter/s, 7.65061s/100 iters), loss = 0.000822741
I1005 23:57:03.457592 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000822537 (* 1 = 0.000822537 loss)
I1005 23:57:03.457609 10142 sgd_solver.cpp:105] Iteration 96400, lr = 0.001
I1005 23:57:10.745715 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:57:11.051250 10142 solver.cpp:330] Iteration 96500, Testing net (#0)
I1005 23:57:12.795228 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:57:12.871116 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9264
I1005 23:57:12.871141 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.304657 (* 1 = 0.304657 loss)
I1005 23:57:12.949666 10142 solver.cpp:218] Iteration 96500 (10.5351 iter/s, 9.49205s/100 iters), loss = 0.00154926
I1005 23:57:12.949712 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00154906 (* 1 = 0.00154906 loss)
I1005 23:57:12.949720 10142 sgd_solver.cpp:105] Iteration 96500, lr = 0.001
I1005 23:57:20.602313 10142 solver.cpp:218] Iteration 96600 (13.0675 iter/s, 7.65254s/100 iters), loss = 0.00130467
I1005 23:57:20.602344 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00130447 (* 1 = 0.00130447 loss)
I1005 23:57:20.602350 10142 sgd_solver.cpp:105] Iteration 96600, lr = 0.001
I1005 23:57:28.256222 10142 solver.cpp:218] Iteration 96700 (13.0653 iter/s, 7.65385s/100 iters), loss = 0.00570383
I1005 23:57:28.256253 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00570362 (* 1 = 0.00570362 loss)
I1005 23:57:28.256258 10142 sgd_solver.cpp:105] Iteration 96700, lr = 0.001
I1005 23:57:35.906191 10142 solver.cpp:218] Iteration 96800 (13.072 iter/s, 7.64992s/100 iters), loss = 0.00338732
I1005 23:57:35.906308 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00338712 (* 1 = 0.00338712 loss)
I1005 23:57:35.906316 10142 sgd_solver.cpp:105] Iteration 96800, lr = 0.001
I1005 23:57:43.573732 10142 solver.cpp:218] Iteration 96900 (13.0422 iter/s, 7.6674s/100 iters), loss = 0.000931807
I1005 23:57:43.573772 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000931603 (* 1 = 0.000931603 loss)
I1005 23:57:43.573778 10142 sgd_solver.cpp:105] Iteration 96900, lr = 0.001
I1005 23:57:50.852041 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:57:51.157213 10142 solver.cpp:330] Iteration 97000, Testing net (#0)
I1005 23:57:52.908272 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:57:52.981271 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9269
I1005 23:57:52.981305 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.30504 (* 1 = 0.30504 loss)
I1005 23:57:53.058259 10142 solver.cpp:218] Iteration 97000 (10.5436 iter/s, 9.48446s/100 iters), loss = 0.00125883
I1005 23:57:53.058286 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00125863 (* 1 = 0.00125863 loss)
I1005 23:57:53.058293 10142 sgd_solver.cpp:105] Iteration 97000, lr = 0.001
I1005 23:58:00.717866 10142 solver.cpp:218] Iteration 97100 (13.0556 iter/s, 7.65955s/100 iters), loss = 0.00349144
I1005 23:58:00.717903 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00349124 (* 1 = 0.00349124 loss)
I1005 23:58:00.717911 10142 sgd_solver.cpp:105] Iteration 97100, lr = 0.001
I1005 23:58:08.372378 10142 solver.cpp:218] Iteration 97200 (13.0645 iter/s, 7.65434s/100 iters), loss = 0.00265834
I1005 23:58:08.372546 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00265813 (* 1 = 0.00265813 loss)
I1005 23:58:08.372572 10142 sgd_solver.cpp:105] Iteration 97200, lr = 0.001
I1005 23:58:16.033394 10142 solver.cpp:218] Iteration 97300 (13.0534 iter/s, 7.66083s/100 iters), loss = 0.000669054
I1005 23:58:16.033428 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000668848 (* 1 = 0.000668848 loss)
I1005 23:58:16.033437 10142 sgd_solver.cpp:105] Iteration 97300, lr = 0.001
I1005 23:58:23.683393 10142 solver.cpp:218] Iteration 97400 (13.072 iter/s, 7.64994s/100 iters), loss = 0.0008399
I1005 23:58:23.683423 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000839696 (* 1 = 0.000839696 loss)
I1005 23:58:23.683440 10142 sgd_solver.cpp:105] Iteration 97400, lr = 0.001
I1005 23:58:30.966434 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:58:31.273151 10142 solver.cpp:330] Iteration 97500, Testing net (#0)
I1005 23:58:33.012248 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:58:33.085302 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9271
I1005 23:58:33.085337 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.304706 (* 1 = 0.304706 loss)
I1005 23:58:33.162312 10142 solver.cpp:218] Iteration 97500 (10.5498 iter/s, 9.47886s/100 iters), loss = 0.000611871
I1005 23:58:33.162343 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000611667 (* 1 = 0.000611667 loss)
I1005 23:58:33.162350 10142 sgd_solver.cpp:105] Iteration 97500, lr = 0.001
I1005 23:58:40.825798 10142 solver.cpp:218] Iteration 97600 (13.049 iter/s, 7.66343s/100 iters), loss = 0.00192108
I1005 23:58:40.825908 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00192087 (* 1 = 0.00192087 loss)
I1005 23:58:40.825915 10142 sgd_solver.cpp:105] Iteration 97600, lr = 0.001
I1005 23:58:48.483827 10142 solver.cpp:218] Iteration 97700 (13.0584 iter/s, 7.6579s/100 iters), loss = 0.0006001
I1005 23:58:48.483868 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000599889 (* 1 = 0.000599889 loss)
I1005 23:58:48.483875 10142 sgd_solver.cpp:105] Iteration 97700, lr = 0.001
I1005 23:58:56.139320 10142 solver.cpp:218] Iteration 97800 (13.0626 iter/s, 7.65543s/100 iters), loss = 0.0015181
I1005 23:58:56.139361 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00151789 (* 1 = 0.00151789 loss)
I1005 23:58:56.139367 10142 sgd_solver.cpp:105] Iteration 97800, lr = 0.001
I1005 23:59:03.788820 10142 solver.cpp:218] Iteration 97900 (13.0729 iter/s, 7.64943s/100 iters), loss = 0.00517041
I1005 23:59:03.788858 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0051702 (* 1 = 0.0051702 loss)
I1005 23:59:03.788877 10142 sgd_solver.cpp:105] Iteration 97900, lr = 0.001
I1005 23:59:11.060109 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:59:11.366375 10142 solver.cpp:330] Iteration 98000, Testing net (#0)
I1005 23:59:13.114648 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:59:13.187747 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9262
I1005 23:59:13.187772 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.305456 (* 1 = 0.305456 loss)
I1005 23:59:13.264650 10142 solver.cpp:218] Iteration 98000 (10.5532 iter/s, 9.47576s/100 iters), loss = 0.0211899
I1005 23:59:13.264683 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0211897 (* 1 = 0.0211897 loss)
I1005 23:59:13.264691 10142 sgd_solver.cpp:105] Iteration 98000, lr = 0.001
I1005 23:59:20.928539 10142 solver.cpp:218] Iteration 98100 (13.0483 iter/s, 7.66383s/100 iters), loss = 0.0043049
I1005 23:59:20.928580 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00430469 (* 1 = 0.00430469 loss)
I1005 23:59:20.928586 10142 sgd_solver.cpp:105] Iteration 98100, lr = 0.001
I1005 23:59:28.597800 10142 solver.cpp:218] Iteration 98200 (13.0392 iter/s, 7.6692s/100 iters), loss = 0.00231044
I1005 23:59:28.597829 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00231023 (* 1 = 0.00231023 loss)
I1005 23:59:28.597836 10142 sgd_solver.cpp:105] Iteration 98200, lr = 0.001
I1005 23:59:36.265457 10142 solver.cpp:218] Iteration 98300 (13.0419 iter/s, 7.6676s/100 iters), loss = 0.00142601
I1005 23:59:36.265486 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0014258 (* 1 = 0.0014258 loss)
I1005 23:59:36.265492 10142 sgd_solver.cpp:105] Iteration 98300, lr = 0.001
I1005 23:59:43.935783 10142 solver.cpp:218] Iteration 98400 (13.0373 iter/s, 7.67027s/100 iters), loss = 0.013038
I1005 23:59:43.935906 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0130378 (* 1 = 0.0130378 loss)
I1005 23:59:43.935925 10142 sgd_solver.cpp:105] Iteration 98400, lr = 0.001
I1005 23:59:51.216141 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:59:51.522186 10142 solver.cpp:330] Iteration 98500, Testing net (#0)
I1005 23:59:53.268050 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1005 23:59:53.341481 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.927
I1005 23:59:53.341517 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.305645 (* 1 = 0.305645 loss)
I1005 23:59:53.418680 10142 solver.cpp:218] Iteration 98500 (10.5455 iter/s, 9.48275s/100 iters), loss = 0.00742587
I1005 23:59:53.418709 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00742566 (* 1 = 0.00742566 loss)
I1005 23:59:53.418716 10142 sgd_solver.cpp:105] Iteration 98500, lr = 0.001
I1006 00:00:01.089258 10142 solver.cpp:218] Iteration 98600 (13.0369 iter/s, 7.67052s/100 iters), loss = 0.00390614
I1006 00:00:01.089290 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00390593 (* 1 = 0.00390593 loss)
I1006 00:00:01.089298 10142 sgd_solver.cpp:105] Iteration 98600, lr = 0.001
I1006 00:00:08.748324 10142 solver.cpp:218] Iteration 98700 (13.0565 iter/s, 7.65901s/100 iters), loss = 0.00576099
I1006 00:00:08.748354 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00576077 (* 1 = 0.00576077 loss)
I1006 00:00:08.748360 10142 sgd_solver.cpp:105] Iteration 98700, lr = 0.001
I1006 00:00:16.419854 10142 solver.cpp:218] Iteration 98800 (13.0353 iter/s, 7.67147s/100 iters), loss = 0.0163537
I1006 00:00:16.419982 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0163535 (* 1 = 0.0163535 loss)
I1006 00:00:16.419992 10142 sgd_solver.cpp:105] Iteration 98800, lr = 0.001
I1006 00:00:24.076505 10142 solver.cpp:218] Iteration 98900 (13.0608 iter/s, 7.6565s/100 iters), loss = 0.00103104
I1006 00:00:24.076550 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00103082 (* 1 = 0.00103082 loss)
I1006 00:00:24.076567 10142 sgd_solver.cpp:105] Iteration 98900, lr = 0.001
I1006 00:00:31.361793 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1006 00:00:31.668318 10142 solver.cpp:330] Iteration 99000, Testing net (#0)
I1006 00:00:33.407860 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1006 00:00:33.481101 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9261
I1006 00:00:33.481137 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.306016 (* 1 = 0.306016 loss)
I1006 00:00:33.557783 10142 solver.cpp:218] Iteration 99000 (10.5472 iter/s, 9.48121s/100 iters), loss = 0.00141258
I1006 00:00:33.557817 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00141237 (* 1 = 0.00141237 loss)
I1006 00:00:33.557826 10142 sgd_solver.cpp:105] Iteration 99000, lr = 0.001
I1006 00:00:41.218524 10142 solver.cpp:218] Iteration 99100 (13.0537 iter/s, 7.66068s/100 iters), loss = 0.00386724
I1006 00:00:41.218564 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00386703 (* 1 = 0.00386703 loss)
I1006 00:00:41.218578 10142 sgd_solver.cpp:105] Iteration 99100, lr = 0.001
I1006 00:00:48.866719 10142 solver.cpp:218] Iteration 99200 (13.0751 iter/s, 7.64813s/100 iters), loss = 0.00415284
I1006 00:00:48.866863 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00415263 (* 1 = 0.00415263 loss)
I1006 00:00:48.866871 10142 sgd_solver.cpp:105] Iteration 99200, lr = 0.001
I1006 00:00:56.522701 10142 solver.cpp:218] Iteration 99300 (13.062 iter/s, 7.65582s/100 iters), loss = 0.00188712
I1006 00:00:56.522732 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00188691 (* 1 = 0.00188691 loss)
I1006 00:00:56.522738 10142 sgd_solver.cpp:105] Iteration 99300, lr = 0.001
I1006 00:01:04.185780 10142 solver.cpp:218] Iteration 99400 (13.0497 iter/s, 7.66302s/100 iters), loss = 0.00155545
I1006 00:01:04.185811 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00155523 (* 1 = 0.00155523 loss)
I1006 00:01:04.185817 10142 sgd_solver.cpp:105] Iteration 99400, lr = 0.001
I1006 00:01:11.468480 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1006 00:01:11.774533 10142 solver.cpp:330] Iteration 99500, Testing net (#0)
I1006 00:01:13.523564 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1006 00:01:13.596743 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.926
I1006 00:01:13.596778 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.307413 (* 1 = 0.307413 loss)
I1006 00:01:13.673905 10142 solver.cpp:218] Iteration 99500 (10.5396 iter/s, 9.48807s/100 iters), loss = 0.00123117
I1006 00:01:13.673938 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00123096 (* 1 = 0.00123096 loss)
I1006 00:01:13.673944 10142 sgd_solver.cpp:105] Iteration 99500, lr = 0.001
I1006 00:01:21.317857 10142 solver.cpp:218] Iteration 99600 (13.0823 iter/s, 7.64389s/100 iters), loss = 0.00679191
I1006 00:01:21.317970 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0067917 (* 1 = 0.0067917 loss)
I1006 00:01:21.317978 10142 sgd_solver.cpp:105] Iteration 99600, lr = 0.001
I1006 00:01:28.976270 10142 solver.cpp:218] Iteration 99700 (13.0577 iter/s, 7.65829s/100 iters), loss = 0.00199958
I1006 00:01:28.976311 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00199937 (* 1 = 0.00199937 loss)
I1006 00:01:28.976317 10142 sgd_solver.cpp:105] Iteration 99700, lr = 0.001
I1006 00:01:36.624403 10142 solver.cpp:218] Iteration 99800 (13.0752 iter/s, 7.64807s/100 iters), loss = 0.000933914
I1006 00:01:36.624434 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000933701 (* 1 = 0.000933701 loss)
I1006 00:01:36.624441 10142 sgd_solver.cpp:105] Iteration 99800, lr = 0.001
I1006 00:01:44.290452 10142 solver.cpp:218] Iteration 99900 (13.0446 iter/s, 7.666s/100 iters), loss = 0.00116785
I1006 00:01:44.290482 10142 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00116764 (* 1 = 0.00116764 loss)
I1006 00:01:44.290488 10142 sgd_solver.cpp:105] Iteration 99900, lr = 0.001
I1006 00:01:51.563530 10147 data_layer.cpp:73] Restarting data prefetching from start.
I1006 00:01:51.875177 10142 solver.cpp:447] Snapshotting to binary proto file xn/PENLU/snapshot/resnet/res32/res32_relu_gauss_iter_100000.caffemodel
I1006 00:01:51.887248 10142 sgd_solver.cpp:273] Snapshotting solver state to binary proto file xn/PENLU/snapshot/resnet/res32/res32_relu_gauss_iter_100000.solverstate
I1006 00:01:51.909471 10142 solver.cpp:310] Iteration 100000, loss = 0.00651504
I1006 00:01:51.909498 10142 solver.cpp:330] Iteration 100000, Testing net (#0)
I1006 00:01:53.651278 10148 data_layer.cpp:73] Restarting data prefetching from start.
I1006 00:01:53.724373 10142 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9258
I1006 00:01:53.724398 10142 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.307437 (* 1 = 0.307437 loss)
I1006 00:01:53.724402 10142 solver.cpp:315] Optimization Done.
I1006 00:01:53.724405 10142 caffe.cpp:259] Optimization Done.
