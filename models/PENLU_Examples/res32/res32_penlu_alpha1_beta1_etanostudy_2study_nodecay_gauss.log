I1006 21:21:49.421849  4081 caffe.cpp:218] Using GPUs 0
I1006 21:21:49.425262  4081 caffe.cpp:223] GPU 0: GeForce GTX 1080
I1006 21:21:49.927266  4081 solver.cpp:44] Initializing solver from parameters: 
test_iter: 100
test_interval: 500
base_lr: 0.1
display: 100
max_iter: 100000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0001
snapshot: 100000
snapshot_prefix: "xn/PENLU/snapshot/resnet/res32/res32_penlu_alpha1_beta1_etanostudy_2study_nodecay_gauss"
solver_mode: GPU
device_id: 0
net: "/home/x306/caffe/xn/PENLU/neural/resnet/res32/res32_penlu_gauss.prototxt"
train_state {
  level: 0
  stage: ""
}
stepvalue: 40000
stepvalue: 80000
I1006 21:21:49.927399  4081 solver.cpp:87] Creating training net from net file: /home/x306/caffe/xn/PENLU/neural/resnet/res32/res32_penlu_gauss.prototxt
I1006 21:21:49.929785  4081 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: /home/x306/caffe/xn/PENLU/neural/resnet/res32/res32_penlu_gauss.prototxt
I1006 21:21:49.929805  4081 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I1006 21:21:49.929994  4081 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer Data1
I1006 21:21:49.930099  4081 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer Accuracy1
I1006 21:21:49.930817  4081 net.cpp:51] Initializing net from parameters: 
name: "resnet_cifar10"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "Data1"
  type: "Data"
  top: "Data1"
  top: "Data2"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 28
    mean_file: "/home/x306/caffe/xn/PENLU/data/cifar10/mean.binaryproto"
  }
  data_param {
    source: "/home/x306/caffe/xn/PENLU/data/cifar10/cifar10_train_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "Convolution1"
  type: "Convolution"
  bottom: "Data1"
  top: "Convolution1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm1"
  type: "BatchNorm"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1"
  type: "Scale"
  bottom: "Convolution1"
  top: "Convolution1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu1"
  type: "PENLU"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution2"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm2"
  type: "BatchNorm"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale2"
  type: "Scale"
  bottom: "Convolution2"
  top: "Convolution2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu2"
  type: "PENLU"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution3"
  type: "Convolution"
  bottom: "Convolution2"
  top: "Convolution3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm3"
  type: "BatchNorm"
  bottom: "Convolution3"
  top: "Convolution3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale3"
  type: "Scale"
  bottom: "Convolution3"
  top: "Convolution3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise1"
  type: "Eltwise"
  bottom: "Convolution1"
  bottom: "Convolution3"
  top: "Eltwise1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu3"
  type: "PENLU"
  bottom: "Eltwise1"
  top: "Eltwise1"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution4"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm4"
  type: "BatchNorm"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale4"
  type: "Scale"
  bottom: "Convolution4"
  top: "Convolution4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu4"
  type: "PENLU"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution5"
  type: "Convolution"
  bottom: "Convolution4"
  top: "Convolution5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm5"
  type: "BatchNorm"
  bottom: "Convolution5"
  top: "Convolution5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale5"
  type: "Scale"
  bottom: "Convolution5"
  top: "Convolution5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise2"
  type: "Eltwise"
  bottom: "Eltwise1"
  bottom: "Convolution5"
  top: "Eltwise2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu5"
  type: "PENLU"
  bottom: "Eltwise2"
  top: "Eltwise2"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution6"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm6"
  type: "BatchNorm"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale6"
  type: "Scale"
  bottom: "Convolution6"
  top: "Convolution6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu6"
  type: "PENLU"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution7"
  type: "Convolution"
  bottom: "Convolution6"
  top: "Convolution7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm7"
  type: "BatchNorm"
  bottom: "Convolution7"
  top: "Convolution7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale7"
  type: "Scale"
  bottom: "Convolution7"
  top: "Convolution7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise3"
  type: "Eltwise"
  bottom: "Eltwise2"
  bottom: "Convolution7"
  top: "Eltwise3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu7"
  type: "PENLU"
  bottom: "Eltwise3"
  top: "Eltwise3"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution8"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm8"
  type: "BatchNorm"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale8"
  type: "Scale"
  bottom: "Convolution8"
  top: "Convolution8"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu8"
  type: "PENLU"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution9"
  type: "Convolution"
  bottom: "Convolution8"
  top: "Convolution9"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm9"
  type: "BatchNorm"
  bottom: "Convolution9"
  top: "Convolution9"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale9"
  type: "Scale"
  bottom: "Convolution9"
  top: "Convolution9"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise4"
  type: "Eltwise"
  bottom: "Eltwise3"
  bottom: "Convolution9"
  top: "Eltwise4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu9"
  type: "PENLU"
  bottom: "Eltwise4"
  top: "Eltwise4"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution10"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution10"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm10"
  type: "BatchNorm"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale10"
  type: "Scale"
  bottom: "Convolution10"
  top: "Convolution10"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu10"
  type: "PENLU"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution11"
  type: "Convolution"
  bottom: "Convolution10"
  top: "Convolution11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm11"
  type: "BatchNorm"
  bottom: "Convolution11"
  top: "Convolution11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale11"
  type: "Scale"
  bottom: "Convolution11"
  top: "Convolution11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise5"
  type: "Eltwise"
  bottom: "Eltwise4"
  bottom: "Convolution11"
  top: "Eltwise5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu11"
  type: "PENLU"
  bottom: "Eltwise5"
  top: "Eltwise5"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution12"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.25
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm12"
  type: "BatchNorm"
  bottom: "Convolution12"
  top: "Convolution12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale12"
  type: "Scale"
  bottom: "Convolution12"
  top: "Convolution12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution13"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution13"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm13"
  type: "BatchNorm"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale13"
  type: "Scale"
  bottom: "Convolution13"
  top: "Convolution13"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu12"
  type: "PENLU"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution14"
  type: "Convolution"
  bottom: "Convolution13"
  top: "Convolution14"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm14"
  type: "BatchNorm"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale14"
  type: "Scale"
  bottom: "Convolution14"
  top: "Convolution14"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise6"
  type: "Eltwise"
  bottom: "Convolution12"
  bottom: "Convolution14"
  top: "Eltwise6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu13"
  type: "PENLU"
  bottom: "Eltwise6"
  top: "Eltwise6"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution15"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution15"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm15"
  type: "BatchNorm"
  bottom: "Convolution15"
  top: "Convolution15"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale15"
  type: "Scale"
  bottom: "Convolution15"
  top: "Convolution15"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu14"
  type: "PENLU"
  bottom: "Convolution15"
  top: "Convolution15"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution16"
  type: "Convolution"
  bottom: "Convolution15"
  top: "Convolution16"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm16"
  type: "BatchNorm"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale16"
  type: "Scale"
  bottom: "Convolution16"
  top: "Convolution16"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise7"
  type: "Eltwise"
  bottom: "Eltwise6"
  bottom: "Convolution16"
  top: "Eltwise7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu15"
  type: "PENLU"
  bottom: "Eltwise7"
  top: "Eltwise7"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution17"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution17"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm17"
  type: "BatchNorm"
  bottom: "Convolution17"
  top: "Convolution17"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale17"
  type: "Scale"
  bottom: "Convolution17"
  top: "Convolution17"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu16"
  type: "PENLU"
  bottom: "Convolution17"
  top: "Convolution17"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution18"
  type: "Convolution"
  bottom: "Convolution17"
  top: "Convolution18"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm18"
  type: "BatchNorm"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale18"
  type: "Scale"
  bottom: "Convolution18"
  top: "Convolution18"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise8"
  type: "Eltwise"
  bottom: "Eltwise7"
  bottom: "Convolution18"
  top: "Eltwise8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu17"
  type: "PENLU"
  bottom: "Eltwise8"
  top: "Eltwise8"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution19"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution19"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm19"
  type: "BatchNorm"
  bottom: "Convolution19"
  top: "Convolution19"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale19"
  type: "Scale"
  bottom: "Convolution19"
  top: "Convolution19"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu18"
  type: "PENLU"
  bottom: "Convolution19"
  top: "Convolution19"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution20"
  type: "Convolution"
  bottom: "Convolution19"
  top: "Convolution20"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm20"
  type: "BatchNorm"
  bottom: "Convolution20"
  top: "Convolution20"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale20"
  type: "Scale"
  bottom: "Convolution20"
  top: "Convolution20"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise9"
  type: "Eltwise"
  bottom: "Eltwise8"
  bottom: "Convolution20"
  top: "Eltwise9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu19"
  type: "PENLU"
  bottom: "Eltwise9"
  top: "Eltwise9"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution21"
  type: "Convolution"
  bottom: "Eltwise9"
  top: "Convolution21"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm21"
  type: "BatchNorm"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale21"
  type: "Scale"
  bottom: "Convolution21"
  top: "Convolution21"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu20"
  type: "PENLU"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution22"
  type: "Convolution"
  bottom: "Convolution21"
  top: "Convolution22"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm22"
  type: "BatchNorm"
  bottom: "Convolution22"
  top: "Convolution22"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale22"
  type: "Scale"
  bottom: "Convolution22"
  top: "Convolution22"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise10"
  type: "Eltwise"
  bottom: "Eltwise9"
  bottom: "Convolution22"
  top: "Eltwise10"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu21"
  type: "PENLU"
  bottom: "Eltwise10"
  top: "Eltwise10"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution23"
  type: "Convolution"
  bottom: "Eltwise10"
  top: "Convolution23"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.17677669
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm23"
  type: "BatchNorm"
  bottom: "Convolution23"
  top: "Convolution23"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale23"
  type: "Scale"
  bottom: "Convolution23"
  top: "Convolution23"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution24"
  type: "Convolution"
  bottom: "Eltwise10"
  top: "Convolution24"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm24"
  type: "BatchNorm"
  bottom: "Convolution24"
  top: "Convolution24"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale24"
  type: "Scale"
  bottom: "Convolution24"
  top: "Convolution24"
  scale_param {
    bias
I1006 21:21:49.931298  4081 layer_factory.hpp:77] Creating layer Data1
I1006 21:21:49.931367  4081 db_lmdb.cpp:35] Opened lmdb /home/x306/caffe/xn/PENLU/data/cifar10/cifar10_train_lmdb
I1006 21:21:49.931396  4081 net.cpp:84] Creating Layer Data1
I1006 21:21:49.931401  4081 net.cpp:380] Data1 -> Data1
I1006 21:21:49.931421  4081 net.cpp:380] Data1 -> Data2
I1006 21:21:49.931428  4081 data_transformer.cpp:25] Loading mean file from: /home/x306/caffe/xn/PENLU/data/cifar10/mean.binaryproto
I1006 21:21:49.932870  4081 data_layer.cpp:45] output data size: 100,3,28,28
I1006 21:21:49.952076  4081 net.cpp:122] Setting up Data1
I1006 21:21:49.952111  4081 net.cpp:129] Top shape: 100 3 28 28 (235200)
I1006 21:21:49.952114  4081 net.cpp:129] Top shape: 100 (100)
I1006 21:21:49.952117  4081 net.cpp:137] Memory required for data: 941200
I1006 21:21:49.952124  4081 layer_factory.hpp:77] Creating layer Convolution1
I1006 21:21:49.952155  4081 net.cpp:84] Creating Layer Convolution1
I1006 21:21:49.952162  4081 net.cpp:406] Convolution1 <- Data1
I1006 21:21:49.952180  4081 net.cpp:380] Convolution1 -> Convolution1
I1006 21:21:50.268852  4081 net.cpp:122] Setting up Convolution1
I1006 21:21:50.268887  4081 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 21:21:50.268889  4081 net.cpp:137] Memory required for data: 5958800
I1006 21:21:50.268905  4081 layer_factory.hpp:77] Creating layer BatchNorm1
I1006 21:21:50.268924  4081 net.cpp:84] Creating Layer BatchNorm1
I1006 21:21:50.268952  4081 net.cpp:406] BatchNorm1 <- Convolution1
I1006 21:21:50.268970  4081 net.cpp:367] BatchNorm1 -> Convolution1 (in-place)
I1006 21:21:50.269116  4081 net.cpp:122] Setting up BatchNorm1
I1006 21:21:50.269124  4081 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 21:21:50.269136  4081 net.cpp:137] Memory required for data: 10976400
I1006 21:21:50.269145  4081 layer_factory.hpp:77] Creating layer Scale1
I1006 21:21:50.269155  4081 net.cpp:84] Creating Layer Scale1
I1006 21:21:50.269160  4081 net.cpp:406] Scale1 <- Convolution1
I1006 21:21:50.269165  4081 net.cpp:367] Scale1 -> Convolution1 (in-place)
I1006 21:21:50.269213  4081 layer_factory.hpp:77] Creating layer Scale1
I1006 21:21:50.269325  4081 net.cpp:122] Setting up Scale1
I1006 21:21:50.269332  4081 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 21:21:50.269345  4081 net.cpp:137] Memory required for data: 15994000
I1006 21:21:50.269349  4081 layer_factory.hpp:77] Creating layer penlu1
I1006 21:21:50.269361  4081 net.cpp:84] Creating Layer penlu1
I1006 21:21:50.269366  4081 net.cpp:406] penlu1 <- Convolution1
I1006 21:21:50.269373  4081 net.cpp:367] penlu1 -> Convolution1 (in-place)
I1006 21:21:50.269995  4081 net.cpp:122] Setting up penlu1
I1006 21:21:50.270005  4081 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 21:21:50.270018  4081 net.cpp:137] Memory required for data: 21011600
I1006 21:21:50.270025  4081 layer_factory.hpp:77] Creating layer Convolution1_penlu1_0_split
I1006 21:21:50.270031  4081 net.cpp:84] Creating Layer Convolution1_penlu1_0_split
I1006 21:21:50.270036  4081 net.cpp:406] Convolution1_penlu1_0_split <- Convolution1
I1006 21:21:50.270043  4081 net.cpp:380] Convolution1_penlu1_0_split -> Convolution1_penlu1_0_split_0
I1006 21:21:50.270052  4081 net.cpp:380] Convolution1_penlu1_0_split -> Convolution1_penlu1_0_split_1
I1006 21:21:50.270123  4081 net.cpp:122] Setting up Convolution1_penlu1_0_split
I1006 21:21:50.270130  4081 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 21:21:50.270143  4081 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 21:21:50.270145  4081 net.cpp:137] Memory required for data: 31046800
I1006 21:21:50.270148  4081 layer_factory.hpp:77] Creating layer Convolution2
I1006 21:21:50.270167  4081 net.cpp:84] Creating Layer Convolution2
I1006 21:21:50.270171  4081 net.cpp:406] Convolution2 <- Convolution1_penlu1_0_split_0
I1006 21:21:50.270179  4081 net.cpp:380] Convolution2 -> Convolution2
I1006 21:21:50.273627  4081 net.cpp:122] Setting up Convolution2
I1006 21:21:50.273638  4081 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 21:21:50.273643  4081 net.cpp:137] Memory required for data: 36064400
I1006 21:21:50.273653  4081 layer_factory.hpp:77] Creating layer BatchNorm2
I1006 21:21:50.273672  4081 net.cpp:84] Creating Layer BatchNorm2
I1006 21:21:50.273679  4081 net.cpp:406] BatchNorm2 <- Convolution2
I1006 21:21:50.273696  4081 net.cpp:367] BatchNorm2 -> Convolution2 (in-place)
I1006 21:21:50.273849  4081 net.cpp:122] Setting up BatchNorm2
I1006 21:21:50.273856  4081 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 21:21:50.273859  4081 net.cpp:137] Memory required for data: 41082000
I1006 21:21:50.273875  4081 layer_factory.hpp:77] Creating layer Scale2
I1006 21:21:50.273885  4081 net.cpp:84] Creating Layer Scale2
I1006 21:21:50.273892  4081 net.cpp:406] Scale2 <- Convolution2
I1006 21:21:50.273900  4081 net.cpp:367] Scale2 -> Convolution2 (in-place)
I1006 21:21:50.273947  4081 layer_factory.hpp:77] Creating layer Scale2
I1006 21:21:50.274051  4081 net.cpp:122] Setting up Scale2
I1006 21:21:50.274057  4081 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 21:21:50.274060  4081 net.cpp:137] Memory required for data: 46099600
I1006 21:21:50.274080  4081 layer_factory.hpp:77] Creating layer penlu2
I1006 21:21:50.274101  4081 net.cpp:84] Creating Layer penlu2
I1006 21:21:50.274106  4081 net.cpp:406] penlu2 <- Convolution2
I1006 21:21:50.274113  4081 net.cpp:367] penlu2 -> Convolution2 (in-place)
I1006 21:21:50.274212  4081 net.cpp:122] Setting up penlu2
I1006 21:21:50.274219  4081 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 21:21:50.274230  4081 net.cpp:137] Memory required for data: 51117200
I1006 21:21:50.274235  4081 layer_factory.hpp:77] Creating layer Convolution3
I1006 21:21:50.274242  4081 net.cpp:84] Creating Layer Convolution3
I1006 21:21:50.274245  4081 net.cpp:406] Convolution3 <- Convolution2
I1006 21:21:50.274250  4081 net.cpp:380] Convolution3 -> Convolution3
I1006 21:21:50.278184  4081 net.cpp:122] Setting up Convolution3
I1006 21:21:50.278194  4081 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 21:21:50.278198  4081 net.cpp:137] Memory required for data: 56134800
I1006 21:21:50.278203  4081 layer_factory.hpp:77] Creating layer BatchNorm3
I1006 21:21:50.278208  4081 net.cpp:84] Creating Layer BatchNorm3
I1006 21:21:50.278213  4081 net.cpp:406] BatchNorm3 <- Convolution3
I1006 21:21:50.278216  4081 net.cpp:367] BatchNorm3 -> Convolution3 (in-place)
I1006 21:21:50.278339  4081 net.cpp:122] Setting up BatchNorm3
I1006 21:21:50.278344  4081 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 21:21:50.278348  4081 net.cpp:137] Memory required for data: 61152400
I1006 21:21:50.278352  4081 layer_factory.hpp:77] Creating layer Scale3
I1006 21:21:50.278358  4081 net.cpp:84] Creating Layer Scale3
I1006 21:21:50.278362  4081 net.cpp:406] Scale3 <- Convolution3
I1006 21:21:50.278365  4081 net.cpp:367] Scale3 -> Convolution3 (in-place)
I1006 21:21:50.278389  4081 layer_factory.hpp:77] Creating layer Scale3
I1006 21:21:50.278465  4081 net.cpp:122] Setting up Scale3
I1006 21:21:50.278470  4081 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 21:21:50.278473  4081 net.cpp:137] Memory required for data: 66170000
I1006 21:21:50.278477  4081 layer_factory.hpp:77] Creating layer Eltwise1
I1006 21:21:50.278482  4081 net.cpp:84] Creating Layer Eltwise1
I1006 21:21:50.278486  4081 net.cpp:406] Eltwise1 <- Convolution1_penlu1_0_split_1
I1006 21:21:50.278488  4081 net.cpp:406] Eltwise1 <- Convolution3
I1006 21:21:50.278492  4081 net.cpp:380] Eltwise1 -> Eltwise1
I1006 21:21:50.278511  4081 net.cpp:122] Setting up Eltwise1
I1006 21:21:50.278515  4081 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 21:21:50.278517  4081 net.cpp:137] Memory required for data: 71187600
I1006 21:21:50.278519  4081 layer_factory.hpp:77] Creating layer penlu3
I1006 21:21:50.278524  4081 net.cpp:84] Creating Layer penlu3
I1006 21:21:50.278527  4081 net.cpp:406] penlu3 <- Eltwise1
I1006 21:21:50.278532  4081 net.cpp:367] penlu3 -> Eltwise1 (in-place)
I1006 21:21:50.278632  4081 net.cpp:122] Setting up penlu3
I1006 21:21:50.278637  4081 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 21:21:50.278640  4081 net.cpp:137] Memory required for data: 76205200
I1006 21:21:50.278645  4081 layer_factory.hpp:77] Creating layer Eltwise1_penlu3_0_split
I1006 21:21:50.278650  4081 net.cpp:84] Creating Layer Eltwise1_penlu3_0_split
I1006 21:21:50.278652  4081 net.cpp:406] Eltwise1_penlu3_0_split <- Eltwise1
I1006 21:21:50.278656  4081 net.cpp:380] Eltwise1_penlu3_0_split -> Eltwise1_penlu3_0_split_0
I1006 21:21:50.278661  4081 net.cpp:380] Eltwise1_penlu3_0_split -> Eltwise1_penlu3_0_split_1
I1006 21:21:50.278682  4081 net.cpp:122] Setting up Eltwise1_penlu3_0_split
I1006 21:21:50.278687  4081 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 21:21:50.278692  4081 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 21:21:50.278693  4081 net.cpp:137] Memory required for data: 86240400
I1006 21:21:50.278695  4081 layer_factory.hpp:77] Creating layer Convolution4
I1006 21:21:50.278703  4081 net.cpp:84] Creating Layer Convolution4
I1006 21:21:50.278707  4081 net.cpp:406] Convolution4 <- Eltwise1_penlu3_0_split_0
I1006 21:21:50.278710  4081 net.cpp:380] Convolution4 -> Convolution4
I1006 21:21:50.284863  4081 net.cpp:122] Setting up Convolution4
I1006 21:21:50.284888  4081 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 21:21:50.284893  4081 net.cpp:137] Memory required for data: 91258000
I1006 21:21:50.284899  4081 layer_factory.hpp:77] Creating layer BatchNorm4
I1006 21:21:50.284909  4081 net.cpp:84] Creating Layer BatchNorm4
I1006 21:21:50.284934  4081 net.cpp:406] BatchNorm4 <- Convolution4
I1006 21:21:50.284952  4081 net.cpp:367] BatchNorm4 -> Convolution4 (in-place)
I1006 21:21:50.285091  4081 net.cpp:122] Setting up BatchNorm4
I1006 21:21:50.285099  4081 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 21:21:50.285110  4081 net.cpp:137] Memory required for data: 96275600
I1006 21:21:50.285121  4081 layer_factory.hpp:77] Creating layer Scale4
I1006 21:21:50.285130  4081 net.cpp:84] Creating Layer Scale4
I1006 21:21:50.285135  4081 net.cpp:406] Scale4 <- Convolution4
I1006 21:21:50.285141  4081 net.cpp:367] Scale4 -> Convolution4 (in-place)
I1006 21:21:50.285177  4081 layer_factory.hpp:77] Creating layer Scale4
I1006 21:21:50.285264  4081 net.cpp:122] Setting up Scale4
I1006 21:21:50.285270  4081 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 21:21:50.285274  4081 net.cpp:137] Memory required for data: 101293200
I1006 21:21:50.285282  4081 layer_factory.hpp:77] Creating layer penlu4
I1006 21:21:50.285292  4081 net.cpp:84] Creating Layer penlu4
I1006 21:21:50.285298  4081 net.cpp:406] penlu4 <- Convolution4
I1006 21:21:50.285306  4081 net.cpp:367] penlu4 -> Convolution4 (in-place)
I1006 21:21:50.285415  4081 net.cpp:122] Setting up penlu4
I1006 21:21:50.285423  4081 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 21:21:50.285426  4081 net.cpp:137] Memory required for data: 106310800
I1006 21:21:50.285435  4081 layer_factory.hpp:77] Creating layer Convolution5
I1006 21:21:50.285447  4081 net.cpp:84] Creating Layer Convolution5
I1006 21:21:50.285454  4081 net.cpp:406] Convolution5 <- Convolution4
I1006 21:21:50.285461  4081 net.cpp:380] Convolution5 -> Convolution5
I1006 21:21:50.291488  4081 net.cpp:122] Setting up Convolution5
I1006 21:21:50.291498  4081 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 21:21:50.291503  4081 net.cpp:137] Memory required for data: 111328400
I1006 21:21:50.291512  4081 layer_factory.hpp:77] Creating layer BatchNorm5
I1006 21:21:50.291522  4081 net.cpp:84] Creating Layer BatchNorm5
I1006 21:21:50.291528  4081 net.cpp:406] BatchNorm5 <- Convolution5
I1006 21:21:50.291537  4081 net.cpp:367] BatchNorm5 -> Convolution5 (in-place)
I1006 21:21:50.291671  4081 net.cpp:122] Setting up BatchNorm5
I1006 21:21:50.291677  4081 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 21:21:50.291682  4081 net.cpp:137] Memory required for data: 116346000
I1006 21:21:50.291692  4081 layer_factory.hpp:77] Creating layer Scale5
I1006 21:21:50.291702  4081 net.cpp:84] Creating Layer Scale5
I1006 21:21:50.291707  4081 net.cpp:406] Scale5 <- Convolution5
I1006 21:21:50.291713  4081 net.cpp:367] Scale5 -> Convolution5 (in-place)
I1006 21:21:50.291749  4081 layer_factory.hpp:77] Creating layer Scale5
I1006 21:21:50.291834  4081 net.cpp:122] Setting up Scale5
I1006 21:21:50.291841  4081 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 21:21:50.291846  4081 net.cpp:137] Memory required for data: 121363600
I1006 21:21:50.291852  4081 layer_factory.hpp:77] Creating layer Eltwise2
I1006 21:21:50.291862  4081 net.cpp:84] Creating Layer Eltwise2
I1006 21:21:50.291867  4081 net.cpp:406] Eltwise2 <- Eltwise1_penlu3_0_split_1
I1006 21:21:50.291873  4081 net.cpp:406] Eltwise2 <- Convolution5
I1006 21:21:50.291882  4081 net.cpp:380] Eltwise2 -> Eltwise2
I1006 21:21:50.291904  4081 net.cpp:122] Setting up Eltwise2
I1006 21:21:50.291909  4081 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 21:21:50.291913  4081 net.cpp:137] Memory required for data: 126381200
I1006 21:21:50.291918  4081 layer_factory.hpp:77] Creating layer penlu5
I1006 21:21:50.291929  4081 net.cpp:84] Creating Layer penlu5
I1006 21:21:50.291935  4081 net.cpp:406] penlu5 <- Eltwise2
I1006 21:21:50.291942  4081 net.cpp:367] penlu5 -> Eltwise2 (in-place)
I1006 21:21:50.292049  4081 net.cpp:122] Setting up penlu5
I1006 21:21:50.292054  4081 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 21:21:50.292057  4081 net.cpp:137] Memory required for data: 131398800
I1006 21:21:50.292062  4081 layer_factory.hpp:77] Creating layer Eltwise2_penlu5_0_split
I1006 21:21:50.292073  4081 net.cpp:84] Creating Layer Eltwise2_penlu5_0_split
I1006 21:21:50.292076  4081 net.cpp:406] Eltwise2_penlu5_0_split <- Eltwise2
I1006 21:21:50.292080  4081 net.cpp:380] Eltwise2_penlu5_0_split -> Eltwise2_penlu5_0_split_0
I1006 21:21:50.292084  4081 net.cpp:380] Eltwise2_penlu5_0_split -> Eltwise2_penlu5_0_split_1
I1006 21:21:50.292109  4081 net.cpp:122] Setting up Eltwise2_penlu5_0_split
I1006 21:21:50.292114  4081 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 21:21:50.292116  4081 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 21:21:50.292119  4081 net.cpp:137] Memory required for data: 141434000
I1006 21:21:50.292121  4081 layer_factory.hpp:77] Creating layer Convolution6
I1006 21:21:50.292129  4081 net.cpp:84] Creating Layer Convolution6
I1006 21:21:50.292131  4081 net.cpp:406] Convolution6 <- Eltwise2_penlu5_0_split_0
I1006 21:21:50.292135  4081 net.cpp:380] Convolution6 -> Convolution6
I1006 21:21:50.298105  4081 net.cpp:122] Setting up Convolution6
I1006 21:21:50.298116  4081 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 21:21:50.298120  4081 net.cpp:137] Memory required for data: 146451600
I1006 21:21:50.298125  4081 layer_factory.hpp:77] Creating layer BatchNorm6
I1006 21:21:50.298131  4081 net.cpp:84] Creating Layer BatchNorm6
I1006 21:21:50.298135  4081 net.cpp:406] BatchNorm6 <- Convolution6
I1006 21:21:50.298140  4081 net.cpp:367] BatchNorm6 -> Convolution6 (in-place)
I1006 21:21:50.298271  4081 net.cpp:122] Setting up BatchNorm6
I1006 21:21:50.298277  4081 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 21:21:50.298280  4081 net.cpp:137] Memory required for data: 151469200
I1006 21:21:50.298285  4081 layer_factory.hpp:77] Creating layer Scale6
I1006 21:21:50.298292  4081 net.cpp:84] Creating Layer Scale6
I1006 21:21:50.298295  4081 net.cpp:406] Scale6 <- Convolution6
I1006 21:21:50.298300  4081 net.cpp:367] Scale6 -> Convolution6 (in-place)
I1006 21:21:50.298327  4081 layer_factory.hpp:77] Creating layer Scale6
I1006 21:21:50.298440  4081 net.cpp:122] Setting up Scale6
I1006 21:21:50.298449  4081 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 21:21:50.298452  4081 net.cpp:137] Memory required for data: 156486800
I1006 21:21:50.298460  4081 layer_factory.hpp:77] Creating layer penlu6
I1006 21:21:50.298482  4081 net.cpp:84] Creating Layer penlu6
I1006 21:21:50.298488  4081 net.cpp:406] penlu6 <- Convolution6
I1006 21:21:50.298506  4081 net.cpp:367] penlu6 -> Convolution6 (in-place)
I1006 21:21:50.298641  4081 net.cpp:122] Setting up penlu6
I1006 21:21:50.298648  4081 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 21:21:50.298651  4081 net.cpp:137] Memory required for data: 161504400
I1006 21:21:50.298667  4081 layer_factory.hpp:77] Creating layer Convolution7
I1006 21:21:50.298689  4081 net.cpp:84] Creating Layer Convolution7
I1006 21:21:50.298696  4081 net.cpp:406] Convolution7 <- Convolution6
I1006 21:21:50.298703  4081 net.cpp:380] Convolution7 -> Convolution7
I1006 21:21:50.305356  4081 net.cpp:122] Setting up Convolution7
I1006 21:21:50.305366  4081 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 21:21:50.305371  4081 net.cpp:137] Memory required for data: 166522000
I1006 21:21:50.305379  4081 layer_factory.hpp:77] Creating layer BatchNorm7
I1006 21:21:50.305389  4081 net.cpp:84] Creating Layer BatchNorm7
I1006 21:21:50.305395  4081 net.cpp:406] BatchNorm7 <- Convolution7
I1006 21:21:50.305403  4081 net.cpp:367] BatchNorm7 -> Convolution7 (in-place)
I1006 21:21:50.305541  4081 net.cpp:122] Setting up BatchNorm7
I1006 21:21:50.305548  4081 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 21:21:50.305552  4081 net.cpp:137] Memory required for data: 171539600
I1006 21:21:50.305570  4081 layer_factory.hpp:77] Creating layer Scale7
I1006 21:21:50.305583  4081 net.cpp:84] Creating Layer Scale7
I1006 21:21:50.305589  4081 net.cpp:406] Scale7 <- Convolution7
I1006 21:21:50.305596  4081 net.cpp:367] Scale7 -> Convolution7 (in-place)
I1006 21:21:50.305635  4081 layer_factory.hpp:77] Creating layer Scale7
I1006 21:21:50.305723  4081 net.cpp:122] Setting up Scale7
I1006 21:21:50.305738  4081 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 21:21:50.305742  4081 net.cpp:137] Memory required for data: 176557200
I1006 21:21:50.305750  4081 layer_factory.hpp:77] Creating layer Eltwise3
I1006 21:21:50.305768  4081 net.cpp:84] Creating Layer Eltwise3
I1006 21:21:50.305774  4081 net.cpp:406] Eltwise3 <- Eltwise2_penlu5_0_split_1
I1006 21:21:50.305780  4081 net.cpp:406] Eltwise3 <- Convolution7
I1006 21:21:50.305786  4081 net.cpp:380] Eltwise3 -> Eltwise3
I1006 21:21:50.305822  4081 net.cpp:122] Setting up Eltwise3
I1006 21:21:50.305829  4081 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 21:21:50.305831  4081 net.cpp:137] Memory required for data: 181574800
I1006 21:21:50.305845  4081 layer_factory.hpp:77] Creating layer penlu7
I1006 21:21:50.305852  4081 net.cpp:84] Creating Layer penlu7
I1006 21:21:50.305867  4081 net.cpp:406] penlu7 <- Eltwise3
I1006 21:21:50.305876  4081 net.cpp:367] penlu7 -> Eltwise3 (in-place)
I1006 21:21:50.305994  4081 net.cpp:122] Setting up penlu7
I1006 21:21:50.306000  4081 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 21:21:50.306004  4081 net.cpp:137] Memory required for data: 186592400
I1006 21:21:50.306008  4081 layer_factory.hpp:77] Creating layer Eltwise3_penlu7_0_split
I1006 21:21:50.306013  4081 net.cpp:84] Creating Layer Eltwise3_penlu7_0_split
I1006 21:21:50.306016  4081 net.cpp:406] Eltwise3_penlu7_0_split <- Eltwise3
I1006 21:21:50.306020  4081 net.cpp:380] Eltwise3_penlu7_0_split -> Eltwise3_penlu7_0_split_0
I1006 21:21:50.306025  4081 net.cpp:380] Eltwise3_penlu7_0_split -> Eltwise3_penlu7_0_split_1
I1006 21:21:50.306048  4081 net.cpp:122] Setting up Eltwise3_penlu7_0_split
I1006 21:21:50.306053  4081 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 21:21:50.306056  4081 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 21:21:50.306059  4081 net.cpp:137] Memory required for data: 196627600
I1006 21:21:50.306061  4081 layer_factory.hpp:77] Creating layer Convolution8
I1006 21:21:50.306067  4081 net.cpp:84] Creating Layer Convolution8
I1006 21:21:50.306071  4081 net.cpp:406] Convolution8 <- Eltwise3_penlu7_0_split_0
I1006 21:21:50.306076  4081 net.cpp:380] Convolution8 -> Convolution8
I1006 21:21:50.311885  4081 net.cpp:122] Setting up Convolution8
I1006 21:21:50.311897  4081 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 21:21:50.311900  4081 net.cpp:137] Memory required for data: 201645200
I1006 21:21:50.311904  4081 layer_factory.hpp:77] Creating layer BatchNorm8
I1006 21:21:50.311910  4081 net.cpp:84] Creating Layer BatchNorm8
I1006 21:21:50.311914  4081 net.cpp:406] BatchNorm8 <- Convolution8
I1006 21:21:50.311919  4081 net.cpp:367] BatchNorm8 -> Convolution8 (in-place)
I1006 21:21:50.312045  4081 net.cpp:122] Setting up BatchNorm8
I1006 21:21:50.312050  4081 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 21:21:50.312053  4081 net.cpp:137] Memory required for data: 206662800
I1006 21:21:50.312058  4081 layer_factory.hpp:77] Creating layer Scale8
I1006 21:21:50.312063  4081 net.cpp:84] Creating Layer Scale8
I1006 21:21:50.312067  4081 net.cpp:406] Scale8 <- Convolution8
I1006 21:21:50.312070  4081 net.cpp:367] Scale8 -> Convolution8 (in-place)
I1006 21:21:50.312096  4081 layer_factory.hpp:77] Creating layer Scale8
I1006 21:21:50.312171  4081 net.cpp:122] Setting up Scale8
I1006 21:21:50.312176  4081 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 21:21:50.312180  4081 net.cpp:137] Memory required for data: 211680400
I1006 21:21:50.312183  4081 layer_factory.hpp:77] Creating layer penlu8
I1006 21:21:50.312189  4081 net.cpp:84] Creating Layer penlu8
I1006 21:21:50.312192  4081 net.cpp:406] penlu8 <- Convolution8
I1006 21:21:50.312196  4081 net.cpp:367] penlu8 -> Convolution8 (in-place)
I1006 21:21:50.312300  4081 net.cpp:122] Setting up penlu8
I1006 21:21:50.312306  4081 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 21:21:50.312309  4081 net.cpp:137] Memory required for data: 216698000
I1006 21:21:50.312312  4081 layer_factory.hpp:77] Creating layer Convolution9
I1006 21:21:50.312337  4081 net.cpp:84] Creating Layer Convolution9
I1006 21:21:50.312341  4081 net.cpp:406] Convolution9 <- Convolution8
I1006 21:21:50.312346  4081 net.cpp:380] Convolution9 -> Convolution9
I1006 21:21:50.318542  4081 net.cpp:122] Setting up Convolution9
I1006 21:21:50.318552  4081 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 21:21:50.318555  4081 net.cpp:137] Memory required for data: 221715600
I1006 21:21:50.318560  4081 layer_factory.hpp:77] Creating layer BatchNorm9
I1006 21:21:50.318565  4081 net.cpp:84] Creating Layer BatchNorm9
I1006 21:21:50.318569  4081 net.cpp:406] BatchNorm9 <- Convolution9
I1006 21:21:50.318573  4081 net.cpp:367] BatchNorm9 -> Convolution9 (in-place)
I1006 21:21:50.318701  4081 net.cpp:122] Setting up BatchNorm9
I1006 21:21:50.318706  4081 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 21:21:50.318709  4081 net.cpp:137] Memory required for data: 226733200
I1006 21:21:50.318714  4081 layer_factory.hpp:77] Creating layer Scale9
I1006 21:21:50.318719  4081 net.cpp:84] Creating Layer Scale9
I1006 21:21:50.318722  4081 net.cpp:406] Scale9 <- Convolution9
I1006 21:21:50.318725  4081 net.cpp:367] Scale9 -> Convolution9 (in-place)
I1006 21:21:50.318752  4081 layer_factory.hpp:77] Creating layer Scale9
I1006 21:21:50.318830  4081 net.cpp:122] Setting up Scale9
I1006 21:21:50.318835  4081 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 21:21:50.318840  4081 net.cpp:137] Memory required for data: 231750800
I1006 21:21:50.318843  4081 layer_factory.hpp:77] Creating layer Eltwise4
I1006 21:21:50.318848  4081 net.cpp:84] Creating Layer Eltwise4
I1006 21:21:50.318851  4081 net.cpp:406] Eltwise4 <- Eltwise3_penlu7_0_split_1
I1006 21:21:50.318855  4081 net.cpp:406] Eltwise4 <- Convolution9
I1006 21:21:50.318857  4081 net.cpp:380] Eltwise4 -> Eltwise4
I1006 21:21:50.318873  4081 net.cpp:122] Setting up Eltwise4
I1006 21:21:50.318877  4081 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 21:21:50.318879  4081 net.cpp:137] Memory required for data: 236768400
I1006 21:21:50.318882  4081 layer_factory.hpp:77] Creating layer penlu9
I1006 21:21:50.318886  4081 net.cpp:84] Creating Layer penlu9
I1006 21:21:50.318891  4081 net.cpp:406] penlu9 <- Eltwise4
I1006 21:21:50.318893  4081 net.cpp:367] penlu9 -> Eltwise4 (in-place)
I1006 21:21:50.319000  4081 net.cpp:122] Setting up penlu9
I1006 21:21:50.319005  4081 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 21:21:50.319007  4081 net.cpp:137] Memory required for data: 241786000
I1006 21:21:50.319012  4081 layer_factory.hpp:77] Creating layer Eltwise4_penlu9_0_split
I1006 21:21:50.319016  4081 net.cpp:84] Creating Layer Eltwise4_penlu9_0_split
I1006 21:21:50.319020  4081 net.cpp:406] Eltwise4_penlu9_0_split <- Eltwise4
I1006 21:21:50.319023  4081 net.cpp:380] Eltwise4_penlu9_0_split -> Eltwise4_penlu9_0_split_0
I1006 21:21:50.319028  4081 net.cpp:380] Eltwise4_penlu9_0_split -> Eltwise4_penlu9_0_split_1
I1006 21:21:50.319049  4081 net.cpp:122] Setting up Eltwise4_penlu9_0_split
I1006 21:21:50.319053  4081 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 21:21:50.319056  4081 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 21:21:50.319059  4081 net.cpp:137] Memory required for data: 251821200
I1006 21:21:50.319062  4081 layer_factory.hpp:77] Creating layer Convolution10
I1006 21:21:50.319068  4081 net.cpp:84] Creating Layer Convolution10
I1006 21:21:50.319072  4081 net.cpp:406] Convolution10 <- Eltwise4_penlu9_0_split_0
I1006 21:21:50.319075  4081 net.cpp:380] Convolution10 -> Convolution10
I1006 21:21:50.325122  4081 net.cpp:122] Setting up Convolution10
I1006 21:21:50.325132  4081 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 21:21:50.325136  4081 net.cpp:137] Memory required for data: 256838800
I1006 21:21:50.325141  4081 layer_factory.hpp:77] Creating layer BatchNorm10
I1006 21:21:50.325147  4081 net.cpp:84] Creating Layer BatchNorm10
I1006 21:21:50.325150  4081 net.cpp:406] BatchNorm10 <- Convolution10
I1006 21:21:50.325155  4081 net.cpp:367] BatchNorm10 -> Convolution10 (in-place)
I1006 21:21:50.325283  4081 net.cpp:122] Setting up BatchNorm10
I1006 21:21:50.325294  4081 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 21:21:50.325297  4081 net.cpp:137] Memory required for data: 261856400
I1006 21:21:50.325302  4081 layer_factory.hpp:77] Creating layer Scale10
I1006 21:21:50.325307  4081 net.cpp:84] Creating Layer Scale10
I1006 21:21:50.325310  4081 net.cpp:406] Scale10 <- Convolution10
I1006 21:21:50.325314  4081 net.cpp:367] Scale10 -> Convolution10 (in-place)
I1006 21:21:50.325342  4081 layer_factory.hpp:77] Creating layer Scale10
I1006 21:21:50.325417  4081 net.cpp:122] Setting up Scale10
I1006 21:21:50.325423  4081 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 21:21:50.325426  4081 net.cpp:137] Memory required for data: 266874000
I1006 21:21:50.325430  4081 layer_factory.hpp:77] Creating layer penlu10
I1006 21:21:50.325436  4081 net.cpp:84] Creating Layer penlu10
I1006 21:21:50.325439  4081 net.cpp:406] penlu10 <- Convolution10
I1006 21:21:50.325444  4081 net.cpp:367] penlu10 -> Convolution10 (in-place)
I1006 21:21:50.325552  4081 net.cpp:122] Setting up penlu10
I1006 21:21:50.325557  4081 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 21:21:50.325561  4081 net.cpp:137] Memory required for data: 271891600
I1006 21:21:50.325565  4081 layer_factory.hpp:77] Creating layer Convolution11
I1006 21:21:50.325573  4081 net.cpp:84] Creating Layer Convolution11
I1006 21:21:50.325577  4081 net.cpp:406] Convolution11 <- Convolution10
I1006 21:21:50.325580  4081 net.cpp:380] Convolution11 -> Convolution11
I1006 21:21:50.331735  4081 net.cpp:122] Setting up Convolution11
I1006 21:21:50.331746  4081 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 21:21:50.331759  4081 net.cpp:137] Memory required for data: 276909200
I1006 21:21:50.331764  4081 layer_factory.hpp:77] Creating layer BatchNorm11
I1006 21:21:50.331770  4081 net.cpp:84] Creating Layer BatchNorm11
I1006 21:21:50.331773  4081 net.cpp:406] BatchNorm11 <- Convolution11
I1006 21:21:50.331778  4081 net.cpp:367] BatchNorm11 -> Convolution11 (in-place)
I1006 21:21:50.331912  4081 net.cpp:122] Setting up BatchNorm11
I1006 21:21:50.331918  4081 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 21:21:50.331919  4081 net.cpp:137] Memory required for data: 281926800
I1006 21:21:50.331924  4081 layer_factory.hpp:77] Creating layer Scale11
I1006 21:21:50.331930  4081 net.cpp:84] Creating Layer Scale11
I1006 21:21:50.331933  4081 net.cpp:406] Scale11 <- Convolution11
I1006 21:21:50.331938  4081 net.cpp:367] Scale11 -> Convolution11 (in-place)
I1006 21:21:50.331969  4081 layer_factory.hpp:77] Creating layer Scale11
I1006 21:21:50.332078  4081 net.cpp:122] Setting up Scale11
I1006 21:21:50.332089  4081 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 21:21:50.332095  4081 net.cpp:137] Memory required for data: 286944400
I1006 21:21:50.332104  4081 layer_factory.hpp:77] Creating layer Eltwise5
I1006 21:21:50.332109  4081 net.cpp:84] Creating Layer Eltwise5
I1006 21:21:50.332113  4081 net.cpp:406] Eltwise5 <- Eltwise4_penlu9_0_split_1
I1006 21:21:50.332116  4081 net.cpp:406] Eltwise5 <- Convolution11
I1006 21:21:50.332121  4081 net.cpp:380] Eltwise5 -> Eltwise5
I1006 21:21:50.332140  4081 net.cpp:122] Setting up Eltwise5
I1006 21:21:50.332144  4081 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 21:21:50.332147  4081 net.cpp:137] Memory required for data: 291962000
I1006 21:21:50.332150  4081 layer_factory.hpp:77] Creating layer penlu11
I1006 21:21:50.332155  4081 net.cpp:84] Creating Layer penlu11
I1006 21:21:50.332159  4081 net.cpp:406] penlu11 <- Eltwise5
I1006 21:21:50.332162  4081 net.cpp:367] penlu11 -> Eltwise5 (in-place)
I1006 21:21:50.332273  4081 net.cpp:122] Setting up penlu11
I1006 21:21:50.332279  4081 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 21:21:50.332283  4081 net.cpp:137] Memory required for data: 296979600
I1006 21:21:50.332286  4081 layer_factory.hpp:77] Creating layer Eltwise5_penlu11_0_split
I1006 21:21:50.332291  4081 net.cpp:84] Creating Layer Eltwise5_penlu11_0_split
I1006 21:21:50.332294  4081 net.cpp:406] Eltwise5_penlu11_0_split <- Eltwise5
I1006 21:21:50.332306  4081 net.cpp:380] Eltwise5_penlu11_0_split -> Eltwise5_penlu11_0_split_0
I1006 21:21:50.332311  4081 net.cpp:380] Eltwise5_penlu11_0_split -> Eltwise5_penlu11_0_split_1
I1006 21:21:50.332334  4081 net.cpp:122] Setting up Eltwise5_penlu11_0_split
I1006 21:21:50.332340  4081 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 21:21:50.332343  4081 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1006 21:21:50.332345  4081 net.cpp:137] Memory required for data: 307014800
I1006 21:21:50.332348  4081 layer_factory.hpp:77] Creating layer Convolution12
I1006 21:21:50.332355  4081 net.cpp:84] Creating Layer Convolution12
I1006 21:21:50.332358  4081 net.cpp:406] Convolution12 <- Eltwise5_penlu11_0_split_0
I1006 21:21:50.332362  4081 net.cpp:380] Convolution12 -> Convolution12
I1006 21:21:50.337785  4081 net.cpp:122] Setting up Convolution12
I1006 21:21:50.337795  4081 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 21:21:50.337800  4081 net.cpp:137] Memory required for data: 309523600
I1006 21:21:50.337805  4081 layer_factory.hpp:77] Creating layer BatchNorm12
I1006 21:21:50.337810  4081 net.cpp:84] Creating Layer BatchNorm12
I1006 21:21:50.337813  4081 net.cpp:406] BatchNorm12 <- Convolution12
I1006 21:21:50.337818  4081 net.cpp:367] BatchNorm12 -> Convolution12 (in-place)
I1006 21:21:50.337960  4081 net.cpp:122] Setting up BatchNorm12
I1006 21:21:50.337965  4081 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 21:21:50.337968  4081 net.cpp:137] Memory required for data: 312032400
I1006 21:21:50.337973  4081 layer_factory.hpp:77] Creating layer Scale12
I1006 21:21:50.337978  4081 net.cpp:84] Creating Layer Scale12
I1006 21:21:50.337981  4081 net.cpp:406] Scale12 <- Convolution12
I1006 21:21:50.337985  4081 net.cpp:367] Scale12 -> Convolution12 (in-place)
I1006 21:21:50.338011  4081 layer_factory.hpp:77] Creating layer Scale12
I1006 21:21:50.338086  4081 net.cpp:122] Setting up Scale12
I1006 21:21:50.338093  4081 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 21:21:50.338095  4081 net.cpp:137] Memory required for data: 314541200
I1006 21:21:50.338099  4081 layer_factory.hpp:77] Creating layer Convolution13
I1006 21:21:50.338106  4081 net.cpp:84] Creating Layer Convolution13
I1006 21:21:50.338110  4081 net.cpp:406] Convolution13 <- Eltwise5_penlu11_0_split_1
I1006 21:21:50.338115  4081 net.cpp:380] Convolution13 -> Convolution13
I1006 21:21:50.341476  4081 net.cpp:122] Setting up Convolution13
I1006 21:21:50.341488  4081 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 21:21:50.341492  4081 net.cpp:137] Memory required for data: 317050000
I1006 21:21:50.341497  4081 layer_factory.hpp:77] Creating layer BatchNorm13
I1006 21:21:50.341503  4081 net.cpp:84] Creating Layer BatchNorm13
I1006 21:21:50.341506  4081 net.cpp:406] BatchNorm13 <- Convolution13
I1006 21:21:50.341511  4081 net.cpp:367] BatchNorm13 -> Convolution13 (in-place)
I1006 21:21:50.341646  4081 net.cpp:122] Setting up BatchNorm13
I1006 21:21:50.341652  4081 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 21:21:50.341655  4081 net.cpp:137] Memory required for data: 319558800
I1006 21:21:50.341660  4081 layer_factory.hpp:77] Creating layer Scale13
I1006 21:21:50.341665  4081 net.cpp:84] Creating Layer Scale13
I1006 21:21:50.341667  4081 net.cpp:406] Scale13 <- Convolution13
I1006 21:21:50.341671  4081 net.cpp:367] Scale13 -> Convolution13 (in-place)
I1006 21:21:50.341698  4081 layer_factory.hpp:77] Creating layer Scale13
I1006 21:21:50.341774  4081 net.cpp:122] Setting up Scale13
I1006 21:21:50.341779  4081 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 21:21:50.341784  4081 net.cpp:137] Memory required for data: 322067600
I1006 21:21:50.341787  4081 layer_factory.hpp:77] Creating layer penlu12
I1006 21:21:50.341794  4081 net.cpp:84] Creating Layer penlu12
I1006 21:21:50.341796  4081 net.cpp:406] penlu12 <- Convolution13
I1006 21:21:50.341800  4081 net.cpp:367] penlu12 -> Convolution13 (in-place)
I1006 21:21:50.341907  4081 net.cpp:122] Setting up penlu12
I1006 21:21:50.341912  4081 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 21:21:50.341922  4081 net.cpp:137] Memory required for data: 324576400
I1006 21:21:50.341928  4081 layer_factory.hpp:77] Creating layer Convolution14
I1006 21:21:50.341935  4081 net.cpp:84] Creating Layer Convolution14
I1006 21:21:50.341938  4081 net.cpp:406] Convolution14 <- Convolution13
I1006 21:21:50.341943  4081 net.cpp:380] Convolution14 -> Convolution14
I1006 21:21:50.347740  4081 net.cpp:122] Setting up Convolution14
I1006 21:21:50.347753  4081 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 21:21:50.347755  4081 net.cpp:137] Memory required for data: 327085200
I1006 21:21:50.347774  4081 layer_factory.hpp:77] Creating layer BatchNorm14
I1006 21:21:50.347784  4081 net.cpp:84] Creating Layer BatchNorm14
I1006 21:21:50.347787  4081 net.cpp:406] BatchNorm14 <- Convolution14
I1006 21:21:50.347791  4081 net.cpp:367] BatchNorm14 -> Convolution14 (in-place)
I1006 21:21:50.347921  4081 net.cpp:122] Setting up BatchNorm14
I1006 21:21:50.347928  4081 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 21:21:50.347929  4081 net.cpp:137] Memory required for data: 329594000
I1006 21:21:50.347935  4081 layer_factory.hpp:77] Creating layer Scale14
I1006 21:21:50.347940  4081 net.cpp:84] Creating Layer Scale14
I1006 21:21:50.347944  4081 net.cpp:406] Scale14 <- Convolution14
I1006 21:21:50.347947  4081 net.cpp:367] Scale14 -> Convolution14 (in-place)
I1006 21:21:50.347973  4081 layer_factory.hpp:77] Creating layer Scale14
I1006 21:21:50.348048  4081 net.cpp:122] Setting up Scale14
I1006 21:21:50.348054  4081 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 21:21:50.348057  4081 net.cpp:137] Memory required for data: 332102800
I1006 21:21:50.348062  4081 layer_factory.hpp:77] Creating layer Eltwise6
I1006 21:21:50.348065  4081 net.cpp:84] Creating Layer Eltwise6
I1006 21:21:50.348069  4081 net.cpp:406] Eltwise6 <- Convolution12
I1006 21:21:50.348071  4081 net.cpp:406] Eltwise6 <- Convolution14
I1006 21:21:50.348076  4081 net.cpp:380] Eltwise6 -> Eltwise6
I1006 21:21:50.348093  4081 net.cpp:122] Setting up Eltwise6
I1006 21:21:50.348098  4081 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 21:21:50.348100  4081 net.cpp:137] Memory required for data: 334611600
I1006 21:21:50.348103  4081 layer_factory.hpp:77] Creating layer penlu13
I1006 21:21:50.348107  4081 net.cpp:84] Creating Layer penlu13
I1006 21:21:50.348110  4081 net.cpp:406] penlu13 <- Eltwise6
I1006 21:21:50.348114  4081 net.cpp:367] penlu13 -> Eltwise6 (in-place)
I1006 21:21:50.348219  4081 net.cpp:122] Setting up penlu13
I1006 21:21:50.348225  4081 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 21:21:50.348228  4081 net.cpp:137] Memory required for data: 337120400
I1006 21:21:50.348232  4081 layer_factory.hpp:77] Creating layer Eltwise6_penlu13_0_split
I1006 21:21:50.348237  4081 net.cpp:84] Creating Layer Eltwise6_penlu13_0_split
I1006 21:21:50.348240  4081 net.cpp:406] Eltwise6_penlu13_0_split <- Eltwise6
I1006 21:21:50.348244  4081 net.cpp:380] Eltwise6_penlu13_0_split -> Eltwise6_penlu13_0_split_0
I1006 21:21:50.348249  4081 net.cpp:380] Eltwise6_penlu13_0_split -> Eltwise6_penlu13_0_split_1
I1006 21:21:50.348273  4081 net.cpp:122] Setting up Eltwise6_penlu13_0_split
I1006 21:21:50.348278  4081 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 21:21:50.348281  4081 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 21:21:50.348284  4081 net.cpp:137] Memory required for data: 342138000
I1006 21:21:50.348287  4081 layer_factory.hpp:77] Creating layer Convolution15
I1006 21:21:50.348294  4081 net.cpp:84] Creating Layer Convolution15
I1006 21:21:50.348296  4081 net.cpp:406] Convolution15 <- Eltwise6_penlu13_0_split_0
I1006 21:21:50.348300  4081 net.cpp:380] Convolution15 -> Convolution15
I1006 21:21:50.354385  4081 net.cpp:122] Setting up Convolution15
I1006 21:21:50.354395  4081 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 21:21:50.354399  4081 net.cpp:137] Memory required for data: 344646800
I1006 21:21:50.354404  4081 layer_factory.hpp:77] Creating layer BatchNorm15
I1006 21:21:50.354409  4081 net.cpp:84] Creating Layer BatchNorm15
I1006 21:21:50.354419  4081 net.cpp:406] BatchNorm15 <- Convolution15
I1006 21:21:50.354425  4081 net.cpp:367] BatchNorm15 -> Convolution15 (in-place)
I1006 21:21:50.354558  4081 net.cpp:122] Setting up BatchNorm15
I1006 21:21:50.354564  4081 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 21:21:50.354568  4081 net.cpp:137] Memory required for data: 347155600
I1006 21:21:50.354573  4081 layer_factory.hpp:77] Creating layer Scale15
I1006 21:21:50.354578  4081 net.cpp:84] Creating Layer Scale15
I1006 21:21:50.354581  4081 net.cpp:406] Scale15 <- Convolution15
I1006 21:21:50.354585  4081 net.cpp:367] Scale15 -> Convolution15 (in-place)
I1006 21:21:50.354611  4081 layer_factory.hpp:77] Creating layer Scale15
I1006 21:21:50.354686  4081 net.cpp:122] Setting up Scale15
I1006 21:21:50.354691  4081 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 21:21:50.354694  4081 net.cpp:137] Memory required for data: 349664400
I1006 21:21:50.354698  4081 layer_factory.hpp:77] Creating layer penlu14
I1006 21:21:50.354704  4081 net.cpp:84] Creating Layer penlu14
I1006 21:21:50.354708  4081 net.cpp:406] penlu14 <- Convolution15
I1006 21:21:50.354712  4081 net.cpp:367] penlu14 -> Convolution15 (in-place)
I1006 21:21:50.354815  4081 net.cpp:122] Setting up penlu14
I1006 21:21:50.354821  4081 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 21:21:50.354825  4081 net.cpp:137] Memory required for data: 352173200
I1006 21:21:50.354830  4081 layer_factory.hpp:77] Creating layer Convolution16
I1006 21:21:50.354835  4081 net.cpp:84] Creating Layer Convolution16
I1006 21:21:50.354840  4081 net.cpp:406] Convolution16 <- Convolution15
I1006 21:21:50.354843  4081 net.cpp:380] Convolution16 -> Convolution16
I1006 21:21:50.359344  4081 net.cpp:122] Setting up Convolution16
I1006 21:21:50.359359  4081 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 21:21:50.359365  4081 net.cpp:137] Memory required for data: 354682000
I1006 21:21:50.359374  4081 layer_factory.hpp:77] Creating layer BatchNorm16
I1006 21:21:50.359381  4081 net.cpp:84] Creating Layer BatchNorm16
I1006 21:21:50.359387  4081 net.cpp:406] BatchNorm16 <- Convolution16
I1006 21:21:50.359395  4081 net.cpp:367] BatchNorm16 -> Convolution16 (in-place)
I1006 21:21:50.359583  4081 net.cpp:122] Setting up BatchNorm16
I1006 21:21:50.359592  4081 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 21:21:50.359597  4081 net.cpp:137] Memory required for data: 357190800
I1006 21:21:50.359607  4081 layer_factory.hpp:77] Creating layer Scale16
I1006 21:21:50.359614  4081 net.cpp:84] Creating Layer Scale16
I1006 21:21:50.359619  4081 net.cpp:406] Scale16 <- Convolution16
I1006 21:21:50.359627  4081 net.cpp:367] Scale16 -> Convolution16 (in-place)
I1006 21:21:50.359664  4081 layer_factory.hpp:77] Creating layer Scale16
I1006 21:21:50.359771  4081 net.cpp:122] Setting up Scale16
I1006 21:21:50.359779  4081 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 21:21:50.359784  4081 net.cpp:137] Memory required for data: 359699600
I1006 21:21:50.359791  4081 layer_factory.hpp:77] Creating layer Eltwise7
I1006 21:21:50.359799  4081 net.cpp:84] Creating Layer Eltwise7
I1006 21:21:50.359804  4081 net.cpp:406] Eltwise7 <- Eltwise6_penlu13_0_split_1
I1006 21:21:50.359810  4081 net.cpp:406] Eltwise7 <- Convolution16
I1006 21:21:50.359818  4081 net.cpp:380] Eltwise7 -> Eltwise7
I1006 21:21:50.359840  4081 net.cpp:122] Setting up Eltwise7
I1006 21:21:50.359849  4081 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 21:21:50.359854  4081 net.cpp:137] Memory required for data: 362208400
I1006 21:21:50.359858  4081 layer_factory.hpp:77] Creating layer penlu15
I1006 21:21:50.359868  4081 net.cpp:84] Creating Layer penlu15
I1006 21:21:50.359872  4081 net.cpp:406] penlu15 <- Eltwise7
I1006 21:21:50.359880  4081 net.cpp:367] penlu15 -> Eltwise7 (in-place)
I1006 21:21:50.360034  4081 net.cpp:122] Setting up penlu15
I1006 21:21:50.360044  4081 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 21:21:50.360049  4081 net.cpp:137] Memory required for data: 364717200
I1006 21:21:50.360057  4081 layer_factory.hpp:77] Creating layer Eltwise7_penlu15_0_split
I1006 21:21:50.360072  4081 net.cpp:84] Creating Layer Eltwise7_penlu15_0_split
I1006 21:21:50.360077  4081 net.cpp:406] Eltwise7_penlu15_0_split <- Eltwise7
I1006 21:21:50.360085  4081 net.cpp:380] Eltwise7_penlu15_0_split -> Eltwise7_penlu15_0_split_0
I1006 21:21:50.360091  4081 net.cpp:380] Eltwise7_penlu15_0_split -> Eltwise7_penlu15_0_split_1
I1006 21:21:50.360128  4081 net.cpp:122] Setting up Eltwise7_penlu15_0_split
I1006 21:21:50.360137  4081 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 21:21:50.360144  4081 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 21:21:50.360148  4081 net.cpp:137] Memory required for data: 369734800
I1006 21:21:50.360154  4081 layer_factory.hpp:77] Creating layer Convolution17
I1006 21:21:50.360164  4081 net.cpp:84] Creating Layer Convolution17
I1006 21:21:50.360170  4081 net.cpp:406] Convolution17 <- Eltwise7_penlu15_0_split_0
I1006 21:21:50.360179  4081 net.cpp:380] Convolution17 -> Convolution17
I1006 21:21:50.364353  4081 net.cpp:122] Setting up Convolution17
I1006 21:21:50.364374  4081 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 21:21:50.364377  4081 net.cpp:137] Memory required for data: 372243600
I1006 21:21:50.364382  4081 layer_factory.hpp:77] Creating layer BatchNorm17
I1006 21:21:50.364388  4081 net.cpp:84] Creating Layer BatchNorm17
I1006 21:21:50.364392  4081 net.cpp:406] BatchNorm17 <- Convolution17
I1006 21:21:50.364397  4081 net.cpp:367] BatchNorm17 -> Convolution17 (in-place)
I1006 21:21:50.364545  4081 net.cpp:122] Setting up BatchNorm17
I1006 21:21:50.364552  4081 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 21:21:50.364564  4081 net.cpp:137] Memory required for data: 374752400
I1006 21:21:50.364569  4081 layer_factory.hpp:77] Creating layer Scale17
I1006 21:21:50.364575  4081 net.cpp:84] Creating Layer Scale17
I1006 21:21:50.364578  4081 net.cpp:406] Scale17 <- Convolution17
I1006 21:21:50.364583  4081 net.cpp:367] Scale17 -> Convolution17 (in-place)
I1006 21:21:50.364609  4081 layer_factory.hpp:77] Creating layer Scale17
I1006 21:21:50.364687  4081 net.cpp:122] Setting up Scale17
I1006 21:21:50.364692  4081 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 21:21:50.364694  4081 net.cpp:137] Memory required for data: 377261200
I1006 21:21:50.364699  4081 layer_factory.hpp:77] Creating layer penlu16
I1006 21:21:50.364706  4081 net.cpp:84] Creating Layer penlu16
I1006 21:21:50.364708  4081 net.cpp:406] penlu16 <- Convolution17
I1006 21:21:50.364712  4081 net.cpp:367] penlu16 -> Convolution17 (in-place)
I1006 21:21:50.364819  4081 net.cpp:122] Setting up penlu16
I1006 21:21:50.364825  4081 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 21:21:50.364827  4081 net.cpp:137] Memory required for data: 379770000
I1006 21:21:50.364831  4081 layer_factory.hpp:77] Creating layer Convolution18
I1006 21:21:50.364840  4081 net.cpp:84] Creating Layer Convolution18
I1006 21:21:50.364842  4081 net.cpp:406] Convolution18 <- Convolution17
I1006 21:21:50.364846  4081 net.cpp:380] Convolution18 -> Convolution18
I1006 21:21:50.371117  4081 net.cpp:122] Setting up Convolution18
I1006 21:21:50.371127  4081 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 21:21:50.371131  4081 net.cpp:137] Memory required for data: 382278800
I1006 21:21:50.371136  4081 layer_factory.hpp:77] Creating layer BatchNorm18
I1006 21:21:50.371142  4081 net.cpp:84] Creating Layer BatchNorm18
I1006 21:21:50.371145  4081 net.cpp:406] BatchNorm18 <- Convolution18
I1006 21:21:50.371150  4081 net.cpp:367] BatchNorm18 -> Convolution18 (in-place)
I1006 21:21:50.371285  4081 net.cpp:122] Setting up BatchNorm18
I1006 21:21:50.371291  4081 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 21:21:50.371294  4081 net.cpp:137] Memory required for data: 384787600
I1006 21:21:50.371299  4081 layer_factory.hpp:77] Creating layer Scale18
I1006 21:21:50.371304  4081 net.cpp:84] Creating Layer Scale18
I1006 21:21:50.371307  4081 net.cpp:406] Scale18 <- Convolution18
I1006 21:21:50.371311  4081 net.cpp:367] Scale18 -> Convolution18 (in-place)
I1006 21:21:50.371346  4081 layer_factory.hpp:77] Creating layer Scale18
I1006 21:21:50.371425  4081 net.cpp:122] Setting up Scale18
I1006 21:21:50.371430  4081 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 21:21:50.371433  4081 net.cpp:137] Memory required for data: 387296400
I1006 21:21:50.371438  4081 layer_factory.hpp:77] Creating layer Eltwise8
I1006 21:21:50.371443  4081 net.cpp:84] Creating Layer Eltwise8
I1006 21:21:50.371446  4081 net.cpp:406] Eltwise8 <- Eltwise7_penlu15_0_split_1
I1006 21:21:50.371449  4081 net.cpp:406] Eltwise8 <- Convolution18
I1006 21:21:50.371454  4081 net.cpp:380] Eltwise8 -> Eltwise8
I1006 21:21:50.371472  4081 net.cpp:122] Setting up Eltwise8
I1006 21:21:50.371477  4081 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 21:21:50.371480  4081 net.cpp:137] Memory required for data: 389805200
I1006 21:21:50.371484  4081 layer_factory.hpp:77] Creating layer penlu17
I1006 21:21:50.371489  4081 net.cpp:84] Creating Layer penlu17
I1006 21:21:50.371492  4081 net.cpp:406] penlu17 <- Eltwise8
I1006 21:21:50.371495  4081 net.cpp:367] penlu17 -> Eltwise8 (in-place)
I1006 21:21:50.371601  4081 net.cpp:122] Setting up penlu17
I1006 21:21:50.371606  4081 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 21:21:50.371609  4081 net.cpp:137] Memory required for data: 392314000
I1006 21:21:50.371614  4081 layer_factory.hpp:77] Creating layer Eltwise8_penlu17_0_split
I1006 21:21:50.371619  4081 net.cpp:84] Creating Layer Eltwise8_penlu17_0_split
I1006 21:21:50.371623  4081 net.cpp:406] Eltwise8_penlu17_0_split <- Eltwise8
I1006 21:21:50.371625  4081 net.cpp:380] Eltwise8_penlu17_0_split -> Eltwise8_penlu17_0_split_0
I1006 21:21:50.371630  4081 net.cpp:380] Eltwise8_penlu17_0_split -> Eltwise8_penlu17_0_split_1
I1006 21:21:50.371654  4081 net.cpp:122] Setting up Eltwise8_penlu17_0_split
I1006 21:21:50.371659  4081 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 21:21:50.371662  4081 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 21:21:50.371666  4081 net.cpp:137] Memory required for data: 397331600
I1006 21:21:50.371668  4081 layer_factory.hpp:77] Creating layer Convolution19
I1006 21:21:50.371675  4081 net.cpp:84] Creating Layer Convolution19
I1006 21:21:50.371678  4081 net.cpp:406] Convolution19 <- Eltwise8_penlu17_0_split_0
I1006 21:21:50.371682  4081 net.cpp:380] Convolution19 -> Convolution19
I1006 21:21:50.377951  4081 net.cpp:122] Setting up Convolution19
I1006 21:21:50.377961  4081 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 21:21:50.377965  4081 net.cpp:137] Memory required for data: 399840400
I1006 21:21:50.377971  4081 layer_factory.hpp:77] Creating layer BatchNorm19
I1006 21:21:50.377976  4081 net.cpp:84] Creating Layer BatchNorm19
I1006 21:21:50.377980  4081 net.cpp:406] BatchNorm19 <- Convolution19
I1006 21:21:50.377985  4081 net.cpp:367] BatchNorm19 -> Convolution19 (in-place)
I1006 21:21:50.378121  4081 net.cpp:122] Setting up BatchNorm19
I1006 21:21:50.378126  4081 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 21:21:50.378130  4081 net.cpp:137] Memory required for data: 402349200
I1006 21:21:50.378134  4081 layer_factory.hpp:77] Creating layer Scale19
I1006 21:21:50.378139  4081 net.cpp:84] Creating Layer Scale19
I1006 21:21:50.378144  4081 net.cpp:406] Scale19 <- Convolution19
I1006 21:21:50.378147  4081 net.cpp:367] Scale19 -> Convolution19 (in-place)
I1006 21:21:50.378175  4081 layer_factory.hpp:77] Creating layer Scale19
I1006 21:21:50.378252  4081 net.cpp:122] Setting up Scale19
I1006 21:21:50.378258  4081 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 21:21:50.378262  4081 net.cpp:137] Memory required for data: 404858000
I1006 21:21:50.378265  4081 layer_factory.hpp:77] Creating layer penlu18
I1006 21:21:50.378270  4081 net.cpp:84] Creating Layer penlu18
I1006 21:21:50.378274  4081 net.cpp:406] penlu18 <- Convolution19
I1006 21:21:50.378278  4081 net.cpp:367] penlu18 -> Convolution19 (in-place)
I1006 21:21:50.378386  4081 net.cpp:122] Setting up penlu18
I1006 21:21:50.378391  4081 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 21:21:50.378393  4081 net.cpp:137] Memory required for data: 407366800
I1006 21:21:50.378406  4081 layer_factory.hpp:77] Creating layer Convolution20
I1006 21:21:50.378413  4081 net.cpp:84] Creating Layer Convolution20
I1006 21:21:50.378417  4081 net.cpp:406] Convolution20 <- Convolution19
I1006 21:21:50.378423  4081 net.cpp:380] Convolution20 -> Convolution20
I1006 21:21:50.384227  4081 net.cpp:122] Setting up Convolution20
I1006 21:21:50.384239  4081 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 21:21:50.384243  4081 net.cpp:137] Memory required for data: 409875600
I1006 21:21:50.384248  4081 layer_factory.hpp:77] Creating layer BatchNorm20
I1006 21:21:50.384253  4081 net.cpp:84] Creating Layer BatchNorm20
I1006 21:21:50.384256  4081 net.cpp:406] BatchNorm20 <- Convolution20
I1006 21:21:50.384260  4081 net.cpp:367] BatchNorm20 -> Convolution20 (in-place)
I1006 21:21:50.384394  4081 net.cpp:122] Setting up BatchNorm20
I1006 21:21:50.384399  4081 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 21:21:50.384402  4081 net.cpp:137] Memory required for data: 412384400
I1006 21:21:50.384407  4081 layer_factory.hpp:77] Creating layer Scale20
I1006 21:21:50.384412  4081 net.cpp:84] Creating Layer Scale20
I1006 21:21:50.384415  4081 net.cpp:406] Scale20 <- Convolution20
I1006 21:21:50.384418  4081 net.cpp:367] Scale20 -> Convolution20 (in-place)
I1006 21:21:50.384445  4081 layer_factory.hpp:77] Creating layer Scale20
I1006 21:21:50.384523  4081 net.cpp:122] Setting up Scale20
I1006 21:21:50.384528  4081 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 21:21:50.384531  4081 net.cpp:137] Memory required for data: 414893200
I1006 21:21:50.384534  4081 layer_factory.hpp:77] Creating layer Eltwise9
I1006 21:21:50.384539  4081 net.cpp:84] Creating Layer Eltwise9
I1006 21:21:50.384543  4081 net.cpp:406] Eltwise9 <- Eltwise8_penlu17_0_split_1
I1006 21:21:50.384546  4081 net.cpp:406] Eltwise9 <- Convolution20
I1006 21:21:50.384549  4081 net.cpp:380] Eltwise9 -> Eltwise9
I1006 21:21:50.384565  4081 net.cpp:122] Setting up Eltwise9
I1006 21:21:50.384570  4081 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 21:21:50.384573  4081 net.cpp:137] Memory required for data: 417402000
I1006 21:21:50.384575  4081 layer_factory.hpp:77] Creating layer penlu19
I1006 21:21:50.384582  4081 net.cpp:84] Creating Layer penlu19
I1006 21:21:50.384585  4081 net.cpp:406] penlu19 <- Eltwise9
I1006 21:21:50.384588  4081 net.cpp:367] penlu19 -> Eltwise9 (in-place)
I1006 21:21:50.384697  4081 net.cpp:122] Setting up penlu19
I1006 21:21:50.384702  4081 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 21:21:50.384706  4081 net.cpp:137] Memory required for data: 419910800
I1006 21:21:50.384711  4081 layer_factory.hpp:77] Creating layer Eltwise9_penlu19_0_split
I1006 21:21:50.384714  4081 net.cpp:84] Creating Layer Eltwise9_penlu19_0_split
I1006 21:21:50.384717  4081 net.cpp:406] Eltwise9_penlu19_0_split <- Eltwise9
I1006 21:21:50.384722  4081 net.cpp:380] Eltwise9_penlu19_0_split -> Eltwise9_penlu19_0_split_0
I1006 21:21:50.384727  4081 net.cpp:380] Eltwise9_penlu19_0_split -> Eltwise9_penlu19_0_split_1
I1006 21:21:50.384749  4081 net.cpp:122] Setting up Eltwise9_penlu19_0_split
I1006 21:21:50.384754  4081 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 21:21:50.384758  4081 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 21:21:50.384763  4081 net.cpp:137] Memory required for data: 424928400
I1006 21:21:50.384764  4081 layer_factory.hpp:77] Creating layer Convolution21
I1006 21:21:50.384773  4081 net.cpp:84] Creating Layer Convolution21
I1006 21:21:50.384775  4081 net.cpp:406] Convolution21 <- Eltwise9_penlu19_0_split_0
I1006 21:21:50.384780  4081 net.cpp:380] Convolution21 -> Convolution21
I1006 21:21:50.391295  4081 net.cpp:122] Setting up Convolution21
I1006 21:21:50.391309  4081 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 21:21:50.391315  4081 net.cpp:137] Memory required for data: 427437200
I1006 21:21:50.391324  4081 layer_factory.hpp:77] Creating layer BatchNorm21
I1006 21:21:50.391331  4081 net.cpp:84] Creating Layer BatchNorm21
I1006 21:21:50.391345  4081 net.cpp:406] BatchNorm21 <- Convolution21
I1006 21:21:50.391352  4081 net.cpp:367] BatchNorm21 -> Convolution21 (in-place)
I1006 21:21:50.391546  4081 net.cpp:122] Setting up BatchNorm21
I1006 21:21:50.391554  4081 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 21:21:50.391559  4081 net.cpp:137] Memory required for data: 429946000
I1006 21:21:50.391569  4081 layer_factory.hpp:77] Creating layer Scale21
I1006 21:21:50.391577  4081 net.cpp:84] Creating Layer Scale21
I1006 21:21:50.391582  4081 net.cpp:406] Scale21 <- Convolution21
I1006 21:21:50.391592  4081 net.cpp:367] Scale21 -> Convolution21 (in-place)
I1006 21:21:50.391629  4081 layer_factory.hpp:77] Creating layer Scale21
I1006 21:21:50.391743  4081 net.cpp:122] Setting up Scale21
I1006 21:21:50.391752  4081 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 21:21:50.391757  4081 net.cpp:137] Memory required for data: 432454800
I1006 21:21:50.391765  4081 layer_factory.hpp:77] Creating layer penlu20
I1006 21:21:50.391775  4081 net.cpp:84] Creating Layer penlu20
I1006 21:21:50.391780  4081 net.cpp:406] penlu20 <- Convolution21
I1006 21:21:50.391788  4081 net.cpp:367] penlu20 -> Convolution21 (in-place)
I1006 21:21:50.391943  4081 net.cpp:122] Setting up penlu20
I1006 21:21:50.391952  4081 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 21:21:50.391957  4081 net.cpp:137] Memory required for data: 434963600
I1006 21:21:50.391965  4081 layer_factory.hpp:77] Creating layer Convolution22
I1006 21:21:50.391976  4081 net.cpp:84] Creating Layer Convolution22
I1006 21:21:50.391981  4081 net.cpp:406] Convolution22 <- Convolution21
I1006 21:21:50.391990  4081 net.cpp:380] Convolution22 -> Convolution22
I1006 21:21:50.397809  4081 net.cpp:122] Setting up Convolution22
I1006 21:21:50.397830  4081 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 21:21:50.397833  4081 net.cpp:137] Memory required for data: 437472400
I1006 21:21:50.397837  4081 layer_factory.hpp:77] Creating layer BatchNorm22
I1006 21:21:50.397843  4081 net.cpp:84] Creating Layer BatchNorm22
I1006 21:21:50.397846  4081 net.cpp:406] BatchNorm22 <- Convolution22
I1006 21:21:50.397850  4081 net.cpp:367] BatchNorm22 -> Convolution22 (in-place)
I1006 21:21:50.398006  4081 net.cpp:122] Setting up BatchNorm22
I1006 21:21:50.398013  4081 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 21:21:50.398025  4081 net.cpp:137] Memory required for data: 439981200
I1006 21:21:50.398030  4081 layer_factory.hpp:77] Creating layer Scale22
I1006 21:21:50.398035  4081 net.cpp:84] Creating Layer Scale22
I1006 21:21:50.398038  4081 net.cpp:406] Scale22 <- Convolution22
I1006 21:21:50.398041  4081 net.cpp:367] Scale22 -> Convolution22 (in-place)
I1006 21:21:50.398072  4081 layer_factory.hpp:77] Creating layer Scale22
I1006 21:21:50.398149  4081 net.cpp:122] Setting up Scale22
I1006 21:21:50.398155  4081 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 21:21:50.398159  4081 net.cpp:137] Memory required for data: 442490000
I1006 21:21:50.398162  4081 layer_factory.hpp:77] Creating layer Eltwise10
I1006 21:21:50.398166  4081 net.cpp:84] Creating Layer Eltwise10
I1006 21:21:50.398170  4081 net.cpp:406] Eltwise10 <- Eltwise9_penlu19_0_split_1
I1006 21:21:50.398174  4081 net.cpp:406] Eltwise10 <- Convolution22
I1006 21:21:50.398176  4081 net.cpp:380] Eltwise10 -> Eltwise10
I1006 21:21:50.398195  4081 net.cpp:122] Setting up Eltwise10
I1006 21:21:50.398200  4081 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 21:21:50.398201  4081 net.cpp:137] Memory required for data: 444998800
I1006 21:21:50.398205  4081 layer_factory.hpp:77] Creating layer penlu21
I1006 21:21:50.398210  4081 net.cpp:84] Creating Layer penlu21
I1006 21:21:50.398212  4081 net.cpp:406] penlu21 <- Eltwise10
I1006 21:21:50.398216  4081 net.cpp:367] penlu21 -> Eltwise10 (in-place)
I1006 21:21:50.398329  4081 net.cpp:122] Setting up penlu21
I1006 21:21:50.398334  4081 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 21:21:50.398336  4081 net.cpp:137] Memory required for data: 447507600
I1006 21:21:50.398340  4081 layer_factory.hpp:77] Creating layer Eltwise10_penlu21_0_split
I1006 21:21:50.398353  4081 net.cpp:84] Creating Layer Eltwise10_penlu21_0_split
I1006 21:21:50.398357  4081 net.cpp:406] Eltwise10_penlu21_0_split <- Eltwise10
I1006 21:21:50.398360  4081 net.cpp:380] Eltwise10_penlu21_0_split -> Eltwise10_penlu21_0_split_0
I1006 21:21:50.398365  4081 net.cpp:380] Eltwise10_penlu21_0_split -> Eltwise10_penlu21_0_split_1
I1006 21:21:50.398391  4081 net.cpp:122] Setting up Eltwise10_penlu21_0_split
I1006 21:21:50.398396  4081 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 21:21:50.398399  4081 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1006 21:21:50.398401  4081 net.cpp:137] Memory required for data: 452525200
I1006 21:21:50.398404  4081 layer_factory.hpp:77] Creating layer Convolution23
I1006 21:21:50.398411  4081 net.cpp:84] Creating Layer Convolution23
I1006 21:21:50.398413  4081 net.cpp:406] Convolution23 <- Eltwise10_penlu21_0_split_0
I1006 21:21:50.398418  4081 net.cpp:380] Convolution23 -> Convolution23
I1006 21:21:50.404623  4081 net.cpp:122] Setting up Convolution23
I1006 21:21:50.404634  4081 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 21:21:50.404637  4081 net.cpp:137] Memory required for data: 453779600
I1006 21:21:50.404642  4081 layer_factory.hpp:77] Creating layer BatchNorm23
I1006 21:21:50.404649  4081 net.cpp:84] Creating Layer BatchNorm23
I1006 21:21:50.404652  4081 net.cpp:406] BatchNorm23 <- Convolution23
I1006 21:21:50.404656  4081 net.cpp:367] BatchNorm23 -> Convolution23 (in-place)
I1006 21:21:50.404790  4081 net.cpp:122] Setting up BatchNorm23
I1006 21:21:50.404796  4081 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 21:21:50.404799  4081 net.cpp:137] Memory required for data: 455034000
I1006 21:21:50.404804  4081 layer_factory.hpp:77] Creating layer Scale23
I1006 21:21:50.404809  4081 net.cpp:84] Creating Layer Scale23
I1006 21:21:50.404812  4081 net.cpp:406] Scale23 <- Convolution23
I1006 21:21:50.404815  4081 net.cpp:367] Scale23 -> Convolution23 (in-place)
I1006 21:21:50.404844  4081 layer_factory.hpp:77] Creating layer Scale23
I1006 21:21:50.404920  4081 net.cpp:122] Setting up Scale23
I1006 21:21:50.404927  4081 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 21:21:50.404929  4081 net.cpp:137] Memory required for data: 456288400
I1006 21:21:50.404933  4081 layer_factory.hpp:77] Creating layer Convolution24
I1006 21:21:50.404942  4081 net.cpp:84] Creating Layer Convolution24
I1006 21:21:50.404944  4081 net.cpp:406] Convolution24 <- Eltwise10_penlu21_0_split_1
I1006 21:21:50.404948  4081 net.cpp:380] Convolution24 -> Convolution24
I1006 21:21:50.411221  4081 net.cpp:122] Setting up Convolution24
I1006 21:21:50.411232  4081 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 21:21:50.411236  4081 net.cpp:137] Memory required for data: 457542800
I1006 21:21:50.411240  4081 layer_factory.hpp:77] Creating layer BatchNorm24
I1006 21:21:50.411247  4081 net.cpp:84] Creating Layer BatchNorm24
I1006 21:21:50.411250  4081 net.cpp:406] BatchNorm24 <- Convolution24
I1006 21:21:50.411257  4081 net.cpp:367] BatchNorm24 -> Convolution24 (in-place)
I1006 21:21:50.411391  4081 net.cpp:122] Setting up BatchNorm24
I1006 21:21:50.411397  4081 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 21:21:50.411401  4081 net.cpp:137] Memory required for data: 458797200
I1006 21:21:50.411406  4081 layer_factory.hpp:77] Creating layer Scale24
I1006 21:21:50.411411  4081 net.cpp:84] Creating Layer Scale24
I1006 21:21:50.411413  4081 net.cpp:406] Scale24 <- Convolution24
I1006 21:21:50.411417  4081 net.cpp:367] Scale24 -> Convolution24 (in-place)
I1006 21:21:50.411447  4081 layer_factory.hpp:77] Creating layer Scale24
I1006 21:21:50.411526  4081 net.cpp:122] Setting up Scale24
I1006 21:21:50.411531  4081 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 21:21:50.411535  4081 net.cpp:137] Memory required for data: 460051600
I1006 21:21:50.411538  4081 layer_factory.hpp:77] Creating layer penlu22
I1006 21:21:50.411545  4081 net.cpp:84] Creating Layer penlu22
I1006 21:21:50.411547  4081 net.cpp:406] penlu22 <- Convolution24
I1006 21:21:50.411552  4081 net.cpp:367] penlu22 -> Convolution24 (in-place)
I1006 21:21:50.411671  4081 net.cpp:122] Setting up penlu22
I1006 21:21:50.411677  4081 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 21:21:50.411680  4081 net.cpp:137] Memory required for data: 461306000
I1006 21:21:50.411685  4081 layer_factory.hpp:77] Creating layer Convolution25
I1006 21:21:50.411694  4081 net.cpp:84] Creating Layer Convolution25
I1006 21:21:50.411696  4081 net.cpp:406] Convolution25 <- Convolution24
I1006 21:21:50.411701  4081 net.cpp:380] Convolution25 -> Convolution25
I1006 21:21:50.418050  4081 net.cpp:122] Setting up Convolution25
I1006 21:21:50.418061  4081 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 21:21:50.418063  4081 net.cpp:137] Memory required for data: 462560400
I1006 21:21:50.418068  4081 layer_factory.hpp:77] Creating layer BatchNorm25
I1006 21:21:50.418076  4081 net.cpp:84] Creating Layer BatchNorm25
I1006 21:21:50.418079  4081 net.cpp:406] BatchNorm25 <- Convolution25
I1006 21:21:50.418082  4081 net.cpp:367] BatchNorm25 -> Convolution25 (in-place)
I1006 21:21:50.418225  4081 net.cpp:122] Setting up BatchNorm25
I1006 21:21:50.418229  4081 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 21:21:50.418232  4081 net.cpp:137] Memory required for data: 463814800
I1006 21:21:50.418237  4081 layer_factory.hpp:77] Creating layer Scale25
I1006 21:21:50.418243  4081 net.cpp:84] Creating Layer Scale25
I1006 21:21:50.418246  4081 net.cpp:406] Scale25 <- Convolution25
I1006 21:21:50.418251  4081 net.cpp:367] Scale25 -> Convolution25 (in-place)
I1006 21:21:50.418279  4081 layer_factory.hpp:77] Creating layer Scale25
I1006 21:21:50.418359  4081 net.cpp:122] Setting up Scale25
I1006 21:21:50.418365  4081 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 21:21:50.418367  4081 net.cpp:137] Memory required for data: 465069200
I1006 21:21:50.418371  4081 layer_factory.hpp:77] Creating layer Eltwise11
I1006 21:21:50.418377  4081 net.cpp:84] Creating Layer Eltwise11
I1006 21:21:50.418380  4081 net.cpp:406] Eltwise11 <- Convolution23
I1006 21:21:50.418383  4081 net.cpp:406] Eltwise11 <- Convolution25
I1006 21:21:50.418387  4081 net.cpp:380] Eltwise11 -> Eltwise11
I1006 21:21:50.418404  4081 net.cpp:122] Setting up Eltwise11
I1006 21:21:50.418409  4081 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 21:21:50.418412  4081 net.cpp:137] Memory required for data: 466323600
I1006 21:21:50.418414  4081 layer_factory.hpp:77] Creating layer penlu23
I1006 21:21:50.418421  4081 net.cpp:84] Creating Layer penlu23
I1006 21:21:50.418423  4081 net.cpp:406] penlu23 <- Eltwise11
I1006 21:21:50.418427  4081 net.cpp:367] penlu23 -> Eltwise11 (in-place)
I1006 21:21:50.418536  4081 net.cpp:122] Setting up penlu23
I1006 21:21:50.418542  4081 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 21:21:50.418545  4081 net.cpp:137] Memory required for data: 467578000
I1006 21:21:50.418550  4081 layer_factory.hpp:77] Creating layer Eltwise11_penlu23_0_split
I1006 21:21:50.418555  4081 net.cpp:84] Creating Layer Eltwise11_penlu23_0_split
I1006 21:21:50.418557  4081 net.cpp:406] Eltwise11_penlu23_0_split <- Eltwise11
I1006 21:21:50.418560  4081 net.cpp:380] Eltwise11_penlu23_0_split -> Eltwise11_penlu23_0_split_0
I1006 21:21:50.418565  4081 net.cpp:380] Eltwise11_penlu23_0_split -> Eltwise11_penlu23_0_split_1
I1006 21:21:50.418589  4081 net.cpp:122] Setting up Eltwise11_penlu23_0_split
I1006 21:21:50.418594  4081 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 21:21:50.418597  4081 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 21:21:50.418599  4081 net.cpp:137] Memory required for data: 470086800
I1006 21:21:50.418602  4081 layer_factory.hpp:77] Creating layer Convolution26
I1006 21:21:50.418608  4081 net.cpp:84] Creating Layer Convolution26
I1006 21:21:50.418612  4081 net.cpp:406] Convolution26 <- Eltwise11_penlu23_0_split_0
I1006 21:21:50.418617  4081 net.cpp:380] Convolution26 -> Convolution26
I1006 21:21:50.422973  4081 net.cpp:122] Setting up Convolution26
I1006 21:21:50.422989  4081 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 21:21:50.422994  4081 net.cpp:137] Memory required for data: 471341200
I1006 21:21:50.423009  4081 layer_factory.hpp:77] Creating layer BatchNorm26
I1006 21:21:50.423018  4081 net.cpp:84] Creating Layer BatchNorm26
I1006 21:21:50.423024  4081 net.cpp:406] BatchNorm26 <- Convolution26
I1006 21:21:50.423032  4081 net.cpp:367] BatchNorm26 -> Convolution26 (in-place)
I1006 21:21:50.423256  4081 net.cpp:122] Setting up BatchNorm26
I1006 21:21:50.423279  4081 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 21:21:50.423285  4081 net.cpp:137] Memory required for data: 472595600
I1006 21:21:50.423293  4081 layer_factory.hpp:77] Creating layer Scale26
I1006 21:21:50.423303  4081 net.cpp:84] Creating Layer Scale26
I1006 21:21:50.423310  4081 net.cpp:406] Scale26 <- Convolution26
I1006 21:21:50.423317  4081 net.cpp:367] Scale26 -> Convolution26 (in-place)
I1006 21:21:50.423379  4081 layer_factory.hpp:77] Creating layer Scale26
I1006 21:21:50.423517  4081 net.cpp:122] Setting up Scale26
I1006 21:21:50.423527  4081 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 21:21:50.423542  4081 net.cpp:137] Memory required for data: 473850000
I1006 21:21:50.423548  4081 layer_factory.hpp:77] Creating layer penlu24
I1006 21:21:50.423557  4081 net.cpp:84] Creating Layer penlu24
I1006 21:21:50.423563  4081 net.cpp:406] penlu24 <- Convolution26
I1006 21:21:50.423570  4081 net.cpp:367] penlu24 -> Convolution26 (in-place)
I1006 21:21:50.423738  4081 net.cpp:122] Setting up penlu24
I1006 21:21:50.423748  4081 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 21:21:50.423753  4081 net.cpp:137] Memory required for data: 475104400
I1006 21:21:50.423760  4081 layer_factory.hpp:77] Creating layer Convolution27
I1006 21:21:50.423771  4081 net.cpp:84] Creating Layer Convolution27
I1006 21:21:50.423777  4081 net.cpp:406] Convolution27 <- Convolution26
I1006 21:21:50.423785  4081 net.cpp:380] Convolution27 -> Convolution27
I1006 21:21:50.429841  4081 net.cpp:122] Setting up Convolution27
I1006 21:21:50.429852  4081 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 21:21:50.429854  4081 net.cpp:137] Memory required for data: 476358800
I1006 21:21:50.429859  4081 layer_factory.hpp:77] Creating layer BatchNorm27
I1006 21:21:50.429865  4081 net.cpp:84] Creating Layer BatchNorm27
I1006 21:21:50.429868  4081 net.cpp:406] BatchNorm27 <- Convolution27
I1006 21:21:50.429873  4081 net.cpp:367] BatchNorm27 -> Convolution27 (in-place)
I1006 21:21:50.430016  4081 net.cpp:122] Setting up BatchNorm27
I1006 21:21:50.430022  4081 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 21:21:50.430023  4081 net.cpp:137] Memory required for data: 477613200
I1006 21:21:50.430049  4081 layer_factory.hpp:77] Creating layer Scale27
I1006 21:21:50.430064  4081 net.cpp:84] Creating Layer Scale27
I1006 21:21:50.430068  4081 net.cpp:406] Scale27 <- Convolution27
I1006 21:21:50.430070  4081 net.cpp:367] Scale27 -> Convolution27 (in-place)
I1006 21:21:50.430102  4081 layer_factory.hpp:77] Creating layer Scale27
I1006 21:21:50.430183  4081 net.cpp:122] Setting up Scale27
I1006 21:21:50.430189  4081 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 21:21:50.430193  4081 net.cpp:137] Memory required for data: 478867600
I1006 21:21:50.430197  4081 layer_factory.hpp:77] Creating layer Eltwise12
I1006 21:21:50.430202  4081 net.cpp:84] Creating Layer Eltwise12
I1006 21:21:50.430205  4081 net.cpp:406] Eltwise12 <- Eltwise11_penlu23_0_split_1
I1006 21:21:50.430208  4081 net.cpp:406] Eltwise12 <- Convolution27
I1006 21:21:50.430212  4081 net.cpp:380] Eltwise12 -> Eltwise12
I1006 21:21:50.430235  4081 net.cpp:122] Setting up Eltwise12
I1006 21:21:50.430240  4081 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 21:21:50.430243  4081 net.cpp:137] Memory required for data: 480122000
I1006 21:21:50.430246  4081 layer_factory.hpp:77] Creating layer penlu25
I1006 21:21:50.430253  4081 net.cpp:84] Creating Layer penlu25
I1006 21:21:50.430255  4081 net.cpp:406] penlu25 <- Eltwise12
I1006 21:21:50.430259  4081 net.cpp:367] penlu25 -> Eltwise12 (in-place)
I1006 21:21:50.430374  4081 net.cpp:122] Setting up penlu25
I1006 21:21:50.430380  4081 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 21:21:50.430392  4081 net.cpp:137] Memory required for data: 481376400
I1006 21:21:50.430397  4081 layer_factory.hpp:77] Creating layer Eltwise12_penlu25_0_split
I1006 21:21:50.430402  4081 net.cpp:84] Creating Layer Eltwise12_penlu25_0_split
I1006 21:21:50.430404  4081 net.cpp:406] Eltwise12_penlu25_0_split <- Eltwise12
I1006 21:21:50.430408  4081 net.cpp:380] Eltwise12_penlu25_0_split -> Eltwise12_penlu25_0_split_0
I1006 21:21:50.430413  4081 net.cpp:380] Eltwise12_penlu25_0_split -> Eltwise12_penlu25_0_split_1
I1006 21:21:50.430440  4081 net.cpp:122] Setting up Eltwise12_penlu25_0_split
I1006 21:21:50.430444  4081 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 21:21:50.430449  4081 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 21:21:50.430452  4081 net.cpp:137] Memory required for data: 483885200
I1006 21:21:50.430454  4081 layer_factory.hpp:77] Creating layer Convolution28
I1006 21:21:50.430460  4081 net.cpp:84] Creating Layer Convolution28
I1006 21:21:50.430464  4081 net.cpp:406] Convolution28 <- Eltwise12_penlu25_0_split_0
I1006 21:21:50.430469  4081 net.cpp:380] Convolution28 -> Convolution28
I1006 21:21:50.436225  4081 net.cpp:122] Setting up Convolution28
I1006 21:21:50.436236  4081 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 21:21:50.436240  4081 net.cpp:137] Memory required for data: 485139600
I1006 21:21:50.436244  4081 layer_factory.hpp:77] Creating layer BatchNorm28
I1006 21:21:50.436250  4081 net.cpp:84] Creating Layer BatchNorm28
I1006 21:21:50.436254  4081 net.cpp:406] BatchNorm28 <- Convolution28
I1006 21:21:50.436257  4081 net.cpp:367] BatchNorm28 -> Convolution28 (in-place)
I1006 21:21:50.436396  4081 net.cpp:122] Setting up BatchNorm28
I1006 21:21:50.436403  4081 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 21:21:50.436404  4081 net.cpp:137] Memory required for data: 486394000
I1006 21:21:50.436409  4081 layer_factory.hpp:77] Creating layer Scale28
I1006 21:21:50.436415  4081 net.cpp:84] Creating Layer Scale28
I1006 21:21:50.436419  4081 net.cpp:406] Scale28 <- Convolution28
I1006 21:21:50.436421  4081 net.cpp:367] Scale28 -> Convolution28 (in-place)
I1006 21:21:50.436450  4081 layer_factory.hpp:77] Creating layer Scale28
I1006 21:21:50.436532  4081 net.cpp:122] Setting up Scale28
I1006 21:21:50.436537  4081 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 21:21:50.436539  4081 net.cpp:137] Memory required for data: 487648400
I1006 21:21:50.436543  4081 layer_factory.hpp:77] Creating layer penlu26
I1006 21:21:50.436549  4081 net.cpp:84] Creating Layer penlu26
I1006 21:21:50.436553  4081 net.cpp:406] penlu26 <- Convolution28
I1006 21:21:50.436558  4081 net.cpp:367] penlu26 -> Convolution28 (in-place)
I1006 21:21:50.436671  4081 net.cpp:122] Setting up penlu26
I1006 21:21:50.436676  4081 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 21:21:50.436678  4081 net.cpp:137] Memory required for data: 488902800
I1006 21:21:50.436683  4081 layer_factory.hpp:77] Creating layer Convolution29
I1006 21:21:50.436691  4081 net.cpp:84] Creating Layer Convolution29
I1006 21:21:50.436693  4081 net.cpp:406] Convolution29 <- Convolution28
I1006 21:21:50.436698  4081 net.cpp:380] Convolution29 -> Convolution29
I1006 21:21:50.443080  4081 net.cpp:122] Setting up Convolution29
I1006 21:21:50.443091  4081 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 21:21:50.443094  4081 net.cpp:137] Memory required for data: 490157200
I1006 21:21:50.443100  4081 layer_factory.hpp:77] Creating layer BatchNorm29
I1006 21:21:50.443106  4081 net.cpp:84] Creating Layer BatchNorm29
I1006 21:21:50.443109  4081 net.cpp:406] BatchNorm29 <- Convolution29
I1006 21:21:50.443114  4081 net.cpp:367] BatchNorm29 -> Convolution29 (in-place)
I1006 21:21:50.443262  4081 net.cpp:122] Setting up BatchNorm29
I1006 21:21:50.443269  4081 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 21:21:50.443271  4081 net.cpp:137] Memory required for data: 491411600
I1006 21:21:50.443276  4081 layer_factory.hpp:77] Creating layer Scale29
I1006 21:21:50.443281  4081 net.cpp:84] Creating Layer Scale29
I1006 21:21:50.443291  4081 net.cpp:406] Scale29 <- Convolution29
I1006 21:21:50.443296  4081 net.cpp:367] Scale29 -> Convolution29 (in-place)
I1006 21:21:50.443328  4081 layer_factory.hpp:77] Creating layer Scale29
I1006 21:21:50.443411  4081 net.cpp:122] Setting up Scale29
I1006 21:21:50.443418  4081 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 21:21:50.443421  4081 net.cpp:137] Memory required for data: 492666000
I1006 21:21:50.443425  4081 layer_factory.hpp:77] Creating layer Eltwise13
I1006 21:21:50.443429  4081 net.cpp:84] Creating Layer Eltwise13
I1006 21:21:50.443434  4081 net.cpp:406] Eltwise13 <- Eltwise12_penlu25_0_split_1
I1006 21:21:50.443436  4081 net.cpp:406] Eltwise13 <- Convolution29
I1006 21:21:50.443440  4081 net.cpp:380] Eltwise13 -> Eltwise13
I1006 21:21:50.443459  4081 net.cpp:122] Setting up Eltwise13
I1006 21:21:50.443464  4081 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 21:21:50.443466  4081 net.cpp:137] Memory required for data: 493920400
I1006 21:21:50.443469  4081 layer_factory.hpp:77] Creating layer penlu27
I1006 21:21:50.443475  4081 net.cpp:84] Creating Layer penlu27
I1006 21:21:50.443477  4081 net.cpp:406] penlu27 <- Eltwise13
I1006 21:21:50.443481  4081 net.cpp:367] penlu27 -> Eltwise13 (in-place)
I1006 21:21:50.443598  4081 net.cpp:122] Setting up penlu27
I1006 21:21:50.443603  4081 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 21:21:50.443605  4081 net.cpp:137] Memory required for data: 495174800
I1006 21:21:50.443610  4081 layer_factory.hpp:77] Creating layer Eltwise13_penlu27_0_split
I1006 21:21:50.443615  4081 net.cpp:84] Creating Layer Eltwise13_penlu27_0_split
I1006 21:21:50.443619  4081 net.cpp:406] Eltwise13_penlu27_0_split <- Eltwise13
I1006 21:21:50.443621  4081 net.cpp:380] Eltwise13_penlu27_0_split -> Eltwise13_penlu27_0_split_0
I1006 21:21:50.443627  4081 net.cpp:380] Eltwise13_penlu27_0_split -> Eltwise13_penlu27_0_split_1
I1006 21:21:50.443652  4081 net.cpp:122] Setting up Eltwise13_penlu27_0_split
I1006 21:21:50.443657  4081 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 21:21:50.443661  4081 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 21:21:50.443665  4081 net.cpp:137] Memory required for data: 497683600
I1006 21:21:50.443666  4081 layer_factory.hpp:77] Creating layer Convolution30
I1006 21:21:50.443673  4081 net.cpp:84] Creating Layer Convolution30
I1006 21:21:50.443676  4081 net.cpp:406] Convolution30 <- Eltwise13_penlu27_0_split_0
I1006 21:21:50.443681  4081 net.cpp:380] Convolution30 -> Convolution30
I1006 21:21:50.445739  4081 net.cpp:122] Setting up Convolution30
I1006 21:21:50.445749  4081 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 21:21:50.445753  4081 net.cpp:137] Memory required for data: 498938000
I1006 21:21:50.445757  4081 layer_factory.hpp:77] Creating layer BatchNorm30
I1006 21:21:50.445765  4081 net.cpp:84] Creating Layer BatchNorm30
I1006 21:21:50.445768  4081 net.cpp:406] BatchNorm30 <- Convolution30
I1006 21:21:50.445772  4081 net.cpp:367] BatchNorm30 -> Convolution30 (in-place)
I1006 21:21:50.445914  4081 net.cpp:122] Setting up BatchNorm30
I1006 21:21:50.445919  4081 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 21:21:50.445922  4081 net.cpp:137] Memory required for data: 500192400
I1006 21:21:50.445927  4081 layer_factory.hpp:77] Creating layer Scale30
I1006 21:21:50.445932  4081 net.cpp:84] Creating Layer Scale30
I1006 21:21:50.445935  4081 net.cpp:406] Scale30 <- Convolution30
I1006 21:21:50.445938  4081 net.cpp:367] Scale30 -> Convolution30 (in-place)
I1006 21:21:50.445968  4081 layer_factory.hpp:77] Creating layer Scale30
I1006 21:21:50.446080  4081 net.cpp:122] Setting up Scale30
I1006 21:21:50.446086  4081 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 21:21:50.446089  4081 net.cpp:137] Memory required for data: 501446800
I1006 21:21:50.446094  4081 layer_factory.hpp:77] Creating layer penlu28
I1006 21:21:50.446099  4081 net.cpp:84] Creating Layer penlu28
I1006 21:21:50.446101  4081 net.cpp:406] penlu28 <- Convolution30
I1006 21:21:50.446115  4081 net.cpp:367] penlu28 -> Convolution30 (in-place)
I1006 21:21:50.446236  4081 net.cpp:122] Setting up penlu28
I1006 21:21:50.446243  4081 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 21:21:50.446245  4081 net.cpp:137] Memory required for data: 502701200
I1006 21:21:50.446249  4081 layer_factory.hpp:77] Creating layer Convolution31
I1006 21:21:50.446257  4081 net.cpp:84] Creating Layer Convolution31
I1006 21:21:50.446260  4081 net.cpp:406] Convolution31 <- Convolution30
I1006 21:21:50.446265  4081 net.cpp:380] Convolution31 -> Convolution31
I1006 21:21:50.450506  4081 net.cpp:122] Setting up Convolution31
I1006 21:21:50.450517  4081 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 21:21:50.450521  4081 net.cpp:137] Memory required for data: 503955600
I1006 21:21:50.450526  4081 layer_factory.hpp:77] Creating layer BatchNorm31
I1006 21:21:50.450532  4081 net.cpp:84] Creating Layer BatchNorm31
I1006 21:21:50.450536  4081 net.cpp:406] BatchNorm31 <- Convolution31
I1006 21:21:50.450541  4081 net.cpp:367] BatchNorm31 -> Convolution31 (in-place)
I1006 21:21:50.450685  4081 net.cpp:122] Setting up BatchNorm31
I1006 21:21:50.450690  4081 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 21:21:50.450693  4081 net.cpp:137] Memory required for data: 505210000
I1006 21:21:50.450698  4081 layer_factory.hpp:77] Creating layer Scale31
I1006 21:21:50.450704  4081 net.cpp:84] Creating Layer Scale31
I1006 21:21:50.450707  4081 net.cpp:406] Scale31 <- Convolution31
I1006 21:21:50.450711  4081 net.cpp:367] Scale31 -> Convolution31 (in-place)
I1006 21:21:50.450740  4081 layer_factory.hpp:77] Creating layer Scale31
I1006 21:21:50.450822  4081 net.cpp:122] Setting up Scale31
I1006 21:21:50.450827  4081 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 21:21:50.450830  4081 net.cpp:137] Memory required for data: 506464400
I1006 21:21:50.450834  4081 layer_factory.hpp:77] Creating layer Eltwise14
I1006 21:21:50.450839  4081 net.cpp:84] Creating Layer Eltwise14
I1006 21:21:50.450842  4081 net.cpp:406] Eltwise14 <- Eltwise13_penlu27_0_split_1
I1006 21:21:50.450845  4081 net.cpp:406] Eltwise14 <- Convolution31
I1006 21:21:50.450850  4081 net.cpp:380] Eltwise14 -> Eltwise14
I1006 21:21:50.450867  4081 net.cpp:122] Setting up Eltwise14
I1006 21:21:50.450871  4081 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 21:21:50.450875  4081 net.cpp:137] Memory required for data: 507718800
I1006 21:21:50.450877  4081 layer_factory.hpp:77] Creating layer penlu29
I1006 21:21:50.450882  4081 net.cpp:84] Creating Layer penlu29
I1006 21:21:50.450886  4081 net.cpp:406] penlu29 <- Eltwise14
I1006 21:21:50.450889  4081 net.cpp:367] penlu29 -> Eltwise14 (in-place)
I1006 21:21:50.451002  4081 net.cpp:122] Setting up penlu29
I1006 21:21:50.451007  4081 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 21:21:50.451010  4081 net.cpp:137] Memory required for data: 508973200
I1006 21:21:50.451015  4081 layer_factory.hpp:77] Creating layer Eltwise14_penlu29_0_split
I1006 21:21:50.451020  4081 net.cpp:84] Creating Layer Eltwise14_penlu29_0_split
I1006 21:21:50.451025  4081 net.cpp:406] Eltwise14_penlu29_0_split <- Eltwise14
I1006 21:21:50.451032  4081 net.cpp:380] Eltwise14_penlu29_0_split -> Eltwise14_penlu29_0_split_0
I1006 21:21:50.451040  4081 net.cpp:380] Eltwise14_penlu29_0_split -> Eltwise14_penlu29_0_split_1
I1006 21:21:50.451076  4081 net.cpp:122] Setting up Eltwise14_penlu29_0_split
I1006 21:21:50.451083  4081 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 21:21:50.451089  4081 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 21:21:50.451093  4081 net.cpp:137] Memory required for data: 511482000
I1006 21:21:50.451098  4081 layer_factory.hpp:77] Creating layer Convolution32
I1006 21:21:50.451109  4081 net.cpp:84] Creating Layer Convolution32
I1006 21:21:50.451114  4081 net.cpp:406] Convolution32 <- Eltwise14_penlu29_0_split_0
I1006 21:21:50.451122  4081 net.cpp:380] Convolution32 -> Convolution32
I1006 21:21:50.457269  4081 net.cpp:122] Setting up Convolution32
I1006 21:21:50.457291  4081 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 21:21:50.457295  4081 net.cpp:137] Memory required for data: 512736400
I1006 21:21:50.457307  4081 layer_factory.hpp:77] Creating layer BatchNorm32
I1006 21:21:50.457314  4081 net.cpp:84] Creating Layer BatchNorm32
I1006 21:21:50.457316  4081 net.cpp:406] BatchNorm32 <- Convolution32
I1006 21:21:50.457320  4081 net.cpp:367] BatchNorm32 -> Convolution32 (in-place)
I1006 21:21:50.457486  4081 net.cpp:122] Setting up BatchNorm32
I1006 21:21:50.457494  4081 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 21:21:50.457495  4081 net.cpp:137] Memory required for data: 513990800
I1006 21:21:50.457511  4081 layer_factory.hpp:77] Creating layer Scale32
I1006 21:21:50.457515  4081 net.cpp:84] Creating Layer Scale32
I1006 21:21:50.457518  4081 net.cpp:406] Scale32 <- Convolution32
I1006 21:21:50.457522  4081 net.cpp:367] Scale32 -> Convolution32 (in-place)
I1006 21:21:50.457554  4081 layer_factory.hpp:77] Creating layer Scale32
I1006 21:21:50.457638  4081 net.cpp:122] Setting up Scale32
I1006 21:21:50.457643  4081 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 21:21:50.457645  4081 net.cpp:137] Memory required for data: 515245200
I1006 21:21:50.457649  4081 layer_factory.hpp:77] Creating layer penlu30
I1006 21:21:50.457656  4081 net.cpp:84] Creating Layer penlu30
I1006 21:21:50.457659  4081 net.cpp:406] penlu30 <- Convolution32
I1006 21:21:50.457664  4081 net.cpp:367] penlu30 -> Convolution32 (in-place)
I1006 21:21:50.457777  4081 net.cpp:122] Setting up penlu30
I1006 21:21:50.457783  4081 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 21:21:50.457787  4081 net.cpp:137] Memory required for data: 516499600
I1006 21:21:50.457790  4081 layer_factory.hpp:77] Creating layer Convolution33
I1006 21:21:50.457799  4081 net.cpp:84] Creating Layer Convolution33
I1006 21:21:50.457803  4081 net.cpp:406] Convolution33 <- Convolution32
I1006 21:21:50.457806  4081 net.cpp:380] Convolution33 -> Convolution33
I1006 21:21:50.464290  4081 net.cpp:122] Setting up Convolution33
I1006 21:21:50.464301  4081 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 21:21:50.464304  4081 net.cpp:137] Memory required for data: 517754000
I1006 21:21:50.464309  4081 layer_factory.hpp:77] Creating layer BatchNorm33
I1006 21:21:50.464314  4081 net.cpp:84] Creating Layer BatchNorm33
I1006 21:21:50.464318  4081 net.cpp:406] BatchNorm33 <- Convolution33
I1006 21:21:50.464323  4081 net.cpp:367] BatchNorm33 -> Convolution33 (in-place)
I1006 21:21:50.464469  4081 net.cpp:122] Setting up BatchNorm33
I1006 21:21:50.464475  4081 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 21:21:50.464478  4081 net.cpp:137] Memory required for data: 519008400
I1006 21:21:50.464483  4081 layer_factory.hpp:77] Creating layer Scale33
I1006 21:21:50.464488  4081 net.cpp:84] Creating Layer Scale33
I1006 21:21:50.464490  4081 net.cpp:406] Scale33 <- Convolution33
I1006 21:21:50.464494  4081 net.cpp:367] Scale33 -> Convolution33 (in-place)
I1006 21:21:50.464524  4081 layer_factory.hpp:77] Creating layer Scale33
I1006 21:21:50.464607  4081 net.cpp:122] Setting up Scale33
I1006 21:21:50.464612  4081 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 21:21:50.464615  4081 net.cpp:137] Memory required for data: 520262800
I1006 21:21:50.464619  4081 layer_factory.hpp:77] Creating layer Eltwise15
I1006 21:21:50.464623  4081 net.cpp:84] Creating Layer Eltwise15
I1006 21:21:50.464627  4081 net.cpp:406] Eltwise15 <- Eltwise14_penlu29_0_split_1
I1006 21:21:50.464630  4081 net.cpp:406] Eltwise15 <- Convolution33
I1006 21:21:50.464635  4081 net.cpp:380] Eltwise15 -> Eltwise15
I1006 21:21:50.464653  4081 net.cpp:122] Setting up Eltwise15
I1006 21:21:50.464658  4081 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 21:21:50.464661  4081 net.cpp:137] Memory required for data: 521517200
I1006 21:21:50.464664  4081 layer_factory.hpp:77] Creating layer penlu31
I1006 21:21:50.464669  4081 net.cpp:84] Creating Layer penlu31
I1006 21:21:50.464673  4081 net.cpp:406] penlu31 <- Eltwise15
I1006 21:21:50.464676  4081 net.cpp:367] penlu31 -> Eltwise15 (in-place)
I1006 21:21:50.464792  4081 net.cpp:122] Setting up penlu31
I1006 21:21:50.464797  4081 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1006 21:21:50.464808  4081 net.cpp:137] Memory required for data: 522771600
I1006 21:21:50.464813  4081 layer_factory.hpp:77] Creating layer Pooling1
I1006 21:21:50.464819  4081 net.cpp:84] Creating Layer Pooling1
I1006 21:21:50.464823  4081 net.cpp:406] Pooling1 <- Eltwise15
I1006 21:21:50.464826  4081 net.cpp:380] Pooling1 -> Pooling1
I1006 21:21:50.466154  4081 net.cpp:122] Setting up Pooling1
I1006 21:21:50.466161  4081 net.cpp:129] Top shape: 100 64 1 1 (6400)
I1006 21:21:50.466166  4081 net.cpp:137] Memory required for data: 522797200
I1006 21:21:50.466167  4081 layer_factory.hpp:77] Creating layer InnerProduct1
I1006 21:21:50.466177  4081 net.cpp:84] Creating Layer InnerProduct1
I1006 21:21:50.466181  4081 net.cpp:406] InnerProduct1 <- Pooling1
I1006 21:21:50.466186  4081 net.cpp:380] InnerProduct1 -> InnerProduct1
I1006 21:21:50.466296  4081 net.cpp:122] Setting up InnerProduct1
I1006 21:21:50.466302  4081 net.cpp:129] Top shape: 100 10 (1000)
I1006 21:21:50.466305  4081 net.cpp:137] Memory required for data: 522801200
I1006 21:21:50.466310  4081 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I1006 21:21:50.466315  4081 net.cpp:84] Creating Layer SoftmaxWithLoss1
I1006 21:21:50.466317  4081 net.cpp:406] SoftmaxWithLoss1 <- InnerProduct1
I1006 21:21:50.466321  4081 net.cpp:406] SoftmaxWithLoss1 <- Data2
I1006 21:21:50.466325  4081 net.cpp:380] SoftmaxWithLoss1 -> SoftmaxWithLoss1
I1006 21:21:50.466331  4081 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I1006 21:21:50.468416  4081 net.cpp:122] Setting up SoftmaxWithLoss1
I1006 21:21:50.468425  4081 net.cpp:129] Top shape: (1)
I1006 21:21:50.468428  4081 net.cpp:132]     with loss weight 1
I1006 21:21:50.468441  4081 net.cpp:137] Memory required for data: 522801204
I1006 21:21:50.468444  4081 net.cpp:198] SoftmaxWithLoss1 needs backward computation.
I1006 21:21:50.468446  4081 net.cpp:198] InnerProduct1 needs backward computation.
I1006 21:21:50.468449  4081 net.cpp:198] Pooling1 needs backward computation.
I1006 21:21:50.468451  4081 net.cpp:198] penlu31 needs backward computation.
I1006 21:21:50.468453  4081 net.cpp:198] Eltwise15 needs backward computation.
I1006 21:21:50.468456  4081 net.cpp:198] Scale33 needs backward computation.
I1006 21:21:50.468458  4081 net.cpp:198] BatchNorm33 needs backward computation.
I1006 21:21:50.468461  4081 net.cpp:198] Convolution33 needs backward computation.
I1006 21:21:50.468462  4081 net.cpp:198] penlu30 needs backward computation.
I1006 21:21:50.468464  4081 net.cpp:198] Scale32 needs backward computation.
I1006 21:21:50.468466  4081 net.cpp:198] BatchNorm32 needs backward computation.
I1006 21:21:50.468468  4081 net.cpp:198] Convolution32 needs backward computation.
I1006 21:21:50.468472  4081 net.cpp:198] Eltwise14_penlu29_0_split needs backward computation.
I1006 21:21:50.468473  4081 net.cpp:198] penlu29 needs backward computation.
I1006 21:21:50.468475  4081 net.cpp:198] Eltwise14 needs backward computation.
I1006 21:21:50.468478  4081 net.cpp:198] Scale31 needs backward computation.
I1006 21:21:50.468480  4081 net.cpp:198] BatchNorm31 needs backward computation.
I1006 21:21:50.468482  4081 net.cpp:198] Convolution31 needs backward computation.
I1006 21:21:50.468485  4081 net.cpp:198] penlu28 needs backward computation.
I1006 21:21:50.468487  4081 net.cpp:198] Scale30 needs backward computation.
I1006 21:21:50.468489  4081 net.cpp:198] BatchNorm30 needs backward computation.
I1006 21:21:50.468492  4081 net.cpp:198] Convolution30 needs backward computation.
I1006 21:21:50.468494  4081 net.cpp:198] Eltwise13_penlu27_0_split needs backward computation.
I1006 21:21:50.468497  4081 net.cpp:198] penlu27 needs backward computation.
I1006 21:21:50.468499  4081 net.cpp:198] Eltwise13 needs backward computation.
I1006 21:21:50.468502  4081 net.cpp:198] Scale29 needs backward computation.
I1006 21:21:50.468505  4081 net.cpp:198] BatchNorm29 needs backward computation.
I1006 21:21:50.468508  4081 net.cpp:198] Convolution29 needs backward computation.
I1006 21:21:50.468509  4081 net.cpp:198] penlu26 needs backward computation.
I1006 21:21:50.468519  4081 net.cpp:198] Scale28 needs backward computation.
I1006 21:21:50.468521  4081 net.cpp:198] BatchNorm28 needs backward computation.
I1006 21:21:50.468523  4081 net.cpp:198] Convolution28 needs backward computation.
I1006 21:21:50.468526  4081 net.cpp:198] Eltwise12_penlu25_0_split needs backward computation.
I1006 21:21:50.468528  4081 net.cpp:198] penlu25 needs backward computation.
I1006 21:21:50.468530  4081 net.cpp:198] Eltwise12 needs backward computation.
I1006 21:21:50.468533  4081 net.cpp:198] Scale27 needs backward computation.
I1006 21:21:50.468536  4081 net.cpp:198] BatchNorm27 needs backward computation.
I1006 21:21:50.468538  4081 net.cpp:198] Convolution27 needs backward computation.
I1006 21:21:50.468540  4081 net.cpp:198] penlu24 needs backward computation.
I1006 21:21:50.468544  4081 net.cpp:198] Scale26 needs backward computation.
I1006 21:21:50.468545  4081 net.cpp:198] BatchNorm26 needs backward computation.
I1006 21:21:50.468547  4081 net.cpp:198] Convolution26 needs backward computation.
I1006 21:21:50.468550  4081 net.cpp:198] Eltwise11_penlu23_0_split needs backward computation.
I1006 21:21:50.468552  4081 net.cpp:198] penlu23 needs backward computation.
I1006 21:21:50.468554  4081 net.cpp:198] Eltwise11 needs backward computation.
I1006 21:21:50.468557  4081 net.cpp:198] Scale25 needs backward computation.
I1006 21:21:50.468559  4081 net.cpp:198] BatchNorm25 needs backward computation.
I1006 21:21:50.468562  4081 net.cpp:198] Convolution25 needs backward computation.
I1006 21:21:50.468564  4081 net.cpp:198] penlu22 needs backward computation.
I1006 21:21:50.468567  4081 net.cpp:198] Scale24 needs backward computation.
I1006 21:21:50.468569  4081 net.cpp:198] BatchNorm24 needs backward computation.
I1006 21:21:50.468572  4081 net.cpp:198] Convolution24 needs backward computation.
I1006 21:21:50.468575  4081 net.cpp:198] Scale23 needs backward computation.
I1006 21:21:50.468576  4081 net.cpp:198] BatchNorm23 needs backward computation.
I1006 21:21:50.468580  4081 net.cpp:198] Convolution23 needs backward computation.
I1006 21:21:50.468581  4081 net.cpp:198] Eltwise10_penlu21_0_split needs backward computation.
I1006 21:21:50.468585  4081 net.cpp:198] penlu21 needs backward computation.
I1006 21:21:50.468586  4081 net.cpp:198] Eltwise10 needs backward computation.
I1006 21:21:50.468590  4081 net.cpp:198] Scale22 needs backward computation.
I1006 21:21:50.468591  4081 net.cpp:198] BatchNorm22 needs backward computation.
I1006 21:21:50.468593  4081 net.cpp:198] Convolution22 needs backward computation.
I1006 21:21:50.468596  4081 net.cpp:198] penlu20 needs backward computation.
I1006 21:21:50.468598  4081 net.cpp:198] Scale21 needs backward computation.
I1006 21:21:50.468601  4081 net.cpp:198] BatchNorm21 needs backward computation.
I1006 21:21:50.468603  4081 net.cpp:198] Convolution21 needs backward computation.
I1006 21:21:50.468605  4081 net.cpp:198] Eltwise9_penlu19_0_split needs backward computation.
I1006 21:21:50.468608  4081 net.cpp:198] penlu19 needs backward computation.
I1006 21:21:50.468611  4081 net.cpp:198] Eltwise9 needs backward computation.
I1006 21:21:50.468613  4081 net.cpp:198] Scale20 needs backward computation.
I1006 21:21:50.468616  4081 net.cpp:198] BatchNorm20 needs backward computation.
I1006 21:21:50.468618  4081 net.cpp:198] Convolution20 needs backward computation.
I1006 21:21:50.468621  4081 net.cpp:198] penlu18 needs backward computation.
I1006 21:21:50.468623  4081 net.cpp:198] Scale19 needs backward computation.
I1006 21:21:50.468626  4081 net.cpp:198] BatchNorm19 needs backward computation.
I1006 21:21:50.468627  4081 net.cpp:198] Convolution19 needs backward computation.
I1006 21:21:50.468631  4081 net.cpp:198] Eltwise8_penlu17_0_split needs backward computation.
I1006 21:21:50.468632  4081 net.cpp:198] penlu17 needs backward computation.
I1006 21:21:50.468636  4081 net.cpp:198] Eltwise8 needs backward computation.
I1006 21:21:50.468638  4081 net.cpp:198] Scale18 needs backward computation.
I1006 21:21:50.468641  4081 net.cpp:198] BatchNorm18 needs backward computation.
I1006 21:21:50.468648  4081 net.cpp:198] Convolution18 needs backward computation.
I1006 21:21:50.468652  4081 net.cpp:198] penlu16 needs backward computation.
I1006 21:21:50.468654  4081 net.cpp:198] Scale17 needs backward computation.
I1006 21:21:50.468657  4081 net.cpp:198] BatchNorm17 needs backward computation.
I1006 21:21:50.468658  4081 net.cpp:198] Convolution17 needs backward computation.
I1006 21:21:50.468662  4081 net.cpp:198] Eltwise7_penlu15_0_split needs backward computation.
I1006 21:21:50.468664  4081 net.cpp:198] penlu15 needs backward computation.
I1006 21:21:50.468667  4081 net.cpp:198] Eltwise7 needs backward computation.
I1006 21:21:50.468669  4081 net.cpp:198] Scale16 needs backward computation.
I1006 21:21:50.468672  4081 net.cpp:198] BatchNorm16 needs backward computation.
I1006 21:21:50.468673  4081 net.cpp:198] Convolution16 needs backward computation.
I1006 21:21:50.468677  4081 net.cpp:198] penlu14 needs backward computation.
I1006 21:21:50.468678  4081 net.cpp:198] Scale15 needs backward computation.
I1006 21:21:50.468682  4081 net.cpp:198] BatchNorm15 needs backward computation.
I1006 21:21:50.468683  4081 net.cpp:198] Convolution15 needs backward computation.
I1006 21:21:50.468685  4081 net.cpp:198] Eltwise6_penlu13_0_split needs backward computation.
I1006 21:21:50.468688  4081 net.cpp:198] penlu13 needs backward computation.
I1006 21:21:50.468690  4081 net.cpp:198] Eltwise6 needs backward computation.
I1006 21:21:50.468693  4081 net.cpp:198] Scale14 needs backward computation.
I1006 21:21:50.468696  4081 net.cpp:198] BatchNorm14 needs backward computation.
I1006 21:21:50.468698  4081 net.cpp:198] Convolution14 needs backward computation.
I1006 21:21:50.468701  4081 net.cpp:198] penlu12 needs backward computation.
I1006 21:21:50.468703  4081 net.cpp:198] Scale13 needs backward computation.
I1006 21:21:50.468705  4081 net.cpp:198] BatchNorm13 needs backward computation.
I1006 21:21:50.468708  4081 net.cpp:198] Convolution13 needs backward computation.
I1006 21:21:50.468710  4081 net.cpp:198] Scale12 needs backward computation.
I1006 21:21:50.468713  4081 net.cpp:198] BatchNorm12 needs backward computation.
I1006 21:21:50.468715  4081 net.cpp:198] Convolution12 needs backward computation.
I1006 21:21:50.468717  4081 net.cpp:198] Eltwise5_penlu11_0_split needs backward computation.
I1006 21:21:50.468720  4081 net.cpp:198] penlu11 needs backward computation.
I1006 21:21:50.468722  4081 net.cpp:198] Eltwise5 needs backward computation.
I1006 21:21:50.468725  4081 net.cpp:198] Scale11 needs backward computation.
I1006 21:21:50.468727  4081 net.cpp:198] BatchNorm11 needs backward computation.
I1006 21:21:50.468729  4081 net.cpp:198] Convolution11 needs backward computation.
I1006 21:21:50.468731  4081 net.cpp:198] penlu10 needs backward computation.
I1006 21:21:50.468734  4081 net.cpp:198] Scale10 needs backward computation.
I1006 21:21:50.468736  4081 net.cpp:198] BatchNorm10 needs backward computation.
I1006 21:21:50.468739  4081 net.cpp:198] Convolution10 needs backward computation.
I1006 21:21:50.468740  4081 net.cpp:198] Eltwise4_penlu9_0_split needs backward computation.
I1006 21:21:50.468744  4081 net.cpp:198] penlu9 needs backward computation.
I1006 21:21:50.468745  4081 net.cpp:198] Eltwise4 needs backward computation.
I1006 21:21:50.468749  4081 net.cpp:198] Scale9 needs backward computation.
I1006 21:21:50.468750  4081 net.cpp:198] BatchNorm9 needs backward computation.
I1006 21:21:50.468752  4081 net.cpp:198] Convolution9 needs backward computation.
I1006 21:21:50.468755  4081 net.cpp:198] penlu8 needs backward computation.
I1006 21:21:50.468757  4081 net.cpp:198] Scale8 needs backward computation.
I1006 21:21:50.468760  4081 net.cpp:198] BatchNorm8 needs backward computation.
I1006 21:21:50.468762  4081 net.cpp:198] Convolution8 needs backward computation.
I1006 21:21:50.468765  4081 net.cpp:198] Eltwise3_penlu7_0_split needs backward computation.
I1006 21:21:50.468767  4081 net.cpp:198] penlu7 needs backward computation.
I1006 21:21:50.468770  4081 net.cpp:198] Eltwise3 needs backward computation.
I1006 21:21:50.468776  4081 net.cpp:198] Scale7 needs backward computation.
I1006 21:21:50.468778  4081 net.cpp:198] BatchNorm7 needs backward computation.
I1006 21:21:50.468780  4081 net.cpp:198] Convolution7 needs backward computation.
I1006 21:21:50.468783  4081 net.cpp:198] penlu6 needs backward computation.
I1006 21:21:50.468786  4081 net.cpp:198] Scale6 needs backward computation.
I1006 21:21:50.468787  4081 net.cpp:198] BatchNorm6 needs backward computation.
I1006 21:21:50.468789  4081 net.cpp:198] Convolution6 needs backward computation.
I1006 21:21:50.468792  4081 net.cpp:198] Eltwise2_penlu5_0_split needs backward computation.
I1006 21:21:50.468794  4081 net.cpp:198] penlu5 needs backward computation.
I1006 21:21:50.468796  4081 net.cpp:198] Eltwise2 needs backward computation.
I1006 21:21:50.468799  4081 net.cpp:198] Scale5 needs backward computation.
I1006 21:21:50.468801  4081 net.cpp:198] BatchNorm5 needs backward computation.
I1006 21:21:50.468804  4081 net.cpp:198] Convolution5 needs backward computation.
I1006 21:21:50.468806  4081 net.cpp:198] penlu4 needs backward computation.
I1006 21:21:50.468808  4081 net.cpp:198] Scale4 needs backward computation.
I1006 21:21:50.468811  4081 net.cpp:198] BatchNorm4 needs backward computation.
I1006 21:21:50.468812  4081 net.cpp:198] Convolution4 needs backward computation.
I1006 21:21:50.468816  4081 net.cpp:198] Eltwise1_penlu3_0_split needs backward computation.
I1006 21:21:50.468817  4081 net.cpp:198] penlu3 needs backward computation.
I1006 21:21:50.468821  4081 net.cpp:198] Eltwise1 needs backward computation.
I1006 21:21:50.468823  4081 net.cpp:198] Scale3 needs backward computation.
I1006 21:21:50.468825  4081 net.cpp:198] BatchNorm3 needs backward computation.
I1006 21:21:50.468827  4081 net.cpp:198] Convolution3 needs backward computation.
I1006 21:21:50.468830  4081 net.cpp:198] penlu2 needs backward computation.
I1006 21:21:50.468832  4081 net.cpp:198] Scale2 needs backward computation.
I1006 21:21:50.468834  4081 net.cpp:198] BatchNorm2 needs backward computation.
I1006 21:21:50.468837  4081 net.cpp:198] Convolution2 needs backward computation.
I1006 21:21:50.468839  4081 net.cpp:198] Convolution1_penlu1_0_split needs backward computation.
I1006 21:21:50.468842  4081 net.cpp:198] penlu1 needs backward computation.
I1006 21:21:50.468844  4081 net.cpp:198] Scale1 needs backward computation.
I1006 21:21:50.468847  4081 net.cpp:198] BatchNorm1 needs backward computation.
I1006 21:21:50.468849  4081 net.cpp:198] Convolution1 needs backward computation.
I1006 21:21:50.468852  4081 net.cpp:200] Data1 does not need backward computation.
I1006 21:21:50.468854  4081 net.cpp:242] This network produces output SoftmaxWithLoss1
I1006 21:21:50.468906  4081 net.cpp:255] Network initialization done.
I1006 21:21:50.471601  4081 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: /home/x306/caffe/xn/PENLU/neural/resnet/res32/res32_penlu_gauss.prototxt
I1006 21:21:50.471609  4081 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I1006 21:21:50.471614  4081 solver.cpp:172] Creating test net (#0) specified by net file: /home/x306/caffe/xn/PENLU/neural/resnet/res32/res32_penlu_gauss.prototxt
I1006 21:21:50.471729  4081 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer Data1
I1006 21:21:50.472457  4081 net.cpp:51] Initializing net from parameters: 
name: "resnet_cifar10"
state {
  phase: TEST
}
layer {
  name: "Data1"
  type: "Data"
  top: "Data1"
  top: "Data2"
  include {
    phase: TEST
  }
  transform_param {
    mean_file: "/home/x306/caffe/xn/PENLU/data/cifar10/mean.binaryproto"
  }
  data_param {
    source: "/home/x306/caffe/xn/PENLU/data/cifar10/cifar10_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "Convolution1"
  type: "Convolution"
  bottom: "Data1"
  top: "Convolution1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm1"
  type: "BatchNorm"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1"
  type: "Scale"
  bottom: "Convolution1"
  top: "Convolution1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu1"
  type: "PENLU"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution2"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm2"
  type: "BatchNorm"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale2"
  type: "Scale"
  bottom: "Convolution2"
  top: "Convolution2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu2"
  type: "PENLU"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution3"
  type: "Convolution"
  bottom: "Convolution2"
  top: "Convolution3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm3"
  type: "BatchNorm"
  bottom: "Convolution3"
  top: "Convolution3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale3"
  type: "Scale"
  bottom: "Convolution3"
  top: "Convolution3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise1"
  type: "Eltwise"
  bottom: "Convolution1"
  bottom: "Convolution3"
  top: "Eltwise1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu3"
  type: "PENLU"
  bottom: "Eltwise1"
  top: "Eltwise1"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution4"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm4"
  type: "BatchNorm"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale4"
  type: "Scale"
  bottom: "Convolution4"
  top: "Convolution4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu4"
  type: "PENLU"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution5"
  type: "Convolution"
  bottom: "Convolution4"
  top: "Convolution5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm5"
  type: "BatchNorm"
  bottom: "Convolution5"
  top: "Convolution5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale5"
  type: "Scale"
  bottom: "Convolution5"
  top: "Convolution5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise2"
  type: "Eltwise"
  bottom: "Eltwise1"
  bottom: "Convolution5"
  top: "Eltwise2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu5"
  type: "PENLU"
  bottom: "Eltwise2"
  top: "Eltwise2"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution6"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm6"
  type: "BatchNorm"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale6"
  type: "Scale"
  bottom: "Convolution6"
  top: "Convolution6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu6"
  type: "PENLU"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution7"
  type: "Convolution"
  bottom: "Convolution6"
  top: "Convolution7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm7"
  type: "BatchNorm"
  bottom: "Convolution7"
  top: "Convolution7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale7"
  type: "Scale"
  bottom: "Convolution7"
  top: "Convolution7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise3"
  type: "Eltwise"
  bottom: "Eltwise2"
  bottom: "Convolution7"
  top: "Eltwise3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu7"
  type: "PENLU"
  bottom: "Eltwise3"
  top: "Eltwise3"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution8"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm8"
  type: "BatchNorm"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale8"
  type: "Scale"
  bottom: "Convolution8"
  top: "Convolution8"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu8"
  type: "PENLU"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution9"
  type: "Convolution"
  bottom: "Convolution8"
  top: "Convolution9"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm9"
  type: "BatchNorm"
  bottom: "Convolution9"
  top: "Convolution9"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale9"
  type: "Scale"
  bottom: "Convolution9"
  top: "Convolution9"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise4"
  type: "Eltwise"
  bottom: "Eltwise3"
  bottom: "Convolution9"
  top: "Eltwise4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu9"
  type: "PENLU"
  bottom: "Eltwise4"
  top: "Eltwise4"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution10"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution10"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm10"
  type: "BatchNorm"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale10"
  type: "Scale"
  bottom: "Convolution10"
  top: "Convolution10"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu10"
  type: "PENLU"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution11"
  type: "Convolution"
  bottom: "Convolution10"
  top: "Convolution11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm11"
  type: "BatchNorm"
  bottom: "Convolution11"
  top: "Convolution11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale11"
  type: "Scale"
  bottom: "Convolution11"
  top: "Convolution11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise5"
  type: "Eltwise"
  bottom: "Eltwise4"
  bottom: "Convolution11"
  top: "Eltwise5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu11"
  type: "PENLU"
  bottom: "Eltwise5"
  top: "Eltwise5"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution12"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.25
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm12"
  type: "BatchNorm"
  bottom: "Convolution12"
  top: "Convolution12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale12"
  type: "Scale"
  bottom: "Convolution12"
  top: "Convolution12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution13"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution13"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm13"
  type: "BatchNorm"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale13"
  type: "Scale"
  bottom: "Convolution13"
  top: "Convolution13"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu12"
  type: "PENLU"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution14"
  type: "Convolution"
  bottom: "Convolution13"
  top: "Convolution14"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm14"
  type: "BatchNorm"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale14"
  type: "Scale"
  bottom: "Convolution14"
  top: "Convolution14"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise6"
  type: "Eltwise"
  bottom: "Convolution12"
  bottom: "Convolution14"
  top: "Eltwise6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu13"
  type: "PENLU"
  bottom: "Eltwise6"
  top: "Eltwise6"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution15"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution15"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm15"
  type: "BatchNorm"
  bottom: "Convolution15"
  top: "Convolution15"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale15"
  type: "Scale"
  bottom: "Convolution15"
  top: "Convolution15"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu14"
  type: "PENLU"
  bottom: "Convolution15"
  top: "Convolution15"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution16"
  type: "Convolution"
  bottom: "Convolution15"
  top: "Convolution16"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm16"
  type: "BatchNorm"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale16"
  type: "Scale"
  bottom: "Convolution16"
  top: "Convolution16"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise7"
  type: "Eltwise"
  bottom: "Eltwise6"
  bottom: "Convolution16"
  top: "Eltwise7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu15"
  type: "PENLU"
  bottom: "Eltwise7"
  top: "Eltwise7"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution17"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution17"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm17"
  type: "BatchNorm"
  bottom: "Convolution17"
  top: "Convolution17"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale17"
  type: "Scale"
  bottom: "Convolution17"
  top: "Convolution17"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu16"
  type: "PENLU"
  bottom: "Convolution17"
  top: "Convolution17"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution18"
  type: "Convolution"
  bottom: "Convolution17"
  top: "Convolution18"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm18"
  type: "BatchNorm"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale18"
  type: "Scale"
  bottom: "Convolution18"
  top: "Convolution18"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise8"
  type: "Eltwise"
  bottom: "Eltwise7"
  bottom: "Convolution18"
  top: "Eltwise8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu17"
  type: "PENLU"
  bottom: "Eltwise8"
  top: "Eltwise8"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution19"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution19"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm19"
  type: "BatchNorm"
  bottom: "Convolution19"
  top: "Convolution19"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale19"
  type: "Scale"
  bottom: "Convolution19"
  top: "Convolution19"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu18"
  type: "PENLU"
  bottom: "Convolution19"
  top: "Convolution19"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution20"
  type: "Convolution"
  bottom: "Convolution19"
  top: "Convolution20"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm20"
  type: "BatchNorm"
  bottom: "Convolution20"
  top: "Convolution20"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale20"
  type: "Scale"
  bottom: "Convolution20"
  top: "Convolution20"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise9"
  type: "Eltwise"
  bottom: "Eltwise8"
  bottom: "Convolution20"
  top: "Eltwise9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu19"
  type: "PENLU"
  bottom: "Eltwise9"
  top: "Eltwise9"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution21"
  type: "Convolution"
  bottom: "Eltwise9"
  top: "Convolution21"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm21"
  type: "BatchNorm"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale21"
  type: "Scale"
  bottom: "Convolution21"
  top: "Convolution21"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu20"
  type: "PENLU"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution22"
  type: "Convolution"
  bottom: "Convolution21"
  top: "Convolution22"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm22"
  type: "BatchNorm"
  bottom: "Convolution22"
  top: "Convolution22"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale22"
  type: "Scale"
  bottom: "Convolution22"
  top: "Convolution22"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise10"
  type: "Eltwise"
  bottom: "Eltwise9"
  bottom: "Convolution22"
  top: "Eltwise10"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu21"
  type: "PENLU"
  bottom: "Eltwise10"
  top: "Eltwise10"
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution23"
  type: "Convolution"
  bottom: "Eltwise10"
  top: "Convolution23"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.17677669
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm23"
  type: "BatchNorm"
  bottom: "Convolution23"
  top: "Convolution23"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale23"
  type: "Scale"
  bottom: "Convolution23"
  top: "Convolution23"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution24"
  type: "Convolution"
  bottom: "Eltwise10"
  top: "Convolution24"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm24"
  type: "BatchNorm"
  bottom: "Convolution24"
  top: "Convolution24"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale24"
  type: "Scale"
  bottom: "Convolution24"
  top: "Convolution24"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu22"
  type: "PENLU"
 
I1006 21:21:50.472870  4081 layer_factory.hpp:77] Creating layer Data1
I1006 21:21:50.472903  4081 db_lmdb.cpp:35] Opened lmdb /home/x306/caffe/xn/PENLU/data/cifar10/cifar10_test_lmdb
I1006 21:21:50.472921  4081 net.cpp:84] Creating Layer Data1
I1006 21:21:50.472925  4081 net.cpp:380] Data1 -> Data1
I1006 21:21:50.472931  4081 net.cpp:380] Data1 -> Data2
I1006 21:21:50.472936  4081 data_transformer.cpp:25] Loading mean file from: /home/x306/caffe/xn/PENLU/data/cifar10/mean.binaryproto
I1006 21:21:50.473053  4081 data_layer.cpp:45] output data size: 100,3,32,32
I1006 21:21:50.483573  4081 net.cpp:122] Setting up Data1
I1006 21:21:50.483602  4081 net.cpp:129] Top shape: 100 3 32 32 (307200)
I1006 21:21:50.483608  4081 net.cpp:129] Top shape: 100 (100)
I1006 21:21:50.483611  4081 net.cpp:137] Memory required for data: 1229200
I1006 21:21:50.483618  4081 layer_factory.hpp:77] Creating layer Data2_Data1_1_split
I1006 21:21:50.483631  4081 net.cpp:84] Creating Layer Data2_Data1_1_split
I1006 21:21:50.483636  4081 net.cpp:406] Data2_Data1_1_split <- Data2
I1006 21:21:50.483644  4081 net.cpp:380] Data2_Data1_1_split -> Data2_Data1_1_split_0
I1006 21:21:50.483656  4081 net.cpp:380] Data2_Data1_1_split -> Data2_Data1_1_split_1
I1006 21:21:50.483711  4081 net.cpp:122] Setting up Data2_Data1_1_split
I1006 21:21:50.483718  4081 net.cpp:129] Top shape: 100 (100)
I1006 21:21:50.483723  4081 net.cpp:129] Top shape: 100 (100)
I1006 21:21:50.483727  4081 net.cpp:137] Memory required for data: 1230000
I1006 21:21:50.483731  4081 layer_factory.hpp:77] Creating layer Convolution1
I1006 21:21:50.483747  4081 net.cpp:84] Creating Layer Convolution1
I1006 21:21:50.483752  4081 net.cpp:406] Convolution1 <- Data1
I1006 21:21:50.483758  4081 net.cpp:380] Convolution1 -> Convolution1
I1006 21:21:50.492982  4081 net.cpp:122] Setting up Convolution1
I1006 21:21:50.492996  4081 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 21:21:50.493000  4081 net.cpp:137] Memory required for data: 7783600
I1006 21:21:50.493010  4081 layer_factory.hpp:77] Creating layer BatchNorm1
I1006 21:21:50.493017  4081 net.cpp:84] Creating Layer BatchNorm1
I1006 21:21:50.493021  4081 net.cpp:406] BatchNorm1 <- Convolution1
I1006 21:21:50.493024  4081 net.cpp:367] BatchNorm1 -> Convolution1 (in-place)
I1006 21:21:50.493181  4081 net.cpp:122] Setting up BatchNorm1
I1006 21:21:50.493187  4081 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 21:21:50.493190  4081 net.cpp:137] Memory required for data: 14337200
I1006 21:21:50.493197  4081 layer_factory.hpp:77] Creating layer Scale1
I1006 21:21:50.493203  4081 net.cpp:84] Creating Layer Scale1
I1006 21:21:50.493206  4081 net.cpp:406] Scale1 <- Convolution1
I1006 21:21:50.493209  4081 net.cpp:367] Scale1 -> Convolution1 (in-place)
I1006 21:21:50.493243  4081 layer_factory.hpp:77] Creating layer Scale1
I1006 21:21:50.493327  4081 net.cpp:122] Setting up Scale1
I1006 21:21:50.493331  4081 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 21:21:50.493335  4081 net.cpp:137] Memory required for data: 20890800
I1006 21:21:50.493338  4081 layer_factory.hpp:77] Creating layer penlu1
I1006 21:21:50.493346  4081 net.cpp:84] Creating Layer penlu1
I1006 21:21:50.493351  4081 net.cpp:406] penlu1 <- Convolution1
I1006 21:21:50.493355  4081 net.cpp:367] penlu1 -> Convolution1 (in-place)
I1006 21:21:50.493481  4081 net.cpp:122] Setting up penlu1
I1006 21:21:50.493487  4081 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 21:21:50.493502  4081 net.cpp:137] Memory required for data: 27444400
I1006 21:21:50.493510  4081 layer_factory.hpp:77] Creating layer Convolution1_penlu1_0_split
I1006 21:21:50.493520  4081 net.cpp:84] Creating Layer Convolution1_penlu1_0_split
I1006 21:21:50.493521  4081 net.cpp:406] Convolution1_penlu1_0_split <- Convolution1
I1006 21:21:50.493526  4081 net.cpp:380] Convolution1_penlu1_0_split -> Convolution1_penlu1_0_split_0
I1006 21:21:50.493531  4081 net.cpp:380] Convolution1_penlu1_0_split -> Convolution1_penlu1_0_split_1
I1006 21:21:50.493559  4081 net.cpp:122] Setting up Convolution1_penlu1_0_split
I1006 21:21:50.493563  4081 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 21:21:50.493566  4081 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 21:21:50.493569  4081 net.cpp:137] Memory required for data: 40551600
I1006 21:21:50.493572  4081 layer_factory.hpp:77] Creating layer Convolution2
I1006 21:21:50.493579  4081 net.cpp:84] Creating Layer Convolution2
I1006 21:21:50.493582  4081 net.cpp:406] Convolution2 <- Convolution1_penlu1_0_split_0
I1006 21:21:50.493587  4081 net.cpp:380] Convolution2 -> Convolution2
I1006 21:21:50.497393  4081 net.cpp:122] Setting up Convolution2
I1006 21:21:50.497403  4081 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 21:21:50.497407  4081 net.cpp:137] Memory required for data: 47105200
I1006 21:21:50.497413  4081 layer_factory.hpp:77] Creating layer BatchNorm2
I1006 21:21:50.497421  4081 net.cpp:84] Creating Layer BatchNorm2
I1006 21:21:50.497423  4081 net.cpp:406] BatchNorm2 <- Convolution2
I1006 21:21:50.497428  4081 net.cpp:367] BatchNorm2 -> Convolution2 (in-place)
I1006 21:21:50.499706  4081 net.cpp:122] Setting up BatchNorm2
I1006 21:21:50.499714  4081 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 21:21:50.499717  4081 net.cpp:137] Memory required for data: 53658800
I1006 21:21:50.499722  4081 layer_factory.hpp:77] Creating layer Scale2
I1006 21:21:50.499728  4081 net.cpp:84] Creating Layer Scale2
I1006 21:21:50.499730  4081 net.cpp:406] Scale2 <- Convolution2
I1006 21:21:50.499734  4081 net.cpp:367] Scale2 -> Convolution2 (in-place)
I1006 21:21:50.499768  4081 layer_factory.hpp:77] Creating layer Scale2
I1006 21:21:50.499853  4081 net.cpp:122] Setting up Scale2
I1006 21:21:50.499858  4081 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 21:21:50.499861  4081 net.cpp:137] Memory required for data: 60212400
I1006 21:21:50.499866  4081 layer_factory.hpp:77] Creating layer penlu2
I1006 21:21:50.499873  4081 net.cpp:84] Creating Layer penlu2
I1006 21:21:50.499876  4081 net.cpp:406] penlu2 <- Convolution2
I1006 21:21:50.499881  4081 net.cpp:367] penlu2 -> Convolution2 (in-place)
I1006 21:21:50.500008  4081 net.cpp:122] Setting up penlu2
I1006 21:21:50.500013  4081 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 21:21:50.500015  4081 net.cpp:137] Memory required for data: 66766000
I1006 21:21:50.500022  4081 layer_factory.hpp:77] Creating layer Convolution3
I1006 21:21:50.500030  4081 net.cpp:84] Creating Layer Convolution3
I1006 21:21:50.500036  4081 net.cpp:406] Convolution3 <- Convolution2
I1006 21:21:50.500041  4081 net.cpp:380] Convolution3 -> Convolution3
I1006 21:21:50.503926  4081 net.cpp:122] Setting up Convolution3
I1006 21:21:50.503935  4081 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 21:21:50.503938  4081 net.cpp:137] Memory required for data: 73319600
I1006 21:21:50.503943  4081 layer_factory.hpp:77] Creating layer BatchNorm3
I1006 21:21:50.503948  4081 net.cpp:84] Creating Layer BatchNorm3
I1006 21:21:50.503950  4081 net.cpp:406] BatchNorm3 <- Convolution3
I1006 21:21:50.503955  4081 net.cpp:367] BatchNorm3 -> Convolution3 (in-place)
I1006 21:21:50.504101  4081 net.cpp:122] Setting up BatchNorm3
I1006 21:21:50.504106  4081 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 21:21:50.504107  4081 net.cpp:137] Memory required for data: 79873200
I1006 21:21:50.504112  4081 layer_factory.hpp:77] Creating layer Scale3
I1006 21:21:50.504117  4081 net.cpp:84] Creating Layer Scale3
I1006 21:21:50.504128  4081 net.cpp:406] Scale3 <- Convolution3
I1006 21:21:50.504132  4081 net.cpp:367] Scale3 -> Convolution3 (in-place)
I1006 21:21:50.504163  4081 layer_factory.hpp:77] Creating layer Scale3
I1006 21:21:50.504243  4081 net.cpp:122] Setting up Scale3
I1006 21:21:50.504248  4081 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 21:21:50.504251  4081 net.cpp:137] Memory required for data: 86426800
I1006 21:21:50.504254  4081 layer_factory.hpp:77] Creating layer Eltwise1
I1006 21:21:50.504259  4081 net.cpp:84] Creating Layer Eltwise1
I1006 21:21:50.504262  4081 net.cpp:406] Eltwise1 <- Convolution1_penlu1_0_split_1
I1006 21:21:50.504266  4081 net.cpp:406] Eltwise1 <- Convolution3
I1006 21:21:50.504271  4081 net.cpp:380] Eltwise1 -> Eltwise1
I1006 21:21:50.504288  4081 net.cpp:122] Setting up Eltwise1
I1006 21:21:50.504292  4081 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 21:21:50.504294  4081 net.cpp:137] Memory required for data: 92980400
I1006 21:21:50.504297  4081 layer_factory.hpp:77] Creating layer penlu3
I1006 21:21:50.504302  4081 net.cpp:84] Creating Layer penlu3
I1006 21:21:50.504305  4081 net.cpp:406] penlu3 <- Eltwise1
I1006 21:21:50.504308  4081 net.cpp:367] penlu3 -> Eltwise1 (in-place)
I1006 21:21:50.504433  4081 net.cpp:122] Setting up penlu3
I1006 21:21:50.504438  4081 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 21:21:50.504441  4081 net.cpp:137] Memory required for data: 99534000
I1006 21:21:50.504444  4081 layer_factory.hpp:77] Creating layer Eltwise1_penlu3_0_split
I1006 21:21:50.504451  4081 net.cpp:84] Creating Layer Eltwise1_penlu3_0_split
I1006 21:21:50.504452  4081 net.cpp:406] Eltwise1_penlu3_0_split <- Eltwise1
I1006 21:21:50.504456  4081 net.cpp:380] Eltwise1_penlu3_0_split -> Eltwise1_penlu3_0_split_0
I1006 21:21:50.504461  4081 net.cpp:380] Eltwise1_penlu3_0_split -> Eltwise1_penlu3_0_split_1
I1006 21:21:50.504487  4081 net.cpp:122] Setting up Eltwise1_penlu3_0_split
I1006 21:21:50.504490  4081 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 21:21:50.504493  4081 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 21:21:50.504495  4081 net.cpp:137] Memory required for data: 112641200
I1006 21:21:50.504498  4081 layer_factory.hpp:77] Creating layer Convolution4
I1006 21:21:50.504504  4081 net.cpp:84] Creating Layer Convolution4
I1006 21:21:50.504506  4081 net.cpp:406] Convolution4 <- Eltwise1_penlu3_0_split_0
I1006 21:21:50.504511  4081 net.cpp:380] Convolution4 -> Convolution4
I1006 21:21:50.509104  4081 net.cpp:122] Setting up Convolution4
I1006 21:21:50.509114  4081 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 21:21:50.509115  4081 net.cpp:137] Memory required for data: 119194800
I1006 21:21:50.509120  4081 layer_factory.hpp:77] Creating layer BatchNorm4
I1006 21:21:50.509125  4081 net.cpp:84] Creating Layer BatchNorm4
I1006 21:21:50.509129  4081 net.cpp:406] BatchNorm4 <- Convolution4
I1006 21:21:50.509132  4081 net.cpp:367] BatchNorm4 -> Convolution4 (in-place)
I1006 21:21:50.509276  4081 net.cpp:122] Setting up BatchNorm4
I1006 21:21:50.509281  4081 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 21:21:50.509284  4081 net.cpp:137] Memory required for data: 125748400
I1006 21:21:50.509292  4081 layer_factory.hpp:77] Creating layer Scale4
I1006 21:21:50.509296  4081 net.cpp:84] Creating Layer Scale4
I1006 21:21:50.509299  4081 net.cpp:406] Scale4 <- Convolution4
I1006 21:21:50.509302  4081 net.cpp:367] Scale4 -> Convolution4 (in-place)
I1006 21:21:50.509332  4081 layer_factory.hpp:77] Creating layer Scale4
I1006 21:21:50.509413  4081 net.cpp:122] Setting up Scale4
I1006 21:21:50.509418  4081 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 21:21:50.509419  4081 net.cpp:137] Memory required for data: 132302000
I1006 21:21:50.509423  4081 layer_factory.hpp:77] Creating layer penlu4
I1006 21:21:50.509429  4081 net.cpp:84] Creating Layer penlu4
I1006 21:21:50.509431  4081 net.cpp:406] penlu4 <- Convolution4
I1006 21:21:50.509436  4081 net.cpp:367] penlu4 -> Convolution4 (in-place)
I1006 21:21:50.509562  4081 net.cpp:122] Setting up penlu4
I1006 21:21:50.509577  4081 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 21:21:50.509578  4081 net.cpp:137] Memory required for data: 138855600
I1006 21:21:50.509583  4081 layer_factory.hpp:77] Creating layer Convolution5
I1006 21:21:50.509590  4081 net.cpp:84] Creating Layer Convolution5
I1006 21:21:50.509593  4081 net.cpp:406] Convolution5 <- Convolution4
I1006 21:21:50.509598  4081 net.cpp:380] Convolution5 -> Convolution5
I1006 21:21:50.510576  4081 net.cpp:122] Setting up Convolution5
I1006 21:21:50.510584  4081 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 21:21:50.510587  4081 net.cpp:137] Memory required for data: 145409200
I1006 21:21:50.510592  4081 layer_factory.hpp:77] Creating layer BatchNorm5
I1006 21:21:50.510597  4081 net.cpp:84] Creating Layer BatchNorm5
I1006 21:21:50.510601  4081 net.cpp:406] BatchNorm5 <- Convolution5
I1006 21:21:50.510604  4081 net.cpp:367] BatchNorm5 -> Convolution5 (in-place)
I1006 21:21:50.510756  4081 net.cpp:122] Setting up BatchNorm5
I1006 21:21:50.510761  4081 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 21:21:50.510763  4081 net.cpp:137] Memory required for data: 151962800
I1006 21:21:50.510768  4081 layer_factory.hpp:77] Creating layer Scale5
I1006 21:21:50.510772  4081 net.cpp:84] Creating Layer Scale5
I1006 21:21:50.510776  4081 net.cpp:406] Scale5 <- Convolution5
I1006 21:21:50.510779  4081 net.cpp:367] Scale5 -> Convolution5 (in-place)
I1006 21:21:50.510810  4081 layer_factory.hpp:77] Creating layer Scale5
I1006 21:21:50.510895  4081 net.cpp:122] Setting up Scale5
I1006 21:21:50.510900  4081 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 21:21:50.510902  4081 net.cpp:137] Memory required for data: 158516400
I1006 21:21:50.510906  4081 layer_factory.hpp:77] Creating layer Eltwise2
I1006 21:21:50.510910  4081 net.cpp:84] Creating Layer Eltwise2
I1006 21:21:50.510913  4081 net.cpp:406] Eltwise2 <- Eltwise1_penlu3_0_split_1
I1006 21:21:50.510916  4081 net.cpp:406] Eltwise2 <- Convolution5
I1006 21:21:50.510920  4081 net.cpp:380] Eltwise2 -> Eltwise2
I1006 21:21:50.510937  4081 net.cpp:122] Setting up Eltwise2
I1006 21:21:50.510941  4081 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 21:21:50.510943  4081 net.cpp:137] Memory required for data: 165070000
I1006 21:21:50.510946  4081 layer_factory.hpp:77] Creating layer penlu5
I1006 21:21:50.510951  4081 net.cpp:84] Creating Layer penlu5
I1006 21:21:50.510954  4081 net.cpp:406] penlu5 <- Eltwise2
I1006 21:21:50.510958  4081 net.cpp:367] penlu5 -> Eltwise2 (in-place)
I1006 21:21:50.511090  4081 net.cpp:122] Setting up penlu5
I1006 21:21:50.511093  4081 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 21:21:50.511096  4081 net.cpp:137] Memory required for data: 171623600
I1006 21:21:50.511101  4081 layer_factory.hpp:77] Creating layer Eltwise2_penlu5_0_split
I1006 21:21:50.511106  4081 net.cpp:84] Creating Layer Eltwise2_penlu5_0_split
I1006 21:21:50.511107  4081 net.cpp:406] Eltwise2_penlu5_0_split <- Eltwise2
I1006 21:21:50.511111  4081 net.cpp:380] Eltwise2_penlu5_0_split -> Eltwise2_penlu5_0_split_0
I1006 21:21:50.511116  4081 net.cpp:380] Eltwise2_penlu5_0_split -> Eltwise2_penlu5_0_split_1
I1006 21:21:50.511144  4081 net.cpp:122] Setting up Eltwise2_penlu5_0_split
I1006 21:21:50.511148  4081 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 21:21:50.511152  4081 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 21:21:50.511153  4081 net.cpp:137] Memory required for data: 184730800
I1006 21:21:50.511157  4081 layer_factory.hpp:77] Creating layer Convolution6
I1006 21:21:50.511162  4081 net.cpp:84] Creating Layer Convolution6
I1006 21:21:50.511169  4081 net.cpp:406] Convolution6 <- Eltwise2_penlu5_0_split_0
I1006 21:21:50.511175  4081 net.cpp:380] Convolution6 -> Convolution6
I1006 21:21:50.515168  4081 net.cpp:122] Setting up Convolution6
I1006 21:21:50.515178  4081 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 21:21:50.515182  4081 net.cpp:137] Memory required for data: 191284400
I1006 21:21:50.515187  4081 layer_factory.hpp:77] Creating layer BatchNorm6
I1006 21:21:50.515199  4081 net.cpp:84] Creating Layer BatchNorm6
I1006 21:21:50.515203  4081 net.cpp:406] BatchNorm6 <- Convolution6
I1006 21:21:50.515206  4081 net.cpp:367] BatchNorm6 -> Convolution6 (in-place)
I1006 21:21:50.515359  4081 net.cpp:122] Setting up BatchNorm6
I1006 21:21:50.515364  4081 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 21:21:50.515367  4081 net.cpp:137] Memory required for data: 197838000
I1006 21:21:50.515372  4081 layer_factory.hpp:77] Creating layer Scale6
I1006 21:21:50.515375  4081 net.cpp:84] Creating Layer Scale6
I1006 21:21:50.515378  4081 net.cpp:406] Scale6 <- Convolution6
I1006 21:21:50.515381  4081 net.cpp:367] Scale6 -> Convolution6 (in-place)
I1006 21:21:50.515413  4081 layer_factory.hpp:77] Creating layer Scale6
I1006 21:21:50.515497  4081 net.cpp:122] Setting up Scale6
I1006 21:21:50.515502  4081 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 21:21:50.515504  4081 net.cpp:137] Memory required for data: 204391600
I1006 21:21:50.515508  4081 layer_factory.hpp:77] Creating layer penlu6
I1006 21:21:50.515516  4081 net.cpp:84] Creating Layer penlu6
I1006 21:21:50.515518  4081 net.cpp:406] penlu6 <- Convolution6
I1006 21:21:50.515522  4081 net.cpp:367] penlu6 -> Convolution6 (in-place)
I1006 21:21:50.515674  4081 net.cpp:122] Setting up penlu6
I1006 21:21:50.515679  4081 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 21:21:50.515681  4081 net.cpp:137] Memory required for data: 210945200
I1006 21:21:50.515686  4081 layer_factory.hpp:77] Creating layer Convolution7
I1006 21:21:50.515693  4081 net.cpp:84] Creating Layer Convolution7
I1006 21:21:50.515696  4081 net.cpp:406] Convolution7 <- Convolution6
I1006 21:21:50.515699  4081 net.cpp:380] Convolution7 -> Convolution7
I1006 21:21:50.522528  4081 net.cpp:122] Setting up Convolution7
I1006 21:21:50.522537  4081 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 21:21:50.522539  4081 net.cpp:137] Memory required for data: 217498800
I1006 21:21:50.522544  4081 layer_factory.hpp:77] Creating layer BatchNorm7
I1006 21:21:50.522552  4081 net.cpp:84] Creating Layer BatchNorm7
I1006 21:21:50.522554  4081 net.cpp:406] BatchNorm7 <- Convolution7
I1006 21:21:50.522558  4081 net.cpp:367] BatchNorm7 -> Convolution7 (in-place)
I1006 21:21:50.522701  4081 net.cpp:122] Setting up BatchNorm7
I1006 21:21:50.522706  4081 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 21:21:50.522708  4081 net.cpp:137] Memory required for data: 224052400
I1006 21:21:50.522718  4081 layer_factory.hpp:77] Creating layer Scale7
I1006 21:21:50.522723  4081 net.cpp:84] Creating Layer Scale7
I1006 21:21:50.522725  4081 net.cpp:406] Scale7 <- Convolution7
I1006 21:21:50.522729  4081 net.cpp:367] Scale7 -> Convolution7 (in-place)
I1006 21:21:50.522760  4081 layer_factory.hpp:77] Creating layer Scale7
I1006 21:21:50.522840  4081 net.cpp:122] Setting up Scale7
I1006 21:21:50.522845  4081 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 21:21:50.522847  4081 net.cpp:137] Memory required for data: 230606000
I1006 21:21:50.522851  4081 layer_factory.hpp:77] Creating layer Eltwise3
I1006 21:21:50.522855  4081 net.cpp:84] Creating Layer Eltwise3
I1006 21:21:50.522857  4081 net.cpp:406] Eltwise3 <- Eltwise2_penlu5_0_split_1
I1006 21:21:50.522861  4081 net.cpp:406] Eltwise3 <- Convolution7
I1006 21:21:50.522863  4081 net.cpp:380] Eltwise3 -> Eltwise3
I1006 21:21:50.522881  4081 net.cpp:122] Setting up Eltwise3
I1006 21:21:50.522884  4081 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 21:21:50.522886  4081 net.cpp:137] Memory required for data: 237159600
I1006 21:21:50.522889  4081 layer_factory.hpp:77] Creating layer penlu7
I1006 21:21:50.522893  4081 net.cpp:84] Creating Layer penlu7
I1006 21:21:50.522897  4081 net.cpp:406] penlu7 <- Eltwise3
I1006 21:21:50.522900  4081 net.cpp:367] penlu7 -> Eltwise3 (in-place)
I1006 21:21:50.523025  4081 net.cpp:122] Setting up penlu7
I1006 21:21:50.523030  4081 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 21:21:50.523031  4081 net.cpp:137] Memory required for data: 243713200
I1006 21:21:50.523036  4081 layer_factory.hpp:77] Creating layer Eltwise3_penlu7_0_split
I1006 21:21:50.523047  4081 net.cpp:84] Creating Layer Eltwise3_penlu7_0_split
I1006 21:21:50.523051  4081 net.cpp:406] Eltwise3_penlu7_0_split <- Eltwise3
I1006 21:21:50.523053  4081 net.cpp:380] Eltwise3_penlu7_0_split -> Eltwise3_penlu7_0_split_0
I1006 21:21:50.523057  4081 net.cpp:380] Eltwise3_penlu7_0_split -> Eltwise3_penlu7_0_split_1
I1006 21:21:50.523083  4081 net.cpp:122] Setting up Eltwise3_penlu7_0_split
I1006 21:21:50.523087  4081 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 21:21:50.523090  4081 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 21:21:50.523092  4081 net.cpp:137] Memory required for data: 256820400
I1006 21:21:50.523094  4081 layer_factory.hpp:77] Creating layer Convolution8
I1006 21:21:50.523100  4081 net.cpp:84] Creating Layer Convolution8
I1006 21:21:50.523103  4081 net.cpp:406] Convolution8 <- Eltwise3_penlu7_0_split_0
I1006 21:21:50.523108  4081 net.cpp:380] Convolution8 -> Convolution8
I1006 21:21:50.529110  4081 net.cpp:122] Setting up Convolution8
I1006 21:21:50.529119  4081 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 21:21:50.529121  4081 net.cpp:137] Memory required for data: 263374000
I1006 21:21:50.529126  4081 layer_factory.hpp:77] Creating layer BatchNorm8
I1006 21:21:50.529131  4081 net.cpp:84] Creating Layer BatchNorm8
I1006 21:21:50.529134  4081 net.cpp:406] BatchNorm8 <- Convolution8
I1006 21:21:50.529139  4081 net.cpp:367] BatchNorm8 -> Convolution8 (in-place)
I1006 21:21:50.529280  4081 net.cpp:122] Setting up BatchNorm8
I1006 21:21:50.529284  4081 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 21:21:50.529286  4081 net.cpp:137] Memory required for data: 269927600
I1006 21:21:50.529291  4081 layer_factory.hpp:77] Creating layer Scale8
I1006 21:21:50.529297  4081 net.cpp:84] Creating Layer Scale8
I1006 21:21:50.529300  4081 net.cpp:406] Scale8 <- Convolution8
I1006 21:21:50.529304  4081 net.cpp:367] Scale8 -> Convolution8 (in-place)
I1006 21:21:50.529333  4081 layer_factory.hpp:77] Creating layer Scale8
I1006 21:21:50.529414  4081 net.cpp:122] Setting up Scale8
I1006 21:21:50.529418  4081 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 21:21:50.529420  4081 net.cpp:137] Memory required for data: 276481200
I1006 21:21:50.529424  4081 layer_factory.hpp:77] Creating layer penlu8
I1006 21:21:50.529429  4081 net.cpp:84] Creating Layer penlu8
I1006 21:21:50.529431  4081 net.cpp:406] penlu8 <- Convolution8
I1006 21:21:50.529435  4081 net.cpp:367] penlu8 -> Convolution8 (in-place)
I1006 21:21:50.529556  4081 net.cpp:122] Setting up penlu8
I1006 21:21:50.529561  4081 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 21:21:50.529562  4081 net.cpp:137] Memory required for data: 283034800
I1006 21:21:50.529567  4081 layer_factory.hpp:77] Creating layer Convolution9
I1006 21:21:50.529573  4081 net.cpp:84] Creating Layer Convolution9
I1006 21:21:50.529577  4081 net.cpp:406] Convolution9 <- Convolution8
I1006 21:21:50.529580  4081 net.cpp:380] Convolution9 -> Convolution9
I1006 21:21:50.532203  4081 net.cpp:122] Setting up Convolution9
I1006 21:21:50.532212  4081 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 21:21:50.532214  4081 net.cpp:137] Memory required for data: 289588400
I1006 21:21:50.532219  4081 layer_factory.hpp:77] Creating layer BatchNorm9
I1006 21:21:50.532224  4081 net.cpp:84] Creating Layer BatchNorm9
I1006 21:21:50.532227  4081 net.cpp:406] BatchNorm9 <- Convolution9
I1006 21:21:50.532232  4081 net.cpp:367] BatchNorm9 -> Convolution9 (in-place)
I1006 21:21:50.532373  4081 net.cpp:122] Setting up BatchNorm9
I1006 21:21:50.532377  4081 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 21:21:50.532379  4081 net.cpp:137] Memory required for data: 296142000
I1006 21:21:50.532384  4081 layer_factory.hpp:77] Creating layer Scale9
I1006 21:21:50.532388  4081 net.cpp:84] Creating Layer Scale9
I1006 21:21:50.532390  4081 net.cpp:406] Scale9 <- Convolution9
I1006 21:21:50.532394  4081 net.cpp:367] Scale9 -> Convolution9 (in-place)
I1006 21:21:50.532424  4081 layer_factory.hpp:77] Creating layer Scale9
I1006 21:21:50.532512  4081 net.cpp:122] Setting up Scale9
I1006 21:21:50.532517  4081 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 21:21:50.532519  4081 net.cpp:137] Memory required for data: 302695600
I1006 21:21:50.532523  4081 layer_factory.hpp:77] Creating layer Eltwise4
I1006 21:21:50.532527  4081 net.cpp:84] Creating Layer Eltwise4
I1006 21:21:50.532531  4081 net.cpp:406] Eltwise4 <- Eltwise3_penlu7_0_split_1
I1006 21:21:50.532533  4081 net.cpp:406] Eltwise4 <- Convolution9
I1006 21:21:50.532536  4081 net.cpp:380] Eltwise4 -> Eltwise4
I1006 21:21:50.532553  4081 net.cpp:122] Setting up Eltwise4
I1006 21:21:50.532557  4081 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 21:21:50.532559  4081 net.cpp:137] Memory required for data: 309249200
I1006 21:21:50.532562  4081 layer_factory.hpp:77] Creating layer penlu9
I1006 21:21:50.532567  4081 net.cpp:84] Creating Layer penlu9
I1006 21:21:50.532569  4081 net.cpp:406] penlu9 <- Eltwise4
I1006 21:21:50.532572  4081 net.cpp:367] penlu9 -> Eltwise4 (in-place)
I1006 21:21:50.532699  4081 net.cpp:122] Setting up penlu9
I1006 21:21:50.532703  4081 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 21:21:50.532706  4081 net.cpp:137] Memory required for data: 315802800
I1006 21:21:50.532711  4081 layer_factory.hpp:77] Creating layer Eltwise4_penlu9_0_split
I1006 21:21:50.532713  4081 net.cpp:84] Creating Layer Eltwise4_penlu9_0_split
I1006 21:21:50.532716  4081 net.cpp:406] Eltwise4_penlu9_0_split <- Eltwise4
I1006 21:21:50.532719  4081 net.cpp:380] Eltwise4_penlu9_0_split -> Eltwise4_penlu9_0_split_0
I1006 21:21:50.532722  4081 net.cpp:380] Eltwise4_penlu9_0_split -> Eltwise4_penlu9_0_split_1
I1006 21:21:50.532748  4081 net.cpp:122] Setting up Eltwise4_penlu9_0_split
I1006 21:21:50.532752  4081 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 21:21:50.532754  4081 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 21:21:50.532757  4081 net.cpp:137] Memory required for data: 328910000
I1006 21:21:50.532758  4081 layer_factory.hpp:77] Creating layer Convolution10
I1006 21:21:50.532764  4081 net.cpp:84] Creating Layer Convolution10
I1006 21:21:50.532766  4081 net.cpp:406] Convolution10 <- Eltwise4_penlu9_0_split_0
I1006 21:21:50.532771  4081 net.cpp:380] Convolution10 -> Convolution10
I1006 21:21:50.538561  4081 net.cpp:122] Setting up Convolution10
I1006 21:21:50.538569  4081 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 21:21:50.538571  4081 net.cpp:137] Memory required for data: 335463600
I1006 21:21:50.538575  4081 layer_factory.hpp:77] Creating layer BatchNorm10
I1006 21:21:50.538579  4081 net.cpp:84] Creating Layer BatchNorm10
I1006 21:21:50.538583  4081 net.cpp:406] BatchNorm10 <- Convolution10
I1006 21:21:50.538586  4081 net.cpp:367] BatchNorm10 -> Convolution10 (in-place)
I1006 21:21:50.538728  4081 net.cpp:122] Setting up BatchNorm10
I1006 21:21:50.538733  4081 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 21:21:50.538735  4081 net.cpp:137] Memory required for data: 342017200
I1006 21:21:50.538739  4081 layer_factory.hpp:77] Creating layer Scale10
I1006 21:21:50.538744  4081 net.cpp:84] Creating Layer Scale10
I1006 21:21:50.538746  4081 net.cpp:406] Scale10 <- Convolution10
I1006 21:21:50.538750  4081 net.cpp:367] Scale10 -> Convolution10 (in-place)
I1006 21:21:50.538779  4081 layer_factory.hpp:77] Creating layer Scale10
I1006 21:21:50.538857  4081 net.cpp:122] Setting up Scale10
I1006 21:21:50.538861  4081 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 21:21:50.538863  4081 net.cpp:137] Memory required for data: 348570800
I1006 21:21:50.538867  4081 layer_factory.hpp:77] Creating layer penlu10
I1006 21:21:50.538873  4081 net.cpp:84] Creating Layer penlu10
I1006 21:21:50.538875  4081 net.cpp:406] penlu10 <- Convolution10
I1006 21:21:50.538879  4081 net.cpp:367] penlu10 -> Convolution10 (in-place)
I1006 21:21:50.539005  4081 net.cpp:122] Setting up penlu10
I1006 21:21:50.539010  4081 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 21:21:50.539011  4081 net.cpp:137] Memory required for data: 355124400
I1006 21:21:50.539022  4081 layer_factory.hpp:77] Creating layer Convolution11
I1006 21:21:50.539029  4081 net.cpp:84] Creating Layer Convolution11
I1006 21:21:50.539032  4081 net.cpp:406] Convolution11 <- Convolution10
I1006 21:21:50.539036  4081 net.cpp:380] Convolution11 -> Convolution11
I1006 21:21:50.545115  4081 net.cpp:122] Setting up Convolution11
I1006 21:21:50.545125  4081 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 21:21:50.545128  4081 net.cpp:137] Memory required for data: 361678000
I1006 21:21:50.545132  4081 layer_factory.hpp:77] Creating layer BatchNorm11
I1006 21:21:50.545138  4081 net.cpp:84] Creating Layer BatchNorm11
I1006 21:21:50.545141  4081 net.cpp:406] BatchNorm11 <- Convolution11
I1006 21:21:50.545146  4081 net.cpp:367] BatchNorm11 -> Convolution11 (in-place)
I1006 21:21:50.545297  4081 net.cpp:122] Setting up BatchNorm11
I1006 21:21:50.545302  4081 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 21:21:50.545305  4081 net.cpp:137] Memory required for data: 368231600
I1006 21:21:50.545310  4081 layer_factory.hpp:77] Creating layer Scale11
I1006 21:21:50.545315  4081 net.cpp:84] Creating Layer Scale11
I1006 21:21:50.545317  4081 net.cpp:406] Scale11 <- Convolution11
I1006 21:21:50.545320  4081 net.cpp:367] Scale11 -> Convolution11 (in-place)
I1006 21:21:50.545351  4081 layer_factory.hpp:77] Creating layer Scale11
I1006 21:21:50.545435  4081 net.cpp:122] Setting up Scale11
I1006 21:21:50.545440  4081 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 21:21:50.545444  4081 net.cpp:137] Memory required for data: 374785200
I1006 21:21:50.545447  4081 layer_factory.hpp:77] Creating layer Eltwise5
I1006 21:21:50.545451  4081 net.cpp:84] Creating Layer Eltwise5
I1006 21:21:50.545454  4081 net.cpp:406] Eltwise5 <- Eltwise4_penlu9_0_split_1
I1006 21:21:50.545457  4081 net.cpp:406] Eltwise5 <- Convolution11
I1006 21:21:50.545461  4081 net.cpp:380] Eltwise5 -> Eltwise5
I1006 21:21:50.545478  4081 net.cpp:122] Setting up Eltwise5
I1006 21:21:50.545483  4081 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 21:21:50.545485  4081 net.cpp:137] Memory required for data: 381338800
I1006 21:21:50.545487  4081 layer_factory.hpp:77] Creating layer penlu11
I1006 21:21:50.545493  4081 net.cpp:84] Creating Layer penlu11
I1006 21:21:50.545495  4081 net.cpp:406] penlu11 <- Eltwise5
I1006 21:21:50.545500  4081 net.cpp:367] penlu11 -> Eltwise5 (in-place)
I1006 21:21:50.545630  4081 net.cpp:122] Setting up penlu11
I1006 21:21:50.545634  4081 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 21:21:50.545636  4081 net.cpp:137] Memory required for data: 387892400
I1006 21:21:50.545641  4081 layer_factory.hpp:77] Creating layer Eltwise5_penlu11_0_split
I1006 21:21:50.545645  4081 net.cpp:84] Creating Layer Eltwise5_penlu11_0_split
I1006 21:21:50.545647  4081 net.cpp:406] Eltwise5_penlu11_0_split <- Eltwise5
I1006 21:21:50.545651  4081 net.cpp:380] Eltwise5_penlu11_0_split -> Eltwise5_penlu11_0_split_0
I1006 21:21:50.545655  4081 net.cpp:380] Eltwise5_penlu11_0_split -> Eltwise5_penlu11_0_split_1
I1006 21:21:50.545682  4081 net.cpp:122] Setting up Eltwise5_penlu11_0_split
I1006 21:21:50.545686  4081 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 21:21:50.545689  4081 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1006 21:21:50.545691  4081 net.cpp:137] Memory required for data: 400999600
I1006 21:21:50.545693  4081 layer_factory.hpp:77] Creating layer Convolution12
I1006 21:21:50.545701  4081 net.cpp:84] Creating Layer Convolution12
I1006 21:21:50.545702  4081 net.cpp:406] Convolution12 <- Eltwise5_penlu11_0_split_0
I1006 21:21:50.545706  4081 net.cpp:380] Convolution12 -> Convolution12
I1006 21:21:50.552139  4081 net.cpp:122] Setting up Convolution12
I1006 21:21:50.552148  4081 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 21:21:50.552151  4081 net.cpp:137] Memory required for data: 404276400
I1006 21:21:50.552155  4081 layer_factory.hpp:77] Creating layer BatchNorm12
I1006 21:21:50.552160  4081 net.cpp:84] Creating Layer BatchNorm12
I1006 21:21:50.552163  4081 net.cpp:406] BatchNorm12 <- Convolution12
I1006 21:21:50.552175  4081 net.cpp:367] BatchNorm12 -> Convolution12 (in-place)
I1006 21:21:50.552322  4081 net.cpp:122] Setting up BatchNorm12
I1006 21:21:50.552327  4081 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 21:21:50.552330  4081 net.cpp:137] Memory required for data: 407553200
I1006 21:21:50.552333  4081 layer_factory.hpp:77] Creating layer Scale12
I1006 21:21:50.552337  4081 net.cpp:84] Creating Layer Scale12
I1006 21:21:50.552340  4081 net.cpp:406] Scale12 <- Convolution12
I1006 21:21:50.552343  4081 net.cpp:367] Scale12 -> Convolution12 (in-place)
I1006 21:21:50.552373  4081 layer_factory.hpp:77] Creating layer Scale12
I1006 21:21:50.552454  4081 net.cpp:122] Setting up Scale12
I1006 21:21:50.552459  4081 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 21:21:50.552461  4081 net.cpp:137] Memory required for data: 410830000
I1006 21:21:50.552465  4081 layer_factory.hpp:77] Creating layer Convolution13
I1006 21:21:50.552471  4081 net.cpp:84] Creating Layer Convolution13
I1006 21:21:50.552474  4081 net.cpp:406] Convolution13 <- Eltwise5_penlu11_0_split_1
I1006 21:21:50.552479  4081 net.cpp:380] Convolution13 -> Convolution13
I1006 21:21:50.558718  4081 net.cpp:122] Setting up Convolution13
I1006 21:21:50.558728  4081 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 21:21:50.558732  4081 net.cpp:137] Memory required for data: 414106800
I1006 21:21:50.558735  4081 layer_factory.hpp:77] Creating layer BatchNorm13
I1006 21:21:50.558739  4081 net.cpp:84] Creating Layer BatchNorm13
I1006 21:21:50.558743  4081 net.cpp:406] BatchNorm13 <- Convolution13
I1006 21:21:50.558748  4081 net.cpp:367] BatchNorm13 -> Convolution13 (in-place)
I1006 21:21:50.558888  4081 net.cpp:122] Setting up BatchNorm13
I1006 21:21:50.558892  4081 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 21:21:50.558894  4081 net.cpp:137] Memory required for data: 417383600
I1006 21:21:50.558899  4081 layer_factory.hpp:77] Creating layer Scale13
I1006 21:21:50.558903  4081 net.cpp:84] Creating Layer Scale13
I1006 21:21:50.558905  4081 net.cpp:406] Scale13 <- Convolution13
I1006 21:21:50.558909  4081 net.cpp:367] Scale13 -> Convolution13 (in-place)
I1006 21:21:50.558938  4081 layer_factory.hpp:77] Creating layer Scale13
I1006 21:21:50.559017  4081 net.cpp:122] Setting up Scale13
I1006 21:21:50.559022  4081 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 21:21:50.559025  4081 net.cpp:137] Memory required for data: 420660400
I1006 21:21:50.559027  4081 layer_factory.hpp:77] Creating layer penlu12
I1006 21:21:50.559033  4081 net.cpp:84] Creating Layer penlu12
I1006 21:21:50.559036  4081 net.cpp:406] penlu12 <- Convolution13
I1006 21:21:50.559039  4081 net.cpp:367] penlu12 -> Convolution13 (in-place)
I1006 21:21:50.559154  4081 net.cpp:122] Setting up penlu12
I1006 21:21:50.559159  4081 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 21:21:50.559161  4081 net.cpp:137] Memory required for data: 423937200
I1006 21:21:50.559180  4081 layer_factory.hpp:77] Creating layer Convolution14
I1006 21:21:50.559191  4081 net.cpp:84] Creating Layer Convolution14
I1006 21:21:50.559195  4081 net.cpp:406] Convolution14 <- Convolution13
I1006 21:21:50.559208  4081 net.cpp:380] Convolution14 -> Convolution14
I1006 21:21:50.565325  4081 net.cpp:122] Setting up Convolution14
I1006 21:21:50.565333  4081 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 21:21:50.565336  4081 net.cpp:137] Memory required for data: 427214000
I1006 21:21:50.565351  4081 layer_factory.hpp:77] Creating layer BatchNorm14
I1006 21:21:50.565356  4081 net.cpp:84] Creating Layer BatchNorm14
I1006 21:21:50.565359  4081 net.cpp:406] BatchNorm14 <- Convolution14
I1006 21:21:50.565363  4081 net.cpp:367] BatchNorm14 -> Convolution14 (in-place)
I1006 21:21:50.565505  4081 net.cpp:122] Setting up BatchNorm14
I1006 21:21:50.565508  4081 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 21:21:50.565511  4081 net.cpp:137] Memory required for data: 430490800
I1006 21:21:50.565516  4081 layer_factory.hpp:77] Creating layer Scale14
I1006 21:21:50.565521  4081 net.cpp:84] Creating Layer Scale14
I1006 21:21:50.565529  4081 net.cpp:406] Scale14 <- Convolution14
I1006 21:21:50.565534  4081 net.cpp:367] Scale14 -> Convolution14 (in-place)
I1006 21:21:50.565565  4081 layer_factory.hpp:77] Creating layer Scale14
I1006 21:21:50.565646  4081 net.cpp:122] Setting up Scale14
I1006 21:21:50.565651  4081 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 21:21:50.565654  4081 net.cpp:137] Memory required for data: 433767600
I1006 21:21:50.565657  4081 layer_factory.hpp:77] Creating layer Eltwise6
I1006 21:21:50.565661  4081 net.cpp:84] Creating Layer Eltwise6
I1006 21:21:50.565663  4081 net.cpp:406] Eltwise6 <- Convolution12
I1006 21:21:50.565666  4081 net.cpp:406] Eltwise6 <- Convolution14
I1006 21:21:50.565670  4081 net.cpp:380] Eltwise6 -> Eltwise6
I1006 21:21:50.565685  4081 net.cpp:122] Setting up Eltwise6
I1006 21:21:50.565687  4081 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 21:21:50.565690  4081 net.cpp:137] Memory required for data: 437044400
I1006 21:21:50.565691  4081 layer_factory.hpp:77] Creating layer penlu13
I1006 21:21:50.565697  4081 net.cpp:84] Creating Layer penlu13
I1006 21:21:50.565699  4081 net.cpp:406] penlu13 <- Eltwise6
I1006 21:21:50.565704  4081 net.cpp:367] penlu13 -> Eltwise6 (in-place)
I1006 21:21:50.565825  4081 net.cpp:122] Setting up penlu13
I1006 21:21:50.565830  4081 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 21:21:50.565832  4081 net.cpp:137] Memory required for data: 440321200
I1006 21:21:50.565836  4081 layer_factory.hpp:77] Creating layer Eltwise6_penlu13_0_split
I1006 21:21:50.565840  4081 net.cpp:84] Creating Layer Eltwise6_penlu13_0_split
I1006 21:21:50.565842  4081 net.cpp:406] Eltwise6_penlu13_0_split <- Eltwise6
I1006 21:21:50.565845  4081 net.cpp:380] Eltwise6_penlu13_0_split -> Eltwise6_penlu13_0_split_0
I1006 21:21:50.565850  4081 net.cpp:380] Eltwise6_penlu13_0_split -> Eltwise6_penlu13_0_split_1
I1006 21:21:50.565876  4081 net.cpp:122] Setting up Eltwise6_penlu13_0_split
I1006 21:21:50.565881  4081 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 21:21:50.565882  4081 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 21:21:50.565884  4081 net.cpp:137] Memory required for data: 446874800
I1006 21:21:50.565886  4081 layer_factory.hpp:77] Creating layer Convolution15
I1006 21:21:50.565892  4081 net.cpp:84] Creating Layer Convolution15
I1006 21:21:50.565896  4081 net.cpp:406] Convolution15 <- Eltwise6_penlu13_0_split_0
I1006 21:21:50.565899  4081 net.cpp:380] Convolution15 -> Convolution15
I1006 21:21:50.572191  4081 net.cpp:122] Setting up Convolution15
I1006 21:21:50.572201  4081 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 21:21:50.572203  4081 net.cpp:137] Memory required for data: 450151600
I1006 21:21:50.572208  4081 layer_factory.hpp:77] Creating layer BatchNorm15
I1006 21:21:50.572213  4081 net.cpp:84] Creating Layer BatchNorm15
I1006 21:21:50.572216  4081 net.cpp:406] BatchNorm15 <- Convolution15
I1006 21:21:50.572221  4081 net.cpp:367] BatchNorm15 -> Convolution15 (in-place)
I1006 21:21:50.572365  4081 net.cpp:122] Setting up BatchNorm15
I1006 21:21:50.572368  4081 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 21:21:50.572371  4081 net.cpp:137] Memory required for data: 453428400
I1006 21:21:50.572374  4081 layer_factory.hpp:77] Creating layer Scale15
I1006 21:21:50.572379  4081 net.cpp:84] Creating Layer Scale15
I1006 21:21:50.572382  4081 net.cpp:406] Scale15 <- Convolution15
I1006 21:21:50.572386  4081 net.cpp:367] Scale15 -> Convolution15 (in-place)
I1006 21:21:50.572415  4081 layer_factory.hpp:77] Creating layer Scale15
I1006 21:21:50.572496  4081 net.cpp:122] Setting up Scale15
I1006 21:21:50.572500  4081 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 21:21:50.572502  4081 net.cpp:137] Memory required for data: 456705200
I1006 21:21:50.572506  4081 layer_factory.hpp:77] Creating layer penlu14
I1006 21:21:50.572511  4081 net.cpp:84] Creating Layer penlu14
I1006 21:21:50.572515  4081 net.cpp:406] penlu14 <- Convolution15
I1006 21:21:50.572518  4081 net.cpp:367] penlu14 -> Convolution15 (in-place)
I1006 21:21:50.572633  4081 net.cpp:122] Setting up penlu14
I1006 21:21:50.572643  4081 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 21:21:50.572645  4081 net.cpp:137] Memory required for data: 459982000
I1006 21:21:50.572649  4081 layer_factory.hpp:77] Creating layer Convolution16
I1006 21:21:50.572656  4081 net.cpp:84] Creating Layer Convolution16
I1006 21:21:50.572659  4081 net.cpp:406] Convolution16 <- Convolution15
I1006 21:21:50.572664  4081 net.cpp:380] Convolution16 -> Convolution16
I1006 21:21:50.578788  4081 net.cpp:122] Setting up Convolution16
I1006 21:21:50.578799  4081 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 21:21:50.578801  4081 net.cpp:137] Memory required for data: 463258800
I1006 21:21:50.578806  4081 layer_factory.hpp:77] Creating layer BatchNorm16
I1006 21:21:50.578811  4081 net.cpp:84] Creating Layer BatchNorm16
I1006 21:21:50.578815  4081 net.cpp:406] BatchNorm16 <- Convolution16
I1006 21:21:50.578819  4081 net.cpp:367] BatchNorm16 -> Convolution16 (in-place)
I1006 21:21:50.578970  4081 net.cpp:122] Setting up BatchNorm16
I1006 21:21:50.578975  4081 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 21:21:50.578977  4081 net.cpp:137] Memory required for data: 466535600
I1006 21:21:50.578982  4081 layer_factory.hpp:77] Creating layer Scale16
I1006 21:21:50.578986  4081 net.cpp:84] Creating Layer Scale16
I1006 21:21:50.578989  4081 net.cpp:406] Scale16 <- Convolution16
I1006 21:21:50.578994  4081 net.cpp:367] Scale16 -> Convolution16 (in-place)
I1006 21:21:50.579023  4081 layer_factory.hpp:77] Creating layer Scale16
I1006 21:21:50.579111  4081 net.cpp:122] Setting up Scale16
I1006 21:21:50.579116  4081 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 21:21:50.579118  4081 net.cpp:137] Memory required for data: 469812400
I1006 21:21:50.579123  4081 layer_factory.hpp:77] Creating layer Eltwise7
I1006 21:21:50.579126  4081 net.cpp:84] Creating Layer Eltwise7
I1006 21:21:50.579129  4081 net.cpp:406] Eltwise7 <- Eltwise6_penlu13_0_split_1
I1006 21:21:50.579133  4081 net.cpp:406] Eltwise7 <- Convolution16
I1006 21:21:50.579136  4081 net.cpp:380] Eltwise7 -> Eltwise7
I1006 21:21:50.579151  4081 net.cpp:122] Setting up Eltwise7
I1006 21:21:50.579155  4081 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 21:21:50.579157  4081 net.cpp:137] Memory required for data: 473089200
I1006 21:21:50.579160  4081 layer_factory.hpp:77] Creating layer penlu15
I1006 21:21:50.579169  4081 net.cpp:84] Creating Layer penlu15
I1006 21:21:50.579174  4081 net.cpp:406] penlu15 <- Eltwise7
I1006 21:21:50.579176  4081 net.cpp:367] penlu15 -> Eltwise7 (in-place)
I1006 21:21:50.579315  4081 net.cpp:122] Setting up penlu15
I1006 21:21:50.579320  4081 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 21:21:50.579322  4081 net.cpp:137] Memory required for data: 476366000
I1006 21:21:50.579326  4081 layer_factory.hpp:77] Creating layer Eltwise7_penlu15_0_split
I1006 21:21:50.579331  4081 net.cpp:84] Creating Layer Eltwise7_penlu15_0_split
I1006 21:21:50.579334  4081 net.cpp:406] Eltwise7_penlu15_0_split <- Eltwise7
I1006 21:21:50.579336  4081 net.cpp:380] Eltwise7_penlu15_0_split -> Eltwise7_penlu15_0_split_0
I1006 21:21:50.579340  4081 net.cpp:380] Eltwise7_penlu15_0_split -> Eltwise7_penlu15_0_split_1
I1006 21:21:50.579365  4081 net.cpp:122] Setting up Eltwise7_penlu15_0_split
I1006 21:21:50.579370  4081 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 21:21:50.579372  4081 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 21:21:50.579375  4081 net.cpp:137] Memory required for data: 482919600
I1006 21:21:50.579376  4081 layer_factory.hpp:77] Creating layer Convolution17
I1006 21:21:50.579382  4081 net.cpp:84] Creating Layer Convolution17
I1006 21:21:50.579385  4081 net.cpp:406] Convolution17 <- Eltwise7_penlu15_0_split_0
I1006 21:21:50.579390  4081 net.cpp:380] Convolution17 -> Convolution17
I1006 21:21:50.585682  4081 net.cpp:122] Setting up Convolution17
I1006 21:21:50.585690  4081 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 21:21:50.585693  4081 net.cpp:137] Memory required for data: 486196400
I1006 21:21:50.585697  4081 layer_factory.hpp:77] Creating layer BatchNorm17
I1006 21:21:50.585710  4081 net.cpp:84] Creating Layer BatchNorm17
I1006 21:21:50.585713  4081 net.cpp:406] BatchNorm17 <- Convolution17
I1006 21:21:50.585716  4081 net.cpp:367] BatchNorm17 -> Convolution17 (in-place)
I1006 21:21:50.585860  4081 net.cpp:122] Setting up BatchNorm17
I1006 21:21:50.585865  4081 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 21:21:50.585866  4081 net.cpp:137] Memory required for data: 489473200
I1006 21:21:50.585871  4081 layer_factory.hpp:77] Creating layer Scale17
I1006 21:21:50.585876  4081 net.cpp:84] Creating Layer Scale17
I1006 21:21:50.585878  4081 net.cpp:406] Scale17 <- Convolution17
I1006 21:21:50.585881  4081 net.cpp:367] Scale17 -> Convolution17 (in-place)
I1006 21:21:50.585911  4081 layer_factory.hpp:77] Creating layer Scale17
I1006 21:21:50.585994  4081 net.cpp:122] Setting up Scale17
I1006 21:21:50.585997  4081 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 21:21:50.585999  4081 net.cpp:137] Memory required for data: 492750000
I1006 21:21:50.586004  4081 layer_factory.hpp:77] Creating layer penlu16
I1006 21:21:50.586009  4081 net.cpp:84] Creating Layer penlu16
I1006 21:21:50.586011  4081 net.cpp:406] penlu16 <- Convolution17
I1006 21:21:50.586015  4081 net.cpp:367] penlu16 -> Convolution17 (in-place)
I1006 21:21:50.586130  4081 net.cpp:122] Setting up penlu16
I1006 21:21:50.586134  4081 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 21:21:50.586136  4081 net.cpp:137] Memory required for data: 496026800
I1006 21:21:50.586140  4081 layer_factory.hpp:77] Creating layer Convolution18
I1006 21:21:50.586148  4081 net.cpp:84] Creating Layer Convolution18
I1006 21:21:50.586149  4081 net.cpp:406] Convolution18 <- Convolution17
I1006 21:21:50.586153  4081 net.cpp:380] Convolution18 -> Convolution18
I1006 21:21:50.592222  4081 net.cpp:122] Setting up Convolution18
I1006 21:21:50.592232  4081 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 21:21:50.592236  4081 net.cpp:137] Memory required for data: 499303600
I1006 21:21:50.592241  4081 layer_factory.hpp:77] Creating layer BatchNorm18
I1006 21:21:50.592244  4081 net.cpp:84] Creating Layer BatchNorm18
I1006 21:21:50.592247  4081 net.cpp:406] BatchNorm18 <- Convolution18
I1006 21:21:50.592252  4081 net.cpp:367] BatchNorm18 -> Convolution18 (in-place)
I1006 21:21:50.592423  4081 net.cpp:122] Setting up BatchNorm18
I1006 21:21:50.592430  4081 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 21:21:50.592432  4081 net.cpp:137] Memory required for data: 502580400
I1006 21:21:50.592437  4081 layer_factory.hpp:77] Creating layer Scale18
I1006 21:21:50.592442  4081 net.cpp:84] Creating Layer Scale18
I1006 21:21:50.592445  4081 net.cpp:406] Scale18 <- Convolution18
I1006 21:21:50.592448  4081 net.cpp:367] Scale18 -> Convolution18 (in-place)
I1006 21:21:50.592481  4081 layer_factory.hpp:77] Creating layer Scale18
I1006 21:21:50.592581  4081 net.cpp:122] Setting up Scale18
I1006 21:21:50.592586  4081 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 21:21:50.592587  4081 net.cpp:137] Memory required for data: 505857200
I1006 21:21:50.592591  4081 layer_factory.hpp:77] Creating layer Eltwise8
I1006 21:21:50.592594  4081 net.cpp:84] Creating Layer Eltwise8
I1006 21:21:50.592597  4081 net.cpp:406] Eltwise8 <- Eltwise7_penlu15_0_split_1
I1006 21:21:50.592600  4081 net.cpp:406] Eltwise8 <- Convolution18
I1006 21:21:50.592604  4081 net.cpp:380] Eltwise8 -> Eltwise8
I1006 21:21:50.592618  4081 net.cpp:122] Setting up Eltwise8
I1006 21:21:50.592622  4081 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 21:21:50.592623  4081 net.cpp:137] Memory required for data: 509134000
I1006 21:21:50.592625  4081 layer_factory.hpp:77] Creating layer penlu17
I1006 21:21:50.592631  4081 net.cpp:84] Creating Layer penlu17
I1006 21:21:50.592633  4081 net.cpp:406] penlu17 <- Eltwise8
I1006 21:21:50.592638  4081 net.cpp:367] penlu17 -> Eltwise8 (in-place)
I1006 21:21:50.592761  4081 net.cpp:122] Setting up penlu17
I1006 21:21:50.592766  4081 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 21:21:50.592767  4081 net.cpp:137] Memory required for data: 512410800
I1006 21:21:50.592779  4081 layer_factory.hpp:77] Creating layer Eltwise8_penlu17_0_split
I1006 21:21:50.592783  4081 net.cpp:84] Creating Layer Eltwise8_penlu17_0_split
I1006 21:21:50.592785  4081 net.cpp:406] Eltwise8_penlu17_0_split <- Eltwise8
I1006 21:21:50.592788  4081 net.cpp:380] Eltwise8_penlu17_0_split -> Eltwise8_penlu17_0_split_0
I1006 21:21:50.592793  4081 net.cpp:380] Eltwise8_penlu17_0_split -> Eltwise8_penlu17_0_split_1
I1006 21:21:50.592820  4081 net.cpp:122] Setting up Eltwise8_penlu17_0_split
I1006 21:21:50.592824  4081 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 21:21:50.592828  4081 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 21:21:50.592829  4081 net.cpp:137] Memory required for data: 518964400
I1006 21:21:50.592831  4081 layer_factory.hpp:77] Creating layer Convolution19
I1006 21:21:50.592839  4081 net.cpp:84] Creating Layer Convolution19
I1006 21:21:50.592841  4081 net.cpp:406] Convolution19 <- Eltwise8_penlu17_0_split_0
I1006 21:21:50.592845  4081 net.cpp:380] Convolution19 -> Convolution19
I1006 21:21:50.595216  4081 net.cpp:122] Setting up Convolution19
I1006 21:21:50.595226  4081 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 21:21:50.595228  4081 net.cpp:137] Memory required for data: 522241200
I1006 21:21:50.595232  4081 layer_factory.hpp:77] Creating layer BatchNorm19
I1006 21:21:50.595238  4081 net.cpp:84] Creating Layer BatchNorm19
I1006 21:21:50.595242  4081 net.cpp:406] BatchNorm19 <- Convolution19
I1006 21:21:50.595247  4081 net.cpp:367] BatchNorm19 -> Convolution19 (in-place)
I1006 21:21:50.595393  4081 net.cpp:122] Setting up BatchNorm19
I1006 21:21:50.595398  4081 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 21:21:50.595401  4081 net.cpp:137] Memory required for data: 525518000
I1006 21:21:50.595405  4081 layer_factory.hpp:77] Creating layer Scale19
I1006 21:21:50.595409  4081 net.cpp:84] Creating Layer Scale19
I1006 21:21:50.595412  4081 net.cpp:406] Scale19 <- Convolution19
I1006 21:21:50.595415  4081 net.cpp:367] Scale19 -> Convolution19 (in-place)
I1006 21:21:50.595445  4081 layer_factory.hpp:77] Creating layer Scale19
I1006 21:21:50.595532  4081 net.cpp:122] Setting up Scale19
I1006 21:21:50.595536  4081 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 21:21:50.595540  4081 net.cpp:137] Memory required for data: 528794800
I1006 21:21:50.595542  4081 layer_factory.hpp:77] Creating layer penlu18
I1006 21:21:50.595547  4081 net.cpp:84] Creating Layer penlu18
I1006 21:21:50.595551  4081 net.cpp:406] penlu18 <- Convolution19
I1006 21:21:50.595554  4081 net.cpp:367] penlu18 -> Convolution19 (in-place)
I1006 21:21:50.595675  4081 net.cpp:122] Setting up penlu18
I1006 21:21:50.595679  4081 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 21:21:50.595681  4081 net.cpp:137] Memory required for data: 532071600
I1006 21:21:50.595686  4081 layer_factory.hpp:77] Creating layer Convolution20
I1006 21:21:50.595693  4081 net.cpp:84] Creating Layer Convolution20
I1006 21:21:50.595695  4081 net.cpp:406] Convolution20 <- Convolution19
I1006 21:21:50.595701  4081 net.cpp:380] Convolution20 -> Convolution20
I1006 21:21:50.600554  4081 net.cpp:122] Setting up Convolution20
I1006 21:21:50.600563  4081 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 21:21:50.600564  4081 net.cpp:137] Memory required for data: 535348400
I1006 21:21:50.600569  4081 layer_factory.hpp:77] Creating layer BatchNorm20
I1006 21:21:50.600574  4081 net.cpp:84] Creating Layer BatchNorm20
I1006 21:21:50.600576  4081 net.cpp:406] BatchNorm20 <- Convolution20
I1006 21:21:50.600580  4081 net.cpp:367] BatchNorm20 -> Convolution20 (in-place)
I1006 21:21:50.600725  4081 net.cpp:122] Setting up BatchNorm20
I1006 21:21:50.600729  4081 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 21:21:50.600731  4081 net.cpp:137] Memory required for data: 538625200
I1006 21:21:50.600736  4081 layer_factory.hpp:77] Creating layer Scale20
I1006 21:21:50.600740  4081 net.cpp:84] Creating Layer Scale20
I1006 21:21:50.600742  4081 net.cpp:406] Scale20 <- Convolution20
I1006 21:21:50.600754  4081 net.cpp:367] Scale20 -> Convolution20 (in-place)
I1006 21:21:50.600786  4081 layer_factory.hpp:77] Creating layer Scale20
I1006 21:21:50.600868  4081 net.cpp:122] Setting up Scale20
I1006 21:21:50.600873  4081 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 21:21:50.600877  4081 net.cpp:137] Memory required for data: 541902000
I1006 21:21:50.600879  4081 layer_factory.hpp:77] Creating layer Eltwise9
I1006 21:21:50.600884  4081 net.cpp:84] Creating Layer Eltwise9
I1006 21:21:50.600886  4081 net.cpp:406] Eltwise9 <- Eltwise8_penlu17_0_split_1
I1006 21:21:50.600889  4081 net.cpp:406] Eltwise9 <- Convolution20
I1006 21:21:50.600893  4081 net.cpp:380] Eltwise9 -> Eltwise9
I1006 21:21:50.600906  4081 net.cpp:122] Setting up Eltwise9
I1006 21:21:50.600910  4081 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 21:21:50.600913  4081 net.cpp:137] Memory required for data: 545178800
I1006 21:21:50.600914  4081 layer_factory.hpp:77] Creating layer penlu19
I1006 21:21:50.600920  4081 net.cpp:84] Creating Layer penlu19
I1006 21:21:50.600922  4081 net.cpp:406] penlu19 <- Eltwise9
I1006 21:21:50.600925  4081 net.cpp:367] penlu19 -> Eltwise9 (in-place)
I1006 21:21:50.601047  4081 net.cpp:122] Setting up penlu19
I1006 21:21:50.601052  4081 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 21:21:50.601053  4081 net.cpp:137] Memory required for data: 548455600
I1006 21:21:50.601058  4081 layer_factory.hpp:77] Creating layer Eltwise9_penlu19_0_split
I1006 21:21:50.601061  4081 net.cpp:84] Creating Layer Eltwise9_penlu19_0_split
I1006 21:21:50.601064  4081 net.cpp:406] Eltwise9_penlu19_0_split <- Eltwise9
I1006 21:21:50.601068  4081 net.cpp:380] Eltwise9_penlu19_0_split -> Eltwise9_penlu19_0_split_0
I1006 21:21:50.601073  4081 net.cpp:380] Eltwise9_penlu19_0_split -> Eltwise9_penlu19_0_split_1
I1006 21:21:50.601096  4081 net.cpp:122] Setting up Eltwise9_penlu19_0_split
I1006 21:21:50.601101  4081 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 21:21:50.601104  4081 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 21:21:50.601106  4081 net.cpp:137] Memory required for data: 555009200
I1006 21:21:50.601109  4081 layer_factory.hpp:77] Creating layer Convolution21
I1006 21:21:50.601114  4081 net.cpp:84] Creating Layer Convolution21
I1006 21:21:50.601116  4081 net.cpp:406] Convolution21 <- Eltwise9_penlu19_0_split_0
I1006 21:21:50.601120  4081 net.cpp:380] Convolution21 -> Convolution21
I1006 21:21:50.607106  4081 net.cpp:122] Setting up Convolution21
I1006 21:21:50.607115  4081 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 21:21:50.607118  4081 net.cpp:137] Memory required for data: 558286000
I1006 21:21:50.607123  4081 layer_factory.hpp:77] Creating layer BatchNorm21
I1006 21:21:50.607128  4081 net.cpp:84] Creating Layer BatchNorm21
I1006 21:21:50.607132  4081 net.cpp:406] BatchNorm21 <- Convolution21
I1006 21:21:50.607136  4081 net.cpp:367] BatchNorm21 -> Convolution21 (in-place)
I1006 21:21:50.607292  4081 net.cpp:122] Setting up BatchNorm21
I1006 21:21:50.607297  4081 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 21:21:50.607300  4081 net.cpp:137] Memory required for data: 561562800
I1006 21:21:50.607306  4081 layer_factory.hpp:77] Creating layer Scale21
I1006 21:21:50.607311  4081 net.cpp:84] Creating Layer Scale21
I1006 21:21:50.607312  4081 net.cpp:406] Scale21 <- Convolution21
I1006 21:21:50.607316  4081 net.cpp:367] Scale21 -> Convolution21 (in-place)
I1006 21:21:50.607347  4081 layer_factory.hpp:77] Creating layer Scale21
I1006 21:21:50.607436  4081 net.cpp:122] Setting up Scale21
I1006 21:21:50.607440  4081 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 21:21:50.607442  4081 net.cpp:137] Memory required for data: 564839600
I1006 21:21:50.607446  4081 layer_factory.hpp:77] Creating layer penlu20
I1006 21:21:50.607452  4081 net.cpp:84] Creating Layer penlu20
I1006 21:21:50.607455  4081 net.cpp:406] penlu20 <- Convolution21
I1006 21:21:50.607461  4081 net.cpp:367] penlu20 -> Convolution21 (in-place)
I1006 21:21:50.607620  4081 net.cpp:122] Setting up penlu20
I1006 21:21:50.607633  4081 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 21:21:50.607636  4081 net.cpp:137] Memory required for data: 568116400
I1006 21:21:50.607641  4081 layer_factory.hpp:77] Creating layer Convolution22
I1006 21:21:50.607648  4081 net.cpp:84] Creating Layer Convolution22
I1006 21:21:50.607651  4081 net.cpp:406] Convolution22 <- Convolution21
I1006 21:21:50.607656  4081 net.cpp:380] Convolution22 -> Convolution22
I1006 21:21:50.614367  4081 net.cpp:122] Setting up Convolution22
I1006 21:21:50.614375  4081 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 21:21:50.614378  4081 net.cpp:137] Memory required for data: 571393200
I1006 21:21:50.614382  4081 layer_factory.hpp:77] Creating layer BatchNorm22
I1006 21:21:50.614387  4081 net.cpp:84] Creating Layer BatchNorm22
I1006 21:21:50.614390  4081 net.cpp:406] BatchNorm22 <- Convolution22
I1006 21:21:50.614394  4081 net.cpp:367] BatchNorm22 -> Convolution22 (in-place)
I1006 21:21:50.614540  4081 net.cpp:122] Setting up BatchNorm22
I1006 21:21:50.614544  4081 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 21:21:50.614547  4081 net.cpp:137] Memory required for data: 574670000
I1006 21:21:50.614552  4081 layer_factory.hpp:77] Creating layer Scale22
I1006 21:21:50.614555  4081 net.cpp:84] Creating Layer Scale22
I1006 21:21:50.614557  4081 net.cpp:406] Scale22 <- Convolution22
I1006 21:21:50.614560  4081 net.cpp:367] Scale22 -> Convolution22 (in-place)
I1006 21:21:50.614591  4081 layer_factory.hpp:77] Creating layer Scale22
I1006 21:21:50.614675  4081 net.cpp:122] Setting up Scale22
I1006 21:21:50.614681  4081 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 21:21:50.614682  4081 net.cpp:137] Memory required for data: 577946800
I1006 21:21:50.614686  4081 layer_factory.hpp:77] Creating layer Eltwise10
I1006 21:21:50.614691  4081 net.cpp:84] Creating Layer Eltwise10
I1006 21:21:50.614693  4081 net.cpp:406] Eltwise10 <- Eltwise9_penlu19_0_split_1
I1006 21:21:50.614696  4081 net.cpp:406] Eltwise10 <- Convolution22
I1006 21:21:50.614701  4081 net.cpp:380] Eltwise10 -> Eltwise10
I1006 21:21:50.614714  4081 net.cpp:122] Setting up Eltwise10
I1006 21:21:50.614718  4081 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 21:21:50.614720  4081 net.cpp:137] Memory required for data: 581223600
I1006 21:21:50.614722  4081 layer_factory.hpp:77] Creating layer penlu21
I1006 21:21:50.614728  4081 net.cpp:84] Creating Layer penlu21
I1006 21:21:50.614730  4081 net.cpp:406] penlu21 <- Eltwise10
I1006 21:21:50.614734  4081 net.cpp:367] penlu21 -> Eltwise10 (in-place)
I1006 21:21:50.614856  4081 net.cpp:122] Setting up penlu21
I1006 21:21:50.614859  4081 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 21:21:50.614861  4081 net.cpp:137] Memory required for data: 584500400
I1006 21:21:50.614866  4081 layer_factory.hpp:77] Creating layer Eltwise10_penlu21_0_split
I1006 21:21:50.614869  4081 net.cpp:84] Creating Layer Eltwise10_penlu21_0_split
I1006 21:21:50.614871  4081 net.cpp:406] Eltwise10_penlu21_0_split <- Eltwise10
I1006 21:21:50.614876  4081 net.cpp:380] Eltwise10_penlu21_0_split -> Eltwise10_penlu21_0_split_0
I1006 21:21:50.614879  4081 net.cpp:380] Eltwise10_penlu21_0_split -> Eltwise10_penlu21_0_split_1
I1006 21:21:50.614905  4081 net.cpp:122] Setting up Eltwise10_penlu21_0_split
I1006 21:21:50.614908  4081 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 21:21:50.614912  4081 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1006 21:21:50.614913  4081 net.cpp:137] Memory required for data: 591054000
I1006 21:21:50.614915  4081 layer_factory.hpp:77] Creating layer Convolution23
I1006 21:21:50.614922  4081 net.cpp:84] Creating Layer Convolution23
I1006 21:21:50.614924  4081 net.cpp:406] Convolution23 <- Eltwise10_penlu21_0_split_0
I1006 21:21:50.614928  4081 net.cpp:380] Convolution23 -> Convolution23
I1006 21:21:50.617399  4081 net.cpp:122] Setting up Convolution23
I1006 21:21:50.617408  4081 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 21:21:50.617411  4081 net.cpp:137] Memory required for data: 592692400
I1006 21:21:50.617415  4081 layer_factory.hpp:77] Creating layer BatchNorm23
I1006 21:21:50.617429  4081 net.cpp:84] Creating Layer BatchNorm23
I1006 21:21:50.617431  4081 net.cpp:406] BatchNorm23 <- Convolution23
I1006 21:21:50.617436  4081 net.cpp:367] BatchNorm23 -> Convolution23 (in-place)
I1006 21:21:50.617584  4081 net.cpp:122] Setting up BatchNorm23
I1006 21:21:50.617588  4081 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 21:21:50.617590  4081 net.cpp:137] Memory required for data: 594330800
I1006 21:21:50.617595  4081 layer_factory.hpp:77] Creating layer Scale23
I1006 21:21:50.617599  4081 net.cpp:84] Creating Layer Scale23
I1006 21:21:50.617602  4081 net.cpp:406] Scale23 <- Convolution23
I1006 21:21:50.617605  4081 net.cpp:367] Scale23 -> Convolution23 (in-place)
I1006 21:21:50.617636  4081 layer_factory.hpp:77] Creating layer Scale23
I1006 21:21:50.617722  4081 net.cpp:122] Setting up Scale23
I1006 21:21:50.617727  4081 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 21:21:50.617728  4081 net.cpp:137] Memory required for data: 595969200
I1006 21:21:50.617732  4081 layer_factory.hpp:77] Creating layer Convolution24
I1006 21:21:50.617739  4081 net.cpp:84] Creating Layer Convolution24
I1006 21:21:50.617743  4081 net.cpp:406] Convolution24 <- Eltwise10_penlu21_0_split_1
I1006 21:21:50.617746  4081 net.cpp:380] Convolution24 -> Convolution24
I1006 21:21:50.621867  4081 net.cpp:122] Setting up Convolution24
I1006 21:21:50.621876  4081 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 21:21:50.621889  4081 net.cpp:137] Memory required for data: 597607600
I1006 21:21:50.621893  4081 layer_factory.hpp:77] Creating layer BatchNorm24
I1006 21:21:50.621899  4081 net.cpp:84] Creating Layer BatchNorm24
I1006 21:21:50.621902  4081 net.cpp:406] BatchNorm24 <- Convolution24
I1006 21:21:50.621906  4081 net.cpp:367] BatchNorm24 -> Convolution24 (in-place)
I1006 21:21:50.622068  4081 net.cpp:122] Setting up BatchNorm24
I1006 21:21:50.622073  4081 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 21:21:50.622076  4081 net.cpp:137] Memory required for data: 599246000
I1006 21:21:50.622081  4081 layer_factory.hpp:77] Creating layer Scale24
I1006 21:21:50.622084  4081 net.cpp:84] Creating Layer Scale24
I1006 21:21:50.622087  4081 net.cpp:406] Scale24 <- Convolution24
I1006 21:21:50.622089  4081 net.cpp:367] Scale24 -> Convolution24 (in-place)
I1006 21:21:50.622120  4081 layer_factory.hpp:77] Creating layer Scale24
I1006 21:21:50.622205  4081 net.cpp:122] Setting up Scale24
I1006 21:21:50.622210  4081 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 21:21:50.622211  4081 net.cpp:137] Memory required for data: 600884400
I1006 21:21:50.622215  4081 layer_factory.hpp:77] Creating layer penlu22
I1006 21:21:50.622220  4081 net.cpp:84] Creating Layer penlu22
I1006 21:21:50.622222  4081 net.cpp:406] penlu22 <- Convolution24
I1006 21:21:50.622226  4081 net.cpp:367] penlu22 -> Convolution24 (in-place)
I1006 21:21:50.622344  4081 net.cpp:122] Setting up penlu22
I1006 21:21:50.622349  4081 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 21:21:50.622351  4081 net.cpp:137] Memory required for data: 602522800
I1006 21:21:50.622355  4081 layer_factory.hpp:77] Creating layer Convolution25
I1006 21:21:50.622364  4081 net.cpp:84] Creating Layer Convolution25
I1006 21:21:50.622365  4081 net.cpp:406] Convolution25 <- Convolution24
I1006 21:21:50.622370  4081 net.cpp:380] Convolution25 -> Convolution25
I1006 21:21:50.628430  4081 net.cpp:122] Setting up Convolution25
I1006 21:21:50.628439  4081 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 21:21:50.628443  4081 net.cpp:137] Memory required for data: 604161200
I1006 21:21:50.628446  4081 layer_factory.hpp:77] Creating layer BatchNorm25
I1006 21:21:50.628451  4081 net.cpp:84] Creating Layer BatchNorm25
I1006 21:21:50.628454  4081 net.cpp:406] BatchNorm25 <- Convolution25
I1006 21:21:50.628458  4081 net.cpp:367] BatchNorm25 -> Convolution25 (in-place)
I1006 21:21:50.628605  4081 net.cpp:122] Setting up BatchNorm25
I1006 21:21:50.628609  4081 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 21:21:50.628612  4081 net.cpp:137] Memory required for data: 605799600
I1006 21:21:50.628623  4081 layer_factory.hpp:77] Creating layer Scale25
I1006 21:21:50.628628  4081 net.cpp:84] Creating Layer Scale25
I1006 21:21:50.628631  4081 net.cpp:406] Scale25 <- Convolution25
I1006 21:21:50.628634  4081 net.cpp:367] Scale25 -> Convolution25 (in-place)
I1006 21:21:50.628666  4081 layer_factory.hpp:77] Creating layer Scale25
I1006 21:21:50.628752  4081 net.cpp:122] Setting up Scale25
I1006 21:21:50.628756  4081 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 21:21:50.628759  4081 net.cpp:137] Memory required for data: 607438000
I1006 21:21:50.628762  4081 layer_factory.hpp:77] Creating layer Eltwise11
I1006 21:21:50.628767  4081 net.cpp:84] Creating Layer Eltwise11
I1006 21:21:50.628769  4081 net.cpp:406] Eltwise11 <- Convolution23
I1006 21:21:50.628772  4081 net.cpp:406] Eltwise11 <- Convolution25
I1006 21:21:50.628775  4081 net.cpp:380] Eltwise11 -> Eltwise11
I1006 21:21:50.628793  4081 net.cpp:122] Setting up Eltwise11
I1006 21:21:50.628796  4081 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 21:21:50.628798  4081 net.cpp:137] Memory required for data: 609076400
I1006 21:21:50.628801  4081 layer_factory.hpp:77] Creating layer penlu23
I1006 21:21:50.628806  4081 net.cpp:84] Creating Layer penlu23
I1006 21:21:50.628809  4081 net.cpp:406] penlu23 <- Eltwise11
I1006 21:21:50.628813  4081 net.cpp:367] penlu23 -> Eltwise11 (in-place)
I1006 21:21:50.628932  4081 net.cpp:122] Setting up penlu23
I1006 21:21:50.628937  4081 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 21:21:50.628939  4081 net.cpp:137] Memory required for data: 610714800
I1006 21:21:50.628943  4081 layer_factory.hpp:77] Creating layer Eltwise11_penlu23_0_split
I1006 21:21:50.628947  4081 net.cpp:84] Creating Layer Eltwise11_penlu23_0_split
I1006 21:21:50.628949  4081 net.cpp:406] Eltwise11_penlu23_0_split <- Eltwise11
I1006 21:21:50.628953  4081 net.cpp:380] Eltwise11_penlu23_0_split -> Eltwise11_penlu23_0_split_0
I1006 21:21:50.628957  4081 net.cpp:380] Eltwise11_penlu23_0_split -> Eltwise11_penlu23_0_split_1
I1006 21:21:50.628983  4081 net.cpp:122] Setting up Eltwise11_penlu23_0_split
I1006 21:21:50.628986  4081 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 21:21:50.628989  4081 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 21:21:50.628991  4081 net.cpp:137] Memory required for data: 613991600
I1006 21:21:50.628993  4081 layer_factory.hpp:77] Creating layer Convolution26
I1006 21:21:50.629001  4081 net.cpp:84] Creating Layer Convolution26
I1006 21:21:50.629004  4081 net.cpp:406] Convolution26 <- Eltwise11_penlu23_0_split_0
I1006 21:21:50.629007  4081 net.cpp:380] Convolution26 -> Convolution26
I1006 21:21:50.634969  4081 net.cpp:122] Setting up Convolution26
I1006 21:21:50.634979  4081 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 21:21:50.634981  4081 net.cpp:137] Memory required for data: 615630000
I1006 21:21:50.634985  4081 layer_factory.hpp:77] Creating layer BatchNorm26
I1006 21:21:50.634990  4081 net.cpp:84] Creating Layer BatchNorm26
I1006 21:21:50.634994  4081 net.cpp:406] BatchNorm26 <- Convolution26
I1006 21:21:50.634997  4081 net.cpp:367] BatchNorm26 -> Convolution26 (in-place)
I1006 21:21:50.635146  4081 net.cpp:122] Setting up BatchNorm26
I1006 21:21:50.635150  4081 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 21:21:50.635152  4081 net.cpp:137] Memory required for data: 617268400
I1006 21:21:50.635157  4081 layer_factory.hpp:77] Creating layer Scale26
I1006 21:21:50.635161  4081 net.cpp:84] Creating Layer Scale26
I1006 21:21:50.635179  4081 net.cpp:406] Scale26 <- Convolution26
I1006 21:21:50.635185  4081 net.cpp:367] Scale26 -> Convolution26 (in-place)
I1006 21:21:50.635237  4081 layer_factory.hpp:77] Creating layer Scale26
I1006 21:21:50.635323  4081 net.cpp:122] Setting up Scale26
I1006 21:21:50.635327  4081 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 21:21:50.635329  4081 net.cpp:137] Memory required for data: 618906800
I1006 21:21:50.635334  4081 layer_factory.hpp:77] Creating layer penlu24
I1006 21:21:50.635339  4081 net.cpp:84] Creating Layer penlu24
I1006 21:21:50.635340  4081 net.cpp:406] penlu24 <- Convolution26
I1006 21:21:50.635354  4081 net.cpp:367] penlu24 -> Convolution26 (in-place)
I1006 21:21:50.635474  4081 net.cpp:122] Setting up penlu24
I1006 21:21:50.635478  4081 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 21:21:50.635481  4081 net.cpp:137] Memory required for data: 620545200
I1006 21:21:50.635485  4081 layer_factory.hpp:77] Creating layer Convolution27
I1006 21:21:50.635493  4081 net.cpp:84] Creating Layer Convolution27
I1006 21:21:50.635494  4081 net.cpp:406] Convolution27 <- Convolution26
I1006 21:21:50.635499  4081 net.cpp:380] Convolution27 -> Convolution27
I1006 21:21:50.642014  4081 net.cpp:122] Setting up Convolution27
I1006 21:21:50.642025  4081 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 21:21:50.642027  4081 net.cpp:137] Memory required for data: 622183600
I1006 21:21:50.642032  4081 layer_factory.hpp:77] Creating layer BatchNorm27
I1006 21:21:50.642050  4081 net.cpp:84] Creating Layer BatchNorm27
I1006 21:21:50.642053  4081 net.cpp:406] BatchNorm27 <- Convolution27
I1006 21:21:50.642058  4081 net.cpp:367] BatchNorm27 -> Convolution27 (in-place)
I1006 21:21:50.642230  4081 net.cpp:122] Setting up BatchNorm27
I1006 21:21:50.642235  4081 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 21:21:50.642236  4081 net.cpp:137] Memory required for data: 623822000
I1006 21:21:50.642264  4081 layer_factory.hpp:77] Creating layer Scale27
I1006 21:21:50.642271  4081 net.cpp:84] Creating Layer Scale27
I1006 21:21:50.642272  4081 net.cpp:406] Scale27 <- Convolution27
I1006 21:21:50.642276  4081 net.cpp:367] Scale27 -> Convolution27 (in-place)
I1006 21:21:50.642310  4081 layer_factory.hpp:77] Creating layer Scale27
I1006 21:21:50.642395  4081 net.cpp:122] Setting up Scale27
I1006 21:21:50.642400  4081 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 21:21:50.642401  4081 net.cpp:137] Memory required for data: 625460400
I1006 21:21:50.642405  4081 layer_factory.hpp:77] Creating layer Eltwise12
I1006 21:21:50.642410  4081 net.cpp:84] Creating Layer Eltwise12
I1006 21:21:50.642413  4081 net.cpp:406] Eltwise12 <- Eltwise11_penlu23_0_split_1
I1006 21:21:50.642416  4081 net.cpp:406] Eltwise12 <- Convolution27
I1006 21:21:50.642419  4081 net.cpp:380] Eltwise12 -> Eltwise12
I1006 21:21:50.642437  4081 net.cpp:122] Setting up Eltwise12
I1006 21:21:50.642441  4081 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 21:21:50.642443  4081 net.cpp:137] Memory required for data: 627098800
I1006 21:21:50.642446  4081 layer_factory.hpp:77] Creating layer penlu25
I1006 21:21:50.642452  4081 net.cpp:84] Creating Layer penlu25
I1006 21:21:50.642453  4081 net.cpp:406] penlu25 <- Eltwise12
I1006 21:21:50.642458  4081 net.cpp:367] penlu25 -> Eltwise12 (in-place)
I1006 21:21:50.642581  4081 net.cpp:122] Setting up penlu25
I1006 21:21:50.642585  4081 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 21:21:50.642587  4081 net.cpp:137] Memory required for data: 628737200
I1006 21:21:50.642591  4081 layer_factory.hpp:77] Creating layer Eltwise12_penlu25_0_split
I1006 21:21:50.642596  4081 net.cpp:84] Creating Layer Eltwise12_penlu25_0_split
I1006 21:21:50.642597  4081 net.cpp:406] Eltwise12_penlu25_0_split <- Eltwise12
I1006 21:21:50.642601  4081 net.cpp:380] Eltwise12_penlu25_0_split -> Eltwise12_penlu25_0_split_0
I1006 21:21:50.642604  4081 net.cpp:380] Eltwise12_penlu25_0_split -> Eltwise12_penlu25_0_split_1
I1006 21:21:50.642630  4081 net.cpp:122] Setting up Eltwise12_penlu25_0_split
I1006 21:21:50.642634  4081 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 21:21:50.642637  4081 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 21:21:50.642639  4081 net.cpp:137] Memory required for data: 632014000
I1006 21:21:50.642642  4081 layer_factory.hpp:77] Creating layer Convolution28
I1006 21:21:50.642647  4081 net.cpp:84] Creating Layer Convolution28
I1006 21:21:50.642650  4081 net.cpp:406] Convolution28 <- Eltwise12_penlu25_0_split_0
I1006 21:21:50.642654  4081 net.cpp:380] Convolution28 -> Convolution28
I1006 21:21:50.649109  4081 net.cpp:122] Setting up Convolution28
I1006 21:21:50.649118  4081 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 21:21:50.649128  4081 net.cpp:137] Memory required for data: 633652400
I1006 21:21:50.649134  4081 layer_factory.hpp:77] Creating layer BatchNorm28
I1006 21:21:50.649139  4081 net.cpp:84] Creating Layer BatchNorm28
I1006 21:21:50.649142  4081 net.cpp:406] BatchNorm28 <- Convolution28
I1006 21:21:50.649147  4081 net.cpp:367] BatchNorm28 -> Convolution28 (in-place)
I1006 21:21:50.649299  4081 net.cpp:122] Setting up BatchNorm28
I1006 21:21:50.649303  4081 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 21:21:50.649305  4081 net.cpp:137] Memory required for data: 635290800
I1006 21:21:50.649310  4081 layer_factory.hpp:77] Creating layer Scale28
I1006 21:21:50.649314  4081 net.cpp:84] Creating Layer Scale28
I1006 21:21:50.649317  4081 net.cpp:406] Scale28 <- Convolution28
I1006 21:21:50.649320  4081 net.cpp:367] Scale28 -> Convolution28 (in-place)
I1006 21:21:50.649351  4081 layer_factory.hpp:77] Creating layer Scale28
I1006 21:21:50.649436  4081 net.cpp:122] Setting up Scale28
I1006 21:21:50.649441  4081 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 21:21:50.649443  4081 net.cpp:137] Memory required for data: 636929200
I1006 21:21:50.649446  4081 layer_factory.hpp:77] Creating layer penlu26
I1006 21:21:50.649452  4081 net.cpp:84] Creating Layer penlu26
I1006 21:21:50.649456  4081 net.cpp:406] penlu26 <- Convolution28
I1006 21:21:50.649458  4081 net.cpp:367] penlu26 -> Convolution28 (in-place)
I1006 21:21:50.649580  4081 net.cpp:122] Setting up penlu26
I1006 21:21:50.649585  4081 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 21:21:50.649586  4081 net.cpp:137] Memory required for data: 638567600
I1006 21:21:50.649591  4081 layer_factory.hpp:77] Creating layer Convolution29
I1006 21:21:50.649600  4081 net.cpp:84] Creating Layer Convolution29
I1006 21:21:50.649602  4081 net.cpp:406] Convolution29 <- Convolution28
I1006 21:21:50.649605  4081 net.cpp:380] Convolution29 -> Convolution29
I1006 21:21:50.655412  4081 net.cpp:122] Setting up Convolution29
I1006 21:21:50.655422  4081 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 21:21:50.655426  4081 net.cpp:137] Memory required for data: 640206000
I1006 21:21:50.655429  4081 layer_factory.hpp:77] Creating layer BatchNorm29
I1006 21:21:50.655434  4081 net.cpp:84] Creating Layer BatchNorm29
I1006 21:21:50.655436  4081 net.cpp:406] BatchNorm29 <- Convolution29
I1006 21:21:50.655441  4081 net.cpp:367] BatchNorm29 -> Convolution29 (in-place)
I1006 21:21:50.655592  4081 net.cpp:122] Setting up BatchNorm29
I1006 21:21:50.655596  4081 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 21:21:50.655599  4081 net.cpp:137] Memory required for data: 641844400
I1006 21:21:50.655603  4081 layer_factory.hpp:77] Creating layer Scale29
I1006 21:21:50.655607  4081 net.cpp:84] Creating Layer Scale29
I1006 21:21:50.655611  4081 net.cpp:406] Scale29 <- Convolution29
I1006 21:21:50.655613  4081 net.cpp:367] Scale29 -> Convolution29 (in-place)
I1006 21:21:50.655644  4081 layer_factory.hpp:77] Creating layer Scale29
I1006 21:21:50.655731  4081 net.cpp:122] Setting up Scale29
I1006 21:21:50.655735  4081 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 21:21:50.655738  4081 net.cpp:137] Memory required for data: 643482800
I1006 21:21:50.655741  4081 layer_factory.hpp:77] Creating layer Eltwise13
I1006 21:21:50.655745  4081 net.cpp:84] Creating Layer Eltwise13
I1006 21:21:50.655748  4081 net.cpp:406] Eltwise13 <- Eltwise12_penlu25_0_split_1
I1006 21:21:50.655751  4081 net.cpp:406] Eltwise13 <- Convolution29
I1006 21:21:50.655755  4081 net.cpp:380] Eltwise13 -> Eltwise13
I1006 21:21:50.655773  4081 net.cpp:122] Setting up Eltwise13
I1006 21:21:50.655777  4081 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 21:21:50.655779  4081 net.cpp:137] Memory required for data: 645121200
I1006 21:21:50.655781  4081 layer_factory.hpp:77] Creating layer penlu27
I1006 21:21:50.655786  4081 net.cpp:84] Creating Layer penlu27
I1006 21:21:50.655788  4081 net.cpp:406] penlu27 <- Eltwise13
I1006 21:21:50.655792  4081 net.cpp:367] penlu27 -> Eltwise13 (in-place)
I1006 21:21:50.655925  4081 net.cpp:122] Setting up penlu27
I1006 21:21:50.655930  4081 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 21:21:50.655931  4081 net.cpp:137] Memory required for data: 646759600
I1006 21:21:50.655936  4081 layer_factory.hpp:77] Creating layer Eltwise13_penlu27_0_split
I1006 21:21:50.655939  4081 net.cpp:84] Creating Layer Eltwise13_penlu27_0_split
I1006 21:21:50.655942  4081 net.cpp:406] Eltwise13_penlu27_0_split <- Eltwise13
I1006 21:21:50.655946  4081 net.cpp:380] Eltwise13_penlu27_0_split -> Eltwise13_penlu27_0_split_0
I1006 21:21:50.655949  4081 net.cpp:380] Eltwise13_penlu27_0_split -> Eltwise13_penlu27_0_split_1
I1006 21:21:50.655977  4081 net.cpp:122] Setting up Eltwise13_penlu27_0_split
I1006 21:21:50.655980  4081 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 21:21:50.655982  4081 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 21:21:50.655985  4081 net.cpp:137] Memory required for data: 650036400
I1006 21:21:50.655987  4081 layer_factory.hpp:77] Creating layer Convolution30
I1006 21:21:50.655992  4081 net.cpp:84] Creating Layer Convolution30
I1006 21:21:50.655994  4081 net.cpp:406] Convolution30 <- Eltwise13_penlu27_0_split_0
I1006 21:21:50.655999  4081 net.cpp:380] Convolution30 -> Convolution30
I1006 21:21:50.662288  4081 net.cpp:122] Setting up Convolution30
I1006 21:21:50.662297  4081 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 21:21:50.662300  4081 net.cpp:137] Memory required for data: 651674800
I1006 21:21:50.662305  4081 layer_factory.hpp:77] Creating layer BatchNorm30
I1006 21:21:50.662310  4081 net.cpp:84] Creating Layer BatchNorm30
I1006 21:21:50.662313  4081 net.cpp:406] BatchNorm30 <- Convolution30
I1006 21:21:50.662317  4081 net.cpp:367] BatchNorm30 -> Convolution30 (in-place)
I1006 21:21:50.662472  4081 net.cpp:122] Setting up BatchNorm30
I1006 21:21:50.662477  4081 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 21:21:50.662479  4081 net.cpp:137] Memory required for data: 653313200
I1006 21:21:50.662484  4081 layer_factory.hpp:77] Creating layer Scale30
I1006 21:21:50.662488  4081 net.cpp:84] Creating Layer Scale30
I1006 21:21:50.662492  4081 net.cpp:406] Scale30 <- Convolution30
I1006 21:21:50.662494  4081 net.cpp:367] Scale30 -> Convolution30 (in-place)
I1006 21:21:50.662528  4081 layer_factory.hpp:77] Creating layer Scale30
I1006 21:21:50.662616  4081 net.cpp:122] Setting up Scale30
I1006 21:21:50.662621  4081 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 21:21:50.662622  4081 net.cpp:137] Memory required for data: 654951600
I1006 21:21:50.662626  4081 layer_factory.hpp:77] Creating layer penlu28
I1006 21:21:50.662632  4081 net.cpp:84] Creating Layer penlu28
I1006 21:21:50.662634  4081 net.cpp:406] penlu28 <- Convolution30
I1006 21:21:50.662637  4081 net.cpp:367] penlu28 -> Convolution30 (in-place)
I1006 21:21:50.662760  4081 net.cpp:122] Setting up penlu28
I1006 21:21:50.662763  4081 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 21:21:50.662765  4081 net.cpp:137] Memory required for data: 656590000
I1006 21:21:50.662770  4081 layer_factory.hpp:77] Creating layer Convolution31
I1006 21:21:50.662776  4081 net.cpp:84] Creating Layer Convolution31
I1006 21:21:50.662780  4081 net.cpp:406] Convolution31 <- Convolution30
I1006 21:21:50.662782  4081 net.cpp:380] Convolution31 -> Convolution31
I1006 21:21:50.668607  4081 net.cpp:122] Setting up Convolution31
I1006 21:21:50.668617  4081 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 21:21:50.668619  4081 net.cpp:137] Memory required for data: 658228400
I1006 21:21:50.668624  4081 layer_factory.hpp:77] Creating layer BatchNorm31
I1006 21:21:50.668629  4081 net.cpp:84] Creating Layer BatchNorm31
I1006 21:21:50.668632  4081 net.cpp:406] BatchNorm31 <- Convolution31
I1006 21:21:50.668637  4081 net.cpp:367] BatchNorm31 -> Convolution31 (in-place)
I1006 21:21:50.668792  4081 net.cpp:122] Setting up BatchNorm31
I1006 21:21:50.668797  4081 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 21:21:50.668799  4081 net.cpp:137] Memory required for data: 659866800
I1006 21:21:50.668803  4081 layer_factory.hpp:77] Creating layer Scale31
I1006 21:21:50.668815  4081 net.cpp:84] Creating Layer Scale31
I1006 21:21:50.668818  4081 net.cpp:406] Scale31 <- Convolution31
I1006 21:21:50.668823  4081 net.cpp:367] Scale31 -> Convolution31 (in-place)
I1006 21:21:50.668855  4081 layer_factory.hpp:77] Creating layer Scale31
I1006 21:21:50.668946  4081 net.cpp:122] Setting up Scale31
I1006 21:21:50.668951  4081 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 21:21:50.668953  4081 net.cpp:137] Memory required for data: 661505200
I1006 21:21:50.668961  4081 layer_factory.hpp:77] Creating layer Eltwise14
I1006 21:21:50.668967  4081 net.cpp:84] Creating Layer Eltwise14
I1006 21:21:50.668972  4081 net.cpp:406] Eltwise14 <- Eltwise13_penlu27_0_split_1
I1006 21:21:50.668977  4081 net.cpp:406] Eltwise14 <- Convolution31
I1006 21:21:50.668982  4081 net.cpp:380] Eltwise14 -> Eltwise14
I1006 21:21:50.669008  4081 net.cpp:122] Setting up Eltwise14
I1006 21:21:50.669024  4081 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 21:21:50.669028  4081 net.cpp:137] Memory required for data: 663143600
I1006 21:21:50.669031  4081 layer_factory.hpp:77] Creating layer penlu29
I1006 21:21:50.669049  4081 net.cpp:84] Creating Layer penlu29
I1006 21:21:50.669054  4081 net.cpp:406] penlu29 <- Eltwise14
I1006 21:21:50.669059  4081 net.cpp:367] penlu29 -> Eltwise14 (in-place)
I1006 21:21:50.669198  4081 net.cpp:122] Setting up penlu29
I1006 21:21:50.669203  4081 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 21:21:50.669205  4081 net.cpp:137] Memory required for data: 664782000
I1006 21:21:50.669210  4081 layer_factory.hpp:77] Creating layer Eltwise14_penlu29_0_split
I1006 21:21:50.669214  4081 net.cpp:84] Creating Layer Eltwise14_penlu29_0_split
I1006 21:21:50.669216  4081 net.cpp:406] Eltwise14_penlu29_0_split <- Eltwise14
I1006 21:21:50.669220  4081 net.cpp:380] Eltwise14_penlu29_0_split -> Eltwise14_penlu29_0_split_0
I1006 21:21:50.669226  4081 net.cpp:380] Eltwise14_penlu29_0_split -> Eltwise14_penlu29_0_split_1
I1006 21:21:50.669255  4081 net.cpp:122] Setting up Eltwise14_penlu29_0_split
I1006 21:21:50.669258  4081 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 21:21:50.669260  4081 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 21:21:50.669262  4081 net.cpp:137] Memory required for data: 668058800
I1006 21:21:50.669265  4081 layer_factory.hpp:77] Creating layer Convolution32
I1006 21:21:50.669271  4081 net.cpp:84] Creating Layer Convolution32
I1006 21:21:50.669275  4081 net.cpp:406] Convolution32 <- Eltwise14_penlu29_0_split_0
I1006 21:21:50.669278  4081 net.cpp:380] Convolution32 -> Convolution32
I1006 21:21:50.676123  4081 net.cpp:122] Setting up Convolution32
I1006 21:21:50.676132  4081 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 21:21:50.676136  4081 net.cpp:137] Memory required for data: 669697200
I1006 21:21:50.676141  4081 layer_factory.hpp:77] Creating layer BatchNorm32
I1006 21:21:50.676146  4081 net.cpp:84] Creating Layer BatchNorm32
I1006 21:21:50.676148  4081 net.cpp:406] BatchNorm32 <- Convolution32
I1006 21:21:50.676152  4081 net.cpp:367] BatchNorm32 -> Convolution32 (in-place)
I1006 21:21:50.676307  4081 net.cpp:122] Setting up BatchNorm32
I1006 21:21:50.676312  4081 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 21:21:50.676314  4081 net.cpp:137] Memory required for data: 671335600
I1006 21:21:50.676319  4081 layer_factory.hpp:77] Creating layer Scale32
I1006 21:21:50.676323  4081 net.cpp:84] Creating Layer Scale32
I1006 21:21:50.676326  4081 net.cpp:406] Scale32 <- Convolution32
I1006 21:21:50.676328  4081 net.cpp:367] Scale32 -> Convolution32 (in-place)
I1006 21:21:50.676359  4081 layer_factory.hpp:77] Creating layer Scale32
I1006 21:21:50.676447  4081 net.cpp:122] Setting up Scale32
I1006 21:21:50.676452  4081 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 21:21:50.676455  4081 net.cpp:137] Memory required for data: 672974000
I1006 21:21:50.676457  4081 layer_factory.hpp:77] Creating layer penlu30
I1006 21:21:50.676462  4081 net.cpp:84] Creating Layer penlu30
I1006 21:21:50.676465  4081 net.cpp:406] penlu30 <- Convolution32
I1006 21:21:50.676476  4081 net.cpp:367] penlu30 -> Convolution32 (in-place)
I1006 21:21:50.676600  4081 net.cpp:122] Setting up penlu30
I1006 21:21:50.676605  4081 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 21:21:50.676607  4081 net.cpp:137] Memory required for data: 674612400
I1006 21:21:50.676611  4081 layer_factory.hpp:77] Creating layer Convolution33
I1006 21:21:50.676618  4081 net.cpp:84] Creating Layer Convolution33
I1006 21:21:50.676621  4081 net.cpp:406] Convolution33 <- Convolution32
I1006 21:21:50.676625  4081 net.cpp:380] Convolution33 -> Convolution33
I1006 21:21:50.681143  4081 net.cpp:122] Setting up Convolution33
I1006 21:21:50.681151  4081 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 21:21:50.681154  4081 net.cpp:137] Memory required for data: 676250800
I1006 21:21:50.681159  4081 layer_factory.hpp:77] Creating layer BatchNorm33
I1006 21:21:50.681164  4081 net.cpp:84] Creating Layer BatchNorm33
I1006 21:21:50.681166  4081 net.cpp:406] BatchNorm33 <- Convolution33
I1006 21:21:50.681169  4081 net.cpp:367] BatchNorm33 -> Convolution33 (in-place)
I1006 21:21:50.681321  4081 net.cpp:122] Setting up BatchNorm33
I1006 21:21:50.681326  4081 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 21:21:50.681329  4081 net.cpp:137] Memory required for data: 677889200
I1006 21:21:50.681334  4081 layer_factory.hpp:77] Creating layer Scale33
I1006 21:21:50.681336  4081 net.cpp:84] Creating Layer Scale33
I1006 21:21:50.681339  4081 net.cpp:406] Scale33 <- Convolution33
I1006 21:21:50.681342  4081 net.cpp:367] Scale33 -> Convolution33 (in-place)
I1006 21:21:50.681375  4081 layer_factory.hpp:77] Creating layer Scale33
I1006 21:21:50.681462  4081 net.cpp:122] Setting up Scale33
I1006 21:21:50.681466  4081 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 21:21:50.681468  4081 net.cpp:137] Memory required for data: 679527600
I1006 21:21:50.681473  4081 layer_factory.hpp:77] Creating layer Eltwise15
I1006 21:21:50.681476  4081 net.cpp:84] Creating Layer Eltwise15
I1006 21:21:50.681479  4081 net.cpp:406] Eltwise15 <- Eltwise14_penlu29_0_split_1
I1006 21:21:50.681483  4081 net.cpp:406] Eltwise15 <- Convolution33
I1006 21:21:50.681485  4081 net.cpp:380] Eltwise15 -> Eltwise15
I1006 21:21:50.681504  4081 net.cpp:122] Setting up Eltwise15
I1006 21:21:50.681509  4081 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 21:21:50.681510  4081 net.cpp:137] Memory required for data: 681166000
I1006 21:21:50.681512  4081 layer_factory.hpp:77] Creating layer penlu31
I1006 21:21:50.681517  4081 net.cpp:84] Creating Layer penlu31
I1006 21:21:50.681520  4081 net.cpp:406] penlu31 <- Eltwise15
I1006 21:21:50.681524  4081 net.cpp:367] penlu31 -> Eltwise15 (in-place)
I1006 21:21:50.681645  4081 net.cpp:122] Setting up penlu31
I1006 21:21:50.681650  4081 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1006 21:21:50.681653  4081 net.cpp:137] Memory required for data: 682804400
I1006 21:21:50.681656  4081 layer_factory.hpp:77] Creating layer Pooling1
I1006 21:21:50.681663  4081 net.cpp:84] Creating Layer Pooling1
I1006 21:21:50.681664  4081 net.cpp:406] Pooling1 <- Eltwise15
I1006 21:21:50.681668  4081 net.cpp:380] Pooling1 -> Pooling1
I1006 21:21:50.681808  4081 net.cpp:122] Setting up Pooling1
I1006 21:21:50.681814  4081 net.cpp:129] Top shape: 100 64 1 1 (6400)
I1006 21:21:50.681816  4081 net.cpp:137] Memory required for data: 682830000
I1006 21:21:50.681818  4081 layer_factory.hpp:77] Creating layer InnerProduct1
I1006 21:21:50.681823  4081 net.cpp:84] Creating Layer InnerProduct1
I1006 21:21:50.681826  4081 net.cpp:406] InnerProduct1 <- Pooling1
I1006 21:21:50.681831  4081 net.cpp:380] InnerProduct1 -> InnerProduct1
I1006 21:21:50.681939  4081 net.cpp:122] Setting up InnerProduct1
I1006 21:21:50.681943  4081 net.cpp:129] Top shape: 100 10 (1000)
I1006 21:21:50.681946  4081 net.cpp:137] Memory required for data: 682834000
I1006 21:21:50.681949  4081 layer_factory.hpp:77] Creating layer InnerProduct1_InnerProduct1_0_split
I1006 21:21:50.681954  4081 net.cpp:84] Creating Layer InnerProduct1_InnerProduct1_0_split
I1006 21:21:50.681957  4081 net.cpp:406] InnerProduct1_InnerProduct1_0_split <- InnerProduct1
I1006 21:21:50.681967  4081 net.cpp:380] InnerProduct1_InnerProduct1_0_split -> InnerProduct1_InnerProduct1_0_split_0
I1006 21:21:50.681972  4081 net.cpp:380] InnerProduct1_InnerProduct1_0_split -> InnerProduct1_InnerProduct1_0_split_1
I1006 21:21:50.682001  4081 net.cpp:122] Setting up InnerProduct1_InnerProduct1_0_split
I1006 21:21:50.682005  4081 net.cpp:129] Top shape: 100 10 (1000)
I1006 21:21:50.682008  4081 net.cpp:129] Top shape: 100 10 (1000)
I1006 21:21:50.682010  4081 net.cpp:137] Memory required for data: 682842000
I1006 21:21:50.682013  4081 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I1006 21:21:50.682016  4081 net.cpp:84] Creating Layer SoftmaxWithLoss1
I1006 21:21:50.682019  4081 net.cpp:406] SoftmaxWithLoss1 <- InnerProduct1_InnerProduct1_0_split_0
I1006 21:21:50.682021  4081 net.cpp:406] SoftmaxWithLoss1 <- Data2_Data1_1_split_0
I1006 21:21:50.682025  4081 net.cpp:380] SoftmaxWithLoss1 -> SoftmaxWithLoss1
I1006 21:21:50.682029  4081 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I1006 21:21:50.682555  4081 net.cpp:122] Setting up SoftmaxWithLoss1
I1006 21:21:50.682564  4081 net.cpp:129] Top shape: (1)
I1006 21:21:50.682566  4081 net.cpp:132]     with loss weight 1
I1006 21:21:50.682574  4081 net.cpp:137] Memory required for data: 682842004
I1006 21:21:50.682576  4081 layer_factory.hpp:77] Creating layer Accuracy1
I1006 21:21:50.682581  4081 net.cpp:84] Creating Layer Accuracy1
I1006 21:21:50.682585  4081 net.cpp:406] Accuracy1 <- InnerProduct1_InnerProduct1_0_split_1
I1006 21:21:50.682587  4081 net.cpp:406] Accuracy1 <- Data2_Data1_1_split_1
I1006 21:21:50.682601  4081 net.cpp:380] Accuracy1 -> Accuracy1
I1006 21:21:50.682608  4081 net.cpp:122] Setting up Accuracy1
I1006 21:21:50.682611  4081 net.cpp:129] Top shape: (1)
I1006 21:21:50.682613  4081 net.cpp:137] Memory required for data: 682842008
I1006 21:21:50.682615  4081 net.cpp:200] Accuracy1 does not need backward computation.
I1006 21:21:50.682617  4081 net.cpp:198] SoftmaxWithLoss1 needs backward computation.
I1006 21:21:50.682621  4081 net.cpp:198] InnerProduct1_InnerProduct1_0_split needs backward computation.
I1006 21:21:50.682632  4081 net.cpp:198] InnerProduct1 needs backward computation.
I1006 21:21:50.682634  4081 net.cpp:198] Pooling1 needs backward computation.
I1006 21:21:50.682637  4081 net.cpp:198] penlu31 needs backward computation.
I1006 21:21:50.682639  4081 net.cpp:198] Eltwise15 needs backward computation.
I1006 21:21:50.682641  4081 net.cpp:198] Scale33 needs backward computation.
I1006 21:21:50.682643  4081 net.cpp:198] BatchNorm33 needs backward computation.
I1006 21:21:50.682646  4081 net.cpp:198] Convolution33 needs backward computation.
I1006 21:21:50.682647  4081 net.cpp:198] penlu30 needs backward computation.
I1006 21:21:50.682649  4081 net.cpp:198] Scale32 needs backward computation.
I1006 21:21:50.682651  4081 net.cpp:198] BatchNorm32 needs backward computation.
I1006 21:21:50.682663  4081 net.cpp:198] Convolution32 needs backward computation.
I1006 21:21:50.682665  4081 net.cpp:198] Eltwise14_penlu29_0_split needs backward computation.
I1006 21:21:50.682668  4081 net.cpp:198] penlu29 needs backward computation.
I1006 21:21:50.682670  4081 net.cpp:198] Eltwise14 needs backward computation.
I1006 21:21:50.682672  4081 net.cpp:198] Scale31 needs backward computation.
I1006 21:21:50.682674  4081 net.cpp:198] BatchNorm31 needs backward computation.
I1006 21:21:50.682677  4081 net.cpp:198] Convolution31 needs backward computation.
I1006 21:21:50.682679  4081 net.cpp:198] penlu28 needs backward computation.
I1006 21:21:50.682682  4081 net.cpp:198] Scale30 needs backward computation.
I1006 21:21:50.682683  4081 net.cpp:198] BatchNorm30 needs backward computation.
I1006 21:21:50.682685  4081 net.cpp:198] Convolution30 needs backward computation.
I1006 21:21:50.682687  4081 net.cpp:198] Eltwise13_penlu27_0_split needs backward computation.
I1006 21:21:50.682689  4081 net.cpp:198] penlu27 needs backward computation.
I1006 21:21:50.682693  4081 net.cpp:198] Eltwise13 needs backward computation.
I1006 21:21:50.682700  4081 net.cpp:198] Scale29 needs backward computation.
I1006 21:21:50.682703  4081 net.cpp:198] BatchNorm29 needs backward computation.
I1006 21:21:50.682705  4081 net.cpp:198] Convolution29 needs backward computation.
I1006 21:21:50.682708  4081 net.cpp:198] penlu26 needs backward computation.
I1006 21:21:50.682710  4081 net.cpp:198] Scale28 needs backward computation.
I1006 21:21:50.682713  4081 net.cpp:198] BatchNorm28 needs backward computation.
I1006 21:21:50.682714  4081 net.cpp:198] Convolution28 needs backward computation.
I1006 21:21:50.682716  4081 net.cpp:198] Eltwise12_penlu25_0_split needs backward computation.
I1006 21:21:50.682718  4081 net.cpp:198] penlu25 needs backward computation.
I1006 21:21:50.682721  4081 net.cpp:198] Eltwise12 needs backward computation.
I1006 21:21:50.682723  4081 net.cpp:198] Scale27 needs backward computation.
I1006 21:21:50.682725  4081 net.cpp:198] BatchNorm27 needs backward computation.
I1006 21:21:50.682729  4081 net.cpp:198] Convolution27 needs backward computation.
I1006 21:21:50.682730  4081 net.cpp:198] penlu24 needs backward computation.
I1006 21:21:50.682732  4081 net.cpp:198] Scale26 needs backward computation.
I1006 21:21:50.682734  4081 net.cpp:198] BatchNorm26 needs backward computation.
I1006 21:21:50.682736  4081 net.cpp:198] Convolution26 needs backward computation.
I1006 21:21:50.682739  4081 net.cpp:198] Eltwise11_penlu23_0_split needs backward computation.
I1006 21:21:50.682741  4081 net.cpp:198] penlu23 needs backward computation.
I1006 21:21:50.682744  4081 net.cpp:198] Eltwise11 needs backward computation.
I1006 21:21:50.682746  4081 net.cpp:198] Scale25 needs backward computation.
I1006 21:21:50.682749  4081 net.cpp:198] BatchNorm25 needs backward computation.
I1006 21:21:50.682750  4081 net.cpp:198] Convolution25 needs backward computation.
I1006 21:21:50.682754  4081 net.cpp:198] penlu22 needs backward computation.
I1006 21:21:50.682755  4081 net.cpp:198] Scale24 needs backward computation.
I1006 21:21:50.682757  4081 net.cpp:198] BatchNorm24 needs backward computation.
I1006 21:21:50.682760  4081 net.cpp:198] Convolution24 needs backward computation.
I1006 21:21:50.682762  4081 net.cpp:198] Scale23 needs backward computation.
I1006 21:21:50.682765  4081 net.cpp:198] BatchNorm23 needs backward computation.
I1006 21:21:50.682766  4081 net.cpp:198] Convolution23 needs backward computation.
I1006 21:21:50.682768  4081 net.cpp:198] Eltwise10_penlu21_0_split needs backward computation.
I1006 21:21:50.682771  4081 net.cpp:198] penlu21 needs backward computation.
I1006 21:21:50.682773  4081 net.cpp:198] Eltwise10 needs backward computation.
I1006 21:21:50.682776  4081 net.cpp:198] Scale22 needs backward computation.
I1006 21:21:50.682778  4081 net.cpp:198] BatchNorm22 needs backward computation.
I1006 21:21:50.682780  4081 net.cpp:198] Convolution22 needs backward computation.
I1006 21:21:50.682783  4081 net.cpp:198] penlu20 needs backward computation.
I1006 21:21:50.682785  4081 net.cpp:198] Scale21 needs backward computation.
I1006 21:21:50.682787  4081 net.cpp:198] BatchNorm21 needs backward computation.
I1006 21:21:50.682790  4081 net.cpp:198] Convolution21 needs backward computation.
I1006 21:21:50.682792  4081 net.cpp:198] Eltwise9_penlu19_0_split needs backward computation.
I1006 21:21:50.682795  4081 net.cpp:198] penlu19 needs backward computation.
I1006 21:21:50.682797  4081 net.cpp:198] Eltwise9 needs backward computation.
I1006 21:21:50.682801  4081 net.cpp:198] Scale20 needs backward computation.
I1006 21:21:50.682803  4081 net.cpp:198] BatchNorm20 needs backward computation.
I1006 21:21:50.682806  4081 net.cpp:198] Convolution20 needs backward computation.
I1006 21:21:50.682808  4081 net.cpp:198] penlu18 needs backward computation.
I1006 21:21:50.682811  4081 net.cpp:198] Scale19 needs backward computation.
I1006 21:21:50.682813  4081 net.cpp:198] BatchNorm19 needs backward computation.
I1006 21:21:50.682816  4081 net.cpp:198] Convolution19 needs backward computation.
I1006 21:21:50.682822  4081 net.cpp:198] Eltwise8_penlu17_0_split needs backward computation.
I1006 21:21:50.682826  4081 net.cpp:198] penlu17 needs backward computation.
I1006 21:21:50.682827  4081 net.cpp:198] Eltwise8 needs backward computation.
I1006 21:21:50.682831  4081 net.cpp:198] Scale18 needs backward computation.
I1006 21:21:50.682832  4081 net.cpp:198] BatchNorm18 needs backward computation.
I1006 21:21:50.682835  4081 net.cpp:198] Convolution18 needs backward computation.
I1006 21:21:50.682837  4081 net.cpp:198] penlu16 needs backward computation.
I1006 21:21:50.682839  4081 net.cpp:198] Scale17 needs backward computation.
I1006 21:21:50.682842  4081 net.cpp:198] BatchNorm17 needs backward computation.
I1006 21:21:50.682844  4081 net.cpp:198] Convolution17 needs backward computation.
I1006 21:21:50.682847  4081 net.cpp:198] Eltwise7_penlu15_0_split needs backward computation.
I1006 21:21:50.682849  4081 net.cpp:198] penlu15 needs backward computation.
I1006 21:21:50.682852  4081 net.cpp:198] Eltwise7 needs backward computation.
I1006 21:21:50.682854  4081 net.cpp:198] Scale16 needs backward computation.
I1006 21:21:50.682857  4081 net.cpp:198] BatchNorm16 needs backward computation.
I1006 21:21:50.682859  4081 net.cpp:198] Convolution16 needs backward computation.
I1006 21:21:50.682862  4081 net.cpp:198] penlu14 needs backward computation.
I1006 21:21:50.682863  4081 net.cpp:198] Scale15 needs backward computation.
I1006 21:21:50.682867  4081 net.cpp:198] BatchNorm15 needs backward computation.
I1006 21:21:50.682868  4081 net.cpp:198] Convolution15 needs backward computation.
I1006 21:21:50.682870  4081 net.cpp:198] Eltwise6_penlu13_0_split needs backward computation.
I1006 21:21:50.682873  4081 net.cpp:198] penlu13 needs backward computation.
I1006 21:21:50.682875  4081 net.cpp:198] Eltwise6 needs backward computation.
I1006 21:21:50.682878  4081 net.cpp:198] Scale14 needs backward computation.
I1006 21:21:50.682880  4081 net.cpp:198] BatchNorm14 needs backward computation.
I1006 21:21:50.682883  4081 net.cpp:198] Convolution14 needs backward computation.
I1006 21:21:50.682885  4081 net.cpp:198] penlu12 needs backward computation.
I1006 21:21:50.682888  4081 net.cpp:198] Scale13 needs backward computation.
I1006 21:21:50.682890  4081 net.cpp:198] BatchNorm13 needs backward computation.
I1006 21:21:50.682893  4081 net.cpp:198] Convolution13 needs backward computation.
I1006 21:21:50.682895  4081 net.cpp:198] Scale12 needs backward computation.
I1006 21:21:50.682898  4081 net.cpp:198] BatchNorm12 needs backward computation.
I1006 21:21:50.682899  4081 net.cpp:198] Convolution12 needs backward computation.
I1006 21:21:50.682902  4081 net.cpp:198] Eltwise5_penlu11_0_split needs backward computation.
I1006 21:21:50.682904  4081 net.cpp:198] penlu11 needs backward computation.
I1006 21:21:50.682906  4081 net.cpp:198] Eltwise5 needs backward computation.
I1006 21:21:50.682909  4081 net.cpp:198] Scale11 needs backward computation.
I1006 21:21:50.682912  4081 net.cpp:198] BatchNorm11 needs backward computation.
I1006 21:21:50.682914  4081 net.cpp:198] Convolution11 needs backward computation.
I1006 21:21:50.682916  4081 net.cpp:198] penlu10 needs backward computation.
I1006 21:21:50.682919  4081 net.cpp:198] Scale10 needs backward computation.
I1006 21:21:50.682921  4081 net.cpp:198] BatchNorm10 needs backward computation.
I1006 21:21:50.682924  4081 net.cpp:198] Convolution10 needs backward computation.
I1006 21:21:50.682926  4081 net.cpp:198] Eltwise4_penlu9_0_split needs backward computation.
I1006 21:21:50.682929  4081 net.cpp:198] penlu9 needs backward computation.
I1006 21:21:50.682930  4081 net.cpp:198] Eltwise4 needs backward computation.
I1006 21:21:50.682934  4081 net.cpp:198] Scale9 needs backward computation.
I1006 21:21:50.682936  4081 net.cpp:198] BatchNorm9 needs backward computation.
I1006 21:21:50.682938  4081 net.cpp:198] Convolution9 needs backward computation.
I1006 21:21:50.682941  4081 net.cpp:198] penlu8 needs backward computation.
I1006 21:21:50.682943  4081 net.cpp:198] Scale8 needs backward computation.
I1006 21:21:50.682950  4081 net.cpp:198] BatchNorm8 needs backward computation.
I1006 21:21:50.682951  4081 net.cpp:198] Convolution8 needs backward computation.
I1006 21:21:50.682955  4081 net.cpp:198] Eltwise3_penlu7_0_split needs backward computation.
I1006 21:21:50.682957  4081 net.cpp:198] penlu7 needs backward computation.
I1006 21:21:50.682960  4081 net.cpp:198] Eltwise3 needs backward computation.
I1006 21:21:50.682962  4081 net.cpp:198] Scale7 needs backward computation.
I1006 21:21:50.682965  4081 net.cpp:198] BatchNorm7 needs backward computation.
I1006 21:21:50.682967  4081 net.cpp:198] Convolution7 needs backward computation.
I1006 21:21:50.682970  4081 net.cpp:198] penlu6 needs backward computation.
I1006 21:21:50.682971  4081 net.cpp:198] Scale6 needs backward computation.
I1006 21:21:50.682973  4081 net.cpp:198] BatchNorm6 needs backward computation.
I1006 21:21:50.682976  4081 net.cpp:198] Convolution6 needs backward computation.
I1006 21:21:50.682978  4081 net.cpp:198] Eltwise2_penlu5_0_split needs backward computation.
I1006 21:21:50.682981  4081 net.cpp:198] penlu5 needs backward computation.
I1006 21:21:50.682983  4081 net.cpp:198] Eltwise2 needs backward computation.
I1006 21:21:50.682986  4081 net.cpp:198] Scale5 needs backward computation.
I1006 21:21:50.682988  4081 net.cpp:198] BatchNorm5 needs backward computation.
I1006 21:21:50.682991  4081 net.cpp:198] Convolution5 needs backward computation.
I1006 21:21:50.682993  4081 net.cpp:198] penlu4 needs backward computation.
I1006 21:21:50.682996  4081 net.cpp:198] Scale4 needs backward computation.
I1006 21:21:50.682997  4081 net.cpp:198] BatchNorm4 needs backward computation.
I1006 21:21:50.682999  4081 net.cpp:198] Convolution4 needs backward computation.
I1006 21:21:50.683002  4081 net.cpp:198] Eltwise1_penlu3_0_split needs backward computation.
I1006 21:21:50.683004  4081 net.cpp:198] penlu3 needs backward computation.
I1006 21:21:50.683007  4081 net.cpp:198] Eltwise1 needs backward computation.
I1006 21:21:50.683010  4081 net.cpp:198] Scale3 needs backward computation.
I1006 21:21:50.683012  4081 net.cpp:198] BatchNorm3 needs backward computation.
I1006 21:21:50.683015  4081 net.cpp:198] Convolution3 needs backward computation.
I1006 21:21:50.683017  4081 net.cpp:198] penlu2 needs backward computation.
I1006 21:21:50.683020  4081 net.cpp:198] Scale2 needs backward computation.
I1006 21:21:50.683022  4081 net.cpp:198] BatchNorm2 needs backward computation.
I1006 21:21:50.683024  4081 net.cpp:198] Convolution2 needs backward computation.
I1006 21:21:50.683027  4081 net.cpp:198] Convolution1_penlu1_0_split needs backward computation.
I1006 21:21:50.683029  4081 net.cpp:198] penlu1 needs backward computation.
I1006 21:21:50.683032  4081 net.cpp:198] Scale1 needs backward computation.
I1006 21:21:50.683034  4081 net.cpp:198] BatchNorm1 needs backward computation.
I1006 21:21:50.683037  4081 net.cpp:198] Convolution1 needs backward computation.
I1006 21:21:50.683039  4081 net.cpp:200] Data2_Data1_1_split does not need backward computation.
I1006 21:21:50.683043  4081 net.cpp:200] Data1 does not need backward computation.
I1006 21:21:50.683044  4081 net.cpp:242] This network produces output Accuracy1
I1006 21:21:50.683048  4081 net.cpp:242] This network produces output SoftmaxWithLoss1
I1006 21:21:50.683109  4081 net.cpp:255] Network initialization done.
I1006 21:21:50.683763  4081 solver.cpp:56] Solver scaffolding done.
I1006 21:21:50.692358  4081 caffe.cpp:248] Starting Optimization
I1006 21:21:50.692365  4081 solver.cpp:272] Solving resnet_cifar10
I1006 21:21:50.692368  4081 solver.cpp:273] Learning Rate Policy: multistep
I1006 21:21:50.695878  4081 solver.cpp:330] Iteration 0, Testing net (#0)
I1006 21:21:54.811378  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:21:54.958834  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.1
I1006 21:21:54.958861  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 87.3365 (* 1 = 87.3365 loss)
I1006 21:21:55.395354  4081 solver.cpp:218] Iteration 0 (-5.35575e-33 iter/s, 4.70205s/100 iters), loss = 2.29703
I1006 21:21:55.395409  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 2.29703 (* 1 = 2.29703 loss)
I1006 21:21:55.395444  4081 sgd_solver.cpp:105] Iteration 0, lr = 0.1
I1006 21:22:12.873903  4081 solver.cpp:218] Iteration 100 (5.72205 iter/s, 17.4762s/100 iters), loss = 1.6474
I1006 21:22:12.873944  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.6474 (* 1 = 1.6474 loss)
I1006 21:22:12.873950  4081 sgd_solver.cpp:105] Iteration 100, lr = 0.1
I1006 21:22:30.021895  4081 solver.cpp:218] Iteration 200 (5.83162 iter/s, 17.1479s/100 iters), loss = 1.55351
I1006 21:22:30.021986  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.55351 (* 1 = 1.55351 loss)
I1006 21:22:30.021993  4081 sgd_solver.cpp:105] Iteration 200, lr = 0.1
I1006 21:22:47.124919  4081 solver.cpp:218] Iteration 300 (5.84697 iter/s, 17.1029s/100 iters), loss = 1.379
I1006 21:22:47.124953  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.379 (* 1 = 1.379 loss)
I1006 21:22:47.124969  4081 sgd_solver.cpp:105] Iteration 300, lr = 0.1
I1006 21:23:04.200364  4081 solver.cpp:218] Iteration 400 (5.8564 iter/s, 17.0753s/100 iters), loss = 1.06949
I1006 21:23:04.200484  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.06949 (* 1 = 1.06949 loss)
I1006 21:23:04.200502  4081 sgd_solver.cpp:105] Iteration 400, lr = 0.1
I1006 21:23:20.946475  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:23:21.627384  4081 solver.cpp:330] Iteration 500, Testing net (#0)
I1006 21:23:25.232759  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:23:25.364969  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.3623
I1006 21:23:25.364996  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 2.60727 (* 1 = 2.60727 loss)
I1006 21:23:25.488385  4081 solver.cpp:218] Iteration 500 (4.69752 iter/s, 21.2878s/100 iters), loss = 1.22119
I1006 21:23:25.488411  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.22119 (* 1 = 1.22119 loss)
I1006 21:23:25.488427  4081 sgd_solver.cpp:105] Iteration 500, lr = 0.1
I1006 21:23:42.627871  4081 solver.cpp:218] Iteration 600 (5.83452 iter/s, 17.1394s/100 iters), loss = 1.04276
I1006 21:23:42.627939  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.04276 (* 1 = 1.04276 loss)
I1006 21:23:42.627959  4081 sgd_solver.cpp:105] Iteration 600, lr = 0.1
I1006 21:23:59.696787  4081 solver.cpp:218] Iteration 700 (5.85865 iter/s, 17.0688s/100 iters), loss = 1.06235
I1006 21:23:59.696828  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.06235 (* 1 = 1.06235 loss)
I1006 21:23:59.696835  4081 sgd_solver.cpp:105] Iteration 700, lr = 0.1
I1006 21:24:16.764011  4081 solver.cpp:218] Iteration 800 (5.85922 iter/s, 17.0671s/100 iters), loss = 1.05038
I1006 21:24:16.764076  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.05038 (* 1 = 1.05038 loss)
I1006 21:24:16.764097  4081 sgd_solver.cpp:105] Iteration 800, lr = 0.1
I1006 21:24:33.823037  4081 solver.cpp:218] Iteration 900 (5.86205 iter/s, 17.0589s/100 iters), loss = 0.820062
I1006 21:24:33.823079  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.820062 (* 1 = 0.820062 loss)
I1006 21:24:33.823086  4081 sgd_solver.cpp:105] Iteration 900, lr = 0.1
I1006 21:24:50.585338  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:24:51.267158  4081 solver.cpp:330] Iteration 1000, Testing net (#0)
I1006 21:24:54.842754  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:24:54.972352  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.3389
I1006 21:24:54.972388  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 3.32041 (* 1 = 3.32041 loss)
I1006 21:24:55.119240  4081 solver.cpp:218] Iteration 1000 (4.6957 iter/s, 21.2961s/100 iters), loss = 0.860415
I1006 21:24:55.119278  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.860415 (* 1 = 0.860415 loss)
I1006 21:24:55.119285  4081 sgd_solver.cpp:105] Iteration 1000, lr = 0.1
I1006 21:25:12.188062  4081 solver.cpp:218] Iteration 1100 (5.85867 iter/s, 17.0687s/100 iters), loss = 0.779354
I1006 21:25:12.188094  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.779354 (* 1 = 0.779354 loss)
I1006 21:25:12.188112  4081 sgd_solver.cpp:105] Iteration 1100, lr = 0.1
I1006 21:25:29.257225  4081 solver.cpp:218] Iteration 1200 (5.85855 iter/s, 17.0691s/100 iters), loss = 0.75949
I1006 21:25:29.257364  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.75949 (* 1 = 0.75949 loss)
I1006 21:25:29.257382  4081 sgd_solver.cpp:105] Iteration 1200, lr = 0.1
I1006 21:25:46.339447  4081 solver.cpp:218] Iteration 1300 (5.85411 iter/s, 17.082s/100 iters), loss = 0.794187
I1006 21:25:46.339489  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.794187 (* 1 = 0.794187 loss)
I1006 21:25:46.339496  4081 sgd_solver.cpp:105] Iteration 1300, lr = 0.1
I1006 21:26:03.410468  4081 solver.cpp:218] Iteration 1400 (5.85792 iter/s, 17.0709s/100 iters), loss = 0.735715
I1006 21:26:03.410576  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.735715 (* 1 = 0.735715 loss)
I1006 21:26:03.410584  4081 sgd_solver.cpp:105] Iteration 1400, lr = 0.1
I1006 21:26:20.169378  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:26:20.851352  4081 solver.cpp:330] Iteration 1500, Testing net (#0)
I1006 21:26:24.448575  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:26:24.615330  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.5057
I1006 21:26:24.615367  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.86276 (* 1 = 1.86276 loss)
I1006 21:26:24.716954  4081 solver.cpp:218] Iteration 1500 (4.69345 iter/s, 21.3063s/100 iters), loss = 0.7219
I1006 21:26:24.716984  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.7219 (* 1 = 0.7219 loss)
I1006 21:26:24.717002  4081 sgd_solver.cpp:105] Iteration 1500, lr = 0.1
I1006 21:26:41.855412  4081 solver.cpp:218] Iteration 1600 (5.8356 iter/s, 17.1362s/100 iters), loss = 0.577892
I1006 21:26:41.855545  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.577892 (* 1 = 0.577892 loss)
I1006 21:26:41.855553  4081 sgd_solver.cpp:105] Iteration 1600, lr = 0.1
I1006 21:26:58.936520  4081 solver.cpp:218] Iteration 1700 (5.85449 iter/s, 17.0809s/100 iters), loss = 0.649639
I1006 21:26:58.936561  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.649639 (* 1 = 0.649639 loss)
I1006 21:26:58.936568  4081 sgd_solver.cpp:105] Iteration 1700, lr = 0.1
I1006 21:27:16.025596  4081 solver.cpp:218] Iteration 1800 (5.85173 iter/s, 17.089s/100 iters), loss = 0.813883
I1006 21:27:16.025719  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.813883 (* 1 = 0.813883 loss)
I1006 21:27:16.025741  4081 sgd_solver.cpp:105] Iteration 1800, lr = 0.1
I1006 21:27:33.108850  4081 solver.cpp:218] Iteration 1900 (5.85375 iter/s, 17.0831s/100 iters), loss = 0.702698
I1006 21:27:33.108880  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.702698 (* 1 = 0.702698 loss)
I1006 21:27:33.108896  4081 sgd_solver.cpp:105] Iteration 1900, lr = 0.1
I1006 21:27:49.868716  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:27:50.549630  4081 solver.cpp:330] Iteration 2000, Testing net (#0)
I1006 21:27:54.147094  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:27:54.313637  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.5468
I1006 21:27:54.313663  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.68625 (* 1 = 1.68625 loss)
I1006 21:27:54.416858  4081 solver.cpp:218] Iteration 2000 (4.6931 iter/s, 21.3079s/100 iters), loss = 0.709026
I1006 21:27:54.416887  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.709026 (* 1 = 0.709026 loss)
I1006 21:27:54.416893  4081 sgd_solver.cpp:105] Iteration 2000, lr = 0.1
I1006 21:28:11.572125  4081 solver.cpp:218] Iteration 2100 (5.82987 iter/s, 17.1531s/100 iters), loss = 0.534076
I1006 21:28:11.572156  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.534076 (* 1 = 0.534076 loss)
I1006 21:28:11.572162  4081 sgd_solver.cpp:105] Iteration 2100, lr = 0.1
I1006 21:28:28.648689  4081 solver.cpp:218] Iteration 2200 (5.85602 iter/s, 17.0765s/100 iters), loss = 0.512014
I1006 21:28:28.648814  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.512014 (* 1 = 0.512014 loss)
I1006 21:28:28.648833  4081 sgd_solver.cpp:105] Iteration 2200, lr = 0.1
I1006 21:28:45.727898  4081 solver.cpp:218] Iteration 2300 (5.85514 iter/s, 17.079s/100 iters), loss = 0.705216
I1006 21:28:45.727928  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.705216 (* 1 = 0.705216 loss)
I1006 21:28:45.727946  4081 sgd_solver.cpp:105] Iteration 2300, lr = 0.1
I1006 21:29:02.803331  4081 solver.cpp:218] Iteration 2400 (5.8564 iter/s, 17.0753s/100 iters), loss = 0.567031
I1006 21:29:02.803480  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.567031 (* 1 = 0.567031 loss)
I1006 21:29:02.803488  4081 sgd_solver.cpp:105] Iteration 2400, lr = 0.1
I1006 21:29:19.570947  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:29:20.254897  4081 solver.cpp:330] Iteration 2500, Testing net (#0)
I1006 21:29:23.851474  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:29:24.017976  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.5791
I1006 21:29:24.018014  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.29086 (* 1 = 1.29086 loss)
I1006 21:29:24.119117  4081 solver.cpp:218] Iteration 2500 (4.69141 iter/s, 21.3156s/100 iters), loss = 0.664634
I1006 21:29:24.119156  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.664634 (* 1 = 0.664634 loss)
I1006 21:29:24.119168  4081 sgd_solver.cpp:105] Iteration 2500, lr = 0.1
I1006 21:29:41.224246  4081 solver.cpp:218] Iteration 2600 (5.84695 iter/s, 17.1029s/100 iters), loss = 0.534848
I1006 21:29:41.224354  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.534848 (* 1 = 0.534848 loss)
I1006 21:29:41.224370  4081 sgd_solver.cpp:105] Iteration 2600, lr = 0.1
I1006 21:29:58.297322  4081 solver.cpp:218] Iteration 2700 (5.85724 iter/s, 17.0729s/100 iters), loss = 0.532749
I1006 21:29:58.297365  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.532749 (* 1 = 0.532749 loss)
I1006 21:29:58.297374  4081 sgd_solver.cpp:105] Iteration 2700, lr = 0.1
I1006 21:30:15.363307  4081 solver.cpp:218] Iteration 2800 (5.85965 iter/s, 17.0659s/100 iters), loss = 0.598627
I1006 21:30:15.363420  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.598627 (* 1 = 0.598627 loss)
I1006 21:30:15.363428  4081 sgd_solver.cpp:105] Iteration 2800, lr = 0.1
I1006 21:30:32.459630  4081 solver.cpp:218] Iteration 2900 (5.84927 iter/s, 17.0961s/100 iters), loss = 0.507556
I1006 21:30:32.459671  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.507556 (* 1 = 0.507556 loss)
I1006 21:30:32.459678  4081 sgd_solver.cpp:105] Iteration 2900, lr = 0.1
I1006 21:30:49.215198  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:30:49.896813  4081 solver.cpp:330] Iteration 3000, Testing net (#0)
I1006 21:30:53.492641  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:30:53.652416  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6266
I1006 21:30:53.652453  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.12246 (* 1 = 1.12246 loss)
I1006 21:30:53.749294  4081 solver.cpp:218] Iteration 3000 (4.69714 iter/s, 21.2895s/100 iters), loss = 0.504148
I1006 21:30:53.749323  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.504148 (* 1 = 0.504148 loss)
I1006 21:30:53.749341  4081 sgd_solver.cpp:105] Iteration 3000, lr = 0.1
I1006 21:31:10.907619  4081 solver.cpp:218] Iteration 3100 (5.82812 iter/s, 17.1582s/100 iters), loss = 0.456253
I1006 21:31:10.907655  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.456253 (* 1 = 0.456253 loss)
I1006 21:31:10.907661  4081 sgd_solver.cpp:105] Iteration 3100, lr = 0.1
I1006 21:31:27.982911  4081 solver.cpp:218] Iteration 3200 (5.85645 iter/s, 17.0752s/100 iters), loss = 0.472791
I1006 21:31:27.983072  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.472791 (* 1 = 0.472791 loss)
I1006 21:31:27.983079  4081 sgd_solver.cpp:105] Iteration 3200, lr = 0.1
I1006 21:31:45.053019  4081 solver.cpp:218] Iteration 3300 (5.85844 iter/s, 17.0694s/100 iters), loss = 0.597419
I1006 21:31:45.053052  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.597419 (* 1 = 0.597419 loss)
I1006 21:31:45.053059  4081 sgd_solver.cpp:105] Iteration 3300, lr = 0.1
I1006 21:32:02.110025  4081 solver.cpp:218] Iteration 3400 (5.86292 iter/s, 17.0563s/100 iters), loss = 0.503256
I1006 21:32:02.110127  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.503256 (* 1 = 0.503256 loss)
I1006 21:32:02.110146  4081 sgd_solver.cpp:105] Iteration 3400, lr = 0.1
I1006 21:32:18.895696  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:32:19.575981  4081 solver.cpp:330] Iteration 3500, Testing net (#0)
I1006 21:32:23.180218  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:32:23.336521  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6317
I1006 21:32:23.336557  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.03985 (* 1 = 1.03985 loss)
I1006 21:32:23.475720  4081 solver.cpp:218] Iteration 3500 (4.68044 iter/s, 21.3655s/100 iters), loss = 0.471915
I1006 21:32:23.475759  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.471915 (* 1 = 0.471915 loss)
I1006 21:32:23.475765  4081 sgd_solver.cpp:105] Iteration 3500, lr = 0.1
I1006 21:32:40.570848  4081 solver.cpp:218] Iteration 3600 (5.85038 iter/s, 17.0929s/100 iters), loss = 0.38664
I1006 21:32:40.571004  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.38664 (* 1 = 0.38664 loss)
I1006 21:32:40.571025  4081 sgd_solver.cpp:105] Iteration 3600, lr = 0.1
I1006 21:32:57.632668  4081 solver.cpp:218] Iteration 3700 (5.86112 iter/s, 17.0616s/100 iters), loss = 0.472517
I1006 21:32:57.632710  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.472517 (* 1 = 0.472517 loss)
I1006 21:32:57.632716  4081 sgd_solver.cpp:105] Iteration 3700, lr = 0.1
I1006 21:33:14.690347  4081 solver.cpp:218] Iteration 3800 (5.8625 iter/s, 17.0576s/100 iters), loss = 0.501549
I1006 21:33:14.690487  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.501549 (* 1 = 0.501549 loss)
I1006 21:33:14.690513  4081 sgd_solver.cpp:105] Iteration 3800, lr = 0.1
I1006 21:33:31.780678  4081 solver.cpp:218] Iteration 3900 (5.85133 iter/s, 17.0901s/100 iters), loss = 0.471571
I1006 21:33:31.780709  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.471571 (* 1 = 0.471571 loss)
I1006 21:33:31.780727  4081 sgd_solver.cpp:105] Iteration 3900, lr = 0.1
I1006 21:33:48.489183  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:33:49.172191  4081 solver.cpp:330] Iteration 4000, Testing net (#0)
I1006 21:33:52.765794  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:33:52.922602  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6446
I1006 21:33:52.922647  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.980596 (* 1 = 0.980596 loss)
I1006 21:33:53.019290  4081 solver.cpp:218] Iteration 4000 (4.70843 iter/s, 21.2385s/100 iters), loss = 0.430775
I1006 21:33:53.019326  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.430775 (* 1 = 0.430775 loss)
I1006 21:33:53.019333  4081 sgd_solver.cpp:105] Iteration 4000, lr = 0.1
I1006 21:34:10.172143  4081 solver.cpp:218] Iteration 4100 (5.82997 iter/s, 17.1527s/100 iters), loss = 0.388436
I1006 21:34:10.172184  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.388436 (* 1 = 0.388436 loss)
I1006 21:34:10.172191  4081 sgd_solver.cpp:105] Iteration 4100, lr = 0.1
I1006 21:34:27.242846  4081 solver.cpp:218] Iteration 4200 (5.85803 iter/s, 17.0706s/100 iters), loss = 0.486268
I1006 21:34:27.242933  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.486268 (* 1 = 0.486268 loss)
I1006 21:34:27.242952  4081 sgd_solver.cpp:105] Iteration 4200, lr = 0.1
I1006 21:34:44.345719  4081 solver.cpp:218] Iteration 4300 (5.84703 iter/s, 17.1027s/100 iters), loss = 0.485611
I1006 21:34:44.345762  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.485611 (* 1 = 0.485611 loss)
I1006 21:34:44.345769  4081 sgd_solver.cpp:105] Iteration 4300, lr = 0.1
I1006 21:35:01.525470  4081 solver.cpp:218] Iteration 4400 (5.82085 iter/s, 17.1796s/100 iters), loss = 0.48412
I1006 21:35:01.525545  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.48412 (* 1 = 0.48412 loss)
I1006 21:35:01.525557  4081 sgd_solver.cpp:105] Iteration 4400, lr = 0.1
I1006 21:35:18.189242  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:35:18.870775  4081 solver.cpp:330] Iteration 4500, Testing net (#0)
I1006 21:35:22.490676  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:35:22.632961  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6637
I1006 21:35:22.632997  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.943443 (* 1 = 0.943443 loss)
I1006 21:35:22.801365  4081 solver.cpp:218] Iteration 4500 (4.70064 iter/s, 21.2737s/100 iters), loss = 0.456248
I1006 21:35:22.801403  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.456248 (* 1 = 0.456248 loss)
I1006 21:35:22.801409  4081 sgd_solver.cpp:105] Iteration 4500, lr = 0.1
I1006 21:35:39.865509  4081 solver.cpp:218] Iteration 4600 (5.86028 iter/s, 17.064s/100 iters), loss = 0.45376
I1006 21:35:39.865664  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.45376 (* 1 = 0.45376 loss)
I1006 21:35:39.865672  4081 sgd_solver.cpp:105] Iteration 4600, lr = 0.1
I1006 21:35:56.938547  4081 solver.cpp:218] Iteration 4700 (5.85727 iter/s, 17.0728s/100 iters), loss = 0.466178
I1006 21:35:56.938588  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.466178 (* 1 = 0.466178 loss)
I1006 21:35:56.938594  4081 sgd_solver.cpp:105] Iteration 4700, lr = 0.1
I1006 21:36:14.020747  4081 solver.cpp:218] Iteration 4800 (5.85408 iter/s, 17.0821s/100 iters), loss = 0.451769
I1006 21:36:14.020826  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.451769 (* 1 = 0.451769 loss)
I1006 21:36:14.020844  4081 sgd_solver.cpp:105] Iteration 4800, lr = 0.1
I1006 21:36:31.217144  4081 solver.cpp:218] Iteration 4900 (5.81522 iter/s, 17.1962s/100 iters), loss = 0.496198
I1006 21:36:31.217176  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.496198 (* 1 = 0.496198 loss)
I1006 21:36:31.217185  4081 sgd_solver.cpp:105] Iteration 4900, lr = 0.1
I1006 21:36:47.847056  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:36:48.529467  4081 solver.cpp:330] Iteration 5000, Testing net (#0)
I1006 21:36:52.103531  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:36:52.233486  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.708
I1006 21:36:52.233515  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.853919 (* 1 = 0.853919 loss)
I1006 21:36:52.381220  4081 solver.cpp:218] Iteration 5000 (4.72501 iter/s, 21.164s/100 iters), loss = 0.377563
I1006 21:36:52.381263  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.377563 (* 1 = 0.377563 loss)
I1006 21:36:52.381270  4081 sgd_solver.cpp:105] Iteration 5000, lr = 0.1
I1006 21:37:09.469368  4081 solver.cpp:218] Iteration 5100 (5.85205 iter/s, 17.088s/100 iters), loss = 0.43019
I1006 21:37:09.469410  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.43019 (* 1 = 0.43019 loss)
I1006 21:37:09.469418  4081 sgd_solver.cpp:105] Iteration 5100, lr = 0.1
I1006 21:37:26.547924  4081 solver.cpp:218] Iteration 5200 (5.85533 iter/s, 17.0784s/100 iters), loss = 0.410157
I1006 21:37:26.548023  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.410157 (* 1 = 0.410157 loss)
I1006 21:37:26.548033  4081 sgd_solver.cpp:105] Iteration 5200, lr = 0.1
I1006 21:37:43.630712  4081 solver.cpp:218] Iteration 5300 (5.8539 iter/s, 17.0826s/100 iters), loss = 0.406865
I1006 21:37:43.630743  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.406865 (* 1 = 0.406865 loss)
I1006 21:37:43.630760  4081 sgd_solver.cpp:105] Iteration 5300, lr = 0.1
I1006 21:38:00.869067  4081 solver.cpp:218] Iteration 5400 (5.80105 iter/s, 17.2382s/100 iters), loss = 0.492737
I1006 21:38:00.869150  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.492737 (* 1 = 0.492737 loss)
I1006 21:38:00.869159  4081 sgd_solver.cpp:105] Iteration 5400, lr = 0.1
I1006 21:38:17.456382  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:38:18.137188  4081 solver.cpp:330] Iteration 5500, Testing net (#0)
I1006 21:38:21.729871  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:38:21.896857  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6928
I1006 21:38:21.896883  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.896754 (* 1 = 0.896754 loss)
I1006 21:38:22.000195  4081 solver.cpp:218] Iteration 5500 (4.73239 iter/s, 21.131s/100 iters), loss = 0.399282
I1006 21:38:22.000227  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.399282 (* 1 = 0.399282 loss)
I1006 21:38:22.000244  4081 sgd_solver.cpp:105] Iteration 5500, lr = 0.1
I1006 21:38:39.147832  4081 solver.cpp:218] Iteration 5600 (5.83246 iter/s, 17.1454s/100 iters), loss = 0.342114
I1006 21:38:39.147945  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.342114 (* 1 = 0.342114 loss)
I1006 21:38:39.147964  4081 sgd_solver.cpp:105] Iteration 5600, lr = 0.1
I1006 21:38:56.213600  4081 solver.cpp:218] Iteration 5700 (5.85974 iter/s, 17.0656s/100 iters), loss = 0.416684
I1006 21:38:56.213635  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.416684 (* 1 = 0.416684 loss)
I1006 21:38:56.213654  4081 sgd_solver.cpp:105] Iteration 5700, lr = 0.1
I1006 21:39:13.306329  4081 solver.cpp:218] Iteration 5800 (5.85048 iter/s, 17.0926s/100 iters), loss = 0.445042
I1006 21:39:13.306478  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.445042 (* 1 = 0.445042 loss)
I1006 21:39:13.306499  4081 sgd_solver.cpp:105] Iteration 5800, lr = 0.1
I1006 21:39:30.615161  4081 solver.cpp:218] Iteration 5900 (5.77747 iter/s, 17.3086s/100 iters), loss = 0.464107
I1006 21:39:30.615196  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.464107 (* 1 = 0.464107 loss)
I1006 21:39:30.615203  4081 sgd_solver.cpp:105] Iteration 5900, lr = 0.1
I1006 21:39:47.162302  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:39:47.845701  4081 solver.cpp:330] Iteration 6000, Testing net (#0)
I1006 21:39:51.439669  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:39:51.604727  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.708
I1006 21:39:51.604754  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.819849 (* 1 = 0.819849 loss)
I1006 21:39:51.737983  4081 solver.cpp:218] Iteration 6000 (4.73424 iter/s, 21.1227s/100 iters), loss = 0.378117
I1006 21:39:51.738023  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.378117 (* 1 = 0.378117 loss)
I1006 21:39:51.738030  4081 sgd_solver.cpp:105] Iteration 6000, lr = 0.1
I1006 21:40:08.847322  4081 solver.cpp:218] Iteration 6100 (5.84551 iter/s, 17.1071s/100 iters), loss = 0.409937
I1006 21:40:08.847373  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.409937 (* 1 = 0.409937 loss)
I1006 21:40:08.847380  4081 sgd_solver.cpp:105] Iteration 6100, lr = 0.1
I1006 21:40:25.940412  4081 solver.cpp:218] Iteration 6200 (5.85036 iter/s, 17.093s/100 iters), loss = 0.350395
I1006 21:40:25.940500  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.350395 (* 1 = 0.350395 loss)
I1006 21:40:25.940516  4081 sgd_solver.cpp:105] Iteration 6200, lr = 0.1
I1006 21:40:43.020092  4081 solver.cpp:218] Iteration 6300 (5.85496 iter/s, 17.0795s/100 iters), loss = 0.480265
I1006 21:40:43.020124  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.480265 (* 1 = 0.480265 loss)
I1006 21:40:43.020141  4081 sgd_solver.cpp:105] Iteration 6300, lr = 0.1
I1006 21:41:00.392227  4081 solver.cpp:218] Iteration 6400 (5.75638 iter/s, 17.372s/100 iters), loss = 0.405682
I1006 21:41:00.392359  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.405682 (* 1 = 0.405682 loss)
I1006 21:41:00.392379  4081 sgd_solver.cpp:105] Iteration 6400, lr = 0.1
I1006 21:41:16.868160  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:41:17.549437  4081 solver.cpp:330] Iteration 6500, Testing net (#0)
I1006 21:41:21.147498  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:41:21.313045  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7036
I1006 21:41:21.313072  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.861783 (* 1 = 0.861783 loss)
I1006 21:41:21.446871  4081 solver.cpp:218] Iteration 6500 (4.7501 iter/s, 21.0522s/100 iters), loss = 0.332679
I1006 21:41:21.446912  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.332679 (* 1 = 0.332679 loss)
I1006 21:41:21.446918  4081 sgd_solver.cpp:105] Iteration 6500, lr = 0.1
I1006 21:41:38.566603  4081 solver.cpp:218] Iteration 6600 (5.84198 iter/s, 17.1175s/100 iters), loss = 0.343866
I1006 21:41:38.566725  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.343866 (* 1 = 0.343866 loss)
I1006 21:41:38.566743  4081 sgd_solver.cpp:105] Iteration 6600, lr = 0.1
I1006 21:41:55.655268  4081 solver.cpp:218] Iteration 6700 (5.8519 iter/s, 17.0885s/100 iters), loss = 0.421636
I1006 21:41:55.655303  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.421636 (* 1 = 0.421636 loss)
I1006 21:41:55.655321  4081 sgd_solver.cpp:105] Iteration 6700, lr = 0.1
I1006 21:42:12.744060  4081 solver.cpp:218] Iteration 6800 (5.85183 iter/s, 17.0887s/100 iters), loss = 0.383357
I1006 21:42:12.744137  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.383357 (* 1 = 0.383357 loss)
I1006 21:42:12.744150  4081 sgd_solver.cpp:105] Iteration 6800, lr = 0.1
I1006 21:42:30.154901  4081 solver.cpp:218] Iteration 6900 (5.7436 iter/s, 17.4107s/100 iters), loss = 0.345298
I1006 21:42:30.154937  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.345298 (* 1 = 0.345298 loss)
I1006 21:42:30.154958  4081 sgd_solver.cpp:105] Iteration 6900, lr = 0.1
I1006 21:42:46.571298  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:42:47.253098  4081 solver.cpp:330] Iteration 7000, Testing net (#0)
I1006 21:42:50.850786  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:42:51.016207  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.719
I1006 21:42:51.016234  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.762918 (* 1 = 0.762918 loss)
I1006 21:42:51.149428  4081 solver.cpp:218] Iteration 7000 (4.76366 iter/s, 20.9923s/100 iters), loss = 0.403308
I1006 21:42:51.149467  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.403308 (* 1 = 0.403308 loss)
I1006 21:42:51.149474  4081 sgd_solver.cpp:105] Iteration 7000, lr = 0.1
I1006 21:43:08.281738  4081 solver.cpp:218] Iteration 7100 (5.83769 iter/s, 17.1301s/100 iters), loss = 0.351108
I1006 21:43:08.281781  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.351108 (* 1 = 0.351108 loss)
I1006 21:43:08.281788  4081 sgd_solver.cpp:105] Iteration 7100, lr = 0.1
I1006 21:43:25.368697  4081 solver.cpp:218] Iteration 7200 (5.85246 iter/s, 17.0868s/100 iters), loss = 0.362134
I1006 21:43:25.368789  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.362134 (* 1 = 0.362134 loss)
I1006 21:43:25.368809  4081 sgd_solver.cpp:105] Iteration 7200, lr = 0.1
I1006 21:43:42.458475  4081 solver.cpp:218] Iteration 7300 (5.85151 iter/s, 17.0896s/100 iters), loss = 0.313991
I1006 21:43:42.458518  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.313991 (* 1 = 0.313991 loss)
I1006 21:43:42.458523  4081 sgd_solver.cpp:105] Iteration 7300, lr = 0.1
I1006 21:43:59.948281  4081 solver.cpp:218] Iteration 7400 (5.71765 iter/s, 17.4897s/100 iters), loss = 0.331396
I1006 21:43:59.948379  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.331396 (* 1 = 0.331396 loss)
I1006 21:43:59.948386  4081 sgd_solver.cpp:105] Iteration 7400, lr = 0.1
I1006 21:44:16.309088  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:44:16.991338  4081 solver.cpp:330] Iteration 7500, Testing net (#0)
I1006 21:44:20.584559  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:44:20.750638  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7382
I1006 21:44:20.750674  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.730149 (* 1 = 0.730149 loss)
I1006 21:44:20.855476  4081 solver.cpp:218] Iteration 7500 (4.78308 iter/s, 20.907s/100 iters), loss = 0.406875
I1006 21:44:20.855515  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.406875 (* 1 = 0.406875 loss)
I1006 21:44:20.855522  4081 sgd_solver.cpp:105] Iteration 7500, lr = 0.1
I1006 21:44:37.995457  4081 solver.cpp:218] Iteration 7600 (5.83508 iter/s, 17.1377s/100 iters), loss = 0.272488
I1006 21:44:37.995568  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.272488 (* 1 = 0.272488 loss)
I1006 21:44:37.995575  4081 sgd_solver.cpp:105] Iteration 7600, lr = 0.1
I1006 21:44:55.076409  4081 solver.cpp:218] Iteration 7700 (5.85453 iter/s, 17.0808s/100 iters), loss = 0.311758
I1006 21:44:55.076452  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.311758 (* 1 = 0.311758 loss)
I1006 21:44:55.076459  4081 sgd_solver.cpp:105] Iteration 7700, lr = 0.1
I1006 21:45:12.141468  4081 solver.cpp:218] Iteration 7800 (5.85997 iter/s, 17.0649s/100 iters), loss = 0.329809
I1006 21:45:12.141564  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.329809 (* 1 = 0.329809 loss)
I1006 21:45:12.141572  4081 sgd_solver.cpp:105] Iteration 7800, lr = 0.1
I1006 21:45:29.666072  4081 solver.cpp:218] Iteration 7900 (5.70631 iter/s, 17.5244s/100 iters), loss = 0.368535
I1006 21:45:29.666115  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.368535 (* 1 = 0.368535 loss)
I1006 21:45:29.666122  4081 sgd_solver.cpp:105] Iteration 7900, lr = 0.1
I1006 21:45:45.979987  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:45:46.663288  4081 solver.cpp:330] Iteration 8000, Testing net (#0)
I1006 21:45:50.238750  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:45:50.366989  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7707
I1006 21:45:50.367020  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.651136 (* 1 = 0.651136 loss)
I1006 21:45:50.514909  4081 solver.cpp:218] Iteration 8000 (4.79646 iter/s, 20.8487s/100 iters), loss = 0.306968
I1006 21:45:50.514940  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.306968 (* 1 = 0.306968 loss)
I1006 21:45:50.514960  4081 sgd_solver.cpp:105] Iteration 8000, lr = 0.1
I1006 21:46:07.590065  4081 solver.cpp:218] Iteration 8100 (5.8565 iter/s, 17.0751s/100 iters), loss = 0.285648
I1006 21:46:07.590100  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.285648 (* 1 = 0.285648 loss)
I1006 21:46:07.590108  4081 sgd_solver.cpp:105] Iteration 8100, lr = 0.1
I1006 21:46:24.674870  4081 solver.cpp:218] Iteration 8200 (5.85319 iter/s, 17.0847s/100 iters), loss = 0.335731
I1006 21:46:24.674981  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.335731 (* 1 = 0.335731 loss)
I1006 21:46:24.674988  4081 sgd_solver.cpp:105] Iteration 8200, lr = 0.1
I1006 21:46:41.761670  4081 solver.cpp:218] Iteration 8300 (5.85253 iter/s, 17.0866s/100 iters), loss = 0.361772
I1006 21:46:41.761711  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.361772 (* 1 = 0.361772 loss)
I1006 21:46:41.761718  4081 sgd_solver.cpp:105] Iteration 8300, lr = 0.1
I1006 21:46:59.353610  4081 solver.cpp:218] Iteration 8400 (5.68446 iter/s, 17.5918s/100 iters), loss = 0.313957
I1006 21:46:59.353754  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.313957 (* 1 = 0.313957 loss)
I1006 21:46:59.353767  4081 sgd_solver.cpp:105] Iteration 8400, lr = 0.1
I1006 21:47:15.621387  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:47:16.293684  4081 solver.cpp:330] Iteration 8500, Testing net (#0)
I1006 21:47:19.887310  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:47:20.052117  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7971
I1006 21:47:20.052155  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.576658 (* 1 = 0.576658 loss)
I1006 21:47:20.160670  4081 solver.cpp:218] Iteration 8500 (4.80658 iter/s, 20.8048s/100 iters), loss = 0.408794
I1006 21:47:20.160712  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.408794 (* 1 = 0.408794 loss)
I1006 21:47:20.160719  4081 sgd_solver.cpp:105] Iteration 8500, lr = 0.1
I1006 21:47:37.309248  4081 solver.cpp:218] Iteration 8600 (5.83142 iter/s, 17.1485s/100 iters), loss = 0.278296
I1006 21:47:37.309345  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.278296 (* 1 = 0.278296 loss)
I1006 21:47:37.309363  4081 sgd_solver.cpp:105] Iteration 8600, lr = 0.1
I1006 21:47:54.393537  4081 solver.cpp:218] Iteration 8700 (5.85377 iter/s, 17.083s/100 iters), loss = 0.336365
I1006 21:47:54.393579  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.336366 (* 1 = 0.336366 loss)
I1006 21:47:54.393584  4081 sgd_solver.cpp:105] Iteration 8700, lr = 0.1
I1006 21:48:11.483320  4081 solver.cpp:218] Iteration 8800 (5.85149 iter/s, 17.0897s/100 iters), loss = 0.382235
I1006 21:48:11.483464  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.382235 (* 1 = 0.382235 loss)
I1006 21:48:11.483474  4081 sgd_solver.cpp:105] Iteration 8800, lr = 0.1
I1006 21:48:29.049134  4081 solver.cpp:218] Iteration 8900 (5.69294 iter/s, 17.5656s/100 iters), loss = 0.345729
I1006 21:48:29.049175  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.345729 (* 1 = 0.345729 loss)
I1006 21:48:29.049182  4081 sgd_solver.cpp:105] Iteration 8900, lr = 0.1
I1006 21:48:45.344565  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:48:46.028617  4081 solver.cpp:330] Iteration 9000, Testing net (#0)
I1006 21:48:49.648294  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:48:49.790565  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.696
I1006 21:48:49.790591  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.920983 (* 1 = 0.920983 loss)
I1006 21:48:49.958389  4081 solver.cpp:218] Iteration 9000 (4.7826 iter/s, 20.9091s/100 iters), loss = 0.242397
I1006 21:48:49.958431  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.242397 (* 1 = 0.242397 loss)
I1006 21:48:49.958437  4081 sgd_solver.cpp:105] Iteration 9000, lr = 0.1
I1006 21:49:07.041539  4081 solver.cpp:218] Iteration 9100 (5.85376 iter/s, 17.083s/100 iters), loss = 0.27138
I1006 21:49:07.041581  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.27138 (* 1 = 0.27138 loss)
I1006 21:49:07.041589  4081 sgd_solver.cpp:105] Iteration 9100, lr = 0.1
I1006 21:49:24.121847  4081 solver.cpp:218] Iteration 9200 (5.85473 iter/s, 17.0802s/100 iters), loss = 0.350654
I1006 21:49:24.121942  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.350655 (* 1 = 0.350655 loss)
I1006 21:49:24.121960  4081 sgd_solver.cpp:105] Iteration 9200, lr = 0.1
I1006 21:49:41.193111  4081 solver.cpp:218] Iteration 9300 (5.85785 iter/s, 17.0711s/100 iters), loss = 0.313312
I1006 21:49:41.193142  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.313312 (* 1 = 0.313312 loss)
I1006 21:49:41.193158  4081 sgd_solver.cpp:105] Iteration 9300, lr = 0.1
I1006 21:49:58.811913  4081 solver.cpp:218] Iteration 9400 (5.67579 iter/s, 17.6187s/100 iters), loss = 0.37908
I1006 21:49:58.812057  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.379081 (* 1 = 0.379081 loss)
I1006 21:49:58.812077  4081 sgd_solver.cpp:105] Iteration 9400, lr = 0.1
I1006 21:50:15.041512  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:50:15.727143  4081 solver.cpp:330] Iteration 9500, Testing net (#0)
I1006 21:50:19.297580  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:50:19.428588  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6551
I1006 21:50:19.428616  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.10973 (* 1 = 1.10973 loss)
I1006 21:50:19.576786  4081 solver.cpp:218] Iteration 9500 (4.81587 iter/s, 20.7647s/100 iters), loss = 0.308999
I1006 21:50:19.576817  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.308999 (* 1 = 0.308999 loss)
I1006 21:50:19.576835  4081 sgd_solver.cpp:105] Iteration 9500, lr = 0.1
I1006 21:50:36.653666  4081 solver.cpp:218] Iteration 9600 (5.85591 iter/s, 17.0768s/100 iters), loss = 0.310094
I1006 21:50:36.653792  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.310094 (* 1 = 0.310094 loss)
I1006 21:50:36.653815  4081 sgd_solver.cpp:105] Iteration 9600, lr = 0.1
I1006 21:50:53.737071  4081 solver.cpp:218] Iteration 9700 (5.8537 iter/s, 17.0832s/100 iters), loss = 0.324379
I1006 21:50:53.737103  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.324379 (* 1 = 0.324379 loss)
I1006 21:50:53.737123  4081 sgd_solver.cpp:105] Iteration 9700, lr = 0.1
I1006 21:51:10.823839  4081 solver.cpp:218] Iteration 9800 (5.85252 iter/s, 17.0867s/100 iters), loss = 0.364783
I1006 21:51:10.823906  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.364783 (* 1 = 0.364783 loss)
I1006 21:51:10.823928  4081 sgd_solver.cpp:105] Iteration 9800, lr = 0.1
I1006 21:51:28.440148  4081 solver.cpp:218] Iteration 9900 (5.6766 iter/s, 17.6162s/100 iters), loss = 0.365666
I1006 21:51:28.440182  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.365666 (* 1 = 0.365666 loss)
I1006 21:51:28.440201  4081 sgd_solver.cpp:105] Iteration 9900, lr = 0.1
I1006 21:51:44.677939  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:51:45.357362  4081 solver.cpp:330] Iteration 10000, Testing net (#0)
I1006 21:51:48.954810  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:51:49.121063  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7847
I1006 21:51:49.121091  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.618954 (* 1 = 0.618954 loss)
I1006 21:51:49.224503  4081 solver.cpp:218] Iteration 10000 (4.81183 iter/s, 20.7821s/100 iters), loss = 0.326033
I1006 21:51:49.224536  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.326033 (* 1 = 0.326033 loss)
I1006 21:51:49.224557  4081 sgd_solver.cpp:105] Iteration 10000, lr = 0.1
I1006 21:52:06.364926  4081 solver.cpp:218] Iteration 10100 (5.83493 iter/s, 17.1382s/100 iters), loss = 0.330708
I1006 21:52:06.364969  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.330708 (* 1 = 0.330708 loss)
I1006 21:52:06.364975  4081 sgd_solver.cpp:105] Iteration 10100, lr = 0.1
I1006 21:52:23.451695  4081 solver.cpp:218] Iteration 10200 (5.85252 iter/s, 17.0867s/100 iters), loss = 0.358137
I1006 21:52:23.451820  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.358138 (* 1 = 0.358138 loss)
I1006 21:52:23.451843  4081 sgd_solver.cpp:105] Iteration 10200, lr = 0.1
I1006 21:52:40.540426  4081 solver.cpp:218] Iteration 10300 (5.85187 iter/s, 17.0885s/100 iters), loss = 0.292676
I1006 21:52:40.540467  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.292676 (* 1 = 0.292676 loss)
I1006 21:52:40.540473  4081 sgd_solver.cpp:105] Iteration 10300, lr = 0.1
I1006 21:52:58.091240  4081 solver.cpp:218] Iteration 10400 (5.69778 iter/s, 17.5507s/100 iters), loss = 0.336687
I1006 21:52:58.091357  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.336687 (* 1 = 0.336687 loss)
I1006 21:52:58.091377  4081 sgd_solver.cpp:105] Iteration 10400, lr = 0.1
I1006 21:53:14.399894  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:53:15.082947  4081 solver.cpp:330] Iteration 10500, Testing net (#0)
I1006 21:53:18.680528  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:53:18.846369  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8042
I1006 21:53:18.846405  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.571818 (* 1 = 0.571818 loss)
I1006 21:53:18.953660  4081 solver.cpp:218] Iteration 10500 (4.79384 iter/s, 20.8601s/100 iters), loss = 0.270816
I1006 21:53:18.953703  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.270816 (* 1 = 0.270816 loss)
I1006 21:53:18.953711  4081 sgd_solver.cpp:105] Iteration 10500, lr = 0.1
I1006 21:53:36.095500  4081 solver.cpp:218] Iteration 10600 (5.83382 iter/s, 17.1414s/100 iters), loss = 0.270195
I1006 21:53:36.095607  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.270195 (* 1 = 0.270195 loss)
I1006 21:53:36.095616  4081 sgd_solver.cpp:105] Iteration 10600, lr = 0.1
I1006 21:53:53.180316  4081 solver.cpp:218] Iteration 10700 (5.85364 iter/s, 17.0834s/100 iters), loss = 0.291608
I1006 21:53:53.180359  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.291608 (* 1 = 0.291608 loss)
I1006 21:53:53.180366  4081 sgd_solver.cpp:105] Iteration 10700, lr = 0.1
I1006 21:54:10.260690  4081 solver.cpp:218] Iteration 10800 (5.85471 iter/s, 17.0803s/100 iters), loss = 0.285932
I1006 21:54:10.260799  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.285932 (* 1 = 0.285932 loss)
I1006 21:54:10.260818  4081 sgd_solver.cpp:105] Iteration 10800, lr = 0.1
I1006 21:54:27.840425  4081 solver.cpp:218] Iteration 10900 (5.68842 iter/s, 17.5796s/100 iters), loss = 0.291721
I1006 21:54:27.840456  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.291721 (* 1 = 0.291721 loss)
I1006 21:54:27.840473  4081 sgd_solver.cpp:105] Iteration 10900, lr = 0.1
I1006 21:54:44.102262  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:54:44.783731  4081 solver.cpp:330] Iteration 11000, Testing net (#0)
I1006 21:54:48.383095  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:54:48.549998  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7134
I1006 21:54:48.550032  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.941183 (* 1 = 0.941183 loss)
I1006 21:54:48.679455  4081 solver.cpp:218] Iteration 11000 (4.7992 iter/s, 20.8368s/100 iters), loss = 0.396606
I1006 21:54:48.679494  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.396607 (* 1 = 0.396607 loss)
I1006 21:54:48.679502  4081 sgd_solver.cpp:105] Iteration 11000, lr = 0.1
I1006 21:55:05.799090  4081 solver.cpp:218] Iteration 11100 (5.842 iter/s, 17.1174s/100 iters), loss = 0.286021
I1006 21:55:05.799121  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.286022 (* 1 = 0.286022 loss)
I1006 21:55:05.799139  4081 sgd_solver.cpp:105] Iteration 11100, lr = 0.1
I1006 21:55:22.877761  4081 solver.cpp:218] Iteration 11200 (5.85529 iter/s, 17.0786s/100 iters), loss = 0.370394
I1006 21:55:22.877853  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.370394 (* 1 = 0.370394 loss)
I1006 21:55:22.877871  4081 sgd_solver.cpp:105] Iteration 11200, lr = 0.1
I1006 21:55:39.947551  4081 solver.cpp:218] Iteration 11300 (5.85836 iter/s, 17.0696s/100 iters), loss = 0.288061
I1006 21:55:39.947582  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.288061 (* 1 = 0.288061 loss)
I1006 21:55:39.947588  4081 sgd_solver.cpp:105] Iteration 11300, lr = 0.1
I1006 21:55:57.495852  4081 solver.cpp:218] Iteration 11400 (5.69859 iter/s, 17.5482s/100 iters), loss = 0.326008
I1006 21:55:57.495945  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.326009 (* 1 = 0.326009 loss)
I1006 21:55:57.495955  4081 sgd_solver.cpp:105] Iteration 11400, lr = 0.1
I1006 21:56:13.767675  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:56:14.448938  4081 solver.cpp:330] Iteration 11500, Testing net (#0)
I1006 21:56:18.037672  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:56:18.203318  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6885
I1006 21:56:18.203356  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.0953 (* 1 = 1.0953 loss)
I1006 21:56:18.310883  4081 solver.cpp:218] Iteration 11500 (4.80426 iter/s, 20.8149s/100 iters), loss = 0.276617
I1006 21:56:18.310914  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.276617 (* 1 = 0.276617 loss)
I1006 21:56:18.310935  4081 sgd_solver.cpp:105] Iteration 11500, lr = 0.1
I1006 21:56:35.450956  4081 solver.cpp:218] Iteration 11600 (5.83452 iter/s, 17.1394s/100 iters), loss = 0.243939
I1006 21:56:35.451067  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.243939 (* 1 = 0.243939 loss)
I1006 21:56:35.451087  4081 sgd_solver.cpp:105] Iteration 11600, lr = 0.1
I1006 21:56:52.539105  4081 solver.cpp:218] Iteration 11700 (5.85207 iter/s, 17.088s/100 iters), loss = 0.292658
I1006 21:56:52.539136  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.292658 (* 1 = 0.292658 loss)
I1006 21:56:52.539142  4081 sgd_solver.cpp:105] Iteration 11700, lr = 0.1
I1006 21:57:09.619501  4081 solver.cpp:218] Iteration 11800 (5.8547 iter/s, 17.0803s/100 iters), loss = 0.355793
I1006 21:57:09.619640  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.355793 (* 1 = 0.355793 loss)
I1006 21:57:09.619663  4081 sgd_solver.cpp:105] Iteration 11800, lr = 0.1
I1006 21:57:27.240996  4081 solver.cpp:218] Iteration 11900 (5.67495 iter/s, 17.6213s/100 iters), loss = 0.272289
I1006 21:57:27.241031  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.272289 (* 1 = 0.272289 loss)
I1006 21:57:27.241051  4081 sgd_solver.cpp:105] Iteration 11900, lr = 0.1
I1006 21:57:43.456977  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:57:44.138892  4081 solver.cpp:330] Iteration 12000, Testing net (#0)
I1006 21:57:47.677738  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:57:47.823503  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6647
I1006 21:57:47.823539  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.13416 (* 1 = 1.13416 loss)
I1006 21:57:47.982617  4081 solver.cpp:218] Iteration 12000 (4.82125 iter/s, 20.7415s/100 iters), loss = 0.343972
I1006 21:57:47.982655  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.343973 (* 1 = 0.343973 loss)
I1006 21:57:47.982672  4081 sgd_solver.cpp:105] Iteration 12000, lr = 0.1
I1006 21:58:05.067562  4081 solver.cpp:218] Iteration 12100 (5.85386 iter/s, 17.0827s/100 iters), loss = 0.258893
I1006 21:58:05.067605  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.258893 (* 1 = 0.258893 loss)
I1006 21:58:05.067611  4081 sgd_solver.cpp:105] Iteration 12100, lr = 0.1
I1006 21:58:22.126716  4081 solver.cpp:218] Iteration 12200 (5.86199 iter/s, 17.059s/100 iters), loss = 0.282166
I1006 21:58:22.126835  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.282166 (* 1 = 0.282166 loss)
I1006 21:58:22.126854  4081 sgd_solver.cpp:105] Iteration 12200, lr = 0.1
I1006 21:58:39.205109  4081 solver.cpp:218] Iteration 12300 (5.85541 iter/s, 17.0782s/100 iters), loss = 0.245171
I1006 21:58:39.205154  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.245172 (* 1 = 0.245172 loss)
I1006 21:58:39.205162  4081 sgd_solver.cpp:105] Iteration 12300, lr = 0.1
I1006 21:58:56.814718  4081 solver.cpp:218] Iteration 12400 (5.67875 iter/s, 17.6095s/100 iters), loss = 0.297501
I1006 21:58:56.814810  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.297501 (* 1 = 0.297501 loss)
I1006 21:58:56.814818  4081 sgd_solver.cpp:105] Iteration 12400, lr = 0.1
I1006 21:59:13.036607  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:59:13.714833  4081 solver.cpp:330] Iteration 12500, Testing net (#0)
I1006 21:59:17.305567  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1006 21:59:17.471091  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7219
I1006 21:59:17.471117  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.928447 (* 1 = 0.928447 loss)
I1006 21:59:17.602187  4081 solver.cpp:218] Iteration 12500 (4.81095 iter/s, 20.7859s/100 iters), loss = 0.249099
I1006 21:59:17.602231  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.249099 (* 1 = 0.249099 loss)
I1006 21:59:17.602237  4081 sgd_solver.cpp:105] Iteration 12500, lr = 0.1
I1006 21:59:34.727685  4081 solver.cpp:218] Iteration 12600 (5.84 iter/s, 17.1233s/100 iters), loss = 0.257333
I1006 21:59:34.727789  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.257334 (* 1 = 0.257334 loss)
I1006 21:59:34.727808  4081 sgd_solver.cpp:105] Iteration 12600, lr = 0.1
I1006 21:59:51.811090  4081 solver.cpp:218] Iteration 12700 (5.85369 iter/s, 17.0832s/100 iters), loss = 0.27985
I1006 21:59:51.811132  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.27985 (* 1 = 0.27985 loss)
I1006 21:59:51.811139  4081 sgd_solver.cpp:105] Iteration 12700, lr = 0.1
I1006 22:00:08.890911  4081 solver.cpp:218] Iteration 12800 (5.85491 iter/s, 17.0797s/100 iters), loss = 0.300909
I1006 22:00:08.891021  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.300909 (* 1 = 0.300909 loss)
I1006 22:00:08.891038  4081 sgd_solver.cpp:105] Iteration 12800, lr = 0.1
I1006 22:00:26.505331  4081 solver.cpp:218] Iteration 12900 (5.67722 iter/s, 17.6143s/100 iters), loss = 0.280588
I1006 22:00:26.505362  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.280588 (* 1 = 0.280588 loss)
I1006 22:00:26.505369  4081 sgd_solver.cpp:105] Iteration 12900, lr = 0.1
I1006 22:00:42.721866  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:00:43.405539  4081 solver.cpp:330] Iteration 13000, Testing net (#0)
I1006 22:00:47.001745  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:00:47.139626  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6998
I1006 22:00:47.139664  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.13494 (* 1 = 1.13494 loss)
I1006 22:00:47.255970  4081 solver.cpp:218] Iteration 13000 (4.81915 iter/s, 20.7505s/100 iters), loss = 0.292882
I1006 22:00:47.256009  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.292882 (* 1 = 0.292882 loss)
I1006 22:00:47.256017  4081 sgd_solver.cpp:105] Iteration 13000, lr = 0.1
I1006 22:01:04.407663  4081 solver.cpp:218] Iteration 13100 (5.83037 iter/s, 17.1516s/100 iters), loss = 0.19304
I1006 22:01:04.407704  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.193041 (* 1 = 0.193041 loss)
I1006 22:01:04.407711  4081 sgd_solver.cpp:105] Iteration 13100, lr = 0.1
I1006 22:01:21.480414  4081 solver.cpp:218] Iteration 13200 (5.85732 iter/s, 17.0726s/100 iters), loss = 0.321908
I1006 22:01:21.480536  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.321909 (* 1 = 0.321909 loss)
I1006 22:01:21.480554  4081 sgd_solver.cpp:105] Iteration 13200, lr = 0.1
I1006 22:01:38.553153  4081 solver.cpp:218] Iteration 13300 (5.85735 iter/s, 17.0726s/100 iters), loss = 0.279277
I1006 22:01:38.553192  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.279277 (* 1 = 0.279277 loss)
I1006 22:01:38.553200  4081 sgd_solver.cpp:105] Iteration 13300, lr = 0.1
I1006 22:01:56.154040  4081 solver.cpp:218] Iteration 13400 (5.68157 iter/s, 17.6008s/100 iters), loss = 0.304735
I1006 22:01:56.154175  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.304735 (* 1 = 0.304735 loss)
I1006 22:01:56.154193  4081 sgd_solver.cpp:105] Iteration 13400, lr = 0.1
I1006 22:02:12.375181  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:02:13.055240  4081 solver.cpp:330] Iteration 13500, Testing net (#0)
I1006 22:02:16.652307  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:02:16.817975  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7057
I1006 22:02:16.818012  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.1171 (* 1 = 1.1171 loss)
I1006 22:02:16.947239  4081 solver.cpp:218] Iteration 13500 (4.80931 iter/s, 20.793s/100 iters), loss = 0.293231
I1006 22:02:16.947280  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.293231 (* 1 = 0.293231 loss)
I1006 22:02:16.947288  4081 sgd_solver.cpp:105] Iteration 13500, lr = 0.1
I1006 22:02:34.052201  4081 solver.cpp:218] Iteration 13600 (5.84701 iter/s, 17.1028s/100 iters), loss = 0.306359
I1006 22:02:34.052345  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.306359 (* 1 = 0.306359 loss)
I1006 22:02:34.052363  4081 sgd_solver.cpp:105] Iteration 13600, lr = 0.1
I1006 22:02:51.121321  4081 solver.cpp:218] Iteration 13700 (5.8586 iter/s, 17.0689s/100 iters), loss = 0.331714
I1006 22:02:51.121363  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.331714 (* 1 = 0.331714 loss)
I1006 22:02:51.121371  4081 sgd_solver.cpp:105] Iteration 13700, lr = 0.1
I1006 22:03:08.190975  4081 solver.cpp:218] Iteration 13800 (5.85839 iter/s, 17.0695s/100 iters), loss = 0.276529
I1006 22:03:08.191059  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.276529 (* 1 = 0.276529 loss)
I1006 22:03:08.191082  4081 sgd_solver.cpp:105] Iteration 13800, lr = 0.1
I1006 22:03:25.789971  4081 solver.cpp:218] Iteration 13900 (5.68219 iter/s, 17.5988s/100 iters), loss = 0.296979
I1006 22:03:25.790014  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.296979 (* 1 = 0.296979 loss)
I1006 22:03:25.790020  4081 sgd_solver.cpp:105] Iteration 13900, lr = 0.1
I1006 22:03:42.018669  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:03:42.699741  4081 solver.cpp:330] Iteration 14000, Testing net (#0)
I1006 22:03:46.319442  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:03:46.463385  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7698
I1006 22:03:46.463413  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.754116 (* 1 = 0.754116 loss)
I1006 22:03:46.631767  4081 solver.cpp:218] Iteration 14000 (4.79808 iter/s, 20.8417s/100 iters), loss = 0.217801
I1006 22:03:46.631800  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.217801 (* 1 = 0.217801 loss)
I1006 22:03:46.631820  4081 sgd_solver.cpp:105] Iteration 14000, lr = 0.1
I1006 22:04:03.698680  4081 solver.cpp:218] Iteration 14100 (5.85933 iter/s, 17.0668s/100 iters), loss = 0.303533
I1006 22:04:03.698714  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.303533 (* 1 = 0.303533 loss)
I1006 22:04:03.698732  4081 sgd_solver.cpp:105] Iteration 14100, lr = 0.1
I1006 22:04:20.771908  4081 solver.cpp:218] Iteration 14200 (5.85716 iter/s, 17.0731s/100 iters), loss = 0.260231
I1006 22:04:20.772019  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.260231 (* 1 = 0.260231 loss)
I1006 22:04:20.772032  4081 sgd_solver.cpp:105] Iteration 14200, lr = 0.1
I1006 22:04:37.844202  4081 solver.cpp:218] Iteration 14300 (5.8575 iter/s, 17.0721s/100 iters), loss = 0.288922
I1006 22:04:37.844238  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.288922 (* 1 = 0.288922 loss)
I1006 22:04:37.844256  4081 sgd_solver.cpp:105] Iteration 14300, lr = 0.1
I1006 22:04:55.446331  4081 solver.cpp:218] Iteration 14400 (5.68116 iter/s, 17.602s/100 iters), loss = 0.212286
I1006 22:04:55.446467  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.212286 (* 1 = 0.212286 loss)
I1006 22:04:55.446476  4081 sgd_solver.cpp:105] Iteration 14400, lr = 0.1
I1006 22:05:11.668162  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:05:12.348618  4081 solver.cpp:330] Iteration 14500, Testing net (#0)
I1006 22:05:15.940569  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:05:16.093116  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8125
I1006 22:05:16.093153  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.561167 (* 1 = 0.561167 loss)
I1006 22:05:16.194378  4081 solver.cpp:218] Iteration 14500 (4.81978 iter/s, 20.7479s/100 iters), loss = 0.247649
I1006 22:05:16.194418  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.247649 (* 1 = 0.247649 loss)
I1006 22:05:16.194427  4081 sgd_solver.cpp:105] Iteration 14500, lr = 0.1
I1006 22:05:33.359616  4081 solver.cpp:218] Iteration 14600 (5.82577 iter/s, 17.1651s/100 iters), loss = 0.201046
I1006 22:05:33.359752  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.201046 (* 1 = 0.201046 loss)
I1006 22:05:33.359761  4081 sgd_solver.cpp:105] Iteration 14600, lr = 0.1
I1006 22:05:50.446296  4081 solver.cpp:218] Iteration 14700 (5.85258 iter/s, 17.0865s/100 iters), loss = 0.378901
I1006 22:05:50.446331  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.378902 (* 1 = 0.378902 loss)
I1006 22:05:50.446347  4081 sgd_solver.cpp:105] Iteration 14700, lr = 0.1
I1006 22:06:07.523963  4081 solver.cpp:218] Iteration 14800 (5.85564 iter/s, 17.0776s/100 iters), loss = 0.261615
I1006 22:06:07.524060  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.261615 (* 1 = 0.261615 loss)
I1006 22:06:07.524067  4081 sgd_solver.cpp:105] Iteration 14800, lr = 0.1
I1006 22:06:25.145361  4081 solver.cpp:218] Iteration 14900 (5.67497 iter/s, 17.6212s/100 iters), loss = 0.247445
I1006 22:06:25.145402  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.247445 (* 1 = 0.247445 loss)
I1006 22:06:25.145408  4081 sgd_solver.cpp:105] Iteration 14900, lr = 0.1
I1006 22:06:41.372434  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:06:42.054040  4081 solver.cpp:330] Iteration 15000, Testing net (#0)
I1006 22:06:45.650758  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:06:45.788419  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.5404
I1006 22:06:45.788456  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 2.2256 (* 1 = 2.2256 loss)
I1006 22:06:45.903674  4081 solver.cpp:218] Iteration 15000 (4.81737 iter/s, 20.7582s/100 iters), loss = 0.297957
I1006 22:06:45.903712  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.297957 (* 1 = 0.297957 loss)
I1006 22:06:45.903717  4081 sgd_solver.cpp:105] Iteration 15000, lr = 0.1
I1006 22:07:03.043800  4081 solver.cpp:218] Iteration 15100 (5.8343 iter/s, 17.14s/100 iters), loss = 0.331447
I1006 22:07:03.043841  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.331447 (* 1 = 0.331447 loss)
I1006 22:07:03.043848  4081 sgd_solver.cpp:105] Iteration 15100, lr = 0.1
I1006 22:07:20.117414  4081 solver.cpp:218] Iteration 15200 (5.85703 iter/s, 17.0735s/100 iters), loss = 0.335089
I1006 22:07:20.117533  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.335089 (* 1 = 0.335089 loss)
I1006 22:07:20.117552  4081 sgd_solver.cpp:105] Iteration 15200, lr = 0.1
I1006 22:07:37.185894  4081 solver.cpp:218] Iteration 15300 (5.85881 iter/s, 17.0683s/100 iters), loss = 0.323857
I1006 22:07:37.185927  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.323858 (* 1 = 0.323858 loss)
I1006 22:07:37.185943  4081 sgd_solver.cpp:105] Iteration 15300, lr = 0.1
I1006 22:07:54.807978  4081 solver.cpp:218] Iteration 15400 (5.67473 iter/s, 17.622s/100 iters), loss = 0.21024
I1006 22:07:54.808104  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.21024 (* 1 = 0.21024 loss)
I1006 22:07:54.808125  4081 sgd_solver.cpp:105] Iteration 15400, lr = 0.1
I1006 22:08:11.039455  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:08:11.722635  4081 solver.cpp:330] Iteration 15500, Testing net (#0)
I1006 22:08:15.320924  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:08:15.485993  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6501
I1006 22:08:15.486019  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.31993 (* 1 = 1.31993 loss)
I1006 22:08:15.617668  4081 solver.cpp:218] Iteration 15500 (4.8055 iter/s, 20.8095s/100 iters), loss = 0.28431
I1006 22:08:15.617710  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.28431 (* 1 = 0.28431 loss)
I1006 22:08:15.617717  4081 sgd_solver.cpp:105] Iteration 15500, lr = 0.1
I1006 22:08:32.722651  4081 solver.cpp:218] Iteration 15600 (5.847 iter/s, 17.1028s/100 iters), loss = 0.181165
I1006 22:08:32.722759  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.181165 (* 1 = 0.181165 loss)
I1006 22:08:32.722777  4081 sgd_solver.cpp:105] Iteration 15600, lr = 0.1
I1006 22:08:49.793895  4081 solver.cpp:218] Iteration 15700 (5.85786 iter/s, 17.0711s/100 iters), loss = 0.275323
I1006 22:08:49.793927  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.275323 (* 1 = 0.275323 loss)
I1006 22:08:49.793934  4081 sgd_solver.cpp:105] Iteration 15700, lr = 0.1
I1006 22:09:06.871752  4081 solver.cpp:218] Iteration 15800 (5.85557 iter/s, 17.0777s/100 iters), loss = 0.195811
I1006 22:09:06.871876  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.195811 (* 1 = 0.195811 loss)
I1006 22:09:06.871888  4081 sgd_solver.cpp:105] Iteration 15800, lr = 0.1
I1006 22:09:24.483309  4081 solver.cpp:218] Iteration 15900 (5.67815 iter/s, 17.6114s/100 iters), loss = 0.317665
I1006 22:09:24.483351  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.317665 (* 1 = 0.317665 loss)
I1006 22:09:24.483358  4081 sgd_solver.cpp:105] Iteration 15900, lr = 0.1
I1006 22:09:40.703368  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:09:41.387850  4081 solver.cpp:330] Iteration 16000, Testing net (#0)
I1006 22:09:44.983227  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:09:45.150367  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8085
I1006 22:09:45.150393  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.596173 (* 1 = 0.596173 loss)
I1006 22:09:45.281344  4081 solver.cpp:218] Iteration 16000 (4.80817 iter/s, 20.7979s/100 iters), loss = 0.176539
I1006 22:09:45.281376  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.176539 (* 1 = 0.176539 loss)
I1006 22:09:45.281394  4081 sgd_solver.cpp:105] Iteration 16000, lr = 0.1
I1006 22:10:02.409435  4081 solver.cpp:218] Iteration 16100 (5.83911 iter/s, 17.1259s/100 iters), loss = 0.289665
I1006 22:10:02.409477  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.289665 (* 1 = 0.289665 loss)
I1006 22:10:02.409484  4081 sgd_solver.cpp:105] Iteration 16100, lr = 0.1
I1006 22:10:19.496433  4081 solver.cpp:218] Iteration 16200 (5.85244 iter/s, 17.0869s/100 iters), loss = 0.331674
I1006 22:10:19.496552  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.331675 (* 1 = 0.331675 loss)
I1006 22:10:19.496570  4081 sgd_solver.cpp:105] Iteration 16200, lr = 0.1
I1006 22:10:36.584637  4081 solver.cpp:218] Iteration 16300 (5.85205 iter/s, 17.088s/100 iters), loss = 0.280521
I1006 22:10:36.584677  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.280522 (* 1 = 0.280522 loss)
I1006 22:10:36.584684  4081 sgd_solver.cpp:105] Iteration 16300, lr = 0.1
I1006 22:10:54.199517  4081 solver.cpp:218] Iteration 16400 (5.67705 iter/s, 17.6148s/100 iters), loss = 0.14722
I1006 22:10:54.199635  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.147221 (* 1 = 0.147221 loss)
I1006 22:10:54.199654  4081 sgd_solver.cpp:105] Iteration 16400, lr = 0.1
I1006 22:11:10.435187  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:11:11.117558  4081 solver.cpp:330] Iteration 16500, Testing net (#0)
I1006 22:11:14.736768  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:11:14.878387  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6939
I1006 22:11:14.878422  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.08587 (* 1 = 1.08587 loss)
I1006 22:11:15.045507  4081 solver.cpp:218] Iteration 16500 (4.79713 iter/s, 20.8458s/100 iters), loss = 0.176527
I1006 22:11:15.045549  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.176527 (* 1 = 0.176527 loss)
I1006 22:11:15.045555  4081 sgd_solver.cpp:105] Iteration 16500, lr = 0.1
I1006 22:11:32.108495  4081 solver.cpp:218] Iteration 16600 (5.86068 iter/s, 17.0629s/100 iters), loss = 0.288585
I1006 22:11:32.108613  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.288585 (* 1 = 0.288585 loss)
I1006 22:11:32.108633  4081 sgd_solver.cpp:105] Iteration 16600, lr = 0.1
I1006 22:11:49.187535  4081 solver.cpp:218] Iteration 16700 (5.85519 iter/s, 17.0789s/100 iters), loss = 0.288155
I1006 22:11:49.187578  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.288155 (* 1 = 0.288155 loss)
I1006 22:11:49.187585  4081 sgd_solver.cpp:105] Iteration 16700, lr = 0.1
I1006 22:12:06.253391  4081 solver.cpp:218] Iteration 16800 (5.85969 iter/s, 17.0657s/100 iters), loss = 0.232913
I1006 22:12:06.253458  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.232913 (* 1 = 0.232913 loss)
I1006 22:12:06.253476  4081 sgd_solver.cpp:105] Iteration 16800, lr = 0.1
I1006 22:12:23.853826  4081 solver.cpp:218] Iteration 16900 (5.68172 iter/s, 17.6003s/100 iters), loss = 0.242933
I1006 22:12:23.853858  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.242933 (* 1 = 0.242933 loss)
I1006 22:12:23.853874  4081 sgd_solver.cpp:105] Iteration 16900, lr = 0.1
I1006 22:12:40.084141  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:12:40.767808  4081 solver.cpp:330] Iteration 17000, Testing net (#0)
I1006 22:12:44.360358  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:12:44.525876  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6934
I1006 22:12:44.525913  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.01208 (* 1 = 1.01208 loss)
I1006 22:12:44.658792  4081 solver.cpp:218] Iteration 17000 (4.80657 iter/s, 20.8049s/100 iters), loss = 0.21358
I1006 22:12:44.658824  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.21358 (* 1 = 0.21358 loss)
I1006 22:12:44.658845  4081 sgd_solver.cpp:105] Iteration 17000, lr = 0.1
I1006 22:13:01.786054  4081 solver.cpp:218] Iteration 17100 (5.83941 iter/s, 17.125s/100 iters), loss = 0.337519
I1006 22:13:01.786088  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.337519 (* 1 = 0.337519 loss)
I1006 22:13:01.786097  4081 sgd_solver.cpp:105] Iteration 17100, lr = 0.1
I1006 22:13:18.866976  4081 solver.cpp:218] Iteration 17200 (5.85452 iter/s, 17.0808s/100 iters), loss = 0.25216
I1006 22:13:18.867069  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.252161 (* 1 = 0.252161 loss)
I1006 22:13:18.867081  4081 sgd_solver.cpp:105] Iteration 17200, lr = 0.1
I1006 22:13:35.943948  4081 solver.cpp:218] Iteration 17300 (5.85589 iter/s, 17.0768s/100 iters), loss = 0.266627
I1006 22:13:35.943991  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.266627 (* 1 = 0.266627 loss)
I1006 22:13:35.943998  4081 sgd_solver.cpp:105] Iteration 17300, lr = 0.1
I1006 22:13:53.547718  4081 solver.cpp:218] Iteration 17400 (5.68064 iter/s, 17.6037s/100 iters), loss = 0.193979
I1006 22:13:53.547813  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.19398 (* 1 = 0.19398 loss)
I1006 22:13:53.547832  4081 sgd_solver.cpp:105] Iteration 17400, lr = 0.1
I1006 22:14:09.765547  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:14:10.446708  4081 solver.cpp:330] Iteration 17500, Testing net (#0)
I1006 22:14:14.046988  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:14:14.205775  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7827
I1006 22:14:14.205801  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.662152 (* 1 = 0.662152 loss)
I1006 22:14:14.301255  4081 solver.cpp:218] Iteration 17500 (4.81849 iter/s, 20.7534s/100 iters), loss = 0.173465
I1006 22:14:14.301298  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.173465 (* 1 = 0.173465 loss)
I1006 22:14:14.301306  4081 sgd_solver.cpp:105] Iteration 17500, lr = 0.1
I1006 22:14:31.453611  4081 solver.cpp:218] Iteration 17600 (5.83018 iter/s, 17.1521s/100 iters), loss = 0.239225
I1006 22:14:31.453732  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.239226 (* 1 = 0.239226 loss)
I1006 22:14:31.453740  4081 sgd_solver.cpp:105] Iteration 17600, lr = 0.1
I1006 22:14:48.543340  4081 solver.cpp:218] Iteration 17700 (5.85153 iter/s, 17.0896s/100 iters), loss = 0.291837
I1006 22:14:48.543373  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.291837 (* 1 = 0.291837 loss)
I1006 22:14:48.543392  4081 sgd_solver.cpp:105] Iteration 17700, lr = 0.1
I1006 22:15:05.631481  4081 solver.cpp:218] Iteration 17800 (5.85205 iter/s, 17.088s/100 iters), loss = 0.223346
I1006 22:15:05.631577  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.223347 (* 1 = 0.223347 loss)
I1006 22:15:05.631599  4081 sgd_solver.cpp:105] Iteration 17800, lr = 0.1
I1006 22:15:23.253106  4081 solver.cpp:218] Iteration 17900 (5.67489 iter/s, 17.6215s/100 iters), loss = 0.25239
I1006 22:15:23.253142  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.25239 (* 1 = 0.25239 loss)
I1006 22:15:23.253161  4081 sgd_solver.cpp:105] Iteration 17900, lr = 0.1
I1006 22:15:39.476573  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:15:40.156405  4081 solver.cpp:330] Iteration 18000, Testing net (#0)
I1006 22:15:43.755671  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:15:43.920749  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6602
I1006 22:15:43.920775  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.3895 (* 1 = 1.3895 loss)
I1006 22:15:44.052078  4081 solver.cpp:218] Iteration 18000 (4.80796 iter/s, 20.7989s/100 iters), loss = 0.253047
I1006 22:15:44.052119  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.253047 (* 1 = 0.253047 loss)
I1006 22:15:44.052126  4081 sgd_solver.cpp:105] Iteration 18000, lr = 0.1
I1006 22:16:01.162617  4081 solver.cpp:218] Iteration 18100 (5.8451 iter/s, 17.1083s/100 iters), loss = 0.221658
I1006 22:16:01.162648  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.221658 (* 1 = 0.221658 loss)
I1006 22:16:01.162665  4081 sgd_solver.cpp:105] Iteration 18100, lr = 0.1
I1006 22:16:18.225754  4081 solver.cpp:218] Iteration 18200 (5.86062 iter/s, 17.063s/100 iters), loss = 0.417865
I1006 22:16:18.225908  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.417865 (* 1 = 0.417865 loss)
I1006 22:16:18.225919  4081 sgd_solver.cpp:105] Iteration 18200, lr = 0.1
I1006 22:16:35.299104  4081 solver.cpp:218] Iteration 18300 (5.85715 iter/s, 17.0731s/100 iters), loss = 0.28796
I1006 22:16:35.299146  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.28796 (* 1 = 0.28796 loss)
I1006 22:16:35.299152  4081 sgd_solver.cpp:105] Iteration 18300, lr = 0.1
I1006 22:16:52.912443  4081 solver.cpp:218] Iteration 18400 (5.67755 iter/s, 17.6132s/100 iters), loss = 0.235758
I1006 22:16:52.912524  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.235758 (* 1 = 0.235758 loss)
I1006 22:16:52.912533  4081 sgd_solver.cpp:105] Iteration 18400, lr = 0.1
I1006 22:17:09.143054  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:17:09.824719  4081 solver.cpp:330] Iteration 18500, Testing net (#0)
I1006 22:17:13.396698  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:17:13.523891  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6815
I1006 22:17:13.523921  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.15132 (* 1 = 1.15132 loss)
I1006 22:17:13.675318  4081 solver.cpp:218] Iteration 18500 (4.8165 iter/s, 20.762s/100 iters), loss = 0.284154
I1006 22:17:13.675349  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.284155 (* 1 = 0.284155 loss)
I1006 22:17:13.675369  4081 sgd_solver.cpp:105] Iteration 18500, lr = 0.1
I1006 22:17:30.747573  4081 solver.cpp:218] Iteration 18600 (5.85749 iter/s, 17.0722s/100 iters), loss = 0.245394
I1006 22:17:30.747679  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.245394 (* 1 = 0.245394 loss)
I1006 22:17:30.747690  4081 sgd_solver.cpp:105] Iteration 18600, lr = 0.1
I1006 22:17:47.823494  4081 solver.cpp:218] Iteration 18700 (5.85626 iter/s, 17.0758s/100 iters), loss = 0.2681
I1006 22:17:47.823537  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.268101 (* 1 = 0.268101 loss)
I1006 22:17:47.823544  4081 sgd_solver.cpp:105] Iteration 18700, lr = 0.1
I1006 22:18:04.909252  4081 solver.cpp:218] Iteration 18800 (5.85287 iter/s, 17.0856s/100 iters), loss = 0.234592
I1006 22:18:04.909340  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.234592 (* 1 = 0.234592 loss)
I1006 22:18:04.909348  4081 sgd_solver.cpp:105] Iteration 18800, lr = 0.1
I1006 22:18:22.527592  4081 solver.cpp:218] Iteration 18900 (5.67595 iter/s, 17.6182s/100 iters), loss = 0.252193
I1006 22:18:22.527624  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.252193 (* 1 = 0.252193 loss)
I1006 22:18:22.527640  4081 sgd_solver.cpp:105] Iteration 18900, lr = 0.1
I1006 22:18:38.763871  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:18:39.443027  4081 solver.cpp:330] Iteration 19000, Testing net (#0)
I1006 22:18:43.037923  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:18:43.204254  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7269
I1006 22:18:43.204282  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.964166 (* 1 = 0.964166 loss)
I1006 22:18:43.335876  4081 solver.cpp:218] Iteration 19000 (4.8058 iter/s, 20.8082s/100 iters), loss = 0.232191
I1006 22:18:43.335918  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.232191 (* 1 = 0.232191 loss)
I1006 22:18:43.335927  4081 sgd_solver.cpp:105] Iteration 19000, lr = 0.1
I1006 22:19:00.451118  4081 solver.cpp:218] Iteration 19100 (5.8435 iter/s, 17.113s/100 iters), loss = 0.214853
I1006 22:19:00.451159  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.214853 (* 1 = 0.214853 loss)
I1006 22:19:00.451169  4081 sgd_solver.cpp:105] Iteration 19100, lr = 0.1
I1006 22:19:17.535084  4081 solver.cpp:218] Iteration 19200 (5.85348 iter/s, 17.0839s/100 iters), loss = 0.26228
I1006 22:19:17.535194  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.26228 (* 1 = 0.26228 loss)
I1006 22:19:17.535213  4081 sgd_solver.cpp:105] Iteration 19200, lr = 0.1
I1006 22:19:34.617576  4081 solver.cpp:218] Iteration 19300 (5.85401 iter/s, 17.0823s/100 iters), loss = 0.167536
I1006 22:19:34.617619  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.167536 (* 1 = 0.167536 loss)
I1006 22:19:34.617625  4081 sgd_solver.cpp:105] Iteration 19300, lr = 0.1
I1006 22:19:52.224372  4081 solver.cpp:218] Iteration 19400 (5.67966 iter/s, 17.6067s/100 iters), loss = 0.258001
I1006 22:19:52.224460  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.258001 (* 1 = 0.258001 loss)
I1006 22:19:52.224481  4081 sgd_solver.cpp:105] Iteration 19400, lr = 0.1
I1006 22:20:08.457777  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:20:09.141402  4081 solver.cpp:330] Iteration 19500, Testing net (#0)
I1006 22:20:12.740787  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:20:12.879266  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.758
I1006 22:20:12.879302  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.742302 (* 1 = 0.742302 loss)
I1006 22:20:12.996655  4081 solver.cpp:218] Iteration 19500 (4.81414 iter/s, 20.7721s/100 iters), loss = 0.272162
I1006 22:20:12.996700  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.272162 (* 1 = 0.272162 loss)
I1006 22:20:12.996708  4081 sgd_solver.cpp:105] Iteration 19500, lr = 0.1
I1006 22:20:30.176597  4081 solver.cpp:218] Iteration 19600 (5.82078 iter/s, 17.1798s/100 iters), loss = 0.208772
I1006 22:20:30.176709  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.208772 (* 1 = 0.208772 loss)
I1006 22:20:30.176717  4081 sgd_solver.cpp:105] Iteration 19600, lr = 0.1
I1006 22:20:47.269295  4081 solver.cpp:218] Iteration 19700 (5.85051 iter/s, 17.0925s/100 iters), loss = 0.320667
I1006 22:20:47.269330  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.320667 (* 1 = 0.320667 loss)
I1006 22:20:47.269346  4081 sgd_solver.cpp:105] Iteration 19700, lr = 0.1
I1006 22:21:04.360633  4081 solver.cpp:218] Iteration 19800 (5.85156 iter/s, 17.0895s/100 iters), loss = 0.211143
I1006 22:21:04.360795  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.211143 (* 1 = 0.211143 loss)
I1006 22:21:04.360806  4081 sgd_solver.cpp:105] Iteration 19800, lr = 0.1
I1006 22:21:21.972642  4081 solver.cpp:218] Iteration 19900 (5.67801 iter/s, 17.6118s/100 iters), loss = 0.289432
I1006 22:21:21.972683  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.289432 (* 1 = 0.289432 loss)
I1006 22:21:21.972689  4081 sgd_solver.cpp:105] Iteration 19900, lr = 0.1
I1006 22:21:38.208170  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:21:38.888169  4081 solver.cpp:330] Iteration 20000, Testing net (#0)
I1006 22:21:42.484387  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:21:42.625229  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7345
I1006 22:21:42.625257  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.886687 (* 1 = 0.886687 loss)
I1006 22:21:42.738870  4081 solver.cpp:218] Iteration 20000 (4.81554 iter/s, 20.7661s/100 iters), loss = 0.170535
I1006 22:21:42.738907  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.170535 (* 1 = 0.170535 loss)
I1006 22:21:42.738914  4081 sgd_solver.cpp:105] Iteration 20000, lr = 0.1
I1006 22:21:59.892967  4081 solver.cpp:218] Iteration 20100 (5.82955 iter/s, 17.154s/100 iters), loss = 0.252544
I1006 22:21:59.893009  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.252544 (* 1 = 0.252544 loss)
I1006 22:21:59.893016  4081 sgd_solver.cpp:105] Iteration 20100, lr = 0.1
I1006 22:22:16.983005  4081 solver.cpp:218] Iteration 20200 (5.8514 iter/s, 17.0899s/100 iters), loss = 0.24229
I1006 22:22:16.983074  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.24229 (* 1 = 0.24229 loss)
I1006 22:22:16.983084  4081 sgd_solver.cpp:105] Iteration 20200, lr = 0.1
I1006 22:22:34.055878  4081 solver.cpp:218] Iteration 20300 (5.85729 iter/s, 17.0727s/100 iters), loss = 0.211485
I1006 22:22:34.055914  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.211485 (* 1 = 0.211485 loss)
I1006 22:22:34.055933  4081 sgd_solver.cpp:105] Iteration 20300, lr = 0.1
I1006 22:22:51.650271  4081 solver.cpp:218] Iteration 20400 (5.68366 iter/s, 17.5943s/100 iters), loss = 0.221598
I1006 22:22:51.650363  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.221598 (* 1 = 0.221598 loss)
I1006 22:22:51.650383  4081 sgd_solver.cpp:105] Iteration 20400, lr = 0.1
I1006 22:23:07.872987  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:23:08.555886  4081 solver.cpp:330] Iteration 20500, Testing net (#0)
I1006 22:23:12.097311  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:23:12.239019  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6516
I1006 22:23:12.239048  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.38646 (* 1 = 1.38646 loss)
I1006 22:23:12.406744  4081 solver.cpp:218] Iteration 20500 (4.81781 iter/s, 20.7563s/100 iters), loss = 0.221226
I1006 22:23:12.406780  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.221226 (* 1 = 0.221226 loss)
I1006 22:23:12.406798  4081 sgd_solver.cpp:105] Iteration 20500, lr = 0.1
I1006 22:23:29.492575  4081 solver.cpp:218] Iteration 20600 (5.85284 iter/s, 17.0857s/100 iters), loss = 0.19195
I1006 22:23:29.492682  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.19195 (* 1 = 0.19195 loss)
I1006 22:23:29.492691  4081 sgd_solver.cpp:105] Iteration 20600, lr = 0.1
I1006 22:23:46.564687  4081 solver.cpp:218] Iteration 20700 (5.85802 iter/s, 17.0706s/100 iters), loss = 0.180105
I1006 22:23:46.564728  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.180105 (* 1 = 0.180105 loss)
I1006 22:23:46.564735  4081 sgd_solver.cpp:105] Iteration 20700, lr = 0.1
I1006 22:24:03.636181  4081 solver.cpp:218] Iteration 20800 (5.85776 iter/s, 17.0714s/100 iters), loss = 0.214916
I1006 22:24:03.636343  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.214916 (* 1 = 0.214916 loss)
I1006 22:24:03.636351  4081 sgd_solver.cpp:105] Iteration 20800, lr = 0.1
I1006 22:24:21.240685  4081 solver.cpp:218] Iteration 20900 (5.68043 iter/s, 17.6043s/100 iters), loss = 0.157852
I1006 22:24:21.240728  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.157852 (* 1 = 0.157852 loss)
I1006 22:24:21.240736  4081 sgd_solver.cpp:105] Iteration 20900, lr = 0.1
I1006 22:24:37.459264  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:24:38.139129  4081 solver.cpp:330] Iteration 21000, Testing net (#0)
I1006 22:24:41.736120  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:24:41.876318  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7662
I1006 22:24:41.876354  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.843171 (* 1 = 0.843171 loss)
I1006 22:24:41.990710  4081 solver.cpp:218] Iteration 21000 (4.8193 iter/s, 20.7499s/100 iters), loss = 0.175546
I1006 22:24:41.990749  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.175546 (* 1 = 0.175546 loss)
I1006 22:24:41.990757  4081 sgd_solver.cpp:105] Iteration 21000, lr = 0.1
I1006 22:24:59.136317  4081 solver.cpp:218] Iteration 21100 (5.83243 iter/s, 17.1455s/100 iters), loss = 0.216896
I1006 22:24:59.136349  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.216896 (* 1 = 0.216896 loss)
I1006 22:24:59.136368  4081 sgd_solver.cpp:105] Iteration 21100, lr = 0.1
I1006 22:25:16.197975  4081 solver.cpp:218] Iteration 21200 (5.86113 iter/s, 17.0616s/100 iters), loss = 0.288927
I1006 22:25:16.198081  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.288927 (* 1 = 0.288927 loss)
I1006 22:25:16.198089  4081 sgd_solver.cpp:105] Iteration 21200, lr = 0.1
I1006 22:25:33.269500  4081 solver.cpp:218] Iteration 21300 (5.85777 iter/s, 17.0714s/100 iters), loss = 0.246667
I1006 22:25:33.269544  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.246667 (* 1 = 0.246667 loss)
I1006 22:25:33.269551  4081 sgd_solver.cpp:105] Iteration 21300, lr = 0.1
I1006 22:25:50.874166  4081 solver.cpp:218] Iteration 21400 (5.68035 iter/s, 17.6046s/100 iters), loss = 0.259337
I1006 22:25:50.874249  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.259337 (* 1 = 0.259337 loss)
I1006 22:25:50.874269  4081 sgd_solver.cpp:105] Iteration 21400, lr = 0.1
I1006 22:26:07.105044  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:26:07.788008  4081 solver.cpp:330] Iteration 21500, Testing net (#0)
I1006 22:26:11.388267  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:26:11.547317  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7249
I1006 22:26:11.547354  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.888496 (* 1 = 0.888496 loss)
I1006 22:26:11.684545  4081 solver.cpp:218] Iteration 21500 (4.80533 iter/s, 20.8102s/100 iters), loss = 0.212582
I1006 22:26:11.684586  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.212582 (* 1 = 0.212582 loss)
I1006 22:26:11.684592  4081 sgd_solver.cpp:105] Iteration 21500, lr = 0.1
I1006 22:26:28.792362  4081 solver.cpp:218] Iteration 21600 (5.84603 iter/s, 17.1056s/100 iters), loss = 0.179509
I1006 22:26:28.792441  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.179508 (* 1 = 0.179508 loss)
I1006 22:26:28.792450  4081 sgd_solver.cpp:105] Iteration 21600, lr = 0.1
I1006 22:26:45.878689  4081 solver.cpp:218] Iteration 21700 (5.85268 iter/s, 17.0862s/100 iters), loss = 0.29457
I1006 22:26:45.878729  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.29457 (* 1 = 0.29457 loss)
I1006 22:26:45.878736  4081 sgd_solver.cpp:105] Iteration 21700, lr = 0.1
I1006 22:27:02.970039  4081 solver.cpp:218] Iteration 21800 (5.85095 iter/s, 17.0912s/100 iters), loss = 0.261017
I1006 22:27:02.970155  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.261017 (* 1 = 0.261017 loss)
I1006 22:27:02.970176  4081 sgd_solver.cpp:105] Iteration 21800, lr = 0.1
I1006 22:27:20.573568  4081 solver.cpp:218] Iteration 21900 (5.68073 iter/s, 17.6034s/100 iters), loss = 0.237099
I1006 22:27:20.573609  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.237099 (* 1 = 0.237099 loss)
I1006 22:27:20.573616  4081 sgd_solver.cpp:105] Iteration 21900, lr = 0.1
I1006 22:27:36.806869  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:27:37.489054  4081 solver.cpp:330] Iteration 22000, Testing net (#0)
I1006 22:27:41.087115  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:27:41.226634  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6124
I1006 22:27:41.226675  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.7374 (* 1 = 1.7374 loss)
I1006 22:27:41.339823  4081 solver.cpp:218] Iteration 22000 (4.81553 iter/s, 20.7661s/100 iters), loss = 0.177863
I1006 22:27:41.339851  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.177863 (* 1 = 0.177863 loss)
I1006 22:27:41.339867  4081 sgd_solver.cpp:105] Iteration 22000, lr = 0.1
I1006 22:27:58.489146  4081 solver.cpp:218] Iteration 22100 (5.83117 iter/s, 17.1492s/100 iters), loss = 0.222593
I1006 22:27:58.489188  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.222593 (* 1 = 0.222593 loss)
I1006 22:27:58.489195  4081 sgd_solver.cpp:105] Iteration 22100, lr = 0.1
I1006 22:28:15.567917  4081 solver.cpp:218] Iteration 22200 (5.85526 iter/s, 17.0787s/100 iters), loss = 0.154649
I1006 22:28:15.568007  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.154649 (* 1 = 0.154649 loss)
I1006 22:28:15.568024  4081 sgd_solver.cpp:105] Iteration 22200, lr = 0.1
I1006 22:28:32.654655  4081 solver.cpp:218] Iteration 22300 (5.85255 iter/s, 17.0866s/100 iters), loss = 0.218888
I1006 22:28:32.654688  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.218888 (* 1 = 0.218888 loss)
I1006 22:28:32.654695  4081 sgd_solver.cpp:105] Iteration 22300, lr = 0.1
I1006 22:28:50.281111  4081 solver.cpp:218] Iteration 22400 (5.67384 iter/s, 17.6248s/100 iters), loss = 0.185528
I1006 22:28:50.281193  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.185528 (* 1 = 0.185528 loss)
I1006 22:28:50.281200  4081 sgd_solver.cpp:105] Iteration 22400, lr = 0.1
I1006 22:29:06.493247  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:29:07.173928  4081 solver.cpp:330] Iteration 22500, Testing net (#0)
I1006 22:29:10.771364  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:29:10.933295  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8035
I1006 22:29:10.933323  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.605064 (* 1 = 0.605064 loss)
I1006 22:29:11.026634  4081 solver.cpp:218] Iteration 22500 (4.82035 iter/s, 20.7454s/100 iters), loss = 0.14926
I1006 22:29:11.026670  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.14926 (* 1 = 0.14926 loss)
I1006 22:29:11.026677  4081 sgd_solver.cpp:105] Iteration 22500, lr = 0.1
I1006 22:29:28.177376  4081 solver.cpp:218] Iteration 22600 (5.83072 iter/s, 17.1505s/100 iters), loss = 0.202094
I1006 22:29:28.177486  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.202094 (* 1 = 0.202094 loss)
I1006 22:29:28.177505  4081 sgd_solver.cpp:105] Iteration 22600, lr = 0.1
I1006 22:29:45.252406  4081 solver.cpp:218] Iteration 22700 (5.85657 iter/s, 17.0749s/100 iters), loss = 0.350602
I1006 22:29:45.252449  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.350602 (* 1 = 0.350602 loss)
I1006 22:29:45.252455  4081 sgd_solver.cpp:105] Iteration 22700, lr = 0.1
I1006 22:30:02.330549  4081 solver.cpp:218] Iteration 22800 (5.85548 iter/s, 17.078s/100 iters), loss = 0.190936
I1006 22:30:02.330682  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.190936 (* 1 = 0.190936 loss)
I1006 22:30:02.330691  4081 sgd_solver.cpp:105] Iteration 22800, lr = 0.1
I1006 22:30:19.859045  4081 solver.cpp:218] Iteration 22900 (5.70506 iter/s, 17.5283s/100 iters), loss = 0.179062
I1006 22:30:19.859086  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.179062 (* 1 = 0.179062 loss)
I1006 22:30:19.859093  4081 sgd_solver.cpp:105] Iteration 22900, lr = 0.1
I1006 22:30:36.088618  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:30:36.769526  4081 solver.cpp:330] Iteration 23000, Testing net (#0)
I1006 22:30:40.368031  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:30:40.534348  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7745
I1006 22:30:40.534384  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.767292 (* 1 = 0.767292 loss)
I1006 22:30:40.642261  4081 solver.cpp:218] Iteration 23000 (4.8116 iter/s, 20.7831s/100 iters), loss = 0.194422
I1006 22:30:40.642289  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.194422 (* 1 = 0.194422 loss)
I1006 22:30:40.642298  4081 sgd_solver.cpp:105] Iteration 23000, lr = 0.1
I1006 22:30:57.783411  4081 solver.cpp:218] Iteration 23100 (5.83395 iter/s, 17.141s/100 iters), loss = 0.19523
I1006 22:30:57.783442  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.19523 (* 1 = 0.19523 loss)
I1006 22:30:57.783448  4081 sgd_solver.cpp:105] Iteration 23100, lr = 0.1
I1006 22:31:14.857286  4081 solver.cpp:218] Iteration 23200 (5.85694 iter/s, 17.0738s/100 iters), loss = 0.213385
I1006 22:31:14.857385  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.213385 (* 1 = 0.213385 loss)
I1006 22:31:14.857403  4081 sgd_solver.cpp:105] Iteration 23200, lr = 0.1
I1006 22:31:31.936570  4081 solver.cpp:218] Iteration 23300 (5.8551 iter/s, 17.0791s/100 iters), loss = 0.353052
I1006 22:31:31.936614  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.353052 (* 1 = 0.353052 loss)
I1006 22:31:31.936620  4081 sgd_solver.cpp:105] Iteration 23300, lr = 0.1
I1006 22:31:49.551321  4081 solver.cpp:218] Iteration 23400 (5.67748 iter/s, 17.6135s/100 iters), loss = 0.228322
I1006 22:31:49.551427  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.228322 (* 1 = 0.228322 loss)
I1006 22:31:49.551435  4081 sgd_solver.cpp:105] Iteration 23400, lr = 0.1
I1006 22:32:05.777305  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:32:06.456895  4081 solver.cpp:330] Iteration 23500, Testing net (#0)
I1006 22:32:10.052587  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:32:10.218212  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7816
I1006 22:32:10.218248  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.698094 (* 1 = 0.698094 loss)
I1006 22:32:10.319068  4081 solver.cpp:218] Iteration 23500 (4.8152 iter/s, 20.7676s/100 iters), loss = 0.211725
I1006 22:32:10.319102  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.211725 (* 1 = 0.211725 loss)
I1006 22:32:10.319109  4081 sgd_solver.cpp:105] Iteration 23500, lr = 0.1
I1006 22:32:27.446722  4081 solver.cpp:218] Iteration 23600 (5.83928 iter/s, 17.1254s/100 iters), loss = 0.212869
I1006 22:32:27.446835  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.212869 (* 1 = 0.212869 loss)
I1006 22:32:27.446843  4081 sgd_solver.cpp:105] Iteration 23600, lr = 0.1
I1006 22:32:44.520642  4081 solver.cpp:218] Iteration 23700 (5.85695 iter/s, 17.0737s/100 iters), loss = 0.206657
I1006 22:32:44.520683  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.206657 (* 1 = 0.206657 loss)
I1006 22:32:44.520689  4081 sgd_solver.cpp:105] Iteration 23700, lr = 0.1
I1006 22:33:01.564265  4081 solver.cpp:218] Iteration 23800 (5.86733 iter/s, 17.0435s/100 iters), loss = 0.217491
I1006 22:33:01.564389  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.217491 (* 1 = 0.217491 loss)
I1006 22:33:01.564399  4081 sgd_solver.cpp:105] Iteration 23800, lr = 0.1
I1006 22:33:19.167188  4081 solver.cpp:218] Iteration 23900 (5.68094 iter/s, 17.6027s/100 iters), loss = 0.111688
I1006 22:33:19.167222  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.111688 (* 1 = 0.111688 loss)
I1006 22:33:19.167238  4081 sgd_solver.cpp:105] Iteration 23900, lr = 0.1
I1006 22:33:35.378157  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:33:36.059794  4081 solver.cpp:330] Iteration 24000, Testing net (#0)
I1006 22:33:39.651659  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:33:39.816958  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6717
I1006 22:33:39.816993  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.25364 (* 1 = 1.25364 loss)
I1006 22:33:39.950453  4081 solver.cpp:218] Iteration 24000 (4.81159 iter/s, 20.7832s/100 iters), loss = 0.275275
I1006 22:33:39.950497  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.275275 (* 1 = 0.275275 loss)
I1006 22:33:39.950505  4081 sgd_solver.cpp:105] Iteration 24000, lr = 0.1
I1006 22:33:57.051112  4081 solver.cpp:218] Iteration 24100 (5.84849 iter/s, 17.0984s/100 iters), loss = 0.186965
I1006 22:33:57.051154  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.186965 (* 1 = 0.186965 loss)
I1006 22:33:57.051162  4081 sgd_solver.cpp:105] Iteration 24100, lr = 0.1
I1006 22:34:14.125706  4081 solver.cpp:218] Iteration 24200 (5.85669 iter/s, 17.0745s/100 iters), loss = 0.218717
I1006 22:34:14.125816  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.218717 (* 1 = 0.218717 loss)
I1006 22:34:14.125834  4081 sgd_solver.cpp:105] Iteration 24200, lr = 0.1
I1006 22:34:31.226197  4081 solver.cpp:218] Iteration 24300 (5.84784 iter/s, 17.1003s/100 iters), loss = 0.294523
I1006 22:34:31.226231  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.294523 (* 1 = 0.294523 loss)
I1006 22:34:31.226249  4081 sgd_solver.cpp:105] Iteration 24300, lr = 0.1
I1006 22:34:48.840873  4081 solver.cpp:218] Iteration 24400 (5.67712 iter/s, 17.6146s/100 iters), loss = 0.249547
I1006 22:34:48.840971  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.249547 (* 1 = 0.249547 loss)
I1006 22:34:48.840983  4081 sgd_solver.cpp:105] Iteration 24400, lr = 0.1
I1006 22:35:05.060389  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:35:05.741228  4081 solver.cpp:330] Iteration 24500, Testing net (#0)
I1006 22:35:09.251780  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:35:09.404476  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7749
I1006 22:35:09.404506  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.699002 (* 1 = 0.699002 loss)
I1006 22:35:09.506145  4081 solver.cpp:218] Iteration 24500 (4.83907 iter/s, 20.6651s/100 iters), loss = 0.173517
I1006 22:35:09.506177  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.173517 (* 1 = 0.173517 loss)
I1006 22:35:09.506197  4081 sgd_solver.cpp:105] Iteration 24500, lr = 0.1
I1006 22:35:26.674595  4081 solver.cpp:218] Iteration 24600 (5.82467 iter/s, 17.1684s/100 iters), loss = 0.177991
I1006 22:35:26.674723  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.177991 (* 1 = 0.177991 loss)
I1006 22:35:26.674741  4081 sgd_solver.cpp:105] Iteration 24600, lr = 0.1
I1006 22:35:43.746470  4081 solver.cpp:218] Iteration 24700 (5.85765 iter/s, 17.0717s/100 iters), loss = 0.148656
I1006 22:35:43.746505  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.148656 (* 1 = 0.148656 loss)
I1006 22:35:43.746512  4081 sgd_solver.cpp:105] Iteration 24700, lr = 0.1
I1006 22:36:00.832612  4081 solver.cpp:218] Iteration 24800 (5.85307 iter/s, 17.085s/100 iters), loss = 0.230181
I1006 22:36:00.832739  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.230181 (* 1 = 0.230181 loss)
I1006 22:36:00.832748  4081 sgd_solver.cpp:105] Iteration 24800, lr = 0.1
I1006 22:36:18.452988  4081 solver.cpp:218] Iteration 24900 (5.67531 iter/s, 17.6202s/100 iters), loss = 0.219765
I1006 22:36:18.453032  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.219765 (* 1 = 0.219765 loss)
I1006 22:36:18.453038  4081 sgd_solver.cpp:105] Iteration 24900, lr = 0.1
I1006 22:36:34.708875  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:36:35.372786  4081 solver.cpp:330] Iteration 25000, Testing net (#0)
I1006 22:36:38.965034  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:36:39.131076  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7904
I1006 22:36:39.131111  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.686044 (* 1 = 0.686044 loss)
I1006 22:36:39.233728  4081 solver.cpp:218] Iteration 25000 (4.81218 iter/s, 20.7806s/100 iters), loss = 0.197011
I1006 22:36:39.233762  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.197011 (* 1 = 0.197011 loss)
I1006 22:36:39.233779  4081 sgd_solver.cpp:105] Iteration 25000, lr = 0.1
I1006 22:36:56.382565  4081 solver.cpp:218] Iteration 25100 (5.83206 iter/s, 17.1466s/100 iters), loss = 0.193054
I1006 22:36:56.382606  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.193054 (* 1 = 0.193054 loss)
I1006 22:36:56.382613  4081 sgd_solver.cpp:105] Iteration 25100, lr = 0.1
I1006 22:37:13.459334  4081 solver.cpp:218] Iteration 25200 (5.85595 iter/s, 17.0767s/100 iters), loss = 0.183693
I1006 22:37:13.459429  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.183693 (* 1 = 0.183693 loss)
I1006 22:37:13.459448  4081 sgd_solver.cpp:105] Iteration 25200, lr = 0.1
I1006 22:37:30.539711  4081 solver.cpp:218] Iteration 25300 (5.85473 iter/s, 17.0802s/100 iters), loss = 0.202302
I1006 22:37:30.539754  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.202302 (* 1 = 0.202302 loss)
I1006 22:37:30.539760  4081 sgd_solver.cpp:105] Iteration 25300, lr = 0.1
I1006 22:37:48.157438  4081 solver.cpp:218] Iteration 25400 (5.67614 iter/s, 17.6176s/100 iters), loss = 0.207947
I1006 22:37:48.157522  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.207947 (* 1 = 0.207947 loss)
I1006 22:37:48.157539  4081 sgd_solver.cpp:105] Iteration 25400, lr = 0.1
I1006 22:38:04.383700  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:38:05.067376  4081 solver.cpp:330] Iteration 25500, Testing net (#0)
I1006 22:38:08.662345  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:38:08.827754  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7344
I1006 22:38:08.827790  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.02127 (* 1 = 1.02127 loss)
I1006 22:38:08.961030  4081 solver.cpp:218] Iteration 25500 (4.8069 iter/s, 20.8034s/100 iters), loss = 0.199753
I1006 22:38:08.961060  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.199753 (* 1 = 0.199753 loss)
I1006 22:38:08.961066  4081 sgd_solver.cpp:105] Iteration 25500, lr = 0.1
I1006 22:38:26.084900  4081 solver.cpp:218] Iteration 25600 (5.84055 iter/s, 17.1217s/100 iters), loss = 0.341715
I1006 22:38:26.084991  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.341715 (* 1 = 0.341715 loss)
I1006 22:38:26.085011  4081 sgd_solver.cpp:105] Iteration 25600, lr = 0.1
I1006 22:38:43.162580  4081 solver.cpp:218] Iteration 25700 (5.85565 iter/s, 17.0775s/100 iters), loss = 0.194506
I1006 22:38:43.162621  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.194506 (* 1 = 0.194506 loss)
I1006 22:38:43.162627  4081 sgd_solver.cpp:105] Iteration 25700, lr = 0.1
I1006 22:39:00.243638  4081 solver.cpp:218] Iteration 25800 (5.85448 iter/s, 17.0809s/100 iters), loss = 0.210549
I1006 22:39:00.243752  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.210549 (* 1 = 0.210549 loss)
I1006 22:39:00.243763  4081 sgd_solver.cpp:105] Iteration 25800, lr = 0.1
I1006 22:39:17.867149  4081 solver.cpp:218] Iteration 25900 (5.6743 iter/s, 17.6233s/100 iters), loss = 0.127967
I1006 22:39:17.867183  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.127967 (* 1 = 0.127967 loss)
I1006 22:39:17.867200  4081 sgd_solver.cpp:105] Iteration 25900, lr = 0.1
I1006 22:39:34.106570  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:39:34.790457  4081 solver.cpp:330] Iteration 26000, Testing net (#0)
I1006 22:39:38.388803  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:39:38.528890  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6641
I1006 22:39:38.528926  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.51556 (* 1 = 1.51556 loss)
I1006 22:39:38.642686  4081 solver.cpp:218] Iteration 26000 (4.81338 iter/s, 20.7754s/100 iters), loss = 0.20929
I1006 22:39:38.642722  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.20929 (* 1 = 0.20929 loss)
I1006 22:39:38.642740  4081 sgd_solver.cpp:105] Iteration 26000, lr = 0.1
I1006 22:39:55.804581  4081 solver.cpp:218] Iteration 26100 (5.8269 iter/s, 17.1618s/100 iters), loss = 0.275555
I1006 22:39:55.804622  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.275555 (* 1 = 0.275555 loss)
I1006 22:39:55.804630  4081 sgd_solver.cpp:105] Iteration 26100, lr = 0.1
I1006 22:40:12.882937  4081 solver.cpp:218] Iteration 26200 (5.8554 iter/s, 17.0783s/100 iters), loss = 0.237467
I1006 22:40:12.883021  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.237467 (* 1 = 0.237467 loss)
I1006 22:40:12.883033  4081 sgd_solver.cpp:105] Iteration 26200, lr = 0.1
I1006 22:40:29.960000  4081 solver.cpp:218] Iteration 26300 (5.85612 iter/s, 17.0762s/100 iters), loss = 0.240784
I1006 22:40:29.960041  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.240784 (* 1 = 0.240784 loss)
I1006 22:40:29.960047  4081 sgd_solver.cpp:105] Iteration 26300, lr = 0.1
I1006 22:40:47.563151  4081 solver.cpp:218] Iteration 26400 (5.68084 iter/s, 17.603s/100 iters), loss = 0.152801
I1006 22:40:47.563262  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.152801 (* 1 = 0.152801 loss)
I1006 22:40:47.563282  4081 sgd_solver.cpp:105] Iteration 26400, lr = 0.1
I1006 22:41:03.790750  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:41:04.472846  4081 solver.cpp:330] Iteration 26500, Testing net (#0)
I1006 22:41:08.067363  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:41:08.234038  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7841
I1006 22:41:08.234076  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.754012 (* 1 = 0.754012 loss)
I1006 22:41:08.401597  4081 solver.cpp:218] Iteration 26500 (4.79886 iter/s, 20.8383s/100 iters), loss = 0.234567
I1006 22:41:08.401643  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.234567 (* 1 = 0.234567 loss)
I1006 22:41:08.401649  4081 sgd_solver.cpp:105] Iteration 26500, lr = 0.1
I1006 22:41:25.461030  4081 solver.cpp:218] Iteration 26600 (5.8619 iter/s, 17.0593s/100 iters), loss = 0.25687
I1006 22:41:25.461109  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.25687 (* 1 = 0.25687 loss)
I1006 22:41:25.461117  4081 sgd_solver.cpp:105] Iteration 26600, lr = 0.1
I1006 22:41:42.527091  4081 solver.cpp:218] Iteration 26700 (5.85963 iter/s, 17.0659s/100 iters), loss = 0.213948
I1006 22:41:42.527129  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.213948 (* 1 = 0.213948 loss)
I1006 22:41:42.527137  4081 sgd_solver.cpp:105] Iteration 26700, lr = 0.1
I1006 22:41:59.606923  4081 solver.cpp:218] Iteration 26800 (5.85489 iter/s, 17.0797s/100 iters), loss = 0.223578
I1006 22:41:59.607015  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.223578 (* 1 = 0.223578 loss)
I1006 22:41:59.607033  4081 sgd_solver.cpp:105] Iteration 26800, lr = 0.1
I1006 22:42:17.230398  4081 solver.cpp:218] Iteration 26900 (5.6743 iter/s, 17.6233s/100 iters), loss = 0.228567
I1006 22:42:17.230440  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.228567 (* 1 = 0.228567 loss)
I1006 22:42:17.230446  4081 sgd_solver.cpp:105] Iteration 26900, lr = 0.1
I1006 22:42:33.452507  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:42:34.135766  4081 solver.cpp:330] Iteration 27000, Testing net (#0)
I1006 22:42:37.735894  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:42:37.901278  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7871
I1006 22:42:37.901314  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.706662 (* 1 = 0.706662 loss)
I1006 22:42:38.006844  4081 solver.cpp:218] Iteration 27000 (4.81317 iter/s, 20.7763s/100 iters), loss = 0.148167
I1006 22:42:38.006881  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.148167 (* 1 = 0.148167 loss)
I1006 22:42:38.006888  4081 sgd_solver.cpp:105] Iteration 27000, lr = 0.1
I1006 22:42:55.160023  4081 solver.cpp:218] Iteration 27100 (5.83059 iter/s, 17.1509s/100 iters), loss = 0.283989
I1006 22:42:55.160058  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.283989 (* 1 = 0.283989 loss)
I1006 22:42:55.160078  4081 sgd_solver.cpp:105] Iteration 27100, lr = 0.1
I1006 22:43:12.247717  4081 solver.cpp:218] Iteration 27200 (5.8522 iter/s, 17.0876s/100 iters), loss = 0.188687
I1006 22:43:12.247813  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.188687 (* 1 = 0.188687 loss)
I1006 22:43:12.247836  4081 sgd_solver.cpp:105] Iteration 27200, lr = 0.1
I1006 22:43:29.331279  4081 solver.cpp:218] Iteration 27300 (5.85364 iter/s, 17.0834s/100 iters), loss = 0.249363
I1006 22:43:29.331313  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.249363 (* 1 = 0.249363 loss)
I1006 22:43:29.331332  4081 sgd_solver.cpp:105] Iteration 27300, lr = 0.1
I1006 22:43:46.946907  4081 solver.cpp:218] Iteration 27400 (5.67681 iter/s, 17.6155s/100 iters), loss = 0.15013
I1006 22:43:46.947000  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.15013 (* 1 = 0.15013 loss)
I1006 22:43:46.947022  4081 sgd_solver.cpp:105] Iteration 27400, lr = 0.1
I1006 22:44:03.185524  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:44:03.867900  4081 solver.cpp:330] Iteration 27500, Testing net (#0)
I1006 22:44:07.467274  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:44:07.631991  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6852
I1006 22:44:07.632019  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.35094 (* 1 = 1.35094 loss)
I1006 22:44:07.767102  4081 solver.cpp:218] Iteration 27500 (4.80306 iter/s, 20.82s/100 iters), loss = 0.205247
I1006 22:44:07.767140  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.205247 (* 1 = 0.205247 loss)
I1006 22:44:07.767148  4081 sgd_solver.cpp:105] Iteration 27500, lr = 0.1
I1006 22:44:24.882061  4081 solver.cpp:218] Iteration 27600 (5.84359 iter/s, 17.1128s/100 iters), loss = 0.155352
I1006 22:44:24.882203  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.155352 (* 1 = 0.155352 loss)
I1006 22:44:24.882211  4081 sgd_solver.cpp:105] Iteration 27600, lr = 0.1
I1006 22:44:41.948936  4081 solver.cpp:218] Iteration 27700 (5.85937 iter/s, 17.0667s/100 iters), loss = 0.228012
I1006 22:44:41.948979  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.228012 (* 1 = 0.228012 loss)
I1006 22:44:41.948987  4081 sgd_solver.cpp:105] Iteration 27700, lr = 0.1
I1006 22:44:59.010234  4081 solver.cpp:218] Iteration 27800 (5.86126 iter/s, 17.0612s/100 iters), loss = 0.185684
I1006 22:44:59.010327  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.185684 (* 1 = 0.185684 loss)
I1006 22:44:59.010349  4081 sgd_solver.cpp:105] Iteration 27800, lr = 0.1
I1006 22:45:16.623425  4081 solver.cpp:218] Iteration 27900 (5.67761 iter/s, 17.613s/100 iters), loss = 0.177571
I1006 22:45:16.623456  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.177571 (* 1 = 0.177571 loss)
I1006 22:45:16.623462  4081 sgd_solver.cpp:105] Iteration 27900, lr = 0.1
I1006 22:45:32.857339  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:45:33.541379  4081 solver.cpp:330] Iteration 28000, Testing net (#0)
I1006 22:45:37.137368  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:45:37.303587  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7625
I1006 22:45:37.303613  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.734255 (* 1 = 0.734255 loss)
I1006 22:45:37.408531  4081 solver.cpp:218] Iteration 28000 (4.81116 iter/s, 20.785s/100 iters), loss = 0.150215
I1006 22:45:37.408571  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.150215 (* 1 = 0.150215 loss)
I1006 22:45:37.408578  4081 sgd_solver.cpp:105] Iteration 28000, lr = 0.1
I1006 22:45:54.538877  4081 solver.cpp:218] Iteration 28100 (5.83836 iter/s, 17.1281s/100 iters), loss = 0.200664
I1006 22:45:54.538918  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.200664 (* 1 = 0.200664 loss)
I1006 22:45:54.538924  4081 sgd_solver.cpp:105] Iteration 28100, lr = 0.1
I1006 22:46:11.609163  4081 solver.cpp:218] Iteration 28200 (5.85817 iter/s, 17.0702s/100 iters), loss = 0.202707
I1006 22:46:11.609277  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.202707 (* 1 = 0.202707 loss)
I1006 22:46:11.609287  4081 sgd_solver.cpp:105] Iteration 28200, lr = 0.1
I1006 22:46:28.681646  4081 solver.cpp:218] Iteration 28300 (5.85744 iter/s, 17.0723s/100 iters), loss = 0.278837
I1006 22:46:28.681689  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.278838 (* 1 = 0.278838 loss)
I1006 22:46:28.681695  4081 sgd_solver.cpp:105] Iteration 28300, lr = 0.1
I1006 22:46:46.288568  4081 solver.cpp:218] Iteration 28400 (5.67962 iter/s, 17.6068s/100 iters), loss = 0.215429
I1006 22:46:46.288682  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.215429 (* 1 = 0.215429 loss)
I1006 22:46:46.288703  4081 sgd_solver.cpp:105] Iteration 28400, lr = 0.1
I1006 22:47:02.520254  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:47:03.202946  4081 solver.cpp:330] Iteration 28500, Testing net (#0)
I1006 22:47:06.823289  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:47:06.965345  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7065
I1006 22:47:06.965379  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.01316 (* 1 = 1.01316 loss)
I1006 22:47:07.132774  4081 solver.cpp:218] Iteration 28500 (4.79754 iter/s, 20.844s/100 iters), loss = 0.191224
I1006 22:47:07.132813  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.191224 (* 1 = 0.191224 loss)
I1006 22:47:07.132819  4081 sgd_solver.cpp:105] Iteration 28500, lr = 0.1
I1006 22:47:24.216531  4081 solver.cpp:218] Iteration 28600 (5.85355 iter/s, 17.0837s/100 iters), loss = 0.198596
I1006 22:47:24.216634  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.198596 (* 1 = 0.198596 loss)
I1006 22:47:24.216653  4081 sgd_solver.cpp:105] Iteration 28600, lr = 0.1
I1006 22:47:41.294164  4081 solver.cpp:218] Iteration 28700 (5.85567 iter/s, 17.0775s/100 iters), loss = 0.209739
I1006 22:47:41.294206  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.209739 (* 1 = 0.209739 loss)
I1006 22:47:41.294214  4081 sgd_solver.cpp:105] Iteration 28700, lr = 0.1
I1006 22:47:58.361619  4081 solver.cpp:218] Iteration 28800 (5.85914 iter/s, 17.0673s/100 iters), loss = 0.288382
I1006 22:47:58.361727  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.288383 (* 1 = 0.288383 loss)
I1006 22:47:58.361744  4081 sgd_solver.cpp:105] Iteration 28800, lr = 0.1
I1006 22:48:15.985397  4081 solver.cpp:218] Iteration 28900 (5.67441 iter/s, 17.623s/100 iters), loss = 0.0877529
I1006 22:48:15.985429  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.087753 (* 1 = 0.087753 loss)
I1006 22:48:15.985435  4081 sgd_solver.cpp:105] Iteration 28900, lr = 0.1
I1006 22:48:32.208545  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:48:32.890803  4081 solver.cpp:330] Iteration 29000, Testing net (#0)
I1006 22:48:36.486153  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:48:36.652750  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7902
I1006 22:48:36.652787  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.716505 (* 1 = 0.716505 loss)
I1006 22:48:36.753376  4081 solver.cpp:218] Iteration 29000 (4.81513 iter/s, 20.7679s/100 iters), loss = 0.200763
I1006 22:48:36.753408  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.200763 (* 1 = 0.200763 loss)
I1006 22:48:36.753427  4081 sgd_solver.cpp:105] Iteration 29000, lr = 0.1
I1006 22:48:53.903764  4081 solver.cpp:218] Iteration 29100 (5.83153 iter/s, 17.1481s/100 iters), loss = 0.204887
I1006 22:48:53.903806  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.204887 (* 1 = 0.204887 loss)
I1006 22:48:53.903813  4081 sgd_solver.cpp:105] Iteration 29100, lr = 0.1
I1006 22:49:10.977864  4081 solver.cpp:218] Iteration 29200 (5.85686 iter/s, 17.074s/100 iters), loss = 0.198766
I1006 22:49:10.977951  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.198767 (* 1 = 0.198767 loss)
I1006 22:49:10.977958  4081 sgd_solver.cpp:105] Iteration 29200, lr = 0.1
I1006 22:49:28.061483  4081 solver.cpp:218] Iteration 29300 (5.85361 iter/s, 17.0835s/100 iters), loss = 0.232018
I1006 22:49:28.061525  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.232018 (* 1 = 0.232018 loss)
I1006 22:49:28.061532  4081 sgd_solver.cpp:105] Iteration 29300, lr = 0.1
I1006 22:49:45.670395  4081 solver.cpp:218] Iteration 29400 (5.67898 iter/s, 17.6088s/100 iters), loss = 0.226238
I1006 22:49:45.670501  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.226238 (* 1 = 0.226238 loss)
I1006 22:49:45.670509  4081 sgd_solver.cpp:105] Iteration 29400, lr = 0.1
I1006 22:50:01.893076  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:50:02.573165  4081 solver.cpp:330] Iteration 29500, Testing net (#0)
I1006 22:50:06.147835  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:50:06.274621  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7629
I1006 22:50:06.274647  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.742871 (* 1 = 0.742871 loss)
I1006 22:50:06.422511  4081 solver.cpp:218] Iteration 29500 (4.81882 iter/s, 20.752s/100 iters), loss = 0.187674
I1006 22:50:06.422550  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.187674 (* 1 = 0.187674 loss)
I1006 22:50:06.422557  4081 sgd_solver.cpp:105] Iteration 29500, lr = 0.1
I1006 22:50:23.496505  4081 solver.cpp:218] Iteration 29600 (5.8569 iter/s, 17.0739s/100 iters), loss = 0.200716
I1006 22:50:23.496579  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.200716 (* 1 = 0.200716 loss)
I1006 22:50:23.496598  4081 sgd_solver.cpp:105] Iteration 29600, lr = 0.1
I1006 22:50:40.570441  4081 solver.cpp:218] Iteration 29700 (5.85692 iter/s, 17.0738s/100 iters), loss = 0.251022
I1006 22:50:40.570472  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.251022 (* 1 = 0.251022 loss)
I1006 22:50:40.570478  4081 sgd_solver.cpp:105] Iteration 29700, lr = 0.1
I1006 22:50:57.642215  4081 solver.cpp:218] Iteration 29800 (5.85766 iter/s, 17.0717s/100 iters), loss = 0.190479
I1006 22:50:57.642341  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.190479 (* 1 = 0.190479 loss)
I1006 22:50:57.642349  4081 sgd_solver.cpp:105] Iteration 29800, lr = 0.1
I1006 22:51:15.243965  4081 solver.cpp:218] Iteration 29900 (5.68131 iter/s, 17.6016s/100 iters), loss = 0.0974597
I1006 22:51:15.244005  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0974599 (* 1 = 0.0974599 loss)
I1006 22:51:15.244012  4081 sgd_solver.cpp:105] Iteration 29900, lr = 0.1
I1006 22:51:31.473835  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:51:32.155040  4081 solver.cpp:330] Iteration 30000, Testing net (#0)
I1006 22:51:35.753012  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:51:35.918215  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.4974
I1006 22:51:35.918251  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 2.67406 (* 1 = 2.67406 loss)
I1006 22:51:36.023489  4081 solver.cpp:218] Iteration 30000 (4.81246 iter/s, 20.7794s/100 iters), loss = 0.136194
I1006 22:51:36.023516  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.136194 (* 1 = 0.136194 loss)
I1006 22:51:36.023524  4081 sgd_solver.cpp:105] Iteration 30000, lr = 0.1
I1006 22:51:53.186734  4081 solver.cpp:218] Iteration 30100 (5.82715 iter/s, 17.161s/100 iters), loss = 0.163291
I1006 22:51:53.186776  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.163291 (* 1 = 0.163291 loss)
I1006 22:51:53.186784  4081 sgd_solver.cpp:105] Iteration 30100, lr = 0.1
I1006 22:52:10.260371  4081 solver.cpp:218] Iteration 30200 (5.85702 iter/s, 17.0735s/100 iters), loss = 0.202022
I1006 22:52:10.260486  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.202023 (* 1 = 0.202023 loss)
I1006 22:52:10.260498  4081 sgd_solver.cpp:105] Iteration 30200, lr = 0.1
I1006 22:52:27.339566  4081 solver.cpp:218] Iteration 30300 (5.85514 iter/s, 17.079s/100 iters), loss = 0.181254
I1006 22:52:27.339608  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.181255 (* 1 = 0.181255 loss)
I1006 22:52:27.339615  4081 sgd_solver.cpp:105] Iteration 30300, lr = 0.1
I1006 22:52:44.952909  4081 solver.cpp:218] Iteration 30400 (5.67755 iter/s, 17.6132s/100 iters), loss = 0.0976212
I1006 22:52:44.953004  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0976214 (* 1 = 0.0976214 loss)
I1006 22:52:44.953012  4081 sgd_solver.cpp:105] Iteration 30400, lr = 0.1
I1006 22:53:01.195825  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:53:01.878259  4081 solver.cpp:330] Iteration 30500, Testing net (#0)
I1006 22:53:05.475734  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:53:05.641183  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6565
I1006 22:53:05.641212  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.47089 (* 1 = 1.47089 loss)
I1006 22:53:05.730332  4081 solver.cpp:218] Iteration 30500 (4.81295 iter/s, 20.7773s/100 iters), loss = 0.127688
I1006 22:53:05.730370  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.127688 (* 1 = 0.127688 loss)
I1006 22:53:05.730376  4081 sgd_solver.cpp:105] Iteration 30500, lr = 0.1
I1006 22:53:22.887851  4081 solver.cpp:218] Iteration 30600 (5.82842 iter/s, 17.1573s/100 iters), loss = 0.114468
I1006 22:53:22.887933  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.114468 (* 1 = 0.114468 loss)
I1006 22:53:22.887941  4081 sgd_solver.cpp:105] Iteration 30600, lr = 0.1
I1006 22:53:39.963799  4081 solver.cpp:218] Iteration 30700 (5.85624 iter/s, 17.0758s/100 iters), loss = 0.231881
I1006 22:53:39.963841  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.231881 (* 1 = 0.231881 loss)
I1006 22:53:39.963848  4081 sgd_solver.cpp:105] Iteration 30700, lr = 0.1
I1006 22:53:57.067838  4081 solver.cpp:218] Iteration 30800 (5.84661 iter/s, 17.1039s/100 iters), loss = 0.160447
I1006 22:53:57.067960  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.160447 (* 1 = 0.160447 loss)
I1006 22:53:57.067979  4081 sgd_solver.cpp:105] Iteration 30800, lr = 0.1
I1006 22:54:14.689771  4081 solver.cpp:218] Iteration 30900 (5.67546 iter/s, 17.6197s/100 iters), loss = 0.171556
I1006 22:54:14.689813  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.171556 (* 1 = 0.171556 loss)
I1006 22:54:14.689821  4081 sgd_solver.cpp:105] Iteration 30900, lr = 0.1
I1006 22:54:30.913305  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:54:31.600003  4081 solver.cpp:330] Iteration 31000, Testing net (#0)
I1006 22:54:35.200217  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:54:35.338425  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7679
I1006 22:54:35.338450  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.765353 (* 1 = 0.765353 loss)
I1006 22:54:35.455451  4081 solver.cpp:218] Iteration 31000 (4.81566 iter/s, 20.7656s/100 iters), loss = 0.244469
I1006 22:54:35.455490  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.244469 (* 1 = 0.244469 loss)
I1006 22:54:35.455497  4081 sgd_solver.cpp:105] Iteration 31000, lr = 0.1
I1006 22:54:52.609711  4081 solver.cpp:218] Iteration 31100 (5.82949 iter/s, 17.1541s/100 iters), loss = 0.227805
I1006 22:54:52.609752  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.227805 (* 1 = 0.227805 loss)
I1006 22:54:52.609760  4081 sgd_solver.cpp:105] Iteration 31100, lr = 0.1
I1006 22:55:09.686713  4081 solver.cpp:218] Iteration 31200 (5.85587 iter/s, 17.0769s/100 iters), loss = 0.258986
I1006 22:55:09.686794  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.258986 (* 1 = 0.258986 loss)
I1006 22:55:09.686801  4081 sgd_solver.cpp:105] Iteration 31200, lr = 0.1
I1006 22:55:26.822587  4081 solver.cpp:218] Iteration 31300 (5.83576 iter/s, 17.1357s/100 iters), loss = 0.187003
I1006 22:55:26.822619  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.187003 (* 1 = 0.187003 loss)
I1006 22:55:26.822628  4081 sgd_solver.cpp:105] Iteration 31300, lr = 0.1
I1006 22:55:44.383908  4081 solver.cpp:218] Iteration 31400 (5.69437 iter/s, 17.5612s/100 iters), loss = 0.203116
I1006 22:55:44.384017  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.203116 (* 1 = 0.203116 loss)
I1006 22:55:44.384037  4081 sgd_solver.cpp:105] Iteration 31400, lr = 0.1
I1006 22:56:00.625849  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:56:01.307428  4081 solver.cpp:330] Iteration 31500, Testing net (#0)
I1006 22:56:04.907680  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:56:05.072670  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6642
I1006 22:56:05.072707  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.21944 (* 1 = 1.21944 loss)
I1006 22:56:05.177971  4081 solver.cpp:218] Iteration 31500 (4.80911 iter/s, 20.7939s/100 iters), loss = 0.12325
I1006 22:56:05.178002  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.12325 (* 1 = 0.12325 loss)
I1006 22:56:05.178020  4081 sgd_solver.cpp:105] Iteration 31500, lr = 0.1
I1006 22:56:22.314194  4081 solver.cpp:218] Iteration 31600 (5.83634 iter/s, 17.134s/100 iters), loss = 0.162876
I1006 22:56:22.314265  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.162876 (* 1 = 0.162876 loss)
I1006 22:56:22.314272  4081 sgd_solver.cpp:105] Iteration 31600, lr = 0.1
I1006 22:56:39.386023  4081 solver.cpp:218] Iteration 31700 (5.85765 iter/s, 17.0717s/100 iters), loss = 0.199611
I1006 22:56:39.386055  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.199612 (* 1 = 0.199612 loss)
I1006 22:56:39.386063  4081 sgd_solver.cpp:105] Iteration 31700, lr = 0.1
I1006 22:56:56.581713  4081 solver.cpp:218] Iteration 31800 (5.81544 iter/s, 17.1956s/100 iters), loss = 0.158618
I1006 22:56:56.581805  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.158619 (* 1 = 0.158619 loss)
I1006 22:56:56.581825  4081 sgd_solver.cpp:105] Iteration 31800, lr = 0.1
I1006 22:57:14.064553  4081 solver.cpp:218] Iteration 31900 (5.72061 iter/s, 17.4806s/100 iters), loss = 0.145024
I1006 22:57:14.064585  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.145025 (* 1 = 0.145025 loss)
I1006 22:57:14.064594  4081 sgd_solver.cpp:105] Iteration 31900, lr = 0.1
I1006 22:57:30.266813  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:57:30.948786  4081 solver.cpp:330] Iteration 32000, Testing net (#0)
I1006 22:57:34.549283  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:57:34.715502  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.5639
I1006 22:57:34.715538  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 2.71573 (* 1 = 2.71573 loss)
I1006 22:57:34.847036  4081 solver.cpp:218] Iteration 32000 (4.81177 iter/s, 20.7824s/100 iters), loss = 0.245959
I1006 22:57:34.847075  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.245959 (* 1 = 0.245959 loss)
I1006 22:57:34.847084  4081 sgd_solver.cpp:105] Iteration 32000, lr = 0.1
I1006 22:57:51.952319  4081 solver.cpp:218] Iteration 32100 (5.8469 iter/s, 17.1031s/100 iters), loss = 0.198569
I1006 22:57:51.952360  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.198569 (* 1 = 0.198569 loss)
I1006 22:57:51.952368  4081 sgd_solver.cpp:105] Iteration 32100, lr = 0.1
I1006 22:58:09.011463  4081 solver.cpp:218] Iteration 32200 (5.862 iter/s, 17.059s/100 iters), loss = 0.231198
I1006 22:58:09.011553  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.231198 (* 1 = 0.231198 loss)
I1006 22:58:09.011564  4081 sgd_solver.cpp:105] Iteration 32200, lr = 0.1
I1006 22:58:26.267705  4081 solver.cpp:218] Iteration 32300 (5.79506 iter/s, 17.2561s/100 iters), loss = 0.154338
I1006 22:58:26.267750  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.154338 (* 1 = 0.154338 loss)
I1006 22:58:26.267758  4081 sgd_solver.cpp:105] Iteration 32300, lr = 0.1
I1006 22:58:43.692175  4081 solver.cpp:218] Iteration 32400 (5.73927 iter/s, 17.4238s/100 iters), loss = 0.166289
I1006 22:58:43.692256  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.166289 (* 1 = 0.166289 loss)
I1006 22:58:43.692276  4081 sgd_solver.cpp:105] Iteration 32400, lr = 0.1
I1006 22:58:59.928484  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:59:00.614038  4081 solver.cpp:330] Iteration 32500, Testing net (#0)
I1006 22:59:04.213093  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1006 22:59:04.378557  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6877
I1006 22:59:04.378587  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.15706 (* 1 = 1.15706 loss)
I1006 22:59:04.511620  4081 solver.cpp:218] Iteration 32500 (4.80324 iter/s, 20.8193s/100 iters), loss = 0.180191
I1006 22:59:04.511652  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.180191 (* 1 = 0.180191 loss)
I1006 22:59:04.511672  4081 sgd_solver.cpp:105] Iteration 32500, lr = 0.1
I1006 22:59:21.631793  4081 solver.cpp:218] Iteration 32600 (5.84183 iter/s, 17.1179s/100 iters), loss = 0.210754
I1006 22:59:21.631929  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.210754 (* 1 = 0.210754 loss)
I1006 22:59:21.631938  4081 sgd_solver.cpp:105] Iteration 32600, lr = 0.1
I1006 22:59:38.720903  4081 solver.cpp:218] Iteration 32700 (5.85175 iter/s, 17.0889s/100 iters), loss = 0.241549
I1006 22:59:38.720945  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.241549 (* 1 = 0.241549 loss)
I1006 22:59:38.720952  4081 sgd_solver.cpp:105] Iteration 32700, lr = 0.1
I1006 22:59:56.018308  4081 solver.cpp:218] Iteration 32800 (5.78125 iter/s, 17.2973s/100 iters), loss = 0.185577
I1006 22:59:56.018378  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.185577 (* 1 = 0.185577 loss)
I1006 22:59:56.018388  4081 sgd_solver.cpp:105] Iteration 32800, lr = 0.1
I1006 23:00:13.400756  4081 solver.cpp:218] Iteration 32900 (5.75367 iter/s, 17.3802s/100 iters), loss = 0.131644
I1006 23:00:13.400797  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.131644 (* 1 = 0.131644 loss)
I1006 23:00:13.400804  4081 sgd_solver.cpp:105] Iteration 32900, lr = 0.1
I1006 23:00:29.634486  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:00:30.315517  4081 solver.cpp:330] Iteration 33000, Testing net (#0)
I1006 23:00:33.915383  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:00:34.055294  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6762
I1006 23:00:34.055321  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.39946 (* 1 = 1.39946 loss)
I1006 23:00:34.169757  4081 solver.cpp:218] Iteration 33000 (4.81489 iter/s, 20.7689s/100 iters), loss = 0.221663
I1006 23:00:34.169797  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.221663 (* 1 = 0.221663 loss)
I1006 23:00:34.169806  4081 sgd_solver.cpp:105] Iteration 33000, lr = 0.1
I1006 23:00:51.341368  4081 solver.cpp:218] Iteration 33100 (5.8236 iter/s, 17.1715s/100 iters), loss = 0.174351
I1006 23:00:51.341411  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.174351 (* 1 = 0.174351 loss)
I1006 23:00:51.341418  4081 sgd_solver.cpp:105] Iteration 33100, lr = 0.1
I1006 23:01:08.413727  4081 solver.cpp:218] Iteration 33200 (5.85746 iter/s, 17.0723s/100 iters), loss = 0.250084
I1006 23:01:08.413864  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.250084 (* 1 = 0.250084 loss)
I1006 23:01:08.413884  4081 sgd_solver.cpp:105] Iteration 33200, lr = 0.1
I1006 23:01:25.759498  4081 solver.cpp:218] Iteration 33300 (5.76516 iter/s, 17.3456s/100 iters), loss = 0.225488
I1006 23:01:25.759543  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.225488 (* 1 = 0.225488 loss)
I1006 23:01:25.759551  4081 sgd_solver.cpp:105] Iteration 33300, lr = 0.1
I1006 23:01:43.087236  4081 solver.cpp:218] Iteration 33400 (5.77127 iter/s, 17.3272s/100 iters), loss = 0.162493
I1006 23:01:43.087350  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.162493 (* 1 = 0.162493 loss)
I1006 23:01:43.087358  4081 sgd_solver.cpp:105] Iteration 33400, lr = 0.1
I1006 23:01:59.297555  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:01:59.978063  4081 solver.cpp:330] Iteration 33500, Testing net (#0)
I1006 23:02:03.575829  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:02:03.741785  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7684
I1006 23:02:03.741812  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.763855 (* 1 = 0.763855 loss)
I1006 23:02:03.868655  4081 solver.cpp:218] Iteration 33500 (4.81203 iter/s, 20.7812s/100 iters), loss = 0.171894
I1006 23:02:03.868695  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.171894 (* 1 = 0.171894 loss)
I1006 23:02:03.868702  4081 sgd_solver.cpp:105] Iteration 33500, lr = 0.1
I1006 23:02:20.979796  4081 solver.cpp:218] Iteration 33600 (5.84489 iter/s, 17.1089s/100 iters), loss = 0.164327
I1006 23:02:20.979907  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.164327 (* 1 = 0.164327 loss)
I1006 23:02:20.979914  4081 sgd_solver.cpp:105] Iteration 33600, lr = 0.1
I1006 23:02:38.065104  4081 solver.cpp:218] Iteration 33700 (5.85304 iter/s, 17.0851s/100 iters), loss = 0.240715
I1006 23:02:38.065145  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.240715 (* 1 = 0.240715 loss)
I1006 23:02:38.065152  4081 sgd_solver.cpp:105] Iteration 33700, lr = 0.1
I1006 23:02:55.473140  4081 solver.cpp:218] Iteration 33800 (5.74451 iter/s, 17.4079s/100 iters), loss = 0.275343
I1006 23:02:55.473212  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.275343 (* 1 = 0.275343 loss)
I1006 23:02:55.473219  4081 sgd_solver.cpp:105] Iteration 33800, lr = 0.1
I1006 23:03:12.735316  4081 solver.cpp:218] Iteration 33900 (5.79306 iter/s, 17.262s/100 iters), loss = 0.214176
I1006 23:03:12.735357  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.214176 (* 1 = 0.214176 loss)
I1006 23:03:12.735363  4081 sgd_solver.cpp:105] Iteration 33900, lr = 0.1
I1006 23:03:28.965139  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:03:29.646306  4081 solver.cpp:330] Iteration 34000, Testing net (#0)
I1006 23:03:33.244132  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:03:33.383611  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7182
I1006 23:03:33.383640  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.932569 (* 1 = 0.932569 loss)
I1006 23:03:33.497900  4081 solver.cpp:218] Iteration 34000 (4.81638 iter/s, 20.7625s/100 iters), loss = 0.168994
I1006 23:03:33.497927  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.168994 (* 1 = 0.168994 loss)
I1006 23:03:33.497936  4081 sgd_solver.cpp:105] Iteration 34000, lr = 0.1
I1006 23:03:50.648648  4081 solver.cpp:218] Iteration 34100 (5.83068 iter/s, 17.1506s/100 iters), loss = 0.170743
I1006 23:03:50.648684  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.170743 (* 1 = 0.170743 loss)
I1006 23:03:50.648694  4081 sgd_solver.cpp:105] Iteration 34100, lr = 0.1
I1006 23:04:07.730934  4081 solver.cpp:218] Iteration 34200 (5.85405 iter/s, 17.0822s/100 iters), loss = 0.232709
I1006 23:04:07.731077  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.232709 (* 1 = 0.232709 loss)
I1006 23:04:07.731096  4081 sgd_solver.cpp:105] Iteration 34200, lr = 0.1
I1006 23:04:25.189524  4081 solver.cpp:218] Iteration 34300 (5.7279 iter/s, 17.4584s/100 iters), loss = 0.231034
I1006 23:04:25.189558  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.231034 (* 1 = 0.231034 loss)
I1006 23:04:25.189568  4081 sgd_solver.cpp:105] Iteration 34300, lr = 0.1
I1006 23:04:42.430253  4081 solver.cpp:218] Iteration 34400 (5.80025 iter/s, 17.2406s/100 iters), loss = 0.204855
I1006 23:04:42.430335  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.204855 (* 1 = 0.204855 loss)
I1006 23:04:42.430342  4081 sgd_solver.cpp:105] Iteration 34400, lr = 0.1
I1006 23:04:58.649430  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:04:59.330332  4081 solver.cpp:330] Iteration 34500, Testing net (#0)
I1006 23:05:02.920934  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:05:03.037766  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7539
I1006 23:05:03.037793  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.824234 (* 1 = 0.824234 loss)
I1006 23:05:03.182998  4081 solver.cpp:218] Iteration 34500 (4.81867 iter/s, 20.7526s/100 iters), loss = 0.250802
I1006 23:05:03.183037  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.250802 (* 1 = 0.250802 loss)
I1006 23:05:03.183044  4081 sgd_solver.cpp:105] Iteration 34500, lr = 0.1
I1006 23:05:20.253136  4081 solver.cpp:218] Iteration 34600 (5.85822 iter/s, 17.07s/100 iters), loss = 0.235676
I1006 23:05:20.253257  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.235676 (* 1 = 0.235676 loss)
I1006 23:05:20.253274  4081 sgd_solver.cpp:105] Iteration 34600, lr = 0.1
I1006 23:05:37.327661  4081 solver.cpp:218] Iteration 34700 (5.85674 iter/s, 17.0743s/100 iters), loss = 0.33049
I1006 23:05:37.327702  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.33049 (* 1 = 0.33049 loss)
I1006 23:05:37.327709  4081 sgd_solver.cpp:105] Iteration 34700, lr = 0.1
I1006 23:05:54.813904  4081 solver.cpp:218] Iteration 34800 (5.71882 iter/s, 17.4861s/100 iters), loss = 0.225192
I1006 23:05:54.813976  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.225192 (* 1 = 0.225192 loss)
I1006 23:05:54.813987  4081 sgd_solver.cpp:105] Iteration 34800, lr = 0.1
I1006 23:06:12.003273  4081 solver.cpp:218] Iteration 34900 (5.8176 iter/s, 17.1892s/100 iters), loss = 0.136141
I1006 23:06:12.003304  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.136141 (* 1 = 0.136141 loss)
I1006 23:06:12.003309  4081 sgd_solver.cpp:105] Iteration 34900, lr = 0.1
I1006 23:06:28.227110  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:06:28.908988  4081 solver.cpp:330] Iteration 35000, Testing net (#0)
I1006 23:06:32.505973  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:06:32.671473  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.5941
I1006 23:06:32.671509  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.53409 (* 1 = 1.53409 loss)
I1006 23:06:32.774480  4081 solver.cpp:218] Iteration 35000 (4.81438 iter/s, 20.7711s/100 iters), loss = 0.229959
I1006 23:06:32.774510  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.229959 (* 1 = 0.229959 loss)
I1006 23:06:32.774528  4081 sgd_solver.cpp:105] Iteration 35000, lr = 0.1
I1006 23:06:49.923390  4081 solver.cpp:218] Iteration 35100 (5.83204 iter/s, 17.1467s/100 iters), loss = 0.130138
I1006 23:06:49.923422  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.130138 (* 1 = 0.130138 loss)
I1006 23:06:49.923429  4081 sgd_solver.cpp:105] Iteration 35100, lr = 0.1
I1006 23:07:07.016957  4081 solver.cpp:218] Iteration 35200 (5.85019 iter/s, 17.0935s/100 iters), loss = 0.304778
I1006 23:07:07.017097  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.304778 (* 1 = 0.304778 loss)
I1006 23:07:07.017105  4081 sgd_solver.cpp:105] Iteration 35200, lr = 0.1
I1006 23:07:24.611155  4081 solver.cpp:218] Iteration 35300 (5.68376 iter/s, 17.594s/100 iters), loss = 0.217031
I1006 23:07:24.611196  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.217031 (* 1 = 0.217031 loss)
I1006 23:07:24.611204  4081 sgd_solver.cpp:105] Iteration 35300, lr = 0.1
I1006 23:07:41.733489  4081 solver.cpp:218] Iteration 35400 (5.84108 iter/s, 17.1201s/100 iters), loss = 0.201615
I1006 23:07:41.733536  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.201615 (* 1 = 0.201615 loss)
I1006 23:07:41.733543  4081 sgd_solver.cpp:105] Iteration 35400, lr = 0.1
I1006 23:07:57.972944  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:07:58.655341  4081 solver.cpp:330] Iteration 35500, Testing net (#0)
I1006 23:08:02.259177  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:08:02.400993  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7281
I1006 23:08:02.401029  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.05475 (* 1 = 1.05475 loss)
I1006 23:08:02.512413  4081 solver.cpp:218] Iteration 35500 (4.81272 iter/s, 20.7783s/100 iters), loss = 0.208433
I1006 23:08:02.512449  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.208433 (* 1 = 0.208433 loss)
I1006 23:08:02.512456  4081 sgd_solver.cpp:105] Iteration 35500, lr = 0.1
I1006 23:08:19.671015  4081 solver.cpp:218] Iteration 35600 (5.82802 iter/s, 17.1585s/100 iters), loss = 0.172744
I1006 23:08:19.671097  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.172744 (* 1 = 0.172744 loss)
I1006 23:08:19.671106  4081 sgd_solver.cpp:105] Iteration 35600, lr = 0.1
I1006 23:08:36.747563  4081 solver.cpp:218] Iteration 35700 (5.8564 iter/s, 17.0753s/100 iters), loss = 0.154022
I1006 23:08:36.747604  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.154022 (* 1 = 0.154022 loss)
I1006 23:08:36.747611  4081 sgd_solver.cpp:105] Iteration 35700, lr = 0.1
I1006 23:08:54.319622  4081 solver.cpp:218] Iteration 35800 (5.69089 iter/s, 17.572s/100 iters), loss = 0.209297
I1006 23:08:54.319702  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.209297 (* 1 = 0.209297 loss)
I1006 23:08:54.319720  4081 sgd_solver.cpp:105] Iteration 35800, lr = 0.1
I1006 23:09:11.427639  4081 solver.cpp:218] Iteration 35900 (5.84597 iter/s, 17.1058s/100 iters), loss = 0.19376
I1006 23:09:11.427680  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.19376 (* 1 = 0.19376 loss)
I1006 23:09:11.427686  4081 sgd_solver.cpp:105] Iteration 35900, lr = 0.1
I1006 23:09:27.655704  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:09:28.339771  4081 solver.cpp:330] Iteration 36000, Testing net (#0)
I1006 23:09:31.859040  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:09:32.025471  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6695
I1006 23:09:32.025507  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.40243 (* 1 = 1.40243 loss)
I1006 23:09:32.139505  4081 solver.cpp:218] Iteration 36000 (4.82818 iter/s, 20.7118s/100 iters), loss = 0.136995
I1006 23:09:32.139544  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.136995 (* 1 = 0.136995 loss)
I1006 23:09:32.139552  4081 sgd_solver.cpp:105] Iteration 36000, lr = 0.1
I1006 23:09:49.287431  4081 solver.cpp:218] Iteration 36100 (5.83237 iter/s, 17.1457s/100 iters), loss = 0.181577
I1006 23:09:49.287475  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.181577 (* 1 = 0.181577 loss)
I1006 23:09:49.287483  4081 sgd_solver.cpp:105] Iteration 36100, lr = 0.1
I1006 23:10:06.363092  4081 solver.cpp:218] Iteration 36200 (5.85633 iter/s, 17.0756s/100 iters), loss = 0.172532
I1006 23:10:06.363222  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.172532 (* 1 = 0.172532 loss)
I1006 23:10:06.363231  4081 sgd_solver.cpp:105] Iteration 36200, lr = 0.1
I1006 23:10:23.891935  4081 solver.cpp:218] Iteration 36300 (5.70495 iter/s, 17.5286s/100 iters), loss = 0.26999
I1006 23:10:23.891978  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.26999 (* 1 = 0.26999 loss)
I1006 23:10:23.891983  4081 sgd_solver.cpp:105] Iteration 36300, lr = 0.1
I1006 23:10:40.955466  4081 solver.cpp:218] Iteration 36400 (5.86049 iter/s, 17.0634s/100 iters), loss = 0.156249
I1006 23:10:40.955600  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.156249 (* 1 = 0.156249 loss)
I1006 23:10:40.955607  4081 sgd_solver.cpp:105] Iteration 36400, lr = 0.1
I1006 23:10:57.201259  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:10:57.883708  4081 solver.cpp:330] Iteration 36500, Testing net (#0)
I1006 23:11:01.502521  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:11:01.647136  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6159
I1006 23:11:01.647167  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.56501 (* 1 = 1.56501 loss)
I1006 23:11:01.815434  4081 solver.cpp:218] Iteration 36500 (4.79392 iter/s, 20.8598s/100 iters), loss = 0.241766
I1006 23:11:01.815472  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.241766 (* 1 = 0.241766 loss)
I1006 23:11:01.815479  4081 sgd_solver.cpp:105] Iteration 36500, lr = 0.1
I1006 23:11:18.885218  4081 solver.cpp:218] Iteration 36600 (5.85834 iter/s, 17.0697s/100 iters), loss = 0.216069
I1006 23:11:18.885316  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.216069 (* 1 = 0.216069 loss)
I1006 23:11:18.885324  4081 sgd_solver.cpp:105] Iteration 36600, lr = 0.1
I1006 23:11:35.962697  4081 solver.cpp:218] Iteration 36700 (5.85572 iter/s, 17.0773s/100 iters), loss = 0.239852
I1006 23:11:35.962728  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.239852 (* 1 = 0.239852 loss)
I1006 23:11:35.962745  4081 sgd_solver.cpp:105] Iteration 36700, lr = 0.1
I1006 23:11:53.584125  4081 solver.cpp:218] Iteration 36800 (5.67494 iter/s, 17.6213s/100 iters), loss = 0.176749
I1006 23:11:53.584203  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.176749 (* 1 = 0.176749 loss)
I1006 23:11:53.584210  4081 sgd_solver.cpp:105] Iteration 36800, lr = 0.1
I1006 23:12:10.668684  4081 solver.cpp:218] Iteration 36900 (5.85329 iter/s, 17.0844s/100 iters), loss = 0.214122
I1006 23:12:10.668725  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.214122 (* 1 = 0.214122 loss)
I1006 23:12:10.668731  4081 sgd_solver.cpp:105] Iteration 36900, lr = 0.1
I1006 23:12:26.891686  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:12:27.575086  4081 solver.cpp:330] Iteration 37000, Testing net (#0)
I1006 23:12:31.178386  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:12:31.319114  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6656
I1006 23:12:31.319150  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.28059 (* 1 = 1.28059 loss)
I1006 23:12:31.433169  4081 solver.cpp:218] Iteration 37000 (4.81594 iter/s, 20.7644s/100 iters), loss = 0.259492
I1006 23:12:31.433205  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.259491 (* 1 = 0.259491 loss)
I1006 23:12:31.433212  4081 sgd_solver.cpp:105] Iteration 37000, lr = 0.1
I1006 23:12:48.599757  4081 solver.cpp:218] Iteration 37100 (5.8253 iter/s, 17.1665s/100 iters), loss = 0.181335
I1006 23:12:48.599798  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.181335 (* 1 = 0.181335 loss)
I1006 23:12:48.599804  4081 sgd_solver.cpp:105] Iteration 37100, lr = 0.1
I1006 23:13:05.695889  4081 solver.cpp:218] Iteration 37200 (5.84931 iter/s, 17.096s/100 iters), loss = 0.226126
I1006 23:13:05.695983  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.226126 (* 1 = 0.226126 loss)
I1006 23:13:05.695991  4081 sgd_solver.cpp:105] Iteration 37200, lr = 0.1
I1006 23:13:23.320288  4081 solver.cpp:218] Iteration 37300 (5.674 iter/s, 17.6242s/100 iters), loss = 0.190572
I1006 23:13:23.320329  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.190572 (* 1 = 0.190572 loss)
I1006 23:13:23.320336  4081 sgd_solver.cpp:105] Iteration 37300, lr = 0.1
I1006 23:13:40.392385  4081 solver.cpp:218] Iteration 37400 (5.85755 iter/s, 17.072s/100 iters), loss = 0.234306
I1006 23:13:40.392480  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.234305 (* 1 = 0.234305 loss)
I1006 23:13:40.392498  4081 sgd_solver.cpp:105] Iteration 37400, lr = 0.1
I1006 23:13:56.616333  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:13:57.298743  4081 solver.cpp:330] Iteration 37500, Testing net (#0)
I1006 23:14:00.920068  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:14:01.062273  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7335
I1006 23:14:01.062299  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.888103 (* 1 = 0.888103 loss)
I1006 23:14:01.229562  4081 solver.cpp:218] Iteration 37500 (4.79915 iter/s, 20.837s/100 iters), loss = 0.160565
I1006 23:14:01.229604  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.160565 (* 1 = 0.160565 loss)
I1006 23:14:01.229611  4081 sgd_solver.cpp:105] Iteration 37500, lr = 0.1
I1006 23:14:18.309525  4081 solver.cpp:218] Iteration 37600 (5.85485 iter/s, 17.0799s/100 iters), loss = 0.273896
I1006 23:14:18.309633  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.273896 (* 1 = 0.273896 loss)
I1006 23:14:18.309640  4081 sgd_solver.cpp:105] Iteration 37600, lr = 0.1
I1006 23:14:35.377003  4081 solver.cpp:218] Iteration 37700 (5.85915 iter/s, 17.0673s/100 iters), loss = 0.182112
I1006 23:14:35.377044  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.182112 (* 1 = 0.182112 loss)
I1006 23:14:35.377050  4081 sgd_solver.cpp:105] Iteration 37700, lr = 0.1
I1006 23:14:53.002218  4081 solver.cpp:218] Iteration 37800 (5.67372 iter/s, 17.6251s/100 iters), loss = 0.237282
I1006 23:14:53.002316  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.237282 (* 1 = 0.237282 loss)
I1006 23:14:53.002326  4081 sgd_solver.cpp:105] Iteration 37800, lr = 0.1
I1006 23:15:10.080235  4081 solver.cpp:218] Iteration 37900 (5.85553 iter/s, 17.0779s/100 iters), loss = 0.269313
I1006 23:15:10.080276  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.269312 (* 1 = 0.269312 loss)
I1006 23:15:10.080282  4081 sgd_solver.cpp:105] Iteration 37900, lr = 0.1
I1006 23:15:26.296393  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:15:26.977576  4081 solver.cpp:330] Iteration 38000, Testing net (#0)
I1006 23:15:30.599364  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:15:30.741217  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6882
I1006 23:15:30.741245  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.304 (* 1 = 1.304 loss)
I1006 23:15:30.909060  4081 solver.cpp:218] Iteration 38000 (4.80106 iter/s, 20.8287s/100 iters), loss = 0.127548
I1006 23:15:30.909103  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.127548 (* 1 = 0.127548 loss)
I1006 23:15:30.909111  4081 sgd_solver.cpp:105] Iteration 38000, lr = 0.1
I1006 23:15:47.989939  4081 solver.cpp:218] Iteration 38100 (5.85454 iter/s, 17.0808s/100 iters), loss = 0.237405
I1006 23:15:47.989984  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.237405 (* 1 = 0.237405 loss)
I1006 23:15:47.989991  4081 sgd_solver.cpp:105] Iteration 38100, lr = 0.1
I1006 23:16:05.093099  4081 solver.cpp:218] Iteration 38200 (5.84694 iter/s, 17.103s/100 iters), loss = 0.185253
I1006 23:16:05.093231  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.185253 (* 1 = 0.185253 loss)
I1006 23:16:05.093240  4081 sgd_solver.cpp:105] Iteration 38200, lr = 0.1
I1006 23:16:22.706022  4081 solver.cpp:218] Iteration 38300 (5.67771 iter/s, 17.6127s/100 iters), loss = 0.165017
I1006 23:16:22.706064  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.165017 (* 1 = 0.165017 loss)
I1006 23:16:22.706071  4081 sgd_solver.cpp:105] Iteration 38300, lr = 0.1
I1006 23:16:39.794039  4081 solver.cpp:218] Iteration 38400 (5.85209 iter/s, 17.0879s/100 iters), loss = 0.196879
I1006 23:16:39.794188  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.196879 (* 1 = 0.196879 loss)
I1006 23:16:39.794196  4081 sgd_solver.cpp:105] Iteration 38400, lr = 0.1
I1006 23:16:56.036509  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:16:56.718255  4081 solver.cpp:330] Iteration 38500, Testing net (#0)
I1006 23:17:00.316808  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:17:00.482383  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.5734
I1006 23:17:00.482409  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 2.57706 (* 1 = 2.57706 loss)
I1006 23:17:00.585649  4081 solver.cpp:218] Iteration 38500 (4.80968 iter/s, 20.7914s/100 iters), loss = 0.163968
I1006 23:17:00.585688  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.163968 (* 1 = 0.163968 loss)
I1006 23:17:00.585695  4081 sgd_solver.cpp:105] Iteration 38500, lr = 0.1
I1006 23:17:17.732650  4081 solver.cpp:218] Iteration 38600 (5.83269 iter/s, 17.1447s/100 iters), loss = 0.215121
I1006 23:17:17.732744  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.215121 (* 1 = 0.215121 loss)
I1006 23:17:17.732762  4081 sgd_solver.cpp:105] Iteration 38600, lr = 0.1
I1006 23:17:34.806228  4081 solver.cpp:218] Iteration 38700 (5.85706 iter/s, 17.0734s/100 iters), loss = 0.197786
I1006 23:17:34.806269  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.197786 (* 1 = 0.197786 loss)
I1006 23:17:34.806277  4081 sgd_solver.cpp:105] Iteration 38700, lr = 0.1
I1006 23:17:52.420871  4081 solver.cpp:218] Iteration 38800 (5.67713 iter/s, 17.6145s/100 iters), loss = 0.190706
I1006 23:17:52.421028  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.190706 (* 1 = 0.190706 loss)
I1006 23:17:52.421056  4081 sgd_solver.cpp:105] Iteration 38800, lr = 0.1
I1006 23:18:09.497455  4081 solver.cpp:218] Iteration 38900 (5.85604 iter/s, 17.0764s/100 iters), loss = 0.0790236
I1006 23:18:09.497490  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0790234 (* 1 = 0.0790234 loss)
I1006 23:18:09.497509  4081 sgd_solver.cpp:105] Iteration 38900, lr = 0.1
I1006 23:18:25.737102  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:18:26.421183  4081 solver.cpp:330] Iteration 39000, Testing net (#0)
I1006 23:18:30.016223  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:18:30.181149  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.622
I1006 23:18:30.181177  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.63281 (* 1 = 1.63281 loss)
I1006 23:18:30.272228  4081 solver.cpp:218] Iteration 39000 (4.81356 iter/s, 20.7747s/100 iters), loss = 0.149648
I1006 23:18:30.272263  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.149648 (* 1 = 0.149648 loss)
I1006 23:18:30.272282  4081 sgd_solver.cpp:105] Iteration 39000, lr = 0.1
I1006 23:18:47.420161  4081 solver.cpp:218] Iteration 39100 (5.83236 iter/s, 17.1457s/100 iters), loss = 0.205961
I1006 23:18:47.420194  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.205961 (* 1 = 0.205961 loss)
I1006 23:18:47.420203  4081 sgd_solver.cpp:105] Iteration 39100, lr = 0.1
I1006 23:19:04.507580  4081 solver.cpp:218] Iteration 39200 (5.85229 iter/s, 17.0873s/100 iters), loss = 0.169038
I1006 23:19:04.507725  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.169038 (* 1 = 0.169038 loss)
I1006 23:19:04.507748  4081 sgd_solver.cpp:105] Iteration 39200, lr = 0.1
I1006 23:19:22.111753  4081 solver.cpp:218] Iteration 39300 (5.68053 iter/s, 17.604s/100 iters), loss = 0.220023
I1006 23:19:22.111784  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.220023 (* 1 = 0.220023 loss)
I1006 23:19:22.111801  4081 sgd_solver.cpp:105] Iteration 39300, lr = 0.1
I1006 23:19:39.197640  4081 solver.cpp:218] Iteration 39400 (5.85282 iter/s, 17.0858s/100 iters), loss = 0.232074
I1006 23:19:39.197765  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.232074 (* 1 = 0.232074 loss)
I1006 23:19:39.197783  4081 sgd_solver.cpp:105] Iteration 39400, lr = 0.1
I1006 23:19:55.429509  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:19:56.108981  4081 solver.cpp:330] Iteration 39500, Testing net (#0)
I1006 23:19:59.703847  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:19:59.869102  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7423
I1006 23:19:59.869137  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.87845 (* 1 = 0.87845 loss)
I1006 23:19:59.974582  4081 solver.cpp:218] Iteration 39500 (4.81307 iter/s, 20.7767s/100 iters), loss = 0.158989
I1006 23:19:59.974620  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.158988 (* 1 = 0.158988 loss)
I1006 23:19:59.974627  4081 sgd_solver.cpp:105] Iteration 39500, lr = 0.1
I1006 23:20:17.095810  4081 solver.cpp:218] Iteration 39600 (5.84146 iter/s, 17.119s/100 iters), loss = 0.17885
I1006 23:20:17.095968  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.17885 (* 1 = 0.17885 loss)
I1006 23:20:17.095988  4081 sgd_solver.cpp:105] Iteration 39600, lr = 0.1
I1006 23:20:34.149258  4081 solver.cpp:218] Iteration 39700 (5.86399 iter/s, 17.0532s/100 iters), loss = 0.225099
I1006 23:20:34.149300  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.225099 (* 1 = 0.225099 loss)
I1006 23:20:34.149307  4081 sgd_solver.cpp:105] Iteration 39700, lr = 0.1
I1006 23:20:51.744858  4081 solver.cpp:218] Iteration 39800 (5.68327 iter/s, 17.5955s/100 iters), loss = 0.16827
I1006 23:20:51.744945  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.16827 (* 1 = 0.16827 loss)
I1006 23:20:51.744963  4081 sgd_solver.cpp:105] Iteration 39800, lr = 0.1
I1006 23:21:08.811090  4081 solver.cpp:218] Iteration 39900 (5.85957 iter/s, 17.0661s/100 iters), loss = 0.161313
I1006 23:21:08.811131  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.161313 (* 1 = 0.161313 loss)
I1006 23:21:08.811137  4081 sgd_solver.cpp:105] Iteration 39900, lr = 0.1
I1006 23:21:25.024071  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:21:25.706815  4081 solver.cpp:330] Iteration 40000, Testing net (#0)
I1006 23:21:29.306284  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:21:29.472723  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.655
I1006 23:21:29.472759  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.28255 (* 1 = 1.28255 loss)
I1006 23:21:29.571086  4081 solver.cpp:218] Iteration 40000 (4.81698 iter/s, 20.7599s/100 iters), loss = 0.146735
I1006 23:21:29.571126  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.146735 (* 1 = 0.146735 loss)
I1006 23:21:29.571132  4081 sgd_solver.cpp:46] MultiStep Status: Iteration 40000, step = 1
I1006 23:21:29.571136  4081 sgd_solver.cpp:105] Iteration 40000, lr = 0.01
I1006 23:21:46.707744  4081 solver.cpp:218] Iteration 40100 (5.83621 iter/s, 17.1344s/100 iters), loss = 0.169488
I1006 23:21:46.707787  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.169488 (* 1 = 0.169488 loss)
I1006 23:21:46.707793  4081 sgd_solver.cpp:105] Iteration 40100, lr = 0.01
I1006 23:22:03.777681  4081 solver.cpp:218] Iteration 40200 (5.85829 iter/s, 17.0698s/100 iters), loss = 0.185423
I1006 23:22:03.777783  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.185423 (* 1 = 0.185423 loss)
I1006 23:22:03.777792  4081 sgd_solver.cpp:105] Iteration 40200, lr = 0.01
I1006 23:22:21.393296  4081 solver.cpp:218] Iteration 40300 (5.67684 iter/s, 17.6154s/100 iters), loss = 0.111058
I1006 23:22:21.393328  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.111058 (* 1 = 0.111058 loss)
I1006 23:22:21.393345  4081 sgd_solver.cpp:105] Iteration 40300, lr = 0.01
I1006 23:22:38.472473  4081 solver.cpp:218] Iteration 40400 (5.85512 iter/s, 17.0791s/100 iters), loss = 0.123195
I1006 23:22:38.472582  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.123195 (* 1 = 0.123195 loss)
I1006 23:22:38.472591  4081 sgd_solver.cpp:105] Iteration 40400, lr = 0.01
I1006 23:22:54.707120  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:22:55.389060  4081 solver.cpp:330] Iteration 40500, Testing net (#0)
I1006 23:22:59.009719  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:22:59.155611  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8926
I1006 23:22:59.155647  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.309073 (* 1 = 0.309073 loss)
I1006 23:22:59.323976  4081 solver.cpp:218] Iteration 40500 (4.79606 iter/s, 20.8505s/100 iters), loss = 0.0766882
I1006 23:22:59.324013  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.076688 (* 1 = 0.076688 loss)
I1006 23:22:59.324020  4081 sgd_solver.cpp:105] Iteration 40500, lr = 0.01
I1006 23:23:16.402202  4081 solver.cpp:218] Iteration 40600 (5.85545 iter/s, 17.0781s/100 iters), loss = 0.143931
I1006 23:23:16.402297  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.143931 (* 1 = 0.143931 loss)
I1006 23:23:16.402314  4081 sgd_solver.cpp:105] Iteration 40600, lr = 0.01
I1006 23:23:33.490022  4081 solver.cpp:218] Iteration 40700 (5.85218 iter/s, 17.0877s/100 iters), loss = 0.153955
I1006 23:23:33.490064  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.153955 (* 1 = 0.153955 loss)
I1006 23:23:33.490070  4081 sgd_solver.cpp:105] Iteration 40700, lr = 0.01
I1006 23:23:51.102963  4081 solver.cpp:218] Iteration 40800 (5.67768 iter/s, 17.6128s/100 iters), loss = 0.0665917
I1006 23:23:51.103075  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0665915 (* 1 = 0.0665915 loss)
I1006 23:23:51.103093  4081 sgd_solver.cpp:105] Iteration 40800, lr = 0.01
I1006 23:24:08.184239  4081 solver.cpp:218] Iteration 40900 (5.85442 iter/s, 17.0811s/100 iters), loss = 0.0601552
I1006 23:24:08.184281  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.060155 (* 1 = 0.060155 loss)
I1006 23:24:08.184288  4081 sgd_solver.cpp:105] Iteration 40900, lr = 0.01
I1006 23:24:24.405124  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:24:25.085098  4081 solver.cpp:330] Iteration 41000, Testing net (#0)
I1006 23:24:28.679679  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:24:28.842456  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8993
I1006 23:24:28.842494  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.292339 (* 1 = 0.292339 loss)
I1006 23:24:28.935940  4081 solver.cpp:218] Iteration 41000 (4.81891 iter/s, 20.7516s/100 iters), loss = 0.0740601
I1006 23:24:28.935974  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0740599 (* 1 = 0.0740599 loss)
I1006 23:24:28.935981  4081 sgd_solver.cpp:105] Iteration 41000, lr = 0.01
I1006 23:24:46.094085  4081 solver.cpp:218] Iteration 41100 (5.82819 iter/s, 17.158s/100 iters), loss = 0.102531
I1006 23:24:46.094128  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.102531 (* 1 = 0.102531 loss)
I1006 23:24:46.094135  4081 sgd_solver.cpp:105] Iteration 41100, lr = 0.01
I1006 23:25:03.165547  4081 solver.cpp:218] Iteration 41200 (5.85777 iter/s, 17.0714s/100 iters), loss = 0.103321
I1006 23:25:03.165660  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.103321 (* 1 = 0.103321 loss)
I1006 23:25:03.165668  4081 sgd_solver.cpp:105] Iteration 41200, lr = 0.01
I1006 23:25:20.790436  4081 solver.cpp:218] Iteration 41300 (5.67385 iter/s, 17.6247s/100 iters), loss = 0.0744426
I1006 23:25:20.790477  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0744424 (* 1 = 0.0744424 loss)
I1006 23:25:20.790484  4081 sgd_solver.cpp:105] Iteration 41300, lr = 0.01
I1006 23:25:37.879927  4081 solver.cpp:218] Iteration 41400 (5.85159 iter/s, 17.0894s/100 iters), loss = 0.0606998
I1006 23:25:37.880055  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0606997 (* 1 = 0.0606997 loss)
I1006 23:25:37.880064  4081 sgd_solver.cpp:105] Iteration 41400, lr = 0.01
I1006 23:25:54.114826  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:25:54.797644  4081 solver.cpp:330] Iteration 41500, Testing net (#0)
I1006 23:25:58.395813  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:25:58.537854  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9031
I1006 23:25:58.537883  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.28846 (* 1 = 0.28846 loss)
I1006 23:25:58.649524  4081 solver.cpp:218] Iteration 41500 (4.81477 iter/s, 20.7694s/100 iters), loss = 0.0574899
I1006 23:25:58.649555  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0574897 (* 1 = 0.0574897 loss)
I1006 23:25:58.649575  4081 sgd_solver.cpp:105] Iteration 41500, lr = 0.01
I1006 23:26:15.814178  4081 solver.cpp:218] Iteration 41600 (5.82596 iter/s, 17.1646s/100 iters), loss = 0.127163
I1006 23:26:15.814292  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.127162 (* 1 = 0.127162 loss)
I1006 23:26:15.814301  4081 sgd_solver.cpp:105] Iteration 41600, lr = 0.01
I1006 23:26:32.908382  4081 solver.cpp:218] Iteration 41700 (5.85 iter/s, 17.094s/100 iters), loss = 0.0767617
I1006 23:26:32.908427  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0767616 (* 1 = 0.0767616 loss)
I1006 23:26:32.908432  4081 sgd_solver.cpp:105] Iteration 41700, lr = 0.01
I1006 23:26:50.517227  4081 solver.cpp:218] Iteration 41800 (5.679 iter/s, 17.6087s/100 iters), loss = 0.127344
I1006 23:26:50.517338  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.127344 (* 1 = 0.127344 loss)
I1006 23:26:50.517345  4081 sgd_solver.cpp:105] Iteration 41800, lr = 0.01
I1006 23:27:07.584938  4081 solver.cpp:218] Iteration 41900 (5.85908 iter/s, 17.0675s/100 iters), loss = 0.0483564
I1006 23:27:07.584969  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0483562 (* 1 = 0.0483562 loss)
I1006 23:27:07.584975  4081 sgd_solver.cpp:105] Iteration 41900, lr = 0.01
I1006 23:27:23.826340  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:27:24.508769  4081 solver.cpp:330] Iteration 42000, Testing net (#0)
I1006 23:27:28.107384  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:27:28.273121  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9032
I1006 23:27:28.273147  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.285024 (* 1 = 0.285024 loss)
I1006 23:27:28.376360  4081 solver.cpp:218] Iteration 42000 (4.8097 iter/s, 20.7913s/100 iters), loss = 0.0484891
I1006 23:27:28.376390  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0484889 (* 1 = 0.0484889 loss)
I1006 23:27:28.376399  4081 sgd_solver.cpp:105] Iteration 42000, lr = 0.01
I1006 23:27:45.502122  4081 solver.cpp:218] Iteration 42100 (5.83991 iter/s, 17.1236s/100 iters), loss = 0.0878534
I1006 23:27:45.502166  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0878533 (* 1 = 0.0878533 loss)
I1006 23:27:45.502171  4081 sgd_solver.cpp:105] Iteration 42100, lr = 0.01
I1006 23:28:02.564527  4081 solver.cpp:218] Iteration 42200 (5.86088 iter/s, 17.0623s/100 iters), loss = 0.141769
I1006 23:28:02.564658  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.141769 (* 1 = 0.141769 loss)
I1006 23:28:02.564666  4081 sgd_solver.cpp:105] Iteration 42200, lr = 0.01
I1006 23:28:20.162197  4081 solver.cpp:218] Iteration 42300 (5.68263 iter/s, 17.5975s/100 iters), loss = 0.0382829
I1006 23:28:20.162231  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0382827 (* 1 = 0.0382827 loss)
I1006 23:28:20.162248  4081 sgd_solver.cpp:105] Iteration 42300, lr = 0.01
I1006 23:28:37.229564  4081 solver.cpp:218] Iteration 42400 (5.85949 iter/s, 17.0663s/100 iters), loss = 0.0265994
I1006 23:28:37.229686  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0265993 (* 1 = 0.0265993 loss)
I1006 23:28:37.229694  4081 sgd_solver.cpp:105] Iteration 42400, lr = 0.01
I1006 23:28:53.455008  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:28:54.137382  4081 solver.cpp:330] Iteration 42500, Testing net (#0)
I1006 23:28:57.736917  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:28:57.903676  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9095
I1006 23:28:57.903712  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.280785 (* 1 = 0.280785 loss)
I1006 23:28:58.017752  4081 solver.cpp:218] Iteration 42500 (4.81047 iter/s, 20.788s/100 iters), loss = 0.0674522
I1006 23:28:58.017792  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0674521 (* 1 = 0.0674521 loss)
I1006 23:28:58.017799  4081 sgd_solver.cpp:105] Iteration 42500, lr = 0.01
I1006 23:29:15.148885  4081 solver.cpp:218] Iteration 42600 (5.83809 iter/s, 17.1289s/100 iters), loss = 0.0890613
I1006 23:29:15.149006  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0890612 (* 1 = 0.0890612 loss)
I1006 23:29:15.149024  4081 sgd_solver.cpp:105] Iteration 42600, lr = 0.01
I1006 23:29:32.238188  4081 solver.cpp:218] Iteration 42700 (5.85167 iter/s, 17.0891s/100 iters), loss = 0.160498
I1006 23:29:32.238229  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.160497 (* 1 = 0.160497 loss)
I1006 23:29:32.238234  4081 sgd_solver.cpp:105] Iteration 42700, lr = 0.01
I1006 23:29:49.856382  4081 solver.cpp:218] Iteration 42800 (5.67598 iter/s, 17.6181s/100 iters), loss = 0.0901008
I1006 23:29:49.856464  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0901005 (* 1 = 0.0901005 loss)
I1006 23:29:49.856483  4081 sgd_solver.cpp:105] Iteration 42800, lr = 0.01
I1006 23:30:06.924713  4081 solver.cpp:218] Iteration 42900 (5.85885 iter/s, 17.0682s/100 iters), loss = 0.0474579
I1006 23:30:06.924757  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0474577 (* 1 = 0.0474577 loss)
I1006 23:30:06.924764  4081 sgd_solver.cpp:105] Iteration 42900, lr = 0.01
I1006 23:30:23.140219  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:30:23.821920  4081 solver.cpp:330] Iteration 43000, Testing net (#0)
I1006 23:30:27.416668  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:30:27.557066  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9023
I1006 23:30:27.557104  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.307294 (* 1 = 0.307294 loss)
I1006 23:30:27.671115  4081 solver.cpp:218] Iteration 43000 (4.82014 iter/s, 20.7463s/100 iters), loss = 0.0490742
I1006 23:30:27.671151  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.049074 (* 1 = 0.049074 loss)
I1006 23:30:27.671157  4081 sgd_solver.cpp:105] Iteration 43000, lr = 0.01
I1006 23:30:44.824101  4081 solver.cpp:218] Iteration 43100 (5.82992 iter/s, 17.1529s/100 iters), loss = 0.0644512
I1006 23:30:44.824134  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0644509 (* 1 = 0.0644509 loss)
I1006 23:30:44.824143  4081 sgd_solver.cpp:105] Iteration 43100, lr = 0.01
I1006 23:31:01.915102  4081 solver.cpp:218] Iteration 43200 (5.85107 iter/s, 17.0909s/100 iters), loss = 0.0655016
I1006 23:31:01.915206  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0655014 (* 1 = 0.0655014 loss)
I1006 23:31:01.915223  4081 sgd_solver.cpp:105] Iteration 43200, lr = 0.01
I1006 23:31:19.536821  4081 solver.cpp:218] Iteration 43300 (5.67487 iter/s, 17.6216s/100 iters), loss = 0.0677774
I1006 23:31:19.536864  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0677772 (* 1 = 0.0677772 loss)
I1006 23:31:19.536871  4081 sgd_solver.cpp:105] Iteration 43300, lr = 0.01
I1006 23:31:36.604008  4081 solver.cpp:218] Iteration 43400 (5.85924 iter/s, 17.0671s/100 iters), loss = 0.016581
I1006 23:31:36.604151  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0165807 (* 1 = 0.0165807 loss)
I1006 23:31:36.604167  4081 sgd_solver.cpp:105] Iteration 43400, lr = 0.01
I1006 23:31:52.822077  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:31:53.505863  4081 solver.cpp:330] Iteration 43500, Testing net (#0)
I1006 23:31:57.101752  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:31:57.267943  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9016
I1006 23:31:57.267979  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.29562 (* 1 = 0.29562 loss)
I1006 23:31:57.370512  4081 solver.cpp:218] Iteration 43500 (4.81549 iter/s, 20.7663s/100 iters), loss = 0.0266089
I1006 23:31:57.370549  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0266087 (* 1 = 0.0266087 loss)
I1006 23:31:57.370556  4081 sgd_solver.cpp:105] Iteration 43500, lr = 0.01
I1006 23:32:14.525650  4081 solver.cpp:218] Iteration 43600 (5.8299 iter/s, 17.1529s/100 iters), loss = 0.120124
I1006 23:32:14.530026  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.120124 (* 1 = 0.120124 loss)
I1006 23:32:14.530035  4081 sgd_solver.cpp:105] Iteration 43600, lr = 0.01
I1006 23:32:31.717283  4081 solver.cpp:218] Iteration 43700 (5.81867 iter/s, 17.1861s/100 iters), loss = 0.0361916
I1006 23:32:31.717324  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0361914 (* 1 = 0.0361914 loss)
I1006 23:32:31.717330  4081 sgd_solver.cpp:105] Iteration 43700, lr = 0.01
I1006 23:32:49.360116  4081 solver.cpp:218] Iteration 43800 (5.66806 iter/s, 17.6427s/100 iters), loss = 0.0515644
I1006 23:32:49.360179  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0515643 (* 1 = 0.0515643 loss)
I1006 23:32:49.360199  4081 sgd_solver.cpp:105] Iteration 43800, lr = 0.01
I1006 23:33:06.448071  4081 solver.cpp:218] Iteration 43900 (5.85212 iter/s, 17.0878s/100 iters), loss = 0.0270773
I1006 23:33:06.448112  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0270771 (* 1 = 0.0270771 loss)
I1006 23:33:06.448118  4081 sgd_solver.cpp:105] Iteration 43900, lr = 0.01
I1006 23:33:22.698635  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:33:23.383842  4081 solver.cpp:330] Iteration 44000, Testing net (#0)
I1006 23:33:26.984105  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:33:27.127876  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9101
I1006 23:33:27.127913  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.282168 (* 1 = 0.282168 loss)
I1006 23:33:27.237476  4081 solver.cpp:218] Iteration 44000 (4.81017 iter/s, 20.7893s/100 iters), loss = 0.0373001
I1006 23:33:27.237506  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0372999 (* 1 = 0.0372999 loss)
I1006 23:33:27.237524  4081 sgd_solver.cpp:105] Iteration 44000, lr = 0.01
I1006 23:33:44.388129  4081 solver.cpp:218] Iteration 44100 (5.83072 iter/s, 17.1506s/100 iters), loss = 0.0438995
I1006 23:33:44.388171  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0438993 (* 1 = 0.0438993 loss)
I1006 23:33:44.388178  4081 sgd_solver.cpp:105] Iteration 44100, lr = 0.01
I1006 23:34:01.462708  4081 solver.cpp:218] Iteration 44200 (5.85716 iter/s, 17.0731s/100 iters), loss = 0.0925942
I1006 23:34:01.462826  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0925941 (* 1 = 0.0925941 loss)
I1006 23:34:01.462844  4081 sgd_solver.cpp:105] Iteration 44200, lr = 0.01
I1006 23:34:19.077944  4081 solver.cpp:218] Iteration 44300 (5.67696 iter/s, 17.6151s/100 iters), loss = 0.0422182
I1006 23:34:19.077986  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.042218 (* 1 = 0.042218 loss)
I1006 23:34:19.077993  4081 sgd_solver.cpp:105] Iteration 44300, lr = 0.01
I1006 23:34:36.148427  4081 solver.cpp:218] Iteration 44400 (5.8581 iter/s, 17.0704s/100 iters), loss = 0.0482946
I1006 23:34:36.148543  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0482944 (* 1 = 0.0482944 loss)
I1006 23:34:36.148566  4081 sgd_solver.cpp:105] Iteration 44400, lr = 0.01
I1006 23:34:52.381481  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:34:53.065424  4081 solver.cpp:330] Iteration 44500, Testing net (#0)
I1006 23:34:56.686174  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:34:56.830797  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9047
I1006 23:34:56.830834  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.303715 (* 1 = 0.303715 loss)
I1006 23:34:56.998350  4081 solver.cpp:218] Iteration 44500 (4.79622 iter/s, 20.8497s/100 iters), loss = 0.0325996
I1006 23:34:56.998394  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0325994 (* 1 = 0.0325994 loss)
I1006 23:34:56.998400  4081 sgd_solver.cpp:105] Iteration 44500, lr = 0.01
I1006 23:35:14.064167  4081 solver.cpp:218] Iteration 44600 (5.8597 iter/s, 17.0657s/100 iters), loss = 0.124559
I1006 23:35:14.064250  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.124559 (* 1 = 0.124559 loss)
I1006 23:35:14.064258  4081 sgd_solver.cpp:105] Iteration 44600, lr = 0.01
I1006 23:35:31.128163  4081 solver.cpp:218] Iteration 44700 (5.86034 iter/s, 17.0639s/100 iters), loss = 0.0629754
I1006 23:35:31.128206  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0629753 (* 1 = 0.0629753 loss)
I1006 23:35:31.128213  4081 sgd_solver.cpp:105] Iteration 44700, lr = 0.01
I1006 23:35:48.745265  4081 solver.cpp:218] Iteration 44800 (5.67634 iter/s, 17.617s/100 iters), loss = 0.0348803
I1006 23:35:48.745376  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0348801 (* 1 = 0.0348801 loss)
I1006 23:35:48.745384  4081 sgd_solver.cpp:105] Iteration 44800, lr = 0.01
I1006 23:36:05.822670  4081 solver.cpp:218] Iteration 44900 (5.85575 iter/s, 17.0772s/100 iters), loss = 0.0114518
I1006 23:36:05.822700  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0114517 (* 1 = 0.0114517 loss)
I1006 23:36:05.822717  4081 sgd_solver.cpp:105] Iteration 44900, lr = 0.01
I1006 23:36:22.042155  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:36:22.721683  4081 solver.cpp:330] Iteration 45000, Testing net (#0)
I1006 23:36:26.322635  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:36:26.488029  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.908
I1006 23:36:26.488065  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.297971 (* 1 = 0.297971 loss)
I1006 23:36:26.591258  4081 solver.cpp:218] Iteration 45000 (4.81499 iter/s, 20.7685s/100 iters), loss = 0.0346581
I1006 23:36:26.591297  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.034658 (* 1 = 0.034658 loss)
I1006 23:36:26.591305  4081 sgd_solver.cpp:105] Iteration 45000, lr = 0.01
I1006 23:36:43.726451  4081 solver.cpp:218] Iteration 45100 (5.83669 iter/s, 17.133s/100 iters), loss = 0.0604214
I1006 23:36:43.726485  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0604213 (* 1 = 0.0604213 loss)
I1006 23:36:43.726492  4081 sgd_solver.cpp:105] Iteration 45100, lr = 0.01
I1006 23:37:00.790882  4081 solver.cpp:218] Iteration 45200 (5.86018 iter/s, 17.0643s/100 iters), loss = 0.0709101
I1006 23:37:00.790946  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.07091 (* 1 = 0.07091 loss)
I1006 23:37:00.790964  4081 sgd_solver.cpp:105] Iteration 45200, lr = 0.01
I1006 23:37:18.402027  4081 solver.cpp:218] Iteration 45300 (5.67827 iter/s, 17.611s/100 iters), loss = 0.0380135
I1006 23:37:18.402070  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0380134 (* 1 = 0.0380134 loss)
I1006 23:37:18.402076  4081 sgd_solver.cpp:105] Iteration 45300, lr = 0.01
I1006 23:37:35.480206  4081 solver.cpp:218] Iteration 45400 (5.85596 iter/s, 17.0766s/100 iters), loss = 0.0494583
I1006 23:37:35.480324  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0494582 (* 1 = 0.0494582 loss)
I1006 23:37:35.480332  4081 sgd_solver.cpp:105] Iteration 45400, lr = 0.01
I1006 23:37:51.699249  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:37:52.381319  4081 solver.cpp:330] Iteration 45500, Testing net (#0)
I1006 23:37:55.979532  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:37:56.121107  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9064
I1006 23:37:56.121145  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.318973 (* 1 = 0.318973 loss)
I1006 23:37:56.233140  4081 solver.cpp:218] Iteration 45500 (4.81864 iter/s, 20.7528s/100 iters), loss = 0.063215
I1006 23:37:56.233180  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0632149 (* 1 = 0.0632149 loss)
I1006 23:37:56.233191  4081 sgd_solver.cpp:105] Iteration 45500, lr = 0.01
I1006 23:38:13.400491  4081 solver.cpp:218] Iteration 45600 (5.82505 iter/s, 17.1672s/100 iters), loss = 0.0376856
I1006 23:38:13.400599  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0376855 (* 1 = 0.0376855 loss)
I1006 23:38:13.400607  4081 sgd_solver.cpp:105] Iteration 45600, lr = 0.01
I1006 23:38:30.473213  4081 solver.cpp:218] Iteration 45700 (5.85735 iter/s, 17.0726s/100 iters), loss = 0.0763289
I1006 23:38:30.473253  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0763288 (* 1 = 0.0763288 loss)
I1006 23:38:30.473259  4081 sgd_solver.cpp:105] Iteration 45700, lr = 0.01
I1006 23:38:48.084789  4081 solver.cpp:218] Iteration 45800 (5.67812 iter/s, 17.6115s/100 iters), loss = 0.0682235
I1006 23:38:48.084869  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0682234 (* 1 = 0.0682234 loss)
I1006 23:38:48.084877  4081 sgd_solver.cpp:105] Iteration 45800, lr = 0.01
I1006 23:39:05.161198  4081 solver.cpp:218] Iteration 45900 (5.85608 iter/s, 17.0763s/100 iters), loss = 0.00506204
I1006 23:39:05.161231  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00506192 (* 1 = 0.00506192 loss)
I1006 23:39:05.161248  4081 sgd_solver.cpp:105] Iteration 45900, lr = 0.01
I1006 23:39:21.390852  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:39:22.072806  4081 solver.cpp:330] Iteration 46000, Testing net (#0)
I1006 23:39:25.670055  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:39:25.814365  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9037
I1006 23:39:25.814401  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.324221 (* 1 = 0.324221 loss)
I1006 23:39:25.923478  4081 solver.cpp:218] Iteration 46000 (4.81645 iter/s, 20.7622s/100 iters), loss = 0.0299939
I1006 23:39:25.923516  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0299938 (* 1 = 0.0299938 loss)
I1006 23:39:25.923523  4081 sgd_solver.cpp:105] Iteration 46000, lr = 0.01
I1006 23:39:43.084452  4081 solver.cpp:218] Iteration 46100 (5.82721 iter/s, 17.1609s/100 iters), loss = 0.0136662
I1006 23:39:43.084494  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0136661 (* 1 = 0.0136661 loss)
I1006 23:39:43.084501  4081 sgd_solver.cpp:105] Iteration 46100, lr = 0.01
I1006 23:40:00.159852  4081 solver.cpp:218] Iteration 46200 (5.85683 iter/s, 17.0741s/100 iters), loss = 0.0526125
I1006 23:40:00.159955  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0526124 (* 1 = 0.0526124 loss)
I1006 23:40:00.159962  4081 sgd_solver.cpp:105] Iteration 46200, lr = 0.01
I1006 23:40:17.792322  4081 solver.cpp:218] Iteration 46300 (5.67141 iter/s, 17.6323s/100 iters), loss = 0.0519735
I1006 23:40:17.792366  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0519734 (* 1 = 0.0519734 loss)
I1006 23:40:17.792371  4081 sgd_solver.cpp:105] Iteration 46300, lr = 0.01
I1006 23:40:34.865700  4081 solver.cpp:218] Iteration 46400 (5.85711 iter/s, 17.0733s/100 iters), loss = 0.0227257
I1006 23:40:34.865818  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0227256 (* 1 = 0.0227256 loss)
I1006 23:40:34.865826  4081 sgd_solver.cpp:105] Iteration 46400, lr = 0.01
I1006 23:40:51.105515  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:40:51.785079  4081 solver.cpp:330] Iteration 46500, Testing net (#0)
I1006 23:40:55.369182  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:40:55.535604  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9072
I1006 23:40:55.535641  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.337564 (* 1 = 0.337564 loss)
I1006 23:40:55.640208  4081 solver.cpp:218] Iteration 46500 (4.81363 iter/s, 20.7743s/100 iters), loss = 0.0318753
I1006 23:40:55.640238  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0318752 (* 1 = 0.0318752 loss)
I1006 23:40:55.640259  4081 sgd_solver.cpp:105] Iteration 46500, lr = 0.01
I1006 23:41:12.782402  4081 solver.cpp:218] Iteration 46600 (5.83431 iter/s, 17.14s/100 iters), loss = 0.0295102
I1006 23:41:12.782480  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0295101 (* 1 = 0.0295101 loss)
I1006 23:41:12.782488  4081 sgd_solver.cpp:105] Iteration 46600, lr = 0.01
I1006 23:41:29.869464  4081 solver.cpp:218] Iteration 46700 (5.85242 iter/s, 17.0869s/100 iters), loss = 0.0411243
I1006 23:41:29.869506  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0411242 (* 1 = 0.0411242 loss)
I1006 23:41:29.869513  4081 sgd_solver.cpp:105] Iteration 46700, lr = 0.01
I1006 23:41:47.487918  4081 solver.cpp:218] Iteration 46800 (5.67617 iter/s, 17.6175s/100 iters), loss = 0.0261417
I1006 23:41:47.488044  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0261416 (* 1 = 0.0261416 loss)
I1006 23:41:47.488062  4081 sgd_solver.cpp:105] Iteration 46800, lr = 0.01
I1006 23:42:04.583107  4081 solver.cpp:218] Iteration 46900 (5.85004 iter/s, 17.0939s/100 iters), loss = 0.0105171
I1006 23:42:04.583149  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0105169 (* 1 = 0.0105169 loss)
I1006 23:42:04.583156  4081 sgd_solver.cpp:105] Iteration 46900, lr = 0.01
I1006 23:42:20.817364  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:42:21.496515  4081 solver.cpp:330] Iteration 47000, Testing net (#0)
I1006 23:42:25.098582  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:42:25.238855  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9056
I1006 23:42:25.238893  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.324757 (* 1 = 0.324757 loss)
I1006 23:42:25.353130  4081 solver.cpp:218] Iteration 47000 (4.81466 iter/s, 20.7699s/100 iters), loss = 0.0290592
I1006 23:42:25.353166  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0290591 (* 1 = 0.0290591 loss)
I1006 23:42:25.353173  4081 sgd_solver.cpp:105] Iteration 47000, lr = 0.01
I1006 23:42:42.500387  4081 solver.cpp:218] Iteration 47100 (5.83187 iter/s, 17.1472s/100 iters), loss = 0.0682907
I1006 23:42:42.500428  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0682905 (* 1 = 0.0682905 loss)
I1006 23:42:42.500434  4081 sgd_solver.cpp:105] Iteration 47100, lr = 0.01
I1006 23:42:59.601384  4081 solver.cpp:218] Iteration 47200 (5.84765 iter/s, 17.1009s/100 iters), loss = 0.0673433
I1006 23:42:59.601492  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0673431 (* 1 = 0.0673431 loss)
I1006 23:42:59.601500  4081 sgd_solver.cpp:105] Iteration 47200, lr = 0.01
I1006 23:43:17.232127  4081 solver.cpp:218] Iteration 47300 (5.67197 iter/s, 17.6306s/100 iters), loss = 0.05436
I1006 23:43:17.232177  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0543599 (* 1 = 0.0543599 loss)
I1006 23:43:17.232183  4081 sgd_solver.cpp:105] Iteration 47300, lr = 0.01
I1006 23:43:34.302606  4081 solver.cpp:218] Iteration 47400 (5.85811 iter/s, 17.0704s/100 iters), loss = 0.0199661
I1006 23:43:34.302764  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.019966 (* 1 = 0.019966 loss)
I1006 23:43:34.302773  4081 sgd_solver.cpp:105] Iteration 47400, lr = 0.01
I1006 23:43:50.528095  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:43:51.209064  4081 solver.cpp:330] Iteration 47500, Testing net (#0)
I1006 23:43:54.806315  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:43:54.971487  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9101
I1006 23:43:54.971523  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.313004 (* 1 = 0.313004 loss)
I1006 23:43:55.100355  4081 solver.cpp:218] Iteration 47500 (4.80826 iter/s, 20.7975s/100 iters), loss = 0.0351075
I1006 23:43:55.100394  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0351074 (* 1 = 0.0351074 loss)
I1006 23:43:55.100400  4081 sgd_solver.cpp:105] Iteration 47500, lr = 0.01
I1006 23:44:12.219388  4081 solver.cpp:218] Iteration 47600 (5.8422 iter/s, 17.1168s/100 iters), loss = 0.00847768
I1006 23:44:12.219509  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00847752 (* 1 = 0.00847752 loss)
I1006 23:44:12.219527  4081 sgd_solver.cpp:105] Iteration 47600, lr = 0.01
I1006 23:44:29.284974  4081 solver.cpp:218] Iteration 47700 (5.85981 iter/s, 17.0654s/100 iters), loss = 0.0694594
I1006 23:44:29.285017  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0694593 (* 1 = 0.0694593 loss)
I1006 23:44:29.285023  4081 sgd_solver.cpp:105] Iteration 47700, lr = 0.01
I1006 23:44:46.892196  4081 solver.cpp:218] Iteration 47800 (5.67952 iter/s, 17.6071s/100 iters), loss = 0.0158701
I1006 23:44:46.892287  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.01587 (* 1 = 0.01587 loss)
I1006 23:44:46.892308  4081 sgd_solver.cpp:105] Iteration 47800, lr = 0.01
I1006 23:45:03.966070  4081 solver.cpp:218] Iteration 47900 (5.85696 iter/s, 17.0737s/100 iters), loss = 0.0172263
I1006 23:45:03.966114  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0172261 (* 1 = 0.0172261 loss)
I1006 23:45:03.966120  4081 sgd_solver.cpp:105] Iteration 47900, lr = 0.01
I1006 23:45:20.181485  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:45:20.863656  4081 solver.cpp:330] Iteration 48000, Testing net (#0)
I1006 23:45:24.457103  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:45:24.599509  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9012
I1006 23:45:24.599537  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.339762 (* 1 = 0.339762 loss)
I1006 23:45:24.711004  4081 solver.cpp:218] Iteration 48000 (4.82048 iter/s, 20.7448s/100 iters), loss = 0.0247176
I1006 23:45:24.711040  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0247175 (* 1 = 0.0247175 loss)
I1006 23:45:24.711047  4081 sgd_solver.cpp:105] Iteration 48000, lr = 0.01
I1006 23:45:41.876832  4081 solver.cpp:218] Iteration 48100 (5.82556 iter/s, 17.1657s/100 iters), loss = 0.0509834
I1006 23:45:41.876865  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0509833 (* 1 = 0.0509833 loss)
I1006 23:45:41.876883  4081 sgd_solver.cpp:105] Iteration 48100, lr = 0.01
I1006 23:45:58.958230  4081 solver.cpp:218] Iteration 48200 (5.85436 iter/s, 17.0813s/100 iters), loss = 0.0414446
I1006 23:45:58.958300  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0414445 (* 1 = 0.0414445 loss)
I1006 23:45:58.958308  4081 sgd_solver.cpp:105] Iteration 48200, lr = 0.01
I1006 23:46:16.578490  4081 solver.cpp:218] Iteration 48300 (5.67533 iter/s, 17.6201s/100 iters), loss = 0.0234041
I1006 23:46:16.578531  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0234039 (* 1 = 0.0234039 loss)
I1006 23:46:16.578537  4081 sgd_solver.cpp:105] Iteration 48300, lr = 0.01
I1006 23:46:33.655411  4081 solver.cpp:218] Iteration 48400 (5.85589 iter/s, 17.0768s/100 iters), loss = 0.0117549
I1006 23:46:33.655494  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0117547 (* 1 = 0.0117547 loss)
I1006 23:46:33.655503  4081 sgd_solver.cpp:105] Iteration 48400, lr = 0.01
I1006 23:46:49.890133  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:46:50.573778  4081 solver.cpp:330] Iteration 48500, Testing net (#0)
I1006 23:46:54.146508  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:46:54.277323  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9062
I1006 23:46:54.277349  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.328364 (* 1 = 0.328364 loss)
I1006 23:46:54.426606  4081 solver.cpp:218] Iteration 48500 (4.81439 iter/s, 20.771s/100 iters), loss = 0.0223247
I1006 23:46:54.426648  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0223245 (* 1 = 0.0223245 loss)
I1006 23:46:54.426656  4081 sgd_solver.cpp:105] Iteration 48500, lr = 0.01
I1006 23:47:11.509866  4081 solver.cpp:218] Iteration 48600 (5.85372 iter/s, 17.0832s/100 iters), loss = 0.0181961
I1006 23:47:11.510017  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.018196 (* 1 = 0.018196 loss)
I1006 23:47:11.510026  4081 sgd_solver.cpp:105] Iteration 48600, lr = 0.01
I1006 23:47:28.603662  4081 solver.cpp:218] Iteration 48700 (5.85015 iter/s, 17.0936s/100 iters), loss = 0.0391409
I1006 23:47:28.603703  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0391407 (* 1 = 0.0391407 loss)
I1006 23:47:28.603708  4081 sgd_solver.cpp:105] Iteration 48700, lr = 0.01
I1006 23:47:41.629900  4081 solver.cpp:218] Iteration 48800 (7.67687 iter/s, 13.0261s/100 iters), loss = 0.0427895
I1006 23:47:41.629987  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0427893 (* 1 = 0.0427893 loss)
I1006 23:47:41.630003  4081 sgd_solver.cpp:105] Iteration 48800, lr = 0.01
I1006 23:47:49.982811  4081 solver.cpp:218] Iteration 48900 (11.972 iter/s, 8.35282s/100 iters), loss = 0.0065932
I1006 23:47:49.982841  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00659304 (* 1 = 0.00659304 loss)
I1006 23:47:49.982857  4081 sgd_solver.cpp:105] Iteration 48900, lr = 0.01
I1006 23:47:57.909984  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:47:58.245126  4081 solver.cpp:330] Iteration 49000, Testing net (#0)
I1006 23:48:00.176489  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:48:00.257758  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9126
I1006 23:48:00.257794  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.320219 (* 1 = 0.320219 loss)
I1006 23:48:00.341094  4081 solver.cpp:218] Iteration 49000 (9.65416 iter/s, 10.3582s/100 iters), loss = 0.0118346
I1006 23:48:00.341119  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0118344 (* 1 = 0.0118344 loss)
I1006 23:48:00.341125  4081 sgd_solver.cpp:105] Iteration 49000, lr = 0.01
I1006 23:48:08.694172  4081 solver.cpp:218] Iteration 49100 (11.9717 iter/s, 8.35303s/100 iters), loss = 0.0103788
I1006 23:48:08.694212  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0103787 (* 1 = 0.0103787 loss)
I1006 23:48:08.694217  4081 sgd_solver.cpp:105] Iteration 49100, lr = 0.01
I1006 23:48:17.033833  4081 solver.cpp:218] Iteration 49200 (11.991 iter/s, 8.3396s/100 iters), loss = 0.0412737
I1006 23:48:17.033934  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0412735 (* 1 = 0.0412735 loss)
I1006 23:48:17.033941  4081 sgd_solver.cpp:105] Iteration 49200, lr = 0.01
I1006 23:48:25.378896  4081 solver.cpp:218] Iteration 49300 (11.9833 iter/s, 8.34494s/100 iters), loss = 0.0483753
I1006 23:48:25.378926  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0483752 (* 1 = 0.0483752 loss)
I1006 23:48:25.378932  4081 sgd_solver.cpp:105] Iteration 49300, lr = 0.01
I1006 23:48:33.727936  4081 solver.cpp:218] Iteration 49400 (11.9775 iter/s, 8.34899s/100 iters), loss = 0.0130607
I1006 23:48:33.727977  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0130605 (* 1 = 0.0130605 loss)
I1006 23:48:33.727982  4081 sgd_solver.cpp:105] Iteration 49400, lr = 0.01
I1006 23:48:41.665577  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:48:42.000389  4081 solver.cpp:330] Iteration 49500, Testing net (#0)
I1006 23:48:43.930955  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:48:44.011941  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.912
I1006 23:48:44.011967  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.314096 (* 1 = 0.314096 loss)
I1006 23:48:44.095368  4081 solver.cpp:218] Iteration 49500 (9.64565 iter/s, 10.3674s/100 iters), loss = 0.0127649
I1006 23:48:44.095393  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0127647 (* 1 = 0.0127647 loss)
I1006 23:48:44.095401  4081 sgd_solver.cpp:105] Iteration 49500, lr = 0.01
I1006 23:48:52.433374  4081 solver.cpp:218] Iteration 49600 (11.9933 iter/s, 8.33796s/100 iters), loss = 0.0129024
I1006 23:48:52.433501  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0129023 (* 1 = 0.0129023 loss)
I1006 23:48:52.433511  4081 sgd_solver.cpp:105] Iteration 49600, lr = 0.01
I1006 23:49:00.772393  4081 solver.cpp:218] Iteration 49700 (11.992 iter/s, 8.33888s/100 iters), loss = 0.119036
I1006 23:49:00.772423  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.119036 (* 1 = 0.119036 loss)
I1006 23:49:00.772440  4081 sgd_solver.cpp:105] Iteration 49700, lr = 0.01
I1006 23:49:09.113909  4081 solver.cpp:218] Iteration 49800 (11.9883 iter/s, 8.34146s/100 iters), loss = 0.0124421
I1006 23:49:09.113940  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.012442 (* 1 = 0.012442 loss)
I1006 23:49:09.113945  4081 sgd_solver.cpp:105] Iteration 49800, lr = 0.01
I1006 23:49:17.447319  4081 solver.cpp:218] Iteration 49900 (12 iter/s, 8.33336s/100 iters), loss = 0.00841185
I1006 23:49:17.447347  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00841165 (* 1 = 0.00841165 loss)
I1006 23:49:17.447353  4081 sgd_solver.cpp:105] Iteration 49900, lr = 0.01
I1006 23:49:25.372022  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:49:25.706151  4081 solver.cpp:330] Iteration 50000, Testing net (#0)
I1006 23:49:27.638977  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:49:27.719216  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9067
I1006 23:49:27.719251  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.344583 (* 1 = 0.344583 loss)
I1006 23:49:27.802497  4081 solver.cpp:218] Iteration 50000 (9.65705 iter/s, 10.3551s/100 iters), loss = 0.0132378
I1006 23:49:27.802522  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0132376 (* 1 = 0.0132376 loss)
I1006 23:49:27.802530  4081 sgd_solver.cpp:105] Iteration 50000, lr = 0.01
I1006 23:49:36.143956  4081 solver.cpp:218] Iteration 50100 (11.9884 iter/s, 8.34141s/100 iters), loss = 0.0476283
I1006 23:49:36.143997  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0476281 (* 1 = 0.0476281 loss)
I1006 23:49:36.144003  4081 sgd_solver.cpp:105] Iteration 50100, lr = 0.01
I1006 23:49:44.490674  4081 solver.cpp:218] Iteration 50200 (11.9808 iter/s, 8.34666s/100 iters), loss = 0.0549765
I1006 23:49:44.490705  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0549763 (* 1 = 0.0549763 loss)
I1006 23:49:44.490711  4081 sgd_solver.cpp:105] Iteration 50200, lr = 0.01
I1006 23:49:52.835821  4081 solver.cpp:218] Iteration 50300 (11.9831 iter/s, 8.3451s/100 iters), loss = 0.00693016
I1006 23:49:52.835851  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00692997 (* 1 = 0.00692997 loss)
I1006 23:49:52.835857  4081 sgd_solver.cpp:105] Iteration 50300, lr = 0.01
I1006 23:50:01.178077  4081 solver.cpp:218] Iteration 50400 (11.9872 iter/s, 8.3422s/100 iters), loss = 0.0285242
I1006 23:50:01.178190  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.028524 (* 1 = 0.028524 loss)
I1006 23:50:01.178197  4081 sgd_solver.cpp:105] Iteration 50400, lr = 0.01
I1006 23:50:09.113332  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:50:09.447686  4081 solver.cpp:330] Iteration 50500, Testing net (#0)
I1006 23:50:11.379988  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:50:11.461421  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.906
I1006 23:50:11.461455  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.348824 (* 1 = 0.348824 loss)
I1006 23:50:11.544780  4081 solver.cpp:218] Iteration 50500 (9.64639 iter/s, 10.3666s/100 iters), loss = 0.0112047
I1006 23:50:11.544805  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0112045 (* 1 = 0.0112045 loss)
I1006 23:50:11.544811  4081 sgd_solver.cpp:105] Iteration 50500, lr = 0.01
I1006 23:50:19.881907  4081 solver.cpp:218] Iteration 50600 (11.9946 iter/s, 8.33708s/100 iters), loss = 0.0294271
I1006 23:50:19.881939  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0294269 (* 1 = 0.0294269 loss)
I1006 23:50:19.881947  4081 sgd_solver.cpp:105] Iteration 50600, lr = 0.01
I1006 23:50:28.224985  4081 solver.cpp:218] Iteration 50700 (11.9861 iter/s, 8.34302s/100 iters), loss = 0.0109743
I1006 23:50:28.225016  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.010974 (* 1 = 0.010974 loss)
I1006 23:50:28.225023  4081 sgd_solver.cpp:105] Iteration 50700, lr = 0.01
I1006 23:50:36.561792  4081 solver.cpp:218] Iteration 50800 (11.9951 iter/s, 8.33675s/100 iters), loss = 0.0367964
I1006 23:50:36.561933  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0367962 (* 1 = 0.0367962 loss)
I1006 23:50:36.561951  4081 sgd_solver.cpp:105] Iteration 50800, lr = 0.01
I1006 23:50:44.901257  4081 solver.cpp:218] Iteration 50900 (11.9914 iter/s, 8.3393s/100 iters), loss = 0.00589672
I1006 23:50:44.901298  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00589649 (* 1 = 0.00589649 loss)
I1006 23:50:44.901304  4081 sgd_solver.cpp:105] Iteration 50900, lr = 0.01
I1006 23:50:52.829983  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:50:53.163830  4081 solver.cpp:330] Iteration 51000, Testing net (#0)
I1006 23:50:55.095232  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:50:55.176061  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9042
I1006 23:50:55.176096  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.365286 (* 1 = 0.365286 loss)
I1006 23:50:55.259474  4081 solver.cpp:218] Iteration 51000 (9.65423 iter/s, 10.3582s/100 iters), loss = 0.0247336
I1006 23:50:55.259505  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0247334 (* 1 = 0.0247334 loss)
I1006 23:50:55.259512  4081 sgd_solver.cpp:105] Iteration 51000, lr = 0.01
I1006 23:51:03.598418  4081 solver.cpp:218] Iteration 51100 (11.992 iter/s, 8.33889s/100 iters), loss = 0.00807608
I1006 23:51:03.598459  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00807584 (* 1 = 0.00807584 loss)
I1006 23:51:03.598465  4081 sgd_solver.cpp:105] Iteration 51100, lr = 0.01
I1006 23:51:11.944651  4081 solver.cpp:218] Iteration 51200 (11.9815 iter/s, 8.34617s/100 iters), loss = 0.0225468
I1006 23:51:11.944752  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0225466 (* 1 = 0.0225466 loss)
I1006 23:51:11.944768  4081 sgd_solver.cpp:105] Iteration 51200, lr = 0.01
I1006 23:51:20.281039  4081 solver.cpp:218] Iteration 51300 (11.9958 iter/s, 8.33627s/100 iters), loss = 0.0441173
I1006 23:51:20.281069  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0441171 (* 1 = 0.0441171 loss)
I1006 23:51:20.281075  4081 sgd_solver.cpp:105] Iteration 51300, lr = 0.01
I1006 23:51:28.622066  4081 solver.cpp:218] Iteration 51400 (11.989 iter/s, 8.34098s/100 iters), loss = 0.0173395
I1006 23:51:28.622107  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0173392 (* 1 = 0.0173392 loss)
I1006 23:51:28.622113  4081 sgd_solver.cpp:105] Iteration 51400, lr = 0.01
I1006 23:51:36.550454  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:51:36.885262  4081 solver.cpp:330] Iteration 51500, Testing net (#0)
I1006 23:51:38.816303  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:51:38.897367  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9015
I1006 23:51:38.897403  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.36299 (* 1 = 0.36299 loss)
I1006 23:51:38.980265  4081 solver.cpp:218] Iteration 51500 (9.65424 iter/s, 10.3581s/100 iters), loss = 0.0235157
I1006 23:51:38.980290  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0235154 (* 1 = 0.0235154 loss)
I1006 23:51:38.980296  4081 sgd_solver.cpp:105] Iteration 51500, lr = 0.01
I1006 23:51:47.325595  4081 solver.cpp:218] Iteration 51600 (11.9828 iter/s, 8.34528s/100 iters), loss = 0.0152475
I1006 23:51:47.325716  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0152472 (* 1 = 0.0152472 loss)
I1006 23:51:47.325724  4081 sgd_solver.cpp:105] Iteration 51600, lr = 0.01
I1006 23:51:55.672300  4081 solver.cpp:218] Iteration 51700 (11.981 iter/s, 8.34657s/100 iters), loss = 0.0181896
I1006 23:51:55.672341  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0181893 (* 1 = 0.0181893 loss)
I1006 23:51:55.672348  4081 sgd_solver.cpp:105] Iteration 51700, lr = 0.01
I1006 23:52:04.013633  4081 solver.cpp:218] Iteration 51800 (11.9886 iter/s, 8.34127s/100 iters), loss = 0.0454411
I1006 23:52:04.013674  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0454408 (* 1 = 0.0454408 loss)
I1006 23:52:04.013680  4081 sgd_solver.cpp:105] Iteration 51800, lr = 0.01
I1006 23:52:12.358222  4081 solver.cpp:218] Iteration 51900 (11.9839 iter/s, 8.34452s/100 iters), loss = 0.0104643
I1006 23:52:12.358260  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.010464 (* 1 = 0.010464 loss)
I1006 23:52:12.358268  4081 sgd_solver.cpp:105] Iteration 51900, lr = 0.01
I1006 23:52:20.290246  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:52:20.624825  4081 solver.cpp:330] Iteration 52000, Testing net (#0)
I1006 23:52:22.557579  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:52:22.638262  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9093
I1006 23:52:22.638296  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.333205 (* 1 = 0.333205 loss)
I1006 23:52:22.721524  4081 solver.cpp:218] Iteration 52000 (9.64949 iter/s, 10.3632s/100 iters), loss = 0.0395648
I1006 23:52:22.721549  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0395645 (* 1 = 0.0395645 loss)
I1006 23:52:22.721555  4081 sgd_solver.cpp:105] Iteration 52000, lr = 0.01
I1006 23:52:31.063617  4081 solver.cpp:218] Iteration 52100 (11.9875 iter/s, 8.34205s/100 iters), loss = 0.0275357
I1006 23:52:31.063647  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0275354 (* 1 = 0.0275354 loss)
I1006 23:52:31.063652  4081 sgd_solver.cpp:105] Iteration 52100, lr = 0.01
I1006 23:52:39.402575  4081 solver.cpp:218] Iteration 52200 (11.992 iter/s, 8.33891s/100 iters), loss = 0.015158
I1006 23:52:39.402606  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0151577 (* 1 = 0.0151577 loss)
I1006 23:52:39.402611  4081 sgd_solver.cpp:105] Iteration 52200, lr = 0.01
I1006 23:52:47.748929  4081 solver.cpp:218] Iteration 52300 (11.9814 iter/s, 8.3463s/100 iters), loss = 0.0682795
I1006 23:52:47.748957  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0682792 (* 1 = 0.0682792 loss)
I1006 23:52:47.748973  4081 sgd_solver.cpp:105] Iteration 52300, lr = 0.01
I1006 23:52:56.094622  4081 solver.cpp:218] Iteration 52400 (11.9823 iter/s, 8.34564s/100 iters), loss = 0.0203177
I1006 23:52:56.094777  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0203175 (* 1 = 0.0203175 loss)
I1006 23:52:56.094786  4081 sgd_solver.cpp:105] Iteration 52400, lr = 0.01
I1006 23:53:04.021059  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:53:04.354367  4081 solver.cpp:330] Iteration 52500, Testing net (#0)
I1006 23:53:06.287117  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:53:06.367537  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9122
I1006 23:53:06.367570  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.337184 (* 1 = 0.337184 loss)
I1006 23:53:06.450733  4081 solver.cpp:218] Iteration 52500 (9.6563 iter/s, 10.3559s/100 iters), loss = 0.0459498
I1006 23:53:06.450758  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0459495 (* 1 = 0.0459495 loss)
I1006 23:53:06.450764  4081 sgd_solver.cpp:105] Iteration 52500, lr = 0.01
I1006 23:53:14.795912  4081 solver.cpp:218] Iteration 52600 (11.983 iter/s, 8.34513s/100 iters), loss = 0.00968436
I1006 23:53:14.795953  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00968406 (* 1 = 0.00968406 loss)
I1006 23:53:14.795959  4081 sgd_solver.cpp:105] Iteration 52600, lr = 0.01
I1006 23:53:23.140988  4081 solver.cpp:218] Iteration 52700 (11.9832 iter/s, 8.34501s/100 iters), loss = 0.0341453
I1006 23:53:23.141017  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0341449 (* 1 = 0.0341449 loss)
I1006 23:53:23.141024  4081 sgd_solver.cpp:105] Iteration 52700, lr = 0.01
I1006 23:53:31.485682  4081 solver.cpp:218] Iteration 52800 (11.9837 iter/s, 8.34464s/100 iters), loss = 0.0192919
I1006 23:53:31.485849  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0192916 (* 1 = 0.0192916 loss)
I1006 23:53:31.485868  4081 sgd_solver.cpp:105] Iteration 52800, lr = 0.01
I1006 23:53:39.834673  4081 solver.cpp:218] Iteration 52900 (11.9778 iter/s, 8.34881s/100 iters), loss = 0.0162582
I1006 23:53:39.834713  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0162578 (* 1 = 0.0162578 loss)
I1006 23:53:39.834719  4081 sgd_solver.cpp:105] Iteration 52900, lr = 0.01
I1006 23:53:47.766435  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:53:48.099777  4081 solver.cpp:330] Iteration 53000, Testing net (#0)
I1006 23:53:50.032940  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:53:50.113611  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9138
I1006 23:53:50.113636  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.336048 (* 1 = 0.336048 loss)
I1006 23:53:50.197669  4081 solver.cpp:218] Iteration 53000 (9.64978 iter/s, 10.3629s/100 iters), loss = 0.0110738
I1006 23:53:50.197692  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0110735 (* 1 = 0.0110735 loss)
I1006 23:53:50.197700  4081 sgd_solver.cpp:105] Iteration 53000, lr = 0.01
I1006 23:53:58.543073  4081 solver.cpp:218] Iteration 53100 (11.9827 iter/s, 8.34536s/100 iters), loss = 0.0768487
I1006 23:53:58.543103  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0768484 (* 1 = 0.0768484 loss)
I1006 23:53:58.543120  4081 sgd_solver.cpp:105] Iteration 53100, lr = 0.01
I1006 23:54:06.889525  4081 solver.cpp:218] Iteration 53200 (11.9812 iter/s, 8.3464s/100 iters), loss = 0.0194641
I1006 23:54:06.889644  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0194638 (* 1 = 0.0194638 loss)
I1006 23:54:06.889667  4081 sgd_solver.cpp:105] Iteration 53200, lr = 0.01
I1006 23:54:15.232942  4081 solver.cpp:218] Iteration 53300 (11.9857 iter/s, 8.34328s/100 iters), loss = 0.0335726
I1006 23:54:15.232983  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0335723 (* 1 = 0.0335723 loss)
I1006 23:54:15.232990  4081 sgd_solver.cpp:105] Iteration 53300, lr = 0.01
I1006 23:54:23.576194  4081 solver.cpp:218] Iteration 53400 (11.9858 iter/s, 8.34319s/100 iters), loss = 0.0399386
I1006 23:54:23.576223  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0399383 (* 1 = 0.0399383 loss)
I1006 23:54:23.576241  4081 sgd_solver.cpp:105] Iteration 53400, lr = 0.01
I1006 23:54:31.499707  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:54:31.835170  4081 solver.cpp:330] Iteration 53500, Testing net (#0)
I1006 23:54:33.766834  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:54:33.847206  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9116
I1006 23:54:33.847242  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.335415 (* 1 = 0.335415 loss)
I1006 23:54:33.930584  4081 solver.cpp:218] Iteration 53500 (9.65779 iter/s, 10.3543s/100 iters), loss = 0.00427306
I1006 23:54:33.930610  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00427275 (* 1 = 0.00427275 loss)
I1006 23:54:33.930618  4081 sgd_solver.cpp:105] Iteration 53500, lr = 0.01
I1006 23:54:42.276597  4081 solver.cpp:218] Iteration 53600 (11.9818 iter/s, 8.34596s/100 iters), loss = 0.0101553
I1006 23:54:42.276777  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0101549 (* 1 = 0.0101549 loss)
I1006 23:54:42.276787  4081 sgd_solver.cpp:105] Iteration 53600, lr = 0.01
I1006 23:54:50.619264  4081 solver.cpp:218] Iteration 53700 (11.9868 iter/s, 8.34249s/100 iters), loss = 0.0278597
I1006 23:54:50.619305  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0278594 (* 1 = 0.0278594 loss)
I1006 23:54:50.619312  4081 sgd_solver.cpp:105] Iteration 53700, lr = 0.01
I1006 23:54:58.965471  4081 solver.cpp:218] Iteration 53800 (11.9816 iter/s, 8.34614s/100 iters), loss = 0.028877
I1006 23:54:58.965498  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0288767 (* 1 = 0.0288767 loss)
I1006 23:54:58.965505  4081 sgd_solver.cpp:105] Iteration 53800, lr = 0.01
I1006 23:55:07.316557  4081 solver.cpp:218] Iteration 53900 (11.9746 iter/s, 8.35104s/100 iters), loss = 0.017684
I1006 23:55:07.316587  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0176837 (* 1 = 0.0176837 loss)
I1006 23:55:07.316594  4081 sgd_solver.cpp:105] Iteration 53900, lr = 0.01
I1006 23:55:15.243930  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:55:15.577525  4081 solver.cpp:330] Iteration 54000, Testing net (#0)
I1006 23:55:17.508927  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:55:17.589592  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9072
I1006 23:55:17.589628  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.352578 (* 1 = 0.352578 loss)
I1006 23:55:17.672583  4081 solver.cpp:218] Iteration 54000 (9.65627 iter/s, 10.356s/100 iters), loss = 0.0224581
I1006 23:55:17.672610  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0224578 (* 1 = 0.0224578 loss)
I1006 23:55:17.672616  4081 sgd_solver.cpp:105] Iteration 54000, lr = 0.01
I1006 23:55:26.016155  4081 solver.cpp:218] Iteration 54100 (11.9853 iter/s, 8.34352s/100 iters), loss = 0.0206825
I1006 23:55:26.016196  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0206822 (* 1 = 0.0206822 loss)
I1006 23:55:26.016201  4081 sgd_solver.cpp:105] Iteration 54100, lr = 0.01
I1006 23:55:34.354096  4081 solver.cpp:218] Iteration 54200 (11.9935 iter/s, 8.33788s/100 iters), loss = 0.0110035
I1006 23:55:34.354126  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0110032 (* 1 = 0.0110032 loss)
I1006 23:55:34.354133  4081 sgd_solver.cpp:105] Iteration 54200, lr = 0.01
I1006 23:55:42.701050  4081 solver.cpp:218] Iteration 54300 (11.9805 iter/s, 8.3469s/100 iters), loss = 0.00776128
I1006 23:55:42.701081  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00776096 (* 1 = 0.00776096 loss)
I1006 23:55:42.701086  4081 sgd_solver.cpp:105] Iteration 54300, lr = 0.01
I1006 23:55:51.040036  4081 solver.cpp:218] Iteration 54400 (11.9919 iter/s, 8.33893s/100 iters), loss = 0.0169522
I1006 23:55:51.040146  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0169518 (* 1 = 0.0169518 loss)
I1006 23:55:51.040164  4081 sgd_solver.cpp:105] Iteration 54400, lr = 0.01
I1006 23:55:58.972414  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:55:59.305687  4081 solver.cpp:330] Iteration 54500, Testing net (#0)
I1006 23:56:01.236125  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:56:01.317024  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9036
I1006 23:56:01.317060  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.363351 (* 1 = 0.363351 loss)
I1006 23:56:01.400240  4081 solver.cpp:218] Iteration 54500 (9.65244 iter/s, 10.3601s/100 iters), loss = 0.0141982
I1006 23:56:01.400264  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0141979 (* 1 = 0.0141979 loss)
I1006 23:56:01.400271  4081 sgd_solver.cpp:105] Iteration 54500, lr = 0.01
I1006 23:56:09.752564  4081 solver.cpp:218] Iteration 54600 (11.9728 iter/s, 8.35228s/100 iters), loss = 0.00360032
I1006 23:56:09.752595  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0036 (* 1 = 0.0036 loss)
I1006 23:56:09.752602  4081 sgd_solver.cpp:105] Iteration 54600, lr = 0.01
I1006 23:56:18.106030  4081 solver.cpp:218] Iteration 54700 (11.9712 iter/s, 8.35341s/100 iters), loss = 0.0161385
I1006 23:56:18.106070  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0161382 (* 1 = 0.0161382 loss)
I1006 23:56:18.106076  4081 sgd_solver.cpp:105] Iteration 54700, lr = 0.01
I1006 23:56:26.457170  4081 solver.cpp:218] Iteration 54800 (11.9745 iter/s, 8.35108s/100 iters), loss = 0.00397195
I1006 23:56:26.457310  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00397163 (* 1 = 0.00397163 loss)
I1006 23:56:26.457319  4081 sgd_solver.cpp:105] Iteration 54800, lr = 0.01
I1006 23:56:34.814432  4081 solver.cpp:218] Iteration 54900 (11.9659 iter/s, 8.3571s/100 iters), loss = 0.00347739
I1006 23:56:34.814460  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00347708 (* 1 = 0.00347708 loss)
I1006 23:56:34.814466  4081 sgd_solver.cpp:105] Iteration 54900, lr = 0.01
I1006 23:56:42.752670  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:56:43.086601  4081 solver.cpp:330] Iteration 55000, Testing net (#0)
I1006 23:56:45.016304  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:56:45.097244  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9047
I1006 23:56:45.097278  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.35188 (* 1 = 0.35188 loss)
I1006 23:56:45.180845  4081 solver.cpp:218] Iteration 55000 (9.64659 iter/s, 10.3664s/100 iters), loss = 0.00658927
I1006 23:56:45.180869  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00658896 (* 1 = 0.00658896 loss)
I1006 23:56:45.180877  4081 sgd_solver.cpp:105] Iteration 55000, lr = 0.01
I1006 23:56:53.530661  4081 solver.cpp:218] Iteration 55100 (11.9764 iter/s, 8.34977s/100 iters), loss = 0.0388248
I1006 23:56:53.530702  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0388245 (* 1 = 0.0388245 loss)
I1006 23:56:53.530709  4081 sgd_solver.cpp:105] Iteration 55100, lr = 0.01
I1006 23:57:01.883249  4081 solver.cpp:218] Iteration 55200 (11.9724 iter/s, 8.35253s/100 iters), loss = 0.0248694
I1006 23:57:01.883368  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0248691 (* 1 = 0.0248691 loss)
I1006 23:57:01.883385  4081 sgd_solver.cpp:105] Iteration 55200, lr = 0.01
I1006 23:57:10.235726  4081 solver.cpp:218] Iteration 55300 (11.9727 iter/s, 8.35234s/100 iters), loss = 0.0459375
I1006 23:57:10.235767  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0459372 (* 1 = 0.0459372 loss)
I1006 23:57:10.235774  4081 sgd_solver.cpp:105] Iteration 55300, lr = 0.01
I1006 23:57:18.583961  4081 solver.cpp:218] Iteration 55400 (11.9787 iter/s, 8.34817s/100 iters), loss = 0.0112998
I1006 23:57:18.584000  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0112995 (* 1 = 0.0112995 loss)
I1006 23:57:18.584007  4081 sgd_solver.cpp:105] Iteration 55400, lr = 0.01
I1006 23:57:26.516660  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:57:26.850941  4081 solver.cpp:330] Iteration 55500, Testing net (#0)
I1006 23:57:28.784832  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:57:28.865319  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9136
I1006 23:57:28.865355  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.346961 (* 1 = 0.346961 loss)
I1006 23:57:28.948596  4081 solver.cpp:218] Iteration 55500 (9.64825 iter/s, 10.3646s/100 iters), loss = 0.016255
I1006 23:57:28.948621  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0162547 (* 1 = 0.0162547 loss)
I1006 23:57:28.948626  4081 sgd_solver.cpp:105] Iteration 55500, lr = 0.01
I1006 23:57:37.305028  4081 solver.cpp:218] Iteration 55600 (11.9669 iter/s, 8.35638s/100 iters), loss = 0.00662797
I1006 23:57:37.305187  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00662764 (* 1 = 0.00662764 loss)
I1006 23:57:37.305207  4081 sgd_solver.cpp:105] Iteration 55600, lr = 0.01
I1006 23:57:45.659739  4081 solver.cpp:218] Iteration 55700 (11.9695 iter/s, 8.35454s/100 iters), loss = 0.00631284
I1006 23:57:45.659778  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00631253 (* 1 = 0.00631253 loss)
I1006 23:57:45.659785  4081 sgd_solver.cpp:105] Iteration 55700, lr = 0.01
I1006 23:57:54.013160  4081 solver.cpp:218] Iteration 55800 (11.9712 iter/s, 8.35336s/100 iters), loss = 0.0112653
I1006 23:57:54.013191  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.011265 (* 1 = 0.011265 loss)
I1006 23:57:54.013198  4081 sgd_solver.cpp:105] Iteration 55800, lr = 0.01
I1006 23:58:02.360401  4081 solver.cpp:218] Iteration 55900 (11.9801 iter/s, 8.34719s/100 iters), loss = 0.0121923
I1006 23:58:02.360431  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.012192 (* 1 = 0.012192 loss)
I1006 23:58:02.360437  4081 sgd_solver.cpp:105] Iteration 55900, lr = 0.01
I1006 23:58:10.297752  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:58:10.633110  4081 solver.cpp:330] Iteration 56000, Testing net (#0)
I1006 23:58:12.566684  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:58:12.647168  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.906
I1006 23:58:12.647203  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.37216 (* 1 = 0.37216 loss)
I1006 23:58:12.730633  4081 solver.cpp:218] Iteration 56000 (9.64304 iter/s, 10.3702s/100 iters), loss = 0.0118384
I1006 23:58:12.730657  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0118381 (* 1 = 0.0118381 loss)
I1006 23:58:12.730664  4081 sgd_solver.cpp:105] Iteration 56000, lr = 0.01
I1006 23:58:21.077157  4081 solver.cpp:218] Iteration 56100 (11.9811 iter/s, 8.34648s/100 iters), loss = 0.0119784
I1006 23:58:21.077188  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0119781 (* 1 = 0.0119781 loss)
I1006 23:58:21.077193  4081 sgd_solver.cpp:105] Iteration 56100, lr = 0.01
I1006 23:58:29.426539  4081 solver.cpp:218] Iteration 56200 (11.977 iter/s, 8.34933s/100 iters), loss = 0.00771734
I1006 23:58:29.426573  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00771703 (* 1 = 0.00771703 loss)
I1006 23:58:29.426579  4081 sgd_solver.cpp:105] Iteration 56200, lr = 0.01
I1006 23:58:37.769659  4081 solver.cpp:218] Iteration 56300 (11.986 iter/s, 8.34306s/100 iters), loss = 0.0067738
I1006 23:58:37.769700  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00677348 (* 1 = 0.00677348 loss)
I1006 23:58:37.769706  4081 sgd_solver.cpp:105] Iteration 56300, lr = 0.01
I1006 23:58:46.117341  4081 solver.cpp:218] Iteration 56400 (11.9795 iter/s, 8.34762s/100 iters), loss = 0.0371585
I1006 23:58:46.117452  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0371582 (* 1 = 0.0371582 loss)
I1006 23:58:46.117470  4081 sgd_solver.cpp:105] Iteration 56400, lr = 0.01
I1006 23:58:54.048142  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:58:54.382925  4081 solver.cpp:330] Iteration 56500, Testing net (#0)
I1006 23:58:56.314609  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:58:56.395527  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9077
I1006 23:58:56.395562  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.365955 (* 1 = 0.365955 loss)
I1006 23:58:56.478989  4081 solver.cpp:218] Iteration 56500 (9.65109 iter/s, 10.3615s/100 iters), loss = 0.0326996
I1006 23:58:56.479015  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0326993 (* 1 = 0.0326993 loss)
I1006 23:58:56.479022  4081 sgd_solver.cpp:105] Iteration 56500, lr = 0.01
I1006 23:59:04.820367  4081 solver.cpp:218] Iteration 56600 (11.9885 iter/s, 8.34133s/100 iters), loss = 0.0104516
I1006 23:59:04.820407  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0104513 (* 1 = 0.0104513 loss)
I1006 23:59:04.820415  4081 sgd_solver.cpp:105] Iteration 56600, lr = 0.01
I1006 23:59:13.167884  4081 solver.cpp:218] Iteration 56700 (11.9797 iter/s, 8.34745s/100 iters), loss = 0.021578
I1006 23:59:13.167914  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0215777 (* 1 = 0.0215777 loss)
I1006 23:59:13.167920  4081 sgd_solver.cpp:105] Iteration 56700, lr = 0.01
I1006 23:59:21.513731  4081 solver.cpp:218] Iteration 56800 (11.9821 iter/s, 8.34579s/100 iters), loss = 0.0234479
I1006 23:59:21.513852  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0234476 (* 1 = 0.0234476 loss)
I1006 23:59:21.513859  4081 sgd_solver.cpp:105] Iteration 56800, lr = 0.01
I1006 23:59:29.864701  4081 solver.cpp:218] Iteration 56900 (11.9749 iter/s, 8.35083s/100 iters), loss = 0.0210146
I1006 23:59:29.864743  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0210143 (* 1 = 0.0210143 loss)
I1006 23:59:29.864750  4081 sgd_solver.cpp:105] Iteration 56900, lr = 0.01
I1006 23:59:37.792718  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:59:38.127149  4081 solver.cpp:330] Iteration 57000, Testing net (#0)
I1006 23:59:40.059140  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1006 23:59:40.139859  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9109
I1006 23:59:40.139894  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.353554 (* 1 = 0.353554 loss)
I1006 23:59:40.223459  4081 solver.cpp:218] Iteration 57000 (9.65373 iter/s, 10.3587s/100 iters), loss = 0.01542
I1006 23:59:40.223484  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0154196 (* 1 = 0.0154196 loss)
I1006 23:59:40.223491  4081 sgd_solver.cpp:105] Iteration 57000, lr = 0.01
I1006 23:59:48.562244  4081 solver.cpp:218] Iteration 57100 (11.9922 iter/s, 8.33874s/100 iters), loss = 0.0131756
I1006 23:59:48.562285  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0131753 (* 1 = 0.0131753 loss)
I1006 23:59:48.562292  4081 sgd_solver.cpp:105] Iteration 57100, lr = 0.01
I1006 23:59:56.909138  4081 solver.cpp:218] Iteration 57200 (11.9806 iter/s, 8.34683s/100 iters), loss = 0.0303511
I1006 23:59:56.909215  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0303507 (* 1 = 0.0303507 loss)
I1006 23:59:56.909224  4081 sgd_solver.cpp:105] Iteration 57200, lr = 0.01
I1007 00:00:05.259363  4081 solver.cpp:218] Iteration 57300 (11.9759 iter/s, 8.35013s/100 iters), loss = 0.00796834
I1007 00:00:05.259394  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00796801 (* 1 = 0.00796801 loss)
I1007 00:00:05.259400  4081 sgd_solver.cpp:105] Iteration 57300, lr = 0.01
I1007 00:00:13.608453  4081 solver.cpp:218] Iteration 57400 (11.9774 iter/s, 8.34904s/100 iters), loss = 0.0036779
I1007 00:00:13.608484  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00367757 (* 1 = 0.00367757 loss)
I1007 00:00:13.608491  4081 sgd_solver.cpp:105] Iteration 57400, lr = 0.01
I1007 00:00:21.536949  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:00:21.871222  4081 solver.cpp:330] Iteration 57500, Testing net (#0)
I1007 00:00:23.805816  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:00:23.886749  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9043
I1007 00:00:23.886785  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.391893 (* 1 = 0.391893 loss)
I1007 00:00:23.970026  4081 solver.cpp:218] Iteration 57500 (9.6511 iter/s, 10.3615s/100 iters), loss = 0.00466948
I1007 00:00:23.970049  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00466916 (* 1 = 0.00466916 loss)
I1007 00:00:23.970057  4081 sgd_solver.cpp:105] Iteration 57500, lr = 0.01
I1007 00:00:32.320513  4081 solver.cpp:218] Iteration 57600 (11.9754 iter/s, 8.35044s/100 iters), loss = 0.0088888
I1007 00:00:32.320606  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00888848 (* 1 = 0.00888848 loss)
I1007 00:00:32.320614  4081 sgd_solver.cpp:105] Iteration 57600, lr = 0.01
I1007 00:00:40.672000  4081 solver.cpp:218] Iteration 57700 (11.9741 iter/s, 8.35137s/100 iters), loss = 0.0186985
I1007 00:00:40.672040  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0186981 (* 1 = 0.0186981 loss)
I1007 00:00:40.672047  4081 sgd_solver.cpp:105] Iteration 57700, lr = 0.01
I1007 00:00:49.024544  4081 solver.cpp:218] Iteration 57800 (11.9725 iter/s, 8.35248s/100 iters), loss = 0.00670987
I1007 00:00:49.024585  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00670954 (* 1 = 0.00670954 loss)
I1007 00:00:49.024592  4081 sgd_solver.cpp:105] Iteration 57800, lr = 0.01
I1007 00:00:57.381840  4081 solver.cpp:218] Iteration 57900 (11.9657 iter/s, 8.35723s/100 iters), loss = 0.00891828
I1007 00:00:57.381884  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00891794 (* 1 = 0.00891794 loss)
I1007 00:00:57.381891  4081 sgd_solver.cpp:105] Iteration 57900, lr = 0.01
I1007 00:01:05.326795  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:01:05.661321  4081 solver.cpp:330] Iteration 58000, Testing net (#0)
I1007 00:01:07.593804  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:01:07.675694  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9086
I1007 00:01:07.675729  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.362521 (* 1 = 0.362521 loss)
I1007 00:01:07.758708  4081 solver.cpp:218] Iteration 58000 (9.63691 iter/s, 10.3768s/100 iters), loss = 0.0100897
I1007 00:01:07.758730  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0100894 (* 1 = 0.0100894 loss)
I1007 00:01:07.758738  4081 sgd_solver.cpp:105] Iteration 58000, lr = 0.01
I1007 00:01:16.104398  4081 solver.cpp:218] Iteration 58100 (11.9823 iter/s, 8.34564s/100 iters), loss = 0.0128328
I1007 00:01:16.104439  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0128325 (* 1 = 0.0128325 loss)
I1007 00:01:16.104445  4081 sgd_solver.cpp:105] Iteration 58100, lr = 0.01
I1007 00:01:24.450937  4081 solver.cpp:218] Iteration 58200 (11.9811 iter/s, 8.34647s/100 iters), loss = 0.0653897
I1007 00:01:24.450966  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0653894 (* 1 = 0.0653894 loss)
I1007 00:01:24.450973  4081 sgd_solver.cpp:105] Iteration 58200, lr = 0.01
I1007 00:01:32.791450  4081 solver.cpp:218] Iteration 58300 (11.9897 iter/s, 8.34046s/100 iters), loss = 0.00645312
I1007 00:01:32.791491  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00645279 (* 1 = 0.00645279 loss)
I1007 00:01:32.791496  4081 sgd_solver.cpp:105] Iteration 58300, lr = 0.01
I1007 00:01:41.130867  4081 solver.cpp:218] Iteration 58400 (11.9913 iter/s, 8.33935s/100 iters), loss = 0.0125321
I1007 00:01:41.130990  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0125318 (* 1 = 0.0125318 loss)
I1007 00:01:41.131009  4081 sgd_solver.cpp:105] Iteration 58400, lr = 0.01
I1007 00:01:49.058431  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:01:49.392508  4081 solver.cpp:330] Iteration 58500, Testing net (#0)
I1007 00:01:51.323703  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:01:51.404239  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9098
I1007 00:01:51.404264  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.35725 (* 1 = 0.35725 loss)
I1007 00:01:51.488147  4081 solver.cpp:218] Iteration 58500 (9.65518 iter/s, 10.3571s/100 iters), loss = 0.0104683
I1007 00:01:51.488173  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.010468 (* 1 = 0.010468 loss)
I1007 00:01:51.488181  4081 sgd_solver.cpp:105] Iteration 58500, lr = 0.01
I1007 00:01:59.843787  4081 solver.cpp:218] Iteration 58600 (11.968 iter/s, 8.35559s/100 iters), loss = 0.030064
I1007 00:01:59.843818  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0300636 (* 1 = 0.0300636 loss)
I1007 00:01:59.843834  4081 sgd_solver.cpp:105] Iteration 58600, lr = 0.01
I1007 00:02:08.193265  4081 solver.cpp:218] Iteration 58700 (11.9769 iter/s, 8.34942s/100 iters), loss = 0.00585263
I1007 00:02:08.193295  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0058523 (* 1 = 0.0058523 loss)
I1007 00:02:08.193302  4081 sgd_solver.cpp:105] Iteration 58700, lr = 0.01
I1007 00:02:16.539139  4081 solver.cpp:218] Iteration 58800 (11.982 iter/s, 8.34582s/100 iters), loss = 0.0150597
I1007 00:02:16.539305  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0150594 (* 1 = 0.0150594 loss)
I1007 00:02:16.539314  4081 sgd_solver.cpp:105] Iteration 58800, lr = 0.01
I1007 00:02:24.889767  4081 solver.cpp:218] Iteration 58900 (11.9754 iter/s, 8.35044s/100 iters), loss = 0.00372464
I1007 00:02:24.889799  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0037243 (* 1 = 0.0037243 loss)
I1007 00:02:24.889806  4081 sgd_solver.cpp:105] Iteration 58900, lr = 0.01
I1007 00:02:32.825451  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:02:33.161175  4081 solver.cpp:330] Iteration 59000, Testing net (#0)
I1007 00:02:35.093256  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:02:35.174190  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.903
I1007 00:02:35.174216  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.396499 (* 1 = 0.396499 loss)
I1007 00:02:35.257686  4081 solver.cpp:218] Iteration 59000 (9.64519 iter/s, 10.3679s/100 iters), loss = 0.00326407
I1007 00:02:35.257716  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00326373 (* 1 = 0.00326373 loss)
I1007 00:02:35.257724  4081 sgd_solver.cpp:105] Iteration 59000, lr = 0.01
I1007 00:02:43.604830  4081 solver.cpp:218] Iteration 59100 (11.9802 iter/s, 8.34709s/100 iters), loss = 0.00761969
I1007 00:02:43.604861  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00761936 (* 1 = 0.00761936 loss)
I1007 00:02:43.604877  4081 sgd_solver.cpp:105] Iteration 59100, lr = 0.01
I1007 00:02:51.946193  4081 solver.cpp:218] Iteration 59200 (11.9885 iter/s, 8.34131s/100 iters), loss = 0.0035726
I1007 00:02:51.946339  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00357227 (* 1 = 0.00357227 loss)
I1007 00:02:51.946347  4081 sgd_solver.cpp:105] Iteration 59200, lr = 0.01
I1007 00:03:00.289281  4081 solver.cpp:218] Iteration 59300 (11.9862 iter/s, 8.34293s/100 iters), loss = 0.0184537
I1007 00:03:00.289314  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0184534 (* 1 = 0.0184534 loss)
I1007 00:03:00.289319  4081 sgd_solver.cpp:105] Iteration 59300, lr = 0.01
I1007 00:03:08.636435  4081 solver.cpp:218] Iteration 59400 (11.9802 iter/s, 8.3471s/100 iters), loss = 0.0175875
I1007 00:03:08.636466  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0175872 (* 1 = 0.0175872 loss)
I1007 00:03:08.636471  4081 sgd_solver.cpp:105] Iteration 59400, lr = 0.01
I1007 00:03:16.564918  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:03:16.899202  4081 solver.cpp:330] Iteration 59500, Testing net (#0)
I1007 00:03:18.830634  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:03:18.911602  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9061
I1007 00:03:18.911629  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.375651 (* 1 = 0.375651 loss)
I1007 00:03:18.995288  4081 solver.cpp:218] Iteration 59500 (9.65363 iter/s, 10.3588s/100 iters), loss = 0.00301779
I1007 00:03:18.995312  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00301746 (* 1 = 0.00301746 loss)
I1007 00:03:18.995318  4081 sgd_solver.cpp:105] Iteration 59500, lr = 0.01
I1007 00:03:27.334982  4081 solver.cpp:218] Iteration 59600 (11.9909 iter/s, 8.33965s/100 iters), loss = 0.0243397
I1007 00:03:27.335101  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0243393 (* 1 = 0.0243393 loss)
I1007 00:03:27.335117  4081 sgd_solver.cpp:105] Iteration 59600, lr = 0.01
I1007 00:03:35.670725  4081 solver.cpp:218] Iteration 59700 (11.9967 iter/s, 8.3356s/100 iters), loss = 0.0525984
I1007 00:03:35.670756  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0525981 (* 1 = 0.0525981 loss)
I1007 00:03:35.670763  4081 sgd_solver.cpp:105] Iteration 59700, lr = 0.01
I1007 00:03:44.013402  4081 solver.cpp:218] Iteration 59800 (11.9866 iter/s, 8.34262s/100 iters), loss = 0.00636501
I1007 00:03:44.013440  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00636467 (* 1 = 0.00636467 loss)
I1007 00:03:44.013448  4081 sgd_solver.cpp:105] Iteration 59800, lr = 0.01
I1007 00:03:52.350100  4081 solver.cpp:218] Iteration 59900 (11.9952 iter/s, 8.33664s/100 iters), loss = 0.00381406
I1007 00:03:52.350133  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00381373 (* 1 = 0.00381373 loss)
I1007 00:03:52.350142  4081 sgd_solver.cpp:105] Iteration 59900, lr = 0.01
I1007 00:04:00.277179  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:04:00.609863  4081 solver.cpp:330] Iteration 60000, Testing net (#0)
I1007 00:04:02.539847  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:04:02.620631  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9081
I1007 00:04:02.620658  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.390405 (* 1 = 0.390405 loss)
I1007 00:04:02.703888  4081 solver.cpp:218] Iteration 60000 (9.65835 iter/s, 10.3537s/100 iters), loss = 0.00375967
I1007 00:04:02.703915  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00375934 (* 1 = 0.00375934 loss)
I1007 00:04:02.703925  4081 sgd_solver.cpp:105] Iteration 60000, lr = 0.01
I1007 00:04:11.056077  4081 solver.cpp:218] Iteration 60100 (11.973 iter/s, 8.35214s/100 iters), loss = 0.00244019
I1007 00:04:11.056109  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00243986 (* 1 = 0.00243986 loss)
I1007 00:04:11.056118  4081 sgd_solver.cpp:105] Iteration 60100, lr = 0.01
I1007 00:04:19.399294  4081 solver.cpp:218] Iteration 60200 (11.9859 iter/s, 8.34316s/100 iters), loss = 0.0132482
I1007 00:04:19.399327  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0132479 (* 1 = 0.0132479 loss)
I1007 00:04:19.399335  4081 sgd_solver.cpp:105] Iteration 60200, lr = 0.01
I1007 00:04:27.742377  4081 solver.cpp:218] Iteration 60300 (11.9861 iter/s, 8.34303s/100 iters), loss = 0.0565283
I1007 00:04:27.742410  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.056528 (* 1 = 0.056528 loss)
I1007 00:04:27.742429  4081 sgd_solver.cpp:105] Iteration 60300, lr = 0.01
I1007 00:04:36.079933  4081 solver.cpp:218] Iteration 60400 (11.994 iter/s, 8.3375s/100 iters), loss = 0.0058723
I1007 00:04:36.080072  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00587197 (* 1 = 0.00587197 loss)
I1007 00:04:36.080080  4081 sgd_solver.cpp:105] Iteration 60400, lr = 0.01
I1007 00:04:44.007230  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:04:44.341935  4081 solver.cpp:330] Iteration 60500, Testing net (#0)
I1007 00:04:46.271368  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:04:46.352475  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9108
I1007 00:04:46.352511  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.378708 (* 1 = 0.378708 loss)
I1007 00:04:46.435963  4081 solver.cpp:218] Iteration 60500 (9.65636 iter/s, 10.3559s/100 iters), loss = 0.00473904
I1007 00:04:46.435988  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00473872 (* 1 = 0.00473872 loss)
I1007 00:04:46.435995  4081 sgd_solver.cpp:105] Iteration 60500, lr = 0.01
I1007 00:04:54.782572  4081 solver.cpp:218] Iteration 60600 (11.981 iter/s, 8.34656s/100 iters), loss = 0.00477026
I1007 00:04:54.782611  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00476993 (* 1 = 0.00476993 loss)
I1007 00:04:54.782618  4081 sgd_solver.cpp:105] Iteration 60600, lr = 0.01
I1007 00:05:03.131572  4081 solver.cpp:218] Iteration 60700 (11.9776 iter/s, 8.34894s/100 iters), loss = 0.00421861
I1007 00:05:03.131603  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00421828 (* 1 = 0.00421828 loss)
I1007 00:05:03.131609  4081 sgd_solver.cpp:105] Iteration 60700, lr = 0.01
I1007 00:05:11.482553  4081 solver.cpp:218] Iteration 60800 (11.9747 iter/s, 8.35093s/100 iters), loss = 0.006006
I1007 00:05:11.482698  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00600566 (* 1 = 0.00600566 loss)
I1007 00:05:11.482717  4081 sgd_solver.cpp:105] Iteration 60800, lr = 0.01
I1007 00:05:19.829409  4081 solver.cpp:218] Iteration 60900 (11.9808 iter/s, 8.34669s/100 iters), loss = 0.00365636
I1007 00:05:19.829442  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00365602 (* 1 = 0.00365602 loss)
I1007 00:05:19.829448  4081 sgd_solver.cpp:105] Iteration 60900, lr = 0.01
I1007 00:05:27.770364  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:05:28.104233  4081 solver.cpp:330] Iteration 61000, Testing net (#0)
I1007 00:05:30.034323  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:05:30.115326  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9148
I1007 00:05:30.115365  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.34103 (* 1 = 0.34103 loss)
I1007 00:05:30.198585  4081 solver.cpp:218] Iteration 61000 (9.64402 iter/s, 10.3691s/100 iters), loss = 0.0125191
I1007 00:05:30.198612  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0125187 (* 1 = 0.0125187 loss)
I1007 00:05:30.198619  4081 sgd_solver.cpp:105] Iteration 61000, lr = 0.01
I1007 00:05:38.535223  4081 solver.cpp:218] Iteration 61100 (11.9953 iter/s, 8.33659s/100 iters), loss = 0.00731654
I1007 00:05:38.535253  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0073162 (* 1 = 0.0073162 loss)
I1007 00:05:38.535259  4081 sgd_solver.cpp:105] Iteration 61100, lr = 0.01
I1007 00:05:46.871711  4081 solver.cpp:218] Iteration 61200 (11.9955 iter/s, 8.33644s/100 iters), loss = 0.0122818
I1007 00:05:46.871827  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0122814 (* 1 = 0.0122814 loss)
I1007 00:05:46.871845  4081 sgd_solver.cpp:105] Iteration 61200, lr = 0.01
I1007 00:05:55.215530  4081 solver.cpp:218] Iteration 61300 (11.9851 iter/s, 8.34369s/100 iters), loss = 0.0085128
I1007 00:05:55.215561  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00851246 (* 1 = 0.00851246 loss)
I1007 00:05:55.215577  4081 sgd_solver.cpp:105] Iteration 61300, lr = 0.01
I1007 00:06:03.559015  4081 solver.cpp:218] Iteration 61400 (11.9855 iter/s, 8.34343s/100 iters), loss = 0.000935121
I1007 00:06:03.559044  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000934774 (* 1 = 0.000934774 loss)
I1007 00:06:03.559051  4081 sgd_solver.cpp:105] Iteration 61400, lr = 0.01
I1007 00:06:11.484820  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:06:11.819649  4081 solver.cpp:330] Iteration 61500, Testing net (#0)
I1007 00:06:13.752782  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:06:13.833706  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9084
I1007 00:06:13.833741  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.382432 (* 1 = 0.382432 loss)
I1007 00:06:13.917501  4081 solver.cpp:218] Iteration 61500 (9.65397 iter/s, 10.3584s/100 iters), loss = 0.0272912
I1007 00:06:13.917527  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0272908 (* 1 = 0.0272908 loss)
I1007 00:06:13.917533  4081 sgd_solver.cpp:105] Iteration 61500, lr = 0.01
I1007 00:06:22.257992  4081 solver.cpp:218] Iteration 61600 (11.9898 iter/s, 8.34044s/100 iters), loss = 0.00490019
I1007 00:06:22.258126  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00489986 (* 1 = 0.00489986 loss)
I1007 00:06:22.258134  4081 sgd_solver.cpp:105] Iteration 61600, lr = 0.01
I1007 00:06:30.605442  4081 solver.cpp:218] Iteration 61700 (11.9799 iter/s, 8.34729s/100 iters), loss = 0.0103602
I1007 00:06:30.605473  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0103599 (* 1 = 0.0103599 loss)
I1007 00:06:30.605479  4081 sgd_solver.cpp:105] Iteration 61700, lr = 0.01
I1007 00:06:38.954777  4081 solver.cpp:218] Iteration 61800 (11.9771 iter/s, 8.34928s/100 iters), loss = 0.00585856
I1007 00:06:38.954808  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00585822 (* 1 = 0.00585822 loss)
I1007 00:06:38.954824  4081 sgd_solver.cpp:105] Iteration 61800, lr = 0.01
I1007 00:06:47.299898  4081 solver.cpp:218] Iteration 61900 (11.9831 iter/s, 8.34506s/100 iters), loss = 0.00970281
I1007 00:06:47.299928  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00970247 (* 1 = 0.00970247 loss)
I1007 00:06:47.299934  4081 sgd_solver.cpp:105] Iteration 61900, lr = 0.01
I1007 00:06:55.233075  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:06:55.567852  4081 solver.cpp:330] Iteration 62000, Testing net (#0)
I1007 00:06:57.499964  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:06:57.580430  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9114
I1007 00:06:57.580466  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.37946 (* 1 = 0.37946 loss)
I1007 00:06:57.664590  4081 solver.cpp:218] Iteration 62000 (9.64819 iter/s, 10.3646s/100 iters), loss = 0.00381799
I1007 00:06:57.664618  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00381766 (* 1 = 0.00381766 loss)
I1007 00:06:57.664624  4081 sgd_solver.cpp:105] Iteration 62000, lr = 0.01
I1007 00:07:06.006652  4081 solver.cpp:218] Iteration 62100 (11.9875 iter/s, 8.34201s/100 iters), loss = 0.00519651
I1007 00:07:06.006693  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00519619 (* 1 = 0.00519619 loss)
I1007 00:07:06.006700  4081 sgd_solver.cpp:105] Iteration 62100, lr = 0.01
I1007 00:07:14.351547  4081 solver.cpp:218] Iteration 62200 (11.9835 iter/s, 8.34483s/100 iters), loss = 0.0280515
I1007 00:07:14.351588  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0280512 (* 1 = 0.0280512 loss)
I1007 00:07:14.351594  4081 sgd_solver.cpp:105] Iteration 62200, lr = 0.01
I1007 00:07:22.701786  4081 solver.cpp:218] Iteration 62300 (11.9758 iter/s, 8.35017s/100 iters), loss = 0.0277634
I1007 00:07:22.701817  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0277631 (* 1 = 0.0277631 loss)
I1007 00:07:22.701824  4081 sgd_solver.cpp:105] Iteration 62300, lr = 0.01
I1007 00:07:31.045900  4081 solver.cpp:218] Iteration 62400 (11.9846 iter/s, 8.34406s/100 iters), loss = 0.00379047
I1007 00:07:31.045986  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00379015 (* 1 = 0.00379015 loss)
I1007 00:07:31.046003  4081 sgd_solver.cpp:105] Iteration 62400, lr = 0.01
I1007 00:07:38.978252  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:07:39.313894  4081 solver.cpp:330] Iteration 62500, Testing net (#0)
I1007 00:07:41.245085  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:07:41.325714  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9101
I1007 00:07:41.325742  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.376671 (* 1 = 0.376671 loss)
I1007 00:07:41.409255  4081 solver.cpp:218] Iteration 62500 (9.64949 iter/s, 10.3632s/100 iters), loss = 0.033603
I1007 00:07:41.409281  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0336027 (* 1 = 0.0336027 loss)
I1007 00:07:41.409288  4081 sgd_solver.cpp:105] Iteration 62500, lr = 0.01
I1007 00:07:49.756420  4081 solver.cpp:218] Iteration 62600 (11.9802 iter/s, 8.34711s/100 iters), loss = 0.0100515
I1007 00:07:49.756453  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0100512 (* 1 = 0.0100512 loss)
I1007 00:07:49.756459  4081 sgd_solver.cpp:105] Iteration 62600, lr = 0.01
I1007 00:07:58.105551  4081 solver.cpp:218] Iteration 62700 (11.9774 iter/s, 8.34907s/100 iters), loss = 0.00450943
I1007 00:07:58.105592  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0045091 (* 1 = 0.0045091 loss)
I1007 00:07:58.105598  4081 sgd_solver.cpp:105] Iteration 62700, lr = 0.01
I1007 00:08:06.451953  4081 solver.cpp:218] Iteration 62800 (11.9813 iter/s, 8.34634s/100 iters), loss = 0.00805485
I1007 00:08:06.452100  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00805452 (* 1 = 0.00805452 loss)
I1007 00:08:06.452117  4081 sgd_solver.cpp:105] Iteration 62800, lr = 0.01
I1007 00:08:14.796567  4081 solver.cpp:218] Iteration 62900 (11.984 iter/s, 8.34445s/100 iters), loss = 0.0241577
I1007 00:08:14.796599  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0241574 (* 1 = 0.0241574 loss)
I1007 00:08:14.796607  4081 sgd_solver.cpp:105] Iteration 62900, lr = 0.01
I1007 00:08:22.726009  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:08:23.060307  4081 solver.cpp:330] Iteration 63000, Testing net (#0)
I1007 00:08:24.991590  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:08:25.072628  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9068
I1007 00:08:25.072654  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.370687 (* 1 = 0.370687 loss)
I1007 00:08:25.155664  4081 solver.cpp:218] Iteration 63000 (9.65341 iter/s, 10.359s/100 iters), loss = 0.00655798
I1007 00:08:25.155692  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00655764 (* 1 = 0.00655764 loss)
I1007 00:08:25.155699  4081 sgd_solver.cpp:105] Iteration 63000, lr = 0.01
I1007 00:08:33.500000  4081 solver.cpp:218] Iteration 63100 (11.9843 iter/s, 8.34428s/100 iters), loss = 0.0265829
I1007 00:08:33.500038  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0265826 (* 1 = 0.0265826 loss)
I1007 00:08:33.500046  4081 sgd_solver.cpp:105] Iteration 63100, lr = 0.01
I1007 00:08:41.847740  4081 solver.cpp:218] Iteration 63200 (11.9794 iter/s, 8.34768s/100 iters), loss = 0.0164869
I1007 00:08:41.847851  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0164865 (* 1 = 0.0164865 loss)
I1007 00:08:41.847859  4081 sgd_solver.cpp:105] Iteration 63200, lr = 0.01
I1007 00:08:50.189527  4081 solver.cpp:218] Iteration 63300 (11.988 iter/s, 8.34166s/100 iters), loss = 0.004288
I1007 00:08:50.189573  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00428766 (* 1 = 0.00428766 loss)
I1007 00:08:50.189579  4081 sgd_solver.cpp:105] Iteration 63300, lr = 0.01
I1007 00:08:58.535899  4081 solver.cpp:218] Iteration 63400 (11.9814 iter/s, 8.3463s/100 iters), loss = 0.00804272
I1007 00:08:58.535930  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00804238 (* 1 = 0.00804238 loss)
I1007 00:08:58.535938  4081 sgd_solver.cpp:105] Iteration 63400, lr = 0.01
I1007 00:09:06.465973  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:09:06.800081  4081 solver.cpp:330] Iteration 63500, Testing net (#0)
I1007 00:09:08.732995  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:09:08.814625  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9121
I1007 00:09:08.814651  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.366867 (* 1 = 0.366867 loss)
I1007 00:09:08.897204  4081 solver.cpp:218] Iteration 63500 (9.65135 iter/s, 10.3612s/100 iters), loss = 0.00066015
I1007 00:09:08.897231  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000659813 (* 1 = 0.000659813 loss)
I1007 00:09:08.897238  4081 sgd_solver.cpp:105] Iteration 63500, lr = 0.01
I1007 00:09:17.248190  4081 solver.cpp:218] Iteration 63600 (11.9747 iter/s, 8.35093s/100 iters), loss = 0.0113019
I1007 00:09:17.248303  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0113015 (* 1 = 0.0113015 loss)
I1007 00:09:17.248312  4081 sgd_solver.cpp:105] Iteration 63600, lr = 0.01
I1007 00:09:25.601101  4081 solver.cpp:218] Iteration 63700 (11.9721 iter/s, 8.35278s/100 iters), loss = 0.00581708
I1007 00:09:25.601142  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00581673 (* 1 = 0.00581673 loss)
I1007 00:09:25.601148  4081 sgd_solver.cpp:105] Iteration 63700, lr = 0.01
I1007 00:09:33.952272  4081 solver.cpp:218] Iteration 63800 (11.9745 iter/s, 8.35111s/100 iters), loss = 0.00375153
I1007 00:09:33.952302  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00375118 (* 1 = 0.00375118 loss)
I1007 00:09:33.952308  4081 sgd_solver.cpp:105] Iteration 63800, lr = 0.01
I1007 00:09:42.300760  4081 solver.cpp:218] Iteration 63900 (11.9783 iter/s, 8.34843s/100 iters), loss = 0.00317825
I1007 00:09:42.300802  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0031779 (* 1 = 0.0031779 loss)
I1007 00:09:42.300808  4081 sgd_solver.cpp:105] Iteration 63900, lr = 0.01
I1007 00:09:50.229070  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:09:50.563138  4081 solver.cpp:330] Iteration 64000, Testing net (#0)
I1007 00:09:52.495121  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:09:52.575942  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9139
I1007 00:09:52.575965  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.353269 (* 1 = 0.353269 loss)
I1007 00:09:52.659631  4081 solver.cpp:218] Iteration 64000 (9.65364 iter/s, 10.3588s/100 iters), loss = 0.0154805
I1007 00:09:52.659674  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0154801 (* 1 = 0.0154801 loss)
I1007 00:09:52.659682  4081 sgd_solver.cpp:105] Iteration 64000, lr = 0.01
I1007 00:10:00.999316  4081 solver.cpp:218] Iteration 64100 (11.9912 iter/s, 8.33948s/100 iters), loss = 0.00922319
I1007 00:10:00.999346  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00922284 (* 1 = 0.00922284 loss)
I1007 00:10:00.999352  4081 sgd_solver.cpp:105] Iteration 64100, lr = 0.01
I1007 00:10:09.336309  4081 solver.cpp:218] Iteration 64200 (11.9948 iter/s, 8.33694s/100 iters), loss = 0.0534661
I1007 00:10:09.336339  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0534658 (* 1 = 0.0534658 loss)
I1007 00:10:09.336345  4081 sgd_solver.cpp:105] Iteration 64200, lr = 0.01
I1007 00:10:17.669782  4081 solver.cpp:218] Iteration 64300 (11.9999 iter/s, 8.33342s/100 iters), loss = 0.0128256
I1007 00:10:17.669823  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0128253 (* 1 = 0.0128253 loss)
I1007 00:10:17.669829  4081 sgd_solver.cpp:105] Iteration 64300, lr = 0.01
I1007 00:10:26.009786  4081 solver.cpp:218] Iteration 64400 (11.9905 iter/s, 8.33994s/100 iters), loss = 0.00164309
I1007 00:10:26.009883  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00164275 (* 1 = 0.00164275 loss)
I1007 00:10:26.009889  4081 sgd_solver.cpp:105] Iteration 64400, lr = 0.01
I1007 00:10:33.931244  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:10:34.265542  4081 solver.cpp:330] Iteration 64500, Testing net (#0)
I1007 00:10:36.197957  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:10:36.278369  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9066
I1007 00:10:36.278395  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.394135 (* 1 = 0.394135 loss)
I1007 00:10:36.361611  4081 solver.cpp:218] Iteration 64500 (9.66025 iter/s, 10.3517s/100 iters), loss = 0.0062388
I1007 00:10:36.361635  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00623846 (* 1 = 0.00623846 loss)
I1007 00:10:36.361642  4081 sgd_solver.cpp:105] Iteration 64500, lr = 0.01
I1007 00:10:44.705219  4081 solver.cpp:218] Iteration 64600 (11.9853 iter/s, 8.34356s/100 iters), loss = 0.00613629
I1007 00:10:44.705260  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00613594 (* 1 = 0.00613594 loss)
I1007 00:10:44.705265  4081 sgd_solver.cpp:105] Iteration 64600, lr = 0.01
I1007 00:10:53.042487  4081 solver.cpp:218] Iteration 64700 (11.9944 iter/s, 8.3372s/100 iters), loss = 0.0274232
I1007 00:10:53.042528  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0274228 (* 1 = 0.0274228 loss)
I1007 00:10:53.042534  4081 sgd_solver.cpp:105] Iteration 64700, lr = 0.01
I1007 00:11:01.377583  4081 solver.cpp:218] Iteration 64800 (11.9976 iter/s, 8.33503s/100 iters), loss = 0.00767837
I1007 00:11:01.377691  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00767802 (* 1 = 0.00767802 loss)
I1007 00:11:01.377698  4081 sgd_solver.cpp:105] Iteration 64800, lr = 0.01
I1007 00:11:09.712508  4081 solver.cpp:218] Iteration 64900 (11.9979 iter/s, 8.33481s/100 iters), loss = 0.00150274
I1007 00:11:09.712549  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00150239 (* 1 = 0.00150239 loss)
I1007 00:11:09.712555  4081 sgd_solver.cpp:105] Iteration 64900, lr = 0.01
I1007 00:11:17.630525  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:11:17.964608  4081 solver.cpp:330] Iteration 65000, Testing net (#0)
I1007 00:11:19.897012  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:11:19.978055  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9089
I1007 00:11:19.978080  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.387225 (* 1 = 0.387225 loss)
I1007 00:11:20.061323  4081 solver.cpp:218] Iteration 65000 (9.663 iter/s, 10.3487s/100 iters), loss = 0.00310389
I1007 00:11:20.061349  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00310354 (* 1 = 0.00310354 loss)
I1007 00:11:20.061357  4081 sgd_solver.cpp:105] Iteration 65000, lr = 0.01
I1007 00:11:28.408264  4081 solver.cpp:218] Iteration 65100 (11.9805 iter/s, 8.34689s/100 iters), loss = 0.00136813
I1007 00:11:28.408294  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00136777 (* 1 = 0.00136777 loss)
I1007 00:11:28.408299  4081 sgd_solver.cpp:105] Iteration 65100, lr = 0.01
I1007 00:11:36.745975  4081 solver.cpp:218] Iteration 65200 (11.9938 iter/s, 8.33766s/100 iters), loss = 0.00668364
I1007 00:11:36.746063  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00668328 (* 1 = 0.00668328 loss)
I1007 00:11:36.746081  4081 sgd_solver.cpp:105] Iteration 65200, lr = 0.01
I1007 00:11:45.087646  4081 solver.cpp:218] Iteration 65300 (11.9882 iter/s, 8.34156s/100 iters), loss = 0.0102195
I1007 00:11:45.087677  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0102192 (* 1 = 0.0102192 loss)
I1007 00:11:45.087682  4081 sgd_solver.cpp:105] Iteration 65300, lr = 0.01
I1007 00:11:53.426733  4081 solver.cpp:218] Iteration 65400 (11.9918 iter/s, 8.33903s/100 iters), loss = 0.0111822
I1007 00:11:53.426764  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0111819 (* 1 = 0.0111819 loss)
I1007 00:11:53.426770  4081 sgd_solver.cpp:105] Iteration 65400, lr = 0.01
I1007 00:12:01.348608  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:12:01.682126  4081 solver.cpp:330] Iteration 65500, Testing net (#0)
I1007 00:12:03.613567  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:12:03.695071  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9036
I1007 00:12:03.695096  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.392442 (* 1 = 0.392442 loss)
I1007 00:12:03.778887  4081 solver.cpp:218] Iteration 65500 (9.65988 iter/s, 10.3521s/100 iters), loss = 0.00156742
I1007 00:12:03.778914  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00156708 (* 1 = 0.00156708 loss)
I1007 00:12:03.778921  4081 sgd_solver.cpp:105] Iteration 65500, lr = 0.01
I1007 00:12:12.116600  4081 solver.cpp:218] Iteration 65600 (11.9938 iter/s, 8.33766s/100 iters), loss = 0.00234968
I1007 00:12:12.116708  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00234933 (* 1 = 0.00234933 loss)
I1007 00:12:12.116714  4081 sgd_solver.cpp:105] Iteration 65600, lr = 0.01
I1007 00:12:20.453706  4081 solver.cpp:218] Iteration 65700 (11.9947 iter/s, 8.33699s/100 iters), loss = 0.00452484
I1007 00:12:20.453737  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00452449 (* 1 = 0.00452449 loss)
I1007 00:12:20.453742  4081 sgd_solver.cpp:105] Iteration 65700, lr = 0.01
I1007 00:12:28.788215  4081 solver.cpp:218] Iteration 65800 (11.9984 iter/s, 8.33446s/100 iters), loss = 0.0193832
I1007 00:12:28.788255  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0193829 (* 1 = 0.0193829 loss)
I1007 00:12:28.788261  4081 sgd_solver.cpp:105] Iteration 65800, lr = 0.01
I1007 00:12:37.123256  4081 solver.cpp:218] Iteration 65900 (11.9976 iter/s, 8.33498s/100 iters), loss = 0.0121446
I1007 00:12:37.123296  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0121443 (* 1 = 0.0121443 loss)
I1007 00:12:37.123301  4081 sgd_solver.cpp:105] Iteration 65900, lr = 0.01
I1007 00:12:45.056470  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:12:45.390103  4081 solver.cpp:330] Iteration 66000, Testing net (#0)
I1007 00:12:47.320668  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:12:47.401576  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.908
I1007 00:12:47.401599  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.386317 (* 1 = 0.386317 loss)
I1007 00:12:47.484915  4081 solver.cpp:218] Iteration 66000 (9.65102 iter/s, 10.3616s/100 iters), loss = 0.00529444
I1007 00:12:47.484939  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00529408 (* 1 = 0.00529408 loss)
I1007 00:12:47.484946  4081 sgd_solver.cpp:105] Iteration 66000, lr = 0.01
I1007 00:12:55.820327  4081 solver.cpp:218] Iteration 66100 (11.9971 iter/s, 8.33536s/100 iters), loss = 0.00446449
I1007 00:12:55.820355  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00446413 (* 1 = 0.00446413 loss)
I1007 00:12:55.820361  4081 sgd_solver.cpp:105] Iteration 66100, lr = 0.01
I1007 00:13:04.155897  4081 solver.cpp:218] Iteration 66200 (11.9969 iter/s, 8.33552s/100 iters), loss = 0.00687748
I1007 00:13:04.155937  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00687712 (* 1 = 0.00687712 loss)
I1007 00:13:04.155943  4081 sgd_solver.cpp:105] Iteration 66200, lr = 0.01
I1007 00:13:12.497684  4081 solver.cpp:218] Iteration 66300 (11.9879 iter/s, 8.34172s/100 iters), loss = 0.0103129
I1007 00:13:12.497714  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0103125 (* 1 = 0.0103125 loss)
I1007 00:13:12.497720  4081 sgd_solver.cpp:105] Iteration 66300, lr = 0.01
I1007 00:13:20.831908  4081 solver.cpp:218] Iteration 66400 (11.9988 iter/s, 8.33417s/100 iters), loss = 0.00457898
I1007 00:13:20.832031  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00457863 (* 1 = 0.00457863 loss)
I1007 00:13:20.832038  4081 sgd_solver.cpp:105] Iteration 66400, lr = 0.01
I1007 00:13:28.756712  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:13:29.091460  4081 solver.cpp:330] Iteration 66500, Testing net (#0)
I1007 00:13:31.021548  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:13:31.102813  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9101
I1007 00:13:31.102838  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.381275 (* 1 = 0.381275 loss)
I1007 00:13:31.186041  4081 solver.cpp:218] Iteration 66500 (9.65812 iter/s, 10.354s/100 iters), loss = 0.0155196
I1007 00:13:31.186064  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0155193 (* 1 = 0.0155193 loss)
I1007 00:13:31.186071  4081 sgd_solver.cpp:105] Iteration 66500, lr = 0.01
I1007 00:13:39.537355  4081 solver.cpp:218] Iteration 66600 (11.9742 iter/s, 8.35127s/100 iters), loss = 0.00383759
I1007 00:13:39.537396  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00383724 (* 1 = 0.00383724 loss)
I1007 00:13:39.537402  4081 sgd_solver.cpp:105] Iteration 66600, lr = 0.01
I1007 00:13:47.888432  4081 solver.cpp:218] Iteration 66700 (11.9746 iter/s, 8.35101s/100 iters), loss = 0.00157519
I1007 00:13:47.888460  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00157484 (* 1 = 0.00157484 loss)
I1007 00:13:47.888468  4081 sgd_solver.cpp:105] Iteration 66700, lr = 0.01
I1007 00:13:56.231640  4081 solver.cpp:218] Iteration 66800 (11.9859 iter/s, 8.34315s/100 iters), loss = 0.00831506
I1007 00:13:56.231765  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0083147 (* 1 = 0.0083147 loss)
I1007 00:13:56.231781  4081 sgd_solver.cpp:105] Iteration 66800, lr = 0.01
I1007 00:14:04.572474  4081 solver.cpp:218] Iteration 66900 (11.9894 iter/s, 8.3407s/100 iters), loss = 0.00238711
I1007 00:14:04.572515  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00238674 (* 1 = 0.00238674 loss)
I1007 00:14:04.572521  4081 sgd_solver.cpp:105] Iteration 66900, lr = 0.01
I1007 00:14:12.502476  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:14:12.836014  4081 solver.cpp:330] Iteration 67000, Testing net (#0)
I1007 00:14:14.767117  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:14:14.847484  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9038
I1007 00:14:14.847506  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.414074 (* 1 = 0.414074 loss)
I1007 00:14:14.930544  4081 solver.cpp:218] Iteration 67000 (9.65437 iter/s, 10.358s/100 iters), loss = 0.00307295
I1007 00:14:14.930574  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00307259 (* 1 = 0.00307259 loss)
I1007 00:14:14.930580  4081 sgd_solver.cpp:105] Iteration 67000, lr = 0.01
I1007 00:14:23.264987  4081 solver.cpp:218] Iteration 67100 (11.9985 iter/s, 8.33439s/100 iters), loss = 0.00896082
I1007 00:14:23.265019  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00896045 (* 1 = 0.00896045 loss)
I1007 00:14:23.265027  4081 sgd_solver.cpp:105] Iteration 67100, lr = 0.01
I1007 00:14:31.601827  4081 solver.cpp:218] Iteration 67200 (11.995 iter/s, 8.33679s/100 iters), loss = 0.0165485
I1007 00:14:31.601949  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0165481 (* 1 = 0.0165481 loss)
I1007 00:14:31.601956  4081 sgd_solver.cpp:105] Iteration 67200, lr = 0.01
I1007 00:14:39.937048  4081 solver.cpp:218] Iteration 67300 (11.9975 iter/s, 8.33508s/100 iters), loss = 0.00978059
I1007 00:14:39.937088  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00978023 (* 1 = 0.00978023 loss)
I1007 00:14:39.937094  4081 sgd_solver.cpp:105] Iteration 67300, lr = 0.01
I1007 00:14:48.271914  4081 solver.cpp:218] Iteration 67400 (11.9979 iter/s, 8.3348s/100 iters), loss = 0.00356132
I1007 00:14:48.271946  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00356096 (* 1 = 0.00356096 loss)
I1007 00:14:48.271952  4081 sgd_solver.cpp:105] Iteration 67400, lr = 0.01
I1007 00:14:56.199232  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:14:56.533144  4081 solver.cpp:330] Iteration 67500, Testing net (#0)
I1007 00:14:58.465899  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:14:58.546501  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.912
I1007 00:14:58.546537  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.366501 (* 1 = 0.366501 loss)
I1007 00:14:58.629714  4081 solver.cpp:218] Iteration 67500 (9.65461 iter/s, 10.3577s/100 iters), loss = 0.00217943
I1007 00:14:58.629741  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00217908 (* 1 = 0.00217908 loss)
I1007 00:14:58.629748  4081 sgd_solver.cpp:105] Iteration 67500, lr = 0.01
I1007 00:15:06.967097  4081 solver.cpp:218] Iteration 67600 (11.9942 iter/s, 8.33733s/100 iters), loss = 0.0252489
I1007 00:15:06.967202  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0252485 (* 1 = 0.0252485 loss)
I1007 00:15:06.967211  4081 sgd_solver.cpp:105] Iteration 67600, lr = 0.01
I1007 00:15:15.315570  4081 solver.cpp:218] Iteration 67700 (11.9784 iter/s, 8.34835s/100 iters), loss = 0.00729974
I1007 00:15:15.315603  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00729939 (* 1 = 0.00729939 loss)
I1007 00:15:15.315608  4081 sgd_solver.cpp:105] Iteration 67700, lr = 0.01
I1007 00:15:23.652927  4081 solver.cpp:218] Iteration 67800 (11.9943 iter/s, 8.3373s/100 iters), loss = 0.00517076
I1007 00:15:23.652968  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00517041 (* 1 = 0.00517041 loss)
I1007 00:15:23.652974  4081 sgd_solver.cpp:105] Iteration 67800, lr = 0.01
I1007 00:15:31.990216  4081 solver.cpp:218] Iteration 67900 (11.9944 iter/s, 8.33722s/100 iters), loss = 0.00460227
I1007 00:15:31.990244  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00460192 (* 1 = 0.00460192 loss)
I1007 00:15:31.990250  4081 sgd_solver.cpp:105] Iteration 67900, lr = 0.01
I1007 00:15:39.917102  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:15:40.250985  4081 solver.cpp:330] Iteration 68000, Testing net (#0)
I1007 00:15:42.181789  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:15:42.262979  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9065
I1007 00:15:42.263015  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.38762 (* 1 = 0.38762 loss)
I1007 00:15:42.346431  4081 solver.cpp:218] Iteration 68000 (9.65609 iter/s, 10.3562s/100 iters), loss = 0.0010991
I1007 00:15:42.346458  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00109875 (* 1 = 0.00109875 loss)
I1007 00:15:42.346465  4081 sgd_solver.cpp:105] Iteration 68000, lr = 0.01
I1007 00:15:50.688812  4081 solver.cpp:218] Iteration 68100 (11.9871 iter/s, 8.34233s/100 iters), loss = 0.0194435
I1007 00:15:50.688841  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0194431 (* 1 = 0.0194431 loss)
I1007 00:15:50.688848  4081 sgd_solver.cpp:105] Iteration 68100, lr = 0.01
I1007 00:15:59.033656  4081 solver.cpp:218] Iteration 68200 (11.9835 iter/s, 8.34479s/100 iters), loss = 0.00302946
I1007 00:15:59.033696  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00302912 (* 1 = 0.00302912 loss)
I1007 00:15:59.033704  4081 sgd_solver.cpp:105] Iteration 68200, lr = 0.01
I1007 00:16:07.379317  4081 solver.cpp:218] Iteration 68300 (11.9824 iter/s, 8.3456s/100 iters), loss = 0.00922559
I1007 00:16:07.379348  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00922525 (* 1 = 0.00922525 loss)
I1007 00:16:07.379354  4081 sgd_solver.cpp:105] Iteration 68300, lr = 0.01
I1007 00:16:15.722666  4081 solver.cpp:218] Iteration 68400 (11.9857 iter/s, 8.3433s/100 iters), loss = 0.0015486
I1007 00:16:15.722779  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00154825 (* 1 = 0.00154825 loss)
I1007 00:16:15.722787  4081 sgd_solver.cpp:105] Iteration 68400, lr = 0.01
I1007 00:16:23.644105  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:16:23.977892  4081 solver.cpp:330] Iteration 68500, Testing net (#0)
I1007 00:16:25.909126  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:16:25.989768  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9085
I1007 00:16:25.989804  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.391322 (* 1 = 0.391322 loss)
I1007 00:16:26.073189  4081 solver.cpp:218] Iteration 68500 (9.66147 iter/s, 10.3504s/100 iters), loss = 0.0035357
I1007 00:16:26.073215  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00353535 (* 1 = 0.00353535 loss)
I1007 00:16:26.073221  4081 sgd_solver.cpp:105] Iteration 68500, lr = 0.01
I1007 00:16:34.414974  4081 solver.cpp:218] Iteration 68600 (11.9879 iter/s, 8.34174s/100 iters), loss = 0.00266316
I1007 00:16:34.415004  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00266281 (* 1 = 0.00266281 loss)
I1007 00:16:34.415010  4081 sgd_solver.cpp:105] Iteration 68600, lr = 0.01
I1007 00:16:42.762662  4081 solver.cpp:218] Iteration 68700 (11.9794 iter/s, 8.34763s/100 iters), loss = 0.00350712
I1007 00:16:42.762703  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00350677 (* 1 = 0.00350677 loss)
I1007 00:16:42.762711  4081 sgd_solver.cpp:105] Iteration 68700, lr = 0.01
I1007 00:16:51.105018  4081 solver.cpp:218] Iteration 68800 (11.9871 iter/s, 8.34229s/100 iters), loss = 0.00922239
I1007 00:16:51.105136  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00922204 (* 1 = 0.00922204 loss)
I1007 00:16:51.105144  4081 sgd_solver.cpp:105] Iteration 68800, lr = 0.01
I1007 00:16:59.449786  4081 solver.cpp:218] Iteration 68900 (11.9838 iter/s, 8.34463s/100 iters), loss = 0.00439594
I1007 00:16:59.449828  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00439561 (* 1 = 0.00439561 loss)
I1007 00:16:59.449834  4081 sgd_solver.cpp:105] Iteration 68900, lr = 0.01
I1007 00:17:07.374873  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:17:07.709012  4081 solver.cpp:330] Iteration 69000, Testing net (#0)
I1007 00:17:09.643270  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:17:09.724427  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9081
I1007 00:17:09.724462  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.403056 (* 1 = 0.403056 loss)
I1007 00:17:09.808243  4081 solver.cpp:218] Iteration 69000 (9.65401 iter/s, 10.3584s/100 iters), loss = 0.00211807
I1007 00:17:09.808269  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00211773 (* 1 = 0.00211773 loss)
I1007 00:17:09.808276  4081 sgd_solver.cpp:105] Iteration 69000, lr = 0.01
I1007 00:17:18.150450  4081 solver.cpp:218] Iteration 69100 (11.9873 iter/s, 8.34216s/100 iters), loss = 0.0018839
I1007 00:17:18.150480  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00188357 (* 1 = 0.00188357 loss)
I1007 00:17:18.150496  4081 sgd_solver.cpp:105] Iteration 69100, lr = 0.01
I1007 00:17:26.497164  4081 solver.cpp:218] Iteration 69200 (11.9808 iter/s, 8.34666s/100 iters), loss = 0.0102461
I1007 00:17:26.497274  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0102458 (* 1 = 0.0102458 loss)
I1007 00:17:26.497282  4081 sgd_solver.cpp:105] Iteration 69200, lr = 0.01
I1007 00:17:34.839521  4081 solver.cpp:218] Iteration 69300 (11.9872 iter/s, 8.34223s/100 iters), loss = 0.0011833
I1007 00:17:34.839552  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00118297 (* 1 = 0.00118297 loss)
I1007 00:17:34.839558  4081 sgd_solver.cpp:105] Iteration 69300, lr = 0.01
I1007 00:17:43.181975  4081 solver.cpp:218] Iteration 69400 (11.987 iter/s, 8.3424s/100 iters), loss = 0.00476846
I1007 00:17:43.182006  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00476814 (* 1 = 0.00476814 loss)
I1007 00:17:43.182023  4081 sgd_solver.cpp:105] Iteration 69400, lr = 0.01
I1007 00:17:51.114357  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:17:51.448355  4081 solver.cpp:330] Iteration 69500, Testing net (#0)
I1007 00:17:53.380211  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:17:53.460631  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9089
I1007 00:17:53.460669  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.371991 (* 1 = 0.371991 loss)
I1007 00:17:53.544210  4081 solver.cpp:218] Iteration 69500 (9.65048 iter/s, 10.3622s/100 iters), loss = 0.00656608
I1007 00:17:53.544248  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00656576 (* 1 = 0.00656576 loss)
I1007 00:17:53.544255  4081 sgd_solver.cpp:105] Iteration 69500, lr = 0.01
I1007 00:18:01.886482  4081 solver.cpp:218] Iteration 69600 (11.9872 iter/s, 8.34221s/100 iters), loss = 0.0181624
I1007 00:18:01.886603  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.018162 (* 1 = 0.018162 loss)
I1007 00:18:01.886621  4081 sgd_solver.cpp:105] Iteration 69600, lr = 0.01
I1007 00:18:10.225558  4081 solver.cpp:218] Iteration 69700 (11.9919 iter/s, 8.33893s/100 iters), loss = 0.00555336
I1007 00:18:10.225597  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00555303 (* 1 = 0.00555303 loss)
I1007 00:18:10.225605  4081 sgd_solver.cpp:105] Iteration 69700, lr = 0.01
I1007 00:18:18.570153  4081 solver.cpp:218] Iteration 69800 (11.9839 iter/s, 8.34453s/100 iters), loss = 0.00969775
I1007 00:18:18.570183  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00969742 (* 1 = 0.00969742 loss)
I1007 00:18:18.570190  4081 sgd_solver.cpp:105] Iteration 69800, lr = 0.01
I1007 00:18:26.910646  4081 solver.cpp:218] Iteration 69900 (11.9898 iter/s, 8.34044s/100 iters), loss = 0.00658129
I1007 00:18:26.910688  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00658096 (* 1 = 0.00658096 loss)
I1007 00:18:26.910694  4081 sgd_solver.cpp:105] Iteration 69900, lr = 0.01
I1007 00:18:34.840649  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:18:35.174289  4081 solver.cpp:330] Iteration 70000, Testing net (#0)
I1007 00:18:37.105736  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:18:37.187320  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9021
I1007 00:18:37.187346  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.422017 (* 1 = 0.422017 loss)
I1007 00:18:37.270720  4081 solver.cpp:218] Iteration 70000 (9.65251 iter/s, 10.36s/100 iters), loss = 0.0012735
I1007 00:18:37.270751  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00127317 (* 1 = 0.00127317 loss)
I1007 00:18:37.270759  4081 sgd_solver.cpp:105] Iteration 70000, lr = 0.01
I1007 00:18:45.619268  4081 solver.cpp:218] Iteration 70100 (11.9782 iter/s, 8.34849s/100 iters), loss = 0.0121082
I1007 00:18:45.619309  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0121079 (* 1 = 0.0121079 loss)
I1007 00:18:45.619315  4081 sgd_solver.cpp:105] Iteration 70100, lr = 0.01
I1007 00:18:53.961663  4081 solver.cpp:218] Iteration 70200 (11.9871 iter/s, 8.34233s/100 iters), loss = 0.00243852
I1007 00:18:53.961704  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00243818 (* 1 = 0.00243818 loss)
I1007 00:18:53.961709  4081 sgd_solver.cpp:105] Iteration 70200, lr = 0.01
I1007 00:19:02.303640  4081 solver.cpp:218] Iteration 70300 (11.9877 iter/s, 8.34191s/100 iters), loss = 0.00161279
I1007 00:19:02.303681  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00161245 (* 1 = 0.00161245 loss)
I1007 00:19:02.303689  4081 sgd_solver.cpp:105] Iteration 70300, lr = 0.01
I1007 00:19:10.645125  4081 solver.cpp:218] Iteration 70400 (11.9884 iter/s, 8.34142s/100 iters), loss = 0.00149175
I1007 00:19:10.645267  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00149141 (* 1 = 0.00149141 loss)
I1007 00:19:10.645275  4081 sgd_solver.cpp:105] Iteration 70400, lr = 0.01
I1007 00:19:18.566085  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:19:18.900240  4081 solver.cpp:330] Iteration 70500, Testing net (#0)
I1007 00:19:20.832366  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:19:20.913522  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9076
I1007 00:19:20.913558  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.395067 (* 1 = 0.395067 loss)
I1007 00:19:20.997423  4081 solver.cpp:218] Iteration 70500 (9.65984 iter/s, 10.3521s/100 iters), loss = 0.00161906
I1007 00:19:20.997449  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00161873 (* 1 = 0.00161873 loss)
I1007 00:19:20.997457  4081 sgd_solver.cpp:105] Iteration 70500, lr = 0.01
I1007 00:19:29.339339  4081 solver.cpp:218] Iteration 70600 (11.9877 iter/s, 8.34186s/100 iters), loss = 0.0236828
I1007 00:19:29.339380  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0236825 (* 1 = 0.0236825 loss)
I1007 00:19:29.339386  4081 sgd_solver.cpp:105] Iteration 70600, lr = 0.01
I1007 00:19:37.677242  4081 solver.cpp:218] Iteration 70700 (11.9935 iter/s, 8.33784s/100 iters), loss = 0.0140261
I1007 00:19:37.677284  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0140258 (* 1 = 0.0140258 loss)
I1007 00:19:37.677289  4081 sgd_solver.cpp:105] Iteration 70700, lr = 0.01
I1007 00:19:46.022433  4081 solver.cpp:218] Iteration 70800 (11.983 iter/s, 8.34513s/100 iters), loss = 0.00482319
I1007 00:19:46.022565  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00482287 (* 1 = 0.00482287 loss)
I1007 00:19:46.022578  4081 sgd_solver.cpp:105] Iteration 70800, lr = 0.01
I1007 00:19:54.359166  4081 solver.cpp:218] Iteration 70900 (11.9953 iter/s, 8.33658s/100 iters), loss = 0.0150331
I1007 00:19:54.359207  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0150328 (* 1 = 0.0150328 loss)
I1007 00:19:54.359213  4081 sgd_solver.cpp:105] Iteration 70900, lr = 0.01
I1007 00:20:02.289754  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:20:02.623781  4081 solver.cpp:330] Iteration 71000, Testing net (#0)
I1007 00:20:04.555516  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:20:04.635776  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9101
I1007 00:20:04.635802  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.381855 (* 1 = 0.381855 loss)
I1007 00:20:04.719007  4081 solver.cpp:218] Iteration 71000 (9.65272 iter/s, 10.3598s/100 iters), loss = 0.00836358
I1007 00:20:04.719032  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00836326 (* 1 = 0.00836326 loss)
I1007 00:20:04.719038  4081 sgd_solver.cpp:105] Iteration 71000, lr = 0.01
I1007 00:20:13.061923  4081 solver.cpp:218] Iteration 71100 (11.9863 iter/s, 8.34287s/100 iters), loss = 0.00260664
I1007 00:20:13.061962  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00260632 (* 1 = 0.00260632 loss)
I1007 00:20:13.061969  4081 sgd_solver.cpp:105] Iteration 71100, lr = 0.01
I1007 00:20:21.405927  4081 solver.cpp:218] Iteration 71200 (11.9847 iter/s, 8.34394s/100 iters), loss = 0.00134789
I1007 00:20:21.406064  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00134757 (* 1 = 0.00134757 loss)
I1007 00:20:21.406070  4081 sgd_solver.cpp:105] Iteration 71200, lr = 0.01
I1007 00:20:29.752578  4081 solver.cpp:218] Iteration 71300 (11.9811 iter/s, 8.3465s/100 iters), loss = 0.00392139
I1007 00:20:29.752620  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00392107 (* 1 = 0.00392107 loss)
I1007 00:20:29.752627  4081 sgd_solver.cpp:105] Iteration 71300, lr = 0.01
I1007 00:20:38.091820  4081 solver.cpp:218] Iteration 71400 (11.9916 iter/s, 8.33918s/100 iters), loss = 0.00377639
I1007 00:20:38.091851  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00377608 (* 1 = 0.00377608 loss)
I1007 00:20:38.091857  4081 sgd_solver.cpp:105] Iteration 71400, lr = 0.01
I1007 00:20:46.017932  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:20:46.352427  4081 solver.cpp:330] Iteration 71500, Testing net (#0)
I1007 00:20:48.281785  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:20:48.362782  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.912
I1007 00:20:48.362818  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.372289 (* 1 = 0.372289 loss)
I1007 00:20:48.445888  4081 solver.cpp:218] Iteration 71500 (9.6581 iter/s, 10.354s/100 iters), loss = 0.00515428
I1007 00:20:48.445914  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00515397 (* 1 = 0.00515397 loss)
I1007 00:20:48.445920  4081 sgd_solver.cpp:105] Iteration 71500, lr = 0.01
I1007 00:20:56.792287  4081 solver.cpp:218] Iteration 71600 (11.9813 iter/s, 8.34635s/100 iters), loss = 0.00439068
I1007 00:20:56.792410  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00439036 (* 1 = 0.00439036 loss)
I1007 00:20:56.792429  4081 sgd_solver.cpp:105] Iteration 71600, lr = 0.01
I1007 00:21:05.133280  4081 solver.cpp:218] Iteration 71700 (11.9892 iter/s, 8.34085s/100 iters), loss = 0.0243025
I1007 00:21:05.133311  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0243021 (* 1 = 0.0243021 loss)
I1007 00:21:05.133316  4081 sgd_solver.cpp:105] Iteration 71700, lr = 0.01
I1007 00:21:13.483813  4081 solver.cpp:218] Iteration 71800 (11.9754 iter/s, 8.35048s/100 iters), loss = 0.00685842
I1007 00:21:13.483852  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0068581 (* 1 = 0.0068581 loss)
I1007 00:21:13.483858  4081 sgd_solver.cpp:105] Iteration 71800, lr = 0.01
I1007 00:21:21.825350  4081 solver.cpp:218] Iteration 71900 (11.9883 iter/s, 8.34147s/100 iters), loss = 0.00306807
I1007 00:21:21.825378  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00306775 (* 1 = 0.00306775 loss)
I1007 00:21:21.825386  4081 sgd_solver.cpp:105] Iteration 71900, lr = 0.01
I1007 00:21:29.760568  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:21:30.094178  4081 solver.cpp:330] Iteration 72000, Testing net (#0)
I1007 00:21:32.024618  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:21:32.105366  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.912
I1007 00:21:32.105402  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.385345 (* 1 = 0.385345 loss)
I1007 00:21:32.188832  4081 solver.cpp:218] Iteration 72000 (9.64932 iter/s, 10.3634s/100 iters), loss = 0.00346002
I1007 00:21:32.188858  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00345971 (* 1 = 0.00345971 loss)
I1007 00:21:32.188864  4081 sgd_solver.cpp:105] Iteration 72000, lr = 0.01
I1007 00:21:40.537691  4081 solver.cpp:218] Iteration 72100 (11.9778 iter/s, 8.34881s/100 iters), loss = 0.00875452
I1007 00:21:40.537732  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0087542 (* 1 = 0.0087542 loss)
I1007 00:21:40.537739  4081 sgd_solver.cpp:105] Iteration 72100, lr = 0.01
I1007 00:21:48.881620  4081 solver.cpp:218] Iteration 72200 (11.9849 iter/s, 8.34386s/100 iters), loss = 0.00352404
I1007 00:21:48.881651  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00352373 (* 1 = 0.00352373 loss)
I1007 00:21:48.881657  4081 sgd_solver.cpp:105] Iteration 72200, lr = 0.01
I1007 00:21:57.221994  4081 solver.cpp:218] Iteration 72300 (11.9899 iter/s, 8.34032s/100 iters), loss = 0.0279374
I1007 00:21:57.222024  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0279371 (* 1 = 0.0279371 loss)
I1007 00:21:57.222030  4081 sgd_solver.cpp:105] Iteration 72300, lr = 0.01
I1007 00:22:05.563824  4081 solver.cpp:218] Iteration 72400 (11.9879 iter/s, 8.34178s/100 iters), loss = 0.00525993
I1007 00:22:05.563931  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00525962 (* 1 = 0.00525962 loss)
I1007 00:22:05.563949  4081 sgd_solver.cpp:105] Iteration 72400, lr = 0.01
I1007 00:22:13.493909  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:22:13.828373  4081 solver.cpp:330] Iteration 72500, Testing net (#0)
I1007 00:22:15.759719  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:22:15.840464  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9028
I1007 00:22:15.840498  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.421749 (* 1 = 0.421749 loss)
I1007 00:22:15.923166  4081 solver.cpp:218] Iteration 72500 (9.65324 iter/s, 10.3592s/100 iters), loss = 0.00919349
I1007 00:22:15.923192  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00919318 (* 1 = 0.00919318 loss)
I1007 00:22:15.923198  4081 sgd_solver.cpp:105] Iteration 72500, lr = 0.01
I1007 00:22:24.260751  4081 solver.cpp:218] Iteration 72600 (11.994 iter/s, 8.33753s/100 iters), loss = 0.00911985
I1007 00:22:24.260784  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00911952 (* 1 = 0.00911952 loss)
I1007 00:22:24.260792  4081 sgd_solver.cpp:105] Iteration 72600, lr = 0.01
I1007 00:22:32.593938  4081 solver.cpp:218] Iteration 72700 (12.0003 iter/s, 8.33313s/100 iters), loss = 0.00210398
I1007 00:22:32.593966  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00210366 (* 1 = 0.00210366 loss)
I1007 00:22:32.593973  4081 sgd_solver.cpp:105] Iteration 72700, lr = 0.01
I1007 00:22:40.926148  4081 solver.cpp:218] Iteration 72800 (12.0017 iter/s, 8.33216s/100 iters), loss = 0.00802579
I1007 00:22:40.926241  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00802547 (* 1 = 0.00802547 loss)
I1007 00:22:40.926259  4081 sgd_solver.cpp:105] Iteration 72800, lr = 0.01
I1007 00:22:49.263777  4081 solver.cpp:218] Iteration 72900 (11.994 iter/s, 8.33751s/100 iters), loss = 0.00238065
I1007 00:22:49.263808  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00238034 (* 1 = 0.00238034 loss)
I1007 00:22:49.263814  4081 sgd_solver.cpp:105] Iteration 72900, lr = 0.01
I1007 00:22:57.186698  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:22:57.521560  4081 solver.cpp:330] Iteration 73000, Testing net (#0)
I1007 00:22:59.455374  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:22:59.535635  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9118
I1007 00:22:59.535671  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.378427 (* 1 = 0.378427 loss)
I1007 00:22:59.618549  4081 solver.cpp:218] Iteration 73000 (9.65744 iter/s, 10.3547s/100 iters), loss = 0.0081168
I1007 00:22:59.618574  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00811649 (* 1 = 0.00811649 loss)
I1007 00:22:59.618582  4081 sgd_solver.cpp:105] Iteration 73000, lr = 0.01
I1007 00:23:07.967638  4081 solver.cpp:218] Iteration 73100 (11.9774 iter/s, 8.34904s/100 iters), loss = 0.0185765
I1007 00:23:07.967679  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0185762 (* 1 = 0.0185762 loss)
I1007 00:23:07.967686  4081 sgd_solver.cpp:105] Iteration 73100, lr = 0.01
I1007 00:23:16.321017  4081 solver.cpp:218] Iteration 73200 (11.9713 iter/s, 8.35331s/100 iters), loss = 0.0244009
I1007 00:23:16.321095  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0244006 (* 1 = 0.0244006 loss)
I1007 00:23:16.321102  4081 sgd_solver.cpp:105] Iteration 73200, lr = 0.01
I1007 00:23:24.670393  4081 solver.cpp:218] Iteration 73300 (11.9771 iter/s, 8.34928s/100 iters), loss = 0.0120175
I1007 00:23:24.670433  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0120171 (* 1 = 0.0120171 loss)
I1007 00:23:24.670440  4081 sgd_solver.cpp:105] Iteration 73300, lr = 0.01
I1007 00:23:33.016635  4081 solver.cpp:218] Iteration 73400 (11.9815 iter/s, 8.34618s/100 iters), loss = 0.00187239
I1007 00:23:33.016676  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00187207 (* 1 = 0.00187207 loss)
I1007 00:23:33.016682  4081 sgd_solver.cpp:105] Iteration 73400, lr = 0.01
I1007 00:23:40.944885  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:23:41.280354  4081 solver.cpp:330] Iteration 73500, Testing net (#0)
I1007 00:23:43.211436  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:23:43.292712  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9141
I1007 00:23:43.292738  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.378508 (* 1 = 0.378508 loss)
I1007 00:23:43.376137  4081 solver.cpp:218] Iteration 73500 (9.65304 iter/s, 10.3594s/100 iters), loss = 0.0178264
I1007 00:23:43.376160  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0178261 (* 1 = 0.0178261 loss)
I1007 00:23:43.376168  4081 sgd_solver.cpp:105] Iteration 73500, lr = 0.01
I1007 00:23:51.716615  4081 solver.cpp:218] Iteration 73600 (11.9898 iter/s, 8.34043s/100 iters), loss = 0.00809995
I1007 00:23:51.716719  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00809963 (* 1 = 0.00809963 loss)
I1007 00:23:51.716727  4081 sgd_solver.cpp:105] Iteration 73600, lr = 0.01
I1007 00:24:00.060500  4081 solver.cpp:218] Iteration 73700 (11.985 iter/s, 8.34377s/100 iters), loss = 0.0140525
I1007 00:24:00.060530  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0140522 (* 1 = 0.0140522 loss)
I1007 00:24:00.060536  4081 sgd_solver.cpp:105] Iteration 73700, lr = 0.01
I1007 00:24:08.403149  4081 solver.cpp:218] Iteration 73800 (11.9867 iter/s, 8.3426s/100 iters), loss = 0.00420658
I1007 00:24:08.403182  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00420627 (* 1 = 0.00420627 loss)
I1007 00:24:08.403187  4081 sgd_solver.cpp:105] Iteration 73800, lr = 0.01
I1007 00:24:16.740198  4081 solver.cpp:218] Iteration 73900 (11.9947 iter/s, 8.337s/100 iters), loss = 0.00807283
I1007 00:24:16.740237  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00807251 (* 1 = 0.00807251 loss)
I1007 00:24:16.740244  4081 sgd_solver.cpp:105] Iteration 73900, lr = 0.01
I1007 00:24:24.670061  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:24:25.005054  4081 solver.cpp:330] Iteration 74000, Testing net (#0)
I1007 00:24:26.936328  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:24:27.016932  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9127
I1007 00:24:27.016968  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.380527 (* 1 = 0.380527 loss)
I1007 00:24:27.100344  4081 solver.cpp:218] Iteration 74000 (9.65244 iter/s, 10.3601s/100 iters), loss = 0.00141817
I1007 00:24:27.100371  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00141787 (* 1 = 0.00141787 loss)
I1007 00:24:27.100378  4081 sgd_solver.cpp:105] Iteration 74000, lr = 0.01
I1007 00:24:35.447304  4081 solver.cpp:218] Iteration 74100 (11.9805 iter/s, 8.34691s/100 iters), loss = 0.00404699
I1007 00:24:35.447333  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00404668 (* 1 = 0.00404668 loss)
I1007 00:24:35.447340  4081 sgd_solver.cpp:105] Iteration 74100, lr = 0.01
I1007 00:24:43.793969  4081 solver.cpp:218] Iteration 74200 (11.9809 iter/s, 8.34661s/100 iters), loss = 0.00445482
I1007 00:24:43.793999  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00445451 (* 1 = 0.00445451 loss)
I1007 00:24:43.794005  4081 sgd_solver.cpp:105] Iteration 74200, lr = 0.01
I1007 00:24:52.137542  4081 solver.cpp:218] Iteration 74300 (11.9854 iter/s, 8.34352s/100 iters), loss = 0.00731663
I1007 00:24:52.137581  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00731631 (* 1 = 0.00731631 loss)
I1007 00:24:52.137588  4081 sgd_solver.cpp:105] Iteration 74300, lr = 0.01
I1007 00:25:00.487610  4081 solver.cpp:218] Iteration 74400 (11.976 iter/s, 8.35001s/100 iters), loss = 0.00381854
I1007 00:25:00.487754  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00381822 (* 1 = 0.00381822 loss)
I1007 00:25:00.487763  4081 sgd_solver.cpp:105] Iteration 74400, lr = 0.01
I1007 00:25:08.416559  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:25:08.750800  4081 solver.cpp:330] Iteration 74500, Testing net (#0)
I1007 00:25:10.684288  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:25:10.765058  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9157
I1007 00:25:10.765094  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.368036 (* 1 = 0.368036 loss)
I1007 00:25:10.848809  4081 solver.cpp:218] Iteration 74500 (9.65155 iter/s, 10.361s/100 iters), loss = 0.00211185
I1007 00:25:10.848836  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00211153 (* 1 = 0.00211153 loss)
I1007 00:25:10.848842  4081 sgd_solver.cpp:105] Iteration 74500, lr = 0.01
I1007 00:25:19.186168  4081 solver.cpp:218] Iteration 74600 (11.9943 iter/s, 8.33731s/100 iters), loss = 0.00864839
I1007 00:25:19.186208  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00864807 (* 1 = 0.00864807 loss)
I1007 00:25:19.186215  4081 sgd_solver.cpp:105] Iteration 74600, lr = 0.01
I1007 00:25:27.533809  4081 solver.cpp:218] Iteration 74700 (11.9795 iter/s, 8.34757s/100 iters), loss = 0.00751378
I1007 00:25:27.533850  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00751346 (* 1 = 0.00751346 loss)
I1007 00:25:27.533856  4081 sgd_solver.cpp:105] Iteration 74700, lr = 0.01
I1007 00:25:35.880656  4081 solver.cpp:218] Iteration 74800 (11.9807 iter/s, 8.34678s/100 iters), loss = 0.00239877
I1007 00:25:35.880771  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00239846 (* 1 = 0.00239846 loss)
I1007 00:25:35.880779  4081 sgd_solver.cpp:105] Iteration 74800, lr = 0.01
I1007 00:25:44.220954  4081 solver.cpp:218] Iteration 74900 (11.9902 iter/s, 8.34016s/100 iters), loss = 0.00324068
I1007 00:25:44.220984  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00324037 (* 1 = 0.00324037 loss)
I1007 00:25:44.220990  4081 sgd_solver.cpp:105] Iteration 74900, lr = 0.01
I1007 00:25:52.144222  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:25:52.477986  4081 solver.cpp:330] Iteration 75000, Testing net (#0)
I1007 00:25:54.410432  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:25:54.491636  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9063
I1007 00:25:54.491670  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.399918 (* 1 = 0.399918 loss)
I1007 00:25:54.574285  4081 solver.cpp:218] Iteration 75000 (9.65878 iter/s, 10.3533s/100 iters), loss = 0.0100754
I1007 00:25:54.574309  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0100751 (* 1 = 0.0100751 loss)
I1007 00:25:54.574316  4081 sgd_solver.cpp:105] Iteration 75000, lr = 0.01
I1007 00:26:02.911125  4081 solver.cpp:218] Iteration 75100 (11.995 iter/s, 8.33679s/100 iters), loss = 0.0102668
I1007 00:26:02.911154  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0102665 (* 1 = 0.0102665 loss)
I1007 00:26:02.911160  4081 sgd_solver.cpp:105] Iteration 75100, lr = 0.01
I1007 00:26:11.248375  4081 solver.cpp:218] Iteration 75200 (11.9944 iter/s, 8.33719s/100 iters), loss = 0.0434175
I1007 00:26:11.248486  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0434172 (* 1 = 0.0434172 loss)
I1007 00:26:11.248508  4081 sgd_solver.cpp:105] Iteration 75200, lr = 0.01
I1007 00:26:19.581719  4081 solver.cpp:218] Iteration 75300 (12.0002 iter/s, 8.33322s/100 iters), loss = 0.0066548
I1007 00:26:19.581760  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00665449 (* 1 = 0.00665449 loss)
I1007 00:26:19.581766  4081 sgd_solver.cpp:105] Iteration 75300, lr = 0.01
I1007 00:26:27.921258  4081 solver.cpp:218] Iteration 75400 (11.9912 iter/s, 8.33947s/100 iters), loss = 0.00392974
I1007 00:26:27.921288  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00392943 (* 1 = 0.00392943 loss)
I1007 00:26:27.921294  4081 sgd_solver.cpp:105] Iteration 75400, lr = 0.01
I1007 00:26:35.847810  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:26:36.182170  4081 solver.cpp:330] Iteration 75500, Testing net (#0)
I1007 00:26:38.114004  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:26:38.195019  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9114
I1007 00:26:38.195053  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.389293 (* 1 = 0.389293 loss)
I1007 00:26:38.278254  4081 solver.cpp:218] Iteration 75500 (9.65536 iter/s, 10.3569s/100 iters), loss = 0.00477469
I1007 00:26:38.278285  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00477438 (* 1 = 0.00477438 loss)
I1007 00:26:38.278291  4081 sgd_solver.cpp:105] Iteration 75500, lr = 0.01
I1007 00:26:46.621742  4081 solver.cpp:218] Iteration 75600 (11.9855 iter/s, 8.34343s/100 iters), loss = 0.0023536
I1007 00:26:46.621858  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0023533 (* 1 = 0.0023533 loss)
I1007 00:26:46.621865  4081 sgd_solver.cpp:105] Iteration 75600, lr = 0.01
I1007 00:26:54.955782  4081 solver.cpp:218] Iteration 75700 (11.9992 iter/s, 8.3339s/100 iters), loss = 0.00406138
I1007 00:26:54.955811  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00406107 (* 1 = 0.00406107 loss)
I1007 00:26:54.955817  4081 sgd_solver.cpp:105] Iteration 75700, lr = 0.01
I1007 00:27:03.293795  4081 solver.cpp:218] Iteration 75800 (11.9933 iter/s, 8.33796s/100 iters), loss = 0.000353481
I1007 00:27:03.293825  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000353181 (* 1 = 0.000353181 loss)
I1007 00:27:03.293831  4081 sgd_solver.cpp:105] Iteration 75800, lr = 0.01
I1007 00:27:11.632494  4081 solver.cpp:218] Iteration 75900 (11.9924 iter/s, 8.33865s/100 iters), loss = 0.0125321
I1007 00:27:11.632524  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0125318 (* 1 = 0.0125318 loss)
I1007 00:27:11.632530  4081 sgd_solver.cpp:105] Iteration 75900, lr = 0.01
I1007 00:27:19.555452  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:27:19.890100  4081 solver.cpp:330] Iteration 76000, Testing net (#0)
I1007 00:27:21.820955  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:27:21.901599  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9099
I1007 00:27:21.901635  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.383711 (* 1 = 0.383711 loss)
I1007 00:27:21.985103  4081 solver.cpp:218] Iteration 76000 (9.65945 iter/s, 10.3526s/100 iters), loss = 0.00439037
I1007 00:27:21.985127  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00439007 (* 1 = 0.00439007 loss)
I1007 00:27:21.985134  4081 sgd_solver.cpp:105] Iteration 76000, lr = 0.01
I1007 00:27:30.330215  4081 solver.cpp:218] Iteration 76100 (11.9831 iter/s, 8.34506s/100 iters), loss = 0.0264784
I1007 00:27:30.330256  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0264781 (* 1 = 0.0264781 loss)
I1007 00:27:30.330263  4081 sgd_solver.cpp:105] Iteration 76100, lr = 0.01
I1007 00:27:38.664512  4081 solver.cpp:218] Iteration 76200 (11.9987 iter/s, 8.33423s/100 iters), loss = 0.0129203
I1007 00:27:38.664553  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.01292 (* 1 = 0.01292 loss)
I1007 00:27:38.664561  4081 sgd_solver.cpp:105] Iteration 76200, lr = 0.01
I1007 00:27:47.006806  4081 solver.cpp:218] Iteration 76300 (11.9872 iter/s, 8.34223s/100 iters), loss = 0.00264656
I1007 00:27:47.006836  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00264627 (* 1 = 0.00264627 loss)
I1007 00:27:47.006842  4081 sgd_solver.cpp:105] Iteration 76300, lr = 0.01
I1007 00:27:55.345784  4081 solver.cpp:218] Iteration 76400 (11.992 iter/s, 8.33892s/100 iters), loss = 0.00481976
I1007 00:27:55.345873  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00481947 (* 1 = 0.00481947 loss)
I1007 00:27:55.345880  4081 sgd_solver.cpp:105] Iteration 76400, lr = 0.01
I1007 00:28:03.268376  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:28:03.601265  4081 solver.cpp:330] Iteration 76500, Testing net (#0)
I1007 00:28:05.531576  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:28:05.612686  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9062
I1007 00:28:05.612723  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.40584 (* 1 = 0.40584 loss)
I1007 00:28:05.695719  4081 solver.cpp:218] Iteration 76500 (9.662 iter/s, 10.3498s/100 iters), loss = 0.00565797
I1007 00:28:05.695744  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00565767 (* 1 = 0.00565767 loss)
I1007 00:28:05.695749  4081 sgd_solver.cpp:105] Iteration 76500, lr = 0.01
I1007 00:28:14.041275  4081 solver.cpp:218] Iteration 76600 (11.9825 iter/s, 8.34551s/100 iters), loss = 0.00244576
I1007 00:28:14.041316  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00244547 (* 1 = 0.00244547 loss)
I1007 00:28:14.041322  4081 sgd_solver.cpp:105] Iteration 76600, lr = 0.01
I1007 00:28:22.386080  4081 solver.cpp:218] Iteration 76700 (11.9836 iter/s, 8.34474s/100 iters), loss = 0.00462079
I1007 00:28:22.386108  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00462051 (* 1 = 0.00462051 loss)
I1007 00:28:22.386116  4081 sgd_solver.cpp:105] Iteration 76700, lr = 0.01
I1007 00:28:30.732964  4081 solver.cpp:218] Iteration 76800 (11.9806 iter/s, 8.34683s/100 iters), loss = 0.0054877
I1007 00:28:30.733085  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00548741 (* 1 = 0.00548741 loss)
I1007 00:28:30.733103  4081 sgd_solver.cpp:105] Iteration 76800, lr = 0.01
I1007 00:28:39.071221  4081 solver.cpp:218] Iteration 76900 (11.9931 iter/s, 8.33812s/100 iters), loss = 0.00417343
I1007 00:28:39.071252  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00417314 (* 1 = 0.00417314 loss)
I1007 00:28:39.071259  4081 sgd_solver.cpp:105] Iteration 76900, lr = 0.01
I1007 00:28:47.002974  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:28:47.336372  4081 solver.cpp:330] Iteration 77000, Testing net (#0)
I1007 00:28:49.266113  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:28:49.348063  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9058
I1007 00:28:49.348099  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.421973 (* 1 = 0.421973 loss)
I1007 00:28:49.431617  4081 solver.cpp:218] Iteration 77000 (9.65219 iter/s, 10.3603s/100 iters), loss = 0.00788207
I1007 00:28:49.431643  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00788178 (* 1 = 0.00788178 loss)
I1007 00:28:49.431649  4081 sgd_solver.cpp:105] Iteration 77000, lr = 0.01
I1007 00:28:57.782672  4081 solver.cpp:218] Iteration 77100 (11.9746 iter/s, 8.351s/100 iters), loss = 0.00889608
I1007 00:28:57.782704  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0088958 (* 1 = 0.0088958 loss)
I1007 00:28:57.782711  4081 sgd_solver.cpp:105] Iteration 77100, lr = 0.01
I1007 00:29:06.125257  4081 solver.cpp:218] Iteration 77200 (11.9868 iter/s, 8.34253s/100 iters), loss = 0.00238412
I1007 00:29:06.125414  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00238384 (* 1 = 0.00238384 loss)
I1007 00:29:06.125423  4081 sgd_solver.cpp:105] Iteration 77200, lr = 0.01
I1007 00:29:14.468593  4081 solver.cpp:218] Iteration 77300 (11.9859 iter/s, 8.34316s/100 iters), loss = 0.00196136
I1007 00:29:14.468623  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00196107 (* 1 = 0.00196107 loss)
I1007 00:29:14.468631  4081 sgd_solver.cpp:105] Iteration 77300, lr = 0.01
I1007 00:29:22.813077  4081 solver.cpp:218] Iteration 77400 (11.984 iter/s, 8.34443s/100 iters), loss = 0.0048073
I1007 00:29:22.813107  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.004807 (* 1 = 0.004807 loss)
I1007 00:29:22.813124  4081 sgd_solver.cpp:105] Iteration 77400, lr = 0.01
I1007 00:29:30.737824  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:29:31.071488  4081 solver.cpp:330] Iteration 77500, Testing net (#0)
I1007 00:29:33.000663  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:29:33.081449  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9024
I1007 00:29:33.081485  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.450042 (* 1 = 0.450042 loss)
I1007 00:29:33.164721  4081 solver.cpp:218] Iteration 77500 (9.66036 iter/s, 10.3516s/100 iters), loss = 0.00290941
I1007 00:29:33.164744  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00290911 (* 1 = 0.00290911 loss)
I1007 00:29:33.164752  4081 sgd_solver.cpp:105] Iteration 77500, lr = 0.01
I1007 00:29:41.513649  4081 solver.cpp:218] Iteration 77600 (11.9777 iter/s, 8.34888s/100 iters), loss = 0.0049891
I1007 00:29:41.513764  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00498881 (* 1 = 0.00498881 loss)
I1007 00:29:41.513782  4081 sgd_solver.cpp:105] Iteration 77600, lr = 0.01
I1007 00:29:49.862179  4081 solver.cpp:218] Iteration 77700 (11.9783 iter/s, 8.3484s/100 iters), loss = 0.0121717
I1007 00:29:49.862218  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0121714 (* 1 = 0.0121714 loss)
I1007 00:29:49.862226  4081 sgd_solver.cpp:105] Iteration 77700, lr = 0.01
I1007 00:29:58.210711  4081 solver.cpp:218] Iteration 77800 (11.9782 iter/s, 8.34847s/100 iters), loss = 0.00279579
I1007 00:29:58.210750  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00279549 (* 1 = 0.00279549 loss)
I1007 00:29:58.210757  4081 sgd_solver.cpp:105] Iteration 77800, lr = 0.01
I1007 00:30:06.559676  4081 solver.cpp:218] Iteration 77900 (11.9776 iter/s, 8.3489s/100 iters), loss = 0.0030766
I1007 00:30:06.559707  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0030763 (* 1 = 0.0030763 loss)
I1007 00:30:06.559713  4081 sgd_solver.cpp:105] Iteration 77900, lr = 0.01
I1007 00:30:14.494974  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:30:14.829146  4081 solver.cpp:330] Iteration 78000, Testing net (#0)
I1007 00:30:16.760342  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:30:16.841328  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8999
I1007 00:30:16.841362  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.44657 (* 1 = 0.44657 loss)
I1007 00:30:16.924721  4081 solver.cpp:218] Iteration 78000 (9.64786 iter/s, 10.365s/100 iters), loss = 0.0282229
I1007 00:30:16.924747  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0282226 (* 1 = 0.0282226 loss)
I1007 00:30:16.924753  4081 sgd_solver.cpp:105] Iteration 78000, lr = 0.01
I1007 00:30:25.268690  4081 solver.cpp:218] Iteration 78100 (11.9848 iter/s, 8.34392s/100 iters), loss = 0.000727402
I1007 00:30:25.268733  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000727102 (* 1 = 0.000727102 loss)
I1007 00:30:25.268738  4081 sgd_solver.cpp:105] Iteration 78100, lr = 0.01
I1007 00:30:33.614150  4081 solver.cpp:218] Iteration 78200 (11.9827 iter/s, 8.34539s/100 iters), loss = 0.00439179
I1007 00:30:33.614181  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00439149 (* 1 = 0.00439149 loss)
I1007 00:30:33.614187  4081 sgd_solver.cpp:105] Iteration 78200, lr = 0.01
I1007 00:30:41.960049  4081 solver.cpp:218] Iteration 78300 (11.982 iter/s, 8.34585s/100 iters), loss = 0.00228754
I1007 00:30:41.960089  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00228724 (* 1 = 0.00228724 loss)
I1007 00:30:41.960096  4081 sgd_solver.cpp:105] Iteration 78300, lr = 0.01
I1007 00:30:50.303076  4081 solver.cpp:218] Iteration 78400 (11.9861 iter/s, 8.34296s/100 iters), loss = 0.00565163
I1007 00:30:50.303197  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00565132 (* 1 = 0.00565132 loss)
I1007 00:30:50.303215  4081 sgd_solver.cpp:105] Iteration 78400, lr = 0.01
I1007 00:30:58.233453  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:30:58.567886  4081 solver.cpp:330] Iteration 78500, Testing net (#0)
I1007 00:31:00.503093  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:31:00.583752  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9107
I1007 00:31:00.583788  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.388528 (* 1 = 0.388528 loss)
I1007 00:31:00.666987  4081 solver.cpp:218] Iteration 78500 (9.64899 iter/s, 10.3638s/100 iters), loss = 0.00190558
I1007 00:31:00.667017  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00190527 (* 1 = 0.00190527 loss)
I1007 00:31:00.667026  4081 sgd_solver.cpp:105] Iteration 78500, lr = 0.01
I1007 00:31:09.004820  4081 solver.cpp:218] Iteration 78600 (11.9936 iter/s, 8.33778s/100 iters), loss = 0.00669018
I1007 00:31:09.004849  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00668987 (* 1 = 0.00668987 loss)
I1007 00:31:09.004855  4081 sgd_solver.cpp:105] Iteration 78600, lr = 0.01
I1007 00:31:17.351218  4081 solver.cpp:218] Iteration 78700 (11.9813 iter/s, 8.34634s/100 iters), loss = 0.00185936
I1007 00:31:17.351248  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00185905 (* 1 = 0.00185905 loss)
I1007 00:31:17.351254  4081 sgd_solver.cpp:105] Iteration 78700, lr = 0.01
I1007 00:31:25.695258  4081 solver.cpp:218] Iteration 78800 (11.9847 iter/s, 8.34399s/100 iters), loss = 0.00626466
I1007 00:31:25.695363  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00626435 (* 1 = 0.00626435 loss)
I1007 00:31:25.695372  4081 sgd_solver.cpp:105] Iteration 78800, lr = 0.01
I1007 00:31:34.031236  4081 solver.cpp:218] Iteration 78900 (11.9964 iter/s, 8.33585s/100 iters), loss = 0.001214
I1007 00:31:34.031276  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0012137 (* 1 = 0.0012137 loss)
I1007 00:31:34.031282  4081 sgd_solver.cpp:105] Iteration 78900, lr = 0.01
I1007 00:31:41.959142  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:31:42.292965  4081 solver.cpp:330] Iteration 79000, Testing net (#0)
I1007 00:31:44.225282  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:31:44.305965  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9074
I1007 00:31:44.305991  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.395658 (* 1 = 0.395658 loss)
I1007 00:31:44.389248  4081 solver.cpp:218] Iteration 79000 (9.65443 iter/s, 10.3579s/100 iters), loss = 0.0290416
I1007 00:31:44.389274  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0290413 (* 1 = 0.0290413 loss)
I1007 00:31:44.389281  4081 sgd_solver.cpp:105] Iteration 79000, lr = 0.01
I1007 00:31:52.727885  4081 solver.cpp:218] Iteration 79100 (11.9924 iter/s, 8.33859s/100 iters), loss = 0.0146745
I1007 00:31:52.727924  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0146742 (* 1 = 0.0146742 loss)
I1007 00:31:52.727931  4081 sgd_solver.cpp:105] Iteration 79100, lr = 0.01
I1007 00:32:01.073004  4081 solver.cpp:218] Iteration 79200 (11.9831 iter/s, 8.34506s/100 iters), loss = 0.00231406
I1007 00:32:01.073107  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00231376 (* 1 = 0.00231376 loss)
I1007 00:32:01.073118  4081 sgd_solver.cpp:105] Iteration 79200, lr = 0.01
I1007 00:32:09.408174  4081 solver.cpp:218] Iteration 79300 (11.9975 iter/s, 8.33505s/100 iters), loss = 0.00135912
I1007 00:32:09.408205  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00135882 (* 1 = 0.00135882 loss)
I1007 00:32:09.408211  4081 sgd_solver.cpp:105] Iteration 79300, lr = 0.01
I1007 00:32:17.747004  4081 solver.cpp:218] Iteration 79400 (11.9922 iter/s, 8.33878s/100 iters), loss = 0.00203139
I1007 00:32:17.747035  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00203109 (* 1 = 0.00203109 loss)
I1007 00:32:17.747041  4081 sgd_solver.cpp:105] Iteration 79400, lr = 0.01
I1007 00:32:25.671109  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:32:26.004349  4081 solver.cpp:330] Iteration 79500, Testing net (#0)
I1007 00:32:27.936125  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:32:28.017310  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9022
I1007 00:32:28.017345  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.436004 (* 1 = 0.436004 loss)
I1007 00:32:28.100502  4081 solver.cpp:218] Iteration 79500 (9.65863 iter/s, 10.3534s/100 iters), loss = 0.00163244
I1007 00:32:28.100527  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00163214 (* 1 = 0.00163214 loss)
I1007 00:32:28.100533  4081 sgd_solver.cpp:105] Iteration 79500, lr = 0.01
I1007 00:32:36.446748  4081 solver.cpp:218] Iteration 79600 (11.9815 iter/s, 8.3462s/100 iters), loss = 0.00663915
I1007 00:32:36.446858  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00663885 (* 1 = 0.00663885 loss)
I1007 00:32:36.446866  4081 sgd_solver.cpp:105] Iteration 79600, lr = 0.01
I1007 00:32:44.798920  4081 solver.cpp:218] Iteration 79700 (11.9731 iter/s, 8.35204s/100 iters), loss = 0.00605536
I1007 00:32:44.798951  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00605505 (* 1 = 0.00605505 loss)
I1007 00:32:44.798959  4081 sgd_solver.cpp:105] Iteration 79700, lr = 0.01
I1007 00:32:53.147725  4081 solver.cpp:218] Iteration 79800 (11.9778 iter/s, 8.34875s/100 iters), loss = 0.00460919
I1007 00:32:53.147764  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00460889 (* 1 = 0.00460889 loss)
I1007 00:32:53.147770  4081 sgd_solver.cpp:105] Iteration 79800, lr = 0.01
I1007 00:33:01.505388  4081 solver.cpp:218] Iteration 79900 (11.9652 iter/s, 8.3576s/100 iters), loss = 0.000539252
I1007 00:33:01.505419  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000538951 (* 1 = 0.000538951 loss)
I1007 00:33:01.505424  4081 sgd_solver.cpp:105] Iteration 79900, lr = 0.01
I1007 00:33:09.437769  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:33:09.773478  4081 solver.cpp:330] Iteration 80000, Testing net (#0)
I1007 00:33:11.705318  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:33:11.786190  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9142
I1007 00:33:11.786216  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.366962 (* 1 = 0.366962 loss)
I1007 00:33:11.869848  4081 solver.cpp:218] Iteration 80000 (9.64841 iter/s, 10.3644s/100 iters), loss = 0.00465303
I1007 00:33:11.869877  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00465273 (* 1 = 0.00465273 loss)
I1007 00:33:11.869884  4081 sgd_solver.cpp:46] MultiStep Status: Iteration 80000, step = 2
I1007 00:33:11.869887  4081 sgd_solver.cpp:105] Iteration 80000, lr = 0.001
I1007 00:33:20.214536  4081 solver.cpp:218] Iteration 80100 (11.9837 iter/s, 8.34464s/100 iters), loss = 0.00202812
I1007 00:33:20.214578  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00202781 (* 1 = 0.00202781 loss)
I1007 00:33:20.214584  4081 sgd_solver.cpp:105] Iteration 80100, lr = 0.001
I1007 00:33:28.564916  4081 solver.cpp:218] Iteration 80200 (11.9756 iter/s, 8.35031s/100 iters), loss = 0.0168403
I1007 00:33:28.564947  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.01684 (* 1 = 0.01684 loss)
I1007 00:33:28.564954  4081 sgd_solver.cpp:105] Iteration 80200, lr = 0.001
I1007 00:33:36.911059  4081 solver.cpp:218] Iteration 80300 (11.9817 iter/s, 8.34609s/100 iters), loss = 0.00484838
I1007 00:33:36.911100  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00484808 (* 1 = 0.00484808 loss)
I1007 00:33:36.911106  4081 sgd_solver.cpp:105] Iteration 80300, lr = 0.001
I1007 00:33:45.255187  4081 solver.cpp:218] Iteration 80400 (11.9846 iter/s, 8.34406s/100 iters), loss = 0.00893904
I1007 00:33:45.255324  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00893874 (* 1 = 0.00893874 loss)
I1007 00:33:45.255332  4081 sgd_solver.cpp:105] Iteration 80400, lr = 0.001
I1007 00:33:53.178771  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:33:53.513036  4081 solver.cpp:330] Iteration 80500, Testing net (#0)
I1007 00:33:55.447120  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:33:55.528208  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9185
I1007 00:33:55.528244  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.353758 (* 1 = 0.353758 loss)
I1007 00:33:55.611431  4081 solver.cpp:218] Iteration 80500 (9.65615 iter/s, 10.3561s/100 iters), loss = 0.00622663
I1007 00:33:55.611456  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00622633 (* 1 = 0.00622633 loss)
I1007 00:33:55.611464  4081 sgd_solver.cpp:105] Iteration 80500, lr = 0.001
I1007 00:34:03.949422  4081 solver.cpp:218] Iteration 80600 (11.9934 iter/s, 8.33794s/100 iters), loss = 0.00359674
I1007 00:34:03.949452  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00359642 (* 1 = 0.00359642 loss)
I1007 00:34:03.949458  4081 sgd_solver.cpp:105] Iteration 80600, lr = 0.001
I1007 00:34:12.280526  4081 solver.cpp:218] Iteration 80700 (12.0033 iter/s, 8.33105s/100 iters), loss = 0.0120353
I1007 00:34:12.280562  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.012035 (* 1 = 0.012035 loss)
I1007 00:34:12.280570  4081 sgd_solver.cpp:105] Iteration 80700, lr = 0.001
I1007 00:34:20.614078  4081 solver.cpp:218] Iteration 80800 (11.9998 iter/s, 8.33349s/100 iters), loss = 0.00107969
I1007 00:34:20.614228  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00107938 (* 1 = 0.00107938 loss)
I1007 00:34:20.614236  4081 sgd_solver.cpp:105] Iteration 80800, lr = 0.001
I1007 00:34:28.950184  4081 solver.cpp:218] Iteration 80900 (11.9963 iter/s, 8.33594s/100 iters), loss = 0.00105048
I1007 00:34:28.950224  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00105017 (* 1 = 0.00105017 loss)
I1007 00:34:28.950230  4081 sgd_solver.cpp:105] Iteration 80900, lr = 0.001
I1007 00:34:36.871137  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:34:37.206221  4081 solver.cpp:330] Iteration 81000, Testing net (#0)
I1007 00:34:39.136049  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:34:39.216449  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9192
I1007 00:34:39.216483  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.345659 (* 1 = 0.345659 loss)
I1007 00:34:39.299314  4081 solver.cpp:218] Iteration 81000 (9.66271 iter/s, 10.3491s/100 iters), loss = 0.00206704
I1007 00:34:39.299350  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00206673 (* 1 = 0.00206673 loss)
I1007 00:34:39.299358  4081 sgd_solver.cpp:105] Iteration 81000, lr = 0.001
I1007 00:34:47.634627  4081 solver.cpp:218] Iteration 81100 (11.9972 iter/s, 8.33525s/100 iters), loss = 0.0264288
I1007 00:34:47.634656  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0264285 (* 1 = 0.0264285 loss)
I1007 00:34:47.634661  4081 sgd_solver.cpp:105] Iteration 81100, lr = 0.001
I1007 00:34:55.962956  4081 solver.cpp:218] Iteration 81200 (12.0073 iter/s, 8.32828s/100 iters), loss = 0.00208365
I1007 00:34:55.963078  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00208334 (* 1 = 0.00208334 loss)
I1007 00:34:55.963084  4081 sgd_solver.cpp:105] Iteration 81200, lr = 0.001
I1007 00:35:04.290195  4081 solver.cpp:218] Iteration 81300 (12.009 iter/s, 8.3271s/100 iters), loss = 0.00288387
I1007 00:35:04.290236  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00288356 (* 1 = 0.00288356 loss)
I1007 00:35:04.290242  4081 sgd_solver.cpp:105] Iteration 81300, lr = 0.001
I1007 00:35:12.613422  4081 solver.cpp:218] Iteration 81400 (12.0147 iter/s, 8.32316s/100 iters), loss = 0.00202815
I1007 00:35:12.613459  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00202784 (* 1 = 0.00202784 loss)
I1007 00:35:12.613466  4081 sgd_solver.cpp:105] Iteration 81400, lr = 0.001
I1007 00:35:20.532642  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:35:20.866585  4081 solver.cpp:330] Iteration 81500, Testing net (#0)
I1007 00:35:22.796772  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:35:22.877740  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9199
I1007 00:35:22.877780  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.345954 (* 1 = 0.345954 loss)
I1007 00:35:22.960049  4081 solver.cpp:218] Iteration 81500 (9.66504 iter/s, 10.3466s/100 iters), loss = 0.0036002
I1007 00:35:22.960077  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00359989 (* 1 = 0.00359989 loss)
I1007 00:35:22.960084  4081 sgd_solver.cpp:105] Iteration 81500, lr = 0.001
I1007 00:35:31.301036  4081 solver.cpp:218] Iteration 81600 (11.9891 iter/s, 8.34094s/100 iters), loss = 0.00353798
I1007 00:35:31.301151  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00353768 (* 1 = 0.00353768 loss)
I1007 00:35:31.301167  4081 sgd_solver.cpp:105] Iteration 81600, lr = 0.001
I1007 00:35:39.637435  4081 solver.cpp:218] Iteration 81700 (11.9958 iter/s, 8.33627s/100 iters), loss = 0.00476817
I1007 00:35:39.637465  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00476786 (* 1 = 0.00476786 loss)
I1007 00:35:39.637471  4081 sgd_solver.cpp:105] Iteration 81700, lr = 0.001
I1007 00:35:47.973083  4081 solver.cpp:218] Iteration 81800 (11.9967 iter/s, 8.33559s/100 iters), loss = 0.000463245
I1007 00:35:47.973112  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000462933 (* 1 = 0.000462933 loss)
I1007 00:35:47.973117  4081 sgd_solver.cpp:105] Iteration 81800, lr = 0.001
I1007 00:35:56.308660  4081 solver.cpp:218] Iteration 81900 (11.9969 iter/s, 8.33552s/100 iters), loss = 0.00365837
I1007 00:35:56.308698  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00365806 (* 1 = 0.00365806 loss)
I1007 00:35:56.308706  4081 sgd_solver.cpp:105] Iteration 81900, lr = 0.001
I1007 00:36:04.236011  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:36:04.570011  4081 solver.cpp:330] Iteration 82000, Testing net (#0)
I1007 00:36:06.504246  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:36:06.585135  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9199
I1007 00:36:06.585170  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.34662 (* 1 = 0.34662 loss)
I1007 00:36:06.668733  4081 solver.cpp:218] Iteration 82000 (9.6525 iter/s, 10.36s/100 iters), loss = 0.00251359
I1007 00:36:06.668757  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00251329 (* 1 = 0.00251329 loss)
I1007 00:36:06.668764  4081 sgd_solver.cpp:105] Iteration 82000, lr = 0.001
I1007 00:36:15.007570  4081 solver.cpp:218] Iteration 82100 (11.9922 iter/s, 8.33879s/100 iters), loss = 0.00200012
I1007 00:36:15.007599  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00199981 (* 1 = 0.00199981 loss)
I1007 00:36:15.007606  4081 sgd_solver.cpp:105] Iteration 82100, lr = 0.001
I1007 00:36:23.345192  4081 solver.cpp:218] Iteration 82200 (11.9939 iter/s, 8.33757s/100 iters), loss = 0.00253324
I1007 00:36:23.345222  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00253294 (* 1 = 0.00253294 loss)
I1007 00:36:23.345238  4081 sgd_solver.cpp:105] Iteration 82200, lr = 0.001
I1007 00:36:31.680599  4081 solver.cpp:218] Iteration 82300 (11.9971 iter/s, 8.33535s/100 iters), loss = 0.00167602
I1007 00:36:31.680629  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00167571 (* 1 = 0.00167571 loss)
I1007 00:36:31.680634  4081 sgd_solver.cpp:105] Iteration 82300, lr = 0.001
I1007 00:36:40.018723  4081 solver.cpp:218] Iteration 82400 (11.9932 iter/s, 8.33807s/100 iters), loss = 0.000671471
I1007 00:36:40.018838  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000671166 (* 1 = 0.000671166 loss)
I1007 00:36:40.018846  4081 sgd_solver.cpp:105] Iteration 82400, lr = 0.001
I1007 00:36:47.938841  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:36:48.272446  4081 solver.cpp:330] Iteration 82500, Testing net (#0)
I1007 00:36:50.203851  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:36:50.284523  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.92
I1007 00:36:50.284559  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.348108 (* 1 = 0.348108 loss)
I1007 00:36:50.367945  4081 solver.cpp:218] Iteration 82500 (9.66269 iter/s, 10.3491s/100 iters), loss = 0.00895691
I1007 00:36:50.367970  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00895661 (* 1 = 0.00895661 loss)
I1007 00:36:50.367976  4081 sgd_solver.cpp:105] Iteration 82500, lr = 0.001
I1007 00:36:58.710992  4081 solver.cpp:218] Iteration 82600 (11.9861 iter/s, 8.343s/100 iters), loss = 0.0016869
I1007 00:36:58.711022  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0016866 (* 1 = 0.0016866 loss)
I1007 00:36:58.711028  4081 sgd_solver.cpp:105] Iteration 82600, lr = 0.001
I1007 00:37:07.058603  4081 solver.cpp:218] Iteration 82700 (11.9796 iter/s, 8.34756s/100 iters), loss = 0.00181931
I1007 00:37:07.058643  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00181901 (* 1 = 0.00181901 loss)
I1007 00:37:07.058650  4081 sgd_solver.cpp:105] Iteration 82700, lr = 0.001
I1007 00:37:15.410468  4081 solver.cpp:218] Iteration 82800 (11.9735 iter/s, 8.3518s/100 iters), loss = 0.00455815
I1007 00:37:15.410557  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00455785 (* 1 = 0.00455785 loss)
I1007 00:37:15.410573  4081 sgd_solver.cpp:105] Iteration 82800, lr = 0.001
I1007 00:37:23.755439  4081 solver.cpp:218] Iteration 82900 (11.9834 iter/s, 8.34486s/100 iters), loss = 0.00078672
I1007 00:37:23.755472  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00078642 (* 1 = 0.00078642 loss)
I1007 00:37:23.755479  4081 sgd_solver.cpp:105] Iteration 82900, lr = 0.001
I1007 00:37:31.686388  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:37:32.020444  4081 solver.cpp:330] Iteration 83000, Testing net (#0)
I1007 00:37:33.952313  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:37:34.033071  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9186
I1007 00:37:34.033105  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.352388 (* 1 = 0.352388 loss)
I1007 00:37:34.116215  4081 solver.cpp:218] Iteration 83000 (9.65184 iter/s, 10.3607s/100 iters), loss = 0.0314367
I1007 00:37:34.116240  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0314364 (* 1 = 0.0314364 loss)
I1007 00:37:34.116247  4081 sgd_solver.cpp:105] Iteration 83000, lr = 0.001
I1007 00:37:42.458830  4081 solver.cpp:218] Iteration 83100 (11.9867 iter/s, 8.34257s/100 iters), loss = 0.00308749
I1007 00:37:42.458878  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00308719 (* 1 = 0.00308719 loss)
I1007 00:37:42.458885  4081 sgd_solver.cpp:105] Iteration 83100, lr = 0.001
I1007 00:37:50.797042  4081 solver.cpp:218] Iteration 83200 (11.9931 iter/s, 8.33814s/100 iters), loss = 0.00198198
I1007 00:37:50.797206  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00198167 (* 1 = 0.00198167 loss)
I1007 00:37:50.797224  4081 sgd_solver.cpp:105] Iteration 83200, lr = 0.001
I1007 00:37:59.134011  4081 solver.cpp:218] Iteration 83300 (11.995 iter/s, 8.33678s/100 iters), loss = 0.00538555
I1007 00:37:59.134042  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00538525 (* 1 = 0.00538525 loss)
I1007 00:37:59.134047  4081 sgd_solver.cpp:105] Iteration 83300, lr = 0.001
I1007 00:38:07.475299  4081 solver.cpp:218] Iteration 83400 (11.9886 iter/s, 8.34123s/100 iters), loss = 0.00100454
I1007 00:38:07.475330  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00100425 (* 1 = 0.00100425 loss)
I1007 00:38:07.475337  4081 sgd_solver.cpp:105] Iteration 83400, lr = 0.001
I1007 00:38:15.408323  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:38:15.742314  4081 solver.cpp:330] Iteration 83500, Testing net (#0)
I1007 00:38:17.674000  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:38:17.754896  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9189
I1007 00:38:17.754932  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.349395 (* 1 = 0.349395 loss)
I1007 00:38:17.838572  4081 solver.cpp:218] Iteration 83500 (9.64952 iter/s, 10.3632s/100 iters), loss = 0.00132695
I1007 00:38:17.838596  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00132665 (* 1 = 0.00132665 loss)
I1007 00:38:17.838603  4081 sgd_solver.cpp:105] Iteration 83500, lr = 0.001
I1007 00:38:26.166767  4081 solver.cpp:218] Iteration 83600 (12.0075 iter/s, 8.32815s/100 iters), loss = 0.000583541
I1007 00:38:26.166883  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000583245 (* 1 = 0.000583245 loss)
I1007 00:38:26.166900  4081 sgd_solver.cpp:105] Iteration 83600, lr = 0.001
I1007 00:38:34.497750  4081 solver.cpp:218] Iteration 83700 (12.0036 iter/s, 8.33085s/100 iters), loss = 0.00343846
I1007 00:38:34.497778  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00343817 (* 1 = 0.00343817 loss)
I1007 00:38:34.497784  4081 sgd_solver.cpp:105] Iteration 83700, lr = 0.001
I1007 00:38:42.832039  4081 solver.cpp:218] Iteration 83800 (11.9987 iter/s, 8.33424s/100 iters), loss = 0.00168031
I1007 00:38:42.832078  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00168001 (* 1 = 0.00168001 loss)
I1007 00:38:42.832084  4081 sgd_solver.cpp:105] Iteration 83800, lr = 0.001
I1007 00:38:51.161604  4081 solver.cpp:218] Iteration 83900 (12.0055 iter/s, 8.3295s/100 iters), loss = 0.00142675
I1007 00:38:51.161644  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00142646 (* 1 = 0.00142646 loss)
I1007 00:38:51.161650  4081 sgd_solver.cpp:105] Iteration 83900, lr = 0.001
I1007 00:38:59.081569  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:38:59.414363  4081 solver.cpp:330] Iteration 84000, Testing net (#0)
I1007 00:39:01.348868  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:39:01.429944  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9192
I1007 00:39:01.429980  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.348261 (* 1 = 0.348261 loss)
I1007 00:39:01.513222  4081 solver.cpp:218] Iteration 84000 (9.66039 iter/s, 10.3516s/100 iters), loss = 0.00667969
I1007 00:39:01.513248  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0066794 (* 1 = 0.0066794 loss)
I1007 00:39:01.513254  4081 sgd_solver.cpp:105] Iteration 84000, lr = 0.001
I1007 00:39:09.850653  4081 solver.cpp:218] Iteration 84100 (11.9942 iter/s, 8.33738s/100 iters), loss = 0.000236005
I1007 00:39:09.850683  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000235714 (* 1 = 0.000235714 loss)
I1007 00:39:09.850689  4081 sgd_solver.cpp:105] Iteration 84100, lr = 0.001
I1007 00:39:18.189751  4081 solver.cpp:218] Iteration 84200 (11.9918 iter/s, 8.33904s/100 iters), loss = 0.00115582
I1007 00:39:18.189780  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00115553 (* 1 = 0.00115553 loss)
I1007 00:39:18.189786  4081 sgd_solver.cpp:105] Iteration 84200, lr = 0.001
I1007 00:39:26.530212  4081 solver.cpp:218] Iteration 84300 (11.9898 iter/s, 8.34041s/100 iters), loss = 0.00166917
I1007 00:39:26.530242  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00166887 (* 1 = 0.00166887 loss)
I1007 00:39:26.530248  4081 sgd_solver.cpp:105] Iteration 84300, lr = 0.001
I1007 00:39:34.872413  4081 solver.cpp:218] Iteration 84400 (11.9873 iter/s, 8.34215s/100 iters), loss = 0.000465875
I1007 00:39:34.872553  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000465584 (* 1 = 0.000465584 loss)
I1007 00:39:34.872560  4081 sgd_solver.cpp:105] Iteration 84400, lr = 0.001
I1007 00:39:42.808605  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:39:43.144186  4081 solver.cpp:330] Iteration 84500, Testing net (#0)
I1007 00:39:45.076241  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:39:45.158136  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9201
I1007 00:39:45.158171  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.348615 (* 1 = 0.348615 loss)
I1007 00:39:45.240856  4081 solver.cpp:218] Iteration 84500 (9.6448 iter/s, 10.3683s/100 iters), loss = 0.00147924
I1007 00:39:45.240890  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00147895 (* 1 = 0.00147895 loss)
I1007 00:39:45.240898  4081 sgd_solver.cpp:105] Iteration 84500, lr = 0.001
I1007 00:39:53.571168  4081 solver.cpp:218] Iteration 84600 (12.0044 iter/s, 8.33025s/100 iters), loss = 0.00154548
I1007 00:39:53.571208  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00154519 (* 1 = 0.00154519 loss)
I1007 00:39:53.571213  4081 sgd_solver.cpp:105] Iteration 84600, lr = 0.001
I1007 00:40:01.904141  4081 solver.cpp:218] Iteration 84700 (12.0006 iter/s, 8.33291s/100 iters), loss = 0.000715453
I1007 00:40:01.904182  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000715165 (* 1 = 0.000715165 loss)
I1007 00:40:01.904187  4081 sgd_solver.cpp:105] Iteration 84700, lr = 0.001
I1007 00:40:10.239747  4081 solver.cpp:218] Iteration 84800 (11.9968 iter/s, 8.33554s/100 iters), loss = 0.00205783
I1007 00:40:10.239895  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00205755 (* 1 = 0.00205755 loss)
I1007 00:40:10.239904  4081 sgd_solver.cpp:105] Iteration 84800, lr = 0.001
I1007 00:40:18.578986  4081 solver.cpp:218] Iteration 84900 (11.9917 iter/s, 8.33907s/100 iters), loss = 0.00239554
I1007 00:40:18.579016  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00239525 (* 1 = 0.00239525 loss)
I1007 00:40:18.579022  4081 sgd_solver.cpp:105] Iteration 84900, lr = 0.001
I1007 00:40:26.502681  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:40:26.837110  4081 solver.cpp:330] Iteration 85000, Testing net (#0)
I1007 00:40:28.769182  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:40:28.849802  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.92
I1007 00:40:28.849838  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.347008 (* 1 = 0.347008 loss)
I1007 00:40:28.933130  4081 solver.cpp:218] Iteration 85000 (9.65802 iter/s, 10.3541s/100 iters), loss = 0.0275166
I1007 00:40:28.933156  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0275163 (* 1 = 0.0275163 loss)
I1007 00:40:28.933162  4081 sgd_solver.cpp:105] Iteration 85000, lr = 0.001
I1007 00:40:37.281433  4081 solver.cpp:218] Iteration 85100 (11.9786 iter/s, 8.34825s/100 iters), loss = 0.0159094
I1007 00:40:37.281464  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0159091 (* 1 = 0.0159091 loss)
I1007 00:40:37.281471  4081 sgd_solver.cpp:105] Iteration 85100, lr = 0.001
I1007 00:40:45.635498  4081 solver.cpp:218] Iteration 85200 (11.9703 iter/s, 8.35401s/100 iters), loss = 0.00129672
I1007 00:40:45.635623  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00129644 (* 1 = 0.00129644 loss)
I1007 00:40:45.635630  4081 sgd_solver.cpp:105] Iteration 85200, lr = 0.001
I1007 00:40:53.984683  4081 solver.cpp:218] Iteration 85300 (11.9774 iter/s, 8.34904s/100 iters), loss = 0.00778518
I1007 00:40:53.984722  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0077849 (* 1 = 0.0077849 loss)
I1007 00:40:53.984728  4081 sgd_solver.cpp:105] Iteration 85300, lr = 0.001
I1007 00:41:02.338335  4081 solver.cpp:218] Iteration 85400 (11.9709 iter/s, 8.35359s/100 iters), loss = 0.00114114
I1007 00:41:02.338366  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00114085 (* 1 = 0.00114085 loss)
I1007 00:41:02.338371  4081 sgd_solver.cpp:105] Iteration 85400, lr = 0.001
I1007 00:41:10.274647  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:41:10.608055  4081 solver.cpp:330] Iteration 85500, Testing net (#0)
I1007 00:41:12.538835  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:41:12.619627  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9201
I1007 00:41:12.619663  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.34834 (* 1 = 0.34834 loss)
I1007 00:41:12.702759  4081 solver.cpp:218] Iteration 85500 (9.64844 iter/s, 10.3644s/100 iters), loss = 0.00110714
I1007 00:41:12.702785  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00110685 (* 1 = 0.00110685 loss)
I1007 00:41:12.702790  4081 sgd_solver.cpp:105] Iteration 85500, lr = 0.001
I1007 00:41:21.044692  4081 solver.cpp:218] Iteration 85600 (11.9877 iter/s, 8.34188s/100 iters), loss = 0.00645016
I1007 00:41:21.044800  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00644987 (* 1 = 0.00644987 loss)
I1007 00:41:21.044806  4081 sgd_solver.cpp:105] Iteration 85600, lr = 0.001
I1007 00:41:29.392277  4081 solver.cpp:218] Iteration 85700 (11.9797 iter/s, 8.34745s/100 iters), loss = 0.00376423
I1007 00:41:29.392318  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00376395 (* 1 = 0.00376395 loss)
I1007 00:41:29.392323  4081 sgd_solver.cpp:105] Iteration 85700, lr = 0.001
I1007 00:41:37.736994  4081 solver.cpp:218] Iteration 85800 (11.9837 iter/s, 8.34465s/100 iters), loss = 0.000767062
I1007 00:41:37.737022  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000766773 (* 1 = 0.000766773 loss)
I1007 00:41:37.737028  4081 sgd_solver.cpp:105] Iteration 85800, lr = 0.001
I1007 00:41:46.084897  4081 solver.cpp:218] Iteration 85900 (11.9791 iter/s, 8.34785s/100 iters), loss = 0.00054506
I1007 00:41:46.084926  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000544771 (* 1 = 0.000544771 loss)
I1007 00:41:46.084933  4081 sgd_solver.cpp:105] Iteration 85900, lr = 0.001
I1007 00:41:54.014123  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:41:54.348687  4081 solver.cpp:330] Iteration 86000, Testing net (#0)
I1007 00:41:56.282542  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:41:56.364217  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9199
I1007 00:41:56.364243  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.348252 (* 1 = 0.348252 loss)
I1007 00:41:56.447754  4081 solver.cpp:218] Iteration 86000 (9.6499 iter/s, 10.3628s/100 iters), loss = 0.00163123
I1007 00:41:56.447779  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00163095 (* 1 = 0.00163095 loss)
I1007 00:41:56.447787  4081 sgd_solver.cpp:105] Iteration 86000, lr = 0.001
I1007 00:42:04.793951  4081 solver.cpp:218] Iteration 86100 (11.9816 iter/s, 8.34615s/100 iters), loss = 0.00184908
I1007 00:42:04.793980  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00184879 (* 1 = 0.00184879 loss)
I1007 00:42:04.793987  4081 sgd_solver.cpp:105] Iteration 86100, lr = 0.001
I1007 00:42:13.142366  4081 solver.cpp:218] Iteration 86200 (11.9784 iter/s, 8.34836s/100 iters), loss = 0.00646317
I1007 00:42:13.142395  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00646289 (* 1 = 0.00646289 loss)
I1007 00:42:13.142401  4081 sgd_solver.cpp:105] Iteration 86200, lr = 0.001
I1007 00:42:21.490141  4081 solver.cpp:218] Iteration 86300 (11.9793 iter/s, 8.34772s/100 iters), loss = 0.00159252
I1007 00:42:21.490180  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00159223 (* 1 = 0.00159223 loss)
I1007 00:42:21.490186  4081 sgd_solver.cpp:105] Iteration 86300, lr = 0.001
I1007 00:42:29.829584  4081 solver.cpp:218] Iteration 86400 (11.9913 iter/s, 8.33938s/100 iters), loss = 0.000842268
I1007 00:42:29.829707  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000841979 (* 1 = 0.000841979 loss)
I1007 00:42:29.829715  4081 sgd_solver.cpp:105] Iteration 86400, lr = 0.001
I1007 00:42:37.756824  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:42:38.089735  4081 solver.cpp:330] Iteration 86500, Testing net (#0)
I1007 00:42:40.021018  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:42:40.101797  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9206
I1007 00:42:40.101832  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.34827 (* 1 = 0.34827 loss)
I1007 00:42:40.185470  4081 solver.cpp:218] Iteration 86500 (9.65647 iter/s, 10.3557s/100 iters), loss = 0.000586607
I1007 00:42:40.185497  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000586319 (* 1 = 0.000586319 loss)
I1007 00:42:40.185503  4081 sgd_solver.cpp:105] Iteration 86500, lr = 0.001
I1007 00:42:48.525084  4081 solver.cpp:218] Iteration 86600 (11.991 iter/s, 8.33956s/100 iters), loss = 0.000943034
I1007 00:42:48.525112  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000942747 (* 1 = 0.000942747 loss)
I1007 00:42:48.525118  4081 sgd_solver.cpp:105] Iteration 86600, lr = 0.001
I1007 00:42:56.868820  4081 solver.cpp:218] Iteration 86700 (11.9851 iter/s, 8.34368s/100 iters), loss = 0.00222104
I1007 00:42:56.868861  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00222075 (* 1 = 0.00222075 loss)
I1007 00:42:56.868867  4081 sgd_solver.cpp:105] Iteration 86700, lr = 0.001
I1007 00:43:05.212615  4081 solver.cpp:218] Iteration 86800 (11.985 iter/s, 8.34373s/100 iters), loss = 0.00263592
I1007 00:43:05.212698  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00263563 (* 1 = 0.00263563 loss)
I1007 00:43:05.212716  4081 sgd_solver.cpp:105] Iteration 86800, lr = 0.001
I1007 00:43:13.556733  4081 solver.cpp:218] Iteration 86900 (11.9846 iter/s, 8.34401s/100 iters), loss = 0.000538872
I1007 00:43:13.556777  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000538585 (* 1 = 0.000538585 loss)
I1007 00:43:13.556785  4081 sgd_solver.cpp:105] Iteration 86900, lr = 0.001
I1007 00:43:21.487437  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:43:21.821285  4081 solver.cpp:330] Iteration 87000, Testing net (#0)
I1007 00:43:23.752307  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:43:23.833580  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9199
I1007 00:43:23.833616  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.347787 (* 1 = 0.347787 loss)
I1007 00:43:23.917052  4081 solver.cpp:218] Iteration 87000 (9.65228 iter/s, 10.3602s/100 iters), loss = 0.00211881
I1007 00:43:23.917076  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00211853 (* 1 = 0.00211853 loss)
I1007 00:43:23.917083  4081 sgd_solver.cpp:105] Iteration 87000, lr = 0.001
I1007 00:43:32.251058  4081 solver.cpp:218] Iteration 87100 (11.9991 iter/s, 8.33396s/100 iters), loss = 0.000884409
I1007 00:43:32.251088  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00088412 (* 1 = 0.00088412 loss)
I1007 00:43:32.251094  4081 sgd_solver.cpp:105] Iteration 87100, lr = 0.001
I1007 00:43:40.581048  4081 solver.cpp:218] Iteration 87200 (12.0049 iter/s, 8.32993s/100 iters), loss = 0.00361496
I1007 00:43:40.581207  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00361467 (* 1 = 0.00361467 loss)
I1007 00:43:40.581224  4081 sgd_solver.cpp:105] Iteration 87200, lr = 0.001
I1007 00:43:48.907142  4081 solver.cpp:218] Iteration 87300 (12.0107 iter/s, 8.32591s/100 iters), loss = 0.00147085
I1007 00:43:48.907174  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00147056 (* 1 = 0.00147056 loss)
I1007 00:43:48.907181  4081 sgd_solver.cpp:105] Iteration 87300, lr = 0.001
I1007 00:43:57.240968  4081 solver.cpp:218] Iteration 87400 (11.9994 iter/s, 8.33377s/100 iters), loss = 0.001653
I1007 00:43:57.240999  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00165271 (* 1 = 0.00165271 loss)
I1007 00:43:57.241015  4081 sgd_solver.cpp:105] Iteration 87400, lr = 0.001
I1007 00:44:05.153517  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:44:05.489388  4081 solver.cpp:330] Iteration 87500, Testing net (#0)
I1007 00:44:07.419384  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:44:07.500303  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9206
I1007 00:44:07.500337  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.347127 (* 1 = 0.347127 loss)
I1007 00:44:07.583544  4081 solver.cpp:218] Iteration 87500 (9.66882 iter/s, 10.3425s/100 iters), loss = 0.00217835
I1007 00:44:07.583570  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00217806 (* 1 = 0.00217806 loss)
I1007 00:44:07.583577  4081 sgd_solver.cpp:105] Iteration 87500, lr = 0.001
I1007 00:44:15.915844  4081 solver.cpp:218] Iteration 87600 (12.0016 iter/s, 8.33225s/100 iters), loss = 0.00110739
I1007 00:44:15.915967  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0011071 (* 1 = 0.0011071 loss)
I1007 00:44:15.915984  4081 sgd_solver.cpp:105] Iteration 87600, lr = 0.001
I1007 00:44:24.248226  4081 solver.cpp:218] Iteration 87700 (12.0016 iter/s, 8.33224s/100 iters), loss = 0.00168228
I1007 00:44:24.248267  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00168199 (* 1 = 0.00168199 loss)
I1007 00:44:24.248275  4081 sgd_solver.cpp:105] Iteration 87700, lr = 0.001
I1007 00:44:32.583552  4081 solver.cpp:218] Iteration 87800 (11.9972 iter/s, 8.33526s/100 iters), loss = 0.00374533
I1007 00:44:32.583590  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00374504 (* 1 = 0.00374504 loss)
I1007 00:44:32.583596  4081 sgd_solver.cpp:105] Iteration 87800, lr = 0.001
I1007 00:44:40.923363  4081 solver.cpp:218] Iteration 87900 (11.9908 iter/s, 8.33975s/100 iters), loss = 0.000355466
I1007 00:44:40.923393  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000355175 (* 1 = 0.000355175 loss)
I1007 00:44:40.923400  4081 sgd_solver.cpp:105] Iteration 87900, lr = 0.001
I1007 00:44:48.848786  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:44:49.181027  4081 solver.cpp:330] Iteration 88000, Testing net (#0)
I1007 00:44:51.111968  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:44:51.193167  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9203
I1007 00:44:51.193202  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.347881 (* 1 = 0.347881 loss)
I1007 00:44:51.277055  4081 solver.cpp:218] Iteration 88000 (9.65845 iter/s, 10.3536s/100 iters), loss = 0.000525079
I1007 00:44:51.277091  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000524789 (* 1 = 0.000524789 loss)
I1007 00:44:51.277099  4081 sgd_solver.cpp:105] Iteration 88000, lr = 0.001
I1007 00:44:59.617403  4081 solver.cpp:218] Iteration 88100 (11.99 iter/s, 8.34029s/100 iters), loss = 0.0067533
I1007 00:44:59.617441  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00675301 (* 1 = 0.00675301 loss)
I1007 00:44:59.617447  4081 sgd_solver.cpp:105] Iteration 88100, lr = 0.001
I1007 00:45:07.956212  4081 solver.cpp:218] Iteration 88200 (11.9922 iter/s, 8.33875s/100 iters), loss = 0.00205807
I1007 00:45:07.956241  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00205778 (* 1 = 0.00205778 loss)
I1007 00:45:07.956248  4081 sgd_solver.cpp:105] Iteration 88200, lr = 0.001
I1007 00:45:16.295840  4081 solver.cpp:218] Iteration 88300 (11.991 iter/s, 8.33957s/100 iters), loss = 0.00148543
I1007 00:45:16.295871  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00148514 (* 1 = 0.00148514 loss)
I1007 00:45:16.295877  4081 sgd_solver.cpp:105] Iteration 88300, lr = 0.001
I1007 00:45:24.633352  4081 solver.cpp:218] Iteration 88400 (11.9941 iter/s, 8.33746s/100 iters), loss = 0.00126422
I1007 00:45:24.633466  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00126393 (* 1 = 0.00126393 loss)
I1007 00:45:24.633482  4081 sgd_solver.cpp:105] Iteration 88400, lr = 0.001
I1007 00:45:32.559196  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:45:32.892179  4081 solver.cpp:330] Iteration 88500, Testing net (#0)
I1007 00:45:34.822981  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:45:34.903995  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.92
I1007 00:45:34.904031  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.348327 (* 1 = 0.348327 loss)
I1007 00:45:34.987138  4081 solver.cpp:218] Iteration 88500 (9.65842 iter/s, 10.3537s/100 iters), loss = 0.000331517
I1007 00:45:34.987162  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000331229 (* 1 = 0.000331229 loss)
I1007 00:45:34.987172  4081 sgd_solver.cpp:105] Iteration 88500, lr = 0.001
I1007 00:45:43.325954  4081 solver.cpp:218] Iteration 88600 (11.9922 iter/s, 8.33877s/100 iters), loss = 0.000694324
I1007 00:45:43.325984  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000694035 (* 1 = 0.000694035 loss)
I1007 00:45:43.325989  4081 sgd_solver.cpp:105] Iteration 88600, lr = 0.001
I1007 00:45:51.671281  4081 solver.cpp:218] Iteration 88700 (11.9828 iter/s, 8.34527s/100 iters), loss = 0.00403867
I1007 00:45:51.671321  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00403838 (* 1 = 0.00403838 loss)
I1007 00:45:51.671327  4081 sgd_solver.cpp:105] Iteration 88700, lr = 0.001
I1007 00:46:00.013852  4081 solver.cpp:218] Iteration 88800 (11.9868 iter/s, 8.34251s/100 iters), loss = 0.00466583
I1007 00:46:00.013964  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00466554 (* 1 = 0.00466554 loss)
I1007 00:46:00.013970  4081 sgd_solver.cpp:105] Iteration 88800, lr = 0.001
I1007 00:46:08.352619  4081 solver.cpp:218] Iteration 88900 (11.9924 iter/s, 8.33864s/100 iters), loss = 0.00288646
I1007 00:46:08.352658  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00288617 (* 1 = 0.00288617 loss)
I1007 00:46:08.352663  4081 sgd_solver.cpp:105] Iteration 88900, lr = 0.001
I1007 00:46:16.275122  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:46:16.609417  4081 solver.cpp:330] Iteration 89000, Testing net (#0)
I1007 00:46:18.538805  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:46:18.620015  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9206
I1007 00:46:18.620049  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.348137 (* 1 = 0.348137 loss)
I1007 00:46:18.703303  4081 solver.cpp:218] Iteration 89000 (9.66126 iter/s, 10.3506s/100 iters), loss = 0.00628546
I1007 00:46:18.703332  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00628518 (* 1 = 0.00628518 loss)
I1007 00:46:18.703339  4081 sgd_solver.cpp:105] Iteration 89000, lr = 0.001
I1007 00:46:27.048416  4081 solver.cpp:218] Iteration 89100 (11.9831 iter/s, 8.34506s/100 iters), loss = 0.000555323
I1007 00:46:27.048457  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000555037 (* 1 = 0.000555037 loss)
I1007 00:46:27.048472  4081 sgd_solver.cpp:105] Iteration 89100, lr = 0.001
I1007 00:46:35.390030  4081 solver.cpp:218] Iteration 89200 (11.9882 iter/s, 8.34155s/100 iters), loss = 0.00219277
I1007 00:46:35.390157  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00219249 (* 1 = 0.00219249 loss)
I1007 00:46:35.390164  4081 sgd_solver.cpp:105] Iteration 89200, lr = 0.001
I1007 00:46:43.733279  4081 solver.cpp:218] Iteration 89300 (11.986 iter/s, 8.3431s/100 iters), loss = 0.00102452
I1007 00:46:43.733309  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00102424 (* 1 = 0.00102424 loss)
I1007 00:46:43.733314  4081 sgd_solver.cpp:105] Iteration 89300, lr = 0.001
I1007 00:46:52.074196  4081 solver.cpp:218] Iteration 89400 (11.9892 iter/s, 8.34086s/100 iters), loss = 0.00100365
I1007 00:46:52.074236  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00100336 (* 1 = 0.00100336 loss)
I1007 00:46:52.074242  4081 sgd_solver.cpp:105] Iteration 89400, lr = 0.001
I1007 00:47:00.005061  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:47:00.340389  4081 solver.cpp:330] Iteration 89500, Testing net (#0)
I1007 00:47:02.272750  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:47:02.353382  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9203
I1007 00:47:02.353418  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.347289 (* 1 = 0.347289 loss)
I1007 00:47:02.436738  4081 solver.cpp:218] Iteration 89500 (9.6502 iter/s, 10.3625s/100 iters), loss = 0.0010971
I1007 00:47:02.436761  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00109681 (* 1 = 0.00109681 loss)
I1007 00:47:02.436767  4081 sgd_solver.cpp:105] Iteration 89500, lr = 0.001
I1007 00:47:10.788414  4081 solver.cpp:218] Iteration 89600 (11.9737 iter/s, 8.35163s/100 iters), loss = 0.00476141
I1007 00:47:10.788518  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00476112 (* 1 = 0.00476112 loss)
I1007 00:47:10.788537  4081 sgd_solver.cpp:105] Iteration 89600, lr = 0.001
I1007 00:47:19.141258  4081 solver.cpp:218] Iteration 89700 (11.9722 iter/s, 8.35272s/100 iters), loss = 0.0012277
I1007 00:47:19.141289  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00122742 (* 1 = 0.00122742 loss)
I1007 00:47:19.141295  4081 sgd_solver.cpp:105] Iteration 89700, lr = 0.001
I1007 00:47:27.495090  4081 solver.cpp:218] Iteration 89800 (11.9706 iter/s, 8.35378s/100 iters), loss = 0.00193352
I1007 00:47:27.495129  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00193324 (* 1 = 0.00193324 loss)
I1007 00:47:27.495136  4081 sgd_solver.cpp:105] Iteration 89800, lr = 0.001
I1007 00:47:35.840895  4081 solver.cpp:218] Iteration 89900 (11.9822 iter/s, 8.34574s/100 iters), loss = 0.000315483
I1007 00:47:35.840936  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000315196 (* 1 = 0.000315196 loss)
I1007 00:47:35.840942  4081 sgd_solver.cpp:105] Iteration 89900, lr = 0.001
I1007 00:47:43.773800  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:47:44.107128  4081 solver.cpp:330] Iteration 90000, Testing net (#0)
I1007 00:47:46.039268  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:47:46.119971  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9209
I1007 00:47:46.120007  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.344797 (* 1 = 0.344797 loss)
I1007 00:47:46.203100  4081 solver.cpp:218] Iteration 90000 (9.65052 iter/s, 10.3621s/100 iters), loss = 0.00179756
I1007 00:47:46.203125  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00179727 (* 1 = 0.00179727 loss)
I1007 00:47:46.203132  4081 sgd_solver.cpp:105] Iteration 90000, lr = 0.001
I1007 00:47:54.540649  4081 solver.cpp:218] Iteration 90100 (11.994 iter/s, 8.3375s/100 iters), loss = 0.00144719
I1007 00:47:54.540689  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00144691 (* 1 = 0.00144691 loss)
I1007 00:47:54.540695  4081 sgd_solver.cpp:105] Iteration 90100, lr = 0.001
I1007 00:48:02.873090  4081 solver.cpp:218] Iteration 90200 (12.0014 iter/s, 8.33238s/100 iters), loss = 0.00177236
I1007 00:48:02.873131  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00177207 (* 1 = 0.00177207 loss)
I1007 00:48:02.873136  4081 sgd_solver.cpp:105] Iteration 90200, lr = 0.001
I1007 00:48:11.206888  4081 solver.cpp:218] Iteration 90300 (11.9994 iter/s, 8.33373s/100 iters), loss = 0.00246681
I1007 00:48:11.206928  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00246652 (* 1 = 0.00246652 loss)
I1007 00:48:11.206934  4081 sgd_solver.cpp:105] Iteration 90300, lr = 0.001
I1007 00:48:19.538250  4081 solver.cpp:218] Iteration 90400 (12.0029 iter/s, 8.3313s/100 iters), loss = 0.00125812
I1007 00:48:19.538394  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00125783 (* 1 = 0.00125783 loss)
I1007 00:48:19.538403  4081 sgd_solver.cpp:105] Iteration 90400, lr = 0.001
I1007 00:48:27.460675  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:48:27.793689  4081 solver.cpp:330] Iteration 90500, Testing net (#0)
I1007 00:48:29.725107  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:48:29.806854  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9208
I1007 00:48:29.806888  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.345198 (* 1 = 0.345198 loss)
I1007 00:48:29.889549  4081 solver.cpp:218] Iteration 90500 (9.66078 iter/s, 10.3511s/100 iters), loss = 0.00397718
I1007 00:48:29.889575  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00397689 (* 1 = 0.00397689 loss)
I1007 00:48:29.889582  4081 sgd_solver.cpp:105] Iteration 90500, lr = 0.001
I1007 00:48:38.227545  4081 solver.cpp:218] Iteration 90600 (11.9934 iter/s, 8.33794s/100 iters), loss = 0.00299799
I1007 00:48:38.227586  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0029977 (* 1 = 0.0029977 loss)
I1007 00:48:38.227591  4081 sgd_solver.cpp:105] Iteration 90600, lr = 0.001
I1007 00:48:46.568994  4081 solver.cpp:218] Iteration 90700 (11.9884 iter/s, 8.34139s/100 iters), loss = 0.00258296
I1007 00:48:46.569034  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00258267 (* 1 = 0.00258267 loss)
I1007 00:48:46.569041  4081 sgd_solver.cpp:105] Iteration 90700, lr = 0.001
I1007 00:48:54.906510  4081 solver.cpp:218] Iteration 90800 (11.9941 iter/s, 8.33745s/100 iters), loss = 0.00162194
I1007 00:48:54.906646  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00162165 (* 1 = 0.00162165 loss)
I1007 00:48:54.906653  4081 sgd_solver.cpp:105] Iteration 90800, lr = 0.001
I1007 00:49:03.251658  4081 solver.cpp:218] Iteration 90900 (11.9832 iter/s, 8.345s/100 iters), loss = 0.00264113
I1007 00:49:03.251700  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00264084 (* 1 = 0.00264084 loss)
I1007 00:49:03.251708  4081 sgd_solver.cpp:105] Iteration 90900, lr = 0.001
I1007 00:49:11.182859  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:49:11.517825  4081 solver.cpp:330] Iteration 91000, Testing net (#0)
I1007 00:49:13.449453  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:49:13.530091  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9205
I1007 00:49:13.530127  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.344939 (* 1 = 0.344939 loss)
I1007 00:49:13.613201  4081 solver.cpp:218] Iteration 91000 (9.65114 iter/s, 10.3615s/100 iters), loss = 0.000712225
I1007 00:49:13.613226  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000711934 (* 1 = 0.000711934 loss)
I1007 00:49:13.613234  4081 sgd_solver.cpp:105] Iteration 91000, lr = 0.001
I1007 00:49:21.962860  4081 solver.cpp:218] Iteration 91100 (11.9766 iter/s, 8.34961s/100 iters), loss = 0.000713641
I1007 00:49:21.962899  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000713351 (* 1 = 0.000713351 loss)
I1007 00:49:21.962906  4081 sgd_solver.cpp:105] Iteration 91100, lr = 0.001
I1007 00:49:30.312826  4081 solver.cpp:218] Iteration 91200 (11.9762 iter/s, 8.34991s/100 iters), loss = 0.00350361
I1007 00:49:30.312922  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00350331 (* 1 = 0.00350331 loss)
I1007 00:49:30.312942  4081 sgd_solver.cpp:105] Iteration 91200, lr = 0.001
I1007 00:49:38.654855  4081 solver.cpp:218] Iteration 91300 (11.9877 iter/s, 8.34191s/100 iters), loss = 0.0015241
I1007 00:49:38.654884  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00152381 (* 1 = 0.00152381 loss)
I1007 00:49:38.654891  4081 sgd_solver.cpp:105] Iteration 91300, lr = 0.001
I1007 00:49:47.006549  4081 solver.cpp:218] Iteration 91400 (11.9737 iter/s, 8.35164s/100 iters), loss = 0.00121717
I1007 00:49:47.006589  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00121688 (* 1 = 0.00121688 loss)
I1007 00:49:47.006595  4081 sgd_solver.cpp:105] Iteration 91400, lr = 0.001
I1007 00:49:54.937515  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:49:55.271674  4081 solver.cpp:330] Iteration 91500, Testing net (#0)
I1007 00:49:57.204032  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:49:57.284579  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.92
I1007 00:49:57.284605  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.347589 (* 1 = 0.347589 loss)
I1007 00:49:57.368320  4081 solver.cpp:218] Iteration 91500 (9.65092 iter/s, 10.3617s/100 iters), loss = 0.00280194
I1007 00:49:57.368346  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00280165 (* 1 = 0.00280165 loss)
I1007 00:49:57.368353  4081 sgd_solver.cpp:105] Iteration 91500, lr = 0.001
I1007 00:50:05.706463  4081 solver.cpp:218] Iteration 91600 (11.9932 iter/s, 8.33809s/100 iters), loss = 0.000610877
I1007 00:50:05.706601  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000610589 (* 1 = 0.000610589 loss)
I1007 00:50:05.706609  4081 sgd_solver.cpp:105] Iteration 91600, lr = 0.001
I1007 00:50:14.043823  4081 solver.cpp:218] Iteration 91700 (11.9944 iter/s, 8.3372s/100 iters), loss = 0.00533489
I1007 00:50:14.043861  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00533461 (* 1 = 0.00533461 loss)
I1007 00:50:14.043867  4081 sgd_solver.cpp:105] Iteration 91700, lr = 0.001
I1007 00:50:22.377254  4081 solver.cpp:218] Iteration 91800 (11.9999 iter/s, 8.33337s/100 iters), loss = 0.00213709
I1007 00:50:22.377295  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0021368 (* 1 = 0.0021368 loss)
I1007 00:50:22.377301  4081 sgd_solver.cpp:105] Iteration 91800, lr = 0.001
I1007 00:50:30.712537  4081 solver.cpp:218] Iteration 91900 (11.9973 iter/s, 8.33522s/100 iters), loss = 0.000917763
I1007 00:50:30.712568  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000917477 (* 1 = 0.000917477 loss)
I1007 00:50:30.712574  4081 sgd_solver.cpp:105] Iteration 91900, lr = 0.001
I1007 00:50:38.635054  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:50:38.969465  4081 solver.cpp:330] Iteration 92000, Testing net (#0)
I1007 00:50:40.899986  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:50:40.981647  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9205
I1007 00:50:40.981684  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.349175 (* 1 = 0.349175 loss)
I1007 00:50:41.064102  4081 solver.cpp:218] Iteration 92000 (9.66043 iter/s, 10.3515s/100 iters), loss = 0.00205524
I1007 00:50:41.064136  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00205495 (* 1 = 0.00205495 loss)
I1007 00:50:41.064143  4081 sgd_solver.cpp:105] Iteration 92000, lr = 0.001
I1007 00:50:49.402745  4081 solver.cpp:218] Iteration 92100 (11.9924 iter/s, 8.33859s/100 iters), loss = 0.000471923
I1007 00:50:49.402776  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000471635 (* 1 = 0.000471635 loss)
I1007 00:50:49.402781  4081 sgd_solver.cpp:105] Iteration 92100, lr = 0.001
I1007 00:50:57.743901  4081 solver.cpp:218] Iteration 92200 (11.9888 iter/s, 8.3411s/100 iters), loss = 0.00679236
I1007 00:50:57.743942  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00679207 (* 1 = 0.00679207 loss)
I1007 00:50:57.743949  4081 sgd_solver.cpp:105] Iteration 92200, lr = 0.001
I1007 00:51:06.091789  4081 solver.cpp:218] Iteration 92300 (11.9792 iter/s, 8.34782s/100 iters), loss = 0.00280105
I1007 00:51:06.091833  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00280076 (* 1 = 0.00280076 loss)
I1007 00:51:06.091842  4081 sgd_solver.cpp:105] Iteration 92300, lr = 0.001
I1007 00:51:14.440454  4081 solver.cpp:218] Iteration 92400 (11.9781 iter/s, 8.3486s/100 iters), loss = 0.000546977
I1007 00:51:14.440567  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000546686 (* 1 = 0.000546686 loss)
I1007 00:51:14.440573  4081 sgd_solver.cpp:105] Iteration 92400, lr = 0.001
I1007 00:51:22.366513  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:51:22.700239  4081 solver.cpp:330] Iteration 92500, Testing net (#0)
I1007 00:51:24.632520  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:51:24.712748  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9205
I1007 00:51:24.712771  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.347566 (* 1 = 0.347566 loss)
I1007 00:51:24.796237  4081 solver.cpp:218] Iteration 92500 (9.65656 iter/s, 10.3557s/100 iters), loss = 0.00179473
I1007 00:51:24.796273  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00179444 (* 1 = 0.00179444 loss)
I1007 00:51:24.796280  4081 sgd_solver.cpp:105] Iteration 92500, lr = 0.001
I1007 00:51:33.148896  4081 solver.cpp:218] Iteration 92600 (11.9723 iter/s, 8.3526s/100 iters), loss = 0.00341409
I1007 00:51:33.148937  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0034138 (* 1 = 0.0034138 loss)
I1007 00:51:33.148944  4081 sgd_solver.cpp:105] Iteration 92600, lr = 0.001
I1007 00:51:41.497984  4081 solver.cpp:218] Iteration 92700 (11.9774 iter/s, 8.34902s/100 iters), loss = 0.00327165
I1007 00:51:41.498024  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00327136 (* 1 = 0.00327136 loss)
I1007 00:51:41.498031  4081 sgd_solver.cpp:105] Iteration 92700, lr = 0.001
I1007 00:51:49.847337  4081 solver.cpp:218] Iteration 92800 (11.9771 iter/s, 8.34929s/100 iters), loss = 0.00171571
I1007 00:51:49.847442  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00171542 (* 1 = 0.00171542 loss)
I1007 00:51:49.847450  4081 sgd_solver.cpp:105] Iteration 92800, lr = 0.001
I1007 00:51:58.190798  4081 solver.cpp:218] Iteration 92900 (11.9856 iter/s, 8.34333s/100 iters), loss = 0.00257233
I1007 00:51:58.190836  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00257204 (* 1 = 0.00257204 loss)
I1007 00:51:58.190843  4081 sgd_solver.cpp:105] Iteration 92900, lr = 0.001
I1007 00:52:06.124932  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:52:06.459595  4081 solver.cpp:330] Iteration 93000, Testing net (#0)
I1007 00:52:08.390149  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:52:08.471462  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9199
I1007 00:52:08.471487  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.345945 (* 1 = 0.345945 loss)
I1007 00:52:08.554183  4081 solver.cpp:218] Iteration 93000 (9.64941 iter/s, 10.3633s/100 iters), loss = 0.00462705
I1007 00:52:08.554208  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00462676 (* 1 = 0.00462676 loss)
I1007 00:52:08.554215  4081 sgd_solver.cpp:105] Iteration 93000, lr = 0.001
I1007 00:52:16.901607  4081 solver.cpp:218] Iteration 93100 (11.9798 iter/s, 8.34737s/100 iters), loss = 0.00103278
I1007 00:52:16.901638  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00103248 (* 1 = 0.00103248 loss)
I1007 00:52:16.901644  4081 sgd_solver.cpp:105] Iteration 93100, lr = 0.001
I1007 00:52:25.238628  4081 solver.cpp:218] Iteration 93200 (11.9948 iter/s, 8.33697s/100 iters), loss = 0.00291478
I1007 00:52:25.238785  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00291449 (* 1 = 0.00291449 loss)
I1007 00:52:25.238796  4081 sgd_solver.cpp:105] Iteration 93200, lr = 0.001
I1007 00:52:33.581269  4081 solver.cpp:218] Iteration 93300 (11.9869 iter/s, 8.34247s/100 iters), loss = 0.000722982
I1007 00:52:33.581310  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000722686 (* 1 = 0.000722686 loss)
I1007 00:52:33.581316  4081 sgd_solver.cpp:105] Iteration 93300, lr = 0.001
I1007 00:52:41.924106  4081 solver.cpp:218] Iteration 93400 (11.9864 iter/s, 8.34277s/100 iters), loss = 0.000961848
I1007 00:52:41.924147  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000961553 (* 1 = 0.000961553 loss)
I1007 00:52:41.924154  4081 sgd_solver.cpp:105] Iteration 93400, lr = 0.001
I1007 00:52:49.847661  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:52:50.181975  4081 solver.cpp:330] Iteration 93500, Testing net (#0)
I1007 00:52:52.114403  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:52:52.195257  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9198
I1007 00:52:52.195293  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.347078 (* 1 = 0.347078 loss)
I1007 00:52:52.278570  4081 solver.cpp:218] Iteration 93500 (9.65773 iter/s, 10.3544s/100 iters), loss = 0.00192235
I1007 00:52:52.278600  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00192206 (* 1 = 0.00192206 loss)
I1007 00:52:52.278607  4081 sgd_solver.cpp:105] Iteration 93500, lr = 0.001
I1007 00:53:00.627249  4081 solver.cpp:218] Iteration 93600 (11.978 iter/s, 8.34863s/100 iters), loss = 0.00105501
I1007 00:53:00.627359  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00105472 (* 1 = 0.00105472 loss)
I1007 00:53:00.627367  4081 sgd_solver.cpp:105] Iteration 93600, lr = 0.001
I1007 00:53:08.970713  4081 solver.cpp:218] Iteration 93700 (11.9856 iter/s, 8.34333s/100 iters), loss = 0.00300909
I1007 00:53:08.970754  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00300879 (* 1 = 0.00300879 loss)
I1007 00:53:08.970760  4081 sgd_solver.cpp:105] Iteration 93700, lr = 0.001
I1007 00:53:17.319939  4081 solver.cpp:218] Iteration 93800 (11.9773 iter/s, 8.34916s/100 iters), loss = 0.00191268
I1007 00:53:17.319981  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00191238 (* 1 = 0.00191238 loss)
I1007 00:53:17.319988  4081 sgd_solver.cpp:105] Iteration 93800, lr = 0.001
I1007 00:53:25.663731  4081 solver.cpp:218] Iteration 93900 (11.9851 iter/s, 8.34373s/100 iters), loss = 0.000634611
I1007 00:53:25.663772  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000634316 (* 1 = 0.000634316 loss)
I1007 00:53:25.663779  4081 sgd_solver.cpp:105] Iteration 93900, lr = 0.001
I1007 00:53:33.596099  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:53:33.930279  4081 solver.cpp:330] Iteration 94000, Testing net (#0)
I1007 00:53:35.859498  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:53:35.940335  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9196
I1007 00:53:35.940371  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.346084 (* 1 = 0.346084 loss)
I1007 00:53:36.022963  4081 solver.cpp:218] Iteration 94000 (9.65329 iter/s, 10.3592s/100 iters), loss = 0.00220335
I1007 00:53:36.022992  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00220305 (* 1 = 0.00220305 loss)
I1007 00:53:36.023000  4081 sgd_solver.cpp:105] Iteration 94000, lr = 0.001
I1007 00:53:44.367965  4081 solver.cpp:218] Iteration 94100 (11.9833 iter/s, 8.34495s/100 iters), loss = 0.00148265
I1007 00:53:44.367995  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00148236 (* 1 = 0.00148236 loss)
I1007 00:53:44.368002  4081 sgd_solver.cpp:105] Iteration 94100, lr = 0.001
I1007 00:53:52.710028  4081 solver.cpp:218] Iteration 94200 (11.9875 iter/s, 8.34201s/100 iters), loss = 0.000583198
I1007 00:53:52.710059  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000582903 (* 1 = 0.000582903 loss)
I1007 00:53:52.710065  4081 sgd_solver.cpp:105] Iteration 94200, lr = 0.001
I1007 00:54:01.056064  4081 solver.cpp:218] Iteration 94300 (11.9818 iter/s, 8.34598s/100 iters), loss = 0.00116709
I1007 00:54:01.056107  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0011668 (* 1 = 0.0011668 loss)
I1007 00:54:01.056113  4081 sgd_solver.cpp:105] Iteration 94300, lr = 0.001
I1007 00:54:09.402189  4081 solver.cpp:218] Iteration 94400 (11.9817 iter/s, 8.34606s/100 iters), loss = 0.000525453
I1007 00:54:09.402330  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000525158 (* 1 = 0.000525158 loss)
I1007 00:54:09.402348  4081 sgd_solver.cpp:105] Iteration 94400, lr = 0.001
I1007 00:54:17.339370  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:54:17.673192  4081 solver.cpp:330] Iteration 94500, Testing net (#0)
I1007 00:54:19.603828  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:54:19.684818  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9197
I1007 00:54:19.684842  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.346319 (* 1 = 0.346319 loss)
I1007 00:54:19.768288  4081 solver.cpp:218] Iteration 94500 (9.64698 iter/s, 10.3659s/100 iters), loss = 0.000879745
I1007 00:54:19.768313  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00087945 (* 1 = 0.00087945 loss)
I1007 00:54:19.768321  4081 sgd_solver.cpp:105] Iteration 94500, lr = 0.001
I1007 00:54:28.113436  4081 solver.cpp:218] Iteration 94600 (11.9831 iter/s, 8.3451s/100 iters), loss = 0.0017323
I1007 00:54:28.113477  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00173201 (* 1 = 0.00173201 loss)
I1007 00:54:28.113483  4081 sgd_solver.cpp:105] Iteration 94600, lr = 0.001
I1007 00:54:36.458693  4081 solver.cpp:218] Iteration 94700 (11.9829 iter/s, 8.34519s/100 iters), loss = 0.00321774
I1007 00:54:36.458734  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00321744 (* 1 = 0.00321744 loss)
I1007 00:54:36.458740  4081 sgd_solver.cpp:105] Iteration 94700, lr = 0.001
I1007 00:54:44.807297  4081 solver.cpp:218] Iteration 94800 (11.9781 iter/s, 8.34854s/100 iters), loss = 0.00292687
I1007 00:54:44.807374  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00292657 (* 1 = 0.00292657 loss)
I1007 00:54:44.807381  4081 sgd_solver.cpp:105] Iteration 94800, lr = 0.001
I1007 00:54:53.158072  4081 solver.cpp:218] Iteration 94900 (11.9751 iter/s, 8.35068s/100 iters), loss = 0.000207378
I1007 00:54:53.158104  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000207082 (* 1 = 0.000207082 loss)
I1007 00:54:53.158110  4081 sgd_solver.cpp:105] Iteration 94900, lr = 0.001
I1007 00:55:01.091859  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:55:01.427729  4081 solver.cpp:330] Iteration 95000, Testing net (#0)
I1007 00:55:03.358772  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:55:03.439662  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9204
I1007 00:55:03.439697  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.347172 (* 1 = 0.347172 loss)
I1007 00:55:03.522975  4081 solver.cpp:218] Iteration 95000 (9.648 iter/s, 10.3648s/100 iters), loss = 0.00594797
I1007 00:55:03.523002  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00594768 (* 1 = 0.00594768 loss)
I1007 00:55:03.523010  4081 sgd_solver.cpp:105] Iteration 95000, lr = 0.001
I1007 00:55:11.867733  4081 solver.cpp:218] Iteration 95100 (11.9836 iter/s, 8.3447s/100 iters), loss = 0.000556689
I1007 00:55:11.867763  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000556396 (* 1 = 0.000556396 loss)
I1007 00:55:11.867769  4081 sgd_solver.cpp:105] Iteration 95100, lr = 0.001
I1007 00:55:20.209437  4081 solver.cpp:218] Iteration 95200 (11.988 iter/s, 8.34165s/100 iters), loss = 0.000352713
I1007 00:55:20.209570  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000352419 (* 1 = 0.000352419 loss)
I1007 00:55:20.209578  4081 sgd_solver.cpp:105] Iteration 95200, lr = 0.001
I1007 00:55:28.560405  4081 solver.cpp:218] Iteration 95300 (11.9749 iter/s, 8.35082s/100 iters), loss = 0.000915604
I1007 00:55:28.560434  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000915311 (* 1 = 0.000915311 loss)
I1007 00:55:28.560441  4081 sgd_solver.cpp:105] Iteration 95300, lr = 0.001
I1007 00:55:36.903904  4081 solver.cpp:218] Iteration 95400 (11.9855 iter/s, 8.34345s/100 iters), loss = 0.00508488
I1007 00:55:36.903936  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00508459 (* 1 = 0.00508459 loss)
I1007 00:55:36.903942  4081 sgd_solver.cpp:105] Iteration 95400, lr = 0.001
I1007 00:55:44.836068  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:55:45.170025  4081 solver.cpp:330] Iteration 95500, Testing net (#0)
I1007 00:55:47.103930  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:55:47.185127  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9203
I1007 00:55:47.185163  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.347316 (* 1 = 0.347316 loss)
I1007 00:55:47.268456  4081 solver.cpp:218] Iteration 95500 (9.64832 iter/s, 10.3645s/100 iters), loss = 0.00112667
I1007 00:55:47.268488  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00112637 (* 1 = 0.00112637 loss)
I1007 00:55:47.268496  4081 sgd_solver.cpp:105] Iteration 95500, lr = 0.001
I1007 00:55:55.609036  4081 solver.cpp:218] Iteration 95600 (11.9897 iter/s, 8.34053s/100 iters), loss = 0.00264501
I1007 00:55:55.609158  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00264471 (* 1 = 0.00264471 loss)
I1007 00:55:55.609165  4081 sgd_solver.cpp:105] Iteration 95600, lr = 0.001
I1007 00:56:03.956951  4081 solver.cpp:218] Iteration 95700 (11.9792 iter/s, 8.34777s/100 iters), loss = 0.00117779
I1007 00:56:03.956992  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0011775 (* 1 = 0.0011775 loss)
I1007 00:56:03.956998  4081 sgd_solver.cpp:105] Iteration 95700, lr = 0.001
I1007 00:56:12.302697  4081 solver.cpp:218] Iteration 95800 (11.9822 iter/s, 8.34568s/100 iters), loss = 0.00338555
I1007 00:56:12.302726  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00338525 (* 1 = 0.00338525 loss)
I1007 00:56:12.302733  4081 sgd_solver.cpp:105] Iteration 95800, lr = 0.001
I1007 00:56:20.642098  4081 solver.cpp:218] Iteration 95900 (11.9913 iter/s, 8.33935s/100 iters), loss = 0.000432921
I1007 00:56:20.642128  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000432623 (* 1 = 0.000432623 loss)
I1007 00:56:20.642135  4081 sgd_solver.cpp:105] Iteration 95900, lr = 0.001
I1007 00:56:28.572270  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:56:28.906304  4081 solver.cpp:330] Iteration 96000, Testing net (#0)
I1007 00:56:30.837869  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:56:30.918424  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9204
I1007 00:56:30.918459  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.348059 (* 1 = 0.348059 loss)
I1007 00:56:31.002104  4081 solver.cpp:218] Iteration 96000 (9.65256 iter/s, 10.3599s/100 iters), loss = 0.00316438
I1007 00:56:31.002130  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00316409 (* 1 = 0.00316409 loss)
I1007 00:56:31.002137  4081 sgd_solver.cpp:105] Iteration 96000, lr = 0.001
I1007 00:56:39.339185  4081 solver.cpp:218] Iteration 96100 (11.9947 iter/s, 8.33699s/100 iters), loss = 0.00198932
I1007 00:56:39.339222  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00198902 (* 1 = 0.00198902 loss)
I1007 00:56:39.339231  4081 sgd_solver.cpp:105] Iteration 96100, lr = 0.001
I1007 00:56:47.677456  4081 solver.cpp:218] Iteration 96200 (11.993 iter/s, 8.33821s/100 iters), loss = 0.000675292
I1007 00:56:47.677500  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000674999 (* 1 = 0.000674999 loss)
I1007 00:56:47.677505  4081 sgd_solver.cpp:105] Iteration 96200, lr = 0.001
I1007 00:56:56.010291  4081 solver.cpp:218] Iteration 96300 (12.0008 iter/s, 8.33277s/100 iters), loss = 0.000479898
I1007 00:56:56.010332  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000479604 (* 1 = 0.000479604 loss)
I1007 00:56:56.010339  4081 sgd_solver.cpp:105] Iteration 96300, lr = 0.001
I1007 00:57:04.349197  4081 solver.cpp:218] Iteration 96400 (11.9921 iter/s, 8.33884s/100 iters), loss = 0.00126447
I1007 00:57:04.349314  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00126417 (* 1 = 0.00126417 loss)
I1007 00:57:04.349333  4081 sgd_solver.cpp:105] Iteration 96400, lr = 0.001
I1007 00:57:12.275218  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:57:12.609410  4081 solver.cpp:330] Iteration 96500, Testing net (#0)
I1007 00:57:14.542088  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:57:14.623005  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9199
I1007 00:57:14.623041  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.348605 (* 1 = 0.348605 loss)
I1007 00:57:14.706218  4081 solver.cpp:218] Iteration 96500 (9.65542 iter/s, 10.3569s/100 iters), loss = 0.000806882
I1007 00:57:14.706243  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000806589 (* 1 = 0.000806589 loss)
I1007 00:57:14.706248  4081 sgd_solver.cpp:105] Iteration 96500, lr = 0.001
I1007 00:57:23.049549  4081 solver.cpp:218] Iteration 96600 (11.9857 iter/s, 8.34328s/100 iters), loss = 0.00163289
I1007 00:57:23.049581  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0016326 (* 1 = 0.0016326 loss)
I1007 00:57:23.049587  4081 sgd_solver.cpp:105] Iteration 96600, lr = 0.001
I1007 00:57:31.395722  4081 solver.cpp:218] Iteration 96700 (11.9816 iter/s, 8.34612s/100 iters), loss = 0.00163207
I1007 00:57:31.395751  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00163178 (* 1 = 0.00163178 loss)
I1007 00:57:31.395757  4081 sgd_solver.cpp:105] Iteration 96700, lr = 0.001
I1007 00:57:39.737686  4081 solver.cpp:218] Iteration 96800 (11.9877 iter/s, 8.34191s/100 iters), loss = 0.00133954
I1007 00:57:39.737784  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00133924 (* 1 = 0.00133924 loss)
I1007 00:57:39.737807  4081 sgd_solver.cpp:105] Iteration 96800, lr = 0.001
I1007 00:57:48.083884  4081 solver.cpp:218] Iteration 96900 (11.9817 iter/s, 8.34609s/100 iters), loss = 0.00208231
I1007 00:57:48.083925  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00208201 (* 1 = 0.00208201 loss)
I1007 00:57:48.083931  4081 sgd_solver.cpp:105] Iteration 96900, lr = 0.001
I1007 00:57:56.010076  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:57:56.343263  4081 solver.cpp:330] Iteration 97000, Testing net (#0)
I1007 00:57:58.276003  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:57:58.356600  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9188
I1007 00:57:58.356626  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.349166 (* 1 = 0.349166 loss)
I1007 00:57:58.440219  4081 solver.cpp:218] Iteration 97000 (9.65599 iter/s, 10.3563s/100 iters), loss = 0.00240114
I1007 00:57:58.440244  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00240084 (* 1 = 0.00240084 loss)
I1007 00:57:58.440250  4081 sgd_solver.cpp:105] Iteration 97000, lr = 0.001
I1007 00:58:06.787294  4081 solver.cpp:218] Iteration 97100 (11.9803 iter/s, 8.34702s/100 iters), loss = 0.00177873
I1007 00:58:06.787325  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00177844 (* 1 = 0.00177844 loss)
I1007 00:58:06.787333  4081 sgd_solver.cpp:105] Iteration 97100, lr = 0.001
I1007 00:58:15.136267  4081 solver.cpp:218] Iteration 97200 (11.9776 iter/s, 8.34892s/100 iters), loss = 0.00153026
I1007 00:58:15.136410  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00152997 (* 1 = 0.00152997 loss)
I1007 00:58:15.136418  4081 sgd_solver.cpp:105] Iteration 97200, lr = 0.001
I1007 00:58:23.482169  4081 solver.cpp:218] Iteration 97300 (11.9821 iter/s, 8.34575s/100 iters), loss = 0.00255293
I1007 00:58:23.482200  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00255264 (* 1 = 0.00255264 loss)
I1007 00:58:23.482208  4081 sgd_solver.cpp:105] Iteration 97300, lr = 0.001
I1007 00:58:31.827213  4081 solver.cpp:218] Iteration 97400 (11.9832 iter/s, 8.34499s/100 iters), loss = 0.000749209
I1007 00:58:31.827253  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000748918 (* 1 = 0.000748918 loss)
I1007 00:58:31.827260  4081 sgd_solver.cpp:105] Iteration 97400, lr = 0.001
I1007 00:58:39.757817  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:58:40.091740  4081 solver.cpp:330] Iteration 97500, Testing net (#0)
I1007 00:58:42.026397  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:58:42.106444  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9199
I1007 00:58:42.106469  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.347788 (* 1 = 0.347788 loss)
I1007 00:58:42.189350  4081 solver.cpp:218] Iteration 97500 (9.65058 iter/s, 10.3621s/100 iters), loss = 0.00143942
I1007 00:58:42.189375  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00143913 (* 1 = 0.00143913 loss)
I1007 00:58:42.189383  4081 sgd_solver.cpp:105] Iteration 97500, lr = 0.001
I1007 00:58:50.519793  4081 solver.cpp:218] Iteration 97600 (12.0042 iter/s, 8.33039s/100 iters), loss = 0.00118124
I1007 00:58:50.519901  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00118095 (* 1 = 0.00118095 loss)
I1007 00:58:50.519908  4081 sgd_solver.cpp:105] Iteration 97600, lr = 0.001
I1007 00:58:58.851886  4081 solver.cpp:218] Iteration 97700 (12.002 iter/s, 8.33197s/100 iters), loss = 0.00378801
I1007 00:58:58.851917  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00378772 (* 1 = 0.00378772 loss)
I1007 00:58:58.851922  4081 sgd_solver.cpp:105] Iteration 97700, lr = 0.001
I1007 00:59:07.183701  4081 solver.cpp:218] Iteration 97800 (12.0023 iter/s, 8.33176s/100 iters), loss = 0.000998177
I1007 00:59:07.183732  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000997886 (* 1 = 0.000997886 loss)
I1007 00:59:07.183748  4081 sgd_solver.cpp:105] Iteration 97800, lr = 0.001
I1007 00:59:15.521517  4081 solver.cpp:218] Iteration 97900 (11.9936 iter/s, 8.33776s/100 iters), loss = 0.000493361
I1007 00:59:15.521548  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000493068 (* 1 = 0.000493068 loss)
I1007 00:59:15.521554  4081 sgd_solver.cpp:105] Iteration 97900, lr = 0.001
I1007 00:59:23.443390  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:59:23.776715  4081 solver.cpp:330] Iteration 98000, Testing net (#0)
I1007 00:59:25.708089  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 00:59:25.788594  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9201
I1007 00:59:25.788627  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.347465 (* 1 = 0.347465 loss)
I1007 00:59:25.871662  4081 solver.cpp:218] Iteration 98000 (9.66175 iter/s, 10.3501s/100 iters), loss = 0.000841132
I1007 00:59:25.871686  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000840838 (* 1 = 0.000840838 loss)
I1007 00:59:25.871693  4081 sgd_solver.cpp:105] Iteration 98000, lr = 0.001
I1007 00:59:34.211449  4081 solver.cpp:218] Iteration 98100 (11.9908 iter/s, 8.33974s/100 iters), loss = 0.00125178
I1007 00:59:34.211490  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00125149 (* 1 = 0.00125149 loss)
I1007 00:59:34.211498  4081 sgd_solver.cpp:105] Iteration 98100, lr = 0.001
I1007 00:59:42.556751  4081 solver.cpp:218] Iteration 98200 (11.9829 iter/s, 8.34524s/100 iters), loss = 0.00425298
I1007 00:59:42.556779  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00425269 (* 1 = 0.00425269 loss)
I1007 00:59:42.556785  4081 sgd_solver.cpp:105] Iteration 98200, lr = 0.001
I1007 00:59:50.898828  4081 solver.cpp:218] Iteration 98300 (11.9875 iter/s, 8.34202s/100 iters), loss = 0.00101361
I1007 00:59:50.898859  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00101331 (* 1 = 0.00101331 loss)
I1007 00:59:50.898865  4081 sgd_solver.cpp:105] Iteration 98300, lr = 0.001
I1007 00:59:59.246141  4081 solver.cpp:218] Iteration 98400 (11.98 iter/s, 8.34726s/100 iters), loss = 0.00443527
I1007 00:59:59.246237  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00443498 (* 1 = 0.00443498 loss)
I1007 00:59:59.246254  4081 sgd_solver.cpp:105] Iteration 98400, lr = 0.001
I1007 01:00:07.172066  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1007 01:00:07.506929  4081 solver.cpp:330] Iteration 98500, Testing net (#0)
I1007 01:00:09.437590  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 01:00:09.518267  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9196
I1007 01:00:09.518302  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.347745 (* 1 = 0.347745 loss)
I1007 01:00:09.600868  4081 solver.cpp:218] Iteration 98500 (9.65754 iter/s, 10.3546s/100 iters), loss = 0.00097935
I1007 01:00:09.600893  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000979054 (* 1 = 0.000979054 loss)
I1007 01:00:09.600899  4081 sgd_solver.cpp:105] Iteration 98500, lr = 0.001
I1007 01:00:17.940425  4081 solver.cpp:218] Iteration 98600 (11.9911 iter/s, 8.33951s/100 iters), loss = 0.00110143
I1007 01:00:17.940466  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00110114 (* 1 = 0.00110114 loss)
I1007 01:00:17.940472  4081 sgd_solver.cpp:105] Iteration 98600, lr = 0.001
I1007 01:00:26.274467  4081 solver.cpp:218] Iteration 98700 (11.9991 iter/s, 8.33398s/100 iters), loss = 0.00109563
I1007 01:00:26.274499  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00109533 (* 1 = 0.00109533 loss)
I1007 01:00:26.274507  4081 sgd_solver.cpp:105] Iteration 98700, lr = 0.001
I1007 01:00:34.613976  4081 solver.cpp:218] Iteration 98800 (11.9912 iter/s, 8.33945s/100 iters), loss = 0.000583662
I1007 01:00:34.614094  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000583366 (* 1 = 0.000583366 loss)
I1007 01:00:34.614102  4081 sgd_solver.cpp:105] Iteration 98800, lr = 0.001
I1007 01:00:42.951442  4081 solver.cpp:218] Iteration 98900 (11.9943 iter/s, 8.33733s/100 iters), loss = 0.00194675
I1007 01:00:42.951472  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00194645 (* 1 = 0.00194645 loss)
I1007 01:00:42.951478  4081 sgd_solver.cpp:105] Iteration 98900, lr = 0.001
I1007 01:00:50.873049  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1007 01:00:51.206918  4081 solver.cpp:330] Iteration 99000, Testing net (#0)
I1007 01:00:53.137971  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 01:00:53.218952  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9201
I1007 01:00:53.218987  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.346693 (* 1 = 0.346693 loss)
I1007 01:00:53.302161  4081 solver.cpp:218] Iteration 99000 (9.66122 iter/s, 10.3507s/100 iters), loss = 0.00406232
I1007 01:00:53.302191  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00406203 (* 1 = 0.00406203 loss)
I1007 01:00:53.302199  4081 sgd_solver.cpp:105] Iteration 99000, lr = 0.001
I1007 01:01:01.653111  4081 solver.cpp:218] Iteration 99100 (11.9748 iter/s, 8.3509s/100 iters), loss = 0.0041128
I1007 01:01:01.653152  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0041125 (* 1 = 0.0041125 loss)
I1007 01:01:01.653158  4081 sgd_solver.cpp:105] Iteration 99100, lr = 0.001
I1007 01:01:10.000018  4081 solver.cpp:218] Iteration 99200 (11.9806 iter/s, 8.34684s/100 iters), loss = 0.0087881
I1007 01:01:10.000176  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00878781 (* 1 = 0.00878781 loss)
I1007 01:01:10.000185  4081 sgd_solver.cpp:105] Iteration 99200, lr = 0.001
I1007 01:01:18.347465  4081 solver.cpp:218] Iteration 99300 (11.98 iter/s, 8.34728s/100 iters), loss = 0.00129017
I1007 01:01:18.347494  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00128987 (* 1 = 0.00128987 loss)
I1007 01:01:18.347501  4081 sgd_solver.cpp:105] Iteration 99300, lr = 0.001
I1007 01:01:26.690614  4081 solver.cpp:218] Iteration 99400 (11.986 iter/s, 8.3431s/100 iters), loss = 0.000530036
I1007 01:01:26.690652  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000529739 (* 1 = 0.000529739 loss)
I1007 01:01:26.690659  4081 sgd_solver.cpp:105] Iteration 99400, lr = 0.001
I1007 01:01:34.622203  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1007 01:01:34.956717  4081 solver.cpp:330] Iteration 99500, Testing net (#0)
I1007 01:01:36.887917  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 01:01:36.968633  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.92
I1007 01:01:36.968668  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.34782 (* 1 = 0.34782 loss)
I1007 01:01:37.052278  4081 solver.cpp:218] Iteration 99500 (9.65102 iter/s, 10.3616s/100 iters), loss = 0.000824262
I1007 01:01:37.052301  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000823966 (* 1 = 0.000823966 loss)
I1007 01:01:37.052309  4081 sgd_solver.cpp:105] Iteration 99500, lr = 0.001
I1007 01:01:45.394153  4081 solver.cpp:218] Iteration 99600 (11.9878 iter/s, 8.34183s/100 iters), loss = 0.000887773
I1007 01:01:45.394266  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000887477 (* 1 = 0.000887477 loss)
I1007 01:01:45.394284  4081 sgd_solver.cpp:105] Iteration 99600, lr = 0.001
I1007 01:01:53.738966  4081 solver.cpp:218] Iteration 99700 (11.9837 iter/s, 8.34469s/100 iters), loss = 0.000876485
I1007 01:01:53.738998  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00087619 (* 1 = 0.00087619 loss)
I1007 01:01:53.739006  4081 sgd_solver.cpp:105] Iteration 99700, lr = 0.001
I1007 01:02:02.086637  4081 solver.cpp:218] Iteration 99800 (11.9795 iter/s, 8.34761s/100 iters), loss = 0.00195251
I1007 01:02:02.086666  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00195222 (* 1 = 0.00195222 loss)
I1007 01:02:02.086673  4081 sgd_solver.cpp:105] Iteration 99800, lr = 0.001
I1007 01:02:10.423712  4081 solver.cpp:218] Iteration 99900 (11.9947 iter/s, 8.33702s/100 iters), loss = 0.00169666
I1007 01:02:10.423741  4081 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00169636 (* 1 = 0.00169636 loss)
I1007 01:02:10.423748  4081 sgd_solver.cpp:105] Iteration 99900, lr = 0.001
I1007 01:02:18.351740  4086 data_layer.cpp:73] Restarting data prefetching from start.
I1007 01:02:18.685271  4081 solver.cpp:447] Snapshotting to binary proto file xn/PENLU/snapshot/resnet/res32/res32_penlu_alpha1_beta1_etanostudy_2study_nodecay_gauss_iter_100000.caffemodel
I1007 01:02:18.698850  4081 sgd_solver.cpp:273] Snapshotting solver state to binary proto file xn/PENLU/snapshot/resnet/res32/res32_penlu_alpha1_beta1_etanostudy_2study_nodecay_gauss_iter_100000.solverstate
I1007 01:02:18.722174  4081 solver.cpp:310] Iteration 100000, loss = 0.000954231
I1007 01:02:18.722194  4081 solver.cpp:330] Iteration 100000, Testing net (#0)
I1007 01:02:20.650774  4087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 01:02:20.731995  4081 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9205
I1007 01:02:20.732033  4081 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.348803 (* 1 = 0.348803 loss)
I1007 01:02:20.732038  4081 solver.cpp:315] Optimization Done.
I1007 01:02:20.732039  4081 caffe.cpp:259] Optimization Done.
