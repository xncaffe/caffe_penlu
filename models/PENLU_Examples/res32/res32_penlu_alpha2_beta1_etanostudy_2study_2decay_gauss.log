I1007 17:39:00.929118  5078 caffe.cpp:218] Using GPUs 0
I1007 17:39:00.962442  5078 caffe.cpp:223] GPU 0: GeForce GTX 1080
I1007 17:39:01.190583  5078 solver.cpp:44] Initializing solver from parameters: 
test_iter: 100
test_interval: 500
base_lr: 0.1
display: 100
max_iter: 100000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0001
snapshot: 100000
snapshot_prefix: "xn/PENLU/snapshot/resnet/res32/res32_penlu_alpha2_beta1_etanostudy_2study_2decay_gauss"
solver_mode: GPU
device_id: 0
net: "/home/x306/caffe/xn/PENLU/neural/resnet/res32/res32_penlu_decay_gauss.prototxt"
train_state {
  level: 0
  stage: ""
}
stepvalue: 40000
stepvalue: 80000
I1007 17:39:01.190724  5078 solver.cpp:87] Creating training net from net file: /home/x306/caffe/xn/PENLU/neural/resnet/res32/res32_penlu_decay_gauss.prototxt
I1007 17:39:01.193044  5078 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: /home/x306/caffe/xn/PENLU/neural/resnet/res32/res32_penlu_decay_gauss.prototxt
I1007 17:39:01.193055  5078 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I1007 17:39:01.193218  5078 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer Data1
I1007 17:39:01.193305  5078 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer Accuracy1
I1007 17:39:01.194011  5078 net.cpp:51] Initializing net from parameters: 
name: "resnet_cifar10"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "Data1"
  type: "Data"
  top: "Data1"
  top: "Data2"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 28
    mean_file: "/home/x306/caffe/xn/PENLU/data/cifar10/mean.binaryproto"
  }
  data_param {
    source: "/home/x306/caffe/xn/PENLU/data/cifar10/cifar10_train_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "Convolution1"
  type: "Convolution"
  bottom: "Data1"
  top: "Convolution1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm1"
  type: "BatchNorm"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1"
  type: "Scale"
  bottom: "Convolution1"
  top: "Convolution1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu1"
  type: "PENLU"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution2"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm2"
  type: "BatchNorm"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale2"
  type: "Scale"
  bottom: "Convolution2"
  top: "Convolution2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu2"
  type: "PENLU"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution3"
  type: "Convolution"
  bottom: "Convolution2"
  top: "Convolution3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm3"
  type: "BatchNorm"
  bottom: "Convolution3"
  top: "Convolution3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale3"
  type: "Scale"
  bottom: "Convolution3"
  top: "Convolution3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise1"
  type: "Eltwise"
  bottom: "Convolution1"
  bottom: "Convolution3"
  top: "Eltwise1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu3"
  type: "PENLU"
  bottom: "Eltwise1"
  top: "Eltwise1"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution4"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm4"
  type: "BatchNorm"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale4"
  type: "Scale"
  bottom: "Convolution4"
  top: "Convolution4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu4"
  type: "PENLU"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution5"
  type: "Convolution"
  bottom: "Convolution4"
  top: "Convolution5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm5"
  type: "BatchNorm"
  bottom: "Convolution5"
  top: "Convolution5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale5"
  type: "Scale"
  bottom: "Convolution5"
  top: "Convolution5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise2"
  type: "Eltwise"
  bottom: "Eltwise1"
  bottom: "Convolution5"
  top: "Eltwise2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu5"
  type: "PENLU"
  bottom: "Eltwise2"
  top: "Eltwise2"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution6"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm6"
  type: "BatchNorm"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale6"
  type: "Scale"
  bottom: "Convolution6"
  top: "Convolution6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu6"
  type: "PENLU"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution7"
  type: "Convolution"
  bottom: "Convolution6"
  top: "Convolution7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm7"
  type: "BatchNorm"
  bottom: "Convolution7"
  top: "Convolution7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale7"
  type: "Scale"
  bottom: "Convolution7"
  top: "Convolution7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise3"
  type: "Eltwise"
  bottom: "Eltwise2"
  bottom: "Convolution7"
  top: "Eltwise3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu7"
  type: "PENLU"
  bottom: "Eltwise3"
  top: "Eltwise3"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution8"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm8"
  type: "BatchNorm"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale8"
  type: "Scale"
  bottom: "Convolution8"
  top: "Convolution8"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu8"
  type: "PENLU"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution9"
  type: "Convolution"
  bottom: "Convolution8"
  top: "Convolution9"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm9"
  type: "BatchNorm"
  bottom: "Convolution9"
  top: "Convolution9"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale9"
  type: "Scale"
  bottom: "Convolution9"
  top: "Convolution9"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise4"
  type: "Eltwise"
  bottom: "Eltwise3"
  bottom: "Convolution9"
  top: "Eltwise4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu9"
  type: "PENLU"
  bottom: "Eltwise4"
  top: "Eltwise4"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution10"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution10"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm10"
  type: "BatchNorm"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale10"
  type: "Scale"
  bottom: "Convolution10"
  top: "Convolution10"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu10"
  type: "PENLU"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution11"
  type: "Convolution"
  bottom: "Convolution10"
  top: "Convolution11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm11"
  type: "BatchNorm"
  bottom: "Convolution11"
  top: "Convolution11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale11"
  type: "Scale"
  bottom: "Convolution11"
  top: "Convolution11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise5"
  type: "Eltwise"
  bottom: "Eltwise4"
  bottom: "Convolution11"
  top: "Eltwise5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu11"
  type: "PENLU"
  bottom: "Eltwise5"
  top: "Eltwise5"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution12"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.25
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm12"
  type: "BatchNorm"
  bottom: "Convolution12"
  top: "Convolution12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale12"
  type: "Scale"
  bottom: "Convolution12"
  top: "Convolution12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution13"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution13"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm13"
  type: "BatchNorm"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale13"
  type: "Scale"
  bottom: "Convolution13"
  top: "Convolution13"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu12"
  type: "PENLU"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution14"
  type: "Convolution"
  bottom: "Convolution13"
  top: "Convolution14"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm14"
  type: "BatchNorm"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale14"
  type: "Scale"
  bottom: "Convolution14"
  top: "Convolution14"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise6"
  type: "Eltwise"
  bottom: "Convolution12"
  bottom: "Convolution14"
  top: "Eltwise6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu13"
  type: "PENLU"
  bottom: "Eltwise6"
  top: "Eltwise6"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution15"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution15"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm15"
  type: "BatchNorm"
  bottom: "Convolution15"
  top: "Convolution15"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale15"
  type: "Scale"
  bottom: "Convolution15"
  top: "Convolution15"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu14"
  type: "PENLU"
  bottom: "Convolution15"
  top: "Convolution15"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution16"
  type: "Convolution"
  bottom: "Convolution15"
  top: "Convolution16"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm16"
  type: "BatchNorm"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale16"
  type: "Scale"
  bottom: "Convolution16"
  top: "Convolution16"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise7"
  type: "Eltwise"
  bottom: "Eltwise6"
  bottom: "Convolution16"
  top: "Eltwise7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu15"
  type: "PENLU"
  bottom: "Eltwise7"
  top: "Eltwise7"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution17"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution17"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm17"
  type: "BatchNorm"
  bottom: "Convolution17"
  top: "Convolution17"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale17"
  type: "Scale"
  bottom: "Convolution17"
  top: "Convolution17"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu16"
  type: "PENLU"
  bottom: "Convolution17"
  top: "Convolution17"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution18"
  type: "Convolution"
  bottom: "Convolution17"
  top: "Convolution18"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm18"
  type: "BatchNorm"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale18"
  type: "Scale"
  bottom: "Convolution18"
  top: "Convolution18"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise8"
  type: "Eltwise"
  bottom: "Eltwise7"
  bottom: "Convolution18"
  top: "Eltwise8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu17"
  type: "PENLU"
  bottom: "Eltwise8"
  top: "Eltwise8"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution19"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution19"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm19"
  type: "BatchNorm"
  bottom: "Convolution19"
  top: "Convolution19"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale19"
  type: "Scale"
  bottom: "Convolution19"
  top: "Convolution19"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu18"
  type: "PENLU"
  bottom: "Convolution19"
  top: "Convolution19"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution20"
  type: "Convolution"
  bottom: "Convolution19"
  top: "Convolution20"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm20"
  type: "BatchNorm"
  bottom: "Convolution20"
  top: "Convolution20"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale20"
  type: "Scale"
  bottom: "Convolution20"
  top: "Convolution20"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise9"
  type: "Eltwise"
  bottom: "Eltwise8"
  bottom: "Convolution20"
  top: "Eltwise9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu19"
  type: "PENLU"
  bottom: "Eltwise9"
  top: "Eltwise9"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution21"
  type: "Convolution"
  bottom: "Eltwise9"
  top: "Convolution21"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm21"
  type: "BatchNorm"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale21"
  type: "Scale"
  bottom: "Convolution21"
  top: "Convolution21"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu20"
  type: "PENLU"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution22"
  type: "Convolution"
  bottom: "Convolution21"
  top: "Convolution22"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm22"
  type: "BatchNorm"
  bottom: "Convolution22"
  top: "Convolution22"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale22"
  type: "Scale"
  bottom: "Convolution22"
  top: "Convolution22"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise10"
  type: "Eltwise"
  bottom: "Eltwise9"
  bottom: "Convolution22"
  top: "Eltwise10"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu21"
  type: "PENLU"
  bottom: "Eltwise10"
  top: "Eltwise10"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution23"
  type: "Convolution"
  bottom: "Eltwise10"
  top: "Convolution23"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.17677669
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm23"
  type: "BatchNorm"
  bottom: "Convolution23"
  top: "Convolution23"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale23"
  type: "Scale"
  bottom: "Convolution23"
  top: "Convolution23"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution24"
  type: "Convolution"
  bottom: "Eltwise10"
  top: "Convolution24"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm24"
  type: "BatchNorm"
  bottom: "Convolution24"
  top: "Convolution24"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale24"
  type: "Scale"
  bottom: "Convolution24"
  top: "Convolution24"
  scale_param {
    bias
I1007 17:39:01.194478  5078 layer_factory.hpp:77] Creating layer Data1
I1007 17:39:01.194555  5078 db_lmdb.cpp:35] Opened lmdb /home/x306/caffe/xn/PENLU/data/cifar10/cifar10_train_lmdb
I1007 17:39:01.194573  5078 net.cpp:84] Creating Layer Data1
I1007 17:39:01.194579  5078 net.cpp:380] Data1 -> Data1
I1007 17:39:01.194597  5078 net.cpp:380] Data1 -> Data2
I1007 17:39:01.194604  5078 data_transformer.cpp:25] Loading mean file from: /home/x306/caffe/xn/PENLU/data/cifar10/mean.binaryproto
I1007 17:39:01.195979  5078 data_layer.cpp:45] output data size: 100,3,28,28
I1007 17:39:01.198207  5078 net.cpp:122] Setting up Data1
I1007 17:39:01.198220  5078 net.cpp:129] Top shape: 100 3 28 28 (235200)
I1007 17:39:01.198225  5078 net.cpp:129] Top shape: 100 (100)
I1007 17:39:01.198226  5078 net.cpp:137] Memory required for data: 941200
I1007 17:39:01.198232  5078 layer_factory.hpp:77] Creating layer Convolution1
I1007 17:39:01.198249  5078 net.cpp:84] Creating Layer Convolution1
I1007 17:39:01.198253  5078 net.cpp:406] Convolution1 <- Data1
I1007 17:39:01.198262  5078 net.cpp:380] Convolution1 -> Convolution1
I1007 17:39:01.343250  5078 net.cpp:122] Setting up Convolution1
I1007 17:39:01.343273  5078 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 17:39:01.343277  5078 net.cpp:137] Memory required for data: 5958800
I1007 17:39:01.343291  5078 layer_factory.hpp:77] Creating layer BatchNorm1
I1007 17:39:01.343312  5078 net.cpp:84] Creating Layer BatchNorm1
I1007 17:39:01.343336  5078 net.cpp:406] BatchNorm1 <- Convolution1
I1007 17:39:01.343344  5078 net.cpp:367] BatchNorm1 -> Convolution1 (in-place)
I1007 17:39:01.343492  5078 net.cpp:122] Setting up BatchNorm1
I1007 17:39:01.343497  5078 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 17:39:01.343498  5078 net.cpp:137] Memory required for data: 10976400
I1007 17:39:01.343508  5078 layer_factory.hpp:77] Creating layer Scale1
I1007 17:39:01.343526  5078 net.cpp:84] Creating Layer Scale1
I1007 17:39:01.343528  5078 net.cpp:406] Scale1 <- Convolution1
I1007 17:39:01.343533  5078 net.cpp:367] Scale1 -> Convolution1 (in-place)
I1007 17:39:01.343585  5078 layer_factory.hpp:77] Creating layer Scale1
I1007 17:39:01.343719  5078 net.cpp:122] Setting up Scale1
I1007 17:39:01.343724  5078 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 17:39:01.343736  5078 net.cpp:137] Memory required for data: 15994000
I1007 17:39:01.343740  5078 layer_factory.hpp:77] Creating layer penlu1
I1007 17:39:01.343761  5078 net.cpp:84] Creating Layer penlu1
I1007 17:39:01.343766  5078 net.cpp:406] penlu1 <- Convolution1
I1007 17:39:01.343775  5078 net.cpp:367] penlu1 -> Convolution1 (in-place)
I1007 17:39:01.344386  5078 net.cpp:122] Setting up penlu1
I1007 17:39:01.344395  5078 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 17:39:01.344408  5078 net.cpp:137] Memory required for data: 21011600
I1007 17:39:01.344415  5078 layer_factory.hpp:77] Creating layer Convolution1_penlu1_0_split
I1007 17:39:01.344436  5078 net.cpp:84] Creating Layer Convolution1_penlu1_0_split
I1007 17:39:01.344439  5078 net.cpp:406] Convolution1_penlu1_0_split <- Convolution1
I1007 17:39:01.344444  5078 net.cpp:380] Convolution1_penlu1_0_split -> Convolution1_penlu1_0_split_0
I1007 17:39:01.344451  5078 net.cpp:380] Convolution1_penlu1_0_split -> Convolution1_penlu1_0_split_1
I1007 17:39:01.344488  5078 net.cpp:122] Setting up Convolution1_penlu1_0_split
I1007 17:39:01.344494  5078 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 17:39:01.344511  5078 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 17:39:01.344513  5078 net.cpp:137] Memory required for data: 31046800
I1007 17:39:01.344516  5078 layer_factory.hpp:77] Creating layer Convolution2
I1007 17:39:01.344535  5078 net.cpp:84] Creating Layer Convolution2
I1007 17:39:01.344550  5078 net.cpp:406] Convolution2 <- Convolution1_penlu1_0_split_0
I1007 17:39:01.344557  5078 net.cpp:380] Convolution2 -> Convolution2
I1007 17:39:01.345448  5078 net.cpp:122] Setting up Convolution2
I1007 17:39:01.345459  5078 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 17:39:01.345464  5078 net.cpp:137] Memory required for data: 36064400
I1007 17:39:01.345482  5078 layer_factory.hpp:77] Creating layer BatchNorm2
I1007 17:39:01.345491  5078 net.cpp:84] Creating Layer BatchNorm2
I1007 17:39:01.345495  5078 net.cpp:406] BatchNorm2 <- Convolution2
I1007 17:39:01.345502  5078 net.cpp:367] BatchNorm2 -> Convolution2 (in-place)
I1007 17:39:01.345638  5078 net.cpp:122] Setting up BatchNorm2
I1007 17:39:01.345644  5078 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 17:39:01.345649  5078 net.cpp:137] Memory required for data: 41082000
I1007 17:39:01.345667  5078 layer_factory.hpp:77] Creating layer Scale2
I1007 17:39:01.345675  5078 net.cpp:84] Creating Layer Scale2
I1007 17:39:01.345679  5078 net.cpp:406] Scale2 <- Convolution2
I1007 17:39:01.345685  5078 net.cpp:367] Scale2 -> Convolution2 (in-place)
I1007 17:39:01.345718  5078 layer_factory.hpp:77] Creating layer Scale2
I1007 17:39:01.345796  5078 net.cpp:122] Setting up Scale2
I1007 17:39:01.345803  5078 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 17:39:01.345808  5078 net.cpp:137] Memory required for data: 46099600
I1007 17:39:01.345818  5078 layer_factory.hpp:77] Creating layer penlu2
I1007 17:39:01.345825  5078 net.cpp:84] Creating Layer penlu2
I1007 17:39:01.345829  5078 net.cpp:406] penlu2 <- Convolution2
I1007 17:39:01.345836  5078 net.cpp:367] penlu2 -> Convolution2 (in-place)
I1007 17:39:01.345937  5078 net.cpp:122] Setting up penlu2
I1007 17:39:01.345950  5078 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 17:39:01.345955  5078 net.cpp:137] Memory required for data: 51117200
I1007 17:39:01.345963  5078 layer_factory.hpp:77] Creating layer Convolution3
I1007 17:39:01.345973  5078 net.cpp:84] Creating Layer Convolution3
I1007 17:39:01.345976  5078 net.cpp:406] Convolution3 <- Convolution2
I1007 17:39:01.345983  5078 net.cpp:380] Convolution3 -> Convolution3
I1007 17:39:01.346880  5078 net.cpp:122] Setting up Convolution3
I1007 17:39:01.346892  5078 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 17:39:01.346897  5078 net.cpp:137] Memory required for data: 56134800
I1007 17:39:01.346905  5078 layer_factory.hpp:77] Creating layer BatchNorm3
I1007 17:39:01.346915  5078 net.cpp:84] Creating Layer BatchNorm3
I1007 17:39:01.346918  5078 net.cpp:406] BatchNorm3 <- Convolution3
I1007 17:39:01.346925  5078 net.cpp:367] BatchNorm3 -> Convolution3 (in-place)
I1007 17:39:01.347054  5078 net.cpp:122] Setting up BatchNorm3
I1007 17:39:01.347060  5078 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 17:39:01.347064  5078 net.cpp:137] Memory required for data: 61152400
I1007 17:39:01.347072  5078 layer_factory.hpp:77] Creating layer Scale3
I1007 17:39:01.347079  5078 net.cpp:84] Creating Layer Scale3
I1007 17:39:01.347084  5078 net.cpp:406] Scale3 <- Convolution3
I1007 17:39:01.347090  5078 net.cpp:367] Scale3 -> Convolution3 (in-place)
I1007 17:39:01.347118  5078 layer_factory.hpp:77] Creating layer Scale3
I1007 17:39:01.347220  5078 net.cpp:122] Setting up Scale3
I1007 17:39:01.347228  5078 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 17:39:01.347231  5078 net.cpp:137] Memory required for data: 66170000
I1007 17:39:01.347239  5078 layer_factory.hpp:77] Creating layer Eltwise1
I1007 17:39:01.347246  5078 net.cpp:84] Creating Layer Eltwise1
I1007 17:39:01.347249  5078 net.cpp:406] Eltwise1 <- Convolution1_penlu1_0_split_1
I1007 17:39:01.347254  5078 net.cpp:406] Eltwise1 <- Convolution3
I1007 17:39:01.347259  5078 net.cpp:380] Eltwise1 -> Eltwise1
I1007 17:39:01.347280  5078 net.cpp:122] Setting up Eltwise1
I1007 17:39:01.347285  5078 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 17:39:01.347288  5078 net.cpp:137] Memory required for data: 71187600
I1007 17:39:01.347292  5078 layer_factory.hpp:77] Creating layer penlu3
I1007 17:39:01.347301  5078 net.cpp:84] Creating Layer penlu3
I1007 17:39:01.347304  5078 net.cpp:406] penlu3 <- Eltwise1
I1007 17:39:01.347309  5078 net.cpp:367] penlu3 -> Eltwise1 (in-place)
I1007 17:39:01.347409  5078 net.cpp:122] Setting up penlu3
I1007 17:39:01.347414  5078 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 17:39:01.347419  5078 net.cpp:137] Memory required for data: 76205200
I1007 17:39:01.347425  5078 layer_factory.hpp:77] Creating layer Eltwise1_penlu3_0_split
I1007 17:39:01.347429  5078 net.cpp:84] Creating Layer Eltwise1_penlu3_0_split
I1007 17:39:01.347434  5078 net.cpp:406] Eltwise1_penlu3_0_split <- Eltwise1
I1007 17:39:01.347439  5078 net.cpp:380] Eltwise1_penlu3_0_split -> Eltwise1_penlu3_0_split_0
I1007 17:39:01.347445  5078 net.cpp:380] Eltwise1_penlu3_0_split -> Eltwise1_penlu3_0_split_1
I1007 17:39:01.347470  5078 net.cpp:122] Setting up Eltwise1_penlu3_0_split
I1007 17:39:01.347476  5078 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 17:39:01.347481  5078 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 17:39:01.347484  5078 net.cpp:137] Memory required for data: 86240400
I1007 17:39:01.347487  5078 layer_factory.hpp:77] Creating layer Convolution4
I1007 17:39:01.347497  5078 net.cpp:84] Creating Layer Convolution4
I1007 17:39:01.347501  5078 net.cpp:406] Convolution4 <- Eltwise1_penlu3_0_split_0
I1007 17:39:01.347506  5078 net.cpp:380] Convolution4 -> Convolution4
I1007 17:39:01.348347  5078 net.cpp:122] Setting up Convolution4
I1007 17:39:01.348358  5078 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 17:39:01.348363  5078 net.cpp:137] Memory required for data: 91258000
I1007 17:39:01.348371  5078 layer_factory.hpp:77] Creating layer BatchNorm4
I1007 17:39:01.348378  5078 net.cpp:84] Creating Layer BatchNorm4
I1007 17:39:01.348389  5078 net.cpp:406] BatchNorm4 <- Convolution4
I1007 17:39:01.348395  5078 net.cpp:367] BatchNorm4 -> Convolution4 (in-place)
I1007 17:39:01.348515  5078 net.cpp:122] Setting up BatchNorm4
I1007 17:39:01.348521  5078 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 17:39:01.348526  5078 net.cpp:137] Memory required for data: 96275600
I1007 17:39:01.348536  5078 layer_factory.hpp:77] Creating layer Scale4
I1007 17:39:01.348541  5078 net.cpp:84] Creating Layer Scale4
I1007 17:39:01.348546  5078 net.cpp:406] Scale4 <- Convolution4
I1007 17:39:01.348551  5078 net.cpp:367] Scale4 -> Convolution4 (in-place)
I1007 17:39:01.348579  5078 layer_factory.hpp:77] Creating layer Scale4
I1007 17:39:01.348651  5078 net.cpp:122] Setting up Scale4
I1007 17:39:01.348657  5078 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 17:39:01.348661  5078 net.cpp:137] Memory required for data: 101293200
I1007 17:39:01.348668  5078 layer_factory.hpp:77] Creating layer penlu4
I1007 17:39:01.348675  5078 net.cpp:84] Creating Layer penlu4
I1007 17:39:01.348680  5078 net.cpp:406] penlu4 <- Convolution4
I1007 17:39:01.348685  5078 net.cpp:367] penlu4 -> Convolution4 (in-place)
I1007 17:39:01.348779  5078 net.cpp:122] Setting up penlu4
I1007 17:39:01.348785  5078 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 17:39:01.348789  5078 net.cpp:137] Memory required for data: 106310800
I1007 17:39:01.348796  5078 layer_factory.hpp:77] Creating layer Convolution5
I1007 17:39:01.348805  5078 net.cpp:84] Creating Layer Convolution5
I1007 17:39:01.348809  5078 net.cpp:406] Convolution5 <- Convolution4
I1007 17:39:01.348814  5078 net.cpp:380] Convolution5 -> Convolution5
I1007 17:39:01.349656  5078 net.cpp:122] Setting up Convolution5
I1007 17:39:01.349668  5078 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 17:39:01.349673  5078 net.cpp:137] Memory required for data: 111328400
I1007 17:39:01.349680  5078 layer_factory.hpp:77] Creating layer BatchNorm5
I1007 17:39:01.349689  5078 net.cpp:84] Creating Layer BatchNorm5
I1007 17:39:01.349692  5078 net.cpp:406] BatchNorm5 <- Convolution5
I1007 17:39:01.349699  5078 net.cpp:367] BatchNorm5 -> Convolution5 (in-place)
I1007 17:39:01.349822  5078 net.cpp:122] Setting up BatchNorm5
I1007 17:39:01.349828  5078 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 17:39:01.349833  5078 net.cpp:137] Memory required for data: 116346000
I1007 17:39:01.349839  5078 layer_factory.hpp:77] Creating layer Scale5
I1007 17:39:01.349844  5078 net.cpp:84] Creating Layer Scale5
I1007 17:39:01.349848  5078 net.cpp:406] Scale5 <- Convolution5
I1007 17:39:01.349854  5078 net.cpp:367] Scale5 -> Convolution5 (in-place)
I1007 17:39:01.349882  5078 layer_factory.hpp:77] Creating layer Scale5
I1007 17:39:01.349958  5078 net.cpp:122] Setting up Scale5
I1007 17:39:01.349964  5078 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 17:39:01.349968  5078 net.cpp:137] Memory required for data: 121363600
I1007 17:39:01.349974  5078 layer_factory.hpp:77] Creating layer Eltwise2
I1007 17:39:01.349979  5078 net.cpp:84] Creating Layer Eltwise2
I1007 17:39:01.349983  5078 net.cpp:406] Eltwise2 <- Eltwise1_penlu3_0_split_1
I1007 17:39:01.349988  5078 net.cpp:406] Eltwise2 <- Convolution5
I1007 17:39:01.349995  5078 net.cpp:380] Eltwise2 -> Eltwise2
I1007 17:39:01.350013  5078 net.cpp:122] Setting up Eltwise2
I1007 17:39:01.350018  5078 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 17:39:01.350021  5078 net.cpp:137] Memory required for data: 126381200
I1007 17:39:01.350024  5078 layer_factory.hpp:77] Creating layer penlu5
I1007 17:39:01.350033  5078 net.cpp:84] Creating Layer penlu5
I1007 17:39:01.350036  5078 net.cpp:406] penlu5 <- Eltwise2
I1007 17:39:01.350041  5078 net.cpp:367] penlu5 -> Eltwise2 (in-place)
I1007 17:39:01.350143  5078 net.cpp:122] Setting up penlu5
I1007 17:39:01.350149  5078 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 17:39:01.350153  5078 net.cpp:137] Memory required for data: 131398800
I1007 17:39:01.350160  5078 layer_factory.hpp:77] Creating layer Eltwise2_penlu5_0_split
I1007 17:39:01.350172  5078 net.cpp:84] Creating Layer Eltwise2_penlu5_0_split
I1007 17:39:01.350177  5078 net.cpp:406] Eltwise2_penlu5_0_split <- Eltwise2
I1007 17:39:01.350181  5078 net.cpp:380] Eltwise2_penlu5_0_split -> Eltwise2_penlu5_0_split_0
I1007 17:39:01.350188  5078 net.cpp:380] Eltwise2_penlu5_0_split -> Eltwise2_penlu5_0_split_1
I1007 17:39:01.350211  5078 net.cpp:122] Setting up Eltwise2_penlu5_0_split
I1007 17:39:01.350216  5078 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 17:39:01.350221  5078 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 17:39:01.350225  5078 net.cpp:137] Memory required for data: 141434000
I1007 17:39:01.350229  5078 layer_factory.hpp:77] Creating layer Convolution6
I1007 17:39:01.350239  5078 net.cpp:84] Creating Layer Convolution6
I1007 17:39:01.350242  5078 net.cpp:406] Convolution6 <- Eltwise2_penlu5_0_split_0
I1007 17:39:01.350248  5078 net.cpp:380] Convolution6 -> Convolution6
I1007 17:39:01.351092  5078 net.cpp:122] Setting up Convolution6
I1007 17:39:01.351104  5078 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 17:39:01.351109  5078 net.cpp:137] Memory required for data: 146451600
I1007 17:39:01.351116  5078 layer_factory.hpp:77] Creating layer BatchNorm6
I1007 17:39:01.351124  5078 net.cpp:84] Creating Layer BatchNorm6
I1007 17:39:01.351127  5078 net.cpp:406] BatchNorm6 <- Convolution6
I1007 17:39:01.351135  5078 net.cpp:367] BatchNorm6 -> Convolution6 (in-place)
I1007 17:39:01.351294  5078 net.cpp:122] Setting up BatchNorm6
I1007 17:39:01.351300  5078 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 17:39:01.351305  5078 net.cpp:137] Memory required for data: 151469200
I1007 17:39:01.351311  5078 layer_factory.hpp:77] Creating layer Scale6
I1007 17:39:01.351318  5078 net.cpp:84] Creating Layer Scale6
I1007 17:39:01.351322  5078 net.cpp:406] Scale6 <- Convolution6
I1007 17:39:01.351327  5078 net.cpp:367] Scale6 -> Convolution6 (in-place)
I1007 17:39:01.351356  5078 layer_factory.hpp:77] Creating layer Scale6
I1007 17:39:01.351430  5078 net.cpp:122] Setting up Scale6
I1007 17:39:01.351436  5078 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 17:39:01.351440  5078 net.cpp:137] Memory required for data: 156486800
I1007 17:39:01.351446  5078 layer_factory.hpp:77] Creating layer penlu6
I1007 17:39:01.351454  5078 net.cpp:84] Creating Layer penlu6
I1007 17:39:01.351459  5078 net.cpp:406] penlu6 <- Convolution6
I1007 17:39:01.351464  5078 net.cpp:367] penlu6 -> Convolution6 (in-place)
I1007 17:39:01.351567  5078 net.cpp:122] Setting up penlu6
I1007 17:39:01.351572  5078 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 17:39:01.351577  5078 net.cpp:137] Memory required for data: 161504400
I1007 17:39:01.351583  5078 layer_factory.hpp:77] Creating layer Convolution7
I1007 17:39:01.351593  5078 net.cpp:84] Creating Layer Convolution7
I1007 17:39:01.351595  5078 net.cpp:406] Convolution7 <- Convolution6
I1007 17:39:01.351601  5078 net.cpp:380] Convolution7 -> Convolution7
I1007 17:39:01.352131  5078 net.cpp:122] Setting up Convolution7
I1007 17:39:01.352144  5078 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 17:39:01.352149  5078 net.cpp:137] Memory required for data: 166522000
I1007 17:39:01.352154  5078 layer_factory.hpp:77] Creating layer BatchNorm7
I1007 17:39:01.352160  5078 net.cpp:84] Creating Layer BatchNorm7
I1007 17:39:01.352164  5078 net.cpp:406] BatchNorm7 <- Convolution7
I1007 17:39:01.352170  5078 net.cpp:367] BatchNorm7 -> Convolution7 (in-place)
I1007 17:39:01.352293  5078 net.cpp:122] Setting up BatchNorm7
I1007 17:39:01.352299  5078 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 17:39:01.352304  5078 net.cpp:137] Memory required for data: 171539600
I1007 17:39:01.352316  5078 layer_factory.hpp:77] Creating layer Scale7
I1007 17:39:01.352324  5078 net.cpp:84] Creating Layer Scale7
I1007 17:39:01.352327  5078 net.cpp:406] Scale7 <- Convolution7
I1007 17:39:01.352332  5078 net.cpp:367] Scale7 -> Convolution7 (in-place)
I1007 17:39:01.352360  5078 layer_factory.hpp:77] Creating layer Scale7
I1007 17:39:01.352442  5078 net.cpp:122] Setting up Scale7
I1007 17:39:01.352449  5078 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 17:39:01.352453  5078 net.cpp:137] Memory required for data: 176557200
I1007 17:39:01.352459  5078 layer_factory.hpp:77] Creating layer Eltwise3
I1007 17:39:01.352464  5078 net.cpp:84] Creating Layer Eltwise3
I1007 17:39:01.352468  5078 net.cpp:406] Eltwise3 <- Eltwise2_penlu5_0_split_1
I1007 17:39:01.352473  5078 net.cpp:406] Eltwise3 <- Convolution7
I1007 17:39:01.352480  5078 net.cpp:380] Eltwise3 -> Eltwise3
I1007 17:39:01.352497  5078 net.cpp:122] Setting up Eltwise3
I1007 17:39:01.352502  5078 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 17:39:01.352506  5078 net.cpp:137] Memory required for data: 181574800
I1007 17:39:01.352509  5078 layer_factory.hpp:77] Creating layer penlu7
I1007 17:39:01.352516  5078 net.cpp:84] Creating Layer penlu7
I1007 17:39:01.352520  5078 net.cpp:406] penlu7 <- Eltwise3
I1007 17:39:01.352526  5078 net.cpp:367] penlu7 -> Eltwise3 (in-place)
I1007 17:39:01.352627  5078 net.cpp:122] Setting up penlu7
I1007 17:39:01.352633  5078 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 17:39:01.352638  5078 net.cpp:137] Memory required for data: 186592400
I1007 17:39:01.352644  5078 layer_factory.hpp:77] Creating layer Eltwise3_penlu7_0_split
I1007 17:39:01.352649  5078 net.cpp:84] Creating Layer Eltwise3_penlu7_0_split
I1007 17:39:01.352653  5078 net.cpp:406] Eltwise3_penlu7_0_split <- Eltwise3
I1007 17:39:01.352658  5078 net.cpp:380] Eltwise3_penlu7_0_split -> Eltwise3_penlu7_0_split_0
I1007 17:39:01.352664  5078 net.cpp:380] Eltwise3_penlu7_0_split -> Eltwise3_penlu7_0_split_1
I1007 17:39:01.352689  5078 net.cpp:122] Setting up Eltwise3_penlu7_0_split
I1007 17:39:01.352694  5078 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 17:39:01.352699  5078 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 17:39:01.352702  5078 net.cpp:137] Memory required for data: 196627600
I1007 17:39:01.352706  5078 layer_factory.hpp:77] Creating layer Convolution8
I1007 17:39:01.352715  5078 net.cpp:84] Creating Layer Convolution8
I1007 17:39:01.352720  5078 net.cpp:406] Convolution8 <- Eltwise3_penlu7_0_split_0
I1007 17:39:01.352725  5078 net.cpp:380] Convolution8 -> Convolution8
I1007 17:39:01.353588  5078 net.cpp:122] Setting up Convolution8
I1007 17:39:01.353600  5078 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 17:39:01.353615  5078 net.cpp:137] Memory required for data: 201645200
I1007 17:39:01.353622  5078 layer_factory.hpp:77] Creating layer BatchNorm8
I1007 17:39:01.353628  5078 net.cpp:84] Creating Layer BatchNorm8
I1007 17:39:01.353632  5078 net.cpp:406] BatchNorm8 <- Convolution8
I1007 17:39:01.353648  5078 net.cpp:367] BatchNorm8 -> Convolution8 (in-place)
I1007 17:39:01.353773  5078 net.cpp:122] Setting up BatchNorm8
I1007 17:39:01.353780  5078 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 17:39:01.353785  5078 net.cpp:137] Memory required for data: 206662800
I1007 17:39:01.353792  5078 layer_factory.hpp:77] Creating layer Scale8
I1007 17:39:01.353797  5078 net.cpp:84] Creating Layer Scale8
I1007 17:39:01.353802  5078 net.cpp:406] Scale8 <- Convolution8
I1007 17:39:01.353809  5078 net.cpp:367] Scale8 -> Convolution8 (in-place)
I1007 17:39:01.353835  5078 layer_factory.hpp:77] Creating layer Scale8
I1007 17:39:01.353924  5078 net.cpp:122] Setting up Scale8
I1007 17:39:01.353930  5078 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 17:39:01.353935  5078 net.cpp:137] Memory required for data: 211680400
I1007 17:39:01.353941  5078 layer_factory.hpp:77] Creating layer penlu8
I1007 17:39:01.353950  5078 net.cpp:84] Creating Layer penlu8
I1007 17:39:01.353952  5078 net.cpp:406] penlu8 <- Convolution8
I1007 17:39:01.353958  5078 net.cpp:367] penlu8 -> Convolution8 (in-place)
I1007 17:39:01.354059  5078 net.cpp:122] Setting up penlu8
I1007 17:39:01.354068  5078 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 17:39:01.354071  5078 net.cpp:137] Memory required for data: 216698000
I1007 17:39:01.354079  5078 layer_factory.hpp:77] Creating layer Convolution9
I1007 17:39:01.354094  5078 net.cpp:84] Creating Layer Convolution9
I1007 17:39:01.354097  5078 net.cpp:406] Convolution9 <- Convolution8
I1007 17:39:01.354104  5078 net.cpp:380] Convolution9 -> Convolution9
I1007 17:39:01.355059  5078 net.cpp:122] Setting up Convolution9
I1007 17:39:01.355072  5078 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 17:39:01.355077  5078 net.cpp:137] Memory required for data: 221715600
I1007 17:39:01.355084  5078 layer_factory.hpp:77] Creating layer BatchNorm9
I1007 17:39:01.355096  5078 net.cpp:84] Creating Layer BatchNorm9
I1007 17:39:01.355103  5078 net.cpp:406] BatchNorm9 <- Convolution9
I1007 17:39:01.355108  5078 net.cpp:367] BatchNorm9 -> Convolution9 (in-place)
I1007 17:39:01.355267  5078 net.cpp:122] Setting up BatchNorm9
I1007 17:39:01.355275  5078 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 17:39:01.355279  5078 net.cpp:137] Memory required for data: 226733200
I1007 17:39:01.355288  5078 layer_factory.hpp:77] Creating layer Scale9
I1007 17:39:01.355295  5078 net.cpp:84] Creating Layer Scale9
I1007 17:39:01.355300  5078 net.cpp:406] Scale9 <- Convolution9
I1007 17:39:01.355306  5078 net.cpp:367] Scale9 -> Convolution9 (in-place)
I1007 17:39:01.355340  5078 layer_factory.hpp:77] Creating layer Scale9
I1007 17:39:01.355420  5078 net.cpp:122] Setting up Scale9
I1007 17:39:01.355428  5078 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 17:39:01.355433  5078 net.cpp:137] Memory required for data: 231750800
I1007 17:39:01.355442  5078 layer_factory.hpp:77] Creating layer Eltwise4
I1007 17:39:01.355448  5078 net.cpp:84] Creating Layer Eltwise4
I1007 17:39:01.355453  5078 net.cpp:406] Eltwise4 <- Eltwise3_penlu7_0_split_1
I1007 17:39:01.355459  5078 net.cpp:406] Eltwise4 <- Convolution9
I1007 17:39:01.355466  5078 net.cpp:380] Eltwise4 -> Eltwise4
I1007 17:39:01.355487  5078 net.cpp:122] Setting up Eltwise4
I1007 17:39:01.355494  5078 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 17:39:01.355497  5078 net.cpp:137] Memory required for data: 236768400
I1007 17:39:01.355504  5078 layer_factory.hpp:77] Creating layer penlu9
I1007 17:39:01.355515  5078 net.cpp:84] Creating Layer penlu9
I1007 17:39:01.355518  5078 net.cpp:406] penlu9 <- Eltwise4
I1007 17:39:01.355525  5078 net.cpp:367] penlu9 -> Eltwise4 (in-place)
I1007 17:39:01.355635  5078 net.cpp:122] Setting up penlu9
I1007 17:39:01.355643  5078 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 17:39:01.355648  5078 net.cpp:137] Memory required for data: 241786000
I1007 17:39:01.355655  5078 layer_factory.hpp:77] Creating layer Eltwise4_penlu9_0_split
I1007 17:39:01.355662  5078 net.cpp:84] Creating Layer Eltwise4_penlu9_0_split
I1007 17:39:01.355669  5078 net.cpp:406] Eltwise4_penlu9_0_split <- Eltwise4
I1007 17:39:01.355674  5078 net.cpp:380] Eltwise4_penlu9_0_split -> Eltwise4_penlu9_0_split_0
I1007 17:39:01.355681  5078 net.cpp:380] Eltwise4_penlu9_0_split -> Eltwise4_penlu9_0_split_1
I1007 17:39:01.355708  5078 net.cpp:122] Setting up Eltwise4_penlu9_0_split
I1007 17:39:01.355715  5078 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 17:39:01.355721  5078 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 17:39:01.355726  5078 net.cpp:137] Memory required for data: 251821200
I1007 17:39:01.355731  5078 layer_factory.hpp:77] Creating layer Convolution10
I1007 17:39:01.355741  5078 net.cpp:84] Creating Layer Convolution10
I1007 17:39:01.355744  5078 net.cpp:406] Convolution10 <- Eltwise4_penlu9_0_split_0
I1007 17:39:01.355752  5078 net.cpp:380] Convolution10 -> Convolution10
I1007 17:39:01.356633  5078 net.cpp:122] Setting up Convolution10
I1007 17:39:01.356645  5078 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 17:39:01.356650  5078 net.cpp:137] Memory required for data: 256838800
I1007 17:39:01.356657  5078 layer_factory.hpp:77] Creating layer BatchNorm10
I1007 17:39:01.356667  5078 net.cpp:84] Creating Layer BatchNorm10
I1007 17:39:01.356673  5078 net.cpp:406] BatchNorm10 <- Convolution10
I1007 17:39:01.356679  5078 net.cpp:367] BatchNorm10 -> Convolution10 (in-place)
I1007 17:39:01.356820  5078 net.cpp:122] Setting up BatchNorm10
I1007 17:39:01.356828  5078 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 17:39:01.356833  5078 net.cpp:137] Memory required for data: 261856400
I1007 17:39:01.356843  5078 layer_factory.hpp:77] Creating layer Scale10
I1007 17:39:01.356850  5078 net.cpp:84] Creating Layer Scale10
I1007 17:39:01.356856  5078 net.cpp:406] Scale10 <- Convolution10
I1007 17:39:01.356863  5078 net.cpp:367] Scale10 -> Convolution10 (in-place)
I1007 17:39:01.356896  5078 layer_factory.hpp:77] Creating layer Scale10
I1007 17:39:01.356978  5078 net.cpp:122] Setting up Scale10
I1007 17:39:01.356987  5078 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 17:39:01.356992  5078 net.cpp:137] Memory required for data: 266874000
I1007 17:39:01.357002  5078 layer_factory.hpp:77] Creating layer penlu10
I1007 17:39:01.357010  5078 net.cpp:84] Creating Layer penlu10
I1007 17:39:01.357015  5078 net.cpp:406] penlu10 <- Convolution10
I1007 17:39:01.357023  5078 net.cpp:367] penlu10 -> Convolution10 (in-place)
I1007 17:39:01.357134  5078 net.cpp:122] Setting up penlu10
I1007 17:39:01.357142  5078 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 17:39:01.357146  5078 net.cpp:137] Memory required for data: 271891600
I1007 17:39:01.357156  5078 layer_factory.hpp:77] Creating layer Convolution11
I1007 17:39:01.357167  5078 net.cpp:84] Creating Layer Convolution11
I1007 17:39:01.357172  5078 net.cpp:406] Convolution11 <- Convolution10
I1007 17:39:01.357180  5078 net.cpp:380] Convolution11 -> Convolution11
I1007 17:39:01.358069  5078 net.cpp:122] Setting up Convolution11
I1007 17:39:01.358080  5078 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 17:39:01.358085  5078 net.cpp:137] Memory required for data: 276909200
I1007 17:39:01.358093  5078 layer_factory.hpp:77] Creating layer BatchNorm11
I1007 17:39:01.358103  5078 net.cpp:84] Creating Layer BatchNorm11
I1007 17:39:01.358108  5078 net.cpp:406] BatchNorm11 <- Convolution11
I1007 17:39:01.358114  5078 net.cpp:367] BatchNorm11 -> Convolution11 (in-place)
I1007 17:39:01.358249  5078 net.cpp:122] Setting up BatchNorm11
I1007 17:39:01.358258  5078 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 17:39:01.358263  5078 net.cpp:137] Memory required for data: 281926800
I1007 17:39:01.358270  5078 layer_factory.hpp:77] Creating layer Scale11
I1007 17:39:01.358278  5078 net.cpp:84] Creating Layer Scale11
I1007 17:39:01.358283  5078 net.cpp:406] Scale11 <- Convolution11
I1007 17:39:01.358289  5078 net.cpp:367] Scale11 -> Convolution11 (in-place)
I1007 17:39:01.358324  5078 layer_factory.hpp:77] Creating layer Scale11
I1007 17:39:01.358407  5078 net.cpp:122] Setting up Scale11
I1007 17:39:01.358414  5078 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 17:39:01.358418  5078 net.cpp:137] Memory required for data: 286944400
I1007 17:39:01.358425  5078 layer_factory.hpp:77] Creating layer Eltwise5
I1007 17:39:01.358433  5078 net.cpp:84] Creating Layer Eltwise5
I1007 17:39:01.358439  5078 net.cpp:406] Eltwise5 <- Eltwise4_penlu9_0_split_1
I1007 17:39:01.358444  5078 net.cpp:406] Eltwise5 <- Convolution11
I1007 17:39:01.358451  5078 net.cpp:380] Eltwise5 -> Eltwise5
I1007 17:39:01.358474  5078 net.cpp:122] Setting up Eltwise5
I1007 17:39:01.358481  5078 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 17:39:01.358485  5078 net.cpp:137] Memory required for data: 291962000
I1007 17:39:01.358491  5078 layer_factory.hpp:77] Creating layer penlu11
I1007 17:39:01.358500  5078 net.cpp:84] Creating Layer penlu11
I1007 17:39:01.358505  5078 net.cpp:406] penlu11 <- Eltwise5
I1007 17:39:01.358511  5078 net.cpp:367] penlu11 -> Eltwise5 (in-place)
I1007 17:39:01.358626  5078 net.cpp:122] Setting up penlu11
I1007 17:39:01.358633  5078 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 17:39:01.358638  5078 net.cpp:137] Memory required for data: 296979600
I1007 17:39:01.358645  5078 layer_factory.hpp:77] Creating layer Eltwise5_penlu11_0_split
I1007 17:39:01.358654  5078 net.cpp:84] Creating Layer Eltwise5_penlu11_0_split
I1007 17:39:01.358659  5078 net.cpp:406] Eltwise5_penlu11_0_split <- Eltwise5
I1007 17:39:01.358672  5078 net.cpp:380] Eltwise5_penlu11_0_split -> Eltwise5_penlu11_0_split_0
I1007 17:39:01.358681  5078 net.cpp:380] Eltwise5_penlu11_0_split -> Eltwise5_penlu11_0_split_1
I1007 17:39:01.358711  5078 net.cpp:122] Setting up Eltwise5_penlu11_0_split
I1007 17:39:01.358718  5078 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 17:39:01.358724  5078 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 17:39:01.358729  5078 net.cpp:137] Memory required for data: 307014800
I1007 17:39:01.358733  5078 layer_factory.hpp:77] Creating layer Convolution12
I1007 17:39:01.358743  5078 net.cpp:84] Creating Layer Convolution12
I1007 17:39:01.358748  5078 net.cpp:406] Convolution12 <- Eltwise5_penlu11_0_split_0
I1007 17:39:01.358757  5078 net.cpp:380] Convolution12 -> Convolution12
I1007 17:39:01.359951  5078 net.cpp:122] Setting up Convolution12
I1007 17:39:01.359963  5078 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 17:39:01.359968  5078 net.cpp:137] Memory required for data: 309523600
I1007 17:39:01.359977  5078 layer_factory.hpp:77] Creating layer BatchNorm12
I1007 17:39:01.359987  5078 net.cpp:84] Creating Layer BatchNorm12
I1007 17:39:01.359992  5078 net.cpp:406] BatchNorm12 <- Convolution12
I1007 17:39:01.359998  5078 net.cpp:367] BatchNorm12 -> Convolution12 (in-place)
I1007 17:39:01.360139  5078 net.cpp:122] Setting up BatchNorm12
I1007 17:39:01.360147  5078 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 17:39:01.360152  5078 net.cpp:137] Memory required for data: 312032400
I1007 17:39:01.360162  5078 layer_factory.hpp:77] Creating layer Scale12
I1007 17:39:01.360170  5078 net.cpp:84] Creating Layer Scale12
I1007 17:39:01.360175  5078 net.cpp:406] Scale12 <- Convolution12
I1007 17:39:01.360183  5078 net.cpp:367] Scale12 -> Convolution12 (in-place)
I1007 17:39:01.360214  5078 layer_factory.hpp:77] Creating layer Scale12
I1007 17:39:01.360296  5078 net.cpp:122] Setting up Scale12
I1007 17:39:01.360302  5078 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 17:39:01.360306  5078 net.cpp:137] Memory required for data: 314541200
I1007 17:39:01.360313  5078 layer_factory.hpp:77] Creating layer Convolution13
I1007 17:39:01.360325  5078 net.cpp:84] Creating Layer Convolution13
I1007 17:39:01.360330  5078 net.cpp:406] Convolution13 <- Eltwise5_penlu11_0_split_1
I1007 17:39:01.360338  5078 net.cpp:380] Convolution13 -> Convolution13
I1007 17:39:01.361595  5078 net.cpp:122] Setting up Convolution13
I1007 17:39:01.361606  5078 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 17:39:01.361611  5078 net.cpp:137] Memory required for data: 317050000
I1007 17:39:01.361619  5078 layer_factory.hpp:77] Creating layer BatchNorm13
I1007 17:39:01.361629  5078 net.cpp:84] Creating Layer BatchNorm13
I1007 17:39:01.361634  5078 net.cpp:406] BatchNorm13 <- Convolution13
I1007 17:39:01.361642  5078 net.cpp:367] BatchNorm13 -> Convolution13 (in-place)
I1007 17:39:01.361779  5078 net.cpp:122] Setting up BatchNorm13
I1007 17:39:01.361786  5078 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 17:39:01.361791  5078 net.cpp:137] Memory required for data: 319558800
I1007 17:39:01.361801  5078 layer_factory.hpp:77] Creating layer Scale13
I1007 17:39:01.361809  5078 net.cpp:84] Creating Layer Scale13
I1007 17:39:01.361814  5078 net.cpp:406] Scale13 <- Convolution13
I1007 17:39:01.361824  5078 net.cpp:367] Scale13 -> Convolution13 (in-place)
I1007 17:39:01.361855  5078 layer_factory.hpp:77] Creating layer Scale13
I1007 17:39:01.361937  5078 net.cpp:122] Setting up Scale13
I1007 17:39:01.361944  5078 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 17:39:01.361948  5078 net.cpp:137] Memory required for data: 322067600
I1007 17:39:01.361955  5078 layer_factory.hpp:77] Creating layer penlu12
I1007 17:39:01.361965  5078 net.cpp:84] Creating Layer penlu12
I1007 17:39:01.361971  5078 net.cpp:406] penlu12 <- Convolution13
I1007 17:39:01.361979  5078 net.cpp:367] penlu12 -> Convolution13 (in-place)
I1007 17:39:01.362088  5078 net.cpp:122] Setting up penlu12
I1007 17:39:01.362097  5078 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 17:39:01.362108  5078 net.cpp:137] Memory required for data: 324576400
I1007 17:39:01.362119  5078 layer_factory.hpp:77] Creating layer Convolution14
I1007 17:39:01.362130  5078 net.cpp:84] Creating Layer Convolution14
I1007 17:39:01.362135  5078 net.cpp:406] Convolution14 <- Convolution13
I1007 17:39:01.362143  5078 net.cpp:380] Convolution14 -> Convolution14
I1007 17:39:01.363211  5078 net.cpp:122] Setting up Convolution14
I1007 17:39:01.363224  5078 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 17:39:01.363229  5078 net.cpp:137] Memory required for data: 327085200
I1007 17:39:01.363248  5078 layer_factory.hpp:77] Creating layer BatchNorm14
I1007 17:39:01.363262  5078 net.cpp:84] Creating Layer BatchNorm14
I1007 17:39:01.363267  5078 net.cpp:406] BatchNorm14 <- Convolution14
I1007 17:39:01.363274  5078 net.cpp:367] BatchNorm14 -> Convolution14 (in-place)
I1007 17:39:01.363430  5078 net.cpp:122] Setting up BatchNorm14
I1007 17:39:01.363437  5078 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 17:39:01.363441  5078 net.cpp:137] Memory required for data: 329594000
I1007 17:39:01.363451  5078 layer_factory.hpp:77] Creating layer Scale14
I1007 17:39:01.363461  5078 net.cpp:84] Creating Layer Scale14
I1007 17:39:01.363466  5078 net.cpp:406] Scale14 <- Convolution14
I1007 17:39:01.363471  5078 net.cpp:367] Scale14 -> Convolution14 (in-place)
I1007 17:39:01.363503  5078 layer_factory.hpp:77] Creating layer Scale14
I1007 17:39:01.363584  5078 net.cpp:122] Setting up Scale14
I1007 17:39:01.363590  5078 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 17:39:01.363595  5078 net.cpp:137] Memory required for data: 332102800
I1007 17:39:01.363601  5078 layer_factory.hpp:77] Creating layer Eltwise6
I1007 17:39:01.363610  5078 net.cpp:84] Creating Layer Eltwise6
I1007 17:39:01.363615  5078 net.cpp:406] Eltwise6 <- Convolution12
I1007 17:39:01.363620  5078 net.cpp:406] Eltwise6 <- Convolution14
I1007 17:39:01.363625  5078 net.cpp:380] Eltwise6 -> Eltwise6
I1007 17:39:01.363642  5078 net.cpp:122] Setting up Eltwise6
I1007 17:39:01.363646  5078 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 17:39:01.363648  5078 net.cpp:137] Memory required for data: 334611600
I1007 17:39:01.363651  5078 layer_factory.hpp:77] Creating layer penlu13
I1007 17:39:01.363656  5078 net.cpp:84] Creating Layer penlu13
I1007 17:39:01.363657  5078 net.cpp:406] penlu13 <- Eltwise6
I1007 17:39:01.363662  5078 net.cpp:367] penlu13 -> Eltwise6 (in-place)
I1007 17:39:01.363780  5078 net.cpp:122] Setting up penlu13
I1007 17:39:01.363785  5078 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 17:39:01.363786  5078 net.cpp:137] Memory required for data: 337120400
I1007 17:39:01.363790  5078 layer_factory.hpp:77] Creating layer Eltwise6_penlu13_0_split
I1007 17:39:01.363793  5078 net.cpp:84] Creating Layer Eltwise6_penlu13_0_split
I1007 17:39:01.363796  5078 net.cpp:406] Eltwise6_penlu13_0_split <- Eltwise6
I1007 17:39:01.363800  5078 net.cpp:380] Eltwise6_penlu13_0_split -> Eltwise6_penlu13_0_split_0
I1007 17:39:01.363803  5078 net.cpp:380] Eltwise6_penlu13_0_split -> Eltwise6_penlu13_0_split_1
I1007 17:39:01.363824  5078 net.cpp:122] Setting up Eltwise6_penlu13_0_split
I1007 17:39:01.363827  5078 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 17:39:01.363831  5078 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 17:39:01.363832  5078 net.cpp:137] Memory required for data: 342138000
I1007 17:39:01.363834  5078 layer_factory.hpp:77] Creating layer Convolution15
I1007 17:39:01.363840  5078 net.cpp:84] Creating Layer Convolution15
I1007 17:39:01.363843  5078 net.cpp:406] Convolution15 <- Eltwise6_penlu13_0_split_0
I1007 17:39:01.363847  5078 net.cpp:380] Convolution15 -> Convolution15
I1007 17:39:01.364854  5078 net.cpp:122] Setting up Convolution15
I1007 17:39:01.364863  5078 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 17:39:01.364866  5078 net.cpp:137] Memory required for data: 344646800
I1007 17:39:01.364869  5078 layer_factory.hpp:77] Creating layer BatchNorm15
I1007 17:39:01.364876  5078 net.cpp:84] Creating Layer BatchNorm15
I1007 17:39:01.364883  5078 net.cpp:406] BatchNorm15 <- Convolution15
I1007 17:39:01.364887  5078 net.cpp:367] BatchNorm15 -> Convolution15 (in-place)
I1007 17:39:01.365013  5078 net.cpp:122] Setting up BatchNorm15
I1007 17:39:01.365017  5078 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 17:39:01.365020  5078 net.cpp:137] Memory required for data: 347155600
I1007 17:39:01.365025  5078 layer_factory.hpp:77] Creating layer Scale15
I1007 17:39:01.365030  5078 net.cpp:84] Creating Layer Scale15
I1007 17:39:01.365031  5078 net.cpp:406] Scale15 <- Convolution15
I1007 17:39:01.365034  5078 net.cpp:367] Scale15 -> Convolution15 (in-place)
I1007 17:39:01.365059  5078 layer_factory.hpp:77] Creating layer Scale15
I1007 17:39:01.365129  5078 net.cpp:122] Setting up Scale15
I1007 17:39:01.365134  5078 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 17:39:01.365135  5078 net.cpp:137] Memory required for data: 349664400
I1007 17:39:01.365139  5078 layer_factory.hpp:77] Creating layer penlu14
I1007 17:39:01.365145  5078 net.cpp:84] Creating Layer penlu14
I1007 17:39:01.365147  5078 net.cpp:406] penlu14 <- Convolution15
I1007 17:39:01.365151  5078 net.cpp:367] penlu14 -> Convolution15 (in-place)
I1007 17:39:01.365252  5078 net.cpp:122] Setting up penlu14
I1007 17:39:01.365255  5078 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 17:39:01.365257  5078 net.cpp:137] Memory required for data: 352173200
I1007 17:39:01.365262  5078 layer_factory.hpp:77] Creating layer Convolution16
I1007 17:39:01.365268  5078 net.cpp:84] Creating Layer Convolution16
I1007 17:39:01.365270  5078 net.cpp:406] Convolution16 <- Convolution15
I1007 17:39:01.365274  5078 net.cpp:380] Convolution16 -> Convolution16
I1007 17:39:01.366281  5078 net.cpp:122] Setting up Convolution16
I1007 17:39:01.366288  5078 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 17:39:01.366291  5078 net.cpp:137] Memory required for data: 354682000
I1007 17:39:01.366297  5078 layer_factory.hpp:77] Creating layer BatchNorm16
I1007 17:39:01.366300  5078 net.cpp:84] Creating Layer BatchNorm16
I1007 17:39:01.366303  5078 net.cpp:406] BatchNorm16 <- Convolution16
I1007 17:39:01.366307  5078 net.cpp:367] BatchNorm16 -> Convolution16 (in-place)
I1007 17:39:01.366431  5078 net.cpp:122] Setting up BatchNorm16
I1007 17:39:01.366436  5078 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 17:39:01.366437  5078 net.cpp:137] Memory required for data: 357190800
I1007 17:39:01.366442  5078 layer_factory.hpp:77] Creating layer Scale16
I1007 17:39:01.366446  5078 net.cpp:84] Creating Layer Scale16
I1007 17:39:01.366448  5078 net.cpp:406] Scale16 <- Convolution16
I1007 17:39:01.366452  5078 net.cpp:367] Scale16 -> Convolution16 (in-place)
I1007 17:39:01.366477  5078 layer_factory.hpp:77] Creating layer Scale16
I1007 17:39:01.366549  5078 net.cpp:122] Setting up Scale16
I1007 17:39:01.366552  5078 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 17:39:01.366554  5078 net.cpp:137] Memory required for data: 359699600
I1007 17:39:01.366559  5078 layer_factory.hpp:77] Creating layer Eltwise7
I1007 17:39:01.366561  5078 net.cpp:84] Creating Layer Eltwise7
I1007 17:39:01.366564  5078 net.cpp:406] Eltwise7 <- Eltwise6_penlu13_0_split_1
I1007 17:39:01.366566  5078 net.cpp:406] Eltwise7 <- Convolution16
I1007 17:39:01.366570  5078 net.cpp:380] Eltwise7 -> Eltwise7
I1007 17:39:01.366585  5078 net.cpp:122] Setting up Eltwise7
I1007 17:39:01.366590  5078 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 17:39:01.366591  5078 net.cpp:137] Memory required for data: 362208400
I1007 17:39:01.366593  5078 layer_factory.hpp:77] Creating layer penlu15
I1007 17:39:01.366597  5078 net.cpp:84] Creating Layer penlu15
I1007 17:39:01.366600  5078 net.cpp:406] penlu15 <- Eltwise7
I1007 17:39:01.366603  5078 net.cpp:367] penlu15 -> Eltwise7 (in-place)
I1007 17:39:01.366704  5078 net.cpp:122] Setting up penlu15
I1007 17:39:01.366709  5078 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 17:39:01.366711  5078 net.cpp:137] Memory required for data: 364717200
I1007 17:39:01.366721  5078 layer_factory.hpp:77] Creating layer Eltwise7_penlu15_0_split
I1007 17:39:01.366724  5078 net.cpp:84] Creating Layer Eltwise7_penlu15_0_split
I1007 17:39:01.366727  5078 net.cpp:406] Eltwise7_penlu15_0_split <- Eltwise7
I1007 17:39:01.366730  5078 net.cpp:380] Eltwise7_penlu15_0_split -> Eltwise7_penlu15_0_split_0
I1007 17:39:01.366734  5078 net.cpp:380] Eltwise7_penlu15_0_split -> Eltwise7_penlu15_0_split_1
I1007 17:39:01.366757  5078 net.cpp:122] Setting up Eltwise7_penlu15_0_split
I1007 17:39:01.366760  5078 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 17:39:01.366763  5078 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 17:39:01.366765  5078 net.cpp:137] Memory required for data: 369734800
I1007 17:39:01.366767  5078 layer_factory.hpp:77] Creating layer Convolution17
I1007 17:39:01.366773  5078 net.cpp:84] Creating Layer Convolution17
I1007 17:39:01.366775  5078 net.cpp:406] Convolution17 <- Eltwise7_penlu15_0_split_0
I1007 17:39:01.366780  5078 net.cpp:380] Convolution17 -> Convolution17
I1007 17:39:01.367482  5078 net.cpp:122] Setting up Convolution17
I1007 17:39:01.367491  5078 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 17:39:01.367492  5078 net.cpp:137] Memory required for data: 372243600
I1007 17:39:01.367496  5078 layer_factory.hpp:77] Creating layer BatchNorm17
I1007 17:39:01.367501  5078 net.cpp:84] Creating Layer BatchNorm17
I1007 17:39:01.367504  5078 net.cpp:406] BatchNorm17 <- Convolution17
I1007 17:39:01.367508  5078 net.cpp:367] BatchNorm17 -> Convolution17 (in-place)
I1007 17:39:01.367631  5078 net.cpp:122] Setting up BatchNorm17
I1007 17:39:01.367635  5078 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 17:39:01.367637  5078 net.cpp:137] Memory required for data: 374752400
I1007 17:39:01.367641  5078 layer_factory.hpp:77] Creating layer Scale17
I1007 17:39:01.367645  5078 net.cpp:84] Creating Layer Scale17
I1007 17:39:01.367648  5078 net.cpp:406] Scale17 <- Convolution17
I1007 17:39:01.367651  5078 net.cpp:367] Scale17 -> Convolution17 (in-place)
I1007 17:39:01.367676  5078 layer_factory.hpp:77] Creating layer Scale17
I1007 17:39:01.367748  5078 net.cpp:122] Setting up Scale17
I1007 17:39:01.367751  5078 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 17:39:01.367753  5078 net.cpp:137] Memory required for data: 377261200
I1007 17:39:01.367758  5078 layer_factory.hpp:77] Creating layer penlu16
I1007 17:39:01.367763  5078 net.cpp:84] Creating Layer penlu16
I1007 17:39:01.367765  5078 net.cpp:406] penlu16 <- Convolution17
I1007 17:39:01.367769  5078 net.cpp:367] penlu16 -> Convolution17 (in-place)
I1007 17:39:01.367868  5078 net.cpp:122] Setting up penlu16
I1007 17:39:01.367872  5078 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 17:39:01.367874  5078 net.cpp:137] Memory required for data: 379770000
I1007 17:39:01.367878  5078 layer_factory.hpp:77] Creating layer Convolution18
I1007 17:39:01.367884  5078 net.cpp:84] Creating Layer Convolution18
I1007 17:39:01.367887  5078 net.cpp:406] Convolution18 <- Convolution17
I1007 17:39:01.367890  5078 net.cpp:380] Convolution18 -> Convolution18
I1007 17:39:01.368896  5078 net.cpp:122] Setting up Convolution18
I1007 17:39:01.368904  5078 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 17:39:01.368907  5078 net.cpp:137] Memory required for data: 382278800
I1007 17:39:01.368911  5078 layer_factory.hpp:77] Creating layer BatchNorm18
I1007 17:39:01.368916  5078 net.cpp:84] Creating Layer BatchNorm18
I1007 17:39:01.368919  5078 net.cpp:406] BatchNorm18 <- Convolution18
I1007 17:39:01.368923  5078 net.cpp:367] BatchNorm18 -> Convolution18 (in-place)
I1007 17:39:01.369047  5078 net.cpp:122] Setting up BatchNorm18
I1007 17:39:01.369051  5078 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 17:39:01.369053  5078 net.cpp:137] Memory required for data: 384787600
I1007 17:39:01.369058  5078 layer_factory.hpp:77] Creating layer Scale18
I1007 17:39:01.369063  5078 net.cpp:84] Creating Layer Scale18
I1007 17:39:01.369065  5078 net.cpp:406] Scale18 <- Convolution18
I1007 17:39:01.369068  5078 net.cpp:367] Scale18 -> Convolution18 (in-place)
I1007 17:39:01.369102  5078 layer_factory.hpp:77] Creating layer Scale18
I1007 17:39:01.369196  5078 net.cpp:122] Setting up Scale18
I1007 17:39:01.369201  5078 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 17:39:01.369204  5078 net.cpp:137] Memory required for data: 387296400
I1007 17:39:01.369217  5078 layer_factory.hpp:77] Creating layer Eltwise8
I1007 17:39:01.369223  5078 net.cpp:84] Creating Layer Eltwise8
I1007 17:39:01.369236  5078 net.cpp:406] Eltwise8 <- Eltwise7_penlu15_0_split_1
I1007 17:39:01.369240  5078 net.cpp:406] Eltwise8 <- Convolution18
I1007 17:39:01.369257  5078 net.cpp:380] Eltwise8 -> Eltwise8
I1007 17:39:01.369290  5078 net.cpp:122] Setting up Eltwise8
I1007 17:39:01.369295  5078 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 17:39:01.369299  5078 net.cpp:137] Memory required for data: 389805200
I1007 17:39:01.369303  5078 layer_factory.hpp:77] Creating layer penlu17
I1007 17:39:01.369312  5078 net.cpp:84] Creating Layer penlu17
I1007 17:39:01.369315  5078 net.cpp:406] penlu17 <- Eltwise8
I1007 17:39:01.369320  5078 net.cpp:367] penlu17 -> Eltwise8 (in-place)
I1007 17:39:01.369441  5078 net.cpp:122] Setting up penlu17
I1007 17:39:01.369446  5078 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 17:39:01.369447  5078 net.cpp:137] Memory required for data: 392314000
I1007 17:39:01.369452  5078 layer_factory.hpp:77] Creating layer Eltwise8_penlu17_0_split
I1007 17:39:01.369457  5078 net.cpp:84] Creating Layer Eltwise8_penlu17_0_split
I1007 17:39:01.369458  5078 net.cpp:406] Eltwise8_penlu17_0_split <- Eltwise8
I1007 17:39:01.369462  5078 net.cpp:380] Eltwise8_penlu17_0_split -> Eltwise8_penlu17_0_split_0
I1007 17:39:01.369467  5078 net.cpp:380] Eltwise8_penlu17_0_split -> Eltwise8_penlu17_0_split_1
I1007 17:39:01.369490  5078 net.cpp:122] Setting up Eltwise8_penlu17_0_split
I1007 17:39:01.369494  5078 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 17:39:01.369498  5078 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 17:39:01.369499  5078 net.cpp:137] Memory required for data: 397331600
I1007 17:39:01.369501  5078 layer_factory.hpp:77] Creating layer Convolution19
I1007 17:39:01.369509  5078 net.cpp:84] Creating Layer Convolution19
I1007 17:39:01.369511  5078 net.cpp:406] Convolution19 <- Eltwise8_penlu17_0_split_0
I1007 17:39:01.369515  5078 net.cpp:380] Convolution19 -> Convolution19
I1007 17:39:01.370954  5078 net.cpp:122] Setting up Convolution19
I1007 17:39:01.370965  5078 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 17:39:01.370967  5078 net.cpp:137] Memory required for data: 399840400
I1007 17:39:01.370972  5078 layer_factory.hpp:77] Creating layer BatchNorm19
I1007 17:39:01.370976  5078 net.cpp:84] Creating Layer BatchNorm19
I1007 17:39:01.370980  5078 net.cpp:406] BatchNorm19 <- Convolution19
I1007 17:39:01.370983  5078 net.cpp:367] BatchNorm19 -> Convolution19 (in-place)
I1007 17:39:01.371124  5078 net.cpp:122] Setting up BatchNorm19
I1007 17:39:01.371127  5078 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 17:39:01.371130  5078 net.cpp:137] Memory required for data: 402349200
I1007 17:39:01.371135  5078 layer_factory.hpp:77] Creating layer Scale19
I1007 17:39:01.371140  5078 net.cpp:84] Creating Layer Scale19
I1007 17:39:01.371141  5078 net.cpp:406] Scale19 <- Convolution19
I1007 17:39:01.371145  5078 net.cpp:367] Scale19 -> Convolution19 (in-place)
I1007 17:39:01.371177  5078 layer_factory.hpp:77] Creating layer Scale19
I1007 17:39:01.371266  5078 net.cpp:122] Setting up Scale19
I1007 17:39:01.371284  5078 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 17:39:01.371289  5078 net.cpp:137] Memory required for data: 404858000
I1007 17:39:01.371295  5078 layer_factory.hpp:77] Creating layer penlu18
I1007 17:39:01.371314  5078 net.cpp:84] Creating Layer penlu18
I1007 17:39:01.371327  5078 net.cpp:406] penlu18 <- Convolution19
I1007 17:39:01.371332  5078 net.cpp:367] penlu18 -> Convolution19 (in-place)
I1007 17:39:01.371462  5078 net.cpp:122] Setting up penlu18
I1007 17:39:01.371471  5078 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 17:39:01.371484  5078 net.cpp:137] Memory required for data: 407366800
I1007 17:39:01.371493  5078 layer_factory.hpp:77] Creating layer Convolution20
I1007 17:39:01.371507  5078 net.cpp:84] Creating Layer Convolution20
I1007 17:39:01.371512  5078 net.cpp:406] Convolution20 <- Convolution19
I1007 17:39:01.371520  5078 net.cpp:380] Convolution20 -> Convolution20
I1007 17:39:01.372607  5078 net.cpp:122] Setting up Convolution20
I1007 17:39:01.372619  5078 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 17:39:01.372624  5078 net.cpp:137] Memory required for data: 409875600
I1007 17:39:01.372632  5078 layer_factory.hpp:77] Creating layer BatchNorm20
I1007 17:39:01.372643  5078 net.cpp:84] Creating Layer BatchNorm20
I1007 17:39:01.372648  5078 net.cpp:406] BatchNorm20 <- Convolution20
I1007 17:39:01.372655  5078 net.cpp:367] BatchNorm20 -> Convolution20 (in-place)
I1007 17:39:01.372802  5078 net.cpp:122] Setting up BatchNorm20
I1007 17:39:01.372809  5078 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 17:39:01.372813  5078 net.cpp:137] Memory required for data: 412384400
I1007 17:39:01.372822  5078 layer_factory.hpp:77] Creating layer Scale20
I1007 17:39:01.372830  5078 net.cpp:84] Creating Layer Scale20
I1007 17:39:01.372836  5078 net.cpp:406] Scale20 <- Convolution20
I1007 17:39:01.372843  5078 net.cpp:367] Scale20 -> Convolution20 (in-place)
I1007 17:39:01.372874  5078 layer_factory.hpp:77] Creating layer Scale20
I1007 17:39:01.372953  5078 net.cpp:122] Setting up Scale20
I1007 17:39:01.372957  5078 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 17:39:01.372959  5078 net.cpp:137] Memory required for data: 414893200
I1007 17:39:01.372963  5078 layer_factory.hpp:77] Creating layer Eltwise9
I1007 17:39:01.372968  5078 net.cpp:84] Creating Layer Eltwise9
I1007 17:39:01.372972  5078 net.cpp:406] Eltwise9 <- Eltwise8_penlu17_0_split_1
I1007 17:39:01.372974  5078 net.cpp:406] Eltwise9 <- Convolution20
I1007 17:39:01.372977  5078 net.cpp:380] Eltwise9 -> Eltwise9
I1007 17:39:01.372993  5078 net.cpp:122] Setting up Eltwise9
I1007 17:39:01.372997  5078 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 17:39:01.372999  5078 net.cpp:137] Memory required for data: 417402000
I1007 17:39:01.373001  5078 layer_factory.hpp:77] Creating layer penlu19
I1007 17:39:01.373006  5078 net.cpp:84] Creating Layer penlu19
I1007 17:39:01.373009  5078 net.cpp:406] penlu19 <- Eltwise9
I1007 17:39:01.373013  5078 net.cpp:367] penlu19 -> Eltwise9 (in-place)
I1007 17:39:01.373121  5078 net.cpp:122] Setting up penlu19
I1007 17:39:01.373126  5078 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 17:39:01.373127  5078 net.cpp:137] Memory required for data: 419910800
I1007 17:39:01.373131  5078 layer_factory.hpp:77] Creating layer Eltwise9_penlu19_0_split
I1007 17:39:01.373136  5078 net.cpp:84] Creating Layer Eltwise9_penlu19_0_split
I1007 17:39:01.373138  5078 net.cpp:406] Eltwise9_penlu19_0_split <- Eltwise9
I1007 17:39:01.373142  5078 net.cpp:380] Eltwise9_penlu19_0_split -> Eltwise9_penlu19_0_split_0
I1007 17:39:01.373145  5078 net.cpp:380] Eltwise9_penlu19_0_split -> Eltwise9_penlu19_0_split_1
I1007 17:39:01.373168  5078 net.cpp:122] Setting up Eltwise9_penlu19_0_split
I1007 17:39:01.373172  5078 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 17:39:01.373175  5078 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 17:39:01.373178  5078 net.cpp:137] Memory required for data: 424928400
I1007 17:39:01.373179  5078 layer_factory.hpp:77] Creating layer Convolution21
I1007 17:39:01.373184  5078 net.cpp:84] Creating Layer Convolution21
I1007 17:39:01.373188  5078 net.cpp:406] Convolution21 <- Eltwise9_penlu19_0_split_0
I1007 17:39:01.373191  5078 net.cpp:380] Convolution21 -> Convolution21
I1007 17:39:01.374579  5078 net.cpp:122] Setting up Convolution21
I1007 17:39:01.374588  5078 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 17:39:01.374590  5078 net.cpp:137] Memory required for data: 427437200
I1007 17:39:01.374595  5078 layer_factory.hpp:77] Creating layer BatchNorm21
I1007 17:39:01.374600  5078 net.cpp:84] Creating Layer BatchNorm21
I1007 17:39:01.374610  5078 net.cpp:406] BatchNorm21 <- Convolution21
I1007 17:39:01.374615  5078 net.cpp:367] BatchNorm21 -> Convolution21 (in-place)
I1007 17:39:01.374752  5078 net.cpp:122] Setting up BatchNorm21
I1007 17:39:01.374756  5078 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 17:39:01.374759  5078 net.cpp:137] Memory required for data: 429946000
I1007 17:39:01.374763  5078 layer_factory.hpp:77] Creating layer Scale21
I1007 17:39:01.374768  5078 net.cpp:84] Creating Layer Scale21
I1007 17:39:01.374771  5078 net.cpp:406] Scale21 <- Convolution21
I1007 17:39:01.374774  5078 net.cpp:367] Scale21 -> Convolution21 (in-place)
I1007 17:39:01.374800  5078 layer_factory.hpp:77] Creating layer Scale21
I1007 17:39:01.374876  5078 net.cpp:122] Setting up Scale21
I1007 17:39:01.374881  5078 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 17:39:01.374883  5078 net.cpp:137] Memory required for data: 432454800
I1007 17:39:01.374886  5078 layer_factory.hpp:77] Creating layer penlu20
I1007 17:39:01.374892  5078 net.cpp:84] Creating Layer penlu20
I1007 17:39:01.374894  5078 net.cpp:406] penlu20 <- Convolution21
I1007 17:39:01.374898  5078 net.cpp:367] penlu20 -> Convolution21 (in-place)
I1007 17:39:01.375007  5078 net.cpp:122] Setting up penlu20
I1007 17:39:01.375011  5078 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 17:39:01.375013  5078 net.cpp:137] Memory required for data: 434963600
I1007 17:39:01.375018  5078 layer_factory.hpp:77] Creating layer Convolution22
I1007 17:39:01.375025  5078 net.cpp:84] Creating Layer Convolution22
I1007 17:39:01.375027  5078 net.cpp:406] Convolution22 <- Convolution21
I1007 17:39:01.375030  5078 net.cpp:380] Convolution22 -> Convolution22
I1007 17:39:01.376112  5078 net.cpp:122] Setting up Convolution22
I1007 17:39:01.376122  5078 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 17:39:01.376126  5078 net.cpp:137] Memory required for data: 437472400
I1007 17:39:01.376129  5078 layer_factory.hpp:77] Creating layer BatchNorm22
I1007 17:39:01.376134  5078 net.cpp:84] Creating Layer BatchNorm22
I1007 17:39:01.376137  5078 net.cpp:406] BatchNorm22 <- Convolution22
I1007 17:39:01.376142  5078 net.cpp:367] BatchNorm22 -> Convolution22 (in-place)
I1007 17:39:01.376277  5078 net.cpp:122] Setting up BatchNorm22
I1007 17:39:01.376282  5078 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 17:39:01.376284  5078 net.cpp:137] Memory required for data: 439981200
I1007 17:39:01.376289  5078 layer_factory.hpp:77] Creating layer Scale22
I1007 17:39:01.376293  5078 net.cpp:84] Creating Layer Scale22
I1007 17:39:01.376296  5078 net.cpp:406] Scale22 <- Convolution22
I1007 17:39:01.376299  5078 net.cpp:367] Scale22 -> Convolution22 (in-place)
I1007 17:39:01.376325  5078 layer_factory.hpp:77] Creating layer Scale22
I1007 17:39:01.376401  5078 net.cpp:122] Setting up Scale22
I1007 17:39:01.376405  5078 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 17:39:01.376407  5078 net.cpp:137] Memory required for data: 442490000
I1007 17:39:01.376411  5078 layer_factory.hpp:77] Creating layer Eltwise10
I1007 17:39:01.376415  5078 net.cpp:84] Creating Layer Eltwise10
I1007 17:39:01.376417  5078 net.cpp:406] Eltwise10 <- Eltwise9_penlu19_0_split_1
I1007 17:39:01.376420  5078 net.cpp:406] Eltwise10 <- Convolution22
I1007 17:39:01.376425  5078 net.cpp:380] Eltwise10 -> Eltwise10
I1007 17:39:01.376440  5078 net.cpp:122] Setting up Eltwise10
I1007 17:39:01.376444  5078 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 17:39:01.376446  5078 net.cpp:137] Memory required for data: 444998800
I1007 17:39:01.376448  5078 layer_factory.hpp:77] Creating layer penlu21
I1007 17:39:01.376452  5078 net.cpp:84] Creating Layer penlu21
I1007 17:39:01.376456  5078 net.cpp:406] penlu21 <- Eltwise10
I1007 17:39:01.376458  5078 net.cpp:367] penlu21 -> Eltwise10 (in-place)
I1007 17:39:01.376566  5078 net.cpp:122] Setting up penlu21
I1007 17:39:01.376571  5078 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 17:39:01.376574  5078 net.cpp:137] Memory required for data: 447507600
I1007 17:39:01.376577  5078 layer_factory.hpp:77] Creating layer Eltwise10_penlu21_0_split
I1007 17:39:01.376587  5078 net.cpp:84] Creating Layer Eltwise10_penlu21_0_split
I1007 17:39:01.376590  5078 net.cpp:406] Eltwise10_penlu21_0_split <- Eltwise10
I1007 17:39:01.376593  5078 net.cpp:380] Eltwise10_penlu21_0_split -> Eltwise10_penlu21_0_split_0
I1007 17:39:01.376597  5078 net.cpp:380] Eltwise10_penlu21_0_split -> Eltwise10_penlu21_0_split_1
I1007 17:39:01.376621  5078 net.cpp:122] Setting up Eltwise10_penlu21_0_split
I1007 17:39:01.376626  5078 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 17:39:01.376628  5078 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 17:39:01.376631  5078 net.cpp:137] Memory required for data: 452525200
I1007 17:39:01.376632  5078 layer_factory.hpp:77] Creating layer Convolution23
I1007 17:39:01.376638  5078 net.cpp:84] Creating Layer Convolution23
I1007 17:39:01.376641  5078 net.cpp:406] Convolution23 <- Eltwise10_penlu21_0_split_0
I1007 17:39:01.376646  5078 net.cpp:380] Convolution23 -> Convolution23
I1007 17:39:01.377539  5078 net.cpp:122] Setting up Convolution23
I1007 17:39:01.377548  5078 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 17:39:01.377552  5078 net.cpp:137] Memory required for data: 453779600
I1007 17:39:01.377555  5078 layer_factory.hpp:77] Creating layer BatchNorm23
I1007 17:39:01.377560  5078 net.cpp:84] Creating Layer BatchNorm23
I1007 17:39:01.377563  5078 net.cpp:406] BatchNorm23 <- Convolution23
I1007 17:39:01.377568  5078 net.cpp:367] BatchNorm23 -> Convolution23 (in-place)
I1007 17:39:01.377699  5078 net.cpp:122] Setting up BatchNorm23
I1007 17:39:01.377704  5078 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 17:39:01.377707  5078 net.cpp:137] Memory required for data: 455034000
I1007 17:39:01.377710  5078 layer_factory.hpp:77] Creating layer Scale23
I1007 17:39:01.377714  5078 net.cpp:84] Creating Layer Scale23
I1007 17:39:01.377717  5078 net.cpp:406] Scale23 <- Convolution23
I1007 17:39:01.377720  5078 net.cpp:367] Scale23 -> Convolution23 (in-place)
I1007 17:39:01.377746  5078 layer_factory.hpp:77] Creating layer Scale23
I1007 17:39:01.377826  5078 net.cpp:122] Setting up Scale23
I1007 17:39:01.377830  5078 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 17:39:01.377832  5078 net.cpp:137] Memory required for data: 456288400
I1007 17:39:01.377836  5078 layer_factory.hpp:77] Creating layer Convolution24
I1007 17:39:01.377843  5078 net.cpp:84] Creating Layer Convolution24
I1007 17:39:01.377846  5078 net.cpp:406] Convolution24 <- Eltwise10_penlu21_0_split_1
I1007 17:39:01.377851  5078 net.cpp:380] Convolution24 -> Convolution24
I1007 17:39:01.379688  5078 net.cpp:122] Setting up Convolution24
I1007 17:39:01.379698  5078 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 17:39:01.379700  5078 net.cpp:137] Memory required for data: 457542800
I1007 17:39:01.379704  5078 layer_factory.hpp:77] Creating layer BatchNorm24
I1007 17:39:01.379709  5078 net.cpp:84] Creating Layer BatchNorm24
I1007 17:39:01.379711  5078 net.cpp:406] BatchNorm24 <- Convolution24
I1007 17:39:01.379716  5078 net.cpp:367] BatchNorm24 -> Convolution24 (in-place)
I1007 17:39:01.379851  5078 net.cpp:122] Setting up BatchNorm24
I1007 17:39:01.379856  5078 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 17:39:01.379858  5078 net.cpp:137] Memory required for data: 458797200
I1007 17:39:01.379863  5078 layer_factory.hpp:77] Creating layer Scale24
I1007 17:39:01.379868  5078 net.cpp:84] Creating Layer Scale24
I1007 17:39:01.379869  5078 net.cpp:406] Scale24 <- Convolution24
I1007 17:39:01.379873  5078 net.cpp:367] Scale24 -> Convolution24 (in-place)
I1007 17:39:01.379899  5078 layer_factory.hpp:77] Creating layer Scale24
I1007 17:39:01.379976  5078 net.cpp:122] Setting up Scale24
I1007 17:39:01.379981  5078 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 17:39:01.379983  5078 net.cpp:137] Memory required for data: 460051600
I1007 17:39:01.379987  5078 layer_factory.hpp:77] Creating layer penlu22
I1007 17:39:01.379993  5078 net.cpp:84] Creating Layer penlu22
I1007 17:39:01.379995  5078 net.cpp:406] penlu22 <- Convolution24
I1007 17:39:01.380007  5078 net.cpp:367] penlu22 -> Convolution24 (in-place)
I1007 17:39:01.380115  5078 net.cpp:122] Setting up penlu22
I1007 17:39:01.380120  5078 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 17:39:01.380122  5078 net.cpp:137] Memory required for data: 461306000
I1007 17:39:01.380127  5078 layer_factory.hpp:77] Creating layer Convolution25
I1007 17:39:01.380133  5078 net.cpp:84] Creating Layer Convolution25
I1007 17:39:01.380136  5078 net.cpp:406] Convolution25 <- Convolution24
I1007 17:39:01.380141  5078 net.cpp:380] Convolution25 -> Convolution25
I1007 17:39:01.382110  5078 net.cpp:122] Setting up Convolution25
I1007 17:39:01.382119  5078 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 17:39:01.382122  5078 net.cpp:137] Memory required for data: 462560400
I1007 17:39:01.382127  5078 layer_factory.hpp:77] Creating layer BatchNorm25
I1007 17:39:01.382133  5078 net.cpp:84] Creating Layer BatchNorm25
I1007 17:39:01.382134  5078 net.cpp:406] BatchNorm25 <- Convolution25
I1007 17:39:01.382139  5078 net.cpp:367] BatchNorm25 -> Convolution25 (in-place)
I1007 17:39:01.382278  5078 net.cpp:122] Setting up BatchNorm25
I1007 17:39:01.382282  5078 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 17:39:01.382284  5078 net.cpp:137] Memory required for data: 463814800
I1007 17:39:01.382289  5078 layer_factory.hpp:77] Creating layer Scale25
I1007 17:39:01.382294  5078 net.cpp:84] Creating Layer Scale25
I1007 17:39:01.382297  5078 net.cpp:406] Scale25 <- Convolution25
I1007 17:39:01.382299  5078 net.cpp:367] Scale25 -> Convolution25 (in-place)
I1007 17:39:01.382326  5078 layer_factory.hpp:77] Creating layer Scale25
I1007 17:39:01.382406  5078 net.cpp:122] Setting up Scale25
I1007 17:39:01.382411  5078 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 17:39:01.382412  5078 net.cpp:137] Memory required for data: 465069200
I1007 17:39:01.382416  5078 layer_factory.hpp:77] Creating layer Eltwise11
I1007 17:39:01.382421  5078 net.cpp:84] Creating Layer Eltwise11
I1007 17:39:01.382423  5078 net.cpp:406] Eltwise11 <- Convolution23
I1007 17:39:01.382426  5078 net.cpp:406] Eltwise11 <- Convolution25
I1007 17:39:01.382431  5078 net.cpp:380] Eltwise11 -> Eltwise11
I1007 17:39:01.382446  5078 net.cpp:122] Setting up Eltwise11
I1007 17:39:01.382449  5078 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 17:39:01.382452  5078 net.cpp:137] Memory required for data: 466323600
I1007 17:39:01.382453  5078 layer_factory.hpp:77] Creating layer penlu23
I1007 17:39:01.382458  5078 net.cpp:84] Creating Layer penlu23
I1007 17:39:01.382462  5078 net.cpp:406] penlu23 <- Eltwise11
I1007 17:39:01.382464  5078 net.cpp:367] penlu23 -> Eltwise11 (in-place)
I1007 17:39:01.382572  5078 net.cpp:122] Setting up penlu23
I1007 17:39:01.382576  5078 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 17:39:01.382578  5078 net.cpp:137] Memory required for data: 467578000
I1007 17:39:01.382583  5078 layer_factory.hpp:77] Creating layer Eltwise11_penlu23_0_split
I1007 17:39:01.382586  5078 net.cpp:84] Creating Layer Eltwise11_penlu23_0_split
I1007 17:39:01.382588  5078 net.cpp:406] Eltwise11_penlu23_0_split <- Eltwise11
I1007 17:39:01.382592  5078 net.cpp:380] Eltwise11_penlu23_0_split -> Eltwise11_penlu23_0_split_0
I1007 17:39:01.382596  5078 net.cpp:380] Eltwise11_penlu23_0_split -> Eltwise11_penlu23_0_split_1
I1007 17:39:01.382618  5078 net.cpp:122] Setting up Eltwise11_penlu23_0_split
I1007 17:39:01.382622  5078 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 17:39:01.382625  5078 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 17:39:01.382627  5078 net.cpp:137] Memory required for data: 470086800
I1007 17:39:01.382629  5078 layer_factory.hpp:77] Creating layer Convolution26
I1007 17:39:01.382637  5078 net.cpp:84] Creating Layer Convolution26
I1007 17:39:01.382639  5078 net.cpp:406] Convolution26 <- Eltwise11_penlu23_0_split_0
I1007 17:39:01.382643  5078 net.cpp:380] Convolution26 -> Convolution26
I1007 17:39:01.384330  5078 net.cpp:122] Setting up Convolution26
I1007 17:39:01.384340  5078 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 17:39:01.384341  5078 net.cpp:137] Memory required for data: 471341200
I1007 17:39:01.384352  5078 layer_factory.hpp:77] Creating layer BatchNorm26
I1007 17:39:01.384358  5078 net.cpp:84] Creating Layer BatchNorm26
I1007 17:39:01.384361  5078 net.cpp:406] BatchNorm26 <- Convolution26
I1007 17:39:01.384366  5078 net.cpp:367] BatchNorm26 -> Convolution26 (in-place)
I1007 17:39:01.384501  5078 net.cpp:122] Setting up BatchNorm26
I1007 17:39:01.384506  5078 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 17:39:01.384508  5078 net.cpp:137] Memory required for data: 472595600
I1007 17:39:01.384513  5078 layer_factory.hpp:77] Creating layer Scale26
I1007 17:39:01.384517  5078 net.cpp:84] Creating Layer Scale26
I1007 17:39:01.384521  5078 net.cpp:406] Scale26 <- Convolution26
I1007 17:39:01.384523  5078 net.cpp:367] Scale26 -> Convolution26 (in-place)
I1007 17:39:01.384551  5078 layer_factory.hpp:77] Creating layer Scale26
I1007 17:39:01.384627  5078 net.cpp:122] Setting up Scale26
I1007 17:39:01.384632  5078 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 17:39:01.384634  5078 net.cpp:137] Memory required for data: 473850000
I1007 17:39:01.384639  5078 layer_factory.hpp:77] Creating layer penlu24
I1007 17:39:01.384644  5078 net.cpp:84] Creating Layer penlu24
I1007 17:39:01.384646  5078 net.cpp:406] penlu24 <- Convolution26
I1007 17:39:01.384649  5078 net.cpp:367] penlu24 -> Convolution26 (in-place)
I1007 17:39:01.384758  5078 net.cpp:122] Setting up penlu24
I1007 17:39:01.384763  5078 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 17:39:01.384764  5078 net.cpp:137] Memory required for data: 475104400
I1007 17:39:01.384769  5078 layer_factory.hpp:77] Creating layer Convolution27
I1007 17:39:01.384775  5078 net.cpp:84] Creating Layer Convolution27
I1007 17:39:01.384778  5078 net.cpp:406] Convolution27 <- Convolution26
I1007 17:39:01.384781  5078 net.cpp:380] Convolution27 -> Convolution27
I1007 17:39:01.386430  5078 net.cpp:122] Setting up Convolution27
I1007 17:39:01.386437  5078 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 17:39:01.386440  5078 net.cpp:137] Memory required for data: 476358800
I1007 17:39:01.386445  5078 layer_factory.hpp:77] Creating layer BatchNorm27
I1007 17:39:01.386451  5078 net.cpp:84] Creating Layer BatchNorm27
I1007 17:39:01.386453  5078 net.cpp:406] BatchNorm27 <- Convolution27
I1007 17:39:01.386456  5078 net.cpp:367] BatchNorm27 -> Convolution27 (in-place)
I1007 17:39:01.386597  5078 net.cpp:122] Setting up BatchNorm27
I1007 17:39:01.386601  5078 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 17:39:01.386605  5078 net.cpp:137] Memory required for data: 477613200
I1007 17:39:01.386628  5078 layer_factory.hpp:77] Creating layer Scale27
I1007 17:39:01.386641  5078 net.cpp:84] Creating Layer Scale27
I1007 17:39:01.386644  5078 net.cpp:406] Scale27 <- Convolution27
I1007 17:39:01.386648  5078 net.cpp:367] Scale27 -> Convolution27 (in-place)
I1007 17:39:01.386677  5078 layer_factory.hpp:77] Creating layer Scale27
I1007 17:39:01.386755  5078 net.cpp:122] Setting up Scale27
I1007 17:39:01.386759  5078 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 17:39:01.386761  5078 net.cpp:137] Memory required for data: 478867600
I1007 17:39:01.386765  5078 layer_factory.hpp:77] Creating layer Eltwise12
I1007 17:39:01.386770  5078 net.cpp:84] Creating Layer Eltwise12
I1007 17:39:01.386772  5078 net.cpp:406] Eltwise12 <- Eltwise11_penlu23_0_split_1
I1007 17:39:01.386775  5078 net.cpp:406] Eltwise12 <- Convolution27
I1007 17:39:01.386778  5078 net.cpp:380] Eltwise12 -> Eltwise12
I1007 17:39:01.386798  5078 net.cpp:122] Setting up Eltwise12
I1007 17:39:01.386803  5078 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 17:39:01.386806  5078 net.cpp:137] Memory required for data: 480122000
I1007 17:39:01.386807  5078 layer_factory.hpp:77] Creating layer penlu25
I1007 17:39:01.386812  5078 net.cpp:84] Creating Layer penlu25
I1007 17:39:01.386816  5078 net.cpp:406] penlu25 <- Eltwise12
I1007 17:39:01.386818  5078 net.cpp:367] penlu25 -> Eltwise12 (in-place)
I1007 17:39:01.386929  5078 net.cpp:122] Setting up penlu25
I1007 17:39:01.386940  5078 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 17:39:01.386942  5078 net.cpp:137] Memory required for data: 481376400
I1007 17:39:01.386947  5078 layer_factory.hpp:77] Creating layer Eltwise12_penlu25_0_split
I1007 17:39:01.386951  5078 net.cpp:84] Creating Layer Eltwise12_penlu25_0_split
I1007 17:39:01.386953  5078 net.cpp:406] Eltwise12_penlu25_0_split <- Eltwise12
I1007 17:39:01.386958  5078 net.cpp:380] Eltwise12_penlu25_0_split -> Eltwise12_penlu25_0_split_0
I1007 17:39:01.386962  5078 net.cpp:380] Eltwise12_penlu25_0_split -> Eltwise12_penlu25_0_split_1
I1007 17:39:01.386986  5078 net.cpp:122] Setting up Eltwise12_penlu25_0_split
I1007 17:39:01.386991  5078 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 17:39:01.386992  5078 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 17:39:01.386994  5078 net.cpp:137] Memory required for data: 483885200
I1007 17:39:01.386997  5078 layer_factory.hpp:77] Creating layer Convolution28
I1007 17:39:01.387003  5078 net.cpp:84] Creating Layer Convolution28
I1007 17:39:01.387006  5078 net.cpp:406] Convolution28 <- Eltwise12_penlu25_0_split_0
I1007 17:39:01.387009  5078 net.cpp:380] Convolution28 -> Convolution28
I1007 17:39:01.388689  5078 net.cpp:122] Setting up Convolution28
I1007 17:39:01.388698  5078 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 17:39:01.388701  5078 net.cpp:137] Memory required for data: 485139600
I1007 17:39:01.388705  5078 layer_factory.hpp:77] Creating layer BatchNorm28
I1007 17:39:01.388711  5078 net.cpp:84] Creating Layer BatchNorm28
I1007 17:39:01.388715  5078 net.cpp:406] BatchNorm28 <- Convolution28
I1007 17:39:01.388718  5078 net.cpp:367] BatchNorm28 -> Convolution28 (in-place)
I1007 17:39:01.388856  5078 net.cpp:122] Setting up BatchNorm28
I1007 17:39:01.388861  5078 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 17:39:01.388864  5078 net.cpp:137] Memory required for data: 486394000
I1007 17:39:01.388869  5078 layer_factory.hpp:77] Creating layer Scale28
I1007 17:39:01.388872  5078 net.cpp:84] Creating Layer Scale28
I1007 17:39:01.388875  5078 net.cpp:406] Scale28 <- Convolution28
I1007 17:39:01.388878  5078 net.cpp:367] Scale28 -> Convolution28 (in-place)
I1007 17:39:01.388906  5078 layer_factory.hpp:77] Creating layer Scale28
I1007 17:39:01.388984  5078 net.cpp:122] Setting up Scale28
I1007 17:39:01.388988  5078 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 17:39:01.388990  5078 net.cpp:137] Memory required for data: 487648400
I1007 17:39:01.388994  5078 layer_factory.hpp:77] Creating layer penlu26
I1007 17:39:01.389000  5078 net.cpp:84] Creating Layer penlu26
I1007 17:39:01.389003  5078 net.cpp:406] penlu26 <- Convolution28
I1007 17:39:01.389006  5078 net.cpp:367] penlu26 -> Convolution28 (in-place)
I1007 17:39:01.389117  5078 net.cpp:122] Setting up penlu26
I1007 17:39:01.389122  5078 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 17:39:01.389124  5078 net.cpp:137] Memory required for data: 488902800
I1007 17:39:01.389128  5078 layer_factory.hpp:77] Creating layer Convolution29
I1007 17:39:01.389135  5078 net.cpp:84] Creating Layer Convolution29
I1007 17:39:01.389137  5078 net.cpp:406] Convolution29 <- Convolution28
I1007 17:39:01.389142  5078 net.cpp:380] Convolution29 -> Convolution29
I1007 17:39:01.391113  5078 net.cpp:122] Setting up Convolution29
I1007 17:39:01.391122  5078 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 17:39:01.391125  5078 net.cpp:137] Memory required for data: 490157200
I1007 17:39:01.391129  5078 layer_factory.hpp:77] Creating layer BatchNorm29
I1007 17:39:01.391134  5078 net.cpp:84] Creating Layer BatchNorm29
I1007 17:39:01.391137  5078 net.cpp:406] BatchNorm29 <- Convolution29
I1007 17:39:01.391141  5078 net.cpp:367] BatchNorm29 -> Convolution29 (in-place)
I1007 17:39:01.391310  5078 net.cpp:122] Setting up BatchNorm29
I1007 17:39:01.391316  5078 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 17:39:01.391319  5078 net.cpp:137] Memory required for data: 491411600
I1007 17:39:01.391324  5078 layer_factory.hpp:77] Creating layer Scale29
I1007 17:39:01.391327  5078 net.cpp:84] Creating Layer Scale29
I1007 17:39:01.391337  5078 net.cpp:406] Scale29 <- Convolution29
I1007 17:39:01.391341  5078 net.cpp:367] Scale29 -> Convolution29 (in-place)
I1007 17:39:01.391371  5078 layer_factory.hpp:77] Creating layer Scale29
I1007 17:39:01.391450  5078 net.cpp:122] Setting up Scale29
I1007 17:39:01.391455  5078 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 17:39:01.391458  5078 net.cpp:137] Memory required for data: 492666000
I1007 17:39:01.391461  5078 layer_factory.hpp:77] Creating layer Eltwise13
I1007 17:39:01.391465  5078 net.cpp:84] Creating Layer Eltwise13
I1007 17:39:01.391468  5078 net.cpp:406] Eltwise13 <- Eltwise12_penlu25_0_split_1
I1007 17:39:01.391470  5078 net.cpp:406] Eltwise13 <- Convolution29
I1007 17:39:01.391474  5078 net.cpp:380] Eltwise13 -> Eltwise13
I1007 17:39:01.391490  5078 net.cpp:122] Setting up Eltwise13
I1007 17:39:01.391494  5078 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 17:39:01.391496  5078 net.cpp:137] Memory required for data: 493920400
I1007 17:39:01.391499  5078 layer_factory.hpp:77] Creating layer penlu27
I1007 17:39:01.391504  5078 net.cpp:84] Creating Layer penlu27
I1007 17:39:01.391505  5078 net.cpp:406] penlu27 <- Eltwise13
I1007 17:39:01.391510  5078 net.cpp:367] penlu27 -> Eltwise13 (in-place)
I1007 17:39:01.391623  5078 net.cpp:122] Setting up penlu27
I1007 17:39:01.391628  5078 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 17:39:01.391629  5078 net.cpp:137] Memory required for data: 495174800
I1007 17:39:01.391634  5078 layer_factory.hpp:77] Creating layer Eltwise13_penlu27_0_split
I1007 17:39:01.391638  5078 net.cpp:84] Creating Layer Eltwise13_penlu27_0_split
I1007 17:39:01.391640  5078 net.cpp:406] Eltwise13_penlu27_0_split <- Eltwise13
I1007 17:39:01.391644  5078 net.cpp:380] Eltwise13_penlu27_0_split -> Eltwise13_penlu27_0_split_0
I1007 17:39:01.391647  5078 net.cpp:380] Eltwise13_penlu27_0_split -> Eltwise13_penlu27_0_split_1
I1007 17:39:01.391671  5078 net.cpp:122] Setting up Eltwise13_penlu27_0_split
I1007 17:39:01.391675  5078 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 17:39:01.391677  5078 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 17:39:01.391680  5078 net.cpp:137] Memory required for data: 497683600
I1007 17:39:01.391682  5078 layer_factory.hpp:77] Creating layer Convolution30
I1007 17:39:01.391688  5078 net.cpp:84] Creating Layer Convolution30
I1007 17:39:01.391691  5078 net.cpp:406] Convolution30 <- Eltwise13_penlu27_0_split_0
I1007 17:39:01.391695  5078 net.cpp:380] Convolution30 -> Convolution30
I1007 17:39:01.393357  5078 net.cpp:122] Setting up Convolution30
I1007 17:39:01.393368  5078 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 17:39:01.393370  5078 net.cpp:137] Memory required for data: 498938000
I1007 17:39:01.393374  5078 layer_factory.hpp:77] Creating layer BatchNorm30
I1007 17:39:01.393379  5078 net.cpp:84] Creating Layer BatchNorm30
I1007 17:39:01.393383  5078 net.cpp:406] BatchNorm30 <- Convolution30
I1007 17:39:01.393386  5078 net.cpp:367] BatchNorm30 -> Convolution30 (in-place)
I1007 17:39:01.393525  5078 net.cpp:122] Setting up BatchNorm30
I1007 17:39:01.393529  5078 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 17:39:01.393532  5078 net.cpp:137] Memory required for data: 500192400
I1007 17:39:01.393537  5078 layer_factory.hpp:77] Creating layer Scale30
I1007 17:39:01.393540  5078 net.cpp:84] Creating Layer Scale30
I1007 17:39:01.393543  5078 net.cpp:406] Scale30 <- Convolution30
I1007 17:39:01.393548  5078 net.cpp:367] Scale30 -> Convolution30 (in-place)
I1007 17:39:01.393573  5078 layer_factory.hpp:77] Creating layer Scale30
I1007 17:39:01.393653  5078 net.cpp:122] Setting up Scale30
I1007 17:39:01.393657  5078 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 17:39:01.393659  5078 net.cpp:137] Memory required for data: 501446800
I1007 17:39:01.393663  5078 layer_factory.hpp:77] Creating layer penlu28
I1007 17:39:01.393668  5078 net.cpp:84] Creating Layer penlu28
I1007 17:39:01.393671  5078 net.cpp:406] penlu28 <- Convolution30
I1007 17:39:01.393674  5078 net.cpp:367] penlu28 -> Convolution30 (in-place)
I1007 17:39:01.393795  5078 net.cpp:122] Setting up penlu28
I1007 17:39:01.393800  5078 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 17:39:01.393801  5078 net.cpp:137] Memory required for data: 502701200
I1007 17:39:01.393806  5078 layer_factory.hpp:77] Creating layer Convolution31
I1007 17:39:01.393812  5078 net.cpp:84] Creating Layer Convolution31
I1007 17:39:01.393815  5078 net.cpp:406] Convolution31 <- Convolution30
I1007 17:39:01.393820  5078 net.cpp:380] Convolution31 -> Convolution31
I1007 17:39:01.395825  5078 net.cpp:122] Setting up Convolution31
I1007 17:39:01.395834  5078 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 17:39:01.395836  5078 net.cpp:137] Memory required for data: 503955600
I1007 17:39:01.395841  5078 layer_factory.hpp:77] Creating layer BatchNorm31
I1007 17:39:01.395846  5078 net.cpp:84] Creating Layer BatchNorm31
I1007 17:39:01.395849  5078 net.cpp:406] BatchNorm31 <- Convolution31
I1007 17:39:01.395853  5078 net.cpp:367] BatchNorm31 -> Convolution31 (in-place)
I1007 17:39:01.395995  5078 net.cpp:122] Setting up BatchNorm31
I1007 17:39:01.396000  5078 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 17:39:01.396003  5078 net.cpp:137] Memory required for data: 505210000
I1007 17:39:01.396008  5078 layer_factory.hpp:77] Creating layer Scale31
I1007 17:39:01.396011  5078 net.cpp:84] Creating Layer Scale31
I1007 17:39:01.396013  5078 net.cpp:406] Scale31 <- Convolution31
I1007 17:39:01.396016  5078 net.cpp:367] Scale31 -> Convolution31 (in-place)
I1007 17:39:01.396044  5078 layer_factory.hpp:77] Creating layer Scale31
I1007 17:39:01.396126  5078 net.cpp:122] Setting up Scale31
I1007 17:39:01.396131  5078 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 17:39:01.396132  5078 net.cpp:137] Memory required for data: 506464400
I1007 17:39:01.396136  5078 layer_factory.hpp:77] Creating layer Eltwise14
I1007 17:39:01.396142  5078 net.cpp:84] Creating Layer Eltwise14
I1007 17:39:01.396144  5078 net.cpp:406] Eltwise14 <- Eltwise13_penlu27_0_split_1
I1007 17:39:01.396147  5078 net.cpp:406] Eltwise14 <- Convolution31
I1007 17:39:01.396150  5078 net.cpp:380] Eltwise14 -> Eltwise14
I1007 17:39:01.396167  5078 net.cpp:122] Setting up Eltwise14
I1007 17:39:01.396170  5078 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 17:39:01.396173  5078 net.cpp:137] Memory required for data: 507718800
I1007 17:39:01.396174  5078 layer_factory.hpp:77] Creating layer penlu29
I1007 17:39:01.396179  5078 net.cpp:84] Creating Layer penlu29
I1007 17:39:01.396181  5078 net.cpp:406] penlu29 <- Eltwise14
I1007 17:39:01.396185  5078 net.cpp:367] penlu29 -> Eltwise14 (in-place)
I1007 17:39:01.396297  5078 net.cpp:122] Setting up penlu29
I1007 17:39:01.396301  5078 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 17:39:01.396303  5078 net.cpp:137] Memory required for data: 508973200
I1007 17:39:01.396307  5078 layer_factory.hpp:77] Creating layer Eltwise14_penlu29_0_split
I1007 17:39:01.396311  5078 net.cpp:84] Creating Layer Eltwise14_penlu29_0_split
I1007 17:39:01.396314  5078 net.cpp:406] Eltwise14_penlu29_0_split <- Eltwise14
I1007 17:39:01.396317  5078 net.cpp:380] Eltwise14_penlu29_0_split -> Eltwise14_penlu29_0_split_0
I1007 17:39:01.396322  5078 net.cpp:380] Eltwise14_penlu29_0_split -> Eltwise14_penlu29_0_split_1
I1007 17:39:01.396344  5078 net.cpp:122] Setting up Eltwise14_penlu29_0_split
I1007 17:39:01.396348  5078 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 17:39:01.396351  5078 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 17:39:01.396353  5078 net.cpp:137] Memory required for data: 511482000
I1007 17:39:01.396355  5078 layer_factory.hpp:77] Creating layer Convolution32
I1007 17:39:01.396360  5078 net.cpp:84] Creating Layer Convolution32
I1007 17:39:01.396363  5078 net.cpp:406] Convolution32 <- Eltwise14_penlu29_0_split_0
I1007 17:39:01.396368  5078 net.cpp:380] Convolution32 -> Convolution32
I1007 17:39:01.398071  5078 net.cpp:122] Setting up Convolution32
I1007 17:39:01.398078  5078 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 17:39:01.398082  5078 net.cpp:137] Memory required for data: 512736400
I1007 17:39:01.398092  5078 layer_factory.hpp:77] Creating layer BatchNorm32
I1007 17:39:01.398098  5078 net.cpp:84] Creating Layer BatchNorm32
I1007 17:39:01.398100  5078 net.cpp:406] BatchNorm32 <- Convolution32
I1007 17:39:01.398104  5078 net.cpp:367] BatchNorm32 -> Convolution32 (in-place)
I1007 17:39:01.398247  5078 net.cpp:122] Setting up BatchNorm32
I1007 17:39:01.398252  5078 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 17:39:01.398253  5078 net.cpp:137] Memory required for data: 513990800
I1007 17:39:01.398258  5078 layer_factory.hpp:77] Creating layer Scale32
I1007 17:39:01.398262  5078 net.cpp:84] Creating Layer Scale32
I1007 17:39:01.398264  5078 net.cpp:406] Scale32 <- Convolution32
I1007 17:39:01.398267  5078 net.cpp:367] Scale32 -> Convolution32 (in-place)
I1007 17:39:01.398296  5078 layer_factory.hpp:77] Creating layer Scale32
I1007 17:39:01.398375  5078 net.cpp:122] Setting up Scale32
I1007 17:39:01.398380  5078 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 17:39:01.398381  5078 net.cpp:137] Memory required for data: 515245200
I1007 17:39:01.398386  5078 layer_factory.hpp:77] Creating layer penlu30
I1007 17:39:01.398391  5078 net.cpp:84] Creating Layer penlu30
I1007 17:39:01.398393  5078 net.cpp:406] penlu30 <- Convolution32
I1007 17:39:01.398397  5078 net.cpp:367] penlu30 -> Convolution32 (in-place)
I1007 17:39:01.398509  5078 net.cpp:122] Setting up penlu30
I1007 17:39:01.398514  5078 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 17:39:01.398515  5078 net.cpp:137] Memory required for data: 516499600
I1007 17:39:01.398519  5078 layer_factory.hpp:77] Creating layer Convolution33
I1007 17:39:01.398526  5078 net.cpp:84] Creating Layer Convolution33
I1007 17:39:01.398528  5078 net.cpp:406] Convolution33 <- Convolution32
I1007 17:39:01.398533  5078 net.cpp:380] Convolution33 -> Convolution33
I1007 17:39:01.400542  5078 net.cpp:122] Setting up Convolution33
I1007 17:39:01.400550  5078 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 17:39:01.400553  5078 net.cpp:137] Memory required for data: 517754000
I1007 17:39:01.400558  5078 layer_factory.hpp:77] Creating layer BatchNorm33
I1007 17:39:01.400563  5078 net.cpp:84] Creating Layer BatchNorm33
I1007 17:39:01.400566  5078 net.cpp:406] BatchNorm33 <- Convolution33
I1007 17:39:01.400569  5078 net.cpp:367] BatchNorm33 -> Convolution33 (in-place)
I1007 17:39:01.400712  5078 net.cpp:122] Setting up BatchNorm33
I1007 17:39:01.400717  5078 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 17:39:01.400718  5078 net.cpp:137] Memory required for data: 519008400
I1007 17:39:01.400723  5078 layer_factory.hpp:77] Creating layer Scale33
I1007 17:39:01.400727  5078 net.cpp:84] Creating Layer Scale33
I1007 17:39:01.400730  5078 net.cpp:406] Scale33 <- Convolution33
I1007 17:39:01.400733  5078 net.cpp:367] Scale33 -> Convolution33 (in-place)
I1007 17:39:01.400760  5078 layer_factory.hpp:77] Creating layer Scale33
I1007 17:39:01.400840  5078 net.cpp:122] Setting up Scale33
I1007 17:39:01.400845  5078 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 17:39:01.400846  5078 net.cpp:137] Memory required for data: 520262800
I1007 17:39:01.400851  5078 layer_factory.hpp:77] Creating layer Eltwise15
I1007 17:39:01.400854  5078 net.cpp:84] Creating Layer Eltwise15
I1007 17:39:01.400857  5078 net.cpp:406] Eltwise15 <- Eltwise14_penlu29_0_split_1
I1007 17:39:01.400861  5078 net.cpp:406] Eltwise15 <- Convolution33
I1007 17:39:01.400863  5078 net.cpp:380] Eltwise15 -> Eltwise15
I1007 17:39:01.400880  5078 net.cpp:122] Setting up Eltwise15
I1007 17:39:01.400883  5078 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 17:39:01.400885  5078 net.cpp:137] Memory required for data: 521517200
I1007 17:39:01.400888  5078 layer_factory.hpp:77] Creating layer penlu31
I1007 17:39:01.400893  5078 net.cpp:84] Creating Layer penlu31
I1007 17:39:01.400895  5078 net.cpp:406] penlu31 <- Eltwise15
I1007 17:39:01.400899  5078 net.cpp:367] penlu31 -> Eltwise15 (in-place)
I1007 17:39:01.401008  5078 net.cpp:122] Setting up penlu31
I1007 17:39:01.401012  5078 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 17:39:01.401021  5078 net.cpp:137] Memory required for data: 522771600
I1007 17:39:01.401026  5078 layer_factory.hpp:77] Creating layer Pooling1
I1007 17:39:01.401031  5078 net.cpp:84] Creating Layer Pooling1
I1007 17:39:01.401033  5078 net.cpp:406] Pooling1 <- Eltwise15
I1007 17:39:01.401037  5078 net.cpp:380] Pooling1 -> Pooling1
I1007 17:39:01.401192  5078 net.cpp:122] Setting up Pooling1
I1007 17:39:01.401198  5078 net.cpp:129] Top shape: 100 64 1 1 (6400)
I1007 17:39:01.401201  5078 net.cpp:137] Memory required for data: 522797200
I1007 17:39:01.401202  5078 layer_factory.hpp:77] Creating layer InnerProduct1
I1007 17:39:01.401212  5078 net.cpp:84] Creating Layer InnerProduct1
I1007 17:39:01.401216  5078 net.cpp:406] InnerProduct1 <- Pooling1
I1007 17:39:01.401218  5078 net.cpp:380] InnerProduct1 -> InnerProduct1
I1007 17:39:01.401315  5078 net.cpp:122] Setting up InnerProduct1
I1007 17:39:01.401320  5078 net.cpp:129] Top shape: 100 10 (1000)
I1007 17:39:01.401322  5078 net.cpp:137] Memory required for data: 522801200
I1007 17:39:01.401326  5078 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I1007 17:39:01.401330  5078 net.cpp:84] Creating Layer SoftmaxWithLoss1
I1007 17:39:01.401334  5078 net.cpp:406] SoftmaxWithLoss1 <- InnerProduct1
I1007 17:39:01.401336  5078 net.cpp:406] SoftmaxWithLoss1 <- Data2
I1007 17:39:01.401340  5078 net.cpp:380] SoftmaxWithLoss1 -> SoftmaxWithLoss1
I1007 17:39:01.401355  5078 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I1007 17:39:01.401607  5078 net.cpp:122] Setting up SoftmaxWithLoss1
I1007 17:39:01.401614  5078 net.cpp:129] Top shape: (1)
I1007 17:39:01.401618  5078 net.cpp:132]     with loss weight 1
I1007 17:39:01.401629  5078 net.cpp:137] Memory required for data: 522801204
I1007 17:39:01.401633  5078 net.cpp:198] SoftmaxWithLoss1 needs backward computation.
I1007 17:39:01.401635  5078 net.cpp:198] InnerProduct1 needs backward computation.
I1007 17:39:01.401638  5078 net.cpp:198] Pooling1 needs backward computation.
I1007 17:39:01.401639  5078 net.cpp:198] penlu31 needs backward computation.
I1007 17:39:01.401641  5078 net.cpp:198] Eltwise15 needs backward computation.
I1007 17:39:01.401643  5078 net.cpp:198] Scale33 needs backward computation.
I1007 17:39:01.401646  5078 net.cpp:198] BatchNorm33 needs backward computation.
I1007 17:39:01.401648  5078 net.cpp:198] Convolution33 needs backward computation.
I1007 17:39:01.401650  5078 net.cpp:198] penlu30 needs backward computation.
I1007 17:39:01.401652  5078 net.cpp:198] Scale32 needs backward computation.
I1007 17:39:01.401654  5078 net.cpp:198] BatchNorm32 needs backward computation.
I1007 17:39:01.401656  5078 net.cpp:198] Convolution32 needs backward computation.
I1007 17:39:01.401659  5078 net.cpp:198] Eltwise14_penlu29_0_split needs backward computation.
I1007 17:39:01.401660  5078 net.cpp:198] penlu29 needs backward computation.
I1007 17:39:01.401662  5078 net.cpp:198] Eltwise14 needs backward computation.
I1007 17:39:01.401665  5078 net.cpp:198] Scale31 needs backward computation.
I1007 17:39:01.401667  5078 net.cpp:198] BatchNorm31 needs backward computation.
I1007 17:39:01.401669  5078 net.cpp:198] Convolution31 needs backward computation.
I1007 17:39:01.401671  5078 net.cpp:198] penlu28 needs backward computation.
I1007 17:39:01.401674  5078 net.cpp:198] Scale30 needs backward computation.
I1007 17:39:01.401675  5078 net.cpp:198] BatchNorm30 needs backward computation.
I1007 17:39:01.401677  5078 net.cpp:198] Convolution30 needs backward computation.
I1007 17:39:01.401679  5078 net.cpp:198] Eltwise13_penlu27_0_split needs backward computation.
I1007 17:39:01.401681  5078 net.cpp:198] penlu27 needs backward computation.
I1007 17:39:01.401684  5078 net.cpp:198] Eltwise13 needs backward computation.
I1007 17:39:01.401686  5078 net.cpp:198] Scale29 needs backward computation.
I1007 17:39:01.401688  5078 net.cpp:198] BatchNorm29 needs backward computation.
I1007 17:39:01.401690  5078 net.cpp:198] Convolution29 needs backward computation.
I1007 17:39:01.401692  5078 net.cpp:198] penlu26 needs backward computation.
I1007 17:39:01.401701  5078 net.cpp:198] Scale28 needs backward computation.
I1007 17:39:01.401703  5078 net.cpp:198] BatchNorm28 needs backward computation.
I1007 17:39:01.401705  5078 net.cpp:198] Convolution28 needs backward computation.
I1007 17:39:01.401707  5078 net.cpp:198] Eltwise12_penlu25_0_split needs backward computation.
I1007 17:39:01.401710  5078 net.cpp:198] penlu25 needs backward computation.
I1007 17:39:01.401711  5078 net.cpp:198] Eltwise12 needs backward computation.
I1007 17:39:01.401715  5078 net.cpp:198] Scale27 needs backward computation.
I1007 17:39:01.401716  5078 net.cpp:198] BatchNorm27 needs backward computation.
I1007 17:39:01.401718  5078 net.cpp:198] Convolution27 needs backward computation.
I1007 17:39:01.401721  5078 net.cpp:198] penlu24 needs backward computation.
I1007 17:39:01.401722  5078 net.cpp:198] Scale26 needs backward computation.
I1007 17:39:01.401724  5078 net.cpp:198] BatchNorm26 needs backward computation.
I1007 17:39:01.401726  5078 net.cpp:198] Convolution26 needs backward computation.
I1007 17:39:01.401728  5078 net.cpp:198] Eltwise11_penlu23_0_split needs backward computation.
I1007 17:39:01.401731  5078 net.cpp:198] penlu23 needs backward computation.
I1007 17:39:01.401732  5078 net.cpp:198] Eltwise11 needs backward computation.
I1007 17:39:01.401736  5078 net.cpp:198] Scale25 needs backward computation.
I1007 17:39:01.401737  5078 net.cpp:198] BatchNorm25 needs backward computation.
I1007 17:39:01.401739  5078 net.cpp:198] Convolution25 needs backward computation.
I1007 17:39:01.401741  5078 net.cpp:198] penlu22 needs backward computation.
I1007 17:39:01.401743  5078 net.cpp:198] Scale24 needs backward computation.
I1007 17:39:01.401746  5078 net.cpp:198] BatchNorm24 needs backward computation.
I1007 17:39:01.401747  5078 net.cpp:198] Convolution24 needs backward computation.
I1007 17:39:01.401749  5078 net.cpp:198] Scale23 needs backward computation.
I1007 17:39:01.401752  5078 net.cpp:198] BatchNorm23 needs backward computation.
I1007 17:39:01.401754  5078 net.cpp:198] Convolution23 needs backward computation.
I1007 17:39:01.401757  5078 net.cpp:198] Eltwise10_penlu21_0_split needs backward computation.
I1007 17:39:01.401758  5078 net.cpp:198] penlu21 needs backward computation.
I1007 17:39:01.401760  5078 net.cpp:198] Eltwise10 needs backward computation.
I1007 17:39:01.401763  5078 net.cpp:198] Scale22 needs backward computation.
I1007 17:39:01.401765  5078 net.cpp:198] BatchNorm22 needs backward computation.
I1007 17:39:01.401767  5078 net.cpp:198] Convolution22 needs backward computation.
I1007 17:39:01.401769  5078 net.cpp:198] penlu20 needs backward computation.
I1007 17:39:01.401772  5078 net.cpp:198] Scale21 needs backward computation.
I1007 17:39:01.401774  5078 net.cpp:198] BatchNorm21 needs backward computation.
I1007 17:39:01.401777  5078 net.cpp:198] Convolution21 needs backward computation.
I1007 17:39:01.401778  5078 net.cpp:198] Eltwise9_penlu19_0_split needs backward computation.
I1007 17:39:01.401780  5078 net.cpp:198] penlu19 needs backward computation.
I1007 17:39:01.401783  5078 net.cpp:198] Eltwise9 needs backward computation.
I1007 17:39:01.401785  5078 net.cpp:198] Scale20 needs backward computation.
I1007 17:39:01.401787  5078 net.cpp:198] BatchNorm20 needs backward computation.
I1007 17:39:01.401789  5078 net.cpp:198] Convolution20 needs backward computation.
I1007 17:39:01.401793  5078 net.cpp:198] penlu18 needs backward computation.
I1007 17:39:01.401794  5078 net.cpp:198] Scale19 needs backward computation.
I1007 17:39:01.401796  5078 net.cpp:198] BatchNorm19 needs backward computation.
I1007 17:39:01.401798  5078 net.cpp:198] Convolution19 needs backward computation.
I1007 17:39:01.401801  5078 net.cpp:198] Eltwise8_penlu17_0_split needs backward computation.
I1007 17:39:01.401803  5078 net.cpp:198] penlu17 needs backward computation.
I1007 17:39:01.401805  5078 net.cpp:198] Eltwise8 needs backward computation.
I1007 17:39:01.401808  5078 net.cpp:198] Scale18 needs backward computation.
I1007 17:39:01.401810  5078 net.cpp:198] BatchNorm18 needs backward computation.
I1007 17:39:01.401815  5078 net.cpp:198] Convolution18 needs backward computation.
I1007 17:39:01.401818  5078 net.cpp:198] penlu16 needs backward computation.
I1007 17:39:01.401820  5078 net.cpp:198] Scale17 needs backward computation.
I1007 17:39:01.401823  5078 net.cpp:198] BatchNorm17 needs backward computation.
I1007 17:39:01.401824  5078 net.cpp:198] Convolution17 needs backward computation.
I1007 17:39:01.401826  5078 net.cpp:198] Eltwise7_penlu15_0_split needs backward computation.
I1007 17:39:01.401829  5078 net.cpp:198] penlu15 needs backward computation.
I1007 17:39:01.401831  5078 net.cpp:198] Eltwise7 needs backward computation.
I1007 17:39:01.401834  5078 net.cpp:198] Scale16 needs backward computation.
I1007 17:39:01.401836  5078 net.cpp:198] BatchNorm16 needs backward computation.
I1007 17:39:01.401839  5078 net.cpp:198] Convolution16 needs backward computation.
I1007 17:39:01.401840  5078 net.cpp:198] penlu14 needs backward computation.
I1007 17:39:01.401844  5078 net.cpp:198] Scale15 needs backward computation.
I1007 17:39:01.401845  5078 net.cpp:198] BatchNorm15 needs backward computation.
I1007 17:39:01.401847  5078 net.cpp:198] Convolution15 needs backward computation.
I1007 17:39:01.401849  5078 net.cpp:198] Eltwise6_penlu13_0_split needs backward computation.
I1007 17:39:01.401852  5078 net.cpp:198] penlu13 needs backward computation.
I1007 17:39:01.401854  5078 net.cpp:198] Eltwise6 needs backward computation.
I1007 17:39:01.401856  5078 net.cpp:198] Scale14 needs backward computation.
I1007 17:39:01.401859  5078 net.cpp:198] BatchNorm14 needs backward computation.
I1007 17:39:01.401861  5078 net.cpp:198] Convolution14 needs backward computation.
I1007 17:39:01.401865  5078 net.cpp:198] penlu12 needs backward computation.
I1007 17:39:01.401866  5078 net.cpp:198] Scale13 needs backward computation.
I1007 17:39:01.401868  5078 net.cpp:198] BatchNorm13 needs backward computation.
I1007 17:39:01.401871  5078 net.cpp:198] Convolution13 needs backward computation.
I1007 17:39:01.401873  5078 net.cpp:198] Scale12 needs backward computation.
I1007 17:39:01.401875  5078 net.cpp:198] BatchNorm12 needs backward computation.
I1007 17:39:01.401877  5078 net.cpp:198] Convolution12 needs backward computation.
I1007 17:39:01.401880  5078 net.cpp:198] Eltwise5_penlu11_0_split needs backward computation.
I1007 17:39:01.401882  5078 net.cpp:198] penlu11 needs backward computation.
I1007 17:39:01.401885  5078 net.cpp:198] Eltwise5 needs backward computation.
I1007 17:39:01.401887  5078 net.cpp:198] Scale11 needs backward computation.
I1007 17:39:01.401890  5078 net.cpp:198] BatchNorm11 needs backward computation.
I1007 17:39:01.401892  5078 net.cpp:198] Convolution11 needs backward computation.
I1007 17:39:01.401895  5078 net.cpp:198] penlu10 needs backward computation.
I1007 17:39:01.401896  5078 net.cpp:198] Scale10 needs backward computation.
I1007 17:39:01.401898  5078 net.cpp:198] BatchNorm10 needs backward computation.
I1007 17:39:01.401901  5078 net.cpp:198] Convolution10 needs backward computation.
I1007 17:39:01.401903  5078 net.cpp:198] Eltwise4_penlu9_0_split needs backward computation.
I1007 17:39:01.401906  5078 net.cpp:198] penlu9 needs backward computation.
I1007 17:39:01.401908  5078 net.cpp:198] Eltwise4 needs backward computation.
I1007 17:39:01.401911  5078 net.cpp:198] Scale9 needs backward computation.
I1007 17:39:01.401913  5078 net.cpp:198] BatchNorm9 needs backward computation.
I1007 17:39:01.401916  5078 net.cpp:198] Convolution9 needs backward computation.
I1007 17:39:01.401918  5078 net.cpp:198] penlu8 needs backward computation.
I1007 17:39:01.401921  5078 net.cpp:198] Scale8 needs backward computation.
I1007 17:39:01.401922  5078 net.cpp:198] BatchNorm8 needs backward computation.
I1007 17:39:01.401924  5078 net.cpp:198] Convolution8 needs backward computation.
I1007 17:39:01.401927  5078 net.cpp:198] Eltwise3_penlu7_0_split needs backward computation.
I1007 17:39:01.401929  5078 net.cpp:198] penlu7 needs backward computation.
I1007 17:39:01.401934  5078 net.cpp:198] Eltwise3 needs backward computation.
I1007 17:39:01.401937  5078 net.cpp:198] Scale7 needs backward computation.
I1007 17:39:01.401939  5078 net.cpp:198] BatchNorm7 needs backward computation.
I1007 17:39:01.401942  5078 net.cpp:198] Convolution7 needs backward computation.
I1007 17:39:01.401944  5078 net.cpp:198] penlu6 needs backward computation.
I1007 17:39:01.401947  5078 net.cpp:198] Scale6 needs backward computation.
I1007 17:39:01.401949  5078 net.cpp:198] BatchNorm6 needs backward computation.
I1007 17:39:01.401952  5078 net.cpp:198] Convolution6 needs backward computation.
I1007 17:39:01.401953  5078 net.cpp:198] Eltwise2_penlu5_0_split needs backward computation.
I1007 17:39:01.401955  5078 net.cpp:198] penlu5 needs backward computation.
I1007 17:39:01.401958  5078 net.cpp:198] Eltwise2 needs backward computation.
I1007 17:39:01.401960  5078 net.cpp:198] Scale5 needs backward computation.
I1007 17:39:01.401963  5078 net.cpp:198] BatchNorm5 needs backward computation.
I1007 17:39:01.401965  5078 net.cpp:198] Convolution5 needs backward computation.
I1007 17:39:01.401968  5078 net.cpp:198] penlu4 needs backward computation.
I1007 17:39:01.401970  5078 net.cpp:198] Scale4 needs backward computation.
I1007 17:39:01.401973  5078 net.cpp:198] BatchNorm4 needs backward computation.
I1007 17:39:01.401974  5078 net.cpp:198] Convolution4 needs backward computation.
I1007 17:39:01.401978  5078 net.cpp:198] Eltwise1_penlu3_0_split needs backward computation.
I1007 17:39:01.401979  5078 net.cpp:198] penlu3 needs backward computation.
I1007 17:39:01.401983  5078 net.cpp:198] Eltwise1 needs backward computation.
I1007 17:39:01.401984  5078 net.cpp:198] Scale3 needs backward computation.
I1007 17:39:01.401988  5078 net.cpp:198] BatchNorm3 needs backward computation.
I1007 17:39:01.401989  5078 net.cpp:198] Convolution3 needs backward computation.
I1007 17:39:01.401993  5078 net.cpp:198] penlu2 needs backward computation.
I1007 17:39:01.401994  5078 net.cpp:198] Scale2 needs backward computation.
I1007 17:39:01.401996  5078 net.cpp:198] BatchNorm2 needs backward computation.
I1007 17:39:01.401998  5078 net.cpp:198] Convolution2 needs backward computation.
I1007 17:39:01.402001  5078 net.cpp:198] Convolution1_penlu1_0_split needs backward computation.
I1007 17:39:01.402004  5078 net.cpp:198] penlu1 needs backward computation.
I1007 17:39:01.402006  5078 net.cpp:198] Scale1 needs backward computation.
I1007 17:39:01.402009  5078 net.cpp:198] BatchNorm1 needs backward computation.
I1007 17:39:01.402010  5078 net.cpp:198] Convolution1 needs backward computation.
I1007 17:39:01.402012  5078 net.cpp:200] Data1 does not need backward computation.
I1007 17:39:01.402014  5078 net.cpp:242] This network produces output SoftmaxWithLoss1
I1007 17:39:01.402066  5078 net.cpp:255] Network initialization done.
I1007 17:39:01.404940  5078 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: /home/x306/caffe/xn/PENLU/neural/resnet/res32/res32_penlu_decay_gauss.prototxt
I1007 17:39:01.404952  5078 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I1007 17:39:01.404956  5078 solver.cpp:172] Creating test net (#0) specified by net file: /home/x306/caffe/xn/PENLU/neural/resnet/res32/res32_penlu_decay_gauss.prototxt
I1007 17:39:01.405077  5078 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer Data1
I1007 17:39:01.405838  5078 net.cpp:51] Initializing net from parameters: 
name: "resnet_cifar10"
state {
  phase: TEST
}
layer {
  name: "Data1"
  type: "Data"
  top: "Data1"
  top: "Data2"
  include {
    phase: TEST
  }
  transform_param {
    mean_file: "/home/x306/caffe/xn/PENLU/data/cifar10/mean.binaryproto"
  }
  data_param {
    source: "/home/x306/caffe/xn/PENLU/data/cifar10/cifar10_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "Convolution1"
  type: "Convolution"
  bottom: "Data1"
  top: "Convolution1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm1"
  type: "BatchNorm"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1"
  type: "Scale"
  bottom: "Convolution1"
  top: "Convolution1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu1"
  type: "PENLU"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution2"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm2"
  type: "BatchNorm"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale2"
  type: "Scale"
  bottom: "Convolution2"
  top: "Convolution2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu2"
  type: "PENLU"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution3"
  type: "Convolution"
  bottom: "Convolution2"
  top: "Convolution3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm3"
  type: "BatchNorm"
  bottom: "Convolution3"
  top: "Convolution3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale3"
  type: "Scale"
  bottom: "Convolution3"
  top: "Convolution3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise1"
  type: "Eltwise"
  bottom: "Convolution1"
  bottom: "Convolution3"
  top: "Eltwise1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu3"
  type: "PENLU"
  bottom: "Eltwise1"
  top: "Eltwise1"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution4"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm4"
  type: "BatchNorm"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale4"
  type: "Scale"
  bottom: "Convolution4"
  top: "Convolution4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu4"
  type: "PENLU"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution5"
  type: "Convolution"
  bottom: "Convolution4"
  top: "Convolution5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm5"
  type: "BatchNorm"
  bottom: "Convolution5"
  top: "Convolution5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale5"
  type: "Scale"
  bottom: "Convolution5"
  top: "Convolution5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise2"
  type: "Eltwise"
  bottom: "Eltwise1"
  bottom: "Convolution5"
  top: "Eltwise2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu5"
  type: "PENLU"
  bottom: "Eltwise2"
  top: "Eltwise2"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution6"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm6"
  type: "BatchNorm"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale6"
  type: "Scale"
  bottom: "Convolution6"
  top: "Convolution6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu6"
  type: "PENLU"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution7"
  type: "Convolution"
  bottom: "Convolution6"
  top: "Convolution7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm7"
  type: "BatchNorm"
  bottom: "Convolution7"
  top: "Convolution7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale7"
  type: "Scale"
  bottom: "Convolution7"
  top: "Convolution7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise3"
  type: "Eltwise"
  bottom: "Eltwise2"
  bottom: "Convolution7"
  top: "Eltwise3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu7"
  type: "PENLU"
  bottom: "Eltwise3"
  top: "Eltwise3"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution8"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm8"
  type: "BatchNorm"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale8"
  type: "Scale"
  bottom: "Convolution8"
  top: "Convolution8"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu8"
  type: "PENLU"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution9"
  type: "Convolution"
  bottom: "Convolution8"
  top: "Convolution9"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm9"
  type: "BatchNorm"
  bottom: "Convolution9"
  top: "Convolution9"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale9"
  type: "Scale"
  bottom: "Convolution9"
  top: "Convolution9"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise4"
  type: "Eltwise"
  bottom: "Eltwise3"
  bottom: "Convolution9"
  top: "Eltwise4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu9"
  type: "PENLU"
  bottom: "Eltwise4"
  top: "Eltwise4"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution10"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution10"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm10"
  type: "BatchNorm"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale10"
  type: "Scale"
  bottom: "Convolution10"
  top: "Convolution10"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu10"
  type: "PENLU"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution11"
  type: "Convolution"
  bottom: "Convolution10"
  top: "Convolution11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm11"
  type: "BatchNorm"
  bottom: "Convolution11"
  top: "Convolution11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale11"
  type: "Scale"
  bottom: "Convolution11"
  top: "Convolution11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise5"
  type: "Eltwise"
  bottom: "Eltwise4"
  bottom: "Convolution11"
  top: "Eltwise5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu11"
  type: "PENLU"
  bottom: "Eltwise5"
  top: "Eltwise5"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution12"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.25
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm12"
  type: "BatchNorm"
  bottom: "Convolution12"
  top: "Convolution12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale12"
  type: "Scale"
  bottom: "Convolution12"
  top: "Convolution12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution13"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution13"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm13"
  type: "BatchNorm"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale13"
  type: "Scale"
  bottom: "Convolution13"
  top: "Convolution13"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu12"
  type: "PENLU"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution14"
  type: "Convolution"
  bottom: "Convolution13"
  top: "Convolution14"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm14"
  type: "BatchNorm"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale14"
  type: "Scale"
  bottom: "Convolution14"
  top: "Convolution14"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise6"
  type: "Eltwise"
  bottom: "Convolution12"
  bottom: "Convolution14"
  top: "Eltwise6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu13"
  type: "PENLU"
  bottom: "Eltwise6"
  top: "Eltwise6"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution15"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution15"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm15"
  type: "BatchNorm"
  bottom: "Convolution15"
  top: "Convolution15"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale15"
  type: "Scale"
  bottom: "Convolution15"
  top: "Convolution15"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu14"
  type: "PENLU"
  bottom: "Convolution15"
  top: "Convolution15"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution16"
  type: "Convolution"
  bottom: "Convolution15"
  top: "Convolution16"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm16"
  type: "BatchNorm"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale16"
  type: "Scale"
  bottom: "Convolution16"
  top: "Convolution16"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise7"
  type: "Eltwise"
  bottom: "Eltwise6"
  bottom: "Convolution16"
  top: "Eltwise7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu15"
  type: "PENLU"
  bottom: "Eltwise7"
  top: "Eltwise7"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution17"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution17"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm17"
  type: "BatchNorm"
  bottom: "Convolution17"
  top: "Convolution17"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale17"
  type: "Scale"
  bottom: "Convolution17"
  top: "Convolution17"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu16"
  type: "PENLU"
  bottom: "Convolution17"
  top: "Convolution17"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution18"
  type: "Convolution"
  bottom: "Convolution17"
  top: "Convolution18"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm18"
  type: "BatchNorm"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale18"
  type: "Scale"
  bottom: "Convolution18"
  top: "Convolution18"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise8"
  type: "Eltwise"
  bottom: "Eltwise7"
  bottom: "Convolution18"
  top: "Eltwise8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu17"
  type: "PENLU"
  bottom: "Eltwise8"
  top: "Eltwise8"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution19"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution19"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm19"
  type: "BatchNorm"
  bottom: "Convolution19"
  top: "Convolution19"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale19"
  type: "Scale"
  bottom: "Convolution19"
  top: "Convolution19"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu18"
  type: "PENLU"
  bottom: "Convolution19"
  top: "Convolution19"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution20"
  type: "Convolution"
  bottom: "Convolution19"
  top: "Convolution20"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm20"
  type: "BatchNorm"
  bottom: "Convolution20"
  top: "Convolution20"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale20"
  type: "Scale"
  bottom: "Convolution20"
  top: "Convolution20"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise9"
  type: "Eltwise"
  bottom: "Eltwise8"
  bottom: "Convolution20"
  top: "Eltwise9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu19"
  type: "PENLU"
  bottom: "Eltwise9"
  top: "Eltwise9"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution21"
  type: "Convolution"
  bottom: "Eltwise9"
  top: "Convolution21"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm21"
  type: "BatchNorm"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale21"
  type: "Scale"
  bottom: "Convolution21"
  top: "Convolution21"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu20"
  type: "PENLU"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution22"
  type: "Convolution"
  bottom: "Convolution21"
  top: "Convolution22"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm22"
  type: "BatchNorm"
  bottom: "Convolution22"
  top: "Convolution22"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale22"
  type: "Scale"
  bottom: "Convolution22"
  top: "Convolution22"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise10"
  type: "Eltwise"
  bottom: "Eltwise9"
  bottom: "Convolution22"
  top: "Eltwise10"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "penlu21"
  type: "PENLU"
  bottom: "Eltwise10"
  top: "Eltwise10"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  penlu_param {
    alpha_filler {
      type: "constant"
      value: 2
    }
    beta_filler {
      type: "constant"
      value: 1
    }
    eta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution23"
  type: "Convolution"
  bottom: "Eltwise10"
  top: "Convolution23"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.17677669
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm23"
  type: "BatchNorm"
  bottom: "Convolution23"
  top: "Convolution23"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale23"
  type: "Scale"
  bottom: "Convolution23"
  top: "Convolution23"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution24"
  type: "Convolution"
  bottom: "Eltwise10"
  top: "Convolution24"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm24"
  type: "BatchNorm"
  bottom: "Convolution24"
  top: "Convolution24"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale24"
  type: "Scale"
  bottom: "Convolution24"
  top: "Convolution24"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "penlu22"
  type: "PENLU"
 
I1007 17:39:01.406260  5078 layer_factory.hpp:77] Creating layer Data1
I1007 17:39:01.431890  5078 db_lmdb.cpp:35] Opened lmdb /home/x306/caffe/xn/PENLU/data/cifar10/cifar10_test_lmdb
I1007 17:39:01.431906  5078 net.cpp:84] Creating Layer Data1
I1007 17:39:01.431913  5078 net.cpp:380] Data1 -> Data1
I1007 17:39:01.431922  5078 net.cpp:380] Data1 -> Data2
I1007 17:39:01.431928  5078 data_transformer.cpp:25] Loading mean file from: /home/x306/caffe/xn/PENLU/data/cifar10/mean.binaryproto
I1007 17:39:01.432078  5078 data_layer.cpp:45] output data size: 100,3,32,32
I1007 17:39:01.436520  5078 net.cpp:122] Setting up Data1
I1007 17:39:01.436542  5078 net.cpp:129] Top shape: 100 3 32 32 (307200)
I1007 17:39:01.436547  5078 net.cpp:129] Top shape: 100 (100)
I1007 17:39:01.436548  5078 net.cpp:137] Memory required for data: 1229200
I1007 17:39:01.436553  5078 layer_factory.hpp:77] Creating layer Data2_Data1_1_split
I1007 17:39:01.436563  5078 net.cpp:84] Creating Layer Data2_Data1_1_split
I1007 17:39:01.436565  5078 net.cpp:406] Data2_Data1_1_split <- Data2
I1007 17:39:01.436571  5078 net.cpp:380] Data2_Data1_1_split -> Data2_Data1_1_split_0
I1007 17:39:01.436579  5078 net.cpp:380] Data2_Data1_1_split -> Data2_Data1_1_split_1
I1007 17:39:01.436621  5078 net.cpp:122] Setting up Data2_Data1_1_split
I1007 17:39:01.436626  5078 net.cpp:129] Top shape: 100 (100)
I1007 17:39:01.436630  5078 net.cpp:129] Top shape: 100 (100)
I1007 17:39:01.436631  5078 net.cpp:137] Memory required for data: 1230000
I1007 17:39:01.436633  5078 layer_factory.hpp:77] Creating layer Convolution1
I1007 17:39:01.436645  5078 net.cpp:84] Creating Layer Convolution1
I1007 17:39:01.436646  5078 net.cpp:406] Convolution1 <- Data1
I1007 17:39:01.436650  5078 net.cpp:380] Convolution1 -> Convolution1
I1007 17:39:01.437870  5078 net.cpp:122] Setting up Convolution1
I1007 17:39:01.437882  5078 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 17:39:01.437885  5078 net.cpp:137] Memory required for data: 7783600
I1007 17:39:01.437901  5078 layer_factory.hpp:77] Creating layer BatchNorm1
I1007 17:39:01.437906  5078 net.cpp:84] Creating Layer BatchNorm1
I1007 17:39:01.437909  5078 net.cpp:406] BatchNorm1 <- Convolution1
I1007 17:39:01.437913  5078 net.cpp:367] BatchNorm1 -> Convolution1 (in-place)
I1007 17:39:01.438062  5078 net.cpp:122] Setting up BatchNorm1
I1007 17:39:01.438067  5078 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 17:39:01.438069  5078 net.cpp:137] Memory required for data: 14337200
I1007 17:39:01.438076  5078 layer_factory.hpp:77] Creating layer Scale1
I1007 17:39:01.438083  5078 net.cpp:84] Creating Layer Scale1
I1007 17:39:01.438086  5078 net.cpp:406] Scale1 <- Convolution1
I1007 17:39:01.438088  5078 net.cpp:367] Scale1 -> Convolution1 (in-place)
I1007 17:39:01.438118  5078 layer_factory.hpp:77] Creating layer Scale1
I1007 17:39:01.438200  5078 net.cpp:122] Setting up Scale1
I1007 17:39:01.438205  5078 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 17:39:01.438210  5078 net.cpp:137] Memory required for data: 20890800
I1007 17:39:01.438213  5078 layer_factory.hpp:77] Creating layer penlu1
I1007 17:39:01.438220  5078 net.cpp:84] Creating Layer penlu1
I1007 17:39:01.438223  5078 net.cpp:406] penlu1 <- Convolution1
I1007 17:39:01.438230  5078 net.cpp:367] penlu1 -> Convolution1 (in-place)
I1007 17:39:01.438356  5078 net.cpp:122] Setting up penlu1
I1007 17:39:01.438372  5078 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 17:39:01.438374  5078 net.cpp:137] Memory required for data: 27444400
I1007 17:39:01.438382  5078 layer_factory.hpp:77] Creating layer Convolution1_penlu1_0_split
I1007 17:39:01.438386  5078 net.cpp:84] Creating Layer Convolution1_penlu1_0_split
I1007 17:39:01.438388  5078 net.cpp:406] Convolution1_penlu1_0_split <- Convolution1
I1007 17:39:01.438391  5078 net.cpp:380] Convolution1_penlu1_0_split -> Convolution1_penlu1_0_split_0
I1007 17:39:01.438397  5078 net.cpp:380] Convolution1_penlu1_0_split -> Convolution1_penlu1_0_split_1
I1007 17:39:01.438423  5078 net.cpp:122] Setting up Convolution1_penlu1_0_split
I1007 17:39:01.438433  5078 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 17:39:01.438436  5078 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 17:39:01.438438  5078 net.cpp:137] Memory required for data: 40551600
I1007 17:39:01.438441  5078 layer_factory.hpp:77] Creating layer Convolution2
I1007 17:39:01.438447  5078 net.cpp:84] Creating Layer Convolution2
I1007 17:39:01.438449  5078 net.cpp:406] Convolution2 <- Convolution1_penlu1_0_split_0
I1007 17:39:01.438454  5078 net.cpp:380] Convolution2 -> Convolution2
I1007 17:39:01.439558  5078 net.cpp:122] Setting up Convolution2
I1007 17:39:01.439569  5078 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 17:39:01.439573  5078 net.cpp:137] Memory required for data: 47105200
I1007 17:39:01.439577  5078 layer_factory.hpp:77] Creating layer BatchNorm2
I1007 17:39:01.439584  5078 net.cpp:84] Creating Layer BatchNorm2
I1007 17:39:01.439586  5078 net.cpp:406] BatchNorm2 <- Convolution2
I1007 17:39:01.439589  5078 net.cpp:367] BatchNorm2 -> Convolution2 (in-place)
I1007 17:39:01.439729  5078 net.cpp:122] Setting up BatchNorm2
I1007 17:39:01.439735  5078 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 17:39:01.439738  5078 net.cpp:137] Memory required for data: 53658800
I1007 17:39:01.439743  5078 layer_factory.hpp:77] Creating layer Scale2
I1007 17:39:01.439754  5078 net.cpp:84] Creating Layer Scale2
I1007 17:39:01.439755  5078 net.cpp:406] Scale2 <- Convolution2
I1007 17:39:01.439759  5078 net.cpp:367] Scale2 -> Convolution2 (in-place)
I1007 17:39:01.439788  5078 layer_factory.hpp:77] Creating layer Scale2
I1007 17:39:01.439867  5078 net.cpp:122] Setting up Scale2
I1007 17:39:01.439872  5078 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 17:39:01.439873  5078 net.cpp:137] Memory required for data: 60212400
I1007 17:39:01.439879  5078 layer_factory.hpp:77] Creating layer penlu2
I1007 17:39:01.439887  5078 net.cpp:84] Creating Layer penlu2
I1007 17:39:01.439889  5078 net.cpp:406] penlu2 <- Convolution2
I1007 17:39:01.439893  5078 net.cpp:367] penlu2 -> Convolution2 (in-place)
I1007 17:39:01.440013  5078 net.cpp:122] Setting up penlu2
I1007 17:39:01.440018  5078 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 17:39:01.440021  5078 net.cpp:137] Memory required for data: 66766000
I1007 17:39:01.440024  5078 layer_factory.hpp:77] Creating layer Convolution3
I1007 17:39:01.440032  5078 net.cpp:84] Creating Layer Convolution3
I1007 17:39:01.440034  5078 net.cpp:406] Convolution3 <- Convolution2
I1007 17:39:01.440037  5078 net.cpp:380] Convolution3 -> Convolution3
I1007 17:39:01.441108  5078 net.cpp:122] Setting up Convolution3
I1007 17:39:01.441118  5078 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 17:39:01.441121  5078 net.cpp:137] Memory required for data: 73319600
I1007 17:39:01.441125  5078 layer_factory.hpp:77] Creating layer BatchNorm3
I1007 17:39:01.441133  5078 net.cpp:84] Creating Layer BatchNorm3
I1007 17:39:01.441135  5078 net.cpp:406] BatchNorm3 <- Convolution3
I1007 17:39:01.441139  5078 net.cpp:367] BatchNorm3 -> Convolution3 (in-place)
I1007 17:39:01.441279  5078 net.cpp:122] Setting up BatchNorm3
I1007 17:39:01.441284  5078 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 17:39:01.441287  5078 net.cpp:137] Memory required for data: 79873200
I1007 17:39:01.441293  5078 layer_factory.hpp:77] Creating layer Scale3
I1007 17:39:01.441296  5078 net.cpp:84] Creating Layer Scale3
I1007 17:39:01.441306  5078 net.cpp:406] Scale3 <- Convolution3
I1007 17:39:01.441310  5078 net.cpp:367] Scale3 -> Convolution3 (in-place)
I1007 17:39:01.441340  5078 layer_factory.hpp:77] Creating layer Scale3
I1007 17:39:01.441417  5078 net.cpp:122] Setting up Scale3
I1007 17:39:01.441422  5078 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 17:39:01.441426  5078 net.cpp:137] Memory required for data: 86426800
I1007 17:39:01.441431  5078 layer_factory.hpp:77] Creating layer Eltwise1
I1007 17:39:01.441435  5078 net.cpp:84] Creating Layer Eltwise1
I1007 17:39:01.441438  5078 net.cpp:406] Eltwise1 <- Convolution1_penlu1_0_split_1
I1007 17:39:01.441442  5078 net.cpp:406] Eltwise1 <- Convolution3
I1007 17:39:01.441445  5078 net.cpp:380] Eltwise1 -> Eltwise1
I1007 17:39:01.441463  5078 net.cpp:122] Setting up Eltwise1
I1007 17:39:01.441468  5078 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 17:39:01.441469  5078 net.cpp:137] Memory required for data: 92980400
I1007 17:39:01.441471  5078 layer_factory.hpp:77] Creating layer penlu3
I1007 17:39:01.441478  5078 net.cpp:84] Creating Layer penlu3
I1007 17:39:01.441479  5078 net.cpp:406] penlu3 <- Eltwise1
I1007 17:39:01.441483  5078 net.cpp:367] penlu3 -> Eltwise1 (in-place)
I1007 17:39:01.441603  5078 net.cpp:122] Setting up penlu3
I1007 17:39:01.441607  5078 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 17:39:01.441609  5078 net.cpp:137] Memory required for data: 99534000
I1007 17:39:01.441614  5078 layer_factory.hpp:77] Creating layer Eltwise1_penlu3_0_split
I1007 17:39:01.441619  5078 net.cpp:84] Creating Layer Eltwise1_penlu3_0_split
I1007 17:39:01.441622  5078 net.cpp:406] Eltwise1_penlu3_0_split <- Eltwise1
I1007 17:39:01.441625  5078 net.cpp:380] Eltwise1_penlu3_0_split -> Eltwise1_penlu3_0_split_0
I1007 17:39:01.441629  5078 net.cpp:380] Eltwise1_penlu3_0_split -> Eltwise1_penlu3_0_split_1
I1007 17:39:01.441653  5078 net.cpp:122] Setting up Eltwise1_penlu3_0_split
I1007 17:39:01.441656  5078 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 17:39:01.441659  5078 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 17:39:01.441661  5078 net.cpp:137] Memory required for data: 112641200
I1007 17:39:01.441665  5078 layer_factory.hpp:77] Creating layer Convolution4
I1007 17:39:01.441673  5078 net.cpp:84] Creating Layer Convolution4
I1007 17:39:01.441675  5078 net.cpp:406] Convolution4 <- Eltwise1_penlu3_0_split_0
I1007 17:39:01.441679  5078 net.cpp:380] Convolution4 -> Convolution4
I1007 17:39:01.442782  5078 net.cpp:122] Setting up Convolution4
I1007 17:39:01.442792  5078 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 17:39:01.442795  5078 net.cpp:137] Memory required for data: 119194800
I1007 17:39:01.442800  5078 layer_factory.hpp:77] Creating layer BatchNorm4
I1007 17:39:01.442807  5078 net.cpp:84] Creating Layer BatchNorm4
I1007 17:39:01.442809  5078 net.cpp:406] BatchNorm4 <- Convolution4
I1007 17:39:01.442814  5078 net.cpp:367] BatchNorm4 -> Convolution4 (in-place)
I1007 17:39:01.442960  5078 net.cpp:122] Setting up BatchNorm4
I1007 17:39:01.442965  5078 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 17:39:01.442967  5078 net.cpp:137] Memory required for data: 125748400
I1007 17:39:01.442975  5078 layer_factory.hpp:77] Creating layer Scale4
I1007 17:39:01.442979  5078 net.cpp:84] Creating Layer Scale4
I1007 17:39:01.442981  5078 net.cpp:406] Scale4 <- Convolution4
I1007 17:39:01.442986  5078 net.cpp:367] Scale4 -> Convolution4 (in-place)
I1007 17:39:01.443015  5078 layer_factory.hpp:77] Creating layer Scale4
I1007 17:39:01.443095  5078 net.cpp:122] Setting up Scale4
I1007 17:39:01.443100  5078 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 17:39:01.443102  5078 net.cpp:137] Memory required for data: 132302000
I1007 17:39:01.443106  5078 layer_factory.hpp:77] Creating layer penlu4
I1007 17:39:01.443111  5078 net.cpp:84] Creating Layer penlu4
I1007 17:39:01.443114  5078 net.cpp:406] penlu4 <- Convolution4
I1007 17:39:01.443119  5078 net.cpp:367] penlu4 -> Convolution4 (in-place)
I1007 17:39:01.443250  5078 net.cpp:122] Setting up penlu4
I1007 17:39:01.443264  5078 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 17:39:01.443265  5078 net.cpp:137] Memory required for data: 138855600
I1007 17:39:01.443270  5078 layer_factory.hpp:77] Creating layer Convolution5
I1007 17:39:01.443277  5078 net.cpp:84] Creating Layer Convolution5
I1007 17:39:01.443281  5078 net.cpp:406] Convolution5 <- Convolution4
I1007 17:39:01.443287  5078 net.cpp:380] Convolution5 -> Convolution5
I1007 17:39:01.444288  5078 net.cpp:122] Setting up Convolution5
I1007 17:39:01.444298  5078 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 17:39:01.444299  5078 net.cpp:137] Memory required for data: 145409200
I1007 17:39:01.444305  5078 layer_factory.hpp:77] Creating layer BatchNorm5
I1007 17:39:01.444310  5078 net.cpp:84] Creating Layer BatchNorm5
I1007 17:39:01.444314  5078 net.cpp:406] BatchNorm5 <- Convolution5
I1007 17:39:01.444317  5078 net.cpp:367] BatchNorm5 -> Convolution5 (in-place)
I1007 17:39:01.444463  5078 net.cpp:122] Setting up BatchNorm5
I1007 17:39:01.444466  5078 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 17:39:01.444469  5078 net.cpp:137] Memory required for data: 151962800
I1007 17:39:01.444474  5078 layer_factory.hpp:77] Creating layer Scale5
I1007 17:39:01.444479  5078 net.cpp:84] Creating Layer Scale5
I1007 17:39:01.444481  5078 net.cpp:406] Scale5 <- Convolution5
I1007 17:39:01.444485  5078 net.cpp:367] Scale5 -> Convolution5 (in-place)
I1007 17:39:01.444514  5078 layer_factory.hpp:77] Creating layer Scale5
I1007 17:39:01.444602  5078 net.cpp:122] Setting up Scale5
I1007 17:39:01.444605  5078 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 17:39:01.444607  5078 net.cpp:137] Memory required for data: 158516400
I1007 17:39:01.444612  5078 layer_factory.hpp:77] Creating layer Eltwise2
I1007 17:39:01.444615  5078 net.cpp:84] Creating Layer Eltwise2
I1007 17:39:01.444618  5078 net.cpp:406] Eltwise2 <- Eltwise1_penlu3_0_split_1
I1007 17:39:01.444622  5078 net.cpp:406] Eltwise2 <- Convolution5
I1007 17:39:01.444625  5078 net.cpp:380] Eltwise2 -> Eltwise2
I1007 17:39:01.444640  5078 net.cpp:122] Setting up Eltwise2
I1007 17:39:01.444645  5078 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 17:39:01.444648  5078 net.cpp:137] Memory required for data: 165070000
I1007 17:39:01.444649  5078 layer_factory.hpp:77] Creating layer penlu5
I1007 17:39:01.444654  5078 net.cpp:84] Creating Layer penlu5
I1007 17:39:01.444656  5078 net.cpp:406] penlu5 <- Eltwise2
I1007 17:39:01.444660  5078 net.cpp:367] penlu5 -> Eltwise2 (in-place)
I1007 17:39:01.444782  5078 net.cpp:122] Setting up penlu5
I1007 17:39:01.444787  5078 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 17:39:01.444788  5078 net.cpp:137] Memory required for data: 171623600
I1007 17:39:01.444792  5078 layer_factory.hpp:77] Creating layer Eltwise2_penlu5_0_split
I1007 17:39:01.444797  5078 net.cpp:84] Creating Layer Eltwise2_penlu5_0_split
I1007 17:39:01.444798  5078 net.cpp:406] Eltwise2_penlu5_0_split <- Eltwise2
I1007 17:39:01.444802  5078 net.cpp:380] Eltwise2_penlu5_0_split -> Eltwise2_penlu5_0_split_0
I1007 17:39:01.444806  5078 net.cpp:380] Eltwise2_penlu5_0_split -> Eltwise2_penlu5_0_split_1
I1007 17:39:01.444833  5078 net.cpp:122] Setting up Eltwise2_penlu5_0_split
I1007 17:39:01.444835  5078 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 17:39:01.444839  5078 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 17:39:01.444841  5078 net.cpp:137] Memory required for data: 184730800
I1007 17:39:01.444844  5078 layer_factory.hpp:77] Creating layer Convolution6
I1007 17:39:01.444850  5078 net.cpp:84] Creating Layer Convolution6
I1007 17:39:01.444852  5078 net.cpp:406] Convolution6 <- Eltwise2_penlu5_0_split_0
I1007 17:39:01.444856  5078 net.cpp:380] Convolution6 -> Convolution6
I1007 17:39:01.445788  5078 net.cpp:122] Setting up Convolution6
I1007 17:39:01.445798  5078 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 17:39:01.445801  5078 net.cpp:137] Memory required for data: 191284400
I1007 17:39:01.445806  5078 layer_factory.hpp:77] Creating layer BatchNorm6
I1007 17:39:01.445816  5078 net.cpp:84] Creating Layer BatchNorm6
I1007 17:39:01.445819  5078 net.cpp:406] BatchNorm6 <- Convolution6
I1007 17:39:01.445823  5078 net.cpp:367] BatchNorm6 -> Convolution6 (in-place)
I1007 17:39:01.445968  5078 net.cpp:122] Setting up BatchNorm6
I1007 17:39:01.445972  5078 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 17:39:01.445974  5078 net.cpp:137] Memory required for data: 197838000
I1007 17:39:01.445979  5078 layer_factory.hpp:77] Creating layer Scale6
I1007 17:39:01.445983  5078 net.cpp:84] Creating Layer Scale6
I1007 17:39:01.445986  5078 net.cpp:406] Scale6 <- Convolution6
I1007 17:39:01.462249  5078 net.cpp:367] Scale6 -> Convolution6 (in-place)
I1007 17:39:01.462311  5078 layer_factory.hpp:77] Creating layer Scale6
I1007 17:39:01.462409  5078 net.cpp:122] Setting up Scale6
I1007 17:39:01.462415  5078 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 17:39:01.462419  5078 net.cpp:137] Memory required for data: 204391600
I1007 17:39:01.462424  5078 layer_factory.hpp:77] Creating layer penlu6
I1007 17:39:01.462430  5078 net.cpp:84] Creating Layer penlu6
I1007 17:39:01.462432  5078 net.cpp:406] penlu6 <- Convolution6
I1007 17:39:01.462435  5078 net.cpp:367] penlu6 -> Convolution6 (in-place)
I1007 17:39:01.462568  5078 net.cpp:122] Setting up penlu6
I1007 17:39:01.462574  5078 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 17:39:01.462575  5078 net.cpp:137] Memory required for data: 210945200
I1007 17:39:01.462580  5078 layer_factory.hpp:77] Creating layer Convolution7
I1007 17:39:01.462589  5078 net.cpp:84] Creating Layer Convolution7
I1007 17:39:01.462591  5078 net.cpp:406] Convolution7 <- Convolution6
I1007 17:39:01.462595  5078 net.cpp:380] Convolution7 -> Convolution7
I1007 17:39:01.463636  5078 net.cpp:122] Setting up Convolution7
I1007 17:39:01.463646  5078 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 17:39:01.463649  5078 net.cpp:137] Memory required for data: 217498800
I1007 17:39:01.463654  5078 layer_factory.hpp:77] Creating layer BatchNorm7
I1007 17:39:01.463662  5078 net.cpp:84] Creating Layer BatchNorm7
I1007 17:39:01.463665  5078 net.cpp:406] BatchNorm7 <- Convolution7
I1007 17:39:01.463670  5078 net.cpp:367] BatchNorm7 -> Convolution7 (in-place)
I1007 17:39:01.463855  5078 net.cpp:122] Setting up BatchNorm7
I1007 17:39:01.463863  5078 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 17:39:01.463865  5078 net.cpp:137] Memory required for data: 224052400
I1007 17:39:01.463877  5078 layer_factory.hpp:77] Creating layer Scale7
I1007 17:39:01.463884  5078 net.cpp:84] Creating Layer Scale7
I1007 17:39:01.463887  5078 net.cpp:406] Scale7 <- Convolution7
I1007 17:39:01.463891  5078 net.cpp:367] Scale7 -> Convolution7 (in-place)
I1007 17:39:01.463932  5078 layer_factory.hpp:77] Creating layer Scale7
I1007 17:39:01.464026  5078 net.cpp:122] Setting up Scale7
I1007 17:39:01.464031  5078 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 17:39:01.464033  5078 net.cpp:137] Memory required for data: 230606000
I1007 17:39:01.464037  5078 layer_factory.hpp:77] Creating layer Eltwise3
I1007 17:39:01.464041  5078 net.cpp:84] Creating Layer Eltwise3
I1007 17:39:01.464045  5078 net.cpp:406] Eltwise3 <- Eltwise2_penlu5_0_split_1
I1007 17:39:01.464047  5078 net.cpp:406] Eltwise3 <- Convolution7
I1007 17:39:01.464051  5078 net.cpp:380] Eltwise3 -> Eltwise3
I1007 17:39:01.464067  5078 net.cpp:122] Setting up Eltwise3
I1007 17:39:01.464071  5078 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 17:39:01.464073  5078 net.cpp:137] Memory required for data: 237159600
I1007 17:39:01.464076  5078 layer_factory.hpp:77] Creating layer penlu7
I1007 17:39:01.464081  5078 net.cpp:84] Creating Layer penlu7
I1007 17:39:01.464082  5078 net.cpp:406] penlu7 <- Eltwise3
I1007 17:39:01.464087  5078 net.cpp:367] penlu7 -> Eltwise3 (in-place)
I1007 17:39:01.464207  5078 net.cpp:122] Setting up penlu7
I1007 17:39:01.464211  5078 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 17:39:01.464213  5078 net.cpp:137] Memory required for data: 243713200
I1007 17:39:01.464226  5078 layer_factory.hpp:77] Creating layer Eltwise3_penlu7_0_split
I1007 17:39:01.464229  5078 net.cpp:84] Creating Layer Eltwise3_penlu7_0_split
I1007 17:39:01.464231  5078 net.cpp:406] Eltwise3_penlu7_0_split <- Eltwise3
I1007 17:39:01.464236  5078 net.cpp:380] Eltwise3_penlu7_0_split -> Eltwise3_penlu7_0_split_0
I1007 17:39:01.464239  5078 net.cpp:380] Eltwise3_penlu7_0_split -> Eltwise3_penlu7_0_split_1
I1007 17:39:01.464265  5078 net.cpp:122] Setting up Eltwise3_penlu7_0_split
I1007 17:39:01.464269  5078 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 17:39:01.464272  5078 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 17:39:01.464274  5078 net.cpp:137] Memory required for data: 256820400
I1007 17:39:01.464277  5078 layer_factory.hpp:77] Creating layer Convolution8
I1007 17:39:01.464283  5078 net.cpp:84] Creating Layer Convolution8
I1007 17:39:01.464287  5078 net.cpp:406] Convolution8 <- Eltwise3_penlu7_0_split_0
I1007 17:39:01.464290  5078 net.cpp:380] Convolution8 -> Convolution8
I1007 17:39:01.465322  5078 net.cpp:122] Setting up Convolution8
I1007 17:39:01.465330  5078 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 17:39:01.465333  5078 net.cpp:137] Memory required for data: 263374000
I1007 17:39:01.465337  5078 layer_factory.hpp:77] Creating layer BatchNorm8
I1007 17:39:01.465344  5078 net.cpp:84] Creating Layer BatchNorm8
I1007 17:39:01.465346  5078 net.cpp:406] BatchNorm8 <- Convolution8
I1007 17:39:01.465350  5078 net.cpp:367] BatchNorm8 -> Convolution8 (in-place)
I1007 17:39:01.465495  5078 net.cpp:122] Setting up BatchNorm8
I1007 17:39:01.465500  5078 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 17:39:01.465502  5078 net.cpp:137] Memory required for data: 269927600
I1007 17:39:01.465507  5078 layer_factory.hpp:77] Creating layer Scale8
I1007 17:39:01.465512  5078 net.cpp:84] Creating Layer Scale8
I1007 17:39:01.465514  5078 net.cpp:406] Scale8 <- Convolution8
I1007 17:39:01.465517  5078 net.cpp:367] Scale8 -> Convolution8 (in-place)
I1007 17:39:01.465548  5078 layer_factory.hpp:77] Creating layer Scale8
I1007 17:39:01.465631  5078 net.cpp:122] Setting up Scale8
I1007 17:39:01.465634  5078 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 17:39:01.465636  5078 net.cpp:137] Memory required for data: 276481200
I1007 17:39:01.465641  5078 layer_factory.hpp:77] Creating layer penlu8
I1007 17:39:01.465646  5078 net.cpp:84] Creating Layer penlu8
I1007 17:39:01.465649  5078 net.cpp:406] penlu8 <- Convolution8
I1007 17:39:01.465653  5078 net.cpp:367] penlu8 -> Convolution8 (in-place)
I1007 17:39:01.465777  5078 net.cpp:122] Setting up penlu8
I1007 17:39:01.465782  5078 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 17:39:01.465785  5078 net.cpp:137] Memory required for data: 283034800
I1007 17:39:01.465788  5078 layer_factory.hpp:77] Creating layer Convolution9
I1007 17:39:01.465795  5078 net.cpp:84] Creating Layer Convolution9
I1007 17:39:01.465798  5078 net.cpp:406] Convolution9 <- Convolution8
I1007 17:39:01.465802  5078 net.cpp:380] Convolution9 -> Convolution9
I1007 17:39:01.467191  5078 net.cpp:122] Setting up Convolution9
I1007 17:39:01.467209  5078 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 17:39:01.467212  5078 net.cpp:137] Memory required for data: 289588400
I1007 17:39:01.467216  5078 layer_factory.hpp:77] Creating layer BatchNorm9
I1007 17:39:01.467221  5078 net.cpp:84] Creating Layer BatchNorm9
I1007 17:39:01.467224  5078 net.cpp:406] BatchNorm9 <- Convolution9
I1007 17:39:01.467228  5078 net.cpp:367] BatchNorm9 -> Convolution9 (in-place)
I1007 17:39:01.467367  5078 net.cpp:122] Setting up BatchNorm9
I1007 17:39:01.467371  5078 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 17:39:01.467373  5078 net.cpp:137] Memory required for data: 296142000
I1007 17:39:01.467378  5078 layer_factory.hpp:77] Creating layer Scale9
I1007 17:39:01.467382  5078 net.cpp:84] Creating Layer Scale9
I1007 17:39:01.467386  5078 net.cpp:406] Scale9 <- Convolution9
I1007 17:39:01.467388  5078 net.cpp:367] Scale9 -> Convolution9 (in-place)
I1007 17:39:01.467417  5078 layer_factory.hpp:77] Creating layer Scale9
I1007 17:39:01.467505  5078 net.cpp:122] Setting up Scale9
I1007 17:39:01.467510  5078 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 17:39:01.467512  5078 net.cpp:137] Memory required for data: 302695600
I1007 17:39:01.467516  5078 layer_factory.hpp:77] Creating layer Eltwise4
I1007 17:39:01.467520  5078 net.cpp:84] Creating Layer Eltwise4
I1007 17:39:01.467522  5078 net.cpp:406] Eltwise4 <- Eltwise3_penlu7_0_split_1
I1007 17:39:01.467525  5078 net.cpp:406] Eltwise4 <- Convolution9
I1007 17:39:01.467530  5078 net.cpp:380] Eltwise4 -> Eltwise4
I1007 17:39:01.467545  5078 net.cpp:122] Setting up Eltwise4
I1007 17:39:01.467550  5078 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 17:39:01.467551  5078 net.cpp:137] Memory required for data: 309249200
I1007 17:39:01.467553  5078 layer_factory.hpp:77] Creating layer penlu9
I1007 17:39:01.467557  5078 net.cpp:84] Creating Layer penlu9
I1007 17:39:01.467561  5078 net.cpp:406] penlu9 <- Eltwise4
I1007 17:39:01.467564  5078 net.cpp:367] penlu9 -> Eltwise4 (in-place)
I1007 17:39:01.467684  5078 net.cpp:122] Setting up penlu9
I1007 17:39:01.467689  5078 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 17:39:01.467690  5078 net.cpp:137] Memory required for data: 315802800
I1007 17:39:01.467694  5078 layer_factory.hpp:77] Creating layer Eltwise4_penlu9_0_split
I1007 17:39:01.467699  5078 net.cpp:84] Creating Layer Eltwise4_penlu9_0_split
I1007 17:39:01.467700  5078 net.cpp:406] Eltwise4_penlu9_0_split <- Eltwise4
I1007 17:39:01.467703  5078 net.cpp:380] Eltwise4_penlu9_0_split -> Eltwise4_penlu9_0_split_0
I1007 17:39:01.467707  5078 net.cpp:380] Eltwise4_penlu9_0_split -> Eltwise4_penlu9_0_split_1
I1007 17:39:01.467731  5078 net.cpp:122] Setting up Eltwise4_penlu9_0_split
I1007 17:39:01.467734  5078 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 17:39:01.467737  5078 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 17:39:01.467739  5078 net.cpp:137] Memory required for data: 328910000
I1007 17:39:01.467741  5078 layer_factory.hpp:77] Creating layer Convolution10
I1007 17:39:01.467747  5078 net.cpp:84] Creating Layer Convolution10
I1007 17:39:01.467751  5078 net.cpp:406] Convolution10 <- Eltwise4_penlu9_0_split_0
I1007 17:39:01.467753  5078 net.cpp:380] Convolution10 -> Convolution10
I1007 17:39:01.468328  5078 net.cpp:122] Setting up Convolution10
I1007 17:39:01.468335  5078 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 17:39:01.468338  5078 net.cpp:137] Memory required for data: 335463600
I1007 17:39:01.468343  5078 layer_factory.hpp:77] Creating layer BatchNorm10
I1007 17:39:01.468348  5078 net.cpp:84] Creating Layer BatchNorm10
I1007 17:39:01.468349  5078 net.cpp:406] BatchNorm10 <- Convolution10
I1007 17:39:01.468353  5078 net.cpp:367] BatchNorm10 -> Convolution10 (in-place)
I1007 17:39:01.468490  5078 net.cpp:122] Setting up BatchNorm10
I1007 17:39:01.468494  5078 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 17:39:01.468497  5078 net.cpp:137] Memory required for data: 342017200
I1007 17:39:01.468502  5078 layer_factory.hpp:77] Creating layer Scale10
I1007 17:39:01.468505  5078 net.cpp:84] Creating Layer Scale10
I1007 17:39:01.468508  5078 net.cpp:406] Scale10 <- Convolution10
I1007 17:39:01.468511  5078 net.cpp:367] Scale10 -> Convolution10 (in-place)
I1007 17:39:01.468538  5078 layer_factory.hpp:77] Creating layer Scale10
I1007 17:39:01.468616  5078 net.cpp:122] Setting up Scale10
I1007 17:39:01.468619  5078 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 17:39:01.468622  5078 net.cpp:137] Memory required for data: 348570800
I1007 17:39:01.468626  5078 layer_factory.hpp:77] Creating layer penlu10
I1007 17:39:01.468631  5078 net.cpp:84] Creating Layer penlu10
I1007 17:39:01.468632  5078 net.cpp:406] penlu10 <- Convolution10
I1007 17:39:01.468636  5078 net.cpp:367] penlu10 -> Convolution10 (in-place)
I1007 17:39:01.468755  5078 net.cpp:122] Setting up penlu10
I1007 17:39:01.468758  5078 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 17:39:01.468760  5078 net.cpp:137] Memory required for data: 355124400
I1007 17:39:01.468770  5078 layer_factory.hpp:77] Creating layer Convolution11
I1007 17:39:01.468777  5078 net.cpp:84] Creating Layer Convolution11
I1007 17:39:01.468780  5078 net.cpp:406] Convolution11 <- Convolution10
I1007 17:39:01.468783  5078 net.cpp:380] Convolution11 -> Convolution11
I1007 17:39:01.469686  5078 net.cpp:122] Setting up Convolution11
I1007 17:39:01.469693  5078 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 17:39:01.469696  5078 net.cpp:137] Memory required for data: 361678000
I1007 17:39:01.469700  5078 layer_factory.hpp:77] Creating layer BatchNorm11
I1007 17:39:01.469705  5078 net.cpp:84] Creating Layer BatchNorm11
I1007 17:39:01.469708  5078 net.cpp:406] BatchNorm11 <- Convolution11
I1007 17:39:01.469712  5078 net.cpp:367] BatchNorm11 -> Convolution11 (in-place)
I1007 17:39:01.469851  5078 net.cpp:122] Setting up BatchNorm11
I1007 17:39:01.469856  5078 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 17:39:01.469857  5078 net.cpp:137] Memory required for data: 368231600
I1007 17:39:01.469862  5078 layer_factory.hpp:77] Creating layer Scale11
I1007 17:39:01.469866  5078 net.cpp:84] Creating Layer Scale11
I1007 17:39:01.469869  5078 net.cpp:406] Scale11 <- Convolution11
I1007 17:39:01.469872  5078 net.cpp:367] Scale11 -> Convolution11 (in-place)
I1007 17:39:01.469899  5078 layer_factory.hpp:77] Creating layer Scale11
I1007 17:39:01.469977  5078 net.cpp:122] Setting up Scale11
I1007 17:39:01.469981  5078 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 17:39:01.469983  5078 net.cpp:137] Memory required for data: 374785200
I1007 17:39:01.469987  5078 layer_factory.hpp:77] Creating layer Eltwise5
I1007 17:39:01.469991  5078 net.cpp:84] Creating Layer Eltwise5
I1007 17:39:01.469995  5078 net.cpp:406] Eltwise5 <- Eltwise4_penlu9_0_split_1
I1007 17:39:01.469996  5078 net.cpp:406] Eltwise5 <- Convolution11
I1007 17:39:01.470000  5078 net.cpp:380] Eltwise5 -> Eltwise5
I1007 17:39:01.470016  5078 net.cpp:122] Setting up Eltwise5
I1007 17:39:01.470019  5078 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 17:39:01.470021  5078 net.cpp:137] Memory required for data: 381338800
I1007 17:39:01.470023  5078 layer_factory.hpp:77] Creating layer penlu11
I1007 17:39:01.470028  5078 net.cpp:84] Creating Layer penlu11
I1007 17:39:01.470031  5078 net.cpp:406] penlu11 <- Eltwise5
I1007 17:39:01.470034  5078 net.cpp:367] penlu11 -> Eltwise5 (in-place)
I1007 17:39:01.470151  5078 net.cpp:122] Setting up penlu11
I1007 17:39:01.470155  5078 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 17:39:01.470157  5078 net.cpp:137] Memory required for data: 387892400
I1007 17:39:01.470161  5078 layer_factory.hpp:77] Creating layer Eltwise5_penlu11_0_split
I1007 17:39:01.470165  5078 net.cpp:84] Creating Layer Eltwise5_penlu11_0_split
I1007 17:39:01.470167  5078 net.cpp:406] Eltwise5_penlu11_0_split <- Eltwise5
I1007 17:39:01.470170  5078 net.cpp:380] Eltwise5_penlu11_0_split -> Eltwise5_penlu11_0_split_0
I1007 17:39:01.470175  5078 net.cpp:380] Eltwise5_penlu11_0_split -> Eltwise5_penlu11_0_split_1
I1007 17:39:01.470197  5078 net.cpp:122] Setting up Eltwise5_penlu11_0_split
I1007 17:39:01.470201  5078 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 17:39:01.470204  5078 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 17:39:01.470206  5078 net.cpp:137] Memory required for data: 400999600
I1007 17:39:01.470208  5078 layer_factory.hpp:77] Creating layer Convolution12
I1007 17:39:01.470214  5078 net.cpp:84] Creating Layer Convolution12
I1007 17:39:01.470217  5078 net.cpp:406] Convolution12 <- Eltwise5_penlu11_0_split_0
I1007 17:39:01.470221  5078 net.cpp:380] Convolution12 -> Convolution12
I1007 17:39:01.471098  5078 net.cpp:122] Setting up Convolution12
I1007 17:39:01.471107  5078 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 17:39:01.471109  5078 net.cpp:137] Memory required for data: 404276400
I1007 17:39:01.471113  5078 layer_factory.hpp:77] Creating layer BatchNorm12
I1007 17:39:01.471118  5078 net.cpp:84] Creating Layer BatchNorm12
I1007 17:39:01.471122  5078 net.cpp:406] BatchNorm12 <- Convolution12
I1007 17:39:01.471132  5078 net.cpp:367] BatchNorm12 -> Convolution12 (in-place)
I1007 17:39:01.471295  5078 net.cpp:122] Setting up BatchNorm12
I1007 17:39:01.471300  5078 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 17:39:01.471302  5078 net.cpp:137] Memory required for data: 407553200
I1007 17:39:01.471307  5078 layer_factory.hpp:77] Creating layer Scale12
I1007 17:39:01.471312  5078 net.cpp:84] Creating Layer Scale12
I1007 17:39:01.471314  5078 net.cpp:406] Scale12 <- Convolution12
I1007 17:39:01.471318  5078 net.cpp:367] Scale12 -> Convolution12 (in-place)
I1007 17:39:01.492784  5078 layer_factory.hpp:77] Creating layer Scale12
I1007 17:39:01.492918  5078 net.cpp:122] Setting up Scale12
I1007 17:39:01.492925  5078 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 17:39:01.492930  5078 net.cpp:137] Memory required for data: 410830000
I1007 17:39:01.492938  5078 layer_factory.hpp:77] Creating layer Convolution13
I1007 17:39:01.492949  5078 net.cpp:84] Creating Layer Convolution13
I1007 17:39:01.492954  5078 net.cpp:406] Convolution13 <- Eltwise5_penlu11_0_split_1
I1007 17:39:01.492961  5078 net.cpp:380] Convolution13 -> Convolution13
I1007 17:39:01.494068  5078 net.cpp:122] Setting up Convolution13
I1007 17:39:01.494078  5078 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 17:39:01.494081  5078 net.cpp:137] Memory required for data: 414106800
I1007 17:39:01.494086  5078 layer_factory.hpp:77] Creating layer BatchNorm13
I1007 17:39:01.494092  5078 net.cpp:84] Creating Layer BatchNorm13
I1007 17:39:01.494096  5078 net.cpp:406] BatchNorm13 <- Convolution13
I1007 17:39:01.494099  5078 net.cpp:367] BatchNorm13 -> Convolution13 (in-place)
I1007 17:39:01.494279  5078 net.cpp:122] Setting up BatchNorm13
I1007 17:39:01.494287  5078 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 17:39:01.494289  5078 net.cpp:137] Memory required for data: 417383600
I1007 17:39:01.494295  5078 layer_factory.hpp:77] Creating layer Scale13
I1007 17:39:01.494300  5078 net.cpp:84] Creating Layer Scale13
I1007 17:39:01.494303  5078 net.cpp:406] Scale13 <- Convolution13
I1007 17:39:01.494307  5078 net.cpp:367] Scale13 -> Convolution13 (in-place)
I1007 17:39:01.494339  5078 layer_factory.hpp:77] Creating layer Scale13
I1007 17:39:01.494447  5078 net.cpp:122] Setting up Scale13
I1007 17:39:01.494451  5078 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 17:39:01.494454  5078 net.cpp:137] Memory required for data: 420660400
I1007 17:39:01.494457  5078 layer_factory.hpp:77] Creating layer penlu12
I1007 17:39:01.494463  5078 net.cpp:84] Creating Layer penlu12
I1007 17:39:01.494467  5078 net.cpp:406] penlu12 <- Convolution13
I1007 17:39:01.494470  5078 net.cpp:367] penlu12 -> Convolution13 (in-place)
I1007 17:39:01.494590  5078 net.cpp:122] Setting up penlu12
I1007 17:39:01.494593  5078 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 17:39:01.494596  5078 net.cpp:137] Memory required for data: 423937200
I1007 17:39:01.494601  5078 layer_factory.hpp:77] Creating layer Convolution14
I1007 17:39:01.494611  5078 net.cpp:84] Creating Layer Convolution14
I1007 17:39:01.494613  5078 net.cpp:406] Convolution14 <- Convolution13
I1007 17:39:01.494618  5078 net.cpp:380] Convolution14 -> Convolution14
I1007 17:39:01.495904  5078 net.cpp:122] Setting up Convolution14
I1007 17:39:01.495913  5078 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 17:39:01.495916  5078 net.cpp:137] Memory required for data: 427214000
I1007 17:39:01.495934  5078 layer_factory.hpp:77] Creating layer BatchNorm14
I1007 17:39:01.495939  5078 net.cpp:84] Creating Layer BatchNorm14
I1007 17:39:01.495940  5078 net.cpp:406] BatchNorm14 <- Convolution14
I1007 17:39:01.495945  5078 net.cpp:367] BatchNorm14 -> Convolution14 (in-place)
I1007 17:39:01.496093  5078 net.cpp:122] Setting up BatchNorm14
I1007 17:39:01.496098  5078 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 17:39:01.496099  5078 net.cpp:137] Memory required for data: 430490800
I1007 17:39:01.496104  5078 layer_factory.hpp:77] Creating layer Scale14
I1007 17:39:01.496109  5078 net.cpp:84] Creating Layer Scale14
I1007 17:39:01.496119  5078 net.cpp:406] Scale14 <- Convolution14
I1007 17:39:01.496122  5078 net.cpp:367] Scale14 -> Convolution14 (in-place)
I1007 17:39:01.496153  5078 layer_factory.hpp:77] Creating layer Scale14
I1007 17:39:01.496237  5078 net.cpp:122] Setting up Scale14
I1007 17:39:01.496242  5078 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 17:39:01.496244  5078 net.cpp:137] Memory required for data: 433767600
I1007 17:39:01.496248  5078 layer_factory.hpp:77] Creating layer Eltwise6
I1007 17:39:01.496253  5078 net.cpp:84] Creating Layer Eltwise6
I1007 17:39:01.496255  5078 net.cpp:406] Eltwise6 <- Convolution12
I1007 17:39:01.496258  5078 net.cpp:406] Eltwise6 <- Convolution14
I1007 17:39:01.496261  5078 net.cpp:380] Eltwise6 -> Eltwise6
I1007 17:39:01.496276  5078 net.cpp:122] Setting up Eltwise6
I1007 17:39:01.496280  5078 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 17:39:01.496282  5078 net.cpp:137] Memory required for data: 437044400
I1007 17:39:01.496284  5078 layer_factory.hpp:77] Creating layer penlu13
I1007 17:39:01.496289  5078 net.cpp:84] Creating Layer penlu13
I1007 17:39:01.496291  5078 net.cpp:406] penlu13 <- Eltwise6
I1007 17:39:01.496296  5078 net.cpp:367] penlu13 -> Eltwise6 (in-place)
I1007 17:39:01.496420  5078 net.cpp:122] Setting up penlu13
I1007 17:39:01.496424  5078 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 17:39:01.496428  5078 net.cpp:137] Memory required for data: 440321200
I1007 17:39:01.496431  5078 layer_factory.hpp:77] Creating layer Eltwise6_penlu13_0_split
I1007 17:39:01.496435  5078 net.cpp:84] Creating Layer Eltwise6_penlu13_0_split
I1007 17:39:01.496438  5078 net.cpp:406] Eltwise6_penlu13_0_split <- Eltwise6
I1007 17:39:01.496440  5078 net.cpp:380] Eltwise6_penlu13_0_split -> Eltwise6_penlu13_0_split_0
I1007 17:39:01.496444  5078 net.cpp:380] Eltwise6_penlu13_0_split -> Eltwise6_penlu13_0_split_1
I1007 17:39:01.496470  5078 net.cpp:122] Setting up Eltwise6_penlu13_0_split
I1007 17:39:01.496474  5078 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 17:39:01.496477  5078 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 17:39:01.496479  5078 net.cpp:137] Memory required for data: 446874800
I1007 17:39:01.496481  5078 layer_factory.hpp:77] Creating layer Convolution15
I1007 17:39:01.496489  5078 net.cpp:84] Creating Layer Convolution15
I1007 17:39:01.496490  5078 net.cpp:406] Convolution15 <- Eltwise6_penlu13_0_split_0
I1007 17:39:01.496495  5078 net.cpp:380] Convolution15 -> Convolution15
I1007 17:39:01.497949  5078 net.cpp:122] Setting up Convolution15
I1007 17:39:01.497958  5078 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 17:39:01.497961  5078 net.cpp:137] Memory required for data: 450151600
I1007 17:39:01.497965  5078 layer_factory.hpp:77] Creating layer BatchNorm15
I1007 17:39:01.497972  5078 net.cpp:84] Creating Layer BatchNorm15
I1007 17:39:01.497974  5078 net.cpp:406] BatchNorm15 <- Convolution15
I1007 17:39:01.497977  5078 net.cpp:367] BatchNorm15 -> Convolution15 (in-place)
I1007 17:39:01.498127  5078 net.cpp:122] Setting up BatchNorm15
I1007 17:39:01.498132  5078 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 17:39:01.498134  5078 net.cpp:137] Memory required for data: 453428400
I1007 17:39:01.498139  5078 layer_factory.hpp:77] Creating layer Scale15
I1007 17:39:01.498145  5078 net.cpp:84] Creating Layer Scale15
I1007 17:39:01.498148  5078 net.cpp:406] Scale15 <- Convolution15
I1007 17:39:01.498152  5078 net.cpp:367] Scale15 -> Convolution15 (in-place)
I1007 17:39:01.498183  5078 layer_factory.hpp:77] Creating layer Scale15
I1007 17:39:01.498266  5078 net.cpp:122] Setting up Scale15
I1007 17:39:01.498270  5078 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 17:39:01.498272  5078 net.cpp:137] Memory required for data: 456705200
I1007 17:39:01.498276  5078 layer_factory.hpp:77] Creating layer penlu14
I1007 17:39:01.498282  5078 net.cpp:84] Creating Layer penlu14
I1007 17:39:01.498286  5078 net.cpp:406] penlu14 <- Convolution15
I1007 17:39:01.498289  5078 net.cpp:367] penlu14 -> Convolution15 (in-place)
I1007 17:39:01.498416  5078 net.cpp:122] Setting up penlu14
I1007 17:39:01.498421  5078 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 17:39:01.498423  5078 net.cpp:137] Memory required for data: 459982000
I1007 17:39:01.498427  5078 layer_factory.hpp:77] Creating layer Convolution16
I1007 17:39:01.498435  5078 net.cpp:84] Creating Layer Convolution16
I1007 17:39:01.498437  5078 net.cpp:406] Convolution16 <- Convolution15
I1007 17:39:01.498441  5078 net.cpp:380] Convolution16 -> Convolution16
I1007 17:39:01.500108  5078 net.cpp:122] Setting up Convolution16
I1007 17:39:01.500118  5078 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 17:39:01.500120  5078 net.cpp:137] Memory required for data: 463258800
I1007 17:39:01.500125  5078 layer_factory.hpp:77] Creating layer BatchNorm16
I1007 17:39:01.500131  5078 net.cpp:84] Creating Layer BatchNorm16
I1007 17:39:01.500134  5078 net.cpp:406] BatchNorm16 <- Convolution16
I1007 17:39:01.500138  5078 net.cpp:367] BatchNorm16 -> Convolution16 (in-place)
I1007 17:39:01.500284  5078 net.cpp:122] Setting up BatchNorm16
I1007 17:39:01.500289  5078 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 17:39:01.500291  5078 net.cpp:137] Memory required for data: 466535600
I1007 17:39:01.500296  5078 layer_factory.hpp:77] Creating layer Scale16
I1007 17:39:01.500301  5078 net.cpp:84] Creating Layer Scale16
I1007 17:39:01.500303  5078 net.cpp:406] Scale16 <- Convolution16
I1007 17:39:01.500306  5078 net.cpp:367] Scale16 -> Convolution16 (in-place)
I1007 17:39:01.500336  5078 layer_factory.hpp:77] Creating layer Scale16
I1007 17:39:01.500421  5078 net.cpp:122] Setting up Scale16
I1007 17:39:01.500424  5078 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 17:39:01.500427  5078 net.cpp:137] Memory required for data: 469812400
I1007 17:39:01.500430  5078 layer_factory.hpp:77] Creating layer Eltwise7
I1007 17:39:01.500434  5078 net.cpp:84] Creating Layer Eltwise7
I1007 17:39:01.500437  5078 net.cpp:406] Eltwise7 <- Eltwise6_penlu13_0_split_1
I1007 17:39:01.500440  5078 net.cpp:406] Eltwise7 <- Convolution16
I1007 17:39:01.500444  5078 net.cpp:380] Eltwise7 -> Eltwise7
I1007 17:39:01.500458  5078 net.cpp:122] Setting up Eltwise7
I1007 17:39:01.500461  5078 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 17:39:01.500463  5078 net.cpp:137] Memory required for data: 473089200
I1007 17:39:01.500465  5078 layer_factory.hpp:77] Creating layer penlu15
I1007 17:39:01.500470  5078 net.cpp:84] Creating Layer penlu15
I1007 17:39:01.500473  5078 net.cpp:406] penlu15 <- Eltwise7
I1007 17:39:01.500478  5078 net.cpp:367] penlu15 -> Eltwise7 (in-place)
I1007 17:39:01.500599  5078 net.cpp:122] Setting up penlu15
I1007 17:39:01.500604  5078 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 17:39:01.500607  5078 net.cpp:137] Memory required for data: 476366000
I1007 17:39:01.500612  5078 layer_factory.hpp:77] Creating layer Eltwise7_penlu15_0_split
I1007 17:39:01.500614  5078 net.cpp:84] Creating Layer Eltwise7_penlu15_0_split
I1007 17:39:01.500617  5078 net.cpp:406] Eltwise7_penlu15_0_split <- Eltwise7
I1007 17:39:01.500620  5078 net.cpp:380] Eltwise7_penlu15_0_split -> Eltwise7_penlu15_0_split_0
I1007 17:39:01.500624  5078 net.cpp:380] Eltwise7_penlu15_0_split -> Eltwise7_penlu15_0_split_1
I1007 17:39:01.500650  5078 net.cpp:122] Setting up Eltwise7_penlu15_0_split
I1007 17:39:01.500654  5078 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 17:39:01.500658  5078 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 17:39:01.500659  5078 net.cpp:137] Memory required for data: 482919600
I1007 17:39:01.500661  5078 layer_factory.hpp:77] Creating layer Convolution17
I1007 17:39:01.500668  5078 net.cpp:84] Creating Layer Convolution17
I1007 17:39:01.500670  5078 net.cpp:406] Convolution17 <- Eltwise7_penlu15_0_split_0
I1007 17:39:01.500674  5078 net.cpp:380] Convolution17 -> Convolution17
I1007 17:39:01.501791  5078 net.cpp:122] Setting up Convolution17
I1007 17:39:01.501801  5078 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 17:39:01.501804  5078 net.cpp:137] Memory required for data: 486196400
I1007 17:39:01.501816  5078 layer_factory.hpp:77] Creating layer BatchNorm17
I1007 17:39:01.501821  5078 net.cpp:84] Creating Layer BatchNorm17
I1007 17:39:01.501823  5078 net.cpp:406] BatchNorm17 <- Convolution17
I1007 17:39:01.501828  5078 net.cpp:367] BatchNorm17 -> Convolution17 (in-place)
I1007 17:39:01.501976  5078 net.cpp:122] Setting up BatchNorm17
I1007 17:39:01.501981  5078 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 17:39:01.501983  5078 net.cpp:137] Memory required for data: 489473200
I1007 17:39:01.501988  5078 layer_factory.hpp:77] Creating layer Scale17
I1007 17:39:01.501992  5078 net.cpp:84] Creating Layer Scale17
I1007 17:39:01.501996  5078 net.cpp:406] Scale17 <- Convolution17
I1007 17:39:01.501998  5078 net.cpp:367] Scale17 -> Convolution17 (in-place)
I1007 17:39:01.502028  5078 layer_factory.hpp:77] Creating layer Scale17
I1007 17:39:01.502112  5078 net.cpp:122] Setting up Scale17
I1007 17:39:01.502116  5078 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 17:39:01.502120  5078 net.cpp:137] Memory required for data: 492750000
I1007 17:39:01.502123  5078 layer_factory.hpp:77] Creating layer penlu16
I1007 17:39:01.502130  5078 net.cpp:84] Creating Layer penlu16
I1007 17:39:01.502131  5078 net.cpp:406] penlu16 <- Convolution17
I1007 17:39:01.502135  5078 net.cpp:367] penlu16 -> Convolution17 (in-place)
I1007 17:39:01.502252  5078 net.cpp:122] Setting up penlu16
I1007 17:39:01.502257  5078 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 17:39:01.502259  5078 net.cpp:137] Memory required for data: 496026800
I1007 17:39:01.502264  5078 layer_factory.hpp:77] Creating layer Convolution18
I1007 17:39:01.502270  5078 net.cpp:84] Creating Layer Convolution18
I1007 17:39:01.502274  5078 net.cpp:406] Convolution18 <- Convolution17
I1007 17:39:01.502276  5078 net.cpp:380] Convolution18 -> Convolution18
I1007 17:39:01.503407  5078 net.cpp:122] Setting up Convolution18
I1007 17:39:01.503417  5078 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 17:39:01.503419  5078 net.cpp:137] Memory required for data: 499303600
I1007 17:39:01.503423  5078 layer_factory.hpp:77] Creating layer BatchNorm18
I1007 17:39:01.503429  5078 net.cpp:84] Creating Layer BatchNorm18
I1007 17:39:01.503432  5078 net.cpp:406] BatchNorm18 <- Convolution18
I1007 17:39:01.503435  5078 net.cpp:367] BatchNorm18 -> Convolution18 (in-place)
I1007 17:39:01.503582  5078 net.cpp:122] Setting up BatchNorm18
I1007 17:39:01.503587  5078 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 17:39:01.503589  5078 net.cpp:137] Memory required for data: 502580400
I1007 17:39:01.503593  5078 layer_factory.hpp:77] Creating layer Scale18
I1007 17:39:01.503597  5078 net.cpp:84] Creating Layer Scale18
I1007 17:39:01.503600  5078 net.cpp:406] Scale18 <- Convolution18
I1007 17:39:01.503603  5078 net.cpp:367] Scale18 -> Convolution18 (in-place)
I1007 17:39:01.503633  5078 layer_factory.hpp:77] Creating layer Scale18
I1007 17:39:01.503717  5078 net.cpp:122] Setting up Scale18
I1007 17:39:01.503722  5078 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 17:39:01.503724  5078 net.cpp:137] Memory required for data: 505857200
I1007 17:39:01.503728  5078 layer_factory.hpp:77] Creating layer Eltwise8
I1007 17:39:01.503732  5078 net.cpp:84] Creating Layer Eltwise8
I1007 17:39:01.503736  5078 net.cpp:406] Eltwise8 <- Eltwise7_penlu15_0_split_1
I1007 17:39:01.503738  5078 net.cpp:406] Eltwise8 <- Convolution18
I1007 17:39:01.503741  5078 net.cpp:380] Eltwise8 -> Eltwise8
I1007 17:39:01.503756  5078 net.cpp:122] Setting up Eltwise8
I1007 17:39:01.503759  5078 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 17:39:01.503762  5078 net.cpp:137] Memory required for data: 509134000
I1007 17:39:01.503763  5078 layer_factory.hpp:77] Creating layer penlu17
I1007 17:39:01.503768  5078 net.cpp:84] Creating Layer penlu17
I1007 17:39:01.503772  5078 net.cpp:406] penlu17 <- Eltwise8
I1007 17:39:01.503775  5078 net.cpp:367] penlu17 -> Eltwise8 (in-place)
I1007 17:39:01.503896  5078 net.cpp:122] Setting up penlu17
I1007 17:39:01.503901  5078 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 17:39:01.503909  5078 net.cpp:137] Memory required for data: 512410800
I1007 17:39:01.503914  5078 layer_factory.hpp:77] Creating layer Eltwise8_penlu17_0_split
I1007 17:39:01.503917  5078 net.cpp:84] Creating Layer Eltwise8_penlu17_0_split
I1007 17:39:01.503921  5078 net.cpp:406] Eltwise8_penlu17_0_split <- Eltwise8
I1007 17:39:01.503924  5078 net.cpp:380] Eltwise8_penlu17_0_split -> Eltwise8_penlu17_0_split_0
I1007 17:39:01.523115  5078 net.cpp:380] Eltwise8_penlu17_0_split -> Eltwise8_penlu17_0_split_1
I1007 17:39:01.523177  5078 net.cpp:122] Setting up Eltwise8_penlu17_0_split
I1007 17:39:01.523186  5078 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 17:39:01.523192  5078 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 17:39:01.523196  5078 net.cpp:137] Memory required for data: 518964400
I1007 17:39:01.523200  5078 layer_factory.hpp:77] Creating layer Convolution19
I1007 17:39:01.523212  5078 net.cpp:84] Creating Layer Convolution19
I1007 17:39:01.523217  5078 net.cpp:406] Convolution19 <- Eltwise8_penlu17_0_split_0
I1007 17:39:01.523224  5078 net.cpp:380] Convolution19 -> Convolution19
I1007 17:39:01.524485  5078 net.cpp:122] Setting up Convolution19
I1007 17:39:01.524498  5078 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 17:39:01.524503  5078 net.cpp:137] Memory required for data: 522241200
I1007 17:39:01.524511  5078 layer_factory.hpp:77] Creating layer BatchNorm19
I1007 17:39:01.524520  5078 net.cpp:84] Creating Layer BatchNorm19
I1007 17:39:01.524525  5078 net.cpp:406] BatchNorm19 <- Convolution19
I1007 17:39:01.524531  5078 net.cpp:367] BatchNorm19 -> Convolution19 (in-place)
I1007 17:39:01.524689  5078 net.cpp:122] Setting up BatchNorm19
I1007 17:39:01.524694  5078 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 17:39:01.524696  5078 net.cpp:137] Memory required for data: 525518000
I1007 17:39:01.524701  5078 layer_factory.hpp:77] Creating layer Scale19
I1007 17:39:01.524706  5078 net.cpp:84] Creating Layer Scale19
I1007 17:39:01.524709  5078 net.cpp:406] Scale19 <- Convolution19
I1007 17:39:01.524713  5078 net.cpp:367] Scale19 -> Convolution19 (in-place)
I1007 17:39:01.524744  5078 layer_factory.hpp:77] Creating layer Scale19
I1007 17:39:01.524853  5078 net.cpp:122] Setting up Scale19
I1007 17:39:01.524860  5078 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 17:39:01.524864  5078 net.cpp:137] Memory required for data: 528794800
I1007 17:39:01.524870  5078 layer_factory.hpp:77] Creating layer penlu18
I1007 17:39:01.524879  5078 net.cpp:84] Creating Layer penlu18
I1007 17:39:01.524884  5078 net.cpp:406] penlu18 <- Convolution19
I1007 17:39:01.524893  5078 net.cpp:367] penlu18 -> Convolution19 (in-place)
I1007 17:39:01.525059  5078 net.cpp:122] Setting up penlu18
I1007 17:39:01.525066  5078 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 17:39:01.525070  5078 net.cpp:137] Memory required for data: 532071600
I1007 17:39:01.525077  5078 layer_factory.hpp:77] Creating layer Convolution20
I1007 17:39:01.525086  5078 net.cpp:84] Creating Layer Convolution20
I1007 17:39:01.525090  5078 net.cpp:406] Convolution20 <- Convolution19
I1007 17:39:01.525097  5078 net.cpp:380] Convolution20 -> Convolution20
I1007 17:39:01.525898  5078 net.cpp:122] Setting up Convolution20
I1007 17:39:01.525907  5078 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 17:39:01.525918  5078 net.cpp:137] Memory required for data: 535348400
I1007 17:39:01.525923  5078 layer_factory.hpp:77] Creating layer BatchNorm20
I1007 17:39:01.525929  5078 net.cpp:84] Creating Layer BatchNorm20
I1007 17:39:01.525931  5078 net.cpp:406] BatchNorm20 <- Convolution20
I1007 17:39:01.525936  5078 net.cpp:367] BatchNorm20 -> Convolution20 (in-place)
I1007 17:39:01.526083  5078 net.cpp:122] Setting up BatchNorm20
I1007 17:39:01.526087  5078 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 17:39:01.526090  5078 net.cpp:137] Memory required for data: 538625200
I1007 17:39:01.526094  5078 layer_factory.hpp:77] Creating layer Scale20
I1007 17:39:01.526098  5078 net.cpp:84] Creating Layer Scale20
I1007 17:39:01.526101  5078 net.cpp:406] Scale20 <- Convolution20
I1007 17:39:01.526113  5078 net.cpp:367] Scale20 -> Convolution20 (in-place)
I1007 17:39:01.526144  5078 layer_factory.hpp:77] Creating layer Scale20
I1007 17:39:01.526228  5078 net.cpp:122] Setting up Scale20
I1007 17:39:01.526233  5078 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 17:39:01.526235  5078 net.cpp:137] Memory required for data: 541902000
I1007 17:39:01.526238  5078 layer_factory.hpp:77] Creating layer Eltwise9
I1007 17:39:01.526242  5078 net.cpp:84] Creating Layer Eltwise9
I1007 17:39:01.526245  5078 net.cpp:406] Eltwise9 <- Eltwise8_penlu17_0_split_1
I1007 17:39:01.526248  5078 net.cpp:406] Eltwise9 <- Convolution20
I1007 17:39:01.526252  5078 net.cpp:380] Eltwise9 -> Eltwise9
I1007 17:39:01.526265  5078 net.cpp:122] Setting up Eltwise9
I1007 17:39:01.526269  5078 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 17:39:01.526271  5078 net.cpp:137] Memory required for data: 545178800
I1007 17:39:01.526273  5078 layer_factory.hpp:77] Creating layer penlu19
I1007 17:39:01.526278  5078 net.cpp:84] Creating Layer penlu19
I1007 17:39:01.526281  5078 net.cpp:406] penlu19 <- Eltwise9
I1007 17:39:01.526285  5078 net.cpp:367] penlu19 -> Eltwise9 (in-place)
I1007 17:39:01.526409  5078 net.cpp:122] Setting up penlu19
I1007 17:39:01.526413  5078 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 17:39:01.526415  5078 net.cpp:137] Memory required for data: 548455600
I1007 17:39:01.526420  5078 layer_factory.hpp:77] Creating layer Eltwise9_penlu19_0_split
I1007 17:39:01.526425  5078 net.cpp:84] Creating Layer Eltwise9_penlu19_0_split
I1007 17:39:01.526427  5078 net.cpp:406] Eltwise9_penlu19_0_split <- Eltwise9
I1007 17:39:01.526440  5078 net.cpp:380] Eltwise9_penlu19_0_split -> Eltwise9_penlu19_0_split_0
I1007 17:39:01.526444  5078 net.cpp:380] Eltwise9_penlu19_0_split -> Eltwise9_penlu19_0_split_1
I1007 17:39:01.526471  5078 net.cpp:122] Setting up Eltwise9_penlu19_0_split
I1007 17:39:01.526475  5078 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 17:39:01.526479  5078 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 17:39:01.526480  5078 net.cpp:137] Memory required for data: 555009200
I1007 17:39:01.526482  5078 layer_factory.hpp:77] Creating layer Convolution21
I1007 17:39:01.526497  5078 net.cpp:84] Creating Layer Convolution21
I1007 17:39:01.526499  5078 net.cpp:406] Convolution21 <- Eltwise9_penlu19_0_split_0
I1007 17:39:01.526504  5078 net.cpp:380] Convolution21 -> Convolution21
I1007 17:39:01.527639  5078 net.cpp:122] Setting up Convolution21
I1007 17:39:01.527648  5078 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 17:39:01.527652  5078 net.cpp:137] Memory required for data: 558286000
I1007 17:39:01.527655  5078 layer_factory.hpp:77] Creating layer BatchNorm21
I1007 17:39:01.527660  5078 net.cpp:84] Creating Layer BatchNorm21
I1007 17:39:01.527663  5078 net.cpp:406] BatchNorm21 <- Convolution21
I1007 17:39:01.527667  5078 net.cpp:367] BatchNorm21 -> Convolution21 (in-place)
I1007 17:39:01.527813  5078 net.cpp:122] Setting up BatchNorm21
I1007 17:39:01.527818  5078 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 17:39:01.527820  5078 net.cpp:137] Memory required for data: 561562800
I1007 17:39:01.527824  5078 layer_factory.hpp:77] Creating layer Scale21
I1007 17:39:01.527829  5078 net.cpp:84] Creating Layer Scale21
I1007 17:39:01.527832  5078 net.cpp:406] Scale21 <- Convolution21
I1007 17:39:01.527835  5078 net.cpp:367] Scale21 -> Convolution21 (in-place)
I1007 17:39:01.527864  5078 layer_factory.hpp:77] Creating layer Scale21
I1007 17:39:01.527950  5078 net.cpp:122] Setting up Scale21
I1007 17:39:01.527954  5078 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 17:39:01.527956  5078 net.cpp:137] Memory required for data: 564839600
I1007 17:39:01.527959  5078 layer_factory.hpp:77] Creating layer penlu20
I1007 17:39:01.527966  5078 net.cpp:84] Creating Layer penlu20
I1007 17:39:01.527968  5078 net.cpp:406] penlu20 <- Convolution21
I1007 17:39:01.527972  5078 net.cpp:367] penlu20 -> Convolution21 (in-place)
I1007 17:39:01.528090  5078 net.cpp:122] Setting up penlu20
I1007 17:39:01.528100  5078 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 17:39:01.528103  5078 net.cpp:137] Memory required for data: 568116400
I1007 17:39:01.528107  5078 layer_factory.hpp:77] Creating layer Convolution22
I1007 17:39:01.528115  5078 net.cpp:84] Creating Layer Convolution22
I1007 17:39:01.528117  5078 net.cpp:406] Convolution22 <- Convolution21
I1007 17:39:01.528121  5078 net.cpp:380] Convolution22 -> Convolution22
I1007 17:39:01.529227  5078 net.cpp:122] Setting up Convolution22
I1007 17:39:01.529235  5078 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 17:39:01.529237  5078 net.cpp:137] Memory required for data: 571393200
I1007 17:39:01.529242  5078 layer_factory.hpp:77] Creating layer BatchNorm22
I1007 17:39:01.529247  5078 net.cpp:84] Creating Layer BatchNorm22
I1007 17:39:01.529249  5078 net.cpp:406] BatchNorm22 <- Convolution22
I1007 17:39:01.529253  5078 net.cpp:367] BatchNorm22 -> Convolution22 (in-place)
I1007 17:39:01.529402  5078 net.cpp:122] Setting up BatchNorm22
I1007 17:39:01.529405  5078 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 17:39:01.529408  5078 net.cpp:137] Memory required for data: 574670000
I1007 17:39:01.529412  5078 layer_factory.hpp:77] Creating layer Scale22
I1007 17:39:01.529417  5078 net.cpp:84] Creating Layer Scale22
I1007 17:39:01.529419  5078 net.cpp:406] Scale22 <- Convolution22
I1007 17:39:01.529422  5078 net.cpp:367] Scale22 -> Convolution22 (in-place)
I1007 17:39:01.529451  5078 layer_factory.hpp:77] Creating layer Scale22
I1007 17:39:01.529536  5078 net.cpp:122] Setting up Scale22
I1007 17:39:01.529539  5078 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 17:39:01.529542  5078 net.cpp:137] Memory required for data: 577946800
I1007 17:39:01.529546  5078 layer_factory.hpp:77] Creating layer Eltwise10
I1007 17:39:01.529551  5078 net.cpp:84] Creating Layer Eltwise10
I1007 17:39:01.529553  5078 net.cpp:406] Eltwise10 <- Eltwise9_penlu19_0_split_1
I1007 17:39:01.529556  5078 net.cpp:406] Eltwise10 <- Convolution22
I1007 17:39:01.529559  5078 net.cpp:380] Eltwise10 -> Eltwise10
I1007 17:39:01.529573  5078 net.cpp:122] Setting up Eltwise10
I1007 17:39:01.529577  5078 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 17:39:01.529579  5078 net.cpp:137] Memory required for data: 581223600
I1007 17:39:01.529582  5078 layer_factory.hpp:77] Creating layer penlu21
I1007 17:39:01.529587  5078 net.cpp:84] Creating Layer penlu21
I1007 17:39:01.529589  5078 net.cpp:406] penlu21 <- Eltwise10
I1007 17:39:01.529593  5078 net.cpp:367] penlu21 -> Eltwise10 (in-place)
I1007 17:39:01.529716  5078 net.cpp:122] Setting up penlu21
I1007 17:39:01.529721  5078 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 17:39:01.529722  5078 net.cpp:137] Memory required for data: 584500400
I1007 17:39:01.529726  5078 layer_factory.hpp:77] Creating layer Eltwise10_penlu21_0_split
I1007 17:39:01.529731  5078 net.cpp:84] Creating Layer Eltwise10_penlu21_0_split
I1007 17:39:01.529732  5078 net.cpp:406] Eltwise10_penlu21_0_split <- Eltwise10
I1007 17:39:01.529736  5078 net.cpp:380] Eltwise10_penlu21_0_split -> Eltwise10_penlu21_0_split_0
I1007 17:39:01.529741  5078 net.cpp:380] Eltwise10_penlu21_0_split -> Eltwise10_penlu21_0_split_1
I1007 17:39:01.529765  5078 net.cpp:122] Setting up Eltwise10_penlu21_0_split
I1007 17:39:01.529769  5078 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 17:39:01.529772  5078 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 17:39:01.529774  5078 net.cpp:137] Memory required for data: 591054000
I1007 17:39:01.529777  5078 layer_factory.hpp:77] Creating layer Convolution23
I1007 17:39:01.529783  5078 net.cpp:84] Creating Layer Convolution23
I1007 17:39:01.529785  5078 net.cpp:406] Convolution23 <- Eltwise10_penlu21_0_split_0
I1007 17:39:01.529788  5078 net.cpp:380] Convolution23 -> Convolution23
I1007 17:39:01.530757  5078 net.cpp:122] Setting up Convolution23
I1007 17:39:01.530766  5078 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 17:39:01.530768  5078 net.cpp:137] Memory required for data: 592692400
I1007 17:39:01.530773  5078 layer_factory.hpp:77] Creating layer BatchNorm23
I1007 17:39:01.530786  5078 net.cpp:84] Creating Layer BatchNorm23
I1007 17:39:01.530788  5078 net.cpp:406] BatchNorm23 <- Convolution23
I1007 17:39:01.530792  5078 net.cpp:367] BatchNorm23 -> Convolution23 (in-place)
I1007 17:39:01.530942  5078 net.cpp:122] Setting up BatchNorm23
I1007 17:39:01.530947  5078 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 17:39:01.530949  5078 net.cpp:137] Memory required for data: 594330800
I1007 17:39:01.530954  5078 layer_factory.hpp:77] Creating layer Scale23
I1007 17:39:01.530958  5078 net.cpp:84] Creating Layer Scale23
I1007 17:39:01.530961  5078 net.cpp:406] Scale23 <- Convolution23
I1007 17:39:01.530963  5078 net.cpp:367] Scale23 -> Convolution23 (in-place)
I1007 17:39:01.530994  5078 layer_factory.hpp:77] Creating layer Scale23
I1007 17:39:01.531080  5078 net.cpp:122] Setting up Scale23
I1007 17:39:01.531085  5078 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 17:39:01.531086  5078 net.cpp:137] Memory required for data: 595969200
I1007 17:39:01.531090  5078 layer_factory.hpp:77] Creating layer Convolution24
I1007 17:39:01.531096  5078 net.cpp:84] Creating Layer Convolution24
I1007 17:39:01.531100  5078 net.cpp:406] Convolution24 <- Eltwise10_penlu21_0_split_1
I1007 17:39:01.531105  5078 net.cpp:380] Convolution24 -> Convolution24
I1007 17:39:01.532447  5078 net.cpp:122] Setting up Convolution24
I1007 17:39:01.532457  5078 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 17:39:01.532459  5078 net.cpp:137] Memory required for data: 597607600
I1007 17:39:01.532464  5078 layer_factory.hpp:77] Creating layer BatchNorm24
I1007 17:39:01.532469  5078 net.cpp:84] Creating Layer BatchNorm24
I1007 17:39:01.532472  5078 net.cpp:406] BatchNorm24 <- Convolution24
I1007 17:39:01.532476  5078 net.cpp:367] BatchNorm24 -> Convolution24 (in-place)
I1007 17:39:01.532627  5078 net.cpp:122] Setting up BatchNorm24
I1007 17:39:01.532632  5078 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 17:39:01.532634  5078 net.cpp:137] Memory required for data: 599246000
I1007 17:39:01.532639  5078 layer_factory.hpp:77] Creating layer Scale24
I1007 17:39:01.532644  5078 net.cpp:84] Creating Layer Scale24
I1007 17:39:01.532645  5078 net.cpp:406] Scale24 <- Convolution24
I1007 17:39:01.532649  5078 net.cpp:367] Scale24 -> Convolution24 (in-place)
I1007 17:39:01.532680  5078 layer_factory.hpp:77] Creating layer Scale24
I1007 17:39:01.532766  5078 net.cpp:122] Setting up Scale24
I1007 17:39:01.532771  5078 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 17:39:01.532773  5078 net.cpp:137] Memory required for data: 600884400
I1007 17:39:01.532778  5078 layer_factory.hpp:77] Creating layer penlu22
I1007 17:39:01.532781  5078 net.cpp:84] Creating Layer penlu22
I1007 17:39:01.532784  5078 net.cpp:406] penlu22 <- Convolution24
I1007 17:39:01.532788  5078 net.cpp:367] penlu22 -> Convolution24 (in-place)
I1007 17:39:01.532910  5078 net.cpp:122] Setting up penlu22
I1007 17:39:01.532914  5078 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 17:39:01.532917  5078 net.cpp:137] Memory required for data: 602522800
I1007 17:39:01.532922  5078 layer_factory.hpp:77] Creating layer Convolution25
I1007 17:39:01.532928  5078 net.cpp:84] Creating Layer Convolution25
I1007 17:39:01.532930  5078 net.cpp:406] Convolution25 <- Convolution24
I1007 17:39:01.532934  5078 net.cpp:380] Convolution25 -> Convolution25
I1007 17:39:01.534664  5078 net.cpp:122] Setting up Convolution25
I1007 17:39:01.534672  5078 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 17:39:01.534675  5078 net.cpp:137] Memory required for data: 604161200
I1007 17:39:01.534679  5078 layer_factory.hpp:77] Creating layer BatchNorm25
I1007 17:39:01.534685  5078 net.cpp:84] Creating Layer BatchNorm25
I1007 17:39:01.534688  5078 net.cpp:406] BatchNorm25 <- Convolution25
I1007 17:39:01.534692  5078 net.cpp:367] BatchNorm25 -> Convolution25 (in-place)
I1007 17:39:01.534842  5078 net.cpp:122] Setting up BatchNorm25
I1007 17:39:01.534847  5078 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 17:39:01.534848  5078 net.cpp:137] Memory required for data: 605799600
I1007 17:39:01.534860  5078 layer_factory.hpp:77] Creating layer Scale25
I1007 17:39:01.534864  5078 net.cpp:84] Creating Layer Scale25
I1007 17:39:01.534868  5078 net.cpp:406] Scale25 <- Convolution25
I1007 17:39:01.534870  5078 net.cpp:367] Scale25 -> Convolution25 (in-place)
I1007 17:39:01.554013  5078 layer_factory.hpp:77] Creating layer Scale25
I1007 17:39:01.554127  5078 net.cpp:122] Setting up Scale25
I1007 17:39:01.554133  5078 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 17:39:01.554136  5078 net.cpp:137] Memory required for data: 607438000
I1007 17:39:01.554141  5078 layer_factory.hpp:77] Creating layer Eltwise11
I1007 17:39:01.554147  5078 net.cpp:84] Creating Layer Eltwise11
I1007 17:39:01.554150  5078 net.cpp:406] Eltwise11 <- Convolution23
I1007 17:39:01.554154  5078 net.cpp:406] Eltwise11 <- Convolution25
I1007 17:39:01.554157  5078 net.cpp:380] Eltwise11 -> Eltwise11
I1007 17:39:01.554178  5078 net.cpp:122] Setting up Eltwise11
I1007 17:39:01.554183  5078 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 17:39:01.554184  5078 net.cpp:137] Memory required for data: 609076400
I1007 17:39:01.554188  5078 layer_factory.hpp:77] Creating layer penlu23
I1007 17:39:01.554193  5078 net.cpp:84] Creating Layer penlu23
I1007 17:39:01.554195  5078 net.cpp:406] penlu23 <- Eltwise11
I1007 17:39:01.554199  5078 net.cpp:367] penlu23 -> Eltwise11 (in-place)
I1007 17:39:01.554332  5078 net.cpp:122] Setting up penlu23
I1007 17:39:01.554335  5078 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 17:39:01.554338  5078 net.cpp:137] Memory required for data: 610714800
I1007 17:39:01.554342  5078 layer_factory.hpp:77] Creating layer Eltwise11_penlu23_0_split
I1007 17:39:01.554347  5078 net.cpp:84] Creating Layer Eltwise11_penlu23_0_split
I1007 17:39:01.554349  5078 net.cpp:406] Eltwise11_penlu23_0_split <- Eltwise11
I1007 17:39:01.554353  5078 net.cpp:380] Eltwise11_penlu23_0_split -> Eltwise11_penlu23_0_split_0
I1007 17:39:01.554358  5078 net.cpp:380] Eltwise11_penlu23_0_split -> Eltwise11_penlu23_0_split_1
I1007 17:39:01.554385  5078 net.cpp:122] Setting up Eltwise11_penlu23_0_split
I1007 17:39:01.554391  5078 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 17:39:01.554394  5078 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 17:39:01.554396  5078 net.cpp:137] Memory required for data: 613991600
I1007 17:39:01.554399  5078 layer_factory.hpp:77] Creating layer Convolution26
I1007 17:39:01.554404  5078 net.cpp:84] Creating Layer Convolution26
I1007 17:39:01.554407  5078 net.cpp:406] Convolution26 <- Eltwise11_penlu23_0_split_0
I1007 17:39:01.554411  5078 net.cpp:380] Convolution26 -> Convolution26
I1007 17:39:01.556337  5078 net.cpp:122] Setting up Convolution26
I1007 17:39:01.556347  5078 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 17:39:01.556350  5078 net.cpp:137] Memory required for data: 615630000
I1007 17:39:01.556355  5078 layer_factory.hpp:77] Creating layer BatchNorm26
I1007 17:39:01.556360  5078 net.cpp:84] Creating Layer BatchNorm26
I1007 17:39:01.556362  5078 net.cpp:406] BatchNorm26 <- Convolution26
I1007 17:39:01.556366  5078 net.cpp:367] BatchNorm26 -> Convolution26 (in-place)
I1007 17:39:01.556519  5078 net.cpp:122] Setting up BatchNorm26
I1007 17:39:01.556522  5078 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 17:39:01.556524  5078 net.cpp:137] Memory required for data: 617268400
I1007 17:39:01.556529  5078 layer_factory.hpp:77] Creating layer Scale26
I1007 17:39:01.556533  5078 net.cpp:84] Creating Layer Scale26
I1007 17:39:01.556535  5078 net.cpp:406] Scale26 <- Convolution26
I1007 17:39:01.556538  5078 net.cpp:367] Scale26 -> Convolution26 (in-place)
I1007 17:39:01.556568  5078 layer_factory.hpp:77] Creating layer Scale26
I1007 17:39:01.556665  5078 net.cpp:122] Setting up Scale26
I1007 17:39:01.556670  5078 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 17:39:01.556673  5078 net.cpp:137] Memory required for data: 618906800
I1007 17:39:01.556676  5078 layer_factory.hpp:77] Creating layer penlu24
I1007 17:39:01.556681  5078 net.cpp:84] Creating Layer penlu24
I1007 17:39:01.556689  5078 net.cpp:406] penlu24 <- Convolution26
I1007 17:39:01.556694  5078 net.cpp:367] penlu24 -> Convolution26 (in-place)
I1007 17:39:01.556840  5078 net.cpp:122] Setting up penlu24
I1007 17:39:01.556844  5078 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 17:39:01.556848  5078 net.cpp:137] Memory required for data: 620545200
I1007 17:39:01.556851  5078 layer_factory.hpp:77] Creating layer Convolution27
I1007 17:39:01.556859  5078 net.cpp:84] Creating Layer Convolution27
I1007 17:39:01.556861  5078 net.cpp:406] Convolution27 <- Convolution26
I1007 17:39:01.556865  5078 net.cpp:380] Convolution27 -> Convolution27
I1007 17:39:01.558616  5078 net.cpp:122] Setting up Convolution27
I1007 17:39:01.558625  5078 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 17:39:01.558629  5078 net.cpp:137] Memory required for data: 622183600
I1007 17:39:01.558632  5078 layer_factory.hpp:77] Creating layer BatchNorm27
I1007 17:39:01.558646  5078 net.cpp:84] Creating Layer BatchNorm27
I1007 17:39:01.558650  5078 net.cpp:406] BatchNorm27 <- Convolution27
I1007 17:39:01.558655  5078 net.cpp:367] BatchNorm27 -> Convolution27 (in-place)
I1007 17:39:01.558809  5078 net.cpp:122] Setting up BatchNorm27
I1007 17:39:01.558814  5078 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 17:39:01.558815  5078 net.cpp:137] Memory required for data: 623822000
I1007 17:39:01.558840  5078 layer_factory.hpp:77] Creating layer Scale27
I1007 17:39:01.558845  5078 net.cpp:84] Creating Layer Scale27
I1007 17:39:01.558847  5078 net.cpp:406] Scale27 <- Convolution27
I1007 17:39:01.558851  5078 net.cpp:367] Scale27 -> Convolution27 (in-place)
I1007 17:39:01.558881  5078 layer_factory.hpp:77] Creating layer Scale27
I1007 17:39:01.558969  5078 net.cpp:122] Setting up Scale27
I1007 17:39:01.558972  5078 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 17:39:01.558974  5078 net.cpp:137] Memory required for data: 625460400
I1007 17:39:01.558979  5078 layer_factory.hpp:77] Creating layer Eltwise12
I1007 17:39:01.558982  5078 net.cpp:84] Creating Layer Eltwise12
I1007 17:39:01.558985  5078 net.cpp:406] Eltwise12 <- Eltwise11_penlu23_0_split_1
I1007 17:39:01.558990  5078 net.cpp:406] Eltwise12 <- Convolution27
I1007 17:39:01.558992  5078 net.cpp:380] Eltwise12 -> Eltwise12
I1007 17:39:01.559011  5078 net.cpp:122] Setting up Eltwise12
I1007 17:39:01.559015  5078 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 17:39:01.559016  5078 net.cpp:137] Memory required for data: 627098800
I1007 17:39:01.559018  5078 layer_factory.hpp:77] Creating layer penlu25
I1007 17:39:01.559026  5078 net.cpp:84] Creating Layer penlu25
I1007 17:39:01.559028  5078 net.cpp:406] penlu25 <- Eltwise12
I1007 17:39:01.559031  5078 net.cpp:367] penlu25 -> Eltwise12 (in-place)
I1007 17:39:01.559156  5078 net.cpp:122] Setting up penlu25
I1007 17:39:01.559160  5078 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 17:39:01.559162  5078 net.cpp:137] Memory required for data: 628737200
I1007 17:39:01.559171  5078 layer_factory.hpp:77] Creating layer Eltwise12_penlu25_0_split
I1007 17:39:01.559175  5078 net.cpp:84] Creating Layer Eltwise12_penlu25_0_split
I1007 17:39:01.559177  5078 net.cpp:406] Eltwise12_penlu25_0_split <- Eltwise12
I1007 17:39:01.559180  5078 net.cpp:380] Eltwise12_penlu25_0_split -> Eltwise12_penlu25_0_split_0
I1007 17:39:01.559185  5078 net.cpp:380] Eltwise12_penlu25_0_split -> Eltwise12_penlu25_0_split_1
I1007 17:39:01.559212  5078 net.cpp:122] Setting up Eltwise12_penlu25_0_split
I1007 17:39:01.559216  5078 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 17:39:01.559218  5078 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 17:39:01.559221  5078 net.cpp:137] Memory required for data: 632014000
I1007 17:39:01.559223  5078 layer_factory.hpp:77] Creating layer Convolution28
I1007 17:39:01.559229  5078 net.cpp:84] Creating Layer Convolution28
I1007 17:39:01.559232  5078 net.cpp:406] Convolution28 <- Eltwise12_penlu25_0_split_0
I1007 17:39:01.559236  5078 net.cpp:380] Convolution28 -> Convolution28
I1007 17:39:01.561283  5078 net.cpp:122] Setting up Convolution28
I1007 17:39:01.561298  5078 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 17:39:01.561301  5078 net.cpp:137] Memory required for data: 633652400
I1007 17:39:01.561306  5078 layer_factory.hpp:77] Creating layer BatchNorm28
I1007 17:39:01.561312  5078 net.cpp:84] Creating Layer BatchNorm28
I1007 17:39:01.561316  5078 net.cpp:406] BatchNorm28 <- Convolution28
I1007 17:39:01.561318  5078 net.cpp:367] BatchNorm28 -> Convolution28 (in-place)
I1007 17:39:01.561475  5078 net.cpp:122] Setting up BatchNorm28
I1007 17:39:01.561480  5078 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 17:39:01.561481  5078 net.cpp:137] Memory required for data: 635290800
I1007 17:39:01.561486  5078 layer_factory.hpp:77] Creating layer Scale28
I1007 17:39:01.561491  5078 net.cpp:84] Creating Layer Scale28
I1007 17:39:01.561492  5078 net.cpp:406] Scale28 <- Convolution28
I1007 17:39:01.561496  5078 net.cpp:367] Scale28 -> Convolution28 (in-place)
I1007 17:39:01.561527  5078 layer_factory.hpp:77] Creating layer Scale28
I1007 17:39:01.561614  5078 net.cpp:122] Setting up Scale28
I1007 17:39:01.561619  5078 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 17:39:01.561620  5078 net.cpp:137] Memory required for data: 636929200
I1007 17:39:01.561625  5078 layer_factory.hpp:77] Creating layer penlu26
I1007 17:39:01.561630  5078 net.cpp:84] Creating Layer penlu26
I1007 17:39:01.561632  5078 net.cpp:406] penlu26 <- Convolution28
I1007 17:39:01.561635  5078 net.cpp:367] penlu26 -> Convolution28 (in-place)
I1007 17:39:01.561758  5078 net.cpp:122] Setting up penlu26
I1007 17:39:01.561763  5078 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 17:39:01.561764  5078 net.cpp:137] Memory required for data: 638567600
I1007 17:39:01.561769  5078 layer_factory.hpp:77] Creating layer Convolution29
I1007 17:39:01.561775  5078 net.cpp:84] Creating Layer Convolution29
I1007 17:39:01.561777  5078 net.cpp:406] Convolution29 <- Convolution28
I1007 17:39:01.561781  5078 net.cpp:380] Convolution29 -> Convolution29
I1007 17:39:01.564026  5078 net.cpp:122] Setting up Convolution29
I1007 17:39:01.564035  5078 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 17:39:01.564038  5078 net.cpp:137] Memory required for data: 640206000
I1007 17:39:01.564043  5078 layer_factory.hpp:77] Creating layer BatchNorm29
I1007 17:39:01.564049  5078 net.cpp:84] Creating Layer BatchNorm29
I1007 17:39:01.564051  5078 net.cpp:406] BatchNorm29 <- Convolution29
I1007 17:39:01.564054  5078 net.cpp:367] BatchNorm29 -> Convolution29 (in-place)
I1007 17:39:01.564215  5078 net.cpp:122] Setting up BatchNorm29
I1007 17:39:01.564219  5078 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 17:39:01.564221  5078 net.cpp:137] Memory required for data: 641844400
I1007 17:39:01.564226  5078 layer_factory.hpp:77] Creating layer Scale29
I1007 17:39:01.564230  5078 net.cpp:84] Creating Layer Scale29
I1007 17:39:01.564232  5078 net.cpp:406] Scale29 <- Convolution29
I1007 17:39:01.564236  5078 net.cpp:367] Scale29 -> Convolution29 (in-place)
I1007 17:39:01.564266  5078 layer_factory.hpp:77] Creating layer Scale29
I1007 17:39:01.564353  5078 net.cpp:122] Setting up Scale29
I1007 17:39:01.564357  5078 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 17:39:01.564359  5078 net.cpp:137] Memory required for data: 643482800
I1007 17:39:01.564363  5078 layer_factory.hpp:77] Creating layer Eltwise13
I1007 17:39:01.564368  5078 net.cpp:84] Creating Layer Eltwise13
I1007 17:39:01.564369  5078 net.cpp:406] Eltwise13 <- Eltwise12_penlu25_0_split_1
I1007 17:39:01.564373  5078 net.cpp:406] Eltwise13 <- Convolution29
I1007 17:39:01.564376  5078 net.cpp:380] Eltwise13 -> Eltwise13
I1007 17:39:01.564394  5078 net.cpp:122] Setting up Eltwise13
I1007 17:39:01.564399  5078 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 17:39:01.564400  5078 net.cpp:137] Memory required for data: 645121200
I1007 17:39:01.564402  5078 layer_factory.hpp:77] Creating layer penlu27
I1007 17:39:01.564406  5078 net.cpp:84] Creating Layer penlu27
I1007 17:39:01.564409  5078 net.cpp:406] penlu27 <- Eltwise13
I1007 17:39:01.564414  5078 net.cpp:367] penlu27 -> Eltwise13 (in-place)
I1007 17:39:01.564543  5078 net.cpp:122] Setting up penlu27
I1007 17:39:01.564548  5078 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 17:39:01.564550  5078 net.cpp:137] Memory required for data: 646759600
I1007 17:39:01.564554  5078 layer_factory.hpp:77] Creating layer Eltwise13_penlu27_0_split
I1007 17:39:01.564558  5078 net.cpp:84] Creating Layer Eltwise13_penlu27_0_split
I1007 17:39:01.564560  5078 net.cpp:406] Eltwise13_penlu27_0_split <- Eltwise13
I1007 17:39:01.564563  5078 net.cpp:380] Eltwise13_penlu27_0_split -> Eltwise13_penlu27_0_split_0
I1007 17:39:01.564568  5078 net.cpp:380] Eltwise13_penlu27_0_split -> Eltwise13_penlu27_0_split_1
I1007 17:39:01.564594  5078 net.cpp:122] Setting up Eltwise13_penlu27_0_split
I1007 17:39:01.564597  5078 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 17:39:01.564600  5078 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 17:39:01.564602  5078 net.cpp:137] Memory required for data: 650036400
I1007 17:39:01.564604  5078 layer_factory.hpp:77] Creating layer Convolution30
I1007 17:39:01.564610  5078 net.cpp:84] Creating Layer Convolution30
I1007 17:39:01.564613  5078 net.cpp:406] Convolution30 <- Eltwise13_penlu27_0_split_0
I1007 17:39:01.564617  5078 net.cpp:380] Convolution30 -> Convolution30
I1007 17:39:01.566630  5078 net.cpp:122] Setting up Convolution30
I1007 17:39:01.566639  5078 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 17:39:01.566642  5078 net.cpp:137] Memory required for data: 651674800
I1007 17:39:01.566646  5078 layer_factory.hpp:77] Creating layer BatchNorm30
I1007 17:39:01.566651  5078 net.cpp:84] Creating Layer BatchNorm30
I1007 17:39:01.566654  5078 net.cpp:406] BatchNorm30 <- Convolution30
I1007 17:39:01.566658  5078 net.cpp:367] BatchNorm30 -> Convolution30 (in-place)
I1007 17:39:01.566812  5078 net.cpp:122] Setting up BatchNorm30
I1007 17:39:01.566817  5078 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 17:39:01.566819  5078 net.cpp:137] Memory required for data: 653313200
I1007 17:39:01.566833  5078 layer_factory.hpp:77] Creating layer Scale30
I1007 17:39:01.566836  5078 net.cpp:84] Creating Layer Scale30
I1007 17:39:01.566839  5078 net.cpp:406] Scale30 <- Convolution30
I1007 17:39:01.566843  5078 net.cpp:367] Scale30 -> Convolution30 (in-place)
I1007 17:39:01.566875  5078 layer_factory.hpp:77] Creating layer Scale30
I1007 17:39:01.566967  5078 net.cpp:122] Setting up Scale30
I1007 17:39:01.566970  5078 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 17:39:01.566972  5078 net.cpp:137] Memory required for data: 654951600
I1007 17:39:01.566977  5078 layer_factory.hpp:77] Creating layer penlu28
I1007 17:39:01.566982  5078 net.cpp:84] Creating Layer penlu28
I1007 17:39:01.566984  5078 net.cpp:406] penlu28 <- Convolution30
I1007 17:39:01.566988  5078 net.cpp:367] penlu28 -> Convolution30 (in-place)
I1007 17:39:01.567116  5078 net.cpp:122] Setting up penlu28
I1007 17:39:01.567121  5078 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 17:39:01.567122  5078 net.cpp:137] Memory required for data: 656590000
I1007 17:39:01.567126  5078 layer_factory.hpp:77] Creating layer Convolution31
I1007 17:39:01.567133  5078 net.cpp:84] Creating Layer Convolution31
I1007 17:39:01.567136  5078 net.cpp:406] Convolution31 <- Convolution30
I1007 17:39:01.567139  5078 net.cpp:380] Convolution31 -> Convolution31
I1007 17:39:01.568856  5078 net.cpp:122] Setting up Convolution31
I1007 17:39:01.568864  5078 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 17:39:01.568867  5078 net.cpp:137] Memory required for data: 658228400
I1007 17:39:01.568872  5078 layer_factory.hpp:77] Creating layer BatchNorm31
I1007 17:39:01.568877  5078 net.cpp:84] Creating Layer BatchNorm31
I1007 17:39:01.568881  5078 net.cpp:406] BatchNorm31 <- Convolution31
I1007 17:39:01.568884  5078 net.cpp:367] BatchNorm31 -> Convolution31 (in-place)
I1007 17:39:01.569039  5078 net.cpp:122] Setting up BatchNorm31
I1007 17:39:01.569044  5078 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 17:39:01.569046  5078 net.cpp:137] Memory required for data: 659866800
I1007 17:39:01.569051  5078 layer_factory.hpp:77] Creating layer Scale31
I1007 17:39:01.569061  5078 net.cpp:84] Creating Layer Scale31
I1007 17:39:01.584877  5078 net.cpp:406] Scale31 <- Convolution31
I1007 17:39:01.584890  5078 net.cpp:367] Scale31 -> Convolution31 (in-place)
I1007 17:39:01.584949  5078 layer_factory.hpp:77] Creating layer Scale31
I1007 17:39:01.585053  5078 net.cpp:122] Setting up Scale31
I1007 17:39:01.585058  5078 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 17:39:01.585062  5078 net.cpp:137] Memory required for data: 661505200
I1007 17:39:01.585065  5078 layer_factory.hpp:77] Creating layer Eltwise14
I1007 17:39:01.585070  5078 net.cpp:84] Creating Layer Eltwise14
I1007 17:39:01.585073  5078 net.cpp:406] Eltwise14 <- Eltwise13_penlu27_0_split_1
I1007 17:39:01.585078  5078 net.cpp:406] Eltwise14 <- Convolution31
I1007 17:39:01.585080  5078 net.cpp:380] Eltwise14 -> Eltwise14
I1007 17:39:01.585100  5078 net.cpp:122] Setting up Eltwise14
I1007 17:39:01.585105  5078 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 17:39:01.585108  5078 net.cpp:137] Memory required for data: 663143600
I1007 17:39:01.585109  5078 layer_factory.hpp:77] Creating layer penlu29
I1007 17:39:01.585115  5078 net.cpp:84] Creating Layer penlu29
I1007 17:39:01.585119  5078 net.cpp:406] penlu29 <- Eltwise14
I1007 17:39:01.585121  5078 net.cpp:367] penlu29 -> Eltwise14 (in-place)
I1007 17:39:01.585258  5078 net.cpp:122] Setting up penlu29
I1007 17:39:01.585261  5078 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 17:39:01.585264  5078 net.cpp:137] Memory required for data: 664782000
I1007 17:39:01.585269  5078 layer_factory.hpp:77] Creating layer Eltwise14_penlu29_0_split
I1007 17:39:01.585273  5078 net.cpp:84] Creating Layer Eltwise14_penlu29_0_split
I1007 17:39:01.585275  5078 net.cpp:406] Eltwise14_penlu29_0_split <- Eltwise14
I1007 17:39:01.585281  5078 net.cpp:380] Eltwise14_penlu29_0_split -> Eltwise14_penlu29_0_split_0
I1007 17:39:01.585285  5078 net.cpp:380] Eltwise14_penlu29_0_split -> Eltwise14_penlu29_0_split_1
I1007 17:39:01.585314  5078 net.cpp:122] Setting up Eltwise14_penlu29_0_split
I1007 17:39:01.585319  5078 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 17:39:01.585321  5078 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 17:39:01.585325  5078 net.cpp:137] Memory required for data: 668058800
I1007 17:39:01.585326  5078 layer_factory.hpp:77] Creating layer Convolution32
I1007 17:39:01.585335  5078 net.cpp:84] Creating Layer Convolution32
I1007 17:39:01.585337  5078 net.cpp:406] Convolution32 <- Eltwise14_penlu29_0_split_0
I1007 17:39:01.585341  5078 net.cpp:380] Convolution32 -> Convolution32
I1007 17:39:01.587733  5078 net.cpp:122] Setting up Convolution32
I1007 17:39:01.587741  5078 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 17:39:01.587744  5078 net.cpp:137] Memory required for data: 669697200
I1007 17:39:01.587749  5078 layer_factory.hpp:77] Creating layer BatchNorm32
I1007 17:39:01.587754  5078 net.cpp:84] Creating Layer BatchNorm32
I1007 17:39:01.587756  5078 net.cpp:406] BatchNorm32 <- Convolution32
I1007 17:39:01.587761  5078 net.cpp:367] BatchNorm32 -> Convolution32 (in-place)
I1007 17:39:01.587923  5078 net.cpp:122] Setting up BatchNorm32
I1007 17:39:01.587926  5078 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 17:39:01.587929  5078 net.cpp:137] Memory required for data: 671335600
I1007 17:39:01.587934  5078 layer_factory.hpp:77] Creating layer Scale32
I1007 17:39:01.587937  5078 net.cpp:84] Creating Layer Scale32
I1007 17:39:01.587940  5078 net.cpp:406] Scale32 <- Convolution32
I1007 17:39:01.587944  5078 net.cpp:367] Scale32 -> Convolution32 (in-place)
I1007 17:39:01.587975  5078 layer_factory.hpp:77] Creating layer Scale32
I1007 17:39:01.588063  5078 net.cpp:122] Setting up Scale32
I1007 17:39:01.588068  5078 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 17:39:01.588070  5078 net.cpp:137] Memory required for data: 672974000
I1007 17:39:01.588073  5078 layer_factory.hpp:77] Creating layer penlu30
I1007 17:39:01.588089  5078 net.cpp:84] Creating Layer penlu30
I1007 17:39:01.588093  5078 net.cpp:406] penlu30 <- Convolution32
I1007 17:39:01.588104  5078 net.cpp:367] penlu30 -> Convolution32 (in-place)
I1007 17:39:01.588233  5078 net.cpp:122] Setting up penlu30
I1007 17:39:01.588238  5078 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 17:39:01.588240  5078 net.cpp:137] Memory required for data: 674612400
I1007 17:39:01.588245  5078 layer_factory.hpp:77] Creating layer Convolution33
I1007 17:39:01.588251  5078 net.cpp:84] Creating Layer Convolution33
I1007 17:39:01.588254  5078 net.cpp:406] Convolution33 <- Convolution32
I1007 17:39:01.588259  5078 net.cpp:380] Convolution33 -> Convolution33
I1007 17:39:01.590008  5078 net.cpp:122] Setting up Convolution33
I1007 17:39:01.590018  5078 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 17:39:01.590020  5078 net.cpp:137] Memory required for data: 676250800
I1007 17:39:01.590024  5078 layer_factory.hpp:77] Creating layer BatchNorm33
I1007 17:39:01.590029  5078 net.cpp:84] Creating Layer BatchNorm33
I1007 17:39:01.590032  5078 net.cpp:406] BatchNorm33 <- Convolution33
I1007 17:39:01.590037  5078 net.cpp:367] BatchNorm33 -> Convolution33 (in-place)
I1007 17:39:01.590193  5078 net.cpp:122] Setting up BatchNorm33
I1007 17:39:01.590196  5078 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 17:39:01.590198  5078 net.cpp:137] Memory required for data: 677889200
I1007 17:39:01.590204  5078 layer_factory.hpp:77] Creating layer Scale33
I1007 17:39:01.590207  5078 net.cpp:84] Creating Layer Scale33
I1007 17:39:01.590210  5078 net.cpp:406] Scale33 <- Convolution33
I1007 17:39:01.590214  5078 net.cpp:367] Scale33 -> Convolution33 (in-place)
I1007 17:39:01.590245  5078 layer_factory.hpp:77] Creating layer Scale33
I1007 17:39:01.590335  5078 net.cpp:122] Setting up Scale33
I1007 17:39:01.590340  5078 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 17:39:01.590342  5078 net.cpp:137] Memory required for data: 679527600
I1007 17:39:01.590346  5078 layer_factory.hpp:77] Creating layer Eltwise15
I1007 17:39:01.590349  5078 net.cpp:84] Creating Layer Eltwise15
I1007 17:39:01.590353  5078 net.cpp:406] Eltwise15 <- Eltwise14_penlu29_0_split_1
I1007 17:39:01.590355  5078 net.cpp:406] Eltwise15 <- Convolution33
I1007 17:39:01.590359  5078 net.cpp:380] Eltwise15 -> Eltwise15
I1007 17:39:01.590378  5078 net.cpp:122] Setting up Eltwise15
I1007 17:39:01.590384  5078 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 17:39:01.590385  5078 net.cpp:137] Memory required for data: 681166000
I1007 17:39:01.590387  5078 layer_factory.hpp:77] Creating layer penlu31
I1007 17:39:01.590392  5078 net.cpp:84] Creating Layer penlu31
I1007 17:39:01.590394  5078 net.cpp:406] penlu31 <- Eltwise15
I1007 17:39:01.590399  5078 net.cpp:367] penlu31 -> Eltwise15 (in-place)
I1007 17:39:01.590520  5078 net.cpp:122] Setting up penlu31
I1007 17:39:01.590525  5078 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 17:39:01.590528  5078 net.cpp:137] Memory required for data: 682804400
I1007 17:39:01.590531  5078 layer_factory.hpp:77] Creating layer Pooling1
I1007 17:39:01.590536  5078 net.cpp:84] Creating Layer Pooling1
I1007 17:39:01.590538  5078 net.cpp:406] Pooling1 <- Eltwise15
I1007 17:39:01.590543  5078 net.cpp:380] Pooling1 -> Pooling1
I1007 17:39:01.590687  5078 net.cpp:122] Setting up Pooling1
I1007 17:39:01.590693  5078 net.cpp:129] Top shape: 100 64 1 1 (6400)
I1007 17:39:01.590695  5078 net.cpp:137] Memory required for data: 682830000
I1007 17:39:01.590698  5078 layer_factory.hpp:77] Creating layer InnerProduct1
I1007 17:39:01.590704  5078 net.cpp:84] Creating Layer InnerProduct1
I1007 17:39:01.590706  5078 net.cpp:406] InnerProduct1 <- Pooling1
I1007 17:39:01.590710  5078 net.cpp:380] InnerProduct1 -> InnerProduct1
I1007 17:39:01.590818  5078 net.cpp:122] Setting up InnerProduct1
I1007 17:39:01.590823  5078 net.cpp:129] Top shape: 100 10 (1000)
I1007 17:39:01.590826  5078 net.cpp:137] Memory required for data: 682834000
I1007 17:39:01.590829  5078 layer_factory.hpp:77] Creating layer InnerProduct1_InnerProduct1_0_split
I1007 17:39:01.590833  5078 net.cpp:84] Creating Layer InnerProduct1_InnerProduct1_0_split
I1007 17:39:01.590842  5078 net.cpp:406] InnerProduct1_InnerProduct1_0_split <- InnerProduct1
I1007 17:39:01.590847  5078 net.cpp:380] InnerProduct1_InnerProduct1_0_split -> InnerProduct1_InnerProduct1_0_split_0
I1007 17:39:01.590852  5078 net.cpp:380] InnerProduct1_InnerProduct1_0_split -> InnerProduct1_InnerProduct1_0_split_1
I1007 17:39:01.590880  5078 net.cpp:122] Setting up InnerProduct1_InnerProduct1_0_split
I1007 17:39:01.590884  5078 net.cpp:129] Top shape: 100 10 (1000)
I1007 17:39:01.590886  5078 net.cpp:129] Top shape: 100 10 (1000)
I1007 17:39:01.590889  5078 net.cpp:137] Memory required for data: 682842000
I1007 17:39:01.590891  5078 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I1007 17:39:01.590895  5078 net.cpp:84] Creating Layer SoftmaxWithLoss1
I1007 17:39:01.590898  5078 net.cpp:406] SoftmaxWithLoss1 <- InnerProduct1_InnerProduct1_0_split_0
I1007 17:39:01.590901  5078 net.cpp:406] SoftmaxWithLoss1 <- Data2_Data1_1_split_0
I1007 17:39:01.590904  5078 net.cpp:380] SoftmaxWithLoss1 -> SoftmaxWithLoss1
I1007 17:39:01.590909  5078 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I1007 17:39:01.591465  5078 net.cpp:122] Setting up SoftmaxWithLoss1
I1007 17:39:01.591473  5078 net.cpp:129] Top shape: (1)
I1007 17:39:01.591475  5078 net.cpp:132]     with loss weight 1
I1007 17:39:01.591483  5078 net.cpp:137] Memory required for data: 682842004
I1007 17:39:01.591485  5078 layer_factory.hpp:77] Creating layer Accuracy1
I1007 17:39:01.591495  5078 net.cpp:84] Creating Layer Accuracy1
I1007 17:39:01.591497  5078 net.cpp:406] Accuracy1 <- InnerProduct1_InnerProduct1_0_split_1
I1007 17:39:01.591501  5078 net.cpp:406] Accuracy1 <- Data2_Data1_1_split_1
I1007 17:39:01.591506  5078 net.cpp:380] Accuracy1 -> Accuracy1
I1007 17:39:01.591511  5078 net.cpp:122] Setting up Accuracy1
I1007 17:39:01.591514  5078 net.cpp:129] Top shape: (1)
I1007 17:39:01.591516  5078 net.cpp:137] Memory required for data: 682842008
I1007 17:39:01.591518  5078 net.cpp:200] Accuracy1 does not need backward computation.
I1007 17:39:01.591521  5078 net.cpp:198] SoftmaxWithLoss1 needs backward computation.
I1007 17:39:01.591523  5078 net.cpp:198] InnerProduct1_InnerProduct1_0_split needs backward computation.
I1007 17:39:01.591526  5078 net.cpp:198] InnerProduct1 needs backward computation.
I1007 17:39:01.591528  5078 net.cpp:198] Pooling1 needs backward computation.
I1007 17:39:01.591531  5078 net.cpp:198] penlu31 needs backward computation.
I1007 17:39:01.591532  5078 net.cpp:198] Eltwise15 needs backward computation.
I1007 17:39:01.591536  5078 net.cpp:198] Scale33 needs backward computation.
I1007 17:39:01.591537  5078 net.cpp:198] BatchNorm33 needs backward computation.
I1007 17:39:01.591538  5078 net.cpp:198] Convolution33 needs backward computation.
I1007 17:39:01.591542  5078 net.cpp:198] penlu30 needs backward computation.
I1007 17:39:01.591543  5078 net.cpp:198] Scale32 needs backward computation.
I1007 17:39:01.591545  5078 net.cpp:198] BatchNorm32 needs backward computation.
I1007 17:39:01.591547  5078 net.cpp:198] Convolution32 needs backward computation.
I1007 17:39:01.591549  5078 net.cpp:198] Eltwise14_penlu29_0_split needs backward computation.
I1007 17:39:01.591552  5078 net.cpp:198] penlu29 needs backward computation.
I1007 17:39:01.591553  5078 net.cpp:198] Eltwise14 needs backward computation.
I1007 17:39:01.591557  5078 net.cpp:198] Scale31 needs backward computation.
I1007 17:39:01.591558  5078 net.cpp:198] BatchNorm31 needs backward computation.
I1007 17:39:01.591560  5078 net.cpp:198] Convolution31 needs backward computation.
I1007 17:39:01.591562  5078 net.cpp:198] penlu28 needs backward computation.
I1007 17:39:01.591564  5078 net.cpp:198] Scale30 needs backward computation.
I1007 17:39:01.591567  5078 net.cpp:198] BatchNorm30 needs backward computation.
I1007 17:39:01.591568  5078 net.cpp:198] Convolution30 needs backward computation.
I1007 17:39:01.591570  5078 net.cpp:198] Eltwise13_penlu27_0_split needs backward computation.
I1007 17:39:01.591572  5078 net.cpp:198] penlu27 needs backward computation.
I1007 17:39:01.591581  5078 net.cpp:198] Eltwise13 needs backward computation.
I1007 17:39:01.591584  5078 net.cpp:198] Scale29 needs backward computation.
I1007 17:39:01.591586  5078 net.cpp:198] BatchNorm29 needs backward computation.
I1007 17:39:01.591588  5078 net.cpp:198] Convolution29 needs backward computation.
I1007 17:39:01.591590  5078 net.cpp:198] penlu26 needs backward computation.
I1007 17:39:01.591593  5078 net.cpp:198] Scale28 needs backward computation.
I1007 17:39:01.591594  5078 net.cpp:198] BatchNorm28 needs backward computation.
I1007 17:39:01.591596  5078 net.cpp:198] Convolution28 needs backward computation.
I1007 17:39:01.591598  5078 net.cpp:198] Eltwise12_penlu25_0_split needs backward computation.
I1007 17:39:01.591601  5078 net.cpp:198] penlu25 needs backward computation.
I1007 17:39:01.591603  5078 net.cpp:198] Eltwise12 needs backward computation.
I1007 17:39:01.591606  5078 net.cpp:198] Scale27 needs backward computation.
I1007 17:39:01.591609  5078 net.cpp:198] BatchNorm27 needs backward computation.
I1007 17:39:01.591611  5078 net.cpp:198] Convolution27 needs backward computation.
I1007 17:39:01.591614  5078 net.cpp:198] penlu24 needs backward computation.
I1007 17:39:01.591615  5078 net.cpp:198] Scale26 needs backward computation.
I1007 17:39:01.591617  5078 net.cpp:198] BatchNorm26 needs backward computation.
I1007 17:39:01.591619  5078 net.cpp:198] Convolution26 needs backward computation.
I1007 17:39:01.591621  5078 net.cpp:198] Eltwise11_penlu23_0_split needs backward computation.
I1007 17:39:01.591624  5078 net.cpp:198] penlu23 needs backward computation.
I1007 17:39:01.591626  5078 net.cpp:198] Eltwise11 needs backward computation.
I1007 17:39:01.591629  5078 net.cpp:198] Scale25 needs backward computation.
I1007 17:39:01.591631  5078 net.cpp:198] BatchNorm25 needs backward computation.
I1007 17:39:01.591634  5078 net.cpp:198] Convolution25 needs backward computation.
I1007 17:39:01.591636  5078 net.cpp:198] penlu22 needs backward computation.
I1007 17:39:01.591639  5078 net.cpp:198] Scale24 needs backward computation.
I1007 17:39:01.591640  5078 net.cpp:198] BatchNorm24 needs backward computation.
I1007 17:39:01.591642  5078 net.cpp:198] Convolution24 needs backward computation.
I1007 17:39:01.591645  5078 net.cpp:198] Scale23 needs backward computation.
I1007 17:39:01.591647  5078 net.cpp:198] BatchNorm23 needs backward computation.
I1007 17:39:01.591650  5078 net.cpp:198] Convolution23 needs backward computation.
I1007 17:39:01.591652  5078 net.cpp:198] Eltwise10_penlu21_0_split needs backward computation.
I1007 17:39:01.591655  5078 net.cpp:198] penlu21 needs backward computation.
I1007 17:39:01.591656  5078 net.cpp:198] Eltwise10 needs backward computation.
I1007 17:39:01.591660  5078 net.cpp:198] Scale22 needs backward computation.
I1007 17:39:01.591661  5078 net.cpp:198] BatchNorm22 needs backward computation.
I1007 17:39:01.591663  5078 net.cpp:198] Convolution22 needs backward computation.
I1007 17:39:01.591666  5078 net.cpp:198] penlu20 needs backward computation.
I1007 17:39:01.591668  5078 net.cpp:198] Scale21 needs backward computation.
I1007 17:39:01.591670  5078 net.cpp:198] BatchNorm21 needs backward computation.
I1007 17:39:01.591672  5078 net.cpp:198] Convolution21 needs backward computation.
I1007 17:39:01.591675  5078 net.cpp:198] Eltwise9_penlu19_0_split needs backward computation.
I1007 17:39:01.591677  5078 net.cpp:198] penlu19 needs backward computation.
I1007 17:39:01.591680  5078 net.cpp:198] Eltwise9 needs backward computation.
I1007 17:39:01.591682  5078 net.cpp:198] Scale20 needs backward computation.
I1007 17:39:01.591684  5078 net.cpp:198] BatchNorm20 needs backward computation.
I1007 17:39:01.591686  5078 net.cpp:198] Convolution20 needs backward computation.
I1007 17:39:01.591689  5078 net.cpp:198] penlu18 needs backward computation.
I1007 17:39:01.591691  5078 net.cpp:198] Scale19 needs backward computation.
I1007 17:39:01.591693  5078 net.cpp:198] BatchNorm19 needs backward computation.
I1007 17:39:01.591696  5078 net.cpp:198] Convolution19 needs backward computation.
I1007 17:39:01.615265  5078 net.cpp:198] Eltwise8_penlu17_0_split needs backward computation.
I1007 17:39:01.615275  5078 net.cpp:198] penlu17 needs backward computation.
I1007 17:39:01.615279  5078 net.cpp:198] Eltwise8 needs backward computation.
I1007 17:39:01.615284  5078 net.cpp:198] Scale18 needs backward computation.
I1007 17:39:01.615289  5078 net.cpp:198] BatchNorm18 needs backward computation.
I1007 17:39:01.615293  5078 net.cpp:198] Convolution18 needs backward computation.
I1007 17:39:01.615298  5078 net.cpp:198] penlu16 needs backward computation.
I1007 17:39:01.615301  5078 net.cpp:198] Scale17 needs backward computation.
I1007 17:39:01.615304  5078 net.cpp:198] BatchNorm17 needs backward computation.
I1007 17:39:01.615309  5078 net.cpp:198] Convolution17 needs backward computation.
I1007 17:39:01.615314  5078 net.cpp:198] Eltwise7_penlu15_0_split needs backward computation.
I1007 17:39:01.615317  5078 net.cpp:198] penlu15 needs backward computation.
I1007 17:39:01.615321  5078 net.cpp:198] Eltwise7 needs backward computation.
I1007 17:39:01.615325  5078 net.cpp:198] Scale16 needs backward computation.
I1007 17:39:01.615330  5078 net.cpp:198] BatchNorm16 needs backward computation.
I1007 17:39:01.615334  5078 net.cpp:198] Convolution16 needs backward computation.
I1007 17:39:01.615336  5078 net.cpp:198] penlu14 needs backward computation.
I1007 17:39:01.615339  5078 net.cpp:198] Scale15 needs backward computation.
I1007 17:39:01.615341  5078 net.cpp:198] BatchNorm15 needs backward computation.
I1007 17:39:01.615344  5078 net.cpp:198] Convolution15 needs backward computation.
I1007 17:39:01.615346  5078 net.cpp:198] Eltwise6_penlu13_0_split needs backward computation.
I1007 17:39:01.615350  5078 net.cpp:198] penlu13 needs backward computation.
I1007 17:39:01.615351  5078 net.cpp:198] Eltwise6 needs backward computation.
I1007 17:39:01.615355  5078 net.cpp:198] Scale14 needs backward computation.
I1007 17:39:01.615357  5078 net.cpp:198] BatchNorm14 needs backward computation.
I1007 17:39:01.615360  5078 net.cpp:198] Convolution14 needs backward computation.
I1007 17:39:01.615362  5078 net.cpp:198] penlu12 needs backward computation.
I1007 17:39:01.615365  5078 net.cpp:198] Scale13 needs backward computation.
I1007 17:39:01.615367  5078 net.cpp:198] BatchNorm13 needs backward computation.
I1007 17:39:01.615370  5078 net.cpp:198] Convolution13 needs backward computation.
I1007 17:39:01.615372  5078 net.cpp:198] Scale12 needs backward computation.
I1007 17:39:01.615375  5078 net.cpp:198] BatchNorm12 needs backward computation.
I1007 17:39:01.615376  5078 net.cpp:198] Convolution12 needs backward computation.
I1007 17:39:01.615380  5078 net.cpp:198] Eltwise5_penlu11_0_split needs backward computation.
I1007 17:39:01.615382  5078 net.cpp:198] penlu11 needs backward computation.
I1007 17:39:01.615384  5078 net.cpp:198] Eltwise5 needs backward computation.
I1007 17:39:01.615387  5078 net.cpp:198] Scale11 needs backward computation.
I1007 17:39:01.615389  5078 net.cpp:198] BatchNorm11 needs backward computation.
I1007 17:39:01.615392  5078 net.cpp:198] Convolution11 needs backward computation.
I1007 17:39:01.615394  5078 net.cpp:198] penlu10 needs backward computation.
I1007 17:39:01.615397  5078 net.cpp:198] Scale10 needs backward computation.
I1007 17:39:01.615399  5078 net.cpp:198] BatchNorm10 needs backward computation.
I1007 17:39:01.615402  5078 net.cpp:198] Convolution10 needs backward computation.
I1007 17:39:01.615404  5078 net.cpp:198] Eltwise4_penlu9_0_split needs backward computation.
I1007 17:39:01.615407  5078 net.cpp:198] penlu9 needs backward computation.
I1007 17:39:01.615411  5078 net.cpp:198] Eltwise4 needs backward computation.
I1007 17:39:01.615413  5078 net.cpp:198] Scale9 needs backward computation.
I1007 17:39:01.615416  5078 net.cpp:198] BatchNorm9 needs backward computation.
I1007 17:39:01.615418  5078 net.cpp:198] Convolution9 needs backward computation.
I1007 17:39:01.615420  5078 net.cpp:198] penlu8 needs backward computation.
I1007 17:39:01.615424  5078 net.cpp:198] Scale8 needs backward computation.
I1007 17:39:01.615432  5078 net.cpp:198] BatchNorm8 needs backward computation.
I1007 17:39:01.615435  5078 net.cpp:198] Convolution8 needs backward computation.
I1007 17:39:01.615438  5078 net.cpp:198] Eltwise3_penlu7_0_split needs backward computation.
I1007 17:39:01.615442  5078 net.cpp:198] penlu7 needs backward computation.
I1007 17:39:01.615444  5078 net.cpp:198] Eltwise3 needs backward computation.
I1007 17:39:01.615447  5078 net.cpp:198] Scale7 needs backward computation.
I1007 17:39:01.615449  5078 net.cpp:198] BatchNorm7 needs backward computation.
I1007 17:39:01.615451  5078 net.cpp:198] Convolution7 needs backward computation.
I1007 17:39:01.615454  5078 net.cpp:198] penlu6 needs backward computation.
I1007 17:39:01.615456  5078 net.cpp:198] Scale6 needs backward computation.
I1007 17:39:01.615458  5078 net.cpp:198] BatchNorm6 needs backward computation.
I1007 17:39:01.615461  5078 net.cpp:198] Convolution6 needs backward computation.
I1007 17:39:01.615463  5078 net.cpp:198] Eltwise2_penlu5_0_split needs backward computation.
I1007 17:39:01.615466  5078 net.cpp:198] penlu5 needs backward computation.
I1007 17:39:01.615469  5078 net.cpp:198] Eltwise2 needs backward computation.
I1007 17:39:01.615473  5078 net.cpp:198] Scale5 needs backward computation.
I1007 17:39:01.615476  5078 net.cpp:198] BatchNorm5 needs backward computation.
I1007 17:39:01.615478  5078 net.cpp:198] Convolution5 needs backward computation.
I1007 17:39:01.615481  5078 net.cpp:198] penlu4 needs backward computation.
I1007 17:39:01.615483  5078 net.cpp:198] Scale4 needs backward computation.
I1007 17:39:01.615486  5078 net.cpp:198] BatchNorm4 needs backward computation.
I1007 17:39:01.615489  5078 net.cpp:198] Convolution4 needs backward computation.
I1007 17:39:01.615491  5078 net.cpp:198] Eltwise1_penlu3_0_split needs backward computation.
I1007 17:39:01.615494  5078 net.cpp:198] penlu3 needs backward computation.
I1007 17:39:01.615496  5078 net.cpp:198] Eltwise1 needs backward computation.
I1007 17:39:01.615499  5078 net.cpp:198] Scale3 needs backward computation.
I1007 17:39:01.615501  5078 net.cpp:198] BatchNorm3 needs backward computation.
I1007 17:39:01.615504  5078 net.cpp:198] Convolution3 needs backward computation.
I1007 17:39:01.615506  5078 net.cpp:198] penlu2 needs backward computation.
I1007 17:39:01.615509  5078 net.cpp:198] Scale2 needs backward computation.
I1007 17:39:01.615511  5078 net.cpp:198] BatchNorm2 needs backward computation.
I1007 17:39:01.615514  5078 net.cpp:198] Convolution2 needs backward computation.
I1007 17:39:01.615516  5078 net.cpp:198] Convolution1_penlu1_0_split needs backward computation.
I1007 17:39:01.615520  5078 net.cpp:198] penlu1 needs backward computation.
I1007 17:39:01.615521  5078 net.cpp:198] Scale1 needs backward computation.
I1007 17:39:01.615525  5078 net.cpp:198] BatchNorm1 needs backward computation.
I1007 17:39:01.615526  5078 net.cpp:198] Convolution1 needs backward computation.
I1007 17:39:01.615530  5078 net.cpp:200] Data2_Data1_1_split does not need backward computation.
I1007 17:39:01.615533  5078 net.cpp:200] Data1 does not need backward computation.
I1007 17:39:01.615535  5078 net.cpp:242] This network produces output Accuracy1
I1007 17:39:01.615538  5078 net.cpp:242] This network produces output SoftmaxWithLoss1
I1007 17:39:01.615597  5078 net.cpp:255] Network initialization done.
I1007 17:39:01.616037  5078 solver.cpp:56] Solver scaffolding done.
I1007 17:39:01.625038  5078 caffe.cpp:248] Starting Optimization
I1007 17:39:01.625051  5078 solver.cpp:272] Solving resnet_cifar10
I1007 17:39:01.625054  5078 solver.cpp:273] Learning Rate Policy: multistep
I1007 17:39:01.628742  5078 solver.cpp:330] Iteration 0, Testing net (#0)
I1007 17:39:03.587347  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:39:03.666297  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.1
I1007 17:39:03.666326  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 87.3365 (* 1 = 87.3365 loss)
I1007 17:39:03.781296  5078 solver.cpp:218] Iteration 0 (0.10558 iter/s, 2.15616s/100 iters), loss = 2.3032
I1007 17:39:03.781347  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 2.3032 (* 1 = 2.3032 loss)
I1007 17:39:03.781389  5078 sgd_solver.cpp:105] Iteration 0, lr = 0.1
I1007 17:39:12.106355  5078 solver.cpp:218] Iteration 100 (12.0121 iter/s, 8.32495s/100 iters), loss = 1.54297
I1007 17:39:12.106385  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.54297 (* 1 = 1.54297 loss)
I1007 17:39:12.106403  5078 sgd_solver.cpp:105] Iteration 100, lr = 0.1
I1007 17:39:20.431856  5078 solver.cpp:218] Iteration 200 (12.0114 iter/s, 8.32542s/100 iters), loss = 1.55799
I1007 17:39:20.431890  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.55799 (* 1 = 1.55799 loss)
I1007 17:39:20.431907  5078 sgd_solver.cpp:105] Iteration 200, lr = 0.1
I1007 17:39:28.756775  5078 solver.cpp:218] Iteration 300 (12.0123 iter/s, 8.32483s/100 iters), loss = 1.34191
I1007 17:39:28.756808  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.34191 (* 1 = 1.34191 loss)
I1007 17:39:28.756815  5078 sgd_solver.cpp:105] Iteration 300, lr = 0.1
I1007 17:39:37.163023  5078 solver.cpp:218] Iteration 400 (11.896 iter/s, 8.40616s/100 iters), loss = 1.10274
I1007 17:39:37.163102  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.10274 (* 1 = 1.10274 loss)
I1007 17:39:37.163112  5078 sgd_solver.cpp:105] Iteration 400, lr = 0.1
I1007 17:39:45.100973  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:39:45.435940  5078 solver.cpp:330] Iteration 500, Testing net (#0)
I1007 17:39:47.364693  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:39:47.444473  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.4354
I1007 17:39:47.444499  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.78405 (* 1 = 1.78405 loss)
I1007 17:39:47.527770  5078 solver.cpp:218] Iteration 500 (9.64822 iter/s, 10.3646s/100 iters), loss = 1.17218
I1007 17:39:47.527801  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.17218 (* 1 = 1.17218 loss)
I1007 17:39:47.527809  5078 sgd_solver.cpp:105] Iteration 500, lr = 0.1
I1007 17:39:55.922758  5078 solver.cpp:218] Iteration 600 (11.912 iter/s, 8.39491s/100 iters), loss = 1.0018
I1007 17:39:55.922791  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.0018 (* 1 = 1.0018 loss)
I1007 17:39:55.922798  5078 sgd_solver.cpp:105] Iteration 600, lr = 0.1
I1007 17:40:04.328841  5078 solver.cpp:218] Iteration 700 (11.8963 iter/s, 8.406s/100 iters), loss = 1.08771
I1007 17:40:04.328876  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.08771 (* 1 = 1.08771 loss)
I1007 17:40:04.328883  5078 sgd_solver.cpp:105] Iteration 700, lr = 0.1
I1007 17:40:12.757221  5078 solver.cpp:218] Iteration 800 (11.8648 iter/s, 8.4283s/100 iters), loss = 0.974395
I1007 17:40:12.757298  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.974395 (* 1 = 0.974395 loss)
I1007 17:40:12.757311  5078 sgd_solver.cpp:105] Iteration 800, lr = 0.1
I1007 17:40:21.146030  5078 solver.cpp:218] Iteration 900 (11.9208 iter/s, 8.38869s/100 iters), loss = 0.885238
I1007 17:40:21.146064  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.885238 (* 1 = 0.885238 loss)
I1007 17:40:21.146073  5078 sgd_solver.cpp:105] Iteration 900, lr = 0.1
I1007 17:40:29.076249  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:40:29.422454  5078 solver.cpp:330] Iteration 1000, Testing net (#0)
I1007 17:40:31.348980  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:40:31.429472  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.5407
I1007 17:40:31.429499  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.21174 (* 1 = 1.21174 loss)
I1007 17:40:31.513821  5078 solver.cpp:218] Iteration 1000 (9.64533 iter/s, 10.3677s/100 iters), loss = 0.935827
I1007 17:40:31.513857  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.935827 (* 1 = 0.935827 loss)
I1007 17:40:31.513867  5078 sgd_solver.cpp:105] Iteration 1000, lr = 0.1
I1007 17:40:39.965852  5078 solver.cpp:218] Iteration 1100 (11.8316 iter/s, 8.45196s/100 iters), loss = 0.794756
I1007 17:40:39.965883  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.794756 (* 1 = 0.794756 loss)
I1007 17:40:39.965901  5078 sgd_solver.cpp:105] Iteration 1100, lr = 0.1
I1007 17:40:48.300433  5078 solver.cpp:218] Iteration 1200 (11.9983 iter/s, 8.33451s/100 iters), loss = 0.778513
I1007 17:40:48.300550  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.778513 (* 1 = 0.778513 loss)
I1007 17:40:48.300565  5078 sgd_solver.cpp:105] Iteration 1200, lr = 0.1
I1007 17:40:56.683666  5078 solver.cpp:218] Iteration 1300 (11.9288 iter/s, 8.38308s/100 iters), loss = 0.811513
I1007 17:40:56.683701  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.811513 (* 1 = 0.811513 loss)
I1007 17:40:56.683719  5078 sgd_solver.cpp:105] Iteration 1300, lr = 0.1
I1007 17:41:05.120064  5078 solver.cpp:218] Iteration 1400 (11.8535 iter/s, 8.43633s/100 iters), loss = 0.788189
I1007 17:41:05.120095  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.788189 (* 1 = 0.788189 loss)
I1007 17:41:05.120103  5078 sgd_solver.cpp:105] Iteration 1400, lr = 0.1
I1007 17:41:13.068918  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:41:13.404481  5078 solver.cpp:330] Iteration 1500, Testing net (#0)
I1007 17:41:15.325387  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:41:15.405441  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.5014
I1007 17:41:15.405477  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.33378 (* 1 = 1.33378 loss)
I1007 17:41:15.488687  5078 solver.cpp:218] Iteration 1500 (9.64455 iter/s, 10.3686s/100 iters), loss = 0.767781
I1007 17:41:15.488713  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.767781 (* 1 = 0.767781 loss)
I1007 17:41:15.488720  5078 sgd_solver.cpp:105] Iteration 1500, lr = 0.1
I1007 17:41:23.862082  5078 solver.cpp:218] Iteration 1600 (11.9427 iter/s, 8.37334s/100 iters), loss = 0.611982
I1007 17:41:23.862174  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.611982 (* 1 = 0.611982 loss)
I1007 17:41:23.862190  5078 sgd_solver.cpp:105] Iteration 1600, lr = 0.1
I1007 17:41:32.340363  5078 solver.cpp:218] Iteration 1700 (11.795 iter/s, 8.47816s/100 iters), loss = 0.635102
I1007 17:41:32.340394  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.635102 (* 1 = 0.635102 loss)
I1007 17:41:32.340410  5078 sgd_solver.cpp:105] Iteration 1700, lr = 0.1
I1007 17:41:40.718824  5078 solver.cpp:218] Iteration 1800 (11.9355 iter/s, 8.3784s/100 iters), loss = 0.778415
I1007 17:41:40.718858  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.778415 (* 1 = 0.778415 loss)
I1007 17:41:40.718865  5078 sgd_solver.cpp:105] Iteration 1800, lr = 0.1
I1007 17:41:49.081408  5078 solver.cpp:218] Iteration 1900 (11.9581 iter/s, 8.36252s/100 iters), loss = 0.647723
I1007 17:41:49.081439  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.647723 (* 1 = 0.647723 loss)
I1007 17:41:49.081446  5078 sgd_solver.cpp:105] Iteration 1900, lr = 0.1
I1007 17:41:57.042898  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:41:57.375891  5078 solver.cpp:330] Iteration 2000, Testing net (#0)
I1007 17:41:59.299379  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:41:59.378844  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.448
I1007 17:41:59.378880  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.60823 (* 1 = 1.60823 loss)
I1007 17:41:59.461917  5078 solver.cpp:218] Iteration 2000 (9.6335 iter/s, 10.3804s/100 iters), loss = 0.622828
I1007 17:41:59.461943  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.622828 (* 1 = 0.622828 loss)
I1007 17:41:59.461951  5078 sgd_solver.cpp:105] Iteration 2000, lr = 0.1
I1007 17:42:07.796125  5078 solver.cpp:218] Iteration 2100 (11.9988 iter/s, 8.33415s/100 iters), loss = 0.597571
I1007 17:42:07.796156  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.597571 (* 1 = 0.597571 loss)
I1007 17:42:07.796162  5078 sgd_solver.cpp:105] Iteration 2100, lr = 0.1
I1007 17:42:16.133361  5078 solver.cpp:218] Iteration 2200 (11.9945 iter/s, 8.33717s/100 iters), loss = 0.630331
I1007 17:42:16.133391  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.630331 (* 1 = 0.630331 loss)
I1007 17:42:16.133397  5078 sgd_solver.cpp:105] Iteration 2200, lr = 0.1
I1007 17:42:24.482713  5078 solver.cpp:218] Iteration 2300 (11.9771 iter/s, 8.34929s/100 iters), loss = 0.702791
I1007 17:42:24.482753  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.702791 (* 1 = 0.702791 loss)
I1007 17:42:24.482759  5078 sgd_solver.cpp:105] Iteration 2300, lr = 0.1
I1007 17:42:32.883245  5078 solver.cpp:218] Iteration 2400 (11.9041 iter/s, 8.40046s/100 iters), loss = 0.65258
I1007 17:42:32.883363  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.65258 (* 1 = 0.65258 loss)
I1007 17:42:32.883373  5078 sgd_solver.cpp:105] Iteration 2400, lr = 0.1
I1007 17:42:40.827816  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:42:41.162346  5078 solver.cpp:330] Iteration 2500, Testing net (#0)
I1007 17:42:43.085957  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:42:43.166235  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.378
I1007 17:42:43.166271  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.92493 (* 1 = 1.92493 loss)
I1007 17:42:43.249330  5078 solver.cpp:218] Iteration 2500 (9.64699 iter/s, 10.3659s/100 iters), loss = 0.580631
I1007 17:42:43.249361  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.580631 (* 1 = 0.580631 loss)
I1007 17:42:43.249368  5078 sgd_solver.cpp:105] Iteration 2500, lr = 0.1
I1007 17:42:51.604003  5078 solver.cpp:218] Iteration 2600 (11.9694 iter/s, 8.35461s/100 iters), loss = 0.459078
I1007 17:42:51.604043  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.459078 (* 1 = 0.459078 loss)
I1007 17:42:51.604049  5078 sgd_solver.cpp:105] Iteration 2600, lr = 0.1
I1007 17:42:59.926265  5078 solver.cpp:218] Iteration 2700 (12.0161 iter/s, 8.32219s/100 iters), loss = 0.44884
I1007 17:42:59.926295  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.44884 (* 1 = 0.44884 loss)
I1007 17:42:59.926301  5078 sgd_solver.cpp:105] Iteration 2700, lr = 0.1
I1007 17:43:08.313033  5078 solver.cpp:218] Iteration 2800 (11.9236 iter/s, 8.3867s/100 iters), loss = 0.669374
I1007 17:43:08.313153  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.669374 (* 1 = 0.669374 loss)
I1007 17:43:08.313171  5078 sgd_solver.cpp:105] Iteration 2800, lr = 0.1
I1007 17:43:16.668923  5078 solver.cpp:218] Iteration 2900 (11.9678 iter/s, 8.35572s/100 iters), loss = 0.562228
I1007 17:43:16.668968  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.562228 (* 1 = 0.562228 loss)
I1007 17:43:16.668977  5078 sgd_solver.cpp:105] Iteration 2900, lr = 0.1
I1007 17:43:24.624043  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:43:24.960535  5078 solver.cpp:330] Iteration 3000, Testing net (#0)
I1007 17:43:26.889318  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:43:26.969353  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.4625
I1007 17:43:26.969389  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.65992 (* 1 = 1.65992 loss)
I1007 17:43:27.052951  5078 solver.cpp:218] Iteration 3000 (9.63025 iter/s, 10.3839s/100 iters), loss = 0.472703
I1007 17:43:27.052976  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.472703 (* 1 = 0.472703 loss)
I1007 17:43:27.052983  5078 sgd_solver.cpp:105] Iteration 3000, lr = 0.1
I1007 17:43:35.482149  5078 solver.cpp:218] Iteration 3100 (11.8636 iter/s, 8.42914s/100 iters), loss = 0.437572
I1007 17:43:35.482178  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.437572 (* 1 = 0.437572 loss)
I1007 17:43:35.482184  5078 sgd_solver.cpp:105] Iteration 3100, lr = 0.1
I1007 17:43:43.853024  5078 solver.cpp:218] Iteration 3200 (11.9463 iter/s, 8.37081s/100 iters), loss = 0.471462
I1007 17:43:43.853152  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.471462 (* 1 = 0.471462 loss)
I1007 17:43:43.853160  5078 sgd_solver.cpp:105] Iteration 3200, lr = 0.1
I1007 17:43:52.245520  5078 solver.cpp:218] Iteration 3300 (11.9156 iter/s, 8.39233s/100 iters), loss = 0.556494
I1007 17:43:52.245554  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.556494 (* 1 = 0.556494 loss)
I1007 17:43:52.245563  5078 sgd_solver.cpp:105] Iteration 3300, lr = 0.1
I1007 17:44:00.617388  5078 solver.cpp:218] Iteration 3400 (11.9449 iter/s, 8.3718s/100 iters), loss = 0.536603
I1007 17:44:00.617419  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.536603 (* 1 = 0.536603 loss)
I1007 17:44:00.617434  5078 sgd_solver.cpp:105] Iteration 3400, lr = 0.1
I1007 17:44:08.574828  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:44:08.909255  5078 solver.cpp:330] Iteration 3500, Testing net (#0)
I1007 17:44:10.842084  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:44:10.922009  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.4089
I1007 17:44:10.922045  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.75821 (* 1 = 1.75821 loss)
I1007 17:44:11.005033  5078 solver.cpp:218] Iteration 3500 (9.62689 iter/s, 10.3876s/100 iters), loss = 0.563233
I1007 17:44:11.005058  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.563233 (* 1 = 0.563233 loss)
I1007 17:44:11.005064  5078 sgd_solver.cpp:105] Iteration 3500, lr = 0.1
I1007 17:44:19.375586  5078 solver.cpp:218] Iteration 3600 (11.9467 iter/s, 8.37049s/100 iters), loss = 0.414835
I1007 17:44:19.375679  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.414835 (* 1 = 0.414835 loss)
I1007 17:44:19.375686  5078 sgd_solver.cpp:105] Iteration 3600, lr = 0.1
I1007 17:44:27.757688  5078 solver.cpp:218] Iteration 3700 (11.9304 iter/s, 8.38198s/100 iters), loss = 0.397961
I1007 17:44:27.757730  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.397961 (* 1 = 0.397961 loss)
I1007 17:44:27.757736  5078 sgd_solver.cpp:105] Iteration 3700, lr = 0.1
I1007 17:44:36.129143  5078 solver.cpp:218] Iteration 3800 (11.9455 iter/s, 8.37138s/100 iters), loss = 0.567541
I1007 17:44:36.129184  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.567541 (* 1 = 0.567541 loss)
I1007 17:44:36.129190  5078 sgd_solver.cpp:105] Iteration 3800, lr = 0.1
I1007 17:44:44.505722  5078 solver.cpp:218] Iteration 3900 (11.9382 iter/s, 8.3765s/100 iters), loss = 0.488761
I1007 17:44:44.505762  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.488761 (* 1 = 0.488761 loss)
I1007 17:44:44.505769  5078 sgd_solver.cpp:105] Iteration 3900, lr = 0.1
I1007 17:44:52.464335  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:44:52.797927  5078 solver.cpp:330] Iteration 4000, Testing net (#0)
I1007 17:44:54.725795  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:44:54.806500  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.5628
I1007 17:44:54.806525  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.26901 (* 1 = 1.26901 loss)
I1007 17:44:54.889556  5078 solver.cpp:218] Iteration 4000 (9.63043 iter/s, 10.3838s/100 iters), loss = 0.40488
I1007 17:44:54.889596  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.40488 (* 1 = 0.40488 loss)
I1007 17:44:54.889603  5078 sgd_solver.cpp:105] Iteration 4000, lr = 0.1
I1007 17:45:03.285737  5078 solver.cpp:218] Iteration 4100 (11.9103 iter/s, 8.3961s/100 iters), loss = 0.465819
I1007 17:45:03.285773  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.465819 (* 1 = 0.465819 loss)
I1007 17:45:03.285779  5078 sgd_solver.cpp:105] Iteration 4100, lr = 0.1
I1007 17:45:11.677124  5078 solver.cpp:218] Iteration 4200 (11.9173 iter/s, 8.39116s/100 iters), loss = 0.435125
I1007 17:45:11.677157  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.435125 (* 1 = 0.435125 loss)
I1007 17:45:11.677165  5078 sgd_solver.cpp:105] Iteration 4200, lr = 0.1
I1007 17:45:20.071442  5078 solver.cpp:218] Iteration 4300 (11.9129 iter/s, 8.39425s/100 iters), loss = 0.50057
I1007 17:45:20.071475  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.50057 (* 1 = 0.50057 loss)
I1007 17:45:20.071482  5078 sgd_solver.cpp:105] Iteration 4300, lr = 0.1
I1007 17:45:28.467521  5078 solver.cpp:218] Iteration 4400 (11.9104 iter/s, 8.39601s/100 iters), loss = 0.405623
I1007 17:45:28.467697  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.405623 (* 1 = 0.405623 loss)
I1007 17:45:28.467706  5078 sgd_solver.cpp:105] Iteration 4400, lr = 0.1
I1007 17:45:36.459086  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:45:36.795380  5078 solver.cpp:330] Iteration 4500, Testing net (#0)
I1007 17:45:38.764847  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:45:38.845190  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.4985
I1007 17:45:38.845214  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.47896 (* 1 = 1.47896 loss)
I1007 17:45:38.928745  5078 solver.cpp:218] Iteration 4500 (9.55929 iter/s, 10.461s/100 iters), loss = 0.398553
I1007 17:45:38.928769  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.398553 (* 1 = 0.398553 loss)
I1007 17:45:38.928777  5078 sgd_solver.cpp:105] Iteration 4500, lr = 0.1
I1007 17:45:47.309327  5078 solver.cpp:218] Iteration 4600 (11.9324 iter/s, 8.38052s/100 iters), loss = 0.279598
I1007 17:45:47.309370  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.279598 (* 1 = 0.279598 loss)
I1007 17:45:47.309376  5078 sgd_solver.cpp:105] Iteration 4600, lr = 0.1
I1007 17:45:55.680197  5078 solver.cpp:218] Iteration 4700 (11.9463 iter/s, 8.3708s/100 iters), loss = 0.287495
I1007 17:45:55.680227  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.287495 (* 1 = 0.287495 loss)
I1007 17:45:55.680243  5078 sgd_solver.cpp:105] Iteration 4700, lr = 0.1
I1007 17:46:04.036361  5078 solver.cpp:218] Iteration 4800 (11.9673 iter/s, 8.3561s/100 iters), loss = 0.467006
I1007 17:46:04.036463  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.467006 (* 1 = 0.467006 loss)
I1007 17:46:04.036471  5078 sgd_solver.cpp:105] Iteration 4800, lr = 0.1
I1007 17:46:12.455297  5078 solver.cpp:218] Iteration 4900 (11.8782 iter/s, 8.41881s/100 iters), loss = 0.372658
I1007 17:46:12.455328  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.372658 (* 1 = 0.372658 loss)
I1007 17:46:12.455344  5078 sgd_solver.cpp:105] Iteration 4900, lr = 0.1
I1007 17:46:20.398649  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:46:20.732249  5078 solver.cpp:330] Iteration 5000, Testing net (#0)
I1007 17:46:22.676895  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:46:22.763866  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6963
I1007 17:46:22.763903  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.947362 (* 1 = 0.947362 loss)
I1007 17:46:22.849826  5078 solver.cpp:218] Iteration 5000 (9.62051 iter/s, 10.3945s/100 iters), loss = 0.348676
I1007 17:46:22.849858  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.348676 (* 1 = 0.348676 loss)
I1007 17:46:22.849864  5078 sgd_solver.cpp:105] Iteration 5000, lr = 0.1
I1007 17:46:31.219100  5078 solver.cpp:218] Iteration 5100 (11.9486 iter/s, 8.36921s/100 iters), loss = 0.353832
I1007 17:46:31.219130  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.353832 (* 1 = 0.353832 loss)
I1007 17:46:31.219136  5078 sgd_solver.cpp:105] Iteration 5100, lr = 0.1
I1007 17:46:39.694782  5078 solver.cpp:218] Iteration 5200 (11.7985 iter/s, 8.47562s/100 iters), loss = 0.368854
I1007 17:46:39.694906  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.368854 (* 1 = 0.368854 loss)
I1007 17:46:39.694913  5078 sgd_solver.cpp:105] Iteration 5200, lr = 0.1
I1007 17:46:48.101308  5078 solver.cpp:218] Iteration 5300 (11.8957 iter/s, 8.40637s/100 iters), loss = 0.515264
I1007 17:46:48.101339  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.515264 (* 1 = 0.515264 loss)
I1007 17:46:48.101346  5078 sgd_solver.cpp:105] Iteration 5300, lr = 0.1
I1007 17:46:56.486428  5078 solver.cpp:218] Iteration 5400 (11.926 iter/s, 8.38506s/100 iters), loss = 0.423254
I1007 17:46:56.486469  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.423254 (* 1 = 0.423254 loss)
I1007 17:46:56.486475  5078 sgd_solver.cpp:105] Iteration 5400, lr = 0.1
I1007 17:47:04.443362  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:47:04.782577  5078 solver.cpp:330] Iteration 5500, Testing net (#0)
I1007 17:47:06.722148  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:47:06.802115  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7556
I1007 17:47:06.802150  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.757789 (* 1 = 0.757789 loss)
I1007 17:47:06.885884  5078 solver.cpp:218] Iteration 5500 (9.61596 iter/s, 10.3994s/100 iters), loss = 0.315458
I1007 17:47:06.885912  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.315458 (* 1 = 0.315458 loss)
I1007 17:47:06.885920  5078 sgd_solver.cpp:105] Iteration 5500, lr = 0.1
I1007 17:47:15.262084  5078 solver.cpp:218] Iteration 5600 (11.9387 iter/s, 8.37614s/100 iters), loss = 0.288576
I1007 17:47:15.262194  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.288576 (* 1 = 0.288576 loss)
I1007 17:47:15.262202  5078 sgd_solver.cpp:105] Iteration 5600, lr = 0.1
I1007 17:47:23.620617  5078 solver.cpp:218] Iteration 5700 (11.964 iter/s, 8.3584s/100 iters), loss = 0.328667
I1007 17:47:23.620652  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.328667 (* 1 = 0.328667 loss)
I1007 17:47:23.620661  5078 sgd_solver.cpp:105] Iteration 5700, lr = 0.1
I1007 17:47:31.974239  5078 solver.cpp:218] Iteration 5800 (11.971 iter/s, 8.35356s/100 iters), loss = 0.432051
I1007 17:47:31.974272  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.432051 (* 1 = 0.432051 loss)
I1007 17:47:31.974282  5078 sgd_solver.cpp:105] Iteration 5800, lr = 0.1
I1007 17:47:40.480357  5078 solver.cpp:218] Iteration 5900 (11.7563 iter/s, 8.50605s/100 iters), loss = 0.383655
I1007 17:47:40.480387  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.383655 (* 1 = 0.383655 loss)
I1007 17:47:40.480394  5078 sgd_solver.cpp:105] Iteration 5900, lr = 0.1
I1007 17:47:48.425230  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:47:48.758455  5078 solver.cpp:330] Iteration 6000, Testing net (#0)
I1007 17:47:50.690377  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:47:50.770752  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7301
I1007 17:47:50.770788  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.789383 (* 1 = 0.789383 loss)
I1007 17:47:50.854001  5078 solver.cpp:218] Iteration 6000 (9.63988 iter/s, 10.3736s/100 iters), loss = 0.347028
I1007 17:47:50.854027  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.347028 (* 1 = 0.347028 loss)
I1007 17:47:50.854034  5078 sgd_solver.cpp:105] Iteration 6000, lr = 0.1
I1007 17:47:59.322911  5078 solver.cpp:218] Iteration 6100 (11.808 iter/s, 8.46885s/100 iters), loss = 0.360544
I1007 17:47:59.322942  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.360544 (* 1 = 0.360544 loss)
I1007 17:47:59.322947  5078 sgd_solver.cpp:105] Iteration 6100, lr = 0.1
I1007 17:48:07.780608  5078 solver.cpp:218] Iteration 6200 (11.8236 iter/s, 8.45764s/100 iters), loss = 0.327568
I1007 17:48:07.780649  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.327568 (* 1 = 0.327568 loss)
I1007 17:48:07.780655  5078 sgd_solver.cpp:105] Iteration 6200, lr = 0.1
I1007 17:48:16.147979  5078 solver.cpp:218] Iteration 6300 (11.9513 iter/s, 8.3673s/100 iters), loss = 0.375199
I1007 17:48:16.148013  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.375199 (* 1 = 0.375199 loss)
I1007 17:48:16.148020  5078 sgd_solver.cpp:105] Iteration 6300, lr = 0.1
I1007 17:48:24.514451  5078 solver.cpp:218] Iteration 6400 (11.9526 iter/s, 8.36641s/100 iters), loss = 0.438537
I1007 17:48:24.514585  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.438537 (* 1 = 0.438537 loss)
I1007 17:48:24.514603  5078 sgd_solver.cpp:105] Iteration 6400, lr = 0.1
I1007 17:48:32.440374  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:48:32.773386  5078 solver.cpp:330] Iteration 6500, Testing net (#0)
I1007 17:48:34.697995  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:48:34.778261  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7347
I1007 17:48:34.778297  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.790262 (* 1 = 0.790262 loss)
I1007 17:48:34.862370  5078 solver.cpp:218] Iteration 6500 (9.66394 iter/s, 10.3477s/100 iters), loss = 0.377787
I1007 17:48:34.862397  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.377787 (* 1 = 0.377787 loss)
I1007 17:48:34.862404  5078 sgd_solver.cpp:105] Iteration 6500, lr = 0.1
I1007 17:48:43.229562  5078 solver.cpp:218] Iteration 6600 (11.9515 iter/s, 8.36713s/100 iters), loss = 0.296082
I1007 17:48:43.229593  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.296082 (* 1 = 0.296082 loss)
I1007 17:48:43.229600  5078 sgd_solver.cpp:105] Iteration 6600, lr = 0.1
I1007 17:48:51.695106  5078 solver.cpp:218] Iteration 6700 (11.8127 iter/s, 8.46548s/100 iters), loss = 0.323848
I1007 17:48:51.695137  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.323848 (* 1 = 0.323848 loss)
I1007 17:48:51.695143  5078 sgd_solver.cpp:105] Iteration 6700, lr = 0.1
I1007 17:49:00.040815  5078 solver.cpp:218] Iteration 6800 (11.9823 iter/s, 8.34565s/100 iters), loss = 0.454448
I1007 17:49:00.040935  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.454448 (* 1 = 0.454448 loss)
I1007 17:49:00.040943  5078 sgd_solver.cpp:105] Iteration 6800, lr = 0.1
I1007 17:49:08.371563  5078 solver.cpp:218] Iteration 6900 (12.0039 iter/s, 8.3306s/100 iters), loss = 0.352253
I1007 17:49:08.371592  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.352253 (* 1 = 0.352253 loss)
I1007 17:49:08.371598  5078 sgd_solver.cpp:105] Iteration 6900, lr = 0.1
I1007 17:49:16.305752  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:49:16.638963  5078 solver.cpp:330] Iteration 7000, Testing net (#0)
I1007 17:49:18.566653  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:49:18.647469  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7581
I1007 17:49:18.647505  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.707342 (* 1 = 0.707342 loss)
I1007 17:49:18.730741  5078 solver.cpp:218] Iteration 7000 (9.65334 iter/s, 10.3591s/100 iters), loss = 0.280973
I1007 17:49:18.730765  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.280973 (* 1 = 0.280973 loss)
I1007 17:49:18.730772  5078 sgd_solver.cpp:105] Iteration 7000, lr = 0.1
I1007 17:49:27.071183  5078 solver.cpp:218] Iteration 7100 (11.9899 iter/s, 8.34037s/100 iters), loss = 0.337477
I1007 17:49:27.071221  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.337477 (* 1 = 0.337477 loss)
I1007 17:49:27.071238  5078 sgd_solver.cpp:105] Iteration 7100, lr = 0.1
I1007 17:49:35.418983  5078 solver.cpp:218] Iteration 7200 (11.9793 iter/s, 8.34773s/100 iters), loss = 0.380955
I1007 17:49:35.419128  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.380955 (* 1 = 0.380955 loss)
I1007 17:49:35.419137  5078 sgd_solver.cpp:105] Iteration 7200, lr = 0.1
I1007 17:49:43.761519  5078 solver.cpp:218] Iteration 7300 (11.987 iter/s, 8.34237s/100 iters), loss = 0.366662
I1007 17:49:43.761560  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.366662 (* 1 = 0.366662 loss)
I1007 17:49:43.761567  5078 sgd_solver.cpp:105] Iteration 7300, lr = 0.1
I1007 17:49:52.108450  5078 solver.cpp:218] Iteration 7400 (11.9806 iter/s, 8.34686s/100 iters), loss = 0.360646
I1007 17:49:52.108490  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.360646 (* 1 = 0.360646 loss)
I1007 17:49:52.108495  5078 sgd_solver.cpp:105] Iteration 7400, lr = 0.1
I1007 17:50:00.039144  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:50:00.373704  5078 solver.cpp:330] Iteration 7500, Testing net (#0)
I1007 17:50:02.300814  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:50:02.380942  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7799
I1007 17:50:02.380980  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.650178 (* 1 = 0.650178 loss)
I1007 17:50:02.464761  5078 solver.cpp:218] Iteration 7500 (9.65601 iter/s, 10.3562s/100 iters), loss = 0.272787
I1007 17:50:02.464788  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.272787 (* 1 = 0.272787 loss)
I1007 17:50:02.464794  5078 sgd_solver.cpp:105] Iteration 7500, lr = 0.1
I1007 17:50:10.813455  5078 solver.cpp:218] Iteration 7600 (11.978 iter/s, 8.34863s/100 iters), loss = 0.338515
I1007 17:50:10.813592  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.338515 (* 1 = 0.338515 loss)
I1007 17:50:10.813599  5078 sgd_solver.cpp:105] Iteration 7600, lr = 0.1
I1007 17:50:19.151166  5078 solver.cpp:218] Iteration 7700 (11.9939 iter/s, 8.33754s/100 iters), loss = 0.359789
I1007 17:50:19.151196  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.359788 (* 1 = 0.359788 loss)
I1007 17:50:19.151202  5078 sgd_solver.cpp:105] Iteration 7700, lr = 0.1
I1007 17:50:27.497314  5078 solver.cpp:218] Iteration 7800 (11.9817 iter/s, 8.34609s/100 iters), loss = 0.412786
I1007 17:50:27.497344  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.412786 (* 1 = 0.412786 loss)
I1007 17:50:27.497349  5078 sgd_solver.cpp:105] Iteration 7800, lr = 0.1
I1007 17:50:35.831370  5078 solver.cpp:218] Iteration 7900 (11.999 iter/s, 8.334s/100 iters), loss = 0.304121
I1007 17:50:35.831400  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.304121 (* 1 = 0.304121 loss)
I1007 17:50:35.831406  5078 sgd_solver.cpp:105] Iteration 7900, lr = 0.1
I1007 17:50:43.760583  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:50:44.094725  5078 solver.cpp:330] Iteration 8000, Testing net (#0)
I1007 17:50:46.021908  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:50:46.102840  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7402
I1007 17:50:46.102876  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.822406 (* 1 = 0.822406 loss)
I1007 17:50:46.185892  5078 solver.cpp:218] Iteration 8000 (9.65768 iter/s, 10.3545s/100 iters), loss = 0.260796
I1007 17:50:46.185919  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.260796 (* 1 = 0.260796 loss)
I1007 17:50:46.185925  5078 sgd_solver.cpp:105] Iteration 8000, lr = 0.1
I1007 17:50:54.525568  5078 solver.cpp:218] Iteration 8100 (11.991 iter/s, 8.33962s/100 iters), loss = 0.341559
I1007 17:50:54.525599  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.341559 (* 1 = 0.341559 loss)
I1007 17:50:54.525605  5078 sgd_solver.cpp:105] Iteration 8100, lr = 0.1
I1007 17:51:02.871851  5078 solver.cpp:218] Iteration 8200 (11.9815 iter/s, 8.34622s/100 iters), loss = 0.280855
I1007 17:51:02.871881  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.280855 (* 1 = 0.280855 loss)
I1007 17:51:02.871887  5078 sgd_solver.cpp:105] Iteration 8200, lr = 0.1
I1007 17:51:11.215957  5078 solver.cpp:218] Iteration 8300 (11.9846 iter/s, 8.34404s/100 iters), loss = 0.366768
I1007 17:51:11.215998  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.366768 (* 1 = 0.366768 loss)
I1007 17:51:11.216004  5078 sgd_solver.cpp:105] Iteration 8300, lr = 0.1
I1007 17:51:19.556594  5078 solver.cpp:218] Iteration 8400 (11.9896 iter/s, 8.34057s/100 iters), loss = 0.247733
I1007 17:51:19.556705  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.247733 (* 1 = 0.247733 loss)
I1007 17:51:19.556722  5078 sgd_solver.cpp:105] Iteration 8400, lr = 0.1
I1007 17:51:27.479498  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:51:27.813150  5078 solver.cpp:330] Iteration 8500, Testing net (#0)
I1007 17:51:29.739784  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:51:29.820163  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7983
I1007 17:51:29.820197  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.583122 (* 1 = 0.583122 loss)
I1007 17:51:29.904028  5078 solver.cpp:218] Iteration 8500 (9.66437 iter/s, 10.3473s/100 iters), loss = 0.373294
I1007 17:51:29.904057  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.373293 (* 1 = 0.373293 loss)
I1007 17:51:29.904063  5078 sgd_solver.cpp:105] Iteration 8500, lr = 0.1
I1007 17:51:38.248499  5078 solver.cpp:218] Iteration 8600 (11.9841 iter/s, 8.34441s/100 iters), loss = 0.294538
I1007 17:51:38.248530  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.294538 (* 1 = 0.294538 loss)
I1007 17:51:38.248536  5078 sgd_solver.cpp:105] Iteration 8600, lr = 0.1
I1007 17:51:46.591629  5078 solver.cpp:218] Iteration 8700 (11.986 iter/s, 8.34307s/100 iters), loss = 0.251624
I1007 17:51:46.591660  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.251624 (* 1 = 0.251624 loss)
I1007 17:51:46.591665  5078 sgd_solver.cpp:105] Iteration 8700, lr = 0.1
I1007 17:51:54.940955  5078 solver.cpp:218] Iteration 8800 (11.9771 iter/s, 8.34927s/100 iters), loss = 0.325277
I1007 17:51:54.941057  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.325277 (* 1 = 0.325277 loss)
I1007 17:51:54.941073  5078 sgd_solver.cpp:105] Iteration 8800, lr = 0.1
I1007 17:52:03.288677  5078 solver.cpp:218] Iteration 8900 (11.9795 iter/s, 8.34759s/100 iters), loss = 0.290993
I1007 17:52:03.288707  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.290992 (* 1 = 0.290992 loss)
I1007 17:52:03.288713  5078 sgd_solver.cpp:105] Iteration 8900, lr = 0.1
I1007 17:52:11.220523  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:52:11.554031  5078 solver.cpp:330] Iteration 9000, Testing net (#0)
I1007 17:52:13.481487  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:52:13.561983  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7253
I1007 17:52:13.562019  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.884087 (* 1 = 0.884087 loss)
I1007 17:52:13.644623  5078 solver.cpp:218] Iteration 9000 (9.65635 iter/s, 10.3559s/100 iters), loss = 0.270976
I1007 17:52:13.644649  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.270976 (* 1 = 0.270976 loss)
I1007 17:52:13.644655  5078 sgd_solver.cpp:105] Iteration 9000, lr = 0.1
I1007 17:52:21.984843  5078 solver.cpp:218] Iteration 9100 (11.9902 iter/s, 8.34017s/100 iters), loss = 0.326033
I1007 17:52:21.984871  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.326033 (* 1 = 0.326033 loss)
I1007 17:52:21.984877  5078 sgd_solver.cpp:105] Iteration 9100, lr = 0.1
I1007 17:52:30.326301  5078 solver.cpp:218] Iteration 9200 (11.9884 iter/s, 8.3414s/100 iters), loss = 0.351511
I1007 17:52:30.326421  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.351511 (* 1 = 0.351511 loss)
I1007 17:52:30.326428  5078 sgd_solver.cpp:105] Iteration 9200, lr = 0.1
I1007 17:52:38.666723  5078 solver.cpp:218] Iteration 9300 (11.99 iter/s, 8.34027s/100 iters), loss = 0.299964
I1007 17:52:38.666764  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.299964 (* 1 = 0.299964 loss)
I1007 17:52:38.666769  5078 sgd_solver.cpp:105] Iteration 9300, lr = 0.1
I1007 17:52:47.010758  5078 solver.cpp:218] Iteration 9400 (11.9847 iter/s, 8.34397s/100 iters), loss = 0.243344
I1007 17:52:47.010787  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.243343 (* 1 = 0.243343 loss)
I1007 17:52:47.010793  5078 sgd_solver.cpp:105] Iteration 9400, lr = 0.1
I1007 17:52:54.940871  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:52:55.275223  5078 solver.cpp:330] Iteration 9500, Testing net (#0)
I1007 17:52:57.200861  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:52:57.281536  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8034
I1007 17:52:57.281572  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.598123 (* 1 = 0.598123 loss)
I1007 17:52:57.365314  5078 solver.cpp:218] Iteration 9500 (9.65765 iter/s, 10.3545s/100 iters), loss = 0.295971
I1007 17:52:57.365340  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.295971 (* 1 = 0.295971 loss)
I1007 17:52:57.365347  5078 sgd_solver.cpp:105] Iteration 9500, lr = 0.1
I1007 17:53:05.720361  5078 solver.cpp:218] Iteration 9600 (11.9689 iter/s, 8.35499s/100 iters), loss = 0.200408
I1007 17:53:05.720485  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.200408 (* 1 = 0.200408 loss)
I1007 17:53:05.720494  5078 sgd_solver.cpp:105] Iteration 9600, lr = 0.1
I1007 17:53:14.068495  5078 solver.cpp:218] Iteration 9700 (11.9789 iter/s, 8.34798s/100 iters), loss = 0.317083
I1007 17:53:14.068536  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.317082 (* 1 = 0.317082 loss)
I1007 17:53:14.068542  5078 sgd_solver.cpp:105] Iteration 9700, lr = 0.1
I1007 17:53:22.419704  5078 solver.cpp:218] Iteration 9800 (11.9744 iter/s, 8.35114s/100 iters), loss = 0.342965
I1007 17:53:22.419745  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.342965 (* 1 = 0.342965 loss)
I1007 17:53:22.419750  5078 sgd_solver.cpp:105] Iteration 9800, lr = 0.1
I1007 17:53:30.769352  5078 solver.cpp:218] Iteration 9900 (11.9767 iter/s, 8.34958s/100 iters), loss = 0.208709
I1007 17:53:30.769392  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.208709 (* 1 = 0.208709 loss)
I1007 17:53:30.769398  5078 sgd_solver.cpp:105] Iteration 9900, lr = 0.1
I1007 17:53:38.709208  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:53:39.043648  5078 solver.cpp:330] Iteration 10000, Testing net (#0)
I1007 17:53:40.968696  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:53:41.049216  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7677
I1007 17:53:41.049250  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.7413 (* 1 = 0.7413 loss)
I1007 17:53:41.132391  5078 solver.cpp:218] Iteration 10000 (9.64975 iter/s, 10.363s/100 iters), loss = 0.236035
I1007 17:53:41.132419  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.236035 (* 1 = 0.236035 loss)
I1007 17:53:41.132426  5078 sgd_solver.cpp:105] Iteration 10000, lr = 0.1
I1007 17:53:49.471853  5078 solver.cpp:218] Iteration 10100 (11.9913 iter/s, 8.3394s/100 iters), loss = 0.345508
I1007 17:53:49.471894  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.345507 (* 1 = 0.345507 loss)
I1007 17:53:49.471899  5078 sgd_solver.cpp:105] Iteration 10100, lr = 0.1
I1007 17:53:57.816925  5078 solver.cpp:218] Iteration 10200 (11.9832 iter/s, 8.345s/100 iters), loss = 0.248821
I1007 17:53:57.816953  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.248821 (* 1 = 0.248821 loss)
I1007 17:53:57.816959  5078 sgd_solver.cpp:105] Iteration 10200, lr = 0.1
I1007 17:54:06.156332  5078 solver.cpp:218] Iteration 10300 (11.9913 iter/s, 8.33935s/100 iters), loss = 0.409483
I1007 17:54:06.156371  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.409483 (* 1 = 0.409483 loss)
I1007 17:54:06.156378  5078 sgd_solver.cpp:105] Iteration 10300, lr = 0.1
I1007 17:54:14.500946  5078 solver.cpp:218] Iteration 10400 (11.9839 iter/s, 8.34455s/100 iters), loss = 0.240475
I1007 17:54:14.501062  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.240474 (* 1 = 0.240474 loss)
I1007 17:54:14.501080  5078 sgd_solver.cpp:105] Iteration 10400, lr = 0.1
I1007 17:54:22.426111  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:54:22.760355  5078 solver.cpp:330] Iteration 10500, Testing net (#0)
I1007 17:54:24.687999  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:54:24.768216  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7492
I1007 17:54:24.768251  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.752683 (* 1 = 0.752683 loss)
I1007 17:54:24.851681  5078 solver.cpp:218] Iteration 10500 (9.66128 iter/s, 10.3506s/100 iters), loss = 0.298925
I1007 17:54:24.851711  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.298925 (* 1 = 0.298925 loss)
I1007 17:54:24.851717  5078 sgd_solver.cpp:105] Iteration 10500, lr = 0.1
I1007 17:54:33.202160  5078 solver.cpp:218] Iteration 10600 (11.9754 iter/s, 8.35042s/100 iters), loss = 0.329331
I1007 17:54:33.202200  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.32933 (* 1 = 0.32933 loss)
I1007 17:54:33.202206  5078 sgd_solver.cpp:105] Iteration 10600, lr = 0.1
I1007 17:54:41.543584  5078 solver.cpp:218] Iteration 10700 (11.9885 iter/s, 8.34135s/100 iters), loss = 0.232945
I1007 17:54:41.543614  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.232945 (* 1 = 0.232945 loss)
I1007 17:54:41.543620  5078 sgd_solver.cpp:105] Iteration 10700, lr = 0.1
I1007 17:54:49.888164  5078 solver.cpp:218] Iteration 10800 (11.9839 iter/s, 8.34452s/100 iters), loss = 0.36779
I1007 17:54:49.888303  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.36779 (* 1 = 0.36779 loss)
I1007 17:54:49.888310  5078 sgd_solver.cpp:105] Iteration 10800, lr = 0.1
I1007 17:54:58.227948  5078 solver.cpp:218] Iteration 10900 (11.991 iter/s, 8.33962s/100 iters), loss = 0.256382
I1007 17:54:58.227977  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.256381 (* 1 = 0.256381 loss)
I1007 17:54:58.227983  5078 sgd_solver.cpp:105] Iteration 10900, lr = 0.1
I1007 17:55:06.161484  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:55:06.495263  5078 solver.cpp:330] Iteration 11000, Testing net (#0)
I1007 17:55:08.422237  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:55:08.503386  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7816
I1007 17:55:08.503422  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.683217 (* 1 = 0.683217 loss)
I1007 17:55:08.586473  5078 solver.cpp:218] Iteration 11000 (9.65394 iter/s, 10.3585s/100 iters), loss = 0.239101
I1007 17:55:08.586500  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.239101 (* 1 = 0.239101 loss)
I1007 17:55:08.586508  5078 sgd_solver.cpp:105] Iteration 11000, lr = 0.1
I1007 17:55:16.921049  5078 solver.cpp:218] Iteration 11100 (11.9983 iter/s, 8.33452s/100 iters), loss = 0.265533
I1007 17:55:16.921089  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.265532 (* 1 = 0.265532 loss)
I1007 17:55:16.921095  5078 sgd_solver.cpp:105] Iteration 11100, lr = 0.1
I1007 17:55:25.264261  5078 solver.cpp:218] Iteration 11200 (11.9859 iter/s, 8.34315s/100 iters), loss = 0.293768
I1007 17:55:25.264360  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.293767 (* 1 = 0.293767 loss)
I1007 17:55:25.264377  5078 sgd_solver.cpp:105] Iteration 11200, lr = 0.1
I1007 17:55:33.597635  5078 solver.cpp:218] Iteration 11300 (12.0001 iter/s, 8.33324s/100 iters), loss = 0.361382
I1007 17:55:33.597674  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.361382 (* 1 = 0.361382 loss)
I1007 17:55:33.597681  5078 sgd_solver.cpp:105] Iteration 11300, lr = 0.1
I1007 17:55:41.935699  5078 solver.cpp:218] Iteration 11400 (11.9933 iter/s, 8.338s/100 iters), loss = 0.308991
I1007 17:55:41.935729  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.308991 (* 1 = 0.308991 loss)
I1007 17:55:41.935734  5078 sgd_solver.cpp:105] Iteration 11400, lr = 0.1
I1007 17:55:49.855453  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:55:50.189837  5078 solver.cpp:330] Iteration 11500, Testing net (#0)
I1007 17:55:52.115972  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:55:52.196249  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7567
I1007 17:55:52.196285  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.701961 (* 1 = 0.701961 loss)
I1007 17:55:52.279420  5078 solver.cpp:218] Iteration 11500 (9.66776 iter/s, 10.3437s/100 iters), loss = 0.229567
I1007 17:55:52.279454  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.229567 (* 1 = 0.229567 loss)
I1007 17:55:52.279461  5078 sgd_solver.cpp:105] Iteration 11500, lr = 0.1
I1007 17:56:00.627452  5078 solver.cpp:218] Iteration 11600 (11.979 iter/s, 8.34797s/100 iters), loss = 0.277384
I1007 17:56:00.627550  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.277384 (* 1 = 0.277384 loss)
I1007 17:56:00.627558  5078 sgd_solver.cpp:105] Iteration 11600, lr = 0.1
I1007 17:56:08.973243  5078 solver.cpp:218] Iteration 11700 (11.9823 iter/s, 8.34567s/100 iters), loss = 0.292873
I1007 17:56:08.973284  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.292873 (* 1 = 0.292873 loss)
I1007 17:56:08.973290  5078 sgd_solver.cpp:105] Iteration 11700, lr = 0.1
I1007 17:56:17.323529  5078 solver.cpp:218] Iteration 11800 (11.9757 iter/s, 8.35021s/100 iters), loss = 0.299
I1007 17:56:17.323570  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.299 (* 1 = 0.299 loss)
I1007 17:56:17.323577  5078 sgd_solver.cpp:105] Iteration 11800, lr = 0.1
I1007 17:56:25.665982  5078 solver.cpp:218] Iteration 11900 (11.987 iter/s, 8.34238s/100 iters), loss = 0.259111
I1007 17:56:25.666023  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.259111 (* 1 = 0.259111 loss)
I1007 17:56:25.666028  5078 sgd_solver.cpp:105] Iteration 11900, lr = 0.1
I1007 17:56:33.602272  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:56:33.936408  5078 solver.cpp:330] Iteration 12000, Testing net (#0)
I1007 17:56:35.863201  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:56:35.944437  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.784
I1007 17:56:35.944473  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.665306 (* 1 = 0.665306 loss)
I1007 17:56:36.027074  5078 solver.cpp:218] Iteration 12000 (9.65156 iter/s, 10.361s/100 iters), loss = 0.27623
I1007 17:56:36.027102  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.27623 (* 1 = 0.27623 loss)
I1007 17:56:36.027108  5078 sgd_solver.cpp:105] Iteration 12000, lr = 0.1
I1007 17:56:44.364223  5078 solver.cpp:218] Iteration 12100 (11.9946 iter/s, 8.33709s/100 iters), loss = 0.333703
I1007 17:56:44.364253  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.333703 (* 1 = 0.333703 loss)
I1007 17:56:44.364260  5078 sgd_solver.cpp:105] Iteration 12100, lr = 0.1
I1007 17:56:52.708520  5078 solver.cpp:218] Iteration 12200 (11.9843 iter/s, 8.34424s/100 iters), loss = 0.32028
I1007 17:56:52.708559  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.32028 (* 1 = 0.32028 loss)
I1007 17:56:52.708565  5078 sgd_solver.cpp:105] Iteration 12200, lr = 0.1
I1007 17:57:01.048961  5078 solver.cpp:218] Iteration 12300 (11.9899 iter/s, 8.34037s/100 iters), loss = 0.365433
I1007 17:57:01.049002  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.365433 (* 1 = 0.365433 loss)
I1007 17:57:01.049010  5078 sgd_solver.cpp:105] Iteration 12300, lr = 0.1
I1007 17:57:09.391098  5078 solver.cpp:218] Iteration 12400 (11.9874 iter/s, 8.34207s/100 iters), loss = 0.205225
I1007 17:57:09.391188  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.205225 (* 1 = 0.205225 loss)
I1007 17:57:09.391196  5078 sgd_solver.cpp:105] Iteration 12400, lr = 0.1
I1007 17:57:17.316819  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:57:17.650004  5078 solver.cpp:330] Iteration 12500, Testing net (#0)
I1007 17:57:19.576187  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:57:19.656808  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6634
I1007 17:57:19.656843  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.222 (* 1 = 1.222 loss)
I1007 17:57:19.740783  5078 solver.cpp:218] Iteration 12500 (9.66224 iter/s, 10.3496s/100 iters), loss = 0.261272
I1007 17:57:19.740809  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.261272 (* 1 = 0.261272 loss)
I1007 17:57:19.740816  5078 sgd_solver.cpp:105] Iteration 12500, lr = 0.1
I1007 17:57:28.091094  5078 solver.cpp:218] Iteration 12600 (11.9757 iter/s, 8.35026s/100 iters), loss = 0.232803
I1007 17:57:28.091135  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.232802 (* 1 = 0.232802 loss)
I1007 17:57:28.091140  5078 sgd_solver.cpp:105] Iteration 12600, lr = 0.1
I1007 17:57:36.438827  5078 solver.cpp:218] Iteration 12700 (11.9794 iter/s, 8.34766s/100 iters), loss = 0.359302
I1007 17:57:36.438864  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.359302 (* 1 = 0.359302 loss)
I1007 17:57:36.438870  5078 sgd_solver.cpp:105] Iteration 12700, lr = 0.1
I1007 17:57:44.792805  5078 solver.cpp:218] Iteration 12800 (11.9704 iter/s, 8.35391s/100 iters), loss = 0.293526
I1007 17:57:44.792933  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.293526 (* 1 = 0.293526 loss)
I1007 17:57:44.792951  5078 sgd_solver.cpp:105] Iteration 12800, lr = 0.1
I1007 17:57:53.137383  5078 solver.cpp:218] Iteration 12900 (11.9841 iter/s, 8.34442s/100 iters), loss = 0.150886
I1007 17:57:53.137423  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.150885 (* 1 = 0.150885 loss)
I1007 17:57:53.137429  5078 sgd_solver.cpp:105] Iteration 12900, lr = 0.1
I1007 17:58:01.072464  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:58:01.406596  5078 solver.cpp:330] Iteration 13000, Testing net (#0)
I1007 17:58:03.333125  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:58:03.413703  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7362
I1007 17:58:03.413739  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.80409 (* 1 = 0.80409 loss)
I1007 17:58:03.496007  5078 solver.cpp:218] Iteration 13000 (9.65386 iter/s, 10.3586s/100 iters), loss = 0.248505
I1007 17:58:03.496042  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.248504 (* 1 = 0.248504 loss)
I1007 17:58:03.496049  5078 sgd_solver.cpp:105] Iteration 13000, lr = 0.1
I1007 17:58:11.834758  5078 solver.cpp:218] Iteration 13100 (11.9923 iter/s, 8.33869s/100 iters), loss = 0.29241
I1007 17:58:11.834800  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.29241 (* 1 = 0.29241 loss)
I1007 17:58:11.834805  5078 sgd_solver.cpp:105] Iteration 13100, lr = 0.1
I1007 17:58:20.179174  5078 solver.cpp:218] Iteration 13200 (11.9842 iter/s, 8.34435s/100 iters), loss = 0.248406
I1007 17:58:20.179277  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.248405 (* 1 = 0.248405 loss)
I1007 17:58:20.179283  5078 sgd_solver.cpp:105] Iteration 13200, lr = 0.1
I1007 17:58:28.518187  5078 solver.cpp:218] Iteration 13300 (11.992 iter/s, 8.33888s/100 iters), loss = 0.381079
I1007 17:58:28.518225  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.381079 (* 1 = 0.381079 loss)
I1007 17:58:28.518231  5078 sgd_solver.cpp:105] Iteration 13300, lr = 0.1
I1007 17:58:36.864503  5078 solver.cpp:218] Iteration 13400 (11.9814 iter/s, 8.34625s/100 iters), loss = 0.30761
I1007 17:58:36.864543  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.307609 (* 1 = 0.307609 loss)
I1007 17:58:36.864549  5078 sgd_solver.cpp:105] Iteration 13400, lr = 0.1
I1007 17:58:44.787497  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:58:45.121289  5078 solver.cpp:330] Iteration 13500, Testing net (#0)
I1007 17:58:47.046841  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:58:47.127295  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7603
I1007 17:58:47.127329  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.778647 (* 1 = 0.778647 loss)
I1007 17:58:47.210916  5078 solver.cpp:218] Iteration 13500 (9.66526 iter/s, 10.3463s/100 iters), loss = 0.19693
I1007 17:58:47.210955  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.196929 (* 1 = 0.196929 loss)
I1007 17:58:47.210963  5078 sgd_solver.cpp:105] Iteration 13500, lr = 0.1
I1007 17:58:55.556800  5078 solver.cpp:218] Iteration 13600 (11.982 iter/s, 8.34582s/100 iters), loss = 0.210069
I1007 17:58:55.556910  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.210069 (* 1 = 0.210069 loss)
I1007 17:58:55.556929  5078 sgd_solver.cpp:105] Iteration 13600, lr = 0.1
I1007 17:59:03.895726  5078 solver.cpp:218] Iteration 13700 (11.9921 iter/s, 8.33879s/100 iters), loss = 0.320007
I1007 17:59:03.895756  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.320006 (* 1 = 0.320006 loss)
I1007 17:59:03.895761  5078 sgd_solver.cpp:105] Iteration 13700, lr = 0.1
I1007 17:59:12.241798  5078 solver.cpp:218] Iteration 13800 (11.9818 iter/s, 8.34601s/100 iters), loss = 0.280173
I1007 17:59:12.241829  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.280173 (* 1 = 0.280173 loss)
I1007 17:59:12.241845  5078 sgd_solver.cpp:105] Iteration 13800, lr = 0.1
I1007 17:59:20.581176  5078 solver.cpp:218] Iteration 13900 (11.9914 iter/s, 8.33932s/100 iters), loss = 0.212386
I1007 17:59:20.581207  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.212386 (* 1 = 0.212386 loss)
I1007 17:59:20.581223  5078 sgd_solver.cpp:105] Iteration 13900, lr = 0.1
I1007 17:59:28.514750  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:59:28.849452  5078 solver.cpp:330] Iteration 14000, Testing net (#0)
I1007 17:59:30.775960  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 17:59:30.857084  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7868
I1007 17:59:30.857110  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.650415 (* 1 = 0.650415 loss)
I1007 17:59:30.939611  5078 solver.cpp:218] Iteration 14000 (9.65403 iter/s, 10.3584s/100 iters), loss = 0.225976
I1007 17:59:30.939658  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.225976 (* 1 = 0.225976 loss)
I1007 17:59:30.939666  5078 sgd_solver.cpp:105] Iteration 14000, lr = 0.1
I1007 17:59:39.273995  5078 solver.cpp:218] Iteration 14100 (11.9986 iter/s, 8.33431s/100 iters), loss = 0.213528
I1007 17:59:39.274035  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.213528 (* 1 = 0.213528 loss)
I1007 17:59:39.274041  5078 sgd_solver.cpp:105] Iteration 14100, lr = 0.1
I1007 17:59:47.617349  5078 solver.cpp:218] Iteration 14200 (11.9857 iter/s, 8.34329s/100 iters), loss = 0.223963
I1007 17:59:47.617391  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.223962 (* 1 = 0.223962 loss)
I1007 17:59:47.617398  5078 sgd_solver.cpp:105] Iteration 14200, lr = 0.1
I1007 17:59:55.955549  5078 solver.cpp:218] Iteration 14300 (11.9931 iter/s, 8.33813s/100 iters), loss = 0.276014
I1007 17:59:55.955590  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.276014 (* 1 = 0.276014 loss)
I1007 17:59:55.955596  5078 sgd_solver.cpp:105] Iteration 14300, lr = 0.1
I1007 18:00:04.301652  5078 solver.cpp:218] Iteration 14400 (11.9817 iter/s, 8.34604s/100 iters), loss = 0.161342
I1007 18:00:04.301759  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.161341 (* 1 = 0.161341 loss)
I1007 18:00:04.301767  5078 sgd_solver.cpp:105] Iteration 14400, lr = 0.1
I1007 18:00:12.223354  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:00:12.557837  5078 solver.cpp:330] Iteration 14500, Testing net (#0)
I1007 18:00:14.483620  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:00:14.563501  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6633
I1007 18:00:14.563537  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.31151 (* 1 = 1.31151 loss)
I1007 18:00:14.647655  5078 solver.cpp:218] Iteration 14500 (9.6657 iter/s, 10.3459s/100 iters), loss = 0.229195
I1007 18:00:14.647682  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.229195 (* 1 = 0.229195 loss)
I1007 18:00:14.647688  5078 sgd_solver.cpp:105] Iteration 14500, lr = 0.1
I1007 18:00:22.994979  5078 solver.cpp:218] Iteration 14600 (11.98 iter/s, 8.34727s/100 iters), loss = 0.191552
I1007 18:00:22.995020  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.191551 (* 1 = 0.191551 loss)
I1007 18:00:22.995026  5078 sgd_solver.cpp:105] Iteration 14600, lr = 0.1
I1007 18:00:31.337508  5078 solver.cpp:218] Iteration 14700 (11.9869 iter/s, 8.34246s/100 iters), loss = 0.300827
I1007 18:00:31.337548  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.300827 (* 1 = 0.300827 loss)
I1007 18:00:31.337554  5078 sgd_solver.cpp:105] Iteration 14700, lr = 0.1
I1007 18:00:39.682754  5078 solver.cpp:218] Iteration 14800 (11.983 iter/s, 8.34518s/100 iters), loss = 0.266419
I1007 18:00:39.682893  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.266419 (* 1 = 0.266419 loss)
I1007 18:00:39.682912  5078 sgd_solver.cpp:105] Iteration 14800, lr = 0.1
I1007 18:00:48.029448  5078 solver.cpp:218] Iteration 14900 (11.981 iter/s, 8.34653s/100 iters), loss = 0.191154
I1007 18:00:48.029489  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.191154 (* 1 = 0.191154 loss)
I1007 18:00:48.029495  5078 sgd_solver.cpp:105] Iteration 14900, lr = 0.1
I1007 18:00:55.962936  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:00:56.297225  5078 solver.cpp:330] Iteration 15000, Testing net (#0)
I1007 18:00:58.223729  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:00:58.304720  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7358
I1007 18:00:58.304756  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.855662 (* 1 = 0.855662 loss)
I1007 18:00:58.387776  5078 solver.cpp:218] Iteration 15000 (9.65413 iter/s, 10.3583s/100 iters), loss = 0.255341
I1007 18:00:58.387802  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.25534 (* 1 = 0.25534 loss)
I1007 18:00:58.387809  5078 sgd_solver.cpp:105] Iteration 15000, lr = 0.1
I1007 18:01:06.729634  5078 solver.cpp:218] Iteration 15100 (11.9878 iter/s, 8.3418s/100 iters), loss = 0.212386
I1007 18:01:06.729663  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.212385 (* 1 = 0.212385 loss)
I1007 18:01:06.729668  5078 sgd_solver.cpp:105] Iteration 15100, lr = 0.1
I1007 18:01:15.080071  5078 solver.cpp:218] Iteration 15200 (11.9755 iter/s, 8.35038s/100 iters), loss = 0.238944
I1007 18:01:15.080174  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.238943 (* 1 = 0.238943 loss)
I1007 18:01:15.080191  5078 sgd_solver.cpp:105] Iteration 15200, lr = 0.1
I1007 18:01:23.421450  5078 solver.cpp:218] Iteration 15300 (11.9886 iter/s, 8.34125s/100 iters), loss = 0.309748
I1007 18:01:23.421490  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.309747 (* 1 = 0.309747 loss)
I1007 18:01:23.421496  5078 sgd_solver.cpp:105] Iteration 15300, lr = 0.1
I1007 18:01:31.766513  5078 solver.cpp:218] Iteration 15400 (11.9832 iter/s, 8.345s/100 iters), loss = 0.340908
I1007 18:01:31.766553  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.340908 (* 1 = 0.340908 loss)
I1007 18:01:31.766559  5078 sgd_solver.cpp:105] Iteration 15400, lr = 0.1
I1007 18:01:39.692962  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:01:40.026805  5078 solver.cpp:330] Iteration 15500, Testing net (#0)
I1007 18:01:41.951295  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:01:42.031733  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6411
I1007 18:01:42.031755  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.2818 (* 1 = 1.2818 loss)
I1007 18:01:42.114845  5078 solver.cpp:218] Iteration 15500 (9.66346 iter/s, 10.3483s/100 iters), loss = 0.262272
I1007 18:01:42.114873  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.262272 (* 1 = 0.262272 loss)
I1007 18:01:42.114881  5078 sgd_solver.cpp:105] Iteration 15500, lr = 0.1
I1007 18:01:50.460625  5078 solver.cpp:218] Iteration 15600 (11.9822 iter/s, 8.34573s/100 iters), loss = 0.22207
I1007 18:01:50.460752  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.222069 (* 1 = 0.222069 loss)
I1007 18:01:50.460768  5078 sgd_solver.cpp:105] Iteration 15600, lr = 0.1
I1007 18:01:58.796658  5078 solver.cpp:218] Iteration 15700 (11.9963 iter/s, 8.33588s/100 iters), loss = 0.190297
I1007 18:01:58.796700  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.190296 (* 1 = 0.190296 loss)
I1007 18:01:58.796705  5078 sgd_solver.cpp:105] Iteration 15700, lr = 0.1
I1007 18:02:07.139956  5078 solver.cpp:218] Iteration 15800 (11.9858 iter/s, 8.34323s/100 iters), loss = 0.307721
I1007 18:02:07.139997  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.307721 (* 1 = 0.307721 loss)
I1007 18:02:07.140002  5078 sgd_solver.cpp:105] Iteration 15800, lr = 0.1
I1007 18:02:15.476747  5078 solver.cpp:218] Iteration 15900 (11.9951 iter/s, 8.33672s/100 iters), loss = 0.212825
I1007 18:02:15.476786  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.212825 (* 1 = 0.212825 loss)
I1007 18:02:15.476793  5078 sgd_solver.cpp:105] Iteration 15900, lr = 0.1
I1007 18:02:23.408165  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:02:23.742687  5078 solver.cpp:330] Iteration 16000, Testing net (#0)
I1007 18:02:25.667381  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:02:25.748508  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6727
I1007 18:02:25.748544  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.992352 (* 1 = 0.992352 loss)
I1007 18:02:25.830545  5078 solver.cpp:218] Iteration 16000 (9.65836 iter/s, 10.3537s/100 iters), loss = 0.164127
I1007 18:02:25.830572  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.164126 (* 1 = 0.164126 loss)
I1007 18:02:25.830579  5078 sgd_solver.cpp:105] Iteration 16000, lr = 0.1
I1007 18:02:34.170765  5078 solver.cpp:218] Iteration 16100 (11.9902 iter/s, 8.34017s/100 iters), loss = 0.319904
I1007 18:02:34.170806  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.319904 (* 1 = 0.319904 loss)
I1007 18:02:34.170812  5078 sgd_solver.cpp:105] Iteration 16100, lr = 0.1
I1007 18:02:42.515527  5078 solver.cpp:218] Iteration 16200 (11.9837 iter/s, 8.3447s/100 iters), loss = 0.268832
I1007 18:02:42.515568  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.268832 (* 1 = 0.268832 loss)
I1007 18:02:42.515573  5078 sgd_solver.cpp:105] Iteration 16200, lr = 0.1
I1007 18:02:50.857197  5078 solver.cpp:218] Iteration 16300 (11.9881 iter/s, 8.3416s/100 iters), loss = 0.27667
I1007 18:02:50.857237  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.276669 (* 1 = 0.276669 loss)
I1007 18:02:50.857244  5078 sgd_solver.cpp:105] Iteration 16300, lr = 0.1
I1007 18:02:59.204751  5078 solver.cpp:218] Iteration 16400 (11.9797 iter/s, 8.34749s/100 iters), loss = 0.227071
I1007 18:02:59.204875  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.227071 (* 1 = 0.227071 loss)
I1007 18:02:59.204883  5078 sgd_solver.cpp:105] Iteration 16400, lr = 0.1
I1007 18:03:07.134413  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:03:07.468520  5078 solver.cpp:330] Iteration 16500, Testing net (#0)
I1007 18:03:09.394726  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:03:09.475445  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7576
I1007 18:03:09.475478  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.787008 (* 1 = 0.787008 loss)
I1007 18:03:09.558668  5078 solver.cpp:218] Iteration 16500 (9.65831 iter/s, 10.3538s/100 iters), loss = 0.266721
I1007 18:03:09.558696  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.26672 (* 1 = 0.26672 loss)
I1007 18:03:09.558702  5078 sgd_solver.cpp:105] Iteration 16500, lr = 0.1
I1007 18:03:17.909485  5078 solver.cpp:218] Iteration 16600 (11.975 iter/s, 8.35076s/100 iters), loss = 0.381346
I1007 18:03:17.909515  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.381345 (* 1 = 0.381345 loss)
I1007 18:03:17.909523  5078 sgd_solver.cpp:105] Iteration 16600, lr = 0.1
I1007 18:03:26.253154  5078 solver.cpp:218] Iteration 16700 (11.9852 iter/s, 8.34361s/100 iters), loss = 0.268805
I1007 18:03:26.253193  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.268805 (* 1 = 0.268805 loss)
I1007 18:03:26.253199  5078 sgd_solver.cpp:105] Iteration 16700, lr = 0.1
I1007 18:03:34.601052  5078 solver.cpp:218] Iteration 16800 (11.9792 iter/s, 8.34783s/100 iters), loss = 0.270463
I1007 18:03:34.601140  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.270463 (* 1 = 0.270463 loss)
I1007 18:03:34.601147  5078 sgd_solver.cpp:105] Iteration 16800, lr = 0.1
I1007 18:03:42.945724  5078 solver.cpp:218] Iteration 16900 (11.9839 iter/s, 8.34456s/100 iters), loss = 0.247305
I1007 18:03:42.945765  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.247305 (* 1 = 0.247305 loss)
I1007 18:03:42.945771  5078 sgd_solver.cpp:105] Iteration 16900, lr = 0.1
I1007 18:03:50.879566  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:03:51.213903  5078 solver.cpp:330] Iteration 17000, Testing net (#0)
I1007 18:03:53.140316  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:03:53.220705  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8077
I1007 18:03:53.220728  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.615786 (* 1 = 0.615786 loss)
I1007 18:03:53.303382  5078 solver.cpp:218] Iteration 17000 (9.65476 iter/s, 10.3576s/100 iters), loss = 0.19084
I1007 18:03:53.303412  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.190839 (* 1 = 0.190839 loss)
I1007 18:03:53.303418  5078 sgd_solver.cpp:105] Iteration 17000, lr = 0.1
I1007 18:04:01.644078  5078 solver.cpp:218] Iteration 17100 (11.9895 iter/s, 8.34064s/100 iters), loss = 0.173239
I1007 18:04:01.644119  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.173238 (* 1 = 0.173238 loss)
I1007 18:04:01.644124  5078 sgd_solver.cpp:105] Iteration 17100, lr = 0.1
I1007 18:04:09.983425  5078 solver.cpp:218] Iteration 17200 (11.9914 iter/s, 8.33928s/100 iters), loss = 0.18885
I1007 18:04:09.983551  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.188849 (* 1 = 0.188849 loss)
I1007 18:04:09.983568  5078 sgd_solver.cpp:105] Iteration 17200, lr = 0.1
I1007 18:04:18.320968  5078 solver.cpp:218] Iteration 17300 (11.9942 iter/s, 8.33739s/100 iters), loss = 0.180895
I1007 18:04:18.321008  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.180895 (* 1 = 0.180895 loss)
I1007 18:04:18.321015  5078 sgd_solver.cpp:105] Iteration 17300, lr = 0.1
I1007 18:04:26.665531  5078 solver.cpp:218] Iteration 17400 (11.9839 iter/s, 8.3445s/100 iters), loss = 0.247326
I1007 18:04:26.665571  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.247326 (* 1 = 0.247326 loss)
I1007 18:04:26.665576  5078 sgd_solver.cpp:105] Iteration 17400, lr = 0.1
I1007 18:04:34.589511  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:04:34.923449  5078 solver.cpp:330] Iteration 17500, Testing net (#0)
I1007 18:04:36.849813  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:04:36.930155  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7649
I1007 18:04:36.930181  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.754558 (* 1 = 0.754558 loss)
I1007 18:04:37.014060  5078 solver.cpp:218] Iteration 17500 (9.66327 iter/s, 10.3485s/100 iters), loss = 0.175429
I1007 18:04:37.014086  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.175429 (* 1 = 0.175429 loss)
I1007 18:04:37.014092  5078 sgd_solver.cpp:105] Iteration 17500, lr = 0.1
I1007 18:04:45.361179  5078 solver.cpp:218] Iteration 17600 (11.9803 iter/s, 8.34707s/100 iters), loss = 0.174347
I1007 18:04:45.361313  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.174346 (* 1 = 0.174346 loss)
I1007 18:04:45.361330  5078 sgd_solver.cpp:105] Iteration 17600, lr = 0.1
I1007 18:04:53.700299  5078 solver.cpp:218] Iteration 17700 (11.9919 iter/s, 8.33897s/100 iters), loss = 0.163602
I1007 18:04:53.700330  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.163601 (* 1 = 0.163601 loss)
I1007 18:04:53.700335  5078 sgd_solver.cpp:105] Iteration 17700, lr = 0.1
I1007 18:05:02.048501  5078 solver.cpp:218] Iteration 17800 (11.9787 iter/s, 8.34815s/100 iters), loss = 0.228841
I1007 18:05:02.048532  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.22884 (* 1 = 0.22884 loss)
I1007 18:05:02.048547  5078 sgd_solver.cpp:105] Iteration 17800, lr = 0.1
I1007 18:05:10.392086  5078 solver.cpp:218] Iteration 17900 (11.9853 iter/s, 8.34353s/100 iters), loss = 0.209428
I1007 18:05:10.392117  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.209428 (* 1 = 0.209428 loss)
I1007 18:05:10.392123  5078 sgd_solver.cpp:105] Iteration 17900, lr = 0.1
I1007 18:05:18.325160  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:05:18.658638  5078 solver.cpp:330] Iteration 18000, Testing net (#0)
I1007 18:05:20.584560  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:05:20.665567  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7906
I1007 18:05:20.665602  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.664362 (* 1 = 0.664362 loss)
I1007 18:05:20.748713  5078 solver.cpp:218] Iteration 18000 (9.65571 iter/s, 10.3566s/100 iters), loss = 0.184234
I1007 18:05:20.748739  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.184233 (* 1 = 0.184233 loss)
I1007 18:05:20.748745  5078 sgd_solver.cpp:105] Iteration 18000, lr = 0.1
I1007 18:05:29.083303  5078 solver.cpp:218] Iteration 18100 (11.9983 iter/s, 8.33454s/100 iters), loss = 0.228498
I1007 18:05:29.083333  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.228497 (* 1 = 0.228497 loss)
I1007 18:05:29.083339  5078 sgd_solver.cpp:105] Iteration 18100, lr = 0.1
I1007 18:05:37.424127  5078 solver.cpp:218] Iteration 18200 (11.9893 iter/s, 8.34077s/100 iters), loss = 0.245697
I1007 18:05:37.424157  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.245696 (* 1 = 0.245696 loss)
I1007 18:05:37.424163  5078 sgd_solver.cpp:105] Iteration 18200, lr = 0.1
I1007 18:05:45.760298  5078 solver.cpp:218] Iteration 18300 (11.996 iter/s, 8.33611s/100 iters), loss = 0.202229
I1007 18:05:45.760337  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.202229 (* 1 = 0.202229 loss)
I1007 18:05:45.760344  5078 sgd_solver.cpp:105] Iteration 18300, lr = 0.1
I1007 18:05:54.103052  5078 solver.cpp:218] Iteration 18400 (11.9865 iter/s, 8.34269s/100 iters), loss = 0.264808
I1007 18:05:54.103191  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.264807 (* 1 = 0.264807 loss)
I1007 18:05:54.103199  5078 sgd_solver.cpp:105] Iteration 18400, lr = 0.1
I1007 18:06:02.026139  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:06:02.360241  5078 solver.cpp:330] Iteration 18500, Testing net (#0)
I1007 18:06:04.285261  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:06:04.365698  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7342
I1007 18:06:04.365733  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.926177 (* 1 = 0.926177 loss)
I1007 18:06:04.449645  5078 solver.cpp:218] Iteration 18500 (9.66517 iter/s, 10.3464s/100 iters), loss = 0.257668
I1007 18:06:04.449676  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.257668 (* 1 = 0.257668 loss)
I1007 18:06:04.449682  5078 sgd_solver.cpp:105] Iteration 18500, lr = 0.1
I1007 18:06:12.792268  5078 solver.cpp:218] Iteration 18600 (11.9867 iter/s, 8.34256s/100 iters), loss = 0.298341
I1007 18:06:12.792307  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.29834 (* 1 = 0.29834 loss)
I1007 18:06:12.792313  5078 sgd_solver.cpp:105] Iteration 18600, lr = 0.1
I1007 18:06:21.127719  5078 solver.cpp:218] Iteration 18700 (11.997 iter/s, 8.33539s/100 iters), loss = 0.196288
I1007 18:06:21.127759  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.196287 (* 1 = 0.196287 loss)
I1007 18:06:21.127765  5078 sgd_solver.cpp:105] Iteration 18700, lr = 0.1
I1007 18:06:29.467880  5078 solver.cpp:218] Iteration 18800 (11.9903 iter/s, 8.34009s/100 iters), loss = 0.198964
I1007 18:06:29.468024  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.198963 (* 1 = 0.198963 loss)
I1007 18:06:29.468030  5078 sgd_solver.cpp:105] Iteration 18800, lr = 0.1
I1007 18:06:37.807543  5078 solver.cpp:218] Iteration 18900 (11.9911 iter/s, 8.3395s/100 iters), loss = 0.200356
I1007 18:06:37.807584  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.200355 (* 1 = 0.200355 loss)
I1007 18:06:37.807590  5078 sgd_solver.cpp:105] Iteration 18900, lr = 0.1
I1007 18:06:45.734869  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:06:46.068377  5078 solver.cpp:330] Iteration 19000, Testing net (#0)
I1007 18:06:47.993979  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:06:48.074818  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.838
I1007 18:06:48.074844  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.500382 (* 1 = 0.500382 loss)
I1007 18:06:48.157438  5078 solver.cpp:218] Iteration 19000 (9.662 iter/s, 10.3498s/100 iters), loss = 0.23056
I1007 18:06:48.157462  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.23056 (* 1 = 0.23056 loss)
I1007 18:06:48.157469  5078 sgd_solver.cpp:105] Iteration 19000, lr = 0.1
I1007 18:06:56.497872  5078 solver.cpp:218] Iteration 19100 (11.9899 iter/s, 8.34038s/100 iters), loss = 0.308636
I1007 18:06:56.497913  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.308635 (* 1 = 0.308635 loss)
I1007 18:06:56.497918  5078 sgd_solver.cpp:105] Iteration 19100, lr = 0.1
I1007 18:07:04.844118  5078 solver.cpp:218] Iteration 19200 (11.9815 iter/s, 8.34618s/100 iters), loss = 0.209592
I1007 18:07:04.844234  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.209591 (* 1 = 0.209591 loss)
I1007 18:07:04.844251  5078 sgd_solver.cpp:105] Iteration 19200, lr = 0.1
I1007 18:07:13.186283  5078 solver.cpp:218] Iteration 19300 (11.9875 iter/s, 8.34203s/100 iters), loss = 0.201167
I1007 18:07:13.186313  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.201166 (* 1 = 0.201166 loss)
I1007 18:07:13.186319  5078 sgd_solver.cpp:105] Iteration 19300, lr = 0.1
I1007 18:07:21.531219  5078 solver.cpp:218] Iteration 19400 (11.9834 iter/s, 8.34487s/100 iters), loss = 0.316684
I1007 18:07:21.531257  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.316683 (* 1 = 0.316683 loss)
I1007 18:07:21.531263  5078 sgd_solver.cpp:105] Iteration 19400, lr = 0.1
I1007 18:07:29.459714  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:07:29.793889  5078 solver.cpp:330] Iteration 19500, Testing net (#0)
I1007 18:07:31.718302  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:07:31.798058  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7023
I1007 18:07:31.798092  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.01743 (* 1 = 1.01743 loss)
I1007 18:07:31.881909  5078 solver.cpp:218] Iteration 19500 (9.66126 iter/s, 10.3506s/100 iters), loss = 0.260542
I1007 18:07:31.881937  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.260541 (* 1 = 0.260541 loss)
I1007 18:07:31.881943  5078 sgd_solver.cpp:105] Iteration 19500, lr = 0.1
I1007 18:07:40.226368  5078 solver.cpp:218] Iteration 19600 (11.9841 iter/s, 8.3444s/100 iters), loss = 0.302474
I1007 18:07:40.226524  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.302474 (* 1 = 0.302474 loss)
I1007 18:07:40.226533  5078 sgd_solver.cpp:105] Iteration 19600, lr = 0.1
I1007 18:07:48.572016  5078 solver.cpp:218] Iteration 19700 (11.9825 iter/s, 8.34548s/100 iters), loss = 0.193666
I1007 18:07:48.572057  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.193666 (* 1 = 0.193666 loss)
I1007 18:07:48.572062  5078 sgd_solver.cpp:105] Iteration 19700, lr = 0.1
I1007 18:07:56.920999  5078 solver.cpp:218] Iteration 19800 (11.9776 iter/s, 8.34892s/100 iters), loss = 0.272617
I1007 18:07:56.921038  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.272617 (* 1 = 0.272617 loss)
I1007 18:07:56.921044  5078 sgd_solver.cpp:105] Iteration 19800, lr = 0.1
I1007 18:08:05.270957  5078 solver.cpp:218] Iteration 19900 (11.9762 iter/s, 8.34989s/100 iters), loss = 0.221317
I1007 18:08:05.270987  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.221317 (* 1 = 0.221317 loss)
I1007 18:08:05.270992  5078 sgd_solver.cpp:105] Iteration 19900, lr = 0.1
I1007 18:08:13.205852  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:08:13.539782  5078 solver.cpp:330] Iteration 20000, Testing net (#0)
I1007 18:08:15.464231  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:08:15.545207  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7149
I1007 18:08:15.545243  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.06956 (* 1 = 1.06956 loss)
I1007 18:08:15.628267  5078 solver.cpp:218] Iteration 20000 (9.65507 iter/s, 10.3572s/100 iters), loss = 0.194029
I1007 18:08:15.628290  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.194028 (* 1 = 0.194028 loss)
I1007 18:08:15.628298  5078 sgd_solver.cpp:105] Iteration 20000, lr = 0.1
I1007 18:08:23.963007  5078 solver.cpp:218] Iteration 20100 (11.998 iter/s, 8.33469s/100 iters), loss = 0.102054
I1007 18:08:23.963038  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.102054 (* 1 = 0.102054 loss)
I1007 18:08:23.963043  5078 sgd_solver.cpp:105] Iteration 20100, lr = 0.1
I1007 18:08:32.302307  5078 solver.cpp:218] Iteration 20200 (11.9915 iter/s, 8.33924s/100 iters), loss = 0.210551
I1007 18:08:32.302337  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.21055 (* 1 = 0.21055 loss)
I1007 18:08:32.302343  5078 sgd_solver.cpp:105] Iteration 20200, lr = 0.1
I1007 18:08:40.640221  5078 solver.cpp:218] Iteration 20300 (11.9935 iter/s, 8.33786s/100 iters), loss = 0.268071
I1007 18:08:40.640261  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.268071 (* 1 = 0.268071 loss)
I1007 18:08:40.640267  5078 sgd_solver.cpp:105] Iteration 20300, lr = 0.1
I1007 18:08:48.982792  5078 solver.cpp:218] Iteration 20400 (11.9868 iter/s, 8.3425s/100 iters), loss = 0.179544
I1007 18:08:48.982858  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.179544 (* 1 = 0.179544 loss)
I1007 18:08:48.982866  5078 sgd_solver.cpp:105] Iteration 20400, lr = 0.1
I1007 18:08:56.902979  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:08:57.236816  5078 solver.cpp:330] Iteration 20500, Testing net (#0)
I1007 18:08:59.162581  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:08:59.243312  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7789
I1007 18:08:59.243346  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.674901 (* 1 = 0.674901 loss)
I1007 18:08:59.326849  5078 solver.cpp:218] Iteration 20500 (9.66748 iter/s, 10.344s/100 iters), loss = 0.241452
I1007 18:08:59.326877  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.241452 (* 1 = 0.241452 loss)
I1007 18:08:59.326884  5078 sgd_solver.cpp:105] Iteration 20500, lr = 0.1
I1007 18:09:07.674968  5078 solver.cpp:218] Iteration 20600 (11.9788 iter/s, 8.34806s/100 iters), loss = 0.267239
I1007 18:09:07.675006  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.267238 (* 1 = 0.267238 loss)
I1007 18:09:07.675012  5078 sgd_solver.cpp:105] Iteration 20600, lr = 0.1
I1007 18:09:16.016734  5078 solver.cpp:218] Iteration 20700 (11.988 iter/s, 8.3417s/100 iters), loss = 0.199663
I1007 18:09:16.016774  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.199662 (* 1 = 0.199662 loss)
I1007 18:09:16.016779  5078 sgd_solver.cpp:105] Iteration 20700, lr = 0.1
I1007 18:09:24.358853  5078 solver.cpp:218] Iteration 20800 (11.9875 iter/s, 8.34205s/100 iters), loss = 0.193582
I1007 18:09:24.358973  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.193582 (* 1 = 0.193582 loss)
I1007 18:09:24.358989  5078 sgd_solver.cpp:105] Iteration 20800, lr = 0.1
I1007 18:09:32.699628  5078 solver.cpp:218] Iteration 20900 (11.9895 iter/s, 8.34063s/100 iters), loss = 0.248691
I1007 18:09:32.699668  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.24869 (* 1 = 0.24869 loss)
I1007 18:09:32.699674  5078 sgd_solver.cpp:105] Iteration 20900, lr = 0.1
I1007 18:09:40.631003  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:09:40.964936  5078 solver.cpp:330] Iteration 21000, Testing net (#0)
I1007 18:09:42.891523  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:09:42.972502  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7597
I1007 18:09:42.972529  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.866506 (* 1 = 0.866506 loss)
I1007 18:09:43.054993  5078 solver.cpp:218] Iteration 21000 (9.6569 iter/s, 10.3553s/100 iters), loss = 0.24126
I1007 18:09:43.055019  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.241259 (* 1 = 0.241259 loss)
I1007 18:09:43.055027  5078 sgd_solver.cpp:105] Iteration 21000, lr = 0.1
I1007 18:09:51.391396  5078 solver.cpp:218] Iteration 21100 (11.9957 iter/s, 8.33635s/100 iters), loss = 0.209129
I1007 18:09:51.391438  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.209129 (* 1 = 0.209129 loss)
I1007 18:09:51.391443  5078 sgd_solver.cpp:105] Iteration 21100, lr = 0.1
I1007 18:09:59.738929  5078 solver.cpp:218] Iteration 21200 (11.9797 iter/s, 8.34746s/100 iters), loss = 0.234818
I1007 18:09:59.739001  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.234817 (* 1 = 0.234817 loss)
I1007 18:09:59.739022  5078 sgd_solver.cpp:105] Iteration 21200, lr = 0.1
I1007 18:10:08.082411  5078 solver.cpp:218] Iteration 21300 (11.9855 iter/s, 8.34338s/100 iters), loss = 0.237775
I1007 18:10:08.082451  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.237774 (* 1 = 0.237774 loss)
I1007 18:10:08.082458  5078 sgd_solver.cpp:105] Iteration 21300, lr = 0.1
I1007 18:10:16.431632  5078 solver.cpp:218] Iteration 21400 (11.9773 iter/s, 8.34915s/100 iters), loss = 0.173829
I1007 18:10:16.431673  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.173829 (* 1 = 0.173829 loss)
I1007 18:10:16.431679  5078 sgd_solver.cpp:105] Iteration 21400, lr = 0.1
I1007 18:10:24.362323  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:10:24.696449  5078 solver.cpp:330] Iteration 21500, Testing net (#0)
I1007 18:10:26.623176  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:10:26.703388  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7814
I1007 18:10:26.703424  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.685917 (* 1 = 0.685917 loss)
I1007 18:10:26.787292  5078 solver.cpp:218] Iteration 21500 (9.65662 iter/s, 10.3556s/100 iters), loss = 0.175096
I1007 18:10:26.787318  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.175095 (* 1 = 0.175095 loss)
I1007 18:10:26.787325  5078 sgd_solver.cpp:105] Iteration 21500, lr = 0.1
I1007 18:10:35.137055  5078 solver.cpp:218] Iteration 21600 (11.9765 iter/s, 8.34971s/100 iters), loss = 0.258011
I1007 18:10:35.137177  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.25801 (* 1 = 0.25801 loss)
I1007 18:10:35.137186  5078 sgd_solver.cpp:105] Iteration 21600, lr = 0.1
I1007 18:10:43.477250  5078 solver.cpp:218] Iteration 21700 (11.9903 iter/s, 8.34006s/100 iters), loss = 0.187869
I1007 18:10:43.477290  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.187868 (* 1 = 0.187868 loss)
I1007 18:10:43.477296  5078 sgd_solver.cpp:105] Iteration 21700, lr = 0.1
I1007 18:10:51.822830  5078 solver.cpp:218] Iteration 21800 (11.9825 iter/s, 8.34552s/100 iters), loss = 0.20628
I1007 18:10:51.822870  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.20628 (* 1 = 0.20628 loss)
I1007 18:10:51.822876  5078 sgd_solver.cpp:105] Iteration 21800, lr = 0.1
I1007 18:11:00.165236  5078 solver.cpp:218] Iteration 21900 (11.9871 iter/s, 8.34234s/100 iters), loss = 0.272945
I1007 18:11:00.165277  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.272944 (* 1 = 0.272944 loss)
I1007 18:11:00.165282  5078 sgd_solver.cpp:105] Iteration 21900, lr = 0.1
I1007 18:11:08.099443  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:11:08.433506  5078 solver.cpp:330] Iteration 22000, Testing net (#0)
I1007 18:11:10.359681  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:11:10.440425  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8211
I1007 18:11:10.440460  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.558199 (* 1 = 0.558199 loss)
I1007 18:11:10.523579  5078 solver.cpp:218] Iteration 22000 (9.65412 iter/s, 10.3583s/100 iters), loss = 0.199956
I1007 18:11:10.523617  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.199956 (* 1 = 0.199956 loss)
I1007 18:11:10.523623  5078 sgd_solver.cpp:105] Iteration 22000, lr = 0.1
I1007 18:11:18.867947  5078 solver.cpp:218] Iteration 22100 (11.9842 iter/s, 8.34431s/100 iters), loss = 0.247188
I1007 18:11:18.867986  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.247187 (* 1 = 0.247187 loss)
I1007 18:11:18.867992  5078 sgd_solver.cpp:105] Iteration 22100, lr = 0.1
I1007 18:11:27.212237  5078 solver.cpp:218] Iteration 22200 (11.9843 iter/s, 8.34422s/100 iters), loss = 0.153023
I1007 18:11:27.212278  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.153022 (* 1 = 0.153022 loss)
I1007 18:11:27.212283  5078 sgd_solver.cpp:105] Iteration 22200, lr = 0.1
I1007 18:11:35.554034  5078 solver.cpp:218] Iteration 22300 (11.9879 iter/s, 8.34173s/100 iters), loss = 0.221542
I1007 18:11:35.554074  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.221541 (* 1 = 0.221541 loss)
I1007 18:11:35.554080  5078 sgd_solver.cpp:105] Iteration 22300, lr = 0.1
I1007 18:11:43.902042  5078 solver.cpp:218] Iteration 22400 (11.979 iter/s, 8.34794s/100 iters), loss = 0.242746
I1007 18:11:43.902115  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.242745 (* 1 = 0.242745 loss)
I1007 18:11:43.902122  5078 sgd_solver.cpp:105] Iteration 22400, lr = 0.1
I1007 18:11:51.830251  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:11:52.164647  5078 solver.cpp:330] Iteration 22500, Testing net (#0)
I1007 18:11:54.090574  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:11:54.171023  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8222
I1007 18:11:54.171057  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.529058 (* 1 = 0.529058 loss)
I1007 18:11:54.255031  5078 solver.cpp:218] Iteration 22500 (9.65915 iter/s, 10.3529s/100 iters), loss = 0.224614
I1007 18:11:54.255065  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.224613 (* 1 = 0.224613 loss)
I1007 18:11:54.255071  5078 sgd_solver.cpp:105] Iteration 22500, lr = 0.1
I1007 18:12:02.603852  5078 solver.cpp:218] Iteration 22600 (11.9778 iter/s, 8.34876s/100 iters), loss = 0.194914
I1007 18:12:02.603893  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.194913 (* 1 = 0.194913 loss)
I1007 18:12:02.603899  5078 sgd_solver.cpp:105] Iteration 22600, lr = 0.1
I1007 18:12:10.944861  5078 solver.cpp:218] Iteration 22700 (11.9891 iter/s, 8.34094s/100 iters), loss = 0.238653
I1007 18:12:10.944900  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.238652 (* 1 = 0.238652 loss)
I1007 18:12:10.944905  5078 sgd_solver.cpp:105] Iteration 22700, lr = 0.1
I1007 18:12:19.289675  5078 solver.cpp:218] Iteration 22800 (11.9836 iter/s, 8.34475s/100 iters), loss = 0.309994
I1007 18:12:19.289810  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.309993 (* 1 = 0.309993 loss)
I1007 18:12:19.289818  5078 sgd_solver.cpp:105] Iteration 22800, lr = 0.1
I1007 18:12:27.632877  5078 solver.cpp:218] Iteration 22900 (11.986 iter/s, 8.34304s/100 iters), loss = 0.163332
I1007 18:12:27.632917  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.163332 (* 1 = 0.163332 loss)
I1007 18:12:27.632923  5078 sgd_solver.cpp:105] Iteration 22900, lr = 0.1
I1007 18:12:35.561151  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:12:35.895653  5078 solver.cpp:330] Iteration 23000, Testing net (#0)
I1007 18:12:37.822049  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:12:37.902886  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8167
I1007 18:12:37.902912  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.566214 (* 1 = 0.566214 loss)
I1007 18:12:37.985911  5078 solver.cpp:218] Iteration 23000 (9.65907 iter/s, 10.353s/100 iters), loss = 0.263905
I1007 18:12:37.985946  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.263905 (* 1 = 0.263905 loss)
I1007 18:12:37.985952  5078 sgd_solver.cpp:105] Iteration 23000, lr = 0.1
I1007 18:12:46.327610  5078 solver.cpp:218] Iteration 23100 (11.9881 iter/s, 8.34164s/100 iters), loss = 0.173702
I1007 18:12:46.327651  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.173701 (* 1 = 0.173701 loss)
I1007 18:12:46.327656  5078 sgd_solver.cpp:105] Iteration 23100, lr = 0.1
I1007 18:12:54.681452  5078 solver.cpp:218] Iteration 23200 (11.9706 iter/s, 8.35377s/100 iters), loss = 0.209517
I1007 18:12:54.681522  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.209517 (* 1 = 0.209517 loss)
I1007 18:12:54.681529  5078 sgd_solver.cpp:105] Iteration 23200, lr = 0.1
I1007 18:13:03.027137  5078 solver.cpp:218] Iteration 23300 (11.9824 iter/s, 8.3456s/100 iters), loss = 0.192864
I1007 18:13:03.027168  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.192863 (* 1 = 0.192863 loss)
I1007 18:13:03.027175  5078 sgd_solver.cpp:105] Iteration 23300, lr = 0.1
I1007 18:13:11.379729  5078 solver.cpp:218] Iteration 23400 (11.9724 iter/s, 8.35253s/100 iters), loss = 0.181734
I1007 18:13:11.379770  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.181734 (* 1 = 0.181734 loss)
I1007 18:13:11.379775  5078 sgd_solver.cpp:105] Iteration 23400, lr = 0.1
I1007 18:13:19.312579  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:13:19.647056  5078 solver.cpp:330] Iteration 23500, Testing net (#0)
I1007 18:13:21.573822  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:13:21.653035  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7731
I1007 18:13:21.653071  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.748424 (* 1 = 0.748424 loss)
I1007 18:13:21.736706  5078 solver.cpp:218] Iteration 23500 (9.65539 iter/s, 10.3569s/100 iters), loss = 0.183535
I1007 18:13:21.736733  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.183535 (* 1 = 0.183535 loss)
I1007 18:13:21.736739  5078 sgd_solver.cpp:105] Iteration 23500, lr = 0.1
I1007 18:13:30.080091  5078 solver.cpp:218] Iteration 23600 (11.9856 iter/s, 8.34333s/100 iters), loss = 0.2035
I1007 18:13:30.080184  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.203499 (* 1 = 0.203499 loss)
I1007 18:13:30.080199  5078 sgd_solver.cpp:105] Iteration 23600, lr = 0.1
I1007 18:13:38.415304  5078 solver.cpp:218] Iteration 23700 (11.9975 iter/s, 8.3351s/100 iters), loss = 0.209495
I1007 18:13:38.415334  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.209495 (* 1 = 0.209495 loss)
I1007 18:13:38.415341  5078 sgd_solver.cpp:105] Iteration 23700, lr = 0.1
I1007 18:13:46.761293  5078 solver.cpp:218] Iteration 23800 (11.9819 iter/s, 8.34593s/100 iters), loss = 0.250519
I1007 18:13:46.761323  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.250519 (* 1 = 0.250519 loss)
I1007 18:13:46.761332  5078 sgd_solver.cpp:105] Iteration 23800, lr = 0.1
I1007 18:13:55.098465  5078 solver.cpp:218] Iteration 23900 (11.9946 iter/s, 8.33712s/100 iters), loss = 0.199326
I1007 18:13:55.098492  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.199326 (* 1 = 0.199326 loss)
I1007 18:13:55.098500  5078 sgd_solver.cpp:105] Iteration 23900, lr = 0.1
I1007 18:14:03.027937  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:14:03.362017  5078 solver.cpp:330] Iteration 24000, Testing net (#0)
I1007 18:14:05.286902  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:14:05.367811  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7476
I1007 18:14:05.367847  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.930973 (* 1 = 0.930973 loss)
I1007 18:14:05.451089  5078 solver.cpp:218] Iteration 24000 (9.65944 iter/s, 10.3526s/100 iters), loss = 0.144816
I1007 18:14:05.451117  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.144815 (* 1 = 0.144815 loss)
I1007 18:14:05.451123  5078 sgd_solver.cpp:105] Iteration 24000, lr = 0.1
I1007 18:14:13.794167  5078 solver.cpp:218] Iteration 24100 (11.9861 iter/s, 8.34302s/100 iters), loss = 0.142357
I1007 18:14:13.794198  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.142357 (* 1 = 0.142357 loss)
I1007 18:14:13.794203  5078 sgd_solver.cpp:105] Iteration 24100, lr = 0.1
I1007 18:14:22.144248  5078 solver.cpp:218] Iteration 24200 (11.976 iter/s, 8.35002s/100 iters), loss = 0.187949
I1007 18:14:22.144278  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.187948 (* 1 = 0.187948 loss)
I1007 18:14:22.144284  5078 sgd_solver.cpp:105] Iteration 24200, lr = 0.1
I1007 18:14:30.489979  5078 solver.cpp:218] Iteration 24300 (11.9823 iter/s, 8.34567s/100 iters), loss = 0.184663
I1007 18:14:30.490007  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.184663 (* 1 = 0.184663 loss)
I1007 18:14:30.490013  5078 sgd_solver.cpp:105] Iteration 24300, lr = 0.1
I1007 18:14:38.842722  5078 solver.cpp:218] Iteration 24400 (11.9722 iter/s, 8.35269s/100 iters), loss = 0.202283
I1007 18:14:38.842797  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.202282 (* 1 = 0.202282 loss)
I1007 18:14:38.842803  5078 sgd_solver.cpp:105] Iteration 24400, lr = 0.1
I1007 18:14:46.775187  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:14:47.109417  5078 solver.cpp:330] Iteration 24500, Testing net (#0)
I1007 18:14:49.035107  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:14:49.115597  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8056
I1007 18:14:49.115622  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.659858 (* 1 = 0.659858 loss)
I1007 18:14:49.199383  5078 solver.cpp:218] Iteration 24500 (9.65572 iter/s, 10.3566s/100 iters), loss = 0.188946
I1007 18:14:49.199409  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.188946 (* 1 = 0.188946 loss)
I1007 18:14:49.199416  5078 sgd_solver.cpp:105] Iteration 24500, lr = 0.1
I1007 18:14:57.543548  5078 solver.cpp:218] Iteration 24600 (11.9845 iter/s, 8.34411s/100 iters), loss = 0.224916
I1007 18:14:57.543588  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.224915 (* 1 = 0.224915 loss)
I1007 18:14:57.543594  5078 sgd_solver.cpp:105] Iteration 24600, lr = 0.1
I1007 18:15:05.879391  5078 solver.cpp:218] Iteration 24700 (11.9965 iter/s, 8.33578s/100 iters), loss = 0.14935
I1007 18:15:05.879420  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.149349 (* 1 = 0.149349 loss)
I1007 18:15:05.879426  5078 sgd_solver.cpp:105] Iteration 24700, lr = 0.1
I1007 18:15:14.223903  5078 solver.cpp:218] Iteration 24800 (11.984 iter/s, 8.34445s/100 iters), loss = 0.234009
I1007 18:15:14.223973  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.234008 (* 1 = 0.234008 loss)
I1007 18:15:14.223979  5078 sgd_solver.cpp:105] Iteration 24800, lr = 0.1
I1007 18:15:22.558910  5078 solver.cpp:218] Iteration 24900 (11.9977 iter/s, 8.33491s/100 iters), loss = 0.1929
I1007 18:15:22.558940  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.192899 (* 1 = 0.192899 loss)
I1007 18:15:22.558948  5078 sgd_solver.cpp:105] Iteration 24900, lr = 0.1
I1007 18:15:30.487550  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:15:30.821420  5078 solver.cpp:330] Iteration 25000, Testing net (#0)
I1007 18:15:32.746868  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:15:32.827610  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8054
I1007 18:15:32.827643  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.569086 (* 1 = 0.569086 loss)
I1007 18:15:32.910531  5078 solver.cpp:218] Iteration 25000 (9.66038 iter/s, 10.3516s/100 iters), loss = 0.252652
I1007 18:15:32.910558  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.252652 (* 1 = 0.252652 loss)
I1007 18:15:32.910565  5078 sgd_solver.cpp:105] Iteration 25000, lr = 0.1
I1007 18:15:41.248212  5078 solver.cpp:218] Iteration 25100 (11.9938 iter/s, 8.33762s/100 iters), loss = 0.187041
I1007 18:15:41.248241  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.18704 (* 1 = 0.18704 loss)
I1007 18:15:41.248247  5078 sgd_solver.cpp:105] Iteration 25100, lr = 0.1
I1007 18:15:49.592939  5078 solver.cpp:218] Iteration 25200 (11.9837 iter/s, 8.34467s/100 iters), loss = 0.22865
I1007 18:15:49.593039  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.22865 (* 1 = 0.22865 loss)
I1007 18:15:49.593047  5078 sgd_solver.cpp:105] Iteration 25200, lr = 0.1
I1007 18:15:57.928864  5078 solver.cpp:218] Iteration 25300 (11.9965 iter/s, 8.3358s/100 iters), loss = 0.180284
I1007 18:15:57.928892  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.180284 (* 1 = 0.180284 loss)
I1007 18:15:57.928899  5078 sgd_solver.cpp:105] Iteration 25300, lr = 0.1
I1007 18:16:06.273106  5078 solver.cpp:218] Iteration 25400 (11.9844 iter/s, 8.34419s/100 iters), loss = 0.197992
I1007 18:16:06.273136  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.197992 (* 1 = 0.197992 loss)
I1007 18:16:06.273142  5078 sgd_solver.cpp:105] Iteration 25400, lr = 0.1
I1007 18:16:14.200585  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:16:14.535526  5078 solver.cpp:330] Iteration 25500, Testing net (#0)
I1007 18:16:16.460726  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:16:16.541154  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7422
I1007 18:16:16.541190  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.918195 (* 1 = 0.918195 loss)
I1007 18:16:16.624634  5078 solver.cpp:218] Iteration 25500 (9.66047 iter/s, 10.3515s/100 iters), loss = 0.303302
I1007 18:16:16.624660  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.303301 (* 1 = 0.303301 loss)
I1007 18:16:16.624667  5078 sgd_solver.cpp:105] Iteration 25500, lr = 0.1
I1007 18:16:24.971601  5078 solver.cpp:218] Iteration 25600 (11.9805 iter/s, 8.34691s/100 iters), loss = 0.183498
I1007 18:16:24.971658  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.183497 (* 1 = 0.183497 loss)
I1007 18:16:24.971664  5078 sgd_solver.cpp:105] Iteration 25600, lr = 0.1
I1007 18:16:33.316792  5078 solver.cpp:218] Iteration 25700 (11.9831 iter/s, 8.34511s/100 iters), loss = 0.26575
I1007 18:16:33.316833  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.26575 (* 1 = 0.26575 loss)
I1007 18:16:33.316839  5078 sgd_solver.cpp:105] Iteration 25700, lr = 0.1
I1007 18:16:41.665145  5078 solver.cpp:218] Iteration 25800 (11.9785 iter/s, 8.34828s/100 iters), loss = 0.206102
I1007 18:16:41.665184  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.206102 (* 1 = 0.206102 loss)
I1007 18:16:41.665189  5078 sgd_solver.cpp:105] Iteration 25800, lr = 0.1
I1007 18:16:50.008267  5078 solver.cpp:218] Iteration 25900 (11.986 iter/s, 8.34306s/100 iters), loss = 0.200433
I1007 18:16:50.008296  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.200432 (* 1 = 0.200432 loss)
I1007 18:16:50.008301  5078 sgd_solver.cpp:105] Iteration 25900, lr = 0.1
I1007 18:16:57.947578  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:16:58.281193  5078 solver.cpp:330] Iteration 26000, Testing net (#0)
I1007 18:17:00.207202  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:17:00.287329  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6973
I1007 18:17:00.287365  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.05931 (* 1 = 1.05931 loss)
I1007 18:17:00.371238  5078 solver.cpp:218] Iteration 26000 (9.6498 iter/s, 10.3629s/100 iters), loss = 0.214498
I1007 18:17:00.371266  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.214497 (* 1 = 0.214497 loss)
I1007 18:17:00.371273  5078 sgd_solver.cpp:105] Iteration 26000, lr = 0.1
I1007 18:17:08.715346  5078 solver.cpp:218] Iteration 26100 (11.9846 iter/s, 8.34405s/100 iters), loss = 0.228957
I1007 18:17:08.715376  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.228957 (* 1 = 0.228957 loss)
I1007 18:17:08.715381  5078 sgd_solver.cpp:105] Iteration 26100, lr = 0.1
I1007 18:17:17.069553  5078 solver.cpp:218] Iteration 26200 (11.9701 iter/s, 8.35415s/100 iters), loss = 0.195968
I1007 18:17:17.069593  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.195967 (* 1 = 0.195967 loss)
I1007 18:17:17.069599  5078 sgd_solver.cpp:105] Iteration 26200, lr = 0.1
I1007 18:17:25.420249  5078 solver.cpp:218] Iteration 26300 (11.9751 iter/s, 8.35063s/100 iters), loss = 0.179577
I1007 18:17:25.420279  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.179576 (* 1 = 0.179576 loss)
I1007 18:17:25.420285  5078 sgd_solver.cpp:105] Iteration 26300, lr = 0.1
I1007 18:17:33.772912  5078 solver.cpp:218] Iteration 26400 (11.9723 iter/s, 8.3526s/100 iters), loss = 0.177634
I1007 18:17:33.772991  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.177633 (* 1 = 0.177633 loss)
I1007 18:17:33.773007  5078 sgd_solver.cpp:105] Iteration 26400, lr = 0.1
I1007 18:17:41.706109  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:17:42.040468  5078 solver.cpp:330] Iteration 26500, Testing net (#0)
I1007 18:17:43.966712  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:17:44.047013  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8279
I1007 18:17:44.047049  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.5482 (* 1 = 0.5482 loss)
I1007 18:17:44.130633  5078 solver.cpp:218] Iteration 26500 (9.65474 iter/s, 10.3576s/100 iters), loss = 0.136918
I1007 18:17:44.130664  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.136918 (* 1 = 0.136918 loss)
I1007 18:17:44.130671  5078 sgd_solver.cpp:105] Iteration 26500, lr = 0.1
I1007 18:17:52.482286  5078 solver.cpp:218] Iteration 26600 (11.9738 iter/s, 8.35159s/100 iters), loss = 0.190899
I1007 18:17:52.482326  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.190899 (* 1 = 0.190899 loss)
I1007 18:17:52.482332  5078 sgd_solver.cpp:105] Iteration 26600, lr = 0.1
I1007 18:18:00.827191  5078 solver.cpp:218] Iteration 26700 (11.9835 iter/s, 8.34484s/100 iters), loss = 0.185753
I1007 18:18:00.827232  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.185752 (* 1 = 0.185752 loss)
I1007 18:18:00.827239  5078 sgd_solver.cpp:105] Iteration 26700, lr = 0.1
I1007 18:18:09.178099  5078 solver.cpp:218] Iteration 26800 (11.9748 iter/s, 8.35084s/100 iters), loss = 0.227073
I1007 18:18:09.178166  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.227072 (* 1 = 0.227072 loss)
I1007 18:18:09.178172  5078 sgd_solver.cpp:105] Iteration 26800, lr = 0.1
I1007 18:18:17.521417  5078 solver.cpp:218] Iteration 26900 (11.9858 iter/s, 8.34323s/100 iters), loss = 0.242071
I1007 18:18:17.521457  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.242071 (* 1 = 0.242071 loss)
I1007 18:18:17.521463  5078 sgd_solver.cpp:105] Iteration 26900, lr = 0.1
I1007 18:18:25.452759  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:18:25.786962  5078 solver.cpp:330] Iteration 27000, Testing net (#0)
I1007 18:18:27.712306  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:18:27.793000  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7431
I1007 18:18:27.793035  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.845496 (* 1 = 0.845496 loss)
I1007 18:18:27.875375  5078 solver.cpp:218] Iteration 27000 (9.65821 iter/s, 10.3539s/100 iters), loss = 0.201353
I1007 18:18:27.875401  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.201352 (* 1 = 0.201352 loss)
I1007 18:18:27.875406  5078 sgd_solver.cpp:105] Iteration 27000, lr = 0.1
I1007 18:18:36.218109  5078 solver.cpp:218] Iteration 27100 (11.9866 iter/s, 8.34268s/100 iters), loss = 0.203568
I1007 18:18:36.218150  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.203568 (* 1 = 0.203568 loss)
I1007 18:18:36.218158  5078 sgd_solver.cpp:105] Iteration 27100, lr = 0.1
I1007 18:18:44.572518  5078 solver.cpp:218] Iteration 27200 (11.9698 iter/s, 8.35434s/100 iters), loss = 0.280159
I1007 18:18:44.572623  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.280158 (* 1 = 0.280158 loss)
I1007 18:18:44.572638  5078 sgd_solver.cpp:105] Iteration 27200, lr = 0.1
I1007 18:18:52.916401  5078 solver.cpp:218] Iteration 27300 (11.985 iter/s, 8.34376s/100 iters), loss = 0.281822
I1007 18:18:52.916442  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.281821 (* 1 = 0.281821 loss)
I1007 18:18:52.916448  5078 sgd_solver.cpp:105] Iteration 27300, lr = 0.1
I1007 18:19:01.269294  5078 solver.cpp:218] Iteration 27400 (11.972 iter/s, 8.35282s/100 iters), loss = 0.235949
I1007 18:19:01.269335  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.235949 (* 1 = 0.235949 loss)
I1007 18:19:01.269340  5078 sgd_solver.cpp:105] Iteration 27400, lr = 0.1
I1007 18:19:09.201067  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:19:09.535104  5078 solver.cpp:330] Iteration 27500, Testing net (#0)
I1007 18:19:11.460629  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:19:11.540851  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7897
I1007 18:19:11.540887  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.626324 (* 1 = 0.626324 loss)
I1007 18:19:11.624981  5078 solver.cpp:218] Iteration 27500 (9.6566 iter/s, 10.3556s/100 iters), loss = 0.19944
I1007 18:19:11.625007  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.19944 (* 1 = 0.19944 loss)
I1007 18:19:11.625015  5078 sgd_solver.cpp:105] Iteration 27500, lr = 0.1
I1007 18:19:19.974879  5078 solver.cpp:218] Iteration 27600 (11.9763 iter/s, 8.34984s/100 iters), loss = 0.171637
I1007 18:19:19.974987  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.171636 (* 1 = 0.171636 loss)
I1007 18:19:19.974992  5078 sgd_solver.cpp:105] Iteration 27600, lr = 0.1
I1007 18:19:28.314906  5078 solver.cpp:218] Iteration 27700 (11.9906 iter/s, 8.33989s/100 iters), loss = 0.185657
I1007 18:19:28.314947  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.185657 (* 1 = 0.185657 loss)
I1007 18:19:28.314954  5078 sgd_solver.cpp:105] Iteration 27700, lr = 0.1
I1007 18:19:36.667961  5078 solver.cpp:218] Iteration 27800 (11.9718 iter/s, 8.35299s/100 iters), loss = 0.225889
I1007 18:19:36.668001  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.225888 (* 1 = 0.225888 loss)
I1007 18:19:36.668007  5078 sgd_solver.cpp:105] Iteration 27800, lr = 0.1
I1007 18:19:45.011206  5078 solver.cpp:218] Iteration 27900 (11.9858 iter/s, 8.34318s/100 iters), loss = 0.189367
I1007 18:19:45.011247  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.189366 (* 1 = 0.189366 loss)
I1007 18:19:45.011253  5078 sgd_solver.cpp:105] Iteration 27900, lr = 0.1
I1007 18:19:52.947440  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:19:53.280971  5078 solver.cpp:330] Iteration 28000, Testing net (#0)
I1007 18:19:55.206662  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:19:55.287868  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7485
I1007 18:19:55.287904  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.830555 (* 1 = 0.830555 loss)
I1007 18:19:55.370952  5078 solver.cpp:218] Iteration 28000 (9.65281 iter/s, 10.3597s/100 iters), loss = 0.27105
I1007 18:19:55.370977  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.271049 (* 1 = 0.271049 loss)
I1007 18:19:55.370983  5078 sgd_solver.cpp:105] Iteration 28000, lr = 0.1
I1007 18:20:03.716322  5078 solver.cpp:218] Iteration 28100 (11.9828 iter/s, 8.34532s/100 iters), loss = 0.218409
I1007 18:20:03.716351  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.218408 (* 1 = 0.218408 loss)
I1007 18:20:03.716356  5078 sgd_solver.cpp:105] Iteration 28100, lr = 0.1
I1007 18:20:12.067358  5078 solver.cpp:218] Iteration 28200 (11.9746 iter/s, 8.35098s/100 iters), loss = 0.140536
I1007 18:20:12.067397  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.140535 (* 1 = 0.140535 loss)
I1007 18:20:12.067404  5078 sgd_solver.cpp:105] Iteration 28200, lr = 0.1
I1007 18:20:20.413007  5078 solver.cpp:218] Iteration 28300 (11.9824 iter/s, 8.34558s/100 iters), loss = 0.202674
I1007 18:20:20.413048  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.202673 (* 1 = 0.202673 loss)
I1007 18:20:20.413054  5078 sgd_solver.cpp:105] Iteration 28300, lr = 0.1
I1007 18:20:28.768170  5078 solver.cpp:218] Iteration 28400 (11.9687 iter/s, 8.3551s/100 iters), loss = 0.176225
I1007 18:20:28.768232  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.176225 (* 1 = 0.176225 loss)
I1007 18:20:28.768249  5078 sgd_solver.cpp:105] Iteration 28400, lr = 0.1
I1007 18:20:36.704644  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:20:37.039078  5078 solver.cpp:330] Iteration 28500, Testing net (#0)
I1007 18:20:38.965337  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:20:39.045168  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8103
I1007 18:20:39.045203  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.595219 (* 1 = 0.595219 loss)
I1007 18:20:39.128677  5078 solver.cpp:218] Iteration 28500 (9.65212 iter/s, 10.3604s/100 iters), loss = 0.135781
I1007 18:20:39.128710  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.13578 (* 1 = 0.13578 loss)
I1007 18:20:39.128716  5078 sgd_solver.cpp:105] Iteration 28500, lr = 0.1
I1007 18:20:47.481117  5078 solver.cpp:218] Iteration 28600 (11.9726 iter/s, 8.35238s/100 iters), loss = 0.203139
I1007 18:20:47.481156  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.203139 (* 1 = 0.203139 loss)
I1007 18:20:47.481161  5078 sgd_solver.cpp:105] Iteration 28600, lr = 0.1
I1007 18:20:55.827962  5078 solver.cpp:218] Iteration 28700 (11.9807 iter/s, 8.34678s/100 iters), loss = 0.199539
I1007 18:20:55.828002  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.199538 (* 1 = 0.199538 loss)
I1007 18:20:55.828008  5078 sgd_solver.cpp:105] Iteration 28700, lr = 0.1
I1007 18:21:04.180860  5078 solver.cpp:218] Iteration 28800 (11.972 iter/s, 8.35283s/100 iters), loss = 0.179634
I1007 18:21:04.180928  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.179634 (* 1 = 0.179634 loss)
I1007 18:21:04.180935  5078 sgd_solver.cpp:105] Iteration 28800, lr = 0.1
I1007 18:21:12.528868  5078 solver.cpp:218] Iteration 28900 (11.979 iter/s, 8.34791s/100 iters), loss = 0.203391
I1007 18:21:12.528908  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.20339 (* 1 = 0.20339 loss)
I1007 18:21:12.528914  5078 sgd_solver.cpp:105] Iteration 28900, lr = 0.1
I1007 18:21:20.469215  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:21:20.804857  5078 solver.cpp:330] Iteration 29000, Testing net (#0)
I1007 18:21:22.728950  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:21:22.809391  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7576
I1007 18:21:22.809417  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.794017 (* 1 = 0.794017 loss)
I1007 18:21:22.892438  5078 solver.cpp:218] Iteration 29000 (9.64925 iter/s, 10.3635s/100 iters), loss = 0.20214
I1007 18:21:22.892464  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.202139 (* 1 = 0.202139 loss)
I1007 18:21:22.892472  5078 sgd_solver.cpp:105] Iteration 29000, lr = 0.1
I1007 18:21:31.242920  5078 solver.cpp:218] Iteration 29100 (11.9754 iter/s, 8.35043s/100 iters), loss = 0.213066
I1007 18:21:31.242960  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.213065 (* 1 = 0.213065 loss)
I1007 18:21:31.242966  5078 sgd_solver.cpp:105] Iteration 29100, lr = 0.1
I1007 18:21:39.594394  5078 solver.cpp:218] Iteration 29200 (11.974 iter/s, 8.35141s/100 iters), loss = 0.194535
I1007 18:21:39.594530  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.194535 (* 1 = 0.194535 loss)
I1007 18:21:39.594548  5078 sgd_solver.cpp:105] Iteration 29200, lr = 0.1
I1007 18:21:47.941690  5078 solver.cpp:218] Iteration 29300 (11.9802 iter/s, 8.34714s/100 iters), loss = 0.170399
I1007 18:21:47.941730  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.170398 (* 1 = 0.170398 loss)
I1007 18:21:47.941736  5078 sgd_solver.cpp:105] Iteration 29300, lr = 0.1
I1007 18:21:56.293123  5078 solver.cpp:218] Iteration 29400 (11.9741 iter/s, 8.35137s/100 iters), loss = 0.1747
I1007 18:21:56.293164  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.174699 (* 1 = 0.174699 loss)
I1007 18:21:56.293169  5078 sgd_solver.cpp:105] Iteration 29400, lr = 0.1
I1007 18:22:04.226357  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:22:04.560596  5078 solver.cpp:330] Iteration 29500, Testing net (#0)
I1007 18:22:06.486640  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:22:06.566609  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7365
I1007 18:22:06.566646  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.810704 (* 1 = 0.810704 loss)
I1007 18:22:06.650197  5078 solver.cpp:218] Iteration 29500 (9.6553 iter/s, 10.357s/100 iters), loss = 0.197351
I1007 18:22:06.650221  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.19735 (* 1 = 0.19735 loss)
I1007 18:22:06.650228  5078 sgd_solver.cpp:105] Iteration 29500, lr = 0.1
I1007 18:22:15.001672  5078 solver.cpp:218] Iteration 29600 (11.974 iter/s, 8.35142s/100 iters), loss = 0.124705
I1007 18:22:15.001762  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.124704 (* 1 = 0.124704 loss)
I1007 18:22:15.001770  5078 sgd_solver.cpp:105] Iteration 29600, lr = 0.1
I1007 18:22:23.349370  5078 solver.cpp:218] Iteration 29700 (11.9795 iter/s, 8.34758s/100 iters), loss = 0.248202
I1007 18:22:23.349400  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.248201 (* 1 = 0.248201 loss)
I1007 18:22:23.349406  5078 sgd_solver.cpp:105] Iteration 29700, lr = 0.1
I1007 18:22:31.702246  5078 solver.cpp:218] Iteration 29800 (11.972 iter/s, 8.35282s/100 iters), loss = 0.134284
I1007 18:22:31.702275  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.134283 (* 1 = 0.134283 loss)
I1007 18:22:31.702280  5078 sgd_solver.cpp:105] Iteration 29800, lr = 0.1
I1007 18:22:40.049108  5078 solver.cpp:218] Iteration 29900 (11.9806 iter/s, 8.34681s/100 iters), loss = 0.166121
I1007 18:22:40.049139  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.166121 (* 1 = 0.166121 loss)
I1007 18:22:40.049154  5078 sgd_solver.cpp:105] Iteration 29900, lr = 0.1
I1007 18:22:47.989809  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:22:48.324049  5078 solver.cpp:330] Iteration 30000, Testing net (#0)
I1007 18:22:50.250563  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:22:50.330974  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7618
I1007 18:22:50.331010  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.789205 (* 1 = 0.789205 loss)
I1007 18:22:50.413704  5078 solver.cpp:218] Iteration 30000 (9.64829 iter/s, 10.3645s/100 iters), loss = 0.213692
I1007 18:22:50.413730  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.213691 (* 1 = 0.213691 loss)
I1007 18:22:50.413738  5078 sgd_solver.cpp:105] Iteration 30000, lr = 0.1
I1007 18:22:58.761831  5078 solver.cpp:218] Iteration 30100 (11.9788 iter/s, 8.34807s/100 iters), loss = 0.193282
I1007 18:22:58.761873  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.193282 (* 1 = 0.193282 loss)
I1007 18:22:58.761878  5078 sgd_solver.cpp:105] Iteration 30100, lr = 0.1
I1007 18:23:07.113759  5078 solver.cpp:218] Iteration 30200 (11.9734 iter/s, 8.35186s/100 iters), loss = 0.136416
I1007 18:23:07.113787  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.136415 (* 1 = 0.136415 loss)
I1007 18:23:07.113793  5078 sgd_solver.cpp:105] Iteration 30200, lr = 0.1
I1007 18:23:15.453506  5078 solver.cpp:218] Iteration 30300 (11.9909 iter/s, 8.33969s/100 iters), loss = 0.123925
I1007 18:23:15.453547  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.123925 (* 1 = 0.123925 loss)
I1007 18:23:15.453553  5078 sgd_solver.cpp:105] Iteration 30300, lr = 0.1
I1007 18:23:23.795449  5078 solver.cpp:218] Iteration 30400 (11.9877 iter/s, 8.34188s/100 iters), loss = 0.106248
I1007 18:23:23.795553  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.106248 (* 1 = 0.106248 loss)
I1007 18:23:23.795560  5078 sgd_solver.cpp:105] Iteration 30400, lr = 0.1
I1007 18:23:31.727275  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:23:32.062256  5078 solver.cpp:330] Iteration 30500, Testing net (#0)
I1007 18:23:33.988816  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:23:34.069346  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8267
I1007 18:23:34.069381  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.517191 (* 1 = 0.517191 loss)
I1007 18:23:34.152709  5078 solver.cpp:218] Iteration 30500 (9.65519 iter/s, 10.3571s/100 iters), loss = 0.162158
I1007 18:23:34.152741  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.162158 (* 1 = 0.162158 loss)
I1007 18:23:34.152760  5078 sgd_solver.cpp:105] Iteration 30500, lr = 0.1
I1007 18:23:42.500095  5078 solver.cpp:218] Iteration 30600 (11.9799 iter/s, 8.34733s/100 iters), loss = 0.207208
I1007 18:23:42.500125  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.207208 (* 1 = 0.207208 loss)
I1007 18:23:42.500131  5078 sgd_solver.cpp:105] Iteration 30600, lr = 0.1
I1007 18:23:50.839814  5078 solver.cpp:218] Iteration 30700 (11.9909 iter/s, 8.33966s/100 iters), loss = 0.216642
I1007 18:23:50.839843  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.216642 (* 1 = 0.216642 loss)
I1007 18:23:50.839849  5078 sgd_solver.cpp:105] Iteration 30700, lr = 0.1
I1007 18:23:59.187899  5078 solver.cpp:218] Iteration 30800 (11.9789 iter/s, 8.34803s/100 iters), loss = 0.174702
I1007 18:23:59.187955  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.174702 (* 1 = 0.174702 loss)
I1007 18:23:59.187961  5078 sgd_solver.cpp:105] Iteration 30800, lr = 0.1
I1007 18:24:07.529953  5078 solver.cpp:218] Iteration 30900 (11.9876 iter/s, 8.34197s/100 iters), loss = 0.21015
I1007 18:24:07.529994  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.210149 (* 1 = 0.210149 loss)
I1007 18:24:07.529999  5078 sgd_solver.cpp:105] Iteration 30900, lr = 0.1
I1007 18:24:15.460223  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:24:15.794342  5078 solver.cpp:330] Iteration 31000, Testing net (#0)
I1007 18:24:17.719936  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:24:17.800951  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7741
I1007 18:24:17.800976  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.754303 (* 1 = 0.754303 loss)
I1007 18:24:17.883390  5078 solver.cpp:218] Iteration 31000 (9.65869 iter/s, 10.3534s/100 iters), loss = 0.174366
I1007 18:24:17.883417  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.174365 (* 1 = 0.174365 loss)
I1007 18:24:17.883424  5078 sgd_solver.cpp:105] Iteration 31000, lr = 0.1
I1007 18:24:26.227134  5078 solver.cpp:218] Iteration 31100 (11.9851 iter/s, 8.34369s/100 iters), loss = 0.170934
I1007 18:24:26.227167  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.170933 (* 1 = 0.170933 loss)
I1007 18:24:26.227174  5078 sgd_solver.cpp:105] Iteration 31100, lr = 0.1
I1007 18:24:34.575543  5078 solver.cpp:218] Iteration 31200 (11.9784 iter/s, 8.34835s/100 iters), loss = 0.173927
I1007 18:24:34.575660  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.173926 (* 1 = 0.173926 loss)
I1007 18:24:34.575667  5078 sgd_solver.cpp:105] Iteration 31200, lr = 0.1
I1007 18:24:42.914079  5078 solver.cpp:218] Iteration 31300 (11.9927 iter/s, 8.3384s/100 iters), loss = 0.220639
I1007 18:24:42.914120  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.220639 (* 1 = 0.220639 loss)
I1007 18:24:42.914126  5078 sgd_solver.cpp:105] Iteration 31300, lr = 0.1
I1007 18:24:51.263782  5078 solver.cpp:218] Iteration 31400 (11.9766 iter/s, 8.34964s/100 iters), loss = 0.162883
I1007 18:24:51.263811  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.162882 (* 1 = 0.162882 loss)
I1007 18:24:51.263818  5078 sgd_solver.cpp:105] Iteration 31400, lr = 0.1
I1007 18:24:59.195714  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:24:59.529762  5078 solver.cpp:330] Iteration 31500, Testing net (#0)
I1007 18:25:01.455427  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:25:01.535836  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8161
I1007 18:25:01.535871  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.559798 (* 1 = 0.559798 loss)
I1007 18:25:01.619249  5078 solver.cpp:218] Iteration 31500 (9.65679 iter/s, 10.3554s/100 iters), loss = 0.127349
I1007 18:25:01.619276  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.127348 (* 1 = 0.127348 loss)
I1007 18:25:01.619282  5078 sgd_solver.cpp:105] Iteration 31500, lr = 0.1
I1007 18:25:09.972717  5078 solver.cpp:218] Iteration 31600 (11.9712 iter/s, 8.35341s/100 iters), loss = 0.218334
I1007 18:25:09.972820  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.218333 (* 1 = 0.218333 loss)
I1007 18:25:09.972826  5078 sgd_solver.cpp:105] Iteration 31600, lr = 0.1
I1007 18:25:18.324544  5078 solver.cpp:218] Iteration 31700 (11.9736 iter/s, 8.3517s/100 iters), loss = 0.288309
I1007 18:25:18.324584  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.288309 (* 1 = 0.288309 loss)
I1007 18:25:18.324590  5078 sgd_solver.cpp:105] Iteration 31700, lr = 0.1
I1007 18:25:26.679488  5078 solver.cpp:218] Iteration 31800 (11.9691 iter/s, 8.35488s/100 iters), loss = 0.225294
I1007 18:25:26.679529  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.225293 (* 1 = 0.225293 loss)
I1007 18:25:26.679535  5078 sgd_solver.cpp:105] Iteration 31800, lr = 0.1
I1007 18:25:35.033157  5078 solver.cpp:218] Iteration 31900 (11.9709 iter/s, 8.3536s/100 iters), loss = 0.138731
I1007 18:25:35.033198  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.13873 (* 1 = 0.13873 loss)
I1007 18:25:35.033203  5078 sgd_solver.cpp:105] Iteration 31900, lr = 0.1
I1007 18:25:42.973062  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:25:43.307379  5078 solver.cpp:330] Iteration 32000, Testing net (#0)
I1007 18:25:45.232583  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:25:45.313730  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7175
I1007 18:25:45.313769  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.965923 (* 1 = 0.965923 loss)
I1007 18:25:45.396528  5078 solver.cpp:218] Iteration 32000 (9.64944 iter/s, 10.3633s/100 iters), loss = 0.187441
I1007 18:25:45.396555  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.187441 (* 1 = 0.187441 loss)
I1007 18:25:45.396562  5078 sgd_solver.cpp:105] Iteration 32000, lr = 0.1
I1007 18:25:53.741660  5078 solver.cpp:218] Iteration 32100 (11.9831 iter/s, 8.34507s/100 iters), loss = 0.127215
I1007 18:25:53.741690  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.127215 (* 1 = 0.127215 loss)
I1007 18:25:53.741696  5078 sgd_solver.cpp:105] Iteration 32100, lr = 0.1
I1007 18:26:02.098160  5078 solver.cpp:218] Iteration 32200 (11.9668 iter/s, 8.35644s/100 iters), loss = 0.153027
I1007 18:26:02.098187  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.153026 (* 1 = 0.153026 loss)
I1007 18:26:02.098192  5078 sgd_solver.cpp:105] Iteration 32200, lr = 0.1
I1007 18:26:10.445515  5078 solver.cpp:218] Iteration 32300 (11.9799 iter/s, 8.3473s/100 iters), loss = 0.280381
I1007 18:26:10.445545  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.28038 (* 1 = 0.28038 loss)
I1007 18:26:10.445551  5078 sgd_solver.cpp:105] Iteration 32300, lr = 0.1
I1007 18:26:18.801221  5078 solver.cpp:218] Iteration 32400 (11.9679 iter/s, 8.35565s/100 iters), loss = 0.147209
I1007 18:26:18.801350  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.147209 (* 1 = 0.147209 loss)
I1007 18:26:18.801357  5078 sgd_solver.cpp:105] Iteration 32400, lr = 0.1
I1007 18:26:26.743665  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:26:27.078773  5078 solver.cpp:330] Iteration 32500, Testing net (#0)
I1007 18:26:29.005149  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:26:29.085999  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7806
I1007 18:26:29.086024  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.742515 (* 1 = 0.742515 loss)
I1007 18:26:29.169472  5078 solver.cpp:218] Iteration 32500 (9.64497 iter/s, 10.3681s/100 iters), loss = 0.154517
I1007 18:26:29.169497  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.154517 (* 1 = 0.154517 loss)
I1007 18:26:29.169503  5078 sgd_solver.cpp:105] Iteration 32500, lr = 0.1
I1007 18:26:37.518239  5078 solver.cpp:218] Iteration 32600 (11.9779 iter/s, 8.34871s/100 iters), loss = 0.21687
I1007 18:26:37.518278  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.21687 (* 1 = 0.21687 loss)
I1007 18:26:37.518285  5078 sgd_solver.cpp:105] Iteration 32600, lr = 0.1
I1007 18:26:45.856122  5078 solver.cpp:218] Iteration 32700 (11.9935 iter/s, 8.33782s/100 iters), loss = 0.182775
I1007 18:26:45.856151  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.182774 (* 1 = 0.182774 loss)
I1007 18:26:45.856156  5078 sgd_solver.cpp:105] Iteration 32700, lr = 0.1
I1007 18:26:54.203634  5078 solver.cpp:218] Iteration 32800 (11.9797 iter/s, 8.34746s/100 iters), loss = 0.233452
I1007 18:26:54.203776  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.233452 (* 1 = 0.233452 loss)
I1007 18:26:54.203784  5078 sgd_solver.cpp:105] Iteration 32800, lr = 0.1
I1007 18:27:02.553948  5078 solver.cpp:218] Iteration 32900 (11.9758 iter/s, 8.35015s/100 iters), loss = 0.151864
I1007 18:27:02.553979  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.151864 (* 1 = 0.151864 loss)
I1007 18:27:02.553985  5078 sgd_solver.cpp:105] Iteration 32900, lr = 0.1
I1007 18:27:10.490802  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:27:10.826180  5078 solver.cpp:330] Iteration 33000, Testing net (#0)
I1007 18:27:12.751310  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:27:12.832253  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7284
I1007 18:27:12.832288  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.875176 (* 1 = 0.875176 loss)
I1007 18:27:12.915272  5078 solver.cpp:218] Iteration 33000 (9.65133 iter/s, 10.3613s/100 iters), loss = 0.128203
I1007 18:27:12.915297  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.128202 (* 1 = 0.128202 loss)
I1007 18:27:12.915303  5078 sgd_solver.cpp:105] Iteration 33000, lr = 0.1
I1007 18:27:21.263455  5078 solver.cpp:218] Iteration 33100 (11.9787 iter/s, 8.34813s/100 iters), loss = 0.282707
I1007 18:27:21.263495  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.282706 (* 1 = 0.282706 loss)
I1007 18:27:21.263501  5078 sgd_solver.cpp:105] Iteration 33100, lr = 0.1
I1007 18:27:29.623435  5078 solver.cpp:218] Iteration 33200 (11.9618 iter/s, 8.35992s/100 iters), loss = 0.158213
I1007 18:27:29.623541  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.158212 (* 1 = 0.158212 loss)
I1007 18:27:29.623558  5078 sgd_solver.cpp:105] Iteration 33200, lr = 0.1
I1007 18:27:37.972753  5078 solver.cpp:218] Iteration 33300 (11.9772 iter/s, 8.34919s/100 iters), loss = 0.124086
I1007 18:27:37.972793  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.124086 (* 1 = 0.124086 loss)
I1007 18:27:37.972800  5078 sgd_solver.cpp:105] Iteration 33300, lr = 0.1
I1007 18:27:46.326387  5078 solver.cpp:218] Iteration 33400 (11.9709 iter/s, 8.35357s/100 iters), loss = 0.140471
I1007 18:27:46.326427  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.14047 (* 1 = 0.14047 loss)
I1007 18:27:46.326433  5078 sgd_solver.cpp:105] Iteration 33400, lr = 0.1
I1007 18:27:54.260504  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:27:54.594907  5078 solver.cpp:330] Iteration 33500, Testing net (#0)
I1007 18:27:56.519140  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:27:56.599380  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6923
I1007 18:27:56.599405  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.18749 (* 1 = 1.18749 loss)
I1007 18:27:56.682773  5078 solver.cpp:218] Iteration 33500 (9.65594 iter/s, 10.3563s/100 iters), loss = 0.20472
I1007 18:27:56.682798  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.204719 (* 1 = 0.204719 loss)
I1007 18:27:56.682804  5078 sgd_solver.cpp:105] Iteration 33500, lr = 0.1
I1007 18:28:05.033732  5078 solver.cpp:218] Iteration 33600 (11.9747 iter/s, 8.35091s/100 iters), loss = 0.228148
I1007 18:28:05.033838  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.228148 (* 1 = 0.228148 loss)
I1007 18:28:05.033843  5078 sgd_solver.cpp:105] Iteration 33600, lr = 0.1
I1007 18:28:13.379755  5078 solver.cpp:218] Iteration 33700 (11.9819 iter/s, 8.34589s/100 iters), loss = 0.146538
I1007 18:28:13.379793  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.146537 (* 1 = 0.146537 loss)
I1007 18:28:13.379799  5078 sgd_solver.cpp:105] Iteration 33700, lr = 0.1
I1007 18:28:21.729238  5078 solver.cpp:218] Iteration 33800 (11.9769 iter/s, 8.34942s/100 iters), loss = 0.227894
I1007 18:28:21.729277  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.227894 (* 1 = 0.227894 loss)
I1007 18:28:21.729284  5078 sgd_solver.cpp:105] Iteration 33800, lr = 0.1
I1007 18:28:30.076783  5078 solver.cpp:218] Iteration 33900 (11.9797 iter/s, 8.34748s/100 iters), loss = 0.167172
I1007 18:28:30.076824  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.167172 (* 1 = 0.167172 loss)
I1007 18:28:30.076829  5078 sgd_solver.cpp:105] Iteration 33900, lr = 0.1
I1007 18:28:38.017472  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:28:38.352838  5078 solver.cpp:330] Iteration 34000, Testing net (#0)
I1007 18:28:40.277809  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:28:40.358213  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6797
I1007 18:28:40.358248  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.3088 (* 1 = 1.3088 loss)
I1007 18:28:40.441313  5078 solver.cpp:218] Iteration 34000 (9.64836 iter/s, 10.3645s/100 iters), loss = 0.129077
I1007 18:28:40.441339  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.129076 (* 1 = 0.129076 loss)
I1007 18:28:40.441345  5078 sgd_solver.cpp:105] Iteration 34000, lr = 0.1
I1007 18:28:48.785950  5078 solver.cpp:218] Iteration 34100 (11.9838 iter/s, 8.34459s/100 iters), loss = 0.296102
I1007 18:28:48.785980  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.296101 (* 1 = 0.296101 loss)
I1007 18:28:48.785986  5078 sgd_solver.cpp:105] Iteration 34100, lr = 0.1
I1007 18:28:57.139401  5078 solver.cpp:218] Iteration 34200 (11.9712 iter/s, 8.3534s/100 iters), loss = 0.229255
I1007 18:28:57.139431  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.229254 (* 1 = 0.229254 loss)
I1007 18:28:57.139437  5078 sgd_solver.cpp:105] Iteration 34200, lr = 0.1
I1007 18:29:05.489569  5078 solver.cpp:218] Iteration 34300 (11.9759 iter/s, 8.35011s/100 iters), loss = 0.255694
I1007 18:29:05.489609  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.255694 (* 1 = 0.255694 loss)
I1007 18:29:05.489615  5078 sgd_solver.cpp:105] Iteration 34300, lr = 0.1
I1007 18:29:13.842167  5078 solver.cpp:218] Iteration 34400 (11.9724 iter/s, 8.35253s/100 iters), loss = 0.120267
I1007 18:29:13.842288  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.120267 (* 1 = 0.120267 loss)
I1007 18:29:13.842304  5078 sgd_solver.cpp:105] Iteration 34400, lr = 0.1
I1007 18:29:21.776316  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:29:22.109998  5078 solver.cpp:330] Iteration 34500, Testing net (#0)
I1007 18:29:24.035884  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:29:24.116610  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8019
I1007 18:29:24.116644  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.631756 (* 1 = 0.631756 loss)
I1007 18:29:24.199786  5078 solver.cpp:218] Iteration 34500 (9.65487 iter/s, 10.3575s/100 iters), loss = 0.252745
I1007 18:29:24.199815  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.252745 (* 1 = 0.252745 loss)
I1007 18:29:24.199821  5078 sgd_solver.cpp:105] Iteration 34500, lr = 0.1
I1007 18:29:32.559531  5078 solver.cpp:218] Iteration 34600 (11.9622 iter/s, 8.35969s/100 iters), loss = 0.18176
I1007 18:29:32.559572  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.18176 (* 1 = 0.18176 loss)
I1007 18:29:32.559578  5078 sgd_solver.cpp:105] Iteration 34600, lr = 0.1
I1007 18:29:40.914221  5078 solver.cpp:218] Iteration 34700 (11.9694 iter/s, 8.35462s/100 iters), loss = 0.170945
I1007 18:29:40.914260  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.170945 (* 1 = 0.170945 loss)
I1007 18:29:40.914268  5078 sgd_solver.cpp:105] Iteration 34700, lr = 0.1
I1007 18:29:49.272805  5078 solver.cpp:218] Iteration 34800 (11.9638 iter/s, 8.35852s/100 iters), loss = 0.203774
I1007 18:29:49.272951  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.203773 (* 1 = 0.203773 loss)
I1007 18:29:49.272960  5078 sgd_solver.cpp:105] Iteration 34800, lr = 0.1
I1007 18:29:57.628026  5078 solver.cpp:218] Iteration 34900 (11.9688 iter/s, 8.35505s/100 iters), loss = 0.143171
I1007 18:29:57.628065  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.143171 (* 1 = 0.143171 loss)
I1007 18:29:57.628072  5078 sgd_solver.cpp:105] Iteration 34900, lr = 0.1
I1007 18:30:05.573796  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:30:05.909211  5078 solver.cpp:330] Iteration 35000, Testing net (#0)
I1007 18:30:07.834125  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:30:07.914525  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8106
I1007 18:30:07.914551  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.590634 (* 1 = 0.590634 loss)
I1007 18:30:07.997961  5078 solver.cpp:218] Iteration 35000 (9.64333 iter/s, 10.3699s/100 iters), loss = 0.190323
I1007 18:30:07.997987  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.190323 (* 1 = 0.190323 loss)
I1007 18:30:07.997994  5078 sgd_solver.cpp:105] Iteration 35000, lr = 0.1
I1007 18:30:16.344147  5078 solver.cpp:218] Iteration 35100 (11.9816 iter/s, 8.34613s/100 iters), loss = 0.147434
I1007 18:30:16.344177  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.147434 (* 1 = 0.147434 loss)
I1007 18:30:16.344182  5078 sgd_solver.cpp:105] Iteration 35100, lr = 0.1
I1007 18:30:24.700218  5078 solver.cpp:218] Iteration 35200 (11.9674 iter/s, 8.35601s/100 iters), loss = 0.179271
I1007 18:30:24.700348  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.179271 (* 1 = 0.179271 loss)
I1007 18:30:24.700356  5078 sgd_solver.cpp:105] Iteration 35200, lr = 0.1
I1007 18:30:33.054826  5078 solver.cpp:218] Iteration 35300 (11.9697 iter/s, 8.35445s/100 iters), loss = 0.194155
I1007 18:30:33.054855  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.194155 (* 1 = 0.194155 loss)
I1007 18:30:33.054872  5078 sgd_solver.cpp:105] Iteration 35300, lr = 0.1
I1007 18:30:41.406124  5078 solver.cpp:218] Iteration 35400 (11.9743 iter/s, 8.35124s/100 iters), loss = 0.116352
I1007 18:30:41.406153  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.116352 (* 1 = 0.116352 loss)
I1007 18:30:41.406159  5078 sgd_solver.cpp:105] Iteration 35400, lr = 0.1
I1007 18:30:49.349288  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:30:49.682456  5078 solver.cpp:330] Iteration 35500, Testing net (#0)
I1007 18:30:51.609402  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:30:51.690021  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8221
I1007 18:30:51.690057  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.552538 (* 1 = 0.552538 loss)
I1007 18:30:51.773727  5078 solver.cpp:218] Iteration 35500 (9.64549 iter/s, 10.3675s/100 iters), loss = 0.171131
I1007 18:30:51.773754  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.17113 (* 1 = 0.17113 loss)
I1007 18:30:51.773761  5078 sgd_solver.cpp:105] Iteration 35500, lr = 0.1
I1007 18:31:00.126538  5078 solver.cpp:218] Iteration 35600 (11.9721 iter/s, 8.35276s/100 iters), loss = 0.214947
I1007 18:31:00.126658  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.214947 (* 1 = 0.214947 loss)
I1007 18:31:00.126675  5078 sgd_solver.cpp:105] Iteration 35600, lr = 0.1
I1007 18:31:08.476692  5078 solver.cpp:218] Iteration 35700 (11.976 iter/s, 8.35001s/100 iters), loss = 0.181996
I1007 18:31:08.476733  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.181995 (* 1 = 0.181995 loss)
I1007 18:31:08.476739  5078 sgd_solver.cpp:105] Iteration 35700, lr = 0.1
I1007 18:31:16.832126  5078 solver.cpp:218] Iteration 35800 (11.9684 iter/s, 8.35537s/100 iters), loss = 0.159642
I1007 18:31:16.832168  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.159641 (* 1 = 0.159641 loss)
I1007 18:31:16.832173  5078 sgd_solver.cpp:105] Iteration 35800, lr = 0.1
I1007 18:31:25.177974  5078 solver.cpp:218] Iteration 35900 (11.9821 iter/s, 8.34578s/100 iters), loss = 0.219135
I1007 18:31:25.178015  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.219134 (* 1 = 0.219134 loss)
I1007 18:31:25.178020  5078 sgd_solver.cpp:105] Iteration 35900, lr = 0.1
I1007 18:31:33.117100  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:31:33.452090  5078 solver.cpp:330] Iteration 36000, Testing net (#0)
I1007 18:31:35.376662  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:31:35.457242  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.816
I1007 18:31:35.457267  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.583247 (* 1 = 0.583247 loss)
I1007 18:31:35.540863  5078 solver.cpp:218] Iteration 36000 (9.64989 iter/s, 10.3628s/100 iters), loss = 0.180013
I1007 18:31:35.540890  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.180013 (* 1 = 0.180013 loss)
I1007 18:31:35.540897  5078 sgd_solver.cpp:105] Iteration 36000, lr = 0.1
I1007 18:31:43.889812  5078 solver.cpp:218] Iteration 36100 (11.9776 iter/s, 8.3489s/100 iters), loss = 0.23821
I1007 18:31:43.889842  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.23821 (* 1 = 0.23821 loss)
I1007 18:31:43.889847  5078 sgd_solver.cpp:105] Iteration 36100, lr = 0.1
I1007 18:31:52.250560  5078 solver.cpp:218] Iteration 36200 (11.9607 iter/s, 8.36069s/100 iters), loss = 0.243155
I1007 18:31:52.250591  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.243155 (* 1 = 0.243155 loss)
I1007 18:31:52.250597  5078 sgd_solver.cpp:105] Iteration 36200, lr = 0.1
I1007 18:32:00.605734  5078 solver.cpp:218] Iteration 36300 (11.9687 iter/s, 8.35512s/100 iters), loss = 0.228339
I1007 18:32:00.605765  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.228339 (* 1 = 0.228339 loss)
I1007 18:32:00.605772  5078 sgd_solver.cpp:105] Iteration 36300, lr = 0.1
I1007 18:32:08.958523  5078 solver.cpp:218] Iteration 36400 (11.9721 iter/s, 8.35273s/100 iters), loss = 0.213509
I1007 18:32:08.958652  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.213508 (* 1 = 0.213508 loss)
I1007 18:32:08.958659  5078 sgd_solver.cpp:105] Iteration 36400, lr = 0.1
I1007 18:32:16.895054  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:32:17.228627  5078 solver.cpp:330] Iteration 36500, Testing net (#0)
I1007 18:32:19.153740  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:32:19.234264  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7831
I1007 18:32:19.234299  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.684192 (* 1 = 0.684192 loss)
I1007 18:32:19.318428  5078 solver.cpp:218] Iteration 36500 (9.65273 iter/s, 10.3598s/100 iters), loss = 0.17384
I1007 18:32:19.318459  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.17384 (* 1 = 0.17384 loss)
I1007 18:32:19.318466  5078 sgd_solver.cpp:105] Iteration 36500, lr = 0.1
I1007 18:32:27.674466  5078 solver.cpp:218] Iteration 36600 (11.9675 iter/s, 8.35598s/100 iters), loss = 0.200481
I1007 18:32:27.674496  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.20048 (* 1 = 0.20048 loss)
I1007 18:32:27.674502  5078 sgd_solver.cpp:105] Iteration 36600, lr = 0.1
I1007 18:32:36.022882  5078 solver.cpp:218] Iteration 36700 (11.9784 iter/s, 8.34836s/100 iters), loss = 0.239322
I1007 18:32:36.022912  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.239322 (* 1 = 0.239322 loss)
I1007 18:32:36.022918  5078 sgd_solver.cpp:105] Iteration 36700, lr = 0.1
I1007 18:32:44.374147  5078 solver.cpp:218] Iteration 36800 (11.9743 iter/s, 8.35121s/100 iters), loss = 0.138089
I1007 18:32:44.374233  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.138088 (* 1 = 0.138088 loss)
I1007 18:32:44.374240  5078 sgd_solver.cpp:105] Iteration 36800, lr = 0.1
I1007 18:32:52.721788  5078 solver.cpp:218] Iteration 36900 (11.9796 iter/s, 8.34753s/100 iters), loss = 0.106504
I1007 18:32:52.721818  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.106504 (* 1 = 0.106504 loss)
I1007 18:32:52.721824  5078 sgd_solver.cpp:105] Iteration 36900, lr = 0.1
I1007 18:33:00.659085  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:33:00.994491  5078 solver.cpp:330] Iteration 37000, Testing net (#0)
I1007 18:33:02.920635  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:33:03.001456  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7943
I1007 18:33:03.001492  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.618595 (* 1 = 0.618595 loss)
I1007 18:33:03.084417  5078 solver.cpp:218] Iteration 37000 (9.65012 iter/s, 10.3626s/100 iters), loss = 0.265103
I1007 18:33:03.084444  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.265103 (* 1 = 0.265103 loss)
I1007 18:33:03.084451  5078 sgd_solver.cpp:105] Iteration 37000, lr = 0.1
I1007 18:33:11.432392  5078 solver.cpp:218] Iteration 37100 (11.979 iter/s, 8.34792s/100 iters), loss = 0.123708
I1007 18:33:11.432422  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.123708 (* 1 = 0.123708 loss)
I1007 18:33:11.432428  5078 sgd_solver.cpp:105] Iteration 37100, lr = 0.1
I1007 18:33:19.783155  5078 solver.cpp:218] Iteration 37200 (11.975 iter/s, 8.35071s/100 iters), loss = 0.167383
I1007 18:33:19.783306  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.167382 (* 1 = 0.167382 loss)
I1007 18:33:19.783313  5078 sgd_solver.cpp:105] Iteration 37200, lr = 0.1
I1007 18:33:28.133455  5078 solver.cpp:218] Iteration 37300 (11.9759 iter/s, 8.35013s/100 iters), loss = 0.163933
I1007 18:33:28.133496  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.163932 (* 1 = 0.163932 loss)
I1007 18:33:28.133502  5078 sgd_solver.cpp:105] Iteration 37300, lr = 0.1
I1007 18:33:36.486753  5078 solver.cpp:218] Iteration 37400 (11.9714 iter/s, 8.35323s/100 iters), loss = 0.135126
I1007 18:33:36.486783  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.135125 (* 1 = 0.135125 loss)
I1007 18:33:36.486789  5078 sgd_solver.cpp:105] Iteration 37400, lr = 0.1
I1007 18:33:44.424111  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:33:44.758985  5078 solver.cpp:330] Iteration 37500, Testing net (#0)
I1007 18:33:46.684545  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:33:46.764770  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7788
I1007 18:33:46.764806  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.735466 (* 1 = 0.735466 loss)
I1007 18:33:46.848300  5078 solver.cpp:218] Iteration 37500 (9.65113 iter/s, 10.3615s/100 iters), loss = 0.192776
I1007 18:33:46.848330  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.192776 (* 1 = 0.192776 loss)
I1007 18:33:46.848338  5078 sgd_solver.cpp:105] Iteration 37500, lr = 0.1
I1007 18:33:55.201342  5078 solver.cpp:218] Iteration 37600 (11.9718 iter/s, 8.35299s/100 iters), loss = 0.240457
I1007 18:33:55.201442  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.240457 (* 1 = 0.240457 loss)
I1007 18:33:55.201447  5078 sgd_solver.cpp:105] Iteration 37600, lr = 0.1
I1007 18:34:03.541549  5078 solver.cpp:218] Iteration 37700 (11.9903 iter/s, 8.34008s/100 iters), loss = 0.156355
I1007 18:34:03.541589  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.156355 (* 1 = 0.156355 loss)
I1007 18:34:03.541595  5078 sgd_solver.cpp:105] Iteration 37700, lr = 0.1
I1007 18:34:11.884655  5078 solver.cpp:218] Iteration 37800 (11.986 iter/s, 8.34304s/100 iters), loss = 0.18708
I1007 18:34:11.884696  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.18708 (* 1 = 0.18708 loss)
I1007 18:34:11.884701  5078 sgd_solver.cpp:105] Iteration 37800, lr = 0.1
I1007 18:34:20.225786  5078 solver.cpp:218] Iteration 37900 (11.9889 iter/s, 8.34107s/100 iters), loss = 0.137879
I1007 18:34:20.225827  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.137878 (* 1 = 0.137878 loss)
I1007 18:34:20.225833  5078 sgd_solver.cpp:105] Iteration 37900, lr = 0.1
I1007 18:34:28.157246  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:34:28.492338  5078 solver.cpp:330] Iteration 38000, Testing net (#0)
I1007 18:34:30.418910  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:34:30.500128  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7682
I1007 18:34:30.500167  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.753074 (* 1 = 0.753074 loss)
I1007 18:34:30.582335  5078 solver.cpp:218] Iteration 38000 (9.65579 iter/s, 10.3565s/100 iters), loss = 0.148231
I1007 18:34:30.582367  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.148231 (* 1 = 0.148231 loss)
I1007 18:34:30.582376  5078 sgd_solver.cpp:105] Iteration 38000, lr = 0.1
I1007 18:34:38.928208  5078 solver.cpp:218] Iteration 38100 (11.9821 iter/s, 8.34582s/100 iters), loss = 0.256053
I1007 18:34:38.928248  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.256053 (* 1 = 0.256053 loss)
I1007 18:34:38.928254  5078 sgd_solver.cpp:105] Iteration 38100, lr = 0.1
I1007 18:34:47.274830  5078 solver.cpp:218] Iteration 38200 (11.981 iter/s, 8.34656s/100 iters), loss = 0.219408
I1007 18:34:47.274860  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.219408 (* 1 = 0.219408 loss)
I1007 18:34:47.274866  5078 sgd_solver.cpp:105] Iteration 38200, lr = 0.1
I1007 18:34:55.612205  5078 solver.cpp:218] Iteration 38300 (11.9943 iter/s, 8.33732s/100 iters), loss = 0.175091
I1007 18:34:55.612246  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.17509 (* 1 = 0.17509 loss)
I1007 18:34:55.612251  5078 sgd_solver.cpp:105] Iteration 38300, lr = 0.1
I1007 18:35:03.957868  5078 solver.cpp:218] Iteration 38400 (11.9824 iter/s, 8.3456s/100 iters), loss = 0.13904
I1007 18:35:03.957957  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.139039 (* 1 = 0.139039 loss)
I1007 18:35:03.957963  5078 sgd_solver.cpp:105] Iteration 38400, lr = 0.1
I1007 18:35:11.884402  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:35:12.218500  5078 solver.cpp:330] Iteration 38500, Testing net (#0)
I1007 18:35:14.144467  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:35:14.224802  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8137
I1007 18:35:14.224838  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.599542 (* 1 = 0.599542 loss)
I1007 18:35:14.308771  5078 solver.cpp:218] Iteration 38500 (9.6611 iter/s, 10.3508s/100 iters), loss = 0.262237
I1007 18:35:14.308800  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.262237 (* 1 = 0.262237 loss)
I1007 18:35:14.308807  5078 sgd_solver.cpp:105] Iteration 38500, lr = 0.1
I1007 18:35:22.661375  5078 solver.cpp:218] Iteration 38600 (11.9724 iter/s, 8.35251s/100 iters), loss = 0.236214
I1007 18:35:22.661415  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.236213 (* 1 = 0.236213 loss)
I1007 18:35:22.661420  5078 sgd_solver.cpp:105] Iteration 38600, lr = 0.1
I1007 18:35:31.001968  5078 solver.cpp:218] Iteration 38700 (11.9896 iter/s, 8.34053s/100 iters), loss = 0.139096
I1007 18:35:31.001999  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.139096 (* 1 = 0.139096 loss)
I1007 18:35:31.002004  5078 sgd_solver.cpp:105] Iteration 38700, lr = 0.1
I1007 18:35:39.350790  5078 solver.cpp:218] Iteration 38800 (11.9778 iter/s, 8.34876s/100 iters), loss = 0.14854
I1007 18:35:39.350873  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.14854 (* 1 = 0.14854 loss)
I1007 18:35:39.350889  5078 sgd_solver.cpp:105] Iteration 38800, lr = 0.1
I1007 18:35:47.696957  5078 solver.cpp:218] Iteration 38900 (11.9817 iter/s, 8.34606s/100 iters), loss = 0.185904
I1007 18:35:47.696997  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.185904 (* 1 = 0.185904 loss)
I1007 18:35:47.697003  5078 sgd_solver.cpp:105] Iteration 38900, lr = 0.1
I1007 18:35:55.635282  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:35:55.970293  5078 solver.cpp:330] Iteration 39000, Testing net (#0)
I1007 18:35:57.896040  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:35:57.976316  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8364
I1007 18:35:57.976352  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.509671 (* 1 = 0.509671 loss)
I1007 18:35:58.060132  5078 solver.cpp:218] Iteration 39000 (9.64962 iter/s, 10.3631s/100 iters), loss = 0.137496
I1007 18:35:58.060158  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.137496 (* 1 = 0.137496 loss)
I1007 18:35:58.060165  5078 sgd_solver.cpp:105] Iteration 39000, lr = 0.1
I1007 18:36:06.406503  5078 solver.cpp:218] Iteration 39100 (11.9813 iter/s, 8.34632s/100 iters), loss = 0.205542
I1007 18:36:06.406543  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.205542 (* 1 = 0.205542 loss)
I1007 18:36:06.406549  5078 sgd_solver.cpp:105] Iteration 39100, lr = 0.1
I1007 18:36:14.757470  5078 solver.cpp:218] Iteration 39200 (11.9748 iter/s, 8.3509s/100 iters), loss = 0.257869
I1007 18:36:14.757572  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.257868 (* 1 = 0.257868 loss)
I1007 18:36:14.757588  5078 sgd_solver.cpp:105] Iteration 39200, lr = 0.1
I1007 18:36:23.102789  5078 solver.cpp:218] Iteration 39300 (11.9829 iter/s, 8.34519s/100 iters), loss = 0.150791
I1007 18:36:23.102829  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.15079 (* 1 = 0.15079 loss)
I1007 18:36:23.102834  5078 sgd_solver.cpp:105] Iteration 39300, lr = 0.1
I1007 18:36:31.447784  5078 solver.cpp:218] Iteration 39400 (11.9833 iter/s, 8.34493s/100 iters), loss = 0.138522
I1007 18:36:31.447824  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.138521 (* 1 = 0.138521 loss)
I1007 18:36:31.447829  5078 sgd_solver.cpp:105] Iteration 39400, lr = 0.1
I1007 18:36:39.378579  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:36:39.712611  5078 solver.cpp:330] Iteration 39500, Testing net (#0)
I1007 18:36:41.637699  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:36:41.718346  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8322
I1007 18:36:41.718381  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.500054 (* 1 = 0.500054 loss)
I1007 18:36:41.802521  5078 solver.cpp:218] Iteration 39500 (9.65748 iter/s, 10.3547s/100 iters), loss = 0.239412
I1007 18:36:41.802548  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.239412 (* 1 = 0.239412 loss)
I1007 18:36:41.802556  5078 sgd_solver.cpp:105] Iteration 39500, lr = 0.1
I1007 18:36:50.151505  5078 solver.cpp:218] Iteration 39600 (11.9776 iter/s, 8.34893s/100 iters), loss = 0.201889
I1007 18:36:50.151645  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.201888 (* 1 = 0.201888 loss)
I1007 18:36:50.151654  5078 sgd_solver.cpp:105] Iteration 39600, lr = 0.1
I1007 18:36:58.492960  5078 solver.cpp:218] Iteration 39700 (11.9886 iter/s, 8.34129s/100 iters), loss = 0.17306
I1007 18:36:58.493000  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.173059 (* 1 = 0.173059 loss)
I1007 18:36:58.493006  5078 sgd_solver.cpp:105] Iteration 39700, lr = 0.1
I1007 18:37:06.844275  5078 solver.cpp:218] Iteration 39800 (11.9743 iter/s, 8.35125s/100 iters), loss = 0.202754
I1007 18:37:06.844305  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.202754 (* 1 = 0.202754 loss)
I1007 18:37:06.844310  5078 sgd_solver.cpp:105] Iteration 39800, lr = 0.1
I1007 18:37:15.192992  5078 solver.cpp:218] Iteration 39900 (11.978 iter/s, 8.34866s/100 iters), loss = 0.118128
I1007 18:37:15.193022  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.118128 (* 1 = 0.118128 loss)
I1007 18:37:15.193037  5078 sgd_solver.cpp:105] Iteration 39900, lr = 0.1
I1007 18:37:23.132009  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:37:23.466634  5078 solver.cpp:330] Iteration 40000, Testing net (#0)
I1007 18:37:25.391083  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:37:25.471298  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7162
I1007 18:37:25.471333  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.915813 (* 1 = 0.915813 loss)
I1007 18:37:25.555109  5078 solver.cpp:218] Iteration 40000 (9.65059 iter/s, 10.3621s/100 iters), loss = 0.185246
I1007 18:37:25.555135  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.185246 (* 1 = 0.185246 loss)
I1007 18:37:25.555140  5078 sgd_solver.cpp:46] MultiStep Status: Iteration 40000, step = 1
I1007 18:37:25.555143  5078 sgd_solver.cpp:105] Iteration 40000, lr = 0.01
I1007 18:37:33.906745  5078 solver.cpp:218] Iteration 40100 (11.9738 iter/s, 8.35158s/100 iters), loss = 0.186501
I1007 18:37:33.906785  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.1865 (* 1 = 0.1865 loss)
I1007 18:37:33.906791  5078 sgd_solver.cpp:105] Iteration 40100, lr = 0.01
I1007 18:37:42.261865  5078 solver.cpp:218] Iteration 40200 (11.9688 iter/s, 8.35505s/100 iters), loss = 0.13125
I1007 18:37:42.261895  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.13125 (* 1 = 0.13125 loss)
I1007 18:37:42.261900  5078 sgd_solver.cpp:105] Iteration 40200, lr = 0.01
I1007 18:37:50.614835  5078 solver.cpp:218] Iteration 40300 (11.9719 iter/s, 8.35291s/100 iters), loss = 0.11332
I1007 18:37:50.614864  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.113319 (* 1 = 0.113319 loss)
I1007 18:37:50.614871  5078 sgd_solver.cpp:105] Iteration 40300, lr = 0.01
I1007 18:37:58.972031  5078 solver.cpp:218] Iteration 40400 (11.9658 iter/s, 8.35714s/100 iters), loss = 0.0611572
I1007 18:37:58.972103  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0611568 (* 1 = 0.0611568 loss)
I1007 18:37:58.972121  5078 sgd_solver.cpp:105] Iteration 40400, lr = 0.01
I1007 18:38:06.909467  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:38:07.244756  5078 solver.cpp:330] Iteration 40500, Testing net (#0)
I1007 18:38:09.170128  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:38:09.250644  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8864
I1007 18:38:09.250680  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.332235 (* 1 = 0.332235 loss)
I1007 18:38:09.334542  5078 solver.cpp:218] Iteration 40500 (9.65027 iter/s, 10.3624s/100 iters), loss = 0.103232
I1007 18:38:09.334573  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.103231 (* 1 = 0.103231 loss)
I1007 18:38:09.334580  5078 sgd_solver.cpp:105] Iteration 40500, lr = 0.01
I1007 18:38:17.687965  5078 solver.cpp:218] Iteration 40600 (11.9712 iter/s, 8.35337s/100 iters), loss = 0.0906839
I1007 18:38:17.688006  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0906835 (* 1 = 0.0906835 loss)
I1007 18:38:17.688012  5078 sgd_solver.cpp:105] Iteration 40600, lr = 0.01
I1007 18:38:26.031813  5078 solver.cpp:218] Iteration 40700 (11.985 iter/s, 8.34378s/100 iters), loss = 0.0895969
I1007 18:38:26.031853  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0895964 (* 1 = 0.0895964 loss)
I1007 18:38:26.031858  5078 sgd_solver.cpp:105] Iteration 40700, lr = 0.01
I1007 18:38:34.378417  5078 solver.cpp:218] Iteration 40800 (11.981 iter/s, 8.34654s/100 iters), loss = 0.0756762
I1007 18:38:34.378538  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0756758 (* 1 = 0.0756758 loss)
I1007 18:38:34.378556  5078 sgd_solver.cpp:105] Iteration 40800, lr = 0.01
I1007 18:38:42.723666  5078 solver.cpp:218] Iteration 40900 (11.9831 iter/s, 8.3451s/100 iters), loss = 0.0592033
I1007 18:38:42.723707  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0592029 (* 1 = 0.0592029 loss)
I1007 18:38:42.723712  5078 sgd_solver.cpp:105] Iteration 40900, lr = 0.01
I1007 18:38:50.662163  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:38:50.995959  5078 solver.cpp:330] Iteration 41000, Testing net (#0)
I1007 18:38:52.921089  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:38:53.002147  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8982
I1007 18:38:53.002182  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.300439 (* 1 = 0.300439 loss)
I1007 18:38:53.084983  5078 solver.cpp:218] Iteration 41000 (9.65135 iter/s, 10.3612s/100 iters), loss = 0.0578034
I1007 18:38:53.085011  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.057803 (* 1 = 0.057803 loss)
I1007 18:38:53.085017  5078 sgd_solver.cpp:105] Iteration 41000, lr = 0.01
I1007 18:39:01.429173  5078 solver.cpp:218] Iteration 41100 (11.9845 iter/s, 8.34413s/100 iters), loss = 0.0823041
I1007 18:39:01.429214  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0823037 (* 1 = 0.0823037 loss)
I1007 18:39:01.429219  5078 sgd_solver.cpp:105] Iteration 41100, lr = 0.01
I1007 18:39:09.778040  5078 solver.cpp:218] Iteration 41200 (11.9778 iter/s, 8.3488s/100 iters), loss = 0.0490502
I1007 18:39:09.778129  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0490498 (* 1 = 0.0490498 loss)
I1007 18:39:09.778146  5078 sgd_solver.cpp:105] Iteration 41200, lr = 0.01
I1007 18:39:18.117195  5078 solver.cpp:218] Iteration 41300 (11.9918 iter/s, 8.33904s/100 iters), loss = 0.0839873
I1007 18:39:18.117235  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0839868 (* 1 = 0.0839868 loss)
I1007 18:39:18.117241  5078 sgd_solver.cpp:105] Iteration 41300, lr = 0.01
I1007 18:39:26.461676  5078 solver.cpp:218] Iteration 41400 (11.9841 iter/s, 8.34441s/100 iters), loss = 0.111397
I1007 18:39:26.461719  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.111396 (* 1 = 0.111396 loss)
I1007 18:39:26.461724  5078 sgd_solver.cpp:105] Iteration 41400, lr = 0.01
I1007 18:39:34.395093  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:39:34.729554  5078 solver.cpp:330] Iteration 41500, Testing net (#0)
I1007 18:39:36.655019  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:39:36.735518  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9102
I1007 18:39:36.735554  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.264805 (* 1 = 0.264805 loss)
I1007 18:39:36.818996  5078 solver.cpp:218] Iteration 41500 (9.65508 iter/s, 10.3572s/100 iters), loss = 0.0569734
I1007 18:39:36.819025  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.056973 (* 1 = 0.056973 loss)
I1007 18:39:36.819031  5078 sgd_solver.cpp:105] Iteration 41500, lr = 0.01
I1007 18:39:45.174552  5078 solver.cpp:218] Iteration 41600 (11.9682 iter/s, 8.3555s/100 iters), loss = 0.0862767
I1007 18:39:45.174639  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0862763 (* 1 = 0.0862763 loss)
I1007 18:39:45.174648  5078 sgd_solver.cpp:105] Iteration 41600, lr = 0.01
I1007 18:39:53.522760  5078 solver.cpp:218] Iteration 41700 (11.9788 iter/s, 8.34809s/100 iters), loss = 0.0440806
I1007 18:39:53.522800  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0440802 (* 1 = 0.0440802 loss)
I1007 18:39:53.522806  5078 sgd_solver.cpp:105] Iteration 41700, lr = 0.01
I1007 18:40:01.876752  5078 solver.cpp:218] Iteration 41800 (11.9704 iter/s, 8.35392s/100 iters), loss = 0.0848053
I1007 18:40:01.876793  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0848048 (* 1 = 0.0848048 loss)
I1007 18:40:01.876799  5078 sgd_solver.cpp:105] Iteration 41800, lr = 0.01
I1007 18:40:10.225097  5078 solver.cpp:218] Iteration 41900 (11.9785 iter/s, 8.34827s/100 iters), loss = 0.0206013
I1007 18:40:10.225139  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0206009 (* 1 = 0.0206009 loss)
I1007 18:40:10.225145  5078 sgd_solver.cpp:105] Iteration 41900, lr = 0.01
I1007 18:40:18.160478  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:40:18.495013  5078 solver.cpp:330] Iteration 42000, Testing net (#0)
I1007 18:40:20.420249  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:40:20.501304  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9095
I1007 18:40:20.501339  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.267467 (* 1 = 0.267467 loss)
I1007 18:40:20.583853  5078 solver.cpp:218] Iteration 42000 (9.65374 iter/s, 10.3587s/100 iters), loss = 0.0371452
I1007 18:40:20.583878  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0371448 (* 1 = 0.0371448 loss)
I1007 18:40:20.583884  5078 sgd_solver.cpp:105] Iteration 42000, lr = 0.01
I1007 18:40:28.925274  5078 solver.cpp:218] Iteration 42100 (11.9884 iter/s, 8.34137s/100 iters), loss = 0.198527
I1007 18:40:28.925305  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.198527 (* 1 = 0.198527 loss)
I1007 18:40:28.925310  5078 sgd_solver.cpp:105] Iteration 42100, lr = 0.01
I1007 18:40:37.277663  5078 solver.cpp:218] Iteration 42200 (11.9727 iter/s, 8.35233s/100 iters), loss = 0.0908318
I1007 18:40:37.277704  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0908314 (* 1 = 0.0908314 loss)
I1007 18:40:37.277711  5078 sgd_solver.cpp:105] Iteration 42200, lr = 0.01
I1007 18:40:45.624927  5078 solver.cpp:218] Iteration 42300 (11.9801 iter/s, 8.3472s/100 iters), loss = 0.101317
I1007 18:40:45.624966  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.101316 (* 1 = 0.101316 loss)
I1007 18:40:45.624972  5078 sgd_solver.cpp:105] Iteration 42300, lr = 0.01
I1007 18:40:53.974141  5078 solver.cpp:218] Iteration 42400 (11.9773 iter/s, 8.34915s/100 iters), loss = 0.0693025
I1007 18:40:53.974268  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0693021 (* 1 = 0.0693021 loss)
I1007 18:40:53.974277  5078 sgd_solver.cpp:105] Iteration 42400, lr = 0.01
I1007 18:41:01.901906  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:41:02.235235  5078 solver.cpp:330] Iteration 42500, Testing net (#0)
I1007 18:41:04.160218  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:41:04.240766  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9128
I1007 18:41:04.240802  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.270296 (* 1 = 0.270296 loss)
I1007 18:41:04.324467  5078 solver.cpp:218] Iteration 42500 (9.66168 iter/s, 10.3502s/100 iters), loss = 0.0259134
I1007 18:41:04.324496  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0259131 (* 1 = 0.0259131 loss)
I1007 18:41:04.324502  5078 sgd_solver.cpp:105] Iteration 42500, lr = 0.01
I1007 18:41:12.684303  5078 solver.cpp:218] Iteration 42600 (11.962 iter/s, 8.35978s/100 iters), loss = 0.0957451
I1007 18:41:12.684341  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0957447 (* 1 = 0.0957447 loss)
I1007 18:41:12.684347  5078 sgd_solver.cpp:105] Iteration 42600, lr = 0.01
I1007 18:41:21.034793  5078 solver.cpp:218] Iteration 42700 (11.9754 iter/s, 8.35042s/100 iters), loss = 0.0779121
I1007 18:41:21.034839  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0779117 (* 1 = 0.0779117 loss)
I1007 18:41:21.034847  5078 sgd_solver.cpp:105] Iteration 42700, lr = 0.01
I1007 18:41:29.386734  5078 solver.cpp:218] Iteration 42800 (11.9734 iter/s, 8.35187s/100 iters), loss = 0.0616286
I1007 18:41:29.386853  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0616282 (* 1 = 0.0616282 loss)
I1007 18:41:29.386870  5078 sgd_solver.cpp:105] Iteration 42800, lr = 0.01
I1007 18:41:37.734227  5078 solver.cpp:218] Iteration 42900 (11.9799 iter/s, 8.34735s/100 iters), loss = 0.0325831
I1007 18:41:37.734267  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0325827 (* 1 = 0.0325827 loss)
I1007 18:41:37.734273  5078 sgd_solver.cpp:105] Iteration 42900, lr = 0.01
I1007 18:41:45.671654  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:41:46.006352  5078 solver.cpp:330] Iteration 43000, Testing net (#0)
I1007 18:41:47.931294  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:41:48.012018  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9129
I1007 18:41:48.012043  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.273463 (* 1 = 0.273463 loss)
I1007 18:41:48.094529  5078 solver.cpp:218] Iteration 43000 (9.6523 iter/s, 10.3602s/100 iters), loss = 0.0474506
I1007 18:41:48.094553  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0474502 (* 1 = 0.0474502 loss)
I1007 18:41:48.094560  5078 sgd_solver.cpp:105] Iteration 43000, lr = 0.01
I1007 18:41:56.440186  5078 solver.cpp:218] Iteration 43100 (11.9824 iter/s, 8.3456s/100 iters), loss = 0.0440843
I1007 18:41:56.440227  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0440839 (* 1 = 0.0440839 loss)
I1007 18:41:56.440232  5078 sgd_solver.cpp:105] Iteration 43100, lr = 0.01
I1007 18:42:04.786021  5078 solver.cpp:218] Iteration 43200 (11.9821 iter/s, 8.34577s/100 iters), loss = 0.074484
I1007 18:42:04.786118  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0744836 (* 1 = 0.0744836 loss)
I1007 18:42:04.786134  5078 sgd_solver.cpp:105] Iteration 43200, lr = 0.01
I1007 18:42:13.131295  5078 solver.cpp:218] Iteration 43300 (11.983 iter/s, 8.34515s/100 iters), loss = 0.0394659
I1007 18:42:13.131335  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0394655 (* 1 = 0.0394655 loss)
I1007 18:42:13.131341  5078 sgd_solver.cpp:105] Iteration 43300, lr = 0.01
I1007 18:42:21.476757  5078 solver.cpp:218] Iteration 43400 (11.9827 iter/s, 8.34539s/100 iters), loss = 0.0495047
I1007 18:42:21.476805  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0495043 (* 1 = 0.0495043 loss)
I1007 18:42:21.476812  5078 sgd_solver.cpp:105] Iteration 43400, lr = 0.01
I1007 18:42:29.396445  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:42:29.731235  5078 solver.cpp:330] Iteration 43500, Testing net (#0)
I1007 18:42:31.656744  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:42:31.737133  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9159
I1007 18:42:31.737169  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.262079 (* 1 = 0.262079 loss)
I1007 18:42:31.820565  5078 solver.cpp:218] Iteration 43500 (9.66769 iter/s, 10.3437s/100 iters), loss = 0.0300557
I1007 18:42:31.820593  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0300554 (* 1 = 0.0300554 loss)
I1007 18:42:31.820600  5078 sgd_solver.cpp:105] Iteration 43500, lr = 0.01
I1007 18:42:40.169567  5078 solver.cpp:218] Iteration 43600 (11.9776 iter/s, 8.34895s/100 iters), loss = 0.0743074
I1007 18:42:40.169710  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.074307 (* 1 = 0.074307 loss)
I1007 18:42:40.169728  5078 sgd_solver.cpp:105] Iteration 43600, lr = 0.01
I1007 18:42:48.506810  5078 solver.cpp:218] Iteration 43700 (11.9946 iter/s, 8.33707s/100 iters), loss = 0.0221436
I1007 18:42:48.506852  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0221432 (* 1 = 0.0221432 loss)
I1007 18:42:48.506858  5078 sgd_solver.cpp:105] Iteration 43700, lr = 0.01
I1007 18:42:56.855301  5078 solver.cpp:218] Iteration 43800 (11.9783 iter/s, 8.34842s/100 iters), loss = 0.0390903
I1007 18:42:56.855347  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0390899 (* 1 = 0.0390899 loss)
I1007 18:42:56.855355  5078 sgd_solver.cpp:105] Iteration 43800, lr = 0.01
I1007 18:43:05.195689  5078 solver.cpp:218] Iteration 43900 (11.99 iter/s, 8.34031s/100 iters), loss = 0.0105176
I1007 18:43:05.195735  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0105171 (* 1 = 0.0105171 loss)
I1007 18:43:05.195742  5078 sgd_solver.cpp:105] Iteration 43900, lr = 0.01
I1007 18:43:13.129570  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:43:13.463670  5078 solver.cpp:330] Iteration 44000, Testing net (#0)
I1007 18:43:15.388896  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:43:15.469748  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9097
I1007 18:43:15.469782  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.28929 (* 1 = 0.28929 loss)
I1007 18:43:15.552649  5078 solver.cpp:218] Iteration 44000 (9.65541 iter/s, 10.3569s/100 iters), loss = 0.0586316
I1007 18:43:15.552675  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0586312 (* 1 = 0.0586312 loss)
I1007 18:43:15.552681  5078 sgd_solver.cpp:105] Iteration 44000, lr = 0.01
I1007 18:43:23.887620  5078 solver.cpp:218] Iteration 44100 (11.9977 iter/s, 8.33492s/100 iters), loss = 0.0872155
I1007 18:43:23.887662  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.087215 (* 1 = 0.087215 loss)
I1007 18:43:23.887667  5078 sgd_solver.cpp:105] Iteration 44100, lr = 0.01
I1007 18:43:32.242146  5078 solver.cpp:218] Iteration 44200 (11.9697 iter/s, 8.35446s/100 iters), loss = 0.0106319
I1007 18:43:32.242187  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0106314 (* 1 = 0.0106314 loss)
I1007 18:43:32.242193  5078 sgd_solver.cpp:105] Iteration 44200, lr = 0.01
I1007 18:43:40.586809  5078 solver.cpp:218] Iteration 44300 (11.9838 iter/s, 8.34459s/100 iters), loss = 0.0803358
I1007 18:43:40.586850  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0803353 (* 1 = 0.0803353 loss)
I1007 18:43:40.586856  5078 sgd_solver.cpp:105] Iteration 44300, lr = 0.01
I1007 18:43:48.940755  5078 solver.cpp:218] Iteration 44400 (11.9705 iter/s, 8.35388s/100 iters), loss = 0.0231353
I1007 18:43:48.940860  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0231348 (* 1 = 0.0231348 loss)
I1007 18:43:48.940871  5078 sgd_solver.cpp:105] Iteration 44400, lr = 0.01
I1007 18:43:56.873669  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:43:57.208842  5078 solver.cpp:330] Iteration 44500, Testing net (#0)
I1007 18:43:59.133781  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:43:59.214169  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9138
I1007 18:43:59.214195  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.272847 (* 1 = 0.272847 loss)
I1007 18:43:59.297755  5078 solver.cpp:218] Iteration 44500 (9.65543 iter/s, 10.3569s/100 iters), loss = 0.0274354
I1007 18:43:59.297785  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0274349 (* 1 = 0.0274349 loss)
I1007 18:43:59.297801  5078 sgd_solver.cpp:105] Iteration 44500, lr = 0.01
I1007 18:44:07.651662  5078 solver.cpp:218] Iteration 44600 (11.9705 iter/s, 8.35385s/100 iters), loss = 0.0742004
I1007 18:44:07.651692  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0741999 (* 1 = 0.0741999 loss)
I1007 18:44:07.651707  5078 sgd_solver.cpp:105] Iteration 44600, lr = 0.01
I1007 18:44:15.999122  5078 solver.cpp:218] Iteration 44700 (11.9798 iter/s, 8.3474s/100 iters), loss = 0.0642273
I1007 18:44:15.999152  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0642268 (* 1 = 0.0642268 loss)
I1007 18:44:15.999171  5078 sgd_solver.cpp:105] Iteration 44700, lr = 0.01
I1007 18:44:24.352963  5078 solver.cpp:218] Iteration 44800 (11.9706 iter/s, 8.35378s/100 iters), loss = 0.0342793
I1007 18:44:24.353070  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0342788 (* 1 = 0.0342788 loss)
I1007 18:44:24.353077  5078 sgd_solver.cpp:105] Iteration 44800, lr = 0.01
I1007 18:44:32.703044  5078 solver.cpp:218] Iteration 44900 (11.9761 iter/s, 8.34995s/100 iters), loss = 0.0243942
I1007 18:44:32.703074  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0243938 (* 1 = 0.0243938 loss)
I1007 18:44:32.703089  5078 sgd_solver.cpp:105] Iteration 44900, lr = 0.01
I1007 18:44:40.642415  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:44:40.976573  5078 solver.cpp:330] Iteration 45000, Testing net (#0)
I1007 18:44:42.902184  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:44:42.983474  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9095
I1007 18:44:42.983500  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.291797 (* 1 = 0.291797 loss)
I1007 18:44:43.066617  5078 solver.cpp:218] Iteration 45000 (9.64924 iter/s, 10.3635s/100 iters), loss = 0.050708
I1007 18:44:43.066642  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0507076 (* 1 = 0.0507076 loss)
I1007 18:44:43.066648  5078 sgd_solver.cpp:105] Iteration 45000, lr = 0.01
I1007 18:44:51.411897  5078 solver.cpp:218] Iteration 45100 (11.9829 iter/s, 8.34523s/100 iters), loss = 0.0614404
I1007 18:44:51.411927  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.06144 (* 1 = 0.06144 loss)
I1007 18:44:51.411932  5078 sgd_solver.cpp:105] Iteration 45100, lr = 0.01
I1007 18:44:59.766341  5078 solver.cpp:218] Iteration 45200 (11.9698 iter/s, 8.35438s/100 iters), loss = 0.0499268
I1007 18:44:59.766468  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0499264 (* 1 = 0.0499264 loss)
I1007 18:44:59.766476  5078 sgd_solver.cpp:105] Iteration 45200, lr = 0.01
I1007 18:45:08.110988  5078 solver.cpp:218] Iteration 45300 (11.9839 iter/s, 8.34451s/100 iters), loss = 0.0284362
I1007 18:45:08.111018  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0284358 (* 1 = 0.0284358 loss)
I1007 18:45:08.111033  5078 sgd_solver.cpp:105] Iteration 45300, lr = 0.01
I1007 18:45:16.469991  5078 solver.cpp:218] Iteration 45400 (11.9632 iter/s, 8.35894s/100 iters), loss = 0.0246934
I1007 18:45:16.470021  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.024693 (* 1 = 0.024693 loss)
I1007 18:45:16.470037  5078 sgd_solver.cpp:105] Iteration 45400, lr = 0.01
I1007 18:45:24.404785  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:45:24.739579  5078 solver.cpp:330] Iteration 45500, Testing net (#0)
I1007 18:45:26.665465  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:45:26.746012  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9107
I1007 18:45:26.746037  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.291513 (* 1 = 0.291513 loss)
I1007 18:45:26.829866  5078 solver.cpp:218] Iteration 45500 (9.65269 iter/s, 10.3598s/100 iters), loss = 0.0248604
I1007 18:45:26.829895  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.02486 (* 1 = 0.02486 loss)
I1007 18:45:26.829900  5078 sgd_solver.cpp:105] Iteration 45500, lr = 0.01
I1007 18:45:35.189714  5078 solver.cpp:218] Iteration 45600 (11.962 iter/s, 8.35979s/100 iters), loss = 0.0441353
I1007 18:45:35.189851  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0441349 (* 1 = 0.0441349 loss)
I1007 18:45:35.189870  5078 sgd_solver.cpp:105] Iteration 45600, lr = 0.01
I1007 18:45:43.535241  5078 solver.cpp:218] Iteration 45700 (11.9827 iter/s, 8.34536s/100 iters), loss = 0.0531371
I1007 18:45:43.535271  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0531367 (* 1 = 0.0531367 loss)
I1007 18:45:43.535287  5078 sgd_solver.cpp:105] Iteration 45700, lr = 0.01
I1007 18:45:51.890904  5078 solver.cpp:218] Iteration 45800 (11.968 iter/s, 8.35561s/100 iters), loss = 0.0230761
I1007 18:45:51.890934  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0230757 (* 1 = 0.0230757 loss)
I1007 18:45:51.890950  5078 sgd_solver.cpp:105] Iteration 45800, lr = 0.01
I1007 18:46:00.241690  5078 solver.cpp:218] Iteration 45900 (11.975 iter/s, 8.35073s/100 iters), loss = 0.0178528
I1007 18:46:00.241724  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0178524 (* 1 = 0.0178524 loss)
I1007 18:46:00.241729  5078 sgd_solver.cpp:105] Iteration 45900, lr = 0.01
I1007 18:46:08.175264  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:46:08.509944  5078 solver.cpp:330] Iteration 46000, Testing net (#0)
I1007 18:46:10.435916  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:46:10.517168  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9157
I1007 18:46:10.517192  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.279302 (* 1 = 0.279302 loss)
I1007 18:46:10.599625  5078 solver.cpp:218] Iteration 46000 (9.65449 iter/s, 10.3579s/100 iters), loss = 0.0388136
I1007 18:46:10.599651  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0388132 (* 1 = 0.0388132 loss)
I1007 18:46:10.599668  5078 sgd_solver.cpp:105] Iteration 46000, lr = 0.01
I1007 18:46:18.937585  5078 solver.cpp:218] Iteration 46100 (11.9934 iter/s, 8.33791s/100 iters), loss = 0.0309991
I1007 18:46:18.937616  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0309987 (* 1 = 0.0309987 loss)
I1007 18:46:18.937633  5078 sgd_solver.cpp:105] Iteration 46100, lr = 0.01
I1007 18:46:27.284687  5078 solver.cpp:218] Iteration 46200 (11.9803 iter/s, 8.34704s/100 iters), loss = 0.0249875
I1007 18:46:27.284718  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0249871 (* 1 = 0.0249871 loss)
I1007 18:46:27.284734  5078 sgd_solver.cpp:105] Iteration 46200, lr = 0.01
I1007 18:46:35.633245  5078 solver.cpp:218] Iteration 46300 (11.9782 iter/s, 8.3485s/100 iters), loss = 0.0125142
I1007 18:46:35.633275  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0125137 (* 1 = 0.0125137 loss)
I1007 18:46:35.633291  5078 sgd_solver.cpp:105] Iteration 46300, lr = 0.01
I1007 18:46:43.979939  5078 solver.cpp:218] Iteration 46400 (11.9809 iter/s, 8.34664s/100 iters), loss = 0.0127019
I1007 18:46:43.980072  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0127015 (* 1 = 0.0127015 loss)
I1007 18:46:43.980078  5078 sgd_solver.cpp:105] Iteration 46400, lr = 0.01
I1007 18:46:51.906898  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:46:52.242115  5078 solver.cpp:330] Iteration 46500, Testing net (#0)
I1007 18:46:54.167980  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:46:54.248757  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9156
I1007 18:46:54.248792  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.284129 (* 1 = 0.284129 loss)
I1007 18:46:54.332578  5078 solver.cpp:218] Iteration 46500 (9.65952 iter/s, 10.3525s/100 iters), loss = 0.0294711
I1007 18:46:54.332607  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0294706 (* 1 = 0.0294706 loss)
I1007 18:46:54.332614  5078 sgd_solver.cpp:105] Iteration 46500, lr = 0.01
I1007 18:47:02.682528  5078 solver.cpp:218] Iteration 46600 (11.9762 iter/s, 8.34989s/100 iters), loss = 0.0260614
I1007 18:47:02.682559  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.026061 (* 1 = 0.026061 loss)
I1007 18:47:02.682574  5078 sgd_solver.cpp:105] Iteration 46600, lr = 0.01
I1007 18:47:11.019580  5078 solver.cpp:218] Iteration 46700 (11.9947 iter/s, 8.33699s/100 iters), loss = 0.0755177
I1007 18:47:11.019611  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0755173 (* 1 = 0.0755173 loss)
I1007 18:47:11.019628  5078 sgd_solver.cpp:105] Iteration 46700, lr = 0.01
I1007 18:47:19.367674  5078 solver.cpp:218] Iteration 46800 (11.9789 iter/s, 8.34804s/100 iters), loss = 0.0277311
I1007 18:47:19.367790  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0277307 (* 1 = 0.0277307 loss)
I1007 18:47:19.367796  5078 sgd_solver.cpp:105] Iteration 46800, lr = 0.01
I1007 18:47:27.710125  5078 solver.cpp:218] Iteration 46900 (11.9871 iter/s, 8.34232s/100 iters), loss = 0.0242889
I1007 18:47:27.710155  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0242885 (* 1 = 0.0242885 loss)
I1007 18:47:27.710170  5078 sgd_solver.cpp:105] Iteration 46900, lr = 0.01
I1007 18:47:35.647248  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:47:35.982262  5078 solver.cpp:330] Iteration 47000, Testing net (#0)
I1007 18:47:37.908524  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:47:37.989635  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.917
I1007 18:47:37.989661  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.278882 (* 1 = 0.278882 loss)
I1007 18:47:38.071979  5078 solver.cpp:218] Iteration 47000 (9.65084 iter/s, 10.3618s/100 iters), loss = 0.0324607
I1007 18:47:38.072005  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0324603 (* 1 = 0.0324603 loss)
I1007 18:47:38.072010  5078 sgd_solver.cpp:105] Iteration 47000, lr = 0.01
I1007 18:47:46.408164  5078 solver.cpp:218] Iteration 47100 (11.996 iter/s, 8.33613s/100 iters), loss = 0.0360337
I1007 18:47:46.408195  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0360333 (* 1 = 0.0360333 loss)
I1007 18:47:46.408210  5078 sgd_solver.cpp:105] Iteration 47100, lr = 0.01
I1007 18:47:54.758111  5078 solver.cpp:218] Iteration 47200 (11.9762 iter/s, 8.34989s/100 iters), loss = 0.0463998
I1007 18:47:54.758234  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0463994 (* 1 = 0.0463994 loss)
I1007 18:47:54.758240  5078 sgd_solver.cpp:105] Iteration 47200, lr = 0.01
I1007 18:48:03.107370  5078 solver.cpp:218] Iteration 47300 (11.9773 iter/s, 8.34912s/100 iters), loss = 0.0816829
I1007 18:48:03.107400  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0816825 (* 1 = 0.0816825 loss)
I1007 18:48:03.107416  5078 sgd_solver.cpp:105] Iteration 47300, lr = 0.01
I1007 18:48:11.459842  5078 solver.cpp:218] Iteration 47400 (11.9726 iter/s, 8.35241s/100 iters), loss = 0.0168412
I1007 18:48:11.459873  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0168408 (* 1 = 0.0168408 loss)
I1007 18:48:11.459889  5078 sgd_solver.cpp:105] Iteration 47400, lr = 0.01
I1007 18:48:19.388105  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:48:19.721570  5078 solver.cpp:330] Iteration 47500, Testing net (#0)
I1007 18:48:21.647326  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:48:21.727754  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9147
I1007 18:48:21.727792  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.282502 (* 1 = 0.282502 loss)
I1007 18:48:21.811511  5078 solver.cpp:218] Iteration 47500 (9.66034 iter/s, 10.3516s/100 iters), loss = 0.0446338
I1007 18:48:21.811548  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0446334 (* 1 = 0.0446334 loss)
I1007 18:48:21.811555  5078 sgd_solver.cpp:105] Iteration 47500, lr = 0.01
I1007 18:48:30.167753  5078 solver.cpp:218] Iteration 47600 (11.9672 iter/s, 8.35618s/100 iters), loss = 0.0494378
I1007 18:48:30.167873  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0494374 (* 1 = 0.0494374 loss)
I1007 18:48:30.167881  5078 sgd_solver.cpp:105] Iteration 47600, lr = 0.01
I1007 18:48:38.520828  5078 solver.cpp:218] Iteration 47700 (11.9718 iter/s, 8.35293s/100 iters), loss = 0.0403846
I1007 18:48:38.520869  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0403842 (* 1 = 0.0403842 loss)
I1007 18:48:38.520874  5078 sgd_solver.cpp:105] Iteration 47700, lr = 0.01
I1007 18:48:46.880421  5078 solver.cpp:218] Iteration 47800 (11.9624 iter/s, 8.35953s/100 iters), loss = 0.0462681
I1007 18:48:46.880462  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0462676 (* 1 = 0.0462676 loss)
I1007 18:48:46.880468  5078 sgd_solver.cpp:105] Iteration 47800, lr = 0.01
I1007 18:48:55.241125  5078 solver.cpp:218] Iteration 47900 (11.9608 iter/s, 8.36064s/100 iters), loss = 0.0129559
I1007 18:48:55.241166  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0129555 (* 1 = 0.0129555 loss)
I1007 18:48:55.241173  5078 sgd_solver.cpp:105] Iteration 47900, lr = 0.01
I1007 18:49:03.181787  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:49:03.516798  5078 solver.cpp:330] Iteration 48000, Testing net (#0)
I1007 18:49:05.443727  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:49:05.524322  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9131
I1007 18:49:05.524356  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.290935 (* 1 = 0.290935 loss)
I1007 18:49:05.607817  5078 solver.cpp:218] Iteration 48000 (9.64635 iter/s, 10.3666s/100 iters), loss = 0.0755647
I1007 18:49:05.607844  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0755643 (* 1 = 0.0755643 loss)
I1007 18:49:05.607851  5078 sgd_solver.cpp:105] Iteration 48000, lr = 0.01
I1007 18:49:13.958040  5078 solver.cpp:218] Iteration 48100 (11.9758 iter/s, 8.35017s/100 iters), loss = 0.0285281
I1007 18:49:13.958081  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0285277 (* 1 = 0.0285277 loss)
I1007 18:49:13.958086  5078 sgd_solver.cpp:105] Iteration 48100, lr = 0.01
I1007 18:49:22.310350  5078 solver.cpp:218] Iteration 48200 (11.9728 iter/s, 8.35224s/100 iters), loss = 0.0227347
I1007 18:49:22.310379  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0227343 (* 1 = 0.0227343 loss)
I1007 18:49:22.310385  5078 sgd_solver.cpp:105] Iteration 48200, lr = 0.01
I1007 18:49:30.658253  5078 solver.cpp:218] Iteration 48300 (11.9791 iter/s, 8.34785s/100 iters), loss = 0.039609
I1007 18:49:30.658283  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0396086 (* 1 = 0.0396086 loss)
I1007 18:49:30.658289  5078 sgd_solver.cpp:105] Iteration 48300, lr = 0.01
I1007 18:49:39.011339  5078 solver.cpp:218] Iteration 48400 (11.9717 iter/s, 8.35303s/100 iters), loss = 0.0356533
I1007 18:49:39.011471  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0356529 (* 1 = 0.0356529 loss)
I1007 18:49:39.011488  5078 sgd_solver.cpp:105] Iteration 48400, lr = 0.01
I1007 18:49:46.949311  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:49:47.285379  5078 solver.cpp:330] Iteration 48500, Testing net (#0)
I1007 18:49:49.210253  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:49:49.290844  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9127
I1007 18:49:49.290879  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.306077 (* 1 = 0.306077 loss)
I1007 18:49:49.374666  5078 solver.cpp:218] Iteration 48500 (9.64955 iter/s, 10.3632s/100 iters), loss = 0.0248793
I1007 18:49:49.374694  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0248789 (* 1 = 0.0248789 loss)
I1007 18:49:49.374701  5078 sgd_solver.cpp:105] Iteration 48500, lr = 0.01
I1007 18:49:57.731011  5078 solver.cpp:218] Iteration 48600 (11.967 iter/s, 8.35629s/100 iters), loss = 0.0363229
I1007 18:49:57.731041  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0363225 (* 1 = 0.0363225 loss)
I1007 18:49:57.731047  5078 sgd_solver.cpp:105] Iteration 48600, lr = 0.01
I1007 18:50:06.070910  5078 solver.cpp:218] Iteration 48700 (11.9906 iter/s, 8.33984s/100 iters), loss = 0.0235279
I1007 18:50:06.070950  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0235275 (* 1 = 0.0235275 loss)
I1007 18:50:06.070955  5078 sgd_solver.cpp:105] Iteration 48700, lr = 0.01
I1007 18:50:14.420670  5078 solver.cpp:218] Iteration 48800 (11.9765 iter/s, 8.34969s/100 iters), loss = 0.0355839
I1007 18:50:14.420801  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0355835 (* 1 = 0.0355835 loss)
I1007 18:50:14.420809  5078 sgd_solver.cpp:105] Iteration 48800, lr = 0.01
I1007 18:50:22.757527  5078 solver.cpp:218] Iteration 48900 (11.9952 iter/s, 8.3367s/100 iters), loss = 0.0157303
I1007 18:50:22.757557  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0157299 (* 1 = 0.0157299 loss)
I1007 18:50:22.757563  5078 sgd_solver.cpp:105] Iteration 48900, lr = 0.01
I1007 18:50:30.690304  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:50:31.023221  5078 solver.cpp:330] Iteration 49000, Testing net (#0)
I1007 18:50:32.948421  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:50:33.028960  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9125
I1007 18:50:33.028985  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.314227 (* 1 = 0.314227 loss)
I1007 18:50:33.111560  5078 solver.cpp:218] Iteration 49000 (9.65813 iter/s, 10.354s/100 iters), loss = 0.0211252
I1007 18:50:33.111588  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0211247 (* 1 = 0.0211247 loss)
I1007 18:50:33.111593  5078 sgd_solver.cpp:105] Iteration 49000, lr = 0.01
I1007 18:50:41.450608  5078 solver.cpp:218] Iteration 49100 (11.9919 iter/s, 8.33899s/100 iters), loss = 0.0127489
I1007 18:50:41.450654  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0127485 (* 1 = 0.0127485 loss)
I1007 18:50:41.450661  5078 sgd_solver.cpp:105] Iteration 49100, lr = 0.01
I1007 18:50:49.794001  5078 solver.cpp:218] Iteration 49200 (11.9856 iter/s, 8.34332s/100 iters), loss = 0.0185493
I1007 18:50:49.794107  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0185489 (* 1 = 0.0185489 loss)
I1007 18:50:49.794124  5078 sgd_solver.cpp:105] Iteration 49200, lr = 0.01
I1007 18:50:58.130255  5078 solver.cpp:218] Iteration 49300 (11.996 iter/s, 8.33612s/100 iters), loss = 0.027381
I1007 18:50:58.130286  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0273806 (* 1 = 0.0273806 loss)
I1007 18:50:58.130301  5078 sgd_solver.cpp:105] Iteration 49300, lr = 0.01
I1007 18:51:06.476305  5078 solver.cpp:218] Iteration 49400 (11.9818 iter/s, 8.34599s/100 iters), loss = 0.0109573
I1007 18:51:06.476344  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0109569 (* 1 = 0.0109569 loss)
I1007 18:51:06.476351  5078 sgd_solver.cpp:105] Iteration 49400, lr = 0.01
I1007 18:51:14.402844  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:51:14.737926  5078 solver.cpp:330] Iteration 49500, Testing net (#0)
I1007 18:51:16.663254  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:51:16.744006  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.913
I1007 18:51:16.744041  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.319955 (* 1 = 0.319955 loss)
I1007 18:51:16.827623  5078 solver.cpp:218] Iteration 49500 (9.66067 iter/s, 10.3512s/100 iters), loss = 0.0273525
I1007 18:51:16.827651  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0273521 (* 1 = 0.0273521 loss)
I1007 18:51:16.827658  5078 sgd_solver.cpp:105] Iteration 49500, lr = 0.01
I1007 18:51:25.180259  5078 solver.cpp:218] Iteration 49600 (11.9724 iter/s, 8.35254s/100 iters), loss = 0.0329824
I1007 18:51:25.180357  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0329819 (* 1 = 0.0329819 loss)
I1007 18:51:25.180366  5078 sgd_solver.cpp:105] Iteration 49600, lr = 0.01
I1007 18:51:33.526756  5078 solver.cpp:218] Iteration 49700 (11.9813 iter/s, 8.34637s/100 iters), loss = 0.0129329
I1007 18:51:33.526794  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0129324 (* 1 = 0.0129324 loss)
I1007 18:51:33.526800  5078 sgd_solver.cpp:105] Iteration 49700, lr = 0.01
I1007 18:51:41.881114  5078 solver.cpp:218] Iteration 49800 (11.9699 iter/s, 8.35429s/100 iters), loss = 0.073195
I1007 18:51:41.881155  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0731945 (* 1 = 0.0731945 loss)
I1007 18:51:41.881161  5078 sgd_solver.cpp:105] Iteration 49800, lr = 0.01
I1007 18:51:50.231334  5078 solver.cpp:218] Iteration 49900 (11.9758 iter/s, 8.35015s/100 iters), loss = 0.0309301
I1007 18:51:50.231364  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0309296 (* 1 = 0.0309296 loss)
I1007 18:51:50.231369  5078 sgd_solver.cpp:105] Iteration 49900, lr = 0.01
I1007 18:51:58.166215  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:51:58.500190  5078 solver.cpp:330] Iteration 50000, Testing net (#0)
I1007 18:52:00.425808  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:52:00.507306  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9089
I1007 18:52:00.507340  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.323688 (* 1 = 0.323688 loss)
I1007 18:52:00.589948  5078 solver.cpp:218] Iteration 50000 (9.65386 iter/s, 10.3586s/100 iters), loss = 0.00962893
I1007 18:52:00.589974  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00962845 (* 1 = 0.00962845 loss)
I1007 18:52:00.589982  5078 sgd_solver.cpp:105] Iteration 50000, lr = 0.01
I1007 18:52:08.938944  5078 solver.cpp:218] Iteration 50100 (11.9776 iter/s, 8.34894s/100 iters), loss = 0.0160805
I1007 18:52:08.938974  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.01608 (* 1 = 0.01608 loss)
I1007 18:52:08.938980  5078 sgd_solver.cpp:105] Iteration 50100, lr = 0.01
I1007 18:52:17.290949  5078 solver.cpp:218] Iteration 50200 (11.9733 iter/s, 8.35194s/100 iters), loss = 0.058709
I1007 18:52:17.290988  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0587085 (* 1 = 0.0587085 loss)
I1007 18:52:17.290994  5078 sgd_solver.cpp:105] Iteration 50200, lr = 0.01
I1007 18:52:25.631821  5078 solver.cpp:218] Iteration 50300 (11.9892 iter/s, 8.34081s/100 iters), loss = 0.0196553
I1007 18:52:25.631851  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0196548 (* 1 = 0.0196548 loss)
I1007 18:52:25.631867  5078 sgd_solver.cpp:105] Iteration 50300, lr = 0.01
I1007 18:52:33.985292  5078 solver.cpp:218] Iteration 50400 (11.9712 iter/s, 8.35341s/100 iters), loss = 0.0184983
I1007 18:52:33.985378  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0184978 (* 1 = 0.0184978 loss)
I1007 18:52:33.985384  5078 sgd_solver.cpp:105] Iteration 50400, lr = 0.01
I1007 18:52:41.912151  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:52:42.246588  5078 solver.cpp:330] Iteration 50500, Testing net (#0)
I1007 18:52:44.171391  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:52:44.252172  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.915
I1007 18:52:44.252208  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.310784 (* 1 = 0.310784 loss)
I1007 18:52:44.335826  5078 solver.cpp:218] Iteration 50500 (9.66144 iter/s, 10.3504s/100 iters), loss = 0.0115168
I1007 18:52:44.335855  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0115164 (* 1 = 0.0115164 loss)
I1007 18:52:44.335860  5078 sgd_solver.cpp:105] Iteration 50500, lr = 0.01
I1007 18:52:52.691465  5078 solver.cpp:218] Iteration 50600 (11.968 iter/s, 8.35558s/100 iters), loss = 0.108934
I1007 18:52:52.691494  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.108934 (* 1 = 0.108934 loss)
I1007 18:52:52.691500  5078 sgd_solver.cpp:105] Iteration 50600, lr = 0.01
I1007 18:53:01.047116  5078 solver.cpp:218] Iteration 50700 (11.968 iter/s, 8.35559s/100 iters), loss = 0.0461976
I1007 18:53:01.047155  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0461971 (* 1 = 0.0461971 loss)
I1007 18:53:01.047161  5078 sgd_solver.cpp:105] Iteration 50700, lr = 0.01
I1007 18:53:09.406210  5078 solver.cpp:218] Iteration 50800 (11.9631 iter/s, 8.35903s/100 iters), loss = 0.0486224
I1007 18:53:09.406368  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0486219 (* 1 = 0.0486219 loss)
I1007 18:53:09.406376  5078 sgd_solver.cpp:105] Iteration 50800, lr = 0.01
I1007 18:53:17.755683  5078 solver.cpp:218] Iteration 50900 (11.9771 iter/s, 8.34929s/100 iters), loss = 0.0175257
I1007 18:53:17.755729  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0175252 (* 1 = 0.0175252 loss)
I1007 18:53:17.755738  5078 sgd_solver.cpp:105] Iteration 50900, lr = 0.01
I1007 18:53:25.696286  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:53:26.030925  5078 solver.cpp:330] Iteration 51000, Testing net (#0)
I1007 18:53:27.956516  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:53:28.037322  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9135
I1007 18:53:28.037355  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.325539 (* 1 = 0.325539 loss)
I1007 18:53:28.120748  5078 solver.cpp:218] Iteration 51000 (9.64786 iter/s, 10.365s/100 iters), loss = 0.00424062
I1007 18:53:28.120774  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00424011 (* 1 = 0.00424011 loss)
I1007 18:53:28.120781  5078 sgd_solver.cpp:105] Iteration 51000, lr = 0.01
I1007 18:53:36.472595  5078 solver.cpp:218] Iteration 51100 (11.9735 iter/s, 8.3518s/100 iters), loss = 0.0140004
I1007 18:53:36.472636  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0139999 (* 1 = 0.0139999 loss)
I1007 18:53:36.472642  5078 sgd_solver.cpp:105] Iteration 51100, lr = 0.01
I1007 18:53:44.834689  5078 solver.cpp:218] Iteration 51200 (11.9588 iter/s, 8.36203s/100 iters), loss = 0.0115665
I1007 18:53:44.834795  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.011566 (* 1 = 0.011566 loss)
I1007 18:53:44.834801  5078 sgd_solver.cpp:105] Iteration 51200, lr = 0.01
I1007 18:53:53.184201  5078 solver.cpp:218] Iteration 51300 (11.9769 iter/s, 8.34938s/100 iters), loss = 0.0134881
I1007 18:53:53.184231  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0134876 (* 1 = 0.0134876 loss)
I1007 18:53:53.184237  5078 sgd_solver.cpp:105] Iteration 51300, lr = 0.01
I1007 18:54:01.544212  5078 solver.cpp:218] Iteration 51400 (11.9618 iter/s, 8.35996s/100 iters), loss = 0.00784505
I1007 18:54:01.544253  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00784454 (* 1 = 0.00784454 loss)
I1007 18:54:01.544260  5078 sgd_solver.cpp:105] Iteration 51400, lr = 0.01
I1007 18:54:09.484314  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:54:09.818578  5078 solver.cpp:330] Iteration 51500, Testing net (#0)
I1007 18:54:11.743846  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:54:11.824319  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9155
I1007 18:54:11.824354  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.319572 (* 1 = 0.319572 loss)
I1007 18:54:11.908190  5078 solver.cpp:218] Iteration 51500 (9.64887 iter/s, 10.3639s/100 iters), loss = 0.0172772
I1007 18:54:11.908218  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0172767 (* 1 = 0.0172767 loss)
I1007 18:54:11.908226  5078 sgd_solver.cpp:105] Iteration 51500, lr = 0.01
I1007 18:54:20.256022  5078 solver.cpp:218] Iteration 51600 (11.9792 iter/s, 8.34777s/100 iters), loss = 0.0134614
I1007 18:54:20.256120  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0134609 (* 1 = 0.0134609 loss)
I1007 18:54:20.256137  5078 sgd_solver.cpp:105] Iteration 51600, lr = 0.01
I1007 18:54:28.600934  5078 solver.cpp:218] Iteration 51700 (11.9835 iter/s, 8.3448s/100 iters), loss = 0.0299282
I1007 18:54:28.600972  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0299277 (* 1 = 0.0299277 loss)
I1007 18:54:28.600978  5078 sgd_solver.cpp:105] Iteration 51700, lr = 0.01
I1007 18:54:36.952504  5078 solver.cpp:218] Iteration 51800 (11.9739 iter/s, 8.3515s/100 iters), loss = 0.016201
I1007 18:54:36.952544  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0162004 (* 1 = 0.0162004 loss)
I1007 18:54:36.952549  5078 sgd_solver.cpp:105] Iteration 51800, lr = 0.01
I1007 18:54:45.305744  5078 solver.cpp:218] Iteration 51900 (11.9715 iter/s, 8.35317s/100 iters), loss = 0.0145643
I1007 18:54:45.305774  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0145637 (* 1 = 0.0145637 loss)
I1007 18:54:45.305780  5078 sgd_solver.cpp:105] Iteration 51900, lr = 0.01
I1007 18:54:53.240854  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:54:53.576048  5078 solver.cpp:330] Iteration 52000, Testing net (#0)
I1007 18:54:55.500486  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:54:55.581455  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9137
I1007 18:54:55.581490  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.321134 (* 1 = 0.321134 loss)
I1007 18:54:55.664391  5078 solver.cpp:218] Iteration 52000 (9.65383 iter/s, 10.3586s/100 iters), loss = 0.0138602
I1007 18:54:55.664417  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0138596 (* 1 = 0.0138596 loss)
I1007 18:54:55.664423  5078 sgd_solver.cpp:105] Iteration 52000, lr = 0.01
I1007 18:55:04.012867  5078 solver.cpp:218] Iteration 52100 (11.9783 iter/s, 8.34842s/100 iters), loss = 0.0265411
I1007 18:55:04.012907  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0265405 (* 1 = 0.0265405 loss)
I1007 18:55:04.012913  5078 sgd_solver.cpp:105] Iteration 52100, lr = 0.01
I1007 18:55:12.366470  5078 solver.cpp:218] Iteration 52200 (11.971 iter/s, 8.35354s/100 iters), loss = 0.0148895
I1007 18:55:12.366511  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0148889 (* 1 = 0.0148889 loss)
I1007 18:55:12.366518  5078 sgd_solver.cpp:105] Iteration 52200, lr = 0.01
I1007 18:55:20.723835  5078 solver.cpp:218] Iteration 52300 (11.9656 iter/s, 8.3573s/100 iters), loss = 0.00615324
I1007 18:55:20.723877  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00615269 (* 1 = 0.00615269 loss)
I1007 18:55:20.723882  5078 sgd_solver.cpp:105] Iteration 52300, lr = 0.01
I1007 18:55:29.080979  5078 solver.cpp:218] Iteration 52400 (11.9659 iter/s, 8.35708s/100 iters), loss = 0.00246122
I1007 18:55:29.081092  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00246067 (* 1 = 0.00246067 loss)
I1007 18:55:29.081109  5078 sgd_solver.cpp:105] Iteration 52400, lr = 0.01
I1007 18:55:37.019598  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:55:37.355029  5078 solver.cpp:330] Iteration 52500, Testing net (#0)
I1007 18:55:39.281126  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:55:39.361629  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9187
I1007 18:55:39.361665  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.303983 (* 1 = 0.303983 loss)
I1007 18:55:39.445032  5078 solver.cpp:218] Iteration 52500 (9.64886 iter/s, 10.3639s/100 iters), loss = 0.00887555
I1007 18:55:39.445060  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.008875 (* 1 = 0.008875 loss)
I1007 18:55:39.445067  5078 sgd_solver.cpp:105] Iteration 52500, lr = 0.01
I1007 18:55:47.797029  5078 solver.cpp:218] Iteration 52600 (11.9733 iter/s, 8.35194s/100 iters), loss = 0.0271023
I1007 18:55:47.797057  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0271017 (* 1 = 0.0271017 loss)
I1007 18:55:47.797063  5078 sgd_solver.cpp:105] Iteration 52600, lr = 0.01
I1007 18:55:56.143239  5078 solver.cpp:218] Iteration 52700 (11.9816 iter/s, 8.34615s/100 iters), loss = 0.0243438
I1007 18:55:56.143266  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0243433 (* 1 = 0.0243433 loss)
I1007 18:55:56.143272  5078 sgd_solver.cpp:105] Iteration 52700, lr = 0.01
I1007 18:56:04.498066  5078 solver.cpp:218] Iteration 52800 (11.9692 iter/s, 8.35477s/100 iters), loss = 0.0446056
I1007 18:56:04.498147  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.044605 (* 1 = 0.044605 loss)
I1007 18:56:04.498153  5078 sgd_solver.cpp:105] Iteration 52800, lr = 0.01
I1007 18:56:12.841660  5078 solver.cpp:218] Iteration 52900 (11.9854 iter/s, 8.34349s/100 iters), loss = 0.0072876
I1007 18:56:12.841691  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00728705 (* 1 = 0.00728705 loss)
I1007 18:56:12.841696  5078 sgd_solver.cpp:105] Iteration 52900, lr = 0.01
I1007 18:56:20.779191  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:56:21.113672  5078 solver.cpp:330] Iteration 53000, Testing net (#0)
I1007 18:56:23.038494  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:56:23.119493  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.917
I1007 18:56:23.119527  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.309978 (* 1 = 0.309978 loss)
I1007 18:56:23.201774  5078 solver.cpp:218] Iteration 53000 (9.65246 iter/s, 10.3601s/100 iters), loss = 0.0130502
I1007 18:56:23.201799  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0130497 (* 1 = 0.0130497 loss)
I1007 18:56:23.201807  5078 sgd_solver.cpp:105] Iteration 53000, lr = 0.01
I1007 18:56:31.546454  5078 solver.cpp:218] Iteration 53100 (11.9838 iter/s, 8.34463s/100 iters), loss = 0.0257534
I1007 18:56:31.546484  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0257528 (* 1 = 0.0257528 loss)
I1007 18:56:31.546489  5078 sgd_solver.cpp:105] Iteration 53100, lr = 0.01
I1007 18:56:39.891264  5078 solver.cpp:218] Iteration 53200 (11.9836 iter/s, 8.34475s/100 iters), loss = 0.01133
I1007 18:56:39.891388  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0113295 (* 1 = 0.0113295 loss)
I1007 18:56:39.891407  5078 sgd_solver.cpp:105] Iteration 53200, lr = 0.01
I1007 18:56:48.234113  5078 solver.cpp:218] Iteration 53300 (11.9865 iter/s, 8.34271s/100 iters), loss = 0.00787007
I1007 18:56:48.234164  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00786954 (* 1 = 0.00786954 loss)
I1007 18:56:48.234170  5078 sgd_solver.cpp:105] Iteration 53300, lr = 0.01
I1007 18:56:56.586272  5078 solver.cpp:218] Iteration 53400 (11.9731 iter/s, 8.35208s/100 iters), loss = 0.00472044
I1007 18:56:56.586302  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00471991 (* 1 = 0.00471991 loss)
I1007 18:56:56.586308  5078 sgd_solver.cpp:105] Iteration 53400, lr = 0.01
I1007 18:57:04.520604  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:57:04.855396  5078 solver.cpp:330] Iteration 53500, Testing net (#0)
I1007 18:57:06.780583  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:57:06.861002  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9166
I1007 18:57:06.861038  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.329292 (* 1 = 0.329292 loss)
I1007 18:57:06.944813  5078 solver.cpp:218] Iteration 53500 (9.65393 iter/s, 10.3585s/100 iters), loss = 0.0322474
I1007 18:57:06.944840  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0322469 (* 1 = 0.0322469 loss)
I1007 18:57:06.944846  5078 sgd_solver.cpp:105] Iteration 53500, lr = 0.01
I1007 18:57:15.297384  5078 solver.cpp:218] Iteration 53600 (11.9725 iter/s, 8.35248s/100 iters), loss = 0.0279227
I1007 18:57:15.297523  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0279222 (* 1 = 0.0279222 loss)
I1007 18:57:15.297538  5078 sgd_solver.cpp:105] Iteration 53600, lr = 0.01
I1007 18:57:23.642863  5078 solver.cpp:218] Iteration 53700 (11.9828 iter/s, 8.34532s/100 iters), loss = 0.00711011
I1007 18:57:23.642904  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00710958 (* 1 = 0.00710958 loss)
I1007 18:57:23.642910  5078 sgd_solver.cpp:105] Iteration 53700, lr = 0.01
I1007 18:57:31.994856  5078 solver.cpp:218] Iteration 53800 (11.9733 iter/s, 8.35192s/100 iters), loss = 0.0186763
I1007 18:57:31.994896  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0186758 (* 1 = 0.0186758 loss)
I1007 18:57:31.994902  5078 sgd_solver.cpp:105] Iteration 53800, lr = 0.01
I1007 18:57:40.340256  5078 solver.cpp:218] Iteration 53900 (11.9827 iter/s, 8.34533s/100 iters), loss = 0.00855638
I1007 18:57:40.340296  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00855586 (* 1 = 0.00855586 loss)
I1007 18:57:40.340302  5078 sgd_solver.cpp:105] Iteration 53900, lr = 0.01
I1007 18:57:48.278208  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:57:48.613406  5078 solver.cpp:330] Iteration 54000, Testing net (#0)
I1007 18:57:50.539147  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:57:50.619868  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9104
I1007 18:57:50.619902  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.335736 (* 1 = 0.335736 loss)
I1007 18:57:50.703091  5078 solver.cpp:218] Iteration 54000 (9.64993 iter/s, 10.3628s/100 iters), loss = 0.0068376
I1007 18:57:50.703117  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00683708 (* 1 = 0.00683708 loss)
I1007 18:57:50.703125  5078 sgd_solver.cpp:105] Iteration 54000, lr = 0.01
I1007 18:57:59.041759  5078 solver.cpp:218] Iteration 54100 (11.9924 iter/s, 8.33861s/100 iters), loss = 0.0181793
I1007 18:57:59.041798  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0181788 (* 1 = 0.0181788 loss)
I1007 18:57:59.041803  5078 sgd_solver.cpp:105] Iteration 54100, lr = 0.01
I1007 18:58:07.392421  5078 solver.cpp:218] Iteration 54200 (11.9752 iter/s, 8.3506s/100 iters), loss = 0.0246165
I1007 18:58:07.392451  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.024616 (* 1 = 0.024616 loss)
I1007 18:58:07.392457  5078 sgd_solver.cpp:105] Iteration 54200, lr = 0.01
I1007 18:58:15.742524  5078 solver.cpp:218] Iteration 54300 (11.976 iter/s, 8.35005s/100 iters), loss = 0.0279412
I1007 18:58:15.742553  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0279407 (* 1 = 0.0279407 loss)
I1007 18:58:15.742559  5078 sgd_solver.cpp:105] Iteration 54300, lr = 0.01
I1007 18:58:24.091220  5078 solver.cpp:218] Iteration 54400 (11.978 iter/s, 8.34864s/100 iters), loss = 0.0133431
I1007 18:58:24.091327  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0133426 (* 1 = 0.0133426 loss)
I1007 18:58:24.091334  5078 sgd_solver.cpp:105] Iteration 54400, lr = 0.01
I1007 18:58:32.022318  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:58:32.355927  5078 solver.cpp:330] Iteration 54500, Testing net (#0)
I1007 18:58:34.282157  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:58:34.362409  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9136
I1007 18:58:34.362434  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.334254 (* 1 = 0.334254 loss)
I1007 18:58:34.446219  5078 solver.cpp:218] Iteration 54500 (9.6573 iter/s, 10.3549s/100 iters), loss = 0.00811374
I1007 18:58:34.446247  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00811324 (* 1 = 0.00811324 loss)
I1007 18:58:34.446254  5078 sgd_solver.cpp:105] Iteration 54500, lr = 0.01
I1007 18:58:42.800321  5078 solver.cpp:218] Iteration 54600 (11.9702 iter/s, 8.35405s/100 iters), loss = 0.0191213
I1007 18:58:42.800350  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0191208 (* 1 = 0.0191208 loss)
I1007 18:58:42.800356  5078 sgd_solver.cpp:105] Iteration 54600, lr = 0.01
I1007 18:58:51.140830  5078 solver.cpp:218] Iteration 54700 (11.9898 iter/s, 8.34045s/100 iters), loss = 0.0131893
I1007 18:58:51.140871  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0131888 (* 1 = 0.0131888 loss)
I1007 18:58:51.140877  5078 sgd_solver.cpp:105] Iteration 54700, lr = 0.01
I1007 18:58:59.497146  5078 solver.cpp:218] Iteration 54800 (11.9671 iter/s, 8.35625s/100 iters), loss = 0.00952817
I1007 18:58:59.497285  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00952768 (* 1 = 0.00952768 loss)
I1007 18:58:59.497303  5078 sgd_solver.cpp:105] Iteration 54800, lr = 0.01
I1007 18:59:07.849135  5078 solver.cpp:218] Iteration 54900 (11.9734 iter/s, 8.35182s/100 iters), loss = 0.0273003
I1007 18:59:07.849175  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0272998 (* 1 = 0.0272998 loss)
I1007 18:59:07.849181  5078 sgd_solver.cpp:105] Iteration 54900, lr = 0.01
I1007 18:59:15.792481  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:59:16.126540  5078 solver.cpp:330] Iteration 55000, Testing net (#0)
I1007 18:59:18.051002  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:59:18.131734  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9173
I1007 18:59:18.131759  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.327198 (* 1 = 0.327198 loss)
I1007 18:59:18.215260  5078 solver.cpp:218] Iteration 55000 (9.64687 iter/s, 10.3661s/100 iters), loss = 0.0427344
I1007 18:59:18.215286  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0427339 (* 1 = 0.0427339 loss)
I1007 18:59:18.215293  5078 sgd_solver.cpp:105] Iteration 55000, lr = 0.01
I1007 18:59:26.568759  5078 solver.cpp:218] Iteration 55100 (11.9711 iter/s, 8.35345s/100 iters), loss = 0.0102469
I1007 18:59:26.568789  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0102463 (* 1 = 0.0102463 loss)
I1007 18:59:26.568795  5078 sgd_solver.cpp:105] Iteration 55100, lr = 0.01
I1007 18:59:34.923876  5078 solver.cpp:218] Iteration 55200 (11.9688 iter/s, 8.35506s/100 iters), loss = 0.0379715
I1007 18:59:34.924012  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.037971 (* 1 = 0.037971 loss)
I1007 18:59:34.924018  5078 sgd_solver.cpp:105] Iteration 55200, lr = 0.01
I1007 18:59:43.276744  5078 solver.cpp:218] Iteration 55300 (11.9722 iter/s, 8.35272s/100 iters), loss = 0.036384
I1007 18:59:43.276775  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0363835 (* 1 = 0.0363835 loss)
I1007 18:59:43.276780  5078 sgd_solver.cpp:105] Iteration 55300, lr = 0.01
I1007 18:59:51.636229  5078 solver.cpp:218] Iteration 55400 (11.9625 iter/s, 8.35943s/100 iters), loss = 0.0237237
I1007 18:59:51.636270  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0237232 (* 1 = 0.0237232 loss)
I1007 18:59:51.636276  5078 sgd_solver.cpp:105] Iteration 55400, lr = 0.01
I1007 18:59:59.570652  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 18:59:59.904808  5078 solver.cpp:330] Iteration 55500, Testing net (#0)
I1007 19:00:01.832201  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:00:01.912463  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9066
I1007 19:00:01.912487  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.367123 (* 1 = 0.367123 loss)
I1007 19:00:01.996075  5078 solver.cpp:218] Iteration 55500 (9.65272 iter/s, 10.3598s/100 iters), loss = 0.00484634
I1007 19:00:01.996101  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00484585 (* 1 = 0.00484585 loss)
I1007 19:00:01.996109  5078 sgd_solver.cpp:105] Iteration 55500, lr = 0.01
I1007 19:00:10.349094  5078 solver.cpp:218] Iteration 55600 (11.9718 iter/s, 8.35297s/100 iters), loss = 0.0119821
I1007 19:00:10.349231  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0119816 (* 1 = 0.0119816 loss)
I1007 19:00:10.349248  5078 sgd_solver.cpp:105] Iteration 55600, lr = 0.01
I1007 19:00:18.697849  5078 solver.cpp:218] Iteration 55700 (11.9781 iter/s, 8.3486s/100 iters), loss = 0.00452304
I1007 19:00:18.697890  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00452256 (* 1 = 0.00452256 loss)
I1007 19:00:18.697896  5078 sgd_solver.cpp:105] Iteration 55700, lr = 0.01
I1007 19:00:27.048336  5078 solver.cpp:218] Iteration 55800 (11.9754 iter/s, 8.35042s/100 iters), loss = 0.0514256
I1007 19:00:27.048377  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0514251 (* 1 = 0.0514251 loss)
I1007 19:00:27.048382  5078 sgd_solver.cpp:105] Iteration 55800, lr = 0.01
I1007 19:00:35.389173  5078 solver.cpp:218] Iteration 55900 (11.9893 iter/s, 8.34077s/100 iters), loss = 0.0141453
I1007 19:00:35.389214  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0141448 (* 1 = 0.0141448 loss)
I1007 19:00:35.389220  5078 sgd_solver.cpp:105] Iteration 55900, lr = 0.01
I1007 19:00:43.324439  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:00:43.659078  5078 solver.cpp:330] Iteration 56000, Testing net (#0)
I1007 19:00:45.584313  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:00:45.665457  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9161
I1007 19:00:45.665493  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.349377 (* 1 = 0.349377 loss)
I1007 19:00:45.748296  5078 solver.cpp:218] Iteration 56000 (9.65339 iter/s, 10.359s/100 iters), loss = 0.00470869
I1007 19:00:45.748323  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00470822 (* 1 = 0.00470822 loss)
I1007 19:00:45.748330  5078 sgd_solver.cpp:105] Iteration 56000, lr = 0.01
I1007 19:00:54.097326  5078 solver.cpp:218] Iteration 56100 (11.9775 iter/s, 8.34898s/100 iters), loss = 0.0314513
I1007 19:00:54.097365  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0314508 (* 1 = 0.0314508 loss)
I1007 19:00:54.097371  5078 sgd_solver.cpp:105] Iteration 56100, lr = 0.01
I1007 19:01:02.452185  5078 solver.cpp:218] Iteration 56200 (11.9692 iter/s, 8.35479s/100 iters), loss = 0.00506775
I1007 19:01:02.452225  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00506726 (* 1 = 0.00506726 loss)
I1007 19:01:02.452231  5078 sgd_solver.cpp:105] Iteration 56200, lr = 0.01
I1007 19:01:10.799171  5078 solver.cpp:218] Iteration 56300 (11.9805 iter/s, 8.34692s/100 iters), loss = 0.00596768
I1007 19:01:10.799211  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00596718 (* 1 = 0.00596718 loss)
I1007 19:01:10.799217  5078 sgd_solver.cpp:105] Iteration 56300, lr = 0.01
I1007 19:01:19.150810  5078 solver.cpp:218] Iteration 56400 (11.9738 iter/s, 8.35157s/100 iters), loss = 0.00320995
I1007 19:01:19.150880  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00320944 (* 1 = 0.00320944 loss)
I1007 19:01:19.150887  5078 sgd_solver.cpp:105] Iteration 56400, lr = 0.01
I1007 19:01:27.084897  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:01:27.418422  5078 solver.cpp:330] Iteration 56500, Testing net (#0)
I1007 19:01:29.344214  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:01:29.424602  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9146
I1007 19:01:29.424638  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.337522 (* 1 = 0.337522 loss)
I1007 19:01:29.507860  5078 solver.cpp:218] Iteration 56500 (9.65535 iter/s, 10.3569s/100 iters), loss = 0.0118372
I1007 19:01:29.507889  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0118367 (* 1 = 0.0118367 loss)
I1007 19:01:29.507894  5078 sgd_solver.cpp:105] Iteration 56500, lr = 0.01
I1007 19:01:37.862228  5078 solver.cpp:218] Iteration 56600 (11.9699 iter/s, 8.35431s/100 iters), loss = 0.0045423
I1007 19:01:37.862257  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00454178 (* 1 = 0.00454178 loss)
I1007 19:01:37.862262  5078 sgd_solver.cpp:105] Iteration 56600, lr = 0.01
I1007 19:01:46.204856  5078 solver.cpp:218] Iteration 56700 (11.9867 iter/s, 8.34257s/100 iters), loss = 0.00991388
I1007 19:01:46.204885  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00991335 (* 1 = 0.00991335 loss)
I1007 19:01:46.204891  5078 sgd_solver.cpp:105] Iteration 56700, lr = 0.01
I1007 19:01:54.562624  5078 solver.cpp:218] Iteration 56800 (11.965 iter/s, 8.35771s/100 iters), loss = 0.0253139
I1007 19:01:54.562773  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0253133 (* 1 = 0.0253133 loss)
I1007 19:01:54.562793  5078 sgd_solver.cpp:105] Iteration 56800, lr = 0.01
I1007 19:02:02.909152  5078 solver.cpp:218] Iteration 56900 (11.9813 iter/s, 8.34637s/100 iters), loss = 0.00198172
I1007 19:02:02.909183  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00198119 (* 1 = 0.00198119 loss)
I1007 19:02:02.909190  5078 sgd_solver.cpp:105] Iteration 56900, lr = 0.01
I1007 19:02:10.844768  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:02:11.178828  5078 solver.cpp:330] Iteration 57000, Testing net (#0)
I1007 19:02:13.104418  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:02:13.184996  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9137
I1007 19:02:13.185031  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.332575 (* 1 = 0.332575 loss)
I1007 19:02:13.267702  5078 solver.cpp:218] Iteration 57000 (9.65392 iter/s, 10.3585s/100 iters), loss = 0.00420297
I1007 19:02:13.267734  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00420245 (* 1 = 0.00420245 loss)
I1007 19:02:13.267740  5078 sgd_solver.cpp:105] Iteration 57000, lr = 0.01
I1007 19:02:21.613570  5078 solver.cpp:218] Iteration 57100 (11.9821 iter/s, 8.34581s/100 iters), loss = 0.0071698
I1007 19:02:21.613612  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00716928 (* 1 = 0.00716928 loss)
I1007 19:02:21.613617  5078 sgd_solver.cpp:105] Iteration 57100, lr = 0.01
I1007 19:02:29.964718  5078 solver.cpp:218] Iteration 57200 (11.9745 iter/s, 8.35108s/100 iters), loss = 0.0122552
I1007 19:02:29.964828  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0122546 (* 1 = 0.0122546 loss)
I1007 19:02:29.964835  5078 sgd_solver.cpp:105] Iteration 57200, lr = 0.01
I1007 19:02:38.314874  5078 solver.cpp:218] Iteration 57300 (11.976 iter/s, 8.35003s/100 iters), loss = 0.00629201
I1007 19:02:38.314904  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00629149 (* 1 = 0.00629149 loss)
I1007 19:02:38.314910  5078 sgd_solver.cpp:105] Iteration 57300, lr = 0.01
I1007 19:02:46.666627  5078 solver.cpp:218] Iteration 57400 (11.9736 iter/s, 8.3517s/100 iters), loss = 0.0317294
I1007 19:02:46.666667  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0317289 (* 1 = 0.0317289 loss)
I1007 19:02:46.666673  5078 sgd_solver.cpp:105] Iteration 57400, lr = 0.01
I1007 19:02:54.602756  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:02:54.935987  5078 solver.cpp:330] Iteration 57500, Testing net (#0)
I1007 19:02:56.860829  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:02:56.941321  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9166
I1007 19:02:56.941356  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.329601 (* 1 = 0.329601 loss)
I1007 19:02:57.024531  5078 solver.cpp:218] Iteration 57500 (9.65453 iter/s, 10.3578s/100 iters), loss = 0.0152499
I1007 19:02:57.024559  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0152493 (* 1 = 0.0152493 loss)
I1007 19:02:57.024566  5078 sgd_solver.cpp:105] Iteration 57500, lr = 0.01
I1007 19:03:05.376372  5078 solver.cpp:218] Iteration 57600 (11.9735 iter/s, 8.35179s/100 iters), loss = 0.0162555
I1007 19:03:05.376529  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.016255 (* 1 = 0.016255 loss)
I1007 19:03:05.376538  5078 sgd_solver.cpp:105] Iteration 57600, lr = 0.01
I1007 19:03:13.720877  5078 solver.cpp:218] Iteration 57700 (11.9842 iter/s, 8.34434s/100 iters), loss = 0.0142396
I1007 19:03:13.720917  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0142391 (* 1 = 0.0142391 loss)
I1007 19:03:13.720923  5078 sgd_solver.cpp:105] Iteration 57700, lr = 0.01
I1007 19:03:22.072072  5078 solver.cpp:218] Iteration 57800 (11.9744 iter/s, 8.35113s/100 iters), loss = 0.00287946
I1007 19:03:22.072100  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00287895 (* 1 = 0.00287895 loss)
I1007 19:03:22.072106  5078 sgd_solver.cpp:105] Iteration 57800, lr = 0.01
I1007 19:03:30.414886  5078 solver.cpp:218] Iteration 57900 (11.9864 iter/s, 8.34276s/100 iters), loss = 0.0186101
I1007 19:03:30.414916  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0186096 (* 1 = 0.0186096 loss)
I1007 19:03:30.414922  5078 sgd_solver.cpp:105] Iteration 57900, lr = 0.01
I1007 19:03:38.352340  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:03:38.686195  5078 solver.cpp:330] Iteration 58000, Testing net (#0)
I1007 19:03:40.611347  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:03:40.692534  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9089
I1007 19:03:40.692569  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.357724 (* 1 = 0.357724 loss)
I1007 19:03:40.775575  5078 solver.cpp:218] Iteration 58000 (9.65192 iter/s, 10.3606s/100 iters), loss = 0.00209178
I1007 19:03:40.775600  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00209128 (* 1 = 0.00209128 loss)
I1007 19:03:40.775607  5078 sgd_solver.cpp:105] Iteration 58000, lr = 0.01
I1007 19:03:49.120126  5078 solver.cpp:218] Iteration 58100 (11.9839 iter/s, 8.3445s/100 iters), loss = 0.0336272
I1007 19:03:49.120156  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0336267 (* 1 = 0.0336267 loss)
I1007 19:03:49.120160  5078 sgd_solver.cpp:105] Iteration 58100, lr = 0.01
I1007 19:03:57.473860  5078 solver.cpp:218] Iteration 58200 (11.9708 iter/s, 8.35368s/100 iters), loss = 0.0148511
I1007 19:03:57.473891  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0148506 (* 1 = 0.0148506 loss)
I1007 19:03:57.473896  5078 sgd_solver.cpp:105] Iteration 58200, lr = 0.01
I1007 19:04:05.824800  5078 solver.cpp:218] Iteration 58300 (11.9748 iter/s, 8.35088s/100 iters), loss = 0.0105068
I1007 19:04:05.824831  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0105063 (* 1 = 0.0105063 loss)
I1007 19:04:05.824846  5078 sgd_solver.cpp:105] Iteration 58300, lr = 0.01
I1007 19:04:14.182893  5078 solver.cpp:218] Iteration 58400 (11.9645 iter/s, 8.35804s/100 iters), loss = 0.00270395
I1007 19:04:14.183007  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00270344 (* 1 = 0.00270344 loss)
I1007 19:04:14.183012  5078 sgd_solver.cpp:105] Iteration 58400, lr = 0.01
I1007 19:04:22.117992  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:04:22.452308  5078 solver.cpp:330] Iteration 58500, Testing net (#0)
I1007 19:04:24.378896  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:04:24.459692  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9176
I1007 19:04:24.459717  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.316096 (* 1 = 0.316096 loss)
I1007 19:04:24.543727  5078 solver.cpp:218] Iteration 58500 (9.65187 iter/s, 10.3607s/100 iters), loss = 0.0531804
I1007 19:04:24.543756  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0531799 (* 1 = 0.0531799 loss)
I1007 19:04:24.543762  5078 sgd_solver.cpp:105] Iteration 58500, lr = 0.01
I1007 19:04:32.894793  5078 solver.cpp:218] Iteration 58600 (11.9746 iter/s, 8.35101s/100 iters), loss = 0.0461299
I1007 19:04:32.894832  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0461293 (* 1 = 0.0461293 loss)
I1007 19:04:32.894839  5078 sgd_solver.cpp:105] Iteration 58600, lr = 0.01
I1007 19:04:41.240736  5078 solver.cpp:218] Iteration 58700 (11.982 iter/s, 8.34588s/100 iters), loss = 0.00550367
I1007 19:04:41.240766  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00550315 (* 1 = 0.00550315 loss)
I1007 19:04:41.240772  5078 sgd_solver.cpp:105] Iteration 58700, lr = 0.01
I1007 19:04:49.594432  5078 solver.cpp:218] Iteration 58800 (11.9708 iter/s, 8.35364s/100 iters), loss = 0.008282
I1007 19:04:49.594527  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00828149 (* 1 = 0.00828149 loss)
I1007 19:04:49.594544  5078 sgd_solver.cpp:105] Iteration 58800, lr = 0.01
I1007 19:04:57.944303  5078 solver.cpp:218] Iteration 58900 (11.9764 iter/s, 8.34975s/100 iters), loss = 0.0120702
I1007 19:04:57.944334  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0120697 (* 1 = 0.0120697 loss)
I1007 19:04:57.944339  5078 sgd_solver.cpp:105] Iteration 58900, lr = 0.01
I1007 19:05:05.888831  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:05:06.222919  5078 solver.cpp:330] Iteration 59000, Testing net (#0)
I1007 19:05:08.147779  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:05:08.228435  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9149
I1007 19:05:08.228462  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.334966 (* 1 = 0.334966 loss)
I1007 19:05:08.311990  5078 solver.cpp:218] Iteration 59000 (9.64541 iter/s, 10.3676s/100 iters), loss = 0.00409766
I1007 19:05:08.312021  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00409714 (* 1 = 0.00409714 loss)
I1007 19:05:08.312028  5078 sgd_solver.cpp:105] Iteration 59000, lr = 0.01
I1007 19:05:16.661623  5078 solver.cpp:218] Iteration 59100 (11.9767 iter/s, 8.34958s/100 iters), loss = 0.0067452
I1007 19:05:16.661662  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00674468 (* 1 = 0.00674468 loss)
I1007 19:05:16.661669  5078 sgd_solver.cpp:105] Iteration 59100, lr = 0.01
I1007 19:05:25.017871  5078 solver.cpp:218] Iteration 59200 (11.9672 iter/s, 8.35618s/100 iters), loss = 0.00298656
I1007 19:05:25.017967  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00298604 (* 1 = 0.00298604 loss)
I1007 19:05:25.017982  5078 sgd_solver.cpp:105] Iteration 59200, lr = 0.01
I1007 19:05:33.366164  5078 solver.cpp:218] Iteration 59300 (11.9787 iter/s, 8.34818s/100 iters), loss = 0.00670454
I1007 19:05:33.366205  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00670402 (* 1 = 0.00670402 loss)
I1007 19:05:33.366211  5078 sgd_solver.cpp:105] Iteration 59300, lr = 0.01
I1007 19:05:41.719463  5078 solver.cpp:218] Iteration 59400 (11.9714 iter/s, 8.35323s/100 iters), loss = 0.00749385
I1007 19:05:41.719493  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00749333 (* 1 = 0.00749333 loss)
I1007 19:05:41.719499  5078 sgd_solver.cpp:105] Iteration 59400, lr = 0.01
I1007 19:05:49.654413  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:05:49.988836  5078 solver.cpp:330] Iteration 59500, Testing net (#0)
I1007 19:05:51.915276  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:05:51.995394  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9073
I1007 19:05:51.995429  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.380452 (* 1 = 0.380452 loss)
I1007 19:05:52.079439  5078 solver.cpp:218] Iteration 59500 (9.65259 iter/s, 10.3599s/100 iters), loss = 0.0165876
I1007 19:05:52.079468  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0165871 (* 1 = 0.0165871 loss)
I1007 19:05:52.079473  5078 sgd_solver.cpp:105] Iteration 59500, lr = 0.01
I1007 19:06:00.438673  5078 solver.cpp:218] Iteration 59600 (11.963 iter/s, 8.35913s/100 iters), loss = 0.00594784
I1007 19:06:00.438792  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0059473 (* 1 = 0.0059473 loss)
I1007 19:06:00.438809  5078 sgd_solver.cpp:105] Iteration 59600, lr = 0.01
I1007 19:06:08.786631  5078 solver.cpp:218] Iteration 59700 (11.9792 iter/s, 8.34781s/100 iters), loss = 0.0103802
I1007 19:06:08.786661  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0103797 (* 1 = 0.0103797 loss)
I1007 19:06:08.786667  5078 sgd_solver.cpp:105] Iteration 59700, lr = 0.01
I1007 19:06:17.145695  5078 solver.cpp:218] Iteration 59800 (11.9631 iter/s, 8.35901s/100 iters), loss = 0.030644
I1007 19:06:17.145725  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0306435 (* 1 = 0.0306435 loss)
I1007 19:06:17.145731  5078 sgd_solver.cpp:105] Iteration 59800, lr = 0.01
I1007 19:06:25.494379  5078 solver.cpp:218] Iteration 59900 (11.978 iter/s, 8.34863s/100 iters), loss = 0.0324447
I1007 19:06:25.494410  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0324442 (* 1 = 0.0324442 loss)
I1007 19:06:25.494416  5078 sgd_solver.cpp:105] Iteration 59900, lr = 0.01
I1007 19:06:33.433845  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:06:33.768489  5078 solver.cpp:330] Iteration 60000, Testing net (#0)
I1007 19:06:35.693611  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:06:35.774802  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9165
I1007 19:06:35.774837  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.338921 (* 1 = 0.338921 loss)
I1007 19:06:35.857558  5078 solver.cpp:218] Iteration 60000 (9.64961 iter/s, 10.3631s/100 iters), loss = 0.0255604
I1007 19:06:35.857585  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0255599 (* 1 = 0.0255599 loss)
I1007 19:06:35.857591  5078 sgd_solver.cpp:105] Iteration 60000, lr = 0.01
I1007 19:06:44.206645  5078 solver.cpp:218] Iteration 60100 (11.9774 iter/s, 8.34903s/100 iters), loss = 0.0256307
I1007 19:06:44.206691  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0256301 (* 1 = 0.0256301 loss)
I1007 19:06:44.206698  5078 sgd_solver.cpp:105] Iteration 60100, lr = 0.01
I1007 19:06:52.561300  5078 solver.cpp:218] Iteration 60200 (11.9695 iter/s, 8.35458s/100 iters), loss = 0.0165683
I1007 19:06:52.561341  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0165678 (* 1 = 0.0165678 loss)
I1007 19:06:52.561347  5078 sgd_solver.cpp:105] Iteration 60200, lr = 0.01
I1007 19:07:00.912660  5078 solver.cpp:218] Iteration 60300 (11.9742 iter/s, 8.35129s/100 iters), loss = 0.0237282
I1007 19:07:00.912700  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0237276 (* 1 = 0.0237276 loss)
I1007 19:07:00.912706  5078 sgd_solver.cpp:105] Iteration 60300, lr = 0.01
I1007 19:07:09.268195  5078 solver.cpp:218] Iteration 60400 (11.9682 iter/s, 8.35547s/100 iters), loss = 0.0181651
I1007 19:07:09.268317  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0181646 (* 1 = 0.0181646 loss)
I1007 19:07:09.268335  5078 sgd_solver.cpp:105] Iteration 60400, lr = 0.01
I1007 19:07:17.203657  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:07:17.538467  5078 solver.cpp:330] Iteration 60500, Testing net (#0)
I1007 19:07:19.464093  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:07:19.544606  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9153
I1007 19:07:19.544642  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.336744 (* 1 = 0.336744 loss)
I1007 19:07:19.628150  5078 solver.cpp:218] Iteration 60500 (9.65269 iter/s, 10.3598s/100 iters), loss = 0.00135353
I1007 19:07:19.628180  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00135298 (* 1 = 0.00135298 loss)
I1007 19:07:19.628186  5078 sgd_solver.cpp:105] Iteration 60500, lr = 0.01
I1007 19:07:27.984561  5078 solver.cpp:218] Iteration 60600 (11.9669 iter/s, 8.35635s/100 iters), loss = 0.00513537
I1007 19:07:27.984602  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00513481 (* 1 = 0.00513481 loss)
I1007 19:07:27.984607  5078 sgd_solver.cpp:105] Iteration 60600, lr = 0.01
I1007 19:07:36.337220  5078 solver.cpp:218] Iteration 60700 (11.9723 iter/s, 8.35259s/100 iters), loss = 0.00364512
I1007 19:07:36.337250  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00364457 (* 1 = 0.00364457 loss)
I1007 19:07:36.337256  5078 sgd_solver.cpp:105] Iteration 60700, lr = 0.01
I1007 19:07:44.687108  5078 solver.cpp:218] Iteration 60800 (11.9763 iter/s, 8.34983s/100 iters), loss = 0.0162859
I1007 19:07:44.687235  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0162854 (* 1 = 0.0162854 loss)
I1007 19:07:44.687242  5078 sgd_solver.cpp:105] Iteration 60800, lr = 0.01
I1007 19:07:53.041224  5078 solver.cpp:218] Iteration 60900 (11.9704 iter/s, 8.35396s/100 iters), loss = 0.00213867
I1007 19:07:53.041256  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00213811 (* 1 = 0.00213811 loss)
I1007 19:07:53.041272  5078 sgd_solver.cpp:105] Iteration 60900, lr = 0.01
I1007 19:08:00.982403  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:08:01.316758  5078 solver.cpp:330] Iteration 61000, Testing net (#0)
I1007 19:08:03.241880  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:08:03.322566  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9135
I1007 19:08:03.322602  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.348099 (* 1 = 0.348099 loss)
I1007 19:08:03.405493  5078 solver.cpp:218] Iteration 61000 (9.64859 iter/s, 10.3642s/100 iters), loss = 0.00114221
I1007 19:08:03.405519  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00114167 (* 1 = 0.00114167 loss)
I1007 19:08:03.405525  5078 sgd_solver.cpp:105] Iteration 61000, lr = 0.01
I1007 19:08:11.751193  5078 solver.cpp:218] Iteration 61100 (11.9823 iter/s, 8.34565s/100 iters), loss = 0.00586416
I1007 19:08:11.751222  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00586361 (* 1 = 0.00586361 loss)
I1007 19:08:11.751227  5078 sgd_solver.cpp:105] Iteration 61100, lr = 0.01
I1007 19:08:20.111070  5078 solver.cpp:218] Iteration 61200 (11.962 iter/s, 8.35982s/100 iters), loss = 0.00535062
I1007 19:08:20.111172  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00535007 (* 1 = 0.00535007 loss)
I1007 19:08:20.111179  5078 sgd_solver.cpp:105] Iteration 61200, lr = 0.01
I1007 19:08:28.464540  5078 solver.cpp:218] Iteration 61300 (11.9713 iter/s, 8.35334s/100 iters), loss = 0.0141979
I1007 19:08:28.464570  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0141973 (* 1 = 0.0141973 loss)
I1007 19:08:28.464584  5078 sgd_solver.cpp:105] Iteration 61300, lr = 0.01
I1007 19:08:36.814582  5078 solver.cpp:218] Iteration 61400 (11.9761 iter/s, 8.34999s/100 iters), loss = 0.00658699
I1007 19:08:36.814612  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00658644 (* 1 = 0.00658644 loss)
I1007 19:08:36.814620  5078 sgd_solver.cpp:105] Iteration 61400, lr = 0.01
I1007 19:08:44.743979  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:08:45.078601  5078 solver.cpp:330] Iteration 61500, Testing net (#0)
I1007 19:08:47.003249  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:08:47.083745  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9117
I1007 19:08:47.083781  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.347939 (* 1 = 0.347939 loss)
I1007 19:08:47.167560  5078 solver.cpp:218] Iteration 61500 (9.65911 iter/s, 10.3529s/100 iters), loss = 0.00470255
I1007 19:08:47.167587  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.004702 (* 1 = 0.004702 loss)
I1007 19:08:47.167593  5078 sgd_solver.cpp:105] Iteration 61500, lr = 0.01
I1007 19:08:55.522397  5078 solver.cpp:218] Iteration 61600 (11.9692 iter/s, 8.35478s/100 iters), loss = 0.00439485
I1007 19:08:55.522514  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00439431 (* 1 = 0.00439431 loss)
I1007 19:08:55.522522  5078 sgd_solver.cpp:105] Iteration 61600, lr = 0.01
I1007 19:09:03.869374  5078 solver.cpp:218] Iteration 61700 (11.9806 iter/s, 8.34684s/100 iters), loss = 0.00607277
I1007 19:09:03.869401  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00607222 (* 1 = 0.00607222 loss)
I1007 19:09:03.869407  5078 sgd_solver.cpp:105] Iteration 61700, lr = 0.01
I1007 19:09:12.228323  5078 solver.cpp:218] Iteration 61800 (11.9633 iter/s, 8.35889s/100 iters), loss = 0.0166896
I1007 19:09:12.228364  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.016689 (* 1 = 0.016689 loss)
I1007 19:09:12.228370  5078 sgd_solver.cpp:105] Iteration 61800, lr = 0.01
I1007 19:09:20.583140  5078 solver.cpp:218] Iteration 61900 (11.9692 iter/s, 8.35475s/100 iters), loss = 0.00890272
I1007 19:09:20.583183  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00890215 (* 1 = 0.00890215 loss)
I1007 19:09:20.583189  5078 sgd_solver.cpp:105] Iteration 61900, lr = 0.01
I1007 19:09:28.526463  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:09:28.860441  5078 solver.cpp:330] Iteration 62000, Testing net (#0)
I1007 19:09:30.785639  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:09:30.866097  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9107
I1007 19:09:30.866132  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.378569 (* 1 = 0.378569 loss)
I1007 19:09:30.949666  5078 solver.cpp:218] Iteration 62000 (9.6465 iter/s, 10.3665s/100 iters), loss = 0.0221287
I1007 19:09:30.949692  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0221281 (* 1 = 0.0221281 loss)
I1007 19:09:30.949698  5078 sgd_solver.cpp:105] Iteration 62000, lr = 0.01
I1007 19:09:39.300806  5078 solver.cpp:218] Iteration 62100 (11.9745 iter/s, 8.35109s/100 iters), loss = 0.013674
I1007 19:09:39.300851  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0136734 (* 1 = 0.0136734 loss)
I1007 19:09:39.300858  5078 sgd_solver.cpp:105] Iteration 62100, lr = 0.01
I1007 19:09:47.660579  5078 solver.cpp:218] Iteration 62200 (11.9621 iter/s, 8.3597s/100 iters), loss = 0.0240734
I1007 19:09:47.660609  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0240728 (* 1 = 0.0240728 loss)
I1007 19:09:47.660625  5078 sgd_solver.cpp:105] Iteration 62200, lr = 0.01
I1007 19:09:56.009392  5078 solver.cpp:218] Iteration 62300 (11.9778 iter/s, 8.34875s/100 iters), loss = 0.0070179
I1007 19:09:56.009421  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00701734 (* 1 = 0.00701734 loss)
I1007 19:09:56.009438  5078 sgd_solver.cpp:105] Iteration 62300, lr = 0.01
I1007 19:10:04.369253  5078 solver.cpp:218] Iteration 62400 (11.962 iter/s, 8.35981s/100 iters), loss = 0.00831647
I1007 19:10:04.369398  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0083159 (* 1 = 0.0083159 loss)
I1007 19:10:04.369406  5078 sgd_solver.cpp:105] Iteration 62400, lr = 0.01
I1007 19:10:12.308218  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:10:12.642940  5078 solver.cpp:330] Iteration 62500, Testing net (#0)
I1007 19:10:14.567452  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:10:14.647879  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9137
I1007 19:10:14.647914  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.357778 (* 1 = 0.357778 loss)
I1007 19:10:14.731586  5078 solver.cpp:218] Iteration 62500 (9.6505 iter/s, 10.3622s/100 iters), loss = 0.00767528
I1007 19:10:14.731612  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00767471 (* 1 = 0.00767471 loss)
I1007 19:10:14.731621  5078 sgd_solver.cpp:105] Iteration 62500, lr = 0.01
I1007 19:10:23.091817  5078 solver.cpp:218] Iteration 62600 (11.9615 iter/s, 8.36018s/100 iters), loss = 0.00219632
I1007 19:10:23.091857  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00219575 (* 1 = 0.00219575 loss)
I1007 19:10:23.091862  5078 sgd_solver.cpp:105] Iteration 62600, lr = 0.01
I1007 19:10:31.446755  5078 solver.cpp:218] Iteration 62700 (11.9691 iter/s, 8.35487s/100 iters), loss = 0.026664
I1007 19:10:31.446795  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0266634 (* 1 = 0.0266634 loss)
I1007 19:10:31.446801  5078 sgd_solver.cpp:105] Iteration 62700, lr = 0.01
I1007 19:10:39.808490  5078 solver.cpp:218] Iteration 62800 (11.9593 iter/s, 8.36167s/100 iters), loss = 0.00774885
I1007 19:10:39.808617  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00774829 (* 1 = 0.00774829 loss)
I1007 19:10:39.808624  5078 sgd_solver.cpp:105] Iteration 62800, lr = 0.01
I1007 19:10:48.163755  5078 solver.cpp:218] Iteration 62900 (11.9687 iter/s, 8.35512s/100 iters), loss = 0.0154289
I1007 19:10:48.163795  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0154283 (* 1 = 0.0154283 loss)
I1007 19:10:48.163801  5078 sgd_solver.cpp:105] Iteration 62900, lr = 0.01
I1007 19:10:56.110684  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:10:56.445318  5078 solver.cpp:330] Iteration 63000, Testing net (#0)
I1007 19:10:58.369974  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:10:58.450446  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9161
I1007 19:10:58.450480  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.329708 (* 1 = 0.329708 loss)
I1007 19:10:58.533488  5078 solver.cpp:218] Iteration 63000 (9.64352 iter/s, 10.3697s/100 iters), loss = 0.0167313
I1007 19:10:58.533514  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0167307 (* 1 = 0.0167307 loss)
I1007 19:10:58.533521  5078 sgd_solver.cpp:105] Iteration 63000, lr = 0.01
I1007 19:11:06.884192  5078 solver.cpp:218] Iteration 63100 (11.9751 iter/s, 8.35065s/100 iters), loss = 0.0103592
I1007 19:11:06.884222  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0103586 (* 1 = 0.0103586 loss)
I1007 19:11:06.884228  5078 sgd_solver.cpp:105] Iteration 63100, lr = 0.01
I1007 19:11:15.240098  5078 solver.cpp:218] Iteration 63200 (11.9677 iter/s, 8.35584s/100 iters), loss = 0.00573752
I1007 19:11:15.240249  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00573695 (* 1 = 0.00573695 loss)
I1007 19:11:15.240257  5078 sgd_solver.cpp:105] Iteration 63200, lr = 0.01
I1007 19:11:23.590618  5078 solver.cpp:218] Iteration 63300 (11.9756 iter/s, 8.35034s/100 iters), loss = 0.0208474
I1007 19:11:23.590657  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0208469 (* 1 = 0.0208469 loss)
I1007 19:11:23.590663  5078 sgd_solver.cpp:105] Iteration 63300, lr = 0.01
I1007 19:11:31.944491  5078 solver.cpp:218] Iteration 63400 (11.9706 iter/s, 8.35381s/100 iters), loss = 0.0246616
I1007 19:11:31.944532  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.024661 (* 1 = 0.024661 loss)
I1007 19:11:31.944538  5078 sgd_solver.cpp:105] Iteration 63400, lr = 0.01
I1007 19:11:39.883628  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:11:40.217228  5078 solver.cpp:330] Iteration 63500, Testing net (#0)
I1007 19:11:42.142333  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:11:42.222762  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9137
I1007 19:11:42.222798  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.341718 (* 1 = 0.341718 loss)
I1007 19:11:42.305944  5078 solver.cpp:218] Iteration 63500 (9.65123 iter/s, 10.3614s/100 iters), loss = 0.00411075
I1007 19:11:42.305976  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00411018 (* 1 = 0.00411018 loss)
I1007 19:11:42.305984  5078 sgd_solver.cpp:105] Iteration 63500, lr = 0.01
I1007 19:11:50.667763  5078 solver.cpp:218] Iteration 63600 (11.9592 iter/s, 8.36176s/100 iters), loss = 0.0247336
I1007 19:11:50.667887  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0247331 (* 1 = 0.0247331 loss)
I1007 19:11:50.667894  5078 sgd_solver.cpp:105] Iteration 63600, lr = 0.01
I1007 19:11:59.024374  5078 solver.cpp:218] Iteration 63700 (11.9668 iter/s, 8.35646s/100 iters), loss = 0.00411036
I1007 19:11:59.024405  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00410978 (* 1 = 0.00410978 loss)
I1007 19:11:59.024410  5078 sgd_solver.cpp:105] Iteration 63700, lr = 0.01
I1007 19:12:07.384747  5078 solver.cpp:218] Iteration 63800 (11.9613 iter/s, 8.36031s/100 iters), loss = 0.00968232
I1007 19:12:07.384788  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00968174 (* 1 = 0.00968174 loss)
I1007 19:12:07.384793  5078 sgd_solver.cpp:105] Iteration 63800, lr = 0.01
I1007 19:12:15.736995  5078 solver.cpp:218] Iteration 63900 (11.9729 iter/s, 8.35218s/100 iters), loss = 0.00230838
I1007 19:12:15.737025  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00230779 (* 1 = 0.00230779 loss)
I1007 19:12:15.737031  5078 sgd_solver.cpp:105] Iteration 63900, lr = 0.01
I1007 19:12:23.683459  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:12:24.018052  5078 solver.cpp:330] Iteration 64000, Testing net (#0)
I1007 19:12:25.942368  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:12:26.022969  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9102
I1007 19:12:26.023005  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.364473 (* 1 = 0.364473 loss)
I1007 19:12:26.106547  5078 solver.cpp:218] Iteration 64000 (9.64367 iter/s, 10.3695s/100 iters), loss = 0.00846905
I1007 19:12:26.106575  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00846847 (* 1 = 0.00846847 loss)
I1007 19:12:26.106581  5078 sgd_solver.cpp:105] Iteration 64000, lr = 0.01
I1007 19:12:34.455916  5078 solver.cpp:218] Iteration 64100 (11.977 iter/s, 8.34931s/100 iters), loss = 0.0136523
I1007 19:12:34.455956  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0136517 (* 1 = 0.0136517 loss)
I1007 19:12:34.455962  5078 sgd_solver.cpp:105] Iteration 64100, lr = 0.01
I1007 19:12:42.808742  5078 solver.cpp:218] Iteration 64200 (11.9721 iter/s, 8.35276s/100 iters), loss = 0.0136666
I1007 19:12:42.808780  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.013666 (* 1 = 0.013666 loss)
I1007 19:12:42.808786  5078 sgd_solver.cpp:105] Iteration 64200, lr = 0.01
I1007 19:12:51.155709  5078 solver.cpp:218] Iteration 64300 (11.9805 iter/s, 8.3469s/100 iters), loss = 0.00833658
I1007 19:12:51.155738  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.008336 (* 1 = 0.008336 loss)
I1007 19:12:51.155745  5078 sgd_solver.cpp:105] Iteration 64300, lr = 0.01
I1007 19:12:59.505314  5078 solver.cpp:218] Iteration 64400 (11.9767 iter/s, 8.34955s/100 iters), loss = 0.0035179
I1007 19:12:59.505430  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00351732 (* 1 = 0.00351732 loss)
I1007 19:12:59.505447  5078 sgd_solver.cpp:105] Iteration 64400, lr = 0.01
I1007 19:13:07.437716  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:13:07.770612  5078 solver.cpp:330] Iteration 64500, Testing net (#0)
I1007 19:13:09.696148  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:13:09.777091  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9107
I1007 19:13:09.777127  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.352639 (* 1 = 0.352639 loss)
I1007 19:13:09.860467  5078 solver.cpp:218] Iteration 64500 (9.65716 iter/s, 10.355s/100 iters), loss = 0.00291979
I1007 19:13:09.860497  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0029192 (* 1 = 0.0029192 loss)
I1007 19:13:09.860503  5078 sgd_solver.cpp:105] Iteration 64500, lr = 0.01
I1007 19:13:18.212879  5078 solver.cpp:218] Iteration 64600 (11.9727 iter/s, 8.35235s/100 iters), loss = 0.00978548
I1007 19:13:18.212908  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00978489 (* 1 = 0.00978489 loss)
I1007 19:13:18.212924  5078 sgd_solver.cpp:105] Iteration 64600, lr = 0.01
I1007 19:13:26.555279  5078 solver.cpp:218] Iteration 64700 (11.987 iter/s, 8.34234s/100 iters), loss = 0.0052583
I1007 19:13:26.555310  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00525772 (* 1 = 0.00525772 loss)
I1007 19:13:26.555325  5078 sgd_solver.cpp:105] Iteration 64700, lr = 0.01
I1007 19:13:34.907977  5078 solver.cpp:218] Iteration 64800 (11.9723 iter/s, 8.35264s/100 iters), loss = 0.00842246
I1007 19:13:34.908107  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00842187 (* 1 = 0.00842187 loss)
I1007 19:13:34.908114  5078 sgd_solver.cpp:105] Iteration 64800, lr = 0.01
I1007 19:13:43.258069  5078 solver.cpp:218] Iteration 64900 (11.9761 iter/s, 8.34994s/100 iters), loss = 0.00228284
I1007 19:13:43.258100  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00228226 (* 1 = 0.00228226 loss)
I1007 19:13:43.258106  5078 sgd_solver.cpp:105] Iteration 64900, lr = 0.01
I1007 19:13:51.196823  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:13:51.531779  5078 solver.cpp:330] Iteration 65000, Testing net (#0)
I1007 19:13:53.457713  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:13:53.538337  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9148
I1007 19:13:53.538372  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.353637 (* 1 = 0.353637 loss)
I1007 19:13:53.621592  5078 solver.cpp:218] Iteration 65000 (9.64929 iter/s, 10.3635s/100 iters), loss = 0.00132628
I1007 19:13:53.621618  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00132569 (* 1 = 0.00132569 loss)
I1007 19:13:53.621624  5078 sgd_solver.cpp:105] Iteration 65000, lr = 0.01
I1007 19:14:01.979250  5078 solver.cpp:218] Iteration 65100 (11.9651 iter/s, 8.35761s/100 iters), loss = 0.00477316
I1007 19:14:01.979279  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00477257 (* 1 = 0.00477257 loss)
I1007 19:14:01.979285  5078 sgd_solver.cpp:105] Iteration 65100, lr = 0.01
I1007 19:14:10.336846  5078 solver.cpp:218] Iteration 65200 (11.9652 iter/s, 8.35754s/100 iters), loss = 0.00771212
I1007 19:14:10.336958  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00771153 (* 1 = 0.00771153 loss)
I1007 19:14:10.336966  5078 sgd_solver.cpp:105] Iteration 65200, lr = 0.01
I1007 19:14:18.692091  5078 solver.cpp:218] Iteration 65300 (11.9687 iter/s, 8.35511s/100 iters), loss = 0.00495298
I1007 19:14:18.692121  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00495238 (* 1 = 0.00495238 loss)
I1007 19:14:18.692126  5078 sgd_solver.cpp:105] Iteration 65300, lr = 0.01
I1007 19:14:27.052110  5078 solver.cpp:218] Iteration 65400 (11.9618 iter/s, 8.35996s/100 iters), loss = 0.00561268
I1007 19:14:27.052150  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00561208 (* 1 = 0.00561208 loss)
I1007 19:14:27.052155  5078 sgd_solver.cpp:105] Iteration 65400, lr = 0.01
I1007 19:14:34.990615  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:14:35.324923  5078 solver.cpp:330] Iteration 65500, Testing net (#0)
I1007 19:14:37.251910  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:14:37.332840  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.909
I1007 19:14:37.332876  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.381788 (* 1 = 0.381788 loss)
I1007 19:14:37.416574  5078 solver.cpp:218] Iteration 65500 (9.64842 iter/s, 10.3644s/100 iters), loss = 0.0066439
I1007 19:14:37.416601  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0066433 (* 1 = 0.0066433 loss)
I1007 19:14:37.416607  5078 sgd_solver.cpp:105] Iteration 65500, lr = 0.01
I1007 19:14:45.778959  5078 solver.cpp:218] Iteration 65600 (11.9584 iter/s, 8.36233s/100 iters), loss = 0.0171104
I1007 19:14:45.779076  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0171098 (* 1 = 0.0171098 loss)
I1007 19:14:45.779083  5078 sgd_solver.cpp:105] Iteration 65600, lr = 0.01
I1007 19:14:54.128759  5078 solver.cpp:218] Iteration 65700 (11.9765 iter/s, 8.34966s/100 iters), loss = 0.0131038
I1007 19:14:54.128788  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0131031 (* 1 = 0.0131031 loss)
I1007 19:14:54.128793  5078 sgd_solver.cpp:105] Iteration 65700, lr = 0.01
I1007 19:15:02.493492  5078 solver.cpp:218] Iteration 65800 (11.955 iter/s, 8.36468s/100 iters), loss = 0.00284036
I1007 19:15:02.493532  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00283976 (* 1 = 0.00283976 loss)
I1007 19:15:02.493538  5078 sgd_solver.cpp:105] Iteration 65800, lr = 0.01
I1007 19:15:10.843227  5078 solver.cpp:218] Iteration 65900 (11.9765 iter/s, 8.34967s/100 iters), loss = 0.0112072
I1007 19:15:10.843255  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0112066 (* 1 = 0.0112066 loss)
I1007 19:15:10.843261  5078 sgd_solver.cpp:105] Iteration 65900, lr = 0.01
I1007 19:15:18.788921  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:15:19.123072  5078 solver.cpp:330] Iteration 66000, Testing net (#0)
I1007 19:15:21.048743  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:15:21.129040  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9147
I1007 19:15:21.129076  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.355889 (* 1 = 0.355889 loss)
I1007 19:15:21.212702  5078 solver.cpp:218] Iteration 66000 (9.64374 iter/s, 10.3694s/100 iters), loss = 0.0202924
I1007 19:15:21.212729  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0202918 (* 1 = 0.0202918 loss)
I1007 19:15:21.212735  5078 sgd_solver.cpp:105] Iteration 66000, lr = 0.01
I1007 19:15:29.565416  5078 solver.cpp:218] Iteration 66100 (11.9722 iter/s, 8.35266s/100 iters), loss = 0.0064681
I1007 19:15:29.565457  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00646751 (* 1 = 0.00646751 loss)
I1007 19:15:29.565464  5078 sgd_solver.cpp:105] Iteration 66100, lr = 0.01
I1007 19:15:37.919858  5078 solver.cpp:218] Iteration 66200 (11.9698 iter/s, 8.35437s/100 iters), loss = 0.00761691
I1007 19:15:37.919898  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00761632 (* 1 = 0.00761632 loss)
I1007 19:15:37.919904  5078 sgd_solver.cpp:105] Iteration 66200, lr = 0.01
I1007 19:15:46.268115  5078 solver.cpp:218] Iteration 66300 (11.9786 iter/s, 8.34819s/100 iters), loss = 0.00110047
I1007 19:15:46.268146  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00109987 (* 1 = 0.00109987 loss)
I1007 19:15:46.268151  5078 sgd_solver.cpp:105] Iteration 66300, lr = 0.01
I1007 19:15:54.620813  5078 solver.cpp:218] Iteration 66400 (11.9723 iter/s, 8.35264s/100 iters), loss = 0.0054966
I1007 19:15:54.620932  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.005496 (* 1 = 0.005496 loss)
I1007 19:15:54.620950  5078 sgd_solver.cpp:105] Iteration 66400, lr = 0.01
I1007 19:16:02.558297  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:16:02.892838  5078 solver.cpp:330] Iteration 66500, Testing net (#0)
I1007 19:16:04.817911  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:16:04.898435  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9117
I1007 19:16:04.898469  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.357426 (* 1 = 0.357426 loss)
I1007 19:16:04.982102  5078 solver.cpp:218] Iteration 66500 (9.65144 iter/s, 10.3611s/100 iters), loss = 0.0146798
I1007 19:16:04.982133  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0146792 (* 1 = 0.0146792 loss)
I1007 19:16:04.982141  5078 sgd_solver.cpp:105] Iteration 66500, lr = 0.01
I1007 19:16:13.342083  5078 solver.cpp:218] Iteration 66600 (11.9618 iter/s, 8.35992s/100 iters), loss = 0.0280639
I1007 19:16:13.342113  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0280633 (* 1 = 0.0280633 loss)
I1007 19:16:13.342118  5078 sgd_solver.cpp:105] Iteration 66600, lr = 0.01
I1007 19:16:21.694329  5078 solver.cpp:218] Iteration 66700 (11.9729 iter/s, 8.35219s/100 iters), loss = 0.00690511
I1007 19:16:21.694370  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0069045 (* 1 = 0.0069045 loss)
I1007 19:16:21.694375  5078 sgd_solver.cpp:105] Iteration 66700, lr = 0.01
I1007 19:16:30.052716  5078 solver.cpp:218] Iteration 66800 (11.9641 iter/s, 8.35832s/100 iters), loss = 0.00697971
I1007 19:16:30.052837  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00697909 (* 1 = 0.00697909 loss)
I1007 19:16:30.052845  5078 sgd_solver.cpp:105] Iteration 66800, lr = 0.01
I1007 19:16:38.407394  5078 solver.cpp:218] Iteration 66900 (11.9696 iter/s, 8.35453s/100 iters), loss = 0.0284837
I1007 19:16:38.407425  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0284831 (* 1 = 0.0284831 loss)
I1007 19:16:38.407431  5078 sgd_solver.cpp:105] Iteration 66900, lr = 0.01
I1007 19:16:46.350242  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:16:46.684006  5078 solver.cpp:330] Iteration 67000, Testing net (#0)
I1007 19:16:48.608665  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:16:48.689353  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.906
I1007 19:16:48.689379  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.388863 (* 1 = 0.388863 loss)
I1007 19:16:48.772094  5078 solver.cpp:218] Iteration 67000 (9.64819 iter/s, 10.3646s/100 iters), loss = 0.00362315
I1007 19:16:48.772119  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00362253 (* 1 = 0.00362253 loss)
I1007 19:16:48.772126  5078 sgd_solver.cpp:105] Iteration 67000, lr = 0.01
I1007 19:16:57.115694  5078 solver.cpp:218] Iteration 67100 (11.9853 iter/s, 8.34355s/100 iters), loss = 0.0215327
I1007 19:16:57.115723  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0215321 (* 1 = 0.0215321 loss)
I1007 19:16:57.115728  5078 sgd_solver.cpp:105] Iteration 67100, lr = 0.01
I1007 19:17:05.463666  5078 solver.cpp:218] Iteration 67200 (11.979 iter/s, 8.34792s/100 iters), loss = 0.00397099
I1007 19:17:05.463807  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00397037 (* 1 = 0.00397037 loss)
I1007 19:17:05.463814  5078 sgd_solver.cpp:105] Iteration 67200, lr = 0.01
I1007 19:17:13.806680  5078 solver.cpp:218] Iteration 67300 (11.9863 iter/s, 8.34285s/100 iters), loss = 0.0043379
I1007 19:17:13.806720  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00433728 (* 1 = 0.00433728 loss)
I1007 19:17:13.806726  5078 sgd_solver.cpp:105] Iteration 67300, lr = 0.01
I1007 19:17:22.154139  5078 solver.cpp:218] Iteration 67400 (11.9798 iter/s, 8.34739s/100 iters), loss = 0.00488433
I1007 19:17:22.154168  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0048837 (* 1 = 0.0048837 loss)
I1007 19:17:22.154173  5078 sgd_solver.cpp:105] Iteration 67400, lr = 0.01
I1007 19:17:30.091595  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:17:30.426345  5078 solver.cpp:330] Iteration 67500, Testing net (#0)
I1007 19:17:32.350420  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:17:32.430871  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9048
I1007 19:17:32.430904  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.374892 (* 1 = 0.374892 loss)
I1007 19:17:32.514780  5078 solver.cpp:218] Iteration 67500 (9.65197 iter/s, 10.3606s/100 iters), loss = 0.00745092
I1007 19:17:32.514807  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00745029 (* 1 = 0.00745029 loss)
I1007 19:17:32.514814  5078 sgd_solver.cpp:105] Iteration 67500, lr = 0.01
I1007 19:17:40.871949  5078 solver.cpp:218] Iteration 67600 (11.9659 iter/s, 8.35711s/100 iters), loss = 0.0026719
I1007 19:17:40.872071  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00267127 (* 1 = 0.00267127 loss)
I1007 19:17:40.872087  5078 sgd_solver.cpp:105] Iteration 67600, lr = 0.01
I1007 19:17:49.228072  5078 solver.cpp:218] Iteration 67700 (11.9675 iter/s, 8.35597s/100 iters), loss = 0.0104572
I1007 19:17:49.228103  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0104565 (* 1 = 0.0104565 loss)
I1007 19:17:49.228109  5078 sgd_solver.cpp:105] Iteration 67700, lr = 0.01
I1007 19:17:57.582160  5078 solver.cpp:218] Iteration 67800 (11.9703 iter/s, 8.35403s/100 iters), loss = 0.00751436
I1007 19:17:57.582201  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00751371 (* 1 = 0.00751371 loss)
I1007 19:17:57.582206  5078 sgd_solver.cpp:105] Iteration 67800, lr = 0.01
I1007 19:18:05.938151  5078 solver.cpp:218] Iteration 67900 (11.9676 iter/s, 8.35592s/100 iters), loss = 0.0318031
I1007 19:18:05.938190  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0318025 (* 1 = 0.0318025 loss)
I1007 19:18:05.938196  5078 sgd_solver.cpp:105] Iteration 67900, lr = 0.01
I1007 19:18:13.884342  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:18:14.220213  5078 solver.cpp:330] Iteration 68000, Testing net (#0)
I1007 19:18:16.144917  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:18:16.225015  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9133
I1007 19:18:16.225041  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.369995 (* 1 = 0.369995 loss)
I1007 19:18:16.308279  5078 solver.cpp:218] Iteration 68000 (9.64315 iter/s, 10.3701s/100 iters), loss = 0.00792085
I1007 19:18:16.308310  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00792021 (* 1 = 0.00792021 loss)
I1007 19:18:16.308315  5078 sgd_solver.cpp:105] Iteration 68000, lr = 0.01
I1007 19:18:24.652130  5078 solver.cpp:218] Iteration 68100 (11.985 iter/s, 8.34379s/100 iters), loss = 0.0140999
I1007 19:18:24.652160  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0140993 (* 1 = 0.0140993 loss)
I1007 19:18:24.652166  5078 sgd_solver.cpp:105] Iteration 68100, lr = 0.01
I1007 19:18:33.004437  5078 solver.cpp:218] Iteration 68200 (11.9728 iter/s, 8.35225s/100 iters), loss = 0.00200537
I1007 19:18:33.004468  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00200472 (* 1 = 0.00200472 loss)
I1007 19:18:33.004474  5078 sgd_solver.cpp:105] Iteration 68200, lr = 0.01
I1007 19:18:41.357947  5078 solver.cpp:218] Iteration 68300 (11.9711 iter/s, 8.35345s/100 iters), loss = 0.0222972
I1007 19:18:41.357987  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0222966 (* 1 = 0.0222966 loss)
I1007 19:18:41.357993  5078 sgd_solver.cpp:105] Iteration 68300, lr = 0.01
I1007 19:18:49.711879  5078 solver.cpp:218] Iteration 68400 (11.9705 iter/s, 8.35387s/100 iters), loss = 0.00907315
I1007 19:18:49.711992  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0090725 (* 1 = 0.0090725 loss)
I1007 19:18:49.712008  5078 sgd_solver.cpp:105] Iteration 68400, lr = 0.01
I1007 19:18:57.652375  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:18:57.986915  5078 solver.cpp:330] Iteration 68500, Testing net (#0)
I1007 19:18:59.911654  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:18:59.991636  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9099
I1007 19:18:59.991662  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.374172 (* 1 = 0.374172 loss)
I1007 19:19:00.075317  5078 solver.cpp:218] Iteration 68500 (9.64944 iter/s, 10.3633s/100 iters), loss = 0.00516033
I1007 19:19:00.075347  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00515967 (* 1 = 0.00515967 loss)
I1007 19:19:00.075353  5078 sgd_solver.cpp:105] Iteration 68500, lr = 0.01
I1007 19:19:08.434712  5078 solver.cpp:218] Iteration 68600 (11.9627 iter/s, 8.35933s/100 iters), loss = 0.00347701
I1007 19:19:08.434744  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00347636 (* 1 = 0.00347636 loss)
I1007 19:19:08.434751  5078 sgd_solver.cpp:105] Iteration 68600, lr = 0.01
I1007 19:19:16.787699  5078 solver.cpp:218] Iteration 68700 (11.9718 iter/s, 8.35293s/100 iters), loss = 0.0110004
I1007 19:19:16.787739  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0109997 (* 1 = 0.0109997 loss)
I1007 19:19:16.787745  5078 sgd_solver.cpp:105] Iteration 68700, lr = 0.01
I1007 19:19:25.145081  5078 solver.cpp:218] Iteration 68800 (11.9656 iter/s, 8.35731s/100 iters), loss = 0.00496401
I1007 19:19:25.145200  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00496336 (* 1 = 0.00496336 loss)
I1007 19:19:25.145206  5078 sgd_solver.cpp:105] Iteration 68800, lr = 0.01
I1007 19:19:33.498201  5078 solver.cpp:218] Iteration 68900 (11.9718 iter/s, 8.35299s/100 iters), loss = 0.0201742
I1007 19:19:33.498231  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0201735 (* 1 = 0.0201735 loss)
I1007 19:19:33.498237  5078 sgd_solver.cpp:105] Iteration 68900, lr = 0.01
I1007 19:19:41.437997  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:19:41.772692  5078 solver.cpp:330] Iteration 69000, Testing net (#0)
I1007 19:19:43.697473  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:19:43.778427  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9153
I1007 19:19:43.778453  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.346525 (* 1 = 0.346525 loss)
I1007 19:19:43.861702  5078 solver.cpp:218] Iteration 69000 (9.64931 iter/s, 10.3634s/100 iters), loss = 0.0166117
I1007 19:19:43.861728  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0166111 (* 1 = 0.0166111 loss)
I1007 19:19:43.861734  5078 sgd_solver.cpp:105] Iteration 69000, lr = 0.01
I1007 19:19:52.202368  5078 solver.cpp:218] Iteration 69100 (11.9895 iter/s, 8.34061s/100 iters), loss = 0.0190854
I1007 19:19:52.202404  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0190848 (* 1 = 0.0190848 loss)
I1007 19:19:52.202411  5078 sgd_solver.cpp:105] Iteration 69100, lr = 0.01
I1007 19:20:00.550838  5078 solver.cpp:218] Iteration 69200 (11.9783 iter/s, 8.34841s/100 iters), loss = 0.00252488
I1007 19:20:00.550966  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00252423 (* 1 = 0.00252423 loss)
I1007 19:20:00.550982  5078 sgd_solver.cpp:105] Iteration 69200, lr = 0.01
I1007 19:20:08.904881  5078 solver.cpp:218] Iteration 69300 (11.9705 iter/s, 8.35389s/100 iters), loss = 0.00707379
I1007 19:20:08.904922  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00707316 (* 1 = 0.00707316 loss)
I1007 19:20:08.904927  5078 sgd_solver.cpp:105] Iteration 69300, lr = 0.01
I1007 19:20:17.261976  5078 solver.cpp:218] Iteration 69400 (11.966 iter/s, 8.35703s/100 iters), loss = 0.0189399
I1007 19:20:17.262017  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0189393 (* 1 = 0.0189393 loss)
I1007 19:20:17.262022  5078 sgd_solver.cpp:105] Iteration 69400, lr = 0.01
I1007 19:20:25.198047  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:20:25.533059  5078 solver.cpp:330] Iteration 69500, Testing net (#0)
I1007 19:20:27.458268  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:20:27.538820  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9178
I1007 19:20:27.538856  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.353711 (* 1 = 0.353711 loss)
I1007 19:20:27.622118  5078 solver.cpp:218] Iteration 69500 (9.65244 iter/s, 10.3601s/100 iters), loss = 0.00332499
I1007 19:20:27.622143  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00332436 (* 1 = 0.00332436 loss)
I1007 19:20:27.622149  5078 sgd_solver.cpp:105] Iteration 69500, lr = 0.01
I1007 19:20:35.978052  5078 solver.cpp:218] Iteration 69600 (11.9676 iter/s, 8.35588s/100 iters), loss = 0.0110329
I1007 19:20:35.978153  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0110322 (* 1 = 0.0110322 loss)
I1007 19:20:35.978170  5078 sgd_solver.cpp:105] Iteration 69600, lr = 0.01
I1007 19:20:44.326709  5078 solver.cpp:218] Iteration 69700 (11.9782 iter/s, 8.34853s/100 iters), loss = 0.0103416
I1007 19:20:44.326738  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0103409 (* 1 = 0.0103409 loss)
I1007 19:20:44.326745  5078 sgd_solver.cpp:105] Iteration 69700, lr = 0.01
I1007 19:20:52.683640  5078 solver.cpp:218] Iteration 69800 (11.9662 iter/s, 8.35688s/100 iters), loss = 0.00335281
I1007 19:20:52.683670  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00335219 (* 1 = 0.00335219 loss)
I1007 19:20:52.683676  5078 sgd_solver.cpp:105] Iteration 69800, lr = 0.01
I1007 19:21:01.035573  5078 solver.cpp:218] Iteration 69900 (11.9734 iter/s, 8.35187s/100 iters), loss = 0.0116853
I1007 19:21:01.035612  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0116847 (* 1 = 0.0116847 loss)
I1007 19:21:01.035619  5078 sgd_solver.cpp:105] Iteration 69900, lr = 0.01
I1007 19:21:08.977459  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:21:09.313022  5078 solver.cpp:330] Iteration 70000, Testing net (#0)
I1007 19:21:11.239008  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:21:11.318697  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9117
I1007 19:21:11.318734  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.372277 (* 1 = 0.372277 loss)
I1007 19:21:11.401927  5078 solver.cpp:218] Iteration 70000 (9.64666 iter/s, 10.3663s/100 iters), loss = 0.0026204
I1007 19:21:11.401952  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00261977 (* 1 = 0.00261977 loss)
I1007 19:21:11.401959  5078 sgd_solver.cpp:105] Iteration 70000, lr = 0.01
I1007 19:21:19.745719  5078 solver.cpp:218] Iteration 70100 (11.985 iter/s, 8.34374s/100 iters), loss = 0.0022962
I1007 19:21:19.745760  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00229557 (* 1 = 0.00229557 loss)
I1007 19:21:19.745766  5078 sgd_solver.cpp:105] Iteration 70100, lr = 0.01
I1007 19:21:28.097949  5078 solver.cpp:218] Iteration 70200 (11.9729 iter/s, 8.35216s/100 iters), loss = 0.00493449
I1007 19:21:28.097988  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00493387 (* 1 = 0.00493387 loss)
I1007 19:21:28.097995  5078 sgd_solver.cpp:105] Iteration 70200, lr = 0.01
I1007 19:21:36.443951  5078 solver.cpp:218] Iteration 70300 (11.9819 iter/s, 8.34594s/100 iters), loss = 0.0204433
I1007 19:21:36.443981  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0204427 (* 1 = 0.0204427 loss)
I1007 19:21:36.443987  5078 sgd_solver.cpp:105] Iteration 70300, lr = 0.01
I1007 19:21:44.796283  5078 solver.cpp:218] Iteration 70400 (11.9728 iter/s, 8.35227s/100 iters), loss = 0.000836364
I1007 19:21:44.796397  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000835734 (* 1 = 0.000835734 loss)
I1007 19:21:44.796413  5078 sgd_solver.cpp:105] Iteration 70400, lr = 0.01
I1007 19:21:52.731542  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:21:53.066454  5078 solver.cpp:330] Iteration 70500, Testing net (#0)
I1007 19:21:54.990973  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:21:55.071418  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9201
I1007 19:21:55.071441  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.353363 (* 1 = 0.353363 loss)
I1007 19:21:55.155004  5078 solver.cpp:218] Iteration 70500 (9.65383 iter/s, 10.3586s/100 iters), loss = 0.00190843
I1007 19:21:55.155031  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00190779 (* 1 = 0.00190779 loss)
I1007 19:21:55.155037  5078 sgd_solver.cpp:105] Iteration 70500, lr = 0.01
I1007 19:22:03.515674  5078 solver.cpp:218] Iteration 70600 (11.9608 iter/s, 8.36061s/100 iters), loss = 0.0196209
I1007 19:22:03.515714  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0196203 (* 1 = 0.0196203 loss)
I1007 19:22:03.515720  5078 sgd_solver.cpp:105] Iteration 70600, lr = 0.01
I1007 19:22:11.865336  5078 solver.cpp:218] Iteration 70700 (11.9766 iter/s, 8.34959s/100 iters), loss = 0.0211075
I1007 19:22:11.865376  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0211069 (* 1 = 0.0211069 loss)
I1007 19:22:11.865381  5078 sgd_solver.cpp:105] Iteration 70700, lr = 0.01
I1007 19:22:20.222558  5078 solver.cpp:218] Iteration 70800 (11.9658 iter/s, 8.35715s/100 iters), loss = 0.00679518
I1007 19:22:20.222685  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00679456 (* 1 = 0.00679456 loss)
I1007 19:22:20.222692  5078 sgd_solver.cpp:105] Iteration 70800, lr = 0.01
I1007 19:22:28.574203  5078 solver.cpp:218] Iteration 70900 (11.9739 iter/s, 8.35149s/100 iters), loss = 0.00103685
I1007 19:22:28.574245  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00103624 (* 1 = 0.00103624 loss)
I1007 19:22:28.574251  5078 sgd_solver.cpp:105] Iteration 70900, lr = 0.01
I1007 19:22:36.516834  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:22:36.851609  5078 solver.cpp:330] Iteration 71000, Testing net (#0)
I1007 19:22:38.775789  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:22:38.856186  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9071
I1007 19:22:38.856221  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.373903 (* 1 = 0.373903 loss)
I1007 19:22:38.939512  5078 solver.cpp:218] Iteration 71000 (9.64763 iter/s, 10.3652s/100 iters), loss = 0.00595139
I1007 19:22:38.939537  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00595077 (* 1 = 0.00595077 loss)
I1007 19:22:38.939543  5078 sgd_solver.cpp:105] Iteration 71000, lr = 0.01
I1007 19:22:47.296113  5078 solver.cpp:218] Iteration 71100 (11.9667 iter/s, 8.35655s/100 iters), loss = 0.00515811
I1007 19:22:47.296144  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0051575 (* 1 = 0.0051575 loss)
I1007 19:22:47.296149  5078 sgd_solver.cpp:105] Iteration 71100, lr = 0.01
I1007 19:22:55.656759  5078 solver.cpp:218] Iteration 71200 (11.9609 iter/s, 8.36059s/100 iters), loss = 0.0231088
I1007 19:22:55.656898  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0231082 (* 1 = 0.0231082 loss)
I1007 19:22:55.656905  5078 sgd_solver.cpp:105] Iteration 71200, lr = 0.01
I1007 19:23:04.020030  5078 solver.cpp:218] Iteration 71300 (11.9573 iter/s, 8.36312s/100 iters), loss = 0.0165042
I1007 19:23:04.020071  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0165036 (* 1 = 0.0165036 loss)
I1007 19:23:04.020076  5078 sgd_solver.cpp:105] Iteration 71300, lr = 0.01
I1007 19:23:12.378093  5078 solver.cpp:218] Iteration 71400 (11.9646 iter/s, 8.358s/100 iters), loss = 0.0134901
I1007 19:23:12.378134  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0134894 (* 1 = 0.0134894 loss)
I1007 19:23:12.378139  5078 sgd_solver.cpp:105] Iteration 71400, lr = 0.01
I1007 19:23:20.325078  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:23:20.661875  5078 solver.cpp:330] Iteration 71500, Testing net (#0)
I1007 19:23:22.586706  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:23:22.667053  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9107
I1007 19:23:22.667078  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.357464 (* 1 = 0.357464 loss)
I1007 19:23:22.750886  5078 solver.cpp:218] Iteration 71500 (9.64067 iter/s, 10.3727s/100 iters), loss = 0.0653604
I1007 19:23:22.750916  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0653598 (* 1 = 0.0653598 loss)
I1007 19:23:22.750922  5078 sgd_solver.cpp:105] Iteration 71500, lr = 0.01
I1007 19:23:31.104507  5078 solver.cpp:218] Iteration 71600 (11.9709 iter/s, 8.35356s/100 iters), loss = 0.00829212
I1007 19:23:31.104601  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00829148 (* 1 = 0.00829148 loss)
I1007 19:23:31.104619  5078 sgd_solver.cpp:105] Iteration 71600, lr = 0.01
I1007 19:23:39.451027  5078 solver.cpp:218] Iteration 71700 (11.9812 iter/s, 8.3464s/100 iters), loss = 0.00984581
I1007 19:23:39.451057  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00984517 (* 1 = 0.00984517 loss)
I1007 19:23:39.451063  5078 sgd_solver.cpp:105] Iteration 71700, lr = 0.01
I1007 19:23:47.806535  5078 solver.cpp:218] Iteration 71800 (11.9682 iter/s, 8.35545s/100 iters), loss = 0.00678964
I1007 19:23:47.806576  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00678901 (* 1 = 0.00678901 loss)
I1007 19:23:47.806581  5078 sgd_solver.cpp:105] Iteration 71800, lr = 0.01
I1007 19:23:56.156893  5078 solver.cpp:218] Iteration 71900 (11.9756 iter/s, 8.35029s/100 iters), loss = 0.015572
I1007 19:23:56.156934  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0155714 (* 1 = 0.0155714 loss)
I1007 19:23:56.156939  5078 sgd_solver.cpp:105] Iteration 71900, lr = 0.01
I1007 19:24:04.097297  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:24:04.430910  5078 solver.cpp:330] Iteration 72000, Testing net (#0)
I1007 19:24:06.356117  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:24:06.437120  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9113
I1007 19:24:06.437156  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.370779 (* 1 = 0.370779 loss)
I1007 19:24:06.520104  5078 solver.cpp:218] Iteration 72000 (9.64958 iter/s, 10.3631s/100 iters), loss = 0.00669827
I1007 19:24:06.520130  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00669764 (* 1 = 0.00669764 loss)
I1007 19:24:06.520138  5078 sgd_solver.cpp:105] Iteration 72000, lr = 0.01
I1007 19:24:14.871577  5078 solver.cpp:218] Iteration 72100 (11.974 iter/s, 8.35142s/100 iters), loss = 0.00313653
I1007 19:24:14.871616  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0031359 (* 1 = 0.0031359 loss)
I1007 19:24:14.871623  5078 sgd_solver.cpp:105] Iteration 72100, lr = 0.01
I1007 19:24:23.226512  5078 solver.cpp:218] Iteration 72200 (11.9691 iter/s, 8.35487s/100 iters), loss = 0.0023508
I1007 19:24:23.226552  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00235017 (* 1 = 0.00235017 loss)
I1007 19:24:23.226557  5078 sgd_solver.cpp:105] Iteration 72200, lr = 0.01
I1007 19:24:31.579071  5078 solver.cpp:218] Iteration 72300 (11.9725 iter/s, 8.35249s/100 iters), loss = 0.00471227
I1007 19:24:31.579110  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00471165 (* 1 = 0.00471165 loss)
I1007 19:24:31.579115  5078 sgd_solver.cpp:105] Iteration 72300, lr = 0.01
I1007 19:24:39.938541  5078 solver.cpp:218] Iteration 72400 (11.9626 iter/s, 8.3594s/100 iters), loss = 0.0101059
I1007 19:24:39.938650  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0101053 (* 1 = 0.0101053 loss)
I1007 19:24:39.938657  5078 sgd_solver.cpp:105] Iteration 72400, lr = 0.01
I1007 19:24:47.880658  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:24:48.215950  5078 solver.cpp:330] Iteration 72500, Testing net (#0)
I1007 19:24:50.142215  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:24:50.222750  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9141
I1007 19:24:50.222787  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.347883 (* 1 = 0.347883 loss)
I1007 19:24:50.306489  5078 solver.cpp:218] Iteration 72500 (9.64524 iter/s, 10.3678s/100 iters), loss = 0.00273475
I1007 19:24:50.306519  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00273412 (* 1 = 0.00273412 loss)
I1007 19:24:50.306525  5078 sgd_solver.cpp:105] Iteration 72500, lr = 0.01
I1007 19:24:58.663547  5078 solver.cpp:218] Iteration 72600 (11.966 iter/s, 8.357s/100 iters), loss = 0.00685495
I1007 19:24:58.663586  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00685431 (* 1 = 0.00685431 loss)
I1007 19:24:58.663592  5078 sgd_solver.cpp:105] Iteration 72600, lr = 0.01
I1007 19:25:07.008970  5078 solver.cpp:218] Iteration 72700 (11.9827 iter/s, 8.34536s/100 iters), loss = 0.00444883
I1007 19:25:07.009011  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0044482 (* 1 = 0.0044482 loss)
I1007 19:25:07.009016  5078 sgd_solver.cpp:105] Iteration 72700, lr = 0.01
I1007 19:25:15.362268  5078 solver.cpp:218] Iteration 72800 (11.9714 iter/s, 8.35323s/100 iters), loss = 0.0111677
I1007 19:25:15.362397  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.011167 (* 1 = 0.011167 loss)
I1007 19:25:15.362404  5078 sgd_solver.cpp:105] Iteration 72800, lr = 0.01
I1007 19:25:23.709539  5078 solver.cpp:218] Iteration 72900 (11.9802 iter/s, 8.34713s/100 iters), loss = 0.0347044
I1007 19:25:23.709580  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0347037 (* 1 = 0.0347037 loss)
I1007 19:25:23.709585  5078 sgd_solver.cpp:105] Iteration 72900, lr = 0.01
I1007 19:25:31.648005  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:25:31.982225  5078 solver.cpp:330] Iteration 73000, Testing net (#0)
I1007 19:25:33.907443  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:25:33.988641  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9167
I1007 19:25:33.988677  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.350408 (* 1 = 0.350408 loss)
I1007 19:25:34.071534  5078 solver.cpp:218] Iteration 73000 (9.65072 iter/s, 10.3619s/100 iters), loss = 0.00744922
I1007 19:25:34.071560  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00744857 (* 1 = 0.00744857 loss)
I1007 19:25:34.071568  5078 sgd_solver.cpp:105] Iteration 73000, lr = 0.01
I1007 19:25:42.420747  5078 solver.cpp:218] Iteration 73100 (11.9773 iter/s, 8.34916s/100 iters), loss = 0.0095119
I1007 19:25:42.420776  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00951126 (* 1 = 0.00951126 loss)
I1007 19:25:42.420783  5078 sgd_solver.cpp:105] Iteration 73100, lr = 0.01
I1007 19:25:50.775085  5078 solver.cpp:218] Iteration 73200 (11.9699 iter/s, 8.35428s/100 iters), loss = 0.00886471
I1007 19:25:50.775187  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00886407 (* 1 = 0.00886407 loss)
I1007 19:25:50.775193  5078 sgd_solver.cpp:105] Iteration 73200, lr = 0.01
I1007 19:25:59.122295  5078 solver.cpp:218] Iteration 73300 (11.9802 iter/s, 8.34708s/100 iters), loss = 0.0316209
I1007 19:25:59.122325  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0316203 (* 1 = 0.0316203 loss)
I1007 19:25:59.122330  5078 sgd_solver.cpp:105] Iteration 73300, lr = 0.01
I1007 19:26:07.478109  5078 solver.cpp:218] Iteration 73400 (11.9678 iter/s, 8.35576s/100 iters), loss = 0.00117457
I1007 19:26:07.478149  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00117393 (* 1 = 0.00117393 loss)
I1007 19:26:07.478155  5078 sgd_solver.cpp:105] Iteration 73400, lr = 0.01
I1007 19:26:15.413539  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:26:15.747763  5078 solver.cpp:330] Iteration 73500, Testing net (#0)
I1007 19:26:17.672616  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:26:17.753264  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9159
I1007 19:26:17.753298  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.351226 (* 1 = 0.351226 loss)
I1007 19:26:17.837090  5078 solver.cpp:218] Iteration 73500 (9.65353 iter/s, 10.3589s/100 iters), loss = 0.00282069
I1007 19:26:17.837119  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00282004 (* 1 = 0.00282004 loss)
I1007 19:26:17.837127  5078 sgd_solver.cpp:105] Iteration 73500, lr = 0.01
I1007 19:26:26.194238  5078 solver.cpp:218] Iteration 73600 (11.9659 iter/s, 8.35709s/100 iters), loss = 0.00665491
I1007 19:26:26.194373  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00665426 (* 1 = 0.00665426 loss)
I1007 19:26:26.194381  5078 sgd_solver.cpp:105] Iteration 73600, lr = 0.01
I1007 19:26:34.542503  5078 solver.cpp:218] Iteration 73700 (11.9788 iter/s, 8.34811s/100 iters), loss = 0.00535951
I1007 19:26:34.542539  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00535887 (* 1 = 0.00535887 loss)
I1007 19:26:34.542547  5078 sgd_solver.cpp:105] Iteration 73700, lr = 0.01
I1007 19:26:42.893726  5078 solver.cpp:218] Iteration 73800 (11.9744 iter/s, 8.35116s/100 iters), loss = 0.00807454
I1007 19:26:42.893756  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0080739 (* 1 = 0.0080739 loss)
I1007 19:26:42.893762  5078 sgd_solver.cpp:105] Iteration 73800, lr = 0.01
I1007 19:26:51.248144  5078 solver.cpp:218] Iteration 73900 (11.9698 iter/s, 8.35436s/100 iters), loss = 0.000878127
I1007 19:26:51.248175  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000877481 (* 1 = 0.000877481 loss)
I1007 19:26:51.248191  5078 sgd_solver.cpp:105] Iteration 73900, lr = 0.01
I1007 19:26:59.188174  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:26:59.522891  5078 solver.cpp:330] Iteration 74000, Testing net (#0)
I1007 19:27:01.448997  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:27:01.529501  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9116
I1007 19:27:01.529537  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.371808 (* 1 = 0.371808 loss)
I1007 19:27:01.612968  5078 solver.cpp:218] Iteration 74000 (9.64808 iter/s, 10.3648s/100 iters), loss = 0.0124019
I1007 19:27:01.612993  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0124012 (* 1 = 0.0124012 loss)
I1007 19:27:01.612999  5078 sgd_solver.cpp:105] Iteration 74000, lr = 0.01
I1007 19:27:09.963160  5078 solver.cpp:218] Iteration 74100 (11.9758 iter/s, 8.35014s/100 iters), loss = 0.00381901
I1007 19:27:09.963201  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00381837 (* 1 = 0.00381837 loss)
I1007 19:27:09.963207  5078 sgd_solver.cpp:105] Iteration 74100, lr = 0.01
I1007 19:27:18.324249  5078 solver.cpp:218] Iteration 74200 (11.9603 iter/s, 8.36102s/100 iters), loss = 0.0174094
I1007 19:27:18.324295  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0174087 (* 1 = 0.0174087 loss)
I1007 19:27:18.324302  5078 sgd_solver.cpp:105] Iteration 74200, lr = 0.01
I1007 19:27:26.682031  5078 solver.cpp:218] Iteration 74300 (11.965 iter/s, 8.35771s/100 iters), loss = 0.0150428
I1007 19:27:26.682060  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0150422 (* 1 = 0.0150422 loss)
I1007 19:27:26.682066  5078 sgd_solver.cpp:105] Iteration 74300, lr = 0.01
I1007 19:27:35.043115  5078 solver.cpp:218] Iteration 74400 (11.9603 iter/s, 8.36103s/100 iters), loss = 0.00135534
I1007 19:27:35.043241  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0013547 (* 1 = 0.0013547 loss)
I1007 19:27:35.043257  5078 sgd_solver.cpp:105] Iteration 74400, lr = 0.01
I1007 19:27:42.986655  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:27:43.320876  5078 solver.cpp:330] Iteration 74500, Testing net (#0)
I1007 19:27:45.246704  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:27:45.327208  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9167
I1007 19:27:45.327232  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.346248 (* 1 = 0.346248 loss)
I1007 19:27:45.410895  5078 solver.cpp:218] Iteration 74500 (9.6454 iter/s, 10.3676s/100 iters), loss = 0.0212483
I1007 19:27:45.410923  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0212477 (* 1 = 0.0212477 loss)
I1007 19:27:45.410929  5078 sgd_solver.cpp:105] Iteration 74500, lr = 0.01
I1007 19:27:53.763986  5078 solver.cpp:218] Iteration 74600 (11.9717 iter/s, 8.35303s/100 iters), loss = 0.0191216
I1007 19:27:53.764016  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.019121 (* 1 = 0.019121 loss)
I1007 19:27:53.764022  5078 sgd_solver.cpp:105] Iteration 74600, lr = 0.01
I1007 19:28:02.117048  5078 solver.cpp:218] Iteration 74700 (11.9717 iter/s, 8.35301s/100 iters), loss = 0.00598186
I1007 19:28:02.117079  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00598122 (* 1 = 0.00598122 loss)
I1007 19:28:02.117085  5078 sgd_solver.cpp:105] Iteration 74700, lr = 0.01
I1007 19:28:10.469877  5078 solver.cpp:218] Iteration 74800 (11.9721 iter/s, 8.35277s/100 iters), loss = 0.00294936
I1007 19:28:10.470001  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00294872 (* 1 = 0.00294872 loss)
I1007 19:28:10.470010  5078 sgd_solver.cpp:105] Iteration 74800, lr = 0.01
I1007 19:28:18.817747  5078 solver.cpp:218] Iteration 74900 (11.9793 iter/s, 8.34772s/100 iters), loss = 0.00394013
I1007 19:28:18.817778  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0039395 (* 1 = 0.0039395 loss)
I1007 19:28:18.817785  5078 sgd_solver.cpp:105] Iteration 74900, lr = 0.01
I1007 19:28:26.756716  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:28:27.090890  5078 solver.cpp:330] Iteration 75000, Testing net (#0)
I1007 19:28:29.016446  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:28:29.097168  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9122
I1007 19:28:29.097204  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.358445 (* 1 = 0.358445 loss)
I1007 19:28:29.180114  5078 solver.cpp:218] Iteration 75000 (9.65036 iter/s, 10.3623s/100 iters), loss = 0.0107034
I1007 19:28:29.180138  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0107028 (* 1 = 0.0107028 loss)
I1007 19:28:29.180145  5078 sgd_solver.cpp:105] Iteration 75000, lr = 0.01
I1007 19:28:37.523157  5078 solver.cpp:218] Iteration 75100 (11.9861 iter/s, 8.34299s/100 iters), loss = 0.0297
I1007 19:28:37.523200  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0296993 (* 1 = 0.0296993 loss)
I1007 19:28:37.523205  5078 sgd_solver.cpp:105] Iteration 75100, lr = 0.01
I1007 19:28:45.884579  5078 solver.cpp:218] Iteration 75200 (11.9598 iter/s, 8.36136s/100 iters), loss = 0.00252703
I1007 19:28:45.884665  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0025264 (* 1 = 0.0025264 loss)
I1007 19:28:45.884680  5078 sgd_solver.cpp:105] Iteration 75200, lr = 0.01
I1007 19:28:54.242765  5078 solver.cpp:218] Iteration 75300 (11.9645 iter/s, 8.35808s/100 iters), loss = 0.00240905
I1007 19:28:54.242807  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00240843 (* 1 = 0.00240843 loss)
I1007 19:28:54.242813  5078 sgd_solver.cpp:105] Iteration 75300, lr = 0.01
I1007 19:29:02.606462  5078 solver.cpp:218] Iteration 75400 (11.9565 iter/s, 8.36363s/100 iters), loss = 0.00699384
I1007 19:29:02.606501  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00699322 (* 1 = 0.00699322 loss)
I1007 19:29:02.606508  5078 sgd_solver.cpp:105] Iteration 75400, lr = 0.01
I1007 19:29:10.552101  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:29:10.887500  5078 solver.cpp:330] Iteration 75500, Testing net (#0)
I1007 19:29:12.813560  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:29:12.894245  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9103
I1007 19:29:12.894271  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.390765 (* 1 = 0.390765 loss)
I1007 19:29:12.978199  5078 solver.cpp:218] Iteration 75500 (9.64165 iter/s, 10.3717s/100 iters), loss = 0.00339918
I1007 19:29:12.978225  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00339856 (* 1 = 0.00339856 loss)
I1007 19:29:12.978232  5078 sgd_solver.cpp:105] Iteration 75500, lr = 0.01
I1007 19:29:21.333587  5078 solver.cpp:218] Iteration 75600 (11.9684 iter/s, 8.35534s/100 iters), loss = 0.0127958
I1007 19:29:21.333731  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0127952 (* 1 = 0.0127952 loss)
I1007 19:29:21.333739  5078 sgd_solver.cpp:105] Iteration 75600, lr = 0.01
I1007 19:29:29.686874  5078 solver.cpp:218] Iteration 75700 (11.9716 iter/s, 8.35312s/100 iters), loss = 0.00764782
I1007 19:29:29.686913  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00764719 (* 1 = 0.00764719 loss)
I1007 19:29:29.686919  5078 sgd_solver.cpp:105] Iteration 75700, lr = 0.01
I1007 19:29:38.046339  5078 solver.cpp:218] Iteration 75800 (11.9626 iter/s, 8.3594s/100 iters), loss = 0.00613112
I1007 19:29:38.046378  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00613048 (* 1 = 0.00613048 loss)
I1007 19:29:38.046385  5078 sgd_solver.cpp:105] Iteration 75800, lr = 0.01
I1007 19:29:46.405035  5078 solver.cpp:218] Iteration 75900 (11.9637 iter/s, 8.35863s/100 iters), loss = 0.00265075
I1007 19:29:46.405076  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00265012 (* 1 = 0.00265012 loss)
I1007 19:29:46.405082  5078 sgd_solver.cpp:105] Iteration 75900, lr = 0.01
I1007 19:29:54.351371  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:29:54.686152  5078 solver.cpp:330] Iteration 76000, Testing net (#0)
I1007 19:29:56.612589  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:29:56.693490  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9168
I1007 19:29:56.693526  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.361994 (* 1 = 0.361994 loss)
I1007 19:29:56.776619  5078 solver.cpp:218] Iteration 76000 (9.6418 iter/s, 10.3715s/100 iters), loss = 0.00794174
I1007 19:29:56.776645  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00794111 (* 1 = 0.00794111 loss)
I1007 19:29:56.776652  5078 sgd_solver.cpp:105] Iteration 76000, lr = 0.01
I1007 19:30:05.124542  5078 solver.cpp:218] Iteration 76100 (11.9791 iter/s, 8.34787s/100 iters), loss = 0.0250015
I1007 19:30:05.124583  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0250009 (* 1 = 0.0250009 loss)
I1007 19:30:05.124588  5078 sgd_solver.cpp:105] Iteration 76100, lr = 0.01
I1007 19:30:13.481899  5078 solver.cpp:218] Iteration 76200 (11.9656 iter/s, 8.35729s/100 iters), loss = 0.00803453
I1007 19:30:13.481940  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00803391 (* 1 = 0.00803391 loss)
I1007 19:30:13.481945  5078 sgd_solver.cpp:105] Iteration 76200, lr = 0.01
I1007 19:30:21.833498  5078 solver.cpp:218] Iteration 76300 (11.9738 iter/s, 8.35153s/100 iters), loss = 0.00444315
I1007 19:30:21.833539  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00444253 (* 1 = 0.00444253 loss)
I1007 19:30:21.833545  5078 sgd_solver.cpp:105] Iteration 76300, lr = 0.01
I1007 19:30:30.192984  5078 solver.cpp:218] Iteration 76400 (11.9625 iter/s, 8.35942s/100 iters), loss = 0.00490368
I1007 19:30:30.193104  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00490306 (* 1 = 0.00490306 loss)
I1007 19:30:30.193121  5078 sgd_solver.cpp:105] Iteration 76400, lr = 0.01
I1007 19:30:38.131966  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:30:38.466264  5078 solver.cpp:330] Iteration 76500, Testing net (#0)
I1007 19:30:40.391783  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:30:40.472514  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9155
I1007 19:30:40.472549  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.349473 (* 1 = 0.349473 loss)
I1007 19:30:40.556007  5078 solver.cpp:218] Iteration 76500 (9.64983 iter/s, 10.3629s/100 iters), loss = 0.00258368
I1007 19:30:40.556033  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00258305 (* 1 = 0.00258305 loss)
I1007 19:30:40.556041  5078 sgd_solver.cpp:105] Iteration 76500, lr = 0.01
I1007 19:30:48.911362  5078 solver.cpp:218] Iteration 76600 (11.9685 iter/s, 8.3553s/100 iters), loss = 0.0116512
I1007 19:30:48.911392  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0116506 (* 1 = 0.0116506 loss)
I1007 19:30:48.911398  5078 sgd_solver.cpp:105] Iteration 76600, lr = 0.01
I1007 19:30:57.258872  5078 solver.cpp:218] Iteration 76700 (11.9797 iter/s, 8.34745s/100 iters), loss = 0.00347123
I1007 19:30:57.258903  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00347059 (* 1 = 0.00347059 loss)
I1007 19:30:57.258909  5078 sgd_solver.cpp:105] Iteration 76700, lr = 0.01
I1007 19:31:05.616295  5078 solver.cpp:218] Iteration 76800 (11.9655 iter/s, 8.35737s/100 iters), loss = 0.012043
I1007 19:31:05.616415  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0120424 (* 1 = 0.0120424 loss)
I1007 19:31:05.616432  5078 sgd_solver.cpp:105] Iteration 76800, lr = 0.01
I1007 19:31:13.967010  5078 solver.cpp:218] Iteration 76900 (11.9752 iter/s, 8.35058s/100 iters), loss = 0.00232606
I1007 19:31:13.967039  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00232542 (* 1 = 0.00232542 loss)
I1007 19:31:13.967056  5078 sgd_solver.cpp:105] Iteration 76900, lr = 0.01
I1007 19:31:21.910233  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:31:22.244758  5078 solver.cpp:330] Iteration 77000, Testing net (#0)
I1007 19:31:24.169173  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:31:24.249688  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9091
I1007 19:31:24.249713  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.384805 (* 1 = 0.384805 loss)
I1007 19:31:24.332957  5078 solver.cpp:218] Iteration 77000 (9.64703 iter/s, 10.3659s/100 iters), loss = 0.00811455
I1007 19:31:24.332984  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0081139 (* 1 = 0.0081139 loss)
I1007 19:31:24.332990  5078 sgd_solver.cpp:105] Iteration 77000, lr = 0.01
I1007 19:31:32.681437  5078 solver.cpp:218] Iteration 77100 (11.9783 iter/s, 8.34843s/100 iters), loss = 0.00791436
I1007 19:31:32.681465  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00791372 (* 1 = 0.00791372 loss)
I1007 19:31:32.681481  5078 sgd_solver.cpp:105] Iteration 77100, lr = 0.01
I1007 19:31:41.035311  5078 solver.cpp:218] Iteration 77200 (11.9706 iter/s, 8.35382s/100 iters), loss = 0.0102717
I1007 19:31:41.035439  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0102711 (* 1 = 0.0102711 loss)
I1007 19:31:41.035445  5078 sgd_solver.cpp:105] Iteration 77200, lr = 0.01
I1007 19:31:49.388388  5078 solver.cpp:218] Iteration 77300 (11.9718 iter/s, 8.35293s/100 iters), loss = 0.00345686
I1007 19:31:49.388419  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00345623 (* 1 = 0.00345623 loss)
I1007 19:31:49.388435  5078 sgd_solver.cpp:105] Iteration 77300, lr = 0.01
I1007 19:31:57.742255  5078 solver.cpp:218] Iteration 77400 (11.9706 iter/s, 8.35381s/100 iters), loss = 0.00776218
I1007 19:31:57.742286  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00776153 (* 1 = 0.00776153 loss)
I1007 19:31:57.742301  5078 sgd_solver.cpp:105] Iteration 77400, lr = 0.01
I1007 19:32:05.678859  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:32:06.013967  5078 solver.cpp:330] Iteration 77500, Testing net (#0)
I1007 19:32:07.938375  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:32:08.019002  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9129
I1007 19:32:08.019038  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.3743 (* 1 = 0.3743 loss)
I1007 19:32:08.102831  5078 solver.cpp:218] Iteration 77500 (9.65203 iter/s, 10.3605s/100 iters), loss = 0.00248696
I1007 19:32:08.102857  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00248632 (* 1 = 0.00248632 loss)
I1007 19:32:08.102864  5078 sgd_solver.cpp:105] Iteration 77500, lr = 0.01
I1007 19:32:16.462354  5078 solver.cpp:218] Iteration 77600 (11.9625 iter/s, 8.35947s/100 iters), loss = 0.0351775
I1007 19:32:16.462456  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0351768 (* 1 = 0.0351768 loss)
I1007 19:32:16.462463  5078 sgd_solver.cpp:105] Iteration 77600, lr = 0.01
I1007 19:32:24.818733  5078 solver.cpp:218] Iteration 77700 (11.9671 iter/s, 8.35625s/100 iters), loss = 0.00374099
I1007 19:32:24.818764  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00374035 (* 1 = 0.00374035 loss)
I1007 19:32:24.818769  5078 sgd_solver.cpp:105] Iteration 77700, lr = 0.01
I1007 19:32:33.179795  5078 solver.cpp:218] Iteration 77800 (11.9603 iter/s, 8.36101s/100 iters), loss = 0.0112909
I1007 19:32:33.179826  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0112903 (* 1 = 0.0112903 loss)
I1007 19:32:33.179831  5078 sgd_solver.cpp:105] Iteration 77800, lr = 0.01
I1007 19:32:41.535562  5078 solver.cpp:218] Iteration 77900 (11.9679 iter/s, 8.35571s/100 iters), loss = 0.00459968
I1007 19:32:41.535601  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00459905 (* 1 = 0.00459905 loss)
I1007 19:32:41.535606  5078 sgd_solver.cpp:105] Iteration 77900, lr = 0.01
I1007 19:32:49.478583  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:32:49.811977  5078 solver.cpp:330] Iteration 78000, Testing net (#0)
I1007 19:32:51.738068  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:32:51.818243  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9051
I1007 19:32:51.818279  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.412949 (* 1 = 0.412949 loss)
I1007 19:32:51.901865  5078 solver.cpp:218] Iteration 78000 (9.6467 iter/s, 10.3662s/100 iters), loss = 0.00815693
I1007 19:32:51.901892  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00815629 (* 1 = 0.00815629 loss)
I1007 19:32:51.901898  5078 sgd_solver.cpp:105] Iteration 78000, lr = 0.01
I1007 19:33:00.257500  5078 solver.cpp:218] Iteration 78100 (11.968 iter/s, 8.35558s/100 iters), loss = 0.00320154
I1007 19:33:00.257544  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00320091 (* 1 = 0.00320091 loss)
I1007 19:33:00.257551  5078 sgd_solver.cpp:105] Iteration 78100, lr = 0.01
I1007 19:33:08.616843  5078 solver.cpp:218] Iteration 78200 (11.9627 iter/s, 8.35929s/100 iters), loss = 0.00492454
I1007 19:33:08.616884  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0049239 (* 1 = 0.0049239 loss)
I1007 19:33:08.616890  5078 sgd_solver.cpp:105] Iteration 78200, lr = 0.01
I1007 19:33:16.970535  5078 solver.cpp:218] Iteration 78300 (11.9709 iter/s, 8.35362s/100 iters), loss = 0.0268369
I1007 19:33:16.970563  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0268362 (* 1 = 0.0268362 loss)
I1007 19:33:16.970569  5078 sgd_solver.cpp:105] Iteration 78300, lr = 0.01
I1007 19:33:25.329898  5078 solver.cpp:218] Iteration 78400 (11.9627 iter/s, 8.35931s/100 iters), loss = 0.00842401
I1007 19:33:25.330015  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00842335 (* 1 = 0.00842335 loss)
I1007 19:33:25.330023  5078 sgd_solver.cpp:105] Iteration 78400, lr = 0.01
I1007 19:33:33.267241  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:33:33.601514  5078 solver.cpp:330] Iteration 78500, Testing net (#0)
I1007 19:33:35.526834  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:33:35.607260  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9126
I1007 19:33:35.607295  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.389221 (* 1 = 0.389221 loss)
I1007 19:33:35.690209  5078 solver.cpp:218] Iteration 78500 (9.65236 iter/s, 10.3602s/100 iters), loss = 0.00415717
I1007 19:33:35.690234  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00415652 (* 1 = 0.00415652 loss)
I1007 19:33:35.690241  5078 sgd_solver.cpp:105] Iteration 78500, lr = 0.01
I1007 19:33:44.040066  5078 solver.cpp:218] Iteration 78600 (11.9763 iter/s, 8.3498s/100 iters), loss = 0.00837672
I1007 19:33:44.040094  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00837607 (* 1 = 0.00837607 loss)
I1007 19:33:44.040100  5078 sgd_solver.cpp:105] Iteration 78600, lr = 0.01
I1007 19:33:52.392561  5078 solver.cpp:218] Iteration 78700 (11.9725 iter/s, 8.35244s/100 iters), loss = 0.00415727
I1007 19:33:52.392591  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00415662 (* 1 = 0.00415662 loss)
I1007 19:33:52.392596  5078 sgd_solver.cpp:105] Iteration 78700, lr = 0.01
I1007 19:34:00.754041  5078 solver.cpp:218] Iteration 78800 (11.9597 iter/s, 8.36143s/100 iters), loss = 0.0168329
I1007 19:34:00.754112  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0168323 (* 1 = 0.0168323 loss)
I1007 19:34:00.754118  5078 sgd_solver.cpp:105] Iteration 78800, lr = 0.01
I1007 19:34:09.110000  5078 solver.cpp:218] Iteration 78900 (11.9676 iter/s, 8.35587s/100 iters), loss = 0.0162287
I1007 19:34:09.110041  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0162281 (* 1 = 0.0162281 loss)
I1007 19:34:09.110047  5078 sgd_solver.cpp:105] Iteration 78900, lr = 0.01
I1007 19:34:17.057945  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:34:17.392874  5078 solver.cpp:330] Iteration 79000, Testing net (#0)
I1007 19:34:19.316747  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:34:19.397505  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9075
I1007 19:34:19.397531  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.388417 (* 1 = 0.388417 loss)
I1007 19:34:19.480510  5078 solver.cpp:218] Iteration 79000 (9.64279 iter/s, 10.3704s/100 iters), loss = 0.00782766
I1007 19:34:19.480536  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.007827 (* 1 = 0.007827 loss)
I1007 19:34:19.480542  5078 sgd_solver.cpp:105] Iteration 79000, lr = 0.01
I1007 19:34:27.831290  5078 solver.cpp:218] Iteration 79100 (11.975 iter/s, 8.35073s/100 iters), loss = 0.0117444
I1007 19:34:27.831328  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0117438 (* 1 = 0.0117438 loss)
I1007 19:34:27.831334  5078 sgd_solver.cpp:105] Iteration 79100, lr = 0.01
I1007 19:34:36.189646  5078 solver.cpp:218] Iteration 79200 (11.9642 iter/s, 8.35829s/100 iters), loss = 0.0191665
I1007 19:34:36.189779  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0191659 (* 1 = 0.0191659 loss)
I1007 19:34:36.189795  5078 sgd_solver.cpp:105] Iteration 79200, lr = 0.01
I1007 19:34:44.535871  5078 solver.cpp:218] Iteration 79300 (11.9817 iter/s, 8.34607s/100 iters), loss = 0.021986
I1007 19:34:44.535912  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0219853 (* 1 = 0.0219853 loss)
I1007 19:34:44.535917  5078 sgd_solver.cpp:105] Iteration 79300, lr = 0.01
I1007 19:34:52.887953  5078 solver.cpp:218] Iteration 79400 (11.9732 iter/s, 8.35202s/100 iters), loss = 0.00760514
I1007 19:34:52.887994  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00760448 (* 1 = 0.00760448 loss)
I1007 19:34:52.888000  5078 sgd_solver.cpp:105] Iteration 79400, lr = 0.01
I1007 19:35:00.821689  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:35:01.153887  5078 solver.cpp:330] Iteration 79500, Testing net (#0)
I1007 19:35:03.078088  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:35:03.158442  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9093
I1007 19:35:03.158475  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.366459 (* 1 = 0.366459 loss)
I1007 19:35:03.242208  5078 solver.cpp:218] Iteration 79500 (9.65794 iter/s, 10.3542s/100 iters), loss = 0.019301
I1007 19:35:03.242242  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0193004 (* 1 = 0.0193004 loss)
I1007 19:35:03.242249  5078 sgd_solver.cpp:105] Iteration 79500, lr = 0.01
I1007 19:35:11.593353  5078 solver.cpp:218] Iteration 79600 (11.9745 iter/s, 8.35109s/100 iters), loss = 0.0147914
I1007 19:35:11.593466  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0147907 (* 1 = 0.0147907 loss)
I1007 19:35:11.593472  5078 sgd_solver.cpp:105] Iteration 79600, lr = 0.01
I1007 19:35:19.938021  5078 solver.cpp:218] Iteration 79700 (11.9839 iter/s, 8.34454s/100 iters), loss = 0.00978995
I1007 19:35:19.938050  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0097893 (* 1 = 0.0097893 loss)
I1007 19:35:19.938055  5078 sgd_solver.cpp:105] Iteration 79700, lr = 0.01
I1007 19:35:28.294355  5078 solver.cpp:218] Iteration 79800 (11.967 iter/s, 8.35628s/100 iters), loss = 0.00409217
I1007 19:35:28.294384  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00409151 (* 1 = 0.00409151 loss)
I1007 19:35:28.294390  5078 sgd_solver.cpp:105] Iteration 79800, lr = 0.01
I1007 19:35:36.641784  5078 solver.cpp:218] Iteration 79900 (11.9798 iter/s, 8.34737s/100 iters), loss = 0.00197201
I1007 19:35:36.641824  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00197136 (* 1 = 0.00197136 loss)
I1007 19:35:36.641829  5078 sgd_solver.cpp:105] Iteration 79900, lr = 0.01
I1007 19:35:44.575343  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:35:44.910125  5078 solver.cpp:330] Iteration 80000, Testing net (#0)
I1007 19:35:46.835490  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:35:46.917065  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9073
I1007 19:35:46.917100  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.388478 (* 1 = 0.388478 loss)
I1007 19:35:47.000041  5078 solver.cpp:218] Iteration 80000 (9.6542 iter/s, 10.3582s/100 iters), loss = 0.0103715
I1007 19:35:47.000066  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0103708 (* 1 = 0.0103708 loss)
I1007 19:35:47.000072  5078 sgd_solver.cpp:46] MultiStep Status: Iteration 80000, step = 2
I1007 19:35:47.000074  5078 sgd_solver.cpp:105] Iteration 80000, lr = 0.001
I1007 19:35:55.354087  5078 solver.cpp:218] Iteration 80100 (11.9703 iter/s, 8.354s/100 iters), loss = 0.00297707
I1007 19:35:55.354127  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00297641 (* 1 = 0.00297641 loss)
I1007 19:35:55.354132  5078 sgd_solver.cpp:105] Iteration 80100, lr = 0.001
I1007 19:36:03.716008  5078 solver.cpp:218] Iteration 80200 (11.9591 iter/s, 8.36186s/100 iters), loss = 0.0155946
I1007 19:36:03.716049  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.015594 (* 1 = 0.015594 loss)
I1007 19:36:03.716055  5078 sgd_solver.cpp:105] Iteration 80200, lr = 0.001
I1007 19:36:12.071100  5078 solver.cpp:218] Iteration 80300 (11.9688 iter/s, 8.35503s/100 iters), loss = 0.00981095
I1007 19:36:12.071138  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00981029 (* 1 = 0.00981029 loss)
I1007 19:36:12.071144  5078 sgd_solver.cpp:105] Iteration 80300, lr = 0.001
I1007 19:36:20.430868  5078 solver.cpp:218] Iteration 80400 (11.9621 iter/s, 8.3597s/100 iters), loss = 0.00148257
I1007 19:36:20.430954  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00148191 (* 1 = 0.00148191 loss)
I1007 19:36:20.430969  5078 sgd_solver.cpp:105] Iteration 80400, lr = 0.001
I1007 19:36:28.373445  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:36:28.707166  5078 solver.cpp:330] Iteration 80500, Testing net (#0)
I1007 19:36:30.633108  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:36:30.713795  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9162
I1007 19:36:30.713830  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.348705 (* 1 = 0.348705 loss)
I1007 19:36:30.797286  5078 solver.cpp:218] Iteration 80500 (9.64664 iter/s, 10.3663s/100 iters), loss = 0.00119363
I1007 19:36:30.797312  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00119297 (* 1 = 0.00119297 loss)
I1007 19:36:30.797319  5078 sgd_solver.cpp:105] Iteration 80500, lr = 0.001
I1007 19:36:39.153014  5078 solver.cpp:218] Iteration 80600 (11.9679 iter/s, 8.35568s/100 iters), loss = 0.00170915
I1007 19:36:39.153054  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00170849 (* 1 = 0.00170849 loss)
I1007 19:36:39.153060  5078 sgd_solver.cpp:105] Iteration 80600, lr = 0.001
I1007 19:36:47.499091  5078 solver.cpp:218] Iteration 80700 (11.9818 iter/s, 8.34601s/100 iters), loss = 0.0144539
I1007 19:36:47.499131  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0144533 (* 1 = 0.0144533 loss)
I1007 19:36:47.499136  5078 sgd_solver.cpp:105] Iteration 80700, lr = 0.001
I1007 19:36:55.854977  5078 solver.cpp:218] Iteration 80800 (11.9677 iter/s, 8.35582s/100 iters), loss = 0.00864234
I1007 19:36:55.855113  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00864167 (* 1 = 0.00864167 loss)
I1007 19:36:55.855119  5078 sgd_solver.cpp:105] Iteration 80800, lr = 0.001
I1007 19:37:04.205632  5078 solver.cpp:218] Iteration 80900 (11.9753 iter/s, 8.35051s/100 iters), loss = 0.00761403
I1007 19:37:04.205672  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00761335 (* 1 = 0.00761335 loss)
I1007 19:37:04.205678  5078 sgd_solver.cpp:105] Iteration 80900, lr = 0.001
I1007 19:37:12.147159  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:37:12.482394  5078 solver.cpp:330] Iteration 81000, Testing net (#0)
I1007 19:37:14.408386  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:37:14.488878  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9187
I1007 19:37:14.488912  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.339545 (* 1 = 0.339545 loss)
I1007 19:37:14.572103  5078 solver.cpp:218] Iteration 81000 (9.64655 iter/s, 10.3664s/100 iters), loss = 0.0046131
I1007 19:37:14.572129  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00461243 (* 1 = 0.00461243 loss)
I1007 19:37:14.572135  5078 sgd_solver.cpp:105] Iteration 81000, lr = 0.001
I1007 19:37:22.923948  5078 solver.cpp:218] Iteration 81100 (11.9735 iter/s, 8.35179s/100 iters), loss = 0.00663163
I1007 19:37:22.923987  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00663096 (* 1 = 0.00663096 loss)
I1007 19:37:22.923993  5078 sgd_solver.cpp:105] Iteration 81100, lr = 0.001
I1007 19:37:31.279917  5078 solver.cpp:218] Iteration 81200 (11.9676 iter/s, 8.3559s/100 iters), loss = 0.00490754
I1007 19:37:31.280019  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00490687 (* 1 = 0.00490687 loss)
I1007 19:37:31.280035  5078 sgd_solver.cpp:105] Iteration 81200, lr = 0.001
I1007 19:37:39.633440  5078 solver.cpp:218] Iteration 81300 (11.9712 iter/s, 8.3534s/100 iters), loss = 0.00157678
I1007 19:37:39.633481  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00157611 (* 1 = 0.00157611 loss)
I1007 19:37:39.633486  5078 sgd_solver.cpp:105] Iteration 81300, lr = 0.001
I1007 19:37:47.991506  5078 solver.cpp:218] Iteration 81400 (11.9646 iter/s, 8.358s/100 iters), loss = 0.00108488
I1007 19:37:47.991547  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00108422 (* 1 = 0.00108422 loss)
I1007 19:37:47.991552  5078 sgd_solver.cpp:105] Iteration 81400, lr = 0.001
I1007 19:37:55.927000  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:37:56.262092  5078 solver.cpp:330] Iteration 81500, Testing net (#0)
I1007 19:37:58.187497  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:37:58.268146  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9203
I1007 19:37:58.268180  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.3367 (* 1 = 0.3367 loss)
I1007 19:37:58.351619  5078 solver.cpp:218] Iteration 81500 (9.65247 iter/s, 10.36s/100 iters), loss = 0.00620668
I1007 19:37:58.351644  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00620602 (* 1 = 0.00620602 loss)
I1007 19:37:58.351651  5078 sgd_solver.cpp:105] Iteration 81500, lr = 0.001
I1007 19:38:06.711951  5078 solver.cpp:218] Iteration 81600 (11.9613 iter/s, 8.36028s/100 iters), loss = 0.00154212
I1007 19:38:06.712065  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00154145 (* 1 = 0.00154145 loss)
I1007 19:38:06.712081  5078 sgd_solver.cpp:105] Iteration 81600, lr = 0.001
I1007 19:38:15.066483  5078 solver.cpp:218] Iteration 81700 (11.9697 iter/s, 8.3544s/100 iters), loss = 0.0014899
I1007 19:38:15.066524  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00148923 (* 1 = 0.00148923 loss)
I1007 19:38:15.066529  5078 sgd_solver.cpp:105] Iteration 81700, lr = 0.001
I1007 19:38:23.428414  5078 solver.cpp:218] Iteration 81800 (11.9591 iter/s, 8.36187s/100 iters), loss = 0.00265908
I1007 19:38:23.428454  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00265842 (* 1 = 0.00265842 loss)
I1007 19:38:23.428460  5078 sgd_solver.cpp:105] Iteration 81800, lr = 0.001
I1007 19:38:31.784374  5078 solver.cpp:218] Iteration 81900 (11.9676 iter/s, 8.35589s/100 iters), loss = 0.0148999
I1007 19:38:31.784415  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0148992 (* 1 = 0.0148992 loss)
I1007 19:38:31.784420  5078 sgd_solver.cpp:105] Iteration 81900, lr = 0.001
I1007 19:38:39.730960  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:38:40.065516  5078 solver.cpp:330] Iteration 82000, Testing net (#0)
I1007 19:38:41.990901  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:38:42.071019  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9198
I1007 19:38:42.071055  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.337111 (* 1 = 0.337111 loss)
I1007 19:38:42.154165  5078 solver.cpp:218] Iteration 82000 (9.64346 iter/s, 10.3697s/100 iters), loss = 0.0176033
I1007 19:38:42.154201  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0176026 (* 1 = 0.0176026 loss)
I1007 19:38:42.154207  5078 sgd_solver.cpp:105] Iteration 82000, lr = 0.001
I1007 19:38:50.501879  5078 solver.cpp:218] Iteration 82100 (11.9794 iter/s, 8.34765s/100 iters), loss = 0.00209331
I1007 19:38:50.501920  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00209264 (* 1 = 0.00209264 loss)
I1007 19:38:50.501926  5078 sgd_solver.cpp:105] Iteration 82100, lr = 0.001
I1007 19:38:58.855054  5078 solver.cpp:218] Iteration 82200 (11.9716 iter/s, 8.3531s/100 iters), loss = 0.00215527
I1007 19:38:58.855095  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00215461 (* 1 = 0.00215461 loss)
I1007 19:38:58.855101  5078 sgd_solver.cpp:105] Iteration 82200, lr = 0.001
I1007 19:39:07.207124  5078 solver.cpp:218] Iteration 82300 (11.9732 iter/s, 8.352s/100 iters), loss = 0.00208857
I1007 19:39:07.207167  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0020879 (* 1 = 0.0020879 loss)
I1007 19:39:07.207173  5078 sgd_solver.cpp:105] Iteration 82300, lr = 0.001
I1007 19:39:15.564718  5078 solver.cpp:218] Iteration 82400 (11.9653 iter/s, 8.35753s/100 iters), loss = 0.00237573
I1007 19:39:15.564863  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00237507 (* 1 = 0.00237507 loss)
I1007 19:39:15.564872  5078 sgd_solver.cpp:105] Iteration 82400, lr = 0.001
I1007 19:39:23.500576  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:39:23.835196  5078 solver.cpp:330] Iteration 82500, Testing net (#0)
I1007 19:39:25.761168  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:39:25.841861  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9214
I1007 19:39:25.841894  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.33672 (* 1 = 0.33672 loss)
I1007 19:39:25.925092  5078 solver.cpp:218] Iteration 82500 (9.65231 iter/s, 10.3602s/100 iters), loss = 0.000577054
I1007 19:39:25.925118  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000576389 (* 1 = 0.000576389 loss)
I1007 19:39:25.925124  5078 sgd_solver.cpp:105] Iteration 82500, lr = 0.001
I1007 19:39:34.278148  5078 solver.cpp:218] Iteration 82600 (11.9717 iter/s, 8.353s/100 iters), loss = 0.00215014
I1007 19:39:34.278189  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00214947 (* 1 = 0.00214947 loss)
I1007 19:39:34.278195  5078 sgd_solver.cpp:105] Iteration 82600, lr = 0.001
I1007 19:39:42.627372  5078 solver.cpp:218] Iteration 82700 (11.9773 iter/s, 8.34915s/100 iters), loss = 0.02579
I1007 19:39:42.627413  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0257893 (* 1 = 0.0257893 loss)
I1007 19:39:42.627418  5078 sgd_solver.cpp:105] Iteration 82700, lr = 0.001
I1007 19:39:50.981281  5078 solver.cpp:218] Iteration 82800 (11.9705 iter/s, 8.35384s/100 iters), loss = 0.00168105
I1007 19:39:50.981401  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00168038 (* 1 = 0.00168038 loss)
I1007 19:39:50.981417  5078 sgd_solver.cpp:105] Iteration 82800, lr = 0.001
I1007 19:39:59.327548  5078 solver.cpp:218] Iteration 82900 (11.9816 iter/s, 8.34612s/100 iters), loss = 0.00139398
I1007 19:39:59.327589  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00139331 (* 1 = 0.00139331 loss)
I1007 19:39:59.327594  5078 sgd_solver.cpp:105] Iteration 82900, lr = 0.001
I1007 19:40:07.265825  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:40:07.600085  5078 solver.cpp:330] Iteration 83000, Testing net (#0)
I1007 19:40:09.525480  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:40:09.606472  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.922
I1007 19:40:09.606498  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.337471 (* 1 = 0.337471 loss)
I1007 19:40:09.689251  5078 solver.cpp:218] Iteration 83000 (9.65099 iter/s, 10.3616s/100 iters), loss = 0.00146299
I1007 19:40:09.689286  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00146232 (* 1 = 0.00146232 loss)
I1007 19:40:09.689293  5078 sgd_solver.cpp:105] Iteration 83000, lr = 0.001
I1007 19:40:18.044049  5078 solver.cpp:218] Iteration 83100 (11.9693 iter/s, 8.35473s/100 iters), loss = 0.00163475
I1007 19:40:18.044090  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00163408 (* 1 = 0.00163408 loss)
I1007 19:40:18.044095  5078 sgd_solver.cpp:105] Iteration 83100, lr = 0.001
I1007 19:40:26.403738  5078 solver.cpp:218] Iteration 83200 (11.9623 iter/s, 8.35962s/100 iters), loss = 0.00234465
I1007 19:40:26.403856  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00234398 (* 1 = 0.00234398 loss)
I1007 19:40:26.403863  5078 sgd_solver.cpp:105] Iteration 83200, lr = 0.001
I1007 19:40:34.758404  5078 solver.cpp:218] Iteration 83300 (11.9696 iter/s, 8.35453s/100 iters), loss = 0.0035359
I1007 19:40:34.758445  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00353522 (* 1 = 0.00353522 loss)
I1007 19:40:34.758450  5078 sgd_solver.cpp:105] Iteration 83300, lr = 0.001
I1007 19:40:43.116775  5078 solver.cpp:218] Iteration 83400 (11.9641 iter/s, 8.3583s/100 iters), loss = 0.00236285
I1007 19:40:43.116816  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00236218 (* 1 = 0.00236218 loss)
I1007 19:40:43.116822  5078 sgd_solver.cpp:105] Iteration 83400, lr = 0.001
I1007 19:40:51.056010  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:40:51.390435  5078 solver.cpp:330] Iteration 83500, Testing net (#0)
I1007 19:40:53.316552  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:40:53.397413  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.922
I1007 19:40:53.397439  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.33591 (* 1 = 0.33591 loss)
I1007 19:40:53.480684  5078 solver.cpp:218] Iteration 83500 (9.64894 iter/s, 10.3638s/100 iters), loss = 0.00719971
I1007 19:40:53.480712  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00719904 (* 1 = 0.00719904 loss)
I1007 19:40:53.480720  5078 sgd_solver.cpp:105] Iteration 83500, lr = 0.001
I1007 19:41:01.833134  5078 solver.cpp:218] Iteration 83600 (11.9726 iter/s, 8.35239s/100 iters), loss = 0.0036792
I1007 19:41:01.833220  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00367853 (* 1 = 0.00367853 loss)
I1007 19:41:01.833235  5078 sgd_solver.cpp:105] Iteration 83600, lr = 0.001
I1007 19:41:10.180791  5078 solver.cpp:218] Iteration 83700 (11.9796 iter/s, 8.34754s/100 iters), loss = 0.00779841
I1007 19:41:10.180830  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00779774 (* 1 = 0.00779774 loss)
I1007 19:41:10.180836  5078 sgd_solver.cpp:105] Iteration 83700, lr = 0.001
I1007 19:41:18.529767  5078 solver.cpp:218] Iteration 83800 (11.9776 iter/s, 8.34891s/100 iters), loss = 0.00907103
I1007 19:41:18.529806  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00907036 (* 1 = 0.00907036 loss)
I1007 19:41:18.529814  5078 sgd_solver.cpp:105] Iteration 83800, lr = 0.001
I1007 19:41:26.877146  5078 solver.cpp:218] Iteration 83900 (11.9799 iter/s, 8.34731s/100 iters), loss = 0.00216629
I1007 19:41:26.877187  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00216563 (* 1 = 0.00216563 loss)
I1007 19:41:26.877192  5078 sgd_solver.cpp:105] Iteration 83900, lr = 0.001
I1007 19:41:34.818210  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:41:35.152905  5078 solver.cpp:330] Iteration 84000, Testing net (#0)
I1007 19:41:37.079452  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:41:37.160136  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9219
I1007 19:41:37.160171  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.336771 (* 1 = 0.336771 loss)
I1007 19:41:37.243247  5078 solver.cpp:218] Iteration 84000 (9.6469 iter/s, 10.366s/100 iters), loss = 0.013162
I1007 19:41:37.243280  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0131613 (* 1 = 0.0131613 loss)
I1007 19:41:37.243288  5078 sgd_solver.cpp:105] Iteration 84000, lr = 0.001
I1007 19:41:45.597506  5078 solver.cpp:218] Iteration 84100 (11.97 iter/s, 8.3542s/100 iters), loss = 0.00736294
I1007 19:41:45.597546  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00736228 (* 1 = 0.00736228 loss)
I1007 19:41:45.597551  5078 sgd_solver.cpp:105] Iteration 84100, lr = 0.001
I1007 19:41:53.948892  5078 solver.cpp:218] Iteration 84200 (11.9742 iter/s, 8.35132s/100 iters), loss = 0.00384826
I1007 19:41:53.948925  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0038476 (* 1 = 0.0038476 loss)
I1007 19:41:53.948930  5078 sgd_solver.cpp:105] Iteration 84200, lr = 0.001
I1007 19:42:02.301105  5078 solver.cpp:218] Iteration 84300 (11.973 iter/s, 8.35215s/100 iters), loss = 0.0019922
I1007 19:42:02.301141  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00199153 (* 1 = 0.00199153 loss)
I1007 19:42:02.301149  5078 sgd_solver.cpp:105] Iteration 84300, lr = 0.001
I1007 19:42:10.654094  5078 solver.cpp:218] Iteration 84400 (11.9719 iter/s, 8.35293s/100 iters), loss = 0.00159792
I1007 19:42:10.654222  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00159725 (* 1 = 0.00159725 loss)
I1007 19:42:10.654228  5078 sgd_solver.cpp:105] Iteration 84400, lr = 0.001
I1007 19:42:18.588785  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:42:18.923449  5078 solver.cpp:330] Iteration 84500, Testing net (#0)
I1007 19:42:20.848808  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:42:20.928989  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9225
I1007 19:42:20.929028  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.334165 (* 1 = 0.334165 loss)
I1007 19:42:21.012703  5078 solver.cpp:218] Iteration 84500 (9.65395 iter/s, 10.3584s/100 iters), loss = 0.00391614
I1007 19:42:21.012730  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00391547 (* 1 = 0.00391547 loss)
I1007 19:42:21.012737  5078 sgd_solver.cpp:105] Iteration 84500, lr = 0.001
I1007 19:42:29.365846  5078 solver.cpp:218] Iteration 84600 (11.9716 iter/s, 8.35308s/100 iters), loss = 0.00531761
I1007 19:42:29.365886  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00531694 (* 1 = 0.00531694 loss)
I1007 19:42:29.365892  5078 sgd_solver.cpp:105] Iteration 84600, lr = 0.001
I1007 19:42:37.708537  5078 solver.cpp:218] Iteration 84700 (11.9866 iter/s, 8.34262s/100 iters), loss = 0.00342662
I1007 19:42:37.708576  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00342596 (* 1 = 0.00342596 loss)
I1007 19:42:37.708582  5078 sgd_solver.cpp:105] Iteration 84700, lr = 0.001
I1007 19:42:46.060515  5078 solver.cpp:218] Iteration 84800 (11.9733 iter/s, 8.35191s/100 iters), loss = 0.0105243
I1007 19:42:46.060614  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0105236 (* 1 = 0.0105236 loss)
I1007 19:42:46.060621  5078 sgd_solver.cpp:105] Iteration 84800, lr = 0.001
I1007 19:42:54.409446  5078 solver.cpp:218] Iteration 84900 (11.9777 iter/s, 8.34881s/100 iters), loss = 0.000942945
I1007 19:42:54.409487  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00094228 (* 1 = 0.00094228 loss)
I1007 19:42:54.409492  5078 sgd_solver.cpp:105] Iteration 84900, lr = 0.001
I1007 19:43:02.347437  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:43:02.682215  5078 solver.cpp:330] Iteration 85000, Testing net (#0)
I1007 19:43:04.608829  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:43:04.689924  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9222
I1007 19:43:04.689949  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.334159 (* 1 = 0.334159 loss)
I1007 19:43:04.772745  5078 solver.cpp:218] Iteration 85000 (9.6495 iter/s, 10.3632s/100 iters), loss = 0.00561714
I1007 19:43:04.772769  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00561647 (* 1 = 0.00561647 loss)
I1007 19:43:04.772776  5078 sgd_solver.cpp:105] Iteration 85000, lr = 0.001
I1007 19:43:13.130251  5078 solver.cpp:218] Iteration 85100 (11.9654 iter/s, 8.35745s/100 iters), loss = 0.0042916
I1007 19:43:13.130291  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00429093 (* 1 = 0.00429093 loss)
I1007 19:43:13.130296  5078 sgd_solver.cpp:105] Iteration 85100, lr = 0.001
I1007 19:43:21.493050  5078 solver.cpp:218] Iteration 85200 (11.9578 iter/s, 8.36273s/100 iters), loss = 0.00532708
I1007 19:43:21.493176  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00532641 (* 1 = 0.00532641 loss)
I1007 19:43:21.493183  5078 sgd_solver.cpp:105] Iteration 85200, lr = 0.001
I1007 19:43:29.844965  5078 solver.cpp:218] Iteration 85300 (11.9735 iter/s, 8.35176s/100 iters), loss = 0.00250662
I1007 19:43:29.845006  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00250596 (* 1 = 0.00250596 loss)
I1007 19:43:29.845012  5078 sgd_solver.cpp:105] Iteration 85300, lr = 0.001
I1007 19:43:38.206786  5078 solver.cpp:218] Iteration 85400 (11.9592 iter/s, 8.36175s/100 iters), loss = 0.00112415
I1007 19:43:38.206826  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00112348 (* 1 = 0.00112348 loss)
I1007 19:43:38.206832  5078 sgd_solver.cpp:105] Iteration 85400, lr = 0.001
I1007 19:43:46.146270  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:43:46.481354  5078 solver.cpp:330] Iteration 85500, Testing net (#0)
I1007 19:43:48.406579  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:43:48.487251  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9227
I1007 19:43:48.487284  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.332145 (* 1 = 0.332145 loss)
I1007 19:43:48.571584  5078 solver.cpp:218] Iteration 85500 (9.64811 iter/s, 10.3647s/100 iters), loss = 0.00199324
I1007 19:43:48.571610  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00199257 (* 1 = 0.00199257 loss)
I1007 19:43:48.571617  5078 sgd_solver.cpp:105] Iteration 85500, lr = 0.001
I1007 19:43:56.928658  5078 solver.cpp:218] Iteration 85600 (11.966 iter/s, 8.35702s/100 iters), loss = 0.00178732
I1007 19:43:56.928793  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00178665 (* 1 = 0.00178665 loss)
I1007 19:43:56.928800  5078 sgd_solver.cpp:105] Iteration 85600, lr = 0.001
I1007 19:44:05.276321  5078 solver.cpp:218] Iteration 85700 (11.9796 iter/s, 8.34751s/100 iters), loss = 0.0247882
I1007 19:44:05.276363  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0247875 (* 1 = 0.0247875 loss)
I1007 19:44:05.276370  5078 sgd_solver.cpp:105] Iteration 85700, lr = 0.001
I1007 19:44:13.634444  5078 solver.cpp:218] Iteration 85800 (11.9645 iter/s, 8.35806s/100 iters), loss = 0.00366738
I1007 19:44:13.634485  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00366671 (* 1 = 0.00366671 loss)
I1007 19:44:13.634490  5078 sgd_solver.cpp:105] Iteration 85800, lr = 0.001
I1007 19:44:21.989595  5078 solver.cpp:218] Iteration 85900 (11.9688 iter/s, 8.35508s/100 iters), loss = 0.00265413
I1007 19:44:21.989635  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00265346 (* 1 = 0.00265346 loss)
I1007 19:44:21.989641  5078 sgd_solver.cpp:105] Iteration 85900, lr = 0.001
I1007 19:44:29.933063  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:44:30.268133  5078 solver.cpp:330] Iteration 86000, Testing net (#0)
I1007 19:44:32.193680  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:44:32.274413  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9235
I1007 19:44:32.274449  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.331146 (* 1 = 0.331146 loss)
I1007 19:44:32.357785  5078 solver.cpp:218] Iteration 86000 (9.64495 iter/s, 10.3681s/100 iters), loss = 0.00121005
I1007 19:44:32.357811  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00120939 (* 1 = 0.00120939 loss)
I1007 19:44:32.357818  5078 sgd_solver.cpp:105] Iteration 86000, lr = 0.001
I1007 19:44:40.708065  5078 solver.cpp:218] Iteration 86100 (11.9757 iter/s, 8.35022s/100 iters), loss = 0.00438088
I1007 19:44:40.708104  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00438021 (* 1 = 0.00438021 loss)
I1007 19:44:40.708111  5078 sgd_solver.cpp:105] Iteration 86100, lr = 0.001
I1007 19:44:49.060897  5078 solver.cpp:218] Iteration 86200 (11.9721 iter/s, 8.35277s/100 iters), loss = 0.00259566
I1007 19:44:49.060940  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00259499 (* 1 = 0.00259499 loss)
I1007 19:44:49.060945  5078 sgd_solver.cpp:105] Iteration 86200, lr = 0.001
I1007 19:44:57.413892  5078 solver.cpp:218] Iteration 86300 (11.9719 iter/s, 8.35293s/100 iters), loss = 0.0019531
I1007 19:44:57.413921  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00195243 (* 1 = 0.00195243 loss)
I1007 19:44:57.413928  5078 sgd_solver.cpp:105] Iteration 86300, lr = 0.001
I1007 19:45:05.776687  5078 solver.cpp:218] Iteration 86400 (11.9578 iter/s, 8.36274s/100 iters), loss = 0.00363174
I1007 19:45:05.776798  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00363107 (* 1 = 0.00363107 loss)
I1007 19:45:05.776804  5078 sgd_solver.cpp:105] Iteration 86400, lr = 0.001
I1007 19:45:13.712853  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:45:14.047549  5078 solver.cpp:330] Iteration 86500, Testing net (#0)
I1007 19:45:15.972932  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:45:16.053329  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.922
I1007 19:45:16.053364  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.332491 (* 1 = 0.332491 loss)
I1007 19:45:16.137270  5078 solver.cpp:218] Iteration 86500 (9.6521 iter/s, 10.3604s/100 iters), loss = 0.00294416
I1007 19:45:16.137297  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00294349 (* 1 = 0.00294349 loss)
I1007 19:45:16.137305  5078 sgd_solver.cpp:105] Iteration 86500, lr = 0.001
I1007 19:45:24.491210  5078 solver.cpp:218] Iteration 86600 (11.9705 iter/s, 8.35389s/100 iters), loss = 0.00137783
I1007 19:45:24.491238  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00137715 (* 1 = 0.00137715 loss)
I1007 19:45:24.491245  5078 sgd_solver.cpp:105] Iteration 86600, lr = 0.001
I1007 19:45:32.838668  5078 solver.cpp:218] Iteration 86700 (11.9798 iter/s, 8.3474s/100 iters), loss = 0.00206263
I1007 19:45:32.838698  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00206195 (* 1 = 0.00206195 loss)
I1007 19:45:32.838704  5078 sgd_solver.cpp:105] Iteration 86700, lr = 0.001
I1007 19:45:41.193140  5078 solver.cpp:218] Iteration 86800 (11.9697 iter/s, 8.35441s/100 iters), loss = 0.00367411
I1007 19:45:41.193251  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00367343 (* 1 = 0.00367343 loss)
I1007 19:45:41.193259  5078 sgd_solver.cpp:105] Iteration 86800, lr = 0.001
I1007 19:45:49.543669  5078 solver.cpp:218] Iteration 86900 (11.9755 iter/s, 8.35039s/100 iters), loss = 0.0022063
I1007 19:45:49.543699  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00220562 (* 1 = 0.00220562 loss)
I1007 19:45:49.543704  5078 sgd_solver.cpp:105] Iteration 86900, lr = 0.001
I1007 19:45:57.483772  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:45:57.818205  5078 solver.cpp:330] Iteration 87000, Testing net (#0)
I1007 19:45:59.743602  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:45:59.823953  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9217
I1007 19:45:59.823988  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.334049 (* 1 = 0.334049 loss)
I1007 19:45:59.906908  5078 solver.cpp:218] Iteration 87000 (9.64955 iter/s, 10.3632s/100 iters), loss = 0.0046258
I1007 19:45:59.906936  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00462512 (* 1 = 0.00462512 loss)
I1007 19:45:59.906944  5078 sgd_solver.cpp:105] Iteration 87000, lr = 0.001
I1007 19:46:08.259142  5078 solver.cpp:218] Iteration 87100 (11.9729 iter/s, 8.35218s/100 iters), loss = 0.000899475
I1007 19:46:08.259186  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000898794 (* 1 = 0.000898794 loss)
I1007 19:46:08.259191  5078 sgd_solver.cpp:105] Iteration 87100, lr = 0.001
I1007 19:46:16.616242  5078 solver.cpp:218] Iteration 87200 (11.966 iter/s, 8.35703s/100 iters), loss = 0.00243694
I1007 19:46:16.616340  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00243626 (* 1 = 0.00243626 loss)
I1007 19:46:16.616356  5078 sgd_solver.cpp:105] Iteration 87200, lr = 0.001
I1007 19:46:24.965382  5078 solver.cpp:218] Iteration 87300 (11.9775 iter/s, 8.34902s/100 iters), loss = 0.00123213
I1007 19:46:24.965422  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00123145 (* 1 = 0.00123145 loss)
I1007 19:46:24.965428  5078 sgd_solver.cpp:105] Iteration 87300, lr = 0.001
I1007 19:46:33.322283  5078 solver.cpp:218] Iteration 87400 (11.9663 iter/s, 8.35683s/100 iters), loss = 0.00102392
I1007 19:46:33.322312  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00102324 (* 1 = 0.00102324 loss)
I1007 19:46:33.322319  5078 sgd_solver.cpp:105] Iteration 87400, lr = 0.001
I1007 19:46:41.260718  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:46:41.595322  5078 solver.cpp:330] Iteration 87500, Testing net (#0)
I1007 19:46:43.519553  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:46:43.600333  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9224
I1007 19:46:43.600368  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.333606 (* 1 = 0.333606 loss)
I1007 19:46:43.683975  5078 solver.cpp:218] Iteration 87500 (9.65099 iter/s, 10.3616s/100 iters), loss = 0.0021265
I1007 19:46:43.684003  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00212582 (* 1 = 0.00212582 loss)
I1007 19:46:43.684010  5078 sgd_solver.cpp:105] Iteration 87500, lr = 0.001
I1007 19:46:52.037497  5078 solver.cpp:218] Iteration 87600 (11.9711 iter/s, 8.35347s/100 iters), loss = 0.00249646
I1007 19:46:52.037626  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00249578 (* 1 = 0.00249578 loss)
I1007 19:46:52.037632  5078 sgd_solver.cpp:105] Iteration 87600, lr = 0.001
I1007 19:47:00.387686  5078 solver.cpp:218] Iteration 87700 (11.976 iter/s, 8.35003s/100 iters), loss = 0.00155404
I1007 19:47:00.387727  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00155336 (* 1 = 0.00155336 loss)
I1007 19:47:00.387732  5078 sgd_solver.cpp:105] Iteration 87700, lr = 0.001
I1007 19:47:08.743465  5078 solver.cpp:218] Iteration 87800 (11.9679 iter/s, 8.35571s/100 iters), loss = 0.00130067
I1007 19:47:08.743505  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00129999 (* 1 = 0.00129999 loss)
I1007 19:47:08.743510  5078 sgd_solver.cpp:105] Iteration 87800, lr = 0.001
I1007 19:47:17.093400  5078 solver.cpp:218] Iteration 87900 (11.9762 iter/s, 8.34987s/100 iters), loss = 0.00107026
I1007 19:47:17.093430  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00106958 (* 1 = 0.00106958 loss)
I1007 19:47:17.093436  5078 sgd_solver.cpp:105] Iteration 87900, lr = 0.001
I1007 19:47:25.036010  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:47:25.371805  5078 solver.cpp:330] Iteration 88000, Testing net (#0)
I1007 19:47:27.297142  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:47:27.377696  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9218
I1007 19:47:27.377730  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.335517 (* 1 = 0.335517 loss)
I1007 19:47:27.460867  5078 solver.cpp:218] Iteration 88000 (9.64562 iter/s, 10.3674s/100 iters), loss = 0.00447533
I1007 19:47:27.460892  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00447465 (* 1 = 0.00447465 loss)
I1007 19:47:27.460898  5078 sgd_solver.cpp:105] Iteration 88000, lr = 0.001
I1007 19:47:35.807044  5078 solver.cpp:218] Iteration 88100 (11.9816 iter/s, 8.34612s/100 iters), loss = 0.001768
I1007 19:47:35.807073  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00176732 (* 1 = 0.00176732 loss)
I1007 19:47:35.807080  5078 sgd_solver.cpp:105] Iteration 88100, lr = 0.001
I1007 19:47:44.161474  5078 solver.cpp:218] Iteration 88200 (11.9698 iter/s, 8.35437s/100 iters), loss = 0.000942602
I1007 19:47:44.161515  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000941923 (* 1 = 0.000941923 loss)
I1007 19:47:44.161521  5078 sgd_solver.cpp:105] Iteration 88200, lr = 0.001
I1007 19:47:52.517601  5078 solver.cpp:218] Iteration 88300 (11.9674 iter/s, 8.35606s/100 iters), loss = 0.00363253
I1007 19:47:52.517642  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00363185 (* 1 = 0.00363185 loss)
I1007 19:47:52.517647  5078 sgd_solver.cpp:105] Iteration 88300, lr = 0.001
I1007 19:48:00.877921  5078 solver.cpp:218] Iteration 88400 (11.9614 iter/s, 8.36025s/100 iters), loss = 0.00146964
I1007 19:48:00.878021  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00146896 (* 1 = 0.00146896 loss)
I1007 19:48:00.878038  5078 sgd_solver.cpp:105] Iteration 88400, lr = 0.001
I1007 19:48:08.818681  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:48:09.152964  5078 solver.cpp:330] Iteration 88500, Testing net (#0)
I1007 19:48:11.077520  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:48:11.157666  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9228
I1007 19:48:11.157701  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.334521 (* 1 = 0.334521 loss)
I1007 19:48:11.241463  5078 solver.cpp:218] Iteration 88500 (9.64933 iter/s, 10.3634s/100 iters), loss = 0.000987398
I1007 19:48:11.241497  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000986714 (* 1 = 0.000986714 loss)
I1007 19:48:11.241503  5078 sgd_solver.cpp:105] Iteration 88500, lr = 0.001
I1007 19:48:19.595851  5078 solver.cpp:218] Iteration 88600 (11.9698 iter/s, 8.35433s/100 iters), loss = 0.00940426
I1007 19:48:19.595891  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00940358 (* 1 = 0.00940358 loss)
I1007 19:48:19.595897  5078 sgd_solver.cpp:105] Iteration 88600, lr = 0.001
I1007 19:48:27.947185  5078 solver.cpp:218] Iteration 88700 (11.9742 iter/s, 8.35127s/100 iters), loss = 0.00103638
I1007 19:48:27.947214  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0010357 (* 1 = 0.0010357 loss)
I1007 19:48:27.947221  5078 sgd_solver.cpp:105] Iteration 88700, lr = 0.001
I1007 19:48:36.295919  5078 solver.cpp:218] Iteration 88800 (11.9779 iter/s, 8.34868s/100 iters), loss = 0.000778568
I1007 19:48:36.296030  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000777886 (* 1 = 0.000777886 loss)
I1007 19:48:36.296046  5078 sgd_solver.cpp:105] Iteration 88800, lr = 0.001
I1007 19:48:44.649430  5078 solver.cpp:218] Iteration 88900 (11.9712 iter/s, 8.35338s/100 iters), loss = 0.0019902
I1007 19:48:44.649459  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00198952 (* 1 = 0.00198952 loss)
I1007 19:48:44.649464  5078 sgd_solver.cpp:105] Iteration 88900, lr = 0.001
I1007 19:48:52.588996  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:48:52.923324  5078 solver.cpp:330] Iteration 89000, Testing net (#0)
I1007 19:48:54.849643  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:48:54.930191  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9232
I1007 19:48:54.930225  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.332362 (* 1 = 0.332362 loss)
I1007 19:48:55.013913  5078 solver.cpp:218] Iteration 89000 (9.64839 iter/s, 10.3644s/100 iters), loss = 0.000900716
I1007 19:48:55.013947  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000900031 (* 1 = 0.000900031 loss)
I1007 19:48:55.013953  5078 sgd_solver.cpp:105] Iteration 89000, lr = 0.001
I1007 19:49:03.363075  5078 solver.cpp:218] Iteration 89100 (11.9773 iter/s, 8.3491s/100 iters), loss = 0.00118041
I1007 19:49:03.363104  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00117972 (* 1 = 0.00117972 loss)
I1007 19:49:03.363111  5078 sgd_solver.cpp:105] Iteration 89100, lr = 0.001
I1007 19:49:11.716585  5078 solver.cpp:218] Iteration 89200 (11.9711 iter/s, 8.35345s/100 iters), loss = 0.00213576
I1007 19:49:11.716719  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00213508 (* 1 = 0.00213508 loss)
I1007 19:49:11.716737  5078 sgd_solver.cpp:105] Iteration 89200, lr = 0.001
I1007 19:49:20.065610  5078 solver.cpp:218] Iteration 89300 (11.9777 iter/s, 8.34888s/100 iters), loss = 0.00385267
I1007 19:49:20.065640  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00385199 (* 1 = 0.00385199 loss)
I1007 19:49:20.065656  5078 sgd_solver.cpp:105] Iteration 89300, lr = 0.001
I1007 19:49:28.421687  5078 solver.cpp:218] Iteration 89400 (11.9674 iter/s, 8.35602s/100 iters), loss = 0.00109552
I1007 19:49:28.421717  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00109484 (* 1 = 0.00109484 loss)
I1007 19:49:28.421723  5078 sgd_solver.cpp:105] Iteration 89400, lr = 0.001
I1007 19:49:36.358419  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:49:36.692850  5078 solver.cpp:330] Iteration 89500, Testing net (#0)
I1007 19:49:38.617998  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:49:38.698644  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9235
I1007 19:49:38.698669  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.332413 (* 1 = 0.332413 loss)
I1007 19:49:38.782582  5078 solver.cpp:218] Iteration 89500 (9.65174 iter/s, 10.3608s/100 iters), loss = 0.00245566
I1007 19:49:38.782608  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00245497 (* 1 = 0.00245497 loss)
I1007 19:49:38.782614  5078 sgd_solver.cpp:105] Iteration 89500, lr = 0.001
I1007 19:49:47.140899  5078 solver.cpp:218] Iteration 89600 (11.9642 iter/s, 8.35826s/100 iters), loss = 0.00265352
I1007 19:49:47.141021  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00265283 (* 1 = 0.00265283 loss)
I1007 19:49:47.141027  5078 sgd_solver.cpp:105] Iteration 89600, lr = 0.001
I1007 19:49:55.487846  5078 solver.cpp:218] Iteration 89700 (11.9806 iter/s, 8.3468s/100 iters), loss = 0.00132923
I1007 19:49:55.487897  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00132854 (* 1 = 0.00132854 loss)
I1007 19:49:55.487905  5078 sgd_solver.cpp:105] Iteration 89700, lr = 0.001
I1007 19:50:03.845686  5078 solver.cpp:218] Iteration 89800 (11.9649 iter/s, 8.35776s/100 iters), loss = 0.0081459
I1007 19:50:03.845726  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00814521 (* 1 = 0.00814521 loss)
I1007 19:50:03.845732  5078 sgd_solver.cpp:105] Iteration 89800, lr = 0.001
I1007 19:50:12.197537  5078 solver.cpp:218] Iteration 89900 (11.9735 iter/s, 8.35178s/100 iters), loss = 0.0019272
I1007 19:50:12.197578  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00192651 (* 1 = 0.00192651 loss)
I1007 19:50:12.197584  5078 sgd_solver.cpp:105] Iteration 89900, lr = 0.001
I1007 19:50:20.136194  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:50:20.470731  5078 solver.cpp:330] Iteration 90000, Testing net (#0)
I1007 19:50:22.395851  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:50:22.476900  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9244
I1007 19:50:22.476935  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.33204 (* 1 = 0.33204 loss)
I1007 19:50:22.559500  5078 solver.cpp:218] Iteration 90000 (9.65075 iter/s, 10.3619s/100 iters), loss = 0.00417295
I1007 19:50:22.559526  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00417226 (* 1 = 0.00417226 loss)
I1007 19:50:22.559533  5078 sgd_solver.cpp:105] Iteration 90000, lr = 0.001
I1007 19:50:30.907507  5078 solver.cpp:218] Iteration 90100 (11.979 iter/s, 8.34795s/100 iters), loss = 0.00293105
I1007 19:50:30.907546  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00293037 (* 1 = 0.00293037 loss)
I1007 19:50:30.907552  5078 sgd_solver.cpp:105] Iteration 90100, lr = 0.001
I1007 19:50:39.261926  5078 solver.cpp:218] Iteration 90200 (11.9698 iter/s, 8.35436s/100 iters), loss = 0.00143019
I1007 19:50:39.261956  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0014295 (* 1 = 0.0014295 loss)
I1007 19:50:39.261962  5078 sgd_solver.cpp:105] Iteration 90200, lr = 0.001
I1007 19:50:47.612182  5078 solver.cpp:218] Iteration 90300 (11.9758 iter/s, 8.3502s/100 iters), loss = 0.00160838
I1007 19:50:47.612222  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00160769 (* 1 = 0.00160769 loss)
I1007 19:50:47.612228  5078 sgd_solver.cpp:105] Iteration 90300, lr = 0.001
I1007 19:50:55.965411  5078 solver.cpp:218] Iteration 90400 (11.9715 iter/s, 8.35316s/100 iters), loss = 0.00296715
I1007 19:50:55.965503  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00296646 (* 1 = 0.00296646 loss)
I1007 19:50:55.965512  5078 sgd_solver.cpp:105] Iteration 90400, lr = 0.001
I1007 19:51:03.906041  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:51:04.241750  5078 solver.cpp:330] Iteration 90500, Testing net (#0)
I1007 19:51:06.166679  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:51:06.247457  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9235
I1007 19:51:06.247491  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.334922 (* 1 = 0.334922 loss)
I1007 19:51:06.331104  5078 solver.cpp:218] Iteration 90500 (9.64731 iter/s, 10.3656s/100 iters), loss = 0.00370739
I1007 19:51:06.331133  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0037067 (* 1 = 0.0037067 loss)
I1007 19:51:06.331140  5078 sgd_solver.cpp:105] Iteration 90500, lr = 0.001
I1007 19:51:14.683135  5078 solver.cpp:218] Iteration 90600 (11.9732 iter/s, 8.35197s/100 iters), loss = 0.00248723
I1007 19:51:14.683168  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00248654 (* 1 = 0.00248654 loss)
I1007 19:51:14.683188  5078 sgd_solver.cpp:105] Iteration 90600, lr = 0.001
I1007 19:51:23.028748  5078 solver.cpp:218] Iteration 90700 (11.9824 iter/s, 8.34555s/100 iters), loss = 0.0107331
I1007 19:51:23.028777  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0107324 (* 1 = 0.0107324 loss)
I1007 19:51:23.028784  5078 sgd_solver.cpp:105] Iteration 90700, lr = 0.001
I1007 19:51:31.376647  5078 solver.cpp:218] Iteration 90800 (11.9791 iter/s, 8.34784s/100 iters), loss = 0.00259998
I1007 19:51:31.376798  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00259929 (* 1 = 0.00259929 loss)
I1007 19:51:31.376806  5078 sgd_solver.cpp:105] Iteration 90800, lr = 0.001
I1007 19:51:39.724200  5078 solver.cpp:218] Iteration 90900 (11.9798 iter/s, 8.34738s/100 iters), loss = 0.0013582
I1007 19:51:39.724231  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00135751 (* 1 = 0.00135751 loss)
I1007 19:51:39.724236  5078 sgd_solver.cpp:105] Iteration 90900, lr = 0.001
I1007 19:51:47.655851  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:51:47.990298  5078 solver.cpp:330] Iteration 91000, Testing net (#0)
I1007 19:51:49.914412  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:51:49.995672  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9238
I1007 19:51:49.995697  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.333414 (* 1 = 0.333414 loss)
I1007 19:51:50.078392  5078 solver.cpp:218] Iteration 91000 (9.65798 iter/s, 10.3541s/100 iters), loss = 0.00116889
I1007 19:51:50.078418  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0011682 (* 1 = 0.0011682 loss)
I1007 19:51:50.078424  5078 sgd_solver.cpp:105] Iteration 91000, lr = 0.001
I1007 19:51:58.420491  5078 solver.cpp:218] Iteration 91100 (11.9875 iter/s, 8.34204s/100 iters), loss = 0.00123338
I1007 19:51:58.420528  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0012327 (* 1 = 0.0012327 loss)
I1007 19:51:58.420536  5078 sgd_solver.cpp:105] Iteration 91100, lr = 0.001
I1007 19:52:06.766706  5078 solver.cpp:218] Iteration 91200 (11.9816 iter/s, 8.34615s/100 iters), loss = 0.00979869
I1007 19:52:06.766880  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00979801 (* 1 = 0.00979801 loss)
I1007 19:52:06.766903  5078 sgd_solver.cpp:105] Iteration 91200, lr = 0.001
I1007 19:52:15.113279  5078 solver.cpp:218] Iteration 91300 (11.9813 iter/s, 8.34637s/100 iters), loss = 0.00304345
I1007 19:52:15.113309  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00304277 (* 1 = 0.00304277 loss)
I1007 19:52:15.113315  5078 sgd_solver.cpp:105] Iteration 91300, lr = 0.001
I1007 19:52:23.461480  5078 solver.cpp:218] Iteration 91400 (11.9787 iter/s, 8.34814s/100 iters), loss = 0.00744939
I1007 19:52:23.461511  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0074487 (* 1 = 0.0074487 loss)
I1007 19:52:23.461516  5078 sgd_solver.cpp:105] Iteration 91400, lr = 0.001
I1007 19:52:31.392588  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:52:31.725615  5078 solver.cpp:330] Iteration 91500, Testing net (#0)
I1007 19:52:33.651419  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:52:33.732347  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9237
I1007 19:52:33.732374  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.332821 (* 1 = 0.332821 loss)
I1007 19:52:33.815961  5078 solver.cpp:218] Iteration 91500 (9.65771 iter/s, 10.3544s/100 iters), loss = 0.000965342
I1007 19:52:33.815990  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00096466 (* 1 = 0.00096466 loss)
I1007 19:52:33.815996  5078 sgd_solver.cpp:105] Iteration 91500, lr = 0.001
I1007 19:52:42.169224  5078 solver.cpp:218] Iteration 91600 (11.9715 iter/s, 8.35321s/100 iters), loss = 0.00321267
I1007 19:52:42.169323  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00321199 (* 1 = 0.00321199 loss)
I1007 19:52:42.169330  5078 sgd_solver.cpp:105] Iteration 91600, lr = 0.001
I1007 19:52:50.521108  5078 solver.cpp:218] Iteration 91700 (11.9735 iter/s, 8.35177s/100 iters), loss = 0.00114042
I1007 19:52:50.521149  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00113974 (* 1 = 0.00113974 loss)
I1007 19:52:50.521154  5078 sgd_solver.cpp:105] Iteration 91700, lr = 0.001
I1007 19:52:58.873662  5078 solver.cpp:218] Iteration 91800 (11.9725 iter/s, 8.35249s/100 iters), loss = 0.00108892
I1007 19:52:58.873692  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00108824 (* 1 = 0.00108824 loss)
I1007 19:52:58.873698  5078 sgd_solver.cpp:105] Iteration 91800, lr = 0.001
I1007 19:53:07.227025  5078 solver.cpp:218] Iteration 91900 (11.9713 iter/s, 8.3533s/100 iters), loss = 0.00104332
I1007 19:53:07.227053  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00104264 (* 1 = 0.00104264 loss)
I1007 19:53:07.227059  5078 sgd_solver.cpp:105] Iteration 91900, lr = 0.001
I1007 19:53:15.164391  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:53:15.499029  5078 solver.cpp:330] Iteration 92000, Testing net (#0)
I1007 19:53:17.425321  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:53:17.505949  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9235
I1007 19:53:17.505975  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.333094 (* 1 = 0.333094 loss)
I1007 19:53:17.588850  5078 solver.cpp:218] Iteration 92000 (9.65087 iter/s, 10.3618s/100 iters), loss = 0.00195858
I1007 19:53:17.588876  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0019579 (* 1 = 0.0019579 loss)
I1007 19:53:17.588881  5078 sgd_solver.cpp:105] Iteration 92000, lr = 0.001
I1007 19:53:25.936009  5078 solver.cpp:218] Iteration 92100 (11.9802 iter/s, 8.34711s/100 iters), loss = 0.000667322
I1007 19:53:25.936039  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000666642 (* 1 = 0.000666642 loss)
I1007 19:53:25.936044  5078 sgd_solver.cpp:105] Iteration 92100, lr = 0.001
I1007 19:53:34.290030  5078 solver.cpp:218] Iteration 92200 (11.9704 iter/s, 8.35396s/100 iters), loss = 0.000701961
I1007 19:53:34.290061  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000701279 (* 1 = 0.000701279 loss)
I1007 19:53:34.290068  5078 sgd_solver.cpp:105] Iteration 92200, lr = 0.001
I1007 19:53:42.638686  5078 solver.cpp:218] Iteration 92300 (11.9781 iter/s, 8.3486s/100 iters), loss = 0.000930049
I1007 19:53:42.638728  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000929368 (* 1 = 0.000929368 loss)
I1007 19:53:42.638733  5078 sgd_solver.cpp:105] Iteration 92300, lr = 0.001
I1007 19:53:50.992298  5078 solver.cpp:218] Iteration 92400 (11.971 iter/s, 8.35354s/100 iters), loss = 0.00522216
I1007 19:53:50.992409  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00522148 (* 1 = 0.00522148 loss)
I1007 19:53:50.992415  5078 sgd_solver.cpp:105] Iteration 92400, lr = 0.001
I1007 19:53:58.922364  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:53:59.257414  5078 solver.cpp:330] Iteration 92500, Testing net (#0)
I1007 19:54:01.184433  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:54:01.264956  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.923
I1007 19:54:01.264992  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.335336 (* 1 = 0.335336 loss)
I1007 19:54:01.348553  5078 solver.cpp:218] Iteration 92500 (9.65613 iter/s, 10.3561s/100 iters), loss = 0.00102017
I1007 19:54:01.348582  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00101949 (* 1 = 0.00101949 loss)
I1007 19:54:01.348588  5078 sgd_solver.cpp:105] Iteration 92500, lr = 0.001
I1007 19:54:09.700381  5078 solver.cpp:218] Iteration 92600 (11.9735 iter/s, 8.35177s/100 iters), loss = 0.00277577
I1007 19:54:09.700423  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00277509 (* 1 = 0.00277509 loss)
I1007 19:54:09.700428  5078 sgd_solver.cpp:105] Iteration 92600, lr = 0.001
I1007 19:54:18.050599  5078 solver.cpp:218] Iteration 92700 (11.9758 iter/s, 8.35015s/100 iters), loss = 0.00524992
I1007 19:54:18.050631  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00524924 (* 1 = 0.00524924 loss)
I1007 19:54:18.050647  5078 sgd_solver.cpp:105] Iteration 92700, lr = 0.001
I1007 19:54:26.400885  5078 solver.cpp:218] Iteration 92800 (11.9757 iter/s, 8.35023s/100 iters), loss = 0.00150194
I1007 19:54:26.401005  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00150126 (* 1 = 0.00150126 loss)
I1007 19:54:26.401021  5078 sgd_solver.cpp:105] Iteration 92800, lr = 0.001
I1007 19:54:34.749948  5078 solver.cpp:218] Iteration 92900 (11.9776 iter/s, 8.34892s/100 iters), loss = 0.000821983
I1007 19:54:34.749977  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000821302 (* 1 = 0.000821302 loss)
I1007 19:54:34.749982  5078 sgd_solver.cpp:105] Iteration 92900, lr = 0.001
I1007 19:54:42.686040  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:54:43.020800  5078 solver.cpp:330] Iteration 93000, Testing net (#0)
I1007 19:54:44.946472  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:54:45.027554  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9235
I1007 19:54:45.027588  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.334271 (* 1 = 0.334271 loss)
I1007 19:54:45.110290  5078 solver.cpp:218] Iteration 93000 (9.65225 iter/s, 10.3603s/100 iters), loss = 0.00225469
I1007 19:54:45.110316  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00225401 (* 1 = 0.00225401 loss)
I1007 19:54:45.110322  5078 sgd_solver.cpp:105] Iteration 93000, lr = 0.001
I1007 19:54:53.469483  5078 solver.cpp:218] Iteration 93100 (11.963 iter/s, 8.35914s/100 iters), loss = 0.000756925
I1007 19:54:53.469524  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000756245 (* 1 = 0.000756245 loss)
I1007 19:54:53.469530  5078 sgd_solver.cpp:105] Iteration 93100, lr = 0.001
I1007 19:55:01.825201  5078 solver.cpp:218] Iteration 93200 (11.968 iter/s, 8.35565s/100 iters), loss = 0.000790305
I1007 19:55:01.825351  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000789623 (* 1 = 0.000789623 loss)
I1007 19:55:01.825357  5078 sgd_solver.cpp:105] Iteration 93200, lr = 0.001
I1007 19:55:10.178992  5078 solver.cpp:218] Iteration 93300 (11.9709 iter/s, 8.35362s/100 iters), loss = 0.00207336
I1007 19:55:10.179023  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00207268 (* 1 = 0.00207268 loss)
I1007 19:55:10.179038  5078 sgd_solver.cpp:105] Iteration 93300, lr = 0.001
I1007 19:55:18.540832  5078 solver.cpp:218] Iteration 93400 (11.9592 iter/s, 8.36178s/100 iters), loss = 0.00214769
I1007 19:55:18.540863  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00214701 (* 1 = 0.00214701 loss)
I1007 19:55:18.540868  5078 sgd_solver.cpp:105] Iteration 93400, lr = 0.001
I1007 19:55:26.477813  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:55:26.812965  5078 solver.cpp:330] Iteration 93500, Testing net (#0)
I1007 19:55:28.739158  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:55:28.819602  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9231
I1007 19:55:28.819636  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.333763 (* 1 = 0.333763 loss)
I1007 19:55:28.903237  5078 solver.cpp:218] Iteration 93500 (9.65033 iter/s, 10.3623s/100 iters), loss = 0.00174346
I1007 19:55:28.903264  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00174278 (* 1 = 0.00174278 loss)
I1007 19:55:28.903270  5078 sgd_solver.cpp:105] Iteration 93500, lr = 0.001
I1007 19:55:37.250156  5078 solver.cpp:218] Iteration 93600 (11.9805 iter/s, 8.34686s/100 iters), loss = 0.00176117
I1007 19:55:37.250296  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00176049 (* 1 = 0.00176049 loss)
I1007 19:55:37.250304  5078 sgd_solver.cpp:105] Iteration 93600, lr = 0.001
I1007 19:55:45.597023  5078 solver.cpp:218] Iteration 93700 (11.9808 iter/s, 8.3467s/100 iters), loss = 0.00106488
I1007 19:55:45.597064  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0010642 (* 1 = 0.0010642 loss)
I1007 19:55:45.597069  5078 sgd_solver.cpp:105] Iteration 93700, lr = 0.001
I1007 19:55:53.947521  5078 solver.cpp:218] Iteration 93800 (11.9754 iter/s, 8.35043s/100 iters), loss = 0.00532047
I1007 19:55:53.947562  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0053198 (* 1 = 0.0053198 loss)
I1007 19:55:53.947568  5078 sgd_solver.cpp:105] Iteration 93800, lr = 0.001
I1007 19:56:02.296912  5078 solver.cpp:218] Iteration 93900 (11.977 iter/s, 8.34932s/100 iters), loss = 0.00386697
I1007 19:56:02.296953  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00386629 (* 1 = 0.00386629 loss)
I1007 19:56:02.296959  5078 sgd_solver.cpp:105] Iteration 93900, lr = 0.001
I1007 19:56:10.236210  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:56:10.570796  5078 solver.cpp:330] Iteration 94000, Testing net (#0)
I1007 19:56:12.497386  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:56:12.578178  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9233
I1007 19:56:12.578213  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.333537 (* 1 = 0.333537 loss)
I1007 19:56:12.661428  5078 solver.cpp:218] Iteration 94000 (9.64837 iter/s, 10.3644s/100 iters), loss = 0.0027489
I1007 19:56:12.661454  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00274823 (* 1 = 0.00274823 loss)
I1007 19:56:12.661461  5078 sgd_solver.cpp:105] Iteration 94000, lr = 0.001
I1007 19:56:21.009917  5078 solver.cpp:218] Iteration 94100 (11.9783 iter/s, 8.34844s/100 iters), loss = 0.0043232
I1007 19:56:21.009948  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00432253 (* 1 = 0.00432253 loss)
I1007 19:56:21.009953  5078 sgd_solver.cpp:105] Iteration 94100, lr = 0.001
I1007 19:56:29.362509  5078 solver.cpp:218] Iteration 94200 (11.9724 iter/s, 8.35253s/100 iters), loss = 0.00248838
I1007 19:56:29.362548  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0024877 (* 1 = 0.0024877 loss)
I1007 19:56:29.362555  5078 sgd_solver.cpp:105] Iteration 94200, lr = 0.001
I1007 19:56:37.710536  5078 solver.cpp:218] Iteration 94300 (11.979 iter/s, 8.34796s/100 iters), loss = 0.00741008
I1007 19:56:37.710577  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0074094 (* 1 = 0.0074094 loss)
I1007 19:56:37.710582  5078 sgd_solver.cpp:105] Iteration 94300, lr = 0.001
I1007 19:56:46.064990  5078 solver.cpp:218] Iteration 94400 (11.9698 iter/s, 8.35439s/100 iters), loss = 0.000810413
I1007 19:56:46.065145  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000809734 (* 1 = 0.000809734 loss)
I1007 19:56:46.065161  5078 sgd_solver.cpp:105] Iteration 94400, lr = 0.001
I1007 19:56:54.000567  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:56:54.335296  5078 solver.cpp:330] Iteration 94500, Testing net (#0)
I1007 19:56:56.260269  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:56:56.340675  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9243
I1007 19:56:56.340711  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.333305 (* 1 = 0.333305 loss)
I1007 19:56:56.424393  5078 solver.cpp:218] Iteration 94500 (9.65324 iter/s, 10.3592s/100 iters), loss = 0.00282458
I1007 19:56:56.424419  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0028239 (* 1 = 0.0028239 loss)
I1007 19:56:56.424427  5078 sgd_solver.cpp:105] Iteration 94500, lr = 0.001
I1007 19:57:04.785020  5078 solver.cpp:218] Iteration 94600 (11.9609 iter/s, 8.36057s/100 iters), loss = 0.0335297
I1007 19:57:04.785061  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.033529 (* 1 = 0.033529 loss)
I1007 19:57:04.785068  5078 sgd_solver.cpp:105] Iteration 94600, lr = 0.001
I1007 19:57:13.138957  5078 solver.cpp:218] Iteration 94700 (11.9705 iter/s, 8.35387s/100 iters), loss = 0.000786172
I1007 19:57:13.138988  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000785494 (* 1 = 0.000785494 loss)
I1007 19:57:13.138993  5078 sgd_solver.cpp:105] Iteration 94700, lr = 0.001
I1007 19:57:21.495867  5078 solver.cpp:218] Iteration 94800 (11.9662 iter/s, 8.35685s/100 iters), loss = 0.00320146
I1007 19:57:21.495949  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00320078 (* 1 = 0.00320078 loss)
I1007 19:57:21.495956  5078 sgd_solver.cpp:105] Iteration 94800, lr = 0.001
I1007 19:57:29.849745  5078 solver.cpp:218] Iteration 94900 (11.9706 iter/s, 8.35377s/100 iters), loss = 0.00256085
I1007 19:57:29.849786  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00256017 (* 1 = 0.00256017 loss)
I1007 19:57:29.849792  5078 sgd_solver.cpp:105] Iteration 94900, lr = 0.001
I1007 19:57:37.790665  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:57:38.125272  5078 solver.cpp:330] Iteration 95000, Testing net (#0)
I1007 19:57:40.051316  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:57:40.132066  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9233
I1007 19:57:40.132091  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.334395 (* 1 = 0.334395 loss)
I1007 19:57:40.215391  5078 solver.cpp:218] Iteration 95000 (9.64732 iter/s, 10.3656s/100 iters), loss = 0.00132128
I1007 19:57:40.215421  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00132059 (* 1 = 0.00132059 loss)
I1007 19:57:40.215428  5078 sgd_solver.cpp:105] Iteration 95000, lr = 0.001
I1007 19:57:48.560437  5078 solver.cpp:218] Iteration 95100 (11.9832 iter/s, 8.34499s/100 iters), loss = 0.00539755
I1007 19:57:48.560467  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00539686 (* 1 = 0.00539686 loss)
I1007 19:57:48.560473  5078 sgd_solver.cpp:105] Iteration 95100, lr = 0.001
I1007 19:57:56.909520  5078 solver.cpp:218] Iteration 95200 (11.9774 iter/s, 8.34903s/100 iters), loss = 0.00466766
I1007 19:57:56.909677  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00466698 (* 1 = 0.00466698 loss)
I1007 19:57:56.909684  5078 sgd_solver.cpp:105] Iteration 95200, lr = 0.001
I1007 19:58:05.261128  5078 solver.cpp:218] Iteration 95300 (11.974 iter/s, 8.35143s/100 iters), loss = 0.00222868
I1007 19:58:05.261158  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.002228 (* 1 = 0.002228 loss)
I1007 19:58:05.261164  5078 sgd_solver.cpp:105] Iteration 95300, lr = 0.001
I1007 19:58:13.612659  5078 solver.cpp:218] Iteration 95400 (11.9739 iter/s, 8.35147s/100 iters), loss = 0.00171256
I1007 19:58:13.612707  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00171188 (* 1 = 0.00171188 loss)
I1007 19:58:13.612715  5078 sgd_solver.cpp:105] Iteration 95400, lr = 0.001
I1007 19:58:21.547571  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:58:21.881440  5078 solver.cpp:330] Iteration 95500, Testing net (#0)
I1007 19:58:23.806591  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:58:23.887348  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9228
I1007 19:58:23.887383  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.334947 (* 1 = 0.334947 loss)
I1007 19:58:23.970641  5078 solver.cpp:218] Iteration 95500 (9.65446 iter/s, 10.3579s/100 iters), loss = 0.000542237
I1007 19:58:23.970667  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000541551 (* 1 = 0.000541551 loss)
I1007 19:58:23.970674  5078 sgd_solver.cpp:105] Iteration 95500, lr = 0.001
I1007 19:58:32.325614  5078 solver.cpp:218] Iteration 95600 (11.969 iter/s, 8.35492s/100 iters), loss = 0.000803505
I1007 19:58:32.325757  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000802819 (* 1 = 0.000802819 loss)
I1007 19:58:32.325765  5078 sgd_solver.cpp:105] Iteration 95600, lr = 0.001
I1007 19:58:40.679620  5078 solver.cpp:218] Iteration 95700 (11.9705 iter/s, 8.35385s/100 iters), loss = 0.00103329
I1007 19:58:40.679652  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0010326 (* 1 = 0.0010326 loss)
I1007 19:58:40.679658  5078 sgd_solver.cpp:105] Iteration 95700, lr = 0.001
I1007 19:58:49.038694  5078 solver.cpp:218] Iteration 95800 (11.9631 iter/s, 8.35902s/100 iters), loss = 0.000999273
I1007 19:58:49.038725  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000998586 (* 1 = 0.000998586 loss)
I1007 19:58:49.038741  5078 sgd_solver.cpp:105] Iteration 95800, lr = 0.001
I1007 19:58:57.389515  5078 solver.cpp:218] Iteration 95900 (11.975 iter/s, 8.35076s/100 iters), loss = 0.00187163
I1007 19:58:57.389544  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00187094 (* 1 = 0.00187094 loss)
I1007 19:58:57.389550  5078 sgd_solver.cpp:105] Iteration 95900, lr = 0.001
I1007 19:59:05.331606  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:59:05.665130  5078 solver.cpp:330] Iteration 96000, Testing net (#0)
I1007 19:59:07.590680  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:59:07.671093  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9229
I1007 19:59:07.671128  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.333904 (* 1 = 0.333904 loss)
I1007 19:59:07.754390  5078 solver.cpp:218] Iteration 96000 (9.64803 iter/s, 10.3648s/100 iters), loss = 0.000937751
I1007 19:59:07.754416  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000937062 (* 1 = 0.000937062 loss)
I1007 19:59:07.754422  5078 sgd_solver.cpp:105] Iteration 96000, lr = 0.001
I1007 19:59:16.090557  5078 solver.cpp:218] Iteration 96100 (11.996 iter/s, 8.33611s/100 iters), loss = 0.00609343
I1007 19:59:16.090587  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00609275 (* 1 = 0.00609275 loss)
I1007 19:59:16.090593  5078 sgd_solver.cpp:105] Iteration 96100, lr = 0.001
I1007 19:59:24.437870  5078 solver.cpp:218] Iteration 96200 (11.98 iter/s, 8.34725s/100 iters), loss = 0.00166688
I1007 19:59:24.437899  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00166619 (* 1 = 0.00166619 loss)
I1007 19:59:24.437904  5078 sgd_solver.cpp:105] Iteration 96200, lr = 0.001
I1007 19:59:32.783617  5078 solver.cpp:218] Iteration 96300 (11.9822 iter/s, 8.34569s/100 iters), loss = 0.0078297
I1007 19:59:32.783658  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00782901 (* 1 = 0.00782901 loss)
I1007 19:59:32.783663  5078 sgd_solver.cpp:105] Iteration 96300, lr = 0.001
I1007 19:59:41.133774  5078 solver.cpp:218] Iteration 96400 (11.9759 iter/s, 8.35009s/100 iters), loss = 0.00354477
I1007 19:59:41.133890  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00354408 (* 1 = 0.00354408 loss)
I1007 19:59:41.133905  5078 sgd_solver.cpp:105] Iteration 96400, lr = 0.001
I1007 19:59:49.061818  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:59:49.396802  5078 solver.cpp:330] Iteration 96500, Testing net (#0)
I1007 19:59:51.322504  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 19:59:51.402837  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9222
I1007 19:59:51.402873  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.333515 (* 1 = 0.333515 loss)
I1007 19:59:51.486820  5078 solver.cpp:218] Iteration 96500 (9.65913 iter/s, 10.3529s/100 iters), loss = 0.00603379
I1007 19:59:51.486846  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00603309 (* 1 = 0.00603309 loss)
I1007 19:59:51.486853  5078 sgd_solver.cpp:105] Iteration 96500, lr = 0.001
I1007 19:59:59.839510  5078 solver.cpp:218] Iteration 96600 (11.9723 iter/s, 8.35259s/100 iters), loss = 0.0149391
I1007 19:59:59.839540  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0149384 (* 1 = 0.0149384 loss)
I1007 19:59:59.839545  5078 sgd_solver.cpp:105] Iteration 96600, lr = 0.001
I1007 20:00:08.190033  5078 solver.cpp:218] Iteration 96700 (11.9754 iter/s, 8.35047s/100 iters), loss = 0.00511368
I1007 20:00:08.190064  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.005113 (* 1 = 0.005113 loss)
I1007 20:00:08.190079  5078 sgd_solver.cpp:105] Iteration 96700, lr = 0.001
I1007 20:00:16.543104  5078 solver.cpp:218] Iteration 96800 (11.9717 iter/s, 8.35301s/100 iters), loss = 0.00260889
I1007 20:00:16.543244  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0026082 (* 1 = 0.0026082 loss)
I1007 20:00:16.543263  5078 sgd_solver.cpp:105] Iteration 96800, lr = 0.001
I1007 20:00:24.891324  5078 solver.cpp:218] Iteration 96900 (11.9788 iter/s, 8.34806s/100 iters), loss = 0.00481461
I1007 20:00:24.891364  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00481392 (* 1 = 0.00481392 loss)
I1007 20:00:24.891371  5078 sgd_solver.cpp:105] Iteration 96900, lr = 0.001
I1007 20:00:32.822448  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 20:00:33.156764  5078 solver.cpp:330] Iteration 97000, Testing net (#0)
I1007 20:00:35.081816  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 20:00:35.162829  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.923
I1007 20:00:35.162865  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.334597 (* 1 = 0.334597 loss)
I1007 20:00:35.245561  5078 solver.cpp:218] Iteration 97000 (9.65795 iter/s, 10.3542s/100 iters), loss = 0.00221526
I1007 20:00:35.245594  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00221457 (* 1 = 0.00221457 loss)
I1007 20:00:35.245600  5078 sgd_solver.cpp:105] Iteration 97000, lr = 0.001
I1007 20:00:43.593973  5078 solver.cpp:218] Iteration 97100 (11.9784 iter/s, 8.34835s/100 iters), loss = 0.00182513
I1007 20:00:43.594002  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00182444 (* 1 = 0.00182444 loss)
I1007 20:00:43.594008  5078 sgd_solver.cpp:105] Iteration 97100, lr = 0.001
I1007 20:00:51.950330  5078 solver.cpp:218] Iteration 97200 (11.967 iter/s, 8.3563s/100 iters), loss = 0.00230668
I1007 20:00:51.950474  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00230599 (* 1 = 0.00230599 loss)
I1007 20:00:51.950491  5078 sgd_solver.cpp:105] Iteration 97200, lr = 0.001
I1007 20:01:00.301295  5078 solver.cpp:218] Iteration 97300 (11.9749 iter/s, 8.35079s/100 iters), loss = 0.00487471
I1007 20:01:00.301336  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00487403 (* 1 = 0.00487403 loss)
I1007 20:01:00.301342  5078 sgd_solver.cpp:105] Iteration 97300, lr = 0.001
I1007 20:01:08.655006  5078 solver.cpp:218] Iteration 97400 (11.9708 iter/s, 8.35365s/100 iters), loss = 0.00704345
I1007 20:01:08.655047  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00704276 (* 1 = 0.00704276 loss)
I1007 20:01:08.655052  5078 sgd_solver.cpp:105] Iteration 97400, lr = 0.001
I1007 20:01:16.592531  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 20:01:16.927323  5078 solver.cpp:330] Iteration 97500, Testing net (#0)
I1007 20:01:18.852453  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 20:01:18.933225  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9228
I1007 20:01:18.933260  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.335795 (* 1 = 0.335795 loss)
I1007 20:01:19.017256  5078 solver.cpp:218] Iteration 97500 (9.65048 iter/s, 10.3622s/100 iters), loss = 0.00221402
I1007 20:01:19.017284  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00221333 (* 1 = 0.00221333 loss)
I1007 20:01:19.017292  5078 sgd_solver.cpp:105] Iteration 97500, lr = 0.001
I1007 20:01:27.378891  5078 solver.cpp:218] Iteration 97600 (11.9595 iter/s, 8.36158s/100 iters), loss = 0.00092204
I1007 20:01:27.379029  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000921351 (* 1 = 0.000921351 loss)
I1007 20:01:27.379035  5078 sgd_solver.cpp:105] Iteration 97600, lr = 0.001
I1007 20:01:35.730012  5078 solver.cpp:218] Iteration 97700 (11.9747 iter/s, 8.35097s/100 iters), loss = 0.00447342
I1007 20:01:35.730042  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00447273 (* 1 = 0.00447273 loss)
I1007 20:01:35.730047  5078 sgd_solver.cpp:105] Iteration 97700, lr = 0.001
I1007 20:01:44.085291  5078 solver.cpp:218] Iteration 97800 (11.9686 iter/s, 8.35522s/100 iters), loss = 0.00162953
I1007 20:01:44.085322  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00162884 (* 1 = 0.00162884 loss)
I1007 20:01:44.085337  5078 sgd_solver.cpp:105] Iteration 97800, lr = 0.001
I1007 20:01:52.438838  5078 solver.cpp:218] Iteration 97900 (11.971 iter/s, 8.35349s/100 iters), loss = 0.00047718
I1007 20:01:52.438868  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000476495 (* 1 = 0.000476495 loss)
I1007 20:01:52.438874  5078 sgd_solver.cpp:105] Iteration 97900, lr = 0.001
I1007 20:02:00.386553  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 20:02:00.721691  5078 solver.cpp:330] Iteration 98000, Testing net (#0)
I1007 20:02:02.648033  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 20:02:02.728696  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9232
I1007 20:02:02.728731  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.335122 (* 1 = 0.335122 loss)
I1007 20:02:02.812129  5078 solver.cpp:218] Iteration 98000 (9.6402 iter/s, 10.3732s/100 iters), loss = 0.00908119
I1007 20:02:02.812155  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00908051 (* 1 = 0.00908051 loss)
I1007 20:02:02.812161  5078 sgd_solver.cpp:105] Iteration 98000, lr = 0.001
I1007 20:02:11.161797  5078 solver.cpp:218] Iteration 98100 (11.9766 iter/s, 8.34962s/100 iters), loss = 0.00159045
I1007 20:02:11.161837  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00158976 (* 1 = 0.00158976 loss)
I1007 20:02:11.161842  5078 sgd_solver.cpp:105] Iteration 98100, lr = 0.001
I1007 20:02:19.510521  5078 solver.cpp:218] Iteration 98200 (11.978 iter/s, 8.34866s/100 iters), loss = 0.00100107
I1007 20:02:19.510561  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00100039 (* 1 = 0.00100039 loss)
I1007 20:02:19.510567  5078 sgd_solver.cpp:105] Iteration 98200, lr = 0.001
I1007 20:02:27.855947  5078 solver.cpp:218] Iteration 98300 (11.9827 iter/s, 8.34536s/100 iters), loss = 0.00177394
I1007 20:02:27.855986  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00177325 (* 1 = 0.00177325 loss)
I1007 20:02:27.855993  5078 sgd_solver.cpp:105] Iteration 98300, lr = 0.001
I1007 20:02:36.201468  5078 solver.cpp:218] Iteration 98400 (11.9826 iter/s, 8.34546s/100 iters), loss = 0.000455482
I1007 20:02:36.201566  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000454801 (* 1 = 0.000454801 loss)
I1007 20:02:36.201573  5078 sgd_solver.cpp:105] Iteration 98400, lr = 0.001
I1007 20:02:44.124594  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 20:02:44.459375  5078 solver.cpp:330] Iteration 98500, Testing net (#0)
I1007 20:02:46.384876  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 20:02:46.465392  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9235
I1007 20:02:46.465427  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.337392 (* 1 = 0.337392 loss)
I1007 20:02:46.549110  5078 solver.cpp:218] Iteration 98500 (9.66416 iter/s, 10.3475s/100 iters), loss = 0.00262255
I1007 20:02:46.549137  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00262187 (* 1 = 0.00262187 loss)
I1007 20:02:46.549144  5078 sgd_solver.cpp:105] Iteration 98500, lr = 0.001
I1007 20:02:54.903743  5078 solver.cpp:218] Iteration 98600 (11.9695 iter/s, 8.35458s/100 iters), loss = 0.0022627
I1007 20:02:54.903772  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00226202 (* 1 = 0.00226202 loss)
I1007 20:02:54.903779  5078 sgd_solver.cpp:105] Iteration 98600, lr = 0.001
I1007 20:03:03.250949  5078 solver.cpp:218] Iteration 98700 (11.9801 iter/s, 8.34715s/100 iters), loss = 0.00491973
I1007 20:03:03.250989  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00491905 (* 1 = 0.00491905 loss)
I1007 20:03:03.250995  5078 sgd_solver.cpp:105] Iteration 98700, lr = 0.001
I1007 20:03:11.610072  5078 solver.cpp:218] Iteration 98800 (11.9631 iter/s, 8.35906s/100 iters), loss = 0.00143757
I1007 20:03:11.610188  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00143689 (* 1 = 0.00143689 loss)
I1007 20:03:11.610195  5078 sgd_solver.cpp:105] Iteration 98800, lr = 0.001
I1007 20:03:19.959933  5078 solver.cpp:218] Iteration 98900 (11.9764 iter/s, 8.34972s/100 iters), loss = 0.00124109
I1007 20:03:19.959972  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00124042 (* 1 = 0.00124042 loss)
I1007 20:03:19.959978  5078 sgd_solver.cpp:105] Iteration 98900, lr = 0.001
I1007 20:03:27.894243  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 20:03:28.227219  5078 solver.cpp:330] Iteration 99000, Testing net (#0)
I1007 20:03:30.153013  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 20:03:30.234223  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9242
I1007 20:03:30.234259  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.33654 (* 1 = 0.33654 loss)
I1007 20:03:30.316897  5078 solver.cpp:218] Iteration 99000 (9.6554 iter/s, 10.3569s/100 iters), loss = 0.00433444
I1007 20:03:30.316926  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00433376 (* 1 = 0.00433376 loss)
I1007 20:03:30.316932  5078 sgd_solver.cpp:105] Iteration 99000, lr = 0.001
I1007 20:03:38.665771  5078 solver.cpp:218] Iteration 99100 (11.9777 iter/s, 8.34882s/100 iters), loss = 0.00175578
I1007 20:03:38.665802  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00175511 (* 1 = 0.00175511 loss)
I1007 20:03:38.665807  5078 sgd_solver.cpp:105] Iteration 99100, lr = 0.001
I1007 20:03:47.013530  5078 solver.cpp:218] Iteration 99200 (11.9793 iter/s, 8.3477s/100 iters), loss = 0.0101582
I1007 20:03:47.013650  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0101575 (* 1 = 0.0101575 loss)
I1007 20:03:47.013658  5078 sgd_solver.cpp:105] Iteration 99200, lr = 0.001
I1007 20:03:55.356426  5078 solver.cpp:218] Iteration 99300 (11.9865 iter/s, 8.34275s/100 iters), loss = 0.00156454
I1007 20:03:55.356463  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00156386 (* 1 = 0.00156386 loss)
I1007 20:03:55.356470  5078 sgd_solver.cpp:105] Iteration 99300, lr = 0.001
I1007 20:04:03.710021  5078 solver.cpp:218] Iteration 99400 (11.971 iter/s, 8.35353s/100 iters), loss = 0.000963036
I1007 20:04:03.710059  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000962356 (* 1 = 0.000962356 loss)
I1007 20:04:03.710065  5078 sgd_solver.cpp:105] Iteration 99400, lr = 0.001
I1007 20:04:11.651276  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 20:04:11.985816  5078 solver.cpp:330] Iteration 99500, Testing net (#0)
I1007 20:04:13.911254  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 20:04:13.991847  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9229
I1007 20:04:13.991883  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.337373 (* 1 = 0.337373 loss)
I1007 20:04:14.076028  5078 solver.cpp:218] Iteration 99500 (9.64698 iter/s, 10.3659s/100 iters), loss = 0.000937113
I1007 20:04:14.076056  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000936434 (* 1 = 0.000936434 loss)
I1007 20:04:14.076061  5078 sgd_solver.cpp:105] Iteration 99500, lr = 0.001
I1007 20:04:22.427278  5078 solver.cpp:218] Iteration 99600 (11.9743 iter/s, 8.3512s/100 iters), loss = 0.00107593
I1007 20:04:22.427378  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00107525 (* 1 = 0.00107525 loss)
I1007 20:04:22.427398  5078 sgd_solver.cpp:105] Iteration 99600, lr = 0.001
I1007 20:04:30.772960  5078 solver.cpp:218] Iteration 99700 (11.9824 iter/s, 8.34556s/100 iters), loss = 0.00132459
I1007 20:04:30.772991  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00132391 (* 1 = 0.00132391 loss)
I1007 20:04:30.772997  5078 sgd_solver.cpp:105] Iteration 99700, lr = 0.001
I1007 20:04:39.131373  5078 solver.cpp:218] Iteration 99800 (11.9641 iter/s, 8.35836s/100 iters), loss = 0.00312224
I1007 20:04:39.131414  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00312156 (* 1 = 0.00312156 loss)
I1007 20:04:39.131420  5078 sgd_solver.cpp:105] Iteration 99800, lr = 0.001
I1007 20:04:47.478071  5078 solver.cpp:218] Iteration 99900 (11.9809 iter/s, 8.34663s/100 iters), loss = 0.00117882
I1007 20:04:47.478111  5078 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00117815 (* 1 = 0.00117815 loss)
I1007 20:04:47.478117  5078 sgd_solver.cpp:105] Iteration 99900, lr = 0.001
I1007 20:04:55.415488  5087 data_layer.cpp:73] Restarting data prefetching from start.
I1007 20:04:55.748875  5078 solver.cpp:447] Snapshotting to binary proto file xn/PENLU/snapshot/resnet/res32/res32_penlu_alpha2_beta1_etanostudy_2study_2decay_gauss_iter_100000.caffemodel
I1007 20:04:55.762681  5078 sgd_solver.cpp:273] Snapshotting solver state to binary proto file xn/PENLU/snapshot/resnet/res32/res32_penlu_alpha2_beta1_etanostudy_2study_2decay_gauss_iter_100000.solverstate
I1007 20:04:55.785804  5078 solver.cpp:310] Iteration 100000, loss = 0.000525792
I1007 20:04:55.785825  5078 solver.cpp:330] Iteration 100000, Testing net (#0)
I1007 20:04:57.711727  5088 data_layer.cpp:73] Restarting data prefetching from start.
I1007 20:04:57.792152  5078 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9245
I1007 20:04:57.792177  5078 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.333936 (* 1 = 0.333936 loss)
I1007 20:04:57.792182  5078 solver.cpp:315] Optimization Done.
I1007 20:04:57.792184  5078 caffe.cpp:259] Optimization Done.
