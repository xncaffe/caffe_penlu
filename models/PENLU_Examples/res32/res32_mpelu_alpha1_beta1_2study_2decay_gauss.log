I1007 22:14:28.052909  5299 caffe.cpp:218] Using GPUs 0
I1007 22:14:28.056375  5299 caffe.cpp:223] GPU 0: GeForce GTX 1080
I1007 22:14:28.571210  5299 solver.cpp:44] Initializing solver from parameters: 
test_iter: 100
test_interval: 500
base_lr: 0.1
display: 100
max_iter: 100000
lr_policy: "multistep"
gamma: 0.1
momentum: 0.9
weight_decay: 0.0001
snapshot: 100000
snapshot_prefix: "xn/PENLU/snapshot/resnet/res32/res32_mpelu_alpha1_beta1_2study_2decay_gauss"
solver_mode: GPU
device_id: 0
net: "/home/x306/caffe/xn/PENLU/neural/resnet/res32/res32_mpelu_decay_gauss.prototxt"
train_state {
  level: 0
  stage: ""
}
stepvalue: 40000
stepvalue: 80000
I1007 22:14:28.571357  5299 solver.cpp:87] Creating training net from net file: /home/x306/caffe/xn/PENLU/neural/resnet/res32/res32_mpelu_decay_gauss.prototxt
I1007 22:14:28.573576  5299 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: /home/x306/caffe/xn/PENLU/neural/resnet/res32/res32_mpelu_decay_gauss.prototxt
I1007 22:14:28.573598  5299 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I1007 22:14:28.573770  5299 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer Data1
I1007 22:14:28.573850  5299 net.cpp:294] The NetState phase (0) differed from the phase (1) specified by a rule in layer Accuracy1
I1007 22:14:28.574509  5299 net.cpp:51] Initializing net from parameters: 
name: "resnet_cifar10"
state {
  phase: TRAIN
  level: 0
  stage: ""
}
layer {
  name: "Data1"
  type: "Data"
  top: "Data1"
  top: "Data2"
  include {
    phase: TRAIN
  }
  transform_param {
    mirror: true
    crop_size: 28
    mean_file: "/home/x306/caffe/xn/PENLU/data/cifar10/mean.binaryproto"
  }
  data_param {
    source: "/home/x306/caffe/xn/PENLU/data/cifar10/cifar10_train_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "Convolution1"
  type: "Convolution"
  bottom: "Data1"
  top: "Convolution1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm1"
  type: "BatchNorm"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1"
  type: "Scale"
  bottom: "Convolution1"
  top: "Convolution1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU1"
  type: "M2PELU"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution2"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm2"
  type: "BatchNorm"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale2"
  type: "Scale"
  bottom: "Convolution2"
  top: "Convolution2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU2"
  type: "M2PELU"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution3"
  type: "Convolution"
  bottom: "Convolution2"
  top: "Convolution3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm3"
  type: "BatchNorm"
  bottom: "Convolution3"
  top: "Convolution3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale3"
  type: "Scale"
  bottom: "Convolution3"
  top: "Convolution3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise1"
  type: "Eltwise"
  bottom: "Convolution1"
  bottom: "Convolution3"
  top: "Eltwise1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU3"
  type: "M2PELU"
  bottom: "Eltwise1"
  top: "Eltwise1"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution4"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm4"
  type: "BatchNorm"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale4"
  type: "Scale"
  bottom: "Convolution4"
  top: "Convolution4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU4"
  type: "M2PELU"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution5"
  type: "Convolution"
  bottom: "Convolution4"
  top: "Convolution5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm5"
  type: "BatchNorm"
  bottom: "Convolution5"
  top: "Convolution5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale5"
  type: "Scale"
  bottom: "Convolution5"
  top: "Convolution5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise2"
  type: "Eltwise"
  bottom: "Eltwise1"
  bottom: "Convolution5"
  top: "Eltwise2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU5"
  type: "M2PELU"
  bottom: "Eltwise2"
  top: "Eltwise2"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution6"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm6"
  type: "BatchNorm"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale6"
  type: "Scale"
  bottom: "Convolution6"
  top: "Convolution6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU6"
  type: "M2PELU"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution7"
  type: "Convolution"
  bottom: "Convolution6"
  top: "Convolution7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm7"
  type: "BatchNorm"
  bottom: "Convolution7"
  top: "Convolution7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale7"
  type: "Scale"
  bottom: "Convolution7"
  top: "Convolution7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise3"
  type: "Eltwise"
  bottom: "Eltwise2"
  bottom: "Convolution7"
  top: "Eltwise3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU7"
  type: "M2PELU"
  bottom: "Eltwise3"
  top: "Eltwise3"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution8"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm8"
  type: "BatchNorm"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale8"
  type: "Scale"
  bottom: "Convolution8"
  top: "Convolution8"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU8"
  type: "M2PELU"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution9"
  type: "Convolution"
  bottom: "Convolution8"
  top: "Convolution9"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm9"
  type: "BatchNorm"
  bottom: "Convolution9"
  top: "Convolution9"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale9"
  type: "Scale"
  bottom: "Convolution9"
  top: "Convolution9"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise4"
  type: "Eltwise"
  bottom: "Eltwise3"
  bottom: "Convolution9"
  top: "Eltwise4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU9"
  type: "M2PELU"
  bottom: "Eltwise4"
  top: "Eltwise4"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution10"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution10"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm10"
  type: "BatchNorm"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale10"
  type: "Scale"
  bottom: "Convolution10"
  top: "Convolution10"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU10"
  type: "M2PELU"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution11"
  type: "Convolution"
  bottom: "Convolution10"
  top: "Convolution11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm11"
  type: "BatchNorm"
  bottom: "Convolution11"
  top: "Convolution11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale11"
  type: "Scale"
  bottom: "Convolution11"
  top: "Convolution11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise5"
  type: "Eltwise"
  bottom: "Eltwise4"
  bottom: "Convolution11"
  top: "Eltwise5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU11"
  type: "M2PELU"
  bottom: "Eltwise5"
  top: "Eltwise5"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution12"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.25
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm12"
  type: "BatchNorm"
  bottom: "Convolution12"
  top: "Convolution12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale12"
  type: "Scale"
  bottom: "Convolution12"
  top: "Convolution12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution13"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution13"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm13"
  type: "BatchNorm"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale13"
  type: "Scale"
  bottom: "Convolution13"
  top: "Convolution13"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU12"
  type: "M2PELU"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution14"
  type: "Convolution"
  bottom: "Convolution13"
  top: "Convolution14"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm14"
  type: "BatchNorm"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale14"
  type: "Scale"
  bottom: "Convolution14"
  top: "Convolution14"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise6"
  type: "Eltwise"
  bottom: "Convolution12"
  bottom: "Convolution14"
  top: "Eltwise6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU13"
  type: "M2PELU"
  bottom: "Eltwise6"
  top: "Eltwise6"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution15"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution15"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm15"
  type: "BatchNorm"
  bottom: "Convolution15"
  top: "Convolution15"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale15"
  type: "Scale"
  bottom: "Convolution15"
  top: "Convolution15"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU14"
  type: "M2PELU"
  bottom: "Convolution15"
  top: "Convolution15"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution16"
  type: "Convolution"
  bottom: "Convolution15"
  top: "Convolution16"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm16"
  type: "BatchNorm"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale16"
  type: "Scale"
  bottom: "Convolution16"
  top: "Convolution16"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise7"
  type: "Eltwise"
  bottom: "Eltwise6"
  bottom: "Convolution16"
  top: "Eltwise7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU15"
  type: "M2PELU"
  bottom: "Eltwise7"
  top: "Eltwise7"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution17"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution17"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm17"
  type: "BatchNorm"
  bottom: "Convolution17"
  top: "Convolution17"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale17"
  type: "Scale"
  bottom: "Convolution17"
  top: "Convolution17"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU16"
  type: "M2PELU"
  bottom: "Convolution17"
  top: "Convolution17"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution18"
  type: "Convolution"
  bottom: "Convolution17"
  top: "Convolution18"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm18"
  type: "BatchNorm"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale18"
  type: "Scale"
  bottom: "Convolution18"
  top: "Convolution18"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise8"
  type: "Eltwise"
  bottom: "Eltwise7"
  bottom: "Convolution18"
  top: "Eltwise8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU17"
  type: "M2PELU"
  bottom: "Eltwise8"
  top: "Eltwise8"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution19"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution19"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm19"
  type: "BatchNorm"
  bottom: "Convolution19"
  top: "Convolution19"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale19"
  type: "Scale"
  bottom: "Convolution19"
  top: "Convolution19"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU18"
  type: "M2PELU"
  bottom: "Convolution19"
  top: "Convolution19"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution20"
  type: "Convolution"
  bottom: "Convolution19"
  top: "Convolution20"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm20"
  type: "BatchNorm"
  bottom: "Convolution20"
  top: "Convolution20"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale20"
  type: "Scale"
  bottom: "Convolution20"
  top: "Convolution20"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise9"
  type: "Eltwise"
  bottom: "Eltwise8"
  bottom: "Convolution20"
  top: "Eltwise9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU19"
  type: "M2PELU"
  bottom: "Eltwise9"
  top: "Eltwise9"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution21"
  type: "Convolution"
  bottom: "Eltwise9"
  top: "Convolution21"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm21"
  type: "BatchNorm"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale21"
  type: "Scale"
  bottom: "Convolution21"
  top: "Convolution21"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU20"
  type: "M2PELU"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution22"
  type: "Convolution"
  bottom: "Convolution21"
  top: "Convolution22"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm22"
  type: "BatchNorm"
  bottom: "Convolution22"
  top: "Convolution22"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale22"
  type: "Scale"
  bottom: "Convolution22"
  top: "Convolution22"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise10"
  type: "Eltwise"
  bottom: "Eltwise9"
  bottom: "Convolution22"
  top: "Eltwise10"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU21"
  type: "M2PELU"
  bottom: "Eltwise10"
  top: "Eltwise10"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution23"
  type: "Convolution"
  bottom: "Eltwise10"
  top: "Convolution23"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.17677669
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm23"
  type: "BatchNorm"
  bottom: "Convolution23"
  top: "Convolution23"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale23"
  type: "Scale"
  bottom: "Convolution23"
  top: "Convolution23"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution24"
  type: "Convolution"
  bottom: "Eltwise10"
  top: "Convolution24"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm24"
  type: "BatchNorm"
  bottom: "Convolution24"
  top: "Convolution24"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale24"
  type: "Scale"
  bottom: "Convolution24"
  top: "Convolution24"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU22"
  type: "M2PELU"
  bottom: "Convolution24"
  top: "Convolution24"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution25"
  type: "Convolution"
  bottom: "Convolution24"
  top: "Convolution25"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm25"
  type: "BatchNorm"
  bottom: "Convolution25"
  top: "Convolution25"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale25"
  type: "Scale"
  bottom: "Convolution25"
  top: "Convolution25"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise11"
  type: "Eltwise"
  bottom: "Convolution23"
  bottom: "Convolution25"
  top: "Eltwise11"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU23"
  type: "M2PELU"
  bottom: "Eltwise11"
  top: "Eltwise11"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution26"
  type: "Convolution"
  bottom: "Eltwise11"
  top: "Convolution26"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm26"
  type: "BatchNorm"
  bottom: "Convolution26"
  top: "Convolution26"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr
I1007 22:14:28.574940  5299 layer_factory.hpp:77] Creating layer Data1
I1007 22:14:28.575007  5299 db_lmdb.cpp:35] Opened lmdb /home/x306/caffe/xn/PENLU/data/cifar10/cifar10_train_lmdb
I1007 22:14:28.575033  5299 net.cpp:84] Creating Layer Data1
I1007 22:14:28.575039  5299 net.cpp:380] Data1 -> Data1
I1007 22:14:28.575057  5299 net.cpp:380] Data1 -> Data2
I1007 22:14:28.575067  5299 data_transformer.cpp:25] Loading mean file from: /home/x306/caffe/xn/PENLU/data/cifar10/mean.binaryproto
I1007 22:14:28.576524  5299 data_layer.cpp:45] output data size: 100,3,28,28
I1007 22:14:28.595357  5299 net.cpp:122] Setting up Data1
I1007 22:14:28.595388  5299 net.cpp:129] Top shape: 100 3 28 28 (235200)
I1007 22:14:28.595393  5299 net.cpp:129] Top shape: 100 (100)
I1007 22:14:28.595397  5299 net.cpp:137] Memory required for data: 941200
I1007 22:14:28.595407  5299 layer_factory.hpp:77] Creating layer Convolution1
I1007 22:14:28.595429  5299 net.cpp:84] Creating Layer Convolution1
I1007 22:14:28.595444  5299 net.cpp:406] Convolution1 <- Data1
I1007 22:14:28.595466  5299 net.cpp:380] Convolution1 -> Convolution1
I1007 22:14:28.901700  5299 net.cpp:122] Setting up Convolution1
I1007 22:14:28.901726  5299 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:14:28.901729  5299 net.cpp:137] Memory required for data: 5958800
I1007 22:14:28.901751  5299 layer_factory.hpp:77] Creating layer BatchNorm1
I1007 22:14:28.901767  5299 net.cpp:84] Creating Layer BatchNorm1
I1007 22:14:28.901782  5299 net.cpp:406] BatchNorm1 <- Convolution1
I1007 22:14:28.901789  5299 net.cpp:367] BatchNorm1 -> Convolution1 (in-place)
I1007 22:14:28.901917  5299 net.cpp:122] Setting up BatchNorm1
I1007 22:14:28.901923  5299 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:14:28.901926  5299 net.cpp:137] Memory required for data: 10976400
I1007 22:14:28.901949  5299 layer_factory.hpp:77] Creating layer Scale1
I1007 22:14:28.901959  5299 net.cpp:84] Creating Layer Scale1
I1007 22:14:28.901962  5299 net.cpp:406] Scale1 <- Convolution1
I1007 22:14:28.901965  5299 net.cpp:367] Scale1 -> Convolution1 (in-place)
I1007 22:14:28.902025  5299 layer_factory.hpp:77] Creating layer Scale1
I1007 22:14:28.902140  5299 net.cpp:122] Setting up Scale1
I1007 22:14:28.902146  5299 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:14:28.902148  5299 net.cpp:137] Memory required for data: 15994000
I1007 22:14:28.902163  5299 layer_factory.hpp:77] Creating layer M2PELU1
I1007 22:14:28.902173  5299 net.cpp:84] Creating Layer M2PELU1
I1007 22:14:28.902176  5299 net.cpp:406] M2PELU1 <- Convolution1
I1007 22:14:28.902180  5299 net.cpp:367] M2PELU1 -> Convolution1 (in-place)
I1007 22:14:28.902801  5299 net.cpp:122] Setting up M2PELU1
I1007 22:14:28.902811  5299 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:14:28.902814  5299 net.cpp:137] Memory required for data: 21011600
I1007 22:14:28.902832  5299 layer_factory.hpp:77] Creating layer Convolution1_M2PELU1_0_split
I1007 22:14:28.902837  5299 net.cpp:84] Creating Layer Convolution1_M2PELU1_0_split
I1007 22:14:28.902840  5299 net.cpp:406] Convolution1_M2PELU1_0_split <- Convolution1
I1007 22:14:28.902844  5299 net.cpp:380] Convolution1_M2PELU1_0_split -> Convolution1_M2PELU1_0_split_0
I1007 22:14:28.902853  5299 net.cpp:380] Convolution1_M2PELU1_0_split -> Convolution1_M2PELU1_0_split_1
I1007 22:14:28.902889  5299 net.cpp:122] Setting up Convolution1_M2PELU1_0_split
I1007 22:14:28.902894  5299 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:14:28.902900  5299 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:14:28.902904  5299 net.cpp:137] Memory required for data: 31046800
I1007 22:14:28.902907  5299 layer_factory.hpp:77] Creating layer Convolution2
I1007 22:14:28.902917  5299 net.cpp:84] Creating Layer Convolution2
I1007 22:14:28.902921  5299 net.cpp:406] Convolution2 <- Convolution1_M2PELU1_0_split_0
I1007 22:14:28.902926  5299 net.cpp:380] Convolution2 -> Convolution2
I1007 22:14:28.907982  5299 net.cpp:122] Setting up Convolution2
I1007 22:14:28.907994  5299 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:14:28.908007  5299 net.cpp:137] Memory required for data: 36064400
I1007 22:14:28.908013  5299 layer_factory.hpp:77] Creating layer BatchNorm2
I1007 22:14:28.908020  5299 net.cpp:84] Creating Layer BatchNorm2
I1007 22:14:28.908025  5299 net.cpp:406] BatchNorm2 <- Convolution2
I1007 22:14:28.908030  5299 net.cpp:367] BatchNorm2 -> Convolution2 (in-place)
I1007 22:14:28.908159  5299 net.cpp:122] Setting up BatchNorm2
I1007 22:14:28.908165  5299 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:14:28.908169  5299 net.cpp:137] Memory required for data: 41082000
I1007 22:14:28.908179  5299 layer_factory.hpp:77] Creating layer Scale2
I1007 22:14:28.908186  5299 net.cpp:84] Creating Layer Scale2
I1007 22:14:28.908191  5299 net.cpp:406] Scale2 <- Convolution2
I1007 22:14:28.908195  5299 net.cpp:367] Scale2 -> Convolution2 (in-place)
I1007 22:14:28.908224  5299 layer_factory.hpp:77] Creating layer Scale2
I1007 22:14:28.908298  5299 net.cpp:122] Setting up Scale2
I1007 22:14:28.908303  5299 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:14:28.908308  5299 net.cpp:137] Memory required for data: 46099600
I1007 22:14:28.908313  5299 layer_factory.hpp:77] Creating layer M2PELU2
I1007 22:14:28.908320  5299 net.cpp:84] Creating Layer M2PELU2
I1007 22:14:28.908324  5299 net.cpp:406] M2PELU2 <- Convolution2
I1007 22:14:28.908329  5299 net.cpp:367] M2PELU2 -> Convolution2 (in-place)
I1007 22:14:28.908406  5299 net.cpp:122] Setting up M2PELU2
I1007 22:14:28.908418  5299 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:14:28.908423  5299 net.cpp:137] Memory required for data: 51117200
I1007 22:14:28.908432  5299 layer_factory.hpp:77] Creating layer Convolution3
I1007 22:14:28.908440  5299 net.cpp:84] Creating Layer Convolution3
I1007 22:14:28.908444  5299 net.cpp:406] Convolution3 <- Convolution2
I1007 22:14:28.908450  5299 net.cpp:380] Convolution3 -> Convolution3
I1007 22:14:28.914535  5299 net.cpp:122] Setting up Convolution3
I1007 22:14:28.914546  5299 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:14:28.914561  5299 net.cpp:137] Memory required for data: 56134800
I1007 22:14:28.914568  5299 layer_factory.hpp:77] Creating layer BatchNorm3
I1007 22:14:28.914574  5299 net.cpp:84] Creating Layer BatchNorm3
I1007 22:14:28.914579  5299 net.cpp:406] BatchNorm3 <- Convolution3
I1007 22:14:28.914585  5299 net.cpp:367] BatchNorm3 -> Convolution3 (in-place)
I1007 22:14:28.914717  5299 net.cpp:122] Setting up BatchNorm3
I1007 22:14:28.914722  5299 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:14:28.914734  5299 net.cpp:137] Memory required for data: 61152400
I1007 22:14:28.914739  5299 layer_factory.hpp:77] Creating layer Scale3
I1007 22:14:28.914746  5299 net.cpp:84] Creating Layer Scale3
I1007 22:14:28.914748  5299 net.cpp:406] Scale3 <- Convolution3
I1007 22:14:28.914752  5299 net.cpp:367] Scale3 -> Convolution3 (in-place)
I1007 22:14:28.914779  5299 layer_factory.hpp:77] Creating layer Scale3
I1007 22:14:28.914890  5299 net.cpp:122] Setting up Scale3
I1007 22:14:28.914896  5299 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:14:28.914907  5299 net.cpp:137] Memory required for data: 66170000
I1007 22:14:28.914913  5299 layer_factory.hpp:77] Creating layer Eltwise1
I1007 22:14:28.914921  5299 net.cpp:84] Creating Layer Eltwise1
I1007 22:14:28.914927  5299 net.cpp:406] Eltwise1 <- Convolution1_M2PELU1_0_split_1
I1007 22:14:28.914929  5299 net.cpp:406] Eltwise1 <- Convolution3
I1007 22:14:28.914934  5299 net.cpp:380] Eltwise1 -> Eltwise1
I1007 22:14:28.914955  5299 net.cpp:122] Setting up Eltwise1
I1007 22:14:28.914960  5299 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:14:28.914963  5299 net.cpp:137] Memory required for data: 71187600
I1007 22:14:28.914966  5299 layer_factory.hpp:77] Creating layer M2PELU3
I1007 22:14:28.914971  5299 net.cpp:84] Creating Layer M2PELU3
I1007 22:14:28.914974  5299 net.cpp:406] M2PELU3 <- Eltwise1
I1007 22:14:28.914978  5299 net.cpp:367] M2PELU3 -> Eltwise1 (in-place)
I1007 22:14:28.915058  5299 net.cpp:122] Setting up M2PELU3
I1007 22:14:28.915063  5299 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:14:28.915066  5299 net.cpp:137] Memory required for data: 76205200
I1007 22:14:28.915071  5299 layer_factory.hpp:77] Creating layer Eltwise1_M2PELU3_0_split
I1007 22:14:28.915076  5299 net.cpp:84] Creating Layer Eltwise1_M2PELU3_0_split
I1007 22:14:28.915077  5299 net.cpp:406] Eltwise1_M2PELU3_0_split <- Eltwise1
I1007 22:14:28.915081  5299 net.cpp:380] Eltwise1_M2PELU3_0_split -> Eltwise1_M2PELU3_0_split_0
I1007 22:14:28.915086  5299 net.cpp:380] Eltwise1_M2PELU3_0_split -> Eltwise1_M2PELU3_0_split_1
I1007 22:14:28.915107  5299 net.cpp:122] Setting up Eltwise1_M2PELU3_0_split
I1007 22:14:28.915112  5299 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:14:28.915115  5299 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:14:28.915118  5299 net.cpp:137] Memory required for data: 86240400
I1007 22:14:28.915120  5299 layer_factory.hpp:77] Creating layer Convolution4
I1007 22:14:28.915127  5299 net.cpp:84] Creating Layer Convolution4
I1007 22:14:28.915132  5299 net.cpp:406] Convolution4 <- Eltwise1_M2PELU3_0_split_0
I1007 22:14:28.915136  5299 net.cpp:380] Convolution4 -> Convolution4
I1007 22:14:28.921346  5299 net.cpp:122] Setting up Convolution4
I1007 22:14:28.921357  5299 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:14:28.921363  5299 net.cpp:137] Memory required for data: 91258000
I1007 22:14:28.921372  5299 layer_factory.hpp:77] Creating layer BatchNorm4
I1007 22:14:28.921389  5299 net.cpp:84] Creating Layer BatchNorm4
I1007 22:14:28.921394  5299 net.cpp:406] BatchNorm4 <- Convolution4
I1007 22:14:28.921401  5299 net.cpp:367] BatchNorm4 -> Convolution4 (in-place)
I1007 22:14:28.921524  5299 net.cpp:122] Setting up BatchNorm4
I1007 22:14:28.921530  5299 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:14:28.921535  5299 net.cpp:137] Memory required for data: 96275600
I1007 22:14:28.921542  5299 layer_factory.hpp:77] Creating layer Scale4
I1007 22:14:28.921548  5299 net.cpp:84] Creating Layer Scale4
I1007 22:14:28.921552  5299 net.cpp:406] Scale4 <- Convolution4
I1007 22:14:28.921557  5299 net.cpp:367] Scale4 -> Convolution4 (in-place)
I1007 22:14:28.921584  5299 layer_factory.hpp:77] Creating layer Scale4
I1007 22:14:28.921656  5299 net.cpp:122] Setting up Scale4
I1007 22:14:28.921663  5299 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:14:28.921666  5299 net.cpp:137] Memory required for data: 101293200
I1007 22:14:28.921676  5299 layer_factory.hpp:77] Creating layer M2PELU4
I1007 22:14:28.921684  5299 net.cpp:84] Creating Layer M2PELU4
I1007 22:14:28.921686  5299 net.cpp:406] M2PELU4 <- Convolution4
I1007 22:14:28.921692  5299 net.cpp:367] M2PELU4 -> Convolution4 (in-place)
I1007 22:14:28.921773  5299 net.cpp:122] Setting up M2PELU4
I1007 22:14:28.921779  5299 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:14:28.921783  5299 net.cpp:137] Memory required for data: 106310800
I1007 22:14:28.921789  5299 layer_factory.hpp:77] Creating layer Convolution5
I1007 22:14:28.921798  5299 net.cpp:84] Creating Layer Convolution5
I1007 22:14:28.921802  5299 net.cpp:406] Convolution5 <- Convolution4
I1007 22:14:28.921808  5299 net.cpp:380] Convolution5 -> Convolution5
I1007 22:14:28.927897  5299 net.cpp:122] Setting up Convolution5
I1007 22:14:28.927908  5299 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:14:28.927912  5299 net.cpp:137] Memory required for data: 111328400
I1007 22:14:28.927920  5299 layer_factory.hpp:77] Creating layer BatchNorm5
I1007 22:14:28.927927  5299 net.cpp:84] Creating Layer BatchNorm5
I1007 22:14:28.927932  5299 net.cpp:406] BatchNorm5 <- Convolution5
I1007 22:14:28.927937  5299 net.cpp:367] BatchNorm5 -> Convolution5 (in-place)
I1007 22:14:28.928058  5299 net.cpp:122] Setting up BatchNorm5
I1007 22:14:28.928064  5299 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:14:28.928066  5299 net.cpp:137] Memory required for data: 116346000
I1007 22:14:28.928076  5299 layer_factory.hpp:77] Creating layer Scale5
I1007 22:14:28.928081  5299 net.cpp:84] Creating Layer Scale5
I1007 22:14:28.928086  5299 net.cpp:406] Scale5 <- Convolution5
I1007 22:14:28.928089  5299 net.cpp:367] Scale5 -> Convolution5 (in-place)
I1007 22:14:28.928117  5299 layer_factory.hpp:77] Creating layer Scale5
I1007 22:14:28.928192  5299 net.cpp:122] Setting up Scale5
I1007 22:14:28.928197  5299 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:14:28.928200  5299 net.cpp:137] Memory required for data: 121363600
I1007 22:14:28.928206  5299 layer_factory.hpp:77] Creating layer Eltwise2
I1007 22:14:28.928212  5299 net.cpp:84] Creating Layer Eltwise2
I1007 22:14:28.928216  5299 net.cpp:406] Eltwise2 <- Eltwise1_M2PELU3_0_split_1
I1007 22:14:28.928220  5299 net.cpp:406] Eltwise2 <- Convolution5
I1007 22:14:28.928226  5299 net.cpp:380] Eltwise2 -> Eltwise2
I1007 22:14:28.928251  5299 net.cpp:122] Setting up Eltwise2
I1007 22:14:28.928259  5299 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:14:28.928264  5299 net.cpp:137] Memory required for data: 126381200
I1007 22:14:28.928269  5299 layer_factory.hpp:77] Creating layer M2PELU5
I1007 22:14:28.928278  5299 net.cpp:84] Creating Layer M2PELU5
I1007 22:14:28.928283  5299 net.cpp:406] M2PELU5 <- Eltwise2
I1007 22:14:28.928290  5299 net.cpp:367] M2PELU5 -> Eltwise2 (in-place)
I1007 22:14:28.928412  5299 net.cpp:122] Setting up M2PELU5
I1007 22:14:28.928424  5299 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:14:28.928429  5299 net.cpp:137] Memory required for data: 131398800
I1007 22:14:28.928438  5299 layer_factory.hpp:77] Creating layer Eltwise2_M2PELU5_0_split
I1007 22:14:28.928455  5299 net.cpp:84] Creating Layer Eltwise2_M2PELU5_0_split
I1007 22:14:28.928462  5299 net.cpp:406] Eltwise2_M2PELU5_0_split <- Eltwise2
I1007 22:14:28.928468  5299 net.cpp:380] Eltwise2_M2PELU5_0_split -> Eltwise2_M2PELU5_0_split_0
I1007 22:14:28.928478  5299 net.cpp:380] Eltwise2_M2PELU5_0_split -> Eltwise2_M2PELU5_0_split_1
I1007 22:14:28.928506  5299 net.cpp:122] Setting up Eltwise2_M2PELU5_0_split
I1007 22:14:28.928511  5299 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:14:28.928514  5299 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:14:28.928516  5299 net.cpp:137] Memory required for data: 141434000
I1007 22:14:28.928519  5299 layer_factory.hpp:77] Creating layer Convolution6
I1007 22:14:28.928525  5299 net.cpp:84] Creating Layer Convolution6
I1007 22:14:28.928529  5299 net.cpp:406] Convolution6 <- Eltwise2_M2PELU5_0_split_0
I1007 22:14:28.928532  5299 net.cpp:380] Convolution6 -> Convolution6
I1007 22:14:28.935101  5299 net.cpp:122] Setting up Convolution6
I1007 22:14:28.935111  5299 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:14:28.935124  5299 net.cpp:137] Memory required for data: 146451600
I1007 22:14:28.935129  5299 layer_factory.hpp:77] Creating layer BatchNorm6
I1007 22:14:28.935144  5299 net.cpp:84] Creating Layer BatchNorm6
I1007 22:14:28.935148  5299 net.cpp:406] BatchNorm6 <- Convolution6
I1007 22:14:28.935153  5299 net.cpp:367] BatchNorm6 -> Convolution6 (in-place)
I1007 22:14:28.935303  5299 net.cpp:122] Setting up BatchNorm6
I1007 22:14:28.935310  5299 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:14:28.935322  5299 net.cpp:137] Memory required for data: 151469200
I1007 22:14:28.935328  5299 layer_factory.hpp:77] Creating layer Scale6
I1007 22:14:28.935333  5299 net.cpp:84] Creating Layer Scale6
I1007 22:14:28.935338  5299 net.cpp:406] Scale6 <- Convolution6
I1007 22:14:28.935343  5299 net.cpp:367] Scale6 -> Convolution6 (in-place)
I1007 22:14:28.935395  5299 layer_factory.hpp:77] Creating layer Scale6
I1007 22:14:28.935495  5299 net.cpp:122] Setting up Scale6
I1007 22:14:28.935500  5299 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:14:28.935513  5299 net.cpp:137] Memory required for data: 156486800
I1007 22:14:28.935516  5299 layer_factory.hpp:77] Creating layer M2PELU6
I1007 22:14:28.935523  5299 net.cpp:84] Creating Layer M2PELU6
I1007 22:14:28.935529  5299 net.cpp:406] M2PELU6 <- Convolution6
I1007 22:14:28.935535  5299 net.cpp:367] M2PELU6 -> Convolution6 (in-place)
I1007 22:14:28.935626  5299 net.cpp:122] Setting up M2PELU6
I1007 22:14:28.935631  5299 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:14:28.935643  5299 net.cpp:137] Memory required for data: 161504400
I1007 22:14:28.935647  5299 layer_factory.hpp:77] Creating layer Convolution7
I1007 22:14:28.935655  5299 net.cpp:84] Creating Layer Convolution7
I1007 22:14:28.935660  5299 net.cpp:406] Convolution7 <- Convolution6
I1007 22:14:28.935667  5299 net.cpp:380] Convolution7 -> Convolution7
I1007 22:14:28.941706  5299 net.cpp:122] Setting up Convolution7
I1007 22:14:28.941715  5299 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:14:28.941728  5299 net.cpp:137] Memory required for data: 166522000
I1007 22:14:28.941732  5299 layer_factory.hpp:77] Creating layer BatchNorm7
I1007 22:14:28.941738  5299 net.cpp:84] Creating Layer BatchNorm7
I1007 22:14:28.941743  5299 net.cpp:406] BatchNorm7 <- Convolution7
I1007 22:14:28.941750  5299 net.cpp:367] BatchNorm7 -> Convolution7 (in-place)
I1007 22:14:28.941870  5299 net.cpp:122] Setting up BatchNorm7
I1007 22:14:28.941876  5299 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:14:28.941880  5299 net.cpp:137] Memory required for data: 171539600
I1007 22:14:28.941885  5299 layer_factory.hpp:77] Creating layer Scale7
I1007 22:14:28.941893  5299 net.cpp:84] Creating Layer Scale7
I1007 22:14:28.941896  5299 net.cpp:406] Scale7 <- Convolution7
I1007 22:14:28.941900  5299 net.cpp:367] Scale7 -> Convolution7 (in-place)
I1007 22:14:28.941926  5299 layer_factory.hpp:77] Creating layer Scale7
I1007 22:14:28.942006  5299 net.cpp:122] Setting up Scale7
I1007 22:14:28.942013  5299 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:14:28.942016  5299 net.cpp:137] Memory required for data: 176557200
I1007 22:14:28.942020  5299 layer_factory.hpp:77] Creating layer Eltwise3
I1007 22:14:28.942025  5299 net.cpp:84] Creating Layer Eltwise3
I1007 22:14:28.942029  5299 net.cpp:406] Eltwise3 <- Eltwise2_M2PELU5_0_split_1
I1007 22:14:28.942034  5299 net.cpp:406] Eltwise3 <- Convolution7
I1007 22:14:28.942040  5299 net.cpp:380] Eltwise3 -> Eltwise3
I1007 22:14:28.942057  5299 net.cpp:122] Setting up Eltwise3
I1007 22:14:28.942062  5299 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:14:28.942066  5299 net.cpp:137] Memory required for data: 181574800
I1007 22:14:28.942070  5299 layer_factory.hpp:77] Creating layer M2PELU7
I1007 22:14:28.942076  5299 net.cpp:84] Creating Layer M2PELU7
I1007 22:14:28.942080  5299 net.cpp:406] M2PELU7 <- Eltwise3
I1007 22:14:28.942085  5299 net.cpp:367] M2PELU7 -> Eltwise3 (in-place)
I1007 22:14:28.942164  5299 net.cpp:122] Setting up M2PELU7
I1007 22:14:28.942169  5299 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:14:28.942173  5299 net.cpp:137] Memory required for data: 186592400
I1007 22:14:28.942179  5299 layer_factory.hpp:77] Creating layer Eltwise3_M2PELU7_0_split
I1007 22:14:28.942184  5299 net.cpp:84] Creating Layer Eltwise3_M2PELU7_0_split
I1007 22:14:28.942188  5299 net.cpp:406] Eltwise3_M2PELU7_0_split <- Eltwise3
I1007 22:14:28.942193  5299 net.cpp:380] Eltwise3_M2PELU7_0_split -> Eltwise3_M2PELU7_0_split_0
I1007 22:14:28.942200  5299 net.cpp:380] Eltwise3_M2PELU7_0_split -> Eltwise3_M2PELU7_0_split_1
I1007 22:14:28.942222  5299 net.cpp:122] Setting up Eltwise3_M2PELU7_0_split
I1007 22:14:28.942227  5299 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:14:28.942232  5299 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:14:28.942236  5299 net.cpp:137] Memory required for data: 196627600
I1007 22:14:28.942239  5299 layer_factory.hpp:77] Creating layer Convolution8
I1007 22:14:28.942247  5299 net.cpp:84] Creating Layer Convolution8
I1007 22:14:28.942251  5299 net.cpp:406] Convolution8 <- Eltwise3_M2PELU7_0_split_0
I1007 22:14:28.942256  5299 net.cpp:380] Convolution8 -> Convolution8
I1007 22:14:28.948303  5299 net.cpp:122] Setting up Convolution8
I1007 22:14:28.948315  5299 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:14:28.948319  5299 net.cpp:137] Memory required for data: 201645200
I1007 22:14:28.948333  5299 layer_factory.hpp:77] Creating layer BatchNorm8
I1007 22:14:28.948339  5299 net.cpp:84] Creating Layer BatchNorm8
I1007 22:14:28.948344  5299 net.cpp:406] BatchNorm8 <- Convolution8
I1007 22:14:28.948350  5299 net.cpp:367] BatchNorm8 -> Convolution8 (in-place)
I1007 22:14:28.948472  5299 net.cpp:122] Setting up BatchNorm8
I1007 22:14:28.948477  5299 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:14:28.948482  5299 net.cpp:137] Memory required for data: 206662800
I1007 22:14:28.948488  5299 layer_factory.hpp:77] Creating layer Scale8
I1007 22:14:28.948494  5299 net.cpp:84] Creating Layer Scale8
I1007 22:14:28.948498  5299 net.cpp:406] Scale8 <- Convolution8
I1007 22:14:28.948503  5299 net.cpp:367] Scale8 -> Convolution8 (in-place)
I1007 22:14:28.948529  5299 layer_factory.hpp:77] Creating layer Scale8
I1007 22:14:28.948601  5299 net.cpp:122] Setting up Scale8
I1007 22:14:28.948606  5299 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:14:28.948611  5299 net.cpp:137] Memory required for data: 211680400
I1007 22:14:28.948616  5299 layer_factory.hpp:77] Creating layer M2PELU8
I1007 22:14:28.948623  5299 net.cpp:84] Creating Layer M2PELU8
I1007 22:14:28.948626  5299 net.cpp:406] M2PELU8 <- Convolution8
I1007 22:14:28.948632  5299 net.cpp:367] M2PELU8 -> Convolution8 (in-place)
I1007 22:14:28.948711  5299 net.cpp:122] Setting up M2PELU8
I1007 22:14:28.948716  5299 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:14:28.948721  5299 net.cpp:137] Memory required for data: 216698000
I1007 22:14:28.948734  5299 layer_factory.hpp:77] Creating layer Convolution9
I1007 22:14:28.948743  5299 net.cpp:84] Creating Layer Convolution9
I1007 22:14:28.948747  5299 net.cpp:406] Convolution9 <- Convolution8
I1007 22:14:28.948753  5299 net.cpp:380] Convolution9 -> Convolution9
I1007 22:14:28.952875  5299 net.cpp:122] Setting up Convolution9
I1007 22:14:28.952885  5299 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:14:28.952890  5299 net.cpp:137] Memory required for data: 221715600
I1007 22:14:28.952898  5299 layer_factory.hpp:77] Creating layer BatchNorm9
I1007 22:14:28.952904  5299 net.cpp:84] Creating Layer BatchNorm9
I1007 22:14:28.952908  5299 net.cpp:406] BatchNorm9 <- Convolution9
I1007 22:14:28.952914  5299 net.cpp:367] BatchNorm9 -> Convolution9 (in-place)
I1007 22:14:28.953034  5299 net.cpp:122] Setting up BatchNorm9
I1007 22:14:28.953040  5299 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:14:28.953044  5299 net.cpp:137] Memory required for data: 226733200
I1007 22:14:28.953052  5299 layer_factory.hpp:77] Creating layer Scale9
I1007 22:14:28.953058  5299 net.cpp:84] Creating Layer Scale9
I1007 22:14:28.953061  5299 net.cpp:406] Scale9 <- Convolution9
I1007 22:14:28.953066  5299 net.cpp:367] Scale9 -> Convolution9 (in-place)
I1007 22:14:28.953094  5299 layer_factory.hpp:77] Creating layer Scale9
I1007 22:14:28.953166  5299 net.cpp:122] Setting up Scale9
I1007 22:14:28.953171  5299 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:14:28.953176  5299 net.cpp:137] Memory required for data: 231750800
I1007 22:14:28.953181  5299 layer_factory.hpp:77] Creating layer Eltwise4
I1007 22:14:28.953186  5299 net.cpp:84] Creating Layer Eltwise4
I1007 22:14:28.953191  5299 net.cpp:406] Eltwise4 <- Eltwise3_M2PELU7_0_split_1
I1007 22:14:28.953196  5299 net.cpp:406] Eltwise4 <- Convolution9
I1007 22:14:28.953200  5299 net.cpp:380] Eltwise4 -> Eltwise4
I1007 22:14:28.953217  5299 net.cpp:122] Setting up Eltwise4
I1007 22:14:28.953222  5299 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:14:28.953227  5299 net.cpp:137] Memory required for data: 236768400
I1007 22:14:28.953229  5299 layer_factory.hpp:77] Creating layer M2PELU9
I1007 22:14:28.953236  5299 net.cpp:84] Creating Layer M2PELU9
I1007 22:14:28.953239  5299 net.cpp:406] M2PELU9 <- Eltwise4
I1007 22:14:28.953245  5299 net.cpp:367] M2PELU9 -> Eltwise4 (in-place)
I1007 22:14:28.953325  5299 net.cpp:122] Setting up M2PELU9
I1007 22:14:28.953330  5299 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:14:28.953335  5299 net.cpp:137] Memory required for data: 241786000
I1007 22:14:28.953341  5299 layer_factory.hpp:77] Creating layer Eltwise4_M2PELU9_0_split
I1007 22:14:28.953346  5299 net.cpp:84] Creating Layer Eltwise4_M2PELU9_0_split
I1007 22:14:28.953349  5299 net.cpp:406] Eltwise4_M2PELU9_0_split <- Eltwise4
I1007 22:14:28.953356  5299 net.cpp:380] Eltwise4_M2PELU9_0_split -> Eltwise4_M2PELU9_0_split_0
I1007 22:14:28.953361  5299 net.cpp:380] Eltwise4_M2PELU9_0_split -> Eltwise4_M2PELU9_0_split_1
I1007 22:14:28.953384  5299 net.cpp:122] Setting up Eltwise4_M2PELU9_0_split
I1007 22:14:28.953389  5299 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:14:28.953394  5299 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:14:28.953398  5299 net.cpp:137] Memory required for data: 251821200
I1007 22:14:28.953402  5299 layer_factory.hpp:77] Creating layer Convolution10
I1007 22:14:28.953409  5299 net.cpp:84] Creating Layer Convolution10
I1007 22:14:28.953413  5299 net.cpp:406] Convolution10 <- Eltwise4_M2PELU9_0_split_0
I1007 22:14:28.953418  5299 net.cpp:380] Convolution10 -> Convolution10
I1007 22:14:28.954237  5299 net.cpp:122] Setting up Convolution10
I1007 22:14:28.954248  5299 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:14:28.954253  5299 net.cpp:137] Memory required for data: 256838800
I1007 22:14:28.954259  5299 layer_factory.hpp:77] Creating layer BatchNorm10
I1007 22:14:28.954267  5299 net.cpp:84] Creating Layer BatchNorm10
I1007 22:14:28.954269  5299 net.cpp:406] BatchNorm10 <- Convolution10
I1007 22:14:28.954282  5299 net.cpp:367] BatchNorm10 -> Convolution10 (in-place)
I1007 22:14:28.954407  5299 net.cpp:122] Setting up BatchNorm10
I1007 22:14:28.954412  5299 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:14:28.954417  5299 net.cpp:137] Memory required for data: 261856400
I1007 22:14:28.954424  5299 layer_factory.hpp:77] Creating layer Scale10
I1007 22:14:28.954429  5299 net.cpp:84] Creating Layer Scale10
I1007 22:14:28.954433  5299 net.cpp:406] Scale10 <- Convolution10
I1007 22:14:28.954438  5299 net.cpp:367] Scale10 -> Convolution10 (in-place)
I1007 22:14:28.954465  5299 layer_factory.hpp:77] Creating layer Scale10
I1007 22:14:28.954537  5299 net.cpp:122] Setting up Scale10
I1007 22:14:28.954542  5299 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:14:28.954545  5299 net.cpp:137] Memory required for data: 266874000
I1007 22:14:28.954551  5299 layer_factory.hpp:77] Creating layer M2PELU10
I1007 22:14:28.954558  5299 net.cpp:84] Creating Layer M2PELU10
I1007 22:14:28.954562  5299 net.cpp:406] M2PELU10 <- Convolution10
I1007 22:14:28.954566  5299 net.cpp:367] M2PELU10 -> Convolution10 (in-place)
I1007 22:14:28.954650  5299 net.cpp:122] Setting up M2PELU10
I1007 22:14:28.954655  5299 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:14:28.954658  5299 net.cpp:137] Memory required for data: 271891600
I1007 22:14:28.954664  5299 layer_factory.hpp:77] Creating layer Convolution11
I1007 22:14:28.954674  5299 net.cpp:84] Creating Layer Convolution11
I1007 22:14:28.954676  5299 net.cpp:406] Convolution11 <- Convolution10
I1007 22:14:28.954681  5299 net.cpp:380] Convolution11 -> Convolution11
I1007 22:14:28.958995  5299 net.cpp:122] Setting up Convolution11
I1007 22:14:28.959007  5299 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:14:28.959010  5299 net.cpp:137] Memory required for data: 276909200
I1007 22:14:28.959017  5299 layer_factory.hpp:77] Creating layer BatchNorm11
I1007 22:14:28.959024  5299 net.cpp:84] Creating Layer BatchNorm11
I1007 22:14:28.959028  5299 net.cpp:406] BatchNorm11 <- Convolution11
I1007 22:14:28.959034  5299 net.cpp:367] BatchNorm11 -> Convolution11 (in-place)
I1007 22:14:28.959157  5299 net.cpp:122] Setting up BatchNorm11
I1007 22:14:28.959162  5299 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:14:28.959185  5299 net.cpp:137] Memory required for data: 281926800
I1007 22:14:28.959194  5299 layer_factory.hpp:77] Creating layer Scale11
I1007 22:14:28.959209  5299 net.cpp:84] Creating Layer Scale11
I1007 22:14:28.959213  5299 net.cpp:406] Scale11 <- Convolution11
I1007 22:14:28.959219  5299 net.cpp:367] Scale11 -> Convolution11 (in-place)
I1007 22:14:28.959247  5299 layer_factory.hpp:77] Creating layer Scale11
I1007 22:14:28.959323  5299 net.cpp:122] Setting up Scale11
I1007 22:14:28.959328  5299 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:14:28.959332  5299 net.cpp:137] Memory required for data: 286944400
I1007 22:14:28.959339  5299 layer_factory.hpp:77] Creating layer Eltwise5
I1007 22:14:28.959345  5299 net.cpp:84] Creating Layer Eltwise5
I1007 22:14:28.959349  5299 net.cpp:406] Eltwise5 <- Eltwise4_M2PELU9_0_split_1
I1007 22:14:28.959354  5299 net.cpp:406] Eltwise5 <- Convolution11
I1007 22:14:28.959360  5299 net.cpp:380] Eltwise5 -> Eltwise5
I1007 22:14:28.959378  5299 net.cpp:122] Setting up Eltwise5
I1007 22:14:28.959383  5299 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:14:28.959386  5299 net.cpp:137] Memory required for data: 291962000
I1007 22:14:28.959390  5299 layer_factory.hpp:77] Creating layer M2PELU11
I1007 22:14:28.959398  5299 net.cpp:84] Creating Layer M2PELU11
I1007 22:14:28.959400  5299 net.cpp:406] M2PELU11 <- Eltwise5
I1007 22:14:28.959406  5299 net.cpp:367] M2PELU11 -> Eltwise5 (in-place)
I1007 22:14:28.959491  5299 net.cpp:122] Setting up M2PELU11
I1007 22:14:28.959496  5299 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:14:28.959499  5299 net.cpp:137] Memory required for data: 296979600
I1007 22:14:28.959506  5299 layer_factory.hpp:77] Creating layer Eltwise5_M2PELU11_0_split
I1007 22:14:28.959511  5299 net.cpp:84] Creating Layer Eltwise5_M2PELU11_0_split
I1007 22:14:28.959522  5299 net.cpp:406] Eltwise5_M2PELU11_0_split <- Eltwise5
I1007 22:14:28.959529  5299 net.cpp:380] Eltwise5_M2PELU11_0_split -> Eltwise5_M2PELU11_0_split_0
I1007 22:14:28.959537  5299 net.cpp:380] Eltwise5_M2PELU11_0_split -> Eltwise5_M2PELU11_0_split_1
I1007 22:14:28.959561  5299 net.cpp:122] Setting up Eltwise5_M2PELU11_0_split
I1007 22:14:28.959566  5299 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:14:28.959570  5299 net.cpp:129] Top shape: 100 16 28 28 (1254400)
I1007 22:14:28.959575  5299 net.cpp:137] Memory required for data: 307014800
I1007 22:14:28.959579  5299 layer_factory.hpp:77] Creating layer Convolution12
I1007 22:14:28.959589  5299 net.cpp:84] Creating Layer Convolution12
I1007 22:14:28.959591  5299 net.cpp:406] Convolution12 <- Eltwise5_M2PELU11_0_split_0
I1007 22:14:28.959597  5299 net.cpp:380] Convolution12 -> Convolution12
I1007 22:14:28.966353  5299 net.cpp:122] Setting up Convolution12
I1007 22:14:28.966365  5299 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:14:28.966378  5299 net.cpp:137] Memory required for data: 309523600
I1007 22:14:28.966384  5299 layer_factory.hpp:77] Creating layer BatchNorm12
I1007 22:14:28.966395  5299 net.cpp:84] Creating Layer BatchNorm12
I1007 22:14:28.966398  5299 net.cpp:406] BatchNorm12 <- Convolution12
I1007 22:14:28.966413  5299 net.cpp:367] BatchNorm12 -> Convolution12 (in-place)
I1007 22:14:28.966567  5299 net.cpp:122] Setting up BatchNorm12
I1007 22:14:28.966573  5299 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:14:28.966585  5299 net.cpp:137] Memory required for data: 312032400
I1007 22:14:28.966591  5299 layer_factory.hpp:77] Creating layer Scale12
I1007 22:14:28.966599  5299 net.cpp:84] Creating Layer Scale12
I1007 22:14:28.966603  5299 net.cpp:406] Scale12 <- Convolution12
I1007 22:14:28.966606  5299 net.cpp:367] Scale12 -> Convolution12 (in-place)
I1007 22:14:28.966647  5299 layer_factory.hpp:77] Creating layer Scale12
I1007 22:14:28.966742  5299 net.cpp:122] Setting up Scale12
I1007 22:14:28.966747  5299 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:14:28.966759  5299 net.cpp:137] Memory required for data: 314541200
I1007 22:14:28.966764  5299 layer_factory.hpp:77] Creating layer Convolution13
I1007 22:14:28.966773  5299 net.cpp:84] Creating Layer Convolution13
I1007 22:14:28.966776  5299 net.cpp:406] Convolution13 <- Eltwise5_M2PELU11_0_split_1
I1007 22:14:28.966784  5299 net.cpp:380] Convolution13 -> Convolution13
I1007 22:14:28.973196  5299 net.cpp:122] Setting up Convolution13
I1007 22:14:28.973206  5299 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:14:28.973212  5299 net.cpp:137] Memory required for data: 317050000
I1007 22:14:28.973219  5299 layer_factory.hpp:77] Creating layer BatchNorm13
I1007 22:14:28.973227  5299 net.cpp:84] Creating Layer BatchNorm13
I1007 22:14:28.973232  5299 net.cpp:406] BatchNorm13 <- Convolution13
I1007 22:14:28.973238  5299 net.cpp:367] BatchNorm13 -> Convolution13 (in-place)
I1007 22:14:28.973372  5299 net.cpp:122] Setting up BatchNorm13
I1007 22:14:28.973378  5299 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:14:28.973382  5299 net.cpp:137] Memory required for data: 319558800
I1007 22:14:28.973390  5299 layer_factory.hpp:77] Creating layer Scale13
I1007 22:14:28.973397  5299 net.cpp:84] Creating Layer Scale13
I1007 22:14:28.973402  5299 net.cpp:406] Scale13 <- Convolution13
I1007 22:14:28.973407  5299 net.cpp:367] Scale13 -> Convolution13 (in-place)
I1007 22:14:28.973436  5299 layer_factory.hpp:77] Creating layer Scale13
I1007 22:14:28.973515  5299 net.cpp:122] Setting up Scale13
I1007 22:14:28.973520  5299 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:14:28.973523  5299 net.cpp:137] Memory required for data: 322067600
I1007 22:14:28.973531  5299 layer_factory.hpp:77] Creating layer M2PELU12
I1007 22:14:28.973538  5299 net.cpp:84] Creating Layer M2PELU12
I1007 22:14:28.973542  5299 net.cpp:406] M2PELU12 <- Convolution13
I1007 22:14:28.973548  5299 net.cpp:367] M2PELU12 -> Convolution13 (in-place)
I1007 22:14:28.973639  5299 net.cpp:122] Setting up M2PELU12
I1007 22:14:28.973644  5299 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:14:28.973649  5299 net.cpp:137] Memory required for data: 324576400
I1007 22:14:28.973654  5299 layer_factory.hpp:77] Creating layer Convolution14
I1007 22:14:28.973664  5299 net.cpp:84] Creating Layer Convolution14
I1007 22:14:28.973666  5299 net.cpp:406] Convolution14 <- Convolution13
I1007 22:14:28.973673  5299 net.cpp:380] Convolution14 -> Convolution14
I1007 22:14:28.974876  5299 net.cpp:122] Setting up Convolution14
I1007 22:14:28.974889  5299 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:14:28.974894  5299 net.cpp:137] Memory required for data: 327085200
I1007 22:14:28.974901  5299 layer_factory.hpp:77] Creating layer BatchNorm14
I1007 22:14:28.974912  5299 net.cpp:84] Creating Layer BatchNorm14
I1007 22:14:28.974916  5299 net.cpp:406] BatchNorm14 <- Convolution14
I1007 22:14:28.974922  5299 net.cpp:367] BatchNorm14 -> Convolution14 (in-place)
I1007 22:14:28.975051  5299 net.cpp:122] Setting up BatchNorm14
I1007 22:14:28.975056  5299 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:14:28.975061  5299 net.cpp:137] Memory required for data: 329594000
I1007 22:14:28.975069  5299 layer_factory.hpp:77] Creating layer Scale14
I1007 22:14:28.975076  5299 net.cpp:84] Creating Layer Scale14
I1007 22:14:28.975080  5299 net.cpp:406] Scale14 <- Convolution14
I1007 22:14:28.975085  5299 net.cpp:367] Scale14 -> Convolution14 (in-place)
I1007 22:14:28.975114  5299 layer_factory.hpp:77] Creating layer Scale14
I1007 22:14:28.975216  5299 net.cpp:122] Setting up Scale14
I1007 22:14:28.975224  5299 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:14:28.975227  5299 net.cpp:137] Memory required for data: 332102800
I1007 22:14:28.975234  5299 layer_factory.hpp:77] Creating layer Eltwise6
I1007 22:14:28.975241  5299 net.cpp:84] Creating Layer Eltwise6
I1007 22:14:28.975244  5299 net.cpp:406] Eltwise6 <- Convolution12
I1007 22:14:28.975250  5299 net.cpp:406] Eltwise6 <- Convolution14
I1007 22:14:28.975255  5299 net.cpp:380] Eltwise6 -> Eltwise6
I1007 22:14:28.975273  5299 net.cpp:122] Setting up Eltwise6
I1007 22:14:28.975278  5299 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:14:28.975282  5299 net.cpp:137] Memory required for data: 334611600
I1007 22:14:28.975286  5299 layer_factory.hpp:77] Creating layer M2PELU13
I1007 22:14:28.975294  5299 net.cpp:84] Creating Layer M2PELU13
I1007 22:14:28.975297  5299 net.cpp:406] M2PELU13 <- Eltwise6
I1007 22:14:28.975302  5299 net.cpp:367] M2PELU13 -> Eltwise6 (in-place)
I1007 22:14:28.975388  5299 net.cpp:122] Setting up M2PELU13
I1007 22:14:28.975394  5299 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:14:28.975397  5299 net.cpp:137] Memory required for data: 337120400
I1007 22:14:28.975404  5299 layer_factory.hpp:77] Creating layer Eltwise6_M2PELU13_0_split
I1007 22:14:28.975409  5299 net.cpp:84] Creating Layer Eltwise6_M2PELU13_0_split
I1007 22:14:28.975412  5299 net.cpp:406] Eltwise6_M2PELU13_0_split <- Eltwise6
I1007 22:14:28.975419  5299 net.cpp:380] Eltwise6_M2PELU13_0_split -> Eltwise6_M2PELU13_0_split_0
I1007 22:14:28.975425  5299 net.cpp:380] Eltwise6_M2PELU13_0_split -> Eltwise6_M2PELU13_0_split_1
I1007 22:14:28.975451  5299 net.cpp:122] Setting up Eltwise6_M2PELU13_0_split
I1007 22:14:28.975456  5299 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:14:28.975461  5299 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:14:28.975466  5299 net.cpp:137] Memory required for data: 342138000
I1007 22:14:28.975468  5299 layer_factory.hpp:77] Creating layer Convolution15
I1007 22:14:28.975477  5299 net.cpp:84] Creating Layer Convolution15
I1007 22:14:28.975481  5299 net.cpp:406] Convolution15 <- Eltwise6_M2PELU13_0_split_0
I1007 22:14:28.975487  5299 net.cpp:380] Convolution15 -> Convolution15
I1007 22:14:28.979423  5299 net.cpp:122] Setting up Convolution15
I1007 22:14:28.979434  5299 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:14:28.979439  5299 net.cpp:137] Memory required for data: 344646800
I1007 22:14:28.979454  5299 layer_factory.hpp:77] Creating layer BatchNorm15
I1007 22:14:28.979460  5299 net.cpp:84] Creating Layer BatchNorm15
I1007 22:14:28.979465  5299 net.cpp:406] BatchNorm15 <- Convolution15
I1007 22:14:28.979471  5299 net.cpp:367] BatchNorm15 -> Convolution15 (in-place)
I1007 22:14:28.979604  5299 net.cpp:122] Setting up BatchNorm15
I1007 22:14:28.979609  5299 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:14:28.979614  5299 net.cpp:137] Memory required for data: 347155600
I1007 22:14:28.979630  5299 layer_factory.hpp:77] Creating layer Scale15
I1007 22:14:28.979637  5299 net.cpp:84] Creating Layer Scale15
I1007 22:14:28.979641  5299 net.cpp:406] Scale15 <- Convolution15
I1007 22:14:28.979647  5299 net.cpp:367] Scale15 -> Convolution15 (in-place)
I1007 22:14:28.979678  5299 layer_factory.hpp:77] Creating layer Scale15
I1007 22:14:28.979755  5299 net.cpp:122] Setting up Scale15
I1007 22:14:28.979760  5299 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:14:28.979764  5299 net.cpp:137] Memory required for data: 349664400
I1007 22:14:28.979771  5299 layer_factory.hpp:77] Creating layer M2PELU14
I1007 22:14:28.979777  5299 net.cpp:84] Creating Layer M2PELU14
I1007 22:14:28.979780  5299 net.cpp:406] M2PELU14 <- Convolution15
I1007 22:14:28.979786  5299 net.cpp:367] M2PELU14 -> Convolution15 (in-place)
I1007 22:14:28.979871  5299 net.cpp:122] Setting up M2PELU14
I1007 22:14:28.979876  5299 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:14:28.979881  5299 net.cpp:137] Memory required for data: 352173200
I1007 22:14:28.979887  5299 layer_factory.hpp:77] Creating layer Convolution16
I1007 22:14:28.979895  5299 net.cpp:84] Creating Layer Convolution16
I1007 22:14:28.979899  5299 net.cpp:406] Convolution16 <- Convolution15
I1007 22:14:28.979907  5299 net.cpp:380] Convolution16 -> Convolution16
I1007 22:14:28.985973  5299 net.cpp:122] Setting up Convolution16
I1007 22:14:28.985983  5299 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:14:28.985990  5299 net.cpp:137] Memory required for data: 354682000
I1007 22:14:28.985996  5299 layer_factory.hpp:77] Creating layer BatchNorm16
I1007 22:14:28.986004  5299 net.cpp:84] Creating Layer BatchNorm16
I1007 22:14:28.986008  5299 net.cpp:406] BatchNorm16 <- Convolution16
I1007 22:14:28.986014  5299 net.cpp:367] BatchNorm16 -> Convolution16 (in-place)
I1007 22:14:28.986145  5299 net.cpp:122] Setting up BatchNorm16
I1007 22:14:28.986150  5299 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:14:28.986155  5299 net.cpp:137] Memory required for data: 357190800
I1007 22:14:28.986162  5299 layer_factory.hpp:77] Creating layer Scale16
I1007 22:14:28.986167  5299 net.cpp:84] Creating Layer Scale16
I1007 22:14:28.986171  5299 net.cpp:406] Scale16 <- Convolution16
I1007 22:14:28.986178  5299 net.cpp:367] Scale16 -> Convolution16 (in-place)
I1007 22:14:28.986207  5299 layer_factory.hpp:77] Creating layer Scale16
I1007 22:14:28.986285  5299 net.cpp:122] Setting up Scale16
I1007 22:14:28.986291  5299 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:14:28.986295  5299 net.cpp:137] Memory required for data: 359699600
I1007 22:14:28.986302  5299 layer_factory.hpp:77] Creating layer Eltwise7
I1007 22:14:28.986307  5299 net.cpp:84] Creating Layer Eltwise7
I1007 22:14:28.986311  5299 net.cpp:406] Eltwise7 <- Eltwise6_M2PELU13_0_split_1
I1007 22:14:28.986317  5299 net.cpp:406] Eltwise7 <- Convolution16
I1007 22:14:28.986322  5299 net.cpp:380] Eltwise7 -> Eltwise7
I1007 22:14:28.986342  5299 net.cpp:122] Setting up Eltwise7
I1007 22:14:28.986347  5299 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:14:28.986351  5299 net.cpp:137] Memory required for data: 362208400
I1007 22:14:28.986354  5299 layer_factory.hpp:77] Creating layer M2PELU15
I1007 22:14:28.986361  5299 net.cpp:84] Creating Layer M2PELU15
I1007 22:14:28.986364  5299 net.cpp:406] M2PELU15 <- Eltwise7
I1007 22:14:28.986371  5299 net.cpp:367] M2PELU15 -> Eltwise7 (in-place)
I1007 22:14:28.986452  5299 net.cpp:122] Setting up M2PELU15
I1007 22:14:28.986459  5299 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:14:28.986469  5299 net.cpp:137] Memory required for data: 364717200
I1007 22:14:28.986476  5299 layer_factory.hpp:77] Creating layer Eltwise7_M2PELU15_0_split
I1007 22:14:28.986484  5299 net.cpp:84] Creating Layer Eltwise7_M2PELU15_0_split
I1007 22:14:28.986486  5299 net.cpp:406] Eltwise7_M2PELU15_0_split <- Eltwise7
I1007 22:14:28.986492  5299 net.cpp:380] Eltwise7_M2PELU15_0_split -> Eltwise7_M2PELU15_0_split_0
I1007 22:14:28.986498  5299 net.cpp:380] Eltwise7_M2PELU15_0_split -> Eltwise7_M2PELU15_0_split_1
I1007 22:14:28.986526  5299 net.cpp:122] Setting up Eltwise7_M2PELU15_0_split
I1007 22:14:28.986531  5299 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:14:28.986536  5299 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:14:28.986539  5299 net.cpp:137] Memory required for data: 369734800
I1007 22:14:28.986543  5299 layer_factory.hpp:77] Creating layer Convolution17
I1007 22:14:28.986552  5299 net.cpp:84] Creating Layer Convolution17
I1007 22:14:28.986555  5299 net.cpp:406] Convolution17 <- Eltwise7_M2PELU15_0_split_0
I1007 22:14:28.986562  5299 net.cpp:380] Convolution17 -> Convolution17
I1007 22:14:28.992590  5299 net.cpp:122] Setting up Convolution17
I1007 22:14:28.992601  5299 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:14:28.992614  5299 net.cpp:137] Memory required for data: 372243600
I1007 22:14:28.992620  5299 layer_factory.hpp:77] Creating layer BatchNorm17
I1007 22:14:28.992628  5299 net.cpp:84] Creating Layer BatchNorm17
I1007 22:14:28.992633  5299 net.cpp:406] BatchNorm17 <- Convolution17
I1007 22:14:28.992638  5299 net.cpp:367] BatchNorm17 -> Convolution17 (in-place)
I1007 22:14:28.992781  5299 net.cpp:122] Setting up BatchNorm17
I1007 22:14:28.992787  5299 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:14:28.992789  5299 net.cpp:137] Memory required for data: 374752400
I1007 22:14:28.992805  5299 layer_factory.hpp:77] Creating layer Scale17
I1007 22:14:28.992810  5299 net.cpp:84] Creating Layer Scale17
I1007 22:14:28.992811  5299 net.cpp:406] Scale17 <- Convolution17
I1007 22:14:28.992815  5299 net.cpp:367] Scale17 -> Convolution17 (in-place)
I1007 22:14:28.992841  5299 layer_factory.hpp:77] Creating layer Scale17
I1007 22:14:28.992925  5299 net.cpp:122] Setting up Scale17
I1007 22:14:28.992930  5299 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:14:28.992933  5299 net.cpp:137] Memory required for data: 377261200
I1007 22:14:28.992946  5299 layer_factory.hpp:77] Creating layer M2PELU16
I1007 22:14:28.992954  5299 net.cpp:84] Creating Layer M2PELU16
I1007 22:14:28.992957  5299 net.cpp:406] M2PELU16 <- Convolution17
I1007 22:14:28.992964  5299 net.cpp:367] M2PELU16 -> Convolution17 (in-place)
I1007 22:14:28.993053  5299 net.cpp:122] Setting up M2PELU16
I1007 22:14:28.993059  5299 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:14:28.993063  5299 net.cpp:137] Memory required for data: 379770000
I1007 22:14:28.993067  5299 layer_factory.hpp:77] Creating layer Convolution18
I1007 22:14:28.993077  5299 net.cpp:84] Creating Layer Convolution18
I1007 22:14:28.993080  5299 net.cpp:406] Convolution18 <- Convolution17
I1007 22:14:28.993084  5299 net.cpp:380] Convolution18 -> Convolution18
I1007 22:14:28.999758  5299 net.cpp:122] Setting up Convolution18
I1007 22:14:28.999768  5299 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:14:28.999781  5299 net.cpp:137] Memory required for data: 382278800
I1007 22:14:28.999786  5299 layer_factory.hpp:77] Creating layer BatchNorm18
I1007 22:14:28.999794  5299 net.cpp:84] Creating Layer BatchNorm18
I1007 22:14:28.999799  5299 net.cpp:406] BatchNorm18 <- Convolution18
I1007 22:14:28.999802  5299 net.cpp:367] BatchNorm18 -> Convolution18 (in-place)
I1007 22:14:28.999943  5299 net.cpp:122] Setting up BatchNorm18
I1007 22:14:28.999948  5299 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:14:28.999961  5299 net.cpp:137] Memory required for data: 384787600
I1007 22:14:28.999966  5299 layer_factory.hpp:77] Creating layer Scale18
I1007 22:14:28.999971  5299 net.cpp:84] Creating Layer Scale18
I1007 22:14:28.999984  5299 net.cpp:406] Scale18 <- Convolution18
I1007 22:14:28.999989  5299 net.cpp:367] Scale18 -> Convolution18 (in-place)
I1007 22:14:29.000030  5299 layer_factory.hpp:77] Creating layer Scale18
I1007 22:14:29.000128  5299 net.cpp:122] Setting up Scale18
I1007 22:14:29.000133  5299 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:14:29.000145  5299 net.cpp:137] Memory required for data: 387296400
I1007 22:14:29.000149  5299 layer_factory.hpp:77] Creating layer Eltwise8
I1007 22:14:29.000155  5299 net.cpp:84] Creating Layer Eltwise8
I1007 22:14:29.000159  5299 net.cpp:406] Eltwise8 <- Eltwise7_M2PELU15_0_split_1
I1007 22:14:29.000164  5299 net.cpp:406] Eltwise8 <- Convolution18
I1007 22:14:29.000169  5299 net.cpp:380] Eltwise8 -> Eltwise8
I1007 22:14:29.000197  5299 net.cpp:122] Setting up Eltwise8
I1007 22:14:29.000201  5299 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:14:29.000205  5299 net.cpp:137] Memory required for data: 389805200
I1007 22:14:29.000216  5299 layer_factory.hpp:77] Creating layer M2PELU17
I1007 22:14:29.000221  5299 net.cpp:84] Creating Layer M2PELU17
I1007 22:14:29.000224  5299 net.cpp:406] M2PELU17 <- Eltwise8
I1007 22:14:29.000229  5299 net.cpp:367] M2PELU17 -> Eltwise8 (in-place)
I1007 22:14:29.000313  5299 net.cpp:122] Setting up M2PELU17
I1007 22:14:29.000320  5299 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:14:29.000324  5299 net.cpp:137] Memory required for data: 392314000
I1007 22:14:29.000329  5299 layer_factory.hpp:77] Creating layer Eltwise8_M2PELU17_0_split
I1007 22:14:29.000334  5299 net.cpp:84] Creating Layer Eltwise8_M2PELU17_0_split
I1007 22:14:29.000337  5299 net.cpp:406] Eltwise8_M2PELU17_0_split <- Eltwise8
I1007 22:14:29.000344  5299 net.cpp:380] Eltwise8_M2PELU17_0_split -> Eltwise8_M2PELU17_0_split_0
I1007 22:14:29.000349  5299 net.cpp:380] Eltwise8_M2PELU17_0_split -> Eltwise8_M2PELU17_0_split_1
I1007 22:14:29.000375  5299 net.cpp:122] Setting up Eltwise8_M2PELU17_0_split
I1007 22:14:29.000380  5299 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:14:29.000385  5299 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:14:29.000389  5299 net.cpp:137] Memory required for data: 397331600
I1007 22:14:29.000393  5299 layer_factory.hpp:77] Creating layer Convolution19
I1007 22:14:29.000403  5299 net.cpp:84] Creating Layer Convolution19
I1007 22:14:29.000406  5299 net.cpp:406] Convolution19 <- Eltwise8_M2PELU17_0_split_0
I1007 22:14:29.000413  5299 net.cpp:380] Convolution19 -> Convolution19
I1007 22:14:29.006635  5299 net.cpp:122] Setting up Convolution19
I1007 22:14:29.006646  5299 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:14:29.006651  5299 net.cpp:137] Memory required for data: 399840400
I1007 22:14:29.006660  5299 layer_factory.hpp:77] Creating layer BatchNorm19
I1007 22:14:29.006666  5299 net.cpp:84] Creating Layer BatchNorm19
I1007 22:14:29.006670  5299 net.cpp:406] BatchNorm19 <- Convolution19
I1007 22:14:29.006678  5299 net.cpp:367] BatchNorm19 -> Convolution19 (in-place)
I1007 22:14:29.006814  5299 net.cpp:122] Setting up BatchNorm19
I1007 22:14:29.006821  5299 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:14:29.006825  5299 net.cpp:137] Memory required for data: 402349200
I1007 22:14:29.006834  5299 layer_factory.hpp:77] Creating layer Scale19
I1007 22:14:29.006839  5299 net.cpp:84] Creating Layer Scale19
I1007 22:14:29.006844  5299 net.cpp:406] Scale19 <- Convolution19
I1007 22:14:29.006849  5299 net.cpp:367] Scale19 -> Convolution19 (in-place)
I1007 22:14:29.006878  5299 layer_factory.hpp:77] Creating layer Scale19
I1007 22:14:29.006958  5299 net.cpp:122] Setting up Scale19
I1007 22:14:29.006963  5299 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:14:29.006968  5299 net.cpp:137] Memory required for data: 404858000
I1007 22:14:29.006974  5299 layer_factory.hpp:77] Creating layer M2PELU18
I1007 22:14:29.006980  5299 net.cpp:84] Creating Layer M2PELU18
I1007 22:14:29.006984  5299 net.cpp:406] M2PELU18 <- Convolution19
I1007 22:14:29.006991  5299 net.cpp:367] M2PELU18 -> Convolution19 (in-place)
I1007 22:14:29.007083  5299 net.cpp:122] Setting up M2PELU18
I1007 22:14:29.007089  5299 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:14:29.007094  5299 net.cpp:137] Memory required for data: 407366800
I1007 22:14:29.007100  5299 layer_factory.hpp:77] Creating layer Convolution20
I1007 22:14:29.007110  5299 net.cpp:84] Creating Layer Convolution20
I1007 22:14:29.007114  5299 net.cpp:406] Convolution20 <- Convolution19
I1007 22:14:29.007122  5299 net.cpp:380] Convolution20 -> Convolution20
I1007 22:14:29.012987  5299 net.cpp:122] Setting up Convolution20
I1007 22:14:29.012998  5299 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:14:29.013003  5299 net.cpp:137] Memory required for data: 409875600
I1007 22:14:29.013011  5299 layer_factory.hpp:77] Creating layer BatchNorm20
I1007 22:14:29.013020  5299 net.cpp:84] Creating Layer BatchNorm20
I1007 22:14:29.013022  5299 net.cpp:406] BatchNorm20 <- Convolution20
I1007 22:14:29.013028  5299 net.cpp:367] BatchNorm20 -> Convolution20 (in-place)
I1007 22:14:29.013161  5299 net.cpp:122] Setting up BatchNorm20
I1007 22:14:29.013167  5299 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:14:29.013171  5299 net.cpp:137] Memory required for data: 412384400
I1007 22:14:29.013180  5299 layer_factory.hpp:77] Creating layer Scale20
I1007 22:14:29.013186  5299 net.cpp:84] Creating Layer Scale20
I1007 22:14:29.013190  5299 net.cpp:406] Scale20 <- Convolution20
I1007 22:14:29.013195  5299 net.cpp:367] Scale20 -> Convolution20 (in-place)
I1007 22:14:29.013224  5299 layer_factory.hpp:77] Creating layer Scale20
I1007 22:14:29.013303  5299 net.cpp:122] Setting up Scale20
I1007 22:14:29.013309  5299 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:14:29.013312  5299 net.cpp:137] Memory required for data: 414893200
I1007 22:14:29.013319  5299 layer_factory.hpp:77] Creating layer Eltwise9
I1007 22:14:29.013326  5299 net.cpp:84] Creating Layer Eltwise9
I1007 22:14:29.013329  5299 net.cpp:406] Eltwise9 <- Eltwise8_M2PELU17_0_split_1
I1007 22:14:29.013334  5299 net.cpp:406] Eltwise9 <- Convolution20
I1007 22:14:29.013340  5299 net.cpp:380] Eltwise9 -> Eltwise9
I1007 22:14:29.013360  5299 net.cpp:122] Setting up Eltwise9
I1007 22:14:29.013365  5299 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:14:29.013368  5299 net.cpp:137] Memory required for data: 417402000
I1007 22:14:29.013372  5299 layer_factory.hpp:77] Creating layer M2PELU19
I1007 22:14:29.013381  5299 net.cpp:84] Creating Layer M2PELU19
I1007 22:14:29.013384  5299 net.cpp:406] M2PELU19 <- Eltwise9
I1007 22:14:29.013389  5299 net.cpp:367] M2PELU19 -> Eltwise9 (in-place)
I1007 22:14:29.013473  5299 net.cpp:122] Setting up M2PELU19
I1007 22:14:29.013479  5299 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:14:29.013484  5299 net.cpp:137] Memory required for data: 419910800
I1007 22:14:29.013490  5299 layer_factory.hpp:77] Creating layer Eltwise9_M2PELU19_0_split
I1007 22:14:29.013497  5299 net.cpp:84] Creating Layer Eltwise9_M2PELU19_0_split
I1007 22:14:29.013500  5299 net.cpp:406] Eltwise9_M2PELU19_0_split <- Eltwise9
I1007 22:14:29.013505  5299 net.cpp:380] Eltwise9_M2PELU19_0_split -> Eltwise9_M2PELU19_0_split_0
I1007 22:14:29.013512  5299 net.cpp:380] Eltwise9_M2PELU19_0_split -> Eltwise9_M2PELU19_0_split_1
I1007 22:14:29.013538  5299 net.cpp:122] Setting up Eltwise9_M2PELU19_0_split
I1007 22:14:29.013543  5299 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:14:29.013548  5299 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:14:29.013551  5299 net.cpp:137] Memory required for data: 424928400
I1007 22:14:29.013556  5299 layer_factory.hpp:77] Creating layer Convolution21
I1007 22:14:29.013564  5299 net.cpp:84] Creating Layer Convolution21
I1007 22:14:29.013568  5299 net.cpp:406] Convolution21 <- Eltwise9_M2PELU19_0_split_0
I1007 22:14:29.013576  5299 net.cpp:380] Convolution21 -> Convolution21
I1007 22:14:29.019824  5299 net.cpp:122] Setting up Convolution21
I1007 22:14:29.019834  5299 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:14:29.019840  5299 net.cpp:137] Memory required for data: 427437200
I1007 22:14:29.019852  5299 layer_factory.hpp:77] Creating layer BatchNorm21
I1007 22:14:29.019860  5299 net.cpp:84] Creating Layer BatchNorm21
I1007 22:14:29.019863  5299 net.cpp:406] BatchNorm21 <- Convolution21
I1007 22:14:29.019870  5299 net.cpp:367] BatchNorm21 -> Convolution21 (in-place)
I1007 22:14:29.020014  5299 net.cpp:122] Setting up BatchNorm21
I1007 22:14:29.020018  5299 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:14:29.020030  5299 net.cpp:137] Memory required for data: 429946000
I1007 22:14:29.020035  5299 layer_factory.hpp:77] Creating layer Scale21
I1007 22:14:29.020043  5299 net.cpp:84] Creating Layer Scale21
I1007 22:14:29.020048  5299 net.cpp:406] Scale21 <- Convolution21
I1007 22:14:29.020052  5299 net.cpp:367] Scale21 -> Convolution21 (in-place)
I1007 22:14:29.020093  5299 layer_factory.hpp:77] Creating layer Scale21
I1007 22:14:29.020180  5299 net.cpp:122] Setting up Scale21
I1007 22:14:29.020185  5299 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:14:29.020189  5299 net.cpp:137] Memory required for data: 432454800
I1007 22:14:29.020192  5299 layer_factory.hpp:77] Creating layer M2PELU20
I1007 22:14:29.020198  5299 net.cpp:84] Creating Layer M2PELU20
I1007 22:14:29.020201  5299 net.cpp:406] M2PELU20 <- Convolution21
I1007 22:14:29.020205  5299 net.cpp:367] M2PELU20 -> Convolution21 (in-place)
I1007 22:14:29.020287  5299 net.cpp:122] Setting up M2PELU20
I1007 22:14:29.020292  5299 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:14:29.020294  5299 net.cpp:137] Memory required for data: 434963600
I1007 22:14:29.020298  5299 layer_factory.hpp:77] Creating layer Convolution22
I1007 22:14:29.020305  5299 net.cpp:84] Creating Layer Convolution22
I1007 22:14:29.020308  5299 net.cpp:406] Convolution22 <- Convolution21
I1007 22:14:29.020313  5299 net.cpp:380] Convolution22 -> Convolution22
I1007 22:14:29.026607  5299 net.cpp:122] Setting up Convolution22
I1007 22:14:29.026618  5299 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:14:29.026631  5299 net.cpp:137] Memory required for data: 437472400
I1007 22:14:29.026638  5299 layer_factory.hpp:77] Creating layer BatchNorm22
I1007 22:14:29.026643  5299 net.cpp:84] Creating Layer BatchNorm22
I1007 22:14:29.026645  5299 net.cpp:406] BatchNorm22 <- Convolution22
I1007 22:14:29.026649  5299 net.cpp:367] BatchNorm22 -> Convolution22 (in-place)
I1007 22:14:29.026804  5299 net.cpp:122] Setting up BatchNorm22
I1007 22:14:29.026811  5299 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:14:29.026823  5299 net.cpp:137] Memory required for data: 439981200
I1007 22:14:29.026829  5299 layer_factory.hpp:77] Creating layer Scale22
I1007 22:14:29.026834  5299 net.cpp:84] Creating Layer Scale22
I1007 22:14:29.026836  5299 net.cpp:406] Scale22 <- Convolution22
I1007 22:14:29.026839  5299 net.cpp:367] Scale22 -> Convolution22 (in-place)
I1007 22:14:29.026870  5299 layer_factory.hpp:77] Creating layer Scale22
I1007 22:14:29.026947  5299 net.cpp:122] Setting up Scale22
I1007 22:14:29.026952  5299 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:14:29.026954  5299 net.cpp:137] Memory required for data: 442490000
I1007 22:14:29.026958  5299 layer_factory.hpp:77] Creating layer Eltwise10
I1007 22:14:29.026964  5299 net.cpp:84] Creating Layer Eltwise10
I1007 22:14:29.026968  5299 net.cpp:406] Eltwise10 <- Eltwise9_M2PELU19_0_split_1
I1007 22:14:29.026970  5299 net.cpp:406] Eltwise10 <- Convolution22
I1007 22:14:29.026974  5299 net.cpp:380] Eltwise10 -> Eltwise10
I1007 22:14:29.026991  5299 net.cpp:122] Setting up Eltwise10
I1007 22:14:29.026995  5299 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:14:29.026998  5299 net.cpp:137] Memory required for data: 444998800
I1007 22:14:29.027000  5299 layer_factory.hpp:77] Creating layer M2PELU21
I1007 22:14:29.027006  5299 net.cpp:84] Creating Layer M2PELU21
I1007 22:14:29.027009  5299 net.cpp:406] M2PELU21 <- Eltwise10
I1007 22:14:29.027012  5299 net.cpp:367] M2PELU21 -> Eltwise10 (in-place)
I1007 22:14:29.027099  5299 net.cpp:122] Setting up M2PELU21
I1007 22:14:29.027112  5299 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:14:29.027114  5299 net.cpp:137] Memory required for data: 447507600
I1007 22:14:29.027118  5299 layer_factory.hpp:77] Creating layer Eltwise10_M2PELU21_0_split
I1007 22:14:29.027123  5299 net.cpp:84] Creating Layer Eltwise10_M2PELU21_0_split
I1007 22:14:29.027127  5299 net.cpp:406] Eltwise10_M2PELU21_0_split <- Eltwise10
I1007 22:14:29.027129  5299 net.cpp:380] Eltwise10_M2PELU21_0_split -> Eltwise10_M2PELU21_0_split_0
I1007 22:14:29.027133  5299 net.cpp:380] Eltwise10_M2PELU21_0_split -> Eltwise10_M2PELU21_0_split_1
I1007 22:14:29.027159  5299 net.cpp:122] Setting up Eltwise10_M2PELU21_0_split
I1007 22:14:29.027168  5299 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:14:29.027181  5299 net.cpp:129] Top shape: 100 32 14 14 (627200)
I1007 22:14:29.027184  5299 net.cpp:137] Memory required for data: 452525200
I1007 22:14:29.027186  5299 layer_factory.hpp:77] Creating layer Convolution23
I1007 22:14:29.027194  5299 net.cpp:84] Creating Layer Convolution23
I1007 22:14:29.027196  5299 net.cpp:406] Convolution23 <- Eltwise10_M2PELU21_0_split_0
I1007 22:14:29.027210  5299 net.cpp:380] Convolution23 -> Convolution23
I1007 22:14:29.033252  5299 net.cpp:122] Setting up Convolution23
I1007 22:14:29.033263  5299 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:14:29.033267  5299 net.cpp:137] Memory required for data: 453779600
I1007 22:14:29.033272  5299 layer_factory.hpp:77] Creating layer BatchNorm23
I1007 22:14:29.033279  5299 net.cpp:84] Creating Layer BatchNorm23
I1007 22:14:29.033282  5299 net.cpp:406] BatchNorm23 <- Convolution23
I1007 22:14:29.033288  5299 net.cpp:367] BatchNorm23 -> Convolution23 (in-place)
I1007 22:14:29.033421  5299 net.cpp:122] Setting up BatchNorm23
I1007 22:14:29.033427  5299 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:14:29.033429  5299 net.cpp:137] Memory required for data: 455034000
I1007 22:14:29.033433  5299 layer_factory.hpp:77] Creating layer Scale23
I1007 22:14:29.033439  5299 net.cpp:84] Creating Layer Scale23
I1007 22:14:29.033442  5299 net.cpp:406] Scale23 <- Convolution23
I1007 22:14:29.033447  5299 net.cpp:367] Scale23 -> Convolution23 (in-place)
I1007 22:14:29.033473  5299 layer_factory.hpp:77] Creating layer Scale23
I1007 22:14:29.033550  5299 net.cpp:122] Setting up Scale23
I1007 22:14:29.033555  5299 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:14:29.033557  5299 net.cpp:137] Memory required for data: 456288400
I1007 22:14:29.033561  5299 layer_factory.hpp:77] Creating layer Convolution24
I1007 22:14:29.033569  5299 net.cpp:84] Creating Layer Convolution24
I1007 22:14:29.033572  5299 net.cpp:406] Convolution24 <- Eltwise10_M2PELU21_0_split_1
I1007 22:14:29.033576  5299 net.cpp:380] Convolution24 -> Convolution24
I1007 22:14:29.035368  5299 net.cpp:122] Setting up Convolution24
I1007 22:14:29.035380  5299 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:14:29.035384  5299 net.cpp:137] Memory required for data: 457542800
I1007 22:14:29.035388  5299 layer_factory.hpp:77] Creating layer BatchNorm24
I1007 22:14:29.035396  5299 net.cpp:84] Creating Layer BatchNorm24
I1007 22:14:29.035400  5299 net.cpp:406] BatchNorm24 <- Convolution24
I1007 22:14:29.035404  5299 net.cpp:367] BatchNorm24 -> Convolution24 (in-place)
I1007 22:14:29.035542  5299 net.cpp:122] Setting up BatchNorm24
I1007 22:14:29.035547  5299 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:14:29.035549  5299 net.cpp:137] Memory required for data: 458797200
I1007 22:14:29.035554  5299 layer_factory.hpp:77] Creating layer Scale24
I1007 22:14:29.035560  5299 net.cpp:84] Creating Layer Scale24
I1007 22:14:29.035563  5299 net.cpp:406] Scale24 <- Convolution24
I1007 22:14:29.035567  5299 net.cpp:367] Scale24 -> Convolution24 (in-place)
I1007 22:14:29.035595  5299 layer_factory.hpp:77] Creating layer Scale24
I1007 22:14:29.035676  5299 net.cpp:122] Setting up Scale24
I1007 22:14:29.035681  5299 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:14:29.035682  5299 net.cpp:137] Memory required for data: 460051600
I1007 22:14:29.035696  5299 layer_factory.hpp:77] Creating layer M2PELU22
I1007 22:14:29.035701  5299 net.cpp:84] Creating Layer M2PELU22
I1007 22:14:29.035706  5299 net.cpp:406] M2PELU22 <- Convolution24
I1007 22:14:29.035709  5299 net.cpp:367] M2PELU22 -> Convolution24 (in-place)
I1007 22:14:29.035799  5299 net.cpp:122] Setting up M2PELU22
I1007 22:14:29.035804  5299 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:14:29.035806  5299 net.cpp:137] Memory required for data: 461306000
I1007 22:14:29.035810  5299 layer_factory.hpp:77] Creating layer Convolution25
I1007 22:14:29.035818  5299 net.cpp:84] Creating Layer Convolution25
I1007 22:14:29.035821  5299 net.cpp:406] Convolution25 <- Convolution24
I1007 22:14:29.035826  5299 net.cpp:380] Convolution25 -> Convolution25
I1007 22:14:29.042006  5299 net.cpp:122] Setting up Convolution25
I1007 22:14:29.042016  5299 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:14:29.042021  5299 net.cpp:137] Memory required for data: 462560400
I1007 22:14:29.042026  5299 layer_factory.hpp:77] Creating layer BatchNorm25
I1007 22:14:29.042032  5299 net.cpp:84] Creating Layer BatchNorm25
I1007 22:14:29.042035  5299 net.cpp:406] BatchNorm25 <- Convolution25
I1007 22:14:29.042040  5299 net.cpp:367] BatchNorm25 -> Convolution25 (in-place)
I1007 22:14:29.042186  5299 net.cpp:122] Setting up BatchNorm25
I1007 22:14:29.042191  5299 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:14:29.042193  5299 net.cpp:137] Memory required for data: 463814800
I1007 22:14:29.042198  5299 layer_factory.hpp:77] Creating layer Scale25
I1007 22:14:29.042204  5299 net.cpp:84] Creating Layer Scale25
I1007 22:14:29.042208  5299 net.cpp:406] Scale25 <- Convolution25
I1007 22:14:29.042212  5299 net.cpp:367] Scale25 -> Convolution25 (in-place)
I1007 22:14:29.042239  5299 layer_factory.hpp:77] Creating layer Scale25
I1007 22:14:29.042321  5299 net.cpp:122] Setting up Scale25
I1007 22:14:29.042325  5299 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:14:29.042328  5299 net.cpp:137] Memory required for data: 465069200
I1007 22:14:29.042332  5299 layer_factory.hpp:77] Creating layer Eltwise11
I1007 22:14:29.042338  5299 net.cpp:84] Creating Layer Eltwise11
I1007 22:14:29.042341  5299 net.cpp:406] Eltwise11 <- Convolution23
I1007 22:14:29.042345  5299 net.cpp:406] Eltwise11 <- Convolution25
I1007 22:14:29.042347  5299 net.cpp:380] Eltwise11 -> Eltwise11
I1007 22:14:29.042366  5299 net.cpp:122] Setting up Eltwise11
I1007 22:14:29.042371  5299 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:14:29.042372  5299 net.cpp:137] Memory required for data: 466323600
I1007 22:14:29.042374  5299 layer_factory.hpp:77] Creating layer M2PELU23
I1007 22:14:29.042381  5299 net.cpp:84] Creating Layer M2PELU23
I1007 22:14:29.042383  5299 net.cpp:406] M2PELU23 <- Eltwise11
I1007 22:14:29.042387  5299 net.cpp:367] M2PELU23 -> Eltwise11 (in-place)
I1007 22:14:29.042476  5299 net.cpp:122] Setting up M2PELU23
I1007 22:14:29.042481  5299 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:14:29.042484  5299 net.cpp:137] Memory required for data: 467578000
I1007 22:14:29.042487  5299 layer_factory.hpp:77] Creating layer Eltwise11_M2PELU23_0_split
I1007 22:14:29.042492  5299 net.cpp:84] Creating Layer Eltwise11_M2PELU23_0_split
I1007 22:14:29.042495  5299 net.cpp:406] Eltwise11_M2PELU23_0_split <- Eltwise11
I1007 22:14:29.042500  5299 net.cpp:380] Eltwise11_M2PELU23_0_split -> Eltwise11_M2PELU23_0_split_0
I1007 22:14:29.042505  5299 net.cpp:380] Eltwise11_M2PELU23_0_split -> Eltwise11_M2PELU23_0_split_1
I1007 22:14:29.042529  5299 net.cpp:122] Setting up Eltwise11_M2PELU23_0_split
I1007 22:14:29.042534  5299 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:14:29.042537  5299 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:14:29.042539  5299 net.cpp:137] Memory required for data: 470086800
I1007 22:14:29.042541  5299 layer_factory.hpp:77] Creating layer Convolution26
I1007 22:14:29.042548  5299 net.cpp:84] Creating Layer Convolution26
I1007 22:14:29.042551  5299 net.cpp:406] Convolution26 <- Eltwise11_M2PELU23_0_split_0
I1007 22:14:29.042562  5299 net.cpp:380] Convolution26 -> Convolution26
I1007 22:14:29.048265  5299 net.cpp:122] Setting up Convolution26
I1007 22:14:29.048275  5299 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:14:29.048280  5299 net.cpp:137] Memory required for data: 471341200
I1007 22:14:29.048283  5299 layer_factory.hpp:77] Creating layer BatchNorm26
I1007 22:14:29.048290  5299 net.cpp:84] Creating Layer BatchNorm26
I1007 22:14:29.048292  5299 net.cpp:406] BatchNorm26 <- Convolution26
I1007 22:14:29.048296  5299 net.cpp:367] BatchNorm26 -> Convolution26 (in-place)
I1007 22:14:29.048434  5299 net.cpp:122] Setting up BatchNorm26
I1007 22:14:29.048440  5299 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:14:29.048444  5299 net.cpp:137] Memory required for data: 472595600
I1007 22:14:29.048447  5299 layer_factory.hpp:77] Creating layer Scale26
I1007 22:14:29.048452  5299 net.cpp:84] Creating Layer Scale26
I1007 22:14:29.048455  5299 net.cpp:406] Scale26 <- Convolution26
I1007 22:14:29.048460  5299 net.cpp:367] Scale26 -> Convolution26 (in-place)
I1007 22:14:29.048486  5299 layer_factory.hpp:77] Creating layer Scale26
I1007 22:14:29.048568  5299 net.cpp:122] Setting up Scale26
I1007 22:14:29.048573  5299 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:14:29.048575  5299 net.cpp:137] Memory required for data: 473850000
I1007 22:14:29.048579  5299 layer_factory.hpp:77] Creating layer M2PELU24
I1007 22:14:29.048585  5299 net.cpp:84] Creating Layer M2PELU24
I1007 22:14:29.048588  5299 net.cpp:406] M2PELU24 <- Convolution26
I1007 22:14:29.048591  5299 net.cpp:367] M2PELU24 -> Convolution26 (in-place)
I1007 22:14:29.048678  5299 net.cpp:122] Setting up M2PELU24
I1007 22:14:29.048683  5299 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:14:29.048686  5299 net.cpp:137] Memory required for data: 475104400
I1007 22:14:29.048689  5299 layer_factory.hpp:77] Creating layer Convolution27
I1007 22:14:29.048697  5299 net.cpp:84] Creating Layer Convolution27
I1007 22:14:29.048701  5299 net.cpp:406] Convolution27 <- Convolution26
I1007 22:14:29.048705  5299 net.cpp:380] Convolution27 -> Convolution27
I1007 22:14:29.054361  5299 net.cpp:122] Setting up Convolution27
I1007 22:14:29.054373  5299 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:14:29.054375  5299 net.cpp:137] Memory required for data: 476358800
I1007 22:14:29.054381  5299 layer_factory.hpp:77] Creating layer BatchNorm27
I1007 22:14:29.054386  5299 net.cpp:84] Creating Layer BatchNorm27
I1007 22:14:29.054390  5299 net.cpp:406] BatchNorm27 <- Convolution27
I1007 22:14:29.054394  5299 net.cpp:367] BatchNorm27 -> Convolution27 (in-place)
I1007 22:14:29.054548  5299 net.cpp:122] Setting up BatchNorm27
I1007 22:14:29.054553  5299 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:14:29.054554  5299 net.cpp:137] Memory required for data: 477613200
I1007 22:14:29.054559  5299 layer_factory.hpp:77] Creating layer Scale27
I1007 22:14:29.054574  5299 net.cpp:84] Creating Layer Scale27
I1007 22:14:29.054576  5299 net.cpp:406] Scale27 <- Convolution27
I1007 22:14:29.054580  5299 net.cpp:367] Scale27 -> Convolution27 (in-place)
I1007 22:14:29.054610  5299 layer_factory.hpp:77] Creating layer Scale27
I1007 22:14:29.054690  5299 net.cpp:122] Setting up Scale27
I1007 22:14:29.054695  5299 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:14:29.054697  5299 net.cpp:137] Memory required for data: 478867600
I1007 22:14:29.054702  5299 layer_factory.hpp:77] Creating layer Eltwise12
I1007 22:14:29.054708  5299 net.cpp:84] Creating Layer Eltwise12
I1007 22:14:29.054710  5299 net.cpp:406] Eltwise12 <- Eltwise11_M2PELU23_0_split_1
I1007 22:14:29.054713  5299 net.cpp:406] Eltwise12 <- Convolution27
I1007 22:14:29.054716  5299 net.cpp:380] Eltwise12 -> Eltwise12
I1007 22:14:29.054738  5299 net.cpp:122] Setting up Eltwise12
I1007 22:14:29.054744  5299 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:14:29.054746  5299 net.cpp:137] Memory required for data: 480122000
I1007 22:14:29.054749  5299 layer_factory.hpp:77] Creating layer M2PELU25
I1007 22:14:29.054754  5299 net.cpp:84] Creating Layer M2PELU25
I1007 22:14:29.054764  5299 net.cpp:406] M2PELU25 <- Eltwise12
I1007 22:14:29.054767  5299 net.cpp:367] M2PELU25 -> Eltwise12 (in-place)
I1007 22:14:29.054859  5299 net.cpp:122] Setting up M2PELU25
I1007 22:14:29.054864  5299 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:14:29.054868  5299 net.cpp:137] Memory required for data: 481376400
I1007 22:14:29.054872  5299 layer_factory.hpp:77] Creating layer Eltwise12_M2PELU25_0_split
I1007 22:14:29.054877  5299 net.cpp:84] Creating Layer Eltwise12_M2PELU25_0_split
I1007 22:14:29.054880  5299 net.cpp:406] Eltwise12_M2PELU25_0_split <- Eltwise12
I1007 22:14:29.054883  5299 net.cpp:380] Eltwise12_M2PELU25_0_split -> Eltwise12_M2PELU25_0_split_0
I1007 22:14:29.054888  5299 net.cpp:380] Eltwise12_M2PELU25_0_split -> Eltwise12_M2PELU25_0_split_1
I1007 22:14:29.054913  5299 net.cpp:122] Setting up Eltwise12_M2PELU25_0_split
I1007 22:14:29.054918  5299 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:14:29.054920  5299 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:14:29.054924  5299 net.cpp:137] Memory required for data: 483885200
I1007 22:14:29.054925  5299 layer_factory.hpp:77] Creating layer Convolution28
I1007 22:14:29.054930  5299 net.cpp:84] Creating Layer Convolution28
I1007 22:14:29.054934  5299 net.cpp:406] Convolution28 <- Eltwise12_M2PELU25_0_split_0
I1007 22:14:29.054939  5299 net.cpp:380] Convolution28 -> Convolution28
I1007 22:14:29.059784  5299 net.cpp:122] Setting up Convolution28
I1007 22:14:29.059795  5299 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:14:29.059798  5299 net.cpp:137] Memory required for data: 485139600
I1007 22:14:29.059803  5299 layer_factory.hpp:77] Creating layer BatchNorm28
I1007 22:14:29.059808  5299 net.cpp:84] Creating Layer BatchNorm28
I1007 22:14:29.059811  5299 net.cpp:406] BatchNorm28 <- Convolution28
I1007 22:14:29.059815  5299 net.cpp:367] BatchNorm28 -> Convolution28 (in-place)
I1007 22:14:29.059960  5299 net.cpp:122] Setting up BatchNorm28
I1007 22:14:29.059965  5299 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:14:29.059978  5299 net.cpp:137] Memory required for data: 486394000
I1007 22:14:29.059983  5299 layer_factory.hpp:77] Creating layer Scale28
I1007 22:14:29.059986  5299 net.cpp:84] Creating Layer Scale28
I1007 22:14:29.059990  5299 net.cpp:406] Scale28 <- Convolution28
I1007 22:14:29.059993  5299 net.cpp:367] Scale28 -> Convolution28 (in-place)
I1007 22:14:29.060021  5299 layer_factory.hpp:77] Creating layer Scale28
I1007 22:14:29.060102  5299 net.cpp:122] Setting up Scale28
I1007 22:14:29.060107  5299 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:14:29.060109  5299 net.cpp:137] Memory required for data: 487648400
I1007 22:14:29.060113  5299 layer_factory.hpp:77] Creating layer M2PELU26
I1007 22:14:29.060119  5299 net.cpp:84] Creating Layer M2PELU26
I1007 22:14:29.060122  5299 net.cpp:406] M2PELU26 <- Convolution28
I1007 22:14:29.060127  5299 net.cpp:367] M2PELU26 -> Convolution28 (in-place)
I1007 22:14:29.060214  5299 net.cpp:122] Setting up M2PELU26
I1007 22:14:29.060220  5299 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:14:29.060222  5299 net.cpp:137] Memory required for data: 488902800
I1007 22:14:29.060226  5299 layer_factory.hpp:77] Creating layer Convolution29
I1007 22:14:29.060233  5299 net.cpp:84] Creating Layer Convolution29
I1007 22:14:29.060237  5299 net.cpp:406] Convolution29 <- Convolution28
I1007 22:14:29.060241  5299 net.cpp:380] Convolution29 -> Convolution29
I1007 22:14:29.066603  5299 net.cpp:122] Setting up Convolution29
I1007 22:14:29.066613  5299 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:14:29.066617  5299 net.cpp:137] Memory required for data: 490157200
I1007 22:14:29.066622  5299 layer_factory.hpp:77] Creating layer BatchNorm29
I1007 22:14:29.066627  5299 net.cpp:84] Creating Layer BatchNorm29
I1007 22:14:29.066630  5299 net.cpp:406] BatchNorm29 <- Convolution29
I1007 22:14:29.066637  5299 net.cpp:367] BatchNorm29 -> Convolution29 (in-place)
I1007 22:14:29.066778  5299 net.cpp:122] Setting up BatchNorm29
I1007 22:14:29.066790  5299 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:14:29.066793  5299 net.cpp:137] Memory required for data: 491411600
I1007 22:14:29.066798  5299 layer_factory.hpp:77] Creating layer Scale29
I1007 22:14:29.066803  5299 net.cpp:84] Creating Layer Scale29
I1007 22:14:29.066807  5299 net.cpp:406] Scale29 <- Convolution29
I1007 22:14:29.066809  5299 net.cpp:367] Scale29 -> Convolution29 (in-place)
I1007 22:14:29.066839  5299 layer_factory.hpp:77] Creating layer Scale29
I1007 22:14:29.066920  5299 net.cpp:122] Setting up Scale29
I1007 22:14:29.066926  5299 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:14:29.066928  5299 net.cpp:137] Memory required for data: 492666000
I1007 22:14:29.066932  5299 layer_factory.hpp:77] Creating layer Eltwise13
I1007 22:14:29.066937  5299 net.cpp:84] Creating Layer Eltwise13
I1007 22:14:29.066941  5299 net.cpp:406] Eltwise13 <- Eltwise12_M2PELU25_0_split_1
I1007 22:14:29.066942  5299 net.cpp:406] Eltwise13 <- Convolution29
I1007 22:14:29.066946  5299 net.cpp:380] Eltwise13 -> Eltwise13
I1007 22:14:29.066964  5299 net.cpp:122] Setting up Eltwise13
I1007 22:14:29.066968  5299 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:14:29.066970  5299 net.cpp:137] Memory required for data: 493920400
I1007 22:14:29.066973  5299 layer_factory.hpp:77] Creating layer M2PELU27
I1007 22:14:29.066978  5299 net.cpp:84] Creating Layer M2PELU27
I1007 22:14:29.066982  5299 net.cpp:406] M2PELU27 <- Eltwise13
I1007 22:14:29.066987  5299 net.cpp:367] M2PELU27 -> Eltwise13 (in-place)
I1007 22:14:29.067075  5299 net.cpp:122] Setting up M2PELU27
I1007 22:14:29.067080  5299 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:14:29.067081  5299 net.cpp:137] Memory required for data: 495174800
I1007 22:14:29.067104  5299 layer_factory.hpp:77] Creating layer Eltwise13_M2PELU27_0_split
I1007 22:14:29.067109  5299 net.cpp:84] Creating Layer Eltwise13_M2PELU27_0_split
I1007 22:14:29.067112  5299 net.cpp:406] Eltwise13_M2PELU27_0_split <- Eltwise13
I1007 22:14:29.067116  5299 net.cpp:380] Eltwise13_M2PELU27_0_split -> Eltwise13_M2PELU27_0_split_0
I1007 22:14:29.067121  5299 net.cpp:380] Eltwise13_M2PELU27_0_split -> Eltwise13_M2PELU27_0_split_1
I1007 22:14:29.067148  5299 net.cpp:122] Setting up Eltwise13_M2PELU27_0_split
I1007 22:14:29.067152  5299 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:14:29.067157  5299 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:14:29.067158  5299 net.cpp:137] Memory required for data: 497683600
I1007 22:14:29.067162  5299 layer_factory.hpp:77] Creating layer Convolution30
I1007 22:14:29.067181  5299 net.cpp:84] Creating Layer Convolution30
I1007 22:14:29.067186  5299 net.cpp:406] Convolution30 <- Eltwise13_M2PELU27_0_split_0
I1007 22:14:29.067191  5299 net.cpp:380] Convolution30 -> Convolution30
I1007 22:14:29.072968  5299 net.cpp:122] Setting up Convolution30
I1007 22:14:29.072978  5299 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:14:29.072981  5299 net.cpp:137] Memory required for data: 498938000
I1007 22:14:29.072985  5299 layer_factory.hpp:77] Creating layer BatchNorm30
I1007 22:14:29.072991  5299 net.cpp:84] Creating Layer BatchNorm30
I1007 22:14:29.072994  5299 net.cpp:406] BatchNorm30 <- Convolution30
I1007 22:14:29.072999  5299 net.cpp:367] BatchNorm30 -> Convolution30 (in-place)
I1007 22:14:29.073138  5299 net.cpp:122] Setting up BatchNorm30
I1007 22:14:29.073144  5299 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:14:29.073148  5299 net.cpp:137] Memory required for data: 500192400
I1007 22:14:29.073153  5299 layer_factory.hpp:77] Creating layer Scale30
I1007 22:14:29.073158  5299 net.cpp:84] Creating Layer Scale30
I1007 22:14:29.073160  5299 net.cpp:406] Scale30 <- Convolution30
I1007 22:14:29.073164  5299 net.cpp:367] Scale30 -> Convolution30 (in-place)
I1007 22:14:29.073191  5299 layer_factory.hpp:77] Creating layer Scale30
I1007 22:14:29.073271  5299 net.cpp:122] Setting up Scale30
I1007 22:14:29.073276  5299 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:14:29.073279  5299 net.cpp:137] Memory required for data: 501446800
I1007 22:14:29.073292  5299 layer_factory.hpp:77] Creating layer M2PELU28
I1007 22:14:29.073297  5299 net.cpp:84] Creating Layer M2PELU28
I1007 22:14:29.073299  5299 net.cpp:406] M2PELU28 <- Convolution30
I1007 22:14:29.073303  5299 net.cpp:367] M2PELU28 -> Convolution30 (in-place)
I1007 22:14:29.073398  5299 net.cpp:122] Setting up M2PELU28
I1007 22:14:29.073403  5299 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:14:29.073405  5299 net.cpp:137] Memory required for data: 502701200
I1007 22:14:29.073410  5299 layer_factory.hpp:77] Creating layer Convolution31
I1007 22:14:29.073417  5299 net.cpp:84] Creating Layer Convolution31
I1007 22:14:29.073421  5299 net.cpp:406] Convolution31 <- Convolution30
I1007 22:14:29.073426  5299 net.cpp:380] Convolution31 -> Convolution31
I1007 22:14:29.079804  5299 net.cpp:122] Setting up Convolution31
I1007 22:14:29.079814  5299 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:14:29.079818  5299 net.cpp:137] Memory required for data: 503955600
I1007 22:14:29.079823  5299 layer_factory.hpp:77] Creating layer BatchNorm31
I1007 22:14:29.079828  5299 net.cpp:84] Creating Layer BatchNorm31
I1007 22:14:29.079833  5299 net.cpp:406] BatchNorm31 <- Convolution31
I1007 22:14:29.079835  5299 net.cpp:367] BatchNorm31 -> Convolution31 (in-place)
I1007 22:14:29.079980  5299 net.cpp:122] Setting up BatchNorm31
I1007 22:14:29.079985  5299 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:14:29.079988  5299 net.cpp:137] Memory required for data: 505210000
I1007 22:14:29.079993  5299 layer_factory.hpp:77] Creating layer Scale31
I1007 22:14:29.079999  5299 net.cpp:84] Creating Layer Scale31
I1007 22:14:29.080003  5299 net.cpp:406] Scale31 <- Convolution31
I1007 22:14:29.080005  5299 net.cpp:367] Scale31 -> Convolution31 (in-place)
I1007 22:14:29.080034  5299 layer_factory.hpp:77] Creating layer Scale31
I1007 22:14:29.080116  5299 net.cpp:122] Setting up Scale31
I1007 22:14:29.080121  5299 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:14:29.080123  5299 net.cpp:137] Memory required for data: 506464400
I1007 22:14:29.080127  5299 layer_factory.hpp:77] Creating layer Eltwise14
I1007 22:14:29.080132  5299 net.cpp:84] Creating Layer Eltwise14
I1007 22:14:29.080137  5299 net.cpp:406] Eltwise14 <- Eltwise13_M2PELU27_0_split_1
I1007 22:14:29.080139  5299 net.cpp:406] Eltwise14 <- Convolution31
I1007 22:14:29.080142  5299 net.cpp:380] Eltwise14 -> Eltwise14
I1007 22:14:29.080160  5299 net.cpp:122] Setting up Eltwise14
I1007 22:14:29.080164  5299 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:14:29.080168  5299 net.cpp:137] Memory required for data: 507718800
I1007 22:14:29.080169  5299 layer_factory.hpp:77] Creating layer M2PELU29
I1007 22:14:29.080174  5299 net.cpp:84] Creating Layer M2PELU29
I1007 22:14:29.080178  5299 net.cpp:406] M2PELU29 <- Eltwise14
I1007 22:14:29.080180  5299 net.cpp:367] M2PELU29 -> Eltwise14 (in-place)
I1007 22:14:29.080267  5299 net.cpp:122] Setting up M2PELU29
I1007 22:14:29.080272  5299 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:14:29.080276  5299 net.cpp:137] Memory required for data: 508973200
I1007 22:14:29.080278  5299 layer_factory.hpp:77] Creating layer Eltwise14_M2PELU29_0_split
I1007 22:14:29.080283  5299 net.cpp:84] Creating Layer Eltwise14_M2PELU29_0_split
I1007 22:14:29.080286  5299 net.cpp:406] Eltwise14_M2PELU29_0_split <- Eltwise14
I1007 22:14:29.080291  5299 net.cpp:380] Eltwise14_M2PELU29_0_split -> Eltwise14_M2PELU29_0_split_0
I1007 22:14:29.080296  5299 net.cpp:380] Eltwise14_M2PELU29_0_split -> Eltwise14_M2PELU29_0_split_1
I1007 22:14:29.080319  5299 net.cpp:122] Setting up Eltwise14_M2PELU29_0_split
I1007 22:14:29.080323  5299 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:14:29.080327  5299 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:14:29.080329  5299 net.cpp:137] Memory required for data: 511482000
I1007 22:14:29.080332  5299 layer_factory.hpp:77] Creating layer Convolution32
I1007 22:14:29.080338  5299 net.cpp:84] Creating Layer Convolution32
I1007 22:14:29.080341  5299 net.cpp:406] Convolution32 <- Eltwise14_M2PELU29_0_split_0
I1007 22:14:29.080353  5299 net.cpp:380] Convolution32 -> Convolution32
I1007 22:14:29.086529  5299 net.cpp:122] Setting up Convolution32
I1007 22:14:29.086541  5299 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:14:29.086544  5299 net.cpp:137] Memory required for data: 512736400
I1007 22:14:29.086549  5299 layer_factory.hpp:77] Creating layer BatchNorm32
I1007 22:14:29.086555  5299 net.cpp:84] Creating Layer BatchNorm32
I1007 22:14:29.086560  5299 net.cpp:406] BatchNorm32 <- Convolution32
I1007 22:14:29.086565  5299 net.cpp:367] BatchNorm32 -> Convolution32 (in-place)
I1007 22:14:29.086727  5299 net.cpp:122] Setting up BatchNorm32
I1007 22:14:29.086735  5299 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:14:29.086736  5299 net.cpp:137] Memory required for data: 513990800
I1007 22:14:29.086742  5299 layer_factory.hpp:77] Creating layer Scale32
I1007 22:14:29.086747  5299 net.cpp:84] Creating Layer Scale32
I1007 22:14:29.086750  5299 net.cpp:406] Scale32 <- Convolution32
I1007 22:14:29.086755  5299 net.cpp:367] Scale32 -> Convolution32 (in-place)
I1007 22:14:29.086786  5299 layer_factory.hpp:77] Creating layer Scale32
I1007 22:14:29.086869  5299 net.cpp:122] Setting up Scale32
I1007 22:14:29.086874  5299 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:14:29.086877  5299 net.cpp:137] Memory required for data: 515245200
I1007 22:14:29.086881  5299 layer_factory.hpp:77] Creating layer M2PELU30
I1007 22:14:29.086889  5299 net.cpp:84] Creating Layer M2PELU30
I1007 22:14:29.086891  5299 net.cpp:406] M2PELU30 <- Convolution32
I1007 22:14:29.086894  5299 net.cpp:367] M2PELU30 -> Convolution32 (in-place)
I1007 22:14:29.086984  5299 net.cpp:122] Setting up M2PELU30
I1007 22:14:29.086989  5299 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:14:29.086992  5299 net.cpp:137] Memory required for data: 516499600
I1007 22:14:29.086995  5299 layer_factory.hpp:77] Creating layer Convolution33
I1007 22:14:29.087003  5299 net.cpp:84] Creating Layer Convolution33
I1007 22:14:29.087007  5299 net.cpp:406] Convolution33 <- Convolution32
I1007 22:14:29.087010  5299 net.cpp:380] Convolution33 -> Convolution33
I1007 22:14:29.093627  5299 net.cpp:122] Setting up Convolution33
I1007 22:14:29.093637  5299 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:14:29.093641  5299 net.cpp:137] Memory required for data: 517754000
I1007 22:14:29.093647  5299 layer_factory.hpp:77] Creating layer BatchNorm33
I1007 22:14:29.093652  5299 net.cpp:84] Creating Layer BatchNorm33
I1007 22:14:29.093654  5299 net.cpp:406] BatchNorm33 <- Convolution33
I1007 22:14:29.093659  5299 net.cpp:367] BatchNorm33 -> Convolution33 (in-place)
I1007 22:14:29.093808  5299 net.cpp:122] Setting up BatchNorm33
I1007 22:14:29.093814  5299 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:14:29.093817  5299 net.cpp:137] Memory required for data: 519008400
I1007 22:14:29.093822  5299 layer_factory.hpp:77] Creating layer Scale33
I1007 22:14:29.093827  5299 net.cpp:84] Creating Layer Scale33
I1007 22:14:29.093830  5299 net.cpp:406] Scale33 <- Convolution33
I1007 22:14:29.093834  5299 net.cpp:367] Scale33 -> Convolution33 (in-place)
I1007 22:14:29.093863  5299 layer_factory.hpp:77] Creating layer Scale33
I1007 22:14:29.093945  5299 net.cpp:122] Setting up Scale33
I1007 22:14:29.093950  5299 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:14:29.093953  5299 net.cpp:137] Memory required for data: 520262800
I1007 22:14:29.093957  5299 layer_factory.hpp:77] Creating layer Eltwise15
I1007 22:14:29.093962  5299 net.cpp:84] Creating Layer Eltwise15
I1007 22:14:29.093966  5299 net.cpp:406] Eltwise15 <- Eltwise14_M2PELU29_0_split_1
I1007 22:14:29.093968  5299 net.cpp:406] Eltwise15 <- Convolution33
I1007 22:14:29.093972  5299 net.cpp:380] Eltwise15 -> Eltwise15
I1007 22:14:29.093991  5299 net.cpp:122] Setting up Eltwise15
I1007 22:14:29.093996  5299 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:14:29.093997  5299 net.cpp:137] Memory required for data: 521517200
I1007 22:14:29.093999  5299 layer_factory.hpp:77] Creating layer M2PELU31
I1007 22:14:29.094004  5299 net.cpp:84] Creating Layer M2PELU31
I1007 22:14:29.094014  5299 net.cpp:406] M2PELU31 <- Eltwise15
I1007 22:14:29.094019  5299 net.cpp:367] M2PELU31 -> Eltwise15 (in-place)
I1007 22:14:29.094111  5299 net.cpp:122] Setting up M2PELU31
I1007 22:14:29.094116  5299 net.cpp:129] Top shape: 100 64 7 7 (313600)
I1007 22:14:29.094120  5299 net.cpp:137] Memory required for data: 522771600
I1007 22:14:29.094123  5299 layer_factory.hpp:77] Creating layer Pooling1
I1007 22:14:29.094130  5299 net.cpp:84] Creating Layer Pooling1
I1007 22:14:29.094131  5299 net.cpp:406] Pooling1 <- Eltwise15
I1007 22:14:29.094136  5299 net.cpp:380] Pooling1 -> Pooling1
I1007 22:14:29.095458  5299 net.cpp:122] Setting up Pooling1
I1007 22:14:29.095466  5299 net.cpp:129] Top shape: 100 64 1 1 (6400)
I1007 22:14:29.095469  5299 net.cpp:137] Memory required for data: 522797200
I1007 22:14:29.095472  5299 layer_factory.hpp:77] Creating layer InnerProduct1
I1007 22:14:29.095481  5299 net.cpp:84] Creating Layer InnerProduct1
I1007 22:14:29.095484  5299 net.cpp:406] InnerProduct1 <- Pooling1
I1007 22:14:29.095489  5299 net.cpp:380] InnerProduct1 -> InnerProduct1
I1007 22:14:29.095590  5299 net.cpp:122] Setting up InnerProduct1
I1007 22:14:29.095595  5299 net.cpp:129] Top shape: 100 10 (1000)
I1007 22:14:29.095598  5299 net.cpp:137] Memory required for data: 522801200
I1007 22:14:29.095603  5299 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I1007 22:14:29.095608  5299 net.cpp:84] Creating Layer SoftmaxWithLoss1
I1007 22:14:29.095612  5299 net.cpp:406] SoftmaxWithLoss1 <- InnerProduct1
I1007 22:14:29.095614  5299 net.cpp:406] SoftmaxWithLoss1 <- Data2
I1007 22:14:29.095618  5299 net.cpp:380] SoftmaxWithLoss1 -> SoftmaxWithLoss1
I1007 22:14:29.095625  5299 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I1007 22:14:29.097699  5299 net.cpp:122] Setting up SoftmaxWithLoss1
I1007 22:14:29.097707  5299 net.cpp:129] Top shape: (1)
I1007 22:14:29.097709  5299 net.cpp:132]     with loss weight 1
I1007 22:14:29.097723  5299 net.cpp:137] Memory required for data: 522801204
I1007 22:14:29.097725  5299 net.cpp:198] SoftmaxWithLoss1 needs backward computation.
I1007 22:14:29.097728  5299 net.cpp:198] InnerProduct1 needs backward computation.
I1007 22:14:29.097731  5299 net.cpp:198] Pooling1 needs backward computation.
I1007 22:14:29.097733  5299 net.cpp:198] M2PELU31 needs backward computation.
I1007 22:14:29.097735  5299 net.cpp:198] Eltwise15 needs backward computation.
I1007 22:14:29.097738  5299 net.cpp:198] Scale33 needs backward computation.
I1007 22:14:29.097740  5299 net.cpp:198] BatchNorm33 needs backward computation.
I1007 22:14:29.097743  5299 net.cpp:198] Convolution33 needs backward computation.
I1007 22:14:29.097744  5299 net.cpp:198] M2PELU30 needs backward computation.
I1007 22:14:29.097746  5299 net.cpp:198] Scale32 needs backward computation.
I1007 22:14:29.097748  5299 net.cpp:198] BatchNorm32 needs backward computation.
I1007 22:14:29.097750  5299 net.cpp:198] Convolution32 needs backward computation.
I1007 22:14:29.097754  5299 net.cpp:198] Eltwise14_M2PELU29_0_split needs backward computation.
I1007 22:14:29.097755  5299 net.cpp:198] M2PELU29 needs backward computation.
I1007 22:14:29.097757  5299 net.cpp:198] Eltwise14 needs backward computation.
I1007 22:14:29.097760  5299 net.cpp:198] Scale31 needs backward computation.
I1007 22:14:29.097762  5299 net.cpp:198] BatchNorm31 needs backward computation.
I1007 22:14:29.097764  5299 net.cpp:198] Convolution31 needs backward computation.
I1007 22:14:29.097766  5299 net.cpp:198] M2PELU28 needs backward computation.
I1007 22:14:29.097769  5299 net.cpp:198] Scale30 needs backward computation.
I1007 22:14:29.097771  5299 net.cpp:198] BatchNorm30 needs backward computation.
I1007 22:14:29.097774  5299 net.cpp:198] Convolution30 needs backward computation.
I1007 22:14:29.097777  5299 net.cpp:198] Eltwise13_M2PELU27_0_split needs backward computation.
I1007 22:14:29.097780  5299 net.cpp:198] M2PELU27 needs backward computation.
I1007 22:14:29.097782  5299 net.cpp:198] Eltwise13 needs backward computation.
I1007 22:14:29.097792  5299 net.cpp:198] Scale29 needs backward computation.
I1007 22:14:29.097796  5299 net.cpp:198] BatchNorm29 needs backward computation.
I1007 22:14:29.097798  5299 net.cpp:198] Convolution29 needs backward computation.
I1007 22:14:29.097800  5299 net.cpp:198] M2PELU26 needs backward computation.
I1007 22:14:29.097803  5299 net.cpp:198] Scale28 needs backward computation.
I1007 22:14:29.097805  5299 net.cpp:198] BatchNorm28 needs backward computation.
I1007 22:14:29.097807  5299 net.cpp:198] Convolution28 needs backward computation.
I1007 22:14:29.097810  5299 net.cpp:198] Eltwise12_M2PELU25_0_split needs backward computation.
I1007 22:14:29.097812  5299 net.cpp:198] M2PELU25 needs backward computation.
I1007 22:14:29.097815  5299 net.cpp:198] Eltwise12 needs backward computation.
I1007 22:14:29.097818  5299 net.cpp:198] Scale27 needs backward computation.
I1007 22:14:29.097820  5299 net.cpp:198] BatchNorm27 needs backward computation.
I1007 22:14:29.097822  5299 net.cpp:198] Convolution27 needs backward computation.
I1007 22:14:29.097826  5299 net.cpp:198] M2PELU24 needs backward computation.
I1007 22:14:29.097827  5299 net.cpp:198] Scale26 needs backward computation.
I1007 22:14:29.097829  5299 net.cpp:198] BatchNorm26 needs backward computation.
I1007 22:14:29.097831  5299 net.cpp:198] Convolution26 needs backward computation.
I1007 22:14:29.097834  5299 net.cpp:198] Eltwise11_M2PELU23_0_split needs backward computation.
I1007 22:14:29.097836  5299 net.cpp:198] M2PELU23 needs backward computation.
I1007 22:14:29.097839  5299 net.cpp:198] Eltwise11 needs backward computation.
I1007 22:14:29.097841  5299 net.cpp:198] Scale25 needs backward computation.
I1007 22:14:29.097844  5299 net.cpp:198] BatchNorm25 needs backward computation.
I1007 22:14:29.097846  5299 net.cpp:198] Convolution25 needs backward computation.
I1007 22:14:29.097848  5299 net.cpp:198] M2PELU22 needs backward computation.
I1007 22:14:29.097851  5299 net.cpp:198] Scale24 needs backward computation.
I1007 22:14:29.097853  5299 net.cpp:198] BatchNorm24 needs backward computation.
I1007 22:14:29.097856  5299 net.cpp:198] Convolution24 needs backward computation.
I1007 22:14:29.097858  5299 net.cpp:198] Scale23 needs backward computation.
I1007 22:14:29.097860  5299 net.cpp:198] BatchNorm23 needs backward computation.
I1007 22:14:29.097862  5299 net.cpp:198] Convolution23 needs backward computation.
I1007 22:14:29.097865  5299 net.cpp:198] Eltwise10_M2PELU21_0_split needs backward computation.
I1007 22:14:29.097868  5299 net.cpp:198] M2PELU21 needs backward computation.
I1007 22:14:29.097870  5299 net.cpp:198] Eltwise10 needs backward computation.
I1007 22:14:29.097873  5299 net.cpp:198] Scale22 needs backward computation.
I1007 22:14:29.097877  5299 net.cpp:198] BatchNorm22 needs backward computation.
I1007 22:14:29.097878  5299 net.cpp:198] Convolution22 needs backward computation.
I1007 22:14:29.097880  5299 net.cpp:198] M2PELU20 needs backward computation.
I1007 22:14:29.097883  5299 net.cpp:198] Scale21 needs backward computation.
I1007 22:14:29.097885  5299 net.cpp:198] BatchNorm21 needs backward computation.
I1007 22:14:29.097888  5299 net.cpp:198] Convolution21 needs backward computation.
I1007 22:14:29.097892  5299 net.cpp:198] Eltwise9_M2PELU19_0_split needs backward computation.
I1007 22:14:29.097893  5299 net.cpp:198] M2PELU19 needs backward computation.
I1007 22:14:29.097896  5299 net.cpp:198] Eltwise9 needs backward computation.
I1007 22:14:29.097898  5299 net.cpp:198] Scale20 needs backward computation.
I1007 22:14:29.097901  5299 net.cpp:198] BatchNorm20 needs backward computation.
I1007 22:14:29.097903  5299 net.cpp:198] Convolution20 needs backward computation.
I1007 22:14:29.097906  5299 net.cpp:198] M2PELU18 needs backward computation.
I1007 22:14:29.097908  5299 net.cpp:198] Scale19 needs backward computation.
I1007 22:14:29.097910  5299 net.cpp:198] BatchNorm19 needs backward computation.
I1007 22:14:29.097913  5299 net.cpp:198] Convolution19 needs backward computation.
I1007 22:14:29.097916  5299 net.cpp:198] Eltwise8_M2PELU17_0_split needs backward computation.
I1007 22:14:29.097923  5299 net.cpp:198] M2PELU17 needs backward computation.
I1007 22:14:29.097925  5299 net.cpp:198] Eltwise8 needs backward computation.
I1007 22:14:29.097928  5299 net.cpp:198] Scale18 needs backward computation.
I1007 22:14:29.097930  5299 net.cpp:198] BatchNorm18 needs backward computation.
I1007 22:14:29.097932  5299 net.cpp:198] Convolution18 needs backward computation.
I1007 22:14:29.097935  5299 net.cpp:198] M2PELU16 needs backward computation.
I1007 22:14:29.097937  5299 net.cpp:198] Scale17 needs backward computation.
I1007 22:14:29.097939  5299 net.cpp:198] BatchNorm17 needs backward computation.
I1007 22:14:29.097941  5299 net.cpp:198] Convolution17 needs backward computation.
I1007 22:14:29.097944  5299 net.cpp:198] Eltwise7_M2PELU15_0_split needs backward computation.
I1007 22:14:29.097947  5299 net.cpp:198] M2PELU15 needs backward computation.
I1007 22:14:29.097949  5299 net.cpp:198] Eltwise7 needs backward computation.
I1007 22:14:29.097952  5299 net.cpp:198] Scale16 needs backward computation.
I1007 22:14:29.097956  5299 net.cpp:198] BatchNorm16 needs backward computation.
I1007 22:14:29.097959  5299 net.cpp:198] Convolution16 needs backward computation.
I1007 22:14:29.097961  5299 net.cpp:198] M2PELU14 needs backward computation.
I1007 22:14:29.097964  5299 net.cpp:198] Scale15 needs backward computation.
I1007 22:14:29.097965  5299 net.cpp:198] BatchNorm15 needs backward computation.
I1007 22:14:29.097968  5299 net.cpp:198] Convolution15 needs backward computation.
I1007 22:14:29.097970  5299 net.cpp:198] Eltwise6_M2PELU13_0_split needs backward computation.
I1007 22:14:29.097973  5299 net.cpp:198] M2PELU13 needs backward computation.
I1007 22:14:29.097975  5299 net.cpp:198] Eltwise6 needs backward computation.
I1007 22:14:29.097978  5299 net.cpp:198] Scale14 needs backward computation.
I1007 22:14:29.097980  5299 net.cpp:198] BatchNorm14 needs backward computation.
I1007 22:14:29.097982  5299 net.cpp:198] Convolution14 needs backward computation.
I1007 22:14:29.097985  5299 net.cpp:198] M2PELU12 needs backward computation.
I1007 22:14:29.097987  5299 net.cpp:198] Scale13 needs backward computation.
I1007 22:14:29.097990  5299 net.cpp:198] BatchNorm13 needs backward computation.
I1007 22:14:29.097992  5299 net.cpp:198] Convolution13 needs backward computation.
I1007 22:14:29.097995  5299 net.cpp:198] Scale12 needs backward computation.
I1007 22:14:29.097997  5299 net.cpp:198] BatchNorm12 needs backward computation.
I1007 22:14:29.098000  5299 net.cpp:198] Convolution12 needs backward computation.
I1007 22:14:29.098001  5299 net.cpp:198] Eltwise5_M2PELU11_0_split needs backward computation.
I1007 22:14:29.098004  5299 net.cpp:198] M2PELU11 needs backward computation.
I1007 22:14:29.098006  5299 net.cpp:198] Eltwise5 needs backward computation.
I1007 22:14:29.098009  5299 net.cpp:198] Scale11 needs backward computation.
I1007 22:14:29.098011  5299 net.cpp:198] BatchNorm11 needs backward computation.
I1007 22:14:29.098014  5299 net.cpp:198] Convolution11 needs backward computation.
I1007 22:14:29.098016  5299 net.cpp:198] M2PELU10 needs backward computation.
I1007 22:14:29.098018  5299 net.cpp:198] Scale10 needs backward computation.
I1007 22:14:29.098021  5299 net.cpp:198] BatchNorm10 needs backward computation.
I1007 22:14:29.098023  5299 net.cpp:198] Convolution10 needs backward computation.
I1007 22:14:29.098026  5299 net.cpp:198] Eltwise4_M2PELU9_0_split needs backward computation.
I1007 22:14:29.098028  5299 net.cpp:198] M2PELU9 needs backward computation.
I1007 22:14:29.098031  5299 net.cpp:198] Eltwise4 needs backward computation.
I1007 22:14:29.098034  5299 net.cpp:198] Scale9 needs backward computation.
I1007 22:14:29.098037  5299 net.cpp:198] BatchNorm9 needs backward computation.
I1007 22:14:29.098038  5299 net.cpp:198] Convolution9 needs backward computation.
I1007 22:14:29.098042  5299 net.cpp:198] M2PELU8 needs backward computation.
I1007 22:14:29.098043  5299 net.cpp:198] Scale8 needs backward computation.
I1007 22:14:29.098049  5299 net.cpp:198] BatchNorm8 needs backward computation.
I1007 22:14:29.098052  5299 net.cpp:198] Convolution8 needs backward computation.
I1007 22:14:29.098054  5299 net.cpp:198] Eltwise3_M2PELU7_0_split needs backward computation.
I1007 22:14:29.098057  5299 net.cpp:198] M2PELU7 needs backward computation.
I1007 22:14:29.098059  5299 net.cpp:198] Eltwise3 needs backward computation.
I1007 22:14:29.098062  5299 net.cpp:198] Scale7 needs backward computation.
I1007 22:14:29.098064  5299 net.cpp:198] BatchNorm7 needs backward computation.
I1007 22:14:29.098067  5299 net.cpp:198] Convolution7 needs backward computation.
I1007 22:14:29.098069  5299 net.cpp:198] M2PELU6 needs backward computation.
I1007 22:14:29.098071  5299 net.cpp:198] Scale6 needs backward computation.
I1007 22:14:29.098073  5299 net.cpp:198] BatchNorm6 needs backward computation.
I1007 22:14:29.098075  5299 net.cpp:198] Convolution6 needs backward computation.
I1007 22:14:29.098078  5299 net.cpp:198] Eltwise2_M2PELU5_0_split needs backward computation.
I1007 22:14:29.098081  5299 net.cpp:198] M2PELU5 needs backward computation.
I1007 22:14:29.098083  5299 net.cpp:198] Eltwise2 needs backward computation.
I1007 22:14:29.098086  5299 net.cpp:198] Scale5 needs backward computation.
I1007 22:14:29.098088  5299 net.cpp:198] BatchNorm5 needs backward computation.
I1007 22:14:29.098091  5299 net.cpp:198] Convolution5 needs backward computation.
I1007 22:14:29.098093  5299 net.cpp:198] M2PELU4 needs backward computation.
I1007 22:14:29.098096  5299 net.cpp:198] Scale4 needs backward computation.
I1007 22:14:29.098098  5299 net.cpp:198] BatchNorm4 needs backward computation.
I1007 22:14:29.098100  5299 net.cpp:198] Convolution4 needs backward computation.
I1007 22:14:29.098104  5299 net.cpp:198] Eltwise1_M2PELU3_0_split needs backward computation.
I1007 22:14:29.098105  5299 net.cpp:198] M2PELU3 needs backward computation.
I1007 22:14:29.098109  5299 net.cpp:198] Eltwise1 needs backward computation.
I1007 22:14:29.098111  5299 net.cpp:198] Scale3 needs backward computation.
I1007 22:14:29.098114  5299 net.cpp:198] BatchNorm3 needs backward computation.
I1007 22:14:29.098116  5299 net.cpp:198] Convolution3 needs backward computation.
I1007 22:14:29.098119  5299 net.cpp:198] M2PELU2 needs backward computation.
I1007 22:14:29.098120  5299 net.cpp:198] Scale2 needs backward computation.
I1007 22:14:29.098124  5299 net.cpp:198] BatchNorm2 needs backward computation.
I1007 22:14:29.098125  5299 net.cpp:198] Convolution2 needs backward computation.
I1007 22:14:29.098129  5299 net.cpp:198] Convolution1_M2PELU1_0_split needs backward computation.
I1007 22:14:29.098130  5299 net.cpp:198] M2PELU1 needs backward computation.
I1007 22:14:29.098134  5299 net.cpp:198] Scale1 needs backward computation.
I1007 22:14:29.098135  5299 net.cpp:198] BatchNorm1 needs backward computation.
I1007 22:14:29.098137  5299 net.cpp:198] Convolution1 needs backward computation.
I1007 22:14:29.098140  5299 net.cpp:200] Data1 does not need backward computation.
I1007 22:14:29.098141  5299 net.cpp:242] This network produces output SoftmaxWithLoss1
I1007 22:14:29.098194  5299 net.cpp:255] Network initialization done.
I1007 22:14:29.100719  5299 upgrade_proto.cpp:77] Attempting to upgrade batch norm layers using deprecated params: /home/x306/caffe/xn/PENLU/neural/resnet/res32/res32_mpelu_decay_gauss.prototxt
I1007 22:14:29.100729  5299 upgrade_proto.cpp:80] Successfully upgraded batch norm layers using deprecated params.
I1007 22:14:29.100733  5299 solver.cpp:172] Creating test net (#0) specified by net file: /home/x306/caffe/xn/PENLU/neural/resnet/res32/res32_mpelu_decay_gauss.prototxt
I1007 22:14:29.100843  5299 net.cpp:294] The NetState phase (1) differed from the phase (0) specified by a rule in layer Data1
I1007 22:14:29.101518  5299 net.cpp:51] Initializing net from parameters: 
name: "resnet_cifar10"
state {
  phase: TEST
}
layer {
  name: "Data1"
  type: "Data"
  top: "Data1"
  top: "Data2"
  include {
    phase: TEST
  }
  transform_param {
    mean_file: "/home/x306/caffe/xn/PENLU/data/cifar10/mean.binaryproto"
  }
  data_param {
    source: "/home/x306/caffe/xn/PENLU/data/cifar10/cifar10_test_lmdb"
    batch_size: 100
    backend: LMDB
  }
}
layer {
  name: "Convolution1"
  type: "Convolution"
  bottom: "Data1"
  top: "Convolution1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm1"
  type: "BatchNorm"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale1"
  type: "Scale"
  bottom: "Convolution1"
  top: "Convolution1"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU1"
  type: "M2PELU"
  bottom: "Convolution1"
  top: "Convolution1"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution2"
  type: "Convolution"
  bottom: "Convolution1"
  top: "Convolution2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm2"
  type: "BatchNorm"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale2"
  type: "Scale"
  bottom: "Convolution2"
  top: "Convolution2"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU2"
  type: "M2PELU"
  bottom: "Convolution2"
  top: "Convolution2"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution3"
  type: "Convolution"
  bottom: "Convolution2"
  top: "Convolution3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm3"
  type: "BatchNorm"
  bottom: "Convolution3"
  top: "Convolution3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale3"
  type: "Scale"
  bottom: "Convolution3"
  top: "Convolution3"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise1"
  type: "Eltwise"
  bottom: "Convolution1"
  bottom: "Convolution3"
  top: "Eltwise1"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU3"
  type: "M2PELU"
  bottom: "Eltwise1"
  top: "Eltwise1"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution4"
  type: "Convolution"
  bottom: "Eltwise1"
  top: "Convolution4"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm4"
  type: "BatchNorm"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale4"
  type: "Scale"
  bottom: "Convolution4"
  top: "Convolution4"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU4"
  type: "M2PELU"
  bottom: "Convolution4"
  top: "Convolution4"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution5"
  type: "Convolution"
  bottom: "Convolution4"
  top: "Convolution5"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm5"
  type: "BatchNorm"
  bottom: "Convolution5"
  top: "Convolution5"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale5"
  type: "Scale"
  bottom: "Convolution5"
  top: "Convolution5"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise2"
  type: "Eltwise"
  bottom: "Eltwise1"
  bottom: "Convolution5"
  top: "Eltwise2"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU5"
  type: "M2PELU"
  bottom: "Eltwise2"
  top: "Eltwise2"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution6"
  type: "Convolution"
  bottom: "Eltwise2"
  top: "Convolution6"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm6"
  type: "BatchNorm"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale6"
  type: "Scale"
  bottom: "Convolution6"
  top: "Convolution6"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU6"
  type: "M2PELU"
  bottom: "Convolution6"
  top: "Convolution6"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution7"
  type: "Convolution"
  bottom: "Convolution6"
  top: "Convolution7"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm7"
  type: "BatchNorm"
  bottom: "Convolution7"
  top: "Convolution7"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale7"
  type: "Scale"
  bottom: "Convolution7"
  top: "Convolution7"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise3"
  type: "Eltwise"
  bottom: "Eltwise2"
  bottom: "Convolution7"
  top: "Eltwise3"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU7"
  type: "M2PELU"
  bottom: "Eltwise3"
  top: "Eltwise3"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution8"
  type: "Convolution"
  bottom: "Eltwise3"
  top: "Convolution8"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm8"
  type: "BatchNorm"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale8"
  type: "Scale"
  bottom: "Convolution8"
  top: "Convolution8"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU8"
  type: "M2PELU"
  bottom: "Convolution8"
  top: "Convolution8"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution9"
  type: "Convolution"
  bottom: "Convolution8"
  top: "Convolution9"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm9"
  type: "BatchNorm"
  bottom: "Convolution9"
  top: "Convolution9"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale9"
  type: "Scale"
  bottom: "Convolution9"
  top: "Convolution9"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise4"
  type: "Eltwise"
  bottom: "Eltwise3"
  bottom: "Convolution9"
  top: "Eltwise4"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU9"
  type: "M2PELU"
  bottom: "Eltwise4"
  top: "Eltwise4"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution10"
  type: "Convolution"
  bottom: "Eltwise4"
  top: "Convolution10"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm10"
  type: "BatchNorm"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale10"
  type: "Scale"
  bottom: "Convolution10"
  top: "Convolution10"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU10"
  type: "M2PELU"
  bottom: "Convolution10"
  top: "Convolution10"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution11"
  type: "Convolution"
  bottom: "Convolution10"
  top: "Convolution11"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.118
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm11"
  type: "BatchNorm"
  bottom: "Convolution11"
  top: "Convolution11"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale11"
  type: "Scale"
  bottom: "Convolution11"
  top: "Convolution11"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise5"
  type: "Eltwise"
  bottom: "Eltwise4"
  bottom: "Convolution11"
  top: "Eltwise5"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU11"
  type: "M2PELU"
  bottom: "Eltwise5"
  top: "Eltwise5"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution12"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution12"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.25
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm12"
  type: "BatchNorm"
  bottom: "Convolution12"
  top: "Convolution12"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale12"
  type: "Scale"
  bottom: "Convolution12"
  top: "Convolution12"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution13"
  type: "Convolution"
  bottom: "Eltwise5"
  top: "Convolution13"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm13"
  type: "BatchNorm"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale13"
  type: "Scale"
  bottom: "Convolution13"
  top: "Convolution13"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU12"
  type: "M2PELU"
  bottom: "Convolution13"
  top: "Convolution13"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution14"
  type: "Convolution"
  bottom: "Convolution13"
  top: "Convolution14"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm14"
  type: "BatchNorm"
  bottom: "Convolution14"
  top: "Convolution14"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale14"
  type: "Scale"
  bottom: "Convolution14"
  top: "Convolution14"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise6"
  type: "Eltwise"
  bottom: "Convolution12"
  bottom: "Convolution14"
  top: "Eltwise6"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU13"
  type: "M2PELU"
  bottom: "Eltwise6"
  top: "Eltwise6"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution15"
  type: "Convolution"
  bottom: "Eltwise6"
  top: "Convolution15"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm15"
  type: "BatchNorm"
  bottom: "Convolution15"
  top: "Convolution15"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale15"
  type: "Scale"
  bottom: "Convolution15"
  top: "Convolution15"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU14"
  type: "M2PELU"
  bottom: "Convolution15"
  top: "Convolution15"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution16"
  type: "Convolution"
  bottom: "Convolution15"
  top: "Convolution16"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm16"
  type: "BatchNorm"
  bottom: "Convolution16"
  top: "Convolution16"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale16"
  type: "Scale"
  bottom: "Convolution16"
  top: "Convolution16"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise7"
  type: "Eltwise"
  bottom: "Eltwise6"
  bottom: "Convolution16"
  top: "Eltwise7"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU15"
  type: "M2PELU"
  bottom: "Eltwise7"
  top: "Eltwise7"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution17"
  type: "Convolution"
  bottom: "Eltwise7"
  top: "Convolution17"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm17"
  type: "BatchNorm"
  bottom: "Convolution17"
  top: "Convolution17"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale17"
  type: "Scale"
  bottom: "Convolution17"
  top: "Convolution17"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU16"
  type: "M2PELU"
  bottom: "Convolution17"
  top: "Convolution17"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution18"
  type: "Convolution"
  bottom: "Convolution17"
  top: "Convolution18"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm18"
  type: "BatchNorm"
  bottom: "Convolution18"
  top: "Convolution18"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale18"
  type: "Scale"
  bottom: "Convolution18"
  top: "Convolution18"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise8"
  type: "Eltwise"
  bottom: "Eltwise7"
  bottom: "Convolution18"
  top: "Eltwise8"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU17"
  type: "M2PELU"
  bottom: "Eltwise8"
  top: "Eltwise8"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution19"
  type: "Convolution"
  bottom: "Eltwise8"
  top: "Convolution19"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm19"
  type: "BatchNorm"
  bottom: "Convolution19"
  top: "Convolution19"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale19"
  type: "Scale"
  bottom: "Convolution19"
  top: "Convolution19"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU18"
  type: "M2PELU"
  bottom: "Convolution19"
  top: "Convolution19"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution20"
  type: "Convolution"
  bottom: "Convolution19"
  top: "Convolution20"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm20"
  type: "BatchNorm"
  bottom: "Convolution20"
  top: "Convolution20"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale20"
  type: "Scale"
  bottom: "Convolution20"
  top: "Convolution20"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise9"
  type: "Eltwise"
  bottom: "Eltwise8"
  bottom: "Convolution20"
  top: "Eltwise9"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU19"
  type: "M2PELU"
  bottom: "Eltwise9"
  top: "Eltwise9"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution21"
  type: "Convolution"
  bottom: "Eltwise9"
  top: "Convolution21"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm21"
  type: "BatchNorm"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale21"
  type: "Scale"
  bottom: "Convolution21"
  top: "Convolution21"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU20"
  type: "M2PELU"
  bottom: "Convolution21"
  top: "Convolution21"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution22"
  type: "Convolution"
  bottom: "Convolution21"
  top: "Convolution22"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 32
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.083
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm22"
  type: "BatchNorm"
  bottom: "Convolution22"
  top: "Convolution22"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale22"
  type: "Scale"
  bottom: "Convolution22"
  top: "Convolution22"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise10"
  type: "Eltwise"
  bottom: "Eltwise9"
  bottom: "Convolution22"
  top: "Eltwise10"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU21"
  type: "M2PELU"
  bottom: "Eltwise10"
  top: "Eltwise10"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution23"
  type: "Convolution"
  bottom: "Eltwise10"
  top: "Convolution23"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 0
    kernel_size: 1
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.17677669
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm23"
  type: "BatchNorm"
  bottom: "Convolution23"
  top: "Convolution23"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale23"
  type: "Scale"
  bottom: "Convolution23"
  top: "Convolution23"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Convolution24"
  type: "Convolution"
  bottom: "Eltwise10"
  top: "Convolution24"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 2
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm24"
  type: "BatchNorm"
  bottom: "Convolution24"
  top: "Convolution24"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale24"
  type: "Scale"
  bottom: "Convolution24"
  top: "Convolution24"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "M2PELU22"
  type: "M2PELU"
  bottom: "Convolution24"
  top: "Convolution24"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution25"
  type: "Convolution"
  bottom: "Convolution24"
  top: "Convolution25"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm25"
  type: "BatchNorm"
  bottom: "Convolution25"
  top: "Convolution25"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
}
layer {
  name: "Scale25"
  type: "Scale"
  bottom: "Convolution25"
  top: "Convolution25"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "Eltwise11"
  type: "Eltwise"
  bottom: "Convolution23"
  bottom: "Convolution25"
  top: "Eltwise11"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "M2PELU23"
  type: "M2PELU"
  bottom: "Eltwise11"
  top: "Eltwise11"
  param {
    lr_mult: 2
    decay_mult: 2
  }
  param {
    lr_mult: 2
    decay_mult: 2
  }
  m2pelu_param {
    alpha_filler {
      type: "constant"
      value: 1
    }
    beta_filler {
      type: "constant"
      value: 1
    }
  }
}
layer {
  name: "Convolution26"
  type: "Convolution"
  bottom: "Eltwise11"
  top: "Convolution26"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    pad: 1
    kernel_size: 3
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.059
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "BatchNorm26"
  type: "BatchNorm"
  bottom: "Convolution26"
  top: "Convolution26"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    decay_mult: 0
  }
  param {
    lr_mult: 0
    d
I1007 22:14:29.101910  5299 layer_factory.hpp:77] Creating layer Data1
I1007 22:14:29.101941  5299 db_lmdb.cpp:35] Opened lmdb /home/x306/caffe/xn/PENLU/data/cifar10/cifar10_test_lmdb
I1007 22:14:29.101956  5299 net.cpp:84] Creating Layer Data1
I1007 22:14:29.101960  5299 net.cpp:380] Data1 -> Data1
I1007 22:14:29.101966  5299 net.cpp:380] Data1 -> Data2
I1007 22:14:29.101971  5299 data_transformer.cpp:25] Loading mean file from: /home/x306/caffe/xn/PENLU/data/cifar10/mean.binaryproto
I1007 22:14:29.102087  5299 data_layer.cpp:45] output data size: 100,3,32,32
I1007 22:14:29.112907  5299 net.cpp:122] Setting up Data1
I1007 22:14:29.112928  5299 net.cpp:129] Top shape: 100 3 32 32 (307200)
I1007 22:14:29.112933  5299 net.cpp:129] Top shape: 100 (100)
I1007 22:14:29.112936  5299 net.cpp:137] Memory required for data: 1229200
I1007 22:14:29.112941  5299 layer_factory.hpp:77] Creating layer Data2_Data1_1_split
I1007 22:14:29.112951  5299 net.cpp:84] Creating Layer Data2_Data1_1_split
I1007 22:14:29.112953  5299 net.cpp:406] Data2_Data1_1_split <- Data2
I1007 22:14:29.112959  5299 net.cpp:380] Data2_Data1_1_split -> Data2_Data1_1_split_0
I1007 22:14:29.112967  5299 net.cpp:380] Data2_Data1_1_split -> Data2_Data1_1_split_1
I1007 22:14:29.113025  5299 net.cpp:122] Setting up Data2_Data1_1_split
I1007 22:14:29.113031  5299 net.cpp:129] Top shape: 100 (100)
I1007 22:14:29.113034  5299 net.cpp:129] Top shape: 100 (100)
I1007 22:14:29.113036  5299 net.cpp:137] Memory required for data: 1230000
I1007 22:14:29.113039  5299 layer_factory.hpp:77] Creating layer Convolution1
I1007 22:14:29.113049  5299 net.cpp:84] Creating Layer Convolution1
I1007 22:14:29.113052  5299 net.cpp:406] Convolution1 <- Data1
I1007 22:14:29.113056  5299 net.cpp:380] Convolution1 -> Convolution1
I1007 22:14:29.115895  5299 net.cpp:122] Setting up Convolution1
I1007 22:14:29.115916  5299 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:14:29.115919  5299 net.cpp:137] Memory required for data: 7783600
I1007 22:14:29.115932  5299 layer_factory.hpp:77] Creating layer BatchNorm1
I1007 22:14:29.115943  5299 net.cpp:84] Creating Layer BatchNorm1
I1007 22:14:29.115948  5299 net.cpp:406] BatchNorm1 <- Convolution1
I1007 22:14:29.115954  5299 net.cpp:367] BatchNorm1 -> Convolution1 (in-place)
I1007 22:14:29.116212  5299 net.cpp:122] Setting up BatchNorm1
I1007 22:14:29.116224  5299 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:14:29.116227  5299 net.cpp:137] Memory required for data: 14337200
I1007 22:14:29.116240  5299 layer_factory.hpp:77] Creating layer Scale1
I1007 22:14:29.116250  5299 net.cpp:84] Creating Layer Scale1
I1007 22:14:29.116257  5299 net.cpp:406] Scale1 <- Convolution1
I1007 22:14:29.116263  5299 net.cpp:367] Scale1 -> Convolution1 (in-place)
I1007 22:14:29.116314  5299 layer_factory.hpp:77] Creating layer Scale1
I1007 22:14:29.116442  5299 net.cpp:122] Setting up Scale1
I1007 22:14:29.116449  5299 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:14:29.116454  5299 net.cpp:137] Memory required for data: 20890800
I1007 22:14:29.116474  5299 layer_factory.hpp:77] Creating layer M2PELU1
I1007 22:14:29.116487  5299 net.cpp:84] Creating Layer M2PELU1
I1007 22:14:29.116492  5299 net.cpp:406] M2PELU1 <- Convolution1
I1007 22:14:29.116497  5299 net.cpp:367] M2PELU1 -> Convolution1 (in-place)
I1007 22:14:29.116658  5299 net.cpp:122] Setting up M2PELU1
I1007 22:14:29.116665  5299 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:14:29.116670  5299 net.cpp:137] Memory required for data: 27444400
I1007 22:14:29.116683  5299 layer_factory.hpp:77] Creating layer Convolution1_M2PELU1_0_split
I1007 22:14:29.116690  5299 net.cpp:84] Creating Layer Convolution1_M2PELU1_0_split
I1007 22:14:29.116699  5299 net.cpp:406] Convolution1_M2PELU1_0_split <- Convolution1
I1007 22:14:29.116705  5299 net.cpp:380] Convolution1_M2PELU1_0_split -> Convolution1_M2PELU1_0_split_0
I1007 22:14:29.116715  5299 net.cpp:380] Convolution1_M2PELU1_0_split -> Convolution1_M2PELU1_0_split_1
I1007 22:14:29.116755  5299 net.cpp:122] Setting up Convolution1_M2PELU1_0_split
I1007 22:14:29.116763  5299 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:14:29.116768  5299 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:14:29.116772  5299 net.cpp:137] Memory required for data: 40551600
I1007 22:14:29.116776  5299 layer_factory.hpp:77] Creating layer Convolution2
I1007 22:14:29.116789  5299 net.cpp:84] Creating Layer Convolution2
I1007 22:14:29.116796  5299 net.cpp:406] Convolution2 <- Convolution1_M2PELU1_0_split_0
I1007 22:14:29.116807  5299 net.cpp:380] Convolution2 -> Convolution2
I1007 22:14:29.120916  5299 net.cpp:122] Setting up Convolution2
I1007 22:14:29.120926  5299 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:14:29.120929  5299 net.cpp:137] Memory required for data: 47105200
I1007 22:14:29.120934  5299 layer_factory.hpp:77] Creating layer BatchNorm2
I1007 22:14:29.120940  5299 net.cpp:84] Creating Layer BatchNorm2
I1007 22:14:29.120944  5299 net.cpp:406] BatchNorm2 <- Convolution2
I1007 22:14:29.120947  5299 net.cpp:367] BatchNorm2 -> Convolution2 (in-place)
I1007 22:14:29.121091  5299 net.cpp:122] Setting up BatchNorm2
I1007 22:14:29.121096  5299 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:14:29.121098  5299 net.cpp:137] Memory required for data: 53658800
I1007 22:14:29.121104  5299 layer_factory.hpp:77] Creating layer Scale2
I1007 22:14:29.121107  5299 net.cpp:84] Creating Layer Scale2
I1007 22:14:29.121110  5299 net.cpp:406] Scale2 <- Convolution2
I1007 22:14:29.121116  5299 net.cpp:367] Scale2 -> Convolution2 (in-place)
I1007 22:14:29.121145  5299 layer_factory.hpp:77] Creating layer Scale2
I1007 22:14:29.121227  5299 net.cpp:122] Setting up Scale2
I1007 22:14:29.121232  5299 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:14:29.121233  5299 net.cpp:137] Memory required for data: 60212400
I1007 22:14:29.121238  5299 layer_factory.hpp:77] Creating layer M2PELU2
I1007 22:14:29.121244  5299 net.cpp:84] Creating Layer M2PELU2
I1007 22:14:29.121246  5299 net.cpp:406] M2PELU2 <- Convolution2
I1007 22:14:29.121250  5299 net.cpp:367] M2PELU2 -> Convolution2 (in-place)
I1007 22:14:29.121350  5299 net.cpp:122] Setting up M2PELU2
I1007 22:14:29.121353  5299 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:14:29.121356  5299 net.cpp:137] Memory required for data: 66766000
I1007 22:14:29.121361  5299 layer_factory.hpp:77] Creating layer Convolution3
I1007 22:14:29.121369  5299 net.cpp:84] Creating Layer Convolution3
I1007 22:14:29.121373  5299 net.cpp:406] Convolution3 <- Convolution2
I1007 22:14:29.121377  5299 net.cpp:380] Convolution3 -> Convolution3
I1007 22:14:29.127363  5299 net.cpp:122] Setting up Convolution3
I1007 22:14:29.127374  5299 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:14:29.127377  5299 net.cpp:137] Memory required for data: 73319600
I1007 22:14:29.127382  5299 layer_factory.hpp:77] Creating layer BatchNorm3
I1007 22:14:29.127389  5299 net.cpp:84] Creating Layer BatchNorm3
I1007 22:14:29.127393  5299 net.cpp:406] BatchNorm3 <- Convolution3
I1007 22:14:29.127398  5299 net.cpp:367] BatchNorm3 -> Convolution3 (in-place)
I1007 22:14:29.127552  5299 net.cpp:122] Setting up BatchNorm3
I1007 22:14:29.127557  5299 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:14:29.127558  5299 net.cpp:137] Memory required for data: 79873200
I1007 22:14:29.127564  5299 layer_factory.hpp:77] Creating layer Scale3
I1007 22:14:29.127569  5299 net.cpp:84] Creating Layer Scale3
I1007 22:14:29.127573  5299 net.cpp:406] Scale3 <- Convolution3
I1007 22:14:29.127575  5299 net.cpp:367] Scale3 -> Convolution3 (in-place)
I1007 22:14:29.127604  5299 layer_factory.hpp:77] Creating layer Scale3
I1007 22:14:29.127683  5299 net.cpp:122] Setting up Scale3
I1007 22:14:29.127687  5299 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:14:29.127689  5299 net.cpp:137] Memory required for data: 86426800
I1007 22:14:29.127693  5299 layer_factory.hpp:77] Creating layer Eltwise1
I1007 22:14:29.127698  5299 net.cpp:84] Creating Layer Eltwise1
I1007 22:14:29.127701  5299 net.cpp:406] Eltwise1 <- Convolution1_M2PELU1_0_split_1
I1007 22:14:29.127703  5299 net.cpp:406] Eltwise1 <- Convolution3
I1007 22:14:29.127709  5299 net.cpp:380] Eltwise1 -> Eltwise1
I1007 22:14:29.127727  5299 net.cpp:122] Setting up Eltwise1
I1007 22:14:29.127730  5299 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:14:29.127732  5299 net.cpp:137] Memory required for data: 92980400
I1007 22:14:29.127734  5299 layer_factory.hpp:77] Creating layer M2PELU3
I1007 22:14:29.127739  5299 net.cpp:84] Creating Layer M2PELU3
I1007 22:14:29.127741  5299 net.cpp:406] M2PELU3 <- Eltwise1
I1007 22:14:29.127745  5299 net.cpp:367] M2PELU3 -> Eltwise1 (in-place)
I1007 22:14:29.127842  5299 net.cpp:122] Setting up M2PELU3
I1007 22:14:29.127846  5299 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:14:29.127849  5299 net.cpp:137] Memory required for data: 99534000
I1007 22:14:29.127852  5299 layer_factory.hpp:77] Creating layer Eltwise1_M2PELU3_0_split
I1007 22:14:29.127858  5299 net.cpp:84] Creating Layer Eltwise1_M2PELU3_0_split
I1007 22:14:29.127861  5299 net.cpp:406] Eltwise1_M2PELU3_0_split <- Eltwise1
I1007 22:14:29.127864  5299 net.cpp:380] Eltwise1_M2PELU3_0_split -> Eltwise1_M2PELU3_0_split_0
I1007 22:14:29.127868  5299 net.cpp:380] Eltwise1_M2PELU3_0_split -> Eltwise1_M2PELU3_0_split_1
I1007 22:14:29.127893  5299 net.cpp:122] Setting up Eltwise1_M2PELU3_0_split
I1007 22:14:29.127897  5299 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:14:29.127899  5299 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:14:29.127902  5299 net.cpp:137] Memory required for data: 112641200
I1007 22:14:29.127903  5299 layer_factory.hpp:77] Creating layer Convolution4
I1007 22:14:29.127909  5299 net.cpp:84] Creating Layer Convolution4
I1007 22:14:29.127912  5299 net.cpp:406] Convolution4 <- Eltwise1_M2PELU3_0_split_0
I1007 22:14:29.127916  5299 net.cpp:380] Convolution4 -> Convolution4
I1007 22:14:29.133915  5299 net.cpp:122] Setting up Convolution4
I1007 22:14:29.133925  5299 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:14:29.133929  5299 net.cpp:137] Memory required for data: 119194800
I1007 22:14:29.133932  5299 layer_factory.hpp:77] Creating layer BatchNorm4
I1007 22:14:29.133939  5299 net.cpp:84] Creating Layer BatchNorm4
I1007 22:14:29.133941  5299 net.cpp:406] BatchNorm4 <- Convolution4
I1007 22:14:29.133944  5299 net.cpp:367] BatchNorm4 -> Convolution4 (in-place)
I1007 22:14:29.134088  5299 net.cpp:122] Setting up BatchNorm4
I1007 22:14:29.134091  5299 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:14:29.134093  5299 net.cpp:137] Memory required for data: 125748400
I1007 22:14:29.134099  5299 layer_factory.hpp:77] Creating layer Scale4
I1007 22:14:29.134104  5299 net.cpp:84] Creating Layer Scale4
I1007 22:14:29.134105  5299 net.cpp:406] Scale4 <- Convolution4
I1007 22:14:29.134109  5299 net.cpp:367] Scale4 -> Convolution4 (in-place)
I1007 22:14:29.134136  5299 layer_factory.hpp:77] Creating layer Scale4
I1007 22:14:29.134214  5299 net.cpp:122] Setting up Scale4
I1007 22:14:29.134218  5299 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:14:29.134227  5299 net.cpp:137] Memory required for data: 132302000
I1007 22:14:29.134235  5299 layer_factory.hpp:77] Creating layer M2PELU4
I1007 22:14:29.134241  5299 net.cpp:84] Creating Layer M2PELU4
I1007 22:14:29.134243  5299 net.cpp:406] M2PELU4 <- Convolution4
I1007 22:14:29.134248  5299 net.cpp:367] M2PELU4 -> Convolution4 (in-place)
I1007 22:14:29.134346  5299 net.cpp:122] Setting up M2PELU4
I1007 22:14:29.134351  5299 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:14:29.134352  5299 net.cpp:137] Memory required for data: 138855600
I1007 22:14:29.134356  5299 layer_factory.hpp:77] Creating layer Convolution5
I1007 22:14:29.134364  5299 net.cpp:84] Creating Layer Convolution5
I1007 22:14:29.134366  5299 net.cpp:406] Convolution5 <- Convolution4
I1007 22:14:29.134371  5299 net.cpp:380] Convolution5 -> Convolution5
I1007 22:14:29.137676  5299 net.cpp:122] Setting up Convolution5
I1007 22:14:29.137684  5299 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:14:29.137687  5299 net.cpp:137] Memory required for data: 145409200
I1007 22:14:29.137692  5299 layer_factory.hpp:77] Creating layer BatchNorm5
I1007 22:14:29.137697  5299 net.cpp:84] Creating Layer BatchNorm5
I1007 22:14:29.137701  5299 net.cpp:406] BatchNorm5 <- Convolution5
I1007 22:14:29.137703  5299 net.cpp:367] BatchNorm5 -> Convolution5 (in-place)
I1007 22:14:29.137850  5299 net.cpp:122] Setting up BatchNorm5
I1007 22:14:29.137854  5299 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:14:29.137856  5299 net.cpp:137] Memory required for data: 151962800
I1007 22:14:29.137861  5299 layer_factory.hpp:77] Creating layer Scale5
I1007 22:14:29.137866  5299 net.cpp:84] Creating Layer Scale5
I1007 22:14:29.137867  5299 net.cpp:406] Scale5 <- Convolution5
I1007 22:14:29.137871  5299 net.cpp:367] Scale5 -> Convolution5 (in-place)
I1007 22:14:29.137900  5299 layer_factory.hpp:77] Creating layer Scale5
I1007 22:14:29.137979  5299 net.cpp:122] Setting up Scale5
I1007 22:14:29.137984  5299 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:14:29.137985  5299 net.cpp:137] Memory required for data: 158516400
I1007 22:14:29.137989  5299 layer_factory.hpp:77] Creating layer Eltwise2
I1007 22:14:29.137995  5299 net.cpp:84] Creating Layer Eltwise2
I1007 22:14:29.137996  5299 net.cpp:406] Eltwise2 <- Eltwise1_M2PELU3_0_split_1
I1007 22:14:29.138000  5299 net.cpp:406] Eltwise2 <- Convolution5
I1007 22:14:29.138003  5299 net.cpp:380] Eltwise2 -> Eltwise2
I1007 22:14:29.138018  5299 net.cpp:122] Setting up Eltwise2
I1007 22:14:29.138022  5299 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:14:29.138025  5299 net.cpp:137] Memory required for data: 165070000
I1007 22:14:29.138026  5299 layer_factory.hpp:77] Creating layer M2PELU5
I1007 22:14:29.138032  5299 net.cpp:84] Creating Layer M2PELU5
I1007 22:14:29.138034  5299 net.cpp:406] M2PELU5 <- Eltwise2
I1007 22:14:29.138038  5299 net.cpp:367] M2PELU5 -> Eltwise2 (in-place)
I1007 22:14:29.138134  5299 net.cpp:122] Setting up M2PELU5
I1007 22:14:29.138139  5299 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:14:29.138141  5299 net.cpp:137] Memory required for data: 171623600
I1007 22:14:29.138144  5299 layer_factory.hpp:77] Creating layer Eltwise2_M2PELU5_0_split
I1007 22:14:29.138149  5299 net.cpp:84] Creating Layer Eltwise2_M2PELU5_0_split
I1007 22:14:29.138150  5299 net.cpp:406] Eltwise2_M2PELU5_0_split <- Eltwise2
I1007 22:14:29.138154  5299 net.cpp:380] Eltwise2_M2PELU5_0_split -> Eltwise2_M2PELU5_0_split_0
I1007 22:14:29.138159  5299 net.cpp:380] Eltwise2_M2PELU5_0_split -> Eltwise2_M2PELU5_0_split_1
I1007 22:14:29.138183  5299 net.cpp:122] Setting up Eltwise2_M2PELU5_0_split
I1007 22:14:29.138187  5299 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:14:29.138190  5299 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:14:29.138192  5299 net.cpp:137] Memory required for data: 184730800
I1007 22:14:29.138195  5299 layer_factory.hpp:77] Creating layer Convolution6
I1007 22:14:29.138201  5299 net.cpp:84] Creating Layer Convolution6
I1007 22:14:29.138204  5299 net.cpp:406] Convolution6 <- Eltwise2_M2PELU5_0_split_0
I1007 22:14:29.138216  5299 net.cpp:380] Convolution6 -> Convolution6
I1007 22:14:29.144291  5299 net.cpp:122] Setting up Convolution6
I1007 22:14:29.144307  5299 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:14:29.144312  5299 net.cpp:137] Memory required for data: 191284400
I1007 22:14:29.144320  5299 layer_factory.hpp:77] Creating layer BatchNorm6
I1007 22:14:29.144326  5299 net.cpp:84] Creating Layer BatchNorm6
I1007 22:14:29.144331  5299 net.cpp:406] BatchNorm6 <- Convolution6
I1007 22:14:29.144338  5299 net.cpp:367] BatchNorm6 -> Convolution6 (in-place)
I1007 22:14:29.144544  5299 net.cpp:122] Setting up BatchNorm6
I1007 22:14:29.144553  5299 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:14:29.144557  5299 net.cpp:137] Memory required for data: 197838000
I1007 22:14:29.144565  5299 layer_factory.hpp:77] Creating layer Scale6
I1007 22:14:29.144572  5299 net.cpp:84] Creating Layer Scale6
I1007 22:14:29.144577  5299 net.cpp:406] Scale6 <- Convolution6
I1007 22:14:29.144582  5299 net.cpp:367] Scale6 -> Convolution6 (in-place)
I1007 22:14:29.144623  5299 layer_factory.hpp:77] Creating layer Scale6
I1007 22:14:29.144737  5299 net.cpp:122] Setting up Scale6
I1007 22:14:29.144743  5299 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:14:29.144747  5299 net.cpp:137] Memory required for data: 204391600
I1007 22:14:29.144754  5299 layer_factory.hpp:77] Creating layer M2PELU6
I1007 22:14:29.144762  5299 net.cpp:84] Creating Layer M2PELU6
I1007 22:14:29.144767  5299 net.cpp:406] M2PELU6 <- Convolution6
I1007 22:14:29.144773  5299 net.cpp:367] M2PELU6 -> Convolution6 (in-place)
I1007 22:14:29.144914  5299 net.cpp:122] Setting up M2PELU6
I1007 22:14:29.144922  5299 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:14:29.144925  5299 net.cpp:137] Memory required for data: 210945200
I1007 22:14:29.144932  5299 layer_factory.hpp:77] Creating layer Convolution7
I1007 22:14:29.144943  5299 net.cpp:84] Creating Layer Convolution7
I1007 22:14:29.144948  5299 net.cpp:406] Convolution7 <- Convolution6
I1007 22:14:29.144954  5299 net.cpp:380] Convolution7 -> Convolution7
I1007 22:14:29.151379  5299 net.cpp:122] Setting up Convolution7
I1007 22:14:29.151391  5299 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:14:29.151393  5299 net.cpp:137] Memory required for data: 217498800
I1007 22:14:29.151399  5299 layer_factory.hpp:77] Creating layer BatchNorm7
I1007 22:14:29.151407  5299 net.cpp:84] Creating Layer BatchNorm7
I1007 22:14:29.151410  5299 net.cpp:406] BatchNorm7 <- Convolution7
I1007 22:14:29.151414  5299 net.cpp:367] BatchNorm7 -> Convolution7 (in-place)
I1007 22:14:29.151557  5299 net.cpp:122] Setting up BatchNorm7
I1007 22:14:29.151562  5299 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:14:29.151564  5299 net.cpp:137] Memory required for data: 224052400
I1007 22:14:29.151569  5299 layer_factory.hpp:77] Creating layer Scale7
I1007 22:14:29.151573  5299 net.cpp:84] Creating Layer Scale7
I1007 22:14:29.151576  5299 net.cpp:406] Scale7 <- Convolution7
I1007 22:14:29.151581  5299 net.cpp:367] Scale7 -> Convolution7 (in-place)
I1007 22:14:29.151608  5299 layer_factory.hpp:77] Creating layer Scale7
I1007 22:14:29.151686  5299 net.cpp:122] Setting up Scale7
I1007 22:14:29.151690  5299 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:14:29.151692  5299 net.cpp:137] Memory required for data: 230606000
I1007 22:14:29.151696  5299 layer_factory.hpp:77] Creating layer Eltwise3
I1007 22:14:29.151701  5299 net.cpp:84] Creating Layer Eltwise3
I1007 22:14:29.151705  5299 net.cpp:406] Eltwise3 <- Eltwise2_M2PELU5_0_split_1
I1007 22:14:29.151707  5299 net.cpp:406] Eltwise3 <- Convolution7
I1007 22:14:29.151710  5299 net.cpp:380] Eltwise3 -> Eltwise3
I1007 22:14:29.151726  5299 net.cpp:122] Setting up Eltwise3
I1007 22:14:29.151731  5299 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:14:29.151732  5299 net.cpp:137] Memory required for data: 237159600
I1007 22:14:29.151734  5299 layer_factory.hpp:77] Creating layer M2PELU7
I1007 22:14:29.151748  5299 net.cpp:84] Creating Layer M2PELU7
I1007 22:14:29.151751  5299 net.cpp:406] M2PELU7 <- Eltwise3
I1007 22:14:29.151754  5299 net.cpp:367] M2PELU7 -> Eltwise3 (in-place)
I1007 22:14:29.151856  5299 net.cpp:122] Setting up M2PELU7
I1007 22:14:29.151861  5299 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:14:29.151863  5299 net.cpp:137] Memory required for data: 243713200
I1007 22:14:29.151867  5299 layer_factory.hpp:77] Creating layer Eltwise3_M2PELU7_0_split
I1007 22:14:29.151871  5299 net.cpp:84] Creating Layer Eltwise3_M2PELU7_0_split
I1007 22:14:29.151873  5299 net.cpp:406] Eltwise3_M2PELU7_0_split <- Eltwise3
I1007 22:14:29.151876  5299 net.cpp:380] Eltwise3_M2PELU7_0_split -> Eltwise3_M2PELU7_0_split_0
I1007 22:14:29.151880  5299 net.cpp:380] Eltwise3_M2PELU7_0_split -> Eltwise3_M2PELU7_0_split_1
I1007 22:14:29.151906  5299 net.cpp:122] Setting up Eltwise3_M2PELU7_0_split
I1007 22:14:29.151909  5299 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:14:29.151912  5299 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:14:29.151914  5299 net.cpp:137] Memory required for data: 256820400
I1007 22:14:29.151916  5299 layer_factory.hpp:77] Creating layer Convolution8
I1007 22:14:29.151922  5299 net.cpp:84] Creating Layer Convolution8
I1007 22:14:29.151926  5299 net.cpp:406] Convolution8 <- Eltwise3_M2PELU7_0_split_0
I1007 22:14:29.151929  5299 net.cpp:380] Convolution8 -> Convolution8
I1007 22:14:29.157946  5299 net.cpp:122] Setting up Convolution8
I1007 22:14:29.157955  5299 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:14:29.157958  5299 net.cpp:137] Memory required for data: 263374000
I1007 22:14:29.157969  5299 layer_factory.hpp:77] Creating layer BatchNorm8
I1007 22:14:29.157974  5299 net.cpp:84] Creating Layer BatchNorm8
I1007 22:14:29.157977  5299 net.cpp:406] BatchNorm8 <- Convolution8
I1007 22:14:29.157980  5299 net.cpp:367] BatchNorm8 -> Convolution8 (in-place)
I1007 22:14:29.158123  5299 net.cpp:122] Setting up BatchNorm8
I1007 22:14:29.158126  5299 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:14:29.158128  5299 net.cpp:137] Memory required for data: 269927600
I1007 22:14:29.158133  5299 layer_factory.hpp:77] Creating layer Scale8
I1007 22:14:29.158138  5299 net.cpp:84] Creating Layer Scale8
I1007 22:14:29.158140  5299 net.cpp:406] Scale8 <- Convolution8
I1007 22:14:29.158143  5299 net.cpp:367] Scale8 -> Convolution8 (in-place)
I1007 22:14:29.158171  5299 layer_factory.hpp:77] Creating layer Scale8
I1007 22:14:29.158252  5299 net.cpp:122] Setting up Scale8
I1007 22:14:29.158257  5299 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:14:29.158258  5299 net.cpp:137] Memory required for data: 276481200
I1007 22:14:29.158262  5299 layer_factory.hpp:77] Creating layer M2PELU8
I1007 22:14:29.158267  5299 net.cpp:84] Creating Layer M2PELU8
I1007 22:14:29.158269  5299 net.cpp:406] M2PELU8 <- Convolution8
I1007 22:14:29.158273  5299 net.cpp:367] M2PELU8 -> Convolution8 (in-place)
I1007 22:14:29.158367  5299 net.cpp:122] Setting up M2PELU8
I1007 22:14:29.158372  5299 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:14:29.158375  5299 net.cpp:137] Memory required for data: 283034800
I1007 22:14:29.158377  5299 layer_factory.hpp:77] Creating layer Convolution9
I1007 22:14:29.158385  5299 net.cpp:84] Creating Layer Convolution9
I1007 22:14:29.158386  5299 net.cpp:406] Convolution9 <- Convolution8
I1007 22:14:29.158391  5299 net.cpp:380] Convolution9 -> Convolution9
I1007 22:14:29.164510  5299 net.cpp:122] Setting up Convolution9
I1007 22:14:29.164520  5299 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:14:29.164522  5299 net.cpp:137] Memory required for data: 289588400
I1007 22:14:29.164526  5299 layer_factory.hpp:77] Creating layer BatchNorm9
I1007 22:14:29.164531  5299 net.cpp:84] Creating Layer BatchNorm9
I1007 22:14:29.164535  5299 net.cpp:406] BatchNorm9 <- Convolution9
I1007 22:14:29.164538  5299 net.cpp:367] BatchNorm9 -> Convolution9 (in-place)
I1007 22:14:29.164679  5299 net.cpp:122] Setting up BatchNorm9
I1007 22:14:29.164683  5299 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:14:29.164691  5299 net.cpp:137] Memory required for data: 296142000
I1007 22:14:29.164697  5299 layer_factory.hpp:77] Creating layer Scale9
I1007 22:14:29.164702  5299 net.cpp:84] Creating Layer Scale9
I1007 22:14:29.164705  5299 net.cpp:406] Scale9 <- Convolution9
I1007 22:14:29.164707  5299 net.cpp:367] Scale9 -> Convolution9 (in-place)
I1007 22:14:29.164736  5299 layer_factory.hpp:77] Creating layer Scale9
I1007 22:14:29.164816  5299 net.cpp:122] Setting up Scale9
I1007 22:14:29.164820  5299 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:14:29.164822  5299 net.cpp:137] Memory required for data: 302695600
I1007 22:14:29.164826  5299 layer_factory.hpp:77] Creating layer Eltwise4
I1007 22:14:29.164830  5299 net.cpp:84] Creating Layer Eltwise4
I1007 22:14:29.164832  5299 net.cpp:406] Eltwise4 <- Eltwise3_M2PELU7_0_split_1
I1007 22:14:29.164835  5299 net.cpp:406] Eltwise4 <- Convolution9
I1007 22:14:29.164839  5299 net.cpp:380] Eltwise4 -> Eltwise4
I1007 22:14:29.164855  5299 net.cpp:122] Setting up Eltwise4
I1007 22:14:29.164860  5299 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:14:29.164861  5299 net.cpp:137] Memory required for data: 309249200
I1007 22:14:29.164863  5299 layer_factory.hpp:77] Creating layer M2PELU9
I1007 22:14:29.164868  5299 net.cpp:84] Creating Layer M2PELU9
I1007 22:14:29.164870  5299 net.cpp:406] M2PELU9 <- Eltwise4
I1007 22:14:29.164875  5299 net.cpp:367] M2PELU9 -> Eltwise4 (in-place)
I1007 22:14:29.164968  5299 net.cpp:122] Setting up M2PELU9
I1007 22:14:29.164973  5299 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:14:29.164975  5299 net.cpp:137] Memory required for data: 315802800
I1007 22:14:29.164979  5299 layer_factory.hpp:77] Creating layer Eltwise4_M2PELU9_0_split
I1007 22:14:29.164983  5299 net.cpp:84] Creating Layer Eltwise4_M2PELU9_0_split
I1007 22:14:29.164985  5299 net.cpp:406] Eltwise4_M2PELU9_0_split <- Eltwise4
I1007 22:14:29.164989  5299 net.cpp:380] Eltwise4_M2PELU9_0_split -> Eltwise4_M2PELU9_0_split_0
I1007 22:14:29.164994  5299 net.cpp:380] Eltwise4_M2PELU9_0_split -> Eltwise4_M2PELU9_0_split_1
I1007 22:14:29.165017  5299 net.cpp:122] Setting up Eltwise4_M2PELU9_0_split
I1007 22:14:29.165021  5299 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:14:29.165024  5299 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:14:29.165026  5299 net.cpp:137] Memory required for data: 328910000
I1007 22:14:29.165029  5299 layer_factory.hpp:77] Creating layer Convolution10
I1007 22:14:29.165035  5299 net.cpp:84] Creating Layer Convolution10
I1007 22:14:29.165036  5299 net.cpp:406] Convolution10 <- Eltwise4_M2PELU9_0_split_0
I1007 22:14:29.165040  5299 net.cpp:380] Convolution10 -> Convolution10
I1007 22:14:29.171103  5299 net.cpp:122] Setting up Convolution10
I1007 22:14:29.171111  5299 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:14:29.171114  5299 net.cpp:137] Memory required for data: 335463600
I1007 22:14:29.171118  5299 layer_factory.hpp:77] Creating layer BatchNorm10
I1007 22:14:29.171123  5299 net.cpp:84] Creating Layer BatchNorm10
I1007 22:14:29.171125  5299 net.cpp:406] BatchNorm10 <- Convolution10
I1007 22:14:29.171129  5299 net.cpp:367] BatchNorm10 -> Convolution10 (in-place)
I1007 22:14:29.171281  5299 net.cpp:122] Setting up BatchNorm10
I1007 22:14:29.171286  5299 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:14:29.171289  5299 net.cpp:137] Memory required for data: 342017200
I1007 22:14:29.171293  5299 layer_factory.hpp:77] Creating layer Scale10
I1007 22:14:29.171298  5299 net.cpp:84] Creating Layer Scale10
I1007 22:14:29.171300  5299 net.cpp:406] Scale10 <- Convolution10
I1007 22:14:29.171303  5299 net.cpp:367] Scale10 -> Convolution10 (in-place)
I1007 22:14:29.171332  5299 layer_factory.hpp:77] Creating layer Scale10
I1007 22:14:29.171411  5299 net.cpp:122] Setting up Scale10
I1007 22:14:29.171416  5299 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:14:29.171417  5299 net.cpp:137] Memory required for data: 348570800
I1007 22:14:29.171420  5299 layer_factory.hpp:77] Creating layer M2PELU10
I1007 22:14:29.171432  5299 net.cpp:84] Creating Layer M2PELU10
I1007 22:14:29.171435  5299 net.cpp:406] M2PELU10 <- Convolution10
I1007 22:14:29.171438  5299 net.cpp:367] M2PELU10 -> Convolution10 (in-place)
I1007 22:14:29.171533  5299 net.cpp:122] Setting up M2PELU10
I1007 22:14:29.171538  5299 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:14:29.171540  5299 net.cpp:137] Memory required for data: 355124400
I1007 22:14:29.171543  5299 layer_factory.hpp:77] Creating layer Convolution11
I1007 22:14:29.171550  5299 net.cpp:84] Creating Layer Convolution11
I1007 22:14:29.171552  5299 net.cpp:406] Convolution11 <- Convolution10
I1007 22:14:29.171557  5299 net.cpp:380] Convolution11 -> Convolution11
I1007 22:14:29.177659  5299 net.cpp:122] Setting up Convolution11
I1007 22:14:29.177670  5299 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:14:29.177672  5299 net.cpp:137] Memory required for data: 361678000
I1007 22:14:29.177676  5299 layer_factory.hpp:77] Creating layer BatchNorm11
I1007 22:14:29.177682  5299 net.cpp:84] Creating Layer BatchNorm11
I1007 22:14:29.177685  5299 net.cpp:406] BatchNorm11 <- Convolution11
I1007 22:14:29.177690  5299 net.cpp:367] BatchNorm11 -> Convolution11 (in-place)
I1007 22:14:29.177839  5299 net.cpp:122] Setting up BatchNorm11
I1007 22:14:29.177844  5299 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:14:29.177845  5299 net.cpp:137] Memory required for data: 368231600
I1007 22:14:29.177850  5299 layer_factory.hpp:77] Creating layer Scale11
I1007 22:14:29.177855  5299 net.cpp:84] Creating Layer Scale11
I1007 22:14:29.177857  5299 net.cpp:406] Scale11 <- Convolution11
I1007 22:14:29.177860  5299 net.cpp:367] Scale11 -> Convolution11 (in-place)
I1007 22:14:29.177889  5299 layer_factory.hpp:77] Creating layer Scale11
I1007 22:14:29.177973  5299 net.cpp:122] Setting up Scale11
I1007 22:14:29.177978  5299 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:14:29.177979  5299 net.cpp:137] Memory required for data: 374785200
I1007 22:14:29.177983  5299 layer_factory.hpp:77] Creating layer Eltwise5
I1007 22:14:29.177989  5299 net.cpp:84] Creating Layer Eltwise5
I1007 22:14:29.177990  5299 net.cpp:406] Eltwise5 <- Eltwise4_M2PELU9_0_split_1
I1007 22:14:29.177994  5299 net.cpp:406] Eltwise5 <- Convolution11
I1007 22:14:29.177997  5299 net.cpp:380] Eltwise5 -> Eltwise5
I1007 22:14:29.178014  5299 net.cpp:122] Setting up Eltwise5
I1007 22:14:29.178019  5299 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:14:29.178020  5299 net.cpp:137] Memory required for data: 381338800
I1007 22:14:29.178023  5299 layer_factory.hpp:77] Creating layer M2PELU11
I1007 22:14:29.178028  5299 net.cpp:84] Creating Layer M2PELU11
I1007 22:14:29.178030  5299 net.cpp:406] M2PELU11 <- Eltwise5
I1007 22:14:29.178033  5299 net.cpp:367] M2PELU11 -> Eltwise5 (in-place)
I1007 22:14:29.178133  5299 net.cpp:122] Setting up M2PELU11
I1007 22:14:29.178138  5299 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:14:29.178140  5299 net.cpp:137] Memory required for data: 387892400
I1007 22:14:29.178143  5299 layer_factory.hpp:77] Creating layer Eltwise5_M2PELU11_0_split
I1007 22:14:29.178148  5299 net.cpp:84] Creating Layer Eltwise5_M2PELU11_0_split
I1007 22:14:29.178150  5299 net.cpp:406] Eltwise5_M2PELU11_0_split <- Eltwise5
I1007 22:14:29.178153  5299 net.cpp:380] Eltwise5_M2PELU11_0_split -> Eltwise5_M2PELU11_0_split_0
I1007 22:14:29.178158  5299 net.cpp:380] Eltwise5_M2PELU11_0_split -> Eltwise5_M2PELU11_0_split_1
I1007 22:14:29.178184  5299 net.cpp:122] Setting up Eltwise5_M2PELU11_0_split
I1007 22:14:29.178187  5299 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:14:29.178190  5299 net.cpp:129] Top shape: 100 16 32 32 (1638400)
I1007 22:14:29.178192  5299 net.cpp:137] Memory required for data: 400999600
I1007 22:14:29.178194  5299 layer_factory.hpp:77] Creating layer Convolution12
I1007 22:14:29.178200  5299 net.cpp:84] Creating Layer Convolution12
I1007 22:14:29.178203  5299 net.cpp:406] Convolution12 <- Eltwise5_M2PELU11_0_split_0
I1007 22:14:29.178210  5299 net.cpp:380] Convolution12 -> Convolution12
I1007 22:14:29.184677  5299 net.cpp:122] Setting up Convolution12
I1007 22:14:29.184687  5299 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:14:29.184689  5299 net.cpp:137] Memory required for data: 404276400
I1007 22:14:29.184695  5299 layer_factory.hpp:77] Creating layer BatchNorm12
I1007 22:14:29.184700  5299 net.cpp:84] Creating Layer BatchNorm12
I1007 22:14:29.184702  5299 net.cpp:406] BatchNorm12 <- Convolution12
I1007 22:14:29.184705  5299 net.cpp:367] BatchNorm12 -> Convolution12 (in-place)
I1007 22:14:29.184849  5299 net.cpp:122] Setting up BatchNorm12
I1007 22:14:29.184852  5299 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:14:29.184855  5299 net.cpp:137] Memory required for data: 407553200
I1007 22:14:29.184859  5299 layer_factory.hpp:77] Creating layer Scale12
I1007 22:14:29.184864  5299 net.cpp:84] Creating Layer Scale12
I1007 22:14:29.184866  5299 net.cpp:406] Scale12 <- Convolution12
I1007 22:14:29.184870  5299 net.cpp:367] Scale12 -> Convolution12 (in-place)
I1007 22:14:29.184900  5299 layer_factory.hpp:77] Creating layer Scale12
I1007 22:14:29.184981  5299 net.cpp:122] Setting up Scale12
I1007 22:14:29.184988  5299 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:14:29.184989  5299 net.cpp:137] Memory required for data: 410830000
I1007 22:14:29.184993  5299 layer_factory.hpp:77] Creating layer Convolution13
I1007 22:14:29.184999  5299 net.cpp:84] Creating Layer Convolution13
I1007 22:14:29.185003  5299 net.cpp:406] Convolution13 <- Eltwise5_M2PELU11_0_split_1
I1007 22:14:29.185006  5299 net.cpp:380] Convolution13 -> Convolution13
I1007 22:14:29.191296  5299 net.cpp:122] Setting up Convolution13
I1007 22:14:29.191305  5299 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:14:29.191308  5299 net.cpp:137] Memory required for data: 414106800
I1007 22:14:29.191313  5299 layer_factory.hpp:77] Creating layer BatchNorm13
I1007 22:14:29.191319  5299 net.cpp:84] Creating Layer BatchNorm13
I1007 22:14:29.191321  5299 net.cpp:406] BatchNorm13 <- Convolution13
I1007 22:14:29.191325  5299 net.cpp:367] BatchNorm13 -> Convolution13 (in-place)
I1007 22:14:29.191468  5299 net.cpp:122] Setting up BatchNorm13
I1007 22:14:29.191473  5299 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:14:29.191474  5299 net.cpp:137] Memory required for data: 417383600
I1007 22:14:29.191479  5299 layer_factory.hpp:77] Creating layer Scale13
I1007 22:14:29.191484  5299 net.cpp:84] Creating Layer Scale13
I1007 22:14:29.191486  5299 net.cpp:406] Scale13 <- Convolution13
I1007 22:14:29.191489  5299 net.cpp:367] Scale13 -> Convolution13 (in-place)
I1007 22:14:29.191519  5299 layer_factory.hpp:77] Creating layer Scale13
I1007 22:14:29.191602  5299 net.cpp:122] Setting up Scale13
I1007 22:14:29.191606  5299 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:14:29.191608  5299 net.cpp:137] Memory required for data: 420660400
I1007 22:14:29.191612  5299 layer_factory.hpp:77] Creating layer M2PELU12
I1007 22:14:29.191618  5299 net.cpp:84] Creating Layer M2PELU12
I1007 22:14:29.191620  5299 net.cpp:406] M2PELU12 <- Convolution13
I1007 22:14:29.191624  5299 net.cpp:367] M2PELU12 -> Convolution13 (in-place)
I1007 22:14:29.191715  5299 net.cpp:122] Setting up M2PELU12
I1007 22:14:29.191720  5299 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:14:29.191721  5299 net.cpp:137] Memory required for data: 423937200
I1007 22:14:29.191725  5299 layer_factory.hpp:77] Creating layer Convolution14
I1007 22:14:29.191735  5299 net.cpp:84] Creating Layer Convolution14
I1007 22:14:29.191738  5299 net.cpp:406] Convolution14 <- Convolution13
I1007 22:14:29.191742  5299 net.cpp:380] Convolution14 -> Convolution14
I1007 22:14:29.196434  5299 net.cpp:122] Setting up Convolution14
I1007 22:14:29.196442  5299 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:14:29.196444  5299 net.cpp:137] Memory required for data: 427214000
I1007 22:14:29.196449  5299 layer_factory.hpp:77] Creating layer BatchNorm14
I1007 22:14:29.196455  5299 net.cpp:84] Creating Layer BatchNorm14
I1007 22:14:29.196465  5299 net.cpp:406] BatchNorm14 <- Convolution14
I1007 22:14:29.196470  5299 net.cpp:367] BatchNorm14 -> Convolution14 (in-place)
I1007 22:14:29.196612  5299 net.cpp:122] Setting up BatchNorm14
I1007 22:14:29.196617  5299 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:14:29.196619  5299 net.cpp:137] Memory required for data: 430490800
I1007 22:14:29.196624  5299 layer_factory.hpp:77] Creating layer Scale14
I1007 22:14:29.196629  5299 net.cpp:84] Creating Layer Scale14
I1007 22:14:29.196631  5299 net.cpp:406] Scale14 <- Convolution14
I1007 22:14:29.196635  5299 net.cpp:367] Scale14 -> Convolution14 (in-place)
I1007 22:14:29.196662  5299 layer_factory.hpp:77] Creating layer Scale14
I1007 22:14:29.196743  5299 net.cpp:122] Setting up Scale14
I1007 22:14:29.196748  5299 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:14:29.196749  5299 net.cpp:137] Memory required for data: 433767600
I1007 22:14:29.196753  5299 layer_factory.hpp:77] Creating layer Eltwise6
I1007 22:14:29.196758  5299 net.cpp:84] Creating Layer Eltwise6
I1007 22:14:29.196760  5299 net.cpp:406] Eltwise6 <- Convolution12
I1007 22:14:29.196763  5299 net.cpp:406] Eltwise6 <- Convolution14
I1007 22:14:29.196766  5299 net.cpp:380] Eltwise6 -> Eltwise6
I1007 22:14:29.196779  5299 net.cpp:122] Setting up Eltwise6
I1007 22:14:29.196784  5299 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:14:29.196785  5299 net.cpp:137] Memory required for data: 437044400
I1007 22:14:29.196787  5299 layer_factory.hpp:77] Creating layer M2PELU13
I1007 22:14:29.196794  5299 net.cpp:84] Creating Layer M2PELU13
I1007 22:14:29.196795  5299 net.cpp:406] M2PELU13 <- Eltwise6
I1007 22:14:29.196799  5299 net.cpp:367] M2PELU13 -> Eltwise6 (in-place)
I1007 22:14:29.196895  5299 net.cpp:122] Setting up M2PELU13
I1007 22:14:29.196902  5299 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:14:29.196903  5299 net.cpp:137] Memory required for data: 440321200
I1007 22:14:29.196907  5299 layer_factory.hpp:77] Creating layer Eltwise6_M2PELU13_0_split
I1007 22:14:29.196912  5299 net.cpp:84] Creating Layer Eltwise6_M2PELU13_0_split
I1007 22:14:29.196913  5299 net.cpp:406] Eltwise6_M2PELU13_0_split <- Eltwise6
I1007 22:14:29.196916  5299 net.cpp:380] Eltwise6_M2PELU13_0_split -> Eltwise6_M2PELU13_0_split_0
I1007 22:14:29.196920  5299 net.cpp:380] Eltwise6_M2PELU13_0_split -> Eltwise6_M2PELU13_0_split_1
I1007 22:14:29.196946  5299 net.cpp:122] Setting up Eltwise6_M2PELU13_0_split
I1007 22:14:29.196950  5299 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:14:29.196954  5299 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:14:29.196955  5299 net.cpp:137] Memory required for data: 446874800
I1007 22:14:29.196957  5299 layer_factory.hpp:77] Creating layer Convolution15
I1007 22:14:29.196964  5299 net.cpp:84] Creating Layer Convolution15
I1007 22:14:29.196966  5299 net.cpp:406] Convolution15 <- Eltwise6_M2PELU13_0_split_0
I1007 22:14:29.196970  5299 net.cpp:380] Convolution15 -> Convolution15
I1007 22:14:29.200464  5299 net.cpp:122] Setting up Convolution15
I1007 22:14:29.200474  5299 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:14:29.200476  5299 net.cpp:137] Memory required for data: 450151600
I1007 22:14:29.200481  5299 layer_factory.hpp:77] Creating layer BatchNorm15
I1007 22:14:29.200486  5299 net.cpp:84] Creating Layer BatchNorm15
I1007 22:14:29.200489  5299 net.cpp:406] BatchNorm15 <- Convolution15
I1007 22:14:29.200492  5299 net.cpp:367] BatchNorm15 -> Convolution15 (in-place)
I1007 22:14:29.200639  5299 net.cpp:122] Setting up BatchNorm15
I1007 22:14:29.200644  5299 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:14:29.200646  5299 net.cpp:137] Memory required for data: 453428400
I1007 22:14:29.200661  5299 layer_factory.hpp:77] Creating layer Scale15
I1007 22:14:29.200667  5299 net.cpp:84] Creating Layer Scale15
I1007 22:14:29.200670  5299 net.cpp:406] Scale15 <- Convolution15
I1007 22:14:29.200672  5299 net.cpp:367] Scale15 -> Convolution15 (in-place)
I1007 22:14:29.200704  5299 layer_factory.hpp:77] Creating layer Scale15
I1007 22:14:29.200788  5299 net.cpp:122] Setting up Scale15
I1007 22:14:29.200799  5299 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:14:29.200803  5299 net.cpp:137] Memory required for data: 456705200
I1007 22:14:29.200806  5299 layer_factory.hpp:77] Creating layer M2PELU14
I1007 22:14:29.200811  5299 net.cpp:84] Creating Layer M2PELU14
I1007 22:14:29.200814  5299 net.cpp:406] M2PELU14 <- Convolution15
I1007 22:14:29.200819  5299 net.cpp:367] M2PELU14 -> Convolution15 (in-place)
I1007 22:14:29.200911  5299 net.cpp:122] Setting up M2PELU14
I1007 22:14:29.200914  5299 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:14:29.200917  5299 net.cpp:137] Memory required for data: 459982000
I1007 22:14:29.200920  5299 layer_factory.hpp:77] Creating layer Convolution16
I1007 22:14:29.200928  5299 net.cpp:84] Creating Layer Convolution16
I1007 22:14:29.200930  5299 net.cpp:406] Convolution16 <- Convolution15
I1007 22:14:29.200934  5299 net.cpp:380] Convolution16 -> Convolution16
I1007 22:14:29.206778  5299 net.cpp:122] Setting up Convolution16
I1007 22:14:29.206790  5299 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:14:29.206795  5299 net.cpp:137] Memory required for data: 463258800
I1007 22:14:29.206804  5299 layer_factory.hpp:77] Creating layer BatchNorm16
I1007 22:14:29.206811  5299 net.cpp:84] Creating Layer BatchNorm16
I1007 22:14:29.206815  5299 net.cpp:406] BatchNorm16 <- Convolution16
I1007 22:14:29.206823  5299 net.cpp:367] BatchNorm16 -> Convolution16 (in-place)
I1007 22:14:29.207041  5299 net.cpp:122] Setting up BatchNorm16
I1007 22:14:29.207051  5299 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:14:29.207056  5299 net.cpp:137] Memory required for data: 466535600
I1007 22:14:29.207063  5299 layer_factory.hpp:77] Creating layer Scale16
I1007 22:14:29.207072  5299 net.cpp:84] Creating Layer Scale16
I1007 22:14:29.207075  5299 net.cpp:406] Scale16 <- Convolution16
I1007 22:14:29.207082  5299 net.cpp:367] Scale16 -> Convolution16 (in-place)
I1007 22:14:29.207125  5299 layer_factory.hpp:77] Creating layer Scale16
I1007 22:14:29.207244  5299 net.cpp:122] Setting up Scale16
I1007 22:14:29.207253  5299 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:14:29.207257  5299 net.cpp:137] Memory required for data: 469812400
I1007 22:14:29.207264  5299 layer_factory.hpp:77] Creating layer Eltwise7
I1007 22:14:29.207270  5299 net.cpp:84] Creating Layer Eltwise7
I1007 22:14:29.207278  5299 net.cpp:406] Eltwise7 <- Eltwise6_M2PELU13_0_split_1
I1007 22:14:29.207283  5299 net.cpp:406] Eltwise7 <- Convolution16
I1007 22:14:29.207288  5299 net.cpp:380] Eltwise7 -> Eltwise7
I1007 22:14:29.207311  5299 net.cpp:122] Setting up Eltwise7
I1007 22:14:29.207319  5299 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:14:29.207322  5299 net.cpp:137] Memory required for data: 473089200
I1007 22:14:29.207325  5299 layer_factory.hpp:77] Creating layer M2PELU15
I1007 22:14:29.207334  5299 net.cpp:84] Creating Layer M2PELU15
I1007 22:14:29.207339  5299 net.cpp:406] M2PELU15 <- Eltwise7
I1007 22:14:29.207345  5299 net.cpp:367] M2PELU15 -> Eltwise7 (in-place)
I1007 22:14:29.207489  5299 net.cpp:122] Setting up M2PELU15
I1007 22:14:29.207499  5299 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:14:29.207501  5299 net.cpp:137] Memory required for data: 476366000
I1007 22:14:29.207509  5299 layer_factory.hpp:77] Creating layer Eltwise7_M2PELU15_0_split
I1007 22:14:29.207515  5299 net.cpp:84] Creating Layer Eltwise7_M2PELU15_0_split
I1007 22:14:29.207518  5299 net.cpp:406] Eltwise7_M2PELU15_0_split <- Eltwise7
I1007 22:14:29.207525  5299 net.cpp:380] Eltwise7_M2PELU15_0_split -> Eltwise7_M2PELU15_0_split_0
I1007 22:14:29.207532  5299 net.cpp:380] Eltwise7_M2PELU15_0_split -> Eltwise7_M2PELU15_0_split_1
I1007 22:14:29.207572  5299 net.cpp:122] Setting up Eltwise7_M2PELU15_0_split
I1007 22:14:29.207581  5299 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:14:29.207586  5299 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:14:29.207589  5299 net.cpp:137] Memory required for data: 482919600
I1007 22:14:29.207593  5299 layer_factory.hpp:77] Creating layer Convolution17
I1007 22:14:29.207613  5299 net.cpp:84] Creating Layer Convolution17
I1007 22:14:29.207618  5299 net.cpp:406] Convolution17 <- Eltwise7_M2PELU15_0_split_0
I1007 22:14:29.207625  5299 net.cpp:380] Convolution17 -> Convolution17
I1007 22:14:29.214148  5299 net.cpp:122] Setting up Convolution17
I1007 22:14:29.214156  5299 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:14:29.214159  5299 net.cpp:137] Memory required for data: 486196400
I1007 22:14:29.214164  5299 layer_factory.hpp:77] Creating layer BatchNorm17
I1007 22:14:29.214169  5299 net.cpp:84] Creating Layer BatchNorm17
I1007 22:14:29.214171  5299 net.cpp:406] BatchNorm17 <- Convolution17
I1007 22:14:29.214175  5299 net.cpp:367] BatchNorm17 -> Convolution17 (in-place)
I1007 22:14:29.214316  5299 net.cpp:122] Setting up BatchNorm17
I1007 22:14:29.214320  5299 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:14:29.214323  5299 net.cpp:137] Memory required for data: 489473200
I1007 22:14:29.214328  5299 layer_factory.hpp:77] Creating layer Scale17
I1007 22:14:29.214331  5299 net.cpp:84] Creating Layer Scale17
I1007 22:14:29.214334  5299 net.cpp:406] Scale17 <- Convolution17
I1007 22:14:29.214337  5299 net.cpp:367] Scale17 -> Convolution17 (in-place)
I1007 22:14:29.214367  5299 layer_factory.hpp:77] Creating layer Scale17
I1007 22:14:29.214447  5299 net.cpp:122] Setting up Scale17
I1007 22:14:29.214452  5299 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:14:29.214453  5299 net.cpp:137] Memory required for data: 492750000
I1007 22:14:29.214457  5299 layer_factory.hpp:77] Creating layer M2PELU16
I1007 22:14:29.214462  5299 net.cpp:84] Creating Layer M2PELU16
I1007 22:14:29.214465  5299 net.cpp:406] M2PELU16 <- Convolution17
I1007 22:14:29.214468  5299 net.cpp:367] M2PELU16 -> Convolution17 (in-place)
I1007 22:14:29.214555  5299 net.cpp:122] Setting up M2PELU16
I1007 22:14:29.214560  5299 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:14:29.214561  5299 net.cpp:137] Memory required for data: 496026800
I1007 22:14:29.214565  5299 layer_factory.hpp:77] Creating layer Convolution18
I1007 22:14:29.214572  5299 net.cpp:84] Creating Layer Convolution18
I1007 22:14:29.214574  5299 net.cpp:406] Convolution18 <- Convolution17
I1007 22:14:29.214578  5299 net.cpp:380] Convolution18 -> Convolution18
I1007 22:14:29.218004  5299 net.cpp:122] Setting up Convolution18
I1007 22:14:29.218014  5299 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:14:29.218015  5299 net.cpp:137] Memory required for data: 499303600
I1007 22:14:29.218020  5299 layer_factory.hpp:77] Creating layer BatchNorm18
I1007 22:14:29.218025  5299 net.cpp:84] Creating Layer BatchNorm18
I1007 22:14:29.218029  5299 net.cpp:406] BatchNorm18 <- Convolution18
I1007 22:14:29.218031  5299 net.cpp:367] BatchNorm18 -> Convolution18 (in-place)
I1007 22:14:29.218173  5299 net.cpp:122] Setting up BatchNorm18
I1007 22:14:29.218178  5299 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:14:29.218180  5299 net.cpp:137] Memory required for data: 502580400
I1007 22:14:29.218185  5299 layer_factory.hpp:77] Creating layer Scale18
I1007 22:14:29.218189  5299 net.cpp:84] Creating Layer Scale18
I1007 22:14:29.218191  5299 net.cpp:406] Scale18 <- Convolution18
I1007 22:14:29.218194  5299 net.cpp:367] Scale18 -> Convolution18 (in-place)
I1007 22:14:29.218224  5299 layer_factory.hpp:77] Creating layer Scale18
I1007 22:14:29.218304  5299 net.cpp:122] Setting up Scale18
I1007 22:14:29.218308  5299 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:14:29.218310  5299 net.cpp:137] Memory required for data: 505857200
I1007 22:14:29.218314  5299 layer_factory.hpp:77] Creating layer Eltwise8
I1007 22:14:29.218320  5299 net.cpp:84] Creating Layer Eltwise8
I1007 22:14:29.218322  5299 net.cpp:406] Eltwise8 <- Eltwise7_M2PELU15_0_split_1
I1007 22:14:29.218325  5299 net.cpp:406] Eltwise8 <- Convolution18
I1007 22:14:29.218329  5299 net.cpp:380] Eltwise8 -> Eltwise8
I1007 22:14:29.218343  5299 net.cpp:122] Setting up Eltwise8
I1007 22:14:29.218348  5299 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:14:29.218358  5299 net.cpp:137] Memory required for data: 509134000
I1007 22:14:29.218359  5299 layer_factory.hpp:77] Creating layer M2PELU17
I1007 22:14:29.218365  5299 net.cpp:84] Creating Layer M2PELU17
I1007 22:14:29.218367  5299 net.cpp:406] M2PELU17 <- Eltwise8
I1007 22:14:29.218370  5299 net.cpp:367] M2PELU17 -> Eltwise8 (in-place)
I1007 22:14:29.218466  5299 net.cpp:122] Setting up M2PELU17
I1007 22:14:29.218469  5299 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:14:29.218472  5299 net.cpp:137] Memory required for data: 512410800
I1007 22:14:29.218475  5299 layer_factory.hpp:77] Creating layer Eltwise8_M2PELU17_0_split
I1007 22:14:29.218479  5299 net.cpp:84] Creating Layer Eltwise8_M2PELU17_0_split
I1007 22:14:29.218482  5299 net.cpp:406] Eltwise8_M2PELU17_0_split <- Eltwise8
I1007 22:14:29.218485  5299 net.cpp:380] Eltwise8_M2PELU17_0_split -> Eltwise8_M2PELU17_0_split_0
I1007 22:14:29.218490  5299 net.cpp:380] Eltwise8_M2PELU17_0_split -> Eltwise8_M2PELU17_0_split_1
I1007 22:14:29.218515  5299 net.cpp:122] Setting up Eltwise8_M2PELU17_0_split
I1007 22:14:29.218519  5299 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:14:29.218523  5299 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:14:29.218524  5299 net.cpp:137] Memory required for data: 518964400
I1007 22:14:29.218526  5299 layer_factory.hpp:77] Creating layer Convolution19
I1007 22:14:29.218531  5299 net.cpp:84] Creating Layer Convolution19
I1007 22:14:29.218534  5299 net.cpp:406] Convolution19 <- Eltwise8_M2PELU17_0_split_0
I1007 22:14:29.218538  5299 net.cpp:380] Convolution19 -> Convolution19
I1007 22:14:29.224326  5299 net.cpp:122] Setting up Convolution19
I1007 22:14:29.224335  5299 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:14:29.224339  5299 net.cpp:137] Memory required for data: 522241200
I1007 22:14:29.224342  5299 layer_factory.hpp:77] Creating layer BatchNorm19
I1007 22:14:29.224347  5299 net.cpp:84] Creating Layer BatchNorm19
I1007 22:14:29.224349  5299 net.cpp:406] BatchNorm19 <- Convolution19
I1007 22:14:29.224354  5299 net.cpp:367] BatchNorm19 -> Convolution19 (in-place)
I1007 22:14:29.224498  5299 net.cpp:122] Setting up BatchNorm19
I1007 22:14:29.224503  5299 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:14:29.224504  5299 net.cpp:137] Memory required for data: 525518000
I1007 22:14:29.224509  5299 layer_factory.hpp:77] Creating layer Scale19
I1007 22:14:29.224514  5299 net.cpp:84] Creating Layer Scale19
I1007 22:14:29.224515  5299 net.cpp:406] Scale19 <- Convolution19
I1007 22:14:29.224519  5299 net.cpp:367] Scale19 -> Convolution19 (in-place)
I1007 22:14:29.224547  5299 layer_factory.hpp:77] Creating layer Scale19
I1007 22:14:29.224628  5299 net.cpp:122] Setting up Scale19
I1007 22:14:29.224632  5299 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:14:29.224634  5299 net.cpp:137] Memory required for data: 528794800
I1007 22:14:29.224638  5299 layer_factory.hpp:77] Creating layer M2PELU18
I1007 22:14:29.224643  5299 net.cpp:84] Creating Layer M2PELU18
I1007 22:14:29.224647  5299 net.cpp:406] M2PELU18 <- Convolution19
I1007 22:14:29.224649  5299 net.cpp:367] M2PELU18 -> Convolution19 (in-place)
I1007 22:14:29.224737  5299 net.cpp:122] Setting up M2PELU18
I1007 22:14:29.224741  5299 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:14:29.224743  5299 net.cpp:137] Memory required for data: 532071600
I1007 22:14:29.224747  5299 layer_factory.hpp:77] Creating layer Convolution20
I1007 22:14:29.224753  5299 net.cpp:84] Creating Layer Convolution20
I1007 22:14:29.224756  5299 net.cpp:406] Convolution20 <- Convolution19
I1007 22:14:29.224761  5299 net.cpp:380] Convolution20 -> Convolution20
I1007 22:14:29.230885  5299 net.cpp:122] Setting up Convolution20
I1007 22:14:29.230893  5299 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:14:29.230896  5299 net.cpp:137] Memory required for data: 535348400
I1007 22:14:29.230901  5299 layer_factory.hpp:77] Creating layer BatchNorm20
I1007 22:14:29.230906  5299 net.cpp:84] Creating Layer BatchNorm20
I1007 22:14:29.230916  5299 net.cpp:406] BatchNorm20 <- Convolution20
I1007 22:14:29.230921  5299 net.cpp:367] BatchNorm20 -> Convolution20 (in-place)
I1007 22:14:29.231070  5299 net.cpp:122] Setting up BatchNorm20
I1007 22:14:29.231075  5299 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:14:29.231076  5299 net.cpp:137] Memory required for data: 538625200
I1007 22:14:29.231081  5299 layer_factory.hpp:77] Creating layer Scale20
I1007 22:14:29.231086  5299 net.cpp:84] Creating Layer Scale20
I1007 22:14:29.231088  5299 net.cpp:406] Scale20 <- Convolution20
I1007 22:14:29.231092  5299 net.cpp:367] Scale20 -> Convolution20 (in-place)
I1007 22:14:29.231122  5299 layer_factory.hpp:77] Creating layer Scale20
I1007 22:14:29.231236  5299 net.cpp:122] Setting up Scale20
I1007 22:14:29.231242  5299 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:14:29.231245  5299 net.cpp:137] Memory required for data: 541902000
I1007 22:14:29.231248  5299 layer_factory.hpp:77] Creating layer Eltwise9
I1007 22:14:29.231252  5299 net.cpp:84] Creating Layer Eltwise9
I1007 22:14:29.231256  5299 net.cpp:406] Eltwise9 <- Eltwise8_M2PELU17_0_split_1
I1007 22:14:29.231258  5299 net.cpp:406] Eltwise9 <- Convolution20
I1007 22:14:29.231262  5299 net.cpp:380] Eltwise9 -> Eltwise9
I1007 22:14:29.231276  5299 net.cpp:122] Setting up Eltwise9
I1007 22:14:29.231279  5299 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:14:29.231281  5299 net.cpp:137] Memory required for data: 545178800
I1007 22:14:29.231283  5299 layer_factory.hpp:77] Creating layer M2PELU19
I1007 22:14:29.231289  5299 net.cpp:84] Creating Layer M2PELU19
I1007 22:14:29.231292  5299 net.cpp:406] M2PELU19 <- Eltwise9
I1007 22:14:29.231294  5299 net.cpp:367] M2PELU19 -> Eltwise9 (in-place)
I1007 22:14:29.231390  5299 net.cpp:122] Setting up M2PELU19
I1007 22:14:29.231395  5299 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:14:29.231397  5299 net.cpp:137] Memory required for data: 548455600
I1007 22:14:29.231400  5299 layer_factory.hpp:77] Creating layer Eltwise9_M2PELU19_0_split
I1007 22:14:29.231405  5299 net.cpp:84] Creating Layer Eltwise9_M2PELU19_0_split
I1007 22:14:29.231407  5299 net.cpp:406] Eltwise9_M2PELU19_0_split <- Eltwise9
I1007 22:14:29.231410  5299 net.cpp:380] Eltwise9_M2PELU19_0_split -> Eltwise9_M2PELU19_0_split_0
I1007 22:14:29.231415  5299 net.cpp:380] Eltwise9_M2PELU19_0_split -> Eltwise9_M2PELU19_0_split_1
I1007 22:14:29.231442  5299 net.cpp:122] Setting up Eltwise9_M2PELU19_0_split
I1007 22:14:29.231446  5299 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:14:29.231449  5299 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:14:29.231451  5299 net.cpp:137] Memory required for data: 555009200
I1007 22:14:29.231453  5299 layer_factory.hpp:77] Creating layer Convolution21
I1007 22:14:29.231459  5299 net.cpp:84] Creating Layer Convolution21
I1007 22:14:29.231462  5299 net.cpp:406] Convolution21 <- Eltwise9_M2PELU19_0_split_0
I1007 22:14:29.231467  5299 net.cpp:380] Convolution21 -> Convolution21
I1007 22:14:29.237538  5299 net.cpp:122] Setting up Convolution21
I1007 22:14:29.237551  5299 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:14:29.237555  5299 net.cpp:137] Memory required for data: 558286000
I1007 22:14:29.237562  5299 layer_factory.hpp:77] Creating layer BatchNorm21
I1007 22:14:29.237571  5299 net.cpp:84] Creating Layer BatchNorm21
I1007 22:14:29.237576  5299 net.cpp:406] BatchNorm21 <- Convolution21
I1007 22:14:29.237581  5299 net.cpp:367] BatchNorm21 -> Convolution21 (in-place)
I1007 22:14:29.237804  5299 net.cpp:122] Setting up BatchNorm21
I1007 22:14:29.237814  5299 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:14:29.237818  5299 net.cpp:137] Memory required for data: 561562800
I1007 22:14:29.237826  5299 layer_factory.hpp:77] Creating layer Scale21
I1007 22:14:29.237843  5299 net.cpp:84] Creating Layer Scale21
I1007 22:14:29.237846  5299 net.cpp:406] Scale21 <- Convolution21
I1007 22:14:29.237854  5299 net.cpp:367] Scale21 -> Convolution21 (in-place)
I1007 22:14:29.237910  5299 layer_factory.hpp:77] Creating layer Scale21
I1007 22:14:29.238059  5299 net.cpp:122] Setting up Scale21
I1007 22:14:29.238070  5299 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:14:29.238072  5299 net.cpp:137] Memory required for data: 564839600
I1007 22:14:29.238080  5299 layer_factory.hpp:77] Creating layer M2PELU20
I1007 22:14:29.238087  5299 net.cpp:84] Creating Layer M2PELU20
I1007 22:14:29.238091  5299 net.cpp:406] M2PELU20 <- Convolution21
I1007 22:14:29.238099  5299 net.cpp:367] M2PELU20 -> Convolution21 (in-place)
I1007 22:14:29.238263  5299 net.cpp:122] Setting up M2PELU20
I1007 22:14:29.238272  5299 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:14:29.238276  5299 net.cpp:137] Memory required for data: 568116400
I1007 22:14:29.238282  5299 layer_factory.hpp:77] Creating layer Convolution22
I1007 22:14:29.238296  5299 net.cpp:84] Creating Layer Convolution22
I1007 22:14:29.238301  5299 net.cpp:406] Convolution22 <- Convolution21
I1007 22:14:29.238308  5299 net.cpp:380] Convolution22 -> Convolution22
I1007 22:14:29.244696  5299 net.cpp:122] Setting up Convolution22
I1007 22:14:29.244705  5299 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:14:29.244709  5299 net.cpp:137] Memory required for data: 571393200
I1007 22:14:29.244712  5299 layer_factory.hpp:77] Creating layer BatchNorm22
I1007 22:14:29.244719  5299 net.cpp:84] Creating Layer BatchNorm22
I1007 22:14:29.244721  5299 net.cpp:406] BatchNorm22 <- Convolution22
I1007 22:14:29.244725  5299 net.cpp:367] BatchNorm22 -> Convolution22 (in-place)
I1007 22:14:29.244874  5299 net.cpp:122] Setting up BatchNorm22
I1007 22:14:29.244879  5299 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:14:29.244881  5299 net.cpp:137] Memory required for data: 574670000
I1007 22:14:29.244885  5299 layer_factory.hpp:77] Creating layer Scale22
I1007 22:14:29.244890  5299 net.cpp:84] Creating Layer Scale22
I1007 22:14:29.244892  5299 net.cpp:406] Scale22 <- Convolution22
I1007 22:14:29.244895  5299 net.cpp:367] Scale22 -> Convolution22 (in-place)
I1007 22:14:29.244926  5299 layer_factory.hpp:77] Creating layer Scale22
I1007 22:14:29.245012  5299 net.cpp:122] Setting up Scale22
I1007 22:14:29.245016  5299 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:14:29.245018  5299 net.cpp:137] Memory required for data: 577946800
I1007 22:14:29.245023  5299 layer_factory.hpp:77] Creating layer Eltwise10
I1007 22:14:29.245026  5299 net.cpp:84] Creating Layer Eltwise10
I1007 22:14:29.245029  5299 net.cpp:406] Eltwise10 <- Eltwise9_M2PELU19_0_split_1
I1007 22:14:29.245033  5299 net.cpp:406] Eltwise10 <- Convolution22
I1007 22:14:29.245035  5299 net.cpp:380] Eltwise10 -> Eltwise10
I1007 22:14:29.245050  5299 net.cpp:122] Setting up Eltwise10
I1007 22:14:29.245054  5299 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:14:29.245056  5299 net.cpp:137] Memory required for data: 581223600
I1007 22:14:29.245059  5299 layer_factory.hpp:77] Creating layer M2PELU21
I1007 22:14:29.245064  5299 net.cpp:84] Creating Layer M2PELU21
I1007 22:14:29.245066  5299 net.cpp:406] M2PELU21 <- Eltwise10
I1007 22:14:29.245069  5299 net.cpp:367] M2PELU21 -> Eltwise10 (in-place)
I1007 22:14:29.245165  5299 net.cpp:122] Setting up M2PELU21
I1007 22:14:29.245170  5299 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:14:29.245172  5299 net.cpp:137] Memory required for data: 584500400
I1007 22:14:29.245175  5299 layer_factory.hpp:77] Creating layer Eltwise10_M2PELU21_0_split
I1007 22:14:29.245180  5299 net.cpp:84] Creating Layer Eltwise10_M2PELU21_0_split
I1007 22:14:29.245182  5299 net.cpp:406] Eltwise10_M2PELU21_0_split <- Eltwise10
I1007 22:14:29.245185  5299 net.cpp:380] Eltwise10_M2PELU21_0_split -> Eltwise10_M2PELU21_0_split_0
I1007 22:14:29.245189  5299 net.cpp:380] Eltwise10_M2PELU21_0_split -> Eltwise10_M2PELU21_0_split_1
I1007 22:14:29.245216  5299 net.cpp:122] Setting up Eltwise10_M2PELU21_0_split
I1007 22:14:29.245220  5299 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:14:29.245223  5299 net.cpp:129] Top shape: 100 32 16 16 (819200)
I1007 22:14:29.245224  5299 net.cpp:137] Memory required for data: 591054000
I1007 22:14:29.245234  5299 layer_factory.hpp:77] Creating layer Convolution23
I1007 22:14:29.245242  5299 net.cpp:84] Creating Layer Convolution23
I1007 22:14:29.245244  5299 net.cpp:406] Convolution23 <- Eltwise10_M2PELU21_0_split_0
I1007 22:14:29.245249  5299 net.cpp:380] Convolution23 -> Convolution23
I1007 22:14:29.251315  5299 net.cpp:122] Setting up Convolution23
I1007 22:14:29.251324  5299 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:14:29.251327  5299 net.cpp:137] Memory required for data: 592692400
I1007 22:14:29.251332  5299 layer_factory.hpp:77] Creating layer BatchNorm23
I1007 22:14:29.251338  5299 net.cpp:84] Creating Layer BatchNorm23
I1007 22:14:29.251340  5299 net.cpp:406] BatchNorm23 <- Convolution23
I1007 22:14:29.251345  5299 net.cpp:367] BatchNorm23 -> Convolution23 (in-place)
I1007 22:14:29.251493  5299 net.cpp:122] Setting up BatchNorm23
I1007 22:14:29.251497  5299 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:14:29.251500  5299 net.cpp:137] Memory required for data: 594330800
I1007 22:14:29.251504  5299 layer_factory.hpp:77] Creating layer Scale23
I1007 22:14:29.251509  5299 net.cpp:84] Creating Layer Scale23
I1007 22:14:29.251513  5299 net.cpp:406] Scale23 <- Convolution23
I1007 22:14:29.251515  5299 net.cpp:367] Scale23 -> Convolution23 (in-place)
I1007 22:14:29.251544  5299 layer_factory.hpp:77] Creating layer Scale23
I1007 22:14:29.251631  5299 net.cpp:122] Setting up Scale23
I1007 22:14:29.251634  5299 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:14:29.251636  5299 net.cpp:137] Memory required for data: 595969200
I1007 22:14:29.251641  5299 layer_factory.hpp:77] Creating layer Convolution24
I1007 22:14:29.251648  5299 net.cpp:84] Creating Layer Convolution24
I1007 22:14:29.251651  5299 net.cpp:406] Convolution24 <- Eltwise10_M2PELU21_0_split_1
I1007 22:14:29.251654  5299 net.cpp:380] Convolution24 -> Convolution24
I1007 22:14:29.257952  5299 net.cpp:122] Setting up Convolution24
I1007 22:14:29.257961  5299 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:14:29.257963  5299 net.cpp:137] Memory required for data: 597607600
I1007 22:14:29.257968  5299 layer_factory.hpp:77] Creating layer BatchNorm24
I1007 22:14:29.257973  5299 net.cpp:84] Creating Layer BatchNorm24
I1007 22:14:29.257977  5299 net.cpp:406] BatchNorm24 <- Convolution24
I1007 22:14:29.257980  5299 net.cpp:367] BatchNorm24 -> Convolution24 (in-place)
I1007 22:14:29.258129  5299 net.cpp:122] Setting up BatchNorm24
I1007 22:14:29.258134  5299 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:14:29.258136  5299 net.cpp:137] Memory required for data: 599246000
I1007 22:14:29.258141  5299 layer_factory.hpp:77] Creating layer Scale24
I1007 22:14:29.258146  5299 net.cpp:84] Creating Layer Scale24
I1007 22:14:29.258147  5299 net.cpp:406] Scale24 <- Convolution24
I1007 22:14:29.258150  5299 net.cpp:367] Scale24 -> Convolution24 (in-place)
I1007 22:14:29.258180  5299 layer_factory.hpp:77] Creating layer Scale24
I1007 22:14:29.258265  5299 net.cpp:122] Setting up Scale24
I1007 22:14:29.258270  5299 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:14:29.258272  5299 net.cpp:137] Memory required for data: 600884400
I1007 22:14:29.258275  5299 layer_factory.hpp:77] Creating layer M2PELU22
I1007 22:14:29.258280  5299 net.cpp:84] Creating Layer M2PELU22
I1007 22:14:29.258283  5299 net.cpp:406] M2PELU22 <- Convolution24
I1007 22:14:29.258286  5299 net.cpp:367] M2PELU22 -> Convolution24 (in-place)
I1007 22:14:29.258376  5299 net.cpp:122] Setting up M2PELU22
I1007 22:14:29.258380  5299 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:14:29.258383  5299 net.cpp:137] Memory required for data: 602522800
I1007 22:14:29.258386  5299 layer_factory.hpp:77] Creating layer Convolution25
I1007 22:14:29.258394  5299 net.cpp:84] Creating Layer Convolution25
I1007 22:14:29.258395  5299 net.cpp:406] Convolution25 <- Convolution24
I1007 22:14:29.258399  5299 net.cpp:380] Convolution25 -> Convolution25
I1007 22:14:29.264504  5299 net.cpp:122] Setting up Convolution25
I1007 22:14:29.264513  5299 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:14:29.264523  5299 net.cpp:137] Memory required for data: 604161200
I1007 22:14:29.264528  5299 layer_factory.hpp:77] Creating layer BatchNorm25
I1007 22:14:29.264533  5299 net.cpp:84] Creating Layer BatchNorm25
I1007 22:14:29.264535  5299 net.cpp:406] BatchNorm25 <- Convolution25
I1007 22:14:29.264539  5299 net.cpp:367] BatchNorm25 -> Convolution25 (in-place)
I1007 22:14:29.264685  5299 net.cpp:122] Setting up BatchNorm25
I1007 22:14:29.264690  5299 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:14:29.264693  5299 net.cpp:137] Memory required for data: 605799600
I1007 22:14:29.264698  5299 layer_factory.hpp:77] Creating layer Scale25
I1007 22:14:29.264701  5299 net.cpp:84] Creating Layer Scale25
I1007 22:14:29.264703  5299 net.cpp:406] Scale25 <- Convolution25
I1007 22:14:29.264708  5299 net.cpp:367] Scale25 -> Convolution25 (in-place)
I1007 22:14:29.264735  5299 layer_factory.hpp:77] Creating layer Scale25
I1007 22:14:29.264819  5299 net.cpp:122] Setting up Scale25
I1007 22:14:29.264823  5299 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:14:29.264827  5299 net.cpp:137] Memory required for data: 607438000
I1007 22:14:29.264830  5299 layer_factory.hpp:77] Creating layer Eltwise11
I1007 22:14:29.264833  5299 net.cpp:84] Creating Layer Eltwise11
I1007 22:14:29.264837  5299 net.cpp:406] Eltwise11 <- Convolution23
I1007 22:14:29.264839  5299 net.cpp:406] Eltwise11 <- Convolution25
I1007 22:14:29.264843  5299 net.cpp:380] Eltwise11 -> Eltwise11
I1007 22:14:29.264861  5299 net.cpp:122] Setting up Eltwise11
I1007 22:14:29.264865  5299 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:14:29.264868  5299 net.cpp:137] Memory required for data: 609076400
I1007 22:14:29.264869  5299 layer_factory.hpp:77] Creating layer M2PELU23
I1007 22:14:29.264873  5299 net.cpp:84] Creating Layer M2PELU23
I1007 22:14:29.264876  5299 net.cpp:406] M2PELU23 <- Eltwise11
I1007 22:14:29.264879  5299 net.cpp:367] M2PELU23 -> Eltwise11 (in-place)
I1007 22:14:29.264972  5299 net.cpp:122] Setting up M2PELU23
I1007 22:14:29.264976  5299 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:14:29.264978  5299 net.cpp:137] Memory required for data: 610714800
I1007 22:14:29.264982  5299 layer_factory.hpp:77] Creating layer Eltwise11_M2PELU23_0_split
I1007 22:14:29.264986  5299 net.cpp:84] Creating Layer Eltwise11_M2PELU23_0_split
I1007 22:14:29.264988  5299 net.cpp:406] Eltwise11_M2PELU23_0_split <- Eltwise11
I1007 22:14:29.264992  5299 net.cpp:380] Eltwise11_M2PELU23_0_split -> Eltwise11_M2PELU23_0_split_0
I1007 22:14:29.264997  5299 net.cpp:380] Eltwise11_M2PELU23_0_split -> Eltwise11_M2PELU23_0_split_1
I1007 22:14:29.265022  5299 net.cpp:122] Setting up Eltwise11_M2PELU23_0_split
I1007 22:14:29.265027  5299 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:14:29.265029  5299 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:14:29.265031  5299 net.cpp:137] Memory required for data: 613991600
I1007 22:14:29.265033  5299 layer_factory.hpp:77] Creating layer Convolution26
I1007 22:14:29.265038  5299 net.cpp:84] Creating Layer Convolution26
I1007 22:14:29.265040  5299 net.cpp:406] Convolution26 <- Eltwise11_M2PELU23_0_split_0
I1007 22:14:29.265045  5299 net.cpp:380] Convolution26 -> Convolution26
I1007 22:14:29.271075  5299 net.cpp:122] Setting up Convolution26
I1007 22:14:29.271086  5299 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:14:29.271088  5299 net.cpp:137] Memory required for data: 615630000
I1007 22:14:29.271093  5299 layer_factory.hpp:77] Creating layer BatchNorm26
I1007 22:14:29.271098  5299 net.cpp:84] Creating Layer BatchNorm26
I1007 22:14:29.271101  5299 net.cpp:406] BatchNorm26 <- Convolution26
I1007 22:14:29.271106  5299 net.cpp:367] BatchNorm26 -> Convolution26 (in-place)
I1007 22:14:29.271282  5299 net.cpp:122] Setting up BatchNorm26
I1007 22:14:29.271291  5299 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:14:29.271293  5299 net.cpp:137] Memory required for data: 617268400
I1007 22:14:29.271301  5299 layer_factory.hpp:77] Creating layer Scale26
I1007 22:14:29.271315  5299 net.cpp:84] Creating Layer Scale26
I1007 22:14:29.271327  5299 net.cpp:406] Scale26 <- Convolution26
I1007 22:14:29.271335  5299 net.cpp:367] Scale26 -> Convolution26 (in-place)
I1007 22:14:29.271369  5299 layer_factory.hpp:77] Creating layer Scale26
I1007 22:14:29.271510  5299 net.cpp:122] Setting up Scale26
I1007 22:14:29.271517  5299 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:14:29.271519  5299 net.cpp:137] Memory required for data: 618906800
I1007 22:14:29.271524  5299 layer_factory.hpp:77] Creating layer M2PELU24
I1007 22:14:29.271529  5299 net.cpp:84] Creating Layer M2PELU24
I1007 22:14:29.271533  5299 net.cpp:406] M2PELU24 <- Convolution26
I1007 22:14:29.271536  5299 net.cpp:367] M2PELU24 -> Convolution26 (in-place)
I1007 22:14:29.271643  5299 net.cpp:122] Setting up M2PELU24
I1007 22:14:29.271647  5299 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:14:29.271649  5299 net.cpp:137] Memory required for data: 620545200
I1007 22:14:29.271653  5299 layer_factory.hpp:77] Creating layer Convolution27
I1007 22:14:29.271661  5299 net.cpp:84] Creating Layer Convolution27
I1007 22:14:29.271663  5299 net.cpp:406] Convolution27 <- Convolution26
I1007 22:14:29.271667  5299 net.cpp:380] Convolution27 -> Convolution27
I1007 22:14:29.278337  5299 net.cpp:122] Setting up Convolution27
I1007 22:14:29.278347  5299 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:14:29.278349  5299 net.cpp:137] Memory required for data: 622183600
I1007 22:14:29.278353  5299 layer_factory.hpp:77] Creating layer BatchNorm27
I1007 22:14:29.278369  5299 net.cpp:84] Creating Layer BatchNorm27
I1007 22:14:29.278373  5299 net.cpp:406] BatchNorm27 <- Convolution27
I1007 22:14:29.278376  5299 net.cpp:367] BatchNorm27 -> Convolution27 (in-place)
I1007 22:14:29.278527  5299 net.cpp:122] Setting up BatchNorm27
I1007 22:14:29.278532  5299 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:14:29.278533  5299 net.cpp:137] Memory required for data: 623822000
I1007 22:14:29.278538  5299 layer_factory.hpp:77] Creating layer Scale27
I1007 22:14:29.278543  5299 net.cpp:84] Creating Layer Scale27
I1007 22:14:29.278545  5299 net.cpp:406] Scale27 <- Convolution27
I1007 22:14:29.278548  5299 net.cpp:367] Scale27 -> Convolution27 (in-place)
I1007 22:14:29.278578  5299 layer_factory.hpp:77] Creating layer Scale27
I1007 22:14:29.278664  5299 net.cpp:122] Setting up Scale27
I1007 22:14:29.278668  5299 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:14:29.278671  5299 net.cpp:137] Memory required for data: 625460400
I1007 22:14:29.278674  5299 layer_factory.hpp:77] Creating layer Eltwise12
I1007 22:14:29.278679  5299 net.cpp:84] Creating Layer Eltwise12
I1007 22:14:29.278681  5299 net.cpp:406] Eltwise12 <- Eltwise11_M2PELU23_0_split_1
I1007 22:14:29.278684  5299 net.cpp:406] Eltwise12 <- Convolution27
I1007 22:14:29.278687  5299 net.cpp:380] Eltwise12 -> Eltwise12
I1007 22:14:29.278707  5299 net.cpp:122] Setting up Eltwise12
I1007 22:14:29.278709  5299 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:14:29.278712  5299 net.cpp:137] Memory required for data: 627098800
I1007 22:14:29.278713  5299 layer_factory.hpp:77] Creating layer M2PELU25
I1007 22:14:29.278719  5299 net.cpp:84] Creating Layer M2PELU25
I1007 22:14:29.278722  5299 net.cpp:406] M2PELU25 <- Eltwise12
I1007 22:14:29.278724  5299 net.cpp:367] M2PELU25 -> Eltwise12 (in-place)
I1007 22:14:29.278815  5299 net.cpp:122] Setting up M2PELU25
I1007 22:14:29.278820  5299 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:14:29.278821  5299 net.cpp:137] Memory required for data: 628737200
I1007 22:14:29.278825  5299 layer_factory.hpp:77] Creating layer Eltwise12_M2PELU25_0_split
I1007 22:14:29.278829  5299 net.cpp:84] Creating Layer Eltwise12_M2PELU25_0_split
I1007 22:14:29.278831  5299 net.cpp:406] Eltwise12_M2PELU25_0_split <- Eltwise12
I1007 22:14:29.278834  5299 net.cpp:380] Eltwise12_M2PELU25_0_split -> Eltwise12_M2PELU25_0_split_0
I1007 22:14:29.278839  5299 net.cpp:380] Eltwise12_M2PELU25_0_split -> Eltwise12_M2PELU25_0_split_1
I1007 22:14:29.278864  5299 net.cpp:122] Setting up Eltwise12_M2PELU25_0_split
I1007 22:14:29.278875  5299 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:14:29.278878  5299 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:14:29.278880  5299 net.cpp:137] Memory required for data: 632014000
I1007 22:14:29.278882  5299 layer_factory.hpp:77] Creating layer Convolution28
I1007 22:14:29.278888  5299 net.cpp:84] Creating Layer Convolution28
I1007 22:14:29.278892  5299 net.cpp:406] Convolution28 <- Eltwise12_M2PELU25_0_split_0
I1007 22:14:29.278895  5299 net.cpp:380] Convolution28 -> Convolution28
I1007 22:14:29.281384  5299 net.cpp:122] Setting up Convolution28
I1007 22:14:29.281395  5299 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:14:29.281400  5299 net.cpp:137] Memory required for data: 633652400
I1007 22:14:29.281407  5299 layer_factory.hpp:77] Creating layer BatchNorm28
I1007 22:14:29.281416  5299 net.cpp:84] Creating Layer BatchNorm28
I1007 22:14:29.281421  5299 net.cpp:406] BatchNorm28 <- Convolution28
I1007 22:14:29.281428  5299 net.cpp:367] BatchNorm28 -> Convolution28 (in-place)
I1007 22:14:29.281646  5299 net.cpp:122] Setting up BatchNorm28
I1007 22:14:29.281653  5299 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:14:29.281656  5299 net.cpp:137] Memory required for data: 635290800
I1007 22:14:29.281661  5299 layer_factory.hpp:77] Creating layer Scale28
I1007 22:14:29.281666  5299 net.cpp:84] Creating Layer Scale28
I1007 22:14:29.281668  5299 net.cpp:406] Scale28 <- Convolution28
I1007 22:14:29.281672  5299 net.cpp:367] Scale28 -> Convolution28 (in-place)
I1007 22:14:29.281703  5299 layer_factory.hpp:77] Creating layer Scale28
I1007 22:14:29.281790  5299 net.cpp:122] Setting up Scale28
I1007 22:14:29.281795  5299 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:14:29.281797  5299 net.cpp:137] Memory required for data: 636929200
I1007 22:14:29.281801  5299 layer_factory.hpp:77] Creating layer M2PELU26
I1007 22:14:29.281806  5299 net.cpp:84] Creating Layer M2PELU26
I1007 22:14:29.281810  5299 net.cpp:406] M2PELU26 <- Convolution28
I1007 22:14:29.281812  5299 net.cpp:367] M2PELU26 -> Convolution28 (in-place)
I1007 22:14:29.281904  5299 net.cpp:122] Setting up M2PELU26
I1007 22:14:29.281909  5299 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:14:29.281913  5299 net.cpp:137] Memory required for data: 638567600
I1007 22:14:29.281915  5299 layer_factory.hpp:77] Creating layer Convolution29
I1007 22:14:29.281922  5299 net.cpp:84] Creating Layer Convolution29
I1007 22:14:29.281924  5299 net.cpp:406] Convolution29 <- Convolution28
I1007 22:14:29.281929  5299 net.cpp:380] Convolution29 -> Convolution29
I1007 22:14:29.287056  5299 net.cpp:122] Setting up Convolution29
I1007 22:14:29.287065  5299 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:14:29.287068  5299 net.cpp:137] Memory required for data: 640206000
I1007 22:14:29.287072  5299 layer_factory.hpp:77] Creating layer BatchNorm29
I1007 22:14:29.287078  5299 net.cpp:84] Creating Layer BatchNorm29
I1007 22:14:29.287081  5299 net.cpp:406] BatchNorm29 <- Convolution29
I1007 22:14:29.287086  5299 net.cpp:367] BatchNorm29 -> Convolution29 (in-place)
I1007 22:14:29.287261  5299 net.cpp:122] Setting up BatchNorm29
I1007 22:14:29.287266  5299 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:14:29.287268  5299 net.cpp:137] Memory required for data: 641844400
I1007 22:14:29.287273  5299 layer_factory.hpp:77] Creating layer Scale29
I1007 22:14:29.287278  5299 net.cpp:84] Creating Layer Scale29
I1007 22:14:29.287281  5299 net.cpp:406] Scale29 <- Convolution29
I1007 22:14:29.287283  5299 net.cpp:367] Scale29 -> Convolution29 (in-place)
I1007 22:14:29.287314  5299 layer_factory.hpp:77] Creating layer Scale29
I1007 22:14:29.287400  5299 net.cpp:122] Setting up Scale29
I1007 22:14:29.287405  5299 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:14:29.287406  5299 net.cpp:137] Memory required for data: 643482800
I1007 22:14:29.287410  5299 layer_factory.hpp:77] Creating layer Eltwise13
I1007 22:14:29.287413  5299 net.cpp:84] Creating Layer Eltwise13
I1007 22:14:29.287416  5299 net.cpp:406] Eltwise13 <- Eltwise12_M2PELU25_0_split_1
I1007 22:14:29.287428  5299 net.cpp:406] Eltwise13 <- Convolution29
I1007 22:14:29.287433  5299 net.cpp:380] Eltwise13 -> Eltwise13
I1007 22:14:29.287452  5299 net.cpp:122] Setting up Eltwise13
I1007 22:14:29.287456  5299 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:14:29.287458  5299 net.cpp:137] Memory required for data: 645121200
I1007 22:14:29.287461  5299 layer_factory.hpp:77] Creating layer M2PELU27
I1007 22:14:29.287466  5299 net.cpp:84] Creating Layer M2PELU27
I1007 22:14:29.287467  5299 net.cpp:406] M2PELU27 <- Eltwise13
I1007 22:14:29.287472  5299 net.cpp:367] M2PELU27 -> Eltwise13 (in-place)
I1007 22:14:29.287564  5299 net.cpp:122] Setting up M2PELU27
I1007 22:14:29.287569  5299 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:14:29.287571  5299 net.cpp:137] Memory required for data: 646759600
I1007 22:14:29.287595  5299 layer_factory.hpp:77] Creating layer Eltwise13_M2PELU27_0_split
I1007 22:14:29.287598  5299 net.cpp:84] Creating Layer Eltwise13_M2PELU27_0_split
I1007 22:14:29.287601  5299 net.cpp:406] Eltwise13_M2PELU27_0_split <- Eltwise13
I1007 22:14:29.287605  5299 net.cpp:380] Eltwise13_M2PELU27_0_split -> Eltwise13_M2PELU27_0_split_0
I1007 22:14:29.287608  5299 net.cpp:380] Eltwise13_M2PELU27_0_split -> Eltwise13_M2PELU27_0_split_1
I1007 22:14:29.287636  5299 net.cpp:122] Setting up Eltwise13_M2PELU27_0_split
I1007 22:14:29.287641  5299 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:14:29.287643  5299 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:14:29.287645  5299 net.cpp:137] Memory required for data: 650036400
I1007 22:14:29.287647  5299 layer_factory.hpp:77] Creating layer Convolution30
I1007 22:14:29.287655  5299 net.cpp:84] Creating Layer Convolution30
I1007 22:14:29.287658  5299 net.cpp:406] Convolution30 <- Eltwise13_M2PELU27_0_split_0
I1007 22:14:29.287662  5299 net.cpp:380] Convolution30 -> Convolution30
I1007 22:14:29.293910  5299 net.cpp:122] Setting up Convolution30
I1007 22:14:29.293918  5299 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:14:29.293920  5299 net.cpp:137] Memory required for data: 651674800
I1007 22:14:29.293926  5299 layer_factory.hpp:77] Creating layer BatchNorm30
I1007 22:14:29.293931  5299 net.cpp:84] Creating Layer BatchNorm30
I1007 22:14:29.293933  5299 net.cpp:406] BatchNorm30 <- Convolution30
I1007 22:14:29.293937  5299 net.cpp:367] BatchNorm30 -> Convolution30 (in-place)
I1007 22:14:29.294092  5299 net.cpp:122] Setting up BatchNorm30
I1007 22:14:29.294097  5299 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:14:29.294100  5299 net.cpp:137] Memory required for data: 653313200
I1007 22:14:29.294103  5299 layer_factory.hpp:77] Creating layer Scale30
I1007 22:14:29.294108  5299 net.cpp:84] Creating Layer Scale30
I1007 22:14:29.294111  5299 net.cpp:406] Scale30 <- Convolution30
I1007 22:14:29.294114  5299 net.cpp:367] Scale30 -> Convolution30 (in-place)
I1007 22:14:29.294144  5299 layer_factory.hpp:77] Creating layer Scale30
I1007 22:14:29.294231  5299 net.cpp:122] Setting up Scale30
I1007 22:14:29.294235  5299 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:14:29.294237  5299 net.cpp:137] Memory required for data: 654951600
I1007 22:14:29.294241  5299 layer_factory.hpp:77] Creating layer M2PELU28
I1007 22:14:29.294246  5299 net.cpp:84] Creating Layer M2PELU28
I1007 22:14:29.294250  5299 net.cpp:406] M2PELU28 <- Convolution30
I1007 22:14:29.294253  5299 net.cpp:367] M2PELU28 -> Convolution30 (in-place)
I1007 22:14:29.294348  5299 net.cpp:122] Setting up M2PELU28
I1007 22:14:29.294351  5299 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:14:29.294353  5299 net.cpp:137] Memory required for data: 656590000
I1007 22:14:29.294356  5299 layer_factory.hpp:77] Creating layer Convolution31
I1007 22:14:29.294363  5299 net.cpp:84] Creating Layer Convolution31
I1007 22:14:29.294365  5299 net.cpp:406] Convolution31 <- Convolution30
I1007 22:14:29.294369  5299 net.cpp:380] Convolution31 -> Convolution31
I1007 22:14:29.299408  5299 net.cpp:122] Setting up Convolution31
I1007 22:14:29.299422  5299 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:14:29.299434  5299 net.cpp:137] Memory required for data: 658228400
I1007 22:14:29.299443  5299 layer_factory.hpp:77] Creating layer BatchNorm31
I1007 22:14:29.299460  5299 net.cpp:84] Creating Layer BatchNorm31
I1007 22:14:29.299465  5299 net.cpp:406] BatchNorm31 <- Convolution31
I1007 22:14:29.299471  5299 net.cpp:367] BatchNorm31 -> Convolution31 (in-place)
I1007 22:14:29.299675  5299 net.cpp:122] Setting up BatchNorm31
I1007 22:14:29.299682  5299 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:14:29.299685  5299 net.cpp:137] Memory required for data: 659866800
I1007 22:14:29.299690  5299 layer_factory.hpp:77] Creating layer Scale31
I1007 22:14:29.299695  5299 net.cpp:84] Creating Layer Scale31
I1007 22:14:29.299697  5299 net.cpp:406] Scale31 <- Convolution31
I1007 22:14:29.299701  5299 net.cpp:367] Scale31 -> Convolution31 (in-place)
I1007 22:14:29.299734  5299 layer_factory.hpp:77] Creating layer Scale31
I1007 22:14:29.299826  5299 net.cpp:122] Setting up Scale31
I1007 22:14:29.299830  5299 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:14:29.299834  5299 net.cpp:137] Memory required for data: 661505200
I1007 22:14:29.299837  5299 layer_factory.hpp:77] Creating layer Eltwise14
I1007 22:14:29.299842  5299 net.cpp:84] Creating Layer Eltwise14
I1007 22:14:29.299844  5299 net.cpp:406] Eltwise14 <- Eltwise13_M2PELU27_0_split_1
I1007 22:14:29.299847  5299 net.cpp:406] Eltwise14 <- Convolution31
I1007 22:14:29.299851  5299 net.cpp:380] Eltwise14 -> Eltwise14
I1007 22:14:29.299870  5299 net.cpp:122] Setting up Eltwise14
I1007 22:14:29.299875  5299 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:14:29.299876  5299 net.cpp:137] Memory required for data: 663143600
I1007 22:14:29.299878  5299 layer_factory.hpp:77] Creating layer M2PELU29
I1007 22:14:29.299885  5299 net.cpp:84] Creating Layer M2PELU29
I1007 22:14:29.299886  5299 net.cpp:406] M2PELU29 <- Eltwise14
I1007 22:14:29.299890  5299 net.cpp:367] M2PELU29 -> Eltwise14 (in-place)
I1007 22:14:29.299986  5299 net.cpp:122] Setting up M2PELU29
I1007 22:14:29.299990  5299 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:14:29.299993  5299 net.cpp:137] Memory required for data: 664782000
I1007 22:14:29.299996  5299 layer_factory.hpp:77] Creating layer Eltwise14_M2PELU29_0_split
I1007 22:14:29.300000  5299 net.cpp:84] Creating Layer Eltwise14_M2PELU29_0_split
I1007 22:14:29.300002  5299 net.cpp:406] Eltwise14_M2PELU29_0_split <- Eltwise14
I1007 22:14:29.300005  5299 net.cpp:380] Eltwise14_M2PELU29_0_split -> Eltwise14_M2PELU29_0_split_0
I1007 22:14:29.300009  5299 net.cpp:380] Eltwise14_M2PELU29_0_split -> Eltwise14_M2PELU29_0_split_1
I1007 22:14:29.300037  5299 net.cpp:122] Setting up Eltwise14_M2PELU29_0_split
I1007 22:14:29.300041  5299 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:14:29.300043  5299 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:14:29.300045  5299 net.cpp:137] Memory required for data: 668058800
I1007 22:14:29.300047  5299 layer_factory.hpp:77] Creating layer Convolution32
I1007 22:14:29.300055  5299 net.cpp:84] Creating Layer Convolution32
I1007 22:14:29.300056  5299 net.cpp:406] Convolution32 <- Eltwise14_M2PELU29_0_split_0
I1007 22:14:29.300060  5299 net.cpp:380] Convolution32 -> Convolution32
I1007 22:14:29.304697  5299 net.cpp:122] Setting up Convolution32
I1007 22:14:29.304708  5299 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:14:29.304711  5299 net.cpp:137] Memory required for data: 669697200
I1007 22:14:29.304716  5299 layer_factory.hpp:77] Creating layer BatchNorm32
I1007 22:14:29.304723  5299 net.cpp:84] Creating Layer BatchNorm32
I1007 22:14:29.304725  5299 net.cpp:406] BatchNorm32 <- Convolution32
I1007 22:14:29.304729  5299 net.cpp:367] BatchNorm32 -> Convolution32 (in-place)
I1007 22:14:29.304894  5299 net.cpp:122] Setting up BatchNorm32
I1007 22:14:29.304899  5299 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:14:29.304901  5299 net.cpp:137] Memory required for data: 671335600
I1007 22:14:29.304906  5299 layer_factory.hpp:77] Creating layer Scale32
I1007 22:14:29.304910  5299 net.cpp:84] Creating Layer Scale32
I1007 22:14:29.304920  5299 net.cpp:406] Scale32 <- Convolution32
I1007 22:14:29.304924  5299 net.cpp:367] Scale32 -> Convolution32 (in-place)
I1007 22:14:29.304960  5299 layer_factory.hpp:77] Creating layer Scale32
I1007 22:14:29.305048  5299 net.cpp:122] Setting up Scale32
I1007 22:14:29.305053  5299 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:14:29.305055  5299 net.cpp:137] Memory required for data: 672974000
I1007 22:14:29.305059  5299 layer_factory.hpp:77] Creating layer M2PELU30
I1007 22:14:29.305065  5299 net.cpp:84] Creating Layer M2PELU30
I1007 22:14:29.305068  5299 net.cpp:406] M2PELU30 <- Convolution32
I1007 22:14:29.305071  5299 net.cpp:367] M2PELU30 -> Convolution32 (in-place)
I1007 22:14:29.305169  5299 net.cpp:122] Setting up M2PELU30
I1007 22:14:29.305173  5299 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:14:29.305176  5299 net.cpp:137] Memory required for data: 674612400
I1007 22:14:29.305179  5299 layer_factory.hpp:77] Creating layer Convolution33
I1007 22:14:29.305186  5299 net.cpp:84] Creating Layer Convolution33
I1007 22:14:29.305189  5299 net.cpp:406] Convolution33 <- Convolution32
I1007 22:14:29.305193  5299 net.cpp:380] Convolution33 -> Convolution33
I1007 22:14:29.311107  5299 net.cpp:122] Setting up Convolution33
I1007 22:14:29.311116  5299 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:14:29.311120  5299 net.cpp:137] Memory required for data: 676250800
I1007 22:14:29.311123  5299 layer_factory.hpp:77] Creating layer BatchNorm33
I1007 22:14:29.311131  5299 net.cpp:84] Creating Layer BatchNorm33
I1007 22:14:29.311133  5299 net.cpp:406] BatchNorm33 <- Convolution33
I1007 22:14:29.311137  5299 net.cpp:367] BatchNorm33 -> Convolution33 (in-place)
I1007 22:14:29.311326  5299 net.cpp:122] Setting up BatchNorm33
I1007 22:14:29.311331  5299 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:14:29.311333  5299 net.cpp:137] Memory required for data: 677889200
I1007 22:14:29.311338  5299 layer_factory.hpp:77] Creating layer Scale33
I1007 22:14:29.311343  5299 net.cpp:84] Creating Layer Scale33
I1007 22:14:29.311347  5299 net.cpp:406] Scale33 <- Convolution33
I1007 22:14:29.311349  5299 net.cpp:367] Scale33 -> Convolution33 (in-place)
I1007 22:14:29.311381  5299 layer_factory.hpp:77] Creating layer Scale33
I1007 22:14:29.311471  5299 net.cpp:122] Setting up Scale33
I1007 22:14:29.311475  5299 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:14:29.311477  5299 net.cpp:137] Memory required for data: 679527600
I1007 22:14:29.311481  5299 layer_factory.hpp:77] Creating layer Eltwise15
I1007 22:14:29.311487  5299 net.cpp:84] Creating Layer Eltwise15
I1007 22:14:29.311491  5299 net.cpp:406] Eltwise15 <- Eltwise14_M2PELU29_0_split_1
I1007 22:14:29.311493  5299 net.cpp:406] Eltwise15 <- Convolution33
I1007 22:14:29.311496  5299 net.cpp:380] Eltwise15 -> Eltwise15
I1007 22:14:29.311516  5299 net.cpp:122] Setting up Eltwise15
I1007 22:14:29.311519  5299 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:14:29.311522  5299 net.cpp:137] Memory required for data: 681166000
I1007 22:14:29.311523  5299 layer_factory.hpp:77] Creating layer M2PELU31
I1007 22:14:29.311529  5299 net.cpp:84] Creating Layer M2PELU31
I1007 22:14:29.311532  5299 net.cpp:406] M2PELU31 <- Eltwise15
I1007 22:14:29.311535  5299 net.cpp:367] M2PELU31 -> Eltwise15 (in-place)
I1007 22:14:29.311635  5299 net.cpp:122] Setting up M2PELU31
I1007 22:14:29.311638  5299 net.cpp:129] Top shape: 100 64 8 8 (409600)
I1007 22:14:29.311640  5299 net.cpp:137] Memory required for data: 682804400
I1007 22:14:29.311645  5299 layer_factory.hpp:77] Creating layer Pooling1
I1007 22:14:29.311650  5299 net.cpp:84] Creating Layer Pooling1
I1007 22:14:29.311651  5299 net.cpp:406] Pooling1 <- Eltwise15
I1007 22:14:29.311655  5299 net.cpp:380] Pooling1 -> Pooling1
I1007 22:14:29.313216  5299 net.cpp:122] Setting up Pooling1
I1007 22:14:29.313222  5299 net.cpp:129] Top shape: 100 64 1 1 (6400)
I1007 22:14:29.313225  5299 net.cpp:137] Memory required for data: 682830000
I1007 22:14:29.313227  5299 layer_factory.hpp:77] Creating layer InnerProduct1
I1007 22:14:29.313239  5299 net.cpp:84] Creating Layer InnerProduct1
I1007 22:14:29.313242  5299 net.cpp:406] InnerProduct1 <- Pooling1
I1007 22:14:29.313247  5299 net.cpp:380] InnerProduct1 -> InnerProduct1
I1007 22:14:29.313360  5299 net.cpp:122] Setting up InnerProduct1
I1007 22:14:29.313365  5299 net.cpp:129] Top shape: 100 10 (1000)
I1007 22:14:29.313367  5299 net.cpp:137] Memory required for data: 682834000
I1007 22:14:29.313371  5299 layer_factory.hpp:77] Creating layer InnerProduct1_InnerProduct1_0_split
I1007 22:14:29.313375  5299 net.cpp:84] Creating Layer InnerProduct1_InnerProduct1_0_split
I1007 22:14:29.313377  5299 net.cpp:406] InnerProduct1_InnerProduct1_0_split <- InnerProduct1
I1007 22:14:29.313381  5299 net.cpp:380] InnerProduct1_InnerProduct1_0_split -> InnerProduct1_InnerProduct1_0_split_0
I1007 22:14:29.313386  5299 net.cpp:380] InnerProduct1_InnerProduct1_0_split -> InnerProduct1_InnerProduct1_0_split_1
I1007 22:14:29.313415  5299 net.cpp:122] Setting up InnerProduct1_InnerProduct1_0_split
I1007 22:14:29.313418  5299 net.cpp:129] Top shape: 100 10 (1000)
I1007 22:14:29.313421  5299 net.cpp:129] Top shape: 100 10 (1000)
I1007 22:14:29.313423  5299 net.cpp:137] Memory required for data: 682842000
I1007 22:14:29.313426  5299 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I1007 22:14:29.313431  5299 net.cpp:84] Creating Layer SoftmaxWithLoss1
I1007 22:14:29.313432  5299 net.cpp:406] SoftmaxWithLoss1 <- InnerProduct1_InnerProduct1_0_split_0
I1007 22:14:29.313446  5299 net.cpp:406] SoftmaxWithLoss1 <- Data2_Data1_1_split_0
I1007 22:14:29.313448  5299 net.cpp:380] SoftmaxWithLoss1 -> SoftmaxWithLoss1
I1007 22:14:29.313453  5299 layer_factory.hpp:77] Creating layer SoftmaxWithLoss1
I1007 22:14:29.315454  5299 net.cpp:122] Setting up SoftmaxWithLoss1
I1007 22:14:29.315464  5299 net.cpp:129] Top shape: (1)
I1007 22:14:29.315465  5299 net.cpp:132]     with loss weight 1
I1007 22:14:29.315474  5299 net.cpp:137] Memory required for data: 682842004
I1007 22:14:29.315476  5299 layer_factory.hpp:77] Creating layer Accuracy1
I1007 22:14:29.315481  5299 net.cpp:84] Creating Layer Accuracy1
I1007 22:14:29.315485  5299 net.cpp:406] Accuracy1 <- InnerProduct1_InnerProduct1_0_split_1
I1007 22:14:29.315487  5299 net.cpp:406] Accuracy1 <- Data2_Data1_1_split_1
I1007 22:14:29.315491  5299 net.cpp:380] Accuracy1 -> Accuracy1
I1007 22:14:29.315497  5299 net.cpp:122] Setting up Accuracy1
I1007 22:14:29.315500  5299 net.cpp:129] Top shape: (1)
I1007 22:14:29.315502  5299 net.cpp:137] Memory required for data: 682842008
I1007 22:14:29.315505  5299 net.cpp:200] Accuracy1 does not need backward computation.
I1007 22:14:29.315507  5299 net.cpp:198] SoftmaxWithLoss1 needs backward computation.
I1007 22:14:29.315510  5299 net.cpp:198] InnerProduct1_InnerProduct1_0_split needs backward computation.
I1007 22:14:29.315512  5299 net.cpp:198] InnerProduct1 needs backward computation.
I1007 22:14:29.315515  5299 net.cpp:198] Pooling1 needs backward computation.
I1007 22:14:29.315517  5299 net.cpp:198] M2PELU31 needs backward computation.
I1007 22:14:29.315520  5299 net.cpp:198] Eltwise15 needs backward computation.
I1007 22:14:29.315521  5299 net.cpp:198] Scale33 needs backward computation.
I1007 22:14:29.315523  5299 net.cpp:198] BatchNorm33 needs backward computation.
I1007 22:14:29.315526  5299 net.cpp:198] Convolution33 needs backward computation.
I1007 22:14:29.315527  5299 net.cpp:198] M2PELU30 needs backward computation.
I1007 22:14:29.315529  5299 net.cpp:198] Scale32 needs backward computation.
I1007 22:14:29.315531  5299 net.cpp:198] BatchNorm32 needs backward computation.
I1007 22:14:29.315533  5299 net.cpp:198] Convolution32 needs backward computation.
I1007 22:14:29.315536  5299 net.cpp:198] Eltwise14_M2PELU29_0_split needs backward computation.
I1007 22:14:29.315538  5299 net.cpp:198] M2PELU29 needs backward computation.
I1007 22:14:29.315541  5299 net.cpp:198] Eltwise14 needs backward computation.
I1007 22:14:29.315543  5299 net.cpp:198] Scale31 needs backward computation.
I1007 22:14:29.315552  5299 net.cpp:198] BatchNorm31 needs backward computation.
I1007 22:14:29.315554  5299 net.cpp:198] Convolution31 needs backward computation.
I1007 22:14:29.315557  5299 net.cpp:198] M2PELU28 needs backward computation.
I1007 22:14:29.315559  5299 net.cpp:198] Scale30 needs backward computation.
I1007 22:14:29.315562  5299 net.cpp:198] BatchNorm30 needs backward computation.
I1007 22:14:29.315563  5299 net.cpp:198] Convolution30 needs backward computation.
I1007 22:14:29.315565  5299 net.cpp:198] Eltwise13_M2PELU27_0_split needs backward computation.
I1007 22:14:29.315568  5299 net.cpp:198] M2PELU27 needs backward computation.
I1007 22:14:29.315570  5299 net.cpp:198] Eltwise13 needs backward computation.
I1007 22:14:29.315573  5299 net.cpp:198] Scale29 needs backward computation.
I1007 22:14:29.315575  5299 net.cpp:198] BatchNorm29 needs backward computation.
I1007 22:14:29.315577  5299 net.cpp:198] Convolution29 needs backward computation.
I1007 22:14:29.315580  5299 net.cpp:198] M2PELU26 needs backward computation.
I1007 22:14:29.315582  5299 net.cpp:198] Scale28 needs backward computation.
I1007 22:14:29.315584  5299 net.cpp:198] BatchNorm28 needs backward computation.
I1007 22:14:29.315587  5299 net.cpp:198] Convolution28 needs backward computation.
I1007 22:14:29.315589  5299 net.cpp:198] Eltwise12_M2PELU25_0_split needs backward computation.
I1007 22:14:29.315592  5299 net.cpp:198] M2PELU25 needs backward computation.
I1007 22:14:29.315594  5299 net.cpp:198] Eltwise12 needs backward computation.
I1007 22:14:29.315596  5299 net.cpp:198] Scale27 needs backward computation.
I1007 22:14:29.315598  5299 net.cpp:198] BatchNorm27 needs backward computation.
I1007 22:14:29.315601  5299 net.cpp:198] Convolution27 needs backward computation.
I1007 22:14:29.315603  5299 net.cpp:198] M2PELU24 needs backward computation.
I1007 22:14:29.315605  5299 net.cpp:198] Scale26 needs backward computation.
I1007 22:14:29.315608  5299 net.cpp:198] BatchNorm26 needs backward computation.
I1007 22:14:29.315609  5299 net.cpp:198] Convolution26 needs backward computation.
I1007 22:14:29.315613  5299 net.cpp:198] Eltwise11_M2PELU23_0_split needs backward computation.
I1007 22:14:29.315614  5299 net.cpp:198] M2PELU23 needs backward computation.
I1007 22:14:29.315616  5299 net.cpp:198] Eltwise11 needs backward computation.
I1007 22:14:29.315619  5299 net.cpp:198] Scale25 needs backward computation.
I1007 22:14:29.315623  5299 net.cpp:198] BatchNorm25 needs backward computation.
I1007 22:14:29.315624  5299 net.cpp:198] Convolution25 needs backward computation.
I1007 22:14:29.315626  5299 net.cpp:198] M2PELU22 needs backward computation.
I1007 22:14:29.315630  5299 net.cpp:198] Scale24 needs backward computation.
I1007 22:14:29.315632  5299 net.cpp:198] BatchNorm24 needs backward computation.
I1007 22:14:29.315634  5299 net.cpp:198] Convolution24 needs backward computation.
I1007 22:14:29.315636  5299 net.cpp:198] Scale23 needs backward computation.
I1007 22:14:29.315639  5299 net.cpp:198] BatchNorm23 needs backward computation.
I1007 22:14:29.315641  5299 net.cpp:198] Convolution23 needs backward computation.
I1007 22:14:29.315644  5299 net.cpp:198] Eltwise10_M2PELU21_0_split needs backward computation.
I1007 22:14:29.315646  5299 net.cpp:198] M2PELU21 needs backward computation.
I1007 22:14:29.315649  5299 net.cpp:198] Eltwise10 needs backward computation.
I1007 22:14:29.315651  5299 net.cpp:198] Scale22 needs backward computation.
I1007 22:14:29.315654  5299 net.cpp:198] BatchNorm22 needs backward computation.
I1007 22:14:29.315656  5299 net.cpp:198] Convolution22 needs backward computation.
I1007 22:14:29.315659  5299 net.cpp:198] M2PELU20 needs backward computation.
I1007 22:14:29.315660  5299 net.cpp:198] Scale21 needs backward computation.
I1007 22:14:29.315662  5299 net.cpp:198] BatchNorm21 needs backward computation.
I1007 22:14:29.315665  5299 net.cpp:198] Convolution21 needs backward computation.
I1007 22:14:29.315667  5299 net.cpp:198] Eltwise9_M2PELU19_0_split needs backward computation.
I1007 22:14:29.315670  5299 net.cpp:198] M2PELU19 needs backward computation.
I1007 22:14:29.315677  5299 net.cpp:198] Eltwise9 needs backward computation.
I1007 22:14:29.315680  5299 net.cpp:198] Scale20 needs backward computation.
I1007 22:14:29.315682  5299 net.cpp:198] BatchNorm20 needs backward computation.
I1007 22:14:29.315685  5299 net.cpp:198] Convolution20 needs backward computation.
I1007 22:14:29.315687  5299 net.cpp:198] M2PELU18 needs backward computation.
I1007 22:14:29.315690  5299 net.cpp:198] Scale19 needs backward computation.
I1007 22:14:29.315691  5299 net.cpp:198] BatchNorm19 needs backward computation.
I1007 22:14:29.315695  5299 net.cpp:198] Convolution19 needs backward computation.
I1007 22:14:29.315696  5299 net.cpp:198] Eltwise8_M2PELU17_0_split needs backward computation.
I1007 22:14:29.315699  5299 net.cpp:198] M2PELU17 needs backward computation.
I1007 22:14:29.315701  5299 net.cpp:198] Eltwise8 needs backward computation.
I1007 22:14:29.315704  5299 net.cpp:198] Scale18 needs backward computation.
I1007 22:14:29.315706  5299 net.cpp:198] BatchNorm18 needs backward computation.
I1007 22:14:29.315708  5299 net.cpp:198] Convolution18 needs backward computation.
I1007 22:14:29.315711  5299 net.cpp:198] M2PELU16 needs backward computation.
I1007 22:14:29.315713  5299 net.cpp:198] Scale17 needs backward computation.
I1007 22:14:29.315716  5299 net.cpp:198] BatchNorm17 needs backward computation.
I1007 22:14:29.315717  5299 net.cpp:198] Convolution17 needs backward computation.
I1007 22:14:29.315721  5299 net.cpp:198] Eltwise7_M2PELU15_0_split needs backward computation.
I1007 22:14:29.315722  5299 net.cpp:198] M2PELU15 needs backward computation.
I1007 22:14:29.315726  5299 net.cpp:198] Eltwise7 needs backward computation.
I1007 22:14:29.315727  5299 net.cpp:198] Scale16 needs backward computation.
I1007 22:14:29.315729  5299 net.cpp:198] BatchNorm16 needs backward computation.
I1007 22:14:29.315732  5299 net.cpp:198] Convolution16 needs backward computation.
I1007 22:14:29.315734  5299 net.cpp:198] M2PELU14 needs backward computation.
I1007 22:14:29.315737  5299 net.cpp:198] Scale15 needs backward computation.
I1007 22:14:29.315739  5299 net.cpp:198] BatchNorm15 needs backward computation.
I1007 22:14:29.315742  5299 net.cpp:198] Convolution15 needs backward computation.
I1007 22:14:29.315743  5299 net.cpp:198] Eltwise6_M2PELU13_0_split needs backward computation.
I1007 22:14:29.315747  5299 net.cpp:198] M2PELU13 needs backward computation.
I1007 22:14:29.315748  5299 net.cpp:198] Eltwise6 needs backward computation.
I1007 22:14:29.315752  5299 net.cpp:198] Scale14 needs backward computation.
I1007 22:14:29.315753  5299 net.cpp:198] BatchNorm14 needs backward computation.
I1007 22:14:29.315755  5299 net.cpp:198] Convolution14 needs backward computation.
I1007 22:14:29.315758  5299 net.cpp:198] M2PELU12 needs backward computation.
I1007 22:14:29.315760  5299 net.cpp:198] Scale13 needs backward computation.
I1007 22:14:29.315762  5299 net.cpp:198] BatchNorm13 needs backward computation.
I1007 22:14:29.315764  5299 net.cpp:198] Convolution13 needs backward computation.
I1007 22:14:29.315768  5299 net.cpp:198] Scale12 needs backward computation.
I1007 22:14:29.315769  5299 net.cpp:198] BatchNorm12 needs backward computation.
I1007 22:14:29.315771  5299 net.cpp:198] Convolution12 needs backward computation.
I1007 22:14:29.315774  5299 net.cpp:198] Eltwise5_M2PELU11_0_split needs backward computation.
I1007 22:14:29.315776  5299 net.cpp:198] M2PELU11 needs backward computation.
I1007 22:14:29.315778  5299 net.cpp:198] Eltwise5 needs backward computation.
I1007 22:14:29.315781  5299 net.cpp:198] Scale11 needs backward computation.
I1007 22:14:29.315783  5299 net.cpp:198] BatchNorm11 needs backward computation.
I1007 22:14:29.315786  5299 net.cpp:198] Convolution11 needs backward computation.
I1007 22:14:29.315788  5299 net.cpp:198] M2PELU10 needs backward computation.
I1007 22:14:29.315790  5299 net.cpp:198] Scale10 needs backward computation.
I1007 22:14:29.315793  5299 net.cpp:198] BatchNorm10 needs backward computation.
I1007 22:14:29.315798  5299 net.cpp:198] Convolution10 needs backward computation.
I1007 22:14:29.315800  5299 net.cpp:198] Eltwise4_M2PELU9_0_split needs backward computation.
I1007 22:14:29.315804  5299 net.cpp:198] M2PELU9 needs backward computation.
I1007 22:14:29.315805  5299 net.cpp:198] Eltwise4 needs backward computation.
I1007 22:14:29.315809  5299 net.cpp:198] Scale9 needs backward computation.
I1007 22:14:29.315811  5299 net.cpp:198] BatchNorm9 needs backward computation.
I1007 22:14:29.315814  5299 net.cpp:198] Convolution9 needs backward computation.
I1007 22:14:29.315816  5299 net.cpp:198] M2PELU8 needs backward computation.
I1007 22:14:29.315819  5299 net.cpp:198] Scale8 needs backward computation.
I1007 22:14:29.315820  5299 net.cpp:198] BatchNorm8 needs backward computation.
I1007 22:14:29.315822  5299 net.cpp:198] Convolution8 needs backward computation.
I1007 22:14:29.315825  5299 net.cpp:198] Eltwise3_M2PELU7_0_split needs backward computation.
I1007 22:14:29.315829  5299 net.cpp:198] M2PELU7 needs backward computation.
I1007 22:14:29.315830  5299 net.cpp:198] Eltwise3 needs backward computation.
I1007 22:14:29.315834  5299 net.cpp:198] Scale7 needs backward computation.
I1007 22:14:29.315835  5299 net.cpp:198] BatchNorm7 needs backward computation.
I1007 22:14:29.315837  5299 net.cpp:198] Convolution7 needs backward computation.
I1007 22:14:29.315840  5299 net.cpp:198] M2PELU6 needs backward computation.
I1007 22:14:29.315842  5299 net.cpp:198] Scale6 needs backward computation.
I1007 22:14:29.315845  5299 net.cpp:198] BatchNorm6 needs backward computation.
I1007 22:14:29.315846  5299 net.cpp:198] Convolution6 needs backward computation.
I1007 22:14:29.315850  5299 net.cpp:198] Eltwise2_M2PELU5_0_split needs backward computation.
I1007 22:14:29.315851  5299 net.cpp:198] M2PELU5 needs backward computation.
I1007 22:14:29.315855  5299 net.cpp:198] Eltwise2 needs backward computation.
I1007 22:14:29.315857  5299 net.cpp:198] Scale5 needs backward computation.
I1007 22:14:29.315860  5299 net.cpp:198] BatchNorm5 needs backward computation.
I1007 22:14:29.315861  5299 net.cpp:198] Convolution5 needs backward computation.
I1007 22:14:29.315863  5299 net.cpp:198] M2PELU4 needs backward computation.
I1007 22:14:29.315866  5299 net.cpp:198] Scale4 needs backward computation.
I1007 22:14:29.315868  5299 net.cpp:198] BatchNorm4 needs backward computation.
I1007 22:14:29.315871  5299 net.cpp:198] Convolution4 needs backward computation.
I1007 22:14:29.315873  5299 net.cpp:198] Eltwise1_M2PELU3_0_split needs backward computation.
I1007 22:14:29.315876  5299 net.cpp:198] M2PELU3 needs backward computation.
I1007 22:14:29.315878  5299 net.cpp:198] Eltwise1 needs backward computation.
I1007 22:14:29.315881  5299 net.cpp:198] Scale3 needs backward computation.
I1007 22:14:29.315883  5299 net.cpp:198] BatchNorm3 needs backward computation.
I1007 22:14:29.315886  5299 net.cpp:198] Convolution3 needs backward computation.
I1007 22:14:29.315889  5299 net.cpp:198] M2PELU2 needs backward computation.
I1007 22:14:29.315891  5299 net.cpp:198] Scale2 needs backward computation.
I1007 22:14:29.315893  5299 net.cpp:198] BatchNorm2 needs backward computation.
I1007 22:14:29.315896  5299 net.cpp:198] Convolution2 needs backward computation.
I1007 22:14:29.315898  5299 net.cpp:198] Convolution1_M2PELU1_0_split needs backward computation.
I1007 22:14:29.315901  5299 net.cpp:198] M2PELU1 needs backward computation.
I1007 22:14:29.315903  5299 net.cpp:198] Scale1 needs backward computation.
I1007 22:14:29.315906  5299 net.cpp:198] BatchNorm1 needs backward computation.
I1007 22:14:29.315907  5299 net.cpp:198] Convolution1 needs backward computation.
I1007 22:14:29.315910  5299 net.cpp:200] Data2_Data1_1_split does not need backward computation.
I1007 22:14:29.315913  5299 net.cpp:200] Data1 does not need backward computation.
I1007 22:14:29.315915  5299 net.cpp:242] This network produces output Accuracy1
I1007 22:14:29.315918  5299 net.cpp:242] This network produces output SoftmaxWithLoss1
I1007 22:14:29.315973  5299 net.cpp:255] Network initialization done.
I1007 22:14:29.316380  5299 solver.cpp:56] Solver scaffolding done.
I1007 22:14:29.324715  5299 caffe.cpp:248] Starting Optimization
I1007 22:14:29.324724  5299 solver.cpp:272] Solving resnet_cifar10
I1007 22:14:29.324728  5299 solver.cpp:273] Learning Rate Policy: multistep
I1007 22:14:29.328421  5299 solver.cpp:330] Iteration 0, Testing net (#0)
I1007 22:14:33.326129  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1007 22:14:33.484119  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.1
I1007 22:14:33.484148  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 87.3365 (* 1 = 87.3365 loss)
I1007 22:14:33.879967  5299 solver.cpp:218] Iteration 0 (-6.89641e-33 iter/s, 4.55376s/100 iters), loss = 2.29678
I1007 22:14:33.879997  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 2.29678 (* 1 = 2.29678 loss)
I1007 22:14:33.880022  5299 sgd_solver.cpp:105] Iteration 0, lr = 0.1
I1007 22:14:50.639895  5299 solver.cpp:218] Iteration 100 (5.96669 iter/s, 16.7597s/100 iters), loss = 1.64632
I1007 22:14:50.639926  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.64632 (* 1 = 1.64632 loss)
I1007 22:14:50.639932  5299 sgd_solver.cpp:105] Iteration 100, lr = 0.1
I1007 22:15:07.135087  5299 solver.cpp:218] Iteration 200 (6.06245 iter/s, 16.495s/100 iters), loss = 1.59328
I1007 22:15:07.135195  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.59328 (* 1 = 1.59328 loss)
I1007 22:15:07.135205  5299 sgd_solver.cpp:105] Iteration 200, lr = 0.1
I1007 22:15:23.920990  5299 solver.cpp:218] Iteration 300 (5.95748 iter/s, 16.7856s/100 iters), loss = 1.27087
I1007 22:15:23.921030  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.27087 (* 1 = 1.27087 loss)
I1007 22:15:23.921037  5299 sgd_solver.cpp:105] Iteration 300, lr = 0.1
I1007 22:15:40.694376  5299 solver.cpp:218] Iteration 400 (5.96191 iter/s, 16.7732s/100 iters), loss = 1.05138
I1007 22:15:40.694502  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.05138 (* 1 = 1.05138 loss)
I1007 22:15:40.694520  5299 sgd_solver.cpp:105] Iteration 400, lr = 0.1
I1007 22:15:56.342222  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1007 22:15:56.999996  5299 solver.cpp:330] Iteration 500, Testing net (#0)
I1007 22:16:00.516425  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1007 22:16:00.651365  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.3186
I1007 22:16:00.651401  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 2.81135 (* 1 = 2.81135 loss)
I1007 22:16:00.812482  5299 solver.cpp:218] Iteration 500 (4.97073 iter/s, 20.1178s/100 iters), loss = 1.27626
I1007 22:16:00.812523  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.27626 (* 1 = 1.27626 loss)
I1007 22:16:00.812530  5299 sgd_solver.cpp:105] Iteration 500, lr = 0.1
I1007 22:16:17.349395  5299 solver.cpp:218] Iteration 600 (6.04716 iter/s, 16.5367s/100 iters), loss = 1.09814
I1007 22:16:17.349509  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.09814 (* 1 = 1.09814 loss)
I1007 22:16:17.349517  5299 sgd_solver.cpp:105] Iteration 600, lr = 0.1
I1007 22:16:33.973815  5299 solver.cpp:218] Iteration 700 (6.01535 iter/s, 16.6241s/100 iters), loss = 1.04175
I1007 22:16:33.973858  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 1.04175 (* 1 = 1.04175 loss)
I1007 22:16:33.973865  5299 sgd_solver.cpp:105] Iteration 700, lr = 0.1
I1007 22:16:50.820422  5299 solver.cpp:218] Iteration 800 (5.93599 iter/s, 16.8464s/100 iters), loss = 0.965484
I1007 22:16:50.820504  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.965484 (* 1 = 0.965484 loss)
I1007 22:16:50.820513  5299 sgd_solver.cpp:105] Iteration 800, lr = 0.1
I1007 22:17:09.815949  5299 solver.cpp:218] Iteration 900 (5.26504 iter/s, 18.9932s/100 iters), loss = 0.739424
I1007 22:17:09.815995  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.739424 (* 1 = 0.739424 loss)
I1007 22:17:09.816002  5299 sgd_solver.cpp:105] Iteration 900, lr = 0.1
I1007 22:17:33.340299  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1007 22:17:34.311352  5299 solver.cpp:330] Iteration 1000, Testing net (#0)
I1007 22:17:39.344977  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1007 22:17:39.588933  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.4939
I1007 22:17:39.588970  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.57295 (* 1 = 1.57295 loss)
I1007 22:17:39.697839  5299 solver.cpp:218] Iteration 1000 (3.34671 iter/s, 29.8801s/100 iters), loss = 0.895619
I1007 22:17:39.697891  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.895619 (* 1 = 0.895619 loss)
I1007 22:17:39.697901  5299 sgd_solver.cpp:105] Iteration 1000, lr = 0.1
I1007 22:18:04.592259  5299 solver.cpp:218] Iteration 1100 (4.01768 iter/s, 24.89s/100 iters), loss = 0.680219
I1007 22:18:04.592355  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.680219 (* 1 = 0.680219 loss)
I1007 22:18:04.592377  5299 sgd_solver.cpp:105] Iteration 1100, lr = 0.1
I1007 22:18:29.193856  5299 solver.cpp:218] Iteration 1200 (4.06483 iter/s, 24.6013s/100 iters), loss = 0.78568
I1007 22:18:29.193888  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.78568 (* 1 = 0.78568 loss)
I1007 22:18:29.193907  5299 sgd_solver.cpp:105] Iteration 1200, lr = 0.1
I1007 22:18:54.231489  5299 solver.cpp:218] Iteration 1300 (3.99402 iter/s, 25.0374s/100 iters), loss = 0.819305
I1007 22:18:54.231595  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.819305 (* 1 = 0.819305 loss)
I1007 22:18:54.231609  5299 sgd_solver.cpp:105] Iteration 1300, lr = 0.1
I1007 22:19:19.458935  5299 solver.cpp:218] Iteration 1400 (3.96397 iter/s, 25.2272s/100 iters), loss = 0.684082
I1007 22:19:19.458968  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.684082 (* 1 = 0.684082 loss)
I1007 22:19:19.458977  5299 sgd_solver.cpp:105] Iteration 1400, lr = 0.1
I1007 22:19:42.902916  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1007 22:19:43.886051  5299 solver.cpp:330] Iteration 1500, Testing net (#0)
I1007 22:19:48.915599  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1007 22:19:49.156957  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6336
I1007 22:19:49.156994  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.09374 (* 1 = 1.09374 loss)
I1007 22:19:49.319629  5299 solver.cpp:218] Iteration 1500 (3.34914 iter/s, 29.8584s/100 iters), loss = 0.700323
I1007 22:19:49.319675  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.700323 (* 1 = 0.700323 loss)
I1007 22:19:49.319684  5299 sgd_solver.cpp:105] Iteration 1500, lr = 0.1
I1007 22:20:14.000588  5299 solver.cpp:218] Iteration 1600 (4.05243 iter/s, 24.6766s/100 iters), loss = 0.572449
I1007 22:20:14.000675  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.572449 (* 1 = 0.572449 loss)
I1007 22:20:14.000687  5299 sgd_solver.cpp:105] Iteration 1600, lr = 0.1
I1007 22:20:38.610627  5299 solver.cpp:218] Iteration 1700 (4.06343 iter/s, 24.6098s/100 iters), loss = 0.609073
I1007 22:20:38.610669  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.609073 (* 1 = 0.609073 loss)
I1007 22:20:38.610676  5299 sgd_solver.cpp:105] Iteration 1700, lr = 0.1
I1007 22:21:03.749524  5299 solver.cpp:218] Iteration 1800 (3.97793 iter/s, 25.1387s/100 iters), loss = 0.655813
I1007 22:21:03.749609  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.655813 (* 1 = 0.655813 loss)
I1007 22:21:03.749619  5299 sgd_solver.cpp:105] Iteration 1800, lr = 0.1
I1007 22:21:29.006072  5299 solver.cpp:218] Iteration 1900 (3.96006 iter/s, 25.2521s/100 iters), loss = 0.639948
I1007 22:21:29.006108  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.639948 (* 1 = 0.639948 loss)
I1007 22:21:29.006127  5299 sgd_solver.cpp:105] Iteration 1900, lr = 0.1
I1007 22:21:52.424500  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1007 22:21:53.406435  5299 solver.cpp:330] Iteration 2000, Testing net (#0)
I1007 22:21:58.403889  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1007 22:21:58.553608  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6135
I1007 22:21:58.553635  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.14894 (* 1 = 1.14894 loss)
I1007 22:21:58.757961  5299 solver.cpp:218] Iteration 2000 (3.36139 iter/s, 29.7496s/100 iters), loss = 0.657992
I1007 22:21:58.758005  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.657992 (* 1 = 0.657992 loss)
I1007 22:21:58.758013  5299 sgd_solver.cpp:105] Iteration 2000, lr = 0.1
I1007 22:22:23.335341  5299 solver.cpp:218] Iteration 2100 (4.06881 iter/s, 24.5772s/100 iters), loss = 0.488285
I1007 22:22:23.335433  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.488285 (* 1 = 0.488285 loss)
I1007 22:22:23.335451  5299 sgd_solver.cpp:105] Iteration 2100, lr = 0.1
I1007 22:22:47.904064  5299 solver.cpp:218] Iteration 2200 (4.07026 iter/s, 24.5684s/100 iters), loss = 0.649902
I1007 22:22:47.904100  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.649902 (* 1 = 0.649902 loss)
I1007 22:22:47.904116  5299 sgd_solver.cpp:105] Iteration 2200, lr = 0.1
I1007 22:23:13.103425  5299 solver.cpp:218] Iteration 2300 (3.96839 iter/s, 25.1992s/100 iters), loss = 0.6635
I1007 22:23:13.103518  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.6635 (* 1 = 0.6635 loss)
I1007 22:23:13.103536  5299 sgd_solver.cpp:105] Iteration 2300, lr = 0.1
I1007 22:23:38.219454  5299 solver.cpp:218] Iteration 2400 (3.98156 iter/s, 25.1158s/100 iters), loss = 0.523344
I1007 22:23:38.219485  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.523344 (* 1 = 0.523344 loss)
I1007 22:23:38.219502  5299 sgd_solver.cpp:105] Iteration 2400, lr = 0.1
I1007 22:24:01.665326  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1007 22:24:02.646303  5299 solver.cpp:330] Iteration 2500, Testing net (#0)
I1007 22:24:07.673480  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1007 22:24:07.861048  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6944
I1007 22:24:07.861085  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.955867 (* 1 = 0.955867 loss)
I1007 22:24:08.001884  5299 solver.cpp:218] Iteration 2500 (3.35819 iter/s, 29.778s/100 iters), loss = 0.53647
I1007 22:24:08.001924  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.53647 (* 1 = 0.53647 loss)
I1007 22:24:08.001946  5299 sgd_solver.cpp:105] Iteration 2500, lr = 0.1
I1007 22:24:32.774513  5299 solver.cpp:218] Iteration 2600 (4.03675 iter/s, 24.7724s/100 iters), loss = 0.539449
I1007 22:24:32.774596  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.539449 (* 1 = 0.539449 loss)
I1007 22:24:32.774610  5299 sgd_solver.cpp:105] Iteration 2600, lr = 0.1
I1007 22:24:57.354477  5299 solver.cpp:218] Iteration 2700 (4.0684 iter/s, 24.5797s/100 iters), loss = 0.63125
I1007 22:24:57.354521  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.63125 (* 1 = 0.63125 loss)
I1007 22:24:57.354528  5299 sgd_solver.cpp:105] Iteration 2700, lr = 0.1
I1007 22:25:22.713441  5299 solver.cpp:218] Iteration 2800 (3.94341 iter/s, 25.3588s/100 iters), loss = 0.590893
I1007 22:25:22.713542  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.590893 (* 1 = 0.590893 loss)
I1007 22:25:22.713560  5299 sgd_solver.cpp:105] Iteration 2800, lr = 0.1
I1007 22:25:47.931211  5299 solver.cpp:218] Iteration 2900 (3.9655 iter/s, 25.2175s/100 iters), loss = 0.51247
I1007 22:25:47.931244  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.51247 (* 1 = 0.51247 loss)
I1007 22:25:47.931252  5299 sgd_solver.cpp:105] Iteration 2900, lr = 0.1
I1007 22:26:11.334862  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1007 22:26:12.309159  5299 solver.cpp:330] Iteration 3000, Testing net (#0)
I1007 22:26:17.382745  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1007 22:26:17.578084  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7109
I1007 22:26:17.578121  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.947373 (* 1 = 0.947373 loss)
I1007 22:26:17.819464  5299 solver.cpp:218] Iteration 3000 (3.34582 iter/s, 29.8881s/100 iters), loss = 0.502003
I1007 22:26:17.819509  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.502003 (* 1 = 0.502003 loss)
I1007 22:26:17.819515  5299 sgd_solver.cpp:105] Iteration 3000, lr = 0.1
I1007 22:26:42.436022  5299 solver.cpp:218] Iteration 3100 (4.06234 iter/s, 24.6164s/100 iters), loss = 0.399417
I1007 22:26:42.436108  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.399417 (* 1 = 0.399417 loss)
I1007 22:26:42.436125  5299 sgd_solver.cpp:105] Iteration 3100, lr = 0.1
I1007 22:27:07.039876  5299 solver.cpp:218] Iteration 3200 (4.06445 iter/s, 24.6036s/100 iters), loss = 0.58744
I1007 22:27:07.039911  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.58744 (* 1 = 0.58744 loss)
I1007 22:27:07.039916  5299 sgd_solver.cpp:105] Iteration 3200, lr = 0.1
I1007 22:27:32.266218  5299 solver.cpp:218] Iteration 3300 (3.96414 iter/s, 25.2262s/100 iters), loss = 0.480491
I1007 22:27:32.266279  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.480491 (* 1 = 0.480491 loss)
I1007 22:27:32.266286  5299 sgd_solver.cpp:105] Iteration 3300, lr = 0.1
I1007 22:27:57.535271  5299 solver.cpp:218] Iteration 3400 (3.95744 iter/s, 25.2689s/100 iters), loss = 0.481718
I1007 22:27:57.535302  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.481718 (* 1 = 0.481718 loss)
I1007 22:27:57.535310  5299 sgd_solver.cpp:105] Iteration 3400, lr = 0.1
I1007 22:28:20.960347  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1007 22:28:21.946004  5299 solver.cpp:330] Iteration 3500, Testing net (#0)
I1007 22:28:27.021451  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1007 22:28:27.217811  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6989
I1007 22:28:27.217839  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.887676 (* 1 = 0.887676 loss)
I1007 22:28:27.453800  5299 solver.cpp:218] Iteration 3500 (3.34243 iter/s, 29.9183s/100 iters), loss = 0.439222
I1007 22:28:27.453835  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.439222 (* 1 = 0.439222 loss)
I1007 22:28:27.453842  5299 sgd_solver.cpp:105] Iteration 3500, lr = 0.1
I1007 22:28:52.106362  5299 solver.cpp:218] Iteration 3600 (4.05675 iter/s, 24.6502s/100 iters), loss = 0.389689
I1007 22:28:52.106453  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.389689 (* 1 = 0.389689 loss)
I1007 22:28:52.106473  5299 sgd_solver.cpp:105] Iteration 3600, lr = 0.1
I1007 22:29:16.759279  5299 solver.cpp:218] Iteration 3700 (4.05636 iter/s, 24.6527s/100 iters), loss = 0.470631
I1007 22:29:16.759315  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.470631 (* 1 = 0.470631 loss)
I1007 22:29:16.759331  5299 sgd_solver.cpp:105] Iteration 3700, lr = 0.1
I1007 22:29:42.017587  5299 solver.cpp:218] Iteration 3800 (3.95912 iter/s, 25.2581s/100 iters), loss = 0.486144
I1007 22:29:42.017684  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.486144 (* 1 = 0.486144 loss)
I1007 22:29:42.017693  5299 sgd_solver.cpp:105] Iteration 3800, lr = 0.1
I1007 22:30:07.359019  5299 solver.cpp:218] Iteration 3900 (3.94615 iter/s, 25.3412s/100 iters), loss = 0.434021
I1007 22:30:07.359064  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.434021 (* 1 = 0.434021 loss)
I1007 22:30:07.359071  5299 sgd_solver.cpp:105] Iteration 3900, lr = 0.1
I1007 22:30:30.765938  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1007 22:30:31.749119  5299 solver.cpp:330] Iteration 4000, Testing net (#0)
I1007 22:30:36.787498  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1007 22:30:37.028739  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7175
I1007 22:30:37.028774  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.881019 (* 1 = 0.881019 loss)
I1007 22:30:37.196346  5299 solver.cpp:218] Iteration 4000 (3.35153 iter/s, 29.8372s/100 iters), loss = 0.456456
I1007 22:30:37.196388  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.456456 (* 1 = 0.456456 loss)
I1007 22:30:37.196395  5299 sgd_solver.cpp:105] Iteration 4000, lr = 0.1
I1007 22:31:01.912276  5299 solver.cpp:218] Iteration 4100 (4.04671 iter/s, 24.7114s/100 iters), loss = 0.426307
I1007 22:31:01.912386  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.426307 (* 1 = 0.426307 loss)
I1007 22:31:01.912395  5299 sgd_solver.cpp:105] Iteration 4100, lr = 0.1
I1007 22:31:26.533876  5299 solver.cpp:218] Iteration 4200 (4.06151 iter/s, 24.6214s/100 iters), loss = 0.500771
I1007 22:31:26.533910  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.500771 (* 1 = 0.500771 loss)
I1007 22:31:26.533917  5299 sgd_solver.cpp:105] Iteration 4200, lr = 0.1
I1007 22:31:51.795285  5299 solver.cpp:218] Iteration 4300 (3.95863 iter/s, 25.2612s/100 iters), loss = 0.451171
I1007 22:31:51.795353  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.451171 (* 1 = 0.451171 loss)
I1007 22:31:51.795361  5299 sgd_solver.cpp:105] Iteration 4300, lr = 0.1
I1007 22:32:17.052193  5299 solver.cpp:218] Iteration 4400 (3.95934 iter/s, 25.2567s/100 iters), loss = 0.391374
I1007 22:32:17.052235  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.391374 (* 1 = 0.391374 loss)
I1007 22:32:17.052242  5299 sgd_solver.cpp:105] Iteration 4400, lr = 0.1
I1007 22:32:40.634533  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1007 22:32:41.617924  5299 solver.cpp:330] Iteration 4500, Testing net (#0)
I1007 22:32:46.653954  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1007 22:32:46.895570  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.748
I1007 22:32:46.895596  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.746517 (* 1 = 0.746517 loss)
I1007 22:32:47.062445  5299 solver.cpp:218] Iteration 4500 (3.33221 iter/s, 30.0101s/100 iters), loss = 0.498787
I1007 22:32:47.062489  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.498787 (* 1 = 0.498787 loss)
I1007 22:32:47.062495  5299 sgd_solver.cpp:105] Iteration 4500, lr = 0.1
I1007 22:33:11.783097  5299 solver.cpp:218] Iteration 4600 (4.04591 iter/s, 24.7163s/100 iters), loss = 0.403906
I1007 22:33:11.783190  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.403906 (* 1 = 0.403906 loss)
I1007 22:33:11.783197  5299 sgd_solver.cpp:105] Iteration 4600, lr = 0.1
I1007 22:33:36.432842  5299 solver.cpp:218] Iteration 4700 (4.05688 iter/s, 24.6495s/100 iters), loss = 0.40271
I1007 22:33:36.432878  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.40271 (* 1 = 0.40271 loss)
I1007 22:33:36.432884  5299 sgd_solver.cpp:105] Iteration 4700, lr = 0.1
I1007 22:34:01.694186  5299 solver.cpp:218] Iteration 4800 (3.95864 iter/s, 25.2612s/100 iters), loss = 0.418683
I1007 22:34:01.694267  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.418683 (* 1 = 0.418683 loss)
I1007 22:34:01.694274  5299 sgd_solver.cpp:105] Iteration 4800, lr = 0.1
I1007 22:34:26.869114  5299 solver.cpp:218] Iteration 4900 (3.97224 iter/s, 25.1747s/100 iters), loss = 0.434225
I1007 22:34:26.869151  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.434225 (* 1 = 0.434225 loss)
I1007 22:34:26.869158  5299 sgd_solver.cpp:105] Iteration 4900, lr = 0.1
I1007 22:34:50.288530  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1007 22:34:51.267954  5299 solver.cpp:330] Iteration 5000, Testing net (#0)
I1007 22:34:56.293007  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1007 22:34:56.486563  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7369
I1007 22:34:56.486591  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.773337 (* 1 = 0.773337 loss)
I1007 22:34:56.621076  5299 solver.cpp:218] Iteration 5000 (3.36114 iter/s, 29.7518s/100 iters), loss = 0.263948
I1007 22:34:56.621106  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.263948 (* 1 = 0.263948 loss)
I1007 22:34:56.621114  5299 sgd_solver.cpp:105] Iteration 5000, lr = 0.1
I1007 22:35:21.442876  5299 solver.cpp:218] Iteration 5100 (4.02874 iter/s, 24.8216s/100 iters), loss = 0.361763
I1007 22:35:21.442976  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.361763 (* 1 = 0.361763 loss)
I1007 22:35:21.442986  5299 sgd_solver.cpp:105] Iteration 5100, lr = 0.1
I1007 22:35:46.106709  5299 solver.cpp:218] Iteration 5200 (4.05456 iter/s, 24.6636s/100 iters), loss = 0.375716
I1007 22:35:46.106745  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.375716 (* 1 = 0.375716 loss)
I1007 22:35:46.106751  5299 sgd_solver.cpp:105] Iteration 5200, lr = 0.1
I1007 22:36:11.432746  5299 solver.cpp:218] Iteration 5300 (3.94853 iter/s, 25.3259s/100 iters), loss = 0.404418
I1007 22:36:11.432845  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.404418 (* 1 = 0.404418 loss)
I1007 22:36:11.432853  5299 sgd_solver.cpp:105] Iteration 5300, lr = 0.1
I1007 22:36:36.600759  5299 solver.cpp:218] Iteration 5400 (3.97333 iter/s, 25.1678s/100 iters), loss = 0.299703
I1007 22:36:36.600802  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.299703 (* 1 = 0.299703 loss)
I1007 22:36:36.600810  5299 sgd_solver.cpp:105] Iteration 5400, lr = 0.1
I1007 22:37:00.016218  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1007 22:37:00.999133  5299 solver.cpp:330] Iteration 5500, Testing net (#0)
I1007 22:37:06.084715  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1007 22:37:06.284489  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7506
I1007 22:37:06.284525  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.721324 (* 1 = 0.721324 loss)
I1007 22:37:06.524914  5299 solver.cpp:218] Iteration 5500 (3.3418 iter/s, 29.924s/100 iters), loss = 0.412987
I1007 22:37:06.524956  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.412987 (* 1 = 0.412987 loss)
I1007 22:37:06.524963  5299 sgd_solver.cpp:105] Iteration 5500, lr = 0.1
I1007 22:37:31.138301  5299 solver.cpp:218] Iteration 5600 (4.06308 iter/s, 24.6119s/100 iters), loss = 0.30752
I1007 22:37:31.138404  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.30752 (* 1 = 0.30752 loss)
I1007 22:37:31.138414  5299 sgd_solver.cpp:105] Iteration 5600, lr = 0.1
I1007 22:37:55.772426  5299 solver.cpp:218] Iteration 5700 (4.05945 iter/s, 24.6339s/100 iters), loss = 0.35452
I1007 22:37:55.772464  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.35452 (* 1 = 0.35452 loss)
I1007 22:37:55.772472  5299 sgd_solver.cpp:105] Iteration 5700, lr = 0.1
I1007 22:38:21.035526  5299 solver.cpp:218] Iteration 5800 (3.95837 iter/s, 25.2629s/100 iters), loss = 0.40924
I1007 22:38:21.035619  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.40924 (* 1 = 0.40924 loss)
I1007 22:38:21.035643  5299 sgd_solver.cpp:105] Iteration 5800, lr = 0.1
I1007 22:38:46.451833  5299 solver.cpp:218] Iteration 5900 (3.93452 iter/s, 25.4161s/100 iters), loss = 0.360507
I1007 22:38:46.451865  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.360507 (* 1 = 0.360507 loss)
I1007 22:38:46.451872  5299 sgd_solver.cpp:105] Iteration 5900, lr = 0.1
I1007 22:39:09.890164  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1007 22:39:10.868754  5299 solver.cpp:330] Iteration 6000, Testing net (#0)
I1007 22:39:15.857334  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1007 22:39:16.026731  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7105
I1007 22:39:16.026757  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.826805 (* 1 = 0.826805 loss)
I1007 22:39:16.231353  5299 solver.cpp:218] Iteration 6000 (3.35803 iter/s, 29.7794s/100 iters), loss = 0.38617
I1007 22:39:16.231389  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.38617 (* 1 = 0.38617 loss)
I1007 22:39:16.231395  5299 sgd_solver.cpp:105] Iteration 6000, lr = 0.1
I1007 22:39:40.870617  5299 solver.cpp:218] Iteration 6100 (4.05859 iter/s, 24.6391s/100 iters), loss = 0.373207
I1007 22:39:40.870723  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.373207 (* 1 = 0.373207 loss)
I1007 22:39:40.870736  5299 sgd_solver.cpp:105] Iteration 6100, lr = 0.1
I1007 22:40:05.499348  5299 solver.cpp:218] Iteration 6200 (4.06034 iter/s, 24.6285s/100 iters), loss = 0.359854
I1007 22:40:05.499385  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.359854 (* 1 = 0.359854 loss)
I1007 22:40:05.499394  5299 sgd_solver.cpp:105] Iteration 6200, lr = 0.1
I1007 22:40:30.733428  5299 solver.cpp:218] Iteration 6300 (3.96292 iter/s, 25.2339s/100 iters), loss = 0.363792
I1007 22:40:30.733513  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.363792 (* 1 = 0.363792 loss)
I1007 22:40:30.733536  5299 sgd_solver.cpp:105] Iteration 6300, lr = 0.1
I1007 22:40:55.962369  5299 solver.cpp:218] Iteration 6400 (3.96373 iter/s, 25.2288s/100 iters), loss = 0.358069
I1007 22:40:55.962402  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.358069 (* 1 = 0.358069 loss)
I1007 22:40:55.962410  5299 sgd_solver.cpp:105] Iteration 6400, lr = 0.1
I1007 22:41:19.402729  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1007 22:41:20.348412  5299 solver.cpp:330] Iteration 6500, Testing net (#0)
I1007 22:41:25.382266  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1007 22:41:25.567953  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7932
I1007 22:41:25.567981  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.615145 (* 1 = 0.615145 loss)
I1007 22:41:25.711012  5299 solver.cpp:218] Iteration 6500 (3.36152 iter/s, 29.7485s/100 iters), loss = 0.385863
I1007 22:41:25.711055  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.385863 (* 1 = 0.385863 loss)
I1007 22:41:25.711062  5299 sgd_solver.cpp:105] Iteration 6500, lr = 0.1
I1007 22:41:50.485955  5299 solver.cpp:218] Iteration 6600 (4.03637 iter/s, 24.7748s/100 iters), loss = 0.402117
I1007 22:41:50.486039  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.402117 (* 1 = 0.402117 loss)
I1007 22:41:50.486047  5299 sgd_solver.cpp:105] Iteration 6600, lr = 0.1
I1007 22:42:15.104557  5299 solver.cpp:218] Iteration 6700 (4.06201 iter/s, 24.6184s/100 iters), loss = 0.350884
I1007 22:42:15.104590  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.350884 (* 1 = 0.350884 loss)
I1007 22:42:15.104598  5299 sgd_solver.cpp:105] Iteration 6700, lr = 0.1
I1007 22:42:40.324555  5299 solver.cpp:218] Iteration 6800 (3.96513 iter/s, 25.2198s/100 iters), loss = 0.350983
I1007 22:42:40.324642  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.350983 (* 1 = 0.350983 loss)
I1007 22:42:40.324651  5299 sgd_solver.cpp:105] Iteration 6800, lr = 0.1
I1007 22:43:05.628949  5299 solver.cpp:218] Iteration 6900 (3.95192 iter/s, 25.3042s/100 iters), loss = 0.419345
I1007 22:43:05.628983  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.419345 (* 1 = 0.419345 loss)
I1007 22:43:05.628988  5299 sgd_solver.cpp:105] Iteration 6900, lr = 0.1
I1007 22:43:29.019709  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1007 22:43:30.002085  5299 solver.cpp:330] Iteration 7000, Testing net (#0)
I1007 22:43:34.882403  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1007 22:43:35.124197  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7746
I1007 22:43:35.124225  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.660527 (* 1 = 0.660527 loss)
I1007 22:43:35.291028  5299 solver.cpp:218] Iteration 7000 (3.37133 iter/s, 29.6619s/100 iters), loss = 0.402786
I1007 22:43:35.291075  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.402787 (* 1 = 0.402787 loss)
I1007 22:43:35.291083  5299 sgd_solver.cpp:105] Iteration 7000, lr = 0.1
I1007 22:44:00.005661  5299 solver.cpp:218] Iteration 7100 (4.04691 iter/s, 24.7102s/100 iters), loss = 0.342745
I1007 22:44:00.005780  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.342745 (* 1 = 0.342745 loss)
I1007 22:44:00.005802  5299 sgd_solver.cpp:105] Iteration 7100, lr = 0.1
I1007 22:44:24.653055  5299 solver.cpp:218] Iteration 7200 (4.05726 iter/s, 24.6471s/100 iters), loss = 0.393166
I1007 22:44:24.653090  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.393167 (* 1 = 0.393167 loss)
I1007 22:44:24.653097  5299 sgd_solver.cpp:105] Iteration 7200, lr = 0.1
I1007 22:44:49.982408  5299 solver.cpp:218] Iteration 7300 (3.94801 iter/s, 25.3292s/100 iters), loss = 0.313274
I1007 22:44:49.982493  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.313274 (* 1 = 0.313274 loss)
I1007 22:44:49.982509  5299 sgd_solver.cpp:105] Iteration 7300, lr = 0.1
I1007 22:45:15.325153  5299 solver.cpp:218] Iteration 7400 (3.94594 iter/s, 25.3425s/100 iters), loss = 0.443404
I1007 22:45:15.325194  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.443404 (* 1 = 0.443404 loss)
I1007 22:45:15.325203  5299 sgd_solver.cpp:105] Iteration 7400, lr = 0.1
I1007 22:45:38.752244  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1007 22:45:39.731830  5299 solver.cpp:330] Iteration 7500, Testing net (#0)
I1007 22:45:44.651906  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1007 22:45:44.850908  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7798
I1007 22:45:44.850935  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.640922 (* 1 = 0.640922 loss)
I1007 22:45:45.071730  5299 solver.cpp:218] Iteration 7500 (3.36175 iter/s, 29.7464s/100 iters), loss = 0.264731
I1007 22:45:45.071768  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.264731 (* 1 = 0.264731 loss)
I1007 22:45:45.071774  5299 sgd_solver.cpp:105] Iteration 7500, lr = 0.1
I1007 22:46:09.745600  5299 solver.cpp:218] Iteration 7600 (4.0536 iter/s, 24.6694s/100 iters), loss = 0.285701
I1007 22:46:09.745679  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.285701 (* 1 = 0.285701 loss)
I1007 22:46:09.745687  5299 sgd_solver.cpp:105] Iteration 7600, lr = 0.1
I1007 22:46:34.400161  5299 solver.cpp:218] Iteration 7700 (4.05608 iter/s, 24.6543s/100 iters), loss = 0.384444
I1007 22:46:34.400205  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.384444 (* 1 = 0.384444 loss)
I1007 22:46:34.400213  5299 sgd_solver.cpp:105] Iteration 7700, lr = 0.1
I1007 22:46:59.657003  5299 solver.cpp:218] Iteration 7800 (3.95935 iter/s, 25.2567s/100 iters), loss = 0.412047
I1007 22:46:59.657097  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.412047 (* 1 = 0.412047 loss)
I1007 22:46:59.657115  5299 sgd_solver.cpp:105] Iteration 7800, lr = 0.1
I1007 22:47:24.990542  5299 solver.cpp:218] Iteration 7900 (3.94737 iter/s, 25.3333s/100 iters), loss = 0.301856
I1007 22:47:24.990577  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.301856 (* 1 = 0.301856 loss)
I1007 22:47:24.990586  5299 sgd_solver.cpp:105] Iteration 7900, lr = 0.1
I1007 22:47:48.420529  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1007 22:47:49.400992  5299 solver.cpp:330] Iteration 8000, Testing net (#0)
I1007 22:47:54.439290  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1007 22:47:54.680268  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.738
I1007 22:47:54.680294  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.773454 (* 1 = 0.773454 loss)
I1007 22:47:54.804049  5299 solver.cpp:218] Iteration 8000 (3.3542 iter/s, 29.8133s/100 iters), loss = 0.39338
I1007 22:47:54.804082  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.39338 (* 1 = 0.39338 loss)
I1007 22:47:54.804090  5299 sgd_solver.cpp:105] Iteration 8000, lr = 0.1
I1007 22:48:19.740255  5299 solver.cpp:218] Iteration 8100 (4.01026 iter/s, 24.9361s/100 iters), loss = 0.285619
I1007 22:48:19.740355  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.285619 (* 1 = 0.285619 loss)
I1007 22:48:19.740361  5299 sgd_solver.cpp:105] Iteration 8100, lr = 0.1
I1007 22:48:44.384284  5299 solver.cpp:218] Iteration 8200 (4.05782 iter/s, 24.6438s/100 iters), loss = 0.290376
I1007 22:48:44.384330  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.290377 (* 1 = 0.290377 loss)
I1007 22:48:44.384335  5299 sgd_solver.cpp:105] Iteration 8200, lr = 0.1
I1007 22:49:09.644178  5299 solver.cpp:218] Iteration 8300 (3.95887 iter/s, 25.2597s/100 iters), loss = 0.329082
I1007 22:49:09.644265  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.329082 (* 1 = 0.329082 loss)
I1007 22:49:09.644273  5299 sgd_solver.cpp:105] Iteration 8300, lr = 0.1
I1007 22:49:34.802975  5299 solver.cpp:218] Iteration 8400 (3.97479 iter/s, 25.1586s/100 iters), loss = 0.408716
I1007 22:49:34.803007  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.408716 (* 1 = 0.408716 loss)
I1007 22:49:34.803014  5299 sgd_solver.cpp:105] Iteration 8400, lr = 0.1
I1007 22:49:58.254371  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1007 22:49:59.237377  5299 solver.cpp:330] Iteration 8500, Testing net (#0)
I1007 22:50:04.222507  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1007 22:50:04.392052  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7405
I1007 22:50:04.392081  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.796147 (* 1 = 0.796147 loss)
I1007 22:50:04.596897  5299 solver.cpp:218] Iteration 8500 (3.35641 iter/s, 29.7938s/100 iters), loss = 0.228241
I1007 22:50:04.596931  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.228241 (* 1 = 0.228241 loss)
I1007 22:50:04.596938  5299 sgd_solver.cpp:105] Iteration 8500, lr = 0.1
I1007 22:50:29.256129  5299 solver.cpp:218] Iteration 8600 (4.0553 iter/s, 24.6591s/100 iters), loss = 0.364095
I1007 22:50:29.256211  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.364095 (* 1 = 0.364095 loss)
I1007 22:50:29.256219  5299 sgd_solver.cpp:105] Iteration 8600, lr = 0.1
I1007 22:50:53.913631  5299 solver.cpp:218] Iteration 8700 (4.0556 iter/s, 24.6573s/100 iters), loss = 0.431997
I1007 22:50:53.913672  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.431997 (* 1 = 0.431997 loss)
I1007 22:50:53.913678  5299 sgd_solver.cpp:105] Iteration 8700, lr = 0.1
I1007 22:51:19.248827  5299 solver.cpp:218] Iteration 8800 (3.9471 iter/s, 25.335s/100 iters), loss = 0.389451
I1007 22:51:19.248906  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.389451 (* 1 = 0.389451 loss)
I1007 22:51:19.248915  5299 sgd_solver.cpp:105] Iteration 8800, lr = 0.1
I1007 22:51:44.495625  5299 solver.cpp:218] Iteration 8900 (3.96093 iter/s, 25.2466s/100 iters), loss = 0.333519
I1007 22:51:44.495658  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.333519 (* 1 = 0.333519 loss)
I1007 22:51:44.495666  5299 sgd_solver.cpp:105] Iteration 8900, lr = 0.1
I1007 22:52:07.968188  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1007 22:52:08.924039  5299 solver.cpp:330] Iteration 9000, Testing net (#0)
I1007 22:52:13.961961  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1007 22:52:14.202778  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7644
I1007 22:52:14.202816  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.716712 (* 1 = 0.716712 loss)
I1007 22:52:14.368234  5299 solver.cpp:218] Iteration 9000 (3.34757 iter/s, 29.8725s/100 iters), loss = 0.407173
I1007 22:52:14.368268  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.407173 (* 1 = 0.407173 loss)
I1007 22:52:14.368278  5299 sgd_solver.cpp:105] Iteration 9000, lr = 0.1
I1007 22:52:39.068192  5299 solver.cpp:218] Iteration 9100 (4.0493 iter/s, 24.6956s/100 iters), loss = 0.37356
I1007 22:52:39.068277  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.37356 (* 1 = 0.37356 loss)
I1007 22:52:39.068285  5299 sgd_solver.cpp:105] Iteration 9100, lr = 0.1
I1007 22:53:03.706650  5299 solver.cpp:218] Iteration 9200 (4.05873 iter/s, 24.6382s/100 iters), loss = 0.286291
I1007 22:53:03.706681  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.286291 (* 1 = 0.286291 loss)
I1007 22:53:03.706687  5299 sgd_solver.cpp:105] Iteration 9200, lr = 0.1
I1007 22:53:28.945418  5299 solver.cpp:218] Iteration 9300 (3.96218 iter/s, 25.2386s/100 iters), loss = 0.328011
I1007 22:53:28.945526  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.328011 (* 1 = 0.328011 loss)
I1007 22:53:28.945535  5299 sgd_solver.cpp:105] Iteration 9300, lr = 0.1
I1007 22:53:54.262215  5299 solver.cpp:218] Iteration 9400 (3.94998 iter/s, 25.3166s/100 iters), loss = 0.343101
I1007 22:53:54.262260  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.343101 (* 1 = 0.343101 loss)
I1007 22:53:54.262267  5299 sgd_solver.cpp:105] Iteration 9400, lr = 0.1
I1007 22:54:17.665910  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1007 22:54:18.651103  5299 solver.cpp:330] Iteration 9500, Testing net (#0)
I1007 22:54:23.555562  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1007 22:54:23.775328  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7632
I1007 22:54:23.775358  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.691221 (* 1 = 0.691221 loss)
I1007 22:54:23.948333  5299 solver.cpp:218] Iteration 9500 (3.3686 iter/s, 29.686s/100 iters), loss = 0.284252
I1007 22:54:23.948369  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.284252 (* 1 = 0.284252 loss)
I1007 22:54:23.948375  5299 sgd_solver.cpp:105] Iteration 9500, lr = 0.1
I1007 22:54:48.633257  5299 solver.cpp:218] Iteration 9600 (4.05177 iter/s, 24.6806s/100 iters), loss = 0.281241
I1007 22:54:48.633327  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.281241 (* 1 = 0.281241 loss)
I1007 22:54:48.633335  5299 sgd_solver.cpp:105] Iteration 9600, lr = 0.1
I1007 22:55:13.265586  5299 solver.cpp:218] Iteration 9700 (4.05973 iter/s, 24.6322s/100 iters), loss = 0.360922
I1007 22:55:13.265620  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.360922 (* 1 = 0.360922 loss)
I1007 22:55:13.265627  5299 sgd_solver.cpp:105] Iteration 9700, lr = 0.1
I1007 22:55:38.494539  5299 solver.cpp:218] Iteration 9800 (3.96373 iter/s, 25.2288s/100 iters), loss = 0.278263
I1007 22:55:38.494663  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.278263 (* 1 = 0.278263 loss)
I1007 22:55:38.494688  5299 sgd_solver.cpp:105] Iteration 9800, lr = 0.1
I1007 22:56:03.735361  5299 solver.cpp:218] Iteration 9900 (3.96187 iter/s, 25.2406s/100 iters), loss = 0.367117
I1007 22:56:03.735394  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.367117 (* 1 = 0.367117 loss)
I1007 22:56:03.735400  5299 sgd_solver.cpp:105] Iteration 9900, lr = 0.1
I1007 22:56:27.164763  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1007 22:56:28.140385  5299 solver.cpp:330] Iteration 10000, Testing net (#0)
I1007 22:56:33.142413  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1007 22:56:33.301715  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7816
I1007 22:56:33.301751  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.632213 (* 1 = 0.632213 loss)
I1007 22:56:33.506525  5299 solver.cpp:218] Iteration 10000 (3.35897 iter/s, 29.771s/100 iters), loss = 0.282943
I1007 22:56:33.506559  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.282943 (* 1 = 0.282943 loss)
I1007 22:56:33.506567  5299 sgd_solver.cpp:105] Iteration 10000, lr = 0.1
I1007 22:56:58.130323  5299 solver.cpp:218] Iteration 10100 (4.06114 iter/s, 24.6236s/100 iters), loss = 0.246267
I1007 22:56:58.130385  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.246267 (* 1 = 0.246267 loss)
I1007 22:56:58.130393  5299 sgd_solver.cpp:105] Iteration 10100, lr = 0.1
I1007 22:57:22.746487  5299 solver.cpp:218] Iteration 10200 (4.0624 iter/s, 24.616s/100 iters), loss = 0.316594
I1007 22:57:22.746529  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.316594 (* 1 = 0.316594 loss)
I1007 22:57:22.746536  5299 sgd_solver.cpp:105] Iteration 10200, lr = 0.1
I1007 22:57:47.988839  5299 solver.cpp:218] Iteration 10300 (3.96162 iter/s, 25.2422s/100 iters), loss = 0.321482
I1007 22:57:47.988942  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.321482 (* 1 = 0.321482 loss)
I1007 22:57:47.988950  5299 sgd_solver.cpp:105] Iteration 10300, lr = 0.1
I1007 22:58:13.303833  5299 solver.cpp:218] Iteration 10400 (3.95027 iter/s, 25.3148s/100 iters), loss = 0.311615
I1007 22:58:13.303874  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.311615 (* 1 = 0.311615 loss)
I1007 22:58:13.303885  5299 sgd_solver.cpp:105] Iteration 10400, lr = 0.1
I1007 22:58:36.721601  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1007 22:58:37.706272  5299 solver.cpp:330] Iteration 10500, Testing net (#0)
I1007 22:58:42.741703  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1007 22:58:42.981778  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7672
I1007 22:58:42.981798  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.733151 (* 1 = 0.733151 loss)
I1007 22:58:43.093699  5299 solver.cpp:218] Iteration 10500 (3.35686 iter/s, 29.7897s/100 iters), loss = 0.32695
I1007 22:58:43.093744  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.32695 (* 1 = 0.32695 loss)
I1007 22:58:43.093752  5299 sgd_solver.cpp:105] Iteration 10500, lr = 0.1
I1007 22:59:07.856995  5299 solver.cpp:218] Iteration 10600 (4.03895 iter/s, 24.7589s/100 iters), loss = 0.243211
I1007 22:59:07.857050  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.243211 (* 1 = 0.243211 loss)
I1007 22:59:07.857058  5299 sgd_solver.cpp:105] Iteration 10600, lr = 0.1
I1007 22:59:32.500001  5299 solver.cpp:218] Iteration 10700 (4.05797 iter/s, 24.6429s/100 iters), loss = 0.328887
I1007 22:59:32.500036  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.328887 (* 1 = 0.328887 loss)
I1007 22:59:32.500041  5299 sgd_solver.cpp:105] Iteration 10700, lr = 0.1
I1007 22:59:57.843472  5299 solver.cpp:218] Iteration 10800 (3.94581 iter/s, 25.3433s/100 iters), loss = 0.278734
I1007 22:59:57.843541  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.278734 (* 1 = 0.278734 loss)
I1007 22:59:57.843549  5299 sgd_solver.cpp:105] Iteration 10800, lr = 0.1
I1007 23:00:23.135859  5299 solver.cpp:218] Iteration 10900 (3.95412 iter/s, 25.2901s/100 iters), loss = 0.318789
I1007 23:00:23.135892  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.318789 (* 1 = 0.318789 loss)
I1007 23:00:23.135898  5299 sgd_solver.cpp:105] Iteration 10900, lr = 0.1
I1007 23:00:46.555610  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:00:47.537325  5299 solver.cpp:330] Iteration 11000, Testing net (#0)
I1007 23:00:52.454684  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:00:52.658548  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8163
I1007 23:00:52.658586  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.542721 (* 1 = 0.542721 loss)
I1007 23:00:52.896790  5299 solver.cpp:218] Iteration 11000 (3.36013 iter/s, 29.7608s/100 iters), loss = 0.250701
I1007 23:00:52.896836  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.250701 (* 1 = 0.250701 loss)
I1007 23:00:52.896842  5299 sgd_solver.cpp:105] Iteration 11000, lr = 0.1
I1007 23:01:17.560134  5299 solver.cpp:218] Iteration 11100 (4.05509 iter/s, 24.6603s/100 iters), loss = 0.235425
I1007 23:01:17.560219  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.235425 (* 1 = 0.235425 loss)
I1007 23:01:17.560226  5299 sgd_solver.cpp:105] Iteration 11100, lr = 0.1
I1007 23:01:42.207720  5299 solver.cpp:218] Iteration 11200 (4.05722 iter/s, 24.6474s/100 iters), loss = 0.261565
I1007 23:01:42.207752  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.261565 (* 1 = 0.261565 loss)
I1007 23:01:42.207759  5299 sgd_solver.cpp:105] Iteration 11200, lr = 0.1
I1007 23:02:07.673336  5299 solver.cpp:218] Iteration 11300 (3.92689 iter/s, 25.4655s/100 iters), loss = 0.320922
I1007 23:02:07.673441  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.320922 (* 1 = 0.320922 loss)
I1007 23:02:07.673450  5299 sgd_solver.cpp:105] Iteration 11300, lr = 0.1
I1007 23:02:32.774065  5299 solver.cpp:218] Iteration 11400 (3.98398 iter/s, 25.1005s/100 iters), loss = 0.35112
I1007 23:02:32.774109  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.35112 (* 1 = 0.35112 loss)
I1007 23:02:32.774116  5299 sgd_solver.cpp:105] Iteration 11400, lr = 0.1
I1007 23:02:56.170625  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:02:57.152891  5299 solver.cpp:330] Iteration 11500, Testing net (#0)
I1007 23:03:02.081279  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:03:02.274307  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.754
I1007 23:03:02.274333  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.833255 (* 1 = 0.833255 loss)
I1007 23:03:02.515008  5299 solver.cpp:218] Iteration 11500 (3.36239 iter/s, 29.7408s/100 iters), loss = 0.29021
I1007 23:03:02.515045  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.29021 (* 1 = 0.29021 loss)
I1007 23:03:02.515053  5299 sgd_solver.cpp:105] Iteration 11500, lr = 0.1
I1007 23:03:27.123834  5299 solver.cpp:218] Iteration 11600 (4.06381 iter/s, 24.6074s/100 iters), loss = 0.191886
I1007 23:03:27.123970  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.191885 (* 1 = 0.191885 loss)
I1007 23:03:27.123980  5299 sgd_solver.cpp:105] Iteration 11600, lr = 0.1
I1007 23:03:51.742875  5299 solver.cpp:218] Iteration 11700 (4.06194 iter/s, 24.6188s/100 iters), loss = 0.336961
I1007 23:03:51.742921  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.336961 (* 1 = 0.336961 loss)
I1007 23:03:51.742928  5299 sgd_solver.cpp:105] Iteration 11700, lr = 0.1
I1007 23:04:17.199503  5299 solver.cpp:218] Iteration 11800 (3.92827 iter/s, 25.4565s/100 iters), loss = 0.34627
I1007 23:04:17.199578  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.34627 (* 1 = 0.34627 loss)
I1007 23:04:17.199585  5299 sgd_solver.cpp:105] Iteration 11800, lr = 0.1
I1007 23:04:42.214349  5299 solver.cpp:218] Iteration 11900 (3.99766 iter/s, 25.0146s/100 iters), loss = 0.228718
I1007 23:04:42.214380  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.228718 (* 1 = 0.228718 loss)
I1007 23:04:42.214396  5299 sgd_solver.cpp:105] Iteration 11900, lr = 0.1
I1007 23:05:05.645754  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:05:06.626819  5299 solver.cpp:330] Iteration 12000, Testing net (#0)
I1007 23:05:11.638759  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:05:11.848172  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7966
I1007 23:05:11.848201  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.599696 (* 1 = 0.599696 loss)
I1007 23:05:11.991822  5299 solver.cpp:218] Iteration 12000 (3.35826 iter/s, 29.7773s/100 iters), loss = 0.289577
I1007 23:05:11.991850  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.289577 (* 1 = 0.289577 loss)
I1007 23:05:11.991858  5299 sgd_solver.cpp:105] Iteration 12000, lr = 0.1
I1007 23:05:36.771461  5299 solver.cpp:218] Iteration 12100 (4.0356 iter/s, 24.7795s/100 iters), loss = 0.301009
I1007 23:05:36.771534  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.301009 (* 1 = 0.301009 loss)
I1007 23:05:36.771543  5299 sgd_solver.cpp:105] Iteration 12100, lr = 0.1
I1007 23:06:01.424196  5299 solver.cpp:218] Iteration 12200 (4.05638 iter/s, 24.6525s/100 iters), loss = 0.454611
I1007 23:06:01.424227  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.45461 (* 1 = 0.45461 loss)
I1007 23:06:01.424235  5299 sgd_solver.cpp:105] Iteration 12200, lr = 0.1
I1007 23:06:27.088719  5299 solver.cpp:218] Iteration 12300 (3.89653 iter/s, 25.6638s/100 iters), loss = 0.339993
I1007 23:06:27.088819  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.339993 (* 1 = 0.339993 loss)
I1007 23:06:27.088829  5299 sgd_solver.cpp:105] Iteration 12300, lr = 0.1
I1007 23:06:51.965092  5299 solver.cpp:218] Iteration 12400 (4.01991 iter/s, 24.8762s/100 iters), loss = 0.28274
I1007 23:06:51.965137  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.28274 (* 1 = 0.28274 loss)
I1007 23:06:51.965144  5299 sgd_solver.cpp:105] Iteration 12400, lr = 0.1
I1007 23:07:15.383419  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:07:16.365672  5299 solver.cpp:330] Iteration 12500, Testing net (#0)
I1007 23:07:21.401711  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:07:21.618955  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7597
I1007 23:07:21.618984  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.739921 (* 1 = 0.739921 loss)
I1007 23:07:21.731034  5299 solver.cpp:218] Iteration 12500 (3.35956 iter/s, 29.7658s/100 iters), loss = 0.31986
I1007 23:07:21.731076  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.31986 (* 1 = 0.31986 loss)
I1007 23:07:21.731083  5299 sgd_solver.cpp:105] Iteration 12500, lr = 0.1
I1007 23:07:46.536267  5299 solver.cpp:218] Iteration 12600 (4.03145 iter/s, 24.805s/100 iters), loss = 0.287069
I1007 23:07:46.536334  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.287069 (* 1 = 0.287069 loss)
I1007 23:07:46.536345  5299 sgd_solver.cpp:105] Iteration 12600, lr = 0.1
I1007 23:08:11.337635  5299 solver.cpp:218] Iteration 12700 (4.03206 iter/s, 24.8012s/100 iters), loss = 0.366604
I1007 23:08:11.337671  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.366604 (* 1 = 0.366604 loss)
I1007 23:08:11.337680  5299 sgd_solver.cpp:105] Iteration 12700, lr = 0.1
I1007 23:08:36.983359  5299 solver.cpp:218] Iteration 12800 (3.89964 iter/s, 25.6434s/100 iters), loss = 0.296032
I1007 23:08:36.983436  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.296032 (* 1 = 0.296032 loss)
I1007 23:08:36.983450  5299 sgd_solver.cpp:105] Iteration 12800, lr = 0.1
I1007 23:09:01.773226  5299 solver.cpp:218] Iteration 12900 (4.03393 iter/s, 24.7897s/100 iters), loss = 0.259083
I1007 23:09:01.773262  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.259083 (* 1 = 0.259083 loss)
I1007 23:09:01.773269  5299 sgd_solver.cpp:105] Iteration 12900, lr = 0.1
I1007 23:09:25.186275  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:09:26.160068  5299 solver.cpp:330] Iteration 13000, Testing net (#0)
I1007 23:09:31.139350  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:09:31.306277  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8036
I1007 23:09:31.306305  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.594695 (* 1 = 0.594695 loss)
I1007 23:09:31.521325  5299 solver.cpp:218] Iteration 13000 (3.36158 iter/s, 29.7479s/100 iters), loss = 0.234285
I1007 23:09:31.521361  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.234285 (* 1 = 0.234285 loss)
I1007 23:09:31.521368  5299 sgd_solver.cpp:105] Iteration 13000, lr = 0.1
I1007 23:09:56.145568  5299 solver.cpp:218] Iteration 13100 (4.06106 iter/s, 24.6241s/100 iters), loss = 0.369232
I1007 23:09:56.145659  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.369232 (* 1 = 0.369232 loss)
I1007 23:09:56.145668  5299 sgd_solver.cpp:105] Iteration 13100, lr = 0.1
I1007 23:10:21.101449  5299 solver.cpp:218] Iteration 13200 (4.00711 iter/s, 24.9557s/100 iters), loss = 0.353031
I1007 23:10:21.101481  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.353031 (* 1 = 0.353031 loss)
I1007 23:10:21.101490  5299 sgd_solver.cpp:105] Iteration 13200, lr = 0.1
I1007 23:10:46.589045  5299 solver.cpp:218] Iteration 13300 (3.92383 iter/s, 25.4853s/100 iters), loss = 0.325322
I1007 23:10:46.589138  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.325321 (* 1 = 0.325321 loss)
I1007 23:10:46.589146  5299 sgd_solver.cpp:105] Iteration 13300, lr = 0.1
I1007 23:11:11.365810  5299 solver.cpp:218] Iteration 13400 (4.03608 iter/s, 24.7765s/100 iters), loss = 0.284404
I1007 23:11:11.365845  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.284404 (* 1 = 0.284404 loss)
I1007 23:11:11.365852  5299 sgd_solver.cpp:105] Iteration 13400, lr = 0.1
I1007 23:11:34.767515  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:11:35.750609  5299 solver.cpp:330] Iteration 13500, Testing net (#0)
I1007 23:11:40.669941  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:11:40.872443  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8039
I1007 23:11:40.872472  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.594027 (* 1 = 0.594027 loss)
I1007 23:11:41.104579  5299 solver.cpp:218] Iteration 13500 (3.36263 iter/s, 29.7386s/100 iters), loss = 0.2454
I1007 23:11:41.104624  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.2454 (* 1 = 0.2454 loss)
I1007 23:11:41.104631  5299 sgd_solver.cpp:105] Iteration 13500, lr = 0.1
I1007 23:12:05.721949  5299 solver.cpp:218] Iteration 13600 (4.06289 iter/s, 24.613s/100 iters), loss = 0.237891
I1007 23:12:05.722043  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.237891 (* 1 = 0.237891 loss)
I1007 23:12:05.722051  5299 sgd_solver.cpp:105] Iteration 13600, lr = 0.1
I1007 23:12:30.693765  5299 solver.cpp:218] Iteration 13700 (4.00455 iter/s, 24.9716s/100 iters), loss = 0.265549
I1007 23:12:30.693796  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.265549 (* 1 = 0.265549 loss)
I1007 23:12:30.693804  5299 sgd_solver.cpp:105] Iteration 13700, lr = 0.1
I1007 23:12:56.083992  5299 solver.cpp:218] Iteration 13800 (3.93887 iter/s, 25.388s/100 iters), loss = 0.32865
I1007 23:12:56.084054  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.32865 (* 1 = 0.32865 loss)
I1007 23:12:56.084074  5299 sgd_solver.cpp:105] Iteration 13800, lr = 0.1
I1007 23:13:20.721781  5299 solver.cpp:218] Iteration 13900 (4.05883 iter/s, 24.6376s/100 iters), loss = 0.308161
I1007 23:13:20.721818  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.30816 (* 1 = 0.30816 loss)
I1007 23:13:20.721827  5299 sgd_solver.cpp:105] Iteration 13900, lr = 0.1
I1007 23:13:44.144130  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:13:45.116127  5299 solver.cpp:330] Iteration 14000, Testing net (#0)
I1007 23:13:50.157594  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:13:50.377912  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7763
I1007 23:13:50.377948  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.68213 (* 1 = 0.68213 loss)
I1007 23:13:50.485626  5299 solver.cpp:218] Iteration 14000 (3.3598 iter/s, 29.7637s/100 iters), loss = 0.243406
I1007 23:13:50.485654  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.243405 (* 1 = 0.243405 loss)
I1007 23:13:50.485671  5299 sgd_solver.cpp:105] Iteration 14000, lr = 0.1
I1007 23:14:15.295383  5299 solver.cpp:218] Iteration 14100 (4.0307 iter/s, 24.8096s/100 iters), loss = 0.331467
I1007 23:14:15.295478  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.331467 (* 1 = 0.331467 loss)
I1007 23:14:15.295496  5299 sgd_solver.cpp:105] Iteration 14100, lr = 0.1
I1007 23:14:40.430224  5299 solver.cpp:218] Iteration 14200 (3.97858 iter/s, 25.1346s/100 iters), loss = 0.299316
I1007 23:14:40.430260  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.299315 (* 1 = 0.299315 loss)
I1007 23:14:40.430269  5299 sgd_solver.cpp:105] Iteration 14200, lr = 0.1
I1007 23:15:05.850911  5299 solver.cpp:218] Iteration 14300 (3.93416 iter/s, 25.4184s/100 iters), loss = 0.248393
I1007 23:15:05.850986  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.248393 (* 1 = 0.248393 loss)
I1007 23:15:05.850994  5299 sgd_solver.cpp:105] Iteration 14300, lr = 0.1
I1007 23:15:30.583256  5299 solver.cpp:218] Iteration 14400 (4.04401 iter/s, 24.7279s/100 iters), loss = 0.300841
I1007 23:15:30.583290  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.300841 (* 1 = 0.300841 loss)
I1007 23:15:30.583297  5299 sgd_solver.cpp:105] Iteration 14400, lr = 0.1
I1007 23:15:54.007138  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:15:54.992524  5299 solver.cpp:330] Iteration 14500, Testing net (#0)
I1007 23:16:00.005662  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:16:00.156327  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7452
I1007 23:16:00.156364  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.818244 (* 1 = 0.818244 loss)
I1007 23:16:00.348999  5299 solver.cpp:218] Iteration 14500 (3.35958 iter/s, 29.7656s/100 iters), loss = 0.302122
I1007 23:16:00.349043  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.302122 (* 1 = 0.302122 loss)
I1007 23:16:00.349050  5299 sgd_solver.cpp:105] Iteration 14500, lr = 0.1
I1007 23:16:24.970013  5299 solver.cpp:218] Iteration 14600 (4.0616 iter/s, 24.6209s/100 iters), loss = 0.25245
I1007 23:16:24.970125  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.25245 (* 1 = 0.25245 loss)
I1007 23:16:24.970134  5299 sgd_solver.cpp:105] Iteration 14600, lr = 0.1
I1007 23:16:50.142798  5299 solver.cpp:218] Iteration 14700 (3.97258 iter/s, 25.1726s/100 iters), loss = 0.385357
I1007 23:16:50.142830  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.385357 (* 1 = 0.385357 loss)
I1007 23:16:50.142838  5299 sgd_solver.cpp:105] Iteration 14700, lr = 0.1
I1007 23:17:15.452639  5299 solver.cpp:218] Iteration 14800 (3.95106 iter/s, 25.3097s/100 iters), loss = 0.291403
I1007 23:17:15.452713  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.291403 (* 1 = 0.291403 loss)
I1007 23:17:15.452719  5299 sgd_solver.cpp:105] Iteration 14800, lr = 0.1
I1007 23:17:40.105803  5299 solver.cpp:218] Iteration 14900 (4.0563 iter/s, 24.653s/100 iters), loss = 0.254376
I1007 23:17:40.105847  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.254375 (* 1 = 0.254375 loss)
I1007 23:17:40.105854  5299 sgd_solver.cpp:105] Iteration 14900, lr = 0.1
I1007 23:18:03.539762  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:18:04.524819  5299 solver.cpp:330] Iteration 15000, Testing net (#0)
I1007 23:18:09.556965  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:18:09.701061  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7839
I1007 23:18:09.701092  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.672485 (* 1 = 0.672485 loss)
I1007 23:18:09.889410  5299 solver.cpp:218] Iteration 15000 (3.35757 iter/s, 29.7834s/100 iters), loss = 0.231769
I1007 23:18:09.889446  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.231769 (* 1 = 0.231769 loss)
I1007 23:18:09.889453  5299 sgd_solver.cpp:105] Iteration 15000, lr = 0.1
I1007 23:18:34.507169  5299 solver.cpp:218] Iteration 15100 (4.06213 iter/s, 24.6176s/100 iters), loss = 0.239531
I1007 23:18:34.507247  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.23953 (* 1 = 0.23953 loss)
I1007 23:18:34.507256  5299 sgd_solver.cpp:105] Iteration 15100, lr = 0.1
I1007 23:18:59.777850  5299 solver.cpp:218] Iteration 15200 (3.95719 iter/s, 25.2705s/100 iters), loss = 0.281357
I1007 23:18:59.777884  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.281356 (* 1 = 0.281356 loss)
I1007 23:18:59.777890  5299 sgd_solver.cpp:105] Iteration 15200, lr = 0.1
I1007 23:19:24.859479  5299 solver.cpp:218] Iteration 15300 (3.98701 iter/s, 25.0815s/100 iters), loss = 0.299729
I1007 23:19:24.859556  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.299729 (* 1 = 0.299729 loss)
I1007 23:19:24.859565  5299 sgd_solver.cpp:105] Iteration 15300, lr = 0.1
I1007 23:19:49.646309  5299 solver.cpp:218] Iteration 15400 (4.03444 iter/s, 24.7866s/100 iters), loss = 0.246588
I1007 23:19:49.646345  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.246588 (* 1 = 0.246588 loss)
I1007 23:19:49.646353  5299 sgd_solver.cpp:105] Iteration 15400, lr = 0.1
I1007 23:20:13.040988  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:20:14.021819  5299 solver.cpp:330] Iteration 15500, Testing net (#0)
I1007 23:20:19.061570  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:20:19.303314  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7946
I1007 23:20:19.303359  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.615014 (* 1 = 0.615014 loss)
I1007 23:20:19.419842  5299 solver.cpp:218] Iteration 15500 (3.35871 iter/s, 29.7734s/100 iters), loss = 0.351495
I1007 23:20:19.419894  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.351494 (* 1 = 0.351494 loss)
I1007 23:20:19.419914  5299 sgd_solver.cpp:105] Iteration 15500, lr = 0.1
I1007 23:20:44.199826  5299 solver.cpp:218] Iteration 15600 (4.03623 iter/s, 24.7756s/100 iters), loss = 0.249871
I1007 23:20:44.199908  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.24987 (* 1 = 0.24987 loss)
I1007 23:20:44.199915  5299 sgd_solver.cpp:105] Iteration 15600, lr = 0.1
I1007 23:21:09.404163  5299 solver.cpp:218] Iteration 15700 (3.96761 iter/s, 25.2041s/100 iters), loss = 0.274985
I1007 23:21:09.404206  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.274984 (* 1 = 0.274984 loss)
I1007 23:21:09.404212  5299 sgd_solver.cpp:105] Iteration 15700, lr = 0.1
I1007 23:21:34.891753  5299 solver.cpp:218] Iteration 15800 (3.92383 iter/s, 25.4853s/100 iters), loss = 0.177582
I1007 23:21:34.891836  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.177581 (* 1 = 0.177581 loss)
I1007 23:21:34.891845  5299 sgd_solver.cpp:105] Iteration 15800, lr = 0.1
I1007 23:21:59.529919  5299 solver.cpp:218] Iteration 15900 (4.05878 iter/s, 24.6379s/100 iters), loss = 0.225704
I1007 23:21:59.529952  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.225704 (* 1 = 0.225704 loss)
I1007 23:21:59.529958  5299 sgd_solver.cpp:105] Iteration 15900, lr = 0.1
I1007 23:22:22.989351  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:22:23.952931  5299 solver.cpp:330] Iteration 16000, Testing net (#0)
I1007 23:22:28.951149  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:22:29.113212  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8117
I1007 23:22:29.113239  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.570494 (* 1 = 0.570494 loss)
I1007 23:22:29.317406  5299 solver.cpp:218] Iteration 16000 (3.35713 iter/s, 29.7873s/100 iters), loss = 0.229876
I1007 23:22:29.317441  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.229876 (* 1 = 0.229876 loss)
I1007 23:22:29.317448  5299 sgd_solver.cpp:105] Iteration 16000, lr = 0.1
I1007 23:22:53.951092  5299 solver.cpp:218] Iteration 16100 (4.05951 iter/s, 24.6335s/100 iters), loss = 0.278708
I1007 23:22:53.951179  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.278708 (* 1 = 0.278708 loss)
I1007 23:22:53.951187  5299 sgd_solver.cpp:105] Iteration 16100, lr = 0.1
I1007 23:23:19.195516  5299 solver.cpp:218] Iteration 16200 (3.96131 iter/s, 25.2442s/100 iters), loss = 0.307959
I1007 23:23:19.195550  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.307959 (* 1 = 0.307959 loss)
I1007 23:23:19.195557  5299 sgd_solver.cpp:105] Iteration 16200, lr = 0.1
I1007 23:23:44.565918  5299 solver.cpp:218] Iteration 16300 (3.94162 iter/s, 25.3703s/100 iters), loss = 0.299254
I1007 23:23:44.565987  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.299254 (* 1 = 0.299254 loss)
I1007 23:23:44.565999  5299 sgd_solver.cpp:105] Iteration 16300, lr = 0.1
I1007 23:24:09.300665  5299 solver.cpp:218] Iteration 16400 (4.04362 iter/s, 24.7303s/100 iters), loss = 0.212651
I1007 23:24:09.300700  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.212651 (* 1 = 0.212651 loss)
I1007 23:24:09.300707  5299 sgd_solver.cpp:105] Iteration 16400, lr = 0.1
I1007 23:24:32.698776  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:24:33.682044  5299 solver.cpp:330] Iteration 16500, Testing net (#0)
I1007 23:24:38.669499  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:24:38.815994  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8321
I1007 23:24:38.816022  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.499294 (* 1 = 0.499294 loss)
I1007 23:24:39.042352  5299 solver.cpp:218] Iteration 16500 (3.3623 iter/s, 29.7415s/100 iters), loss = 0.241755
I1007 23:24:39.042387  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.241755 (* 1 = 0.241755 loss)
I1007 23:24:39.042394  5299 sgd_solver.cpp:105] Iteration 16500, lr = 0.1
I1007 23:25:03.664002  5299 solver.cpp:218] Iteration 16600 (4.06149 iter/s, 24.6215s/100 iters), loss = 0.304749
I1007 23:25:03.664083  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.304749 (* 1 = 0.304749 loss)
I1007 23:25:03.664090  5299 sgd_solver.cpp:105] Iteration 16600, lr = 0.1
I1007 23:25:28.999955  5299 solver.cpp:218] Iteration 16700 (3.947 iter/s, 25.3357s/100 iters), loss = 0.330635
I1007 23:25:28.999987  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.330635 (* 1 = 0.330635 loss)
I1007 23:25:28.999994  5299 sgd_solver.cpp:105] Iteration 16700, lr = 0.1
I1007 23:25:54.315728  5299 solver.cpp:218] Iteration 16800 (3.95013 iter/s, 25.3156s/100 iters), loss = 0.228899
I1007 23:25:54.315841  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.228899 (* 1 = 0.228899 loss)
I1007 23:25:54.315851  5299 sgd_solver.cpp:105] Iteration 16800, lr = 0.1
I1007 23:26:18.959111  5299 solver.cpp:218] Iteration 16900 (4.05826 iter/s, 24.6411s/100 iters), loss = 0.232002
I1007 23:26:18.959146  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.232002 (* 1 = 0.232002 loss)
I1007 23:26:18.959153  5299 sgd_solver.cpp:105] Iteration 16900, lr = 0.1
I1007 23:26:42.365171  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:26:43.349194  5299 solver.cpp:330] Iteration 17000, Testing net (#0)
I1007 23:26:48.230461  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:26:48.469544  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7551
I1007 23:26:48.469570  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.811457 (* 1 = 0.811457 loss)
I1007 23:26:48.630218  5299 solver.cpp:218] Iteration 17000 (3.3703 iter/s, 29.671s/100 iters), loss = 0.204943
I1007 23:26:48.630260  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.204943 (* 1 = 0.204943 loss)
I1007 23:26:48.630267  5299 sgd_solver.cpp:105] Iteration 17000, lr = 0.1
I1007 23:27:13.342201  5299 solver.cpp:218] Iteration 17100 (4.04734 iter/s, 24.7076s/100 iters), loss = 0.338134
I1007 23:27:13.342267  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.338134 (* 1 = 0.338134 loss)
I1007 23:27:13.342275  5299 sgd_solver.cpp:105] Iteration 17100, lr = 0.1
I1007 23:27:38.663053  5299 solver.cpp:218] Iteration 17200 (3.94934 iter/s, 25.3207s/100 iters), loss = 0.307725
I1007 23:27:38.663087  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.307725 (* 1 = 0.307725 loss)
I1007 23:27:38.663094  5299 sgd_solver.cpp:105] Iteration 17200, lr = 0.1
I1007 23:28:03.914036  5299 solver.cpp:218] Iteration 17300 (3.96026 iter/s, 25.2508s/100 iters), loss = 0.242705
I1007 23:28:03.914129  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.242705 (* 1 = 0.242705 loss)
I1007 23:28:03.914137  5299 sgd_solver.cpp:105] Iteration 17300, lr = 0.1
I1007 23:28:28.536399  5299 solver.cpp:218] Iteration 17400 (4.06139 iter/s, 24.6221s/100 iters), loss = 0.248474
I1007 23:28:28.536433  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.248474 (* 1 = 0.248474 loss)
I1007 23:28:28.536439  5299 sgd_solver.cpp:105] Iteration 17400, lr = 0.1
I1007 23:28:51.942590  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:28:52.923924  5299 solver.cpp:330] Iteration 17500, Testing net (#0)
I1007 23:28:57.920418  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:28:58.085307  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.81
I1007 23:28:58.085343  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.593814 (* 1 = 0.593814 loss)
I1007 23:28:58.290277  5299 solver.cpp:218] Iteration 17500 (3.36092 iter/s, 29.7537s/100 iters), loss = 0.275737
I1007 23:28:58.290320  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.275737 (* 1 = 0.275737 loss)
I1007 23:28:58.290329  5299 sgd_solver.cpp:105] Iteration 17500, lr = 0.1
I1007 23:29:22.924052  5299 solver.cpp:218] Iteration 17600 (4.05949 iter/s, 24.6336s/100 iters), loss = 0.286112
I1007 23:29:22.924127  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.286112 (* 1 = 0.286112 loss)
I1007 23:29:22.924135  5299 sgd_solver.cpp:105] Iteration 17600, lr = 0.1
I1007 23:29:48.255697  5299 solver.cpp:218] Iteration 17700 (3.94766 iter/s, 25.3315s/100 iters), loss = 0.241633
I1007 23:29:48.255734  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.241633 (* 1 = 0.241633 loss)
I1007 23:29:48.255754  5299 sgd_solver.cpp:105] Iteration 17700, lr = 0.1
I1007 23:30:13.525365  5299 solver.cpp:218] Iteration 17800 (3.95734 iter/s, 25.2695s/100 iters), loss = 0.314191
I1007 23:30:13.525454  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.314191 (* 1 = 0.314191 loss)
I1007 23:30:13.525476  5299 sgd_solver.cpp:105] Iteration 17800, lr = 0.1
I1007 23:30:38.176107  5299 solver.cpp:218] Iteration 17900 (4.05671 iter/s, 24.6505s/100 iters), loss = 0.236095
I1007 23:30:38.176143  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.236095 (* 1 = 0.236095 loss)
I1007 23:30:38.176153  5299 sgd_solver.cpp:105] Iteration 17900, lr = 0.1
I1007 23:31:01.604161  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:31:02.582185  5299 solver.cpp:330] Iteration 18000, Testing net (#0)
I1007 23:31:07.615723  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:31:07.762526  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7829
I1007 23:31:07.762557  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.737979 (* 1 = 0.737979 loss)
I1007 23:31:07.944524  5299 solver.cpp:218] Iteration 18000 (3.35928 iter/s, 29.7683s/100 iters), loss = 0.217351
I1007 23:31:07.944556  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.217351 (* 1 = 0.217351 loss)
I1007 23:31:07.944563  5299 sgd_solver.cpp:105] Iteration 18000, lr = 0.1
I1007 23:31:32.604092  5299 solver.cpp:218] Iteration 18100 (4.05525 iter/s, 24.6594s/100 iters), loss = 0.280642
I1007 23:31:32.604193  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.280641 (* 1 = 0.280641 loss)
I1007 23:31:32.604202  5299 sgd_solver.cpp:105] Iteration 18100, lr = 0.1
I1007 23:31:57.835815  5299 solver.cpp:218] Iteration 18200 (3.9633 iter/s, 25.2315s/100 iters), loss = 0.343272
I1007 23:31:57.835850  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.343272 (* 1 = 0.343272 loss)
I1007 23:31:57.835856  5299 sgd_solver.cpp:105] Iteration 18200, lr = 0.1
I1007 23:32:23.020877  5299 solver.cpp:218] Iteration 18300 (3.97063 iter/s, 25.1849s/100 iters), loss = 0.255822
I1007 23:32:23.020979  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.255822 (* 1 = 0.255822 loss)
I1007 23:32:23.020987  5299 sgd_solver.cpp:105] Iteration 18300, lr = 0.1
I1007 23:32:47.821745  5299 solver.cpp:218] Iteration 18400 (4.03215 iter/s, 24.8006s/100 iters), loss = 0.282185
I1007 23:32:47.821780  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.282185 (* 1 = 0.282185 loss)
I1007 23:32:47.821787  5299 sgd_solver.cpp:105] Iteration 18400, lr = 0.1
I1007 23:33:11.248466  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:33:12.233027  5299 solver.cpp:330] Iteration 18500, Testing net (#0)
I1007 23:33:17.196758  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:33:17.369463  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7681
I1007 23:33:17.369494  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.735844 (* 1 = 0.735844 loss)
I1007 23:33:17.596288  5299 solver.cpp:218] Iteration 18500 (3.35859 iter/s, 29.7744s/100 iters), loss = 0.166235
I1007 23:33:17.596323  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.166235 (* 1 = 0.166235 loss)
I1007 23:33:17.596329  5299 sgd_solver.cpp:105] Iteration 18500, lr = 0.1
I1007 23:33:42.256160  5299 solver.cpp:218] Iteration 18600 (4.0552 iter/s, 24.6597s/100 iters), loss = 0.281828
I1007 23:33:42.256255  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.281828 (* 1 = 0.281828 loss)
I1007 23:33:42.256274  5299 sgd_solver.cpp:105] Iteration 18600, lr = 0.1
I1007 23:34:07.534960  5299 solver.cpp:218] Iteration 18700 (3.95592 iter/s, 25.2786s/100 iters), loss = 0.338779
I1007 23:34:07.534993  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.338778 (* 1 = 0.338778 loss)
I1007 23:34:07.535001  5299 sgd_solver.cpp:105] Iteration 18700, lr = 0.1
I1007 23:34:32.875461  5299 solver.cpp:218] Iteration 18800 (3.94627 iter/s, 25.3404s/100 iters), loss = 0.185351
I1007 23:34:32.875530  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.185351 (* 1 = 0.185351 loss)
I1007 23:34:32.875538  5299 sgd_solver.cpp:105] Iteration 18800, lr = 0.1
I1007 23:34:57.528308  5299 solver.cpp:218] Iteration 18900 (4.05635 iter/s, 24.6527s/100 iters), loss = 0.201641
I1007 23:34:57.528342  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.201641 (* 1 = 0.201641 loss)
I1007 23:34:57.528352  5299 sgd_solver.cpp:105] Iteration 18900, lr = 0.1
I1007 23:35:20.957636  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:35:21.944339  5299 solver.cpp:330] Iteration 19000, Testing net (#0)
I1007 23:35:26.952627  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:35:27.108340  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8118
I1007 23:35:27.108378  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.56348 (* 1 = 0.56348 loss)
I1007 23:35:27.306210  5299 solver.cpp:218] Iteration 19000 (3.35821 iter/s, 29.7777s/100 iters), loss = 0.232194
I1007 23:35:27.306255  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.232194 (* 1 = 0.232194 loss)
I1007 23:35:27.306262  5299 sgd_solver.cpp:105] Iteration 19000, lr = 0.1
I1007 23:35:51.938400  5299 solver.cpp:218] Iteration 19100 (4.05975 iter/s, 24.632s/100 iters), loss = 0.291594
I1007 23:35:51.938484  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.291594 (* 1 = 0.291594 loss)
I1007 23:35:51.938495  5299 sgd_solver.cpp:105] Iteration 19100, lr = 0.1
I1007 23:36:17.187188  5299 solver.cpp:218] Iteration 19200 (3.96062 iter/s, 25.2486s/100 iters), loss = 0.262719
I1007 23:36:17.187232  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.262719 (* 1 = 0.262719 loss)
I1007 23:36:17.187237  5299 sgd_solver.cpp:105] Iteration 19200, lr = 0.1
I1007 23:36:42.506435  5299 solver.cpp:218] Iteration 19300 (3.94959 iter/s, 25.3191s/100 iters), loss = 0.171981
I1007 23:36:42.506517  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.171981 (* 1 = 0.171981 loss)
I1007 23:36:42.506525  5299 sgd_solver.cpp:105] Iteration 19300, lr = 0.1
I1007 23:37:07.130266  5299 solver.cpp:218] Iteration 19400 (4.06114 iter/s, 24.6236s/100 iters), loss = 0.202267
I1007 23:37:07.130302  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.202267 (* 1 = 0.202267 loss)
I1007 23:37:07.130309  5299 sgd_solver.cpp:105] Iteration 19400, lr = 0.1
I1007 23:37:30.527770  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:37:31.509233  5299 solver.cpp:330] Iteration 19500, Testing net (#0)
I1007 23:37:36.409662  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:37:36.629114  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8096
I1007 23:37:36.629142  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.571743 (* 1 = 0.571743 loss)
I1007 23:37:36.813774  5299 solver.cpp:218] Iteration 19500 (3.36889 iter/s, 29.6833s/100 iters), loss = 0.29273
I1007 23:37:36.813810  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.29273 (* 1 = 0.29273 loss)
I1007 23:37:36.813818  5299 sgd_solver.cpp:105] Iteration 19500, lr = 0.1
I1007 23:38:01.494819  5299 solver.cpp:218] Iteration 19600 (4.05242 iter/s, 24.6766s/100 iters), loss = 0.306562
I1007 23:38:01.494923  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.306562 (* 1 = 0.306562 loss)
I1007 23:38:01.494932  5299 sgd_solver.cpp:105] Iteration 19600, lr = 0.1
I1007 23:38:26.749969  5299 solver.cpp:218] Iteration 19700 (3.95962 iter/s, 25.2549s/100 iters), loss = 0.221489
I1007 23:38:26.750011  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.221489 (* 1 = 0.221489 loss)
I1007 23:38:26.750018  5299 sgd_solver.cpp:105] Iteration 19700, lr = 0.1
I1007 23:38:52.062094  5299 solver.cpp:218] Iteration 19800 (3.9507 iter/s, 25.312s/100 iters), loss = 0.257832
I1007 23:38:52.062178  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.257831 (* 1 = 0.257831 loss)
I1007 23:38:52.062187  5299 sgd_solver.cpp:105] Iteration 19800, lr = 0.1
I1007 23:39:16.704633  5299 solver.cpp:218] Iteration 19900 (4.05806 iter/s, 24.6423s/100 iters), loss = 0.20616
I1007 23:39:16.704669  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.206159 (* 1 = 0.206159 loss)
I1007 23:39:16.704679  5299 sgd_solver.cpp:105] Iteration 19900, lr = 0.1
I1007 23:39:40.111511  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:39:41.095453  5299 solver.cpp:330] Iteration 20000, Testing net (#0)
I1007 23:39:46.084731  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:39:46.254087  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.795
I1007 23:39:46.254114  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.656204 (* 1 = 0.656204 loss)
I1007 23:39:46.458587  5299 solver.cpp:218] Iteration 20000 (3.36092 iter/s, 29.7538s/100 iters), loss = 0.280217
I1007 23:39:46.458621  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.280217 (* 1 = 0.280217 loss)
I1007 23:39:46.458628  5299 sgd_solver.cpp:105] Iteration 20000, lr = 0.1
I1007 23:40:11.127717  5299 solver.cpp:218] Iteration 20100 (4.05367 iter/s, 24.669s/100 iters), loss = 0.244298
I1007 23:40:11.127794  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.244298 (* 1 = 0.244298 loss)
I1007 23:40:11.127801  5299 sgd_solver.cpp:105] Iteration 20100, lr = 0.1
I1007 23:40:36.558696  5299 solver.cpp:218] Iteration 20200 (3.93225 iter/s, 25.4307s/100 iters), loss = 0.312689
I1007 23:40:36.558729  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.312689 (* 1 = 0.312689 loss)
I1007 23:40:36.558735  5299 sgd_solver.cpp:105] Iteration 20200, lr = 0.1
I1007 23:41:01.729884  5299 solver.cpp:218] Iteration 20300 (3.97282 iter/s, 25.171s/100 iters), loss = 0.272206
I1007 23:41:01.730005  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.272206 (* 1 = 0.272206 loss)
I1007 23:41:01.730027  5299 sgd_solver.cpp:105] Iteration 20300, lr = 0.1
I1007 23:41:26.382910  5299 solver.cpp:218] Iteration 20400 (4.05634 iter/s, 24.6528s/100 iters), loss = 0.288058
I1007 23:41:26.382943  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.288058 (* 1 = 0.288058 loss)
I1007 23:41:26.382949  5299 sgd_solver.cpp:105] Iteration 20400, lr = 0.1
I1007 23:41:49.815377  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:41:50.797164  5299 solver.cpp:330] Iteration 20500, Testing net (#0)
I1007 23:41:55.719795  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:41:55.923810  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8211
I1007 23:41:55.923837  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.547311 (* 1 = 0.547311 loss)
I1007 23:41:56.139353  5299 solver.cpp:218] Iteration 20500 (3.36063 iter/s, 29.7563s/100 iters), loss = 0.258855
I1007 23:41:56.139400  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.258855 (* 1 = 0.258855 loss)
I1007 23:41:56.139407  5299 sgd_solver.cpp:105] Iteration 20500, lr = 0.1
I1007 23:42:20.815793  5299 solver.cpp:218] Iteration 20600 (4.0532 iter/s, 24.6719s/100 iters), loss = 0.233025
I1007 23:42:20.815917  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.233025 (* 1 = 0.233025 loss)
I1007 23:42:20.815932  5299 sgd_solver.cpp:105] Iteration 20600, lr = 0.1
I1007 23:42:46.170624  5299 solver.cpp:218] Iteration 20700 (3.94406 iter/s, 25.3546s/100 iters), loss = 0.236374
I1007 23:42:46.170656  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.236374 (* 1 = 0.236374 loss)
I1007 23:42:46.170665  5299 sgd_solver.cpp:105] Iteration 20700, lr = 0.1
I1007 23:43:11.496626  5299 solver.cpp:218] Iteration 20800 (3.94854 iter/s, 25.3258s/100 iters), loss = 0.332931
I1007 23:43:11.496737  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.332931 (* 1 = 0.332931 loss)
I1007 23:43:11.496749  5299 sgd_solver.cpp:105] Iteration 20800, lr = 0.1
I1007 23:43:36.131636  5299 solver.cpp:218] Iteration 20900 (4.0593 iter/s, 24.6348s/100 iters), loss = 0.190328
I1007 23:43:36.131671  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.190328 (* 1 = 0.190328 loss)
I1007 23:43:36.131680  5299 sgd_solver.cpp:105] Iteration 20900, lr = 0.1
I1007 23:43:59.553694  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:44:00.537263  5299 solver.cpp:330] Iteration 21000, Testing net (#0)
I1007 23:44:05.565759  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:44:05.804958  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7633
I1007 23:44:05.804986  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.834758 (* 1 = 0.834758 loss)
I1007 23:44:05.974006  5299 solver.cpp:218] Iteration 21000 (3.35096 iter/s, 29.8422s/100 iters), loss = 0.307091
I1007 23:44:05.974040  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.307091 (* 1 = 0.307091 loss)
I1007 23:44:05.974046  5299 sgd_solver.cpp:105] Iteration 21000, lr = 0.1
I1007 23:44:30.689424  5299 solver.cpp:218] Iteration 21100 (4.04677 iter/s, 24.711s/100 iters), loss = 0.292568
I1007 23:44:30.689499  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.292568 (* 1 = 0.292568 loss)
I1007 23:44:30.689507  5299 sgd_solver.cpp:105] Iteration 21100, lr = 0.1
I1007 23:44:55.957804  5299 solver.cpp:218] Iteration 21200 (3.95755 iter/s, 25.2681s/100 iters), loss = 0.362655
I1007 23:44:55.957836  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.362655 (* 1 = 0.362655 loss)
I1007 23:44:55.957842  5299 sgd_solver.cpp:105] Iteration 21200, lr = 0.1
I1007 23:45:21.375000  5299 solver.cpp:218] Iteration 21300 (3.93437 iter/s, 25.4171s/100 iters), loss = 0.198917
I1007 23:45:21.375099  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.198916 (* 1 = 0.198916 loss)
I1007 23:45:21.375108  5299 sgd_solver.cpp:105] Iteration 21300, lr = 0.1
I1007 23:45:46.032368  5299 solver.cpp:218] Iteration 21400 (4.05562 iter/s, 24.6571s/100 iters), loss = 0.218797
I1007 23:45:46.032399  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.218797 (* 1 = 0.218797 loss)
I1007 23:45:46.032407  5299 sgd_solver.cpp:105] Iteration 21400, lr = 0.1
I1007 23:46:09.478477  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:46:10.450812  5299 solver.cpp:330] Iteration 21500, Testing net (#0)
I1007 23:46:15.531980  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:46:15.727555  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.808
I1007 23:46:15.727582  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.612577 (* 1 = 0.612577 loss)
I1007 23:46:15.968001  5299 solver.cpp:218] Iteration 21500 (3.34052 iter/s, 29.9355s/100 iters), loss = 0.233676
I1007 23:46:15.968035  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.233676 (* 1 = 0.233676 loss)
I1007 23:46:15.968042  5299 sgd_solver.cpp:105] Iteration 21500, lr = 0.1
I1007 23:46:40.644129  5299 solver.cpp:218] Iteration 21600 (4.05252 iter/s, 24.676s/100 iters), loss = 0.310085
I1007 23:46:40.644228  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.310085 (* 1 = 0.310085 loss)
I1007 23:46:40.644237  5299 sgd_solver.cpp:105] Iteration 21600, lr = 0.1
I1007 23:47:05.969573  5299 solver.cpp:218] Iteration 21700 (3.94863 iter/s, 25.3252s/100 iters), loss = 0.346016
I1007 23:47:05.969605  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.346016 (* 1 = 0.346016 loss)
I1007 23:47:05.969612  5299 sgd_solver.cpp:105] Iteration 21700, lr = 0.1
I1007 23:47:31.292387  5299 solver.cpp:218] Iteration 21800 (3.94903 iter/s, 25.3227s/100 iters), loss = 0.340198
I1007 23:47:31.292492  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.340198 (* 1 = 0.340198 loss)
I1007 23:47:31.292511  5299 sgd_solver.cpp:105] Iteration 21800, lr = 0.1
I1007 23:47:55.927657  5299 solver.cpp:218] Iteration 21900 (4.05926 iter/s, 24.635s/100 iters), loss = 0.322245
I1007 23:47:55.927688  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.322245 (* 1 = 0.322245 loss)
I1007 23:47:55.927695  5299 sgd_solver.cpp:105] Iteration 21900, lr = 0.1
I1007 23:48:19.344404  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:48:20.328128  5299 solver.cpp:330] Iteration 22000, Testing net (#0)
I1007 23:48:25.358664  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:48:25.600469  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7639
I1007 23:48:25.600504  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.760462 (* 1 = 0.760462 loss)
I1007 23:48:25.725551  5299 solver.cpp:218] Iteration 22000 (3.35596 iter/s, 29.7977s/100 iters), loss = 0.17847
I1007 23:48:25.725600  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.17847 (* 1 = 0.17847 loss)
I1007 23:48:25.725610  5299 sgd_solver.cpp:105] Iteration 22000, lr = 0.1
I1007 23:48:50.488639  5299 solver.cpp:218] Iteration 22100 (4.03829 iter/s, 24.7629s/100 iters), loss = 0.271699
I1007 23:48:50.488729  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.271699 (* 1 = 0.271699 loss)
I1007 23:48:50.488737  5299 sgd_solver.cpp:105] Iteration 22100, lr = 0.1
I1007 23:49:15.823549  5299 solver.cpp:218] Iteration 22200 (3.94716 iter/s, 25.3347s/100 iters), loss = 0.329866
I1007 23:49:15.823591  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.329866 (* 1 = 0.329866 loss)
I1007 23:49:15.823597  5299 sgd_solver.cpp:105] Iteration 22200, lr = 0.1
I1007 23:49:40.986500  5299 solver.cpp:218] Iteration 22300 (3.97412 iter/s, 25.1628s/100 iters), loss = 0.231604
I1007 23:49:40.986582  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.231604 (* 1 = 0.231604 loss)
I1007 23:49:40.986590  5299 sgd_solver.cpp:105] Iteration 22300, lr = 0.1
I1007 23:50:05.658432  5299 solver.cpp:218] Iteration 22400 (4.05323 iter/s, 24.6717s/100 iters), loss = 0.268398
I1007 23:50:05.658463  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.268398 (* 1 = 0.268398 loss)
I1007 23:50:05.658469  5299 sgd_solver.cpp:105] Iteration 22400, lr = 0.1
I1007 23:50:29.100317  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:50:30.085108  5299 solver.cpp:330] Iteration 22500, Testing net (#0)
I1007 23:50:35.228821  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:50:35.395535  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7589
I1007 23:50:35.395562  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.82664 (* 1 = 0.82664 loss)
I1007 23:50:35.599282  5299 solver.cpp:218] Iteration 22500 (3.33994 iter/s, 29.9407s/100 iters), loss = 0.243826
I1007 23:50:35.599316  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.243826 (* 1 = 0.243826 loss)
I1007 23:50:35.599323  5299 sgd_solver.cpp:105] Iteration 22500, lr = 0.1
I1007 23:51:00.235595  5299 solver.cpp:218] Iteration 22600 (4.05907 iter/s, 24.6362s/100 iters), loss = 0.216532
I1007 23:51:00.235710  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.216532 (* 1 = 0.216532 loss)
I1007 23:51:00.235719  5299 sgd_solver.cpp:105] Iteration 22600, lr = 0.1
I1007 23:51:25.573005  5299 solver.cpp:218] Iteration 22700 (3.94677 iter/s, 25.3372s/100 iters), loss = 0.371937
I1007 23:51:25.573046  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.371937 (* 1 = 0.371937 loss)
I1007 23:51:25.573053  5299 sgd_solver.cpp:105] Iteration 22700, lr = 0.1
I1007 23:51:50.917825  5299 solver.cpp:218] Iteration 22800 (3.9456 iter/s, 25.3447s/100 iters), loss = 0.223929
I1007 23:51:50.917914  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.223929 (* 1 = 0.223929 loss)
I1007 23:51:50.917932  5299 sgd_solver.cpp:105] Iteration 22800, lr = 0.1
I1007 23:52:15.576119  5299 solver.cpp:218] Iteration 22900 (4.05547 iter/s, 24.6581s/100 iters), loss = 0.168577
I1007 23:52:15.576162  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.168577 (* 1 = 0.168577 loss)
I1007 23:52:15.576169  5299 sgd_solver.cpp:105] Iteration 22900, lr = 0.1
I1007 23:52:38.995211  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:52:39.979862  5299 solver.cpp:330] Iteration 23000, Testing net (#0)
I1007 23:52:44.981384  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:52:45.140249  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7805
I1007 23:52:45.140275  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.694146 (* 1 = 0.694146 loss)
I1007 23:52:45.345011  5299 solver.cpp:218] Iteration 23000 (3.35923 iter/s, 29.7687s/100 iters), loss = 0.189682
I1007 23:52:45.345043  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.189682 (* 1 = 0.189682 loss)
I1007 23:52:45.345051  5299 sgd_solver.cpp:105] Iteration 23000, lr = 0.1
I1007 23:53:09.962599  5299 solver.cpp:218] Iteration 23100 (4.06216 iter/s, 24.6174s/100 iters), loss = 0.316774
I1007 23:53:09.962667  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.316774 (* 1 = 0.316774 loss)
I1007 23:53:09.962676  5299 sgd_solver.cpp:105] Iteration 23100, lr = 0.1
I1007 23:53:35.237987  5299 solver.cpp:218] Iteration 23200 (3.95644 iter/s, 25.2752s/100 iters), loss = 0.286268
I1007 23:53:35.238023  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.286268 (* 1 = 0.286268 loss)
I1007 23:53:35.238029  5299 sgd_solver.cpp:105] Iteration 23200, lr = 0.1
I1007 23:54:00.476322  5299 solver.cpp:218] Iteration 23300 (3.96225 iter/s, 25.2382s/100 iters), loss = 0.22932
I1007 23:54:00.476410  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.22932 (* 1 = 0.22932 loss)
I1007 23:54:00.476423  5299 sgd_solver.cpp:105] Iteration 23300, lr = 0.1
I1007 23:54:25.092064  5299 solver.cpp:218] Iteration 23400 (4.06248 iter/s, 24.6155s/100 iters), loss = 0.247681
I1007 23:54:25.092098  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.247681 (* 1 = 0.247681 loss)
I1007 23:54:25.092105  5299 sgd_solver.cpp:105] Iteration 23400, lr = 0.1
I1007 23:54:48.486786  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:54:49.469714  5299 solver.cpp:330] Iteration 23500, Testing net (#0)
I1007 23:54:54.513253  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:54:54.700718  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8065
I1007 23:54:54.700764  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.606975 (* 1 = 0.606975 loss)
I1007 23:54:54.840023  5299 solver.cpp:218] Iteration 23500 (3.36159 iter/s, 29.7478s/100 iters), loss = 0.154039
I1007 23:54:54.840065  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.154038 (* 1 = 0.154038 loss)
I1007 23:54:54.840072  5299 sgd_solver.cpp:105] Iteration 23500, lr = 0.1
I1007 23:55:19.590368  5299 solver.cpp:218] Iteration 23600 (4.04038 iter/s, 24.7502s/100 iters), loss = 0.204299
I1007 23:55:19.590483  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.204299 (* 1 = 0.204299 loss)
I1007 23:55:19.590492  5299 sgd_solver.cpp:105] Iteration 23600, lr = 0.1
I1007 23:55:44.748839  5299 solver.cpp:218] Iteration 23700 (3.97484 iter/s, 25.1582s/100 iters), loss = 0.251102
I1007 23:55:44.748884  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.251102 (* 1 = 0.251102 loss)
I1007 23:55:44.748891  5299 sgd_solver.cpp:105] Iteration 23700, lr = 0.1
I1007 23:56:09.725054  5299 solver.cpp:218] Iteration 23800 (4.00417 iter/s, 24.974s/100 iters), loss = 0.293896
I1007 23:56:09.725148  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.293896 (* 1 = 0.293896 loss)
I1007 23:56:09.725157  5299 sgd_solver.cpp:105] Iteration 23800, lr = 0.1
I1007 23:56:34.337363  5299 solver.cpp:218] Iteration 23900 (4.06305 iter/s, 24.6121s/100 iters), loss = 0.249177
I1007 23:56:34.337400  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.249177 (* 1 = 0.249177 loss)
I1007 23:56:34.337407  5299 sgd_solver.cpp:105] Iteration 23900, lr = 0.1
I1007 23:56:57.736232  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:56:58.720765  5299 solver.cpp:330] Iteration 24000, Testing net (#0)
I1007 23:57:03.617513  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:57:03.837736  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8245
I1007 23:57:03.837764  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.549057 (* 1 = 0.549057 loss)
I1007 23:57:04.021572  5299 solver.cpp:218] Iteration 24000 (3.36881 iter/s, 29.6841s/100 iters), loss = 0.206222
I1007 23:57:04.021605  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.206222 (* 1 = 0.206222 loss)
I1007 23:57:04.021612  5299 sgd_solver.cpp:105] Iteration 24000, lr = 0.1
I1007 23:57:28.733491  5299 solver.cpp:218] Iteration 24100 (4.04734 iter/s, 24.7076s/100 iters), loss = 0.257032
I1007 23:57:28.733570  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.257032 (* 1 = 0.257032 loss)
I1007 23:57:28.733585  5299 sgd_solver.cpp:105] Iteration 24100, lr = 0.1
I1007 23:57:54.183609  5299 solver.cpp:218] Iteration 24200 (3.92929 iter/s, 25.4499s/100 iters), loss = 0.217663
I1007 23:57:54.183642  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.217663 (* 1 = 0.217663 loss)
I1007 23:57:54.183650  5299 sgd_solver.cpp:105] Iteration 24200, lr = 0.1
I1007 23:58:19.294515  5299 solver.cpp:218] Iteration 24300 (3.9827 iter/s, 25.1086s/100 iters), loss = 0.199389
I1007 23:58:19.294600  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.199389 (* 1 = 0.199389 loss)
I1007 23:58:19.294607  5299 sgd_solver.cpp:105] Iteration 24300, lr = 0.1
I1007 23:58:43.904762  5299 solver.cpp:218] Iteration 24400 (4.06339 iter/s, 24.61s/100 iters), loss = 0.214951
I1007 23:58:43.904795  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.214951 (* 1 = 0.214951 loss)
I1007 23:58:43.904803  5299 sgd_solver.cpp:105] Iteration 24400, lr = 0.1
I1007 23:59:07.507156  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:59:08.487983  5299 solver.cpp:330] Iteration 24500, Testing net (#0)
I1007 23:59:13.523950  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1007 23:59:13.737093  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8328
I1007 23:59:13.737121  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.520318 (* 1 = 0.520318 loss)
I1007 23:59:13.882295  5299 solver.cpp:218] Iteration 24500 (3.33585 iter/s, 29.9774s/100 iters), loss = 0.216705
I1007 23:59:13.882328  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.216704 (* 1 = 0.216704 loss)
I1007 23:59:13.882335  5299 sgd_solver.cpp:105] Iteration 24500, lr = 0.1
I1007 23:59:38.625598  5299 solver.cpp:218] Iteration 24600 (4.04187 iter/s, 24.741s/100 iters), loss = 0.151265
I1007 23:59:38.625751  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.151264 (* 1 = 0.151264 loss)
I1007 23:59:38.625766  5299 sgd_solver.cpp:105] Iteration 24600, lr = 0.1
I1008 00:00:04.241194  5299 solver.cpp:218] Iteration 24700 (3.90391 iter/s, 25.6154s/100 iters), loss = 0.284308
I1008 00:00:04.241230  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.284308 (* 1 = 0.284308 loss)
I1008 00:00:04.241240  5299 sgd_solver.cpp:105] Iteration 24700, lr = 0.1
I1008 00:00:29.199167  5299 solver.cpp:218] Iteration 24800 (4.00676 iter/s, 24.9578s/100 iters), loss = 0.290211
I1008 00:00:29.199265  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.290211 (* 1 = 0.290211 loss)
I1008 00:00:29.199273  5299 sgd_solver.cpp:105] Iteration 24800, lr = 0.1
I1008 00:00:53.843808  5299 solver.cpp:218] Iteration 24900 (4.05771 iter/s, 24.6444s/100 iters), loss = 0.234027
I1008 00:00:53.843858  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.234027 (* 1 = 0.234027 loss)
I1008 00:00:53.843866  5299 sgd_solver.cpp:105] Iteration 24900, lr = 0.1
I1008 00:01:17.277026  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:01:18.250521  5299 solver.cpp:330] Iteration 25000, Testing net (#0)
I1008 00:01:23.285290  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:01:23.525969  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8411
I1008 00:01:23.525995  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.49273 (* 1 = 0.49273 loss)
I1008 00:01:23.694275  5299 solver.cpp:218] Iteration 25000 (3.35005 iter/s, 29.8503s/100 iters), loss = 0.187899
I1008 00:01:23.694313  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.187899 (* 1 = 0.187899 loss)
I1008 00:01:23.694320  5299 sgd_solver.cpp:105] Iteration 25000, lr = 0.1
I1008 00:01:48.464656  5299 solver.cpp:218] Iteration 25100 (4.03779 iter/s, 24.766s/100 iters), loss = 0.318959
I1008 00:01:48.464741  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.318958 (* 1 = 0.318958 loss)
I1008 00:01:48.464749  5299 sgd_solver.cpp:105] Iteration 25100, lr = 0.1
I1008 00:02:14.105685  5299 solver.cpp:218] Iteration 25200 (3.90003 iter/s, 25.6408s/100 iters), loss = 0.234493
I1008 00:02:14.105720  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.234493 (* 1 = 0.234493 loss)
I1008 00:02:14.105726  5299 sgd_solver.cpp:105] Iteration 25200, lr = 0.1
I1008 00:02:39.087802  5299 solver.cpp:218] Iteration 25300 (4.0029 iter/s, 24.9819s/100 iters), loss = 0.236665
I1008 00:02:39.087903  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.236665 (* 1 = 0.236665 loss)
I1008 00:02:39.087914  5299 sgd_solver.cpp:105] Iteration 25300, lr = 0.1
I1008 00:03:03.724467  5299 solver.cpp:218] Iteration 25400 (4.05903 iter/s, 24.6364s/100 iters), loss = 0.15491
I1008 00:03:03.724498  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.15491 (* 1 = 0.15491 loss)
I1008 00:03:03.724504  5299 sgd_solver.cpp:105] Iteration 25400, lr = 0.1
I1008 00:03:27.154615  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:03:28.140619  5299 solver.cpp:330] Iteration 25500, Testing net (#0)
I1008 00:03:33.021564  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:03:33.262099  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6978
I1008 00:03:33.262125  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.03814 (* 1 = 1.03814 loss)
I1008 00:03:33.423295  5299 solver.cpp:218] Iteration 25500 (3.36715 iter/s, 29.6987s/100 iters), loss = 0.239358
I1008 00:03:33.423336  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.239358 (* 1 = 0.239358 loss)
I1008 00:03:33.423344  5299 sgd_solver.cpp:105] Iteration 25500, lr = 0.1
I1008 00:03:58.321914  5299 solver.cpp:218] Iteration 25600 (4.017 iter/s, 24.8942s/100 iters), loss = 0.295648
I1008 00:03:58.322011  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.295648 (* 1 = 0.295648 loss)
I1008 00:03:58.322021  5299 sgd_solver.cpp:105] Iteration 25600, lr = 0.1
I1008 00:04:23.943045  5299 solver.cpp:218] Iteration 25700 (3.90307 iter/s, 25.6209s/100 iters), loss = 0.203996
I1008 00:04:23.943089  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.203996 (* 1 = 0.203996 loss)
I1008 00:04:23.943095  5299 sgd_solver.cpp:105] Iteration 25700, lr = 0.1
I1008 00:04:48.732945  5299 solver.cpp:218] Iteration 25800 (4.03392 iter/s, 24.7898s/100 iters), loss = 0.251293
I1008 00:04:48.733041  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.251293 (* 1 = 0.251293 loss)
I1008 00:04:48.733049  5299 sgd_solver.cpp:105] Iteration 25800, lr = 0.1
I1008 00:05:13.391130  5299 solver.cpp:218] Iteration 25900 (4.05549 iter/s, 24.658s/100 iters), loss = 0.22719
I1008 00:05:13.391177  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.22719 (* 1 = 0.22719 loss)
I1008 00:05:13.391185  5299 sgd_solver.cpp:105] Iteration 25900, lr = 0.1
I1008 00:05:36.834692  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:05:37.809733  5299 solver.cpp:330] Iteration 26000, Testing net (#0)
I1008 00:05:42.767494  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:05:42.932039  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8218
I1008 00:05:42.932068  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.562143 (* 1 = 0.562143 loss)
I1008 00:05:43.172864  5299 solver.cpp:218] Iteration 26000 (3.35778 iter/s, 29.7816s/100 iters), loss = 0.220834
I1008 00:05:43.172899  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.220834 (* 1 = 0.220834 loss)
I1008 00:05:43.172906  5299 sgd_solver.cpp:105] Iteration 26000, lr = 0.1
I1008 00:06:08.106501  5299 solver.cpp:218] Iteration 26100 (4.01067 iter/s, 24.9335s/100 iters), loss = 0.248675
I1008 00:06:08.106587  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.248675 (* 1 = 0.248675 loss)
I1008 00:06:08.106595  5299 sgd_solver.cpp:105] Iteration 26100, lr = 0.1
I1008 00:06:33.740010  5299 solver.cpp:218] Iteration 26200 (3.90131 iter/s, 25.6324s/100 iters), loss = 0.394392
I1008 00:06:33.740042  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.394392 (* 1 = 0.394392 loss)
I1008 00:06:33.740049  5299 sgd_solver.cpp:105] Iteration 26200, lr = 0.1
I1008 00:06:58.511934  5299 solver.cpp:218] Iteration 26300 (4.0372 iter/s, 24.7696s/100 iters), loss = 0.261202
I1008 00:06:58.512032  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.261202 (* 1 = 0.261202 loss)
I1008 00:06:58.512043  5299 sgd_solver.cpp:105] Iteration 26300, lr = 0.1
I1008 00:07:23.176815  5299 solver.cpp:218] Iteration 26400 (4.05438 iter/s, 24.6647s/100 iters), loss = 0.180133
I1008 00:07:23.176849  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.180133 (* 1 = 0.180133 loss)
I1008 00:07:23.176856  5299 sgd_solver.cpp:105] Iteration 26400, lr = 0.1
I1008 00:07:46.652717  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:07:47.597960  5299 solver.cpp:330] Iteration 26500, Testing net (#0)
I1008 00:07:52.492584  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:07:52.714957  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8148
I1008 00:07:52.714984  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.581055 (* 1 = 0.581055 loss)
I1008 00:07:52.894202  5299 solver.cpp:218] Iteration 26500 (3.36505 iter/s, 29.7172s/100 iters), loss = 0.278671
I1008 00:07:52.894234  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.278671 (* 1 = 0.278671 loss)
I1008 00:07:52.894245  5299 sgd_solver.cpp:105] Iteration 26500, lr = 0.1
I1008 00:08:18.222790  5299 solver.cpp:218] Iteration 26600 (3.94879 iter/s, 25.3242s/100 iters), loss = 0.203492
I1008 00:08:18.222892  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.203492 (* 1 = 0.203492 loss)
I1008 00:08:18.222906  5299 sgd_solver.cpp:105] Iteration 26600, lr = 0.1
I1008 00:08:43.732782  5299 solver.cpp:218] Iteration 26700 (3.92006 iter/s, 25.5098s/100 iters), loss = 0.336412
I1008 00:08:43.732811  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.336412 (* 1 = 0.336412 loss)
I1008 00:08:43.732818  5299 sgd_solver.cpp:105] Iteration 26700, lr = 0.1
I1008 00:09:08.384984  5299 solver.cpp:218] Iteration 26800 (4.05646 iter/s, 24.652s/100 iters), loss = 0.258037
I1008 00:09:08.385087  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.258037 (* 1 = 0.258037 loss)
I1008 00:09:08.385097  5299 sgd_solver.cpp:105] Iteration 26800, lr = 0.1
I1008 00:09:33.031209  5299 solver.cpp:218] Iteration 26900 (4.05745 iter/s, 24.646s/100 iters), loss = 0.158289
I1008 00:09:33.031250  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.158289 (* 1 = 0.158289 loss)
I1008 00:09:33.031257  5299 sgd_solver.cpp:105] Iteration 26900, lr = 0.1
I1008 00:09:56.408387  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:09:57.390388  5299 solver.cpp:330] Iteration 27000, Testing net (#0)
I1008 00:10:02.309670  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:10:02.511878  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.756
I1008 00:10:02.511915  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.811187 (* 1 = 0.811187 loss)
I1008 00:10:02.735224  5299 solver.cpp:218] Iteration 27000 (3.36657 iter/s, 29.7039s/100 iters), loss = 0.157846
I1008 00:10:02.735271  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.157846 (* 1 = 0.157846 loss)
I1008 00:10:02.735278  5299 sgd_solver.cpp:105] Iteration 27000, lr = 0.1
I1008 00:10:27.965345  5299 solver.cpp:218] Iteration 27100 (3.96421 iter/s, 25.2257s/100 iters), loss = 0.245924
I1008 00:10:27.965421  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.245924 (* 1 = 0.245924 loss)
I1008 00:10:27.965430  5299 sgd_solver.cpp:105] Iteration 27100, lr = 0.1
I1008 00:10:53.446962  5299 solver.cpp:218] Iteration 27200 (3.92474 iter/s, 25.4794s/100 iters), loss = 0.352904
I1008 00:10:53.447007  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.352904 (* 1 = 0.352904 loss)
I1008 00:10:53.447015  5299 sgd_solver.cpp:105] Iteration 27200, lr = 0.1
I1008 00:11:18.104722  5299 solver.cpp:218] Iteration 27300 (4.05554 iter/s, 24.6576s/100 iters), loss = 0.229451
I1008 00:11:18.104794  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.229451 (* 1 = 0.229451 loss)
I1008 00:11:18.104801  5299 sgd_solver.cpp:105] Iteration 27300, lr = 0.1
I1008 00:11:42.748189  5299 solver.cpp:218] Iteration 27400 (4.05789 iter/s, 24.6433s/100 iters), loss = 0.192852
I1008 00:11:42.748222  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.192852 (* 1 = 0.192852 loss)
I1008 00:11:42.748229  5299 sgd_solver.cpp:105] Iteration 27400, lr = 0.1
I1008 00:12:06.179039  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:12:07.155570  5299 solver.cpp:330] Iteration 27500, Testing net (#0)
I1008 00:12:12.033676  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:12:12.275269  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8314
I1008 00:12:12.275295  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.52575 (* 1 = 0.52575 loss)
I1008 00:12:12.445051  5299 solver.cpp:218] Iteration 27500 (3.36738 iter/s, 29.6967s/100 iters), loss = 0.159254
I1008 00:12:12.445093  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.159254 (* 1 = 0.159254 loss)
I1008 00:12:12.445101  5299 sgd_solver.cpp:105] Iteration 27500, lr = 0.1
I1008 00:12:37.762737  5299 solver.cpp:218] Iteration 27600 (3.9505 iter/s, 25.3133s/100 iters), loss = 0.256518
I1008 00:12:37.762820  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.256518 (* 1 = 0.256518 loss)
I1008 00:12:37.762828  5299 sgd_solver.cpp:105] Iteration 27600, lr = 0.1
I1008 00:13:03.015525  5299 solver.cpp:218] Iteration 27700 (3.95999 iter/s, 25.2526s/100 iters), loss = 0.201033
I1008 00:13:03.015559  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.201033 (* 1 = 0.201033 loss)
I1008 00:13:03.015566  5299 sgd_solver.cpp:105] Iteration 27700, lr = 0.1
I1008 00:13:27.632259  5299 solver.cpp:218] Iteration 27800 (4.0623 iter/s, 24.6166s/100 iters), loss = 0.280585
I1008 00:13:27.632341  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.280585 (* 1 = 0.280585 loss)
I1008 00:13:27.632349  5299 sgd_solver.cpp:105] Iteration 27800, lr = 0.1
I1008 00:13:52.258070  5299 solver.cpp:218] Iteration 27900 (4.06082 iter/s, 24.6256s/100 iters), loss = 0.175087
I1008 00:13:52.258108  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.175087 (* 1 = 0.175087 loss)
I1008 00:13:52.258116  5299 sgd_solver.cpp:105] Iteration 27900, lr = 0.1
I1008 00:14:15.647902  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:14:16.630501  5299 solver.cpp:330] Iteration 28000, Testing net (#0)
I1008 00:14:21.662756  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:14:21.886482  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8109
I1008 00:14:21.886518  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.602845 (* 1 = 0.602845 loss)
I1008 00:14:21.991493  5299 solver.cpp:218] Iteration 28000 (3.36323 iter/s, 29.7333s/100 iters), loss = 0.147035
I1008 00:14:21.991533  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.147035 (* 1 = 0.147035 loss)
I1008 00:14:21.991540  5299 sgd_solver.cpp:105] Iteration 28000, lr = 0.1
I1008 00:14:47.458439  5299 solver.cpp:218] Iteration 28100 (3.92668 iter/s, 25.4668s/100 iters), loss = 0.182751
I1008 00:14:47.458520  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.182751 (* 1 = 0.182751 loss)
I1008 00:14:47.458528  5299 sgd_solver.cpp:105] Iteration 28100, lr = 0.1
I1008 00:15:12.804205  5299 solver.cpp:218] Iteration 28200 (3.94611 iter/s, 25.3414s/100 iters), loss = 0.20963
I1008 00:15:12.804249  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.20963 (* 1 = 0.20963 loss)
I1008 00:15:12.804255  5299 sgd_solver.cpp:105] Iteration 28200, lr = 0.1
I1008 00:15:37.453927  5299 solver.cpp:218] Iteration 28300 (4.05686 iter/s, 24.6496s/100 iters), loss = 0.283913
I1008 00:15:37.454010  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.283913 (* 1 = 0.283913 loss)
I1008 00:15:37.454018  5299 sgd_solver.cpp:105] Iteration 28300, lr = 0.1
I1008 00:16:02.109416  5299 solver.cpp:218] Iteration 28400 (4.05593 iter/s, 24.6553s/100 iters), loss = 0.215027
I1008 00:16:02.109457  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.215027 (* 1 = 0.215027 loss)
I1008 00:16:02.109463  5299 sgd_solver.cpp:105] Iteration 28400, lr = 0.1
I1008 00:16:25.556948  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:16:26.530319  5299 solver.cpp:330] Iteration 28500, Testing net (#0)
I1008 00:16:31.562505  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:16:31.802892  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7801
I1008 00:16:31.802928  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.741932 (* 1 = 0.741932 loss)
I1008 00:16:31.993742  5299 solver.cpp:218] Iteration 28500 (3.34625 iter/s, 29.8842s/100 iters), loss = 0.171677
I1008 00:16:31.993784  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.171677 (* 1 = 0.171677 loss)
I1008 00:16:31.993791  5299 sgd_solver.cpp:105] Iteration 28500, lr = 0.1
I1008 00:16:57.380440  5299 solver.cpp:218] Iteration 28600 (3.93975 iter/s, 25.3823s/100 iters), loss = 0.29026
I1008 00:16:57.380534  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.29026 (* 1 = 0.29026 loss)
I1008 00:16:57.380543  5299 sgd_solver.cpp:105] Iteration 28600, lr = 0.1
I1008 00:17:22.700865  5299 solver.cpp:218] Iteration 28700 (3.94942 iter/s, 25.3202s/100 iters), loss = 0.256603
I1008 00:17:22.700901  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.256603 (* 1 = 0.256603 loss)
I1008 00:17:22.700907  5299 sgd_solver.cpp:105] Iteration 28700, lr = 0.1
I1008 00:17:47.350951  5299 solver.cpp:218] Iteration 28800 (4.05681 iter/s, 24.6499s/100 iters), loss = 0.261681
I1008 00:17:47.351050  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.261681 (* 1 = 0.261681 loss)
I1008 00:17:47.351063  5299 sgd_solver.cpp:105] Iteration 28800, lr = 0.1
I1008 00:18:11.990983  5299 solver.cpp:218] Iteration 28900 (4.05847 iter/s, 24.6398s/100 iters), loss = 0.120576
I1008 00:18:11.991019  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.120576 (* 1 = 0.120576 loss)
I1008 00:18:11.991026  5299 sgd_solver.cpp:105] Iteration 28900, lr = 0.1
I1008 00:18:35.413784  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:18:36.385247  5299 solver.cpp:330] Iteration 29000, Testing net (#0)
I1008 00:18:41.462538  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:18:41.659898  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7568
I1008 00:18:41.659931  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.765632 (* 1 = 0.765632 loss)
I1008 00:18:41.901775  5299 solver.cpp:218] Iteration 29000 (3.34329 iter/s, 29.9106s/100 iters), loss = 0.266518
I1008 00:18:41.901818  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.266518 (* 1 = 0.266518 loss)
I1008 00:18:41.901825  5299 sgd_solver.cpp:105] Iteration 29000, lr = 0.1
I1008 00:19:07.236817  5299 solver.cpp:218] Iteration 29100 (3.94713 iter/s, 25.3349s/100 iters), loss = 0.293854
I1008 00:19:07.236897  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.293854 (* 1 = 0.293854 loss)
I1008 00:19:07.236905  5299 sgd_solver.cpp:105] Iteration 29100, lr = 0.1
I1008 00:19:32.497359  5299 solver.cpp:218] Iteration 29200 (3.95878 iter/s, 25.2603s/100 iters), loss = 0.251007
I1008 00:19:32.497398  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.251007 (* 1 = 0.251007 loss)
I1008 00:19:32.497404  5299 sgd_solver.cpp:105] Iteration 29200, lr = 0.1
I1008 00:19:57.153163  5299 solver.cpp:218] Iteration 29300 (4.05586 iter/s, 24.6557s/100 iters), loss = 0.222286
I1008 00:19:57.153244  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.222286 (* 1 = 0.222286 loss)
I1008 00:19:57.153250  5299 sgd_solver.cpp:105] Iteration 29300, lr = 0.1
I1008 00:20:21.804158  5299 solver.cpp:218] Iteration 29400 (4.05667 iter/s, 24.6508s/100 iters), loss = 0.313818
I1008 00:20:21.804191  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.313818 (* 1 = 0.313818 loss)
I1008 00:20:21.804198  5299 sgd_solver.cpp:105] Iteration 29400, lr = 0.1
I1008 00:20:45.244282  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:20:46.230975  5299 solver.cpp:330] Iteration 29500, Testing net (#0)
I1008 00:20:51.304551  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:20:51.502115  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8081
I1008 00:20:51.502149  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.619828 (* 1 = 0.619828 loss)
I1008 00:20:51.744078  5299 solver.cpp:218] Iteration 29500 (3.34004 iter/s, 29.9398s/100 iters), loss = 0.214235
I1008 00:20:51.744123  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.214235 (* 1 = 0.214235 loss)
I1008 00:20:51.744130  5299 sgd_solver.cpp:105] Iteration 29500, lr = 0.1
I1008 00:21:16.993614  5299 solver.cpp:218] Iteration 29600 (3.96049 iter/s, 25.2494s/100 iters), loss = 0.267529
I1008 00:21:16.993695  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.267529 (* 1 = 0.267529 loss)
I1008 00:21:16.993705  5299 sgd_solver.cpp:105] Iteration 29600, lr = 0.1
I1008 00:21:42.048286  5299 solver.cpp:218] Iteration 29700 (3.99131 iter/s, 25.0545s/100 iters), loss = 0.388724
I1008 00:21:42.048329  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.388724 (* 1 = 0.388724 loss)
I1008 00:21:42.048336  5299 sgd_solver.cpp:105] Iteration 29700, lr = 0.1
I1008 00:22:06.661165  5299 solver.cpp:218] Iteration 29800 (4.06294 iter/s, 24.6127s/100 iters), loss = 0.186676
I1008 00:22:06.661268  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.186676 (* 1 = 0.186676 loss)
I1008 00:22:06.661276  5299 sgd_solver.cpp:105] Iteration 29800, lr = 0.1
I1008 00:22:31.290704  5299 solver.cpp:218] Iteration 29900 (4.0602 iter/s, 24.6293s/100 iters), loss = 0.256655
I1008 00:22:31.290741  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.256655 (* 1 = 0.256655 loss)
I1008 00:22:31.290752  5299 sgd_solver.cpp:105] Iteration 29900, lr = 0.1
I1008 00:22:54.749717  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:22:55.700475  5299 solver.cpp:330] Iteration 30000, Testing net (#0)
I1008 00:23:00.615991  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:23:00.814112  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8042
I1008 00:23:00.814141  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.6648 (* 1 = 0.6648 loss)
I1008 00:23:01.050556  5299 solver.cpp:218] Iteration 30000 (3.36025 iter/s, 29.7597s/100 iters), loss = 0.203724
I1008 00:23:01.050593  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.203723 (* 1 = 0.203723 loss)
I1008 00:23:01.050601  5299 sgd_solver.cpp:105] Iteration 30000, lr = 0.1
I1008 00:23:26.291316  5299 solver.cpp:218] Iteration 30100 (3.96243 iter/s, 25.237s/100 iters), loss = 0.296984
I1008 00:23:26.291401  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.296983 (* 1 = 0.296983 loss)
I1008 00:23:26.291409  5299 sgd_solver.cpp:105] Iteration 30100, lr = 0.1
I1008 00:23:51.544811  5299 solver.cpp:218] Iteration 30200 (3.95988 iter/s, 25.2533s/100 iters), loss = 0.355398
I1008 00:23:51.544845  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.355398 (* 1 = 0.355398 loss)
I1008 00:23:51.544853  5299 sgd_solver.cpp:105] Iteration 30200, lr = 0.1
I1008 00:24:16.216035  5299 solver.cpp:218] Iteration 30300 (4.05333 iter/s, 24.6711s/100 iters), loss = 0.172461
I1008 00:24:16.216115  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.172461 (* 1 = 0.172461 loss)
I1008 00:24:16.216122  5299 sgd_solver.cpp:105] Iteration 30300, lr = 0.1
I1008 00:24:40.881110  5299 solver.cpp:218] Iteration 30400 (4.05435 iter/s, 24.6648s/100 iters), loss = 0.172816
I1008 00:24:40.881145  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.172816 (* 1 = 0.172816 loss)
I1008 00:24:40.881152  5299 sgd_solver.cpp:105] Iteration 30400, lr = 0.1
I1008 00:25:04.376585  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:25:05.337203  5299 solver.cpp:330] Iteration 30500, Testing net (#0)
I1008 00:25:10.337005  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:25:10.534010  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8215
I1008 00:25:10.534039  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.554291 (* 1 = 0.554291 loss)
I1008 00:25:10.689955  5299 solver.cpp:218] Iteration 30500 (3.35473 iter/s, 29.8087s/100 iters), loss = 0.255004
I1008 00:25:10.689990  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.255004 (* 1 = 0.255004 loss)
I1008 00:25:10.689997  5299 sgd_solver.cpp:105] Iteration 30500, lr = 0.1
I1008 00:25:36.168678  5299 solver.cpp:218] Iteration 30600 (3.92519 iter/s, 25.4765s/100 iters), loss = 0.209244
I1008 00:25:36.168746  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.209243 (* 1 = 0.209243 loss)
I1008 00:25:36.168754  5299 sgd_solver.cpp:105] Iteration 30600, lr = 0.1
I1008 00:26:01.424953  5299 solver.cpp:218] Iteration 30700 (3.95945 iter/s, 25.2561s/100 iters), loss = 0.267692
I1008 00:26:01.424989  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.267692 (* 1 = 0.267692 loss)
I1008 00:26:01.425000  5299 sgd_solver.cpp:105] Iteration 30700, lr = 0.1
I1008 00:26:26.075909  5299 solver.cpp:218] Iteration 30800 (4.05666 iter/s, 24.6508s/100 iters), loss = 0.162209
I1008 00:26:26.076033  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.162209 (* 1 = 0.162209 loss)
I1008 00:26:26.076045  5299 sgd_solver.cpp:105] Iteration 30800, lr = 0.1
I1008 00:26:50.734675  5299 solver.cpp:218] Iteration 30900 (4.05539 iter/s, 24.6585s/100 iters), loss = 0.200231
I1008 00:26:50.734709  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.200231 (* 1 = 0.200231 loss)
I1008 00:26:50.734728  5299 sgd_solver.cpp:105] Iteration 30900, lr = 0.1
I1008 00:27:14.183156  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:27:15.155355  5299 solver.cpp:330] Iteration 31000, Testing net (#0)
I1008 00:27:20.188752  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:27:20.429409  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7342
I1008 00:27:20.429446  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.843401 (* 1 = 0.843401 loss)
I1008 00:27:20.596345  5299 solver.cpp:218] Iteration 31000 (3.34879 iter/s, 29.8615s/100 iters), loss = 0.166347
I1008 00:27:20.596387  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.166347 (* 1 = 0.166347 loss)
I1008 00:27:20.596395  5299 sgd_solver.cpp:105] Iteration 31000, lr = 0.1
I1008 00:27:45.944094  5299 solver.cpp:218] Iteration 31100 (3.94581 iter/s, 25.3434s/100 iters), loss = 0.19084
I1008 00:27:45.944177  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.190839 (* 1 = 0.190839 loss)
I1008 00:27:45.944185  5299 sgd_solver.cpp:105] Iteration 31100, lr = 0.1
I1008 00:28:11.280614  5299 solver.cpp:218] Iteration 31200 (3.94691 iter/s, 25.3363s/100 iters), loss = 0.274619
I1008 00:28:11.280649  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.274619 (* 1 = 0.274619 loss)
I1008 00:28:11.280656  5299 sgd_solver.cpp:105] Iteration 31200, lr = 0.1
I1008 00:28:35.933313  5299 solver.cpp:218] Iteration 31300 (4.05637 iter/s, 24.6526s/100 iters), loss = 0.273299
I1008 00:28:35.933393  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.273298 (* 1 = 0.273298 loss)
I1008 00:28:35.933403  5299 sgd_solver.cpp:105] Iteration 31300, lr = 0.1
I1008 00:29:00.597228  5299 solver.cpp:218] Iteration 31400 (4.05454 iter/s, 24.6637s/100 iters), loss = 0.174445
I1008 00:29:00.597260  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.174445 (* 1 = 0.174445 loss)
I1008 00:29:00.597267  5299 sgd_solver.cpp:105] Iteration 31400, lr = 0.1
I1008 00:29:24.026298  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:29:25.007565  5299 solver.cpp:330] Iteration 31500, Testing net (#0)
I1008 00:29:30.089743  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:29:30.282899  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7269
I1008 00:29:30.282925  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.934977 (* 1 = 0.934977 loss)
I1008 00:29:30.524202  5299 solver.cpp:218] Iteration 31500 (3.34148 iter/s, 29.9268s/100 iters), loss = 0.255712
I1008 00:29:30.524235  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.255712 (* 1 = 0.255712 loss)
I1008 00:29:30.524242  5299 sgd_solver.cpp:105] Iteration 31500, lr = 0.1
I1008 00:29:55.864985  5299 solver.cpp:218] Iteration 31600 (3.94623 iter/s, 25.3406s/100 iters), loss = 0.182882
I1008 00:29:55.865069  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.182881 (* 1 = 0.182881 loss)
I1008 00:29:55.865077  5299 sgd_solver.cpp:105] Iteration 31600, lr = 0.1
I1008 00:30:21.120976  5299 solver.cpp:218] Iteration 31700 (3.95949 iter/s, 25.2558s/100 iters), loss = 0.17631
I1008 00:30:21.121007  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.17631 (* 1 = 0.17631 loss)
I1008 00:30:21.121014  5299 sgd_solver.cpp:105] Iteration 31700, lr = 0.1
I1008 00:30:45.768470  5299 solver.cpp:218] Iteration 31800 (4.05723 iter/s, 24.6473s/100 iters), loss = 0.251375
I1008 00:30:45.768548  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.251374 (* 1 = 0.251374 loss)
I1008 00:30:45.768555  5299 sgd_solver.cpp:105] Iteration 31800, lr = 0.1
I1008 00:31:10.404685  5299 solver.cpp:218] Iteration 31900 (4.0591 iter/s, 24.636s/100 iters), loss = 0.150735
I1008 00:31:10.404719  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.150735 (* 1 = 0.150735 loss)
I1008 00:31:10.404726  5299 sgd_solver.cpp:105] Iteration 31900, lr = 0.1
I1008 00:31:33.821055  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:31:34.805682  5299 solver.cpp:330] Iteration 32000, Testing net (#0)
I1008 00:31:39.840299  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:31:40.025986  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7821
I1008 00:31:40.026016  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.758638 (* 1 = 0.758638 loss)
I1008 00:31:40.168648  5299 solver.cpp:218] Iteration 32000 (3.35978 iter/s, 29.7638s/100 iters), loss = 0.310004
I1008 00:31:40.168680  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.310004 (* 1 = 0.310004 loss)
I1008 00:31:40.168687  5299 sgd_solver.cpp:105] Iteration 32000, lr = 0.1
I1008 00:32:05.483729  5299 solver.cpp:218] Iteration 32100 (3.95024 iter/s, 25.3149s/100 iters), loss = 0.181473
I1008 00:32:05.483810  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.181473 (* 1 = 0.181473 loss)
I1008 00:32:05.483819  5299 sgd_solver.cpp:105] Iteration 32100, lr = 0.1
I1008 00:32:30.546865  5299 solver.cpp:218] Iteration 32200 (3.98996 iter/s, 25.0629s/100 iters), loss = 0.368853
I1008 00:32:30.546900  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.368853 (* 1 = 0.368853 loss)
I1008 00:32:30.546907  5299 sgd_solver.cpp:105] Iteration 32200, lr = 0.1
I1008 00:32:55.189347  5299 solver.cpp:218] Iteration 32300 (4.05806 iter/s, 24.6423s/100 iters), loss = 0.180727
I1008 00:32:55.189435  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.180727 (* 1 = 0.180727 loss)
I1008 00:32:55.189445  5299 sgd_solver.cpp:105] Iteration 32300, lr = 0.1
I1008 00:33:19.833163  5299 solver.cpp:218] Iteration 32400 (4.05785 iter/s, 24.6436s/100 iters), loss = 0.167458
I1008 00:33:19.833201  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.167458 (* 1 = 0.167458 loss)
I1008 00:33:19.833209  5299 sgd_solver.cpp:105] Iteration 32400, lr = 0.1
I1008 00:33:43.261771  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:33:44.246505  5299 solver.cpp:330] Iteration 32500, Testing net (#0)
I1008 00:33:49.245751  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:33:49.404405  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7492
I1008 00:33:49.404453  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.788211 (* 1 = 0.788211 loss)
I1008 00:33:49.607153  5299 solver.cpp:218] Iteration 32500 (3.35865 iter/s, 29.7738s/100 iters), loss = 0.244494
I1008 00:33:49.607228  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.244494 (* 1 = 0.244494 loss)
I1008 00:33:49.607237  5299 sgd_solver.cpp:105] Iteration 32500, lr = 0.1
I1008 00:34:14.932538  5299 solver.cpp:218] Iteration 32600 (3.94863 iter/s, 25.3252s/100 iters), loss = 0.34015
I1008 00:34:14.932654  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.34015 (* 1 = 0.34015 loss)
I1008 00:34:14.932662  5299 sgd_solver.cpp:105] Iteration 32600, lr = 0.1
I1008 00:34:40.255512  5299 solver.cpp:218] Iteration 32700 (3.94902 iter/s, 25.3228s/100 iters), loss = 0.221962
I1008 00:34:40.255560  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.221962 (* 1 = 0.221962 loss)
I1008 00:34:40.255568  5299 sgd_solver.cpp:105] Iteration 32700, lr = 0.1
I1008 00:35:04.894948  5299 solver.cpp:218] Iteration 32800 (4.05856 iter/s, 24.6393s/100 iters), loss = 0.165941
I1008 00:35:04.895025  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.16594 (* 1 = 0.16594 loss)
I1008 00:35:04.895032  5299 sgd_solver.cpp:105] Iteration 32800, lr = 0.1
I1008 00:35:29.528239  5299 solver.cpp:218] Iteration 32900 (4.05958 iter/s, 24.6331s/100 iters), loss = 0.289443
I1008 00:35:29.528272  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.289442 (* 1 = 0.289442 loss)
I1008 00:35:29.528280  5299 sgd_solver.cpp:105] Iteration 32900, lr = 0.1
I1008 00:35:52.949100  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:35:53.930215  5299 solver.cpp:330] Iteration 33000, Testing net (#0)
I1008 00:35:58.850873  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:35:59.046805  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7255
I1008 00:35:59.046831  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.01903 (* 1 = 1.01903 loss)
I1008 00:35:59.287464  5299 solver.cpp:218] Iteration 33000 (3.36032 iter/s, 29.7591s/100 iters), loss = 0.245592
I1008 00:35:59.287502  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.245592 (* 1 = 0.245592 loss)
I1008 00:35:59.287508  5299 sgd_solver.cpp:105] Iteration 33000, lr = 0.1
I1008 00:36:24.554709  5299 solver.cpp:218] Iteration 33100 (3.95795 iter/s, 25.2656s/100 iters), loss = 0.210549
I1008 00:36:24.554787  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.210549 (* 1 = 0.210549 loss)
I1008 00:36:24.554795  5299 sgd_solver.cpp:105] Iteration 33100, lr = 0.1
I1008 00:36:49.810150  5299 solver.cpp:218] Iteration 33200 (3.95958 iter/s, 25.2552s/100 iters), loss = 0.282743
I1008 00:36:49.810195  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.282742 (* 1 = 0.282742 loss)
I1008 00:36:49.810201  5299 sgd_solver.cpp:105] Iteration 33200, lr = 0.1
I1008 00:37:14.467633  5299 solver.cpp:218] Iteration 33300 (4.05559 iter/s, 24.6573s/100 iters), loss = 0.226937
I1008 00:37:14.467774  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.226937 (* 1 = 0.226937 loss)
I1008 00:37:14.467793  5299 sgd_solver.cpp:105] Iteration 33300, lr = 0.1
I1008 00:37:39.121740  5299 solver.cpp:218] Iteration 33400 (4.05616 iter/s, 24.6539s/100 iters), loss = 0.126812
I1008 00:37:39.121774  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.126812 (* 1 = 0.126812 loss)
I1008 00:37:39.121781  5299 sgd_solver.cpp:105] Iteration 33400, lr = 0.1
I1008 00:38:02.560118  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:38:03.532793  5299 solver.cpp:330] Iteration 33500, Testing net (#0)
I1008 00:38:08.462714  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:38:08.648622  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7774
I1008 00:38:08.648651  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.749084 (* 1 = 0.749084 loss)
I1008 00:38:08.887310  5299 solver.cpp:218] Iteration 33500 (3.3596 iter/s, 29.7654s/100 iters), loss = 0.154115
I1008 00:38:08.887356  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.154115 (* 1 = 0.154115 loss)
I1008 00:38:08.887362  5299 sgd_solver.cpp:105] Iteration 33500, lr = 0.1
I1008 00:38:34.250504  5299 solver.cpp:218] Iteration 33600 (3.94307 iter/s, 25.3609s/100 iters), loss = 0.272414
I1008 00:38:34.250569  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.272414 (* 1 = 0.272414 loss)
I1008 00:38:34.250577  5299 sgd_solver.cpp:105] Iteration 33600, lr = 0.1
I1008 00:38:59.700373  5299 solver.cpp:218] Iteration 33700 (3.92932 iter/s, 25.4497s/100 iters), loss = 0.171702
I1008 00:38:59.700407  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.171702 (* 1 = 0.171702 loss)
I1008 00:38:59.700414  5299 sgd_solver.cpp:105] Iteration 33700, lr = 0.1
I1008 00:39:24.343303  5299 solver.cpp:218] Iteration 33800 (4.05798 iter/s, 24.6428s/100 iters), loss = 0.33699
I1008 00:39:24.343386  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.33699 (* 1 = 0.33699 loss)
I1008 00:39:24.343396  5299 sgd_solver.cpp:105] Iteration 33800, lr = 0.1
I1008 00:39:48.973775  5299 solver.cpp:218] Iteration 33900 (4.06005 iter/s, 24.6302s/100 iters), loss = 0.211189
I1008 00:39:48.973831  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.211189 (* 1 = 0.211189 loss)
I1008 00:39:48.973851  5299 sgd_solver.cpp:105] Iteration 33900, lr = 0.1
I1008 00:40:12.567376  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:40:13.552125  5299 solver.cpp:330] Iteration 34000, Testing net (#0)
I1008 00:40:18.469112  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:40:18.670369  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7639
I1008 00:40:18.670399  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.779755 (* 1 = 0.779755 loss)
I1008 00:40:18.897022  5299 solver.cpp:218] Iteration 34000 (3.3419 iter/s, 29.9231s/100 iters), loss = 0.16813
I1008 00:40:18.897056  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.16813 (* 1 = 0.16813 loss)
I1008 00:40:18.897063  5299 sgd_solver.cpp:105] Iteration 34000, lr = 0.1
I1008 00:40:44.179697  5299 solver.cpp:218] Iteration 34100 (3.95597 iter/s, 25.2783s/100 iters), loss = 0.216664
I1008 00:40:44.179771  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.216664 (* 1 = 0.216664 loss)
I1008 00:40:44.179780  5299 sgd_solver.cpp:105] Iteration 34100, lr = 0.1
I1008 00:41:09.345072  5299 solver.cpp:218] Iteration 34200 (3.97374 iter/s, 25.1652s/100 iters), loss = 0.207411
I1008 00:41:09.345108  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.20741 (* 1 = 0.20741 loss)
I1008 00:41:09.345115  5299 sgd_solver.cpp:105] Iteration 34200, lr = 0.1
I1008 00:41:34.162803  5299 solver.cpp:218] Iteration 34300 (4.0294 iter/s, 24.8176s/100 iters), loss = 0.213654
I1008 00:41:34.162870  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.213654 (* 1 = 0.213654 loss)
I1008 00:41:34.162878  5299 sgd_solver.cpp:105] Iteration 34300, lr = 0.1
I1008 00:41:58.833922  5299 solver.cpp:218] Iteration 34400 (4.05335 iter/s, 24.671s/100 iters), loss = 0.156538
I1008 00:41:58.833964  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.156538 (* 1 = 0.156538 loss)
I1008 00:41:58.833982  5299 sgd_solver.cpp:105] Iteration 34400, lr = 0.1
I1008 00:42:22.317454  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:42:23.264292  5299 solver.cpp:330] Iteration 34500, Testing net (#0)
I1008 00:42:28.215636  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:42:28.406774  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8201
I1008 00:42:28.406803  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.567024 (* 1 = 0.567024 loss)
I1008 00:42:28.616181  5299 solver.cpp:218] Iteration 34500 (3.35772 iter/s, 29.7821s/100 iters), loss = 0.162914
I1008 00:42:28.616237  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.162914 (* 1 = 0.162914 loss)
I1008 00:42:28.616250  5299 sgd_solver.cpp:105] Iteration 34500, lr = 0.1
I1008 00:42:54.044387  5299 solver.cpp:218] Iteration 34600 (3.93299 iter/s, 25.426s/100 iters), loss = 0.326009
I1008 00:42:54.044452  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.326009 (* 1 = 0.326009 loss)
I1008 00:42:54.044461  5299 sgd_solver.cpp:105] Iteration 34600, lr = 0.1
I1008 00:43:19.385690  5299 solver.cpp:218] Iteration 34700 (3.94615 iter/s, 25.3412s/100 iters), loss = 0.216675
I1008 00:43:19.385735  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.216675 (* 1 = 0.216675 loss)
I1008 00:43:19.385740  5299 sgd_solver.cpp:105] Iteration 34700, lr = 0.1
I1008 00:43:44.040172  5299 solver.cpp:218] Iteration 34800 (4.05608 iter/s, 24.6543s/100 iters), loss = 0.196342
I1008 00:43:44.040246  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.196342 (* 1 = 0.196342 loss)
I1008 00:43:44.040256  5299 sgd_solver.cpp:105] Iteration 34800, lr = 0.1
I1008 00:44:08.688360  5299 solver.cpp:218] Iteration 34900 (4.05713 iter/s, 24.648s/100 iters), loss = 0.139445
I1008 00:44:08.688397  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.139445 (* 1 = 0.139445 loss)
I1008 00:44:08.688406  5299 sgd_solver.cpp:105] Iteration 34900, lr = 0.1
I1008 00:44:32.122843  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:44:33.106709  5299 solver.cpp:330] Iteration 35000, Testing net (#0)
I1008 00:44:38.099930  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:44:38.260489  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7952
I1008 00:44:38.260515  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.623519 (* 1 = 0.623519 loss)
I1008 00:44:38.464161  5299 solver.cpp:218] Iteration 35000 (3.35845 iter/s, 29.7756s/100 iters), loss = 0.157987
I1008 00:44:38.464195  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.157987 (* 1 = 0.157987 loss)
I1008 00:44:38.464201  5299 sgd_solver.cpp:105] Iteration 35000, lr = 0.1
I1008 00:45:03.784194  5299 solver.cpp:218] Iteration 35100 (3.94946 iter/s, 25.3199s/100 iters), loss = 0.172416
I1008 00:45:03.784276  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.172416 (* 1 = 0.172416 loss)
I1008 00:45:03.784283  5299 sgd_solver.cpp:105] Iteration 35100, lr = 0.1
I1008 00:45:29.118130  5299 solver.cpp:218] Iteration 35200 (3.94731 iter/s, 25.3337s/100 iters), loss = 0.21866
I1008 00:45:29.118166  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.21866 (* 1 = 0.21866 loss)
I1008 00:45:29.118175  5299 sgd_solver.cpp:105] Iteration 35200, lr = 0.1
I1008 00:45:53.766487  5299 solver.cpp:218] Iteration 35300 (4.05709 iter/s, 24.6482s/100 iters), loss = 0.165808
I1008 00:45:53.766571  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.165808 (* 1 = 0.165808 loss)
I1008 00:45:53.766578  5299 sgd_solver.cpp:105] Iteration 35300, lr = 0.1
I1008 00:46:18.401378  5299 solver.cpp:218] Iteration 35400 (4.05932 iter/s, 24.6347s/100 iters), loss = 0.230516
I1008 00:46:18.401422  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.230516 (* 1 = 0.230516 loss)
I1008 00:46:18.401429  5299 sgd_solver.cpp:105] Iteration 35400, lr = 0.1
I1008 00:46:41.838115  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:46:42.819870  5299 solver.cpp:330] Iteration 35500, Testing net (#0)
I1008 00:46:47.851820  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:46:48.044282  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7917
I1008 00:46:48.044311  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.669556 (* 1 = 0.669556 loss)
I1008 00:46:48.180390  5299 solver.cpp:218] Iteration 35500 (3.35809 iter/s, 29.7789s/100 iters), loss = 0.172278
I1008 00:46:48.180431  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.172278 (* 1 = 0.172278 loss)
I1008 00:46:48.180441  5299 sgd_solver.cpp:105] Iteration 35500, lr = 0.1
I1008 00:47:13.489030  5299 solver.cpp:218] Iteration 35600 (3.95125 iter/s, 25.3085s/100 iters), loss = 0.288081
I1008 00:47:13.489112  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.288081 (* 1 = 0.288081 loss)
I1008 00:47:13.489120  5299 sgd_solver.cpp:105] Iteration 35600, lr = 0.1
I1008 00:47:38.680640  5299 solver.cpp:218] Iteration 35700 (3.96961 iter/s, 25.1914s/100 iters), loss = 0.209435
I1008 00:47:38.680677  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.209435 (* 1 = 0.209435 loss)
I1008 00:47:38.680687  5299 sgd_solver.cpp:105] Iteration 35700, lr = 0.1
I1008 00:48:03.312271  5299 solver.cpp:218] Iteration 35800 (4.05984 iter/s, 24.6315s/100 iters), loss = 0.164885
I1008 00:48:03.312364  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.164885 (* 1 = 0.164885 loss)
I1008 00:48:03.312382  5299 sgd_solver.cpp:105] Iteration 35800, lr = 0.1
I1008 00:48:27.927894  5299 solver.cpp:218] Iteration 35900 (4.0625 iter/s, 24.6154s/100 iters), loss = 0.173886
I1008 00:48:27.927927  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.173886 (* 1 = 0.173886 loss)
I1008 00:48:27.927933  5299 sgd_solver.cpp:105] Iteration 35900, lr = 0.1
I1008 00:48:51.353025  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:48:52.333987  5299 solver.cpp:330] Iteration 36000, Testing net (#0)
I1008 00:48:57.231720  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:48:57.452880  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6876
I1008 00:48:57.452913  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.29426 (* 1 = 1.29426 loss)
I1008 00:48:57.658507  5299 solver.cpp:218] Iteration 36000 (3.36355 iter/s, 29.7305s/100 iters), loss = 0.181326
I1008 00:48:57.658563  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.181326 (* 1 = 0.181326 loss)
I1008 00:48:57.658572  5299 sgd_solver.cpp:105] Iteration 36000, lr = 0.1
I1008 00:49:22.967699  5299 solver.cpp:218] Iteration 36100 (3.95177 iter/s, 25.3051s/100 iters), loss = 0.273785
I1008 00:49:22.967777  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.273785 (* 1 = 0.273785 loss)
I1008 00:49:22.967790  5299 sgd_solver.cpp:105] Iteration 36100, lr = 0.1
I1008 00:49:48.065822  5299 solver.cpp:218] Iteration 36200 (3.98472 iter/s, 25.0958s/100 iters), loss = 0.202499
I1008 00:49:48.065866  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.202499 (* 1 = 0.202499 loss)
I1008 00:49:48.065873  5299 sgd_solver.cpp:105] Iteration 36200, lr = 0.1
I1008 00:50:12.702208  5299 solver.cpp:218] Iteration 36300 (4.05906 iter/s, 24.6362s/100 iters), loss = 0.16946
I1008 00:50:12.702299  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.16946 (* 1 = 0.16946 loss)
I1008 00:50:12.702307  5299 sgd_solver.cpp:105] Iteration 36300, lr = 0.1
I1008 00:50:37.349530  5299 solver.cpp:218] Iteration 36400 (4.05727 iter/s, 24.6471s/100 iters), loss = 0.217371
I1008 00:50:37.349565  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.217371 (* 1 = 0.217371 loss)
I1008 00:50:37.349571  5299 sgd_solver.cpp:105] Iteration 36400, lr = 0.1
I1008 00:51:00.793050  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:51:01.771458  5299 solver.cpp:330] Iteration 36500, Testing net (#0)
I1008 00:51:06.793037  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:51:06.934417  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.6984
I1008 00:51:06.934444  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.989182 (* 1 = 0.989182 loss)
I1008 00:51:07.132176  5299 solver.cpp:218] Iteration 36500 (3.35768 iter/s, 29.7825s/100 iters), loss = 0.149085
I1008 00:51:07.132208  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.149085 (* 1 = 0.149085 loss)
I1008 00:51:07.132215  5299 sgd_solver.cpp:105] Iteration 36500, lr = 0.1
I1008 00:51:32.588893  5299 solver.cpp:218] Iteration 36600 (3.92826 iter/s, 25.4566s/100 iters), loss = 0.364089
I1008 00:51:32.588963  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.364089 (* 1 = 0.364089 loss)
I1008 00:51:32.588982  5299 sgd_solver.cpp:105] Iteration 36600, lr = 0.1
I1008 00:51:57.714880  5299 solver.cpp:218] Iteration 36700 (3.97997 iter/s, 25.1258s/100 iters), loss = 0.178035
I1008 00:51:57.714915  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.178035 (* 1 = 0.178035 loss)
I1008 00:51:57.714933  5299 sgd_solver.cpp:105] Iteration 36700, lr = 0.1
I1008 00:52:22.390352  5299 solver.cpp:218] Iteration 36800 (4.05263 iter/s, 24.6753s/100 iters), loss = 0.147929
I1008 00:52:22.390434  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.147929 (* 1 = 0.147929 loss)
I1008 00:52:22.390446  5299 sgd_solver.cpp:105] Iteration 36800, lr = 0.1
I1008 00:52:47.066536  5299 solver.cpp:218] Iteration 36900 (4.05253 iter/s, 24.676s/100 iters), loss = 0.189385
I1008 00:52:47.066572  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.189385 (* 1 = 0.189385 loss)
I1008 00:52:47.066582  5299 sgd_solver.cpp:105] Iteration 36900, lr = 0.1
I1008 00:53:10.496902  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:53:11.479010  5299 solver.cpp:330] Iteration 37000, Testing net (#0)
I1008 00:53:16.515280  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:53:16.755682  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8068
I1008 00:53:16.755709  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.609035 (* 1 = 0.609035 loss)
I1008 00:53:16.870909  5299 solver.cpp:218] Iteration 37000 (3.35523 iter/s, 29.8042s/100 iters), loss = 0.216007
I1008 00:53:16.870944  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.216007 (* 1 = 0.216007 loss)
I1008 00:53:16.870954  5299 sgd_solver.cpp:105] Iteration 37000, lr = 0.1
I1008 00:53:42.526321  5299 solver.cpp:218] Iteration 37100 (3.89833 iter/s, 25.652s/100 iters), loss = 0.152555
I1008 00:53:42.526413  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.152555 (* 1 = 0.152555 loss)
I1008 00:53:42.526427  5299 sgd_solver.cpp:105] Iteration 37100, lr = 0.1
I1008 00:54:07.554781  5299 solver.cpp:218] Iteration 37200 (3.99549 iter/s, 25.0282s/100 iters), loss = 0.249624
I1008 00:54:07.554824  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.249624 (* 1 = 0.249624 loss)
I1008 00:54:07.554831  5299 sgd_solver.cpp:105] Iteration 37200, lr = 0.1
I1008 00:54:32.203968  5299 solver.cpp:218] Iteration 37300 (4.05695 iter/s, 24.649s/100 iters), loss = 0.193759
I1008 00:54:32.204066  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.193759 (* 1 = 0.193759 loss)
I1008 00:54:32.204074  5299 sgd_solver.cpp:105] Iteration 37300, lr = 0.1
I1008 00:54:56.828986  5299 solver.cpp:218] Iteration 37400 (4.06095 iter/s, 24.6248s/100 iters), loss = 0.222728
I1008 00:54:56.829020  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.222728 (* 1 = 0.222728 loss)
I1008 00:54:56.829027  5299 sgd_solver.cpp:105] Iteration 37400, lr = 0.1
I1008 00:55:20.276068  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:55:21.224611  5299 solver.cpp:330] Iteration 37500, Testing net (#0)
I1008 00:55:26.275811  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:55:26.512979  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7112
I1008 00:55:26.513005  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 1.03572 (* 1 = 1.03572 loss)
I1008 00:55:26.672713  5299 solver.cpp:218] Iteration 37500 (3.35081 iter/s, 29.8436s/100 iters), loss = 0.210142
I1008 00:55:26.672757  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.210142 (* 1 = 0.210142 loss)
I1008 00:55:26.672765  5299 sgd_solver.cpp:105] Iteration 37500, lr = 0.1
I1008 00:55:52.398839  5299 solver.cpp:218] Iteration 37600 (3.88737 iter/s, 25.7243s/100 iters), loss = 0.267585
I1008 00:55:52.398918  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.267586 (* 1 = 0.267586 loss)
I1008 00:55:52.398926  5299 sgd_solver.cpp:105] Iteration 37600, lr = 0.1
I1008 00:56:17.224831  5299 solver.cpp:218] Iteration 37700 (4.02806 iter/s, 24.8258s/100 iters), loss = 0.215869
I1008 00:56:17.224865  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.215869 (* 1 = 0.215869 loss)
I1008 00:56:17.224871  5299 sgd_solver.cpp:105] Iteration 37700, lr = 0.1
I1008 00:56:41.839936  5299 solver.cpp:218] Iteration 37800 (4.06257 iter/s, 24.615s/100 iters), loss = 0.234856
I1008 00:56:41.840015  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.234856 (* 1 = 0.234856 loss)
I1008 00:56:41.840023  5299 sgd_solver.cpp:105] Iteration 37800, lr = 0.1
I1008 00:57:06.451020  5299 solver.cpp:218] Iteration 37900 (4.06325 iter/s, 24.6109s/100 iters), loss = 0.12277
I1008 00:57:06.451053  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.12277 (* 1 = 0.12277 loss)
I1008 00:57:06.451061  5299 sgd_solver.cpp:105] Iteration 37900, lr = 0.1
I1008 00:57:29.833489  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:57:30.813647  5299 solver.cpp:330] Iteration 38000, Testing net (#0)
I1008 00:57:35.927855  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:57:36.101160  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8095
I1008 00:57:36.101187  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.601335 (* 1 = 0.601335 loss)
I1008 00:57:36.302419  5299 solver.cpp:218] Iteration 38000 (3.34994 iter/s, 29.8512s/100 iters), loss = 0.202457
I1008 00:57:36.302453  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.202457 (* 1 = 0.202457 loss)
I1008 00:57:36.302460  5299 sgd_solver.cpp:105] Iteration 38000, lr = 0.1
I1008 00:58:01.893915  5299 solver.cpp:218] Iteration 38100 (3.90789 iter/s, 25.5893s/100 iters), loss = 0.225285
I1008 00:58:01.894006  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.225285 (* 1 = 0.225285 loss)
I1008 00:58:01.894017  5299 sgd_solver.cpp:105] Iteration 38100, lr = 0.1
I1008 00:58:26.612797  5299 solver.cpp:218] Iteration 38200 (4.04559 iter/s, 24.7183s/100 iters), loss = 0.311782
I1008 00:58:26.612829  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.311782 (* 1 = 0.311782 loss)
I1008 00:58:26.612843  5299 sgd_solver.cpp:105] Iteration 38200, lr = 0.1
I1008 00:58:51.257349  5299 solver.cpp:218] Iteration 38300 (4.05772 iter/s, 24.6444s/100 iters), loss = 0.180501
I1008 00:58:51.257431  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.180501 (* 1 = 0.180501 loss)
I1008 00:58:51.257438  5299 sgd_solver.cpp:105] Iteration 38300, lr = 0.1
I1008 00:59:15.889215  5299 solver.cpp:218] Iteration 38400 (4.05982 iter/s, 24.6316s/100 iters), loss = 0.254897
I1008 00:59:15.889243  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.254897 (* 1 = 0.254897 loss)
I1008 00:59:15.889262  5299 sgd_solver.cpp:105] Iteration 38400, lr = 0.1
I1008 00:59:39.360162  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:59:40.332397  5299 solver.cpp:330] Iteration 38500, Testing net (#0)
I1008 00:59:45.381932  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 00:59:45.623873  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8009
I1008 00:59:45.623901  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.623225 (* 1 = 0.623225 loss)
I1008 00:59:45.804237  5299 solver.cpp:218] Iteration 38500 (3.34282 iter/s, 29.9149s/100 iters), loss = 0.131847
I1008 00:59:45.804270  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.131847 (* 1 = 0.131847 loss)
I1008 00:59:45.804280  5299 sgd_solver.cpp:105] Iteration 38500, lr = 0.1
I1008 01:00:11.463323  5299 solver.cpp:218] Iteration 38600 (3.89759 iter/s, 25.6569s/100 iters), loss = 0.277058
I1008 01:00:11.463423  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.277059 (* 1 = 0.277059 loss)
I1008 01:00:11.463431  5299 sgd_solver.cpp:105] Iteration 38600, lr = 0.1
I1008 01:00:36.266993  5299 solver.cpp:218] Iteration 38700 (4.0317 iter/s, 24.8034s/100 iters), loss = 0.148235
I1008 01:00:36.267036  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.148235 (* 1 = 0.148235 loss)
I1008 01:00:36.267043  5299 sgd_solver.cpp:105] Iteration 38700, lr = 0.1
I1008 01:01:00.931200  5299 solver.cpp:218] Iteration 38800 (4.05448 iter/s, 24.6641s/100 iters), loss = 0.167519
I1008 01:01:00.931272  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.16752 (* 1 = 0.16752 loss)
I1008 01:01:00.931279  5299 sgd_solver.cpp:105] Iteration 38800, lr = 0.1
I1008 01:01:25.596660  5299 solver.cpp:218] Iteration 38900 (4.05428 iter/s, 24.6653s/100 iters), loss = 0.155583
I1008 01:01:25.596704  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.155583 (* 1 = 0.155583 loss)
I1008 01:01:25.596709  5299 sgd_solver.cpp:105] Iteration 38900, lr = 0.1
I1008 01:01:49.034723  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:01:50.016795  5299 solver.cpp:330] Iteration 39000, Testing net (#0)
I1008 01:01:55.208665  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:01:55.428290  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7833
I1008 01:01:55.428318  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.784123 (* 1 = 0.784123 loss)
I1008 01:01:55.648581  5299 solver.cpp:218] Iteration 39000 (3.32759 iter/s, 30.0518s/100 iters), loss = 0.15958
I1008 01:01:55.648612  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.15958 (* 1 = 0.15958 loss)
I1008 01:01:55.648619  5299 sgd_solver.cpp:105] Iteration 39000, lr = 0.1
I1008 01:02:21.163774  5299 solver.cpp:218] Iteration 39100 (3.91925 iter/s, 25.5151s/100 iters), loss = 0.263599
I1008 01:02:21.163872  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.263599 (* 1 = 0.263599 loss)
I1008 01:02:21.163882  5299 sgd_solver.cpp:105] Iteration 39100, lr = 0.1
I1008 01:02:45.971552  5299 solver.cpp:218] Iteration 39200 (4.03103 iter/s, 24.8076s/100 iters), loss = 0.219415
I1008 01:02:45.971587  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.219415 (* 1 = 0.219415 loss)
I1008 01:02:45.971593  5299 sgd_solver.cpp:105] Iteration 39200, lr = 0.1
I1008 01:03:10.809504  5299 solver.cpp:218] Iteration 39300 (4.02612 iter/s, 24.8378s/100 iters), loss = 0.191475
I1008 01:03:10.809577  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.191475 (* 1 = 0.191475 loss)
I1008 01:03:10.809586  5299 sgd_solver.cpp:105] Iteration 39300, lr = 0.1
I1008 01:03:35.789050  5299 solver.cpp:218] Iteration 39400 (4.0033 iter/s, 24.9794s/100 iters), loss = 0.183227
I1008 01:03:35.789085  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.183227 (* 1 = 0.183227 loss)
I1008 01:03:35.789093  5299 sgd_solver.cpp:105] Iteration 39400, lr = 0.1
I1008 01:03:59.221254  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:04:00.208148  5299 solver.cpp:330] Iteration 39500, Testing net (#0)
I1008 01:04:05.647022  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:04:05.833631  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.7208
I1008 01:04:05.833657  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.993692 (* 1 = 0.993692 loss)
I1008 01:04:06.034876  5299 solver.cpp:218] Iteration 39500 (3.30626 iter/s, 30.2457s/100 iters), loss = 0.204926
I1008 01:04:06.034905  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.204926 (* 1 = 0.204926 loss)
I1008 01:04:06.034912  5299 sgd_solver.cpp:105] Iteration 39500, lr = 0.1
I1008 01:04:31.361992  5299 solver.cpp:218] Iteration 39600 (3.94869 iter/s, 25.3249s/100 iters), loss = 0.275692
I1008 01:04:31.362054  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.275692 (* 1 = 0.275692 loss)
I1008 01:04:31.362063  5299 sgd_solver.cpp:105] Iteration 39600, lr = 0.1
I1008 01:04:56.152483  5299 solver.cpp:218] Iteration 39700 (4.03418 iter/s, 24.7882s/100 iters), loss = 0.229519
I1008 01:04:56.152518  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.229519 (* 1 = 0.229519 loss)
I1008 01:04:56.152524  5299 sgd_solver.cpp:105] Iteration 39700, lr = 0.1
I1008 01:05:20.795779  5299 solver.cpp:218] Iteration 39800 (4.05792 iter/s, 24.6432s/100 iters), loss = 0.284763
I1008 01:05:20.795874  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.284763 (* 1 = 0.284763 loss)
I1008 01:05:20.795883  5299 sgd_solver.cpp:105] Iteration 39800, lr = 0.1
I1008 01:05:45.437561  5299 solver.cpp:218] Iteration 39900 (4.05819 iter/s, 24.6416s/100 iters), loss = 0.179736
I1008 01:05:45.437593  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.179736 (* 1 = 0.179736 loss)
I1008 01:05:45.437599  5299 sgd_solver.cpp:105] Iteration 39900, lr = 0.1
I1008 01:06:08.965468  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:06:09.929718  5299 solver.cpp:330] Iteration 40000, Testing net (#0)
I1008 01:06:15.339798  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:06:15.551132  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8027
I1008 01:06:15.551159  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.608493 (* 1 = 0.608493 loss)
I1008 01:06:15.671957  5299 solver.cpp:218] Iteration 40000 (3.30751 iter/s, 30.2342s/100 iters), loss = 0.160701
I1008 01:06:15.671988  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.160701 (* 1 = 0.160701 loss)
I1008 01:06:15.671994  5299 sgd_solver.cpp:46] MultiStep Status: Iteration 40000, step = 1
I1008 01:06:15.671998  5299 sgd_solver.cpp:105] Iteration 40000, lr = 0.01
I1008 01:06:41.067975  5299 solver.cpp:218] Iteration 40100 (3.93798 iter/s, 25.3937s/100 iters), loss = 0.245471
I1008 01:06:41.068094  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.245471 (* 1 = 0.245471 loss)
I1008 01:06:41.068102  5299 sgd_solver.cpp:105] Iteration 40100, lr = 0.01
I1008 01:07:05.725991  5299 solver.cpp:218] Iteration 40200 (4.05551 iter/s, 24.6578s/100 iters), loss = 0.117347
I1008 01:07:05.726023  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.117347 (* 1 = 0.117347 loss)
I1008 01:07:05.726030  5299 sgd_solver.cpp:105] Iteration 40200, lr = 0.01
I1008 01:07:30.383322  5299 solver.cpp:218] Iteration 40300 (4.05561 iter/s, 24.6572s/100 iters), loss = 0.0755999
I1008 01:07:30.383416  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0755999 (* 1 = 0.0755999 loss)
I1008 01:07:30.383426  5299 sgd_solver.cpp:105] Iteration 40300, lr = 0.01
I1008 01:07:55.019528  5299 solver.cpp:218] Iteration 40400 (4.0591 iter/s, 24.636s/100 iters), loss = 0.049575
I1008 01:07:55.019569  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.049575 (* 1 = 0.049575 loss)
I1008 01:07:55.019577  5299 sgd_solver.cpp:105] Iteration 40400, lr = 0.01
I1008 01:08:18.450390  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:08:19.559284  5299 solver.cpp:330] Iteration 40500, Testing net (#0)
I1008 01:08:24.955368  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:08:25.136240  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8841
I1008 01:08:25.136270  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.34819 (* 1 = 0.34819 loss)
I1008 01:08:25.327209  5299 solver.cpp:218] Iteration 40500 (3.29951 iter/s, 30.3075s/100 iters), loss = 0.0691764
I1008 01:08:25.327252  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0691764 (* 1 = 0.0691764 loss)
I1008 01:08:25.327262  5299 sgd_solver.cpp:105] Iteration 40500, lr = 0.01
I1008 01:08:50.846359  5299 solver.cpp:218] Iteration 40600 (3.91865 iter/s, 25.519s/100 iters), loss = 0.113067
I1008 01:08:50.846439  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.113067 (* 1 = 0.113067 loss)
I1008 01:08:50.846451  5299 sgd_solver.cpp:105] Iteration 40600, lr = 0.01
I1008 01:09:15.520303  5299 solver.cpp:218] Iteration 40700 (4.0529 iter/s, 24.6737s/100 iters), loss = 0.116244
I1008 01:09:15.520335  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.116244 (* 1 = 0.116244 loss)
I1008 01:09:15.520341  5299 sgd_solver.cpp:105] Iteration 40700, lr = 0.01
I1008 01:09:40.207864  5299 solver.cpp:218] Iteration 40800 (4.05065 iter/s, 24.6874s/100 iters), loss = 0.094956
I1008 01:09:40.207922  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.094956 (* 1 = 0.094956 loss)
I1008 01:09:40.207939  5299 sgd_solver.cpp:105] Iteration 40800, lr = 0.01
I1008 01:10:05.038595  5299 solver.cpp:218] Iteration 40900 (4.02729 iter/s, 24.8306s/100 iters), loss = 0.0615593
I1008 01:10:05.038636  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0615593 (* 1 = 0.0615593 loss)
I1008 01:10:05.038642  5299 sgd_solver.cpp:105] Iteration 40900, lr = 0.01
I1008 01:10:28.642977  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:10:29.723150  5299 solver.cpp:330] Iteration 41000, Testing net (#0)
I1008 01:10:34.945011  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:10:35.185834  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9077
I1008 01:10:35.185859  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.278732 (* 1 = 0.278732 loss)
I1008 01:10:35.354806  5299 solver.cpp:218] Iteration 41000 (3.29858 iter/s, 30.3161s/100 iters), loss = 0.0478794
I1008 01:10:35.354849  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0478794 (* 1 = 0.0478794 loss)
I1008 01:10:35.354856  5299 sgd_solver.cpp:105] Iteration 41000, lr = 0.01
I1008 01:11:00.689503  5299 solver.cpp:218] Iteration 41100 (3.94785 iter/s, 25.3303s/100 iters), loss = 0.136767
I1008 01:11:00.689611  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.136767 (* 1 = 0.136767 loss)
I1008 01:11:00.689620  5299 sgd_solver.cpp:105] Iteration 41100, lr = 0.01
I1008 01:11:25.326301  5299 solver.cpp:218] Iteration 41200 (4.05901 iter/s, 24.6366s/100 iters), loss = 0.0633468
I1008 01:11:25.326345  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0633468 (* 1 = 0.0633468 loss)
I1008 01:11:25.326354  5299 sgd_solver.cpp:105] Iteration 41200, lr = 0.01
I1008 01:11:49.989154  5299 solver.cpp:218] Iteration 41300 (4.0547 iter/s, 24.6627s/100 iters), loss = 0.0882023
I1008 01:11:49.989231  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0882023 (* 1 = 0.0882023 loss)
I1008 01:11:49.989248  5299 sgd_solver.cpp:105] Iteration 41300, lr = 0.01
I1008 01:12:14.641528  5299 solver.cpp:218] Iteration 41400 (4.05644 iter/s, 24.6521s/100 iters), loss = 0.095187
I1008 01:12:14.641564  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.095187 (* 1 = 0.095187 loss)
I1008 01:12:14.641571  5299 sgd_solver.cpp:105] Iteration 41400, lr = 0.01
I1008 01:12:38.353163  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:12:39.460217  5299 solver.cpp:330] Iteration 41500, Testing net (#0)
I1008 01:12:44.611753  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:12:44.852730  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9077
I1008 01:12:44.852756  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.283932 (* 1 = 0.283932 loss)
I1008 01:12:44.992760  5299 solver.cpp:218] Iteration 41500 (3.29478 iter/s, 30.3511s/100 iters), loss = 0.0502097
I1008 01:12:44.992794  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0502097 (* 1 = 0.0502097 loss)
I1008 01:12:44.992800  5299 sgd_solver.cpp:105] Iteration 41500, lr = 0.01
I1008 01:13:10.407335  5299 solver.cpp:218] Iteration 41600 (3.93542 iter/s, 25.4102s/100 iters), loss = 0.107753
I1008 01:13:10.407444  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.107753 (* 1 = 0.107753 loss)
I1008 01:13:10.407452  5299 sgd_solver.cpp:105] Iteration 41600, lr = 0.01
I1008 01:13:35.090721  5299 solver.cpp:218] Iteration 41700 (4.05135 iter/s, 24.6832s/100 iters), loss = 0.108161
I1008 01:13:35.090754  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.108161 (* 1 = 0.108161 loss)
I1008 01:13:35.090760  5299 sgd_solver.cpp:105] Iteration 41700, lr = 0.01
I1008 01:13:59.713413  5299 solver.cpp:218] Iteration 41800 (4.06132 iter/s, 24.6225s/100 iters), loss = 0.064841
I1008 01:13:59.713505  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.064841 (* 1 = 0.064841 loss)
I1008 01:13:59.713523  5299 sgd_solver.cpp:105] Iteration 41800, lr = 0.01
I1008 01:14:24.371805  5299 solver.cpp:218] Iteration 41900 (4.05545 iter/s, 24.6582s/100 iters), loss = 0.0444862
I1008 01:14:24.371839  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0444862 (* 1 = 0.0444862 loss)
I1008 01:14:24.371845  5299 sgd_solver.cpp:105] Iteration 41900, lr = 0.01
I1008 01:14:48.265230  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:14:49.372509  5299 solver.cpp:330] Iteration 42000, Testing net (#0)
I1008 01:14:54.462559  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:14:54.631657  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9066
I1008 01:14:54.631683  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.280264 (* 1 = 0.280264 loss)
I1008 01:14:54.836684  5299 solver.cpp:218] Iteration 42000 (3.28248 iter/s, 30.4647s/100 iters), loss = 0.0522064
I1008 01:14:54.836716  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0522064 (* 1 = 0.0522064 loss)
I1008 01:14:54.836722  5299 sgd_solver.cpp:105] Iteration 42000, lr = 0.01
I1008 01:15:20.079910  5299 solver.cpp:218] Iteration 42100 (3.96148 iter/s, 25.2431s/100 iters), loss = 0.0835859
I1008 01:15:20.080025  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0835859 (* 1 = 0.0835859 loss)
I1008 01:15:20.080035  5299 sgd_solver.cpp:105] Iteration 42100, lr = 0.01
I1008 01:15:44.709446  5299 solver.cpp:218] Iteration 42200 (4.0602 iter/s, 24.6293s/100 iters), loss = 0.0481692
I1008 01:15:44.709481  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0481693 (* 1 = 0.0481693 loss)
I1008 01:15:44.709488  5299 sgd_solver.cpp:105] Iteration 42200, lr = 0.01
I1008 01:16:09.350667  5299 solver.cpp:218] Iteration 42300 (4.05827 iter/s, 24.6411s/100 iters), loss = 0.0890796
I1008 01:16:09.350761  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0890797 (* 1 = 0.0890797 loss)
I1008 01:16:09.350770  5299 sgd_solver.cpp:105] Iteration 42300, lr = 0.01
I1008 01:16:34.002802  5299 solver.cpp:218] Iteration 42400 (4.05648 iter/s, 24.6519s/100 iters), loss = 0.0754478
I1008 01:16:34.002835  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0754478 (* 1 = 0.0754478 loss)
I1008 01:16:34.002842  5299 sgd_solver.cpp:105] Iteration 42400, lr = 0.01
I1008 01:16:57.977124  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:16:59.019192  5299 solver.cpp:330] Iteration 42500, Testing net (#0)
I1008 01:17:03.967660  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:17:04.172194  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9114
I1008 01:17:04.172219  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.275877 (* 1 = 0.275877 loss)
I1008 01:17:04.351246  5299 solver.cpp:218] Iteration 42500 (3.29508 iter/s, 30.3483s/100 iters), loss = 0.0494641
I1008 01:17:04.351286  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0494641 (* 1 = 0.0494641 loss)
I1008 01:17:04.351295  5299 sgd_solver.cpp:105] Iteration 42500, lr = 0.01
I1008 01:17:29.977571  5299 solver.cpp:218] Iteration 42600 (3.90258 iter/s, 25.6241s/100 iters), loss = 0.0797542
I1008 01:17:29.977632  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0797542 (* 1 = 0.0797542 loss)
I1008 01:17:29.977639  5299 sgd_solver.cpp:105] Iteration 42600, lr = 0.01
I1008 01:17:54.645565  5299 solver.cpp:218] Iteration 42700 (4.05386 iter/s, 24.6679s/100 iters), loss = 0.0454549
I1008 01:17:54.645598  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0454549 (* 1 = 0.0454549 loss)
I1008 01:17:54.645606  5299 sgd_solver.cpp:105] Iteration 42700, lr = 0.01
I1008 01:18:19.304647  5299 solver.cpp:218] Iteration 42800 (4.05533 iter/s, 24.6589s/100 iters), loss = 0.0611078
I1008 01:18:19.304725  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0611078 (* 1 = 0.0611078 loss)
I1008 01:18:19.304733  5299 sgd_solver.cpp:105] Iteration 42800, lr = 0.01
I1008 01:18:43.960425  5299 solver.cpp:218] Iteration 42900 (4.05588 iter/s, 24.6556s/100 iters), loss = 0.0407158
I1008 01:18:43.960456  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0407157 (* 1 = 0.0407157 loss)
I1008 01:18:43.960463  5299 sgd_solver.cpp:105] Iteration 42900, lr = 0.01
I1008 01:19:07.991421  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:19:08.977401  5299 solver.cpp:330] Iteration 43000, Testing net (#0)
I1008 01:19:14.022568  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:19:14.255841  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9126
I1008 01:19:14.255867  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.278483 (* 1 = 0.278483 loss)
I1008 01:19:14.435963  5299 solver.cpp:218] Iteration 43000 (3.28134 iter/s, 30.4754s/100 iters), loss = 0.0263604
I1008 01:19:14.436003  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0263604 (* 1 = 0.0263604 loss)
I1008 01:19:14.436012  5299 sgd_solver.cpp:105] Iteration 43000, lr = 0.01
I1008 01:19:39.819952  5299 solver.cpp:218] Iteration 43100 (3.94017 iter/s, 25.3796s/100 iters), loss = 0.0733451
I1008 01:19:39.820026  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.073345 (* 1 = 0.073345 loss)
I1008 01:19:39.820034  5299 sgd_solver.cpp:105] Iteration 43100, lr = 0.01
I1008 01:20:04.478456  5299 solver.cpp:218] Iteration 43200 (4.05542 iter/s, 24.6584s/100 iters), loss = 0.0350761
I1008 01:20:04.478489  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.035076 (* 1 = 0.035076 loss)
I1008 01:20:04.478497  5299 sgd_solver.cpp:105] Iteration 43200, lr = 0.01
I1008 01:20:29.142668  5299 solver.cpp:218] Iteration 43300 (4.05448 iter/s, 24.6641s/100 iters), loss = 0.0738481
I1008 01:20:29.142747  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.073848 (* 1 = 0.073848 loss)
I1008 01:20:29.142755  5299 sgd_solver.cpp:105] Iteration 43300, lr = 0.01
I1008 01:20:53.788158  5299 solver.cpp:218] Iteration 43400 (4.05758 iter/s, 24.6453s/100 iters), loss = 0.0857676
I1008 01:20:53.788190  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0857674 (* 1 = 0.0857674 loss)
I1008 01:20:53.788197  5299 sgd_solver.cpp:105] Iteration 43400, lr = 0.01
I1008 01:21:17.898720  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:21:18.885248  5299 solver.cpp:330] Iteration 43500, Testing net (#0)
I1008 01:21:23.918833  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:21:24.159144  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9066
I1008 01:21:24.159173  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.295513 (* 1 = 0.295513 loss)
I1008 01:21:24.327632  5299 solver.cpp:218] Iteration 43500 (3.27447 iter/s, 30.5393s/100 iters), loss = 0.0756258
I1008 01:21:24.327673  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0756257 (* 1 = 0.0756257 loss)
I1008 01:21:24.327682  5299 sgd_solver.cpp:105] Iteration 43500, lr = 0.01
I1008 01:21:49.672780  5299 solver.cpp:218] Iteration 43600 (3.94621 iter/s, 25.3408s/100 iters), loss = 0.0845596
I1008 01:21:49.672860  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0845596 (* 1 = 0.0845596 loss)
I1008 01:21:49.672868  5299 sgd_solver.cpp:105] Iteration 43600, lr = 0.01
I1008 01:22:14.331667  5299 solver.cpp:218] Iteration 43700 (4.05537 iter/s, 24.6587s/100 iters), loss = 0.0686055
I1008 01:22:14.331720  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0686055 (* 1 = 0.0686055 loss)
I1008 01:22:14.331728  5299 sgd_solver.cpp:105] Iteration 43700, lr = 0.01
I1008 01:22:38.997123  5299 solver.cpp:218] Iteration 43800 (4.05428 iter/s, 24.6653s/100 iters), loss = 0.0750116
I1008 01:22:38.997197  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0750116 (* 1 = 0.0750116 loss)
I1008 01:22:38.997205  5299 sgd_solver.cpp:105] Iteration 43800, lr = 0.01
I1008 01:23:03.667250  5299 solver.cpp:218] Iteration 43900 (4.05351 iter/s, 24.67s/100 iters), loss = 0.0570363
I1008 01:23:03.667284  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0570362 (* 1 = 0.0570362 loss)
I1008 01:23:03.667290  5299 sgd_solver.cpp:105] Iteration 43900, lr = 0.01
I1008 01:23:27.874506  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:23:28.855499  5299 solver.cpp:330] Iteration 44000, Testing net (#0)
I1008 01:23:33.932693  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:23:34.130318  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9156
I1008 01:23:34.130344  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.271505 (* 1 = 0.271505 loss)
I1008 01:23:34.362751  5299 solver.cpp:218] Iteration 44000 (3.25783 iter/s, 30.6952s/100 iters), loss = 0.045974
I1008 01:23:34.362788  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.045974 (* 1 = 0.045974 loss)
I1008 01:23:34.362795  5299 sgd_solver.cpp:105] Iteration 44000, lr = 0.01
I1008 01:23:59.677474  5299 solver.cpp:218] Iteration 44100 (3.95063 iter/s, 25.3124s/100 iters), loss = 0.0791449
I1008 01:23:59.677579  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0791449 (* 1 = 0.0791449 loss)
I1008 01:23:59.677590  5299 sgd_solver.cpp:105] Iteration 44100, lr = 0.01
I1008 01:24:24.293687  5299 solver.cpp:218] Iteration 44200 (4.0624 iter/s, 24.616s/100 iters), loss = 0.0607177
I1008 01:24:24.293722  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0607177 (* 1 = 0.0607177 loss)
I1008 01:24:24.293730  5299 sgd_solver.cpp:105] Iteration 44200, lr = 0.01
I1008 01:24:48.919524  5299 solver.cpp:218] Iteration 44300 (4.0608 iter/s, 24.6257s/100 iters), loss = 0.0708354
I1008 01:24:48.919610  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0708354 (* 1 = 0.0708354 loss)
I1008 01:24:48.919617  5299 sgd_solver.cpp:105] Iteration 44300, lr = 0.01
I1008 01:25:13.559741  5299 solver.cpp:218] Iteration 44400 (4.05844 iter/s, 24.64s/100 iters), loss = 0.0289469
I1008 01:25:13.559784  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0289468 (* 1 = 0.0289468 loss)
I1008 01:25:13.559792  5299 sgd_solver.cpp:105] Iteration 44400, lr = 0.01
I1008 01:25:37.590703  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:25:38.571143  5299 solver.cpp:330] Iteration 44500, Testing net (#0)
I1008 01:25:43.647316  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:25:43.842124  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.913
I1008 01:25:43.842150  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.274468 (* 1 = 0.274468 loss)
I1008 01:25:44.083549  5299 solver.cpp:218] Iteration 44500 (3.27615 iter/s, 30.5237s/100 iters), loss = 0.0353034
I1008 01:25:44.083582  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0353034 (* 1 = 0.0353034 loss)
I1008 01:25:44.083590  5299 sgd_solver.cpp:105] Iteration 44500, lr = 0.01
I1008 01:26:09.385365  5299 solver.cpp:218] Iteration 44600 (3.95231 iter/s, 25.3017s/100 iters), loss = 0.0483241
I1008 01:26:09.385502  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0483241 (* 1 = 0.0483241 loss)
I1008 01:26:09.385511  5299 sgd_solver.cpp:105] Iteration 44600, lr = 0.01
I1008 01:26:34.012867  5299 solver.cpp:218] Iteration 44700 (4.06054 iter/s, 24.6273s/100 iters), loss = 0.0681517
I1008 01:26:34.012902  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0681516 (* 1 = 0.0681516 loss)
I1008 01:26:34.012909  5299 sgd_solver.cpp:105] Iteration 44700, lr = 0.01
I1008 01:26:58.646679  5299 solver.cpp:218] Iteration 44800 (4.05949 iter/s, 24.6337s/100 iters), loss = 0.0458802
I1008 01:26:58.646764  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0458801 (* 1 = 0.0458801 loss)
I1008 01:26:58.646772  5299 sgd_solver.cpp:105] Iteration 44800, lr = 0.01
I1008 01:27:23.302810  5299 solver.cpp:218] Iteration 44900 (4.05582 iter/s, 24.6559s/100 iters), loss = 0.0443249
I1008 01:27:23.302848  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0443249 (* 1 = 0.0443249 loss)
I1008 01:27:23.302858  5299 sgd_solver.cpp:105] Iteration 44900, lr = 0.01
I1008 01:27:47.341501  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:27:48.311128  5299 solver.cpp:330] Iteration 45000, Testing net (#0)
I1008 01:27:53.193385  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:27:53.434653  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9146
I1008 01:27:53.434681  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.278422 (* 1 = 0.278422 loss)
I1008 01:27:53.559317  5299 solver.cpp:218] Iteration 45000 (3.30509 iter/s, 30.2564s/100 iters), loss = 0.04363
I1008 01:27:53.559351  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.04363 (* 1 = 0.04363 loss)
I1008 01:27:53.559360  5299 sgd_solver.cpp:105] Iteration 45000, lr = 0.01
I1008 01:28:18.959311  5299 solver.cpp:218] Iteration 45100 (3.93736 iter/s, 25.3977s/100 iters), loss = 0.0815765
I1008 01:28:18.959411  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0815765 (* 1 = 0.0815765 loss)
I1008 01:28:18.959419  5299 sgd_solver.cpp:105] Iteration 45100, lr = 0.01
I1008 01:28:43.570076  5299 solver.cpp:218] Iteration 45200 (4.0633 iter/s, 24.6105s/100 iters), loss = 0.0613677
I1008 01:28:43.570111  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0613677 (* 1 = 0.0613677 loss)
I1008 01:28:43.570121  5299 sgd_solver.cpp:105] Iteration 45200, lr = 0.01
I1008 01:29:08.207686  5299 solver.cpp:218] Iteration 45300 (4.05886 iter/s, 24.6375s/100 iters), loss = 0.0449285
I1008 01:29:08.207763  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0449285 (* 1 = 0.0449285 loss)
I1008 01:29:08.207772  5299 sgd_solver.cpp:105] Iteration 45300, lr = 0.01
I1008 01:29:32.840540  5299 solver.cpp:218] Iteration 45400 (4.05964 iter/s, 24.6327s/100 iters), loss = 0.0387795
I1008 01:29:32.840575  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0387795 (* 1 = 0.0387795 loss)
I1008 01:29:32.840582  5299 sgd_solver.cpp:105] Iteration 45400, lr = 0.01
I1008 01:29:56.954614  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:29:57.927280  5299 solver.cpp:330] Iteration 45500, Testing net (#0)
I1008 01:30:02.961140  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:30:03.202630  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9136
I1008 01:30:03.202653  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.282676 (* 1 = 0.282676 loss)
I1008 01:30:03.315709  5299 solver.cpp:218] Iteration 45500 (3.28138 iter/s, 30.475s/100 iters), loss = 0.0573025
I1008 01:30:03.315743  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0573025 (* 1 = 0.0573025 loss)
I1008 01:30:03.315760  5299 sgd_solver.cpp:105] Iteration 45500, lr = 0.01
I1008 01:30:28.848603  5299 solver.cpp:218] Iteration 45600 (3.91719 iter/s, 25.5285s/100 iters), loss = 0.0950995
I1008 01:30:28.848685  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0950995 (* 1 = 0.0950995 loss)
I1008 01:30:28.848693  5299 sgd_solver.cpp:105] Iteration 45600, lr = 0.01
I1008 01:30:53.505321  5299 solver.cpp:218] Iteration 45700 (4.05573 iter/s, 24.6565s/100 iters), loss = 0.0492186
I1008 01:30:53.505354  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0492186 (* 1 = 0.0492186 loss)
I1008 01:30:53.505360  5299 sgd_solver.cpp:105] Iteration 45700, lr = 0.01
I1008 01:31:18.165305  5299 solver.cpp:218] Iteration 45800 (4.05518 iter/s, 24.6598s/100 iters), loss = 0.0483334
I1008 01:31:18.165386  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0483333 (* 1 = 0.0483333 loss)
I1008 01:31:18.165395  5299 sgd_solver.cpp:105] Iteration 45800, lr = 0.01
I1008 01:31:42.828635  5299 solver.cpp:218] Iteration 45900 (4.05464 iter/s, 24.6631s/100 iters), loss = 0.0168584
I1008 01:31:42.828670  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0168583 (* 1 = 0.0168583 loss)
I1008 01:31:42.828677  5299 sgd_solver.cpp:105] Iteration 45900, lr = 0.01
I1008 01:32:06.964984  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:32:07.948225  5299 solver.cpp:330] Iteration 46000, Testing net (#0)
I1008 01:32:12.980136  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:32:13.221079  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9152
I1008 01:32:13.221114  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.287191 (* 1 = 0.287191 loss)
I1008 01:32:13.355583  5299 solver.cpp:218] Iteration 46000 (3.27581 iter/s, 30.5268s/100 iters), loss = 0.019219
I1008 01:32:13.355631  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0192189 (* 1 = 0.0192189 loss)
I1008 01:32:13.355640  5299 sgd_solver.cpp:105] Iteration 46000, lr = 0.01
I1008 01:32:38.787485  5299 solver.cpp:218] Iteration 46100 (3.93242 iter/s, 25.4296s/100 iters), loss = 0.0380335
I1008 01:32:38.787564  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0380335 (* 1 = 0.0380335 loss)
I1008 01:32:38.787572  5299 sgd_solver.cpp:105] Iteration 46100, lr = 0.01
I1008 01:33:03.438845  5299 solver.cpp:218] Iteration 46200 (4.05661 iter/s, 24.6511s/100 iters), loss = 0.0454014
I1008 01:33:03.438881  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0454013 (* 1 = 0.0454013 loss)
I1008 01:33:03.438889  5299 sgd_solver.cpp:105] Iteration 46200, lr = 0.01
I1008 01:33:28.072415  5299 solver.cpp:218] Iteration 46300 (4.05952 iter/s, 24.6334s/100 iters), loss = 0.0736429
I1008 01:33:28.072518  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0736428 (* 1 = 0.0736428 loss)
I1008 01:33:28.072530  5299 sgd_solver.cpp:105] Iteration 46300, lr = 0.01
I1008 01:33:52.722684  5299 solver.cpp:218] Iteration 46400 (4.05679 iter/s, 24.65s/100 iters), loss = 0.0232571
I1008 01:33:52.722713  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0232571 (* 1 = 0.0232571 loss)
I1008 01:33:52.722720  5299 sgd_solver.cpp:105] Iteration 46400, lr = 0.01
I1008 01:34:16.841663  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:34:17.816359  5299 solver.cpp:330] Iteration 46500, Testing net (#0)
I1008 01:34:22.855110  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:34:23.094832  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9113
I1008 01:34:23.094857  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.300971 (* 1 = 0.300971 loss)
I1008 01:34:23.204218  5299 solver.cpp:218] Iteration 46500 (3.28069 iter/s, 30.4814s/100 iters), loss = 0.0190528
I1008 01:34:23.204252  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0190528 (* 1 = 0.0190528 loss)
I1008 01:34:23.204259  5299 sgd_solver.cpp:105] Iteration 46500, lr = 0.01
I1008 01:34:48.592833  5299 solver.cpp:218] Iteration 46600 (3.93945 iter/s, 25.3843s/100 iters), loss = 0.0772278
I1008 01:34:48.592922  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0772279 (* 1 = 0.0772279 loss)
I1008 01:34:48.592931  5299 sgd_solver.cpp:105] Iteration 46600, lr = 0.01
I1008 01:35:13.237416  5299 solver.cpp:218] Iteration 46700 (4.05772 iter/s, 24.6444s/100 iters), loss = 0.0326801
I1008 01:35:13.237458  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0326802 (* 1 = 0.0326802 loss)
I1008 01:35:13.237467  5299 sgd_solver.cpp:105] Iteration 46700, lr = 0.01
I1008 01:35:37.888284  5299 solver.cpp:218] Iteration 46800 (4.05668 iter/s, 24.6507s/100 iters), loss = 0.0314848
I1008 01:35:37.888360  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0314849 (* 1 = 0.0314849 loss)
I1008 01:35:37.888368  5299 sgd_solver.cpp:105] Iteration 46800, lr = 0.01
I1008 01:36:02.547193  5299 solver.cpp:218] Iteration 46900 (4.05537 iter/s, 24.6587s/100 iters), loss = 0.0224888
I1008 01:36:02.547233  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0224888 (* 1 = 0.0224888 loss)
I1008 01:36:02.547240  5299 sgd_solver.cpp:105] Iteration 46900, lr = 0.01
I1008 01:36:26.590759  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:36:27.574205  5299 solver.cpp:330] Iteration 47000, Testing net (#0)
I1008 01:36:32.653076  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:36:32.850769  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9142
I1008 01:36:32.850795  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.292492 (* 1 = 0.292492 loss)
I1008 01:36:33.088013  5299 solver.cpp:218] Iteration 47000 (3.27432 iter/s, 30.5407s/100 iters), loss = 0.0476703
I1008 01:36:33.088057  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0476703 (* 1 = 0.0476703 loss)
I1008 01:36:33.088076  5299 sgd_solver.cpp:105] Iteration 47000, lr = 0.01
I1008 01:36:58.430083  5299 solver.cpp:218] Iteration 47100 (3.94648 iter/s, 25.339s/100 iters), loss = 0.0476393
I1008 01:36:58.430161  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0476393 (* 1 = 0.0476393 loss)
I1008 01:36:58.430169  5299 sgd_solver.cpp:105] Iteration 47100, lr = 0.01
I1008 01:37:23.081761  5299 solver.cpp:218] Iteration 47200 (4.05656 iter/s, 24.6514s/100 iters), loss = 0.0416794
I1008 01:37:23.081794  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0416795 (* 1 = 0.0416795 loss)
I1008 01:37:23.081802  5299 sgd_solver.cpp:105] Iteration 47200, lr = 0.01
I1008 01:37:47.726989  5299 solver.cpp:218] Iteration 47300 (4.0576 iter/s, 24.6451s/100 iters), loss = 0.0298216
I1008 01:37:47.727102  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0298217 (* 1 = 0.0298217 loss)
I1008 01:37:47.727120  5299 sgd_solver.cpp:105] Iteration 47300, lr = 0.01
I1008 01:38:12.366892  5299 solver.cpp:218] Iteration 47400 (4.0585 iter/s, 24.6397s/100 iters), loss = 0.0633237
I1008 01:38:12.366937  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0633237 (* 1 = 0.0633237 loss)
I1008 01:38:12.366945  5299 sgd_solver.cpp:105] Iteration 47400, lr = 0.01
I1008 01:38:36.389775  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:38:37.366688  5299 solver.cpp:330] Iteration 47500, Testing net (#0)
I1008 01:38:42.399600  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:38:42.611124  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9187
I1008 01:38:42.611152  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.28058 (* 1 = 0.28058 loss)
I1008 01:38:42.776052  5299 solver.cpp:218] Iteration 47500 (3.2885 iter/s, 30.409s/100 iters), loss = 0.0212588
I1008 01:38:42.776087  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0212588 (* 1 = 0.0212588 loss)
I1008 01:38:42.776094  5299 sgd_solver.cpp:105] Iteration 47500, lr = 0.01
I1008 01:39:08.033504  5299 solver.cpp:218] Iteration 47600 (3.95925 iter/s, 25.2573s/100 iters), loss = 0.0549445
I1008 01:39:08.033586  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0549445 (* 1 = 0.0549445 loss)
I1008 01:39:08.033592  5299 sgd_solver.cpp:105] Iteration 47600, lr = 0.01
I1008 01:39:32.672536  5299 solver.cpp:218] Iteration 47700 (4.05864 iter/s, 24.6388s/100 iters), loss = 0.0699758
I1008 01:39:32.672572  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0699758 (* 1 = 0.0699758 loss)
I1008 01:39:32.672580  5299 sgd_solver.cpp:105] Iteration 47700, lr = 0.01
I1008 01:39:57.285452  5299 solver.cpp:218] Iteration 47800 (4.06293 iter/s, 24.6128s/100 iters), loss = 0.0313452
I1008 01:39:57.285539  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0313452 (* 1 = 0.0313452 loss)
I1008 01:39:57.285547  5299 sgd_solver.cpp:105] Iteration 47800, lr = 0.01
I1008 01:40:21.890153  5299 solver.cpp:218] Iteration 47900 (4.0643 iter/s, 24.6045s/100 iters), loss = 0.0174868
I1008 01:40:21.890197  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0174868 (* 1 = 0.0174868 loss)
I1008 01:40:21.890204  5299 sgd_solver.cpp:105] Iteration 47900, lr = 0.01
I1008 01:40:45.988961  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:40:46.974032  5299 solver.cpp:330] Iteration 48000, Testing net (#0)
I1008 01:40:52.095136  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:40:52.286590  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9104
I1008 01:40:52.286618  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.312119 (* 1 = 0.312119 loss)
I1008 01:40:52.483798  5299 solver.cpp:218] Iteration 48000 (3.26867 iter/s, 30.5935s/100 iters), loss = 0.0241109
I1008 01:40:52.483834  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0241109 (* 1 = 0.0241109 loss)
I1008 01:40:52.483855  5299 sgd_solver.cpp:105] Iteration 48000, lr = 0.01
I1008 01:41:17.850592  5299 solver.cpp:218] Iteration 48100 (3.94222 iter/s, 25.3664s/100 iters), loss = 0.0989462
I1008 01:41:17.850674  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0989462 (* 1 = 0.0989462 loss)
I1008 01:41:17.850682  5299 sgd_solver.cpp:105] Iteration 48100, lr = 0.01
I1008 01:41:42.500630  5299 solver.cpp:218] Iteration 48200 (4.05683 iter/s, 24.6498s/100 iters), loss = 0.0268104
I1008 01:41:42.500664  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0268105 (* 1 = 0.0268105 loss)
I1008 01:41:42.500671  5299 sgd_solver.cpp:105] Iteration 48200, lr = 0.01
I1008 01:42:07.150200  5299 solver.cpp:218] Iteration 48300 (4.05689 iter/s, 24.6494s/100 iters), loss = 0.0227481
I1008 01:42:07.150297  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0227481 (* 1 = 0.0227481 loss)
I1008 01:42:07.150312  5299 sgd_solver.cpp:105] Iteration 48300, lr = 0.01
I1008 01:42:31.769929  5299 solver.cpp:218] Iteration 48400 (4.06182 iter/s, 24.6195s/100 iters), loss = 0.023235
I1008 01:42:31.769965  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0232351 (* 1 = 0.0232351 loss)
I1008 01:42:31.769973  5299 sgd_solver.cpp:105] Iteration 48400, lr = 0.01
I1008 01:42:55.865056  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:42:56.847606  5299 solver.cpp:330] Iteration 48500, Testing net (#0)
I1008 01:43:01.944038  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:43:02.165776  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9148
I1008 01:43:02.165804  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.297315 (* 1 = 0.297315 loss)
I1008 01:43:02.357758  5299 solver.cpp:218] Iteration 48500 (3.26929 iter/s, 30.5877s/100 iters), loss = 0.0175629
I1008 01:43:02.357795  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.017563 (* 1 = 0.017563 loss)
I1008 01:43:02.357806  5299 sgd_solver.cpp:105] Iteration 48500, lr = 0.01
I1008 01:43:27.285492  5299 solver.cpp:218] Iteration 48600 (4.0123 iter/s, 24.9233s/100 iters), loss = 0.0365744
I1008 01:43:27.285571  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0365745 (* 1 = 0.0365745 loss)
I1008 01:43:27.285579  5299 sgd_solver.cpp:105] Iteration 48600, lr = 0.01
I1008 01:43:51.881625  5299 solver.cpp:218] Iteration 48700 (4.06572 iter/s, 24.5959s/100 iters), loss = 0.0500189
I1008 01:43:51.881661  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0500189 (* 1 = 0.0500189 loss)
I1008 01:43:51.881669  5299 sgd_solver.cpp:105] Iteration 48700, lr = 0.01
I1008 01:44:16.485318  5299 solver.cpp:218] Iteration 48800 (4.06445 iter/s, 24.6035s/100 iters), loss = 0.0326897
I1008 01:44:16.485383  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0326897 (* 1 = 0.0326897 loss)
I1008 01:44:16.485391  5299 sgd_solver.cpp:105] Iteration 48800, lr = 0.01
I1008 01:44:41.125689  5299 solver.cpp:218] Iteration 48900 (4.0584 iter/s, 24.6402s/100 iters), loss = 0.0307947
I1008 01:44:41.125725  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0307947 (* 1 = 0.0307947 loss)
I1008 01:44:41.125735  5299 sgd_solver.cpp:105] Iteration 48900, lr = 0.01
I1008 01:45:05.363796  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:45:06.346375  5299 solver.cpp:330] Iteration 49000, Testing net (#0)
I1008 01:45:11.504593  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:45:11.745741  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9162
I1008 01:45:11.745769  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.302247 (* 1 = 0.302247 loss)
I1008 01:45:11.904831  5299 solver.cpp:218] Iteration 49000 (3.24897 iter/s, 30.779s/100 iters), loss = 0.0605702
I1008 01:45:11.904865  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0605703 (* 1 = 0.0605703 loss)
I1008 01:45:11.904873  5299 sgd_solver.cpp:105] Iteration 49000, lr = 0.01
I1008 01:45:36.783637  5299 solver.cpp:218] Iteration 49100 (4.01985 iter/s, 24.8766s/100 iters), loss = 0.0447614
I1008 01:45:36.783715  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0447614 (* 1 = 0.0447614 loss)
I1008 01:45:36.783723  5299 sgd_solver.cpp:105] Iteration 49100, lr = 0.01
I1008 01:46:01.415124  5299 solver.cpp:218] Iteration 49200 (4.05988 iter/s, 24.6313s/100 iters), loss = 0.0354804
I1008 01:46:01.415156  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0354804 (* 1 = 0.0354804 loss)
I1008 01:46:01.415163  5299 sgd_solver.cpp:105] Iteration 49200, lr = 0.01
I1008 01:46:26.035778  5299 solver.cpp:218] Iteration 49300 (4.06166 iter/s, 24.6205s/100 iters), loss = 0.0310459
I1008 01:46:26.035897  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0310459 (* 1 = 0.0310459 loss)
I1008 01:46:26.035907  5299 sgd_solver.cpp:105] Iteration 49300, lr = 0.01
I1008 01:46:50.663869  5299 solver.cpp:218] Iteration 49400 (4.06044 iter/s, 24.6279s/100 iters), loss = 0.0376683
I1008 01:46:50.663906  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0376684 (* 1 = 0.0376684 loss)
I1008 01:46:50.663913  5299 sgd_solver.cpp:105] Iteration 49400, lr = 0.01
I1008 01:47:14.771078  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:47:15.742926  5299 solver.cpp:330] Iteration 49500, Testing net (#0)
I1008 01:47:21.005141  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:47:21.246258  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9126
I1008 01:47:21.246289  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.315937 (* 1 = 0.315937 loss)
I1008 01:47:21.415091  5299 solver.cpp:218] Iteration 49500 (3.25192 iter/s, 30.7511s/100 iters), loss = 0.0541403
I1008 01:47:21.415122  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0541404 (* 1 = 0.0541404 loss)
I1008 01:47:21.415129  5299 sgd_solver.cpp:105] Iteration 49500, lr = 0.01
I1008 01:47:46.347566  5299 solver.cpp:218] Iteration 49600 (4.0112 iter/s, 24.9302s/100 iters), loss = 0.0304085
I1008 01:47:46.347692  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0304085 (* 1 = 0.0304085 loss)
I1008 01:47:46.347700  5299 sgd_solver.cpp:105] Iteration 49600, lr = 0.01
I1008 01:48:10.960124  5299 solver.cpp:218] Iteration 49700 (4.063 iter/s, 24.6123s/100 iters), loss = 0.0180981
I1008 01:48:10.960160  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0180981 (* 1 = 0.0180981 loss)
I1008 01:48:10.960166  5299 sgd_solver.cpp:105] Iteration 49700, lr = 0.01
I1008 01:48:35.574424  5299 solver.cpp:218] Iteration 49800 (4.0627 iter/s, 24.6142s/100 iters), loss = 0.0293392
I1008 01:48:35.574509  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0293392 (* 1 = 0.0293392 loss)
I1008 01:48:35.574522  5299 sgd_solver.cpp:105] Iteration 49800, lr = 0.01
I1008 01:49:00.192126  5299 solver.cpp:218] Iteration 49900 (4.06215 iter/s, 24.6175s/100 iters), loss = 0.0138395
I1008 01:49:00.192162  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0138396 (* 1 = 0.0138396 loss)
I1008 01:49:00.192169  5299 sgd_solver.cpp:105] Iteration 49900, lr = 0.01
I1008 01:49:24.229440  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:49:25.200127  5299 solver.cpp:330] Iteration 50000, Testing net (#0)
I1008 01:49:30.423310  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:49:30.641844  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9143
I1008 01:49:30.641870  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.307116 (* 1 = 0.307116 loss)
I1008 01:49:30.802831  5299 solver.cpp:218] Iteration 50000 (3.26685 iter/s, 30.6106s/100 iters), loss = 0.0397655
I1008 01:49:30.802868  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0397655 (* 1 = 0.0397655 loss)
I1008 01:49:30.802878  5299 sgd_solver.cpp:105] Iteration 50000, lr = 0.01
I1008 01:49:55.613487  5299 solver.cpp:218] Iteration 50100 (4.03055 iter/s, 24.8105s/100 iters), loss = 0.0961115
I1008 01:49:55.613528  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0961116 (* 1 = 0.0961116 loss)
I1008 01:49:55.613539  5299 sgd_solver.cpp:105] Iteration 50100, lr = 0.01
I1008 01:50:20.256651  5299 solver.cpp:218] Iteration 50200 (4.05795 iter/s, 24.643s/100 iters), loss = 0.0390365
I1008 01:50:20.256688  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0390365 (* 1 = 0.0390365 loss)
I1008 01:50:20.256695  5299 sgd_solver.cpp:105] Iteration 50200, lr = 0.01
I1008 01:50:44.908640  5299 solver.cpp:218] Iteration 50300 (4.0565 iter/s, 24.6518s/100 iters), loss = 0.0225161
I1008 01:50:44.908766  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0225161 (* 1 = 0.0225161 loss)
I1008 01:50:44.908773  5299 sgd_solver.cpp:105] Iteration 50300, lr = 0.01
I1008 01:51:09.537503  5299 solver.cpp:218] Iteration 50400 (4.06031 iter/s, 24.6286s/100 iters), loss = 0.0179205
I1008 01:51:09.537528  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0179206 (* 1 = 0.0179206 loss)
I1008 01:51:09.537534  5299 sgd_solver.cpp:105] Iteration 50400, lr = 0.01
I1008 01:51:33.627787  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:51:34.627946  5299 solver.cpp:330] Iteration 50500, Testing net (#0)
I1008 01:51:39.964557  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:51:40.178707  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9145
I1008 01:51:40.178750  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.305821 (* 1 = 0.305821 loss)
I1008 01:51:40.391201  5299 solver.cpp:218] Iteration 50500 (3.24112 iter/s, 30.8535s/100 iters), loss = 0.014315
I1008 01:51:40.391237  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0143151 (* 1 = 0.0143151 loss)
I1008 01:51:40.391244  5299 sgd_solver.cpp:105] Iteration 50500, lr = 0.01
I1008 01:52:05.059923  5299 solver.cpp:218] Iteration 50600 (4.05441 iter/s, 24.6645s/100 iters), loss = 0.0710161
I1008 01:52:05.059988  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0710161 (* 1 = 0.0710161 loss)
I1008 01:52:05.060003  5299 sgd_solver.cpp:105] Iteration 50600, lr = 0.01
I1008 01:52:29.715580  5299 solver.cpp:218] Iteration 50700 (4.05589 iter/s, 24.6555s/100 iters), loss = 0.0544395
I1008 01:52:29.715612  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0544395 (* 1 = 0.0544395 loss)
I1008 01:52:29.715620  5299 sgd_solver.cpp:105] Iteration 50700, lr = 0.01
I1008 01:52:54.315950  5299 solver.cpp:218] Iteration 50800 (4.065 iter/s, 24.6002s/100 iters), loss = 0.0265465
I1008 01:52:54.316048  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0265465 (* 1 = 0.0265465 loss)
I1008 01:52:54.316059  5299 sgd_solver.cpp:105] Iteration 50800, lr = 0.01
I1008 01:53:18.976697  5299 solver.cpp:218] Iteration 50900 (4.05506 iter/s, 24.6605s/100 iters), loss = 0.00830444
I1008 01:53:18.976729  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00830453 (* 1 = 0.00830453 loss)
I1008 01:53:18.976737  5299 sgd_solver.cpp:105] Iteration 50900, lr = 0.01
I1008 01:53:43.001588  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:53:44.048013  5299 solver.cpp:330] Iteration 51000, Testing net (#0)
I1008 01:53:49.308502  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:53:49.543081  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9171
I1008 01:53:49.543108  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.30696 (* 1 = 0.30696 loss)
I1008 01:53:49.697154  5299 solver.cpp:218] Iteration 51000 (3.25518 iter/s, 30.7203s/100 iters), loss = 0.0158338
I1008 01:53:49.697191  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0158339 (* 1 = 0.0158339 loss)
I1008 01:53:49.697206  5299 sgd_solver.cpp:105] Iteration 51000, lr = 0.01
I1008 01:54:14.451484  5299 solver.cpp:218] Iteration 51100 (4.04041 iter/s, 24.75s/100 iters), loss = 0.0311674
I1008 01:54:14.451552  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0311675 (* 1 = 0.0311675 loss)
I1008 01:54:14.451565  5299 sgd_solver.cpp:105] Iteration 51100, lr = 0.01
I1008 01:54:39.263183  5299 solver.cpp:218] Iteration 51200 (4.03038 iter/s, 24.8115s/100 iters), loss = 0.014519
I1008 01:54:39.263222  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0145191 (* 1 = 0.0145191 loss)
I1008 01:54:39.263242  5299 sgd_solver.cpp:105] Iteration 51200, lr = 0.01
I1008 01:55:03.920817  5299 solver.cpp:218] Iteration 51300 (4.05556 iter/s, 24.6575s/100 iters), loss = 0.0138843
I1008 01:55:03.920924  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0138844 (* 1 = 0.0138844 loss)
I1008 01:55:03.920938  5299 sgd_solver.cpp:105] Iteration 51300, lr = 0.01
I1008 01:55:28.586536  5299 solver.cpp:218] Iteration 51400 (4.05425 iter/s, 24.6655s/100 iters), loss = 0.0344695
I1008 01:55:28.586589  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0344697 (* 1 = 0.0344697 loss)
I1008 01:55:28.586608  5299 sgd_solver.cpp:105] Iteration 51400, lr = 0.01
I1008 01:55:52.766860  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:55:53.843147  5299 solver.cpp:330] Iteration 51500, Testing net (#0)
I1008 01:55:59.085252  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:55:59.257060  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.915
I1008 01:55:59.257084  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.313909 (* 1 = 0.313909 loss)
I1008 01:55:59.456740  5299 solver.cpp:218] Iteration 51500 (3.23939 iter/s, 30.87s/100 iters), loss = 0.0278176
I1008 01:55:59.456771  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0278178 (* 1 = 0.0278178 loss)
I1008 01:55:59.456779  5299 sgd_solver.cpp:105] Iteration 51500, lr = 0.01
I1008 01:56:24.292290  5299 solver.cpp:218] Iteration 51600 (4.02685 iter/s, 24.8333s/100 iters), loss = 0.0355346
I1008 01:56:24.292372  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0355347 (* 1 = 0.0355347 loss)
I1008 01:56:24.292381  5299 sgd_solver.cpp:105] Iteration 51600, lr = 0.01
I1008 01:56:48.956707  5299 solver.cpp:218] Iteration 51700 (4.05446 iter/s, 24.6642s/100 iters), loss = 0.0433931
I1008 01:56:48.956738  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0433932 (* 1 = 0.0433932 loss)
I1008 01:56:48.956745  5299 sgd_solver.cpp:105] Iteration 51700, lr = 0.01
I1008 01:57:13.588726  5299 solver.cpp:218] Iteration 51800 (4.05978 iter/s, 24.6319s/100 iters), loss = 0.0224169
I1008 01:57:13.588804  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.022417 (* 1 = 0.022417 loss)
I1008 01:57:13.588812  5299 sgd_solver.cpp:105] Iteration 51800, lr = 0.01
I1008 01:57:38.241765  5299 solver.cpp:218] Iteration 51900 (4.05633 iter/s, 24.6528s/100 iters), loss = 0.00899004
I1008 01:57:38.241803  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00899023 (* 1 = 0.00899023 loss)
I1008 01:57:38.241811  5299 sgd_solver.cpp:105] Iteration 51900, lr = 0.01
I1008 01:58:02.396142  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:58:03.474618  5299 solver.cpp:330] Iteration 52000, Testing net (#0)
I1008 01:58:08.573771  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 01:58:08.793889  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9165
I1008 01:58:08.793917  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.311604 (* 1 = 0.311604 loss)
I1008 01:58:08.910403  5299 solver.cpp:218] Iteration 52000 (3.26068 iter/s, 30.6685s/100 iters), loss = 0.0400999
I1008 01:58:08.910436  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0401001 (* 1 = 0.0401001 loss)
I1008 01:58:08.910444  5299 sgd_solver.cpp:105] Iteration 52000, lr = 0.01
I1008 01:58:33.702244  5299 solver.cpp:218] Iteration 52100 (4.03395 iter/s, 24.7896s/100 iters), loss = 0.0322168
I1008 01:58:33.702316  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.032217 (* 1 = 0.032217 loss)
I1008 01:58:33.702328  5299 sgd_solver.cpp:105] Iteration 52100, lr = 0.01
I1008 01:58:58.318217  5299 solver.cpp:218] Iteration 52200 (4.06243 iter/s, 24.6158s/100 iters), loss = 0.0331184
I1008 01:58:58.318264  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0331185 (* 1 = 0.0331185 loss)
I1008 01:58:58.318271  5299 sgd_solver.cpp:105] Iteration 52200, lr = 0.01
I1008 01:59:22.940598  5299 solver.cpp:218] Iteration 52300 (4.06137 iter/s, 24.6222s/100 iters), loss = 0.0117965
I1008 01:59:22.940731  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0117966 (* 1 = 0.0117966 loss)
I1008 01:59:22.940738  5299 sgd_solver.cpp:105] Iteration 52300, lr = 0.01
I1008 01:59:47.557965  5299 solver.cpp:218] Iteration 52400 (4.06221 iter/s, 24.6171s/100 iters), loss = 0.0538279
I1008 01:59:47.558009  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.053828 (* 1 = 0.053828 loss)
I1008 01:59:47.558017  5299 sgd_solver.cpp:105] Iteration 52400, lr = 0.01
I1008 02:00:11.820845  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:00:12.894104  5299 solver.cpp:330] Iteration 52500, Testing net (#0)
I1008 02:00:18.010331  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:00:18.214084  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9147
I1008 02:00:18.214109  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.316864 (* 1 = 0.316864 loss)
I1008 02:00:18.390408  5299 solver.cpp:218] Iteration 52500 (3.24335 iter/s, 30.8323s/100 iters), loss = 0.0535988
I1008 02:00:18.390441  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.053599 (* 1 = 0.053599 loss)
I1008 02:00:18.390450  5299 sgd_solver.cpp:105] Iteration 52500, lr = 0.01
I1008 02:00:43.051255  5299 solver.cpp:218] Iteration 52600 (4.05538 iter/s, 24.6586s/100 iters), loss = 0.0289573
I1008 02:00:43.051337  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0289574 (* 1 = 0.0289574 loss)
I1008 02:00:43.051344  5299 sgd_solver.cpp:105] Iteration 52600, lr = 0.01
I1008 02:01:07.672183  5299 solver.cpp:218] Iteration 52700 (4.06162 iter/s, 24.6207s/100 iters), loss = 0.0236872
I1008 02:01:07.672219  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0236874 (* 1 = 0.0236874 loss)
I1008 02:01:07.672235  5299 sgd_solver.cpp:105] Iteration 52700, lr = 0.01
I1008 02:01:32.322842  5299 solver.cpp:218] Iteration 52800 (4.05671 iter/s, 24.6505s/100 iters), loss = 0.0155698
I1008 02:01:32.322937  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.01557 (* 1 = 0.01557 loss)
I1008 02:01:32.322943  5299 sgd_solver.cpp:105] Iteration 52800, lr = 0.01
I1008 02:01:56.990530  5299 solver.cpp:218] Iteration 52900 (4.05392 iter/s, 24.6675s/100 iters), loss = 0.0160417
I1008 02:01:56.990572  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0160419 (* 1 = 0.0160419 loss)
I1008 02:01:56.990579  5299 sgd_solver.cpp:105] Iteration 52900, lr = 0.01
I1008 02:02:21.350530  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:02:22.406824  5299 solver.cpp:330] Iteration 53000, Testing net (#0)
I1008 02:02:27.470237  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:02:27.631362  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9082
I1008 02:02:27.631392  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.336132 (* 1 = 0.336132 loss)
I1008 02:02:27.813433  5299 solver.cpp:218] Iteration 53000 (3.24436 iter/s, 30.8228s/100 iters), loss = 0.017904
I1008 02:02:27.813468  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0179042 (* 1 = 0.0179042 loss)
I1008 02:02:27.813475  5299 sgd_solver.cpp:105] Iteration 53000, lr = 0.01
I1008 02:02:52.587335  5299 solver.cpp:218] Iteration 53100 (4.03653 iter/s, 24.7738s/100 iters), loss = 0.0193781
I1008 02:02:52.587435  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0193782 (* 1 = 0.0193782 loss)
I1008 02:02:52.587450  5299 sgd_solver.cpp:105] Iteration 53100, lr = 0.01
I1008 02:03:17.208600  5299 solver.cpp:218] Iteration 53200 (4.06157 iter/s, 24.621s/100 iters), loss = 0.0178769
I1008 02:03:17.208636  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0178771 (* 1 = 0.0178771 loss)
I1008 02:03:17.208643  5299 sgd_solver.cpp:105] Iteration 53200, lr = 0.01
I1008 02:03:41.849339  5299 solver.cpp:218] Iteration 53300 (4.05834 iter/s, 24.6406s/100 iters), loss = 0.00828881
I1008 02:03:41.849447  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00828899 (* 1 = 0.00828899 loss)
I1008 02:03:41.849460  5299 sgd_solver.cpp:105] Iteration 53300, lr = 0.01
I1008 02:04:06.616917  5299 solver.cpp:218] Iteration 53400 (4.03757 iter/s, 24.7674s/100 iters), loss = 0.044753
I1008 02:04:06.616951  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0447532 (* 1 = 0.0447532 loss)
I1008 02:04:06.616960  5299 sgd_solver.cpp:105] Iteration 53400, lr = 0.01
I1008 02:04:31.045260  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:04:32.145417  5299 solver.cpp:330] Iteration 53500, Testing net (#0)
I1008 02:04:37.103744  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:04:37.263415  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9166
I1008 02:04:37.263444  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.30968 (* 1 = 0.30968 loss)
I1008 02:04:37.467799  5299 solver.cpp:218] Iteration 53500 (3.24164 iter/s, 30.8486s/100 iters), loss = 0.00899936
I1008 02:04:37.467840  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00899953 (* 1 = 0.00899953 loss)
I1008 02:04:37.467849  5299 sgd_solver.cpp:105] Iteration 53500, lr = 0.01
I1008 02:05:02.120584  5299 solver.cpp:218] Iteration 53600 (4.05636 iter/s, 24.6526s/100 iters), loss = 0.0432208
I1008 02:05:02.120654  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0432209 (* 1 = 0.0432209 loss)
I1008 02:05:02.120662  5299 sgd_solver.cpp:105] Iteration 53600, lr = 0.01
I1008 02:05:26.766315  5299 solver.cpp:218] Iteration 53700 (4.05752 iter/s, 24.6456s/100 iters), loss = 0.0488691
I1008 02:05:26.766350  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0488693 (* 1 = 0.0488693 loss)
I1008 02:05:26.766356  5299 sgd_solver.cpp:105] Iteration 53700, lr = 0.01
I1008 02:05:51.417872  5299 solver.cpp:218] Iteration 53800 (4.05656 iter/s, 24.6514s/100 iters), loss = 0.0346735
I1008 02:05:51.417950  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0346737 (* 1 = 0.0346737 loss)
I1008 02:05:51.417958  5299 sgd_solver.cpp:105] Iteration 53800, lr = 0.01
I1008 02:06:16.245564  5299 solver.cpp:218] Iteration 53900 (4.0278 iter/s, 24.8275s/100 iters), loss = 0.0207346
I1008 02:06:16.245600  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0207348 (* 1 = 0.0207348 loss)
I1008 02:06:16.245609  5299 sgd_solver.cpp:105] Iteration 53900, lr = 0.01
I1008 02:06:40.643695  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:06:41.639432  5299 solver.cpp:330] Iteration 54000, Testing net (#0)
I1008 02:06:46.593761  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:06:46.757663  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9135
I1008 02:06:46.757694  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.338127 (* 1 = 0.338127 loss)
I1008 02:06:46.957756  5299 solver.cpp:218] Iteration 54000 (3.25627 iter/s, 30.7099s/100 iters), loss = 0.00992413
I1008 02:06:46.957793  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00992431 (* 1 = 0.00992431 loss)
I1008 02:06:46.957803  5299 sgd_solver.cpp:105] Iteration 54000, lr = 0.01
I1008 02:07:11.775112  5299 solver.cpp:218] Iteration 54100 (4.02946 iter/s, 24.8172s/100 iters), loss = 0.0202158
I1008 02:07:11.775238  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0202159 (* 1 = 0.0202159 loss)
I1008 02:07:11.775250  5299 sgd_solver.cpp:105] Iteration 54100, lr = 0.01
I1008 02:07:36.428580  5299 solver.cpp:218] Iteration 54200 (4.05626 iter/s, 24.6532s/100 iters), loss = 0.0342832
I1008 02:07:36.428614  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0342833 (* 1 = 0.0342833 loss)
I1008 02:07:36.428622  5299 sgd_solver.cpp:105] Iteration 54200, lr = 0.01
I1008 02:08:01.074784  5299 solver.cpp:218] Iteration 54300 (4.05744 iter/s, 24.6461s/100 iters), loss = 0.0430734
I1008 02:08:01.074844  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0430736 (* 1 = 0.0430736 loss)
I1008 02:08:01.074851  5299 sgd_solver.cpp:105] Iteration 54300, lr = 0.01
I1008 02:08:25.977180  5299 solver.cpp:218] Iteration 54400 (4.0157 iter/s, 24.9023s/100 iters), loss = 0.010732
I1008 02:08:25.977213  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0107322 (* 1 = 0.0107322 loss)
I1008 02:08:25.977221  5299 sgd_solver.cpp:105] Iteration 54400, lr = 0.01
I1008 02:08:50.318575  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:08:51.238708  5299 solver.cpp:330] Iteration 54500, Testing net (#0)
I1008 02:08:56.172055  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:08:56.362879  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9096
I1008 02:08:56.362905  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.357238 (* 1 = 0.357238 loss)
I1008 02:08:56.602069  5299 solver.cpp:218] Iteration 54500 (3.26533 iter/s, 30.6247s/100 iters), loss = 0.0160908
I1008 02:08:56.602104  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.016091 (* 1 = 0.016091 loss)
I1008 02:08:56.602111  5299 sgd_solver.cpp:105] Iteration 54500, lr = 0.01
I1008 02:09:21.264955  5299 solver.cpp:218] Iteration 54600 (4.05512 iter/s, 24.6602s/100 iters), loss = 0.0199326
I1008 02:09:21.265025  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0199328 (* 1 = 0.0199328 loss)
I1008 02:09:21.265033  5299 sgd_solver.cpp:105] Iteration 54600, lr = 0.01
I1008 02:09:45.922941  5299 solver.cpp:218] Iteration 54700 (4.05551 iter/s, 24.6578s/100 iters), loss = 0.0290093
I1008 02:09:45.922976  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0290095 (* 1 = 0.0290095 loss)
I1008 02:09:45.922982  5299 sgd_solver.cpp:105] Iteration 54700, lr = 0.01
I1008 02:10:10.583686  5299 solver.cpp:218] Iteration 54800 (4.05505 iter/s, 24.6606s/100 iters), loss = 0.00681346
I1008 02:10:10.583757  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00681366 (* 1 = 0.00681366 loss)
I1008 02:10:10.583765  5299 sgd_solver.cpp:105] Iteration 54800, lr = 0.01
I1008 02:10:35.628157  5299 solver.cpp:218] Iteration 54900 (3.99292 iter/s, 25.0443s/100 iters), loss = 0.00267681
I1008 02:10:35.628196  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00267702 (* 1 = 0.00267702 loss)
I1008 02:10:35.628208  5299 sgd_solver.cpp:105] Iteration 54900, lr = 0.01
I1008 02:10:59.942072  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:11:00.921140  5299 solver.cpp:330] Iteration 55000, Testing net (#0)
I1008 02:11:05.811205  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:11:06.048033  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9136
I1008 02:11:06.048059  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.331811 (* 1 = 0.331811 loss)
I1008 02:11:06.216778  5299 solver.cpp:218] Iteration 55000 (3.26943 iter/s, 30.5864s/100 iters), loss = 0.0691408
I1008 02:11:06.216812  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.069141 (* 1 = 0.069141 loss)
I1008 02:11:06.216820  5299 sgd_solver.cpp:105] Iteration 55000, lr = 0.01
I1008 02:11:30.932965  5299 solver.cpp:218] Iteration 55100 (4.04664 iter/s, 24.7118s/100 iters), loss = 0.0227268
I1008 02:11:30.933040  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0227271 (* 1 = 0.0227271 loss)
I1008 02:11:30.933051  5299 sgd_solver.cpp:105] Iteration 55100, lr = 0.01
I1008 02:11:55.572921  5299 solver.cpp:218] Iteration 55200 (4.05849 iter/s, 24.6397s/100 iters), loss = 0.0660689
I1008 02:11:55.572963  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0660691 (* 1 = 0.0660691 loss)
I1008 02:11:55.572969  5299 sgd_solver.cpp:105] Iteration 55200, lr = 0.01
I1008 02:12:20.213845  5299 solver.cpp:218] Iteration 55300 (4.05831 iter/s, 24.6408s/100 iters), loss = 0.0208529
I1008 02:12:20.213922  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0208531 (* 1 = 0.0208531 loss)
I1008 02:12:20.213930  5299 sgd_solver.cpp:105] Iteration 55300, lr = 0.01
I1008 02:12:45.371064  5299 solver.cpp:218] Iteration 55400 (3.97504 iter/s, 25.157s/100 iters), loss = 0.0049955
I1008 02:12:45.371099  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00499575 (* 1 = 0.00499575 loss)
I1008 02:12:45.371106  5299 sgd_solver.cpp:105] Iteration 55400, lr = 0.01
I1008 02:13:09.585095  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:13:10.561202  5299 solver.cpp:330] Iteration 55500, Testing net (#0)
I1008 02:13:15.485280  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:13:15.695467  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9109
I1008 02:13:15.695510  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.333998 (* 1 = 0.333998 loss)
I1008 02:13:15.858508  5299 solver.cpp:218] Iteration 55500 (3.28028 iter/s, 30.4852s/100 iters), loss = 0.00666956
I1008 02:13:15.858548  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00666982 (* 1 = 0.00666982 loss)
I1008 02:13:15.858554  5299 sgd_solver.cpp:105] Iteration 55500, lr = 0.01
I1008 02:13:40.744061  5299 solver.cpp:218] Iteration 55600 (4.01876 iter/s, 24.8833s/100 iters), loss = 0.0201714
I1008 02:13:40.744190  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0201716 (* 1 = 0.0201716 loss)
I1008 02:13:40.744215  5299 sgd_solver.cpp:105] Iteration 55600, lr = 0.01
I1008 02:14:05.382838  5299 solver.cpp:218] Iteration 55700 (4.05868 iter/s, 24.6385s/100 iters), loss = 0.0169462
I1008 02:14:05.382874  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0169464 (* 1 = 0.0169464 loss)
I1008 02:14:05.382880  5299 sgd_solver.cpp:105] Iteration 55700, lr = 0.01
I1008 02:14:30.028110  5299 solver.cpp:218] Iteration 55800 (4.0576 iter/s, 24.6451s/100 iters), loss = 0.0369875
I1008 02:14:30.028182  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0369877 (* 1 = 0.0369877 loss)
I1008 02:14:30.028189  5299 sgd_solver.cpp:105] Iteration 55800, lr = 0.01
I1008 02:14:55.258935  5299 solver.cpp:218] Iteration 55900 (3.96343 iter/s, 25.2307s/100 iters), loss = 0.00178501
I1008 02:14:55.258972  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00178527 (* 1 = 0.00178527 loss)
I1008 02:14:55.258980  5299 sgd_solver.cpp:105] Iteration 55900, lr = 0.01
I1008 02:15:19.485857  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:15:20.469518  5299 solver.cpp:330] Iteration 56000, Testing net (#0)
I1008 02:15:25.437433  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:15:25.593109  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9131
I1008 02:15:25.593138  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.334716 (* 1 = 0.334716 loss)
I1008 02:15:25.835245  5299 solver.cpp:218] Iteration 56000 (3.27075 iter/s, 30.5741s/100 iters), loss = 0.0188117
I1008 02:15:25.835283  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0188119 (* 1 = 0.0188119 loss)
I1008 02:15:25.835302  5299 sgd_solver.cpp:105] Iteration 56000, lr = 0.01
I1008 02:15:50.479518  5299 solver.cpp:218] Iteration 56100 (4.05776 iter/s, 24.6441s/100 iters), loss = 0.0101482
I1008 02:15:50.479589  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0101485 (* 1 = 0.0101485 loss)
I1008 02:15:50.479604  5299 sgd_solver.cpp:105] Iteration 56100, lr = 0.01
I1008 02:16:15.110658  5299 solver.cpp:218] Iteration 56200 (4.05993 iter/s, 24.631s/100 iters), loss = 0.0286906
I1008 02:16:15.110692  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0286909 (* 1 = 0.0286909 loss)
I1008 02:16:15.110702  5299 sgd_solver.cpp:105] Iteration 56200, lr = 0.01
I1008 02:16:39.755187  5299 solver.cpp:218] Iteration 56300 (4.05772 iter/s, 24.6444s/100 iters), loss = 0.00383795
I1008 02:16:39.755269  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00383821 (* 1 = 0.00383821 loss)
I1008 02:16:39.755281  5299 sgd_solver.cpp:105] Iteration 56300, lr = 0.01
I1008 02:17:04.922901  5299 solver.cpp:218] Iteration 56400 (3.97338 iter/s, 25.1675s/100 iters), loss = 0.027789
I1008 02:17:04.922936  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0277893 (* 1 = 0.0277893 loss)
I1008 02:17:04.922945  5299 sgd_solver.cpp:105] Iteration 56400, lr = 0.01
I1008 02:17:29.146952  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:17:30.133826  5299 solver.cpp:330] Iteration 56500, Testing net (#0)
I1008 02:17:35.117525  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:17:35.276901  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9134
I1008 02:17:35.276937  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.336165 (* 1 = 0.336165 loss)
I1008 02:17:35.487649  5299 solver.cpp:218] Iteration 56500 (3.27198 iter/s, 30.5625s/100 iters), loss = 0.0227027
I1008 02:17:35.487686  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0227029 (* 1 = 0.0227029 loss)
I1008 02:17:35.487694  5299 sgd_solver.cpp:105] Iteration 56500, lr = 0.01
I1008 02:18:00.128386  5299 solver.cpp:218] Iteration 56600 (4.0587 iter/s, 24.6384s/100 iters), loss = 0.0133304
I1008 02:18:00.128466  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0133307 (* 1 = 0.0133307 loss)
I1008 02:18:00.128474  5299 sgd_solver.cpp:105] Iteration 56600, lr = 0.01
I1008 02:18:24.743463  5299 solver.cpp:218] Iteration 56700 (4.06259 iter/s, 24.6149s/100 iters), loss = 0.0343911
I1008 02:18:24.743499  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0343913 (* 1 = 0.0343913 loss)
I1008 02:18:24.743505  5299 sgd_solver.cpp:105] Iteration 56700, lr = 0.01
I1008 02:18:49.345372  5299 solver.cpp:218] Iteration 56800 (4.06475 iter/s, 24.6018s/100 iters), loss = 0.00398404
I1008 02:18:49.345480  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0039843 (* 1 = 0.0039843 loss)
I1008 02:18:49.345494  5299 sgd_solver.cpp:105] Iteration 56800, lr = 0.01
I1008 02:19:14.588865  5299 solver.cpp:218] Iteration 56900 (3.96145 iter/s, 25.2433s/100 iters), loss = 0.0111269
I1008 02:19:14.588901  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0111271 (* 1 = 0.0111271 loss)
I1008 02:19:14.588907  5299 sgd_solver.cpp:105] Iteration 56900, lr = 0.01
I1008 02:19:38.655911  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:19:39.603641  5299 solver.cpp:330] Iteration 57000, Testing net (#0)
I1008 02:19:44.547683  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:19:44.754637  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9145
I1008 02:19:44.754673  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.335855 (* 1 = 0.335855 loss)
I1008 02:19:44.883702  5299 solver.cpp:218] Iteration 57000 (3.30091 iter/s, 30.2947s/100 iters), loss = 0.0151519
I1008 02:19:44.883734  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0151521 (* 1 = 0.0151521 loss)
I1008 02:19:44.883741  5299 sgd_solver.cpp:105] Iteration 57000, lr = 0.01
I1008 02:20:09.648347  5299 solver.cpp:218] Iteration 57100 (4.03838 iter/s, 24.7624s/100 iters), loss = 0.0282076
I1008 02:20:09.648432  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0282079 (* 1 = 0.0282079 loss)
I1008 02:20:09.648445  5299 sgd_solver.cpp:105] Iteration 57100, lr = 0.01
I1008 02:20:34.286700  5299 solver.cpp:218] Iteration 57200 (4.05875 iter/s, 24.6381s/100 iters), loss = 0.0209165
I1008 02:20:34.286736  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0209168 (* 1 = 0.0209168 loss)
I1008 02:20:34.286743  5299 sgd_solver.cpp:105] Iteration 57200, lr = 0.01
I1008 02:20:58.929543  5299 solver.cpp:218] Iteration 57300 (4.058 iter/s, 24.6427s/100 iters), loss = 0.0146466
I1008 02:20:58.929625  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0146469 (* 1 = 0.0146469 loss)
I1008 02:20:58.929641  5299 sgd_solver.cpp:105] Iteration 57300, lr = 0.01
I1008 02:21:24.167798  5299 solver.cpp:218] Iteration 57400 (3.96227 iter/s, 25.238s/100 iters), loss = 0.0279935
I1008 02:21:24.167834  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0279938 (* 1 = 0.0279938 loss)
I1008 02:21:24.167841  5299 sgd_solver.cpp:105] Iteration 57400, lr = 0.01
I1008 02:21:48.241087  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:21:49.212642  5299 solver.cpp:330] Iteration 57500, Testing net (#0)
I1008 02:21:54.103045  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:21:54.277253  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9126
I1008 02:21:54.277281  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.348169 (* 1 = 0.348169 loss)
I1008 02:21:54.448935  5299 solver.cpp:218] Iteration 57500 (3.3024 iter/s, 30.281s/100 iters), loss = 0.0487977
I1008 02:21:54.448966  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.048798 (* 1 = 0.048798 loss)
I1008 02:21:54.448973  5299 sgd_solver.cpp:105] Iteration 57500, lr = 0.01
I1008 02:22:19.233371  5299 solver.cpp:218] Iteration 57600 (4.03482 iter/s, 24.7843s/100 iters), loss = 0.0166838
I1008 02:22:19.233474  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.016684 (* 1 = 0.016684 loss)
I1008 02:22:19.233492  5299 sgd_solver.cpp:105] Iteration 57600, lr = 0.01
I1008 02:22:43.885305  5299 solver.cpp:218] Iteration 57700 (4.05651 iter/s, 24.6517s/100 iters), loss = 0.00978785
I1008 02:22:43.885346  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00978814 (* 1 = 0.00978814 loss)
I1008 02:22:43.885354  5299 sgd_solver.cpp:105] Iteration 57700, lr = 0.01
I1008 02:23:08.540345  5299 solver.cpp:218] Iteration 57800 (4.05599 iter/s, 24.6549s/100 iters), loss = 0.0136165
I1008 02:23:08.540437  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0136168 (* 1 = 0.0136168 loss)
I1008 02:23:08.540454  5299 sgd_solver.cpp:105] Iteration 57800, lr = 0.01
I1008 02:23:33.748461  5299 solver.cpp:218] Iteration 57900 (3.96701 iter/s, 25.2079s/100 iters), loss = 0.00200159
I1008 02:23:33.748493  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00200188 (* 1 = 0.00200188 loss)
I1008 02:23:33.748500  5299 sgd_solver.cpp:105] Iteration 57900, lr = 0.01
I1008 02:23:57.825486  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:23:58.801116  5299 solver.cpp:330] Iteration 58000, Testing net (#0)
I1008 02:24:03.882021  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:24:04.079627  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9097
I1008 02:24:04.079653  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.362934 (* 1 = 0.362934 loss)
I1008 02:24:04.311285  5299 solver.cpp:218] Iteration 58000 (3.27243 iter/s, 30.5584s/100 iters), loss = 0.01456
I1008 02:24:04.311321  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0145602 (* 1 = 0.0145602 loss)
I1008 02:24:04.311327  5299 sgd_solver.cpp:105] Iteration 58000, lr = 0.01
I1008 02:24:28.981858  5299 solver.cpp:218] Iteration 58100 (4.05379 iter/s, 24.6683s/100 iters), loss = 0.0567845
I1008 02:24:28.981932  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0567847 (* 1 = 0.0567847 loss)
I1008 02:24:28.981940  5299 sgd_solver.cpp:105] Iteration 58100, lr = 0.01
I1008 02:24:53.643157  5299 solver.cpp:218] Iteration 58200 (4.05497 iter/s, 24.6611s/100 iters), loss = 0.0224247
I1008 02:24:53.643189  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.022425 (* 1 = 0.022425 loss)
I1008 02:24:53.643196  5299 sgd_solver.cpp:105] Iteration 58200, lr = 0.01
I1008 02:25:18.308838  5299 solver.cpp:218] Iteration 58300 (4.05424 iter/s, 24.6655s/100 iters), loss = 0.0127496
I1008 02:25:18.308919  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0127499 (* 1 = 0.0127499 loss)
I1008 02:25:18.308928  5299 sgd_solver.cpp:105] Iteration 58300, lr = 0.01
I1008 02:25:43.659139  5299 solver.cpp:218] Iteration 58400 (3.94476 iter/s, 25.3501s/100 iters), loss = 0.00731651
I1008 02:25:43.659174  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00731679 (* 1 = 0.00731679 loss)
I1008 02:25:43.659181  5299 sgd_solver.cpp:105] Iteration 58400, lr = 0.01
I1008 02:26:07.793503  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:26:08.771908  5299 solver.cpp:330] Iteration 58500, Testing net (#0)
I1008 02:26:13.843570  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:26:14.038893  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9155
I1008 02:26:14.038929  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.322594 (* 1 = 0.322594 loss)
I1008 02:26:14.280334  5299 solver.cpp:218] Iteration 58500 (3.26573 iter/s, 30.621s/100 iters), loss = 0.00374285
I1008 02:26:14.280380  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00374313 (* 1 = 0.00374313 loss)
I1008 02:26:14.280387  5299 sgd_solver.cpp:105] Iteration 58500, lr = 0.01
I1008 02:26:38.926930  5299 solver.cpp:218] Iteration 58600 (4.05738 iter/s, 24.6464s/100 iters), loss = 0.0635211
I1008 02:26:38.927012  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0635214 (* 1 = 0.0635214 loss)
I1008 02:26:38.927021  5299 sgd_solver.cpp:105] Iteration 58600, lr = 0.01
I1008 02:27:03.582428  5299 solver.cpp:218] Iteration 58700 (4.05593 iter/s, 24.6553s/100 iters), loss = 0.00497448
I1008 02:27:03.582458  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00497477 (* 1 = 0.00497477 loss)
I1008 02:27:03.582464  5299 sgd_solver.cpp:105] Iteration 58700, lr = 0.01
I1008 02:27:28.215283  5299 solver.cpp:218] Iteration 58800 (4.05964 iter/s, 24.6327s/100 iters), loss = 0.0351184
I1008 02:27:28.215371  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0351187 (* 1 = 0.0351187 loss)
I1008 02:27:28.215394  5299 sgd_solver.cpp:105] Iteration 58800, lr = 0.01
I1008 02:27:53.558640  5299 solver.cpp:218] Iteration 58900 (3.94584 iter/s, 25.3431s/100 iters), loss = 0.0146815
I1008 02:27:53.558678  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0146818 (* 1 = 0.0146818 loss)
I1008 02:27:53.558687  5299 sgd_solver.cpp:105] Iteration 58900, lr = 0.01
I1008 02:28:17.495551  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:28:18.477574  5299 solver.cpp:330] Iteration 59000, Testing net (#0)
I1008 02:28:23.512670  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:28:23.752687  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9087
I1008 02:28:23.752714  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.361202 (* 1 = 0.361202 loss)
I1008 02:28:23.859467  5299 solver.cpp:218] Iteration 59000 (3.30026 iter/s, 30.3007s/100 iters), loss = 0.0205391
I1008 02:28:23.859504  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0205393 (* 1 = 0.0205393 loss)
I1008 02:28:23.859513  5299 sgd_solver.cpp:105] Iteration 59000, lr = 0.01
I1008 02:28:48.643504  5299 solver.cpp:218] Iteration 59100 (4.03557 iter/s, 24.7797s/100 iters), loss = 0.0254443
I1008 02:28:48.643586  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0254445 (* 1 = 0.0254445 loss)
I1008 02:28:48.643595  5299 sgd_solver.cpp:105] Iteration 59100, lr = 0.01
I1008 02:29:13.285640  5299 solver.cpp:218] Iteration 59200 (4.05813 iter/s, 24.6419s/100 iters), loss = 0.007806
I1008 02:29:13.285676  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00780627 (* 1 = 0.00780627 loss)
I1008 02:29:13.285682  5299 sgd_solver.cpp:105] Iteration 59200, lr = 0.01
I1008 02:29:37.926434  5299 solver.cpp:218] Iteration 59300 (4.05834 iter/s, 24.6406s/100 iters), loss = 0.0108459
I1008 02:29:37.926511  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0108462 (* 1 = 0.0108462 loss)
I1008 02:29:37.926517  5299 sgd_solver.cpp:105] Iteration 59300, lr = 0.01
I1008 02:30:03.255885  5299 solver.cpp:218] Iteration 59400 (3.94801 iter/s, 25.3292s/100 iters), loss = 0.00668163
I1008 02:30:03.255929  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00668192 (* 1 = 0.00668192 loss)
I1008 02:30:03.255936  5299 sgd_solver.cpp:105] Iteration 59400, lr = 0.01
I1008 02:30:27.189177  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:30:28.172394  5299 solver.cpp:330] Iteration 59500, Testing net (#0)
I1008 02:30:33.210805  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:30:33.402869  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.916
I1008 02:30:33.402915  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.334158 (* 1 = 0.334158 loss)
I1008 02:30:33.537923  5299 solver.cpp:218] Iteration 59500 (3.3023 iter/s, 30.2819s/100 iters), loss = 0.0189344
I1008 02:30:33.537953  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0189347 (* 1 = 0.0189347 loss)
I1008 02:30:33.537969  5299 sgd_solver.cpp:105] Iteration 59500, lr = 0.01
I1008 02:30:58.310706  5299 solver.cpp:218] Iteration 59600 (4.03671 iter/s, 24.7726s/100 iters), loss = 0.00512499
I1008 02:30:58.310809  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00512527 (* 1 = 0.00512527 loss)
I1008 02:30:58.310819  5299 sgd_solver.cpp:105] Iteration 59600, lr = 0.01
I1008 02:31:22.960652  5299 solver.cpp:218] Iteration 59700 (4.05684 iter/s, 24.6497s/100 iters), loss = 0.0239241
I1008 02:31:22.960687  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0239244 (* 1 = 0.0239244 loss)
I1008 02:31:22.960705  5299 sgd_solver.cpp:105] Iteration 59700, lr = 0.01
I1008 02:31:47.620187  5299 solver.cpp:218] Iteration 59800 (4.05525 iter/s, 24.6594s/100 iters), loss = 0.0382872
I1008 02:31:47.620266  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0382875 (* 1 = 0.0382875 loss)
I1008 02:31:47.620278  5299 sgd_solver.cpp:105] Iteration 59800, lr = 0.01
I1008 02:32:12.899312  5299 solver.cpp:218] Iteration 59900 (3.95587 iter/s, 25.2789s/100 iters), loss = 0.00696513
I1008 02:32:12.899345  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00696541 (* 1 = 0.00696541 loss)
I1008 02:32:12.899354  5299 sgd_solver.cpp:105] Iteration 59900, lr = 0.01
I1008 02:32:37.004276  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:32:37.985741  5299 solver.cpp:330] Iteration 60000, Testing net (#0)
I1008 02:32:42.853548  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:32:43.077482  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9137
I1008 02:32:43.077508  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.338452 (* 1 = 0.338452 loss)
I1008 02:32:43.183034  5299 solver.cpp:218] Iteration 60000 (3.30212 iter/s, 30.2836s/100 iters), loss = 0.00313211
I1008 02:32:43.183063  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0031324 (* 1 = 0.0031324 loss)
I1008 02:32:43.183084  5299 sgd_solver.cpp:105] Iteration 60000, lr = 0.01
I1008 02:33:07.967648  5299 solver.cpp:218] Iteration 60100 (4.03479 iter/s, 24.7845s/100 iters), loss = 0.0134436
I1008 02:33:07.967775  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0134439 (* 1 = 0.0134439 loss)
I1008 02:33:07.967783  5299 sgd_solver.cpp:105] Iteration 60100, lr = 0.01
I1008 02:33:32.605949  5299 solver.cpp:218] Iteration 60200 (4.05876 iter/s, 24.6381s/100 iters), loss = 0.0347098
I1008 02:33:32.605993  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0347101 (* 1 = 0.0347101 loss)
I1008 02:33:32.605999  5299 sgd_solver.cpp:105] Iteration 60200, lr = 0.01
I1008 02:33:57.239114  5299 solver.cpp:218] Iteration 60300 (4.05959 iter/s, 24.633s/100 iters), loss = 0.0152641
I1008 02:33:57.239194  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0152644 (* 1 = 0.0152644 loss)
I1008 02:33:57.239202  5299 sgd_solver.cpp:105] Iteration 60300, lr = 0.01
I1008 02:34:22.475837  5299 solver.cpp:218] Iteration 60400 (3.96251 iter/s, 25.2365s/100 iters), loss = 0.00873201
I1008 02:34:22.475872  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00873231 (* 1 = 0.00873231 loss)
I1008 02:34:22.475879  5299 sgd_solver.cpp:105] Iteration 60400, lr = 0.01
I1008 02:34:46.538067  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:34:47.498395  5299 solver.cpp:330] Iteration 60500, Testing net (#0)
I1008 02:34:52.519944  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:34:52.709535  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9138
I1008 02:34:52.709563  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.352751 (* 1 = 0.352751 loss)
I1008 02:34:52.847815  5299 solver.cpp:218] Iteration 60500 (3.29253 iter/s, 30.3718s/100 iters), loss = 0.0432758
I1008 02:34:52.847846  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0432761 (* 1 = 0.0432761 loss)
I1008 02:34:52.847852  5299 sgd_solver.cpp:105] Iteration 60500, lr = 0.01
I1008 02:35:17.615525  5299 solver.cpp:218] Iteration 60600 (4.03754 iter/s, 24.7676s/100 iters), loss = 0.017801
I1008 02:35:17.615608  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0178013 (* 1 = 0.0178013 loss)
I1008 02:35:17.615617  5299 sgd_solver.cpp:105] Iteration 60600, lr = 0.01
I1008 02:35:42.261502  5299 solver.cpp:218] Iteration 60700 (4.05749 iter/s, 24.6458s/100 iters), loss = 0.0227431
I1008 02:35:42.261538  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0227434 (* 1 = 0.0227434 loss)
I1008 02:35:42.261545  5299 sgd_solver.cpp:105] Iteration 60700, lr = 0.01
I1008 02:36:06.884842  5299 solver.cpp:218] Iteration 60800 (4.06121 iter/s, 24.6232s/100 iters), loss = 0.00479932
I1008 02:36:06.884922  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00479961 (* 1 = 0.00479961 loss)
I1008 02:36:06.884928  5299 sgd_solver.cpp:105] Iteration 60800, lr = 0.01
I1008 02:36:32.118312  5299 solver.cpp:218] Iteration 60900 (3.96303 iter/s, 25.2332s/100 iters), loss = 0.009285
I1008 02:36:32.118345  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0092853 (* 1 = 0.0092853 loss)
I1008 02:36:32.118351  5299 sgd_solver.cpp:105] Iteration 60900, lr = 0.01
I1008 02:36:56.175586  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:36:57.143795  5299 solver.cpp:330] Iteration 61000, Testing net (#0)
I1008 02:37:02.179702  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:37:02.420590  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9114
I1008 02:37:02.420617  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.36678 (* 1 = 0.36678 loss)
I1008 02:37:02.590390  5299 solver.cpp:218] Iteration 61000 (3.28171 iter/s, 30.4719s/100 iters), loss = 0.00368145
I1008 02:37:02.590423  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00368175 (* 1 = 0.00368175 loss)
I1008 02:37:02.590431  5299 sgd_solver.cpp:105] Iteration 61000, lr = 0.01
I1008 02:37:27.299729  5299 solver.cpp:218] Iteration 61100 (4.04776 iter/s, 24.705s/100 iters), loss = 0.00553446
I1008 02:37:27.299810  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00553477 (* 1 = 0.00553477 loss)
I1008 02:37:27.299818  5299 sgd_solver.cpp:105] Iteration 61100, lr = 0.01
I1008 02:37:51.949215  5299 solver.cpp:218] Iteration 61200 (4.05692 iter/s, 24.6493s/100 iters), loss = 0.0126392
I1008 02:37:51.949249  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0126395 (* 1 = 0.0126395 loss)
I1008 02:37:51.949255  5299 sgd_solver.cpp:105] Iteration 61200, lr = 0.01
I1008 02:38:16.598202  5299 solver.cpp:218] Iteration 61300 (4.05699 iter/s, 24.6488s/100 iters), loss = 0.00510964
I1008 02:38:16.598280  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00510994 (* 1 = 0.00510994 loss)
I1008 02:38:16.598287  5299 sgd_solver.cpp:105] Iteration 61300, lr = 0.01
I1008 02:38:41.859258  5299 solver.cpp:218] Iteration 61400 (3.9587 iter/s, 25.2608s/100 iters), loss = 0.0064193
I1008 02:38:41.859292  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0064196 (* 1 = 0.0064196 loss)
I1008 02:38:41.859299  5299 sgd_solver.cpp:105] Iteration 61400, lr = 0.01
I1008 02:39:05.960223  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:39:06.939556  5299 solver.cpp:330] Iteration 61500, Testing net (#0)
I1008 02:39:11.915380  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:39:12.072788  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9124
I1008 02:39:12.072818  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.356285 (* 1 = 0.356285 loss)
I1008 02:39:12.303508  5299 solver.cpp:218] Iteration 61500 (3.28471 iter/s, 30.4441s/100 iters), loss = 0.0091684
I1008 02:39:12.303551  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0091687 (* 1 = 0.0091687 loss)
I1008 02:39:12.303558  5299 sgd_solver.cpp:105] Iteration 61500, lr = 0.01
I1008 02:39:36.946089  5299 solver.cpp:218] Iteration 61600 (4.05804 iter/s, 24.6424s/100 iters), loss = 0.0188936
I1008 02:39:36.946172  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0188939 (* 1 = 0.0188939 loss)
I1008 02:39:36.946180  5299 sgd_solver.cpp:105] Iteration 61600, lr = 0.01
I1008 02:40:01.576455  5299 solver.cpp:218] Iteration 61700 (4.06007 iter/s, 24.6301s/100 iters), loss = 0.00614976
I1008 02:40:01.576486  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00615006 (* 1 = 0.00615006 loss)
I1008 02:40:01.576493  5299 sgd_solver.cpp:105] Iteration 61700, lr = 0.01
I1008 02:40:26.215376  5299 solver.cpp:218] Iteration 61800 (4.05864 iter/s, 24.6388s/100 iters), loss = 0.00358358
I1008 02:40:26.215476  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00358389 (* 1 = 0.00358389 loss)
I1008 02:40:26.215484  5299 sgd_solver.cpp:105] Iteration 61800, lr = 0.01
I1008 02:40:51.451185  5299 solver.cpp:218] Iteration 61900 (3.96266 iter/s, 25.2356s/100 iters), loss = 0.0179043
I1008 02:40:51.451221  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0179047 (* 1 = 0.0179047 loss)
I1008 02:40:51.451227  5299 sgd_solver.cpp:105] Iteration 61900, lr = 0.01
I1008 02:41:15.446672  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:41:16.428297  5299 solver.cpp:330] Iteration 62000, Testing net (#0)
I1008 02:41:21.297901  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:41:21.539384  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9142
I1008 02:41:21.539420  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.346253 (* 1 = 0.346253 loss)
I1008 02:41:21.657006  5299 solver.cpp:218] Iteration 62000 (3.31064 iter/s, 30.2057s/100 iters), loss = 0.0127655
I1008 02:41:21.657053  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0127658 (* 1 = 0.0127658 loss)
I1008 02:41:21.657061  5299 sgd_solver.cpp:105] Iteration 62000, lr = 0.01
I1008 02:41:46.420400  5299 solver.cpp:218] Iteration 62100 (4.03894 iter/s, 24.759s/100 iters), loss = 0.0170555
I1008 02:41:46.420473  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0170558 (* 1 = 0.0170558 loss)
I1008 02:41:46.420481  5299 sgd_solver.cpp:105] Iteration 62100, lr = 0.01
I1008 02:42:11.063702  5299 solver.cpp:218] Iteration 62200 (4.05792 iter/s, 24.6432s/100 iters), loss = 0.00974123
I1008 02:42:11.063747  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00974154 (* 1 = 0.00974154 loss)
I1008 02:42:11.063753  5299 sgd_solver.cpp:105] Iteration 62200, lr = 0.01
I1008 02:42:35.712019  5299 solver.cpp:218] Iteration 62300 (4.0571 iter/s, 24.6482s/100 iters), loss = 0.00892775
I1008 02:42:35.712128  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00892807 (* 1 = 0.00892807 loss)
I1008 02:42:35.712138  5299 sgd_solver.cpp:105] Iteration 62300, lr = 0.01
I1008 02:43:00.957064  5299 solver.cpp:218] Iteration 62400 (3.96121 iter/s, 25.2448s/100 iters), loss = 0.0085295
I1008 02:43:00.957109  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00852982 (* 1 = 0.00852982 loss)
I1008 02:43:00.957116  5299 sgd_solver.cpp:105] Iteration 62400, lr = 0.01
I1008 02:43:24.999563  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:43:25.968443  5299 solver.cpp:330] Iteration 62500, Testing net (#0)
I1008 02:43:30.915812  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:43:31.082237  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9108
I1008 02:43:31.082267  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.367488 (* 1 = 0.367488 loss)
I1008 02:43:31.319635  5299 solver.cpp:218] Iteration 62500 (3.29355 iter/s, 30.3624s/100 iters), loss = 0.00494201
I1008 02:43:31.319674  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00494232 (* 1 = 0.00494232 loss)
I1008 02:43:31.319681  5299 sgd_solver.cpp:105] Iteration 62500, lr = 0.01
I1008 02:43:55.937631  5299 solver.cpp:218] Iteration 62600 (4.06209 iter/s, 24.6178s/100 iters), loss = 0.00702098
I1008 02:43:55.937722  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0070213 (* 1 = 0.0070213 loss)
I1008 02:43:55.937731  5299 sgd_solver.cpp:105] Iteration 62600, lr = 0.01
I1008 02:44:20.587776  5299 solver.cpp:218] Iteration 62700 (4.05681 iter/s, 24.6499s/100 iters), loss = 0.0216734
I1008 02:44:20.587808  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0216738 (* 1 = 0.0216738 loss)
I1008 02:44:20.587815  5299 sgd_solver.cpp:105] Iteration 62700, lr = 0.01
I1008 02:44:45.225697  5299 solver.cpp:218] Iteration 62800 (4.05881 iter/s, 24.6378s/100 iters), loss = 0.0041338
I1008 02:44:45.225767  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00413413 (* 1 = 0.00413413 loss)
I1008 02:44:45.225775  5299 sgd_solver.cpp:105] Iteration 62800, lr = 0.01
I1008 02:45:10.496489  5299 solver.cpp:218] Iteration 62900 (3.95716 iter/s, 25.2706s/100 iters), loss = 0.00192804
I1008 02:45:10.496531  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00192837 (* 1 = 0.00192837 loss)
I1008 02:45:10.496537  5299 sgd_solver.cpp:105] Iteration 62900, lr = 0.01
I1008 02:45:34.633534  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:45:35.601042  5299 solver.cpp:330] Iteration 63000, Testing net (#0)
I1008 02:45:40.608670  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:45:40.770928  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9097
I1008 02:45:40.770957  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.367189 (* 1 = 0.367189 loss)
I1008 02:45:40.958489  5299 solver.cpp:218] Iteration 63000 (3.2828 iter/s, 30.4618s/100 iters), loss = 0.0187108
I1008 02:45:40.958524  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0187111 (* 1 = 0.0187111 loss)
I1008 02:45:40.958530  5299 sgd_solver.cpp:105] Iteration 63000, lr = 0.01
I1008 02:46:05.596762  5299 solver.cpp:218] Iteration 63100 (4.05875 iter/s, 24.6381s/100 iters), loss = 0.0266147
I1008 02:46:05.596854  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0266151 (* 1 = 0.0266151 loss)
I1008 02:46:05.596863  5299 sgd_solver.cpp:105] Iteration 63100, lr = 0.01
I1008 02:46:30.255203  5299 solver.cpp:218] Iteration 63200 (4.05544 iter/s, 24.6582s/100 iters), loss = 0.0110999
I1008 02:46:30.255236  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0111003 (* 1 = 0.0111003 loss)
I1008 02:46:30.255244  5299 sgd_solver.cpp:105] Iteration 63200, lr = 0.01
I1008 02:46:54.896239  5299 solver.cpp:218] Iteration 63300 (4.0583 iter/s, 24.6409s/100 iters), loss = 0.00449373
I1008 02:46:54.896315  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00449404 (* 1 = 0.00449404 loss)
I1008 02:46:54.896323  5299 sgd_solver.cpp:105] Iteration 63300, lr = 0.01
I1008 02:47:20.150604  5299 solver.cpp:218] Iteration 63400 (3.95975 iter/s, 25.2541s/100 iters), loss = 0.00534714
I1008 02:47:20.150645  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00534745 (* 1 = 0.00534745 loss)
I1008 02:47:20.150650  5299 sgd_solver.cpp:105] Iteration 63400, lr = 0.01
I1008 02:47:44.278483  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:47:45.262107  5299 solver.cpp:330] Iteration 63500, Testing net (#0)
I1008 02:47:50.286052  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:47:50.526551  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9129
I1008 02:47:50.526576  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.36398 (* 1 = 0.36398 loss)
I1008 02:47:50.697840  5299 solver.cpp:218] Iteration 63500 (3.27364 iter/s, 30.5471s/100 iters), loss = 0.00535568
I1008 02:47:50.697885  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.005356 (* 1 = 0.005356 loss)
I1008 02:47:50.697893  5299 sgd_solver.cpp:105] Iteration 63500, lr = 0.01
I1008 02:48:15.405519  5299 solver.cpp:218] Iteration 63600 (4.04805 iter/s, 24.7033s/100 iters), loss = 0.0207783
I1008 02:48:15.405623  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0207786 (* 1 = 0.0207786 loss)
I1008 02:48:15.405632  5299 sgd_solver.cpp:105] Iteration 63600, lr = 0.01
I1008 02:48:40.053490  5299 solver.cpp:218] Iteration 63700 (4.05717 iter/s, 24.6478s/100 iters), loss = 0.0132178
I1008 02:48:40.053524  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0132181 (* 1 = 0.0132181 loss)
I1008 02:48:40.053541  5299 sgd_solver.cpp:105] Iteration 63700, lr = 0.01
I1008 02:49:04.681686  5299 solver.cpp:218] Iteration 63800 (4.06041 iter/s, 24.628s/100 iters), loss = 0.0158085
I1008 02:49:04.681789  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0158088 (* 1 = 0.0158088 loss)
I1008 02:49:04.681803  5299 sgd_solver.cpp:105] Iteration 63800, lr = 0.01
I1008 02:49:29.825793  5299 solver.cpp:218] Iteration 63900 (3.97711 iter/s, 25.1439s/100 iters), loss = 0.00360962
I1008 02:49:29.825826  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00360992 (* 1 = 0.00360992 loss)
I1008 02:49:29.825835  5299 sgd_solver.cpp:105] Iteration 63900, lr = 0.01
I1008 02:49:53.916359  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:49:54.895956  5299 solver.cpp:330] Iteration 64000, Testing net (#0)
I1008 02:49:59.929498  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:50:00.086119  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9079
I1008 02:50:00.086148  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.3894 (* 1 = 0.3894 loss)
I1008 02:50:00.259495  5299 solver.cpp:218] Iteration 64000 (3.28585 iter/s, 30.4335s/100 iters), loss = 0.00337673
I1008 02:50:00.259529  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00337704 (* 1 = 0.00337704 loss)
I1008 02:50:00.259537  5299 sgd_solver.cpp:105] Iteration 64000, lr = 0.01
I1008 02:50:24.909759  5299 solver.cpp:218] Iteration 64100 (4.05678 iter/s, 24.6501s/100 iters), loss = 0.0105047
I1008 02:50:24.909837  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.010505 (* 1 = 0.010505 loss)
I1008 02:50:24.909844  5299 sgd_solver.cpp:105] Iteration 64100, lr = 0.01
I1008 02:50:49.557950  5299 solver.cpp:218] Iteration 64200 (4.05713 iter/s, 24.648s/100 iters), loss = 0.00646572
I1008 02:50:49.557983  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00646604 (* 1 = 0.00646604 loss)
I1008 02:50:49.557991  5299 sgd_solver.cpp:105] Iteration 64200, lr = 0.01
I1008 02:51:14.209563  5299 solver.cpp:218] Iteration 64300 (4.05655 iter/s, 24.6515s/100 iters), loss = 0.00716021
I1008 02:51:14.209642  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00716053 (* 1 = 0.00716053 loss)
I1008 02:51:14.209650  5299 sgd_solver.cpp:105] Iteration 64300, lr = 0.01
I1008 02:51:39.495842  5299 solver.cpp:218] Iteration 64400 (3.95475 iter/s, 25.2861s/100 iters), loss = 0.0347119
I1008 02:51:39.495874  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0347122 (* 1 = 0.0347122 loss)
I1008 02:51:39.495882  5299 sgd_solver.cpp:105] Iteration 64400, lr = 0.01
I1008 02:52:03.487233  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:52:04.469252  5299 solver.cpp:330] Iteration 64500, Testing net (#0)
I1008 02:52:09.483273  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:52:09.639744  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.913
I1008 02:52:09.639782  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.354238 (* 1 = 0.354238 loss)
I1008 02:52:09.833417  5299 solver.cpp:218] Iteration 64500 (3.29649 iter/s, 30.3353s/100 iters), loss = 0.0255312
I1008 02:52:09.833461  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0255315 (* 1 = 0.0255315 loss)
I1008 02:52:09.833467  5299 sgd_solver.cpp:105] Iteration 64500, lr = 0.01
I1008 02:52:34.461597  5299 solver.cpp:218] Iteration 64600 (4.06041 iter/s, 24.628s/100 iters), loss = 0.00987494
I1008 02:52:34.461711  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00987526 (* 1 = 0.00987526 loss)
I1008 02:52:34.461719  5299 sgd_solver.cpp:105] Iteration 64600, lr = 0.01
I1008 02:52:59.112915  5299 solver.cpp:218] Iteration 64700 (4.05662 iter/s, 24.6511s/100 iters), loss = 0.00708007
I1008 02:52:59.112957  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00708038 (* 1 = 0.00708038 loss)
I1008 02:52:59.112963  5299 sgd_solver.cpp:105] Iteration 64700, lr = 0.01
I1008 02:53:23.768781  5299 solver.cpp:218] Iteration 64800 (4.05586 iter/s, 24.6557s/100 iters), loss = 0.00646102
I1008 02:53:23.768869  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00646134 (* 1 = 0.00646134 loss)
I1008 02:53:23.768877  5299 sgd_solver.cpp:105] Iteration 64800, lr = 0.01
I1008 02:53:49.251127  5299 solver.cpp:218] Iteration 64900 (3.92432 iter/s, 25.4821s/100 iters), loss = 0.0148601
I1008 02:53:49.251173  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0148604 (* 1 = 0.0148604 loss)
I1008 02:53:49.251180  5299 sgd_solver.cpp:105] Iteration 64900, lr = 0.01
I1008 02:54:13.145295  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:54:14.126905  5299 solver.cpp:330] Iteration 65000, Testing net (#0)
I1008 02:54:19.046178  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:54:19.243824  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9132
I1008 02:54:19.243851  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.339475 (* 1 = 0.339475 loss)
I1008 02:54:19.480681  5299 solver.cpp:218] Iteration 65000 (3.30804 iter/s, 30.2294s/100 iters), loss = 0.015741
I1008 02:54:19.480715  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0157413 (* 1 = 0.0157413 loss)
I1008 02:54:19.480723  5299 sgd_solver.cpp:105] Iteration 65000, lr = 0.01
I1008 02:54:44.105098  5299 solver.cpp:218] Iteration 65100 (4.06167 iter/s, 24.6204s/100 iters), loss = 0.00813042
I1008 02:54:44.105172  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00813074 (* 1 = 0.00813074 loss)
I1008 02:54:44.105185  5299 sgd_solver.cpp:105] Iteration 65100, lr = 0.01
I1008 02:55:08.743500  5299 solver.cpp:218] Iteration 65200 (4.05873 iter/s, 24.6383s/100 iters), loss = 0.00700197
I1008 02:55:08.743537  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00700228 (* 1 = 0.00700228 loss)
I1008 02:55:08.743546  5299 sgd_solver.cpp:105] Iteration 65200, lr = 0.01
I1008 02:55:33.392154  5299 solver.cpp:218] Iteration 65300 (4.05704 iter/s, 24.6485s/100 iters), loss = 0.0050566
I1008 02:55:33.392235  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0050569 (* 1 = 0.0050569 loss)
I1008 02:55:33.392247  5299 sgd_solver.cpp:105] Iteration 65300, lr = 0.01
I1008 02:55:58.953379  5299 solver.cpp:218] Iteration 65400 (3.91221 iter/s, 25.561s/100 iters), loss = 0.00560237
I1008 02:55:58.953418  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00560268 (* 1 = 0.00560268 loss)
I1008 02:55:58.953428  5299 sgd_solver.cpp:105] Iteration 65400, lr = 0.01
I1008 02:56:22.652379  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:56:23.639025  5299 solver.cpp:330] Iteration 65500, Testing net (#0)
I1008 02:56:28.546645  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:56:28.757668  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9153
I1008 02:56:28.757697  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.337424 (* 1 = 0.337424 loss)
I1008 02:56:28.949571  5299 solver.cpp:218] Iteration 65500 (3.33401 iter/s, 29.9939s/100 iters), loss = 0.00128806
I1008 02:56:28.949610  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00128837 (* 1 = 0.00128837 loss)
I1008 02:56:28.949620  5299 sgd_solver.cpp:105] Iteration 65500, lr = 0.01
I1008 02:56:53.627934  5299 solver.cpp:218] Iteration 65600 (4.05285 iter/s, 24.674s/100 iters), loss = 0.00872341
I1008 02:56:53.628062  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00872371 (* 1 = 0.00872371 loss)
I1008 02:56:53.628070  5299 sgd_solver.cpp:105] Iteration 65600, lr = 0.01
I1008 02:57:18.248617  5299 solver.cpp:218] Iteration 65700 (4.06167 iter/s, 24.6204s/100 iters), loss = 0.0169962
I1008 02:57:18.248656  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0169965 (* 1 = 0.0169965 loss)
I1008 02:57:18.248664  5299 sgd_solver.cpp:105] Iteration 65700, lr = 0.01
I1008 02:57:42.863996  5299 solver.cpp:218] Iteration 65800 (4.06252 iter/s, 24.6152s/100 iters), loss = 0.00983683
I1008 02:57:42.864075  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00983713 (* 1 = 0.00983713 loss)
I1008 02:57:42.864085  5299 sgd_solver.cpp:105] Iteration 65800, lr = 0.01
I1008 02:58:08.453003  5299 solver.cpp:218] Iteration 65900 (3.90796 iter/s, 25.5888s/100 iters), loss = 0.0138863
I1008 02:58:08.453038  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0138866 (* 1 = 0.0138866 loss)
I1008 02:58:08.453047  5299 sgd_solver.cpp:105] Iteration 65900, lr = 0.01
I1008 02:58:32.068058  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:58:33.050246  5299 solver.cpp:330] Iteration 66000, Testing net (#0)
I1008 02:58:38.086539  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 02:58:38.327985  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9123
I1008 02:58:38.328011  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.365907 (* 1 = 0.365907 loss)
I1008 02:58:38.469288  5299 solver.cpp:218] Iteration 66000 (3.33178 iter/s, 30.014s/100 iters), loss = 0.0113586
I1008 02:58:38.469319  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0113589 (* 1 = 0.0113589 loss)
I1008 02:58:38.469326  5299 sgd_solver.cpp:105] Iteration 66000, lr = 0.01
I1008 02:59:03.230239  5299 solver.cpp:218] Iteration 66100 (4.03933 iter/s, 24.7566s/100 iters), loss = 0.0547017
I1008 02:59:03.230319  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.054702 (* 1 = 0.054702 loss)
I1008 02:59:03.230327  5299 sgd_solver.cpp:105] Iteration 66100, lr = 0.01
I1008 02:59:27.882714  5299 solver.cpp:218] Iteration 66200 (4.05642 iter/s, 24.6523s/100 iters), loss = 0.0248452
I1008 02:59:27.882745  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0248455 (* 1 = 0.0248455 loss)
I1008 02:59:27.882751  5299 sgd_solver.cpp:105] Iteration 66200, lr = 0.01
I1008 02:59:52.539747  5299 solver.cpp:218] Iteration 66300 (4.05566 iter/s, 24.6569s/100 iters), loss = 0.0358826
I1008 02:59:52.539844  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0358829 (* 1 = 0.0358829 loss)
I1008 02:59:52.539855  5299 sgd_solver.cpp:105] Iteration 66300, lr = 0.01
I1008 03:00:18.271754  5299 solver.cpp:218] Iteration 66400 (3.88624 iter/s, 25.7318s/100 iters), loss = 0.00449893
I1008 03:00:18.271786  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00449923 (* 1 = 0.00449923 loss)
I1008 03:00:18.271793  5299 sgd_solver.cpp:105] Iteration 66400, lr = 0.01
I1008 03:00:41.743999  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:00:42.729521  5299 solver.cpp:330] Iteration 66500, Testing net (#0)
I1008 03:00:47.640625  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:00:47.842089  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9119
I1008 03:00:47.842118  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.360218 (* 1 = 0.360218 loss)
I1008 03:00:48.065438  5299 solver.cpp:218] Iteration 66500 (3.35643 iter/s, 29.7935s/100 iters), loss = 0.00518546
I1008 03:00:48.065474  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00518577 (* 1 = 0.00518577 loss)
I1008 03:00:48.065481  5299 sgd_solver.cpp:105] Iteration 66500, lr = 0.01
I1008 03:01:12.701697  5299 solver.cpp:218] Iteration 66600 (4.05979 iter/s, 24.6318s/100 iters), loss = 0.00818413
I1008 03:01:12.701799  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00818444 (* 1 = 0.00818444 loss)
I1008 03:01:12.701807  5299 sgd_solver.cpp:105] Iteration 66600, lr = 0.01
I1008 03:01:37.321424  5299 solver.cpp:218] Iteration 66700 (4.06182 iter/s, 24.6195s/100 iters), loss = 0.0136004
I1008 03:01:37.321461  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0136007 (* 1 = 0.0136007 loss)
I1008 03:01:37.321470  5299 sgd_solver.cpp:105] Iteration 66700, lr = 0.01
I1008 03:02:01.933020  5299 solver.cpp:218] Iteration 66800 (4.06315 iter/s, 24.6115s/100 iters), loss = 0.0198634
I1008 03:02:01.933076  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0198637 (* 1 = 0.0198637 loss)
I1008 03:02:01.933084  5299 sgd_solver.cpp:105] Iteration 66800, lr = 0.01
I1008 03:02:27.567133  5299 solver.cpp:218] Iteration 66900 (3.90107 iter/s, 25.634s/100 iters), loss = 0.0174543
I1008 03:02:27.567167  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0174546 (* 1 = 0.0174546 loss)
I1008 03:02:27.567175  5299 sgd_solver.cpp:105] Iteration 66900, lr = 0.01
I1008 03:02:51.099145  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:02:52.065965  5299 solver.cpp:330] Iteration 67000, Testing net (#0)
I1008 03:02:57.120826  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:02:57.339217  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9111
I1008 03:02:57.339244  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.366275 (* 1 = 0.366275 loss)
I1008 03:02:57.544692  5299 solver.cpp:218] Iteration 67000 (3.33608 iter/s, 29.9753s/100 iters), loss = 0.00277911
I1008 03:02:57.544724  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00277939 (* 1 = 0.00277939 loss)
I1008 03:02:57.544731  5299 sgd_solver.cpp:105] Iteration 67000, lr = 0.01
I1008 03:03:22.232241  5299 solver.cpp:218] Iteration 67100 (4.05134 iter/s, 24.6832s/100 iters), loss = 0.0171515
I1008 03:03:22.232445  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0171518 (* 1 = 0.0171518 loss)
I1008 03:03:22.232456  5299 sgd_solver.cpp:105] Iteration 67100, lr = 0.01
I1008 03:03:46.891505  5299 solver.cpp:218] Iteration 67200 (4.05532 iter/s, 24.659s/100 iters), loss = 0.0161597
I1008 03:03:46.891536  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.01616 (* 1 = 0.01616 loss)
I1008 03:03:46.891543  5299 sgd_solver.cpp:105] Iteration 67200, lr = 0.01
I1008 03:04:11.535898  5299 solver.cpp:218] Iteration 67300 (4.05774 iter/s, 24.6442s/100 iters), loss = 0.00206854
I1008 03:04:11.536001  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00206883 (* 1 = 0.00206883 loss)
I1008 03:04:11.536012  5299 sgd_solver.cpp:105] Iteration 67300, lr = 0.01
I1008 03:04:37.355933  5299 solver.cpp:218] Iteration 67400 (3.87331 iter/s, 25.8177s/100 iters), loss = 0.0147651
I1008 03:04:37.355965  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0147654 (* 1 = 0.0147654 loss)
I1008 03:04:37.355973  5299 sgd_solver.cpp:105] Iteration 67400, lr = 0.01
I1008 03:05:00.910980  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:05:01.895498  5299 solver.cpp:330] Iteration 67500, Testing net (#0)
I1008 03:05:06.970679  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:05:07.167860  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9095
I1008 03:05:07.167886  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.38277 (* 1 = 0.38277 loss)
I1008 03:05:07.410152  5299 solver.cpp:218] Iteration 67500 (3.32757 iter/s, 30.0519s/100 iters), loss = 0.00706999
I1008 03:05:07.410188  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00707027 (* 1 = 0.00707027 loss)
I1008 03:05:07.410195  5299 sgd_solver.cpp:105] Iteration 67500, lr = 0.01
I1008 03:05:32.044512  5299 solver.cpp:218] Iteration 67600 (4.05939 iter/s, 24.6342s/100 iters), loss = 0.00872252
I1008 03:05:32.044600  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00872279 (* 1 = 0.00872279 loss)
I1008 03:05:32.044607  5299 sgd_solver.cpp:105] Iteration 67600, lr = 0.01
I1008 03:05:56.669708  5299 solver.cpp:218] Iteration 67700 (4.06092 iter/s, 24.625s/100 iters), loss = 0.0152079
I1008 03:05:56.669751  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0152081 (* 1 = 0.0152081 loss)
I1008 03:05:56.669759  5299 sgd_solver.cpp:105] Iteration 67700, lr = 0.01
I1008 03:06:21.441920  5299 solver.cpp:218] Iteration 67800 (4.0368 iter/s, 24.7721s/100 iters), loss = 0.00902294
I1008 03:06:21.441994  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00902321 (* 1 = 0.00902321 loss)
I1008 03:06:21.442004  5299 sgd_solver.cpp:105] Iteration 67800, lr = 0.01
I1008 03:06:47.059784  5299 solver.cpp:218] Iteration 67900 (3.90355 iter/s, 25.6177s/100 iters), loss = 0.00545716
I1008 03:06:47.059816  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00545743 (* 1 = 0.00545743 loss)
I1008 03:06:47.059823  5299 sgd_solver.cpp:105] Iteration 67900, lr = 0.01
I1008 03:07:10.617602  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:07:11.600922  5299 solver.cpp:330] Iteration 68000, Testing net (#0)
I1008 03:07:16.563383  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:07:16.733016  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9121
I1008 03:07:16.733048  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.355116 (* 1 = 0.355116 loss)
I1008 03:07:16.964654  5299 solver.cpp:218] Iteration 68000 (3.34395 iter/s, 29.9047s/100 iters), loss = 0.00284692
I1008 03:07:16.964689  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00284719 (* 1 = 0.00284719 loss)
I1008 03:07:16.964696  5299 sgd_solver.cpp:105] Iteration 68000, lr = 0.01
I1008 03:07:41.581539  5299 solver.cpp:218] Iteration 68100 (4.06228 iter/s, 24.6167s/100 iters), loss = 0.030825
I1008 03:07:41.581619  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0308252 (* 1 = 0.0308252 loss)
I1008 03:07:41.581626  5299 sgd_solver.cpp:105] Iteration 68100, lr = 0.01
I1008 03:08:06.198293  5299 solver.cpp:218] Iteration 68200 (4.06231 iter/s, 24.6165s/100 iters), loss = 0.00318214
I1008 03:08:06.198328  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00318241 (* 1 = 0.00318241 loss)
I1008 03:08:06.198334  5299 sgd_solver.cpp:105] Iteration 68200, lr = 0.01
I1008 03:08:31.079051  5299 solver.cpp:218] Iteration 68300 (4.01919 iter/s, 24.8806s/100 iters), loss = 0.0344055
I1008 03:08:31.079124  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0344058 (* 1 = 0.0344058 loss)
I1008 03:08:31.079133  5299 sgd_solver.cpp:105] Iteration 68300, lr = 0.01
I1008 03:08:56.786566  5299 solver.cpp:218] Iteration 68400 (3.89025 iter/s, 25.7053s/100 iters), loss = 0.00727258
I1008 03:08:56.786602  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00727285 (* 1 = 0.00727285 loss)
I1008 03:08:56.786612  5299 sgd_solver.cpp:105] Iteration 68400, lr = 0.01
I1008 03:09:20.211355  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:09:21.166061  5299 solver.cpp:330] Iteration 68500, Testing net (#0)
I1008 03:09:26.064447  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:09:26.287456  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9141
I1008 03:09:26.287492  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.364073 (* 1 = 0.364073 loss)
I1008 03:09:26.491873  5299 solver.cpp:218] Iteration 68500 (3.36642 iter/s, 29.7052s/100 iters), loss = 0.00603967
I1008 03:09:26.491919  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00603994 (* 1 = 0.00603994 loss)
I1008 03:09:26.491925  5299 sgd_solver.cpp:105] Iteration 68500, lr = 0.01
I1008 03:09:51.345820  5299 solver.cpp:218] Iteration 68600 (4.02421 iter/s, 24.8496s/100 iters), loss = 0.00836372
I1008 03:09:51.345922  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00836399 (* 1 = 0.00836399 loss)
I1008 03:09:51.345932  5299 sgd_solver.cpp:105] Iteration 68600, lr = 0.01
I1008 03:10:16.144052  5299 solver.cpp:218] Iteration 68700 (4.03258 iter/s, 24.798s/100 iters), loss = 0.00894954
I1008 03:10:16.144093  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0089498 (* 1 = 0.0089498 loss)
I1008 03:10:16.144099  5299 sgd_solver.cpp:105] Iteration 68700, lr = 0.01
I1008 03:10:41.398555  5299 solver.cpp:218] Iteration 68800 (3.96005 iter/s, 25.2522s/100 iters), loss = 0.00526576
I1008 03:10:41.398650  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00526602 (* 1 = 0.00526602 loss)
I1008 03:10:41.398674  5299 sgd_solver.cpp:105] Iteration 68800, lr = 0.01
I1008 03:11:06.758416  5299 solver.cpp:218] Iteration 68900 (3.94327 iter/s, 25.3597s/100 iters), loss = 0.0180944
I1008 03:11:06.758452  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0180946 (* 1 = 0.0180946 loss)
I1008 03:11:06.758461  5299 sgd_solver.cpp:105] Iteration 68900, lr = 0.01
I1008 03:11:30.328582  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:11:31.300472  5299 solver.cpp:330] Iteration 69000, Testing net (#0)
I1008 03:11:36.208588  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:11:36.416499  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9138
I1008 03:11:36.416527  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.357303 (* 1 = 0.357303 loss)
I1008 03:11:36.616811  5299 solver.cpp:218] Iteration 69000 (3.34916 iter/s, 29.8582s/100 iters), loss = 0.00201381
I1008 03:11:36.616844  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00201406 (* 1 = 0.00201406 loss)
I1008 03:11:36.616852  5299 sgd_solver.cpp:105] Iteration 69000, lr = 0.01
I1008 03:12:01.316010  5299 solver.cpp:218] Iteration 69100 (4.04943 iter/s, 24.6948s/100 iters), loss = 0.00706503
I1008 03:12:01.316097  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00706528 (* 1 = 0.00706528 loss)
I1008 03:12:01.316104  5299 sgd_solver.cpp:105] Iteration 69100, lr = 0.01
I1008 03:12:25.970719  5299 solver.cpp:218] Iteration 69200 (4.05606 iter/s, 24.6545s/100 iters), loss = 0.0260674
I1008 03:12:25.970762  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0260676 (* 1 = 0.0260676 loss)
I1008 03:12:25.970767  5299 sgd_solver.cpp:105] Iteration 69200, lr = 0.01
I1008 03:12:51.166749  5299 solver.cpp:218] Iteration 69300 (3.9689 iter/s, 25.1959s/100 iters), loss = 0.0132491
I1008 03:12:51.166844  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0132493 (* 1 = 0.0132493 loss)
I1008 03:12:51.166854  5299 sgd_solver.cpp:105] Iteration 69300, lr = 0.01
I1008 03:13:16.572162  5299 solver.cpp:218] Iteration 69400 (3.93684 iter/s, 25.4011s/100 iters), loss = 0.0276571
I1008 03:13:16.572196  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0276573 (* 1 = 0.0276573 loss)
I1008 03:13:16.572201  5299 sgd_solver.cpp:105] Iteration 69400, lr = 0.01
I1008 03:13:40.005920  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:13:40.988899  5299 solver.cpp:330] Iteration 69500, Testing net (#0)
I1008 03:13:45.870836  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:13:46.107265  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9103
I1008 03:13:46.107291  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.377615 (* 1 = 0.377615 loss)
I1008 03:13:46.278601  5299 solver.cpp:218] Iteration 69500 (3.36629 iter/s, 29.7063s/100 iters), loss = 0.00299766
I1008 03:13:46.278648  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0029979 (* 1 = 0.0029979 loss)
I1008 03:13:46.278656  5299 sgd_solver.cpp:105] Iteration 69500, lr = 0.01
I1008 03:14:11.002125  5299 solver.cpp:218] Iteration 69600 (4.04545 iter/s, 24.7191s/100 iters), loss = 0.0149605
I1008 03:14:11.002195  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0149607 (* 1 = 0.0149607 loss)
I1008 03:14:11.002202  5299 sgd_solver.cpp:105] Iteration 69600, lr = 0.01
I1008 03:14:35.641006  5299 solver.cpp:218] Iteration 69700 (4.05865 iter/s, 24.6387s/100 iters), loss = 0.0578749
I1008 03:14:35.641038  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0578751 (* 1 = 0.0578751 loss)
I1008 03:14:35.641044  5299 sgd_solver.cpp:105] Iteration 69700, lr = 0.01
I1008 03:15:00.901996  5299 solver.cpp:218] Iteration 69800 (3.9587 iter/s, 25.2608s/100 iters), loss = 0.0032855
I1008 03:15:00.902074  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00328575 (* 1 = 0.00328575 loss)
I1008 03:15:00.902082  5299 sgd_solver.cpp:105] Iteration 69800, lr = 0.01
I1008 03:15:26.139328  5299 solver.cpp:218] Iteration 69900 (3.96242 iter/s, 25.2371s/100 iters), loss = 0.0100675
I1008 03:15:26.139358  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0100677 (* 1 = 0.0100677 loss)
I1008 03:15:26.139364  5299 sgd_solver.cpp:105] Iteration 69900, lr = 0.01
I1008 03:15:49.561782  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:15:50.544495  5299 solver.cpp:330] Iteration 70000, Testing net (#0)
I1008 03:15:55.434826  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:15:55.665988  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9102
I1008 03:15:55.666018  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.384308 (* 1 = 0.384308 loss)
I1008 03:15:55.845747  5299 solver.cpp:218] Iteration 70000 (3.36629 iter/s, 29.7063s/100 iters), loss = 0.00332158
I1008 03:15:55.845782  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00332182 (* 1 = 0.00332182 loss)
I1008 03:15:55.845800  5299 sgd_solver.cpp:105] Iteration 70000, lr = 0.01
I1008 03:16:20.563905  5299 solver.cpp:218] Iteration 70100 (4.04633 iter/s, 24.7138s/100 iters), loss = 0.0415412
I1008 03:16:20.563999  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0415414 (* 1 = 0.0415414 loss)
I1008 03:16:20.564023  5299 sgd_solver.cpp:105] Iteration 70100, lr = 0.01
I1008 03:16:45.202111  5299 solver.cpp:218] Iteration 70200 (4.05877 iter/s, 24.638s/100 iters), loss = 0.0338775
I1008 03:16:45.202149  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0338777 (* 1 = 0.0338777 loss)
I1008 03:16:45.202160  5299 sgd_solver.cpp:105] Iteration 70200, lr = 0.01
I1008 03:17:10.447188  5299 solver.cpp:218] Iteration 70300 (3.96119 iter/s, 25.2449s/100 iters), loss = 0.00246073
I1008 03:17:10.447276  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00246097 (* 1 = 0.00246097 loss)
I1008 03:17:10.447288  5299 sgd_solver.cpp:105] Iteration 70300, lr = 0.01
I1008 03:17:35.783107  5299 solver.cpp:218] Iteration 70400 (3.947 iter/s, 25.3357s/100 iters), loss = 0.00233543
I1008 03:17:35.783151  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00233566 (* 1 = 0.00233566 loss)
I1008 03:17:35.783160  5299 sgd_solver.cpp:105] Iteration 70400, lr = 0.01
I1008 03:17:59.206778  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:18:00.187448  5299 solver.cpp:330] Iteration 70500, Testing net (#0)
I1008 03:18:05.103045  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:18:05.307147  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.913
I1008 03:18:05.307176  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.365557 (* 1 = 0.365557 loss)
I1008 03:18:05.505625  5299 solver.cpp:218] Iteration 70500 (3.36447 iter/s, 29.7224s/100 iters), loss = 0.00990628
I1008 03:18:05.505671  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00990651 (* 1 = 0.00990651 loss)
I1008 03:18:05.505678  5299 sgd_solver.cpp:105] Iteration 70500, lr = 0.01
I1008 03:18:30.201303  5299 solver.cpp:218] Iteration 70600 (4.05001 iter/s, 24.6913s/100 iters), loss = 0.00980632
I1008 03:18:30.201431  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00980655 (* 1 = 0.00980655 loss)
I1008 03:18:30.201441  5299 sgd_solver.cpp:105] Iteration 70600, lr = 0.01
I1008 03:18:54.844442  5299 solver.cpp:218] Iteration 70700 (4.05796 iter/s, 24.6429s/100 iters), loss = 0.00267772
I1008 03:18:54.844475  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00267794 (* 1 = 0.00267794 loss)
I1008 03:18:54.844481  5299 sgd_solver.cpp:105] Iteration 70700, lr = 0.01
I1008 03:19:20.183197  5299 solver.cpp:218] Iteration 70800 (3.94655 iter/s, 25.3386s/100 iters), loss = 0.0577084
I1008 03:19:20.183305  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0577087 (* 1 = 0.0577087 loss)
I1008 03:19:20.183318  5299 sgd_solver.cpp:105] Iteration 70800, lr = 0.01
I1008 03:19:45.696869  5299 solver.cpp:218] Iteration 70900 (3.9195 iter/s, 25.5135s/100 iters), loss = 0.00246854
I1008 03:19:45.696905  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00246876 (* 1 = 0.00246876 loss)
I1008 03:19:45.696923  5299 sgd_solver.cpp:105] Iteration 70900, lr = 0.01
I1008 03:20:09.117166  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:20:10.096648  5299 solver.cpp:330] Iteration 71000, Testing net (#0)
I1008 03:20:14.994874  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:20:15.211843  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9091
I1008 03:20:15.211870  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.395008 (* 1 = 0.395008 loss)
I1008 03:20:15.401533  5299 solver.cpp:218] Iteration 71000 (3.36649 iter/s, 29.7045s/100 iters), loss = 0.00690435
I1008 03:20:15.401574  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00690457 (* 1 = 0.00690457 loss)
I1008 03:20:15.401582  5299 sgd_solver.cpp:105] Iteration 71000, lr = 0.01
I1008 03:20:40.082022  5299 solver.cpp:218] Iteration 71100 (4.0525 iter/s, 24.6761s/100 iters), loss = 0.00255894
I1008 03:20:40.082124  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00255915 (* 1 = 0.00255915 loss)
I1008 03:20:40.082132  5299 sgd_solver.cpp:105] Iteration 71100, lr = 0.01
I1008 03:21:04.726241  5299 solver.cpp:218] Iteration 71200 (4.05778 iter/s, 24.644s/100 iters), loss = 0.0168655
I1008 03:21:04.726286  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0168657 (* 1 = 0.0168657 loss)
I1008 03:21:04.726294  5299 sgd_solver.cpp:105] Iteration 71200, lr = 0.01
I1008 03:21:29.980705  5299 solver.cpp:218] Iteration 71300 (3.95972 iter/s, 25.2543s/100 iters), loss = 0.00273732
I1008 03:21:29.980787  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00273753 (* 1 = 0.00273753 loss)
I1008 03:21:29.980795  5299 sgd_solver.cpp:105] Iteration 71300, lr = 0.01
I1008 03:21:55.303828  5299 solver.cpp:218] Iteration 71400 (3.949 iter/s, 25.3229s/100 iters), loss = 0.00272601
I1008 03:21:55.303859  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00272623 (* 1 = 0.00272623 loss)
I1008 03:21:55.303865  5299 sgd_solver.cpp:105] Iteration 71400, lr = 0.01
I1008 03:22:18.721822  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:22:19.704972  5299 solver.cpp:330] Iteration 71500, Testing net (#0)
I1008 03:22:24.738960  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:22:24.979046  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9085
I1008 03:22:24.979077  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.382608 (* 1 = 0.382608 loss)
I1008 03:22:25.143364  5299 solver.cpp:218] Iteration 71500 (3.35128 iter/s, 29.8394s/100 iters), loss = 0.00410486
I1008 03:22:25.143404  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00410508 (* 1 = 0.00410508 loss)
I1008 03:22:25.143414  5299 sgd_solver.cpp:105] Iteration 71500, lr = 0.01
I1008 03:22:49.847795  5299 solver.cpp:218] Iteration 71600 (4.04857 iter/s, 24.7001s/100 iters), loss = 0.00882291
I1008 03:22:49.847900  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00882313 (* 1 = 0.00882313 loss)
I1008 03:22:49.847909  5299 sgd_solver.cpp:105] Iteration 71600, lr = 0.01
I1008 03:23:14.458989  5299 solver.cpp:218] Iteration 71700 (4.06323 iter/s, 24.611s/100 iters), loss = 0.00377038
I1008 03:23:14.459028  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00377061 (* 1 = 0.00377061 loss)
I1008 03:23:14.459035  5299 sgd_solver.cpp:105] Iteration 71700, lr = 0.01
I1008 03:23:39.697129  5299 solver.cpp:218] Iteration 71800 (3.96228 iter/s, 25.238s/100 iters), loss = 0.00516635
I1008 03:23:39.697201  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00516658 (* 1 = 0.00516658 loss)
I1008 03:23:39.697209  5299 sgd_solver.cpp:105] Iteration 71800, lr = 0.01
I1008 03:24:04.857734  5299 solver.cpp:218] Iteration 71900 (3.9745 iter/s, 25.1604s/100 iters), loss = 0.0127286
I1008 03:24:04.857766  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0127288 (* 1 = 0.0127288 loss)
I1008 03:24:04.857774  5299 sgd_solver.cpp:105] Iteration 71900, lr = 0.01
I1008 03:24:28.413841  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:24:29.395264  5299 solver.cpp:330] Iteration 72000, Testing net (#0)
I1008 03:24:34.269798  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:24:34.511827  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9096
I1008 03:24:34.511854  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.381481 (* 1 = 0.381481 loss)
I1008 03:24:34.669922  5299 solver.cpp:218] Iteration 72000 (3.35435 iter/s, 29.812s/100 iters), loss = 0.00152821
I1008 03:24:34.669968  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00152844 (* 1 = 0.00152844 loss)
I1008 03:24:34.669976  5299 sgd_solver.cpp:105] Iteration 72000, lr = 0.01
I1008 03:24:59.370890  5299 solver.cpp:218] Iteration 72100 (4.04914 iter/s, 24.6966s/100 iters), loss = 0.0347301
I1008 03:24:59.370965  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0347303 (* 1 = 0.0347303 loss)
I1008 03:24:59.370976  5299 sgd_solver.cpp:105] Iteration 72100, lr = 0.01
I1008 03:25:23.978648  5299 solver.cpp:218] Iteration 72200 (4.0638 iter/s, 24.6075s/100 iters), loss = 0.00590415
I1008 03:25:23.978682  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00590439 (* 1 = 0.00590439 loss)
I1008 03:25:23.978688  5299 sgd_solver.cpp:105] Iteration 72200, lr = 0.01
I1008 03:25:49.300925  5299 solver.cpp:218] Iteration 72300 (3.94911 iter/s, 25.3221s/100 iters), loss = 0.00666687
I1008 03:25:49.301002  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00666711 (* 1 = 0.00666711 loss)
I1008 03:25:49.301010  5299 sgd_solver.cpp:105] Iteration 72300, lr = 0.01
I1008 03:26:14.631842  5299 solver.cpp:218] Iteration 72400 (3.94778 iter/s, 25.3307s/100 iters), loss = 0.013895
I1008 03:26:14.631872  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0138952 (* 1 = 0.0138952 loss)
I1008 03:26:14.631878  5299 sgd_solver.cpp:105] Iteration 72400, lr = 0.01
I1008 03:26:38.052572  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:26:39.036767  5299 solver.cpp:330] Iteration 72500, Testing net (#0)
I1008 03:26:43.911551  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:26:44.147904  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9069
I1008 03:26:44.147930  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.385354 (* 1 = 0.385354 loss)
I1008 03:26:44.316961  5299 solver.cpp:218] Iteration 72500 (3.36871 iter/s, 29.685s/100 iters), loss = 0.00915186
I1008 03:26:44.316994  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00915211 (* 1 = 0.00915211 loss)
I1008 03:26:44.317003  5299 sgd_solver.cpp:105] Iteration 72500, lr = 0.01
I1008 03:27:09.011649  5299 solver.cpp:218] Iteration 72600 (4.05017 iter/s, 24.6903s/100 iters), loss = 0.0247806
I1008 03:27:09.011765  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0247808 (* 1 = 0.0247808 loss)
I1008 03:27:09.011775  5299 sgd_solver.cpp:105] Iteration 72600, lr = 0.01
I1008 03:27:33.648351  5299 solver.cpp:218] Iteration 72700 (4.05902 iter/s, 24.6365s/100 iters), loss = 0.00747072
I1008 03:27:33.648387  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00747096 (* 1 = 0.00747096 loss)
I1008 03:27:33.648394  5299 sgd_solver.cpp:105] Iteration 72700, lr = 0.01
I1008 03:27:58.967546  5299 solver.cpp:218] Iteration 72800 (3.9496 iter/s, 25.319s/100 iters), loss = 0.00260867
I1008 03:27:58.967617  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00260892 (* 1 = 0.00260892 loss)
I1008 03:27:58.967625  5299 sgd_solver.cpp:105] Iteration 72800, lr = 0.01
I1008 03:28:24.424127  5299 solver.cpp:218] Iteration 72900 (3.92893 iter/s, 25.4522s/100 iters), loss = 0.00442335
I1008 03:28:24.424160  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0044236 (* 1 = 0.0044236 loss)
I1008 03:28:24.424165  5299 sgd_solver.cpp:105] Iteration 72900, lr = 0.01
I1008 03:28:48.010139  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:28:48.993824  5299 solver.cpp:330] Iteration 73000, Testing net (#0)
I1008 03:28:53.910748  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:28:54.113828  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9099
I1008 03:28:54.113855  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.368551 (* 1 = 0.368551 loss)
I1008 03:28:54.331689  5299 solver.cpp:218] Iteration 73000 (3.34365 iter/s, 29.9074s/100 iters), loss = 0.00678862
I1008 03:28:54.331735  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00678886 (* 1 = 0.00678886 loss)
I1008 03:28:54.331744  5299 sgd_solver.cpp:105] Iteration 73000, lr = 0.01
I1008 03:29:18.996959  5299 solver.cpp:218] Iteration 73100 (4.05501 iter/s, 24.6609s/100 iters), loss = 0.00821294
I1008 03:29:18.997064  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00821318 (* 1 = 0.00821318 loss)
I1008 03:29:18.997074  5299 sgd_solver.cpp:105] Iteration 73100, lr = 0.01
I1008 03:29:43.629984  5299 solver.cpp:218] Iteration 73200 (4.05963 iter/s, 24.6328s/100 iters), loss = 0.0109928
I1008 03:29:43.630026  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.010993 (* 1 = 0.010993 loss)
I1008 03:29:43.630033  5299 sgd_solver.cpp:105] Iteration 73200, lr = 0.01
I1008 03:30:08.871947  5299 solver.cpp:218] Iteration 73300 (3.96168 iter/s, 25.2418s/100 iters), loss = 0.0187504
I1008 03:30:08.872037  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0187507 (* 1 = 0.0187507 loss)
I1008 03:30:08.872045  5299 sgd_solver.cpp:105] Iteration 73300, lr = 0.01
I1008 03:30:34.136323  5299 solver.cpp:218] Iteration 73400 (3.95818 iter/s, 25.2642s/100 iters), loss = 0.0157235
I1008 03:30:34.136365  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0157238 (* 1 = 0.0157238 loss)
I1008 03:30:34.136371  5299 sgd_solver.cpp:105] Iteration 73400, lr = 0.01
I1008 03:30:57.569265  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:30:58.549343  5299 solver.cpp:330] Iteration 73500, Testing net (#0)
I1008 03:31:03.452983  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:31:03.668715  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9113
I1008 03:31:03.668745  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.361993 (* 1 = 0.361993 loss)
I1008 03:31:03.870198  5299 solver.cpp:218] Iteration 73500 (3.36319 iter/s, 29.7337s/100 iters), loss = 0.00227215
I1008 03:31:03.870244  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00227238 (* 1 = 0.00227238 loss)
I1008 03:31:03.870251  5299 sgd_solver.cpp:105] Iteration 73500, lr = 0.01
I1008 03:31:28.533126  5299 solver.cpp:218] Iteration 73600 (4.05538 iter/s, 24.6586s/100 iters), loss = 0.00440137
I1008 03:31:28.533246  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00440161 (* 1 = 0.00440161 loss)
I1008 03:31:28.533255  5299 sgd_solver.cpp:105] Iteration 73600, lr = 0.01
I1008 03:31:53.179656  5299 solver.cpp:218] Iteration 73700 (4.0574 iter/s, 24.6463s/100 iters), loss = 0.00868343
I1008 03:31:53.179689  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00868366 (* 1 = 0.00868366 loss)
I1008 03:31:53.179697  5299 sgd_solver.cpp:105] Iteration 73700, lr = 0.01
I1008 03:32:18.509384  5299 solver.cpp:218] Iteration 73800 (3.94795 iter/s, 25.3296s/100 iters), loss = 0.00356964
I1008 03:32:18.509469  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00356987 (* 1 = 0.00356987 loss)
I1008 03:32:18.509476  5299 sgd_solver.cpp:105] Iteration 73800, lr = 0.01
I1008 03:32:43.692118  5299 solver.cpp:218] Iteration 73900 (3.97101 iter/s, 25.1825s/100 iters), loss = 0.00165049
I1008 03:32:43.692153  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00165071 (* 1 = 0.00165071 loss)
I1008 03:32:43.692162  5299 sgd_solver.cpp:105] Iteration 73900, lr = 0.01
I1008 03:33:07.255693  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:33:08.239015  5299 solver.cpp:330] Iteration 74000, Testing net (#0)
I1008 03:33:13.275254  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:33:13.516383  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9154
I1008 03:33:13.516409  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.3477 (* 1 = 0.3477 loss)
I1008 03:33:13.677876  5299 solver.cpp:218] Iteration 74000 (3.33493 iter/s, 29.9856s/100 iters), loss = 0.0618195
I1008 03:33:13.677912  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0618198 (* 1 = 0.0618198 loss)
I1008 03:33:13.677920  5299 sgd_solver.cpp:105] Iteration 74000, lr = 0.01
I1008 03:33:38.402591  5299 solver.cpp:218] Iteration 74100 (4.04525 iter/s, 24.7203s/100 iters), loss = 0.0166376
I1008 03:33:38.402671  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0166379 (* 1 = 0.0166379 loss)
I1008 03:33:38.402679  5299 sgd_solver.cpp:105] Iteration 74100, lr = 0.01
I1008 03:34:03.060852  5299 solver.cpp:218] Iteration 74200 (4.05547 iter/s, 24.658s/100 iters), loss = 0.0423275
I1008 03:34:03.060889  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0423277 (* 1 = 0.0423277 loss)
I1008 03:34:03.060897  5299 sgd_solver.cpp:105] Iteration 74200, lr = 0.01
I1008 03:34:28.288736  5299 solver.cpp:218] Iteration 74300 (3.96389 iter/s, 25.2277s/100 iters), loss = 0.0110502
I1008 03:34:28.288822  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0110504 (* 1 = 0.0110504 loss)
I1008 03:34:28.288831  5299 sgd_solver.cpp:105] Iteration 74300, lr = 0.01
I1008 03:34:53.541065  5299 solver.cpp:218] Iteration 74400 (3.96007 iter/s, 25.2521s/100 iters), loss = 0.0170441
I1008 03:34:53.541097  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0170443 (* 1 = 0.0170443 loss)
I1008 03:34:53.541105  5299 sgd_solver.cpp:105] Iteration 74400, lr = 0.01
I1008 03:35:16.978515  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:35:17.961935  5299 solver.cpp:330] Iteration 74500, Testing net (#0)
I1008 03:35:22.995378  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:35:23.235540  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9104
I1008 03:35:23.235566  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.3772 (* 1 = 0.3772 loss)
I1008 03:35:23.404181  5299 solver.cpp:218] Iteration 74500 (3.34863 iter/s, 29.863s/100 iters), loss = 0.00258319
I1008 03:35:23.404213  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00258341 (* 1 = 0.00258341 loss)
I1008 03:35:23.404222  5299 sgd_solver.cpp:105] Iteration 74500, lr = 0.01
I1008 03:35:48.118847  5299 solver.cpp:218] Iteration 74600 (4.04689 iter/s, 24.7103s/100 iters), loss = 0.0228486
I1008 03:35:48.118932  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0228488 (* 1 = 0.0228488 loss)
I1008 03:35:48.118940  5299 sgd_solver.cpp:105] Iteration 74600, lr = 0.01
I1008 03:36:12.769341  5299 solver.cpp:218] Iteration 74700 (4.05675 iter/s, 24.6503s/100 iters), loss = 0.0322719
I1008 03:36:12.769378  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0322721 (* 1 = 0.0322721 loss)
I1008 03:36:12.769385  5299 sgd_solver.cpp:105] Iteration 74700, lr = 0.01
I1008 03:36:38.013229  5299 solver.cpp:218] Iteration 74800 (3.96138 iter/s, 25.2437s/100 iters), loss = 0.00972783
I1008 03:36:38.013316  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00972804 (* 1 = 0.00972804 loss)
I1008 03:36:38.013324  5299 sgd_solver.cpp:105] Iteration 74800, lr = 0.01
I1008 03:37:03.201484  5299 solver.cpp:218] Iteration 74900 (3.97014 iter/s, 25.188s/100 iters), loss = 0.00188836
I1008 03:37:03.201517  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00188857 (* 1 = 0.00188857 loss)
I1008 03:37:03.201524  5299 sgd_solver.cpp:105] Iteration 74900, lr = 0.01
I1008 03:37:26.765022  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:37:27.748311  5299 solver.cpp:330] Iteration 75000, Testing net (#0)
I1008 03:37:32.664988  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:37:32.863831  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9065
I1008 03:37:32.863858  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.400796 (* 1 = 0.400796 loss)
I1008 03:37:33.095530  5299 solver.cpp:218] Iteration 75000 (3.34517 iter/s, 29.8939s/100 iters), loss = 0.0134638
I1008 03:37:33.095564  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.013464 (* 1 = 0.013464 loss)
I1008 03:37:33.095573  5299 sgd_solver.cpp:105] Iteration 75000, lr = 0.01
I1008 03:37:57.722977  5299 solver.cpp:218] Iteration 75100 (4.06123 iter/s, 24.6231s/100 iters), loss = 0.00760056
I1008 03:37:57.723081  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00760077 (* 1 = 0.00760077 loss)
I1008 03:37:57.723091  5299 sgd_solver.cpp:105] Iteration 75100, lr = 0.01
I1008 03:38:22.366642  5299 solver.cpp:218] Iteration 75200 (4.05787 iter/s, 24.6434s/100 iters), loss = 0.035055
I1008 03:38:22.366681  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0350552 (* 1 = 0.0350552 loss)
I1008 03:38:22.366690  5299 sgd_solver.cpp:105] Iteration 75200, lr = 0.01
I1008 03:38:47.707821  5299 solver.cpp:218] Iteration 75300 (3.94617 iter/s, 25.341s/100 iters), loss = 0.0222987
I1008 03:38:47.707906  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0222989 (* 1 = 0.0222989 loss)
I1008 03:38:47.707923  5299 sgd_solver.cpp:105] Iteration 75300, lr = 0.01
I1008 03:39:12.948618  5299 solver.cpp:218] Iteration 75400 (3.96187 iter/s, 25.2406s/100 iters), loss = 0.00914939
I1008 03:39:12.948654  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0091496 (* 1 = 0.0091496 loss)
I1008 03:39:12.948662  5299 sgd_solver.cpp:105] Iteration 75400, lr = 0.01
I1008 03:39:36.402289  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:39:37.351271  5299 solver.cpp:330] Iteration 75500, Testing net (#0)
I1008 03:39:42.332136  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:39:42.501163  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9137
I1008 03:39:42.501189  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.364311 (* 1 = 0.364311 loss)
I1008 03:39:42.706305  5299 solver.cpp:218] Iteration 75500 (3.36049 iter/s, 29.7575s/100 iters), loss = 0.00461812
I1008 03:39:42.706341  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00461832 (* 1 = 0.00461832 loss)
I1008 03:39:42.706347  5299 sgd_solver.cpp:105] Iteration 75500, lr = 0.01
I1008 03:40:07.337862  5299 solver.cpp:218] Iteration 75600 (4.05986 iter/s, 24.6314s/100 iters), loss = 0.00735956
I1008 03:40:07.337970  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00735977 (* 1 = 0.00735977 loss)
I1008 03:40:07.337978  5299 sgd_solver.cpp:105] Iteration 75600, lr = 0.01
I1008 03:40:31.993017  5299 solver.cpp:218] Iteration 75700 (4.05599 iter/s, 24.6549s/100 iters), loss = 0.0129367
I1008 03:40:31.993052  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.012937 (* 1 = 0.012937 loss)
I1008 03:40:31.993059  5299 sgd_solver.cpp:105] Iteration 75700, lr = 0.01
I1008 03:40:57.326068  5299 solver.cpp:218] Iteration 75800 (3.94744 iter/s, 25.3329s/100 iters), loss = 0.00344122
I1008 03:40:57.326151  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00344143 (* 1 = 0.00344143 loss)
I1008 03:40:57.326159  5299 sgd_solver.cpp:105] Iteration 75800, lr = 0.01
I1008 03:41:22.663779  5299 solver.cpp:218] Iteration 75900 (3.94672 iter/s, 25.3375s/100 iters), loss = 0.0089113
I1008 03:41:22.663815  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00891151 (* 1 = 0.00891151 loss)
I1008 03:41:22.663823  5299 sgd_solver.cpp:105] Iteration 75900, lr = 0.01
I1008 03:41:46.093327  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:41:47.075390  5299 solver.cpp:330] Iteration 76000, Testing net (#0)
I1008 03:41:52.145965  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:41:52.340484  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9148
I1008 03:41:52.340512  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.353354 (* 1 = 0.353354 loss)
I1008 03:41:52.582782  5299 solver.cpp:218] Iteration 76000 (3.34237 iter/s, 29.9188s/100 iters), loss = 0.00989018
I1008 03:41:52.582815  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00989039 (* 1 = 0.00989039 loss)
I1008 03:41:52.582821  5299 sgd_solver.cpp:105] Iteration 76000, lr = 0.01
I1008 03:42:17.235972  5299 solver.cpp:218] Iteration 76100 (4.05629 iter/s, 24.653s/100 iters), loss = 0.00636464
I1008 03:42:17.236058  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00636486 (* 1 = 0.00636486 loss)
I1008 03:42:17.236068  5299 sgd_solver.cpp:105] Iteration 76100, lr = 0.01
I1008 03:42:41.880182  5299 solver.cpp:218] Iteration 76200 (4.05779 iter/s, 24.644s/100 iters), loss = 0.00984068
I1008 03:42:41.880218  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0098409 (* 1 = 0.0098409 loss)
I1008 03:42:41.880223  5299 sgd_solver.cpp:105] Iteration 76200, lr = 0.01
I1008 03:43:07.211529  5299 solver.cpp:218] Iteration 76300 (3.9477 iter/s, 25.3312s/100 iters), loss = 0.00493193
I1008 03:43:07.211612  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00493216 (* 1 = 0.00493216 loss)
I1008 03:43:07.211621  5299 sgd_solver.cpp:105] Iteration 76300, lr = 0.01
I1008 03:43:32.553597  5299 solver.cpp:218] Iteration 76400 (3.94604 iter/s, 25.3418s/100 iters), loss = 0.054623
I1008 03:43:32.553632  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0546232 (* 1 = 0.0546232 loss)
I1008 03:43:32.553640  5299 sgd_solver.cpp:105] Iteration 76400, lr = 0.01
I1008 03:43:55.961144  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:43:56.942482  5299 solver.cpp:330] Iteration 76500, Testing net (#0)
I1008 03:44:01.860652  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:44:02.066462  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9086
I1008 03:44:02.066488  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.38071 (* 1 = 0.38071 loss)
I1008 03:44:02.305390  5299 solver.cpp:218] Iteration 76500 (3.36116 iter/s, 29.7516s/100 iters), loss = 0.0128867
I1008 03:44:02.305438  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0128869 (* 1 = 0.0128869 loss)
I1008 03:44:02.305447  5299 sgd_solver.cpp:105] Iteration 76500, lr = 0.01
I1008 03:44:26.941704  5299 solver.cpp:218] Iteration 76600 (4.05931 iter/s, 24.6347s/100 iters), loss = 0.0166537
I1008 03:44:26.941790  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0166539 (* 1 = 0.0166539 loss)
I1008 03:44:26.941798  5299 sgd_solver.cpp:105] Iteration 76600, lr = 0.01
I1008 03:44:51.594283  5299 solver.cpp:218] Iteration 76700 (4.05641 iter/s, 24.6524s/100 iters), loss = 0.0190503
I1008 03:44:51.594317  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0190505 (* 1 = 0.0190505 loss)
I1008 03:44:51.594323  5299 sgd_solver.cpp:105] Iteration 76700, lr = 0.01
I1008 03:45:16.974670  5299 solver.cpp:218] Iteration 76800 (3.94007 iter/s, 25.3802s/100 iters), loss = 0.0075911
I1008 03:45:16.974763  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00759133 (* 1 = 0.00759133 loss)
I1008 03:45:16.974772  5299 sgd_solver.cpp:105] Iteration 76800, lr = 0.01
I1008 03:45:42.191484  5299 solver.cpp:218] Iteration 76900 (3.96597 iter/s, 25.2145s/100 iters), loss = 0.00338703
I1008 03:45:42.191519  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00338726 (* 1 = 0.00338726 loss)
I1008 03:45:42.191527  5299 sgd_solver.cpp:105] Iteration 76900, lr = 0.01
I1008 03:46:05.796303  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:46:06.773852  5299 solver.cpp:330] Iteration 77000, Testing net (#0)
I1008 03:46:11.811928  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:46:12.053231  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9104
I1008 03:46:12.053266  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.378658 (* 1 = 0.378658 loss)
I1008 03:46:12.220497  5299 solver.cpp:218] Iteration 77000 (3.33013 iter/s, 30.0289s/100 iters), loss = 0.0139142
I1008 03:46:12.220530  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0139144 (* 1 = 0.0139144 loss)
I1008 03:46:12.220537  5299 sgd_solver.cpp:105] Iteration 77000, lr = 0.01
I1008 03:46:36.950999  5299 solver.cpp:218] Iteration 77100 (4.0443 iter/s, 24.7261s/100 iters), loss = 0.0281357
I1008 03:46:36.951074  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.028136 (* 1 = 0.028136 loss)
I1008 03:46:36.951083  5299 sgd_solver.cpp:105] Iteration 77100, lr = 0.01
I1008 03:47:01.743279  5299 solver.cpp:218] Iteration 77200 (4.03355 iter/s, 24.7921s/100 iters), loss = 0.0861464
I1008 03:47:01.743327  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0861466 (* 1 = 0.0861466 loss)
I1008 03:47:01.743335  5299 sgd_solver.cpp:105] Iteration 77200, lr = 0.01
I1008 03:47:27.315985  5299 solver.cpp:218] Iteration 77300 (3.91044 iter/s, 25.5726s/100 iters), loss = 0.00706493
I1008 03:47:27.316076  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00706515 (* 1 = 0.00706515 loss)
I1008 03:47:27.316084  5299 sgd_solver.cpp:105] Iteration 77300, lr = 0.01
I1008 03:47:52.549202  5299 solver.cpp:218] Iteration 77400 (3.96306 iter/s, 25.233s/100 iters), loss = 0.00713404
I1008 03:47:52.549239  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00713425 (* 1 = 0.00713425 loss)
I1008 03:47:52.549249  5299 sgd_solver.cpp:105] Iteration 77400, lr = 0.01
I1008 03:48:15.967675  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:48:16.950215  5299 solver.cpp:330] Iteration 77500, Testing net (#0)
I1008 03:48:21.985859  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:48:22.173491  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9121
I1008 03:48:22.173519  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.355039 (* 1 = 0.355039 loss)
I1008 03:48:22.314559  5299 solver.cpp:218] Iteration 77500 (3.35963 iter/s, 29.7652s/100 iters), loss = 0.00201737
I1008 03:48:22.314594  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00201759 (* 1 = 0.00201759 loss)
I1008 03:48:22.314600  5299 sgd_solver.cpp:105] Iteration 77500, lr = 0.01
I1008 03:48:47.106393  5299 solver.cpp:218] Iteration 77600 (4.03361 iter/s, 24.7917s/100 iters), loss = 0.00273659
I1008 03:48:47.106468  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0027368 (* 1 = 0.0027368 loss)
I1008 03:48:47.106479  5299 sgd_solver.cpp:105] Iteration 77600, lr = 0.01
I1008 03:49:11.773264  5299 solver.cpp:218] Iteration 77700 (4.05404 iter/s, 24.6667s/100 iters), loss = 0.0122546
I1008 03:49:11.773299  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0122548 (* 1 = 0.0122548 loss)
I1008 03:49:11.773315  5299 sgd_solver.cpp:105] Iteration 77700, lr = 0.01
I1008 03:49:37.565426  5299 solver.cpp:218] Iteration 77800 (3.87717 iter/s, 25.792s/100 iters), loss = 0.00309058
I1008 03:49:37.565531  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0030908 (* 1 = 0.0030908 loss)
I1008 03:49:37.565541  5299 sgd_solver.cpp:105] Iteration 77800, lr = 0.01
I1008 03:50:02.435142  5299 solver.cpp:218] Iteration 77900 (4.02098 iter/s, 24.8695s/100 iters), loss = 0.0439087
I1008 03:50:02.435190  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0439089 (* 1 = 0.0439089 loss)
I1008 03:50:02.435197  5299 sgd_solver.cpp:105] Iteration 77900, lr = 0.01
I1008 03:50:25.852916  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:50:26.835717  5299 solver.cpp:330] Iteration 78000, Testing net (#0)
I1008 03:50:31.912525  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:50:32.106458  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9067
I1008 03:50:32.106483  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.406564 (* 1 = 0.406564 loss)
I1008 03:50:32.346863  5299 solver.cpp:218] Iteration 78000 (3.34319 iter/s, 29.9116s/100 iters), loss = 0.0114311
I1008 03:50:32.346900  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0114313 (* 1 = 0.0114313 loss)
I1008 03:50:32.346907  5299 sgd_solver.cpp:105] Iteration 78000, lr = 0.01
I1008 03:50:56.965250  5299 solver.cpp:218] Iteration 78100 (4.06203 iter/s, 24.6182s/100 iters), loss = 0.0046845
I1008 03:50:56.965351  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0046847 (* 1 = 0.0046847 loss)
I1008 03:50:56.965360  5299 sgd_solver.cpp:105] Iteration 78100, lr = 0.01
I1008 03:51:21.611747  5299 solver.cpp:218] Iteration 78200 (4.05741 iter/s, 24.6463s/100 iters), loss = 0.00758196
I1008 03:51:21.611783  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00758216 (* 1 = 0.00758216 loss)
I1008 03:51:21.611793  5299 sgd_solver.cpp:105] Iteration 78200, lr = 0.01
I1008 03:51:47.408107  5299 solver.cpp:218] Iteration 78300 (3.87654 iter/s, 25.7962s/100 iters), loss = 0.0176373
I1008 03:51:47.408177  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0176375 (* 1 = 0.0176375 loss)
I1008 03:51:47.408187  5299 sgd_solver.cpp:105] Iteration 78300, lr = 0.01
I1008 03:52:12.394374  5299 solver.cpp:218] Iteration 78400 (4.00257 iter/s, 24.984s/100 iters), loss = 0.00412893
I1008 03:52:12.394413  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00412912 (* 1 = 0.00412912 loss)
I1008 03:52:12.394423  5299 sgd_solver.cpp:105] Iteration 78400, lr = 0.01
I1008 03:52:36.005800  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:52:36.986784  5299 solver.cpp:330] Iteration 78500, Testing net (#0)
I1008 03:52:42.020617  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:52:42.262094  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9068
I1008 03:52:42.262120  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.392339 (* 1 = 0.392339 loss)
I1008 03:52:42.426487  5299 solver.cpp:218] Iteration 78500 (3.32979 iter/s, 30.032s/100 iters), loss = 0.00514136
I1008 03:52:42.426529  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00514155 (* 1 = 0.00514155 loss)
I1008 03:52:42.426537  5299 sgd_solver.cpp:105] Iteration 78500, lr = 0.01
I1008 03:53:07.161249  5299 solver.cpp:218] Iteration 78600 (4.04361 iter/s, 24.7304s/100 iters), loss = 0.0141281
I1008 03:53:07.161299  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0141283 (* 1 = 0.0141283 loss)
I1008 03:53:07.161306  5299 sgd_solver.cpp:105] Iteration 78600, lr = 0.01
I1008 03:53:31.771703  5299 solver.cpp:218] Iteration 78700 (4.06334 iter/s, 24.6103s/100 iters), loss = 0.0109692
I1008 03:53:31.771745  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0109694 (* 1 = 0.0109694 loss)
I1008 03:53:31.771752  5299 sgd_solver.cpp:105] Iteration 78700, lr = 0.01
I1008 03:53:57.470522  5299 solver.cpp:218] Iteration 78800 (3.89158 iter/s, 25.6965s/100 iters), loss = 0.0102654
I1008 03:53:57.470623  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0102656 (* 1 = 0.0102656 loss)
I1008 03:53:57.470639  5299 sgd_solver.cpp:105] Iteration 78800, lr = 0.01
I1008 03:54:22.272914  5299 solver.cpp:218] Iteration 78900 (4.03191 iter/s, 24.8022s/100 iters), loss = 0.00588369
I1008 03:54:22.272951  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00588387 (* 1 = 0.00588387 loss)
I1008 03:54:22.272959  5299 sgd_solver.cpp:105] Iteration 78900, lr = 0.01
I1008 03:54:45.688786  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:54:46.673557  5299 solver.cpp:330] Iteration 79000, Testing net (#0)
I1008 03:54:51.588662  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:54:51.793404  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9051
I1008 03:54:51.793433  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.393795 (* 1 = 0.393795 loss)
I1008 03:54:51.988032  5299 solver.cpp:218] Iteration 79000 (3.36531 iter/s, 29.715s/100 iters), loss = 0.00417115
I1008 03:54:51.988070  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00417133 (* 1 = 0.00417133 loss)
I1008 03:54:51.988077  5299 sgd_solver.cpp:105] Iteration 79000, lr = 0.01
I1008 03:55:16.682132  5299 solver.cpp:218] Iteration 79100 (4.05027 iter/s, 24.6897s/100 iters), loss = 0.00951131
I1008 03:55:16.682210  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00951149 (* 1 = 0.00951149 loss)
I1008 03:55:16.682219  5299 sgd_solver.cpp:105] Iteration 79100, lr = 0.01
I1008 03:55:41.413202  5299 solver.cpp:218] Iteration 79200 (4.04353 iter/s, 24.7309s/100 iters), loss = 0.0110555
I1008 03:55:41.413234  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0110557 (* 1 = 0.0110557 loss)
I1008 03:55:41.413241  5299 sgd_solver.cpp:105] Iteration 79200, lr = 0.01
I1008 03:56:07.274300  5299 solver.cpp:218] Iteration 79300 (3.86715 iter/s, 25.8588s/100 iters), loss = 0.0030619
I1008 03:56:07.274385  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00306209 (* 1 = 0.00306209 loss)
I1008 03:56:07.274394  5299 sgd_solver.cpp:105] Iteration 79300, lr = 0.01
I1008 03:56:31.927695  5299 solver.cpp:218] Iteration 79400 (4.05627 iter/s, 24.6532s/100 iters), loss = 0.0113638
I1008 03:56:31.927732  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.011364 (* 1 = 0.011364 loss)
I1008 03:56:31.927739  5299 sgd_solver.cpp:105] Iteration 79400, lr = 0.01
I1008 03:56:55.360817  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:56:56.332538  5299 solver.cpp:330] Iteration 79500, Testing net (#0)
I1008 03:57:01.410605  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:57:01.606222  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8827
I1008 03:57:01.606247  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.518795 (* 1 = 0.518795 loss)
I1008 03:57:01.848075  5299 solver.cpp:218] Iteration 79500 (3.34222 iter/s, 29.9202s/100 iters), loss = 0.00418422
I1008 03:57:01.848110  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0041844 (* 1 = 0.0041844 loss)
I1008 03:57:01.848117  5299 sgd_solver.cpp:105] Iteration 79500, lr = 0.01
I1008 03:57:26.469153  5299 solver.cpp:218] Iteration 79600 (4.06159 iter/s, 24.6209s/100 iters), loss = 0.0220062
I1008 03:57:26.469252  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0220064 (* 1 = 0.0220064 loss)
I1008 03:57:26.469261  5299 sgd_solver.cpp:105] Iteration 79600, lr = 0.01
I1008 03:57:51.294731  5299 solver.cpp:218] Iteration 79700 (4.02814 iter/s, 24.8254s/100 iters), loss = 0.0154968
I1008 03:57:51.294773  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.015497 (* 1 = 0.015497 loss)
I1008 03:57:51.294781  5299 sgd_solver.cpp:105] Iteration 79700, lr = 0.01
I1008 03:58:16.866057  5299 solver.cpp:218] Iteration 79800 (3.91098 iter/s, 25.569s/100 iters), loss = 0.00848665
I1008 03:58:16.866156  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00848681 (* 1 = 0.00848681 loss)
I1008 03:58:16.866165  5299 sgd_solver.cpp:105] Iteration 79800, lr = 0.01
I1008 03:58:41.514084  5299 solver.cpp:218] Iteration 79900 (4.05715 iter/s, 24.6478s/100 iters), loss = 0.00409084
I1008 03:58:41.514119  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.004091 (* 1 = 0.004091 loss)
I1008 03:58:41.514127  5299 sgd_solver.cpp:105] Iteration 79900, lr = 0.01
I1008 03:59:04.936620  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:59:05.921099  5299 solver.cpp:330] Iteration 80000, Testing net (#0)
I1008 03:59:10.909399  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 03:59:11.080754  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.8944
I1008 03:59:11.080780  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.474164 (* 1 = 0.474164 loss)
I1008 03:59:11.285596  5299 solver.cpp:218] Iteration 80000 (3.35893 iter/s, 29.7714s/100 iters), loss = 0.00166485
I1008 03:59:11.285632  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.001665 (* 1 = 0.001665 loss)
I1008 03:59:11.285639  5299 sgd_solver.cpp:46] MultiStep Status: Iteration 80000, step = 2
I1008 03:59:11.285641  5299 sgd_solver.cpp:105] Iteration 80000, lr = 0.001
I1008 03:59:35.911001  5299 solver.cpp:218] Iteration 80100 (4.06087 iter/s, 24.6253s/100 iters), loss = 0.0125333
I1008 03:59:35.911079  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0125334 (* 1 = 0.0125334 loss)
I1008 03:59:35.911087  5299 sgd_solver.cpp:105] Iteration 80100, lr = 0.001
I1008 04:00:00.814364  5299 solver.cpp:218] Iteration 80200 (4.01556 iter/s, 24.9031s/100 iters), loss = 0.00685545
I1008 04:00:00.814399  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00685559 (* 1 = 0.00685559 loss)
I1008 04:00:00.814406  5299 sgd_solver.cpp:105] Iteration 80200, lr = 0.001
I1008 04:00:26.397224  5299 solver.cpp:218] Iteration 80300 (3.90911 iter/s, 25.5813s/100 iters), loss = 0.00846433
I1008 04:00:26.397294  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00846447 (* 1 = 0.00846447 loss)
I1008 04:00:26.397302  5299 sgd_solver.cpp:105] Iteration 80300, lr = 0.001
I1008 04:00:51.048579  5299 solver.cpp:218] Iteration 80400 (4.0566 iter/s, 24.6512s/100 iters), loss = 0.000566068
I1008 04:00:51.048615  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000566206 (* 1 = 0.000566206 loss)
I1008 04:00:51.048624  5299 sgd_solver.cpp:105] Iteration 80400, lr = 0.001
I1008 04:01:14.488346  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:01:15.460944  5299 solver.cpp:330] Iteration 80500, Testing net (#0)
I1008 04:01:20.411378  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:01:20.580307  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9181
I1008 04:01:20.580337  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.354159 (* 1 = 0.354159 loss)
I1008 04:01:20.822099  5299 solver.cpp:218] Iteration 80500 (3.35871 iter/s, 29.7734s/100 iters), loss = 0.00130314
I1008 04:01:20.822137  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00130328 (* 1 = 0.00130328 loss)
I1008 04:01:20.822144  5299 sgd_solver.cpp:105] Iteration 80500, lr = 0.001
I1008 04:01:45.477767  5299 solver.cpp:218] Iteration 80600 (4.05589 iter/s, 24.6555s/100 iters), loss = 0.00510159
I1008 04:01:45.477859  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00510172 (* 1 = 0.00510172 loss)
I1008 04:01:45.477870  5299 sgd_solver.cpp:105] Iteration 80600, lr = 0.001
I1008 04:02:10.571533  5299 solver.cpp:218] Iteration 80700 (3.98509 iter/s, 25.0935s/100 iters), loss = 0.00718815
I1008 04:02:10.571566  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00718828 (* 1 = 0.00718828 loss)
I1008 04:02:10.571575  5299 sgd_solver.cpp:105] Iteration 80700, lr = 0.001
I1008 04:02:36.006861  5299 solver.cpp:218] Iteration 80800 (3.93156 iter/s, 25.4352s/100 iters), loss = 0.00116212
I1008 04:02:36.006955  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00116225 (* 1 = 0.00116225 loss)
I1008 04:02:36.006963  5299 sgd_solver.cpp:105] Iteration 80800, lr = 0.001
I1008 04:03:00.665386  5299 solver.cpp:218] Iteration 80900 (4.05543 iter/s, 24.6583s/100 iters), loss = 0.0019295
I1008 04:03:00.665422  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00192964 (* 1 = 0.00192964 loss)
I1008 04:03:00.665429  5299 sgd_solver.cpp:105] Iteration 80900, lr = 0.001
I1008 04:03:24.088258  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:03:25.074602  5299 solver.cpp:330] Iteration 81000, Testing net (#0)
I1008 04:03:30.029979  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:03:30.197896  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9202
I1008 04:03:30.197922  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.3348 (* 1 = 0.3348 loss)
I1008 04:03:30.438437  5299 solver.cpp:218] Iteration 81000 (3.35876 iter/s, 29.7729s/100 iters), loss = 0.00168981
I1008 04:03:30.438474  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00168995 (* 1 = 0.00168995 loss)
I1008 04:03:30.438482  5299 sgd_solver.cpp:105] Iteration 81000, lr = 0.001
I1008 04:03:55.067510  5299 solver.cpp:218] Iteration 81100 (4.06027 iter/s, 24.6289s/100 iters), loss = 0.00336626
I1008 04:03:55.067595  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0033664 (* 1 = 0.0033664 loss)
I1008 04:03:55.067602  5299 sgd_solver.cpp:105] Iteration 81100, lr = 0.001
I1008 04:04:20.231619  5299 solver.cpp:218] Iteration 81200 (3.97395 iter/s, 25.1639s/100 iters), loss = 0.014998
I1008 04:04:20.231657  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0149981 (* 1 = 0.0149981 loss)
I1008 04:04:20.231667  5299 sgd_solver.cpp:105] Iteration 81200, lr = 0.001
I1008 04:04:45.567319  5299 solver.cpp:218] Iteration 81300 (3.94735 iter/s, 25.3335s/100 iters), loss = 0.00225696
I1008 04:04:45.567356  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00225711 (* 1 = 0.00225711 loss)
I1008 04:04:45.567364  5299 sgd_solver.cpp:105] Iteration 81300, lr = 0.001
I1008 04:05:10.206490  5299 solver.cpp:218] Iteration 81400 (4.0586 iter/s, 24.639s/100 iters), loss = 0.0156507
I1008 04:05:10.206533  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0156509 (* 1 = 0.0156509 loss)
I1008 04:05:10.206542  5299 sgd_solver.cpp:105] Iteration 81400, lr = 0.001
I1008 04:05:33.603860  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:05:34.588934  5299 solver.cpp:330] Iteration 81500, Testing net (#0)
I1008 04:05:39.573294  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:05:39.745363  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9216
I1008 04:05:39.745391  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.32858 (* 1 = 0.32858 loss)
I1008 04:05:39.950387  5299 solver.cpp:218] Iteration 81500 (3.36205 iter/s, 29.7437s/100 iters), loss = 0.00384426
I1008 04:05:39.950419  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0038444 (* 1 = 0.0038444 loss)
I1008 04:05:39.950426  5299 sgd_solver.cpp:105] Iteration 81500, lr = 0.001
I1008 04:06:04.590867  5299 solver.cpp:218] Iteration 81600 (4.05839 iter/s, 24.6403s/100 iters), loss = 0.00559817
I1008 04:06:04.590943  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00559831 (* 1 = 0.00559831 loss)
I1008 04:06:04.590951  5299 sgd_solver.cpp:105] Iteration 81600, lr = 0.001
I1008 04:06:29.792084  5299 solver.cpp:218] Iteration 81700 (3.9681 iter/s, 25.201s/100 iters), loss = 0.00464714
I1008 04:06:29.792115  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00464728 (* 1 = 0.00464728 loss)
I1008 04:06:29.792122  5299 sgd_solver.cpp:105] Iteration 81700, lr = 0.001
I1008 04:06:55.188621  5299 solver.cpp:218] Iteration 81800 (3.93757 iter/s, 25.3964s/100 iters), loss = 0.00220137
I1008 04:06:55.188730  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00220151 (* 1 = 0.00220151 loss)
I1008 04:06:55.188740  5299 sgd_solver.cpp:105] Iteration 81800, lr = 0.001
I1008 04:07:19.998303  5299 solver.cpp:218] Iteration 81900 (4.03072 iter/s, 24.8095s/100 iters), loss = 0.00878907
I1008 04:07:19.998334  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00878921 (* 1 = 0.00878921 loss)
I1008 04:07:19.998350  5299 sgd_solver.cpp:105] Iteration 81900, lr = 0.001
I1008 04:07:43.417474  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:07:44.404173  5299 solver.cpp:330] Iteration 82000, Testing net (#0)
I1008 04:07:49.284567  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:07:49.526511  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9222
I1008 04:07:49.526538  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.329133 (* 1 = 0.329133 loss)
I1008 04:07:49.689153  5299 solver.cpp:218] Iteration 82000 (3.36806 iter/s, 29.6907s/100 iters), loss = 0.00830388
I1008 04:07:49.689198  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00830402 (* 1 = 0.00830402 loss)
I1008 04:07:49.689206  5299 sgd_solver.cpp:105] Iteration 82000, lr = 0.001
I1008 04:08:14.420693  5299 solver.cpp:218] Iteration 82100 (4.04413 iter/s, 24.7272s/100 iters), loss = 0.00128601
I1008 04:08:14.420790  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00128615 (* 1 = 0.00128615 loss)
I1008 04:08:14.420799  5299 sgd_solver.cpp:105] Iteration 82100, lr = 0.001
I1008 04:08:39.697481  5299 solver.cpp:218] Iteration 82200 (3.95623 iter/s, 25.2766s/100 iters), loss = 0.00249648
I1008 04:08:39.697513  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00249662 (* 1 = 0.00249662 loss)
I1008 04:08:39.697520  5299 sgd_solver.cpp:105] Iteration 82200, lr = 0.001
I1008 04:09:05.046561  5299 solver.cpp:218] Iteration 82300 (3.94494 iter/s, 25.3489s/100 iters), loss = 0.00522406
I1008 04:09:05.046653  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0052242 (* 1 = 0.0052242 loss)
I1008 04:09:05.046674  5299 sgd_solver.cpp:105] Iteration 82300, lr = 0.001
I1008 04:09:29.704814  5299 solver.cpp:218] Iteration 82400 (4.05548 iter/s, 24.658s/100 iters), loss = 0.00422489
I1008 04:09:29.704849  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00422502 (* 1 = 0.00422502 loss)
I1008 04:09:29.704869  5299 sgd_solver.cpp:105] Iteration 82400, lr = 0.001
I1008 04:09:53.133404  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:09:54.118245  5299 solver.cpp:330] Iteration 82500, Testing net (#0)
I1008 04:09:59.119634  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:09:59.280917  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9218
I1008 04:09:59.280944  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.328344 (* 1 = 0.328344 loss)
I1008 04:09:59.485417  5299 solver.cpp:218] Iteration 82500 (3.35791 iter/s, 29.7804s/100 iters), loss = 0.0162539
I1008 04:09:59.485455  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.016254 (* 1 = 0.016254 loss)
I1008 04:09:59.485462  5299 sgd_solver.cpp:105] Iteration 82500, lr = 0.001
I1008 04:10:24.116405  5299 solver.cpp:218] Iteration 82600 (4.05995 iter/s, 24.6308s/100 iters), loss = 0.00721461
I1008 04:10:24.116509  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00721475 (* 1 = 0.00721475 loss)
I1008 04:10:24.116516  5299 sgd_solver.cpp:105] Iteration 82600, lr = 0.001
I1008 04:10:49.473830  5299 solver.cpp:218] Iteration 82700 (3.94365 iter/s, 25.3572s/100 iters), loss = 0.00161704
I1008 04:10:49.473875  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00161717 (* 1 = 0.00161717 loss)
I1008 04:10:49.473881  5299 sgd_solver.cpp:105] Iteration 82700, lr = 0.001
I1008 04:11:14.646337  5299 solver.cpp:218] Iteration 82800 (3.97261 iter/s, 25.1724s/100 iters), loss = 0.00950192
I1008 04:11:14.646471  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00950207 (* 1 = 0.00950207 loss)
I1008 04:11:14.646479  5299 sgd_solver.cpp:105] Iteration 82800, lr = 0.001
I1008 04:11:39.277763  5299 solver.cpp:218] Iteration 82900 (4.05992 iter/s, 24.631s/100 iters), loss = 0.00155412
I1008 04:11:39.277809  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00155427 (* 1 = 0.00155427 loss)
I1008 04:11:39.277817  5299 sgd_solver.cpp:105] Iteration 82900, lr = 0.001
I1008 04:12:02.705217  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:12:03.678325  5299 solver.cpp:330] Iteration 83000, Testing net (#0)
I1008 04:12:08.705471  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:12:08.893503  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9222
I1008 04:12:08.893541  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.325668 (* 1 = 0.325668 loss)
I1008 04:12:09.034277  5299 solver.cpp:218] Iteration 83000 (3.36063 iter/s, 29.7564s/100 iters), loss = 0.00152501
I1008 04:12:09.034317  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00152516 (* 1 = 0.00152516 loss)
I1008 04:12:09.034323  5299 sgd_solver.cpp:105] Iteration 83000, lr = 0.001
I1008 04:12:33.835019  5299 solver.cpp:218] Iteration 83100 (4.03217 iter/s, 24.8006s/100 iters), loss = 0.00326416
I1008 04:12:33.835106  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00326431 (* 1 = 0.00326431 loss)
I1008 04:12:33.835114  5299 sgd_solver.cpp:105] Iteration 83100, lr = 0.001
I1008 04:12:59.178594  5299 solver.cpp:218] Iteration 83200 (3.94581 iter/s, 25.3433s/100 iters), loss = 0.00602459
I1008 04:12:59.178627  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00602475 (* 1 = 0.00602475 loss)
I1008 04:12:59.178632  5299 sgd_solver.cpp:105] Iteration 83200, lr = 0.001
I1008 04:13:24.512195  5299 solver.cpp:218] Iteration 83300 (3.94735 iter/s, 25.3335s/100 iters), loss = 0.00884113
I1008 04:13:24.512287  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00884128 (* 1 = 0.00884128 loss)
I1008 04:13:24.512310  5299 sgd_solver.cpp:105] Iteration 83300, lr = 0.001
I1008 04:13:49.157495  5299 solver.cpp:218] Iteration 83400 (4.05761 iter/s, 24.6451s/100 iters), loss = 0.00905065
I1008 04:13:49.157531  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0090508 (* 1 = 0.0090508 loss)
I1008 04:13:49.157539  5299 sgd_solver.cpp:105] Iteration 83400, lr = 0.001
I1008 04:14:12.603570  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:14:13.579844  5299 solver.cpp:330] Iteration 83500, Testing net (#0)
I1008 04:14:18.452977  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:14:18.694295  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.923
I1008 04:14:18.694322  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.326073 (* 1 = 0.326073 loss)
I1008 04:14:18.818963  5299 solver.cpp:218] Iteration 83500 (3.3714 iter/s, 29.6613s/100 iters), loss = 0.00142245
I1008 04:14:18.818997  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00142261 (* 1 = 0.00142261 loss)
I1008 04:14:18.819005  5299 sgd_solver.cpp:105] Iteration 83500, lr = 0.001
I1008 04:14:43.594099  5299 solver.cpp:218] Iteration 83600 (4.03668 iter/s, 24.7728s/100 iters), loss = 0.00128529
I1008 04:14:43.594244  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00128544 (* 1 = 0.00128544 loss)
I1008 04:14:43.594254  5299 sgd_solver.cpp:105] Iteration 83600, lr = 0.001
I1008 04:15:08.944542  5299 solver.cpp:218] Iteration 83700 (3.94474 iter/s, 25.3502s/100 iters), loss = 0.00222413
I1008 04:15:08.944581  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00222429 (* 1 = 0.00222429 loss)
I1008 04:15:08.944591  5299 sgd_solver.cpp:105] Iteration 83700, lr = 0.001
I1008 04:15:34.179666  5299 solver.cpp:218] Iteration 83800 (3.96275 iter/s, 25.235s/100 iters), loss = 0.00625652
I1008 04:15:34.179765  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00625668 (* 1 = 0.00625668 loss)
I1008 04:15:34.179774  5299 sgd_solver.cpp:105] Iteration 83800, lr = 0.001
I1008 04:15:58.850322  5299 solver.cpp:218] Iteration 83900 (4.05344 iter/s, 24.6704s/100 iters), loss = 0.00312936
I1008 04:15:58.850373  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00312952 (* 1 = 0.00312952 loss)
I1008 04:15:58.850381  5299 sgd_solver.cpp:105] Iteration 83900, lr = 0.001
I1008 04:16:22.441457  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:16:23.425814  5299 solver.cpp:330] Iteration 84000, Testing net (#0)
I1008 04:16:28.306509  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:16:28.507266  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9227
I1008 04:16:28.507302  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.32745 (* 1 = 0.32745 loss)
I1008 04:16:28.635699  5299 solver.cpp:218] Iteration 84000 (3.35737 iter/s, 29.7852s/100 iters), loss = 0.00337455
I1008 04:16:28.635728  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00337472 (* 1 = 0.00337472 loss)
I1008 04:16:28.635735  5299 sgd_solver.cpp:105] Iteration 84000, lr = 0.001
I1008 04:16:53.438405  5299 solver.cpp:218] Iteration 84100 (4.03184 iter/s, 24.8026s/100 iters), loss = 0.00749775
I1008 04:16:53.438499  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00749791 (* 1 = 0.00749791 loss)
I1008 04:16:53.438521  5299 sgd_solver.cpp:105] Iteration 84100, lr = 0.001
I1008 04:17:18.729717  5299 solver.cpp:218] Iteration 84200 (3.95396 iter/s, 25.2911s/100 iters), loss = 0.00405912
I1008 04:17:18.729753  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00405929 (* 1 = 0.00405929 loss)
I1008 04:17:18.729763  5299 sgd_solver.cpp:105] Iteration 84200, lr = 0.001
I1008 04:17:44.202561  5299 solver.cpp:218] Iteration 84300 (3.92577 iter/s, 25.4727s/100 iters), loss = 0.000994326
I1008 04:17:44.202642  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000994494 (* 1 = 0.000994494 loss)
I1008 04:17:44.202664  5299 sgd_solver.cpp:105] Iteration 84300, lr = 0.001
I1008 04:18:08.863243  5299 solver.cpp:218] Iteration 84400 (4.05506 iter/s, 24.6605s/100 iters), loss = 0.00270053
I1008 04:18:08.863288  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0027007 (* 1 = 0.0027007 loss)
I1008 04:18:08.863298  5299 sgd_solver.cpp:105] Iteration 84400, lr = 0.001
I1008 04:18:32.301769  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:18:33.267026  5299 solver.cpp:330] Iteration 84500, Testing net (#0)
I1008 04:18:38.145092  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:18:38.385474  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9226
I1008 04:18:38.385499  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.327 (* 1 = 0.327 loss)
I1008 04:18:38.530627  5299 solver.cpp:218] Iteration 84500 (3.37072 iter/s, 29.6672s/100 iters), loss = 0.00150404
I1008 04:18:38.530668  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0015042 (* 1 = 0.0015042 loss)
I1008 04:18:38.530675  5299 sgd_solver.cpp:105] Iteration 84500, lr = 0.001
I1008 04:19:03.291251  5299 solver.cpp:218] Iteration 84600 (4.03938 iter/s, 24.7563s/100 iters), loss = 0.00212942
I1008 04:19:03.291338  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00212959 (* 1 = 0.00212959 loss)
I1008 04:19:03.291357  5299 sgd_solver.cpp:105] Iteration 84600, lr = 0.001
I1008 04:19:28.558945  5299 solver.cpp:218] Iteration 84700 (3.95766 iter/s, 25.2675s/100 iters), loss = 0.00207949
I1008 04:19:28.558979  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00207967 (* 1 = 0.00207967 loss)
I1008 04:19:28.558986  5299 sgd_solver.cpp:105] Iteration 84700, lr = 0.001
I1008 04:19:53.738832  5299 solver.cpp:218] Iteration 84800 (3.97145 iter/s, 25.1797s/100 iters), loss = 0.00413855
I1008 04:19:53.738940  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00413872 (* 1 = 0.00413872 loss)
I1008 04:19:53.738948  5299 sgd_solver.cpp:105] Iteration 84800, lr = 0.001
I1008 04:20:18.419363  5299 solver.cpp:218] Iteration 84900 (4.05181 iter/s, 24.6803s/100 iters), loss = 0.00651151
I1008 04:20:18.419414  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00651168 (* 1 = 0.00651168 loss)
I1008 04:20:18.419422  5299 sgd_solver.cpp:105] Iteration 84900, lr = 0.001
I1008 04:20:41.913734  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:20:42.860772  5299 solver.cpp:330] Iteration 85000, Testing net (#0)
I1008 04:20:47.773589  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:20:47.984143  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9229
I1008 04:20:47.984170  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.327105 (* 1 = 0.327105 loss)
I1008 04:20:48.178293  5299 solver.cpp:218] Iteration 85000 (3.36035 iter/s, 29.7588s/100 iters), loss = 0.00476941
I1008 04:20:48.178328  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00476959 (* 1 = 0.00476959 loss)
I1008 04:20:48.178334  5299 sgd_solver.cpp:105] Iteration 85000, lr = 0.001
I1008 04:21:12.862064  5299 solver.cpp:218] Iteration 85100 (4.05197 iter/s, 24.6794s/100 iters), loss = 0.00597031
I1008 04:21:12.862151  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00597049 (* 1 = 0.00597049 loss)
I1008 04:21:12.862159  5299 sgd_solver.cpp:105] Iteration 85100, lr = 0.001
I1008 04:21:38.114403  5299 solver.cpp:218] Iteration 85200 (3.96007 iter/s, 25.2521s/100 iters), loss = 0.00289172
I1008 04:21:38.114435  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00289189 (* 1 = 0.00289189 loss)
I1008 04:21:38.114442  5299 sgd_solver.cpp:105] Iteration 85200, lr = 0.001
I1008 04:22:03.424813  5299 solver.cpp:218] Iteration 85300 (3.95097 iter/s, 25.3103s/100 iters), loss = 0.00216566
I1008 04:22:03.424898  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00216583 (* 1 = 0.00216583 loss)
I1008 04:22:03.424909  5299 sgd_solver.cpp:105] Iteration 85300, lr = 0.001
I1008 04:22:28.062911  5299 solver.cpp:218] Iteration 85400 (4.05879 iter/s, 24.6379s/100 iters), loss = 0.00549157
I1008 04:22:28.062944  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00549174 (* 1 = 0.00549174 loss)
I1008 04:22:28.062950  5299 sgd_solver.cpp:105] Iteration 85400, lr = 0.001
I1008 04:22:51.489258  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:22:52.469676  5299 solver.cpp:330] Iteration 85500, Testing net (#0)
I1008 04:22:57.454651  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:22:57.627012  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9225
I1008 04:22:57.627038  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.325555 (* 1 = 0.325555 loss)
I1008 04:22:57.830212  5299 solver.cpp:218] Iteration 85500 (3.35941 iter/s, 29.7671s/100 iters), loss = 0.00584769
I1008 04:22:57.830250  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00584785 (* 1 = 0.00584785 loss)
I1008 04:22:57.830256  5299 sgd_solver.cpp:105] Iteration 85500, lr = 0.001
I1008 04:23:22.466027  5299 solver.cpp:218] Iteration 85600 (4.05915 iter/s, 24.6357s/100 iters), loss = 0.00109861
I1008 04:23:22.466112  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00109877 (* 1 = 0.00109877 loss)
I1008 04:23:22.466120  5299 sgd_solver.cpp:105] Iteration 85600, lr = 0.001
I1008 04:23:47.690681  5299 solver.cpp:218] Iteration 85700 (3.96441 iter/s, 25.2244s/100 iters), loss = 0.00535585
I1008 04:23:47.690714  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00535601 (* 1 = 0.00535601 loss)
I1008 04:23:47.690721  5299 sgd_solver.cpp:105] Iteration 85700, lr = 0.001
I1008 04:24:13.010741  5299 solver.cpp:218] Iteration 85800 (3.94946 iter/s, 25.3199s/100 iters), loss = 0.00413997
I1008 04:24:13.010845  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00414014 (* 1 = 0.00414014 loss)
I1008 04:24:13.010859  5299 sgd_solver.cpp:105] Iteration 85800, lr = 0.001
I1008 04:24:37.661064  5299 solver.cpp:218] Iteration 85900 (4.05678 iter/s, 24.6501s/100 iters), loss = 0.00359391
I1008 04:24:37.661103  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00359409 (* 1 = 0.00359409 loss)
I1008 04:24:37.661121  5299 sgd_solver.cpp:105] Iteration 85900, lr = 0.001
I1008 04:25:01.067260  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:25:02.053555  5299 solver.cpp:330] Iteration 86000, Testing net (#0)
I1008 04:25:06.940454  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:25:07.175374  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9224
I1008 04:25:07.175400  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.32789 (* 1 = 0.32789 loss)
I1008 04:25:07.355130  5299 solver.cpp:218] Iteration 86000 (3.36769 iter/s, 29.6939s/100 iters), loss = 0.0017285
I1008 04:25:07.355186  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00172868 (* 1 = 0.00172868 loss)
I1008 04:25:07.355196  5299 sgd_solver.cpp:105] Iteration 86000, lr = 0.001
I1008 04:25:32.059140  5299 solver.cpp:218] Iteration 86100 (4.04865 iter/s, 24.6996s/100 iters), loss = 0.00248246
I1008 04:25:32.059221  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00248263 (* 1 = 0.00248263 loss)
I1008 04:25:32.059228  5299 sgd_solver.cpp:105] Iteration 86100, lr = 0.001
I1008 04:25:57.309733  5299 solver.cpp:218] Iteration 86200 (3.96034 iter/s, 25.2504s/100 iters), loss = 0.0225441
I1008 04:25:57.309769  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0225442 (* 1 = 0.0225442 loss)
I1008 04:25:57.309777  5299 sgd_solver.cpp:105] Iteration 86200, lr = 0.001
I1008 04:26:22.636816  5299 solver.cpp:218] Iteration 86300 (3.94837 iter/s, 25.3269s/100 iters), loss = 0.00169156
I1008 04:26:22.636885  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00169174 (* 1 = 0.00169174 loss)
I1008 04:26:22.636893  5299 sgd_solver.cpp:105] Iteration 86300, lr = 0.001
I1008 04:26:47.272637  5299 solver.cpp:218] Iteration 86400 (4.05915 iter/s, 24.6357s/100 iters), loss = 0.00594422
I1008 04:26:47.272673  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00594439 (* 1 = 0.00594439 loss)
I1008 04:26:47.272691  5299 sgd_solver.cpp:105] Iteration 86400, lr = 0.001
I1008 04:27:10.681780  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:27:11.665627  5299 solver.cpp:330] Iteration 86500, Testing net (#0)
I1008 04:27:16.643370  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:27:16.791930  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9232
I1008 04:27:16.791965  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.326408 (* 1 = 0.326408 loss)
I1008 04:27:17.023181  5299 solver.cpp:218] Iteration 86500 (3.3613 iter/s, 29.7504s/100 iters), loss = 0.00729736
I1008 04:27:17.023216  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00729753 (* 1 = 0.00729753 loss)
I1008 04:27:17.023223  5299 sgd_solver.cpp:105] Iteration 86500, lr = 0.001
I1008 04:27:41.643589  5299 solver.cpp:218] Iteration 86600 (4.0617 iter/s, 24.6203s/100 iters), loss = 0.00714977
I1008 04:27:41.643700  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00714994 (* 1 = 0.00714994 loss)
I1008 04:27:41.643715  5299 sgd_solver.cpp:105] Iteration 86600, lr = 0.001
I1008 04:28:06.899265  5299 solver.cpp:218] Iteration 86700 (3.95954 iter/s, 25.2554s/100 iters), loss = 0.00192492
I1008 04:28:06.899296  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00192509 (* 1 = 0.00192509 loss)
I1008 04:28:06.899303  5299 sgd_solver.cpp:105] Iteration 86700, lr = 0.001
I1008 04:28:32.157389  5299 solver.cpp:218] Iteration 86800 (3.95914 iter/s, 25.258s/100 iters), loss = 0.00241196
I1008 04:28:32.157485  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00241214 (* 1 = 0.00241214 loss)
I1008 04:28:32.157493  5299 sgd_solver.cpp:105] Iteration 86800, lr = 0.001
I1008 04:28:56.809967  5299 solver.cpp:218] Iteration 86900 (4.05641 iter/s, 24.6523s/100 iters), loss = 0.00428603
I1008 04:28:56.810001  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0042862 (* 1 = 0.0042862 loss)
I1008 04:28:56.810008  5299 sgd_solver.cpp:105] Iteration 86900, lr = 0.001
I1008 04:29:20.412595  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:29:21.401068  5299 solver.cpp:330] Iteration 87000, Testing net (#0)
I1008 04:29:26.473179  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:29:26.670693  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9229
I1008 04:29:26.670719  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.325036 (* 1 = 0.325036 loss)
I1008 04:29:26.911510  5299 solver.cpp:218] Iteration 87000 (3.32211 iter/s, 30.1014s/100 iters), loss = 0.00584059
I1008 04:29:26.911546  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00584076 (* 1 = 0.00584076 loss)
I1008 04:29:26.911552  5299 sgd_solver.cpp:105] Iteration 87000, lr = 0.001
I1008 04:29:51.731060  5299 solver.cpp:218] Iteration 87100 (4.02911 iter/s, 24.8194s/100 iters), loss = 0.00675342
I1008 04:29:51.731197  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00675359 (* 1 = 0.00675359 loss)
I1008 04:29:51.731205  5299 sgd_solver.cpp:105] Iteration 87100, lr = 0.001
I1008 04:30:17.066522  5299 solver.cpp:218] Iteration 87200 (3.94708 iter/s, 25.3352s/100 iters), loss = 0.00331569
I1008 04:30:17.066555  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00331586 (* 1 = 0.00331586 loss)
I1008 04:30:17.066562  5299 sgd_solver.cpp:105] Iteration 87200, lr = 0.001
I1008 04:30:42.386834  5299 solver.cpp:218] Iteration 87300 (3.94942 iter/s, 25.3202s/100 iters), loss = 0.00268806
I1008 04:30:42.386914  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00268823 (* 1 = 0.00268823 loss)
I1008 04:30:42.386921  5299 sgd_solver.cpp:105] Iteration 87300, lr = 0.001
I1008 04:31:07.048140  5299 solver.cpp:218] Iteration 87400 (4.05497 iter/s, 24.6611s/100 iters), loss = 0.00236542
I1008 04:31:07.048171  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00236559 (* 1 = 0.00236559 loss)
I1008 04:31:07.048178  5299 sgd_solver.cpp:105] Iteration 87400, lr = 0.001
I1008 04:31:30.475497  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:31:31.456127  5299 solver.cpp:330] Iteration 87500, Testing net (#0)
I1008 04:31:36.347214  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:31:36.571240  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.923
I1008 04:31:36.571269  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.3263 (* 1 = 0.3263 loss)
I1008 04:31:36.765416  5299 solver.cpp:218] Iteration 87500 (3.36506 iter/s, 29.7171s/100 iters), loss = 0.0018784
I1008 04:31:36.765453  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00187857 (* 1 = 0.00187857 loss)
I1008 04:31:36.765461  5299 sgd_solver.cpp:105] Iteration 87500, lr = 0.001
I1008 04:32:01.470963  5299 solver.cpp:218] Iteration 87600 (4.04839 iter/s, 24.7012s/100 iters), loss = 0.00542734
I1008 04:32:01.471046  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00542751 (* 1 = 0.00542751 loss)
I1008 04:32:01.471055  5299 sgd_solver.cpp:105] Iteration 87600, lr = 0.001
I1008 04:32:26.735416  5299 solver.cpp:218] Iteration 87700 (3.95817 iter/s, 25.2642s/100 iters), loss = 0.00379711
I1008 04:32:26.735451  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00379728 (* 1 = 0.00379728 loss)
I1008 04:32:26.735457  5299 sgd_solver.cpp:105] Iteration 87700, lr = 0.001
I1008 04:32:51.892452  5299 solver.cpp:218] Iteration 87800 (3.97505 iter/s, 25.1569s/100 iters), loss = 0.00415422
I1008 04:32:51.892544  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00415439 (* 1 = 0.00415439 loss)
I1008 04:32:51.892552  5299 sgd_solver.cpp:105] Iteration 87800, lr = 0.001
I1008 04:33:16.514320  5299 solver.cpp:218] Iteration 87900 (4.06147 iter/s, 24.6216s/100 iters), loss = 0.00869676
I1008 04:33:16.514356  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00869694 (* 1 = 0.00869694 loss)
I1008 04:33:16.514364  5299 sgd_solver.cpp:105] Iteration 87900, lr = 0.001
I1008 04:33:39.918752  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:33:40.893906  5299 solver.cpp:330] Iteration 88000, Testing net (#0)
I1008 04:33:45.785586  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:33:46.010601  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9224
I1008 04:33:46.010627  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.32759 (* 1 = 0.32759 loss)
I1008 04:33:46.175005  5299 solver.cpp:218] Iteration 88000 (3.37148 iter/s, 29.6605s/100 iters), loss = 0.00534317
I1008 04:33:46.175038  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00534335 (* 1 = 0.00534335 loss)
I1008 04:33:46.175045  5299 sgd_solver.cpp:105] Iteration 88000, lr = 0.001
I1008 04:34:10.900951  5299 solver.cpp:218] Iteration 88100 (4.04505 iter/s, 24.7216s/100 iters), loss = 0.00183275
I1008 04:34:10.901021  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00183293 (* 1 = 0.00183293 loss)
I1008 04:34:10.901033  5299 sgd_solver.cpp:105] Iteration 88100, lr = 0.001
I1008 04:34:36.151991  5299 solver.cpp:218] Iteration 88200 (3.96026 iter/s, 25.2509s/100 iters), loss = 0.00164385
I1008 04:34:36.152034  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00164403 (* 1 = 0.00164403 loss)
I1008 04:34:36.152040  5299 sgd_solver.cpp:105] Iteration 88200, lr = 0.001
I1008 04:35:01.474898  5299 solver.cpp:218] Iteration 88300 (3.94902 iter/s, 25.3228s/100 iters), loss = 0.00341005
I1008 04:35:01.474970  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00341023 (* 1 = 0.00341023 loss)
I1008 04:35:01.474978  5299 sgd_solver.cpp:105] Iteration 88300, lr = 0.001
I1008 04:35:26.123291  5299 solver.cpp:218] Iteration 88400 (4.05708 iter/s, 24.6482s/100 iters), loss = 0.00437469
I1008 04:35:26.123333  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00437487 (* 1 = 0.00437487 loss)
I1008 04:35:26.123339  5299 sgd_solver.cpp:105] Iteration 88400, lr = 0.001
I1008 04:35:49.549527  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:35:50.534117  5299 solver.cpp:330] Iteration 88500, Testing net (#0)
I1008 04:35:55.414819  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:35:55.655246  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9222
I1008 04:35:55.655278  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.32818 (* 1 = 0.32818 loss)
I1008 04:35:55.819407  5299 solver.cpp:218] Iteration 88500 (3.36746 iter/s, 29.696s/100 iters), loss = 0.00383327
I1008 04:35:55.819444  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00383346 (* 1 = 0.00383346 loss)
I1008 04:35:55.819464  5299 sgd_solver.cpp:105] Iteration 88500, lr = 0.001
I1008 04:36:20.545523  5299 solver.cpp:218] Iteration 88600 (4.04503 iter/s, 24.7217s/100 iters), loss = 0.0122591
I1008 04:36:20.545641  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0122593 (* 1 = 0.0122593 loss)
I1008 04:36:20.545655  5299 sgd_solver.cpp:105] Iteration 88600, lr = 0.001
I1008 04:36:45.840430  5299 solver.cpp:218] Iteration 88700 (3.9534 iter/s, 25.2947s/100 iters), loss = 0.00381501
I1008 04:36:45.840466  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00381519 (* 1 = 0.00381519 loss)
I1008 04:36:45.840477  5299 sgd_solver.cpp:105] Iteration 88700, lr = 0.001
I1008 04:37:11.116971  5299 solver.cpp:218] Iteration 88800 (3.95626 iter/s, 25.2764s/100 iters), loss = 0.00229001
I1008 04:37:11.117072  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00229019 (* 1 = 0.00229019 loss)
I1008 04:37:11.117090  5299 sgd_solver.cpp:105] Iteration 88800, lr = 0.001
I1008 04:37:35.740591  5299 solver.cpp:218] Iteration 88900 (4.06118 iter/s, 24.6234s/100 iters), loss = 0.0020658
I1008 04:37:35.740628  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00206598 (* 1 = 0.00206598 loss)
I1008 04:37:35.740636  5299 sgd_solver.cpp:105] Iteration 88900, lr = 0.001
I1008 04:37:59.149613  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:38:00.127943  5299 solver.cpp:330] Iteration 89000, Testing net (#0)
I1008 04:38:05.159893  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:38:05.311432  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9224
I1008 04:38:05.311462  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.327272 (* 1 = 0.327272 loss)
I1008 04:38:05.488965  5299 solver.cpp:218] Iteration 89000 (3.36155 iter/s, 29.7482s/100 iters), loss = 0.00540124
I1008 04:38:05.489001  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00540142 (* 1 = 0.00540142 loss)
I1008 04:38:05.489009  5299 sgd_solver.cpp:105] Iteration 89000, lr = 0.001
I1008 04:38:30.105577  5299 solver.cpp:218] Iteration 89100 (4.06232 iter/s, 24.6165s/100 iters), loss = 0.00333106
I1008 04:38:30.105654  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00333124 (* 1 = 0.00333124 loss)
I1008 04:38:30.105661  5299 sgd_solver.cpp:105] Iteration 89100, lr = 0.001
I1008 04:38:55.587409  5299 solver.cpp:218] Iteration 89200 (3.9244 iter/s, 25.4816s/100 iters), loss = 0.0138262
I1008 04:38:55.587443  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0138264 (* 1 = 0.0138264 loss)
I1008 04:38:55.587451  5299 sgd_solver.cpp:105] Iteration 89200, lr = 0.001
I1008 04:39:20.740522  5299 solver.cpp:218] Iteration 89300 (3.97601 iter/s, 25.1508s/100 iters), loss = 0.00285958
I1008 04:39:20.740594  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00285976 (* 1 = 0.00285976 loss)
I1008 04:39:20.740603  5299 sgd_solver.cpp:105] Iteration 89300, lr = 0.001
I1008 04:39:45.390588  5299 solver.cpp:218] Iteration 89400 (4.05681 iter/s, 24.6499s/100 iters), loss = 0.00107123
I1008 04:39:45.390624  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00107141 (* 1 = 0.00107141 loss)
I1008 04:39:45.390630  5299 sgd_solver.cpp:105] Iteration 89400, lr = 0.001
I1008 04:40:08.818507  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:40:09.802486  5299 solver.cpp:330] Iteration 89500, Testing net (#0)
I1008 04:40:14.757362  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:40:14.923496  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9222
I1008 04:40:14.923526  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.328882 (* 1 = 0.328882 loss)
I1008 04:40:15.164079  5299 solver.cpp:218] Iteration 89500 (3.35871 iter/s, 29.7733s/100 iters), loss = 0.00252845
I1008 04:40:15.164116  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00252863 (* 1 = 0.00252863 loss)
I1008 04:40:15.164125  5299 sgd_solver.cpp:105] Iteration 89500, lr = 0.001
I1008 04:40:39.789171  5299 solver.cpp:218] Iteration 89600 (4.06092 iter/s, 24.6249s/100 iters), loss = 0.00393174
I1008 04:40:39.789250  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00393192 (* 1 = 0.00393192 loss)
I1008 04:40:39.789258  5299 sgd_solver.cpp:105] Iteration 89600, lr = 0.001
I1008 04:41:05.423926  5299 solver.cpp:218] Iteration 89700 (3.90099 iter/s, 25.6345s/100 iters), loss = 0.0041125
I1008 04:41:05.423959  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00411268 (* 1 = 0.00411268 loss)
I1008 04:41:05.423965  5299 sgd_solver.cpp:105] Iteration 89700, lr = 0.001
I1008 04:41:30.442193  5299 solver.cpp:218] Iteration 89800 (3.9971 iter/s, 25.0181s/100 iters), loss = 0.0031931
I1008 04:41:30.442296  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00319329 (* 1 = 0.00319329 loss)
I1008 04:41:30.442303  5299 sgd_solver.cpp:105] Iteration 89800, lr = 0.001
I1008 04:41:55.085834  5299 solver.cpp:218] Iteration 89900 (4.05788 iter/s, 24.6434s/100 iters), loss = 0.00399976
I1008 04:41:55.085866  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00399994 (* 1 = 0.00399994 loss)
I1008 04:41:55.085872  5299 sgd_solver.cpp:105] Iteration 89900, lr = 0.001
I1008 04:42:18.507973  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:42:19.478487  5299 solver.cpp:330] Iteration 90000, Testing net (#0)
I1008 04:42:24.513929  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:42:24.728297  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9229
I1008 04:42:24.728325  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.327672 (* 1 = 0.327672 loss)
I1008 04:42:24.859959  5299 solver.cpp:218] Iteration 90000 (3.35864 iter/s, 29.774s/100 iters), loss = 0.00983154
I1008 04:42:24.859989  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00983172 (* 1 = 0.00983172 loss)
I1008 04:42:24.859997  5299 sgd_solver.cpp:105] Iteration 90000, lr = 0.001
I1008 04:42:49.654361  5299 solver.cpp:218] Iteration 90100 (4.03347 iter/s, 24.7926s/100 iters), loss = 0.00154073
I1008 04:42:49.654438  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00154091 (* 1 = 0.00154091 loss)
I1008 04:42:49.654445  5299 sgd_solver.cpp:105] Iteration 90100, lr = 0.001
I1008 04:43:15.395881  5299 solver.cpp:218] Iteration 90200 (3.88481 iter/s, 25.7413s/100 iters), loss = 0.0039624
I1008 04:43:15.395915  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00396259 (* 1 = 0.00396259 loss)
I1008 04:43:15.395922  5299 sgd_solver.cpp:105] Iteration 90200, lr = 0.001
I1008 04:43:40.256270  5299 solver.cpp:218] Iteration 90300 (4.02249 iter/s, 24.8602s/100 iters), loss = 0.00161161
I1008 04:43:40.256353  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00161179 (* 1 = 0.00161179 loss)
I1008 04:43:40.256361  5299 sgd_solver.cpp:105] Iteration 90300, lr = 0.001
I1008 04:44:05.066087  5299 solver.cpp:218] Iteration 90400 (4.03069 iter/s, 24.8097s/100 iters), loss = 0.00161795
I1008 04:44:05.066113  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00161814 (* 1 = 0.00161814 loss)
I1008 04:44:05.066119  5299 sgd_solver.cpp:105] Iteration 90400, lr = 0.001
I1008 04:44:28.496136  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:44:29.476119  5299 solver.cpp:330] Iteration 90500, Testing net (#0)
I1008 04:44:34.499794  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:44:34.740746  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9222
I1008 04:44:34.740773  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.326953 (* 1 = 0.326953 loss)
I1008 04:44:34.855844  5299 solver.cpp:218] Iteration 90500 (3.35688 iter/s, 29.7896s/100 iters), loss = 0.0045376
I1008 04:44:34.855881  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00453778 (* 1 = 0.00453778 loss)
I1008 04:44:34.855890  5299 sgd_solver.cpp:105] Iteration 90500, lr = 0.001
I1008 04:44:59.625547  5299 solver.cpp:218] Iteration 90600 (4.0378 iter/s, 24.766s/100 iters), loss = 0.00678693
I1008 04:44:59.625639  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00678712 (* 1 = 0.00678712 loss)
I1008 04:44:59.625650  5299 sgd_solver.cpp:105] Iteration 90600, lr = 0.001
I1008 04:45:25.426564  5299 solver.cpp:218] Iteration 90700 (3.87585 iter/s, 25.8008s/100 iters), loss = 0.00409235
I1008 04:45:25.426599  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00409253 (* 1 = 0.00409253 loss)
I1008 04:45:25.426611  5299 sgd_solver.cpp:105] Iteration 90700, lr = 0.001
I1008 04:45:50.133435  5299 solver.cpp:218] Iteration 90800 (4.04817 iter/s, 24.7025s/100 iters), loss = 0.000989814
I1008 04:45:50.133553  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000989999 (* 1 = 0.000989999 loss)
I1008 04:45:50.133563  5299 sgd_solver.cpp:105] Iteration 90800, lr = 0.001
I1008 04:46:14.769291  5299 solver.cpp:218] Iteration 90900 (4.05916 iter/s, 24.6356s/100 iters), loss = 0.00235892
I1008 04:46:14.769336  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00235911 (* 1 = 0.00235911 loss)
I1008 04:46:14.769343  5299 sgd_solver.cpp:105] Iteration 90900, lr = 0.001
I1008 04:46:38.209134  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:46:39.196188  5299 solver.cpp:330] Iteration 91000, Testing net (#0)
I1008 04:46:44.068301  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:46:44.310534  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9224
I1008 04:46:44.310570  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.326756 (* 1 = 0.326756 loss)
I1008 04:46:44.415148  5299 solver.cpp:218] Iteration 91000 (3.37317 iter/s, 29.6457s/100 iters), loss = 0.0107503
I1008 04:46:44.415194  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0107505 (* 1 = 0.0107505 loss)
I1008 04:46:44.415204  5299 sgd_solver.cpp:105] Iteration 91000, lr = 0.001
I1008 04:47:09.190318  5299 solver.cpp:218] Iteration 91100 (4.03701 iter/s, 24.7708s/100 iters), loss = 0.00239969
I1008 04:47:09.190397  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00239988 (* 1 = 0.00239988 loss)
I1008 04:47:09.190404  5299 sgd_solver.cpp:105] Iteration 91100, lr = 0.001
I1008 04:47:34.984134  5299 solver.cpp:218] Iteration 91200 (3.87693 iter/s, 25.7936s/100 iters), loss = 0.00380555
I1008 04:47:34.984165  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00380573 (* 1 = 0.00380573 loss)
I1008 04:47:34.984171  5299 sgd_solver.cpp:105] Iteration 91200, lr = 0.001
I1008 04:47:59.765476  5299 solver.cpp:218] Iteration 91300 (4.03532 iter/s, 24.7812s/100 iters), loss = 0.0078483
I1008 04:47:59.765563  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00784849 (* 1 = 0.00784849 loss)
I1008 04:47:59.765580  5299 sgd_solver.cpp:105] Iteration 91300, lr = 0.001
I1008 04:48:24.407796  5299 solver.cpp:218] Iteration 91400 (4.05808 iter/s, 24.6422s/100 iters), loss = 0.00464051
I1008 04:48:24.407840  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0046407 (* 1 = 0.0046407 loss)
I1008 04:48:24.407846  5299 sgd_solver.cpp:105] Iteration 91400, lr = 0.001
I1008 04:48:47.818969  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:48:48.800040  5299 solver.cpp:330] Iteration 91500, Testing net (#0)
I1008 04:48:53.678591  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:48:53.920872  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9226
I1008 04:48:53.920899  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.326846 (* 1 = 0.326846 loss)
I1008 04:48:54.045770  5299 solver.cpp:218] Iteration 91500 (3.37407 iter/s, 29.6378s/100 iters), loss = 0.000393405
I1008 04:48:54.045814  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000393592 (* 1 = 0.000393592 loss)
I1008 04:48:54.045820  5299 sgd_solver.cpp:105] Iteration 91500, lr = 0.001
I1008 04:49:18.783285  5299 solver.cpp:218] Iteration 91600 (4.04246 iter/s, 24.7374s/100 iters), loss = 0.00669086
I1008 04:49:18.783372  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00669105 (* 1 = 0.00669105 loss)
I1008 04:49:18.783381  5299 sgd_solver.cpp:105] Iteration 91600, lr = 0.001
I1008 04:49:44.682637  5299 solver.cpp:218] Iteration 91700 (3.86113 iter/s, 25.8991s/100 iters), loss = 0.0124767
I1008 04:49:44.682672  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0124769 (* 1 = 0.0124769 loss)
I1008 04:49:44.682678  5299 sgd_solver.cpp:105] Iteration 91700, lr = 0.001
I1008 04:50:09.576426  5299 solver.cpp:218] Iteration 91800 (4.01743 iter/s, 24.8915s/100 iters), loss = 0.00163614
I1008 04:50:09.576540  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00163633 (* 1 = 0.00163633 loss)
I1008 04:50:09.576548  5299 sgd_solver.cpp:105] Iteration 91800, lr = 0.001
I1008 04:50:34.201629  5299 solver.cpp:218] Iteration 91900 (4.06092 iter/s, 24.625s/100 iters), loss = 0.00187456
I1008 04:50:34.201664  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00187475 (* 1 = 0.00187475 loss)
I1008 04:50:34.201671  5299 sgd_solver.cpp:105] Iteration 91900, lr = 0.001
I1008 04:50:57.628602  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:50:58.603535  5299 solver.cpp:330] Iteration 92000, Testing net (#0)
I1008 04:51:03.517851  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:51:03.722034  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9232
I1008 04:51:03.722065  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.327542 (* 1 = 0.327542 loss)
I1008 04:51:03.942816  5299 solver.cpp:218] Iteration 92000 (3.36236 iter/s, 29.741s/100 iters), loss = 0.000763117
I1008 04:51:03.942859  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000763307 (* 1 = 0.000763307 loss)
I1008 04:51:03.942867  5299 sgd_solver.cpp:105] Iteration 92000, lr = 0.001
I1008 04:51:28.642168  5299 solver.cpp:218] Iteration 92100 (4.04941 iter/s, 24.695s/100 iters), loss = 0.00436875
I1008 04:51:28.642248  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00436894 (* 1 = 0.00436894 loss)
I1008 04:51:28.642256  5299 sgd_solver.cpp:105] Iteration 92100, lr = 0.001
I1008 04:51:54.565774  5299 solver.cpp:218] Iteration 92200 (3.85752 iter/s, 25.9234s/100 iters), loss = 0.00500754
I1008 04:51:54.565817  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00500773 (* 1 = 0.00500773 loss)
I1008 04:51:54.565824  5299 sgd_solver.cpp:105] Iteration 92200, lr = 0.001
I1008 04:52:19.201058  5299 solver.cpp:218] Iteration 92300 (4.05924 iter/s, 24.6351s/100 iters), loss = 0.00271371
I1008 04:52:19.201138  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0027139 (* 1 = 0.0027139 loss)
I1008 04:52:19.201145  5299 sgd_solver.cpp:105] Iteration 92300, lr = 0.001
I1008 04:52:43.823823  5299 solver.cpp:218] Iteration 92400 (4.06132 iter/s, 24.6225s/100 iters), loss = 0.00124408
I1008 04:52:43.823858  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00124427 (* 1 = 0.00124427 loss)
I1008 04:52:43.823874  5299 sgd_solver.cpp:105] Iteration 92400, lr = 0.001
I1008 04:53:07.225538  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:53:08.207387  5299 solver.cpp:330] Iteration 92500, Testing net (#0)
I1008 04:53:13.085182  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:53:13.326230  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9226
I1008 04:53:13.326257  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.326967 (* 1 = 0.326967 loss)
I1008 04:53:13.490341  5299 solver.cpp:218] Iteration 92500 (3.37082 iter/s, 29.6664s/100 iters), loss = 0.00168814
I1008 04:53:13.490378  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00168832 (* 1 = 0.00168832 loss)
I1008 04:53:13.490398  5299 sgd_solver.cpp:105] Iteration 92500, lr = 0.001
I1008 04:53:38.245666  5299 solver.cpp:218] Iteration 92600 (4.04024 iter/s, 24.751s/100 iters), loss = 0.00256458
I1008 04:53:38.245748  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00256477 (* 1 = 0.00256477 loss)
I1008 04:53:38.245765  5299 sgd_solver.cpp:105] Iteration 92600, lr = 0.001
I1008 04:54:04.094027  5299 solver.cpp:218] Iteration 92700 (3.86906 iter/s, 25.8461s/100 iters), loss = 0.00637217
I1008 04:54:04.094063  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00637236 (* 1 = 0.00637236 loss)
I1008 04:54:04.094070  5299 sgd_solver.cpp:105] Iteration 92700, lr = 0.001
I1008 04:54:28.824717  5299 solver.cpp:218] Iteration 92800 (4.04427 iter/s, 24.7263s/100 iters), loss = 0.00253574
I1008 04:54:28.824805  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00253592 (* 1 = 0.00253592 loss)
I1008 04:54:28.824812  5299 sgd_solver.cpp:105] Iteration 92800, lr = 0.001
I1008 04:54:53.478492  5299 solver.cpp:218] Iteration 92900 (4.05621 iter/s, 24.6535s/100 iters), loss = 0.00399412
I1008 04:54:53.478523  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0039943 (* 1 = 0.0039943 loss)
I1008 04:54:53.478530  5299 sgd_solver.cpp:105] Iteration 92900, lr = 0.001
I1008 04:55:16.915942  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:55:17.890794  5299 solver.cpp:330] Iteration 93000, Testing net (#0)
I1008 04:55:22.917611  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:55:23.055218  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.922
I1008 04:55:23.055248  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.326519 (* 1 = 0.326519 loss)
I1008 04:55:23.252838  5299 solver.cpp:218] Iteration 93000 (3.35861 iter/s, 29.7742s/100 iters), loss = 0.00655969
I1008 04:55:23.252873  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00655987 (* 1 = 0.00655987 loss)
I1008 04:55:23.252881  5299 sgd_solver.cpp:105] Iteration 93000, lr = 0.001
I1008 04:55:48.093201  5299 solver.cpp:218] Iteration 93100 (4.02573 iter/s, 24.8402s/100 iters), loss = 0.00357776
I1008 04:55:48.093281  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00357794 (* 1 = 0.00357794 loss)
I1008 04:55:48.093288  5299 sgd_solver.cpp:105] Iteration 93100, lr = 0.001
I1008 04:56:13.909382  5299 solver.cpp:218] Iteration 93200 (3.87357 iter/s, 25.816s/100 iters), loss = 0.00188041
I1008 04:56:13.909418  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00188059 (* 1 = 0.00188059 loss)
I1008 04:56:13.909426  5299 sgd_solver.cpp:105] Iteration 93200, lr = 0.001
I1008 04:56:38.555316  5299 solver.cpp:218] Iteration 93300 (4.05749 iter/s, 24.6458s/100 iters), loss = 0.000428939
I1008 04:56:38.555402  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00042912 (* 1 = 0.00042912 loss)
I1008 04:56:38.555419  5299 sgd_solver.cpp:105] Iteration 93300, lr = 0.001
I1008 04:57:03.189945  5299 solver.cpp:218] Iteration 93400 (4.05936 iter/s, 24.6344s/100 iters), loss = 0.00130997
I1008 04:57:03.189980  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00131015 (* 1 = 0.00131015 loss)
I1008 04:57:03.189986  5299 sgd_solver.cpp:105] Iteration 93400, lr = 0.001
I1008 04:57:26.627914  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:57:27.610868  5299 solver.cpp:330] Iteration 93500, Testing net (#0)
I1008 04:57:32.603617  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:57:32.771351  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9223
I1008 04:57:32.771386  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.326776 (* 1 = 0.326776 loss)
I1008 04:57:32.973598  5299 solver.cpp:218] Iteration 93500 (3.35756 iter/s, 29.7835s/100 iters), loss = 0.0156787
I1008 04:57:32.973642  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0156789 (* 1 = 0.0156789 loss)
I1008 04:57:32.973649  5299 sgd_solver.cpp:105] Iteration 93500, lr = 0.001
I1008 04:57:57.920280  5299 solver.cpp:218] Iteration 93600 (4.00857 iter/s, 24.9465s/100 iters), loss = 0.000973589
I1008 04:57:57.920344  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000973771 (* 1 = 0.000973771 loss)
I1008 04:57:57.920363  5299 sgd_solver.cpp:105] Iteration 93600, lr = 0.001
I1008 04:58:23.640781  5299 solver.cpp:218] Iteration 93700 (3.88797 iter/s, 25.7203s/100 iters), loss = 0.00843414
I1008 04:58:23.640815  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00843432 (* 1 = 0.00843432 loss)
I1008 04:58:23.640822  5299 sgd_solver.cpp:105] Iteration 93700, lr = 0.001
I1008 04:58:48.284217  5299 solver.cpp:218] Iteration 93800 (4.0579 iter/s, 24.6433s/100 iters), loss = 0.00358358
I1008 04:58:48.284348  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00358376 (* 1 = 0.00358376 loss)
I1008 04:58:48.284358  5299 sgd_solver.cpp:105] Iteration 93800, lr = 0.001
I1008 04:59:12.932795  5299 solver.cpp:218] Iteration 93900 (4.05707 iter/s, 24.6484s/100 iters), loss = 0.0028777
I1008 04:59:12.932827  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00287788 (* 1 = 0.00287788 loss)
I1008 04:59:12.932834  5299 sgd_solver.cpp:105] Iteration 93900, lr = 0.001
I1008 04:59:36.372483  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:59:37.355715  5299 solver.cpp:330] Iteration 94000, Testing net (#0)
I1008 04:59:42.259917  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 04:59:42.476084  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9226
I1008 04:59:42.476111  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.326891 (* 1 = 0.326891 loss)
I1008 04:59:42.659551  5299 solver.cpp:218] Iteration 94000 (3.36399 iter/s, 29.7266s/100 iters), loss = 0.00314243
I1008 04:59:42.659587  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00314261 (* 1 = 0.00314261 loss)
I1008 04:59:42.659595  5299 sgd_solver.cpp:105] Iteration 94000, lr = 0.001
I1008 05:00:07.720461  5299 solver.cpp:218] Iteration 94100 (3.99097 iter/s, 25.0566s/100 iters), loss = 0.00947624
I1008 05:00:07.720551  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00947643 (* 1 = 0.00947643 loss)
I1008 05:00:07.720561  5299 sgd_solver.cpp:105] Iteration 94100, lr = 0.001
I1008 05:00:33.192659  5299 solver.cpp:218] Iteration 94200 (3.92591 iter/s, 25.4718s/100 iters), loss = 0.00223059
I1008 05:00:33.192703  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00223078 (* 1 = 0.00223078 loss)
I1008 05:00:33.192713  5299 sgd_solver.cpp:105] Iteration 94200, lr = 0.001
I1008 05:00:57.946885  5299 solver.cpp:218] Iteration 94300 (4.04008 iter/s, 24.752s/100 iters), loss = 0.00186639
I1008 05:00:57.946995  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00186658 (* 1 = 0.00186658 loss)
I1008 05:00:57.947007  5299 sgd_solver.cpp:105] Iteration 94300, lr = 0.001
I1008 05:01:22.569967  5299 solver.cpp:218] Iteration 94400 (4.06127 iter/s, 24.6229s/100 iters), loss = 0.00156836
I1008 05:01:22.570003  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00156855 (* 1 = 0.00156855 loss)
I1008 05:01:22.570014  5299 sgd_solver.cpp:105] Iteration 94400, lr = 0.001
I1008 05:01:45.980295  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 05:01:46.957725  5299 solver.cpp:330] Iteration 94500, Testing net (#0)
I1008 05:01:51.993444  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 05:01:52.185189  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9232
I1008 05:01:52.185215  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.327084 (* 1 = 0.327084 loss)
I1008 05:01:52.321573  5299 solver.cpp:218] Iteration 94500 (3.36118 iter/s, 29.7515s/100 iters), loss = 0.00215305
I1008 05:01:52.321605  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00215324 (* 1 = 0.00215324 loss)
I1008 05:01:52.321612  5299 sgd_solver.cpp:105] Iteration 94500, lr = 0.001
I1008 05:02:17.614086  5299 solver.cpp:218] Iteration 94600 (3.95376 iter/s, 25.2924s/100 iters), loss = 0.00416454
I1008 05:02:17.614183  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00416473 (* 1 = 0.00416473 loss)
I1008 05:02:17.614193  5299 sgd_solver.cpp:105] Iteration 94600, lr = 0.001
I1008 05:02:43.054316  5299 solver.cpp:218] Iteration 94700 (3.93113 iter/s, 25.438s/100 iters), loss = 0.00407211
I1008 05:02:43.054352  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0040723 (* 1 = 0.0040723 loss)
I1008 05:02:43.054358  5299 sgd_solver.cpp:105] Iteration 94700, lr = 0.001
I1008 05:03:07.671166  5299 solver.cpp:218] Iteration 94800 (4.06228 iter/s, 24.6167s/100 iters), loss = 0.00431845
I1008 05:03:07.671273  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00431864 (* 1 = 0.00431864 loss)
I1008 05:03:07.671296  5299 sgd_solver.cpp:105] Iteration 94800, lr = 0.001
I1008 05:03:32.294522  5299 solver.cpp:218] Iteration 94900 (4.06122 iter/s, 24.6231s/100 iters), loss = 0.00588522
I1008 05:03:32.294558  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00588541 (* 1 = 0.00588541 loss)
I1008 05:03:32.294565  5299 sgd_solver.cpp:105] Iteration 94900, lr = 0.001
I1008 05:03:55.724535  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 05:03:56.701081  5299 solver.cpp:330] Iteration 95000, Testing net (#0)
I1008 05:04:01.611748  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 05:04:01.815963  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.922
I1008 05:04:01.815989  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.327535 (* 1 = 0.327535 loss)
I1008 05:04:02.046325  5299 solver.cpp:218] Iteration 95000 (3.36116 iter/s, 29.7516s/100 iters), loss = 0.00285071
I1008 05:04:02.046362  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0028509 (* 1 = 0.0028509 loss)
I1008 05:04:02.046370  5299 sgd_solver.cpp:105] Iteration 95000, lr = 0.001
I1008 05:04:27.313397  5299 solver.cpp:218] Iteration 95100 (3.9584 iter/s, 25.2627s/100 iters), loss = 0.00300109
I1008 05:04:27.313482  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00300128 (* 1 = 0.00300128 loss)
I1008 05:04:27.313490  5299 sgd_solver.cpp:105] Iteration 95100, lr = 0.001
I1008 05:04:52.549242  5299 solver.cpp:218] Iteration 95200 (3.96265 iter/s, 25.2356s/100 iters), loss = 0.00343282
I1008 05:04:52.549274  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00343302 (* 1 = 0.00343302 loss)
I1008 05:04:52.549291  5299 sgd_solver.cpp:105] Iteration 95200, lr = 0.001
I1008 05:05:17.193617  5299 solver.cpp:218] Iteration 95300 (4.05774 iter/s, 24.6442s/100 iters), loss = 0.0025307
I1008 05:05:17.193699  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0025309 (* 1 = 0.0025309 loss)
I1008 05:05:17.193707  5299 sgd_solver.cpp:105] Iteration 95300, lr = 0.001
I1008 05:05:41.826802  5299 solver.cpp:218] Iteration 95400 (4.0596 iter/s, 24.633s/100 iters), loss = 0.00153814
I1008 05:05:41.826834  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00153834 (* 1 = 0.00153834 loss)
I1008 05:05:41.826840  5299 sgd_solver.cpp:105] Iteration 95400, lr = 0.001
I1008 05:06:05.257547  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 05:06:06.240377  5299 solver.cpp:330] Iteration 95500, Testing net (#0)
I1008 05:06:11.178184  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 05:06:11.365288  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9217
I1008 05:06:11.365314  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.327675 (* 1 = 0.327675 loss)
I1008 05:06:11.606839  5299 solver.cpp:218] Iteration 95500 (3.35797 iter/s, 29.7799s/100 iters), loss = 0.00186249
I1008 05:06:11.606894  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00186269 (* 1 = 0.00186269 loss)
I1008 05:06:11.606915  5299 sgd_solver.cpp:105] Iteration 95500, lr = 0.001
I1008 05:06:36.844240  5299 solver.cpp:218] Iteration 95600 (3.9624 iter/s, 25.2372s/100 iters), loss = 0.00226205
I1008 05:06:36.844316  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00226225 (* 1 = 0.00226225 loss)
I1008 05:06:36.844324  5299 sgd_solver.cpp:105] Iteration 95600, lr = 0.001
I1008 05:07:02.083117  5299 solver.cpp:218] Iteration 95700 (3.96218 iter/s, 25.2387s/100 iters), loss = 0.00239464
I1008 05:07:02.083149  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00239484 (* 1 = 0.00239484 loss)
I1008 05:07:02.083156  5299 sgd_solver.cpp:105] Iteration 95700, lr = 0.001
I1008 05:07:26.722439  5299 solver.cpp:218] Iteration 95800 (4.05858 iter/s, 24.6392s/100 iters), loss = 0.0022153
I1008 05:07:26.722520  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0022155 (* 1 = 0.0022155 loss)
I1008 05:07:26.722532  5299 sgd_solver.cpp:105] Iteration 95800, lr = 0.001
I1008 05:07:51.371536  5299 solver.cpp:218] Iteration 95900 (4.05698 iter/s, 24.6489s/100 iters), loss = 0.0024189
I1008 05:07:51.371582  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0024191 (* 1 = 0.0024191 loss)
I1008 05:07:51.371587  5299 sgd_solver.cpp:105] Iteration 95900, lr = 0.001
I1008 05:08:14.963605  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 05:08:15.950042  5299 solver.cpp:330] Iteration 96000, Testing net (#0)
I1008 05:08:21.027245  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 05:08:21.226888  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9215
I1008 05:08:21.226914  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.328415 (* 1 = 0.328415 loss)
I1008 05:08:21.465024  5299 solver.cpp:218] Iteration 96000 (3.32299 iter/s, 30.0933s/100 iters), loss = 0.00149682
I1008 05:08:21.465065  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00149703 (* 1 = 0.00149703 loss)
I1008 05:08:21.465073  5299 sgd_solver.cpp:105] Iteration 96000, lr = 0.001
I1008 05:08:46.722590  5299 solver.cpp:218] Iteration 96100 (3.95957 iter/s, 25.2553s/100 iters), loss = 0.0101885
I1008 05:08:46.722704  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0101887 (* 1 = 0.0101887 loss)
I1008 05:08:46.722714  5299 sgd_solver.cpp:105] Iteration 96100, lr = 0.001
I1008 05:09:12.055752  5299 solver.cpp:218] Iteration 96200 (3.94743 iter/s, 25.3329s/100 iters), loss = 0.00192385
I1008 05:09:12.055784  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00192405 (* 1 = 0.00192405 loss)
I1008 05:09:12.055793  5299 sgd_solver.cpp:105] Iteration 96200, lr = 0.001
I1008 05:09:36.707471  5299 solver.cpp:218] Iteration 96300 (4.05654 iter/s, 24.6516s/100 iters), loss = 0.00185314
I1008 05:09:36.707551  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00185334 (* 1 = 0.00185334 loss)
I1008 05:09:36.707559  5299 sgd_solver.cpp:105] Iteration 96300, lr = 0.001
I1008 05:10:01.353196  5299 solver.cpp:218] Iteration 96400 (4.05754 iter/s, 24.6455s/100 iters), loss = 0.00105882
I1008 05:10:01.353229  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00105903 (* 1 = 0.00105903 loss)
I1008 05:10:01.353236  5299 sgd_solver.cpp:105] Iteration 96400, lr = 0.001
I1008 05:10:24.778966  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 05:10:25.752411  5299 solver.cpp:330] Iteration 96500, Testing net (#0)
I1008 05:10:30.740906  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 05:10:30.897930  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9223
I1008 05:10:30.897959  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.328008 (* 1 = 0.328008 loss)
I1008 05:10:31.107691  5299 solver.cpp:218] Iteration 96500 (3.36085 iter/s, 29.7543s/100 iters), loss = 0.00161632
I1008 05:10:31.107725  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00161653 (* 1 = 0.00161653 loss)
I1008 05:10:31.107731  5299 sgd_solver.cpp:105] Iteration 96500, lr = 0.001
I1008 05:10:56.352147  5299 solver.cpp:218] Iteration 96600 (3.96129 iter/s, 25.2443s/100 iters), loss = 0.00180357
I1008 05:10:56.352229  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00180377 (* 1 = 0.00180377 loss)
I1008 05:10:56.352241  5299 sgd_solver.cpp:105] Iteration 96600, lr = 0.001
I1008 05:11:21.428961  5299 solver.cpp:218] Iteration 96700 (3.98778 iter/s, 25.0766s/100 iters), loss = 0.0010912
I1008 05:11:21.429008  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0010914 (* 1 = 0.0010914 loss)
I1008 05:11:21.429014  5299 sgd_solver.cpp:105] Iteration 96700, lr = 0.001
I1008 05:11:46.058547  5299 solver.cpp:218] Iteration 96800 (4.06018 iter/s, 24.6294s/100 iters), loss = 0.00143194
I1008 05:11:46.058639  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00143214 (* 1 = 0.00143214 loss)
I1008 05:11:46.058656  5299 sgd_solver.cpp:105] Iteration 96800, lr = 0.001
I1008 05:12:10.682811  5299 solver.cpp:218] Iteration 96900 (4.06107 iter/s, 24.624s/100 iters), loss = 0.00229765
I1008 05:12:10.682847  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00229785 (* 1 = 0.00229785 loss)
I1008 05:12:10.682853  5299 sgd_solver.cpp:105] Iteration 96900, lr = 0.001
I1008 05:12:34.105876  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 05:12:35.090916  5299 solver.cpp:330] Iteration 97000, Testing net (#0)
I1008 05:12:39.994338  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 05:12:40.214694  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9231
I1008 05:12:40.214721  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.327903 (* 1 = 0.327903 loss)
I1008 05:12:40.399775  5299 solver.cpp:218] Iteration 97000 (3.3651 iter/s, 29.7168s/100 iters), loss = 0.000994221
I1008 05:12:40.399817  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000994427 (* 1 = 0.000994427 loss)
I1008 05:12:40.399826  5299 sgd_solver.cpp:105] Iteration 97000, lr = 0.001
I1008 05:13:05.723419  5299 solver.cpp:218] Iteration 97100 (3.94956 iter/s, 25.3193s/100 iters), loss = 0.00515208
I1008 05:13:05.723510  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00515228 (* 1 = 0.00515228 loss)
I1008 05:13:05.723520  5299 sgd_solver.cpp:105] Iteration 97100, lr = 0.001
I1008 05:13:31.052664  5299 solver.cpp:218] Iteration 97200 (3.94804 iter/s, 25.329s/100 iters), loss = 0.00430989
I1008 05:13:31.052712  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00431009 (* 1 = 0.00431009 loss)
I1008 05:13:31.052721  5299 sgd_solver.cpp:105] Iteration 97200, lr = 0.001
I1008 05:13:55.710261  5299 solver.cpp:218] Iteration 97300 (4.05557 iter/s, 24.6575s/100 iters), loss = 0.00183544
I1008 05:13:55.710350  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00183565 (* 1 = 0.00183565 loss)
I1008 05:13:55.710357  5299 sgd_solver.cpp:105] Iteration 97300, lr = 0.001
I1008 05:14:20.332576  5299 solver.cpp:218] Iteration 97400 (4.06139 iter/s, 24.6221s/100 iters), loss = 0.00212453
I1008 05:14:20.332621  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00212474 (* 1 = 0.00212474 loss)
I1008 05:14:20.332628  5299 sgd_solver.cpp:105] Iteration 97400, lr = 0.001
I1008 05:14:43.714359  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 05:14:44.698122  5299 solver.cpp:330] Iteration 97500, Testing net (#0)
I1008 05:14:49.593719  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 05:14:49.814357  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.923
I1008 05:14:49.814385  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.327243 (* 1 = 0.327243 loss)
I1008 05:14:49.993719  5299 solver.cpp:218] Iteration 97500 (3.37143 iter/s, 29.661s/100 iters), loss = 0.00999373
I1008 05:14:49.993754  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00999394 (* 1 = 0.00999394 loss)
I1008 05:14:49.993762  5299 sgd_solver.cpp:105] Iteration 97500, lr = 0.001
I1008 05:15:15.375798  5299 solver.cpp:218] Iteration 97600 (3.94048 iter/s, 25.3776s/100 iters), loss = 0.00340026
I1008 05:15:15.375902  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00340047 (* 1 = 0.00340047 loss)
I1008 05:15:15.375911  5299 sgd_solver.cpp:105] Iteration 97600, lr = 0.001
I1008 05:15:40.626744  5299 solver.cpp:218] Iteration 97700 (3.96028 iter/s, 25.2507s/100 iters), loss = 0.00239676
I1008 05:15:40.626777  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00239697 (* 1 = 0.00239697 loss)
I1008 05:15:40.626785  5299 sgd_solver.cpp:105] Iteration 97700, lr = 0.001
I1008 05:16:05.291242  5299 solver.cpp:218] Iteration 97800 (4.05443 iter/s, 24.6644s/100 iters), loss = 0.00146864
I1008 05:16:05.291393  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00146885 (* 1 = 0.00146885 loss)
I1008 05:16:05.291405  5299 sgd_solver.cpp:105] Iteration 97800, lr = 0.001
I1008 05:16:29.940088  5299 solver.cpp:218] Iteration 97900 (4.05702 iter/s, 24.6486s/100 iters), loss = 0.00614542
I1008 05:16:29.940130  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00614562 (* 1 = 0.00614562 loss)
I1008 05:16:29.940137  5299 sgd_solver.cpp:105] Iteration 97900, lr = 0.001
I1008 05:16:53.383422  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 05:16:54.354327  5299 solver.cpp:330] Iteration 98000, Testing net (#0)
I1008 05:16:59.235530  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 05:16:59.474335  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9226
I1008 05:16:59.474361  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.328249 (* 1 = 0.328249 loss)
I1008 05:16:59.654183  5299 solver.cpp:218] Iteration 98000 (3.36542 iter/s, 29.7139s/100 iters), loss = 0.0018196
I1008 05:16:59.654222  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0018198 (* 1 = 0.0018198 loss)
I1008 05:16:59.654229  5299 sgd_solver.cpp:105] Iteration 98000, lr = 0.001
I1008 05:17:24.972231  5299 solver.cpp:218] Iteration 98100 (3.95044 iter/s, 25.3137s/100 iters), loss = 0.00239296
I1008 05:17:24.972308  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00239316 (* 1 = 0.00239316 loss)
I1008 05:17:24.972317  5299 sgd_solver.cpp:105] Iteration 98100, lr = 0.001
I1008 05:17:50.116798  5299 solver.cpp:218] Iteration 98200 (3.97704 iter/s, 25.1443s/100 iters), loss = 0.000810895
I1008 05:17:50.116832  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000811096 (* 1 = 0.000811096 loss)
I1008 05:17:50.116852  5299 sgd_solver.cpp:105] Iteration 98200, lr = 0.001
I1008 05:18:14.739784  5299 solver.cpp:218] Iteration 98300 (4.06127 iter/s, 24.6228s/100 iters), loss = 0.0024204
I1008 05:18:14.739881  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0024206 (* 1 = 0.0024206 loss)
I1008 05:18:14.739890  5299 sgd_solver.cpp:105] Iteration 98300, lr = 0.001
I1008 05:18:39.362473  5299 solver.cpp:218] Iteration 98400 (4.06133 iter/s, 24.6225s/100 iters), loss = 0.00252607
I1008 05:18:39.362509  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00252627 (* 1 = 0.00252627 loss)
I1008 05:18:39.362516  5299 sgd_solver.cpp:105] Iteration 98400, lr = 0.001
I1008 05:19:02.768738  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 05:19:03.753056  5299 solver.cpp:330] Iteration 98500, Testing net (#0)
I1008 05:19:08.637568  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 05:19:08.878340  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9225
I1008 05:19:08.878367  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.329646 (* 1 = 0.329646 loss)
I1008 05:19:09.056906  5299 solver.cpp:218] Iteration 98500 (3.36765 iter/s, 29.6943s/100 iters), loss = 0.00369983
I1008 05:19:09.056948  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00370004 (* 1 = 0.00370004 loss)
I1008 05:19:09.056957  5299 sgd_solver.cpp:105] Iteration 98500, lr = 0.001
I1008 05:19:34.451683  5299 solver.cpp:218] Iteration 98600 (3.9385 iter/s, 25.3904s/100 iters), loss = 0.00293623
I1008 05:19:34.451813  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00293643 (* 1 = 0.00293643 loss)
I1008 05:19:34.451828  5299 sgd_solver.cpp:105] Iteration 98600, lr = 0.001
I1008 05:19:59.709966  5299 solver.cpp:218] Iteration 98700 (3.95913 iter/s, 25.2581s/100 iters), loss = 0.0035799
I1008 05:19:59.710005  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0035801 (* 1 = 0.0035801 loss)
I1008 05:19:59.710023  5299 sgd_solver.cpp:105] Iteration 98700, lr = 0.001
I1008 05:20:24.378891  5299 solver.cpp:218] Iteration 98800 (4.05371 iter/s, 24.6688s/100 iters), loss = 0.00188321
I1008 05:20:24.378990  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00188341 (* 1 = 0.00188341 loss)
I1008 05:20:24.379012  5299 sgd_solver.cpp:105] Iteration 98800, lr = 0.001
I1008 05:20:49.037267  5299 solver.cpp:218] Iteration 98900 (4.05546 iter/s, 24.6581s/100 iters), loss = 0.00367617
I1008 05:20:49.037304  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00367637 (* 1 = 0.00367637 loss)
I1008 05:20:49.037313  5299 sgd_solver.cpp:105] Iteration 98900, lr = 0.001
I1008 05:21:12.470726  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 05:21:13.452117  5299 solver.cpp:330] Iteration 99000, Testing net (#0)
I1008 05:21:18.324206  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 05:21:18.565320  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9228
I1008 05:21:18.565346  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.328848 (* 1 = 0.328848 loss)
I1008 05:21:18.732825  5299 solver.cpp:218] Iteration 99000 (3.36752 iter/s, 29.6954s/100 iters), loss = 0.00351235
I1008 05:21:18.732868  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00351255 (* 1 = 0.00351255 loss)
I1008 05:21:18.732875  5299 sgd_solver.cpp:105] Iteration 99000, lr = 0.001
I1008 05:21:41.482846  5299 solver.cpp:218] Iteration 99100 (4.39645 iter/s, 22.7456s/100 iters), loss = 0.0030683
I1008 05:21:41.482887  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0030685 (* 1 = 0.0030685 loss)
I1008 05:21:41.482893  5299 sgd_solver.cpp:105] Iteration 99100, lr = 0.001
I1008 05:21:58.557344  5299 solver.cpp:218] Iteration 99200 (5.85672 iter/s, 17.0744s/100 iters), loss = 0.00383989
I1008 05:21:58.557435  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0038401 (* 1 = 0.0038401 loss)
I1008 05:21:58.557451  5299 sgd_solver.cpp:105] Iteration 99200, lr = 0.001
I1008 05:22:15.080726  5299 solver.cpp:218] Iteration 99300 (6.05209 iter/s, 16.5232s/100 iters), loss = 0.000993511
I1008 05:22:15.080766  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000993719 (* 1 = 0.000993719 loss)
I1008 05:22:15.080772  5299 sgd_solver.cpp:105] Iteration 99300, lr = 0.001
I1008 05:22:31.623608  5299 solver.cpp:218] Iteration 99400 (6.04493 iter/s, 16.5428s/100 iters), loss = 0.00235422
I1008 05:22:31.623699  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00235443 (* 1 = 0.00235443 loss)
I1008 05:22:31.623720  5299 sgd_solver.cpp:105] Iteration 99400, lr = 0.001
I1008 05:22:47.353873  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 05:22:48.013679  5299 solver.cpp:330] Iteration 99500, Testing net (#0)
I1008 05:22:51.537518  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 05:22:51.674445  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9231
I1008 05:22:51.674471  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.327795 (* 1 = 0.327795 loss)
I1008 05:22:51.837138  5299 solver.cpp:218] Iteration 99500 (4.94722 iter/s, 20.2134s/100 iters), loss = 0.00652299
I1008 05:22:51.837182  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.0065232 (* 1 = 0.0065232 loss)
I1008 05:22:51.837189  5299 sgd_solver.cpp:105] Iteration 99500, lr = 0.001
I1008 05:23:08.374117  5299 solver.cpp:218] Iteration 99600 (6.04709 iter/s, 16.5369s/100 iters), loss = 0.00245357
I1008 05:23:08.374212  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00245377 (* 1 = 0.00245377 loss)
I1008 05:23:08.374229  5299 sgd_solver.cpp:105] Iteration 99600, lr = 0.001
I1008 05:23:25.440006  5299 solver.cpp:218] Iteration 99700 (5.8597 iter/s, 17.0657s/100 iters), loss = 0.00252067
I1008 05:23:25.440039  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00252088 (* 1 = 0.00252088 loss)
I1008 05:23:25.440047  5299 sgd_solver.cpp:105] Iteration 99700, lr = 0.001
I1008 05:23:41.980828  5299 solver.cpp:218] Iteration 99800 (6.04569 iter/s, 16.5407s/100 iters), loss = 0.00259104
I1008 05:23:41.980916  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.00259124 (* 1 = 0.00259124 loss)
I1008 05:23:41.980932  5299 sgd_solver.cpp:105] Iteration 99800, lr = 0.001
I1008 05:23:58.510330  5299 solver.cpp:218] Iteration 99900 (6.04984 iter/s, 16.5294s/100 iters), loss = 0.000673743
I1008 05:23:58.510361  5299 solver.cpp:237]     Train net output #0: SoftmaxWithLoss1 = 0.000673946 (* 1 = 0.000673946 loss)
I1008 05:23:58.510368  5299 sgd_solver.cpp:105] Iteration 99900, lr = 0.001
I1008 05:24:14.230332  5304 data_layer.cpp:73] Restarting data prefetching from start.
I1008 05:24:14.888152  5299 solver.cpp:447] Snapshotting to binary proto file xn/PENLU/snapshot/resnet/res32/res32_mpelu_alpha1_beta1_2study_2decay_gauss_iter_100000.caffemodel
I1008 05:24:14.902196  5299 sgd_solver.cpp:273] Snapshotting solver state to binary proto file xn/PENLU/snapshot/resnet/res32/res32_mpelu_alpha1_beta1_2study_2decay_gauss_iter_100000.solverstate
I1008 05:24:14.950880  5299 solver.cpp:310] Iteration 100000, loss = 0.000907813
I1008 05:24:14.950901  5299 solver.cpp:330] Iteration 100000, Testing net (#0)
I1008 05:24:18.468389  5305 data_layer.cpp:73] Restarting data prefetching from start.
I1008 05:24:18.589645  5299 solver.cpp:397]     Test net output #0: Accuracy1 = 0.9225
I1008 05:24:18.589673  5299 solver.cpp:397]     Test net output #1: SoftmaxWithLoss1 = 0.328287 (* 1 = 0.328287 loss)
I1008 05:24:18.589678  5299 solver.cpp:315] Optimization Done.
I1008 05:24:18.589680  5299 caffe.cpp:259] Optimization Done.
